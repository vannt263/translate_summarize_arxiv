{
  "article_text": [
    "a recurring challenge in statistical physics , computational chemistry , and single molecule experiments is the collection of a sufficient amount of data to estimate physical quantities of interest to adequate precision . in computer simulations of physical or chemical models ,",
    "such quantities include potentials of mean force , phase coexistence curves , fluctuation or temperature - dependent properties , and free energy differences . in single - molecule experiments , these quantities might include potentials of mean force along a pulling coordinate or the distance between fluorescence probes during resonant energy transfer",
    ". for all of these problems , collection of sufficient statistics for a reliable estimate often requires multiple simulations at different thermodynamic states  @xcite or measurements performed under different applied biasing potentials . in computer simulations , multi - state techniques such as umbrella sampling  @xcite , simulated  @xcite and parallel tempering  @xcite and the use of alchemical intermediates in free energy calculations can greatly aid convergence ; in experiments , data collected under constant applied force can help provide adequate sampling of conformations of interest  @xcite .    even with these methods",
    ", it may require a large quantity of data to produce estimates with the desired precision .",
    "computing the most precise estimate possible from the available data can therefore be critical in allowing these quantities to be estimated with reasonable computational or experimental effort .",
    "while the choice of thermodynamic states to sample can also greatly affect efficiency , we focus here on only the problem of statistically efficient estimation given samples from predetermined states .",
    "early methods for computing free energy differences  @xcite or equilibrium expectations  @xcite relied upon one - sided exponential averaging ( exp ) , which is formally exact but does not make the most efficient use of data when samples from more than one state are available  @xcite . subsequently , the bennett acceptance ratio method ( bar )  @xcite greatly improved upon exp for the computation of free energy differences , producing statistically optimal estimates of free energy differences when two states are sampled  @xcite and yielding estimates that can be more than an order of magnitude more precise  @xcite . more recently",
    ", multiple histogram reweighting methods  @xcite were proposed as a way to incorporate data from multiple states to produce superior estimates of free energy differences and equilibrium expectations for arbitrary thermodynamic states , including states not sampled .",
    "while multiple histogram techniques  most notably , the weighted histogram analysis method ( wham )  @xcite  can produce statistically optimal estimates of the discretized densities of states  @xcite or histogram occupation probabilities  @xcite , they have several limitations for the treatment of continuous systems .",
    "first , the reliance on energy histograms of width sufficient to contain many samples  often larger than many times the thermal energy  introduces a bias that can be substantial and often difficult to assess  @xcite .",
    "second , unlike bar , there are no direct expressions to estimate the statistical uncertainty in free energy differences or expectations obtained from wham .",
    "third , application of wham to a samples collected with a biasing potential that is not trivially scaled by a linear field parameter requires a number of bins that grows exponentially in the number of states , making it computationally intractable for even modest numbers of states .",
    "while more recent maximum likelihood  @xcite and bayesian formulations  @xcite mitigate the memory requirements , they do not remove the histogram bias effects , and introduce a costly markov chain monte carlo sampling procedure to estimate uncertainties  @xcite .    here",
    ", we use recent results from the field of statistical inference  @xcite to construct a statistically optimal estimator for computing free energy differences and equilibrium expectations at arbitrary thermodynamic states , using equilibrium samples from multiple thermodynamic states . the resulting estimator , termed the multistate bennett acceptance ratio ( mbar ) estimator as it reduces to bennett s method when only two states are considered  @xcite , is equivalent to wham in the limit that histogram bin widths are shrunk to zero but is derived without the need to invoke histograms . unlike wham",
    ", this estimator provides a direct assessment of uncertainties , critical in making comparison between experiment and theory , and the computational expense of computing the estimator remains modest across a wider variety of applications .",
    "furthermore , it can easily be applied to data sampled from non - boltzmann sampling schemes , or to the analysis of single - molecule experiments in cases where an external bias potential is applied .",
    "this paper is organized as follows : section [ section : extended - bridge - sampling ] recapitulates the literature on extended bridge sampling estimators , used here as the basis for the mbar estimator .",
    "expressions for computing estimates of free energy differences ( section [ section : free - energies ] ) and equilibrium expectations ( section [ section : equilibrium - expectations ] ) are then provided .",
    "finally , we illustrate the method in section [ section : application ] by applying it to the estimation of the potential of mean force for a dna hairpin system by combining data from multiple equilibrium optical force clamp experiments under different external biasing potentials .",
    "suppose we obtain @xmath0 uncorrelated equilibrium samples from each of @xmath1 thermodynamic states within the same ensemble , such as nvt , npt , or @xmath2vt ( see appendix  [ appendix : correlated - data ] for more information on subsampling correlated timeseries data to produce uncorrelated samples ) .",
    "each state is characterized by a specified combination of inverse temperature , potential energy function , pressure , and/or chemical potential(s ) , depending upon the ensemble .",
    "we define the _ reduced potential function _",
    "@xmath3 for state @xmath4 to be @xmath5 \\label{equation : reduced - potential}\\end{aligned}\\ ] ] where @xmath6 denotes the configuration of the system within a configuration space @xmath7 , with volume @xmath8 ( in the case of a constant pressure ensemble ) and @xmath9 the number of molecules of each of @xmath10 components of the system ( in the case of a ( semi)grand ensemble ) . for each state @xmath4",
    ", @xmath11 denotes the inverse temperature , @xmath12 the potential energy function ( which may include biasing weights ) , @xmath13 the external pressure , and @xmath14 the vector of chemical potentials of the @xmath10 system components .",
    "configurations @xmath15 from state @xmath4 are sampled from the probability distribution @xmath16 where @xmath17 is here nonnegative and represents an unnormalized density function , and @xmath18 is the ( generally unknown ) normalization constant ( known in statistical mechanics as the _ partition function _ ) . in samples obtained from standard metropolis monte carlo or molecular dynamics simulations or from experiment ,",
    "this unnormalized density is simply the boltzmann weight @xmath19 $ ] but may in general differ in simulations employing non - boltzmann weights , such as multicanonical simulations  @xcite and those using tsallis statistics  @xcite .",
    "we wish to produce an estimator for the difference in dimensionless free energies @xmath20 where the @xmath21 are related to the dimensional free energies @xmath22 by @xmath23 , and also the equilibrium expectations @xmath24 these expectations can be computed as ratios of the normalization constants if we define new functions @xmath25 , where the @xmath26 no longer need be nonnegative for states from which no samples are collected  @xcite .    to construct an estimator for these ratios of normalization constants , we first note the identity @xmath27 \\cdot \\frac{\\int_{{{\\bf \\gamma } } } d{{{\\mbox{\\boldmath{$x$}}}}}\\ , q_i({{{\\mbox{\\boldmath{$x$ } } } } } ) \\ , \\alpha_{ij}({{{\\mbox{\\boldmath{$x$ }",
    "} } } } ) \\ , q_j({{{\\mbox{\\boldmath{$x$}}}}})}{\\int_{{{\\bf \\gamma } } } d{{{\\mbox{\\boldmath{$x$}}}}}\\ , q_i({{{\\mbox{\\boldmath{$x$ } } } } } ) } \\nonumber \\\\ & = & \\int_{{{\\bf \\gamma } } } d{{{\\mbox{\\boldmath{$x$}}}}}\\ , q_i({{{\\mbox{\\boldmath{$x$ } } } } } ) \\ , \\alpha_{ij}({{{\\mbox{\\boldmath{$x$ } } } } } ) \\ , q_j({{{\\mbox{\\boldmath{$x$ } } } } } )   \\nonumber \\\\ & = & \\left[\\int_{{{\\bf \\gamma } } } d{{{\\mbox{\\boldmath{$x$}}}}}\\ , q_j({{{\\mbox{\\boldmath{$x$}}}}})\\right ] \\cdot \\frac{\\int_{{{\\bf \\gamma } } } d{{{\\mbox{\\boldmath{$x$}}}}}\\ , q_j({{{\\mbox{\\boldmath{$x$ } } } } } ) \\ , \\alpha_{ij}({{{\\mbox{\\boldmath{$x$ } } } } } ) \\ , q_i({{{\\mbox{\\boldmath{$x$}}}}})}{\\int_{{{\\bf \\gamma } } } d{{{\\mbox{\\boldmath{$x$}}}}}\\ , q_j({{{\\mbox{\\boldmath{$x$ } } } } } ) } \\nonumber \\\\ & = &",
    "c_j { \\left \\langle \\alpha_{ij } q_i \\right \\rangle}_j \\label{equation : bennett_starting}\\end{aligned}\\ ] ] which holds for arbitrary choice of functions @xmath28 , provided the @xmath18 are nonzero .    using this relation , summing over the index @xmath29 , and substituting the empirical estimator @xmath30 for the expectations @xmath31",
    ", we obtain a set of @xmath1 estimating equations @xmath32 for @xmath33 , where solution of the set of equations for the @xmath34 yields an estimate of the @xmath18 from the sampled data determined up to a scalar multiplier .",
    "[ equation : extended - bridge - sampling - estimator ] defines a family of asymptotically unbiased estimators parameterized by the choice of functions @xmath28 , known in the statistics literature as _ extended bridge sampling _",
    "estimators  @xcite . by making the choice",
    "@xmath35 we obtain an estimator than has been proven to be optimal , in the sense that it has the lowest variance for a large class of choices of @xmath28  @xcite .",
    "this estimator is also asymptotically unbiased and guaranteed to have a unique solution ( up to a multiplicative constant )  @xcite , and can also been derived from maximum - likelihood measure theoretic methods  @xcite or cast as a reverse logistic regression problem  @xcite .    while a closed - form expression for the @xmath34 can not be obtained from eqs .",
    "[ equation : extended - bridge - sampling - estimator ] and [ equation : optimal - alpha ] , the @xmath34 can nevertheless be easily computed by any suitable method for solving systems of coupled nonlinear equations .",
    "a simple self - consistent iteration method and an efficient newton - raphson solver are described in appendix  [ appendix : solution - of - estimating - equations ] .    in the large sample limit , the error in the ratios @xmath36 will be normally distributed  @xcite , and the asymptotic covariance matrix @xmath37 , where @xmath38 , can be estimated by  @xcite @xmath39 where @xmath40 is the @xmath41 identity matrix ( with @xmath42 the total number of samples ) , and @xmath43 .",
    "the superscript @xmath44 denotes a suitable generalized inverse , such as the standard moore - penrose pseudoinverse , since the quantity in parentheses will be rank - deficient .",
    "@xmath45 denotes the @xmath46 matrix of weights @xmath47 the samples are now indexed by a single index @xmath48 , as the association of which samples @xmath49 came from which distribution @xmath50 is no longer relevant .",
    "we note that this definition ensures @xmath51 for all @xmath52 and @xmath53 for all @xmath48 .",
    "the computational cost of evaluating the pseudoinverse of an @xmath41 matrix in computing @xmath54 can be reduced to that of computing the eigenvalue decomposition of a @xmath55 matrix , and in many cases can be reduced directly to a simpler @xmath55 matrix ( see appendix  [ appendix : efficient - computation - of - asymptotic - covariance ] ) .",
    "the covariance of estimates of arbitrary functions @xmath56 and @xmath57 of the log normalization constants @xmath58 can be estimated from @xmath54 by the expansion @xmath59",
    "when configurations are sampled with boltzmann statistics , where @xmath60 $ ] , eqs .",
    "[ equation : extended - bridge - sampling - estimator ] and [ equation : optimal - alpha ] produce the following estimating equations for the dimensionless free energies @xmath61}{\\sum\\limits_{k=1}^k n_k \\ , \\exp[\\hat{f}_k - u_k({{{\\mbox{\\boldmath{$x$}}}}}_{jn } ) ] } \\label{equation : estimator - of - free - energies}\\end{aligned}\\ ] ] which must be solved self - consistency for the @xmath62 .",
    "again , because the normalization constants are only determined up to a multiplicative constant , the estimated free energies @xmath62 are determined uniquely only up to an additive constant , so only differences @xmath63 will be meaningful .",
    "the uncertainty in the estimated free energy difference can be computed from eqs .",
    "[ equation : asymptotic - covariance ] and [ equation : asymptotic - covariance - transformation ] as @xmath64 free energy differences and uncertainties between states not sampled are easily estimated by augmenting the set of states with additional reduced potentials @xmath3 with the number of samples @xmath65 . for these unsampled states ,",
    "no additional self - consistent estimation is required , so many such states can be estimated very efficiently .",
    "the equilibrium expectation of some mechanical observable @xmath66 that depends only on configuration @xmath67 ( and not momentum ) is given by eq .",
    "[ equation : equilibrium - expectation ] , and can be computed as a ratio of normalization constants @xmath68 by defining two additional `` states '' characterized by the functions  @xcite @xmath69 where again @xmath70 $ ] if the expectation with respect to the boltzmann weight is desired . even though @xmath71 may no longer be strictly nonnegative , we can still make use of the extended bridge sampling estimator ( eq .  [ equation : extended - bridge - sampling - estimator ] ) to estimate the expectation @xmath72 since @xmath73 .    similarly , we augment the matrix @xmath45 ( eq .",
    "[ equation : p_weights ] ) with columns @xmath74 and @xmath75 corresponding to @xmath71 and @xmath76 , respectively : @xmath77}{\\sum\\limits_{k=1}^k n_k \\ , \\exp[\\hat{f}_k - u_k({{{\\mbox{\\boldmath{$x$}}}}}_n ) ] } \\nonumber \\\\ w_{na } & = & \\hat{c}_a^{-1 } \\ , \\frac{\\exp[-u({{{\\mbox{\\boldmath{$x$}}}}}_n)]}{\\sum\\limits_{k=1}^k n_k \\ ,",
    "\\exp[\\hat{f}_k - u_k({{{\\mbox{\\boldmath{$x$}}}}}_n)]}\\end{aligned}\\ ] ] where the normalization constants @xmath78 and @xmath79 are defined in terms of self - consistent estimating equations as @xmath80}{\\sum\\limits_{k=1}^k n_k \\ , \\exp[\\hat{f}_k - u_k({{{\\mbox{\\boldmath{$x$}}}}}_n ) ] } \\nonumber \\\\ \\hat{c}_a & = & \\sum\\limits_{n=1}^n \\frac{\\exp[-u({{{\\mbox{\\boldmath{$x$}}}}}_n)]}{\\sum\\limits_{k=1}^k n_k \\ , \\exp[\\hat{f}_k - u_k({{{\\mbox{\\boldmath{$x$}}}}}_n ) ] } \\end{aligned}\\ ] ] we can then write the estimator of the expectation as @xmath81 and an estimator for the uncertainty as @xmath82 where the covariance matrix @xmath54 is now computed from the augmented @xmath45",
    ". covariances between estimates of @xmath72 at different thermodynamic states , or between two observables @xmath72 and @xmath83 , can also be constructed by adding the appropriate columns to the covariance matrix and applying eq .",
    "[ equation : asymptotic - covariance - transformation ] to estimate the desired uncertainty .",
    "if the dimensionless free energies @xmath62 have already been determined , computation of @xmath84 for any @xmath66 and any @xmath26 does not require additional iterative solution of the self - consistent estimating equations .",
    "the mbar estimator is not limited in application to data produced from simulation  it can also be applied to combine data from multiple equilibrium experiments in the presence of externally - applied fields . to illustrate , we estimate potential of mean force ( pmf ) of a dna hairpin attached by dsdna linkers to glass beads along the distance between the beads .",
    "the collection of equilibrium trajectories under a variety of constant force loads ( corresponding to a linear external potential along the extension coordinate ) for the dna hairpin system 20r55/4 t collected by an optical double trap experiment  @xcite we reported earlier  @xcite .",
    "the complete dataset was obtained from michael woodside ( national institute for nanotechnology , nrc and department of physics , university of alberta ) , and consists of 16 trajectories at 296.15 k , each 5 s in duration and sampled with a period of 0.1 ms , totaling 50 000 samples each .",
    "each trajectory was collected under a different constant force load , with force loads ranging from 12.35 pn to 14.41 pn , with an estimated 10% relative error in the measurement of this force value .",
    "the data were analyzed to produce an optimal estimate of the pmf under a force load of 14.19 pn , a force load where it is difficult to determine the entire pmf to high precision from equilibrium trajectories at this force load alone ( figure  [ figure : pmf ] ) .",
    "the sampled extension range was divided up into 50 unequally - sized bins such that the number of samples per bin was equal in order to avoid regions with zero histogram counts , as would occur with equally - spaced bins .",
    "analysis with the mbar estimator took 18 s on a standard 2.16 ghz intel core 2 duo macbook pro , and the resulting error bars are more than an order of magnitude smaller than those derived from the single trajectory at this force load in the poorly sampled region of the pmf .",
    "below , we describe how this analysis was performed with both types of analysis .    to estimate the potential of mean force from the 14.19 pn trajectory alone ( black filled squares in figure  [ figure : pmf ] ) , the total number of counts @xmath0 per histogram bin was determined , and the reduced potential of mean force ( in units of @xmath85 ) @xmath21 computed up to an irrelevant additive constant from @xmath86 where @xmath87 is the relative width of bin @xmath4 , necessary to correct for the nonuniform bin sizes .",
    "the statistical uncertainty in the histogram count was estimated by standard methods ( see eq .  26 of @xcite ) @xmath88 where @xmath89 is the statistical inefficiency of the extension time series , estimated from the extension autocorrelation function ( see section 5.2 of @xcite ) .    to estimate the potential of mean force using the mbar estimator , the dataset was first subsampled with an interval equal to the statistical inefficiency of each trajectory at constant force to produce a set of uncorrelated samples .",
    "the reduced potential energy for each state @xmath90 under the experimental conditions corresponds to @xmath91 \\end{aligned}\\ ] ] where @xmath92 is the ( unknown ) potential energy function of the system in the absence of an externally - applied biasing potential , @xmath93 is the pressure - volume work , and @xmath94 is the ( known ) externally applied biasing potential , given by @xmath95 where @xmath96 is the extension coordinate , @xmath97 is the constant applied force along the positive @xmath98 direction , and @xmath99 is a constant offset .    because only differences @xmath100 appear in the estimating equations ( eq .",
    "[ equation : estimator - of - free - energies ] ) , the unknown components of the reduced potential energy cancel out and need not be considered @xmath101 while the constant term @xmath102 involving the unknown zero potential intercepts will appear in the estimated state free energies , these do not influence computed expectations in eq .",
    "[ equation : estimator - for - expectations ] , and are hence irrelevant .",
    "the probability of finding the system in a bin @xmath4 under the conditions of interest is given by the expectation @xmath103 where @xmath104 is an indicator function that assumes the value of @xmath105 if the system is in bin @xmath4 and zero otherwise .",
    "the potential of mean force ( in units of thermal energy @xmath85 ) can then be computed from the @xmath13 , up to an irrelevant additive constant , as @xmath106 and the uncertainties propagated by eq .",
    "[ equation : asymptotic - covariance - transformation ] .",
    "because each potential of mean force is only determined up to an arbitrary additive constant , the mean value of each pmf was subtracted before plotting .",
    "this is equivalent to choosing the additive constants so as to obtain an optimal least - squares rms fit between the two pmfs .",
    "it should be noted that these pmf corresponds to the potential of mean force along the entire system connected to the glass beads , which includes not only the dna hairpin but the two dsdna linkers and their attachments to the glass beads . in other work , deconvolution or related methods have been applied to correct for the stretching of the linkers to estimate pmf for the dna hairpin alone  @xcite .",
    "the mbar estimator presented here provides a rapid and robust way to extract estimates of free energy differences and equilibrium expectations from multiple equilibrium samples of different thermodynamic states in a statistically optimal way .",
    "as the estimator is asymptotically efficient among a wide class of `` bridge sampling '' estimators  @xcite , which includes exp and bar as members , the resulting estimates from mbar will have the lowest ( or equal ) variance in the large sample limit .",
    "while multiple histogram techniques  @xcite have been widely used for combining data from multistate simulations , the mbar estimator supplants these methods in the majority of cases .",
    "most importantly , it provides a reliable and inexpensive method for estimating the uncertainties in the resulting estimates and their correlations , which are critical for propagating uncertainties to quantities of interest .",
    "additionally , the elimination of histograms avoids both the bias arising from discretization of continuous energies as well as the computational overhead of constructing and storing high dimensional histograms .    in this framework ,",
    "multiple histogram reweighting methods such as wham can be understood as a histogram kernel density estimator approximation to mbar . in some applications",
    ", histograms can reduce the computational expense required for solving the estimating equations ( eq .",
    "[ equation : extended - bridge - sampling - estimator ] ) at the expense of introducing bias . when samples are distributed according to the boltzmann weight , the estimator for the free energies ( eq .  [ equation : estimator - of - free - energies ] ) is precisely eq .",
    "21 of  @xcite or eq .  15 of  @xcite , in both cases presented as a reduction of the histogram bin width to zero in the standard wham equations ( eqs .",
    "1920 of @xcite ) .",
    "while the validity of this limit is dubious  the derivations in these references rely upon an estimate of the uncertainty in each histogram count which can not be correct when the bins are nearly empty  the derivation of this equation from the extended bridge sampling estimator demonstrates for the first time that these equations are , in fact , asymptotically unbiased estimators of the true free energy differences .",
    "the mbar estimator also can be considered a multistate generalization of bennett s acceptance ratio estimator ( bar )  @xcite . in deriving bar ,",
    "bennett constructed an estimator from eq .",
    "[ equation : bennett_starting ] directly , determining the single @xmath107 which minimized the variance of the estimator of the free energy difference between only two states . in deriving mbar , summing over all states @xmath29 and determining the functions @xmath28 that minimizes the covariance matrix of the estimator for ratios of normalization constants produces an optimal estimator for the multistate case .",
    "a proof of the equivalence of mbar and bar for two states can be found in appendix  [ appendix : equivalence - to - bar ] .",
    "bar and a recent pairwise multistate generalization ( which we shall refer to as pbar )  @xcite differ from mbar in that they can also be applied to _",
    "work measurements between pairs of states , in addition to equilibrium reduced potential differences ( _ instantaneous _ work measurements ) .",
    "however , pbar constructs a total likelihood function from products of likelihood functions connecting pairs of states , assuming independence of all work measurements . for equilibrium samples",
    ", this means that a sampled configuration @xmath108 from a state @xmath4 can only be used to provide information about the instantaneous work required to switch to a _",
    "single _ other state @xmath29 for use in the pbar estimator , whereas in mbar , each sampled @xmath108 can be used to provide information about _ all _ states . as a result",
    ", mbar should require significant fewer samples from each state to produce an estimate of equivalent precision with equilibrium data .",
    "a python implementation of the mbar estimator described here is available under the gnu general public license ( gpl ) , and is provided online , along with several example applications , at https://simtk.org/home/pymbar .",
    "we are indebted to michael woodside for providing us with detailed datasets from ref .",
    "@xcite and helpful comments .",
    "we thank evangelos a.  coutsias , gavin e.  crooks , fernando a.  escobedo , edward h.  feng , andrew gelman , andrew i.  jewett , libusha kelly , jun s.  liu , david d.  l.  minh , david l.  mobley , frank m.  no , vijay s.  pande , sanghyun park , m.  scott shell , zhiqiang tan , matthew a.  wyczalkowski , and the anonymous reviewers for enlightening discussions and constructive comments on this manuscript .",
    "jdc gratefully acknowledges support from ken a.  dill through nih grant gm34993 and vijay s.  pande through an nsf grant for cyberinfrastructure ( nsf che-0535616 ) , and mrs support from richard a.  friesner and an nih nrsa fellowship .",
    "while estimating equations based on eq .",
    "[ equation : extended - bridge - sampling - estimator ] can be applied to correlated or uncorrelated datasets , provided that the empirical estimator @xmath109 remains asymptotically unbiased , the asymptotic covariance matrix estimator ( eq .  [ equation : asymptotic - covariance ] ) only produces sensible estimates when applied to _ uncorrelated _ datasets .",
    "application to correlated datasets may produce severe underestimates of the true statistical uncertainty , and should be avoided .",
    "a set of uncorrelated configurations can be obtained from a correlated time series , such as is generated by a molecular dynamics or metropolis monte carlo simulation , by subsampling the time series with an interval approximately equal to the equilibrium relaxation time for the system . because the equilibrium relaxation time is difficult to compute for all but the simplest systems",
    ", we find the _ maximum _ of the statistical inefficiency @xmath89 computed for several relevant observables ( such as the reduced potential @xmath110 in boltzmann - weighted sampling , structural observables @xmath66 in the computation of potentials of mean force , etc . ) provides a practical estimate useful for subsampling .    the statistical inefficiency @xmath111 of the observable @xmath66 of a time series @xmath112 is formally defined as ( see janke  @xcite for a detailed exposition ) @xmath113 where @xmath114 denotes the integrated autocorrelation time and @xmath115 the normalized fluctuation autocorrelation function of the observable @xmath116 .",
    "direct application of these equations substituting the empirical estimator for the expectation can be problematic due to statistical noise . as a result ,",
    "there exist a number of standard procedures  @xcite to improve the quality and stability of this estimate for physical systems , making use of properties such as stationarity .",
    "the fast method for estimating the integrated autocorrelation time described in section 5.2 of chodera et al .",
    "@xcite is implemented in the python implementation of mbar available online .",
    "application of mbar to simulation data requires @xmath117 to be evaluated for all @xmath1 reduced potential functions @xmath110 and all @xmath118 uncorrelated sampled configuration @xmath108 ,",
    "a total of @xmath119 reduced potential evaluations . in practice , this is not overly burdensome ; the samples @xmath108 are generally produced by schemes that generate chains of highly correlated samples , such as molecular dynamics or monte carlo simulations .",
    "once the stored configurations are subsampled to eliminate correlations and produce an effectively uncorrelated sample ( as described above ) , the number of remaining samples @xmath120 is generally smaller than the number of samples @xmath121 produced during the simulation by one or more orders of magnitude .    in cases",
    "where the @xmath110 differ only by a linear scaling parameter of one or more components ( such as temperature or an external field parameter ) , computation of @xmath117 for all @xmath1 states is a trivial operation . for other cases , such as",
    "when all samples are collected from thermodynamic states that only differ in the external biasing potential ( e.g.  linear or harmonic ) , we note that the reduced energy differences @xmath122 involve only differences in the external biasing potential , which can often be rapidly computed . section  [ section : application ] contains an illustration of this in application to single - molecule pulling experiments .",
    "a number of methods can be used to obtain a self - consistent solution to the free energy estimating equations obtained from combining eqs .  [",
    "equation : extended - bridge - sampling - estimator ] and [ equation : optimal - alpha ] @xmath123 or , in terms of the dimensionless free energies @xmath124 , @xmath125 while any method capable of solving a coupled set of nonlinear equations may be employed here , we describe some practical choices we made in the implementation of this algorithm . while any method capable of solving a coupled set of nonlinear equations may be employed , we describe two approaches to their solution : a straightforward yet reliable self - consistent iteration method and an efficient yet slightly less reliable newton - raphson method .",
    "both methods are implemented in the python implementation of the estimator available online .      as in @xcite , the @xmath62",
    "could be obtained by self - consistent iteration of eq .",
    "[ equation : estimator - of - free - energies ] using the last set of iterates @xmath126 to produce a new estimated set of iterates @xmath127 : @xmath128 convergence is assured regardless of the initial choice of @xmath129 , so it is sufficient to initialize the iteration by choosing @xmath130 .",
    "alternative initial choices of the initial reduced free energies @xmath129 may speed convergence .",
    "for example , we have found the choice @xmath131 which , for boltzmann weighting ( @xmath132 $ ] ) corresponds to the average reduced potential energy , usually works well .",
    "additional inexpensive choices are possible , such as fixing @xmath133 and estimating consecutive differences @xmath134 , @xmath135 using the bennett acceptance ratio ( bar ) estimator  @xcite .      for numerical reasons , it is convenient to constrain @xmath136 during the course of iteration by subtracting @xmath137 from the updated values in order to obtain a unique solution and prevent uncontrolled growth in the magnitude of the estimates .",
    "iteration is terminated when the quantities of interest change by a fraction of the desired precision with additional iterations , but a convenient rule of thumb is to terminate when @xmath138 .",
    "because the quantities of interest and the relative free energies can converge at different rates , it is advised that the former be monitored when possible .",
    "it is also critical to avoid _ overflow _ in the computation of exponentials @xmath139 . to compute log sums of the form @xmath140",
    ", we can use the equivalent form @xmath141 = c + \\ln \\sum_{n=1}^n \\exp[a_n - c]\\end{aligned}\\ ] ] where @xmath142 . to minimize _ underflow",
    "_ , the terms @xmath143 $ ] can be summed in order from smallest to largest .      a more efficient approach to determination of the @xmath62",
    "is to employ a newton - raphson solver , which has the advantage of quadratic convergence ( a near doubling of the number of digits of precision ) with each iteration when sufficiently near the solution . because each iteration requires inversion of a @xmath144 matrix",
    ", this approach is only efficient if @xmath1 is small , say @xmath145 , but this will be satisfied in a wide number of cases .",
    "first , we write the estimating equations in terms of a set of functions @xmath146 such that the solution of the estimating equations ( eq .  [",
    "equation : appendix - estimating - equations ] ) corresponds to @xmath147 .",
    "several such choices of both the function @xmath148 and the parameterization ( the normalization constants @xmath18 or their logarithms @xmath58 ) are possible , and the efficiencies of approaches based on different choices may differ substantially , but we find it convenient to choose @xmath149 where @xmath150 is defined in eq .  [",
    "equation : p_weights ] .",
    "it can easily be seen that @xmath147 is equivalent to the estimating equations : @xmath151    in newton - raphson , the function @xmath148 is expanded about the current iterate @xmath152 to first order : @xmath153 where @xmath154 we seek the next iterate @xmath155 such that @xmath156 , which yields the update equation @xmath157^+ { { \\bf g}}({{\\mbox{\\boldmath{$\\theta$}}}}^{(n ) } ) \\label{equation : newton - raphson - iteration}\\end{aligned}\\ ] ] where @xmath44 denotes the pseudoinverse .",
    "if all the @xmath17 are unique and @xmath158 for all states , the standard matrix inverse may be substituted for the pseudoinverse .",
    "we only need to iterate over states for which @xmath158 ; the relative free energies of states where @xmath65 , and expectation values at all states , can be determined after the self - consistent equations are solved to determine the relative free energies of states where @xmath158 . since we must constrain @xmath136 to avoid drift during the process of free energy determination , we can simply use a modified form of eq .",
    "[ equation : newton - raphson - iteration ] where rows and columns corresponding to the first state are omitted . @xmath159^+",
    "{ { \\bf g}}({{\\mbox{\\boldmath{$\\theta$}}}}^{(n)})_{(2:k,2:k ) } .",
    "\\label{equation : newton - raphson - iteration - truncate}\\end{aligned}\\ ] ]    @xmath160 $ ] is a scalar multiplier that controls the rate of convergence . since the initial iterate @xmath161 may be far from the realm of quadratic convergence ( i.e.  outside the range at which the taylor expansion in eq .",
    "[ equation : newton - raphson - taylor - expansion ] holds ) , it is often safer to choose an initial @xmath162 .",
    "we have found @xmath163 works well for the first step , with @xmath164 used thereafter .    even then , there are times when with reduced @xmath165 does not prevent numerical instability",
    ". the instability may be due to the initial guess iterate @xmath166 being too far from the region of quadratic convergence , such that the first - order taylor expansion above is a poor approximation to @xmath148 in eq .",
    "[ equation : newton - raphson - taylor - expansion ] . in this case , a better procedure for choosing the initial iterate may aid convergence .",
    "starting with one or more iterations of the self - consistent method ( section [ section : self - consistent - iteration ] ) , or using an initial estimate from application of bar  @xcite to sequential states may be sufficient .",
    "less commonly , failure to converge may be result from numerical precision limiting the accurate calculation of the pseudoinverse @xmath167^+$ ] . in all cases",
    ", we find that self - consistent iteration still works reliably to recover the estimator , and can be used as a fallback procedure .",
    "the @xmath46 matrix @xmath45 ( eq .  [ equation : p_weights ] in the main paper ) can be written in terms of its singular value decomposition @xmath168 where @xmath169 is an @xmath41 unitary matrix of left singular vectors ( such that @xmath170 ) , @xmath171 is an @xmath46 matrix containing @xmath172 singular values along the diagonal , and @xmath173 is a @xmath55 unitary matrix of right singular vectors .",
    "the estimator for the asymptotic covariance matrix @xmath54 ( eq .  [ equation : asymptotic - covariance ] ) can then be expanded to @xmath174^+ ( { { \\bf u } } { { \\bf \\sigma } } { { \\bf v}}^{\\mathrm{t } } ) \\nonumber \\\\ & = & { { \\bf v } } { { \\bf \\sigma}}^{\\mathrm{t}}{{\\bf u}}^{\\mathrm{t}}[{{\\bf i}}_n - { { \\bf u } } { { \\bf \\sigma } } { { \\bf v}}^{\\mathrm{t}}{{\\bf",
    "n } } { { \\bf v } } { { \\bf \\sigma}}^{\\mathrm{t}}{{\\bf u}}^{\\mathrm{t}}]^+ { { \\bf u } } { { \\bf \\sigma } } { { \\bf v}}^{\\mathrm{t}}\\nonumber \\\\ & = & { { \\bf v } } { { \\bf \\sigma}}^{\\mathrm{t}}{{\\bf u}}^{\\mathrm{t}}[{{\\bf u } } { { \\bf u}}^{\\mathrm{t}}- { { \\bf u } } { { \\bf \\sigma } } { { \\bf v}}^{\\mathrm{t}}{{\\bf n } } { { \\bf v } } { { \\bf \\sigma}}^{\\mathrm{t}}{{\\bf u}}^{\\mathrm{t}}]^+ { { \\bf u } } { { \\bf \\sigma } } { { \\bf v}}^{\\mathrm{t}}\\nonumber \\\\ & = & { { \\bf v } } { { \\bf \\sigma}}^{\\mathrm{t}}{{\\bf u}}^{\\mathrm{t}}[{{\\bf u } } ( { { \\bf i}}_n - { { \\bf \\sigma } } { { \\bf v}}^{\\mathrm{t}}{{\\bf n } } { { \\bf v } } { { \\bf \\sigma}}^{\\mathrm{t}}){{\\bf u}}^{\\mathrm{t}}]^+ { { \\bf u } } { { \\bf \\sigma } } { { \\bf v}}^{\\mathrm{t}}\\nonumber \\\\ & = & { { \\bf v } } { { \\bf \\sigma}}^{\\mathrm{t}}{{\\bf u}}^{\\mathrm{t}}{{\\bf u } } [ { { \\bf i}}_n - { { \\bf \\sigma } } { { \\bf v}}^{\\mathrm{t}}{{\\bf n } } { { \\bf v } } { { \\bf \\sigma}}^{\\mathrm{t}}]^+ { { \\bf u}}^{\\mathrm{t}}{{\\bf u } } { { \\bf \\sigma } } { { \\bf v}}^{\\mathrm{t}}\\nonumber \\\\ & = & { { \\bf v } } { { \\bf \\sigma}}^{\\mathrm{t}}[{{\\bf i}}_n - { { \\bf \\sigma } } { { \\bf v}}^{\\mathrm{t}}{{\\bf n } } { { \\bf v } } { { \\bf \\sigma}}^{\\mathrm{t}}]^+ { { \\bf \\sigma } } { { \\bf v}}^{\\mathrm{t}}\\nonumber \\\\\\end{aligned}\\ ] ] we partition the matrix of singular values @xmath171 into a @xmath55 diagonal region @xmath175 ( of which only the first @xmath176 diagonal entries will be nonzero ) and an @xmath177 zero matrix @xmath178 : @xmath179\\end{aligned}\\ ] ] we can then rewrite the above expression as @xmath180 \\left\\ { \\left [ \\begin{array}{cc } { { \\bf i}}_k & { { \\bf 0}}\\\\ { { \\bf 0 } } & { { \\bf i}}_{(n - k ) } \\end{array } \\right ] -   \\left [ \\begin{array}{c } { { \\bf \\sigma}}_k \\\\ { { \\bf 0 } } \\end{array } \\right ] { { \\bf v}}^{\\mathrm{t}}{{\\bf n } } { { \\bf v } }   \\left [ \\begin{array}{cc } { { \\bf \\sigma}}_k & { { \\bf 0 } } \\end{array } \\right ] \\right\\}^+   \\left [ \\begin{array}{c } { { \\bf \\sigma}}_k \\\\ { { \\bf 0 } } \\end{array } \\right ] { { \\bf v}}^{\\mathrm{t}}\\nonumber \\\\ & = & { { \\bf v } } { { \\bf \\sigma}}_k [ { { \\bf i}}_k - { { \\bf \\sigma}}_k { { \\bf v}}^{\\mathrm{t}}{{\\bf n } } { { \\bf v } } { { \\bf \\sigma}}_k ] ^+ { { \\bf \\sigma}}_k { { \\bf v}}^{\\mathrm{t}}\\label{equation : asymptotic - covariance - in - terms - of - svd}\\end{aligned}\\ ] ] we note that pseudoinversion of the quantity in brackets now only requires @xmath181 work , though this can be further reduced to @xmath182 work if the reduced svd is used .    the singular values @xmath183 and matrix of right singular vectors @xmath173 can easily be computed from the eigenvalue decomposition of @xmath184 : @xmath185      in the case that @xmath45 has full column rank ( because all @xmath186 , @xmath187 are unique ) we can make further progress . using eq .  [",
    "equation : asymptotic - covariance - in - terms - of - svd ] , we can write @xmath188^{-1 } \\nonumber \\\\   & = & [ { { \\bf v } } ( { { \\bf \\sigma}}_k^{-2 } ) { { \\bf v}}^{\\mathrm{t}}- { { \\bf n } } ] ^+ \\nonumber \\\\   & = & [ ( { { \\bf w}}^{\\mathrm{t}}{{\\bf w}})^{-1 } - { { \\bf n } } ] ^+\\end{aligned}\\ ] ] we note that @xmath189 , and @xmath190 , and so @xmath191 , and observe that @xmath192 $ ] has rank @xmath193 with kernel @xmath194 @xmath195 { { \\bf 1}}_k & = & ( { { \\bf w}}^{\\mathrm{t}}{{\\bf w}})^{-1 } { { \\bf 1}}_k - { { \\bf n } } { { \\bf 1}}_k \\nonumber \\\\ & = & ( { { \\bf w}}^{\\mathrm{t}}{{\\bf w}})^{-1 } { { \\bf w}}^{\\mathrm{t}}{{\\bf w } } { { \\bf",
    "n } } { { \\bf 1}}_k - { { \\bf",
    "n } } { { \\bf 1}}_k \\nonumber \\\\ & = & { { \\bf n } } { { \\bf 1}}_k - { { \\bf n } } { { \\bf 1}}_k \\nonumber \\\\ & = & { { \\bf 0 } } \\nonumber\\end{aligned}\\ ] ] we can supplement the quantity in brackets with @xmath196 , where @xmath197 is some nonzero scalar , without changing the covariance values computed from it , and make it invertible : @xmath198^{-1 } \\label{equation : covariance - matrix - full - rank}\\end{aligned}\\ ] ] we choose @xmath199 to ensure the inversion is well - conditioned ( as in @xcite ) , producing @xmath200^{-1 } \\label{equation : simplified - asymptotic - covariance}.\\end{aligned}\\ ] ]",
    "we start with eq .  [ equation : estimator - of - free - energies ] . for ease of use , we define @xmath201 and @xmath202 and @xmath203 without loss of generalization , since the equations are symmetric , we examine the self - consistent equation for @xmath204 .",
    "@xmath205}{\\sum\\limits_{k=1}^2 n_{k } \\ , \\exp[\\hat{f}_{k } - u_{k}({{{\\mbox{\\boldmath{$x$}}}}}_{jn } ) ] } \\nonumber \\\\ 1    & = & \\sum_{n=1}^{n_1 } \\frac{\\exp[\\hat{f}_1-u_1({{{\\mbox{\\boldmath{$x$}}}}}_{1n})]}{n_1\\ , \\exp[\\hat{f}_{1 } - u_{1}({{{\\mbox{\\boldmath{$x$}}}}}_{1n } ) ] + n_2 \\,\\exp[\\hat{f}_{2 } - u_{2}({{{\\mbox{\\boldmath{$x$}}}}}_{1n } ) ] } + \\nonumber \\\\ & & \\sum_{n=1}^{n_2 } \\frac{\\exp[\\hat{f}_1-u_1({{{\\mbox{\\boldmath{$x$}}}}}_{2n})]}{n_{1 } \\ , \\exp[\\hat{f}_{1 } - u_{1}({{{\\mbox{\\boldmath{$x$}}}}}_{2n } ) ] + n_2 \\ , \\exp[\\hat{f}_{2 } - u_{2}({{{\\mbox{\\boldmath{$x$}}}}}_{2n } ) ] } \\nonumber \\\\ 1    & = & \\sum_{n=1}^{n_1 } \\frac{1}{n_1 + n_2 \\,\\exp[\\delta \\hat{f } - \\delta u({{{\\mbox{\\boldmath{$x$}}}}}_{1n } ) ] } +   \\sum_{n=1}^{n_2 } \\frac{1}{n_{1 } + n_2 \\ , \\exp[\\delta \\hat{f } - \\delta u({{{\\mbox{\\boldmath{$x$}}}}}_{2n } ) ] } \\nonumber \\\\   n_1   & = & \\sum_{n=1}^{n_1 } \\frac{1}{1 + \\frac{n_2}{n_1 } \\,\\exp[\\delta \\hat{f } -",
    "\\delta u({{{\\mbox{\\boldmath{$x$}}}}}_{1n } ) ] } +   \\sum_{n=1}^{n_2 } \\frac{1}{1 + \\frac{n_2}{n_1 } \\ , \\exp[\\delta \\hat{f } - \\delta u({{{\\mbox{\\boldmath{$x$}}}}}_{2n } ) ] } \\nonumber \\\\",
    "n_1   & = & \\sum_{n=1}^{n_1 } \\frac{1}{1 + \\exp[m + \\delta \\hat{f } - \\delta u({{{\\mbox{\\boldmath{$x$}}}}}_{1n } ) ] } +   \\sum_{n=1}^{n_2 } \\frac{1}{1 + \\exp[m + \\delta \\hat{f } - \\delta u({{{\\mbox{\\boldmath{$x$}}}}}_{2n } ) ] } \\label{equation : intermediate1}\\end{aligned}\\ ] ] we make the additional observation that @xmath206 which allows us to write  eq .",
    "[ equation : intermediate1 ] as : @xmath207 }   - 1\\right]+   \\sum_{n=1}^{n_2 } \\frac{1}{1 + \\exp[m + \\delta \\hat{f } - \\delta u({{{\\mbox{\\boldmath{$x$}}}}}_{2n } ) ] } \\\\     & = & \\sum_{n=1}^{n_1 } \\frac{1}{1",
    "+ \\exp[m + \\delta \\hat{f } - \\delta u({{{\\mbox{\\boldmath{$x$}}}}}_{1n } ) ] } -   \\sum_{n=1}^{n_2 } \\frac{1}{1 + \\exp[-m - \\delta \\hat{f } + \\delta u({{{\\mbox{\\boldmath{$x$}}}}}_{2n})]}\\end{aligned}\\ ] ] which is exactly the equation for bar presented in shirts _ et al .",
    "_  @xcite .",
    "we now examine the expression for the variance limited to two states .",
    "when the two thermodynamic states are not identical , the @xmath45 will have full rank , and the asymptotic covariance matrix can be written as ( see eq .  [",
    "equation : covariance - matrix - full - rank ] above ) : @xmath208^{-1}\\end{aligned}\\ ] ] where we have from eq .",
    "[ equation : p_weights ] @xmath209 defining @xmath210 as the fermi function , and @xmath211 , then in the case of two states @xmath212 and @xmath213 .    the matrix @xmath214 can then be written as : @xmath215 if we represent the matrix @xmath216 , the determinant @xmath217 will be @xmath218 . the variance of ratios is actually independent of multiplicative factor used in front of @xmath219 , as we will show below , so we will use @xmath197 in place of @xmath220 for generality .",
    "the inverse of the covariance matrix is then : @xmath221 the determinant will then be : @xmath222 however , we note that @xmath223 is singular , and thus the sum of the first three terms in eq .  [",
    "equation : determinant_thetainv ] equals zero .",
    "additionally , because it has kernel @xmath224 , it must also satisfy @xmath225 and @xmath226 . because we know by symmetry that @xmath227 , which we denote by simply @xmath228 , this determinant then becomes : @xmath229 = \\frac{4ab}{d}\\ ] ]",
    "we then obtain : @xmath230^{-1 }   & = &                                 \\frac{d}{4ab}\\left(\\begin{array}{ccc }                                   \\frac{a_{11}}{d } - n_2 + b &    \\frac{a}{d } - b \\\\                                  \\frac{a}{d } - b &    \\frac{a_{22}}{d } - n_1 + b \\\\                                                                                 \\end{array}\\right)\\end{aligned}\\ ] ] the variance in @xmath231 will be @xmath232 , which reduces to : @xmath233   \\\\                         & = & \\frac{1}{4ba}\\left[(a_{11 } - a - n_2 d ) + ( a_{22 } - a - n_1 d ) + 4bd\\right ] \\\\                         & = & \\frac{d}{a } \\end{aligned}\\ ] ] which is indeed independent of @xmath234 . since",
    "@xmath235 and @xmath236 , given @xmath237 ( as noted above ) , we can find that @xmath238 .",
    "we then obtain : @xmath239^{-1 } - \\frac{n}{n_1n_2 } \\\\                                                                              & = & \\frac{1}{n}\\left[\\left\\langle\\frac{1}{2 + 2\\cosh(m+\\delta \\hat{f } -\\delta u({{{\\mbox{\\boldmath{$x$}}}}}))}\\right\\rangle^{-1 } - \\left(\\frac{n}{n_2 } + \\frac{n}{n_1}\\right)\\right ]                                       \\end{aligned}\\ ] ] this is the equation for the asymptotic covariance of of free energies given for the bar method in shirts _ et al . _",
    "@xcite      here , a _ thermodynamic state _ is defined by a combination of potential energy function ( including any biasing potentials ) and external thermodynamic parameters , such as temperature , pressure , and chemical potential , all within the same thermodynamic ensemble ( e.g. canonical , isothermal - isobaric , ( semi)grand canonical ) .",
    "w. janke , in _ quantum simulations of complex many - body systems : from theory to algorithms _",
    ", edited by j. grotendorst , d. marx , and a. murmatsu ( john von neumann institute for computing , jlich , germany , 2002 ) , vol .  10 , pp .  423445 ."
  ],
  "abstract_text": [
    "<S> we present a new estimator for computing free energy differences and thermodynamic expectations as well as their uncertainties from samples obtained from multiple equilibrium states via either simulation or experiment . </S>",
    "<S> the estimator , which we term the multistate bennett acceptance ratio ( mbar ) estimator because it reduces to the bennett acceptance ratio when only two states are considered , has significant advantages over multiple histogram reweighting methods for combining data from multiple states . </S>",
    "<S> it does not require the sampled energy range to be discretized to produce histograms , eliminating bias due to energy binning and significantly reducing the time complexity of computing a solution to the estimating equations in many cases . </S>",
    "<S> additionally , an estimate of the statistical uncertainty is provided for all estimated quantities . in the large sample limit </S>",
    "<S> , mbar is unbiased and has the lowest variance of any known estimator for making use of equilibrium data collected from multiple states . </S>",
    "<S> we illustrate this method by producing a highly precise estimate of the potential of mean force for a dna hairpin system , combining data from multiple optical tweezer measurements under constant force bias . </S>"
  ]
}