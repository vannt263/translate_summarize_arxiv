{
  "article_text": [
    "suppose that we have a sequence of quantum states , each drawn from an ensemble with known density matrix @xmath0 .",
    "schumacher compression then allows the sequence to be efficiently encoded so that @xmath1 qubits are required to encode each state in the limit that the length of the sequence goes to infinity @xcite .",
    "this resembles classical source coding , in which a source can be compressed to a rate asymptotically approaching its shannon entropy .",
    "however , classical compression can be performed by algorithms that are _ universal _ ( do not depend on a description of the source ) and _ efficient _ ( have running time polynomial in the length of the input ) .",
    "in contrast , most existing quantum compression algorithms either rely on knowing the basis in which @xmath0 is diagonal @xcite or have no known polynomial time implementations @xcite .",
    "this paper presents an efficient , universal , quantum data compression algorithm ; that is , it can compress an unknown i.i.d .",
    "quantum source @xmath2 in @xmath3 time to a rate converging to its von neumann entropy @xmath4 and with error approaching zero as the number of copies , @xmath5 , increases .",
    "another efficient universal quantum data compression algorithm was presented in @xcite , but our algorithm has the advantages of simplicity and a better rate - disturbance tradeoff .",
    "our algorithm consists of two parts : a weak measurement of @xmath2 that estimates @xmath0 accurately without causing very much damage to the state , followed by compressing @xmath6 based on this estimate .",
    "conceptually , this resembles classical methods of compression which determine the empirical distribution of their input in their first pass over the data and perform the compression in the second pass .",
    "the only new difficulties we will encounter in the quantum case come from the need to perform state tomography on @xmath0 without causing very much damage and to compress @xmath0 based on an imperfect estimate .",
    "the problem of weakly measuring states of the form @xmath2 was introduced in @xcite and further developed in @xcite . while it is impossible to measure a single state @xmath0 without causing disturbance",
    ", we expect ordinary classical logic to apply to @xmath2 when @xmath5 is large , so that it is possible to measure even non - commuting observables precisely with little disturbance . for example , in nuclear magnetic resonance , the total @xmath7-magnetization of @xmath8 nuclear spins is continuously measured without causing decoherence by a probe consisting of a coil of wire around the sample .",
    "this is possible because the measurement does not precisely determine the number of nuclear spins pointing in the @xmath7 direction , but only gives a crude estimate of the quantity . in this section",
    ", we will introduce a procedure for state tomography on @xmath2 and then show how to modify it so its disturbance vanishes for large @xmath5 while at the same time it yields an asymptotically accurate estimate of @xmath0 .",
    "let @xmath9 is an orthonormal ( @xmath10 ) basis of traceless hermitian @xmath11 matrices , and write the density matrix @xmath0 as @xmath12 .",
    "estimating @xmath0 reduces to estimating the @xmath13 quantities @xmath14 .",
    "if we now diagonalize @xmath15 as @xmath16 , then @xmath17 , so state tomography reduces to estimating @xmath18 quantites of the form @xmath19 and then performing a classical computation .",
    "quantities @xmath14 would cause the state estimate to converge more quickly , but this would make our exposition slightly more complicated . unfortunately , there is no known polynomial time implementation of quantum state tomography that has the probability of large deviations vanish at the asymptotically optimal rate . ]",
    "if we did nt mind damaging the state , then one method of estimating @xmath20 would be to apply the projective measurement @xmath21 to each copy of @xmath0 .",
    "the number of occurences of @xmath22 would be binomially distributed with mean @xmath23 and variance @xmath24 , so we could reliably estimate @xmath25 to an accuracy of @xmath26 . of course",
    ", this measurement would drastically damage some states , such as @xmath27 .    instead of measuring each state individually",
    ", we can also express this measurement as a collective operation on all @xmath5 states simultaneously .",
    "it is given by the operators m_k= _ _",
    "i=1^n x_i + ( 1-x_i)(- ) .",
    "[ eq : collective - measurement]where @xmath28 ranges from @xmath29 to @xmath5 and @xmath30 denotes the number of 1 s in the @xmath5-bit string @xmath7 . clearly , measuring @xmath31 yields the same statistics as measuring each state individually and counting the @xmath22 outcomes .",
    "the measurement can also be constructed efficiently : we unitarily count the number of occurences of @xmath32 in the @xmath5 states in an ancilla register and then measure the ancilla ( see fig .",
    "[ fig : measure ] ) .    unfortunately , even the collective measurement in eq .",
    "( [ eq : collective - measurement ] ) causes substantial damage to the state .",
    "for example , if the measurement @xmath31 is repeated , then the distribution of @xmath28 will have a variance of @xmath33 the first time and @xmath29 on subsequent measurements .",
    "in @xcite this problem was solved by initalizing the ancilla in fig .",
    "( [ fig : measure ] ) to the state @xmath34 instead of @xmath35 .",
    "the measurement of @xmath28 then has variance @xmath36 and it can be shown@xcite that the damage to @xmath2 is @xmath37 . ref .",
    "@xcite proposed a method which causes more damage to the state , but is easier to analyze for our purposes .    to implement the gentle measurement of @xcite",
    ", we will divide up the range from @xmath38 into @xmath39 bins , with boundaries @xmath40 .",
    "then we will modify the collective measurement of eq .",
    "( [ eq : collective - measurement ] ) to measure only the bin that the state lies in instead of determining the exact value of @xmath28 .",
    "the new measurement @xmath41 is given in terms of the @xmath42 of eq .",
    "( [ eq : collective - measurement ] ) by m_j = _ b_j-1k < b_j m_k [ eq : gentle - measurement]where @xmath43 ranges from 1 to @xmath39 .",
    "if the bin size , @xmath44 , is much larger than the @xmath45 width of @xmath2 then we expect to project onto a measurement outcome that contains almost all of the support of @xmath2 , thereby causing little disturbance .",
    "since we want to avoid having a bin boundary within @xmath45 of the state , _ for any choice of @xmath0 _ , we will choose the @xmath46 uniformly at random from between 0 and @xmath5 .",
    "the choice of @xmath39 now defines a trade - off between disturbance caused to @xmath2 and information gained about @xmath0 .",
    "choosing a smaller @xmath39 means that each bin is larger , so that a measurement outcome lets us infer less about @xmath0 , but we have a smaller probability of damaging @xmath2 by projecting onto only part of its support .",
    "[ prop : gentle ] the measurement @xmath47 described above can be implemented in @xmath48 gates .",
    "if we choose @xmath49 for @xmath50 , then the measurement will fail with probability @xmath51 . upon success",
    ", the measurement outcome is within @xmath52 of @xmath23 and the disturbance ( in the sense of entanglement fidelity ) is less than @xmath53 for any constant @xmath54 .",
    "* proof of proposition  [ prop : gentle ] : *    we begin by describing how to implement @xmath47 .",
    "first we count the number of times @xmath32 occurs in @xmath2 and store the result @xmath55 in an ancilla register .",
    "then we perform a classical computation to determine which bin @xmath43 contains the result @xmath28 .",
    "we measure @xmath43 , thus implementing the projective measurement @xmath56 and then uncompute @xmath43 and finally uncompute @xmath28 .",
    "this is demonstrated in fig  [ fig : gentle - measure ]    we define three possible causes of failure : i ) some @xmath46 will be too close to @xmath23 ( within @xmath57 ) , ii ) there wo nt be any @xmath46 on either side of @xmath23 within @xmath58 and iii ) measuring @xmath59 will yield a bin that does not contain @xmath23 .",
    "using the union bound , we can show that i ) has probability @xmath60 .",
    "next , the probability that no @xmath46 is in @xmath61 $ ] is @xmath62 , and likewise for the interval @xmath63 $ ] , so the probability of ii ) is @xmath64 . finally , if we are given that no bin is within @xmath57 of @xmath23 ( i.e. i ) hasnt occured ) , then using a chernoff bound we can show that the probability of iii ) is less than @xmath65 .",
    "thus , the possibility of failure is dominated by the probability of i ) , which is @xmath51 .",
    "we say that the gentle measurement is successful if none of i ) , ii ) or iii ) occur . in this case",
    ", we can take as our estimate for @xmath25 an arbitrary value within the bin we have measured and by ii ) will err by no more than @xmath66 .",
    "finally , let @xmath59 be the measurement outcome we obtain , let @xmath67 be a purification of @xmath68 and define @xmath69 .",
    "then the post - measurement state is @xmath70 and the entanglement fidelity is @xmath71 . from iii ) we have @xmath72 where @xmath73 , so @xmath74 .    ' '' ''    to perform gentle tomography we simply divide the @xmath5 states into @xmath18 blocks of length @xmath75 and gently measure each block .",
    "if @xmath76 is the basis for @xmath15 , then we can index the blocks by @xmath77 and @xmath78 and measure @xmath79 on block @xmath80 .    for any @xmath50 and fixed hilbert space dimension , applying the procedure described above to @xmath2 requires poly@xmath81 time and fails with probability @xmath51 . upon success ,",
    "the disturbance is less than @xmath82 and the estimate @xmath83 satisfies @xmath84 .",
    "* proof : * we say that tomography succeeds when each of the @xmath18 measurements succeed individually . since the dimension @xmath85 is a constant , we can use proposition  [ prop : gentle ] to bound the failure probability by @xmath86 and the state disturbance by @xmath87 .    we still need to describe how to form an accurate estimate @xmath83 .",
    "assume that each gentle measurement has succeeded .",
    "then the @xmath18 gentle measurements output not state estimates , but bins , ( @xmath88 ) , guaranteeing only that @xmath89 .",
    "we will try to find a state @xmath83 that is consistent with each bin . since @xmath0 is consistent with each bin , we know that some such @xmath83 exists .",
    "we can find it efficiently by solving a semi - definite program for @xmath83 given by the constraints : @xmath90 , @xmath91 and @xmath92 for each bin @xmath93 .",
    "given such a @xmath83 , we have for each gentle measurement that @xmath94 , where @xmath95 .",
    "then if @xmath96 , @xmath97    ' '' ''    this extends our trade - off curve for gentle measurements to full gentle state tomography .",
    "it is an interesting question whether the tradeoff we have found between accuracy and probability of failure is optimal up to logarithmic factors .",
    "now look more closely at the quantum coding . schumacher compression works by identifying the eigenvalues and eigenvectors of @xmath0 , then coherently performing classical shannon compression on sequences of those eigenvectors with probabilities given by the corresponding eigenvalues .",
    "however , we are forced to operate with only an estimate @xmath98 , so we will need to use a data compression scheme that deals well with small inaccuracies in the state estimate .    this case has been analyzed in @xcite , which found that compressing @xmath0 in the basis @xmath99 with any classical algorithm gives an asymptotic rate of @xmath100 .",
    "this is because compressing @xmath0 faithfully reduces to compressing the diagonal entries of @xmath0 in an arbitrary basis @xmath99 . due to the nonnegativity of the relative entropy ( @xmath101 )",
    ", we have @xmath102 for any density matrix @xmath103 that can be diagonalized as @xmath104 .",
    "thus , for any density matrix @xmath103 , we can encode @xmath0 by diagonalizing it in the basis of @xmath103 and then using a classical reversible algorithm .",
    "this will achieve a rate @xmath105 .",
    "unfortunately , there is no simple bound for @xmath106 in terms of @xmath107 ; in fact , the relative entropy can be infinite if the support of @xmath0 is not contained within the support of @xmath83 .",
    "this problem corresponds to the situation when our state estimate has led the encoder to believe that certain vectors will never appear , so that when it encounters them in @xmath0 , it has made no provision to deal with them .",
    "the solution to this is simple : assume that any input vector has a small , but non - zero , chance of occuring .",
    "this means that instead of encoding according to @xmath83 , we will use @xmath108 as our state estimate , for some small @xmath109 .",
    "suppose that after performing gentle tomography @xmath110",
    ". then if we choose @xmath111 , we can bound the rate by @xmath112 the second inequality follows from the operator inequality @xmath113 ( implying @xmath114 ) and the last inequality is due to fannes inequality .",
    "we have neglected the inefficiency of the classical coding , since we can choose it to be @xmath115 and will incur only exponentially small damage for @xmath116 .    to analyze the errors , note that since we usually can not tell when tomography has failed , we ought to consider failure to be another form of disturbance .",
    "thus , the @xmath117 probability of failure dominates the state disturbance and the errors from classical coding .",
    "this is consistent with the observation in @xcite that universal compression schemes have yet to achieve better than a polynomially vanishing error .",
    "since our compression algorithm outputs a variable number of qubits , damage to the encoded state is not the only possible form of error . upon failure ,",
    "our algorithm risks producing a string length well above the @xmath118 qubits we expect ; in fact , the only absolute bound we can establish is @xmath119 qubits .",
    "fortunately , the probability that @xmath2 is compressed to @xmath120 qubits for @xmath121 decreases as @xmath122 for some constant @xmath123 depending only on @xmath0 and @xmath124 .",
    "following @xcite , we define this _ overflow exponent _ as k = _ n the codes described in @xcite achieve the optimal value of @xmath123 : @xmath125 .",
    "in contrast , our algorithm directly , instead of inferring it from @xmath85 gentle measurements of @xmath15 s eigenvectors . using this for gentle tomography results in a compression scheme with an overflow exponent @xmath85",
    "times higher , though still not optimal . ] achieves k=_:h()r _ k=1^d^2 - 1 s(m_k()m_k ( ) ) where @xmath42 denotes the operation of measuring in the eigenbasis of @xmath15 ( i.e. @xmath126 ) .    to review ,",
    "our encoding procedure is :    1 .",
    "perform gentle tomography on @xmath2 using @xmath127 bins , yielding an estimate @xmath83 .",
    "2 .   construct a modified estimate @xmath128 for @xmath129 .",
    "3 .   encode @xmath2 with an efficient classical algorithm ( such as arithmetic coding@xcite ) using the basis of @xmath130 as the computational basis .",
    "4 .   attach a classical description of @xmath130 with @xmath45 bits of precision and a @xmath131 bit register indicating the length of the compressed data .",
    "the decoding procedure is simply to extract the description of @xmath130 and use it as the basis for a classical decoding algorithm .",
    "we have described a polynomial time algorithm for compressing @xmath2 into @xmath132 qubits with error rate @xmath133 .",
    "this matches the error rate and inefficiency of the proof of @xcite , though not their overflow exponent .",
    "the procedure of @xcite , on the other hand , can only achieve a compression rate of @xmath134 by incurring an error rate of @xmath135 ( possibly up to logarithmic factors ) and an overflow exponent of zero .",
    "for example , compressing qubits with constant error is only possible at a rate of @xmath136 .",
    "more elegant would be a method for ergodic sources analogous to lempel - ziv - walsh coding that adaptively created a quantum dictionary and compressed quantum information on the fly .",
    "but the method proposed here still allows the coding of sources with unknown statistics to attain the quantum transmission limit for sources with known statistics as the message length approaches infinity .",
    "this work was partially supported by the hewlett packard  mit foundation ( hp - mit ) , by the aro under a muri program , by arda via nro , and by the nsa and arda under contract number daad19 - 01 - 1 - 06 .",
    "we are grateful to i. chuang , k. matsumoto , r. schack and b. schumacher for helpful discussions ."
  ],
  "abstract_text": [
    "<S> quantum state tomography  the practice of estimating a quantum state by performing measurements on it  is useful in a variety of contexts . </S>",
    "<S> we introduce `` gentle tomography '' as a version of tomography that preserves the measured quantum data . as an application of gentle tomography </S>",
    "<S> , we describe a polynomial - time method for universal source coding . </S>"
  ]
}