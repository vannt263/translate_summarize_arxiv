{
  "article_text": [
    "we consider a piece of cortex @xmath5 ( the _ neural field _ ) , which is a regular compact subset when representing locations on the cortex , or periodic domains such as the torus of dimension 1 @xmath6 in the case of the representation of the visual field , in which neurons code for a specific orientation in the visual stimulus : in that model , @xmath5 is considered to be the feature space  @xcite . ] of @xmath7 for some @xmath8 , and the density of neurons on @xmath5 is given by a probability measure @xmath9 assumed to be absolutely continuous with respect to lebesgue s measure @xmath10 on @xmath5 , with strictly positive and bounded density @xmath11 $ ] .    on @xmath5",
    ", we consider a spatially extended network composed of @xmath12 neurons at random locations @xmath13 drawn independently with law @xmath14 in a probability space @xmath15 , and we will denote by @xmath16 the expectation with respect to this probability space . a given neuron @xmath17 projects local connections in its neighborhood @xmath18 , and long - range connections over the whole neural field .",
    "we will consider here that the local microcircuit connectivity consists of a fully connected graph with @xmath1 nearest - neighbors .",
    "the synaptic weights corresponding to these connections are assumed equal to @xmath19 where @xmath20 ( it is generally positive since local interactions in the cortex tend to be excitatory ) .",
    "a central example is the case @xmath21 with @xmath22 .    with zero probability",
    ", it may occur for a given neuron @xmath23 that its local microcircuit @xmath18 is not well defined .",
    "this occurs if there exists @xmath24 such that the number of neurons at distance strictly smaller than @xmath25 of neuron @xmath23 , denoted @xmath26 , is strictly smaller than @xmath0 and the number of neurons at a distance smaller or equal to @xmath25 is strictly larger than @xmath0 , meaning in particular that there exists several neurons at distance precisely @xmath25 .",
    "this event has a null probability , @xmath18 is defined as the union of all neurons at distance strictly smaller than @xmath25 , completed by @xmath27 neurons randomly chosen among those at distance exactly @xmath25 of neuron @xmath23 .",
    "the neurons also send non - local connections which are specific ( i.e. depend on the type of neurons , indexed here by the spatial location ) , which are much sparser than the local microcircuit .",
    "we will consider that the macro - connections are random variables @xmath28 drawn in @xmath15 and frozen during the evolution of the network , with law : @xmath29 where @xmath30 is a bernoulli random variable with parameter @xmath31 @xmath32 the coefficient @xmath33 governs the connectivity weight between neurons at location @xmath34 and @xmath35 .",
    "for instance , in the visual cortex , if the neurons of the cortical column at location @xmath34 codes for the collinear ( resp , orthogonal ) orientation as neurons in the column at @xmath35 , @xmath33 is positive ( negative ) .",
    "these coefficients are assumed to be smooth ( see assumption  [ assump : spacecontinuity ] ) and bounded , and we denote : @xmath36 the scaling coefficient @xmath37 corresponds to the total incoming connections from the microcircuit related to neuron @xmath38 .",
    "the parameter @xmath31 accounts for the connectivity level of the macrocircuit .",
    "in particular , if populations are not connected , we will set @xmath39 . in that sense , the function @xmath31 does not account for all absent links in the network , but rather for the sparsity of the macro - circuit .",
    "motivated by the fact that the macro - circuit is very sparse and that micro - circuits form non - trivial patches of connectivity , we will assume that , when @xmath40 , @xmath41 the hypothesis on the connectivity ensure the following facts , desirable for a modeling at the neural field scale ( see fig .",
    "[ fig : neurons ] ) :    * the local micro - circuit shrinks to a single point in the limit @xmath40 ( see lemma  [ lem : sizemicro ] ) , and * the macro - circuit is sparse at the level of single cells ( @xmath42 ) , but non - sparse at the level of cortical columns ( @xmath43 ) .    note that in all our developments , one only needs the assumption that @xmath44 as @xmath45 .",
    "this is of course a consequence of our current assumption .",
    "a schematic topology usually considered could be the 2-dimensional regular lattice @xmath46 approximating the unit square @xmath47 ^ 2 $ ] with @xmath48 points . in this model ,",
    "typical micro - circuit size could be chosen to be @xmath49 with @xmath22 , and @xmath31 of order @xmath50 with @xmath51 .",
    "our model takes into account the fact that in reality , neurons are not regularly placed on the cortex , and therefore such a regular lattice case is extremely unlikely to arise ( this architecture has probability zero ) .",
    "moreover , in contrast with this more artificial example , the probability distribution of the location of one given neuron do not depend on the network size . in our setting ,",
    "@xmath14 accounts for the density of neurons on the cortex , and as the network size is increased , new neurons are added on the neural field at locations independent of that of other neurons , with the same probability @xmath14 , so that neuron locations sample the asymptotic cell density .",
    "these elements describe the random topology of the network .",
    "prior to the evolution , a number of neurons @xmath12 and a configuration @xmath52 is drawn in the probability space @xmath15 .",
    "the configuration of the network provides :    * the locations of the neurons @xmath53 i.i.d . with law",
    "@xmath14 * the connectivity weights , in particular the values of the i.i.d .",
    "bernoulli variables @xmath54 of parameter @xmath31 .",
    "let us start by analyzing the topology of the micro - circuit .",
    "at the macroscopic scale , we expect local micro - circuits to shrink to a single point in space , which would precisely correspond to the scale at which imaging techniques record the activity of the brain ( a pixel in the image ) .",
    "the micro - circuit connects a neuron to its @xmath0 nearest neighbors .",
    "we made the assumptions that @xmath0 tends to infinity as @xmath40 while keeping @xmath1 .",
    "this property ensures that for a fixed neuron @xmath55 and for any @xmath56 , the distance and @xmath57 , @xmath58 the euclidean norm of @xmath59 , regardless of the space involved and the dimension @xmath60 considered . ]",
    "@xmath61 is , with overwhelming probability , upperbounded by a constant multiplied by @xmath62 . in the regular lattice case ,",
    "this property is trivial . in our random setting",
    ", we introduce the maximal distance between two neurons in the microcircuit associated to neuron @xmath23 is noted : @xmath63 this quantity has a law that is independent of the specific neuron @xmath23 chosen .    [",
    "lem : sizemicro ] the microcircuit shrinks to a single point in space as @xmath12 to infinity .",
    "more precisely , for any @xmath17 , the maximal distance @xmath64 between two neurons in the microcircuit associated to neuron @xmath23 decreases towards @xmath65 , in the sense that there exists @xmath66 such that the maximal distance between two points in a microcircuit satisfies the inequality : @xmath67 \\leq c \\left(\\left(\\frac{v(n)}{n}\\right)^{\\frac 1 d } + \\frac{1}{v(n)}\\right).\\ ] ]    we have assumed that the locations @xmath34 are iid with law @xmath14 absolutely continuous with respect to lebesgue s measure with density lowerbounded by some positive quantity @xmath68 .",
    "let us fix a neuron @xmath23 at location @xmath34 which is almost surely in the interior of @xmath5 .",
    "we are interested in the distances between different neurons within the microcircuit around @xmath23 , and will therefore consider the distribution of relative locations of neurons belonging to @xmath18 conditionally to the location @xmath34 of neuron @xmath23 .",
    "we will denote @xmath69 the expectation under this conditioning .",
    "it is clear that the set of random variables @xmath70 are identically distributed .",
    "moreover , these are independent conditionally on the value of @xmath34 .",
    "we will show that , for any neuron @xmath71 , the distance @xmath72 tends to zero as @xmath12 increases with probability one . to this end",
    ", we use the characterization of the maximal distance @xmath73 as the minimal radius @xmath74 such that the ball centered at @xmath34 with diameter @xmath74 contains @xmath0 points : @xmath75 we will show that there exists a quantity @xmath76 tending to zero such that @xmath77 with large probability , i.e. @xmath78 . to this end , we start by noting that conditionally on @xmath34 , the random variables @xmath79 are independent , identically distributed",
    ". moreover , for @xmath34 fixed , there exists @xmath80 such that for any @xmath81 , @xmath82 .",
    "therefore , for @xmath81 , the random variables @xmath83 are such that : @xmath84}=\\int_{b(r_i,\\alpha(n ) ) } d\\lambda(r)\\in [ \\lambda_{min},\\lambda_{max}]\\times \\gamma(n)\\\\          \\text{var}_i(z_j^n ) = { \\mathcal{e}}_i{[z_j^n ] } - { \\mathcal{e}}_i{[z_j^n]}^2 \\in [ \\lambda_{\\min } - \\lambda_{\\max } \\gamma(n),\\lambda_{\\max}-\\lambda_{\\min } \\gamma(n ) ] \\times \\gamma(n )      \\end{cases}\\ ] ] where @xmath85\\times c = [ ac , bc]$ ] and @xmath86 with @xmath87 the volume of the unit ball in @xmath7 . the radius @xmath76 is chosen such that : @xmath88 with @xmath89 .",
    "this assumption implies that @xmath90\\geq \\eta^d \\frac{v(n)}{n}\\ ] ] we have : @xmath91}= \\frac 1 { v(n)}\\sum_{j=1}^n ( z_j^n-{\\mathcal{e}}_{i}{[z_j^n ] } ) .\\ ] ] which tends to zero in probability , since ( we recall that the variance is of order @xmath92 for @xmath12 large ) @xmath93}\\right)\\right)^2\\right ] = \\frac n { v^2(n ) } \\text{var}_i(z_j^n ) = o \\left(\\frac 1 { v(n)}\\right ) .",
    "\\end{aligned}\\ ] ] the quantity @xmath94 is therefore lowerbounded , with overwhelming probability , by @xmath95 which is , under our assumption on @xmath96 , is greater than @xmath97 for @xmath12 large enough : with overwhelming probability , for large @xmath12 , the microcircuit is fully included in the ball of radius @xmath76 .",
    "we have assumed that the set @xmath5 is bounded .",
    "let us denote by @xmath98 its diameter ( i.e. the maximal distance between two points in @xmath5 ) .",
    "we have : @xmath99 & = { \\mathcal{e}}_i[d^n_m(i ) \\mathbbm{1}_{d^n_m(i)\\leq 2\\alpha(n ) } ] + { \\mathcal{e}}_i[d^n_m(i ) \\mathbbm{1}_{d^n_m(i ) > 2\\alpha(n)}]\\\\          & \\leq 2\\alpha(n ) + d(\\gamma){\\mathcal{p}}_i\\left[m_n(\\alpha(n))<v(n ) \\right]\\\\          & \\leq 2\\alpha(n ) + d(\\gamma){\\mathcal{p}}_i\\left [ \\left \\vert \\frac{m_n(\\alpha(n))}{v(n)}-\\frac{n}{v(n ) } { \\mathcal{e}}_i{[z_j^n ] } \\right\\vert   > \\eta^d-1 \\right]\\\\          & \\leq 2\\alpha(n ) + d(\\gamma)\\frac{{\\mathcal{e}}_i { \\left[\\left(\\frac 1 { v(n)}\\sum_{j=1}^n \\left(z_j^n-{\\mathcal{e}}_i{[z_j^n]}\\right)\\right)^2\\right]}}{(\\eta^d-1)^2 } \\\\          & \\leq c \\left(\\left(\\frac{v(n)}{n})\\right)^{\\frac 1 d } + \\frac{1}{v(n)}\\right )      \\end{aligned}\\ ] ] which ends the proof .",
    "let us now introduce the dynamics of the neurons activity .",
    "the state of each neuron @xmath23 in the network is described by a @xmath100-dimensional variable @xmath101 , typically corresponding to the membrane potential of the neuron and possibly additional variables such as those related to ionic concentrations and gated channels .",
    "these variables have a stochastic dynamics . in order to deal with these stochastic evolutions ,",
    "we introduce a new complete probability space @xmath102 endowed with a filtration @xmath103 satisfying the usual conditions , and we denote by @xmath104 the expectation with respect to this probability space . note that this space is distinct from the configuration space @xmath15 .",
    "once a configuration @xmath52 is fixed for a @xmath12-neurons network , it is frozen and each neuron will have a random evolution following the equations : @xmath105 where @xmath106 governs the intrinsic dynamics of each cell , @xmath107 is a sequence of independent @xmath108 brownian motions of dimension @xmath109 modeling the external noise , @xmath110 a bounded and measurable function of @xmath111 modeling the level of noise at each space location , and @xmath112 the interaction function . the map @xmath113 is the interaction delay between neurons located at @xmath74 and those at @xmath114 which is assumed to be of the form : @xmath115 where @xmath116 is the synaptic transmission time and @xmath117 the transport time ( @xmath118 is the transmission speed assumed constant ) . since @xmath5 is bounded , all delays are bounded by a finite quantity @xmath119 ( in our notations , @xmath120 ) . in what follows , we will use the shorthand notation @xmath121 .",
    "the parameters of the system are assumed to satisfy the following assumptions :    1 .",
    "[ assump : loclipschspace ] @xmath122 is @xmath123-lipschitz - continuous with respect to all three variables , 2 .",
    "[ assump : loclipschbspace ] @xmath124 is @xmath125-lipschitz - continuous with respect to both variables and bounded . we denote @xmath126 3 .",
    "[ assump : lineargrowth ] the drift satisfies uniformly in space ( @xmath74 ) and time ( @xmath127 ) , the inequality : @xmath128 4 .",
    "[ assump : spacecontinuity ] the drift , delay , diffusion and connectivity functions are regular with respect to the space variables @xmath129 ( we will assume for instance that these are all @xmath130-lipschitz continuous ) .",
    "let us first state the following proposition ensuring well - posedness of the network system under the assumptions of the section :    [ pro : existenceuniquenessnetwork ] let @xmath131}$ ] a square integrable process with values in @xmath132 .",
    "under the current assumptions , for any configuration @xmath52 of the network , there exists a unique strong solution to the network equations with initial condition @xmath133 .",
    "this solution is square integrable and defined for all times .",
    "the proof of this proposition is classical .",
    "it is a direct application of the general theory of sdes in infinite dimensions  ( * ? ? ?",
    "* chapter 7 ) , and elementary proof in our particular case of delayed stochastic differential equations can be found in  ( * ? ? ?",
    "* theorem 5.2.2 ) : for any fixed configuration , we have a regular @xmath12-dimensional sde with delays satisfying a monotone growth condition  [ assump : lineargrowth ] ensuring a.s .",
    "boundedness for all times of the solution .",
    "the proof of this property is essentially based on the same arguments as those of the proof of theorem  [ thm : existenceuniquenessspace ] , and the interested reader is invited to follow the steps of that demonstration .",
    "it is important to note that the bound one obtains on the expectation of the squared process depends on the configuration of the network .",
    "indeed , the macroscopic interaction term involves the sum of a random number of terms @xmath134 rescaled by @xmath135 .",
    "the quantity @xmath136 can take large values ( up to @xmath12 ) with positive ( but small ) probability , and therefore the scaling coefficient is not enough to properly control such cases .",
    "the bound obtained by classical methods will therefore diverge in @xmath12 , and this will be a deep question for our aim to prove convergence results as @xmath45 . in the present manuscript , we will be able to handle these terms properly in that limit by using fine estimates related to @xmath137 , see lemma  [ lem : sumchi ] .",
    "we are interested in the limit , as @xmath45 , of the behavior of the neurons .",
    "since we are dealing with diffusions in random environment , there are at least two notions of convergence : _ quenched _ convergence results valid for almost all configuration @xmath138 , and _ annealed _ results valid for the law of the network averaged across all possible configurations . here",
    ", we will show averaged convergence results as well as quenched properties along subsequences .",
    "similarly to what was observed in  @xcite , the limit of such spatially extended mean - field models will be stochastic processes indexed by the space variable , which , as a function of space , are not measurable with respect to the borel algebra @xmath139 . as noted in  @xcite ,",
    "this is not a mathematical artifact of the approach , since neurons accumulating on the neural field are driven by independent brownian motions , and therefore no regularity is to be expected in the limit . however , even if trajectories are highly irregular , this will not be the case of the law of these solutions . in order to handle this irregularity",
    ", we will use the _ spatially chaotic _",
    "brownian motion on @xmath5 , a two - parameter process @xmath140 such that for any fixed @xmath111 , the process @xmath141 is a @xmath109-dimensional standard brownian motion , and for @xmath142 in @xmath5 , the processes @xmath143 and @xmath144 are independent of _ spatially chaotic _ if the processes @xmath145 and @xmath146 are independent for any @xmath142 . ] .",
    "this process is relatively singular seen as a spatio - temporal process : in particular , it is not measurable with respect to @xmath147 .",
    "the spatially chaotic brownian motion is distinct from other more usual spatio - temporal processes . in particular",
    ", its covariance is @xmath148}=(t\\wedge t ' ) \\delta_{r = r'}$ ] : the covariance is not measurable with respect to @xmath139 .",
    "in contrast , the more classical space - time brownian motion ( the process corresponding to space - time white noise differential terms ) on the positive line ( @xmath149 ) has a covariance @xmath150 : it is continuous with respect to space . it is also distinct from wiener processes on hilbert spaces  ( * ? ? ? * chapter 4.1 . ) ( a.k.a .",
    "cylindrical brownian motions ) which have a covariance defined through a trace - class operator on the hilbert space , and may be decomposed as the sum of standard brownian motions on a basis of that hilbert space ( i.e. , there is a countable number of brownian motions involved ) . the chaotic brownian motion , due to his high singularity as a space - time process ,",
    "is more suitably seen as an infinite collection of wiener processes .",
    "we will show that the network equations   satisfies the propagation of chaos property in the limit where @xmath12 goes to infinity , and that the state of the network converges towards a very particular mckean - vlasov equation involving a spatially chaotic brownian motion .",
    "the propagation of chaos property ( boltzmann s molecular chaos hypothesis , or stozahlansatz ) states that , provided that the initial conditions of all neurons are independent , the law of any finite set of neurons converge to a product of laws ( loosely speaking , are asymptotically independent ) for all times ( see  @xcite ) . in our network , this property means that the heuristic notion of boltzmann s stozahlansatz applies in that the dependence relationship between the state of , say 2 , fixed neurons in the network , dilute away in the thermodynamic limit , and these end up being independent in the large @xmath12 limit . in detail , for almost all configuration of the network , the asymptotic law of neurons located at @xmath74 in the support of @xmath14 will be measurable with respect to @xmath151 and converge towards the stochastic neural field mean - field equation with delays : @xmath152\\,dt\\\\          + \\int_{\\gamma } j(r , r'){\\mathbbm{e}}_{\\bar{z}}[b(\\bar{x}_t(r),\\bar{z}_{t-\\tau(r , r')}(r ' ) ) ] \\ , d\\lambda(r ' ) \\,dt       \\end{gathered}\\ ] ] where @xmath153 is a spatially chaotic brownian and the process @xmath154 is independent and has the same law as @xmath155 . in other words",
    ", we will show that the law of the solution @xmath156 , noted @xmath157 , is measurable with respect to @xmath147 , and that the mean - field equation can be expressed as the integro - differential mckean - vlasov equation : @xmath158 let us eventually give the fokker - planck equation on the possible density @xmath159 of @xmath160 with respect to lebesgue s measure : @xmath161 .",
    "\\end{gathered}\\ ] ]    the mean - field equations   are similar to those found in the setting of  @xcite but present an additional term related to the presence of a micro - circuit , showing the local averaging effects arising in our setting .",
    "interestingly , this shows a kind of universal behavior across all possible choices of parameters @xmath0 and @xmath31 , i.e. across possible local statistics of the topology .",
    "the limit equations are very complex : similarly to what was discussed in  @xcite , they resemble mckean - vlasov equations but involve delays , spatially chaotic brownian motions and an ` integral over spatial locations ' ( in a sense that will be made clearer in the sequel ) .",
    "this is hence a very unusual stochastic equation we need to thoroughly study in order to ensure that these make sense and are well - posed .",
    "the existence and uniqueness of solutions to this mean - field equation are addressed in section  [ sec : existenceuniquenessspace ] , and the proof of the propagation of chaos and convergence of the network equations towards the solution of the mean - field equation is performed in section  [ sec : propachaspace ] .",
    "the mean - field equation   involves two unusual terms : a stochastic integral involving spatially chaotic brownian motions and an integrated mckean - vlasov mean - field term with delays .",
    "the spatially chaotic brownian motion was introduced in  @xcite . in order to handle these equations , we start by introducing and discussing the functional spaces in which we are working , and the notion of solutions to these singular equations .    first of all , in order to make sense of the mean - field equation  , we need to show that the lebesgue s integral over @xmath5 term is well defined .",
    "this integral involves the expectation of the process , so even though the solution is not measurable with respect to space , its expectation may be depending on the regularity of its law with respect to space . in this view",
    ", we consider the set @xmath162 of spatially chaotic processes @xmath163 defined for times @xmath164 $ ] that have the following continuity property : there exists a _ coupled process _ @xmath165 indexed by @xmath111 , such that for any fixed @xmath111 , @xmath165 has the same law as @xmath156 , and moreover , there exists a constant @xmath66 such that for any @xmath166 : @xmath167}\\left\\vert \\hat{x}_t(r)-\\hat{x}_t(r')\\right\\vert \\right]}\\leq c ( \\vert r - r'\\vert + \\sqrt{\\vert r - r'\\vert}).\\ ] ] note that in this case , for any lipschitz - continuous function @xmath168 , the map @xmath169}$ ] is continuous ( hlder @xmath170 ) . in particular",
    ", it is measurable .",
    "one can then define the lebesgue s integral of it over @xmath5 .",
    "such processes are called _ chaotic processes with regular law_.    we note that in the absence of space - dependent delays , the process is more regular ( lipschitz - continuous ) .",
    "moreover , stochastic processes @xmath171 are said square integrable for all @xmath111 if : @xmath172}<\\infty.\\ ] ]    we further consider the subset @xmath173 composed of processes @xmath163 that satisfy the following regularity in time : there exists @xmath66 such that : @xmath174}\\leq c ( \\sqrt{\\vert t - t'\\vert } + \\vert t - t'\\vert).\\ ] ] eventually , for a process @xmath175 , we define the squared norm : @xmath176}\\vert{z_s({r})}\\vert^2 \\right]}\\,d\\lambda(r)\\ ] ] and the @xmath177 norm : @xmath178}\\vert{z_s({r})}\\vert \\right]}\\,d\\lambda(r).\\ ] ] these clearly define norms on random variables indexed by @xmath111 , when identifying processes that are @xmath179-a.s .",
    "we denote @xmath180 the set of of random variables in @xmath162 such that @xmath181 .",
    "note that this norm depends on @xmath14 the distribution over @xmath5 of neurons .",
    "it is of course possible to define a norm using lebesgue s measure on @xmath5 , which would be in that case independent of the choice of @xmath14 .",
    "the two obtained measures will be of course equivalent since here we assumed that @xmath14 was equivalent to lebesgue s measure .",
    "let us start by giving a simple yet informative example of such process .",
    "let @xmath143 be a spatially chaotic brownian motion , and consider @xmath182 , r\\in\\gamma}$ ] a @xmath183-progressively measurable real - valued process indexed by @xmath184 that belongs to @xmath185 and which is independent of the collection of brownian motions @xmath186 .",
    "we denote by @xmath187 the coupled process corresponding to the regularity condition .",
    "we assume that for any @xmath188 we have @xmath189 } < c<\\infty , \\text { and}\\\\                       { \\mathbbm{e}\\left [ \\vert \\hat{\\delta}_t(r)-\\hat{\\delta}_t(r')\\vert^2 \\right]}\\leq c^2 ( \\vert r - r'\\vert + \\sqrt{\\vert r - r'\\vert})^2                  \\end{cases}\\ ] ] since for any fixed @xmath111 , the process @xmath143 is a standard brownian motion , the process @xmath190 defined by the stochastic integral : @xmath191 is well defined .",
    "it is spatially chaotic since for @xmath142 the brownian motions @xmath143 and @xmath144 and the processes @xmath192 and @xmath193 are independent .",
    "moreover , they have a regular law in the sense of our definition .",
    "indeed , let @xmath194 be a standard brownian motion independent of @xmath187 .",
    "the process @xmath195 has the same law as @xmath190 , and moreover , @xmath196}\\leq \\left(\\int_0^t { \\mathbbm{e}\\left [ \\vert   \\hat{\\delta}_s(r)-\\hat{\\delta}_s(r')\\vert^2 \\right]}\\,ds\\right)^{1/2}\\leq \\sqrt{t } c ( \\vert r - r'\\vert+\\sqrt{\\vert r - r'\\vert}).\\ ] ] the process @xmath190 therefore belongs to @xmath162 .",
    "moreover , it is a square integrable martingale with quadratic variation @xmath197}\\,ds$ ] .",
    "this implies that for any @xmath198 in @xmath199 $ ] : @xmath200 } = { \\mathbbm{e}\\left [ \\vert\\int_t^{t ' } \\delta_s(r ) dw_s(r)\\vert \\right]}\\leq \\left(\\int_{t}^{t ' } { \\mathbbm{e}\\left [ \\vert\\delta_s(r)\\vert^2 \\right]}\\,ds\\right)^{1/2}\\leq c \\sqrt{t'-t}.\\ ] ]    the process therefore belongs to @xmath201 .",
    "note that this example illustrates an important fact .",
    "the process @xmath190 involves two processes , @xmath192 and @xmath143 , and in order to build up the coupled @xmath202 , we used the fact that we were able to find two processes @xmath187 and @xmath203 such that the pairs @xmath204 and @xmath205 had the same law ( here , the two components are independent ) .",
    "this fact will be also prominent in the definition of the solutions to the mean - field equation .",
    "[ def : solution ] a _ strong solution _ to the mean - field equation   on the probability space @xmath206 , with respect to the chaotic brownian motion @xmath186 and with an initial condition @xmath207 is a spatially chaotic process @xmath208 , i.e. with continuous sample paths and regular law , such that :    1 .",
    "there exists a coupling @xmath209 , r\\in\\gamma)$ ] , such that for any fixed @xmath184 @xmath210 and moreover : @xmath211}\\left\\vert \\hat{\\zeta}^0_t(r)-\\hat{\\zeta}^0_t(r')\\right\\vert \\right]}\\leq c ( \\vert r - r'\\vert + \\sqrt{\\vert r - r'\\vert}),\\\\              { \\mathbbm{e}\\left [ \\sup_{t\\in [ -\\tau,0]}\\left\\vert \\hat{x}_t(r)-\\hat{x}_t(r')\\right\\vert \\right]}\\leq c ( \\vert r - r'\\vert + \\sqrt{\\vert r - r'\\vert } ) .",
    "\\end{cases}\\ ] ] this regularity ensures that for any lipschitz - continuous map @xmath212 , the map @xmath213}$ ] is continuous . in particular , it is measurable and hence the integral @xmath214}d\\lambda(r)$ ] can be computed in the usual ( lebesgue s ) sense .",
    "2 .   for any @xmath184 ,",
    "@xmath215)$ ] is a strong solution , in the usual sense ( see  ( * ? ? ?",
    "* defintion 5.2.1 ) ) , i.e. it is adapted to the filtration @xmath216 , almost surely equal to @xmath217 for @xmath218 $ ] , and the equality : @xmath219 \\,ds\\\\                  \\quad+ \\int_0^t \\int_{\\gamma",
    "} j(r , r'){\\mathbbm{e}}_{z } [ b(x_s(r ) , z_{s-\\tau(r , r ' ) } ( r ' ) ) ] d\\lambda(r')\\,ds ,",
    "\\qquad   t>0\\\\                   \\zeta^0_t(r ) , \\qquad t\\in [ -\\tau , 0]\\\\                   ( z_t)\\operatorname{\\stackrel{\\mathcal{l}}{=}}(x_t ) \\text { independent of $ ( x_t)$ and $ ( w_t(\\cdot))$ }                  \\end{cases}\\ ] ] holds almost surely .",
    "[ thm : existenceuniquenessspace ] let @xmath220,\\ ; r\\in\\gamma ) \\in \\mathcal{z}_{0}^2 $ ] a square - integrable process with a regular law . the mean - field equation with initial condition @xmath221 has a unique strong solution on @xmath222 $ ] for any @xmath223 .",
    "the solution belongs to @xmath224 .",
    "this theorem is proved through a usual fixed point argument for a map @xmath225 acting on stochastic processes @xmath226 in @xmath180 defined by : @xmath227 \\,ds\\\\                      \\quad+ \\int_0^t \\int_{\\gamma } j(r , r'){\\mathbbm{e}}_{z } [ b(x_s(r ) , z_{s-\\tau(r , r ' ) } ( r ' ) ) ] d\\lambda(r')\\,ds , \\qquad   t>0\\\\                       \\zeta^0_t(r ) \\qquad , \\qquad t\\in [ -\\tau , 0]\\\\                       ( z_t)\\operatorname{\\stackrel{\\mathcal{l}}{=}}(x_t ) \\text { independent of $ ( x_t)$ and $ ( w_t(\\cdot))$ }          \\end{cases }      \\end{aligned}\\ ] ] we aim at building a sequence of processes by iterating the map @xmath225 starting from a given initial process , and showing that this constitutes a cauchy sequence , converging to the unique fixed point of the map , i.e. the unique solution of the mean - field equations .",
    "this classical scheme appears relatively complex to handle in our present case .",
    "indeed , the construction of the sequence is not trivial , as we need to be able to integrate the expectation of a function of the processes , hence we need this expectation to be measurable with respect to space .",
    "second is the fact that we aim at showing existence and uniqueness in a relatively strong sense ( condition ( ii ) of the definition ) valid for any @xmath111 ( and not @xmath14-almost surely as would be the case under the norm  ) .",
    "let us start by showing that we can iterate the map @xmath225 . to this end",
    ", we analyze the processes @xmath228 , image of processes @xmath229 under the map @xmath225 .",
    "it is easy to see that @xmath230 is spatially chaotic .",
    "let us start by showing that @xmath230 is square integrable ( in what follows , @xmath231 denotes a constant independent of time , that may vary from line to line ) .",
    "we note that : @xmath232 + \\int_{\\gamma } j(r , r ' ) { \\mathbbm{e}}_z[b(x , z_{s-\\tau(r , r')})]d\\lambda(r')\\ ] ] is lipschitz - continuous with respect to @xmath233 ( with constant @xmath234 ) , and hence @xmath235 .",
    "standard inequalities allow showing that the value @xmath236 } \\vert y_s(r)\\vert^2 \\right]}$ ] satisfies the relationship : @xmath237 } \\vert \\zeta^0_s(r)\\vert^2 \\right ] } + t \\,c\\int_0^t ( 1+n_s^x(r))\\,ds",
    "+ 4\\,t \\vert\\sigma(r)\\vert^2 \\bigg ) \\ ] ] which is finite under the assumption that @xmath156 and @xmath221 are square integrable .",
    "note that this property readily implies , by application of gronwall s lemma , that any possible solution is square integrable .",
    "the regularity in time is then a direct consequence of this inequality and of the fact that the lipschitz continuity of @xmath238 implies that @xmath239 . indeed , for @xmath198 , we have @xmath240 } & \\leq \\int_{t}^{t ' } { \\mathbbm{e}\\left",
    "[ \\vert \\psi(r , s , x_s(r))\\vert \\right ] } ds + { \\mathbbm{e}\\left [ \\vert \\sigma(r ) ( w_{t'}(r)-w_t(r))\\vert \\right]}\\\\              & \\leq   c ( 1+n_t^x(r)^{1/2 } ) ( t'-t ) + \\vert \\sigma(r)\\vert \\sqrt{t'-t}.          \\end{aligned}\\ ] ] it therefore remains to show that @xmath230 is regular in law .",
    "let @xmath203 be a standard brownian motion , and assume that @xmath241 is a coupling of @xmath242 in the sense that they are equal in law for any fixed @xmath74 , and that both @xmath165 and @xmath243 have the regularity property   ( @xmath226 is a process satisfying the assumptions of definition  [ def : solution ] ) .",
    "we define @xmath244 as : @xmath245 \\,ds\\\\              + \\int_0^t \\int_{\\gamma } j(r , u){\\mathbbm{e}}_{z } [ b(\\hat{x}_s(r ) , z_{s-\\tau(r , u ) } ( u ) ) ] d\\lambda(u)\\,ds          \\end{gathered}\\ ] ] it is clear that this process has the same law as @xmath230 since @xmath246 , and this obviously also holds for the processes @xmath247 and @xmath248 .",
    "let us denote @xmath249 } \\vert \\hat{x}_s(r)-\\hat{x}_s(r')\\vert \\right]}$ ] .",
    "we have : @xmath250 } \\int_0^s \\bigg\\{k_f(\\vert r - r'\\vert + \\vert \\hat{x}_u(r)-\\hat{x}_u(r')\\vert ) + \\vert \\bar{j}\\vert l   \\big(\\vert \\hat{x}_u(r)-\\hat{x}_u(r')\\vert   \\\\                          & + d_{u-\\tau_s } \\big)+ k_{\\gamma } ( 1+\\vert b\\vert_{\\infty})\\vert r - r'\\vert + \\vert j\\vert_{\\infty } l \\vert \\hat{x}_u(r)-\\hat{x}_u(r')\\vert + \\int_{\\gamma } \\mathbbm{e}[\\vert    \\hat{x}_{u-\\tau_s(r , v)}(v)-\\hat{x}_{u-\\tau_s(r',v)}(v)]d\\lambda(v)\\bigg\\}\\,du\\bigg]\\\\                          & \\leq \\big(c+t ( k_{\\gamma}(1+\\vert b\\vert_{\\infty})+k_f)\\big ) \\vert r - r'\\vert +   c\\big(1+t\\sqrt{k_{\\gamma}}\\vert j\\vert_{\\infty } l \\big)\\sqrt{\\vert r - r'\\vert } + \\int_0^t",
    "\\big(k_f + 2\\vert\\bar{j}\\vert l + \\vert j\\vert_{\\infty}\\big ) d_s^x\\,ds                      \\end{aligned}\\ ] ] and we conclude , using the assumption that @xmath251 , on the regularity of the law of the process @xmath244 . in particular ,",
    "let us emphasize the fact that for any @xmath252 a @xmath97-lipschitz - continuous function , @xmath253 } \\vert { \\mathbbm{e}\\left [ \\varphi(x_t(r))-\\varphi(x_t(r ' ) ) \\right ] } \\vert\\leq c \\big(\\vert r - r'\\vert + \\sqrt{\\vert r - r'\\vert}\\big),\\ ] ] which implies that the expectation @xmath254 $ ] is measurable with respect to the borel algebra @xmath139 in @xmath114 , allowing to make sense of the integral over the space variable @xmath114 .",
    "let us eventually remark that , again , by gronwall s lemma , any possible solution has a coupled process satisfying the regularity condition  .",
    "these properties ensure that we can make sense of the spatial integral term in the definition of @xmath225 for iterates of that function .",
    "a sequence of processes can therefore be defined by iterating the map .",
    "we fix @xmath226 a process in @xmath255 satisfying the coupling assumptions above ( related to definition  [ def : solution ] ) , and build the sequence @xmath256 by induction through the recursion relationship @xmath257 .",
    "we show that these processes constitute a cauchy sequence for @xmath258",
    ". this will not be enough for our purposes : we are interested in proving existence and uniqueness of solutions for all @xmath74 . equipped with the estimates on the distance  , we will come back to the sequence of processes at single locations , show that these also constitute a cauchy sequence in the space of stochastic processes in @xmath259 ( which is complete ) and conclude .",
    "again , one needs to be careful in the definition of the above recursion and build recursively a sequence of processes @xmath260 independent of the collection of processes @xmath261 and having the same law as follows :    * @xmath262 is independent of @xmath133 and has the same law as @xmath133 * for @xmath263 , @xmath264 is independent of the sequence of processes @xmath265 and is such that the collection of processes @xmath266 has the same joint law as @xmath265 , i.e. @xmath267 is chosen such as its conditional law given @xmath268 is the same as that of @xmath256 given @xmath269 .    once all these ingredients have been introduced , it is easy to show that @xmath270 satisfies a recursion relationship , by decomposing this difference into the sum of elementary terms : @xmath271\\\\           & \\quad + \\int_0^t \\int_{\\gamma } j(r , r')\\big\\{\\big ( { \\mathbbm{e}}_{z } [ b(x_s^{k}(r ) , z^{k}_{s-\\tau(r , r ' ) } ( r ' ) ) ] \\\\          & \\qquad \\qquad \\qquad-{\\mathbbm{e}}_{z } [ b(x^{k-1}_s(r ) , z^{k-1}_{s-\\tau(r , r ' ) } ( r ' ) ) ] \\big)\\big\\}d\\lambda(r')\\,ds \\\\               & = : a_t(r ) + b_t(r)+ c_t(r )      \\end{aligned}\\ ] ] and checking that the following inequalities apply : @xmath272 through the use of cauchy - schwarz inequality , @xmath273 by standard mckean - vlasov arguments , and @xmath274 }   \\bigg \\vert \\int_{\\gamma}j(r , r')\\int_0^s \\big({\\mathbbm{e}}_{z } [ b(x_u^{k}(r ) , z_{u-\\tau(r , r')}^{k } ( r ' ) ) - b(x_u^{k-1}(r ) , z_{u-\\tau(r , r')}^{k-1 } ( r ' ) ) ] \\big ) { du\\,}d\\lambda(r ' ) \\bigg\\vert d\\lambda(r)\\bigg]\\\\               & \\leq \\vert j\\vert_{\\infty } \\;\\int_{\\gamma^2 } \\int_0^t{\\mathbbm{e}}\\bigg [ { \\mathbbm{e}}_{z } [ \\big \\vert b(x_u^{k}(r ) , z_{u-\\tau(r , r')}^{k } ( r ' ) ) - b(x_u^{k-1}(r ) , z_{u-\\tau(r , r')}^{k-1 } ( r ' ) ) ] \\big\\vert\\big ) du\\bigg]d\\lambda(r)d\\lambda(r ' ) \\quad ( cs)\\\\                  & \\leq 2 \\ , l\\vert j\\vert_{\\infty } \\int_{\\gamma^2 } \\int_0^t { \\mathbbm{e}\\left [ \\vert x_s^{k}(r)-x_s^{k-1}(r)\\vert \\right]}\\,ds d\\lambda(r)d\\lambda(r')\\quad \\ref{assump : loclipschbspace}\\\\                  & \\leq 2 \\;l\\vert j\\vert_{\\infty } \\int_0^t \\vert{x^{k}-x^{k-1}}\\vert_s^1\\,ds              \\end{aligned}\\ ] ] these inequalities imply : @xmath275 with @xmath276 .",
    "let us now denote for @xmath277 the norm @xmath278 } \\vert",
    "z_s(r ) \\vert \\right]}$ ] consider @xmath279 .",
    "similar developments yield to the inequality : @xmath280 where @xmath281 and @xmath282 correspond to the constants of the penultimate equation . we denote @xmath283 and @xmath284 . by recursion and using equation",
    ", we obtain : @xmath285 this implies that the processes @xmath286 for fixed @xmath74 constitute a cauchy sequence in the space of stochastic processes . from this relationship",
    ", routine methods allow proving existence and uniqueness of fixed point for @xmath225 ( see e.g.  @xcite ) , and that this fixed point is adapted and almost surely continuous .",
    "proving uniqueness of the solution using equation   is then classical .",
    "we therefore proved that there exists a unique solution to the mean - field equation , which moreover is regular in space in the sense defined above .",
    "of course , as stated , the solutions are discontinuous at all points @xmath111 .",
    "the proposition nevertheless ensures a form of regularity in law , which will be central in the sequel to prove averaging effects in the microcircuit .",
    "now that we have introduced suitable spaces in which the mean - field equations are well - defined , and proved that the equation was well - posed , we are in a position to demonstrate the main result of the manuscript , namely the convergence in law of the solutions of the network equations   towards the equations  , and the fact that the propagation of chaos property occurs .",
    "we consider that the network equations have chaotic initial conditions with law continuous in space @xmath287 . in detail , the initial conditions of the @xmath12 neurons in the network are considered independent processes @xmath288 , e)$ ] ( the space of square integrable processes from @xmath289 $ ] on @xmath259 ) with law equal to @xmath290 .",
    "our convergence result raises several difficulties compared to more standard models :    * first is the fact that at the micro - circuit scale , there will be a local averaging principle ( yielding the convergence towards a local term @xmath291 $ ] .",
    "this property is not classical : indeed , in the network equation , the microcircuit interaction term is @xmath292 , and therefore involve the state of neurons located at different places on @xmath5 and different delays .",
    "the convergence will be handled using ( i ) the fact that in the limit considered , the neurons belong to the microcircuit collapse at a single space location , and ( ii ) regularity properties of the law of the solution as a function of space and time",
    ". this convergence will be the subject of lemma  [ lem : convmicro ] .",
    "* second , the macro - circuit interaction term involve delocalized terms across the neural field . the sum will be shown to converge to a non - local averaged term involving an integral over space .",
    "this will be proved through the use of lemma  [ lem : convmacro ] and  [ lem : sumchi ] .",
    "moreover , we will prove our convergence through a non - classical coupling method that we now describe .",
    "let us now fix a configuration @xmath52 of the network .",
    "the neuron labeled @xmath23 in the network is driven by the @xmath109-dimensional brownian motion @xmath293 , and has the initial condition @xmath294 .",
    "we aim at defining a spatially chaotic brownian motion @xmath295 on @xmath296 such that the standard brownian motion @xmath297 is equal to @xmath298 , and proceed as follows .",
    "let @xmath299 , r\\in\\gamma}$ ] be a @xmath300-dimensional spatially chaotic brownian motion independent of the processes @xmath301 .",
    "the process @xmath295 defined by the coupling : @xmath302 is clearly a spatially chaotic brownian motion , and will be used to construct a particular solution of the mean - field equations . in order to completely define a solution of the mean - field equations , we need to specify an initial condition , and aim at coupling it to the initial condition of neuron @xmath23 . to this end",
    ", we define a spatially chaotic process @xmath303 equal in law to @xmath304 and independent of @xmath305 , and define a coupled process @xmath306 as : @xmath307    here again , it is clear that this process is spatially chaotic , i.e. that for any @xmath142 , the processes @xmath308 and @xmath309 are independent , and that @xmath308 has the law of @xmath310 .    now that these processes have been constructed , we are in a position to define the process @xmath311 as the unique solution of the mean - field equation  , driven by the spatially chaotic brownian motion @xmath312 and with the spatially chaotic initial condition @xmath313 : @xmath314d\\lambda(r')\\,dt } \\\\                  &",
    "\\displaystyle{\\quad + \\bar{j}{\\mathbbm{e}}_{z}[b(x_t(r),z_{t-\\tau_s}(r))]\\,dt+ \\sigma(r)\\ , dw^i_t(r ) \\qquad \\text{for } t\\geq 0}\\\\                  \\\\",
    "\\bar{x}^i_t(r ) & = \\zeta^{i,0}_t ( r ) \\qquad \\text{for }   t\\in [ -\\tau , 0]\\\\              \\\\              ( z_t)&\\operatorname{\\stackrel{\\mathcal{l}}{=}}(\\bar{x}^i_t ) \\in { \\mathcal{m}}\\quad \\text { independent of $ ( \\bar{x}^i_t)$ and $ ( w^{i}_t(\\cdot))$}.          \\end{array }          \\right .\\ ] ] the same procedure applied for all @xmath315 allows building a collection of independent stochastic processes @xmath316",
    ". these are clearly independent of the configurations of the finite - size network .",
    "let us denote by @xmath317 the probability distribution of @xmath318 solution of the mean - field equation .",
    "as previously , the process @xmath319 generically denotes a process belonging to @xmath162 and distributed as @xmath109 .",
    "we start by analyzing the local averaging property on the micro - circuit .",
    "this is the subject of the following lemma .",
    "[ lem : convmicro ] there exists a positive constant @xmath281 such that , for any @xmath12 sufficiently large , averaged across all configurations @xmath52 : @xmath320\\right \\vert \\right]}\\right\\ } \\leq k_1 \\sqrt{\\left({\\frac{v(n)}{n}}\\right)^{\\frac{1}{d}}+\\frac{1}{{v(n)}}}\\ ] ]    conditioned on @xmath34 , the set @xmath321 is a collection of independent identically distributed random variables .",
    "the map @xmath322 is lipschitz continuous .",
    "therefore , the regularity properties proved in theorem  [ thm : existenceuniquenessspace ] ensure that we have ( in what follows , @xmath281 denotes a constant , independent of @xmath12 , that may change from line to line ) : @xmath323-{\\mathbbm{e}}_{{z}}[b(\\bar{x}^i_t(r),{z}_{t-\\tau_{s}}(r_i ) ] \\vert \\leq k_1(\\sqrt{\\vert \\tau_{ij}-\\tau_s \\vert } + \\vert r_j - r_i\\vert+ \\sqrt{\\vert r_j - r_i\\vert})=k_1(\\sqrt{d_{ij}}+d_{ij}).\\ ] ] for almost any configuration @xmath52 and any @xmath71 , we have seen that for @xmath12 sufficiently large , by application of proposition  [ lem : sizemicro ] , the distances @xmath72 are small ( of order @xmath62 ) .",
    "moreover , we have : @xmath324 \\\\              & \\quad = \\frac{1}{v(n ) } \\sum_{j\\in { \\mathcal{v}}(i)}\\left ( b(\\bar{x}^i_t(r_i),\\bar{x}^j_{t-\\tau(r_i , r_j)}(r_j ) ) - { \\mathcal{e}}[{\\mathbbm{e}}_{z}[b(\\bar{x}^i_t(r_i),z_{t-\\tau_{ij}}(r_j))]]\\right)\\\\              & \\qquad + \\frac{1}{v(n ) } \\sum_{j\\in { \\mathcal{v}}(i)}{\\mathcal{e}}[{\\mathbbm{e}}_{z}[b(\\bar{x}^i_t(r_i),z_{t-\\tau_{ij}}(r_j ) ) ] ] -   { \\mathbbm{e}}_{z}[b(\\bar{x}^i_t(r_i),{z}_{t-\\tau_s}(r_i ) ) ]          \\end{aligned}\\ ] ] for any measurable function @xmath325 , the quantity @xmath326 $ ] is precisely the average of the random variable @xmath327 .",
    "therefore , a quadratic control argument ( see e.g.  ( * ? ? ?",
    "* theorem 1.4 . ) ) allows to show that the first term is of order @xmath328 , in the sense that : @xmath329\\right)]]\\leq \\frac{k_1}{\\sqrt{v(n)}}.\\ ] ] this argument consists in showing that the expectation of the square of the sum is of order @xmath330 , which is performed by showing that ( i ) the terms of the sum are centered ( i.e. that the expectation term introduced  which was chosen to this purpose is precisely the expectation with respect to @xmath331 of @xmath332 for @xmath331 equal in law to @xmath333 which all have the same law ) and ( ii ) using cauchy - schwarz inequality to bound the term by the square root of the expectation of the squared sum , developing the square and showing that the number of null terms is bounded by some constant multiplied by @xmath0 .",
    "this argument is not developed here as it will be the core of the proof of lemma  [ lem : convmacro ] .",
    "the second term is handled by using the control given by equation   and the result of proposition  [ lem : sizemicro ] , ensuring that @xmath334 -   { \\mathbbm{e}}_{z}[b(\\bar{x}^i_t(r_i),{z}_{t-\\tau_s}(r_i))]\\big]\\big]\\\\\\leq k_1\\bigg(\\sqrt{\\left({\\frac{v(n)}{n}}\\right)^{\\frac{1}{d}}+\\frac 1 { v(n ) } }              + \\left({\\frac{v(n)}{n}}\\right)^{\\frac{1}{d}}+\\frac 1 { v(n)}\\bigg ) .",
    "\\end{gathered}\\ ] ] put together , the two last estimates yield the desired result .",
    "[ lem : convmacro ] the coupled macroscopic interaction term converges towards a non - local mean - field term with speed @xmath335 , in the sense that there exists a constant @xmath336 independent of @xmath12 such that : @xmath337d\\lambda(r)\\right \\vert\\big]\\big]\\leq \\frac{k_2}{\\sqrt{n\\beta(n)}}.\\ ] ]    conditioned on the location @xmath34 of neuron @xmath23 , the collection of @xmath338-random variables @xmath339 are independent and identically distributed .",
    "the sum @xmath340 is therefore , conditionally on @xmath341 and @xmath34 , the sum of independent and identically distributed processes , with finite mean and variance ( since @xmath124 is a bounded function ) .",
    "the expectation of each term in the sum , conditionally on @xmath342 and @xmath34 , is equal to : @xmath343 d\\lambda(r).\\ ] ] let us denote by @xmath344 the term under consideration is simply the empirical average @xmath345 , and conditionally on @xmath341 and @xmath34 , the terms are independent , identically distributed , centered @xmath346-random variables with second moment : @xmath347\\leq \\frac{1}{\\beta(n)}m_2\\ ] ] where @xmath348 is a finite constant independent of @xmath12 , @xmath34 and @xmath341",
    ". let us denote by @xmath349 $ ] the expectation on @xmath338 conditioned on @xmath34 and @xmath342 .",
    "we have : @xmath350 & \\leq \\sqrt{\\hat{{\\mathbbm{e}}}_i\\big[\\big(\\frac 1 n \\sum_{j=1}^n \\phi_{ij}\\big)^2\\big]}\\\\          & \\leq \\frac 1 n \\sqrt{\\sum_{j=1}^n \\hat{{\\mathbbm{e}}}_i\\big[\\phi_{ij}^2\\big ] } \\leq \\sqrt{\\frac{m_2}{n\\beta(n)}}.      \\end{aligned}\\ ] ] thanks to the fact that @xmath348 is independent of @xmath342 , we conclude that : @xmath351 \\big ] = { \\mathbbm{e}}\\big[\\hat{{\\mathbbm{e}}}_i\\big[\\vert \\frac 1 n \\sum_{j=1}^n \\phi_{ij}\\vert\\big]\\big\\vert r_i\\big]\\leq \\sqrt{\\frac{m_2}{n\\beta(n)}}\\ ] ]      now that we have analyzed the local and macroscopic interaction terms defined with the coupled processes , we are in a position to demonstrate our main result , namely the full multiscale convergence result .",
    "[ thm : propagationchaosspace ] let @xmath352 a fixed neuron in the network . under the assumptions  [ assump : loclipschspace]-[assump",
    ": spacecontinuity ] , for almost all configuration @xmath52 of the neuron locations @xmath353 and connectivity links @xmath354 , the process @xmath355 solution of the network equations converges in law towards the process @xmath356 solution of the mean - field equations with initial condition @xmath304 and moreover , the speed of convergence is given by : @xmath357\\right ) = o\\left(\\sqrt{\\left(\\frac{v(n)}{n}\\right)^{\\frac 1 { d}}+\\frac 1 { { v(n)}}}+\\frac 1 { \\sqrt{n\\beta(n)}}\\right)\\ ] ]    the notation @xmath358 denotes the expectation on @xmath15 the distribution of network configurations @xmath52 ,",
    "i.e. space locations @xmath359 and connectivity links @xmath360 .",
    "the expectation @xmath361 $ ] is therefore the global expectation , i.e. on @xmath362 .",
    "the result shows that the expectation tends to zero .",
    "this implies quenched convergence ( i.e. for almost all configuration @xmath52 ) along subsequences . in detail",
    ", the speed of converge @xmath363 announced in the theorem ( on the righthand side of equation  ) allows to define subsequences ( i.e. a sequence of network size @xmath364 ) for which we have almost sure convergence .",
    "these sequences are such that borel - cantelli lemma can be applied , namely subsequences extracted through a strictly increasing application @xmath365 such that @xmath366 is summable .",
    "we prepare for the proof by demonstrating the following fine estimate that will be used to control configurations with more links than the expected value :    [ lem : sumchi ] under our assumptions , for any @xmath17 and @xmath367 , we have for @xmath12 sufficiently large : @xmath368 where @xmath369 .    in order to demonstrate the result , we make use of chernoff - hoeffding theorem  @xcite controlling the deviations from the mean of bernoulli random variables with fixed mean @xmath60 , is such that , for any @xmath370 , @xmath371\\leq \\left(\\left(\\frac p { p+\\varepsilon}\\right)^{p+\\varepsilon}\\left(\\frac { 1-p } { 1-p-\\varepsilon}\\right)^{1-p-\\varepsilon}\\right)^m.\\ ] ] ] .",
    "let us denote by @xmath372 .",
    "this is a binomial variable of parameters @xmath373 .",
    "chernoff - hoeffding theorem ensures that : @xmath374 & \\leq \\left(\\left(\\frac{\\beta(n)}{\\gamma\\beta(n)}\\right)^{\\gamma \\beta(n)}\\left(\\frac{1-\\beta(n)}{1-\\gamma\\beta(n)}\\right)^{1-\\gamma \\beta(n)}\\right)^n\\\\          & \\leq \\exp\\left(-\\gamma \\log(\\gamma ) n \\beta(n ) + n\\big(1-\\gamma\\beta(n)\\big)\\big(\\log\\big(1-\\beta(n)\\big)-\\log\\big(1-\\gamma\\beta(n)\\big)\\big)\\right ) .      \\end{aligned}\\ ] ] using a taylor expansion of the logarithmic terms for large @xmath12 ( using the fact that @xmath31 tends to zero at infinity ) , it is easy to obtain @xmath375 \\leq \\exp\\left ( ( -\\gamma\\log(\\gamma)+\\gamma-1 ) n\\beta(n ) + o(n\\beta(n)^2)\\right)\\ ] ] note that for @xmath367 , the quantity @xmath376 is strictly positive .",
    "we therefore have , for @xmath12 sufficiently large , that the probability is bounded by : @xmath375 \\leq \\exp\\left ( -\\frac 1 2 ( \\gamma\\log(\\gamma)-\\gamma+1 ) n\\beta(n))\\right).\\ ] ] this allows to conclude the lemma as follows .",
    "it is clear by definition that @xmath377 .",
    "therefore , @xmath378",
    "\\end{aligned}\\ ] ] yielding the desired result .",
    "we are now in a position to perform the proof of theorem  [ thm : propagationchaosspace ] .    the proof is based on evaluating the distance @xmath379 $ ] , and breaking it into a few elementary , easily controllable terms .",
    "a substantial difference with usual mean - field proofs is that network equations correspond to processes taking values in @xmath259 in which the interaction term is sum over a finite number of neurons in the network equation , while the mean - field equation is a spatially extended equation with an effective interaction term involving an integral over @xmath5 .",
    "this will be handled using the result of lemma  [ lem : convmacro ] .",
    "we introduce in the distance coupled interaction terms that were controlled in lemmas  [ lem : convmicro ] and  [ lem : convmacro ] and obtain the following elementary decomposition ( each line of the righthand side corresponds to one term of the decomposition , @xmath380 ) : @xmath381\\big)\\ , ds\\\\                   & \\quad + \\frac{1}{n\\beta(n ) } \\sum_{j=1}^{n } \\int_0^t j(r_i , r_j)\\chi_{ij } \\big(b(x^{i,{\\mathcal{a}}_n}_s , x^{j,{\\mathcal{a}}_n}_{s-\\tau_{ij}})-b(\\bar{x}^{i}_s(r_{i}),\\bar{x}^{j}_{s-\\tau_{ij}}(r_{j } ) ) \\big)\\,ds\\\\                   & \\quad + \\int_0^t \\big(\\frac{1}{n\\beta(n ) } \\sum_{j=1}^{n",
    "} j(r_i , r_j)\\chi_{ij } b(\\bar{x}^{i}_s(r_{i}),\\bar{x}^{j}_{s-\\tau_{ij}}(r_{j } ) ) -\\int_{\\gamma } j(r_i , r ' ) { \\mathbbm{e}}_z[b(\\bar{x}^i_s(r_{i}),z_{s-\\tau(r_{i},r')}(r'))]d\\lambda(r')\\big)\\,ds\\\\                         & \\nonumber \\qquad = : a^i_t(n)+b^i_t(n)+c^i_t(n)+d^i_t(n)+e^i_t(n )              \\end{aligned}\\ ] ] it is easy to show , using assumptions  [ assump : loclipschspace ] and  [ assump : loclipschbspace ] , that the terms @xmath382 and @xmath383 satisfy the inequalities : @xmath384 & \\leq k_f\\,\\int_0^{t } { \\mathbbm{e}}\\big[\\sup_{-\\tau\\leq u\\leq s } \\vert x_u^{i,{\\mathcal{a}}_n}-\\bar{x}_u^i(r_{i})\\vert \\big]\\ , ds\\\\                      \\max_{i=1\\cdots n}\\mathcal{e}\\big[{\\mathbbm{e}}\\big[\\sup_{-\\tau\\leq s\\leq t } \\vert b_s^i(n ) \\vert\\big]\\big ] & \\leq \\frac{v(n)+1}{v(n ) } l\\ , \\int_0^{t }   \\max_{k=1\\cdots n}{\\mathcal{e}}\\big[{\\mathbbm{e}}\\big[\\sup_{-\\tau\\leq u\\leq s}\\vert x^{k,{\\mathcal{a}}_n}_u-\\bar{x}^k_u(r_{i } ) \\vert\\big]\\big ] \\ , ds              \\end{aligned}\\ ] ] the term @xmath385 requires to be handled with care , because of the sparsity of the macrocircuit .",
    "indeed , this term involves the sum of @xmath12 random variables and is rescaled by @xmath386 . as we assumed @xmath42 in order to account for the sparsity in the macrocircuit , most terms in the sum are equal to zero such that @xmath387 .",
    "we have : @xmath388\\leq \\vert j\\vert_{\\infty } \\frac 1 { n\\beta(n ) } \\sum_{j } \\chi_{ij } \\int_0^t { \\mathbbm{e}}\\big[\\sup_{0 \\leq u \\leq s } \\vert b(x^{i,{\\mathcal{a}}_n}_u , x^{j,{\\mathcal{a}}_n}_{u-\\tau_{ik}})-b(\\bar{x}^i_u,\\bar{x}^j_{u-\\tau_{ik } } ) \\vert \\big]\\,ds\\ ] ] this expression shows how critical the singular sparse coupling is to our estimates .",
    "indeed , the random variable @xmath389 almost surely tends to @xmath97 as @xmath12 goes to infinity , but it can reach very large values ( up to @xmath390 which diverges as @xmath12 goes to infinity ) .",
    "configurations @xmath52 for which the sum is large are increasingly improbable , but for these configurations , the deterministic scaling @xmath391 is not fast enough to overcome the divergence of the input term .",
    "there is therefore a competition between the probability of having configurations with large values of @xmath392 and the divergence of the solutions .",
    "however , in the present case , this control will be possible using the estimate of the probability that the number of links exceeds @xmath393 using the result of lemma  [ lem : sumchi ] .",
    "indeed , fixing @xmath367 , and distinguishing whether @xmath394 or not , we obtain : @xmath395\\big ] & \\leq   2 \\gamma \\ ; l \\ ; \\vert j \\vert_{\\infty } \\int_0^t \\max_{k=1\\cdots n}{\\mathcal{e}}\\big [ { \\mathbbm{e}}\\big[\\sup_{-\\tau \\leq u \\leq s } \\vert x^{k,{\\mathcal{a}}_n}_{u}-\\bar{x}^k_{u } \\vert \\big]\\big]\\,ds\\\\              & \\qquad + 2 \\vert b\\vert_{\\infty}\\vert j\\vert_{\\infty } { \\mathcal{e}}\\left(\\frac 1 { n\\beta(n ) } \\sum_{j } \\chi_{ij } { \\mathbbm{1}_{\\mathcal{d}_{\\gamma}}}\\right )               \\end{aligned}\\ ] ] where @xmath369 as defined in lemma  [ lem : sumchi ] . by application of this lemma , and using the fact that the second term of the upper bound is negligible compared to @xmath396 , we conclude that : @xmath397\\big ] & \\leq   2 \\gamma \\ ; l \\ ; \\vert j \\vert_{\\infty } \\int_0^t \\max_{k=1\\cdots n}{\\mathcal{e}}\\big",
    "[ { \\mathbbm{e}}\\big[\\sup_{-\\tau \\leq u \\leq s } \\vert x^{k,{\\mathcal{a}}_n}_{u}-\\bar{x}^k_{u } \\vert \\big]\\,ds + \\frac{k_c}{\\sqrt{n\\beta{(n)}}}.               \\end{aligned}\\ ] ]    we are left with controlling the terms @xmath398 and @xmath399 .",
    "these consist of sums only involving the coupled processes , and were analyzed in the previous sections . by direct application of the results of lemmas  [",
    "lem : convmicro ] and  [ lem : convmacro ] , we have : @xmath400\\big ] } & \\leq \\displaystyle{k_1\\sqrt{\\left(\\frac{v(n)}{n}\\right)^{\\frac{1}{d}}+\\frac 1 { { v(n)}}}}\\\\                  \\displaystyle{\\max_{k=1\\cdots n}{\\mathcal{e}}\\big [ { \\mathbbm{e}}\\big[\\sup_{-\\tau\\leq s \\leq t } \\vert e^k_t \\vert \\big]\\big ] } & \\leq \\displaystyle{\\frac{k_2}{\\sqrt{n\\beta{(n ) } } } }              \\end{cases}\\ ] ]    all together , we hence have , for some constants @xmath401 and @xmath402 independent of @xmath12 @xmath403\\right),\\ ] ] the inequality : @xmath404 which proves the theorem by application of gronwall s lemma .    [ cor : propachaosspace ]",
    "let @xmath405 and fix @xmath406 neurons @xmath407 . under the assumptions of theorem  [ thm : propagationchaosspace ]",
    ", the process @xmath408 converges in law towards @xmath409 .",
    "we have : @xmath410\\right ) \\\\              & \\quad   \\leq l \\max_{k=1\\cdots",
    "n}\\mathcal{e}\\left({\\mathbbm{e}}\\left [ \\sup_{-\\tau\\leq t \\leq t } \\left\\vert x^{k,{\\mathcal{a}}_n}_t-\\bar{x}^{k}_t\\right\\vert^2 \\right]\\right)\\\\          \\end{aligned}\\ ] ] which tends to zero as @xmath12 goes to infinity , hence the law of @xmath408 converges towards that of @xmath411 which is equal by definition to @xmath412 .",
    "the dynamics of neuronal networks in the brain lead us to analyze a class of spatially extended networks which display multiscale connectivity patterns that are singular in at least two aspects :    * the network display local dense connectivity patterns in which neurons are connected to their @xmath0-nearest neighbors , where @xmath1 . * the macro - circuit was also singular , in the sense that the probability of two neurons @xmath23 and @xmath38 to be connect tends towards zero .",
    "this is very far from usual mean - field models that consider full connectivity patterns , or partial connectivity patterns proportional to the network size  @xcite . in these cases ,",
    "the convergence is substantially slower , and the rescaling actually required thorough controls on the number of incoming connections to each neurons .",
    "the introduction of local microcircuits with negligible size was suggested in  @xcite , in the context of the fluctuations induced by the microcircuit .",
    "our scaling , motivated by characterizing the macroscopic activity at the scale of the neural field @xmath5 , lead us to consider local microcircuits with spatial extension of order @xmath413 , which tends to zero in the limit @xmath45 . at this scale ,",
    "the fluctuations related to the microcircuit vanish , which allowed identifying the large @xmath12 limit process .",
    "however , at the scale of one neuron ( or considering , similarly to  @xcite , a field of size @xmath12 , i.e. typical distances between neurons of order @xmath97 ) , the microcircuits may induce more complex phenomena in which fluctuations become prominent .",
    "this interesting problem remains largely open and can not be addressed with the techniques presented in the manuscript .",
    "the developments presented in this article also go way beyond what was done in the domain of mean - field analysis of large spatially extended systems . in that domain ,",
    "probably the two most relevant contributions to date are  @xcite and  @xcite . in  @xcite , a relatively sketchy model of neural field",
    "was proposed , in which the system was fully connected and neurons gathered at discrete space location that eventually filled the neural field .",
    "the model presented here is considerably more relevant from the biological viewpoint , and necessitated to deeply modify the proofs proposed in that manuscript . in particular , the connectivity patterns are now randomized , and the proof is now made independent of results arising in finite - populations networks .",
    "moreover , the two main contributions of the article , namely the singular coupling , was absent of the above cited manuscript .",
    "such coupling was discussed in  @xcite , where the authors consider the case of network with nearest - neighbors topology ( only a local micro - circuit ) in which neurons connect to a non - trivial proportion of neurons @xmath3 .",
    "there is a substantial difficulty in considering only very local micro - circuits connectivity and sparse macro - circuits .",
    "here , we solved this problem and framed it in a more general setting with multiscale coupling .",
    "the proof presented in the present manuscript is relatively general .",
    "in particular , it can be extended to models with non locally lipchitz continuous dynamics ( as is the case of the classical fitzhugh - nagumo model  @xcite ) as was presented in  @xcite , or to networks with multiple layers .",
    "the results enjoy a relatively broad universality . indeed , we observe that the limit obtained is independent of the choice of the size of the micro - circuit and sparsity of the macro - circuit ( as long as proper scaling is considered ) .",
    "this property shows that the limit is universal : for any choice of function @xmath0 and @xmath31 , the macroscopic limit of our networks are identical .",
    "an interesting question is then what would be an optimal choice of functions @xmath0 and @xmath31 so that the convergence is the fastest .",
    "the speed of convergence towards the mean - field equation is hence governed by three quantities :    * the term @xmath414 controls the regularity of the law solution of the mean - field equation with respect to space .",
    "the larger @xmath0 , the wider the micro - circuit , and therefore the slowest the local convergence . * the term @xmath415 controls the speed of averaging at the micro - circuit scale , which decreases with the size of the micro - circuit @xmath0 . * the term @xmath396 controls the speed of the averaging at the macro - circuit scale .",
    "this term is of course the smallest when @xmath31 is large . in the biological system under consideration",
    ", there is nevertheless an energetic cost to increasing the connectivity level .",
    "the two first term corresponding to the micro - circuit convergence properties can give an information on the order of the optimal micro - circuit size .",
    "minima are obtained when @xmath0 is of order @xmath416 , e.g. @xmath417 in dimension @xmath97 .",
    "other choices may be analyze to optimize other criteria such that information capacity vs energetic considerations , anatomical constraints , size of clusters sharing resources ,  .",
    "eventually , this result has also implications in neuroscience modeling . in this domain",
    ", authors widely use the so - called wilson - cowan neural field model ( see  @xcite for a review ) .",
    "this model is given by non - local differential equations of type : @xmath418 where @xmath419 represents the mean firing - rate of neurons and @xmath420 corresponds to a sigmoidal function .",
    "this type of equations is similar to those obtained in the analysis of fully connected neural fields , as shown in  @xcite , when considering a discrete wilson - cowan type of dynamics for the underlying network , i.e. a case where @xmath421 and @xmath422 for @xmath420 a smooth sigmoidal function . in this case",
    ", we showed  @xcite that the solutions were attracted by gaussian spatially chaotic processes with mean @xmath423 and standard deviation @xmath424 satisfying the integro - differential equations : @xmath425 where @xmath426 .",
    "these are compatible with the neural field equations .",
    "however , these actually appear to overlook the complex connectivity pattern , and in particular neglect the additional local averaging term that we found here using rigorous probabilistic methods . taking into account local microcircuitry would actually yield an additional term in the equation on @xmath423 : @xmath427 the study of these new equations will , with no doubt , present substantial different dynamics , are offer a new neural field model well worth analyzing in order to understand the qualitative role of local microcircuits on the dynamics ."
  ],
  "abstract_text": [
    "<S> the cortex is a very large network characterized by a complex connectivity including at least two scales : a microscopic scale at which the interconnections are non - specific and very dense , while macroscopic connectivity patterns connecting different regions of the brain at larger scale are extremely sparse . </S>",
    "<S> this motivates to analyze the behavior of networks with multiscale coupling , in which a neuron is connected to its @xmath0 nearest - neighbors where @xmath1 , and in which the probability of macroscopic connection between two neurons vanishes . </S>",
    "<S> these are called singular multi - scale connectivity patterns . </S>",
    "<S> we introduce a class of such networks and derive their continuum limit . </S>",
    "<S> we show convergence in law and propagation of chaos in the thermodynamic limit . </S>",
    "<S> the limit equation obtained is an intricate non - local mckean - vlasov equation with delays which is universal with respect to the type of micro - circuits and macro - circuits involved .    ' '' ''    ' '' ''    </S>",
    "<S> the purpose of this paper is to provide a general convergence and propagation of chaos result for large , spatially extended networks of coupled diffusions with multi - scale disordered connectivity . </S>",
    "<S> such networks arise in the analysis of neuronal networks of the brain . </S>",
    "<S> indeed , the brain cortical tissue is a large , spatially extended network whose dynamics is the result of a complex interplay of different cells , in particular neurons , electrical cells with stochastic behaviors . in the cortex , neurons interact depending on their anatomical locations and on the feature they code for . </S>",
    "<S> the neuronal tissue of the brain constitute spatially - extended structures presenting complex structures with local , dense and non - specific interactions ( microcircuits ) and long - distance lateral connectivity that are function - specific . </S>",
    "<S> in other words , a given cell in the cortex sends its projections at ( i ) a local scale : the neurons connect extensively to anatomically close cells ( the _ microcircuits _ ) , forming a dense local network , and ( ii ) superimposed to this local architecture , a very sparse functional architecture arises , in which long - range connections are made with other cells that are anatomically more remote but that respond to the same stimulus ( the functional _ macrocircuit _ ) . </S>",
    "<S> this canonical architecture was first evidenced by electrophysiological recordings in the 70 s  @xcite and made more precise as experimental techniques developed ( see  @xcite for striking representations of this architecture in the striate cortex ) . </S>",
    "<S> the primary visual cortex of certain mammals is a paradigmatic well documented cortical area in which this architecture was evidenced . in </S>",
    "<S> such cortical areas , neurons organize into columns of small spatial extension containing a large number of cells ( on the order of tens of thousands cells ) responding preferentially to specific orientations in visual stimuli  @xcite , constituting local microcircuits that distribute across the cortex in a continuous map , each cell connecting densely with its nearest neighbors and sparsely with remote cells coding for the same stimulus  @xcite . </S>",
    "<S> these spatially extended networks are called _ neural fields_.    such organizations and structures are deemed to subtend processing of complex sensory or cortical information and support brain functions  @xcite . in particular , the activity of these neuronal assemblies produce a mesoscopic , spatially extended signal , which is precisely at the spatial resolution of the most prominent imaging techniques ( eeg , meg , mri ) . </S>",
    "<S> these recordings are good indicators of brain activity : they are a central diagnostic tool used by physicians to assert function or disfunction .    in these spatially extended systems , the presence of delays in the communication of cells , chiefly due to the transport of information through axons and to the typical time the synaptic machinery needs to transmit it , is essential to the dynamics . </S>",
    "<S> these transmission delays will chiefly affect the long connections of the macrocircuit , which are orders of magnitude longer than those of the microcircuit .    </S>",
    "<S> the mathematical and computational analysis of the dynamics of neural fields relies almost exclusively on the use of heuristic models since the seminal work of wilson , cowan and amari @xcite . </S>",
    "<S> these propose to describe the mesoscopic cortical activity through a deterministic , scalar variable whose dynamics is given by integro - differential equations . </S>",
    "<S> this model was widely studied analytically and numerically , and successfully accounted for hallucination patterns , binocular rivalry and synchronization  @xcite . justifying these models starting from biologically realistic settings </S>",
    "<S> has since then been a great endeavor  @xcite .    </S>",
    "<S> this problem was undertaken recently using probabilistic methods . </S>",
    "<S> the first contribution  @xcite introduced an approximation of the underlying connectivity of the neural network involved , considering a fully connected architecture ( each neuron was connected to all the others ) and neurons in the same column were considered to be precisely at the same spatial location . </S>",
    "<S> they showed propagation of chaos and convergence to some intricate mckean - vlasov equation . </S>",
    "<S> more recently , an heterogeneous macrocircuit model was analyzed in  @xcite . in that paper , the authors considered a network with heterogeneous and non - global connectivity : neurons were connected with their @xmath2-nearest neighbors , where @xmath3 with @xmath4 , or with power - law synaptic weights , and obtained a limit theorem for the behavior of the empirical density . in both cases , </S>",
    "<S> the connectivity was considered at a single scale , and did not reproduce the actual type of connectivity pattern observed in the brain .    in the present manuscript </S>",
    "<S> , we come back to these models with a more plausible architecture including local microcircuit together with non - local macroscopic sparse connectivity . using statistical methods and in particular an extension of the coupling method  @xcite </S>",
    "<S> , we will demonstrate the propagation of chaos property , and convergence towards a complex nonlinear markov equation similar to the classical _ mckean - vlasov _ </S>",
    "<S> equations , but with a non - local integral over space locations and delays . </S>",
    "<S> interestingly , this object presents substantial differences with the usual mckean - vlasov limits : beyond the presence of delays , the neural field limit regime is at a mesoscopic scale where averaging effects locally to occur , but is fine enough to resolve brain s structure and its activity , resulting in the presence of an integral term over space . </S>",
    "<S> the solution , seen as a function of space , is everywhere discontinuous , which makes the limiting object highly singular . </S>",
    "<S> the present work is distinct of that of  @xcite in that we consider local connectivity patterns in which neurons connect to a negligible portion of the neurons . </S>",
    "<S> this includes non - trivial issues , and necessitate to thoroughly control the regularity of the law of the solution as a function of space . on the other hand , beyond the presence of random locations of individual neurons and the presence of a dense microcircuit , the sparse macro - circuit generalizes non - trivially the work done in  @xcite . </S>",
    "<S> indeed , at the macro - circuit scale , the probability of connecting two fixed neurons tends to zero . </S>",
    "<S> we therefore need to deal with a non - globally connected network , and address the problem by using fine estimates on the interaction terms and chernoff - hoeffding theorem  @xcite .    </S>",
    "<S> the speed of convergence towards the mean - field equations is quantified and involves three terms , one governing the local averaging effects arising from the micro - circuits , one arising from the regularity properties of the solutions , and one corresponding to the speed of convergence of the macro - circuit interaction term towards a continuous limit . in the neural field regime , </S>",
    "<S> the limit equations are very singular , in particular trajectories are not measurable with respect to the space . </S>",
    "<S> these limits are very hard to analyze at this level of generality . </S>",
    "<S> however , in the type of models usually considered in the study of neural fields , namely the firing - rate model , it was shown in  @xcite that the behavior can be rigorously and exactly reduced to a system of deterministic integro - differential equations that are compatible with the usual wilson and cowan system in the zero noise limit . </S>",
    "<S> noise intervenes in these equations a nonlinear fashion , fundamentally shaping in the macroscopic dynamics .    </S>",
    "<S> the paper is organized as follows . </S>",
    "<S> we start in section  [ sec : model ] by introducing precisely our model and proving a few simple results on the network equations and on the topology of the micro - circuit . </S>",
    "<S> this being shown , we will turn in section  [ sec : existenceuniquenessspace ] to the analysis of the network equations , and will in particular make sense of the intricate non - local mckean - vlasov equation , show well - posedness and some regularity estimates on the law of the mean - field equations . section  [ sec : propachaspace ] will be devoted to the demonstration of the convergence of the network equations towards the mean - field equations . </S>"
  ]
}