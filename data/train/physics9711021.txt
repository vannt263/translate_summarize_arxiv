{
  "article_text": [
    "classical confidence intervals are the traditional way in which high energy physicists report errors on results of experiments .",
    "approximate methods of confidence interval construction , in particular the likelihood - ratio method , are often used in order to reduce computation .",
    "when these approximations are invalid , true confidence intervals can be obtained using the original ( defining ) construction of neyman @xcite . in recent years , there has been considerable dissatisfaction with the usual results of neyman s construction for upper confidence limits , in particular when the result is an unphysical ( or empty set ) interval .",
    "this dissatisfaction led the particle data group ( pdg ) @xcite to describe procedures for bayesian interval construction in the troublesome cases : poisson processes with background , and gaussian errors with a bounded physical region .    in this paper",
    ", we use the freedom inherent in neyman s construction in a novel way to obtain a unified set of classical confidence intervals for setting upper limits and quoting two - sided confidence intervals .",
    "the new element is a particular choice of ordering , based on likelihood ratios , which we substitute for more common choices in neyman s construction .",
    "we then obtain confidence intervals which are never unphysical or empty .",
    "thus they remove an original motivation for the description of bayesian intervals by the pdg .",
    "moreover , we show below that commonly quoted confidence intervals are wrong _ more _ than allowed by the stated confidence _ if _",
    "( as is typical ) one uses the experimental data to decide whether to consult confidence interval tables for upper limits or for central confidence intervals .",
    "in contrast , our unified set of confidence intervals satisfies ( by construction ) the classical criterion of frequentist coverage of the unknown true value .",
    "thus the problem of wrong confidence intervals is also solved .",
    "our intervals also effectively decouple the calculation of intervals from the test of goodness - of - fit , which is desirable but in fact not the case for traditional classical upper limit calculations .    after developing the new intervals for the two prototypical 1-d problems , we generalize them for use in the analysis of experiments searching for neutrino oscillations , continuing to adhere to the neyman construction .    in sec .",
    "[ sec - review ] , we review and contrast bayesian and classical interval construction . in sec .",
    "[ sec - exam ] , we review the troublesome cases of poisson processes with background and gaussian errors with a bounded physical region .",
    "we introduce the unifying ordering principle in sec .",
    "[ sec - order ] , and apply it to the previously discussed problems . in sec .",
    "[ sec - neut ] , we generalize the method for use in neutrino oscillation searches , and compare it to other classical methods . finally , in sec .",
    "[ sec - excess ] , we introduce an additional quantity helpful in describing experiments which observe less background than expected .",
    "we conclude in sec .",
    "[ sec - conclude ] .",
    "we adopt the following notation : the subscript @xmath0 on a parameter means the unknown true value ; the subscript 0 means a particular measured value obtained by an experiment .",
    "thus , for example , @xmath1 is a parameter whose true value @xmath2 is unknown ; @xmath3 is the particular result of an experiment which measures the number of events @xmath4 . for most of our discussion ,",
    "we use for illustration 90% c.l . confidence intervals on a single parameter @xmath1 . the confidence level ( c.l . )",
    "is more generally called @xmath5 .",
    "although our approach is classical , it is worthwhile to review bayesian intervals since we find that misconceptions about classical intervals can have their roots in misinterpreting them as bayesian intervals .",
    "for advocacy of bayesian intervals in high energy physics , see , for example , refs .",
    "@xcite .",
    "suppose that we wish to make an inference about a parameter @xmath1 whose true value @xmath2 is unknown .",
    "assume that we do this by making a single measurement of an observable @xmath6 such that the probability density function ( pdf ) for obtaining the value @xmath6 depends on the unknown parameter @xmath1 in a known way : we call this pdf @xmath7 @xcite .",
    "( note that @xmath6 need not be a measurement of @xmath1 , though that is often the case ; @xmath6 just needs to be some observable whose pdf depends on @xmath1 . )",
    "now suppose that the single measurement of @xmath6 yields the value @xmath8 .",
    "one substitutes this value of @xmath6 into @xmath7 to obtain @xmath9 , known as the likelihood function , which we denote @xmath10 .",
    "the bayesian deems it sensible to speak of pdf s for the unknown @xmath2 ; these pdf s represent degree of belief about @xmath2 .",
    "one makes inferences using the `` posterior '' pdf , which is the conditional pdf @xmath11 for the unknown @xmath2 , _ given _ the result @xmath8 of the measurement .",
    "it is related to @xmath12 by applying bayes s theorem .",
    "bayes s theorem in classical probability says that the probability that an element is in both sets @xmath13 and @xmath14 is @xmath15 .",
    "bayesians apply this to pdf s for @xmath2 , obtaining @xmath16 typically the denominator is just a normalization constant , so the major issue is what to use for @xmath17 , which is called the `` prior '' pdf .",
    "for the moment we assume that one has the prior pdf , so that then one has the posterior pdf .",
    "a bayesian interval @xmath18 $ ] corresponding to a confidence level @xmath5 can be constructed from the posterior pdf by requiring @xmath19 these intervals are more properly called `` credible intervals '' , although the phrase `` bayesian confidence intervals '' is also used @xcite .",
    "note that there is freedom in the _ choice _ of @xmath20 depending on whether one desires an upper limit , lower limit , central interval , etc .",
    "we believe that for making decisions , this bayesian description of inference is probably how many scientists do ( and should ) think , and that the prior pdf one uses is typically the _ subjective _ prior .",
    "one person s subjective prior incorporates all of that person s personal beliefs as well as the results of previous experiments .",
    "thus , values of @xmath1 which contradict well - founded theoretical thinking are ( properly ) given a low prior @xcite .",
    "there have been long - standing attempts to take the subjectivity out of the prior pdf , in order to have an `` objective '' bayesian interval .",
    "one attempts to define a prior pdf which represents prior ignorance , or which is `` non - informative '' .",
    "the naive choice of uniform prior is not well - defined for a continuous variable , since one must specify in what metric the prior is uniform ; this is just as hard as specifying the functional form in a particular given metric . for a parameter @xmath21 which is restricted to @xmath22 $ ] ,",
    "a common non - informative prior in the statistics literature @xcite is @xmath23 , which corresponds to a uniform prior for @xmath24 .",
    "an alternative @xcite for the poisson mean is @xmath25 .",
    "in contrast , the pdg recommendation is equivalent to using a prior which is uniform in @xmath2 .",
    "this recommendation has no basis that we know of in bayesian theory .",
    "it is based on the desire to have intervals which are conservative ( see below ) and somewhat robust from a frequentist ( anti - bayesian ) point of view .    in our view , the attempt to find a non - informative prior within bayesian inference is misguided .",
    "the real power of bayesian inference lies in its ability to incorporate `` informative '' prior information , not `` ignorance '' .",
    "the interpretation of bayesian intervals based on uniform priors is vague at best , since they may bear no relation either to subjective bayesian intervals of a typical scientist , or to classical confidence intervals which are probability statements based only on @xmath7 .",
    "neyman s original `` confidence intervals '' @xcite completely avoid the concept of pdf s in @xmath2 , and hence have no troublesome prior .",
    "they are limited to statements derived from @xmath7 ; in our experience this can lead to misinterpretations by those who mistakenly take them to be statements about @xmath11 .",
    "we believe that , compared to bayesian intervals with an `` objective prior '' , confidence intervals provide the preferred option for publishing numerical results of an experiment in an objective way .",
    "however , it is critical not to interpret them as bayesian intervals , i.e. , as statements about @xmath11 .",
    "rather , a confidence interval @xmath18 $ ] is a _ member of a set _ , such that the set has the property that @xmath26 ) = \\alpha.\\ ] ] here @xmath20 and @xmath27 are functions of the measured @xmath6 , and eq .",
    "[ eqn - cover ] refers to the _ varying _ confidence intervals @xmath18 $ ] from an ensemble of experiments with _ fixed _",
    "for a set of confidence intervals , eq .",
    "[ eqn - cover ] is true for every allowed @xmath1 .",
    "thus , in particular , the intervals contain the _ fixed unknown _ @xmath2 in a fraction @xmath5 of experiments .",
    "this is entirely different from the bayesian statement that the degree of belief that @xmath2 is in @xmath18 $ ] is @xmath5 .    if eq .",
    "( [ eqn - cover ] ) is satisfied , then one says that the intervals `` cover '' @xmath1 at the stated confidence , or equivalently , that the set of intervals has the correct `` coverage '' . if there is any value of @xmath1 for which @xmath28 )",
    "< \\alpha$ ] , then we say that the intervals `` undercover '' for that @xmath1 .",
    "significant undercoverage for any @xmath1 is a serious flaw .",
    "if there is any value of @xmath1 for which @xmath29 ) > \\alpha$ ] , then we say that the intervals `` overcover '' for that @xmath1 . a set of intervals",
    "is called `` conservative '' if it overcovers for some values of @xmath1 while undercovering for no values of @xmath1 .",
    "conservatism , while not generally considered to be as serious a flaw as undercoverage , comes with a price : loss of power in rejecting false hypotheses .",
    "our confidence intervals require the full power of neyman s construction , which for one measured quantity and one unknown parameter is called the method of `` confidence belts '' @xcite .",
    "figure [ fig - example - belt ] illustrates such a construction on a graph of the parameter @xmath1 vs.  the measured quantity @xmath6 . for each value of @xmath1",
    ", one examines @xmath7 along the horizontal line through @xmath1 .",
    "one selects an interval @xmath30 $ ] which is a subset of this line such that @xmath31\\,|{\\mu } ) = \\alpha.\\ ] ] such intervals are drawn as horizontal line segments on fig .",
    "[ fig - example - belt ] , at representative values of @xmath1 .",
    "we refer to the interval @xmath30 $ ] as the `` acceptance region '' or the `` acceptance interval '' for that @xmath1 . in order to specify uniquely the acceptance region",
    ", one must _ choose _ auxiliary criteria .",
    "one has total freedom to make this choice , _ if the choice is not influenced by the data @xmath8_. the most common choices are : @xmath32 which leads to `` upper confidence limits '' ( which satisfy @xmath33 ) ; and @xmath34 which leads to `` central confidence intervals '' ( which satisfy @xmath35 ) . for these choices ,",
    "the full confidence belt construction is rarely mentioned , since a simpler explanation suffices when one specifies @xmath36 and @xmath37 _",
    "separately_. for more complicated choices which still satisfy the more general specification of eq.([eqn - acc - region ] ) , an ordering principle is needed to specify which @xmath6 s to include in the acceptance region .",
    "we give our ordering principle in sec .",
    "[ sec - order ] .",
    "the construction is complete when horizontal acceptance intervals are drawn for each value of @xmath1 . upon performing an experiment to measure @xmath6 and obtaining the value @xmath8 ,",
    "one draws a vertical line ( shown dashed in fig .",
    "[ fig - example - belt ] ) through @xmath8 on the horizontal axis .",
    "the confidence interval is the union of all values of @xmath1 for which the corresponding horizontal interval is intercepted by the vertical line ; typically this is a simply connected interval @xmath18 $ ] .",
    "when displayed in texts , typically only the endpoints of the intervals are drawn , which collectively form the `` confidence belt '' .    by construction , eq .",
    "( [ eqn - cover ] ) is satisfied for all @xmath1 ; hence it is satisfied for @xmath2 , whose value is fixed but unknown .",
    "figures [ fig - std - gauss - ul ] and [ fig - std - gauss - central ] show standard confidence belts ( for upper limits and central intervals , respectively ) when the observable @xmath6 is simply the measured value of @xmath21 in an experiment with a gaussian resolution function with known fixed rms deviation @xmath38 , set here to unity .",
    "i.e. , @xmath39 we consider the interesting case where only non - negative values for @xmath1 are physically allowed ( for example , if @xmath1 is a mass ) .",
    "thus , the graph does not exist for @xmath40 .",
    "although these are standard graphs , we believe that common use of them is not entirely proper .",
    "[ fig - std - gauss - ul ] , constructed using eq .",
    "[ eqn - upper ] , is appropriate for experiments _ when it is determined before performing the experiment that an upper limit will be published_. fig .",
    "[ fig - std - gauss - central ] , constructed using eq .",
    "[ eqn - central ] , is appropriate for experiments _ when it is determined before performing the experiment that a central confidence interval will be published_. however , it may be deemed more sensible to decide , _ based on the results of the experiment _ , whether to publish an upper limit or a central confidence interval .",
    "let us suppose , for example , that physicist x takes the following attitude in an experiment designed to measure a small quantity : `` if the result @xmath6 is less then @xmath41 , i will state an upper limit from the standard tables .",
    "if the result is greater than @xmath41 , i will state a central confidence interval from the standard tables . ''",
    "we call this policy `` flip - flopping '' based on the data .",
    "furthermore , physicist x may say , `` if my measured value of a physically positive quantity is negative , i will pretend that i measured zero when quoting a confidence interval '' , which introduces some conservatism .",
    "we can examine the effect of such a flip - flopping policy by displaying it in confidence - belt form as shown in fig .",
    "[ fig - gauss - flipflop ] . for each value of measured @xmath6 , we draw at that @xmath6 the vertical segment @xmath18 $ ] that physicist x will quote as a confidence interval",
    ". then we can examine this collection of vertical confidence intervals to see what horizontal acceptance intervals it implies .",
    "for example , for @xmath42 , the acceptance interval has @xmath43 and @xmath44 .",
    "this interval only contains 85% of the probability @xmath7 .",
    "thus eq .",
    "( [ eqn - acc - region ] ) is not satisfied .",
    "physicists x s intervals _ undercover _ for a significant range of @xmath1 : they are _ not _ confidence intervals or conservative confidence intervals .    both figs .",
    "[ fig - std - gauss - ul ] and [ fig - std - gauss - central ] _ are _ confidence intervals when used appropriately , i.e. , without flip - flopping .",
    "however , the result is unsatisfying when one measures , for example , @xmath45 . in that case , one draws the vertical line as directed and finds that the confidence interval is the empty set !",
    "( an alternative way of expressing this situation is to allow non - physical @xmath1 s when constructing the confidence belt , and then to say that the confidence interval is entirely in the non - physical region .",
    "this requires knowing @xmath7 for non - physical @xmath1 , which can raise conceptual difficulties . )",
    "when this situation arises , one _ knows _ that one is in the `` wrong '' 10% of the ensemble quoting 90% c.l",
    ". intervals .",
    "one can go ahead and quote the wrong result , and the ensemble of intervals will have the proper coverage .",
    "but this is not very comforting .",
    "both problems of the previous two paragraphs are solved by the ordering principle which we give in sec .",
    "[ sec - order ] .",
    "figures [ fig - std - pois - ul ] and [ fig - std - pois - central ] show standard @xcite confidence belts for a poisson process when the observable @xmath6 is the total number of observed events @xmath4 , consisting of signal events with mean @xmath1 and background events with _ known _",
    "mean @xmath46 .",
    "i.e. ,    @xmath47    in these figures , we use for illustration the case where @xmath48 .    since @xmath4 is an integer , eq .",
    "( [ eqn - cover ] ) can only be approximately satisfied . by convention dating to the 1930 s ,",
    "one strictly avoids undercoverage and replaces the equality in eq.([eqn - cover ] ) with `` @xmath49 '' .",
    "thus the intervals overcover , and are conservative .    although the word `` conservative '' in this context may be viewed by some as desirable , in fact it is an undesirable property of a set of confidence intervals .",
    "ideal intervals cover the unknown true value at exactly the stated confidence : 90% c.l .",
    "should _ fail to contain the true value 10% of the time .",
    "if one desires intervals which cover more than 90% of the time , the solution is not to add conservatism to the intervals , but rather to choose a higher confidence level .",
    "the discreteness of @xmath4 in the poisson problem leads unavoidably to some conservatism , but this is unfortunate , not a virtue .",
    "the poisson intervals in figs .",
    "[ fig - std - pois - ul ] and [ fig - std - pois - central ] suffer from the same problems as the gaussian intervals .",
    "first , if physicist x uses the data to decide whether to use fig .",
    "[ fig - std - pois - ul ] or fig .",
    "[ fig - std - pois - central ] , then the resulting hybrid set can undercover .",
    "second , there is a well - known problem if , for example , @xmath48 and no events are observed . in that case , the confidence interval is again the empty set .",
    "these problems are solved by the ordering principle given in sec .",
    "[ sec - order ] .    for this poisson case , there is an alternative set of intervals , given by crow and gardner @xcite , which is instructive because it requires the full neyman construction . in constructing these intervals ,",
    "one minimizes the horizontal length of the acceptance region @xmath50 $ ] at each value of @xmath1 .",
    "since @xmath4 is a discrete variable , the concept of length in the horizontal direction can be well - defined as the number of discrete points .",
    "said another way , the points in the acceptance interval at each @xmath1 are chosen in order of decreasing @xmath51 , until the until the sum of @xmath51 meets or exceeds the desired c.l .",
    "( there are other technical details in the original paper . )",
    "the crow - gardner intervals are instructive because neither eq .",
    "( [ eqn - upper ] ) nor eq.([eqn - central ] ) is satisfied , even as a conservative inequality .",
    "( recall that @xmath6 is identified with @xmath4 in this section . ) for @xmath52 , @xmath53 varies between 0.018 and 0.089 , and @xmath54 varies between 0.011 and 0.078 , in a manner dictated by the neyman construction so that always @xmath55\\,|{\\mu } ) \\ge 0.9 $ ] . like crow and gardner , we use neyman s construction , but with a different ordering for choosing the points in the acceptance interval .",
    "we begin with a numerical example which occurs in the construction of confidence belts for a poisson process with background .",
    "the construction proceeds in the manner of fig .",
    "[ fig - example - belt ] , where the measurement @xmath6 in fig .",
    "[ fig - example - belt ] now corresponds to the measured total number of events @xmath4 .    let the known mean background be @xmath48 , and consider the construction of the horizontal acceptance interval at signal mean @xmath56 .",
    "then @xmath51 is given by eq .",
    "( [ eqn - pois ] ) , and is given in second column of table  [ tab - pois - exam ] .",
    "now consider , for example , @xmath57 .",
    "for the assumed @xmath58 , the probability of obtaining 0 events is 0.03 if @xmath56 , which is quite low on an absolute scale .",
    "however , it is not so low when compared to the probability ( 0.05 ) of obtaining 0 events with @xmath58 and @xmath59 , which is the alternate hypothesis with the greatest likelihood .",
    "a _ ratio _ of likelihoods , in this case 0.03/0.05 , is what we use as our ordering principle when selecting those values of @xmath4 to place in the acceptance interval .",
    "that is , for each @xmath4 , we let @xmath60 be that value of mean signal @xmath1 which maximizes @xmath51 ; we require @xmath60 to be physically allowed , i.e. , non - negative in this case .",
    "then @xmath61 , and is given in the third column of table  [ tab - pois - exam ] .",
    "we then compute @xmath62 , which is given in the fourth column .",
    "the fifth column contains the ratio , @xmath63 and is the quantity on which our ordering principle is based .",
    "@xmath64 is a ratio of two likelihoods : the likelihood of obtaining @xmath4 given the actual mean @xmath1 , and the likelihood of obtaining @xmath4 given the best - fit physically allowed mean .",
    "values of @xmath4 are added to the acceptance region for a given @xmath1 in decreasing order of @xmath64 , until the sum of @xmath51 meets or exceeds the desired c.l .",
    "this ordering , for values of @xmath4 necessary to obtain total probability of 90% , is shown in the column labeled `` rank '' .",
    "thus , the acceptance region for @xmath56 ( analogous to a horizontal line segment in figure 1 ) , is the interval @xmath65 $ ] . due to the discreteness of @xmath4 ,",
    "the acceptance region contains more summed probability than 90% ; this is unavoidable no matter what the ordering principle , and leads to confidence intervals which are conservative .",
    "for comparison , in the column of table  [ tab - pois - exam ] labeled `` u.l . '' , we place check marks at the values of @xmath4 which are in the acceptance region of standard 90% c.l .",
    "upper limits for this example ; and in the column labeled `` central '' , we place check marks at the values of @xmath4 which are in the acceptance region of standard 90% c.l central confidence intervals .",
    "the construction proceeds by finding the acceptance region for all values of @xmath1 , for the given value of @xmath46 . with a computer , we perform the construction on a grid of discrete values of @xmath1 , in the interval @xmath66 $ ] in steps of 0.005 .",
    "this suffices for the precision desired ( 0.01 ) in endpoints of confidence intervals .",
    "we find that a mild pathology arises as a result of the fact that the observable @xmath4 is discrete . when the vertical dashed line is drawn at some @xmath3 ( in analogy with in fig .",
    "[ fig - example - belt ] ) , it can happen that the set of intersected horizontal line segments is not simply connected .",
    "when this occurs we naturally take the confidence interval to have @xmath20 corresponding to the bottom - most segment intersected , and to have @xmath27 corresponding to the top - most segment intersected .",
    "we then repeat the construction for a selection of fixed values of @xmath46 .",
    "we find an additional mild pathology , again caused by the discreteness in @xmath4 : when we compare the results for different values of @xmath46 for fixed @xmath3 , the upper endpoint @xmath27 is not always a decreasing function of @xmath46 , as would be expected .",
    "when this happens , we force the function to be non - increasing , by lengthening selected confidence intervals as necessary .",
    "we have investigated this behavior , and compensated for it , over a fine grid of @xmath46 in the range @xmath67 $ ] in increments of 0.001 ( with some additional searching to even finer precision ) .",
    "our compensation for the two pathologies mentioned in the previous paragraphs adds slightly to our intervals conservatism , which however remains dominated by the unavoidable effects due to the discreteness in @xmath4 .",
    "the confidence belts resulting from our construction are shown in fig .",
    "[ fig - pois - new ] , which may be compared with figs .",
    "[ fig - std - pois - ul ] and [ fig - std - pois - central ] . at large @xmath4 , fig .",
    "[ fig - pois - new ] is similar to fig .",
    "[ fig - std - pois - central ] ; the background is effectively subtracted without constraint , and our ordering principle produces two - sided intervals which are approximately central intervals . at small @xmath4 , the confidence intervals from fig .  [ fig - pois - new ]",
    "automatically become upper limits on @xmath1 ; i.e. , the lower endpoint @xmath20 is 0 for @xmath68 in this case .",
    "thus , flip - flopping between figs .",
    "[ fig - std - pois - ul ] and [ fig - std - pois - central ] is replaced by one coherent set of confidence intervals , ( and no interval is the empty set ) .",
    "tables [ tab - p68a]-[tab - p99b ] give our confidence intervals @xmath18 $ ] for the signal mean @xmath1 for the most commonly used confidence levels , namely 68.27% ( sometimes called 1-@xmath38 intervals by analogy with gaussian intervals ) , 90% , 95% , and 99% .",
    "values in italics indicate results which must be taken with particular caution , since the probability of obtaining the number of events observed or fewer is less than 1% , even if @xmath69 .",
    "( see sec .",
    "[ goodness - of - fit ] below . )",
    "figure  [ fig - pdg - back1 ] shows , for @xmath57 through @xmath70 , the value of @xmath27 as a function of @xmath46 , for 90% c.l .",
    "the small horizontal sections in the curves are the result of the mild pathology mentioned above , in which the original curves make a small dip , which we have eliminated . dashed portions in the lower right",
    "indicate results which must be taken with particular caution , corresponding to the italicized values in the tables .",
    "dotted portions on the upper left indicate regions where @xmath20 is non - zero .",
    "these corresponding values of @xmath20 are shown in fig .",
    "[ fig - pdg - back2 ] .",
    "figure  [ fig - pdg - back1 ] can be compared with the bayesian calculation in fig .",
    "28.8 of ref .",
    "@xcite which uses a uniform prior for @xmath2 .",
    "a noticeable difference is that our curve for @xmath57 decreases as a function of @xmath46 , while the result of the bayesian calculation stays constant ( at 2.3 ) . the decreasing limit in our case reflects the fact that @xmath71 decreases as @xmath46 increases .",
    "we find that objections to this behavior are typically based on a misplaced bayesian interpretation of classical intervals , namely the attempt to interpret them as statements about @xmath72 .",
    "it is straightforward to apply our ordering principle to the other troublesome example of sec .",
    "[ sec - exam ] , the case of a gaussian resolution function ( eq .  [ eqn - gauss ] ) for @xmath1 , when @xmath1 is physically bounded to non - negative values . in analogy with the poisson case , for a particular @xmath6 , we let @xmath60 be the physically allowed value of @xmath1 for which @xmath7 is maximum",
    ". then @xmath73 , and @xmath74 we then compute @xmath64 in analogy to eq .",
    "[ eqn - r - order ] , using eqs .",
    "[ eqn - gauss ] and [ eqn - pmubest ] : @xmath75 during our neyman construction of confidence intervals , @xmath64 determines the order in which values of @xmath6 are added to the acceptance region at a particular value of @xmath1 . in practice , this means that for a given value of @xmath1 , one finds the interval @xmath30 $ ] such that @xmath76 and @xmath77 we solve for @xmath78 and @xmath79 numerically to the desired precision , for each @xmath1 in a grid with 0.001 spacing . with the acceptance regions all constructed , we then read off the confidence intervals @xmath18 $ ] for each @xmath8 as in fig .",
    "[ fig - example - belt ] .",
    "table [ tab - gauss - new ] contains the results for representative measured values and confidence levels .",
    "figure  [ fig - gauss - new ] shows the confidence belt for 90% c.l .",
    "it is instructive to compare fig .",
    "[ fig - gauss - new ] with fig .",
    "[ fig - std - gauss - central ] . at large @xmath6 , the confidence intervals @xmath18 $ ] are the same in both plots , since that is far away from the constraining boundary . below @xmath80 ,",
    "the lower endpoint of the new confidence intervals is zero , so that there is automatically a transition from two - sided confidence intervals to an upper confidence limit given by @xmath27 .",
    "the point of this transition is fixed by the calculation of the acceptance interval for @xmath69 ; the solution has @xmath81 , and so eq .  [ eqn - accept ]",
    "is satisfied by @xmath82 when @xmath83 .",
    "of course , one is not obligated to claim a non - null discovery just because the 90% c.l .",
    "confidence interval does not contain zero . with a proper understanding of what confidence intervals are ( sec .",
    "[ sec - class ] ) , one realizes that they do not indicate degree of belief .",
    "our 90% c.l .",
    "upper limit at @xmath84 is @xmath85 , which , interestingly , is the standard 95% c.l .",
    "upper limit , rather than @xmath86 , which is the standard 90% c.l .",
    "upper limit .",
    "the departure from the standard 90% c.l .",
    "upper limits reflects the fact , mentioned above , that they provide frequentist coverage only when the decision to quote an upper limit is not based on the data .",
    "our method repairs the undercoverage caused by flip - flopping ( fig.[fig - gauss - flipflop ] ) , with a necessary cost in loosening the upper limits around @xmath84 .",
    "as @xmath6 decreases , the upper limits from our method decrease , asymptotically going as @xmath87 for large negative @xmath6 .",
    "as in the poisson case , particular caution is necessary when interpreting limits obtained from measured values of @xmath6 which are unlikely for all physical @xmath1 .",
    "an advantage of our intervals compared to the standard classical intervals is that ours effectively decouple the confidence level used for a goodness - of - fit test from the confidence level used for confidence interval construction .    to elaborate ,",
    "let us first recall the procedure used in a standard `` easy '' @xmath88 fit ( free from constraints , background , etc . ) , for example the fit of a one - parameter curve to a set of points with gaussian error bars .",
    "one examines the @xmath88 between the data and the fitted curve , as function of the fit parameter .",
    "the _ value _ of @xmath88 at its minimum is used to determine goodness - of - fit : using standard tables , one can convert this value to a goodness - of - fit confidence level which tells one the quality of the fit .",
    "a very poor fit means that the information on the fitted parameter is suspect : the experimental uncertainties may not be assessed properly , the functional form of the parametrized curve may be wrong , or , in the most general terms , the hypotheses being considered may not be the relevant ones .",
    "if the value of the minimum @xmath88 is considered acceptable , then one examines the _ shape _ of @xmath88 ( as a function of the fit parameter ) near its minimum , in order to obtain an ( approximate ) confidence interval for the fit parameter at _ any _ desired confidence level .",
    "this procedure is powerful because it does not permit random fluctuations that favor no particular parameter value to influence the confidence interval .",
    "the two confidence levels invoked in this example are then independent ; for example , one may require that the goodness - of - fit c.l .",
    "be in the top 99% in order to consider the fit to be acceptable , while quoting a 68% c.l .",
    "confidence interval for the fitted parameter .    the problems with the standard classical intervals in sec .",
    "[ sec - exam ] can be viewed from the point of view that they effectively constrain the c.l .",
    "used for goodness - of - fit to be related to that used for the confidence interval . in both the gaussian and the poisson upper limit examples ,",
    "consider , for example , 90% as the c.l .",
    "for upper limits ; the confidence interval is the empty set ( or outside the physical region , some prefer to say ) some fraction of the time which is determined by this choice of c.l . for example , if the true mean is zero in the constrained gaussian problem , then the empty set is obtained 10% of the time from fig .",
    "[ fig - std - gauss - ul ] ; if the true mean is zero in the poisson - with - background problem , the empty set can be obtained up to 10% of the time from confidence belts such as fig .",
    "[ fig - std - pois - ul ] ( depending on the mean background @xmath46 , and on how discreteness affects the intervals for that @xmath46 . )",
    "an empty - set confidence interval has the same effect as failing a goodness - of - fit test : no useful confidence interval is inferred . with the standard confidence intervals ,",
    "one is forced to use a specific c.l .",
    "for this effective goodness - of - fit test , coupled to the c.l . used for interval construction .",
    "we believe this to be most undesirable , and at the heart of the community s dissatisfaction with the standard intervals .",
    "in contrast , our construction always provides a confidence interval at the desired confidence level ( with of course some conservatism for the discrete problems ) .",
    "independently , one can calculate the analog of goodness - of - fit , and decide whether or not to consider the data or model ( including mean expected background ) to be invalid .",
    "this issue arises in the case when an upper limit is quoted ; i.e. , the confidence interval is @xmath89 $ ] .    in the constrained gaussian case",
    ", one might have data @xmath90 and hence 90% c.l .",
    "confidence interval @xmath91 $ ] from tab .",
    "[ tab - gauss - new ] .",
    "the natural analog for goodness - of - fit is the probability to obtain @xmath92 under the best - fit assumption of @xmath69 .    in the poisson - with - background case , one might have data @xmath93 for @xmath94 , and hence 90% c.l .",
    "confidence interval @xmath95 $ ] from tab .",
    "[ tab - p90a ] .",
    "the natural analog for goodness - of - fit is the probability to obtain @xmath96 under the best - fit assumption of @xmath69 .    as noted above , in fig .",
    "[ fig - pdg - back1 ] we follow the practice of the pdg @xcite by indicating with dashed lines those regions where the goodness - of - fit criterion is less than 1% . in tables",
    "[ tab - p68a]-[tab - gauss - new ] , the corresponding intervals are italicized .    in summary , because our intervals decouple of the confidence level used for a goodness - of - fit test from the confidence level used for confidence interval construction ,",
    "one is free to choose them independently , at whatever level desired .",
    "experimental searches for neutrino oscillations provide an example of the application of this technique to a multidimensional problem .",
    "indeed it is just this problem that originally focused our attention on this investigation .",
    "experiments of this type search for a transformation of one species of neutrino into another . to be concrete ,",
    "we assume that the experiment is to search for transformations between muon type neutrinos , @xmath97 , and electron type neutrinos , @xmath98 , and that the influence of other types of neutrinos can be ignored .",
    "we hypothesize that the weak eigenstates @xmath99 and @xmath100 are linear superpositions of two mass eigenstates , @xmath101 and @xmath102 , @xmath103 and @xmath104 and that the mass eigenvalues for @xmath105 and @xmath106 are @xmath107 and @xmath108 , respectively . quantum mechanics dictates that the probability of such a transformation is given by the formula @xcite @xmath109 where @xmath110 is the probability for a @xmath111 to transform into a @xmath98 , @xmath112 is the distance in km between the creation of the neutrino from meson decay and its interaction in the detector , @xmath113 is the neutrino energy in gev , and @xmath114 in @xmath115 .",
    "the result of such an experiment is typically represented as a two - dimensional confidence region in the plane of the two unknown physical parameters , @xmath116 , the rotation angle between the weak and mass eigenstates , and @xmath117 , the ( positive ) difference between the squares of the neutrino masses .",
    "traditionally , @xmath118 is plotted along the horizontal axis and @xmath117 is plotted along the vertical axis .",
    "an example of such a plot is shown in fig .",
    "[ fig - null - result ] , based on a toy model that we develop below . in this example , no evidence for oscillations is seen and the confidence region is set as the area to the left of the curve in this figure .",
    "the problem of setting the confidence region for a neutrino oscillation search experiment often shares all of the difficulties discussed in the previous sections .",
    "the variable @xmath118 is clearly bounded by zero and one .",
    "values outside this region can have no possible interpretation within the theoretical framework that defines the unknown physical parameters .",
    "yet consider an experiment searching in a region of @xmath117 in which oscillations either do not exist or are well below the sensitivity of the experiment .",
    "such an experiment is typically searching for a small signal of excess @xmath98 interactions in a potentially large background of @xmath98 interactions from conventional sources and misidentified @xmath111 interactions .",
    "thus , it is equally likely to have a best fit to a negative value of @xmath118 as to a positive one , provided that the fit to eq .",
    "( [ eqn - neut - osc - prob ] ) is unconstrained .",
    "typically , the experimental measurement consists of counting the number of events in an arbitrary number of bins@xcite in the observed energy of the neutrino and possibly other measured variables , such as the location of the interaction in the detector .",
    "thus , the measured data consist of a set @xmath119 , together with an assumed known mean expected background @xmath120 and a calculated expected oscillation contribution @xmath121 .    to construct the confidence region ,",
    "the experimenter must choose an ordering principle to decide which of the large number of possible @xmath122 sets should be included in the acceptance region for each point on the @xmath123 plane .",
    "we suggest the ordering principle identical to the one suggested in sec [ sec - order ] , namely the ratio of the probabilities @xmath124 where @xmath125 gives the highest probability for @xmath126 for the physically allowed values of @xmath118 and @xmath117 .    in the gaussian regime , @xmath127 , so this approach is equivalent to using the difference in @xmath88 between @xmath128 and @xmath129 , i.e. , @xmath130,\\ ] ] where @xmath131 is the gaussian error .",
    "we actually recommend an alternative form based on the likelihood function,@xcite @xmath132,\\ ] ] since it can be used in all cases .",
    "to demonstrate how this works in practice , and how it compares to alternative approaches that have been used , we consider a toy model of a typical neutrino oscillation experiment .",
    "the toy model is defined by the following parameters : mesons are assumed to decay to neutrinos uniformly in a region 600  m to 1000  m from the detector .",
    "the expected background from conventional @xmath98 interactions and misidentified @xmath111 interactions is assumed to be 100 events in each of 5 energy bins which span the region from 10 to 60 gev .",
    "we assume that the @xmath111 flux is such that if @xmath133 averaged over any bin , then that bin would have an expected additional contribution of 100 events due to @xmath134 oscillations .",
    "the acceptance region for each point in the @xmath135 plane is calculated by performing a monte carlo simulation of the results of a large number of experiments for the given set of unknown physical parameters and the known neutrino flux of the actual experiment . for each experiment , @xmath136 is calculated according to the prescription of either eq .",
    "[ eqn - neut - osc - rprime - one ] or [ eqn - neut - osc - rprime - two ] .",
    "the single number that is needed for each point in the @xmath123 plane is @xmath137 , such that @xmath5 of the simulated experiments have @xmath138 .",
    "after the data are analyzed , @xmath136 for the data and each point in the @xmath123 plane , i.e. @xmath139 , is compared to @xmath140 and the acceptance region is all points such that @xmath141    figure [ fig - null - result ] is an example of the result of a calculation for a random experiment in the toy model for which there were no oscillations , i.e. , for @xmath142 .",
    "one might naively expect that @xmath143 , the 90% c.l .",
    "value for a @xmath88 distribution with two degrees of freedom .",
    "for the toy model , it actually varies from about 2.4 to 6.6 across the @xmath123 plane .",
    "the deviation from 4.61 is caused by at least three effects :",
    "proximity to the unphysical region .",
    "points close to the unphysical region occasionally have best fits in the unphysical region .",
    "since our algorithm restricts fits to the physical region , these fits give a lower @xmath144 than unrestricted fits . 2 .",
    "sinusoidal nature of the oscillation function .",
    "the @xmath88 distribution assumes a gaussian probability density function , but the oscillation probability function is sinusoidal . for high values of @xmath117 fluctuations can cause a global minimum in a ",
    "wrong \" trough of the function , increasing the value of @xmath145 from what it would be if there were only one trough .",
    "3 .   one - dimensional regions . in some regions of the plane ,",
    "the probability distribution function becomes one rather than two dimensional .",
    "for example , at very low values of @xmath117 the only relevant quantity is the number of events in the lowest energy bin , since the oscillation probability , eq .",
    "( [ eqn - neut - osc - prob ] ) , is proportional to @xmath146 for sufficiently low @xmath117 .",
    "fluctuations in higher energy bins do not lead to any physical interpretation , and thus cancel in the calculation of @xmath136 . in these regions",
    ", @xmath140 tends to lower values than normal .",
    "most papers reporting the results of neutrino oscillation searches have not been explicit enough for us to determine exactly how the confidence regions were set .",
    "however , we can imagine three classical methods that either have or could have been used .",
    "we refer to these as the raster scan , the flip - flop raster scan , and the global scan .",
    "all of them have the advantage that a gaussian approximation is made so that a full neyman construction of the confidence region is not necessary .    1 .   the raster scan : for each value of @xmath117 , a best fit is made for @xmath118 . at each @xmath117 , @xmath88",
    "is calculated as a function of @xmath118 , and the 1-d confidence interval in @xmath118 at that @xmath117 is taken to be all points that have a @xmath88 within 2.71 of the minimum value .",
    "( 2.71 is the two - sided 90% c.l .  for a @xmath88 distribution with one degree of freedom . )",
    "the confidence region in the @xmath147 plane is then the union of all these intervals . 2 .",
    "the flip - flop raster scan : similar to the raster scan except that a decision to use a one - sided upper limit or a two - sided interval is made based on the data .",
    "if there is a signal with significance greater than three standard deviations , the raster scan is used .",
    "if not , an upper limit is set by a raster scan using the one - sided 90% c.l .",
    "@xmath136 value of 1.64 .",
    "the global scan : a best fit is made to both @xmath118 and @xmath117 , and the confidence region is given as all points that have a @xmath88 within 4.61 of the minimum value .",
    "( as mentioned above , 4.61 is the two - sided 90% c.l .  for a @xmath88 distribution with two degrees of freedom . )    in all three cases , we assume that there is no restriction that the best fit be in the physical region .",
    "this is because the method of using a fixed @xmath144 depends on the reference @xmath88 being the minimum of a parabolic @xmath88 distribution .",
    "any attempt to restrict the minimum to the physical region automatically gives improper coverage .",
    "thus , all three of these methods suffer from the possibility that they could either rule out the entire physical plane , or give limits which are not characteristic of the sensitivity of the experiment .",
    "we have used the toy model to study the coverage of each of these techniques .",
    "the raster scan gives exact coverage .",
    "however , it is not a powerful technique in that it can not distinguish a likely value of @xmath117 from an unlikely one , since it works at fixed @xmath148 .",
    "this is best illustrated in the case in which a positive signal is found .",
    "figure [ fig - power - demo ] shows the confidence regions for both the raster scan and our proposed technique for a sample case for which @xmath149 ( ev/@xmath150 and @xmath151 .",
    "both techniques provide exact coverage , but the proposed technique isolates the signal , with one ghost region , while the raster scan does not .",
    "since the raster scan gives exact coverage , it will not surprise the reader to learn that the flip - flop raster scan undercovers for the reasons given in sec .",
    "[ sec - exam ] .",
    "figure [ fig - flipflop - cover ] shows the region of significant undercoverage ( greater than 1% ) for the flip - flop raster scan .",
    "the coverage drops as low as 85% , as is to be expected from the discussion in sec .",
    "[ sec - exam ] . to set the scale , a quantity we call the  sensitivity \" is also shown in this figure .",
    "the sensitivity is defined as the average upper limit one would get from an ensemble of experiments with the expected background and no true signal .",
    "we discuss the use of this quantity further in sec .",
    "[ sec - excess ] .",
    "unlike the raster scan and flip - flop raster scan , the global scan is a powerful technique .",
    "however , it suffers from not giving proper coverage for the reasons enumerated at the end of the previous subsection ( numbers 2 and 3 ) .",
    "it has both regions of undercoverage and overcoverage , as shown in fig .",
    "[ fig - global - cover ] .",
    "the coverage varies across the plane from about 76% to 94% .",
    "table [ tab - brand - x ] summarizes the properties of the proposed technique and the three alternative techniques that we have considered .",
    "we started this investigation to solve the problem in classical statistics in which an experiment which measures significantly fewer events than are expected from backgrounds will report a meaningless or unphysical result .",
    "while we have solved that problem , our solution still yields results that are bothersome to some in that an experiment that measures fewer events than expected from backgrounds will report a lower upper limit than an identical experiment that measures a number of events equal to that expected from background .",
    "this seems particularly troublesome in the case in which the experiment has no observed events .",
    "why should an experiment claim credit for expected backgrounds , when it is clear , in that particular experiment , there were none ? or why should a well designed experiment which has no background and observes no events be forced to report a higher upper limit than a less well designed experiment which expects backgrounds , but , by chance , observes none ?",
    "the origin of these concerns lies in the natural tendency to want to interpret these results as the probability @xmath11 of a hypothesis given data , rather than what they are really related to , namely the probability @xmath152 of obtaining data given a hypothesis .",
    "it is the former that a scientist may want to know in order to make a decision , but the latter which classical confidence intervals relate to . as we discussed in sec .",
    "[ sec - bayes ] , scientists may make bayesian inferences of @xmath11 based on experimental results combined with their personal , subjective prior probability distribution function .",
    "it is thus incumbent on the experimenter to provide information that will assist in this assessment .",
    "our suggestion for doing this is that in cases in which the measurement is less than the estimated background , the experiment report both the upper limit and the `` sensitivity '' of the experiment , where the `` sensitivity '' is defined as the average upper limit that would be obtained by an ensemble of experiments with the expected background and no true signal . table [ tab - sens ] gives these values , for the case of a measurement of a poisson variable .",
    "thus , an experiment that measures 2 events and has an expected background of 3.5 events would report a 90% c.l .",
    "upper limit of 2.7 events ( from tab .",
    "[ tab - p90a ] ) , but a sensitivity of 4.6 events ( from tab .",
    "[ tab - sens ] ) .",
    "figure [ fig - null - result - sens ] represents a common occurrence for a neutrino oscillation search experiment .",
    "it is a repeat of fig .",
    "[ fig - null - result ] , an example of the toy model in which @xmath153 , but with the sensitivity shown by a dashed line .",
    "the behavior is typical of what one would expect . due to random fluctuations ,",
    "the upper limit is greater than the sensitivity for some values of @xmath117 and less than others . in this case",
    ", it is due to fluctuations , but in an actual experiment , it could also be due to the presence of a signal around or below the experiment s sensitivity at some value @xmath117 , making other values of @xmath117 less likely . again , for cases in which a significant portion of the upper limit curve is below the sensitivity of the experiment , we suggest that the sensitivity curve be displayed as well as the upper limit .",
    "the construction described in this paper strictly adheres to the neyman method @xcite , as applied to discrete distributions since the 1930 s @xcite .",
    "thus , the resulting confidence intervals are firmly grounded in classical statistics theory . what is new is the particular choice of ordering we",
    "make within the freedom inherent in neyman s method .",
    "this choice , described in sec .",
    "[ sec - order ] , yields intervals which automatically change over from upper limits to two - sided intervals as the `` signal '' becomes more statistically significant .",
    "this eliminates undercoverage caused by basing this choice on the data ( `` flip - flopping '' ) .",
    "our tables give classical confidence intervals for the two common problems for which the pdg has described bayesian solutions incorporating a ( questionable ) uniform prior for a bounded variable : poisson processes with background , and gaussian errors with a bounded physical region .",
    "this introduction of bayesian methods was at least partly motivated by problems with the traditional classical intervals ( non - physical or empty - set intervals , and coupling of goodness - of - fit c.l . with confidence interval c.l . )",
    "which our new intervals solve .",
    "thus , there should be renewed discussion of the appropiateness of bayesian intervals for reporting experimental measurements in an objective way .",
    "the new ordering principle can be applied quite generally .",
    "we have developed the application to neutrino oscillation searches , where the confidence region can have a particularly complicated stucture due to physical constraints and multiple local minima in the pdf s .    finally , we certainly agree that no matter how one constructs an interval , it is important to publish relevant ingredients to the calculation so that the reader ( and the pdg ) can ( at least approximately ) perform alternative calculations or combine the result with other experiments @xcite . in the gaussian case , the ingredients are the measured value ( even if non - physical ) and the standard error .",
    "( separating the statistical and systematic errors , as is often done , is even better ) . in the case of a counting experiment with known background ,",
    "the required ingredients are : the number of observed events ; the expected mean background ; and the factor ( incorporating , e.g. , integrated luminosity , efficiencies , etc . , ) which converts the number of observed events to the relevant physics quantity ( cross section , branching ratio , etc . ) .",
    "_ note added in proof . _ although we are not aware of previous application of this ordering principle to the construction of confidence intervals for the presentation of scientific results , such an ordering is naturally implied by the theory of likelihood ratio tests , as explained in sec .",
    "23.1 of ref .",
    "we thank h. chernoff for clarifying discussions on this point .",
    "j. neyman , phil .",
    "royal soc .",
    "london , series a , * 236 * 333 - 80 ( 1937 ) . reprinted in _ a selection of early statistical papers on j. neyman _ ( university of california press , berkeley , 1967 ) , pp .",
    "250 - 289 .",
    "see in particular pp .",
    "250 - 252 , 261 - 268 , 285 - 286 , of the reprint .",
    "unfortunately , the quantity which neyman calls @xmath5 is precisely what is called @xmath154 in modern references .",
    "we use the adjectives `` classical '' and `` frequentist '' synonymously to refer to the theory of these confidence intervals .      o. helene , nucl .",
    "* 212 * 319 - 22 ( 1983 ) ; o. helene , nucl",
    "* 228 * 120 - 28 ( 1984 ) , with criticism by f. james , nucl . instr . meth . *",
    "a240 * 203 - 4 ( 1985 ) ; o. helene , nucl .",
    "a300 * 132 - 36 ( 1991 ) .",
    "h. b. prosper , nucl .",
    "* a241 * 236 - 240 ( 1985 ) ; h. b. prosper , phys .",
    "rev . * d37 * 1153 - 1160 ( 1988 ) ; and comment by d.a .",
    "williams , phys .",
    "* d38 * 3582 - 83 ( 1988 ) ; and reply by h. b. prosper , phys . rev .",
    "* d38 * 3584 - 5 ( 1988 ) .    to be pedantic ,",
    "classically this pdf is better written @xmath155 , where the semi - colon delimits a following parameter . to a bayesian ,",
    "the same function is @xmath7 where the vertical line means a _ conditional _ pdf for @xmath6 , _ given _ a particular value of @xmath1 .",
    "while keeping in mind the different interpretations , we use the notation @xmath7 in both contexts throughout this paper .",
    "a. stuart and j.k .",
    "kendall s advanced theory of statistics _",
    ", vol . 2 , _ classical inference and relationship _",
    "( oxford university press , new york , 1991 ) ; see also earlier editions by kendall and stuart .    h. jeffreys , j. royal statist .",
    "series a , * 186 * 453 - 461 ( 1946 ) ; g.e.p .",
    "box and g.c .",
    "tiao , _ bayesian inference and statistical analysis _",
    "( addison - wesley , reading , mass . , 1973 ) .",
    "see in particular pp .",
    "25 - 46 ; r.e .",
    "kass , biometrika * 77 * 107 - 14 ( 1990 ) ; j.g .",
    "ibrahim and p.w .",
    "laud , j. amer .",
    ". assoc . *",
    "86 * 981 - 86 ( 1991 ) and references therein .",
    "other than convenience in displaying and handling the data , there is no good reason to bin the data at all .",
    "the bins can be made so fine that there is a most one measured event in each bin , so that the binned likelihood reduces to an unbinned likelihood .",
    ".illustrative calculations in the confidence belt construction for signal mean @xmath1 in the presence of known mean background @xmath48 . here",
    "we find the acceptance interval for @xmath56 .",
    "[ cols=\"^,^,^,^,^,^,^,^\",options=\"header \" , ]     ddddd @xmath46 & & & & + 0.0 & 1.29 & 2.44 & 3.09 & 4.74 + 0.5 & 1.52 & 2.86 & 3.59 & 5.28 + 1.0 & 1.82 & 3.28 & 4.05 & 5.79 + 1.5 & 2.07 & 3.62 & 4.43 & 6.27 + 2.0 & 2.29 & 3.94 & 4.76 & 6.69 + 2.5 & 2.45 & 4.20 & 5.08 & 7.11 + 3.0 & 2.62 & 4.42 & 5.36 & 7.49 + 3.5 & 2.78 & 4.63 & 5.62 & 7.87 + 4.0 & 2.91 & 4.83 & 5.86 & 8.18 + 5.0 & 3.18 & 5.18 & 6.32 & 8.76 + 6.0 & 3.43 & 5.53 & 6.75 & 9.35 + 7.0 & 3.63 & 5.90 & 7.14 & 9.82 + 8.0 & 3.86 & 6.18 & 7.49 & 10.27 + 9.0 & 4.03 & 6.49 & 7.81 & 10.69 + 10.0 & 4.20 & 6.76 & 8.13 & 11.09 + 11.0 & 4.42 & 7.02 & 8.45 & 11.46 + 12.0 & 4.56 & 7.28 & 8.72 & 11.83 + 13.0 & 4.71 & 7.51 & 9.01 & 12.22 + 14.0 & 4.87 & 7.75 & 9.27 & 12.56 + 15.0 & 5.03 & 7.99 & 9.54 & 12.90 +"
  ],
  "abstract_text": [
    "<S> we give a classical confidence belt construction which unifies the treatment of upper confidence limits for null results and two - sided confidence intervals for non - null results . </S>",
    "<S> the unified treatment solves a problem ( apparently not previously recognized ) that the choice of upper limit or two - sided intervals leads to intervals which are not confidence intervals if the choice is based on the data . </S>",
    "<S> we apply the construction to two related problems which have recently been a battle - ground between classical and bayesian statistics : poisson processes with background , and gaussian errors with a bounded physical region . </S>",
    "<S> in contrast with the usual classical construction for upper limits , our construction avoids unphysical confidence intervals . </S>",
    "<S> in contrast with some popular bayesian intervals , our intervals eliminate conservatism ( frequentist coverage greater than the stated confidence ) in the gaussian case and reduce it to a level dictated by discreteness in the poisson case . we generalize the method in order to apply it to analysis of experiments searching for neutrino oscillations . </S>",
    "<S> we show that this technique both gives correct coverage and is powerful , while other classical techniques that have been used by neutrino oscillation search experiments fail one or both of these criteria . </S>"
  ]
}