{
  "article_text": [
    "in their lauded paper  @xcite , david slepian and jack  k.  wolf characterize the information rates needed to losslessly communicate two correlated , memoryless information sources when these sources are encoded separately .",
    "their well - known result states that two discrete sources @xmath0 and @xmath1 can be losslessly reproduced if @xmath2 where @xmath3 is the rate of the encoder observing @xmath0 and @xmath4 is the rate of the encoder observing @xmath1 .",
    "conversely , lossless reproduction is not possible if @xmath5 lies outside the closure of this region .",
    "see cover and thomas  ( * ? ? ?",
    "* section  14.4 ) or csiszr and krner  ( * ? ? ? * section  3.1 ) for precise statements of the result and modern proofs .",
    "this result is naturally viewed as a multi - source generalization of the classical result of shannon  @xcite , which says that , loosely speaking , a discrete memoryless source with known law can be losslessly reproduced if and only if the data rate exceeds the entropy of the source .",
    "shannon too studied a generalization of this result , albeit in a different direction .",
    "he studied the problem of reproducing a source imperfectly , subject to a minimum fidelity constraint , and showed that the required rate is given by the well - known rate - distortion formula  @xcite .",
    "one of the central problems of shannon theory is to understand the limits of source coding for models that combine the two generalizations .",
    "that is , we seek to determine the rates required to reproduce two correlated sources , each subject to a fidelity constraint , when the sources are encoded separately ( see fig .  [",
    "mtsc : basic : fig ] ) .",
    "determining the set of achievable rates and distortions for this setup is often called the _ multiterminal source - coding problem _ , even though this name suggests a more elaborate network topology .",
    "this problem has been unsolved for some time .",
    "the model we consider in this paper is slightly more general and is depicted in fig .",
    "[ mtsc : fig ] .    beyond considering an arbitrary number of encoders , @xmath6 , we also allow for a hidden source , @xmath7 ,",
    "which is not directly observed by any encoder or the decoder , and a `` side information '' source , @xmath8 , which is observed by the decoder but not by any encoder .",
    "we also permit arbitrary functions of the sources to be reproduced , in addition to , or in place of , the sources themselves .",
    "we will therefore use @xmath9 , etc .",
    ", to denote the instantaneous estimates instead of @xmath10 , etc .",
    ", as before . in this paper , we will refer to this more general problem as the multiterminal source - coding problem .",
    "one might doubt the wisdom of embellishing the model when even the basic form shown in fig .",
    "[ mtsc : basic : fig ] is unsolved .",
    "but one of the contributions of this paper is to show that far from obscuring the problem , the added generality actually illuminates it .",
    "of course , the more general problem is also unsolved .",
    "many special cases have been solved , however .",
    "for these , the reader is referred to the classical papers of slepian and wolf  @xcite , mentioned earlier ; wyner  @xcite ; ahlswede and krner  @xcite ; wyner and ziv  @xcite ; krner and marton  @xcite ; and gelfand and pinsker  @xcite ; and to the more recent papers of berger and yeung  @xcite ; gastpar  @xcite ; oohama  @xcite ; and prabhakaran , tse , and ramchandran  @xcite . while all of these papers contain conclusive results , these results are established using coding theorems that are tailored to the special cases under consideration .",
    "the solutions to these solved special cases suggest a coding technique for the general model  @xcite .",
    "the idea is this .",
    "each encoder first quantizes its observation as in single - user rate - distortion theory .",
    "the quantized processes are then losslessly communicated to the decoder using the binning scheme of cover  @xcite .",
    "the decoder uses the quantized processes to produce the desired estimates .",
    "the set of rate - distortion vectors that can be achieved using this scheme is described in section  [ relation ] .",
    "this inner bound to the rate - distortion region is tight in all of the special cases listed above except that of krner and marton  @xcite .",
    "indeed , the krner - marton problem seems to require a custom coding technique that relies on the problem s unique structure .",
    "this suggests that the multiterminal source - coding problem may not have a classical single - letter solution .",
    "we attack this problem , therefore , by proving single - letter inner and outer bounds on the rate - distortion region .",
    "the best inner bound in the literature has just been described .",
    "the best outer bound , which is due to berger  @xcite and tung  @xcite , is described in section  [ relation ] . in light of the result of krner and marton ,",
    "it is clear that the two bounds must not coincide in all cases .",
    "this gap can not be entirely attributed to the inner bound , however , as there are instances of the problem that can be solved from first principles for which the berger - tung outer bound is strictly bigger than the true rate - distortion region ( see section  [ contrived ] of this paper ) .",
    "our aim is to provide an improved outer bound for the problem .",
    "we prove such a bound in the next section , following a precise formulation of the problem .",
    "we show that our bound is contained in ( i.e. , subsumes ) the berger - tung outer bound in section  [ relation ] . in that section",
    ", we also provide several examples for which the containment is strict .",
    "one example is the binary erasure version of the `` ceo problem , '' the general version of which was introduced by berger , zhang , and viswanathan  @xcite .",
    "the ceo problem is a special case of the multiterminal source - coding problem in which the observed processes @xmath11 are conditionally independent given the hidden process @xmath7 and in which the decoder ( the ceo ) is only interested in estimating the hidden process into @xmath7 and redefining the distortion measure as needed .",
    "nonetheless , it defines a useful special case . ] .",
    "berger , zhang , and viswanathan characterize the tradeoff between sum rate and hamming distortion in the high - rate and many - encoder limit .",
    "gelfand and pinsker  @xcite had earlier found the rate region in the lossless reproduction case .",
    "we consider the problem in which @xmath7 is binary and uniform , and the encoders observe @xmath7 through independent binary erasure channels .",
    "the decoder reproduces @xmath7 subject to a constraint on the `` erasure distortion '' ( see section  [ beceo : subsection ] or cover and thomas  @xcite ) . for this problem ,",
    "we show that our outer bound is tight in the sum rate for any number of users .",
    "in contrast , the berger - tung outer bound contains points whose sum rate is strictly smaller than the optimum .    in our view",
    ", this result is of interest in its own right .",
    "the binary erasure ceo problem arises naturally in sensor networks in which the sensors occasionally `` sleep '' to conserve energy .",
    "this application is described in section  [ beceo : subsection ] .",
    "the result also provides an example for which the binning - based coding scheme mentioned earlier is optimum . finally , this is one of relatively few conclusive results for the multiterminal source - coding problem in general , and the ceo problem in particular .",
    "these problems are considered sufficiently difficult that it is worth reporting solutions to special cases .",
    "one of the few other conclusive results available is for the gaussian version of the ceo problem , which was first studied by viswanathan and berger  @xcite . here",
    "the encoders observe a hidden gaussian source through independent gaussian additive - noise channels .",
    "the distortion measure is expected squared error .",
    "the rate - distortion region for this problem was recently found by oohama  @xcite and independently by prabhakaran , tse , and ramchandran  @xcite .",
    "we show that the converse result of these four authors can be recovered from our single - letter outer bound , while the berger - tung outer bound contains points that lie outside the true rate - distortion region .    the converse results used to solve all of the other special cases mentioned so far are also consequences of our bound .",
    "this is discussed in section  [ recover ] .",
    "our outer bound therefore serves to unify most of what is known about the nonexistence of multiuser source codes .",
    "this unification is noteworthy in the case of oohama  @xcite and prabhakaran , tse , and ramchandran  @xcite because the connection between their remarkable converse result and the classical discrete results in this area is not immediately apparent .",
    "as we will see , subject to some technical caveats , most of the key results in multiterminal source coding can be recovered by combining the general inner bound described earlier with the outer bound described next .",
    "we work exclusively in discrete time .",
    "we use uppercase letters to denote random variables and vectors , lowercase letters to denote their realizations , and script letters to denote their ranges .",
    "let @xmath12 be a vector - valued , finite - alphabet memoryless source . for @xmath13",
    ", we denote @xmath14 by @xmath15 .",
    "if @xmath16 , we write this simply as @xmath17 . in this context , the set @xmath18 should be interpreted as @xmath19 rather than @xmath20 .",
    "when @xmath21 , we shall write @xmath22 and @xmath23 in place of @xmath24 and @xmath25 , respectively . also , we use @xmath26 to denote @xmath27 , @xmath28 to denote @xmath29 , and @xmath30 to denote @xmath31 similar notation will be used for other vectors that appear later .",
    "the notation for the encoding and decoding rules is shown in fig .",
    "[ rules ] .    for each @xmath32 in @xmath33 ,",
    "encoder @xmath32 observes @xmath28 , then employs a mapping @xmath34 to convey information about it to the decoder .",
    "the decoder observes @xmath35 and uses it and the received messages to estimate @xmath36 functions of the vector - valued source according to the mappings @xmath37 we assume that @xmath36 distortion measures @xmath38 are given .",
    "we mention at this point that while the generality of this setup will be useful later when studying examples , it is not needed to appreciate the bounding technique itself .",
    "the reader is welcome to focus on the basic model shown in fig .",
    "[ mtsc : basic : fig ] for that purpose .",
    "[ achievable : defn ] the rate - distortion vector @xmath39 is _ achievable _ if there exists a block length @xmath40 , encoders @xmath41 , and a decoder @xmath42 such that . ]",
    "@xmath43 \\ \\text{for all $ k$}. \\end{split}\\ ] ] let @xmath44 be the set of achievable rate - distortion vectors .",
    "its closure , @xmath45 , is called the _ rate - distortion region_.    we will sometimes be concerned with projections of the rate - distortion region .",
    "we denote these by , for example , @xmath46 , meaning @xmath47    in this paper , we view lossless compression as a limit of lossy compression with the distortion tending to zero .",
    "more precisely , if we wish to reproduce @xmath0 losslessly , we will set , say , @xmath48 with @xmath49 equal to hamming distance , and then examine @xmath50 .",
    "this convention and definition  [ achievable : defn ] together yield a notion of lossless compression that is weaker than the one traditionally used .",
    "it is common instead to require that for all sufficiently large block lengths , there exists a code for which the probability of correctly reproducing the entire vector @xmath51 is arbitrarily close to 1 . but a weaker notion is desirable here since we are proving an outer bound or `` converse '' result .    to state our result ,",
    "let @xmath52 be generic random variables with the distribution of the source at a single time .",
    "let @xmath53 denote the set of finite - alphabet random variables @xmath54 satisfying    1 .",
    "@xmath55 is independent of @xmath56 , 2 .",
    "@xmath57 ) , shorthand for `` @xmath58 , @xmath59 and @xmath60 form a markov chain in this order '' , for all @xmath32 , and 3 .",
    "@xmath61 .",
    "it is straightforward to verify that @xmath53 is precisely the set of finite - alphabet random variables @xmath62 whose joint distribution with @xmath56 factors as @xmath63 this description is helpful in that it suggests a parametrization of the space @xmath53 .",
    "let @xmath64 denote the set of finite - alphabet random variables @xmath65 with the property that @xmath11 are conditionally independent given @xmath66 .",
    "note that @xmath64 is nonempty since it contains , e.g. , @xmath67 .",
    "there are many ways of coupling a given @xmath65 in @xmath64 and @xmath68 in @xmath53 . in this paper",
    ", we shall only consider the unique coupling for which @xmath69 , which we call the _ markov coupling .",
    "_ whenever the joint distribution of @xmath65 , @xmath70 , and @xmath68 arises , we assume that this coupling is in effect .",
    "it is evident from the definition of @xmath64 that there is considerable latitude in choosing how @xmath65 depends on @xmath7 .",
    "this is because the sole constraint on the choice of @xmath65 only depends on the joint distribution of @xmath65 and @xmath71 .",
    "but as the following definition makes clear , this freedom is inconsequential since our outer bound only depends on the distributions of @xmath72 and @xmath73 separately .",
    "[ me : defn ] let @xmath74 \\",
    "\\text{for all $ k$ } \\bigg\\}.\\end{aligned}\\ ] ] then define @xmath75    the first theorem is our main result .",
    "[ main ] the rate - distortion region is contained in @xmath76 .",
    "in fact , @xmath77    _ proof .",
    "_ it suffices to show the second statement .",
    "suppose @xmath78 is achievable .",
    "let @xmath79 be encoders and @xmath80 a decoder satisfying  ( [ constraints ] ) .",
    "take any @xmath65 in @xmath64 and augment the sample space to include @xmath81 so that @xmath82 is independent over @xmath83",
    ". next let @xmath84 be uniformly distributed over @xmath85 , independent of @xmath81 , @xmath86 , @xmath87 , and @xmath35 .",
    "then define @xmath88 it can be verified that @xmath89 is in @xmath53 and that , together with @xmath7 , @xmath90 , @xmath8 , and @xmath65 , it satisfies the markov coupling .",
    "it suffices to show that @xmath78 is in @xmath91 .",
    "first , note that  ( [ constraints ] ) implies @xmath92     \\ \\text{for all $ k$},\\ ] ] i.e. , @xmath93 \\",
    "\\text{for all $ k$}.\\ ] ] second , let @xmath13 .",
    "then by the cardinality bound on entropy , @xmath94 since conditioning reduces entropy , this implies @xmath95 by the chain rule for mutual information , @xmath96 applying the chain rule again gives @xmath97 consider next the second term on the right - hand side of  ( [ twoterms ] ) . since @xmath98 , @xmath99 applying the chain rule once more gives @xmath100 but @xmath101 and the second term on the left - hand side is zero",
    ". thus @xmath102 substituting the results of these various calculations into  ( [ blockchain ] ) gives @xmath103 .",
    "\\end{split}\\ ] ] if @xmath18 is nonempty , this can be rewritten as @xmath104 the case @xmath16 is handled separately . in this case , observe that @xmath105 substituting this into  ( [ substitute ] ) and proceeding as in the @xmath106 case completes the proof . @xmath107    it is worth noting that the proof uses classical techniques .",
    "most of the manipulations in the latter part of the proof can be viewed as versions of the chain rule for mutual information . since this chain rule holds in abstract spaces  (",
    "* ( 3.6.6 ) ) , the proof can be readily extended to more general alphabets .",
    "the key step in the proof is the introduction of @xmath81 in  ( [ blockchain ] ) . unlike the other auxiliary random variables ,",
    "@xmath81 does not represent a component of the code .",
    "rather , it is used to aid the analysis by inducing conditional independence among the messages sent by the encoders .",
    "this technique of augmenting the source to induce conditional independence was pioneered by ozarow  @xcite , who used it to solve the gaussian two - descriptions problem .",
    "wang and viswanath  @xcite used it to determine the sum rate of the gaussian vector multiple - descriptions problem with individual and central decoders .",
    "it was also used by wagner , tavildar , and viswanath  @xcite to solve the gaussian two - terminal source - coding problem .",
    "a step that is similar to  ( [ blockchain ] ) appeared in gelfand and pinsker  @xcite and in later papers on the gaussian ceo problem  @xcite , although in these works @xmath81 is part of the source , so no augmentation is involved .",
    "the significance of conditional independence has long been known in the related field of distributed detection ( e.g. ,  @xcite ) .",
    "given the similarity between distributed detection and the multiterminal source - coding problem , one expects conditional independence to play a significant role here as well .",
    "indeed , most conclusive results for the multiterminal source - coding problem require a conditional independence assumption  @xcite .",
    "the motivation for introducing @xmath81 is that it allows one to apply the approach used in these works to problems that lack conditional independence .",
    "we do not consider the problem of computing @xmath108 in this paper .",
    "note that we have not specified the alphabet sizes of the auxiliary random variables @xmath109 , @xmath110 , and @xmath84 .",
    "as such , the outer bound provided by theorem  [ main ] is not computable  @xcite in the present form .",
    "one might question the utility of an outer bound that can not be computed .",
    "the remainder of the paper , however , will show that the bound is still useful as a theoretical tool .",
    "in addition , cardinality bounds might be found later , although obtaining such bounds appears to be more difficult in this case than for related bounds .",
    "it should be mentioned that the time - sharing variable @xmath84 is unnecessary ; it can be absorbed into the other variables .",
    "we have included it to ease the comparison with existing inner and outer bounds , to which we turn next .",
    "the coding scheme described in the introduction gives rise to the following inner bound on the rate - distortion region .",
    "[ bt : inner : defn ] let @xmath111 denote the set of finite - alphabet random variables @xmath112 satisfying    1 .",
    "@xmath84 is independent of @xmath56 , 2 .",
    "@xmath113 for all @xmath32 , and 3 .",
    ".    then define @xmath115 \\ \\text{for",
    "all $ k$ } \\bigg\\}.\\end{aligned}\\ ] ] finally , let @xmath116    [ bt : inner ] @xmath117 .    in appendix  [",
    "closed ] we show that @xmath118 is in fact closed .",
    "we call @xmath119 the berger - tung @xcite inner bound , since although these authors prove a bound that is less general than the one given here , their proof can be extended to prove proposition  [ bt : inner ] .",
    "et al . _",
    "@xcite or gastpar  @xcite for recent sketches of the proof that accommodate some of the generalizations included here .    to understand the difference between @xmath118 and @xmath108 , suppose that @xmath120 is in @xmath53 and @xmath110 is deterministic .",
    "then @xmath121 is in @xmath111 , and for all",
    "@xmath13 and all @xmath98 , @xmath122 thus @xmath123 conversely , if @xmath121 is in @xmath111 , then for any deterministic @xmath110 , @xmath124 is in @xmath53 and  ( [ tworegions ] ) holds for any @xmath65 .",
    "it follows that @xmath118 is equal to @xmath108 with @xmath110 restricted to be deterministic in the definition of @xmath53 .    in particular , to obtain coincident inner and outer bounds",
    ", it suffices to show that restricting @xmath110 to be deterministic in the definition of @xmath53 does not reduce @xmath108 .",
    "we will see later how this can be accomplished in several examples . of course , it is not possible for the problem solved by krner and marton  @xcite , since they show that the inner bound is not tight in that case .",
    "the best outer bound in the literature is the following .",
    "[ bt : outer : defn ] let @xmath125 denote the set of finite - alphabet random variables @xmath126 satisfying    1 .",
    "@xmath84 is independent of @xmath56 , 2 .",
    "@xmath127 for all @xmath32 , and 3 .",
    "@xmath128 .",
    "then let @xmath129 \\",
    "\\text{for all $ k$ } \\bigg\\}.\\end{aligned}\\ ] ] finally , let @xmath130    @xmath131 .",
    "as with the inner bound , berger  @xcite and tung  @xcite prove the result for a model that is more restrictive than the one considered here , but their proof can be extended to this setup ( c.f .",
    "the difference between @xmath118 and @xmath132 is that condition ( _ ii _ ) has been weakened in the latter .",
    "we next show that the berger - tung outer bound is subsumed by the one in the previous section .",
    "[ contain ] @xmath133 .    _ proof .",
    "_ first observe that for any @xmath124 in @xmath53 , @xmath134 since @xmath135 , it holds @xmath136 thus @xmath121 is in @xmath125 and in particular , @xmath137 it follows that @xmath138 @xmath107    the proof reveals that @xmath108 improves upon @xmath132 in two ways .",
    "the first is that @xmath108 allows for optimization over @xmath65 while @xmath132 effectively requires the choice @xmath139 .",
    "the second is that @xmath53 is `` smaller '' than @xmath125 in the sense that if @xmath124 is in @xmath53 then @xmath121 is in @xmath125 .",
    "the balance of this section is devoted to showing that these improvements make the containment in proposition  [ contain ] strict in some cases .",
    "as the reader will see , the former difference is entirely responsible for the gap that we expose between the two bounds in our examples .",
    "we hasten to add , however , that the latter improvement is not an empty one in that anantharam and borkar  @xcite have shown that there can exist a @xmath121 in @xmath125 with the property that there does not exist a @xmath110 such that @xmath124 is in @xmath53 .",
    "it is interesting to note that the anantharam - borkar example arose independently of this work in the context of distributed stochastic control .    we will exhibit three examples for which @xmath132 strictly contains @xmath108 .",
    "the first is rather contrived and can be solved from first principles .",
    "it is included to illustrate the difference between the two bounds .",
    "let @xmath140 , @xmath141 , @xmath142 , and @xmath143 be independent and identically distributed ( i.i.d . )",
    "random variables , uniformly distributed over @xmath144 .",
    "consider two encoders ( @xmath145 ) with @xmath146 and @xmath147 ( there is no hidden source or side information in this example ) .",
    "we have a single distortion constraint ( @xmath148 ) with @xmath149 and @xmath150 in words , the decoder attempts to guess either the first or the second coordinate of both encoders observations .",
    "it incurs a distortion of zero if it guesses correctly the same coordinate of the two sources and one otherwise .",
    "note that the decoder need not declare which coordinate it is attempting to guess .    for this problem , @xmath151    _ proof .",
    "_ suppose @xmath152 is in @xmath108 , and @xmath153 .",
    "observe that since @xmath0 and @xmath1 are independent , deterministic random variables are in @xmath64 .",
    "thus there exists @xmath68 in @xmath53 such that @xmath154 \\\\ r_1 & \\ge i(y_1;u_1|w , t ) \\\\",
    "r_2 & \\ge i(y_2;u_2|w , t).\\end{aligned}\\ ] ] by condition ( _ ii _ ) defining @xmath53 , @xmath155 since @xmath1 is independent of @xmath156 in this example , @xmath1 must be independent of @xmath157 .",
    "thus @xmath158 likewise , @xmath0 is independent of @xmath159 and hence given @xmath55 , @xmath0 is independent of @xmath160 .",
    "this observation combined with  ( [ repeatii ] ) implies @xmath161 .",
    "in particular , @xmath162 . by condition ( _ iii _ ) defining @xmath53 , @xmath163 .",
    "these last two chains imply that @xmath164 thus conditioned on @xmath55 and the event @xmath165 , we have @xmath166 .",
    "it follows that @xmath167 since @xmath168 is a function of @xmath90 and @xmath169 .",
    "next , observe that on the events @xmath165 and @xmath170 , @xmath1 and @xmath169 together must reveal one of the two bits of @xmath0 . thus @xmath171 continuing our chain of inequalities , @xmath172 now @xmath173 where , here and throughout , @xmath174 is the binary entropy function with natural logarithms .",
    "we conclude that @xmath175 similarly , @xmath176 substituting these two observations into  ( [ toyformula ] ) and recalling  ( [ toycondition ] ) yields @xmath177 by symmetry , @xmath178 must satisfy the same inequality .",
    "this implies the desired conclusion . @xmath107",
    "it is easy to see that the point @xmath179 is achievable .",
    "using rate @xmath180 , each encoder can send , say , the first coordinate of its observation .",
    "the decoder can then realize zero distortion by repeating the two bits it receives .",
    "this fact and the above proposition together imply @xmath181 in particular , @xmath108 is tight in the zero - distortion limit .",
    "in contrast , we show next that the berger - tung outer bound is not .",
    "the point @xmath182 is contained in @xmath132 .    _ proof .",
    "_ let the random variable @xmath110 be uniformly distributed over @xmath183 , and let @xmath184 and @xmath185 .",
    "let @xmath186 .",
    "it is straightforward to verify that @xmath187 is in @xmath125 ( the time - sharing random variable @xmath84 is unneeded and can be taken to be constant ) .",
    "next note that @xmath188 = 0 $ ] . finally , one can compute @xmath189 this implies that @xmath190 the conclusion follows .",
    "@xmath107      here @xmath7 is uniformly distributed over @xmath191 , and @xmath192 for @xmath32 in @xmath33 , where @xmath193 are i.i.d .  with @xmath194 and @xmath195 .",
    "let @xmath196 .",
    "we will assume that there is no side information and that the decoder is only interested in reproducing the hidden process @xmath7 .",
    "we measure the fidelity of its reproduction using a family of distortion measures , @xmath197 , where @xmath198 we are particularly interested in the large-@xmath199 limit . in this regime , @xmath200 approximates the `` erasure distortion measure ''  @xcite , @xmath201 we use a finite approximation because an infinite distortion measure causes difficulties in the proof of the berger - tung inner bound .",
    "this example is motivated by the following problem arising in energy - limited sensor networks .",
    "we seek to monitor a remote source , @xmath7 . to this end",
    ", we deploy an array of sensors , each of which is capable of observing the source with negligible probability of error . to lengthen the lifetime of the network",
    ", each sensor spends a fraction @xmath202 of the time in a low - power `` sleep '' state .",
    "we assume that the sensors cycle between the awake and sleep states independently of each other and on a faster time scale than the sampling ; at each discrete time , each sensor sleeps with probability @xmath202 , independently of the other sensors and the past .",
    "sensors do not make any observations while they are asleep , resulting in erasures .",
    "we permit the coding process to introduce additional erasures , but not errors , yielding the erasure distortion measure .",
    "what sum rate is required in order for the decoder to reproduce a fraction @xmath203 of the @xmath86 variables while almost never making an error ?",
    "of course , @xmath204 must satisfy @xmath205 .",
    "define @xmath206 where @xmath207 is the rate - distortion region when the distortion measure is @xmath208 .",
    "we define @xmath209 and @xmath210 analogously .    in appendix",
    "[ beceo : achieve ] , we show that if @xmath211 , then @xmath212.\\ ] ] in appendix  [ beceo : converse ] , we show that the quantity on the right - hand side is also a lower bound to @xmath213 .",
    "hence it must equal @xmath214 .",
    "that is , the improved outer bound and the berger - tung inner bound together yield a conclusive result for the sum rate of the binary erasure ceo problem .",
    "evidently this problem was previously unsolved . in appendix",
    "[ bt : loose : be ] , we show that @xmath215 contains points with a strictly smaller sum rate in general .",
    "[ beceo : figure ] shows the correct sum rate for @xmath216 and several values of @xmath6 .",
    "we turn to a continuous example . here",
    "@xmath217 are jointly gaussian and @xmath11 are conditionally independent given @xmath7 . for @xmath218 ,",
    "let us write @xmath219 , where @xmath220 are mutually independent and @xmath221 = \\sigma^2_\\ell > 0 \\ \\text{for all $ \\ell$}.\\ ] ] we will denote the variance of @xmath7 by @xmath222 .",
    "again there is no side information , and the decoder is only interested in reproducing the hidden process @xmath7 , @xmath223 the rate - distortion region for this problem was recently found by oohama  @xcite and prabhakaran , tse , and ramchandran  @xcite .",
    "the two proofs are nearly the same , and build on earlier work of oohama  @xcite .",
    "the primary contribution is the converse result , which makes heavy use of the entropy power inequality  ( * ? ? ?",
    "* theorem  16.6.3 ) .",
    "the berger - tung inner bound is used for achievability .",
    "it is straightforward to extend theorem  [ main ] to this continuous setting .",
    "a statement of the continuous version is given in appendix  [ gaussian : proof ] , where we also use the techniques of oohama  @xcite and prabhakaran , tse , and ramchandran  @xcite to prove the following .",
    "[ gaussian : prop ] for the gaussian ceo problem , @xmath224     + \\sum_{\\ell \\in a } r_\\ell \\bigg\\},\\end{gathered}\\ ] ]    where @xmath225 .",
    "since this expression equals @xmath45  @xcite , we conclude that @xmath108 is tight in this example .",
    "it also follows that the converse result of oohama  @xcite and prabhakaran , tse , and ramchandran  @xcite is a consequence of the outer bound provided in this paper .",
    "this does not imply , however , that the task of proving the converse result is made any easier by our bound .",
    "in fact , comparing appendix  [ gaussian : proof ] to the original works shows that proving proposition  [ gaussian : prop ] is as formidable a task as proving the converse result unaided .",
    "but this is still an improvement over the berger - tung outer bound , the closure of which we show in appendix  [ bt : loose : gaussian ] contains points outside the rate - distortion region .",
    "we end this section by mentioning that oohama s",
    "@xcite converse is actually more general than the result described here , in that oohama permits one of the encoders to make noise - free observations ( i.e. , @xmath226 ) . comparing oohama s proof to appendix  [ gaussian : proof ]",
    "shows that the outer bound supplied in this paper also recovers this more general result .",
    "having seen that the new outer bound recovers the converse of oohama  @xcite and prabhakaran , tse , and ramchandran  @xcite for the gaussian ceo problem , we show in this final section that it also recovers the converse results for the discrete problems of slepian and wolf  @xcite , wyner  @xcite , ahlswede and krner  @xcite , wyner and ziv  @xcite , gelfand and pinsker  @xcite , berger and yeung  @xcite , and gastpar  @xcite .",
    "the outer bound also recovers the converse result for the problem studied by krner and marton  @xcite , although the proof of this fact is not as interesting .",
    "we shall therefore focus on the others . to recover these converse results",
    ", we shall use the following conclusive result for a special case of the problem .",
    "suppose that there exists a function @xmath227 such that @xmath11 are conditionally independent given @xmath228 . also let @xmath229 and @xmath230 we make no other assumptions about the problem .",
    "we would like to characterize the set @xmath231 . in words , conditioned on the side information and some function of the hidden variable ,",
    "the observations are independent , and the hidden variable must be reproduced losslessly .",
    "note that @xmath232 will be empty unless @xmath233 .",
    "gelfand and pinsker  @xcite refer to this condition as `` completeness of observations . ''",
    "[ reduction ] for this problem , @xmath234    _ proof .",
    "_ to show  ( [ recover : main ] ) , it suffices to show that @xmath235 is contained in @xmath236 .",
    "suppose @xmath237 is a point in @xmath108 and @xmath153 . by choosing @xmath238 in definition  [ me : defn ]",
    ", we see that there exists @xmath239 in @xmath53 such that @xmath240 & \\le d_k \\ \\text{for all $ k \\ge 2$},\\end{aligned}\\ ] ] and for all @xmath241 , @xmath242 now @xmath243 where we have used the fact that @xmath244 by fano s inequality  ( * ? ? ?",
    "* lemma  1.3.8 ) , @xmath245 thus @xmath246 it follows that @xmath247 & \\ge i(g(y_0);\\mathbf{u}_a|\\mathbf{u}_{a^c},y_{l+1},w,\\tilde{t } )   \\\\   & \\phantom{i(y_0;\\mathbf{u}_a ) } +          \\sum_{\\ell \\in a } i(y_\\ell;u_\\ell|g(y_0),y_{l+1},w,\\tilde{t } ) \\\\   & = i(g(y_0);\\mathbf{u}_a|\\mathbf{u}_{a^c},y_{l+1},w,\\tilde{t } )   \\\\   & \\phantom{i(y_0;\\mathbf{u}_a| } +      i(\\mathbf{y}_a;\\mathbf{u}_a|\\mathbf{u}_{a^c},g(y_0),y_{l+1},w,\\tilde{t } ) \\\\   & = i(g(y_0),\\mathbf{y}_a;\\mathbf{u}_a|\\mathbf{u}_{a^c},y_{l+1},w,\\tilde{t } ) \\\\   & \\ge i(\\mathbf{y}_a;\\mathbf{u}_a|\\mathbf{u}_{a^c},y_{l+1},w,\\tilde{t } ) .\\end{aligned}\\ ] ] if we now define @xmath248 , it is evident that @xmath121 is in @xmath111 and the point @xmath249 is in @xmath118 .",
    "this implies that @xmath250 which proves  ( [ recover : main ] ) . to prove  ( [ recover : region ] )",
    ", it suffices to show that @xmath118 is closed .",
    "this is shown in appendix  [ closed ] .",
    "@xmath107    the differences between this result and that of gelfand and pinsker  @xcite are numerous but minor .",
    "the most visible differences are that gelfand and pinsker s model does not allow for side information at the decoder or distortion constraints beyond the one on @xmath7 .",
    "indeed , the region given here reduces to theirs when these extensions are ignored .",
    "thus this result seems to be a generalization of theirs , albeit a trivial one since their proof can be modified to handle these extensions .",
    "a closer comparison , however , reveals that they define the rate region more stringently than we do here .",
    "thus , our result does not recover theirs , strictly speaking , although it does recover the converse component of their result since our definitions are weaker .",
    "the reason for including side information and additional distortion constraints in the model is that they enable us to also recover the converse results for the other problems mentioned earlier .",
    "for instance , gastpar  @xcite considers the problem of reproducing the observations individually , subject to separate distortion constraints , under the assumption that the decoder is provided with side information that makes the observations conditionally independent .",
    "his converse result can be recovered by setting @xmath251 .",
    "it is easily verified that , under this condition , our region coincides with his .",
    "the classical wyner - ziv problem  @xcite can be viewed as gastpar s problem with a single encoder ( @xmath252 ) . so that converse result is recovered too .",
    "berger and yeung  @xcite solve the two - encoder problem in which the observations are to be reproduced individually , with at least one of the two being reproduced losslessly . in our notation , this corresponds to setting @xmath145 and @xmath253 .",
    "note that our conditional independence assumption necessarily holds in this case .    to see that under these assumptions",
    ", our region reduces to theirs , suppose @xmath254 for some @xmath255",
    ". then @xmath256 also , @xmath257 where we have used the fact that @xmath258 ( see cover and thomas  @xcite ) .",
    "finally , @xmath259 it is now evident that the two regions are identical ( c.f .",
    "thus the converse result of berger and yeung is a consequence of the outer bound provided here .",
    "the classical problem of source coding with side information  @xcite can be viewed as a special case of the berger - yeung problem in which @xmath260 exceeds the maximum value of @xmath261 , the distortion measure for @xmath1 .",
    "berger and yeung demonstrate how , under this assumption , the region described above reduces to the one given by wyner  @xcite and ahlswede and krner  @xcite .",
    "_ ipso facto _ , the converse result for this problem is also recovered .",
    "this paper ends the way it began , with the result of slepian and wolf  @xcite . here",
    "the aim is to losslessly reproduce all of the observations . for two encoders ( @xmath145 ) ,",
    "this can be viewed as a special case of the problem of berger and yeung .",
    "these authors show how the region described in eqs .",
    "( [ by:1])([by:3 ] ) reduces to the one given at the beginning of the paper . the result for more than two encoders",
    "can be viewed as a special case of proposition  [ reduction ] in which @xmath262 . in this case , if @xmath263 , then for any @xmath241 , @xmath264 since @xmath265 .",
    "now @xmath90 is independent of @xmath84 , so @xmath266 which is the well - known rate region for this problem .",
    "thus the converse of slepian and wolf is also recovered . for this result ,",
    "as with the others , our outer bound dispenses with the need to prove a custom converse coding theorem .",
    "in fact , proposition  [ reduction ] can be viewed as unifying all of the results in this discussion , assuming one is willing to ignore the discrepancies in the definition of the rate - distortion region mentioned earlier .",
    "showing that a particular rate - distortion vector is achievable using the berger - tung inner bound is mostly a matter of finding the proper `` test channels '' @xmath267 for the encoders .",
    "to prove ( [ beceo : sumrate ] ) , we use binary erasure test channels that are identically distributed across the encoders . in this appendix and the next two , the notation is drawn from section  [ beceo : subsection ] .    for any @xmath211 , @xmath268.\\end{gathered}\\ ] ]    _ proof . _ fix @xmath204 and let @xmath269 be i.i.d . , independent of @xmath217 , with @xmath270 for @xmath32 in @xmath33 ,",
    "let @xmath271 .",
    "then let @xmath272 then for all @xmath199 , @xmath273 =     \\pr(u_\\ell = 0 \\ \\text{for all } \\ \\ell )    = \\left[\\pr(u_1 = 0)\\right]^l = d.\\ ] ] thus @xmath274 is contained in @xmath118 for all @xmath199 if for all @xmath275 , @xmath276 the rate vectors satisfying this collection of inequalities are known to form a contrapolymatroid  @xcite .",
    "as such , there exist rate vectors @xmath277 satisfying  ( [ contrapoly ] ) such that @xmath278 in particular , this holds for any vertex of  ( [ contrapoly ] )  @xcite .",
    "now @xmath279 but @xmath280 and @xmath281 then for any @xmath199 , there exist vectors @xmath274 in @xmath282 such that @xmath283.\\ ] ] the conclusion follows .",
    "we evaluate the outer bound s sum - rate constraint for the binary erasure ceo problem via a sequence of lemmas . throughout this appendix",
    ", @xmath284 will denote the function on @xmath285 defined by @xmath286 we begin by proving several facts about @xmath284 .",
    "for this , the following calculations are useful .",
    "[ calc ] for all @xmath287 in @xmath288 $ ] , @xmath289 and @xmath290    _ proof .",
    "_ it is well known that @xmath291 replacing @xmath292 with @xmath293 and rearranging yields  ( [ firstcalc ] ) . to see  ( [ secondcalc ] ) , note that  ( [ firstcalc ] ) implies that the first derivative of @xmath294 is nonpositive on @xmath295 $ ] . since the function in  ( [ calcfun ] ) is nonnegative at @xmath296 , it follows that @xmath297 for all @xmath287 in @xmath295 $ ] .",
    "one can now obtain  ( [ secondcalc ] ) by multiplying both sides by @xmath298 and dividing both sides by @xmath299 .",
    "@xmath107    [ convex ] the function @xmath300 is nonincreasing and convex as a function of @xmath287 on @xmath301 .",
    "_ the first derivative of @xmath300 on @xmath302 is @xmath303 this observation , the first conclusion of lemma  [ calc ] , and the continuity of @xmath284 together imply that @xmath300 is nonincreasing on @xmath304 $ ] .",
    "since @xmath300 is constant on @xmath305 , it follows that @xmath300 is nonincreasing on @xmath301 .",
    "the second derivative of @xmath300 on @xmath302 is @xmath306 this observation , the second conclusion of lemma  [ calc ] , and the continuity of @xmath284 together imply that @xmath300 is convex on @xmath304 $ ] . since @xmath300 is nonincreasing on @xmath307 and constant on @xmath305 , it follows that @xmath300 is convex on @xmath301 .",
    "+ @xmath107    [ convexcor ] the function @xmath308 is nonincreasing and convex in @xmath309 on @xmath310 .",
    "_ @xmath311 with @xmath312 , and @xmath300 is convex and nonincreasing while @xmath313 is concave and nondecreasing .",
    "@xmath107    the next lemma is central to our evaluation of the outer bound s sum rate .",
    "note that condition ( _ i _ ) in the hypothesis implies that @xmath314 .",
    "that is , the reproduction @xmath169 is never in error ( although it may be an erasure ) .",
    "[ central ] suppose @xmath315 and @xmath316 is such that    1 .",
    "@xmath317 \\le d \\",
    "\\text{for all }",
    "\\ \\lambda$ ] , 2 .",
    "@xmath318 for all @xmath32 , and 3 .",
    ".    then @xmath320    _ proof .",
    "_ for each encoder @xmath32 , let @xmath321 then define @xmath322 finally , let @xmath323 then @xmath324 \\\\    & = \\frac{1}{l } \\sum_{\\ell = 1}^l \\bigg [ \\frac{1}{2}h\\left(p      + ( 1-p)\\delta_{\\ell,+ } \\right ) + \\frac{1}{2}h\\left(p       + ( 1-p)\\delta_{\\ell,- } \\right ) \\\\    & \\phantom{= \\frac{1}{l } \\sum_{\\ell = 1}^l \\bigg [ } - \\frac{1}{2}(1-p )      h(\\delta_{\\ell,+ } ) - \\frac{1}{2}(1-p ) h(\\delta_{\\ell,-})\\bigg].\\end{aligned}\\ ] ] since @xmath325 a.s . ,",
    "on the event @xmath326 we must have @xmath327 and hence @xmath328 for all @xmath32 .",
    "in addition , the condition @xmath329 dictates that when @xmath326 we must have @xmath330 for some @xmath32 , for otherwise we would have @xmath331 .",
    "all of this implies that @xmath332 on the event that @xmath326 .",
    "similarly , @xmath333 on the event @xmath334 .",
    "thus @xmath335 implies that @xmath336 , so @xmath337 this implies that @xmath338 thus @xmath339 : \\\\   & \\phantom{\\inf\\big\\ { \\sum_{\\ell = 1}^l \\frac{1}{2 } \\big [ }    \\delta_{\\ell,+ } , \\delta_{\\ell,- } \\in [ 0,1 ] \\",
    "\\text{for all } \\",
    "\\ell \\ \\text{and } \\\\   & \\phantom{\\inf\\big\\ { }   \\frac{1}{2 } \\prod_{\\ell = 1}^l ( p + ( 1-p ) \\delta_{\\ell,+ } )   + \\frac{1}{2 } \\prod_{\\ell = 1}^l ( p + ( 1-p ) \\delta_{\\ell,- } ) \\le d    \\bigg\\}.\\end{aligned}\\ ] ] this optimization problem is not convex , but if we change variables to @xmath340 then it can be rewritten as @xmath341 : \\\\    & \\phantom{\\ge \\inf\\big\\ { } \\delta_{\\ell,+ } , \\delta_{\\ell,- } \\in    [ \\log p,0 ] \\",
    "\\text{for all } \\ \\ell \\ \\text{and } \\\\ & \\phantom{\\ge \\inf\\big\\ { } \\frac{1}{2 } \\exp\\left(\\sum_{\\ell = 1}^l       \\delta_{\\ell,+}\\right )   + \\frac{1}{2 } \\exp\\left(\\sum_{\\ell = 1}^l \\delta_{\\ell,-}\\right ) \\le d     \\bigg\\ } \\\\ & = \\inf\\bigg\\ { \\frac{1}{l } \\sum_{\\ell = 1}^l    \\frac{1}{2 } \\left[g\\left(e^{\\delta_{\\ell,+}}\\right ) +        g\\left(e^{\\delta_{\\ell,-}}\\right ) \\right ] :   \\\\    & \\phantom{\\ge \\inf\\big\\ { }   \\delta_{\\ell,+ } , \\delta_{\\ell,- } \\in    [ \\log p,0 ] \\",
    "\\text{for all } \\ \\ell \\ \\text{and } \\\\ & \\phantom{\\ge \\inf\\big\\ { } \\frac{1}{2 } \\exp\\left(\\sum_{\\ell = 1}^l      \\delta_{\\ell,+}\\right )   + \\frac{1}{2 } \\exp\\left(\\sum_{\\ell = 1}^l \\delta_{\\ell,-}\\right ) \\le d    \\bigg\\},\\end{aligned}\\ ] ] which is convex by lemma  [ convex ] .",
    "thus we may assume without loss of optimality that @xmath342 and @xmath343 this gives @xmath344 : \\\\   & \\phantom{\\ge \\inf\\bigg\\ { }    \\frac{1}{2}e^{l \\delta_+ } + \\frac{1}{2}e^{l \\delta_- }                \\le d\\bigg\\ } \\\\",
    "& \\ge \\inf\\big\\{g\\left(e^\\delta\\right ) : \\delta",
    "\\in [ \\log p , 0 ] :     e^{l\\delta } \\le d\\big\\ } \\\\    & \\ge g(d^{1/l}),\\end{aligned}\\ ] ] by lemma  [ convex ] . @xmath107",
    "the quantity @xmath345 can be interpreted as the amount of information that the @xmath32th encoder sends about its observation _",
    "_ noise__. lemma  [ central ] then says that if a fraction @xmath204 of the output symbols is allowed to be erased and no errors are allowed , then the amount of information that the average encoder must send about its observation noise is at least @xmath346 .",
    "we would like to extend this last assertion to allow `` few '' decoding errors instead of none .",
    "to this end , we will employ the following cardinality bound on the alphabet sizes of the auxiliary random variables @xmath347 .",
    "[ cardinality ] let @xmath316 be such that    1 .",
    "@xmath318 for all @xmath32 , and 2 .",
    "@xmath319 .",
    "then for any @xmath199 , there exist alternate random variables @xmath348 and @xmath349 also satisfying ( _ i _ ) and ( _ ii _ ) such that @xmath350 & \\le e[d_1^\\lambda(y_0,z_1 ) ] , \\\\",
    "i(y_\\ell;\\tilde{u}_\\ell|y_0 ) & = i(y_\\ell;u_\\ell|y_0 ) \\",
    "\\text{for all $ \\ell$},\\end{aligned}\\ ] ] and @xmath351    see wyner and ziv  ( * ? ? ?",
    "* theorem  a2 ) or csiszr and krner  ( * ? ? ?",
    "* theorem  3.4.6 ) for proofs of similar results .",
    "the next lemma is the desired extension of lemma  [ central ] .",
    "[ continuity ] suppose @xmath315 and @xmath316 is such that    1 .",
    "@xmath317 \\le d$ ] , 2 .",
    "@xmath352 for all @xmath32 , and 3 .",
    "@xmath319 .",
    "if @xmath353 then @xmath354    _ proof .",
    "_ by lemma  [ cardinality ] , we may assume that @xmath355 for each @xmath32 .",
    "we may also assume that @xmath169 is a deterministic function of @xmath109 : @xmath356 .",
    "define @xmath357 we now define random variables @xmath358 to replace @xmath359",
    ". the replacements will be close to the originals in distribution but will have the property that @xmath360 .",
    "that is , @xmath361 will never be in error .",
    "set @xmath362 for each @xmath32 , and let @xmath363 then define @xmath364 there is a natural way of coupling @xmath365 to @xmath109 such that if @xmath366 is in @xmath367 then @xmath368 . with this coupling in mind",
    ", it is evident that @xmath369 & =      e[d_1^\\lambda(y_0,\\tilde{z}_1)1(\\max(\\tilde{u}_1,\\ldots ,      \\tilde{u}_l ) \\le 4 ) ] \\\\      & \\phantom{e [ } +      e[d_1^\\lambda(y_0,\\tilde{z}_1)1(\\max(\\tilde{u}_1,\\ldots,\\tilde{u}_l ) = 5 ) ] \\\\     & \\le e[d_1^\\lambda(y_0,z_1)1(\\max(\\tilde{u}_1,\\ldots ,      \\tilde{u}_l ) \\le 4 ) ] \\\\     & \\phantom{e [ } + \\pr(\\max(\\tilde{u}_1,\\ldots,\\tilde{u}_l ) = 5 ) \\\\     & \\le d + \\pr(\\max(\\tilde{u}_1,\\ldots,\\tilde{u}_l ) = 5).\\end{aligned}\\ ] ] now for any @xmath32 in @xmath33 , @xmath370 by the union bound , this is upper bounded by @xmath371   \\\\     + \\left[\\frac{1-p}{2 } \\pr(u_\\ell \\in a_{\\ell,+}|y_\\ell = -1 ) +          p \\pr(u_\\ell",
    "\\in a_{\\ell,+}|y_\\ell = 0 ) \\right].\\end{gathered}\\ ] ] since @xmath372 , @xmath373 \\\\    & \\phantom{= }   + \\bigg[\\frac{1-p}{2 }              \\pr(u_\\ell \\in a_{\\ell,+}|y_\\ell = -1,y_0 = -1 ) \\\\    & \\phantom{= } + p \\pr(u_\\ell \\in a_{\\ell,+}|y_\\ell = 0,y_0 = -1 ) \\bigg ] \\\\    & \\le \\pr(u_\\ell \\in a_{\\ell,-}|y_0 = 1 ) +         \\pr(u_\\ell \\in a_{\\ell,+}|y_0 = -1).\\end{aligned}\\ ] ] but @xmath374 which implies @xmath375 by the definition of @xmath376 , for each @xmath377 , there exists at least one @xmath378 such that @xmath379 and @xmath380 together with  ( [ preholder ] ) , this implies @xmath381 applying hlder s inequality  @xcite gives @xmath382^{1/l } \\cdot |a_{\\ell,+}|^{(l-1)/l } \\\\     & \\le 4 \\left(\\frac{2d}{\\lambda}\\right)^{1/l}.\\end{aligned}\\ ] ] likewise , @xmath383 thus @xmath384 by the union bound , it follows that @xmath385 and therefore @xmath386 \\le d +     8l\\left(\\frac{2d}{\\lambda}\\right)^{1/l } \\le d + \\delta.\\ ] ] note that @xmath387 only if @xmath366 is in @xmath376 for some @xmath32 , and @xmath388 thus @xmath389 and similarly , @xmath390 .",
    "it follows from lemma  [ central ] that @xmath391 the remainder of the proof is devoted to showing that @xmath392 is close to @xmath345 .",
    "for this we use the decomposition @xmath393 observe that @xmath394 thus @xmath395 similarly , @xmath396 therefore if we view @xmath58 as a random variable on @xmath397 , for any @xmath398 in @xmath399 , @xmath400 a standard result on the continuity of entropy  ( * ? ? ?",
    "* lemma  1.2.7 ) now implies that ( recall @xmath401 ) @xmath402 so @xmath403 likewise , for any @xmath398 in @xmath191 , @xmath404 thus @xmath405 so @xmath406 as before .",
    "it follows that @xmath407 combining this with  ( [ midway ] ) yields @xmath408 @xmath107    we are now in a position to prove the main result of this appendix .    for any @xmath315 , @xmath409    _ proof . _ fix @xmath211 and @xmath410 $ ] , and suppose @xmath199 satisfies @xmath411.\\ ] ] by taking @xmath412 in the definition of @xmath413",
    ", it follows that there exist @xmath277 in @xmath414 and @xmath68 in @xmath53 such that @xmath415 , \\",
    "\\text{and } \\\\",
    "\\mathcal{r}_o(d,\\lambda ) + \\delta \\ge   \\sum_{\\ell = 1}^l r_\\ell & \\ge",
    "i(y_0;\\mathbf{u}|t ) +   \\sum_{\\ell = 1}^l i(y_\\ell;u_\\ell|y_0,w , t ) .",
    "\\end{split}\\ ] ] for each possible realization @xmath416 of @xmath55 , let @xmath417.\\ ] ] let @xmath418",
    ". then by markov s inequality , @xmath419 in particular , @xmath420 .",
    "also , for any @xmath421 , @xmath422 by  ( [ biglambda ] ) .",
    "thus , by lemma  [ continuity ] , if @xmath421 , @xmath423 by averaging over @xmath421 and invoking corollary  [ convexcor ] , we obtain @xmath424 from  ( [ markov ] ) , it follows that @xmath425.\\ ] ] now by the data processing inequality , @xmath426 let @xmath427 . continuing , @xmath428 substituting this and  ( [ sumnoise ] ) into  ( [ sumrate ] ) yields @xmath429 - \\delta.\\ ] ] the proof is terminated by letting @xmath430 and then @xmath431 .",
    "we will show numerically that for one instance of the binary erasure ceo problem , @xmath132 contains points with a strictly superoptimal sum rate .",
    "let @xmath145 and @xmath432 .",
    "let @xmath433 and @xmath434 be @xmath144-valued random variables with the joint distribution @xmath435,\\ ] ] i.e. , @xmath436 we assume that @xmath437 is independent of ( @xmath438 . let @xmath439 for @xmath32 in @xmath183 , and let @xmath440 . since @xmath441 can be written as @xmath442 where @xmath443 and @xmath444 are i.i.d . with @xmath445 ( recall the notation of section  [ beceo : subsection ] )",
    ", we have @xmath446 .",
    "note that @xmath447 and @xmath448 have the joint distribution @xmath449.\\ ] ] thus for any @xmath199 , @xmath317 = \\pr(n_1 \\cdot w_1 = n_2 \\cdot w_2 = 0 ) = 3/5 $ ] .",
    "now we can compute @xmath450 and @xmath451 it follows that @xmath452 is in @xmath453 for any @xmath199 .",
    "thus @xmath454 from the previous two appendices , the correct sum rate is @xmath455",
    "two lemmas are needed for our proof of proposition  [ gaussian : prop ] .",
    "the first is a simple extension of theorem  [ main ] to the gaussian ceo problem setting of section  [ ceo : gaussian ] . for this appendix ,",
    "let us redefine @xmath64 to be the set of real - valued random variables @xmath65 such that @xmath11 are conditionally independent given @xmath65 ( the side information @xmath8 is unneeded in this context and shall be ignored ) .",
    "let us also redefine @xmath53 to be the set of random variables @xmath456 such that each takes values in a finite - dimensional euclidean space , and collectively they satisfy the markov conditions defining the original @xmath53 ,    1 .",
    "@xmath55 is independent of @xmath457 , 2 .",
    "@xmath458 for all @xmath32 , and 3 .",
    "@xmath459 ,    and one new technical condition ,    1 .",
    "the conditional distribution of @xmath58 given @xmath110 and @xmath84 is discrete for each @xmath32 .",
    "note that any conditional distribution involving these random variables is well - defined  ( * ? ? ?",
    "* theorem  6.3 ) . as such",
    ", so is any conditional mutual information  ( * ? ? ?",
    "* ch .  3 , especially the translator s notes at the end ) .    for the gaussian ceo problem , @xmath460 if @xmath108 is defined using the @xmath64 and @xmath53 just described .",
    "the proof follows the original and is omitted .",
    "the second ingredient is a consequence of an intriguing result of oohama  @xcite and prabhakaran , tse , and ramchandran that relates information the encoders send about the hidden source to information they send about their observation `` noise . ''",
    "[ core ] if @xmath68 is in @xmath53 , then for all @xmath13 , @xmath461    _ proof .",
    "_ for any realization of @xmath55 , it follows from lemma  3 in oohama  @xcite that is a discrete , deterministic function of @xmath441 for each @xmath32 , but the proof shows that conditions ( _ ii _ ) and ( _ iv _ ) above are actually sufficient . ]",
    "@xmath462 we now average over @xmath416 and invoke the convexity of @xmath463 twice , once on each side .",
    "@xmath107    _ proof of proposition  [ gaussian : prop]_.",
    "if @xmath274 is in @xmath108 , then there exists @xmath68 in @xmath53 such that @xmath464 \\le d$ ] and for all @xmath13 , @xmath465 now @xmath466 since @xmath467 , the right - hand side can be lower bounded as follows @xmath468},\\end{aligned}\\ ] ] where we have used the rate - distortion theorem for gaussian sources  ( * ? ? ?",
    "* theorem  13.3.2 ) .",
    "in particular , @xmath469 let us address the second term on the left - hand side of  ( [ gaussian : main : formula ] ) .",
    "observe that @xmath470 defining @xmath471 and applying lemma  [ core ] to the right - hand side gives @xmath472.\\ ] ] substituting ( [ gaussian : rd ] ) and ( [ invokingkey ] ) into ( [ gaussian : main : formula ] ) gives @xmath473^{-1 }    \\right\\}.\\ ] ] the conclusion follows upon substitution of this inequality and the definition of @xmath474 into  ( [ gaussian : proof : var ] ) . @xmath107",
    "we have just seen that the improved outer bound is capable of recovering the converse result of oohama  @xcite and prabhakaran , tse , and ramchandran  @xcite for the gaussian ceo problem . here",
    "we will show that the berger - tung outer bound does not recover this result . as with the binary erasure ceo problem",
    ", we will show that , in general , the berger - tung outer bound contains points with a strictly superoptimal sum rate .",
    "consider the case in which , in the notation of section  [ ceo : gaussian ] , @xmath145 and @xmath475",
    ". in words , two encoders each observe a unit variance , i.i.d.gaussian process in additive gaussian noise with a signal - to - noise ratio of unity .",
    "it follows from proposition  [ gaussian : prop ] that the minimum sum rate needed to achieve the distortion @xmath476 is at least @xmath477 nats .",
    "let @xmath110 , @xmath478 , and @xmath479 be gaussian random variables , independent of each other and @xmath7 , @xmath0 , and @xmath1 .",
    "let @xmath478 and @xmath479 have unit variance ; we denote the variance of @xmath110 by @xmath480 .",
    "let @xmath481 note that the sum of @xmath482 and @xmath483 is a sufficient statistic for @xmath7 given @xmath482 and @xmath483 .",
    "this observation makes it easy to verify that if @xmath484 $ ] , then @xmath464 = 1/2 $ ] .",
    "note that this distortion is independent of @xmath480 .",
    "it follows that for any value of @xmath480 , @xmath132 contains points of the form @xmath485 with @xmath486 but  ( * ? ? ?",
    "* theorem  9.4.1 ) @xmath487 and @xmath488 observe that , when viewed as functions of @xmath480 , @xmath489 is strictly decreasing and @xmath490 is continuous . since @xmath491 yields @xmath492 it follows that there exists @xmath493 such that @xmath494",
    "the main step in proving that @xmath118 is closed is to show that one can limit the ranges of the auxiliary random variables without reducing the region .",
    "[ bt : hat : defn ] let @xmath495 denote the set of finite - alphabet random variables @xmath112 in @xmath111 such that @xmath496 and @xmath497 then let @xmath498    we shall show that @xmath499 in two steps , first handling the case in which @xmath84 is deterministic , and then bootstrapping to the general case .",
    "both steps involve now - standard uses of carathodory s theorem  ( * ? ? ?",
    "* theorem  17.1 ) .",
    "we give proofs of both steps , albeit condensed ones , due to the complexity of our setup .",
    "[ deterministic ] suppose that @xmath126 is in @xmath118 and @xmath84 is deterministic .",
    "then there exists @xmath500 in @xmath501 such that @xmath502 is deterministic and @xmath503 .",
    "_ for any @xmath13 containing @xmath504 , we have @xmath505 while for any nonempty @xmath241 not containing @xmath504 , we have @xmath506 carathodory s theorem guarantees that we can find a @xmath507 with @xmath508 such that @xmath509 , @xmath510 @xmath511 and similarly for @xmath512 and @xmath513 $ ] .",
    "since @xmath514 , if we substitute @xmath507 for @xmath482 , the resulting @xmath68 is in @xmath111 and @xmath515 is unchanged .",
    "repeating this procedure for @xmath516 completes the proof .",
    "@xmath107    @xmath499 .",
    "_ let @xmath121 be in @xmath111 .",
    "for each @xmath83 in @xmath517 , let @xmath518 denote the joint distribution of @xmath121 conditioned on the event @xmath519 .",
    "by lemma  [ deterministic ] , for each @xmath83 , there exists @xmath520 such that @xmath521 is in @xmath495 and @xmath522 . by replacing @xmath359 with @xmath520 for each value of @xmath84",
    ", we obtain @xmath523 in @xmath111 such that @xmath524 for all @xmath32 and @xmath525 .",
    "now @xmath526\\pr(t = t )      \\ \\text{for all $ k$ } \\bigg\\}.\\end{gathered}\\ ] ] carathodory s theorem implies that we can find a @xmath502 with @xmath527 and @xmath528 such that @xmath529 and similarly for @xmath530 $ ] .",
    "then @xmath531 is in @xmath495 and @xmath532 since @xmath121 in @xmath111 was arbitrary , it holds @xmath533 .",
    "this completes the proof since the reverse containment is obvious .",
    "@xmath107    the cardinality bounds provided by the last two lemmas , while finite , are exponential in @xmath6 and hence impractical for moderate numbers of encoders .",
    "one can improve upon these bounds by exploiting the polymatroid structure  @xcite of @xmath118 .",
    "while this would be useful if one wished to numerically evaluate the bound , our aim here is merely to show that it is closed .",
    "@xmath501 is closed .",
    "_ the markov conditions defining @xmath495 can be expressed as @xmath534 since the conditional mutual information function is continuous , @xmath495 is compact when viewed as a subset of euclidean space .",
    "thus if @xmath535 is a sequence in @xmath501 that converges to @xmath78 , by considering subsequences we may assume that @xmath535 is in @xmath536 for each @xmath40 and @xmath537 . by invoking the continuity of mutual information once again",
    ", we obtain @xmath538 for each @xmath241 . likewise , @xmath93 \\",
    "\\text{for all $ k$}.\\ ] ] it follows that @xmath78 is in @xmath515 and therefore also in @xmath501 . @xmath107",
    "@xmath118 is closed .",
    "it is a pleasure to acknowledge discussions with vinod prabhakaran .",
    "the results in section  [ ceo : gaussian ] are due to him .",
    "this work has also benefited from the helpful comments of stark  c. draper , pramod  viswanath , and anant sahai .",
    "y.  oohama , `` rate - distortion theory for gaussian multiterminal source coding systems with several side informations at the decoder , '' _ ieee trans .",
    "inf . theory _ ,",
    "51 , no .  7 , pp .",
    "25772593 , july 2005 .",
    "t.  berger , `` multiterminal source coding , '' in _ the information theory approach to communications _",
    "cism courses and lectures , g.  longo , ed.1em plus 0.5em minus 0.4emspringer - verlag , 1978 , vol .",
    "171231 .",
    "j.  chen , x.  zhang , t.  berger , and s.  b. wicker , `` an upper bound on the sum - rate distortion function and its corresponding rate allocation schemes for the ceo problem , '' _",
    "ieee j. select .",
    "areas commun .",
    "_ , vol .",
    "22 , no .  6 , pp .",
    "977987 , aug .",
    "2004 .",
    "p.  viswanath , `` sum rate of a class of gaussian multiterminal source coding problems , '' in _ advances in network information theory _",
    "dimacs in discrete mathematics and theoretical computer science , p.  gupta , g.  kramer , and a.  j. van wijngaarden , eds.1em plus 0.5em minus 0.4emams , 2004 , vol .",
    "66 , pp . 4360 ."
  ],
  "abstract_text": [
    "<S> we prove a new outer bound on the rate - distortion region for the multiterminal source - coding problem . </S>",
    "<S> this bound subsumes the best outer bound in the literature and improves upon it strictly in some cases . </S>",
    "<S> the improved bound enables us to obtain a new , conclusive result for the binary erasure version of the `` ceo problem . '' </S>",
    "<S> the bound recovers many of the converse results that have been established for special cases of the problem , including the recent one for the gaussian version of the ceo problem . </S>"
  ]
}