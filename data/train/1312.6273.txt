{
  "article_text": [
    "nowadays information on the internet is exploding exponentially through time , and approximately 80% are stored in the form of text .",
    "so text mining has been a very hot topic .",
    "one particular research area is document clustering , which is a major topic in the information retrieval community .",
    "it allows to efficiently capture high - order similarities between objects described by rows and columns of a data matrix . in the domain of text clustering ,",
    "a document is described as a set of words .",
    "the relationship between documents and words allows for exploitation of the relationship between groups of words that occur mostly in a group of documents .    in @xcite ,",
    "a co - similarity measure has been proposed , called x - sim @xcite which builds on the idea of iteratively generating the similarity matrices between documents and words , each of them built on the basis of the other .",
    "this measure works well for unsupervised document clustering .",
    "however , in recent researches , the sentence has been considered as a more informative feature term for improving the effectiveness of document clustering @xcite . while considering three levels documents @xmath0 sentences @xmath0 words to represent the data set , we are able to deal with a dependency between documents - sentences , as also between sentences - words and , by deduction , between documents - words .    another important aspect in co - clustering",
    "is the weight computing .",
    "a weighted value may be assigned as a link from a document to a word ( or sentence ) indicating the presence of the word ( sentence ) in that document .",
    "the 0/1 encoding denotes the presence or absence of an object in a given document .",
    "different weighting schemes such as the tf - idf @xcite may be incorporated to better represent the importance of words in the corpus , but it has spawned the view that classical probability theory is unable to deal with uncertainties in natural language and machine learning .",
    "so , we proceed to a fuzzification control process which converts crisp similarities to fuzzy ones .",
    "the conversion to fuzzy values is represented by the membership functions @xcite .",
    "they allow a graphical representation of a fuzzy set @xcite .",
    "these fuzzy similarity matrices are used to calculate fuzzy similarity between documents , sentences and words in a triadic computing called ft - sim ( fuzzy triadic similarity ) .    moreover , with the development of the web and the high availability of the storage spaces , more and more documents become accessible .",
    "data can be provided from multiple sites and can be seen as a collection of matrices . by separately processing these matrices ,",
    "we get a huge loss of information .",
    "several extensions to the co - clustering methods have been proposed to deal with such multi - view data .",
    "some works aim at combining multiple similarity matrices to perform a given learning task @xcite . the idea being to build clusters from multiple similarity matrices computed along different views .",
    "multi - view co - clustering such as mv - sim @xcite architecture , based on x - sim measure @xcite deals with the problem of learning co - similarities from a collection of matrices describing interrelated types of objects .",
    "it was proved that this architecture provides some interesting properties both in terms of convergence and scalability and it allows an efficient parallelization of the process .    for this",
    ", we provide parallel architectures for ft - sim to tackle the problem of learning similarities from a collection of matrices . for multi - source or large matrices ,",
    "we propose different parallel architectures in which each ft - sim is the basic component or node we will use to deal with multiple matrices .",
    "thus , we consider a model in which data sets are distributed into @xmath1 sites ( or relation matrices ) .",
    "they describe the connections between documents for each local data set .",
    "our goal is then to compute a fuzzy documents @xmath0 documents matrix @xmath2 for each site @xmath3 @xmath4 trying to take into account all the representative information expressed in the relations .    to combine multiple occurrences of ft - sim , we propose sequential , merging and",
    "splitting based parallel architectures .",
    "the rest of the paper is organized as follows : in section 2 we highlights backgrounds related to similarity measures in a multi - view data sets . in section 3 we provide our fuzzy triadic similarity measure . in section 4 we present the three proposed architectures allowing parallel computing for co - clustering .",
    "section 5 concludes the paper and gives indications of some future work .",
    "most of the existing clustering methods focus on data sets described by a unique data matrix , which can either be a matrix which describes objects by their characteristics , or a relation matrix that describes the intensity of the relation between instances of two types of objects , such as a documents @xmath0 words matrix . in the latter case ,",
    "both types of objects can be clustered ; methods dealing with this task are referred to as co - clustering approaches and have been extensively studied",
    ".    however , in many applications , data sets involving more than two types of interacting objects , or simply related , are also frequent .",
    "a simple way to represent such data sets is to use as many matrices as there are relations between the objects .",
    "then , one could use classical co - clustering methods to separately cluster the objects occurring in the different matrices but , in this way , interactions between objects are not taken into account , thus leading to a loss of information . therefore ,",
    "handling the views together , referenced as the multi - view clustering task , is an interesting challenge in the learning domain to resolve limits of classical clustering .",
    "many extensions to the clustering methods have been proposed to deal with multi - view data . in @xcite , they describe an extension of k - means ( mvkm ) and of em algorithms using multi - view model . in @xcite and @xcite ,",
    "the authors build clusters from multiple similarity matrices computed along different views . in @xcite , a co - clustering system",
    "called mvsc has been proposed .",
    "it permits a multi - view spectral clustering while using the co - training that has been widely used in semi - supervised learning problems .",
    "the general idea is to learn the clustering in one view and use it to label the data in an other view so as to modify the graph structure ( similarity matrix ) .",
    "closer to our approach , some works aim at combining multiple similarity matrices to perform a given learning task .",
    "the mvsim architecture @xcite which is an extension of the x - sim algorithm @xcite , adapts the previous algorithm to the multi - view context .",
    "it computes simultaneously the co - similarity matrix for each of @xmath1 different kinds of objects @xmath5 described by @xmath6 relation matrices .",
    "the basic idea is to create a learning network isomorphic to these data sets structures .",
    "it was shown that it is possible to use this architecture to efficiently compute co - similarities on large data sets by splitting a data matrix into smaller ones .",
    "sentence - based analysis means that the similarity between documents should be based on matching sentences rather than on matching single words only .",
    "sentences contain more information than single words ( information regarding proximity and order of words ) and have a higher descriptive power@xcite @xcite@xcite .",
    "thus a document must be broken into a set of sentences , and a sentence is broken into a set of words .",
    "we focus on how to combine the advantages of two representation models in document co - clustering .    to represent our textual data set ,",
    "two representations have been proposed : the collection of matrices and the k - partite graph @xcite . in the first",
    ", each matrix describes a view on the data . in the second ,",
    "a graph is said to be k - partite when the nodes are partitioned into @xmath7 subsets with the condition than no two nodes of the same subset are adjacent .",
    "thus in the k - partite graph paradigm @xcite , a given subset of nodes contains the instances of one type of objects , and a link between two nodes of different subsets represents the relation between these two nodes .    to explain our model we consider matrices to represent the data sets and we use a three - partite graph representation of the data matrices with three relations linking to explain our model .    from a functional point of view",
    ", the proposed ft - sim model can be represented in the following way as shown in figure [ fig:1 ] , where @xmath8 and @xmath9 are two data matrices representing a corpus and describing the connection between documents / sentences and sentences / words , brought by the three - partite graph @xcite .",
    "after the generation of @xmath8 and @xmath9 matrices , we proceed to a fuzzification process .",
    "it converts crisp values to fuzzy ones .",
    "the conversion to fuzzy values is represented by the membership functions @xcite .",
    "they allow a graphical representation of a fuzzy set @xcite .",
    "there are various methods to assign membership values or the membership functions to fuzzy variables .",
    "we mention essentially the triangular and trapezoidal ones .",
    "the second form is the most suitable one for modeling fuzzy sentences @xmath0 documents and words @xmath0 sentences similarities .    for each document , we define a fuzzy membership function through a linear transformation between the lower bound value @xmath10 , a membership of @xmath11 , to the upper bound value @xmath12 , which is assigned a membership of @xmath13 .",
    "this function is used because smaller values linearly increase in membership to the larger values for a positive slope and opposite for a negative slope .",
    "the following formulas show the fuzzy linear membership functions for @xmath14 and @xmath15 . @xmath16_{ji } = \\left\\ { \\begin{array}{l l } 1 , & \\qquad \\qquad if~~sd_{ji}\\geq l_{i}\\\\    \\frac{sd_{ji}-u_{i}}{u_{i}-l_{i } } , & \\qquad \\qquad if~~l_{i } < sd_{ji}<u_{i } \\\\ 0 , & \\qquad \\qquad if~~sd_{ji } \\leq l_{i}\\\\   \\end{array } \\right . } \\ ] ]    and @xmath17_{kj } = \\left\\ { \\begin{array}{l l } 1 , & \\qquad \\qquad if~~ws_{kj}\\geq l_{i}\\\\    \\frac{ws_{kj}-u_{i}}{u_{i}-l_{i } } , & \\qquad \\qquad if ~~l_{i } < ws_{kj } < u_{i } \\\\ 0 , & \\qquad \\qquad if~~ws_{kj } \\leq l_{i}\\\\   \\end{array } \\right .   } \\ ] ]    before proceeding to fuzzy triadic computing , we must initialize documents @xmath0 documents , sentences @xmath0 sentences and words @xmath0 words fuzzy matrices with the identity ones denoted as @xmath18 , @xmath19 and @xmath20 .",
    "the similarity between the same documents ( resp . sentences and words ) have the value equal to 1 .",
    "all others values are initialized with zero .",
    "@xmath21 is as follows :    @xmath22_{lm}^{(t)}=~\\begin{blockarray}{cccc }    d_1   & \\dots & d_m   \\\\",
    "\\begin{block}{[ccc]c }    1 & \\dots   & \\mu_{1m}^{(t ) } & ~d_{1 }   \\\\",
    "\\vdots & \\ddots & \\vdots &       \\\\",
    "\\mu_{l1}^{(t ) } & \\dots   & 1 & ~d_{l }   \\\\    \\end{block } \\end{blockarray } } \\ ] ]    where @xmath23 @xmath24 , @xmath25 is the membership degree of the @xmath26 document according the @xmath27 one .",
    "similarly , we determine the @xmath28 and @xmath29 .",
    "after initializing @xmath21 , we calculate the new matrix @xmath21 which represents fuzzy similarities between documents while using @xmath30 and @xmath31 .",
    "usually , the similarity measure between two documents @xmath32 and @xmath33 is defined as a function that is the sum of the similarities between shared sentences .",
    "our idea is to generalize this function in order to take into account the intersection between all the possible pairs of sentences occurring in documents @xmath32 and @xmath33 . in this way , not only",
    "can we capture the fuzzy similarity of their common sentences but also the fuzzy ones coming from sentences that are not directly common in the documents but are shared with some other documents.for each pair of sentences not directly shared by the documents , we need to take into account the fuzzy similarity between them as provided by @xmath30 .",
    "since we work with fuzzy matrices formed by membership degrees , we should certainly be applied in accordance with the operators for fuzzy sets , especially the intersection and union .",
    "thus , @xmath34 , except the case @xmath35 , can be formulated as follows : @xmath36    as we have shown for @xmath21 computing , we generalize fuzzy similarities in order to take into account the intersection between all the possible pairs of words occurring in sentences @xmath37 and @xmath38 . in this way , not only",
    "do we capture the fuzzy similarity of their common words but also the fuzzy ones coming from words that are not directly common in the sentences but are shared with some other sentences .",
    "for each pair of words not directly shared by the sentences , we need to take into account the fuzzy similarity between them as provided by @xmath39 .",
    "the overall fuzzy similarity between documents @xmath37 and @xmath38 is defined in the following equation : @xmath40    similarly , for each pair of words not directly shared by the sentences , we need to take into account the fuzzy similarity between them as provided by @xmath41 . the overall fuzzy similarity between documents @xmath42 and @xmath43",
    "is defined in the following equation : @xmath36",
    "for multi - source or large data sets , we propose different parallel architectures in which each ft - sim is the basic component or site we will use to deal with multiple matrices .",
    "thus , we consider a model in which the data sets are composed of @xmath1 relation matrices @xmath44 and @xmath45 @xmath4 .",
    "they describe the connections between documents for each local data set .",
    "our goal is then to compute a fuzzy matrix @xmath2 for each data set trying to take into account all the information expressed in the relations .    to combine multiple occurrences of ft - sim",
    ", we can adopt three different architectures : a sequential , a merging or a splitting based one .      in this first model",
    ", an instance of @xmath46 is associated to each local site @xmath3 .",
    "each site is represented by the relation matrice corresponding to the similarity between sentences / documents @xmath44 and words / sentences @xmath45 for @xmath47 . @xmath1 being the number of data sources .",
    "this instance is denoted @xmath46 .",
    "figure [ fig:2 ] shows the sequential - based parallel architecture .",
    "as shown in figure [ fig:2 ] , we assume a link between each @xmath46 and the following one",
    ". then it computes the similarity matrices from the data matrices of the first data set @xmath48 and @xmath49 , and uses the resulting document similarity matrix to initialize the next site .",
    "the document similarity issue of the @xmath50 data - set @xmath51 is used to initialize the next document similarity denoted by @xmath52 ( the second document similarity matrice at iteration @xmath11 ) . the initialization function presented in algorithm 1",
    "is then run with a second @xmath53 and @xmath54 matrices etc .",
    "the natural question that arises is : how to initialise @xmath55 with @xmath56 ?    in the beginning , @xmath55 must contain all documents existing in the @xmath57 and the @xmath58 data sets .",
    "they are initialized as an identity matrix denoted by @xmath59 .",
    "after that , the obtained @xmath55 is updated with the similarities in @xmath60 .",
    "the different steps for the sequential - based parallel process are presented in algorithme 2 .",
    "each @xmath46 is connected to the inputs of the following one which creates a chain . in that way",
    ", the instances are sequentially run in a static or dynamic order and the similarity matrices @xmath60 are progressively updated .",
    "the problem with this model is that the order matters .",
    "how do we choose the order of the matrices ?",
    "how many iterations do we perform for each local @xmath46 ?",
    "thus , without any prior knowledge about the relative interest of the relation matrices and the number of iterations for each local computing , this model seems difficult to optimize .      in the second model",
    ", we propose to compute the similarity matrices from several sites and merge them before performing the co - clustering algorithm on it .",
    "figure [ fig:3 ] shows the merging - based parallel architecture .        in this topology ,",
    "all local @xmath46 instances @xmath47 are run in parallel , then the similarity matrices @xmath60 are simultaneously updated with an aggregation function .",
    "this policy offers the benefit that all the instances of @xmath46 have the same influence .",
    "the aggregation function takes @xmath1 matrices @xmath61 , @xmath62, .. ,@xmath63 issue from each data source @xmath3 for a given iteration @xmath64 .",
    "two rules are adopted :    _ rule 1 : _ if a given document does not appear in a single site then we assign its corresponding similarity measures directly in @xmath65 .",
    "_ rule 2 : _ if a particular document appears in several different sites , we assign the minimum of all similarity measures relevant to this document to @xmath65 without taking into account the value of 0 .    the different steps of aggregation computing are presented in algorithm 3 .",
    "so , for a given iteration @xmath64 , each instance @xmath46 produces its own similarity matrix @xmath66 .",
    "we thus get a set of output similarity matrices @xmath67 , @xmath68, .. ,@xmath69 the cardinal of which being equal to the number of data - sets related to @xmath1 .",
    "therefore , we use the aggregation function denoted by @xmath70 and developed in the merging based function to compute a consensus similarity matrix merging all of the @xmath67 , @xmath62, .. ,@xmath71 with the current matrix @xmath72 .    in turn , this resulting consensus matrix is connected to the inputs of all the @xmath46 instances , to be taken into account in the @xmath73 iteration , thus creating feedback loops allowing the system to spread the knowledge provided by each @xmath66 within the network .",
    "the different steps for the merging - based parallel process are presented in algorithme 4 .    the complexity of this architecture is obviously related to that of the @xmath46 algorithm . in the parallel merging - based architecture , as each instance of @xmath46 can run on an independent core , the method can easily be parallelized , thus keeping the global complexity unchanged ( considering the number of iterations as a constant factor ) .",
    "so , the complexity of the merging function can be ignored .      in this section",
    "we present a generated model that can use previous architectures to efficiently compute ft - sim on large data sets by splitting a data matrix into smaller ones .",
    "figure [ fig:4 ] shows the splitting - based parallel architecture .        in order to reduce the complexity of a problem of treating huge data sets , it is possible to split a given data matrix into a collection of smaller ones , each sub - matrix becoming a component of our network and processed as a separate view .",
    "we have to evaluate the splitting approaches with the aim of finding the one most suitable with our solution . here , our goal is to cluster the documents and to explore the behavior of the proposed architecture when varying the number of @xmath74 splits , obtaining @xmath74 sub - matrices . then we adopt a random split sentence method . for each @xmath75 matrix ,",
    "the sentences are divided into @xmath74 sub - sets thereby forming @xmath74 sub - matrices @xmath75 .",
    "so , the number of @xmath46 instances in the proposed network is equal to the number of splits @xmath74 .",
    "for example , let us consider a problem with one [ documents / sentences ] matrix of size @xmath76 by @xmath77 in which we just want to cluster the documents .",
    "we can divide the problem into a collection of @xmath78 matrices of size @xmath79 by @xmath80 .",
    "thus , by using a distributed version of @xmath46 on @xmath78 cores , we will gain both in time and space complexity .    by splitting a matrix",
    ", we lost some information .",
    "the solution does not compute the co - similarities between all pairs of sentences but only between the words occurring in each @xmath44 .",
    "thanks to the feedback loops of this architecture and to the presence of the common similarity matrix @xmath65 , we will be able to spread the information through the network and alleviate the problem of inter - matrice comparisons .",
    "thus , by using a parallel version of @xmath46 on @xmath74 cores , we will gain both in time and space complexity : indeed , the time complexity decreases , leading to an overall gain of @xmath81 @xcite . in the same way , the memory needed to store the similarity matrices between words will decrease by a @xmath82 factor .",
    "in this paper , a fuzzy triadic similarity model , called ft - sim , for the co - clustering task has been proposed .",
    "it takes , iteratively , into account three abstraction computing levels document @xmath0 sentences @xmath0 words .",
    "the sentences consisting of one or more words are used to designate the fuzzy similarity of two documents .",
    "we are able to cluster together documents that have similar concepts based on their shared ( or similar ) sentences and in the same way to cluster together sentences based on words .",
    "this also allows us to use any classical clustering algorithm such as fuzzy - c - means ( fcm ) @xcite or other fuzzy partitioned - based clustering approaches @xcite .",
    "our proposition has been extended to suit with multi - view models . because the domain of text clustering focuses on documents and their similarities , in our proposition we spread informations about document similarities .",
    "we have presented three parallel architectures that combine ft - sim instances to compute similarities from different sources .",
    "1 f.  hussain , _ x - sim : a new cosimilarity measure : application to text mining and bioinformatics _ , phd thesis , 2010 .",
    "h.  chim and x.  deng , _ efficient phrase - based document similarity for clustering _ , knowledge and data engineering , ieee transactions , vol . 20 ,",
    "1217 - 1229 , 2008 . g.  salton and c.  buckley , _ term - weighing approaches in automatic text retrieval _ , in information processing and management , vol .",
    "513 - 523 , 1988 .",
    "s.  kundu , _ min - transitivity of fuzzy leftness relationship and its application to decision making _ , fuzzy sets and systems , vol .",
    "357 - 367 , 1997 .",
    "fuzzy sets _ , information and control 8 , pp .",
    "338 - 353 , 1965 .",
    "w.  tang and z.  lu and i.s .",
    "dhillon , _ clustering with multiple graphs _ , proceedings of the @xmath83 ieee international conference on data mining , pp .",
    "1016 - 1021 , 2009 . f.  de carvalho and y.  lechevallier and f.m .",
    "de melo , _ partitioning hard clustering algorithms based on multiple dissimilarity matrices _ , pattern recognition 45 , pp .",
    "447 - 464 , 2012 .",
    "g.  bisson and c.  grimal , _ co - clustering of multi - view datasets : a parallelizable approach _ , ieee international conference on data mining , pp .",
    "828 - 833 , 2012 .",
    "i.  drost and s.  bickel and t.  scheer , _ discovering communities in linked data by multi - view clustering _ ,",
    "proceedings of the @xmath84 annual conference of the german classication society , studies in classication , data analysis , and knowledge organization , pp . 342 - 349 , 2005 .",
    "a.  kumar and h.  daume , _ a co - training approach for multi - view spectral clustering _ , proceedings of the @xmath85 international conference on machine learning , pp . 393 - 400 , 2011 .",
    "h.  chim and x.  deng , _ efficient phrase - based document similarity for clustering _ , knowledge and data engineering , ieee transactions , vol .",
    "1217 - 1229 , 2008 .",
    "torres - moreno and p.velzquez-morales and j .- g .",
    "meunier , _ cortex : un algorithme pour la condensation automatique de textes _ , colloque interdisciplinaire en sciences cognitives , 2001 .",
    "m.  sven and l.  jorg and n.  hermann , _",
    "algorithms for bigram and trigram word clustering _ , speech communication , vol .",
    "19 - 37 , 1998 .",
    "b.  long and x.  wu and z.m .",
    "zhang and s.y .",
    "philip , _ unsupervised learning on k - partite graphs _ , proceedings of the @xmath86 acm sigkdd international conference on knowledge discovery and data mining , pp .",
    "317 - 326 , 2006 .",
    "s.  alouane , m.  sassi hidri and k.  barkaoui , _ fuzzy triadic similarity for text categorization : towards parallel computing _ , international conference on web and information technologies , pp .",
    "265 - 274 , 2013 .",
    "g.  bisson and c.  grimal , _ an architecture to efficiently learn co - similarities from multi - view datasets _ , international conference on neural information processing , pp .",
    "184 - 193 , 2012 .",
    "bezdek , _ fcm : the fuzzy c - means clustering algorithm _ , computers et geosciences , vol . 10(2 - 3 ) , pp .",
    "191 - 203 , 1984 .",
    "macqueen , _ some methods for classification and analysis of multivariate observation _ , proceedings of the @xmath87 berkeley symposium on mathematical statistics and probability , pp .",
    "281 - 297 , 1967 ."
  ],
  "abstract_text": [
    "<S> in a context of document co - clustering , we define a new similarity measure which iteratively computes similarity while combining fuzzy sets in a three - partite graph . </S>",
    "<S> the fuzzy triadic similarity ( ft - sim ) model can deal with uncertainty offers by the fuzzy sets . </S>",
    "<S> moreover , with the development of the web and the high availability of storage spaces , more and more documents become accessible . </S>",
    "<S> documents can be provided from multiple sites and make similarity computation an expensive processing . </S>",
    "<S> this problem motivated us to use parallel computing . in this paper , we introduce parallel architectures which are able to treat large and multi - source data sets by a sequential , a merging or a splitting - based process . </S>",
    "<S> then , we proceed to a local and a central ( or global ) computing using the basic ft - sim measure . </S>",
    "<S> the idea behind these architectures is to reduce both time and space complexities thanks to parallel computation .    </S>",
    "<S> keywords : document co - clustering , three - partite graph , fuzzy sets , parallel computing . </S>"
  ]
}