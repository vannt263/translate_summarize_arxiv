{
  "article_text": [
    "regularization of inverse problems in banach spaces is a field of highly active research , cf . ,",
    "e.g. , @xcite for variational regularization and , e.g. , @xcite , for iterative methods .",
    "the main reason for this lies in the fact that extension of the scope from hilbert to general banach spaces better allows to formulate requirements on the searched for solution and to describe realistic noise models .",
    "we will here especially concentrate on a combination of a newton - type strategy with landweber iterations to approximate the newton step , which leads to a fully explicit iteration , cf .",
    "@xcite .    to formulate the method ,",
    "consider a nonlinear ill - posed operator equation @xmath0 where @xmath1 maps between banach spaces @xmath2 and @xmath3 .",
    "the given data @xmath4 are typically contaminated by noise , and we are going to assume that the noise level @xmath5 in @xmath6 is known . in the following , @xmath7 is some initial guess and we will assume that a solution @xmath8 to exists . for some @xmath9 , we will make use of the duality mappings @xmath10 from @xmath2 to its dual @xmath11 , and @xmath12 from @xmath3 to @xmath13 , respectively . while under the assumptions we will make on @xmath2 , the mapping @xmath14 will in fact be single valued",
    ", this will not necessarily be the case for @xmath15 and we will denote by @xmath16 a single valued selection from @xmath15 .",
    "therewith , we consider a combination of the iteratively regularized gau - newton method with an iteratively regularized landweber method for approximating the newton step , using some initial guess @xmath7 and starting from some @xmath17 ( that need not necessarily coincide with @xmath7 ) @xmath18    it is clear that the choice of the parameters @xmath19 , @xmath20 , @xmath21 , and of the overall stopping index @xmath22 crucially influences the stability and efficiency of the method . while in @xcite",
    ", @xcite only either convergence or convergence rates have been established with disjoint parameter choices for each of these two cases , the aim of this paper is to provide a unified parameter choice strategy for this method that allows to show both unconditional convergence and convergence rates under additional regularity assumptions on the solution .",
    "moreover , by using an appropriate choice of the stopping index for the inner iteration , differently from @xcite , @xcite we can show continuous dependence of the iterates @xmath23 on the data @xmath4 for each fixed outer iteration index @xmath24 and therewith are able to prove strong convergence .",
    "finally , the new parameter choice appears to enhance efficiency as compared to @xcite , as the numerical tests below show .",
    "the remainder of this paper is organized as follows . in section",
    "[ sec : prelim ] we provide some preliminaries .",
    "the parameter choice as well as convergence results are derived and formulated in section [ sec : conv_an ] .",
    "section [ sec : numres ] shows some numerical tests for a coefficient identification problem in an elliptic pde in one and two space dimensions .",
    "throughout this paper we will assume that @xmath2 is smooth , which means that the duality mapping is single - valued , and moreover , that @xmath2 is @xmath25-convex for some @xmath26 , which implies @xmath27 for some constant @xmath28 , cf .",
    "corollary 2.61 in @xcite . here",
    ", @xmath29 denotes the bregman distance @xmath30 ( where @xmath31 denotes a single valued selection of @xmath32 ) .",
    "we will also make use of its shifted version @xmath33 as a consequence of the above assumptions , @xmath2 is reflexive and we also have @xmath34 for some @xmath35 , where @xmath36 denotes the dual index @xmath37 , cf .",
    "( 4 ) in @xcite . under these assumptions ,",
    "the duality mapping is bijective and @xmath38 , the latter denoting the ( by @xmath25-convexity also single - valued ) duality mapping on the dual @xmath11 of @xmath2 .",
    "we will also make use of the identities @xmath39 and @xmath40 for more details on the geometry of banach spaces we refer , e.g. , to @xcite , @xcite and the references therein .",
    "the assumptions on the forward operator besides a condition on the domain @xmath41 include a structural condition on its degree of nonlinearity .",
    "for simplicity of exposition we restrict ourselves to the tangential cone condition @xmath42 and mention in passing that this could be extended to a more general condition on the degree of nonlinearity ( cf .",
    "@xcite ) as in @xcite . here",
    "@xmath43 is not necessarily the frchet derivative of @xmath1 but just a linearization of @xmath1 satisfying the taylor remainder estimate .",
    "additionally , we assume that @xmath43 and @xmath1 are uniformly bounded on @xmath44 .",
    "here @xmath45 with @xmath46 such that @xmath47 . by distinction between the cases",
    "@xmath48 and @xmath49 and the second triangle inequality we obtain from that @xmath50 with @xmath51    for obtaining convergence rates we impose a variational inequality ( or variational source condition ) @xmath52 with with @xmath53 the parameter of smoothness of @xmath2 , @xmath54 and @xmath55 $ ]",
    ". condition corresponds to a source condition @xmath56 in the special case of hilbert spaces ( where @xmath57 ) , cf .",
    ", e.g. , @xcite .",
    "note that is stronger for larger @xmath58 and always holds for @xmath59 with @xmath60 due to , .",
    "the case @xmath59 can be identified with the situation that no additional regularity ( i.e. , with @xmath61 ) is known to hold .",
    "we here first of all follow the lines of section 2 in @xcite .",
    "some of the estimates are the same as in @xcite ( and will be repeated here only for convenience of the reader ) .",
    "some of them are different , though and therewith enable different parameter choice strategies .    for any @xmath62",
    "we have @xmath63 where we abbreviate @xmath64    assuming that @xmath65 , we now estimate each of the terms on the right hand side separately .    by and we have for the term ( i ) @xmath66 where we have used the triangle inequality in @xmath67 and @xmath2 , the inequality @xmath68 and , as well as the abbreviations @xmath69 here @xmath70 which by @xmath71 defines a strictly monotonically increasing and convex function on @xmath72 .",
    "note that estimate is just the same as ( 15 ) in @xcite .    for the term ( ii ) in we",
    "get , using , , @xmath73 this is the same as ( 19 ) in @xcite .    to make use of the variational inequality for estimating ( iii ) , we first of all use to conclude @xmath74 hence @xmath75 this together with implies @xmath76 where we have used the elementary estimate @xmath77 with @xmath78 and @xmath79 as in . note that differs from the corresponding estimate ( 24 ) in @xcite .",
    "finally , for the term ( iv ) we have that @xmath80 which is just ( 26 ) in @xcite .",
    "altogether we arrive at the estimate @xmath81 where @xmath82 ( small @xmath83 denoting constants that can be made small by assuming @xmath7 to be sufficiently close to @xmath8 and therewith @xmath84 , @xmath85 , @xmath86 small ) , and @xmath79 as in . multiplying with @xmath87 and abbreviating @xmath88 we get @xmath89    to obtain monotone decay of the sequence @xmath90 with increasing @xmath91 we choose    * @xmath92 such that @xmath93 for some @xmath94 , @xmath95 .",
    "we will do so by setting @xmath96 with @xmath97 sufficiently small , cf .",
    "@xcite , and assuming that @xmath98 * @xmath99 such that @xmath100 and @xmath101 the latter can be achieved by @xmath102 in case @xmath61 we additionally require @xmath103 with an upper bound @xmath104 for @xmath105 .",
    "note that this just means @xmath106 in case @xmath59 , i.e. , @xmath107 , thus an empty condition in this case . to meet conditions , with a minimal @xmath108 we set @xmath109",
    "it remains to choose    * the inner stopping index @xmath21 and * the outer stopping index @xmath110 ,    see below .",
    "+ indeed with these choices of @xmath20 and @xmath108 we can inductively conclude from that @xmath111 this monotonicity result holds for all @xmath62 and for all @xmath112 .    by and @xmath113 ( cf . )",
    "it can be shown inductively that all iterates remain in @xmath44 provided @xmath114    moreover , implies that @xmath115 hence by @xmath116 , @xmath117 @xmath118 and @xmath119 especially , since @xmath120 , implies @xmath121 hence @xmath122 as @xmath123 .    to quantify the behavior as @xmath124 of the sequence @xmath19 according to , , for fixed @xmath24 we distinguish between two cases .",
    "+ * case ( i ) * : there exists a @xmath125 such that for all @xmath126 we have @xmath127 .",
    "considering an arbitrary accumulation point @xmath128 of @xmath19 ( which exists since @xmath129 ) we therefore have @xmath130 , hence @xmath131 . + * case ( ii ) * : consider the situation that ( i ) does not hold , i.e. , there exists a subsequence @xmath132 such that for all @xmath133 we have @xmath134 .",
    "then by , , and we have @xmath135 .",
    "+ altogether we have shown that @xmath136 since @xmath85 and @xmath5 can be assumed to be sufficiently small , this especially implies the bound @xmath137 in .",
    "we consider @xmath138 as our regularized solution , where @xmath110 , @xmath139 ( and also @xmath21 for all @xmath140 ; note that @xmath139 is to be distinguished from @xmath141 - actually the latter is not defined , since we only define @xmath21 for @xmath140 ! ) are still to be chosen appropriately , according to the requirements from the proofs of    * convergence rates in case @xmath142 , * convergence for exact data @xmath143 , * convergence for noisy data as @xmath144 .      from",
    "we get @xmath145 hence in order to get the desired rate @xmath146 in view of ( which is a sharp bound in case ( ii ) above ) we need to have a bound @xmath147 for some constant @xmath148 , and we should choose @xmath139 large enough so that @xmath149 which is possible with a finite @xmath139 by for @xmath150 . note that this holds without any requirements on @xmath21 for @xmath151 .      to show that @xmath152 is a cauchy sequence ( following the seminal paper @xcite ) , for arbitrary @xmath153",
    ", we choose the index @xmath154 such that @xmath155 is minimal and use the identity @xmath156 and the fact that the monotone decrease and boundedness from below of the sequence @xmath157 implies its convergence , hence it suffices to prove that the last term in tends to zero as @xmath158 .",
    "( analogously it can be shown that @xmath159 tends to zero as @xmath160 ) .",
    "this term can be rewritten as @xmath161 where @xmath162 by our choice of @xmath163 ( note that @xmath164 in case @xmath107 ) , condition and and minimality of @xmath155 .",
    "thus we have by @xmath165 and young s inequality that there exists @xmath166 such that @xmath167 for which we can conclude convergence as @xmath168 from provided that @xmath169 which we guarantee by choosing , for an a priori fixed summable sequence @xmath170 , e.g. @xmath171 @xmath172 \\,,\\ ] ] or , using just @xmath173 for some fixed integer @xmath174 , e.g. , @xmath175 .",
    "this is consistent with , since in case @xmath143 we have @xmath176 , so condition never gets active in the noiseless case .      in case @xmath142 , convergence follows from the convergence rates results in subsection [ subsec : rates ] .",
    "therefore it only remains to show convergence as @xmath144 in case @xmath177 .    in this section",
    "we explicitly emphasize dependence of the computed quantities on the noisy data and on the noise level by a superscript @xmath5 .",
    "let @xmath178 with @xmath179 a zero sequence and @xmath180 the corresponding stopping index .",
    "as usual @xcite we distinguish between the two cases that ( i ) @xmath180 has a finite accumulation point and ( ii ) @xmath180 tends to infinity .",
    "+ * case ( i ) * : there exists an @xmath181 and a subsequence @xmath182 such that for all @xmath183 we have @xmath184 .",
    "provided @xmath185 we can conclude that @xmath186 as @xmath187 , and by taking the limit as @xmath187 also in , @xmath188 is a solution to .",
    "thus we may set @xmath189 in ( with @xmath107 ) to obtain @xmath190 where we have again used the continuous dependence in the last step .",
    "+ * case ( ii ) * : let @xmath191 as @xmath192 , and let @xmath8 be a solution to",
    ". for arbitrary @xmath193 , by convergence for @xmath143 ( see the previous subsection ) we can find @xmath24 such that @xmath194 and , by theorem 2.60 ( d ) in @xcite there exists @xmath195 such that for all @xmath196 we have @xmath197 and @xmath198 , provided @xmath199 hence , by monotonicity of the errors we have @xmath200    indeed , , can be concluded from continuity of @xmath1 , @xmath43 , the definition of the method , as well as stable dependence of all parameters @xmath20 , @xmath19 , @xmath21 according to , , , , on the data @xmath4 .",
    "altogether we have derived the following algorithm .",
    "[ algonirlw ] ( newton  iteratively regularized landweber method )",
    "@xmath201 here we use the abbreviations according to , , , , .",
    "the analysis above yields the following convergence result .",
    "[ teo ] assume that @xmath2 is smooth and @xmath25-convex with @xmath202 , that @xmath7 is sufficiently close to @xmath8 , i.e. , @xmath203 , that @xmath1 satisfies with , that @xmath1 and @xmath43 are continuous and uniformly bounded in @xmath44 , and that , hold .",
    "+ then , the iterates @xmath204 defined by algorithm [ algonirlw ] remain in @xmath44 and converge to a solution @xmath8 of subsequentially as @xmath144 ( i.e. , there exists a convergent subsequence and the limit of every convergent subsequence is a solution ) . in case of exact data @xmath143 , we have subsequential convergence of @xmath23 to a solution of as @xmath123 .",
    "if additionally a variational inequality with @xmath205 $ ] and @xmath84 sufficiently small is satisfied , we obtain optimal convergence rates @xmath206    note that we here deal with an a priori parameter choice : @xmath207 and therefore @xmath58 has to be known , otherwise @xmath58 must be set to a lower bound @xmath208 for the true @xmath58 and since @xmath209 implies validity of with @xmath58 replaced by @xmath208 , theorem [ teo ] still implies the ( possibly suboptimal ) rates @xmath210 , or just convergence if we have set @xmath211 .",
    "in this section we present some numerical experiments to test the method defined in section [ sec : conv_an ] .",
    "we consider the identification of the space - dependent coefficient @xmath83 in the elliptic boundary value problem @xmath212 from the measurement of @xmath213 in @xmath214 , where @xmath215 is a fixed function and where @xmath214 is assumed to be a smooth , bounded domain in @xmath216 , @xmath217 @xmath218 @xmath219 .",
    "note that inhomogeneous dirichlet boundary conditions can be easily incorporated into the right - hand side @xmath215 if necessary .",
    "+ we consider three examples with @xmath220 and an example with @xmath221 . in all cases",
    ", we take @xmath222 , @xmath223 , @xmath224 , @xmath225 and recall that the following facts hold true .    * for @xmath223 , the duality mapping in @xmath2 is given by @xmath226 .",
    "* if the domain of the forward operator is defined by @xmath227 the condition is satisfied with @xmath228 .",
    "* there follows from lemma @xmath229 in @xcite that the operator @xmath230 , @xmath231 is well defined . here",
    "@xmath232 is given by @xmath233 .",
    "moreover , @xmath234 and the adjoint of @xmath234 @xmath235 are well defined and bounded .    in all the numerical simulations ,",
    "we take @xmath107 and stop the outer iteration by means of the discrepancy principle .",
    "concerning the stopping index of the inner iteration , we slightly modify algorithm 1 , requiring also that if @xmath236 then the iteration has to be stopped .",
    "more precisely , @xmath237 and the regularized solution is @xmath238 .",
    "we consider the same numerical simulations as in @xcite , taking @xmath239 and inhomogeneous boundary conditions @xmath240 , @xmath241 .",
    "we solve all differential equations approximately by a finite difference method by dividing the interval @xmath242 $ ] into @xmath243 subintervals with equal length @xmath244 , in all examples below @xmath245 . the @xmath246 and @xmath247 norms are calculated approximately by means of a quadrature method .",
    "[ doublepeak ] in the first simulation we assume that the solution is sparse : @xmath248 the test problem is constructed by taking @xmath249 , @xmath250 , @xmath251 and @xmath252 .",
    "we perturb the exact data @xmath213 with gaussian white noise : the corresponding perturbed data @xmath253 satisfies @xmath254 , with @xmath255 . + we apply algorithm 1 , with the inner stopping index satisfying , with @xmath256 , @xmath257 , @xmath258 .",
    "the upper bound @xmath259 is fixed equal to @xmath260 and @xmath97 is chosen as @xmath261 , where @xmath262 is the first index that satisfies @xmath263    in figure [ figure1 ] we show the results obtained by our method with @xmath264 and @xmath265 respectively .",
    "the reconstructed solutions are very similar to those obtained in @xcite and @xcite .",
    "concerning the total number of inner iterations @xmath266 similarly to @xcite , it is larger in the case @xmath264 ( @xmath267 ) than in the case @xmath265 ( @xmath268 ) . in both cases ,",
    "the value of @xmath269 is lower than the corresponding value found in @xcite .",
    "we underline that it is possible to make different choices for @xmath270 , @xmath259 , @xmath271 to look for further improvements of the speed of the method .",
    "the partial freedom in the choices of these parameters makes algorithm 1 more flexible than the method described in @xcite . in our numerical simulations , we tested different choices which gave similar but slightly worse results than those stated here .",
    "[ triplepeak ] we modify the exact solution of the previous example into : @xmath272 and choose again @xmath255 . in this case , we take @xmath256 , @xmath273 , @xmath274 , @xmath275 and @xmath97 as in the previous example .    in figure [ figure2 ]",
    "we show the results obtained by our method with @xmath264 and @xmath265 respectively . as usual , the reconstruction of the sparsity is much better for @xmath265 . concerning the total number of inner iteration @xmath269 , in this case we obtain @xmath276 ( with a corresponding error of @xmath277 ) and @xmath278 ( with a corresponding error of @xmath279 ) .",
    "we observe that although the corresponding error is slightly larger than that obtained in @xcite , the value of @xmath280 is slightly more than a fifth than the value obtained in @xcite , with a gain in the speed of the @xmath281 .",
    "moreover , in the case @xmath265 algorithm 1 performs @xmath282 iterations less than in @xcite , with a gain in the speed of the @xmath283 , and obtains even a lower error .",
    "[ outliers ] we consider an example with noisy data where a few data points called outliers are remarkably different from other data points .",
    "this situation may arise from procedural measurement errors .",
    "+ we suppose @xmath284 to be a smooth solution @xmath285 and take @xmath286 , @xmath287 , @xmath288 and @xmath289 as exact data of the problem .",
    "we start the iteration from the initial guess @xmath290 , and take @xmath291 , @xmath292 , @xmath293 and @xmath97 as in the previous example . using the same matlab seed for generating random data , we consider the same perturbed data as in @xcite , example 3 , case @xmath294 ( cf .",
    "figure [ figure3 ] here and figure 3 , picture ( d ) in that paper ) .",
    "+ we run both algorithm @xmath295 with @xmath296 and the algorithm that generated the results presented in @xcite for this example with @xmath264 and @xmath297 and @xmath298 do not satisfy the condition of theorem [ teo ] .",
    "however , this condition is needed only to have a lower bound for @xmath20 and such a bound is verified experimentally in this example for these values of @xmath299 and @xmath298 . ] .",
    "pictures ( b ) and ( d ) from figure [ figure3 ] show the corresponding results .",
    "the solution obtained by algorithm 1 is slightly more precise , with an error equal to @xmath300 for algorithm 1 and equal to @xmath301 for the method in @xcite .",
    "the most interesting fact is that algorithm @xmath295 computes only @xmath302 total inner iterations to obtain this solution , whereas for the method in @xcite @xmath303 and the reconstruction is poorer .",
    "moreover , due to the flexibility of our method , we can simply change the value of @xmath304 into @xmath305 to get a more precise solution ( see picture ( c ) in figure [ figure3 ] ) .",
    "a visual inspection gives an idea of the improvement : the error of this solution , obtained with @xmath306 total inner iterations , is equal to @xmath307 .",
    "+ we summarize the numerical results of the 1-dimensional examples in table @xmath308 .",
    "+ method & total n. of inner iterations & error : @xmath309 + alg .",
    "1 @xmath265 & 3063 & 0.0413 + alg . 1 @xmath310 & 3992 & 0.1059 +   + method & total n. of inner iterations & error : @xmath309 + alg",
    ". 1 @xmath265 & 3110 & 0.0482 + alg",
    ". 1 @xmath310 & 4141 & 0.1110 +   + method & total n. of inner iterations & error : @xmath309 + alg . 1 @xmath311 & 249 & 0.1885 + alg . 1 @xmath312 & 278 & 0.1161 + method from @xcite & 3285 & 0.2939 +      we show the performance of algorithm 1 in the following 2-dimensional example .",
    "+ let @xmath313 and assume the exact solution to be @xmath314 ^ 2}(x , y ) , \\text { } \\text { } \\text { } x , y \\in \\omega,\\ ] ] where the function @xmath315 is the characteristic function on a subset of @xmath316 .",
    "we take as exact data @xmath317 : as a consequence , the fixed right hand side of the problem is @xmath318 and the data at the boundary are given by @xmath319 for every @xmath320 @xmath218 @xmath321 @xmath214 .",
    "we discretize the interval @xmath242_x$ ] into @xmath243 subintervals and the interval @xmath242_y$ ] into @xmath322 subintervals and compute the solutions of the forward operator @xmath323 by a finite difference method .",
    "the @xmath246 and @xmath247 norms in @xmath214 are calculated by a simple quadrature method .",
    "+ we fix @xmath265 , @xmath324 , @xmath312 , @xmath325 , @xmath275 and @xmath97 as in the 1-dimensional examples .",
    "we run algorithm 1 starting from @xmath228 with the data @xmath253 perturbed by white gaussian noise with two different noise levels . in the first case ,",
    "we choose a small value for @xmath326 with @xmath327 . in the second case",
    "we choose @xmath328 with @xmath327 and with @xmath329 .",
    "+    in figure [ figure4 ] we plot the exact solution and the reconstructions obtained using algorithm 1 in all these cases .",
    "the pictures show that the method provides a good reconstruction of the sparsity in this example .",
    "in particular , we underline that in the case @xmath328 the choice of a large @xmath299 improves the result , obtaining a better reconstruction with very few iterations ( the total number of iterations is equal to @xmath330 in this case ) .",
    "in this paper we have devised an alternative parameter choice strategy for the iteratively regularized newton- landweber iteration proposed in @xcite .",
    "this strategy is based on alternative error estimates and allows for a unified treatment of the unconditional convergence case and convergence with rates . in our future research",
    "we will try to extend the analysis to faster inner iterations than landweber such as steepest descent or conjugate gradient methods .",
    "support by the german science foundation dfg under grant ka 1778/5 - 1 is gratefully acknowledged .",
    "b.  kaltenbacher .",
    "convergence rates for the iteratively regularized landweber iteration in banach space .",
    "proceedings of the 25th ifip tc7 conference on system modeling and optimization , springer , 2013 , to appear .",
    "b.  kaltenbacher , f.  schpfer , and th .",
    "convergence of some iterative methods for the regularization of nonlinear ill - posed problems in banach spaces .",
    "_ inverse problems _ , 25 , 2009 .",
    "065003 doi : 10.1088/0266 - 5611/25/6/065003 .",
    "a.  neubauer , t.  hein , b.  hofmann , s.  kindermann , and u.  tautenhahn .",
    "improved and extended results for enhanced convergence rates of tikhonov regularization in banach spaces .",
    "_ , 89(11):17291743 , 2010 .",
    "t.  schuster , b.  kaltenbacher , b.  hofmann , and k.  kazimierski .",
    "_ regularization methods in banach spaces_. de gruyter , berlin , new york , 2012 .",
    "b . xu and g.  f. roach .",
    "characteristic inequalities of uniformly convex and uniformly smooth banach spaces . _ journal of mathematical analysis and applications _ ,",
    "* 157 * ( 1991 ) , 189210 ."
  ],
  "abstract_text": [
    "<S> this paper is a close follow - up of @xcite and @xcite , where newton - landweber iterations have been shown to converge either ( unconditionally ) without rates or ( under an additional regularity assumption ) with rates . </S>",
    "<S> the choice of the parameters in the method were different in each of these two cases . </S>",
    "<S> we now found a unified and more general strategy for choosing these parameters that enables both convergence and convergence rates . </S>",
    "<S> moreover , as opposed to the previous one , this choice yields strong convergence as the noise level tends to zero , also in the case of no additional regularity . </S>",
    "<S> additionally , the resulting method appears to be more efficient than the one from @xcite , as our numerical tests show .    </S>",
    "<S> barbara kaltenbacher    ivan tomba    ( communicated by the associate editor name ) </S>"
  ]
}