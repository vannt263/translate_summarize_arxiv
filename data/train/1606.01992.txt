{
  "article_text": [
    "we develop an active set algorithm for a general nonlinear polyhedral constrained optimization problem @xmath0 here @xmath1 is a real - valued , continuously differentiable function , @xmath2 , @xmath3 , and @xmath4 is assumed to be nonempty . in an earlier paper @xcite",
    ", we developed an active set algorithm for bound constrained optimization . in this paper , we develop new machinery for handling the more complex polyhedral constraints of ( [ p ] ) .",
    "our polyhedral active set algorithm ( pasa ) has two phases : phase one is the gradient projection algorithm , while phase two is any algorithm for solving a linearly constrained optimization problem over a face of the polyhedron @xmath4 .",
    "the gradient projection algorithm of phase one is robust in the sense that it converges to a stationary point under mild assumptions , but the convergence rate is often linear at best .",
    "when optimizing over a face of the polyhedron in phase two , we could accelerate the convergence through the use of a superlinearly convergent algorithm based on conjugate gradients , a quasi - newton update , or a newton iteration . in this paper , we give rules for switching between phases which ensure that asymptotically , only phase two is performed .",
    "hence , the asymptotic convergence rate of pasa coincides with the convergence rate of the scheme used to solve the linearly constrained problem of phase two . a separate paper will focus on a specific numerical implementation of pasa .",
    "we briefly survey some of the rich history of active set methods . some of the initial work focused on the use of the conjugate gradient method with bound constraints as in @xcite .",
    "work on gradient projection methods include @xcite .",
    "convergence is accelerated using newton and trust region methods @xcite .",
    "superlinear and quadratic convergence for nondegenerate problems can be found in @xcite , while analogous convergence results are given in @xcite , even for degenerate problems .",
    "the affine scaling interior point approach @xcite is related to the trust region algorithm .",
    "linear , superlinear , and quadratic convergence results have been established .",
    "recent developments on active set methods for quadratic programming problem can be found in @xcite .",
    "a treatment of active set methods in a rather general setting is given in @xcite .",
    "we also point out the recent work @xcite on a very efficient two - phase active set method for conic - constrained quadratic programming , and the earlier work @xcite on a two - phase active set method for quadratic programming . as in @xcite",
    "the first phase in both applications is the gradient projection method .",
    "the second phase is a newton method in @xcite , while it is a linear solver in @xcite .",
    "note that pasa applies to the general nonlinear objective in ( [ p ] ) .",
    "active set strategies were applied to @xmath5 minimization in @xcite and in @xcite they were applied to the minimization of a nonsmooth dual problem that arises when projecting a point onto a polyhedron . in @xcite , a nonmonotone line search based on  shrinkage \" is used to estimate a support at the solution , while a nonmonotone sparsa algorithm @xcite is used in @xcite to approximately identify active constraints .    unlike most active set methods in the literature , our algorithm is not guaranteed to identify the active constraints in a finite number of iterations due to the structure of the line search in the gradient projection phase . instead , we show that only the fast phase two algorithm is performed asymptotically , even when strict complementary slackness is violated",
    ". moreover , our line search only requires one projection in each iteration , while algorithms that identify active constraints often employ a piecewise projection scheme that may require additional projections when the stepsize increases .",
    "the paper is organized as follows .",
    "section  [ structure ] gives a detailed statement of the polyhedral active set algorithm , while section  [ global ] establishes its global convergence .",
    "section  [ stationarity ] gives some properties for the solution and multipliers associated with a euclidean projection onto @xmath4 .",
    "finally , section  [ nondegenerate ] shows that asymptotically pasa performs only phase two when converging to a nondegenerate stationary point , while section  [ degenerate ] establishes the analogous result for degenerate problems when the active constraint gradients are linearly independent and a strong second - order sufficient optimality condition holds",
    ".    * notation .",
    "* throughout the paper , @xmath6 denotes a generic nonnegative constant which has different values in different inequalities . for any set @xmath7 , @xmath8 stands for the number of elements ( cardinality ) of @xmath7 , while @xmath9 is the complement of @xmath7 .",
    "the set @xmath10 is defined by @xmath11 the distance between a set @xmath12 and a point @xmath13 is given by @xmath14 where @xmath15 is the euclidean norm .",
    "the subscript @xmath16 is often used to denote the iteration number in an algorithm , while @xmath17 stands for the @xmath18-th component of the iterate @xmath19 .",
    "the gradient @xmath20 is a row vector while @xmath21 is the gradient arranged as a column vector ; here @xmath22 denotes transpose .",
    "the gradient at the iterate @xmath19 is @xmath23 . in several theorems",
    ", we assume that @xmath1 is lipschitz continuously differentiable in a neighborhood of a stationary point @xmath24 .",
    "the lipschitz constant for @xmath25 is always denoted @xmath26 .",
    "we let @xmath27 denote the hessian of @xmath1 at @xmath28 .",
    "the ball with center @xmath28 and radius @xmath29 is denoted @xmath30 . for any matrix @xmath31",
    ", @xmath32 is the null space .",
    "if @xmath7 is a subset of the row indices of @xmath31 , then @xmath33 denotes the submatrix of @xmath31 with row indices @xmath7 . for any vector @xmath34 , @xmath35 is the subvector of @xmath34 with indices @xmath7 .",
    "@xmath36 denotes the euclidean projection of @xmath28 onto @xmath4 : @xmath37 for any @xmath38 , the active and free index sets are defined by @xmath39 respectively .",
    "as explained in the introduction , pasa uses the gradient projection algorithm in phase one and a linearly constrained optimization algorithm in phase two .",
    "algorithm  [ gpa ] is the gradient projection algorithm ( gpa ) used for the analysis in this paper . a cartoon of the algorithm appears in figure  [ gpa - fig ] .",
    "l + * * @xmath40 and @xmath41 , @xmath42 + while stopping condition does not hold + 1 .",
    "@xmath43 @xmath44 , @xmath45 @xmath46 + 2 .",
    "@xmath47 where @xmath48 is smallest integer such that + @xmath49 + 3 .",
    "@xmath50 and @xmath51 + end while +    ]    this is a simple monotone algorithm based on an armijo line search .",
    "better numerical performance is achieved with a more general nonmonotone line search such as that given in @xcite , and all the analysis directly extends to this more general framework ; however , to simplify the analysis and discussion in the paper , we utilize algorithm  [ gpa ] for the gpa .",
    "the requirements for the linearly constrained optimizer ( lco ) of phase two , which operates on the _ faces _ of @xmath4 , are now developed .",
    "one of the requirements is that when the active sets repeat in an infinite series of iterations , then the iterates must approach stationary . to formulate this requirement in a precise way , we define @xmath52 thus @xmath53 is the projection of the gradient @xmath54 onto the null space @xmath55 .",
    "we also let @xmath56 denote @xmath53 for @xmath57 . if @xmath58 is empty , then @xmath59 , while if @xmath28 is a vertex of @xmath4 , then @xmath60 .",
    "this suggests that @xmath61 represents a local measure of stationarity in the sense that it vanishes if and only if @xmath28 is a stationary point on its associated face @xmath62 the requirements for the phase two lco are the following :    * @xmath63 and @xmath64 for each @xmath16 .",
    "* @xmath65 for each @xmath16 . *",
    "if @xmath66 for @xmath67 , then @xmath68 .",
    "condition f1 requires that the iterates in phase two are monotone , in contrast to phase one where the iterates could be nonmonotone . by f2",
    "the active set only grows during phase two , while f3 implies that the local stationarity measure becomes small when the active set does not change .",
    "conditions f1 , f2 , and f3 are easily fulfilled by algorithms based on gradient or newton type iterations which employ a monotone line search and which add constraints to the active set whenever a new constraint becomes active .",
    "our decision for switching between phase one ( gpa ) and phase two ( lco ) is based on a comparison of two different measures of stationarity .",
    "one measure is the local stationarity measure @xmath69 , introduced already , which measures stationarity relative to a face of @xmath4 .",
    "the second measure of stationarity is a global metric in the sense that it vanishes at @xmath28 if and only if @xmath28 is a stationary point for the optimization problem ( [ p ] ) . for @xmath70 ,",
    "let @xmath71 be the point obtained by taking a step from @xmath28 along the negative gradient and projecting onto @xmath4 ; that is , @xmath72 the vector @xmath73 points from @xmath28 to the projection of @xmath74 onto @xmath4 . as seen in (",
    "2.1 ) , when @xmath75 , @xmath76 if and only if @xmath28 is a stationary point for ( [ p ] ) .",
    "we monitor convergence to a stationary point using the function @xmath77 defined by @xmath78 @xmath79 vanishes if and only if @xmath28 is a stationary point of ( [ p ] ) . if @xmath80 , then @xmath81 , the norm of the gradient , which is the usual way to assess convergence to a stationary point in unconstrained optimization .",
    "the rules for switching between phase one and phase two depend on the relative size of the stationarity measures @xmath77 and @xmath82 .",
    "we choose a parameter @xmath83 and branch from phase one to phase two when @xmath84 .",
    "similarly , we branch from phase two to phase one when @xmath85 . to ensure that only phase two is executed asymptotically at a degenerate stationary point",
    ", we may need to decrease @xmath86 as the iterates converge . the decision to decrease @xmath86",
    "is based on what we called the undecided index set @xmath87 which is defined as follows .",
    "let @xmath28 denote the current iterate , let @xmath79 be the global measure of stationarity , and let @xmath88 denote any lagrange multiplier associated with the polyhedral constraint in ( [ y - def ] ) and @xmath89 .",
    "that is , if @xmath90 is the solution of ( [ y - def ] ) for @xmath89 , then @xmath91 is any vector that satisfies the conditions @xmath92 given parameters @xmath93 and @xmath94 , the undecided index set is defined by @xmath95 if @xmath28 is close enough to a stationary point that @xmath79 is small , then the indices in @xmath96 correspond to those constraints for which the associated multiplier @xmath97 is relatively large in the sense that @xmath98 , and the @xmath18-th constraint is relatively inactive in the sense that @xmath99 . by the first - order optimality conditions at a local minimizer , large multipliers are associated with active constraints . hence , when the multiplier is relatively large and the constraint is relatively inactive , we consider the constraint undecided .",
    "when @xmath96 is empty , then we feel that the active constraints are nearly identified , so we decrease @xmath86 in phase one so that phase two will compute a more accurate local stationary point before branching back to phase one .",
    "algorithm  [ pasa ] is the polyhedral active set algorithm ( pasa ) .",
    "the parameter @xmath100 is the convergence tolerance , the parameter @xmath86 controls the branching between phase one and phase two , while the parameter @xmath101 controls the decay of @xmath86 when the undecided index set is empty .",
    "l + * * @xmath102 , @xmath86 and @xmath103 + @xmath104 , @xmath105 + * * while @xmath106 execute gpa + if @xmath107 and @xmath85 , then @xmath108 .",
    "+ if @xmath84 , goto phase two .",
    "+ end while + * * while @xmath106 execute lco + if @xmath85 , goto phase one .",
    "+ end while +",
    "since algorithm  [ gpa ] , gpa , is a special case of the nonmonotone gradient projection algorithm studied in @xcite , our previously established global convergence result , stated below , holds .",
    "[ gpa - theorem ] let @xmath109 be the level set defined by @xmath110 assume the following conditions hold :    * @xmath1 is bounded from below on @xmath109 and @xmath111 . *",
    "if @xmath112 is the collection of @xmath113 whose distance to @xmath109 is at most @xmath114 , then @xmath25 is lipschitz continuous on @xmath112 .",
    "then gpa with @xmath115 either terminates in a finite number of iterations at a stationary point , or we have @xmath116    the global convergence of pasa essentially follows from the global convergence of gpa and the requirement f3 for the linearly constrained optimizer .",
    "[ global_theorem ] if the assumptions of theorem  @xmath117 hold and the linearly constrained optimizer satisfies f1f3 , then pasa with @xmath115 either terminates in a finite number of iterations at a stationary point , or we have @xmath118    if only phase one is performed for @xmath16 sufficiently large , then ( [ lim_to_zero ] ) follows from theorem  [ gpa - theorem ] . if only phase two is performed for @xmath16 sufficiently large , then @xmath84 for @xmath16 sufficiently large . since @xmath86 is only changed in phase one , we can treat @xmath86 as a fixed positive scalar for @xmath16 sufficiently large .",
    "by f2 , the active sets approach a fixed limit for @xmath16 sufficiently large . by f3 and the inequality @xmath84 , ( [ lim_to_zero ] )",
    "finally , suppose that there are an infinite number of branches from phase two to phase one .",
    "if ( [ lim_to_zero ] ) does not hold , then there exists @xmath119 such that @xmath120 for all @xmath16 . by property p6 of @xcite and the definition @xmath121",
    ", we have @xmath122 which implies that @xmath123 by p4 and p5 of @xcite and the lower bound @xmath124 , we have @xmath125 for the armijo line search in gpa , it follows from ( * ? ? ?",
    "2.1 ) that @xmath126 for all iterations in gpa , where @xmath26 is the lipschitz constant for @xmath25 .",
    "combine this with ( [ g4 ] ) to obtain @xmath127 by the line search condition in step  2 of gpa , it follows from ( [ g1 ] ) , ( [ g2 ] ) , and ( [ lower ] ) that there exists @xmath128 such that @xmath129 for all iterations in gpa with @xmath16 sufficiently large . since the objective function decreases monotonically in phase two , and since there are an infinite number of iterations in gpa , ( [ g3 ] ) contradicts the assumption a1 that @xmath1 is bounded from below .",
    "the proof that only phase two of pasa is executed asymptotically relies on some properties for the solution of the projection problem ( [ y - def ] ) that are established in this section .",
    "since the projection onto a convex set is a nonexpansive operator , we have @xmath130 where @xmath26 is a lipschitz constant for @xmath131 . since @xmath132 for all @xmath75 when @xmath24 is a stationary point , it follows that @xmath133 for all @xmath75 . in the special case where @xmath134 , ( [ lip ] ) yields @xmath135 similar to ( [ lip ] ) , but with @xmath136 replaced by @xmath137 , we have @xmath138    next , let us develop some properties for the multipliers associated with the constraint in the ( [ y - def ] ) .",
    "the first - order optimality conditions associated with ( [ y - def ] ) can be expressed as follows : at any solution @xmath139 of ( [ y - def ] ) , there exists a multiplier @xmath140 such that @xmath141 let @xmath142 denote the set of multipliers @xmath143 satisfying ( [ first - order ] ) at the solution @xmath139 of ( [ y - def ] ) . if @xmath24 is a stationary point for ( [ p ] ) and @xmath75 , then @xmath133 , and the first equation in ( [ first - order ] ) reduces to @xmath144 which is the gradient of the lagrangian for ( [ p ] ) , but with the multiplier scaled by @xmath145 . since @xmath146 , @xmath147 is a multiplier for the constraint in ( [ p ] ) .",
    "thus if @xmath24 is a stationary point for ( [ p ] ) and @xmath148 is the set of lagrange multipliers associated with the constraint , we have @xmath149 by ( [ lip * ] ) @xmath71 approaches @xmath24 as @xmath28 approaches @xmath24 . consequently ,",
    "the indices @xmath150 free at @xmath24 are free at @xmath71 when @xmath28 is sufficiently close to @xmath24 .",
    "the multipliers associated with ( [ y - def ] ) have the following stability property .    [ setclose ]",
    "suppose @xmath24 is a stationary point for @xmath151 and for some @xmath152 , @xmath131 is lipschitz continuous in @xmath153 with lipschitz constant @xmath26 . if @xmath70 and @xmath154 is close enough to @xmath24 that @xmath155 , then @xmath156 for all @xmath157 , where @xmath6 is independent of @xmath28 and depends only on @xmath158 .",
    "this is essentially a consequence of the upper lipschitzian properties of polyhedral multifunctions as established in ( * ? ? ?",
    "1 ) or ( * ? ? ?",
    "4.2 ) . here is a short proof based on hoffman s stability result @xcite for a perturbed linear system of inequalities . since @xmath155",
    ", it follows that any @xmath159 is feasible in the system @xmath160 with @xmath161 . since @xmath24 is a stationary point for ( [ p ] ) , the elements of @xmath162 are feasible in the same system but with @xmath163 hence , by hoffman s result @xcite , there exists a constant @xmath6 , independent of @xmath164 and @xmath165 and depending only on @xmath158 , such that @xmath166 we use ( [ lip * ] ) to obtain @xmath167 which completes the proof .    in the following proposition ,",
    "we study the projection of a step @xmath168 onto the subset @xmath169 of @xmath4 that also satisfies the active constraints at @xmath19 .",
    "we show that the step can be replaced by @xmath170 without effecting the projection .",
    "[ p = prop ] for all @xmath70 , we have @xmath171 where @xmath172    let @xmath173 be defined by @xmath174 with the change of variables @xmath175 , we can write @xmath176 since @xmath177 is the orthogonal projection of @xmath178 onto the null space @xmath179 , where @xmath180 , the difference @xmath181 is orthogonal to @xmath179 . since @xmath182 , it follows from pythagoras that for any @xmath183 , we have @xmath184 since @xmath185 does not appear in the last term , minimizing @xmath186 over @xmath183 is equivalent to minimizing @xmath187 over @xmath183 . by ( [ nd1 ] )",
    ", we obtain @xmath188 changing variables from @xmath185 back to @xmath136 gives @xmath189 comparing this to ( [ 1 ] ) gives ( [ p= ] ) .",
    "in this section , we focus on the case where the iterates of pasa converge to a nondegenerate stationary point ; that is , a stationary point @xmath24 for which there exists a scalar @xmath190 such that @xmath191 for all @xmath192 and @xmath193 .    [ nondegenerate - theorem ] if pasa with @xmath115 generates an infinite sequence of iterates that converge to a nondegenerate stationary point @xmath24 , then within a finite number of iterations , only phase two is executed .    by ( [ lip * ] ) and proposition  [ setclose ] , @xmath194 is close to @xmath24 and @xmath195 is close to @xmath148 when @xmath28 is close to @xmath24 .",
    "it follows that for @xmath29 sufficiently small , we have @xmath196 since @xmath197 for all @xmath198 , it also follows from ( [ lip * ] ) that we can take @xmath29 smaller , if necessary , to ensure that for all @xmath198 and @xmath154 , we have @xmath199 by the last condition in ( [ ax < b ] ) , we have @xmath200 by ( [ lambda>0 ] ) and ( [ ax < b ] ) , @xmath201 that is , if @xmath202 and @xmath192 , then by ( [ lambda>0 ] ) and complementary slackness , @xmath18 lies in @xmath203 , which implies that @xmath204 .",
    "conversely , if @xmath205 , then by ( [ ax < b ] ) , @xmath18 lies in @xmath206 .",
    "hence , ( [ 600 ] ) holds .",
    "choose @xmath207 large enough that @xmath208 for all @xmath209 .",
    "since @xmath210 for all @xmath209 by ( [ 601 ] ) and ( [ 600 ] ) , it follows that @xmath211 where @xmath169 is defined in ( [ omegak ] ) .",
    "the inclusion ( [ 602 ] ) along with proposition  [ p = prop ] yield @xmath212 we subtract @xmath19 from both sides and refer to the definition ( [ dalpha ] ) of @xmath137 to obtain @xmath213 recall that at a local minimizer @xmath214 of a smooth function @xmath215 over the convex set @xmath169 , the variational inequality @xmath216 holds for all @xmath217 .",
    "we identify @xmath215 with the objective in ( [ 10 ] ) , @xmath214 with @xmath218 , and @xmath28 with the point @xmath219 to obtain the inequality @xmath220 hence , @xmath221 by definition , the left side of this inequality is @xmath222 , while the right side is @xmath223 .",
    "consequently , @xmath224 when @xmath209 .",
    "since @xmath225 , it follows that phase one immediately branches to phase two , while phase two can not branch to phase one .",
    "this completes the proof .",
    "we now focus on a degenerate stationary point @xmath24 where there exists @xmath192 and @xmath226 such that @xmath227 .",
    "we wish to establish a result analogous to theorem  [ nondegenerate - theorem ] . to compensate for the degeneracy",
    ", it is assumed that the active constraint gradients at @xmath24 are linearly independent ; that is , the rows of @xmath158 corresponding to indices @xmath192 are linearly independent , which implies that @xmath162 is a singleton . under this assumption ,",
    "proposition  [ setclose ] yields the following lipschitz property .",
    "[ setlip ] suppose @xmath24 is a stationary point for @xmath151 and the active constraint gradients are linearly independent at @xmath24 .",
    "if for some @xmath152 , @xmath131 is lipschitz continuous in @xmath153 with lipschitz constant @xmath26 and @xmath154 is close enough to @xmath24 that @xmath155 for some @xmath70 , then @xmath228 is a singleton and @xmath229 where @xmath6 is independent of @xmath28 and depends only on @xmath158 .    since @xmath155 , it follows that @xmath230 .",
    "hence , the active constraint gradients are linearly independent at @xmath24 and at @xmath71 .",
    "this implies that both @xmath228 and @xmath162 are singletons , and corollary  [ setlip ] follows from proposition  [ setclose ] .    to treat degenerate problems ,",
    "the convergence theory involves one more requirement for the linearly constrained optimizer :    * when branching from phase one to phase two , the first iteration in phase two is given by an armijo line search of the following form : choose @xmath48 as small as possible such that @xmath231 with @xmath169 defined in ( [ omegak ] ) , @xmath232 , @xmath41 , and @xmath42 ( as in the armijo line search of gpa ) .",
    "as @xmath233 increases , @xmath234 tends to zero and @xmath235 approaches @xmath19 .",
    "hence , for @xmath233 sufficiently large , @xmath236 if @xmath237 .",
    "since @xmath238 if @xmath239 , it follows that @xmath240 for @xmath233 sufficiently large , which implies that @xmath241 @xmath242 ; consequently , for @xmath233 sufficiently large , the armijo line search inequality ( [ p - armijo ] ) reduces to the ordinary armijo line search condition @xmath243 which holds for @xmath244 sufficiently small .",
    "the basic difference between the armijo line search in f4 and the armijo line search in gpa is that in f4 , the constraints active at @xmath19 remain active at @xmath235 and f2 holds . with the additional startup procedure f4 for lco ,",
    "the global convergence result theorem  [ global_theorem ] remains applicable since conditions f1 and f2 are satisfied by the initial iteration in phase two .",
    "let @xmath24 be a stationary point where the active constraint gradients are linearly independent .",
    "for any given @xmath13 , we define @xmath245 where @xmath246 . if @xmath28 is close enough to @xmath24 that @xmath247 , then the feasible set in ( [ fstar ] ) is nonempty since @xmath24 satisfies the constraints ; hence , the projection in ( [ fstar ] ) is nonempty when @xmath28 is sufficiently close to @xmath24 .",
    "[ ratio ] suppose @xmath24 is a stationary point where the active constraint gradients are linearly independent and @xmath1 is lipschitz continuously differentiable in a neighborhood of @xmath24 .",
    "if pasa with @xmath248 generates an infinite sequence of iterates @xmath19 converging to @xmath24 , then there exists @xmath249 such that @xmath250 for all @xmath16 sufficiently large .",
    "choose @xmath29 in accordance with corollary  [ setlip ] .",
    "similar to what is done in the proof of theorem  [ nondegenerate - theorem ] , choose @xmath152 smaller if necessary to ensure that for all @xmath154 , we have @xmath251 and @xmath252 choose @xmath207 large enough that @xmath208 for all @xmath209 and suppose that @xmath19 is any pasa iterate with @xmath209 . if @xmath253 , then by ( [ 700 ] ) , @xmath254 by complementary slackness .",
    "hence , @xmath255 for all @xmath28 on the line segment connecting @xmath19 and @xmath256 .",
    "in particular , @xmath257 if @xmath235 is generated by gpa in phase one , while @xmath257 by f2 if @xmath235 is generated in phase two .",
    "it follows that if constraint @xmath258 becomes active at iterate @xmath19 , then @xmath259 for all @xmath260 .",
    "let @xmath261 be the limit of @xmath262 as @xmath16 tends to infinity ; choose @xmath207 larger if necessary to ensure that @xmath263 for all @xmath209 and suppose that @xmath19 is any iterate of pasa with @xmath209 .",
    "if @xmath264 , then since @xmath263 , it follows that @xmath265 , which implies that @xmath266 . thus ( [ aidentify ] ) holds trivially since the left side vanishes .",
    "let us focus on the nontrivial case where @xmath261 is strictly contained in @xmath267 .",
    "the analysis is partitioned into three cases .",
    "* _ for @xmath16 sufficiently large , @xmath19 is generated solely by lco .",
    "it follows that for any @xmath268 , there exists @xmath209 such that @xmath269 . by the first - order optimality conditions for @xmath270",
    ", there exists @xmath271 , with @xmath272 for all @xmath237 , such that @xmath273 the multiplier @xmath274 is unique by the independence of the active constraint gradients and the fact that @xmath275 by the last condition in ( [ 701 ] ) .",
    "similarly , at @xmath24 we have @xmath276 , where @xmath277",
    ". combine this with ( [ 702 ] ) to obtain @xmath278 since @xmath279 by the last condition in ( [ 701 ] ) , it follows from complementary slackness that @xmath280 for all @xmath198 .",
    "since the columns of @xmath281 corresponding to indices in @xmath282 are linearly independent , there exists a constant @xmath6 such that @xmath283 hence , for @xmath100 sufficiently small and @xmath16 sufficiently large , it follows from ( [ 703 ] ) and ( [ 704 ] ) that @xmath284 for all @xmath258 , which contradicts the assumption that @xmath261 is strictly contained in @xmath267 .",
    "consequently , case 1 can not occur .",
    "* case 2 . *",
    "_ pasa makes an infinite number of branches from phase one to phase two and from phase two to phase one .",
    "_ let us consider the first iteration of phase two . by proposition",
    "[ p = prop ] and the definition of @xmath235 in f4 , we have @xmath285 the first - order optimality condition for @xmath235 is that there exists @xmath271 such that @xmath286 where @xmath272 for all @xmath287 .",
    "subtracting from this the identity @xmath288 yields @xmath289 by the lipschitz continuity of @xmath131 , the bound @xmath290 in f4 , and the assumption that the @xmath19 converge to @xmath24 , the right side of ( [ 800 ] ) tends to zero as @xmath16 tends to infinity . exploiting the independence of the active constraint gradients and the identity @xmath280 for all @xmath198 , we deduce from ( [ 704 ] ) and ( [ 800 ] ) that @xmath291 tends to 0 as @xmath16 tends to infinity .",
    "it follows that for each @xmath18 , @xmath292 tends to zero . if @xmath244 is uniformly bounded away from 0 , then @xmath284 when @xmath258 . by complementary slackness , @xmath264 , which would contradict the assumption that @xmath261 is strictly contained in @xmath267 .",
    "consequently , case 2 could not occur .",
    "we will now establish a positive lower bound for @xmath244 in f4 of phase two .",
    "if the armijo stepsize terminates at @xmath293 , then @xmath294 , and we are done .",
    "next , suppose the stepsize terminates at @xmath295 .",
    "since @xmath233 is as small as possible , it follows from proposition  [ p = prop ] and f4 that @xmath296 where @xmath297 the inequality @xmath298 holds since @xmath295 . since @xmath299 by the second condition in ( [ 701 ] ) , we have @xmath300 since the projection onto a convex set is a nonexpansive operator , we obtain @xmath301 the right side of this inequality tends to zero as @xmath16 tends to infinity .",
    "choose @xmath16 large enough that @xmath302 is within the ball centered at @xmath24 where @xmath1 is lipschitz continuously differentiable .",
    "let us expand @xmath1 in a taylor series around @xmath19 to obtain @xmath303 this inequality combined with ( [ 900 ] ) yields @xmath304 as in ( [ g1 ] ) , but with @xmath4 replaced by @xmath169 , we have @xmath305 note that @xmath306 due to ( [ 900 ] ) . combine ( [ 901 ] ) and ( [ 902 ] ) and replace @xmath307 by @xmath308 to obtain @xmath309 hence , if @xmath295 in f4 , then @xmath244 has the lower bound given in ( [ 903 ] ) for @xmath16 sufficiently large , while @xmath310 if @xmath293 .",
    "this completes the proof of case 2 .",
    "* case 3 . * _ for @xmath16 sufficiently large , @xmath19 is generated solely by gpa .",
    "_ the taylor expansion ( [ 904 ] ) can be written @xmath311 where @xmath312 is as defined in gpa .",
    "if ( [ aidentify ] ) is violated , then for any choice of @xmath128 , there exists @xmath313 such that @xmath314 by taking @xmath6 sufficiently large , we will show that @xmath315 in this case , ( [ 100 ] ) implies that @xmath316 is accepted in gpa and @xmath317 by corollary  [ setlip ] , @xmath318 @xmath319 tends to 0 as @xmath16 tends to infinity .",
    "this implies that @xmath320 when @xmath321 , which contradicts the assumption that @xmath261 is strictly contained in @xmath267 .",
    "hence , ( [ aidentify ] ) can not be violated .    to establish ( [ key0 ] ) ,",
    "first observe that @xmath322 by ( [ lip * ] ) . by the first - order optimality condition ( [ first - order ] ) for @xmath256 , it follows that @xmath323 the dot product of this equation with @xmath324 gives @xmath325 again , by the definition of @xmath324 and by complementary slackness , we have @xmath326 by corollary  [ setlip ] , it follows that for @xmath207 sufficiently large and for any @xmath209 , @xmath327 hence , for any @xmath258 and @xmath209 , ( [ key3 ] ) gives @xmath328 since @xmath329 , @xmath330 , and each term in the inner product @xmath331 is nonnegative .",
    "combine ( [ key2])([key4 ] ) to obtain @xmath332 for any @xmath258 and @xmath209 .",
    "the distance @xmath333 between @xmath19 and its projection @xmath334 in ( [ fstar ] ) is bounded by a constant times the maximum violation of the constraint @xmath335 for @xmath336 ; that is , there exists a constant @xmath337 such that @xmath338 since @xmath335 for all @xmath239 , it follows that the maximum constraint violation in ( [ 101 ] ) is achieved for some @xmath258 ( otherwise , @xmath266 and ( [ clower ] ) is violated ) .",
    "consequently , if the index @xmath258 in ( [ key5 ] ) is chosen to make @xmath339 as large as possible , then @xmath340",
    "if ( [ clower ] ) holds , then by ( [ key1 ] ) , we have @xmath341 hence , the expression ( [ key0 ] ) has the upper bound @xmath342 since @xmath343 , this is nonpositive when @xmath6 is sufficiently large .",
    "this completes the proof of ( [ key0 ] ) .",
    "note that there is a fundamental difference between the prototype gpa used in this paper and the versions of the gradient projection algorithm based on a piecewise projected gradient such as those in @xcite . in gpa",
    "there is a single projection followed by a backtrack towards the starting point .",
    "consequently , we are unable to show that the active constraints are identified in a finite number of iterations , unlike the piecewise projection schemes , where the active constraints can be identified in a finite number of iterations , but at the expense additional projections when the stepsize increases . in lemma [ ratio ] we show that even though we do not identify the active constraints , the violation of the constraints @xmath344 for @xmath258 by iterate @xmath19 is on the order of the error in @xmath19 squared .    when @xmath24 is fully determined by the active constraints for which the strict complementarity holds , convergence is achieved in a finite number of iterations as we now show .",
    "suppose @xmath24 is a stationary point where the active constraint gradients are linearly independent and @xmath1 is lipschitz continuously differentiable in a neighborhood of @xmath24 .",
    "if the pasa iterates @xmath19 converge to @xmath24 and @xmath345 , then @xmath346 after a finite number of iterations .",
    "choose @xmath16 large enough that @xmath275 and @xmath334 is nonempty .",
    "since @xmath345 and the active constraint gradients are linearly independent , we have @xmath347 . by lemma",
    "[ ratio ] , we must have @xmath346 whenever @xmath348 .    to complete the analysis of pasa in the degenerate case and",
    "show that pasa ultimately performs only iterations in phase two , we also need to assume that the strong second - order sufficient optimality condition holds .",
    "recall that a stationary point @xmath24 of ( [ p ] ) satisfies the strong second - order sufficient optimality condition if there exists @xmath349 such that @xmath350 first , we observe that under this assumption , the distance from @xmath19 to @xmath24 is bounded in terms of @xmath351 .",
    "[ stability ] if @xmath1 is twice continuously differentiable in a neighborhood of a local minimizer @xmath24 for @xmath151 where the active constraint gradients are linearly independent and the strong second - order sufficient optimality condition holds , then for some @xmath352 and for all @xmath353 , we have @xmath354 e({{\\bf{x } } } ) , \\ ] ] where @xmath26 is a lipschitz constant for @xmath25 on @xmath355 .    by the continuity of the second derivative of @xmath1",
    ", it follows from ( [ opt2 ] ) that for @xmath356 sufficiently small , @xmath357 for all @xmath358 , where @xmath359 given @xmath360 , define @xmath361 . since @xmath362 , it follows that @xmath363 since @xmath364 for all @xmath258 , it follows from corollary  [ setlip ] and complementary slackness that @xmath365 can be chosen smaller if necessary to ensure that @xmath366 which implies that @xmath367 . since @xmath368 and @xmath369 , we also have @xmath370 @xmath371 . with this substitution in ( [ 151 ] ) , we obtain @xmath372 by the lipschitz continuity of @xmath131 , ( [ h53 ] ) , and ( [ lipd ] ) , it follows that @xmath373 for all @xmath374 . since @xmath361 ,",
    "the difference @xmath375 is orthogonal to @xmath179 when @xmath264 .",
    "since @xmath376 , it follows from pythagoras that @xmath377 consequently , @xmath378 for all @xmath374 , and @xmath379 by p8 in @xcite , ( [ 31 ] ) , and ( [ z30 ] ) , we have @xmath380 insert ( [ h53 ] ) and ( [ 98 ] ) in ( [ x - x * ] ) to complete the proof .",
    "we now examine the asymptotic behavior of the undecided index set @xmath87 .",
    "[ undecided - lemma ] if @xmath1 is twice continuously differentiable in a neighborhood of a local minimizer @xmath24 for @xmath151 where the active constraint gradients are linearly independent and the strong second - order sufficient optimality condition holds , and if pasa generates an infinite sequence of iterates converging to @xmath24 , then @xmath381 is empty for @xmath16 sufficiently large .",
    "if @xmath382 for some @xmath16 , then pasa terminates and the lemma holds trivially . hence , assume that @xmath383 for all @xmath16 . to show @xmath381 is empty for some @xmath16",
    ", we must show that either @xmath384 for each @xmath18 . if @xmath258 , then @xmath385_i = 0 $ ] , and by lemma  [ ratio ] , @xmath386_i = [ ( { { \\bf{a}}}(\\bar{{{\\bf{x}}}}_k - { { \\bf{x}}}_k)]_i \\le \\|{{\\bf{a}}}\\| \\|\\bar{{{\\bf{x}}}}_k - { { \\bf{x}}}_k\\| \\le c\\|{{\\bf{a}}}\\|\\|{{\\bf{x}}}_k - { { \\bf{x}}}^*\\|^2.\\ ] ] by lemma [ stability ] , there exists a constant @xmath387 such that @xmath388 for @xmath28 near @xmath24 .",
    "hence , for all @xmath258 and @xmath16 sufficiently large , we have @xmath386_i \\le cd^2 \\|{{\\bf{a}}}\\| e({{\\bf{x}}}_k)^2 = cd^2   \\|{{\\bf{a}}}\\| e({{\\bf{x}}}_k)^{2-\\beta } e({{\\bf{x}}}_k)^\\beta .\\ ] ] since @xmath389 , @xmath390 tends to zero as @xmath16 tends to infinity , and ( b ) holds when @xmath16 is large enough that @xmath391 .    if @xmath392 , then @xmath393 . by corollary  [ setlip ] ,",
    "there exist @xmath249 such that @xmath394 since @xmath94 , @xmath395 tends to zero as @xmath16 tends to infinity , and ( a ) holds when @xmath16 is large enough that @xmath396 . in summary , for @xmath16 sufficiently large , ( a ) holds when @xmath392 and ( b ) holds when @xmath258 .",
    "this implies that @xmath381 is empty for @xmath16 sufficiently large .",
    "as shown in the proof of lemma  [ undecided - lemma ] , ( b ) holds for @xmath258 and @xmath16 sufficiently large .",
    "this implies that the constraint violation @xmath397 tends to zero faster than the error @xmath351 .",
    "the following result , along with lemma  [ undecided - lemma ] , essentially implies that pasa eventually performs only phase two .",
    "[ mu - bound ] if @xmath1 is twice continuously differentiable in a neighborhood of a local minimizer @xmath24 for @xmath151 where the active constraint gradients are linearly independent and the strong second - order sufficient optimality condition holds , and if pasa generates an infinite sequence of iterates converging to @xmath24 , then there exists @xmath398 such that @xmath399 for @xmath16 sufficiently large .",
    "let @xmath400 .",
    "the projection @xmath334 has the property that the difference @xmath401 is orthogonal to @xmath55 .",
    "choose @xmath16 large enough that @xmath275 .",
    "it follows that @xmath402 .",
    "hence , by pythagoras , we have @xmath403 consequently , @xmath404 and @xmath334 approaches @xmath24 as @xmath16 tends to infinity .",
    "choose @xmath352 small enough that @xmath1 is twice continuously differentiable in @xmath405 , and let @xmath26 be the lipschitz constant for @xmath25 in @xmath405 .",
    "choose @xmath16 large enough that @xmath406 . by ( [ 201 ] ) @xmath407 .",
    "since @xmath408 , it follows from ( [ lipd ] ) that @xmath409 lemma  [ ratio ] gives @xmath410 since @xmath19 converges to @xmath24 , it follows from ( [ 999 ] ) that for any @xmath268 , @xmath411 when @xmath16 is sufficiently large .",
    "combine ( [ z39 ] ) and ( [ xxzz ] ) to obtain @xmath412 for some constant @xmath6 and any @xmath16 sufficiently large .",
    "choose @xmath352 small enough that ( [ 31 ] ) holds for all @xmath360 , and choose @xmath16 large enough that @xmath413 .",
    "the bound ( [ 31 ] ) yields @xmath414 by the first - order optimality conditions for a local minimizer @xmath24 of ( [ p ] ) , there exists a multiplier @xmath415 such that @xmath416 observe that @xmath417_i = 0 $ ] for each @xmath18 since @xmath418_i = 0 $ ] when @xmath258 , while @xmath419 when @xmath392 .",
    "hence , we have @xmath420{^{\\sf t}}{\\mbox{\\boldmath $ \\lambda$}}^ * = 0.\\ ] ] we utilize this identity to obtain @xmath421 by the first equality in ( [ 1st ] ) .",
    "the first - order optimality conditions for the minimizer @xmath422 in ( [ dl ] ) imply the existence of @xmath423 such that @xmath424 since @xmath275 , we have @xmath425 , @xmath426{^{\\sf t}}{\\mbox{\\boldmath $ \\lambda$}}_{{\\cal { i } } } = { { \\bf{0}}}$ ] , and    @xmath427    by ( [ 2nd ] ) . combine ( [ upper ] ) , ( [ x1 ] ) , and ( [ x2 ] ) to obtain @xmath428 if @xmath429 denotes @xmath430 , then @xmath431 .",
    "hence , @xmath432 .",
    "it follows that @xmath433 since the projection on a convex set is nonexpansive , @xmath434 combine ( [ xxzz ] ) , ( [ p1 ] ) , and ( [ p2 ] ) to get @xmath435 consequently , by ( [ dbar ] ) we have @xmath436 for @xmath100 sufficiently small and @xmath16 sufficiently large .",
    "finally , ( [ first ] ) completes the proof .    by",
    "the analysis of section  [ nondegenerate ] , ( [ facecond ] ) holds with @xmath437 for a nondegenerate problem ; neither the strong second - order sufficient optimality condition nor independence of the active constraint gradients are needed in this case .",
    "we now show that within a finite number of iterations , pasa will perform only lco .",
    "[ ua - rules ] if pasa with @xmath115 generates an infinite sequence of iterates converging to a local minimizer @xmath24 of @xmath151 where the active constraint gradients are linearly independent and the strong second - order sufficient optimality condition holds , and if @xmath1 is twice continuously differentiable near @xmath24 , then within a finite number of iterations , only phase two is executed .    by lemma  [ undecided - lemma ] ,",
    "the undecided index set @xmath381 is empty for @xmath16 sufficiently large , and by lemma  [ mu - bound ] , there exists @xmath398 such that @xmath438 .",
    "if @xmath16 is large enough that @xmath381 is empty , then in phase one , @xmath86 will be reduced until @xmath439 .",
    "once this holds , phase one branches to phase two and phase two can not branch to phase one .",
    "similar to theorem  4.2 of @xcite , when @xmath1 is a strongly convex quadratic and lco is based on a projected conjugate gradient method , theorem  [ ua - rules ] implies that when the active constraint gradients are linearly independent , pasa converges to the optimal solution in a finite number of iterations .",
    "a new active set algorithm pasa was developed for solving polyhedral constrained nonlinear optimization problems .",
    "phase one of the algorithm is the gradient projection algorithm , while phase two is any algorithm for linearly constrained optimization ( lco ) which monotonically improves the value of the objective function , which never frees an active constraint , and which has the property that the projected gradients tend to zero , at least along a subsequence of the iterates .",
    "simple rules were given in algorithm  [ pasa ] for branching between the two phases .",
    "global convergence to a stationary point was established , while asymptotically , within a finite number of iterations , only phase two is performed . for nondegenerate problems ,",
    "this result follows almost immediately , while for degenerate problems , the analysis required linear independence of the active constraint gradients , the strong second - order sufficient optimality conditions , and a special startup procedure for lco . the numerical implementation and performance of pasa for general polyhedral constrained problems will be studied in a separate paper .",
    "numerical performance for bound constrained optimization problems is studied in @xcite .                                                                , _",
    "superlinear and quadratic convergence of affine - scaling interior - point newton methods for problems with simple bounds without strict complementarity assumption _ , math",
    ". program .",
    ", 86 ( 1999 ) , pp .",
    "615635 .                                        , _ interior - point gradient methods with diagonal - scalings for simple - bound constrained optimization _ , tech . rep . tr04 - 06 , department of computational and applied mathematics , rice university , houston , texas , 2004 ."
  ],
  "abstract_text": [
    "<S> a polyhedral active set algorithm pasa is developed for solving a nonlinear optimization problem whose feasible set is a polyhedron . </S>",
    "<S> phase one of the algorithm is the gradient projection method , while phase two is any algorithm for solving a linearly constrained optimization problem . </S>",
    "<S> rules are provided for branching between the two phases . global convergence to a stationary point is established , while asymptotically pasa performs only phase two when either a nondegeneracy assumption holds , or the active constraints are linearly independent and a strong second - order sufficient optimality condition holds .    </S>",
    "<S> polyhedral constrained optimization , active set algorithm , pasa , gradient projection algorithm , local and global convergence    90c06 , 90c26 , 65y20 </S>"
  ]
}