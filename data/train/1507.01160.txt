{
  "article_text": [
    "mab problems  @xcite are a class of resource allocation problems in which a decision - maker allocates a single resource by sequentially choosing one among a set of competing alternative options called arms . in the so - called stationary mab problem , a decision - maker at each discrete time instant chooses an arm and",
    "collects a reward drawn from an unknown stationary probability distribution associated with the selected arm .",
    "the objective of the decision - maker is to maximize the total expected reward aggregated over the sequential allocation process .",
    "these problems capture the fundamental trade - off between exploration ( collecting more information to reduce uncertainty ) and exploitation ( using the current information to maximize the immediate reward ) , and they model a variety of robotic missions including search and surveillance .",
    "recently , there has been significant interest in bayesian algorithms for the mab problem  @xcite .",
    "bayesian methods are attractive because they allow for incorporating prior knowledge and spatial structure of the problem through the prior in the inference process .    in this paper",
    ", we investigate the influence of the prior on the performance of a bayesian algorithm for the mab problem with gaussian rewards .",
    "mab problems became popular following the seminal paper by robbins  @xcite and gathered interest in diverse areas including controls  @xcite , robotics  @xcite , machine learning  @xcite , economics  @xcite , ecology  @xcite , and neuroscience  @xcite .",
    "much recent work on mab problems focuses on a quantity termed _ cumulative expected regret_. the cumulative expected regret of a sequence of decisions is the cumulative difference between the expected reward of the options chosen and the maximum possible expected reward . in a ground - breaking work , lai and",
    "robbins  @xcite established a logarithmic lower bound on the expected number of times a sub - optimal arm needs to be sampled by an optimal policy in a frequentist setting , thereby showing that cumulative expected regret is bounded below by a logarithmic function of time .",
    "their work established the best possible performance of any solution to the standard mab problem .",
    "they also developed an algorithm based on an upper confidence bound on estimated reward and showed that this algorithm achieves the performance bound asymptotically .    in the following , we use the phrase _ logarithmic regret _ to refer to cumulative",
    "expected regret being bounded above by a logarithmic function of time , i.e. , having the same order of growth rate as the optimal solution .    in the context of the bounded mab problem , i.e. , the mab problem in which the reward is sampled from a distribution with a bounded support , auer  @xcite developed upper confidence bound - based algorithms that achieve logarithmic regret uniformly in time ; see  @xcite for an extensive survey of upper confidence bound - based algorithms .",
    "bayesian approaches to the mab problem have also been considered .",
    "srinivas  @xcite developed asymptotically optimal upper confidence bound - based algorithms for gaussian process optimization .",
    "agrawal  and  goyal  @xcite showed that a bayesian algorithm known as thompson sampling  @xcite is near - optimal for binary bandits with a uniform prior .",
    "liu  and  li  @xcite characterize the sensitivity of the performance of thompson sampling to the assumptions on prior .",
    "kaufman  @xcite developed a generic bayesian upper confidence bound - based algorithm and established its optimality for binary bandits with a uniform prior .",
    "reverdy  @xcite studied the bayesian algorithm proposed in  @xcite in the case of correlated gaussian rewards and analyzed its performance for uninformative priors .",
    "they called this algorithm the upper credible limit ( ucl ) algorithm and showed that the ucl algorithm models human decision - making in the spatially - embedded mab problem .",
    "we define a spatially - embedded mab problem as an mab problem in which the arms are embedded in a metric space and the correlation coefficient between arms is a function of distance between them . for example , in the problem of spatial search over an uncertain distributed resource field , patches in the environment can be modeled as spatially located alternatives and the spatial structure of the resource distribution as a prior on the spatially correlated reward .",
    "this is an example of a _ spatially - embedded mab problem . _",
    "it was observed in  @xcite that good assumptions on the correlation structure result in significant improvement of the performance of the ucl algorithm , and these assumptions can successfully account for the better performance of human subjects .    in this note",
    "we rigorously study the influence of the assumptions in the prior on the performance of the ucl algorithm for a mab problem with gaussian rewards .",
    "since the ucl algorithm models human decision - making well , the results in this paper help us identify the set of parameters in the prior that explain the individual differences in performance of human subjects .",
    "the major contributions of this work are twofold :    first , we study the ucl algorithm with uncorrelated informative prior and characterize its performance .",
    "we illuminate the opposing influences of the degree of confidence of a prior and the magnitude of its inaccuracy , i.e. , the gap between its mean prediction and the true mean reward value , on the decision - making performance .",
    "second , we propose and study a new correlated ucl algorithm with correlated informative prior and characterize its performance .",
    "we show that large correlation scales reduce the number of steps required to explore the surface .",
    "we then show that incorrectly assumed large correlation scales may lead to a much higher number of selections of suboptimal arms than suggested by the lai - robbins bound .",
    "this analysis provides insight into the structure of good priors in the context of explore - exploit problems .",
    "the remainder of the paper is organized in the following way . in section  [ sec : review ] , we recall the mab problem and an associated bayesian algorithm , ucl . we analyze the ucl algorithm for uncorrelated informative prior and correlated informative prior in section  [ sec : uncorr - ucl ]  and  [ sec : corr - ucl ] , respectively .",
    "we illustrate our results with some numerical examples in section  [ sec : numerics ] , and we conclude in section  [ sec : conclusions ] .",
    "in this section we recall the mab problem and the bayes - ucb algorithm proposed in  @xcite .",
    "the @xmath0-armed bandit problem refers to the choice among @xmath0 options that a decision - making agent should make to maximize the cumulative expected reward .",
    "the agent collects reward @xmath1 by choosing arm @xmath2 at each time @xmath3 , where @xmath4 is the horizon length for the sequential decision process . in the so - called stationary mab problem ,",
    "the reward from option @xmath5 is sampled from a stationary distribution @xmath6 and has an unknown mean @xmath7 .",
    "the decision - maker s objective is to maximize the cumulative expected reward @xmath8 by selecting a sequence of arms @xmath9 .",
    "equivalently , defining @xmath10 and @xmath11 as the expected _ regret _ at time @xmath12 , the objective can be formulated as minimizing the cumulative expected regret defined by @xmath13}}= \\sum_{i=1}^n \\delta_i { \\ensuremath{\\mathbb{e}\\left [ n_{i}(t ) \\right]}},\\end{aligned}\\ ] ] where @xmath14 is the total number of times option @xmath15 has been chosen until time @xmath16 and @xmath17 is the expected regret due to picking arm @xmath15 instead of arm @xmath18 .",
    "the bayes - ucb algorithm for the stationary @xmath0-armed bandit problem was proposed in  @xcite .",
    "the bayes - ucb algorithm at each time    1 .   computes the posterior distribution of the mean reward at each arm ; 2 .   computes a @xmath19 upper credible limit for each arm ; 3 .   selects the arm with highest upper credible limit .    in step ( ii )",
    ", the upper credible limit is defined as the least upper bound to the upper credible set , and the function @xmath20 is tuned to achieve efficient performance . in the context of bernoulli rewards , kaufmann  @xcite set @xmath21 , for some @xmath22 , and show that for @xmath23 and uninformative priors , the bayes - ucb algorithm achieves the optimal performance .",
    "reverdy  @xcite studied the bayes - ucb algorithm in the context of gaussian rewards with known variances . for simplicity the algorithm in  @xcite",
    "is called the ucl ( upper credible limit ) algorithm .",
    "it is shown that for an uninformative prior , the ucl algorithm is order - optimal , i.e. , it achieves cumulative expected regret that is within a constant factor of that suggested by the lai - robbins bound .",
    "it is also shown that a variation of the ucl algorithm models human decision - making in an mab task .",
    "in this paper , we focus on the gaussian mab problem , i.e. , the reward distribution @xmath6 is gaussian with mean @xmath24 and variance @xmath25 . the variance @xmath25 is assumed known , e.g. , from previous observations or known characteristics of the reward generation process .",
    "we now recall the ucl algorithm and analyze its performance for a general prior .",
    "suppose the prior on the mean rewards at each arm is a gaussian random variable with mean vector @xmath26 and variance @xmath27 .    for the above mab problem ,",
    "let the number of times arm @xmath15 has been selected until time @xmath12 be denoted by @xmath28 .",
    "let the empirical mean of the rewards from arm @xmath15 until time @xmath12 be @xmath29 .",
    "then , the posterior distribution at time @xmath12 of the mean reward at arm @xmath15 has mean and variance @xmath30 respectively , where @xmath31 .",
    "moreover , @xmath32 & = \\frac{\\delta^2 \\mu_{i}^0 + n_i(t ) m_i}{\\delta^2+n_{i}(t ) } \\ ; \\text{and}\\ ; \\text{var}[\\mu_{i}(t ) ] = \\frac { n_i(t ) \\sigma_s^2}{(\\delta^2+n_{i}(t))^2}.\\end{aligned}\\ ] ]    the ucl algorithm for the gaussian mab problem , at each decision instance @xmath3 , selects an arm with the maximum @xmath33-upper credible limit , i.e. , it selects an arm @xmath34 , where @xmath35 @xmath36 is the inverse cumulative distribution function for the standard gaussian random variable , @xmath37 , and @xmath38 and @xmath39 are tunable parameters .    in the context of gaussian rewards",
    ", the function @xmath40 decomposes into two terms corresponding to the estimate of the mean reward and the associated variance .",
    "this makes the ucl algorithm amenable to an analysis akin to the analysis for ucb1  @xcite .",
    "using such an analysis , it was shown in  @xcite that the ucl algorithm with an uninformative prior and parameter values @xmath41 and @xmath42 achieves an order - optimal performance . in the following , we investigate the performance of the ucl algorithm for general priors .      to analyze the regret of the ucl algorithm , we require some inequalities that we recall in the following lemma .    [",
    "lem : ineq ] for the standard normal random variable @xmath43 and the associated inverse cumulative distribution function @xmath44 , the following statements hold :    1 .   for any @xmath45 @xmath46 2 .   for any @xmath47 $ ] , @xmath48 and @xmath49 , @xmath50    statement ( i ) in lemma  [",
    "lem : ineq ] can be found in  @xcite . the first inequality in ( ii ) follows from ( i ) .",
    "the second inequality in ( ii ) was established in  @xcite , and the last inequality can be easily verified using the second inequality in ( ii ) .",
    "[ lem : diff - of - squares ] for any @xmath51 such that @xmath52 , @xmath53    the inequality follows trivially using a completing the square argument .",
    "let @xmath54 , for each @xmath55 .",
    "set @xmath56 , @xmath57 , and @xmath58 , for some @xmath59 .",
    "[ thm : uncorr - regret ] for the gaussian mab problem , and the ucl algorithm with uncorrelated prior , the expected number of times a suboptimal arm @xmath15 is selected satisfies @xmath60 \\le   \\eta_i + \\hat n_i(t),\\ ] ] where @xmath61 , and @xmath62 is defined in  .",
    "@xmath63    ' '' ''    see  [ proof - uncorr - regret ] .",
    "[ rem : uncor - regret ]",
    "in this section , we study a new correlated ucl algorithm for the correlated mab problem . we first propose a modified ucl algorithm , and then analyze its performance .",
    "the modification is designed to leverage prior information on correlation structure .",
    "suppose the prior on the mean rewards at each arm is a multivariate gaussian random variable with mean vector @xmath64 and covariance matrix @xmath65 .    for the above mab problem ,",
    "the posterior distribution of the mean rewards at each arm at time @xmath12 is a gaussian distribution with mean @xmath66 and covariance @xmath67 defined by @xmath68 where @xmath69 is the column @xmath0-vector with @xmath2-th entry equal to one , and every other entry zero . in the following ,",
    "we denote entries of @xmath70 and the diagonal entries of @xmath67 by @xmath71 and @xmath72 , respectively .    as in section  [ subsec : deterministic - ucl ] , let @xmath28 be the number of times arm @xmath15 has been selected until time @xmath12 , and @xmath29 be the empirical mean of the rewards from arm @xmath15 until time @xmath12 .",
    "then , it is easy to verify that @xmath73 where @xmath74 , @xmath75 is the diagonal matrix with entries @xmath76 , and @xmath77 is the vector of @xmath78 .",
    "the correlated ucl algorithm for the gaussian mab problem , at each decision instance @xmath3 , selects an arm with the maximum upper credible limit , i.e. , it selects an arm @xmath34 , where @xmath79 @xmath36 is the inverse cumulative distribution function for the standard gaussian random variable , @xmath37 , @xmath80 is the correlation coefficient between arm @xmath15 and arm @xmath81 at time @xmath12 and @xmath38 and @xmath39 are tunable parameters .",
    "note that for uncorrelated priors , @xmath82 and the correlated ucl algorithm reduces to the ucl algorithm .    in the context of uninformative priors , @xmath83 for each @xmath55 , and",
    "the ucl algorithm selects each arm once in first @xmath0 steps . in a similar vein",
    ", we introduce an initialization phase for the correlated ucl algorithm .    _",
    "* initialization : * _ in the initialization phase , an arm @xmath2 defined by @xmath84 is selected at time @xmath12 . here",
    ", @xmath85 is a pre - specified positive constant .",
    "let @xmath86 be the number of steps in the initialization phase .",
    "[ lem : initialization - corr - stat ] for the correlated mab problem and the inference process  , the initialization phase ends in at most @xmath0 steps and the variance following the initialization phase @xmath87 , for each @xmath5 .",
    "note that to prove the lemma , it suffices to show that no arm will be selected twice in the initialization phase .",
    "it follows from the sherman - morrison formula for the rank-@xmath88 update for the covariance in   that @xmath89 where @xmath90 is the @xmath91 component of @xmath67 , for each @xmath5 . if @xmath92 , then @xmath93 .",
    "thus , arm @xmath81 will not be selected again in the initialization phase which establishes our claim .",
    "[ rem : corr - init ]      for correlated priors , the inference equations   yield the following expressions for the bias @xmath94 and covariance @xmath95 of the estimate @xmath70 @xmath96 - \\bs m   =   ( \\lambda_0 + p(t)^{-1})^{-1 } \\lambda_0 ( \\bs \\mu_0 - \\bs m)\\\\ \\bar \\sigma(t ) & : = \\text{cov}(\\bs \\mu_t )   = ( \\lambda_0 + p(t)^{-1})^{-1 } p(t)^{-1}(\\lambda_0 + p(t)^{-1})^{-1},\\end{aligned}\\ ] ] where @xmath97 is the vector of mean reward .",
    "let @xmath98 and @xmath99 , @xmath100 be the diagonal and off - diagonal entries of @xmath67 , and @xmath101 be the diagonal entries of @xmath102 .",
    "we now analyze the properties of covariance matrices @xmath67 and @xmath102 .",
    "let @xmath103 be the submatrix of @xmath104 obtained after excluding the @xmath15-th row and @xmath15-th column .",
    "let @xmath105 be the row vector obtained after excluding the @xmath15-th entry from the @xmath15-th row of @xmath104 .",
    "we define the variance of arm @xmath15 conditioned on the mean reward at every other arm by @xmath106 let @xmath107 . with a slight abuse of notation , we refer to @xmath28 as the number of times arm @xmath15 is selected after the initialization phase .",
    "we also define for each @xmath5 @xmath108 where @xmath109 is the @xmath110 component of @xmath111 .",
    "[ lem : bounds - variances ] the following statements hold for the inference process  :    1 .",
    "the variance @xmath98 satisfies @xmath112 2 .   the variance @xmath113 satisfies @xmath114    we start by establishing the first statement .",
    "the covariance update in can be simplified using the sherman - morrison formula to obtain @xmath115 it follows that @xmath116 it follows that after the initialization phase @xmath117 . moreover , at each future round , if @xmath118 , then @xmath119 ; otherwise , @xmath120 .",
    "the upper bound on @xmath98 immediately follows from this observation and the induction argument .",
    "we now establish the lower bound on @xmath98 .",
    "since the inference process involves a stationary environment , the sequence in which arms are played is of no significance and the inference only depends on the number of times an arm has been played . consequently , the inference is the same if arms are played in blocks . in particular ,",
    "each arm @xmath121 can be played in a block of size @xmath122 .",
    "further , any order in which these blocks are played leads to the same inference .",
    "suppose for such a modified allocation of arms , @xmath123 is the time when the block associated with arm @xmath81 begins .",
    "suppose that arm @xmath15 is played the last .",
    "then , from   and for the modified allocation process , it follows that @xmath124 i.e. , the posterior variance @xmath125 is lower bounded by the conditional variance of arm @xmath15 under a noise free reward from arm @xmath81 .",
    "it follows that , for the modified allocation sequence , @xmath126 .",
    "now , the lower bound follows from the variance update after the last block .    to establish the second statement ,",
    "we note that @xmath127 .",
    "it follows that @xmath128 where the second inequality follows from the fact @xmath129 .",
    "similarly , @xmath130 establishing the lower bound .",
    "[ thm : corr - regret ] for the gaussian mab problem , and the correlated ucl algorithm , the expected number of times a suboptimal arm @xmath15 is selected after the initialization phase satisfies @xmath60 \\le   \\eta_i + \\hat n_i(t),\\ ] ] where @xmath131 , and @xmath132    see  [ proof : corr - regret ] .",
    "[ rem : corr - regret ]",
    "in this section , we illustrate the results of the preceding two sections with data from numerical simulations .",
    "the theoretical results pertain to different quality priors defined by how rich is the information they can capture about the rewards associated with the bandit .",
    "uninformative priors capture no information , while uncorrelated informative priors capture beliefs about individual arms .",
    "correlated ( informative ) priors add to uncorrelated informative priors the ability to capture beliefs about the relationship between different arms , which we leverage in our new correlated ucl algorithm .",
    "when an informative prior models the environment well , we refer to it as a _ well - informed _ prior ; conversely , if the prior models the environment poorly , we refer to it as _ ill - informed_.    as in @xcite , our simulations focus on the case of a spatially - embedded bandit problem , for which @xcite showed that correlated priors can lead to higher performance .",
    "the simulations show that , among well - informed priors , those with richer information content result in higher performance .",
    "theorems [ thm : uncorr - regret ] and [ thm : corr - regret ] allow us to quantify the extent to which a prior is well - informed .",
    "we consider here the spatially - embedded bandit problem studied in @xcite .",
    "the reward surface is relatively smooth with regions of both high and low rewards .",
    "this means that a correlated prior capturing length scale information can improve performance .",
    "the mean reward value is equal to 30 , and the sampling variance for each arm is @xmath133 .",
    "figure [ fig : goodpriors ] shows simulations from cases where the informative priors are well - informed .",
    "mean cumulative regret computed from an ensemble of 100 simulations is shown for three priors : an uninformative prior , an informative uncorrelated prior , and an informative correlated prior . for all the simulations , the parameter @xmath134 was set equal to @xmath135 , and for correlated priors the parameter @xmath136 was set equal to 1 .",
    "the informative priors have an initial mean belief @xmath137 with a higher value ( equal to 100 ) in regions with high rewards , and a lower value of zero elsewhere .",
    "the uncorrelated prior sets @xmath138 , meaning the prior represents the equivalent of a single prior observation .",
    "the correlated prior sets @xmath139 as in the uncorrelated case , and uses a correlation structure representing an exponential kernel as in @xcite .",
    "this kernel encodes the information that the closer two arms are in the embedding space , the more correlated are their rewards .    the richer information provided by the informative priors results in better performance in this case where the priors are well - informed : the informative correlated prior results in less regret than the informative uncorrelated prior , which in turn results in less regret than the uninformative prior . for short horizons",
    ", the informative priors result in cumulative regret which is less than the lai - robbins lower bound . the ucl algorithm and",
    "the correlated ucl algorithm can violate the lower bound because of the additional information provided by the priors , which effectively shifts the regret curve leftwards .",
    "asymptotically , however , the algorithms will tend to match the lai - robbins regret rate for any prior .",
    "in contrast , figure [ fig : badpriors ] shows simulations from cases where the informative priors are variously ill - informed .",
    "mean cumulative regret computed from an ensemble of @xmath140 simulations is shown for three increasingly informative priors , as in figure [ fig : goodpriors ] .",
    "the informative priors have an initial mean belief @xmath137 that is uniform with each element @xmath141 . as in figure",
    "[ fig : goodpriors ] , the uncorrelated prior sets @xmath138 , meaning the prior represents the equivalent of a single prior observation .",
    "the correlated prior sets @xmath139 and uses a correlation structure that again represents an exponential kernel but with a longer length scale to represent a smoother reward surface .",
    "although the informative priors accurately represent the overall mean value of the reward surface , they fail to capture the spatial heterogeneity of the reward surface , in particular the fact that it has high- and low - value patches .",
    "therefore , both informative priors are ill - informed about the mean rewards and the informative uncorrelated prior results in much poorer performance than the uninformative prior for moderate task horizons . however ,",
    "by adding the correlation structure to the ill - informed uncorrelated prior , we can recover much of the performance exhibited by the well - informed correlated prior of figure [ fig : goodpriors ] .",
    "in a spatially - embedded task like the one studied here , information about correlation structure among arms can be as valuable as accurate information about the value of individual arms .    .",
    "because of the additional information provided by the informative priors , the algorithms can sample arms more selectively from the initial time @xmath142 , which results in better performance than the uninformative prior and allows the algorithms to outperform the lai - robbins bound on regret.,scaledwidth=50.0% ]    , the traces show mean cumulative regret from 100 simulations for each of three different priors .",
    "again the algorithms exhibit an initialization phase behavior for the uninformative and informative correlated priors , whose end can be seen in the bends in the regret curves near @xmath143 .",
    "the ill - informed correlated prior improves performance relative to the uninformative prior although not quite as much as the well - informed correlated prior does in figure [ fig : goodpriors ] .",
    "in contrast , the ill - informed uncorrelated prior significantly decreases performance relative to all other priors . by encoding a strong incorrect belief about the rewards , this",
    "prior requires multiple samples of suboptimal arms to learn that they are suboptimal .",
    "this appears in the regret curve as an initialization phase that lasts until @xmath144 4,500 , at which point the mean cumulative regret is approximately 35,000.,scaledwidth=50.0% ]",
    "in this note we studied and modified the ucl algorithm for the correlated mab problem with gaussian rewards .",
    "we investigated the influence of the assumptions in the prior on the performance of the ucl algorithm and the new correlated ucl algorithm .",
    "we characterized scenarios in which the informative priors perform better than the uninformative prior and characterized the improvement in the performance in terms of cumulative regret .",
    "in particular , we showed conditions in which an informative correlated prior can be leveraged to significantly reduce cumulative regret .",
    "there are several possible avenues of future research .",
    "first , we considered that the environment is stationary .",
    "an interesting future direction is to consider non - stationary environments in which the reward at each arm may be time - varying and the autocorrelation scale may be known .",
    "second , we considered these problems for a single player .",
    "many application scenarios involve a group of individuals and it is of interest to study collaborative and competitive multiplayer versions of these problems .",
    "10    j.  gittins , k.  glazebrook , and r.  weber . .",
    "wiley , second edition , 2011 .",
    "e.  kaufmann , o.  capp , and a.  garivier .",
    "on bayesian upper confidence bounds for bandit problems . in _ international conference on artificial intelligence and statistics _ , pages 592600 , la palma , canary islands , spain , april 2012 .",
    "n.  srinivas , a.  krause , s.  m. kakade , and m.  seeger .",
    "information - theoretic regret bounds for gaussian process optimization in the bandit setting .",
    ", 58(5):32503265 , 2012 .",
    "s.  agrawal and n.  goyal .",
    "analysis of thompson sampling for the multi - armed bandit problem . in s.",
    "mannor , n.  srebro , and r.  c. williamson , editors , _ jmlr : workshop and conference proceedings _ , volume 23 : colt 2012 , pages 39.139.26 , 2012 .",
    "p.  reverdy , v.  srivastava , and n.  e. leonard .",
    "modeling human decision making in generalized gaussian multiarmed bandits .",
    ", 102(4):544571 , 2014 .",
    "h.  robbins . some aspects of the sequential design of experiments .",
    ", 58:527535 , 1952 .",
    "r.  agrawal , m.  v. hedge , and d.  teneketzis .",
    "asymptotically efficient adaptive allocation rules for the multi - armed bandit problem with switching cost .",
    ", 33(10):899906 , 1988 .",
    "v.  anantharam , p.  varaiya , and j.  walrand . .",
    ", 32(11):968976 , 1987 .",
    "j.  l. ny , m.  dahleh , and e.  feron .",
    "multi - uav dynamic routing with partial observations using restless bandit allocation indices . in _ proceedings of american controls",
    "conference _ , pages 42204225 , seattle , washington , usa , june 2008 .",
    "m.  y. cheung , j.  leighton , and f.  s. hover .",
    "autonomous mobile acoustic relay positioning as a multi - armed bandit with switching costs . in _",
    "ieee / rsj international conference on intelligent robots and systems _ , pages 33683373 , tokyo , japan , november 2013 .",
    "v.  srivastava , p.  reverdy , and n.  e. leonard .",
    "surveillance in an abruptly changing world via multiarmed bandits . in _",
    "ieee conf . on decision and control _ ,",
    "pages 692697 , los angeles , ca , december 2014 .",
    "m.  babaioff , y.  sharma , and a.  slivkins .",
    "characterizing truthful multi - armed bandit mechanisms . in _ proceedings of the 10th acm conference on electronic commerce _ , pages 7988 , stanford , ca ,",
    "usa , july 2009 .",
    "f.  radlinski , r.  kleinberg , and t.  joachims . learning diverse rankings with multi - armed bandits . in _ proceedings of the 25th international conference on machine learning _ , pages 784791 , helsinki , finland , july 2008 .",
    "mccall and j.  j. mccall . a sequential study of migration and job search .",
    ", 5(4):452476 , 1987 .",
    "j.  r. krebs , a.  kacelnik , and p.  taylor .",
    "test of optimal sampling by foraging great tits .",
    ", 275(5675):2731 , 1978 .",
    "v.  srivastava , p.  reverdy , and n.  e. leonard .",
    "optimal foraging and multi - armed bandits . in _",
    "allerton conf .  on communications , control and computing _ ,",
    "pages 494499 , monticello , il , usa , october 2013 .",
    "r.  c. wilson , a.  geana , j.  m. white , e.  a. ludvig , and j.  d. cohen .",
    "humans use directed and random exploration to solve the explore - exploit dilemma .",
    ", 143(6):20742081 , 2014 .",
    "p.  reverdy , v.  srivastava , r.  c. wilson , and n.  e. leonard .",
    "human decision making and the explore - exploit tradeoff : algorithmic models for multi - armed bandit problems . in simon haykin ,",
    "editor , _ cognitive dynamic systems_. wiley series on adaptive and cognitive dynamic systems .",
    "ieee press / wiley , 2015 .",
    "t.  l. lai and h.  robbins .",
    "asymptotically efficient adaptive allocation rules . , 6(1):422 , 1985 .",
    "p.  auer , n.  cesa - bianchi , and p.  fischer .",
    "finite - time analysis of the multiarmed bandit problem .",
    ", 47(2):235256 , 2002 .",
    "s.  bubeck and n.  cesa - bianchi .",
    "regret analysis of stochastic and nonstochastic multi - armed bandit problems .",
    ", 5(1):1122 , 2012 .",
    "e.  kaufmann , n.  korda , and r.  munos .",
    "thompson sampling : an asymptotically optimal finite - time analysis . in _",
    "algorithmic learning theory _ ,",
    "pages 199213 .",
    "springer , 2012 .    w.  r. thompson . on the likelihood that one unknown probability exceeds another in view of the evidence of two samples .",
    ", 25(3/4):285294 , 1933 .    c.  y. liu and l.  li . on the prior sensitivity of thompson sampling",
    ". , 2015 .",
    "m.  abramowitz and i.  a. stegun , editors . .",
    "dover publications , 1964 .",
    "in the spirit of  @xcite , we bound @xmath14 as follows : @xmath145 where @xmath146 is some positive integer and @xmath147 is the indicator function , with @xmath148 if @xmath149 is a true statement and @xmath150 otherwise .    at time @xmath12 , the agent picks option @xmath15 over @xmath18 only if @xmath151 this is true when at least one of the following equations holds : @xmath152 where @xmath153 and @xmath37 .",
    "otherwise , if none of the equations ( [ eq : qi*])-([eq : micomp ] ) holds , @xmath154 and option @xmath18 is picked over option @xmath15 at time t. as noted earlier , the posterior mean @xmath71 is a gaussian random variable : @xmath155 we will now analyze the events  ,  ,  and  . let @xmath156 be the probability of the event  .    [ lem - first - event - uncorr ] the following statements hold for event  :    1 .",
    "if @xmath157 , then @xmath158 2 .   if @xmath159 , then @xmath160    for @xmath161 , event   is true if @xmath162 where @xmath163 is a standard normal random variable .",
    "similarly , for @xmath164 , event   is not true if ( i ) @xmath165 , or ( ii ) @xmath166 and @xmath167 .",
    "we now establish the first statement . if @xmath165 and @xmath168 , then @xmath169 . if @xmath165 and @xmath170 , then @xmath171 therefore , @xmath172    to establish the second statement , we note that if @xmath173 and @xmath168 , then event   does not hold if @xmath174 if @xmath173 and @xmath170 , then @xmath175 , where @xmath176 .",
    "note that @xmath177 , if @xmath178 .",
    "define @xmath179 it follows that for @xmath180 , @xmath181 where the second last inequality follows from lemma  [ lem : diff - of - squares ] and @xmath182 and @xmath183 are as defined in section [ sec : uncorr - ucl - regret ] .    therefore , @xmath184    let @xmath185 be the joint probability of the event   and the event @xmath186 , for some @xmath187 .",
    "[ lem - sec - event - uncorr ] the following statements hold for event  :    1 .",
    "if @xmath188 , then @xmath189 2 .   if @xmath190 , then @xmath191    the event  ( [ eq : qi ] ) holds if @xmath192 where @xmath163 is a standard normal random variable .",
    "we start with establishing the first statement . if @xmath193 and @xmath194 , then @xmath195 where @xmath196 .",
    "it follows that @xmath177 , if @xmath197 .",
    "it follows that for @xmath198 @xmath199 where the second last inequality follows from lemma  [ lem : diff - of - squares ] .",
    "therefore , @xmath200 the second statement follows similarly to the first statement in lemma  [ lem - first - event - uncorr ] .",
    "we now analyze the probability of event  .",
    "@xmath201 where @xmath17 , the inequality   follows from lemma  [ lem : ineq ] , and the inequality   follows from the monotonicity of the logarithmic function .",
    "therefore , the event  ( [ eq : micomp ] ) is not true if @xmath202 setting @xmath61 , we get @xmath203 } } & \\leq \\eta_i + \\sum_{t = 1}^t \\prob(q_{i}^t > q_{i^*}^t , n_{i}(t-1 ) \\geq \\eta_i ) \\\\   & = \\eta_i + \\sum_{t = 1}^t \\big(\\prob_1(t ) + \\prob_2(t)\\big)\\\\   & <",
    "\\eta_i + \\hat n_i(t ) . \\end{aligned}\\ ] ] this completes the proof of the theorem .",
    "similar to the proof of theorem  [ thm : uncorr - regret ] , at time @xmath12 , the agent picks option @xmath15 over @xmath18 only if @xmath204 .",
    "this is true when at least one of the following equations holds : @xmath205 where @xmath206 , @xmath37 .",
    "it follows using the same argument as in theorem  [ thm : uncorr - regret ] that @xmath214 similarly , @xmath215 also , event   is not true if @xmath216 adding the probabilities of the events  - , we obtain the desired expression ."
  ],
  "abstract_text": [
    "<S> we consider the correlated multiarmed bandit ( mab ) problem in which the rewards associated with each arm are modeled by a multivariate gaussian random variable , and we investigate the influence of the assumptions in the bayesian prior on the performance of the upper credible limit ( ucl ) algorithm and a new correlated ucl algorithm . </S>",
    "<S> we rigorously characterize the influence of accuracy , confidence , and correlation scale in the prior on the decision - making performance of the algorithms . </S>",
    "<S> our results show how priors and correlation structure can be leveraged to improve performance .    multiarmed bandit problem , bayesian algorithms , decision - making , spatial search , upper credible limit algorithm , influence of priors </S>"
  ]
}