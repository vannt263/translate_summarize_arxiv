{
  "article_text": [
    "we consider a multiple testing scenario encountered in many current applications of statistics .",
    "given a large index set @xmath0 and a family @xmath1 of null hypotheses about the distribution of a high - dimensional random vector @xmath2 , we wish to design a procedure , basically a family of test statistics and thresholds , to estimate the subset @xmath3 over which the null hypotheses are false .",
    "we shall refer to @xmath4 as the `` active set '' and write @xmath5 for our estimator of @xmath4 based on a random sample @xmath6 of size @xmath7 from @xmath8 .",
    "the hypotheses in @xmath9 ( namely the ones for which the null is rejected ) are referred to as `` detections '' or `` discoveries . ''",
    "naturally , the goal is to maximize the number @xmath10 of detected true positives while simultaneously controlling the number @xmath11 of false discoveries .    there are two widely used criteria for controlling false positives : + * fwer : * assume that @xmath12 is defined on the probability space @xmath13 . the family - wise error rate ( fwer ) is @xmath14 which is the probability of making at least one false discovery .",
    "this is usually controlled using bonferroni bounds and their refinements @xcite , or using resampling methods or random permutation . + * fdr : * the false discovery rate ( fdr ) is the expected ratio between the number of false alarms @xmath11 and the number of discoveries @xmath15 @xcite .",
    "+ in many cases , including the settings in computational biology which directly motivate this work , we find @xmath16 , @xmath17 as well as small `` effect sizes . ''",
    "this is the case , for example , in genome - wide association studies ( gwas ) where @xmath18 and the dependence of the `` phenotype '' @xmath19 on the `` genotype '' @xmath20 is often assumed to be linear ; the active set @xmath4 are those @xmath21 with non - zero coefficients and effect size refers to the fraction of the total variance of @xmath19 explained by a particular @xmath22 . under these challenging circumstances , the fwer criterion is usually very conservative and power is limited ; that is , number of true positive detections is often very small ( if not null ) compared to @xmath23 ( the `` missing heritability '' ) .",
    "this is why the less conservative fdr criterion is sometimes preferred : it allows for a higher number of true detections , but of course at the expense of false positives . however , there are situations , such as gwas , in which this tradeoff is unacceptable ; for example , collecting more data and doing follow - up experiments may be too labor intensive or expensive , and therefore having even one false discovery may be deemed undesirable .    to set the stage for our proposal , suppose we are given a family @xmath24 of test statistics and can assume that deviations from the null are captured by small values of @xmath25 ( e.g. , p - values ) .",
    "we make the usual assumption , easily achieved in practice , that the distribution of @xmath26 does not depend on @xmath21 when @xmath27 , and individual rejection regions are of the form @xmath28 for a constant @xmath29 independent of @xmath21 . defining @xmath30 , the bonferroni upper - bound is @xmath31 to ensure that @xmath32 , @xmath33 is selected such that @xmath34 whenever @xmath35 .",
    "the bonferroni bound can only be marginally improved ( see , in particular estimator @xcite , which will be referred to as bonferroni - holm in the rest of the paper ) in the general case . while alternative procedures ( including permutation tests ) can be designed to take advantage of correlations among tests ,",
    "the bound is sharp when @xmath36 and tests are independent .",
    "* coarse - to - fine testing : * clearly some additional assumptions or domain - specific knowledge is necessary to ameliorate the reduction in power resulting from controlling the fwer . motivated by applications in genomics , we suppose the set @xmath0 has a natural hierarchical structure . in principle , it should then be possible to gain power if the active hypotheses are not randomly distributed throughout @xmath0 but rather have a tendency to cluster within cells of the hierarchy .",
    "in fact , we shall consider the simplest example consisting of only two levels corresponding to individual hypotheses indexed by @xmath37 and a partition of @xmath0 into non - overlapping subsets @xmath38 , which we call `` cells . ''",
    "we will propose a particular multiple testing strategy which is coarse - to - fine with respect to this structure , controls the fwer , and whose power will exceed that of the standard bonferroni - holm approach for typical models and realistic parameters when a minimal degree of clustering is present .",
    "it is important to note that clustering property is not a condition for a correct control of the fwer at a given level using our coarse - to - fine procedure , but only for its increased efficiency in discovering active hypotheses .",
    "our estimate of @xmath4 is now based on two families of test statistics : @xmath39 , as above , and @xmath40 .",
    "the cell - level test @xmath41 is designed to assume small values only when @xmath42 is `` active , '' meaning that @xmath43 .",
    "our estimator of @xmath4 is now @xmath44 one theoretical challenge of this method is to derive a tractable method for controlling the fwer at a given level @xmath45 .",
    "evidently , this method can only out - perform bonferroni if @xmath46 ; otherwise , the coarse - to - fine active set is a subset of the bonferroni discoveries .",
    "a key parameter is @xmath47 , an upper bound on the number of active cells , and in the next section we will derive an fwer bound @xmath48 under an appropriate compound null hypothesis .    the main results of the paper are in the ensuing analysis for different models for @xmath8 . in each case , the first objective is to compute @xmath49 for a given @xmath50 and @xmath51 and the second objective is to maximize the power over all pairs @xmath52 which satisfy @xmath53 .",
    "the smaller our upper bound on @xmath47 , the stronger is the clustering of active hypotheses in cells and the greater is the gain in power compared with the bonferroni bound . in particular , as soon as @xmath54 , the coarse - to - fine strategy will lead to a considerably less conservative score threshold for individual hypotheses relative to the bonferroni estimate and the coarse - to - fine procedure will yield an increase in power for a given fwer .",
    "again , our assumptions about clustering are only expressed through an upper bound on @xmath47 ; no other assumptions about the distribution of @xmath4 are made and the fwer is controlled in all cases .",
    "the main technical difficulty arises from the correlation between the corresponding test statistics .",
    "this must be taken into account since it increases the likelihood of an individual index @xmath21 being falsely declared active when the cell @xmath55 that contains it is falsely discovered ( survivorship bias ) .",
    "more specifically , we require sharp estimates of quadrant probabilities under the _ joint distribution _ of @xmath56 and @xmath26 when @xmath55 , the cell containing @xmath21 , is inactive .",
    "all these issues will be analyzed in two cases .",
    "first , we will consider the standard linear model with gaussian data . in this case",
    "@xmath49 is expressed in terms of centered chi - square distributions and the power is expressed in terms of non - centered chi - square distributions .",
    "the efficiency of the coarse - to - fine method in detecting active hypotheses will depend on effect sizes , both at the level of cells and individual @xmath21 , among other factors .",
    "a non - parametric procedure will then be developed in section [ sec:5 ] based on generalized permutation testing and invariance assumptions .",
    "finally , we shall derive a high - confidence upper bound on @xmath47 based on a martingale argument .",
    "extensive simulations comparing the power of the coarse - to - fine and bonferroni - holm appear throughout .",
    "* applications and related work : * as indicated above , our work ( and some of our notation ) is inspired by statistical issues arising in gwas @xcite and related areas in computational genomics . in the most common version of gwas , the `` genotype '' of an individual",
    "is represented by the genetic states @xmath22 at a very large family of genomic locations @xmath37 ; these variations are called single nucleotide polymorphisms or snps . in any given study",
    "the objective is to find those snps @xmath57 `` associated '' with a given `` phenotype '' , for example a measurable trait @xmath19 such as height or blood pressure .",
    "the null hypothesis for snp @xmath21 is that @xmath19 and @xmath22 are independent r.v.s , and whereas @xmath58 may run into the millions , the set @xmath4 of active variants is expected to be fewer than one hundred .",
    "( ideally , one seeks the `` causal '' variants , an even smaller set , but separating correlation and causality is notoriously difficult . )",
    "control of the fwer is the gold standard and the linear model is common .",
    "if the considered variants are confined to coding regions , then the set of genes provides a natural partition of @xmath0 ( and the fact that genes are organized into pathways provides a natural three - level hierarchy ) @xcite    another application of large - scale multiple testing is variable filtering in high - dimensional prediction : the objective is to predict a categorical or continuous variable @xmath19 based on a family of potentially discriminating features @xmath59 . learning a predictor @xmath60 from i.i.d .",
    "samples of @xmath61 is often facilitated by limiting _ a priori _ the set of features utilized in training @xmath60 to a subset @xmath57 determined by testing the features one - by - one for dependence on @xmath19 and setting a signficance threshold . in most applications of machine learning to artificial perception , no premium is placed on pruning @xmath4 to a highly distinguished subset ; indeed , the particular set of selected features is rarely examined or considered of significance .",
    "in contrast , the identities of the particular features selected and appearing in decision rules are often of keen interest in computational genomics , e.g. , discovering cancer biomarkers , where the variables @xmath22 represent `` omics '' data ( e.g. , gene expression ) , and @xmath19 codes for two possible cellular or disease phenotypes .",
    "obtaining a `` signature '' @xmath62 devoid of false positives can be beneficial in understanding the underlying biology and interpreting the decision rules . in this case the gene ontology ( go ) @xcite provides a very rich hierarchical structure , but one example being the organization of genes in pathways .",
    "indeed , building predictors to separate `` driver mutations '' from `` passenger mutations '' in cancer would appear to be a promising candidate for coarse - to - fine testing due to the fact that drivers are known to cluster in pathways .",
    "there is a literature on coarse - to - fine pattern recognition ( see , e.g. , @xcite and the references therein ) , but the emphasis has traditionally been on computational efficiency rather than error control .",
    "computation is not considered here . moreover , in most of this work , especially applications to vision and speech , the emphasis is on detecting true positives ( e.g. , patterns of interest such as faces ) at the expense of false positives .",
    "simply `` reversing '' the role of true positives and negatives is not feasible due to the loss of reasonable invariance assumptions ; in effect , every pattern of interest is unique .",
    "finally , in @xcite , a hierarchical testing approach is used in the context of the fwer .",
    "however , the intention is to improve the power of detection relative to the bonferroni - holm methods only at level of clusters of hypotheses ; in contrast to our method , the two approaches have comparable power at the level of individual hypotheses .",
    "* organization of the paper : * the paper is structured as follows : in section [ sec:2 ] we present a bonferroni - based inequality that will be central for controlling the fwer using the coarse - to - fine method in different models . in section [ sec:3 ] will consider a parametric model that will illustrate precisely the way we control the fwer at a fixed level and permit a power comparison between coarse - to - fine and bonferroni - holm .",
    "we then propose a non - parametric procedure in section [ sec:5 ] under general invariance assumptions .",
    "a method for estimating an upper bound on the number of active cells and incorporating it into the testing procedure without violating the fwer constraint is derived in section [ sec:6 ] .",
    "finally , some concluding remarks are made in the discussion .",
    "the finite family of null hypotheses will be denoted by @xmath63 , where @xmath64 is either true or false .",
    "we are interested in the active set of indices , @xmath65 and will write @xmath66 for the set of inactive indices",
    ". suppose our data @xmath6 takes values in @xmath67 .",
    "the set @xmath9 is commonly designed based on individual rejection regions @xmath68 , with @xmath69 as indicated in the previous section , in the conservative bonferroni approach , the @xmath70 is controlled at level @xmath45 by assuming @xmath71 .",
    "if the rejection regions are designed so that this probability is independent of @xmath21 whenever @xmath72 , then the condition boils down to @xmath73 for @xmath74 .",
    "generally , @xmath75 for a constant @xmath76 for some family of test statistics @xmath77 .",
    "while there is not much to do in the general case to improve on the bonferroni method , it is possible to improve power if @xmath0 is structured and one has prior knowledge about way the active hypotheses are organized relative to this structure . in this paper",
    ", we consider a coarse - to - fine framework in which @xmath0 is provided with a partition @xmath78 , so that @xmath79 , where the subsets @xmath80 ( which we will call cells ) are non - overlapping . for @xmath81 , we let @xmath55 denote the unique cell @xmath42 that contains it .",
    "the `` coarse '' step selects cells likely to contain active indices , followed by a `` fine '' step in which a bonferroni or equivalent procedure is applied only to hypotheses included in the selected cells .",
    "more explicitly , we will associate a rejection region @xmath82 to each @xmath83 and consider the discovery set @xmath84 we will say that a cell @xmath42 is active if and only if @xmath85 , which we shall also express as @xmath86 , implicitly defining @xmath87 as the logical  and \" of all @xmath88 . we will also consider the double null hypothesis @xmath89 of @xmath21 belonging in an inactive cell ( which obviously implies that @xmath21 is inactive too ) , and we will let @xmath90 be the set of such @xmath21 s .",
    "let @xmath91 denote the size of the largest cell in @xmath78 and @xmath47 be the number of active cells .",
    "we will develop our procedure under the assumption that @xmath47 is known , or , at least bounded from above . while this can actually be a plausible assumption in practice",
    ", we will relax it in section [ sec:5 ] in which we will design a procedure to estimate a bound on @xmath47",
    ". then under these assumptions we have the following result :    [ prop : first.bound ] with @xmath92 defined by : @xmath93    this is just the bonferroni bound applied to the decomposition @xmath94 so that @xmath95 and the proposition results from @xmath96 and @xmath97 .",
    "the sets @xmath82 and @xmath98 will be designed using statistics @xmath99 and @xmath26 setting @xmath100 $ ] and @xmath101 $ ] for some constants @xmath50 and @xmath51 , and assuming that the distribution of @xmath102 ( resp .",
    "@xmath26 ) is independent of @xmath21 for @xmath103 ( resp .",
    "@xmath104 ) . letting @xmath105 for @xmath106 and @xmath107 for @xmath108 , the previous upper bound becomes @xmath109    in the following sections our goal will be to design @xmath50 and @xmath51 such that this upper bound is smaller than a predetermined level @xmath45 .",
    "controlling the second term will lead to less conservative choices of the constant @xmath51 ( compared to the bonferroni estimate ) , as soon as @xmath110 ( or @xmath54 if all cells have comparable sizes ) .",
    "depending on the degree of clustering , the probability @xmath111 of false detection in the two - step procedure can be made much smaller than @xmath112 without harming the true detection rate and the coarse - to - fine procedure will yield an increase in power for a given fwer .",
    "we require tight estimates of @xmath111 and taking into account the correlation between @xmath56 and @xmath26 is necessary to deal with `` survivorship bias . ''",
    "in this section , the observation is a realization of an i.i.d .",
    "family of random variables @xmath113 where the @xmath114 s are real - valued and the variables @xmath115 is a high - dimensional family of variables indexed by the set @xmath0 .",
    "we assume that the distribution of @xmath116 , are independent and centered gaussian , with variance @xmath117 , and that @xmath118 where @xmath119 are i.i.d .",
    "gaussian with variance @xmath120 and @xmath121 , are unknown real coefficients",
    ". we will denote by @xmath122 the vector @xmath123 and by @xmath124 where @xmath125 is the vector composed by ones repeated @xmath7 times .",
    "we also let @xmath126 and @xmath127 , so that @xmath128    finally , we will denote by @xmath129 the common variance of @xmath130 and assume that it is known ( or estimated from the observed data ) .      for @xmath81 ,",
    "we denote by @xmath131 the orthogonal projection on the subspace @xmath132 spanned by the two vectors @xmath133 and @xmath125 .",
    "we will also denote by @xmath134 ( @xmath83 ) the orthogonal projection on the subspace @xmath135 spanned by the vectors @xmath133 , @xmath136 , and @xmath125 .",
    "the scores at the @xmath42 level and @xmath21 level will be respectively : @xmath137 and @xmath138 ( the projections are simply obtained by least - square regression of @xmath122 on @xmath139 , for @xmath134 and on @xmath133 for @xmath131 . ) we now provide estimates of @xmath140 for @xmath106 and @xmath141 and @xmath142 for @xmath104 .",
    "note that , because we consider residual sums of squares , we here use large values of the scores in the rejection regions ( instead of small values in the introduction and other parts of the paper ) , hopefully without risk of confusion .",
    "[ prop:1 ] for all @xmath50 and @xmath51 : @xmath143 where @xmath144 is the cdf of a @xmath145 distribution evaluated at @xmath146 and : @xmath147 moreover @xmath148 where @xmath149 is the c.d.f . of a chi - squared distribution with @xmath150 degrees of freedom .    for @xmath106 and @xmath151 , we can write @xmath152 because @xmath153 and @xmath154 .",
    "consider the conditional probability : @xmath155    the conditional distribution of @xmath122 given @xmath156 is gaussian @xmath157 ( where @xmath158 is the @xmath7-dimensional identity matrix ) .",
    "denote by @xmath159 the projection on the orthogonal complement of @xmath160 in @xmath132 and by @xmath161 the projection on the orthogonal complement of @xmath162 in @xmath135 , so that @xmath163 and @xmath164 this implies that : @xmath165 at this stage , applying cochran s theorem to @xmath166 and @xmath167 , which are conditionally independent given @xmath168 , reduces the problem to finding an upper bound for : @xmath169 where @xmath170 is @xmath171 and @xmath172 is @xmath173 , and the two variables are independent .",
    "let us write this probability as @xmath174 which is less than : @xmath175 ( here , @xmath176 refers to the expectation with respect to @xmath177 . )    consider the first term in the sum : @xmath178",
    ". this term can be re - written as : @xmath179 at this stage , we will use the following tail inequality for @xmath180 random variables : @xmath181 for any @xmath182 .",
    "we apply this result to @xmath183 and @xmath184 to get the upper bound : @xmath185 since the density of a @xmath173 is proportional to @xmath186 , the term in @xmath187 will cancel in the last integral ( expectation ) . using a simple change of variables in the remaining integral , we have as a final upper bound : @xmath188 where @xmath144 is the cdf of a beta(a , b ) evaluated at @xmath146 .",
    "+ the second upper - bound , for @xmath189 , is easily obtained , the proof being left to the reader .",
    "this leads us immediately to the following corollary :    [ cor:2 ] with the thresholds @xmath50 and @xmath51 , an upper bound of the fwer is : @xmath190    figure [ fig : level.curves ] provides an illustration of the level curves associated to the above fwer upper bound .",
    "more precisely , it illustrates the tradeoff between the conservativeness at the cell level and the individual index level . in the next section , the optimization for power will be made along these level lines .",
    "figure 1 also provides the value of the bonferroni - holm threshold . for the coarse - to - fine procedure to be less conservative than the bonferroni - holm approach , we need the index - level threshold to be smaller , i.e. , the optimal point on the level line to be chosen below the corresponding dashed line .",
    "level curves of the upper bound of the fwer for the levels 0.2 ( blue ) , 0.1 ( green ) and 0.05 ( red ) .",
    "the horizontal dashed lines represent the thresholds at the individual level for a bonferroni - holm test , with corresponding colors . ]    the derivation of is based on the assumption that we have a fixed cell size ( across all the cells ) , which is not needed . in the case where the size of the cell is varying , it is easy to generalize the previous upper bound . letting @xmath191 it suffices to replace @xmath192 in with @xmath193 where @xmath50 does not depend on the cell @xmath42 .",
    "equation provides a constraint on the pair @xmath52 to control the fwer at a given level @xmath194 .",
    "we now show how to obtain `` optimal '' thresholds @xmath195 that maximize discovery subject to this constraint .",
    "the discussion will also help understanding how active indices clustering in cells improve the power of the coarse - to - fine procedure .",
    "the conditional distribution of @xmath122 given @xmath196 is @xmath197 with @xmath153 .",
    "it follows from this that , conditionally to these variables , @xmath198 follows a non - central chi - square distribution @xmath199 , with @xmath200 where @xmath201 .",
    "using the fact that @xmath202 converges to @xmath203 we will work with the approximation @xmath204 with a similar analysis , and letting for @xmath205 , @xmath206 , we will assume that @xmath207 with @xmath208 we now have the simple lemma    [ prop:3 ] if @xmath209 and @xmath210 , then for all @xmath211 such that @xmath212 , i=1,2 @xmath213    this is based on the inequality @xcite , valid for @xmath214 : @xmath215    which implies @xmath216 as soon as @xmath217 , and on the simple lower - bound @xmath218    this proposition can be applied , in our case , to @xmath219 and @xmath220 .",
    "more concretely , we fix a target effect size @xmath170 ( the ratio of the effect of @xmath133 compared to the total variance of @xmath122 ) , and a target cluster size , @xmath150 , that represents the number of active loci that we expect to find in an active cell , and we take @xmath221 and @xmath222 to optimize the upper - bound in subject to the fwer constraint and @xmath223 and @xmath224 to find optimal constants @xmath52 for this target case .",
    "this is illustrated with numerical simulations in the next section .",
    "figures [ fig : digraph.1 ] compares the powers of the coarse - to - fine procedure and of the bonferroni - holm procedure under the parametric model described in the section .",
    "comparison of the power of different methods .",
    "we compare the detection rate of an individual active index for different number of active indices in the cell containing that index .",
    "the coarse - to - fine method is more powerful when the number of active indices is two or greater .",
    "this confirms the intuition that the more the clustering assumption is true , the more powerful is the coarse - to - fine method compared to bonferoni - holm approcach . ]",
    "the parameters chosen in our simulations were taken with our motivating application ( to gwas ) in mind .",
    "thinking of @xmath19 as a phenotype , and @xmath0 as a set of snp s , we assimilate cells @xmath83 to genes .",
    "we used @xmath225 and @xmath226 .",
    "the true number of active variables is 50 with a corresponding coefficient @xmath227 for each of them , and we generate the data according to the linear model described in this section with a variance noise that is equal to 10 .",
    "we assumed that we knew an upper bound @xmath47 for the number of active sets ( this assumption is relaxed in section [ sec:6 ] ) . to compute the optimal thresholds , some values for @xmath228 and @xmath229 have to be chosen ( this should not be based on observed data , since this would invalidate our fwer and power estimates ) . in our experiments , we optimize the upper bound on the probability for an active variable to be detected in an active cell by choosing @xmath230 and @xmath231 .",
    "this corresponds to an `` almost non noisy case '' where the effect size of the `` gene '' is two times the effect size of the `` snp '' .",
    "recall that @xmath12 denotes the random variable representing all the data , taking values in @xmath67 .",
    "we will build our procedure from user - defined _ scores _ , denoted @xmath229 ( at the locus level ) and @xmath228 ( at the cell level ) , both defined on @xmath67 , i.e. , functions of the observed data .",
    "moreover , we assume that there exists a group action of some group @xmath232 on @xmath67 , which will be denoted @xmath233 for example , if , like in the previous paragraph , one takes @xmath234 and @xmath235 , we will take @xmath232 to be the permutation group of @xmath236 with @xmath237 to simplify the discussion , we will assume that @xmath238 is finite and denote by @xmath239 the uniform probability measure on @xmath238 , so that @xmath240 we note , however , that our discussion remains true if @xmath238 is a compact group , @xmath239 the right - invariant haar probability measure on @xmath238 and @xmath241 are continuous in @xmath242 .",
    "our running assumption will be that ,    1 .   for any @xmath106 , the joint distribution of @xmath243 is independent of @xmath244 .",
    "2 .   for any @xmath245 , the joint distribution of @xmath246 is independent of @xmath244 .",
    "we will also use the following well - known result .    [",
    "lem : basic ] let @xmath247 be a random variable and let @xmath248 denote the left limit of its cumulative distribution function , i.e. , @xmath249 .",
    "then , for @xmath250 $ ] , one has @xmath251 ( with equality if @xmath252 is continuous ) .",
    "we define the asymptotic scores at the cell and variable level by @xmath253 and @xmath254 @xmath255 and @xmath256 are the typical statistics used in randomized tests , estimating the proportion of scores that are higher than the observed one after randomization . for the coarse - to - fine procedure , we will need one more `` conditional '' statistic .    for a given constant @xmath50 , we define @xmath257 we then let @xmath258 we call our scores asymptotic in this section because exact expectations over @xmath239 can not be computed in general , and can only be obtained as limits of monte - carlo samples .",
    "the practical finite - sample case will be handled in the next section .",
    "we this notation , we let @xmath259 which depends on the choice of three constants , @xmath260 and @xmath261 .",
    "we then have :    [ th : ideal ] for all @xmath104 : @xmath262 and for all @xmath106 , @xmath263    this result tells us how to control the fwer for a two - level permutation test based on any scores in the ( generally intractable ) case in which we can exactly compute the test statistics , when we declare an index @xmath21 active if and only if @xmath264 and @xmath265 and @xmath266 .    for",
    ", we use a standard argument justifying randomization tests , that we provide here for completeness .",
    "if @xmath104 , we have @xmath267 + from the invariance assumption , we have @xmath268 it now remains to remark that @xmath269 where @xmath172 is the random variable on @xmath238 defined by @xmath270 , so that , by lemma [ lem : basic ] , @xmath271 which proves .",
    "+ let us now prove , assuming @xmath106 and letting @xmath141 .",
    "we write @xmath272 and find an upper bound for the right - hand side of the inequality . using the invariance assumption , we have , for all @xmath273 , @xmath274 notice that , since @xmath239 is right - invariant , we have @xmath275 and @xmath276    let @xmath277 denote the probability @xmath239 conditional to the event @xmath278 ( @xmath279 being fixed )",
    ". then @xmath280 where @xmath281 hence , lemma [ lem : basic ] implies that , for each @xmath279 : @xmath282 hence , @xmath283    applying lemma [ lem : basic ] to the random variable @xmath284 for the probability distribution @xmath239 , we immediately get @xmath285 so that @xmath286    as an immediate corollary , we have :    [ cor : fwer.ideal ] @xmath287    [ rem:1 ] even though @xmath238 is finite , it is a huge set in typical applications , and while lemma only provides inequalities for discrete distributions , we can safely ignore the discontinuity in practice and work as if the distributions to which we applied this lemma were continuous .",
    "doing so , it is easy to convince oneself , by inspecting the previous proof that our estimates become ( for @xmath106 , @xmath141 ) @xmath288 this implies that @xmath289 because we have also : @xmath290 this tells us that , conditional to @xmath291 , @xmath292 is uniform distributed on @xmath293 $ ] .",
    "as mentioned above , this result does not have practical interest since it requires applying all possible permutations to the data . in practice ,",
    "a random subset of permutations is picked instead , and we will develop the related theory in the next section ( using these inequalities as intermediary results in our proofs ) .",
    "we now replace @xmath41 , @xmath294 and @xmath295 with monte - carlo estimates and describe how the upper bounds in theorem [ th : ideal ] need to be modified .    for a positive integer @xmath296 , we let @xmath297 denote the @xmath296-fold product measure on @xmath238 , whose realizations are @xmath296 independent group elements @xmath298",
    ". we will use the notation @xmath299 and @xmath300 to denote probability or expectation for the joint distribution of @xmath8 and @xmath242 ( i.e. , @xmath301 ) .",
    "we will also denote by @xmath302 the empirical measure @xmath303 with this notation , we let @xmath304 @xmath305 and @xmath306 where @xmath307 we can now define @xmath308 and state :    [ th : sample ] making the continuous approximation described in remark [ rem:1 ] , the following holds . for @xmath104 , @xmath309 and , for @xmath106 and @xmath141 , @xmath310    [ cor : sample ] the fwer for the randomized test is controlled by @xmath311    we start with which is simpler and standard .",
    "let @xmath104 .",
    "conditionally to @xmath312 , @xmath313 follows a binomial distribution @xmath314 ( with @xmath295 defined by equation ) , so that @xmath315 } } \\binom{k}{j } \\mathbb e\\left(t_v({\\mathbf u})^j(1-t_v({\\mathbf u}))^{k - j}\\right)\\ ] ] where @xmath316}$ ] denotes the integral part .",
    "the continuous approximation implies that @xmath256 is uniformly distributed , so that @xmath317 yielding @xmath318}}{k } \\leq { \\theta_v}'.\\ ] ] + we now consider and take @xmath106 , @xmath141 .",
    "we need to prove that : @xmath319    given @xmath312 , @xmath320 is the empirical mean of @xmath296 i.i.d bernoulli random variables ( @xmath321 ) with success probability @xmath255 .",
    "hoeffding s inequality @xcite implies that @xmath322 so : @xmath323 we now fix @xmath324 in @xmath325 and consider @xmath326 since this probability does not depend on which @xmath324 is chosen , we will estimate it , without loss of generality , for @xmath327 , which will simplify the notation . for this , notice that @xmath328 and also that @xmath329 now we use hoeffding s inequality to obtain @xmath330 the same upper - bound applies to @xmath331 by taking the expectation with respect to @xmath332 , and one deduces from this that @xmath333 introduce @xmath334 on the event @xmath335",
    "one has @xmath336 moreover , we have @xmath337 , by applying lemma [ lem : basic ] to the random variable @xmath338 under the distribution @xmath339 .",
    "this implies that , on @xmath340 , we have @xmath341 which implies @xmath342 we now provide an estimate for the last term in .",
    "we have @xmath343 now write @xmath344 given @xmath312 , the probability ( for @xmath239 ) of the event @xmath345 is @xmath346 and @xmath347 follows a binomial distribution @xmath348 .",
    "we make the continuous approximation ( remark [ rem:1 ] ) to write @xmath349 , and to use the fact that @xmath350 is uniformly distributed on @xmath293 $ ] conditionally to @xmath351 , so that @xmath352 is uniformly distributed on @xmath353 $ ] given @xmath354 .",
    "this implies @xmath355}}\\binom{k } { i } p^{i}{(1-p)}^{k - i}\\right)dp\\\\ & \\leq \\frac{1}{(k+1)({\\theta_g}+{\\varepsilon_g})}\\sum_{i=0}^{{[k({\\theta_g}+{\\varepsilon_g}){\\theta_v}]}}\\left(\\int_{0}^{1}\\binom{k+1 } { i } p^{i}{(1-p)}^{k - i}dp\\right)\\\\ &   = \\frac{{[k({\\theta_g}+{\\varepsilon_g}){\\theta_v}]}+1}{(k+1)({\\theta_g}+{\\varepsilon_g})}\\end{aligned}\\ ] ] since each of the integrals is equal to 1 ( they are densities of beta distributions ) . from",
    ", we find @xmath356 which , combined with equations and completes the proof of the theorem .      for the simulations",
    ", we generated data according to the parametric model described in section [ sec:3 ] , and compared the detection rate using the non - parametric approach to the one obtained with thresholds optimized as described in section [ sec:3 ] .",
    "we fixed the ratio between the non - parametric thresholds @xmath50 and @xmath51 to coincide with the ratio between the type i errors at the cell and index levels in the parametric case , i.e. , @xmath357 for @xmath106 , where @xmath358 are the scores and thresholds designed for the parametric case .",
    "fixing @xmath359 and the fwer uniquely determines the thresholds .",
    "figure [ fig : digraph.0 ] provides a comparison between the coarse - to - fine approaches ( parametric and non - parametric ) and bonferroni - holm . in figures [ fig : digraph.4 ] and [ fig :",
    "digraph.5 ] , the non - parametric coarse - to - fine method is compared with bonferroni - holm for two different index - level effect sizes . using the notation of section [ sec:3 ] ,",
    "the cell - level effect size is defined by @xmath360 while @xmath361 at the index level .",
    "the range of index - level effect sizes we consider in these simulation is similar to the one observed in typical genome - wide association studies .             improves the performance of the bonferroni - holm method .",
    "the coarse - to - fine method is performs better at levels that correspond to two or more active indices per cell . ]",
    "we now focus on the issue of estimating the number of active cells , @xmath47 , from observed data , since this number intervenes in our fwer estimates .",
    "we use a method inspired from @xcite for the estimation of false discovery rates , adapted to our context . our estimation will be made based on cell statistics @xmath362 under the following setting .    * if @xmath363 ( @xmath42 is inactive ) , then @xmath41 is uniformly distributed . * if @xmath364 are inactive , then @xmath365 , @xmath366 are independent .",
    "these assumptions will be justified in section [ sec : justify ] .",
    "we will also assume that @xmath41 takes large values when @xmath42 is active , so that , for a suitable non conservative threshold @xmath367 , we have @xmath368 . to simplify the argument",
    ", we will actually make the approximation that :    * there exists @xmath369 such that @xmath370 if @xmath371 .    for @xmath250 $ ] , we define @xmath372 .",
    "let @xmath373 be the set of active cells , and @xmath374 .",
    "note that @xmath375 .",
    "then , for @xmath376 , @xmath377 we therefore have , for @xmath376 , @xmath378 where @xmath379 is a centered random variable . the following proposition states that the process @xmath380 for @xmath376 has the covariance structure of a brownian bridge .",
    "+    [ prob : cov ] under assumptions a1 to a3 , we have , for @xmath381 , @xmath382    since @xmath383 , one has @xmath384    if @xmath385 , then @xmath386 , and for @xmath387 : @xmath388 finally , from , we get @xmath389 which concludes the proof .",
    "we now make a gaussian approximation for large @xmath78 of the vector @xmath390 with @xmath391 , with @xmath392 .",
    "[ prop : clt ] using the previous notation , @xmath393 when @xmath394 diverges to infinity , where @xmath395 is the covariance matrix with entries : @xmath396    our assumptions ensure that @xmath172 satisfies a central limit theorem conditionally to @xmath19 , with a limit , @xmath397 that is independent of the value of @xmath8 .",
    "this implies that the limit is also unconditional .",
    "we are now able to present our principal result which provides a high - probability upper bound for @xmath47 .",
    "[ th : j ] let @xmath398 be a randomization variable , independent of @xmath362 . for @xmath399 and @xmath400 ,",
    "define @xmath401    then @xmath402 where @xmath403 .    as a consequence ,",
    "given @xmath404 , let @xmath405 . then @xmath406 is such that @xmath407 ( we use a randomly sampled value of @xmath408 ) .",
    "let us now prove this result .",
    "we know from proposition [ prop : clt ] that the vector @xmath409 where @xmath410 then , since min is a continuous function on @xmath411 , we deduce that : @xmath412 but : @xmath413 the process @xmath414 , @xmath415 is a martingale and @xmath416 is a submartingale for all @xmath417 s . applying doob s inequality ,",
    "then optimizing over @xmath418 s finally gives : @xmath419    it remains to prove that @xmath420 but : @xmath421 then : @xmath422 solving the quadratic inequality for @xmath423 , one finds that @xmath424 is equivalent to @xmath425 , which completes the proof .",
    "the previous section provided us with an estimator @xmath426 in such that @xmath427 with probability larger than @xmath428 , which implies that @xmath429 with probability @xmath428 at least .",
    "we previously chose constants @xmath50 and @xmath51 by optimizing the detection rate on a well - chosen alternative hypothesis subject to the upper - bound being less than a significance level @xmath45 .",
    "this was done using a deterministic upper - bound of @xmath47 , but can not be directly applied with a data - based estimation of @xmath47 since this would yield data - dependent constant @xmath50 and @xmath51 , which can not be plugged into the definition of the set @xmath92 without invalidating our estimation of the fwer . in other terms , if , for a fixed number @xmath430 , one defines @xmath431 to be the discovery set obtained by optimizing @xmath50 and @xmath51 subject to @xmath432 , our previous results imply that @xmath433 for all @xmath434 , but not necessarily that @xmath435 .",
    "a simple way to address this issue is to replace @xmath436 with @xmath437 because @xmath438 with probability at least @xmath428 , we have @xmath439 so that @xmath440 controls the fwer at level @xmath441 as intended .",
    "we check that conditions a1 and a2 are satisfied for the two situations that we consider in this paper . in the example from section [ sec:3 ] , we can take ( using the same notation and introducing the c.d.f . of a chi - square distribution ) @xmath442 ( recall that @xmath134 is the orthogonal projection on the space generated by @xmath443 and @xmath444 .",
    "we also let @xmath445 be the empirical variance of @xmath446 . )",
    "note that the conditional distribution of @xmath41 given @xmath447 is always uniform over @xmath293 $ ] and therefore does not depend on @xmath448 , which proves that @xmath41 and @xmath446 are independent .",
    "similarly , taking @xmath449 , @xmath365 and @xmath366 are conditionally independent given @xmath446 ( because @xmath450 and @xmath451 are independent ) .",
    "but @xmath452 and @xmath453 being conditionally independent given @xmath446 and each of them independent of @xmath446 implies that the three variables are mutually independent . + the same argument can be applied to the non - parametric case , when ( now using notation from that section ) one assumes that scores are such that @xmath454 , and uses to simplify the discussion the statistic @xmath455 assuming , in addition , the following .",
    "if we denote by @xmath456 the space where the random variable @xmath457 takes its values , there exists a group @xmath458 , a group isomorphism @xmath459 between @xmath238 and @xmath458 and a group action of @xmath458 on @xmath456 that we will denote by @xmath460 satisfying the two following conditions :    * the distribution of @xmath457 is invariant under the action @xmath460 .",
    "* @xmath461    for example , for permutation tests , the group @xmath458 is simply the group of permutations @xmath238 itself .",
    "the isomorphism @xmath459 is the inverse map @xmath462 .",
    "the group action @xmath460 is just the permutation of the observations .",
    "finally , @xmath228 can be any score that is symmetric with respect to the observations . + assuming these conditions",
    ", one can immediately apply lemma @xmath463 to conclude .",
    "given a partition of the space of hypotheses , the basic assumption which allows the coarse - to - fine multiple testing algorithm to obtain greater power than the bonferroni - holm approach at the same fwer level is that the distribution of the numbers of active hypotheses across the cells of the partition is non - uniform .",
    "the gap in performance is then roughly proportional to the degree of skewness .",
    "the test derived for the parametric model can be seen as a generalization to coarse - to - fine testing of the f - test for determining whether a set of coefficients is zero in a regression model ; the testing procedure derived for the non - parametric case is a generalization of permutation tests to a multi - level multiple testing .",
    "this scenario was motivated by the situation encountered in genome - wide association studies , where the hypotheses are associated with genetic variations ( e.g. , snps ) , each having a location along the genome , and the cells are associated with genes . in principle , our coarse - to - fine procedure will then detect more active variants to the extent that these variants cluster in genes .",
    "of course this extent will depend in practice on many factors , including effect sizes , the representation of the genotype ( i.e. , the choice of variants to explore ) as well as the phenotype , and complex interactions within the genotype .",
    "it may be very difficult and uncommon to know anything specific about the expected nature of the combinatorics between genes and variants . in some sense",
    ", `` the proof is in the pudding , '' in that one can simply try both the standard and coarse - to - fine approaches and compare the sets of variants detected .",
    "given tight control of the fwer , everything found is likely to be real .",
    "indeed , the analytical bounds obtained here make this comparison possible , at least under linear model commonly used in gwas and in a general non - parametric model under invariance assumptions .",
    "looking ahead , we have only analyzed the coarse - to - fine approach for the simplest case of two - levels and a true partition , i.e. , non - overlapping cells .",
    "the methods for controlling the fwer for both the parametric and non - parametric cases generalize naturally to multiple levels assuming nested partitions .",
    "the analytical challenge is to generalize the coarse - to - fine approach to overlapping cells , even for two levels : while our methods for controlling the fwer remain valid , they are likely to become overly conservative if cell overlap .",
    "this case is of particular interest in applications , where genes are grouped into overlapping `` pathways . '' for example , in `` systems biology , '' cellular phenotypes , especially complex diseases such as cancer , are studied in the context of these pathways and mutated genes and other abnormalities are in fact known to cluster in pathways ; indeed , this is the justification for a pathway - based analysis .",
    "hence the clustering properties may be stronger for variants or genes in pathways than for variants in genes .",
    "michael ashburner , catherine  a ball , judith  a blake , david botstein , heather butler , j  michael cherry , allan  p davis , kara dolinski , selina  s dwight , janan  t eppig , et  al .",
    "gene ontology : tool for the unification of biology .",
    ", 25(1):2529 , 2000 ."
  ],
  "abstract_text": [
    "<S> we analyze control of the familywise error rate ( fwer ) in a multiple testing scenario with a great many null hypotheses about the distribution of a high - dimensional random variable among which only a very small fraction are false , or `` active '' . in order to improve power relative to conservative bonferroni bounds , </S>",
    "<S> we explore a coarse - to - fine procedure adapted to a situation in which tests are partitioned into subsets , or `` cells '' , and active hypotheses tend to cluster within cells . </S>",
    "<S> we develop procedures for a standard linear model with gaussian data and a non - parametric case based on generalized permutation testing , and demonstrate considerably higher power than bonferroni estimates at the same fwer when the active hypotheses do cluster . </S>",
    "<S> the main technical difficulty arises from the correlation between the test statistics at the individual and cell levels , which increases the likelihood of a hypothesis being falsely discovered when the cell that contains it is falsely discovered ( survivorship bias ) . </S>",
    "<S> this requires sharp estimates of certain quadrant probabilities when a cell is inactive .    , </S>"
  ]
}