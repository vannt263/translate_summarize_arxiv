{
  "article_text": [
    "there are many reasons why computing an integral like @xmath0 where @xmath1 is a probability measure , may prove intractable , from the shape of the domain @xmath2 to the dimension of @xmath2 ( and @xmath3 ) , to the complexity of one of the functions @xmath4 or @xmath5 .",
    "standard numerical methods may be hindered by the same reasons .",
    "similar difficulties ( may ) occur when attempting to find the extrema of @xmath5 over the domain @xmath2 .",
    "this is why the recourse to monte carlo methods may prove unavoidable : exploiting the probabilistic nature of @xmath5 and its weighting of the domain @xmath2 is often the most natural and most efficient way to produce approximations to integrals connected with @xmath5 and to determine the regions of the domain @xmath2 that are more heavily weighted by @xmath5 .",
    "the monte carlo approach @xcite emerged with computers , at the end of wwii , as it relies on the ability of producing a large number of realisations of a random variable distributed according to a given distribution , taking advantage of the stabilisation of the empirical average predicted by the law of large numbers .",
    "however , producing simulations from a specific distribution may prove near impossible or quite costly and therefore the ( standard ) monte carlo may also face intractable situations .",
    "an indirect approach to the simulation of complex distributions and in particular to the curse of dimensionality met by regular monte carlo methods is to use a markov chain associated with this target distribution , using markov chain theory to validate the convergence of the chain to the distribution of interest and the stabilisation of empirical averages @xcite .",
    "it is thus little surprise that markov chain monte carlo ( mcmc ) methods have been used for almost as long as the original monte carlo techniques , even though their impact on statistics has not been truly felt until the very early 1990s .",
    "a comprehensive entry about the history of mcmc methods can be found in @xcite .",
    "the paper is organised as follows : in section [ sec : algo ] , we define and justify the metropolis ",
    "hastings algorithm , along historical notes about its origin . in section [ sec : zimp ] , we provide details on the implementation and calibration of the algorithm . a mixture example is processed in section [ sec : ex ] .",
    "section [ sec : ext ] includes recent extensions of the standard metropolis ",
    "hastings algorithm , while section [ sec : con ] concludes about further directions for markov chain monte carlo methods when faced with complex models and huge datasets .",
    "r0.5     given a probability density @xmath5 called the _ target _ , defined on a state space @xmath2 , and",
    "computable up to a multiplying constant , @xmath6 , the metropolis ",
    "hastings algorithm , named after @xcite and @xcite , proposes a generic way to construct a markov chain on @xmath2 that is ergodic and stationary with respect to @xmath5meaning that , if @xmath7 , then @xmath8and that therefore converges in distribution to @xmath5 . while there are other generic ways of delivering markov chains associated with an arbitrary stationary distribution , see , e.g. , @xcite , the metropolis ",
    "hastings algorithm is the workhorse of mcmc methods , both for its simplicity and its versatility , and hence the first solution to consider in intractable situations .",
    "the main motivation for using markov chains is that they provide shortcuts in cases where generic sampling requires too much effort from the experimenter . rather than aiming at the  big picture \" immediately , as an accept - reject algorithm",
    "would do @xcite , markov chains construct a progressive picture of the target distribution , proceeding by local exploration of the state space @xmath2 until all the regions of interest have been uncovered .",
    "an analogy for the method is the case of a visitor to a museum forced by a general blackout to watch a painting with a small torch . due to the narrow beam of the torch ,",
    "the person can not get a global view of the painting but can proceed along this painting until all parts have been seen .",
    "r0.5     before describing the algorithm itself , let us stress the probabilistic foundations of markov chain monte carlo ( mcmc ) algorithms : the markov chain returned by the method , @xmath9 is such that @xmath10 is converging to @xmath5 .",
    "this means that the chain can be considered as a sample , albeit a dependent sample , and approximately distributed from @xmath5 . due to the markovian nature of the simulation ,",
    "the first values are highly dependent on the starting value @xmath11 and usually removed from the sample as _ burn - in _ or _ warm - up_. while there are very few settings where _ the _ time when the chain _ reaches _ stationarity can be determined , see , e.g. , @xcite , there is no need to look for such an instant since the empirical average @xmath12 converges almost surely to @xmath13 , no matter what the starting value , if the markov chain is ergodic , i.e. , forgets about its starting value .",
    "this implies that , in theory , simulating a markov chain is intrinsically equivalent to a standard i.i.d .",
    "simulation from the target , the difference being in a loss of efficiency , i.e. , in the necessity to simulate more terms to achieve a given variance for the above monte carlo estimator .",
    "the foundational principle for mcmc algorithms is thus straightforward , even though the practical implementation of the method may prove delicate or in cases impossible .    without proceeding much further into markov chain theory ,",
    "we stress that the existence of a stationary distribution for a chain implies this chain automatically enjoys a strong stability called _",
    "irreducibility_. namely , the chain can move all over the state space , i.e. , can eventually reach any region of the state space , no matter its initial value .      the metropolis ",
    "hastings algorithm associated with a target density @xmath5 requires the choice of a conditional density @xmath14 also called _ proposal or candidate kernel_. the transition from the value of the markov chain @xmath15 at time @xmath16 and its value at time @xmath17 proceeds via the following transition step :    [ al : mh ] * metropolis  hastings * +    given @xmath18 ,    1 .",
    "generate @xmath19 .",
    "2 .   take @xmath20 where @xmath21    r0.5     then , as shown in @xcite , this transition preserves the stationary density @xmath5 if the chain is irreducible , that is , if @xmath14 has a wide enough support to eventually reach any region of the state space @xmath2 with positive mass under @xmath5 .",
    "a sufficient condition is that @xmath14 is positive everywhere .",
    "the very nature of accept - reject step introduced by those authors is therefore sufficient to turn a simulation from an almost arbitrary proposal density @xmath14 into a generation that preserves @xmath5 as the stationary distribution .",
    "this sounds both amazing and too good to be true ! but it is true , in the theoretical sense drafted above . in practice ,",
    "the performances of the algorithm are obviously highly dependent on the choice of the transition @xmath14 , since some choices see the chain unable to converge in a manageable time .      to capture the mechanism behind the algorithm ,",
    "let us consider an elementary example :    [ ex : toysin ] our target density is a perturbed version of the normal @xmath22 density , @xmath23 , @xmath24 and our proposal is a uniform @xmath25 kernel , @xmath26 implementing this algorithm is straightforward : two functions to define are the target and the transition    .... target = function(x ) {    sin(x)^2*sin(2*x)^2*dnorm(x ) }    metropolis = function(x , alpha=1 ) {    y = runif(1,x - alpha , x+alpha )    if ( runif(1)>target(y)/target(x ) ) y = x    return(y ) } ....    and all we need is a starting value    .... t=10 ^ 4 x = rep(3.14,t )                                                                             for ( t in 2:t ) x[t]=metropolis(x[t-1 ] )                                                     ....    which results in the histogram of figure [ fig : toysin ] , where the target density is properly normalised by a numerical integration . if we look at the sequence @xmath27 returned by the algorithm , it changes values around @xmath28 times .",
    "this means that one proposal out of two is rejected .",
    "if we now change the scale of the uniform to @xmath29 , the chain @xmath27 takes more than @xmath30 different values , however the histogram in figure [ fig : kapitalsin ] shows a poor fit to the target in that only one mode is properly explored .",
    "the proposal lacks the power to move the chain far enough to reach the other parts of the support of @xmath31 .",
    "a similar behaviour occurs when we start at @xmath32 .",
    "a last illustration of the possible drawbacks of using this algorithm is shown on figure [ fig : weaksin ] : when using the scale @xmath33 the chain is slow in exploring the support , hence does not reproduce the correct shape of @xmath5 after @xmath34 iterations .    from this example",
    ", we learned that some choices of proposal kernels work well to recover the shape of the target density , while others are poorer , and may even fail altogether to converge .",
    "details about the implementation of the algorithm and the calibration of the proposal @xmath14 are detailed in section [ sec : zimp ] .",
    "the initial geographical localisation of the mcmc algorithms is the nuclear research laboratory in los alamos , new mexico , which work on the hydrogen bomb eventually led to the derivation metropolis algorithm in the early 1950s .",
    "what can be reasonably seen as the first mcmc algorithm is indeed the metropolis algorithm , published by @xcite .",
    "those algorithms are thus contemporary with the standard monte carlo method , developped by ulam and von neumann in the late 1940s .",
    "( nicolas metropolis is also credited with suggesting the name ",
    "monte carlo ",
    ", see @xcite , and published the very first monte carlo paper , see @xcite . )",
    "this metropolis algorithm , while used in physics , was only generalized by @xcite and @xcite towards statistical applications , as a method apt to overcome the curse of dimensionality penalising regular monte carlo methods .",
    "even those later generalisations and the work of hammersley , clifford , and besag in the 1970 s did not truly impact the statistical community until @xcite experimented with the gibbs sampler for image processing , @xcite created a form of gibbs sampler for latent variable models and @xcite extracted the quintessential aspects of gibbs sampler to turn it into a universal principle and rekindle the appeal of the metropolis ",
    "hastings algorithm for bayesian computation and beyond .",
    "when working with a metropolis  hastings algorithm , the generic nature of algorithm [ al : mh ] is as much an hindrance as a blessing in that the principle remains valid for almost every choice of the proposal @xmath14 .",
    "it thus does not give indications about the calibration of this proposal .",
    "for instance , in example [ ex : toysin ] , the method is valid for all choices of @xmath35 but the comparison of the histogram of the outcome with the true density shows that @xmath35 has a practical impact on the convergence of the algorithm and hence on the number of iterations it requires .",
    "figure [ fig : acfsin ] illustrates this divergence in performances via the autocorrelation graphs of three chains produced by the r code in example [ ex : toysin ] for three highly different values of @xmath36 .",
    "it shows why @xmath37 should be prefered to the other two values in that each value of the markov chain contains  more \" information in that case .",
    "the fundamental difficulty when using the metropolis ",
    "hastings algorithm is in uncovering which calibration is appropriate without engaging into much experimentation or , in other words , in an as automated manner as possible .",
    "r0.5     a ( the ? ) generic version of the metropolis ",
    "hastings algorithm is the _ random walk metropolis ",
    "hastings algorithm _ , which exploits as little as possible knowledge about the target distribution , proceeding instead in a local if often myopic manner . to achieve this",
    ", the proposal distribution @xmath14 aims at a _",
    "local _ exploration of the neighborhood of the current value of the markov chain , i.e. , simulating the proposed value @xmath38 as @xmath39 where @xmath40 is a random perturbation with distribution @xmath41 , for instance a uniform distribution as in example [ ex : toysin ] or a normal distribution .",
    "if we call _ random walk metropolis ",
    "hastings algorithms _ all the cases when @xmath41 is symmetric , the acceptance probability in algorithm [ al : mh ] gets simplified into @xmath42    while this probability is independent of the scale of the proposal @xmath41 , we just saw that the performances of the algorithm are quite dependent on such quantities .",
    "in order to achieve an higher degree of efficiency , i.e. , towards a decrease of the monte carlo variance , @xcite studied a formal gaussian setting aiming at the ideal acceptance rate .",
    "indeed , example [ ex : toysin ] showed that acceptance rates that are either  too high \" or  too low \"",
    "slow down the convergence of the markov chain .",
    "they then showed that the ideal variance in the proposal is twice the variance of the target or , equivalently , that the acceptance rate should be close to @xmath43 .",
    "while this rule is only an indication ( in the sense that it was primarily designed for a specific and asymptotic gaussian environment ) , it provides a golden rule for the default calibration of random walk metropolis ",
    "hastings algorithms .",
    "we now consider the alternative of the _ effective sample size _ for comparing and calibrating mcmc algorithms . even for a stationary markov chain ,",
    "using @xmath44 iterations does not amount to simulating an iid sample from @xmath5 that would lead to the same variability .",
    "indeed , the empirical average can not be associated with the standard variance estimator @xmath45 due to the correlations amongst the @xmath10 s . in this",
    "setting , the _ effective sample size _ is defined as the correction factor @xmath46 such that @xmath47 is the variance of the empirical average ) .",
    "this quantity can be computed as in @xcite and @xcite by @xmath48 where @xmath49 is the autocorrelation associated with the sequence @xmath50 , @xmath51 estimated by ` spectrum0 ` and ` effectivesize ` from the r library ` coda ` , via the spectral density at zero .",
    "a rough alternative is to rely on subsampling , as in @xcite , so that @xmath52 is approximately independent from @xmath10 .",
    "the lag @xmath53 is possibly determined in r via the autocorrelation function ` autocorr ` .    *",
    "( example [ ex : toysin ] continued ) * we can compare the markov chains obtained with @xmath36 against those two criteria :    .... > autocor(mcmc(x ) )              [ , 1 ]     [ , 2 ]     [ , 3 ] lag 0   1.0000000 1.0000000 1.0000000 lag 1   0.9672805 0.9661440 0.9661440 lag 5   0.8809364 0.2383277 0.8396924 lag 10 0.8292220 0.0707092 0.7010028 lag 50 0.7037832 -0.033926 0.1223127 > effectivesize(x )        [ , 1 ]        [ , 2 ]        [ , 3 ]    33.45704 1465.66551   172.17784   ....    this shows how much comparative improvement is brought by the value @xmath37 , but also that even this quasi - optimal case is far from an i.i.d . setting .      in practice , the above tools of ideal acceptance rate and of higher effective sample size give goals for calibrating metropolis  hastings algorithms",
    "this means comparing a range of values of the parameters involved in the proposal and selecting the value that achieves the highest target for the adopted goal . for a multidimensional parameter",
    ", global maximisation run afoul of the curse of dimensionality as exploring a grid of possible values quickly becomes impossible .",
    "the solution to this difficulty stands in running partial optimisations , with simulated ( hence controlled ) data , for instance setting all parameters but one fixed to the values used for the simulated data .",
    "if this is not possible , optimisation of the proposal parameters can be embedded in a metropolis - within - gibbs since for each step several values of the corresponding parameter can be compared via the metropolis ",
    "hastings acceptance probability .",
    "r.5     we refer the reader to chapter 8 of @xcite for more detailed descriptions of the calibration of mcmc algorithms , including the use of adaptive mecchanisms .",
    "indeed , calibration is normaly operated in a warm - up stage since , otherwise , if one continuously tune an mcmc algorithm according to its past outcome , the algorithm stops being markovian .",
    "in order to preserve convergence in an adaptive mcmc algorithm , the solution found in the literature for this difficulty is to progressively tone / tune down the adaptive aspect . for instance , @xcite propose a _ diminishing adaptation _ condition that states that the distance between two consecutive markov kernels must uniformly decrease to zero .",
    "for instance , a random walk proposal that relies on the empirical variance of the past sample as suggested in @xcite does satisfy this condition .",
    "an alternative proposed by @xcite proceeds by tuning the scale of a random walk for each component against the acceptance rate , which is the solution implemented in the ` amcmc ` package developed by @xcite .",
    "@xcite consider the special case of a mixture of a poisson and of a geometric distributions with the same mean parameter @xmath54 : @xmath55 where @xmath56 and @xmath57 .",
    "given @xmath58 observations @xmath59 and a prior decomposed into @xmath60 and @xmath61^{a_0 - 1}$ ] , @xmath62 being the default value , the likelihood function is available in closed form as @xmath63 where @xmath64 . in r code",
    ", this translates as    .... likelihood = function(x , lam , alp ) {    prod(alp*dpois(x , lam)+(1-alp)*dgeom(x , lam/(1+lam ) ) ) } posterior = function(x , lam , alp ) {    sum(log(alp*dpois(x , lam)+(1-alp)*dgeom(x,1/(1+lam))))-        log(lam)+dbeta(alp,.5,.5,log = true ) } ....    if we want to build a metropolis ",
    "hastings algorithm that simulates from the associated posterior , the proposal can proceed by either proposing a joint move on @xmath65 or moving one parameter at a time in a metropolis - within - gibbs fashion . in the first case , we can imagine a random walk in two dimensions , @xmath66 with an acceptance probability @xmath67 the metropolis ",
    "hastings r code would then be    .... metropolis = function(x , lam , alp , eps=1,del=1 ) {    prop = c(exp(rnorm(1,log(lam),sqrt(del*(1+log(lam)^2 ) ) ) ) ,            rbeta(1,1+eps*alp,1+eps*(1-alp ) ) )    rat = posterior(x , prop[1],prop[2])-posterior(x , lam , alp)+           dbeta(alp,1+eps*prop[2],1+eps*(1-prop[2]),log = true)-           dbeta(prop[2],1+eps*alp,1+eps*(1-alp),log = true)+           dnorm(log(lam),log(prop[1 ] ) ,                 sqrt(del*(1+log(prop[1])^2)),log = true)-           dnorm(log(prop[1]),log(lam ) ,                 sqrt(del*(1+log(lam)^2)),log = true)+           log(prop[1]/lam )    if ( log(runif(1))>rat ) prop = c(lam , alp )    return(prop ) } ....    where the ratio ` prop[1]/lam ` in the acceptance probability is just the jacobian for the log - normal transform . running the following r code    .... t=1e4 x = rpois(123,lambda=1 ) para = matrix(c(mean(x),runif(1)),nrow=2,ncol = t ) like = rep(0,t ) for ( t in 2:t ) {     para[,t]=metropolis(x , para[1,t-1],para[2,t-1],eps=.1,del=.1 )     like[t]=posterior(x , para[1,t],para[2,t ] ) } ....    then produced the histograms of figure [ fig:2dmet ] , after toying with the values of @xmath68 and @xmath69 to achieve a large enough average acceptance probability , which is provided by ` length(unique(para[1,]))/t ` the second version of the metropolis ",
    "hastings algorithm we can test is to separately modify @xmath54 by a random walk proposal , test whether or not it is acceptable , and repeat with @xmath35 : the r code is then very similar to the above one :    .... metropolis = function(x , lam , alp , eps=1,del=1 ) {    prop = exp(rnorm(1,log(lam),sqrt(del*(1+log(lam)^2 ) ) ) )    rat = posterior(x , prop , alp)-posterior(x , lam , alp)+           dnorm(log(lam),log(prop[1 ] ) ,                 sqrt(del*(1+log(prop[1])^2)),log = true)-           dnorm(log(prop[1]),log(lam ) ,                 sqrt(del*(1+log(lam)^2)),log = true)+           log(prop / lam )    if ( log(runif(1))>rat ) prop = lam    qrop = rbeta(1,1+eps*alp,1+eps*(1-alp ) )    rat = posterior(x , prop , qrop)-posterior(x , prop , alp)+           dbeta(alp,1+eps*qrop,1+eps*(1-qrop),log = true)-           dbeta(qrop,1+eps*alp,1+eps*(1-alp),log = true )    if ( log(runif(1))>rat ) qrop = alp    return(c(prop , qrop ) ) } ....",
    "r.5     in this special case , both algorithms thus return mostly equivalent outcomes , with a slightly more dispersed output in the case of the metropolis - within - gibbs version ( figure [ fig:12met ] ) . in a more general perspective , calibrating random walks in multiple dimensions may prove unwieldly , especially with large dimensions , while the metropolis - within - gibbs remains manageable .",
    "one drawback of the later is common to all gibbs implementations , namely that it induces higher correlations between the components , which means a slow convergence of the chain ( and in extreme cases no convergence at all ) .",
    "an extension of the random walk metropolis ",
    "hastings algorithm is based on the langevin diffusion solving @xmath70where @xmath71 is the standard brownian motion and @xmath72 denotes the gradient of @xmath73 , since this diffusion has @xmath74 as its stationary and limiting distribution . the algorithm is based on a discretised version of the above , namely @xmath75 for a discretisation step @xmath4 , which is used as a proposed value for @xmath76 , and accepted with the standard metropolis  hastings probability @xcite .",
    "this new proposal took the name of metropolis adjusted langevin algorithms ( hence mala ) . while computing ( twice ) the gradient of @xmath5 at each iteration requires extra time , there is strong support for doing so , as mala algorithms do provide noticeable speed - ups in convergence for most problems .",
    "note that @xmath31 only needs to be known up to a multiplicative constant because of the log transform .",
    "r.5     another extension of the metropolis ",
    "hastings algorithm is the particle mcmc ( or _ pmcmc _ ) , developed by @xcite .",
    "while we can not provide an introduction to particle filters here , see , e.g. , @xcite , we want to point out the appeal of this approach in state space models like hidden markov models ( hmm ) .",
    "this innovation is similar to the pseudo - marginal algorithm approach of @xcite , taking advantage of the auxiliary variables exploited by particle filters .    in the case of an hmm , i.e. , where a _ latent _ markov chain @xmath77 with density @xmath78 is associated with an _ observed _ sequence @xmath79 such that @xmath80 pmcmc applies as follows . at every iteration @xmath16 ,",
    "a value @xmath81 of the parameter @xmath82 is proposed , followed by a new value of the latent series @xmath83 generated from a particle filter approximation of @xmath84 . as the particle filter produces in addition @xcite an unbiased estimator of the marginal posterior of @xmath85 , @xmath86 , this estimator",
    "can be directly included in the metropolis ",
    "hastings ratio @xmath87 the validation of this substitution follows from the general argument of @xcite for pseudo - marginal techniques , even though additional arguments are required to establish that all random variables used therein are accounted for ( see @xcite and @xcite ) .",
    "we however stress that the general validation of those algorithm as converging to the joint posterior does not proceed from pseudo - marginal arguments .",
    "an extension of pmcmc called @xmath88 that approximates the sequential filtering distribution is proposed in @xcite .",
    "as illustrated by the previous section , there are many settings where computing the target density @xmath31 is impossible .",
    "another example is made of doubly intractable likelihoods @xcite , when the likelihood function contains a term that is intractable , for instance @xmath89 with an intractable normalising constant @xmath90 this phenomenon is quite common in graphical models , as for instance for the ising model @xcite .",
    "solutions based on auxiliary variables have been proposed ( see , e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) , but they may prove difficult to calibrate .    in such settings , @xcite developped an approach based on an idea of @xcite , designing a valid metropolis",
    " hastings algorithm that substitutes the intractable target @xmath91 with an unbiased estimator . a slight change to the metropolis ",
    "hastings acceptance ratio ensures that the stationary density of the corresponding markov chain is still equal to the target @xmath5 .",
    "indeed , provided @xmath92 is an unbiased estimator of @xmath93 when @xmath94 , it is rather straightforward to check that the acceptance ratio @xmath95 preserves stationarity with respect to an extended target ( see @xcite ) for details ) when @xmath96 , and @xmath97 . @xcite",
    "propose an alternative validation via auxiliary weights used in the unbiased estimation , assuming the unbiased estimator ( or the weight ) is generated conditional on the proposed value in the original markov chain .",
    "the performances of pseudo - marginal solutions depend on the quality of the estimators @xmath98 and are always poorer than when using the exact target @xmath5 .",
    "in particular , improvements can be found by using multiple samples of @xmath99 to estimate @xmath5 @xcite .",
    "the metropolis  hastings algorithm is to be understood as a default or off - the - shelf solution , meaning that ( a ) it rarely achieves optimal rates of convergence @xcite and may get into convergence difficulties if improperly calibrated but ( b ) it can be combined with other solutions as a baseline solution , offering further local or more rarely global exploration to a taylored algorithm . provided _ reversibility _",
    "is preserved , it is indeed valid to mix several mcmc algorithms together , for instance picking one of the kernels at random or following a cycle @xcite . unless a proposal is relatively expensive to compute or to implement , it rarely hurts to add an extra kernel into the mcmc machinery .",
    "this is not to state that the metropolis ",
    "hastings algorithm is the ultimate solution to all simulation and stochastic evaluation problems .",
    "for one thing , there exist settings where the intractability of the target is such that no practical mcmc solution is available .",
    "for another thing , there exist non reversible versions of those algorithms , like hamiltonian ( or hybrid ) monte carlo ( hmc ) @xcite .",
    "this method starts by creating a completly artificial variable @xmath100 , inspired by the momentum in physics , and a joint distribution on @xmath101 which energy  minus the log - density  is defined by the hamiltonian @xmath102 where @xmath103 is the so - called mass matrix . the second part in the target is called the kinetic energy , still by analogy with mechanics . when the joint vector @xmath101 is driven by hamilton s equations @xmath104 this dynamics preserves the joint distribution with density @xmath105 .",
    "if we could simulate _",
    "exactly _ from this joint distribution of @xmath101 , a sample from @xmath106 would be a by - product . in practice ,",
    "the equation is only solved approximately and hence requires a metropolis  hastings correction .",
    "its practical implementation is called the _ leapfrog approximation _ @xcite as it relies on a small discretisation step @xmath68 , updating @xmath100 and @xmath14 via a modified euler s method called the leapfrog that is reversible and preserves volume as well .",
    "this discretised update can be repeated for an arbitrary number of steps .",
    "the appeal of hmc against other mcmc solutions is that the value of the hamiltonian changes very little during the metropolis step , while possibly producing a very different value of @xmath14 . intuitively , moving along level sets in the augmented space is almost energy - free , but if those move proceeds far enough , the markov chain on @xmath14 can reach distant regions , thus avoid the typical local nature of regular mcmc algorithms .",
    "this strengthe explains in part why a statistical software like stan @xcite is mostly based on hmc moves .    as a last direction for new mcmc solutions ,",
    "let us point out the requirements set by big data , i.e. , in settings where the likelihood function can not be cheaply evaluated for the entire dataset .",
    "see , e.g. , @xcite , for recent entries on different parallel ways of handling massive datasets , and @xcite for delayed and prefetching mcmc techniques that avoid considering the entire likelihood at once ."
  ],
  "abstract_text": [
    "<S> this article is a self - contained introduction to the metropolis - hastings algorithm , this ubiquitous tool for producing dependent simulations from an arbitrary distribution . </S>",
    "<S> the document illustrates the principles of the methodology on simple examples with r codes and provides entries to the recent extensions of the method . </S>"
  ]
}