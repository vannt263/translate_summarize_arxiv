{
  "article_text": [
    "one success of network science has been to identify that some complex systems can be simplified by considering just the topology of the pairwise interactions between their parts . abstracting a complex system as a graph can bring physical insights and predictive power .",
    "yet these graphs can still be very complicated .",
    "network geometry is an approach which further abstracts the system by modelling the nodes of the network as points in a geometric space .",
    "most existing approaches use riemannian spaces , the simplest example of which is euclidean space . random geometric graphs ( rgg ) are graphs embedded in euclidean space @xcite .",
    "recently there has been much interest in geometric approaches to the study of networks in non - euclidean spaces @xcite .",
    "embedding in hyperbolic spaces can yield scale free , clustered networks with community structure illustrating the remarkable power that geometric approaches have to recover complex network properties .",
    "a well established geometric approach to data analysis is _",
    "multidimensional scaling _",
    "( mds ) , a technique to give data expressed as distances or similarities a spatial representation @xcite . in most mds analysis ,",
    "the space used for that spatial representation has been euclidean , and the technique , as usually described , requires a riemannian manifold , where the triangle inequality is maintained .",
    "mds has been used in network science , to fit models of rggs to networks from real data , for example , from protein interactions @xcite .",
    "normally , the mds algorithm takes as an argument pairwise distances between objects , so when applying it to simple networks , where only binary pairwise relations exist , these distances have to be inferred from the network structure . in the simplest euclidean case ( as in @xcite ) , the shortest path on the network is used as an estimate for the distances between vertices , from which mds is used to calculate coordinates .",
    "once these coordinates have been calculated , a new rgg can be built from them , and if it is similar to the original graph , the initial geometric assumption was a good one .    in this paper we will consider networks where each node is associated with a particular time and directed edges between nodes represent causal relations .",
    "such a network forms a * directed acyclic graph * ( dag)@xcite .",
    "instead of embedding a network in geometric space alone , the causal ordering of the nodes in a dag suggests that an embedding in space and time is needed .",
    "the causal structure of such a network has the same constraints as the causal structure of spacetime as used in special and general relativity @xcite.this suggests that the geometries used in relativity , which are pseudo - riemannian are the appropriate ones to use because of the special properties of a time dimension . in particular , we will consider _ lorentzian spacetimes _ , a special case of pseudo - riemannian manifolds in which there is one time dimension with some number of spatial dimensions .",
    "euclidean space , being flat and isotropic , is the simplest riemannian manifold .",
    "analogously , flat isotropic spacetime is minkowski spacetime , the simplest lorentzian manifold . in this paper , we first generalise classical mds to allow converting distances into coordinates for pseudo - riemannian manifolds .",
    "we then show how this allows embedding of dags in minkowski spacetime ^{1/\\lambda}$ ] .",
    "this is _ not _ what we mean by a minkowski metric in this paper , rather we mean the minkowski spacetime of special relativity@xcite . ] , and that the coordinates of geometric graphs in minkowski spacetime can be successfully recovered .",
    "we then illustrate this technique by finding coordinates for some citation networks , which naturally form dags and suggest applications such as paper recommendation .",
    "we will begin by briefly summarising the details of standard mds in euclidean space .",
    "suppose we have @xmath0 objects , and are given the squared euclidean distance , @xmath1 between each pair .",
    "we wish to find the co - ordinates of the objects , which will be @xmath2 dimensional vectors , @xmath3 for each object @xmath4 , such that they fit the constraint that @xmath5 .",
    "the classical mds algorithm solves this problem by using this @xmath6 matrix of square distances , @xmath7 , and then constructing the double centred matrix @xmath8 where @xmath9 .",
    "it can then be shown ( details are available in @xcite ) that @xmath10 where @xmath11 is an @xmath12 matrix of co - ordinate vectors @xmath13 which satisfy the constraint of recovering the original distances , and with the centre of mass of the coordinates at the origin .",
    "@xmath14 is guaranteed to be semi - positive definite ( i.e.  it has no negative eigenvalues ) .",
    "so we can then find ( up to a distance - preserving symmetry transformation ) the coordinates in @xmath11 by decomposing @xmath14 into @xmath15 where @xmath16 is a diagonal matrix of the eigenvalues of @xmath14 , and @xmath17 a matrix of its eigenvectors .",
    "a solution is given by @xmath18 this process yields coordinates in @xmath0 dimensions , but only @xmath2 of the eigenvalues will be non - zero .",
    "it is possible retrieve coordinates in fewer dimensions , by using only the largest @xmath19 eigenvalues and their corresponding eigenvectors .",
    "the larger eigenvalues correspond to principle components , meaning that using them as the coordinates minimises the square difference between the original distances we started with , and the ones calculated from these inferred coordinates .",
    "these coordinates are in this sense the most accurate @xmath19 dimensional representation of the original data .",
    "minkowski spacetime is a combination of a @xmath20-dimensional euclidean space , and one time dimension forming a @xmath21-dimensional manifold .",
    "a point @xmath4 in this space , has coordinates @xmath3 consisting of a time coordinate , @xmath22 , and spatial coordinates @xmath23 , with @xmath24 .",
    "the minkowski separation between two such spacetime points @xmath4 and @xmath25 is given by @xmath26 pairs of points can then be classified into three types : for a positive separation the pair is spacelike separated , for a negative separation the pair is timelike separated , while exactly zero separation means the pair is lightlike separated .",
    "we can now ask the same question that classical euclidean mds poses : given pairwise separations @xmath27 , for points in this space , can we recover coordinates which respect these separations ?    proceeding with the classical euclidean algorithm we can construct the double centred matrix @xmath14 as before using @xmath28",
    ". however we now encounter a problem when decomposing @xmath14 .",
    "previously the eigenvalues were guaranteed to be non - negative , but now we find one negative eigenvalue corresponding to the time dimension s negative sign in equation  [ m_metric ] . since we need to take the square root of these eigenvalues , and we want real coordinates this is a problem .",
    "it turns out that the changes required to the classical mds algorithm are remarkably simple ( details are given in appendix a ) . instead of looking for a matrix of coordinates @xmath11 such that @xmath29 , we now search solutions to @xmath30 where @xmath31 is matrix representing the metric of the embedding space . for traditional mds with its euclidean space",
    "@xmath31 is just the identity matrix so this factor drops out from the analysis .",
    "however for dags where nodes are also associated with a time coordinate , we choose @xmath31 to represent the minkowski metric . in our conventions , this is a diagonal matrix with @xmath32 in the first column and @xmath33 in the others .",
    "we again decompose @xmath14 and now need solutions to @xmath34 the difference to traditional mds is that the @xmath32 present in @xmath31 changes the sign of the one negative eigenvalue in @xmath35 .",
    "this allows us to take the square root of @xmath16 as we do in classical euclidean mds .      to use lorentzian mds on networks ,",
    "we require a method of estimating the separations between every pair of nodes from the network structure .",
    "we will do this using ideas from causal set theory .",
    "a causal set is a locally finite partially ordered set .    in the causal set approach to quantum gravity",
    ", the underlying structure of spacetime is postulated to be a causal set .",
    "spacetime is seen as discrete at the planck scale , and the continuous spacetime we perceive emerges at larger length scales.@xcite .",
    "the only structure present are elements of the set and the relation , @xmath36 between pairs of elements . in the correspondence between the discrete causal set , and the continuous spacetime that emerges",
    ", the relation @xmath36 corresponds to timelike separation where @xmath37 corresponds to @xmath38 being in the past of @xmath39 , and spacelike separated pairs are not related .",
    "causal sets give us a natural way of discretising spacetime with related elements , and we can use them in our approach because they have the same structure as a dag . in physics a timelike separated pair are allowed to be causally related , as information could pass from one to the other , from past to future .",
    "however a spacelike separated pair can never be causally related as light could not reach one event from the other .",
    "this is why we will associate timelike separation in the continuous spacetime with a link representing a causal relation in the network .",
    "we can now construct the equivalent of an rgg in minkowski space .",
    "we begin by assigning coordinates in @xmath40 to @xmath0 points , by sampling uniformly at random from @xmath41^d$ ] .",
    "we will denote the coordinates of point @xmath4 by @xmath42 , @xmath43 , where @xmath44 is the time coordinate .",
    "we then construct the causal set graph , @xmath45 by placing an edge from @xmath4 to @xmath25 if @xmath46 and directing that edge from the past to the future .",
    "the fact that edges in the graph now represent causal relations illustrates why the graph is necessarily a dag , as closed causal loops are forbidden .",
    "figure  [ fig : eigenval ] shows the distribution of the eigenvalues @xmath16 for causal sets and random dags .    , @xmath47 , and @xmath48 dimensions , and for a random dag . in all cases ,",
    "one large negative eigenvalue is seen , corresponding to the one timelike dimension . for the causal sets ,",
    "this timelike dimension is the one time dimension in the minkowski spacetime they are embedded in . for the random dag ,",
    "this corresponds to the time ordering which could be created as a consequence of the acyclic property of this graph .",
    "we observe @xmath20 large positive eigenvalues corresponding to the spatial dimensions in each causal set , illustrating that the coarse graining of the causal set does not prevent the mds algorithm from successfully identifying the principle components of the space . for",
    "a given number of points , higher dimensionality will mean fewer relations between the causal set s elements and since these relations are the information used by the mds algorithm its ability to cleanly pick out @xmath20 dimensions diminishes as @xmath20 increases .",
    "however for the random dag there is no clear separation of large eigenvalues suggesting there is no natural dimension to an embedding minkowski spacetime.,scaledwidth=100.0% ]      to use mds on a network we must estimate the separation matrix @xmath7 using the network s structure . for euclidean mds , the separation is always a non - negative number and the shortest path between nodes in the graph is a natural and effective estimator for the distance .",
    "however in minkowski spacetime , the separation of points is not always positive , so the the number of steps along some path is not going to be measure of all lorenztian separations .",
    "the solution is to estimate spacelike and timelike separations separately when studying a dag .",
    "suppose we have two connected nodes in the graph , meaning they are timelike separated .",
    "it was conjectured in @xcite and later shown in @xcite that for timelike separated points @xmath4 and @xmath25 in @xmath45 the length of _ longest path _ @xmath49 between two connected nodes , say @xmath4 and @xmath25 , is proportional their timelike separation ( in the limit of long separations , and where the longest path must respect the edge s direction ) .",
    "so in this case we set @xmath50 .",
    "finding the distance between spacelike pairs is more challenging and to our knowledge there is no solution as easily calculated as the longest path is for timelike pairs .",
    "good approximations are known however , and we will use a very simple one , described in @xcite as ` naive spatial distance ' .",
    "suppose we have two disconnected points @xmath4 and @xmath25 in the @xmath51 meaning they are spacelike separated .",
    "we then look for a pair of nodes , @xmath52 and @xmath53 , where @xmath52 is in the future of both nodes @xmath4 and @xmath25 while @xmath53 is in the past of both @xmath4 and @xmath25 and @xmath25 equal to some maximal distance which is a parameter of the algorithm . in the examples shown here",
    ", we used the length of the longest path in the graph as this parameter . ] .",
    "we then chose nodes @xmath52 and @xmath53 so as to minimise the length of the longest path between @xmath52 and @xmath53 ( which are necessarily connected , via paths through @xmath38 and @xmath39 ) .",
    "the timelike separation between @xmath52 and @xmath53 is then used as an estimate for the spacelike separation between @xmath4 and @xmath25 .",
    "figure  [ fig : causal_set ] shows an example of how we estimate timelike and spacelike separations .",
    "this estimate is simple and at first appealing , but fails in more than two dimensions for large graphs ( hence the ` naive ' in the name ) .",
    "nonetheless we find it is sufficient for our purposes nodes too many cases had no two - links and so the spacelike separation could nt be calculated ] .",
    "this is partly because it is inaccurate only for large causal sets but also because in the mds algorithm each point s coordinates is fixed by many distances , both timelike and spacelike which limits the effect of noise some poor estimations of spacelike separations .",
    "we can then set @xmath54 for the chosen @xmath52 and @xmath53 .",
    "these timelike and spacelike distances define our separation matrix @xmath7 ( where timelike separation has the @xmath55 sign in our conventions ) .",
    "finally we use the algorithm described in the previous section to assign coordinates in some @xmath19-dimensional minkowski spacetime @xmath56 to each vertex in the dag .",
    "given a causal set graph , @xmath45 it is possible , in principle and for large enough @xmath57 , to recover all properties of the spacetime ( up to a factor of the density of the sprinkling)@xcite .",
    "in minkowski spacetime there is only one parameter to recover , @xmath2 , and this can be estimated for the process described above and for dags in general @xcite .",
    "our task here is to recover not properties of the manifold in which the nodes are embedded , but to find the full details of that embedding .",
    "if the graph was originally made sprinkling points into @xmath40 then we know that an exact embedding is possible ( since the original sprinkled coordinates must be a solution ) , and so the embedding algorithm should approximately recover the original coordinates ( up to distance preserving factors ) . if the graph was not , then we may only be able to find an approximate embedding .",
    "as is the case for classical mds , our lorentzian mds is guaranteed to recover the coordinates of points when the exact distances are used as the algorithms input . however , when distances are estimated using graph topology , the pairwise separations will be noisy as they are coarse grained by the discrete graph ( see figure  [ fig : m_mds ] ) . to assess the reliability of this algorithm",
    "we will test it first on the causal set model described above .",
    "we will take the coordinates produced by the lorentzian mds algorithm use them to rebuild the graph by again placing edges only between timelike separated pairs .",
    "if the overlap between the edges between nodes in the recreated graph , and in the original graph is high , the embedding is an accurate one , and similarly if the overlap is low the embedding is poor . as in @xcite",
    "we will measure this using the sensitivity ( the fraction of the correct edges which were predicted ) and specificity ( the fraction of correct non - edges which were predicted ) .",
    "embedding of the top @xmath58 most cited papers in the ` hep - th ` citation network .",
    "node size is proportional to the number of citations , and lines correspond to citations amongst these papers .",
    "a large group of papers is visible in the middle of the plot , forming a long chain of citations , as well as some more isolated papers on either side .",
    "a small number of spacelike citations are visible ( those edges more than @xmath59 from vertical ) because this two - dimensional embedding is not perfect , but only the optimal set of coordinates found by the mds algorithm.,scaledwidth=100.0% ]    our mds algorithm is able to find accurate embeddings for randomly sprinkled causal sets .",
    "we can now attempt to embed networks formed from real social systems , and here we will use citation networks from the arxiv ( 2003 kdd cup datasets ) and the us supreme court@xcite , as well as random dags for comparison . recall that the dimensionality of the embedding is something we can choose , by selecting the @xmath19 largest eigenvalues in the mds algorithm . to measure the effectiveness of the embedding",
    "we will compare the original network , with a new network generated from the coordinates determined by the mds algorithm .",
    "we want to measure the effectiveness of a classifier which predicts edges in the network from the mds coordinates . to do this we will use the established method of the area under the receiver - operator curve , auc . varying a continuous parameter ,",
    "the sensitivity and specificity of the embedding is measured , and plotted , as in figure  [ fig : auc_example ] and the area under this curve describes the quality of the classifier .",
    "the continuous parameter we will vary is the speed of light ( or the speed information can be transferred ) in the minkowski space , @xmath60 .",
    "previously , we have set @xmath61 , but varying this speed will change which nodes are connected in new network generated from the mds coordinates .",
    "now , nodes @xmath4 and @xmath25 are connected if their coordinates satisfy @xmath62 for small values of @xmath60 , very few nodes are connected and so the specificity is high ( few false positives ) but the sensitivity is low ( many false negatives ) . for large values of @xmath60 ,",
    "many nodes are connected and so the reverse is true .",
    "values for @xmath63 dimensional embeddings of @xmath64 networks . where the curve reaches the top - left of the plot we are in the @xmath65 regime ( @xmath61 denoted by the large black point on each curve ) where the trade - off between false positives and false negatives is balanced .",
    "the shape of these roc curves measures the effectiveness of the embedding and it is clear that the the causal set performs best , the random dag worst and the citation networks in between.,scaledwidth=100.0% ]    we will measure the ease of embedding a network by taking the mean of the area under this curve for networks of size @xmath66-@xmath67 . in the case of the citation networks this was done by randomly sampling intervals of this size from the citation network . in the cases of the causal set graph , and the random dags , many instances of the required sizes are stochastically generated .",
    "-dimensional spacetime , then embedded back into that same dimensional spacetime .",
    "their auc values therefore represent the ideal case , where we know an embedding is possible .",
    "the random dags show the worst embeddings .",
    "their auc values represent the success of an embedding for a graph which has no structure .",
    "they are noticeably more embeddable in higher dimensions which is because there are more degrees of freedom in which to assign coordinates while maintaining the randomly placed links .",
    "the bars show means and standard deviations of the auc for random dags of size @xmath68 to @xmath69 .",
    "citation networks from the arxiv , and the us supreme court fall between these extremes , illustrating the presence of some structure which makes them easier to embed in spacetime .",
    "we sampled @xmath70 intervals with between @xmath66 and @xmath67 nodes randomly from each citation network , and the bars show means and standard deviations for the auc in each case.,scaledwidth=100.0% ]",
    "finding a good geometric embedding of a network provides a powerful tool for the analysis of that network as it allows standard geometric techniques and intuition to be used .",
    "calculations of network properties can be made more efficient , for example , when finding optimal routes from one node to another , the node coordinates provide local information which can improve routing algorithms@xcite .",
    "coordinates resulting from geometric embedding also provide a natural visualisation for a network .",
    "such visualisations are used in bibliometrics to help identify distinct fields or assist literature reviews@xcite .    in the cases of citation analysis , where we conjecture that the spatial dimensions that result from a geometric approach correspond to similarity in the topic of a paper , our approach yields spatial similarities between papers while accounting for the time difference in their publication .",
    "once embedding coordinates are known , the idea that nodes may be ` similar ' can be expressed as nodes being close by using an appropriate metric , which need not be the lorentzian one we used in the construction of the coordinates .",
    "two nodes might be spacelike separated , so have no direct links , yet be close in a euclidean sense because mds calculates coordinates globally using information from all vertices and edges .",
    "papers could be recommended if spatially close to others a reader has interest in even if there are no local connections between them , potentially bringing work or authors to the attention of readers who are not aware of them .",
    "spatial similarity can also be used to define clusters .",
    "the idea of ` centrality ' or importance of a node has a natural representation in terms of the density of points in the geometric neighbourhood of the point linked with the chosen node .",
    "another use of this approach is where edges in a network are placed primarily according to some geometric rule but their connections are also governed by some smaller second order effect . it may only be possible to measure the smaller effect once we have accounted for the primary geometric one by assigning coordinates using lorentzian mds or a similar method",
    "we can see this effect clearly when the geometric embedding is one in real geographic space , such as in @xcite where accounting for geographic distance in phone - call data allows more accurate prediction of the second order effect of shared language .",
    "other approaches to geometric embedding exist in the literature .",
    "mds is characterised by maintaining global separations between pairs .",
    "others , such as isomap@xcite maintain shortest paths between pairs linked by local interactions .",
    "that approach may not be as appropriate in pseudo - riemannian geometries .",
    "firstly , the shortest path locally may not correspond to the geodesic distance like it does in euclidean space ; as discussed above in graphs embedded in minkowski space it is the longest path which corresponds to the geodesic .",
    "secondly , the idea of local neighbours is less clearly defined if there are different types of separation , or if , as is the case for minkowski space , the number of nearest neighbours diverges .",
    "another class of embedding approaches are probabalistic , such as stochastic neighbour embedding @xcite .",
    "although it is beyond the scope of this work , we do not see why such approaches could not be adapted to pseudo - riemannian manifolds , and the ability to use a mixture of separated images for the same object may prove very useful .    finally we note that inserting a metric signature into the equations for classical mds allows it to be used on any metric signature , even though we have focused only on the lorentzian signature here .",
    "to our knowledge this pseudo - riemannian output is a new development , although some kind of manifold learning techniques exist which can take pseudo - riemannian manifolds as their input @xcite .",
    "we note that when performing the lorentzian network mds algorithm we often find multiple negative eigenvalues , suggesting that embeddings in spaces with more than one timelike dimension is also possible , as are potential embeddings into lorentzian manifolds other than minkowski space , incorporating curvature or preferred directions .",
    "10 j.  dall and m.  christensen .",
    "_ random geometric graphs_. phys .",
    "e , 66(1):016121 , july 2002 .",
    "m.  penrose .",
    "_ random geometric graphs_. oxford university press , 2003 .",
    "z.  xie and t.  rogers . _ scale - invariant random geometric graphs_. arxiv:1505.01332 , 2015 .",
    "d.  krioukov , f.  papadopoulos , m.  kitsak , a.  vahdat , and m.  boguna .",
    "_ hyperbolic geometry of complex networks_. phys .",
    "e , 82(3):036106 , 2010 .",
    "d.  krioukov , m.  kitsak , r.  sinkovits , d.  rideout , d.  meyer , and m.  boguna .",
    "_ network cosmology . _",
    "scientific reports , 2:793 , 2012 .",
    "j.  r. clough and t.  s. evans .",
    "_ what is the dimension of citation space ?",
    "_ physica a , 448:235247 , 2016 .",
    "zhihao wu , giulia menichetti , christoph rahmede , and ginestra bianconi . _",
    "emergent complex network geometry_. scientific reports , 5:10073 , 2015 .",
    "trevor  f. cox and m.a.a .",
    "_ multidimensional scaling , second edition_. crc press , 2000 .",
    "d.  j. higham , m.  rasajski , and n.  przulj .",
    "_ fitting a geometric graph to a protein - protein interaction network_. bioinformatics , 24(8):10931099 , 2008 .",
    "j.  r. clough , j.  gollings , t.  v. loach , and t.  s. evans .",
    "_ transitive reduction of citation networks_. complex networks , 3(2):189:203 , 2015 .",
    "s.  w. hawking and g.  f.  r. ellis . _ the large scale structure of space - time_. cambridge university press , 1973 .",
    "g.  brightwell and m.  luczak . _ the mathematics of causal sets_. arxiv:1510.05612 , 2015 .    roger  n. shepard .",
    "_ attention and the metric structure of the stimulus space_. journal of mathematical psychology , 1(1):5487 , 1964 .",
    "h.  minkowski .",
    "_ die grundgleichungen fur die elektromagnetischen vorgange in bewegten korpern _ , 1910 .",
    "l.  bombelli , j.  lee , d.  meyer , and r.  d sorkin .",
    "_ space - time as a causal set_. phys .",
    "lett . 59(5):521524 , 1987 .",
    "l.  bombelli and d.  meyer .",
    "_ the origin of lorentzian geometry_. physics letters a , 141(5 - 6):226228 , 1989 .",
    "f.  dowker .",
    "_ causal sets as discrete spacetime_. contemporary physics , 47(1):19 , 2006 .",
    "j.  myrheim .",
    "_ statistical geometry_. cern2538 , 1978 .",
    "b.  bollobs and g.  brightwell .",
    "_ box - spaces and random partial orders_. transactions of the ams , 324(i):5972 , 1991 .",
    "g.  brightwell and r.  gregory .",
    "_ structure of random discrete spacetime_. phys .",
    "66(3 ) , 1991 .    d.  rideout and p.  wallden .",
    "_ spacelike distance from discrete causal order_. classical and quantum gravity , 155013:32 , 2009 .",
    "f.  dowker , j.  henson , and r.  d. sorkin .",
    "_ quantum gravity phenomenology , lorentz invariance and discreteness_. modern physics letters a , 19(24):18291840 , 2004 .",
    "d.  d. reid .",
    "_ manifold dimension of a causal set : tests in conformally flat spacetimes_. phys .",
    "d , ( october 2002):18 , 2003 .",
    "j.  h. fowler and s.  jeon . _ the authority of supreme court precedent_. social networks , 30(1):1630 , 2008 .",
    "d.  krioukov , f.  papadopoulos , a.  vahdat , and m.  boguna . _ curvature and temperature of complex networks_. phys .",
    "e , 80(3):035101 , 2009 .",
    "n.  j.  van eck and l.  waltman .",
    "_ citnetexplorer : a new software tool for analyzing and visualizing citation networks_. journal of informetrics , 8(4):802 - 823 , 2014 .",
    "p.  expert , t.  s. evans , v.  d. blondel , and r.  lambiotte .",
    "_ uncovering space - independent communities in spatial networks .",
    "_ pnas , 108(19):76638 , 2011 .",
    "j.  b. tenenbaum , v.  de  silva , and j.  c. langford .",
    "_ a global geometric framework for nonlinear dimensionality reduction .",
    "_ science , 290(5500):231923 , 2000 .",
    "s.  t. roweis and l.  k. saul .",
    "_ nonlinear dimensionality reduction by locally linear embedding . _ science , 290(5500):23236 , 2000 .",
    "g.  e. hinton and s.  t. roweis .",
    "_ stochastic neighbor embedding_. advances in neural information processing systems , 833840 , 2002 .",
    "d.  liu , s.  trajanovski , and p.  van mieghem .",
    "_ reverse line graph construction : the matrix relabeling algorithm marinlinga versus roussopoulos s algorithm_. arxiv:1005.0943 , 2010 .",
    "r.  liu , z.  lin , z.  su , and k.  tang .",
    "_ feature extraction by learning lorentzian metric tensor and its extensions_. pattern recognition , 43(10):32983306 , 2010 .",
    "following closely the derivation for euclidean mds in @xcite we begin with the timelike ( negative ) and spacelike ( positive ) square distances between each pair of points , and wish to derive the inner product matrix @xmath14 , where @xmath71 .",
    "we will denote the minkowski separation between @xmath4 and @xmath25 as @xmath72 .    as usual",
    "we first fix the coordinates centre of mass , placing it at the origin , such that @xmath73 for each @xmath74 in a @xmath75-dimensional space . remembering that @xmath76 with @xmath31 a diagonal @xmath77 matrix with @xmath32 in the first row and @xmath78 in every other row ( the minkowski metric ) we have : @xmath79 the last term on the right vanishing",
    "if the order of the sums is reversed due to the condition we stipulated above . doing the same summing over @xmath80 as well gives : @xmath81 we can now write down each element in the matrix @xmath82 we are trying to calculate . @xmath83 \\\\ b_{ij } & = -\\frac{1}{2 } \\left [ s_{ij } - \\frac{1}{n } \\sum_{i=1}^{n } s_{ij }   + \\frac{1}{n } \\sum_{i=1}^n \\mathbf{x}_i^{\\mathrm{t}}{{{\\mathbf{\\textsf{g}}}}}\\mathbf{x}_i   - \\frac{1}{n } \\sum_{j=1}^{n } s_{ij }   + \\frac{1}{n } \\sum_{j=1}^n \\mathbf{x}_j^{\\mathrm{t}}{{{\\mathbf{\\textsf{g}}}}}\\mathbf{x}_j \\right ] \\\\",
    "b_{ij } & = -\\frac{1}{2 } \\left [ s_{ij } - \\frac{1}{n } \\sum_{i=1}^{n } s_{ij } - \\frac{1}{n } \\sum_{j=1}^{n } s_{ij } + \\frac{1}{n^2 } \\sum_{i=1}^{n } \\sum_{j=1}^{n } s_{ij } \\right]\\end{aligned}\\ ] ] which gives us the the matrix @xmath14 from the distances .",
    "in the euclidean case all of the eigenvalues of @xmath14 are positive ( or zero ) . in general , the signs of eigenvalues of the matrix @xmath14 will follow the signature of the metric @xmath31 . for any metric , @xmath14 is symmetric and",
    "so can can be decomposed into orthogonal eigenvectors , @xmath17 and eigenvalues @xmath16 .",
    "@xmath84 we aim to find a solution to the equation @xmath85 .",
    "trying @xmath86 where @xmath87 is some real diagonal matrix gives @xmath88 assuming that the metric @xmath31 is diagonal we then have that @xmath89 and since @xmath87 is real , the signs of the elements of @xmath16 must equal those of @xmath31 ."
  ],
  "abstract_text": [
    "<S> geometric approaches to network analysis combine simply defined models with great descriptive power . in this work </S>",
    "<S> we provide a method for embedding directed acyclic graphs into minkowski spacetime using multidimensional scaling ( mds).first we generalise the classical mds algorithm , defined only for metrics with a euclidean signature , to manifolds of any metric signature . </S>",
    "<S> we then use this general method to develop an algorithm to be used on networks which have causal structure allowing them to be embedded in lorentzian manifolds . </S>",
    "<S> the method is demonstrated by calculating embeddings for both causal sets and citation networks in minkowski spacetime . </S>",
    "<S> we finally suggest a number of applications in citation analysis such as paper recommendation , identifying missing citations and fitting citation models to data using this geometric approach . </S>"
  ]
}