{
  "article_text": [
    "multidimensional generation / integration is an important ingredient in a variety of computational problems in science , finance and industry .",
    "the common and efficient techniques employed in these problems are stochastic simulations ( ss ) , known also as monte carlo ( mc ) methods .",
    "these algorithms often require large cpu power , but can be easily parallelized and run on multi - node computer clusters , also referred to as pc - farms .",
    "stochastic simulations have been applied in simulations in high energy physics ( hep ) since the early 1960 s . from its early beginnings",
    "ss programs were accompanied with an auxiliary library of random number generators , histogramming , job control scripts to compile / run etc . with the advent of pc - farms",
    "run under unix in the early 1990 s , the system environment of ss programs was supplemented with makefile scripts , batch system scripts for running jobs in parallel , software tools for collecting results from many jobs , more sophisticated management of input / output files ( parsers to read input data , a primitive form of persistency , output compression ) .",
    "the last decade has added to the above arsenal of tools the use of the fully object oriented programming language c++ and ides such as eclipse or kdevelop .    the state of the art in these auxiliary system tools for ss computations of the late 1990 s is well represented by these included in the ss / mc project bhlumi  @xcite , which was dedicated to calculations of quantum electrodynamical effects in the small angle electron - positron scattering at the lep experiments .",
    "the present mcdevelop system owes a lot to the above project .",
    "the actual event generator bhlumi and its all auxiliary programs were written in fortran77 . it included a library of random number generators , the simple but powerful histogramming package glibk , featuring latex - based graphics and a primitive form of persistency , that is a possibility of dumping into a disk file the status of the mc generator and all histograms for the purpose of resuming the mc production later on .",
    "multipurpose use of the bhlumi generator consisting of 3 subgenerators was managed by a custom set of interconnected makefiles in many subdirectories .",
    "this auxiliary part of bhlumi also included system of makefile and csh shell scripts managing multiple parallel jobs on an early pc - farm under the nqs batch system .",
    "the above was representative of the state of art in the 1990 s and most of its functionality is preserved in the present mcdevelop system .    over the last decades",
    "the above multifunctional auxiliary system derived from bhlumi was ported to c++ , the system of makefiles is no longer written by hand but rather managed semi - automatically by automake ( one of the tools in gnu build system autotools ) . moreover , a modern integrated development environment ( ide ) kdevelop was introduced into the everyday source code development process .",
    "histogramming and graphics are now done with help of the root library .",
    "this new incarnation of the older system has been already employed in the development of various projects related to lhc physics ( for instance cmc  @xcite or evolfmc  @xcite ) and will be used for developing other ss / mc projects for hep in the future .",
    "we hope that other developers of ss software , also beyond hep , will also profit from its great efficiency and rich functionality .",
    "let us list complete specification of the functionality of the ss software development and execution framework , as implemented in mcdevelop :    1 .",
    "generally , it should be universal , that is easily adjustable for any ss application of the interest .",
    "2 .   reduced dependence on non - open source codes and proprietary libraries , without sacrificing required functionality .",
    "3 .   histogramming , graphics and random number generators from external open - source packages integrated with the main code .",
    "availability of the modern source code tools such as a syntax - aware editor and visualisation of the object classes .",
    "easy semi - automatic configuration of the compilation / linking parameters , paths to system libraries , environmental variables , easy access to debuggers ( including debugging of memory leaks ) , etc . 6",
    ".   the framework should facilitate off - line analysis of results with help of suitable graphical libraries and convenient i / o methods , in particular the use of persistency mechanism of the c++ objects should be implemented and fully exploited .",
    "transparent and flexible methodology of setting up input data and other configuration parameters , both in single - node and pc - farm execution mode",
    "capability of running easily multiple jobs on a pc - farm under the nqs - like batch system  it should be easy to switch from one - node to multi - node execution mode , without any modifications to the code and input data .",
    "deployment of multiple jobs on the pc - farm should include setting up separate working directories for each job ( with different random number seed initialisation for each of them ) , easy starting and stopping all jobs , combining output ( histograms ) from multiple output files in all working directories into a single output files , etc . 10 .",
    "while running on a pc - farm , one should be able to do on - line analysis of the partial accumulated results , that is to inspect these partial mc results ( combined from all running jobs ) without stopping the production of the pc - farm .",
    "the framework we present here has all the above listed features .",
    "the particular solutions implementing basic functionality will be presented in section 2 and the use of computer farm within mcdevelop framework in section 3 .",
    "the external package chosen to supplement the functionality of mcdevelop is root  @xcite .",
    "root provides histogramming , graphics , and persistency of the c++ objects , as well as the random number generator foam .",
    "moreover , the optional use of kdevelop 3.5.3 , the ide of the popular desktop environment kde ( www.kde.org ) provides integrated source code development and testing environment including runtime debuggers .",
    "it is conveniently integrated with autotools , which we use for configuration , compilation and linking .",
    "the use of the powerful general purpose simulation tool foam  @xcite within mcdevelop is very easy due to its inclusion in root .",
    "for the users interested mainly in the use of foam mcdevelop provides a convenient integrated working environment .",
    "let us elaborate a little bit more on the role of foam . with the presently available cpu power it is possible and convenient to use some general purpose tool for generating or integrating an arbitrarily complicated multidimensional distribution , typically up to dimension @xmath0 , instead of inventing custom monte carlo algorithm adjusted to particular shape of the distribution ( integrand ) , as it was recommended two decades ago .",
    "object(s ) of the class tfoam may be useful in any kind and size of a ss project ; in the smaller one it may actually be an essential part of it , while in the big one may serve as a component(s ) .",
    "foam is primarily aimed to generate automatically mc events with unit weight according to an arbitrary multidimensional distribution provided by the user .",
    "it can also be used for numerical integration .",
    "foam works in two stages : ( i ) initialisation , in which it divides the integration domain into system cells , in such a way that cells are smaller and cover more densely the regions where the user distribution varies strongly ( has peaks ) ( ii ) generation , when it generates mc events _ exactly _ according to the user ( pre-)defined distribution . the user may request for either weight one events or weighted events .",
    "mcdevelop facilitates the use of foam  in particular it provides an _ interface _ to the user distribution function in its base class .",
    "we do not elaborate in this document on the use of foam , its steering parameters etc .",
    ", as it is accompanied with its own detailed user manual  @xcite and there are several examples of its use in the subdirectory tutorials of the root distribution , see http://root.cern.ch/root/html/tutorials/foam/index.html .",
    "let us remark that every hep experiment has its own software environment for running massive production ( simulation ) of the monte carlo events on pc - farms with the functionality similar to that of mcdevelop .",
    "the main difference between them is that the main aim of mcdevelop is to develop source code of the mc event generators and testing them extensively , while hep experiments rather concentrate on their use .",
    "also , hep experiments store mc events on disks , while mcdevelop is oriented towards booking and filling many histograms .    in the next section",
    "we describe how the above non - trivial goals were achieved .",
    "in fact they determine quite rigidly the organisation and structure of mcdevelop .",
    "we briefly present the workflow of the program , functionality and structure of its main c++ classes .",
    "section 3 is the user manual describing its execution on the different levels of proficiency .",
    "the more technical details extending the functionality of mcdevelop framework , such as the use of autotools and kdevelop ide will be explained in sections : [ sec : autotools ] and [ sec : kdevelop ] in particular in the context of linking with ( external ) root  @xcite libraries .",
    "mcdevelop was derived from the existing ss projects such as bhlumi  @xcite and evolfmc  @xcite , by means of extracting ( abstracting ) their universal part , such that it can be easily exploited in other ss applications , not only within hep .",
    "a transparent , modular structure is achieved by means of design and implementation of its c++ classes , organisation of the data flow reflecting the needs of typical ss project , and its directory structure .    in this section",
    "we will describe , how the framework is split into a main library of c++ programs and template subprojects , and discuss how they are interrelated .",
    "the workflow of the typical mc production run will be described .",
    "main c++ classes will be described in some details at the end of this section .",
    "mcdevelop is located in a single unix directory consisting of the following subdirectories :    * mcdev - contains universal part of the framework , library of base classes and scripts for setting up and running multiple jobs in parallel on a pc - farm ; * template0 and template - collect demonstration applications , templates of user ss applications ; * m4 - required by automake in order to link the project with external libraries .",
    "the mcdev subdirectory contains the main part of mcdevelop source code : headers and implementations of the base classes tmcgen , trobol and a few auxiliary classes , which are used to build and link the main library libmcdev .",
    "most of the classes in the ss project developed under mcdevelop are derived ( inherited ) from an appropriate base class mentioned above .",
    "the subdirectory mcdev / farming contains also several scripts ( interpreted root macros ) , which can be used to setup parallel batch jobs on a pc - farm with the nqs batch system , submit them , monitor their performance and optionally stop them .",
    "finally , they help to combine output results ( histograms ) from any number of working directories into a single output file .",
    "the distribution directory of mcdevelop contains not only the core framework but also two templates of the ss projects based on mcdevelop .",
    "their role is to guide potential users in using mcdevelop or customising their own ss project within the mcdevelop framework .",
    "they may also be exploited as a starting point to develop the user s own ss project from the scratch within the mcdevelop framework .",
    "these template projects can be found in subdirectories template0 and template .",
    "their structure is typical of projects already developed within the mcdevelop framework .",
    "each of these demonstration project contains the main execution program mainpr which generates a series of mc events , and a program xplot analysing results of ss / mc run .",
    "xplot exploits the graphics capabilities of root .",
    "the simulation run is performed in the subdirectory work where an initialisation script start.c and all output files are placed .",
    "start.c is a small c++ macro interpreted by root , enabling the user to initialise adjustable parameters of the mc run ( eg .",
    "number of events to generate ) .",
    "of course , in a bigger ss projects there will be several analysis programs like xplot , possibly in a separate subdirectory , and/or several subdirectories like work .",
    "persistency is an additional feature in the object oriented programming ( oop ) framework , which allows to write an entire object into disk file , then read it from the disk later on by the same job or other job in the `` ready to go '' state . from our past experience we know , that the typical ss software project gains in functionality through the persistency of the following objects : ( i ) the random number generator common to all components of the mc generator , ( ii ) the entire mc generator , object of a single mc event , ( iii ) the module analysing well defined aspects of the simulation during the execution .",
    "c++ does not support persistency , hence it has to be added with help of external software tools . in our case",
    "we profit from the implementation of persistency in the root  @xcite package .",
    "let us remark that any of the tools adding persistency on top of c++ has to deal with the difficult problem of storing and regenerating pointers inside a single object and among interrelated objects .",
    "the solution of this problem in root is working well , however it requires special care in the implementation ( special directives in the headers ) .",
    "we characterise the important role of persistency in the functionality of any ss project in section  [ sect : workflow ] . here",
    ", we will briefly explain the importance of persistency on the example of the random number generator and a  semaphore \" object .",
    "the object of the central random number generator is provided by one of root classes .",
    "it is allocated inside a configuration script start.c ( see below for more details about this script ) .",
    "after ( optional ) resetting of its initial seed it is immediately written into the disk file ( by default mcgen.root ) . at the start of the production it is restored from the disk and a pointer to it is distributed all over components of the monte carlo event generator .",
    "it is important that this object is the same and only one random number generator object for the entire mc generator . for a parallel execution it is cloned from the disk file for each batch job , and its random number seed",
    "is reinitialised `` in the flight '' , such that different parallel batch jobs use different random number series from the same instance of the r.n . generator . at the end of the mc",
    "run the object of r.n .",
    "generator is dumped into the disk and can be easily read from the disk in the case of continuing mc run in the next batch job , as if there was no break in the mc generation run at all .",
    "the object of the mc event generator class ( inheriting from the base class tmcgen ) undergoes similar history as r.n .",
    "generator described earlier .",
    "the important difference is that it may contain many objects of other classes , including foam , or pointers to these objects .",
    "its initialisation consumes often considerable cpu time and is performed in several steps .",
    "it is therefore quite profitable to be able to write such an operational object of the mc generator , or several version of it ( for instance initialised with different input parameters ) into a disk file for the later use .",
    "let us stress that root is capable to write / read into diskfile an entire object which consists of many other objects , even the ones referred to by pointers .",
    "the other persistent object implemented and used in mcdevelop during the execution of the program , is a special small auxiliary object of the tsemaf class .",
    "its role is to control the execution of multiple batch jobs on pc - farm .",
    "this and other objects are read / written from / to disk files many times during mc production run , see sections  [ sect : workflow ] and  [ sect : run ] for more details .      before moving to implementation details ,",
    "let us overview the general workflow of the program .",
    "this will help to better understand the functionality and data structure of the classes as well as the critical role of persistency in their implementation .",
    "the role and interrelations of the main components presented in the previous sections  [ sect : mcdev ] and  [ sect : templates ] and classes described in next section [ sect : classes ] will then become clearer .",
    "the two basic components in the workflow are : the interpreted c++ script start.c and compiled c++ program mainpr .",
    "mainpr is located in the top subdirectory of a given ( sub)project and by default is identical for all ( sub)projects . it is the main , universal production executable .",
    "start.c is placed in the subdirectory work and is specific for a project .",
    "it is already called before mc production .",
    "the purpose of start.c is to allocate objects of ( i ) the random number generator of the trandom base class , ( ii ) the mc event generator of the tmcgen base class and ( iii ) objects of the analysis module of the trobol class .",
    "moreover start.c is the place where user may easily customise these objects by resetting their default parameters ( data members ) .",
    "typically , the user may reset in start.c random number seed and any configuration / input parameters in the tmcgen object before the actual initialisation .",
    "( it is good practise to set these parameters in the constructor to some default values and optionally reset them in start.c . )",
    "start.c also allocates a small object of the tsemaf class used to control execution of the main loop over mc events in the main program mainpr .",
    "objects of the mc generator originally allocated in start.c is in the `` preliminary form '' , before any genuine initialisation .",
    "the instances of the all above objects are then saved into disk files created at the end of start.c execution .",
    "they are semafor.root and mcgen.root files encoded in the root format ( with compression ) .",
    "note that all the above objects at the time of their allocation and customisation in start.c are at this stage not interrelated , for instance with the help of pointers .",
    "it is the role of mainpr to read the object of the monte carlo event generator and other related objects from disk files mcgen.root , histo.root , semafor.root ( created by start.c ) , to assemble / initialise the working object of the mc event generator and to run the main loop generating series of the mc events .",
    "we follow the policy of keeping the part of software managing the mc production , collecting and analysing average quantities and distributions all over the entire series of the mc events well separated from the mc event generator . in mcdevelop",
    "this analysis role is reserved for an objects of the classes inheriting from the persistent base class trobol .    during the generation of a long series of the mc events in mainpr",
    ", the object of the trobol class is invoked to analyse each mc event and accumulate all interesting information in the histograms . after generating a well defined subsample series of the mc events , which we shall refer to as an _ event group _ , ( the number of mc events in the group is defined by the user )",
    "mainpr dumps the actual copy ( status ) of the mc event generator object and the object of trobol class containing all histograms into mcgen.root , histo.root files . in principle",
    "these objects are in the `` ready to go '' state . if the user wishes to restart mc generation in the next production job , they will be fully functional , as if there was no break in the production  without any need of the re - initialisation of the mc generator object .    after generating each event group of the mc events , mainpr is reading object of the tsemaf class from semafor.root file .",
    "this object contains the text flag defining the state of mc production : `` start '' , `` continue '' , or `` stop '' .",
    "the initial value of the flag in start.c is `` start '' .",
    "it is changed in mainpr to `` continue '' .",
    "however , the user has the possibility to change this flag in the object in semafor.root file to `` stop '' , even before the end of the job .",
    "once mainpr discovers `` stop '' , it terminates the loop over mc events . the above method provides protection against unexpected code or machine crashes , because only a fraction of results are lost .",
    "the saved state of mc generator can be used not only to continue or resume monte carlo production , and is also useful for debugging program crashes after generating long series of mc events .",
    "obviously , for the above workflow the extensive use of persistency is critical and instrumental .    finally , let us note that in the file histo.root distribution histograms as th1d or th2d root objects are stored not as data members of the trobol object , or using one of the container classes of root , but rather as a loose collection of histograms accessed with help of text type `` keys '' .",
    "this organisation is chosen mainly for historical reasons and can be replaced by something more sophisticated .",
    "mcdevelop consists of several base classes located in subdirectory mcdev and derived classes , specific for each subproject , located in the subdirectory of a given subproject .",
    "this is shown in figure  [ fig : classes ] .",
    "each ( sub)project directory has its own set of dedicated classes derived from the base classes and builds its own project s library .",
    "main base classes of mcdevelop are also listed in table  [ tab : classes ] . in the following",
    "we shall describe the base classes in a more detail .",
    "+ & abstract base class for any type of mc generator .",
    "it handles generation of mc events according to a user - defined distribution .",
    "the method generate ( ) is virtual and needs to be implemented in derived classes .",
    "+ & an object of this class handles mc production , collects and saves the raw material for analysing mc results at the end of the mc run .",
    "it features a three - stroke engine of the methods for analysis : initialise - production - finalise .",
    "its virtual functions must be reimplemented by the user in derived classes .",
    "+   + & an object of this class helps to manage / control the mc event production loop in the main program mainpr .",
    "main program reads from this object a semaphore variable m_flag in order to decide whether to terminate or continue job execution .",
    "+ & library of auxiliary procedures for digesting the mc results .",
    "it includes procedures for normalising semi - automatically all the histograms at the end of the mc run .",
    "its functions defhist1d",
    "( ) and defhist2d ( ) can be extended / customised in order to compare histograms from the mc run with the analytical distributions .",
    "+      the tmcgen class is the base class from which the actual mc generator class should be derived .",
    "although the use of foam in the mc generator is not mandatory , we assume that it will be used quite often , hence we facilitate it by means of the inheritance from the interface class tfoamintegrand . in this way tmcgen",
    "may implement the density method providing the distribution to be generated by foam .",
    "+ the constructor of the class tmcgen(const char * name ) creates the tmcgen object , whose name is specified in the argument .",
    "for example , the instruction : + tmcgen * mcgenerator = * new * tmcgen(``mcgenerator '' ) ; + creates an instance of tmcgen generator named mcgenerator .",
    "the generator instance is originally allocated in the start.c script . there",
    "the user can adjust some of the parameters .",
    "a typical change is in the generated distribution , which can be done in the following : + mcgenerator->m_metype = `` example '' ; //matrix element type   + the complete initialisation of the object of this class is done automatically by mainpr .",
    "the main data members of the tmcgen class are summarised in table  [ tab : mcgen_members ] .    .",
    "data members of tmcgen class .",
    "members indicated with superscripts @xmath1 are provided with streamers . [ cols=\"<,<\",options=\"header \" , ]         + & explicit default constructor for + & root streamer , + trobol(const char * ) & user constructor + ~  trobol ( ) & explicit destructor , +   + & resets all pointers after recreating + @xmath2 initialize(ofstream * , tfile * , tfile * ) & objects from disk files , + virtual void production(double & ) & the main function steering the ss ; + & invokes tmcgen::generate ( ) .",
    "+ virtual void filedump ( ) & saves all objects into relevant files , + virtual void finalize ( ) & finalises ss and does final printouts .",
    "+    the main members of trobol class are listed in the table  [ tab : robol_members ] .",
    "the object of the trobol class owns pointers to random number generator , mc generator and to all output disk files .",
    "it is an important object in the stochastic simulation project code .",
    "its main methods are listed in table  [ tab : robol_functions ] .",
    "the generate ( ) method of the mc event generator object is invoked in the production ( ) function of the trobol object .",
    "this arrangement is convenient for present applications but not mandatory .",
    "this call could be placed in mainpr main program .",
    "it might be more convenient / transparent option within a bigger ss project with several objects / classes derived from trobol class dedicated to different types of analysis of the mc results .",
    "in this section we explain how to build the whole mcdevelop framework , that is configure it , compile and link with shared libraries .",
    "the same must be also done by any ss project constructed and managed under mcdevelop .    in the following subsections",
    "we will describe how to execute two example demonstration ss projects included in the distribution .",
    "the users of mcdevelop will be also advised how to develop their own new ss project with the help of mcdevelop and how to run massive stochastic simulations on a pc - farm .",
    "let us start with building mcdevelop from the source code .",
    "after de - archiving a copy of the mcdevelop distribution directory into a local directory $ mcdevpath , one should type in the command line : +   + $ cd $ mcdevpath + $ autoreconf -i force +   + after that one should execute configure.in script : +   + $ ./configure +   + after running configure script without error messages , one may execute : +   + $ make + $ make install +   + in order to compile and link the whole project . by default libraries",
    "are installed in mcdevpath / lib , and header fies are copied to mcdevpath / include .",
    "alternatively , one can skip these two lines and comply with instructions in the next subsection .",
    "the mcdevelop distribution directory includes example of a simple mc program to be run immediately after installation is completed .",
    "once the framework is configured / built on the computer ( see previous section ) , the user may type in the command line : + $ cd template0/work + $ make start + the latter command invokes make install command in mcdev and template0 , which compiles base classes into the libmcdevlib.so library and links the classes specific to the actual demonstration program  the library libtemplate0.so is built .",
    "the c++ script start.c is also executed / interpreted using root .",
    "start.c allocates and configures a few principal objects of the project and writes them into root output files ( profiting from persistency mechanism of root ) .",
    "the project subdirectory template0 holds copy of the main program mainpr , which handles all mc simulation and saves results in template0/work . the standard output from mainpr",
    "will look as follows : +   +        ievent = 200000 + ievent = 400000 + ievent = 600000 + ievent = 800000 + ievent = 1000000 +        * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * + * * * * * * * * * * * * * * * * foam::finalise * * * * * * * * * * * * * * * * * * * * * * * * + directly from foam : mcresult= 1.0510578 + - 0.0001480123 + * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * +   +         + real 0m3.240s + user 0m2.548s + sys 0m0.116s +",
    "the above ss project template generates a simple 2-dimensional distribution using foam .",
    "the program prints out the number of generated events after generating every group of 10k mc events  at the same time output the root files are written and saved into the disk . in the output we see the result of the mc integration by foam together with its statistical error and the execution time of the job .",
    "one may easily change the number of requested total mc events in the run and the number of events within each event group .",
    "for this the user may correct the following lines in start0.c script in template0/work subdirectory : +   + double nevtot = 1e5 ; + double nevgrp = 2e4 ;   +   + optionally , in order to stop the mc run before generating all events , one may type : +   + $ make stop   +   + in such a case the program will generate events until the end of the current event group , save results and terminate .    two dimensional histogram being the result of the above quick run",
    "can be visualised using small program ./xplot0 . to run it",
    ", one should simply type : +   + $ cd .. + $ ./xplot0   +   + this small analysis program xplot0 has been already compiled / built by make utility simultaneously with the main program mainpr .      in order to present graphically results of the mc run one should build and execute xplot .",
    "it can be done using automake manager as for mainpr , which is explained in detail in section  [ sec : kdevelop ] . in case",
    "the working directory path is not set , proceed in the same way as with mainpr and set the working directory path ( the third line ) to : +   + $ mcdevpath / template/ +   + xplot uses mcdevpath / template / work / histo.root file to read out histograms as well as mcdevpath / template / work / mcgen.root to extract properties of the mc generator object read from this file . in order to use files from elsewhere the user should edit xplot.cxx file or change its working directory path , as described above .",
    "a typical example of analysis plot is shown in fig .",
    "[ fig : legoplot ] .",
    "as it was already stressed , ss jobs often consume large amounts of cpu time , hence it is profitable to run them on a pc - farm . in the following",
    "we will make an overview of the functionality of the mcdevelop framework for running jobs in parallel based on the existing examples .",
    "we will also present , how our `` farming '' setup can be used in applications .",
    "we assume that nqs - like batch system is installed on the farm , hence qsub command and the queue class qunlimitted are default parameters for submitting jobs used in the examples to follow .",
    "farming scripts are located in mcdev / farming .",
    "they are invoked by default from each subdirectory work after configuring the project .",
    "these scripts can help to set up a separate working directory for each batch job .",
    "they are also able to launch batch jobs , inspect the job s performance and merge results .    setting up working directories",
    "is done with : +   + $ make qfarm6 + the above command invokes the c++ script setfarmq.c which creates 6 working directories , one for each batch job , and prepares separate input files there .",
    "the number of nodes @xmath3 of batch jobs can be easily adjusted to actual needs . by default @xmath4",
    "are supported while executing : +   + $ make qfarm_n _ +   + in order to change the number of nodes to a non - default value , one may clone the following lines in the file $ mcdevpath / template / work / makefile.am : +   + qfarm6 : farm - clean check_all + ( echo `` > > > set up mc gener : '' ; $ ( rootexec ) -b -q",
    "-l ./start.c ) + ( echo `` > > > set up farm dir : '' ; $ ( rootexec ) -b -q -l +  ..",
    "/ .. /mcdev",
    "/ farming / setfarmq.c(``$(dset)'',6) ;) + ( ln -s .. / .. /$main ./farm/$dset.exe ; echo `` > >",
    "> > > done '' ) +   + and set the desired number @xmath3 instead of 6 in the first and fourth line . +",
    "the next command +   + $ make qsubmitall +   + submits as many batch jobs , as there are batch subdirectories made in the previous step , with the help of the c++ script submfarmq.c .",
    "mcdev / farming contains additional scripts , which enable to check the current performance , while running or after completing the batch jobs .",
    "for instance : +   + $ make q - nev +   + prints numbers of generated events and status of all batch jobs in the execution . another command : +",
    "+ $ make combine +   + merges partial results ( typically 1-d and 2-d histograms ) from all working nodes and saves them to the file histo.root using root script hadd.c .",
    "+ sometimes we want to stop all jobs immediately  this can be done with the help of : +   + $ make farm - stop +   + finally , removing all subdirectories created for a given series of the batch jobs can be done using : +   + $ make farm - clean      the solution applied for parallel execution of jobs implemented within the mcdevelop framework is universal and can be used in other projects , too .",
    "its biggest advantage is that the user s code does not need to be changed while moving from a sequential to parallel mode .",
    "the required customisations of the configuration setup of mcdevelop for using it on any pc farm will be described in this section .    if the name of the local queue and queue class is different than default values , one should configure the project by running : +   + $ ./configure with - queue = local_queue with - class = local_class +   + before proceeding further .",
    "the scripts from mcdev / farming are typically invoked from the work directories .",
    "the relevant paths are specified in work / makefile.am and should be adjusted by the user for the use within a different directory structure .",
    "all these scripts are root interpreted macros written in c++ , therefore a proper installation of the root package on the pc - farm is required .",
    "the environmental variables of root are defined for the mcdevelop framework by autoconf macros in $ mcdevpath / m4/root.m4 .",
    "the distribution directory can easily accommodate a user s completely new ss project .",
    "let us stress that mcdevelop is a convenient framework for development of both simple small new projects similar to the ones in two demonstrations directories template0 and template and also ( in fact mainly ) for development of the large size ss project , accompanied by many testing programs and user applications .",
    "simple example projects template0 and template of the distribution directory may be treated as tutorials , and/or may be also cloned into a new directory and customised to become a new ss project .",
    "let us now instruct briefly the user how to develop a simple application in a new project s directory , following the schemes implemented in the demonstration projects .",
    "any change to the directory structure must be known by autotools , so that the project can be correctly built .",
    "the details of customising the autotools configuration scripts are described in section  [ sec : automake_new_project ] .    while developing a new project within mcdevelop framework , the amount of the necessary customisations of the existing code can vary .",
    "for instance the user may only provide his own density distribution function(s ) for foam for generating mc events in the mc generator class inheriting from tmcgen .",
    "new histograms may be defined / added in a class deriving from trobol and new programs for graphical analysis can be developed .",
    "let us stress that mcdevelop is first of all a convenient framework for developing _ large size systems _ of ss programs , in fact much bigger and more complicated than the mcdevelop itself and any of the example projects included in the distribution directory . in such a big ss project",
    "we assume that a new sophisticated mc event generator of the user will be developed and tested .",
    "it will still inherit from the class tmcgen .",
    "however , it will be constructed using many objects of many c++ classes .",
    "also , typically , in such a big ss project there will be several different trobol classes / objects dedicated to specific types of testing and/or using generated mc events .",
    "these extensions may also involve modifications of the base trobol class itself , such that its sole role is analysing mc events ; the object of the mc event generator will invoked only in the mainpr program , and not in the methods of trobol ( as is done presently ) .",
    "the use of autotools within mcdevelop plays an auxiliary , yet important role . in this section",
    "we present basic ideas of maintaining project build through configuration scripts , focusing on customisation of this build configuration for the purpose of more advanced projects .",
    "the reader familiar with autotools may skip this part of the manual .",
    "compilation and linking of mcdevelop itself and of the ss projects developed using mcdevelop is organised by means of gnu build system autotools , which consists of the well known and widely used set of tools : autoconf+automake+libtool , respectively . ] .",
    "these tools are configured using a user defined configure.in file in the main directory and makefile.am files in the main directory and all subdirectories .",
    "the automake utility uses all the makefile.am files of the project , that are listed in the configure.in script and translates them into makefiles .",
    "the standard make utility uses resulting makefiles in order to compile all relevant source code and link resulting binaries with the libraries of the project and other shared libraries .",
    "final executables are located in the relevant subdirectories created by the build system , see below .",
    "the structure of the project is encoded in the configure.in and makefile.am files . once it is changed ( eg . through adding or removing a new source code , library or directory )",
    ", the user may need to edit * both * configuration scripts ( makefile.am and configure.in ) .",
    "editing them is , however , much less work then creating and maintaining `` manually '' the whole system of interrelated makefile files in several directories .",
    "the script configure.in contains list of all makefile.am files used within the project in the macro : +   + ac_output([makefile mcdev / makefile template0/makefile @xmath5 + template0/work / makefile template / makefile template / work / makefile ] )   +   + this list should be appended with any new makefile.am in the directory system .",
    "moreover , every makefile.am specifies subdirectories ( if any ) of the project .",
    "for instance makefile.am in the main directory in the current version of mcdevelop includes the line : +   + subdirs = mcdev template0 template   +   + adding new project directory should be reflected in the above command .",
    "if the new project consists of subdirectories , then all files makefile.am in upper - level directories should list all subdirectories of the lower level in the directory tree . according to general philosophy of autotools , all source files , as well as the resulting libraries and binaries",
    "are specified in files makefile.am in each project s ( sub)directories . here , the user is referred do manuals of autotools .",
    "one may also use automake manager of kdevelop to create and edit all new makefile.am files of a new project . on the other hand , there some parts for the new makefile.am files which has to be added / edited `` by hand '' using text editor .",
    "for example , the work / makefile.am file includes a sizeable part of the make utility instructions , which are managing multiple batch job preparation and submission on a pc - farm .",
    "this part of the new work / makefile.am file should be copied from our examples and customised slightly for any any new project , if the user is interested in running massive parallel jobs on pc - farm .",
    "in particular . in this part of the new work",
    "/ makefile.am one may need to correct path to the directory farming , where all c++ scripts described in section  [ sect : farm ] reside .",
    "since mcdevelop uses root , certain paths and environmental variables have to be adjusted .",
    "it is done automatically by autotools with help of scripts located in m4 subdirectory .",
    "presently , m4/root.m4 macro is interpreted by autoconf in order to check the existence of root in the system and to set up root - related environmental variables ( paths to root headers and libraries ) so that the shared libraries of root can be properly used all over the entire project ..",
    "optionally , scripts in m4 subdirectory can be adjusted by the user for linking any other external libraries .    in order to profit from the persistency mechanism of root",
    ", it is also necessary to link the project s classes with the automatic input / output _ streamer classes_.",
    "only classes explicitly listed in the linkdef.h files will be supplied with automatic streamers and will gain persistency capabilities .",
    "automatic input / output streamers are produced by the cint utility of the root using header files of the classes listed in linkdef.h ( see @xcite for details ) .",
    "adding a new class for which user wishes to be supplemented with the streaming functionality requires adding by hand the following single new line in linkdef.h : +   +",
    "the following example shows the usage of the kdevelop , the ide of kde and of a little bit more advanced example program analysing mc results with the help of root graphics .",
    "generally , kdevelop makes it easier to edit / develop source code of the project , compile and link it , run and debug executables and manage makefile.am files of automake .",
    "it makes work of the programmer more comfortable and more efficient .",
    "note that kdevelop is really a graphical front - end of the automake+autotools system .",
    "in fact we do not treat this as a disadvantage , but rather as an advantage !",
    "this allows any project developed under kdevelop and mcdevelop to be exported into another system ( pc - farm ) and to be compiled / built / run from the command line or a shell script without kdevelop being installed there .",
    "second template example as well as developing the user s own project can be done efficiently after importing mcdevelop into an ide . in this section",
    "we present , how to do it on the example of kdevelop .",
    "the user familiar with kdevelop or using other ide can skip this section .",
    "one should start by invoking kdevelop from the command line : +   + $ cd $ mcdevpath + $ kdevelop   +   + this opens window of the kdevelop ide .",
    "then , from the upper menu choose : project @xmath6 import existing project .... once a panel visualised on the figure  [ fig : import ] pops up on the screen , write the correct $ mcdevpath path in the top line ( or use the prompt to find it ) .",
    "next , it is quite important to choose correct project type",
    ". it must be set as _ generic c++ application ( automake - based)_.    one may also need to choose project @xmath6 build configuration and tick _ default _ instead of the original _ debug _ in a pop - up list , in order to be able to compile and run the program .",
    "once the project is imported into kdevelop , we can proceed to a more advanced template example of the user project in the distribution directory and compile / link / run it within this environment .",
    "the following set of commands : +   + $ cd $ mcdevpath / template + $ make install + $ cd /work + $ root -b -q -l ./start.c +   + should be executed in the console of kdevelop or other system console .",
    "these commands install the library and to execute an initialisation script start.c .",
    "the following step is to open the automake manager from the right - hand - side menu of kdevelop . in the upper frame",
    "choose template .",
    "+   + the lower frame should now present libtemplate with implementation of classes building this library and two executable programs : mainpr and xplot , as shown in the picture on the right .",
    "+   + click on mainpr , then choose a rocket icon from above the frame in order to compile it and build . then click on the blue cog next to the rocket to execute the program .",
    "+         + due to a bug in kdevelop , one may sometimes need to set the correct path for working directory of the executables .",
    "to do it click on mainpr ( program in bin ) in the automake manager to highlight it . then click on options icon in the automake manager . from the _ target options _ for mainpr window choose the bookmark _",
    "argument_. then set the working directory path ( the third line ) to : +   + $ mcdevpath / template / work +   + and click the _ ok _ button . then repeat the above chain of the commands",
    "the following future developments of the mcdevelop ss software development environment will have the highest priority :      * acknowledgements * + we would like to thank m. skrzypek , w. placzek and z. was , the co - authors of previous stochastic simulation project published by the krakow group .",
    "their ideas and experience were naturally incorporated into mcdevelop .",
    "we would like to acknowledge p. golonka for his help in using autotools with root .",
    "we thank m. skrzypek , w. placzek , p. richardson and d. grellscheid for useful comments and reading the manuscript .",
    "s.  jadach , w.  paczek , e.  richter - was , b.  f.  l. ward , and z.  was , _ comput .",
    "* 102 * ( 1997 ) 229 .",
    "s.  jadach , w.  paczek , m.  skrzypek , p.  stephens , and z.  was , http://www.arxiv.org/abs/hep-ph/0703281[hep-ph/0703281 ] .",
    "s.  jadach , w.  placzek , m.  skrzypek , and p.  stoklosa , _ comput .",
    "commun . _ * 181 * ( 2010 ) 393412 , http://www.arxiv.org/abs/0812.3299[0812.3299 ] .",
    "r.  brun and f.  rademakers , _ nucl",
    ". instrum .",
    "_ * a389 * ( 1997 ) 8186 .",
    "s.  jadach , _ comput .",
    "* 152 * ( 2003 ) 55100 , http://www.arxiv.org/abs/physics/0203033[physics/0203033 ] ."
  ],
  "abstract_text": [
    "<S> we present mcdevelop , a universal computer framework for developing and exploiting the wide class of stochastic simulations ( ss ) software . </S>",
    "<S> this powerful universal ss software development tool has been derived from a series of scientific projects for precision calculations in high energy physics ( hep ) , which feature a wide range of functionality in the ss software needed for advanced precision quantum field theory calculations for the past lep experiments and for the ongoing lhc experiments at cern , geneva . </S>",
    "<S> mcdevelop is a `` spin - off '' product of hep to be exploited in other areas , while it will still serve to develop new ss software for hep experiments . </S>",
    "<S> typically ss involve independent generation of large sets of random  events \" , often requiring considerable cpu power . </S>",
    "<S> since ss jobs usually do not share memory it makes them easy to parallelize . the efficient development </S>",
    "<S> , testing and running in parallel ss software requires a convenient framework to develop software source code , deploy and monitor batch jobs , merge and analyse results from multiple parallel jobs , even before the production runs are terminated . throughout the years of development of stochastic simulations for hep , a sophisticated framework featuring all the above mentioned functionality has been implemented . </S>",
    "<S> mcdevelop represents its latest version , written mostly in c++ ( gnu compiler gcc ) . </S>",
    "<S> it uses autotools to build binaries ( optionally managed within the kdevelop 3.5.3 integrated development environment ( ide ) ) . </S>",
    "<S> it uses the open - source root package for histogramming , graphics and the mechanism of persistency for the c++ objects . </S>",
    "<S> mcdevelop helps to run multiple parallel jobs on any computer cluster with nqs - type batch system .    </S>",
    "<S> = 1    * ifjpan - iv-2010 - 5 * + * mcnet-10 - 12 * +     * mcdevelop  the universal framework for stochastic simulations *    _ institute of nuclear physics , polish academy of sciences , + ul . </S>",
    "<S> radzikowskiego 152 , 31 - 342 , krakw , poland _ </S>",
    "<S> +    _ institute of nuclear physics , polish academy of sciences , + ul . </S>",
    "<S> radzikowskiego 152 , 31 - 342 , krakw , poland , _ +   _ theory group , physics department , cern , ch-1211 , geneva 23 , switzerland + _    * program summary *    _ title of the program : _ + mcdevelop .    </S>",
    "<S> _ computer : _ + any computer system or cluster with c++ compiler and unix - like operating system . </S>",
    "<S> + _ operating system : _ </S>",
    "<S> + most unix systems , linux + the application programs were thoroughly tested under ubuntu 7.04 , 8.04 and cern scientific linux 5 .    _ programming languages used : _ + ansi c++    other requirements : + ( i ) root package installed , version 5.0 or higher . </S>",
    "<S> + ( ii ) gnu compiler gcc and gnu build system autotools  optionally within kdevelop 3.5.3 integrated development environment . </S>",
    "<S> + ( iii ) nqs - type batch system ( for running jobs in a parallel mode ) </S>"
  ]
}