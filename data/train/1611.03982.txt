{
  "article_text": [
    "in the age of cloud computing , cloud servers with adequate resources help their clients by performing huge amount of computation or by storing large amount of data ( say , in the order of terabytes ) on their behalf . in this",
    "setting , a client only has to download the result of the computation or has to read ( or update ) the required portion of the outsourced data .",
    "several storage service providers like amazon simple storage service ( s3 ) , dropbox , google drive and microsoft azure provide storage outsourcing facility to their clients ( data owners )",
    ". however , a cloud storage server can be malicious and delete some ( less frequently accessed ) part of the client s data in order to save space .",
    "secure cloud storage protocols ( two - party protocols between the client and the server ) provide a cryptographic solution to this problem by ensuring that the client s data are stored untampered in the cloud server .    in a secure cloud storage scheme , a client can remotely check the integrity of her data file outsourced to the cloud server . a possible way to do this",
    "is to divide the data file into blocks and attach an authenticator ( or tag ) to each of these blocks before the initial outsourcing .",
    "when the client wants to check the integrity of her data , she downloads all the blocks of the file along with their tags from the server and verifies them individually .",
    "however , this process is highly inefficient due to the large communication bandwidth required between the client and the cloud server .    in order to resolve the issue mentioned above",
    ", a notion called _ proofs - of - storage _ comes into play where the client can audit her data file stored in the server without accessing the whole file , and still , be able to detect an unwanted modification of the file done by the malicious server .",
    "the concept of _ provable data possession _ ( pdp ) is introduced by ateniese et al .",
    "@xcite where the client computes an authentication tag for each block of her data file and uploads the file along with these authentication tags as stated earlier .",
    "later , the client can execute an _ audit _ protocol and verify the integrity of the data file by checking only a predefined number of randomly sampled blocks of the file .",
    "although efficient pdp schemes  @xcite are available in the literature , they only provide the guarantee of retrievability of _ almost all _ blocks of the data file .",
    "we briefly mention some situations where this guarantee is not sufficient .",
    "the data file may contain some sensitive information ( e.g. , accounting information ) any part of which the client does not want to lose . on the other hand , a corruption in the compression table of an outsourced compressed file might make the whole file unavailable . in a searchable symmetric encryption scheme  @xcite ,",
    "the client encrypts a database using a symmetric encryption scheme to form an index ( metadata for that database )  @xcite and outsources the encrypted documents along with the index to the server .",
    "the size of this index is very small compared to the encrypted database itself .",
    "however , loss of the index completely defeats the purpose of the searchable encryption scheme . in such circumstances",
    ", the client wants a stronger notion than pdp which would guarantee that the server has stored the _",
    "entire _ file properly and the client can retrieve _ all _ of her data blocks at any point of time .    to address the issue mentioned above , juels and",
    "kaliski  @xcite introduce _ proofs of retrievability _",
    "( por ) where the data file outsourced to the server can be retrieved in its entirety by the client .",
    "the underlying idea  @xcite of a por scheme is to encode the original data file with an error - correcting code , authenticate the blocks of the encoded file with tags and upload them on the storage server . as in pdp schemes",
    ", the client can execute an audit protocol to check the integrity of the outsourced data file .",
    "the use of error - correcting codes ensures that _ all _ data blocks of the file are retrievable .",
    "depending on the nature of the outsourced data , por schemes are classified as : por schemes for _ static _ data ( static por ) and _ dynamic _ data ( dynamic por ) .",
    "for static data , the client can not change her data after the initial outsourcing ( suitable mostly for backup or archival data ) .",
    "dynamic data are more generic in that the client can modify her data as often as needed .",
    "the por schemes are _ publicly verifiable _ if audits can be performed by any third party auditor ( tpa ) with the knowledge of public parameters only ; they are _ privately verifiable _ if only the client ( data owner ) with some secret information can perform audits .",
    "designing an _ efficient _ and publicly verifiable dynamic por scheme is an important research problem due to its practical applications .",
    "there are various efficiency parameters where the performance of a dynamic por scheme might be improved .",
    "some of them include the communication bandwidth required to read or write a data block ( or to perform an audit ) , the client s storage , and the computational cost at the client s ( or the server s ) end . on the other hand",
    ", the client often prefers to delegate the auditing task to a third party auditor ( tpa ) who performs audits on the client s data and informs the client in case of any anomaly detected in the server s behavior .    to the best of our knowledge , there is only one practical )  @xcite , and the current @xmath0 candidates are impractical . ]",
    "dynamic por scheme with public verifiability that is proposed by shi et al .",
    "@xcite . in this work ,",
    "we provide a construction of a publicly verifiable dynamic por scheme that is more efficient ( in terms of write and audit costs ) than the publicly verifiable scheme proposed by shi et al .",
    "moreover , the public parameters used in the latter scheme need to be changed for _ each _ write operation performed on the client s data which is clearly an overhead as , in that case , these public parameters are to be validated and certified for every write .    *",
    "our contribution*we summarize our contributions in this paper as follows .",
    "* we construct a _ dynamic _ proofs - of - retrievability ( por ) scheme where the client outsources her data file to the cloud server and she can update the content of the file later . * our dynamic por scheme offers _ public verifiability _ , that is , the client can delegate the auditing task to a third party auditor who performs audits on the client s behalf . * we show that our scheme is secure in the sense that the client gets an assurance that her data file stored by the server is authentic and up - to - date , and _ all _ the data blocks can be retrieved by the client as often as needed . *",
    "we analyze the performance of our scheme and compare it with other existing dynamic por schemes ( having private or public verifiability ) . *",
    "our publicly verifiable dynamic por scheme enjoys more efficiency ( in terms of communication bandwidths required for a write and an audit ) than the `` state - of - the - art '' publicly verifiable dynamic por scheme  @xcite .",
    "moreover , unlike the latter scheme , there is no need to validate or certify the public parameters in our scheme for every write operation as they are fixed since the initial setup phase .",
    "the rest of the paper is organized as follows .",
    "section  [ prelims ] describes the preliminaries and background related to our work . in section  [ scs ] ,",
    "we survey the existing literature on secure cloud storage schemes .",
    "section  [ scheme ] provides a detailed construction of our publicly verifiable dynamic por scheme .",
    "we analyze the security of our scheme in section  [ security ] .",
    "finally , in section  [ performance_ana ] , we discuss the performance of our scheme and compare our scheme with other existing dynamic por schemes based on different parameters ( shown in table  [ tab : comparison_por ] ) .",
    "we also show that our scheme is more efficient than the publicly verifiable dynamic por scheme proposed by shi et al .  @xcite . in the concluding section  [ sec : conclusion ]",
    ", we summarize the work done in this paper .",
    "we take @xmath1 to be the security parameter .",
    "an algorithm denoted by @xmath2 is a probabilistic polynomial - time algorithm when its running time is polynomial in @xmath1 and its output @xmath3 is a random variable which depends on the internal coin tosses of @xmath4 .",
    "if @xmath4 is given access to an oracle @xmath5 , we denote @xmath4 by @xmath6 also .",
    "an element @xmath7 chosen uniformly at random from a set @xmath8 is denoted as @xmath9 .",
    "a function @xmath10 is called negligible in @xmath1 if for all positive integers @xmath11 and for all sufficiently large @xmath1 , we have @xmath12 .      a @xmath13-erasure code is an error - correcting code  @xcite that comprises an encoding algorithm enc : @xmath14 ( encodes a message consisting of @xmath15 symbols into a longer codeword consisting of @xmath16 symbols ) and a decoding algorithm dec : @xmath17 ( decodes a codeword to a message ) , where @xmath18 is a finite alphabet and @xmath19 is the minimum distance ( hamming distance between any two codewords is at least @xmath19 ) of the code .",
    "the quantity @xmath20 is called the rate of the code .",
    "a @xmath13-erasure code can tolerate up to @xmath21 erasures .",
    "if @xmath22 , we call the code a maximum distance separable ( mds ) code . for an mds code , the original message can be reconstructed from any @xmath15 out of @xmath16 symbols of the codeword .",
    "reed - solomon codes  @xcite and their extensions are examples of non - trivial mds codes .",
    "a merkle hash tree  @xcite is a binary tree where each leaf - node stores a data item .",
    "the label of each leaf - node is the data item stored in the node itself .",
    "a collision - resistant hash function @xmath23 is used to label the intermediate nodes of the tree .",
    "each of the outputs of @xmath23 on different inputs is a binary string of length @xmath24 .",
    "the label of a intermediate node @xmath25 is the output of @xmath23 computed on the labels of the children nodes of @xmath25 .",
    "a merkle hash tree is used as a standard tool for efficient memory - checking .",
    "child node b + @xmath26 child node d + @xmath27 child node h + @xmath28 child node i + @xmath29 child node e + @xmath30 child node j + @xmath31 child node k + @xmath32 child node c + @xmath33 child node f + @xmath34 child node l + @xmath35 child node m + @xmath36 child node g + @xmath37 child node",
    "n + @xmath38 child node o + @xmath39 ;    fig .",
    "[ fig : mht ] shows a merkle hash tree containing the data items @xmath40 stored at the leaf - nodes .",
    "consequently , the labels of the intermediate nodes are computed using the hash function @xmath23 .",
    "the hash value of the node @xmath41 is the _ root - digest_. the proof showing that a data item @xmath19 is present in the tree consists of the data item @xmath19 and the labels of the nodes along the _ associated path _ ( the sequence of siblings of the node containing the data item @xmath19 ) .",
    "for example , a proof showing that @xmath31 is present in the tree consists of @xmath42 , where @xmath43 and @xmath44 are the labels of the nodes @xmath45 and @xmath46 , respectively .",
    "given such a proof , a verifier computes the hash value of the root .",
    "the verifier outputs ` accept ` if the computed hash value matches with the root - digest ; it outputs ` reject ` , otherwise .",
    "the size of a proof is logarithmic in the number of data items stored in the leaf - nodes of the tree .    due to the collision - resistance property of @xmath23 , it is infeasible ( except with some probability negligible in the security parameter @xmath1 ) to add or modify a data item in the merkle hash tree without changing its root - digest .",
    "we define a digital signature scheme as proposed by goldwasser et al .",
    "a digital signature scheme consists of the following polynomial - time algorithms : a key generation algorithm keygen , a signing algorithm sign and a verification algorithm verify .",
    "keygen takes as input the security parameter @xmath1 and outputs a pair of keys @xmath47 , where @xmath48 is the secret key and @xmath49 is the corresponding public verification key .",
    "algorithm sign takes a message @xmath50 from the message space @xmath51 and the secret key @xmath48 as input and outputs a signature @xmath52 .",
    "algorithm verify takes as input the public key @xmath49 , a message @xmath50 and a signature @xmath52 , and outputs ` accept ` or ` reject ` depending upon whether the signature is valid or not .",
    "any of these algorithms can be probabilistic in nature .",
    "the correctness and security ( existential unforgeability under adaptive chosen message attacks  @xcite ) of a digital signature scheme are described as follows .    1 .   _",
    "correctness_:algorithm verify always accepts a signature generated by an honest signer , that is , @xmath53=1 .",
    "\\end{aligned}\\ ] ] 2 .   _",
    "security_:let sign@xmath54 be the signing oracle and @xmath4 be any probabilistic polynomial - time adversary with an oracle access to sign@xmath54 .",
    "the adversary @xmath4 adaptively makes polynomial number of sign queries to sign@xmath54 for different messages and gets back the signatures on those messages .",
    "the signature scheme is secure if @xmath4 can not produce , except with some probability negligible in @xmath1 , a valid signature on a message not queried previously , that is , for any probabilistic polynomial - time adversary @xmath55 , the following probability is negligible in @xmath1 , where @xmath56 is the set of sign queries made by @xmath4 to @xmath57 .",
    "the discrete log problem over a multiplicative group @xmath58 of prime order @xmath59 and generated by @xmath60 is defined as follows .",
    "given @xmath61 , the discrete log problem over @xmath62 is to compute @xmath63 such that @xmath64 .",
    "the discrete log assumption says that , for any probabilistic polynomial - time adversary @xmath2 , the following probability _",
    "x_q[x(y ) : y = g^x ] is negligible in @xmath1 , where the probability is taken over the internal coin tosses of @xmath4 and the random choice of @xmath65 .",
    "we define a proofs - of - retrievability scheme for _ dynamic _ data as follows  @xcite .    a dynamic por scheme consists of the following protocols between two stateful parties : a client ( data owner ) and a server .    * _ init(@xmath66 ) : _ this protocol associates a random file - identifier _ `",
    "fid ` _ to the data file @xmath67 consisting of @xmath68 data blocks each of @xmath69 bits , and it outputs the client state @xmath70 and another file @xmath71 to be stored by the server . * _ read(@xmath72 ) : _ this protocol outputs the data block at the @xmath73-th location of the current state of the file or _ ` abort`_. * _ write(@xmath74 ) : _ this protocol inserts the block @xmath75 after the @xmath73-th block of the file or sets @xmath73-th block of the file to @xmath75 or deletes the @xmath73-th block of the file ( @xmath75 is _ ` null ` _ in this case ) .",
    "it outputs updated @xmath76 or _ ` abort`_. * _ audit(@xmath77 ) : _ this protocol checks memory contents of the current state of the data file and outputs 1 or 0 .",
    "a dynamic por scheme is _ privately verifiable _ if only the client with some secret information can perform an audit , that is , @xmath70 is secret .",
    "otherwise , it is _",
    "publicly verifiable_. for a publicly verifiable dynamic por scheme , a third party auditor ( tpa ) can audit the client s data on behalf of the client who delegates her auditing task to the tpa . in this case",
    ", we use the term `` verifier '' to denote an auditor who can be the tpa or the client herself .",
    "security of a dynamic por scheme is described in section  [ security_def ] .",
    "ateniese et al .",
    "@xcite introduce the notion of _ provable data possession _ ( pdp ) . in a pdp scheme , the client computes an authentication tag ( e.g. , message authentication code  @xcite ) for each block of her data file and uploads the file along with the authentication tags . during an audit protocol",
    ", the client samples a predefined number of random block - indices and sends them to the server ( _ challenge _ phase ) .",
    "the cardinality of the challenge set is typically taken to be @xmath24 , where @xmath1 is the security parameter .",
    "depending upon the challenge , the server does some computations over the stored data and sends a proof to the client ( _ response _ phase ) .",
    "finally , the client checks the integrity of her data based on this proof ( _ verification _ phase ) .",
    "_ almost all _ data blocks can be retrieved from a ( possibly malicious ) server passing an audit with a non - negligible probability .",
    "other pdp schemes include  @xcite .    juels and kaliski  @xcite introduce _ proofs of retrievability _",
    "( por ) for static data ( naor and rothblum  @xcite give a similar idea for sublinear authenticators ) . according to shacham and waters  @xcite , the retrievability guarantee for _ all _ data blocks of the outsourced",
    "file can be achieved by encoding the original file with an erasure code ( see section  [ erasure_code ] ) before authenticating ( and uploading ) the blocks of the encoded file . due to",
    "the redundancy added to the data blocks , the server has to delete or modify a considerable number of blocks to actually delete or modify a data block which makes it difficult for the server to pass an audit .    following the work by juels and kaliski , several por schemes have been proposed for static data ( _ static por _ ) and dynamic data ( _ dynamic por _ ) .",
    "shacham and waters  @xcite propose two por schemes for static data ( one with private verifiability and another with public verifiability ) where the response from the server is short .",
    "bowers et al .",
    "@xcite propose a theoretical framework for designing por schemes and provide a prototype implementation of a variant of  @xcite . in another work , bowers et al .",
    "@xcite introduce hail ( high - availability and integrity layer ) , a distributed por setting where the client s data are disseminated across multiple servers .",
    "dodis et al .",
    "@xcite introduce a notion called `` por codes '' and show how por schemes can be instantiated based on these por codes .",
    "they explore the connection between por codes and the notion of hardness amplification  @xcite .",
    "xu and chang  @xcite improve the privately verifiable scheme of  @xcite by making the communication bandwidth required for an audit to be @xmath24 .",
    "armknecht et al .",
    "@xcite propose a por scheme where any entity among the client ( data owner ) , the auditor and the cloud server can be malicious , and any two of them can collude as well .",
    "the auditor performs two audits : one for the auditor itself and another on behalf of the client .",
    "the challenge sets are generated using a public randomized algorithm derived from the hash value of the latest block added to the bitcoin block chain  @xcite .",
    "a few dynamic por schemes are there in the literature .",
    "stefanov et al .",
    "@xcite propose an authenticated file system called `` iris '' that is highly scalable and resilient against a malicious cloud server .",
    "cash et al .",
    "@xcite encode a small number of data blocks _ locally _ and hide the access pattern of the related ( belonging to the same codeword ) blocks from the server using oblivious ram ( oram )  @xcite .",
    "due to the use of expensive oram primitives , this scheme is inefficient .",
    "shi et al .",
    "@xcite propose two practical dynamic por schemes which reduce the cost of computation as well as the communication bandwidth required to execute the protocols involved .",
    "chandran et al .",
    "@xcite introduce the notion of `` locally updatable and locally decodable codes '' and propose an efficient dynamic por scheme by applying the techniques used in the construction of such a code . the por scheme by guan et al .",
    "@xcite exploits the privately verifiable scheme of  @xcite and gives a publicly verifiable scheme with the help of indistinguishability obfuscation ( @xmath0 )  @xcite .",
    "in this section , we describe our publicly verifiable dynamic por scheme with efficient writes and audits . like the existing dynamic por schemes  @xcite ,",
    "our construction also rely on the hierarchical structure provided by the oblivious ram  @xcite .",
    "specifically , we follow a storage structure similar to the one proposed by shi et al .  @xcite . however , our construction is more efficient than their scheme in terms of the cost of a write operation and the cost of an audit .",
    "our construction is based on _ collision - resistant homomorphic hashing _",
    "technique  @xcite along with a digital signature scheme .",
    "our scheme relies on a storage structure similar to that proposed by shi et al .",
    "let the client ( data owner ) associate a random file - identifier ` fid ` of @xmath1 bit - size to the data file she wants to outsource to the cloud server .",
    "we assume that the data file is divided into blocks of size @xmath69 bits , and read ( and write ) operations are performed on these blocks .",
    "the value of @xmath69 is taken to be @xmath78 for a large prime @xmath79 .",
    "the way this prime @xmath79 is selected is discussed in section  [ buff_h ] . for static data , a standard way to guarantee retrievability of the file is to encode the file using an erasure code  @xcite .",
    "the main drawback of using erasure codes in _ dynamic _ por is that an update in a single block in a codeword ( say , c ) is followed by updates on other @xmath80 blocks in c , where @xmath68 is the number of blocks being encoded to form c. the underlying idea to overcome this drawback is not to update the encoded copy ( c ) for every write operation ( insertion , deletion or modification ) .",
    "instead , it is updated ( or rebuilt ) only when sufficient updates are done on the data file .",
    "thus , the amortized cost for writes is reduced dramatically . however ,",
    "this encoded copy stores stale data between two such rebuilds . therefore ,",
    "a hierarchical log structure is maintained which temporarily stores values for the intermediate writes between two successive rebuilds of c. each level of this hierarchical log is also encoded using an erasure code .",
    "we adopt the storage structure and code construction mentioned above in our scheme .",
    "however , we use collision - resistant homomorphic hashing to construct another hierarchical storage ( discussed in section  [ storage_tags ] ) in order to reduce the cost of a write and an audit for the client .",
    "our scheme involves the following three data structures in order to store the data blocks of the client s file :    * an _ unencoded _ buffer u containing all the up - to - date data blocks of the file ( that is , u is updated after every write operation is performed ) , * an _ encoded _ buffer c which is updated after every @xmath68 writes ( that is , c is rebuilt afresh by encoding the latest u after every @xmath68 write operations ) , and * an _ encoded _ hierarchical ( multiple levels of buffers ) log structure h which accommodates all intermediate writes between two successive rebuilds of c ( h is made empty after every @xmath68 writes ) .",
    "we note that _ all _ of these data structures are stored on the cloud server .",
    "the server also stores two additional data structures , @xmath81 and @xmath82 ( similar to h and c , respectively ) , for authentication tags described in section  [ storage_tags ] .",
    "the buffer u contains an up - to - date copy of the data file .",
    "reads and writes are performed directly on the required locations of u. a merkle hash tree is maintained over the data blocks of u to check the authenticity of the read block ( see section  [ mht ] for the description of a merkle hash tree ) . the merkle proof sent by the server along with the read block",
    "is verified with respect to the up - to - date root - digest ( say , @xmath83 ) of the merkle hash tree .",
    "one can also use other authenticated data structures like rank - based authenticated skip lists  @xcite instead of a merkle hash tree .",
    "let @xmath68 be the number of blocks the client outsources to the cloud server initially .",
    "so the height of the merkle tree built on u is @xmath84 .",
    "read and write operations on the buffer u are described in details in section  [ operations ] .",
    "a hierarchical log structure h is maintained that consists of @xmath85 levels @xmath86 , where @xmath87 .",
    "the log structure h stores the intermediate writes temporarily . for each @xmath88 ,",
    "the @xmath89-th level h@xmath90 consists of an encoded copy of @xmath91 data blocks using a @xmath92-erasure code , where @xmath93 and @xmath94 contain @xmath91 blocks each .",
    "the original data blocks encoded in h@xmath95 arrive at time @xmath96 , where @xmath97 is a multiple of @xmath91 .",
    "we describe the encoding procedure as follows .",
    "let @xmath79 be a large prime such that @xmath98 for some @xmath99 and the bit - size of a block @xmath100 , where @xmath101 .",
    "let @xmath102 denote a generator of @xmath103 .",
    "then , @xmath104 is a @xmath105-th primitive root of unity modulo @xmath79 .",
    "when a block @xmath75 is written to h , it is inserted in the topmost level ( @xmath106 ) if h@xmath107 is empty .",
    "that is , @xmath108 is set to @xmath75 .",
    "in addition , @xmath109 is set to @xmath110 for the @xmath97-th ( @xmath111 ) write , where @xmath112 is the @xmath105-th primitive root of unity modulo @xmath79 .",
    "here , @xmath113 is the bit reversal function , where @xmath114 is the value of the binary string obtained by reversing the binary representation of @xmath97 .    if the top @xmath73 levels @xmath115 are already full , a _",
    "rebuild _ is performed to accommodate all the blocks in these levels as well as the new block in @xmath116 ( and to make all the levels up to @xmath117 empty ) .",
    "shi et al .",
    "@xcite employ a fast incrementally constructible code based on fast fourier transform ( fft )  @xcite , we use similar code and parameters for the ease of comparison . ] .",
    "[ fig : rebuildx ] describes the algorithm for rebuild of @xmath93 that in turn uses the algorithm ` mix ` shown in fig .",
    "[ fig : mixx ] .",
    "although the algorithm deals with @xmath93 , the same algorithm can be used for rebuilding @xmath94 if we replace the @xmath118 arrays by corresponding @xmath119 arrays and the incoming block @xmath75 by @xmath110 .",
    "we refer  @xcite for the form of the @xmath120 generator matrix @xmath121 for the @xmath89-th level code .",
    "let @xmath122 be the vector containing @xmath91 data blocks most recently inserted in h ( after applying a permutation ) .",
    "then , the output of the algorithm ` mix ` for h@xmath95 is the same as that when @xmath122 is multiplied by @xmath121 .",
    "any @xmath123 submatrix of the generator matrix @xmath121 is full rank , and thus , the code achieves the maximum distance separable ( mds ) property .    as a concrete example",
    ", the rebuild of @xmath124 is demonstrated in fig .",
    "[ fig : rebuildh ] .",
    "the other part of h@xmath125 ( that is , @xmath126 ) is rebuilt in a similar fashion .",
    "we observe that , by using this code , the rebuild cost of h@xmath95 is @xmath127 ( i.e. , linear in the length of h@xmath95 ) since the algorithm ` mix ` populates h@xmath95 by combining two arrays @xmath128 ( see fig .  [",
    "fig : mixx ] and fig .",
    "[ fig : rebuildh ] ) .",
    "the @xmath89-th level is rebuilt after @xmath91 writes .",
    "therefore , the amortized cost for rebuilding is @xmath129 per write operation .",
    "each rebuild of the buffer c ( discussed in section  [ buff_c ] ) is followed by making all levels of h empty .",
    "unlike the buffer u ( and h ) , no read or write operations are performed directly on the buffer c. after @xmath68 write operations , the buffer u is encoded using an erasure code to form a new copy of c , and the existing copy of c is replaced by this new one .",
    "the rebuild of c can be done using the same fft - based code discussed in section  [ buff_h ] which costs @xmath130 both in time and bandwidth . as c is rebuilt after every @xmath68 write operations , the cost incurred per write is @xmath129 .",
    "we note that c contains stale data between two successive rebuilds .",
    "however , the intermediate writes are accommodated in h with appropriate encoding .",
    "thus , these blocks written between two successive rebuilds of c are also retrievable at any point of time .",
    "in addition to the log structure h and the buffer c for data blocks , two similar structures @xmath81 and @xmath82 for authentication tags corresponding to the data blocks in h and c ( respectively ) are stored on the cloud server .",
    "thus , the server stores u , h , c , @xmath81 and @xmath82 .",
    "the benefits of storing @xmath81 and @xmath82 on the server are as follows .",
    "let us assume that the authentication tags for data blocks have the following properties .    1 .",
    "the size of a tag is much less than that of a block .",
    "the tags are homomorphic in the sense that , given the tags of two blocks @xmath131 and @xmath132 , the tag on any linear combination of @xmath131 and @xmath132 can be generated .",
    "we note that the fundamental operation for a write ( or rebuild ) on h and c is to encode data blocks , that is , to compute a linear combination of those data blocks ( see eqn .  1 and eqn .  2 in fig .",
    "[ fig : mixx ] ) . due",
    "the _ second _ property mentioned above , while the server itself performs write operations on h and c , the client ( data owner ) can perform similar operations on @xmath81 and @xmath82 . on the other hand , due to the _ first _ property",
    ", the bandwidth required between the client and the server for a write operation decreases significantly as the client now has to download much smaller tags instead of large data blocks .",
    "the cost of storage is less nowadays , whereas bandwidth is more expensive and often limited .",
    "therefore , it is reasonable if we trade the storage off to reduce the communication bandwidth between the client and the server required for a write ( or rebuild ) .",
    "indeed , the authentication tags ( described in the following section ) we use in our dynamic por scheme satisfy the following properties .    *",
    "the size of a tag is @xmath24 and is independent of the size of a data block ( @xmath1 is the security parameter ) , where @xmath133 . *",
    "the homomorphic property is achieved by using a collision - resistant homomorphic hash function .",
    "apart from efficient write operations , the cost of an audit in our _ publicly verifiable dynamic _ por scheme is comparable to that in the privately verifiable scheme of  @xcite , and it is _ much less _ than that in the publicly verifiable scheme discussed in the same work .      *",
    "* setup**for the data file identified by ` fid ` , the client runs an algorithm setup(@xmath134 ) to set parameters for generating authentication tags .",
    "the algorithm setup selects two random primes @xmath135 and @xmath59 such that @xmath136 , @xmath137 and @xmath138 .",
    "now , it divides each block @xmath75 of the data file into segments of size @xmath139 bits each .",
    "this ensures that each segment is less than @xmath59 and can therefore be represented as an element of @xmath140 .",
    "thus , @xmath141 is the number of segments in a block , where a block is @xmath100 bits long . in this",
    "setting , each block @xmath75 can be represented as a vector @xmath142\\in \\z_q^m$ ] .",
    "let @xmath62 be a subgroup of @xmath143 having order @xmath59 .",
    "that is , @xmath62 consists of the order @xmath59 elements in @xmath144 .",
    "then , @xmath50 random elements @xmath145 are selected .",
    "let @xmath146 be a digital signature scheme ( see section  [ dig_sig ] ) where the algorithm sign takes messages in @xmath147 as input and outputs signatures of size @xmath24 bits each .",
    "let the pair of signing and verification keys for @xmath148 be @xmath149 .",
    "the setup algorithm outputs the primes @xmath135 and @xmath59 , the secret key @xmath150 , the public parameters @xmath151 , and the descriptions of @xmath62 and @xmath148 .    * * format of a tag**the client computes the homomorphic hash  @xcite on a block @xmath152\\in \\z_q^m$ ] as @xmath153 using the signature scheme @xmath148 , the client generates the final authentication tag for the block @xmath75 as @xmath154 where ` addr ` is the physical address the data block @xmath75 is written to at time @xmath97 and ` fid ` is the file - identifier of the data file the block @xmath75 belongs to .    * * collision - resistance and homomorphic properties**as shown in  @xcite , given that the discrete log assumption ( see section  [ dislog ] ) holds in @xmath62 , it is computationally hard to find two data blocks @xmath131 and @xmath132 such that @xmath155 and @xmath156 ( _ collision - resistance _ property ) .    on the other hand , given two data blocks @xmath157\\in \\z_q^m$ ] and @xmath158\\in \\z_q^m$ ] , any linear combination of @xmath131 and @xmath132 can be written as @xmath159\\in \\z_q^m$ ] .",
    "therefore , @xmath160 can be computed as @xmath161 ( _ homomorphic _ property ) .    * * size of a tag**the size of an authentication tag @xmath162 is the sum of @xmath163 ( that is , @xmath164 bits ) and the size of signature of @xmath148 . if we use the standard ecdsa ( elliptic curve digital signature algorithm )  @xcite as the signature scheme @xmath148 , then each signature is @xmath165 bits long bits  @xcite .",
    "however , the verification of a signature is more expensive due to computation of bilinear pairings  @xcite . ] .",
    "thus , @xmath166 is also @xmath24 bits .    * * improvement in cost of tag computation**to compute the homomorphic hash @xmath160 on a block @xmath75 using eqn .",
    "[ eqn : tag ] , it requires @xmath50 exponentiations and @xmath167 multiplications modulo @xmath135 .",
    "we can reduce this computational complexity in the following way at the cost of the client storing @xmath50 elements of @xmath168 which is essentially equivalent to just one block .",
    "the client chooses @xmath169 and @xmath170 .",
    "the client sets @xmath171 for each @xmath172 $ ] .",
    "the client includes the vector @xmath173 $ ] and @xmath60 in her secret key @xmath174 and makes @xmath175 public as before .",
    "now , the homomorphic hash @xmath160 on a block @xmath75 is computed as @xmath176 which requires only _ one _ exponentiation modulo @xmath135 along with @xmath50 multiplications and @xmath167 additions modulo @xmath59 .",
    "this is a huge improvement in the cost for computing an authentication tag . on the other hand ,",
    "the storage overhead at the client s side is @xmath177 which is same as the size of a single block @xmath75 .",
    "considering the fact that the client outsources millions of blocks to the cloud server , this amount of client storage is reasonable for all practical purposes .",
    "the storage structures for @xmath81 and @xmath82 are exactly the same as those for h and c , respectively , except that the authentication tags ( instead of data blocks ) are stored in @xmath81 and @xmath82 ( see section  [ storage_blocks ] for structures of h and c ) .",
    "there are three types of operations involved in a dynamic por scheme .",
    "the client can read , write and audit her data stored on the cloud server .",
    "the read and write operations are _ authenticated _ in that the client can verify the authenticity of these operations .",
    "we note that though the client herself performs reads and writes on her data , she can delegate the auditing task to a third party auditor ( tpa ) for a publicly verifiable scheme .",
    "as our scheme is _ publicly verifiable _ , we use the term _ verifier _ to denote an auditor who can be a tpa or the client herself .",
    "[ fig : flow ] gives an overview of the communication flow between the client and the server during these operations .",
    "reads are performed directly from the unencoded buffer u. the authenticity and freshness of the block read can be guaranteed by using a merkle hash tree  @xcite ( or a similar data structure like rank - based authenticated skip list  @xcite ) over the blocks of u. that is , the blocks of u constitute the leaf - nodes of the merkle hash tree ( see section  [ mht ] for a brief description of a merkle hash tree ) . the server sends the merkle proof @xmath178 containing the requested block and the labels of the nodes along the associated path of the tree to the client .",
    "the client maintains the up - to - date value of the root - digest of the merkle hash tree ( or the label of the root node of the rank - based authenticated skip list ) , and she verifies the proof @xmath178 with respect to this root - digest .",
    "we note that the size of the root - digest of the merkle hash tree is @xmath24 bits .",
    "let ` updtype ` denote the type of a write operation which can be insertion of a new block after the @xmath73-th block , deletion of the @xmath73-th block or modification of the @xmath73-th block .",
    "a write operation affects the buffers in the following way .    *",
    "* * write on u**as the buffer u is unencoded , a write operation on u can be performed in a similar way as done on the data blocks in a dynamic provable data possession ( pdp ) scheme  @xcite .",
    "+ let @xmath83 be the root - digest of the current merkle hash tree which is stored at the client s side .",
    "the client performs an _ authenticated _ read on the @xmath73-th data block of u ( as described above ) . if the associated merkle proof @xmath178 does not match with @xmath83 , the client aborts",
    "otherwise , she computes , from @xmath178 , the value that would be the new root - digest ( say , @xmath179 ) if the write operation is correctly performed on u stored at the server .",
    "the client stores @xmath179 temporarily at her end and asks the server to perform the write on u. the server performs this write operation on u , computes the root - digest @xmath180 of the merkle hash tree and sends @xmath180 to the client .",
    "the client verifies whether @xmath181 if they are not equal , the client aborts",
    ". otherwise , the client sets @xmath182 at her end . *",
    "* * write on h and @xmath81**we assume that deletion of a block in u corresponds to insertion of a block ( with ` null ` content ) in the hierarchical log h. therefore , for a write of any ` updtype ` ( i.e. , insertion , deletion or modification ) , only insertions take place in h. the way a ( possibly encoded ) block @xmath75 is inserted in h is discussed in details in section  [ buff_h ] .",
    "the cloud server itself performs this operation on h. + an insertion in @xmath81 is performed by the client herself as this procedure requires the knowledge of secret information held by the client .",
    "the client computes the authentication tag on the ( possibly encoded ) block and insert it in @xmath81 .",
    "the underlying basic operation of the rebuild phase of h is to compute a linear combination @xmath75 ( e.g. , @xmath183 of two blocks @xmath131 and @xmath132 ( see eqn .  1 and  2 in fig .",
    "[ fig : mixx ] ) .",
    "similarly , the corresponding operation for the rebuild of @xmath81 is to compute @xmath162 given @xmath184 and @xmath185 . for @xmath186 ,",
    "the client first downloads @xmath187 and verifies the signature on @xmath188 by checking whether @xmath189 where @xmath49 is the verification key for the signature scheme @xmath148 .",
    "we note that ` addr`@xmath190 ( or ` addr`@xmath191 ) is the physical address of the block @xmath131 ( or @xmath132 ) written at time @xmath192 ( or @xmath193 ) , and ` fid ` is the file - identifier of the data file the block @xmath75 belongs to . for any block in h and c ,",
    "the time when the block was written most recently can be easily computed from the current time itself .",
    "if the verification passes , the client computes @xmath194 and @xmath162 subsequently .",
    "this requires two exponentiations and one multiplication modulo @xmath135 along with one sign and two verify operations . * * * write on c and @xmath82**as mentioned in section  [ buff_c ] , c ( @xmath82 for authentication tags ) is rebuilt after every @xmath68 writes .",
    "the server performs a rebuild on c , whereas a rebuild on @xmath82 is performed by the client .",
    "basic operations involved in rebuilds of c and @xmath82 are the same as those for rebuilds of h and @xmath81 , respectively , and thus are omitted here .      in the _ challenge _ phase , the verifier chooses @xmath195 random locations @xmath196 from different levels ( @xmath24 locations from each level ) of h and c. then , she sends a challenge set @xmath197 to the cloud server , where @xmath198 are random coefficients . in the _ response _ phase",
    ", the server sends to the verifier a proof containing @xmath199 and @xmath200 . upon receiving the proof from the server , the verifier verifies each of the signatures on @xmath201 .",
    "then , she computes @xmath202 and @xmath203 using eqn .",
    "[ eqn : tag ] . finally , the verifier checks whether @xmath204 and outputs 0 if any of the verifications fails ; she outputs 1 , otherwise .",
    "we define security of a dynamic por scheme  @xcite and show that our scheme described in section  [ scheme ] is secure according to this definition .",
    "we also show that the server can not pass an audit without storing _ all _ data blocks properly , except with some probability negligible in @xmath1 .",
    "a secure dynamic por scheme offers the following guarantees .    * * * authenticity and freshness**the authenticity property requires that the cloud server can not produce valid proofs during authenticated reads , writes and audits without storing the corresponding blocks and their respective authentication information untampered , except with a probability negligible in the security parameter @xmath1 .",
    "+ for dynamic data , the client can modify an existing data block .",
    "however , a malicious cloud server may discard this change and keep an old copy of the block .",
    "as the old copy of the block and its corresponding tag constitute a valid pair , the client has no way to detect if the cloud server is storing the _ fresh _ ( latest ) copy .",
    "thus , the client must be convinced that the server has stored the up - to - date blocks . * * * retrievability**we first describe the following security game between the challenger and the adversary . * * the adversary selects a file @xmath67 associated with a file - identifier ` fid ` to store .",
    "the challenger processes the file to form another file @xmath71 and returns @xmath71 to the adversary .",
    "the challenger stores only some metadata for verification purpose . * * the adversary adaptively chooses a sequence of operations defined by @xmath205 ( @xmath206 is polynomial in the security parameter @xmath1 ) , where @xmath207 is a read , a write or an audit .",
    "the challenger executes these operations on the file stored by the adversary . for each operation",
    ", the challenger verifies the response sent by the adversary and updates the metadata at her end only if the response passes the verification . *",
    "* let @xmath208 be the final state of the file after @xmath206 operations .",
    "the challenger has the latest metadata for the file @xmath208 .",
    "now , she executes an audit protocol with the adversary .",
    "the challenger sends a random challenge set @xmath209 to the adversary , and the adversary returns a cryptographic proof to the challenger .",
    "the adversary wins the game if the verification algorithm accepts the proof .",
    "+ the retrievability of data requires that , given a probabilistic polynomial - time adversary @xmath4 that can win the security game described above with some non - negligible probability , there exists a polynomial - time extractor algorithm @xmath210 that can extract _ all _ the blocks ( except with negligible probability ) by challenging @xmath4 for a polynomial ( in @xmath1 ) number of times and verifying the responses sent by @xmath4 .",
    "the algorithm @xmath210 has _ black - box rewinding access _ to @xmath4 .",
    "our scheme satisfies the following properties required for security .    *",
    "* authenticity and freshness * the authenticity and freshness of reads and writes on u are guaranteed by the use of a merkle hash tree on the blocks of u. every read or write operation is associated with a merkle proof ( corresponding to the up - to - date root - digest ) which is hard to forge due to the collision - resistant hash function @xmath23 used in the construction of the merkle hash tree ( see section  [ mht ] ) . + as discussed in section  [ tag_gen ] , due to the collision - resistance property of the authentication tags , it is computationally hard to find two data blocks @xmath131 and @xmath132 such that @xmath155 and @xmath156 . additionally , an authentication tag for a block @xmath75 is of the form @xmath211 , where the signing algorithm sign uses the secret key @xmath48 of the client and @xmath97 is the last write - time ( computable from the current time ) of the block @xmath75 .",
    "the authenticity and freshness of h , @xmath81 , c and @xmath82 ( checked during an audit ) directly follow from these facts combined . * * * retrievability**given that our scheme satisfies the _ authenticity _ and _ freshness _ properties mentioned above , it is not hard to see that there exists a polynomial - time extractor algorithm @xmath210 , for each adversary @xmath4 that wins the security game described in section  [ security_def ] with some non - negligible probability , that can extract at least @xmath212-fraction of the data blocks ( for some @xmath212 ) with the help of gaussian elimination  @xcite .",
    "use of a @xmath212-rate erasure code ensures retrievability of all the blocks of the data file . in our case , @xmath213 .",
    "as we mention in section  [ operations ] , all the levels of h and the buffer c are audited with @xmath24 random locations each . to delete a block in any of these levels",
    ", the server has to actually delete half of the blocks in that level .",
    "this is true due to the use of a @xmath92-erasure code for each level @xmath214 .",
    "thus , if the server has corrupted half of the blocks in any level , then the server passes an audit with probability @xmath215 which is negligible in the security parameter @xmath1 .",
    "we analyze the performance of the following types of operations ( described in section  [ operations ] ) involved in our publicly verifiable dynamic por scheme .    * * * read**for an authenticated read on the data block @xmath75 present in u , the server sends the corresponding merkle proof @xmath178 which consists of the block @xmath75 , the data block in the sibling leaf - node of @xmath75 and the hash values along the associated path of the merkle hash tree ( see section  [ mht ] ) .",
    "thus , a read operation takes @xmath216 communication bandwidth between the client and the server .",
    "+ to reduce this cost , the client can generate authentication tags on the data blocks of u ( as discussed in section  [ tag_gen ] ) and construct a merkle tree over these tags instead of the data blocks . in this setting , @xmath178 consists of @xmath162 , the authentication tag in its sibling leaf - node and the hash values along the associated path .",
    "this reduces the communication bandwidth between the client and the server for a read to @xmath217 . * * * write**a write operation incurs the following costs . *",
    "* _ write on u_:a write operation on u involves an authenticated read operation followed by the verification of eqn .",
    "[ eqn : mht ] .",
    "thus , each write operation requires @xmath217 bandwidth between the client and the server ( for communicating @xmath178 and @xmath180 ) . *",
    "* _ write on h and @xmath81_:the cost of a write on h is @xmath129 ( see section  [ buff_h ] ) . similarly ,",
    "the cost of a write on @xmath81 is @xmath218 as the blocks are replaced by their authentication tags in @xmath81 and the size of a tag is @xmath24 bits . * * _ write on c and @xmath82_:c ( or @xmath82 ) is rebuilt after every @xmath68 writes .",
    "as mentioned in section  [ buff_c ] , a write operation on c costs @xmath129 both in time and bandwidth .",
    "similarly , the cost of a write on @xmath82 is @xmath218 .",
    "* * * audit**during an audit , for a challenge set @xmath209 containing @xmath195 random locations @xmath196 and random coefficients @xmath219 , the server computes and sends to the verifier a proof containing @xmath199 and @xmath200 .",
    "thus , the bandwidth required for an audit is given by @xmath220 .    * * comparison among dynamic por schemes**we compare our scheme with other existing dynamic por schemes which is summarized in table  [ tab : comparison_por ] .",
    "the comparison is based on the asymptotic complexity for different parameters .",
    "some of the figures mentioned in table  [ tab : comparison_por ] are taken from  @xcite .",
    "table  [ tab : parameters ] mentions typical values of some parameters used in our scheme  @xcite .",
    ".comparison among dynamic por schemes based on different parameters ( asymptotic complexity ) [ cols=\"^,^,^,^,^,^,^ \" , ]     additionally , one drawback of the publicly verifiable scheme proposed by shi et al .",
    "@xcite is due to the fact that one or more merkle hash trees ( _ separate _ from the merkle hash tree maintained for u ) are maintained to ensure the integrity of the blocks in the _ hierarchical log _ h ( one for the entire log or one for each of its levels ) . to enable a third party auditor ( tpa ) to audit the data blocks residing at different levels of this log , the root - digests of these trees need to be made public",
    "however , some of these root - digests are changed as often as new data blocks are inserted in the hierarchical log structure , thus resulting in a change in the public parameters for _ each _ write .",
    "this incurs an additional ( non - trivial ) overhead for validation and certification of the public parameters for every write operation . on the other hand ,",
    "the public parameters in our publicly verifiable dynamic por scheme are fixed throughout the execution of the protocols involved .",
    "in this work , we have proposed a dynamic por scheme where the client can update her data file after the initial outsourcing of the file to the cloud server and retrieve all of her data at any point of time .",
    "our scheme is publicly verifiable , that is , anyone having the knowledge of the public parameters of the scheme can perform an audit on the client s behalf .",
    "our scheme offers security guarantees of a dynamic por scheme .",
    "our publicly verifiable dynamic por scheme is more efficient ( in terms of the cost of a write or an audit ) than the only known construction of a practical and publicly verifiable dynamic por scheme  @xcite .",
    "ateniese , g. , burns , r.c . ,",
    "curtmola , r. , herring , j. , kissner , l. , peterson , z.n.j . , song , d.x . : provable data possession at untrusted stores . in : acm conference on computer and communications security , ccs 2007 .",
    "( 2007 ) 598609    ateniese , g. , pietro , r.d . , mancini , l.v .",
    ", tsudik , g. : scalable and efficient provable data possession . in : international conference on security and privacy in communication networks ,",
    "securecomm 2008 .",
    "( 2008 )  9                    curtmola , r. , garay , j.a . , kamara , s. , ostrovsky , r. : searchable symmetric encryption : improved definitions and efficient constructions . in : acm conference on computer and communications security , ccs 2006 .",
    "( 2006 ) 7988            garg , s. , gentry , c. , halevi , s. , raykova , m. , sahai , a. , waters , b. : candidate indistinguishability obfuscation and functional encryption for all circuits . in : ieee symposium on foundations of computer science , focs 2013 .",
    "( 2013 ) 4049          guan , c. , ren , k. , zhang , f. , kerschbaum , f. , yu , j. : symmetric - key based proofs of retrievability supporting public verification . in : european symposium on research in computer security - esorics 2015 , part i. ( 2015 ) 203223    impagliazzo , r. , jaiswal , r. , kabanets , v. : approximately list - decoding direct product codes and uniform hardness amplification . in : ieee symposium on foundations of computer science - focs 2006 .",
    "( 2006 ) 187196                              wang , q. , wang , c. , ren , k. , lou , w. , li , j. : enabling public auditability and data dynamics for storage security in cloud computing .",
    "transactions on parallel and distributed systems * 22*(5 ) ( 2011 ) 847859"
  ],
  "abstract_text": [
    "<S> cloud service providers offer various facilities to their clients . </S>",
    "<S> the clients with limited resources opt for some of these facilities </S>",
    "<S> . they can outsource their bulk data to the cloud server . </S>",
    "<S> the cloud server maintains these data in lieu of monetary benefits . </S>",
    "<S> however , a malicious cloud server might delete some of these data to save some space and offer this extra amount of storage to another client . </S>",
    "<S> therefore , the client might not retrieve her file ( or some portions of it ) as often as needed . </S>",
    "<S> proofs of retrievability ( por ) provide an assurance to the client that the server is actually storing all of her data appropriately and they can be retrieved at any point of time . in a dynamic por scheme , the client can update her data after she uploads them to the cloud server . </S>",
    "<S> moreover , in publicly verifiable por schemes , the client can delegate her auditing task to some third party specialized for this purpose . in this work , </S>",
    "<S> we design a publicly verifiable dynamic por scheme that is more efficient ( in terms of bandwidth required between the client and the server ) than the `` state - of - the - art '' publicly verifiable dynamic por scheme . </S>",
    "<S> we also analyze security and performance of our scheme . </S>"
  ]
}