{
  "article_text": [
    "in the context of coded communication , the channel coding theorem relates the error probability and the code rate , showing that there exist codes whose error probability tends to zero provided that the code rate is smaller than the channel capacity . for uncoded systems , the error probability and the channel capacity",
    "are also related . in particular , references @xcite show that given one of the two values , tight bounds on the other can be given for the family of binary - input memoryless and symmetric ( bims ) channels .",
    "such channels are described by the channel transition probability @xmath2 , where @xmath3 and @xmath4 .",
    "we assume that the channel output alphabet @xmath5 has finite size , though our approach also holds for well - behaved channels with infinite alphabet size , like the binary - input additive white gaussian noise ( biawgn ) channel .",
    "we adopt gallager s definition of symmetric channel @xcite , that is , a channel is said symmetric if the channel transition probability matrix ( rows corresponding to input values ) is such that it can be partitioned in submatrices for which each row is a permutation of any other row and each column is a permutation of any other column .",
    "both the binary erasure channel ( bec ) and the binary symmetric channel ( bsc ) are symmetric .",
    "more precisely , references @xcite show that the uncoded error probability of any bims channel with capacity @xmath0 is upper - bounded by that of the bec and lower - bounded by that of the bsc of the same capacity .",
    "similar results have been found in @xcite for the bhattacharyya parameter , a simple upper bound to the uncoded error probability ; here only the extremal property of the bec was proved . in the context of iterative decoding , analogous",
    "extremal properties of the bec and bsc have been found @xcite for the building blocks of iterative decoders for low - density parity - check codes , namely variable - node and check - node decoders .",
    "upper and lower bounds to the error probability of good codes can be given in terms of error exponents , e.g.  gallager s random coding bound ( * ? ? ?",
    "5.6.3 ) , the sphere - packing bound by shannon _",
    "_ @xcite and arimoto s strong converse bound @xcite .",
    "these exponents are expressed as optimization problems involving gallager s @xmath1 function ( * ? ? ?",
    "* eq .  5.6.14 ) , @xmath6 where @xmath7}{p_{y|x}(y|x)^{\\frac{1}{1+\\rho}}}\\right)^\\rho\\right]\\ ] ] and the pair @xmath8 is distributed according to @xmath9 .",
    "here and throughout the paper @xmath10 $ ] denotes the expectation of a random variable and all logarithms are in base @xmath11 .",
    "equiprobable inputs maximize the @xmath1 function for bims channels @xcite , and we henceforth assume such distribution , i.e.  @xmath12 .    in this paper , we characterize the feasible values of @xmath13 for an arbitrary bims channel of fixed channel capacity @xmath0 and show that the @xmath1 function is upper - bounded ( resp .",
    "lower - bounded ) by that of the bec ( resp .",
    "bsc ) of the same capacity . since the aforementioned exponents are expressed using the @xmath1 function , we are able to find their extremal values .",
    "in fact , our analysis leads to similar results for the cutoff rate , the bhattacharyya parameter , the channel dispersion and to a number of other extensions .",
    "the @xmath14 functions for the bec and bsc of erasure / crossover probability @xmath15 , respectively denoted by @xmath16 and @xmath17 , are given by @xmath18 using the capacity expressions for the bec , @xmath19 , and bsc , @xmath20 , we can find the erasure / crossover probability corresponding to a given capacity @xmath0 and parametrize the @xmath16 and function @xmath17 as functions of @xmath0 , namely @xmath21 where @xmath22 is the binary entropy function , and @xmath23 denotes the inverse of @xmath24 for @xmath25 $ ] .",
    "@xmath26 are respectively defined as the inverses of eqs .",
    ", with respect to @xmath0 .    for bims channels , one has the bounds @xmath27 and @xmath28 for @xmath29 and @xmath30 for @xmath31 .",
    "this is a consequence of the facts that @xmath14 is non - negative and non - increasing for @xmath32 ( * ? ? ?",
    "5b ) , that @xmath33 , and that @xmath34 . it is however not apparent whether further limitations exist on the feasible pairs of capacity @xmath0 and @xmath14 . against this first impression",
    ", the next theorem tightly characterizes the set of possible pairs of capacity @xmath0 and @xmath14 function for any bims channel ( see figure [ fig : extremes_f0_c ] ) . in the next section",
    ", we apply this theorem and prove several analogous characterizations for other relevant quantities in the analysis of the error probability over bims channels .",
    "[ th : extremes_f0 ] for any bims channel with capacity @xmath0 and function @xmath14 for @xmath35 , the following statements hold    1 .   the function @xmath14 of the channel satisfies @xmath36 2 .   the capacity @xmath0 of the channel satisfies @xmath37    the extremes in  are attained by the bec and the bsc .",
    "furthermore , for a given pair @xmath38 satisfying the inequalities in or , there exists a bims channel with capacity @xmath0 and function @xmath14 .",
    "conversely , if the inequalities do not hold for the pair @xmath38 , there exists no such bims channel with capacity @xmath0 and function @xmath14 .      the proof is built around the idea that every bims channel admits a decomposition into subchannels that are bscs .",
    "this decomposition follows directly from gallager s definition of symmetric channels @xcite as used in this paper .",
    "a formal description may be found e.g. in @xcite .",
    "here we deem identical the bec with erasure probability 1 and the bsc with crossover probability @xmath39 . in this decomposition , each channel output @xmath40 is associated with an index @xmath41 which is independent of the input and depends on the channel output only .",
    "we denote by @xmath42 the probability mass or density function of subchannel @xmath43 , and by @xmath44 the corresponding binary output alphabet of the bsc with index @xmath43 .",
    "assuming such a decomposition , and since @xmath45 @xcite we have @xmath46}{p_{y|x}(y|x)^{\\frac{1}{1+\\rho}}}\\right)^\\rho\\right]\\\\ & = { \\mathbb{e}}\\left[{\\mathbb{e}}\\left [ \\left(\\frac{{\\mathbb{e}}\\bigl[p_{y|x , a}(y|x',a)^{\\frac{1}{1+\\rho}}|y , a\\bigr]}{p_{y|x , a}(y|x , a)^{\\frac{1}{1+\\rho}}}\\right)^\\rho\\bigg| ~a\\right]\\right]\\\\ & = { \\mathbb{e}}\\left[f^{{\\rm bsc}}(\\rho;c(a))\\right],\\end{aligned}\\ ] ] where @xmath47 denotes the capacity of subchannel @xmath43 .",
    "the following lemma is proved in appendix [ app : f - is - concave ] .",
    "[ lem : f - is - concave ] the function @xmath48 is concave in @xmath49 $ ] for any @xmath32 , non - decreasing for @xmath31 , and non - increasing for @xmath29 .    noting that @xmath50 = c$ ] , and given the concavity of the function @xmath48",
    ", we apply jensen s inequality to obtain @xmath51   \\\\      & \\leq f^{{\\rm bsc}}(\\rho ; { \\mathbb{e}}[c(a ) ] )   \\\\      & =    f^{{\\rm bsc}}(\\rho;c )   .",
    "\\end{aligned}\\ ] ] the bound is obviously achieved when the channel is a bsc .",
    "since @xmath48 is concave , we can lower - bound it by a straight line joining the points @xmath52 ( @xmath53 ) and @xmath54 ( @xmath55 ) ( see figure [ fig : extremes_f0_c ] ) , and then evaluate the expectation , i.e. , @xmath56 this bound is obviously achieved when the channel is a bec , thus proving eq . .     for @xmath57 .",
    "the upper curves correspond to the bsc and the lower straight lines to the bec . ]",
    "eq . determines the boundaries of the region of feasible pairs @xmath38 .",
    "since @xmath48 is concave and @xmath58 is convex , the region of feasible pairs is convex .",
    "moreover , the functions @xmath48 and @xmath58 are non - decreasing for @xmath31 and non - increasing for @xmath29 . fixing the value of @xmath14",
    ", the convexity of the region implies eq . .",
    "we next prove that the region of feasible pairs @xmath38 is connected by constructing a bims channel with corresponding capacity @xmath0 and function @xmath14 .",
    "consider a binary symmetric - erasure channel ( bsec ) with input alphabet @xmath59 , output alphabet @xmath60 , cross - over probability @xmath61 and erasure probability @xmath62 .",
    "its transition probabilities are given by @xmath63 , @xmath64 , and @xmath65 .",
    "the capacity @xmath66 and function @xmath67 are respectively @xmath68 for fixed @xmath0 , there exist several bsec channels with capacity @xmath0 , among them a bsc and a bec . each of them is characterized by a pair of probabilities @xmath61 and @xmath62",
    ". the corresponding @xmath67 function is given by eq . .",
    "since the function @xmath67 is continuous in @xmath61 and @xmath62 , one can always find a bsec with capacity @xmath0 whose function @xmath67 coincides with the desired @xmath14 .      in the proof of theorem",
    "[ th : extremes_f0 ] , we exploited the fact that the region of feasible pairs @xmath38 is convex and connected to characterize the extreme values of the capacity @xmath0 or the function @xmath14 . in this section",
    ", we apply the theorem to provide extreme values for other relevant quantities in the error probability analysis of channel coding .",
    "a simple extension to channel parameters @xmath69 given by @xmath70 , where @xmath71 is a monotonic continuous function , will prove convenient .",
    "[ th : extremes_general ] let the channel parameter @xmath69 be given by @xmath70 , where @xmath71 is a monotonic strictly increasing continuous function .",
    "for any bims channel , we have that    1 .   the channel parameter @xmath72 satisfies @xmath73 2 .",
    "the channel capacity @xmath0 satisfies @xmath74    the inequalities  are reversed if @xmath71 is monotonic , strictly decreasing and continuous .",
    "[ [ gallagers - function ] ] gallager s function + + + + + + + + + + + + + + + + + + +    by letting @xmath75 , the previous theorem readily gives the extremes of gallager s function @xmath76 for a fixed capacity , and the extremes of the capacity for a fixed @xmath1 .",
    "[ [ cutoff - rate ] ] cutoff rate + + + + + + + + + + +    a particular case of the @xmath1 function is the cutoff rate , given by @xmath77 .",
    "thus , the above result also gives the extremes of the cutoff rate .",
    "[ [ bhattacharyya - parameter ] ] bhattacharyya parameter + + + + + + + + + + + + + + + + + + + + + + +    a related quantity is the bhattacharyya parameter @xmath78 , given by @xmath79 the bsc / bec have the largest / smallest possible bhattacharyya parameter for bims channels of capacity @xmath0 , interestingly giving the reverse extremes of the uncoded error probability @xcite .",
    "this result recovers sason s @xcite and arikan s @xcite bound for the bec , and provides the extreme in the other direction attained by the bsc .",
    "[ fig : extremes_cz ] shows the bounds to @xmath0 for a given value of @xmath78 from theorem [ th : extremes_general ] , as well as arikan s generic bounds for binary - input discrete memoryless channels ( * ? ? ?",
    "( 1 ) , ( 2 ) ) , illustrating some improvement .     as a function of the bhattacharyya parameter @xmath78 .",
    "s upper and lower bounds ( * ? ? ?",
    "( 1 ) , ( 2 ) ) and the biawgn channel curve ( dashed line ) are also shown for reference . ]",
    "[ [ random - coding - exponent ] ] random coding exponent + + + + + + + + + + + + + + + + + + + + + +    the random coding exponent @xmath80 ( * ? ? ? * sect .",
    "5.6 ) , given by @xmath81 provides an upper bound to the error probability of codes of rate @xmath82 .",
    "this exponent involves a maximization of a function that , for fixed @xmath83 falls under the conditions for applicability of theorems  [ th : extremes_f0 ] and  [ th : extremes_general ] .",
    "therefore , the exponent @xmath80 satisfies @xmath84 figure [ fig : error_exponents_extremes_c ] illustrates the extremes of random - coding error exponents @xmath80 .",
    "the random - coding error exponent of an arbitrary bims channel must lie in the shaded area , two such examples are the biawgn channel of the same capacity ( with and without fading ) .        [",
    "[ expurgated - error - exponent ] ] expurgated error exponent + + + + + + + + + + + + + + + + + + + + + + + + +    for rates below the channel critical rate , the expurgated error exponent @xmath85 ( * ? ? ? * sect .",
    "5.7 ) , given by @xmath86 provides a tighter estimate of the error probability of good codes than the random - coding exponent .",
    "the function @xmath87 is expressed in terms of the bhattacharyya parameter @xmath78 as @xmath88 theorem  [ th : extremes_general ] provides the extremes of the expurgated exponent .",
    "[ [ strong - converse - exponent ] ] strong converse exponent + + + + + + + + + + + + + + + + + + + + + + + +    in @xcite , arimoto lower - bounded the error probability of block codes at rates above capacity in terms of the function @xmath89 given by @xmath90 theorem  [ th : extremes_general ] also provides the extremes of this exponent .",
    "[ [ sphere - packing - exponent ] ] sphere - packing exponent + + + + + + + + + + + + + + + + + + + + + + +    the error probability of codes of rate @xmath82 is lower - bounded by a bound that depends on the sphere - packing exponent @xcite @xmath91 , given by @xmath92 again , theorem  [ th : extremes_general ] provides the extremes of this exponent .",
    "[ [ threshold - decoding - error - exponents ] ] threshold - decoding error exponents + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the exponent of random - coding bounds based on threshold decoding can also be expressed in closed form .",
    "shannon @xcite derived the exponent of feinstein s bound to the error probability @xcite .",
    "more generally , the exponent corresponding to a generalized form of feinstein s bound @xcite can be expressed as @xmath93 theorem [ th : extremes_general ] directly gives the error exponent extremes for the generalized feinstein s bound .",
    "the exponent of the dependence - testing bound @xcite is @xcite @xmath94 where @xmath95 , for @xmath96 , and @xmath97}{p_{y|x}(y|x)^s}\\right)^\\rho\\right].\\ ] ] following similar and somewhat simpler steps to those in the proof of lemma [ lem : f - is - concave ] , one can prove that @xmath98 , evaluated for a bsc with capacity @xmath0 , is concave in @xmath0 .",
    "therefore , theorem  [ th : extremes_general ] holds and shows that the exponent of the dt bound has similar extreme values .",
    "[ [ channel - dispersion ] ] channel dispersion + + + + + + + + + + + + + + + + + +    recently , the gaussian approximation to the error probability @xmath99 of length-@xmath100 codes at rates close to the capacity has received renewed attention . in this approximation ,",
    "a critical channel parameter is the dispersion @xmath101 , which for bims channels @xcite is given by @xmath102 moreover , it can be proved that one can choose either the @xmath13 function or the simpler @xmath103 to compute the latter derivative , that is @xmath104 .",
    "as proved in appendix [ app : bounded_i3 ] , the third derivative of @xmath103 at @xmath105 is bounded for bims channels .",
    "thus , a second - order taylor expansion of @xmath103 around @xmath106 shows that @xmath107 has the same extremes as @xmath103 . as illustration ,",
    "figure [ fig : extremes_dispersion_v ] depicts the possible values of channel dispersion as a function of the capacity @xmath0 of the bims channel . the dashed line , which lies within the shaded area indicating the feasible region of pairs capacity / dispersion , corresponds to the biawgn channel .    .",
    "]    [ [ error - probability - of - specific - codes ] ] error probability of specific codes + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    our theorems may also be applied to specific codes @xmath108 with a given distance spectrum by means of the shulman - feder bound @xcite ( see also @xcite ) given by @xmath109 where @xmath110 is a function of the distance spectrum of the code that quantifies how far the distance spectrum of @xmath108 is from that of the ensemble average .",
    "[ [ exact - error - probability ] ] exact error probability + + + + + + + + + + + + + + + + + + + + + + +    one might wonder whether our extremal results extend to the actual error probability .",
    "the answer is not immediately obvious . for uncoded transmission ( a code of length @xmath111 and rate @xmath112 ) over a given bims channel of capacity @xmath0",
    "the error probability @xmath113 is upper- and lower - bounded by that of the bec and the bsc , respectively , @xmath114 @xcite .",
    "in contrast , the extremes of the exponential bounds to the error probability , including the bhattacharyya parameter , are reversed .",
    "this phenomenon suggests the existence of a pair @xmath115 such that a crossing point occurs , in the sense that for rates above ( resp .  below )",
    "@xmath116 the extremes may be those of uncoded transmission ( resp .",
    "the error exponents ) .",
    "[ [ connection - with - arikan - telatar - and - alsan ] ] connection with arikan , telatar @xcite , and alsan @xcite + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    unpublished work by arikan and telatar @xcite uncovered results of similar nature to those reported in this paper , showing that for channels with a fixed rate @xmath117 , for @xmath118 , the random coding exponent satisfies @xmath119 for @xmath120 we have that @xmath121 and we obtain the trivial result that @xmath122 . instead",
    ", our results compare channels of a fixed capacity and provide the extremal values of the random - coding exponent and other quantities .",
    "the suitability of either of these two approaches to the problem may depend on the specific application .",
    "a more recent result by alsan @xcite recovers both theorem  [ th : extremes_f0 ] in this paper and the results in @xcite as particular cases , for bims channels in the interval @xmath123 .",
    "we aim at proving the concavity of the function @xmath124 where @xmath125 is itself a function of @xmath0 , namely @xmath126 . without loss of generality ,",
    "we limit our attention to the interval @xmath127 $ ] .",
    "the function is concave if @xmath128 .",
    "applying the chain rule of derivation , we have that @xmath129 direct computation gives @xmath130 an application of the inverse function theorem yields @xmath131 the derivatives with respect to @xmath0 are therefore given by @xmath132 since we have that @xmath133 for @xmath31 and @xmath134 for @xmath29 , we conclude that @xmath135 is increasing and decreasing in the respective ranges of @xmath83 .",
    "let @xmath140 $ ] . with this change of variables we obtain @xmath141 we wish to show that @xmath142 .",
    "the partial derivative with respect to @xmath83 is given by @xmath143 we are interested in the sign of @xmath144 , whose derivative is in turn given by @xmath145 we readily see that @xmath146,\\\\   \\frac{\\partial g_0(z,\\rho)}{\\partial \\rho } & \\leq 0,~~~~~\\rho\\in[1,+\\infty).\\end{aligned}\\ ] ]      * @xmath148 in @xmath149 $ ] , since @xmath144 is non - decreasing and @xmath150 , * @xmath151 in @xmath152 $ ] , since @xmath144 is non - decreasing and @xmath153 , * @xmath151 in @xmath154 , since @xmath144 is non - increasing and @xmath155 .",
    "we wish to prove that the partial derivative @xmath157 is bounded . to this end",
    ", we first note that the function @xmath158 can be expressed as @xmath159,\\end{aligned}\\ ] ] where @xmath160 is the information density , defined as @xmath161 the function @xmath158 is a cumulant generating function .",
    "its third derivative evaluated at @xmath120 gives the third - order cumulant , that is the third - order central moment , @xmath162 ( \\ln 2)^2.\\ ] ]      [ lemma : mink ] consider a memoryless channel with discrete input alphabet @xmath164 and arbitrary output alphabet @xmath5 .",
    "then , with equiprobable inputs we have @xmath165\\leq \\left(2\\log|{{\\cal x}}| + \\frac{k}{\\ln2}\\bigl(1 + |{{\\cal x}}|^{\\frac{1}{k}}\\bigr)\\right)^k.\\ ] ]    we will make use of minkowski s inequality @xmath166 where @xmath167)^{\\frac{1}{k}}. $ ] using the definition of @xmath168 , we now have that @xmath169\\right)^\\frac{1}{k}\\\\ & \\leq   2\\log |{{\\cal x}}|   + \\frac{k}{\\ln2 } + \\frac{k}{\\ln2 } |{{\\cal x}}|^\\frac{1}{k}\\end{aligned}\\ ] ] where we have used that @xmath170 ( * ? ? ?",
    "* eq . ( 4.1.37 ) ) .",
    "a.  martinez and a.  guilln  i fbregas , `` random - coding bounds for threshold decoders : error exponent and saddlepoint approximation , '' in _ 2011 ieee int .",
    "theory , saint petersburg , russia _ , jul .- aug . 2011 ."
  ],
  "abstract_text": [
    "<S> this paper determines the range of feasible values of standard error exponents for binary - input memoryless symmetric channels of fixed capacity @xmath0 and shows that extremes are attained by the binary symmetric and the binary erasure channel . </S>",
    "<S> the proof technique also provides analogous extremes for other quantities related to gallager s @xmath1 function , such as the cutoff rate , the bhattacharyya parameter , and the channel dispersion . </S>"
  ]
}