{
  "article_text": [
    "an important primitive for the _ processing _ of quantum information is the ability to _ store _ it despite constant corruptive influence of the external environment on the applied hardware and imperfections of the latter . while one approach seeks to achieve this by constructing a _ self - correcting quantum memory _",
    "( see ref .",
    "@xcite for a recent review ) , an alternative possibility is to dynamically protect the stored quantum information by constantly pumping entropy out of the system .",
    "topological quantum error correction codes @xcite store one logical qubit in a large number of physical qubits , in a way which guarantees that a sufficiently low density of errors on the physical qubits can be detected and undone , without affecting the stored logical qubit .",
    "most promising is the surface code @xcite , which requires only local four - qubit parity operators to be measured .",
    "while proposals for direct measurement of such operators exist @xcite , most of the literature focuses on time - dependent interactions between the four qubits and an auxiliary qubit , allowing to perform sequential cnot gates and to finally read the measurement result off the auxiliary qubit .",
    "see ref .",
    "@xcite for a recent review .",
    "in order to decode the syndrome information , i.e. , use the outcomes of all four - qubit measurements to find out how to optimally perform error correction , a classical computation is necessary .",
    "this classical computation is not trivial and brute force approaches are infeasible .",
    "decoding algorithms based on renormalization techniques @xcite or minimum - weight perfect matching ( mwpm ) @xcite have a runtime complexity @xmath2 and can be parallelized to @xmath4 ( neglecting logarithms ) , where @xmath0 is the linear size of the code .",
    "as these algorithms are approximative , the logical error rates achievable with them fall short of those theoretically achievable by brute force decoding .",
    "a markov chain monte carlo ( mcmc ) algorithm @xcite can cope with higher physical error rates than the two mentioned algorithms , but has super - polynomial ( yet sub - exponential ) runtime complexity . in this work",
    ", we present an efficient mcmc decoding algorithm that allows to achieve logical error rates lower than those achievable by means of mwpm @xcite .",
    "equivalently , a smaller code size is required to achieve a certain target logical error rate .",
    "our algorithm allows for trade - offs between runtime and achieved logical error rate .",
    "if we define the runtime or our algorithm to be the minimal computation time such that the achieved logical error rate is lower than the one achievable by means of mwpm , we find it to be at most @xmath5 .",
    "the runtime complexity can be parallelized to @xmath2 , thus adding complexity @xmath6 to mwpm and renormalization technique decoding algorithms . for low enough error rates",
    ", it is found that even an @xmath7 increase in the runtime relative to mwpm allows us to achieve a lower logical error rate .    in summary , in comparison to alternative algorithms @xcite our algorithm allows for lower quantum information error rates and smaller code sizes at the cost of a ( polynomially ) higher classical runtime complexity .",
    "given the current state of the art of quantum and classical information processing , shifting requirements from quantum to classical seems desirable .",
    "our algorithm is generalizable to the ( realistic ) case of imperfect stabilizer measurements , though we restrict numerical simulations in this work to the case of perfect measurements for simplicity .",
    "surface code .",
    "black dots are data qubits , grey dots are syndrome qubits that allow to read off the results of the stabilizer measurements when sequential cnot gates have been performed between them and the adjacent data qubits .",
    "stabilizer operators are either tensor products of @xmath8 operators ( acting on the data qubits around a white square / triangle ) or tensor products of @xmath9 operators ( acting on the data qubits around a blue square / triangle).,scaledwidth=50.0% ]    stabilizer operators are , in the context of the surface code , tensor products of @xmath8 or @xmath9 operators ( see fig .  [",
    "fig : code ] ) which are required to yield a @xmath10 eigenvalue when applied to the quantum state stored in the code .",
    "eigenvalues @xmath11 are treated as errors and interpreted as the presence of an _",
    "anyon_. a surface code of size @xmath0 has @xmath12 ( @xmath13- and @xmath14-qubit ) stabilizers .",
    "since all stabilizers commute , they can be measured simultaneously and hence the presence of anyons can be detected .",
    "any pauli operator @xmath8 , @xmath15 , or @xmath9 applied to a data qubit creates at least one anyon as it anti - commutes with at least one stabilizer .",
    "we call violated @xmath8-stabilizers s - anyons and violated @xmath9-stabilizers p - anyons .    given some anyon configuration @xmath16 ,",
    "the goal is to apply a series of single - qubit @xmath8 and @xmath9 operators , such that all anyons are removed and a trivial operation has been performed on the code subspace .",
    "two such hypotheses about what errors the physical qubits have suffered are equivalent if they can be deformed into each other through the application of stabilizers .",
    "equivalent error chains will lead to the same operation performed on the code subspace ( consisting of the states which are @xmath10 eigenstates of each stabilizer ) . for the surface code , there are four such equivalence classes .",
    "the goal is therefore to find the most probable equivalence class of error chains and not to find the most likely error chain .",
    "the most likely error chain need not be an element of the most likely equivalence class , though trying to correct by undoing the most likely error path is a reasonable approximation and is the idea behind minimum - weight perfect matching correction algorithms .",
    "more precisely , mwpm matches both kinds of anyons independently of each other and thus ignores potential correlations between @xmath8- and @xmath9-errors .    decoherence models in which each qubit independently is subject to the channel @xmath17 ( with @xmath18 ) allow for efficient simulation on a classical computer . while physical decoherence models may not exactly have the form of eq .",
    "( [ eq : paulichannel ] ) , they may be approximated by such a channel through a _",
    "pauli twirl approximation _ @xcite .",
    "the two most frequently studied noise models of the form of eq .",
    "( [ eq : paulichannel ] ) are _ independent bit- and phase - flip errors _",
    "( @xmath19 , @xmath20 and @xmath21 for independent bit- and phase - flip probabilities @xmath22 and @xmath23 ) and _ depolarizing noise _ ( @xmath24 ) . the theoretical maximal error rates up to which error correction is possible by exact error correction",
    "are known to be @xmath25 for independent bit- and phase - flip errors @xcite and @xmath26 for depolarizing noise @xcite .",
    "any approximate error correction algorithm will yield threshold error rates below these theoretical maxima .",
    "minimum weight matching considers bit flip errors ( which create @xmath1-anyons ) and phase flip errors ( which create @xmath27-anyons ) independently . as such",
    "it is only well designed for noise models with no correlations between @xmath8- and @xmath9-errors .",
    "errors models that do have these correlations , such as depolarizing noise , can only be treated approximately .",
    "typically this means that the correction will be done as if the bit and phase flip errors occurred with independent probabilities @xmath28 and @xmath29 , calculated according to the true ( correlated ) noise model .",
    "this suboptimal treatment of correlated noise leads to suboptimal behaviour .",
    "thresholds are significantly lower than the theoretical maxmima and the effectiveness below threshold is also significantly affected .",
    "for example , let us consider the behaviour for depolarizing noise with very low @xmath1 . in this case the probability of a logical error is dominated by the probability of the most likely fatal error pattern ( one which causes the decoder to guess the wrong equivalence class ) .",
    "this means the fatal error pattern with the minimum number of single qubit errors .",
    "perfect matching treats this noise model as one in which bit and phase flip errors occur independently with probabilities @xmath30 . a fatal error pattern that causes a logical bit flip error requires , for odd @xmath0 , at least @xmath31 single qubit bit flips to occur in a line , such that they create a pair of @xmath1-anyons separated by just over half the size of the code ( or a single @xmath1-anyon which is closer to the boundary to which it is not connected by the error chain ) .",
    "this is because the matching will incorrectly think that they were created by the @xmath32 bit flips required to create them within the opposite equivalence class , since this matching has a smaller weight .",
    "an equivalent argument holds for logical phase flips .",
    "the probability of logical errors in the low @xmath1 limit is then @xmath33 .",
    "an optimal decoder will behave slightly differently , since it can see the difference between bit - flips caused by @xmath8 errors and those caused by @xmath15 .",
    "a line of @xmath31 bit flips is then only sufficient to cause a logical bit - flip error if it contains at most one error caused by @xmath15 , since the presence of @xmath15 s in the line will create @xmath27-anyons along its length .",
    "this leaves a trail of breadcrumbs to show the decoder that the larger weight matching is in fact the correct one .",
    "an equivalent argument holds for logical phase flips .",
    "it is therefore a chain of @xmath31 errors with at most one @xmath15 error and all remaining ones either @xmath8 or @xmath9 errors that are required for a logical error .",
    "the probability of these in the low @xmath1 limit is then @xmath34 . clearly , a decoder which is able to take correlations between bit- and phase - flips into account will thus for @xmath3 lead to a logical error rate which is smaller by a factor @xmath35 than the one for standard mwpm .    in order to address this issue ,",
    "we introduce two new algorithms to perform decoding .",
    "the first , an enhanced version of mwpm , is discussed in sec .",
    "[ sec : enhanced ] .",
    "it performs optimally in the limit of @xmath3 and is also able to outperform standard mwpm for non - vanishing values of @xmath1 .",
    "it is based on performing mwpm for four sligtly modified anyon configurations and thus does not require an enhanced runtime complexity relative to mwpm .",
    "the second algorithm , discussed in sec .",
    "[ sec : mcmc ] , uses enhanced mwpm as a starting point and then performs markov chain monte carlo sampling in order to further reduce the logical error rate .",
    "this requires a runtime complexity that is at most an @xmath2 factor greater than that of mwpm .",
    "however , even this modest increase is only required for @xmath1 close to threshold . for lower values of @xmath1 ,",
    "no increase in the runtime complexity is necessary @xcite .",
    "our first method consists of only a small change to the standard mwpm decoding , but it nevertheless has a large effect . to explain this fully",
    ", we must first explain standard mwpm in more detail .    for a graph with weighted edges between an even number of vertices , edmond s mwpm algorithm @xcite finds the pairing of minimal weight efficiently .",
    "we employ the library ` blossom v ` @xcite to perform mwpm . for the graphs which are relevant for the surface code",
    ", mwpm can be performed in runtime complexity @xmath2 and can be parallelized to @xmath4 @xcite . in order to obtain such graphs ,",
    "we assign to the edge between two anyons ( corresponding to the vertices ) the minimal number of single - qubit errors necessary to link them ( their manhattan distance ) . for each anyon , we place a virtual partner on the closer boundary of the type which is able to absorb it ( top an bottom for s - anyons and left and right for p - anyons ) .",
    "we then add an edge between each anyon and its virtual partner ( with weight again given by the manhattan distance ) and zero - weight edges between all virtual anyons on the same boundary . including these virtual anyons",
    "ensures that the number of vertices in the graph is even and that each anyon can be matched to the closest absorbing boundary .",
    "the zero - weight edges ensure that unnecessary virtual anyons can be removed at no cost .",
    "the four equivalence classes of errors in the surface code may be identified by determining the parity of the number of errors that lie on a given line that links the top and bottom or left and right boundary .",
    "this method outputs only a single matching for a single equivalence class , that which yields the minimum weight matching overall . to make our enhancement",
    "we will force the decoder to output the minimum weight matching for each equivalence class , which requires us to enforce changes in the parities of error numbers along lines across the code .",
    "this can be achieved by adding one further virtual anyon on the top and bottom or the left and right boundary , respectively , and connecting it with zero - weight edges to all virtual anyons already present at this boundary @xcite .",
    "it is thus guaranteed that a any pairing of all real and virtual anyons of the same type is an element of a different equivalence class than the one obtained if these two additional virtual anyons had not been included .",
    "see fig .",
    "[ fig : equivclasses ] for an illustration .",
    "( 0.8,0.5 ) ( -0.15,0.075 ) ( 0.35,0.04 ) ( -0.09,0.5)a ) ( 0.43,0.5)b )    this prodcedure allows us to find two non - equivalent minimum - weight error chains for both kinds of anyons .",
    "combining these @xmath36 error chains gives four hypotheses about the errors that have happened .",
    "each of these matchings is the most likely within its equivalence class for the approximate error model where the correlations between @xmath37- and @xmath38-errors are ignored .",
    ", we may now determine which is most likely according to the true correlated noise model , by simply determining the probability for the total error chain in each .",
    "for the case of depolarizing noise this means determining which has the minimal number of errors , where one @xmath37- and one @xmath38-error on the same qubit count only as one @xmath39-error ( rather than two errors , as counted by standard matching ) .",
    "( 0.8,0.6 ) ( -0.12,-0.02 ) ( horizontal axis ) and error rates @xmath1 .",
    "data points below the red line indicated that enhanced mwpm performs worse than standard mwpm . each data point",
    "is sampled over as many error configurations as were necessary in order to obtain @xmath40 logical errors .",
    "the grey dashed lines are guides to the eye.,title=\"fig:\",scaledwidth=50.0% ]    ( 0.49,0.55)@xmath41 ( 0.54,0.40)@xmath42 ( 0.74,0.29)@xmath43 ( 0.74,0.22)@xmath44 ( 0.74,0.16)@xmath45 ( 0.74,0.10)@xmath46 ( 0.74,0.05)@xmath47    fig .",
    "[ fig : mwpm ] compares the logical error rates of enhanced and standard mwpm for error rates @xmath1 which are of the same order of magnitude as the threshold value .",
    "very surprisingly , there are regimes ( both @xmath0 and @xmath1 large enough ) , where `` enhanced '' mwpm performs worse than standard mwpm . while we know that for low enough @xmath1 the ratio displayed in fig .",
    "[ fig : mwpm ] increases exponentially with @xmath0 , the ratio _ decreases _ with @xmath0 for @xmath48 .",
    "we can offer no explanation for this behavior . further comparison of enhanced and standard mwpm can be found in fig .",
    "[ fig : differentalgos ] .",
    "we now consider an algorithm based on an analytically exact rewriting of the probability of each equivalence class which allows evaluation with the metropolis algorithm .",
    "let us discuss depolarizing noise here and note that our discussion generalizes straightforwardly to arbitrary error models of the form of eq .",
    "( [ eq : paulichannel ] ) .",
    "we have defined a depolarization rate @xmath1 to mean that each spin has suffered a @xmath8 , @xmath15 , or @xmath9 error with probability @xmath49 each and no error with probability @xmath50 .",
    "consequently , the probability of an error chain involving @xmath51 single - qubit errors is up to a normalization constant given by @xmath52 , where @xmath53 is defined through @xmath54 given an anyon configuration @xmath16 , the relative probability of equivalence class @xmath55 can be written as @xmath56 where the sum runs over all error chains that are compatible with the anyon configuration @xmath16 and elements of equivalence class @xmath55 , and @xmath51 denotes the number of single - qubit errors in a particular error chain . the goal is to find the equivalence class @xmath55 with maximal @xmath57 .",
    "the metropolis algorithm allows us to approximate expressions of the form @xmath58 ( we use @xmath59 to denote a generic `` inverse temperature '' and @xmath53 to denote the specific one defined through eq .",
    "( [ eq : betabar ] ) ) .",
    "the sum is here over all error configurations in equivalence class @xmath55 that are compatible with the syndrome information @xmath16 . in order to approximate an expression of the form in eq .",
    "( [ eq : avgdefi ] ) by use of the metropolis algorithm , we pick one stabilizer at random and calculate the number @xmath60 by which the total number of errors @xmath51 in the code would change if that stabilizer were applied .",
    "if @xmath61 , we apply the stabilizer and if @xmath62 we apply it with probability @xmath63 .",
    "summing up @xmath64 over all steps and dividing by the total number of steps then yields our approximation to eq .",
    "( [ eq : avgdefi ] ) .",
    "deforming error patterns only through the application of stabilizers ensures that all error patterns in one such markov chain belong to the same class , and that all of them are compatible with the same anyon configuration @xmath16 . since we will need the average @xmath65 for each equivalence class @xmath55 , we need an initial error configuration from each equivalence class which is compatible with the measured anyon syndrome @xmath16 .",
    "in fact , we will start the metropolis markov chains with the minimum weight error configuration from each equivalence class , provided by the method described above in section [ sec : enhanced ] and fig .",
    "[ fig : equivclasses ] .",
    "the reason for starting with the minimum weight error configuration rather than a random initial configuration from the same equivalence class is based on the intuition that `` heating up '' from the groundstate to inverse temperatures @xmath59 as needed for the equilibrium averages in eq .",
    "( [ eq : avgdefi ] ) takes less time than `` cooling down '' from a high energy configuration .    note that @xmath66 in eq .",
    "( [ eq : avgdefi ] ) has @xmath67 summands for each equivalence class @xmath55 , so knowing an averaged sum is as good as knowing the whole sum .",
    "we have @xmath68 corresponding to a simple monte carlo sampling of the sum . however , the sum is dominated by an exponentially small fraction of summands with `` energy '' @xmath51 close to the minimal value , so monte carlo sampling is computationally similarly expensive as a brute force calculation of the sum .",
    "our goal is thus to rewrite @xmath57 in a way that involves only quantities which are evaluable efficiently with the metropolis algorithm .",
    "applying the fundamental theorem of calculus we have @xmath69 if we know the functions @xmath70 , the most likely equivalence class is , according to eq .",
    "( [ eq : main ] ) , the one in which the area under the curve is smallest . in the correctable regime ( @xmath71 )",
    "the differences in `` free energy '' @xmath72 between the different equivalence classes grow proportionally in @xmath0 and correspondingly the probability of all equivalence classes but the most likely one decreases exponentially with @xmath0 .    for a positive @xmath59",
    ", the average number of errors @xmath70 can be efficiently calculated to arbitrary accuracy by means of the metropolis algorithm .",
    "the integral @xmath73 can be calculated to arbitrary accuracy by first calculating the values @xmath70 for a sufficient number of inverse temperatures @xmath59 and then applying a quadrature formula like simpson s rule .",
    "( 0.72,0.5 ) ( -0.12,-0.15 ) eigenvalue has been measured , i.e. , anyons .",
    "red stabilizers are tensor products of @xmath8 and blue stabilizers are tensor products of @xmath9",
    ". if the correlations between bit- and phase - flips present in depolarizing noise are ignored , both a ) and b ) are error patterns of minimal weight compatible with the anyon configuration .",
    "mwpm will thus result in either one of them with the same likelyhood .",
    "while enhanced mwpm will correctly assign a weight of @xmath13 to a ) and a weight of @xmath74 to b ) , it considers only that of the two configurations which comes out of the matching algorithm .",
    "by contrast , if we start the single - temperature algorithm with configuration a ) , it will eventually apply the lower of the two red stabilizer operators and thereby convert it to the true minimum - weight configuration b).,title=\"fig:\",scaledwidth=50.0% ] ( -0.09,0.28)a ) ( 0.43,0.28)b )    recall that we are not interested in the precise value of the integrals @xmath75 , but only in knowing for which equivalence class @xmath55 this integral is smallest .",
    "for this reason , calculating the whole integral is quite often an overkill .",
    "in fact , most of the relevant information contained in the function @xmath70 can be extracted by finding its value for a _ single _ inverse temperature @xmath76 .",
    "assume that we determine the values @xmath77 for some @xmath78 for all equivalence classes @xmath55 .",
    "if the functions @xmath70 for the different equivalence classes do not cross , knowing the values @xmath77 is as good as knowing the whole integrals @xmath75 for deciding for which equivalence class @xmath55 the integral is smallest .",
    "as @xmath79 , each qubit is affected by an @xmath37- , @xmath39- , or @xmath38-error or no error at all with probability @xmath80 , so @xmath81 , where @xmath82 is the number of data qubits in the code .",
    "the low-@xmath59 tail of the function @xmath70 thus contains almost no information about the equivalence class @xmath55 .",
    "so while the integral @xmath75 is dominated by its low-@xmath59 part ( @xmath70 is a monotonically decreasing function of @xmath59 ) , the _ differences _ between these integrals for the different equivalence classes are mainly due to their high-@xmath59 part .",
    "so even if there are crossings in the low-@xmath59 tails of the functions @xmath70 , basing the decision for the most likely equivalence class on a single value @xmath77 is likely to yield the same outcome as basing the decision on the whole integral @xmath75 .",
    "we thus define our _ single - temperature algorithm _ as sampling the values @xmath77 for all equivalence classes and performing error correction in accordance with the equivalence class @xmath55 for which this value is smallest .",
    "this algorithm has only two free parameters , namely @xmath83 and @xmath84 , the number of steps for which we perform the metropolis algorithm in order to sample @xmath77 . for @xmath85 ( zero temperature )",
    ", the single - temperature algorithm will never increase the weight of an error configuration .",
    "still , it provides an improvement over enhanced mwpm since applying stabilizers allows to find error configurations which , taking correlations between bit- and phase - flips into account , are of lower weight than the ones found by mwpm .",
    "this does not require that the weight of the error configuration be ever increased , see fig .",
    "[ fig : minimalexample ] for an illustration . at finite temperature ,",
    "a second improvement over ( enhanced ) mwpm comes into play .",
    "namely , temperature allows to take entropic contributions to the free energy into account , i.e. , consider error configurations which are not of minimal weight but give a non - negligible contribution to the free energy due to their large number .",
    "however , for @xmath86 ( infinite temperature ) the single - temperature algorithm becomes useless ( @xmath87 for all equivalence classes ) , such that some finite value of @xmath76 is optimal .",
    "indeed , we find empirically that for depolarizing noise the optimal values for @xmath83 are close to @xmath53 .",
    "we thus set @xmath88 throughout for this error model .",
    "as for @xmath84 , we may ask how many metropolis steps are necessary for our single - temperature algorithm to achieve logical error rates below those achievable with mwpm . in order to set the bar high",
    ", we compare our algorithm with the better of either standard or enhanced mwpm , i.e. , that with the lower error rate .",
    "[ fig : depolachievemwpm ] shows the ratio of the logical error rate achieved by the single - temperature algorithm divided by the smaller of the two logical error rates achievable by the two variants of mwpm .",
    "if @xmath0 is higher than a certain @xmath1-dependent threshold , the logical error rate will be increased if @xmath84 is too small , and only improve when it is made larger .",
    "for some fixed @xmath0 , this regime of increased logical error rate vanishes if @xmath1 is small enough , see the blue curve in fig .",
    "[ fig : depolachievemwpm ] .",
    "then , already a handful of metropolis steps is sufficient in order to outperform both variants of mwpm .",
    "as for the limit of a vanishing error rate @xmath1 , recall that in this limit enhanced mwpm performs optimally and the single - temperature algorithm becomes redundant .",
    "let us discuss the scaling of the necessary values of @xmath84 as a function of @xmath0 if we are in the regime where the single - temperature algorithm _ can _ perform worse than ( at least one variant of ) mwpm when @xmath84 is too low .",
    "the approximation made by mwpm is , effectively , to approximate the free energy for each equivalence class by the number of errors in its minimum weight error chain .",
    "the simplest improvement to this that can be achieved by the single temperature algorithm is to calculate @xmath89 by sampling within the vicinity of the minimum weight chains .",
    "this will give a better approximation of the free energy by taking into account some of the effects of entropy .",
    "since such sampling requires only @xmath7 deformations per string in the minimum weight error chain , this approximation is equivalent to assuming that the autocorrelation time for the calculation of @xmath89 ( when starting from the minimum weight chain ) is @xmath7 for each string . the runtime complexity required to generate independent metropolis samples for the entire code is then @xmath2 , which is thus the time - scale needed to estimate @xmath70 up to some given _ relative _ error .",
    "the quantities @xmath70 themselves grow like @xmath2 , and so does a constant relative error .",
    "however , the distinguishability , i.e. , the difference in the quantity @xmath70 between the correct and the remaining equivalence classes , only grows like @xmath90 below threshold ( see below ) , such that the relative difference between the equivalence classes _ decreases _ like @xmath91 .",
    "a constant relative error is thus not sufficient  we need a relative error of order @xmath91 .",
    "as the relative error decreases with the inverse square root of the sample size , this leads to a further factor @xmath2 in the runtime complexity .",
    "the inset in fig .",
    "[ fig : depolachievemwpm ] numerically verifies the @xmath5 scaling anticipated from the above analysis .",
    "( 0.8,0.64 ) ( -0.12,-0.02 ) .",
    "the data were obtained for a depolarization rate of @xmath45 and for code sizes @xmath92 and @xmath93 , respectively .",
    "the inset shows the value of @xmath94 which is necessary to achieve a unit ratio against @xmath0 for the case of depolarizing noise with @xmath45 and @xmath47 .",
    "the fitting lines correspond to the functions @xmath95 and @xmath96 .",
    "each data point in the two figures is averaged over as many error configurations as were required for @xmath97 logical errors to occur .",
    ", title=\"fig:\",scaledwidth=50.0% ] ( 0.31,0.25 ) .",
    "the data were obtained for a depolarization rate of @xmath45 and for code sizes @xmath92 and @xmath93 , respectively .",
    "the inset shows the value of @xmath94 which is necessary to achieve a unit ratio against @xmath0 for the case of depolarizing noise with @xmath45 and @xmath47 .",
    "the fitting lines correspond to the functions @xmath95 and @xmath96 .",
    "each data point in the two figures is averaged over as many error configurations as were required for @xmath97 logical errors to occur .",
    ", title=\"fig:\",scaledwidth=28.0% ]    ( 0.07,0.16)@xmath92 ( 0.14,0.26)@xmath93    ( 0.47,0.43)@xmath47 ( 0.60,0.39)@xmath45    the quantity which determines whether error correction will be successful is the difference @xmath98 , where @xmath99 denotes the minimal averaged number of errors of all three false equivalence classes .",
    "this difference is displayed for various values of @xmath1 and @xmath0 in fig .",
    "[ fig : depolfdiffs ] . for @xmath100",
    "this difference increases linearly with @xmath0 , while for @xmath101 it becomes even negative for large enough @xmath0 .",
    "this is to be expected : for an error rate sufficiently close to the @xmath102 threshold , each of the averages @xmath77 for the four equivalence classes @xmath55 has the same probability for being the smallest one , such that the probability that one of the three false equivalence classes becomes minimal approaches @xmath103 .",
    "the inset in fig .",
    "[ fig : depolfdiffs ] shows the logical error rates achievable with our single - temperature algorithm if we set @xmath104 .",
    "there is a threshold for @xmath1 between @xmath105 and @xmath106 below which the logical error rate decreases exponentially with @xmath0 .",
    "this means that the threshold error rate for our algorithm is significantly below the theoretical maximum of @xmath102 @xcite and the value of @xmath107 achieved in ref .",
    "@xcite but closer to the threshold of mwpm @xcite .",
    "this is unsurprising since we use mwpm as a starting point for our markov chains and use only the runtime complexity for @xmath84 which is necessary to match mwpm .",
    "however , the relevant figures of merit in practice are the logical error rates achievable well below threshold ( where our algorithm offers significant improvement over mwpm , see below ) and the runtime complexity ( where our algorithm offers significant improvement over the algorithm of ref .",
    "@xcite ) .",
    "( 0.8,0.7 ) ( -0.05,0.00 ) ( vertical axis ; we use @xmath88 and @xmath104 ) for various depolarization rates @xmath1 and code sizes @xmath0 ( horizontal axis ) .",
    "different lines correspond to different depolarization rates @xmath1 . from top to bottom we have @xmath108 . each data point",
    "is averaged over as many error configurations as are necessary to obtain @xmath97 logical errors .",
    "the inset shows the logical error rates of our single - temperature algorithm for the same system sizes and depolarization rates , with depolarization rates increasing from bottom to top .",
    ", title=\"fig:\",scaledwidth=45.0% ] ( 0.10,0.40 ) ( vertical axis ; we use @xmath88 and @xmath104 ) for various depolarization rates @xmath1 and code sizes @xmath0 ( horizontal axis ) .",
    "different lines correspond to different depolarization rates @xmath1 . from top to bottom we have @xmath108 . each data point",
    "is averaged over as many error configurations as are necessary to obtain @xmath97 logical errors .",
    "the inset shows the logical error rates of our single - temperature algorithm for the same system sizes and depolarization rates , with depolarization rates increasing from bottom to top . , title=\"fig:\",scaledwidth=16.0% ] ( -0.13,0.13 )    @xmath98    ( 0.06,0.03)@xmath109 ( 0.165,0.03)@xmath110 ( 0.275,0.03)@xmath111 ( 0.38,0.03)@xmath112 ( 0.49,0.03)@xmath113 ( 0.60,0.03)@xmath114 ( 0.705,0.03)@xmath115 ( 0.81,0.03)@xmath116    ( -0.055,0.155)@xmath117 ( -0.07,0.255)@xmath109 ( -0.07,0.36)@xmath118 ( -0.07,0.46)@xmath110    ( 0.131,0.385)@xmath109 ( 0.170,0.385)@xmath110 ( 0.209,0.385)@xmath111 ( 0.248,0.385)@xmath112 ( 0.286,0.385)@xmath113 ( 0.325,0.385)@xmath114 ( 0.364,0.385)@xmath115 ( 0.402,0.385)@xmath116    ( 0.042,0.422)@xmath119 ( 0.042,0.450)@xmath120 ( 0.042,0.506)@xmath121 ( 0.042,0.530)@xmath122 ( 0.042,0.590)@xmath123    fig .",
    "[ fig : differentalgos ] compares the logical error rates achievable with different algorithms for @xmath124 and different depolarization rates @xmath1 .",
    "we set the logical error rates achievable with standard mwpm to unity and divide them by the logical error rates achievable with alternate algorithms .",
    "the algorithms which are displayed are :    * standard , unimproved mpwm , as employed in ref .",
    "an @xmath37- and a @xmath38-error on the same qubit count as two errors . * enhanced mwpm . an @xmath37- and a @xmath38-error on the same qubit count as two errors during the matching ,",
    "but as one error during a final comparison of all equivalence classes . corresponds to the single - temperature algorithm with @xmath125 .",
    "* single - temperature algorithm with @xmath104 metropolis steps and @xmath88 . * the parallel - tempering algorithm developed in ref .",
    "@xcite .",
    "the logical error rates decrease from a to d , while the runtime complexities increase .",
    "we see that the advantages achievable over algorithm a vanish as @xmath126 but increase the lower @xmath1 gets .",
    "we believe our single - temperature algorithm c to offer the most attractive trade - off ratio between low logical error rates and low classical runtime complexity , as it increases the latter only modestly compared with algorithms a and b , while algorithm d has a super - polynomial ( in @xmath0 ) runtime complexity .",
    "we have verified numerically that estimating the entire integral @xmath75 by sampling the values @xmath70 for @xmath127 equidistant temperatures @xmath59 over @xmath128 metropolis steps and then applying simpson s quadrature formula leads only to modest improvements over algorithm c. it would be more beneficial to invest the additional computational cost into increasing @xmath84 in algorithm c.    ( 0.8,0.6 ) ( -0.05,0.00 ) ( horizontal axis ) and a code of linear size @xmath124 .",
    "each data point is averaged over as many error configurations as are necessary to obtain @xmath97 logical errors .",
    "a value greater than @xmath129 denotes an increase in effectiveness over mwpm , with greater increases for higher values.,title=\"fig:\",scaledwidth=45.0% ]    ( -0.005,-0.025)@xmath130 ( 0.115,-0.025)@xmath131 ( 0.24,-0.025)@xmath132 ( 0.36,-0.025)@xmath133 ( 0.485,-0.025)@xmath134 ( 0.61,-0.025)@xmath135 ( 0.735,-0.025)@xmath136    ( -0.055,0.124)@xmath74 ( -0.055,0.245)@xmath14 ( -0.055,0.36)@xmath137 ( -0.055,0.51)@xmath138    ( 0.03,0.09)@xmath16 ( 0.04,0.16)@xmath139 ( 0.13,0.51)@xmath140 ( 0.54,0.41)@xmath141    fig .",
    "[ fig : st ] shows the logical error rates of algorithm a divided by those of algorithm c for various values of @xmath1 and @xmath0 .",
    "we see the advantage of algorithm c increasing for lower @xmath1 and larger @xmath0 .",
    "note that we expect real quantum computers to be operated at error rates @xmath1 below and code distances @xmath0 above those displayed in fig .",
    "[ fig : st ] .",
    "( 0.8,0.6 ) ( -0.05,0.00 ) ( horizontal axis ) and code sizes @xmath0 . each data point",
    "is averaged over as many error configurations as are necessary to obtain @xmath97 logical errors.,title=\"fig:\",scaledwidth=45.0% ]    ( 0.17,-0.025)@xmath142 ( 0.415,-0.025)@xmath133 ( 0.665,-0.025)@xmath143    ( -0.065,0.11)@xmath74 ( -0.065,0.22)@xmath14 ( -0.065,0.33)@xmath137 ( -0.065,0.44)@xmath138 ( -0.081,0.55)@xmath109    ( -0.01,0.21)@xmath144 ( 0.05,0.47)@xmath92 ( 0.17,0.50)@xmath124 ( 0.32,0.545)@xmath93    to get an idea about what effect this reduction of the logical error rates has on the necessary code size , let us have a look at the code size which is needed for a proof of principle experiment .",
    "i.e. , given some physical error rate @xmath1 , which code size @xmath0 is needed to bring the logical error rate below the physical one ? for @xmath145 , we need @xmath146 in order to achieve a logical error rate below @xmath1 with algorithm c and need @xmath147 with algorithm a. so by modestly enhancing the classical runtime complexity , we are able to reduce the number of physical data qubits required for such a proof of principle experiment from @xmath148 to @xmath149 .    the behavior of the curves in figs .",
    "[ fig : differentalgos ] and [ fig : st ] in the limit @xmath150 demonstrates that the algorithms presented here do indeed achieve the predicted increased effectiveness over standard mwpm in the low @xmath1 limit .",
    "the ratio of the logical error rate of algorithm @xmath16 to the logical error rate of algorithms @xmath139 to @xmath141 can therefore be expected to be exponentially large in @xmath0 for @xmath150 . in this limit ,",
    "the mcmc procedure becomes unnecessary and we can rely on algorithm @xmath139 .",
    "the advantage of algorithm c over algorithms a and b is due to at least two different reasons .",
    "first , mwpm is naturally suited to the error model of independent bit- and phase - flips , where each type of anyon can be treated independent of the other .",
    "it is much less suited to error models such as depolarizing noise which feature correlations between bit- and phase - flip errors .",
    "algorithm b can only partially overcome these limitations .",
    "second , while algorithms a and b are based on finding the most likely error chain and hoping that it is an element of the most likely equivalence class , algorithms c to f are based on finding the most likely equivalence class .",
    "an interesting question is thus how our single - temperature algorithm compares with mwpm for independent bit- and phase - flip errors , the error model mwpm is best suited to and where only the second advantage applies .",
    "empirically , we find that for this error model choosing @xmath151 works best and that for a bit-/phase - flip probability of @xmath152 ( close to the theoretical threshold ) @xmath5 metropolis steps are again sufficient to achieve a logical error rate below the one of mwpm @xcite , with @xmath153 giving the best fit to the required number .",
    "for @xmath154 , a bit-/phase - flip probability of @xmath155 , and by sampling over @xmath156 metropolis steps we achieve a logical error rate which is a factor @xmath157 lower than the one of mwpm .",
    "so significant improvements over mwpm can be achieved even for the error model best suited to it , though the advantage is much more drastic for an error model with correlations between bit- and phase - flip errors , with which our single - temperature algorithm can deal very naturally .",
    "the runtime of our algorithm can be reduced by a factor @xmath2 using parallelization which exploits the fact that our algorithm needs local changes only .",
    "we partition the whole code into @xmath2 rectangles of area @xmath4 .",
    "adjacent rectangles overlap along lines of data qubits , while qubits in the corners belong to four rectangles , see fig .",
    "[ fig : parallel ] .",
    "the rectangles are collected into four groups @xmath158 such that the rectangles within one group have no overlapping qubits . at step @xmath159 of the metropolis markov chain ,",
    "we choose one stabilizer in each rectangle belonging to group @xmath160 at random and probe whether to apply it or not according to the metropolis procedure .",
    "this way we can guarantee that no data qubit is affected by more than one applied stabilizer at each step . if a randomly chosen stabilizer is applied and flips a qubit which is shared with an other rectangle ( other rectangles ) , this flip is communicated to the adjacent rectangle(-s ) . for each rectangle",
    ", we add up the number of local errors @xmath51 over the different metropolis steps and calculate the total average @xmath77 in the end . to compensate for double-(quadruple-)counting , errors on qubits along the boundary",
    "thereby have to be discounted by a factor @xmath161 and errors on qubits in the corners by a factor @xmath80 .",
    "as we probe now @xmath2 stabilizers in each time step , the runtime reduces from @xmath5 to @xmath2 .",
    "( 0.8,0.8 ) ( -0.15,0.00 ) .",
    "data qubits along the boundaries belong to two rectangles and data qubits in the corners to four.,title=\"fig:\",scaledwidth=55.0% ]",
    "let us assume that each stabilizer measurement yields the wrong result with probability @xmath162 .",
    "if stabilizers are measured by use of cnot gates , this model is a simplification in that it ignores correlations between spatio - temporally nearby syndrome measurement failures induced by these gates @xcite . in order to make the failure probability small despite non - negligible @xmath162 , we now necessarily need to perform stabilizer measurements at several times @xmath163 .",
    "a hypothesis about what errors have happened then not only has to state which data qubit has suffered an error in which time interval @xmath164 $ ] , but also which stabilizer measurement has been erroneous at which time @xmath165 .",
    "such hypotheses can be deformed into equivalent ones by applying a bit-/phase - flip @xmath8/@xmath9 to a particular qubit at time intervals @xmath166 $ ] and @xmath164 $ ] and inverting the hypothesis about whether the stabilizer measurements at time @xmath165 that anti - commute with this error have been erroneous ( see the illustration in fig .  [",
    "fig : noisystabilizer ] ) .",
    "( 0.8,0.8 ) ( -0.15,0.00 ) .",
    "the two encircled syndrome qubits have detected errors ( @xmath11 eigenvalues ) .",
    "a possible hypothesis is that no data qubit has suffered an error and both syndrome measurements have been erroneous .",
    "an alternate hypotheses would state that the data qubits indicated by red lightning bolts have suffered errors and that syndrome measurement by use of the syndrome qubits indicated by red lightning bolts has been erroneous .",
    "different equivalent hypotheses can be deformed into each other through the application of operators like the red square that invert whether a hypothetical error has happened or not at two adjacent syndrome qubits and one data qubit at two subsequent times .",
    ", title=\"fig:\",scaledwidth=55.0% ]    in the case of depolarizing noise , a hypothesis that involves @xmath51 data - qubit errors and @xmath167 erroneous syndrome measurements has a relative probability @xmath168\\ , \\end{aligned}\\ ] ] where @xmath53 is as defined in eq .",
    "( [ eq : betabar ] ) and @xmath169 the `` energy '' of a hypothesis is thus given by @xmath170 where @xmath171 determines the relative weight of erroneous syndrome measurements to data qubit errors .",
    "our method to find the most probable equivalence class in the case of perfect stabilizer measurements can thus be generalized to the case where syndrome measurements fail with a considerable probability .",
    "numerical results for the latter case will appear in future work .",
    "we have developped two novel error correction algorithms  enhanced mwpm and the single - temperature mcmc algorithm  and compared them with each other and with standard mwpm over several regimes of the error rate @xmath1 : close to threshold , intermediate values , and vanishing values . for the first two regimes , numerical simulations have provided us with insight into their respective performance , while in the third regime , analytical arguments are both unavoidable and possible",
    ".    the relevant regime in practice will be the second one . in this regime ,",
    "no increase in the runtime complexity is necessary for the single - temperature algorithm to achieve lower logical error rates than the other two algorithms , so any cpu - time not needed to perform mwpm can be used to lower the logical error rate by the method described in this work .",
    "we have numerically investigated the decreases in the logical error rates which are achievable if we are willing to increase the classical runtime complexity by @xmath2 .",
    "nothe that advantages much higher than those displayed figs .",
    "[ fig : differentalgos ] and fig .",
    "[ fig : st ] can likely be achieved , as we have probed only relatively small values of @xmath0 and high values of @xmath1 , quantum computers will be operated at error rates significantly below threshold , and the advantages increase for higher values of @xmath0 and lower values of @xmath1 .",
    "besides lowering the logical error rate for a given code size , our algorithm also reduces the code size necessary for a proof of principle experiment and thus reduces the experimental requirements for such an experiment .    like the renormalization group method @xcite but unlike mwpm our algorithm readily generalizes to the @xmath172 toric codes with @xmath173 @xcite .",
    "our algorithm relies on the availability of a low energy state of each equivalence class as a starting point for the markov chains . in the case of @xmath174 ( studied in this work ) , such a low energy state can be efficiently obtained by use of mwpm , while for @xmath173 the broom algorithm of ref .",
    "@xcite may be applied . how starting the markov chains with a random ( and thus likely high energy )",
    "input state from each equivalence state would affect the necessary runtime remains unclear and will be the subject of future work .",
    "this work is supported by the swiss nsf , nccr qsit , and iarpa .",
    "we thank austin fowler for encouraging us to discuss the @xmath150 limit and david poulin for comments concerning the applicability of our algorithm .                                    as the error correction algorithm of ref .",
    "@xcite itself allows for trade - offs between runtime and error rates , and mwpm based algorithms have attained most interest in the literature , we do not directly compare our algorithm to the former .",
    "if there are no virtual anyons on a certain boundary , we connect the additional virtual anyon to all _ real _ anyons of the same type , with edges weighted by their distance to the corresponding boundary . if there are no real anyons , we connect the two new virtual anyons placed on opposite boundary .",
    "this way , the minimum weight error configuration of each equivalence class can be found for any possible anyon configuration ."
  ],
  "abstract_text": [
    "<S> minimum - weight perfect matching ( mwpm ) has been been the primary classical algorithm for error correction in the surface code , since it is of low runtime complexity and achieves relatively low logical error rates [ phys .  </S>",
    "<S> rev .  </S>",
    "<S> lett .  * 108 * , 180501 ( 2012 ) ] . </S>",
    "<S> a markov chain monte carlo ( mcmc ) algorithm [ phys .  </S>",
    "<S> rev .  </S>",
    "<S> lett .  * 109 * , 160503 ( 2012 ) ] is able to achieve lower logical error rates and higher thresholds than mwpm , but requires a classical runtime complexity which is super - polynomial in @xmath0 , the linear size of the code . in this work we present an mcmc algorithm that achieves significantly lower logical error rates than mwpm at the cost of a polynomially increased classical runtime complexity . for error rates </S>",
    "<S> @xmath1 close to the threshold , our algorithm needs a runtime complexity which is increased by @xmath2 relative to mwpm in order to achieve a lower logical error rate . if @xmath1 is below an @xmath0-dependent critical value , no increase in the runtime complexity is necessary any longer . for @xmath3 , </S>",
    "<S> the logical error rate achieved by our algorithm is exponentially smaller ( in @xmath0 ) than that of mwpm , without requiring an increased runtime complexity . </S>",
    "<S> our algorithm allows for trade - offs between runtime and achieved logical error rates as well as for parallelization , and can be also used to correct in the case of imperfect stabilizer measurements . </S>"
  ]
}