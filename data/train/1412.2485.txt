{
  "article_text": [
    "learning and classification with a large amount of data raises the need for algorithms that scale well in time and space usage with the number of data points being trained on .",
    "_ streaming _ algorithms have properties that do just that : they run in a single pass over the data and use space polylogarithmic in the total number of points .",
    "the technique of making a single pass over the data has three key advantages : 1 ) points may be seen once and then discarded so they do not take up additional storage space ; 2 ) the running time scales linearly in the size of the input , a practical necessity for data sets with sizes in the millions , and 3 ) it enables these algorithms to function in a streaming model , where instead of data is not immediately available , individual data points may arrive slowly over time .",
    "this third feature enables data to be learned and models to be updated `` online '' in real time , instead of periodically running a batch update over all existing data .",
    "support vector machines ( svms ) are one such learning model that would benefit from an efficient and accurate streaming representation .",
    "standard 2-class svms models attempt to find the maximum - margin linear separator ( i.e. hyperplane ) between positive and negative instances and as such , they have a very small hypothesis complexity but provable generalization bounds @xcite .",
    "there have been several implementations of a streaming svm classifier ( @xcite , @xcite , @xcite ) , but so the most effective version has been based off the reduction from svm to the minimum enclosing ball ( meb ) problem introduced by  @xcite .",
    "the connection between these two problems has made it possible to harness the work done on streaming mebs and apply them to svms , as was done in  @xcite . in this paper , we utilize the blurred ball cover approximation to the meb problem proposed in  @xcite to obtain a streaming svm that is both fast and space efficient . we also show that our implementation not only outperforms existing streaming svm implementations ( including those not based off of meb reductions ) but also that our error rates are competitive with libsvm , a state - of - the - art batch svm open - source project available [ here ] .",
    "the core vector machine ( cvm ) was introduced by  @xcite as an new take on the standard support vector machine ( svm ) . instead of attempting to solve a quadratic system",
    ", the cvm makes use of the observation that many common kernels for the standard svm can be viewed as minimum enclosing ball ( meb ) problems .",
    "consider the following svm optimization problem on @xmath0 inputs @xmath1 : @xmath2 where @xmath3 and @xmath4 are the data points and labels , respectively , and @xmath5 is a feature map induced by the kernel of choice . here",
    ", the @xmath6 are error cushions that specify the cost of misclassifying @xmath3 .",
    "let @xmath7 be the optimal separating hyperplane .",
    "@xcite showed that if the kernel @xmath8 satisfies @xmath9 , a constant , then @xmath7 can be found by finding the minimum enclosing ball of the points @xmath10 , where @xmath11\\ ] ] where @xmath12 is the @xmath13th standard basis element ( all zeroes except for the @xmath13th position , which is 1 ) . if @xmath14 is the optimal meb center , then @xmath15 .",
    "a couple of things to note about this equivalence : first , it transforms the supervised svm training problem into an unsupervised one - the meb is blind to the true label of the point .",
    "second , the notion of a _ margin _ in the original svm problem is transformed into a _ core set _ , a subset of inputs such that finding the meb of the corset is a good approximation to finding the meb over the entire input . as such , core sets",
    "can be thought of as the minimal amount of information that defines the meb .",
    "the implementation of the cvm in  @xcite follows the meb approximation algorithm described in  @xcite : given @xmath16 , add to the core set @xmath17 the point @xmath18 that is the farthest from the current meb center @xmath19 .",
    "recompute the meb from the core set and continue until all points are within @xmath20 from @xmath19 , where @xmath21 is the radius of the meb .",
    "the core vector machine achieves a @xmath22 approximation factor but makes @xmath23 passes over the data and requires storage space linear in the size of the input , an approach that does nt scale for streaming applications . to this end , @xcite presented the streamsvm , a streaming version of the cvm , which computes the meb over the input @xmath24 in a streaming fashion , keeping a running approximate meb of all the data seen so far and adjusting it upon receiving a new input point .",
    "the streamsvm used only constant space and using a small lookahead resulted in a favorable performance compared to libsvm ( batch ) as well as the streaming perceptron , pegasos , and lasvm implementations .",
    "however , the streaming meb algorithm that powers streamsvm is only approximate and offers a worst - case approximation ratio of between @xmath25 and @xmath26 of the true meb , leaving open the possibility of a better streaming algorithm to improve the performance of streamsvm .    in this paper",
    ", we present the blurred ball svm , a streaming algorithm based on the blurred ball cover proposed in  @xcite .",
    "it takes a parameter @xmath16 and keeps track of multiple core sets ( and their corresponding mebs ) , performing updates only when an incoming data point lies outside the union of the @xmath27 expansion of all the maintained mebs .",
    "the blurred ball svm also makes a single pass over the input , with space complexity independent of @xmath28 .",
    "the algorithm consists of two parts : a _ training _ procedure to update the blurred ball cover and a _ classification _ method , which harnesses the blurred ball to label the point with one of the two possible classes . for simplicity ,",
    "we choose the classes to be @xmath29 .",
    "as described above , a ball with radius @xmath30 and center @xmath19 is a linear classifier consisting of a hyperplane passing through the origin with normal @xmath19 . for the rest of this paper",
    ", we will require the following assumptions , established by tsang et al :    * the data points @xmath31 , denoted by @xmath32 , are linearly separable ( this is always the case if @xmath33 ) .",
    "* @xmath34 , a constant .    with these assumptions ,",
    "the training procedure is described in algorithm  [ updatealgo ] and is identical to the blurred ball cover update described in algorithm 1 of  @xcite .",
    "@xmath35}$ ] compute @xmath36 ( normalized to norm @xmath37 ) as defined above add @xmath38 to the lookahead buffer _ buf _ @xmath39 discard any core set with meb radius smaller than @xmath40 @xmath41 _ buf _ @xmath42    for the purposes of analysis , we show the following properties of the linear classifier that results from the blurred balls :    [ mebequivsvm ] a ball @xmath43 with center @xmath19 and radius @xmath30 corresponds to a linear classifier with hyperplane @xmath44 having the following properties :    1 .",
    "@xmath45 and @xmath46 .",
    "2 .   its margin has size @xmath47 .",
    "3 .   a point @xmath48 lies inside @xmath43 iff @xmath49 , with equality for support vectors , which lie on @xmath50 .",
    "first , note that @xmath45 .",
    "suppose instead that @xmath51 .",
    "then we use the following property of a meb : any half - space @xmath52 such that @xmath53 contains at least one data point used to construct the meb .",
    "suppose that @xmath54 , i.e. @xmath51 .",
    "then this property shows that there is no hyperplane passing through the origin that contains all points entirely on one side .",
    "now , assume that the data points are separable and let @xmath55 be the normal of the hyperplane that separates the raw data points @xmath3 such that @xmath56 for positively labeled points and @xmath57 for negatively classified points .",
    "then , @xmath58 for all @xmath13 , a contradiction to the above property if @xmath51 .",
    "we can thus assume that @xmath45 and @xmath46 for a linearly separable dataset .",
    "the reduction described in section  [ background ] shows that the linear separator defined by a meb with center @xmath59 and radius @xmath30 is a hyperplane with normal parallel to @xmath59 .",
    "let @xmath60 be the point farthest from the origin such that @xmath61 for all data points @xmath62 .",
    "in other words , the maximum margin is @xmath60 and @xmath63 from the reduction .",
    "we can further conclude that @xmath64 as follows : let @xmath65 denote the support vectors , those that lie on the margin and are a distance @xmath66 from the maximum - margin hyperplane .",
    "the ball @xmath67 for @xmath68 includes all data points ( it intersects @xmath69 along the margin ) .",
    "if @xmath70 , then @xmath71 and @xmath19 is thus not the center of the meb ( since @xmath72 is strictly better ) .",
    "so @xmath64 and the meb has radius @xmath73 for @xmath74 .",
    "therefore , the margin is @xmath75 .",
    "since @xmath76 intersects @xmath69 only along the hyperplane that defines the margin , @xmath77 , and @xmath78 .",
    "since we have multiple linear separators , we have the ability to combine them in a non - linear fashion to classify a new point .",
    "define the _ support _ of a point @xmath48 to be @xmath79 , the cores in the blurred ball cover that contain @xmath48 .",
    "define the _ score _ of a point @xmath48 to be : @xmath80 the sum of the distances of @xmath48 to the separator of all the classifiers containing @xmath48 .",
    "note that @xmath81 , since each ball has @xmath46 .",
    "@xmath82 $ ]",
    "we ran the blurred ball svm on several canonical datasets and compared the accuracy of each run with the batch libsvm implementation , the stream svm proposed by subramanian , and the streaming setting of the perceptron ( which runs through the data only once but is otherwise identical to the perceptron training algorithm ) .",
    "table  [ results ] shows the experimental results .",
    "all trials were averaged over 20 runs with respect to random orderings of the input data stream .",
    "the perceptron , lasvm and stream svm data were taken from the experiments documented in  @xcite .",
    "the blurred ball svm on the mnist dataset was run with @xmath83 and @xmath84 , and on the ijcnn dataset was run with @xmath85 and @xmath86 .",
    "the choice of @xmath87 and @xmath17 was determined coarsely through experimentation .",
    "we offer two versions of the blurred ball svm - using lookahead buffer sizes of @xmath88 and @xmath89 .",
    "figures  [ lookaheadgraph ] and  [ lookaheadgraph - time ] compare performance of different lookaheads as @xmath87 is varied .",
    "all experiments were run on a macintosh laptop with a 1.7 ghz processor with 4 gb 1600 mhz standard flash memory .",
    "it s clear that the blurred ball svm outperforms other streaming svms , but even more surprising is that it also manages to outperform the batch implementation on the mnist dataset .",
    "we suspect that this is due to the fact that our classifier allows for non - convex separators .",
    ".results on standard datasets comparing the performance of the blurred ball svm with other streaming svms and the batch libsvm baseline .",
    "@xmath90 is the size of the lookahead used in the streaming algorithms .",
    "measurements were averaged over 20 runs ( w.r.t random orderings of the input stream ) .",
    "the bold number for each dataset is the streaming svm that gave the highest accuracy for that dataset . [",
    "cols=\"^,^,^,^,^\",options=\"header \" , ]     [ results ]    , with lookaheads @xmath88 and @xmath89 .",
    "despite diverging for large @xmath87 , the accuracies with both lookaheads were much more similar for small @xmath87 . ]    , with lookaheads @xmath88 and @xmath89 . ]",
    "being able to learn an svm model in an online setting opens up myriad possibilities in the analysis of large amounts of data .",
    "there are several open questions whose answers may shed light on a streaming approach with higher accuracy than the blurred ball svm presented here :    1 .",
    "is there a streaming algorithm for maintaining an meb with better guarantees than the blurred ball cover proposed by  @xcite ?",
    "the paper originally provided a bound of @xmath91 , which was improved by  @xcite to less than @xmath92 .",
    "although @xcite showed that it is impossible to achieve an arbitrarily small approximation factor , with @xmath93 for any @xmath94 , it s possible that a better streaming meb algorithm exists with provable bounds better than the 1.22 factor demonstrated by  @xcite .",
    "the structure of the points in this svm setup is unique : all data points lie on a sphere of radius @xmath37 centered at the origin .",
    "although there is no streaming meb algorithm for unrestricted points , does this specific structure lend itself to a @xmath22 meb approximation ?",
    "if so , we would be able to construct an svm with separator arbitrarily close to the optimal .",
    "we have presented a streaming , or `` online '' algorithm for svm learning by making use of a reduction from the minimum enclosing ball problem .",
    "our training algorithm is tunable using the @xmath87 parameter to adjust the desired approximation ratio .",
    "we also came up with multiple types of classifiers , some of them non - convex , and showed that our implementation surpassed the accuracy of other streaming implementations . one surprising finding is that our implementation surpasses the standard libsvm dataset on canonical mnist binary digit classification datasets",
    ". tests on other digit recognition datasets show similar results , suggesting that this better performance could be due to structural idiosyncrasies of the data ."
  ],
  "abstract_text": [
    "<S> a widely - used tool for binary classification is the support vector machine ( svm ) , a supervised learning technique that finds the `` maximum margin '' linear separator between the two classes . </S>",
    "<S> while svms have been well studied in the batch ( offline ) setting , there is considerably less work on the streaming ( online ) setting , which requires only a single pass over the data using sub - linear space . </S>",
    "<S> existing streaming algorithms are not yet competitive with the batch implementation . in this paper </S>",
    "<S> , we use the formulation of the svm as a minimum enclosing ball ( meb ) problem to provide a streaming svm algorithm based off of the blurred ball cover originally proposed by agarwal and sharathkumar . </S>",
    "<S> our implementation consistently outperforms existing streaming svm approaches and provides higher accuracies than libsvm on several datasets , thus making it competitive with the standard svm batch implementation . </S>"
  ]
}