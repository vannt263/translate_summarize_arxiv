{
  "article_text": [
    "the viability of the bayesian approach to inverse problems was established in the pioneering text @xcite which , in particular , demonstrated the potential for markov chain monte carlo ( mcmc ) methods in this context . nonetheless , the high dimensional nature of the unknown , often found from discretizing a field , leads to difficult problems in the design of proposals which are cheap to implement , yet which mix efficiently .",
    "one recent approach to tackle these problems has been the development of algorithms with mesh - free mixing times , such as those highlighted in @xcite ; these non - standard mcmc algorithms avoid the unnecessary penalties incurred by naive proposals related to exploration of the part of the parameter space dominated by the prior . nonetheless , in the large dataset or small",
    "observational noise regimes , one is still confronted with an inference problem in high dimensions which , whilst of smaller order than the dimension of the pde solver , exhibits wide variations in scales in different coordinates of the parameterizations , leading to substantial challenges for algorithmic tuning .",
    "a different approach , which we will adopt here , involves smc samplers @xcite .",
    "these are particle methods which , in the context of bayesian inverse problems , build an approximation to a sequence of measures which interpolate from the prior to the posterior ; the sequential nature of the approximation allows for adaptation of the particle distribution and weights from the ( typically simple ) prior to the ( potentially very complex ) posterior .",
    "recent work in the context of inverse problems @xcite has shown how , by using the aforementioned dimension - independent mcmc methods within smc , it is possible to construct algorithms which combine the desirable dimension - independent aspects of novel mcmc algorithms with the desirable self - adaptation of particle methods .",
    "this combination is beneficial for complex posteriors such as those arising in the large dataset or small noise regimes ; in particular the computational results in @xcite demonstrate an order of magnitude speed - up of these new smc methods over the mcmc methods highlighted in @xcite , within the context of the inverse problem for the initial condition of the navier - stokes equation .",
    "furthermore , recent works @xcite have shown that important aspects of this smc algorithm for inverse problems , such as adaptation , tempering and parallelization , have the potential to provide effective methods even for high - dimensional inverse problems",
    ".    the contributions of this article are three - fold :    1 .   a computational study of smc methods for a class of bayesian inverse problems which arise in applications such as hydrology @xcite , and are more challenging to fit , in comparison to the navier - stokes inverse problem which was the focus of the development of novel smc methods in @xcite ; furthermore , with modification of the measurement set - up , the inverse problems considered also find application in medical imaging problems such as eit @xcite .",
    "an enhancement of the class of smc methods introduced in @xcite which leads to greater efficiency and , in particular , the ability to efficiently solve the elliptic inverse problems which are the focus of this paper .",
    "3 .   a proof of the fact that these smc algorithms have monte carlo convergence rates which are mesh - independent and",
    ", indeed converge in the function space setting .",
    "this complements related theoretical work @xcite which establishes mesh - independence mixing for the novel mcmc methods which are used as proposal kernels within the smc approach of @xcite which we build upon here .",
    "this article is structured as follows . in section [ 3dinv ]",
    "we describe the bayesian model and associated pde . in section [ sec",
    ": smc ] our computational procedure is outlined , along with our theoretical results . in section [ sec : numerics ] we present our numerical results .",
    "the article is concluded in section [ sec : summ ] with a discussion of areas for future work .",
    "consider two normed linear spaces , @xmath3 and @xmath4 , corresponding to the state space of the parameters ( @xmath5 ) and observations ( @xmath6 ) respectively .",
    "we will observe data at spatial locations @xmath7 and we denote the observation at location @xmath8 as @xmath9 .",
    "let @xmath10 and , for each @xmath11 , let @xmath12 be a random variable of zero mean ; then we will be concerned with models of the form : @xmath13 here @xmath14 is an underlying system behaviour for a given parameter @xmath15 , and @xmath16 expresses measurement ( and indeed sometimes model error ) at location @xmath8 . in our context , @xmath17 is associated to the solution of a pde , with parameter @xmath15 .",
    "we are interested in drawing inference on @xmath15 , given a prior distribution on @xmath5 , conditional upon observing realizations of @xmath9 for a set of points @xmath18 , with @xmath19 .",
    "this is the framework of our bayesian inverse problem . in subsection [ ssec :",
    "fm ] we define the forward model , and in subsection [ ssec : modelk ] we describe prior modelling on our unknown .",
    "subsection [ ssec : bayesian ] shows that the posterior distribution is well - defined and states a key property of the log - likelihood , used in what follows .      in this paper , we focus on the general scenario where the forward map @xmath17 is described by an elliptic pde .",
    "in particular , we work with a problem of central significance in hydrology , namely the estimation of subsurface flow from measurements of the pressure ( hydraulic head ) at certain locations @xmath8 in the domain of interest . the pressure and velocity are linked by darcy s law in which the subsurface permeability appears as a parameter ; estimating it is thus a key step in predicting the subsurface flow . in this subsection",
    "we define the forward map from permability to pressure space .    in detail , we consider the @xmath20dimensional cube @xmath21^d$ ] as our domain , in both the cases @xmath22 define a mapping @xmath23 , denoting pressure ( or hydraulic head ) , @xmath24 , denoting a quantity proportional to velocity , and @xmath25 , denoting permeability ( or hydraulic conductivity ) of soil @xcite .",
    "the behaviour of the system is described through the elliptic pde :    [ eq2 ] @xmath26    equation ( [ eq2]a ) is darcy s law and contains the permeability @xmath15 ( for us the key parameter ) ; equation ( [ eq2]b ) expresses continuity of mass and here @xmath27 is assumed known and characterizes the source / sink configuration ; in equation ( [ eq2]c ) @xmath28 is the boundary of the domain , and we are thus assuming a homogeneous boundary condition on the boundary pressure  other boundary conditions , specifying the flux , are also possible .",
    "together equations define an elliptic pde for pressure @xmath29 .",
    "if @xmath15 is in @xmath30 and lower bounded by a positive constant @xmath31 a.e . in @xmath32 then , for every @xmath33 , there is a unique solution @xmath34 to the pde satisfying @xmath35 see @xcite and the references therein . in this setting ,",
    "the forward map @xmath36 is well - defined and thus corresponds to solution of the elliptic pde for a given permeability field @xmath15 .",
    "a typical choice of the source / sink function @xmath37 is @xmath38 the set of points @xmath39 denote the known position of sources or sinks , and the signs of each @xmath40 determine whether one has a source or sink at @xmath41 @xcite .",
    "we note that the cleanest setting for the mathematical formulation of the problem requires @xmath33 and , in theory , will require mollification of the dirac s at each @xmath41 ; in practice this modification makes little difference to the inference .",
    "we describe the modelling of @xmath15 in three dimensions ; simplification to the two dimensional setting is straightforward .",
    "we begin by expressing the unknown model parameter as a fourier series : @xmath42 here we have scaled fourier coefficients @xmath43 and the real coefficients @xmath44 , complex coefficients @xmath45 ( satisfying @xmath46 ) and real - valued @xmath47 function @xmath48 will be chosen to enforce the mathematically necessary ( and physically sensible ) positivity restriction @xmath49 the use of fourier series in principle enables the representation of arbitrary functions in @xmath50 by use of periodic extensions",
    ". however we will impose a rate of decay on the @xmath44 , in order to work in the setting of inversion for this problem , as developed in @xcite ; this rate of decay will imply a certain degree of smoothness in the function @xmath51 noting that the functions @xmath52 have @xmath30 norm equal to one , we can place ourselves in the setting of @xcite by assuming that , for some @xmath53 , @xmath54 , @xmath55 we choose @xmath56 of the form @xmath57 and then impose @xmath58 in dimension @xmath59 or @xmath60 in dimension @xmath61 .",
    "given this set - up , we need to find a suitable prior for @xmath15 , so that the forward model @xmath14 is almost - surely well - defined , as well as reflecting any prior statistical information we may have .",
    "there are several widely adopted approaches in the literature for prior parameterization of the permeability , the most common being the log - normal choice ( see @xcite for details and , for example , @xcite for a recent application ) , widely adopted by geophysicists , and the uniform case @xcite which has been succesfully adopted in the computational mathematics literature , building on earlier work of schwab in uncertainty quantification @xcite .",
    "we work with the uniform priors popularized by schwab : we choose @xmath62}$ ] in the representation for @xmath15 , resulting in a pushforward measure @xmath63 on @xmath15 as in @xcite .",
    "we let @xmath3 denote the separable banach space found from the closure , with respect to the @xmath64 norm , of the set of functions used in the representation of @xmath65 .",
    "then @xmath63 is viewed as a measure on @xmath3 ; see @xcite for further details .",
    "once the parameters @xmath56 are chosen to satisfy , the mean function @xmath66 can be chosen to ensure that there is @xmath67 such that @xmath65 is in @xmath30 and satisfies almost surely with respect to the prior @xmath63 on function @xmath15 .",
    "we observe the pressure at certain locations , the set of which is denoted as @xmath68 .",
    "we will suppose that for each @xmath69 and independently , @xmath70 , where @xmath71 is the normal distribution of mean 0 and known variance @xmath72 .",
    "then the log - likelihood is , up to an irrelevant additive constant , given by @xmath73    along with the prior modelling in subsection [ ssec : modelk ] , this defines a scenario so that the forward model @xmath74 is , almost - surely , well - defined and , in fact , lipschitz . as in @xcite",
    "we may then define a posterior @xmath75 on @xmath15 which has density with respect to @xmath63 given by : @xmath76 exploring the posterior distribution @xmath75 is the objective of the paper . in doing so , the following fact will be relevant ; it is easily established by using the fact that holds almost surely for @xmath77 , together with the bound on the solution of the elliptic pde given in .",
    "[ lem : note ] there is a constant @xmath78 such that @xmath79 almost surely for @xmath80    we finish by noting that , in algorithmic practice , it is typically necessary ( see , however , @xcite in the context of mcmc ) to apply a spectral truncation : @xmath81 where @xmath82 is a truncation parameter . having defined the desired parameterization of @xmath15 , we consider the truncated vector of fourier coefficients @xmath83 as the object of inference in practice .",
    "in this section we describe the application of smc methods to bayesian inversion .",
    "subsection [ ssec : smc ] contains an explanation of the basic methodology and statement of a basic ( non - adaptive ) algorithm .",
    "subsection [ ssec : t ] contains statement and proof of a convergence theorem for the basic form of the algorithm , notable because it applies in infinite dimensional spaces . in subsection",
    "[ ssec : a ] we describe an adaptive version of the smc algorithm , which we use in practice .",
    "let @xmath84 denote a measure space and @xmath63 a probability measure on that space .",
    "we wish to sample from a target probability measure @xmath85 on @xmath84 , which has density with respect to @xmath63 known up to a normalizing constant : @xmath86 we introduce a sequence of `` bridging '' densities which enable us to connect @xmath63 to @xmath85 : @xmath87 where @xmath88 we refer to the @xmath89 as _ temperatures_. we let @xmath90 denote the probability measure with density proportional to @xmath91 with respect to @xmath63 . assuming that @xmath92 is finite @xmath63 almost surely we obtain @xmath93 we note that the assumption on @xmath94 being finite is satisfied for our elliptic inverse problem ; see lemma [ lem : note ] .",
    "although @xmath95 may be far from @xmath63 , careful choice of the @xmath96 can ensure that @xmath97 is close to @xmath98 allowing gradual evolution of approximation of @xmath63 into approximation of @xmath85 .",
    "other choices of bridging densities are possible and are discussed in e.g.  @xcite .",
    "let @xmath99 denote the sequence of ( nonlinear ) maps on measures found by applying bayes s theorem with likelihood proportional to @xmath100 and let @xmath101 be a sequence of markov kernels ( and equivalently , for notational convenience , the resulting linear maps on measures ) with invariant measure @xmath102 .",
    "we define @xmath103 to be the nonlinear maps on measures found as @xmath104 .",
    "explicitly we have , for each @xmath105 and any probability measure @xmath106 on @xmath107 : @xmath108 where we use the notation @xmath109 and @xmath110 .",
    "it then follows that @xmath111 the standard smc algorithm is described in figure [ tab : smc ] .",
    "it involves a population of @xmath112 particles evolving with @xmath113 . with no resampling ,",
    "the algorithm coincides with annealed importance sampling as in @xcite .",
    "with resampling at every step ( i.e. the case @xmath114 , where @xmath115 denotes the cut - off point for the effective sample size ( ees ) ) we define the empirical approximating measures by the iteration @xmath116 here @xmath117    ' '' ''    _ _    1 .",
    "sample @xmath118 i.i.d . from @xmath63 and define the weights @xmath119 for @xmath120 set @xmath121 and @xmath122 .",
    "2 .   for each @xmath123 set @xmath124 and sample @xmath125 from @xmath126 calculate the normalized weights @xmath127 3 .",
    "calculate the effective sample size ( ess ) : @xmath128 if @xmath129 : + resample @xmath130 according to the normalized weights @xmath131 ; + re - initialise the weights by setting @xmath132 for @xmath133 ; + let @xmath130 now denote the resampled particles .",
    "if @xmath134 set @xmath135 and return to step 1 ; otherwise stop .    ' '' ''      the issue of dimensionality in smc methods has attracted substantial attention in the literature @xcite . in this section , using a simple approach for the analysis of particle filters which is clearly exposed in @xcite , we show that for our smc method it is possible to prove dimension - free error bounds . whilst the theoretical result in this subsection is not entirely new ( similar results follow from the work in @xcite ) , a direct and simple proof is included for non - specialists in smc methods , to highight the utility of smc methods in inverse problems , and to connect with related recent results in dimension - independent mcmc , such as @xcite , which are far harder to establish .",
    "we will consider the algorithm in figure [ tab : smc ] with @xmath136 , so one resamples at every time step ( and this is multinomially ) .",
    "note that then , for @xmath137 , at the end of each step of the algorithm the approximation to @xmath90 is given by @xmath138 which follows from the algorithm in figure [ tab : smc ] with @xmath136 or , equivalently , . throughout",
    ", we will assume that there exists a @xmath139 such that for each @xmath137 and any @xmath140 @xmath141 we note that this holds for the elliptic inverse problem from the previous section , when the uniform prior @xmath63 is employed ; see lemma [ lem : note ] .",
    "let @xmath142 denote the collection of all probability measures on @xmath107 .",
    "let @xmath143 and @xmath144 denote two possibly random elements in @xmath142 , and @xmath145 expectation w.r.t .",
    "@xmath146 we define the distance between @xmath147 by @xmath148 where the supremum is over all @xmath149 with @xmath150 this definition of distance is indeed a metric on the space of random probability measures ; in particular it satisfies the triangle inequality . in the context of smc the randomness underlying the approximations comes from the various sampling operations within the algorithm .",
    "we have the following convergence result for the smc algorithm .    [ th39 ]",
    "assume and consider the smc algorithm with @xmath114 .",
    "then , for any @xmath137 , @xmath151    for @xmath152 the result holds via lemma [ lem : tech_lem2 ] . for @xmath153 , we have , by the triangle inequality , lemma [ lem : tech_lem ] and lemma [ lem : tech_lem2 ] ( which may be used by the conditional independence structure of the algorithm )",
    ", @xmath154 iterating gives the desired result .",
    "[ rem : fil ] this theorem shows that the sequential particle filter actually reproduces the true posterior distribution @xmath155 , in the limit @xmath156 .",
    "we make some comments about this .",
    "* the measure @xmath155 is well - approximated by @xmath157 in the sense that , as the number of particles @xmath156 , the approximating measure converges to the true measure .",
    "the result holds in the infinite dimensional setting . as a consequence",
    "the algorithm as stated is robust to finite dimensional approximation . * in principle the theory applies even if the markov kernel @xmath158 is simply the identity mapping on probability measures .",
    "however , moving the particles according to a non - trivial @xmath90-invariant measure is absolutely essential for the methodology to work in practice .",
    "this can be seen by noting that if @xmath158 is indeed taken to be the identity map on measures then the particle positions will be unchanged as @xmath113 changes , meaning that the measure @xmath155 is approximated by weighted samples ( almost ) from the prior , clearly undesirable in general .",
    "* the mcmc methods in @xcite provide explicit examples of markov kernels with the desired property of preserving the measures @xmath90 , including the infinite dimensional setting .",
    "* in fact , if the markov kernel @xmath158 has some ergodicity properties then it is sometimes possible to obtain bounds which are _ uniform _ in @xmath29 ; see @xcite .",
    "[ lem : tech_lem ] assume .",
    "then , for any @xmath105 and any @xmath159 , @xmath160    for any measurable @xmath161 we have @xmath162(f )   & = \\frac{1}{\\mu(\\ell_{n-1})}[\\mu-\\nu](\\ell_{n-1}k_n(f))\\\\ & \\quad\\quad\\quad\\quad\\quad +   \\frac{\\nu(\\ell_{n-1}k_n(f))}{\\mu(\\ell_{n-1})\\nu(\\ell_{n-1 } ) } [ \\nu-\\mu](\\ell_{n-1}).\\end{aligned}\\ ] ] so we have , by minkowski , @xmath163(f)|^2]^{1/2 } & \\leq \\mathbb{e}^{\\omega}\\big[\\big|\\frac{1}{\\mu(\\ell_{n-1})}[\\mu-\\nu](\\ell_{n-1}k_n(f))\\big|^2\\big]^{1/2}\\\\ & \\quad\\quad\\quad\\quad\\quad+ \\mathbb{e}^{\\omega}\\big[\\big|\\frac{\\nu(\\ell_{n-1}k_n(f))}{\\mu(\\ell_{n-1})\\nu(\\ell_{n-1 } ) } [ \\nu-\\mu](\\ell_{n-1})]\\big|^2\\big]^{1/2}.\\end{aligned}\\ ] ] note that the ratio @xmath164 is an expectation of @xmath37 and is hence bounded by @xmath165 in modulus , if @xmath166 then using the fact that @xmath167 and @xmath168 ( see ) we deduce that @xmath163(f)|^2]^{1/2 } & \\leq \\frac{1}{\\kappa^2}\\mathbb{e}^{\\omega}\\big[\\big|[\\mu-\\nu](\\ell_{n-1}k_n(f)\\kappa)\\big|^2\\big]^{1/2}\\\\ & \\quad\\quad\\quad\\quad\\quad+   \\frac{1}{\\kappa^2}\\mathbb{e}^{\\omega}\\big[\\big|[\\nu-\\mu](\\ell_{n-1}\\kappa)]\\big|^2\\big]^{1/2}.\\end{aligned}\\ ] ] using the fact that @xmath167 and @xmath169 , with the first following from together with the markov property for @xmath158 , taking suprema over @xmath37 completes the proof .",
    "[ lem : tech_lem2 ] the sampling operator satisfies @xmath170    let @xmath85 be an element of @xmath171 and @xmath172 a set of i.i.d",
    ".  samples with @xmath173 ; the randomness entering the probability measures is through these samples , expectation with respect to which we denote by @xmath174 in what follows .",
    "then @xmath175 and , defining @xmath176 , we deduce that @xmath177 it is straightforward to see that @xmath178 furthermore , for @xmath179 , @xmath180 it follows that , for @xmath179 , @xmath181 since the result is independent of @xmath85 we may take the supremum over all probability measures and obtain the desired result .      in practice",
    ", the smc samplers algorithm requires the specification of @xmath182 as well as any parameters in the mcmc kernels .",
    "as demonstrated in @xcite , the theoretical validity of which is established in @xcite , these parameters may be set on the fly .",
    "first , we focus on the specification of the sequence of distributions . given step @xmath183 and @xmath184",
    ", we select the next target density by adapting the temperatures to a required value for the effective sample size ( ess ) statistic as in @xcite ( see also @xcite for an alternative procedure ) .",
    "so , for a user - specified threshold @xmath185 , we choose @xmath186 as the solution of @xmath187 .",
    "one can use an inexpensive bisection method to obtain @xmath96 .",
    "second , we turn to the specification of the mutation kernels @xmath158 .",
    "several options are available here , but we will use reflective random walk metropolis proposals on each univariate component , conditionally independently .",
    "we will adapt the random - move proposal scales , @xmath188 , with @xmath189 the co - ordinate and @xmath113 the time index .",
    "a simple choice would be to tune @xmath188 to the marginal variance along the @xmath189-th co - ordinate ; since this is analytically unavailable we opt for the smc estimate at the previous time - step .",
    "thus , we set @xmath190 where @xmath191 is a global scaling parameter . for @xmath191 itself , we propose to modify it based on the previous average acceptance rate over the population of particles ( denoted @xmath192 ) , to try to have average acceptance rates in a neighbourhood of 0.2 ( see e.g.  @xcite and the references therein for a justification ) .",
    "our adaptive strategy works as follows ; @xmath193 thus , we scale @xmath194 upwards ( downwards ) if the last average acceptance rate went above ( below ) a predetermined neighbourhood of 0.2 .",
    "this approach is different to the work in @xcite .",
    "in addition , one can synthesize a number , say @xmath195 , of baseline mcmc kernels , to obtain an overall effective one with good mixing ; this is a new contribution relative to @xcite . to adapt @xmath195 ,",
    "we follow the following heuristic ; we propose to select @xmath195 using @xmath196 , with @xmath123 being a global parameter .",
    "the intuition is that for random - walk - type transitions of increment with small standard deviation @xmath197 , one needs @xmath198 steps to travel distance @xmath199 in the state - space .",
    "a final modification for practical computational reasons is that we force @xmath195 steps to lie within a predetermined bounded set , i.e. @xmath200 $ ] .",
    "the adaptive smc algorithm works as in figure [ tab : smc ] , except in step 1 , before simulation from @xmath158 is undertaken , our adaptive procedure is implemented .",
    "then one may resample ( or not ) and then move the samples according to @xmath158 .",
    "in addition , the algorithm will run for a random number of time steps and terminate when @xmath201 ( which will happen in a finite number of steps almost surely ) .",
    "in this section , we describe the details of our implementation ( section [ ssec : i ] ) , describe the objects of inference ( section [ ssec : oii ] ) and give our results in 2d ( section [ ssec:2d ] ) and 3d ( section [ ssec:3d ] ) .",
    "the software used in our experiments has been implemented in c++ for the gnu@xmath202linux platform .",
    "we used the libmesh library for finite elements computation @xcite , we used the fast fourier transform for rapid evaluation of the sum in @xmath65 at pre - determined grid - points in @xmath203 and we exploited parallel computation wherever possible , for which we used the mpi libraries .",
    "our experiments were run on a computer server with 23 `` intel(r ) xeon(r)cpu x7460 @2.66ghz '' processors , each with 2 cores ; 50 gb memory and running `` redhat linux version 2.6.18-194.el5 '' operating system .",
    "the experiments discussed in this paper used 20 processors .",
    "all the colour plots of random fields ( e.g. permeability fields ) have been prepared using the rainbow color scheme from the r programming language / environment .",
    "the scheme quantizes the hue quantity of hsv ( hue saturation value ) triplet of a pixel .",
    "our level of quantization is selected to be 256 ( 8 bits ) , with the hue range of @xmath204 $ ] , hence we normalize the random fields to this range and quantize to 8 bits to get the hue value for a pixel .",
    "saturation and value were taken to be 1 .",
    "all images were computed using @xmath205 equi - spaced point evaluations from the respective random fields .",
    "the work in @xcite investigates the performance of the bayesian approach for our elliptic inverse problem and gives sufficient conditions under which posterior consistency holds .",
    "posterior consistency is concerned with `` ball probabilities '' of type @xmath206 where @xmath207 and @xmath208 is the @xmath209 neighbourhood of the true value of @xmath15 .",
    "one way to check such a result numerically is to use the posterior estimates obtained via our method .",
    "the estimated ball probabilities are computed as follows : @xmath210    although not all the conditions in @xcite required for posterior consistency to hold are fulfilled , we will nonetheless empirically investigate such a consistency property .",
    "this also provides a severe test for the smc method since it implies posterior measures in the large dataset limit .",
    "we consider equation in dimension @xmath61 and with source and sinks as specified in . our goal is to construct a sequence of posterior estimates , corresponding to increasing number of observations in order to numerically illustrate posterior consistency .",
    "table [ tab_2d_param ] shows the parameters used in our experiments .",
    ".parameter values of used for the 2d experiments . between 5 and 1000 steps are allowed for the iterates of the mcmc kernels .",
    "the frequency cutoff determines the level of discretization of the permeability field .",
    "finite elements d.o.f .",
    "denotes the number of finite elements used in the numerical solution of the elliptic pde , higher values indicate better approximation at the expense of computational resources . for @xmath211",
    "see . [ cols=\"<,^\",options=\"header \" , ]     in figure [ smc_performance ] , we consider the performance of our smc algorithm in this very challenging scenario . in figure [ smc_performance ] ( a )",
    ", we can see the average acceptance rates of the mcmc moves , over the time parameter of the smc algorithm .",
    "we can observe that these acceptance rates do not collapse to zero and are not too far from 0.2 .",
    "this indicates that the step - sizes are chosen quite reasonably by the adaptive smc algorithm and the mcmc kernels have some mixing ability . in figure [ smc_performance ] ( b ) , we can see the number of mcmc iterations that are used per - particle over the time parameter of the smc algorithm .",
    "we can observe , as one might expect , that as the target distribution becomes more challenging , the number of mcmc steps required grows .",
    "figure [ smc_performance ] indicates reasonable performance of our smc algorithm .    in terms of inference ,",
    "the posterior density estimates are shown in figure [ density ] .",
    "recall that the priors are uniform .",
    "these estimates indicate a clear deviation from the prior specification , illustrating that the data influence our inference significantly .",
    "this is not obvious , and establishes that one can hope to use this bayesian model in real applications .    2.9 in     2.5 in",
    "in this article we have presented an smc method for bayesian inverse problems and applied it to a particular elliptic pde inversion ; the methodology , however , is transferable to other pde inverse problems .",
    "simulations demonstrated both the feasability of the smc method for challenging infinite dimensional inversion , as well as the property of posterior contraction to the truth .",
    "in addition to simulations , we have provided a straightforward proof of the fact that smc methods are robust to the dimension of the problem .",
    "there are several avenues for future research .",
    "firstly , our error bounds explode w.r.t . the time parameter .",
    "it is of interest to find realistic conditions for which this is not the case ( for instance the bounds in @xcite have assumptions which either do not hold or are hard to verify ) .",
    "secondly , a further algorithmic innovation is to use multi - level monte carlo method as in @xcite , within the smc context ; this is being considered in @xcite . and",
    "finally it is of interest to consider the use of these methods to solve other bayesian inference problems ."
  ],
  "abstract_text": [
    "<S> in this article we consider a bayesian inverse problem associated to elliptic partial differential equations ( pdes ) in two and three dimensions . </S>",
    "<S> this class of inverse problems is important in applications such as hydrology , but the complexity of the link function between unknown field and measurements can make it difficult to draw inference from the associated posterior . we prove that for this inverse problem a basic smc method has a monte carlo rate of convergence with constants which are independent of the dimension of the discretization of the problem ; indeed convergence of the smc method is established in a function space setting . </S>",
    "<S> we also develop an enhancement of the sequential monte carlo ( smc ) methods for inverse problems which were introduced in @xcite ; the enhancement is designed to deal with the additional complexity of this elliptic inverse problem . the efficacy of the methodology , and its desirable theoretical properties , are demonstrated on numerical examples in both two and three dimensions . + * keywords * : inverse problems , elliptic pdes , groundwater flow , adaptive smc , markov chain monte carlo .    * sequential monte carlo methods for bayesian elliptic inverse problems *    by alexandros beskos@xmath0 , ajay jasra@xmath1 , ege a. muzaffer@xmath1 & andrew m. stuart@xmath2    @xmath0department of statistical science , university college london , london , wc1e 7hb , uk . </S>",
    "<S> + e-mail:`alex@stats.ucl.ac.uk ` + @xmath1department of statistics & applied probability , national university of singapore , singapore , 117546 , sg . </S>",
    "<S> + e-mail:`staja@nus.edu.sg , m.ege85@nus.edu.sg ` + @xmath2department of mathematics , university of warwick , coventry , cv4 7al , uk . </S>",
    "<S> + e-mail:`a.m.stuart@warwick.ac.uk ` </S>"
  ]
}