{
  "article_text": [
    "in this article , we continue the analysis we began in @xcite on stochastic homogenization of discrete elliptic equations .",
    "more precisely , we consider real functions @xmath23 of the sites @xmath24 in a @xmath0-dimensional cartesian lattice  @xmath1 .",
    "every edge @xmath25 of the lattice is endowed with a `` conductivity '' @xmath26 .",
    "this defines a discrete elliptic differential operator @xmath27 via @xmath28 where the sum is over the @xmath29 sites @xmath30 which are connected by an edge @xmath31 $ ] to the site @xmath24 .",
    "it is sometimes more convenient to think in terms of the associated dirichlet form , that is,@xmath32 where the last sum is over all edges @xmath25 and @xmath33 denotes the two sites connected by @xmath25 , that is , @xmath31=[y , x]$ ] ( with the convention that an edge is not oriented ) .",
    "we assume the conductivities @xmath34 to be uniformly elliptic in the sense of @xmath35 for some fixed constants @xmath36 .",
    "we are interested in random coefficients . to fix ideas , we consider the simplest situation possible : @xmath37 hence",
    ", the statistics are described by a distribution on the finite interval @xmath38 $ ] .",
    "we d like to see this discrete elliptic operator with random coefficients as a good model problem for continuum elliptic operators with random coefficients of correlation length unity .",
    "classical results in stochastic homogenization of linear elliptic equations ( see @xcite and @xcite for the continuous case , and @xcite and @xcite for the discrete case ) state that there exist _ homogeneous and deterministic _ coefficients @xmath39 such that the solution operator of the continuum differential operator @xmath40 describes the large scale behavior of the solution operator of the discrete differential operator @xmath27 . as a by product of this homogenization result ,",
    "one obtains a characterization of the homogenized coefficients @xmath39 : it is shown that for every direction @xmath5 , there exists a unique scalar field  @xmath6 such that @xmath9 is stationary [ stationarity means that the fields @xmath41 and @xmath42 have the same statistics for all shifts @xmath43 and @xmath44 , solving the equation @xmath45 and normalized by @xmath8 . as in periodic homogenization ,",
    "the function @xmath46 can be seen as the @xmath2-harmonic function which macroscopically behaves as the affine function @xmath47 . with this `` corrector ''  @xmath6 , the homogenized coefficients @xmath39 ( which in general form a symmetric matrix and for our simple statistics in fact a multiple of the identity : @xmath48 ) can be characterized as follows : @xmath49 since the scalar field @xmath50 is stationary , it does not matter ( in terms of the distribution ) at which site @xmath24 it is evaluated in the formula  ( [ pv1 ] ) , so that we suppress the argument @xmath24 in our notation .",
    "when one is interested in explicit values for @xmath17 , one has to solve ( [ pv2 ] ) .",
    "since this is not possible in practice , one has to make approximations . for a discussion of the literature on error estimates , in particular the pertinent work by yurinskii @xcite and naddaf and spencer @xcite",
    ", we refer to @xcite , section  1.2 . a standard approach used in practice",
    "consists in solving ( [ pv2 ] ) in a  box @xmath51 with periodic boundary conditions @xmath52 and replacing ( [ pv1 ] ) by a space average @xmath53 such an approach is consistent in the sense that @xmath54 almost surely , as proved , for instance , in @xcite for the continuous case , and in  @xcite for the discrete case .",
    "numerical experiments tend to show that the use of periodic boundary conditions gives better results than other choices such as homogeneous dirichlet boundary conditions , see @xcite .",
    "an important question for practical purposes is to quantify the dependence of the error @xmath55 in terms of @xmath21 .",
    "let us give another interpretation of ( [ pv2-b ] ) : this equation on @xmath15 is equivalent to ( [ pv2 ] ) on @xmath56 with a modified conductivity matrix @xmath57 , that is the periodization of @xmath58 on @xmath56 .",
    "doing this , we have replaced independent coefficients @xmath2 by @xmath15-periodically correlated coefficients @xmath59 .",
    "since @xmath2 and @xmath59 are not jointly stationary ( see definition  [ def : stationary ] ) , it may be difficult to compare @xmath9 to @xmath60 . to circumvent this difficulty , and following the route of @xcite and @xcite , and as in @xcite",
    ", we slightly depart from ( [ pv2-b ] ) by introducing a zero - order term in ( [ pv2 ] ) : @xmath61 as for the periodization , this localizes the dependence of @xmath62 upon @xmath63 to those points @xmath64 such that @xmath65 ( at first order ) . yet , unlike the periodization , @xmath66 and @xmath9 are jointly stationary . in terms of random walk interpretation ,",
    "the lifetime of the random walker is of order @xmath22 , and the distance to the origin of order @xmath67 .",
    "hence , up to taking @xmath68 , in first approximation , the function @xmath69 only depends on the coefficients @xmath70 for @xmath71 , as it is the case for @xmath72 .    we d like to view @xmath69 as a variant of @xmath73 which is convenient for our analysis .",
    "we then define @xmath74 where @xmath75 is a smooth mask with unit mass and support @xmath15 .",
    "the aim of this paper is to determine the scaling of the error @xmath76 in terms of @xmath21 and @xmath22 .",
    "eventually this will allow us to make a reasonable choice for @xmath22 and @xmath21 at fixed computational complexity .",
    "@xmath77when approximating @xmath17 by  @xmath78 , we make two types of errors : a `` systematic error '' and a `` random error . '' in particular , as shown in @xcite , @xmath79.\\ ] ] the first term is the square of the systematic error ( see @xcite , ( 1.10 ) ) @xmath80\\\\[-8pt ] & \\hspace*{3pt}=&\\langle(\\nabla\\phi_t-\\nabla\\phi)\\cdot a ( \\nabla \\phi_t-\\nabla \\phi ) \\rangle.\\nonumber\\hspace*{-35pt}\\end{aligned}\\ ] ] it measures the fact that the coefficient @xmath81 at bond @xmath25 does ( up to exponentially small terms ) not influence @xmath82 if @xmath83 .",
    "this error vanishes for @xmath84 .",
    "the second term is the square of the random error , @xmath85^{1/2}.\\end{aligned}\\ ] ] it measures the fluctuations of the energy density .",
    "this error vanishes as @xmath86 .    in @xcite ,",
    "theorem  1 , we have proved that @xmath87^{1/2 } \\lesssim \\cases { d=2,&\\quad$l^{-1}\\ln^qt$ , \\cr d>2,&\\quad$l^{-d/2}$ , } \\hspace*{-30pt}\\ ] ] for some @xmath88 depending only on @xmath89 , where `` @xmath90 '' stands for `` @xmath91 '' up to a  multiplicative constant depending only on @xmath89 and @xmath0 .",
    "we have also identified the systematic error in the limit of vanishing conductivity contrast , that is , @xmath92 , and found @xmath93 where `` @xmath94 '' means that both terms have the same scaling ( in @xmath22 ) . in this paper",
    ", we shall actually prove that for general @xmath95 and @xmath96 ( see theorem [ th1 ] ) @xmath97 where there is a logarithmic correction for @xmath98 when compared to the vanishing conductivity asymptotics .    assuming that @xmath99 can be well approximated on domains of size @xmath21",
    "if we choose @xmath100 , the combination of ( [ eq : error - sys ] ) and ( [ eq : intro - thm - var ] ) yields @xmath101 hence , the numerical strategy converges at the rate of the central limit theorem for @xmath102 ( up to logarithmic corrections for @xmath98 and @xmath103 ) .    up to dimension 4 , the systematic error for @xmath20 scales as the square of the random error .",
    "in particular , this leaves room for the choice @xmath22 .",
    "if we take @xmath104 , then the systematic error is of the same order as the random error .",
    "what we have gained is that @xmath99 can now be well - approximated on domains of size @xmath105 , and not only @xmath21 .",
    "note also that the random error is unchanged if instead of taking the average of one realization of @xmath99 on  @xmath15 ( with the mask @xmath106 ) we take the empirical average of the averages of  @xmath107 independent realizations of @xmath99 on a domain @xmath108 ( with the according mask @xmath109 ) .",
    "hence , since @xmath99 can be well - approximated on domains of size @xmath110 , considering @xmath111 realization of @xmath99 approximated on @xmath15 or @xmath112 independent realizations of @xmath99 approximated on @xmath113 yields the same scaling for the error between the homogenized coefficients and their approximations .",
    "since the computational cost of solving a linear problem is superlinear in the number of unknowns , it seems best to choose @xmath107 as large as possible , and therefore taking @xmath114 seems a reasonable strategy at first order .",
    "yet , we do not make precise in this paper the relation between  @xmath115 and @xmath116 in terms of absolute values ( we only consider the scaling ) , which may make the optimal choice for @xmath107 more subtle in practice than this general principle .",
    "a complete numerical analysis of the numerical method ( including the influence of @xmath115 and the optimization of @xmath107 ) will be presented in @xcite .",
    "we conclude this introduction by mentioning the very recent contribution  @xcite by mourrat .",
    "the equation under investigation is the same as above , namely a discrete elliptic equation on @xmath56 with i.i.d .",
    "the object under study is the spectral measure associated with the generator of the environment viewed by the particle . without entering into details",
    ", there exists some nonnegative measure @xmath117 associated with the elliptic operator and direction @xmath118 , such that the homogenized coefficient is given by @xmath119 as recalled in @xcite , we also have @xmath120 in particular , the systematic error can be written as @xmath121 so that information on the scaling of the systematic error in terms of @xmath22 yields information on the spectral behavior and conversely . the interplay between the strategy used in the present paper and the spectral measure",
    "is further investigated by mourrat and the first author in @xcite . in what follows ,",
    "we do not make use of the spectral measure , which makes our approach self - contained .",
    "the article is organized as follows : in section  [ sec : main - res ] , we introduce the general framework and state the main results of this paper , that is , the systematic error actually scales as in ( [ eq : error - sys ] ) . the last two sections are dedicated to its proof .    throughout the paper ,",
    "we make use of the following notation :    * @xmath122 is the dimension ; * @xmath123 denotes the sum over @xmath124 , and @xmath125 denotes the sum over @xmath124 such that @xmath126 , @xmath127 subset of @xmath128 ; * @xmath129 is the ensemble average , or equivalently the expectation in the underlying probability space ; * @xmath130 $ ] is the variance associated with the ensemble average ; * @xmath131}$ ] is the covariance associated with the ensemble average ; * @xmath90 and @xmath132 stand for @xmath91 and @xmath133 up to a multiplicative constant which only depends on the dimension @xmath0 and the constants @xmath89 ( see definition  [ def : alpha - beta ] below ) if not otherwise stated ; * when both @xmath90 and @xmath132 hold , we simply write @xmath94 ; * we use @xmath134 instead of @xmath132 when the multiplicative constant is ( much ) larger than  @xmath135 ; * @xmath136 denotes the canonical basis of @xmath56 .",
    "[ def : alpha - beta ] we say that @xmath34 is a conductivity function if there exist @xmath137 such that for every edge @xmath25 of @xmath56 , one has @xmath138 $ ] .",
    "we denote by @xmath139 the set of such conductivity functions .    the elliptic operator @xmath140 , @xmath141 associated with a conductivity function @xmath142 is defined for all  @xmath124  by @xmath143 where @xmath144 , \\qquad \\nabla^ * u(x):= \\left [ \\matrix { u(x)-u(x-{\\mathbf{e}}_1 ) \\cr",
    "\\vdots\\cr u(x)-u(x-{\\mathbf{e}}_d ) } \\right]\\ ] ] and @xmath145},\\ ] ] @xmath146,\\dots , e_d=[x , x+{\\mathbf{e}}_d]$ ] .",
    "we now turn to the definition of the statistics of the conductivity function .",
    "@xmath77a conductivity function is said to be independent and  identically distributed ( i.i.d . )",
    "if the coefficients @xmath81 are i.i.d",
    ". random variables .",
    "[ def : stationary ] the conductivity matrix @xmath2 is obviously stationary in the sense that for all @xmath147 , @xmath148 and @xmath149 have the same statistics , so that for all @xmath150 , @xmath151 therefore , any translation invariant function of @xmath2 , such as the modified corrector @xmath99 ( see lemma  [ lem : app - corr ] ) , is jointly stationary with @xmath2",
    ". in particular , not only are @xmath99 and its gradient @xmath66 stationary , but also any function of @xmath2 ,  @xmath99 and  @xmath66 .",
    "a useful such example is the energy density , which is stationary by joint stationarity of @xmath2 and @xmath66 .",
    "another translation invariant function of @xmath2 is the green functions @xmath152 of definition  [ def : green ] . in this case",
    ", stationarity means that @xmath153 has the same statistics as @xmath154 for all @xmath147 , so that in particular , for all  @xmath155 , @xmath156    [ lem : corr ] let @xmath142 be an i.i.d .",
    "conductivity function , then for all @xmath157 , there exists a unique random function  @xmath158 which satisfies the corrector equation @xmath159 and such that @xmath8 , @xmath9 is stationary and @xmath160 .",
    "in addition , .",
    "we also define an `` approximation '' of the corrector as follows .",
    "[ lem : app - corr ] let be an i.i.d .",
    "conductivity function , then for all @xmath161 and @xmath118 , there exists a unique stationary random function @xmath162 which satisfies the `` approximate '' corrector equation @xmath163 and such that @xmath164 .",
    "in addition , @xmath165 .",
    "let @xmath142 be an i.i.d",
    ". conductivity function and let @xmath166 and @xmath6 be as in lemma  [ lem : corr ] .",
    "we define the homogenized @xmath167-matrix @xmath17 as @xmath168    note that ( [ eq : fo - homog ] ) fully characterizes @xmath17 since @xmath17 is a symmetric matrix ( it is actually of the form @xmath169 for an i.i.d",
    ". conductivity function ) .",
    "the main result of the article is the following estimate of the systematic error introduced in section  [ sec : intro ] .",
    "[ th1 ] let @xmath142 be an i.i.d .",
    "conductivity function , and let @xmath99 denote the approximate corrector associated with the conductivity function  @xmath34 and direction @xmath118 , @xmath170 .",
    "we then define for all @xmath171 the symmetric matrix @xmath172 characterized by @xmath173 then , there exists an exponent @xmath174 depending only on @xmath89 such that @xmath175\\\\[-8pt ] d&=&4\\mbox{:}\\qquad |a_{\\mathrm{hom}}-a_t| \\lesssim t^{-2}\\ln t,\\nonumber\\\\ d&>&4\\mbox{:}\\qquad |a_{\\mathrm{hom}}-a_t| \\lesssim t^{-2}.\\nonumber\\end{aligned}\\ ] ]    as a by - product of the proof of theorem  [ th1 ] , we obtain the following corollary .",
    "[ prop1 ] let @xmath142 be an i.i.d .",
    "conductivity function , @xmath176 , @xmath161 , and let @xmath99 and @xmath177 denote the approximate corrector and stationary corrector ( see @xcite , corollary  1 ) associated with the conductivity function @xmath34 and direction @xmath118 , @xmath170 , respectively .",
    "then @xmath178 in particular , @xmath179    this corollary gives a full characterization of the convergence of the regularized corrector to the exact corrector for @xmath176 .",
    "note that the definition ( [ eq : def - at ] ) of @xmath180 does not include the zero - order term @xmath181 , so that @xmath182 does not coincide with the energy associated with the equation .",
    "surprisingly , the addition of the zero - order term in the definition of @xmath180 would make the estimate ( [ eq : estim - err - hom ] ) saturate at @xmath183 for @xmath176 .    for @xmath98 , although we lose control of @xmath99 we may still quantify the rate of convergence of @xmath66 to @xmath9 , the gradient of the corrector of definition  [ lem : corr ] .",
    "in particular , ( [ eq : prop1 ] ) is replaced by @xmath184 for some @xmath174 depending only on @xmath89 .      in order to prove theorem  [ th1 ] and corollary  [ prop1 ]",
    ", we need three auxiliary lemmas in addition to the results of @xcite : the first one is a  covariance estimate very similar to the variance estimate in @xcite , lemma  2.3 , the next one is a refined version of the decay estimates of @xcite , lemma  2.8 , whereas the last one is a generalization of the convolution estimate of @xcite , lemma  2.10 .",
    "[ lem : cov ] let @xmath185 be a sequence of i.i.d .",
    "random variables with range @xmath38 $ ] .",
    "let @xmath186 and @xmath187 be two borel measurable functions of @xmath188 ( i.e. , measurable w.r.t .",
    "the smallest @xmath189-algebra on @xmath190 for which all coordinate functions @xmath191 are borel measurable , cf .",
    "@xcite , definition 14.4 ) .",
    "then we have @xmath192 } \\le \\sum_{i=1}^\\infty\\biggl\\langle\\sup_{a_i } \\biggl|\\frac{\\partial x}{\\partial a_i } \\biggr|^2 \\biggr\\rangle^{1/2 } \\biggl\\langle\\sup_{a_i } \\biggl|\\frac{\\partial y}{\\partial a_i } \\biggr|^2 \\biggr\\rangle^{1/2 } \\operatorname{var } [ a_1 ] , \\ ] ] where @xmath193 denotes the supremum of the modulus of the @xmath194th partial derivative @xmath195 of @xmath196 with respect to the variable @xmath197 $ ] , for @xmath198 .",
    "the proof of this lemma is standard . as for @xcite , lemma  2.3",
    ", it relies on a  martingale difference decomposition .",
    "we define discrete green s functions in the following definition .",
    "[ def : green ] let @xmath122 . for",
    "all @xmath161 , the green function @xmath199 associated with the conductivity function @xmath34 is defined for all @xmath200 and @xmath142 as the unique solution @xmath201 to @xmath202\\\\[-8pt ] \\eqntext{\\forall v\\in l^2({\\mathbb{z}}^d),}\\end{aligned}\\ ] ] where @xmath2 is as in  ( [ eq : def - elliptic ] ) .    throughout this paper ,",
    "when no confusion occurs , we use the shorthand notation @xmath203 for @xmath204 .",
    "we need a decay of the green function  @xmath203 and its ( discrete ) gradient @xmath205 in @xmath206 that is _ uniform _ in @xmath34 but nevertheless coincides ( in terms of scaling ) with the decay of the _ constant - coefficient _ green function .",
    "the constant - coefficient green function in the continuous case is known to decay as @xmath207 its gradient decays as the first derivative of these expressions .",
    "note the cross - over of the decay at distances @xmath208 of the order of the intrinsic length scale @xmath209 from algebraic ( or logarithmic in case of @xmath98 ) to exponential .    in the class of @xmath34-uniform estimates ,",
    "these decay properties survive as _ pointwise _ in @xmath33 estimates on the level of the discrete green function  @xmath203 itself , but only as _ averaged _ estimates on the level of its discrete gradient  @xmath205 .",
    "more precisely , @xmath205 has to be averaged in @xmath24 on dyadic annuli centered at @xmath210 .",
    "it will be important that the average can be ( at least slightly ) stronger than a _ square _ average ( see @xcite , lemma  2.9 ) .",
    "on the other hand , we do not need the exponential decay : super algebraic decay is sufficient for our purposes .    [",
    "lem : ptwise - green - decay ] let @xmath142 , and @xmath152 be the associated green function . for @xmath176 , we have for all @xmath211 , and all  @xmath212 @xmath213 where the constant in `` @xmath90 '' depends on @xmath214 . for @xmath98",
    ", we have for all @xmath211 @xmath215 where the constant in `` @xmath90 '' depends on @xmath214 .    finally , for the proof of theorem  [ th1 ] , we need to know that also the _ convolution _ of the gradient of the green s function with itself decays at the optimal rate , that is , with the following lemma .",
    "[ b - lem : dyad ] let @xmath216 satisfy the following properties .",
    "_ assumptions on @xmath217 [ estimate of @xmath218 : _ for all @xmath219 and @xmath161 , @xmath220 and for @xmath221 @xmath222 _ assumptions on @xmath223 [ estimate of @xmath224 : _ for @xmath176 , and for all , @xmath225 and for @xmath98 , @xmath226 then we have @xmath227",
    "throughout this section , we let @xmath118 be such that @xmath228 .      in view of ( [ eq : err - syst ] ) , in order to estimate @xmath229 , we need to estimate how close the modified corrector @xmath99 is to the original corrector @xmath6 [ in terms of @xmath230 .",
    "therefore , it is natural to introduce @xmath231 ( the prefactor @xmath232 is such that @xmath233 is properly renormalized in the limit @xmath234 at least for large @xmath0 ) . considering @xmath233 is also convenient since for @xmath98 , the corrector @xmath6 is not known to be stationary ( only its gradient is known to be stationary ) so that working with the modified correctors @xmath99 , which are known to be stationary , avoids technical subtleties .",
    "in fact , we opt for a dyadically discrete version of @xmath233 defined via @xmath235 this discrete version has the technical advantage that we do not have to think about the differentiability of @xmath99 in @xmath22 .",
    "moreover , its dyadic nature is in line with the dyadic decomposition of the @xmath22-axis according to latexmath:[\\[\\label{eq : dyad - taxis }    forced upon us in the case of @xmath98 . in order to get ( [ eq : dyad - taxis ] ) , we used the fact that @xmath237 which is proved in @xcite , proof of theorem  1 , step  8 .",
    "we shall also use that  @xmath233 solves @xmath238      _ step _ 1 .",
    "derivation of @xmath239 although this could be directly inferred from the spectral formula ( [ intro : spectral ] ) for  @xmath180 , we give an elementary argument relying only on the corrector equation .",
    "we recall the following consequence of ( [ eq : app - corr ] ) which is proved in @xcite , proof of theorem  1 , step  8 : @xmath240 for every field @xmath241 that is jointly stationary with @xmath2 and such that @xmath242 . from formally differentiating the definition ( [ eq : def - at ] ) of @xmath180 w.r.t . @xmath22 and using ( [ eq : vf - proba ] ) for @xmath243",
    ", we obtain @xmath244 we claim that the corresponding discrete - in-@xmath22 version reads @xmath245 indeed , by definition of @xmath180 , by expanding the square , by symmetry of @xmath2 , by definition of @xmath233 , and ( [ eq : vf - proba ] ) , we have @xmath246 in the next four steps , we focus on the first term of the r.h.s . of ( [ eq : step2-main ] ) . the second term will be dealt with the same way in step  7 .",
    "_ step _ 2 .",
    "proof of @xmath247 where the sum runs over the edges @xmath25 , and proof of the representation formulas @xmath248 \\frac{\\partial\\psi_{t}(0)}{\\partial a(e)}&=&-\\nabla_i\\psi _ { t}(z)\\nabla_{z_i}g_t(z,0 ) \\label{eq : step4-main-2 } \\nonumber\\\\[-9pt]\\\\[-9pt ] & & { } -\\frac{1}{2}\\int_{{\\mathbb{z}}^d}g_t(0,w)\\bigl(\\xi_i+\\nabla_i\\phi _ { 2t}(z)\\bigr)\\nabla_{z_i}g_{2t}(z , w)\\,dw,\\nonumber\\end{aligned}\\ ] ] where the edge is @xmath249 $ ] .    due to @xcite , lemma  2.6 ,",
    "the functions @xmath250 and @xmath251 are measurable with respect to the coefficients @xmath34 .",
    "hence , ( [ eq : step3-main ] ) is a consequence of the covariance estimate of lemma [ lem : cov ] : since @xmath252 , @xmath253 & = & { \\operatorname{cov } [ \\phi_t;\\psi_{t } ] } .\\end{aligned}\\ ] ] formula ( [ eq : step4-main-1 ] ) is identical to @xcite , lemma  2.4 , ( 2.12 ) . to prove ( [ eq : step4-main-2 ] ) , we first make use of the green representation formula for the solution to ( [ eq : def - psitu ] ) : @xmath254 for all @xmath124 .",
    "since @xmath255 and @xmath256 are continuously differentiable by @xcite , lemma  2.4 , we deduce by formula ( [ eq : fo - psi ] ) that @xmath257 is also continuously differentiable .",
    "using then the formulas @xcite , lemma  2.5 , ( 2.15 ) , and @xcite , lemma  2.4 , ( 2.12 ) , for the derivatives of @xmath152 and @xmath99 with respect to @xmath81 , and the fact that @xmath258 ( see  @xcite , corollary  2.2 ) , we may switch the order of the differentiation and the integration to obtain for all @xmath124 @xmath259 & & \\hphantom{\\frac{\\partial\\psi_{t}(x)}{\\partial a(e ) } = } { } + \\frac{1}{2}\\int_{{\\mathbb{z}}^d}g_t(x , w)\\frac{\\partial \\phi_{2t}(w)}{\\partial a(e)}\\,dw \\nonumber\\\\[-2pt ] & & \\hspace*{7.4pt}\\stackrel{\\mbox{\\fontsize{8.36}{9}\\selectfont\\cite{gloria - otto-09 } } , ( 2.12)\\ \\mathrm{and}\\ ( 2.15)}{=}-\\frac { 1}{2}\\int_{{\\mathbb{z}}^d}\\nabla_{z_i}g_t(x , z)\\nabla_{z_i}g_t(z , w ) \\phi _ { 2t}(w)\\,dw \\\\[-2pt ] & & \\hspace*{46pt } { } -\\frac{1}{2}\\int_{{\\mathbb{z}}^d}g_t(x , w)\\bigl(\\xi_i+\\nabla_i \\phi _ { 2t}(z)\\bigr)\\nabla_{z_i}g_{2t}(z , w)\\,dw \\nonumber\\\\[-2pt ] & & \\hspace*{33.5pt}\\stackrel{\\mbox{\\fontsize{8.36}{9}\\selectfont{(\\ref{eq : step4-main - psi})}}}{= }",
    "-\\nabla _ { z_i}g_t(x , z)\\nabla_i \\psi_{t}(z)\\nonumber \\\\[-2pt ] & & \\hspace*{46pt } { } - \\frac{1}{2}\\int_{{\\mathbb{z}}^d}g_t(x , w)\\bigl(\\xi_i+\\nabla_{i}\\phi_{2t}(z)\\bigr)\\nabla_{z_i } g_{2t}(z , w)\\,dw,\\nonumber\\end{aligned}\\ ] ] which is ( [ eq : step4-main-2 ] ) taking @xmath260 .",
    "_ step _ 3 . in this step",
    ", we shall prove that @xmath261 where @xmath262\\\\[-9pt ] & & \\hphantom{\\int_{{\\mathbb{z}}^d}}{}\\times \\biggl\\langle\\biggl(\\int_{{\\mathbb{z}}^d}g_t(w)\\bigl(1+|\\nabla\\phi _ { 2t}(z)|\\bigr)|\\nabla _ zg_{2t}(z , w)|\\,dw \\biggr)^2 \\biggr\\rangle^{1/2}\\,dz,\\nonumber\\end{aligned}\\ ] ] and @xmath263 , @xmath264\\\\[-8pt ] & & \\hphantom{\\int_{{\\mathbb{z}}^d } } { } \\times\\langle|\\nabla\\psi_{t}(z)|^2|\\nabla_zg_t(z,0)|^2 \\rangle^{1/2}\\,dz,\\nonumber \\\\ \\label{eq : n2-def } \\mathcal{n}_2&:= & \\mu_d(t)\\int_{{\\mathbb{z}}^d } \\bigl\\langle\\bigl(1+|\\nabla\\phi _",
    "t(z)|^2\\bigr)|\\nabla_z g_t(z,0)|^2 \\bigr\\rangle^{1/2 } \\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\hphantom{\\mu_d(t)\\int_{{\\mathbb{z}}^d}}{}\\times\\bigl\\langle\\bigl(1+|\\nabla\\phi_{2t}(z)|^2\\bigr)|\\nabla _ zg_t(z,0)|^2 \\bigr\\rangle ^{1/2}\\,dz\\nonumber\\end{aligned}\\ ] ] with @xmath265 the term @xmath266 is a linear error : it is of the same type as for the analysis in the limit of vanishing ellipticity contrast ( see @xcite , the appendix ) . on the contrary , the term @xmath267 is nonlinear and does not appear in the limit of vanishing ellipticity contrast . as we shall prove ,",
    "it is of lower order .",
    "the terms @xmath266 and @xmath268 in estimate ( [ eq : step5-main ] ) would be direct consequences of ( [ eq : step3-main ] ) , and ( [ eq : step4-main-1 ] ) and ( [ eq : step4-main-2 ] ) , disregarding the suprema in @xmath81 in ( [ eq : step3-main ] ) . taking the suprema in @xmath81 into account",
    "actually brings the second nonlinear term @xmath269 , which turns out to be of lower order than @xmath268 .    according to @xcite , lemma  2.4 , ( 2.13 )",
    ", we have for ( [ eq : step4-main-1 ] ) @xmath270 it remains to deal with ( [ eq : step4-main-2 ] ) .",
    "using the pointwise decay of @xmath152 in lemma  [ lem : ptwise - green - decay ] combined with the susceptibility estimates @xcite , lemma  2.4 , ( 2.14 ) , and @xcite , lemma  2.5 , ( 2.16 ) , of @xmath66 and @xmath271 w.r.t .",
    "@xmath81 , we obtain @xmath272\\\\[-8pt ] & & \\qquad \\lesssim \\int_{{\\mathbb{z}}^d}g_t(w)\\bigl(1+|\\nabla_i\\phi_{2t}(z)|\\bigr)|\\nabla _ { z}g_{2t}(z , w)|\\,dw,\\nonumber\\end{aligned}\\ ] ] which together with ( [ eq : sup-1 ] ) gives the linear term @xmath273 .    to treat the first term of the r.h.s . of ( [ eq : step4-main-2 ] ) , we need to deal with the supremum of @xmath274 over @xmath81 .",
    "we appeal to ( [ eq : diff - psit ] ) that we rewrite in the form @xmath275 where @xmath276 and @xmath277 .",
    "hence , @xmath278\\\\[-8pt ] & & { } -\\frac{1}{2 } \\bigl(\\xi_i+\\nabla_i \\phi_{2t}(z)\\bigr ) \\int _ { { \\mathbb{z}}^d}g_t(e , w ) g_{2t}(e , w)\\ , dw,\\nonumber\\end{aligned}\\ ] ] where @xmath279 . on the one hand , the uniform bound @xcite , corollary  2.3 , on @xmath271 yields @xmath280 . on the other hand , as we shall argue , the integrability of  @xmath271 and @xmath281 from @xcite , lemma  2.9 ( combined with the uniform bound  @xcite , corollary  2.3 , on gradients ) implies @xmath282 hence , if we regard ( [ eq : step5-estimdpsi ] ) as an ordinary differential equation for @xmath283 in the variable @xmath81 , we obtain @xmath284 since @xmath81 lies in a bounded domain @xmath38 $ ] , and @xmath285 according to @xcite , lemma 2.4 , ( 2.14 ) , with @xmath286 instead of @xmath22 . note that ( [ eq : sup-1 ] ) , ( [ eq : sup - psi ] ) and @xmath287 give the nonlinear terms @xmath268 and @xmath288 .",
    "we now give the argument for ( [ eq : th1-step5-grad2 ] ) .",
    "we first use the cauchy ",
    "schwarz inequality @xmath289 and then make a decomposition of @xmath56 into the ball of radius @xmath221 , and dyadic annuli @xmath290 for @xmath291 . on the ball of radius  @xmath115 , we use the uniform estimate of @xcite , corollary 2.3 , on @xmath271 , whereas on the dyadic annuli we appeal to the decay estimate in @xcite , lemma 2.9 , for the gradient of the green function , which requires @xmath115 to be sufficiently large although still of order @xmath135 . both terms in the r.h.s .",
    "scale the same way and we only treat the first one : @xmath292 using @xcite , corollary 2.3 , and @xcite , lemma 2.9 , for @xmath293 , respectively .",
    "this concludes step 3 .",
    "_ step _ 4 .",
    "suboptimal estimate of the nonlinear term @xmath267 : @xmath294 \\mathcal{n}_2&\\lesssim & \\mu_d(t)^q,\\label{eq : step6-main2}\\end{aligned}\\ ] ] where @xmath88 is a generic exponent which only depends on @xmath89 .",
    "we first deal with @xmath268 , and begin with the second factor of the r.h.s . of ( [ eq : n - def ] ) .",
    "the pointwise estimate ( [ eq : def_gt_d>2 ] ) of lemma  [ lem : ptwise - green - decay ] for @xmath176 on the green function gives the _ suboptimal pointwise _ estimate on the gradient of the green function",
    "@xmath295 this estimate coincides for @xmath98 with the uniform bound of @xcite , corollary  2.3 .",
    "the coercivity of @xmath2 thus yields @xmath296 & & \\qquad \\lesssim(1+|z|)^{2-d}\\langle\\nabla\\psi_{t}(z)\\cdot a(z)\\nabla \\psi_{t}(z ) \\rangle^{1/2}\\\\[-2pt ] & & \\qquad = ( 1+|z|)^{2-d}\\langle\\nabla\\psi_{t}\\cdot a\\nabla\\psi_{t } \\rangle^{1/2}\\end{aligned}\\ ] ] by joint stationarity of @xmath297 and @xmath2 .",
    "hence , ( [ eq : n - def ] ) turns into @xmath298 we then let @xmath299 be a meyers exponent as in @xcite , lemma  2.9 and use hlder s inequality in probability with exponents @xmath300 , the stationarity of @xmath66 , the fact that the gradient of @xmath99 is estimated by @xmath99 as in ( [ eq : nabla - par - g ] ) , and the bounds on the stochastic moments of @xmath99 in @xcite , proposition  1,=-1 @xmath301 & & { } \\times \\int_{{\\mathbb{z}}^d}(1+|z|)^{2-d } \\bigl\\langle1+|\\nabla\\phi_t(z)|^{2p/(p-2 ) } \\bigr\\rangle^{(p-2)/(2p)}\\langle    & = & \\langle\\nabla\\psi_{t}\\cdot a\\nabla\\psi_{t } \\rangle ^{1/2}\\bigl\\langle1+|\\nabla\\phi_t|^{2p/(p-2 ) } \\bigr\\rangle^{(p-2)/(2p ) } \\nonumber\\\\[-2pt ] & & { } \\times \\int_{{\\mathbb{z}}^d}(1+|z|)^{2-d } \\langle|\\nabla g_t(z,0)|^p \\rangle^{1/p}\\,dz \\\\[-2pt ] & \\lesssim&\\langle\\nabla\\psi_{t}\\cdot a\\nabla\\psi_{t } \\rangle ^{1/2}\\bigl\\langle1+|\\phi_t|^{2p/(p-2 ) } \\bigr\\rangle^{(p-2)/(2p ) } \\nonumber\\\\[-2pt ] & & { } \\times \\int_{{\\mathbb{z}}^d}(1+|z|)^{2-d } \\langle|\\nabla g_t(z,0)|^p \\rangle^{1/p}\\,dz \\nonumber\\\\[-2pt ] & \\lesssim & \\mu_d(t)^q\\langle\\nabla\\psi_{t}\\cdot a\\nabla\\psi _ { t }",
    "\\rangle^{1/2 } \\int_{{\\mathbb{z}}^d}(1+|z|)^{2-d } \\langle|\\nabla g_t(z,0)|^p \\rangle^{1/p}\\,dz,\\nonumber\\end{aligned}\\]]=0 for some generic @xmath88 depending only on @xmath89 .",
    "hlder s inequality with exponents @xmath302 in @xmath56 , combined with the same dyadic decomposition of @xmath56 as for the proof of ( [ eq : th1-step5-grad2 ] ) ( and the uniform bound on @xmath271 from @xcite , corollary  2.3 ) yields @xmath303 using the optimal decay of @xmath271 on dyadic annuli in @xmath304 norm from @xcite , lemma  2.9 , with @xmath305 , this turns into @xmath306 recalling that @xmath221 , this implies @xmath307 combined with ( [ eq : modif - n ] ) it proves ( [ eq : step6-main1 ] ) .",
    "we now turn to @xmath288 .",
    "proceeding as above to deal with the terms @xmath66 and  @xmath308 in @xmath288 , we obtain as desired @xmath309 using the same dyadic decomposition of @xmath56 as for the proof of ( [ eq : th1-step5-grad2 ] ) together with the higher integrability of gradients of @xcite , lemma  2.9 and @xcite , corollary  2.3 .",
    "_ step _ 5 . estimate of the linear term @xmath266 : @xmath310 we first treat the second factor of ( [ eq : l - def ] ) .",
    "we proceed as in step  4 to deal with the expectation of the corrector term , and let @xmath299 be a meyers exponent as in @xcite , lemma  2.9 .",
    "we obtain by hlder s inequality in probability with exponents @xmath311 and the bounds on the stochastic moments of @xmath99 from @xcite , proposition  1 : @xmath312 we thus have latexmath:[\\ ] ] where @xmath406 is characterized by @xmath407 .    for the integral over the r.h.s .",
    "of ( [ eq : decompzd-1 ] ) , we appeal to ( [ eq : lemma-2.10 - 1 ] ) and to the definitions ( [ b - eq : def_gt_d>2 ] ) and ( [ b - eq : def_gt_d=2 ] ) of @xmath403 for @xmath408 : @xmath409 for the integral over ( [ eq : decompzd-3 ] ) , we use this time ( [ eq : lemma-2.10 - 2 ] ) for @xmath392 and the definitions ( [ b - eq : def_gt_d>2 ] ) and ( [ b - eq : def_gt_d=2 ] ) of @xmath403 for @xmath410 , so that for all @xmath291 we have @xmath411 summing this inequality on @xmath291 then yields the estimate @xmath412 we now deal with the integral over the last part ( [ eq : decompzd-2 ] ) of @xmath56 . to this aim ,",
    "we combine ( [ eq : lemma-2.10 - 2 ] ) for @xmath413 with the definitions ( [ b - eq : def_gt_d>2 ] ) and ( [ b - eq : def_gt_d=2 ] ) of  @xmath403 for @xmath414 . in particular , for all @xmath415 , we have @xmath416 summing this inequality over @xmath415 and using that @xmath417 then yield @xmath418 the combination of ( [ eq : lem - conv-1 ] ) , ( [ eq : lem - conv-2 ] ) and ( [ eq : lem - conv-3 ] ) finally proves ( [ b - eq : dyad ] ) ."
  ],
  "abstract_text": [
    "<S> this paper is the companion article to [ _ ann . </S>",
    "<S> probab . _ * 39 * ( 2011 ) 779856 ] . </S>",
    "<S> we consider a discrete elliptic equation on the @xmath0-dimensional lattice @xmath1 with random coefficients @xmath2 of the simplest type : they are identically distributed and independent from edge to edge . on scales </S>",
    "<S> large w.r.t . </S>",
    "<S> the lattice spacing ( i.e. , unity ) , the solution operator is known to behave like the solution operator of a ( continuous ) elliptic equation with constant deterministic coefficients . </S>",
    "<S> this symmetric `` homogenized '' matrix @xmath3 is characterized by @xmath4 for any direction @xmath5 , where the random field @xmath6 ( the `` corrector '' ) is the unique solution of @xmath7 in @xmath1 such that @xmath8 , @xmath9 is stationary and @xmath10 , @xmath11 denoting the ensemble average ( or expectation ) .    in order to approximate the homogenized coefficients @xmath12 , the corrector problem is usually solved in a box @xmath13 of size @xmath14 with periodic boundary conditions , and the space averaged energy on @xmath15 defines an approximation @xmath16 of @xmath17 . although the statistics is modified ( independence is replaced by periodic correlations ) and the ensemble average is replaced by a space average , the approximation @xmath16 converges almost surely to @xmath17 as @xmath18 . in this paper </S>",
    "<S> , we give estimates on both errors . </S>",
    "<S> to be more precise , we do not consider periodic boundary conditions on a box of size @xmath14 , but replace the elliptic operator by @xmath19 with ( typically ) @xmath20 , as standard in the homogenization literature . </S>",
    "<S> we then replace the ensemble average by a space average on @xmath15 , and estimate the overall error on the homogenized coefficients in terms of @xmath21 and @xmath22 .    and    .    </S>"
  ]
}