{
  "article_text": [
    "tree source coding with a fidelity criterion has been studied since the late sixties and the early seventies of the previous century , see , e.g. , ( * ? ? ? * subsection 6.2.4),@xcite,@xcite,@xcite,@xcite,@xcite .",
    "the first results , that were obtained by jelinek and anderson @xcite , were for tree coding of binary sources with the hamming distortion measure , and by dick , berger and jelinek @xcite for gaussian sources and the squared error distortion measure .",
    "davis and hellman @xcite proved a tree coding theorem for a general memoryless source and a general fidelity criterion .",
    "in particular , they pointed out that in an earlier paper by jelinek @xcite , the proof of the coding theorem was valid only for symmetric sources , and so , by modifying the branching process associated with the tree code , they were able to relax the symmetry condition of the tree coding theorem . in this context , it should be pointed out that gallager @xcite also made a symmetry assumption in the same spirit .",
    "the main message in this short paper is , first of all , in the observation that the tree source coding problem is very intimately related to an important model in statistical physics of disordered systems , namely , the directed polymer in a random medium ( dprm ) , cf .",
    "e.g. , @xcite,@xcite,@xcite,@xcite,@xcite,@xcite,@xcite,@xcite,@xcite and references therein . loosely speaking , in the dprm , each configuration of the underlying physical system corresponds to a walk along consecutive bonds of a certain lattice , or a tree , where each such bond is assigned with an independent random variable ( energy ) , and where the total energy ( which is analogous to the distortion of the tree code ) of this walk is the sum of energies along the bonds visited . for a given realization of these random energy variables ,",
    "the probability of each walk is given by the boltzmann distribution , namely , it is proportional to an exponential function of the negative total energy . the main challenge , as usual in equilibrium statistical physics , is to characterize the asymptotic normalized free energy of a typical realization of the system . for the case where the walks are defined on a tree ( from the root to one of the leaves ) , this problem has a closed ",
    "form solution .",
    "this relationship between tree codes and the dprm is interesting on its own right .",
    "it turns out to be so strong , that the various analysis techinques and the results concerning the dprm can readily be harnessed to the ensemble peformance analysis of tree codes .",
    "in particular , the distortion achieved by the best codeword in the tree codebook is identified with the free energy of the dprm when the system is frozen ( taken to zero temperature ) .",
    "this observation , does not merely provide an alternative proof of the tree coding theorem , but moreover , it enables to show that , at least under a certain symmetry assumption concerning the source and the distortion function , the distortion ",
    "rate function is achieved eventually almost surely ( with respect to the randomness of the code ) for every individual source sequence .",
    "this is different from ( and stronger than ) the previous findings , mentioned in the first paragraph above , which were coding theorems concerning the average distortion .",
    "the outline of this work is as follows : in section 2 , we establish our notation conventions and give a brief background in statistical mechanics in general and on the dprm in particular . in section 3 ,",
    "we show how the solution to the dprm model can be used to prove that the tree code ensemble achieves distortion  rate function almost surely for every input .",
    "finally , in section 4 , we provide a short summary of this paper .",
    "throughout this paper , scalar random variables ( rv s ) will be denoted by capital letters , like @xmath0 and @xmath1 , their sample values will be denoted by the respective lower case letters , and their alphabets will be denoted by the respective calligraphic letters .",
    "a similar convention will apply to random vectors and their sample values , which will be denoted with the same symbols in the boldface font .",
    "thus , for example , @xmath2 will denote a random @xmath3-vector @xmath4 , and @xmath5 is a specific vector value in @xmath6 , the @xmath3-th cartesian power of @xmath7 .",
    "sources and other probability measures that underly sequence generation will be denoted generically by the letters @xmath8 and @xmath9 , and specific letter probabilities will be denoted by the corresponding lower case letters , e.g. , @xmath10 , @xmath11 , etc .",
    "the expectation operator will be denoted by @xmath12 .",
    "information theoretic quantities like entropies and mutual informations will be denoted following the usual conventions of the information theory literature .",
    "consider a physical system with @xmath3 particles , which can be in a variety of microscopic states ( ` microstates ' ) , defined by combinations of physical quantities associated with these particles , e.g. , positions , momenta , angular momenta , spins , etc .",
    ", of all @xmath3 particles . for each such microstate of the system , which we shall designate by a vector @xmath13",
    ", there is an associated energy , given by an _ hamiltonian _",
    "( energy function ) , @xmath14 .",
    "for example , if @xmath15 , where @xmath16 is the momentum vector of particle number @xmath17 and @xmath18 is its position vector , then classically , @xmath19 $ ] , where @xmath20 is the mass of each particle , @xmath21 is its height  one of the coordinates of @xmath18 , and @xmath22 is the gravitation constant .",
    "one of the most fundamental results in statistical physics ( based on the law of energy conservation and the basic postulate that all microstates of the same energy level are equiprobable ) is that when the system is in thermal equilibrium with its environment , the probability of finding the system in a microstate @xmath23 is given by the _ boltzmann ",
    "distribution @xmath24 where @xmath25 , @xmath26 being boltzmann s contant and @xmath27 being temperature , and @xmath28 is the normalization constant , called the _ partition function _ , which is given by @xmath29 or @xmath30 depending on whether @xmath23 is discrete or continuous .",
    "the role of the partition function is by far deeper than just being a normalization factor , as it is actually the key quantity from which many macroscopic physical quantities can be derived , for example , the free energy is @xmath31 , the average internal energy ( i.e. , the expectation of @xmath14 where @xmath23 drawn is according ( [ bd ] ) ) is given by @xmath32 , the heat capacity is obtained from the second derivative , etc .",
    "one of the ways to obtain eq .",
    "( [ bd ] ) , is as the maximum entropy distribution under an average energy constraint ( owing to the second law of thermodynamics ) , where @xmath33 plays the role of a lagrange multiplier that controls the average energy .    quite often",
    ", real  world physical systems of many particles , such as magnetic materials and solid  state devices , are subjected to effects of impurity ( e.g. , defects ) that may appear as amorphic structures and disorder . to model such disorder , it is customary to let the hamiltonian , @xmath14 , depend also on certain random parameters and to examine the behavior of systems pertaining to typical realizations of these random parameters .",
    "there are many models of this kind in the physics literature .",
    "one of them is the dprm , which is defined on a certain graph , such as a hypercubic lattice , or a tree .",
    "we henceforth focus on the latter and describe it more formally than in the introduction .",
    "consider a _ cayley tree _ , namely , a full balanced tree with branching ratio @xmath34 and depth @xmath3 ( cf .  fig .  [ tree ] , where @xmath35 and @xmath36 ) .",
    "let us index the branches by a pair of integers @xmath37 , where @xmath38 describes the generation ( with @xmath39 corresponding to the @xmath34 branches that emanate from the root ) , and @xmath40 enumerates the branches of the @xmath17th generation , say , from left to right ( see fig .",
    "[ tree ] ) . for each branch",
    "@xmath41 , @xmath38 , we randomly draw an independent random variable @xmath42 according to a fixed probability function @xmath43 ( i.e. , a probability mass function in the discrete case , or probability density function in the continuous case ) .    a _ walk _",
    "@xmath44 , from the root of the tree to one of its leaves , is described by a finite sequence @xmath45 , where @xmath46 and @xmath47 , @xmath48 .",
    ", the number @xmath49 alone dictates the entire walk . ] for a given realization of the rv s @xmath50 , we define the hamiltonian associated with @xmath44 as @xmath51 , and then the partition function as : @xmath52 of course , since @xmath53 are rv s , then so is @xmath54 .",
    "the primary question addressed by physicists , in this context , concerns the ( typical ) behavior of the rv @xmath55 for @xmath3 large , which is ( up to the minus sign ) , exactly the normalized free energy per step .",
    "it turns out ( as proved e.g. , in @xcite,@xcite ) that @xmath56 has a _ self  averaging _ property , in the terminology of physicists , in other words , the sequence of random variables @xmath57 converges in probability ( and in fact , almost surely , as is shown in @xcite ) to a deterministic constant @xmath58 , which is given by @xmath59 with the function @xmath60 being defined as @xmath61}{\\beta}\\ ] ] where the expectation , which is assumed finite , is taken w.r.t .",
    "@xmath43 , and where @xmath62 is the value of @xmath33 at which @xmath63 is minimum , or equivalently , the solution to the equation @xmath64 , where @xmath65 is the derivative of @xmath60 .    as can be seen",
    ", @xmath66 is a point at which the asymptotic normalized free energy per step , @xmath58 , changes its behavior : although @xmath58 and its first derivative are continuous functions for all @xmath33 , the second derivative is discontinuous at @xmath66 . in the terminology of physicists ,",
    "this is referred to as a _",
    "second order phase transition_. observe that while one might expect that the sequence @xmath56 would converge to the same limit as @xmath67 , i.e. , the so called _ quenched average _ , the high temperature phase result ( [ physresult ] ) corresponds to @xmath68 $ ] , which is called the _",
    "annealed average_. this means that jensen s inequality is essentially tight at this range of @xmath33 .",
    "however , these two averages depart from each other at the low temperature phase , @xmath69 .",
    "as can be observed , in this phase , the asymptotic normalized free energy no longer depends on @xmath33 , and it is referred to as the _ glassy phase _ or the _ frozen phase _ , which is characterized by zero thermodynamical entropy , in other words , the partition function is dominated by a sub  exponential number of configurations possessing the ground  state energy ( cf .",
    "e.g. , ( * ? ? ?",
    "* chap .  5 ) ) . for reasons that will become apparent",
    "shortly , this frozen phase is the relevant phase for our source coding problem .",
    "the asymptotic free energy formula ( [ physresult ] ) has been proved in the physics literature at least in four different ways : the first @xcite is based on martingales , the second is based on non  integer moments of the partition function @xcite,@xcite , the third is based on a recursion of a certain generating function of the partition function as well as on traveling waves @xcite,@xcite , and the fourth method is the so  called _ replica method _ @xcite , which , although not rigorous , is very useful in statistical mechanics .",
    "we now turn to our lossy source coding problem , where some of the notation that will be used will be deliberately identical to that of subsection [ phys ] .",
    "consider a discrete memoryless source ( dms ) @xmath8 that generates symbols @xmath70 from a finite alphabet @xmath7 .",
    "let @xmath71 denote a finite reproduction alphabet and let @xmath72 be a given distortion function .",
    "consider next an ensemble of tree codes for encoding source @xmath3tuples , @xmath13 , which is defined as follows : given a coding rate @xmath73 ( in nats / source  symbol ) , which is assumed to be the natural logarithm of some positive integer @xmath34 , and given a probability distribution on the reproduction alphabet , @xmath74 , let us draw @xmath75 independent copies of @xmath1 under @xmath9 , and denote them by @xmath76 .",
    "we shall refer to the randomly chosen set , @xmath77 , as our ` codebook ' for the first source symbol , @xmath78 .",
    "next , for each @xmath79 , we randomly select another such codebook under @xmath9 , @xmath80 , for the second symbol , @xmath81 . then , for each @xmath79 and @xmath82 , we again draw under @xmath9 yet another codebook @xmath83 , for @xmath84 , and so on .",
    "in general , for each @xmath85 , we randomly draw @xmath86 codebooks under @xmath9 , which are indexed by @xmath87 , @xmath88 , @xmath89 .",
    "once the above described random code selection process is complete , the resulting set of codebooks @xmath90 is revealed to both the encoder and decoder , and the encoding  decoding system works as follows :    * _ encoding : _ given a source @xmath3tuple @xmath91 , find a vector of indices @xmath92 that minimizes the overall distortion @xmath93 .",
    "represent each component @xmath94 ( based on @xmath95 ) by @xmath96 nats ( that is , @xmath97 bits ) , thus a total of @xmath98 nats . *",
    "_ decoding : _ at each time @xmath99 ( @xmath100 ) , after having decoded @xmath101 , output the reproduction symbol @xmath102 .",
    "a few comments are in order at this point : first , as we see , the codebook generation process is branching hierarchically by a factor of @xmath34 at each step , hence it is convenient to think of the code as having the structure of a cayley tree , as in subsection [ phys ] .",
    "the encoder seeks the best walk on that tree in the sense of minimum distortion .",
    "note also that the process of converting the optimum walk @xmath103 into a compressed bitstream is extremely simple : we just convert each @xmath104 into its binary representation using @xmath97 bits without any attempt at compression .",
    "in other words , the entropy coding part is trivial in the sense that it uses neither the memory that may be present in the sequence @xmath92 , nor the possible skewdness of the distributions of these symbols .",
    "finally , the decoding process is a purely sequential delayless process : at time @xmath99 , the decoder outputs the @xmath99-th reproduction symbol .",
    "this is in contrast to the decoder of a general block code , which has to wait until the entire bit string of length @xmath98 has been received before it can start to decode .",
    "thus , at least the decoding delay is saved this way .",
    "there is also a slight reduction in the search complexity at the encoder , due to the tree structure , but not a dramatic one .    in order to analyze the rate",
    " distortion performance of this ensemble of codes , using the results of subsection [ phys ] , we now make the following assumption :    _ the random coding distribution @xmath9 is such that the distribtion of the rv @xmath105 is the same for all @xmath106 .",
    "_    it turns out that this assumption is fulfilled quite often ",
    "it is the case whenever the random coding distribution together with distortion function exhibit a sufficiently high degree of symmetry .",
    "for example , if @xmath9 is the uniform distribution over @xmath71 and the rows of the distortion matrix @xmath107 are permutations of each other , which is in turn the case , for example , when @xmath108 is a group and @xmath109 is a difference distortion function w.r.t .  the group difference operation .",
    "somewhat more generally , this assumption still holds when the different rows of the distortion matrix are formed by permutations of each other subject to the following rule : @xmath110 can be swapped with @xmath111 provided that @xmath112 .",
    "it should be pointed out that if the optimum random coding distribution @xmath113 , namely , the one corresponding to the output of the test channel that achieves the rate  distortion function of @xmath0 , happens to satisfy the above symmetry assumption , then as we show below ( using a technique different from those of the earlier papers on tree coding ) , the rate ",
    "distortion performance of the above descrirbed code ensemble achieves the rate  distortion function .",
    "moreover , this will turn out to be the case , not only in expectation , but also with probability one .",
    "we now turn to our analysis which makes heavy use of the results of subsection [ phys ] . for",
    "a given @xmath23 and a given realization of the set of codebooks , define the partition function in analogy to that of the dprm : @xmath114 where the summation extends over all @xmath115 possible walks , @xmath116 , along the cayley tree , as defined in subsection [ phys ] . clearly , considering our symmetry assumption",
    ", this falls exactly under the umbrella of the dprm , with the distortions @xmath117 playing the role of the branch energies @xmath118 .",
    "therefore , @xmath119 converges almost surely , as @xmath3 grows without bound , to @xmath58 , now defined as @xmath120 where @xmath121}{\\beta}\\nonumber\\\\ & = & \\frac{\\ln[e^r\\cdot{\\mbox{\\boldmath $ e$}}\\{e^{-\\beta\\rho(x , y)}\\}]}{\\beta}\\nonumber\\\\ & = & \\frac{r+\\ln[{\\mbox{\\boldmath $ e$}}\\{e^{-\\beta\\rho(x , y)}\\}]}{\\beta},\\end{aligned}\\ ] ] where @xmath122 is an arbitrary member of @xmath7 , which is immaterial by the symmetry assumption .",
    "thus , for every @xmath123 , the distortion is given by @xmath124\\nonumber\\\\ & = & \\limsup_{n\\to\\infty}\\limsup_{\\ell\\to\\infty}\\left[-\\frac{\\ln z_n(\\beta_\\ell)}{n\\beta_\\ell}\\right]\\nonumber\\\\ & \\le&\\limsup_{\\ell\\to\\infty}\\limsup_{n\\to\\infty}\\left[-\\frac{\\ln z_n(\\beta_\\ell)}{n\\beta_\\ell}\\right]\\nonumber\\\\ & { \\stackrel{\\mbox{a.s . } } { = } } & -\\liminf_{\\ell\\to\\infty}f(\\beta_\\ell)\\\\ & = & -\\phi(\\beta_c)\\nonumber\\\\ & = & \\max_{\\beta\\ge 0}\\left[-\\frac{\\ln[{\\mbox{\\boldmath $ e$}}\\{e^{-\\beta\\rho(x , y)}\\}]+r}{\\beta}\\right]\\nonumber\\\\ & { \\stackrel{\\delta } { = } } & d_0(r),\\end{aligned}\\ ] ] where : ( i ) @xmath125 is an arbitrary sequence tending to infinity , ( ii ) the almost  sure equality is due to ( * ? ? ?",
    "* theorem 1 ) , and ( iii ) the inequality at the third line is justified by the following chain : @xmath126&\\le & \\limsup_{n\\to\\infty}\\limsup_{\\ell\\to\\infty}\\left[-\\frac{\\ln\\exp\\{-\\beta_\\ell \\sum_{t=1}^n\\rho(x_t , y_{j_1^*,\\ldots , j_t^*})\\}}{\\beta_\\ell n}\\right]\\nonumber\\\\ & = & \\limsup_{n\\to\\infty}\\frac{1}{n } \\sum_{t=1}^n\\rho(x_t , y_{j_1^*,\\ldots , j_t^*})\\nonumber\\\\ & = & \\limsup_{\\ell\\to\\infty } \\limsup_{n\\to\\infty}\\frac{1}{n } \\sum_{t=1}^n\\rho(x_t , y_{j_1^*,\\ldots ,",
    "j_t^*})\\nonumber\\\\ & = & \\limsup_{\\ell\\to\\infty } \\limsup_{n\\to\\infty}\\left[-\\frac{\\ln\\exp\\{-\\beta_\\ell \\sum_{t=1}^n\\rho(x_t , y_{j_1^*,\\ldots , j_t^*})\\}}{\\beta_\\ell n}\\right]\\nonumber\\\\ & \\le&\\limsup_{\\ell\\to\\infty } \\limsup_{n\\to\\infty}\\left[-\\frac{\\ln[d^{-n}\\sum_{{\\mbox{\\boldmath $ w$}}}\\exp\\{-\\beta_\\ell \\sum_{t=1}^n\\rho(x_t , y_{j_1,\\ldots , j_t})\\}}{\\beta_\\ell n}\\right]\\nonumber\\\\ & = & \\limsup_{\\ell\\to\\infty}\\left\\ { \\limsup_{n\\to\\infty}\\left[-\\frac{\\ln z_n(\\beta_\\ell ) } { \\beta_\\ell n}\\right]+\\frac{\\ln d}{\\beta_\\ell}\\right\\}\\nonumber\\\\ & = & \\limsup_{\\ell\\to\\infty } \\limsup_{n\\to\\infty}\\left[-\\frac{\\ln z_n(\\beta_\\ell ) } { \\beta_\\ell n}\\right]\\end{aligned}\\ ] ] we have shown then that the almost  sure distortion performance is uniformly given by @xmath127 for every individual source sequence @xmath128 .",
    "now , let us suppose that @xmath9 is chosen to be the output distribution @xmath113 induced by the source @xmath8 and the test channel @xmath129 that achieves the rate  distortion function , and that the symmetry assumption continues to hold for @xmath130 . then",
    ", we claim that @xmath127 , defined with @xmath131 , coincides with the distortion  rate function of the source , @xmath132 .    to see why this is true , recall that the rate  distortion function @xmath133 has the following representation ( see , e.g. , ( * ? ? ?",
    "* , corollary 4.2.3),@xcite,@xcite ) : @xmath134\\right\\}\\ ] ] which , due to convexity in @xmath33 and concavity in @xmath9 , is equaivalent to @xmath135\\right\\}\\nonumber\\\\ & = & -\\min_{\\beta\\ge 0}\\left\\{\\beta d+\\sum_{x\\in{{\\cal x}}}p(x)\\ln\\left[\\sum_{y\\in{{\\cal y}}}q^*(y)e^{-\\beta\\rho(x , y)}\\right]\\right\\},\\end{aligned}\\ ] ] and which , under the symmetry assumption , tells us that for every point @xmath136 on the rate  distortion curve , we have : @xmath137\\right\\}.\\ ] ] let @xmath138 achieve this minimum , i.e. , @xmath139,\\ ] ] or , equivalently , @xmath140+r}{\\beta^*}\\ ] ] thus , clearly , @xmath141+r}{\\beta}\\right\\}=d_0(r),\\ ] ] and so , it remains to show also the converse inequality , @xmath142 . to this end , observe that eq .",
    "( [ base ] ) implies that for every point @xmath136 on the rate ",
    "distortion function : @xmath143,\\ ] ] holds for all @xmath144 ( with equality for @xmath145 ) .",
    "equivalently , for all @xmath144 : @xmath146+r}{\\beta},\\ ] ] and so , @xmath147+r}{\\beta}\\right\\}=d_0(r),\\ ] ] thus proving that @xmath148 .",
    "in this short paper , we tried to convey the following messages : ( i ) there is an intimate relationship between tree coding and the statistical physics of the dprm , which we believe , is interesting , first of all , on its own right .",
    "( ii ) the statistical mechanical approach provides an alternative way to prove the tree coding theorem .",
    "( iii ) existing results concerning the dprm are harnessed right away to provide almost  sure convergence to the distortion ",
    "rate function of the source , thus strenghening the existing coding theorem , at least under a certain symmetry condition .",
    "it is speculated that the various statistical mechanical techniques that were exercised in the dprm model ( cf .",
    "last paragraph of subsection [ phys ] ) and otherwise may shed more light on ensemble performance analysis on this and other information  theoretic settings of theoretical and practical interest .",
    "this research direction is currently pursued further .",
    "m.  r.  evans and b.  derrida , `` improved bounds for the transition temperature of directed polymers in a finite  dimensional random medium , '' _ journal of statistical physics _",
    "69 , nos .",
    "1/2 , pp .  427437 , 1992 .",
    "n.  merhav , `` an identity of chernoff bounds with an interpretation in statistical physics and applications in information theory , '' _ ieee trans .",
    "theory _ , vol .",
    "54 , no .  8 , pp.37103721 , august 2008 .        a.  procacci , b.  n.  b.  de lima , and b.  scoppola , `` a remark on high temperature polymer expansion for lattice systems with infinite range pair interactions , '' _ lett .  in math .",
    "_ , vol .  45 , pp .",
    "303322 , 1998 ."
  ],
  "abstract_text": [
    "<S> using well  known results from statistical physics , concerning the almost  sure behavior of the free energy of directed polymers in a random medium , we prove that random tree codes achieve the distortion  </S>",
    "<S> rate function almost surely under a certain symmetry condition .    </S>",
    "<S> * index terms : * directed polymer , cayley tree , free energy , partition function , tree coding , rate  distortion theory , delay .    </S>",
    "<S> department of electrical engineering + technion - israel institute of technology + haifa 32000 , israel + merhav@ee.technion.ac.il + </S>"
  ]
}