{
  "article_text": [
    "in this paper we introduce retypd , a machine - code type - inference tool that finds * re*gular * ty*pes using * p*ush*d*own systems .",
    "retypd includes several novel features targeted at improved types for reverse engineering , decompilation , and high - level program analyses .",
    "these features include :    * inference of most - general type schemes ( ) * inference of recursive structure types ( ) * sound analysis of pointer subtyping ( ) * tracking of customizable , high - level information such as purposes and typedef names ( ) * inference of type qualifiers such as ` const ` ( ) * no dependence on high - quality points - to data ( ) * more accurate recovery of source - level types ( )    retypd continues in the tradition of secondwrite @xcite and tie @xcite by introducing a principled static type - inference algorithm applicable to stripped binaries .",
    "diverging from previous work on machine - code type reconstruction , we use a rich type system that supports polymorphism , mutable references , and recursive types . the principled type - inference phase is followed by a second phase that uses heuristics to `` downgrade '' the inferred types to human - readable c types before display . by factoring type inference into two phases",
    ", we can sequester unsound heuristics and quirks of the c type systems from the sound core of the type - inference engine .",
    "this adds a degree of freedom to the design space so that we may leverage a relatively complex type system during type analysis , yet still emit familiar c types for the benefit of the reverse engineer .",
    "retypd operates on an intermediate representation ( ir ) recovered by automatically disassembling a binary using grammatech s static analysis tool codesurfer for binaries @xcite . by generating type constraints from a tsl - based abstract interpreter @xcite",
    ", retypd can operate uniformly on binaries for any platform supported by codesurfer , including x86 , x86 - 64 , and arm .    during the development of retypd",
    ", we carried out an extensive investigation of common machine - code idioms in compiled c and c++ code that create challenges for existing type - inference methods .",
    "for each challenging case , we identified requirements for any type system that could correctly type the idiomatic code .",
    "the results of this investigation appear in .",
    "the type system used by retypd was specifically designed to satisfy these requirements .",
    "these common idioms pushed us into a far richer type system than we had first expected , including features like recursively constrained type schemes that have not previously been applied to machine - code type inference .",
    "due to space limitations , details of the proofs and algorithms appear in the appendices , which are available in the online version of this paper at ` arxiv:1603.05495 ` @xcite .",
    "scripts and data sets used for evaluation also appear there .",
    "there are many challenges to carrying out type inference on machine code , and many common idioms that lead to sophisticated demands on the feature set of a type system . in this section ,",
    "we describe several of the challenges seen during the development of retypd that led to our particular combination of type - system features .",
    "since type erasure typically happens early in the compilation process , many compiler optimizations may take well - typed machine code and produce functionally equivalent but ill - typed results .",
    "we found that there were three common optimization techniques that required special care : the use of a variable as a syntactic constant , early returns along error paths , and the re - use of stack slots .    _ semi - syntactic constants _ : suppose a function with signature ` void f(int x , char * y ) ` is invoked as ` f(0 , null ) ` .",
    "this will usually be compiled to x86 machine code similar to    xor eax , eax push eax ; y : = null push eax ; x : = 0 call f    this represents a code - size optimization , since ` push eax ` can be encoded in one byte instead of the five bytes needed to push an immediate value ( 0 )",
    ". we must be careful that the type variables for @xmath0 and @xmath1 are not unified ; here , ` eax ` is being used more like a syntactic constant than a dynamic value that should be typed .",
    "_ fortuitous re - use of values _ : a related situation appears in the common control - flow pattern represented by the snippet of c and the corresponding machine code in . note that on procedure exit , the return value in ` eax ` may have come from either the return value of ` s2 t ` or from the return value of ` get_s ` ( if ` null ` ) .",
    "if this situation is not detected , we will see a false relationship between the incompatible return types of ` get_t ` and ` get_s ` .    ' '' ''",
    "t * get_t(void ) s * s = get_s ( ) ; if ( s = = null ) return null ; t * t = s2t(s ) ; return t ;    get_t : call get_s test eax , eax jz local_exit push eax call s2 t add esp , 4 local_exit : ret    _ re - use of stack slots _ :",
    "if a function uses two variables of the same size in disjoint scopes , there is no need to allocate two separate stack slots for those variables .",
    "often the optimizer will reuse a stack slot from a variable that has dropped out of scope .",
    "this is true even if the new variable has a different type .",
    "this optimization even applies to the stack slots used to store formal - in parameters , as in ; once the function s argument is no longer needed , the optimizer can overwrite it with a local variable of an incompatible type .",
    "more generally , we can not assume that the map from program variables to physical locations is one - to - one .",
    "we can not even make the weaker assumption that the program variables inhabiting a single physical location at different times will all belong to a single type .",
    "we handle these issues through a combination of type - system features ( subtyping instead of unification ) and program analyses ( reaching definitions for stack variables and trace partitioning @xcite ) .    ' '' ''",
    "# include < stdlib.h >    struct ll struct ll * next ; int handle ; ;    int close_last(struct ll * list ) while ( list->next ! = null ) list = list->next ; return close(list->handle ) ;    close_last : push ebp mov ebp , esp sub esp,8 mov edx , dword [ ebp+arg_0 ] jmp loc_8048402 loc_8048400 : mov edx , eax loc_8048402 : mov eax , dword [ edx ] test eax , eax jnz loc_8048400 mov eax , dword [ edx+4 ] mov dword [ ebp+arg_0],eax leave jmp _",
    "_ thunk_.close    ' '' ''    typedef struct struct_0 * field_0 ; int // # filedescriptor field_4 ; struct_0 ;    int // # successz close_last(const struct_0 * ) ;      we discovered that , although not directly supported by the c type system , most programs define or make use of functions that are effectively polymorphic .",
    "the most well - known example is ` malloc ` : the return value is expected to be immediately cast to some other type ` t * ` .",
    "each call to ` malloc ` may be thought of as returning some pointer of a different type .",
    "the type of ` malloc ` is effectively _ not _",
    "@xmath2 , but rather @xmath3 .    the problem of a polymorphic `",
    "malloc ` could be mitigated by treating each call site @xmath4 as a call to a distinct function ` malloc`@xmath5 , each of which may have a distinct return type t@xmath5*. unfortunately , it is not sufficient to treat a handful of special functions like ` malloc ` this way : it is common to see binaries that use user - defined allocators and wrappers to ` malloc ` .",
    "all of these functions would also need to be accurately identified and duplicated for each callsite .    a similar problem exists for functions like ` free ` , which is polymorphic in its lone parameter .",
    "even more complex are functions like ` memcpy ` , which is polymorphic in its first two parameters and its return type , though the three types are not independent of each other . furthermore",
    ", the polymorphic type signatures @xmath6 are all strictly more informative to the reverse engineer than the standard c signatures .",
    "how else could one know that the ` void * ` returned by ` malloc ` is not meant to be an opaque handle , but rather should be cast to some other pointer type ?    in compiled c++ binaries ,",
    "polymorphic functions are even more common .",
    "for example , a class member function must potentially accept both ` base_t * ` and ` derived_t * ` as types for ` this ` .",
    "@xcite noted that using bounded polymorphic type schemes for ` libc ` functions increased the precision of type - qualifier inference , at the level of source code . to advance the state of the art in machine - code type recovery , we believe it is important to also embrace polymorphic functions as a natural and common feature of machine code .",
    "significant improvements to static type reconstruction  even for monomorphic types  will require the capability to infer polymorphic types of some nontrivial complexity .",
    "the relevance of recursive types for decompilation was recently discussed by @xcite , where lack of a recursive type system for machine code was cited as an important source of imprecision .",
    "since recursive data structures are relatively common , it is desirable that a type - inference scheme for machine code be able to represent and infer recursive types natively .",
    "unlike in source code , there is no syntactic distinction in machine code between a pointer - to-`struct ` and a pointer - to - first - member - of-`struct ` .",
    "for example , if @xmath7 has type ` struct ` ` { char * , file * , size_t } * ` on a 32-bit platform , then it should be possible to infer that @xmath8 can be safely passed to ` fclose ` ; conversely , if @xmath8 is passed to ` fclose ` we may need to infer that @xmath7 points to a structure that , at offset 4 , contains a ` file * ` .",
    "this affects the typing of local structures , as well : a structure on the stack may be manipulated using a pointer to its starting address or by manipulating the members directly , e.g. , through the frame pointer .",
    "these idioms , along with casts from ` derived * ` to ` base * ` , fall under the general class of _ physical _ @xcite or _ non - structural _ @xcite subtyping . in retypd , we model these forms of subtyping using type scheme specialization ( ) .",
    "additional hints about the extent of local variables are found using data - delineation analysis @xcite .",
    "the problem of producing correct disassembly for stripped binaries is equivalent to the halting problem . as a result",
    ", we can never assume that our reconstructed program representation will be perfectly correct .",
    "even sound analyses built on top of an unsound program representation may exhibit inconsistencies and quirks .",
    "thus , we must be careful that incorrect disassembly or analysis results from one part of the binary will not influence the correct type results we may have gathered for the rest of the binary .",
    "type systems that model value assignments as type unifications are vulnerable to over - unification issues caused by bad ir .",
    "since unification is non - local , bad constraints in one part of the binary can degrade _ all _ type results .",
    "another instance of this problem arises from the use of register parameters .",
    "although the x86 cdecl calling convention uses the stack for parameter passing , most optimized binaries will include many functions that pass parameters in registers for speed .",
    "often , these functions do not conform to any standard calling convention .",
    "although we work hard to ensure that only true register parameters are reported , conservativeness demands the occasional false positive .",
    "type - reconstruction methods that are based on unification are generally sensitive to precision loss due to false - positive register parameters .",
    "a common case is the `` ` push ecx ` '' idiom that reserves space for a single local variable in the stack frame of a function @xmath9 .",
    "if ` ecx ` is incorrectly viewed as a register parameter of @xmath9 in a unification - based scheme , whatever type variables are bound to ` ecx ` at each callsite to @xmath9 will be mistakenly unified . in our early experiments , we found these overunifications to be a persistent and hard - to - diagnose source of imprecision .    in our early unification - based experiments ,",
    "mitigation heuristics against overunification quickly ballooned into a disproportionately large and unprincipled component of type analysis .",
    "we designed retypd s subtype - based constraint system to avoid the need for such ad - hoc prophylactics against overunification .      even at the level of source code ,",
    "there are already many type - unsafe idioms in common use .",
    "most of these idioms operate by directly manipulating the bit representation of a value , either to encode additional information or to perform computations that are not possible using the type s usual interface .",
    "some common examples include    * hashing values by treating them as untyped bit blocks @xcite , * stealing unused bits of a pointer for tag information , such as whether a thunk has been evaluated @xcite , * reducing the storage requirements of a doubly - linked list by xor - combining the ` next ` and ` prev ` pointers , and * directly manipulating the bit representation of another type , as in the ` quake3 ` inverse square root trick @xcite .    because of these type - unsafe idioms , it is important that a type - inference scheme continues to produce useful results even in the presence of apparently contradictory constraints .",
    "we handle this situation in three ways :    1 .   separating the phases of constraint entailment , solving , and consistency checking , 2 .   modeling types with sketches ( ) that carry more information than c types , and 3 .",
    "using unions to combine types with otherwise incompatible capabilities ( e.g. , @xmath10 is both ` int`-like and pointer - like ) .",
    "degradation of points - to accuracy on large programs has been identified as a source of type - precision loss in other systems @xcite .",
    "our algorithm can provide high - quality types even in the absence of points - to information .",
    "precision can be further improved by increasing points - to knowledge via machine - code analyses such as vsa @xcite , but good results are already attained with no points - to analysis beyond the simpler problem of tracking the stack pointer .      programs may define an ad - hoc type hierarchy via typedefs .",
    "this idiom appears in the windows api , where a variety of handle types are all defined as typedefs of void*. some of the handle types are to be used as subtypes of other handles ; for example , a gdi handle ( hgdi ) is a generic handle used to represent any one of the more specific hbrush , hpen , _",
    "etc_. in other cases , a typedef may indicate a _ supertype _ , as in ` lparam ` or ` dword ` ; although these are typedefs of ` int ` , they have the intended semantics of a generic 32-bit type , which in different contexts may be used as a pointer , an integer , a flag set , and so on .    to accurately track ad - hoc hierarchies requires a type system based around subtyping rather than unification .",
    "models for common api type hierarchies are useful ; still better is the ability for the end user to define or adjust the initial type hierarchy at run time .",
    "we support this feature by parameterizing the main type representation by an uninterpreted lattice @xmath11 , as described in .",
    ".example field labels ( type capabilities ) in @xmath12 . [ cols=\">,^,<\",options=\"header \" , ]",
    "the initial type - simplification stage results in types that are as general as possible . often , this means that types are found to be more general than is strictly helpful to a ( human ) observer . a policy called @xmath13",
    "is used to specialize type schemes to the most _ specific _ scheme that is compatible with all uses .",
    "for example , a c++ object may include a getter function with a highly polymorphic type scheme , since it could operate equally well on any structure with a field of the right type at the right offset .",
    "but we expect that in every calling context , the getter will be called on a specific object type ( or perhaps its derived types ) . by specializing the function signature",
    ", we make use of contextual clues in exchange for generality before presenting a final c type to the user .",
    "suppose we have a c++ class    class myfile public : char * filename ( ) const return m_filename ; private : file * m_handle ; char * m_filename ; ;    in a 32-bit binary , the implementation of ` myfile::filename ` ( if not inlined ) will be roughly equivalent to the c code    typedef int32_t dword ; dword get_filename(const void * this ) char * raw_ptr = ( char * ) this ; dword * field_ptr = ( dword * ) ( raw_ptr + 4 ) ; return * field_ptr ;    accordingly , we would expect the most - general inferred type scheme for ` myfile::filename ` to be @xmath14 indicating that ` get_filename ` will accept a pointer to anything which has a value of some 32-bit type @xmath15 at offset 4 , and will return a value of that same type . if the function is truly used polymorphically , this is exactly the kind of precision that we wanted our type system to maintain .",
    "but in the more common case , ` get_filename ` will only be called with values where ` this ` has type ` myfile * ` ( or perhaps a subtype , if we include inheritance ) .",
    "if every callsite to ` get_filename ` passes it a pointer to ` myfile * ` , it may be best to specialize the type of ` get_function ` to the monomorphic type @xmath16    the function @xmath13 in is used to specialize each function s type _ just enough _ to match how the function is actually used in a program , at the cost of reduced generality .",
    "a useful but less sound heuristic is represented by the ` reroll ` policy for handling types which look like unrolled recursive types :    .... reroll(x ) :   if there are u and $ \\ell$ with x.$\\ell$u = x.$\\ell$ ,        and sketch(x ) $ \\subsketch$ sketch(x.$\\ell$ ) :     replace x with x.$\\ell$   else :     policy does not apply ....    in practice , we often need to add other guards which inspect the shape of @xmath0 to determine if the application of reroll appears to be appropriate or not . for example , we may require @xmath0 to have at least one field other than @xmath17 to help distinguish a pointer - to - linked - list from a pointer - to - pointer - to - linked - list .",
    "the results of constraint generation for the example program in appears in .",
    "the constraint - simplification algorithm builds the automaton @xmath18 ( ) to recognize the simplified entailment closure of the constraint set .",
    "@xmath18 recognizes exactly the input / output pairs of the form @xmath19 and @xmath20 to generate the simplified constraint set , a type variable @xmath10 is synthesized for the single internal state in @xmath18 .",
    "the path leading from the start state to @xmath10 generates the constraint @xmath21 the loop transition generates @xmath22 and the two transitions out of @xmath10 generate @xmath23 finally , the two remaining transitions from start to end generate @xmath24 to generate the simplified constraint set , we gather up these constraints ( applying some lattice operations to combine inequalities that only differ by a lattice constant ) and close over the introduced @xmath10 by introducing an @xmath25 quantifier . the result is the constraint set of .",
    "@xmath26    \\pgfsetlinewidth{1bp }    \\pgfsetcolor{black }    \\node[shape = circle , draw ] ( s ) at ( 37.942bp,19.588bp ) { } ;    \\node[shape = circle , draw ] ( t ) at ( 252.16bp,68.075bp ) { } ;    \\node[shape = circle , draw , accepting ] ( e ) at ( 544.7bp,19.588bp ) { } ;        \\path [ - > ] ( s ) edge [ bend left=20 ]   node [ above ] { \\small{close\\_last.in / $ \\varepsilon$ } } ( t ) ;    \\path [ - > ] ( t ) edge [ bend left=20 ]   node [ above ] { \\small{.load.32@4 / \\#filedescriptor } } ( e ) ;    \\path [ - > ] ( t ) edge [ bend right=10 ] node [ below ] { \\small{.load.32@4 / int } } ( e ) ;    \\path [ - > ] ( s ) edge [ bend right=20 ] node [ below ] { \\small{\\#successz / close\\_last.out } } ( e ) ;    \\path [ - > ] ( s ) edge [ bend right=50 ] node [ below ] { \\small{int / close\\_last.out } } ( e ) ;    \\path [ - > ] ( t ) edge [ loop above , in=60,out=135,looseness=10 ] node [ above ] { \\small{.load.32@0 / $ \\varepsilon$ } } ( t ) ;    \\begin{scope }    \\definecolor{strokecol}{rgb}{0.0,0.0,0.0 } ;    \\pgfsetstrokecolor{strokecol } \\end{scope }    \\begin{scope }    \\definecolor{strokecol}{rgb}{0.0,0.0,0.0 } ;    \\pgfsetstrokecolor{strokecol } \\end{scope }    \\begin{scope }    \\definecolor{strokecol}{rgb}{0.0,0.0,0.0 } ;    \\pgfsetstrokecolor{strokecol } \\end{scope }    \\end{tikzpicture}\\ ] ]      _",
    "text:08048420 close_last proc near _",
    "close_last : _ text:08048420 mov edx , dword [ esp+fd ] ar_close_last_initial[4:7 ]",
    "< : edx_8048420_close_last[0:3 ] close_last.in@stack0 < : ar_close_last_initial[4:7 ] eax_804843f_close_last[0:3 ] < : close_last.out@eax _ text:08048424 jmp loc_8048432 _ text:08048426 db 141 , 118 , 0 , 141 , 188 , 39 _",
    "text:0804842c times 4 db 0 _ text:08048430 _ text:08048430 loc_8048430 : _ text:08048430 mov edx , eax eax_8048432_close_last[0:3 ]",
    "< : edx_8048430_close_last[0:3 ] _",
    "text:08048432 loc_8048432 : _ text:08048432 mov eax , dword [ edx ] edx_8048420_close_last[0:3 ]",
    "< : unknown_loc_106 edx_8048430_close_last[0:3 ] < : unknown_loc_106 unknown_loc_106.load.32@0 < : eax_8048432_close_last[0:3 ] _ text:08048434 test eax , eax _",
    "text:08048436 jnz loc_8048430 _ text:08048438 mov eax , dword [ edx+4 ] edx_8048420_close_last[0:3 ] < : unknown_loc_111 edx_8048430_close_last[0:3 ] < : unknown_loc_111 unknown_loc_111.load.32@4 < : eax_8048438_close_last[0:3 ] _ text:0804843b mov dword [ esp+fd],eax eax_8048438_close_last[0:3 ]",
    "< : ar_close_last_804843b[4:7 ] _",
    "text:0804843f jmp _",
    "_ thunk_.close ar_close_last_804843b[4:7 ] < : close:0x804843f.in@stack0 close:0x804843f.in@stack0 < : # filedescriptor close:0x804843f.in@stack0 < : int close:0x804843f.out@eax < : eax_804843f_close_last[0:3 ] int < : close:0x804843f.out@eax _ text:08048443 _ text:08048443 close_last endp"
  ],
  "abstract_text": [
    "<S> for many compiled languages , source - level types are erased very early in the compilation process . as a result , further compiler passes may convert type - safe source into type - unsafe machine code . </S>",
    "<S> type - unsafe idioms in the original source and type - unsafe optimizations mean that type information in a stripped binary is essentially nonexistent . the problem of recovering high - level types by performing type inference over stripped machine code </S>",
    "<S> is called _ type reconstruction _ , and offers a useful capability in support of reverse engineering and decompilation .    in this paper </S>",
    "<S> , we motivate and develop a novel type system and algorithm for machine - code type inference . </S>",
    "<S> the features of this type system were developed by surveying a wide collection of common source- and machine - code idioms , building a catalog of challenging cases for type reconstruction . </S>",
    "<S> we found that these idioms place a sophisticated set of requirements on the type system , inducing features such as recursively - constrained polymorphic types . </S>",
    "<S> many of the features we identify are often seen only in expressive and powerful type systems used by high - level functional languages .    using these type - system features as a guideline , </S>",
    "<S> we have developed retypd : a novel static type - inference algorithm for machine code that supports recursive types , polymorphism , and subtyping . </S>",
    "<S> retypd yields more accurate inferred types than existing algorithms , while also enabling new capabilities such as reconstruction of pointer ` const ` annotations with 98% recall . </S>",
    "<S> retypd can operate on weaker program representations than the current state of the art , removing the need for high - quality points - to information that may be impractical to compute .    </S>",
    "<S> reverse engineering , type systems , polymorphism , static analysis , binary analysis , pushdown automata </S>"
  ]
}