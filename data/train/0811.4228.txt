{
  "article_text": [
    "large scale structures traced by galaxies are believed to have formed by amplification of small perturbations @xcite .",
    "galaxies are highly over - dense systems , matter density @xmath0 in galaxies is thousands of times larger than the average density @xmath1 in the universe .",
    "typical density contrast ( @xmath2 ) in matter at these scales in the early universe was much smaller than unity .",
    "thus the problem of galaxy formation and the large scale distribution of galaxies requires an understanding of the evolution of density perturbations from small initial values to the large values we encounter today .",
    "initial density perturbations were present at all scales that have been observed @xcite .",
    "the equations that describe the evolution of density perturbations in an expanding universe have been known for several decades and these are easy to solve when the amplitude of perturbations is small .",
    "once density contrast at relevant scales becomes comparable to unity , perturbations becomes non - linear and coupling with perturbations at other scales can not be ignored . the equation for evolution of density perturbations can not be solved for generic initial conditions in this regime .",
    "n - body simulations ( e.g. , see ) are often used to study the evolution in this regime .",
    "alternative approaches can be used if one requires only a limited amount of information and in such a case either quasi - linear approximation schemes or scaling relations @xcite suffice . however , even the approximation schemes and scaling relations must be compared and calibrated with simulations before these can be used with confidence .",
    "last three decades have seen a rapid development of techniques and computing power for cosmological simulations and the results of these simulations have provided valuable insight into the study of structure formation .",
    "the state of the art simulations used less than @xmath3 particles two decades ago @xcite and if the improvement had been due only to computing power then the largest simulation possible today should have been around @xmath4 particles , whereas the largest simulations done till date used more than @xmath5 particles @xcite .",
    "evidently , development of new methods and optimizations has also played a significant role in the evolution of simulation studies @xcite along the way , code developers have also successfully met the challenge posed by the emergence of distributed parallel programming .    in modeling gravitational clustering , cosmological n - body codes should ensure the following :    * the universe does not have a boundary .",
    "therefore cosmological simulations need to be run with periodic boundary conditions",
    ". the simulation volume should be large enough for the effects of missing modes to be small , @xcite .",
    "* the mass of each particle in simulations should be much smaller than mass scales of interest in the simulation output .",
    "this is to ensure adequate mass resolution . *",
    "each particle in an n - body simulation represents a very large number of particles / objects in the universe .",
    "thus we must ensure that pair - wise interaction of n - body particles is softened at scales comparable with the local inter - particle separation .",
    "if this is not ensured then the resulting two body collisions introduce errors in the resulting distribution of particles , @xcite .    in spite of the vast improvement in computing power , simulators have often had to compromise on one or more of these points .",
    "often , errors also creep in due to the approximate methods used for solving for force in simulations .",
    "a large fraction of current cosmological n - body codes suffer from collisionality or force biasing .",
    "force is biased when softening lengths @xmath6 are much larger than the local mean inter - particle separation , @xmath7 . whereas a complementary effect ,",
    "collisions , occur whenever @xmath8 .",
    "the reader is referred to @xcite for a detailed discussion on these two effects .",
    "codes that adapt their softening lengths to local densities generally are mostly of the adaptive mesh refinement type .",
    "these use a grid for solving the poisson equation and often have anisotropies in force at the scales comparable to the size of a grid cell",
    ". codes which use fixed softening lengths are not entirely collisionless , and , in highly over - dense regions biasing of force also exists .",
    "the tpm , @xcite is a particle based code with a one step adaptive resolution .",
    "however , in this case the use of the unmodified pm approach for computing the long range force introduces significant errors at scales comparable to the grid . in this work",
    "we describe a code which addresses all three issues of force anisotropy , collisionality and force biasing by employing an adaptive softening formalism with the hybrid treepm code .",
    "the choice of the optimal softening length has been discussed at length @xcite .",
    "these studies were carried out in the context of isolated haloes in dynamical equilibrium , e.g. , plummer and hernquist profiles , therefore errors could be defined clearly .",
    "it is also possible to compute and compare various physical quantities with analytical expressions derived from the distribution function .",
    "@xcite derived analytical expressions for errors in the context of these profiles .",
    "this work suggested that the optimal softening length must adapt to the local inter - particle separation as a function of space and time . @xcite",
    "have developed an energy - momentum conserving formalism with adaptive softening and demonstrated that it was superior to fixed softening .",
    "the evolution of perturbations at small scales depends strongly on the mass and force resolution .",
    "high force resolutions can lead to better modeling of dense haloes , but gives rise to two body collisions in regions where the softening length is smaller than the local inter particle separation @xcite .",
    "as all particles in very high density regions go through such a phase during evolution , any errors arising due to two body collisions can potentially effect the structure of high density haloes that form . a high force resolution without a corresponding mass resolution",
    "can also give misleading results as we can not probe _ shapes _ of collapsed objects @xcite .",
    "in addition , discreteness and stochasticity also limit our ability to measure physical quantities in simulations , and these too need to be understood properly @xcite . in all such cases , the errors in modeling is large at small scales .",
    "it is important to understand how such errors may spread to larger scales and affect physical quantities .",
    "this work is organized as follows . in ",
    "2 we describe the formalism for adaptive softening in a cosmological -body code . in ",
    "3 we review the treepm method , which forms the backbone of our gravity solver and describe how adaptive softening is implemented with it .",
    "we briefly discuss the performance characteristics of atreepm in  4 .",
    "we discuss validation of the atreepm code in  5 and we conclude in  6 .",
    "the aim of any collisionless -body code is to self consistently evolve the phase - space distribution function ( df ) @xmath9 under its own gravitational force field @xmath10 : _ t f & + & ( _ f ) .",
    "+ ( _ f ) .",
    "= 0 + ( , t ) & = & -g ^f(^,,t ) the approach that one takes is to sample the df , by   phase - space points , @xmath11 , at initial time @xmath12 .",
    "liouville s theorem then states that evolving the trajectories of these points to any time @xmath13 will be a representation of the df at that time .",
    "since the system is a collisionless one , one has to suppress artificial two - body collisions arising out of interactions between particles which were generated for sampling the density field .",
    "one therefore assigns a finite size to n - body particles which ensures softening of force at small scales , instead of assuming these to be point particles .",
    "the density field when sampled by point particles , ( ) = f(,,t ) _ j=1^n m_j _ d^3 ( - ) is now smoothed at small scales if we assign a finite size @xmath6 to every particle : ( ) = f(,,t )",
    "_ j=1^n m_j w(| -| , ) where @xmath14 is known as the smoothing kernel and we have assumed that particles are spherical in shape . here @xmath15 is the mass of the @xmath16 particle . we can now integrate the poisson equation to obtain the expression for the kernel for computing force and potential .",
    "both the quantities are softened at scales below the softening length @xmath6 .",
    "we choose to work with the cubic spline kernel whose expression is given below .",
    "complete expressions for the potential and force are given in the appendix ( see eqn.([pot_fixedh ] , [ force_fixedh ] ) ) .",
    "w(u , ) = \\ {    ll 1 - 6()^^2 + 6()^^3 , & + 2(1- ) ^^3 , & + 0 , &    .",
    "[ eq_mon_kernel ] in the context of individual softening lengths the density at the location of the @xmath17 particle is given by : ( r_i ) = _",
    "j=1^n m_j w(r_ij,_i ) = _",
    "j=1^n_n m_j w(r_ij,_i ) where _ i , j _ indicate the particle indices , @xmath18 and @xmath19 .",
    "the summation in principle can be extended upto infinity if the kernel is infinite in extent ( e.g. plummer , gaussian kernels ) .",
    "but since such kernels tend to bias the force @xcite we will work only with those kernels which have compact support , in particular the cubic spline kernel .",
    "such kernels ensure that the force is newtonian beyond the softening scale .",
    "@xmath20 is the number of the nearest nearbors within @xmath21 for the particle @xmath22 . in the discussion that follows we assume that this number is fixed for every particle and sets the value of the softening length @xmath21 .",
    "we implicitly assume it in our summation . integrating the poisson equation",
    "we obtain the green s function for the potential @xmath23 , where the functional form for @xmath24 is given in the appendix ( see eqn.([pot_fixedh ] , [ force_fixedh ] ) ) .    with the introduction of individual softening lengths for particles ,",
    "the symmetry of the potential is lost and momentum conservation is violated . since @xmath25 is now a local quantity ,",
    "the eom is incomplete if one takes the expression of force with the fixed softening length @xmath6 replacing it by a local softening length @xmath26 .",
    "hence energy conservation also gets violated .",
    "this is because the force is derived from the potential and with the introduction of a local softening length @xmath26 in the potential , the gradient must also act on @xmath26 giving us an extra term .",
    "traditionally this _",
    "_ grad-__@xmath6 ( @xmath27 ) term has been ignored since in typical applications these were found to be subdominant when compared to the usual force .",
    "it has been shown recently @xcite , that this term plays an important role in n - body simulations .",
    "we study the impact of ignoring this term in cosmological simulations .",
    "a remedy for momentum non - conservation is to use a symmetrized softening length @xmath28 and plug it into the expression for density to re - derive a symmetrized expression for the potential as @xmath29 .",
    "this prescription changes the softening length and hence the neighborlist , which one has to recompute .",
    "another disadvantage is that with this prescription for symmetrization , the number of neighbors is not fixed for every particle and hence errors in all smoothed estimates are not the same for every particle .",
    "an alternate method @xcite is to symmetrize the kernel itself . _",
    "ij & = & _ ji = + _ ij & = & the total potential is thus _",
    "tot = _ i , j^n _ ij we can use this to write a lagrangian which is manifestly symmetric and this ensures momentum conservation .",
    "energy is conserved only if the @xmath30 term is retained in the eom .",
    "i^n m_iv_i^2 - _ i , j^n m_im_j _ ij    the eom of motion can be derived with this lagrangian ( the reader is referred to @xcite for details ) = & -&g_j m_j ^_ij + & - & _ j m_j where the first term is the standard newtonian force term ( we refer to it as the @xmath31 term ) .",
    "the second is the energy conserving @xmath30 term which would be zero for fixed softening .",
    "notice that all terms are antisymmetric in @xmath32 and hence the total momentum is conserved . here",
    "@xmath33 and @xmath34 are : _",
    "i @xmath35 _ j m_j @xmath36 + _ i = expressions for @xmath37 , @xmath38 and @xmath39 are given in the appendix ( see [ kernel_dwde],[kernel_dwdr ] and[pot_dphide ] ) .",
    "as @xmath40 we have @xmath41 .",
    "the term @xmath34 term ensures that the eom is accurate to all orders in @xmath6 @xcite .",
    "the treepm algorithm @xcite is a hybrid n - body method which improves the accuracy and performance of the barnes - hut ( bh ) tree method @xcite by combining it with the pm method .",
    "the treepm method explicitly breaks the potential into a short - range and a longe - range component at a scale @xmath42 .",
    "the pm method is used to calculate long - range force and the short - range force is computed using the bh tree method .",
    "use of the bh tree for short - range force calculation enhances the force resolution as compared to the pm method .",
    "the gravitational force is divided into a long range and a short range part using partitioning of unity in the poisson equation .",
    "@xmath43 \\end{aligned}\\ ] ] here @xmath44 and @xmath45 are the short - range and long - range potentials in fourier space .",
    "@xmath0 is the density , g is the gravitational coupling constant and @xmath42 is the scale at which the splitting of the potential is done .",
    "it has been shown that this particular split between the long range and the short range force is optimal amongst a large class of suitable functional forms @xcite .",
    "the long - range force is computed in fourier space with the pm method and the short - range force is computed in real space with the tree method .",
    "the short range potential and force in real space are : ^sr ( , ) & = & gm ( , ) ( ) + ^sr ( , ) & = & gm(,)c ( ) + c ( ) & = & here @xmath46 is the complementary error function . @xmath47 and @xmath48 are the usual potential and force kernels , respectively .",
    "@xmath49 modifies the softened newtonian force kernel @xmath48 to the short - range force @xmath50 .",
    "the expression for @xmath47 and @xmath48 depend on the kernel @xmath51 used for smoothing and are given for cubic spline in the appendix .",
    "we find that tabulating @xmath52 and @xmath53 and using interpolation to compute these functions is much more effective than calculating them every time .",
    "the short range force is below @xmath54 of the total force at @xmath55 .",
    "the short range force is therefore computed within a sphere of radius @xmath56 using the bh tree method .",
    "the long range force falls below @xmath54 of the total force for @xmath57 .",
    "thus the choice of softening length does not affect the long range force in a significant manner as long as the force softening is done with a kernel that has a compact support and the softening length is below @xmath58 .",
    "the bh tree structure is built out of cells and particles .",
    "cells may contain smaller cells ( sub - cells ) within them .",
    "sub - cells can have even smaller cells within them , or they can contain a particle . in three dimensions , each cubic cell is divided into eight cubic sub - cells .",
    "cells , as structures , have attributes like total mass , location of center of mass and pointers to sub - cells .",
    "particles , on the other hand have the usual attributes : position , velocity and mass",
    ".    force on a particle is computed by adding contribution of other particles or of cells . a cell that is sufficiently far away",
    "can be considered as a single entity and we can add the force due to the total mass contained in the cell from its center of mass . if the cell is not sufficiently far away then we must consider its constituents , sub - cells and particles . whether a cell can be accepted as a single entity for force calculation is decided by the cell acceptance criterion ( cac ) .",
    "we compute the ratio of the size of the cell @xmath59 and the distance @xmath60 from the particle in question to its center of mass and compare it with a threshold value @xmath61 the error in force increases with @xmath62 .",
    "poor choice of @xmath62 can lead to significant errors @xcite .",
    "many different approaches have been tried for the cac in order to minimize error as well as cpu time usage @xcite .",
    "the tree code gains over direct summation as the number of contributions to the force is much smaller than the number of particles .",
    "the treepm method is characterized therefore by three parameters , @xmath42,@xmath63 and @xmath62 . for a discussion on the optimum choice of these parameters the reader",
    "is referred to @xcite . for all our tests",
    "we choose conservative values @xmath64 , @xmath65 and @xmath66 which give errors below @xmath54 in force .",
    "all lengths are specified in units of the pm grid .",
    "we choose to implement adaptive softening with a modified treepm code @xcite , which incorporates barnes optimization using _ groups _",
    "@xcite , into the treepm code . in principle",
    "one can also incorporate a similar formalism for treecodes @xcite , 3 m codes @xcite and other variants like tpm @xcite , treepm @xcite and gotpm @xcite .",
    "we shall discuss one advantage of using the treepm code with the group optimizations below .",
    "our first task is to get an estimate of the softening length for each particle . a natural way to extract a local length scale uses the numerical value of local density .",
    "the local number density is related to the softening length as : ~()^ [ eps_con ] @xmath67 is the number density at the location of the particle and we assume all particles have the same mass . here",
    ", @xmath20 is a reference number and we take it to be the number of neighbors used for estimation of the number density .",
    "the above equation is implicit and can be solved iteratively , see , e.g. , @xcite for details .",
    "@xcite have shown that errors are not very sensitive to the exact value of @xmath20 .",
    "we choose @xmath68 in our simulations , and also comment on variation in results with this choice .",
    "we are using the formalism developed by @xcite for achieving an adaptive resolution in gravitational interactions of particles . as the formalism was developed in the context of sph codes , and some of the quantities required",
    "can be computed naturally using the sph method , the same was used even though the gravitational interaction is completely collisionless .",
    "we follow a similar implementation and use methods commonly used in sph simulations , even though there are no hydrodynamical effects present in the gravitational interaction being studied here . for",
    "an overview of sph methods , please see @xcite .",
    "the sph methods assign values for functions like the density to particles by averaging over nearest neighbors .",
    "the list of nearest neighbors is an essential requirement for computing anything using these methods .",
    "all quantities ( @xmath0 , @xmath69 , @xmath34 , @xmath33 etc . ) can be computed at runtime with this neighborlist once we have converged to a value for @xmath6 by solving eqn.([eps_con ] ) .",
    "we compute the neighborlist using linked lists @xcite .",
    "we put bounds on the maximum and minimum softening lengths , @xmath70 and @xmath71 . a maximum bound",
    "is required so that force softening is restricted to the short - range force only , we choose @xmath72 in order to ensure that the long range force is of order @xmath54 of the total force ( or smaller ) at scales where force softening is important .",
    "this ensures that any errors arising from non - modification of the long range force are smaller than @xmath54 , if one puts a lower threshold on the maximum allowed error then the scale @xmath70 has to be lowered correspondingly .",
    "alternatively , one can work with a larger @xmath42 and then it becomes possible to allow a larger @xmath70 .",
    "a lower bound is also required for the reason that we do not want a few isolated highly over - dense regions to dominate the cpu time requirements .",
    "the value of the lower bound must correspond to densities that are much higher than highest over - densities of interest in the simulation .",
    "we set this lower bound @xmath73 , which corresponds to @xmath74 .",
    "the lower bound however is not critical to the structure of the code and may be omitted .    in our implementation",
    "a neighbor search is carried out only upto @xmath70 .",
    "particles which do not have @xmath20 neighbors within @xmath70 are assigned @xmath75 and the spherical top hat ( sth ) density is assigned with the number of neighbors within @xmath70 . for these particles we assign @xmath76 and @xmath77 , which makes their @xmath78 .",
    "a similar assignment is carried out for particles which have @xmath79 .",
    "the @xmath27 term is calculated before the short - range force so that the individual softening lengths needed for short - range force calculation are also assigned in the process .",
    "even though we use two separate data structures , namely linked lists for @xmath27 and tree for @xmath80 in order to compute the total short - range force , additional memory requirements compared to treepm are minimal : we require one additional array for storing the softening lengths . the @xmath27 term does not require an additional array since it is a component of the short - range force and it can be computed at run time .",
    "this is because the two data structures are never required at the same time .",
    "we require specification of the largest force softening length in a given cell ( see the subsection on the cell acceptance criterion below . ) .",
    "this amounts to a single precision array of the same size as the number of cells in the tree .",
    "an advantage of using an analytical splitting of force , in the manner treepm does , is that computation of short - range force does not need global data structures .",
    "for example one can geometrically divide regions into smaller regions and construct local trees and linked lists in them ( just like one would go about doing it in a distributed code ) and iterate through these regions for computing short - range force instead of constructing one global data structure for the entire simulation volume for computing the short - range force @xcite .",
    "this reduces memory usage significantly and the dominant part is taken up by the arrays required for computing the long range pm force .",
    "we have implemented a hierarchical time integrator similar to that used in gadget-2 @xcite , in which particle trajectories are integrated with individual timesteps and synchronized with the largest timestep .",
    "as we allow the block time step to vary with time , we work with the so called kdk approach ( kick - drift - kick ) in which velocities are updated in two half steps whereas position is updated in a full step .",
    "it can be shown that with a variable time step , kdk performs better than dkd ( drift - kick - drift ) ( see @xcite for details . ) .",
    "we give separate pm ( long range , global ) kicks and tree ( short range , individual ) kicks term . ] .",
    "the block timestep @xmath81 is determined by the particle which has the maximum pm acceleration @xmath82 : t^^pm = t",
    "( ) ^1/2 here @xmath83 is the dimensionless accuracy parameter . in our implementation of the hierarchy of time steps , the smaller time steps differ by an integer power ( @xmath84 ) of @xmath85 from the largest , block time step . an array is then used to store the value @xmath84 which determines the timestep of the particle .",
    "individual timesteps @xmath86 are first calculated : t_i^sr = t ( ) ^1/2 [ eq_tstep_atpm_sr ] and then the appropriate hierarchy @xmath84 is chosen depending on this value . here",
    "@xmath87 and @xmath21 are the modulus of the individual short - range acceleration ( sum of the @xmath80 and @xmath27 terms ) and the softening lengths respectively .",
    "treepm has a similar time - stepping criterion with @xmath21 replace by @xmath6 .",
    "the code drifts all the particles with the smallest timestep to the next time , where a force computation is done for particles that require an updation of velocity ( kick ) .",
    "however the neighborlist and individual softening lengths @xmath21 are computed for all particles at every small timestep .",
    "this is because , even though some particles do not require a velocity update , their neighbors might require one for which they would contribute through their updated softening lengths .",
    "the @xmath27 term however can be computed only for those particles requiring a velocity update .    within a given block time step ,",
    "the smaller time steps are constant for a given particle .",
    "the time step changes across block time step and this brings in inaccuracies in evolution of trajectories .",
    "it is possible , in principle , to ensure that the second order accuracy is maintained here .",
    "however , we find that the time steps for particles change very slowly and this change does not affect trajectories in a significant manner .",
    "the courant condition is satisfied for the choice of @xmath83 we use .",
    "indeed , we chose @xmath83 by requiring that two particles in a highly eccentric orbit around each other maintain the trajectory correctly for tens of orbits .",
    "[ cols=\"^,^ \" , ]",
    "in this paper we have introduced the first cosmological n - body code that has a continuously varying force resolution .",
    "this is based on a well defined formalism that ensures energy and momentum conservation .",
    "an important aspect of this formalism is that it modifies the equation of motion at scales below the force softening length .",
    "our implementation of the formalism uses methods developed for sph codes , this is required as we need to assign quantities like density to particles .",
    "we have described our implementation of the code in detail here . we have given a brief summary of errors in force for the adaptive treepm code with the new parameter @xmath20 .",
    "given that this code is based on the treepm code , it inherits the errors in force with respect to all the other parameters .",
    "as we have seen in earlier work @xcite , errors in force can be minimised to a fairly low level for the treepm with a judicious choice of parameters .",
    "we find that the time taken by the adaptive treepm ( for @xmath88 ) is comparable to that taken by the fixed resolution treepm code if the latter uses a force softening length that is about @xmath89 of the mean inter - particle separation .",
    "one of the key reasons for considering adaptive resolution is to avoid two body collisions .",
    "cosmological simulations require collisionless evolution .",
    "we test the adaptive treepm by simulating collapse of an oblique plane - wave .",
    "we find that unlike the fixed resolution treepm code that leads to large transverse motions , a clear sign of two body collisions , the adaptive treepm code does not have any significant transverse motions .",
    "( see figures  [ fig_plwave_treepm ] , [ fig_plwave_atreepm ] )    we have compared the performance of the adaptive treepm with that of the fixed resolution treepm code for power law initial conditions .",
    "we used a power law model and the einstein - de sitter background as it allows us to test codes by requiring self - similar evolution of the correlation function .",
    "we find that for @xmath88 , the resulting density distribution in the adaptive treepm is comparable to that seen in the highest resolution treepm in many respects .",
    "the correlation function for the two match at all scales and the mass function of collapsed haloes matches for haloes with more than @xmath20 particles .",
    "the adaptive treepm with the @xmath27 term in the equation of motion does much better than the treepm as well as the adaptive treepm without the extra term in resolving highly over - dense cores of massive haloes .",
    "it is noteworthy that the adaptive code takes less time than the treepm it has been compared with ( see fig .  [ fig_timing ] ) .",
    "we have tested the codes by looking for convergence in results as we modify the key parameters that describe the force resolution .",
    "we find that the fixed resolution treepm code converges slower than expected from , for example , self - similar evolution of clustering .",
    "the adaptive treepm code with the @xmath27 term converges fairly quickly and offers an effective dynamical range that is slightly smaller than the fixed resolution treepm that takes almost the same time to run .    given our analysis of errors , and the comparison of the performance of the atreepm code with and without the extra term in the equation of motion ,",
    "the natural conclusion is that we require the extra term in order to obtain low errors and numerical convergence .",
    "this raises the obvious question about the amr codes where no such extra term is used .",
    "further , in most amr codes , resolution is increased when there are of order @xmath90 particles in the lower resolution elements .",
    "we find that the errors are minimized when this number is around @xmath91 even when the extra term is not taken into account .",
    "it is not clear how serious these issues are , given that amr codes have been developed and tested in a variety of ways over the last three decades , but it is a concern . ] .",
    "we have established in this paper that an adaptive resolution code for evolution of perturbations in collisionless dark matter can give reliable results for a range of indicators from clustering properties to mass function of collapsed haloes and even get the internal dynamics of collapsed haloes tight .",
    "further , we show that such a code is efficient in that it is faster than fixed resolution codes that give us comparable force resolution in highly over dense regions .",
    "such a code is very useful as it allows us to probe clustering at small scales in a reliable manner .",
    "studies of box - size effects have shown that large simulation boxes are required in order to limit the effect of perturbations at larger scales that are not taken into account @xcite . in such a situation an adaptive code provides us with a reasonable range of scales over which the results can be trusted .",
    "we expect to use this code to address several issues related to gravitational clustering in an expanding universe .",
    "we also plan to revisit issues related to density profiles of collapsed haloes .    given the conclusions listed above , we feel that the adaptive treepm methods represents an exciting development where we can set aside worries about the impact of collisionality .",
    "the relative speed of the adaptive code also makes this a more pragmatic option .",
    "the authors are indebted to daniel j. price for clarifying several issues regarding their implementation of the adaptive code .",
    "the authors thank martin white , volker springel and alessandro romeo for useful discussions and comments . numerical experiments for this study",
    "were carried out at cluster computing facility in the harish - chandra research institute ( http://cluster.hri.res.in ) .",
    "this research has made use of nasa s astrophysics data system .",
    "athanassoula e. , fady e. , lambert j.  c. , bosma a. , 2000 , mnras , 314 , 475    bagla j.  s. , padmanabhan t. , 1994 , mnras , 266 , 227    bagla j.  s. , padmanabhan t. , 1997 , pramana , 49 , 161    bagla j.  s. , padmanabhan t. , 1997 , mnras , 286 , 1023    bagla j.  s. , 2002 , japa , 23 , 185    bagla j.  s. , ray s. , 2003 , newa , 8 , 665    bagla j.  s. , ray s. , 2005 , mnras , 358 , 1076    bagla j.  s. , 2005 , csci , 88 , 1088    bagla j.  s. , prasad j. , 2006 , mnras , 370 , 993    bagla j.  s. , prasad j. , 2008 , arxiv , arxiv:0802.2796    bagla j.  s. , prasad j. , khandai n. , 2008 , arxiv , arxiv:0804.1197    barnes j. , hut p. , 1986 ,",
    "natur , 324 , 446    barnes j.  e. , 1990 , jcoph , 87 , 161    bernardeau f. , colombi s. , gaztaaga e. , scoccimarro r. , 2002 , phr , 367 , 1    bertschinger e. , 1998 , ara&a , 36 , 599    binney j. , knebe a. , 2002 , mnras , 333 , 378    binney j. , 2004 , mnras , 350 , 939    bode p. , ostriker j.  p. , 2003 ,",
    "apjs , 145 , 1    bode p. , ostriker j.  p. , xu g. , 2000 , apjs , 128 , 561    bouchet f.  r. , adam j .-",
    ", pellat r. , 1985 , a&a , 144 , 413    bouchet f.  r. , kandrup h.  e. , 1985 , apj , 299 , 1    bouchet f.  r. , hernquist l. , 1988 , apjs , 68 , 521    brainerd t.  g. , scherrer r.  j. , villumsen j.  v. , 1993 , apj , 418 , 570    brieu p.  p. , evrard a.  e. , 2000 , newa , 5 , 163    brieu p.  p. , summers f.  j. , ostriker j.  p. , 1995 ,",
    "apj , 453 , 566    couchman h.  m.  p. , 1991 ,",
    "apj , 368 , l23    couchman h.  m.  p. , thomas p.  a. , pearce f.  r. , 1995 , apj , 452 , 797    davis m. , peebles p.  j.  e. , 1977 , apjs , 34 , 425    dehnen w. , 2000 , apj , 536 , l39    dehnen w. , 2001 , mnras , 324 , 273    dehnen w. , 2002 , jcoph , 179 , 27    diemand j. , moore b. , stadel j. , kazantzidis s. , 2004 , mnras , 348 , 977    dolag k. , borgani s. , schindler s. , diaferio a. , bykov a.  m. , 2008 , ssrv , 134 , 229    dubinski j. , 1996 , newa , 1 , 133    dubinski j. , kim j. , park c. , humble r. , 2004 , newa , 9 , 111    dyer c.  c. , ip p.  s.  s. , 1993 , apj , 409 , 60    ebisuzaki t. , makino j. , fukushige t. , taiji m. , sugimoto d. , ito t. , okumura s.  k. , 1993 , pasj , 45 , 269    efstathiou g. , davis m. , white s.  d.  m. , frenk c.  s. , 1985 , apjs , 57 , 241    el - zant a.  a. , 2006 , mnras , 370 , 1247    evrard a.  e. , 1988 , mnras , 235 , 911    evrard a.  e. , crone m.  m. , 1992 , apj , 394 , l1    efstathiou g. , frenk c.  s. , white s.  d.  m. , davis m. , 1988 , mnras , 235 , 715    gingold r.  a. , monaghan j.  j. , 1977 , mnras , 181 , 375    gingold r.  a. , monaghan j.  j. , 1982 , jcoph , 46 , 429    greengard l. , rokhlin v. , 1987 , jcoph , 73 , 325    gurbatov s.  n. , saichev a.  i. , shandarin s.  f. , 1989 , mnras , 236 , 385    hamana t. , yoshida n. , suto y. , 2002 , apj , 568 , 455    hamilton a.  j.  s. , kumar p. , lu e. , matthews a. , 1991 , apj , 374 , l1    heitmann k. , ricker p.  m. , warren m.  s. , habib s. , 2005 , apjs , 160 , 28    heitmann k. , et al . , 2008 , cs&d , 1 , 015003    hernquist l. , 1987 , apjs , 64 , 715    hernquist l. , katz n. , 1989 , apjs , 70 , 419    hernquist l. , 1990 , jcoph , 87 , 137    hernquist l. , barnes j.  e. , 1990 , apj , 349 , 562    hernquist l. , bouchet f.  r. , suto y. , 1991 , apjs , 75 , 231    hockney r.  w. , eastwood j.  w. , 1988 , computer simulation using particles , mcgraw - hill    hui l. , bertschinger e. , 1996 , apj , 471 , 1    jain b. , mo h.  j. , white s.  d.  m. , 1995 , mnras , 276 , l25    jernigan j.  g. , porter d.  h. , 1989 , apjs , 71 , 871    joyce m. , marcos b. , baertschiger t. , 2008 , arxiv , arxiv:0805.1357    kanekar n. , 2000 , apj , 531 , 17    kawai a. , makino j. , 2001 , apj , 550 , l143    klypin a.  a. , shandarin s.  f. , 1983 , mnras , 204 , 891    knebe a. , green a. , binney j. , 2001 , mnras , 325 , 845    knebe a. , kravtsov a.  v. , gottlber s. , klypin a.  a. , 2000 , mnras , 317 , 630    khandai n. , bagla j.  s. , 2008 , arxiv:0802.3215 [ astro - ph ]    kravtsov a.  v. , klypin a.  a. , khokhlov a.  m. , 1997 , apjs , 111 , 73    kuhlman b. , melott a.  l. , shandarin s.  f. , 1996 , apj , 470 , l41    little b. , weinberg d.  h. , park c. , 1991 , mnras , 253 , 295    lucy l.  b. , 1977 , aj , 82 , 1013    ma c .- p . , 1998 , apj , 508 , l5    macfarland t. , couchman h.  m.  p. , pearce f.  r. , pichlmeier j. , 1998 , newa , 3 , 687    makino j. , 1991 , pasj , 43 , 621    makino j. , 2004 , pasj , 56 , 521    makino j. , 2002 , newa , 7 , 373    makino j. , 1990 , jcoph , 87 , 148    makino j. , fukushige t. , koga m. , namura k. , 2003 , pasj , 55 , 1163    matarrese s. , lucchin f. , moscardini l. , saez d. , 1992 , mnras , 259 , 437    melott a.  l. , shandarin s.  f. , splinter r.  j. , suto y. , 1997 , apj , 479 , l79    merritt d. , 1996 , aj , 111 , 2462    merz h. , pen u .-",
    "l . , trac h. , 2005 , newa , 10 , 393    miller r.  h. , 1983 , apj , 270 , 390    monaghan j.  j. , lattanzio j.  c. , 1985 , a&a , 149 , 135    monaghan j.  j. , 1992 , ara&a , 30 , 543    nityananda r. , padmanabhan t. , 1994 , mnras , 271 , 976    oshea b.  w. , nagamine k. , springel v. , hernquist l. , norman m.  l. , 2005 , apjs , 160 , 1    padmanabhan t. , 2002 , theoretical astrophysics , volume iii : galaxies and cosmology .",
    "cambridge university press .",
    "padmanabhan t. , 1996 , mnras , 278 , l29    padmanabhan t. , cen r. , ostriker j.  p. , summers f.  j. , 1996 , apj , 466 , 604    peacock j.  a. , dodds s.  j. , 1996 , mnras , 280 , l19    peacock j.  a. , dodds s.  j. , 1994 , mnras , 267 , 1020    peacock j.  a. , 1999 , cosmological physics , cambridge university press    peebles p.  j.  e. , 1980 , the large - scale structure of the universe , princeton university press    peebles p.  j.  e. , 1974 , a&a , 32 , 391    percival w.  j. , et al . , 2007 , apj , 657 , 645    power c. , knebe a. , 2006 , mnras , 370 , 691    prasad j. , 2007 , japa , 28 , 117    price d.  j. , monaghan j.  j. , 2007 , mnras , 374 , 1347    ray s. , bagla j.  s. , 2004 , astro , arxiv : astro - ph/0405220    romeo a.  b. , agertz o. , moore b. , stadel j. , 2008 , apj , 686 , 1    sahni v. , coles p. , 1995 , phr , 262 , 1    salmon j.  k. , warren m.  s. , 1994 , jcoph , 111 , 136    smith r.  e. , et al . , 2003 , mnras , 341 , 1311    spergel d.  n. , et al . , 2007 , apjs , 170 , 377    splinter r.  j. , melott a.  l. , shandarin s.  f. , suto y. , 1998 , apj , 497 , 38    springel v. , yoshida n. , white s.  d.  m. , 2001 , newa , 6 , 79    springel v. , hernquist l. , 2002 , mnras , 333 , 649    springel v. , 2005 , mnras , 364 , 1105    springel v. , et al . , 2005 , natur , 435 , 629    suisalu i. , saar e. , 1995 , mnras , 274 , 287    szebehely v. , peters c.  f. , 1967 , aj , 72 , 1187    thacker r.  j. , couchman h.  m.  p. , 2006",
    ", cophc , 174 , 540    theis c. , 1998 , a&a , 330 , 1180    theuns t. , 1994 , cophc , 78 , 238    thibaut j. , pichon c. , sousbie t. , prunet s. , pogosyan d. , 2008 , mnras , 387 , 397    wadsley j.  w. , stadel j. , quinn t. , 2004 , newa , 9 , 137    xu g. , 1995 , apjs , 98 , 355    yoshikawa k. , fukushige t. , 2005 , pasj , 57 , 849    zeldovich y.  b. , 1970 , a&a , 5 , 84    zhan h. , 2006 , apj , 639 , 617",
    "one can integrate the poisson equation for a given kernel to obtain the softened two - body potential kernel . for the case of the cubic spline kernel",
    "we have the expression for the two - body potential kernel @xmath92 and the regular two - body force @xmath93 : ( , ) & = & \\ {          . [ force_fixedh ] for variable or local smoothing length @xmath94",
    "there will be an additional term given in eqs.(10 - 12 ) for which one needs to compute @xmath95 , @xmath96 and @xmath97 for the cubic spline kernel these expressions are : & = & \\ {"
  ],
  "abstract_text": [
    "<S> cosmological -body simulations are used for a variety of applications . indeed progress in the study of large scale structures and galaxy formation </S>",
    "<S> would have been very limited without this tool . for nearly twenty years </S>",
    "<S> the limitations imposed by computing power forced simulators to ignore some of the basic requirements for modeling gravitational instability . </S>",
    "<S> one of the limitations of most cosmological codes has been the use of a force softening length that is much smaller than the typical inter - particle separation . </S>",
    "<S> this leads to departures from collisionless evolution that is desired in these simulations . </S>",
    "<S> we propose a particle based method with an adaptive resolution where the force softening length is reduced in high density regions while ensuring that it remains well above the local inter - particle separation . </S>",
    "<S> the method , called the adaptive treepm , is based on the treepm code . </S>",
    "<S> we present the mathematical model and an implementation of this code , and demonstrate that the results converge over a range of options for parameters introduced in generalizing the code from the treepm code . </S>",
    "<S> we explicitly demonstrate collisionless evolution in collapse of an oblique plane wave . </S>",
    "<S> we compare the code with the fixed resolution treepm code and also an implementation that mimics adaptive mesh refinement methods and comment on the agreement , and disagreements in the results . </S>",
    "<S> we find that in most respects the atreepm code performs at least as well as the fixed resolution treepm in highly over - dense regions , from clustering and number density of haloes , to internal dynamics of haloes . </S>",
    "<S> we also show that the adaptive code is faster than the corresponding high resolution treepm code .    </S>",
    "<S> gravitation , methods : n - body simulations , cosmology : large scale structure of the universe </S>"
  ]
}