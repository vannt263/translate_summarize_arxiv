{
  "article_text": [
    "during nuclear physics experiments , data are usually stored in the so - called `` list - mode '' , that is in the sequence of their occurrence which will be called `` time - ordered '' in this article .",
    "this is the most natural if not the only reasonable way to store measured data during the experiment .",
    "but the analysis of time - ordered data might not be efficient if the interesting nuclei represent only a small portion of the events in the dataset . in this case",
    ", the analysis of time - ordered data means that , to select a nucleus of interest with varying conditions , the whole dataset has to be read with the majority of the data being ignored after finding out that they do not match the selection criteria .",
    "as all data have to be read , the analysis time is proportional to the size of the whole dataset , independent of how much of the data are actually used .",
    "the aim of the work presented here was to develop a software that allows to store event data in a way that allows to reduce the amount of data read unnecessarily and thereby to reduce analysis time .",
    "although the software has been developed with particle - identification in nuclear physics experiments in mind , it is not restricted to this type of data .",
    "note that for high - multiplicity @xmath0-ray data , cromaz et  al .",
    "@xcite have developed _ blue _ , a database program that sorts the events by @xmath0-ray energies .",
    "it allows fast access to events identified by a set of @xmath0-ray energies .",
    "blue _ database is based on a very similar principle but focused and specialised on high - multiplicity @xmath0-ray data .    the standard way to improve the speed of analysis is to do a `` pre - sorting '' : the time - ordered dataset is split `` manually '' into different subsets , e.g. into one subset for each nucleus .",
    "using the sorting software presented here has some advantages over this technique : the work of dividing into subsets is done mostly automatic  only quantities suitable for selection have to be calculated by user code  and all data are stored in one file for convenient handling and interactive access .",
    "furthermore also the selection criteria are flexible , as changing them does not require re - reading the time - ordered dataset .",
    "to reduce the number of data being read unnecessarily , the data are partially ordered and indexed with respect to some quantities @xmath1 .",
    "the @xmath1 might , e.g. , represent time - of - flight or energy - loss values allowing to identify particles .",
    "these values @xmath2 with @xmath3 have to be extracted from the data by user code .",
    "the @xmath4 denote the sets of values for the @xmath1 , e.g. sets of integer and floating - point numbers .",
    "the sorting procedure divides the space @xmath5 into sub - volumes  they are called `` buckets '' here  which contain events with similar values of the @xmath1 . the dimensions of each `` bucket '' sub - volume are stored in an index when the sorting process is finished . when reading the dataset applying selection criteria on the @xmath1 , the index is used to identify the buckets which have to be looked at .",
    "only the events in those buckets are actually read  no time is spent reading the events in the other buckets , as they are then known not to match the selection criteria .    in more detail ,",
    "the sorting procedure works as follows .",
    "a user code reads events from the list - mode storage and calculates the @xmath6 quantities @xmath1 event by event .",
    "each event is then handed over to the sorting program which sorts them into a tree structure of buckets .",
    "the bucket tree is built while the time - ordered dataset is read . in the beginning",
    "there is just one bucket with number @xmath7 at depth @xmath8 which represents the full space @xmath9 .",
    "the program starts putting events into it until it contains @xmath10 events , the user - defined maximum number of events a bucket may contain . whenever a bucket number @xmath11 with depth @xmath12 contains @xmath10 events , the bucket is split and assigned @xmath13 child buckets with numbers @xmath14 and depth @xmath15 whose volumes are @xmath16 with @xmath17 \\cap    \\mathbb{q}_k ) \\cdots \\times \\mathbb{q}_m , \\\\",
    "i=1,2,\\dots , n_l+1 , \\ ; l_{b,0 } = -\\infty , \\ ; l_{b , n_l+1 } = + \\infty.\\end{gathered}\\ ] ] here , @xmath18 so that with increasing depth e.g. for @xmath19 the volumes are divided alternatingly along the @xmath20 and @xmath21 axes ( see fig .",
    "[ fig : tree ] ) .",
    "the limiting values @xmath22 for the child buckets of @xmath11 are calculated from an analysis of the @xmath1 values of the events in bucket @xmath11 . after creating the child buckets , as the last step of splitting ,",
    "the events from the full bucket @xmath11 are sorted into the child buckets @xmath14 . applying this procedure repeatedly ,",
    "a tree of buckets is created where each bucket at depth @xmath15 contains events or has children with a more limited range in the value @xmath1 ( with @xmath18 ) than the events in the parent bucket at depth @xmath12 .     and",
    "@xmath23 with @xmath20 on the ordinate and @xmath21 on the abscissa .",
    "each line represents the limit @xmath24 for the two child buckets .",
    "thicker lines indicate a lower depth .",
    ", width=226 ]    during the construction of the tree , the data of all buckets have to be kept in memory for fast splitting .",
    "as the amount of available memory will not be sufficient to keep all events , the procedure is stopped when a predefined number of buckets @xmath25 is created : the splitting of buckets is stopped and events are immediately sorted into the appropriate buckets and written to disk .",
    "the numbers @xmath25 , @xmath10 and @xmath26 have to match the amount of available memory . in the example described below , @xmath27 , @xmath28 and @xmath23 were used and for simplicity the single limit was determined as @xmath29 for the @xmath1 of the events in the bucket being split .",
    "finally , when the end of the input is reached , an index is written where all the limits @xmath22 are registered . the file obtained this way",
    "contains the events partially sorted by the @xmath1 . the depth and",
    "the size of the buckets may vary widely and will reflect the distribution of the sorted quantities @xmath1 , especially if these quantities are correlated .    as the tree structure is built up from a subset of the events ,",
    "it is important that the distribution of the events is the same throughout the dataset .",
    "feeding data already sorted by any of the @xmath1 into the program will produce a database without much or even without any gain in access speed .",
    "neither does it make sense to select a monotonously increasing value as one of the ordering quantities @xmath1 .",
    "furthermore , the sorting requires that the data are in the form of self - contained units ( events )  as they are re - ordered , any information contained in their order is lost .",
    "if the granularity of the buckets is not sufficient after the first sorting run , the number of buckets can be increased using a second program that builds a new tree for each of the childless buckets in the input database .",
    "it works very similar to the initial sorting program , except that it reads from a different source  database buckets instead of the time - ordered dataset  and creates child buckets of the input bucket .",
    "again the required constancy of the distribution of the events is used .    for a query with constraints on the desired range of one or more @xmath1 ,",
    "only those buckets need to be looked at where the limits  which are read from the index  overlap with the desired @xmath1 ranges . therefore ,  depending on the query ",
    "only a part of the buckets and thus a portion of the data whose size is approximately proportional to the number of selected events has to be read",
    ". this can be much faster than reading the whole list - mode dataset , especially if the selected @xmath1 region contains only a small number of events .",
    "the present implementation of the sorting code , written in the ` c++ ` programming language , is flexible regarding the structure of the events that are to be stored : data of integer ( signed and unsigned 1- , 2- or 4-byte ) or floating point type can be stored in almost any order and with almost arbitrary names for later interactive retrieval .",
    "arrays of values can be defined with either fixed or variable size , e.g. to accommodate @xmath0-ray data with varying multiplicity . to reduce the size of the produced database ,",
    "the data are compressed using the standard compression library zlib  @xcite .",
    "an easy to use interface to root  @xcite with a query format similar to ttree::draw can be used to interactively produce histograms and matrices .",
    "this interface allows using the root graphical cuts to select pairs of the @xmath1 .",
    "note that root trees can store data having a tree - like event structure ( which may be much more complex than the currently implemented event structures of the database sorting program ) , but that root trees , being a general and very efficient list - mode storage format , do not have an index for data access as described here . for non - interactive queries , it is possible to use a c++ interface to access the stored data .    the database can be extended with `` friends '' , these are files containing additional data for all the events in a database .",
    "for example , @xmath0-ray data produced with different calibration coefficients might be stored in different friend files , so that the calibrations can be reviewed without making copies of the data for the other detectors .",
    "it is also possible to have friends calculating values on - the - fly , e.g. lookup of detector positions if only the detector number has been stored .",
    "the use of these friends can reduce the size of the database significantly .",
    "identification is shown , on the ordinate the energy loss measured in the ionisation chamber for the charge identification , both in arbitrary units .",
    "each blob corresponds to one nuclear species .",
    ", width=226 ]    the software has been developed and is being used for the analysis of data taken in an experiment at ganil .",
    "the aim of the experiment was to determine the energy of the first @xmath30 state in @xmath31ca by observation of the @xmath0-rays from the @xmath32 transition  @xcite . in the experiment",
    "a @xmath33ca primary beam of @xmath34mev / u was fragmented in a primary carbon target in the sissi device , producing a cocktail of nuclear species . out of these products , @xmath35ca along with ",
    "due to insufficient separation  some other nuclear species , was selected by the @xmath36 spectrometer of ganil , resulting in a secondary `` @xmath35ca '' beam . on a secondary be target , the @xmath35ca beam underwent few - nucleon - removal , again producing many different nuclei with @xmath31ca among them .",
    "these nuclei were identified using the spectrometer speg  @xcite , by time - of - flight and @xmath37 measurements to determine their mass over charge ratio @xmath38 , and the energy loss in an ionisation chamber to determine their charge .",
    "a typical resulting identification matrix is shown in figure  [ fig : pid ] . to detect @xmath0 rays , 74 baf@xmath39 detectors of the `` chteau de cristal ''  @xcite and three small exogam ge clover detectors",
    "@xcite were placed around the target .    to improve the particle identification in speg , not only the signal from the ionisation chamber but",
    "also the charge deposited in the four drift chambers ( which are mainly used to determine particle positions ) can be used to determine the charge of the ions .",
    "similarly , for the @xmath38 identification both the time - of - flight measurement and the energy deposited in the beam - stopping scintillator were used .",
    "these four parameters were used as the @xmath1 for sorting and indexing : the ionisation chamber signal as @xmath20 , the time - of - flight signal as @xmath21 , the charge deposited in the drift chambers as @xmath40 and the energy deposited in the scintillator as @xmath41 , thus alternating between mass and charge identification . for each event , information from other detectors was stored along with the @xmath1 , e.g. time - of - flight information for the incoming secondary beam , trigger information , the @xmath0 ray energies and times of detection measured by the baf@xmath39 detectors .    using the sorting software , around 250000 buckets",
    "were filled for @xmath42 events in two steps : in the first step , the list - mode data were read and in the second step , the granularity of buckets was increased .",
    "an overview of query times on the author s computer is given in fig .",
    "[ fig : times ] .",
    "as can be seen , the query time is very small for selections of a small number of events . for @xmath31ca ,",
    "the query time is slightly less than 2s .",
    "a software has been developed which allows indexing and partial sorting of data .",
    "query times for a subset of such an indexed dataset are roughly proportional to the size of the queried subset .",
    "this may be a large speed - up compared to reading time - ordered data .",
    "the programs have proven to be very useful for the analysis of data from an experiment on @xmath31ca performed at ganil .",
    "the author wishes to thank w.  korten , a.  grgen ( both cea saclay ) , f.  azaiez ( ipn orsay ) and h.  hbel ( hiskp bonn ) for making possible his stay at the cea saclay after the ganil experiment and for discussing this work .",
    "furthermore , he wants to thank all the contributors to the experiment at ganil for their support ."
  ],
  "abstract_text": [
    "<S> in nuclear physics experiments involving in - flight fragmentation of ions , usually a large number of different nuclei is produced and various detection systems are employed to identify the species event by event , e.g. by measuring their specific energy loss and time - of - flight . for such cases  not necessarily limited to nuclear physics  where subsets of a large dataset can be identified using a small number of measured signals a software for fast access to varying subsets of such a dataset has been developed . </S>",
    "<S> the software has been used successfully in the analysis of a one neutron knock - out experiment at ganil . </S>"
  ]
}