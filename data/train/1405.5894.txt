{
  "article_text": [
    "optimization problems are ubiquitous in science and engineering and many optimization problems that appear in physics , such as finding the ground state of an ising spin glass , are np - hard @xcite .",
    "even though no general algorithms exist to solve such problems in polynomial time , various numerical approaches have been developed in the past to construct approximate solutions , however .",
    "here we present an approach to find extremal points of complicated functionals using flow equations .",
    "this method combines ideas of homotopy continuation and bayesian inference .",
    "homotopy continuation is a method to solve optimization problems by constructing a one parameter set of solutions which smoothly connect the known extremum of a solvable problem to the extremum of the functional of interest @xcite .",
    "it has been shown rigorously that this method is able to locate all extremal points for certain problem classes with polynomial nonlinearities @xcite . while homotopy continuation methods are only starting to get used in physics @xcite , it is not always obvious to find a solvable reference problem that is suitable as a starting point to construct a homotopy . here",
    "we argue that bayesian inference @xcite can be used to define such a solvable reference problem in a very general way , in particular for non - polynomial problems , as long as one is interested in isolated ( global ) extremal points .",
    "the bayesian approach is based on defining a prior probability , which is updated by new information .",
    "in addition we perform a continuous update of the prior during the homotopy flow .",
    "this allows to derive a flow equation for the optimization parameters which has fixed points at extremal points of the minimizing functional .",
    "moreover , the bayesian prior only enters the flow equation as an initial condition .",
    "the paper is outlined as follows : in sec .",
    "[ sec1 ] we present the flow equation method in general form and apply it to three examples from theoretical condensed matter physics in subsequent sections . in sec .",
    "[ sec2 ] it is used for numerical analytic continuation , whereas sec .",
    "[ sec3 ] describes how this approach can be applied to find ground - states of classical ( or variational ground - states of quantum ) frustrated ising models . in all three cases the flow equation method gives comparable or better results than standard techniques",
    "here we introduce the flow equation method in its most general functional form and apply it in a discretized version later on .",
    "suppose we want to find the minimum of an energy functional @xmath0 $ ] with respect to the function @xmath1 of a real variable @xmath2 .",
    "for the rest of the paper it is crucial that @xmath1 is positive , which can be achieved in any case after a reparametrization .",
    "a direct solution of the equation @xmath3 determines all the extremal points , but is not practically feasible in most cases .",
    "we thus proceed by constructing a flow equation which finds minima of the functional @xmath0 $ ] directly .    using bayes theorem",
    "we can recast our minimization problem in a probabilistic form .",
    "we wish to maximize the posterior probability @xmath4 , i.e.  the probability to find a function @xmath5 given that it minimizes the energy functional , where @xmath6 $ ] .",
    "quite generally bayes theorem expresses the posterior probability to find @xmath5 conditioned on an arbitrary energy @xmath7 as @xcite @xmath8 where the likelihood function @xmath9)$ ] is the probability to find an energy @xmath7 given a function @xmath5 and we define the dirac @xmath10 function via @xmath11 - \\mathcal{e }   \\big| / \\sigma)}{2 \\sigma }   \\ , \\label{likelihood}\\ ] ] where @xmath12 defines the width of the exponential distribution .",
    "note that this representation of the @xmath10 function is particularly suited for our purpose , but not essential .",
    "lastly , the prior probability @xmath13 expresses our initial guess for the function @xmath5 .",
    "the basic idea of the maximum entropy ( maxent ) principle is to express the prior probability in the form @xcite",
    "@xmath14 \\big ) \\ , \\label{prior}\\ ] ] where @xmath15 = \\int dx   \\left ( f(x ) - f_0(x ) - f(x ) \\ , \\ln \\frac{f(x)}{f_0(x ) } \\right )   \\label{entropy}\\ ] ] is a shannon or von - neumann entropy and @xmath16 is an arbitrary coefficient that weighs the relative importance of the prior probability with respect to the likelihood function .",
    "here @xmath17 denotes the prior , i.e.  our initial guess for the solution of the minimization problem .",
    "note that the function @xmath5 has to be positive , otherwise the entropy is not well defined .",
    "the entropic form of the prior probability ensures that no bias is introduced apart from the initial guess @xmath18 .    in the following we are interested in the specific instance where we want to maximize the posterior probability @xmath4 .",
    "from eqs .  , and it is clear that the the posterior probability is maximized by finding the minimum of the functional @xmath19 = e[f(x ) ] \\ , t - s[f(x ) ] \\ , ( 1-t ) \\ , \\label{eqq}\\ ] ] where we used the specific choice @xmath20 for the coefficient in eq .  .",
    "again , the parameter @xmath21 $ ] in eq",
    ".   weighs the relative importance of the prior probability with respect to the likelihood function .",
    "the entropy is maximal for @xmath22 , which thus corresponds to the minimum of the functional @xmath23 at @xmath24 . for @xmath25",
    "the minimum of @xmath23 corresponds to the minimum of @xmath26 .",
    "starting from eq .",
    "we can straightforwardly derive a flow equation for @xmath27 as a function of the homotopy parameter @xmath28 by requiring that @xmath1 minimizes the functional @xmath29 $ ] for all @xmath28 : @xmath30}{\\delta \\ !",
    "f(x ) } \\notag \\\\   & = & \\frac{\\delta q[f;t]}{\\delta \\ !",
    "f(x ) } + \\int dy \\ ,",
    "\\frac{\\delta^2 q[f;t]}{\\delta \\ !",
    "f(x ) \\delta \\ !",
    "f(y ) } \\ , \\delta \\ !   f(y ) + \\frac{\\delta \\partial_t q[f;t]}{\\delta \\ !",
    "f(x ) } \\delta t \\notag \\\\   & & + \\mathcal{o}(\\delta \\ !",
    "f^2 , \\delta t^2)\\end{aligned}\\ ] ] the first term on the r.h.s .",
    "vanishes by construction , since @xmath5 minimizes @xmath23 .",
    "we thus arrive at the flow equation ( for notational brevity we write @xmath31 ) @xmath32 note that this flow equation depends explicitly on the prior @xmath17 .",
    "this explicit dependence can be eliminated if the prior is continuously updated by setting @xmath33 during the homotopy flow . from this",
    "follows that @xmath34 using a discretized version of eq .  , which is more suitable for practical applications , the flow equation takes the final form ( defining @xmath35 for some discrete set @xmath36 ) @xmath37 this equation describes the flow of the variables @xmath38 as a function of @xmath28 towards a fixed point where the energy functional is minimal , i.e.  @xmath39 with a positive hessian matrix @xmath40 . note that the prior enters only as an initial condition .    a numerical solution of eq .",
    "is straightforward , and the computationally most costly step is the numerical inversion of the hessian matrix @xmath41 .",
    "since the majority of interesting minimization problems have many local minima , the success of the flow equation method to find the global minimum of @xmath42 $ ] depends on the possibility to choose an initial condition which lies in the basin of attraction of the fixed point corresponding to the global minimum .",
    "the flow equation preserves symmetries during the flow , which makes this method especially suited to find solutions where the global minimum is constrained by symmetries which can be enforced by choosing a proper initial condition ( we give an example in sec .",
    "[ sec3b ] ) .",
    "this is in contrast to traditional methods based on random updates , such as simulated annealing @xcite .",
    "note that the flow equation also has fixed points at @xmath43 , which is particularly useful for some applications , as will be shown in sec .",
    "[ sec2 ] .",
    "the continuous update of the prior can lead to a slower convergence than the standard homotopy continuation without update of the prior for some problems .",
    "in fact , it might happen that one does not reach the energy minimum during the flow from @xmath24 to @xmath25 . in this case",
    "the flow has to be restarted at @xmath24 with the output of the previous run as initial condition until one converges to the minimum .",
    "alternatively it is also possible to rescale the energy term with a large pre - factor , which leads to a faster convergence .",
    "by contrast , homotopy continuation guarantees to reach an energy minimum at @xmath25 when using eq .   without prior update .",
    "it is important to emphasize , however , that the continuous prior update has practical advantages in many cases . indeed ,",
    "when solving the flow equation numerically , a truncation error will be accumulated due to the finite step - size .",
    "the advantage of using the flow equation is that it is less prone to truncation errors , because the flow is directed towards the fixed point @xmath44 . without prior update the truncation error",
    "can be kept small only by reducing the step - size , which is computationally costly for problems with a large number of variables .",
    "the question which version of the flow equation works better thus depends on the problem at hand .    for the problem of numerical analytic continuation to be discussed in sec .",
    "[ sec2 ] , the continuous update of the prior has an additional conceptual advantage . in this case",
    "the flow has to be stopped at some @xmath45 , because the hessian @xmath40 is singular .",
    "for this reason the result depends explicitly on the prior in conventional maxent approaches .",
    "by contrast , using the dependence on the prior is only implicit through the initial condition .",
    "the possibility to get stuck in a local minimum is inherent to all numerical minimization algorithms and the flow equation approach is not an exception . compared to standard gradient - based methods this approach is less sensitive to the choice of initial conditions , however , and the probability to find the global minimum is substantially higher for the problems we ve studied so far .",
    "finally , we note that the functional @xmath23 in eq .   takes the form of a free energy . the flow equation approach can thus be viewed as a deterministic annealing method , where the energetic ground - state is found by following the minimum of the free energy while decreasing temperature @xcite .",
    "following the derivation of the flow equation above , it is obvious that our starting point is reminiscent of the maxent method which is used routinely to analytically continue imaginary time data to real frequencies @xcite .",
    "our approach can be viewed as an alternative method to solve the maxent equations numerically .",
    "numerical analytic continuation can be reduced to the problem of finding the spectral function @xmath46 as function of real frequency @xmath47 , given numerical green s function data @xmath48 on the imaginary ( matsubara ) axis .",
    "they are related by the cauchy integral @xmath49 after discretising the integral , the problem of finding @xmath46 amounts to a matrix inversion problem with the severe complication that the matrix is almost singular : many eigenvalues are very close to zero and thus tiny numerical errors blow up exponentially in the matrix inversion process .",
    "numerical analytic continuation is thus per se an ill defined mathematical problem .",
    "nevertheless , ideas have been put forward to regularize the matrix inversion without introducing too many artificial features .",
    "the most widely used approach to analytically continue noisy green s function data from monte carlo simulations is the maxent method @xcite , which can be derived using bayesian inference as outlined above , but other methods have been put forward as well @xcite .    fitting the spectral function @xmath46 to the green s function data @xmath50 amounts to minimizing the mean square distance @xmath51 where @xmath52 denotes the standard deviation of the noisy data @xmath48 from the expected value .",
    "finding the minimum of @xmath53 via @xmath54 leads immediately to the ill defined matrix inversion problem in eq .  .",
    "in order to regularize the inversion maxent adds an entropy term and minimizes @xmath55 = - \\kappa \\ ,   s[a ] + \\chi^2[a]/2",
    "$ ] instead .",
    "again , the entropy term depends on a prior @xmath56 . apart from choosing the prior",
    ", the main problem in traditional maxent is to determine the weight parameter @xmath16 and the standard approach nowadays is to use bryan s algorithm @xcite .     including statistical noise with @xmath57 .",
    "red line with squares : numerically reconstructed spectral function @xmath46 obtained using the flow equation method .",
    "blue dashed line with dots : historic maxent @xcite result for comparison .",
    "the orange dash - dotted line shows the spectral function obtained using the flow equation method for noiseless green s function data .",
    "a flat prior spectrum @xmath58 has been used in all cases . ]    here we solve the analytic continuation problem by minimizing @xmath53 using the flow - equation after discretising the integral in .",
    "green s function data from monte carlo simulations has a statistical error , thus we do nt want to follow the flow to the fixed point @xmath54 , as this amounts to fitting the noise . moreover , the flow equation is unstable close to @xmath25 , where the hessian is almost singular .",
    "consequently , we stop the flow at some @xmath28 and we face a similar problem as determining the weight @xmath16 in the traditional maxent approach .",
    "the naive criterion of stopping the flow when @xmath59 is similar to the so - called historical maxent scheme @xcite . for the case of noisy green s function data",
    "we rather choose to stop the flow when @xmath60 is minimal .",
    "indeed , while @xmath53 is monotonically decreasing during the flow , the norm of the gradient of @xmath53 with respect to @xmath61 has a minimum at some point for noisy data , if the problem is sufficiently oversampled ( i.e. the number of data points @xmath48 is much larger than the number of sampling points form the discretisation of @xmath46 ) .",
    "we identify this minimum with the point beyond which one starts to over - fit the noisy data . for clean data without noise",
    "we terminate the flow before the inversion of the hessian becomes numerically unstable . in passing we",
    "note that the @xmath62 term in eq .  , which regularizes the matrix inversion , is precizely the discrete fisher information metric @xcite .",
    "in order to check the applicability of our method , we perform numerical analytic continuation for a simple model spectral function of the form @xmath63 we generate green s function data from this model for @xmath64 using eq .   and add random gaussian noise with @xmath65 .",
    "the results of the flow equation method are shown in fig .  [",
    "fig : ac ] together with results obtained with the historic maxent approach . in all cases",
    "the same flat prior spectral function @xmath66 has been used .",
    "[ fig : ac ] shows that the flow equation method gives slightly better results compared to historic maxent .",
    "the flow equation is particularly useful when the spectral function is zero in some frequency interval , i.e.  if there is a gap in the spectrum , because eq .   has fixed points at @xmath43 . by contrast ,",
    "standard maxent has problems if the spectral function is close to zero , because the entropy term diverges .",
    "note that the additional fixed points at @xmath43 are only approached asymptotically and thus it is unlikely that the flow is forced into a poor minimum .",
    "indeed , for @xmath67 the flow equation simplifies considerably and has the solution @xmath68 with @xmath69 .",
    "moreover , the prior spectrum enters the flow equation only as an initial condition . for this reason we can expect that different priors lead to the same spectral function as long as the initial conditions lie in the basin of attraction of the same fixed point .",
    "consequently , our method might be useful as an alternative to pad approximants for data without statistical noise @xcite .",
    "and magnetization @xmath70 for 100 instances of random @xmath71 s , obtained after minimizing for random gaussian nearest neighbor @xmath71 s with zero mean and unit variance , @xmath72 and @xmath73 on a square lattice with @xmath74 sites and periodic boundary conditions .",
    "energies are in units of @xmath75 . ]",
    "now we re going to apply the flow equation to find variational ground states of frustrated ising models with random- or long - range antiferromagnetic interactions in a combined longitudinal- and transverse field on a two dimensional square lattice .",
    "the hamiltonian has the form @xmath76 where @xmath77 and @xmath78 are pauli matrices on lattice site @xmath79 , and the exchange couplings @xmath71 are either restricted to nearest neighbors and randomly drawn from a gaussian distribution with zero mean and unit variance , or decrease with a power law @xmath80 as a function of distance between the two sites , where @xmath81 denotes the position of lattice site @xmath79 . as variational ansatz for the ground state we use the most general product state @xmath82 where @xmath83 and @xmath84 are the two eigenstates of @xmath85 .",
    "note that this ansatz gives the exact ground - state in the classical ising limit @xmath86 , but does nt include quantum correlations between the spins . in the ground - state",
    "the parameters @xmath87 and @xmath88 can be chosen to be real . using the normalisation condition",
    "@xmath89 we reduce the problem to a minimization of the energy with respect to probabilities @xmath90 $ ] to be in the spin - up state @xmath91 & = &   \\sum_{i < j } j_{ij } ( 2 f_i   - 1 ) ( 2 f_j   - 1 ) - h_z \\sum_i ( 2 f_i - 1 ) \\notag \\\\ & & - 2 h_x \\sum_i \\sqrt{f_i ( 1-f_i ) } \\ . \\label{ising}\\end{aligned}\\ ] ] in the following we compare results of minimizing with the flow equation method , simulated annealing and other gradient based methods .      as a first example we choose random nearest - neighbor @xmath71 s from a gaussian distribution with zero mean and unit variance . in this case",
    ".   represents an edwards - anderson model in a combined longitudinal- and transverse - field , which is a prime example of a model for spin - glasses @xcite .",
    "we minimize on a square lattice with @xmath74 sites and periodic boundary conditions , using the flow equation method as well as simulated annealing . in fig .",
    "[ fig : hist ] we show histograms of ground - state energy and magnetisation in z - direction @xmath92 , obtained by minimizing @xmath93 different random instances , starting from random initial states with average magnetisation close to @xmath94 . for each instance",
    "we use 10 different initial conditions and choose the solution with the lowest energy . shown",
    "are results for @xmath72 and @xmath73 .",
    "average energies , magnetizations and their variances are listed in table [ tab1 ] .",
    "the results are comparable , even though the flow equation gives slightly lower energies .",
    "its main advantage , however , is a significant speed - up in the simulation time by a factor @xmath95 as compared to simulated annealing .",
    "note that eq .",
    "was solved using a two - stage runge - kutta scheme ( heun s method ) with adaptive step size .",
    "simulated annealing was performed using the gsl library @xcite , where the temperature was lowered from @xmath96 to @xmath97 using a damping factor @xmath98 with @xmath99 iterations at each temperature and a maximum step size of @xmath100 .",
    ".comparison between the flow equation method and simulated annealing for the ising spin glass problem defined in sec .",
    "[ sec4a ] . listed",
    "are the mean energy @xmath101 and magnetisation @xmath85 corresponding to the histograms shown in fig .",
    "[ fig : hist ] , together with their variances . [ cols=\"^,^,^,^,^\",options=\"header \" , ]     [ tab1 ]      , slightly above the saturation field where all spins point down .",
    "plotted is the probability @xmath102 to find a spin pointing up on a given site of a @xmath103 lattice with open boundary conditions .",
    "the probabilities were obtained by minimizing eq . with dipolar interactions for @xmath104 and @xmath105 ( see text ) .",
    "the corresponding energies are @xmath106 ( left ) and @xmath107 ( right ) .",
    "energies are measured in units of the nearest - neighbor exchange coupling @xmath108 . ]    finally , in fig .",
    "[ fig : dipolar ] we show results of minimizing eq .   with dipolar interactions @xmath109 on a square lattice of @xmath110 sites with open boundary conditions at large negative longitudinal fields @xmath111 slightly above the saturation field where all spins point down . shown",
    "are results for @xmath112 and @xmath113 .",
    "finding the ground - state in the regime close to the saturation field is particularly hard , because in the classical limit @xmath86 this corresponds to finding the minimum energy configuration of classical dipoles on a lattice @xcite .",
    "the up - spins want to maximize their distance and form a triangular lattice , which is not possible due to the underlying square lattice .",
    "incommensurability issues thus play an important role , resulting in many local energy minima .    in fig .",
    "[ fig : dipolar ] we compare the flow equation method with a quasi - newton bfgs algorithm @xcite . for the results shown here a continuous update of the prior",
    "was not performed , because the convergence turned out to be slightly better . in both cases",
    "we initialize all @xmath114 and find that our flow equation leads to a state with energy @xmath106 , which is always lower than the state obtained using the bfgs algorithm , where the lowest energy state we found has @xmath107 ( energies are measured in units of the nearest - neighbor exchange coupling @xmath115 ) . moreover , the results of the bfgs algorithm are extremely sensitive to the initial condition and one easily ends up in a local minimum with high energy , whereas our flow equation is rather insensitive to the choice of initial conditions . as can be seen in fig .  [",
    "fig : dipolar ] , the up - spins try to maximize their distance and form a regular arrangement which is pinned by boundary effects .",
    "we also tried simulated annealing to find the variational ground - state , but the results were rather poor with energies around @xmath116 .",
    "note that the model in eq .   with dipolar interactions on a square lattice with open boundary conditions",
    "is symmetric under rotations by 90 degrees , as well as inversions about the x- , y - axis and the diagonals .",
    "the flow equation only depends on derivatives of eq .   and thus respects the symmetries of the problem .",
    "accordingly it preserves the symmetries during the flow , if the initial condition is symmetric as well . for the problem at hand",
    "it is not known wether the ground - state breaks these symmetries , but the symmetric solutions we found were always lower in energy than solutions found by starting from a random initial condition .",
    "we presented a multidimensional minimization method which combines ideas of homotopy continuation and the maximum entropy principle and applied it successfully to problems in condensed matter physics .",
    "we note that this flow equation method has some similarities with quantum annealing @xcite or adiabatic quantum computation @xcite . in our approach",
    "we adiabatically deform a product state to determine the ground state of a classical ising model , rather than following the exact ground - state of the full quantum model adiabatically to the ising limit , starting from large @xmath117 ( for a similar idea see also @xcite ) .",
    "finally we note that it is straightforward to generalize the flow equation to a stochastic differential equation by adding a random force term which might be able to kick the flow out of a local minimum . by properly choosing a random force term which vanishes sufficiently fast for @xmath118 it might possible to construct a method which has similarities to simulated annealing and which has an even higher success rate finding the global minimum .",
    "we leave such extensions of this method open for further investigation .",
    "we thank a.m. luchli and w. lechner for discussions and w. zwerger for comments on the manuscript .",
    "this work was supported by the erwin - schrdinger fellowship j 3077-n16 of the austrian science fund ( fwf ) ."
  ],
  "abstract_text": [
    "<S> we develop a method for multidimensional optimization using flow equations . </S>",
    "<S> this method is based on homotopy continuation in combination with a maximum entropy approach . </S>",
    "<S> extrema of the optimizing functional correspond to fixed points of the flow equation . </S>",
    "<S> while ideas based on bayesian inference such as the maximum entropy method always depend on a prior probability , the additional step in our approach is to perform a continuous update of the prior during the homotopy flow . </S>",
    "<S> the prior probability thus enters the flow equation only as an initial condition . </S>",
    "<S> we demonstrate the applicability of this optimization method for two paradigmatic problems in theoretical condensed matter physics : numerical analytic continuation from imaginary to real frequencies and finding ( variational ) ground - states of frustrated ( quantum ) ising models with random or long - range antiferromagnetic interactions . </S>"
  ]
}