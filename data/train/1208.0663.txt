{
  "article_text": [
    "* programmable machines*. before presenting our results , let us summarize what is known about optimal machines for programmable discrimination",
    ". this will also allow us to introduce our notation and conventions .",
    "neglecting statistical fluctuations , the ts of size @xmath0 is given by a state pattern of the form @xmath7\\otimes[\\psi_1^{\\otimes n}]$ ] , where the shorthand notation @xmath8\\equiv|\\,\\cdot\\,\\rangle\\langle\\,\\cdot\\,|$ ] will be used throughout the paper , and where no knowledge about the actual states @xmath5 and @xmath6 is assumed ( the figure of merit will be an average over _ all _ states of this form ) .",
    "the qubit state that we wish to label ( the _ data _ qubit ) belongs either to the first group ( it is @xmath9 $ ] ) or to the second one ( it is @xmath10 $ ] ) .",
    "thus , the optimal machine must discriminate between the two possible states : either @xmath11_{ab}\\otimes[\\psi_1^{\\otimes n}]_{c}$ ] , in which case it should output the label @xmath3 , or @xmath12_{a}\\otimes[\\psi_1^{\\otimes ( n+1)}]_{bc}$ ] , in which case the machine should output the label @xmath4 . here and when needed for clarity , we name the three subsystems involved in this problem  @xmath13 ,  @xmath14 and  @xmath15 , where @xmath16 is the ts and  @xmath14 is the data qubit . in order to discriminate  @xmath17 from  @xmath18 , a joined two - outcome measurement , independent of the actual states @xmath5 and @xmath6 , is performed on all  @xmath19 qubits .",
    "mathematically , it is represented by a positive operator valued measure ( povm ) @xmath20 .",
    "the minimum average error probability of the quantum classification process is given by @xmath21 , where @xmath22 $ ] .",
    "this average can be cast as a @xmath23 group integral and , in turn , readily computed using schur s lemma to give @xmath24=\\parallel\\sigma^n_0-\\sigma^n_1\\parallel_1 \\label{delta},\\ ] ] where @xmath25 is the trace norm and @xmath26 are average states defined as @xmath27 in this paper  @xmath28 stands for the projector on the fully symmetric invariant subspace of @xmath29 qubits , which has dimension @xmath30 .",
    "sometimes , it turns out to be more convenient to use the subsystem labels , as on the right of  ( [ sigma states ] ) .",
    "the maximum in  ( [ delta ] ) is attained by choosing @xmath31 to be the projector onto the positive part of @xmath32 .    the right - hand side of  ( [ delta ] )",
    "can be computed by switching to the total angular momentum basis , @xmath33 , where @xmath34 and @xmath35 ( an additional label may be required to specify the way subsystems couple to give @xmath36 ; see below ) . in this ( jordan ) basis  @xcite",
    "the problem simplifies significantly , as it reduces to pure state discrimination  @xcite on each subspace corresponding to a possible value of the total angular momentum @xmath36 and magnetic number  @xmath37 . by  writing the various values  of the total angular momentum as  @xmath38",
    ", the final answer takes the form  @xcite : @xmath39 a simple asymptotic expression for large @xmath1 can be computed using euler - maclaurin s summation formula . after some algebra one obtains @xmath40 the leading order ( @xmath41 ) coincides with the average error probability @xmath42 , where @xmath43 is the minimum error in discrimination between the two _ known _ states @xmath44 and @xmath45 . + * learning machines*. the formulas above give an absolute lower bound to the error probability that can be physically attainable .",
    "we wish to show that this bound can actually be attained by a learning machine that uses a classical register to store all the relevant information obtained in the learning process regardless the size , @xmath0 , of the ts .",
    "a first hint that this may be possible is that the optimal measurement  @xmath46 can be shown to have positive partial transposition with respect to the partition ts / data qubit .",
    "indeed this is a necessary condition for any measurement that consists of a local povm on the ts whose outcome is fed - forward to a second povm on the data qubit .",
    "this class of one - way adaptive measurement can be characterized as : @xmath47 where the positive operators @xmath48 ( @xmath49 ) act on the hilbert space of the ts ( data qubit we wish to classify ) , and @xmath50 .",
    "the povm @xmath51 represents the learning process , and the parameter @xmath52 , which a priori may be discrete or continuous , encodes the information gathered in the measurement and required at the classification stage . for each possible value of  @xmath52",
    ", @xmath53 defines the measurement on the data qubit , whose two outcomes represent the classification decision . clearly , the size of the required classical memory will be determined by the information content of the random variable  @xmath52 . + * covariance and structure of @xmath54*. we will next prove that the povm @xmath55 , which extracts the relevant information from the ts , can be chosen to be covariant .",
    "this will also shed some light on the physical interpretation of the classical variable @xmath52 .",
    "the states ( [ sigma states ] ) are by definition invariant under a rigid rotation acting on subsystems @xmath16 and @xmath14 , of the form @xmath56 , where throughout this paper , @xmath57 stands for an element of the appropriate representation of su(2 ) , which should be obvious by context ( in this case @xmath58 , where @xmath59 is in the fundamental representation ) . since @xmath60 , the positive operator @xmath61 gives the same error probability as @xmath31 for _ any _ choice of @xmath57 [ as can be seen from , e.g. , eq .",
    "( [ delta ] ) ] . the same property thus holds for their average over the whole su(2 ) group @xmath62 , which is invariant under rotations , and where @xmath63 denotes the su(2 ) haar measure . by further exploiting rotation invariance ( see sec .  methods for full details ) @xmath64 can be written as @xmath65 u^{\\dagger}\\right)\\ ] ] for some positive operator @xmath66 , where we use the short hand notation @xmath67\\equiv{\\left|{{\\mbox{\\footnotesize${1\\over2}$}},{\\mbox{\\footnotesize${1\\over2}$}}}\\rangle\\!\\langle{{\\mbox{\\footnotesize${1\\over2}$}},{\\mbox{\\footnotesize${1\\over2}$}}}\\right|}$ ] .",
    "similarly , the second povm element can be chosen to be an average ,  @xmath68 , of the form  ( [ lm covariant povm ] ) , with @xmath69\\equiv{\\left|{{\\mbox{\\footnotesize${1\\over2}$}},-{\\mbox{\\footnotesize${1\\over2}$}}}\\rangle\\!\\langle{{\\mbox{\\footnotesize${1\\over2}$}},-{\\mbox{\\footnotesize${1\\over2}$}}}\\right| } $ ] instead of  .",
    "we immediately recognize @xmath70 to be of the form  ( [ lm povm ] ) , where @xmath59 , @xmath71 and @xmath72u^\\dagger$ ] play the role of  @xmath52 , @xmath48 and  @xmath49 respectively .",
    "hence , w.l.o.g .",
    "we can choose @xmath73 , which is a covariant povm with seed  @xmath66 .",
    "note that @xmath59 entirely defines the stern - gerlach measurement , @xmath74u^\\dagger , u[\\,\\downarrow\\,]u^\\dagger \\}$ ] , i.e. , @xmath59 specifies the direction along which the stern - gerlach has to be oriented .",
    "this is the relevant information that has to be retrieved from the ts and kept in the classical memory of the lm .",
    "covariance has also implications on the structure of  @xmath75 . in sec .",
    "methods , we show that this seed can always be written as @xmath76 where @xmath77 and @xmath78 ( @xmath29 ) stands for the total angular momentum  @xmath79 ( magnetic number @xmath80 ) of the qubits in the  ts . in other words ,  the seed is a direct sum of operators with a well defined magnetic number . as a result , we can interpret that @xmath75 points along the @xmath81-axis .",
    "the constrain  ( [ omega_m ] ) ensures  that @xmath55 is a resolution of the identity .    to gain more insight into the structure of  @xmath66 , we trace subsystems  @xmath14 in the definition of @xmath82 , given by the first equality in eq .",
    "( [ delta ] ) .",
    "for the covariant povm  ( [ lm covariant povm ] ) , rotational invariance enables us to express this quantity as @xmath83\\right\\}\\!=\\ !",
    "2\\max_\\omega { { \\rm tr}\\,}\\ ! ( \\gamma_\\uparrow \\omega ) , \\label{delta sdp}\\ ] ] where we have defined @xmath84 ( \\sigma^n_0-\\sigma^n_1)\\}\\ ] ] ( the two resulting terms in the right - hand side are the post - measurement states of  @xmath16 conditioned to the outcome  @xmath85 after the stern - gerlach measurement @xmath86 is performed on  @xmath14 ) and the maximization is over valid seeds ( i.e. , over positive operators  @xmath66 such that @xmath87 ) .",
    "we calculate  @xmath88 in sec .  methods . the resulting expression can be cast in the simple and transparent form @xmath89 where @xmath90 is the @xmath81 component of the total angular momentum operator acting on subsystem @xmath91 , i.e. , on the training qubits to which the human expert assigned the label  0/1 .",
    "( [ ja - jc ] ) suggests that the optimal @xmath66 should project on the subspace of @xmath13 ( @xmath15 ) with maximum ( minimum ) magnetic number , which implies that @xmath92 .",
    "an obvious candidate is @xmath93 , \\quad { \\left|{\\phi^0}\\right\\rangle } = \\sum_{j=0}^n \\sqrt{2j+1 } { \\left|{j,0}\\right\\rangle } .\\ ] ] below we prove that indeed this seed generates the optimal  lm  povm . +",
    "* optimality of the lm*. we now prove our main result : the povm @xmath94 , generated from the seed state in eq .",
    "( [ seed ] ) , gives an error probability @xmath95 equal to the minimum error probability  @xmath96 of the optimal programmable discriminator ,  eq .",
    "( [ optdisc ] ) .",
    "it is , therefore , optimal and , moreover , it attains the absolute minimum allowed by quantum physics .",
    "the proof goes as follows . from the very definition of error probability ,",
    "@xmath97 we have @xmath98\\!\\otimes\\!{[\\uparrow]}\\right)\\!+\\ !   { { \\rm tr}\\,}\\!\\!\\left(\\!\\openone_{\\!ab}\\!\\otimes\\!\\!\\openone_{\\!c } [ \\phi^0]\\!\\otimes\\![\\downarrow]\\right)\\over 2 d_n d_{n+1 } } , \\ ] ] where we have used rotational invariance .",
    "we can further simplify this expression by writing it as @xmath99 to compute the projections inside the norm signs we first write @xmath100 ( @xmath101 will be considered below ) in the total angular momentum basis @xmath102 , where the attached subscripts remind us how subsystems @xmath13 , @xmath14 and  @xmath15 are both _ ordered _ and _ coupled _ to give the total angular momentum  @xmath36 ( note that a permutation of subsystems , prior to fixing the coupling , can only give rise to a global phase , thus not affecting the value of the norm we wish to compute ) .",
    "this is a trivial task since @xmath103 , i.  e. , subsystems are ordered and coupled as the subscript @xmath104 specifies , so we just need the clebsch - gordan coefficients @xmath105    the projector @xmath106 , however , is naturally written as @xmath107 .",
    "this basis differs from that above in the coupling of the subsystems . to compute the projection @xmath108 we only need to know the overlaps between the two bases @xmath109 .",
    "6j - symbols provide this information as a function of the angular momenta of the various subsystems ( the overlaps are computed explicitly in sec .",
    "methods ) . using the clebsch - gordan coefficients and the overlaps between the two bases , it is not difficult to obtain @xmath110 an identical expression can be obtained for @xmath111 in the basis @xmath112 .",
    "to finish the proof , we compute the norm squared of  ( [ projection ] ) and substitute in  ( [ p^lm norm ] ) .",
    "it is easy to check that this gives the expression of the error probability in  ( [ optdisc ] ) , i.e. ,  @xmath113 . +",
    "* memory of the lm*. let us go back to the povm condition , specifically to the minimum number of unitary transformations needed to ensure that , given a suitable discretization @xmath114 of ( [ lm covariant povm ] ) , @xmath115u^\\dagger_\\mu\\}$ ] is a resolution of the identity for arbitrary  @xmath1 .",
    "this issue is addressed in  @xcite , where an explicit algorithm for constructing finite povms , including the ones we need here , is given . from the results there , we can bound the minimum number of outcomes of @xmath55 by @xmath116 .",
    "this figure is important because its binary logarithm gives an upper bound to the minimum memory required .",
    "we see that it grows at most logarithmically with the size of the ts .",
    "+ * e&d machines*. e&d machines can be discussed within this very framework , as they are particular instances of lms . in this case",
    "the povm  @xmath55 has the form @xmath117 , where @xmath118 and @xmath119 are themselves povms on the ts subsystems @xmath13 and  @xmath15 respectively .",
    "the role of  @xmath120 and  @xmath121 is to estimate ( optimally ) the qubit states in these subsystems  @xcite .",
    "the measurement on  @xmath14 ( the data qubit ) now depends on the pair of outcomes of  @xmath120 and  @xmath121 : @xmath122 .",
    "it performs standard one - qubit discrimination according to the two pure - state specifications , say , the unit bloch vectors @xmath123 and @xmath124 , estimated with @xmath120 and  @xmath121 . in this section , we wish to show that e&d machines perform worse than the optimal lm .",
    "we start by tracing subsystems  @xmath16 in eq .",
    "( [ delta ] ) , which for e&d reads @xmath125.\\ ] ] if we write @xmath126 , we have @xmath127 where @xmath128 and @xmath129 are the bloch vectors of the data qubit states @xmath130 conditioned to the outcomes  @xmath131 and  @xmath132 respectively , and  @xmath133 , @xmath134 are their probabilities .",
    "we now recall that optimal estimation necessarily requires that all elements of @xmath135 must be of the form @xmath136 u^\\dagger_\\alpha$ ] , where  @xmath137 , @xmath138 , and  @xmath139 are appropriate su(2 ) rotations ( analogous necessary conditions are required for  @xmath121 )  @xcite . substituting in eq .",
    "( [ conditioned ] ) we obtain @xmath140 , and @xmath141+[\\,\\downarrow\\,]\\right)\\ ] ] ( a similar expression holds for @xmath142 ) .",
    "this means that the bloch vector of the data qubit conditioned to outcome  @xmath131 is proportional to @xmath143 ( the bloch vector of the corresponding estimate ) and is shrunk by a factor @xmath144 .",
    "note in passing that the shrinking factor  @xmath145 is independent of the measurements , provided it is optimal .",
    "surprisingly at first sight , povms that are optimal , and thus equivalent , for estimation may lead to different minimum error probabilities .",
    "in particular , the continuous covariant povm is outperformed in the problem at hand by those with a finite number of outcomes .",
    "optimal povms with few outcomes enforce large angles between the estimates  @xmath123 and @xmath124 , and thus between @xmath128 and @xmath129 ( @xmath146 in the @xmath147 example below ) .",
    "this translates into increased discrimination efficiency , as shown by  ( [ e+d ] ) , without compromising the quality of the estimation itself .",
    "hence the orientation of @xmath120 relative to @xmath121 ( which for two continuous povms does not even make sense ) plays an important role , as it does the actual number of outcomes . with an increasing size of the ts ,",
    "the optimal estimation povms require also a larger number of outcomes and the angle between the estimates decreases in average , since they tend to fill the 2-sphere isotropically .",
    "hence , the minimum error probability is expected to approach that of two continuous povms .",
    "this is supported by numerical calculations .",
    "the problem of finding the optimal e&d machine for arbitrary @xmath1 appears to be a hard one and is currently under investigation . here",
    "we will give the absolute optimal e&d machine for @xmath147 and , also , we will compute the minimum error probability for both  @xmath135 and  @xmath121 being the continuous povm that is optimal for estimation .",
    "the later , as mentioned , is expected to attain the optimal e&d error probability asymptotically .",
    "we can obtain an upper bound on  ( [ e+d ] ) by applying the schwarz inequality .",
    "we  readily find that @xmath148 where we have used that @xmath149 , as follows from the povm condition on @xmath135 and @xmath121 .",
    "the maximum norm of @xmath150 and @xmath151 is bounded by @xmath152 [ the shrinking factor @xmath145 for @xmath147 ] .",
    "thus @xmath154 where the value of @xmath155 can be read off from eq .  ( [ optdisc ] ) .",
    "the e&d bound @xmath156 is attained by the choices and @xmath157 $ ] , where we have used the definition  @xmath158 .    for arbitrary @xmath1 ,",
    "a simple expression for the error probability can be derived in the continuous povm case , @xmath159u^\\dagger_{{\\mbox{\\boldmath\\scriptsize$s$}}}\\}_{{\\mbox{\\boldmath\\scriptsize$s$}}\\in{\\mathbb s}^2}$ ] , where @xmath160 is a unit vector ( a point on the 2-sphere @xmath161 ) and  @xmath162 is the representation of the rotation that takes the unit vector along the @xmath81-axis ,  @xmath163 , into  @xmath160 .",
    "here @xmath160 labels the outcomes of the measurement and thus plays the role of  @xmath131 and @xmath132 . the continuous version of  ( [ e+d ] ) can be easily computed to be @xmath164 asymptotically , we have @xmath165 .",
    "therefore , the excess risk , which we recall is the difference between the average error probability of the machine under consideration and that of the optimal discrimination protocol for _ known _ qubit states ( @xmath41 ) , is @xmath166 .",
    "this is twice the excess risk of the optimal programmable machine and the optimal lm , which can be read off from eq .",
    "( [ progr asymp ] ) : @xmath167 for @xmath147 , eq .",
    "( [ delta n=1 ] ) leads to @xmath168 .",
    "this value is already  @xmath169 larger than excess risk of the optimal lm :  @xmath170 . + * robustness of lms*. so far we have adhered to the simplifying assumptions that the two types of states produced by the source are pure and , moreover , exactly equal in number .",
    "neither of these two assumptions is likely to hold in practice , as both , interaction with the environment , i.e. , decoherence and noise , and statistical fluctuations in the numbers of states of each type , will certainly take place . here",
    "we prove that the performance of the optimal lm is not altered by these effects in the asymptotic limit of large ts .",
    "more precisely , the excess risk of the optimal  lm remains equal to that of the optimal programmable discriminator to leading order in @xmath171 when noise and statistical fluctuations are taken into account .",
    "let us first consider the impact of noise , which we will assume isotropic and uncorrelated .",
    "hence , instead of producing @xmath172 $ ] , the source produces copies of @xmath173 + ( 1-r ) \\frac{{\\openone}}{2},\\quad 0<r\\le1 .",
    "\\label{rho mixed}\\ ] ] in contrast to the pure qubits case , where @xmath174 $ ] belongs to the fully symmetric invariant subspace of maximum angular momentum @xmath175 , the state of @xmath91 is now a full - rank matrix of the form @xmath176 .",
    "hence , it has projections on all the orthogonal subspaces @xmath177 , where  @xmath178 and @xmath179 is the multiplicity space of the representation with total angular momentum @xmath78 ( see sec .",
    "methods for a formula of the multiplicity  @xmath180 ) , and  @xmath78 is in the range from  @xmath3  ( @xmath181 ) to @xmath182 if @xmath1 is even ( odd ) .",
    "therefore @xmath176 is block - diagonal in the total angular momentum eigenbasis .",
    "the multiplicity space  @xmath179 carries the label of the @xmath180 different equivalent representations of given  @xmath78 , which arise from the various ways the individual qubits can couple to produce total angular momentum  @xmath78 . for permutation invariant states ( such as  @xmath176 )",
    ", this has no physical relevance and the only effect of @xmath179 in calculations is through its dimension @xmath180 .",
    "hence , the multiplicity space will be dropped throughout this paper .",
    "the average states now become a direct sum of the form @xmath183 where we use the shorthand notation @xmath184 [ each angular momentum ranges from @xmath3 ( @xmath181 ) to @xmath182 for @xmath1 even ( odd ) ] , and @xmath185 is the probability of any of the two average states projecting on the block labeled  @xmath186 . hence , @xmath187 the number of terms in eq .",
    "( [ delta lm sum xi ] ) , is @xmath188 ^ 2 $ ] for even / odd @xmath1 .",
    "it grows quadratically with @xmath1 , in contrast to the pure state case for which there is a single contribution corresponding to @xmath189 . in the asymptotic limit of large @xmath1",
    ", however , a big simplification arises because of the following results : for each @xmath186 of the form @xmath190 , the following relation holds ( see sec .  methods )",
    "@xmath191 where @xmath192 are the average states  ( [ sigma states ] ) for a number of  @xmath193 _ pure _ qubits . here",
    "@xmath194 is the expectation value restricted to  @xmath195 of the of the angular momentum in the state @xmath196 , where @xmath197 has bloch vector @xmath198 .",
    "( [ ja = jc ] ) is an exact algebraic identity that holds for any value of @xmath78 , @xmath1 and @xmath199 ( it bears no relation whatsoever to measurements of any kind ) .",
    "the second result is that for large  @xmath1 , both  @xmath200 and  @xmath201 become continuous probability distributions , @xmath202 and @xmath203 , where @xmath204 $ ] .",
    "asymptotically , they approach dirac delta functions peaked at   ( see sec .",
    "methods ) .",
    "hence , the only relevant contribution to  @xmath155 comes from  @xmath205 .",
    "it then follows that in the asymptotic limit @xmath206 hence , mixed - state quantum classification using a ts of  size @xmath0 is equivalent to its _ pure_-state version for a ts of size @xmath207 , provided @xmath1 is asymptotically large .",
    "in particular , our proof of optimality above also holds for _ arbitrary _",
    "@xmath208 $ ] if the ts is sizable enough , and  .",
    "this result is much stronger than robustness against decoherence , which only would require optimality for values of @xmath199 close to unity .    from eqs .",
    "( [ delta lm sum xi ] ) and  ( [ s - s asymp ] ) one can easily compute  @xmath155 for arbitrary @xmath199 using that  @xcite @xmath209 up to exponentially vanishing terms .",
    "the trace norm of  @xmath210 can be retrieved from , e.g. , eq .  ( [ ex risk ] ) . for  @xmath211 _ pure _ qubits",
    "one has @xmath212 $ ] .",
    "after some trivial algebra we obtain @xmath213 for the error probability , in agreement with the optimal programmable machine value given in  @xcite , as claimed above .",
    "this corresponds to an excess risk of @xmath214 in the non - asymptotic case , the sum in eq .",
    "( [ delta lm sum xi ] ) is not restricted to @xmath190 and the calculation of the excess risk becomes very involved . rather than attempting to obtain an analytical result , for small training samples we have resorted to a numerical optimization .",
    "we first note that eqs .",
    "( [ omega ] ) through ( [ ja - jc ] ) define a _",
    "semidefinite programming _ optimization problem ( sdp ) , for which very efficient numerical algorithms have been developed  @xcite . in this framework ,",
    "one maximizes the objective function  @xmath155 [ second equality in eq .",
    "( [ delta sdp ] ) ] of the sdp variables  @xmath215 , subject to the linear condition ( [ omega_m ] ) .",
    "we use this approach to compute the error probability , or equivalently , the excess risk of a lm for mixed - state quantum classification of small samples ( @xmath216 ) , where no analytical expression of the optimal seed is known . for mixed states",
    "the expression of @xmath88 and @xmath217 can be found in sec .",
    "methods , eqs .",
    "( [ ja - jc 2 ] ) through  ( [ sdp methods 2 ] ) .",
    "our results are shown in fig .",
    "[ fig1 ] , where we plot @xmath218 ( shaped dots ) and the lower bounds given by @xmath219 ( solid lines ) as a function of the purity @xmath199 for up to  @xmath220 .",
    "we note that the excess risk of the optimal lm is always remarkably close to the absolute minimum provided by the optimal programmable machine and in the worst case ( @xmath221 ) it is only @xmath222 larger .",
    "for @xmath147 we see that @xmath223 for any value of  @xmath199",
    ". this must be the case since for a single qubit in @xmath13 and @xmath15 one has @xmath224 , and eq .",
    "( [ ja = jc ] ) holds .",
    "( color online ) excess risk @xmath218 ( points ) and its corresponding lower bound @xmath219 ( lines ) , both as a function of the purity @xmath199 , and for values of @xmath1 ranging from 1 to 5 ( from top to bottom ) . ]",
    "we now turn to robustness against statistical fluctuations in the number of states of each type produced by the source . in a real scenario",
    "one has to expect that  @xmath225 , @xmath226 .",
    "hence ,  @xmath88 has the general form  ( [ ja - jc 2 ] ) , which gives us a hint that our choice @xmath227 may not be optimal for finite  @xmath1 .",
    "this has been confirmed by numerical analysis using the same sdp approach discussed above . here , we show that the asymptotic performance ( for large training samples ) of the optimal lm , however , is still the same as that of the optimal programmable discriminator running under the same conditions ( mixed states and statistical fluctuations in @xmath228 ) .",
    "asymptotically , a real source for the problem at hand will typically produce  @xmath229 mixed copies of each type . in sec .",
    "methods , it is shown that the relation  ( [ s - s asymp ] ) still holds in this case if @xmath1 is large .",
    "it reads @xmath230 ( @xmath231 first appears at order @xmath232 ) .",
    "hence , the effect of both statistical fluctuations in @xmath228 and noise ( already considered above ) is independent of the machine used for quantum classification ( i.e. , it is the same for lm , programmable machines , e&d ,  ) . in particular , the relation  ( [ rlm = ropt ] ) , @xmath223 , between the excess rate of the optimal lm and its absolute limit given by the optimal programmable discriminator still holds asymptotically , which proves robustness .    to illustrate this ,",
    "let us consider the effect of statistical fluctuations in  @xmath228 for pure states .",
    "the optimal programmable machine for arbitrary @xmath233 , @xmath234 and @xmath235 was presented in  @xcite .",
    "the error probability for the case at hand ( @xmath236 ) is in sec",
    ".  methods . from its asymptotic expansion when @xmath233 and @xmath235 are both large one",
    "readily has @xmath237 we see that when  @xmath229 ( i.e. , when statistical fluctuations in @xmath228 are taken into account ) one still has  @xmath238 .",
    "we have presented a _ supervised _ quantum learning machine that classifies a single qubit prepared in a pure but otherwise unknown state after it has been trained with a number of already classified qubits .",
    "its performance attains the absolute bound given by the optimal programmable discrimination machine .",
    "this learning machine does not require quantum memory and can also be reused without retraining , which may save a lot of resources .",
    "the machine has been shown to be robust against noise and statistical fluctuations in the number of states of each type produced by the source . for small",
    "sized training sets the machine is very close to optimal , attaining an excess risk that is larger than the absolute lower limit by at most @xmath222 . in the absence of noise and statistical fluctuations",
    ", the machine attains optimality for _ any _ size of the training set .",
    "one may rise the question of whether or not the separated measurements on the training set and data qubit can be reversed in time ; in a classical scenario where , e.g. , one has to identify one of two faces based on a stack of training portraits , it is obvious that , without memory limitations , the order of training and data observation can be reversed ( in both cases the final decision is taken based on the very same information ) .",
    "we will briefly show that this is not so in the quantum world .",
    "in the reversed setting , the machine first performs a measurement  @xmath239 , with each element of rank one  @xmath240 u^\\dagger_\\mu$ ] , and stores the information ( which of the possible outcomes is obtained ) in the classical memory to control the measurement to be performed on the training set in a later time .",
    "the probability of error conditioned to one of the outcomes , say @xmath85 , is given by the helstrom formula @xmath241 , where @xmath88 is defined in eq .",
    "( [ def gammaup ] ) . using eq .",
    "( [ ja - jc ] ) one has @xmath242 $ ] .",
    "the averaged error probability is then @xmath243 in the limit of infinite copies we obtain @xmath244 , which is way larger than @xmath245 . the same minimum error probability of  eq .",
    "( [ pelmback ] ) can be attained by performing a stern - gerlach measurement on the data qubit , which requires just one bit of classical memory .",
    "this is all the classical information that we can hope to retrieve from the data qubit , in agreement with holevo s bound  @xcite .",
    "this clearly limits the possibilities of a correct classification very much in the same way as in face identification with limited memory size .",
    "in contrast , the amount of classical information  sent forward \" in the optimal learning machine goes as the logarithm of the size of the training sample .",
    "this asymmetry also shows that despite the separability of the measurements , non - classical correlations between the training set and the data qubit play an important role in quantum learning .",
    "some relevant generalizations of this work to , e.g. , higher dimensional systems and arbitrarily unbalanced training sets , remain an open problem .",
    "another challenging problem with direct practical applications in quantum control and information processing is the extension of this work to _ unsupervised _ machines , where no human expert classifies the training sample .",
    "the state @xmath196 of @xmath1 identical copies of a general qubit state @xmath197 with purity  @xmath199 and bloch vector @xmath246 , has a block diagonal form in the basis of the total angular momentum given by @xmath247 here @xmath248 if @xmath1 is even ( odd ) , @xmath249 is the identity in the multiplicity space @xmath179 , of dimension @xmath180 ( the multiplicity of the representation with total angular momentum @xmath78 ) , where @xmath250 the normalized state @xmath251 , which is supported on the representation subspace @xmath252 of dimension  @xmath253 ,  is @xmath254\\right)u_{{\\mbox{\\boldmath\\scriptsize$s$}}}^{\\dagger }   , \\ ] ] where @xmath255 and @xmath256 so that @xmath257 , and we stick to our shorthand notation @xmath8\\equiv|\\,\\cdot\\,\\rangle\\langle\\,\\cdot\\,|$ ] , i.e. , @xmath258\\equiv { \\left|{j , m}\\rangle\\!\\langle{j , m}\\right|}$ ]",
    ". the measurement on @xmath196 defined by the set of projectors on the various subspaces  @xmath195 will produce @xmath251 as a posterior state with probability @xmath259 one can easily check that @xmath260 .    in the large @xmath1 limit ,",
    "we can replace @xmath261 for a continuous probability distribution @xmath262 in @xmath263 $ ] , where @xmath264 . applying stirling s approximation to @xmath265",
    "one obtains : @xmath266 where @xmath267 is the ( binary ) relative entropy @xmath268 the approximation is valid for @xmath269 and @xmath199 both in the open unit interval  @xmath270 . for non - vanishing @xmath199 , @xmath262 becomes a dirac delta function peaked at @xmath271 , @xmath272 , which corresponds to  @xmath273 .",
    "+      we start with a povm element of the form @xmath274 .",
    "since @xmath49 must be a rank - one projector , it can always be written as @xmath275 \\,u_\\mu^\\dagger$ ] for a suitable su(2 ) rotation @xmath276 .",
    "thus , @xmath277u_\\mu^\\dagger u^\\dagger \\right).\\ ] ] we next use the invariance of the haar measure @xmath63 to make the change of variable : @xmath278 and , accordingly , @xmath279 . after regrouping terms we have @xmath280u'{}^\\dagger\\right )   \\nonumber \\\\ & = & \\!\\ ! \\int\\!\\ ! du ' \\!\\left[u'_{ac}\\!\\left(\\ !",
    "\\sum_\\mu u^\\dagger_{\\mu\\ , { ac } }   l_\\mu u_{\\mu\\ , { ac}}\\!\\!\\right )   u'{}_{ac}^\\dagger\\right]\\!\\otimes\\ !   \\left(u'[\\,\\uparrow\\,]u'{}^\\dagger \\right)\\nonumber \\\\ & = & \\int\\!\\ !",
    "du \\left(u_{ac}\\ , \\omega\\ , u^\\dagger_{ac}\\right)\\otimes \\left(u[\\,\\uparrow\\ , ] u^{\\dagger}\\right ) , \\end{aligned}\\ ] ] where we have defined the povm element @xmath281 is obtained by replacing   by   in the expressions above . from the povm  condition",
    "@xmath282 it immediately follows that  @xmath283 , where @xmath284 is the identity on the hilbert space of the ts , i.e. , @xmath285 . therefore @xmath286 is a covariant povm .",
    "the positive operator @xmath66 is called the seed of the covariant povm  @xmath55 .    now , let @xmath287 be a rotation about the @xmath81-axis , which leaves @xmath67 $ ] invariant . by performing the change of variables @xmath288 [ and @xmath289 in the last equation above",
    ", we readily see that @xmath66 and @xmath290 both give the same average operator @xmath64 for any @xmath291 .",
    "so , its average over @xmath292 , @xmath293 can be used as a seed w.l.o.g .",
    ", where we have dropped the subscript @xmath16 to simplify the notation .",
    "such a seed is by construction invariant under the group of rotations about the @xmath81-axis ( just like @xmath67 $ ] ) and , by schur s lemma , a direct sum of operators with well defined magnetic number .",
    "therefore , in the total angular momentum basis for  @xmath16 , we can always choose the seed of @xmath55 as @xmath294 the constrain  ( [ omega_m ] ) follows from the povm condition @xmath295 and schur s lemma .",
    "the result also holds if  @xmath13 and @xmath15 have different number of copies ( provided they add up to @xmath0 ) . it also holds for mixed states .",
    "+      let us consider three angular momenta @xmath296 that couple to give a total @xmath36 .",
    "note that there is no unique way  to carry out this coupling ; we might first couple @xmath297 and  @xmath298 to give a resultant @xmath299 , and couple this to @xmath300 to give  @xmath36 , or alternatively , we may couple @xmath297 to the resultant  @xmath301 of coupling @xmath298 and @xmath300 .",
    "moreover , the intermediate couplings can give in principle different values of  @xmath299 or  @xmath301 which , when coupled to @xmath300 or @xmath297 , end up giving the same value of @xmath36 .",
    "all these possibilities lead to linearly independent states with the same @xmath36 and @xmath37 , thus they must be distinguished by specifying the intermediate angular momentum and the order of coupling .",
    "there exists a unitary transformation that maps the states obtained from the two possible orderings of the coupling ; wigner s 6j - symbols  @xcite , denoted in the next equation by @xmath302 , provide the coefficients of this transformation : @xmath303 & & = \\ !",
    "( -1)^{j_1+j_2+j_3+j}\\ !",
    "\\sqrt{\\!(2j_{12}+1)(2j_{23}+1 ) } \\!\\left\\ { \\begin{array}{ccc } \\!j_1\\ ! & \\ !",
    "j_2\\ ! & \\ !",
    "j_{12}\\!\\ ! \\\\",
    "\\!j_3\\ ! & \\",
    "! j\\ ! & \\ !",
    "j_{23}\\!\\ ! \\end{array } \\right\\ }   .\\end{aligned}\\ ] ] note that this overlap is independent of @xmath37 . for the proof of optimality of the lm , we couple subsystems  @xmath13 ,  @xmath14 and  @xmath15 in two ways : @xmath304 and @xmath104 to produce the states @xmath305 and @xmath306 , which we denote by @xmath307 and @xmath308 respectively for short .",
    "the various angular momenta involved are fixed to , @xmath309 , @xmath310 , @xmath311 , whereas @xmath312 . with these values ,",
    "the overlaps we need are given by @xmath313      let us start with the general case where @xmath314 . to obtain @xmath315",
    "we first write eqs .",
    "( [ sigmaxi1 ] ) and  ( [ sigmaxi2 ] ) as the su(2 ) group integrals @xmath316_a\\ ! \\otimes\\!\\rho^b_0\\ !",
    "\\right ) \\ !",
    "u_{ab}^{\\dagger } \\\\ \\!\\ ! & \\otimes&\\!\\ !",
    "! du ' \\ , u'_c\\ ! \\left(\\sum_{m =- j'}^{j'}\\!\\ !",
    "a^{j'}_m [ j',m]_c\\ ! \\right ) u'^{\\dagger}_c \\ , , \\end{aligned}\\ ] ] where @xmath317 is given in eq .  ( [ a_m ] )",
    ", @xmath318 is the mixed state  @xmath319 , eq .",
    "( [ rho mixed ] ) , of the qubit  @xmath14 .",
    "we next couple @xmath13 with @xmath14 ( more precisely , their subspaces of angular momentum  @xmath78 ) using the clebsch - gordan coefficients @xmath320 will vanish for all @xmath321 .",
    "we  readily obtain @xmath322 where @xmath323 is the projector on  @xmath195 and @xmath324 .",
    "the superscripts attached to the various projectors specify the subsystems to which they refer .",
    "these projectors are formally equal to those used in eq .",
    "( [ sigma states ] ) ( i.e. , @xmath323 projects on the fully symmetric subspace of @xmath193 qubits ) and , hence , we stick to the same notation . note that @xmath325 , as it should be .",
    "we can further simplify this expression by introducing @xmath326 , i.e. , the expectation value of the @xmath81-component of the total angular momentum in the state  @xmath251 ( i.e. , of @xmath327 in the state  @xmath176 ) for a bloch vector  @xmath328 : @xmath329 using the relation@xmath330 and @xmath331 , we can write @xmath332 similarly , we can show that @xmath333 therefore , if @xmath334 , @xmath335 comparing with eq .",
    "( [ sigma states ] ) , the two terms in the second line can be understood as the average states for a number of @xmath193 pure qubits , i.e. , as @xmath336 and @xmath337  respectively .",
    "hence , if @xmath190 we have the relation @xmath338 which is eq .",
    "( [ ja = jc ] ) .",
    "it is important to emphasize that this equation is exact ( i.e. ,  it holds for any value of @xmath78 , @xmath1 and  @xmath199 ) and bears no relation whatsoever to measurements ( i.e. , it is an algebraic identity between the various operators involved ) .    in the asymptotic limit , for @xmath233 and @xmath235 of the form @xmath339 , @xmath340 , @xmath341 ,",
    "the probabilities @xmath261 and @xmath342 are peaked at @xmath343 and  @xmath344 , as was explained above .",
    "hence , only the average state components @xmath345 with @xmath346 such that @xmath347 and @xmath348 are important . from  eqs .",
    "( [ new sigma0xi ] ) and  ( [ new sigma1xi ] ) it is straightforward to obtain    @xmath349    where we have used that  @xcite @xmath209 up to exponentially vanishing terms . this relation , for the particular value of @xmath350 , is used in the proof of robustness , eq .",
    "( [ ja = jc asymp ] ) .",
    "+      here we calculate @xmath351 ( \\sigma^n_{0,\\xi}-\\sigma^n_{1,\\xi})\\}$ ] , where the average states are defined in eqs .",
    "( [ sigmaxi1 ] ) and  ( [ sigmaxi2 ] ) , and explicitly given in  eqs .",
    "( [ new sigma0xi ] ) and  ( [ new sigma1xi ] ) for  @xmath314 .",
    "let us first calculate the conditional state @xmath352 \\sigma^n_{0,\\xi})$ ] .",
    "for that , we need to express @xmath353 $ ] in the original product basis @xmath354 . recalling the clebsch - gordan coefficients @xmath355",
    ", one readily obtains @xmath356 { { \\openone}^{ab}_{2j+1}\\over d_{2j+1}}\\right)=\\!\\!\\sum_{m =- j}^{j}\\!\\frac{j\\!+\\!1\\!+\\!m}{2(j+1)d_{2j}}[j , m]_a , \\ ] ] which can be written as @xmath356 { { \\openone}^{ab}_{2j+1}\\over d_{2j+1}}\\right)= { 1\\over2}\\left({{\\openone}^a_{2j}\\over d_{2j}}+{1\\over d_{2j}}{\\hat{j}^a_z\\over j+1}\\right ) , \\ ] ] where @xmath357 is the @xmath81 component of the total angular momentum operator acting on subsystem @xmath13 .",
    "an analogous expression is obtained for @xmath358 { \\openone}^{bc}_{2j'+1}\\right)$ ] . substituting in eqs .",
    "( [ new sigma0xi ] ) and  ( [ new sigma1xi ] ) and subtracting the resulting expressions , one has @xmath359 , with @xmath360 where we have written @xmath361 , instead of @xmath314 used in the derivation .",
    "for pure states , @xmath362 , @xmath189 , @xmath363 , and we recover eq .",
    "( [ ja - jc ] ) .    in order to minimize the excess risk using sdp",
    ", we find it convenient to write eq .",
    "( [ delta sdp ] ) in the form @xmath364 where we recall that @xmath365 , and we assumed w.l.o.g .",
    "that the seed of the optimal povm has the block form  @xmath366 .",
    "the povm condition , eq .",
    "( [ omega_m ] ) must now hold on each block , thus for  , we must impose that @xmath367      the minimum error probability of the optimal programmable machine with a number of @xmath233 , @xmath4 and @xmath235 copies ( @xmath368 ) in ports @xmath13 , @xmath14 and @xmath15 respectively , is  @xcite @xmath369 \\!&\\times&\\ ! \\left .",
    "{ 1\\!-\\!4{d_0d_1\\over(d_0\\!+\\!d_1)^2}\\frac{(n_a\\!-\\!n_c\\!+\\!k\\!+\\!1 ) ( k\\!+\\!1)}{(n_a+1)(n_c+1 ) } } \\right\\ } , \\end{aligned}\\ ] ] where @xmath370 and @xmath371 are the dimensions of the average states @xmath372 . the asymptotic form of this expression when @xmath233 and @xmath235 are both very large can be easily derived using euler - maclaurin s summation formula .",
    "the result up to subleading order is @xmath373 which leads to eq .",
    "( [ opt asym ] ) .",
    "we acknowledge financial support from : erdf : european regional development fund ; the spanish micinn , through contract fis2008 - 01236 , fpi grant no . bes-2009 - 028117 ( gs ) and",
    "( eb ) pr2010 - 0367 ; and from the generalitat de catalunya cirit , contract 2009sgr-0985 ."
  ],
  "abstract_text": [
    "<S> a quantum learning machine for binary classification of qubit states that does not require quantum memory is introduced and shown to perform with the minimum error rate allowed by quantum mechanics for _ any _ size of the training set . </S>",
    "<S> this result is shown to be robust under ( an arbitrary amount of ) noise and under ( statistical ) variations in the composition of the training set , provided it is large enough . </S>",
    "<S> this machine can be used an arbitrary number of times without retraining . </S>",
    "<S> its required classical memory grows only logarithmically with the number of training qubits , while its excess risk decreases as the inverse of this number , and twice as fast as the excess risk of an  estimate - and - discriminate \" machine , which estimates the states of the training qubits and classifies the data qubit with a discrimination protocol tailored to the obtained estimates .    </S>",
    "<S> quantum computers are expected to perform some ( classical ) computational tasks of practical interest , e.g. , large integer factorization , with unprecedented efficiency . </S>",
    "<S> quantum simulators , on the other hand , perform tasks of a more  quantum nature \" , which can not be efficiently carried out by a classical computer . </S>",
    "<S> namely , they have the ability to simulate complex quantum dynamical systems of interest . </S>",
    "<S> the need to perform tasks of genuine quantum nature is emerging as individual quantum systems play a more prominent role in labs ( and , eventually , in everyday life ) . </S>",
    "<S> examples include : quantum teleportation , dynamical control of quantum systems , or quantum state identification . </S>",
    "<S> quantum information techniques are already being developed in order to execute these tasks efficiently .    </S>",
    "<S> this paper is concerned with a simple , yet fundamental instance of quantum state identification . </S>",
    "<S> a source produces two unknown pure qubit states with equal probability . </S>",
    "<S> a human expert ( who knows the source specifications , for instance ) classifies a number of @xmath0 states produced by this source into two sets of size roughly @xmath1 ( statistical fluctuations of order @xmath2 should be expected ) and attaches the labels @xmath3 and  @xmath4 to them . </S>",
    "<S> we view these  @xmath0 states as a training sample , and we set ourselves to find a universal machine that uses this sample to assign the right label to a new unknown state produced by the same source . </S>",
    "<S> we refer to this task as quantum classification for short .    </S>",
    "<S> quantum classification can be understood as a _ supervised quantum learning _ problem , as has been noticed by guta and kotlowski in their recent work  @xcite ( though they use a slightly different setting ) . </S>",
    "<S> learning theory , more properly named _ machine _ learning theory , is a very active and broad field which roughly speaking deals with algorithms capable of learning from experience  @xcite . </S>",
    "<S> its quantum counterpart  @xcite not only provides improvements over some classical learning problems but also has a wider range of applicability , which includes the problem at  hand . </S>",
    "<S> quantum learning has also strong links with quantum control theory and is becoming a significant element of the quantum information processing toolbox .    </S>",
    "<S> an absolute limit on the minimum error in quantum classification is provided by the so called optimal programmable discrimination machine  @xcite . in this context , to ensure optimality one assumes that a fully general two - outcome joint measurement is performed on _ both _ the  @xmath0 training qubits and the qubit we  wish to classify , where the observed outcome determines which of the two labels ,  @xmath3 or  @xmath4 , is assigned to the latter qubit . </S>",
    "<S> thus , in principle , this assumption implies that in a learning scenario a quantum memory is needed to store the training sample till the very moment we wish to classify the unknown qubit . </S>",
    "<S> the issue of whether or not the joint measurement assumption can be relaxed has not yet been addressed . nor has the issue of how the information left after the joint measurement can be used to classify a second unknown qubit produced by the same source , unless a fresh new training set ( ts ) is provided ( which may seem unnatural in a learning context ) . the aim of this paper is to show that for a sizable ts ( asymptotically large @xmath1 ) the lower bound on the probability of misclassifying the unknown qubit set by programmable discrimination can be attained by first performing a suitable measurement on the ts followed by a stern - gerlach type of measurement on the unknown qubit , where forward classical communication is used to control the parameters of the second measurement . </S>",
    "<S> the whole protocol can thus be undersood as a learning machine ( lm ) , which requires much less demanding assumptions while still having the same accuracy as the optimal programmable discrimination machine . </S>",
    "<S> all the relevant information about the ts needed to control the stern - gerlach measurement is kept in a _ classical _ memory , thus classification can be executed any time after the learning process is completed . </S>",
    "<S> once trained , this machine can be subsequently used an arbitrary number of times to classify states produced by the same source . </S>",
    "<S> moreover ,  this optimal lm is robust under noise , i.e. , it still attains optimal performance if the states produced by the source undergo depolarization to any degree . </S>",
    "<S> interestingly enough , in the ideal scenario where the qubit states are pure and  the ts consists in exactly the same number of copies of each of the two types 0/1 ( no statistical fluctuations are allowed ) this lm attains the optimal programmable discrimination bound for _ any _ size @xmath0 of the ts , not necessarily asymptotically large .    at this point </S>",
    "<S> it should be noted that lms without  quantum memory can be naturally assembled from  two quantum information primitives : state estimation and state discrimination . </S>",
    "<S> we will refer to these specific constructions as  estimate - and - discriminate \" ( e&d ) machines . </S>",
    "<S> the protocol they execute is as follows : by performing , e.g. , an optimal covariant measurement on the  @xmath1 qubits in the ts labeled @xmath3 , their state  @xmath5 is estimated with some accuracy , and likewise the state  @xmath6 of the other  @xmath1 qubits that carry the label  @xmath4 is characterized . </S>",
    "<S> this classical information is stored and subsequently used to discriminate an unknown qubit state . </S>",
    "<S> it will be shown that the excess risk ( i.e. , excess average error over classification when the states @xmath5 and @xmath6 are perfectly known ) of this protocol is twice that of the optimal lm . </S>",
    "<S> the fact that the e&d machine is suboptimal means that the kind of information retrieved from the ts and stored in the classical memory of the optimal lm is specific to the classification problem at hand , and that the machine itself is more than the mere assemblage of well known protocols </S>",
    "<S> .    we will first present our results for the ideal scenario where states are pure and no statistical fluctuation in the number of copies of each type of state is allowed . </S>",
    "<S> the effect of these fluctuations and the robustness of the lm optimality against noise will be postponed to the end of the section . </S>"
  ]
}