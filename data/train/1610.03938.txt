{
  "article_text": [
    "the most famous approach of model selection is to derive a risk estimator and to choose the model minimizing it .",
    "this type of model selection includes cross - validation and so - called `` information criteria '' including aic @xcite , bic @xcite , gic @xcite and so on .",
    "basically , information criteria have been derived by using asymptotic expansion , which requires the sample number @xmath0 to go to the infinity .",
    "though the cross - validation was not derived by asymptotic assumption , its unbiasedness or performance is guaranteed basically by asymptotic theory . for regression , @xcite proposed an interesting model selection criteria called direct eigenvalue estimator ( dee ) .",
    "dee has the following remarkable characteristics : ( i ) dee is an approximately unbiased risk estimator for finite @xmath0 .",
    "( ii ) no asymptotic assumption ( @xmath1 ) is necessary to derive it .",
    "( iii ) no prior knowledge about the noise variance and the noise distribution is necessary . due to these virtues",
    ", dee is expected to perform nicely for small sample cases .",
    "dee requires two assumptions in its derivation instead of using the asymptotic assumption .",
    "the first assumption is that a large number of unlabeled data are available in addition to the labeled data .",
    "this assumption is often made in recent machine learning literatures and is practical because the unlabeled data can usually be gathered automatically .",
    "the other assumption is most important , which imposes statistical independence between the inside - the - model part and the outside - the - model part of the dependent variable @xmath2 .",
    "this assumption holds not exactly in general but hold approximately . by numerical experiments",
    ", @xcite showed that dee performed better than many of the conventional information criteria and the cross - validation .",
    "however , they also reported that another criterion adj @xcite often performed better than dee .",
    "it should be noted here that the comparison between adj and dee is fair since adj also assumes that a lot of unlabeled data are available . even though adj is the state - of - the - art",
    ", that result seems somewhat strange because dee was derived specifically for regression by exploiting the properties of regression exhaustively while the derivation of adj is somewhat heuristic and was developed for general setting . by careful investigation , we found an inappropriate part in the derivation process of dee , although the resultant form of dee is ` valid ' in a sense . as a result , dee can not derive its potential . to clarify these facts",
    ", we formulate the derivation process of dee again and introduce a class of ` valid ' risk estimators based on the idea of dee .",
    "then , we show that dee belongs to this class but is not close to the optimal estimator among this class . indeed",
    ", we can find several more reasonable risk estimators ( mdee ) in this class .",
    "the variations arise from how to balance a certain bias - variance trade - off .",
    "the performance of mdee is investigated by numerical experiments .",
    "we compare the performance of mdee with the original dee , adj and other existing model selection methods .",
    "this paper is an extended version of the conference paper @xcite .",
    "we pointed out the above inappropriate part in the derivation of dee and proposed a naive modification in the paper .",
    "however , theoretical analysis and numerical experiments are significantly strengthened in this paper .",
    "the paper is organized as follows .",
    "we set up a regression problem and introduce some notations in section [ regression ] . in section [ chapelle ] ,",
    "we briefly review the result of @xcite and explain which part is inappropriate in the derivation of dee . in section",
    "[ proposal ] , a class of valid risk estimators are defined .",
    "we explain why dee is valid but not close to the optimal estimator in this class .",
    "in addition , some modifications of dee are proposed .",
    "section [ sim ] provided numerical experiments to investigate the performance of our proposal .",
    "the conclusion is described in section [ conclusion ] .",
    "we employ a usual regression setting as reviewed briefly below .",
    "let @xmath3 and @xmath4 .",
    "suppose that we have training data @xmath5 generated from the joint density @xmath6 i.i.d .",
    "( independently and identically distributed ) , where @xmath7 for each @xmath8 . here , we further assume the following regression model : @xmath9 where @xmath10 is a certain regression function belonging to @xmath11 and @xmath12 is a noise random variable which is subject to @xmath13 with mean zero and variance @xmath14 and is independent of @xmath15 .",
    "this implies that @xmath16 .",
    "the goal of regression problem is to estimate @xmath10 based on the given data set . to estimate @xmath10 ,",
    "let us consider a model of regression function defined by @xmath17 where @xmath18 .",
    "here , @xmath19 denotes the transposition of vectors or a matrices . just for convenience",
    ", we can assume that @xmath20 is a basis of @xmath21 . if not",
    ", we can always extend it as such without loss of generality . by this assumption",
    ", there exists @xmath22 such that @xmath23 almost everywhere .",
    "our task now reduces to find an estimator @xmath24 of @xmath25 as accurate as possible .",
    "its accuracy is measured by the loss function ( mean squared error ) defined as @xmath26 .",
    "\\label{loss}\\ ] ] here , @xmath27 $ ] denotes the expectation with respect to random variables @xmath28 .",
    "similarly , each expectation @xmath29 has subscripts expressing over which random variables the expectation is taken .",
    "since @xmath30 essentially can express an arbitrary element of @xmath11 , @xmath30 itself is too flexible and tends to cause overfitting in general .",
    "therefore , we usually use a truncated version of @xmath30 as a model @xmath31 where @xmath32 is a positive integer .",
    "the ideal estimate of parameter @xmath33 is obtained by minimizing the loss function @xmath34 in ( [ loss ] ) with respect to @xmath33 .",
    "however , @xmath34 is not available because the distribution @xmath35 is unknown .",
    "therefore , we usually minimize an empirical loss function based on @xmath36 , which is defined as @xmath37 for notation simplicity , we define @xmath38 and @xmath39 as @xmath40 matrix whose @xmath41 component is @xmath42 . then , @xmath43 , where @xmath44 is the euclidean norm . the estimator @xmath45 minimizing @xmath46",
    "is referred to as least squares estimator ( lse ) , i.e. , @xmath47 we sometimes drop @xmath48 of @xmath45 for notation simplicity .",
    "an important task is to choose the optimal @xmath32 .",
    "when @xmath32 is too large , @xmath49 tends to overfit , while @xmath49 can not approximate @xmath10 with too small @xmath32 . to choose @xmath32",
    ", we assume that additional unlabeled data @xmath50 are available , where each @xmath51 is subject to @xmath52 independently .",
    "the number of unlabeled data @xmath53 is assumed to be significantly larger than @xmath0 .",
    "note that @xmath54 is used not for parameter estimation but only for model selection as well as @xcite .",
    "the basic idea to choose @xmath32 is as follows .",
    "the following risk ( expected loss function ) @xmath55\\ ] ] is often employed to measure the performance of the model .",
    "hence , one of natural strategies is deriving an estimate of @xmath56 ( denoted by @xmath57 ) using @xmath58 , and then choosing the model as @xmath59 .",
    "many researchers have proposed estimators of @xmath56 so far . in the next section ,",
    "we introduce one of such estimators , which was proposed by @xcite .",
    "most of past information criteria have been derived based on asymptotic expansion .",
    "that is , they postulate that @xmath1 . in contrast , @xcite derived a risk estimator called dee ( direct eigenvalue estimator ) without using asymptotic assumption . in this section ,",
    "we briefly review dee and explain that its derivation includes an inappropriate part .",
    "as is well known , @xmath60 is not an unbiased estimator of @xmath56 .",
    "that is , @xmath61\\ ] ] is not equal to zero .",
    "let @xmath62 be @xmath63}{e_d[{l_d}(f_d(\\cdot;\\hat{\\alpha}(d)))]}.\\ ] ] using @xmath62 , let us consider the following risk estimator @xmath64 it is immediate to see that this estimator is exactly unbiased , i.e. , @xmath65 .",
    "that is , @xmath62 is a so - called bias - correcting term .",
    "remarkably , this estimator corrects the bias multiplicatively , whereas the most of existing information criteria correct the bias additively like aic .",
    "@xcite showed that @xmath62 can be calculated as the following theorem .",
    "[ deederivation ] let @xmath66 .",
    "define @xmath67 .",
    "suppose that the following assumptions hold.n    * assume that @xmath68 is orthonormal with respect to the expectation inner product @xmath69 $ ] , i.e. , @xmath70 where @xmath71 is kronecker s delta .",
    "* let @xmath72 .",
    "define @xmath73 and @xmath74 .",
    "assume that @xmath75    then @xmath62 is exactly calculated as @xmath76}{1-(d / n)}. \\label{predee}\\ ] ]    see @xcite for the meaning of the assumption a2 .",
    "a key fact is that theorem [ deederivation ] holds for finite @xmath0 and the resultant form of @xmath62 does not depend on any unknown quantities except @xmath77 $ ] .",
    "in addition , it seems to be not difficult to find valid estimators of @xmath77 $ ] .",
    "indeed , @xcite derived its estimator as @xmath78 where @xmath79 is defined by @xmath80 and @xmath81 is an @xmath82 matrix whose @xmath83 component is @xmath84 .",
    "the resultant risk estimator is called dee and is given by @xmath85 note that the resultant bias correction factor is invariant under coordinate transformation .",
    "that is , the orthonormal assumption ( [ orthassumption ] ) can be removed by chance . however",
    ", this is somewhat queer .",
    "dee was derived based on ( [ predee ] ) but ( [ predee ] ) is not invariant under coordinate transformation ( it was derived by assuming the orthonormality of basis ) .",
    "actually , ( [ deepestimator ] ) is not a consistent estimator of @xmath77 $ ] in non - orthonormal case .",
    "this is because the derivation of estimator ( [ deepestimator ] ) includes an inappropriate part .",
    "we explain it in the remark at the end of this section .",
    "however , we must emphasize that the resultant form of dee in ( [ finaldee ] ) is valid as a risk estimator in a sense in spite of the above fact . indeed , dee dominated other model selection methods in numerical experiments , as reported by @xcite .",
    "however , due to the inappropriate derivation , dee can not demonstrate its potential performance .",
    "we will explain it in details in the next section .",
    "[ [ remark ] ] remark + + + + + +    we explain here which part of the derivation of dee is inappropriate .",
    "@xcite derived ( [ deepestimator ] ) as follows .",
    "first , they rewrote @xmath77 $ ] as @xmath86=e_d\\left[\\sum_{k=1}^d(1/\\lambda_k)\\right],\\ ] ] where @xmath87 is the @xmath88-th eigenvalue of @xmath89 .",
    "the subsequent part is described by quoting the corresponding part of their paper ( page 16 of @xcite ) .",
    "note that some notations and equation numbers are replaced in order to be consistent with this paper .    in the case",
    "when along with training data , `` unlabeled '' data are available ( x without y ) , one can compute two covariance matrices : one from unlabeled data @xmath79 and another from the training data @xmath89 .",
    "there is a unique matrix @xmath90 ( @xcite ; corollary 7.6.5 ) such that @xmath91 where @xmath92 is a diagonal matrix * with diagonal elements @xmath93*. to perform model selection , we used the correcting term in ( [ predee ] ) , where we replace @xmath94 with its empirical value , @xmath95    however , corollary 7.6.5 in @xcite does not guarantee the existence of a matrix @xmath90 satisfying ( [ critical ] ) .",
    "we quote the statement of the corollary .",
    "if @xmath96 is positive definite and @xmath97 is hermitian , then there exists a nonsingular matrix @xmath98 such that @xmath99 is diagonal and @xmath100 .",
    "here , @xmath101 denotes the set of all square matrices of dimension @xmath0 , whose elements are complex numbers .",
    "furthermore , the symbol @xmath102 denotes the hermitian adjoint .",
    "as seen in the quote , the above corollary only guarantees that @xmath103 and @xmath104 is diagonal . however , quote 1 claims that @xmath104 must be not only a diagonal matrix but also a diagonal matrix whose elements are equal to the eigenvalues of @xmath89 ( see the bold part of quote 1 )",
    ". this claim does not hold correct in general . indeed , ( [ deederivation ] ) is queer . since ( [ deederivation ] ) implies that @xmath105 for any unlabeled data , unlabeled data plays exactly no role .",
    "in this section , we consider what estimators are valid based on the idea of chapelle et al . and which estimator is ` good ' among valid estimators .",
    "to do so , let us calculate the bias correction factor @xmath62 without the orthonormal assumption ( [ orthassumption ] ) .",
    "as described before , the invariance of dee under coordinate transformation was obtained based on the inappropriate way .",
    "[ tcalcnonorth ] let @xmath66 .",
    "suppose that only the assumption a2 is satisfied in theorem [ deederivation ] .",
    "then @xmath62 is exactly calculated as @xmath106}{1-(d / n ) } , \\label{correction2}\\end{aligned}\\ ] ] where @xmath107 $ ] is a @xmath108 matrix with @xmath109 $ ] .",
    "see section [ tcalcnonorthproof ] for its proof .",
    "the form of ( [ correction2 ] ) is invariant under coordinate transformation .",
    "it is natural because the definition of @xmath62 is invariant under coordinate transformation due to the property of lse .",
    "there remain two unknown quantities @xmath110 and @xmath111 $ ] in ( [ correction2 ] ) .",
    "remarkably , both of them can be estimated using only the information about covariates @xmath15 .",
    "let us define @xmath112 and @xmath113 .",
    "taking theorem [ tcalcnonorth ] into account , it is natural to consider the following class of risk estimators .",
    "we say that a risk estimator @xmath57 is valid ( in the sense of dee ) if there exists a consistent estimator converges to the true value @xmath114 in probability as @xmath0 and @xmath53 go to the infinity . ]",
    "@xmath115 of @xmath114 such that @xmath116    we can easily understand that the resultant form of dee is valid under some regularity conditions because @xmath79 and @xmath117 in ( [ finaldee ] ) are statistically independent and are consistent estimators of @xmath110 and @xmath118 respectively .",
    "we imagine that chapelle et al .",
    "knew the result of theorem [ tcalcnonorth ] because they implied this result in remark 3 of section 2.2 of @xcite . based on this fact , they seemingly recognized that the resultant form of dee is valid .",
    "however , it is unclear that dee is close to the optimal estimator in this class . in general",
    ", @xmath118 is more difficult to estimate than @xmath110 because @xmath118 is based on the inverse matrix of @xmath89 .",
    "more concretely , @xmath117 tends to fluctuate more largely than @xmath89 especially when @xmath0 is not large enough .",
    "hence , spending more samples to estimate @xmath118 seems to be a reasonable strategy .",
    "however , dee spends the most of @xmath119 ( i.e. , @xmath53 samples ) to estimate @xmath110 and spends only @xmath0 samples to estimate @xmath118 .",
    "note that this strategy of dee for estimation of @xmath114 has no necessity since the corresponding part was derived inappropriately .",
    "therefore , let us discuss what estimators are good in among valid risk estimators .",
    "we start from the following theorem .",
    "[ riskerror ] let @xmath120 be a valid risk estimator with @xmath115 .",
    "define @xmath121 with @xmath62 in ( [ correction2 ] ) .",
    "if @xmath115 depends on only unlabeled data i.e. , @xmath122 , then @xmath123=     e_d\\big[\\left({r^*}(d)-{\\widehat{r}_d}^*(d)\\right)^2\\big]}\\nonumber\\\\   & & \\hskip-1cm+2\\frac{{\\rm bias}(\\widehat{h})}{n - d}{\\rm    cov}({\\widehat{r}_d}^*(d),{l_d}(f_d(\\cdot;\\hat{\\alpha}(d))))+\\frac{{\\rm    mse}(\\widehat{h})}{(n - d)^2}e_d\\left[{l_d}(f_d(\\cdot;\\hat{\\alpha}(d)))^2\\right].\\label{riskerrordecom}\\end{aligned}\\ ] ] here , @xmath124 denotes usual covariance between @xmath125 and @xmath126 and @xmath127,\\ { \\rm mse}({{\\rm tr}}(\\widehat{h})):=e\\left[\\left({{\\rm tr}}\\left(\\widehat{h}\\right)-{{\\rm tr}}\\left(cv\\right)\\right)^2\\right]\\!.    \\end{aligned}\\ ] ]    the first term of the right side of ( [ riskerrordecom ] ) is independent of the choice of @xmath128 .",
    "it expresses error of the ideally unbiased ( but unknown ) risk estimator @xmath129 .",
    "the second term is of order @xmath130 while the third term is of order @xmath131 .",
    "therefore , it is natural to use an unbiased estimator of @xmath114 as @xmath128 . if @xmath128 is unbiased , @xmath132 & = & e_d\\!\\big[\\!\\!\\left({r^*}(d)\\!-\\!{\\widehat{r}_d}^*(d)\\right)^2\\!\\big]\\nonumber\\\\ & & + \\frac{{\\rm     var}\\left(\\widehat{h}\\right)}{(n - d)^2}e_d\\left[{l_d}(f_d(\\cdot;\\hat{\\alpha}(d)))^2\\right ] , \\label{unbiasedmse }     \\end{aligned}\\ ] ] where @xmath133 denotes a variance of @xmath134",
    "that is , as long as @xmath128 is unbiased , @xmath128 having the smallest @xmath133 gives the best performance .",
    "this fact motivates us to consider the following estimator .",
    "let us divide the unlabeled data set @xmath54 into two data sets @xmath135 and @xmath136 for estimating @xmath110 and @xmath118 respectively .",
    "furthermore , we divide @xmath137 into @xmath138 subsets such that the @xmath139-th subset is @xmath140 as a result , each @xmath141 is an i.i.d .   copy of @xmath142 .",
    "define @xmath143 as an empirical correlation matrix of @xmath144 based on @xmath141 .",
    "then , it is natural to estimate @xmath118 as @xmath145 on the other hand , we can estimate @xmath110 using @xmath146 simply as @xmath147 then , we simply make @xmath148 .",
    "the resultant risk estimator is @xmath149 we refer to this modified version of dee as mdee1 .",
    "there are other possible variations depending on how to estimate @xmath110 and @xmath118 based on unlabeled data .",
    "we prepare the three candidates shown in table [ mdeevariation ] .",
    ".variation of mdee .",
    "this table expresses which data are used to estimate @xmath110 and @xmath118 .",
    "[ cols=\"^,^,^ \" , ]     the results are shown in fig .",
    "[ fig13]-[fig14 ] .",
    "first , we should mention that mdee seemed to work poorly for the data sets `` eeheat '' and `` eecool . ''",
    "these data sets include discrete covariates taking only a few values .",
    "thus , there are some sub data sets @xmath141 in which the above covariates take the exactly same value .",
    "in such cases , @xmath150 based on such @xmath141 diverges to infinity . to see this",
    ", we show the histogram of @xmath151 of mdee3 for `` eeheat '' data with @xmath152 in fig .",
    "[ eeheatts ] . from fig .",
    "[ eeheatts ] , we can see that some values of them take extremely large values .",
    "there are some ways to avoid this difficulty .",
    "the simplest way is to replace the empirical mean @xmath153 in ( [ modified ] ) with the median of @xmath154 .",
    "applying this idea to mdee3 , we obtain a new criterion referred to as rmdee ( robust mdee ) .",
    "each panel of `` eeheat '' and `` eecool '' in fig .",
    "[ fig14 ] contains the result of rmdee instead mdee2 . from fig .",
    "[ fig14 ] , we can see that rmdee worked significantly better than mdee1 or mdee3 . on real - world data ,",
    "mdee1 slightly performed better than mdee2 or mdee3 .",
    "however , their differences are little . in most cases ,",
    "mdee ( or rmdee ) dominated dee or at least performed equally . remarkably , mdee always dominated adj except ` eeheat ' when @xmath155 . as a whole , mdee ( or rmdee ) often performed the best or the second best .     of mdee3",
    "when @xmath152 . ]",
    "even though the idea of dee seems to be promising , it was reported that dee performs worse than adj which was the state - of - the - art . by checking the derivation of dee",
    ", we found that the resultant form of dee is valid in a sense but its derivation includes an inappropriate part . by refining the derivation in the generalized setting , we defined a class of valid risk estimators based on the idea of dee and showed that more reasonable risk estimators could be found in that class .",
    "both dee and mdee assume that a large set of unlabeled data is available .",
    "even though these unlabeled data can also be used to estimate the parameter ( i.e. , semi - supervised learning ) , dee and mdee do not use them for parameter estimation . hence , combining the idea of dee with semi - supervised estimator is an interesting future work .",
    "however , it seems not to be an easy task because the derivation of dee strongly depends on the explicit form of lse .",
    "this work was partially supported by jsps kakenhi grant numbers ( 19300051 ) , ( 21700308 ) , ( 25870503 ) , ( 24500018 ) .",
    "we thank the anonymous reviewers for useful comments .",
    "some theoretical results were motivated by their comments ."
  ],
  "abstract_text": [
    "<S> the risk estimator called `` direct eigenvalue estimator '' ( dee ) is studied . </S>",
    "<S> dee was developed for small sample regression . </S>",
    "<S> in contrast to many existing model selection criteria , derivation of dee requires neither any asymptotic assumption nor any prior knowledge about the noise variance and the noise distribution . it was reported that dee performed well in small sample cases but dee performed a little worse than the state - of - the - art adj . </S>",
    "<S> this seems somewhat counter - intuitive because dee was developed for specifically regression problem by exploiting available information exhaustively , while adj was developed for general setting . in this paper , we point out that the derivation of dee includes an inappropriate part in spite that the resultant form of dee is valid in a sense . as its result , dee can not derive its potential . </S>",
    "<S> we introduce a class of ` valid ' risk estimators based on the idea of dee and show that better risk estimators ( mdee ) can be found in the class . by numerical experiments </S>",
    "<S> , we verify that mdee often performs better than or at least equally the original dee and adj . </S>"
  ]
}