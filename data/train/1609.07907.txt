{
  "article_text": [
    "one of the main goals of information theory founded by c.e .",
    "shannon in 1948 is to make digital communications over a noisy channel .",
    "applications are found in nowadays technology in fourth and fifth generations of mobile networks , in digital video broadcast , in optical communications at the internet backbone , etc .",
    "information theory @xcite predicts the existence of good error - correcting codes that are capable of achieving channel capacity .",
    "these optimal codes can transmit at the highest possible information rate given the noise level in the channel . in the past half century , mathematicians and engineers built many families of error - correcting codes  @xcite,@xcite , to make true ( or almost true ) the performance predicted by information theory .",
    "the latter is a theory for asymptotically long codes . at asymptotic length ,",
    "the code analysis is easier  @xcite ( think about the law of large numbers ) .",
    "also , in some specific applications such as fiber optic communications and data storage , huge packets of data are used allowing the application of capacity achieving codes . in recent fifth generation systems which are currently under construction , engineers are interested in short length packets . in parallel , at the theoretical side",
    ", researchers are studying the finite length regime of codes  ( e.g.  @xcite ) .",
    "our paper is dedicated to error - correcting codes of short length , typically 256 bits .",
    "phenomena observed at asymptotic length ( 100 thousand bits and above ) like channel polarization  @xcite and threshold saturation  @xcite do not have a practical effect at these short lengths .    in this work",
    ", we compare the performance of short - length linear binary codes under equal - complexity identical decoding conditions based on a universal decoder .",
    "complexity is not the main issue of this paper .",
    "we aim at comparing codes with respect to their performance by means of the best possible decoder which yields maximum likelihood ( ml ) or near maximum likelihood error rates .",
    "two channels are considered for this performance comparison : the binary erasure channel ( bec ) and the binary input additive white gaussian noise ( bi - awgn ) channel .",
    "the former channel corrupts the transmitted codeword by erasing some of its bits , the latter adds white gaussian noise to the observed values corresponding to the codeword bits . to recover the original information transmitted over the channel , the receiver has to decode the corrupted observation . over the years",
    ", many decoding strategies have been developed , often specific to one family of error - correcting codes @xcite,@xcite,@xcite . for our comparison , we use a universal decoder that can decode any linear binary block code : gaussian - elimination based ml decoder on the bec and probabilistic ordered statistics decoder ( osd ) on the bi - awgn channel .",
    "moreover , the decoders under consideration are also optimal@xmath0near - optimal whereas many decoding strategies are sub - optimal , favoring decoding speed over performance . as a result",
    "we compare codes and not decoders .",
    "the paper is structured as follows .",
    "notation and ml decoding on the erasure channel are described in the next section .",
    "section  [ sec_osd ] briefly explains osd decoding and its improvements .",
    "the list of linear binary block codes considered in this paper is found in section  [ sec_codes ] .",
    "section  [ sec_results ] includes performance results in terms of word error rate .",
    "our conclusions on the performance of short - length codes are drawn in the final section .",
    "the first scenario we consider is that of ml decoding on the bec channel . at the transmitter , a length-@xmath1 binary information message @xmath2 , consisting of independent and identically distributed ( i.i.d . )",
    "bits with @xmath3 , is encoded into a binary coded message @xmath4 of length @xmath5 using a linear binary block code @xmath6 .",
    "the code @xmath6 is completely specified by its @xmath7 generator matrix @xmath8  @xcite . in systematic form",
    "we have @xmath9 $ ] , where @xmath10 is the @xmath11 identity and @xmath12 is a parity matrix defining the code .",
    "the encoding operation can be written as @xmath13 $ ] with @xmath14 the parity bits corresponding to @xmath15 .",
    "this codeword is transmitted over the bec channel with erasure probability @xmath16 such that at the receiver we get the sequence @xmath17 with @xmath18 and @xmath19 , for @xmath20 , i.e. the symbol transmitted over the channel is erased with probability @xmath16 . at the receiver , ml decision is performed to construct an estimate @xmath21 of the originally transmitted @xmath15 , based on the observation @xmath17 .",
    "maximum likelihood decoding of a linear binary code on the erasure channel is equivalent to filling bits , as much as possible , among those erased by the channel .",
    "the verb _ fill _ is equivalent to _ solve _ in this context .",
    "let @xmath22 be the @xmath23 parity - check matrix of @xmath6 .",
    "the parity - check constraint @xmath24 is true for every codeword @xmath25 in @xmath6  @xcite .",
    "the linear system @xmath24 is used to fill erasures via gaussian elimination .",
    "let @xmath26 be the erasure weight , i.e. @xmath26 is the number of erased bits in the transmitted codeword @xmath25 .",
    "assume that @xmath6 has parameters @xmath27 , where @xmath28 is its minimum hamming distance .",
    "for @xmath29 , all @xmath26 erasures in any @xmath26 positions can be filled by an algebraic decoder or a ml decoder  @xcite . for non - trivial binary codes",
    ", for @xmath30 , @xmath31 being the rank of @xmath22 , algebraic decoding fails because it is bounded by @xmath28 whereas ml decoding based on solving @xmath24 may fill a fraction of the erased bits or all of them .",
    "ml decoding via gaussian elimination has an affordable complexity , at least in software applications , for a code length @xmath5 as high as a thousand bits .",
    "the cost of solving @xmath24 is @xmath32 .",
    "results shown in section  [ sec_results ] are obtained for a short length @xmath33 .",
    "the transmitter for the bi - awgn channel is the same as for the bec channel , notation is inherited from the previous section . before transmission on the bi - awgn channel ,",
    "the coded message is mapped to a bpsk symbol sequence @xmath34 using the rule @xmath35 .",
    "this symbol sequence is transmitted over the awgn channel characterized by its single sided noise spectral density @xmath36 . at the output of the channel , we receive @xmath37 where @xmath38 is a set of i.i.d . real gaussian random variables with zero mean and variance @xmath39 . note that the symbols @xmath40 are normalized to unit energy such that the energy transmitted per information bit equals @xmath41 .    at the receiver soft - decision decoding",
    "is performed to construct an estimate @xmath42 of the originally transmitted information message @xmath15 . for this estimate",
    ", the decoder makes use of two vectors corresponding to the sign and magnitude of the received signal @xmath43 : + the hard - decision @xmath44 $ ] where @xmath45 and the confidence values @xmath46 to understand that @xmath47 is indeed a measure for the confidence of the received @xmath48 , it suffices to see that the log - likelihood ratio is @xmath49 for the considered system .",
    "a hard - decision decoder only uses the vector @xmath17 to produce its estimate @xmath42 .",
    "the omission of the information contained in the magnitude of @xmath43 explains why hard - decision decoders perform worse than soft - decision decoders ( page 15 in @xcite ) .",
    "soft - decision decoding by the receiver is performed using the osd algorithm , an efficient most reliable basis ( mrb ) decoding algorithm firstly proposed by dorsch @xcite , further developed by fang and battail @xcite , and later analyzed and revived by fossorier and lin  @xcite . in the first step of the algorithm ,",
    "the received vector @xmath43 is sorted in order of descending confidence and the corresponding permutation @xmath50 is applied to the generator matrix @xmath8 , yielding @xmath51 .",
    "gaussian elimination is now performed on @xmath51 to construct the systematic @xmath52 , note that an additional permutation @xmath53 may be necessary .",
    "we write @xmath54 $ ] and @xmath55 , note that @xmath56 corresponds to the most - reliable independent positions of the received vector @xmath43 .    during the osd algorithm ,",
    "test - error patterns ( teps ) @xmath57 of increasing weight are generated .",
    "they are added to the hard - decision information bits @xmath56 on the mrb and the corresponding codeword @xmath58 is obtained by re - encoding via the systematic generator matrix @xmath52 .",
    "the trivial tep @xmath59 results in the order-0 osd codeword @xmath60 .",
    "the tep @xmath61 results in codeword @xmath62 . undoing the permutations",
    "yields the estimate @xmath63 of the original codeword @xmath25 .",
    "after every re - encoding operation , the euclidean distance between the osd codeword @xmath64 and the received vector @xmath43 is calculated .",
    "if this distance is lower than that of the current best osd codeword , we select @xmath64 as the new best codeword estimate .",
    "note that for bpsk modulation , minimizing the euclidean distance is equivalent to minimizing the weighted hamming distance @xmath65 the osd algorithm is terminated after a predetermined number of re - encodings . for example , in osd order 2 , the following patterns are generated :",
    "@xmath66    it follows that in osd order 1 , @xmath67 patterns are generated , in osd order 2 we generate @xmath68 patterns , etc .",
    "hence the complexity of the algorithm is @xmath69 . in",
    "@xcite it was shown that order-@xmath70 reprocessing is asymptotically optimal ( close to ml ) for @xmath71 such that the complexity is determined by both @xmath1 and @xmath72 .",
    "choosing the osd order lower than the optimal allows a performance - complexity trade - off . in this paper , in section  [ sec_results ] , we compare codes at the best possible osd decoding performance .      in the literature , several improvements to the original osd algorithm have been presented that aim to reduce the complexity of the optimal decoder and offer a finer performance - complexity trade - off   @xcite . in our implementation of the algorithm we used the probabilistic necessary condition from  @xcite , the probabilistic sufficient condition  @xcite , the reference re - encoding scheme  @xcite , the preprocessing rules from  @xcite , and the multiple biases diversity scheme from  @xcite .",
    "after having implemented these improvements , we can no longer use the rule @xmath73 to determine the optimal osd order .",
    "furthermore , the parameters of the improvements also have to be set . to determine if the decoder performs ( near-)optimally , we make use of an ml lower bound calculated during computer simulation",
    "whenever the decoder outputs an erroneous estimate of the originally transmitted information word , the euclidean distance between the original codeword @xmath25 and the received vector @xmath74 is evaluated .",
    "if this distance is larger than the distance between the decoder output @xmath75 and @xmath74 , then the ml decoder would also have made an erroneous decision .",
    "figure  [ fig_plot_osd_ml_lower ] shows the simulated performance of the ( 256,115 ) extended bch code for two different choices of osd parameters . the ml lower bound derived from the simulation with near - optimal parameters is also shown .",
    "we conclude that the second set of parameters leads to near - optimal results for this particular code at these signal - to - noise ( snr ) values .",
    "the sub - optimal parameters , not considered in section  [ sec_results ] , are however suitable for some practical applications because they lead to a decoding with a noticeably lower complexity at the expense of only a small loss of performance .",
    "we apologize for not considering convolutional codes and turbo codes ( parallel concatenated conv .",
    "codes )  @xcite , @xcite .",
    "results on turbo codes will be included in a future work .",
    "given the recent research activity in the coding community @xcite , we had to consider polar codes and reed - muller codes .",
    "also , bch codes are known to be good codes at short length  @xcite , @xcite .",
    "finally , ldpc codes from modern coding theory  @xcite are included .",
    "the list of binary codes regarded for performance comparison in the next section is :    * reed - muller codes : the code length is @xmath76 .",
    "take arikan s kernel @xmath77  @xcite and build its kronecker product @xmath78 times , i.e. build @xmath79 .",
    "then , select the @xmath1 rows of largest hamming weight to get the @xmath80 generator matrix . * polar codes : as for reed - muller codes , @xmath1 rows are selected from @xmath79 .",
    "these rows correspond to the highest mutual information . the bits of the remaining @xmath31 channels are frozen .",
    "* bch codes : standard binary primitive @xmath81 bch codes are built from their generator polynomial  @xcite , @xcite .",
    "an extension by one parity bit is made to get an even length .",
    "* ldpc codes : regular ( 3,6 ) low - density parity - check codes are built from a random bipartite tanner graph  @xcite .",
    "length-2 cycles are avoided , the number of length-4 cycles is reduced , but no other constraint was applied to the graph construction .",
    "the use of a cyclic redundancy check ( crc ) code to improve list decoding of polar code was introduced by i.  tal and a.  vardy @xcite . here ,",
    "given the universal nature of gaussian elimination for ml decoding on the bec and the universal nature of osd decoding on the bi - awgn channel , the crc code was jointly decoded with all of the codes listed above to investigate its influence on the performance .",
    "by jointly we mean that a unique generator matrix is used for decoding .",
    "this joint matrix is simply the product of the crc matrix with the generator matrix of the original code @xmath6 .",
    "let @xmath8 be the @xmath80 generator matrix of @xmath6 .",
    "let @xmath82 be the @xmath83 generator matrix of the crc code , where @xmath84 is the degree of the crc polynomial . then",
    ", joint osd decoding is based on the following generator matrix : @xmath85 the serial concatenation has the crc as outer code and the original error - correcting code @xmath6 as inner code .",
    "it is clear that the crc will scramble the original matrix @xmath8 making any code @xmath6 look like a random code .",
    "we considered @xmath86 redundancy bits and the crc - ccitt code with generator polynomial @xmath87",
    "we ran computer simulations to obtain the performance of binary codes listed in the previous section .",
    "randomly generated data is transmitted using the systems described in sections  [ sec_bec ]  and  [ sec_osd ] . at every considered value of @xmath16 for the bec and @xmath88 for the bi - awgn channel ,",
    "codewords were generated , transmitted , and decoded until 100 word errors occurred . during the computer simulation on the bi - awgn channel ,",
    "the ml lower bound was also recorded but we omit it from the figures to keep the graphs as clear as possible .",
    "the osd parameters were chosen such that the performance is near - ml and the ml lower bound ( almost ) coincides with the actual simulated performance of the code .",
    "lower bounds on the optimal performance of finite - length codes exist for both the bec and bi - awgn channel . on the figures we include for the bec the polyanskiy - poor - verd ( ppv ) bound on the maximal achievable rate , from theorem  53 in  @xcite , @xmath89 where @xmath90 is the word error probability at coding rate @xmath91 , length @xmath5 , and bec parameter @xmath16 .",
    "@xmath92 is the gaussian - tail function .",
    "computer simulations below take @xmath33 and @xmath93 or close to @xmath94 . on the bi - awgn channel ,",
    "we include the word error probability of optimal spherical code , by c.e .",
    "shannon  @xcite , @xmath95^n}{\\sqrt{\\frac{2re_b}{n_0}}g \\sin^2 \\theta_0 - \\cos \\theta_0},\\end{aligned}\\ ] ] where @xmath96 $ ] .",
    "the cone half - angle @xmath97 is computed by solving @xmath98 the two above approximations from @xcite are extremely accurate for lengths @xmath99 .",
    "+ figure  [ fig_plot_bec_no_crc ] shows the word error rate versus the channel erasure probability for ldpc , polar , rm , and bch codes , all under ml decoding on the bec . the performance of the ldpc code under iterative belief - propagation ( bp ) decoding is also included .",
    "no crc is used for this performance comparison .",
    "the binary ( 256,131 ) bch code is outperforming all other codes .",
    "notice that the regular-(3,6 ) binary ldpc code has an excellent behavior .",
    "figure  [ fig_plot_bec_crc ] shows the same codes on the bec concatenated with the 16-bit crc code given in section  [ sec_codes ] .",
    "the horizontal scale in figure  [ fig_plot_bec_crc ] is from 0.44 to 0.5 only !",
    "all codes exhibit a performance within a small range of error rate . as mentioned in section  [ sec_codes ]",
    ", the crc scrambles the original generator matrix and the universal decoder ( gaussian elimination or osd ) does a joint decoding of both codes .",
    "it is worth mentioning that the bch code has dimension @xmath100 , hence its coding rate is higher than other codes and its ppv bound moves up with respect to the ppv bound at rate  @xmath94 .",
    "this explains why the bch code appears to be weaker , in fact it is closer to its ppv bound than the other codes .",
    "the word error rate on the binary - input gaussian channel is plotted on figures  [ fig_plot_biawgn_no_crc ] and  [ fig_plot_biawgn_crc ] , without and with crc respectively .",
    "figure  [ fig_plot_biawgn_no_crc ] also includes the ldpc code under iterative belief - propagation ( bp ) decoding . with or without crc ,",
    "the ( 256,128 ) bch code has the best performance versus the signal - to - noise ratio . as on the bec",
    ", the crc makes all codes behave almost like random codes , so the snr gap between the worst and the best codes is very small .",
    "we have compared the performance of four different short - length linear binary codes on the binary erasure channel ( bec ) and the binary - input gaussian ( bi - awgn ) channel .",
    "the word error rate versus the channel parameter was plotted for ldpc , reed - muller , polar , and bch codes . in both channel scenarios ,",
    "a universal , optimal@xmath0near - optimal decoder was used : the ml decoder for the bec ( via gaussian elimination ) and the osd soft - decision decoder for the awgn channel . from the computer simulation results ,",
    "we conclude that the bch code outperforms reed - muller , polar , and ldpc codes on both channels .",
    "this behavior changes when we concatenate codes with a 16-bit crc and perform joint decoding . as a result ,",
    "the performance curves of the different codes lie much closer together and the choice of a good error - correcting code is not so critical .",
    "johannes  van  wonterghem would like to thank the research foundation in flanders ( fwo ) for funding his phd fellowship .",
    "the work of joseph  j.  boutros was supported by the qatar national research fund ( qnrf ) , a member of qatar foundation , under nprp project 6 - 784 - 2 - 329 .",
    "e.  arikan , `` channel polarization : a method for constructing capacity achieving codes for symmetric binary - input memoryless channels , '' _ ieee trans .",
    "inf . theory _ ,",
    "55 , no .  7 , pp .  3051 - 3073 , july  2009 .    s.  kudekar , t.  richardson , and r.l .",
    "urbanke , `` spatially coupled ensembles universally achieve capacity under belief propagation , '' _ ieee trans .",
    "inf . theory _ ,",
    "59 , no .  12 , pp .  7761 - 7813 , dec .  2013 .                w.  jin and m.  p.  c.  fossorier , `` probabilistic sufficient conditions on optimality for reliability based decoding of linear block codes , '' _ ieee international symposium on information theory _",
    ", seattle , wa , pp .  2235 - 2239 , 2006 ."
  ],
  "abstract_text": [
    "<S> we compare the performance of short - length linear binary codes on the binary erasure channel and the binary - input gaussian channel . </S>",
    "<S> we use a universal decoder that can decode any linear binary block code : gaussian - elimination based maximum - likelihood decoder on the erasure channel and probabilistic ordered statistics decoder on the gaussian channel . as such </S>",
    "<S> we compare codes and not decoders . </S>",
    "<S> the word error rate versus the channel parameter is found for ldpc , reed - muller , polar , and bch codes at length 256 bits . </S>",
    "<S> bch codes outperform other codes in absence of cyclic redundancy check . under joint decoding </S>",
    "<S> , the concatenation of a cyclic redundancy check makes all codes perform very close to optimal lower bounds . </S>"
  ]
}