{
  "article_text": [
    "game theory arouse from the need to model economic behavior , where multiple decision makers ( mdm ) with antagonistic goals is a natural feature .",
    "it was further extended to broader areas , where mdm had however to deal with systems governed by ordinary differential equations , the so - called differential games .",
    "see e.g. , @xcite for a nice introduction to the general theory and @xcite for differential games .",
    "recently , engineering problems with antagonistic design goals and with real or virtual mdm were formulated by some authors within a game - theoretic framework .",
    "see e.g. , @xcite for aerodynamics , @xcite for structural topology design , @xcite for missing data recovery problems .",
    "the study of multi - agent systems or games such as poker under this setting is also quite common in the ai and machine learning communities , see e.g. , @xcite .",
    "solutions to games are called equilibria .",
    "contrarily to classical optimization , the definition of an equilibrium depends on the game setting ( or rules ) . within the static with complete information",
    "setting , a relevant one is the so - called nash equilibrium ( ne ) . shortly speaking ,",
    "a ne is a fixed - point of iterated many single optimizations ( see the exact definition in section-[sec : background ] below ) .",
    "its computation generically carries the well known tricks related to computing a fixed - point , as well as those related to intensive optimizations notably when cost evaluations are expensive , which is mostly the case for engineering applications .",
    "there is an extensive literature related to theoretical analysis of algorithms for computing ne @xcite , but very little -if any- on black - box models ( i.e. , non convex utilities ) and expensive - to - evaluate ones ; to the best of our knowledge , only home - tailored implementations are used . on the other hand , _ bayesian optimization _ ( bo , * ? ? ?",
    "* ) is a popular approach to tackle black - box problems .",
    "our aim is to investigate the extension of such approach to the problem of computing game equilibria .",
    "bo relies on gaussian processes , which are used as emulators ( or surrogates ) of the black - box model outputs based on a small set of model evaluations .",
    "posterior distributions provided by the gaussian process are used to design _ acquisition functions _ that guide sequential search strategies that balance between exploration and exploitation .",
    "such approaches have been transposed to frameworks other than optimization , such as uncertainty quantification @xcite or optimal stopping problems in finance @xcite .    in this paper",
    ", we show that the bo apparatus can be applied to the search of game equilibria , and in particular the classical nash equilibrium ( ne ) . to this end , we propose two complementary acquisition functions , one based on a greedy search approach and one based on the stepwise uncertainty reduction paradigm @xcite .",
    "our proposal is designed to tackle derivative - free , expensive models , hence requiring very few model evaluations to converge to the solution .",
    "the rest of the paper is organized as follows .",
    "section [ sec : background ] reviews the basics of game theory and present our gaussian process framework .",
    "section [ sec : sequential ] presents our main contribution , with the definition of two acquisition functions , along with computational aspects .",
    "finally , section [ sec : experiments ] demonstrates the capability of our algorithm on several challenging problems .",
    "for non - cooperative static games with complete information and no leadership / followers features , a relevant game solution is nash equilibrium @xcite .",
    "let us consider a finite number , say @xmath0 , of decision makers ( i.e. , players ) .",
    "player ( i ) has an action space @xmath1 , and a specific cost function @xmath2 .",
    "we denote @xmath3 , and @xmath4 .",
    "we shall use the convention @xmath5 when we need to emphasize the role of @xmath6 .",
    "we warn the reader that _ it is only notation , no effective permutation is done_. then , one has @xmath7 .",
    "that is , clearly each player s cost depends on others choices .",
    "[ [ definition . ] ] definition .",
    "+ + + + + + + + + + +    a nash equilibrium @xmath8 is a strategy such that , for any @xmath9 ,    @xmath10    in other words , when all players have chosen to play a ne , then no single player ( i ) has incentive to move from his @xmath11 .",
    "let us however mention by now that , generically , nash equilibria are not efficient , i.e. , do not belong to the underlying set of best compromise solutions , called pareto front , of the objective vector @xmath12 .",
    "[ [ remark . ] ] remark .",
    "+ + + + + + +    in this work , we focus essentially on continuous games ( i.e. , with infinite sets @xmath1 ) or on large finite games ( i.e. , with large finite sets @xmath1 ) , and consider solely pure - strategy nash equilibria ( as opposed to mixed - strategies equilibria , in which the optimal strategies can be chosen stochastically * ? ? ?",
    "* chapter 1 ) .    from a bo perspective , the costs , issued from a black - box model , are expressed as functions of decision ( or design ) variables which we denote @xmath13 , with @xmath14 , rather than actions @xmath15 . if a classical setting is to consider a single decision variable by player ( @xmath16=@xmath17 )",
    ", there are many cases where the strategies encompass a set of variables : this is the case of the differential game example described in section [ ssec : differential ] .",
    "hence , @xmath15 carries the splitting of @xmath18 between players ; e.g. , if two players share a decision variable @xmath19 as follows : player ( 1 ) controls @xmath20 and player ( 2 ) controls @xmath21 and @xmath22 , then @xmath23 with @xmath24 and @xmath25 .",
    "as we show in the next section , such a distinction becomes critical when it comes to gp modeling , which may only be done with respect to @xmath18 .",
    "hence , we write the costs as a single function @xmath26 , with real vectorial inputs and outputs : @xmath27.\\end{aligned}\\ ] ] @xmath28 is the definition space of the decision variables @xmath18 , typically a hyper - rectangle .",
    "note that in the following , we also use the notation @xmath29 when it does not bring any confusion .",
    "as we show in section [ sec : sequential ] , our approach requires @xmath28 to be discrete .",
    "if @xmath28 is originally continuous , we assume that a representative discretization is available so that the equilibrium of the corresponding finite game is similar to the one of original problem . to account for the particular form of ne , the discretization must realize a full - factorial design in the @xmath30 space : given each action space @xmath31 of size @xmath32 , @xmath28 consists of all the combinations @xmath33 ( @xmath34 , @xmath35 , @xmath36 ) , and we have @xmath37 .",
    "if a regular grid over @xmath18 always satisfies this constraint , many alternatives are possible : going back to the example @xmath24 and @xmath25 , one may discretize for instance @xmath20 over a regular grid and @xmath38 using a latin hypercube design .",
    "the idea of replacing an expensive function by a cheap - to - evaluate surrogate is not new , with initial attempts based on linear regression .",
    "gaussian process regression , or kriging , extends the versatility and efficiency of surrogate - based methods in many applications , such as in optimization or reliability analysis . among alternative non - parametric models such as radial basis functions or random forests ,",
    "see e.g. , @xcite for a discussion , gp priors are attractive in particular for their tractability , since they are simply characterized by their mean @xmath39 and covariance ( or kernel ) @xmath40 functions , see e.g. , @xcite . in the following ,",
    "we consider zero - mean processes ( @xmath41 ) and no observational noise for the sake of conciseness , but our approach straightforwardly adapts to those cases .",
    "briefly , for a single objective @xmath42 , conditionally on @xmath43 observations at @xmath44 , the predictive distribution is another gp , with mean and covariance functions given by : @xmath45 where @xmath46 and @xmath47 .",
    "commonly , @xmath40 belongs to a parametric family of covariance functions such as the gaussian and matrn kernels , based on hypothesis about the smoothness of @xmath42 .",
    "corresponding hyperparameters are often obtained as maximum likelihood estimates , see e.g. , @xcite or @xcite for the corresponding details .",
    "+ with several objectives , while a joint modeling is possible ( see e.g. , @xcite ) , it is more common practice to treat them separately . in the following ,",
    "we assume that we have a statistical emulator for @xmath48 , conditioned on a set of observations @xmath49 , in the form of a multivariate gaussian process @xmath50 ( @xmath51 ) : @xmath52 with @xmath53 $ ] , @xmath54 , such that @xmath55 is the predictive mean and covariance , respectively , of a kriging model of the objective @xmath2 .",
    "this predictive distribution is used either to derive quantities based on its moments or to draw samples of @xmath50 indexed by a discrete set . for the latter ,",
    "the simple approach that we follow here is to cast the simulation as a standard gaussian vector simulation problem , thus relying on a cholesky decomposition of the covariance matrix ( see e.g. , * ? ? ?",
    "* for details ) .",
    "bayesian optimization methods are usually outlined as follows : a first set of observations @xmath56 is generated using a space - filling design to obtain a first predictive distribution of @xmath57 .",
    "then , observations are performed sequentially by maximizing a so - called _ acquisition function _ ( or infill criterion ) @xmath58 , that represents the potential usefulness of a given input @xmath18 .",
    "that is , at step @xmath59 , @xmath60 in unconstrained optimization , the canonical choice for @xmath58 is the so - called _ expected improvement _",
    "( ei , * ? ? ?",
    "* ) , which offers an efficient trade - off between exploration of unsampled regions ( high posterior variance ) and exploitation of promising ones ( low posterior mean ) .",
    "improvement - based approaches have many advantages ( among which a convenient closed form expression for the ei ) , however it can not apply to our case , as it requires to measure an ( expected ) progress over a _",
    "current best solution _ , which does not exist here ( there is no such thing as a `` current best ne '' ) .",
    "hence , we propose in the following two acquisition functions based on alternative concepts , respectively the probability of achieving equilibrium and stepwise uncertainty reduction .",
    "both aim at providing an efficient trade - off between exploration and exploitation .",
    "given a predictive distribution of @xmath57 , a first natural metric to consider is the probability of achieving the ne . in case of finite games , this probability writes : @xmath61 where @xmath62 denotes the alternatives for @xmath6 , and @xmath63 is fixed to its value in @xmath15 .",
    "since our gp model assumes the independence of the posterior distributions of the objectives , we have : @xmath64 as exploited recently by @xcite in a multi - point optimization context , each @xmath65 can be expressed as @xmath66 where @xmath32 is the number of alternatives for @xmath6 with fixed @xmath63 and @xmath67 .",
    "@xmath68 amounts to compute the cumulative distribution function ( cdf ) of @xmath69 $ ] , the ( gaussian ) vector of size @xmath70 with mean @xmath71 and covariance @xmath72 , i.e. , @xmath73 .",
    "see @xcite for calculation details .",
    "several fast implementations of the multivariate gaussian cdf are available , for instance in the ` r ` packages ` mnormt ` ( for @xmath74 ) @xcite or , up to @xmath75 , by quasi - monte - carlo with ` mvtnorm ` @xcite .    alternatively , this quantity can be computed using monte - carlo methods by drawing @xmath76",
    "samples @xmath77 of @xmath78 $ ] to compute @xmath79 @xmath80 denoting the indicator function .",
    "this latter approach may be preferred when the number of alternatives @xmath32 is high ( say @xmath81 ) , which makes the cdf evaluation overly expensive while a coarse estimation may be sufficient .",
    "note that on both cases , a substantial computational speed - up can be achieved by removing from the @xmath1 s the non - critical strategies .",
    "this point is discussed in section [ sec : numerical ] .",
    "using @xmath82 as an acquisition function ( to maximize ) defines an intuitive sequential sampling strategy ( i.e. , sampling at designs most likely to achieve ne ) .",
    "note that its counterpart in global optimization , called _ probability of improvement _ , is usually discarded for not being exploratory enough @xcite .",
    "here , @xmath83 is expected to perform better , as both solutions with low mean and those with high variance may realize the minimum .",
    "still , maximizing @xmath83 is a _",
    "myopic _ approach ( i.e. , favoring an immediate reward instead of a long - term one ) , which are often sub - optimal ( see e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* and references therein ) . instead",
    ", other authors have advocated for the use of an information gain from a new observation instead , see e.g. , @xcite , which motivated the definition of an alternative acquisition function , which we describe next .      _ stepwise uncertainty reduction _",
    "( sur ) has recently emerged as an efficient approach to perform sequential sampling , with successful applications in optimization @xcite or uncertainty quantification @xcite .",
    "its principle is to perform a sequence of observations in order to reduce as quickly as possible an uncertainty measure related to the quantity of interest ( in the present case : the equilibrium ) .",
    "let us first denote by @xmath84 the application that associates a ne with a multivariate function .",
    "if we consider a random process @xmath50 in lieu of the deterministic objective @xmath48 , the equilibrium @xmath85 is a random vector of @xmath86 with unknown distribution .",
    "let @xmath87 be a measure of variability ( or residual uncertainty ) of @xmath85 ; we use here the determinant of its second moment : @xmath88.\\end{aligned}\\ ] ]    the sur strategy aims at reducing @xmath87 by adding sequentially observations @xmath89 on which @xmath50 is conditioned .",
    "an `` ideal '' choice of @xmath90 would be : @xmath91,\\ ] ] where @xmath92 is the process conditioned on the observation @xmath93 . since we do not want to evaluate @xmath48 for all @xmath90 candidates , we consider the following criterion instead : @xmath94 \\right),\\ ] ] with @xmath95 following the posterior distribution ( conditioned on the @xmath43 current observations ) and @xmath96 denoting the expectation over @xmath97 .",
    "the sur strategy is then : @xmath98    in practice , computing @xmath99 is a complex task , as no closed - form expression is available .",
    "the next subsection is dedicated to this question .",
    "let us first focus on the measure @xmath87 when no new observation is involved .",
    "due to the strong non - linearity of @xmath100 , no analytical simplification is available , so we rely on conditional simulations of @xmath50 to evaluate @xmath87 .",
    "let @xmath101 be independent drawings of @xmath102 ( each @xmath103 ) .",
    "the following empirical estimator of @xmath104 is available : @xmath105,\\ ] ] with @xmath106 the sample covariance of @xmath107 .",
    "now , let us assume that we evaluate the criterion for a given candidate observation point @xmath108 .",
    "let @xmath109 be independent drawings of @xmath110 . for each @xmath111",
    ", we can condition @xmath50 on the event @xmath112 in order to generate @xmath113 drawings of @xmath114 , from which we can compute the empirical estimator @xmath115 .",
    "then , an estimator of @xmath99 is obtained using the empirical mean : @xmath116      the proposed sur strategy has a substantial numerical cost , as the criterion requires a double loop for its computation : one over the @xmath117 values of @xmath118 and another over the @xmath119 sample paths .",
    "the two computational bottlenecks are the sample path generations and the searches of equilibria , and both are performed in total @xmath120 times for a single estimation of @xmath121 .",
    "thankfully , several computational shortcuts allow us to limit the cost of our approach .",
    "first , fast formulae are used to obtain drawings of @xmath122 based on drawings of @xmath50 .",
    "we refer to @xcite for the detailed algebra and complexity analysis . in our case",
    ", we generate a unique set of drawings @xmath101 , prior to the search for @xmath90 , which we update quickly when necessary depending on the pair @xmath123 .",
    "second , we discard points in @xmath28 that are unlikely to provide information regarding the equilibrium prior to the search of @xmath90 , as we detail below . by doing so ,",
    "we reduce substantially the sample paths size and the dimension of each finite game , which drastically reduces the cost .",
    "we call @xmath124 the retained subset .",
    "finally , @xmath125 is evaluated only on a small , promising subset of @xmath124 .",
    "we call @xmath126 this set .    to select the subsets , we rely on a fast - to - evaluate score functions @xmath127 , which can be seen as a proxy to the more expensive acquisition function",
    ". the subset of @xmath28 is then chosen by sampling randomly with probabilities proportional to the scores @xmath128 , while ensuring that the subset retains a factorial form .",
    "we propose three scores , of increasing complexity and cost , which can be interleaved :    * @xmath129 : the simplest score is the posterior density at a target @xmath130 in the objective space , for instance the ne of the posterior mean ( hence , it requires one ne search ) .",
    "@xmath129 reflects a proximity to an estimate of the ne .",
    "we use this scheme for the first iteration to select @xmath131 . *",
    "@xmath132 : once conditional simulations have been performed , the above scheme can be replaced by the probability for a given strategy to fall into the box defined by the extremal values of the simulated ne ( i.e. , @xmath107 ) .",
    "we use this scheme to select @xmath131 for all the other iterations .",
    "* @xmath133 : since @xmath83 is faster ( in particular in its monte carlo setting with small @xmath76 ) than @xmath134 , it can be used to select @xmath135 .",
    "note that in our experiments , @xmath129 and @xmath132 are also used with the @xmath83 acquisition function .",
    "last but not least , this framework enjoys savings from parallelization in several ways .",
    "in particular , the searches of ne for each sample @xmath136 can be readily distributed .",
    "an overview of the full sur approach is given in pseudo - code in algorithm [ alg : sur ] .",
    "note that by construction , sur does not necessarily sample at the ne , even when it is well - identified .",
    "hence , as a post - processing step , the returned ne estimator is the design that maximizes the probability of achieving equilibrium .",
    "@xmath137 , @xmath138 , @xmath139 , @xmath140 construct initial design of experiments @xmath56    train the @xmath141 gp models on available data estimate @xmath142 , the ne on the posterior mean ; select @xmath131 using @xmath129 select @xmath131 using @xmath132 generate @xmath119 drawings @xmath143 on @xmath124 compute @xmath107 ( for @xmath132 ) select @xmath135 using @xmath133 find @xmath144 evaluate @xmath145 @xmath146    [ alg : sur ]",
    "these experiments have been performed in ` r ` @xcite relying on the ` dicekriging ` package @xcite , while ` scilab ` @xcite has been used for fixed point methods . the code to reproduce the experiments will be made available .",
    "we first consider a classical optimization toy problem ( p1 ) as given in @xcite , with two variables and two cost functions , defined as : @xmath147 with @xmath148 $ ] and @xmath149 $ ] .",
    "both functions are non - convex .",
    "we set @xmath150 and @xmath151 ( note that choosing @xmath152 and @xmath153 does not change the ne here ) .",
    "the actual ne is attained at @xmath154 and @xmath155 .",
    "our strategies are parameterized as follow .",
    "@xmath28 is first discretized over a @xmath156 regular grid .",
    "since the size of @xmath28 is relatively small , we use @xmath157 , and @xmath158 .",
    "we use @xmath159 initial observations from a latin hypercube design , and observations are added sequentially using both acquisition functions . as a comparison , we ran a standard fixed - point algorithm @xcite based on finite differences .",
    "this experiment is replicated five times with different initial sets of observations for the gp - based approaches and different initial points for the fixed - point algorithm .",
    "the results are reported in table [ tab : p1results ] .",
    "in addition , figure [ fig : p1 ] provide some illustration for a single run . in the initial state (",
    "top left ) , the simulated nes form a cloud in the region of the actual ne .",
    "a first point is added , although far from the ne , that impacts the form of the cloud ( top right ) . after adding 7 points",
    "( bottom left ) the cloud is smaller and centered on the actual ne , and after 14 additions ( bottom right ) , all simulated ne but two concentrate on the actual ne .",
    "the observed values have been added around the actual ne , but not only , which indicates that some exploration steps have been performed .",
    ".p1 convergence results . [",
    "cols=\"^,^,^\",options=\"header \" , ]",
    "we have proposed here a novel approach to solve nash games with drastically limited budgets of evaluations based on gp regression , taking the form of a bayesian optimization algorithm .",
    "experiments on challenging synthetic problems demonstrate the potential of this approach compared to classical , derivative - based algorithms .    on the test problems , the two acquisition functions performed similarly well .",
    "@xmath83 has the benefit of not relying on conditional simulation paths , which makes it simpler to implement and less computationally intensive in most cases .",
    "still , the sur approach has several decisive advantages ; in particular , it does not actually require the new observations to belong to the grid @xmath124 , such that it could be optimized continuously .",
    "moreover , it lays the groundwork for many extensions that may be pursued in future work .",
    "first , sur strategies are well - suited to allow selecting batches of points instead of only one , a key feature in distributed computer experiments @xcite .",
    "second , other games and equilibria may be considered : the versatility of the sur approach may allow its transposition to other frameworks , such as mixed - strategies or bayesian games .",
    "in particular , our framework transposes directly to the case of noisy evaluations , as it can be directly modeled by the gps without affecting the acquisition functions . finally , investigating convergence properties , in light of recent advances on sur approaches @xcite , may be investigated .",
    "the authors acknowledge inspiration from lorentz center workshop `` samco - surrogate model assisted multicriteria optimization '' , at leiden university feb 29 - march 4 , 2016 .",
    "mickal binois is grateful for support from national science foundation grant dms-1521702 .",
    "brown , n. , ganzfried , s. & sandholm , t. ( 2015 ) .",
    "hierarchical abstraction , distributed equilibrium computation , and post - processing , with application to a champion no - limit texas holdem agent . in _ proceedings of the 2015 international conference on autonomous agents and multiagent systems_.            fleuret , f. & geman , d. ( 1999 ) . graded learning for object detection . in _ proceedings of the workshop on statistical and computational theories of vision of the ieee international conference on computer vision and pattern recognition ( cvpr / sctv ) _ , vol .  2 .",
    "gonzalez , j. , osborne , m. & lawrence , n. ( 2016 ) .",
    "glasses : relieving the myopia of bayesian optimisation . in _ proceedings of the 19th international conference on artificial intelligence and statistics_.            hernndez - lobato , j.  m. , hoffman , m.  w. & ghahramani , z. ( 2014 ) .",
    "predictive entropy search for efficient global optimization of black - box functions . in _ advances in neural information processing systems_.",
    "jala , m. , lvy - leduc , c. , moulines ,  . , conil , e. & wiart , j. ( 2016 ) . sequential design of computer experiments for the assessment of fetus exposure to electromagnetic fields .",
    "_ technometrics _ * 58 * , 3042 .",
    "lanctot , m. , burch , n. , zinkevich , m. , bowling , m. & gibson , r.  g. ( 2012 ) .",
    "no - regret learning in extensive - form games with imperfect recall . in _ proceedings of the 29th international conference on machine learning ( icml-12)_.            picheny , v. ( 2014 ) .",
    "a stepwise uncertainty reduction approach to constrained global optimization . in _ proceedings of the 17th international conference on artificial intelligence and statistics _",
    "jmlr w&cp .",
    "roustant , o. , ginsbourger , d. & deville , y. ( 2012 ) .",
    ", diceoptim : two r packages for the analysis of computer experiments by kriging - based metamodeling and optimization .",
    "_ journal of statistical software _ * 51 * , 155 ."
  ],
  "abstract_text": [
    "<S> game theory finds nowadays a broad range of applications in engineering and machine learning . </S>",
    "<S> however , in a derivative - free , expensive black - box context , very few algorithmic solutions are available to find game equilibria . here </S>",
    "<S> , we propose a novel gaussian - process based approach for solving games in this context . </S>",
    "<S> we follow a classical bayesian optimization framework , with sequential sampling decisions based on acquisition functions . </S>",
    "<S> two strategies are proposed , based either on the probability of achieving equilibrium or on the stepwise uncertainty reduction paradigm . </S>",
    "<S> practical and numerical aspects are discussed in order to enhance the scalability and reduce computation time . </S>",
    "<S> our approach is evaluated on several synthetic game problems with varying number of players and decision space dimensions . </S>",
    "<S> we show that equilibria can be found reliably for a fraction of the cost ( in terms of black - box evaluations ) compared to classical , derivative - based algorithms . </S>"
  ]
}