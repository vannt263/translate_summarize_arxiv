{
  "article_text": [
    "the boosting algorithm is one of the most powerful learning techniques introduced during the past decade .",
    "the motivation for the boosting algorithm is to design a procedure that combines many `` weak '' classifiers ( such as decision trees , random forests , anns etc . ) to achieve a powerful classifier .",
    "one starts with unweighted training events and builds a decision tree@xcite .",
    "if a training event is misclassified , then the weight of that event is increased ( boosted ) .",
    "a second tree is built using exactly the same set of training events but with new weights .",
    "again misclassified events have their weights boosted and the procedure is repeated several hundred to thousand times until the performance becomes optimal .",
    "each test event is followed through each tree in turn .",
    "if it lands on a signal leaf it is given a score of 1 , otherwise @xmath0 .",
    "the sum of the scores from all trees , is the final score of the event .",
    "a high score means that the event is most likely signal and a low score that it is most likely background .",
    "the major advantages of boosted decision trees are their stability , their ability to handle large numbers of input variables , and their use of boosted weights for misclassified events to give these events a better chance to be correctly classified in succeeding trees .",
    "the artificial neural network ( ann ) technique has been widely used in data analysis of high energy physics ( hep ) experiments in the last decade .",
    "the use of the ann technique usually gives better results than the traditional simple - cut techniques .",
    "based on our previous studies , boosted decision trees ( bdt ) with the adaboost@xcite or @xmath1boost@xcite algorithms perform better than ann and some other boosting algorithms for miniboone particle identification ( pid)@xcite . more and more major hep experiments ( atlas , babar , cdf , d0 etc . ) @xcite have begun to use boosting algorithms as an important tool for data analysis since our first successful application of bdt for miniboone pid@xcite .    in this paper",
    "we discuss the boosting method in the context of miniboone . for practical applications of data mining algorithms , performance , stability and robustness",
    "are determinants .",
    "we focus on stability and robustness of ann and bdt with @xmath1boost ( @xmath2 ) by smearing or shifting values of input variables randomly for testing samples .",
    "the results obtained in this paper do not represent optimal miniboone pid performance because we only use 30 arbitrarily selected variables for ann and bdt training and testing .",
    "bdt with more input variables results in significantly better performance . however , ann will not improve significantly by using more input variables @xcite .",
    "miniboone is a crucial experiment operated at fermi national accelerator laboratory which is designed to confirm or refute the evidence for @xmath3 oscillations at @xmath4 seen by the lsnd experiment@xcite .",
    "it will imply new physics beyond the standard model of particle physics if the lsnd signal is confirmed by the miniboone experiment .",
    "the training sample has 50000 signal and 100000 background events .",
    "an independent testing sample has 54200 signal and 146600 background events . fully oscillated @xmath5 charged current quasi - elastic ( ccqe )",
    "events are signal ; all @xmath6 and non - ccqe intrinsic @xmath5 events are treated as background .",
    "the signature of each event is given by 322 variables@xcite .",
    "thirty out of 322 variables were selected randomly for this study .",
    "( the selection was by variable name not by the power of the variables . )",
    "all selected variables are used for ann and bdt training and testing .",
    "the detailed description of reconstructed variables is available in miniboone technical notes@xcite .",
    "here we briefly mention some of variables used for this study .",
    "the miniboone neutrino detector is filled with 800 tons of pure mineral oil , which is contained in a spherical tank of 610-cm inner radius .",
    "the detector is divided into two optical isolated regions .",
    "the inner region employs 1280 8-inch photomultiplier tubes ( pmts ) to measure the charge , time and position of particles produced by neutrino interactions on nuclei .",
    "the outer veto region is instrumented with 240 pmts to tag particles entering or leaving the detector .",
    "the final state charged particles passing through the oil can emit both prompt cherenkov and delayed isotropic scintillation photons , which are detected in a ratio of about 3:1 for @xmath7 particles .",
    "some reconstructed variables are listed in the following :    * fraction of very prompt pmt hits , @xmath8 * fraction of very late pmt hits , @xmath9 * reconstructed track length * angle between track direction and neutrino beam direction * ratio of scintillation flux to cherenkov flux * time likelihood in the cherenkov ring region @xmath10 * time likelihood in @xmath11 * time likelihood in @xmath12 * time likelihood in @xmath13 * time likelihood in @xmath14 * charge likelihood in various @xmath15 regions * reconstructed @xmath16 mass * angle between two @xmath17 s from @xmath16 decay * distance from the first @xmath17 conversion point to the tank wall * the difference of time likelihoods between electron and @xmath16 * the difference of charge likelihoods between electron and @xmath16 * ratio of measured to predicted charge in @xmath18 * ratio of measured to predicted charge in @xmath19 * for the two @xmath17 hypothesis , the fraction of cherenkov flux in the lower energy @xmath17    the time ( charge ) likelihood is the likelihood of the time ( charge ) distribution of the pmt hits under the given hypothesis .",
    "we prepared 10 statistically independent training samples .",
    "each sample has 5000 signal and 10000 background events selected sequentially from the large training sample . both ann and bdt",
    "are trained separately on each of these training samples . for a given testing sample , then , ann and bdt each have 10 sets of results .",
    "the mean values and variance of the 10 sets of results are calculated to compare the ann and bdt methods .",
    "in order to study the stability of ann and bdt on the testing samples , we randomly smear the input variables by 1% , 3% , 5% , 8% and 10% , respectively . the smearing formula is written as @xmath20 where @xmath21 represents value of @xmath22-th variable in @xmath23-th testing event , @xmath24 is the smearing factor (= 0 , 0.01 , 0.03 , 0.05 , 0.08 , 0.1 ) .",
    "@xmath25 is a random number with a gaussian distribution ; it is different for each variable and each event .",
    "the random shift formula can be written as @xmath20 where @xmath21 represents value of @xmath22-th variable in @xmath23-th testing event , @xmath24 is the shifting factor (= 0 , 0.01 , 0.03 , 0.05 , 0.08 , 0.1 ) and @xmath25 is a discrete random number with value 1 or @xmath0 .",
    "the values of all training variables are shifted positively .",
    "the formula is , @xmath26 where @xmath21 represents value of @xmath22-th variable in @xmath23-th testing event , @xmath24 is the shifting factor (= 0 , 0.01 , 0.03 , 0.05 , 0.08 , 0.1 ) .",
    "the values of all training variables are shifted negatively .",
    "the formula is , @xmath27 where @xmath21 represents value of @xmath22-th variable in @xmath23-th testing event , @xmath24 is the shifting factor (= 0 , 0.01 , 0.03 , 0.05 , 0.08 , 0.1 ) .",
    "each variable is shifted in one direction for all testing events . the shift direction for each variable",
    "is determined by a random number with the discrete values of 1 or @xmath0 .. the formula is written as , @xmath28 where @xmath21 represents value of @xmath22-th variable in @xmath23-th testing event , @xmath24 is the shifting factor (= 0 , 0.01 , 0.03 , 0.05 , 0.08 , 0.1 ) .",
    "all ann and bdt results shown in this paper are from testing samples .",
    "table 1 lists the signal and background efficiencies for ann and bdt with root mean square ( rms ) errors and statistical errors for background efficiencies .",
    "the efficiency ratio is defined as background efficiency from ann divided by that from bdt using the original testing sample ( no smearing and shifting ) and the same signal efficiency .",
    "efficiency ratio values greater than 1 mean that bdt works better than ann by suppressing more background events ( less background efficiency ) for a given signal efficiency . from table 1 ,",
    "the efficiency ratios vary from about 1.12 to 1.75 for signal efficiencies ranging from 90% to 30% .",
    "lower signal efficiencies yield higher ratio values .",
    "the statistical error of the test background efficiency for ann is slightly higher than that for bdt depending on the signal efficiency .",
    "the variance of 10 test background efficiencies for ann trained with 10 randomly selected training samples is about @xmath29 times larger than that for bdt .",
    "this result indicates that bdt training performance is more stable than ann training .",
    "the background efficiency versus signal efficiency for the smeared testing sample set 1 is shown in figure 1 .",
    "the top plot shows results from ann , the bottom plot shows results from bdt .",
    "dots are for the results from the testing sample without smearing , boxes , triangles , stars , circles and crosses are for results from testing samples with 1% , 3% , 5% , 8% and 10% smearing , respectively .",
    "both ann and bdt are quite stable for testing samples which are randomly smeared within 5% , typically within about 5%-12% performance decrease for bdt and 7% - 16% decrease for ann as shown in figure 1 . for the 10% smeared testing sample , however",
    ", the performance of ann is degraded by 37% to 62% ; higher signal efficiency results have larger degradation .",
    "the corresponding performance of bdt is degraded by 19% to 57% .",
    "the variance ( rms ) of background efficiencies based on trials versus signal efficiency for the 10 different smeared testing samples is shown in figure 2 .",
    "the variance of background efficiencies from bdt is about @xmath29 times smaller than that from ann as presented in the bottom plot of figure 3 .",
    "the variance ratios between ann and bdt remain reasonably stable for various testing samples with different smearing factors .",
    "figure 3 shows the ratio of background efficiency from ann and bdt versus signal efficiency ( top plot ) and the ratio of rms of background efficiency from ann and bdt versus signal efficiency ( bottom plot ) .",
    "dots are for results from the testing sample without smearing ; boxes , triangles , stars , circles and crosses are for results from 1% , 3% , 5% , 8% and 10% smearing , respectively .",
    "error bars in the top plot are for rms errors of ratios which are calculated by propagating errors from the rms errors from ann and bdt results .",
    "the performance of bdt ranges from 12% to 75% better than that of ann , depending on the signal efficiency as shown in the top plot of figure 3 .",
    "the ratio of background efficiency from ann and bdt increases with an increase in the smearing factor . for the testing sample with 10% random smearing ,",
    "the efficiency ratio increases about 15% .",
    "this result indicates that the bdt is more stable than ann for this set of specific testing samples with random smearing .",
    "figure 4 shows the background efficiency versus smearing factor for three given signal efficiencies 30%(dots ) , 50%(boxes ) and 70%(triangles ) .",
    "the top plot of figure 4 shows results from ann .",
    "the bottom plot of figure 4 shows results from bdt .",
    "the performance of ann and bdt degrade modestly with relatively small smearing factors @xmath30 0.03 .",
    "larger smearing factors result in significant performance degradation of ann and bdt .",
    "figure 5 shows the ratio of background efficiency from ann and bdt versus signal efficiency ( top plot ) and the ratio of variance of background efficiency from ann and bdt versus signal efficiency ( bottom plot ) for the testing samples of set 2 with random shifting .",
    "figure 6 shows the background efficiency versus smearing factor , for ann ( top plot ) and bdt ( bottom plot ) .",
    "resutls from the randomly shifted testing samples of set 2 are comparable to those from the randomly smeared testing samples of set 1 . in order to estimate the dependence of ann and bdt performance on the factor of random shifting , we vary the shifting factor from 0 to 0.5 , as shown in figure 7 .",
    "both ann and bdt performance degrade significantly by randomly shifting the input variables with large shifting factor ( @xmath31 0.1 ) .",
    "figure 8 shows the ratio of background efficiency from ann and bdt versus signal efficiency ( top plot ) and the ratio of variance of background efficiency from ann and bdt versus signal efficiency ( bottom plot ) for the testing samples of set 3 with overall positive shifting .",
    "figure 9 shows the background efficiency versus smearing factor , for ann ( top plot ) and bdt ( bottom plot ) .",
    "the results are reasonably stable for both ann and bdt versus shifting factor .",
    "figure 10 shows the ratio of background efficiency from ann and bdt versus signal efficiency ( top plot ) and the ratio of variance of background efficiency from ann and bdt versus signal efficiency ( bottom plot ) for the testing samples of set 4 with overall negative shifting .",
    "figure 11 shows the background efficiency versus smearing factor , for ann ( top plot ) and bdt ( bottom plot ) .",
    "the results are remain reasonably stable for both ann and bdt versus shifting factor .",
    "figure 12 shows the ratio of background efficiency from ann and bdt versus signal efficiency ( top plot ) and the ratio of variance of background efficiency from ann and bdt versus signal efficiency ( bottom plot ) for the testing samples of set 5 with random positive or negative shifting .",
    "figure 13 shows the background efficiency versus smearing factor , for ann ( top plot ) and bdt ( bottom plot ) .      in order to make a cross check , a new set of 30 out of the 322 particle identification variables",
    "were selected and the whole analysis was redone .",
    "most results are quite similar to the results obtained in sections 3.13.3 .",
    "bdt , again , was more stable than ann .",
    "however , the second set of 30 variables overall was less powerful by a factor of about 2 than the first set . because of this",
    ", the variances were dominated more by the random variations than the variations due to a change in power with smearing or shifting .",
    "the variances of the second set were only about half the variances of the first set , but exhibited much more random behavior .",
    "the performance , stability and robustness of ann and bdt were compared for particle identification using the miniboone monte carlo samples .",
    "bdt has better particle identification performance than ann , even using only 30 pid variables .",
    "the bdt performance relative to that of ann depends on the signal efficiency .",
    "the variance in background efficiencies of testing results due to various bdt trainings is smaller than those from ann trainings regardless of testing samples with or without smearing and shifting .",
    "the performance of both bdt and ann are degraded by smearing and shifting the input variables of the testing samples .",
    "ann degrades more than bdt depending on the signal efficiency based on miniboone monte carlo samples .",
    "we wish to express our gratitude to the miniboone collaboration for the excellent work on the monte carlo simulation and the software package for physics analysis .",
    "this work is supported by the department of energy and by the national science foundation of the united states .",
    "roe , h.j .",
    "yang , j. zhu , y. liu , i. stancu , g. mcgregor , _ boosted decision trees as an alternative to artificial neural network for particle identification _ , nucl.instrum.meth .",
    "a543(2005 ) 577 - 584 , physics/0408124 ."
  ],
  "abstract_text": [
    "<S> in this paper , we compare the performance , stability and robustness of artificial neural networks ( ann ) and boosted decision trees ( bdt ) using miniboone monte carlo samples . </S>",
    "<S> these methods attempt to classify events given a number of identification variables . </S>",
    "<S> the bdt algorithm has been discussed by us in previous publications . </S>",
    "<S> testing is done in this paper by smearing and shifting the input variables of testing samples . based on these studies </S>",
    "<S> , bdt has better particle identification performance than ann . the degradation of the classifications obtained by shifting or smearing variables of testing results is smaller for bdt than for ann </S>",
    "<S> .    boosted decision trees ; artificial neural networks ; stability ; robustness ; particle identification ; neutrino oscillations ; miniboone </S>"
  ]
}