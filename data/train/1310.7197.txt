{
  "article_text": [
    "two points inside a polygon are _ visible _ to each other if their connecting segment remains completely inside the polygon .",
    "_ visibility polygon _ @xmath14 of a point @xmath15 in a simple polygon @xmath2 is the set of @xmath2 points that are visible from @xmath15 .",
    "the visibility problem has also been considered for line segments .",
    "a point @xmath16 is said to be _ weakly visible _ to a line segment @xmath0 if there exists a point @xmath17 such that @xmath18 and @xmath16 are visible to each other .",
    "the problem of computing the _ weak visibility polygon _ ( or @xmath19 ) of @xmath0 inside a polygon @xmath2 is to compute all points of @xmath2 that are weakly visible from @xmath0 .",
    "if @xmath2 is a simple polygon , @xmath1 can be computed in linear time @xcite . for a polygon with holes ,",
    "the weak visibility polygon has a complicated structure .",
    "suri and orourke @xcite showed that the weak visibility polygon can be computed in @xmath9 time if output as a union of @xmath9 triangular regions .",
    "they also showed that @xmath1 can be output as a polygon in @xmath20 , where @xmath21 is @xmath22 .",
    "their algorithm is worst - case optimal as there are polygons with holes whose weak visibility polygon from a given segment can have @xmath23 vertices .",
    "the query version of this problem has been considered by few .",
    "it is shown in @xcite that a simple polygon @xmath2 can be preprocessed in @xmath3 time and @xmath4 space such that given an arbitrary query line segment inside the polygon , @xmath24 time is required to recover @xmath21 weakly visible vertices .",
    "this result was later improved by @xcite in which the preprocessing time and space were reduced to @xmath8 and @xmath9 respectively , at the expense of more query time of @xmath25 . in a recent work , we presented an algorithm to report @xmath1 of any @xmath0 in @xmath5 time by spending @xmath3 time and @xmath4 space for preprocessing  @xcite .",
    "later , chen and wang considered the same problem and , by improving the preprocessing time of the visibility algorithm of bose",
    "_ et al . _",
    "@xcite , they improved the preprocessing time to @xmath4 @xcite . in another work @xcite",
    ", we showed that the @xmath1 can be reported in near optimal time of @xmath26 , after preprocessing the input polygon in time and space of @xmath8 and @xmath9 , respectively .      in the first part of this paper",
    ", we present an algorithm for computing the weak visibility polygon of any query line segment in a simple polygons @xmath2 .",
    "we build a data structure in @xmath3 time and @xmath4 space that can compute @xmath1 in @xmath5 time for any query line segment @xmath0 . a preliminary version of this result appeared in  @xcite .",
    "in the second part of the paper , we consider the problem of computing @xmath1 in polygonal domains . for a polygon with @xmath6 holes and total vertices of @xmath7 ,",
    "our algorithm needs the preprocessing time of @xmath8 and space of @xmath9 .",
    "we can compute @xmath27 in time @xmath10 . here",
    "@xmath11 is an output sensitive parameter of at most @xmath12 , and @xmath13 is the size of the output polygon .",
    "our algorithm is an improvement over the previous result of suri and orourke @xcite , considering the extra cost of preprocessing .",
    "let @xmath2 be a polygon with total vertices of @xmath7 .",
    "also , let @xmath28 be a point inside @xmath2 .",
    "the _ visibility sequence _ of a point @xmath28 is the sequence of vertices and edges of @xmath2 that are visible from @xmath28 .",
    "a _ visibility decomposition _ of @xmath2 is to partition @xmath2 into a set of _ visibility regions _ , such that any point inside each region has the same visibility sequence .",
    "this partition is induced by the _",
    "critical constraint edges _ , which are the lines in the polygon each induced by two vertices of @xmath2 , such that the visibility sequences of the points on its two sides are different .",
    "the visibility sequences of two _ neighboring _ visibility regions which are separated by an edge , differ only in one vertex .",
    "this fact is used to reduce the space complexity of maintaining the visibility sequences of the regions @xcite .",
    "this is done by defining the _",
    "sink regions_. a sink is a region with the smallest visibility sequence compared to all of its adjacent regions . it is therefore sufficient to only maintain the visibility sequences of the sinks , from which the visibility sequences of all other regions can be computed . by constructing a directed dual graph ( see figure  [ fig : f2 ] ) over the visibility regions , one can maintain the difference between the visibility sequences of the neighboring regions @xcite .",
    "in a simple polygon with @xmath7 vertices , the number of visibility and sink regions are respectively @xmath4 and @xmath9  @xcite . for a non - simple polygon ,",
    "these numbers are both @xmath22 @xcite .      here",
    ", we present the linear algorithm of guibas _ et al . _  for computing @xmath1 of a line segment @xmath0 inside @xmath2 , as described in @xcite",
    "this algorithm is used in computing the weak viability polygons in an output sensitive way to be explained in section  [ sec : first - alg ] . for simplicity",
    ", we assume that @xmath0 is a convex edge of @xmath2 , but we will show that this can be extended to any line segment in the polygon .",
    "let @xmath29 denote the shortest path tree in @xmath2 rooted at @xmath28 .",
    "the algorithm traverses @xmath29 using a dfs and checks the turn at each vertex @xmath30 in @xmath29 .",
    "if the path makes a right turn at @xmath30 , then we find the descendant of @xmath30 in the tree with the largest index @xmath31 ( see figure [ fig : guibas ] ) . as there is no vertex between @xmath32 and @xmath33 , we can compute the intersection point @xmath34 of @xmath35 and @xmath36 in @xmath37 time , where @xmath38 is the parent of @xmath30 in @xmath29 .",
    "finally the counter - clockwise boundary of @xmath2 is removed from @xmath30 to @xmath34 by inserting the segment @xmath39 .",
    "let @xmath40 denote the remaining portion of @xmath2 .",
    "we follow the same procedure for @xmath15 .",
    "this time , the algorithm checks every vertex to see whether the path makes its first left turn .",
    "if so , we will cut the polygon at that vertex in a similar way .",
    "after finishing the procedure , the remaining portion of @xmath40 would be @xmath1 .    .",
    "in the left figure , the shortest path from @xmath28 to @xmath32 makes a first right turn at @xmath30 . in the right figure ,",
    "the shortest path from @xmath15 to @xmath41 makes a first left turn at @xmath42 . ]",
    "in this section , we show how to modify the presented algorithm of section  [ sec : guibas ] , so that @xmath19 can be computed efficiently in an output sensitive way .",
    "an important part of this algorithm is computing the shortest path trees .",
    "therefore , we first show how tom compute these trees in an output sensitive way .",
    "then , we present a primary version of our algorithm . later , in section [ sec : improve ] , we show hot to improve this algorithm .",
    "the euclidean shortest path tree of a point inside a simple polygon of size @xmath7 can be computed in @xmath44 time @xcite . in this section",
    "we show how to preprocess @xmath2 , so that for any given point @xmath28 we can report any part of @xmath29 in an output sensitive way .    the shortest path tree @xmath29 is composed of two kinds of edges : the _ primary edges _ that connect the root @xmath28 to its direct visible vertices , and the _ secondary edges _ that connect two vertices of @xmath29 ( see figure [ fig : pspt ] ) .",
    "we can also recognize two kinds of the secondary edges : a 1st type secondary edge ( 1st type for short ) is a secondary edge that is connected to a primary edge , and a 2nd type secondary edge ( 2nd type for short ) is a secondary edge that is not connected to a primary edge .",
    "we show how to store these edges in the preprocessing phase , so that they can be retrieved efficiently in the query time .",
    "the primary edges of @xmath45 can be computed by using the algorithm of computing the visibility polygons @xcite .",
    "more precisely , with a preprocessing cost of @xmath3 time and @xmath4 space , a pointer to the sorted list of the visible vertices of a query point @xmath28 can be computed in time @xmath46 .     and its different types of edges : the edges that are directly connected to the root @xmath28 ( primary edges ) , the edges that are connected to the primary edges ( 1st type secondary edges ) , and the remaining edges ( 2nd type secondary edges ) . ]    for computing the secondary edges of @xmath43 , in the preprocessing time , we store all the possible values of the secondary edges of each vertex . having these values",
    ", we can detect the appropriate list in the query time and report the edges without any further cost .",
    "each vertex @xmath16 in @xmath2 have @xmath44 potential parents in @xmath43 . for each potential parent of @xmath16",
    ", it may have @xmath44 2nd type edges in @xmath43 .",
    "therefore , for a vertex @xmath16 , @xmath9 space is needed to store all the possible combinations of the 2nd type edges .",
    "computing and storing these potential edges can be done in @xmath8 time . in the query time ,",
    "when we arrive at the vertex @xmath16 , we use these data to extract the 2nd type edges of @xmath16 in @xmath43 .",
    "computing these data for all the vertices of @xmath2 needs @xmath3 time and @xmath4 space .",
    "the parent of a 1st type edge of @xmath43 is the root of the tree . as the root can be in any of the @xmath4 visibility regions , we need to consider all these potential parents to compute the possible combinations of the 1st type edges of a vertex .",
    "considering all the regions , the possible first type edges can be computed in @xmath47 time and @xmath22 space .    given a simple polygon @xmath2 ,",
    "we can build a data structure of size @xmath22 in time @xmath47 , so that for a query point @xmath28 , the shortest path tree @xmath29 can be reported in @xmath48 time , where @xmath21 is the size of the tree to be reported .    in section  [ sec",
    ": improve ] we will show how to improve the processing time and space by a linear factor",
    ".      in this section , we use the linear algorithm presented in section [ sec : guibas ] for computing @xmath19 of a simple polygon .",
    "this algorithm is not output sensitive by itself .",
    "see the example of figure  [ g1 ] . as stated in section [ sec : guibas ] , to compute @xmath1 , first we traverse @xmath29 using dfs and we check the turn at every vertex of @xmath29 .",
    "consider vertex @xmath16 . as we traverse the shortest path @xmath49 ,",
    "all the children of @xmath16 must be checked .",
    "this can cost @xmath44 time . when we traverse @xmath45 , a sub - polygon with @xmath16 as its vertex will be omitted .",
    "therefore , the time spent on processing the children of @xmath16 in @xmath29 is redundant .     in @xmath29",
    "are processed .",
    "these vertices which are not in @xmath1 impose redundant @xmath44 time . ]",
    "to achieve an output sensitive algorithm , we build the data structure explained in the previous section , so that @xmath43 of any point inside the polygon can be computed in the query time . also , we store some additional information about the vertices of the polygon in the preprocessing phase .",
    "we say that a vertex @xmath16 of a simple polygon is _ left critical _ ( lc for short ) with respect to a point @xmath28 , if @xmath50 makes its first left turn at @xmath16 .",
    "in other words , each shortest path from @xmath28 to a non - lc vertex is a convex chain that makes only clockwise turns at each node .",
    "the _ critical state _ of a vertex is whether or not it is lc . if we have the critical state of all the vertices of the polygon with respect to a point @xmath28 , we say that we have the _ critical information _ of @xmath28 .",
    "the idea is to change the algorithm of section [ sec : guibas ] and make it output sensitive .",
    "the outline of the algorithm is as follows : in the first round , we traverse @xmath29 using dfs . at each vertex",
    ", we check whether this vertex is left critical with respect to @xmath15 or not .",
    "if so , we are sure that the descendants of this vertex are not visible from @xmath0 , so we postpone its processing to the time it is reached from @xmath15 , and check other branches of @xmath29 .",
    "otherwise , we proceed with the algorithm and check whether @xmath29 makes a right turn at this vertex . in the second round ,",
    "we traverse @xmath45 and perform the normal procedure of the algorithm .",
    "[ lemma3 ] all the traversed vertices in @xmath29 and @xmath45 are vertices of @xmath1 .",
    "assume that when we are traversing @xmath29 , we meet @xmath16 and @xmath51 .",
    "let @xmath52 be the parent of @xmath16 in @xmath53 . in this case",
    ", @xmath52 or one of its ancestors must be lc with respect to @xmath15 , otherwise the algorithm will detect it as a @xmath19 vertex .",
    "therefore , @xmath16 can not be seen while traversing @xmath29 . the same argument can be applied to @xmath45 .    in the preprocessing phase ,",
    "we compute the critical information of a point inside each region , and assign this information to that region . in the query time and upon receiving a line segment @xmath0 , we find the regions of @xmath28 and @xmath15 .",
    "using the critical information of these two regions , we can apply the algorithm and compute @xmath1 .",
    "as there are @xmath4 regions in the visibility decomposition , @xmath22 space is needed to store the critical information of all the vertices . for each region",
    ", we compute @xmath43 of a point , and by traversing the tree , we update the critical information of each vertex with respect to that region . for each region , we assign an array of size @xmath44 to store these information .",
    "we also build the structure described in section [ sec : spt ] for computing @xmath43 in time @xmath47 and @xmath22 space . in the query time",
    ", we locate the visibility regions of @xmath28 and @xmath15 in @xmath46 time . as the processing time spent in each vertex",
    "is @xmath37 , by lemma [ lemma3 ] , the query time is @xmath54 .",
    "[ lem : primaryresult ] using @xmath47 time to preprocess a simple polygon @xmath2 and construct a data structure of size @xmath22 , it is possible to report @xmath27 in @xmath54 time .    until now , we assumed that @xmath0 is a polygonal edge .",
    "this can be generalized for any @xmath0 in @xmath2 .",
    "[ lemma3.1 ] let @xmath0 be a line segment inside a simple polygon @xmath2 .",
    "we can decompose @xmath2 into two sub - polygons @xmath55 and @xmath56 , such that each sub - polygon has @xmath0 as a polygonal edge .",
    "furthermore , the critical information of @xmath55 and @xmath56 can be computed from the critical information of @xmath2 .",
    "we find the intersection points of the supporting line of @xmath0 with the border of @xmath2 .",
    "then , we split @xmath2 into two simple polygons @xmath55 and @xmath56 , both having @xmath0 as a polygonal edge .",
    "the visibility regions of @xmath55 and @xmath56 are subsets of the visibility regions of @xmath2 .",
    "therefore , we have the critical information and @xmath43 edges of these regions . the primary edges of @xmath28 and @xmath15 can also be divided to those in @xmath55 and those in @xmath56 .",
    "see the example of figure [ fig : split ] .",
    "is inside the polygon , we split it along the supporting line of @xmath0 to create two sub - problems .",
    "the dotted lines are some of the critical constraints in the polygon . ]      in this section we improve the preprocessing cost of lemma [ lem : primaryresult ] .",
    "to do this , we improve the parts of the algorithm of section [ sec : wvp ] that need @xmath47 preprocessing time and @xmath22 space .",
    "we show that it is sufficient to compute the critical information and the 1st type edges of the sink regions ( see section [ sec : pre : decompos ] for the definition of the sink regions ) . for any query point @xmath28 in a non - sink region ,",
    "the 1st type edges of @xmath29 can be computed from the 1st type edges of the sink regions ( lemma [ lem : lemma4 ] ) .",
    "also , the critical information of the other regions can be deduced from the critical information of the sink regions ( lemma [ lem : lemma5 ] ) .",
    "as there are @xmath9 sinks in a simple polygon , the processing time and space of our algorithm will be reduced to @xmath3 and @xmath4 , respectively .    in the query time , if both @xmath28 and @xmath15 belong to the sink regions , we have the critical information of their regions and we can proceed the algorithm . on the other hand , if one of these points is on a non - sink region , lemma  [ lem : lemma4 ] and [ lem : lemma5 ] show that the secondary edges and the critical information of that point can be retrieved in @xmath54 time .",
    "[ lem : lemma4 ] assume that , for a visibility region @xmath57 , the 1st type secondary edges are computed for a neighboring region that share a common edge with @xmath57 , these edges can be updated in constant time",
    ".     enters a new visibility region , the combinatorial structure of @xmath29 can be maintained in constant time . ]    when a view point @xmath28 crosses the common border of two neighboring regions , a vertex becomes visible or invisible @xcite to @xmath28 . in figure",
    "[ fig : h4 ] , for example , when @xmath28 crosses the border specified by @xmath52 and @xmath16 , a 1st type edge of @xmath52 becomes a primary edge of @xmath28 , and all the edges of @xmath16 become the 1st type edges .",
    "we can see that no other vertex is affected by this movement .",
    "processing these changes can be done in constant time , since it includes the following changes : removing a secondary edge of @xmath52 ( @xmath58 ) , adding a primary edge ( @xmath59 ) , and moving an array pointer ( edges of @xmath16 ) from the 2nd type edges of @xmath58 to the 1st type edges of @xmath59 .",
    "note that we know the exact positions of these elements in their corresponding lists .",
    "the only edge that involves in these changes ( i.e. , the edge corresponding to the crossed critical constraint ) , can be identified in the preprocessing time .",
    "therefore , the time we spent in the query time would be @xmath37 .",
    "[ lem : lemma5 ] the critical information of a point can be maintained between two neighboring region that share a common edge in constant time .",
    "0.23   w.r.t @xmath28 , as @xmath28 moves between the two regions.,title=\"fig : \" ]    0.23   w.r.t @xmath28 , as @xmath28 moves between the two regions.,title=\"fig : \" ]     +    0.23   w.r.t @xmath28 , as @xmath28 moves between the two regions.,title=\"fig : \" ]    0.23   w.r.t @xmath28 , as @xmath28 moves between the two regions.,title=\"fig : \" ]    suppose that we want to maintain the critical information of @xmath28 , and @xmath28 is crossing the critical constraint defined by @xmath58 . here ,",
    "@xmath52 and @xmath16 are two reflex vertices of @xmath2 .",
    "the only vertices that affect directly by this change are @xmath52 and @xmath16 .",
    "depending on the critical states of @xmath52 and @xmath16 w.r.t .",
    "@xmath28 , four situations may occur ( see figure [ fig : e2 - 1 ] ) . in the first three cases ,",
    "the critical state of @xmath16 will not change . in the forth case ,",
    "however , the critical state of @xmath16 will change . before the cross , the shortest path @xmath50 makes a left turn at @xmath52 , therefore , both @xmath52 and @xmath16 are lc w.r.t .",
    "however , after the cross , @xmath52 is not on @xmath50 and @xmath16 is no longer lc .",
    "this means that the critical state of all the children of @xmath16 in @xmath29 could be changed as well .    to handle these cases",
    ", we modify the way the critical information of each vertex w.r.t .",
    "@xmath28 are stored . at each vertex @xmath16 , we store two additional values : the number of lc vertices we met in the path @xmath60 ( including @xmath16 ) , or its _ critical number _ , and _ debit number _ , which is the critical number that is to be propagated in the subtree of the vertex .",
    "if a vertex is lc , it means that its critical number is greater than zero ( see figure [ fig : critical - numbers ] ) . also , if a vertex has a non - zero debit number , the critical numbers of all its children must be added by this number .",
    "computing and storing these additional numbers along the critical information will not change the time and space requirements .",
    "now let us consider the forth case in figure [ fig : e2 - 1 ] .",
    "when @xmath16 becomes visible to @xmath28 , it is no longer lc w.r.t .",
    "therefore , the critical number of @xmath16 must be changed to @xmath61 , and the critical number of all the descendants of @xmath16 in @xmath29 must be decreased by one .",
    "however , instead of changing the critical numbers of the descendants of @xmath16 , we decrease the debit number of @xmath16 by one , indicating that the critical numbers of its descendants in @xmath29 must be subtracted by one .",
    "the actual propagation will happen at the query time when we traverse @xmath29 .",
    "if @xmath28 moves in the reverse path , i.e. , when @xmath16 becomes invisible to @xmath28 , we handle the tree in the same way by adding @xmath62 to its debit number , and propagating this addition in the query time .    .",
    "]    in the preprocessing time , we build the dual directed graph of the visibility regions . in this graph",
    ", every node represents a visibility region , and an edge between two nodes corresponds to a gain of one vertex in the visibility set in one direction , and a loss in the other direction .",
    "we compute the critical information and 1st type edges of all the sink regions . by lemma [ lem : lemma4 ] and [ lem : lemma5 ] , any two neighboring regions have the same critical information and secondary edges , except at one vertex .",
    "we associated this vertex with the edge .    in the query time , we locate the region containing the point @xmath28 , and follow any path from this region to a sink .",
    "as each arc represents a vertex that is visible to @xmath28 , and therefore to @xmath0 , the number of arcs in the path is @xmath63 .",
    "when traversing the path from the sink back to the region of @xmath28 , we update the critical information and the secondary edges of the visible vertices in each region . at the original region , we would have the critical information and the 1st type edges of this region .",
    "we perform the same procedure for @xmath15 . having the critical information and the 1st type edges of @xmath28 and @xmath15",
    ", we can compute @xmath1 with the algorithm of section [ sec : wvp ] . in general",
    ", we have the following theorem :    [ theom : weak_in_simple ] a simple polygon @xmath2 can be preprocessed in @xmath3 time and @xmath4 space such that given an arbitrary query line segment inside the polygon , @xmath1 can be computed in @xmath54 time .",
    "in this section , we propose an algorithm for computing the weak visibility polygons in polygonal domains .",
    "let @xmath2 be a polygon with @xmath6 holes and @xmath7 total vertices .",
    "also let @xmath0 be a query line segment .",
    "we use the idea presented @xcite and convert the non - simple polygon @xmath2 into a simple polygon @xmath64 .",
    "then , we use the algorithms of computing @xmath19 in simple polygons to compute a preliminary version of @xmath1 . with some additional work , we find the final @xmath1 .",
    "a hole @xmath65 can be eliminated by adding two _ cut - diagonals _ connecting a vertex of @xmath65 to the boundary of @xmath2 . by cutting @xmath2 along these diagonals",
    ", we will have another polygon in which @xmath65 is on its boundary .",
    "we repeat this procedure for all the holes and produce a simple polygon @xmath64 .    .",
    "]    let @xmath66 be the supporting line of @xmath0 . for simplicity",
    ", we assume that all the holes are on the same side of @xmath66 .",
    "otherwise , we can split the polygon along @xmath66 and generate two sub - polygons that satisfy this requirement . to add the cut - diagonals , we select the nearest point of each hole to @xmath66 , and perform a ray shooting query from that point in the left direction of @xmath66 , to find the first intersection with a point of @xmath2",
    "( see figure [ fig : wvp3-cuts ] ) .",
    "this point can be a point on the border of @xmath2 or a point on the border of another hole .",
    "we select the shooting segment to be the cut - diagonal . finding the nearest points of the holes",
    "can be done in @xmath67 time .",
    "also , performing the ray shooting procedure for each hole can be done in @xmath44 time .",
    "therefore , adding the cut - diagonals can be done in total time of @xmath68 .",
    "the resulting simple polygon will have @xmath69 vertices . as @xmath6 is @xmath44 ,",
    "the number of vertices of @xmath64 is also @xmath44 .    having a simple polygon @xmath64 ,",
    "we compute @xmath70 in @xmath64 by using the algorithm of section [ sec : guibas ] .",
    "next , we add the edges of the polygon that can be seen through the cut - diagonals .",
    "an example of the algorithm can be seen in figure [ fig : w3-steps ] .",
    "first , we compute @xmath71 in @xmath64 .",
    "then , for each segment of the cut - diagonals that can be seen from @xmath0 , we recursively compute the segments of @xmath2 that are visible from @xmath0 through that diagonal .",
    "this leads to the final @xmath1 .     inside a polygon with holes . ]      for computing @xmath1 , we must update @xmath70 with the edges that are visible through the cut diagonals . to do this",
    ", we define the _ partial weak visibility polygon_. suppose that a simple polygon @xmath2 is divided by a diagonal @xmath72 into two parts , @xmath73 and @xmath74 . for a line segment @xmath75 , we define the partial weak visibility polygon @xmath76 to be the polygon @xmath77 . in other words , @xmath78 is the portion of @xmath2 that is weakly visible from @xmath0 _ through _ @xmath72 . to compute @xmath78 , one can compute @xmath1 by the algorithm of section [ sec : guibas ] , and then report those vertices in @xmath73 .",
    "[ lemma : partial ] given a polygon @xmath2 and a diagonal @xmath72 which cuts @xmath2 into two parts , @xmath73 and @xmath74 , for any query line segment @xmath75 , the partial weak visibility polygon @xmath78 can be computed in @xmath44 time .",
    "lemma [ lemma : partial ] only holds for simple polygons , but we use its idea for our algorithm .",
    "assume that @xmath2 has only one hole @xmath65 and this hole has been eliminated by the cut @xmath79 .",
    "let @xmath80 be another cut which is on the supporting line of @xmath79 and is on the other side of @xmath65 , such that @xmath81 is on the border of @xmath65 and @xmath82 is on the border of @xmath2 .",
    "we can also eliminate @xmath65 by @xmath80 and obtain another simple polygon @xmath83 .",
    "now lemma [ lemma : partial ] can be applied to the polygon @xmath83 and answer partial weak visibility queries through the cut @xmath79 . following the terminology used by @xcite",
    ", we denote this algorithm by @xmath84 .    by performing the @xmath84 algorithm once for each hole @xmath85 and assuming that @xmath2 has been cut to a simple polygon",
    ", we can extend this algorithm to more holes .",
    "this leads to @xmath6 data structures of size @xmath44 for storing the simple polygons to perform lemma [ lemma : partial ] for @xmath85 . using these data structures",
    ", we can find the edges of @xmath2 that are visible from @xmath0 through the cut - diagonals .",
    "we first add the cut - diagonals to make a simple polygon @xmath64 .",
    "then , we compute @xmath70 and find the set of segments that are visible from @xmath0 in @xmath64 . if a segment @xmath72 of the cut - diagonal of a hole @xmath65 is visible from @xmath0 , we use lemma [ lemma : partial ] and replace that segment with the partial weak visibility polygon of @xmath0 through that segment .",
    "we continue this for every cut - diagonal that can be seen from @xmath0 . due to the nature of visibility",
    ", this procedure will end .",
    "if we have processed @xmath86 segments of the cut - diagonals , we end up with @xmath87 simple polygons of size @xmath44 .",
    "it can be easily shown that the union of these polygons is @xmath1 .",
    "now let us analyze the running time of the algorithm .",
    "the cut - diagonals can be added in @xmath88 time .",
    "running the algorithm of theorem [ theom : weak_in_simple ] in @xmath64 takes @xmath44 time .",
    "in addition , for each segment of the cut - diagonals that has appeared in @xmath70 , we perform the algorithm of lemma [ lemma : partial ] in @xmath44 time .",
    "in general , we have the following lemma :    [ lemma : wvp3:primary - result ] the time needed to compute @xmath27 as a set of @xmath86 simple polygons of size @xmath44 is @xmath89 , where @xmath86 is the number of cut - diagonals that has been appeared in @xmath70 during the algorithm .    .",
    "]    the upper bound of @xmath86 is @xmath90 and this bound is tight .",
    "we have selected the cut - diagonals in such a way that the query line segment @xmath0 does not intersect the supporting line of any of the cut - diagonals . also , the cut - diagonals do not intersect each other . therefore ,",
    "if @xmath0 sees a cut - diagonal @xmath66 through another cut - diagonal @xmath91 , then @xmath0 can not see @xmath91 through @xmath66 .",
    "hence , the upper bound of @xmath86 is @xmath90 .",
    "figure [ fig : wvp3-h - bound ] shows a sample with tight bound of @xmath92 .",
    "in the algorithm of the previous section , we may perform the @xmath84 algorithm up to @xmath6 times for each hole , resulting the high running time of @xmath93 . in this section ,",
    "we show how to change this algorithm and improve the final result .",
    "a vertex @xmath16 of the polygon @xmath2 can see the line segment @xmath0 directly or through the cut - diagonals .",
    "more precisely , @xmath16 can see up to @xmath6 parts of @xmath0 through different cut - diagonals .",
    "these parts can be categorized by the critical constraints that are tangent to the holes and pass through @xmath16 and cut @xmath0 .",
    "the next lemma put a limit on the number of these critical constraints .",
    "the number of the critical constraints that see @xmath0 is @xmath94 , where @xmath95 is the number of visible holes from @xmath0 .",
    "let the number of vertices of the hole @xmath85 be @xmath96 .",
    "there are three kinds of constraints :    * for each vertex @xmath16 that is not on the border of @xmath85 and is visible to @xmath85 , there are at most two critical constraints that touch @xmath85 and cut @xmath0 . therefore , the total number of these constraints is @xmath94 . * the number of the critical constraints induced by two vertices of @xmath85 that cut @xmath0 is @xmath97 .",
    "we also have @xmath98 . *",
    "the number of the critical constraints that cut @xmath0 and do not touch any hole is @xmath44 @xcite .    putting these together",
    ", we can prove the lemma .",
    "we preprocess the polygon @xmath2 so that , in query time , we can efficiently find the critical constraints that cut @xmath0 .",
    "there are @xmath44 critical constraints passing through each vertex in @xmath2 .",
    "therefore , the set of critical constraints can be computed in @xmath8 time and @xmath9 space .",
    "as the critical constraints passing through a vertex can be treated as a simple polygon ( see figure [ fig : wvp3-to - simple ] ) , we build the ray shooting data structure for each vertex in @xmath44 time and space , so that the ray shooting queries can be answered in @xmath46 time . in query time , we find the critical constraints of each vertex that cut @xmath0 in @xmath99 time , or in total time of @xmath100 for all the vertices . here",
    "@xmath101 is the number of constraints that pass through @xmath16 and cut @xmath0 .     as a simple polygon ( dashed lines ) and build the ray shooting data structure in @xmath44 time to answer the ray shooting queries . ]    by performing an angular sweep through these lines , we can find the visible parts of @xmath0 and the visible cut - diagonals from the vertices in @xmath94 time .",
    "we store these parts in the vertices , according to the visible cut - diagonal of each part . performing this procedure for all the vertices of @xmath2 , including the vertices of the holes , and storing the visible parts of @xmath0 in each vertex",
    "can be done in @xmath100 time and @xmath94 space .",
    "so , we have the following lemma :     critical constraints from each vertex of the polygon that hit a cut - diagonal . ]",
    "given a polygonal domain @xmath2 with @xmath6 disjoint holes and @xmath7 total vertices , it can be processed into a structure in @xmath9 space and @xmath8 preprocessing time so that for any query line segment @xmath0 , the critical constraints that cut @xmath0 can be computed and sorted in @xmath100 time , where @xmath95 .    it the rest of the paper we show that these critical constraints make an arrangement that can be used to compute @xmath1 .",
    "we defined @xmath70 to be the part of @xmath2 that can be seen directly from @xmath0 .",
    "let @xmath102 be the cut - diagonal of the hole @xmath85 .",
    "we define @xmath103 to be the part of @xmath2 that can be seen @xmath0 through @xmath102 .",
    "it is clear that @xmath104 .",
    "now , we show how to compute @xmath103 .",
    "first notice that @xmath103 is on the upper half plane of @xmath102 .",
    "let @xmath105 be the part of @xmath64 that is above @xmath102 .",
    "as @xmath0 can see @xmath105 through different parts of @xmath102 , @xmath103 may not a simple polygon .",
    "let @xmath106 be the set of critical constraints originating from the vertices of @xmath105 that can see @xmath0 and directly cut @xmath102 , plus the critical constraints that can see @xmath0 and hit the border of @xmath105 and cut @xmath102 just before they hit @xmath105 .",
    "each critical constraint is distinguished by one or two reflex vertices .",
    "we call each one of these vertices as the anchor of the critical constraint .",
    "also , each one of these critical constraints may cut the border of @xmath105 at most twice .",
    "let @xmath107 be the segments on the border of @xmath105 resulted from these cuttings .",
    "it is clear that @xmath108 .",
    "let @xmath109 , and let @xmath110 be the arrangement induced by the segments of @xmath111 .",
    "we show that @xmath110 partitions @xmath105 into visible and invisible regions .",
    "[ lemma : e_exists ] for each point @xmath112 that is visible from @xmath0 , there is a segment @xmath72 in @xmath111 that can be rotated around its anchor until it hits @xmath113 , while remaining visible to @xmath0 .",
    ", there is a critical constraint @xmath114 that can be rotated around its anchor @xmath115 until it hits @xmath113 . ]",
    "as @xmath113 is visible from @xmath0 , it must be visible from some point @xmath116 of @xmath0 , such that @xmath117 cuts @xmath102 ( see figure [ fig : wvp3-exist - disc - line ] ) .",
    "we rotate the segment @xmath117 counterclockwise about @xmath113 until it hits some vertex @xmath118 .",
    "notice that the case @xmath119 is possible and does not require separate treatment .",
    "next , we rotate the segment clockwise about @xmath120 until it hits another vertex @xmath121 .",
    "we continue the rotations until the segment reaches one of the endpoints of @xmath102 , or the lower part of the segment hits a point @xmath34 of the polygon , or the segment reaches the end - point @xmath28 . let @xmath115 be the last point that the segment hits on the upper part of @xmath72 .",
    "as we only rotate the segment clockwise , this procedure will end .",
    "it is clear that @xmath114 is a critical constraint in @xmath111 , and we can reach the point @xmath113 by rotating @xmath114 counterclockwise about @xmath34 .",
    "all the points of a cell @xmath122 in @xmath110 have the same visibility status w.r.t .",
    "@xmath0 .",
    "suppose that the points @xmath52 and @xmath16 are in @xmath122 , and @xmath52 is visible and @xmath16 is invisible from @xmath0 .",
    "let @xmath58 be the line segment connecting @xmath52 and @xmath16 , and @xmath113 be the nearest point to @xmath52 on @xmath58 that is invisible from @xmath0 . according to lemma [ lemma : e_exists ]",
    ", there is a segment @xmath123 with @xmath34 as its anchor such that if we rotate @xmath72 around @xmath34 , it will hit @xmath52 .",
    "we continue to rotate @xmath72 until it hits @xmath113 . as @xmath113 is invisible from @xmath0",
    ", @xmath124 must be a critical constraint .",
    "this means that we have another critical constraint from a vertex @xmath125 that sees @xmath0 , and it crosses the cell @xmath122 .",
    "thus , the assumption that @xmath122 is a cell in @xmath110 is contradicted .",
    "to compute the final @xmath1 , we have to compute @xmath126 .",
    "@xmath70 is a simple polygon of size @xmath44 which can be represented by @xmath44 line segments .",
    "also , @xmath127 can be represented by the arrangement of @xmath128 line segments , where @xmath129 .",
    "it can be easily shown that @xmath130 .",
    "therefore , @xmath1 can be represented as the arrangement of @xmath131 line segments .    in the next section ,",
    "we consider the problem of computing the boundary of @xmath1 .",
    "we showed how to output @xmath1 as an arrangement of @xmath94 line segments . here , we show that @xmath1 can be output as a polygon in @xmath132 time .",
    "balaban @xcite showed that by using a data structure of size @xmath97 , one can report the intersections of @xmath133 line segments in time @xmath134 , where @xmath21 is the number of intersections .",
    "this algorithm is optimal because at least @xmath135 time is needed to report the intersections . here",
    ", we have @xmath94 line segments and reporting all the intersections needs @xmath10 time and @xmath94 space . with the same running time",
    ", we can classify the edge fragments by using the method of margalit and knott @xcite , while reporting the line segment intersections .",
    "we can summarize this in the following theorem :    a polygon domain @xmath2 with @xmath6 disjoint holes and @xmath7 vertices can be preprocessed in time @xmath8 to build a data structure of size @xmath9 , so that the visibility polygon of an arbitrary query line segment @xmath0 within @xmath2 can be computed in @xmath136 time and @xmath137 space , where @xmath21 is the size of the output which is @xmath138 and @xmath11 is the number of visible holes from @xmath0 .",
    "we considered the problem of computing the weak visibility polygon of line segments in simple polygons and polygonal domains . in the first part of the paper",
    ", we presented an algorithm to report @xmath1 of any line segment @xmath0 in a simple polygon of size @xmath7 in @xmath5 time , by spending @xmath3 time preprocessing the polygon and maintaining a data structure of size @xmath4 .    in the second part of the paper ,",
    "we have considered the same problem in polygons with holes .",
    "we presented an algorithm to compute @xmath27 of any @xmath0 in a polygon with @xmath6 polygonal obstacles with a total of @xmath7 vertices in time @xmath136 by spending @xmath8 time preprocessing the polygon and maintaining a data structure of size @xmath9 .",
    "the factor @xmath11 is an output sensitive parameter of size at most @xmath139 , and @xmath140 is the size of the output ."
  ],
  "abstract_text": [
    "<S> in this paper we consider the problem of computing the weak visibility polygon of any query line segment @xmath0 ( or @xmath1 ) inside a given polygon @xmath2 . </S>",
    "<S> our first non - trivial algorithm runs in simple polygons and needs @xmath3 time and @xmath4 space in the preprocessing phase to report @xmath1 of any query line segment @xmath0 in time @xmath5 . </S>",
    "<S> we also give an algorithm to compute the weak visibility polygon of a query line segment in a non - simple polygon with @xmath6 pairwise - disjoint polygonal obstacles with a total of @xmath7 vertices . </S>",
    "<S> our algorithm needs @xmath8 time and @xmath9 space in the preprocessing phase and computes @xmath1 in query time of @xmath10 , in which @xmath11 is an output sensitive parameter of at most @xmath12 , and @xmath13 is the output size . </S>",
    "<S> this is the best query - time result on this problem so far .    computational geometry , visibility , line segment visibility </S>"
  ]
}