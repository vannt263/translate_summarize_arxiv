{
  "article_text": [
    "lets imagine a monkey typing on a keyboard with @xmath22 letters and a space bar , where the chance for typing space is @xmath23 and for any of the letters is @xmath24 .",
    "a text produced by this monkey has a certain information content given by the entropy of the letter configurations produced by the monkey .",
    "these configurations result in a word frequency distribution ( wfd ) @xmath31 and the corresponding entropy @xmath103 gives a measure of the information associated with this frequency distribution .",
    "the most likely @xmath31 corresponds to the maximum of @xmath104 under the appropriate constraints .",
    "this can equivalent be viewed as the minimum information loss , or cost , in comparison with an unconstrained @xmath31 @xcite .",
    "consequently , the minimum - cost @xmath31 gives the most likely wfd for a monkey .",
    "since the wfd in the continuum approximation is different from the real distribution @xmath31 , we will call the former @xmath25 .",
    "let @xmath1 be the frequency with which a specific word occurs in a text and let the corresponding probability distribution be @xmath105 .",
    "this means that @xmath105 is the probability that a word belongs to the frequency interval @xmath106 $ ] .",
    "the entropy associated with the probability distribution @xmath25 is @xmath107 ( where @xmath108 implies an integral whenever the index is a continuous variable ) .",
    "let @xmath109 be the number of words in the word - letter length interval @xmath110 $ ] .",
    "this means that the number of words in the frequency interval @xmath106 $ ] is @xmath111 because all words of a given length @xmath112 occur with the same frequency .",
    "the number of distinct words in the same interval is @xmath113 , which means that @xmath114 is the degeneracy of a word with frequency @xmath1 .",
    "the information loss due to this degeneracy is @xmath115(in nats ) .",
    "the average information loss is given by @xmath116 \\label{icost}\\ ] ] and this is the appropriate information cost associated with the words : the @xmath25 which minimizes this cost corresponds to the most likely @xmath25 .",
    "the next step is to express @xmath117 and @xmath118 in terms of the two basic probability distributions , @xmath25 and the probability for hitting the keys : @xmath117 is just @xmath119 .",
    "the frequency @xmath1 for a world containing @xmath112 letters is    @xmath120    thus @xmath121 with @xmath122 so that @xmath123 and , consequently , @xmath124 $ ]",
    ". furthermore , @xmath125 and from eq.[kl ] one gets @xmath126 from which follows that @xmath127 .",
    "thus the most likely distribution @xmath25 corresponds to the minimum of the information word cost @xmath128 with @xmath129 variational calculus then gives @xmath130 so that @xmath131 note that the total number of words @xmath7 only enter this estimate though the normalization condition .",
    "this means that the continuum approximation @xmath132 for the monkey - book is independent of how many words @xmath17 it contains .",
    "thus if you start from a monkey - book with @xmath17 words and you randomly pick a fraction of these @xmath17 words , then this smaller book will also a have a wfd which in the continuum limit follows the same power - law .",
    "this is a consequence of the fact that the frequency @xmath1 for a word a length @xmath112 is always given by eq.([kl ] ) irrespective of the book - size .",
    "it is this specific monkey - book constraint which makes @xmath133 in eq.([icost ] ) @xmath17-invariant and hence forces the continuum @xmath25 to always follow the same power - law .",
    "the crucial point to realize is that the very same constaint forces the real @xmath31 to have a `` peaky '' structure .",
    "one should also note that if you started from a book consisting of @xmath17 words randomly drawn from the _ continuum _",
    "@xmath25 then a randomly drawn fraction from this book will no longer follow the original power - law .",
    "18 r.h . baayen ( 2001 ) ,",
    "_ word frequency distributions _ , kluwer academic publisher ( dordrecht , the netherlands ) .",
    "r. ferrer - i - cancho and r. gavalda ( 2009 ) , _ the frequency spectrum of finite samples from the intermittent silence process . _ journal of the american society for information science and technology 60 ( 4 ) , 837 - 843 ."
  ],
  "abstract_text": [
    "<S> a `` monkey book '' is a book consisting of a random distribution of letters and blanks , where a group of letters surrounded by two blanks is defined as a word . </S>",
    "<S> we compare the statistics of the word distribution for a monkey book with the corresponding distribution for the general class of random books , where the latter are books for which the words are randomly distributed . </S>",
    "<S> it is shown that the word distribution statistics for the monkey book is different and quite distinct from a typical sampled book or real book . </S>",
    "<S> in particular the monkey book obeys heaps power law to an extraordinary good approximation , in contrast to the word distributions for sampled and real books , which deviate from heaps law in a characteristics way . </S>",
    "<S> the somewhat counter - intuitive conclusion is that a `` monkey book '' obeys heaps power law precisely because its word - frequency distribution is _ not _ a smooth power law , contrary to the expectation based on simple mathematical arguments that if one is a power law , so is the other .      </S>",
    "<S> words in a book occur with different frequencies . </S>",
    "<S> common words like `` the '' occur very frequently and constitute about 5% of the total number of written words in the book , whereas about half the different words only occur a single time @xcite . </S>",
    "<S> the word - frequency @xmath0 is defined as the number of words which occur @xmath1-times . </S>",
    "<S> the corresponding word - frequency distribution ( wfd ) is defined as @xmath2 where @xmath3 is the total number of different words . </S>",
    "<S> such a distribution is typically broad and is often called `` fat - tailed '' and  power law-like . </S>",
    "<S> `` power law''-like means that the large @xmath1-tail of the distribution to a reasonable approximation follows a power law , so that @xmath4 . </S>",
    "<S> typically , one finds that @xmath5 for a real book @xcite . </S>",
    "<S> what does this broad frequency distribution imply ? has it something to do with how the book is actually written ? or has it something to do with the evolution of the language itself ? </S>",
    "<S> the fact that the wfd has a particular form was first associated with the empirical zipf - law for the corresponding word - rank distribution.@xcite zipf s law corresponds to @xmath6 . </S>",
    "<S> subsequently herbert simon proposed that the particular form of the wfd could be associated with a growth model , the simon model , where the distribution of words was related to a particular stochastical way of writing a text from the beginning to the end.@xcite however , a closer scrutiny of the simon model reveals that the statistical properties implied by this model are fundamentally different from what is found in any real text.@xcite mandelbrot ( at about the same time as simon suggested his growth model ) instead proposed that the language itself had evolved so as to optimize an information measure based on an estimated word cost ( the more letters needed to build up a word the higher cost for the word).@xcite thus in this case the power law of the word - distribution was proposed to be a reflection of an evolved property of the language itself . </S>",
    "<S> however , it was later pointed out by miller in ref .  </S>",
    "<S> @xcite that you do not need any particular language - evolution optimization to obtain a power law : a monkey randomly typing letters and blanks on a type - writer will also produce a wfd which is power - law like within a continuum approximation . </S>",
    "<S> the monkey book , hence , at least superficially have properties in common with real books @xcite . the case that the relation to real books are just superficial have in particular been argued in refs @xcite and @xcite .    in 1978 , harold stanley heaps @xcite presented another empirical law describing the relation between the number of different words , @xmath3 , and the total number of words , @xmath7 . </S>",
    "<S> power law states that @xmath8 , where @xmath9 is a constant between zero and one . </S>",
    "<S> however , it was recently shown that heaps law gives an inadequate description of this relation for real books , and that it needs to be modified so that the exponent @xmath9 changes with the size of the book from @xmath10 for @xmath11 to @xmath12 as @xmath13 @xcite . </S>",
    "<S> it was also shown that the wfd of real books , in general , can be better described by introducing an exponential cut off so that @xmath14 @xcite . a simple mathematical derivation of the relation between the power - law exponents @xmath15 and @xmath9 gives the result @xmath16 @xcite . </S>",
    "<S> this in turn means that the shape of the wfd also changes with the size of the book , so that @xmath6 for small @xmath17 , but reaches the limit value @xmath18 as @xmath17 goes to infinity . </S>",
    "<S> the same analysis showed that the parameter @xmath19 is size dependent according to @xmath20 @xcite . </S>",
    "<S> it was also shown empirically that the works of a single author follows the same @xmath21-curve to a good approximation and which was further manifested in the _ meta - book concept _ : the @xmath21-curve characterizing a text of an individual author is obtainable by pulling sections from the authors collective meta book.@xcite as will be further discussed below , the shape of the @xmath21 curve is mathematically closely related to the _ random book transformation _ ( rbt ) @xcite@xcite .    </S>",
    "<S> as mentioned above , the writing of a real book can not be described by a growth model because the statistical properties of a real book are translational invariant @xcite . the monkey book , on the other hand , </S>",
    "<S> is produced by a translational - invariant stationary process . </S>",
    "<S> an important question of much attention is then how close the statistical properties of the monkey book really are to those of a real book . </S>",
    "<S> it is shown in the present work that in the context of heaps law the answer is somewhat paradoxical .      </S>",
    "<S> imagine an alphabet with @xmath22-letters and a typewriter with a keyboard with one key for each letter and a space bar . for a monkey randomly typing on the typewriter the chance for hitting the space bar </S>",
    "<S> is assumed to be @xmath23 and the chance for hitting any of the letters is @xmath24 . </S>",
    "<S> a word is then defined as a sequence of letters surrounded by blanks . </S>",
    "<S> what is the resulting wfd for a text containing @xmath7 words ? </S>",
    "<S> miller in ref .  </S>",
    "<S> @xcite found that in the continuum limit this is in fact a power law . in the appendix we re </S>",
    "<S> - derive this result using an information cost method . </S>",
    "<S> a more standard alternative derivation can be found in ref .  </S>",
    "<S> @xcite .    </S>",
    "<S> we will denote the word - frequency distributions in the continuum limit by @xmath25 and in the monkey book case it is given by    @xmath26    with    @xmath27    thus , if @xmath28 then @xmath18 if @xmath29 and @xmath30 in the infinite limit of @xmath22 .       given by eq .  </S>",
    "<S> [ gamma ] , whereas the full curve with disjunct peaks represents the real distribution @xmath31 . @xmath31 and its continuum approximation @xmath25 are clearly very different.(b ) the corresponding cumulative distributions @xmath32 and @xmath33 . </S>",
    "<S> broken straight line corresponds to @xmath34 and the black zig - zag line to the corresponding real cumulative distribution @xmath33 . note that @xmath32 to good approximation is an envelope of the black zig - zag @xmath33 . </S>",
    "<S> the gray zig - zag - curve is the cumulative @xmath33 for a tenth of the monkey book . </S>",
    "<S> note that @xmath32 still gives an equally good envelop . </S>",
    "<S> thus the envelop of the cumulative @xmath33 for a monkey book is a _ size - independent _ power law . ]    </S>",
    "<S> the above result for @xmath25 is an approximation of the actual ( discrete ) result expected from random typing . </S>",
    "<S> the true wfd of the model will here be denoted as @xmath31 . </S>",
    "<S> what is then the relation between the power - law form of @xmath25 and the actual probability , @xmath31 , for a word to occur @xmath1-times in the text ? </S>",
    "<S> it is quite straight - forward to let a computer take the place of a monkey and simulate monkey books @xcite . </S>",
    "<S> fig .  </S>",
    "<S> 1a gives an example for an alphabet with @xmath35 letters , a total lumber of words @xmath36 and with the chance to hit the space bar @xmath37 . </S>",
    "<S> such a book should have a power - law exponent of @xmath38 according to eq .  </S>",
    "<S> [ gamma ] . </S>",
    "<S> note that @xmath31 for higher @xmath1 consists of disjunct peaks : the peak with the highest @xmath1 corresponds to the @xmath35 one - letter words , the next towards lower @xmath1 to the @xmath39 two - letter words and so forth . </S>",
    "<S> thus the power law tail @xmath40 in the case of a monkey - book is not a smooth tail but a sequence of separated peaks as previously reported in ref .  </S>",
    "<S> @xcite . </S>",
    "<S> so what is the relation to the continuum @xmath41 ? plotted in log - log scales as in fig .  1a , @xmath25 is just a straight - line with the slope @xmath42 ( broken line in fig .  </S>",
    "<S> 1a ) . </S>",
    "<S> represented in this way there is no obvious discernible relation between the separated peaks of @xmath31 and the straight line given by @xmath25 . in order to directly see the connection one can instead compare the cumulative distributions @xmath43 and @xmath44 . in fig .  1b , @xmath33 corresponds to the full drawn zig - zag - curve and the straight broken line with slope @xmath45 to the continuum approximation @xmath32 . in this plot </S>",
    "<S> the connection is more obvious : @xmath32 is an envelope of @xmath33 . </S>",
    "<S> figure 1b also illustrates that the envelop slope for the monkey book is independent of the length of the book : the full drawn zigzag curve corresponds to @xmath36 whereas the dotted zigzag curve corresponds to @xmath46 . </S>",
    "<S> both of them have the envelop slope @xmath47 given by the continuum approximation @xmath32 .    _ to sum up _ : the continuum approximation @xmath48 is very different from the actual spiked monkey book , @xmath31 . </S>",
    "<S> however , </S>",
    "<S> the envelop , @xmath32 , for the cumulative wfd , @xmath33 , of the monkey book is nevertheless a power law with a slope which is independent of the size of the book .      </S>",
    "<S> heaps law is an empirical law which states that the number of different words , @xmath3 , in a book approximately increases as @xmath49 as a function of the total number of words @xcite . for a random book , like the monkey book </S>",
    "<S> , there is a direct connection between @xmath31 and the @xmath21-curve . </S>",
    "<S> a random book means a book </S>",
    "<S> where the class of words which occurs @xmath1 times are randomly distributed throughout the book : the chance of finding a word with frequency @xmath1 is independent of the position in the book i.e. it is as likely to find a word with a frequency @xmath1 at the beginning , in the middle or at the end of the book . </S>",
    "<S> suppose that such a book of size @xmath17 has a wfd @xmath50 created by sampling a fixed theoretical probability distribution @xmath51 , where the normalization constant is only weakly dependent on @xmath7 . the number of different words for a given size is then related to @xmath7 through the relation    @xmath52    and , since in the present case    @xmath53    it follows that    @xmath54    a heuristic direct way to this result is to argue that the first time for a word with frequency @xmath1 to occur is inversely proportional to its frequency @xmath55 , so that you in the time - interval @xmath56 $ ] introduce @xmath57 new words . </S>",
    "<S> since @xmath58 is proportional to how far into the book you are , this means that @xmath59 . </S>",
    "<S> the conclusion from eqs .  </S>",
    "<S> [ heap]-[heaps_law ] is that the @xmath21-curve of a random book with @xmath60 should follow heaps law very precisely with the power - law index @xmath61 . </S>",
    "<S> one consequence of this is that if you start with such a book of size @xmath7 and the number of different words @xmath62 and then randomly pick half the words , then this new book of @xmath63 words will on the average have @xmath64 different words . </S>",
    "<S> thus , starting from a random book of size @xmath7 , you can obtain the complete @xmath62-curve by dividing the book into parts of smaller sizes . </S>",
    "<S> furthermore , in the special case where @xmath50 is a power law with a functional form , and a power - law index , which is _ size - independent _ , the @xmath62-curve follows heaps law very precisely with @xmath61 . </S>",
    "<S> figure 2 illustrates that this is indeed true for monkey books by showing the @xmath21-curve for different alphabet sizes ( full drawn curves ) together with the corresponding analytic solutions ( broken curves ) . </S>",
    "<S> note that for heaps law , @xmath8 , and the relationship @xmath61 to hold , the full curves should be parallel to the broken curves for each alphabet size , respectively . also , the continuum theory from eq .  </S>",
    "<S> [ gamma ] gives @xmath18 for @xmath29 ( an alphabet with a single letter ) which by eq .  </S>",
    "<S> [ heaps_law ] predicts @xmath65 , and which is again in full agreement with the monkey book .     for alphabets of length @xmath66 and @xmath67 , respectively . </S>",
    "<S> according to eq.(7 ) the @xmath21 should for @xmath68 , and @xmath69 follows heaps power laws with the exponents @xmath70 and @xmath71 , respectively , and the corresponding broken lines show that these predictions are borne out to excellent precision . for @xmath72 , eq.(7 ) </S>",
    "<S> predicts that @xmath21 instead should be proportional to @xmath73 , since @xmath74 . </S>",
    "<S> the corresponding broken curve again shows an excellent agreement . ]    however , notwithstanding this excellent agreement , the reasoning is nevertheless flawed by a serious inconsistency : the connection to heaps law , @xmath8 , was here established for a random book with a continuous power - law wfd , whereas the wfd of a monkey book consists of a series of disjunct peaks , and only the envelope of its cumulative wfd can be described by a continuous power law . </S>",
    "<S> it thus seems reasonable that a random book with a wfd which is well described by a smooth power law would satisfy heaps law to an even greater extent . </S>",
    "<S> however , this reasoning is not correct . </S>",
    "<S> the derived form of heaps law , @xmath75 is based on a wfd for which the functional form and @xmath15 is _ </S>",
    "<S> size independent_. but as we will show in the following section , this is an impossibility : a random book with a continuous wfd can in principle _ not _ be described by a size - independent power - law .      the most direct way to realize this inconsistency problem is to start from a random book which has a smooth power - law wfd with an index @xmath15 . </S>",
    "<S> such a book can be obtained by randomly sampling word frequencies from a continuous power - law distribution of a given @xmath15 and then placing them , separated by blanks , randomly on a line . for this  sampled book </S>",
    "<S>  one can then directly obtain the @xmath62-curve by dividing the book into parts , as described above . </S>",
    "<S> fig .  </S>",
    "<S> 3a gives an example of a @xmath21-curve for a sampled book with @xmath76 , @xmath77 and @xmath36 . </S>",
    "<S> the resulting wfd is shown in fig .  </S>",
    "<S> 3b .    </S>",
    "<S> it is immediately clear from fig .  </S>",
    "<S> 3a that a sampled book with a power - law wfd does _ not _ have an @xmath62-curve which follows heaps law , @xmath8 ( it deviates from the straight line in the figure ) . </S>",
    "<S> this is thus in contrast to the result of the derivation given by eq .  </S>",
    "<S> [ heap]-[heaps_law ] and the monkey - book which does obey heaps law , @xmath75 , as seen from fig .  </S>",
    "<S> 2 . </S>",
    "<S> this means that the monkey book obeys heaps law _ </S>",
    "<S> because _ the wfd is _ not _ well described by a smooth power law , and that the  spiked  form of the monkey-@xmath31 is , in fact , crucial for the result . </S>",
    "<S> the explanation for the size invariance of the monkey book can be found in the derivation presented in the appendix . </S>",
    "<S> since the frequency of each word is exponential in the length of the word , it naturally introduces a discrete size - invariant property of the book . </S>",
    "<S> this discreteness is responsible for the disjunct peaks shown in fig .  1a , and it is easy to realize that non - overlapping gaussian peaks will transform into new gaussian peaks with conserved relative amplitudes , thus resulting in a size - independent envelope </S>",
    "<S> .     described by a smooth power law wfd @xmath78 . </S>",
    "<S> ( a ) full drawn curve is the real @xmath21 whereas the broken straight line is the heaps  power law prediction from eq.(7 ) . </S>",
    "<S> since the real @xmath21-curve is bent , it is clear that a power law wfd does not give a power law @xmath21 . </S>",
    "<S> ( b ) illustrates that the wfd obtained for a part of the full book containing @xmath79 words where @xmath80 has a different functional form than @xmath81 . </S>",
    "<S> the curves show the cumulative distributions @xmath43 for the full random book @xmath82 and @xmath83 , respectively . ]    </S>",
    "<S> the core of this paradoxical behavior lies in the fact that the derived form of the @xmath21-curve requires a size - independent wfd , and that a random book is always subject to well - defined statistical properties . </S>",
    "<S> one of these properties is that the @xmath84 transforms according to the rbt ( random book transformation ) when dividing it into parts @xcite : the probability for a word that appears @xmath85 times in the full book of size @xmath7 to appear @xmath1 times in a smaller section of size @xmath86 can be expressed in binomial coefficients : let @xmath87 and @xmath88 be two column matrices with elements numerated by @xmath89 and @xmath1 , then    @xmath90    where @xmath91 is the triangular matrix with the elements @xmath92    and @xmath80 is the ratio of the book sizes . </S>",
    "<S> the normalization factor @xmath93 is    @xmath94    suppose that @xmath84 is a power law with an index @xmath15 . </S>",
    "<S> the requirement for the corresponding random book to obey heaps law is then that @xmath84 under the rbt - transformation remains a power law with the same index @xmath15 . </S>",
    "<S> however , the rbt - transformation does not leave invariant a power law with an index @xmath95 @xcite . </S>",
    "<S> this fact is illustrated in fig .  </S>",
    "<S> 3c , which shows that a power law @xmath84 changes its functional form when describing a smaller part of the book . </S>",
    "<S> this change of the functional form is the reason for why the @xmath62-curve in fig .  </S>",
    "<S> 3a does not obey heaps law . </S>",
    "<S> the implication of this is that a random book which is well described by the continuum approximation @xmath96 can never have a @xmath21-curve of the heaps law form @xmath97 .    in fig .  </S>",
    "<S> 4a - c we compare the result for a power law @xmath84 in fig .  </S>",
    "<S> 3a - c to the real book _ </S>",
    "<S> moby dick _ by herman melville . </S>",
    "<S> fig .  </S>",
    "<S> 4a shows the @xmath62 for @xmath98 both for the real book and for the randomized version ( where the words in the real book are randomly re - distributed throughout the book ) @xcite . </S>",
    "<S> as seen , the @xmath21-curve for the real and randomized book are closely the same and very reminiscent of the pure power - law case in fig .  </S>",
    "<S> 3a : a real and random book , as well as a power - law book , deviates from heaps law in the same way . in fig .  </S>",
    "<S> 4c we show that the reason is the same : the form of the wfd changes with the size of the book in similar ways . </S>",
    "<S> the result for the real book is not a property solely found in moby dick , but has previously been shown to be an ubiquitous feature of novels @xcite .    </S>",
    "<S> -curves for _ moby dick _ </S>",
    "<S> ( dark curve ) and for the randomized _ moby dick _ ( light curve ) together with a power law ( straight broken line ) . </S>",
    "<S> real and random _ moby dick _ has to excellent approximation the same @xmath21 and this @xmath21-curve is not a power law . </S>",
    "<S> note the striking similarity with fig.3a . </S>",
    "<S> ( b ) change in the cumulative distribution @xmath33 with text length for _ moby dick _ , dark curve corresponds to the full length @xmath99 words and the light curve to @xmath100 ( @xmath101 ) . </S>",
    "<S> the change in the functional form of the wfd is very similar to the power law book shown in fig.3b . ]    </S>",
    "<S> _ to sum up : _ a simple mathematical derivation tells us that if the wfd is well described by a power law , then so is the @xmath21-curve . </S>",
    "<S> this power - law form @xmath8 is called heaps law . however , a sampled book , as well as real books , does not follow heaps law , in spite of the fact that their wfds are well described by smooth power laws . </S>",
    "<S> in contrast , the monkey book which has a spiky , disjunct , wfd , does obey heap s law very well .      </S>",
    "<S> we have shown that the @xmath21-curve for a monkey book obeys heaps power - law form @xmath102 very precisely . </S>",
    "<S> this is in contrast to real and randomized real books , as well as sampled books with word - frequency distributions ( wfd ) which are well described by smooth power laws : all of these have @xmath21-curves which deviate from heaps law in similar ways . </S>",
    "<S> in addition we discussed the incompatibility of simultaneous power - law forms of the wfd and the @xmath21-curves ( heaps law ) . </S>",
    "<S> this led to the somewhat counter - intuitive conclusion that heaps power law requires a wfd which is _ not _ a smooth power law ! we have argued that the reason for this inconsistency is that the simple derivation that leads to heaps law when starting from a power - law wfd assumes that the functional form is size independent when sectioning down the book to smaller sizes . </S>",
    "<S> however , it is shown , using the random book transformation ( rbt ) , that this assumption is in fact not true for real or randomized books , nor for a sampled power - law book . </S>",
    "<S> in contrast , a monkey book , which has a spiked and disjunct wfd , possesses an invariance under this transformation . </S>",
    "<S> it is shown that this invariance is a direct consequence of the discreteness in the frequencies of words due to the discreteness in the length of the words ( see appendix ) . </S>"
  ]
}