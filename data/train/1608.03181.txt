{
  "article_text": [
    "testing software components without access to source code or hand - crafted models is challenging because there is no guidance for the selection of test inputs .",
    "selection is invariably guided by intuition or , if automated , by random or quasi - random input generation algorithms @xcite . left to chance alone",
    ", random test sets can easily fail to expose facets of software behaviour that depend upon specific input characteristics .",
    "furthermore it can become exceedingly difficult to reason about the adequacy of a randomly - generated test set , especially for non - numerical programs without an operational profile @xcite .",
    "recently , several `` learning - based testing '' ( lbt ) techniques have emerged @xcite that aim to address these limitations .",
    "lbt techniques are based on the idea , first espoused by weyuker @xcite and budd and angluin @xcite , that there is a natural duality between inductive model inference and software testing .",
    "the former seeks to infer a general model of behaviour for a system from an incomplete sample of observations of its behaviour .",
    "the latter seeks to identify the smallest possible set of observations that are required to expose the full range of behaviour .",
    "although the ultimate purposes are different , both are bound by an intrinsic challenge : attempting to establish the link between the often infinite range of externally observable behaviour of a system and a finite sample of observations ( or vice versa ) .",
    "lbt techniques seek to exploit this duality by using machine learning algorithms to infer input / output models from test executions .",
    "these models can then be used to derive new test cases .",
    "the rationale is that this ought to form a virtuous loop ( or , to adopt popper s terminology , a cycle of `` conjecture and refutation '' @xcite ) where the inferred models become increasingly detailed and accurate , and thereby drive the test generation to produce increasingly rigorous test sets .",
    "the step of generating new test inputs from an inferred model is especially important .",
    "new test inputs ought ideally to expose ` new ' aspects of software behaviour that have not featured in previous test executions .",
    "intuitively , the test generation approach tends to be closely tied to the type of inferred model ( e.g. , if an approach infers a state machine , it will tend to adopt a state machine testing algorithm to derive new tests @xcite ) .    unfortunately , there are two barriers that currently restrict lbt approaches to relatively specific classes of relatively small - scale software systems :    the dependence between the type of inferred model and the test generation approach can be highly limiting .",
    "whole families of powerful machine learning algorithms have to be excluded as they do not produce explicit , ` testable ' models .",
    "the application of model - based test generation approaches to inferred models can yield large numbers of test cases , which hampers scalability .",
    "many of the generated tests are of little _ utility _ to the learner .",
    "whereas the goal is to find ` counter - examples ' to the inferred models , the majority of test cases can merely end up corroborating what is already known .    in this paper",
    "we investigate the possibility of using an active learning query strategy frameworks @xcite to circumvent these limitations . in machine learning",
    ", query strategy frameworks provide a means by which to use an existing inferred model ( or set of models ) to select further samples that are most likely to be of `` high utility '' to the learner  i.e. provide information that is not already contained within the training set .",
    "these tend to be based on the principle that the best samples are those whose prediction elicits the highest degree of _ uncertainty _ with respect to the current model . in the context of lbt ,",
    "if one accepts the existence of a relationship between the adequacy of a test set and the accuracy of a model inferred from it , then it should follow that test cases selected by an effective uncertainty sampling technique should form an effective basis for test case selection .    in detail ,",
    "the contributions of this paper are as follows :    we introduce the first application of query strategy frameworks to test generation ( section  [ sec : qbc_test ] ) .",
    "we present an implementation of a query strategy framework for test generation using query by committee  @xcite on inferred models ( section  [ sec : qbc_test ] ) .",
    "we propose the use of genetic programming  @xcite as a basis for model inference , as it directly enables query by committee ( section  [ sec : qbc_test ] ) .",
    "we present an implementation of an lbt - based testing using query strategy frameworks , based on genetic programming and query by committee ( section  [ sec : qbc_test ] ) .",
    "we present an empirical evaluation on eight functions provided within the apache commons math and jodatime frameworks , using mutation testing to assess the effectiveness of the generated test cases ( section  [ sec : eval ] ) .",
    "our experiments demonstrate that uncertainty sampling leads to a higher mean number of mutants detected than random or adaptive random testing ( the baseline techniques we use in this paper ) .",
    "it also tends to require fewer test executions to produce higher numbers of mutants .",
    "this is especially valuable for test - scenarios where there is a non - trivial cost associated with test execution ( e.g. tests take a prohibitive amount of time , or their outputs need to be checked by a human test - oracle ) .",
    "black - box testing in general refers to the concept of testing a software system without access to its source code .",
    "ideally , black - box testing is driven by detailed formal specifications or test models , which enable techniques to automatically generate tests , and act as test oracle that decides whether a given test execution revealed a fault or not . in practice ,",
    "such specifications are not always available , in which case automated generation of tests is limited to few options .",
    "the most common approach to test automation in the absence of formal specifications and source code is to randomly select tests , for example using a uniform distribution on the input space or an operational profile @xcite .",
    "the effectiveness of random testing highly depends on the specifics of the system under test : random testing is generally unlikely to find specific input values  @xcite , and may perform poorly at covering the underlying behaviour of the program .",
    "adaptive random testing ( art )  @xcite aims to alleviate these problems by ensuring that tests are spread out across the program input space as much as possible .",
    "in general , art works iteratively by repeatedly sampling a set of random inputs , and out of this set selecting the input that is most different to previously executed tests as the next test to run on the system under test . while there is evidence that this approach makes the selected tests more effective than a completely random selection , every test input adds to complexity of generating the next test input , because there is an additional point in euclidean space against which to measure the next group of random inputs .",
    "if running a test on a system under test is cheap , then pure random testing may be more effective than art  @xcite as it can simply execute significantly more tests in the same time as art .",
    "however , in practice test execution can often take a long time , and the absence of an automated oracle ( e.g. , a formal specification ) may make it necessary to manually investigate every single test outcome .",
    "thus , we assume that it is desirable to generate the most effective set of tests , rather than relying on the ability to run large sets of potentially redundant tests .",
    "we use the term ` learning - based testing ' ( lbt ) to refer to the ( now relatively broad ) family of techniques that seek to use machine learning to support the generation of test cases .",
    "the idea was first explored by weyuker @xcite and budd and angluin @xcite in the early eighties .",
    "for the subsequent 15 years it was the subject of some predominantly theoretical research @xcite . however , over the subsequent 15 years it adopted a more practical bent , with several authors developing accompanying proof - of - concept tools @xcite .",
    "@xmath0 @xmath1 @xmath2 @xmath1    algorithm [ alg : iterativealgorithm ] shows the main generic lbt steps :    the algorithm starts with an initial set @xmath3 of inputs to the program .",
    "this may be empty , but it may also be an established test set that we wish to improve .",
    "the loop of model inference and test generation is executed until a stopping criterion * terminate(@xmath2,@xmath0 ) * evaluates to true .",
    "for example , it might attempt to establish the equivalence between the inferred model @xmath0 and the system under test @xmath4 , and return true if the model is sufficiently similar in some sense @xcite .",
    "it might alternatively simply terminate after a fixed number of iterations , if @xmath5 reaches a particular size , or there has been no change to @xmath0 after a certain number of iterations .    in this loop ,",
    "the first step is to infer a predictive input / output model * hyp * of the program using the function * infermodel(@xmath2)*. the type of the model can vary , and depends on the nature of the system under test .",
    "proposed techniques have adopted state machines @xcite , decision trees @xcite and daikon invariants  @xcite .",
    "the input to the * infermodel * function are the executions , i.e. , the input / output pairs resulting from executing the test inputs @xmath3 on the system under test @xmath4 using function * execute(@xmath4,@xmath6)*.    finally , * selectinputs(@xmath0,@xmath4 ) * selects new inputs . the test generation strategy might be random @xcite , driven by source code coverage  @xcite , or using a model - based test algorithm with respect to @xmath7 @xcite .",
    "much of the research on combining inference and testing has focussed on the interplay between the _ terminate _ and _ infermodel _ functions  on the ability to leverage inference mechanisms to provide more meaningful adequacy criteria .",
    "this is what motivated most of the early research into the area as well  @xcite .",
    "recent inference and test generation techniques have been combined to guarantee that the behaviour of the system has been exercised to a certain extent .",
    "for example , several researchers have combined angluin s @xmath8 inference technique  @xcite with established state machine testing techniques  @xcite and showed that these lead to strong guarantees that the inferred model accurately represents what has been explored .",
    "lbt techniques tend to be limited in their practical applicability because they rely on the inference of models that not only approximate the behaviour of the sut , but are _ also _ usable as a basis for automated test generation . as illustrated in figure [ fig : problem ] , the processes of inference and testing are highly interdependent ; the model has to be _",
    "learnable _ from the sut @xcite , but also has to be _",
    "testable _ , in the sense that it can provide a suitable basis for the generation of new test cases .",
    "this explains why lbt techniques so far have been largely restricted to state machines @xcite , decision trees @xcite , and invariants  @xcite . as a consequence ,",
    "entire families of machine learning algorithms that infer models that are harder to subject to symbolic reasoning are excluded , even if they could potentially infer more accurate models from a broader class of sut s .",
    "these include kernel - method techniques such as svm @xcite , neural net learners @xcite , and genetic programming  @xcite .",
    "aside from the constraints mentioned above , the use of ` off - the - shelf ' test generation techniques , coupled with the iterative nature of the approach , can lead to scalability problems .",
    "test generation algorithms generate test cases without considering the test cases that have been generated in previous iterations .",
    "this can produce very large test sets , especially if the testing algorithm in question produces large numbers of test cases anyway ( e.g. , the popular w - method @xcite for state machines is a good example of an algorithm that does not scale well , and has often used for test - driven model inference @xcite ) .",
    "the primary challenge addressed in this paper is to find a means by which to remove the constraints on the classes of machine learners that can be applied to lbt .",
    "although we want to remove the constraints on the types of models that are inferred , it is crucial that they can still guide test generation , and do so in a scalable way that does not needlessly re - test behaviour that has already been tested .",
    "in this paper we will show how the above problem can be solved by the use of query strategy frameworks , a core facet of active learning techniques @xcite in machine learning .",
    "precisely how this is achieved will be described in the next section . here",
    "we provide a generic introduction to query strategy frameworks and query by committee .",
    "machine learning algorithms can be broadly categorised into conventional ( _ passive _ ) machine learners and _ active _ machine learners .",
    "passive learners infer models from data that is given to them before learning commences .",
    "active learners might start from some given data , but crucially are also imbued with the ability to obtain further data .",
    "the learner might surmise that the inferred model is incomplete because the initial sample lacked data of a certain characteristic , so the learner can set out to obtain more relevant data , which it can use to refine its model .",
    "the active learning setting gives rise to the _ query strategy problem _ @xcite .",
    "the process of obtaining a sample might be expensive , so it is consequently important to keep the number of queries ( additional samples ) down to a minimum .",
    "however , any additional data that _ is _ sampled must be of a _ high utility _ ",
    "i.e. , it must lead to improvements in the model inferred by the learner .",
    "this problem has been the subject of a large amount of research over the past two decades ( a good overview is provided by settles @xcite ) .",
    "the essential goal is to avoid selecting a query that fails to add new information that is of value to the learner .",
    "any new data should ideally confound the predictions of the current model .",
    "one factor that plays a key role in selecting queries is the notion of _ uncertainty_. given a data - point that was not part of the original training set ( referred to as a ` query ' ) , the degree of uncertainty exhibited by the current hypothesis model as to how it should be classified can provide an indication of how useful it would be to obtain a real sample . the goal is thus to identify queries for which the level of confidence in the corresponding output is at its lowest , with the aim of eliciting aspects of behaviour that were perhaps under - represented in the training sample .",
    "one key challenge is to find a suitable metric that can be used to assess this `` uncertainty '' for a given model prediction . for statistical machine learners , where the output is often in the form of a probability distribution , numerous uncertainty sampling techniques have been developed @xcite .",
    "however , in the context of lbt , models such as inferred state machines tend not to be probabilistic .",
    "there is a ` trick ' that enables the application of uncertainty sampling even when the inferred models are themselves not probabilistic .",
    "if one can , from a given sample , infer _ multiple _ different models , then it becomes possible to use their mutual agreement / disagreement to estimate a level of uncertainty and use this as a basis for uncertainty sampling @xcite .",
    "algorithm [ alg : qbc ] shows the query by committee ( qbc ) approach proposed by seung _",
    "_ @xcite .",
    "@xmath9 @xmath1 @xmath10    the entire process iterates for a fixed number of iterations  ( @xmath11 ) .    at each iteration ,",
    "the * learnmultiple * function produces a `` committee '' of hypothesis models .",
    "this is conventionally achieved by ensemble methods @xcite , which produce different hypotheses by inferring models from different samples of the training set ( in this paper we will illustrate an alternative approach of using the population generated by a genetic programming algorithm ) .    once the models have been inferred , the * randompoints * function generates a set of random ` inputs ' @xmath12  in machine learning terms this is a set of _ unlabelled _ data points .",
    "the size of @xmath12 is determined by the @xmath13 parameter .",
    "the nested for - loop then essentially picks a subset of @xmath14 points in @xmath12 .",
    "these are selected by evaluating each point in @xmath12 to determine those points about which the inferred models @xmath9 are _ least _ in agreement ( as computed by the * computeutility * function ) . in other words",
    ", these points would be of most _ utility _ to the learner .",
    "once these points are selected , they are labelled with the * label * function , added to the training set , and the process iterates .    after the final iteration",
    ", a set of models is inferred from the aggregate training set , and a model is selected to be returned by the * best * function .",
    "the selection criteria can vary depending on the inference approach ",
    "one straightforward option ( adopted in this paper ) is to return the model that best predicts the outputs ( or ` labels ' ) produced by @xmath15 .",
    "there is a clear similarity between the qbc algorithm and the lbt algorithm in algorithm [ alg : iterativealgorithm ] .",
    "both involve loops , where models are inferred at each iteration . in both cases ,",
    "the models are used as a basis for selecting more data ( test inputs in the testing context , unlabelled data points in the machine learning case ) .",
    "there are also two significant differences . in the case of qbc ,",
    "the output is the final inferred model , whereas in lbt the output is the data that was used to infer the model ( the test set with its outputs ) . in lbt , there is no fixed approach to generate test data  it could be random , or adopt a model - based testing algorithm . in qbc",
    ", there is only one approach ; regardless of the type of model or system , a random pool of unlabelled data points are generated , and the best @xmath14 points are chosen based on the ` uncertainty ' that they elicit from the inferred committee of models .",
    "in the context of machine learning , qbc enables uncertainty - based sampling to occur , regardless of the type of model that is inferred . in this paper",
    "we produce the testing by committee approach , which applies qbc to lbt to circumvent the dependence between the model inference algorithm and the test - generation algorithm . in principle",
    "this enables lbt to use _ any _ model inference algorithm , and to select test cases based on the combined uncertainty of the inferred models .    in this section",
    "we first set out our _ test by committee _",
    "algorithm , which combines lbt with qbc .",
    "we then provide technique that implements this approach using genetic programming as a basis for the model inference .",
    "@xmath9 @xmath1    our proposed ` test by committee ' ( tbc ) algorithm is shown in algorithm [ alg : qbc - test ] .",
    "it clearly combines algorithms [ alg : iterativealgorithm ] and [ alg : qbc ] .",
    "the key similarities and dissimilarities are as follows :    as with qbc , we limit the number of iterations to a fixed number @xmath11 ( though it would certainly be possible to integrate something more elaborate , along the lines of the @xmath16 function in algorithm [ alg : iterativealgorithm ] ) .",
    "the step of @xmath17 is the same as in algorithm [ alg : qbc ] ; a population of models are inferred using either ensemble methods or , as we will demonstrate , population - based learners such as genetic programming .    to generate the candidate test inputs",
    ", we introduce a new function * randominputs*. the @xmath4 is only used to gain information about its interface . once the types of the interface are known , inputs are formulated as combinations of random values of the appropriate types .",
    "the process of adding new tests to the test set is the same as in algorithm [ alg : qbc ] . for @xmath14 iterations , the best candidate is selected from @xmath12 by seeing which candidate test case causes the most disagreement amongst models in @xmath9 .",
    "the chosen test is then executed to identify its actual output , and this is then added to @xmath5 ( it is also removed from @xmath12 to avoid re - selection ) .",
    "many of the steps are in effect the same as they are in conventional lbt . however , two steps are very different , and therefore require a more in - depth discussion .",
    "the model inference step ( @xmath17 ) requires multiple models .",
    "the process of selecting the best candidate test case ( @xmath18 ) is also new in the context of testing , and requires more details . in both cases , there are many possible ways in which they could be implemented . in the following two subsections ,",
    "we describe how we have chosen to implement them for our proof of concept .",
    "to produce the models required for query - by - committee it is possible to use a genetic programming ( gp ) inference engine @xcite .",
    "a gp evolves programs of a given target language towards an optimisation goal , specified by a fitness function . as mentioned previously , in principle any inference technique",
    "could be applied ( underpinned by ensemble methods @xcite )",
    ". however , ( a ) the intrinsic population - based nature of gps renders them suitable for qbc , and ( b ) gps can easily be adapted to different types of languages , making them well suited for modelling programs in different domains .    for space reasons",
    ", we only provide the essential details of gps here , and refer the reader to poli _ et al . _ s gp field guide @xcite , along with our source code for further details . in ( tree - based ) gps ,",
    "candidate programs are ` evolved ' as abstract syntax trees , where branch nodes correspond to ` non - terminals ' representing functions , and leaf - nodes represent atomic values or variables ( terminals ) .",
    "the basic loop is as follows ( details on the terms in italics will be elaborated in the next section ) :    generate an initial population of programs as random compositions of non - terminals and terminals .",
    "execute each evolved program and evaluate it according to some _ fitness function_.    _ select _ the best programs from the population .",
    "create a new population by a process of _ cross - over _ and _",
    "mutation_.    repeat from step 2 until some stopping criterion is met .    in its traditional application ,",
    "the result of the gp is the program with the best fitness value , which represents the best solution .",
    "in our case , we can exploit the population - based nature of the gp : at the end of the search , the population consists of a range of slightly varied candidate solutions optimised for the problem at hand .      the first step to applying qbc",
    "is to select the committee . for this",
    "we select the fittest set of chromosomes @xmath9 .",
    "the size of this set is determined by the parameter @xmath19 .",
    "the query generation step involves generating a pool of random inputs @xmath12 , and then assessing every @xmath20 to find the one that creates most ` uncertainty ' according to the set of inferred models in @xmath9 ( in our case the set of chromosomes inferred by the gp ) .",
    "every potential test input @xmath21 is executed on every model @xmath22 , and the outputs are recorded .",
    "the input that produces the greatest spread of predictions is then chosen to be executed on the real sut .",
    "we have implemented the approach described in the previous section .",
    "the implementation targets numeric programs without side - effects returning single outputs . in this section , we provide details of this implementation .      in this section",
    "we elaborate the detailed aspects of the generic gp algorithm shown in section  [ sub : gp_qbc ] .",
    "* fitness function : * the fitness function provides a metric for the accuracy of the inferred program to predict the sut . fitness is evaluated by executing a candidate program on all existing test inputs , and comparing the outputs to those that were actually observed in the trace data . * selection : * step 3 selects good candidates from the population , so that they can be fed into the next generation",
    ". a popular approach , which we adopt here , is tournament selection @xcite . in our case",
    "the selection process is _ elitist _ , this means that the best individual from one generation is always preserved for the next one .    *",
    "crossover and mutation : * the candidates that were selected in step 3 are subjected to a mixture of crossover and mutation ( the frequency at which they occur is given in probabilistic terms ) .",
    "we choose to use the most common form cross - over called _ subtree - crossover _ @xcite .",
    "mutation is carried out by selecting a random node in a tree and changing it .",
    "if the selected node happens to be a terminal , its value is simply changed .",
    "if it is a non - terminal , we replace its subtree with a randomly generated one .",
    "arbitrary crossover or mutation can easily lead to nonsensical programs - for example by using string terminals with a function that expects integer parameters .",
    "strongly - typed gp @xcite prevents this from happening by ensuring that every terminal and non - terminal has a declared type . *",
    "termination and result : * the loop terminates once a candidate has been identified that can not improve in terms of fitness , or once the number of iterations hits a given limit .",
    "p0.1 p0.8   + double ( d ) & add(x : d , y : d ) , subtract(x : d , y : d ) , multiply(x : d , y : d ) , divide(x : d , y : d ) , power(x : d , y : d ) , root(x : d , y : d ) , cast(x : i ) , if(x : b , y : d , z : d ) , cos(x : d ) , exp(x : d),log(x : d ) + integer ( i ) & cast(x : d ) + boolean ( b ) & and(x : b , y : b ) , or(x : b , y : b ) , lt(x : d , y : d ) , gt(x : d , y : d ) , eq(x : b , y : b ) , eqarith(x : d , y : d),eqstring(x : s , y : s ) + logic ( all ) & if - then - else(a : b , b : d , c : d),if - then - else(a : b , b : i , c : i),if - then - else(a : b , b : s , c : s),if - then - else(a : b , b : b , c : b ) +   + double ( d ) & all variable names in @xmath23 of type double , one free variable limited to the interval @xmath24 $ ] , -1.0 + integer ( i ) & all variable names in @xmath23 of type integer , one free variable limited to the interval @xmath24 $ ] , 0 + booleans ( b ) & all variable names in @xmath23 of type boolean , ` true ` , ` false ` .",
    "+ strings ( s ) & all variable names in @xmath23 of type string , any customised pre - defined string values .",
    "+    * terminals and non - terminals : * the choices of terminals and non - terminals are shown in table [ tab : terms ] .",
    "in general , of course , the choice of gp operators is flexible , and is ideally informed by knowledge about the system being inferred . in our case , we sought a reasonably general set that can be applied across a range of programs .",
    "the question of how to refine the selection of terminals and non - terminals to best suit a sut is part of our ongoing work .      for the purpose of this work ( as a proof of concept )",
    ", we are restricting ourselves to a particular class of system that produces single numerical outputs ( either integers or numbers with decimal places ) .",
    "our initial use of standard deviation proved to be problematic , as it could often produce a misleadingly high value for the situation where most of the models were in fact in agreement , but one `` rogue '' model had produced an extreme value .    to address this problem , we instead opted for the mean absolute deviation ( mad ) value @xcite , which is less vulnerable to data - spikes . for a set of values @xmath25 , @xmath26 , where @xmath27 calculates the mean of @xmath28 .",
    "it is necessary to select a value to accommodate the situation where an inferred model returns either infinity or not a number ( e.g. , because an inferred model divides by zero ) , but the sut returns a valid value .",
    "the value should be high , to indicate that the model is incorrect , but can not be too high ( e.g. , double.max_value ) , because this prevents the calculation of an accurate mean over multiple outputs . in this case",
    ", we substitute the result with a value of 10,000,000 ( this was a somewhat ad - hoc choice , and establishing a more justified value is part of our future work ) .",
    "this section contains a brief walk - through of tbc . as a sut",
    "we choose a simple bmi calculator .",
    "this takes as input two numbers ( height in meters and weight in kilograms ) , and returns a `` body mass index '' value , calculated as @xmath29 .",
    "for our technique to operate , we do not need to be able to look at the internal implementation , but only need to know of the interface .",
    "however , to provide a complete overview , let us assume that the calculator is implemented as a bash script , with the following source code :    .... # ! /bin",
    "/ bash awk \" begin { print $ 2 / ( $ 1 * $ 1 ) } \" ....    our implementation accepts a specification of the interface in the following self - explanatory json format .    ....",
    "{      \" command \" : \" bmi.sh \" ,      \" parameters \" : [          {              \" name \" : \" height \" ,              \" type \" : \" double \" ,              \" max \" : \" 100 \" ,              \" min \" : \" -100 \"          } ,          {              \" name \" : \" weight \" ,              \" type \" : \" double \" ,              \" max \" : \" 100 \" ,              \" min \" : \" -100 \"          }      ] ,      \" output \" : [          {              \" name \" : \" output \" ,              \" type \" : \" double \"          }      ] }     ....    finally , we provide an existing basic test set that we wish to improve upon . our implementation accepts a space - separated text file , where the order of values is taken to be the order of parameters in the specification file ( height followed by weight ) :    .... 1.7 50 1.8 70 1.9 100 1.7 110 0.0 5 5.0 0 ....    with reference to the tbc process in algorithm [ alg : qbc - test ] , the bmi represents the @xmath4 , and the above list of test sets represents @xmath3 . for the sake of illustration",
    ", we will only show one iteration ( @xmath30 ) , and we will only add a single test set in this iteration @xmath31 . to illustrate how new test cases are selected , we set @xmath13 to 3 , although this would usually be much higher ( in the evaluation we will set it to 1000 ) .",
    "the tbc algorithm begins by inferring the `` committee '' @xmath9 via @xmath17 . in our case",
    ", this produces the top 10 chromosomes .",
    "to give an idea of what is inferred , two of the fittest gp programs after the first iteration is as follows :    ....      gp1 : mult(weight , exp(-1.1518922634307343 ) ) )           gp2 : div(height , exp(height - log(weight ) ) ....    although they are clearly inaccurate , we can assume that ( as the fittest members of their pool of solutions ) , they at least _ approximate _ the output .",
    "this is illustrated in figure [ fig : gpout ] , which plots outputs ( the dashed and dotted lines ) against the expected output ( the plain line ) , for all test inputs .",
    "as the next step , @xmath32 produces a set of @xmath13 inputs ( in this case three ) .",
    "the resulting inputs are shown on the left in table [ tab : inputs ] .",
    "for each input , the disagreement between the models is calculated as the maximum average deviation ( as described previously ) , shown in the right - hand column . from this , it is clear that the second input produced a huge divergence between the two inferred models .    the input with the highest mad value is thus added to the test set , and the tbc process moves to the next iteration .",
    "this time , thanks to the new test execution , the inferred models ought to be more precise , and lead to test cases that explore new aspects of the input domain .    .proposed inputs and mad calculation [ cols=\">,>,>\",options=\"header \" , ]     to gauge how effective a test set is at exposing faults , we employed mutation testing @xcite .",
    "we used the major java mutation testing framework ( version 1.6 , with all mutants )  @xcite .",
    "we seeded mutants conservatively , by selecting any classes that were executed by the initial set of tests ( we could not seed mutants in every class in the system because of the resource constraints of mutation testing ) . it does not make sense to measure the mutation score as the proportion of mutants killed , because the conservative seeding strategy will invariably mean that this proportion is liable to be very small ( for example , all of the units use a fraction of the ` org.apache.commons.math4.util.fastmath ` class ) .",
    "instead , we simply compare the absolute numbers of mutants detected , which suffices to provide valid answers to our two research questions .    to prevent any bias arising from configurations",
    ", we used the same configuration for tbc across all experiments . for the gp configuration we used the set of terminals and non - terminals detailed in table [ tab : terms ] .",
    "we used a population size of 800 , with a crossover - rate of 0.9 , a mutation rate of 0.1 , a maximum term - depth of 10 and a tournament size of 6 @xcite .",
    "we set the number of tests generated per iteration 1000 , and the number selected for addition to the test set to 5 .",
    "to answer rq1 , we analysed the mutation scores that were computed after 60 iterations , grouped according to the technique ( tbc , art , and random ) . to compare them we carried out two ( non - parametric ) wilcoxon rank sum tests per sut ( having confirmed that the distributions are not normally distributed according to the shapiro wilks test ) .",
    "the first null - hypothesis was that the mutation scores for tbc are smaller than those for random tests .",
    "the second null - hypothesis was that the mutation scores for tbc are smaller than those for art tests .",
    "the distributions were also visualised as box - plots .    to answer rq2",
    "( how much more effective is tbc ? ) , we recorded the last iteration at which tbc produced the highest mutation score ( versus art and random ) .",
    "we also plotted the trajectories of the means to show how the trajectories differed over the course of the 60 iterations .",
    "the mean numbers of mutants killed for each system are shown in table [ tab : means ] .",
    "the distributions are also visualised as box - plots in figure [ fig : boxplots ] .",
    "the table shows that , after 60 iterations , tbc has killed the highest mean number of mutants for every program .",
    "the improvement over art and random testing varies substantially between the systems . for besselj ,",
    "binomial , derivative sinh , and erf , the difference is statistically significant ; this is corroborated in the box plots . in three of these systems ( binomial , derivative sinh and erf )",
    ", difference is so marked that the lower quartile for tbc is higher than the upper quartile for art and random .    for gamma , romberg , periodtoweeks and daysbetween",
    "although the mean is higher for tbc , the differences are not statistically significant ( they are partially significant for periodtoweeks and daysbetween ) .",
    "looking at the box plots , in all cases apart from periodtoweeks the boxes for tbc are noticeably elevated . in the case of periodtoweeks ,",
    "the median score for tbc is the same as art ( even thought the mean score is substantially higher ) .",
    "this is largely due to one particular execution that achieved a particularly large number of mutations . in all cases , the difference in distributions",
    "is particularly marked at the lower end ; art and random have lower minimum scores , and lower lower - quartiles than tbc , which indicates that tbc is more consistent .",
    "rq1 : in our experiments , tbc was more effective than random testing and art . in all cases",
    "there was a higher mean number of mutants killed , and the difference in distributions was significant in 4/8 suts .",
    "we discuss the relative efficiency of tbc versus art and random testing by looking at how rapidly tbc out - performs the other approaches ( by achieving a higher mean number of mutation faults without being overtaken in subsequent iterations ) .",
    "figure [ fig : trajectories ] shows the average mutation scores and their standard deviations throughout the 60 iterations .",
    "it is important to note the differences in scales ; the different suts give rise to markedly different numbers of mutants .",
    "this means that similar differentials in the mean numbers of mutants on different plots can appear markedly different .",
    "we discuss the various trajectories by starting with the systems where the performances are most similar .    in all of the studied systems ,",
    "tbc eventually kills more mutants on average than random and art testing . in some systems",
    "the numbers of faults detected remain similar throughout , whereas in others tbc significantly outperforms art and random from the start .",
    "these cases are discussed in more detail below .    as one might expect from the results for rq1 ,",
    "the trajectories in the romberg and gammaq suts are visually similar ; these are the systems where the relative performance between the techniques is at its closest . in the romberg sut ,",
    "tbc is consistently better than art from iteration 20 onwards , but only outperforms random testing after iteration 50 . in gammaq",
    ", tbc consistently outperforms art and random from iteration 23 onwards , though only marginally .",
    "perhaps more surprisingly for both jodatime systems periodtoweeks and daysbetween the trajectory for tbc is noticeably higher than for art and random . for periodtoweeks ,",
    "the number of mutants killed for tbc rapidly increases after 10 iterations to a level that art and random only start to approach after 40 - 50 iterations .    in erf ,",
    "both art and tbc outperform random testing from the start .",
    "art and tbc are similar up to iteration 40 , where art continues to plateau at 189 whilst the mean number of killed mutants for tbc rises to over 190 .    in binomial , besselj , and derivativesinh ,",
    "the results for tbc are markedly better from the start . in the case of besselj",
    "the difference may look smaller , but this is because of the scale of the graphs . in besselj",
    "the mean tbc score after 60 iterations is 447.5 , whereas for scores for art and random are approximately 443 ; this difference of 5 is in fact larger than the differences in the other systems .",
    "rq2 : in our experiments , tbc was significantly more efficient at exposing faults than random testing and art .",
    "* threats to external validity : * the answers to rq1 and rq2 can only validly be applied to systems of a similar character to those tested here .",
    "we have only tested eight systems from two frameworks .",
    "this means that they will often have shared developers , and they all deal with similar domains .",
    "we have additionally restricted ourselves to units that are functional , which do not accept sequential inputs ( as discussed in section [ sub : subjects ] ) . to attenuate this risk",
    ", we attempted to make the selection of suts as indiscriminate as possible within our broader selection constraints .",
    "the suts presented here are the first ones we encountered that fitted our criteria .",
    "however , to truly address this threat a larger study on a more diverse range of suts is needed , which is what we will be doing in our future work .    as mentioned previously , the choice of value ranges for the parameters is important for all of the techniques .",
    "there is a high probability that our choice of ranges is not ideal ( given that we avoided using domain knowledge to avoid bias ) .",
    "it is possible that , for certain range limitations , the differences between the various techniques are reduced ( i.e. , if the value ranges are reduced ) .",
    "investigating the relationship between the selection of value ranges and the relative performance of these techniques is something that we are exploring as part of our ongoing and future work .",
    "* threats to internal validity : * the mutation score depends upon the seeding of mutants .",
    "it is possible that code was executed that was not seeded with mutants , thus skewing the results .",
    "we attempted to limit this possibility by tracking the execution of code with profiling tools .",
    "the results indicate that tbc tends to detect more faults with fewer tests than the baseline techniques .",
    "however , during the experiments a further factor became apparent that did not favour tbc : time . for art",
    "every test input adds to complexity of generating the next test input , because there is an additional point in euclidean space against which to measure the next group of random inputs .",
    "arcuri and briand made this point in their critique of art @xcite , where they showed that if time is taken into account instead of the number of tests , then art was by some distance inferior to conventional random testing .",
    "this question of time is even more pertinent to tbc than art ( indeed , it applies to every lbt technique ) .",
    "lbt involves the repeated execution of the given ( and increasing ) set of tests ( random and art do not ) .",
    "it involves model inference , which again takes time . with the use of gp , inference time",
    "is tied to the number of available tests ( since these evaluate the fitness function ) . for the binomial system ( the most time - consuming system studied ) , the full 60 iterations took on average 12 hours . for erf ( one of the least time consuming systems ) it took on average 89 minutes .",
    "the timing question is clearly an important one to address , and a larger empirical study will be incorporating this . looking at some of the trajectories in figure [ fig : trajectories ]",
    "( such as binomial and derivativesin ) it is doubtful whether random tests would catch up with tbc , even if we did allow for a large disparity in the number of tests . in any case , it is not necessarily always possible ; some test cases simply take long to execute ( e.g. if they involve complex processing or network communications ) , so the ability to execute huge numbers of tests rapidly is not always an option .",
    "also , even if it is an option , the availability of many tests is not necessarily desirable either , especially if checking the outputs is a non - trivial task .",
    "in this paper we have made an explicit connection between the problems of test data generation in software engineering and sampling in active machine learning .",
    "our solution proposes the use of uncertainty sampling as a means by which to generate suitable test data .",
    "we have provided a proof of concept implementation , along with the results of an empirical study of eight units within the apache commons math and jodatime frameworks .",
    "the initial results are encouraging .",
    "our tbc approach outperforms random testing and adaptive random testing .",
    "although promising , the approach has also given rise to several important questions , which were touched upon in the discussion of the threats to validity for the study .",
    "we have not yet studied the specific relationship between the variable - range constraints and the strength of the results .",
    "we have not examined the relationship between the amount of data in the initial test set , and the value of the final model .",
    "we have not studied the relationship between the accuracy of the final model and the effectiveness of the final test set .    in our ongoing and future work",
    "we will seek to explore these questions .",
    "we will carry out experiments to examine the effect of variable range on the number of mutants killed .",
    "we will look at the accuracy of the inferred model to see if , in this context , it leads to better test sets ( building upon the work by fraser",
    "_ et al . _",
    "we will also investigate the adoption of alternative machine learning algorithms that can model more sophisticated types of functionalities , such as complex data structures and sequential behaviour .",
    "ghani , kamran , and john a. clark .",
    "`` strengthening inferred specifications using search based testing . ''",
    "software testing verification and validation workshop , 2008 .",
    "ieee international conference on .",
    "ieee , 2008 ."
  ],
  "abstract_text": [
    "<S> we can never be _ certain _ that a software system is correct simply by testing it , but with every additional successful test we become less _ uncertain _ about its correctness . in absence of source code or elaborate specifications and models , </S>",
    "<S> tests are usually generated or chosen randomly . </S>",
    "<S> however , rather than randomly choosing tests , it would be preferable to choose those tests that decrease our uncertainty about correctness the most . in order to guide test generation </S>",
    "<S> , we apply what is referred to in machine learning as `` query strategy framework '' : we infer a behavioural model of the system under test and select those tests which the inferred model is `` least certain '' about . </S>",
    "<S> running these tests on the system under test thus directly targets those parts about which tests so far have failed to inform the model . </S>",
    "<S> we provide an implementation that uses a genetic programming engine for model inference in order to enable an uncertainty sampling technique known as `` query by committee '' , and evaluate it on eight subject systems from the apache commons math framework and jodatime . </S>",
    "<S> the results indicate that test generation using uncertainty sampling outperforms conventional and adaptive random testing .    </S>",
    "<S> < ccs2012 > </S>",
    "<S> < concept > < concept_id>10011007.10011074.10011099.10011102.10011103</concept_id > < concept_desc > software and its engineering  software testing and debugging</concept_desc > < concept_significance>500</concept_significance > < /concept > </S>",
    "<S> < /ccs2012 > </S>"
  ]
}