{
  "article_text": [
    "the spread of contagion  ( information diffusion or spread of an infection ) is a universal phenomenon that is extensively studied in the context of physical , biological , and social networks .",
    "such cascades can have one or multiple sources ( or _ seeds _ ) and spread from infected nodes to neighbors through the link structure .",
    "a motivating application for the study of influence is viral marketing strategies  @xcite , in which the influence of a set @xmath1 of people in a social network is the number of adoptions triggered if we give @xmath1 free copies of a product .",
    "the problem also has important applications beyond social graphs , such as placing sensors in water distribution networks for detecting contamination  @xcite .",
    "a popular model for information diffusion is _ independent cascade _ ( ic ) , in which an independent random variable is associated with each ( directed ) edge @xmath2 to model the degree of influence of @xmath3 on @xmath4 .",
    "a single propagation instance is obtained by instantiating all edge variables .",
    "we then study the distribution of a property of interest , such as the number of infected nodes , over these random instances .",
    "the simplest and most studied ic model is _ binary ic _ , in which the range of the edge random variables is binary .",
    "a biased coin of probability @xmath5 is flipped for each directed edge @xmath2 .",
    "accordingly , the edge can be either _ live _ , meaning that once @xmath3 is infected , @xmath4 is also infected , or _",
    "null_. this model was formalized in a seminal work by kempe et al .",
    "@xcite and is based on earlier studies by goldenberg et al .",
    "note that each direction of an undirected edge @xmath6 may have its own independent random variable , since influence is not necessarily symmetric . a particular propagation instance",
    "is specified by the set of live edges , and a node is infected by a seed set @xmath1 in this instance if and only if it is reachable from a seed node .",
    "the _ influence _ of @xmath1 is formally defined as the expectation , over instances , of the number of infected nodes .    instead of working directly on this probabilistic ic model , kempe et al .",
    "@xcite proposed a simulation - based approach , in which a set @xmath7 of propagation instances ( graphs ) is generated in monte carlo fashion according to the influence model .",
    "the average influence of @xmath1 on @xmath7 is an unbiased estimate that converges to the expectation on the probabilistic model .",
    "the ability to compute influence with respect to an _ arbitrary _ set of propagation instances has significant advantages , as it is useful for instances generated from traces or by more complex models @xcite , which exhibit correlations between edges that can not be captured by the simplified ic model  @xcite .",
    "moreover , the average behavior of a probabilistic model on a small set of instances captures its `` typical '' behavior , which is often more relevant than the expected value when the variance is very high .",
    "a basic primitive in the study of influence are _ influence queries _ : compute ( or approximate ) the influence of a query set @xmath1 of seed nodes . with binary influence",
    ", this amounts to performing graph searches from the seed set in multiple instances .",
    "unfortunately , this does not scale well when many queries are posed over graphs with millions of nodes .",
    "even more computationally challenging is the fundamental _ influence maximization _ problem , which is finding the most potent seed set of a certain size or cost .",
    "the problem was formalized by kempe et al .",
    "@xcite and inspired by richardson and domingos  @xcite .",
    "kempe et al .  showed that , even when the influence function is deterministic ( but the number @xmath8 of seeds is a parameter ) , the problem encodes the classic max cover problem and therefore is np - hard  @xcite .",
    "moreover , an inapproximability result of feige  @xcite implies that any algorithm that can guarantee a solution that is at least  @xmath9 times the optimum is likely to scale poorly with the number of seeds .",
    "chen et al .",
    "@xcite showed that computing the exact influence of a single seed in the binary ic model , even when edge probabilities are @xmath10 , is  # p  hard  @xcite .    using simulations , the objective studied by kempe et al .",
    "@xcite is then to find a set @xmath1 of seeds with maximum average influence over a fixed set of propagation instances .",
    "a natural heuristic is to use the set of most influential individuals , say those with high degree or centrality  @xcite , as seeds .",
    "this approach , however , can not account for the dependence between seeds , missing the fact that two important nodes may `` cover '' essentially the same communities .",
    "kempe et al .",
    "@xcite proposed a greedy algorithm ( greedy ) instead .",
    "it starts with an empty seed set and iteratively adds to @xmath1 the node with maximum _ marginal _ gain in influence ( relative to current seed set ) . since our objective is monotone and submodular , a classical result from nemhauser et al .",
    "@xcite implies that the influence of the greedy solution with @xmath8 seeds is at least @xmath11 of the best possible for any seed set of the same size . from feige s inapproximability result",
    ", this is the best approximation ratio guarantee we can  ( asymptotically and realistically ) hope for .",
    "greedy has become the gold standard for influence maximization , in terms of the quality of the results .",
    "greedy , however , does not scale to modern real - world social networks .",
    "the issue is that evaluating the marginal contribution of each node requires a directed reachability computation in each instance  ( of which there can be hundreds ) .",
    "several performance improvements to greedy have thus been proposed .",
    "leskovec et al .",
    "@xcite proposed celf , which are `` lazy '' evaluations of the marginal contribution , performed only when a node is a candidate for the highest marginal contribution .",
    "chen et al .",
    "@xcite took a different approach , using the reachability sketches of cohen  @xcite to speed up the reevaluation of the marginal contribution of all nodes .",
    "while effective , even with these and other accelerations  @xcite , the best current implementations of greedy do not scale to networks beyond  @xmath12 edges  @xcite , which are quite small by modern standards .    to support massive graphs , several studies proposed algorithms specific to the ic model , which work directly with the edge probabilities instead of with simulations and thus can not be reliably applied to a set of arbitrary instances .",
    "borg et al .",
    "@xcite recently proposed an algorithm based on reverse reachability searches from sampled nodes , similar in spirit to the approach used for reachability sketching  @xcite .",
    "their algorithm provides theoretical guarantees on the approximation quality and has good asymptotic performance , but large `` constants . ''",
    "very recently , tang et .",
    "@xcite developed tim , which engineers the ( mostly theoretical ) algorithm of borgs et al .",
    "@xcite to obtain a scalable implementation with guarantees .",
    "a significant drawback of this approach is that it only works for a pre - specified seed set size @xmath8 , whereas greedy produces a sequence of nodes , with each prefix having an approximation guarantee with respect to the same - size optimum . in applications we are often interested not in a single point , but in a trade - off curve that allows us to find a sweet spot of influence per cost or characterize the network .",
    "tim also scales very poorly with the seed set size @xmath8 , and the evaluation only considered seed sets of up to 50 nodes .",
    "the degreediscount  @xcite heuristic refines the natural approach of adding the next highest degree node .",
    "mia  @xcite converts the binary ic sampling probabilities @xmath13 to deterministic edge weights and works essentially with one deterministic instance .",
    "irie , by jung et al .",
    "@xcite , is a heuristic approximation of greedy addition of seed nodes , and has the best performance we are aware of for an algorithm that produces a sequence of seed nodes . in each step , the probability of each node to be covered by the current seed set @xmath1 is estimated using another algorithm ( or simulations ) .",
    "they then use eigenvector computations to approximate marginal contributions of all nodes . of those approaches , the irie heuristic scales much better and",
    "is much more accurate than other heuristics . in particular",
    ", it performs nearly as well as greedy on many research collaboration graphs  @xcite .",
    "[ [ contributions . ] ] contributions .",
    "+ + + + + + + + + + + + + +    we design a novel sketch - based approach for influence computation which offers scalability with performance guarantees .",
    "our main contribution is skim  ( sketch - based influence maximization ) , a highly scalable ( approximate ) implementation of the greedy algorithm for influence maximization .",
    "we also introduce _ influence oracles _ : after preprocessing that is almost linear , we can answer _ influence queries _ very efficiently , considering only the sketches of the query seed set .",
    "we can apply our design on inputs specified as a fixed set of propagation instances , as in kempe et al .",
    "@xcite , with influence defined as the average over them .",
    "we also handle inputs specified as an ic model , where influence is defined as the expectation .",
    "our model is defined precisely in section  [ model : sec ] .",
    "we now provide more details on our design .",
    "the exact computation of an influence query requires expensive graph searches from the query seed set @xmath1 on each of @xmath14 instances .",
    "the exact greedy algorithm for influence maximization requires a similar computation for each marginal contribution .",
    "we address this scalability issue by working with sketches .",
    "the core of our approach are per - node summary structures which we call _ combined reachability sketches_. the sketch of a node compactly represents its influence `` coverage '' across  @xmath14 instances ; we call this its _ combined reachability set_. the combined reachability sketch of a node , precisely defined in section  [ sketch : sec ] , is the bottom-@xmath15 min - hash sketch  @xcite of the combined reachability set of the node .",
    "this generalizes the reachability sketches of cohen  @xcite , which are defined for a single instance .",
    "the parameter @xmath15 is a small constant that determines the tradeoff between computation and accuracy .",
    "bottom-@xmath15 sketches of sets support cardinality estimation , which means that we can estimate the influence  ( over all instances ) of a node or of a set of nodes from their combined reachability sketches .",
    "the estimate has a small relative error and good concentration  @xcite .",
    "our use of combination sketches and state - of - the - art optimal estimators is key to obtaining the best balance between sketch size and accuracy .",
    "our skim  algorithm for influence maximization is presented in section [ binaryim : sec ] .",
    "it scales by running the greedy algorithm in `` sketch space , '' always taking a node with the maximum _ estimated _ ( rather than exact ) marginal contribution .",
    "skim  computes combined reachability sketches , but only until the node with the maximum estimated influence is computed .",
    "this node is then added to the seed set .",
    "we then update the sketches to be with respect to a _",
    "residual _ problem in which the node that is selected into the seed set and its `` influence '' are no longer present .",
    "skim  then resumes the sketch computation , starting with the residual sketches , but ( again ) stopping when a node with maximum estimated influence ( in the current , residual , instance ) is found .",
    "a new residual problem is then computed .",
    "this process is iterated until the seed set reaches the desired size .",
    "since the residual problem becomes smaller with iterations , we can compute a very large seed set very efficiently .",
    "we also prove that the total overhead of the updates required to maintain the residual sketches is small .",
    "in particular , for a set @xmath16 of @xmath14 _ arbitrary _ instances , the algorithm can be run to exhaustion , producing a full permutation of the nodes in @xmath17 } |g^{(i)}|+m \\epsilon^{-2}\\log^2 n)$ ] time , where @xmath18 is the sum over nodes of the maximum indegree ( over instances ) . for all @xmath19 ,",
    "the first @xmath8 nodes we select have with a very high probability ( at least @xmath20 for a constant @xmath21 ) influence that is at least @xmath22 times the maximum influence of a seed set of the same size @xmath8 .",
    "these are worst - case bounds .",
    "we propose an adaptive approach that exploits properties of actual networks , in particular a skewed influence distribution , to achieve faster running times with the same guarantees .",
    "our use of the residual instances by skim  is the key for maintaining the accuracy of the greedy selection through the execution and providing with high probability , approximation ratio guarantees that nearly match those of exact greedy .",
    "section  [ binaryq : sec ] presents our influence oracles , which preprocess the input to compute combined reachability sketches for all nodes . for instances",
    "@xmath7 with @xmath23 nodes and @xmath24 edges , the sketches are built in @xmath25 total time .",
    "the influence of a set @xmath26 can then be approximated from the sketches of the nodes in @xmath1 .",
    "the oracle applies the union cardinality estimator of cohen and kaplan  @xcite to estimate the union of the influence sets of the seed nodes .",
    "the query runs in time @xmath27 and unbiasedly with a well - concentrated relative error of @xmath28 . while preprocessing depends on the number of instances , the sketch size and the approximation quality only depend on the sketch parameter @xmath15 .",
    "the asymptotic bounds we obtain are novel also from a theoretical perspective , and significantly improve the state of the art , even for influence maximization on a single  ( deterministic ) instance ( select a seed set in a directed graph with maximum reachable set ) .    section  [ experiments : sec ] presents an extensive experimental study . besides demonstrating the scalability of our algorithms on real - world networks , we compare skim  with existing approaches , including exact greedy ( when size allows ) , the state - of - the - art irie heuristic , and tim .",
    "we obtain ic models from networks by using the well - studied weighted and uniform  @xcite probabilities .",
    "our algorithms scale up to very large graphs with barely any compromise on quality over exact greedy , with theoretical guarantees . on instances generated by an ic model ,",
    "we achieve more than an order of magnitude speedup over the best greedy heuristics , which are designed specifically for this model . even for a fixed small seed set size ,",
    "skim  is significantly faster than tim .",
    "moreover , our algorithm is efficient and accurate enough to be executed exhaustively , producing a full permutation of the nodes for networks with billions of edges . for the first time",
    ", we provide the full ( approximate ) pareto front of influence versus seed set size .",
    "these relations showcase a basic property of the network , and the general pattern that a small fraction of nodes influences a large fraction of the network .",
    "in contrast , most previous studies we are aware of only considered seed sets with at most 50 nodes , revealing only a very restricted view of this relation .",
    "a _ propagation instance _ @xmath29 is specified by the edge set @xmath30",
    ". the _ influence _ of a set of nodes @xmath1 in instance @xmath31 is the number of nodes reachable from @xmath1 using the edges @xmath30 : @xmath32 where the predicate @xmath33 holds if @xmath34 or if there is a forward path from a node in @xmath1 to the node @xmath3 .",
    "our input is specified as a set @xmath35 of @xmath36 propagation instances @xmath37 on the same set of nodes .",
    "the influence of @xmath1 over all instances @xmath7 is the average single - instance influence : @xmath38 } { \\mathop{\\sf inf}}({g^{(i)}},s).\\ ] ] the set of propagation instances can be derived from cascade traces or generated by a probabilistic model .",
    "the input can also be specified as a probabilistic model , such as independent cascade ( ic )  @xcite , which defines a distribution @xmath39 over instances @xmath40 that share a set @xmath41 of nodes . in this case , the influence of @xmath39 is defined as the expectation @xmath42    we are interested in _ influence oracles _ and in _ influence maximization_. influence queries are specified by a seed set  @xmath43 and the goal is to compute ( or estimate ) the influence @xmath44 .",
    "influence oracles , after efficient preprocessing of the input , allow us to support very fast queries .",
    "influence maximization is the problem of finding a seed set  @xmath45 with maximum influence , where @xmath46 is given .",
    "we are interested in efficiently computing a seed set whose influence is close to the maximum one , as well as in computing a sequence of seeds so that each prefix has influence that is close to maximum for its size .",
    "at the heart of our approach are _ combined reachability sketches _ , which are summary structures @xmath47 that we associate with each node @xmath3 .",
    "the combined sketches can be defined with respect either to a set @xmath35 of @xmath36 instances or to a probabilistic model  @xmath39 .",
    "we first consider as input a set of @xmath36 instances .",
    "we define the _ reachability set _ of a node @xmath3 in instance @xmath31 as  @xmath48 where @xmath49 means that @xmath4 is reachable from  @xmath3 in @xmath31 . considering all instances , the _ combined reachability set _ is a set of node - instance pairs : @xmath50 the influence of a set of nodes @xmath1 on instances  @xmath7",
    "can thus be expressed as @xmath51 } \\bigl| \\bigcup_{u\\in s } r(g^{(i)},u ) \\bigr| = \\frac{1}{\\ell } \\bigl| \\bigcup_{u\\in s } r_u \\bigr|.\\ ] ] this is the average over the instances @xmath7 ( with @xmath52 $ ] ) of the number of nodes reachable from at least one node in @xmath1 .",
    "the combined reachability sketch of a node captures its reachability information _ across _ instances .",
    "the sketches we use are the bottom-@xmath15 min - hash sketches  @xcite @xmath53 of the combined reachability sets @xmath54 : we associate with each node - instance pair @xmath55 an independent random rank value  @xmath56 $ ] , where  @xmath57 $ ] is the uniform distribution on @xmath58 $ ] .",
    "the _ combined reachability sketch _ of @xmath3 is the set of the @xmath15 smallest rank values amongst  @xmath59 : @xmath60 where bottom-@xmath15 of a set is its subset consisting of the  @xmath15 smallest values . when there is a single instance ( @xmath61 ) the combined reachability sketches are the same as the reachability sketches of cohen  @xcite .",
    "we define the _ threshold rank _",
    "@xmath62 of each node @xmath3 as @xmath63 which is the @xmath15th lowest rank value in @xmath64 .",
    "( for a set @xmath65 of cardinality @xmath66 , we define @xmath67 . )",
    "therefore , when  @xmath68 we have  @xmath69 , and @xmath70 otherwise .",
    "the cardinality  @xmath71 can be estimated from @xmath47 using a bottom-@xmath15 cardinality estimator .",
    "the estimate is  @xmath72 if  @xmath70  ( i.e. , if @xmath73 ) and is  @xmath74 otherwise .",
    "this estimate has a coefficient of variation ( cv ) , which is the ratio of the standard deviation to the mean , that is never more than  @xmath75 and is well concentrated  @xcite . by applying chernoff bounds with @xmath76",
    ", we obtain that using  @xmath77 , the probability of having relative error larger than @xmath78 is at most  @xmath79 . therefore , we can be correct with high probability on estimating the influence of all nodes .",
    "[ structranks : sec ] instead of using ranks drawn from @xmath57 $ ] , we can work with integral permutation ranks with respect to a permutation on the @xmath80 node - instance pairs .",
    "we can also structure the permutation so that each sequence in positions @xmath81 to @xmath82 for integral @xmath83 has each node appear in exactly one pair .",
    "the associated instance with a node @xmath4 in chunk @xmath84 is randomly selected from instances @xmath85 for which the pair @xmath86 does not have a permutation rank of @xmath87 or less ( independently for each node ) .",
    "one can show that this can only improve estimation accuracy  @xcite .",
    "only the first  @xmath88 positions can be included in combined reachability sketches of nodes .",
    "when estimating influence , we can convert permutation ranks to random ranks using the exponential distribution  @xcite .",
    "we can also estimate cardinality of a subset of the @xmath89 elements directly from permutation ranks @xmath90 $ ] , using the unbiased estimator  @xmath91 , where the threshold @xmath92 is the @xmath15th smallest permutation rank .",
    "this estimator can be interpreted as setting aside the element with permutation rank @xmath92 , and estimating the fraction ( of the other @xmath93 elements ) that is in our set by the fraction of such elements with rank smaller than @xmath92 , which is  @xmath94 .",
    "we now define sketches with respect to a binary ic model @xmath39 , presented as a graph with probabilities @xmath13 associated with its edges .",
    "the influence of a set of nodes @xmath1 is @xmath95 the sketches we define for @xmath39 also contain at most @xmath15 rank values , but provide approximation guarantees with respect to .",
    "the sketches can be interpreted as the sketches computed for @xmath14 instances generated according to the model @xmath40 as @xmath96 .",
    "when doing so , at the limit , each unique rank value corresponds to a unique instance , so we do not need to explicitly represent `` instances . ''",
    "we work with structured permutation ranks ( section  [ permranks : sec ] ) .",
    "since it suffices to consider the first @xmath97 ranks , this conveniently removes the dependence of the rank representation on @xmath14 .",
    "we can similarly apply an estimator to the @xmath15th smallest rank @xmath98 to estimate influence : instead of estimating cardinality ( which goes to infinity with @xmath14 ) and dividing by @xmath14 using the estimator @xmath99 we take the limit as @xmath96 and estimate influence using @xmath100 .",
    "in this section we present our sketch - based influence maximization  ( skim ) algorithm .",
    "we first review greedy , the greedy algorithm for influence maximization ( working with @xmath14 instances ) presented by kempe et al .",
    "greedy is applied with respect to the influence objective @xmath44 , as defined in equation  .",
    "it starts with an empty seed set @xmath101 . in each iteration",
    ", it adds to  @xmath1 the node @xmath4 with maximum _ marginal gain _",
    ", @xmath102 this is the same as choosing @xmath4 maximizing @xmath103 .",
    "skim  approximates exact greedy by ensuring that at _ each iteration _ , with sufficiently high probability , or in expectation over iterations , the node we choose to add to the seed set has a marginal gain that is close to the maximum one . to do so",
    ", it suffices to compute sketches only to the point that the node with the maximum estimated marginal gain is revealed . to maintain accuracy , we maintain a residual problem and respective sketches .",
    "skim  constructs ( partial ) combined reachability sketches by adapting a construction of reachability sketches  @xcite : it processes node - instance pairs @xmath104 by increasing rank , performing a reverse reachability search in @xmath105 from  @xmath3 .",
    "the sketch @xmath53 of each visited node @xmath4 is augmented with the rank @xmath106 of the pair . for a given value of @xmath15 , the first node  @xmath3",
    "whose sketch reaches size @xmath15 is also the node with maximum estimated influence .",
    "this is because the bottom-@xmath15 cardinality estimate of a node depends only on the @xmath15th smallest rank in  @xmath47 , @xmath62 ( which is a complete sufficient statistic for cardinality estimation from the sketch  @xcite ) ; see equation  . for the node @xmath3 , @xmath62 is equal to the rank @xmath106 of the last processed pair @xmath104 . for other nodes",
    "@xmath4 with incomplete sketches , we know that @xmath107 , so their estimate is lower .",
    "sketch building is suspended once the node @xmath4 with maximum estimated influence is found .",
    "skimthen adds  @xmath4 to the seed set and generates a _",
    "problem , with @xmath4 and all node - instance pairs it covers removed from the instances  @xmath39 .",
    "the  ( partially computed ) sketches of each remaining node @xmath3 are updated using  @xmath108 , which deletes from the sketch the ranks of all covered node - instance pairs .",
    "the process of building sketches is then resumed on the residual problem , working with updated partial sketches and instances .",
    "we continue processing node - instance pairs in increasing rank order , starting from the first rank that exceeds @xmath109 and skipping pairs that are already covered",
    ".    @xmath110 hash map of node - instance pairs to nodes @xmath111 @xmath112    shuffle the @xmath80 node - instance pairs  @xmath104    we provide pseudocode for skim  as algorithm [ greedyssc : alg ] . instead of maintaining the actual partial sketches @xmath53 , the algorithm only keeps their cardinalities @xmath113 $ ] . to support correct and efficient updates of the sketches , we maintain an inverted index @xmath114 $ ] that lists , for each rank value",
    "@xmath106 we processed , all nodes @xmath4 such that @xmath115 . the entry for rank  @xmath106",
    "is created and populated when we perform a reverse reachability search from pair @xmath104 .",
    "the algorithm outputs the list of pairs @xmath116 , where @xmath117 is a permutation of the nodes according to the order they are selected into the seed set , and @xmath118 is the marginal influence of @xmath119 .",
    "the surprising property of our construction is that this whole iterative process is very efficient .",
    "if we run skim  with a fixed  @xmath120 , section  [ sec : analysis ] will show that we obtain the following worst - case performance guarantees :    [ skimtime : thm ] skim  runs in time @xmath121 , where @xmath122 .",
    "the permutation @xmath117 of nodes has the property that with probability @xmath123 , for all @xmath124 $ ] , the set of seed nodes @xmath125 , has @xmath126 .",
    "it is not hard to show that the influence of a node @xmath4 in the residual problem of iteration @xmath84 is equal to its marginal influence with respect to @xmath127 in the original problem .",
    "therefore ,  @xmath118 , which is the influence of @xmath119 in the residual problem of iteration @xmath84 , is the marginal influence of @xmath119 , with respect to  @xmath127 in the original problem .",
    "thus , by definition , for all @xmath124 $ ] and  @xmath125 , @xmath128 } i_i$ ] .",
    "we also show that the partial sketches correctly capture a component of the sketches computed for the residual problem :    at the end of an iteration selecting @xmath4 , each updated partial sketch @xmath47 is equal to the set of entries of the combined reachability sketch @xmath129 of @xmath3 in the residual problem that have rank value at most @xmath109 .",
    "the content of each sketch @xmath47 before computing the residual is clearly a superset of all reachable node - instance pairs  @xmath130 with rank @xmath131 in the residual problem .",
    "we can then verify that entries are removed from  @xmath47 only and for all covered node - instance pairs with  @xmath131 .",
    "we now analyze the running time of skim .",
    "all updates of the residual problem together take time linear in the size of  @xmath7 , since nodes and edges that are covered by the current seed set are removed once visited and never considered again .",
    "the remaining component of the computation is determined by the number of times ranks are inserted ( and removed ) from sketches . inserting a value to @xmath47",
    "involves a scan of all ( remaining ) incoming edges to @xmath3 in an instance .",
    "removals of ranks can be charged to insertions .",
    "so we need to bound the total number of rank insertions :    the expected total number of rank insertions at a particular node is @xmath132 .    consider a sketch @xmath53 .",
    "we can show , viewing the sketches as uniform samples of reaching pairs , that each rank value removal corresponds to cardinality  and hence influence  ( marginal gain)being reduced in expectation by a factor of @xmath133 .",
    "the initial influence is at most @xmath23 , so there are at most  @xmath134 insertions until the marginal influence is reduced below @xmath135 , at which point we do not need to consider the node .    the running time is dominated by the sum over nodes @xmath4 , of the number of times a rank",
    "is inserted to the sketch of  @xmath4 , times the in - degree of @xmath4 ( the maximum over instances ) . from the lemma",
    ", we obtain a bound of @xmath136 on the total number of insertions .",
    "thus , we obtain a bound of @xmath137 on the running time of the algorithm .      to obtain an approximation that is within @xmath138 with good probability",
    ", we can choose a fixed @xmath139 , for some constant  @xmath21 .",
    "the relative error of each influence estimate of a node in an iteration is at most @xmath78 with probability of at least  @xmath20 .",
    "since we use polynomially many estimates ( maximize influence among  @xmath23 nodes in each of at most @xmath23 iterations ) , all estimates are within a relative error of @xmath78 with probability that is polynomially close to @xmath140 .",
    "lastly , we bound the approximation ratio of the `` approximate '' greedy algorithm we work with , which uses seeds with close to maximum instead of maximum marginal gain :    [ approxgreedy : lemma ] with any submodular and monotone objective function , approximate greedy , which iteratively chooses a node with marginal gain that is at least @xmath141 of the maximum , has an approximation ratio of at least @xmath142 .",
    "the same claim holds in expectation when the selection is well concentrated , that is , its probability of being below @xmath143 times the maximum decreases exponentially with @xmath144 .",
    "the argument extends the analysis of exact greedy by nemhauser et al .",
    "@xcite . for any @xmath8 , and after selecting any set @xmath145 of seeds , the maximum marginal gain by adding a single node is always at least  @xmath146 of the maximum possible gain for @xmath8 nodes .",
    "when using the approximation , this is at least @xmath147 of the maximum possible gain .",
    "therefore , after approximate greedy selection of @xmath8 nodes , the influence is at least @xmath148 using the first order term of the taylor expansion .",
    "this worst - case analysis is too pessimistic , both for the approximation ratio and running time . in our experiments , we tested skim  with a fixed @xmath15 , and observed that the computed seed sets had influence that is much closer to the exact greedy selection than indicated by the worst - case bounds .",
    "the explanation is that the influence distribution on real inputs is heavy - tailed , with the vast majority of nodes having a much smaller influence than the one of maximum influence .",
    "one factor of @xmath149 in the worst - case running time is due to a `` union bound '' ensuring a relative error of @xmath78 for all nodes in all iterations , with high probability . with a heavy tail distribution",
    ", we can identify the maximum with a small error if we ensure a small error only on the few nodes that have influence close to the maximum .",
    "furthermore , when the maximum influence is separated out from other influence values , our approximate maximum is more likely to be the node with actual maximum influence .",
    "moreover , the estimation error over iterations averages out , so as the seed set gets larger we can work with lower accuracy and still guarantee good approximation .",
    "we propose incorporating error estimation that is _ adaptive _ rather than worst - case .",
    "this facilitates tighter confidence bounds on the estimation quality of our output .",
    "it also allows us to adjust the sketch parameter @xmath15 during computation in order to meet pre - specified accuracy and confidence levels .",
    "let the _ discrepancy _ in an iteration be the gap between the actual maximum and the marginal influence of the selected seed .",
    "we will bound the sum of discrepancies across iterations by maintaining a confidence distribution on this sum .",
    "the estimation uses two components .",
    "( i )  the exact marginal influence @xmath150 of the selected node in each iteration , as well as the sum  @xmath151 , which is the influence of our seed set .",
    "the value  @xmath150 is computed when generating the residual problem .",
    "( ii )  noting in each iteration the size of the second largest sketch  ( excluding the last processed rank ) . intuitively , if the second largest sketch is much smaller than the first one , it is more likely that the first one is the actual maximum .",
    "we bound the discrepancy in a single iteration using chernoff bounds .",
    "the probability that the sum of independent bernoulli trials falls below its expectation @xmath152 by more than  @xmath153 is @xmath154 < \\left ( \\frac{\\exp(-\\nu)}{(1-\\nu)^{(1-\\nu ) } } \\right)^\\mu.\\ ] ] we use this to bound the probability that the discrepancy exceeds  @xmath155 , where @xmath156 is the exact marginal gain of our selected seed node .",
    "we consider the second largest sketch size ,  @xmath157  ( the last rank of @xmath158 is not considered part of the sketch even if included ) .",
    "we use @xmath159 , @xmath160 , and @xmath161 in equation   to obtain a confidence level .    finally , to maintain an upper bound on the confidence - error distribution of the sum of discrepancies , we take a convolution , after each iteration , of the current distribution with the distribution of the current iteration .",
    "skim  can be adapted for higher concurrency by running the sketch - building phases in batches of ranks .",
    "we can also adapt it to process inputs presented as an ic model instead of as a set of instances .",
    "this yields a more efficient implementation than when generating a set of instances using simulations and running skim  on them . in ic - model skim ,",
    "the residual problem is a collection of partial models and sketch building is performed on the probabilistic model .",
    "we omit details due to space limitations .",
    "we now present an accurate and efficient oracle for binary influence , which is based on precomputing a combined reachability sketch ( as defined in section  [ sketch : sec ] ) for each node .",
    "we preprocess a set of @xmath14 instances @xmath35 using @xmath162 computation and working storage of @xmath163 per node .",
    "the preprocessing generates combined reachability sketches @xmath53 of size @xmath163 for each node @xmath164 .",
    "[ binaryinforacles : thm ] given a set @xmath165 of combined reachability sketches for @xmath39 with parameter @xmath15 , influence queries @xmath44 for a set @xmath1 of nodes can be estimated in @xmath166 time from the sketches @xmath167 .",
    "the estimate is nonnegative and unbiased , has cv at least  @xmath75 , and is well concentrated , meaning that the probability that the relative error exceeds @xmath168 decreases exponentially with @xmath144 .",
    "we next present the two components of our oracle : estimating the influence of @xmath1 from the sketches of the nodes in @xmath1 and efficiently computing all combined reachability sketches .",
    "we show how to use the combined reachability sketches of a set of nodes @xmath1 to estimate the influence of @xmath1 , as given in equation  . in graph terms",
    ", this means estimating the cardinality of the union @xmath169 from the sketches @xmath47 , with @xmath34 .",
    "the influence  @xmath44 is the union cardinality divided by the number of instances @xmath14 and , accordingly , is estimated using @xmath170 .",
    "our estimators use the threshold rank @xmath62 of each node @xmath3 ; see  equation  .    from the bottom-@xmath15 sketches of each set @xmath64 for @xmath34",
    "we can unbiasedly estimate the cardinality of the union @xmath169 .",
    "one way to do this is to compute the bottom-@xmath15 sketch of the union  @xcite , which has threshold value @xmath171 and apply the cardinality estimator @xmath172 .",
    "this would already conclude the proof of theorem [ binaryinforacles : thm ] .    in our implementation , we use a strictly better union cardinality estimator that uses all the ( at most @xmath173 ) values in the set of sketches instead of just the @xmath15th smallest : @xmath174 this estimator , proposed by cohen and kaplan  @xcite , can be computed from the @xmath175 sketches in time @xmath166 , by first sorting the @xmath175 sketches by decreasing threshold , and then identifying for each distinct rank value the threshold of the first sketch that contains it . when the sets @xmath64 are all the same , the estimate is the same as applying an estimator to the bottom-@xmath15 sketch on the union , but equation   can have up to a factor of @xmath176 lower cv when the sets @xmath64 are sufficiently disjoint . moreover",
    ", this estimator is an optimal sum estimator in that it minimizes variance given the information available in the sketches .",
    "we can also derive a permutation version of equation  .",
    "the simplest way is to treat the permutation rank @xmath92 as a uniform rank @xmath177 which is the probability that the rank of another node is smaller than @xmath92 .",
    "when there is a single instance @xmath29 , the combined sketches are simply reachability sketches  @xcite .",
    "reachability sketches @xmath178 for all nodes can be computed very efficiently , using at most @xmath179 edge traversals in total , where @xmath18 is the number of edges  @xcite .",
    "shuffle the @xmath80 node - instance pairs  @xmath104    algorithm [ reachsketch1:alg ] computes combined sketches by applying the pruned searches algorithm of cohen  @xcite on each instance @xmath180 , obtaining a sketch @xmath181 for each node , and combining the results .",
    "the combined sketch @xmath53 is obtained by taking the bottom-@xmath15 values in the union of the @xmath14 sketches , defined as  @xmath182    the algorithm runs in @xmath183 time . rather than storing all sets of sketches , we can compute and merge concurrently or sequentially , but after each step , take the bottom-@xmath15 values in the current bottom-@xmath15 set and the newly computed sketch for instance  @xmath105 : @xmath184 .",
    "therefore , the additional run time storage requirement for sketches is  @xmath185 .",
    "this gives us the worst - case bounds on the computation stated in theorem  [ binaryinforacles : thm ] .",
    "we implemented our algorithms in c++ using visual studio 2013 with full optimization .",
    "all experiments were run on a machine with two intel xeon e5 - 2690 cpus and 384gib of ddr3 - 1066 ram , running windows 2008r2 server .",
    "each cpu has 8 cores  ( 2.90ghz , 8@xmath18664kib l1 , 8  @xmath186256kib , and 20mib l3 cache ) , but all runs are sequential for consistency .",
    "we ran our experiments on benchmark networks available as part of the snap  @xcite and webgraph  @xcite projects .",
    "more specifically , we test _ social _  ( , , , , , , , ) , _ collaboration _  ( ) , and web  ( , ) networks . is obtained from   by reversing all arcs  ( influence follows the reverse direction of links ) .",
    "kempe et al .",
    "@xcite proposed two natural ways of associating probabilities with edges in the binary ic model : the _ uniform _ scheme assigns a constant probability  @xmath187 to each directed edge  ( they used  @xmath188 and  @xmath189 ) , whereas in the _ weighted cascade _  ( wc ) scheme the probability is the inverse of the degree of the head node  ( making the probability that a node is influenced less dependent on its number of neighbors ) .",
    "we consider the wc scheme by default , but we will also experiment with the uniform scheme  ( un ) .",
    "these two schemes are the most commonly tested in previous studies of scalability  @xcite .      [ cols= \" < , > , > , > , > , > , > , > , > , > , > , > \" , ]     figure  [ fig : oracleerror ] shows in detail how the error of the estimator  ( @xmath190 axis ) decreases when the seed set size increases  ( @xmath191 axis ) . to better evaluate the performance of estimating the _ union _ of several reachability sets , we use the following _ neighborhood generator _ for queries",
    ": for each query , it first picks a node  @xmath3 at random with probability proportional to its degree . from",
    "@xmath3 it exhaustively grows a bfs of the smallest depth  @xmath192 such that the tree contains at least  @xmath8 nodes .",
    "the nodes for the seed set are then uniformly sampled from this tree . with this generator",
    ", we expect the reachability sets of seed nodes to highly overlap .",
    "looking at the figure , we observe that the estimation error of our oracle decreases rapidly for increasing  @xmath8 .",
    "also , running queries from the neighborhood generator  ( right ) compared to the uniform one  ( left ) , has almost no effect on the estimation error ; for 50 seed nodes it is even better on many instances .",
    ", title=\"fig:\"],title=\"fig : \" ]    finally , figure  [ fig : ell ]  ( right ) reports the performance of the oracle for fixed instances on the general ic model .",
    "we vary the number  @xmath14 of instances generated by simulations when building the oracle , but compute the error on a different set of  8192 instances . since our oracle implementation is optimized for fixed instances , we see a higher error with  @xmath193 .",
    "we can also see that the error decreases with the number of simulations .",
    "we conclude that for an ic model oracle , it is beneficial to construct sketches that have approximation guarantees with respect to the ic model itself  ( cf .",
    "section  [ icsketches : sec ] ) rather than work with simulations .",
    "we presented highly scalable algorithms for binary influence computation .",
    "skim  is a sketch - space implementation of the greedy influence maximization algorithm that scales it by several orders of magnitude , to graphs with billions of edges .",
    "skim  computes a sequence of nodes such that each prefix has a probabilistic guarantee on approximation quality that is close to that of greedy .",
    "we also presented sketch - based influence oracles , which after a near - linear processing of the instances can estimate influence queries in time proportional to the number of seeds .",
    "our experimental study focused on instances generated by an ic model , since the fastest algorithms we compared with only apply in this model .",
    "our experiments revealed that skim  is accurate and faster than other algorithms by one to two order of magnitude .    in future work , we plan to develop a skim - like algorithm for _ timed influence _ , where edges have lengths that are interpreted as transition times and we consider both the speed and scope of infection @xcite .",
    "we also plan to use sketches to efficiently estimate the jaccard similarity of the influence sets of two nodes , which we believe to be an effective similarity measure  @xcite ."
  ],
  "abstract_text": [
    "<S> propagation of contagion through networks is a fundamental process . </S>",
    "<S> it is used to model the spread of information , influence , or a viral infection . </S>",
    "<S> diffusion patterns can be specified by a probabilistic model , such as independent cascade ( ic ) , or captured by a set of representative traces .    </S>",
    "<S> basic computational problems in the study of diffusion are _ influence queries _  ( determining the potency of a specified _ seed set _ of nodes ) and _ influence maximization _  ( identifying the most influential seed set of a given size ) . answering </S>",
    "<S> each influence query involves many edge traversals , and does not scale when there are many queries on very large graphs . </S>",
    "<S> the gold standard for influence maximization is the greedy algorithm , which iteratively adds to the seed set a node maximizing the marginal gain in influence . </S>",
    "<S> greedy has a guaranteed approximation ratio of at least  @xmath0 and actually produces a sequence of nodes , with each prefix having approximation guarantee with respect to the same - size optimum . </S>",
    "<S> since greedy does not scale well beyond a few million edges , for larger inputs one must currently use either heuristics or alternative algorithms designed for a pre - specified small seed set size .    </S>",
    "<S> we develop a novel sketch - based design for influence computation . </S>",
    "<S> our greedy sketch - based influence maximization  ( skim ) algorithm scales to graphs with billions of edges , with one to two orders of magnitude speedup over the best greedy methods . </S>",
    "<S> it still has a guaranteed approximation ratio , and in practice its quality nearly matches that of exact greedy . </S>",
    "<S> we also present _ influence oracles _ , which use linear - time preprocessing to generate a small sketch for each node , allowing the influence of any seed set to be quickly answered from the sketches of its nodes . </S>"
  ]
}