{
  "article_text": [
    "face recognition is one of the classical problems in computer vision . given a natural image that may contain a human face , it has been known that the appearance of the face image can be easily affected by many image nuisances , including background illumination , pose , and facial corruption / disguise such as makeup , beard , and glasses .",
    "therefore , to develop a _ robust _ face recognition system whose performance can be comparable to or even exceed that of human vision , the computer system needs to address at least the following three closely related problems : first , it needs to effectively model the change of illumination on the human face .",
    "second , it needs to align the pose of the face .",
    "third , it needs to tolerance the corruption of facial features that leads to potential gross pixel error against the gallery images .    in the literature ,",
    "many well - known solutions have been studied to tackle these problems @xcite , although a complete review of the field is outside the scope of this paper .",
    "more recently , a new face recognition framework called _ sparse - representation based classification _ ( src ) was proposed @xcite , which can successfully address most of the above problems .",
    "the framework is built on a subspace illumination model characterizing the distribution of a corruption - free face image sample ( stacked in vector form ) under a fixed pose , one subspace model per subject class @xcite .",
    "when an unknown query image is jointly represented by all the subspace models , only a small subset of these subspace coefficients need to be nonzero , which would primarily correspond to the subspace model of the true subject .",
    "therefore , by optimizing the sparsity of such an overcomplete linear representation , the dominant nonzero coefficients indicate the identity of the query image . in the case of image corruption ,",
    "since the corruption typically only affects a sparse set of pixel values , one can concurrently optimize a sparse error term in the image space to compensate for the corrupted pixel values .    in practice",
    ", a face image may appear at any image location with random background .",
    "therefore , a face detection and registration step is typically first used to detect the face image .",
    "most of the methods in face detection would learn a class of local image features / patches that are sensitive to the appearance of key facial features @xcite . using either an active shape model @xcite or an active appearance model @xcite , the location of the face",
    "can be detected even when the expression of the face is not neutral or some facial features are occluded @xcite .",
    "however , using these face registration algorithms _ alone _ is not sufficient to align a query image to gallery images in src .",
    "the main reasons are two - fold : first , except for some fast detectors such as viola - jones @xcite , more sophisticated detectors are expensive to run and require learning prior distribution of the shape model from meticulously hand - labeled gallery images . more importantly",
    ", these detectors would register the pixel values of the query image with respect to the _ average _ shape model learned from all the gallery images , but they typically can not align the pixel values of the query image to the gallery images for the purpose of recognition , as required in src .",
    "following the sparse representation framework in @xcite , we propose a novel algorithm to effectively extend src for face alignment and recognition in the small - sample - set scenario .",
    "we observe that in addition to the aforementioned image nuisances , one of the outstanding challenges in face recognition is indeed the small sample set problem .",
    "for instance , in many biometric , surveillance , and internet applications , there may be only a few gallery examples that are collected for a subject of interest , and the subject may not be able to undergo a comprehensive image collection session in a laboratory .",
    "unfortunately , most of the existing src - based alignment and recognition algorithms would fail in such scenarios . for starters",
    ", the original src algorithm @xcite assumes a plurality of gallery samples from each class must sufficiently span its illumination subspace .",
    "the algorithm performs poorly in the single sample regime , as we will later shown in our experiment . in @xcite , in order to guarantee that the gallery images contain sufficient illumination patterns , the test subjects must further go through a nontrivial passport - style image collection process in a dark room in order to be entered into the gallery database .",
    "more recently , another development in the src framework is simultaneous face alignment and recognition methods @xcite .",
    "nevertheless , these methods did not go beyond the basic assumption used in src and other prior art that the face illumination model is measured by multiple gallery samples for each class .",
    "furthermore , as shown in @xcite , robust face alignment and recognition can be solved separately as a two - step process , as long as the recovered image transformation can be carried over from the alignment stage to the recognition stage .",
    "therefore , simultaneous face alignment and recognition could make the already expensive sparse optimization problem even more difficult to solve .",
    "single - sample face alignment and recognition represents an important step towards practical face recognition solutions using images collected in the wild or on the internet .",
    "we contend that the problem can be solved quite effectively by an elegant algorithm .",
    "the key observation is that one sample per class mainly deprives the algorithm of an illumination subspace model for individual classes .",
    "we show that an _ illumination dictionary _ can be learned from additional subject classes to compensate for the lack of the illumination information in the gallery set .    due to the fact that the variations of human faces are usually smaller than illumination changes of the same face , we propose a dictionary learning method to decompose the face images as vectors into two components : a low - rank matrix encodes the subject identities while a sparsely - used matrix ( or dictionary ) represents the possible illumination variations .",
    "the auxiliary illumination images can be selected outside the set of gallery subjects . since most of the information associated with the subject identities",
    "is contained in the rank - constrained matrix , the sparsely - used illumination dictionary is expected to be subject - invariant .",
    "finally , we show that the other image nuisances , including pose variation and image corruption , can be readily corrected by a single gallery image of _ arbitrary illumination condition _ combined with the illumination dictionary .",
    "the algorithm also does not need to know the information of any possible facial corruption for the algorithm to be robust .",
    "the new method is called _ sparse illumination learning and transfer _ ( silt ) .",
    "similarly , the illumination dictionary defined in the method will be referred to as the silt dictionary .",
    "preliminary results of this work were first reported in our conference paper @xcite . to the best of our knowledge ,",
    "the paper @xcite was the first to propose a solution to perform small - sample - set facial alignment and recognition via a sparse illumination transfer .",
    "however , the construction of the illumination dictionary in @xcite was largely ad hoc via a simple concatenation of the auxiliary illumination samples .",
    "it was suggested in @xcite that a sparse illumination representation can be found to compensate for the missing illumination model in single gallery images . in this paper",
    ", we propose a new illumination dictionary model to specifically learn the dictionary from the auxiliary images .",
    "we also study efficient optimization algorithms to solve the dictionary learning problem numerically . finally ,",
    "more comprehensive experiments are conducted , especially on the case when the number of available illumination learning subjects grows from one to many . in the largest scale , we employ all the 38 available subjects in the extended yaleb database @xcite as the auxiliary illumination samples .",
    "the new results show improved recognition results than those in @xcite .",
    "in terms of the algorithm complexity , learning the silt dictionary contains two successive procedures ; one is principal component analysis ( pca)-like solution while the other involves solving a sequence of linear programs .",
    "the leaning algorithm is almost parameter - free , only dependent on the dictionary size .",
    "applying the silt dictionary in the alignment and recognition stages potentially can significantly improve the speed of src - type algorithms , because a sparse optimization solver such as those in @xcite is now faced with much smaller linear systems that only involves a single sample per class plus a small learned illumination dictionary .",
    "this paper bears resemblance to the work called extended src @xcite , whereby an intraclass variant dictionary was similarly added to be a part of the src objective function for recognition .",
    "our work differs from @xcite in that the proposed silt dictionary is automatically learned from a selection of independent subject(s ) , whereas in @xcite , the dictionary is simply hand - crafted . yet ,",
    "the subject classes used to learn the silt dictionary is also impartial to the gallery classes .",
    "furthermore , by transferring both the pose and illumination from the alignment stage to the recognition stage , our algorithm can handle insufficient illumination and misalignment at the same time , and allows for the single reference images to have arbitrary illumination conditions .",
    "finally , our algorithm is also robust to moderate amounts of image pixel corruption , even though we do not need to include any image corruption examples in the silt dictionary , while in @xcite the intraclass variant dictionary uses both normal and corrupted face samples .",
    "we also compare our performance with @xcite in section [ sec : experiment ] .",
    "more recently , the problem of single - sample face recognition was considered in another work @xcite , called _ sparse variation dictionary learning _ ( svdl ) .",
    "the work proposed an alternative method to learn a sparse variation dictionary that amends the src framework with single samples .",
    "the main difference between the two dictionary learning algorithms is that in svdl , both the illumination learning images and the gallery images are involved in the dictionary learning algorithm .",
    "the authors argued that jointly considering the illumination samples and the gallery samples helps to generate a very compact , adaptive dictionary that exploits the correlation between the illumination learning set and the gallery set . while in this paper , the learning of the silt dictionary is independent of the gallery set and the alignment and recognition tasks .",
    "therefore , the learned dictionary can be estimated off - line and without costing any computational penalty when the gallery images are presented .",
    "furthermore , the silt framework addresses both face alignment and recognition problems , and is capable of transferring both the illumination _ and _ pose information from the alignment stage to the recognition stage .",
    "in contrast , svdl in @xcite only concerns face recognition with a frontal position , and its complexity would grow substantially when its adaptive dictionary needs to be re - computed under varying poses of the query image .",
    "we will show in section [ sec : experiment ] that , without considering this pose - related computational penalty for svdl , the silt framework outperforms svdl in both recognition accuracy and robustness to pixel corruption .",
    "in this section , we first briefly review the src framework . assume a face image @xmath0 in grayscale can be written in vector form by stacking its pixels . given @xmath1 subject classes ,",
    "assume @xmath2 well - aligned gallery images @xmath3\\in{\\mathbb{r}}^{d\\times n_i}$ ] of the same dimension as @xmath4 are sampled for the @xmath5-th class under the frontal position and various illumination conditions .",
    "these gallery images are further aligned in terms of the coordinates of some salient facial features , e.g. , eye corners and/or mouth corners . for brevity",
    ", the gallery images under such conditions are said to be in the _",
    "neutral position_. furthermore , we do not explicitly model the variation of facial expression in this paper . based on the illumination subspace assumption ,",
    "if @xmath4 belongs to the @xmath5-th class , then @xmath4 lies in the low - dimensional subspace spanned by the gallery images in @xmath6 , namely , @xmath7    when the query image @xmath4 is captured in practice , it may contain an unknown 3d pose that is different from the neutral position . in image registration literature @xcite ,",
    "the effect of the 3d pose can be modeled as an image transformation as @xmath8 , where @xmath9 is a finite - dimensional group of transformations , such as translation , similarity transform , affine transform , and homography .",
    "the goal of face alignment is to recover the transformation @xmath10 , such that the unwarped query image @xmath11 in the neutral position remains in the same illumination subspace : @xmath12 .    in robust face alignment , the issue is often further exacerbated by the cascade of complex illumination patterns and moderate image pixel corruption and occlusion . in the src framework @xcite ,",
    "the combined effect of image misalignment and sparse corruption is modeled by @xmath13 where the alignment is achieved on a per - class basis for each @xmath6 , and @xmath14 is the sparse alignment error .",
    "after linearizing the potentially nonlinear image transformation function @xmath10 , can be solved iteratively by a standard @xmath15-minimization solver . in @xcite , it was shown that the alignment based on can tolerate translation shift up to 20% of the between - eye distance and up to @xmath16 in - plane rotation , which is typically sufficient to compensate moderate misalignment caused by a good face detector .",
    "once the optimal transformation @xmath17 is recovered for each class @xmath5 , the transformation is carried over to the recognition algorithm , where the gallery images in each @xmath6 are transformed by @xmath18 to align with the query image @xmath4 .",
    "finally , a global sparse representation @xmath19 with respect to the transformed gallery images is sought by solving the following sparse optimization problem : @xmath20\\xx + \\ee .",
    "\\end{array } \\label{eq : cab}\\ ] ] one can further show that when the correlation of the face samples in @xmath21 is sufficiently tight in the high - dimensional image space , solving via @xmath15-minimization guarantees to recover both the sparse coefficients @xmath19 and very dense ( sparsity @xmath22 ) randomly signed error @xmath23 @xcite .",
    "in this section , we propose a novel face alignment algorithm that is effective even when a very small number of training images are provided per class , called _ sparse illumination learning and transfer _ ( silt ) . in the extreme case",
    ", we specifically consider the _ single - sample face alignment problem _ where only one training image @xmath24 of _ arbitrary illumination _ is available from class @xmath5 .",
    "the same algorithm easily extends to the case when multiple training images are provided . in section [ sec :",
    "recognition ] , we will show how to integrate the estimation of silt in robust single - sample face recognition . in section [ sec : experiment",
    "] , we further show in our experiment that silt is also complementary and useful in other existing face recognition methods as an image pre - processing step .      to mitigate the scarcity of the training images , something has to give to recover the missing illumination model under which the image appearance of a human face can be affected .",
    "motivated by the idea of transfer learning @xcite , we stipulate that one can obtain the illumination information for both alignment _ and _ recognition from a set of additional subject classes , called the _",
    "illumination dictionary_. the auxiliary face images for learning the illumination dictionary have the same frontal pose as the gallery images , and can be collected offline and different from the query classes @xmath25 $ ] . in other words ,",
    "no matter how scarce the gallery images are , one can always obtain a potentially large set of auxiliary face images from other unrelated subjects who may have similar face shapes as the query subjects and may provide sufficient illumination examples .",
    "suppose that we are given face images of sufficient illumination patterns for additional @xmath26 subjects @xmath27 \\in { \\mathbb{r}}^{d\\times(np)}$ ] , and assume without loss of generality that each subject contains @xmath28 face images , i.e. , @xmath29 for subject @xmath5 , and each image has the same dimension as the gallery images .",
    "our hope is that @xmath30 can be expressed by a superposition of a rank - constrained matrix and a sparsely - used matrix : @xmath31 where @xmath32 is a matrix where each column vector represents a subject class from 1 to @xmath33 , @xmath34 , @xmath35 is a learned illumination dictionary , and @xmath36 is a sparse matrix . here , @xmath37 denotes the kronecker product , and hence the first term @xmath38 in is clearly low rank .",
    "we also assume that @xmath39 for @xmath40 to prevent model over - fitting .",
    "one can better understand the roles of the different matrices in as follows : @xmath41 describes the inter - class variation associated with the @xmath33 different subject identifies , @xmath40 describes the common intra - class variation associated with the illumination change , and @xmath42 operates like a sparse representation of illumination patterns that compensate the singular subject images in @xmath43 . considering other possible face variations , we may further add a small error term @xmath44 in as @xmath45    to encourage sparsity of @xmath42 and minimum fitting error @xmath46 , we formulate the illumination dictionary learning problem as an optimization problem @xmath47 where @xmath48 denotes the matrix @xmath49-norm and @xmath50 is the frobenius norm .",
    "note that in the src framework such as and , the image corruption has been traditionally estimated by minimizing a sparse error term @xmath51 .",
    "the reason we can model a dense error term using @xmath52 is that the selection of the auxiliary illumination examples is conducted manually and offline .",
    "therefore , it is reasonable to assume that the face images in @xmath30 do not contain significant facial disguise and pixel corruption .",
    "this assumption also simplifies the complexity of the optimization problem in .",
    "solving is a challenging problem , mainly because it has a non - convex objective function _ and _ a non - convex , non - linear constraint . in optimization ,",
    "the standard procedure to relax the non - convex objective function is to find a good convex surrogate .",
    "however , the second problem about how to handle the non - convex , non - linear constraint is less understood .",
    "although the well - known alternating direction method @xcite can be applied , the solution may not converge to the global optimum .    in the following ,",
    "we will reformulate the constraint in and propose a successive optimization algorithm .",
    "the algorithm can be shown numerically to recover @xmath53 exactly if @xmath42 is sufficiently sparse .",
    "first , we reformulate the constraint of as follows : @xmath54 where @xmath55 measures the possible ambiguity between the first two terms of the right hand side , and @xmath56 is a non - singular transformation such that @xmath57 , where @xmath58 is the identity matrix of proper dimension .    from , we have @xmath59 hence , problem can be written as : @xmath60.\\ ] ] the new formulation in allows us to apply a successive optimization strategy . in this case , successive optimization exploits the successive structure of to recursively approximate problem .",
    "although it is a heuristic , but it can have promising performance in practice .    more specifically , we approximate problem by decoupling it into two successively processed stages : @xmath61 suppose that @xmath62 are found , then the solutions of the other variables in problem are given by    [ eq : post_process]@xmath63    in what follows , we describe how to solve problem and .",
    "problem is a difficult non - convex problem .",
    "fortunately we can prove that it has a closed - form solution , as stated in the following theorem :    suppose that @xmath64 $ ] where @xmath65 is the training set associated with subject @xmath5 , and assume each subject has @xmath28 images .",
    "problem has the following closed - form solution : @xmath66 , \\label{eq : av2}\\\\ \\overline{{c}}^ * & = & [ ~ \\boldsymbol{q}_1 ( { u}{u}^t ) , \\boldsymbol{q}_2 ( { u}{u}^t ) , \\hdots , \\boldsymbol{q}_{k } ( { u}{u}^t ) ~ ] , \\label{eq : b_bar}\\\\ { h}^ * & = & ( \\overline{{c}}^*)^t({d } - \\overline{{v}}^*\\otimes{\\mathbf 1}^t),\\\\ { e}^ * & = & { d } - \\overline{{v}}^*\\otimes{\\mathbf 1}^t - \\overline{{c}}^*{h}^*. \\end{array}\\end{aligned}\\ ] ] where @xmath67 and @xmath68 is the eigenvector associated with the @xmath5th principal eigenvalue of the square matrix @xmath69 . [ thm ]    the proof of theorem [ thm ] is given in appendix .",
    "to better understand the closed - form solution , we can see that each column of @xmath70 represents the mean vector of a training set @xmath65 .",
    "therefore , @xmath71 represents a normalized data matrix when the mean vectors are removed from @xmath30 . since the column vectors of @xmath72 are the first @xmath73 orthonomal basis vectors that maximizes the inter - class variance , it can be thought of as a variant of principal component analysis ( pca ) .",
    "we now turn our attention to problem , which is more difficult than .",
    "the problem is very similar to a conventional sparse dictionary learning problem , where the goal is to learn a basis that most compactly represents the face images @xmath30 . while many heuristics have been proposed before ( _ e.g. _ , see @xcite and the references therein ) , because of its combinatorial nature , this problem is difficult to solve efficiently .",
    "our solution of is largely inspired by a recent paper @xcite , which shows that the inverse problem can be well - defined , and there exist efficient and provably correct algorithms to solve the inverse problem .",
    "the only difference lies in that our problem has an additional unknown matrix @xmath74 here .",
    "hence , we propose to solve problem by solving the following linear programs sequentially ; that is , for @xmath5 from 1 to @xmath73 , we solve @xmath75where @xmath76 and @xmath77 denote the estimates of the @xmath5th row vector of @xmath78 and @xmath74 , respectively , @xmath79\\in\\mathbb{r}^{k\\times ( i-1)}$ ] denotes a matrix comprising previously found solutions , @xmath80 is the orthogonal complement projector of @xmath81 , and @xmath82 is an analysis filter .",
    "note that the constraint in is to ensure @xmath83 , and so the rank of the final solution @xmath84 is equal to @xmath73 .",
    "the intuition behind is to use a sequence of @xmath15-minimization ( or linear programs ) to approximate the non - convex @xmath49 minimization problem .",
    "while the problem addressed in @xcite slightly differs from , their theoretical results may suggest us how to choose the analysis filter @xmath85 . applying their results to our problem , we select @xmath85 to be a column of @xmath86 and choose the solution to be the one that results in minimum cardinality .",
    "the details of the successive optimization for problem are summarized in algorithm [ algorithm_sop ] . here ,",
    "@xmath87_i$ ] denotes the @xmath5th column of a matrix .",
    "note that the proposed method only has the number of atoms @xmath73 to tune .",
    "therefore , it generates consistent results for a given dataset and @xmath73 .",
    "* initialize * @xmath88 and @xmath89 .",
    "compute @xmath70 , @xmath90 , @xmath86 , and @xmath91 by .",
    "update @xmath92 .",
    "compute @xmath93 , @xmath94 , @xmath95 by .    to illustrate the illumination dictionary model in",
    ", we conduct a simple experiment on extended yaleb database @xcite .",
    "only the frontal images of the 38 subjects in the database are included .",
    "figure [ fig : dictoinaries ] illustrates the learned identity vectors of the first 10 subjects in @xmath43 and the first 10 atoms in the illumination dictionary @xmath40 .    in the next section",
    ", we will propose an extension of the src framework using silt , which is aimed at addressing both alignment and recognition with small gallery samples .",
    "in particular , among the estimates from algorithm [ algorithm_sop ] , only the illumination dictionary @xmath40 will be used in the subsequent sparse illumination transfer process . we should emphasize here that in the literature , there are several other algorithms that deal with illumination transfer functions , such as the quotient image @xcite and edge - preserving filters @xcite .",
    "the focus of this paper is to learn an illumination dictionary for single - sample alignment and recognition in the src framework .",
    "the approach of adding an auxiliary dictionary to help recognition was also considered in @xcite",
    ". however , most of these illumination transfer methods are only for recognition but not alignment .",
    "without loss of generality , we assume each gallery class only contains one sample @xmath96 .",
    "it is important to note that in our problem setting , each @xmath24 can be sampled from an arbitrary lighting condition , and we do not assume the gallery images to share the same illumination pattern . in the alignment stage , given a query image @xmath4 , we estimate an image transformation @xmath17 applied in the 2-d image coordinates of @xmath4 to align it with @xmath24 . clearly , if one were to directly apply the standard src solution , the so - defined alignment error @xmath97 may not be sparse .",
    "more specifically , the different illumination conditions between @xmath4 and @xmath24 may introduce a _ dense _ alignment error even when the two images are perfectly aligned .",
    "although an alignment error can still be minimized with respect to an @xmath15-norm or @xmath98-norm penalty , the algorithm would lose its robustness when concurrently handling sparse image corruption and facial disguise .",
    "the silt algorithm mitigates the problem by using the sparsely - used illumination dictionary @xmath40 to compensate the illumination difference between @xmath4 and @xmath24 .",
    "more specifically , silt alignment solves the following problem : @xmath99 in , @xmath100 is a parameter that balances the weight of @xmath101 and @xmath23 , which can be chosen empirically . in our experiment",
    ", we find @xmath102 generally leads to good performance for both uncorrupted and corrupted cases .",
    "@xmath40 is the silt dictionary learned in algorithm [ algorithm_sop ] .",
    "finally , the objective function can be solved efficiently using @xmath15-minimization techniques such as those discussed in @xcite .",
    "figure [ fig : alignment ] shows two examples of the silt alignment results .",
    "next , we propose a novel face recognition algorithm that extends the src framework to the single - sample case .",
    "similar to the above alignment algorithm , the algorithm also applies trivially when multiple gallery samples are available per class .    in the previous src framework ,",
    "once the transformation @xmath17 is recovered for each class @xmath6 , the transformation is carried over to the recognition stage , where the gallery images in @xmath6 are transformed by @xmath18 to align with the query image @xmath4 . in the single - sample case",
    ", the sparse representation model in will not be satisfied due to two reasons .",
    "first , as the @xmath21 matrix only contains one sample per class , even when @xmath4 is a valid query image with no gross image corruption or facial disguise , the equality constraint @xmath103 typically will not hold true . as a result",
    ", it becomes difficult to classify @xmath4 based on the sparse coefficients of @xmath19 as suggested in src .",
    "second , as the illumination condition of @xmath4 may not be fully expressed by the linear combination @xmath104 , it causes the error @xmath105 to be dense , mostly to compensate the difference in their illumination conditions .",
    "the problem reduces the effectiveness of src to compensate gross image corruption by minimizing the sparsity of @xmath23 .    in the silt framework , we have seen in that if an auxiliary illumination dictionary @xmath40 is provided , it can be used to compensate the missing illumination information in single gallery images @xmath24 .",
    "therefore , in the recognition stage , one may consider transfer both the illumination information @xmath106 and alignment @xmath17 to compensate each @xmath24 : @xmath107 the collection of all the warped gallery images is defined as @xmath108 $ ] .",
    "unfortunately , a careful examination of this proposal reveals a rather subtle issue that prevents us to directly apply the warped gallery images @xmath109 in the recognition stage .",
    "the problem lies in the fact that the illumination dictionary @xmath40 is learned from the auxiliary face images with the frontal position that are typically cropped and normalized . as a result",
    ", the atoms of the dictionary @xmath40 can not be simply warped by an image transformation @xmath18 . an exact solution to update the pose of the illumination dictionary",
    "@xmath40 would require the algorithm to first warp the auxiliary images themselves in @xmath30 , and then retrain the illumination dictionary @xmath110 for each transformation @xmath17 .",
    "clearly , this task is prohibitively expensive . in this paper .",
    "therefore , the problem of warping a learned dictionary was mitigated . ]    in addition , applying that warps auxiliary images and gallery images to the query image sometimes can be undesirable in practice .",
    "figure [ fig : recognition - cropping ] illustrates the problem . in many cases , the auxiliary and gallery images are provided only within a cropped face region .",
    "therefore , any pixel outside the original bounding box may not have a valid value .",
    "in some other cases , even when those pixels are available , still the original pixels within the training bounding box are typically well chosen to best represent the appearance of the face . as a result ,",
    "using pixel values outside the bounding box may negatively affect the accuracy of the recognition",
    ".     may result in copying some pixel values that are out of bound .",
    "the values of these out - of - bound pixels are not available in . in this example , the pixel with the coordinates @xmath111 after transformation @xmath18 remains within the original bounding box in green color , but @xmath112 is outside the original bounding box .",
    "pixel coordinates such as @xmath113 should be removed from the support set @xmath114 . ]    in this paper , we propose a more efficient solution to address the problem .",
    "the key idea is to constrain the sparse representation - based classification on a subset of pixels whose pixel values remain valid after the alignment compensation .    without loss of generality , we assume each auxiliary image in @xmath30 is of dimension @xmath115 , i.e. , @xmath116 . in the silt recognition step , given an estimated transformation from the alignment stage @xmath18 for the gallery image @xmath24 , we apply the transformation @xmath18 on each pixel within the face image @xmath117\\times[1,h]$ ] .",
    "define the support set for the transformation @xmath18 : @xmath118\\times[1,h ]   \\}.\\ ] ]    given all the collection of all the transformations @xmath119 , we define the total support set @xmath114 as the intersection @xmath120 that is , each element in @xmath114 corresponds to a valid pixel in the auxiliary images and @xmath40 after the transformations @xmath18 are applied for all @xmath121 .",
    "the projection of an image in vector form @xmath4 onto a support set @xmath114 is denoted as @xmath122 .",
    "the effect of applying a mask defined by a support set @xmath114 is illustrated in figure [ fig : silt - effect ] .",
    "initially , the input query images in the first column and the gallery images of the same subjects have very different illumination conditions and poses . in the third column ,",
    "an illumination transfer pattern is estimated for each gallery image .",
    "for example , in the second subject example , the left side of @xmath4 is brighter than that of @xmath123 .",
    "this is reflected by having a brighter illumination pattern in its @xmath124 .",
    "finally , the gallery images are further warped based on the estimated poses @xmath125 , and the masks of their support sets @xmath114 are applied to both the warped gallery images @xmath126 and the query images @xmath127 .",
    "we can see that , compared to the input image pairs @xmath128 , the processed image pairs in the silt algorithm @xmath129 have closer illumination conditions and similar poses .     and applying a mask @xmath114 on both the query image @xmath4 and the warped gallery image @xmath130 . * ( a)*. query images @xmath4 . * ( b)*. gallery images @xmath123 .",
    "* ( c)*. illumination transfer information @xmath124 . *",
    "( d)*. warped gallery images @xmath130 under a mask @xmath114 . *",
    "( e)*. applying the same masks @xmath114 on @xmath4 . ]",
    "the remaining silt algorithm involves solving a sparse representation @xmath19 in the presence of a possible sparse error @xmath23 constrained on the support set @xmath114 , namely , @xmath131 where the operation @xmath132 applies pixel selection on each column of @xmath109 based on the support set @xmath114 .",
    "similar to the previous formulations , the parameter @xmath133 is chosen empirically via cross validation .",
    "using the sparse representation @xmath19 in , the final decision rule to classify @xmath4 can be simplified from the original src algorithm in @xcite where the reconstruction residual was used . in silt , since there is only one sample per each subject class in @xmath21 , the class with the largest coefficient magnitude in @xmath19 is the estimated class of the query image @xmath4 .",
    "we note that this simplified strategy does not compromise the generality of the silt method , as one can still estimate the objective function of the reconstruction residual when each class contains one or more gallery images .",
    "figure [ fig : recognition ] shows an example of the silt recognition and its estimated sparse representation .",
    "before we move on to examine the performance of the new recognition algorithm , one may question the efficacy of enforcing a sparse representation in the constraint . the question may arise because in the original src framework",
    ", the data matrix @xmath134 $ ] is a collection of highly correlated image samples that span the @xmath1 illumination subspaces .",
    "therefore , it makes sense to enforce a sparse representation as also validated by several followup studies @xcite .",
    "however , in single - sample recognition , only one sample @xmath24 is provided per class .",
    "therefore , one would think that the best recognition performance can only be achieved by the nearest - neighbor algorithm .",
    "there are at least two arguments to justify the use of sparse representation in .",
    "one one hand , as discussed in @xcite , in the case that @xmath23 and @xmath135 represent a small error and the nearest - neighbor solution corresponds to a one - sparse binary vector @xmath136^t$ ] in the formulation , then solving via @xmath15-minimization can also recover the sparsest solution , namely , @xmath137 . on the other hand , in the case that @xmath135 represents a large illumination change and @xmath23 represents additional gross image corruption , as long as the elements of @xmath21 in remain tightly correlated in the image space ,",
    "the @xmath15-minimization algorithm can compensate the dense error in the query image @xmath4 @xcite .",
    "this is a unique advantage over nearest - neighbor type algorithms .",
    "in this section , we present a comprehensive experiment to demonstrate the performance of our illumination learning , face alignment , and recognition algorithms .    the illumination dictionary is constructed from extended yaleb database @xcite .",
    "the extended yaleb contains 21888 face image of 38 subjects under 9 poses and 64 illumination conditions . for every subject in a particular pose ,",
    "an image with ambient ( background ) illumination was also captured . in this paper , only the frontal images of the 38 subjects are used as the auxiliary images .    for the gallery and query subjects ,",
    "we choose images from a much larger cmu multi - pie database @xcite . except for section [ sec : exp - robustness ] ,",
    "166 shared subject classes from session 1 and session 2 are selected for testing . in session 1 , we randomly select one frontal image per class with arbitrary illumination as the gallery image",
    ". then we randomly select two different frontal images from session 1 or session 2 for testing .",
    "the outer eye corners of both training and query images are manually marked as the ground truth for registration .",
    "all the training face images are manually cropped into @xmath138 pixels based on the locations of eyes out - corner points , and the distance between the two outer eye corners is normalized to be 50 pixels for each person .",
    "we again emphasize that our experimental setting is more practical than those used in some other publications , as we allow the training images to have arbitrary illumination and not necessarily just the ambient illumination .",
    "we compare our algorithms with several state - of - the - art face alignment and recognition algorithms under the src framework . to conduct a fair comparison",
    ", it is important to separate those algorithms that were originally proposed to handle only the recognition problem versus those that can handle both face alignment and recognition .",
    "the original src algorithm @xcite , the extended src ( esrc ) @xcite , and svdl @xcite belong to the first case , while deformable src ( dsrc ) @xcite , misalignment robust representation ( mrr ) @xcite , and silt proposed in this paper belong to the second case .    finally , as the silt algorithm relies on an auxiliary illumination dictionary @xmath40 , another variability we need to investigate further is how the choice of @xmath40 may affect the performance of silt .",
    "our investigation on this issue will be divided in three steps .",
    "first , in section [ sec : dl_simulations ] , we validate in an ideal , noise - free simulation that the proposed dictionary learning algorithm can successfully recover the subject identity matrix @xmath43 and the illumination dictionary @xmath40 in .",
    "we further utilize extended yaleb database to construct an illumination dictionary from the real face images .",
    "second , in section [ sec : exp - robustness ] , we will compare the recognition rates of silt using different illumination dictionaries .",
    "the experiment further shows the silt framework significantly outperforms dsrc and mrr in single - sample face recognition with misalignment and pixel corruption .",
    "finally , in section [ sec : exp - dictionary ] , we again use extended yaleb database to illustrate how the variation in the atom size and the training subjects of the auxiliary data affects the performance of the silt algorithm .      in this experiment",
    ", we validate the performance of the illumination dictionary learning algorithm in algorithm [ algorithm_sop ] .",
    "first , we use noise - free synthetic data to evaluate the success rate for the algorithm to recover a subject - identity matrix @xmath43 and a sparsely - used dictionary @xmath40 as in .",
    "specifically , the elements in the @xmath139 and @xmath140 matrices are generated from independent and identically distributed ( i.i.d . )",
    "gaussian distributions .",
    "the columns of the sparse coefficient matrix @xmath141 are assumed to be @xmath142-sparse , where each column has exactly @xmath142 non - zero coefficients , where @xmath143 is the number of samples from each class and varies with the atom size @xmath73 .",
    "these synthesized ground - truth matrices then generate the data matrices @xmath144 .    in the experiment ,",
    "we set @xmath145 , @xmath146 , and let @xmath73 vary between 10 and 50 and @xmath142 between 1 and 10 .",
    "in addition , to resolve the potential ambiguity in the permutation of the estimated dictionary atoms , we adopt the following relative error metric to a performance index : @xmath147 where @xmath148 is a permutation matrix , and @xmath149 is a diagonal scaling matrix .",
    "figure [ fig : mse ] shows the simulation result .",
    "the average relative error for both @xmath43 and @xmath40 is reported in grayscale , where the white blocks indicate zero error , and the darker blocks indicate larger relative error .",
    "we can clearly see that when the dictionary size @xmath73 is sufficiently large and when the sparsity @xmath142 sufficiently small , algorithm [ algorithm_sop ] perfectly recovers the two matrices .",
    "the algorithm only fails when @xmath150 and @xmath151 .",
    "furthermore , the phase transition from failed recovery settings to perfect recovery settings is quite sharp .     and basis size @xmath73 for ( a ) @xmath43 and ( b ) @xmath40 estimated by algorithm [ algorithm_sop ] . ]    next , we apply algorithm [ algorithm_sop ] to learn the illumination dictionary @xmath40 from extended yaleb database . for the experimental purpose in the subsequent sections , we construct two dictionaries with very different settings :    1 .   _",
    "ad - hoc dictionary _ : we choose the very first subject in extended yaleb database with 65 aligned frontal images ( 1 ambient + 64 illuminations ) . the dictionary @xmath40 is directly constructed by subtracting the ambient image from the other 64 illumination images , and no additional learning algorithm is involved .",
    "this dictionary is identical to the one used in our previous work @xcite .",
    "yale dictionary _ : we employ all the 38 subjects in extended yaleb database to learn an illumination dictionary using algorithm [ algorithm_sop ] .",
    "some atoms from the above two dictionaries are shown as figure  [ fig : dict ] .",
    "the atom size of yale dictionary in this illustration is fixed at @xmath152 . in section  [ sec : exp - robustness ] and [ sec : exp - dictionary ] , we will compare the performance of different dictionaries .    .",
    "* top : * ad - hoc dictionary constructed from the first subject of extended yaleb database . * bottom : * yale dictionary learned from all the 38 subjects.,scaledwidth=98.0% ]      in this experiment , we demonstrate the performance of the silt alignment algorithm . the performance is measured using simulated 2d deformation on the face image , including translation , rotation and scaling . without loss of generality",
    ", we will only use yale dictionary as our illumination dictionary .",
    "the added deformation is introduced to the query images based on the ground truth coordinates of eye corners .",
    "the translation ranges from [ -12 , 12 ] pixels with a step size of 2 pixels .",
    "similar to @xcite , we use the estimated alignment error @xmath153 as an indicator of success .",
    "more specifically , let @xmath154 be the alignment error obtained by aligning a query image from the manually labeled position to the training images .",
    "we consider the alignment successful if @xmath155 .",
    "we compare our method with dsrc and mrr . as dsrc and mrr",
    "would require to have multiple reference images per class , to provide a fair comparison , we evaluate both algorithms under two settings : firstly , seven reference images are provided per class to dsrc .",
    "we denote this case as dsrc-7 .",
    "secondly , one randomly chosen image per class as the same setting as in the silt algorithm .",
    "we denote this case as dsrc-1 and mrr-1 , respectively .",
    "we draw the following observations from the alignment results shown in figure  [ fig:2d - deformation ] :    1 .",
    "silt works well under a broad range of 2d deformation , particularly when the translation in @xmath156 or @xmath157 direction is less than 20% of the eye distance ( 10 pixels ) and when the in - plane rotation is less than 30 degrees . 2 .",
    "clearly , silt outperforms both dsrc-1 and mrr-1 when the same setting is used , namely , one sample per class .",
    "the obvious reason is that dsrc and mrr were not designed to handle the single - sample alignment scenario .",
    "the accuracy of silt and dsrc-7 is generally comparable across the board in all the simulations .",
    "however , since dsrc-7 has access to seven gallery images of different illumination conditions , the result shows the power of using the new illumination dictionary in , where silt only works with a single gallery image .",
    "+      in this subsection , we evaluate the silt recognition algorithm based on single reference images of the 166 subject classes shared in multi - pie sessions 1 and 2 .",
    "we compare its performance with src @xcite , esrc @xcite , dsrc @xcite , mrr @xcite , and svdl @xcite .",
    "the illumination dictionary used in these experiments is yale dictionary .",
    "first , we note that the new silt framework and the existing sparse representation algorithms are _ not _ mutually exclusive . in particular , the illumination transfer can be easily adopted by the other algorithms to improve the illumination condition of the training images , especially in the single - sample setting . in the first experiment",
    ", we demonstrate the improvement of src and esrc with the illumination transfer .",
    "since both algorithms do not address the alignment problem , manual labels of the face location are assumed to be the aligned face location .",
    "the comparison is presented in table [ table : manual_recog_rate ] .",
    ".single - sample recognition accuracy via manual alignment .",
    "the atom size is fixed to 80 .",
    "[ cols=\"<,^,^\",options=\"header \" , ]     [ table : atom_size_src ]    first , we notice that there is no data point taken at 200 atom size when the subject number is one .",
    "this is due to the fact that each subject in extended yaleb database only provides 65 frontal images .",
    "when one tries to solve for more atoms in the corresponding illumination dictionary in , the problem becomes ill - conditions .",
    "this issue can be first observed by examining the recognition rates for one subject and atom sizes greater than 60 , namely , 80 and 120 . in these two settings ,",
    "the recognition rates are either identical or slightly worse than those at atom size 60 in both table [ table : atom_size_esrc ] and table [ table : atom_size_src ] . at atom size 200 , through visual inspection",
    ", we discover that the illumination patterns in the estimated @xmath40 matrices are close to random noise , and do not contain useful illumination information for the silt algorithm .",
    "therefore , their performance is ignored .",
    "second , when the subject number is higher than one , increasing the atom size of the illumination dictionary clearly improves the recognition rate .",
    "for example , using all the 38 subjects and the silt+esrc@xmath158 algorithm , the recognition rate using a 40-atom illumination dictionary is 90.8% .",
    "the rate is raised to 96.8% when the atom size increases to 200 .",
    "it is worth emphasizing that this recognition rate represents one of the best accuracy on multi - pie database when only single gallery images of random illumination are available , to the best of our knowledge .",
    "finally , it comes as no surprise that if we fix the size of the illumination dictionary in each column of table [ table : atom_size_esrc ] and table [ table : atom_size_src ] , including more subjects in the illumination database also improves the recognition .",
    "this phenomenon can be explained by considering the well - known lambertian model of the human face .",
    "it states that the image appearance of a face is determined not only by the illumination of the environment , but also by the shape of the face and its surface albedo pertaining to individual subjects .",
    "therefore , having more subjects would help to generalize the distribution of the illumination patterns under different face shape and albedo .",
    "then , the use of sparse representation in the alignment and recognition algorithms can effectively select a sparse subset of these illumination patterns that are most similar to the illumination , shape , and albedo condition of the query image .",
    "in this paper , we have presented a novel face recognition algorithm specifically designed for single - sample alignment and recognition . to compensate for the missing illumination information traditionally provided by multiple gallery images , we have proposed a novel dictionary learning algorithm to estimate an illumination dictionary from auxiliary training images .",
    "we have further proposed an illumination transfer technique to transfer the estimate illumination compensation and pose information from the face alignment stage to the recognition stage .",
    "the overall algorithm is called _ sparse illumination learning and transfer _ ( silt ) .",
    "the extensive experiment has validated that not only the standalone silt algorithm outperforms the state of the art in single - sample face recognition by a significant margin , the illumination learning and transfer technique is also complementary to many existing algorithms as a pre - processing step to improve the image condition due to misalignment and pixel corruption .",
    "although we have provided some exciting results that represent a meaningful step forward towards a real - world face recognition system in this paper , one of the open problems remains to be how to improve illumination transfer in complex real - world conditions and with minimal training data .",
    "although the current way of constructing the illumination dictionary is efficient , the method is not able to separate the effect of surface albedo , shape , and illumination completely from face images",
    ". therefore , we believe a more sophisticated illumination transfer algorithm could lead to better overall performance .",
    "we proof theorem [ thm ] in this appendix . first , eliminating the variable @xmath46 of problem with @xmath159 problem",
    "can then be equivalently written as @xmath160 as a basic result in least squares @xcite , the optimal @xmath161 can be written as @xmath162 for any @xmath163 and any @xmath164 such that @xmath165 . substituting @xmath86 into yields @xmath166where",
    "@xmath167 denotes the orthogonal complement projector of @xmath72 .",
    "it is also easy to show from that a solution of @xmath168 is @xmath169_i = \\frac{1}{n } { d}_i{\\mathbf 1},~i=1, ... ,p.\\]]note that the solution @xmath170_i$ ] presents the mean vector of the data matrix @xmath171 corresponding to subject @xmath5 .",
    "furthermore , by letting @xmath172 , problem becomes @xmath173 , and it is equivalent to @xmath174by @xcite , an optimal solution @xmath90 is known to be the @xmath73 principal eigenvector matrix of @xmath175 ; i.e. , @xmath176.\\ ] ] hence , the problem solution simply follows from , , and .",
    "@xmath177              x.  chen , m.  chen , x.  jin , and q.  zhao . face illumination transfer through edge - preserving filters . in _ proceedings of the ieee international conference on computer vision and pattern recognition _ , 2011 .",
    "j.  ho , m.  yang , j.  lim , k.  lee , and d.  kriegman . clustering appearances of objects under varying illumination conditions . in _ proceedings of the ieee international conference on computer vision and pattern recognition _ , pages 1118 , 2003 .",
    "j.  huang , x.  huang , and d.  metaxas .",
    "simultaneous image transformation and sparse representation recovery . in _ proceedings of the ieee international conference on computer vision and pattern recognition _ , 2008 .    c.  lampert , h.  nickisch , and s.  harmeling .",
    "learning to detect unseen object classes by between - class attribute transfer . in _ proceedings of the ieee international conference on computer vision and pattern recognition _ , 2009 .",
    "a.  quattoni , m.  collins , and t.  darrell .",
    "transfer learning for image classification with sparse prototype representations . in _ proceedings of the ieee international conference on computer vision and pattern recognition _",
    ", 2008 .",
    "m.  yang , l.  v. gool , and l.  zhang .",
    "sparse variation dictionary learning for face recognition with a single training sample per person . in _ proceedings of the ieee international conference on computer vision _ , 2013 ."
  ],
  "abstract_text": [
    "<S> single - sample face recognition is one of the most challenging problems in face recognition . </S>",
    "<S> we propose a novel algorithm to address this problem based on a sparse representation based classification ( src ) framework . </S>",
    "<S> the new algorithm is robust to image misalignment and pixel corruption , and is able to reduce required gallery images to one sample per class . to compensate for the missing illumination information traditionally provided by multiple gallery images , a sparse illumination learning and transfer ( silt ) technique is introduced . the illumination in silt is learned by fitting illumination examples of auxiliary face images from one or more additional subjects with a sparsely - used illumination dictionary . </S>",
    "<S> by enforcing a sparse representation of the query image in the illumination dictionary , the silt can effectively recover and transfer the illumination and pose information from the alignment stage to the recognition stage . </S>",
    "<S> our extensive experiments have demonstrated that the new algorithms significantly outperform the state of the art in the single - sample regime and with less restrictions . in particular , </S>",
    "<S> the single - sample face alignment accuracy is comparable to that of the well - known deformable src algorithm using multiple gallery images per class . </S>",
    "<S> furthermore , the face recognition accuracy exceeds those of the src and extended src algorithms using hand labeled alignment initialization .    </S>",
    "<S> example.eps gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidthlight gsave .4 setgray fill grestore stroke grestore </S>"
  ]
}