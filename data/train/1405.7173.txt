{
  "article_text": [
    "the literature devoted to change - point models is vast , particularly in the areas of economics , genome research , quality control , and signal processing .",
    "when there are notable changes in a sequence of data , we can typically break the sequence into several data segments , so that the observations within each segment are relatively homogeneous . in the conventional change - point problems , the posited models for different data segments are often of the same structure but with different parameter values .",
    "however , the underlying distributions are typically unknown , and thus parametric methods potentially suffer from model misspecification .",
    "the least - squares fitting is the standard choice for the mcp , while its performance often deteriorates when the error follows a heavy - tailed distribution or when the data contain outliers .    without imposing any parametric modeling assumption , we consider the multiple change - point problem ( mcp ) based on independent data @xmath0 , such that @xmath1 where @xmath2 is the true number of change - points , @xmath3 s are the locations of these change - points with the convention of @xmath4 and @xmath5 , and @xmath6 is the cumulative distribution function ( c.d.f . ) of segment @xmath7 satisfying @xmath8 . the number of change - points @xmath2 is allowed to grow with the sample size @xmath9 .",
    "although extensive research has been conducted to estimate the number of change - points @xmath2 and the locations of these change - points @xmath3 s , most of the work assumes that @xmath6 s belong to some - known parametric functional families or that they differ only in their locations ( or scales ) . for a comprehensive coverage on single change - point problems @xmath10 ,",
    "see @xcite .",
    "the standard approach to the mcp is based on least - squares or likelihood methods via a dynamic programming ( dp ) algorithm in conjunction with a selection procedure such as the bayesian information criterion ( bic ) for determining the number of change - points [ @xcite ; @xcite ; @xcite ; @xcite ( @xcite ) ; @xcite ; @xcite ; @xcite ] . by reframing the mcp in a variable selection context , @xcite proposed a penalized least - squares criterion with a lasso - type penalty [ @xcite ] .",
    "@xcite developed a graph - based approach to detecting change - points , which is applicable in high - dimensional data and non - euclidean data .",
    "other recent development in this area includes @xcite , @xcite and @xcite .",
    "our goal is to develop an efficient nonparametric procedure for the mcp in ( [ om1 ] ) without imposing any parametric structure on the @xmath6 s ; virtually any salient difference between two successive c.d.f.s ( say , @xmath6 and @xmath11 ) would ensure detection of the change - point asymptotically . in the nonparametric context ,",
    "most of the existing work focuses on the single change - point problem by using some seminorm on the difference between pre- and post - empirical distributions at the change - point [ @xcite ; @xcite ; @xcite ] .",
    "@xcite studied a semiparametric change - point model based on the empirical likelihood , and applied the method to detect the change from a distribution to a weighted one .",
    "@xcite proposed another empirical likelihood approach without assuming any relationship between the two distributions .",
    "however , extending these methods to the mcp is not straightforward .",
    "@xcite proposed to use the weighted empirical measure to detect two different nonparametric distributions over a window of observations and then run the window through the full data sequence to detect the number of change - points .",
    "although the approach of @xcite is simple and easy to implement , our simulation studies show that even with elaborately chosen tuning parameters the estimates of the locations @xmath3 s as well as the number of change - points are not satisfactory",
    ". this may be partly due to the `` local '' nature of the running window , and thus the information in the data is not fully and efficiently utilized .",
    "@xcite proposed a new estimation method , ecp , under multivariate settings , which is based on hierarchical clustering by recursively using a single change - point estimation procedure .    observing the connection between multiple change - points and goodness - of - fit tests , we propose a nonparametric maximum likelihood approach to the mcp .",
    "our proposed nonparametric multiple change - point detection ( nmcd ) procedure can be regarded as a nonparametric counterpart of the classical least - squares mcp method [ @xcite ] . under some mild conditions ,",
    "we demonstrate that the nmcd can achieve the optimal rate , @xmath12 , for the estimation of the change - points without any distributional assumptions . due to the use of empirical functions , technical arguments for controlling the supremum of the nonparametric likelihood function",
    "are nontrivial and are interesting in their own rights . as a matter of fact",
    ", some techniques regarding the empirical process have been nicely integrated with the mcp methodologies .",
    "in addition , our theoretical results are applicable to the situation with a diverging number of change - points , that is , when the number of change - points , @xmath2 , grows as @xmath9 goes to infinity .",
    "this substantially enlarges the scope of applicability of the proposed method , from a traditional fixed dimensionality to a more challenging high - dimensional setting .    in the proposed nmcd procedure ,",
    "the number of change - points , @xmath2 , is determined by the bic .",
    "given @xmath2 , the dp algorithm utilizes the intrinsic order structure of the likelihood to recursively compute the maximizer of the objective function with a complexity of @xmath13 .",
    "to exclude most of the irrelevant points , we also suggest an initial screening procedure so that the nmcd is implemented in a much lower - dimensional space .",
    "compared with existing parametric and nonparametric approaches , the proposed nmcd has satisfactory performance of identifying multiple change - points in terms of estimation accuracy and computation time .",
    "it offers robust and effective detection capability regardless of whether the @xmath6 s differ in the location , scale , or shape .",
    "the remainder of the paper is organized as follows . in section  [ sec2 ] , we first describe how to recast the mcp in ( [ om1 ] ) into a maximization problem and then introduce our nonparametric likelihood method followed by its asymptotic properties . the algorithm and practical implementation are presented in section  [ sec3 ] .",
    "the numerical performance and comparisons with other existing methods are presented in section  [ sec4 ] .",
    "section  [ sec5 ] contains a real data example to illustrate the application of our nmcd method .",
    "several remarks draw the paper to its conclusion in section  [ sec6 ] .",
    "technical proofs are provided in the , and the proof of a corollary and additional simulation results are given in the supplementary material [ @xcite ] .",
    "assume that @xmath14 are independent and identically distributed from @xmath15 , and let @xmath16 denote the empirical c.d.f . of the sample , then @xmath17 .",
    "if we regard the sample as binary data with the probability of success @xmath18 , this leads to the nonparametric maximum log - likelihood @xmath19 in the context of ( [ om1 ] ) , we can write the joint log - likelihood for a candidate set of change - points @xmath20 as @xmath21\\\\[-8pt ] & & { } + \\bigl(1-{\\widehat{f}}_{\\tau_k'}^{\\tau_{k+1}'}(u ) \\bigr ) \\log\\bigl({1- { \\widehat{f}}_{\\tau_k'}^{\\tau_{k+1}'}(u ) } \\bigr ) \\bigr\\},\\nonumber\\end{aligned}\\ ] ] where @xmath22 is the empirical c.d.f . of the subsample @xmath23 with @xmath24 and @xmath25 . to estimate the change - points @xmath26 , we can maximize ( [ sjl ] ) in an integrated form @xmath27 where @xmath28 is some positive weight function so that @xmath29 is finite , and the integral is used to combine all the information across @xmath30 .",
    "the rationale of using ( [ pl ] ) can be clearly seen from the behavior of its population counterpart . for simplicity",
    ", we assume that there exists only one change - point @xmath31 , and let @xmath32 and @xmath33 . through differentiation with respect to @xmath34",
    ", it can be verified that the limiting function of @xmath35 , @xmath36 increases as @xmath34 approaches @xmath37 from both sides , where @xmath38 are the limits of @xmath39 and @xmath40 , respectively .",
    "this implies that the function @xmath41 attains its local maximum at the true location of the change - point , @xmath37 .",
    "[ rem1 ] the log - likelihood function ( [ sjl ] ) is essentially related to the two - sample goodness - of - fit ( gof ) test statistic based on the nonparametric likelihood ratio [ @xcite ; @xcite ] . to see this ,",
    "let @xmath14 be independent , and suppose that @xmath42 have a common continuous distribution function @xmath43 , and @xmath44 have @xmath45 .",
    "we are interested in testing the null hypothesis @xmath46 that @xmath47 for all @xmath48 against @xmath49 that @xmath50 for some @xmath48 . for each fixed @xmath48 ,",
    "a natural approach is to apply the likelihood ratio test , @xmath51 where @xmath18 corresponds to the c.d.f . of the pooled sample . by noting that @xmath52 , @xmath53 would be of the same form as ( [ sjl ] ) with @xmath54 up to a constant which does not depend on the segmentation point  @xmath55 .",
    "@xcite considered using @xmath53 to test whether there is at most one change - point .    in the two - sample gof test , @xcite ( @xcite ) demonstrated that by choosing appropriate weight functions @xmath56 we can produce new omnibus tests that are generally much more powerful than the conventional ones such as kolmogorov ",
    "smirnov , cramr ",
    "von mises and anderson  darling test statistics .",
    "if we take @xmath57 , and also note that @xmath58 is zero for @xmath59 and @xmath60 where @xmath61 represent the order statistics , the objective function in ( [ pl ] ) can be rewritten as @xmath62 where @xmath63 . as recommended by @xcite ,",
    "we take a common `` continuity correction '' by replacing @xmath64 with @xmath65 for all @xmath7  and  @xmath66 .    to determine @xmath67 in the mcp , we observe that @xmath68 is a convex function with respect to @xmath34 , and thus @xmath69 which means that the maximum log - likelihood @xmath70 is a nondecreasing function in @xmath67 .",
    "hence , we can use schwarz s bayesian information criterion ( bic ) to strike a balance between the likelihood and the number of change - points by incorporating a penalty for large @xmath67 . more specifically",
    ", we identify the value of @xmath67 by minimizing @xmath71 and @xmath72 is a proper sequence going to infinity .",
    "@xcite used the bic with @xmath73 to select the number of change - points and showed its consistency in the least - squares framework .",
    "however , the traditional bic tends to select a model with some spurious change - points .",
    "detailed discussions on the choice of @xmath72 and other tuning parameters are given in section  [ sec3.2 ] .",
    "in the context of change - point estimation , it is well known that the points around the true change - point can not be distinguished asymptotically with a fixed change magnitude . in the least - squares",
    "fitting , the total with perfect segmentation is asymptotically equivalent to that with an estimate of the change - point in a neighborhood of the true change - point [ @xcite ] .",
    "for example , suppose that there is only one change - point @xmath74 with a change size @xmath75 , then we can only achieve @xmath76 as @xmath77 , where @xmath78 denotes the maximum likelihood estimator ( mle ) of @xmath74 [ see chapter  1 of @xcite ] . for single change - point nonparametric models , @xcite obtained a rate of @xmath79 , @xcite derived a rate of @xmath80 a.s .",
    "( almost surely ) for any @xmath81 , and @xcite achieved a rate of @xmath12 .",
    "the estimator in @xcite is shown to be consistent a.s . and",
    "the differences between the estimated and true locations of change - points are of order @xmath82 a.s .",
    "let @xmath83 denote the set of estimates of the change - points using the proposed nmcd .",
    "the next theorem establishes the desirable property for the nmcd estimator when @xmath2 is prespecified@xmath84 is asymptotically close to the true change - point set .",
    "let @xmath85 contain all the sets in the @xmath86-neighborhood of the true locations , @xmath87 where @xmath86 is some positive sequence .",
    "denote @xmath88 for @xmath89 . for @xmath90 , define @xmath91 which is the kullback ",
    "leibler distance between two bernoulli distributions with respective success probabilities @xmath92 and @xmath93 .",
    "hence , whenever @xmath94 , and accordingly @xmath95 , @xmath96 is strictly larger than zero .",
    "furthermore , for @xmath90 , define @xmath97    to establish the consistency of the proposed nmcd , the following assumptions are imposed :    @xmath98 are continuous and @xmath99 for @xmath100 .    let @xmath101 ; @xmath102 as @xmath103 .",
    "@xmath104 uniformly in @xmath30 , where @xmath105 is the c.d.f . of the pooled sample .",
    "@xmath106 is a positive constant .",
    "assumption ( a1 ) is required in some exponential tail inequalities as detailed in the proof of lemma [ klem4 ] , while the @xmath6 s can be discrete or mixed distributions in practice .",
    "assumption ( a2 ) is a standard requirement for the theoretical development in the mcp , which allows the change - points to be asymptotically distinguishable .",
    "assumption ( a3 ) is a technical condition that is trivially satisfied by the glivenko ",
    "cantelli theorem when @xmath2 is finite .",
    "generally , it can be replaced by the conditions that @xmath107 exists and @xmath108 converges to 0 a.s . by the dvoretzky  kiefer ",
    "wolfowitz inequality , the latter one holds if @xmath109 for any @xmath110 .",
    "assumption ( a4 ) means that the smallest signal strength among all the changes is bounded away from zero",
    ".    we may consider relaxing @xmath111 in assumption  ( a2 ) by allowing @xmath112 as @xmath113 .",
    "it is intuitive that if two successive distributions are very different , then we do not need a very large @xmath114 to locate the change point . for the mean change problem , @xcite and @xcite revealed that in order to obtain the @xmath12 consistency ,",
    "a condition @xmath115 is required , where @xmath75 is the minimal jump size at the change - points ( similar to @xmath116 ) . in our nonparametric",
    "setting , such an extension warrants future investigation .",
    "[ teo1 ] under assumptions , if @xmath117 @xmath118 and @xmath119 , then @xmath120    under the classical mean change - point model , @xcite studied the property of the least - squares estimator , @xmath121 where @xmath122 denotes the average of the observations @xmath123 .",
    "it is well known that the least - squares estimator is consistent with the optimal rate @xmath12 , when the number of change - points is known ( and does not depend on @xmath9 ) and the change magnitudes are fixed ; see @xcite and the references therein . under a similar setting with @xmath124",
    ", we can establish the same rate of @xmath12 for our nonparametric approach .",
    "[ cor1 ] under assumptions , and , @xmath125 for @xmath126 .",
    "the proof is similar to that of theorem  [ teo1 ] , which is provided in the supplementary material [ @xcite ] . with the knowledge of @xmath127",
    ", we can obtain an optimal rate of @xmath12 without specifying the distributions , which is consistent with the single change - point case in @xcite .",
    "the next theorem establishes the consistency of the nmcd procedure with the bic in ( [ bic ] ) .",
    "let @xmath128 , where @xmath129 is an upper bound on the true number of change - points .",
    "[ probic ] under assumptions , @xmath130 , @xmath131 with any @xmath132 , then @xmath133 as @xmath134 .",
    "it is remarkable that in the conventional setting where @xmath129 is bounded , we can use @xmath72 of order @xmath135 instead of its least - squares counterpart @xmath136 in @xcite . in conjunction with theorem  [ teo1 ] , this result implies that @xmath137 with a fixed number of change - points .",
    "one important property of the proposed maximum likelihood approach is that ( [ fpl ] ) is separable .",
    "the optimum for splitting cases @xmath138 into  @xmath67 segments conceptually consists of first finding the rightmost change - point @xmath139 , and then finding the remaining change - points from the fact that they constitute the optimum for splitting cases @xmath140 into @xmath141 segments .",
    "this separability is called bellman s `` principle of optimality '' [ @xcite ] .",
    "thus , ( [ fpl ] ) can be maximized via the dp algorithm and fitting such a nonparametric mcp model is straightforward and fast .",
    "the total computational complexity is @xmath142 for a given @xmath67 ; see @xcite and @xcite for the pseudo - codes of the dp .",
    "@xcite suggested using the dp on a grid of @xmath143 values .",
    "@xcite proposed using a lasso - type penalized estimator to achieve a reduced version of the least - squares method .",
    "@xcite developed a screening and ranking algorithm to detect dna copy number variations in the mcp framework .    due to the dp s computational complexity in @xmath144 , an optimal segmentation of a very long sequence",
    "could be computationally intensive ; for example , dna sequences nowadays are often extremely long [ @xcite ] . to alleviate the computational burden",
    ", we introduce a preliminary screening step which can exclude most of the irrelevant points and , as a consequence , the nmcd is implemented in a much lower - dimensional space .",
    "choose an appropriate integer @xmath145 which is the length of each subsequence of the data , and take the estimated change - point set @xmath146 .",
    "initialize @xmath147 for @xmath148 ; and for @xmath149 , update @xmath150 to be the cramr ",
    "von mises two - sample test statistic for the samples @xmath151 and @xmath152 .    for @xmath149 ,",
    "define @xmath153 . if @xmath154 , update @xmath155 .",
    "intuitively speaking , this screening step finds the most influential points that have the largest _ local _ jump sizes quantified by the cramr ",
    "von mises statistic , and thus helps to avoid including too many candidate points around the true change - point . as a result",
    ", we can obtain a candidate change - point set , @xmath156 , of which the cardinality , @xmath157 , is usually much smaller than @xmath9 .",
    "finally , we run the nmcd procedure within the set @xmath156 using the dp algorithm to find the solution of @xmath158    apparently , the screening procedure is fast because it mainly requires calculating @xmath159 cramr ",
    "von mises statistics .",
    "in contrast , @xcite used a thresholding step to determine the number of change - points .",
    "the main difference between @xcite and @xcite lies in the choice of the local test statistic ; the former uses some seminorm of empirical distribution functions and the latter is based on the two - sample mean difference .",
    "we next clarify how to choose @xmath160 , which formally establishes the consistency of the screening procedure .",
    "[ sis ] under assumptions , if @xmath161 and @xmath162 , then we have @xmath163 , where @xmath164    this result follows by verifying condition ( a3 ) in @xcite ; see example  ii of @xcite . with probability tending to one ,",
    "the screening algorithm can at least include one @xmath86-neighborhood of the true location set by choosing an appropriate @xmath160 .",
    "given a candidate @xmath67 , the computation of nmcd reduces to @xmath165 , which is of order @xmath166 in conjunction with the bic .",
    "both the r and codes for implementing the entire procedure are available from the authors upon request .",
    "we propose to take @xmath167 , which is found to be more powerful than simply using @xmath168 .",
    "the function @xmath169 attains its minimum at @xmath170 , that is when @xmath30 is the median of the sample .",
    "intuitively , when two successive distributions mainly differ in their centers , both choices of @xmath171 would be powerful a large portion of observations are around the center .",
    "however , if the difference between two adjacent distributions lies in their tails , using @xmath168 may not work well because only very limited information is included in the integral of ( [ pl ] ) .",
    "in contrast , our weight would be larger for those more extreme observations ( far way from the median ) .    to better understand this",
    ", we analyze the term @xmath116 , which reflects the detection ability to a large extent .",
    "consider a special case @xmath172 and thus @xmath173 it is easy to check that @xmath174 is unbounded , while the counterpart @xmath175 is finite .",
    "consequently , the nmcdprocedure would be more powerful by using the weight @xmath176 .    under the assumption that @xmath177 with @xmath132 and @xmath178",
    ", we establish the consistency of the bic in ( [ bic ] ) for model selection .",
    "the choice of @xmath72 depends on @xmath129 and @xmath114 which are unknown .",
    "the value of @xmath129 depends on the practical consideration of how many change - points are to be identified , while @xmath114 reflects the length of the smallest segment . for practical use ,",
    "we take @xmath129 to be fixed and recommend @xmath179 with @xmath180 .",
    "a  small value of @xmath181 helps to prevent underfitting , as one is often reluctant to miss any important change - point .",
    "the performance of nmcd insensitive to the choice of @xmath129 , as long as @xmath129 is not too small , which is also to avoid underfitting .",
    "we suggest @xmath182 , that is , the cardinality of the candidate change - point set in the screening algorithm .",
    "to evaluate the finite - sample performance of the proposed nmcd procedure , we conduct extensive simulation studies , and also make comparisons with existing methods .",
    "we calculate the distance between the estimated set @xmath183 and the true change - point set @xmath184 [ @xcite ] , @xmath185 which quantify the over - segmentation error and the under - segmentation error , respectively .",
    "a desirable estimator should be able to balance both quantities .",
    "in addition , we consider the average rand index [ @xcite ] , which measures the discrepancy of two sets from an average viewpoint .    following model  ( i ) introduced by @xcite , we generate the blocks datasets , which contains @xmath186 change - points : @xmath187 where there are @xmath9 equally spaced covariates @xmath188 in @xmath189 $ ] .",
    "three error distributions for  @xmath190 are considered : @xmath191 , student s @xmath192 distribution with three degrees of freedom @xmath193 , and the standardized ( zero mean and unit variance ) chi - squared distribution with one degree of freedom @xmath194 . the blocks datasets with @xmath195 , as depicted in the top three plots of figure  a.1 in the supplementary material [ @xcite ] ,",
    "are generally considered difficult for multiple change - point estimation due to highly heterogeneous segment levels and lengths .    in a more complicated setting with both location and scale changes",
    ", we consider model  ( ii ) with @xmath196 : @xmath197 where all the other setups are the same as those of model  ( i ) . as shown by the bottom three plots in figure a.1 ,",
    "there are two location changes and two scale changes .    in addition",
    ", we include a simulation study when the distributions differ in the skewness and kurtosis .",
    "in particular , we consider @xmath198 where @xmath199 correspond to the standard normal , the standardized @xmath200 ( with zero mean and unit variance ) , the standardized @xmath194 , and the standard normal distribution , respectively . because there is no mean or variance difference between the @xmath201 s , as depicted in the left panel of figure a.4 , the estimation for such a change - point problem is rather difficult .",
    "all the simulation results are obtained with 1000 replications .      to study the sensitivity of the choice of @xmath72 , figure  [ fig1](a ) shows the curves of @xmath202 versus the value of @xmath203 with @xmath204 under model  ( i ) .",
    "clearly , the estimation is reasonably well with a value of @xmath203 around 1 . for more adaptive model selection , a data - adaptive complexity penalty in @xcite could be considered .",
    "and @xmath205 when the tuning parameters vary :  the curves of @xmath202 versus the value of @xmath203 ; the curves of @xmath206 versus the value of @xmath203 . ]    in the screening procedure , the choice of @xmath160 needs to balance the computation and underfitting . by proposition",
    "[ sis ] , @xmath207 , while @xmath114 is typically unknown . in practice",
    ", we recommend to choose @xmath208 , which is the smallest integer that is larger than @xmath209 .",
    "figure  [ fig1](b ) shows the curves of under - segmentation errors versus the value of @xmath203 with @xmath210 under model  ( i ) . in a neighborhood of @xmath211 ,",
    "our method provides a reasonably effective reduction of the subset @xmath156 and the performance is relatively stable . in general , we do not recommend a too large value of @xmath160 so as to avoid underfitting . from the results shown in section  [ sec4.6 ] ,",
    "the choice of @xmath212 and @xmath213 works also well when the number of change - points increases as the sample size increases .",
    "@@lcd4.0cccccc@ & & & & + & & & & + * model * & * error * & & & & & & & * nmcd * * + ( i)&@xmath214 & 500 & 0.96  ( 1.19 ) & 0.96  ( 1.14 ) & 1.16  ( 1.15 ) & 0.96  ( 1.19 ) & 0.96  ( 1.14 ) & 1.16  ( 1.15 ) + & & 1000 & 0.91  ( 1.15 ) & 0.97  ( 1.16 ) & 1.06  ( 1.21 ) & 0.91  ( 1.15 ) & 0.97  ( 1.16 ) & 1.06  ( 1.21 ) + & @xmath193 & 500 & 13.6  ( 12.0 ) & 3.77  ( 4.48 ) & 3.86  ( 4.33 ) & 14.3  ( 18.4 ) & 3.95  ( 7.51 ) & 3.97  ( 7.63 ) + & & 1000 & 20.2  ( 21.3 ) & 2.58  ( 2.50 ) & 2.90  ( 2.72 ) & 21.9  ( 34.5 ) & 2.56  ( 2.40 ) & 2.90  ( 2.72 ) + & @xmath194 & 500 & 1.39  ( 2.91 ) & 0.70  ( 0.80 ) & 0.80  ( 1.22 ) & 1.13  ( 1.57 ) & 0.70  ( 0.80 ) & 0.81  ( 1.41 ) + & & 1000 & 1.05  ( 2.15 ) & 0.59  ( 0.77 ) & 0.58  ( 0.71 ) & 0.99  ( 1.38 ) & 0.59  ( 0.77 ) & 0.58  ( 0.71 ) + ( ii)&@xmath214&500 & 1.59  ( 1.72 ) & 2.35  ( 2.42 ) & 3.34  ( 4.96 ) & 1.59  ( 1.72 ) & 2.35  ( 2.42 ) & 3.34  ( 4.96 ) + & & 1000 & 1.58  ( 1.52 ) & 2.68  ( 2.59 ) & 2.74  ( 2.89 ) & 1.58  ( 1.52 ) & 2.68  ( 2.59 ) & 2.74  ( 2.89 ) + & @xmath193 & 500 & 13.6  ( 25.8 ) & 4.75  ( 6.87 ) & 6.42  ( 8.84 ) & 7.52  ( 10.2 ) & 4.54  ( 5.19 ) & 6.05  ( 6.42 ) + & & 1000 & 16.4  ( 40.2 ) & 4.10  ( 3.88 ) & 5.27  ( 7.20 ) & 10.3  ( 18.0 ) & 4.10  ( 3.88 ) & 5.24  ( 6.85 ) + & @xmath194 & 500 & 6.36  ( 11.3 ) & 1.57  ( 2.12 ) & 1.65  ( 2.90 ) & 5.88  ( 8.93 ) & 1.57  ( 2.12 ) & 1.65  ( 2.90 ) + & & 1000 & 4.80  ( 67.8 ) & 1.17  ( 1.45 ) & 1.49  ( 2.10 ) & 4.80  ( 7.82 ) & 1.17  ( 1.45 ) & 1.49  ( 2.10 ) +      firstly , under model  ( i ) with location changes only , we make a comparison of nmcd with the parametric likelihood ( pl ) method which coincides with the classical least - squares method in ( [ yao ] ) under the normality assumption [ @xcite ] .",
    "we also consider a variant of nmcd by using @xmath168 ( abbreviated as nmcd * ) .",
    "the comparison is conducted with and without knowing the true number of change - points @xmath2 , respectively .",
    "table  [ tknowk ] presents the average values of @xmath206 and @xmath215 for @xmath216 and 1000 and @xmath205 when @xmath2 is known to be 11 .",
    "to gain more insight , we also present the standard deviations of the two distances in parentheses .",
    "simulation results with other values of @xmath217 can be found in the supplementary material [ @xcite ] .",
    "as expected , the pl has superior efficiency for the case with normal errors , since the parametric model is correctly specified .",
    "the nmcd procedure also offers satisfactory performance and the differences in the two @xmath218 values between nmcd and pl are extremely small , while both methods significantly outperform the nmcd * procedure . for the cases with @xmath193 and @xmath194 errors , the nmcd procedure almost uniformly outperforms the pl in terms of estimation accuracy of the locations .",
    "not only are the distance values of @xmath206 and @xmath215 smaller , but the corresponding standard deviations are also much smaller using the nmcd .",
    "@@lcd4.0cccccc@ & & & & + & & & & + * model * & * error * & & & & & & & @xmath219 + ( i)&@xmath214 & 500 & 0.93  ( 1.08 ) & 2.16  ( 6.57 ) & 0.09  ( 0.31 ) & 0.96  ( 1.34 ) & 0.99  ( 1.05 ) & 0.00  ( 0.04 ) + & & 1000 & 0.94  ( 1.14 ) & 2.30  ( 10.3 ) & 0.05  ( 0.25 ) & 0.96  ( 1.25 ) & 1.01  ( 1.25 ) & 0.00  ( 0.04 ) + & @xmath193 & 500 & 2.91  ( 2.92 ) & 39.0  ( 24.9 ) & 6.05  ( 3.47 ) & 3.34  ( 4.22 ) & 8.64  ( 15.2 ) & 0.36  ( 0.88 ) + & & 1000 & 2.94  ( 3.02 ) & 95.2  ( 48.8 ) & 9.70  ( 4.14 ) & 2.54  ( 2.78 ) & 10.0  ( 26.8 ) & 0.36  ( 0.75 ) + & @xmath194 & 500 & 0.85  ( 0.99 ) & 49.5  ( 23.6 ) & 10.9  ( 4.69 ) & 0.73  ( 0.95 ) & 1.36  ( 5.59 ) & 0.05  ( 0.28 ) + & & 1000 & 0.85  ( 1.05 ) & 111  ( 46.2 ) & 14.2  ( 4.06 ) & 0.53  ( 0.69 ) & 0.89  ( 4.28 ) & 0.02  ( 0.20 ) + ( ii ) & @xmath214 & 500 & 1.66  ( 1.61 ) & 2.22  ( 5.56 ) & 0.04  ( 0.22 ) & 2.28  ( 2.31 ) & 4.45  ( 8.54 ) & 0.13  ( 0.37 ) + & & 1000 & 1.69  ( 1.50 ) & 1.71  ( 1.52 ) & 0.01  ( 0.11 ) & 2.19  ( 2.11 ) & 3.93  ( 10.6 ) & 0.06  ( 0.27 ) + & @xmath193 & 500 & 5.77  ( 6.57 ) & 24.1  ( 20.0 ) & 1.58  ( 1.56 ) & 5.18  ( 6.18 ) & 14.1  ( 16.5 ) & 0.75  ( 1.01 ) + & & 1000 & 5.59  ( 6.26 ) & 62.4  ( 41.3 ) & 2.72  ( 2.21 ) & 4.50  ( 4.44 ) & 17.0  ( 28.4 ) & 0.47  ( 0.87 ) + & @xmath194 & 500 & 5.03  ( 6.19 ) & 43.1  ( 16.0 ) & 4.71  ( 2.66 ) & 1.67  ( 2.39 ) & 7.27  ( 12.6 ) & 0.43  ( 0.80 ) + & & 1000 & 5.00  ( 6.29 ) & 91.1  ( 31.1 ) & 6.22  ( 3.23 ) & 1.26  ( 1.50 ) & 9.45  ( 22.7 ) & 0.28  ( 0.70 ) +    next , we consider the @xmath2 unknown case , for which both the nmcd and pl procedures are implemented by setting @xmath220 and using the bic to choose the number of change - points",
    ". the average values of the distances @xmath206 and @xmath215 are tabulated in table  [ tunknowk ] .",
    "in addition , we also present the average values of @xmath202 with standard deviations in parentheses , which reflect the overall estimation accuracy of @xmath2 .",
    "clearly , the two methods have comparable performances under the normal error , while the proposed nmcd significantly outperforms pl in terms of @xmath215 and @xmath221 for the two nonnormal cases , because the efficiency of the bic used in pl relies heavily on the parametric assumption .",
    "when we compare the results across tables  [ tknowk ] and [ tunknowk ] , the standard deviations for the distance measures increase from the @xmath2 known to the @xmath2 unknown cases , as estimating @xmath2 further enlarges the variability .",
    "we turn to the comparison between nmcd and pl under model ( ii ) in which both location and scale changes are exhibited . in this situation , the standard least - squares method ( [ yao ] ) does not work well because it is constructed for location changes only .",
    "to further allow for scale changes under the pl method , we consider @xmath222 where @xmath223 , and the bic is modified accordingly .",
    "the bottom panels of tables  [ tknowk ] and [ tunknowk ] tabulate the values of @xmath206 and @xmath215 when @xmath2 is specified in advance and estimated by using the bic , respectively .",
    "clearly , the nmcd method delivers a satisfactory detection performance for the normal case and performs much better than the pl method for the two nonnormal cases .",
    "therefore , the conclusion remains that the pl method is generally sensitive to model specification , while the nmcd does not depend on any parametric modeling assumption and thus is much more robust .",
    "we consider the methods of @xcite and @xcite , as they also do not make any assumptions regarding the nature of the changes .",
    "the nmcd is implemented with the initial nonparametric screening procedure , and @xmath2 is selected by the bic . in both our screening procedure and lee s ( @xcite ) method ,",
    "the window is set as @xmath224 , and the threshold value of the latter is chosen as @xmath225 .",
    "the ecp method of @xcite is implemented using the `` ecp '' r package with the false alarm rate 0.05 and @xmath226 .",
    "@@lcd4.0d3.1d3.2d2.2cccccc@ & & & & & + & & & & & + * model * & * error * & & & & & & & & & & * nmcd * + ( i ) & @xmath191 & 500 & 84.9 & 6.03 & 2.62 & 0.920 & 0.994 & 0.992 & 28.5 & 0.07 & 0.01 + & & 1000 & 176 & 7.42 & 2.23 & 0.915 & 0.997 & 0.994 & 43.2 & 0.07 & 0.00 + & @xmath193 & 500 & 86.7 & 4.95 & 8.94 & 0.920 & 0.995 & 0.988 & 27.5 & 0.06 & 0.22 + & & 1000 & 177 & 7.29 & 7.63 & 0.914 & 0.997 & 0.993 & 42.9 & 0.08 & 0.02 + & @xmath194 & 500 & 85.0 & 4.67 & 3.00 & 0.921 & 0.995 & 0.992 & 28.3 & 0.06 & 0.02 + & & 1000 & 176 & 5.67 & 2.80 & 0.915 & 0.997 & 0.994 & 43.1 & 0.05 & 0.01 + ( ii ) & @xmath191 & 500 & 69.0 & 17.6 & 14.4 & 0.832 & 0.980 & 0.980 & 33.8 & 0.06 & 0.11 + & & 1000 & 140 & 17.5 & 14.4 & 0.830 & 0.990 & 0.987 & 51.3 & 0.07 & 0.03 + & @xmath193 & 500 & 69.3 & 16.8 & 20.4 & 0.833 & 0.982 & 0.974 & 33.7 & 0.10 & 0.25 + & & 1000 & 141 & 12.5 & 21.4 & 0.830 & 0.992 & 0.983 & 51.6 & 0.06 & 0.13 + & @xmath194 & 500 & 67.9 & 8.25 & 10.5 & 0.833 & 0.989 & 0.983 & 34.0 & 0.05 & 0.12 + & & 1000 & 139 & 10.2 & 12.6 & 0.830 & 0.994 & 0.987 & 51.2 & 0.07 & 0.09 + ( iii ) & & 500 & 120 & 394 & 78.2 & 0.822 & 0.446 & 0.894 & 35.4 & 1.73 & 0.53 + & & 1000 & 243 & 452 & 43.9 & 0.818 & 0.714 & 0.965 & 52.8 & 1.22 & 0.19 +    table  [ tleeunknowk ] shows the comparison results based on @xmath227 , @xmath221 , and the rand index under models ( i)(iii ) with @xmath205 , respectively .",
    "lee s ( @xcite ) method is unable to produce a reasonable estimate for @xmath2 and the resulting models are much overfitted in all the cases , which indicates that its `` local '' nature incurs substantial loss of the information . under model  ( i ) , the nmcd performs better than ecp for normal and @xmath228 errors , while the opposite is true for the @xmath192 error distribution . under model ( ii )",
    ", the ecp also exhibits certain advantage , especially for student s @xmath192 and @xmath194 error distributions .",
    "both the nmcd and ecp methods significantly outperform that of @xcite in models ( i ) and ( ii ) . under model ( iii ) , both the methods of ecp and @xcite appear not working well , while the nmcd still produces reasonable detection results .",
    "as the divergence measure used in the ecp is essentially similar to euclidean distances , the ecp is expected to perform well when the distributions differ in the first two moments , which however is not the case for model ( iii ) .",
    "the advantages of nmcd are mainly due to the joint use of the nonparametric likelihood and the weight function @xmath229 . based on the empirical distribution functions ,",
    "the nonparametric likelihood approach is capable of detecting various types of changes .",
    "in addition , the difference between two adjacent distributions under model ( iii ) does not lie in their centers , and thus using our proposed @xmath56 would provide certain improvement as discussed in section  [ sec3.2 ] . due to the use of dp ,",
    "our procedure is much faster than the ecp .",
    "@xcite proposed the least - squares total variation method ( lstv ) to estimate the locations of multiple change - points . by reframing the mcp in a variable selection context , they use a penalized least - squares criterion with a lasso - type penalty .",
    "the lstv enjoys efficient computation using the least angle regression [ @xcite ] , while it does not provide competitive performance relative to the classical least - squares method with the dp , even when the true number of change - points is known . to improve the performance ,",
    "the so - called lstv * was further developed by incorporating a reduced version of the dp .",
    "roughly speaking , the lstv plays essentially a similar role in the lstv * as our screening procedure in the nmcd .",
    "we conduct comparisons between lstv , lstv * and nmcd under model ( i ) only as the former two methods are not effective for scale changes in model ( ii ) .",
    "the lstv procedure is implemented until the cardinality of the active set is exactly @xmath186 , and both the nmcd and lstv * procedures are implemented by setting @xmath220 and using the bic to estimate the number of change - points .",
    "@@ld1.2cccccccc@ & & & & + & & & & + @xmath230 & & @xmath231 & @xmath232 & @xmath231 & @xmath232 & @xmath233 & @xmath231 & @xmath232 & @xmath233 + 500 & 0.1 & 20.2 & 31.2 & 1.14 & 1.88 & 0.18 & 0.00 & 0.00 & 0.00 + & 0.25 & 23.4 & 29.4 & 1.08 & 2.05 & 0.18 & 0.07 & 0.07 & 0.00 + & 0.5 & 26.1 & 27.0 & 2.10 & 3.14 & 0.17 & 1.39 & 1.30 & 0.03 + 1000 & 0.1 & 43.1 & 60.2 & 2.82 & 2.21 & 0.15 & 0.00 & 0.00 & 0.00 + & 0.25 & 46.2 & 59.4 & 3.23 & 2.24 & 0.16 & 0.04 & 0.04 & 0.00 + & 0.5 & 48.4 & 51.0 & 4.45 & 2.49 & 0.17 & 1.20 & 1.20 & 0.01 + & & + & & +    the results in table  [ tlstv ] show that the proposed nmcd and lstv * substantially outperform lstv in terms of both @xmath206 and @xmath215 .",
    "moreover , the nmcd performs uniformly better than lstv * , which may be partly explained by the fact that the induced shrinkage of lasso often results in significant bias toward zero for large regression coefficients [ @xcite ] .",
    "consequently , the lstv also suffers from such bias , which in turn may lead to unsatisfactory estimation of the locations @xmath3 s . in table",
    "[ tlstv ] , we also report the average computation time of the nmcd and lstv * methods using an intel core 2.2  mhz cpu . for a large sample size , nmcd is much faster .      to examine the setting that the number of change - points increases with the sample size",
    ", we choose seven increasing sample sizes , @xmath2341000 , 1500 , 2000 , 3000 , 5000 , 7500 and 10,000 , under models ( i ) and ( ii ) , respectively .",
    "the number of change - points in model ( i ) is chosen as @xmath235 , corresponding to the values of 13 , 16 , 18 , 22 , 29 , 35 and 40 . in each replication",
    ", we randomly generate the jump sizes @xmath236 as follows : @xmath237 and @xmath238 , @xmath239 , where @xmath240 . in model ( ii ) ,",
    "we take @xmath241 , and we only consider the scale changes ( i.e. , @xmath242 for all @xmath243 ) and the inflation ( deflation ) sizes @xmath244 are chosen as : @xmath245 and @xmath246 , @xmath239 , where @xmath240 .",
    "we take the error distributions to be @xmath193 and @xmath194 in models ( i )  and  ( ii ) , respectively .",
    "we fix @xmath205 , and generate @xmath247 from @xmath248 .",
    "all the tuning parameters are the same as those in section  [ sec4.3 ] .    , @xmath215 , and @xmath249 versus the sample size , respectively .",
    "]    figure  [ fig - diverg ] depicts the curves of @xmath206 , @xmath215 , and @xmath249 versus the sample size , respectively . for both models ,",
    "all the distance values are reasonably small and the three curves are generally stable .",
    "this demonstrates that the nmcd is able to deliver satisfactory detection performance with a diverging number of change - points . from all these numerical studies ,",
    "we conclude that the proposed nmcd is a viable alternative approach to the mcp if we take into account its efficiency , computational speed , and robustness to error distributions and change patterns .",
    "for illustration , we apply the proposed nmcd procedure to identify changes in the isochore structure , which refers to the proportion of the g@xmath250c composition in the large - scale dna bases rather than a or t [ @xcite ; @xcite ] .",
    "such genetic information is important to understand the evolution of base composition , mutation and recombination rates .",
    "figure  [ isochore ] shows the g@xmath250c content in percentage of a chromosome sequence with long homogeneous genome regions characterized by well - defined mean g@xmath250c contents .",
    "c contents , together with the estimated changepoints using the proposed nmcd and lstv * , respectively .",
    "the red and blue solid lines represent the sample means in each segmentation estimated by nmcd and lstv * , respectively . ]",
    "as the data sequence appears to be complicated without any obvious pattern and the sample size is large with @xmath251 , identification of multiple change - points is very challenging .",
    "the data appear to contain quite a few outlying observations , and thus we expect that our nonparametric scheme would produce more robust detection results .",
    "we take the upper bound for the number of change - points as @xmath252 , and set @xmath253 and @xmath254 . after the initial screening procedure ,",
    "305 candidate points remain , which dramatically reduces the dimensionality of change - point detection .",
    "the bic selection criterion further leads to the estimated number of change - points @xmath255 .",
    "the entire procedure is completed in  54  seconds using an intel core 2.2  mhz cpu .",
    "it can be seen from figure  [ isochore ] that the change - point estimates are generally reasonable based on the proposed nmcd procedure .",
    "it can detect some local and sharp features as well as those long unchanged data segments . for comparison ,",
    "we also apply the lstv * to the same dataset , and exhibit the result in figure  [ isochore ] .",
    "the estimated number of change - points using lstv * is @xmath256 .",
    "we can see that both methods perform well , and the line segments of the two methods are largely overlapping , except that the nmcd tends to detect relatively more picks or sharp changes .",
    "some large changes could be overlooked by lstv * due to the lasso - type bias for large coefficients .",
    "this also explains that the number of change - points identified by the lstv * is smaller than that of the proposed nmcd .",
    "we performed the shapiro ",
    "wilk goodness - of - fit tests for normality on the 44 segments identified by nmcd and found that 34 tests are significant under the 0.01 nominal level . as an example",
    ", figure  [ figegana ] shows the normal qq - plot of the fifth segment , from which we can conclude that its distribution is far from normal .",
    "furthermore , the density estimation of two consecutive segments ( the 5th and 6th ) shown in figure  [ figegana ] indicates that the two distributions differ not only in the location but also in the scale and shape . in light of these characteristics ,",
    "our nmcd procedure is more desirable than those parametric methods which need to specify the mean or scale changes in advance .",
    "in the mcp , we have proposed a nonparametric likelihood - based method for detection of multiple change - points .",
    "the consistency of the proposed nmcd procedure is established under mild conditions .",
    "the true number of change - points is assumed to be unknown , and the bic is used to choose the number of change - points . to facilitate the implementation of nmcd , we suggest a dp algorithm in conjunction with a screening procedure , which has been shown to work well , particularly in large datasets . the computational scheme is fast and competitive with existing methods and , furthermore ,",
    "numerical comparisons show that nmcd is able to strike a better balance for over- and under - segmentation errors with nonnormal data and even has comparable performance with the parametric model under the correctly specified distributional assumption .",
    "the proposed method is based on the assumption that there exists at least one change point . in practical applications ,",
    "we need to use some tests within the nonparametric context to verify this assumption .",
    "the tests proposed by @xcite and @xcite are suited for this purpose .",
    "our proposed nmcd is an omnibus method , and thus can not diagnose whether a change occurs in the location , scale , or shape . to further determine which parameter changes , additional nonparametric tests need to be used as an auxiliary tool .",
    "moreover , research is warranted to extend our method to other settings , such as the autocorrelated observations , multivariate cases [ @xcite ] , and multiple structural changes in linear models [ @xcite ] .",
    "first of all , we present a lemma in wellner ( @xcite ) .",
    "let @xmath257 denote the empirical c.d.f . of a random sample of @xmath9 uniform random variables on @xmath258 , and define @xmath259 and .",
    "[ wl ] for all @xmath260 and @xmath261 ,    @xmath262 ,    @xmath263 ,    @xmath264 ,    @xmath265 ,    @xmath266 ,    where @xmath267 and @xmath268 .    before proceeding further",
    ", we state a key lemma , which allows us to control the supremum of the likelihood function .",
    "[ klem4 ] suppose that assumptions hold and @xmath269 .",
    "let @xmath270 , then @xmath271 where @xmath272 @xmath273 and @xmath274 is given in the proof .",
    "without loss of generality , suppose that @xmath275 is uniform on @xmath189 $ ] and @xmath276 .",
    "then we have @xmath277 where @xmath278 by setting @xmath279 , @xmath280 , and noting that @xmath281 , we write @xmath282    first , we provide an upper bound for @xmath283 , where @xmath284 with @xmath285to show this , we choose @xmath286 such that as @xmath134 , @xmath287 based on assumption ( a2 ) and the fact that @xmath288 by using lemma [ wl](iv ) .",
    "similarly , @xmath289    also , we consider the event @xmath290 , and thus @xmath291 by choosing a proper @xmath292 . in parallel , let @xmath293 , and we have @xmath294 and @xmath295 .    for the interaction of the events @xmath296 , @xmath297 , and @xmath298 we have @xmath299 as @xmath134 . consequently , as @xmath134 , @xmath300 where the probability @xmath301 would be zero when @xmath9 is sufficiently large , as long as @xmath302 .",
    "similarly , we can show that @xmath303 as @xmath134 .",
    "thus , @xmath304 by symmetry , we immediately have @xmath305 thus , it remains to give a bound of @xmath306 .",
    "following similar argument in the proof of theorem  3.1 of @xcite , we can express @xmath307 as @xmath308 for @xmath309 where @xmath310 .",
    "then we rewrite @xmath311 as @xmath312 consider the event @xmath313 for some @xmath314 and , by applying lemma [ wl](v ) , we have @xmath315 on the event @xmath316 and @xmath317 , we have @xmath318 symmetrically , we also have @xmath319 on the event @xmath320 , where @xmath321 occurs with the probability tending to zero . on the other hand , by using lemma [ wl](v ) again , it is easy to see that , for sufficiently large @xmath9 , @xmath322 where the constant @xmath323 depends on @xmath324 .",
    "now , we consider the term @xmath325 , and let @xmath326 . by taking @xmath327 in inequality 11.2.1 of @xcite [ ( @xcite ) , page  446 ] ,",
    "@xmath328 where @xmath329 , @xmath330 , and @xmath331 . by using the fact that @xmath332 as @xmath333 [ proposition 11.1.1 in @xcite ] , @xmath334 for sufficiently large @xmath274 .",
    "consequently , we have @xmath335 as long as @xmath274 is sufficiently large . by symmetry",
    ", we can also show that @xmath336 finally , we obtain as @xmath134 , @xmath337 which completes the proof of this lemma .",
    "by lemma [ klem4 ] , the next lemma follows immediately .",
    "[ klem ] suppose that assumptions hold and @xmath338 .",
    "then @xmath339 where @xmath340 with a sufficiently large @xmath274 .",
    "let @xmath341 be a sequence of positive random variables @xmath342 if for any @xmath110 , @xmath343 where @xmath274 is a constant depending only on @xmath344 .    [ yl2 ]",
    "suppose that assumptions hold .",
    "for any @xmath345 and @xmath346 , as @xmath77 , @xmath347    by noting that @xmath348 is a convex function , the left inequality is obvious . without loss of generality ,",
    "we assume @xmath54 , and for @xmath349 the result follows by induction . by the fact that @xmath350 , @xmath351 similarly , for any @xmath67 , we have @xmath352 thus , for any @xmath110 , @xmath353 where the last result follows immediately from lemma [ klem ] .    next , we demonstrate that the global minimum of the bic includes no less than @xmath2 change - point estimators asymptotically .",
    "[ prol ] if assumptions hold , @xmath354 .",
    "define @xmath355 , and consider @xmath356 .",
    "let @xmath357 @xmath358 .",
    "for @xmath359 , @xmath360 must belong to one @xmath361 .",
    "for every @xmath362 , we have @xmath363\\\\[-8pt ] & & \\qquad \\leq r_n\\bigl ( \\tau_1',\\ldots,\\tau_{l } ' , \\tau_1,\\ldots,\\tau_{r-1},\\tau_r- \\rho_n , \\tau_r+\\rho_n,\\tau_{r+1 } , \\ldots,\\tau_{k_n}\\bigr)\\nonumber\\end{aligned}\\ ] ] and the right - hand side of ( [ yao10 ] ) can be expressed as @xmath364 , where @xmath365 ( @xmath366 ) is the sum of integrals involving the @xmath367 s ( @xmath368 ) ; @xmath369 is that involving the @xmath367 s ( @xmath370 ) ; @xmath371 is that involving the @xmath367 s ( @xmath372 ) ; @xmath373 is that involving the @xmath367 s ( @xmath374 ) . for @xmath366 , by lemma [ yl2 ] , we have @xmath375 where @xmath376 .",
    "similarly , we have @xmath377 and in addition , @xmath378 where @xmath379 .",
    "note that @xmath380\\,dw(u ) \\\\ & & { } -\\rho_n\\int_{x_{(1)}}^{x_{(n)}}\\bigl [ { \\widehat{f}}_{\\tau_r-\\rho _ n}^{\\tau _ r}(u)\\log\\bigl(f_{r}(u)\\bigr ) \\\\ & & \\hspace*{54pt } { } + \\bigl\\{1-{\\widehat{f}}_{\\tau_r-\\rho_n}^{\\tau _ r}(u)\\bigr\\}\\log \\bigl(1-f_{r}(u)\\bigr)\\bigr]\\,dw(u ) \\\\ & & { } -\\rho_n\\int_{x_{(1)}}^{x_{(n)}}\\bigl [ { \\widehat{f}}_{\\tau_r}^{\\tau _ r+\\rho _ n}(u)\\log\\bigl(f_{{r+1}}(u)\\bigr ) \\\\ & & \\hspace*{53pt}{}+ \\bigl\\{1-{\\widehat{f}}_{\\tau_r}^{\\tau_r+\\rho _ n}(u)\\bigr\\}\\log \\bigl(1-f_{{r+1}}(u)\\bigr)\\bigr]\\,dw(u)+\\widetilde{o}_p(b_n;k_n ) \\\\ & = & -\\rho_n\\int_{x_{(1)}}^{x_{(n)}}\\biggl [ { \\widehat{f}}_{\\tau_r-\\rho _ n}^{\\tau _ r}(u)\\log\\biggl(\\frac{f_{r}(u)}{f_{r,1/2}(u ) } \\biggr ) \\\\ & & \\hspace*{53pt}{}+\\bigl\\{1-{\\widehat{f}}_{\\tau _ r-\\rho_n}^{\\tau_r}(u)\\bigr\\}\\log \\biggl ( \\frac{1-f_{r}(u)}{1-f_{r,1/2}(u ) } \\biggr)\\biggr]\\,dw(u ) \\\\ & & { } -\\rho_n\\int_{x_{(1)}}^{x_{(n)}}\\biggl [ { \\widehat{f}}_{\\tau_r}^{\\tau _ r+\\rho _ n}(u)\\log\\biggl(\\frac{f_{\\tau_{r+1}}(u)}{f_{r,1/2}(u ) } \\biggr ) \\\\ & & \\hspace*{54pt}{}+\\bigl\\ { 1-{\\widehat{f}}_{\\tau_r}^{\\tau_r+\\rho_n}(u)\\bigr\\}\\log \\biggl(\\frac { 1-f_{{r+1}}(u)}{1-f_{r,1/2}(u ) } \\biggr)\\biggr]\\,dw(u ) \\\\ & & { } + \\widetilde{o}_p(b_n;k_n ) \\\\ & \\equiv&-\\widetilde{\\delta}+\\widetilde{o}_p(b_n;k_n).\\end{aligned}\\ ] ] let @xmath381 , and then @xmath382\\,dw(u ) \\\\ & = & \\rho_n\\int_{0}^{1}\\biggl [ { \\widehat{f}}_{\\tau_r-\\rho_n}^{\\tau_r}(u)\\log\\biggl(\\frac { f_{r}(u)}{f_{r,1/2}(u ) } \\biggr ) \\\\ & & \\hspace*{30pt}{}+\\bigl\\{1-{\\widehat{f}}_{\\tau _ r-\\rho_n}^{\\tau _",
    "r}(u)\\bigr\\}\\log \\biggl(\\frac{1-f_{r}(u)}{1-f_{r,1/2}(u ) } \\biggr)\\biggr]\\,dw(u ) \\\\ &",
    "\\equiv&\\widetilde{\\delta}_{1}'.\\end{aligned}\\ ] ] by assumption ( a3 ) , we have @xmath383 \\\\ & & \\hspace*{25pt}{}\\times\\frac{1}{f(u)(1-f(u))}\\,df(u ) \\bigl(1+o(1)\\bigr),\\qquad\\mbox{a.s.}\\end{aligned}\\ ] ] using the similar procedure , we can obtain the corresponding bound for @xmath384 . as a result , as @xmath103 , @xmath385 \\\\ & & \\hspace*{30pt}{}\\times\\frac{1}{f(u)(1-f(u))}\\,df(u ) \\\\ & & \\hspace*{15pt}{}+\\int_{0}^{1 } \\biggl[f_{{r+1}}(u)\\log \\biggl(\\frac { f_{{r+1}}(u)}{f_{r,1/2}(u ) } \\biggr)+ \\bigl\\{1-f_{{r+1}}(u)\\bigr\\}\\log \\biggl ( \\frac { 1-f_{{r+1}}(u)}{1-f_{r,1/2}(u ) } \\biggr ) \\biggr ] \\\\ & & \\hspace*{209pt}{}\\times\\frac{1}{f(u)(1-f(u))}\\,df(u ) \\biggr\\ } \\\\ & \\equiv&\\rho_n s(f_{{r}},f_{{r+1}}),\\end{aligned}\\ ] ] in which the distance @xmath386 is strictly larger than zero .",
    "therefore , @xmath387 let @xmath388 , and for @xmath359 , with probability tending to 1 , we have @xmath389 as @xmath134 . for any @xmath110 , we have , as @xmath390 , @xmath391 this completes the proof of this proposition .",
    "let @xmath392 denote the set of global minimum of bic with @xmath72 and its cardinality is @xmath67 .",
    "[ prou ] suppose that assumptions hold . for @xmath393 and @xmath394 as @xmath134 , where @xmath395    for every @xmath396 , @xmath397\\\\[-8pt ] & & \\qquad \\leq r_n\\bigl ( \\tau_1',\\ldots,\\tau_{l } ' , \\tau_1,\\ldots,\\tau_{r-1},\\tau_r- \\delta_n,\\tau_r+\\delta_n , \\tau_{r+1},\\ldots,\\tau_{k_n}\\bigr)\\nonumber\\end{aligned}\\ ] ] and the right - hand side of ( [ yao11 ] ) can be expressed as @xmath364 , where @xmath365 ( @xmath366 ) is the sum of squares involving the @xmath367 s ( @xmath368 )",
    "; @xmath369 is that involving the @xmath367 s ( @xmath370 ) ; @xmath371 is that involving the @xmath367 s ( @xmath398 ) ; @xmath373 is that involving the @xmath367 s ( @xmath399 ) .",
    "define @xmath400 .",
    "it can be further seen that uniformly in @xmath396 , @xmath401 these results imply that @xmath402 thus , as @xmath103 , @xmath403 for any @xmath110 .",
    "thus , the result follows .",
    "proof of theorem  [ teo1 ] define @xmath404 . for every @xmath405 , @xmath406 by lemma [ klem4 ] .",
    "thus , we know that @xmath407 with probability tending to one for each @xmath408",
    ". consequently , @xmath409 by the similar argument as that in proposition [ prou ] .",
    "proof of theorem  [ probic ] by proposition [ prol ] , it suffices to show that @xmath410 .",
    "this can be proved by contradiction .",
    "let @xmath411 be the complement of the union of @xmath412 .",
    "as shown in proposition [ prou ] , for @xmath413 and every @xmath414 , @xmath415 consequently , as @xmath103 , @xmath416 we obtain the result by the same argument as that in proposition [ prol ] .",
    "the authors would like to thank professor runze li , an associate editor , and three anonymous referees for their many insightful and constructive comments that have resulted in significant improvements in the article ."
  ],
  "abstract_text": [
    "<S> in multiple change - point problems , different data segments often follow different distributions , for which the changes may occur in the mean , scale or the entire distribution from one segment to another . without the need to know the number of change - points in advance , we propose a nonparametric maximum likelihood approach to detecting multiple change - points </S>",
    "<S> . our method does not impose any parametric assumption on the underlying distributions of the data sequence , which is thus suitable for detection of any changes in the distributions . </S>",
    "<S> the number of change - points is determined by the bayesian information criterion and the locations of the change - points can be estimated via the dynamic programming algorithm and the use of the intrinsic order structure of the likelihood function . under some mild conditions , </S>",
    "<S> we show that the new method provides consistent estimation with an optimal rate . </S>",
    "<S> we also suggest a prescreening procedure to exclude most of the irrelevant points prior to the implementation of the nonparametric likelihood method . </S>",
    "<S> simulation studies show that the proposed method has satisfactory performance of identifying multiple change - points in terms of estimation accuracy and computation time .    ,    ,     + </S>"
  ]
}