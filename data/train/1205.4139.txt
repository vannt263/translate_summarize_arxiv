{
  "article_text": [
    "compressed sensing ( cs ) is a novel sampling technique , where one can recover sparse signals from the undersampled measurements @xcite . in a typical cs problem",
    ", the goal is to exactly reconstruct the @xmath0 @xmath1-_sparse signal vector _",
    "@xmath2 based on the @xmath3 _ measurement vector _ @xmath4 . by @xmath1-sparse",
    "we mean that there are at most @xmath1 nonzero elements in @xmath2 .",
    "the vectors @xmath2 and @xmath4 are linearly related to each other as @xmath5 where @xmath6 is the @xmath7 _ sensing matrix _ and @xmath8 is the @xmath3 noise vector . and",
    "the relation of @xmath1 , @xmath9 , and @xmath10 is generally @xmath11 .    for the sensing matrix @xmath6 , partial fourier matrices and partial hadamard matrices are popular sensing matrices , where we mean that the partial matrix is constructed by some @xmath9 rows of @xmath12 original matrix @xmath13 . in other words , @xmath14 , where @xmath15 is the @xmath16 row selection matrix consisting of @xmath9 rows ( indices from some index set @xmath17 ) of @xmath12 identity matrix @xmath18 .",
    "firstly , the partial fourier matrix is frequently used because of its good recovery performance , fast implementation using the fast fourier transform ( fft ) , and applicability to practical signals .",
    "the examples include channel estimation in communication systems @xcite and magnetic resonance imaging ( mri ) @xcite . for the partial fourier matrix , the index set @xmath17",
    "can be constructed randomly or based on the cyclic difference set @xcite .",
    "secondly , some recent researches showed that well - designed deterministic sensing matrices based on linear block codes have better performance and less complexity for signal recovery compared to random sensing matrices @xcite , @xcite .",
    "it is well known that a sensing matrix whose columns are bipolar - presented codewords of a binary linear block code can be viewed as a partial hadamard matrix .",
    "and we can exploit the efficiency of the fast hadamard transform ( fht ) .",
    "to recover @xmath2 in ( [ eq : csbasic ] ) , matching pursuit algorithms ( mpas ) find a sparse estimation of the signal @xmath2 from @xmath4 in a greedy fashion .",
    "it works iteratively by choosing the component that has the highest correlation with the current residual .",
    "examples include the orthogonal matching pursuit ( omp ) @xcite and its modified versions such as the compressive sampling matching pursuit ( cosamp ) @xcite , the regularized omp ( romp ) @xcite , the subspace pursuit ( sp ) @xcite , and the backtracking - based matching pursuit ( bb mp ) @xcite .",
    "for instance , we summarize the omp which is the most basic algorithm among the mpas .",
    "the steps marked by @xmath19 are the common steps to the mpas .    ' '' ''",
    "* algorithm 1.1 conventional omp recovery algorithm *    ' '' ''    1 .",
    "initialize : @xmath20 , @xmath21 , @xmath22 .",
    "@xmath19 2 .",
    "correlation computation : @xmath23 .",
    "@xmath19 3 .",
    "identification : @xmath24 4 .",
    "augment the index set : @xmath25 .",
    "5 .   construct @xmath26 : @xmath27 .",
    "@xmath19 6 .",
    "least squares : @xmath28 . 7 .",
    "update current residual : @xmath29 , @xmath30 .",
    "@xmath19 8 .",
    "@xmath31 , return to 2 ) if the halting criterion is not triggered .",
    "@xmath19    ' '' ''    in algorithm 1.1 , performing @xmath23 in 2 ) can be viewed as computing the correlations between the current residual @xmath32 and the columns of @xmath6 .",
    "and we denote @xmath33 as the correlation vector at the @xmath34-th iteration .",
    "the whole computational complexity of the omp is dominated by the correlation computation step and so are the other mpas.    in this letter , we propose a new fast correlation computation method which can be applied to almost all mpas including omp , cosamp , romp , sp , and bb mp .",
    "the recovery performances of the mpas applied by the proposed method are exactly the same as those of the original mpas . and",
    ", for most practical parameters , the proposed method can reduce the computational complexity of the mpas substantially .",
    "the proposed method can operate only when the sensing matrix is the partial unitary matrix satisfying the following two constraints :    1 .",
    "every element of the unitary matrix @xmath35 has the magnitude @xmath36 .",
    "the set @xmath37 , where @xmath38 is the @xmath39-th column of @xmath35 , is closed under element - wise multiplication @xmath40 .    at a glance , the above constraints seem to be too strict , however , the fourier matrix and the hadamard matrix are two kinds of the unitary matrices with these constraints .",
    "therefore , the proposed method is meaningful and it can be widely adopted in cs .",
    "in this section , we describe the proposed fast correlation computation method for general mpas .",
    "the mpas have the common steps marked by @xmath19 in algorithm 1.1 and we derive the fast correlation computation method based on only those steps . in the following derivation , @xmath35 is the unitary matrix satisfying the two constraints and the sensing matrix is @xmath41 . for simplicity ,",
    "we handle not the @xmath34-th iteration but the @xmath42-th iteration .    using the steps 5 ) and 7 ) in algorithm 1.1 ,",
    "the correlation computation step 2 ) at the @xmath42-th iteration @xmath43 can be rewritten as @xmath44 where @xmath45 .    in ( [ eq : corr_com ] ) , @xmath46 can be represented as @xmath47 where @xmath48 is the @xmath49-th column of @xmath18 , @xmath50 is the cardinality of the index set @xmath51 , and @xmath52 is the @xmath53-th element of @xmath54 . by using ( [ eq :",
    "corr_com ] ) and ( [ eq : superposition ] ) , we obtain @xmath55    without loss of generality , we assume the first column of @xmath35 is @xmath56 . and ( [ eq : superposition2 ] ) can be rewritten as @xmath57 where @xmath58 and @xmath59 is the @xmath49-th column of @xmath35 . because the matrix @xmath60 is the diagonal matrix , @xmath61 and ( [ eq : superposition3 ] )",
    "can be rewritten as @xmath62    we denote @xmath63 and thus @xmath64 .",
    "consequently , the correlation computation at the @xmath42-th iteration can be expressed as @xmath65 where @xmath66 which is called the _ correlation kernel vector_. note that the correlation kernel vector @xmath67 is independent to the sparse signal vector @xmath2 and thus can be stored in advance .",
    "the matrix @xmath68 in ( [ eq : kernelsum ] ) is a permutation matrix according to the following theorem .",
    "the permutation matrix can be performed with negligible computational complexity because of its structure .",
    "* theorem 2 - 1 * : @xmath63 is a permutation matrix ( i.e. , a square binary matrix that has exactly one element 1 in each row and each column and @xmath69s elsewhere ) if the unitary matrix @xmath35 is under the two constraints .",
    "_ proof of theorem 2 - 1 _ : @xmath70 can be expressed as @xmath71    @xmath72 , @xmath73 , are distinct column vectors because their elements are nonzero by the first constraint of @xmath35 . and",
    "each vector belongs to the set @xmath37 because of the second constraint of @xmath35 .",
    "therefore , ( [ eq : appendix1 ] ) can be rewritten as @xmath74 where @xmath68 is the permutation matrix which is determined by @xmath75 and the structure of @xmath35 .",
    "@xmath76    to sum it up , the correlation computation at the @xmath34-th iteration ( i.e. , computing @xmath33 ) can be performed by @xmath77 subtractions of properly scaled and permutated versions of the correlation kernel vector @xmath67 to the initial correlation vector @xmath78 .",
    "in this section , we apply the fast correlation computation method to the conventional omp . and",
    "we discuss the complexity of the proposed omp algorithm applied by the proposed method . applying the proposed correlation computation method to other",
    "mpas is straightforward and entirely analogous with this section .",
    "the proposed correlation computation method ( [ eq : kernelsum ] ) for a general mpa can be easily converted for the omp as @xmath79 and the proposed omp recovery algorithm can be given by simply replacing the correlation computation step 2 ) in algorithm 1.1 with ( [ eq : kernelsumomp ] ) .",
    "note that the proposed omp algorithm is actually identical to the conventional omp algorithm .",
    "the only difference is the computation method and thus the proposed omp guarantees the same recovery performance compared to the conventional omp .      in this subsection",
    ", we investigate the computational complexity of the proposed omp algorithm in the cases of using the partial fourier matrix and the partial hadamard matrix .",
    "firstly , for each matrix , we will discuss the properness of the proposed algorithm in terms of the storage requirements for the permutation matrices .",
    "secondly , we compare the computational complexity of the proposed omp algorithm to that of the conventional omp algorithm . for the exact comparison",
    ", we consider the number of flops of each algorithm .",
    "and we regard one complex multiplication as @xmath80 flops and one complex addition as @xmath81 flops .",
    "we remark that the proposed omp performs the @xmath82 subtractions of properly scaled and permutated versions of the correlation kernel vector at the @xmath34-th iteration to compute the correlation vector in the second equation in ( [ eq : kernelsumomp ] ) .",
    "we consider the case when @xmath10 is a power of two , which is used very often in signal processing .",
    "but , the proposed method can be used for any @xmath10 .",
    "when we use the partial fourier matrix as the sensing matrix , from the discrete fourier transform ( dft ) properties , @xmath83 is the matrix which cyclically shifts @xmath67 when @xmath83 is multiplied with the vector @xmath67 from the left .",
    "therefore , the storage requirements for the permutation matrices can be negligible .",
    "it is well known that the correlation computation at each iteration in the conventional omp can be implemented by the @xmath10-point fft .",
    "the @xmath10-point fft requires @xmath84 flops .    for the proposed omp , in ( [ eq : kernelsumomp ] )",
    ", the first iteration ( @xmath22 ) can be implemented by one fft . and , when @xmath85 , the correlation vector is computed by using the correlation kernel vector . exploiting the conjugate symmetric property of the correlation kernel vector using the partial fourier matrix as the sensing matrix , performing the second equation in ( [ eq : kernelsumomp ] ) has the cost of @xmath86 complex multiplications , @xmath87 real additions , and @xmath88 complex additions at the @xmath34-th iteration .",
    "aggregately , the proposed omp requires @xmath89 flops at the @xmath34-th iteration .",
    "t & @xmath90 & @xmath91 + conventional omp & @xmath84 & @xmath84 + proposed omp & @xmath84 & @xmath89 +   +   + t & @xmath90 & @xmath91 + conventional omp & @xmath92 & @xmath92 + proposed omp & @xmath92 & @xmath93 +      the storage requirements of the proposed omp algorithm with partial hadamard matrix are also favorable .",
    "there is no need to store the entire @xmath10 permutation matrices .",
    "if we store only the @xmath94 permutation matrices , the permutation matrix @xmath83 for any @xmath95 can be easily performed by sequentially applying some matrices among the stored @xmath94 permutation matrices .",
    "it is easily induced from the properties of the hadamard matrix .",
    "it is well known that the correlation computation at each iteration in the conventional omp can be implemented by the @xmath10-point fht .",
    "the @xmath10-point fht requires @xmath96 complex additions ( i.e. , @xmath92 flops ) .",
    "for the proposed omp , in ( [ eq : kernelsumomp ] ) , the first iteration ( @xmath22 ) can be implemented by one fht . and , when @xmath85 , the correlation vector is computed by using the correlation kernel vector . because the correlation kernel vector consists of only a small number of values compared to @xmath10 using the partial hadamard matrix as the sensing matrix , performing the second equation in ( [ eq : kernelsumomp ] ) has approximately the cost of @xmath88 complex additions .",
    "table i summarizes this subsection .",
    "here we present some numerical results characterizing the performance of the proposed omp algorithm compared to the conventional omp algorithm .",
    "the results were produced using the partial fourier matrices and the partial hadamard matrices with practical and various sizes .",
    "and we plot the computational complexities for @xmath97 , which is reasonable for given @xmath9 and @xmath10 .      fig .",
    "[ fig : omp_3n ] shows the relative computational complexity of the proposed omp compared to the conventional omp when the partial fourier matrices are used . because the computational complexity of the proposed omp algorithm at the @xmath34-th iteration is proportional to @xmath98",
    ", there is a excessive point and thus adaptive strategy is needed .",
    "for instance , for @xmath99 and @xmath100 , @xmath101 is the excessive point and the conventional omp can be used from the @xmath102-th iteration .",
    "consequently , the proposed omp algorithm has a benefit to reduce the computational complexity substantially .",
    "especially , for large @xmath10 , the proposed omp has a good benefit .",
    "[ fig : omp_3n_hdm ] shows the relative computational complexity of the proposed omp compared to the conventional omp when the partial hadamard matrices are used . like the case of using the partial fourier matrices in fig .",
    "[ fig : omp_3n ] , the proposed omp algorithm has a benefit to reduce the computational complexity substantially .      besides the proposed omp",
    ", we present the numerical result when the proposed correlation computation method is applied to the cosamp  @xcite . due to lack of space",
    ", we leave out the detailed description of the proposed cosamp .",
    "[ fig : csmp ] shows the relative computational complexity of the proposed cosamp compared to the conventional cosamp at the @xmath34-th iteration .",
    "we use the partial fourier matrices as the sensing matrix .",
    "different to the proposed omp , the proposed cosamp requires the same computational cost at each iteration except when @xmath22 .",
    "especially , the proposed cosamp algorithm has a good benefit for small @xmath1 and large @xmath10 .",
    "for instance , when @xmath99 , @xmath103 , and @xmath104 , the proposed cosamp requires only the @xmath105 computational cost compared to the conventional cosamp .",
    "r. calderbank , s. howard , and s. jafarpour , `` construction of a large class of deterministic sensing matrices that satisfy a statistical isometry property , '' _ ieee j. sel",
    ". topics signal process .",
    "2 , pp . 358374 , apr .",
    "s. hong , h. park , b. shin , j .- s .",
    "no , and h. chung , `` a new performance measure using @xmath106-set correlation for compressed sensing matrices , '' _ ieee signal process .",
    "3 , pp . 143146 , mar .",
    "2012 .",
    "d. needell and r. vershynin , `` signal recovery from incomplete and inaccurate measurements via regularized orthogonal matching pursuit , '' _ ieee j. select .",
    "top . signal process .",
    "2 , pp . 310316 , apr . 2010 ."
  ],
  "abstract_text": [
    "<S> there have been many matching pursuit algorithms ( mpas ) which handle the sparse signal recovery problem a.k.a . </S>",
    "<S> compressed sensing ( cs ) . in the mpas </S>",
    "<S> , the correlation computation step has a dominant computational complexity . in this letter </S>",
    "<S> , we propose a new fast correlation computation method when we use some classes of partial unitary matrices as the sensing matrix . </S>",
    "<S> those partial unitary matrices include partial fourier matrices and partial hadamard matrices which are popular sensing matrices . </S>",
    "<S> the proposed correlation computation method can be applied to almost all mpas without causing any degradation of their recovery performance . and </S>",
    "<S> , for most practical parameters , the proposed method can reduce the computational complexity of the mpas substantially .    </S>",
    "<S> compressed sensing ( cs ) , fast correlation computation , fourier matrix , hadamard matrix , matching pursuit algorithm ( mpa ) . </S>"
  ]
}