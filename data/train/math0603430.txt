{
  "article_text": [
    "spatial random fields ( srf s ) have a wide range of applications in subsurface hydrology @xcite , petroleum engineering @xcite , environmental data analysis @xcite , mining exploration and reserves estimation @xcite , and environmental health @xcite among other fields . from the applications viewpoint ,",
    "the main goals are first to characterize the spatial continuity of such processes , and then to exploit the continuity for spatial estimation ( prediction ) and simulation .",
    "a methodological problem of continuing interest is the inference of the random field parameters that characterize the spatial continuity from the experimental data .",
    "the latter are typically distributed on irregular sampling grids .",
    "this paper seeks to address the issue of random field inference within the context of a specific model , the fluctuation - gradient - curvature ( fgc ) spartan spatial random field ( ssrf ) , which was introduced in @xcite .",
    "ssrfs result from a convolution of a kernel function with an underlying srf that may include non - resolved fine - scale detail at length scales below @xmath0 .",
    "the kernel function acts as a low - pass filter that suppresses the spectral component of fluctuations above a cutoff wavevector @xmath1 the removed part corresponds to sub - resolution scales .",
    "we will denote _ sample averages _ with a horizontal bar over the averaged quantity , and _",
    "ensemble averages _ with the mathematical expectation symbol , i.e. , @xmath2 $ ] . without loss of generality in the following it is assumed that @xmath3    let the data be given by the measurements @xmath4 , of the scalar quantity @xmath5 at the set of sampling locations @xmath6 in the domain @xmath7 .",
    "the area enclosed by the convex hull of @xmath8 is denoted by @xmath9 .",
    "we assume that the data can be modeled as a _ sample _ ( realization ) of @xmath10 , which is a gaussian , weakly stationary , isotropic fgc - ssrf .",
    "the isotropic assumption is not a major restriction , since under certain conditions the anisotropic parameters can be established and isotropic conditions can be restored by rotation and rescaling transformations @xcite .",
    "the isotropic fgc - ssrf involves the _ parameter set _",
    "@xmath11 : the _ scale coefficient _",
    "@xmath12 determines the variance , the _ shape coefficient _",
    "@xmath13 determines the shape of the covariance function , the _ characteristic length _",
    "@xmath14 determines the range of spatial dependence , and @xmath15 is a _ wavevector cutoff _ related to the resolution scale @xmath0 @xcite .",
    "regarding parameter inference , the main idea introduced in @xcite and further elaborated here , is that the ssrf model parameters can be estimated by matching sample constraints and their ensemble counterparts .",
    "the model parameters are determined by treating the sample constraints as estimators of the respective stochastic constraints .",
    "this perspective relies on the validity of the _ ergodic hypothesis _",
    "@xcite .",
    "the constraint matching idea is similar to the standard approach , in which the experimental variogram is matched with various model functions to determine an optimal model of spatial continuity .",
    "however , there are significant differences between the two approaches .",
    "( 1 ) in the ssrf approach the number of estimated constraints is small ( four in the case of the fgc - ssrf ) .",
    "this is due to the efficient parametrization of spatial dependence in the fgc - ssrf , which is based on interactions instead of the covariance matrix .",
    "in contrast , variogram modeling attempts to match the entire functional dependence of the variogram function . ( 2 ) the fgc - ssrf includes a family of covariance functions that account for various types of spatial continuity @xcite .",
    "hence , in practice fitting the sample constraints with one ssrf model may be sufficient .",
    "in contrast , the experimental variogram is fitted with a number of model functions to determine the `` optimal '' spatial model .",
    "( 3 ) the ssrf sample constraints focus on the short - range behavior of spatial continuity .",
    "this is motivated by two observations : in geostatistical applications , the long - range behavior can only be estimated with significant uncertainty ; in addition , it is known that the long - range behavior does not have a significant impact on optimal linear prediction in regions where the field is densely sampled @xcite . ( 4 ) the computational complexity of ssrf constraint calculations , at least on regular grids , is @xmath16 , where @xmath17 is @xmath18 and depends on the kernel bandwidth , while for variogram calculations the respective complexity is at best @xmath19 if tree - based structures are used , or @xmath20 using standard methods @xcite .",
    "the main results obtained in this paper include the following : ( 1 ) generalized gradient and curvature estimators are formulated in terms of kernel averages , and a consistent method for selecting the kernel bandwidths is proposed .",
    "the generalized gradient and curvature estimators have a wider scope than the fgc - ssrf model : they are defined for both differentiable and continuous ( but non - differentiable ) spatial models . in the differentiable case ,",
    "the estimators are defined in terms of finite - difference approximations of the respective derivatives . in the continuous case ,",
    "the finite differences are not divided by the corresponding length spacing ( step ) in order to obtain asymptotically well defined quantities .",
    "( 2 ) convergence properties for the generalized gradient and curvature estimators are proved .",
    "( 3 ) the constraint - based parameter inference procedure introduced in @xcite is improved by adding a constraint that eliminates the nonlinear dependence of the model variance on the fgc - ssrf parameters .",
    "( 4 ) numerical simulations establish the performance of the constraints estimators and the parameter inference procedure .",
    "the remaining of this paper is structured as follows : an introduction to the fgc - ssrf in continuum space is given in section  ( [ sec : fgc - ssrf ] ) . in section  ( [ sec :",
    "constraint ] ) the definition of the sample constraints on regular grids is reviewed .",
    "this is followed by the definition of generalized stochastic constraints for the fgc - ssrf in section  ( [ sec : cons - irreg ] ) .",
    "generalized sample constraints for the gradient and curvature are defined in section  ( [ sec : sample ] ) .",
    "theorems establishing the convergence of the constraint estimators are stated and proved in section  ( [ sec : asympt ] ) .",
    "subsequently , the parameter inference process developed in @xcite is reviewed and refined in section  ( [ sec : inference ] ) .",
    "finally , numerical simulations are used to validate the estimators and the parameter inference process in section  ( [ sec : simul ] ) .",
    "in general , a _ gibbs _",
    "random field has the following joint probability density function ( p.d.f . ) @xmath21 = \\frac          { \\exp \\left\\ { { - h[x_\\lambda ( { \\bf s});{\\bm \\theta } ] } \\right\\ } }          { z({\\bm \\theta})},\\ ] ] where @xmath22 $ ] is the _ energy functional _ , @xmath23 is a set of _ model parameters _ , and the constant @xmath24 , called the _",
    "partition function _ is the p.d.f .",
    "normalization factor obtained by integrating @xmath25 \\right\\ } $ ] over all the realizations of the srf . the fgc p.d.f . in @xmath26",
    "is determined from the equation :    @xmath27 = \\frac{1}{{2\\eta _ 0 \\xi ^d } } \\int d{\\bf s } \\",
    ", \\textsl{h}_{\\rm fgc } \\left [ { x_\\lambda({\\bf s});{\\bm \\theta ' } } \\right],\\ ] ]    where @xmath28 , and @xmath29 is the normalized ( to @xmath30 ) local energy density at point @xmath31 .",
    "the functional @xmath32 $ ] is given _ in the continuum _ by the following expression    @xmath33 = \\left [ { x_\\lambda ( { \\bf s } ) } \\right]^2 + \\eta _ 1 \\,\\xi ^2 \\left [ { \\nabla x_\\lambda ( { \\bf s } ) } \\right]^2   + \\xi ^4 \\left [ { \\nabla ^2 x_\\lambda ( { \\bf s } ) } \\right]^2 , \\ ] ]    the functional ( [ fgccont ] ) is permissible if the resulting covariance function is positive definite , i.e. , if it satisfies _",
    "bochner s theorem _ @xcite .",
    "permissibility constrains the value of @xmath34 ( see @xcite,@xcite ) .",
    "the explicit , albeit non - linear , dependence of the p.d.f . on three physically meaningful parameters ,",
    "@xmath35 instead of three linear coefficients multiplying the terms @xmath36 ^ 2 , $ ] @xmath37 ^ 2 $ ] and @xmath38 ^ 2,$ ] simplifies the parameter inference problem and allows intuitive initial guesses for the parameters .",
    "the fgc model has a particularly simple expression in fourier space .",
    "if the fourier transform of the covariance function is defined by means of @xmath39 then the energy functional in fourier space is given by    @xmath40 = \\frac{1}{2 ( 2 \\pi)^{d } } \\int d{\\bf k } \\tilde{x}_{\\lambda}({\\bf k } ) \\",
    ", \\tilde{g}^{-1}_{{\\rm x};\\lambda}({\\bf k};{\\bm \\theta } ) \\ , \\tilde{x}_{\\lambda}(-{\\bf k}).\\ ] ]",
    "the interaction is diagonal in fourier space , i.e. , the _ precision matrix _ @xmath41 couples only components with equal wavevectors .",
    "for a real - valued ssrf @xmath42 it follows that @xmath43 .",
    "since bochner s theorem guarantees the non - negativity of the covariance spectral density , it follows from  ( [ enfunc ] ) that the energy is a non - negative functional .",
    "the covariance spectral density follows from the expression :    @xmath44    where @xmath45 is the fourier transform of the coarse - graining kernel , which determines how the fluctuations are cut off at the resolution scale @xmath0 @xcite . for isotropic",
    "ssrf s , @xmath46 has no directional dependence . in @xcite ,",
    "a kernel having a boxcar spectral density with a sharp wavevector cutoff at @xmath15 was used .",
    "this kernel leads to a band - limited covariance spectral density @xmath47 .",
    "the energy density defined by eq .",
    "( [ fgccont ] ) is valid in the continuum , and for differentiable srfs .",
    "generalized versions of the functional that are valid on regular lattices can be defined .",
    "for example :    [ def1 ] we define the local energy terms @xmath48 @xmath49 and @xmath50 , @xmath51 , as follows : @xmath52 ^ 2 , \\quad s_1(a_1)= \\sum_{i=1}^d \\big [ { x_{\\lambda}}({\\bf s}+a_1 { \\bf \\vec{e}}_i)-     { x_{\\lambda}}({\\bf s } ) \\big ] ^2/a_1 ^ 2\\ ] ] @xmath53 \\ ; \\delta_2^{(j)}[{x_{\\lambda}}({\\bf s})],\\ ] ] where @xmath54 is the centered second - order difference operator in the direction @xmath55 i.e , @xmath56=\\big [ { x_{\\lambda}}({\\bf s}+a_2\\;{\\bf\\vec{e}}_i )          + { x_{\\lambda}}({\\bf s}-a_2\\;{\\bf\\vec{e}}_i )          -2{x_{\\lambda}}({\\bf s})\\big ] /a_2 ^ 2.\\ ] ] @xmath57 represents the square of the fluctuations , @xmath58 the square of the generalized gradient , and @xmath59 the square of the generalized curvature .",
    "the _ generalized gradient _ and _ curvature _ terms above are expressed in terms of finite differences instead of derivatives .",
    "these terms replace the gradient and curvature in ( [ fgccont ] ) . on a hypercubic lattice @xmath60 in @xmath61 dimensions with step @xmath62 ,",
    "one obtains @xmath63 .",
    "the sample counterparts of @xmath64 , obtained by replacing @xmath42 with @xmath65 , are thus well - defined even for non - differentiable srfs .",
    "parameter inference is based on matching the sample constraints , @xmath66 , with the stochastic constraints , @xmath67 $ ] , as shown in @xcite .",
    "[ def2 ] the ensemble moments @xmath68,$ ] @xmath69 $ ] and @xmath70 $ ] provide the ssrf model constraints .",
    "these can be expressed in terms of the variance @xmath71 and the semivariogram function @xmath72 as follows :    @xmath73= g_{{\\lambda}}(0),\\qquad   \\label{sto1}\\ ] ]    @xmath74:=\\frac{\\phi_1(a_1)}{a_1^{2 } } = \\frac{\\cone}{a_1^{2}}\\ ;   f_{{\\lambda}}(a_1 )   \\label{sto2}\\ ] ]    @xmath75 : = \\frac{\\phi_2(a_2)}{a_2^{4}}= \\frac{1}{a_2 ^ 4 } \\ , \\left[\\ctwo \\ , f_{{\\lambda}}(a_2 ) - \\cthree \\ , f_{{\\lambda}}(\\sqrt{2 }",
    "a_2)- \\cone\\ , f_{{\\lambda}}(2a_2 ) \\right],\\ ] ]    where @xmath76 @xmath77 , and @xmath78    the ssrf constraints are expressed in terms of the semivariogram @xmath72 , but this does not imply that the experimental variogram is required for determining the spatial model .    the dependence of the stochastic constraints on the ssrf parameters @xmath79 is not shown explicitly to keep the notation concise .",
    "the stochastic constraints are well defined for the fgc - ssrf , which are differentiable if @xmath15 is finite @xcite . in the case of continuous but non - differentiable models , the ratios @xmath80 and @xmath81",
    "are not well defined when @xmath82 .",
    "then , the constraints are defined in terms of the quantities @xmath83 and @xmath84 respectively .",
    "in most geostatistical applications the available sample is distributed on an irregular sampling grid . in order to infer the model parameters , suitable stochastic and sample - based constraints need to be defined . on regular grids",
    "the lattice symmetry leads to obvious choices for the _ distance increments _ ( steps ) @xmath85 and @xmath86 and the finite differences . on irregular grids ,",
    "we formulate the sample gradient and curvature constraints using kernel averages .",
    "we also define steps @xmath85 and @xmath86 , suitable for general sampling point distributions .",
    "in addition , the kernel bandwidths are selected so as to yield good asymptotic properties for the generalized gradient and curvature estimators .",
    "the stochastic constraints are related to the srf model and thus do not depend on the sampling point distribution .",
    "hence , the constraints defined in ( [ sto1])-([sto3 ] ) can be used for irregular grids as well .",
    "the dependence of the constraints on the ssrf parameters is made explicit using the _ spectral representation of the covariance function _ @xcite .",
    "if we define @xmath87 , @xmath88 and @xmath89 then for any @xmath90 the following relations hold : @xmath91 the _ variance stochastic constraint _ , obtained for @xmath92 , is given by @xmath93=\\frac{\\eta_0 } { 2^d\\,\\pi^{d/2 } \\gamma(d/2 ) } \\ ,    \\int_{0}^{\\infty } dv\\ , v^{{d/2 - 1 } }    \\ , \\frac { \\big |\\tilde{q}_{{\\lambda}}(w ) \\",
    ", \\big      |^2}{\\pi(v)}.\\ ] ] in general , the dependence of @xmath68 $ ] on @xmath34 and @xmath94 is nonlinear @xcite , i.e. , @xmath95 . the function @xmath96 tends to an asymptotic finite bound as @xmath97 .",
    "the bound is attained with very good accuracy if @xmath98 , where @xmath99 is an @xmath100 constant that depends on @xmath61 . to eliminate the dependence of the ssrf variance on @xmath34 and @xmath94",
    ", we impose the relation    @xmath101    which is equivalent to the following normalization constraint : @xmath102=\\int_{0}^{\\infty } dv\\ , v^{{d/2 - 1 } }    \\ ,   \\frac { \\big |\\tilde{q}_{{\\lambda}}(w ) \\ , \\big|^2}{\\pi(v)}=1.\\ ] ]    the stochastic constraint for the _ generalized gradient _ is given by @xmath103 = \\frac{\\cone\\sigx } { a_{1}^{2 } } \\int_{0}^{\\infty } dv\\ , \\left [ v^{{d/2 - 1}}-\\gamma_d \\ , v^{(d-2)/4 } \\ , \\frac{j_{{d/2 - 1}}(a_1 w ) } { a_1^{{d/2 - 1}}}\\right]\\frac{\\big        |^2}{\\pi(v)},\\ ] ] where @xmath104 .    based on ( [ sto3 ] ) and ( [ eq : cov ] )",
    ", the stochastic constraint for the _ generalized curvature _ is given by @xmath105 & = & \\frac{\\sigx } { a_{2}^{4 } } \\int_{0}^{\\infty } dv\\ , \\frac{\\big |\\tilde{q}_{{\\lambda}}(w ) \\",
    ", \\big    v^{{d/2 - 1}}-\\gamma_d\\ , \\frac{v^{(d-2)/4}}{a_2^{{d/2 - 1 } } } \\right . \\nonumber\\\\      & &      \\left .",
    "\\left [ \\ctwo j_{{d/2 - 1}}(a_2w )    - \\cthree \\ , \\frac{j_{{d/2 - 1}}(a_2 \\sqrt{2}w)}{2^{d/4 - 1/2 } }      - \\cone\\ , \\frac{j_{{d/2 - 1}}(2a_2\\ , w)}{2^{{d/2 - 1 } } }   \\right ] \\right\\}.\\end{aligned}\\ ] ]    the selection of @xmath12 based on eq .",
    "( [ eq : eta0 ] ) increases the number of ssrf constraints to four ; the other three are given by the equations  ( [ stoch-0 ] ) , ( [ semi - der2 ] ) and  ( [ semi - der4 ] ) .",
    "thus , the number of parameters matches the number of constraints .    the steps @xmath85 and @xmath86 depend on the sampling point distribution .",
    "their selection is discussed in section  ( [ sec : asympt ] ) below . in general",
    ", @xmath86 is different from @xmath85 . to incorporate the spatial modelling of data from non - differentiable distributions",
    ", one should focus on the quantities @xmath106 $ ] and @xmath107 $ ] instead of @xmath69 $ ] and @xmath70.$ ]",
    "we formulate sample constraints that provide ` well - behaved ' estimators of the model constraints defined above . we emphasize that the following sample estimators of the generalized gradient and curvature constraints are not restricted to the fgc - ssrf model .",
    "the variance constraint is local , i.e. , it does not involve differences between neighboring points .",
    "hence , if the distribution of the sampling points is uniform , it is sufficient to use the classical variance estimator . to estimate a non - zero mean one can use the sample average , @xmath108 , in view of which the sample variance @xmath109 is given by : @xmath110 ^ 2.\\ ] ]    declustered estimates of the mean and the variance can be used if the sampling point distribution is non - uniform , in order to obtain unbiased estimates of the variance . however , non - ergodic fluctuations , which often dominate the estimation of the variance from a single sample , are not significantly reduced by cell declustering .",
    "another possibility is using the kernel - based variance estimator @xcite , which has improved convergence properties .",
    "however , we are not aware of a systematic method for selecting the kernel bandwidth for the variance .      to define sample - based generalized gradient and curvature constraints we use _ isotropic kernel functions _",
    "@xmath111 with suitably selected bandwidth parameters , @xmath112 ( for the gradient estimator ) and @xmath113 ( for the curvature estimator ) .",
    "the selection of the bandwidths is guided by consistency principles that link them to the respective steps , @xmath85 and @xmath86 .",
    "the kernel @xmath114 is a bounded , positive , and compactly supported @xmath115 $ ] function .",
    "hence , the moments @xmath116 and @xmath117 are finite for all @xmath118 .",
    "in addition , we define the _ kernel moment ratio : _",
    "@xmath119 in practice non - compactly supported kernels ( e.g. , the gaussian kernel , ) that decrease to @xmath120 faster than polynomially work just as well as compactly supported kernels .",
    "the following notation is introduced to facilitate calculations with kernel averages . for @xmath121",
    ", @xmath122 will denote the distance vector , and @xmath123 its euclidean norm .",
    "the abbreviations @xmath124 and @xmath125 where @xmath126 will be used for the kernel weights .",
    "the weights @xmath127 and @xmath128 are random variables , due to the variability in the sampling positions .",
    "the symbol @xmath129 will denote a summation over both position indices @xmath130 and @xmath131 excluding the diagonal terms @xmath132 .",
    "similarly , the triple summation @xmath133 and the quadruple summation @xmath134 will exclude all the terms in which at least two indices take the same value .    given kernel bandwidths @xmath135 and",
    "@xmath136 , and a two - point sample function @xmath137 or a function of sampling positions @xmath138 , where @xmath139 , the _ off - diagonal kernel - weighted averages _ will be denoted by :    @xmath140    @xmath141    the _ normalized kernel average of @xmath142 _ is defined by means of the equation : @xmath143    more specifically , we will denote the _ sample increment srf _ by means of @xmath144 the sample function that represents the kernel average of @xmath145 with a kernel bandwidth @xmath146 will be denoted by @xmath147^{2 } \\ , \\right\\rangle_{h}.\\ ] ] the random variable @xmath148 incorporates variability due to both @xmath149 and the sampling positions .      the notation introduced above is now used to define sample estimators for the squares of the generalized gradient and curvature .",
    "[ def - gradcons ] the sample average of the square generalized gradient is defined as follows :    @xmath150 ^ 2   \\right\\rangle_{h_1}=\\frac{\\cone}{2a_{1}^{2 } } \\ ,   { \\overline{f_{x}}(h_1)}:=\\frac{\\overline{\\varphi_1}(h_1)}{a_{1}^{2}},\\ ] ]    where @xmath151 .",
    "the bandwidth @xmath135 is related to @xmath85 by means of the following consistency principle : @xmath152    the step - bandwidth dependence introduced by the consistency principle is physically motivated , because only @xmath85 represents an actual length scale . by adopting ( [ eq : alpha1 ] ) , the kernel average in ( [ bars1irr ] ) is forced to focus on points separated by distances controlled by the step value .",
    "this makes sense for calculations of generalized gradient and curvature terms .",
    "the sample constraint defined in ( [ bars1irr ] ) is analogous to the respective stochastic constraint in ( [ sto2 ] ) .",
    "in addition , the consistency principle ensures that , for differentiable srfs , @xmath153 is an unbiased estimator of @xmath69 $ ] ( see below ) .",
    "we introduced the three related quantities , @xmath154 , @xmath155 and @xmath153 for the following reasons : if the observed srf can be considered differentiable , the generalized gradient constraint @xmath153 is well defined at the limit @xmath156 if the observed srf is continuous but non - differentiable the limit of @xmath153 as @xmath157 does not exist . in this case , it makes more sense to work with the kernel - averaged square increment , @xmath155 . to simplify the accounting it is often advantageous to work with the square increment per direction , @xmath154 ; in the isotropic case @xmath155 and @xmath154 are simply proportionally related .",
    "similar comments apply to the case of the generalized curvature constraint .",
    "+    [ def - curvcons ] the sample average of the square generalized curvature is defined as follows : @xmath158,\\ ] ]    the constants @xmath159 are given by the following averages :    @xmath160    @xmath161\\left\\langle s_{i , j}^4 \\right\\rangle_{h_2}+\\cone\\left\\langle s_{i , j}^4 \\right\\rangle_{h_2}\\frac{\\left\\langle s_{i , j}^2 \\right\\rangle_{2h_2}}{\\left\\langle s_{i , j}^2 \\right\\rangle_{h_2}}-\\cone\\left\\langle s_{i , j}^4 \\right\\rangle_{2h_2 } } { { \\displaystyle}\\cthree \\left\\langle s_{i , j}^4 \\right\\rangle_{\\sqrt{2}h_2}-\\cthree \\left\\langle",
    "s_{i , j}^4 \\right\\rangle_{h_2}\\frac{\\left\\langle s_{i , j}^2 \\right\\rangle_{\\sqrt{2}h_2}}{\\left\\langle s_{i , j}^2 \\right\\rangle_{h_2}}}.\\ ] ]    the bandwidth @xmath136 is linked to the step by means of the consistency principle : @xmath162    the sample constraint @xmath163 given by ( [ bars2irr ] ) includes three terms that correspond to the terms in the respective stochastic constraint ( [ sto3 ] ) . the coefficients @xmath164 and @xmath165 in ( [ bars2irr ] ) incorporate the impact of the sampling network topology and the kernel function used . as shown in lemma  ( [ lem : mu1mu2-as ] ) , section  ( [ ssec : gen - curv ] ) , the coefficients @xmath164 and @xmath165 are approximately equal to @xmath166 .",
    "their precise form is selected to ensure that , in the case of differentiable srfs , the generalized curvature constraint is asymptotically unbiased .",
    "the asymptotic limit corresponds to @xmath167 . at the limit",
    "it is assumed that @xmath168 . in order to establish the asymptotic properties of the sample estimators for the generalized gradient and curvature , we first present some formalism and the conditions required for the validity of the proofs .",
    "+      the following notation will be used in the proofs of asymptotic behavior .    1 .",
    "[ c : loc ] the sampling locations will be expressed as @xmath169 , where @xmath170 is the characteristic domain scale , and @xmath171 denote the realizations of the random vector @xmath172^{d}$ ] .",
    "[ c : dist ] for any vectors @xmath173 , @xmath174 , the pair distance will be denoted by @xmath175 , and its euclidean norm by @xmath176 .",
    "[ c : uij ] in integrals of kernel averages , the distance of the normalized sampling locations will be denoted by @xmath177 .",
    "[ c : int ] a vector @xmath178 will be expressed in spherical polar coordinates as @xmath179 where @xmath180 @xmath181 @xmath182 , and @xmath183 for @xmath184 the jacobian of the transformation is given by @xmath185 where @xmath186 and @xmath187 the area of the @xmath188dimensional unit sphere will be denoted by : @xmath189 where @xmath190 + 5 .",
    "[ c : pert ] the following aspect ratios will be used as small _ perturbation parameters _ : @xmath191 and @xmath192 .",
    "+      the following conditions will be assumed to hold :    1 .   [",
    "h : loc ] the normalized location random vectors @xmath193 are assumed to be independent and identically distributed .",
    "[ h : f1 ] the probability density function ( pdf ) @xmath194 of the sampling - location pair - distance vector is continuously differentiable in a neighborhood of zero .",
    "[ h : f2 ] the joint pdfs @xmath195 and @xmath196 are also continuously differentiable in a neighborhood of zero .",
    "[ h : gc ] the conditional pdf @xmath197 is uniformly bounded in @xmath198 + 5 .",
    "[ h : match ] the joint moments of @xmath149 are identical to those of @xmath199 for example , @xmath200 , with @xmath201 , @xmath202 + 6 .",
    "[ h : semi ] the model semivariogram @xmath72 is continuous in a neighborhood of zero .",
    "[ h : psil ] there exists a continuous and bounded function @xmath203 such that @xmath204 =   \\psi_{{\\lambda}}\\left(s_{i , p},s_{j , q},s_{i , q},s_{j , p}\\right ) .\\ ] ] + for example , if @xmath205 is a gaussian srf with semivariogram @xmath206 + @xmath207 ^ 2.\\ ] ] 8 .",
    "[ h : psil - prop ] if @xmath208 , there exist @xmath209 and three continuous functions @xmath210 @xmath211 and @xmath212 such that : @xmath213 @xmath214 and @xmath215 for example , if @xmath205 is a gaussian srf with a spherical or exponential covariance function , the above conditions hold with @xmath216 in the case of differentiable covariance models commonly used ( gaussian , hole - type , rational quadratic , cauchy ) one has @xmath217 + 9 .",
    "[ h : g3bounds ] the following integral of the function @xmath218 is bounded : 10 . [",
    "h : band ] the bandwidths @xmath135 and @xmath219 tend to @xmath120 as @xmath220 tends to @xmath221 .",
    "[ h : dens ] at the asymptotic limit , @xmath222 , tends to @xmath120 as @xmath220 tends to @xmath221 .",
    "this condition is satisfied simultaneously with @xmath223 if @xmath224 and @xmath225 +    conditions ( [ h : loc])-([h : gc ] ) specify properties of the sampling point distribution .",
    "condition ( [ h : match ] ) expresses the correspondence between the srf model and the sampled data . conditions ( [ h : semi])-([h : g3bounds ] ) specify properties which are satisfied by default for fgc - ssrfs .",
    "they are explicitly stated here , because the convergence properties of the constraint estimators are proved for more general cases , including non - gaussian srf models . in particular , conditions ( [ h : psil])-([h : g3bounds ] )",
    "are used in the analysis of the sample constraints variance .",
    "conditions ( [ h : band])-([h : dens ] ) imply an _ asymptotic densification _ of the sampling network , since the area enclosed by the convex hull increases slower than the number of points . for regular grids ,",
    "this condition is obtained if the spacing decreases as the number of nodes increases .",
    "the densification conditions are necessary for proving asymptotic convergence of the estimators .",
    "[ lem : ergod ] if the above conditions hold , the following is true :    @xmath226 \\big ) = 1,\\ ] ]    where the indices @xmath227 refer to any pair of non - identical sampling points .",
    "similarly , if the summation is over a weighted @xmath228 @xmath229 non - diagonal function , the result is @xmath230 .",
    "this ergodic result follows directly by applying the arguments in the proof of theorem 3.1 in @xcite , which will not be repeated here .",
    "equation  ( [ eq : sumw ] ) enables the calculation of sample kernel averages in the asymptotic limit .",
    "we will also use the following lemma :    [ lem : useful ] let @xmath231 be a sequence of uniformly bounded random variables such that @xmath232 almost surely . then @xmath233^k = o(1),$ ] for any @xmath234      in this section we prove a relation between the `` gradient '' step and the kernel bandwidth @xmath135 , and we propose a physical estimate for the step .",
    "we also investigate the asymptotic properties of the mean and variance of the generalized gradient estimator .",
    "[ alpha1-as ] the following relation holds between the bandwidth @xmath135 and the gradient step @xmath85 : @xmath235 where @xmath236 , is the kernel moment ratio defined in ( [ eq : mom - rat ] ) .",
    "* proof : *    based on the consistency principle ( [ eq : alpha1 ] ) , the step @xmath85 is expressed as follows :    @xmath237    the above can be calculated explicitly in the asymptotic regime using lemma  ( [ lem : ergod ] ) .",
    "_ leading - order calculation of @xmath238 $ ] .",
    "_ @xmath239 =   \\int d{{\\bm \\omega}}\\ ;    k\\big ( { l_{n}}\\|{{\\bm \\omega}}\\|/h_1\\big ) \\ , f_1({{\\bm \\omega}}).\\ ] ]    the dominant asymptotic contribution from the integral is evaluated by means of a taylor expansion of the pdf @xmath240 in terms of the small parameter @xmath241 using the condition ( [ h : f1 ] ) , i.e. ,    @xmath242 & = &   \\int_0^{\\infty } d{\\omega}\\;{\\omega}^{d-1 } k\\left ( { \\omega}/p_n\\right )   \\int_{\\mathbb{s}_d}d{{\\bm \\theta}}\\ ;    j_d({{\\bm \\theta}})f_1\\left({\\omega } { { \\hat{\\bm \\omega}}}\\right )    \\nonumber \\\\   & = & p_n^d \\int_0^{r } du \\;u^{d-1 } k\\left ( u\\right )   \\int_{\\mathbb{s}_d}d{{\\bm \\theta}}\\ ;    j_d({{\\bm \\theta}})f_1\\left(p_n\\,u { { \\hat{\\bm \\omega}}}\\right )    \\nonumber \\\\    & = & p_n^{d } \\ , a_d \\ , f_1(0 ) \\ ,",
    "m_{k , d }    + o\\left(p_n^{d+1}\\right).\\end{aligned}\\ ] ]    this expansion gives the asymptotically dominant term of @xmath238 $ ] .",
    "based on lemma  ( [ lem : ergod ] ) it follows that :    @xmath243    where @xmath244 is the area of the @xmath188dimensional unit sphere defined in paragraph  ( [ c : int ] ) of the notation subsection .",
    "_ leading - order calculation of @xmath245 $ ] . _    @xmath246 & = &   { l_{n}}^2 \\ , { \\mathbb{e}}\\left [ s_{i , j}^{2 } \\ ,   k\\left ( p_n   \\ , u_{i , j } \\right )     \\right ]   = { l_{n}}^2 \\ , \\int d{{\\bm \\omega}}\\;\\|{{\\bm \\omega}}\\|^2    k\\left(\\|{{\\bm \\omega}}\\| /p_n\\right ) \\ ,   f_1({{\\bm \\omega } } )   \\nonumber \\\\    & = & { l_{n}}^2   p_{n}^{d+2 } a_d f_1(0 ) \\",
    ", m_{k , d+2 }    + o\\left({l_{n}}^2 \\ , p_{n}^{d+3 } \\right).\\end{aligned}\\ ] ]    hence , from lemma  ( [ lem : ergod ] ) and equation ( [ eq : esswijs ] ) it follows that @xmath247 based on ( [ eq : kha1-w ] ) , ( [ eq : ewij ] ) , and ( [ eq : esswij ] ) the asymptotic behavior of the step @xmath85 is given by :    @xmath248      lemma ( [ alpha1-as ] ) is valid for any step @xmath85 .",
    "we define by @xmath249 the set that includes for every sampling point @xmath250 the distance vectors from all its near neighbors @xmath251 , and also @xmath252 a sensible estimate @xmath253 is the geostatistical @xmath61-power average of the euclidean distances , @xmath254 , of all the vectors in @xmath249 i.e. , @xmath255 this definition implies that @xmath253 is a random variable that depends on the sampling point configuration . in connection with the consistency principle ,",
    "the bandwidth @xmath135 is also a random variable .",
    "however , since @xmath253 represents an average over all the near neighbor distances for all the points , its fluctuations are not very significant .",
    "in particular , the coefficient of variation declines with the number of sample points . to avoid cumbersome notation we will not distinguish between @xmath256 and @xmath257 , @xmath258 and the respective stochastic moments in the following theorems on the asymptotic properties .",
    "other estimators of the distance step such as the median or the root mean square neighbor distances can be used .",
    "however , the equation  ( [ hata ] ) leads to consistent convergence properties for the variance of the sample constraints , regardless of the spatial dimension .",
    "the kernel bandwidth , @xmath259 is then given in view of ( [ eq : bandw1 ] ) by @xmath260 the above gives an explicit linear solution for the bandwidth in terms of the step .",
    "in practical applications @xmath241 is a small parameter , and ( [ eq : estim - h1 ] ) is sufficient . alternatively , ( [ eq : alpha1 ] ) can be solved numerically to obtain the bandwidth in the pre - asymptotic case .    [ lem - h1as ]",
    "let us assume that the sampling network densification conditions ( [ h : band ] ) and ( [ h : dens ] ) hold , i.e. , @xmath261 , where @xmath262 and @xmath263 for every realization of the sampling network .",
    "then , if the gradient step is defined by the equation ( [ hata ] ) , the bandwidth exponent satisfies the inequality @xmath264 .",
    "* proof : * it holds that @xmath265 ( where @xmath266 is a geometric constant that depends on @xmath61 ) . since @xmath267 , in light of equations (",
    "[ hata ] ) and ( [ eq : estim - h1 ] ) it follows that @xmath268 for any @xmath220 , which implies that @xmath269    ( mean of the sample gradient constraint - differentiable case . )",
    "[ theor : grad - dif ] assume that conditions ( [ h : loc])-([h : dens ] ) above are satisfied , and that @xmath72 is four times differentiable in a neighborhood of zero .",
    "then @xmath270 is an asymptotically unbiased estimator of the stochastic constraint @xmath271 .",
    "more specifically , the following holds    @xmath272 =   d \\,\\tau_2\\,h_1 ^ 4 \\left ( b_4 - b_2^{2 }",
    "\\right )   + o(h_1 ^ 2\\,p_n)+o(h_1 ^ 4),\\ ] ]    where @xmath273    * proof : * since @xmath274 and @xmath275 we focus on @xmath154 and @xmath72 to avoid unnecessary clutter .",
    "the sample function @xmath154 , defined in ( [ fbar ] ) , is expressed as follows in light of equations  ( [ ksum ] ) and  ( [ kernel - av ] ) :    @xmath276    @xmath277 $ ] involves an expectation over both the sampling point distribution and the distribution of the field values .",
    "hence , we can write @xmath278={\\mathbb{e}}\\left\\ { { \\mathbb{e}}\\left [ { \\overline{f_{x}}(h_1)}/{{\\bf u}}_1,\\ldots,{{\\bf u}}_n\\right ] \\right\\},\\ ] ] where the inner ( conditional ) expectation is over the field values keeping the sampling locations fixed , whereas the outer expectation is with respect to the sampling point distribution",
    ".    _ calculation of the conditional expectation @xmath279.$ ] _",
    "since only the numerator of ( [ eq : khs1-w ] ) depends on the field values , we obtain    @xmath280= \\frac { { \\mathbb{k}}_{h_1 } \\big\\ { f_{{\\lambda}}({l_{n}}{{\\bf u}}_{i , j})\\big\\ } } { { \\mathbb{k}}_{h_1 } \\left\\ { 1\\right\\}}.\\ ] ]    _ leading - order calculation of @xmath281 _ + using lemma  ( [ lem : ergod ] ) we obtain @xmath282 =   \\int d{{\\bm \\omega}}\\;k\\big ( \\|{{\\bm \\omega}}\\| /p_n\\big )   \\;f_{{\\lambda}}\\big ( { l_{n}}\\|{{\\bm \\omega}}\\| \\big ) f_1({{\\bm \\omega } } ) \\\\ & = &   \\int d { \\omega}\\,{\\omega}^{d-1 } \\ , k\\big ( { \\omega}/p_n\\big ) \\ , f_{{\\lambda}}\\big ( { l_{n}}{\\omega}\\big )   \\int_{\\mathbb{s}_d}d{{\\bm \\theta}}\\ ;    j_d({{\\bm \\theta}})f_1\\left({\\omega } { { \\hat{\\bm \\omega}}}\\right ) \\\\     & = & p_n^{d}a_d\\big [ f_1(0 ) + o(p_n)\\big ]     \\int d u\\ ,   u^{d-1 } k\\big ( u\\big ) f_{{\\lambda}}\\big ( h_1 u \\big ) .",
    "\\end{aligned}\\ ] ] since the kernel is compactly supported , it is possible to approximate @xmath283 with a taylor series expansion around zero , i.e. , @xmath284 where @xmath285 @xmath286 . inserting the expansion in the integral it follows that @xmath287     = p_n^{d}a_d\\big [ f_1(0 ) + o(p_n)\\big ] \\ , \\left [ \\tau_2\\,h_1 ^ 2 m_{k , d+2}+     \\tau_4 \\,h_1 ^ 4 m_{k , d+4 } + o(h_1 ^ 4)\\right].\\ ] ] finally , based on the above and lemma  ( [ lem : ergod ] )",
    ", it follows that @xmath288\\left [ \\tau_2\\,h_1 ^ 2 m_{k , d+2}+     \\tau_4 \\,h_1 ^ 4 m_{k , d+4 } + o(h_1 ^ 4)\\right ]     \\quad \\mbox{a.s}.\\ ] ] using this equation in connection with ( [ eq : ewij ] ) and ( [ eq : khs1-w ] ) leads to    @xmath289 = \\tau_2\\,h_1 ^ 2 \\ , b_2 + \\tau_4\\,h_1 ^ 4 \\ , b_4 + o(h_1 ^ 2p_n)+o(h_1 ^ 4)\\quad \\mbox{a.s}.\\ ] ]    the respective expansion for @xmath290 is obtained using the consistency principle , ( [ eq : bandw1 ] ) , as well as equations  ( [ eq : fexdif ] ) and ( [ eq : estim - h1 ] ) , i.e. ,    @xmath291    from the equations ( [ eq : e - fh1 ] ) , ( [ eq : fl - dif ] ) and lemma  ( [ lem : useful ] ) , it follows that    @xmath292= \\tau_4\\,h_1 ^ 4 \\ , \\left ( b_4 - b_2 ^ 2 \\right ) + o(h_1 ^ 2p_n ) + o(h_1 ^ 4).\\ ] ]    the asymptotic convergence then follows from the densification effect , i.e. , from @xmath293 . in light of the above",
    ", @xmath154 is an asymptotically unbiased estimator of @xmath294 since the difference @xmath295-f_{{\\lambda}}(a_1)$ ] converges to @xmath120 faster than each component as @xmath296    if we consider fluctuations in the bandwidth and the step , @xmath135 on the right hand - side of equation  ( [ eq : fxh1 ] ) should be replaced by the respective mean value , and the corrections should also include bandwidth fluctuations",
    ".    the asymptotic decline of the bias as @xmath297 follows from the consistency principle and does not require the specific choice of the step ( [ hata ] ) .",
    "the latter may only influence the upper bound of the bandwidth exponent @xmath298    the following is also a direct consequence of theorem  ( [ theor : grad - dif ] ) and lemma  ( [ alpha1-as ] ) :    @xmath299 - { \\mathbb{e}}[{s_1}(a_1)]= \\tau_4\\,h_1 ^ 2 \\ , \\left(\\frac{b_4}{b_2}-b_2\\right ) + o(p_n ) + o(h_1 ^ 2).\\ ] ]    equation  ( [ eq : s1bias ] ) shows that the generalized gradient @xmath153 is an asymptotically unbiased estimator of the stochastic constraint @xmath300 $ ] .",
    "[ theor : grad - cont ] ( mean of the sample `` gradient '' constraint - continuous case . ) assume that conditions ( [ h : loc])-([h : dens ] ) above are satisfied , and that @xmath72 is continuous but non differentiable at zero .",
    "for @xmath301 , it follows that @xmath270 is an is an asymptotically unbiased estimator of the stochastic constraint @xmath302 more specifically :    @xmath303=   d \\,\\tau_2\\,h_1 ^ 2      \\left(b_2- b_1 ^ 2\\right )   + d \\ , \\tau_3\\,h_1 ^ 3 \\ , \\left ( b_3 - b_1^{3 } \\right ) + o(h_1\\ , p_n ) + o(h_1 ^ 3).\\ ] ]    in addition , @xmath270 is an asymptotically biased estimator of the stochastic constraint @xmath304 i.e. ,    @xmath305 =    d\\ , \\tau_1\\,h_1 \\ ,",
    "\\left(b_1-b_2^{1/2}\\right ) +    d \\,\\tau_3\\,h_1 ^ 3 \\ , \\left(b_3-b_2^{3/2}\\right )   + o(h_1p_n)+o(h_1 ^ 3).\\ ] ]    the mean relative error of @xmath306 $ ] is given by    @xmath307    = \\frac{b_{1,2}}{\\sqrt{b_{2 } } }     +      h_1 ^ 2\\ ,   \\frac{\\tau_3}{\\tau_1}\\frac{b_{3,2}}{\\sqrt{b_{2 } } }     + o(p_n)+o(h_1 ^ 2),\\ ] ]    where @xmath308 and @xmath309    * proof : * the logic of the proof is the same as in theorem  ( [ theor : grad - dif ] ) , and therefore we only present the main points .",
    "the derivatives of @xmath72 do not exist at zero .",
    "however , if @xmath72 admits at least third - order derivatives for any @xmath310 , the taylor series expansion of the semivariogram is expressed as    @xmath311    where @xmath312 .",
    "then we obtain @xmath313 = p_n^{d}a_d\\big [ f_1(0 ) + o(p_n)\\big ] \\left [ { \\sum}_{j=1}^{3 } \\tau_j\\,h^j m_{k , d+j}+o(h_1 ^ 3)\\right ] ,   \\end{aligned}\\ ] ] and in connection with ( [ eq : ewij ] ) and ( [ eq : khs1-w ] ) it follows that    @xmath314= \\sum_{j=1}^{3 } \\tau_j\\,h^j \\ , b_j + o(h_1 ^ 3)\\quad \\mbox{a.s}.\\ ] ]    based on ( [ eq : fexcon ] ) , the semivariogram @xmath315 is expressed as @xmath316 hence , we obtain    @xmath317 - f_{{\\lambda}}(a'_1 )   = \\sum_{j=2,3 } \\tau_j\\,h_1^j \\left ( b_j - b_1^j \\right ) + o(h_1\\,p_n)+o(h_1 ^ 3 ) \\quad { \\rm a.s}.\\ ] ]    the above proves equation  ( [ eq : biasphi1 - 1 ] ) . the equation  ( [ eq : biasphi1 - 2 ] ) is proved in the same way , but the expansion  ( [ eq : fexcon ] ) is replaced with an expansion around @xmath85 , i.e. ,    @xmath318    the above , in connection with  ( [ eq : ee - fh1 ] ) , leads to    @xmath319 - f_{{\\lambda}}(a_1 )   = \\sum_{j=1,3 } \\tau_j\\,h_1^{j } \\ , \\left(b_j - b_2^{j/2}\\right )   + o(h_1\\,p_n)+o(h_1 ^ 3 ) \\quad { \\rm a.s}.\\ ] ]    finally , equation  ( [ eq : relerr1 ] ) for the mean relative error ( relative bias ) , follows from  ( [ eq : fexcon2 ] ) and  ( [ eq : fexcon3 ] ) .    based on equation  ( [ eq : relerr1 ] ) the relative bias depends on the kernel function through the coefficients @xmath320 and @xmath321 . as @xmath322 , the relative bias converges to @xmath323 .",
    "[ lem : relbias1 ] the asymptotic relative bias , @xmath324 is a non - positive number .",
    "* proof : * @xmath236 is a positive number . by definition , @xmath325 .",
    "let us define the density function @xmath326.\\ ] ] in light of this definition and equation ( [ eq : mom - rat ] ) , we obtain @xmath327,$ ] where @xmath328 denotes the expectation with respect to the density function @xmath329 then , @xmath330 \\right)^{2 } \\right ] \\ge 0 $ ] , and thus @xmath331 follows directly .    as a direct consequence of equations  ( [ eq : estim - h1 ] ) and  ( [ eq : ee - fh1 ] ) ,",
    "one obtains that @xmath332 \\propto o(h_1^{-1})$ ] .",
    "hence , the sample function @xmath333 $ ] is not well defined at the asymptotic limit .",
    "thus , the `` gradient '' constraints in the continuous but non - differentiable case refer to the sample function @xmath155 and its stochastic counterpart , @xmath334    ( variance of the sample `` gradient '' constraint . ) [ theor : grad - var ] if the conditions ( [ h : loc])-([h : dens ] ) above are satisfied , @xmath155 is an asymptotically consistent estimator of @xmath334 in particular , the variance of @xmath270 is given asymptotically by :    @xmath335    = o\\left ( \\frac{1}{n^{2c_1 \\gamma+\\epsilon_1}}\\right ) , \\quad    \\epsilon_1 = \\min\\ { \\delta , 2-\\delta - d\\,\\gamma\\}.\\ ] ]    * proof : * the variance of @xmath154 is given by means of :    @xmath336 = { \\mathbb{e}}\\big [ { \\mathbb{v}ar}[{\\overline{f_{x}}(h_1)}/{{\\bf u}}_1,\\ldots,{{\\bf u}}_n ] \\big]+ { \\mathbb{v}ar}\\big [ { \\mathbb{e}}[{\\overline{f_{x}}(h_1)}/{{\\bf u}}_1,\\ldots,{{\\bf u}}_n ] \\big ]   .\\ ] ]    according to eq .",
    "( [ eq : e - fh1 ] ) in the differentiable case , and eq .",
    "( [ eq : ee - fh1 ] ) in the non - differentiable case , the second term on the right hand side of eq .",
    "( [ eq : vars1 - 2 ] ) is @xmath337 hence , we focus on the first term , which is expressed as follows :    @xmath338 & = & { \\sum}'_{i , j}\\,{\\sum}'_{k , l } \\frac{w_{i , j } \\ , w_{k , l } \\ , } { \\left [ { \\mathbb{k}}_{h_1 } ( 1)\\right]^{2 } }   \\ , { \\mathbb{c}ov}\\left \\ {         ( x^{*}_{i , j})^2 , \\ , ( x^{*}_{k , l})^2   \\right \\ } \\nonumber \\\\ & = &   v_{1,1 } + v_{1,2 } + v_{1,3},\\end{aligned}\\ ] ]    where the functions @xmath339 , in light of @xmath203 defined in  ( [ psila ] ) , are given by @xmath340^{2 } }    \\\\ \\label{eq : v12 }    v_{1,2 }   & = & 4   \\ , \\frac { { \\sum}'_{i , j , k } w_{i , j } \\ , w_{k , i } \\ ,    \\psi_{{\\lambda}}\\left(s_{i , k},s_{j , i},0,s_{j , k}\\right ) }    {   \\left [ \\sum'_{i , j } w_{i , j }   \\right]^{2 } }    \\\\ \\label{eq : v13 }    v_{1,3 }    & = & \\frac { { \\sum}'_{i , j , k , l } w_{i , j } \\ , w_{k , l } \\ ,    \\psi_{{\\lambda}}\\left(s_{i , k},s_{j , l},s_{i , l},s_{j , k}\\right ) }    {   \\left [ { \\sum}'_{i , j } w_{i , j }    \\right]^{2 } } .\\end{aligned}\\ ] ]    _ leading - order calculation of the denominator .",
    "_    the quantities @xmath339 in equations ( [ eq : v11])-([eq : v13 ] ) have a common denominator , the asymptotic behavior of which follows from ( [ eq : ewij ] ) .",
    "more precisely , the following is true : @xmath341^{2 } = n^4 \\ , p_n^{2d } \\ , \\left [ a_d \\ , f_1(0 ) \\ , m_{k , d}\\right]^2    + o\\left(n^4p_n^{2d}\\right ) \\quad \\mbox{a.s.}\\ ] ]    _ leading - order calculation of @xmath342 _",
    "denote the numerators of ( [ eq : v11])-([eq : v13 ] ) by @xmath343 .",
    "then , it follows from lemma  ( [ lem : ergod ] ) that @xmath344 almost surely , where : @xmath345\\\\   & = & \\int d{{\\bm \\omega}}\\ ;   k^2\\left   ( \\|{{\\bm \\omega}}\\|/ p_n \\right )     \\psi_{{\\lambda}}\\big(0,0,{l_{n}}\\|{{\\bm \\omega}}\\|,{l_{n}}\\|{{\\bm \\omega}}\\|\\big ) f_1({{\\bm \\omega}}).\\end{aligned}\\ ] ] we use the variable @xmath346 , and a taylor expansion of @xmath240 around zero .",
    "we evaluate the integral over @xmath347 with the mean value theorem .",
    "finally , we apply the first scaling property of @xmath203 in condition ( [ h : psil - prop ] ) , to obtain the following @xmath348 \\nonumber \\\\ & = & p_{n}^{d}\\,g_1(u^*)\\left ( \\frac { h_1}{\\xi}\\right ) ^{2c_1 } a_d\\,f_1(0 ) \\int_{0}^{r } du\\ ; u^{d-1 } \\ , k^2(u ) + o(p_{n}^{d}\\,h_1^{2c_1}).\\end{aligned}\\ ] ] hence , it follows that @xmath349 is given by @xmath350 finally , from equations ( [ eq : ewij ] ) , ( [ eq : v11-den ] ) , ( [ eq : v11-num ] ) and based on lemma  ( [ lem : ergod ] ) , it follows that @xmath351 hence , the asymptotic dependence of @xmath352 on @xmath220 becomes    @xmath353    _ leading - order calculation of @xmath354 _    the numerator of @xmath355 is equal to @xmath356 almost surely , where : @xmath357\\\\    & = & \\iint d{{\\bm \\omega}}_1 d{{\\bm \\omega}}_2\\ ; k\\left ( \\frac{\\|{{\\bm \\omega}}_1\\|}{p_n}\\right )   k\\left ( \\frac{\\|{{\\bm \\omega}}_2\\|}{p_n}\\right )      \\psi_{{\\lambda}}\\big({l_{n}}\\|{{\\bm \\omega}}_2\\|,{l_{n}}\\|{{\\bm \\omega}}_1\\|,0,{l_{n}}\\|{{\\bm \\omega}}_{1,2}\\|\\big ) \\ ,      f_2({{\\bm \\omega}}_1,{{\\bm \\omega}}_2).\\end{aligned}\\ ] ] converting @xmath358 and @xmath359 to spherical polar coordinates , using the perturbation parameter @xmath241 with the change of variables @xmath360 , @xmath361 leads to : @xmath362 we evaluate the integrals over @xmath363 and @xmath359 using the mean value theorem , defining @xmath364 . by applying the second scaling property of condition ( [ h : psil - prop ] ) for @xmath203 ,",
    "the following is obtained : @xmath365 hence , the following expression is obtained for the numerator of @xmath355 : @xmath366 finally , based on equations ( [ eq : ewij ] ) , ( [ eq : v11-den ] ) , ( [ eq : v12-num ] ) and lemma  ( [ lem : ergod ] ) , the following asymptotic expression is obtained for @xmath355 @xmath367    therefore , the asymptotic dependence of @xmath355 on @xmath220 becomes    @xmath368    _ leading - order calculation of @xmath369 _    the numerator of @xmath370 , @xmath371 , includes a summation over quartets of sampling points and thus involves the joint pdf of three independent distances @xmath372 . for reasons of brevity ,",
    "we denote @xmath373 , @xmath374 , and @xmath375 ; then @xmath376 and @xmath377 ; also @xmath378 and @xmath379 .",
    "according to lemma ( [ lem : ergod ] ) , @xmath380 almost surely , where @xmath381 is given by    @xmath382 \\\\    & = & \\iiint d{{\\bm \\omega}}_1    d{{\\bm \\omega}}_2   d{{\\bm \\omega}}_3 \\ ;    k\\left(\\frac{\\|{{\\bm \\omega}}_1\\|}{p_n}\\right )    k\\left ( \\frac{\\|{{\\bm \\omega}}_2\\|}{p_n}\\right ) \\ ,    f_3\\left({{\\bm \\omega}}_1,{{\\bm \\omega}}_3,{{\\bm \\omega}}_2+{{\\bm \\omega}}_3\\right)\\\\    & &    \\psi_{{\\lambda}}\\left ( { l_{n}}{\\omega}_3,{l_{n}}u_{j , l } ,    { l_{n}}u_{i , l } , { l_{n}}{\\omega}_{1,3}\\right ) .\\end{aligned}\\ ] ]    converting @xmath383 @xmath359 and @xmath384 to spherical polar coordinates , the following expression is obtained : @xmath385 using the variable transformations @xmath386 @xmath387 , @xmath388 and the taylor expansion of @xmath389 around @xmath390 , @xmath371 is transformed as follows @xmath391.\\end{aligned}\\ ] ] the integrals over @xmath392 , @xmath393 and @xmath394 are evaluated using the mean value theorem and the third scaling property of condition ( [ h : psil - prop ] ) : @xmath395 finally , the following expression is obtained for @xmath396    @xmath397    where @xmath398 is a finite constant thanks to assumption  ( [ h : g3bounds ] ) .    hence , based on equations ( [ eq : esswij ] ) , ( [ eq : v11-den ] ) ,",
    "( [ eq : v13-num ] ) and lemma  ( [ lem : ergod ] ) , the following asymptotic expression is obtained for @xmath399 @xmath400    hence , the asymptotic dependence of @xmath399 on @xmath220 becomes    @xmath401    _ variance convergence rate_.    based on equations ( [ eq : v11-n ] ) , ( [ eq : v12-n ] ) and ( [ eq : v13-n ] ) , the convergence of @xmath399 is slower than that of @xmath355 since @xmath402 the convergence of @xmath352 is faster than that of @xmath399 if @xmath403 . if this condition holds , then @xmath399 is the rate - limiting term . in light of lemma  ( [ lem - h1as ] )",
    "this inequality is satisfied for the bandwidth defined by  ( [ hata ] ) .",
    "the rate of convergence of the gradient estimator s variance is the same for the differentiable and non - differentiable cases .",
    "the three terms , i.e. , @xmath404 possess distinct convergence rates .",
    "these terms correspond to sample functions that involve doublets , triplets and quartets of non - identical sampling points . using the step estimate ( [ hata ] ) and",
    "the consistency principle , the slowest convergence rate ( asymptotically dominant term ) is due to the term that involves quartets of non - identical points . on intuitive grounds",
    ", we would expect the same behavior to hold for different step estimates .      in this section",
    "we prove a relation between the `` curvature '' step and the kernel bandwidth @xmath136 , and we propose an estimate for the step .",
    "we then investigate the asymptotic properties of the mean and variance of the generalized curvature estimator . in the process",
    ", we also show that to a first approximation @xmath405 and we calculate the asymptotic dependence of the leading corrections .    in the proofs of asymptotic dependence",
    ", we will use the following modification of lemma  ( [ lem : ergod ] ) . @xmath406",
    "\\big ) = 1.\\ ] ]    [ alpha2-as ] the following relation holds between the bandwidth @xmath136 and the curvature step @xmath86 :    @xmath407    * proof : * the proof is along the lines of lemma  ( [ alpha1-as ] ) .",
    "according to the definition  ( [ alpha2 ] ) and the kernel - average equation ( [ kernel - av ] ) , the step @xmath86 is defined by : @xmath408    _ leading - order calculation of @xmath409.$ ] _    @xmath410&=&\\int d{{\\bm \\omega}}\\ ;    k\\big ( { l_{n}}\\|{{\\bm \\omega}}\\|/r\\,h_2\\big ) \\ , f_1({{\\bm \\omega } } ) \\nonumber \\\\ & = & \\int d{\\omega}\\;{\\omega}^{d-1 } k\\left ( { \\omega}/r\\,q_n\\right )   \\int_{\\mathbb{s}_d}d{{\\bm \\theta}}\\ ;    j_d({{\\bm \\theta}})f_1\\left({\\omega } { { \\hat{\\bm \\omega}}}\\right )    \\\\    & = & r^d \\ , q_n^{d } \\ , a_d \\ , f_1(0 ) \\ , m_{k ,",
    "d }     + o\\left(q_n^{d+1}\\right ) .",
    "\\nonumber\\end{aligned}\\ ] ]    hence , we obtain @xmath411    the term @xmath412 is a special case of @xmath413 , which we evaluate below .",
    "+ _ leading - order calculation of @xmath414.$ ] _",
    "@xmath415   & = &     { l_{n}}^m \\ , \\int d{{\\bm \\omega}}\\;\\|{{\\bm \\omega}}\\|^m \\ ,    k\\left ( \\|{{\\bm \\omega}}\\|/rq_n\\right ) \\ ,   f_1({{\\bm \\omega } } ) \\nonumber \\\\    & = & { l_{n}}^m \\,r^{d+m } \\ , q_n^{d+m } \\ , a_d \\ ,",
    "f_1(0 ) \\ , m_{k , d+m }    + o\\left({l_{n}}^m \\ , q_n^{d+5}\\right).\\end{aligned}\\ ] ] hence , it follows that @xmath416 from the eqs .",
    "( [ esswij1 ] ) and ( [ esswij4 ] ) it follows that @xmath417 the asymptotic behavior of @xmath86 is obtained from ( [ esswij44 ] ) for @xmath418 and @xmath419 :    @xmath420    the coefficients @xmath421 and @xmath165 appear in the definition of the generalized curvature constraint .",
    "we calculate the asymptotic dependence of these coefficients .",
    "[ lem : mu1mu2-as ] the coefficients @xmath421 and @xmath165 are given asymptotically by : @xmath422    * proof : * based on the equations ( [ muhat1 ] ) and ( [ muhat2 ] ) the coefficients involve the averages @xmath423 and @xmath424 where @xmath126 .",
    "both averages are given by equation  ( [ esswij44 ] ) .",
    "the lemma is proved following straightforward but tedious algebraic manipulations .    for the curvature step",
    "we will use the same expression as for the gradient step , i.e. , @xmath425 , given by equation  ( [ hata ] ) . the kernel bandwidth , @xmath426 is then given in view of ( [ a2hat ] ) as follows :    @xmath427    [ lem - h2as ] let us assume that @xmath428 . then",
    ", if the curvature step is defined by the equation ( [ hata ] ) , the bandwidth exponent satisfies the inequality @xmath429 .    *",
    "proof : * the proof is completely analogous to the proof of lemma  ( [ lem - h1as ] ) if @xmath430 is replaced by @xmath431 .    ( mean of the sample curvature constraint - differentiable case . ) [ theor : curv - mean ] assume that hypotheses ( [ h : loc])-([h : dens ] ) above are satisfied , and that @xmath72 admits five derivatives in a neighborhood of zero .",
    "then @xmath432 is an asymptotically unbiased estimator of @xmath433 more specifically , the following holds    @xmath434 = -24d(d+4)\\ , \\tau_6\\,h_2 ^ 6\\ , \\left ( b_6 -b_4^{3/2 } \\right ) + o(h_2 ^ 2 \\ , q_n)+o(h_2 ^ 6),\\ ] ]    where @xmath435 and @xmath436 .",
    "* proof : *    based on ( [ bars2irr ] ) , @xmath84 is expressed in terms of @xmath437 as follows : @xmath438.\\ ] ] the sample function @xmath437 is defined in terms of ( [ fbar ] ) , and it is expressed in light of ( [ ksum2 ] ) as follows : @xmath439 hence , @xmath440 $ ] is expressed in terms of @xmath441 $ ] . as in theorem  ( [ theor : grad - dif ] ) , the ensemble average implies @xmath441={\\mathbb{e}}\\left\\ { { \\mathbb{e}}\\left [ { \\overline{f_{x}}(rh_2)}/{{\\bf u}}_1,\\ldots,{{\\bf u}}_n\\right ] \\right\\}.$ ]    _ calculation of the conditional expectation @xmath442.$ ] _    only the numerator of ( [ eq : khs2-w ] ) depends on the field values , i.e. , @xmath443= \\frac { { \\mathbb{k}}_{rh_2 } \\big\\ { f_{{\\lambda}}({l_{n}}{{\\bf u}}_{i , j})\\big\\ } } { { \\mathbb{k}}_{rh_2 } \\left\\ { 1\\right\\}}.\\ ] ]    _ leading - order calculation of @xmath444 _ @xmath445 =   \\int d{{\\bm \\omega}}\\;k\\left ( \\|{{\\bm \\omega}}\\| /(rq_n)\\right )   \\;f_{{\\lambda}}\\left({l_{n}}\\|{{\\bm \\omega}}\\| \\right ) f_1({{\\bm \\omega } } ) \\\\ & = &   \\int d { \\omega}\\,{\\omega}^{d-1 } \\ , k\\left ( { \\omega}/(rq_n)\\right ) \\ ,",
    "f_{{\\lambda}}\\left({l_{n}}{\\omega}\\right )   \\int_{\\mathbb{s}_d}d{{\\bm \\theta}}\\ ;    j_d({{\\bm \\theta}})f_1\\left({\\omega } { { \\hat{\\bm \\omega}}}\\right ) \\\\     & = & r^d\\,q_n^{d}a_d\\big [ f_1(0 ) + o(p_n)\\big ]     \\int d u\\ ,   u^{d-1 } k(u ) f_{{\\lambda}}(r\\,h_2u ) .   \\end{aligned}\\ ] ] the sixth - order taylor series expansion of @xmath446 around zero yields @xmath447 inserting the expansion in the kernel integral , it follows that @xmath448      =   q_n^{d } \\ ,",
    "\\left[f_1(0 ) + o(p_n)\\right ] \\ ,     \\left [ { \\sum}_{i=2,4,6 } m_{k , d+i } \\ , \\tau_i\\,(r \\ , h_2)^i + o(h_2 ^ 6 ) \\right].\\ ] ] the above in connection with ( [ esswij1 ] ) for",
    "the kernel average @xmath449 lead to : @xmath450 = \\sum_{i=2,4,6 } g_i \\ , \\tau_i\\,(r \\ , h_2)^i   + o(h_2 ^ 2 \\",
    ", q_n)+o(h_2 ^ 6 ) \\quad { \\rm a.s}.\\ ] ] from ( [ eq : e - fh2 ] ) and ( [ eq : varphi2 ] ) it follows that the @xmath451 term vanishes if the coefficients @xmath452 are defined as in equations ( [ muhat1 ] ) and ( [ muhat2 ] ) .",
    "finally , we obtain @xmath453= -\\czero \\ , b_4 \\ , \\tau_4\\,h_2 ^ 4 \\ , -24d(d+4)\\ , b_6 \\ , \\tau_6\\,h_2 ^ 6 + o(h_2 ^ 2 \\,q_n)+o(h_2 ^ 6 ) \\quad { \\rm a.s}.\\ ] ]    using the definition of @xmath454 , equation ( [ sto3 ] ) , the expansion ( [ eq : fexdif6 ] ) , and the step - bandwidth relation , ( [ eq : bandw3 ] ) , a series expansion is obtained for @xmath454 @xmath455 the two preceding expansions allow calculating the bias for the curvature constraint by subtracting the terms on the respective sides . the proof is completed by applying lemma [ lem : useful ] to obtain equation ( [ eq : biasphi2dif ] ) .    [ theor : curv - cont ] ( mean of the sample `` curvature '' constraint - continuous case",
    "assume that conditions ( [ h : loc])-([h : dens ] ) above are satisfied , and that @xmath72 is continuous but non differentiable at zero . for @xmath456",
    ", it follows that @xmath457 is an asymptotically unbiased estimator of the stochastic constraint @xmath458 more specifically , if @xmath459 $ ] , and @xmath460 $ ] then : @xmath461 =      c^{(5)}_{d } \\ , \\tau_3\\,h_2 ^ 3\\ , \\left ( b_3- b_1^{3 } \\right ) + o(h_2 ^ 3)+o(h_2\\ , q_n).\\ ] ]    in addition , @xmath457 is an asymptotically biased estimator of the stochastic constraint @xmath462 i.e. , @xmath463 & = &    c^{(4)}_{d}\\ ,   \\tau_1\\,h_2 \\,\\left ( b_1 -b_4^{1/4}\\right )    +      c^{(5)}_{d } \\,\\tau_3\\,h_2 ^ 3\\ , \\left ( b_3 - b_4^{3/4 } \\right )    \\nonumber \\\\    & + &   o(h_2 ^ 3)+o(h_2\\,q_n).\\end{aligned}\\ ] ] the mean relative error of @xmath464 $ ] is given by    @xmath465    = \\frac{b_{1,4}}{b_{4}^{1/4 } }     +      h_2 ^ 2\\ ,   \\left ( \\frac{\\tau_3}{\\tau_1 } \\right ) \\frac{b_{3,4}}{b_{4}^{1/4 } }     + o(p_n)+o(h_2 ^ 2),\\ ] ]    where @xmath466 and @xmath467    * proof : *    first we calculate @xmath468 $ ] .",
    "this requires calculation of @xmath442 $ ] .",
    "the latter is given in equation ( [ eq : econd - fh2 ] ) .",
    "on the right hand side of that equation , the denominator , @xmath469 , is given by equation ( [ esswij1 ] ) .",
    "the numerator , @xmath470 , converges to @xmath471 $ ] according to ( [ eq : sumq ] ) .",
    "for @xmath472 the taylor expansion of @xmath72 is given by @xmath473 where @xmath474 .",
    "then , we obtain by the standard procedure    @xmath475 = q_n^{d}\\,a_d \\big [ f_1(0 ) + o(q_n)\\big ] \\left [ { \\sum}_{j=1}^{3 } \\tau_j\\,r^{j } \\ , h_2^j \\ , m_{k ,",
    "d+j}+o(h_2 ^ 3)\\right ] .   \\end{aligned}\\ ] ]    based on the above , it follows that    @xmath476 = \\sum_{j=1,2,3 } \\tau_j\\,r^j\\,h_2^{j } \\,b_j + \\",
    "q_n ) + o(h_2 ^ 3)\\quad \\mbox{a.s}.\\ ] ]    finally , using lemma  ( [ lem : useful ] ) and equation ( [ eq : varphi2 ] ) , we obtain the following @xmath477&= & c^{(4)}_d \\ ,",
    "\\tau_1\\,h_2 \\ , b_1   + c^{(5)}_d \\ , \\tau_3\\,h_2 ^ 3\\ , b_3 + o(h_2 ^ 3)+o(h_2q_n ) \\quad \\mbox{a.s.},\\end{aligned}\\ ] ]",
    "where the term @xmath451 vanishes due to cancelation of the coefficients .",
    "based on ( [ sto3 ] ) and the expansion ( [ eq : fexcon - curv ] ) , the stochastic term is expressed as @xmath478 this expansion in connection with the one above for @xmath468 $ ] leads to @xmath477-\\phi_2(a'_2 ) & = & c^{(5)}_d \\tau_3\\,h_2 ^ 3\\ , \\left ( b_3 - b_1^{3}\\right ) + o(h_2 ^ 3)+o(h_2q_n ) \\quad \\mbox{a.s}.\\end{aligned}\\ ] ] the proof of equation ( [ eq : biasphi2 - 1 ] ) is completed by applying lemma [ lem : useful ] to the above result .",
    "the estimator is asymptotically unbiased since the bias converges to @xmath120 faster than either the sample or the stochastic constraints .",
    "equations ( [ eq : biasphi2 - 2 ] ) and ( [ eq : relerr2 ] ) follow along the same lines .",
    "the main difference is that the stochastic constraint now becomes @xmath84 , where @xmath479 according to ( [ eq : bandw3 ] ) .",
    "[ lem : relbias2 ] the asymptotic relative bias , @xmath480 is non - positive .",
    "* proof : * as @xmath481 , the relative bias converges to @xmath482 .",
    "@xmath483 is a positive number . by definition ,",
    "@xmath484 . using the density function defined in lemma  ( [ lem : relbias1 ] ) , we can write @xmath485 \\right\\}^{2 } \\right ] \\ge 0 $ ] ,",
    "from which it follows that @xmath486 .",
    "( variance of the sample `` curvature '' constraint . )",
    "[ theor : curv - var ] if the hypotheses ( [ h : loc])-([h : dens ] ) above are satisfied , then @xmath432 is an asymptotically consistent estimator @xmath487 more specifically , the following holds :    @xmath488    = o\\left ( \\frac{1}{n^{2c_1 \\nu+\\epsilon_2}}\\right ) , \\quad    \\epsilon_2 = \\min\\ { \\delta , 2-\\delta - d\\,\\nu \\}.\\ ] ]    * proof : * the proof is based on the same approach as in theorem  [ theor : grad - var ] .",
    "the calculations are more extended due to the cross - products between the sample functions @xmath489 , @xmath490 and @xmath491 .",
    "however , in this case we also obtain terms containing doublets , triplets and quartets of sampling points . since the complications are of a trivial nature , the lengthy calculations will be omitted here .",
    "using for the curvature step equation ( [ hata ] ) , the quartet term dominates the convergence .",
    "this term leads to the slow asymptotic decline of the variance as @xmath492 or equivalently as @xmath493 .",
    ".calculations of @xmath320 , @xmath494 , @xmath236 , @xmath495 , and the relative bias of the `` gradient '' and `` curvature '' constraint estimators using different kernel functions . [ cols=\"^,^,^,^,^\",options=\"header \" , ]     the asymptotic relative bias of the `` gradient '' and `` curvature '' constraint estimators obtained for different types of kernel functions , according to equations  ( [ eq : relerr1 ] ) and ( [ eq : relerr2 ] ) , is shown in table  ( [ table1 ] ) .",
    "in particular , we include the _ gaussian kernel _ , @xmath496 , the _ triangular kernel _ , @xmath497 , the _ quadratic kernel _ , @xmath498 , and the _ tricube kernel _ , @xmath499 .",
    "the gaussian kernel is not compactly supported , but it decays to zero very fast .",
    "the quadratic kernel gives the lowest relative bias , followed by the tricube kernel .",
    "model parameter inference is based on the procedure introduced in @xcite , which is expanded herein .",
    "the main idea is to estimate the ssrf parameters , @xmath23 by matching sample constraints with their stochastic counterparts .",
    "we use the sample constraints @xmath500 @xmath501 and @xmath502 , given by equations  ( [ bars0 ] ) , ( [ bars1irr ] ) , ( [ bars2irr ] ) respectively , as well as the stochastic constraints @xmath68,$ ] @xmath503 $ ] and @xmath504 , $ ] given by equations  ( [ stoch-0 ] ) , ( [ semi - der2 ] ) , ( [ semi - der4 ] ) respectively .",
    "we also impose the normalization constraint ( [ s0prime ] ) .    determining @xmath23",
    "is then expressed as an optimization problem that aims at minimizing the deviation between the stochastic moments and their estimators ; the latter include the sample - based variance , gradient , and curvature constraints , and @xmath166 for the normalization constraint .",
    "we introduce the metric @xmath505 to measure the distance between the sample and ensemble constraints :    @xmath506}{{\\mathbb{e}}[s_0]}\\right ) ^{1/\\beta } \\right\\}^2 \\nonumber \\\\      & + & \\left\\ { 1-\\left(\\frac{\\overline{\\mathcal{s}_1}(\\hat{a}_1 ) }      { \\overline{\\mathcal{s}_2}(\\hat{a}_2 ) }      \\frac{{\\mathbb{e}}[s_2(\\hat{a}_2)]}{{\\mathbb{e}}[s_1(\\hat{a}_1)]}\\right)^{1/\\beta } \\right\\}^2\\end{aligned}\\ ] ]    in equation  ( [ functional2 ] ) , @xmath68,$ ] @xmath503 $ ] and @xmath504 $ ] are the values of the constraints obtained for the `` current '' values of the spartan parameters @xmath507 @xmath14 and @xmath508 and for @xmath509 as given by ( [ hata ] ) .",
    "the simplex search method of nelder and mead @xcite is used for the optimization .",
    "the initial parameter vector @xmath510 is updated at every optimization step .",
    "for @xmath13 the value @xmath511 is arbitrarily chosen .",
    "the initial value @xmath512 of the characteristic length is estimated from the data .",
    "the initial estimate of the characteristic length is given by @xmath513^{1/2}. $ ] the frequency cutoff @xmath15 is chosen according @xmath514 .",
    "the final vector , @xmath515 , to which the optimization converges gives the optimal parameters of the ssrf model .",
    "note that the functional @xmath516 is independent of @xmath12 , which can be set equal to @xmath166 during the optimization .",
    "the optimal @xmath517 is obtained using the condition of the variance independence from @xmath94 and @xmath13 , i.e. , equation ( [ eq : eta0 ] ) , which leads to the following : @xmath518 in light of ( [ stoch-0 ] ) and ( [ s0prime ] ) , equation  ( [ eta0optimal ] ) guarantees that the model variance matches the sample variance .",
    "some comments are in order regarding the definition of the distance metric ( [ functional2 ] ) .",
    "the functional is of the general form @xmath519 , where @xmath520}{\\overline{\\mathcal{s}_1}(\\hat{a}_1 ) \\ , { \\mathbb{e}}[s_0 ] } , \\quad z_3=\\frac{\\overline{\\mathcal{s}_1}(\\hat{a}_1 ) \\ , { \\mathbb{e}}[s_2(\\hat{a}_2 ) ] } { \\overline{\\mathcal{s}_2}(\\hat{a}_2)\\,{\\mathbb{e}}[s_1(\\hat{a}_1)]}.\\ ] ] the number of terms ( squares ) in @xmath521 is equal to the number of variables .",
    "the @xmath522 are functions that involve specific sample and ensemble constraints .",
    "the definitions of @xmath523 , @xmath524 are motivated by the goals of ( i ) eliminating the dependence on @xmath12 ( since the latter is an overall scaling factor ) ( ii ) defining dimensionless variables so that the optimization does not depend on the units used and ( iii ) forming combinations of constraints of similar magnitude so that they contribute on an equal footing in the optimization .",
    "straightforward constraint differences , i.e. , @xmath525 $ ] are neither dimensionless nor of similar magnitude . using ratios @xmath526 $ ] yields dimensionless ratios of similar magnitude , but it preserves the @xmath12 dependence .",
    "the proposed combinations for @xmath522 for @xmath527 , which are of the form @xmath528/\\ , \\overline{\\mathcal{s}_i}\\,{\\mathbb{e}}[s_{i-1}]$ ] involve ratios of the form @xmath529/{\\mathbb{e}}[s_{i-1}]$ ] , which eliminate the @xmath12 dependence .",
    "a significant advantage of using ratios @xmath526 $ ] is that @xmath526=\\overline{\\varphi_{i}(h_i)}/\\phi_i(a_i)$ ] for @xmath530 .",
    "that is , the terms @xmath531 in the denominators of both @xmath532 and @xmath529 $ ] drop out  see equations ( [ semi - der2 ] ) , ( [ bars1irr ] ) for the generalized gradient constraint , and ( [ semi - der4 ] ) , ( [ bars2irr ] ) for the generalized curvature constraint .",
    "for example , in the case of the generalized gradient constraint this means that even if the limit of @xmath533 for @xmath534 is not well defined ( i.e. , for non - differentiable models ) , the ratio @xmath526 \\propto { \\overline{f_{x}}(h_1)}/ f_{{\\lambda}}(a_1)$ ] is still well defined . similarly one can show that the respective ratio for the generalized curvature constraint is also well defined .",
    "larger values of the exponent @xmath535 give smaller values of the distance functional for the same number of iterations .",
    "the results for the ssrf parameters do not depend on @xmath535 .",
    "hence , @xmath535 is a handle on the convergence rate of the optimization and can be set to one .",
    "multiple `` solutions '' of the minimization problem for the model parameters can not be ruled out . the distance functional has by definition a single solution in terms of the @xmath522 . however , since the dependence @xmath536 is nonlinear , more than one solutions for @xmath537 may be possible , or the optimization algorithm may get trapped near local minima .",
    "it is acceptable to have more than one solutions corresponding to different types of `` reasonable '' spatial dependence .",
    "numerical experiments based on simulated samples are conducted to illustrate the performance of the proposed ssrf inference process .",
    "the experiments investigate the ability of fgc - ssrfs to model spatial distributions generated based on commonly used theoretical models .",
    "the comparisons are based on the covariance function and on cross - validation .",
    "three covariance models are considered :    1 .",
    "spherical @xmath538 2 .",
    "exponential @xmath539 3 .",
    "gaussian @xmath540    a uniform distribution of @xmath541 sampling locations @xmath542 on the two - dimensional domain @xmath543\\times [ 0,5]$ ] is assumed .",
    "the simulated data are denoted by @xmath544 @xmath545 where @xmath546 is the _ sample index_. the data are generated from a standard gaussian spatial random field ( zero mean and unit variance ) using the cholesky lu decomposition method .",
    "the spatial dependence is given by the three models above , with correlation lengths @xmath547 and @xmath548 @xmath549 .",
    "for each covariance model @xmath550 independent samples are obtained .",
    "each realization differs from the others in both the sampling locations and the values of the field .",
    "the triangular kernel with support @xmath551 $ ] is used in ssrf parameter estimation for all the samples .    for each sample",
    ", the ssrf covariance estimator is calculated at @xmath552 , uniformly spaced intervals between @xmath120 and @xmath553 figure [ fig : sphe ] displays the results for simulations based on the spherical model .",
    "the covariance function obtained from a single sample is shown for plot ( a ) , and for the correlation function in plot ( b ) .",
    "the latter is obtained from the ssrf covariance estimator following division by the sample variance estimate and eliminates the impact of sample - to - sample variance fluctuations .",
    "box plots based on all the samples are shown in plot ( c ) for the covariance function and in plot ( d ) for the correlation function .",
    "the same plots for the exponential model are shown in figure  [ fig : expo ] , and for the gaussian model in figure  [ fig : gaus ] .",
    "the closer agreement is between the ssrf estimator and the exponential model .",
    "this is justified by the fact that in @xmath554 the ssrf model for @xmath555 and @xmath556 is equivalent to the exponential covariance @xcite . the ssrf estimator matches the gaussian covariance very well near the origin , due to the differentiability of both models . at large lags",
    "the ssrf model box plots exhibit considerable scatter , which is due to the fact that for certain realizations the optimization converges to negative @xmath13 .",
    "it is clear from the plots that the ssrf model does not provide a perfect match with the `` true '' covariance models over the entire range of lags .",
    "however , this is not a major obstacle in geostatistical applications , in which the `` true '' covariance is unknown . in practice ,",
    "estimation of the empirical covariance function ( or equivalently the variogram ) from a single sample involves considerable uncertainties , which are difficult to quantify @xcite .",
    "the uncertainties are more pronounced at larger lags , at which the averaging procedure involves a smaller number of pairs . moreover",
    ", the theoretical covariance functions merely represent approximations of `` actual '' covariance functions , and thus do not have any `` inherent '' advantage over the ssrf model .      in geostatistical applications ,",
    "the performance of a spatial model is typically evaluated by its ability to `` predict '' measured sample values at a number of cross validation points .",
    "here we consider @xmath557 sampling locations over the domain @xmath558\\times [ 0,100].$ ] the set of @xmath559 points is partitioned into a validation set , @xmath560 , consisting of @xmath561 points chosen at random , and the training set , @xmath562 including the remaining @xmath563 points .",
    "the two sets of points are shown in figure  [ fig : locations ] .",
    "one hundred independent samples are simulated from a gaussian srf with mean @xmath564 and standard deviation @xmath565 using an exponential covariance model , which will henceforth be referred to as the `` true model '' .",
    "the correlation length is set to @xmath566 ( i.e. , the correlation range , where the covariance drops to @xmath567 of the initial value is @xmath568 ) .",
    "the true exponential model and the ssrf covariance estimator , obtained from a single sample on @xmath569 , are given in figure [ fig : predfig1 ] .",
    "the behavior of the spartan estimator follows the plots of figure  ( [ fig : expo ] ) , that is , the ssrf overestimates the true model near the origin , where it fails to capture the abrupt decline of the exponential .",
    "the performance of the ssrf covariance model is evaluated by means of cross validation .",
    "we use the method of ordinary kriging , e.g. ,  @xcite , both with the ssrf covariance and the true exponential covariance to `` predict '' the field values in @xmath570 the predictions based on the ssrf covariance will be denoted by @xmath571 while those of the true model with @xmath572 @xmath573 ; @xmath574 is the realization ( sample ) index . in general , a prediction will be denoted by @xmath575 where `` t = ssrf '' for the ssrf model and `` t = true '' for the true covariance .",
    "the relative prediction error is then given by @xmath576    in table  2 we compare for each point of @xmath560 the mean relative error ( mre ) , @xmath577 , and the mean absolute relative error ( mare ) , @xmath578 .",
    "the mre is @xmath567 or lower for both estimators , as expected given the fact that kriging is an unbiased predictor .",
    "the mare is slightly higher for the spartan model .",
    "this is explained based on the difference between the ssrf and the true covariance function ( see figure  [ fig : predfig1 ] below ) .",
    "note that at @xmath579 both models give the same results for the mre and the mare .",
    "this happens because @xmath580 does not have any nearby neighbors , and thus the prediction at this point is reduced to the mean value .",
    "the analysis in this section shows that the ssrf covariance model performs satisfactorily , in terms of cross validation compared to the predictions obtained with the exponential model used to generate the data .",
    "ccccccccccc + * statistics * & @xmath581 & @xmath582 & @xmath583 & @xmath584 & @xmath585 & @xmath586 & @xmath587 & @xmath588 & @xmath589 & @xmath590 + [ 0.5ex ] + mre true & @xmath591 & @xmath592 & @xmath593 & @xmath594 & @xmath595 & @xmath596 & @xmath597 & @xmath598 & @xmath599 & @xmath600 +   + mre spartan & @xmath601 & @xmath602 & @xmath603 & @xmath594 & @xmath604 & @xmath605 & @xmath606 & @xmath607 & @xmath608 & @xmath600 +   + mare true & @xmath609 & @xmath610 & @xmath611 & @xmath612 & @xmath613 & @xmath614 & @xmath615 & @xmath616 & @xmath617 & @xmath618 +   + mare spartan & @xmath619 & @xmath620 & @xmath621 & @xmath612 & @xmath622 & @xmath623 & @xmath624 & @xmath625 & @xmath626 & @xmath627 +   +    [ tab : pred1 ]",
    "this research is supported by the marie curie action : marie curie fellowship for the transfer of knowledge ( project spatstat , contract no .",
    "mtkd - ct-2004 - 014135 ) and co - funded by the european social fund and national resources - ( epeaek - ii ) pythagoras .",
    "hristopulos , d. t. ( 2002 ) . new anisotropic covariance models and estimation of anisotropic parameters based on the covariance tensor identity .",
    "res . and risk assessment _ , * 16*(1 ) , 43 - 62 .",
    "hristopulos , d. t. ( 2004 ) .",
    "anisotropic spartan random field models for geostatistical analysis . in _ proceedings of 1st international conference on advances in mineral resources management and environmental geotechnology 2004 _ ( eds z agioutantis and k komnitsas ) , pp .",
    "127 - 132 .",
    "heliotopos conferences , athens .",
    "hristopulos , d. t. ( 2005 ) .",
    "identification of spatial anisotropy by means of the covariance tensor identity . in _ mapping radioactivity in the environment :",
    "spatial interpolation comparison 2005 _ ( ed . g. dubois ) , office for official publications of the european communities , luxembourg , in print .",
    "hristopulos , d. t. ( 2005 ) .",
    "spartan gaussian random fields for geostatistical applications : non - constrained simulations on square lattices and irregular grids . _ j. comput .",
    "methods sci .",
    "_ , * 5*(2 ) , 149 - 164 .",
    "smith , r.l .",
    "spatial statistics in environmental science . in _ nonlinear and nonstationary signal processing . _",
    "j. fitzgerald , r. l. smith , a. t. walden and p. c. young ) , pp .",
    "152 - 183 , cambridge university press , cambridge ."
  ],
  "abstract_text": [
    "<S> this paper addresses the inference of spatial dependence in the context of a recently proposed framework . </S>",
    "<S> more specifically , the paper focuses on the estimation of model parameters for a class of generalized gibbs random fields @xcite , i.e. , spartan spatial random fields ( ssrfs ) . </S>",
    "<S> the problem of parameter inference is based on the minimization of a distance metric . </S>",
    "<S> the latter involves a specifically designed distance between sample constraints ( variance , generalized `` gradient '' and `` curvature '' ) and their ensemble counterparts . </S>",
    "<S> the general principles used in the construction of the metric are discussed and intuitively motivated . in order to enable calculation of the metric from sample data , estimators for generalized `` gradient '' and </S>",
    "<S> `` curvature '' constraints are constructed . </S>",
    "<S> these estimators , which are not restricted to ssrfs , are formulated using compactly supported kernel functions . </S>",
    "<S> an intuitive method for kernel bandwidth selection is proposed . </S>",
    "<S> it is proved that the estimators are asymptotically unbiased and consistent for differentiable random fields , under specified regularity conditions . for continuous but non - differentiable random fields </S>",
    "<S> , it is shown that the estimators are asymptotically consistent . </S>",
    "<S> the bias is calculated explicitly for different kernel functions . </S>",
    "<S> the performance of the sample constraint estimators and the ssrf inference process are investigated by means of numerical simulations .    </S>",
    "<S> [ multiblock footnote omitted ] </S>"
  ]
}