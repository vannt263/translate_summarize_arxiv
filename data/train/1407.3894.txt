{
  "article_text": [
    "in several physical problems , such as estimation of the mass inertia matrix in the design of controllers for solid structures and robots , an overdetermined linear system of equations with multiple right hand side vectors arises with the constraint that the unknown matrix be symmetric and positive definite ; see , e.g. , @xcite .",
    "a method for solving such a problem has been proposed in @xcite .",
    "there are also physical contexts , such as modeling a deformable structure @xcite and computing the correlation matrix in finance or insurance / reinsurance industries @xcite , where a symmetric positive semi - definite solution of an over determined linear system of equations needs to be computed or equivalently the problem @xmath0    needs to be solved , where @xmath1 , with @xmath2 , are given and @xmath3 , a symmetric positive semi - definite matrix , is to be computed as a solution .",
    "in some special applications , the data matrix @xmath4 has a simple structure , which may be taken into consideration for efficiently organized computations .",
    "computing the correlation matrix in finance is such an example where the data matrix is the identity matrix ; see , e.g. , @xcite .",
    "+ unlike the positive definite total least squares problem , here the unknown matrix is singular and thus our previously defined error formulation in @xcite is no more applicable .",
    "we need to formulate the error in the measured data and target matrices as a function of the unknown matrix but not its inverse . +",
    "a number of least squares formulations have been proposed for the physical problems , which may be classified as ordinary and total least squares problems . unlike the ordinary formulation , in a total least squares formulation",
    "both data and target matrices are assumed to contain error .",
    "also , single or multiple right hand sides may arise . in @xcite ,",
    "ordinary and total least squares formulations with single or multiple right hand sides have been considered . for detailed analysis of total least squares ,",
    "see @xcite .",
    "+ here , we consider an specific case of the total least squares problem with multiple right hand side vectors .",
    "our goal is to compute a symmetric positive semi - definite solution @xmath3 of the overdetermined system of equations @xmath5 , where both matrices @xmath4 and @xmath6 may contain error .",
    "several approaches have been proposed for this problem , commonly considering the ordinary least squares formulation and minimizing the error @xmath7 over all @xmath8 symmetric positive semi - definite matrices , where @xmath9 is the frobenious norm .",
    "larson @xcite discussed a method for computing a symmetric solution to an overdetermined linear system of equations based on solving the corresponding normal system of equations .",
    "krislock @xcite proposed an interior point method for solving a variety of least squares problems with positive definiteness constraint .",
    "woodgate @xcite described a new algorithm for solving a similar problem in which a symmetric positive semi - definite matrix @xmath10 is computed to minimize @xmath11 , with known @xmath12 and @xmath13 . in @xcite",
    ", toh introduced a path following algorithm for solving a positive semi - definite quadratic optimization problem . later in 2009",
    ", he posted a matlab package for solving such a problem ; see @xcite .",
    "hu @xcite gave a quadratic programming approach to solve a least squares problem with a symmetric positive definite unknown matrix . in his method , the upper and lower bounds for the entries of the target matrix can be given as extra constraints .",
    "in real measurements , however , both the data and target matrices may contain error .",
    "thus , to be practical , a total least squares formulation seems to be appropriate .",
    "here , we define a new error function to consider error in both data and target matrices and propose an iterative algorithm to minimize the defined error .",
    "+ if the goal is to compute the correlation matrix , the mathematical problem is a little different .",
    "computing the correlation matrix is very important in financial modeling .",
    "it is applicable for example in obtaining a quadratic model for an economical system and even in reverse engineering for extreme scenario stress testing @xcite . in this case",
    ", the data matrix is the identity and a large number of linear constraints are to be satisfied .",
    "sun @xcite presented an algorithm for computing the correlation matrix .",
    "rebonato @xcite and werner @xcite also discussed solving the same problem .",
    "we will see later that the minimum rank problem can also be solved by applying our proposed algorithm .",
    "this problem appears in the literature in diverse areas including system identification and control , euclidean embedding , and collaborative filtering ; see @xcite . in a minimum rank problem ,",
    "the goal is to find a positive semi - definite solution with the minimum possible rank to an overdetermined linear system of equations .",
    "+ the remainder of our work is organized as follows . in section 2",
    ", we define a new error function for solving a positive semi - definite total least squares problem with a fixed rank . a method for solving the resulting optimization problem",
    "is presented in section 3 .",
    "also , a discussion on solving the positive semi - definite total least squares problem ( with arbitrary rank ) is given in section 3 . in section 4 ,",
    "we introduce two slightly different problems and discuss how to solve them based on the proposed method in section 3 .",
    "these two problems are : the minimum rank problem and computing the correlation matrix .",
    "comparative computational results are given in section 5 .",
    "section 6 gives our conclusion .",
    "available methods for solving a positive semi - definite least squares problem consider an ordinary least squares formulation ; see , e.g. , @xcite .",
    "a practically useful total error formulation was introduced in @xcite for a positive definite total least squares problem . based on this formulation , the solution of the optimization problem @xmath14 is a solution of a corresponding positive definite total least squares problem , where @xmath15 is symmetric and by @xmath16 , we mean @xmath15 is positive definite .",
    "the error formulation in @xcite not being suitable here , we first motivate and present a new error formulation for the positive semi - definite total least squares case .",
    "+ in ( [ 2 ] ) , the entries of @xmath17 and @xmath18 represent the errors in @xmath4 and @xmath6 , respectively . here , we need to represent the error in @xmath4 independent of @xmath19 . before discussing how to solve the positive semi - definite total least squares problem , we consider the newly noted problem , positive semi - definite total least squares problem with a given rank , @xmath20 , of the unknown matrix ( r@xmath20-psdtls ) . in section 3 , we outline an algorithm for solving r@xmath20-psdtls and discuss how to solve the positive semi - definite total least squares problem applying the proposed algorithm .",
    "+ the error in @xmath4 is supposed to be the difference between the real value of @xmath4 and the predicted value for @xmath4 obtained by @xmath5 . to compute the predicted value for @xmath4 , we use the general least squares solution of the system @xmath21 . considering the block form @xmath22 and @xmath23 , where @xmath24 , for @xmath25 , we have @xmath26 , for @xmath25 . the general solution to such a linear system has the form @xmath27 where @xmath28 is the pseudo - inverse of @xmath15 and @xmath29 is an arbitrary vector in the null space of @xmath15 @xcite .",
    "a straight choice for @xmath29 is @xmath30 which results in @xmath31 and @xmath32 .",
    "we later consider the suitable choices for @xmath29 which minimizes @xmath33 .",
    "to compute @xmath34 from ( [ 3 ] ) , the spectral decomposition can be applied . +   + * result . *    now , making use of the spectral decomposition of @xmath35 in ( [ 3 ] ) , we have @xmath36 where @xmath37 , for @xmath38 , are arbitrary vectors , and @xmath39 thus , the predicted value for @xmath4 is @xmath40 with @xmath41 , arbitrary , and the error in @xmath4 is equal to @xmath42 .",
    "a reasonable choice for @xmath43 in this formulation would be the one minimizing the norm of @xmath44 , which is the solution of the optimization problem @xmath45 where @xmath46 and @xmath9 is the frobenius norm . solving ( [ 6 ] ) results in @xcite @xmath47 substituting ( [ 7 ] ) in ( [ 5 ] ) , we get @xmath48 using @xmath49 along with ( [ 8 ] ) , we get @xmath50 based on the above discussion , @xmath51 and @xmath52 represent the error in @xmath4 and @xmath6 respectively . thus , to solve a rank @xmath20 positive semi - definite total least squares problem",
    ", it is appropriate to minimize the error @xmath53 with @xmath54 standing for trace of a matrix .",
    "consequently , the optimization problem @xmath55 needs to be solved , where @xmath15 is symmetric and by @xmath56 , we mean @xmath15 is positive semi - definite .",
    "we can rewrite the optimization problem using the spectral decomposition of @xmath15 and substituting @xmath15 and @xmath28 by @xmath57 and @xmath58 respectively . considering well - known properties of the trace operator @xcite and the above formulation for @xmath15 and @xmath28 , we get @xmath59 letting @xmath60 , @xmath61 and @xmath62 , problem ( [ 10 ] ) is then equivalent to @xmath63 where @xmath64 satisfies @xmath65 and @xmath66 is a nonsingular diagonal matrix . +",
    "the lagrangian function corresponding to the constrained optimization problem @xmath67 is @xmath68 , where the lagrangian coefficient vector @xmath69 corresponds to the constraint vector @xmath70 .",
    "necessary conditions for a solution , known as karush - kahn - ticker conditions , is @xmath71 as well as @xmath72 , which gives @xmath70 ; for kkt conditions , see @xcite .",
    "thus , @xmath73 is the lagrangian function for the optimization problem ( [ 12 ] ) .",
    "+    an appropriate characteristic of the error formulation proposed by @xmath74 is that its value is nonnegative and it is equal to zero if and only if @xmath75 .",
    "it is clear that if @xmath75 , then @xmath76 . assuming @xmath77 , from ( [ 66 ] ) we have @xmath78 which holds if and only if @xmath79 multiplying both sides from right by @xmath80 , we get @xmath81 or equivalently @xmath82 if ( [ 67 ] ) is satisfied , then we have @xmath83 ; hence , @xmath84 .",
    "here , we discuss how to solve ( [ 12 ] ) .",
    "we also study the computational complexity and the convergence properties of our proposed algorithm .",
    "we are to propose an algorithm for solving ( [ 12 ] ) .",
    "more precisely , a nonsingular diagonal matrix @xmath85 and a matrix @xmath86 need to be computed to minimize @xmath87 where @xmath88 is the stiefel manifold @xcite : @xmath89 in the following lemma , we show that the optimization problem ( [ 12 ] ) is strictly convex under a weak assumption on the data and target matrices .",
    "we also make use of the well - known properties of convexity to propose our algorithm .",
    "+   +    [ 55 ] the function @xmath90 is always convex and it is strictly convex on the set @xmath91 , where @xmath92 .    the key point of the proof is to reformulate @xmath93 as @xmath94 thus , @xmath93 is always convex and it is strictly convex if and only if @xmath95 + @xmath96 , for @xmath97 , is positive definite which holds if and only if @xmath98 , for @xmath97 , has full column rank .    * note .",
    "* since the function @xmath93 is strictly convex and the set @xmath99 is convex , a point @xmath100 satisfying the karush ",
    "tucker ( kkt ) optimality conditions is the unique solution of problem ( [ 12 ] ) ; for kkt conditions , see @xcite .",
    "+   + next , in the following theorem we derive the kkt optimality conditions for problem ( [ 12 ] ) .",
    "+    [ 14 ] if @xmath101 is the solution of problem ( [ 12 ] ) , then it satisfies @xmath102 where @xmath103 is the @xmath104th column of @xmath105 .",
    "+    the kkt necessary conditions for ( [ 12 ] ) are obtained by setting @xmath106 .",
    "thus , if @xmath101 forms a solution for ( [ 12 ] ) with @xmath107 , then we must have @xmath108 , for @xmath109 . to simplify the computation of @xmath110",
    ", we can reformulate @xmath111 using the definition of the trace operator .",
    "let @xmath112 and @xmath113 .",
    "we have @xmath114 and @xmath115 so , @xmath111 is equal to @xmath116 now , from ( [ 15 ] ) we have    @xmath117    and @xmath118 can be computed by @xmath119 .    considering the above discussion ,",
    "in each iteration of our proposed algorithm we need to + ( 1 ) compute one term of the sequence @xmath120 converging to the minimizer of the + @xmath121error @xmath122 , and + ( 2 ) compute the diagonal elements of @xmath123 from ( [ 27 ] ) .",
    "+ edelman @xcite introduced two methods for solving optimization problems on stiefel manifolds : the newton method and conjugate gradient method on the stiefel manifold . here , we adaptively use the newton approach to develop an algorithm for solving ( [ 12 ] ) . in each iteration of our proposed algorithm ,",
    "a newton step is computed from the newton method on the stiefel manifold and then the diagonal elements of @xmath123 , @xmath118 , are updated by ( [ 27 ] ) .",
    "we show in section 3.2 that our proposed algorithm converges to the unique solution of ( [ 12 ] ) at least quadratically .",
    "also , we discuss its computational complexity in section 3.2 . +   + we are now ready to outline the steps of our proposed algorithm . + * algorithm 1 . * solving rank @xmath20 positive semi - definite total least squares problem using the newton method on stiefel manifold ( r@xmath20-psdtls ) .",
    "+ - @xmath124 and @xmath125 are upper bounds for relative and absolute error , respectively taken to be close to the machine ( or user s ) unit roundoff error and machine ( or user s ) zero .",
    "+ ( 1 ) let @xmath60 , @xmath62 and @xmath61 .",
    "+ ( 2 ) choose @xmath105 such that @xmath65 .",
    "+ repeat + ( 3.1 ) let @xmath119 .",
    "+ ( 3.2 ) compute the @xmath126 matrix @xmath127 such that @xmath128 and let @xmath129 ( 3.3 ) to compute @xmath130 , solve the linear system of equations @xmath131",
    "@xmath132where @xmath133 @xmath132and @xmath134 .",
    "+ ( 3.4 ) move from @xmath105 in direction @xmath130 to @xmath135 using @xmath136 , where @xmath137 @xmath132is the compact @xmath138 factorization of @xmath139 , and @xmath140 and @xmath141 are : @xmath142 @xmath132with @xmath143 .",
    "+ ( 3.5 ) compute @xmath144 .",
    "let @xmath145 . +",
    "until @xmath146 .",
    "+ ( 4 ) let @xmath147 and @xmath148",
    ". +   + * note . * the linear equation @xmath149 may be solved by various methods including conjugate gradient and gmres @xcite .",
    "another possible method is to convert the linear operator appearing on the left side of ( [ 17 ] ) to an @xmath150 linear system of equations . in section 5",
    ", we present the numerical results obtained by using these three methods and compare the respective obtained accuracies and computing times .",
    "+      in section 3.1 , we outlined algorithm 1 to solve the rank @xmath20 positive semi - definite total least squares problem .",
    "here , we discuss how to solve the general positive semi - definite total least squares problem . +",
    "a positive semi - definite solution for the overdetermined linear system of equations @xmath5 , whose rank is not known , needs to be computed .",
    "this problem arises for example in estimation of compliance matrix of a deformable structure @xcite . to solve this problem",
    ", we can apply psdtls for possible values of @xmath151 , compute the corresponding solutions @xmath152 , and identify the one minimizing @xmath148 .",
    "we will refer to this approach as psdtls . in section 5.1 ,",
    "we report some numerical results to compare psdtls by two existing methods .",
    "although our proposed method ( psdtls ) computes the minimizer of @xmath153 for each value of @xmath151 and then finds the optimal solution among @xmath154 , for @xmath151 , it takes less time to solve the problem than two other proposed methods in the literature .      here , we discuss convergence properties of r@xmath20-psdtls .",
    "we cite a theorem to be used to establish the local quadratic convergence of r@xmath20-psdtls to the unique solution of ( [ 12 ] ) .",
    "we also show that the computational complexity of every iteration of our proposed algorithm is @xmath155 moreover , we provide an upper bound for the computational complexity of our proposed approach for solving the positive semi - definite total least squares problem , psdtls .    [ 28 ] ( @xcite ) newton s method @xcite applied to the function @xmath156 on the stiefel manifold @xmath157 locally converges to the unique solution of @xmath158 at least quadratically .",
    "+    see @xcite .",
    "+    algorithm 1 converges locally to the unique solution of problem ( [ 12 ] ) at least quadratically .",
    "in algorithm 1 , we have two main computations : applying newton s approach on stiefel manifold to update @xmath105 and updating the scalars @xmath118 using ( [ 27 ] ) . the rate of convergence is not affected by ( [ 27 ] ) and it is governed by newton s approach .",
    "thus , considering theorem [ 28 ] , r@xmath20-psdtls converges at least quadratically to the unique solution of ( [ 12 ] ) .",
    "@xmath159    @xmath160**computing cost : rank @xmath20 positive semi - definite total least squares problem . * * the computational complexity of one iteration of r@xmath20-psdtls is given in table [ t1 ] .",
    "the first , second and third columns respectively give the computational complexities of solving the linear problem ( [ 17 ] ) using conjugate gradient method in the operator form ( cg - o ) , gmres in the operator form ( gmres - o ) and conjugate gradient method after converting ( [ 17 ] ) into a linear system of equations ( cg - l ) ; for details , see @xcite .",
    ".computational complexities for one iteration using different approaches .",
    "[ cols=\"^,^,^,^ \" , ]     considering the numerical results reported in this section , we summarize our observations : +   + ( 1 ) a newly defined problem , r@xmath20-psdls , was considered and an efficient algorithm + @xmath121was proposed for its solution . +",
    "( 2 ) although our proposed algorithm for solving the psdls problem , psdtls , ap- + @xmath121plies r@xmath20-psdtls , for @xmath161 , in search for the solution , it appears to be @xmath121more efficient than psdls - intp and psdls - pftoh .",
    "+ ( 3 ) in contrast with other available methods , our use of total formulation for solving + @xmath121the psdls problem to consider error in both data and target matrices turns to be @xmath121practically effective to produce more meaningful results .",
    "+ ( 4 ) the proposed method for solving the psdls problem , psdtls , is more efficient + @xmath121than the other methods .",
    "+ ( 5 ) the proposed method for solving the minimum rank problem , mr - psdtls , is @xmath121also more efficient than mr - toh and mr - recht .",
    "+ ( 6 ) the proposed method for computing the correlation matrix , cm - psdtls , shows + @xmath121to be more efficient and robust in computing a correlation matrix with a lower @xmath121value of standard deviation of error in @xmath6 as compared to cm - intp and cm - sun .",
    "we proposed a new approach to solve positive semi - definite total least squares ( psdls ) problems .",
    "consideration of our proposed error estimate for both data and target matrices admitted a more realistic problem formulation .",
    "we first considered a newly defined given rank positive semi - definite total least squares ( r@xmath20-psdtls ) problem and presented an at least quadratically convergent algorithm for its solution .",
    "numerical results confirmed the effectiveness of our approach to compute solutions of r@xmath20-psdls problems in less computing time than the interior point method and the path following algorithm .",
    "we then showed how to apply r@xmath20-psdtls to solve the general psdls problem .",
    "based on the reported numerical results , our method for solving the psdls problem also showed to be more efficient than the interior point method and the path following algorithm .",
    "an specifically effective approach was also described to solve the rank @xmath162 positive semi - definite total least squares problem , r@xmath162-psdtls .",
    "in addition , we noted that r@xmath20-psdtls can be applied to other problems arising in control and financial modeling : the minimum rank ( mr ) problem and correlation matrix computation . using the dolan - mor performance profiles",
    ", we showed our proposed method for solving the mr problem to be more efficient than a path following algorithm and a semi - definite programming approach for solving the mr problem .",
    "furthermore , in computing the correlation matrix , numerical results showed lower standard deviation of error as compared to the interior point method and semi - definite programming approach . +   + * acknowledgement . *",
    "the authors thank research council of sharif university of technology for supporting this work .",
    "+    10 edelman a. , arias t. a. , smith s. t. : the geometry of algorithms with orthogonality constraints , siam j. matrix anal .",
    ", 20(2 ) , 303 - 353 ( 1998 ) golub g. h. , van loan c. f. : an analysis of the total least squares problem , siam j. numer .",
    ", 17 , 883 - 893 ( 1980 ) hu h. : positive definite constrained least - squares estimation of matrices , linear algebra appl , 229 , 167 - 174 ( 1995 ) hu h. , olkin i. : a numerical procedure for finding the positive definite matrix closest to a patterned matrix , statistical and probability letters , 12 , 511 - 515 ( 1991 ) krislock n. g. , lang j. , varah j. , pai d. k. , seidel h. : local compliance estimation via positive semi - denite constrained least squares , ieee trans .",
    "robotics and automation 20(6 ) , 10071011 ( 2004 ) larson h. j. : least squares estimation of the components of a symmetric matrix , technometrics , 8(2 ) , 360 - 362 ( 1966 ) mcinroy j. , hamann j. c. : design and control of flexure jointed hexapods , ieee trans .",
    "robotics and automation , 16(4 ) , 372 - 381 ( 2000 ) paige c. c. , strako z. : scaled total least squares fundamentals , numer . math .",
    ", 91 , 117 - 146 ( 2000 ) rebonato r. , jckel p. : the most general methodology to create a valid correlation matrix for risk management and option pricing purposes , j. risk , 2 , 1727 ( 1999 ) recht b. , fazel m. , parrilo p.",
    "a. : guaranteed minimum - rank solutions of linear matrix equations via nuclear norm minimization , siam review , 52(3 ) , 471 - 501 ( 2010 ) smith s. t. : optimization techniques on riemannian manifolds , fields ins",
    ". com . , 3 , 113 - 146 ( 1994 ) sun d. , gao y. : calibrating least squares covariance matrix problems with equality and inequality constraints , siam .",
    "j. matrix anal . and appl .",
    ", 31 , 1432 - 1457 ( 2009 ) tisseur f. : the quadratic eigenvalue problem , siam review , 43(2 ) , 235 - 286 ( 2001 ) toh k. c. : an inexact primal - dual path - following algorithm for convex quadratic sdp , mathematical programming , 112 , 221 - 254 ( 2007 ) woodgate k. g. : least - squares solution of @xmath163 over positive semidefinite symmetric @xmath10 , linear algebra appl . , 245 , 171 - 190 ( 1996 ) fazel m. : rank minimization with applications , phd thesis , stanford university ( 2002 ) huffel s. v. , vandewalle j. : the total least squares problem : computational aspects and analysis , siam ( 1991 ) krislock n. g. : numerical solution of semidefinite constrained least squares problems , m. sc .",
    "thesis , university of british colombia ( 2003 ) nocedal j. , wright s. j. : numerical optimization , springer , new york ( 1999 ) saad y. : iterative methods for sparse linear systems , siam , philadelphia , second edition ( 2003 ) van loan c. f. , golub g. : matrix computation , 4th edition , jhu press ( 2012 ) werner r. , schttle k. : calibration of correlation matrices  sdp or not sdp , technical report , munich university of technology , munich ( 2007 ) poignet p. , gautier m. : comparison of weighted least squares and extended kalman filtering methods for dynamic identification of robots , proceedings of the ieee conference on robotics and automation , san francisco , ca , usa , 3622 - 3627 ( 2000 ) bagherpour n. , mahdavi - amiri n. : direct methods for solving positive definite total least squares problems using orthogonal matrix decompositions , http://arxiv.org/ , ( 2014 ) gauthier g. , goldberg l. , hayes m. , vannerem p. : reverse engineering for extreme scenario stress testing , msci research report , https://fp7.portals.mbs.ac.uk/portals/59/docs/ ( 2010 ) hand p. : conditions for existence of dual certificates in rank - one semidefinite problems , http://arxiv.org/ ( 2014 ) higham n. j. : computing the nearest correlation matrix ( a problem from finance ) , mims eprint : 2006.70 , http://eprints.ma.man.ac.uk/ ( 2006 ) liang x. , li r. c. : the hyperbolic quadratic eigenvalue problem , http://www.uta.edu/math/preprint/rep201401.pdf ( 2014 ) petersen k. b. , pedersen m. s. : the matrix cookbook , http://orion.uwaterloo.ca/  hwolkowi/ ( 2008 ) toh k. c. : qsdp version 0 , beta  a matlab software for convex quadratic semidefinite programming , http://www.math.nus.edu.sg/  mattohkc / qsdp.html ( 2009 ) toh k. c. , yun s. : an accelerated proximal gradient algorithm for nuclear norm regularized least squares problems , http://www.optimization-online.org/db-file/2009/03/2268.pdf ( 2009 )"
  ],
  "abstract_text": [
    "<S> we have recently presented a method to solve an overdetermined linear system of equations with multiple right hand side vectors , where the unknown matrix is to be symmetric and positive definite . </S>",
    "<S> the coefficient and the right hand side matrices are respectively named data and target matrices . </S>",
    "<S> a more complicated problem is encountered when the unknown matrix is to be positive semi - definite . </S>",
    "<S> the problem arises in estimating the compliance matrix to model deformable structures and approximating correlation and covariance matrices in financial modeling . </S>",
    "<S> several methods have been proposed for solving such problems assuming that the data matrix is unrealistically error free . here , </S>",
    "<S> considering error in measured data and target matrices , we propose a new approach to solve a positive semi - definite constrained total least squares problem . </S>",
    "<S> we first consider solving the problem when the rank of the unknown matrix is known , by defining a new error formulation for the positive semi - definite total least squares problem . </S>",
    "<S> minimization of our newly defined error consists of an optimization problem on the stiefel manifold . to solve the optimization problem , in each iteration </S>",
    "<S> a linear operator subproblem arises for which we propose three different iterative methods . </S>",
    "<S> we prove quadratic convergence of our proposed approach . </S>",
    "<S> we then describe how to generalize our proposed method to solve the general positive semi - definite total least squares problem . </S>",
    "<S> we further apply the proposed approach to solve the minimum rank problem and the problem of computing correlation matrix . </S>",
    "<S> comparative numerical results show the efficiency of our proposed algorithms . in solving positive semi - definite total least squares problems </S>",
    "<S> , we find that in most cases the linear operator equation is solved faster and turns to be more accurate using the gmres method . </S>",
    "<S> also , comparison of the results obtained by our algorithm with the ones due to two other methods , the interior point method and a matlab routine for solving a quadratic programming problem with semi - definite constraint based on a path following algorithm , confirms the efficiency of our approach . </S>",
    "<S> numerical test results also show that our approach for computing a correlation matrix leads to smaller standard deviations of error in the target matrix . </S>",
    "<S> finally , the dolan - mor performance profiles are shown to summarize our comparative study . </S>",
    "<S> +    total least squares , positive semi - definite constraints , deformable structures , correlation matrix    65f05 , 65f20 , 49m05 </S>"
  ]
}