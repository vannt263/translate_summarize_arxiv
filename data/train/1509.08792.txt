{
  "article_text": [
    "in this paper we scratch an intelligent variable neighbourhood search ( int - vns ) aimed to achieve further improvements of a successful vns for the minimum labelling spanning tree ( mlst ) and the @xmath1-labelled spanning forest ( @xmath1lsf ) problems .",
    "this approach integrates the basic vns with other complementary intelligence tools and has been shown a promising strategy in  @xcite for the mlst problem and in  @xcite for the @xmath1lsf problem .",
    "the approach could be easily adapted to other optimization problems where the space solution consists of the subsets of a reference set ; like the feature subset selection or some location problems .",
    "first we introduced a local search mechanism that is inserted at top of the basic vns to get the complementary variable neighbourhood search ( co - vns ) .",
    "then we insert a probability - based constructive method and a reactive setting of the size of shaking process .",
    "a labelled graph @xmath2 consists of an undirected graph where @xmath3 is its set of nodes and @xmath4 is the set of edges that are labelled on the set @xmath0 of labels . in this paper",
    "we consider two problems defined on a labelled graph : the mlst and the @xmath1lsf problems .",
    "the mlst problem  @xcite consists on , given a labelled input graph @xmath2 , to get the spanning tree with the minimum number of labels ; i.e. , to find the labelled spanning tree @xmath5 of the input graph that minimizes the size of label set @xmath6 .",
    "the @xmath1lsf problem  @xcite is defined as follows .",
    "given a labelled input graph @xmath2 and an integer positive value @xmath7 , to find a labelled spanning forest @xmath8 of the input graph having the minimum number of connected components with the upper bound @xmath7 for the number of labels to use , i.e. @xmath9 , the labelled subgraph @xmath10 may contain cycles , but they can arbitrarily break each of them by eliminating edges in polynomial time until a forest or a tree is obtained . therefore in both problems , the matter is to find the optimal set of labels @xmath11 . since a mlst solution would be a solution also to the @xmath1lsf problem if the obtained solution tree would not violate the limit @xmath7 on the used number of labels , it is easily deductable that the two problems are deeply correlated .",
    "the np - hardness of the mlst and @xmath1lsf problems was stated in @xcite and in  @xcite respectively .",
    "therefore any practical solution approach to both problems requires heuristics  @xcite .",
    "the first extension of the vns metaheuristic that we introduced for these problems is a local search mechanism that is inserted at top of the basic vns  @xcite .",
    "the resulting local search method is referred to as  _ complementary variable neighbourhood search _",
    "( co - vns )  @xcite .",
    "given a labelled graph @xmath12 with @xmath13 vertices , @xmath14 edges , and @xmath15 labels , co - vns replaces iteratively each incumbent solution @xmath11 with another solution selected from the _ complementary space _ of @xmath11 defined as the sets of labels that are not contained in @xmath11 ; @xmath16 .",
    "the iterative process of extraction of a complementary solution helps to escape the algorithm from possible traps in local minima , since the complementary solution lies in a very different zone of the search space with respect to the incumbent solution .",
    "this process yields an immediate peak of diversification of the whole local search procedure . to get a complementary solution , co",
    "- vns uses a greedy heuristic as constructive method in the complementary space of the current solution . for the mlst and @xmath1lsf problems",
    "the greedy heuristic is the maximum vertex covering algorithm ( mvca )  @xcite applied to the subgraph of @xmath17 with labels in @xmath18 .",
    "note that co - vns stops if either the set of unused labels contained in the complementary space is empty ( @xmath19 ) or a final feasible solution is produced .",
    "successively , the basic vns is applied in order to improve the resulting solution .    at the starting point of vns",
    ", it is required to define a suitable series of neighbourhood structures of size @xmath20 . in order to impose a neighbourhood structure on the solution space @xmath21",
    "we use the hamming distance between two solutions @xmath22 given by @xmath23 where @xmath24 consists of labels that are in one of the solutions but not in the other .",
    "vns starts from an initial solution @xmath11 with @xmath25 increasing iteratively from 1 up to the maximum neighborhood size , @xmath20 .",
    "the basic idea of vns to change the neighbourhood structure when the search is trapped at a local minimum , is implemented by the shaking phase .",
    "it consists of the random selection of another point in the neighbourhood @xmath26 of the current solution @xmath11 .",
    "given @xmath11 , we consider its @xmath27 neighbourhood @xmath26 comprised by sets having a hamming distance from @xmath11 equal to @xmath25 labels , where @xmath28 . in order to construct the neighbourhood of a solution @xmath11",
    ", the algorithm proceeds with the deletion of @xmath25 labels from @xmath11 .",
    "the proposed intelligent metaheuristic ( int - vns ) is built from co - vns , with the insertion of a probability - based local search as constructive method to get the complementary space solutions .",
    "in particular , this local search is a modification of greedy heuristic , obtained by introducing a probabilistic choice on the next label to be added into incomplete solutions . by allowing worse components to be added to incomplete solutions ,",
    "this probabilistic constructive heuristic produces a further increase on the diversification of the optimization process .",
    "the construction criterion is as follows .",
    "the procedure starts from an initial solution and iteratively selects at random a candidate move .",
    "if this move leads to a solution having a better objective function value than the current solution , then this move is accepted unconditionally ; otherwise the move is accepted with a probability that depends on the deterioration , @xmath29 , of the objective function value .",
    "this construction criterion takes inspiration from simulated annealing ( sa )  @xcite .",
    "however , the probabilistic local search works with partial solutions which are iteratively extended with additional components until complete solutions emerge . in the probabilistic local search , the acceptance probability of a worse component into a partial solution",
    "is evaluated according to the usual sa criterion by the boltzmann function @xmath30 , where the temperature parameter @xmath31 controls the dynamics of the search .",
    "initially the value of @xmath31 is large , so allowing many worse moves to be accepted , and is gradually reduced by the following geometric cooling law : @xmath32 , where @xmath33 and @xmath34 $ ] , with @xmath35 being the current best solution .",
    "this cooling law is very fast and produces a good balance between intensification and diversification capabilities .",
    "in addition , this cooling schedule does not requires any intervention from the user regarding the setting of its parameters , as it is guided automatically by the best solution @xmath35 .",
    "therefore the whole optimization process is able to react in response to the search algorithm s behavior and to adapt its setting on - line according to the instance of the problem under evaluation  @xcite .",
    "the probabilistic local search has the purpose of allowing also the inclusion of less promising labels to incomplete solutions .",
    "probability values assigned to each label are decreasing in the quality of the solution they give . in this way , at each step , labels with a better quality will have a higher probability of being selected ; the progressive reduction of the temperature in the adaptive cooling law produces , step by step , an increasing of this diversity in probabilities . at the beginning of int - vns",
    ", the algorithm generates an initial feasible solution at random , that is the first current best solution @xmath35 , and set parameter @xmath20 to the number of labels of the initial solution ( @xmath36 ) .",
    "then the _ complementary _ procedure is applied to @xmath35 to obtain a solution @xmath11 from the complementary space of @xmath35 by means of the probabilistic local search .",
    "the complementary procedure stops if either a feasible solution @xmath11 is obtained , or the set of unused labels contained in the complementary space is empty producing a final infeasible solution .",
    "subsequently , the shaking phase used for the basic vns is applied to the resulting solution @xmath11 .",
    "it consists of the random selection of a point @xmath37 in the neighbourhood @xmath26 of the current solution @xmath11 , as in co - vns .",
    "the successive local search corresponds also to that of co - vns .",
    "however , since either co - vns , or the deletion of labels in the shaking phase , can produce an incomplete solution , the first step of the local search consists of including additional labels in the current solution in order to restore feasibility , if needed .",
    "the addition of labels at this step is according to the probabilistic procedure .",
    "then , the local search tries to drop labels in @xmath37 , and then to add further labels following the greedy rule , until @xmath7 labels emerge . at this step ,",
    "if no improvements are obtained the neighbourhood structure is increased ( @xmath38 ) producing progressively a larger diversification .",
    "otherwise , the algorithm moves @xmath11 to solution @xmath37 restarting the search with the smallest neighbourhood ( @xmath39 ) .",
    "this iterative process is repeated until the maximum size of the shaking phase , @xmath20 , is reached .",
    "the resulting local minimum @xmath11 is compared to the current best solution @xmath35 , which is updated in case of improvement ( @xmath40 ) . at this point a reactive setting for the parameter @xmath20 is used  @xcite . in case of an improved solution , @xmath20 is decreased ( @xmath41 ) in order to raise the intensification factor of the search process .",
    "conversely , in case of none improvement , the maximum size of the shaking is increased ( latexmath:[$q_{max } \\leftarrow min(q_{max}+1 ; 2 \\cdot    algorithm . in each case , the adaptive setting of @xmath20 is bounded to lie in the interval between @xmath43 and @xmath44 to avoid a lack of balance between intensification and diversification factors .",
    "the algorithm proceeds with the same procedure until the user termination conditions are satisfied , producing at the end the best solution to date , @xmath35 , as output .",
    "the achieved optimization strategy seems to be highly promising for both labelling graph problems . ongoing investigation",
    "consists in statistical comparisons of the resulting strategy against the best algorithms in the literature for these problems , in order to quantify and qualify the improvements obtained .",
    "further investigation will deal with the application of this strategy to other problems ."
  ],
  "abstract_text": [
    "<S> in this paper we describe an extension of the variable neighbourhood search ( vns ) which integrates the basic vns with other complementary approaches from machine learning , statistics and experimental algorithmic , in order to produce high - quality performance and to completely automate the resulting optimization strategy . </S>",
    "<S> the resulting intelligent vns has been successfully applied to a couple of optimization problems where the solution space consists of the subsets of a finite reference set . </S>",
    "<S> these problems are the labelled spanning tree and forest problems that are formulated on an undirected labelled graph ; a graph where each edge has a label in a finite set of labels @xmath0 . </S>",
    "<S> the problems consist on selecting the subset of labels such that the subgraph generated by these labels has an optimal spanning tree or forest , respectively . </S>",
    "<S> these problems have several applications in the real - world , where one aims to ensure connectivity by means of homogeneous connections . </S>"
  ]
}