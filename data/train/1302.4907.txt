{
  "article_text": [
    "the problem of small area estimation ( sae ) is how to produce reliable estimates of characteristics of interest such as means , counts , quantiles , et cetera , for areas or domains for which only small samples or no samples are available .",
    "although the point estimators are usually of first priority , a related problem is how to assess the estimation ( prediction ) error .",
    "the great importance of sae stems from the fact that many new programs , such as fund allocation for needed areas , new educational or health programs and environmental planning rely heavily on these estimates .",
    "sae techniques are also used in many countries to test and adjust the counts obtained from censuses that use administrative records .    in 2002",
    "i published a review paper with a similar title ( @xcite ) . in that year",
    "small area estimation ( sae ) was flourishing both in research and applications , but my own feeling then was that the topic has been more or less exhausted in terms of research and that it will just turn into a routine application in sample survey practice .",
    "as the past 9 years show , i was completely wrong ; not only is the research in this area accelerating , but it now involves some of the best known statisticians , who otherwise are not involved in survey sampling theory or applications .",
    "the diversity of new problems investigated is overwhelming , and the solutions proposed are not only elegant and innovative , but also very practical .",
    "@xcite published a comprehensive book on sae that covers all the main developments in this topic up to that time .",
    "the book was written about ten years after the review paper of ghosh and rao ( @xcite ) , published in _ statistical science _ , which stimulated much of the early research in sae .",
    "since 2003 , a few other review papers have been published ; see , for example , rao ( @xcite , @xcite ) , jiang and lahiri ( @xcite , @xcite ) , datta ( @xcite ) and lehtonen and veiganen ( @xcite ) .",
    "notwithstanding , sae is researched and applied so broadly that i decided that the time is ripe for a new comprehensive review that focuses on the main developments in the last 78 years that i am aware of , and which are hardly covered in the review papers mentioned above .",
    "the style of the paper is similar to the style of my previous review , explaining the problems investigated and describing the proposed solutions , but without dwelling on theoretical details , which can be found in the original articles . for further clarity and to make the paper more",
    "self - contained , i  start with a short background and overview some of the `` older '' developments .",
    "i hope that this paper will be useful to researchers who wish to learn about the research carried out in sae and to practitioners who might be interested in applying the new methods .",
    "the term `` sae '' is somewhat confusing , since it is the size of the sample in the area that causes estimation problems , and not the size of the area . also , the `` areas '' are not necessarily geographical districts and may define another grouping , such as socio - demographic groups or types of industry , in which case they are often referred to as domains . closely related concepts in common use are `` poverty mapping '' or `` disease mapping , '' which amount to sae of poverty measures or disease incidence and then presenting the results on a map , with different colors defining different levels ( categories ) of the estimators .",
    "what is common to most small area estimation problems is that point estimators and error measures are required for every area separately , and not just as an average over all the areas under consideration .",
    "sae methods can be divided broadly into `` design - based '' and `` model - based '' methods .",
    "the latter methods use either the frequentist approach or the full bayesian methodology , and in some cases combine the two , known in the sae literature as `` empirical bayes . ''",
    "design - based methods often use a model for the construction of the estimators ( known as `` model assisted '' ) , but the bias , variance and other properties of the estimators are evaluated under the randomization ( design - based ) distribution .",
    "the randomization distribution of an estimator is the distribution over all possible samples that could be selected from the target population of interest under the sampling design used to select the sample , with the population measurements considered as fixed values ( parameters ) .",
    "model - based methods on the other hand usually condition on the selected sample , and the inference is with respect to the underlying model .    a common feature to design- and model - based sae is the use of auxiliary covariate information , as obtained from large surveys and/or administrative records such as censuses and registers . some estimators only require knowledge of the covariates for the sampled units and the true area means of these covariates .",
    "other estimators require knowledge of the covariates for every unit in the population .",
    "the use of auxiliary information for sae is vital because with the small sample sizes often encountered in practice , even the most elaborated model can be of little help if it does not involve a set of covariates with good predictive power for the small area quantities of interest .",
    "consider a population @xmath0 of size @xmath1 , divided into @xmath2 exclusive and exhaustive areas @xmath3 with @xmath4 units in area @xmath5",
    ", @xmath6 .",
    "suppose that samples are available for @xmath7 of the areas , and let @xmath8 define the overall sample , where @xmath9 of size @xmath10 is the sample observed for sampled area @xmath5",
    ", @xmath11 .",
    "note that @xmath10 is random unless a planned sample of fixed size is taken in that area .",
    "let @xmath12 define the characteristic of interest , and denote by @xmath13 the response value for unit @xmath14 belonging to area @xmath5 , @xmath15 , @xmath16 with sample means @xmath17 , where we assume without loss of generality that the sample consists of the first @xmath10 units .",
    "we denote by @xmath18 the covariate values associated with unit @xmath19 and by @xmath20 the column vector of sample means .",
    "the corresponding vector of true area means is @xmath21 .",
    "the area target quantity is denoted by @xmath22 ; for example , @xmath23 , the response area mean .",
    "estimating a proportion is a special case where @xmath13 is binary .",
    "in other applications @xmath22 may represent a count or a quantile .",
    "a recent comprehensive review of design - based methods in sae is provided by lehtonen and veijanen ( @xcite ) . here",
    "i only overview some of the basic ideas .",
    "suppose that the sample is selected by simple random sampling without replacement ( srswor ) and that the target quantities of interest are the means  @xmath24 .",
    "estimation of a mean contains as special cases the estimation of a proportion and the estimation of the area distribution @xmath25 , in which case @xmath26 , where @xmath27 is the indicator function .",
    "estimators of the percentiles of the area distribution are commonly obtained from the estimated distribution .    if no covariates are available the _ direct _ design - unbiased estimator of the area mean and its conditional design variance over the _ randomization _ distribution for given @xmath10 are given by @xmath28\\\\[-8pt ] v_{d}[\\bar{y}_{i}|n_{i } ] & = & ( s_{i}^{2}/n_{i})[1 - ( n_{i}/n_{i})],\\nonumber\\end{aligned}\\ ] ] where @xmath29 . the term `` direct '' is used to signify an estimator that only uses the data available for the target area at the specific time of interest . the variance @xmath30 $ ] is @xmath31 , and for small @xmath10 it is usually large , unless @xmath32 is sufficiently small .",
    "next suppose that covariates @xmath33 are also observed with @xmath34 .",
    "an estimator in common use that utilizes the covariate information is the _ synthetic _",
    "estimator , @xmath35 where @xmath36 ^ { - 1}\\sum_{i = 1}^{m } \\sum_{j = 1}^{n_{i } } \\mathrm{x}_{ij}y_{ij}$ ] is the ordinary least square ( ols ) estimator . notice that under srswor , @xmath37 is approximately design - unbiased and consistent for the vector @xmath38 of regression coefficients computed from all the population values , irrespective of whether a linear relationship @xmath12 and  @xmath39 exists in the population .",
    "the design - unbiasedness and consistency are with respect to the randomization distribution , letting @xmath1 and @xmath40 increase to infinity in a proper way .",
    "an estimator is approximately design - unbiased if the randomization bias tends to zero as the sample size increases .",
    "the term `` synthetic '' refers to the fact that an ( approximately ) design - unbiased estimator computed from all the areas ( @xmath37 in the present case ) is used for every area separately , assuming that the areas are `` homogeneous '' with respect to the quantity being estimated .",
    "thus , synthetic estimators borrow information from other `` similar areas '' and they are therefore _ indirect _ estimators .",
    "the obvious advantage of the synthetic estimator over the simple sample mean or other direct estimators such as the regression estimator @xmath41 , where @xmath42 is computed only from the data observed for area @xmath5 , is that @xmath43 , and @xmath44 is usually large .",
    "the use of the synthetic estimator is motivated ( `` assisted '' ) by a linear regression model of @xmath12 on @xmath39 in the population with a common vector of coefficients .",
    "however , for @xmath34 , @xmath45 , where @xmath46 is the ols computed from all the population values in area @xmath5 .",
    "thus , if in fact different regression coefficients @xmath46 operate in different areas , the synthetic estimator may have a large bias . when the sample is selected with unequal probabilities , the ols estimator @xmath37 in ( [ 4.2 ] ) is commonly replaced by the probability weighted ( pw ) estimator @xmath47 ^ { - 1}\\sum_{i = 1}^{m } \\sum_{j = 1}^{n_{i } } w_{ij}\\mathrm{x}_{ij}y_{ij},\\ ] ] where @xmath48\\}$ ] are the base sampling weights .    in order to deal with the possible large bias of the synthetic estimator , it is common to estimate the bias and then subtract it from the synthetic estimator . the resulting _ survey regression",
    "_ estimator takes the form @xmath49\\\\[-8pt ] & = & \\hat{\\bar{y}}_{i,\\mathrm{h\\mbox{--}t } } + ( \\bar{x}_{i } - \\hat{\\bar{x}}_{i,\\mathrm{h\\mbox{--}t}})'\\hat{b}_{\\mathrm{pw}},\\nonumber\\end{aligned}\\ ] ] where @xmath50 are the horvitz  thompson ( h  t ) estimators of @xmath51 .",
    "the estimator ( [ 4.3 ] ) is approximately design - unbiased and performs well when the covariates have good predictive power , but the variance is back to order @xmath31 .",
    "the variance is often reduced by multiplying the bias correction @xmath52 by @xmath53 .",
    "a compromise between the possibly large bias of the synthetic estimator and the possibly large variance of the survey regression estimator is achieved by taking a linear combination of the two .",
    "the resulting _ combined _ ( _ composite _ ) estimator is defined as @xmath54 ideally , the coefficient @xmath55 should be chosen to minimize the mean square error ( mse ) of @xmath56 , but assessing sufficiently accurately the bias of the synthetic estimator for a given area is usually impossible .",
    "hence , it is common to let @xmath55 depend on the sample size @xmath10 in the area , such that the larger @xmath10 , the larger is @xmath55 .",
    "see @xcite for review of other combined estimators , and methods of specifying @xmath55 .",
    "a general class of estimators is obtained by calibrating the base sampling weights @xmath57 .",
    "suppose that the population can be partitioned into @xmath58 calibration groups @xmath59 with known totals @xmath60 of the auxiliary variables in the groups , such that each area @xmath61 belongs to one of the groups .",
    "let @xmath62 define the respective partitioning of the sample . in a special case @xmath63 and @xmath64 .",
    "the _ calibrated _ estimator of the mean @xmath24 is computed as @xmath65 the calibration weights @xmath66 are chosen so that they minimize an appropriate distance from the base weights @xmath67 , subject to satisfying the constraints @xmath68 .",
    "for example , when using the distance @xmath69 and @xmath70 , the calibrated weights are @xmath71^ { - 1 } \\mathrm{x}_{ij}\\biggr\\},\\nonumber\\end{aligned}\\ ] ] where @xmath72 is the h ",
    "t estimator of the total @xmath60 . when @xmath73 ( the calibration group is the domain ) , @xmath74 is the familiar",
    "_ generalized regression _ ( greg ) estimator in the domain .",
    "calibration of the sampling weights is in broad use in sample survey practice , not only for sae .",
    "see kott ( @xcite ) for a recent comprehensive review and discussion .",
    "the rationale of the use of calibrated estimators in sae is that if @xmath12 is approximately a linear combination of @xmath39 in @xmath75 , then @xmath76 for domains @xmath77 , and since @xmath78 , @xmath79 is expected to be a good estimator of @xmath24 .",
    "indeed , the advantage of estimator ( [ 4.5 ] ) over ( [ 4.2 ] ) is that it is assisted by a model that only assumes common regression coefficients within the groups @xmath75 , and not for all the domains , as implicitly assumed by estimator ( [ 4.2 ] ) .",
    "estimator ( [ 4.5 ] ) is approximately design - unbiased irrespective of any model , but @xmath80 , which may still be large .",
    "another way of calibrating the weights is by use of _ instrumental variables _ ( estevao and srndal , @xcite , @xcite ) .",
    "denote the vector of instrument values for unit @xmath19 by @xmath81 .",
    "the calibrated weights are defined as @xmath82\\\\[-8pt ]   g'_{c } & = & \\bigl(t_{\\mathrm{x}(c ) } - \\hat{t}_{\\mathrm{x(c),\\mathrm{h\\mbox{--}t}}}\\bigr)'\\biggl[\\sum_{i , j \\in s_{(c ) } } w_{ij}h_{ij}\\mathrm{x}'_{ij}\\biggr]^ { - 1}.\\nonumber\\end{aligned}\\ ] ] note that the instrument values need only beknown for the sampled units in @xmath83 and that@xmath84 , thus satisfying the same constraints as before .",
    "the calibrated estimator of @xmath24 is now @xmath85 .",
    "when @xmath86 .",
    "the use of instruments replaces the search for an appropriate distance function by imposing a structure on the calibration weights , and it allows one , in principle , to find the best instruments in terms of minimizing an approximation to the variance of the calibrated estimator .",
    "however , as noted by estevao and srndal ( @xcite ) , the resulting optimal weights depend on unknown population quantities which , when estimated from the sample , may yield unstable estimators .",
    "see kott ( @xcite ) for further discussion .    the synthetic estimator ( [ 4.2 ] ) , the survey regression estimator ( [ 4.3 ] ) and the various calibrated estimators considered above are all assisted by models that assume a linear relationship between @xmath12 and @xmath39 .",
    "these estimators only require knowledge of the covariates for the sampled units , and the area ( or group ) totals of these covariates .",
    "lehtonen , srndal and veijanen ( @xcite , @xcite ) consider the use of generalized linear models ( glm ) , or even generalized linear mixed models ( glmm ) as the assisting models , which require knowledge of the covariates for every element in the population .",
    "suppose that @xmath87 for some nonlinear function @xmath88 with an unknown vector parameter @xmath89 , where @xmath90 defines the expectation under the model .",
    "a simple important example is where @xmath91 is the logistic function .",
    "estimating @xmath89 by the _ pseudo - likelihood _ ( pl ) approach yields the estimator @xmath92 and predicted values @xmath93 .",
    "the pl approach consists of estimating the likelihood equations that would be obtained in case of a census by the corresponding h ",
    "t estimators ( or weighting each score function by its sampling weight ) , and then solving the resulting estimated equations .",
    "the synthetic and `` generalized greg '' estimators are computed as @xmath94.\\nonumber\\end{aligned}\\ ] ]    a further extension is to include random area effects in the assisting model , assuming @xmath95 , @xmath96 , @xmath97 .",
    "estimation of the fixed parameters @xmath98 , @xmath99 and the random effects @xmath100 is now under the model , ignoring the sampling weights .",
    "the extended synthetic and generalized greg estimators are defined similarly to ( [ 4.8 ] ) , but with @xmath101 replaced by @xmath102 . for sufficiently large sample size @xmath10 ,",
    "the extended generalized greg is approximately design - unbiased for the true area mean , but it is not clear how to estimate the design ( randomization ) variance in this case in a way that accounts for the prediction of the random effects .",
    "@xcite compare the mse of model - based predictors and a greg assisted by a linear mixed model ( lmm ) .",
    "@xcite propose the use of model - dependent estimators that are design - consistent under the randomization distribution as the area sample sizes increase .",
    "the basic idea is to model the direct estimators @xmath103 instead of the individual observations @xmath13 , and then employ the empirical best predictor of the area mean under the model .",
    "the authors consider the general two - level model @xmath104 = \\xi_{i } = \\xi(u_{i},\\hat{\\bar{x}}_{iw};\\psi)$],where the @xmath100s are independent random area effects with zero mean and variance @xmath99 , @xmath105 , and @xmath106 is some known function with unknown parameters @xmath89 .",
    "the empirical best predictor is the best predictor under the model ( minimum expected quadratic loss ) , but with the parameters @xmath89 replaced by model consistent estimators ; @xmath107 .",
    "the estimator is shown to be model - consistent under correct model specification and design - consistent for large @xmath10 , even if the model is misspecified , thus robustifying the estimation .",
    "the authors develop estimators of the prediction mean squared error ( pmse ) for bounded sample sizes  @xmath108 , with bias of desired order @xmath109 , where @xmath110 is the number of sampled areas .",
    "the pmse is computed with respect to the model holding for the individual observations and over the randomization distribution .",
    "the use of design consistent estimators in sae is somewhat questionable because of the small sample sizes in some or all of the areas , but it is nonetheless a desirable property .",
    "this is so because it is often the case that in some of the areas the samples are large , and it is essential that an estimator should work well at least in these areas , even if the model fails .",
    "estimators with large randomization bias even for large samples do not appeal to practitioners .",
    "@xcite propose the use of model - based direct estimators ( mbde ) .",
    "the idea is to fit a model for the population values , compute the weights defining the empirical best linear unbiased predictor ( eblup ) of the population total under the model and then use the weights associated with a given area to compute an almost direct estimator .",
    "the model fitted for the population values @xmath111 is the general linear model , @xmath112\\\\[-8pt ] e(\\varepsilon_{u}\\varepsilon ' _ { u } ) & = & \\sigma = \\left [ \\matrix { \\sigma_{ss } & \\sigma_{sr } \\cr \\sigma_{rs } & \\sigma_{rr } } \\right],\\nonumber\\end{aligned}\\ ] ] where @xmath113 signifies the sample of size @xmath40 , and @xmath114 signifies the sample - complement of size @xmath115 . as seen later ,",
    "the models in common use for sae defined by ( [ 5.1 ] ) and ( [ 5.3 ] ) below are special cases of ( [ 4.9 ] ) .",
    "let @xmath116 denote the column vector of sample outcomes . for known @xmath117 ,",
    "the blup of the population total @xmath118 under the model is @xmath119\\hspace*{-20pt}\\\\ & = & \\sum_{k \\in s } w_{k}^{\\mathrm{blup}}y_{k},\\nonumber\\hspace*{-20pt}\\end{aligned}\\ ] ] where @xmath120 is a row vector of ones of length @xmath121 , @xmath122 is the design matrix corresponding to the sampled ( nonsampled ) units and @xmath123 is the generalized least square estimator .",
    "the eblup is @xmath124 , where the eblup weights are the same as in ( [ 4.10 ] ) , but with estimated parameters .",
    "the mbde of the true mean in area @xmath5 is @xmath125 the authors derive estimators for the bias and variance of the mbde and illustrate its robustness to certain model misspecifications .",
    "note , however , that @xmath126 is a ratio estimator and therefore may have a nonnegligible bias in areas @xmath5 with small sample size .",
    "all the estimators considered so far assume a given sampling design with random area sample sizes.when the target areas are known in advance , considerable gains in efficiency can be achieved by modifying the sampling design and in particular , by controlling the sample sizes within these areas . in a recent article , falrosi and righi ( @xcite ) propose a general strategy for multivariate multi - domain estimation that guarantees that the sampling errors of the domain estimators are lower than pre - specified thresholds .",
    "the strategy combines the use of a balanced sampling technique and greg estimation , but extensions to the use of synthetic estimators and model - based estimation are also considered .",
    "a  successful application of this strategy requires good predictions of weighted sums of residuals featuring in the variance expressions , and it may happen that the resulting overall sample size is far too large , but this is a promising approach that should be studied further .",
    "the apparent advantage of design - based methods is that the estimation is less dependent on an assumed model , although models are used ( assisted ) for the construction of the estimators .",
    "the estimators are approximately unbiased and consistent under the randomization distribution for large sample sizes within the areas , which as discussed before is a desirable property that protects against possible model misspecification at least in large areas .    against this advantage",
    "stand many disadvantages .",
    "direct estimators generally have large variance due to small sample sizes .",
    "the survey regression estimator is approximately unbiased but may likewise be too variable .",
    "synthetic estimators have small variance but are generally biased .",
    "composite estimators have smaller bias than synthetic estimators but larger variance , and it is not obvious how to best choose the weights attached to the synthetic estimator and the unbiased estimator .",
    "computation of randomization - based confidence intervals generally requires large sample normality assumptions , but the sample sizes in at least some of the areas may be too small to justify asymptotic normality .",
    "another limitation of design - based inference ( not restricted to sae ) is that it does not lend itself to conditional inference , for example , conditioning on the sampled values of the covariates or the sampled clusters in a two - stage sampling design .",
    "this again inflates the variance of the estimators .",
    "conditional inference is in the heart of classical statistical inference under both the frequentist and the bayesian approaches .",
    "last , but not least , an important limitation of design - based sae is that there is no founded theory for estimation in areas with no samples .",
    "the use of the randomization distribution does not extend to prediction problems , such as the prediction of small area means for areas with no samples .",
    "it is often the case that samples are available for only a minority of the areas , but estimators and mse estimators are required for each of the areas , whether sampled or not .",
    "model - based methods assume a model for the sample data and use the optimal or approximately optimal predictor of the area characteristic of interest under the model .",
    "the mse of the prediction error is likewise defined and estimated with respect to the model .",
    "note that i now use the term `` prediction '' rather than estimation because the target characteristics are generally random under the model .",
    "the use of models overcomes the problems underlying the use of design - based methods , but it is important to emphasize again that even the most elaborated model can not produce sufficiently accurate predictors when the area sample size is too small , and no covariates with good predictive power are available .",
    "the use of models raises the question of the robustness of the inference to possible model misspecification , and sections  [ sec6.3][sec6.6 ] review studies that deal with this problem from different perspectives .",
    "section  [ sec8 ] considers model selection and diagnostic checking .",
    "denote by @xmath22 the target quantity in area @xmath5 ( mean , proportion , @xmath127 ) .",
    "let @xmath128 define the observed responses for area @xmath5 and @xmath129 define the corresponding values of the covariates ( when available ) . as becomes evident below",
    ", @xmath128 is either a scalar , in which case @xmath129 is a vector , or @xmath128 is a vector , in which case @xmath129 is usually a matrix .",
    "a typical small area model consists of two parts : the first part models the distribution ( or just the moments ) of @xmath130 .",
    "the second part models the distribution ( moments ) of @xmath131 , linking the @xmath22s to known covariates and to each other .",
    "this is achieved by including in the model random effects that account for the variability of the @xmath22s not explained by the covariates .",
    "the hyper - parameters @xmath132 are typically unknown and are estimated either under the frequentist approach , or under the bayesian approach by setting appropriate prior distributions . in some applications",
    "the index @xmath5 may define time , in which case the model for @xmath133 is a time series model .      in this section ,",
    "i review briefly three models in common use , as most of the recent developments in sae relate to these models or extensions of them . for more details",
    "see @xcite , jiang and lahiri ( @xcite , @xcite ) , @xcite and the referencestherein .",
    "i assume that the model holding for the sample data is the same as the model holding in the population , so that there is no sample selection bias .",
    "the case of informative selection of the areas to be sampled or informative sampling within the selected areas , whereby the sample selection or response probabilities are related to the response variable even after conditioning on the model covariates is considered in section  [ sec7 ] .",
    "notice that in this case the sample model differs from the population model .",
    "this model is in broad use when the covariate information is only at the area level , so that @xmath129 is a vector of known area characteristics .",
    "the model , studied originally for sae by @xcite is defined as @xmath134 where @xmath135 denotes the direct sample estimator of @xmath22 ( e.g. , the sample mean @xmath136 when the sample is selected by srs ) , and @xmath137 represents the sampling error , assumed to have zero mean and known design ( randomization ) variance , @xmath138 .",
    "the random effects @xmath100 are assumed to be independent with zero mean and variance @xmath99 . for known @xmath99 ,",
    "the best linear unbiased predictor ( blup ) of @xmath22 under this model is @xmath139 the blup @xmath140 is in the form of a composite estimate [ equation ( [ 4.4 ] ) ] , but with a tuning ( shrinkage ) coefficient @xmath141 , which is a function of the ratio @xmath142 of the variances of the prediction errors of @xmath143 and @xmath135 , respectively .",
    "the coefficient @xmath144 defines optimally the weights assigned to the synthetic estimator @xmath145 and @xmath135 , unlike the case of design - based estimators where the weight is assigned in a more ad hoc manner .",
    "see the discussion below ( [ 4.4 ] ) .",
    "note that the blup property does not require specifying the distribution of the error terms beyond the first two moments , and @xmath140 is also the linear bayes predictor in this case .",
    "under normality of the error terms and a diffuse uniform prior for @xmath146 is the bayesian predictor ( posterior mean ) of @xmath22 . for a nonsampled area @xmath121 , the blup",
    "is now obtained optimally as @xmath147 .    in practice , the variance @xmath99 is seldom known and is replaced in @xmath144 and @xmath123 by a sample estimate , yielding what is known as the empirical blup ( eblup ) under the frequentist approach , or the empiricalbayes ( eb ) predictor when assuming normality .",
    "the latter predictor is the posterior mean of @xmath22 , but with @xmath99 replaced by a sample estimate obtained from the marginal distribution of the direct estimators given the variance .",
    "alternatively , one may compute the hierarchical bayes ( hb ) predictor by assuming prior distributions for @xmath148 and @xmath99 and computing the posterior distribution of @xmath22 given the available data .",
    "the posterior distribution can be used for computation of the point predictor and a credibility ( confidence ) interval .",
    "[ rem1 ] the synthetic estimator @xmath145 , and hence the blup @xmath149 are unbiased predictors under the joint distribution of @xmath128 and @xmath22 in the sense that @xmath150 , but are biased when conditioning on @xmath100 .",
    "the predictor @xmath140 is biased also under the randomization distribution .",
    "conditioning on @xmath100 amounts to assuming different fixed intercepts in different areas and the unbiasedness of @xmath140 under the model is achieved by viewing the intercepts as random .",
    "[ rem2 ] it is often the case that the _ linking model _ is defined for a transformation of @xmath22 . for example , @xcite actually assume @xmath151 in ( [ 5.1 ] ) and use the direct estimator @xmath152 , and then predict @xmath22 as @xmath153 , where @xmath154 is the blup ( eblup ) of @xmath155 under the model .",
    "however , @xmath153 is not the blup of @xmath156 $ ] .",
    "on the other hand , the eb and hb approaches produce optimal predictors of @xmath22 , even if the linking model uses a transformation of @xmath22 , with or without the use of a similar transformation for the direct estimator . in this respect ,",
    "the latter two approaches are more flexible and with wider applicability , but at the expense of requiring further parametric assumptions .",
    "this model uses individual observations @xmath13 such that @xmath128 is now a vector , and @xmath129 is generally a matrix .",
    "the use of this model for sae requires that the area means @xmath157 are known .",
    "the model , first proposed for sae by battese , harter and fuller ( @xcite ) has the form @xmath158 where the @xmath100s ( random effects ) and the @xmath159s ( residual terms ) are mutually independent with zero means and variances @xmath99 and @xmath160 , respectively . under the model ,",
    "the true small area means are @xmath161 , but since @xmath162 for large @xmath4 , the target means are often defined as @xmath163 . for known variances @xmath164 ,",
    "the blup of @xmath22 is @xmath165 \\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } + ( 1 - \\gamma_{i})\\bar{x}'_{i}\\hat{\\beta } _ { \\mathrm{gls}},\\nonumber\\end{aligned}\\ ] ] where @xmath123 is the gls of @xmath148 computed from all the observations , @xmath166 and @xmath167 . for area",
    "@xmath121 with no sample ( but known @xmath168 , the blup is @xmath169 .",
    "see @xcite for the blup of the means @xmath24 in sampled areas .",
    "the blup ( [ 5.4 ] ) is also the bayesian predictor ( posterior mean ) under normality of the error terms and a diffuse uniform prior for @xmath148 . replacing the variances @xmath99 and @xmath160 in @xmath144 and @xmath123 by sample estimates yields the corresponding eblup or eb predictors .",
    "hierarchical bayes ( hb ) predictors are obtained by specifying prior distributions for @xmath148 and the two variances and computing the posterior distribution of @xmath22 ( or @xmath170 given all the sample observations in all the areas .",
    "remark  [ rem1 ] applies to the blup ( eblup ) under this model as well .",
    "the previous two models assume continuous responses .",
    "suppose now that @xmath13 is binary , taking the values 1 or 0 , in which case the small area quantities of interest are usually proportions or counts ( say , the proportion or total of unemployed persons in the area ) .",
    "the following generalized linear mixed model ( glmm ) considered originally by macgibbon and tomberlin ( @xcite ) for sae is in broad use for this kind of problems : @xmath171\\\\[-8pt ]   \\operatorname{logit}(p_{ij } ) & = & \\mathrm{x}'_{ij}\\beta + u_{i } ; \\quad u_{i}\\sim n(0,\\sigma_{u}^{2}).\\nonumber\\end{aligned}\\ ] ] the responses @xmath13 are assumed to be conditionally independent , given the random effects @xmath100 , and likewise for the random effects .",
    "the purpose is to predict the true area proportions @xmath172 .",
    "let @xmath173 denote the model parameters . for this model",
    ", there is no explicit expression for the best predictor ( bp ) under a quadratic loss function , that is , for @xmath174 , but as shown in @xcite , the bp can be computed ( approximated ) numerically as the ratio of two one - dimensional integrals .",
    "jiang and lahiri review methods of estimating @xmath89 , yielding the empirical bp ( ebp ) @xmath175 , which is also the eb predictor under the same assumptions .",
    "application of the full hb approach under this model consists of the following basic steps :    specify prior distributions for @xmath99 and @xmath176 ;    generate observations from the posterior distributions of @xmath148 , @xmath99 and @xmath177 by say , mcmc simulations , and draw a large number of realizations @xmath178 , @xmath179 , @xmath180 , and hence realizations @xmath181 for @xmath182 ;    predict : @xmath183 ; @xmath184 .",
    "writing @xmath185 , the posterior variance is approximated as @xmath186 .",
    "ghosh et al .",
    "( @xcite ) discuss the use of hb sae for glmm , covering binary , count , multi - category and spatial data .",
    "in particular , sufficient conditions are developed for the joint posterior distribution of the parameters of interest to be proper .",
    "as stated in the introduction , an important aspect of sae is the assessment of the accuracy of the predictors .",
    "this problem is solved `` automatically '' under the bayesian paradigm , which produces realizations of the posterior distribution of the target quantities .",
    "however , estimation of the prediction mse ( pmse ) and the computation of confidence intervals ( c.i . ) under the frequentist approach is complicated because of the added variability induced by the estimation of the model hyper - parameters .",
    "@xcite developed pmse estimators with bias of order @xmath109 , ( @xmath110  is the number of sampled areas ) , under the linear mixed models ( [ 5.1 ] ) and ( [ 5.2 ] ) for the case where the random errors have a normal distribution , and the model variances are estimated by the anova method of moments .",
    "@xcite extended the estimation of prasad and rao to the more general mixed linear model , @xmath187 where @xmath188 and @xmath189 are fixed matrices of order @xmath190 and @xmath191 , respectively , and @xmath100 and @xmath137 are independent normally distributed random effects and residual terms of orders @xmath192 and @xmath193 , respectively , @xmath194 , @xmath195 .",
    "the variance matrices are known functions of variance components @xmath196 .",
    "the authors develop pmse estimators with bias of order @xmath109 for the eblup obtained when estimating @xmath148 and @xmath197 by mle or reml .",
    "das , jiang and rao ( @xcite ) extend the model of @xcite by relaxing the assumption of independence of the error terms between the areas and likewise develop an estimator for the pmse of the eblup when estimating the unknown model parameters by mle or reml , with bias of order @xmath109 .",
    "datta , rao and smith ( @xcite ) show that for the area level model ( [ 5.1 ] ) , if @xmath99 is estimated by the method proposed by @xcite , it is required to add an extra term to the pmse estimator to achieve the desired order of bias of @xmath109 .",
    "see @xcite for an extensive review of methods of estimating the pmse of the eblup and eb under linear mixed models ( lmm ) .",
    "estimation of the pmse under the glmm is more involved , and in what follows , i review resampling procedures that can be used in such cases . for convenience ,",
    "i consider the mixed logistic model ( [ 5.5 ] ) , but the procedures are applicable to other models belonging to this class .",
    "the first procedure , proposed by jiang , lahiri and wan ( @xcite ) uses the jackknife method .",
    "let @xmath198 denote the pmse , where @xmath199 is the true proportion and @xmath200 is the ebp .",
    "the following decomposition holds : @xmath201\\\\[-8pt ] & = & m_{1i } + m_{2i},\\nonumber\\end{aligned}\\ ] ] where @xmath202 is the pmse of the bp ( assumes known parameter values ) and @xmath203 is the contribution to the pmse from estimating the model parameters , @xmath89 .",
    "denote by @xmath204 the `` _ _ naive _ _ '' estimator of @xmath202 , obtained by setting @xmath205 .",
    "let @xmath206 denote the naive estimator when estimating @xmath89 from all the areas except for area @xmath207 , and @xmath208 denote the corresponding ebp .",
    "the jackknife estimator of pmse is @xmath209\\\\[-8pt ] & & { } - \\frac{m - 1}{m}\\sum_{l = 1}^{m } [ \\hat{\\lambda } _",
    "{ i}^{\\mathrm{bp}}(\\hat{\\psi } _ { - l } ) - \\hat{\\lambda } _ { i}^{\\mathrm{bp}}(\\hat{\\psi } ) ] , \\nonumber\\\\ \\hat{m}_{2i } & = & \\frac{m - 1}{m}\\sum_{l = 1}^{m } [ \\hat{p}_{i}^{\\mathrm{ebp}}(\\hat{\\psi } _ { - l } ) - \\hat{p}_{i}^{\\mathrm{ebp}}(\\hat{\\psi } ) ] ^{2}.\\nonumber\\end{aligned}\\ ] ] under some regularity conditions , @xmath210 , as desired .",
    "the jackknife estimator estimates the unconditional pmse over the joint distribution of the random effects and the responses .",
    "@xcite proposed a modification of the jackknife , which is simpler and estimates the conditional pmse,@xmath211 $ ] . denoting @xmath212",
    ", the modification consists of replacing @xmath213 in ( [ 6.3 ] ) by @xmath214 $ ] .",
    "the modified estimator @xmath215 has bias of order @xmath216 in estimating the conditional pmse and bias of order @xmath109 in estimating the unconditional pmse .",
    "@xcite propose estimating thepmse by use of double - bootstrap . for model ( [ 5.5 ] )",
    ", the procedure consists of the following steps :    \\(1 ) generate a new population from the model ( [ 5.5 ] ) with parameters @xmath217 and compute the `` true '' area proportions for this population . compute the ebps based on new sample data and newly estimated parameters .",
    "the new population and sample use the same covariates as the original population and sample . repeat the process independently @xmath218 times , with @xmath218 sufficiently large . denote by @xmath219 and @xmath220 the `` true '' proportions and corresponding ebps for population and sample @xmath221 , @xmath222 . compute the first - step bootstrap pmse estimator , @xmath223^{2}.\\ ] ]    \\(2 ) for each sample drawn in step ( 1 ) , repeat the computations of step ( 1 ) @xmath224 times with @xmath224 sufficiently large , yielding new `` true '' proportions@xmath225 and ebps @xmath226 , @xmath227 . compute the second - step bootstrap pmse estimator , @xmath228\\\\[-8pt ] & & \\hspace*{31pt}{}\\cdot\\sum_{b_{2 } = 1}^{b_{2 } } \\bigl[\\hat{p}_{i , b_{2}}^{(\\mathrm{ebp})}(\\hat{\\psi } _ { b_{2 } } ) - p_{i , b_{2}}(\\hat{\\psi } _",
    "{ b_{1}})\\bigr]^{2}.\\nonumber\\end{aligned}\\ ] ] the double - bootstrap pmse estimator is obtained by computing one of the classical bias corrected estimators .",
    "for example , @xmath229,\\vspace*{2pt}\\cr   \\quad\\mbox{if } \\hat{\\lambda } _ { i,1}^{\\mathrm{bs } } < \\hat{\\lambda } _ { i,2}^{\\mathrm{bs}}. } \\end{aligned}\\ ] ] notice that whereas the first - step bootstrap estimator ( [ 6.4 ] ) has bias of order @xmath230 , the double - bootstrap estimator has bias of order @xmath109 under some regularity conditions .",
    "@xcite develop a general method of bias correction , which models the error of a target estimator as a function of the corresponding bootstrap estimator , and the original estimators and bootstrap estimators of the parameters governing the model fitted to the sample data .",
    "this is achieved by drawing at random a large number of plausible parameters governing the model , generating a pseudo original sample for each parameter and bootstrap samples for each pseudo sample , and then searching by a cross validation procedure the best functional relationship among a set of eligible bias correction functions that includes the classical bootstrap bias corrections .",
    "the use of this method produces estimators with bias of correct order and under certain conditions it also permits estimating the mse of the bias corrected estimator .",
    "application of the method for estimating the pmse under the model ( [ 5.5 ] ) in an extensive simulation study outperforms the double - bootstrap and jackknife procedures , with good performance in estimating the mse of the pmse estimators .",
    "[ rem3 ] all the resampling methods considered above are in fact model dependent since they require computing repeatedly the empirical best predictors under the model .",
    "chambers , chandra and tzavidis ( @xcite ) develop conditional bias - robust pmse estimators for the case where the small area estimators can be expressed as weighted sums of sample values .",
    "the authors assume that for unit @xmath231 , @xmath232 ; @xmath233 , @xmath234 , @xmath235 , with @xmath236 taken as a fixed vector of coefficients , and consider linear estimators of the form @xmath237 with fixed weights @xmath238 .",
    "thus , if @xmath22 defines the true area mean , @xmath239 where @xmath240 and @xmath241 , with @xmath242 defining the indicator function .",
    "assuming that for @xmath243 , @xmath244 is estimated as @xmath245 and @xmath246 , the bias and variance in ( [ 6.7 ] ) are estimated as @xmath247\\\\ & & \\hspace*{35pt}{}\\cdot\\lambda_{j}^ { - 1 } ( y_{j } - \\hat{\\mu } _ { j})^{2},\\nonumber\\end{aligned}\\ ] ]",
    "where @xmath248 , and @xmath249 defines the sample without unit @xmath14 .",
    "the authors apply the procedure for estimating the pmse of the eblup and the mbde estimator ( [ 4.11 ] ) under model ( [ 5.3 ] ) , and for estimating the pmse of the m - quantile estimator defined in section  [ sec6.6 ] . for the first two applications the authors condition on the model variance estimators so that the pmse estimators do not have bias of desired order even under correct model specification . on the other hand ,",
    "the estimators are shown empirically to have smaller bias than the traditional pmse estimators in the presence of outlying observations , although with larger mses than the traditional estimators in the case of small area sample sizes .",
    "as in other statistical applications , very often analysts are interested in prediction intervals for the unknown area characteristics .",
    "construction of prediction intervals under the bayesian approach , known as _ credibility intervals _ , is straightforward via the posterior distribution of the predictor .",
    "a `` natural '' prediction interval under the frequentist approach with desired coverage rate @xmath250 is @xmath251^{1/2}$ ] , where @xmath252 is the eb , ebp or eblup predictor , and @xmath253 is an appropriate estimate of the prediction error variance .",
    "however , even under asymptotic normality of the prediction error , the use of this prediction interval has coverage error of order @xmath230 , which is not sufficiently accurate .",
    "recent work in sae focuses therefore on reducing the coverage error via parametric bootstrap .",
    "@xcite consider the following general model : for a suitable smooth function @xmath254 of the covariates @xmath255 in area @xmath5 and a vector parameter @xmath148 , random variables @xmath256 ; @xmath257 are drawn from a distribution @xmath258 .",
    "the outcome observations @xmath13 are drawn independently from a distribution @xmath259 , where @xmath260 is a known link function , and @xmath261 is either known or is the same for every area @xmath5 .",
    "for given covariates @xmath262 , sample size @xmath263 and known parameters , an @xmath264-level prediction interval for the corresponding realization @xmath265 is @xmath266,\\ ] ] where @xmath267 defines the @xmath268-level quantile of the distribution @xmath258 .",
    "a naive prediction interval with estimated parameters is @xmath269 , but this interval has coverage error of order @xmath230 , and it does not use the area - specific outcome values . to reduce the error ,",
    "@xmath270 is calibrated on @xmath264 .",
    "this is implemented by generating parametric bootstrap samples and re - estimating @xmath148 and @xmath271 similarly to the first step of the double - bootstrap procedure for pmse estimation described in section  [ sec6.1 ] .",
    "denote by @xmath272 the bootstrap interval , and let @xmath273 denote the solution of the equation @xmath274 , where @xmath275 . the bootstrap - calibrated prediction interval with coverage error of order @xmath276 is @xmath277 .",
    "chatterjee , lahiri and li ( @xcite ) consider the general linear mixed model of das , jiang and rao ( @xcite ) , mentioned in section  [ sec6.1 ] : @xmath278 , where @xmath279 ( of dimension @xmath40 ) signifies all the observations in all the areas , @xmath280 and @xmath281 are known matrices and @xmath282 and @xmath283 are independent vector normal errors of random effects and residual terms with variance matrices @xmath284 and @xmath285 , which are functions of a @xmath121-vector parameter @xmath89 .",
    "note that this model and the model of @xcite include as special cases the mixed linear models defined by ( [ 5.1 ] ) and ( [ 5.3 ] ) .",
    "the present model can not handle nonlinear mixed models [ e.g. , the glmm ( [ 5.5 ] ) ] , which the hall and maiti model can , but it does not require conditional independence of the observations given the random effects , as under the hall and maiti model .",
    "the ( parametric bootstrap ) prediction interval of chatterjee , lahiri and li ( @xcite ) for a univariate linear combination @xmath286 is obtained by the following steps .",
    "first compute the conditional mean , @xmath287 and variance @xmath288 of @xmath289 .",
    "next generate new observations @xmath290 , where @xmath291 , @xmath292 . from @xmath293 ,",
    "estimate @xmath294 and @xmath295 using the same method as for @xmath296 and @xmath217 , and compute @xmath297 and @xmath298 ( same as @xmath287 and @xmath299 , but with estimated parameters ) .",
    "denote by @xmath300 the bootstrap distribution of @xmath301 , where @xmath302 , and let @xmath303 be the total number of unknown parameters .",
    "then as @xmath304 and under some regularity conditions , if @xmath305 , @xmath306 satisfy @xmath307 , @xmath308\\\\[-8pt ] & & \\quad = 1 - \\alpha + o(d^{3}n^ { - 3/2}).\\nonumber\\end{aligned}\\ ] ] note that this theory allows @xmath309 to grow with @xmath40 and that the coverage error is defined in terms of @xmath40 rather than  @xmath110 , the number of sampled areas , as under the @xcite approach .",
    "the total sample size increases also as the sample sizes within the areas increase , and not just by increasing @xmath110 . by appropriate choice of @xmath310 , the interval ( [ 6.10 ] ) is area specific .",
    "[ rem4 ] the article by chatterjee , lahiri and li ( @xcite ) contains a thorough review of many other prediction intervals proposed in the literature .",
    "model - based sae depends on models that can be hard to validate and if the model is misspecified , the resulting predictors may perform poorly . benchmarking robustifies the inference by forcing the model - based predictors to agree with a design - based estimator for an aggregate of the areas for which the design - based estimator is reliable . assuming that the aggregation contains all the areas",
    ", the benchmarking equation takes the general form , @xmath311 the coefficients @xmath312 are fixed weights , assumed without loss of generality to sum to 1 ( e.g. , relative area sizes ) . constraint ( [ 6.9 ] ) has the further advantage of guaranteeing consistency of publication between the model - based small area predictors and the design - based estimator for the aggregated area , which is often required by statistical bureaus .",
    "for example , the model - based predictors of total unemployment in counties should add up to the design - based estimate of total unemployment in the country , which is deemed accurate .    a benchmarking method in common use ,",
    "often referred to as ratio or pro - rata adjustment , is @xmath313\\\\[-8pt ] & & { } \\cdot\\hat{\\theta } _ { i,\\mathrm{model}}.\\nonumber\\end{aligned}\\ ] ] the use of this procedure , however , applies the same ratio correction for all the areas , irrespective of the precision of the model - based predictors before benchmarking . as a result ,",
    "the prorated predictor in a given area is not consistent as the sample size in that area increases .",
    "additionally , estimation of the pmse of the prorated predictors is not straightforward .",
    "consequently , other procedures have been proposed in the literature .",
    "wang , fuller and qu ( @xcite ) derive benchmarked blup ( bblup ) under the area level model ( [ 5.1 ] ) as the predictors minimizing @xmath314 subject to ( [ 6.11 ] ) , where the @xmath315s are chosen positive weights .",
    "the bblup is @xmath316 when the variance @xmath99 is unknown , it is replaced by its estimator everywhere in ( [ 6.13 ] ) , yielding the empirical bblup .",
    "you and rao ( @xcite ) achieve `` automatic benchmarking '' for the unit level model ( [ 5.3 ] ) by changing the estimator of @xmath148 .",
    "wang , fuller and qu ( @xcite ) consider a similar procedure for the area level model . alternatively",
    ", the authors propose to augment the covariates @xmath317 to @xmath318 .",
    "( the variances @xmath319 are considered known under the area level model . )",
    "the use of the augmented model yields a blup that likewise satisfies the benchmark constraint ( [ 6.11 ] ) and is more robust to omission of an important covariate from @xmath129 , provided that the missing covariate is sufficiently correlated with the added covariate in @xmath320 .",
    "@xcite add monthly benchmark constraints of the form ( [ 6.11 ] ) to the measurement ( observation ) equation of a time series state - space model fitted jointly to the direct estimates in several areas .",
    "adding benchmark constraints to time series models is particularly important since time series models are slow to adapt to abrupt changes . the benchmarked predictor obtained under the augmented time series model belongs to the family of predictors ( [ 6.13 ] ) proposed by wang , fuller and qu ( @xcite ) . by adding the constraints to the model equations",
    ", the use of this approach permits estimating the variance of the benchmarked estimators as part of the model fitting .",
    "the variance accounts for the variances of the model error terms , the variances and autocovariances of the sampling errors of the direct estimators and of the benchmarks @xmath321 , @xmath322 and the cross - covariances and autocovariances between the sampling errors of the direct estimators and the benchmarks .",
    "datta et al .",
    "( @xcite ) develop bayesian benchmarking by minimizing @xmath323\\quad \\mbox{s.t.}\\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\quad\\sum_{i = 1}^{m } b_{i } \\hat{\\theta } _ { i}^{\\mathrm{bench } } = \\sum_{i = 1}^{m } b_{i } \\hat{\\theta } _ { i,\\mathrm{design}},\\nonumber\\end{aligned}\\ ] ] where @xmath324 .",
    "the solution of this minimization problem is the same as ( [ 6.13 ] ) , but with @xmath325 replaced everywhere by the posterior mean @xmath326 .",
    "denote the resulting predictors by @xmath327 .",
    "the use of these predictors has thedrawback of `` over shrinkage '' in the sense that@xmath328 $ ] , where @xmath329 and @xmath330 . to deal with this problem , datta et al .",
    "( @xcite ) propose to consider instead the predictors @xmath331 , satisfying the constraints @xmath332\\\\[-8pt ] \\quad&\\displaystyle \\sum_{i = 1}^{m } b_{i } \\biggl(\\hat{\\theta } _ { i,\\mathrm{bayes}}^{\\mathrm{bench},2 } - \\sum_{i = 1}^{m } b_{i } \\hat{\\theta } _ { i,\\mathrm{design}}\\biggr)^{2 } = h,&\\nonumber\\end{aligned}\\ ] ] where @xmath333 $ ] .",
    "the benchmarked predictors have now the form @xmath334 notice that the development of the bayesian benchmarked predictors is general and not restricted to any particular model .",
    "the pmse of the benchmarked predictor can be estimated as @xmath335 = \\operatorname{var}(\\hat{\\theta } _ { i,\\mathrm{bayes}}|\\hat{\\theta } _ { \\mathrm{design } } ) + ( \\hat{\\theta } _",
    "{ i,\\mathrm{bayes}}^{\\mathrm{bench},2 } - \\hat{\\theta } _ { i,\\mathrm{bayes}})^{2}$ ] , noting that the cross - product @xmath336 = 0 $ ] .",
    "@xcite likewise consider bayesian benchmarking , focusing on estimation of area proportions . denoting by @xmath337 the number of sample units in area @xmath5 having characteristic @xmath58 , and by @xmath338 the probability to have this characteristic ,",
    "the authors assume the beta - binomial hierarchical bayesian model , @xmath339,\\quad i = 1,\\ldots , m,\\hspace*{-18pt } \\\\",
    "p(\\mu,\\tau ) & = & ( 1 + \\tau^{2})^ { - 1},\\quad 0",
    "1 , \\tau\\ge 0.\\nonumber\\end{aligned}\\ ] ] let @xmath340 .",
    "the benchmark constraint is defined as , @xmath341.\\hspace*{-15pt}\\ ] ] the authors derive the joint posterior distribution of the true probabilities @xmath342 under the unrestricted model ( [ 6.17 ] ) , and the restricted model with ( [ 6.18 ] ) , and prove that it is proper .",
    "computational details are given .",
    "different scenarios are considered regarding the prior distribution of @xmath343 . under the first scenario @xmath344 , implying that @xmath343 is a point mass at @xmath345 , assumed to be known . under a second scenario @xmath345 and @xmath346",
    "are specified by the analyst . in a third scenario @xmath347 , @xmath348 , implying @xmath349 ( noninformative prior ) .",
    "theoretical arguments and empirical results show that the largest gain from using the restricted model is under the first scenario where @xmath343 is completely specified , followed by the second scenario with @xmath350 .",
    "no gain in precision occurs under the third scenario with a noninformative prior .    to complete this section ,",
    "i mention a different frequentist benchmarking procedure applied by ugarte , militino and goicoa ( @xcite ) . by this procedure , the small area predictors in sampled and nonsampled areas under the unit level model ( [ 5.3 ] )",
    "are benchmarked to a synthetic estimator for a region composed of the areas as obtained under a linear regression model with heterogeneous variances ( but no random effects ) .",
    "the benchmarked predictors minimize a weighted residual sum of squares ( wrss ) under model ( [ 5.3 ] ) among all the predictors satisfying the benchmark constraint .",
    "notice that the predictors minimizing the wrss without the constraint are the optimal predictors ( [ 5.4 ] ) . for known variances",
    "the benchmarked predictors are linear , but in practice the variances are replaced by sample estimates .",
    "the authors estimate the pmse of the resulting empirical benchmarked predictors by a single - step parametric bootstrap procedure .",
    "@xcite consider the case where some or all the covariates @xmath129 in the area level model ( [ 5.1 ] ) are unknown , and one uses an estimator @xmath351 obtained from another independent survey , with@xmath352 under the sampling design .",
    "( forknown covariates @xmath353 , @xmath354 . ) denoting the resulting predictor by @xmath355 , it follows that for known @xmath356 , @xmath357 where @xmath358 is the pmse if one knew @xmath129 .",
    "thus , reporting @xmath358 in this case results in under - reporting the true pmse .",
    "moreover , if @xmath359 , @xmath360 .",
    "the authors propose therefore to use instead the predictor @xmath361\\\\[-8pt ]   \\tilde{\\gamma } _ { i } & = & ( \\sigma_{u}^{2 } + \\beta ' c_{i}\\beta)/(\\sigma_{di}^{2 } + \\sigma_{u}^{2 } + \\beta ' c_{i}\\beta).\\nonumber\\end{aligned}\\ ] ] the predictor @xmath362 minimizes the mse of linear combinations of @xmath135 and @xmath363 .",
    "additionally , @xmath364'\\beta$ ] , implying that the bias vanishes if @xmath351 is unbiased for @xmath129 , and @xmath365 .",
    "the authors develop estimators for @xmath99 and @xmath148 , which are then substituted in ( [ 6.20 ] ) to obtain the corresponding empirical predictor .",
    "the pmse of the empirical predictor is estimated using the jackknife procedure of jiang , lahiri and wan ( @xcite ) , described in section  [ sec6.1 ] .",
    "ghosh , sinha and kim ( @xcite ) and torabi , datta and rao ( @xcite ) study a different situation of measurement errors .",
    "the authors assume that the true model is the unit level model ( [ 5.3 ] ) with a single covariate @xmath366 for all the units in the same area , but @xmath366 is not observed , and instead , different measurements @xmath367 are obtained for different sampled units @xmath368 .",
    "the sample consists therefore of the observations @xmath369 .",
    "an example giving rise to such a scenario is where @xmath366 defines the true level of air pollution in the area and the @xmath367 s represent pollution measures at different sites in the area .",
    "it is assumed that @xmath370 ; @xmath371 , and @xmath372 are independent normally distributed random errors with zero means and variances @xmath99 , @xmath160 and @xmath373 , respectively . since @xmath366 is random , this kind of measurement error",
    "is called _ structural measurement error_. the difference between the two articles is that ghosh , sinha and kim ( @xcite ) only use the observations @xmath374 for predicting the true area means @xmath24 , whereas torabi , datta and rao ( @xcite ) also use the sample observations @xmath375 .    assuming that all the model parameters are known , the posterior distribution of the unobserved @xmath12-values in area @xmath5 is multivariate normal , which under the approach of torabi , datta and rao ( @xcite ) yields the following bayes predictor ( also blup ) for @xmath24 : @xmath376 where @xmath377 , @xmath378 and @xmath379^ { - 1}\\sigma_{\\varepsilon } ^{2}v_{i}$ ] , with @xmath380 . for large @xmath4 and small @xmath381 ,",
    "the pmse of @xmath382 is @xmath383 = a_{i}[\\beta_{1}^{2}\\sigma_{x}^{2 } + \\sigma_{u}^{2 } - n_{i}\\beta_{1}^{2}\\sigma_{x}^{4}v_{i}^ { - 1}]$ ] . estimating the model parameters @xmath384 by a method of moments ( mom ) proposed by ghosh , sinha and kim ( @xcite ) and replacing them by their estimates yields the eb estimator , which is shown to be asymptotically optimal in the sense that @xmath385 as @xmath386 .",
    "the pmse of the eb predictor is estimated by a weighted jackknife procedure of @xcite .",
    "the bayes predictor of ghosh , sinha and kim ( @xcite ) has a similar structure to ( [ 6.21 ] ) , but without the correction term @xmath387 , and with the shrinkage coefficient @xmath388 replaced by @xmath389^ { - 1}\\sigma_{\\varepsilon } ^{2}$ ] in the other two terms . as noted above",
    ", the authors develop a mom for estimating the unknown model parameters to obtain the eb predictor and prove its asymptotic optimality .",
    "they also develop an hb predictor with appropriate priors for all the parameters .",
    "the hb predictor and its pmse are obtained by mcmc simulations .",
    "@xcite consider the same unit level model as above with sample observations @xmath390 , but assume that the true covariate @xmath366 is a fixed unknown parameter , which is known as _ functional measurement error_. the work by @xcite reviewed before also assumes a functional measurement error , but considers the area level model . for known parameters and @xmath366",
    ", the bayes predictor takes now the simple form @xmath391 a pseudo - bayes predictor ( pb ) is obtained by substituting the sample mean @xmath392 for @xmath366 in ( [ 6.22 ] ) .",
    "a  pseudo - empirical bayes predictor ( peb ) is obtained by estimating all the other unknown model parameters by the mom developed in ghosh , sinha and kim ( @xcite ) .",
    "the authors show the asymptotic optimality of the peb , @xmath393 as @xmath386 .",
    "datta , rao and torabi ( @xcite ) propose to replace the estimator @xmath392 of @xmath366 by its maximum likelihood estimator ( mle ) under the model .",
    "the corresponding pb of @xmath24 ( assuming that the other model parameters are known ) is the same as the pb of @xcite , but with @xmath46 replaced by @xmath394 .",
    "a  peb predictor is obtained by replacing the model parameters by the mom estimators developed in ghosh , sinha and kim ( @xcite ) , and it is shown to be asymptotically optimal under the same optimality criterion as before .",
    "the pmse of the peb is estimated by the jackknife procedures of jiang , lahiri and wan ( @xcite ) described in section  [ sec6.1 ] and the weighted jackknife procedure of @xcite .",
    "the authors report the results of a simulation study showing that their peb predictor outperforms the peb of @xcite in terms of pmse . a modification to the predictor of @xcite is also proposed .",
    "@xcite consider the area level model  ( [ 5.1 ] ) from a bayesian perspective , but assume that the random effect or the sampling error ( but not both ) have a nonstandardized student s @xmath395 distribution .",
    "the @xmath310 distribution is often used in statistical modeling to account for possible outliers because of its long tails .",
    "one of the models considered by the authors is @xmath396,\\\\   e_{i}&\\sim & n(0,\\sigma_{di}^{2}),\\nonumber\\end{aligned}\\ ] ] which implies @xmath397 and @xmath398 .",
    "the coefficient @xmath55 is distributed around 1 , inflating or deflating the variance of @xmath399 .",
    "a  large value @xmath55 signals the existence of an outlying area mean @xmath22 .",
    "the degrees of freedom parameter , @xmath121 , is taken as known .",
    "setting @xmath400 is equivalent to assuming the model ( [ 5.1 ] ) .",
    "the authors consider several possible ( small ) values for @xmath121 in their application , but the choice of an appropriate value depends on data exploration . alternatively , the authors assume model ( [ 6.23 ] ) for the sampling error @xmath137 ( with @xmath319 instead of @xmath99 ) , in which case it is assumed that @xmath401 .",
    "the effect of assuming the model for the random effects is to push the small area predictor ( the posterior mean ) toward the direct estimator , whereas the effect of assuming the model for the sampling errors is to push the predictor toward the synthetic part .",
    "the use of either model is shown empirically to perform well in identifying outlying areas , but at present it is not clear how to choose between the two models .",
    "@xcite extend the approach to a bivariate area level model where two direct estimates are available for every area , with uncorrelated sampling errors but correlated random effects .",
    "this model handles a situation where estimates are obtained from two different surveys .",
    "ghosh , maiti and roy ( @xcite ) likewise consider model ( [ 5.1 ] ) and follow the eb approach .",
    "the starting point in this study is that an outlying direct estimate may arise either from a large sampling error or from an outlying random effect .",
    "the authors propose therefore to replace the eb predictor obtained from ( [ 5.2 ] ) by the robust eb predictor , @xmath402 ; \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber   \\hat{v}_{i}^{2 } & = & \\hat{\\operatorname{var}}(\\tilde{y}_{i } - \\mathrm{x}'_{i}\\hat{\\beta } _ { \\mathrm{gls}}),\\end{aligned}\\ ] ] where @xmath403 is the empirical gls under the model with estimated variance @xmath404 , and @xmath405 is the huber influence function @xmath406 for some value @xmath407 .",
    "thus , for large positive standardized residuals @xmath408 , the eb @xmath409 under the model is replaced by @xmath410 , and similarly for large negative standardized residuals , whereas in other cases the ordinary  eb , @xmath411 , is unchanged .",
    "the value @xmath412 may change from one area to the other , and it is chosen adaptively in such a way that the excess bayes risk under model ( [ 5.1 ] ) from using the predictor ( [ 6.24 ] ) is bounded by some percentage point .",
    "alternatively , @xmath412 may be set to some constant @xmath413 , as is often found in the robustness literature .",
    "the authors derive the pmse of @xmath414 under the model ( [ 5.1 ] ) for the case where @xmath99 is estimated by mle with bias of order @xmath109 , and develop an estimator for the pmse that is correct up to the order @xmath415 .    under the approach of ghosh , maiti and roy(@xcite ) , the eb predictor is replaced by the robust predictor ( [ 6.24 ] ) , but the estimation of the unknown model parameters and the development of the pmse and its estimator are under the original model ( [ 5.1 ] ) , without accounting for possible outliers .",
    "sinha and rao ( @xcite ) propose to robustify also the estimation of the model parameters .",
    "the authors consider the mixed linear model ( [ 6.1 ] ) , which when written compactly for all the observations @xmath416 , has the form @xmath417 where @xmath282 is the vector of random effects , and @xmath283 is the vector of residuals or sampling errors . the matrices @xmath418 and @xmath419 are block diagonal with elements that are functions of a vector parameter @xmath196 of variance components such that @xmath420 .",
    "the target is to predict the linear combination @xmath421 by @xmath422 . under the model , the mle of @xmath148 and @xmath197",
    "are obtained by solving the normal equations @xmath423 ; @xmath424 , @xmath425 . to account for possible outliers ,",
    "the authors propose solving instead @xmath426 @xmath427 where @xmath428 , @xmath429 $ ] , @xmath430'$ ] with @xmath431 defining the huber influence function , @xmath432 is the identity matrix of order @xmath40 and @xmath433 $ ] [ @xmath434 .",
    "notice that since @xmath418 and @xmath419 are block diagonal , the normal equations and the robust estimating equations can be written as sums over the @xmath110 areas .",
    "denote by @xmath435 , @xmath436 the solutions of ( [ 6.26 ] ) .",
    "the random effects are predicted by solving @xmath437\\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\quad { } - \\hat{q}^ { - 1/2}\\psi_{g}(\\hat{q}^ { - 1/2}u ) = 0,\\nonumber\\end{aligned}\\ ] ] where @xmath438 , @xmath439 .",
    "sinha and rao ( @xcite ) estimate the pmse of the robust small area predictors by application of the first step of the double - bootstrap procedure of @xcite ( equation  6.4 ) .",
    "the parameter estimates and the predictors of the random effects needed for the application of the bootstrap procedure are computed by the robust estimating equations ( [ 6.26])([6.27 ] ) , but the generation of the bootstrap samples is under the original model with no outliers . the estimation of the pmse can possibly be improved by generating some outlying observations , thus reflecting more closely the properties of the original sample .      in this section",
    "i review four different approaches proposed in the literature for further robustification of the inference by relaxing some of the model assumptions or using different estimators .",
    "all four studies focus on the commonly used area - level and/or unit - level models defined by ( [ 5.1 ] ) and ( [ 5.3 ] ) , respectively .",
    "classical model - based sae methods model the expectations @xmath440 and@xmath441 . @xcite and tzavidis , marchetti and chambers ( @xcite ) propose modeling instead the quantiles of the distribution @xmath442 , where for now @xmath128 is a scalar .",
    "assuming a linear model for the quantiles , this leads to a family of models indexed by the coefficient @xmath443 ; @xmath444 $ ] . in quantile regression",
    "the vector @xmath445 is estimated by minimizing @xmath446\\}.\\nonumber\\end{aligned}\\ ] ] _ m - quantile _ regression uses influence functions for estimating @xmath445 by solving the equations @xmath447\\\\[-8pt ] \\qquad & & \\psi_{q}(r_{iq } ) = 2\\psi(s^ { - 1}r_{iq})[(1 - q){i}(r_{iq } \\le 0)\\nonumber\\\\ & & \\hspace*{118pt } { } + q{i}(r_{iq } > 0)],\\nonumber\\end{aligned}\\ ] ] where @xmath113 is a robust estimate of scale , and @xmath448 is an appropriate influence function .",
    "the ( unique ) solution @xmath449 of ( [ 6.29 ] ) is obtained by an iterative reweighted least square algorithm .",
    "note that each sample value @xmath450 lies on one and only one of the quantiles @xmath451 ( which follows from the fact that the quantiles are continuous in @xmath452 ) .",
    "how is the m - quantile theory used for sae ?",
    "suppose that the sample consists of unit level observations @xmath453 .",
    "identify for unit @xmath19 the value @xmath454 such that @xmath455 .",
    "a predictor of the mean @xmath22 in area @xmath5 is obtained by averaging the quantiles @xmath454 over the sampled units @xmath456 and computing @xmath457\\\\[-8pt ] \\bar{q}_{i } & = & \\sum_{j = 1}^{n_{i } } q_{ij}/n_{i}.\\nonumber\\end{aligned}\\ ] ] alternatively , one can average the vector coefficients @xmath458and replace @xmath459 in ( [ 6.30 ] ) by the mean @xmath460 .",
    "the vectors @xmath459 or @xmath461 account for differences between the areas , similarly to the random effects under the unit level model ( [ 5.3 ] ) .",
    "the use of this approach is not restricted to the estimation of means , although it does assume continuous @xmath12-values .",
    "for example , the distribution function in area @xmath5 can be estimated as @xmath462 $ ] .",
    "@xcite develop unconditional and area specific estimators for the variance of the m - quantile estimators ( [ 6.30 ] ) assuming @xmath459 ( or @xmath463 is fixed , and estimators for the bias under the linear model @xmath464 .",
    "the m - quantile approach does not assume a parametric model , although it assumes that the quantiles are linear in the covariates in the theory outlined above . clearly , if the unit level model ( [ 5.3 ] ) holds , the use of the model is more efficient , but the authors illustrate that the m - quantile estimators can be more robust to model misspecification .",
    "notice in this regard that the approach is not restricted to a specific definition of the small areas .",
    "it accounts also for possible outliers by choosing an appropriate influence function in the estimating equation ( [ 6.29 ] ) . on the other hand",
    ", there seems to be no obvious way of how to predict the means or other target quantities for nonsampled areas .",
    "a possible simple solution would be to set @xmath465 for such areas or weight the @xmath452-values of neighboring sampled areas , but it raises the question of how to estimate the corresponding pmse , unless under a model .",
    "another way of robustifying the inference is by use of penalized spline ( p - spline ) regression .",
    "the idea here is to avoid assuming a specific functional form for the expectation of the response variable .",
    "suppose that there is a single covariate @xmath466 .",
    "the p - spline model assumes @xmath467 , @xmath468 , @xmath469 .",
    "the mean @xmath470 is taken as unknown and approximated as @xmath471,\\nonumber\\end{aligned}\\ ] ] where @xmath472 is the degree of the spline , and @xmath473 are fixed knots . for large @xmath474 and good spread of the knots over the range of @xmath466 ,",
    "spline ( [ 6.31 ] ) approximates well most smooth functions .",
    "it uses the basis @xmath475 $ ] to approximate the mean , but other bases can be considered , particularly when there are more covariates .",
    "opsomer et al .",
    "( @xcite ) use p - spline regression for sae by treating the @xmath476-coefficients in ( [ 6.31 ] ) as additional random effects .",
    "suppose that the data consist of unit - level observations , @xmath477 . for unit @xmath14 in area @xmath5 ,",
    "the model considered is @xmath478\\\\[-8pt ] & & { } + \\sum_{k = 1}^{k } \\gamma_{k}(x_{ij } - k_{k } ) _ { + } ^{p } + u_{i } + \\varepsilon_{ij},\\nonumber\\end{aligned}\\ ] ] where the @xmath100s are the usual area random effects and @xmath159s are the residuals .",
    "let @xmath479 , @xmath480 .",
    "defining @xmath481 ( 0 ) if unit @xmath14 is ( is not ) in area @xmath5 and denoting @xmath482 and @xmath483'$ ] , the model holding for the vector @xmath12 of all the response values can be written compactly as @xmath484 where @xmath485'$ ] with @xmath486 , and @xmath487'$ ] with @xmath488'$ ] .",
    "the model ( [ 6.33 ] ) looks similar to ( [ 6.25 ] ) but the responses @xmath13 are not independent between the areas because of the common random effects @xmath489 .",
    "nonetheless , the blup and eblup of @xmath490 can be obtained using standard results ; see the article for the appropriate expressions .",
    "the small area eblup are obtained as @xmath491\\\\[-8pt ] \\bar{x}_{i}^{(p ) } & = & \\sum_{l \\in u_{i } } x_{l}^{(p ) } /n_{i},\\quad \\bar{z}_{i } = \\sum_{l \\in u_{i } } z_{l}/n_{i}.\\nonumber\\end{aligned}\\ ] ]    the use of this approach requires that the covariates are known for every element in the population .",
    "opsomer et al .",
    "( @xcite ) derive the pmse of the eblup  ( [ 6.34 ] ) correct to second order for the case where the unknown variances are estimated by reml , and an estimator of the pmse with bias correct to the same order .",
    "the authors develop also a nonparametric bootstrap algorithm for estimating the pmse and for testing the hypotheses @xmath492 and @xmath493 of no random effects .",
    "@xcite use a similar model to ( [ 6.33 ] ) , but rather than computing the eblup under the model , the authors propose predictors that are robust to outliers , similar ( but not the same ) to the methodology developed by sinha and rao ( @xcite ) for the mixed linear model described in section  [ sec6.5 ] .",
    "jiang , nguyen and rao ( @xcite ) show how to select an appropriate spline model by use of the fence method described in section  [ sec8 ] .",
    "@xcite consider the use of empirical likelihoods ( el ) instead of fully parametric likelihoods as another way of robustifying the inference . when combined with appropriate proper priors",
    ", it defines a semiparametric bayesian approach , which can handle continuous and discrete outcomes in area- and unit - level models , without specifying the distribution of the outcomes as under the classical bayesian approach .",
    "denote by @xmath494 and @xmath495 the area parameters and the corresponding direct estimators , and by @xmath496 the `` jumps '' defining the cumulative distribution of @xmath497 , so that @xmath498",
    ". the el is @xmath499 and for given moments @xmath500,@xmath501 , the estimate @xmath502 is the solution of the constrained maximization problem @xmath503\\\\[-8pt ]   & & \\hspace*{36pt}\\sum_{i= 1}^{m } \\tau_{i } [ y_{i } - k(\\theta_{i } ) ] = 0,\\nonumber\\\\   & & \\hspace*{36pt}\\sum_{i = 1}^{m } \\tau_{i}\\biggl\\ { \\frac{[y_{i } - k(\\theta _ { i})]^{2}}{v(\\theta _ { i } ) } - 1\\biggr\\ } = 0.\\nonumber\\end{aligned}\\ ] ] under the area model ( [ 5.1 ] ) @xmath504 and @xmath505 .",
    "the authors assume proper priors for @xmath506 and hence for @xmath343 , thus guaranteeing that the posterior distribution @xmath507 is also proper . for given @xmath343",
    "the constrained maximization problem ( [ 6.35 ] ) is solved by standard methods ( see the article ) , and by combining the el with the prior distributions , observations from the posterior distribution @xmath507 are obtained by mcmc simulations .    for the unit - level model ( [ 5.3 ] ) ,",
    "@xmath508 and @xmath509 . denoting by @xmath510 the `` jumps '' of the cumulative distribution in area @xmath5 , the el",
    "is defined in this case as @xmath511 , and for given @xmath512 , @xmath513'$ ] is the solution of the area specific maximization problem @xmath514\\\\[-8pt ] & & \\hspace*{38pt}\\sum_{j = 1}^{n_{i } } \\tau_{ij } [ y_{ij } - k(\\theta_{ij } ) ] = 0,\\nonumber\\\\ & & \\hspace*{38pt}\\sum_{j = 1}^{n_{i } } \\tau_{ij}\\biggl\\ { \\frac{[y_{ij } - k(\\theta _ { ij})]^{2}}{v(\\theta _ { ij } ) } - 1\\biggr\\ } = 0.\\nonumber\\end{aligned}\\ ] ] the authors applied the procedure for estimating state - wise median income of four - person families in the usa , using the area - level model .",
    "comparisons with the census values for the same year reveal much better predictions under the proposed approach compared to the direct survey estimates and the hb predictors obtained under normality of the direct estimates .      in the three previous ap - proaches  reviewed in this section ,",
    "the intended robustification is achieved by relaxing some of the model assumptions .",
    "jiang , nguyen and rao ( @xcite ) propose instead to change the estimation of the fixed model parameters .",
    "the idea is simple . in classical model - based sae the eblup or eb predictors",
    "are obtained by replacing the parameters in the expression of the bp by their mle or reml estimators . noting that in sae the actual target is the prediction of the area means , and the estimation of model parameters is just an intermediate step , the authors propose to estimate the fixed parameters in such a way that the resulting predictors are optimal under some loss function .",
    "consider the area - level model ( [ 5.1 ] ) with normal errors , and suppose first that @xmath99 is known . under the model , @xmath515 , but suppose that the model is misspecified and @xmath516 , such that @xmath517 , @xmath518 .",
    "let @xmath154 be a predictor of @xmath22 , and define the mean square prediction error to be @xmath519 , where the expectation is under the _ correct model_. by ( [ 5.2 ] ) , the mspe of the bp for given @xmath148 is @xmath520= e\\ { \\sum_{i = 1}^{m } [ \\gamma_{i}y_{i } + ( 1 - \\gamma_{i})\\mathrm{x}'_{i}\\beta - \\theta_{i}]^{2 } \\}$ ] .",
    "the authors propose minimizing the expression inside the expectation with respect to @xmath148 , which is shown to be equivalent to minimizing @xmath521 $ ] , yielding the `` best predictive estimator '' ( bpe ) @xmath522^ { - 1}\\sum_{i = 1}^{m } ( 1 - \\gamma_{i})^{2 } \\mathrm{x}_{i}y_{i}.\\hspace*{-15pt}\\end{aligned}\\ ] ] notice that unless @xmath523 , @xmath524 differs from the commonly used gls estimator under the model ( [ 5.1 ] ) ; @xmath525^ { - 1}\\sum_{i = 1}^{m } \\gamma_{i } \\mathrm{x}_{i}y_{i}$ ] .",
    "the `` observed best predictor '' ( obp ) of @xmath22 is obtained by replacing @xmath123 by @xmath524 in the bp ( [ 5.2 ] ) under the model  ( [ 5.1 ] ) .",
    "the authors derive also the bpe of @xmath526 for the case where @xmath99 is unknown , in which case the obp is obtained by replacing @xmath99 and @xmath123 by the bpe of @xmath89 in ( [ 5.2 ] ) .",
    "another extension is for the unit level model  ( [ 5.3 ] ) , with the true area means and mspe defined as @xmath527 and @xmath528 = \\sum_{i = 1}^{m } e_{d } [ \\tilde{\\theta } _ {",
    "i}(\\psi ) - \\theta_{i}]^{2}$ ] , respectively , where @xmath529 and @xmath530 is the design ( randomization ) expectation over all possible sample selections ( section  [ sec4.1 ] ) .",
    "the reason for using the design expectation in this case is that it is almost free of model assumptions .",
    "theoretical derivations and empirical studies using simulated data and a real data set illustrate that the obp can outperform very significantly the eblup in terms of pmse if the underlying model is misspecified .",
    "the two predictors are shown to have similar pmse under correct model specification .",
    "@xcite consider the following ( hard ) problem : predict the ordered area means @xmath531 under the area - level model @xmath532 [ special case of ( 5.1 ) ] , with @xmath533 , @xmath534 ; @xmath535 and @xmath412 are general distributions with zero means and variances @xmath99 and @xmath536 . to illustrate the difference between the prediction of ordered and unordered means ,",
    "consider the prediction of @xmath537 .",
    "if @xmath140 satisfies @xmath538 , then @xmath539 \\ge\\theta_{(m)}$ ] so that the largest estimator overestimates the true largest mean .",
    "on the other hand , the bayesian predictors @xmath540 $ ] satisfy @xmath541 < e(\\theta_{(m)})$ ] , an underestimation in expectation .",
    "@xcite considered the prediction of ordered means from a bayesian perspective , but their approach requires heavy numerical calculations and is sensitive to the choice of priors .",
    "@xcite compare three predictors of the ordered means under the frequentist approach , using the loss function @xmath542 and the bayes risk @xmath543 $ ] .",
    "let @xmath140 define the direct estimator of @xmath22 and @xmath544 the @xmath5th ordered direct estimator ( statistic ) .",
    "the predictors compared are @xmath545 the results below assume that @xmath99 and @xmath536 are known and that @xmath546 is estimated by @xmath547 .",
    "denote by @xmath548}_{(\\cdot)}$ ] the predictor of the ordered means when using the predictors @xmath549 , @xmath550 , and let @xmath551 be the shrinkage coefficient when predicting the unordered means [ equation ( [ 5.2 ] ) ] .",
    "the authors derive several theoretical comparisons .",
    "for example , if @xmath552 , then @xmath553}(\\delta),\\theta_{(\\cdot)}\\bigr)\\bigr ] \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\quad \\le e\\bigl[l\\bigl(\\tilde{\\theta } _ { ( \\cdot)}^{[1]},\\theta_{(\\cdot)}\\bigr)\\bigr]\\quad \\mbox{for all } \\gamma\\le\\delta\\le 1.\\end{aligned}\\ ] ] noting that @xmath554 = 1 $ ] , it follows that ( [ 6.39 ] ) holds asymptotically for all @xmath489 , and the inequality @xmath555 implies less shrinkage of the direct estimators toward the mean . in particular , the optimal choice of @xmath556 for @xmath557}(\\delta)$ ] satisfies @xmath558 .    the results above assume general distributions @xmath535 and @xmath412 . when these distributions are normal , then for @xmath559 , @xmath560},\\theta_{(\\cdot ) }",
    ") ] \\le e[l(\\tilde{\\theta } _ { ( \\cdot)}^{[2]}(\\delta),\\theta_{(\\cdot)})]$ ] for all @xmath556 .",
    "a conjecture supported by simulations is that this relationship holds also for @xmath561 .",
    "however , the simulations suggest that for sufficiently large @xmath110 ( e.g. , ) , @xmath562}$ ] is efficiently replaced by @xmath557}(\\gamma^{1/2})$ ] .",
    "the last two conclusions are shown empirically to hold also in the case where @xmath99 is unknown and replaced by the mom variance estimator .",
    "[ rem5 ] the problem of predicting the ordered means is different from ranking them , one of the famous triple - goal estimation objectives in sae .",
    "the triple - goal estimation consists of producing `` good '' area specific estimates , `` good '' estimates of the histogram ( distribution ) and `` good '' estimates of the ranks .",
    "see @xcite for discussion .",
    "judkins and liu ( @xcite ) considered another related problem of estimating the range of the area means .",
    "the authors show theoretically and by simulations that the range of the direct estimators overestimates the true range , whereas the range of the empirical bayes estimators underestimates the true range , in line with the discussion at the beginning of this section .",
    "the bias is much reduced by use of a constrained empirical bayes estimator . for the model considered by @xcite ,",
    "the constrained estimator is obtained by replacing the shrinkage coefficient @xmath563 in ( [ 5.2 ] ) by @xmath564 , which again shrinkages less the direct estimator .      in this section",
    "i review two relatively new applications of sae ; assessment of literacy and poverty mapping .",
    "the latter application , in particular , received considerable attention in recent years .",
    "the notable feature of assessing literacy from a literacy test is that the possible outcome is either zero , indicating illiteracy , or a positive continuous score measuring the level of literacy .",
    "another example of this kind of data is the consumption of illicit drugs , where the consumption is either zero or a continuous measure . in both examples",
    "the zero scores are `` structural '' ( true ) zeroes .",
    "the common models used for sae are not applicable for this kind of responses if the proportion of zeroes is high .",
    "pfeffermann , terryn and moura ( @xcite ) consider the estimation of the average literacy score and the proportion of people with positive scores in districts and villages in cambodia , a  study sponsored by the unesco institute for statistics ( uis ) .",
    "denote by @xmath565 the test score of adult @xmath121 from village @xmath14 of district @xmath5 and by @xmath566 a set of covariates and district and village random effects .",
    "the following relationship holds : @xmath567\\\\[-8pt ] & & { } \\cdot\\pr(y_{ijk } > 0|r_{ijk}).\\nonumber\\end{aligned}\\ ] ] the two parts in the right - hand side of ( [ 6.40 ] ) are modeled as @xmath568 = \\mathrm{x}'_{ijk}\\beta + u_{i } + v_{ij}$ ] , where @xmath569 are district and nested village random effects , @xmath570 ; @xmath571 , where @xmath572 defines a set of covariates which may differ from @xmath573 and @xmath574 are district and nested village random effects , which are correlated respectively with @xmath569 .",
    "the village and district predictors of the average score and the proportion of positive scores are obtained by application of the bayesian approach with noninformative priors , using mcmc simulations .",
    "the use of the bayesian approach enables one to account for the correlations between the respective random effects in the two models , which is not feasible when fitting the two models separately .",
    "the area predictors are obtained by imputing the responses for nonsampled individuals by sampling from their posterior distribution , and adding the imputed responses to the observed responses ( when observations exist ) .",
    "[ rem6 ] mohadjer et al .",
    "( @xcite ) estimate the proportions @xmath575 of adults in the lowest level of literacy in counties and states of the usa , by modeling the direct estimates @xmath576 in county @xmath14 of state @xmath5 as @xmath577 , and modeling @xmath578 with @xmath100 and @xmath579 defining state and county random effects .",
    "the state and county estimates are likewise obtained by mcmc simulations with noninformative priors .",
    "note that this is not a two - part model .",
    "the estimation of poverty indicators in small regions is of major interest in many countries across the world , initiated and sponsored in many cases by the united nations and the world bank . in a celebrated article ( awarded by the canadian statistical society as the best paper published in 2010 in _ the candian journal of statistics _ ) , molina and rao focus on estimation of area means of nonlinear poverty measures called fgt defined as @xmath580\\\\[-8pt ]   f_{\\alpha ij } & = & \\biggl ( \\frac{z - e_{ij}}{z } \\biggr)^{\\alpha } \\times{i}(e_{ij } <",
    "z),\\nonumber\\\\ \\eqntext{\\alpha = 0,1,2,}\\end{aligned}\\ ] ] where @xmath581 is a measure of welfare for unit @xmath14 in area @xmath5 such as income or expenditure , @xmath582 is a poverty threshold under which a person is considered `` poor '' ( e.g. , 60% of the nation median income ) and @xmath583 is the indicator function . for @xmath584 , @xmath585 is the proportion under poverty . for @xmath586 ,",
    "@xmath585 measures the `` poverty gap , '' and for @xmath587 , @xmath585 measures `` poverty severity . ''    for @xmath588",
    "it is practically impossible to assign a distribution for the measures @xmath589 , and in order to estimate the means @xmath585 in sampled and nonsampled areas , molina and rao ( @xcite ) assume the existence of a one - to - one transformation @xmath590 such that the transformed outcomes @xmath13 satisfy the unit level model ( [ 5.3 ] ) with normal distribution of the random effects and the residuals .",
    "notice that @xmath591^{\\alpha } \\times{i}[t^ { - 1}(y_{ij } ) < z ] = : h_{\\alpha } ( y_{ij})$ ] .",
    "for sampled units @xmath456 @xmath589 is known , and for the nonsampled units @xmath592 , the missing measures are imputed by the ebp @xmath593 = \\sum_{l = 1}^{l } h_{\\alpha } ( y_{ik}^{(l)})/l$ ] with large @xmath594 , where @xmath116 defines all the observed outcomes .",
    "the predictions @xmath595 are obtained by monte carlo simulation from the conditional normal distribution of the unobserved outcomes given the observed outcomes under the model ( [ 5.3 ] ) , using estimated parameters @xmath596 .",
    "the pmse of the ebp @xmath597/n_{i}$ ] is estimated similarly to the first step of the double - bootstrap procedure described in section  [ sec6.1 ] .",
    "model- and design - based simulations and application to a real data set from spain using the transformation @xmath598 demonstrate good performance of the area predictors and the pmse estimators .",
    "[ rem7 ] the world bank ( wb ) is currently using a different method , under which all the population values @xmath13 are simulated from model ( [ 5.3 ] ) with estimated parameters ( including for sampled units ) , but with random effects for design clusters , which may be different from the small areas .",
    "as discussed and illustrated by @xcite , the use of this procedure means that all the areas are practically considered as nonsampled , and the resulting predictors of the means @xmath599 in ( [ 6.41 ] ) are in fact synthetic predictors since the random effects and the area means of the residuals cancel out over the @xmath594 simulated populations .",
    "simulation results in molina and rao ( @xcite ) show that the wb method produces predictors with much larger pmse than the pmse of the ebp predictors proposed by them .",
    "all the studies reviewed in this paper assume , at least implicitly , that the selection of areas that are sampled and the sampling designs within the selected areas are noninformative , implying that the model assumed for the population values applies also to the sample data with no sampling bias .",
    "this , however , may not be the case , and as illustrated in the literature , ignoring the effects of informative sampling may bias the inference quite severely .",
    "a  similar problem is not missing at random ( nmar ) nonresponse under which the response probabilities depend on the missing data , which again can bias the predictions if not accounted for properly .",
    "these problems received attention under both the frequentist and the bayesian approaches .",
    "@xcite consider the problem of informative sampling of areas and within the areas .",
    "the basic idea in this article is to fit a sample model to the observed data and then exploit the relationship between the sample model , the population model and the sample - complement model ( the model holding for nonsampled units ) in order to obtain unbiased predictors for the means in sampled and nonsampled areas .",
    "consider a two - stage sampling design by which @xmath110 out of @xmath2 areas are selected in the first stage with probabilities @xmath600 , and @xmath10 out of @xmath4 units are sampled from the @xmath5th selected area with probabilities @xmath601 .",
    "denote by @xmath602 and @xmath603 the sample indicator variables for the two stages of sampling and by @xmath604 and @xmath605 the first and second stage sampling weights .",
    "suppose that the first level area random effects @xmath606 are generated independently from a distribution with p.d.f .",
    "@xmath607 , and that for given @xmath100 the second level values @xmath608 are generated independently from a distribution with p.d.f .",
    "@xmath609 . the conditional first - level",
    "_ sample p.d.f .",
    "_ of @xmath100 , that is , the p.d.f . of @xmath100 for area",
    "@xmath610 is @xmath611 the conditional first - level _ sample - complement _ _ p.d.f .",
    "_ of  @xmath100 , that is , the p.d.f . for area @xmath612",
    "is @xmath613\\\\[-8pt ] & = & \\operatorname{pr}({i}_{i } = 0| u_{i})f_{p}(u_{i})/\\pr({i}_{i } = 0).\\nonumber\\end{aligned}\\ ] ] note that the _ population _ , _ sample _ and _ sample - complement _ p.d.f.s are the same if @xmath614 , in which case the area selection is _",
    "noninformative_. similar relationships hold between the sample p.d.f .",
    ", population p.d.f . and sample - complement p.d.f .",
    "of the outcomes @xmath13 within the selected areas , for given values of the random effects .",
    "@xcite illustrate their approach by assuming that the _ sample model _ is the unit - level model ( [ 5.3 ] ) with normal random effects and residuals , and that the sampling weights within the selected areas have sample model expectations , @xmath615 where @xmath616,and @xmath617 and @xmath618 are fixed constants .",
    "no model is assumed for the relationship between the area selection probabilities and the area means .",
    "the authors show that under this model and for given parameters @xmath619 , the true mean @xmath24 in sampled area @xmath5 can be predicted as @xmath620\\\\ & & \\hspace*{102pt}{}+ ( n_{i } - n_{i})b\\sigma_{e}^{2}\\},\\nonumber\\end{aligned}\\ ] ] where @xmath621 represents all the known data and @xmath622 is the optimal predictor of the sample model mean @xmath623 .",
    "the last term in ( [ 7.4 ] ) corrects for the sample selection effect , that is , the difference between the sample - complement expectation and the sample expectation in sampled areas .",
    "the mean @xmath624 of area @xmath121 not in the sample can be predicted as @xmath625.\\nonumber\\end{aligned}\\ ] ] the last term of ( [ 7.5 ] ) corrects for the fact that the mean of the random effects in areas outside the sample is different from zero under informative selection of the areas .",
    "the authors develop test procedures for testing the informativeness of the sample selection and a bootstrap procedure for estimating the pmse of the empirical predictors obtained by substituting the unknown model parameters by sample estimates .",
    "the method is applied for predicting the mean body mass index ( bmi ) in counties of the usa using data from the third national health and nutrition examination survey ( nhanes iii ) .",
    "malec , davis and cao ( @xcite , hereafter mdc ) and nandram and choi ( @xcite , hereafter nc ) likewise consider the estimation of county level bmi statistics from nhanes iii , with both articles accounting for within - area informative sampling in a similar manner , and the latter article accounting , in addition , for informative nonresponse .",
    "another difference between the two articles is that mdc consider binary population outcomes ( overweight / normal status ) , with logistic probabilities that contain fixed and multivariate random area effects , whereas nc assume a log - normal distribution for the continuous bmi measurement , with linear spline regressions containing fixed and random area effects defining the means . in order to account for sampling effects ,",
    "both articles assume that each sampled unit represents @xmath626 other units ( not sampled ) within a specified group ( cluster ) of units , with unit @xmath14 selected with probability @xmath627 that can take one of the @xmath412 observed values @xmath628 , @xmath629 in that group .",
    "the groups are defined by county and demographic characteristics .",
    "specifically , let @xmath630 if unit @xmath14 is sampled ( not sampled ) .",
    "the mdc model for a given group assumes @xmath631 & \\eqntext{y= 0,1 ; g = 1,\\ldots , g , } \\\\ & & \\pr(y_{j } = y|p ) = p^{y}(1 - p)^{1 - y},\\nonumber\\\\ & \\eqntext{0 \\le p \\le 1 ; p(k ) = 1.}\\end{aligned}\\ ] ] it follows that @xmath632\\\\[-8pt ] & & \\quad\\propto\\frac{p^{y}(1 - p)^{1 - y}}{\\sum_{g = 1}^{g } \\pi _ { g}^{*}\\sum_{y = 0}^{1 } \\theta _ { gy}p^{y}(1 - p)^{1 - y}}.\\nonumber\\end{aligned}\\ ] ] mdc show that the mle of @xmath633 is @xmath634 where @xmath635 is the sample frequency of @xmath628 in the group for units with overweight status @xmath12 .",
    "they plug the estimate into ( [ 7.7 ] ) and then into the full likelihood that includes also the distribution of random effects contained in a logit model for @xmath472 .",
    "nc generalize model ( [ 7.6 ] ) by allowing the outcome to be continuous , assuming @xmath636 , @xmath637 where @xmath638 for @xmath639 , and replacing the bernoulli distribution for @xmath12 by a continuous p.d.f . to account for informative nonresponse",
    ", the authors assume that the response probabilities @xmath640 are logistic with @xmath641 , where @xmath642 is another set of random effects having a bivariate normal distribution .",
    "[ rem8 ] as the notation suggests , both mdc and nc use the full bayesian approach with appropriate prior distributions to obtain the small area predictors under the respective models .",
    "see the articles for details .",
    "the authors do not consider informative sampling of the areas .",
    "i conclude this section by describing an article by @xcite , which uses a very different model from the other models considered in the present paper .",
    "the article considers the estimation of small area compositions in the presence of nmar nonresponse .",
    "compositions are the counts or proportions in categories of a categorical variable such as types of households , and estimates of the compositions are required for every area .",
    "zhang deals with this problem by assuming that the generalized spree model ( gspree ) developed in @xcite holds for the complete data ( with no missingness ) . in order to account for the nonresponse",
    ", zhang assumes that the probability to respond is logistic , with a fixed composition effect @xmath643 and a random area effect @xmath644 as the explanatory variables .",
    "( same probability for all the units in a given cell defined by area @xmath645 category . ) the model depends therefore on two sets of random effects , one set for the underlying complete data , with a vector of correlated multivariate normal composition effects in each area defining the gspree model , and the other set for the response probabilities .",
    "@xcite estimates the small area compositions under the extendedgspree using the em algorithm , and estimates the pmse under the model , accounting for the fixed and random effects estimation .",
    "the approach is applied to a real data set from norway .",
    "model selection and checking is one of the major problems in sae because the models usually contain unobservable random effects , with limited or no information on their distribution .",
    "notice that classical model selection criteria such as the aic do not apply straightforwardly to mixed models because they use the likelihood , which requires specification of the distribution of the random effects , and because of difficulties in determining the effective number of parameters . in",
    "what follows i review several recent studies devoted to model selection and validation from both a frequentist and bayesian perspective .",
    "these should be considered as supplements to `` ordinary '' checking procedures based on graphical displays , significance testing , sensitivity of the computed predictors and their pmses to the choice of the likelihood and the prior distributions , and comparison of the model - dependent predictors with the corresponding model free direct estimators in sampled areas .",
    "such model evaluation procedures can be found in almost every article on sae ; see , for example , mohadjer et al .",
    "( @xcite ) and nandram and choi ( @xcite ) for recent diverse applications .",
    "@xcite study the use of the aic assuming model ( [ 6.1 ] ) with @xmath646,@xmath647 .",
    "the authors distinguish between inference on the marginal model with focus on the fixed effects , and inference on the model operating in the small areas with the associated vector random effects @xmath100 .",
    "for the first case , the model can be written as a regression model with correlated residuals : @xmath648 ; @xmath649 .",
    "for this case , the classical ( marginal ) aic , @xmath650 applies , where @xmath12 is the vector of all the observations , @xmath651 is the marginal likelihood evaluated at the mle of @xmath89 , the vector containing @xmath148 , @xmath652 and the unknown elements of @xmath418 and .",
    "@xcite validates by simulations that one can use also in this case the maic with @xmath653 , despite the use of different fixed effects design matrices under different models .    for the case where the focus is the model operating at the small areas , @xcite propose using a conditional aic , which , for a given likelihood @xmath654 , is defined as @xmath655\\\\[-8pt ]   p^ * & = & \\frac{n(n - k - 1)(\\rho + 1 ) + n(k + 1)}{(n - k)(n - k - 2)},\\nonumber\\end{aligned}\\ ] ] where @xmath121 is the number of covariates",
    ", @xmath656 is the ebp of @xmath282 and @xmath657 with @xmath535 defining the matrix mapping the observed vector @xmath12 into the fitted vector @xmath658 , such that @xmath659 . notice that under this definition of the caic , the @xmath100s are additional parameters .",
    "a conditional aic for the case where @xmath89 is estimated by reml is also developed .",
    "the article contains theoretical results on properties of the caic and empirical results illustrating its good performance .",
    "the use of ( [ 8.1 ] ) is not restricted to mixed linear models with normal distributions of the error terms , and it can be used to select the design matrices @xmath188 and @xmath189 .    pan and lin ( @xcite ) propose alternative goodness - of - fit test statistics for the glmm , based on estimated cumulative sums of residuals . utilizing the notation for model ( [ 6.1 ] ) , the glmm assumes the existence of a one - to - one link function @xmath660 , satisfying @xmath661 = \\mathrm{x}'_{ij}\\beta + \\mathrm{z}'_{ij}u_{i}$ ] , where @xmath33 and @xmath662 are the rows of the matrices @xmath188 and @xmath189 corresponding to unit @xmath663 .",
    "the unconditional predictor of @xmath13 is @xmath664 $ ] , which is estimated by @xmath665 .",
    "the estimated model residuals are therefore @xmath666 , and they are computed by numerical integration .",
    "the authors consider two statistics based on the distributions of aggregates of the residuals , @xmath667\\\\[-8pt ]   w_{g}(r ) & = & n^ { - 1/2}\\sum_{i = 1}^{m } \\sum_{j = 1}^{n_{i } } i(\\hat{m}_{ij } \\le r ) e_{ij},\\nonumber\\end{aligned}\\ ] ] where @xmath668 .",
    "in particular , for  testing the functional form of the @xmath207th covariate , one  may consider the process @xmath669 , which is a special caseof  @xmath670 .",
    "the authors develop a simple approximation for the null distribution of @xmath671 and use it for visual inspection by plotting the observed values against realizations from the null distributions for different values of @xmath466 , and for a formal test defined by the supremum @xmath672 .",
    "the statistic @xmath673 is used for testing the functional form of the deterministic part of the model . to test the appropriateness of the link function , the authors follow similar steps , using the statistics @xmath674 for visual inspection and @xmath675 for formal testing . as discussed in the article ,",
    "although different tests are proposed for different parts of the model , each test actually checks the entire model , including the assumptions regarding the random components .",
    "the goodness - of - fit tests considered so far assume a given structure of the random effects , but are random effects actually needed in a sae model applied to a given data set ?",
    "datta , hall and mandal ( @xcite ) show that if in fact the random effects are not needed and are removed from the model , it improves the precision of point and interval estimators .",
    "the authors assume the availability of @xmath121 covariates @xmath676 , @xmath180 ( viewed random for the theoretical developments ) and weighted area - level means @xmath677 ; @xmath678 of the outcome with known weights and known sums @xmath679 , @xmath680 , @xmath681 .",
    "the weights @xmath57 are used for generating new area level means from bootstrap samples , and the sums @xmath682 are used for estimating model parameters by constructing appropriate estimating equations .    in order to test for the presence of random effects ,",
    "the authors propose the test statistic @xmath683^ { - 1}[\\bar{y}_{i } - \\lambda_{1}(\\mathrm{x}_{i},\\hat{\\psi } ) ] ^{2},\\ ] ] where @xmath684 , @xmath685 define the conditional mean and residual variance of @xmath686 under the reduced model of no random effects , with estimated ( remaining ) parameters @xmath217 .",
    "critical values of the distribution of @xmath687 under the null hypothesis of no random effects are obtained by generating bootstrap samples with new outcomes from the conditional distribution of @xmath688 for given ( original ) covariates and weights , and computing the test statistic for each sample .",
    "empirical results indicate good powers of the proposed procedure and reduction in pmse when the null hypothesis is not rejected .",
    "the procedure is applicable to very general models .",
    "jiang et al .",
    "( @xcite ) propose a class of strategies for mixed model selection called _ fence methods _ , which apply to lmm and glmm .",
    "the strategies involve a procedure to isolate a subgroup of correct models , and then select the optimal model from this subgroup according to some criterion .",
    "let @xmath689 define a measure of `` lack of fit '' of a candidate model @xmath2 with parameters @xmath690 , such that @xmath691 is minimized when @xmath2 is the true model .",
    "examples of @xmath692 are minus the loglikelihood or the residual sum of squares .",
    "define @xmath693 , and let @xmath694 be such that @xmath695 where @xmath696 represents the set of candidate models .",
    "it is shown that under certain conditions , @xmath697 is a correct model with probability tending to one . in practice",
    ", there can be more than one correct model and a second step of the proposed procedure is to select an optimal model among models that are within a fence around @xmath698 .",
    "examples of optimality criteria are minimal dimension or minimum pmse .",
    "the fence is defined as @xmath699 , where @xmath700 is an estimate of the standard deviation of @xmath701 , and @xmath702 is a tuning coefficient that increases with the total sample size .",
    "jiang et al . (",
    "@xcite ) discuss alternative ways of computing @xmath703 and propose an adaptive procedure for choosing the tuning coefficient .",
    "the procedure consists of parametric bootstrapping new samples from the `` full '' model , computing for every candidate model @xmath704 the empirical proportion @xmath705 that it is selected by the fence method with a given @xmath702 , computing @xmath706 and choosing @xmath702 that maximizes @xmath707 .",
    "jiang et al .",
    "( @xcite ) apply the method for selecting the covariates in the area - level model ( [ 5.1 ] ) and the unit level model ( [ 5.3 ] ) .",
    "jiang , nguyen and rao ( @xcite ) apply the method for selecting nonparametric p - spline models of the form ( [ 6.31 ] ) . selecting a model in this case",
    "requires selecting the degree of the spline @xmath472 , the number of knots @xmath474 and a smoothing parameter @xmath708 used for estimation of the model parameters .",
    "so far i have considered model selection and diagnostic procedures under the frequentist approach , but sound model checking is obviously required also under the bayesian approach .",
    "although this article is concerned with new developments , it is worth starting with a simulation procedure proposed by dey et al .",
    "( @xcite ) since it highlights a possible advantage of the bayesian approach in model checking .",
    "let @xmath309 define a discrepancy measure between the assumed model and the data , such as minus the first - stage likelihood of a hierarchical model .",
    "denote by @xmath709 the observed data and assume an _ informative prior_. the procedure consists of generating a large number @xmath419 of new data sets @xmath710 , @xmath179 under the presumed model via monte carlo simulations and comparing the posterior distribution of @xmath711 with the distributions of @xmath712 .",
    "specifically , for each posterior distribution @xmath713 compute the vector of quantiles @xmath714 ( say @xmath715 , @xmath716 , @xmath717 ) , compute @xmath718 and the euclidean distances between @xmath719 and @xmath720 , and checkwhether the distance of the quantiles of the distribution of @xmath711 from @xmath720 is smaller or larger than , say , the 95th percentile of the @xmath419 distances .",
    "[ rem9 ] the procedure is computationally intensive , and it requires informative priors to allow generating new data sets , but it is very flexible in terms of the models tested and the discrepancy measure(s ) used .",
    "a frequentist analog via parametric bootstrap would require that the distribution of @xmath309 does not depend on the model parameters , or that the sample sizes are sufficiently large to permit ignoring parameter estimation .",
    "@xcite investigate bayesian methods for _ objective _ model checking , which requires _ noninformative priors _ for the parameters @xmath89 .",
    "the authors assume a given diagnostic statistic @xmath687 ( not a function of @xmath89 ) and consider two `` surprise measures '' of conflict between the observed data and the presumed model ; the @xmath472-value @xmath721 $ ] , and the relative predictive surprise @xmath722/\\sup_{t}[h(t)]$ ] , where @xmath723 is some specified distribution . denote by @xmath343 the small area parameters .",
    "writing @xmath724 , it is clear that defining @xmath723 requires integrating @xmath343 out of @xmath725 with respect to some distribution for @xmath343 .",
    "the prior @xmath726 can not be used since it is also improper and the authors consider three alternative solutions : 1 . set the model hyper - parameters @xmath89 at their estimated value and integrate with respect to @xmath727 .",
    "this is basically an application of empirical bayes and @xmath728 .",
    "2 . integrate @xmath343 out by use of the posterior distribution @xmath729 .",
    "3 .  noticing that under the above two solutions , the data are used both for obtaining a proper distribution for @xmath343 and for computing the statistic @xmath730 , the third solution removes the information in @xmath730 from @xmath709 by using the conditional likelihood @xmath731 .",
    "the resulting posterior distribution for @xmath343 is then used to obtain the distribution @xmath723 , similarly to the previous cases .",
    "the specified distribution @xmath723 under all three cases may not have a closed form , in which case it is approximated by mcmc simulations .",
    "see the article for details and for illustrations of the approach showing , in general , the best performance under the third solution .    @xcite consider a specific model inadequacy , namely , fitting models that do not account for all the hierarchical structure present , and , like the last article , restrict to noninformative priors .",
    "the authors consider two testing procedures , both based on the predictive posterior distribution @xmath732 , where @xmath733 and @xmath709 are assumed to be independent given @xmath89 .",
    "the first procedure uses the posterior predictive @xmath472-values , @xmath734 .",
    "the second procedure uses the @xmath472-values of a diagnostic statistic @xmath735 or a discrepancy measure @xmath736 ( see above ) , for example , the @xmath472-values @xmath737 $ ] .",
    "the authors analyze the simple case of a balanced sample where the fitted model is @xmath738 , @xmath180 , @xmath739 .",
    "it is shown that if the model is correct , then as @xmath740 the distributions of @xmath709 and @xmath741 are the same , and the @xmath472-values @xmath742 are distributed uniformly , as revealed in a q  q plot . on the other hand , if the true model is the two - level model @xmath743 , @xmath744 , then as @xmath745 the mean and variance of the two models still agree , but not the covariances , so that it is the ensemble of the @xmath742s or their q  q plot against the uniform distribution , but not individual @xmath472-values , that permits distinguishing the two models .",
    "this , however , is only effective if the intra - cluster correlation is sufficiently high , and the number of areas sufficiently small .",
    "similar conclusions hold when comparing a two - stage hierarchical model with a three - stage model , and when applying the second testing procedure with the classical anova @xmath746 test statistic as the diagnostic statistic , that is , when computing @xmath747 $ ] .",
    "@xcite consider a third procedure for detecting a missing hierarchical structure , which uses q ",
    "q plots of the predictive standardized residuals @xmath748^{1/2}}$ ] against the standard normal distribution .",
    "the conditions under which the procedure performs well in detecting a misspecified hierarchy are the same as above .    finally , i like to mention two articles that in a certain way bridge between the frequentist and bayesian approaches for model selection .",
    "the idea here is to set up a noninformative prior under the bayesian approach so that the resulting posterior small area predictors have acceptable properties under the frequentist approach .",
    "this provides frequentist validation to the bayesian methodology , and the analyst may then take advantage of the flexibility of bayesian inference by drawing observations from the posterior distribution of the area parameters . both articles",
    "consider the area - level model ( [ 5.1 ] ) , but the idea applies to other models .",
    "datta , rao and smith ( @xcite ) assume a flat prior for @xmath148 and seek a prior @xmath749 satisfying @xmath750 + o(m^ { - 1})$ ] , where @xmath751 is the posterior variance of @xmath22 , and@xmath752 $ ] is the frequentist pmse of theeblup ( or eb ) when estimating @xmath99 by reml .",
    "the expectation and pmse are computed under the joint distribution of @xmath343 and @xmath12 under the model .",
    "the unique prior satisfying this requirement is shown to be @xmath753.\\ ] ] the prior is area specific in the sense that different priors are required for different areas .",
    "@xcite extend the condition of datta , rao and smith ( @xcite ) to a weighted combination of the posterior expectations and the pmses , thus obtaining a single prior for all the areas .",
    "the authors seek a prior which for a given set of weights @xmath754 satisfies @xmath755\\}\\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\quad = o(1/m).\\nonumber\\end{aligned}\\ ] ] the prior @xmath749 satisfying ( [ 8.5 ] ) is shown to be @xmath756\\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } \\bigg/\\sum_{i = 1}^{m } \\omega_{i}[\\sigma_{di}^{2}/(\\sigma_{di}^{2 } + \\sigma_{u}^{2 } ) ] ^{2}.\\nonumber\\end{aligned}\\ ] ] by appropriate choice of the weights @xmath757 , prior ( [ 8.6 ] ) contains as special cases the flat prior @xmath758 , the prior developed by datta , rao and smith ( @xcite ) for a given area and the average moment matching prior ( obtained by setting @xmath759 .",
    "in this article i reviewed many new important developments in design- and model - based sae .",
    "these developments give analysts much richer and more versatile tools for their applications .",
    "which approach should one follow in practice ?",
    "model - based predictors are generally more accurate and , as discussed in section  [ sec4.3 ] , the models permit predictions for nonsampled areas for which no design - based theory exists . with everything else that can be done under a model , much of which reviewed in sections  [ sec6][sec8 ] , it seems to me that the choice between the two approaches is clear - cut , unless the sample sizes in all the areas are sufficiently large , although even in this case models have much more to offer like , for example , in the case of measurement errors or nmar nonresponse .",
    "this is not to say that design - based estimators have no role in model - based prediction . to begin with , the design - based estimators are often the input data for the model , as under the area - level model .",
    "design - based estimators can be used for assessing the model - based predictors or for calibrating them via benchmarking , and the sampling weights play an important role when accounting for informative sampling .",
    "next is the question of whether to follow the bayesian approach ( ba ) or the frequentist approach ( fa ) .",
    "i  have to admit that before starting this extensive review i was very much in favor of fa , but the ba has some clear advantages .",
    "this is because one can generate as many observations as desired from the posterior distributions of the area parameters , and hence it is much more flexible in the kind of models and inference possibilities that it can handle , for example , when the linking model does not match the conditional sampling model ( remark  [ rem2 ] ) .",
    "note also that the computation of pmse ( bayes risk ) or credibility intervals under ba does not rely on asymptotic properties .",
    "a common criticism of ba is that it requires specification of prior distributions but as emphasized in section  [ sec8 ] , bayesian models with proper , or improper priors can be tested in a variety of ways .",
    "another criticism is that the application of ba is often very computation intensive and requires expert knowledge and computing skills even with modern available software . while this criticism may be correct ( notably in my experience ) ,",
    "the use of fa methods when fitting the glmm is also very computation intensive and requires similar skills . saying all this , it is quite obvious to me that the use of fa will continue to be dominant for many years to come because , except for few exceptions , official statistical bureaus are very reluctant to use bayesian methods .    where do we go from here ?",
    "research on sae continues all over the world , both in terms of new theories and in applications to new intriguing problems , and i  hope that this review will contribute to this research .",
    "the new developments that i have reviewed are generally either under ba or fa , and one possible direction that i  hope to see is to incorporate the new developments under one approach into the other .",
    "for example , use the el approach under fa , use spline regressions under ba , account for nmar nonresponse in fa or produce poverty mapping with ba .",
    "some of these extensions will be simple ; other may require more extensive research , and some may not be feasible , but this will make it easier for analysts to choose between the two approaches .",
    "i am very grateful to three reviewers for very constructive comments which enhanced the discussion and coverage of this review very significantly ."
  ],
  "abstract_text": [
    "<S> the problem of small area estimation ( sae ) is how to produce reliable estimates of characteristics of interest such as means , counts , quantiles , etc . , for areas or domains for which only small samples or no samples are available , and how to assess their precision . </S>",
    "<S> the purpose of this paper is to review and discuss some of the new important developments in small area estimation methods . </S>",
    "<S> rao [ _ small area estimation _ ( 2003 ) ] wrote a very comprehensive book , which covers all the main developments in this topic until that time . </S>",
    "<S> a few review papers have been written after 2003 , but they are limited in scope . hence , the focus of this review is on new developments in the last 78 years , but to make the review more self - contained , i also mention shortly some of the older developments . </S>",
    "<S> the review covers both design - based and model - dependent methods , with the latter methods further classified into frequentist and bayesian methods . </S>",
    "<S> the style of the paper is similar to the style of my previous review on sae published in 2002 , explaining the new problems investigated and describing the proposed solutions , but without dwelling on theoretical details , which can be found in the original articles . </S>",
    "<S> i hope that this paper will be useful both to researchers who like to learn more on the research carried out in sae and to practitioners who might be interested in the application of the new methods .    . </S>"
  ]
}