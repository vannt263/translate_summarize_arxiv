{
  "article_text": [
    "one of the core problems in compressed sensing is to find the sparest solution to the underdetermined system @xmath4 , where @xmath5 is an underdetermined matrix ( i.e. @xmath6 ) , and @xmath7 a vector representing some measured or represented signals .",
    "the problem is popularly modeled into the following @xmath1-minimization : @xmath8 where @xmath9 indicates the number of nonzero elements of @xmath10 , which is commonly called @xmath1-norm although it is not a real vector norm . since @xmath11 has more columns than rows , the underdetermined linear system @xmath4 admits an infinite number of solutions . in order to find the sparest one ,",
    "much excellent theoretical work has been devoted themselves to the @xmath1-minimization ( 1 ) .",
    "however , in paper [ 1 ] the author proves that @xmath1-minimization ( 1 ) is np - hard and is combinational and computationally intractable because of the discrete and discontinuous nature .",
    "therefore , alternative strategies to find sparest solution have been put forward ( see , for example [ 3][5][11][12][17][22][23 ] ) , among which is the model @xmath12-minimization : @xmath13 where @xmath14 , the @xmath12-norm of @xmath10 . the model ( 2 )",
    "is a convex problem and hence can be recast as linear problem solvable efficiently .",
    "however , in order to get the sparest solution to @xmath4 by @xmath12-minimization ( 1 ) we need certain conditions on @xmath11 and/or @xmath15 , for example , the novel restricted isometry property ( rip ) of @xmath11 .",
    "a matrix @xmath11 is said to have restricted isometry property of order s if there exists a constant @xmath16 such that @xmath17 for any s - sparse vector @xmath10 .",
    "a vector @xmath10 is said s - sparse if @xmath18 .    in papers [ 3 ] and [ 5 ] cands and tao",
    "show that any s - sparse vector can be recovered via @xmath12-minimization ( 2 ) as long as @xmath19 or @xmath20 . in paper",
    "[ 11 ] , the author improves the latter inequality and establishes exact recovery of s - sparse vector via @xmath12-minimization under the condition @xmath21 .",
    "however , it should be pointed out that the problem of calculating @xmath22 of a given matrix @xmath11 is still np - hard , work done by gribuval and nielsen [ 10 ] adopts a new strategy that lies between @xmath1-minimization ( 1 ) and @xmath12-minimization ( 2 ) . instead of @xmath12-minimization ( 3 ) , they consider the @xmath2-minimization with @xmath23 @xmath24 where @xmath25 . in the literature",
    ", @xmath26 is still called @xmath2-norm of @xmath10 though it is only a quass - norm when @xmath23 ( because in this case it violates the triangular inequality ) . from the definition of @xmath2-norm , it seems to be more natural to consider @xmath2-minimization ( 4 ) instead of @xmath1-minimization ( 1 ) than others , due to the fact that @xmath27 . in paper",
    "[ 4 ] , chartrand claims that an s - sparse vector can be recovered by @xmath2-minimization ( 4 ) for some @xmath28 small enough provided @xmath29 .",
    "recently , peng , yue and li [ 7 ] proves that there exists a constant @xmath30 , such that every a solution to @xmath2-minimization is also the solution to @xmath1-minimization whenever @xmath31 .",
    "this result builds a bridge between @xmath2-minimization ( 4 ) and @xmath1-minimization ( 1 ) , and what is important is that this conclusion is not limited by the structure of matrix .",
    "however , the authors do not give an analysis expression of @xmath32 so that the model of choice of @xmath2-minimization ( 4 ) is still difficult .",
    "that is , when does @xmath1-minimization ( 1 ) equal to @xmath2-minimization ( 4 ) is still open . in this paper",
    "we devote ourselves to giving a complete answer to this problem .",
    "our paper is organized as follows . in section 2",
    ", we will present some preliminaries of the null space property , which plays a core role in the proof of our main theorem . in section 3",
    "we focus on proving the main results of this paper . there",
    "we will present an analysis expression of @xmath32 such that the unique solution of @xmath1-minimization ( 1 ) is also the unique solution of @xmath2-minimization ( 4 ) . finally , we summarize our finding in last section .    for convenience , for @xmath33 , we define its support by @xmath34 and the cardinality of set s by @xmath35 .",
    "let @xmath36 be the null space of matrix a , denote by @xmath37 the minimum nonzero absolute - value eigenvalue of a and by @xmath38 the maximum one .",
    "we also use the subscript notation @xmath39 to denote such a vector that is equal to @xmath10 on the index set s and zero everywhere else . and use the subscript notation @xmath40 to denote a submatrix whose columns are those of the columns of @xmath11 that are in the set index s.",
    "in order to investigate conditions under which both @xmath1-minimization ( 1 ) and @xmath2-minimization ( 4 ) have the same unique solution , it is convenient for us to work with a sufficient and necessary condition of the solution to @xmath1-minimization ( 1 ) and @xmath2-minimization ( 4 ) . therefore , in this preliminary section , we focus on introducing such an condition , namely the null space property ( nsp ) .",
    "( nsp)[10].given a matrix @xmath5 with @xmath41 , @xmath42 is the unique solution to @xmath2-minimization @xmath43 if and only if : @xmath44 for any @xmath45 , and set @xmath46 with @xmath47 , where @xmath48    nsp provides a sufficient and necessary condition to judge a vector whether can be recovered by @xmath1-minimization ( 1 ) or @xmath2-minimization ( 4 ) , which is the most important advantage of nsp .",
    "however , nsp is difficult to be checked for a given matrix . in order to reach our goal , we recall the concept null space constant ( nsc ) , which is closely related to nsp and will offer tremendous help in illustrating the performance of @xmath1-minimization ( 1 ) and @xmath2-minimization ( 4 ) .",
    "( nsc)[9].let @xmath49 and @xmath50 , the null space constant @xmath51 is the smallest number such that : @xmath52 for any index set @xmath53 with @xmath54 and any @xmath45    combining nsc , nsp and papers [ 2 ] [ 21 ] , we can derive the following corollaries :    for any @xmath55 $ ] , @xmath56 is a sufficient and necessary condition to recovery any t - sparse vector by @xmath2-minimization    if the condition ( 5 ) is satisfied for some @xmath57 , then it is also satisfied for all the @xmath58 [ 2],[21 ] .    in the case",
    "when @xmath59 , if @xmath42 is the unique solution to the @xmath1-minimization ( 1 ) , and @xmath60 , then we have the following results :    \\(a ) @xmath61 , for any @xmath45 .",
    "\\(b ) @xmath62 , where @xmath63 represents the integer part of @xmath64    in paper [ 9 ] , the author proves that @xmath51 is a continuous function in @xmath65 $ ] when @xmath66 , where @xmath67 is the smallest number of columns from @xmath11 that are linearly dependent .",
    "therefore , if @xmath68 for some fixed @xmath11 and @xmath69 , then there exists a constant @xmath70 such that @xmath56 for any @xmath71 $ ] , i.e. both @xmath1-minimization ( 1 ) and @xmath2-minimization ( 4 ) have the same unique solution .",
    "this a corollary of the main theorem in [ 7 ] .",
    "@xmath72 $ ] there exists a constant @xmath30 such that , when @xmath73 , every solution to @xmath2-minimization ( 4 ) also solves @xmath1-minimization ( 1 ) .    obviously , this theorem qualitatively proves the effectiveness of solving the original @xmath1-minimization ( 1 ) problem through @xmath2-minimization ( 4 ) .",
    "moreover , the theorem will become more practical , if @xmath70 is computable .",
    "since the main aim of this paper is to give a computable method for the estimation of @xmath32 , we can conclude the following lemma .",
    "let @xmath5 be an underdetermined matrix , if @xmath1-minimization ( 1 ) has the unique solution @xmath42 with @xmath60 , then there exists a constant @xmath74 with @xmath75 such that @xmath76 , for any @xmath77 with @xmath78    the proof is divided into two steps .",
    "step 1 : to prove the existence of @xmath79    in order to prove this result we just need to prove that the set @xmath80 has a nonzero infimum .",
    "if we assume that inf s=0 , i.e. for any @xmath81 , there exists a vector @xmath82 such that @xmath83 . without of generality ,",
    "we can assume @xmath84 , furthermore , the bounded sequence @xmath85 has a subsequence @xmath86 which is convergent , i.e. @xmath87 and it is obvious that @xmath88 because that the function @xmath89 is a continuous one .",
    "let @xmath90 , since @xmath87 , it is easy to get that : for any @xmath91 , there exists @xmath92 such that @xmath93 when @xmath94 .",
    "let @xmath95 , when @xmath96 , for any @xmath91 , such that @xmath93 .",
    "therefore , we can get that @xmath97 when @xmath96 , such that @xmath98 .",
    "however , according to corollary 3 , it is easy to get that @xmath61 for any @xmath99 .",
    "and we notice that @xmath100 , so the result @xmath98 contradicts corollary 3 .",
    "therefore , there exists a constant @xmath74 such that @xmath76 , for any @xmath77 with @xmath78 .",
    "step 2 : to prove @xmath75    according to the proof above , there exists a vector @xmath101 such that @xmath102 .",
    "let @xmath103 , it is easy to get that @xmath104 , for any @xmath105 .",
    "it is obvious that @xmath106 is a symmetric matrix , according to the rayleigh - ritz theorem , the smallest eigenvalue of @xmath107 is @xmath108 and we can choose an eigenvector @xmath109 of eigenvalue @xmath108 .",
    "if @xmath110 , then we can consider such a vector @xmath111 with @xmath112 when @xmath113 and zero everywhere else .",
    "therefore , it is easy to get that @xmath114 which contradicts the definition of @xmath115    therefore , the proof is completed .",
    "let @xmath5 be an underdetermined matrix , if @xmath1-minimization ( 1 ) has the unique solution @xmath42 with @xmath60 , there exist constants @xmath116 such that @xmath117 for any @xmath118 .",
    "in this section we focus on the proposed problem in the last section . by introducing a new technique and utilizing preparations provided in section 2",
    ", we will present an analysis expression of @xmath0 such that both @xmath1-minimization(1 ) and @xmath2-minimization ( 4 ) have the same unique solution for @xmath3 . to this end , we first begin with two lemmas .    for any @xmath33 and @xmath119 , then we have that @xmath120    for any @xmath33 , without loss of generality , we can rearrange the elements of @xmath10 such that @xmath121 @xmath122 . according to hlder inequality , we can show that @xmath123 that is @xmath120 .",
    "given a matrix @xmath5 .",
    "if @xmath124 holds for any @xmath118 .",
    "then we have that @xmath125 for any @xmath126 and @xmath127,with @xmath128 and @xmath129    according to the assumption on matrix @xmath11 , it is easy to get that @xmath130 since @xmath129 , we have that @xmath131 from which we get that @xmath132    with the above lemmas in hand , we now can prove our main theorems    given a matrix @xmath5 with @xmath41 .",
    "if @xmath42 is the unique solution to @xmath1-minimization ( 1 ) , for an arbitrary index set @xmath133 with @xmath134 and for any @xmath45 , we have the following inequality : @xmath135 where @xmath136 $ ] + and @xmath137    according to theorem 1 and corollary 3 , it is easy to get that @xmath61 for any @xmath45 .    according to lemma 1 and corollary 4 , we can find constants @xmath79 and @xmath138 such that @xmath139 for any @xmath78 .",
    "now we consider a vector @xmath45 , and consider an arbitrary index set @xmath140 .",
    "we partition the complement of @xmath141    @xmath142=\\{indices of the largest @xmath143 absolute - values component of @xmath10 except @xmath141 }    @xmath144=\\{indices of the largest t absolute - values component of @xmath10 except @xmath141 and @xmath142 }    @xmath145=\\{indices of the largest t absolute - values component of @xmath10 except @xmath141 , @xmath142  and @xmath144 }    ",
    "@xmath146=\\{indices of the rest component of @xmath10 }    obviously , the set @xmath147 has @xmath69 elements except @xmath146 possibly .",
    "it is obvious that every element in the set @xmath142 is nonzero , so we consider that    @xmath148=\\{indices of the @xmath69 largest absolute - values components of @xmath142 }    @xmath149=\\{indices of the rest components of @xmath142 } .",
    "such that @xmath150    since @xmath151 for any @xmath78 .",
    "we have that @xmath152 since @xmath153 , we have that @xmath154 according to lemma 3 , we get that @xmath155 substituting the inequalities ( 9 ) into ( 8) , we have @xmath156 by the definition of @xmath157 and @xmath158 , it is easy to get that @xmath159 and @xmath160 , and hence , @xmath161 substituting the inequalities ( 11 ) and ( 10 ) into ( 7 ) @xmath162    for any @xmath163 and any element @xmath64 of @xmath164 , it is easy to get that @xmath165 , so that @xmath166 and @xmath167    substituting the inequalities into ( 12 ) , we can derive that @xmath168    we denote @xmath169 , and @xmath170 + then we can get such an inequality , @xmath171 and @xmath172 therefore , @xmath173    according to lemma 2 , we have that : @xmath174    substituting b into this inequality , we can obtain that @xmath175 we notice that the sets @xmath141 and @xmath176(@xmath177 ) all have @xmath69 elements and the set @xmath142 has @xmath143 elements , such that @xmath178 , we can get that @xmath179    according to lemma 1 , we have that @xmath180 . substituting the inequalities into ( 14 ) , we can obtain @xmath181    therefore , the proof is completed .",
    "theorem 3 presents a result which is very similar to the result in theorem 1 .",
    "however , it is worth to being pointed out that the constant @xmath182 plays a central role in theorem 3 . in fact , we can treat @xmath183 as an estimation to @xmath51 in definition 1 , where the former is calculateble and while the latter is np - hard , so @xmath182 may be considered as an improvement of @xmath51 . according to theorem 1 ,",
    "if we take @xmath69 as the @xmath1-norm of the unique solution to @xmath1-minimization , then we can get the main contribution as soon as the inequality @xmath184 is satisfied .",
    "assume @xmath5 is an underdetermined matrix of full rank , and denote @xmath185 .",
    "if @xmath1-minimization ( 1 ) has an unique solution , then @xmath2-minimization  ( 4 ) has the same unique solution as @xmath1-minimization ( 1 ) for any @xmath186 , where @xmath187 @xmath188 \\right]}\\ and\\ \\lambda=\\displaystyle\\frac{\\lambda_{max}(a^ta)}{\\lambda_{min^{+}}(a^ta)}\\ ] ]    according to theorem 3 and theorem 1 , we can get the equivalence between @xmath1-minimization ( 1 ) and @xmath2-minimization ( 4 ) as soon as @xmath184 is satisfied .",
    "however @xmath69 ca nt be calculated directly .",
    "we need to estimate @xmath69 and change the inequality @xmath184 into a computable one through inequality technique .    due to the integer - value virtue of @xmath9",
    ", we can have that@xmath189 and @xmath190 therefore,@xmath191 .        according to corollary 3 ,",
    "we have that @xmath192 .",
    "it is obvious that @xmath193 is a solution to the underdetermined system @xmath4 so that @xmath194 where @xmath195    furthermore , it is easy to prove that the function @xmath196 is an increasing function in @xmath69 when @xmath197 is fixed",
    ". meanwhile @xmath198 is a decreasing function in @xmath197 when @xmath69 is fixed    since @xmath199 , we can get @xmath200 if one of these two inequalities @xmath201 or @xmath202 is satisfied .",
    "furthermore , the inequality @xmath203 when @xmath10 fixed is very easy to solve , the range of such @xmath197 is @xmath204\\right]}\\ ] ]    hence , for any @xmath205 , we have that @xmath206 . therefore ,",
    "by theorem 1 , we know both @xmath1-minimization ( 1 ) and @xmath2-minimization ( 4 ) have the same unique solution .",
    "combining theorems 3 and 4 , we have reached the major goals of this paper .",
    "the most important result in these two theorems is the analysis expression of @xmath0 , with which , the specific range of @xmath197 can be calculated easily .",
    "we present two examples to demonstrate the validation of theorem 4 ,    we consider an underdetermined system @xmath4 , where    @xmath207 and @xmath208    it is obvious that the sparest solution is @xmath209^t$ ] , and the solution to the equation can be expressed as the following form : @xmath210^t+t[\\frac{18}{11}\\ \\frac{2}{11}\\ -\\frac{30}{11}\\ 1]^t\\ ] ] therefore , the @xmath2-norm of @xmath10 can be expressed @xmath211    furthermore , @xmath212,@xmath213 and @xmath214 .",
    "it is easy to get that @xmath215^t$ ] , hence @xmath216 and @xmath217 , so @xmath218 .",
    "as shown in the fig1 , we can get the solution to @xmath2-minimization in different cases when @xmath219 for @xmath220 , which are just the sparest solution @xmath209^t$ ]        we consider an underdetermined system @xmath4 , where    @xmath221 and @xmath222    it is easy to get the sparest solution @xmath223^t$ ] , and the solutions of the underdetermined system @xmath4 can be expressed as the following parameterized form @xmath224^t+s[\\frac{31}{6}\\",
    "-\\frac{3}{4}\\ -\\frac{7}{3}\\ 1\\ 0]^t+t[7.1\\ -2.25\\ -2.8\\ 0\\ 1]^t \\ where \\ s , t\\in r\\ ] ] therefore , @xmath225 furthermore , @xmath226 , @xmath227 and @xmath228 .",
    "it is easy to get that @xmath229^t$ ] , hence @xmath230 and @xmath231 , so @xmath232 .    from fig2",
    ", we can also find that the solution in different case when @xmath233 for @xmath234 .",
    "the result can be seen more clearly in fig3 .",
    "in this paper we have studied the equivalence between @xmath1-minimization ( 1 ) and @xmath2-minimization ( 4 ) . by using the null space property , a sufficient and necessary condition to recover a sparse vector via these two models , we present an analysis expression of @xmath0 in theorem 4 to make sure both @xmath1-minimization ( 1 ) and @xmath2-minimization ( 4 ) for @xmath235 have the same unique solution .    however ,",
    "in this paper , we only consider the situation when @xmath1-minimization ( 1 ) has the unique solution . and it should be pointed out that the condition of uniqueness is a very important one for our main contribution , especially for lemma 1 . under the condition of uniqueness , in lemma 1 , we can get a result which is similar to rip .",
    "unlike the nonhomogeneity of rip , the result is not conflict with the equivalence of all the linear systems @xmath236 . therefore , the authors guess that we can replace rip with the condition of uniqueness in more application .",
    "meanwhile , it also need to be pointed out that the main result in theorem 4 , the analysis expression of @xmath0 have a closer relationship with the matrix @xmath11 than the vector @xmath15 .",
    "let @xmath237 , we can find that , although @xmath238 is smaller than @xmath0 , @xmath238 have the same effect as @xmath0 does .",
    "the phenomenon may also be explained by the condition of uniqueness and the null space property , a property only depend on the structure of the matrix @xmath11 itself .",
    "therefore , what is such @xmath0 without the condition of uniqueness ? the authors think the answer to this problem will be an important improvement for the application of @xmath2-minimization . in conclusion",
    ", the authors hope that in publishing this paper , a brick will be thrown out and be replaced with a gem .",
    "this work was supported by the nsfc under contact no.11131006 and by the eu fp7 project eye2e ( 269118 ) and livcode ( 295151 ) , and in part by the national basic research program of china under contact no .",
    "2013cb329404    30 b.k.natarjan , `` sparse appoximate solution to linear systems '' siam.j.comput .",
    "vol.24.no,pp227-234,apri.1995 michael evan davies , remi gribonval `` resricted isometry constants where @xmath2 sparse recovery can fail for @xmath239 '' .",
    "ieee tran .",
    "theory , vol .",
    "55 , no . 5 , pp2203 - 2214 , may",
    "ej.cands,t.tao , `` the restricted isometry property and its implication for compressed sensing , c.r.acad.sci.ser.i 346(2008)589 - 592 r. chartand , ' ' exact reconstruction of sparse signals via nonconvex minimization `` ieee signal process .",
    "14(2007)707 - 710 .",
    "ej.cands,t.tao , near - opyimal signal recovey from random projections : universal encoding stragies , ieee tran . in form .",
    "theory 52 ( 12)(2006 ) 5406 - 5425 a. tillmann and m. presh , ' ' the computational complexity of restricted isometry property , the null space property , and ralated concepts in compressed sensing `` ieee tran inf .",
    "theory , vol .",
    "60 , no2 pp1248 - 1259 , feb .",
    "2014 jigen peng , shiguang yue , haiyang li . ' ' np / cmp equvalence : a phenomenon hidden among sparstiy models @xmath1 minimization and @xmath2 minimization for information processing `` ieee tran .",
    "theory , vol .",
    "7 , pp4028 - 4023 , july .",
    "2015 meng wang , weiyu xu , ao tang . ' ' on the performance of sparse recovery via @xmath2-minimization @xmath240 `` ieee tran .",
    "theory , vol .",
    "11 , pp7255 - 7278 , nov .",
    "2011 laming chen and yuantao gu . ' ' on the null space constant for @xmath2-minimization `` .",
    "ieee signal processing letters .",
    "10 , octorber 2015 r.gribonval and m. nislsen , ' ' sparest representations in union of bases `` ieee tran , inf .",
    "theory , vol .",
    "49 , no 12 , pp3320 - 3325 , dec . 2003 .",
    "s.foucart and m .- j . lai , ' ' sparseest solutions of underdetermined linear system via @xmath241-minimiztion for @xmath242 , `` appl",
    "harmnic anal , vol .",
    "26 , no 3 , pp .",
    "395 - 407 , 2009 .",
    "donoho and j. tanner , ' ' sparse nonnegative aolution of underdetermined linear equations by linear programming `` proc .",
    "sci usa , vol .",
    "27 , pp9446 - 9451 , 2005 d.l .",
    "donoho and m. elad , ' ' optimally sparse representation in general ( nonorthogonal ) dicitionaries via @xmath12 minimization `` , proc .",
    "acad , sci .",
    "usa , vol .",
    "102 , no5 , pp2197 - 2202,2003 c. herzet , c. soussen , j. idier , and r. gribonval , ' ' exact recovery conditions for sparse representations with partial support information `` ieee tran .",
    "theory , vol .",
    "11 , pp7509 - 7524 , nov .",
    "z.xu , x. chang , f. xu , and h. zhang , ' ' @xmath243 regularization : a threshold representation theory and a fast solver `` ieee trans .",
    "neural netw .",
    "syst , vol .",
    "7 , pp1013 - 1027 , jul . 2012",
    ". k.g.murty , ' ' a problem in enumerating extreme points , and an efficient algorithm for one class of polytopes `` optim .",
    "lett , vol .",
    "3 , no . 2,pp221 - 237 , 2009 r.g .",
    "baraniuk , v. cevher , m.f , duarte , c.hegde , model - based compressive sensing , ieee tran .",
    "theory , 56(4)(2010)1982 - 2001 m.j.lai , y.y .",
    "xu , w.t yin , ' ' improved iteratively reweighted least squares for unconstrained smoothed @xmath2 minimization , siam j. numer , anal .",
    "5(2)(2013)927 - 957 `` r. chartrand , v. staneva . ' ' restricted isometry properties and nonconvex compressive sensing `` inverse probl .",
    "24(3)(2008)1 - 14 d.l .",
    "donoho and x. huo , ' ' uncertainty priciples and ideal atomic decomposition `` , ieee tran .",
    "theory , vol .",
    "47 , no . 7 , pp2845 - 2862 , nov .",
    "2001 r.gribonval and m. nislsen , ' ' highly sparse representations from dictionaries are unique and independent of the sparseness measure , `` appl , comput .",
    "harmonic anal , vol .",
    "22,no . 3 , pp335 - 355,2007 j.a",
    ". tropp , ' ' greed is good : algorithmic results for sparse approximation , `` ieee tran .",
    "inform . theory 50(2004 ) 2231 - 2242 .",
    "a. petukhov , ' ' fast implementation of orthogonal greedy althorithm for tight wavelet frames , \" signal process .",
    "86(2006 ) 471 - 479"
  ],
  "abstract_text": [
    "<S> in this paper , we present an analysis expression of @xmath0 such that the unique solution to @xmath1-minimization also can be the unique solution to @xmath2-minimization for any @xmath3 . </S>",
    "<S> furthermore , the main contribution of this paper is nt only the analysis expressed of such @xmath0 but also its proof </S>",
    "<S> . finally , we display the results of two examples to confirm the validity of our conclusions    * keywords : * sparse recovery , null space constant , null space property , @xmath1-minimization , @xmath2-minimization , </S>"
  ]
}