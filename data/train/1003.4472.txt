{
  "article_text": [
    "in this paper we study the efficient numerical solution of an inverse scattering problem for time harmonic electromagnetic waves .",
    "the forward problem is essentially described by the time - harmonic maxwell equations @xmath0 for the electric field @xmath1 . our aim is to reconstruct a local inhomogeneity of the refractive index @xmath2 of a medium , given far field measurements for many incident waves .",
    "a more detailed discussion of the forward problem is given in ",
    "[ sec : forward ] .",
    "after discretization the inverse problem is described by a nonlinear , ill - conditioned system of equations @xmath3 with a function @xmath4 , which is infinitely smooth on the subset @xmath5 where it is defined .",
    "since the system is highly ill - conditioned , we have consider the effects of data noise .",
    "here we assume an additive noise model for the observe data @xmath6 : @xmath7 the noise vector @xmath8 is assumed to be a vector of random variables with known finite covariance matrix and a known bound on the expectation @xmath9 .    in this article",
    "we contribute to preconditioning techniques for the _ levenberg - marquardt algorithm _ and the _ iteratively regularized gauss - newton method _ ( irgnm ) .",
    "these methods are obtained by applying tikhonov regularization with some an initial guess @xmath10 and a regularization parameter @xmath11 to the newton equations @xmath12 . here",
    "@xmath13\\in \\rset^{{n}\\times { m}}$ ] denotes the jacobian of @xmath14 at @xmath15 .",
    "this leads to normal equations of the form @xmath16 with @xmath17 the choice  @xmath18 corresponds to the levenberg - marquardt algorithm and the choice @xmath19 to the irgnm . as opposed to the levenberg - marquardt algorithm as used in optimization we simply choose the regularization parameter  @xmath11 of the form @xmath20 convergence and convergence rates of the irgnm in an infinite dimensional setting have been studied first in @xcite . for further references and results including a convergence analysis of levenberg - marquardt algorithm we refer to the monographs @xcite .    as an alternative ,",
    "hanke @xcite suggested to apply the conjugate gradient ( cg ) method the normal equation @xmath21 and use the regularizing properties of the cg method applied to the normal equation with early stopping .",
    "this is referred to as newton - cg method . regularized newton methods with inner iterative regularization methods have also been studied by rieder @xcite .",
    "finally , applying a gradient method to the functional @xmath22 leads to the nonlinear landweber iteration @xmath23 first studied in @xcite . for an overview on iterative regularization methods for nonlinear ill - posed problems we refer to @xcite .    a continuation method for inverse electromagnetic medium scattering problems with multi - frequency data has been studied in @xcite . for an overview on level set methods for inverse scattering problems we refer to @xcite .",
    "for the inverse electromagnetic scattering problem studied in this paper the evaluation of @xmath24 and one row of its jacobian @xmath25 is very expensive and involves the solution of a three - dimensional forward scattering problem for many incident waves .",
    "therefore , a computation of the full jacobian is not reasonable , and regularization method for the inverse problem should only access @xmath25 via matrix - vector multiplications @xmath26 and @xmath27 .",
    "hence , from the methods discussed above only landweber iteration and newton - cg can be implemented directly . however , the convergence of landweber iteration is known to be very slow , which is confirmed by our numerical experiments reported in  [ sec : num ] . preconditioning",
    "techniques for landweber iteration have been studied in @xcite , but it is not clear how to apply these techniques to inverse electromagnetic medium scattering problems since the operator does not act in hilbert scales . to use the irgnm and levenberg - marquardt , we have to solve the system of equations  ( [ 260201 ] ) by iterative methods .",
    "it turns out that standard iterative solvers need many iterations since the systems becomes very ill - conditioned as @xmath28 .    for the efficient solution of these linear systems",
    "we apply the cg - method and exploit its close connection to lanczos method .",
    "the latter method is used to approximately compute eigenpairs of  @xmath29 to construct a spectral preconditioner for the cg - method . since the eigenvalues  @xmath30 of  @xmath31 decay at an exponential rate",
    ", it turns out that the approximations determined by lanczos method are well suited to construct an efficient spectral preconditioner .",
    "spectral preconditioning is reviewed in ",
    "[ sec : spectralprec ] . in ",
    "[ sec : itlanczos ] we describe how the original method proposed in @xcite can be improved by the construction of updates of the preconditioner during the newton iteration . for a convergence analysis of the irgnm in combination with the discrepancy principle discussed below",
    "we refer to  @xcite .",
    "it should be mentioned that all known convergence results need some condition restricting the degree of nonlinearity of  @xmath14 , and unfortunately none of these conditions has been verified for the electromagnetic medium scattering problem",
    ".    an essential element of any iterative regularization method for an ill - posed problem is a data - driven choice of the stopping index .",
    "the most common rule is morozov s discrepancy principle  @xcite , which consists in stopping the newton iteration at the first index  @xmath32 satisfying @xmath33 the discrepancy principle is also frequently used for random noise setting @xmath34 .",
    "however , it is easy to see that this can not give good results in the limit @xmath35 ( see e.g.  @xcite ) , and this is confirmed in our numerical experiments . in  [ sec : lepskij ] we show how a lepski - type stopping rule can be implemented efficiently in combination with the regularization method studied in  [ sec : itlanczos ] .    finally , in ",
    "[ sec : num ] we report on some numerical experiments to demonstrate the efficiency of the methods proposed in this paper .",
    "the propagation of time - harmonic electromagnetic waves in an inhomogeneous , non - magnetic , isotropic medium without free charges is described by the time - harmonic maxwell equations    [ eq : forward ] @xmath36 ( see @xcite ) . here",
    "@xmath37 describes the space - dependent part of a time - harmonic electromagnetic field of the form @xmath38 with angular frequency @xmath39 .",
    "moreover , @xmath40 denotes the wave number , @xmath41 the electric permittivity of vacuum , and @xmath42 the magnetic permeability of vacuum .",
    "the refractive index of the medium given by @xmath43 is assumed to be @xmath44-smooth , real and positive in this paper .",
    "moreover , we assume that @xmath45 . now , given a plane incident wave @xmath46 with direction @xmath47 and polarization @xmath48 such that @xmath49 , the forward scattering problem consists in finding a total field @xmath50 satisfying such that the scattered field @xmath51 satisfies the silver - mller radiation condition @xmath52    uniformly for all directions @xmath53 .",
    "the latter condition implies that @xmath54 has the asymptotic behavior @xmath55 with a function @xmath56 called the _ far field pattern _ of @xmath54 .",
    "it satisfies @xmath57 .",
    "the inverse problem studied in this paper is to reconstruct @xmath58 given measurements of @xmath59 for all @xmath60 and @xmath48 such that @xmath61 .",
    "the forward scattering problem has an equivalent formulation in terms of the electromagnetic lippmann - schwinger equation @xmath62 for @xmath63 with the scalar fundamental solution @xmath64 .",
    "for the numerical solution of the forward scattering problems we use a fast solver of , which converges super - linearly for smooth refractive indices ( see @xcite ) .",
    "we typically use between @xmath65 and @xmath66 degrees of freedom to represent @xmath67 for each @xmath68 .",
    "the unknown perturbation @xmath58 of the refractive index is represented by a set of coefficients @xmath69 with @xmath70 using tensor products of splines in radial direction and spherical harmonics in angular direction ( see @xcite ) . moreover , we use 25 incident waves with random incident directions @xmath71 and random polarizations @xmath72 where the directions @xmath71 were drawn from the uniform distribution on @xmath73 .",
    "the exact data are given by complex numbers @xmath74 for @xmath75 and @xmath76 where the @xmath77 and @xmath78 were generated in the same way as the @xmath71 and @xmath72 .",
    "this yields a real data vector @xmath79 of size @xmath80 .",
    "let us start by recalling the preconditioned conjugate gradient ( cg ) method and its connection to lanczos method ( see e.g.  @xcite ) .",
    "we consider a preconditioned equation @xmath81 where  @xmath82 is an arbitrary matrix of rank @xmath83 , and @xmath84 is a symmetric and positive definite preconditioning matrix .",
    "although the matrix @xmath85 is not symmetric in general , the induced linear mapping in @xmath86 is symmetric and positive definite with respect to the scalar product  @xmath87 since @xmath88 therefore , the cg - method applied to  ( [ 040109 ] ) can be coded as follows :    [ 211107](preconditioned conjugate gradient method )    * @xmath89 * while @xmath90 * * @xmath91 * * @xmath92 * * @xmath93 * * @xmath94 * * @xmath95 * * @xmath96 * * @xmath97 * * @xmath98 * * @xmath99 .",
    "the stopping criterion  @xmath90 ensures a relative accuracy of @xmath100 of the approximate solution if @xmath101 ( i.e.  @xmath102 if @xmath103 , see @xcite ) .    quantities arising in algorithm  [ 211107 ] can be used to approximate the largest eigenvalues and corresponding eigenvectors of  @xmath85 as follows : multiplying  @xmath104 from the left by  @xmath105 and using the definitions and identities @xmath106 yields @xmath107 the identity  @xmath108 multiplied from the left by  @xmath109 together with @xmath110 yields @xmath111 putting  ( [ 2009 - 08 - 25_01 ] ) and  ( [ 2009 - 08 - 25_02 ] ) together we have for all  @xmath112 @xmath113 these formulas can be rewritten as @xmath114 where  @xmath115 and @xmath116 if we denote by  @xmath117 and  @xmath118 the eigenvalues with corresponding eigenvectors of the symmetric and positive definite matrix  @xmath119 , implies @xmath120 hence , in the case that  @xmath121 vanishes  @xmath122 are exact eigenvalues of  @xmath85 with corresponding eigenvectors  @xmath123 . in the typical case",
    "@xmath124 the vectors  @xmath125 usually converge rapidly to the eigenvectors corresponding to the outliers in the spectrum of  @xmath85 ( cf .",
    "@xcite and the references on the kaniel - paige theory therein ) and lanczos method can be interpreted as a particular case of the rayleigh - ritz method .",
    "this connection can be used to interpret the so - called _ ritz values _",
    "@xmath126 and the _ ritz vectors _  @xmath123 as approximations to some eigenpairs of  @xmath127 .",
    "if @xmath128 is an eigendecomposition of the matrix @xmath119 with @xmath129 , i.e. @xmath130 is orthogonal and @xmath131 , one can prove the equality  ( see  @xcite ) @xmath132 where  @xmath133 denotes the bottom entry of  @xmath134 .",
    "this identity can be used to judge the accuracy of the ritz pairs and to decide which of them to use in the spectral preconditioner .",
    "assume now that @xmath135 is of the special form @xmath136 with @xmath137 .",
    "let @xmath138 be orthonormal eigenvectors of @xmath139 , and let @xmath140 be the corresponding eigenvalues .",
    "given eigenpairs @xmath141 for @xmath142 in some non - empty subset @xmath143 , we define a spectral preconditioner for @xmath144 by @xmath145 its properties are summarized in the following proposition :    [ prop : precond ] assume that @xmath146 .",
    "then    * @xmath147 is symmetric and positive definite , and its inverse is given by @xmath148 * @xmath149 .",
    "* the spectrum of the preconditioned matrix is given by @xmath150 and the eigenvalue @xmath151 has multiplicity @xmath152 .",
    "* if @xmath153 is an eigenvalue of @xmath154 with corresponding eigenvector @xmath155 , then @xmath156 is an eigenpair of @xmath157 .",
    "@xmath147 is obviously symmetric , and it is positive definite since all its eigenvalues are @xmath158 .",
    "the formula for the inverse follows from a straightforward computation",
    ".    let @xmath159 . identifying matrices with their induced linear mappings",
    ", we have @xmath160 and @xmath161 , and @xmath162 and @xmath163 are invariant under all the involved linear mappings .",
    "therefore , @xmath164 since @xmath165 for all @xmath166 , assertion b ) follows .",
    "c ) is obtained from b ) by inserting the eigenvectors  @xmath167 into the formula .",
    "if @xmath168 is an eigenpair of @xmath154 and @xmath153 , it follows that @xmath169 .",
    "therefore , @xmath170 .",
    "this implies assertion d ) .",
    "we comment on the assumption @xmath146 in proposition [ prop : precond ] . for the acoustic medium scattering problem injectivity of the continuous frchet derivative @xmath171",
    "$ ] has been shown in ( * ? ? ?",
    "for the electromagnetic medium scattering problem uniqueness proofs for the nonlinear inverse problem ( see @xcite ) can be modified analogously to show injectivity of @xmath171 $ ] .",
    "it is easy to see that this implies injectivity of @xmath172 if @xmath172 is a sufficiently accurate discrete approximation of @xmath171 $ ] on a finite dimensional subspace .",
    "spectral preconditioning in newton methods is particularly useful for exponentially ill - posed problems such as the electromagnetic inverse medium scattering problem .",
    "typically , lanczos method approximates outliers in the spectrum well , whereas eigenvalues in the bulk of the spectrum are harder to approximate .",
    "frequently the more isolated an eigenvalue is , the better the approximation ( see  @xcite and  ( * ? ? ?",
    "* chapter 7 ) ) . for exponentially ill - conditioned problems",
    "the spectrum of  @xmath173 consists of a small number of isolated eigenvalues and a large number of eigenvalues clustering at  @xmath11 .",
    "if all the large isolated eigenvalues are found and computed accurately , spectral preconditioning reduces the condition number significantly .",
    "updating the preconditioner may be necessary for the following reasons :    * if the matrix @xmath173 has multiple isolated eigenvalues , the lanczos method approximates at most one ritz pair corresponding to this multiple eigenvalue . * during newton s method the regularization parameter  @xmath11 tends to zero .",
    "hence , if we keep the number of known eigenpairs for the construction of the preconditioner  @xmath174 fixed , the number of cg - steps will increase rapidly during our frozen newton method ( see  @xcite ) .    in the preconditioned newton iteration we keep the jacobian @xmath175 frozen for several newton steps and replace eq .",
    "by    @xmath176    where @xmath177    moreover , given some eigenpairs @xmath178 of @xmath179 with orthonormal eigenvectors @xmath180",
    ", the spectral preconditioner is defined by @xmath181    a preconditioned semi - frozen newton method with updates of the preconditioner can be coded as follows :    [ alg : irgnm_prec_update ] input : initial guess @xmath182 , data @xmath183 , @xmath184 and/or @xmath185 _ ( see ) _",
    "* @xmath186 ; @xmath187 * repeat * * evaluate @xmath188 and define @xmath189 by ; * * if @xmath190 * * * @xmath191 ; * * * solve @xmath192 by cg - method ; * * * compute via lanczos method orthonormal ritz pairs @xmath193 of @xmath194 ; * * * select subset @xmath195 _ ( see ) _ and set @xmath196 for @xmath197 _ ( see prop . [",
    "prop : precond ] ) _ ; * * else * * * define @xmath174 by ; * * * if mustupdate ( ) _ ( see remark [ it : mustupdate ] below ! ) _ * * * * solve @xmath198 by cg - method ; * * * * @xmath199 ; * * * * compute ritz pairs @xmath200 of @xmath201 using lanczos method ; * * * * select subset @xmath202 _ ( see remark [ it : lanczos ] ) _ and set @xmath196 for @xmath203 ; * * * * set @xmath204 and reorthogonalize @xmath205 ; * * * else * * * * solve @xmath206 by cg - method ; * * * end * * end * * @xmath207 ; @xmath208 ; * until stop ( ) _ ( see  [ sec : lepskij ] ) _ * select stopping index @xmath32 _ ( see  [ sec : lepskij ] ) _ and return @xmath209 ;    we add some remarks on heuristics and implementation details for algorithm [ alg : irgnm_prec_update ] :    1 .   usually round - off",
    "errors cause loss of orthogonality in the residual vectors  @xmath210 computed in algorithm  [ 211107 ] .",
    "this loss of orthogonality is closely related to the convergence of the ritz vectors ( see  @xcite ) . to sustain stability , algorithm  [ 211107 ]",
    "was amended by a complete reorthogonalization scheme based on householder transformations ( see @xcite ) .",
    "the necessity of reorthogonalization is also our reason for preconditioning with @xmath211 from both sides instead of @xmath212 from the left when updating the preconditioner . in the latter case",
    ", reorthogonalization would have to be performed with respect to the inner product @xmath213 , which is more complicated .",
    "note that @xmath214 3 .",
    "spectrally preconditioned linear systems react very sensitively to errors in the eigenelements ( see  @xcite ) .",
    "hence , to ensure efficiency of the preconditioner it is necessary that the approximations of the ritz pairs used in the construction of the preconditioner be of high accuracy .",
    "this is achieved by choosing @xmath215 in algorithm  [ 211107 ] when updating or recomputing the preconditioner , whereas @xmath216 is sufficient otherwise .",
    "numerical experience shows that computation time invested into improved accuracy of the ritz pairs pays off in the following newton steps .",
    "[ it : mustupdate ] mustupdate ( ) : we update the preconditioner if the last update or recomputation is at least 4 newton steps ago and the number of inner iterations in the previous newton step is @xmath217 .",
    "we found it useful not to perform a complete recomputation of the current preconditioner if it works well .",
    "therefore , we amend the condition @xmath190 by the additional requirement that the number of inner iterations in the previous step be not too small , say @xmath218 .",
    "the condition @xmath190 is a generalization of the rule to recompute the preconditioner whenever @xmath219 is a square number , which was proposed in the original paper @xcite . under certain conditions",
    "it was shown in @xcite to be optimal among all rules where @xmath220 is replaced by a function @xmath221 with @xmath222 $ ] .",
    "[ it : lanczos ] for updating the preconditioner we only select ritz values of @xmath201 which are sufficiently well separated from the cluster at @xmath151 , say @xmath223 .",
    "first , these eigenvalues are usually computed more accurately by lanczos method , and second , they are more relevant for preconditioning . 7 .   in the initial phase when the updates @xmath224 are large , keeping the jacobian frozen is not efficient",
    ". therefore , we use other methods in this phase , e.g.  newton - cg . in some cases globalization strategies will be necessary in this phase , although this was not the case in the examples reported below .",
    "lepski - type stopping rules for regularized newton methods have been studied in @xcite .",
    "we refer to the original paper @xcite on regression problems and to @xcite for a considerable simplification of the idea and its application to linear inverse problems .",
    "as opposed to the discrepancy principle , lepski - type stopping rules yield order optimal rates of convergence for all smoothness classes up to the qualification of the underlying linear regularization method ( in case of random noise typically only up to a logarithmic factor ) .    a crucial element of lepski s method are estimates of the propagated data noise error , and the performance depends essentially on the sharpness of these estimates .",
    "let @xmath225 .",
    "if @xmath226 is a deterministic noise vector , an estimate of the propagated data noise error is given by @xmath227 and these estimates are sharp if @xmath228 is an eigenpair of @xmath229 .",
    "however , if @xmath230 is a random vector with @xmath231 , finite second moments with covariance matrix @xmath232 , the estimate is usually very pessimistic , and we have @xmath233 denoting the right hand side of or , respectively , by @xmath234 , the lepski stopping rule is defined by @xmath235 with a parameter @xmath236 and a maximal newton step number @xmath237 .",
    "we choose @xmath238 in our numerical experiments and @xmath239 with a reasonable upper bound on the size of propagated data noise in the optimal reconstruction .",
    "@xmath240 may be an a - priori known bound @xmath241 .",
    "however , it is advisable to choose a smaller value of @xmath240 to reduce the number of newton iterations .",
    "the final results @xmath242 do not depend critically on @xmath240 .",
    "the main computational challenge in the implementation of the stopping rule for random noise is the efficient and accurate computation of @xmath234 .",
    "one possibility is to generate @xmath243 independent copies @xmath244 of the noise vector and use the approximation @xmath245 .",
    "however , this involves the iterative solution of @xmath246 instead of @xmath151 least squares system and leads to a tremendous increase of the computational cost .    with the methods described in the previous sections we can construct approximations @xmath247 of @xmath248 , which allow cheap matrix - vector multiplications not involving evaluations of the forward mapping @xmath249 .",
    "this yields the approximation @xmath250 here @xmath251 denote the approximated left singular vectors of @xmath252 , which can be computed directly by an appropriately modified lanczos method ( see e.g. @xcite ) . in the case of white noise ,",
    "i.e. @xmath253 , the expected value of the right hand side is given by the simple expression @xmath254 obviously , equality holds in if @xmath255 is a complete set of eigenvalues of @xmath256 ( with multiplicities ) . under certain assumptions",
    "it has been shown in @xcite in an infinite dimensional setting that the left hand side can be bounded by a small constant times the right hand side uniformly in @xmath11 if @xmath255 contains all eigenvalues @xmath257 .",
    "our numerical results in section [ sec : num ] indicate that this approximation is sufficiently accurate .     an exact refractive index and its reconstruction by the irgnm with updated preconditioner at iteration 23 .",
    "the plots show the cube @xmath258 ^ 3 $ ] , the wave number is @xmath259.,scaledwidth=130.0% ]",
    "as a test example we use the refractive index shown in figure  [ fig : two_bumps ] . for further information on the forward problem and its numerical solution",
    "we refer to  [ sec : forward ] and @xcite .",
    "performance of the preconditioned newton method applied to the example in figure [ fig : two_bumps ] .",
    "the left panels show the continuous @xmath260-error of the reconstructed refractive indices and the norm of the residuals @xmath261 over the newton step @xmath262 .",
    "the upper right panel shows the computed singular values used for preconditioning ( solid horizontal lines ) .",
    "after step 11 the method changed from newton - cg to irgnm . at steps @xmath263 and @xmath264 the preconditioner was completely recomputed for the derivative at a new iterate .",
    "this is indicated by solid vertical lines .",
    "updates of the preconditioner , indicated by dotted vertical lines , were performed at steps 16 and 24 .",
    "the dots on the diagonal line indicate the values of the regularization parameter @xmath265 .",
    "some sufficiently accurate singular values computed during the newton - cg phase are shown for their own interest although they were not used in the computation .",
    "the right lower panel shows the number of inner cgne iterations over the newton step @xmath262 ]    figure [ fig : two_bumps_stefan1 ] illustrates the performance of the irgnm with updated preconditioners . in the update steps for the preconditioner at @xmath267 and @xmath268",
    "the new singular values mainly fall into two categories : first , we have singular values which are not well separated from the cluster for the regularization parameter @xmath269 but are well separated for @xmath11 .",
    "these singular values are in or near the interval @xmath270 $ ] .",
    "the second category are multiple or nearly multiple singular values where only one element in the eigenspace is found in the application of lanczos method .",
    "the use of an update clearly reduces the number of inner cgne steps in the following newton iterations .",
    "moreover , in fig [ fig : comparison ] we compared the speed of convergence of the iterative regularization methods discussed in the introduction for exact data . here",
    "we measure `` speed '' both in terms of cpu - time and in terms of the number of evaluations of @xmath14 , @xmath271 $ ] or @xmath271'$ ] .",
    "landweber iteration is clearly the slowest method although some good progress is achieved in the first few steps .",
    "the newton - cg method performs very well up to some accuracy after which on it becomes slow , a behavior also observed in most other examples .",
    "we stopped the newton - cg iteration at an @xmath260-error of @xmath272 , which was achieved by the updated preconditioned irgnm 2.5 times earlier .",
    "we also include a comparison with the preconditioned irgnm without updating as suggested in @xcite .",
    "the updating improves the performance particularly at high accuracies .",
    "note that in the first newton steps where @xmath58 is still small , the iterative solution of the forward problem is faster than in later newton steps .",
    ".[tab : stoprules ] performance of stopping rules averaged over 15 noise samples for the problem in figure  [ fig : two_bumps ] .",
    "the numbers indicate means and standard deviations . [",
    "cols=\"<,^,^\",options=\"header \" , ]     finally , we tested the performance of the lepski - type stopping for randomly perturbed data .",
    "more precisely , we added independent gaussian variables to each data point . the  relative noise level ",
    "@xmath273 was about @xmath274 , but we stress that such a point - wise definition of the noise level does not make sense for random noise when considering the limit @xmath35 .",
    "we compare the discrepancy principle with @xmath275 to lepski s method with @xmath238 .",
    "moreover , we look at the optimal stopping index for each noise sample .",
    "as expected , the discrepancy principle stops the iteration too early .",
    "note in figure  [ fig : two_bumps_stefan1 ] that @xmath276 is at least an order of magnitude smaller than @xmath277 at the optimal @xmath278 .",
    "( in figure  [ fig : two_bumps_stefan1 ] we used exact data , but the behavior is similar for noisy data . ) the results in tab .",
    "[ tab : stoprules ] indicate that lepski s stopping rule is stable and yields considerably better results than the discrepancy principle .      the second author acknowledges financial support by dfg ( german research foundation ) in the research training group 1023  identification in mathematical models : synergy of stochastic and numerical methods  ."
  ],
  "abstract_text": [
    "<S> we study the construction and updating of spectral preconditioners for  regularized newton methods and their application to electromagnetic inverse medium scattering problems . </S>",
    "<S> moreover , we show how a lepski - type stopping rule can be implemented efficiently for these methods . in numerical examples , </S>",
    "<S> the proposed method compares favorably with other iterative regularization method in terms of work - precision diagrams for exact data . for data perturbed by random noise , </S>",
    "<S> the lepski - type stopping rule performs considerably better than the commonly used discrepancy principle .    </S>",
    "<S> [ def]theorem [ def]lemma [ def]corollary [ def]proposition [ def]example [ def]assumption [ def]remark [ def]notation [ def]algorithm </S>"
  ]
}