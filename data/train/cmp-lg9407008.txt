{
  "article_text": [
    "with the intensive exploration of contemporary theories on unification grammars@xcite and feature structures@xcite in the last decade , the old image of machine translation ( mt ) as a brutal form of natural language processing has given way to that of a process based on a uniform and reversible architecture@xcite .",
    "the developers of mt systems based on the constraint - based formalism found a serious problem in `` language mismatching , '' namely , the difference between semantic representations in the source and target languages .",
    "attempts to design a pure interlingual mt system were therefore abandoned , and the notion of `` semantic transfer''@xcite came into focus as a practical solution to the problem of handling the language mismatching .",
    "the constraint - based formalism@xcite seemed promising as a formal definition of transfer , but pure constraints are too rigid to be precisely imposed on target - language sentences .",
    "some researchers(e.g . , russell@xcite ) introduced the concept of _ defeasible reasoning _ in order to formalize what is missing from a pure constraint - based approach , and control mechanisms for such reasoning have also been proposed@xcite . with this additional mechanism",
    ", we can formulate the `` transfer '' process as a mapping from a set of constraints into another set of mandatory and defeasible constraints .",
    "this idea leads us further to the concept of `` information - based '' mt , which means that , with an appropriate representation scheme , a source sentence can be represented by a set of constraints that it implies and that , given a target sentence , the set @xmath0 of constraints can be divided into three disjoint subsets :    * the subset @xmath1 of constraints that is also implied by the target sentence * the subset @xmath2 of constraints that is not implied by , but is consistent with , the translated sentence * the subset @xmath3 of constraints that is violated by the target sentence    the target sentence may also imply another set @xmath4 of constraints , none of which is in @xmath0 .",
    "that is , the set @xmath5 of constraints implied by the target sentences is a union of @xmath1 and @xmath4 , while @xmath6 .",
    "when @xmath7 , we have a _ fully interlingual _",
    "translation of the source sentence .",
    "if @xmath8 , and @xmath9 , the target sentence is said to be _ under - generated _ , while it is said to be _ over - generated _ when @xmath10 , and @xmath11 . in either case , @xmath3 must be empty if a consistent translation is required .",
    "thus , the goal of machine translation is to find an optimal pair of source and target sentences that minimizes @xmath12 , and @xmath4 .",
    "intuitively , @xmath1 corresponds to essential information , and @xmath2 and @xmath4 can be viewed as language - dependent supportive information .",
    "@xmath3 might be the inconsistency between the assumptions of the source- and target - language speakers .    in this paper",
    ", we introduce _ tricolor dags _ to represent the above constraints , and discuss how tricolor dags are used for practical mt systems . in particular , we give a generation algorithm that incorporates the notion of semantic transfer by gradually approaching the optimal target sentence through the use of tricolor dags , when a fully interlingual translation fails .",
    "tricolor dags give a _",
    "graph - algorithmic _ interpretation of the constraints , and the distinctions between the types of constraint mentioned above allow us to adjust the margin between the current and optimal solution effectively .",
    "a _ tricolor dag _ ( tdag , for short ) is a rooted , directed , acyclic graph with a set of three colors ( red , yellow , and green ) for nodes and directed arcs .",
    "it is used to represent a feature structure of a source or target sentence .",
    "each node represents either an atomic value or a root of a dag , and each arc is labeled with a feature name . the only difference between the familiar usage of dags in unification grammars and that of tdags is that the color of a node or arc represents its degree of importance :    1 .",
    "red shows that a node ( arc ) is essential .",
    "yellow shows that a node ( arc ) may be ignored , but must not be violated .",
    "green shows that a node ( arc ) may be violated .    for practical reasons ,",
    "the above distinctions are interpreted as follows :    1 .",
    "red shows that a node ( arc ) is derived from lexicons and grammatical constraints .",
    "yellow shows that a node ( arc ) may be inferred from a source or a target sentence by using domain knowledge , common sense , and so on .",
    "green shows that a node ( arc ) is defeasibly inferred , specified as a default , or heuristically specified .    when all the nodes and arcs of tdags are red , tdags are basically the same as the feature structures of grammar - based translation@xcite .",
    "a tdag is _ well - formed _",
    "iff the following conditions are satisfied :    1 .",
    "the root is a red node .",
    "2 .   each red arc connects two red nodes .",
    "3 .   each red node is reachable from the root through the red arcs and red nodes .",
    "4 .   each yellow node is reachable from the root through the arcs and nodes that are red and/or yellow . 5 .",
    "each yellow arc connects red and/or yellow nodes .",
    "no two arcs start from the same node , and have the same feature name .",
    "conditions 1 to 3 require that all the red nodes and red arcs between them make a single , connected dag .",
    "condition 4 and 5 state that a defeasible constraint must not be used to derive an imposed constraint . in the rest of this paper , we will consider only well - formed tdags .",
    "furthermore , since only the semantic portions of tdags are used for machine translation , we will not discuss syntactic features .",
    "the _ subsumption _ relationship among the tdags is defined as the usual subsumption over dags , with the following extensions .    * a red node ( arc )",
    "subsumes only a red node ( arc ) . * a yellow node ( arc ) subsumes a red node ( arc ) and a yellow node ( arc ) . * a green node ( arc ) subsumes a node ( arc ) with any color .",
    "the _ unification _ of tdags is similarly defined .",
    "the colors of unified nodes and arcs are specified as follows :    * unification of a red node ( arc ) with another node ( arc ) makes a red node ( arc ) . *",
    "unification of a yellow node ( arc ) with a yellow or green node ( arc ) makes a yellow node ( arc ) . *",
    "unification of two green nodes ( arcs ) makes a green node ( arc ) .    since the green nodes and arcs represent defeasible constraints , unification of a green node ( either a root of a tdag or an atomic node ) with a red or yellow node always succeeds , and results in a red or yellow node .",
    "when two conflicting green nodes are to be unified , the result is _ indefinite _ , or a single non - atomic green node .    now , the problem is that a red node / arc in a _ source tdag _ ( the tdag for a source sentence ) may not always be a red node / arc in the _ target tdag _ ( the tdag for a target sentence ) .",
    "for example , the _ functional control _ of the verb `` wish '' in the english sentence    ....     john wished to walk ....    may produce the @xmath13 in figure  [ tdag ] , but the red arc corresponding to the _ agent _ of the * walk predicate may not be preserved in a target @xmath14 .",
    "this means that the target sentence alone can not convey the information that it is john who wished to walk , even if this information can be understood from the context .",
    "hence the red arc is relaxed into a yellow one , and any target tdag must have an agent of * walk that is consistent with * john . this relaxation will help the sentence generator in two ways .",
    "first , it can prevent generation failure ( or non - termination in the worst case ) .",
    "second , it retains important information for a choosing correct translation of the verb `` walk . ''",
    "another example is the problem of identifying _ number _ and _ determiner _ in japanese - to - english translation .",
    "this type of information is rarely available from a syntactic representation of a japanese noun phrase , and a set of heuristic rules@xcite is the only known basis for making a reasonable guess .",
    "even if such contextual processing could be integrated into a logical inference system , the obtained information should be defeasible , and hence should be represented by green nodes and arcs in the tdags .",
    "pronoun resolution can be similarly represented by using green nodes and arcs .",
    "it is worth looking at the source and target tdags in the opposite direction . from the japanese sentence ,",
    ".... john    ha    aruku koto   wo   nozonda john   + subj walk + nom   + obj wished ....    we get the source @xmath15 in figure  [ tdag ] , where functional control and number information are missing . with the help of contextual processing , we get the target @xmath16 , which can be used to generate the english sentence `` john wished to walk . ''",
    "as illustrated in the previous section , it is often the case that we have to solve mismatches between source and target tdags in order to obtain successful translations .",
    "syntactic / semantic transfer has been formulated by several researchers@xcite as a means of handling situations in which fully interlingual translation does not work .",
    "it is not enough , however , to capture only the equivalent relationship between source and target semantic representations : this is merely a mapping among red nodes and arcs in tdags .",
    "what is missing in the existing formulation is the provision of some margin between _ what is said _ and _ what is translated . _",
    "the semantic transfer in our framework is defined as a set of successive operations on tdags for creating a sequence of tdags @xmath17 , @xmath18 , @xmath19 , @xmath20 such that @xmath17 is a source tdag and @xmath20 is a target tdag that is a successful input to the sentence generator .",
    "a powerful contextual processing and a domain knowledge base can be used to infer additional facts and constraints , which correspond to the addition of yellow nodes and arcs .",
    "default inheritance , proposed by russell et al.@xcite , provides an efficient way of obtaining further information necessary for translation , which corresponds to the addition of green nodes and arcs .",
    "a set of well - known heuristic rules , which we will describe later in the `` implementation '' section , can also be used to add green nodes and arcs . to complete the model of semantic transfer , we have to introduce a `` painter . ''",
    "a _ painter _ maps a red node to either a yellow or a green node , a yellow node to a green node , and so on .",
    "it is used to loosen the constraints imposed by the tdags .",
    "every application of the painter monotonically loses some information in a tdag , and only a finite number of applications of the painter are possible before the tdag consists entirely of green nodes and arcs except for a red root node .",
    "note that the painter never removes a node or an arc from a tdag , it simply weakens the constraints imposed by the nodes and arcs .",
    "formally , semantic transfer is defined as a sequence of the following operations on tdags :    * addition of a yellow node ( and a yellow arc ) to a given tdag .",
    "the node must be connected to a node in the tdag by a yellow arc .",
    "* addition of a yellow arc to a given tdag .",
    "the arc must connect two red or yellow nodes in the tdag .",
    "* addition of a green node ( and a green arc ) to a given tdag .",
    "the node must be connected to a node in the tdag by the green arc .",
    "* addition of a green arc to a given tdag .",
    "the arc can connect two nodes of any color in the tdag .",
    "* replacement of a red node ( arc ) with a yellow one , as long as the well - formedness is preserved . *",
    "replacement of a yellow node ( arc ) with a green one , as long as the well - formedness is preserved .",
    "the first two operations define the logical implications ( possibly with common sense or domain knowledge ) of a given tdag .",
    "the next two operations define the defeasible ( or heuristic ) inference from a given tdag .",
    "the last two operations define the _",
    "painter_. the definition of the painter specifies that it can only gradually relax the constraints .",
    "that is , when a red or yellow node ( or arc ) x has other red or yellow nodes that are only connected through x , x can not be `` painted '' until each of the connected red and yellow nodes is painted yellow or green to maintain the reachability through x.    in the sentence analysis phase , the first four operations can be applied for obtaining a source tdag as a reasonable semantic interpretation of a sentence .",
    "the application of these operations can be controlled by `` weighted abduction''@xcite , default inheritance , and so on .",
    "these operations can also be applied at semantic transfer for augmenting the tdag with a common sense knowledge of the target language . on the other hand ,",
    "these operations are not applied to a tdag in the generation phase , as we will explain in the next section .",
    "this is because the lexicon and grammatical constraints are only applied to determine whether red nodes and arcs are exactly derived .",
    "if they are not exactly derived , we will end up with either over- or under - generation beyond the permissible margin .",
    "semantic transfer is applied to a source tdag as many times as necessary until a successful generation is made .",
    "recall the sample sentence in figure  [ tdag ] , where two _ painter _ calls were made to change two red arcs in @xmath13 into yellow ones in @xmath14 .",
    "these are examples of the first substitution operation shown above .",
    "an addition of a green node and a green arc , followed by an addition of a green arc , was applied to @xmath15 to obtain @xmath16 .",
    "these additions are examples of the third and fourth addition operations .",
    "before describing the generation algorithm , let us look at the representation of lexicons and grammars for machine translation .",
    "a _ lexical rule _ is represented by a set of equations , which introduce red nodes and arcs into a source tdag .",
    "a _ phrasal rule _ is similarly defined by a set of equations , which also introduce red nodes and arcs for describing a syntactic head and its complements .",
    "for example , if we use shieber s patr - ii@xcite notation , the lexical rule for `` wished '' can be represented as follows :    v = @xmath21 = wished + = v + = past + = np + = v + = infinitival + = * wish + =   + =   + =   +    the last four equations are semantic equations .",
    "its tdag representation is shown in figure  [ lex ] .",
    "it would be more practical to further assume that such a lexical rule is obtained from a type inference system , which makes use of a syntactic class hierarchy so that each lexical class can inherit general properties of its superclasses .",
    "similarly , semantic concepts such as * wish and * walk should be separately defined in an ontological hierarchy together with necessary domain knowledge ( e.g. , selectional constraints on case fillers and _ part - of _ relationships .",
    "see kbmt-89@xcite . ) a unification grammar is used for both analysis and generation .",
    "let us assume that we have two unification grammars for english and japanese . analyzing a sentence yields a source tdag with red nodes and arcs .",
    "semantic interpretation resolves possible ambiguity and the resulting tdag may include all kinds of nodes and arcs .",
    "for example , the sentence    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the boston office called _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    would give the source tdag in figure  [ hobbs ] . by utilizing the domain knowledge , the node labeled * person",
    "is introduced into the tdag as a real caller of the action * call , and two arcs representing _ person work - for * office _ and _ office in * boston _ are abductively inferred .",
    "our generation algorithm is based on wedekind s dag traversal algorithm@xcite for lfg . the algorithm runs with an input tdag by traversing the nodes and arcs that were derived from the lexicon and grammar rules .",
    "the termination conditions are as follows :    * every red node and arc in the tdag was derived . * no new red node ( arc )",
    "is to be introduced into the tdag if there is no corresponding node ( arc ) of any color in the tdag .",
    "that is , the generator can change the color of a node ( arc ) to red , but can not add a new node ( arc ) .",
    "* for each set of red paths ( i.e. , the sequence of red arcs ) that connects the same pair of nodes , the _ reentrancy _ was also derived .",
    "these conditions are identical to those of wedekind except that yellow ( or green ) nodes and arcs may or may not be derived .",
    "for example , the sentence `` the boston office called '' in figure  [ hobbs ] can be translated into japanese by the following sequence of semantic transfer and sentence generation .    1 .",
    "apply the painter to change the yellow of the _ definite _ node and the _ def _ arc to green .",
    "2 .   apply the painter to change the yellow of the _ singular _ node and the _ num _ arc to green .",
    "the resulting tdag is shown in figure  [ hobbs2 ] .",
    "3 .   run the sentence generator with an input feature structure , which has a root and an arc _ pred _ connecting to the given tdag .",
    "( see the node marked `` 1 '' in figure  [ hobbs2 ] . )",
    "the generator applies a phrasal rule , say s @xmath21 np vp , which derives the _ subj _ arc connecting to the subject np ( marked `` 2 '' ) , and the _ agent _ arc .",
    "the generator applies a phrasal rule , say np @xmath21 mod np , which derives the _ npmod _ arc to the modifier of the np ( marked `` 3 '' ) and the _ mod _ arc .",
    "lexical rules are applied and all the semantic nodes , * call , * office , and * boston are derived .",
    ".... ; ; run the generator with input f - structure 0 >   * j - gg - start called with ( ( pred \" yobu \" ) ( cat v ) ( vtype v-5dan - b )   ( subcat trans ) ( asp - type shunkan )   ( : mood ( ( pred \" @dec \" ) ) )   ( aux ( ( pred \" @aux \" ) ( : time ( ( pred \" @past \" ) ) )     ( : passive ( ( pred \" @minus \" ) ) ) ) )   ( subj ( ( cat n ) ( pred \" jimusho \" )     ( xadjunct ( ( xcop \" deno \" ) ( cat n )       ( pred \" boston \" ) ) ) ) ) )     ...     3 >   * j - gg - s called ; ; < start > -> ... - > < s >      4 >   * j - gg - xp called with ; ; subj - filler          ( ( case ( * or * \" ha \" \" ga \" ) ) ( cat n )           ( neg * undefined * ) ( pred \" jimusho \" )           ( xadjunct ( ( cop - ) ( cat n )              ( pred \" boston \" ) ) ) )       5 >   * j - gg - np called ; ; head np of subj            ...            10 <   * gg - n - root returns ; ; np mod             \" boston \" ; ; \" boston \"           9 >   * j - gg - n called ; ; head np            10 <   * gg - n - root returns             \" jimusho \"            ...         7 <   * 9 ( < ss >",
    "< np > ) returns ; ; mod+np                \" boston deno jimusho \"          ...       5 <   * 1 ( < np > < p > ) returns ; ; np+case - marker              \" boston deno jimusho ha \"      4 <   * j - gg - xp returns \" boston deno jimusho ha \"      4 >   * j - gg - s called with ; ; vp part       5 >   * j - gg - vp called ; ; stem +        6 >   * j - gg - v called ; ; function word chains        ( ( subj * undefined * )         ( advadjunct * undefined * )         ( ppadjunct * undefined * )         ( : mood * undefined * )         ( aux ( ( : time ( ( pred \" @past \" ) ) )          ( : passive           ( ( pred ( * or * * undefined * \" @minus \" ) ) ) )          ( pred \" @aux \" ) ) )         ( cat v ) ( type final ) ( asp - type shunkan )         ( vtype v-5dan - b ) ( subcat trans )         ( pred \" yobu \" ) )         7 >   * j - gg - rentai - past called ; ; past - form         ...            14 <   * gg - v - root returns \" yo \" ; ; stem        ...        6 <   * j - gg - v returns \" yobi mashita \"       5 <   * j - gg - vp returns \" yobi mashita \"      4 <   * j - gg - s returns \" yobi mashita \"     3 <   * j - gg - s returns         \" boston deno jimusho ha yobi mashita \"     ... 0 <   * j - gg - start returns      \" boston deno jimusho ha yobi mashita \" ....    the annotated sample run of the sentence generator is shown in figure  [ gen ] .",
    "the input tdag in the sample run is embedded in the input feature structure as a set of pred values , but the semantic arcs are not shown in the figure .",
    "the input feature structure has syntactic features that were specified in the lexical rules .",
    "the feature value * undefined * is used to show that the node has been traversed by the generator .    the basic property of the generation algorithm is as follows :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ let @xmath22 be a given tdag , @xmath23 be the connected subgraph including all the red nodes and arcs in @xmath22 , and @xmath24 be the connected subgraph of @xmath22 obtained by changing all the colors of the nodes and arcs to red .",
    "then , any successful generation with the derived tdag @xmath25 satisfies the condition that @xmath23 subsumes @xmath25 , and @xmath25 subsumes @xmath24 . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the proof is immediately obtained from the definition of successful generation and the fact that the generator never introduces a new node or a new arc into an input tdag .",
    "the tdags can also be employed by the semantic head - driven generation algorithm@xcite while retaining the above property .",
    "semantic monotonicity always holds for a tdag , since red nodes must be connected .",
    "it has been shown by takeda@xcite that semantically non - monotonic representations can also be handled by introducing a _ functional _ semantic class .",
    "we have been developing a prototype english - to - japanese mt system , called shalt2@xcite , with a lexicon for a computer - manual domain including about 24,000 lexemes each for english and japanese , and a general lexicon including about 50,000 english words and their translations .",
    "a sample set of 736 sentences was collected from the `` ibm as/400 getting started '' manual , and was tested with the above semantic transfer and generation algorithm .",
    "the result of the syntactic analysis by the english parser is mapped to a tdag using a set of semantic equations obtained from the lexicons .",
    "we have a very shallow knowledge base for the computer domain , and no logical inference system was used to derive further constraints from the given source sentences .",
    "the japanese grammar is similar to the one used in kbmt-89 , which is written in pseudo - unification@xcite equations , but we have added several new types of equation for handling coordinated structures .",
    "the japanese grammar can generate sentences from all the successful tdags for the sample english sentences .",
    "it turned out that there were a few collections of semantic transfer sequences which contributed very strongly to the successful generation .",
    "these sequences include    * painting the functional control arcs in yellow . * painting the gaps of relative clauses in yellow . * painting the number and definiteness features in yellow . * painting the passivization feature in green .",
    "other kinds of semantic transfer are rather idiosyncratic , and are usually triggered by a particular lexical rule .",
    "some of the sample sentences used for the translations are as follows :    .... make sure you are using the proper edition for the level of the product .",
    "yuuzaa ha   seihin",
    "no   reberu ni user + subj product + pos level + for tekisetsuna han       wo   siyoushite   iru proper       edition + obj use         + prog koto   wo   tashikamete kudasai + nom + obj confirm     +",
    "imp    publications are not stocked at the address given below .",
    "siryou        ha    ika         de   teikyousuru publication + subj following + loc provide adoresu   ni   sutokku   sare      masen address + loc stock    + passive + neg    this publication could contain technical inaccuracies or typographical errors .",
    "kono siryou        ha    gijyutsutekina this publication + subj technical huseikakusa aruiha insatsujyouno eraa    wo inaccuracy   or      typographical error + obj fuku      me        mashita contain + ability + past ....    the overall accuracy of the translated sentences was about 63% .",
    "the main reason for translation errors was the occurrence of errors in lexical and structural disambiguation by the syntactic / semantic analyzer .",
    "we found that the accuracy of semantic transfer and sentence generation was practically acceptable .",
    "though there were few serious errors , some occurred when a source tdag had to be completely `` paraphrased '' into a different tdag .",
    "for example , the sentence    .... let 's get started .",
    "....    was very hard to translate into a natural japanese sentence . therefore , a tdag had to be paraphrased into a totally different tdag , which is another important role of semantic transfer .",
    "other serious errors were related to the ordering of constituents in the tdag .",
    "it might be generally acceptable to assume that the ordering of nodes in a dag is immaterial . however , the different ordering of adjuncts sometimes resulted in a misleading translation , as did the ordering of members in a coordinated structure .",
    "these subtle issues have to be taken into account in the framework of semantic transfer and sentence generation .",
    "in this paper , we have introduced tricolor dags to represent various degrees of constraint , and defined the notions of semantic transfer and sentence generation as operations on tdags .",
    "this approach proved to be so practical that nearly all of the source sentences that were correctly parsed were translated into readily acceptable sentences . without semantic transfer",
    ", the translated sentences would include greater numbers of incorrectly selected words , or in some cases the generator would simply fail    extension of tdags for disjunctive information and a set of feature structures must be fully incorporated into the framework .",
    "currently only a limited range of the cases are implemented .",
    "optimal control of semantic transfer is still unknown .",
    "integration of the constraint - based formalism , defeasible reasoning , and practical heuristic rules are also important for achieving high - quality translation .",
    "the ability to process and represent various levels of knowledge in tdags by using a uniform architecture is desirable , but there appears to be some efficient procedural knowledge that is very hard to represent declaratively .",
    "for example , the negative determiner `` no '' modifying a noun phrase in english has to be procedurally transferred into the negation of the verb governing the noun phrase in japanese .",
    "translation of `` any '' , `` yet '' , `` only '' , and so on involves similar problems .",
    "while tdags reflect three discrete types of constraints , it is possible to generalize the types into continuous , numeric values such as _ potential energy_@xcite",
    ". this approach will provide a considerably more flexible margin that defines a set of permissible translations , but it is not clear whether we can successfully define a numeric value for each lexical rule in order to obtain acceptable translations .",
    "the idea of the tricolor dags grew from discussions with shiho ogino on the design and implementation of the sentence generator .",
    "i would also like to thank the members of the nl group  naohiko uramoto , tetsuya nasukawa , hiroshi maruyama , hiroshi nomiyama , hideo watanabe , masayuki morohashi , and taijiro tsutsumi  for stimulating comments and discussions that directly and indirectly contributed to shaping the paper .",
    "michael mcdonald , who has always been the person i turn to for proofreading , helped me write the final version ."
  ],
  "abstract_text": [
    "<S> machine translation ( mt ) has recently been formulated in terms of constraint - based knowledge representation and unification theories , but it is becoming more and more evident that it is not possible to design a practical mt system without an adequate method of handling mismatches between semantic representations in the source and target languages . in this paper </S>",
    "<S> , we introduce the idea of `` information - based '' mt , which is considerably more flexible than interlingual mt or the conventional transfer - based mt . </S>"
  ]
}