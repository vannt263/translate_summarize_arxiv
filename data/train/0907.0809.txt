{
  "article_text": [
    "many general techniques for learning and decoding with structured outputs are computationally demanding , are ill - suited for dealing with large data sets , and employ parameter optimization for an intractable search ( decoding ) problem . in some instances , such as syntactic parsing , efficient task - specific decoding algorithms have been developed , but , unfortunately , these are rarely applicable outside of one specific task .    rather than separating the learning problem from the decoding problem , we propose to consider these two aspects in an integrated manner . by doing so , we are able to learn model parameters appropriate for the search procedure , avoiding the need to heuristically combine an _ a priori _ unrelated learning technique and search algorithm . after phrasing the learning problem in terms of search ,",
    "we present two online parameter update methods : a simple perceptron - style update and an approximate large margin update .",
    "we apply our model to two tasks : a simple syntactic chunking task for which exact search _ is _ possible ( to allow for comparison to exact learning and decoding methods ) and a joint tagging / chunking task for which exact search is intractable .",
    "most previous work on the structured outputs problem extends standard classifiers to linear chains . among these",
    "are maximum entropy markov models and conditional random fields @xcite ; case - factor diagrams @xcite ; sequential gaussian process models @xcite ; support vector machines for structured outputs @xcite and max - margin markov models @xcite ; and kernel dependency estimation models @xcite .",
    "these models learn distributions or weights on simple graphs ( typically linear chains ) .",
    "probabilistic models are optimized by gradient descent on the log likelihood , which requires computable expectations of features across the structure .",
    "margin - based techniques are optimized by solving a quadratic program ( qp ) whose constraints specify that the best structure must be weighted higher than all other structures .",
    "linear chain assumptions can reduce the exponentially - many constraints to a polynomial , but training remains computationally expensive .",
    "recent effort to reduce this computational demand considers employing constraints that the correct output only outweigh the @xmath0-best model hypotheses @xcite .",
    "alternatively an online algorithm for which only very small qps are solved is also possible @xcite .    at the heart of all these algorithms , batch or online , likelihood- or margin - based , is the computation :    @xmath1    this seemingly innocuous statement is necessary in _ all _ models , and `` simply '' computes the structure @xmath2 from the set of all possible structures @xmath3 that maximizes some function @xmath4 on an input @xmath5 , parametrized by a weight vector @xmath6 .",
    "this computation is typically left unspecified , since it is `` problem specific . ''    unfortunately , this @xmath7 computation is , in real problems with complex graphical structure , often intractable . compounding this issue",
    "is that this best guess @xmath2 is only one ingredient to the learning algorithms : likelihood - based models require feature expectations and the margin - based methods require either a @xmath0-best list of best @xmath8 or a marginal distribution across the graphical structure .",
    "one alternative that alleviates some of these issues is to use a perceptron algorithm , where _ only _",
    "the @xmath7 is required @xcite , but performance can be adversely affected by the fact that even the @xmath7 can not be computed exactly ; see @xcite for example .",
    "we present the _ learning as search optimization ( laso ) _ framework for predicting structured outputs .",
    "the idea is to delve into eq   to first reduce the requirement that an algorithm need to compute an @xmath7 , and also to produce generic algorithms that can be applied to problems that are significantly more complex that the standard sequence labeling tasks that the majority of prior work has focused on .",
    "the generic _ search _ problem is covered in great depth in any introductory ai book . its importance stems from the intractability of computing the `` best '' solution to many problems ; instead , one must search for a `` good '' solution .",
    "most ai texts contain a definition of the search problem and a general search algorithm ; we work here with that from .",
    "a _ search problem _ is a structure containing four fields : states ( the world of exploration ) , operators ( transitions in the world ) , goal test ( a subset of states ) and path cost ( computes the cost of a path ) .",
    "one defines a general search algorithm given a search problem , an initial state and a `` queuing function . ''",
    "the search algorithm will either fail ( if it can not find a goal state ) or will return a path .",
    "such an algorithm ( figure  [ fig : search ] ) operates by cycling through a queue , taking the first element off , testing it as a goal and expanding it according to operators if otherwise .",
    "each node stores the path taken to get there and the cost of this path .",
    "the _ enqueue _ function places the expanded nodes , _ next _ , onto the queue according to some variable ordering that can yield depth - first , breadth - first , greedy , beam , hill - climbing , and a * search ( among others ) .",
    "since most search techniques can be described in this framework , we will treat it as fixed .",
    "given the search framework described , for a given task the search problem will be fixed , the initial state will be fixed and the generic search algorithm will be fixed .",
    "the only place left , therefore , for parameterization is in the _ enqueue _ function , whose job it is to essentially rank hypotheses on a queue .",
    "the goal of learning , therefore , is to produce an _ enqueue _ function that places good hypotheses high on the queue and bad hypotheses low on the queue . in the case of optimal search",
    ", this means that we will find the optimal solution quickly ; in the case of approximate search ( with which we are most interested ) , this is the difference between finding a good solution or not .    in our model",
    ", we will assume that the enqueue function is based on two components : a path component @xmath9 and a heuristic component @xmath10 , and that the score of a node will be given by @xmath11 .",
    "this formulation includes a * search when @xmath10 is an admissible heuristic , heuristic search when @xmath10 is inadmissible , best - first search when @xmath10 is identically zero , and any variety of beam search when a queue is cut off at a particular point at each iteration .",
    "we will assume @xmath10 is given and that @xmath9 is a linear function of features of the input @xmath5 and the path to and including the current node , @xmath12 : @xmath13 , where @xmath14 is the vector of features .",
    "the supervised learning problem in this search - based framework is to take a search problem , a heuristic function , and training data with the goal of producing a good weight vector @xmath15 for the path function @xmath9 . as in standard structured output learning",
    ", we will assume that our training data consists of @xmath16-many pairs @xmath17 that tell us for a given input @xmath18 what is the correct structured output @xmath19 .",
    "we will make one more important _ monotonicity assumption _ : for any given node @xmath20 and an output @xmath21 , we can tell whether @xmath22 can or can not lead to @xmath8 . in the case that @xmath22 can lead to @xmath8 , we refer to @xmath22 as `` @xmath8-good . ''",
    "; in this paper , we only use @xmath23 loss . ]",
    "the learning problem can thus be formulated as follows : we wish to find a weight vector @xmath15 such that : ( 1 ) the first goal state dequeued is @xmath8-good and ( 2 ) the queue always contains at least one @xmath8-good state . in this framework , we explore an online learning scenario , where learning is tightly entwined with the search procedure . from a pragmatic perspective , this makes sense : it is useless to the model to learn parameters for cases that it will never actually encounter .",
    "we propose a learning algorithm of the form shown in figure  [ fig : learn ] . in this algorithm , we write _",
    "siblings_(_node _ , @xmath8 ) to denote the set of @xmath8-good siblings of this node .",
    "this can be calculated recursively by back - tracing to the first @xmath8-good ancestor and then tracing forward through only @xmath8-good nodes to the same search depth as @xmath12 ( in tasks where there is a unique @xmath8-good search path  which is common  the sibling of a node is simply the appropriate initial segment of this path ) .",
    "there are two changes to the search algorithm to facilitate learning ( comparing figure  [ fig : search ] and figure  [ fig : learn ] ) .",
    "the first change is that whenever we make an error ( a non @xmath8-good goal node is dequeued or none of the queue is @xmath8-good ) , we update the weight vector @xmath15 .",
    "secondly , when an error is made , instead of continuing along this bad search path , we instead clear the queue and insert all the _ correct _ moves we could have made . )",
    "was given to a rl algorithm @xcite .",
    "similar approaches attempt to predict value functions for generalization using techniques such as temporal difference ( td ) or q - learning @xcite .",
    "more recently , applied rl techniques to solving combinatorial scheduling problems , but again focus on the standard td(@xmath24 ) framework .",
    "these frameworks , however , are not explicitly tailored for supervised learning and without the aid of our monotonicity assumption it is difficult to establish convergence and generalization proofs . despite these differences , our search optimization framework clearly lies on the border between supervised learning and reinforcement learning , and further investigation may reveal interesting connections . ]",
    "note that this algorithm can not fail ( in the sense that it will always find a goal state ) .",
    "aiming at a contradiction , suppose it were to fail ; this would mean that _ nodes _ would have become empty .",
    "since `` operators '' will never return an empty set , this means that _ sibs _ must have been empty .",
    "but since a node that is inserted into the queue is either itself good or has an ancestor that is good , so could never have become empty .",
    "( there may be a complication with cyclic search spaces  in this case , both algorithms need to be augmented with some memory to avoid such loops , as is standard . )",
    "we propose two methods for updating the model parameters . to facilitate discussion",
    ", we will refer to a problem as _ linearly separable _ if there exists a weight vector @xmath15 with @xmath25 such that the search algorithm parameterized by @xmath15 ( a ) will not fail and ( b ) will return an optimal solution .",
    "note that with this definition , linear separability is a joint property of the problem _ and _ the search algorithm : what is separable with exact search may not be separable with a heuristic search . in the case of linearly separable data ,",
    "we define the _ margin _ as the maximal @xmath26 such that the data remain separable when all @xmath8-good states are down - weighted by @xmath26 . in other words , @xmath26 is the minimum over all decisions of @xmath27 , where @xmath9 is a @xmath8-good node and @xmath28 is a @xmath8-bad node .    [",
    "[ perceptron - updates . ] ] perceptron updates . + + + + + + + + + + + + + + + + + + +    a simple perceptron - style update rule @xcite , given @xmath29 is @xmath30 , where :    [ eq : delta ] = _ n _ sibs _ - _ n _ nodes _    when an update is made , the feature vector for the incorrect decisions are subtracted off , and the feature vectors for all possible correct decisions are added .",
    "whenever @xmath31 , this looks exactly like the standard perceptron update . when there is only one sibling but many nodes , this resembles the gradient of the log likelihood for conditional models after approximating the `` log sum exp '' with jensen s inequality to turn it into a simple sum",
    "when there is more than one correct next hypothesis , this update rule resembles that used in multi - label or ranking variants of the perceptron @xcite . in that work ,",
    "different `` weighting '' schemes are proposed , including , for instance , one that weights the nodes in the sums proportional to the loss suffered ; such schemes are also possible in our framework , but space prohibits a discussion of them here .",
    "based on this update , we can prove the following theorem :    for any training sequence that is separable with by a margin of size @xmath26 , using the perceptron update rule the number of errors made during training is bounded above by @xmath32 , where , @xmath33 is a constant such that for all training instances @xmath34 , for all nodes @xmath12 in the path to @xmath8 and all successors @xmath35 of @xmath12 ( good or otherwise ) , @xmath36 .",
    "in the case of inseparable data , we follow and define @xmath37 as the least obtainable error with weights @xmath15 and margin @xmath26 over the training data : @xmath38^{1/2}$ ] , where the sum is over all states leading to a solution and @xmath39 is the empirical margin between the correct state and the hypothesized state @xmath22 . using this notation",
    ", we obtain two corollaries ( proofs are direct adaptations of and ):    for _ any _ training sequence , the number of mistakes made by the training algorithm is bounded above by @xmath40 , where @xmath33 is as before .",
    "[ cor : perc - gen ] for any i.i.d . training sequence of length @xmath12 and any test example @xmath41 , the probability of error on the test example is bounded above by @xmath42 , where the expectation is taken over all @xmath43 data points .",
    "[ [ approximate - large - margin - updates . ] ] approximate large margin updates .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    one major disadvantage to the perceptron algorithm is that it only updates the weights when errors are made .",
    "this can lead to a brittle estimate of the parameters , in which the `` good '' states are weighted only minimally better than the `` bad '' states .",
    "we would like to enforce a large margin between the good states and bad states , but would like to do so without adding significant computational complexity to the problem . in the case of binary classification , has presented an online , approximate large margin algorithm that trains similarly to a perceptron called alma .",
    "the primary difference ( aside from a step size on the weight updates ) is that updates are made if either ( a ) the algorithm makes a mistake or ( b ) _ the algorithm is close to making a mistake . _ here , we adapt this algorithm to structured outputs in our framework .",
    "our algorithm , like alma , has four parameters : @xmath44 .",
    "@xmath45 determines the degree of approximation required : for @xmath46 , the algorithm seeks the true maximal margin solution , for @xmath47 , it seeks one within @xmath45 of the maximal . @xmath48 and",
    "@xmath49 can be seen as tuning parameters , but a default setting of @xmath50 and @xmath51 is reasonable ( see theorem 4 below ) .",
    "we measure the instance vectors with norm @xmath52 and the weight vector with its dual value @xmath53 ( where @xmath54 ) .",
    "we use @xmath55 , but large @xmath52 produces sparser solutions , since the weight norm will approach @xmath56 .",
    "the update is :    w ( w + ck^-1/2  ( ) )    here , @xmath0 is the `` generation '' number of the weight vector ( initially 1 and incremented at every update ) and @xmath57 is the projection of @xmath58 into the @xmath59 unit sphere : @xmath60 .",
    "one final change to the algorithm is to down - weight the score of all @xmath8-good nodes by @xmath61 .",
    "thus , a good node will only survive if it is good by a large margin .",
    "this setup gives rise to a bound on the number of updates made ( proof sketched in appendix",
    "a ) and two corollaries ( proofs are nearly identical to theorem 4 and @xcite ) :    [ thm : alma ] for any training sequence that is separable with by a margin of size @xmath26 using the approximate large margin update rule with parameters @xmath62 , the number of errors made during training is bounded above by @xmath63 .",
    "suppose for a given @xmath45 , @xmath48 and @xmath49 are such that @xmath64 ; letting @xmath65 , the number of corrections made is bounded above by :    [ eq : nonlin - bounds ] _ w , 1 d_w , + 2 + ^1/2    [ cor : alma - gen ] for any i.i.d .",
    "training sequence of length @xmath12 and any test example @xmath41 , the probability of error on the test example is bounded above by @xmath66 , where @xmath67 is given in eq   and the expectation is taken over all @xmath43 data points .",
    "[ sec : chunking ]    the syntactic chunking problem is a sequence segmentation and labeling problem ; for example :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ @xmath68 [ said]@xmath69 [ it]@xmath68 [ increased]@xmath69 [ its loan - loss reserves]@xmath68 [ by]@xmath70 [ $ 93 million]@xmath68 [ after]@xmath70 [ reviewing]@xmath69 [ its loan portfolio]@xmath68 , [ raising]@xmath69 [ its total loan and real estate reserves]@xmath68 [ to]@xmath70 [ $ 217 million]@xmath68 . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    typical approaches to this problem recast it as a sequence labeling task and then solve it using any of the standard sequence labeling models ; see @xcite for a prototypical example using crfs . the reduction to sequence labeling",
    "is typically done through the `` bio '' encoding , where the beginning of an @xmath71 phrase is tagged b-@xmath71 , the non - beginning ( inside ) of an @xmath71 phrase is tagged i-@xmath71 and any word not in a phrase is tagged o ( outside ) .",
    "more recently , have described a straightforward extension to the crf ( called a semi - crf ) in which the segmentation and labeling is done directly .",
    "we explore similar models in the context of syntactic chunking , where entire chunks are hypothesized , and no reduction to word - based labels is made .",
    "we use the same set of features across all models , separated into `` base features '' and `` meta features . ''",
    "the base features apply to words individually , while meta features apply to entire chunks .",
    "the base features we use are : the chunk length , the word ( original , lower cased , stemmed , and original - stem ) , the case pattern of the word , the first and last 1 , 2 and 3 characters , and the part of speech and its first character .",
    "we additionally consider membership features for lists of names , locations , abbreviations , stop words , etc .",
    "the meta features we use are , for any base feature @xmath28 , @xmath28 at position @xmath72 ( for any sub - position of the chunk ) , @xmath28 before / after the chunk , the entire @xmath28-sequence in the chunk , and any 2- or 3-gram tuple of @xmath28s in the chunk .",
    "we use a first order markov assumption ( chunk label only depends on the most recent previous label ) and all features are placed on labels , not on transitions . in this task , the @xmath7 computation from eq   _ is _ tractable ; moreover , through a minor adaptation of the standard hmm forward and backward algorithms , we can compute feature expectations , which enable us to do training in a likelihood - based fashion .",
    "our search space is structured so that each state is the segmentation and labeling of an initial segment of the input string , and an operation extends a state by an entire labeled chunk ( of any number of words ) .",
    "for instance , on the example shown at the beginning of this section , the initial hypothesis would be empty ; the first correct child would be to hypothesize a chunk of length @xmath73 with the tag np .",
    "the next correct hypothesis would be a chunk of length @xmath56 with tag vp .",
    "this process would continue until the end of the sentence is reached . for beam search , we execute search as described , but after every expansion we only retain the @xmath28 best hypotheses to continue on to the next round .",
    "our models for this problem are denoted lasop@xmath74 and lasoa@xmath74 , where @xmath28 is the size of the beam we use in search , which we vary over @xmath75 , where @xmath76 denotes full , exact viterbi search and forward - backward updates similar to those used in the semi - crf .",
    "this points out an important issue in our framework : if the graphical structure of the problem _ is _ amenable to exact search and exact updates , then the framework can accommodate this . in this case , for example , when using exact search , updates are only made at the end of decoding when the highest ranking output is incorrect ( after adjusting the weights down for lasoa ) , but other than this exception , the sum over the bad nodes in the updates is computed over the entire search lattice and strongly resemble almost identical to those used in the conditional likelihood models for the gradient of the log normalization constant .",
    "we always use averaged weights .",
    "we report results on the conll 2000 data set , which includes @xmath77 training sentences ( @xmath78 words ) and @xmath79 test sentences ( @xmath80 words ) .",
    "we compare our proposed models against several baselines .",
    "the first baseline is denoted zdj02 and is the best system on this task to date @xcite .",
    "the second baseline is the likelihood - trained model , denoted semicrf .",
    "we use @xmath81 of the training data to tune model parameters .",
    "the third baseline is the standard structured perceptron algorithm , denoted perceptron .",
    "for the semicrf , this is the prior variance ; for the online algorithms , this is the number of iterations to run ( for alma , @xmath82 ; changing @xmath45 in the range @xmath83 $ ] does not affect the score by more than @xmath84 in all cases ) .",
    "the results , in terms of training time , test decoding time , precision , recall and f - score are shown in table  [ tab : chunking ] .",
    "as we can see , the semicrf is by far the most computationally expensive algorithm , more than twice as slow to train than even the lasop@xmath85 algorithm .",
    "the perceptron has roughly comparable training time to the exactly trained laso algorithms ( slightly faster since it only updates for the best solution ) , but its performance falls short .",
    "moreover , decoding time for the semicrf takes a half hour for the two thousand test sentences , while the greedy decoding takes only 52 seconds .",
    "it is interesting to note that at the larger beam sizes , the large margin algorithm is actually faster than the perceptron algorithm .",
    ".results on syntactic chunking task ; columns are training and testing time ( h : m ) , and precision / recall / f - score on test data .",
    "[ cols=\"<,>,>,^,^,^\",options=\"header \" , ]",
    "in this paper , we have suggested that one views the learning with structured outputs problem as a search optimization problem and that the same search technique should be applied during both learning and decoding .",
    "we have presented two parameter update schemes in the laso framework , one perceptron - style and the other based on an approximate large margin scheme , both of which can be modified to work in kernel space or with alternative norms ( but not both ) .",
    "our framework most closely resembles that used by the incremental parser of .",
    "there are , however , several differences between the two methodologies .",
    "their model builds on standard perceptron - style updates @xcite in which a full pass of decoding is done before any updates are made , and thus does not fit into the search optimization framework we have outlined .",
    "collins and roark found experimentally that stopping the parsing early whenever the correct solution falls out of the beam results in drastically improved performance . however , theyhad little theoretical justification for doing so .",
    "these `` early updates , '' however , do strongly resemble our update strategy , with the difference that when collins and roark make an error , they stop decoding the current input and move on to the next ; on the other hand , when our model makes an error , it continues from the correct solution(s ) .",
    "this choice is justified both theoretically and experimentally . on the tasks reported in this paper",
    ", we observe the same phenomenon : early updates are better than no early updates , and the search optimization framework is better than early updates .",
    "for instance , in the joint tagging / chunking task from section  [ sec : joint ] , using a beam of 10 , we achieved an f - score of @xmath86 in our framework ; using only early updates , this drops to @xmath87 and using standard perceptron updates , it drops to @xmath88 .",
    "our work also bears a resemblance to training _",
    "local classifiers _ and combining them together with global inference @xcite .",
    "the primary difference is that when learning local classifiers , one must assume to have access to all possible decisions and must rank them according to some loss function .",
    "alternatively , in our model , one only needs to consider alternatives that are in the queue at any given time , which gives us direct access to those aspects of the search problem that are easily confused .",
    "this , in turn , resembles the online large margin algorithms proposed by , which suffer from the problem that the @xmath7 must be computed exactly .",
    "finally , one can also consider our framework in the context of game theory , where it resembles the iterated gradient ascent technique described by and the closely related marginal best response framework @xcite .",
    "we believe that laso provides a powerful framework to learn to predict structured outputs .",
    "it enables one to build highly effective models of complex tasks efficiently , without worrying about how to normalize a probability distribution , compute expectations , or estimate marginals .",
    "it necessarily suffers against probabilistic models in that the output of the classifier will not be a probability ; however , in problems with exponential search spaces , normalizing a distribution is quite impractical . in this sense , it compares favorably with the energy - based models proposed by , for example , , which also avoid probabilistic normalization , but still require the exact computation of the @xmath7 .",
    "we have applied the model to two comparatively trivial tasks : chunking and joint tagging / chunking .",
    "since laso is not limited to problems with clean graphical structures , we believe that this framework will be appropriate for many other complex structured learning problems .",
    "we thank michael collins , andrew mccallum , charles sutton , thomas dietterich , fernando pereira and ryan mcdonald for enlightening discussions , as well as the anonymous reviewers who gave very helpful comments .",
    "this work was supported by darpa - ito grant nn66001 - 00 - 1 - 9814 and nsf grant iis-0326276 .",
    "we follow , thm 3 , modifying the bound of the normalization factor when projecting @xmath15 ; suppose @xmath15 is the optimal separating hyperplane .",
    "denoting the normalization factor @xmath89 on update @xmath0 , we find : @xmath90 ( @xmath26 is the margin ) by observing @xmath91 is bounded above by @xmath26 since @xmath92 \\leq \\vec w\\t \\left[\\max_{n \\in \\textit{sibs } } \\vec \\ph(x , n ) - \\min_{n \\in \\textit{nodes } } \\vec \\ph(x , n)\\right ] \\leq \\ga$ ] , due to the definition of the margin .",
    "@xmath89 is bounded by @xmath93 to bound number of updates @xmath35 by @xmath94 .",
    "algebra completes the proof ."
  ],
  "abstract_text": [
    "<S> mappings to structured output spaces ( strings , trees , partitions , etc . ) </S>",
    "<S> are typically learned using extensions of classification algorithms to simple graphical structures ( eg . , linear chains ) in which search and parameter estimation can be performed exactly . unfortunately , in many complex problems , it is rare that exact search or parameter estimation is tractable . </S>",
    "<S> instead of learning exact models and searching via heuristic means , we embrace this difficulty and treat the structured output problem in terms of approximate search . </S>",
    "<S> we present a framework for learning as search optimization , and two parameter updates with convergence theorems and bounds . </S>",
    "<S> empirical evidence shows that our integrated approach to learning and decoding can outperform exact models at smaller computational cost . </S>"
  ]
}