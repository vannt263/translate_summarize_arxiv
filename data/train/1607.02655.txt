{
  "article_text": [
    "increasing access to streaming data on dynamic networks drives interest in formal models to quantify stochasticity and structure of latent processes underlying observable data streams .",
    "modeling interests are coupled with concerns to monitor and adapt to changing patterns , and to signal and highlight dynamics that may reflect interesting departures from the norm .",
    "key challenges are real - time / sequential analysis and scalability : interest lies in relevant statistical models whose analyses are inherently sequential in time , as well as computationally efficient and scalable with network size and sampling rates .",
    "relevant models should also define sound statistical methods for monitoring and short - term prediction , and elucidate the complexities and dynamics in network structure in both single sample inference and multi - sample comparisons across contexts .",
    "we contribute to this area with modeling and methodological developments coupled with a motivating applied study of internet traffic in e - commerce .",
    "consistent with the primary applied goals outlined above , the main contributions of this work are as follows .    * a flexible and customized statistical modeling framework for : ( i ) characterizing patterns of temporal variation in network flows at the levels of nodes and pairs of nodes ; ( ii ) model - based exploratory data analyses of network flows within and across contexts ; and ( iii ) the ability to scale to large networks . * use of these flexible , efficient models as bayesian emulators of more structured network flow models .",
    "this yields computationally efficient dissection of the dynamics to evaluate node - specific and dependence / interaction effects across nodes in a structured model context where analysis is otherwise computationally challenging in more than small networks . *",
    "formal bayesian model assessment methodology for sequential monitoring of flow patterns with the ability to signal departures from predictions in real - time and allow informed interventions as a response , and in a scalable framework . *",
    "development and validation of the above in exploratory and monitoring analyses of data from the motivating application ; here the observations are streaming counts of visitors in a set of defined web domains ( collections of webpages ) in a structurally well - defined but dynamic / evolving website .",
    "this includes evaluation of node - specific and node - pair interactions in the flow dynamics within the network over a given time period , comparisons across time periods and across days , and analyses utilizing bayesian monitoring and adaptation to respond to departures from predicted flow patterns .    following a discussion of",
    "the motivating applied setting , network and data in section  [ sec : webdata ] , we develop our class of bayesian dynamic flow models ( bdfms ) in section  [ sec : bdfm ] .",
    "bdfms are flexible univariate dynamic models for series of counts representing flows into the network and between within - network node pairs . these ( non - stationary and non - normal ) state - space models for streaming count data rely on discrete - time gamma processes historically used in volatility modeling , and that have very recently become of interest as flexible smoothing and short - term predictive models for space - time processes underlying count data .",
    "our use of these models for within - network flows is novel and involves methodological extension to adapt and customize them to provide suitable univariate emulators of the underlying , inherent dynamic multinomial structures governing flows at each time point .",
    "this use of sets of _ decoupled _ univariate models that are then _ recoupled _ to define the actual multinomial probability processes is : ( a ) explicitly designed to be computationally efficient in on - line data analysis , scaling quadratically in the number of network nodes and enabling distributed implementation for streaming data on large networks ; ( b ) allows for diverse patterns in the dynamics of flow rates that a time - varying dirichlet - multinomial model simply annot ; and ( c ) relates to the recent development of conceptually similar ( decouple / recouple ) approaches that have advanced multivariate dynamic modeling in conditionally normal contexts  @xcite .",
    "section  [ sec : bdfmdata ] discusses some aspects and summaries of exploratory analysis of the network flow data from a defined maxpoint network of the fox news website .",
    "this highlights the use of customized bdfms , with one focus on exploring aspects of flow dynamics on the network across the same time periods on different days .",
    "the supporting appendix material gives additional technical details and discussion .",
    "section  [ sec : dgm ] introduces a class of more highly structured _ dynamic gravity models ( dgms ) _ for network flows .",
    "these are non - normal , log - linear random - effects models with time - varying parameters for flow rate contributions of origin nodes , destination nodes and origin - destination interaction effects .",
    "our dgms extend prior work with static gravity models  ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "? * ; * ? ? ?",
    "* ) to the time - varying parameter context , defining a class of models able to represent complicated patterns of dependency structure , and their temporal variations , across nodes .",
    "importantly , we show that the flexible and computationally simple bdfm framework can be mapped one : one to that of the dgm .",
    "this underlies one further novel contribution of this work : the use of the fast , efficient bdfms as _",
    "emulators _ of dgms .",
    "this is key from the viewpoint of scalability ; fitting gravity models , even without time - varying parameters , is a challenging issue in more than modest dimensional networks , and simply infeasible in any realistic dynamic extension appropriate for scalable , on - line analysis of streaming network flow data .",
    "further , we avoid the challenging approach of defining and parametrizing time - evolution models for dgms directly , adopting the implicit structures induced in the mapping from bdfms where model specification and fitting is relatively facile .",
    "example results and highlights from the bayesian emulation analysis of dgms for the maxpoint fox news study appear in section  [ sec : dgmdata ] .",
    "section  [ sec : monitor ] develops methods of formal , sequential bayesian model monitoring and adaptation ( automatic intervention ) for bdfms .",
    "the aim here is to build into the fast , decoupled analysis an ability to efficiently evaluate incoming flows against model predictions so as to signal data at the level of individual nodes and node - pairs that appear discrepant , and that may signal outliers or changes in flow trends / rates beyond the norm .",
    "in addition to signaling such events and thus providing opportunity for direct intervention , we couple monitoring with the use of automatic intervention to allow the model to appropriately adapt to data at the next few time points .",
    "this bayesian testing / adaptation strategy builds on core theory underlying its use in time series forecasting contexts with dynamic linear models  ( @xcite ; see also chapter 11 of  @xcite ) .",
    "some of the novelty here is in the use of these ideas in non - linear , non - normal dynamic models for count data our class of bdfms .",
    "importantly , monitoring is applied in parallel across nodes and node - pairs , so is also scalable with network size .",
    "some departures from normal variation in patterns of flow may be related across nodes , and the approach has an ability to explore and evaluate this both within the bdfm model context and then following the map to more structured dgms that directly reflect interaction effects .",
    "application to the fox news network data highlights some aspects of the use of this in connection with selected network nodes .",
    "summary comments conclude the paper in section  [ sec : closingcomments ] , and additional supporting material is given in the appendix .",
    "our context is traffic flow among _ domains _ ( defined sets of pages ) of the fox news website .",
    "domains include the homepage and several categories of news and consumer content such as politics , entertainment , travel , science , etc. as defined by fox news . while the domain structure is persistent , the nature of webpage definition and content within a domain is dynamic ; content changes on a daily basis ( updated at midnight ) but also more rapidly when noteworthy events occur .",
    "maxpoint places ads on pages in these fox news domains , and thus can track flows of anonymized users as they move through its pages . while some users can be tracked individually ,",
    "this is not the norm , and we focus in this paper on aggregated flow counts , not the trajectories of individuals .    on - line",
    "advertisers are interested in a host of statistical issues related to traffic flow and domain content .",
    "the field has become quite sophisticated , employing complex recommender systems  @xcite , sentiment analysis  @xcite , text mining @xcite , and other methods  @xcite .",
    "however , basic questions of understanding and characterizing traffic across domains have not received the attention they require .",
    "in particular , there is commercial value in identifying how the popularity of a site changes on short time scales , and how sites interact with respect to traffic .",
    "as example , our data showed a morning - after spike in traffic to the entertainment domain following the grammy awards , which would have been an opportunity to market concert tickets ; unusual interactions in flows between science and health may reflect new medical findings that might incline people to purchase gym memberships ; increased flow rates from homepage to science that contradict the general stable or somewhat decreasing trends of overall traffic may indicate specific opportunities to target scientific product consumers .",
    "as pages within a domain are updated , questions arise as to whether browsing traffic patterns change as a result . to address this statistically ,",
    "we need to understand stochastic variation in past browser traffic so that comparisons can be made of incoming traffic streams against recent statistical norms \" , and significant deviations from short - term predictions based on current dynamic patterns can be identified .",
    "companies that have flow models which enable them to predict how traffic will change as content changes , that are able to sensitively characterize and monitor patterns of change in interactions as well as overall rates , and that can signal anomalous changes to provide opportunities for intervention and actions , will be advantaged .",
    "they can recognize opportunities more quickly , and for example may then adapt bidding strategies for relevant keywords to be dynamically calibrated to expected revenue .",
    "the data set contains fox news website visit data during 09:0010:00am and 01:0002:00pm est on each of six days , february 23rd-24th , march 2nd-3rd and 9th-10th , 2015 . these days are mondays or tuesdays .",
    "since the fox news website structure changes often , with new pages being added and old pages being archived , the analysis aggregates webpages into groups specified by the host domain www.foxnews.com , and the set of first url paths after the host domain , including examples such as e.g. www.foxnews.com/politics/ * and www.foxnews.com / us/*. these classify all pages into 22 domains : homepage , politics , us , opinion , entertainment , technology , science , health , travel , leisure , world news , sports , shows , weather , category , latino , story , on - air , video , national news , magazine , and other .",
    "the data set includes anonymized visitors from nearly every time zone on the planet . in order to study time - of - day effects , such as , say , a tendency to browse news in the morning and entertainment in the afternoon",
    ", it is necessary to stratify by time zone .",
    "here we focus on users in the eastern north america time zone ; those are the most numerous , and the two time windows used in this study were chosen with the expectation that different browsing patterns might occur at those times .",
    "aggregate data give time series of counts in half - minute intervals , i.e. , @xmath0 time points of domain occupancy , flows from each domain , and flows into each domain .",
    "in each half minute interval , if the record shows the same user in two or more domains , then each of her / his moves is counted in the flow data into each of these domains .",
    "if the user refreshes the same page multiple times spanning more than one time interval , then s / he is counted as simply staying in that domain ; this can be done as the web browsing tool performs automatic refresh .",
    "importantly , if a user stays in the same domain for more than five minutes , s / he is declared as no longer active and counted as leaving the fox news site . if such a user later appears in one domain , s / he counts as inflow from outside the fox news site . finally ,",
    "we can not track user information either before or after the one - hour observation window ; we thus restrict attention to the period 09:0509:55am and 01:0501:55pm , consisting of uncensored flows , using the first 5 minutes of data informally to define priors .",
    "thus the series runs from @xmath1 with @xmath2 in each time period .",
    "aggregation at half - minute intervals reflects a balance of interests in fine - time scale modeling against information content of data with low flow rates . for domain pairs with low flow rates",
    "it is sometimes too low , leading to excessive volatility in the bdfm and noisy parameter estimates in the dgm .",
    "no single window is good for all node pairs at all times , but preliminary exploration found this to be a good compromise .",
    "the decision that a user is inactive after five minutes is based on previous research on how users access on - line articles .",
    "few people read more than the first paragraph of a news story , and at the times of day for which data were collected , interruptions are likely .",
    "investigations of on - line session length have focused on dynamics of search engine use  ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* and references therein ) in settings where the full breadth of user browsing behavior is visible .",
    "using additional context such as change in search engine query topic , these studies have derived average user session lengths between 560minutes  @xcite .",
    "we employed a session length limit on the lower end of this spectrum due to the fact that a user is likely to only spend a fraction of a larger total browsing session on fox news .",
    "referring to sites external to the fox news website as node 0 , we have @xmath3 network nodes ; the @xmath4 actual domains and  external \" , indexed as @xmath5 at each time @xmath6 define @xmath7 as the flow count from node @xmath8 to @xmath9 , including the inflows @xmath10 and outflows @xmath11 relative to the external domain .",
    "also , denote the number of occupants of node @xmath8 at the end of the @xmath12 period by @xmath13 a random quantity at the start of the period , but then known and given by the sum of inflows minus outflows at the end of the period .",
    "figure  [ fig : networkmovie ] provides a visualization of data at the first time interval , and the schematic in figure  [ fig : networkcartoon ] reflects our notation .",
    "if @xmath14 has a gamma distribution with shape @xmath15 and scale @xmath16 , we write @xmath17 , noting that @xmath18 and @xmath19 if @xmath20 has a beta distribution with p.d.f .",
    "proportional to @xmath21 for @xmath22 we write @xmath23 if the @xmath24vector of counts @xmath25 has a multinomial distribution with total counts @xmath26 and probability vector @xmath27 we write @xmath28 for any series of random quantities @xmath29 over @xmath30 we use the succinct notation @xmath31 for any indices @xmath32    .,width=480 ]    @xmath33   & & & & & & * + + + [ o][f-]{1 } \\ar@{.}[d ] & \\\\ & & &      * + + + [ o][f-]{i } \\ar@/^/@{-->}^*+{x_{i1t}}[rrru ]       \\ar@{-->}^*+{x_{ijt}}[rrr ] \\ar@/_/@{-->}^*+{x_{iit}}[rrrd ]       \\ar@/_0pc/@{-->}_*+{x_{i0t}}[llld ] & & & * + + + [ o][f-]{j } \\ar@{.}[d ] & \\\\   \\textrm{outflow } & & & & & & * + + + [ o][f-]{i } & \\\\ } \\ ] ]",
    "bdfms are based on gamma - beta random walks that have been key to stochastic volatility modeling for more than 30 years  ( * ? ? ?",
    "* ; * ? ? ?",
    "* section 10.8 ) . based initially on bayesian discount concepts related to exponential smoothing for volatilities  @xcite and with steady \" evolutions in non - gaussian dynamic models  @xcite , these _ gamma - beta discount models _ yield closed form bayesian analyses .",
    "they have seen some though limited use as models for rates underling time series of conditionally poisson counts  @xcite , which is a starting point here .",
    "we extend the applicability of the basic model in a number of ways , with novel model forms customized to the network flow context and that define flexible models for conditional multinomial data with time - varying probabilities that go beyond prior use .",
    "we also heavily utilize full bayesian posterior simulation of posteriors for latent rate processes , extending the use from the normal / linear dynamic volatility modeling context  ( * ? ? ?",
    "* chapter 4 ) .",
    "the essentials of gamma - beta discount models follow ; see appendix  [ app : betagammadm ] for further details and discussion . in generic notation , suppose that @xmath34 is a time series with @xmath35 conditionally independently over @xmath36 here @xmath37 is a latent level process and @xmath38 a scaling factor known at time @xmath12 .",
    "the @xmath37 process evolves via the markov model @xmath39 where @xmath40 is a specified _ discount factor _ and @xmath41 is a known function of @xmath42 and independent innovations @xmath43 drive the evolution .",
    "the beta distributions imply : ( i ) @xmath44 hence this is a multiplicative random walk model , or",
    " steady \" evolution ; ( ii ) a lower value of @xmath45 leads to a more diffuse distribution for @xmath43 , and hence increased uncertainty about @xmath37 and adaptability to changing rates over time ; a value closer to one indicates a steady , stable evolution .",
    "the model is structured to ensure full conjugacy in the forward filtering / bayesian sequential learning over time , and in retrospective analysis .",
    "this is reflected in some key summaries , as follows and with further details in appendix  [ app : betagammadm ] . here",
    "@xmath46 is a synthetic notation for initial information .    *",
    "_ forward filtering ( ff ) : _ at any time @xmath47 both the prior @xmath48 and the posterior @xmath49 for the current \" latent level are gamma distributions , with trivially computed parameters that are updated as @xmath12 evolves * _ one - step forecasts : _ the one - step ahead forecast distribution made at time @xmath50 to predict time @xmath12 is generalized negative binomial with p.d.f . in . on observing @xmath51 the p.d.f",
    "is trivially evaluated to feed into computation of model marginal likelihoods ( mmls , as in appendix ) for assessment .",
    "* _ backward sampling : _ at end time @xmath52 recursive simulation generates _ time trajectories _",
    "@xmath53 of the rate process under its full posterior @xmath54 the computations are trivial , as detailed in section  [ sec : bs ] .",
    "the model can be defined by any sequence of specified discount factors @xmath55 a constant value over time defines a global smoothing rate ; values closer to 1 constrain the stochastic innovation and hence the change from @xmath56 to @xmath37 ; smaller discount factor values lead to greater random changes in these poisson levels .",
    "intervention to specify smaller discount factors at some time points , to reflect or anticipate higher levels of dynamic variation at those times , are sometimes relevant . in our network flow models",
    "below , we customize the specification of the sequence of discount factor to address issues that arise in cases of low flow levels .",
    "that extension of discount - based modeling defines the @xmath45 as time - varying functions of an underlying base discount rate , and the latter are then evaluated using mml measures .",
    "this model provides the basis for flows into network nodes ; we adapt and generalize it to define components of flexible multinomial dynamic models for flows between nodes in a network .      with notation for inflows as in figure",
    "[ fig : networkcartoon ] , we adopt the general model of section  [ sec : gammabetadm ] by adding suffices @xmath8 for network nodes and setting the poisson mean scaling factors to 1 .",
    "we now customize this model via specification of discount factor sequences . at",
    "any node @xmath57 the time @xmath12 inflow to node @xmath8 is @xmath58 independently across nodes @xmath59 and the latent levels @xmath60 follow node - specific gamma - beta discount models with discount factor @xmath61 at time @xmath62 the time @xmath63 update / evolve steps are : ( i ) the time @xmath12 prior @xmath64 updates to the posterior @xmath65 with @xmath66 and @xmath67 this then evolves to the time @xmath68 prior @xmath69 , and so on .",
    "specifying discount factors @xmath61 relates to the information content of gamma distributions as measured by the shape parameters @xmath70 ; evolution each time point reduces this by discount factor , the latter representing a per - time - step decay of information induced by the stochastic evolution .",
    "our specification of discount rates is motivated by the following considerations .",
    "first , baseline levels of variation on @xmath60 are likely to be node specific , so that each node should have its own baseline discount rate to be assessed in data analysis .",
    "second , in cases of zero flow rates for a period of time , @xmath71 is continually discounted and shrinks towards 0 while @xmath72 is incremented by 1 at each update step . that is , discounting is not balanced by the prior - posterior update and the generates more and more diffuse posteriors favoring lower and lower @xmath73 ideally , the posterior and prior should be very similar in cases of 0 flows , and we address this with the specification @xmath74 at each @xmath75 where @xmath76 is a _ constant baseline discount factor _ for node @xmath8 and @xmath77 a specified constant .",
    "the aim is that @xmath61 be close to the baseline unless information content is very low ; this our applied studies take @xmath78 ( so that @xmath61 be close to within 10% of the baseline when @xmath79 ) .",
    "then in cases of high information content , the effective @xmath61 is close to @xmath80 otherwise , @xmath61 will be closer to 1 in cases of low information content , so appropriately limiting the decay of information in such cases .",
    "node - specific mml measures that feed into model assessment to aid in selection of the baseline discount factors @xmath81 these measures of short - term predictive fit of the models can also be monitored sequentially over time for on - line tracking of model performance .",
    "this ability to flag anomalous data at one node or any subset of nodes is key to commercial application of the analysis , since that corresponds to new opportunities or new threats ( e.g. , offer concert tickets after the grammy awards , but not on david bowie s obituary ) .",
    "this view on anomaly detection is extended below , in section  [ sec : monitor ] , using bayesian model monitoring concepts .",
    "one aspect of this is the ability to signal a need to _ temporarily _ reduce the value of the discount factor for a node at a time of degradation of predictive performance that may relate to changes in @xmath60 that are larger than the standard \" baseline discount factor value @xmath76 determines .",
    "transitions from any node @xmath8 at time @xmath12 are inherently multinomial with time - varying transition probabilities .",
    "to build flexible and scalable models for dynamics and dependencies in transition probability vectors is a challenge , with computational issues for even simple models quickly dominating .",
    "novel models here adapt and extend the univariate poisson / gamma - beta random walk models to enable flexibility in modeling node - pair specific effects as they vary over time as well as scalability .    considering flows from node @xmath8",
    "to node @xmath9 at time @xmath47 and using notation as in figure  [ fig : networkcartoon ] , the core model is @xmath82 where the current node @xmath8 occupancy level is @xmath83 and @xmath84 is the @xmath85-vector of transition probabilities @xmath86 ( including the external \" node i.e. , leaving the fox news network at @xmath87 we structure _ decoupled _ bdfms in terms of positive flow rates @xmath88 underlying each @xmath89 specifically , @xmath90 independently , with independent gamma - beta evolutions for each latent level @xmath91 these bdfms for each node pair can be customized with node - pair specific discount factors , allowing greater or lesser degrees of variation by node pair .",
    "the set of models for elements of @xmath92 implies a dynamic model for the vector of transition probabilities @xmath84 having elements @xmath93 independence across nodes enables scaling , as the analyses can then be decoupled and run in parallel for the @xmath88 and then recoupled to infer the @xmath94 dependencies in patterns of changes in the @xmath88 are recovered in evaluating the posterior distributions and , as in section  [ sec : dgm ] , in using this set of models to emulate gravity models that explicitly characterize interdependencies .",
    "a key and critical component of the model is the definition of the scaling factors @xmath95 in  . in decoupling the multinomial flows from node @xmath8 into parallel poisson models for nodes @xmath96 the inherent dependency on total occupancy of node @xmath8",
    "we restore this in using this specific definition of scaling factors to explicitly correct for occupancy changes .",
    "this recognizes that the decoupled , scaled models are not predictive of overall occupancy rather , they are decoupled , tractable models that are relevant to tracking and short - term prediction of _ relative _ occupancy levels through the implied multinomial probabilities .",
    "the relevance of this scaling factor is most evident in cases of major changes in occupancy , when an abrupt increase in node @xmath8 occupancy @xmath97 at time @xmath50 relative to its prior value @xmath98 will lead to increased flows to other nodes at time @xmath12 even if the underlying transition probabilities @xmath84 are essentially constant .",
    "in such a case , the scaling factor will encourage the appropriate view that the @xmath88 are stable .",
    "then , inferences on the @xmath88 directly yield inferences on the transition probabilities of interest : theoretically , the conditional multinomial probabilities are simply not impacted by the scaling factors , i.e. , @xmath99 the theory and analysis details of section  [ sec : gammabetadm ] and appendix  [ app : betagammadm ] now apply with data and latent flow levels indexed by origin node @xmath8 and destination node @xmath100 as with inflow models , we have flexibility to choose discount factors specific to context . following the discussion of section  [ sec : inflows ] , we specify @xmath101 at each @xmath102 where @xmath103 is a _ constant baseline discount factor _ for node pair @xmath104 and @xmath77 a specified constant .",
    "again this is later overlaid with intervention to adjust discount factor values as needed , based on sequential monitoring of flow patterns and using the mml measures now of course for each node pair as one formal guide to model adequacy .    in sequential analysis of transitions ,",
    "the node - pair specific models generate full joint predictions one - step ahead ( or more , if desired ) for the theoretically exact set of multivariate flow vectors @xmath105 across all nodes .",
    "the one - step forecast distribution does not have an analytic closed form , but is trivially simulated to define forecasts .",
    "that is : ( i ) simulate directly from each of the gamma - beta evolutions for the @xmath106 ( ii ) transform sampled values to the conditional multinomial probabilities @xmath88 ; then ( iii ) sample the multinomial @xmath82 at these parameter values .",
    "similarly , for both on - line and retrospective inference about transition probabilities , samples from posteriors for the @xmath88 again simply transform to the required probability scale .",
    "the analysis was applied separately to data from each of the six days .",
    "we focus on the am period of february 23rd 2015 for initial summaries , and then make some comparisons across days .",
    "priors for the inflow rates are @xmath107 with @xmath108 and @xmath109 where @xmath110 is from inflows in the 5minutes _ prior _ to the start of model analysis at @xmath111 the priors for the node - node flows are , similarly , @xmath112 with @xmath113 and with @xmath114 where each @xmath115 is a point estimate based on that prior period . with @xmath116",
    "the priors are relatively diffuse , and for most nodes one or a few initial observations `` wash out '' the effect of the prior .",
    "while some node - node pairs have very low counts , they all see traffic that then updates shape parameters over a few early periods ; some network links have counts in the thousands , while the average is around 4050 across the time period .     for the inflows to fox news nodes @xmath117 for the february 23rd 2015 am period .",
    ", width=432 ]    the prior for each baseline discount factor is a smoothness encouraging @xmath118 truncated to ( 0.9,0.999 ) ; reanalysis using uniform priors on this range led to little in the way of noticeable differences , as the marginal likelihoods at @xmath119 dominate . running models in parallel across discrete grids of each discount factors and evaluating mml measures at @xmath119",
    "gives marginal likelihoods that are mapped to posteriors .",
    "figure  [ fig : dfall ] plots posteriors for the @xmath76 in the inflow models .",
    "some nodes exhibit higher volatility in flows than others , consistent with smaller discount factors ; these are particularly associated with domains with high flow counts ( e.g. , inflows to homepage ) .",
    "constraining the range to higher values is consistent with the expectations to generally smooth \" trajectories for the @xmath120 processes , which turns out to be consistent with the majority of flows ; allowing smaller values has little or no impact on much of the reported analysis .",
    "however , for some node flows with patterns of higher levels of change and variation , lower discount factors would lead to posteriors that suggest more volatile trajectories in a few cases .",
    "these are better addressed in a model that uses a higher discount factor as standard , but then with interventions to allow increased uncertainty and adaptation in response to discrepant observations ( whether single or in batches ) ; our developments in section  [ sec : monitor ] are heavily motivated by this .",
    "the model is , of course , open to specification of whatever priors a user may regard as relevant or wish to explore .",
    "summary inferences on selected model components are reported from models with discount factors set at posterior modes .",
    "figure  [ fig : firsteg ] gives one example of learning about inflow the leisure domain .",
    "this exemplifies sequential learning about the flow rate together with its retrospectively updated trajectory and a visual assessment of one - step ahead forecasting aligned with the data .",
    "( homepage ) to @xmath121 ( politics ) . _",
    "data @xmath122 ( plus signs ) with one - step ahead forecast means and 95% intervals .",
    "_ trajectory of mean and 95% intervals from on - line posteriors @xmath123 . _",
    "lower : _ revised trajectory under @xmath124 , width=364 ]     ( homepage ) to @xmath121 ( politics ) . _",
    "data @xmath122 ( plus signs ) with one - step ahead forecast means and 95% intervals .",
    "_ trajectory of mean and 95% intervals from on - line posteriors @xmath123 . _",
    "lower : _ revised trajectory under @xmath124 , width=364 ]    a similar display in figure  [ fig : phihomepol ] is an example of flow between two network nodes : from homepage to politics .",
    "as with figure  [ fig : firsteg ] , we note the concordance of incoming data with the one - step predictive intervals as they are successively revised in the forward analysis , and the enhanced smoothing of trajectories in the retrospective analysis .",
    "pointwise intervals of the trajectories of transition probabilities @xmath125 ( homepage @xmath126 entertainment ) for each of the six mornings .",
    ", width=480 ]     pointwise intervals of the trajectories of transition probabilities @xmath125 ( homepage @xmath126 entertainment ) for each of the six mornings .",
    ", width=480 ]    on transition probabilities , it is natural to look at examples involving the homepage , the most popular single domain on fox news .",
    "for example , figure  [ fig : trans2 ] shows that the probability of people leaving the fox news website from homepage increases in this 50 minute window for each of the six mornings .",
    "note that there are significant day effects ; e.g. , visitors were more likely to leave fox news on the morning of march 9th compared to the other mornings .",
    "more detailed insights based on the gravity model analysis are noted in section  [ sec : dgmdata ] .",
    "similar figures ( not shown ) highlight patterns and day - to - day differences for other transitions .",
    "for example , most homepage visitors stay on homepage for a while and have a high probability of exiting the fox news site entirely from that page . across all six days ,",
    "the probability of staying on the homepage each time interval generally decreases over the course of the 50 minute morning period .    as an illustration of a more detailed analysis of a very specific flow ,",
    "consider figure  [ fig : trans5 ] . among the visitors who leave the homepage for other fox news domains ,",
    "entertainment is generally the most popular destination . across all mornings ,",
    "we see major differences in trajectories of transition probabilities ; in particular february 23rd and 24th have higher rates than the other days .",
    "it is noteworthy that the academy awards ceremony was held on the night of february 22nd , which may have driven this uptick .",
    "additional summaries of inference on trajectories of selected @xmath88 and @xmath86 processes appear in the mapping to dynamic gravity models ; see the upper row of frames in figures  [ fig : gmhome_sci ] and [ fig : gmhome_ent ] , for examples .",
    "a more intricate , multivariate dynamic model involves node - specific main effects and node - node interaction terms , representing dependencies in patterns of flows linked to inflow / outflow and node - node relationships . for each within - network node @xmath127 and",
    "all @xmath128 the model is @xmath129 with : ( i ) a baseline process @xmath130 ; ( ii ) a node @xmath8 main effect process @xmath131 adjusting the baseline intensity of flows the origin or outflow parameter process for node @xmath8 ; ( iii ) a node @xmath9 main effect process @xmath132 representing the additional  attractiveness \" of node @xmath9  the destination or inflow parameter process for node @xmath9 ; and ( iv ) an interaction term @xmath133 , representing the directional  affinity \" of node @xmath8 for @xmath9 over time relative to the combined contributions of baseline and main effects .",
    "models of this and more elaborate forms have seen some use in transportation studies  ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ) where the interaction term is typically structured as a function of physical distance between nodes ; there the  gravity model \" terminology relates to the role of small distances in defining large interactions and hence  attraction \" of traffic from node @xmath8 to node @xmath100 we refer to the @xmath133 interactions as  affinities \" . in dissecting the network flow activity , we are most interested in questions about which affinities are greater than one ( @xmath9 attracts flow from @xmath8 over and above the main effects ) , or less than one ( @xmath9 is relatively unattractive to @xmath8 ) , or not significantly different to one ( neutral ) .",
    "critically , affinities are time - varying , and any identified patterns of variation over time may be related to interpretable events or network changes .    in a first fully bayesian approach to gravity models using mcmc methods , @xcite developed such models in the static case ; i.e. , with no dynamics in the model parameters , and applied the model to a large transportation flow network . @xcite explored a similar approach in studies of patient flows to hospitals .",
    "analysis via mcmc is computationally very demanding , and the burden increases quadratically in @xmath134 , and inherently non - sequentially .",
    "more recently , @xcite studied such models for spread of infectious diseases , and used gaussian process approximations for approximate inference rather than full mcmc or other computational methods .",
    "we share the spirit of this latter work , in using the simply and efficiently implemented bdfm as a path to fitting the gravity model  now extended to time - varying effect parameter processes .",
    "however , we do not constrain the affinity parameters @xmath133 as a function of covariates of any kind , simply treating the dgm as a dynamic , random effects model .",
    "this leads to a _",
    "parameter mapping between the bdfm to the dgm ; as a result , the trivially generated simulations from the full posterior of the bdfm are mapped directly to full posterior samples from the dgm , providing immediate access to inference on main effect and affinity processes over time .",
    "given a set of flow rates @xmath88 for all @xmath135 at each time @xmath6 the mapping to dgm parameters in requires aliasing constraints to match dimensions .",
    "we adopt the common zero - sum constraint on logged values .",
    "define @xmath136 , @xmath137 , @xmath138 and @xmath139 using the @xmath140 notation to denote summation over the range of identified indices , constrain via @xmath141 , @xmath142 for all @xmath143 we then have a bijective map between bdfm and dgm parameters ; given the @xmath88 we can directly compute implied , identified dgm parameters .",
    "the dgm is saturated there are exactly as many parameters in the dgm as there are observations in the data set .",
    "however , the emulating bdfm enforces smoothness over time in parameter process trajectories , and this acts to substantially reduce the effective model dimension one key attribute of the emulation approach .",
    "note that this overall strategy inherently adopts the view that temporal structure for dgm parameter processes are those induced by the mapping from bdfms . in current form ,",
    "the evolution of latent rate processes in the latter are random walks with levels of variation defined by rate - specific discount factor sequences , so the evolutions for the induced dgm parameters will be more elaborate but still basically of random walk form .    define @xmath144 for each @xmath135 at each time @xmath145 then at each time @xmath47 compute the following in the order given :    * the baseline level @xmath146 where @xmath147 ; * for each @xmath59 the origin node main effect @xmath148 where @xmath149 ; * for each @xmath128 the destination node main effect @xmath150 where @xmath151 ; * for each @xmath127 and @xmath128 the affinity @xmath152 where @xmath153    in our data analysis below , we apply this to all simulated @xmath88 from the full posterior analysis under the bdfm to map to posteriors for the dgm parameter processes .",
    "a technical problem with this mapping arises in cases of sparse flows , i.e. , when multiple @xmath7 counts are zero or very small for multiple node pairs .",
    "in such cases the posterior for @xmath88 favors very small values and the log transforms are large and negative , which unduly impacts the resulting overall mean and/or origin or destination means . while one can imagine model extensions to address this , at a practical level it suffices to adjust the mapping as is typically done in related problems of log - linear models of contingency tables with structural zeros @xcite .",
    "this is implemented by simply restricting the summations in identifiability constraints to node pairs for which @xmath154 , for some small @xmath155 and adjusting divisors to count the numbers of terms in each summation . for our study",
    ", we use @xmath156 . with this adjustment ,",
    "very small @xmath157 appropriately lead to very small affinities @xmath158 , i.e. , small rates underlying very sparse flows .",
    "we first apply the gravity model decomposition to the morning data on february 23rd . following bdfm analysis as in section  [ sec : bdfmdata ]",
    ", posterior simulations ( 5,000 monte carlo samples ) of flow rates are mapped to posterior samples from the corresponding dynamic gravity model .",
    ".,width=624 ]    .,width=624 ]    inference on outflow ( origin ) parameters @xmath159 and inflow ( destination ) parameters @xmath160 for six chosen nodes are shown in figures  [ fig : alphat ]  and  [ fig : betat ] .",
    "the posteriors for origin effects show that large - scale domains , such homepage , have higher values of @xmath161 , while domains with low or zero flows , such as science , naturally have lower values . across all domains ,",
    "subsets show similar patterns but there are also major differences apparent .",
    "in particular , the posterior analysis shows that several domains , such as homepage and entertainment , are substantially higher than the average as both origin and destination nodes .",
    "several nodes , such as opinion , have above ( or below ) average destination effects but origin effects about the norm .",
    "these distinctions between the two effects show the roles of @xmath161 and @xmath162 as representing common factors across the origin and destination of the flows node - by - node .",
    "they are also naturally related over time in most domains ; this captures the effect of the overall scale , or popularity , of some domains such as homepage and entertainment here , while also showing up in clearly similar patterns over time in less active domains , such as world .",
    "further , while some trajectories are relatively stable over time , others show marked changes in the node - specific effects over the morning period .",
    "opinion , for example , has a roughly constant and above - average inflow effect for much of the morning , but it decays toward the end of the morning period ; world starts off at a level slightly above the norm in both inflow and outflow effects , which both then increase substantially as the morning progresses ; science , in contrast , has roughly constant effects across the full time period .    for the affinity effects",
    "@xmath158 , we have @xmath163 parameters ( one for each pair of nodes except the unobserved external @xmath126 external flow ) at each time @xmath12 .",
    "the number of effects becomes massive for large @xmath134 . even in this example for illustration , @xmath4 ,",
    "the number of @xmath133 for fixed @xmath12 is 528 , so it is impossible to examine all the results in this paper .",
    "for this reason , we pick up a few affinity effects that may interest readers in terms of interpretation . for affinity @xmath133 with retrospective posterior c.d.f @xmath164",
    ", we introduce the _ bayesian credible value _",
    "@xmath165 as a simple numerical measure of deviation from the  neutral \" value of 1 .",
    "this highlights the practical relevance of the affinity effect and its changes over time .",
    "traffic from homepage to other domains are central to understanding normal patterns of variation as homepage is usually the landing page for visitors . where users tend to go next , and how the flow patterns begin to evolve from homepage generally , is one key interest from the advertisement and marketing viewpoints .",
    "figure  [ fig : gmhome_sci ] displays some relevant summaries for flows from homepage to science .",
    "first , overall counts and also relative frequencies of transitions tend to increase over this morning period .",
    "the bdfm appropriately tracks these slowly evolving trends ( while not , of course , predicting them ) .",
    "second , origin / outflow and destination / inflow parameter processes are relatively constant over time , although the former exhibits a slight increase in the later morning period . of more interest and highlighting the flexibility and incisiveness of the bdfm@xmath126dgm emulation",
    "map the affinity process is clearly time - varying .",
    "initially at reduced levels fox news visitors tend to be much less likely to go to science from homepage during the first half or more of the morning period this trends upwards to be basically negligible in impact after about 35 - 40minutes . note that , while the overall outflow and inflow processes are roughly constant over time for this par of nodes , the raw data indicate continued growth in traffic towards the end of the time period , and thus the model responds by inferring the upward drift in the interaction / affinity process .",
    "the pattern over time of the affinity effect also relates to dynamic sparsity . \"",
    "while we do not have models that are explicitly exploring sparsity in main or interaction effects , the emulation approach has enabled the identification of an interaction / affinity process that is relevant for some period of time but then , practically , irrelevant for others .",
    "in contrast to our easy and scalable methodology , other more formal bayesian approaches to dynamic sparsity modeling  ( e.g. * ? ? ? * ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) are difficult or impossible to reliably implement in a sequential context , being reliant on intense mcmc methods for batch data processing .",
    "we do note , however , that we are not formally testing consistency of posteriors for affinities against the value of 1 , but simply exploring the trajectories to generate insights .",
    "more formal assessment is available , if desired , by considering differences in affinities over time from the full posterior sample .",
    "= homepage @xmath166=science .",
    "as in figures  [ fig : alphat ] and [ fig : betat ] , the + symbols indicate empirical values ( with cases of 0 occupancy leading to missing values ) .",
    "_ upper left : _ posterior trajectory for the latent flow level process @xmath88 with raw counts ( crosses ) . _",
    "upper right : _ posterior trajectory for the transition probability process @xmath86 with raw frequencies ( crosses ) .",
    "_ center left : _ posterior trajectory for the homepage origin ( outflow ) effect process @xmath167 _ center right : _ posterior trajectory for the science destination ( inflow ) effect process @xmath168 _ lower left : _ posterior trajectory for the homepage : science affinity / interaction process @xmath133 . _ lower right : _ corresponding trajectories of bayesian credible values assessing support for @xmath133 near 1 .",
    ", width=624 ]    = homepage @xmath166=entertainment , with details as in figure  [ fig : gmhome_sci ] .",
    ", width=624 ]    a second example , chosen to represent node pairs with high inflow and outflow levels , concerns transitions from homepage to entertainment ; see figure  [ fig : gmhome_ent ] . here",
    "again we see that the trivially implemented emulation approach is able to identify a high level of stability over time in the main effects , while indicating subtle changes to reduced levels of affinity in the latter part of the morning period .",
    "considering the downward trending patterns in raw data / relative frequencies of flows from homepage to entertainment in the latter period , it would not otherwise be easy to isolate these patterns as idiosyncratic to the node pair .",
    "inferences reflected here on the trajectory of the affinity process clearly show significantly reduced levels later on , with @xmath133 falling from around 6.5 to around 5.5 ; relative to the network - wide structure , high affinity is maintained throughout at a practical level , but at a reduced level later on for this node pair .",
    "some heat - maps in figure  [ fig : gmimagesfeb23am ] show aspects of relationships in some estimated dgm parameters across nodes and across time .",
    "these show patterns in the values of the posterior means of @xmath169 over time ; this includes all main effects and the directional affinities / interactions of all network nodes for flows from domain @xmath170 , the homepage . simply for nice \" visual display ,",
    "the nodes are ordered in terms of correlation over time with the estimated homepage outflow effect @xmath171 in all three images .",
    "the values shown are standardized within each image so that the min / max across time are 0/1 .",
    "note common patterns that reflect interdependencies in dynamics across subsets of network nodes .",
    "the @xmath159 image reflects natural evolution in the morning period of traffic from network nodes , showing the increasing rates of transitions from some of the more popular , core domains ( homepage , politics , world , entertainment and others ) in later morning .",
    "the @xmath160 image shows consonant patterns in a subset of these core domains in that their attractiveness increases in later morning but with some clearly different cases . for the homepage affinity processes @xmath172 there are quite a few domains that see increased incremental traffic rates in the first half , or so , of the morning period , which then drop off to low levels later on .",
    "@cc@ outflow effects @xmath159 & inflow effects @xmath160 + , @xmath160 and @xmath173 ( 1=homepage ) .",
    "shading runs from 0 ( dark grey / dark blue in on - line version ) to 1 ( white / yellow in on - line version ) on these standardized scales .",
    "the nodes are ordered based on correlation over time of the main outflow effects @xmath159 with that of homepage ; this is an arbitrary ordering chosen simply for visual presentation .",
    ", title=\"fig:\",width=254 ] & , @xmath160 and @xmath173 ( 1=homepage ) .",
    "shading runs from 0 ( dark grey / dark blue in on - line version ) to 1 ( white / yellow in on - line version ) on these standardized scales .",
    "the nodes are ordered based on correlation over time of the main outflow effects @xmath159 with that of homepage ; this is an arbitrary ordering chosen simply for visual presentation . , title=\"fig:\",width=254 ] +   +      the study covers morning ( 09:0010:00am ) and afternoon ( 01:0002:00pm ) periods on each of 6 days , as already discussed and explored in section  [ sec : bdfmdata ] . moving to the dgm",
    ", we now explore additional features concerning time - of - day effects as well as day - to - day variation .",
    "this is based on running the coupled bdfm - dgm analysis separately on each time period / day .",
    "figure  [ fig : mdall ] shows the dgm trajectories for the retrospective baseline parameter process @xmath174 for each of the 12 fifty - minute intervals . trajectories are similar across days but for notable differences on february 24th and march 3rd . on february 24th , the afternoon flow is significantly lower than the morning flow , while the morning flow that day is much larger than across other days .",
    "one plausible reason is increased morning traffic in response to discussions following the academy awards ceremony , with a resulting lull in the afternoon traffic . the reverse happens on march 3 where , although the morning traffic seems typical , the afternoon traffic is unusually high .",
    "this was the day on which fox news posted an article concerning hillary clinton s use of her personal email account for all correspondence during her tenure as secretary of state .",
    "it is plausible that this led to larger than usual afternoon traffic flows as the controversy unfolded .     across days with 95% intervals .",
    "dark / full lines ( red in the on - line paper ) are for morning periods , lighter / dashed lines are for afternoons .",
    ", width=528 ]    an advantage of the dgm representation is that it allows investigation of such speculative explanations .",
    "for example , examination of destination effects ( not shown ) @xmath175 confirm that the entertainment node was unusually popular on february 24th am , and that the politics and opinion nodes were unusually popular on march 3 pm , compared to similar flows on other days .",
    "in routine use of dynamic models in sequential monitoring of flows , one key interest is that of being sensitive to data patterns that seem outside the norm , i.e. , anomalous , and may reflect events and changes requiring investigation and intervention .",
    "we address this here with methodology based on the concepts and theory underlying bayesian model monitoring in conditionally normal dlms .",
    "while this theory of sequential bayesian model assessment is well - established , it does not seem to have been adapted to apply to dynamic models of counts ; our contributions in this paper include this extension and required customization of the approach .",
    "revert to the generic context of a poisson - gamma model , as in section[sec : gammabetadm ] and appendix  [ app : betagammadm ] , with time @xmath12 count observation @xmath34 and underlying state @xmath37 .",
    "the general strategy here applies to all cases : inflows to any node @xmath9 when @xmath176 as well as transitions from a node @xmath8 to @xmath9 when @xmath177    the sequential bayesian testing approach in dlms  ( * ? ? ?",
    "* chapter 11 ) is extended here to apply to the poisson - gamma dynamic model .",
    "regard the model as the standard model \" at time @xmath47 relabeling the one - step predictive density at each time @xmath12 as @xmath178 the suffix 0 indicates the standard model , and we now explicitly recognize the dependence on the discount factors defining levels of stochastic change in the underlying state process @xmath37 .",
    "the two components of monitoring and adaptation are as follows .    _",
    "a. alternative model predictions : _ a purely synthetic _ alternative model _ at time @xmath12 that requires only the specification of the alternative predictive p.d.f .",
    "@xmath179 , differing from the standard only in the current discount factor @xmath180 this implies that @xmath181 is more diffuse that @xmath182 but similarly located . in our poisson - gamma case , the implied generalized negative binomial p.d.f.s @xmath182 and @xmath181 have precisely the same mean but the latter has a larger variance and gives more support to both smaller and larger values of @xmath34 .    _",
    "b. bayes factor comparisons : _ evaluation of bayes factors comparing the standard model predictive p.d.f.s with the alternative define the monitoring tests .",
    "these marginal likelihood ratios are computed based on both the time @xmath12 observation and recent consecutive observations to assess and compare consistency of this local data with predictions from the standard model relative to the more diffuse synthetic alternative .",
    "support for the standard model is regarded as a business as usual \" signal . a signal of support for the alternative addresses the potential for : ( i ) the single observation to be discrepant , a possible outlier ; ( ii ) a relatively abrupt change in the @xmath37 process at time @xmath12 , beyond that predicted by the model with current discount rate @xmath183 and ( iii ) change in the @xmath37 process at higher levels than the norm , but that are not so abrupt and may have been developing at subtler levels over a few recent time points .",
    "define the following :    * the time @xmath12 bayes factor @xmath184 assessing the current observation alone .",
    "* the _ lag-@xmath185 local bayes factor _",
    "@xmath186 based on the most recent @xmath187 observations , including @xmath188 * the _ local cumulative bayes factor _ @xmath189 and corresponding _ run - length _ @xmath190 such that @xmath191    bayesian testing theory  ( @xcite and chapter 11 of  @xcite ) shows that the local test measures @xmath192 are trivially updated as time evolves . at time @xmath12 , the updated pair is @xmath193 = \\begin{cases }      [ h_t , \\ , 1 ] ,   &   \\textrm{if } l_{t-1}\\ge 1 , \\\\      [ h_t l_{t-1 } , \\ , 1+l_{t-1 } ] , &   \\textrm{if } l_{t-1 } < 1 . \\\\ \\end{cases}\\ ] ] past consistency with the standard model @xmath194 means that the entire focus at time @xmath12 is on the single observation @xmath188 if , however , recent evidence weighs against the standard model @xmath195 , then that evidence continues to accumulate based on the new observation .",
    "the pair @xmath196 $ ] define a tracking signal that can be used to formally intervene by rejecting potential outliers and adopting the smaller discount factor @xmath197 at such times as well as when @xmath198 and/or @xmath190 suggest cumulating changes in the @xmath37 process beyond the norm .",
    "this operates as follows .",
    "specify a bayes factor threshold @xmath199 ( e.g. @xmath200 ) and run - length threshold @xmath15 ( e.g. @xmath201 when standing at time @xmath12 , compute single - period bayes factor @xmath202 . then",
    ":    * if @xmath203 , reject @xmath34 as potentially outlying .",
    "+ @xmath204 intervene to apply reduced discount factor @xmath197 at time @xmath205 in case of changes . * if @xmath206 , then proceed to update @xmath196 $ ] to continue monitoring in case of potential changes .",
    "* * if @xmath207 _ or _ @xmath208 + @xmath204 apply reduced discount factor @xmath197 to allow for adaptation to potential changes ; + @xmath204 update using time @xmath12 data as usual but with this increased prior uncertainty ; + @xmath204 reset monitor to @xmath209 and @xmath210 * * if @xmath211 _ and _ @xmath212 + @xmath204 proceed as usual with prior - posterior and monitor updates .",
    "* forecast ahead as desired , then proceed to time @xmath213    this process is displayed in schematic form in figure  [ fig : flowchart ] of appendix  [ app : monitoring ] , this modified from  ( * ? ?",
    "* chapter 11 ) , which also discusses choices of thresholds @xmath214 .",
    "we follow the recommendations there for these choices . as discussed in sections  [ sec :",
    "inflows ] and [ sec : transits ] , the discount factors in the standard models are based on @xmath215 where , in the generic notation here , @xmath216 is the shape parameter of the time @xmath50 posterior gamma distribution for @xmath56 and @xmath217 a baseline discount rate .",
    "we therefore select the alternative discount factor @xmath197 for the intervention analysis as @xmath218 where for some smaller baseline @xmath219 the studies of fox news network data now mentioned are based on @xmath220 whereas the standard models are based on values of @xmath217 running between 0.9 and 0.99 across the sets of inflow and transition flow models .",
    "one example from the fox news study is summarized in figure  [ fig : monitorhome_world ] . while a rather extreme case in terms of one series of time points where the departure from the steady random - walk evolution of the bfdm is very apparent , this example nicely highlights the efficacy of the on - line monitoring and automated intervention strategy .",
    "the example is transition flows from homepage to world over the february 23rd am period .",
    "= homepage @xmath166=world with bayesian model monitoring and discount - based intervention .",
    "data is from the february 23rd am period . _ upper : _",
    "symbol + indicates observations judged consistent with the standard model ; x indicates cases identified as potential outliers by low @xmath202 ; * indicates those flagged as potential change points via low @xmath198 ; o indicates cases with @xmath221 .",
    "the vertical arrows indicate times of automatic intervention .",
    "the full line and shaded region represent one - step forecast means and 95% intervals .",
    "_ center : _ tracks of @xmath222 ( above center ) and @xmath223 ( below center ) over time .",
    "_ lower : _ data ( + ) with one - step forecast means and 95% intervals from the standard bdfm analysis in light gray ( red in on - line version ) compared to the analysis with monitoring and intervention in black / dark gray ( gray in on - line version ) .",
    ", width=480 ]    there are several periods in which @xmath221 but the evidence against the normal model is not so strong as to signal an exception and call for intervention .",
    "the period around 2325minutes saw a substantial upswing in flows that triggered interventions to adapt three times .",
    "interventions at about 32.5 and 48minutes were triggered by a cumulated run - length @xmath190 suggesting gradual drift from the standard model .",
    "we also note that this picture is very similar when shown in terms of the flow frequencies @xmath224 and conditional transition probabilities @xmath86 rather than raw counts @xmath7 and rates @xmath91 this is an example where there were ( at least ) two periods of change in transition characteristics beyond those defined by the bdfm , but that monitoring and intervention is able to adapt to on - line . in a real - life , sequential context , much more can and should be done , of course , at times of intervention .",
    "the analysis summary here simply serves to show the potential , recognizing that this is applied in parallel across all inflow and node - node transition models in a wholly automated manner .",
    "a second example in figure  [ fig : monitorhome_science ] shows a somewhat more typical stable trajectory , with only two interventions that appropriately adapt to the modest and subtle level changes in the latter part of the time period .",
    "= homepage @xmath166=science under monitoring and intervention , with details as in figure  [ fig : monitorhome_world ] .",
    ", width=480 ]",
    "the bdfm framework is adaptive to time - varying rates of flows within dynamic networks and able to coherently quantify non - stationary changes in within- and into-/out of- network flow rate processes .",
    "this extends and customizes non - stationary process models for count data for transition flows in a network .",
    "novelties include use of relevant occupancy factors to appropriately scale poisson rates in sets of decoupled models , and the introduction of discount factor scheduling to appropriately address problems with , in particular , low flow rates .",
    "sequential analysis of the resulting bayesian dynamic flow model is fast and efficient .",
    "the decoupled analyses yield full posterior distributions for rate parameter process parameters across nodes and pairs of nodes in a scalable manner .",
    "our analysis of the fox news network time series data sets shows the utility of the bdfm in generating initial inferences on flow rate processes , in highlighting differences across days and in generating potential practical leads \" . on the latter , for example",
    ", it is immediately clear from the bdfm results that most visitors go to just one domain , rather than traversing to multiple domains .",
    "this has potential decision implications for computational advertising , and also likely highlights a difference between on - line news consumers and traditional newspaper readers .",
    "the emulation map `` from the bdfm to the dgm represents a strategy of increasing interest in various areas , especially with regard to efficient computation and scalability .",
    "we fit a flexible , adaptive model in a set of decoupled analyses , and then directly map posterior samples to the more substantively interesting parameter processes in a model that is otherwise challenging to fit . applied to the fox news flow data , we show some ( of the many ) examples of how this isolates dynamics in node - specific and interaction effects . in some such cases ,",
    "this indicates time - varying sparsity '' in node - node interaction effects over time , highlighted with our use of bayesian credible values over time : some interaction effects ( affinities ) appear significant at some points in time but not in others . a number of the specific node - node inferences mentioned in the application section highlight additional results of substantive interest , some of which are initially unexpected .",
    "others include a sustained positive affinity of opinion for homepage , but a similarly sustained but negative affinity of science for homepage .",
    "additionally , comparisons across different times of the day and across days identified and quantified patterns related to anomalous flows corresponding to identifiable news events that appear to have driven traffic to specific nodes on the fox news site .    computational demands for the full analysis scale as @xmath225 where @xmath26 is the monte carlo sample size .",
    "analysis is very fast , based on the core modeling and emulation strategy .",
    "a 2016 matlab implementation running on a standard laptop ( 2.3ghz cpu , 16 gb memory ) took less that 5minutes to run our one period context with @xmath226 and @xmath227 one current interest is in developing this in analysis of a more elaborate , sub - domain network of more than 1,000 nodes , currently under development .",
    "additional methodological development concerns the use of formal sequential bayesian model monitoring based on bayes factor tests , and the accompanying automated intervention analysis to allow models to adapt at time of potential change in underlying flow parameter processes beyond normal levels of variation .",
    "importantly , our use of decoupled / recouple models for within - network transitions allows statistically and computationally efficient development of sequential bayesian testing based on bayesian factors related to short - term prediction of each of the individual node - node flows in parallel . at each time point",
    ", the decoupled models are monitored , and any signals of significant departure from predictions may be linked across node pairs to explore for dependencies .",
    "an unusually significant decrease in inflow to entertainment at one time , for example , may come via increased transitions from homepage alone , or represent an entertainment effect evident in flows from other domains as well .",
    "monitoring and change detection in the decoupled bdfms can lead to intervention to modify posteriors one or more of the decoupled posteriors for the @xmath228 but the mapping to the dgm parameters will then quantify and highlight the potential relevance for dependencies as well as interaction / affinity effects .",
    "there are now opportunities to use and develop these models as a basis to characterize the stochastic dynamics of website flows , and hence feed into modeling and decision analysis that addresses the needs to respond to changing patterns in computational advertising .",
    "an ability to rapidly signal potential anomalies in a small subset of domains in real - time will be of huge interest in this field .",
    "more immediately , some of the evident questions arising from the current study concern the overlay of the unbiased \" inferences about changes and structure in network flows with substantive covariate information . in many applications , including computational advertising but also capital and transportation flows , there are useful covariates that could inform the analysis .",
    "our perspective here has been mainly exploratory , aiming to define a formal basis for effectively characterizing non - stationary stochastic dynamics in flow data , and adapting models over time .",
    "one next step is to overlay any particular application with covariate information as descriptive / explanatory as we exemplified with some vignettes from the fox news study .",
    "one aspect of this is to consider random effects representing otherwise unexplained extra - poisson variation that seems relevant in some cases .",
    "a more predictive level would involve extensions to incorporate covariates in the bdfms , so future research in that direction is warranted .",
    "finally , we note that the general context of time - varying traffic flow analysis arises in multiple other fields . beyond in origin - destination analysis and related goals in studies of transportation networks",
    "( e.g. * ? ? ?",
    "* ) and physical traffic  ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) , such data in neural spike train experiments , other varieties of internet traffic , and network studies in areas as diverse as biological anthropology ( e.g. , grooming interactions in primate troops ) , human social networks , flows between institutions in finance and economic networks , and others .",
    "our work here represents new methodology of bayesian dynamic modeling in an application with at least conceptual intersections with some of these areas , and may well be explored in such applications .",
    "this appendix provides additional details and discussion of the gamma - beta  steady \" dynamic model for time - varying poisson rates , extending the background details underlying the core model summarized in section  [ sec : gammabetadm ] .    using generic notation ,",
    "a series of non - negative counts @xmath34 over @xmath1 is modeled via @xmath229 conditionally independently over time , where the underlying / latent poisson rate process @xmath37 follows a gamma - beta stochastic model and each @xmath38 is a scaling constant known at time @xmath62 this is effectively a non - stationary , non - gaussian random walk model , so it has enormous flexibility in adapting to changes over time .",
    "the extent of anticipated stochastic change over time is defined by a discount factor parameter @xmath40 , potentially different at each time @xmath12 .",
    "we detail the model concept and structure , and the implied machinery for bayesian learning and forecasting that includes the forward filtering , backward sampling ( ffbs ) algorithm for conditionally poisson time series coupled with the gamma - beta steady process model .      at time @xmath230",
    "introduce an hypothetical latent state @xmath231 and use @xmath46 as a synthetic notation for all available initial information .",
    "specify an initial gamma prior , so @xmath232 where @xmath233 , @xmath234 are known .    for each @xmath6",
    "the model and forward / sequential analysis are then as follows .",
    "[ [ posterior - at - time - t-1 ] ] posterior at time @xmath50 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    standing at time @xmath50 , the posterior for the current poisson rate given the initial information and all data observed over past times @xmath235 is gamma , @xmath236 where the defining parameters are known , evaluated from past information @xmath237    [ [ evolution - to - time - t ] ] evolution to time @xmath12 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the poisson rate evolves to time @xmath12 via the gamma - beta evolution @xmath238 where the random  shock \" , or innovation , @xmath239 is independent of @xmath240 this is a multiplicative random walk model in that @xmath241 hence the use of the  steady model \" terminology . a lower value of @xmath45 leads to a more diffuse beta innovation distribution and the ability to adapt to changing rates over time , while a value closer to one indicates a steady , stable evolution .",
    "the random walk nature of the model allows for changes , but does not anticipate specific directional changes .",
    "the model results in a fully bayesian solution to rather simple , flexible smoothing of discrete time series in the context of variation in the underlying latent process .",
    "note that the beta innovations distribution for @xmath239 at time @xmath12 depends in the accumulated information content about the time @xmath50 level through the shape parameter @xmath242 the discount factor @xmath45 acts to decrease the information content between times @xmath50 and @xmath12 in a natural way .",
    "that is , information loss rates are constant over time , rather than parameters of the innovation distribution .",
    "the specific choice of beta distribution ensures that the implied time @xmath12 prior has a conjugate gamma form .",
    "[ [ prior - for - time - t ] ] prior for time @xmath12 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the time @xmath50 gamma posterior of   couples with the beta innovation to give the time @xmath50 prior for the next state as @xmath243 here we see the discounting effect of the random walk model : the prior for the evolved rate is more diffuse than the time @xmath50 posterior , reflecting increased uncertainty due to evolution .",
    "[ [ one - step - ahead - predictions ] ] one - step ahead predictions : + + + + + + + + + + + + + + + + + + + + + + + + + + +    predicting the data at time @xmath47 the one - step ahead forecast distribution is generalized negative binomial with p.d.f .",
    "@xmath244 on @xmath245    [ [ posterior - at - time - t ] ] posterior at time @xmath12 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    observing @xmath34 , the resulting posterior is @xmath246 , which has the same form as that at time @xmath50 but with updated parameters @xmath247 and @xmath248 .",
    "a key ingredient of formal model assessment is the model marginal likelihood that , in this first - order markov model , is computed as the product of one - step forecast p.d.f.s evaluated at the realized data . at time",
    "@xmath12 , this product is @xmath249 the product is most usefully written in its one - step updated form @xmath250 where the contribution at time @xmath12 derives from the one - step ahead predictive density of evaluated at the datum @xmath188 these are trivially computed .",
    "one of the most useful roles of the marginal likelihood is in comparing models based on different ( sets of ) discount factor values . as one key special case ,",
    "suppose @xmath251 is fixed over the time period of interest . then   gives the value of the marginal likelihood @xmath252 at any chosen value of @xmath253 in parallel analyses using a discrete set of @xmath254 values , the log of the marginal likelihood is linearly accumulated as data are sequentially processed . at any time @xmath12",
    "this can be mapped to a posterior @xmath255 and then normalized over the grid of values for inference on @xmath254 at any time of interest .",
    "this can be used to identify / choose a modal value for inference on the @xmath37 conditional on a chosen @xmath256 or for model averaging .",
    "the sequentially computed contributions to the marginal likelihood  the realized p.d.f .",
    "ordinates @xmath257can be monitored sequentially over time to provide an on - line tracking of model performance , with potential uses in flagging anomalous data at one node or any subset of nodes , using standard bayesian model monitoring concepts ; see  @xcite , west and harrison ( 1986 , 1989 and chapter 11 of 1997 ) , and  ( * ? ? ?",
    "* section 4.3.8 ) .      reaching the end time @xmath258",
    ", we look back over time and revise the summary posterior distributions for the full trajectory of the latent gamma process @xmath259 based on all the observed data .",
    "this uses backward sampling based on theory in  ( * ? ? ?",
    "* section 10.8 ) ; see also  ( * ? ? ?",
    "* section 4.3.7 and problem 4 of section 4.6 ) .",
    "* sample the final rate from the time @xmath258 posterior @xmath260 .",
    "* recurse back over time @xmath261 , at each stage sampling @xmath37 from the implied @xmath262 via @xmath263 with a  backward innovation \" @xmath264 drawn from @xmath265 , independently of @xmath266    repeating the backward sampling generates a monte carlo sample of the trajectory @xmath259 from the full posterior @xmath267 for summary inferences .",
    "@xmath268{\\txt{time $ t$:\\\\ $ h_t>\\tau$ ? } } \\ar[d]^{\\txt{{{\\color{royalblue3}yes } } } } \\ar[rrd]^{\\txt{{{\\color{brickred}no } } } }          & &                       \\\\      * + [ f]{\\txt{$l_t>\\tau$ { \\em and } $ l_t < k$ ? } }          \\ar[d]^{\\txt{{{\\color{royalblue3}yes } } } } \\ar[rrd]^{\\txt{{{\\color{brickred}no } } } }                        & & * + [ f]{\\txt { { { \\color{brickred}possible outlier ? } } \\\\ - reject $ x_t$ - } } \\ar[d ]       \\\\      * + [ f]{\\txt{{{\\color{royalblue3}model ok } } } } \\ar[d ]                       & & * + [ f]{\\txt { { { \\color{brickred}possible changes ? } } \\\\ intervene : adopt lower $ \\delta_t$                                                          \\\\ prior$\\to$posterior update}}\\ar[lld ]   \\\\      * + [ f]{\\txt{prior$\\to$posterior update\\\\ forecast etc } } \\ar[d ] & & \\\\       * + [ f]{\\txt{time $ t+1 $ : \\\\ $ h_{t+1}>\\tau$ ? } } \\ar@{.>}[d]\\ar@{.>}[rd ] & & \\\\      & & \\\\   } \\ ] ]"
  ],
  "abstract_text": [
    "<S> traffic flow count data in networks arise in many applications , such as automobile or aviation transportation , certain directed social network contexts , and internet studies . using an example of internet browser traffic flow through domains of an international news website , we present bayesian analyses of two linked classes of models which , in tandem , allow fast , scalable and interpretable bayesian inference . </S>",
    "<S> we first develop flexible state - space models for streaming count data , able to adaptively characterize and quantify network dynamics effectively and efficiently in real - time . </S>",
    "<S> we then use these efficiently implemented models as _ emulators _ of more structured , time - varying gravity models that allow closer and formal dissection of network dynamics . </S>",
    "<S> this yields interpretable inferences on traffic flow characteristics , and on dynamics in interactions among network nodes . </S>",
    "<S> bayesian model monitoring theory defines a strategy for sequential model assessment and adaptation in cases of signaled departures of network flow data from model - based predictions . </S>",
    "<S> exploratory and sequential monitoring analyses of evolving traffic on a defined network of web domains in e - commerce demonstrate the utility of this coupled bayesian emulation approach to analysis of streaming network count data .    _ </S>",
    "<S> key words : _ bayesian model emulation , decouple / recouple , dynamic network flow model , dynamic gravity model , monitoring and anomaly detection    0 </S>"
  ]
}