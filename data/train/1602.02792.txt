{
  "article_text": [
    "repeated games , and , in particular , the repeated prisoner s dilemma , have been used extensively to study the reciprocation of cooperative behaviors in social dilemmas @xcite .",
    "these games traditionally involve a sequence of interactions in which two players act simultaneously ( or , at least without knowing the opponent s move ) and condition their decisions on the history of their previous encounters .",
    "even though such synchronized decisions seem often contrived in realistic social interactions , the biologically more realistic and relevant scenario with asynchronous interactions has received surprisingly little attention . in asynchronous games , players take turns and alternate moves in either a strict or random fashion @xcite .    a classic example of an asynchronous game with alternating moves is blood donation in vampire bats @xcite .",
    "when a well - fed bat donates blood to a hungry fellow , the recipient has the opportunity to return the favor at a later time .",
    "similarly , social grooming between two primates is not always performed simultaneously ; instead , one animal grooms another , who then has the opportunity to reciprocate in the future @xcite . on a smaller scale , the biosynthesis of iron - scavenging compounds by microorganisms through quorum sensing can result in asynchronous responses to fellow  players \" in the population @xcite . even for interactions that appear to involve simultaneous decisions , such as in acts of predator inspection by fish @xcite ,",
    "it remains difficult to rule out that these interactions are not instead based on rapid , non - synchronous decisions @xcite .    the iterated prisoner s dilemma game , which involves a choice to either cooperate , @xmath2 , or defect , @xmath3 , in each round , has played a central role in the study of reciprocal altruism @xcite .",
    "rather unexpectedly , after decades of intense study of iterated games , @xcite showed that a player can unilaterally enforce linear payoff relationships in synchronous games .",
    "for example , if @xmath4 and @xmath5 are the expected payoffs to players @xmath0 and @xmath1 , respectively , and @xmath6 is an extortion factor , then player @xmath0 can ensure that @xmath7 , regardless of the strategy of player @xmath1 .",
    "moreover , such linear relationships may be enforced using merely memory - one strategies , which condition the next move on the outcome of just the previous round .",
    "the discovery of these so - called  zero - determinant \" strategies triggered a flurry of follow - up studies .",
    "most notably , from an evolutionary perspective , extortionate strategies fare poorly @xcite but can be stable provided that extortioners recognize one another @xcite . however , generous counterparts of extortionate strategies perform much better in evolving populations @xcite and constitute nash equilibria for the repeated prisoner s dilemma @xcite ( but generally only if there are just two discrete levels of cooperation @xcite ) . against humans ,",
    "extortionate strategies typically underperform generous strategies when the extortioner is also a human @xcite but can outperform generous strategies when the extortioner is a computer @xcite .",
    "thus , for the settings in which zero - determinant strategies are known to exist , their performance is sensitive to the context in which they arise .",
    "our focus here is on extending these strategies further into the domain of alternating interactions from a classical , non - evolutionary viewpoint . in particular , we establish the existence of zero - determinant strategies for several types of alternating interactions between two players .",
    "recently , autocratic strategies were introduced as a generalization of zero - determinant strategies to simultaneous games with arbitrary action spaces @xcite . an autocratic strategy for player",
    "@xmath0 is any strategy that , for some constants @xmath8 , @xmath9 , and @xmath10 ( not all zero ) , enforces the linear relationship    @xmath11    on expected payoffs every strategy of player @xmath1 . here",
    ", we consider autocratic strategies in alternating games . in a strictly - alternating game",
    ", one player moves first ( either @xmath0 or @xmath1 ) and waits for the opponent s response before moving again .",
    "this process then repeats , with each player moving only after the opponent moved ( see fig .",
    "[ fig : strictistrictiirandom](a),(b ) ) .",
    "in contrast , in a randomly - alternating game , the player who moves in each round is chosen stochastically : at each time step , @xmath0 moves with probability @xmath12 and @xmath1 moves with probability @xmath13 for some @xmath14 ( see fig .",
    "[ fig : strictistrictiirandom](c ) ) .",
    "note that only for @xmath15 is it the case that both players move , on average , equally often .",
    "previous studies of zero - determinant strategies have focused on enforcing linear payoff relationships using conditional responses with short memories .",
    "a player using a memory - one strategy determines his or her response ( stochastically ) based on the outcome of just the previous round .",
    "although strategies with longer memory length have been shown to help establish cooperation @xcite , they are not always reliably implemented in players with limited memory capacity ( including humans ) @xcite . here , we follow the tradition of concentrating on shorter - memory strategies . in particular",
    ", we establish the existence of memory - one autocratic strategies for alternating games and give several simple examples that enforce linear payoff relationships for every strategy of the opponent ( even those with unlimited memory ) .    in the classical donation game @xcite , a player either ( i ) cooperates and donates @xmath16 to the opponent at a cost of @xmath17 or ( ii ) defects and donates nothing and pays no cost , which yields the payoff matrix    @xmath18    and represents an instance of the prisoner s dilemma",
    "provided that benefits exceed the costs , @xmath19 .",
    "the continuous donation game extends this binary action space and allows for a continuous range of cooperation levels @xcite .",
    "an action in this game is an investment level , @xmath20 , taken from an interval , @xmath21 $ ] , where @xmath22 indicates an upper bound on investments .",
    "based on its investment level , @xmath20 , a player then pays a cost of @xmath23 to donate @xmath24 to the opponent where @xmath25 and @xmath26 are continuous non - decreasing functions with @xmath27 for @xmath28 and @xmath29 ; an investment of zero corresponds to defection , which neither generates benefits nor incurs costs @xcite .",
    "biologically - relevant interpretations of continuous investment levels ( as well as alternating moves ) include ( i ) the effort expended in social grooming and ectoparasite removal by primates @xcite ; ( ii ) the quantity of blood donated by one vampire bat to another @xcite ; ( iii ) the amount of iron - binding agents ( siderophores ) produced by bacterial parasites @xcite ; and ( iv ) the honesty level of a ( human ) party involved in a trade agreement @xcite .",
    "in alternating games , the assignment of payoffs to players deserves closer inspection @xcite . here , we focus on alternating games in which both players obtain payoffs after every move ( like in the continuous donation game ) ( see fig .",
    "[ fig : strictistrictiirandom ] ; * ? ? ?",
    "alternatively , payoffs could result from every pair of moves rather than every individual move @xcite .",
    "while it is possible to construct a theory of autocratic strategies for strictly - alternating games in either setting , it becomes difficult to even define payoffs in the latter setup for randomly - alternating games because either player can move several times in a row ( see fig .",
    "[ fig : strictistrictiirandom](c ) ) . therefore , we follow @xcite in order to include the particularly relevant and intriguing case of randomly - alternating games .",
    "randomly - alternating games seem more relevant for modeling biological interactions because often strict alternation can not be maintained or enforced , or the players find themselves in different roles , which translate into different propensities to move . to accommodate these situations",
    ", we consider a class of randomly - alternating games in which the probability that player @xmath0 moves in a given round , @xmath12 , is not necessarily @xmath30 . any other value of @xmath12 results in asymmetric interactions  even if the payoffs in each encounter are symmetric  simply because one player moves more often than the other .",
    "for example , dominance hierarchies in primates naturally result in asymmetric behavioral patterns @xcite .",
    "in male chimpanzees , dominance hierarchies require smaller , subordinate chimpanzees to groom larger , dominant chimpanzees more often than vice versa @xcite .",
    "therefore , including such asymmetries significantly expands the scope of interactions to which the theory of autocratic strategies applies .",
    "in every round of an alternating game , either player @xmath0 or player @xmath1 moves . on player @xmath0 s turn , she chooses an action , @xmath31 , from an action space , @xmath32 , and gets a payoff @xmath33 while her opponent gets @xmath34 .",
    "similarly , when player @xmath1 moves , he chooses an action , @xmath35 , from @xmath36 and gets a payoff @xmath37 while his opponent gets @xmath38 .",
    "future payoffs are discounted by a factor @xmath39 ( with @xmath40 ) , which can represent a time preference @xcite that is derived , for example , from interest rates for monetary payoffs .",
    "alternatively , @xmath39 can be interpreted as the probability that there will be another round , which results in a finitely - repeated game with an average length of @xmath41 rounds @xcite .      in a pair of rounds in which player @xmath0 moves before @xmath1 ,",
    "the payoffs are @xmath42 and @xmath43 , respectively .",
    "note that the payoffs from @xmath1 s move are discounted by a factor of @xmath39 because @xmath1 moves one round after @xmath0 .",
    "the payoff functions , @xmath44 and @xmath45 , satisfy the ",
    "equal gains from switching \" property @xcite , which means the difference between @xmath46 and @xmath47 is independent of the opponent s move , @xmath35 .",
    "this property follows immediately from the fact that @xmath44 ( or @xmath45 ) is obtained by adding the separate contributions based on the moves of @xmath0 and @xmath1 .",
    "thus , if player @xmath0 moves first and @xmath48 is the sequence of play , then her average payoff is    @xmath49 = \\left(1-\\lambda\\right)\\sum_{t=0}^{\\infty}\\lambda^{2t}u_{x}\\left(x_{2t},y_{2t+1}\\right ) .\\end{aligned}\\ ] ]    the second expression resembles the average payoff for a simultaneous - move game whose one - shot payoff function is @xmath44 @xcite .",
    "similarly , replacing @xmath44 with @xmath45 yields player @xmath1 s average payoff , @xmath5 .    for strictly - alternating games ,",
    "we borrow the term  memory - one strategy \" from synchronous games to mean a conditional response based on the previous moves of both players .",
    "even though this memory now covers two rounds of interactions , it remains meaningful because player @xmath1 always moves after player @xmath0 ( or vice versa ) .",
    "for an arbitrary action space , @xmath50 , a memory - one strategy for player @xmath0 formally consists of an initial action , @xmath51 , and a memory - one action , @xmath52 $ ] , which are both probability distributions on @xmath50 . since player @xmath0 moves first , she bases her initial action on @xmath51 and subsequently uses the two previous moves , @xmath31 and @xmath35 , to choose an action in the next round using @xmath52 $ ] ( see fig .",
    "[ fig : memoryonestrategies ] for graphical depictions ) .     in a strictly - alternating game",
    "whose action spaces are @xmath53 $ ] for some @xmath54 .",
    "( a ) depicts a reactive stochastic strategy in which solely @xmath1 s last move is used to determine the probability distribution with which @xmath0 chooses her next action .",
    "the mean of this distribution is an increasing function of @xmath35 , which means that @xmath0 is more likely to invest more ( play closer to @xmath22 ) as @xmath35 increases .",
    "( b ) illustrates a reactive two - point strategy , i.e. a strategy that plays only two actions , @xmath55 ( defect ) or @xmath22 ( fully cooperate ) .",
    "player @xmath1 s last move is used to determine the probability with which @xmath0 plays @xmath22 in the next round ; if @xmath0 does not use @xmath22 , then she uses @xmath55 . as @xmath1 s",
    "last action , @xmath35 , increases , @xmath0 is more likely to reciprocate and use @xmath22 in response .",
    "( c ) shows a strategy that gives @xmath0 s next move deterministically as a function of both of the players last moves . unlike in ( a ) and ( b ) , @xmath0 s next move",
    "is uniquely determined by her own last move , @xmath31 , and the last move of her opponent , @xmath35 .",
    "if @xmath1 used @xmath56 in the previous round , then @xmath0 responds by playing @xmath55 as well .",
    "@xmath0 s subsequent action is then an increasing function of @xmath35 whose rate of change is largest when @xmath0 s last move , @xmath31 , is smallest . in particular ,",
    "if @xmath1 used @xmath57 in the previous round , then @xmath0 s next action is a decreasing function of her last move , @xmath31 . therefore , in ( c ) , @xmath0 exploits players who are unconditional cooperators .",
    "[ fig : memoryonestrategies ] ]    [ thm : strictx ] suppose that    @xmath58\\left(s\\right ) - \\left(1-\\lambda^{2}\\right)\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right)\\end{aligned}\\ ] ]    holds for some bounded @xmath59 and for each @xmath60 and @xmath61 .",
    "then , if player @xmath0 moves first , the pair @xmath62\\right)$ ] allows @xmath0 to enforce the equation @xmath63 for every strategy of player @xmath1 .",
    "a proof of this result may be found in supporting information .",
    "note that the average payoff , @xmath4 , of eq .",
    "( [ eq : expectedxfirst ] ) is the same as in a simultaneous - move game whose payoff function is @xmath64 and whose discounting factor is @xmath65 @xcite .",
    "hence , it is not so surprising that autocratic strategies exist in this case too ( and under similar conditions ) .",
    "however , the situation changes if @xmath1 moves first and @xmath66 is the sequence of play . in this case , @xmath0 s average payoff is    @xmath67 .\\end{aligned}\\ ] ]    when @xmath1 moves first , player @xmath0 s initial move , @xmath68 $ ] , is now a function of @xmath1 s first move , @xmath69 .",
    "however , @xmath0 s lack of control over the first round does not ( in general ) preclude the existence of autocratic strategies :    [ thm : stricty ] suppose that    @xmath70\\left(s\\right ) - \\left(1-\\lambda^{2}\\right)\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left[y_{0}\\right]\\left(s\\right)\\end{aligned}\\ ] ]    holds for some bounded @xmath59 and for each @xmath60 and @xmath71 .",
    "then , if player @xmath0 moves second , the pair @xmath72,\\sigma_{x}\\left[x , y\\right]\\right)$ ] allows @xmath0 to enforce the equation @xmath63 for every strategy of player @xmath1 .    for a proof of this statement , see supporting information .",
    "note that eq .",
    "( [ eq : mainequationstrictii ] ) is slightly more restrictive than eq .",
    "( [ eq : mainequationstricti ] ) because player @xmath0 has no control over the outcome of the initial round . evidently , for undiscounted ( infinite ) games ( @xmath73 ) , it is irrelevant who moves first and hence the conditions for the existence of autocratic strategies coincide ( c.f .",
    "( [ eq : mainequationstricti ] ) and ( [ eq : mainequationstrictii ] ) ) .      in a randomly - alternating game ,",
    "the player who moves in any given round is determined probabilistically : player @xmath0 moves with probability @xmath12 and player @xmath1 with probability @xmath13 .",
    "suppose that @xmath0 and @xmath1 each make plans to play @xmath74 and @xmath75 at time @xmath76 , respectively , assuming they move at time @xmath76 .",
    "then , in the repeated game , these strategies give player @xmath0 an average payoff of    @xmath77    @xmath1 s average payoff , @xmath5 , is obtained from eq .",
    "( [ eq : payrandom ] ) by replacing @xmath78 and @xmath79 by @xmath80 and @xmath81 , respectively .    for randomly - alternating games ,",
    "we need to reconsider the concept of memory - one strategies .",
    "if moves alternate randomly , then a logical extension is provided by a conditional response based on the previous move as well as on which player moved . in particular ,",
    "@xmath82 $ ] denotes a mixed action for player @xmath0 after player @xmath1 uses @xmath35 in the previous round , and @xmath83 $ ] denotes a mixed action after playing @xmath31 herself .",
    "note that the cognitive requirement in terms of memory capacity in strictly - alternating games remains the same as for simultaneous games , whereas for randomly - alternating games the requirements are significantly less demanding as reflected in two univariate response functions as compared to response functions involving two variables . for two - action games ( such as the classical donation game ) , however , memory - one strategies for synchronous , strictly - alternating , and randomly - alternating games all reduce to four - tuples of probabilities ( see  [ sec : classicaldg ] below ) .    rather surprisingly , randomly - alternating games also admit autocratic strategies :    [ thm : random ] if , for some bounded @xmath59 ,    [ eq : mainequationrandom ] @xmath84\\left(s\\right ) -\\left(1-\\lambda\\right)\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) ; \\\\",
    "\\alpha g_{x}\\left(y\\right ) + \\beta g_{y}\\left(y\\right ) + \\gamma & = -\\lambda",
    "\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,\\sigma_{x}^{y}\\left[y\\right]\\left(s\\right ) -\\left(1-\\lambda\\right)\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) \\end{aligned}\\ ] ]    for each @xmath60 and @xmath61 , then the strategy @xmath85 , \\sigma_{x}^{y}\\left[y\\right]\\right)$ ] allows @xmath0 to enforce the equation @xmath63 for every strategy of player @xmath1 .    for a proof of this result , we refer the reader to supporting information .",
    "however , through examples we demonstrate in  [ sec : classicaldg ] and  [ sec : cdg ] that autocratic strategies do require that player @xmath0 moves sufficiently often , i.e. condition eq .",
    "( [ eq : mainequationrandom ] ) implicitly puts a lower bound on @xmath12 .",
    "theorems [ thm : strictx ] , [ thm : stricty ] , and [ thm : random ] give conditions under which @xmath0 can enforce @xmath63 for every strategy of player @xmath1 .",
    "although @xmath0 is using a memory - one strategy to enforce this linear relationship , we make no assumptions on @xmath1 s strategy ; it can be any behavioral strategy with arbitrary ( even infinite ) memory . for two - action ( and undiscounted ) games with simultaneous moves , @xcite",
    "show that if @xmath0 uses a memory - one strategy , then the strategy of @xmath1 may also be assumed to be memory - one .",
    "while this result is required for the use of their  determinant trick \" to establish the existence of zero - determinant strategies , it is not needed here due to a technique of @xcite .",
    "further details are in supporting information .",
    "while our main results hold for alternating games with generic action spaces , we first illustrate their implications for the classical , two - action donation game . the classical donation game , whose payoff matrix is given by eq .",
    "( [ eq : donationpayoffmatrix ] ) , is based on the discrete actions of cooperate , @xmath2 , and defect , @xmath3 . without discounting , initial moves do not matter and hence a memory - one strategy for player @xmath0 is defined by a four - tuple , @xmath86 , where @xmath87 is the probability that @xmath0 cooperates after @xmath0 plays @xmath31 and @xmath1 plays @xmath35 for @xmath88 . in the simultaneous - move donation game , @xcite",
    "show that for @xmath6 ,    @xmath89    unilaterally enforces the extortionate relationship @xmath7 provided that a normalization factor , @xmath90 , exists .    in undiscounted ( infinite ) and strictly - alternating games , we know from eqs .",
    "( [ eq : mainequationstricti ] ) and ( [ eq : mainequationstrictii ] ) that player @xmath0 does not need to take into account who moves first when devising an autocratic strategy and , moreover , the conditions become identical to those for simultaneous games @xcite .",
    "therefore , player @xmath0 can use a single strategy to enforce @xmath7 in both simultaneous and strictly - alternating games . for discounted ( finite ) games ,",
    "however , autocratic strategies depend on whether the moves are simultaneous or strictly - alternating , but the condition on the discounting factor guaranteeing their existence , @xmath91 , does not .    in the undiscounted but randomly - alternating donation game ,",
    "player @xmath0 moves with probability @xmath12 and player @xmath1 with probability @xmath13 in each round . a memory - one strategy for player @xmath0",
    "is given by @xmath92 and @xmath93 , where @xmath94 ( resp .",
    "@xmath95 ) denotes the probability that @xmath0 plays @xmath2 if @xmath0 moved @xmath31 ( resp .",
    "@xmath1 moved @xmath35 ) in the preceding round . in this game , player @xmath0 can enforce @xmath7 with    @xmath96    provided that the normalization factor , @xmath90 , falls within the range    @xmath97    the existence of such a @xmath90 in this range requires that @xmath0 moves sufficiently frequently , i.e.    @xmath98    otherwise , player @xmath0 loses control over the outcome of the game and can no longer enforce a linear payoff relationship . the autocratic strategy defined by eq .",
    "( [ eq : pdiscretealternating ] ) is unforgiving and always responds to defection with defection but more readily cooperates than its counterpart for simultaneous or strictly - alternating donation games , defined by eq .",
    "( [ eq : pdiscrete ] ) , since @xmath99 and @xmath100 .",
    "in the continuous donation game , the action space available to players @xmath0 and @xmath1 is an interval @xmath21 $ ] , which indicates a continuous range of cooperative investment levels with an upper bound @xmath54 .",
    "if @xmath0 plays @xmath101 $ ] , she donates @xmath102 to her opponent at a cost @xmath103 to herself with @xmath104 for @xmath105 and @xmath29 @xcite .",
    "this game is symmetric with @xmath106 and @xmath107 .      for each variant of alternating moves , we consider three particularly important classes of autocratic strategies for the continuous donation game : equalizer , extortionate , and generous .",
    "an equalizer strategy is an autocratic strategy that allows @xmath0 to unilaterally set either @xmath108 ( self - equalizing ) or @xmath109 ( opponent - equalizing ) @xcite . in all scenarios ,",
    "we show that no self - equalizing strategies exist that allow player @xmath0 to set @xmath108 for @xmath110 .",
    "however , player @xmath0 can typically set the score of her opponent .",
    "equalizer strategies are defined in the same way for alternating and simultaneous - move games , whereas extortionate and generous strategies require slightly different definitions . in the simultaneous version of the continuous donation game , player",
    "@xmath0 can enforce the linear relationship @xmath111 for any @xmath6 and @xmath112 , provided @xmath39 is sufficiently close to @xmath113 @xcite .",
    "note that the  baseline payoff , \" @xmath114 , indicates the payoff of an autocratic strategy against itself @xcite .",
    "if @xmath115 and @xmath116 , then such an autocratic strategy is called  extortionate \" since it ensures that the expected payoff of player @xmath0 is at least that of player @xmath1 .",
    "conversely , if @xmath117 , then this strategy is called  generous \" ( or  compliant \" ) since it ensures that the expected payoff of player @xmath0 is at most that of player @xmath1 @xcite .",
    "the bounds on @xmath114 arise from the payoffs for mutual cooperation and mutual defection in repeated games .",
    "of course , in the simultaneous - move game , those bounds are the same as the payoffs for mutual cooperation and defection in one - shot interactions .",
    "discounted ( finite ) , alternating games , on the other hand , result in asymmetric payoffs even if the underlying one - shot interaction is symmetric .",
    "for example , if player @xmath0 moves first in the strictly - alternating , continuous donation game , and if both players are unconditional cooperators , then @xmath118 but @xmath119 , which are not equal for discounting factors @xmath120 .",
    "thus , rather than comparing both @xmath4 and @xmath5 to the same payoff , @xmath114 , it makes more sense to compare @xmath4 to @xmath121 and @xmath5 to @xmath122 for some @xmath121 and @xmath122 .",
    "therefore , we focus on conditions that allow player @xmath0 to enforce @xmath123 for @xmath121 and @xmath122 within a suitable range .",
    "note that if player @xmath0 enforces this payoff relation and , conversely , player @xmath1 enforces @xmath124 for some @xmath115 , then player @xmath0 gets @xmath121 and @xmath1 gets @xmath122 , which preserves the original interpretation of @xmath114 as the  baseline payoff \" @xcite .",
    "also note that the two strategies enforcing the respective payoff relation need not be the same due to the asymmetry in payoffs , which arises from the asymmetry induced by alternating moves .    for @xmath125 ,",
    "let @xmath126 and @xmath127 be the baseline payoffs to players @xmath0 and @xmath1 , respectively , when @xmath0 uses @xmath20 unconditionally and @xmath1 uses @xmath128 unconditionally in the repeated game . for sufficiently weak discounting factors , @xmath39 , player",
    "@xmath0 can enforce @xmath123 for any alternating game if and only if    @xmath129    where @xmath130 .",
    "( [ eq : kappainequalities ] ) implies that if player @xmath0 attempts to minimize player @xmath1 s baseline payoff , @xmath122 , for a fixed @xmath121 , then @xmath131 .",
    "hence player @xmath0 enforces @xmath132 , or @xmath7 .",
    "such an autocratic strategy is called  extortionate \" since it minimizes the baseline payoff of the opponent , or , equivalently , it minimizes the difference @xmath133 .",
    "conversely , if player @xmath0 tries to maximize @xmath1 s baseline payoff , then @xmath134 and @xmath0 enforces the equation @xmath135 .",
    "this type of autocratic strategy is called  generous \" since it maximizes the baseline payoff of the opponent , or , equivalently , it maximizes the difference @xmath133 .",
    "therefore , qualitatively speaking , in spite of the more detailed considerations necessary for alternating games , the introduction of distinct baseline payoffs for players @xmath0 and @xmath1 does not affect the spirit in which extortionate and generous strategies are defined .",
    "interestingly , and somewhat surprisingly , it is possible for player @xmath0 to devise an autocratic strategy based on merely two distinct actions , @xmath136 and @xmath137 , despite the fact that her opponent may draw on a continuum of actions @xcite . in strictly - alternating games ,",
    "such a  two - point \" strategy adjusts @xmath138 ( resp .",
    "@xmath139 ) , the probability of playing @xmath136 ( resp .",
    "@xmath137 ) , in response to the previous moves , @xmath31 and @xmath35 , while the actions @xmath136 and @xmath137 themselves remain unchanged .",
    "these strategies are particularly illustrative because they admit analytical solutions and simpler intuitive interpretations . in",
    "the following we focus first on two - point autocratic strategies for player @xmath0 based on the two actions of full cooperation , @xmath22 , and defection , @xmath55 . for each variant of alternating game , we derive stochastic two - point strategies enforcing extortionate , generous , and equalizer payoff relationships . for the more interesting case of randomly - alternating moves ,",
    "we also give deterministic analogues of these strategies that use infinitely many points in the action space .",
    "the baseline payoffs for full , mutual cooperation if player @xmath0 moves first are    @xmath140    while the baseline payoffs for mutual defection are always @xmath130 .",
    "the function @xmath141 conveniently eliminates @xmath31 from eq .",
    "( [ eq : mainequationstricti ] ) . for",
    "sufficiently long interactions or weak discounting factors , i.e.    @xmath142    the two - point strategy defined by    @xmath143    allows player @xmath0 to unilaterally enforce @xmath123 as long as @xmath144 falls within a suitable range ( see eq .",
    "( [ sieq : extgenstrictinitial ] ) ) and @xmath145 . whether the autocratic strategy defined by @xmath146 is extortionate or generous depends on the choice of @xmath147 , @xmath121 , and @xmath122 .",
    "note that @xmath148 does not depend on player @xmath0 s own previous move , @xmath31 , and hence represents an instance of a reactive strategy @xcite .",
    "similarly , choosing @xmath149 again eliminates @xmath31 from eq .",
    "( [ eq : mainequationstricti ] ) but now enables player @xmath0 to adopt an equalizer strategy and set her opponent s score to @xmath109 with @xmath150 by using    @xmath151    provided the initial probability of cooperation , @xmath144 , falls within a feasible range ( see eq .",
    "( [ sieq : equalizerstrictinitial ] ) ) .",
    "however , just like in the simultaneous - move game , player @xmath0 can never set her own score ( see * ? ? ?",
    "the baseline payoffs for full cooperation if player @xmath1 moves first are    @xmath152    and , again , the baseline payoffs for mutual defection are both @xmath55 .",
    "the scaling function @xmath153 eliminates @xmath31 from eq .",
    "( [ eq : mainequationstrictii ] ) . for sufficiently weak discounting , i.e. if eq .",
    "( [ eq : strictlambdainequality ] ) holds , the autocratic , reactive strategy , that cooperates ( plays @xmath22 ) with probability    @xmath154    after player @xmath1 moved @xmath35 , then enables player @xmath0 to unilaterally enforce @xmath123 whenever @xmath155 . again , whether @xmath148 translates into an extortionate or generous strategy depends on @xmath147 , @xmath121 , and @xmath122 .",
    "note that the first move of @xmath0 depends on simply her opponent s initial move and hence does not need to be specified separately .",
    "similarly , setting @xmath156 also eliminates @xmath31 from eq .",
    "( [ eq : mainequationstrictii ] ) but enables player @xmath0 to enforce @xmath109 with @xmath157 , which implicitly requires @xmath158 .",
    "this equalizer strategy plays @xmath22 with probability    @xmath159    after player @xmath1 played @xmath35 .",
    "although player @xmath0 can set the score of player @xmath1 , she can not set her own score .      in randomly - alternating games ,",
    "the average payoffs , @xmath4 and @xmath5 , for players @xmath0 and @xmath1 , respectively , depend on the probability @xmath12 with which player @xmath0 moves in any given round ; see eq .",
    "( [ eq : payrandom ] ) .",
    "the region spanned by feasible payoff pairs , @xmath160 , not only depends on @xmath12 but also on the class of strategies considered ; see fig .",
    "[ fig : feasibleregion ] .    , when @xmath0 uses a two - point strategy ( hatched ) and when @xmath0 uses the entire action space ( light blue ) .",
    "the benefit function is @xmath161 , the cost function is @xmath162 , and the action spaces are @xmath163 $ ] ( see * ? ? ?",
    "the probability that player @xmath0 moves in any given round is ( a ) @xmath164 , ( b ) @xmath165 , and ( c ) @xmath166 . in each figure , the payoffs for mutual defection ( @xmath55 ) are indicated by a red point and for mutual full - cooperation ( @xmath167 ) by a green point .",
    "the blue point marks the payoffs when @xmath0 defects and @xmath1 fully cooperates , and the magenta point vice versa . from (",
    "a ) and ( c ) , we see that if @xmath168 , then the payoffs for the alternating game are typically asymmetric even though the one - shot game is symmetric.[fig : feasibleregion ] ]    in particular , the two - point strategies based on the extreme actions , @xmath55 and @xmath22 , cover only a portion of the payoff region spanned by strategies utilizing the full action space , @xmath21 $ ] .",
    "we use both two - point and deterministic autocratic strategies for illustrations as they are among the more straightforward ways in which to enforce linear payoff relationships .      here , we focus on these two - point autocratic strategies for player @xmath0 , which are concentrated on the two points @xmath55 and @xmath22 and are defined by ( i ) the probability that @xmath0 uses @xmath22 in the first round , @xmath144 ; ( ii ) the probability that @xmath0 uses @xmath22 following her own move in which she used @xmath31 , @xmath169 ; and ( iii ) the probability that @xmath0 uses @xmath22 following her opponent s move in which he used @xmath35 , @xmath170 .    for randomly - alternating moves ,",
    "the baseline payoffs for full cooperation are    @xmath171    while those for mutual defection remain both @xmath55 .",
    "suppose that discounting is sufficiently weak , or interactions cover sufficiently many rounds , i.e.    @xmath172    and that @xmath155 .",
    "then , the two - point autocratic strategy defined by    @xmath173    enables player @xmath0 to unilaterally enforce @xmath123 provided @xmath144 falls within a suitable range ( see eq .",
    "( [ sieq : extgenrandominitial ] ) ) .",
    "the scaling function @xmath174 was chosen such that @xmath0 s response depends on the previous action but not on which player used it .",
    "if player @xmath0 is at least as likely to move in each round as is player @xmath1 , i.e. @xmath175 , then , for every @xmath6 , a sufficiently weak discounting factor exists that satisfies eq .",
    "( [ eq : donationextortioncondition ] ) and @xmath176 and hence enables player @xmath0 to enforce @xmath123 .",
    "in particular , both extortionate and generous autocratic strategies exist for the randomly - alternating , continuous donation game ; see fig .",
    "[ fig : twopointsimulation ] .     defects and @xmath1 fully cooperates in every round , and the magenta point vice versa . in the top row , both players move with equal probability in a given round ( @xmath165 ) , whereas in the bottom row player @xmath0 moves twice as often as player @xmath1 ( @xmath166 ) .",
    "the extortionate strategies in ( a ) and ( d ) enforce @xmath7 , while the generous strategies in ( b ) and ( e ) enforce @xmath135 with @xmath177 ( black ) and @xmath178 ( blue ) .",
    "the equalizer strategies in ( c ) and ( f ) enforce @xmath109 with @xmath179 ( black ) and @xmath180 ( blue ) . the simulation data in each panel show the average payoffs , @xmath181 , for player @xmath0 s two - point strategy against @xmath182 random memory - one strategies for player @xmath1 .",
    "the benefit function is @xmath161 and the cost function is @xmath162 for action spaces @xmath163 $ ] .",
    "[ fig : twopointsimulation ] ]    similarly , an equalizing two - point strategy for player @xmath0 can ensure @xmath109 for any    @xmath183    @xmath0 can enforce such a relationship using the two - point strategy defined by    @xmath184    provided @xmath144 falls within a specified range ( see eq .",
    "( [ sieq : equalizerrandominitial ] ) ) .",
    "note that player @xmath0 is unable to unilaterally set the payoff of player @xmath1 to anything below unconditional defection , @xmath55 , and beyond unconditional cooperation , @xmath185 ; see supporting information for further details .",
    "moreover , it must be true that @xmath186 . for @xmath165 , the discounting factor , @xmath39 , must therefore satisfy @xmath187 , which enables player @xmath0 to set @xmath1 s score to anything between @xmath55 and @xmath188 . in the limit where player @xmath0 moves exclusively , @xmath189 , player @xmath1 s score can be set to at most @xmath190 , which , itself , is clear from the definition of the continuous donation game .",
    "although player @xmath0 can unilaterally set @xmath1 s score , she can not set her own score to anything above @xmath55 , and , for @xmath191 , she can not set her own score to anything at all .",
    "for sufficiently large @xmath192 , player @xmath0 can guarantee herself non - positive payoffs using an autocratic strategy ; see supporting information .",
    "however , strategies enforcing a return that is at most @xmath55 may be of limited use since a player can always do at least as well through unconditional defection .",
    "in contrast , in the simultaneous version of the continuous donation game , player @xmath0 can never set her own score @xcite .",
    "this difference is not that surprising : even though player @xmath0 can exert control over randomly - alternating games for large @xmath12 , the structure of the continuous donation game precludes her from providing herself positive payoffs through actions of her own .",
    "deterministic strategies , for which @xmath0 reacts to the previous move by playing an action with certainty ( rather than probabilistically ) , cover a broader range of feasible payoffs ( see fig .",
    "[ fig : feasibleregion ] ) than do two - point strategies ( see also * ? ? ?",
    "a simple example of a deterministic strategy is tit - for - tat , which cooperates in the first round and subsequently copies the opponent s previous move @xcite .    a deterministic strategy for a randomly - alternating game consists of ( i ) an initial action , @xmath193 ; ( ii ) a reaction function to one s own move , @xmath194 ; and ( iii ) a reaction function to the opponent s move , @xmath195 .",
    "here , we give examples of deterministic extortionate , generous , and equalizer strategies for the continuous donation game .",
    "for example , player @xmath0 can enforce @xmath123 by using    @xmath196    where @xmath197 denotes the inverse of the function @xmath198 , provided the initial action , @xmath193 , is chosen appropriately .",
    "for instance , if @xmath199 and @xmath200 , then @xmath0 may use @xmath201 to enforce the extortionate relationship @xmath7 .",
    "if @xmath202 and @xmath203 , then @xmath0 may use @xmath204 to enforce the generous relationship @xmath135 . in both cases , @xmath39 must satisfy eq .",
    "( [ eq : donationextortioncondition ] ) for @xmath205 and @xmath206 to be well - defined reaction functions .",
    "similarly , @xmath0 can unilaterally equalize @xmath1 s payoff to @xmath109 by using    @xmath207    if @xmath179 , then player @xmath0 may use @xmath201 ; if @xmath180 , then @xmath0 may use @xmath204 . the feasible payoff regions and simulation data for each of these classes of autocratic strategies",
    "are given in fig .",
    "[ fig : deterministicsimulation ] .    ) . in ( a )",
    ", extortionate strategies enforce @xmath7 and in ( b ) , generous strategies enforce @xmath135 with @xmath177 ( black ) and @xmath178 ( blue ) . in ( c ) ,",
    "equalizer strategies enforce @xmath109 with @xmath179 ( black ) and @xmath180 ( blue ) .",
    "since deterministic strategies utilize a larger portion of the action space than two - point strategies , the players can attain a broader range of payoff pairs , @xmath181 ( c.f . fig .",
    "[ fig : twopointsimulation ] ) .",
    "the simulation data in each panel shows the average payoffs , @xmath181 , for @xmath0 s deterministic strategy against @xmath182 randomly - chosen , memory - one strategies of the opponent .",
    "the benefit function is @xmath161 and the cost function is @xmath162 for @xmath208 $ ] .",
    "[ fig : deterministicsimulation ] ]    what is noteworthy about these strategies is that they require only the last move and not who played it . in other words ,",
    "a player using one of these strategies responds to a move by herself in exactly the same way as she responds to a move by her opponent .",
    "although a player never knows in advance when she will move in a randomly - alternating game , she can still enforce extortionate , generous , and equalizer relationships on payoffs by playing an action that is uniquely determined by the most recent action of the game .",
    "repeated games likely rank among the best - studied topics in game theory , and the resulting insights have been instrumental for our understanding of strategic behavioral patterns . for this reason , it came as all the more of a surprise when @xcite reported a new class of  zero - determinant \" strategies , which enable players to exert unprecedented control in repeated interactions .",
    "however , notwithstanding decades of extensive literature on repeated games , alternating interactions have received very little attention when compared to their simultaneous counterparts .",
    "this emphasis is particularly puzzling because many , if not most , social encounters among plants or animals ( including humans ) that unfold over several rounds seem better captured by alternating actions of the interacting agents .",
    "moreover , even within the realm of alternating games , it is often assumed that individual turns alternate strictly rather than randomly @xcite .    here",
    ", we introduce autocratic strategies , a generalization of zero - determinant strategies , for alternating games . due to similarities with simultaneous - move games ,",
    "it is perhaps unsurprising that autocratic strategies also exist for strictly - alternating games .",
    "however , even so , the continuous donation game demonstrates that the autocratic strategies themselves depend on the timing of the players moves .",
    "what is more surprising , and even unexpected , is the fact that autocratic strategies exist for randomly - alternating games as well .",
    "this extension exemplifies the surprising robustness of autocratic strategies by relaxing the original assumptions in three important ways : ( i ) to allow for discounted payoffs , i.e. to consider finite numbers of rounds in each interaction @xcite ; ( ii ) to extend the action set from two distinct actions to infinite action spaces @xcite ; and now ( iii ) to admit asynchronous decisions and , in particular , randomly - alternating ones .",
    "the latter even includes asymmetric scenarios where one player moves , on average , more frequently than the other . under this far more generic setup",
    "we demonstrate that autocratic strategies still exist and enable players to enforce extortionate , generous , and equalizer relationships with their opponent .    in the strictly - alternating , continuous donation game ,",
    "autocratic strategies exist for player @xmath0 provided that the discounting factor , @xmath39 , is sufficiently weak , or , equivalently , that interactions span sufficiently many rounds ; see eq .",
    "( [ eq : strictlambdainequality ] ) .",
    "interestingly , the condition on @xmath39 does not depend on whether player @xmath0 moves first or second and is even identical to the corresponding condition in the synchronous game @xcite . in the absence of discounting , @xmath73",
    ", the same strategy enforces , for instance , an extortionate payoff relationship in simultaneous games as well as alternating games and regardless of whether or not player @xmath0 moved first .",
    "we demonstrate this phenomenon for the classical and continuous donation games in  [ sec : classicaldg ] and  [ sec : cdg ] , respectively .",
    "the condition for the existence of autocratic strategies in the randomly - alternating game , eq .  ( [ eq : donationextortioncondition ] ) , is similar to that of the strictly - alternating ( and simultaneous ) games , although slightly stronger . not surprisingly , this condition depends on the probability that player @xmath0 moves in a given round , @xmath12 . for each type of alternating game , we give examples of simple two - point autocratic strategies in which player @xmath0 s actions",
    "are restricted to @xmath55 ( defect ) and @xmath22 ( fully cooperate ) .",
    "although @xmath0 can enforce any extortionate , generous , or equalizer payoff relationship in the continuous donation game using a two - point strategy , a larger region of feasible payoffs is attainable if @xmath0 uses a deterministic autocratic strategy ( see fig .  [",
    "fig : feasibleregion ] ) .    while autocratic strategies undoubtedly mark important behavioral patterns , their importance in an evolutionary context is still debated : extortionate strategies perform poorly @xcite , whereas generous strategies perform much better @xcite .",
    "in fact , a generous strategy against itself represents a nash equilibrium in the simultaneous , two - action prisoner s dilemma @xcite .",
    "however , for extensions to continuous action spaces , such as the continuous donation game , even a generous strategy with full mutual cooperation is not necessarily a nash equilibrium @xcite .",
    "similar considerations for alternating games are further nuanced because they naturally introduce asymmetries in payoffs for the two players , even if the underlying interaction is symmetric and both players follow the same strategy . in fact",
    ", this asymmetry holds for any strictly - alternating game with discounting factor @xmath209 because then it matters which player moved first .",
    "similarly , in randomly - alternating games , the payoffs typically depend on the probability @xmath210 with which player @xmath0 moves and hence differ if @xmath211 . consequently , even if player @xmath0 and @xmath1 adopt the same autocratic strategy , then player @xmath0 does not necessarily enforce the same linear relationship on payoffs as player @xmath1 , which complicates the notion of equilibria both in the sense of nash as well as rest points of the evolutionary dynamics .    among alternating games ,",
    "the randomly - alternating ones represent perhaps the most promising and relevant setup from a biological perspective ( see * ? ? ?",
    "* ) . in the continuous donation game ,",
    "autocratic strategies exist even if the probability that player @xmath0 moves in a given round differs from that of player @xmath1 ( i.e. @xmath168 ) .",
    "of course , @xmath210 must be large enough to ensure that player @xmath0 is capable of exerting sufficient control over the game to pursue an autocratic strategy . for @xmath212",
    ", this condition always holds in the continuous donation game but might also apply under weaker conditions .",
    "interestingly , such asymmetries easily arise from dominance hierarchies .",
    "for example , in bouts of social grooming between primates @xcite , subordinate individuals , @xmath0 , typically groom dominant individuals , @xmath1 , more frequently than vice versa and hence @xmath212 . as a consequence ,",
    "the subordinate player has more autocratic strategies available to impact social grooming than does the dominant player .",
    "thus , autocratic strategies can be particularly useful for exerting control over asymmetric interactions .",
    "this observation marks not only an important distinction between autocratic strategies for synchronous and alternating games but also promises interesting applications to biologically - relevant interactions .",
    "the authors are grateful to christian hilbe for helpful conversations and useful comments .",
    "a. m. and c. h. thank the max planck institute for evolutionary biology and a. m. the program for evolutionary dynamics for their hospitality while this paper was written .",
    "the authors acknowledge financial support from the natural sciences and engineering research council of canada ( nserc ) , grant rgpin-2015 - 05795 .",
    "the authors declare no competing financial interests .",
    "adami , c. and hintze , a. ( 2013 ) .",
    "evolutionary instability of zero - determinant strategies demonstrates that winning is not everything . , 4 .",
    "akin , e. ( 2015 ) . .",
    ", 6(3):175190 .",
    "axelrod , r. ( 1984 ) . .",
    "basic books .",
    "axelrod , r. and hamilton , w. ( 1981 ) . .",
    ", 211(4489):13901396 .",
    "baek , s.  k. , jeong , h .- c . , hilbe , c. , and nowak , m.  a. ( 2016 ) . comparing reactive and memory - one strategies of direct reciprocity .",
    ", 6:25676 .",
    "dunbar , r. i.  m. ( 1991 ) . .",
    ", 57(3):121131 .",
    "foster , m.  w. , gilby , i.  c. , murray , c.  m. , johnson , a. , wroblewski , e.  e. , and pusey , a.  e. ( 2009 ) . .",
    ", 71(2):136144 .",
    "frean , m.  r. ( 1994 ) . .",
    ", 257(1348):7579 .",
    "fudenberg , d. and tirole , j. ( 1991 ) . .",
    "the mit press .",
    "hauert , c. and schuster , h.  g. ( 1997 ) .",
    "effects of increasing the number of players and memory size in the iterated prisoners dilemma : a numerical approach . , 264(1381):513519 .",
    "hauert , c. and schuster , h.  g. ( 1998 ) . .",
    ", 192(2):155166 .",
    "hilbe , c. , nowak , m.  a. , and sigmund , k. ( 2013 ) . .",
    ", 110:69136918 .",
    "hilbe , c. , rhl , t. , and milinski , m. ( 2014 ) . . , 5 .",
    "hilbe , c. , traulsen , a. , and sigmund , k. ( 2015 ) . .",
    ", 92:4152 .",
    "iliopoulos , d. , hintze , a. , and adami , c. ( 2010 ) . .",
    ", 6(10):18 .",
    "killingback , t. and doebeli , m. ( 2002 ) . .",
    ", 160(4):421438 .",
    "killingback , t. , doebeli , m. , and knowlton , n. ( 1999 ) . .",
    ", 266(1430):17231728 .",
    "lazaro - perea , c. , de  ftima  arruda , m. , and snowdon , c.  t. ( 2004 ) . .",
    ", 67(4):627636 .",
    "mcavoy , a. and hauert , c. ( 2016 ) .",
    "autocratic strategies for iterated games with arbitrary action spaces . , 113(13):35733578 .",
    "mehlman , p.  t. and chapais , b. ( 1988 ) . .",
    ", 29(2):195217 .",
    "milinski , m. ( 1987 ) . in sticklebacks and the evolution of cooperation .",
    ", 325(6103):433435 .",
    "milinski , m. and wedekind , c. ( 1998 ) . .",
    ", 95(23):1375513758 .",
    "miller , m.  b. and bassler , b.  l. ( 2001 ) . .",
    ", 55(1):165199 .",
    "muroyama , y. ( 1991 ) . .",
    ", 119(3):161170 .",
    "neill , d.  b. ( 2001 ) . .",
    ", 211(2):159180 .",
    "newton - fisher , n.  e. and lee , p.  c. ( 2011 ) . .",
    ", 81(2):439446 .",
    "nowak , m. and sigmund , k. ( 1990 ) .",
    "the evolution of stochastic strategies in the prisoner s dilemma .",
    ", 20(3):247265 .",
    "nowak , m.  a. ( 2006 ) .",
    "five rules for the evolution of cooperation . , 314(5805):15601563 .",
    "nowak , m.  a. and sigmund , k. ( 1994 ) . .",
    ", 168(2):219226 .    press , w.  h. and dyson , f.  j. ( 2012 )",
    ". iterated prisoner s dilemma contains strategies that dominate any evolutionary opponent .",
    ", 109(26):1040910413 .",
    "sigmund , k. ( 2010 ) . .",
    "princeton university press .",
    "stevens , j.  r. , volstorf , j. , schooler , l.  j. , and rieskamp , j. ( 2011 ) . . , 1 .",
    "stewart , a.  j. and plotkin , j.  b. ( 2012 ) . .",
    ", 109(26):1013410135 .",
    "stewart , a.  j. and plotkin , j.  b. ( 2013 ) . .",
    ", 110(38):1534815353 .",
    "stewart , a.  j. and plotkin , j.  b. ( 2016 ) .",
    "small groups and long memories promote cooperation .",
    ", 6:26889 .",
    "stintzi , a. , evans , k. , meyer , j .-",
    "m . , and poole , k. ( 1998 ) . .",
    ", 166(2):341345 .",
    "trivers , r.  l. ( 1971 ) . .",
    ", 46(1):3557 .",
    "verhoeff , t. ( 1998 ) . .",
    "computing science notes 93/02 , faculty of mathematics and computing science , eindhoven university of technology , the netherlands .",
    "wahl , l.  m. and nowak , m.  a. ( 1999a ) . .",
    ", 200(3):307321 .",
    "wahl , l.  m. and nowak , m.  a. ( 1999b ) . .",
    ", 200(3):323338 .",
    "wang , z. , zhou , y. , lien , j.  w. , zheng , j. , and xu , b. ( 2016 ) .",
    "extortion can outperform generosity in the iterated prisoner s dilemma .",
    ", 7:11125 .",
    "wedekind , c. and milinski , m. ( 1996 ) . .",
    ", 93(7):26862689 .    west , s.  a. and buckling , a. ( 2003 ) .",
    "cooperation , virulence and siderophore production in bacterial parasites .",
    ", 270(1510):3744 .",
    "wilkinson , g.  s. ( 1984 ) .",
    "reciprocal food sharing in the vampire bat .",
    ", 308(5955):181184 .",
    "zagorsky , b.  m. , reiter , j.  g. , chatterjee , k. , and nowak , m.  a. ( 2013 ) . .",
    ", 8(12):e80814 .    here , we prove our main results for each type of alternating game ( strictly- and randomly - alternating moves ) . by a measurable space ,",
    "we mean a set , @xmath213 , equipped with a @xmath214-algebra of subsets , @xmath215 , although we usually suppress @xmath215 .",
    "the notation @xmath216 indicates the space of all probability measures on @xmath213 , i.e. the set of all measures , @xmath217 , with @xmath218 .",
    "all functions are bounded and measurable .",
    "let @xmath50 and @xmath219 be the action spaces available to players @xmath0 and @xmath1 , respectively .",
    "we assume that these spaces are measurable , but otherwise we impose no restrictions on them .",
    "let @xmath33 and @xmath34 be the payoffs to players @xmath0 and @xmath1 , respectively , when @xmath0 moves @xmath60 .",
    "similarly , let @xmath38 and @xmath37 be the payoffs to players @xmath0 and @xmath1 , respectively , when @xmath1 moves @xmath61 . if @xmath39 is the discounting factor , then one may compress a pair of rounds in which @xmath0 moves first and @xmath1 moves second in order to form two - round payoff functions ,    @xmath220    in each of these two - round payoff functions , the payoff from player @xmath1 s move is discounted by a factor of @xmath39 to account for the time difference or , equivalently , for the probability that the interaction ends before player @xmath1 s turn .    due to the differences in the expressions for the average payoffs when @xmath0 moves first and when @xmath1 moves first , respectively ,",
    "we treat each of these cases separately in our study of autocratic strategies .",
    "if player @xmath0 moves first , then the entire sequence of play can be grouped into two - round pairs in which @xmath0 moves first and @xmath1 moves second .",
    "more specifically , if @xmath48 is the sequence of play , then this sequence may be rewritten as @xmath221 . when written in this manner",
    ", one may use @xmath44 to express the average payoff to player @xmath0 for this sequence as    @xmath222 \\nonumber \\\\ & = \\left(1-\\lambda\\right)\\sum_{t=0}^{\\infty}\\lambda^{2t}\\big ( f_{x}\\left(x_{2t}\\right ) + \\lambda g_{x}\\left(y_{2t+1}\\right ) \\big ) \\nonumber \\\\ & = \\left(1-\\lambda\\right)\\sum_{t=0}^{\\infty}\\lambda^{2t}u_{x}\\left(x_{2t},y_{2t+1}\\right ) .\\end{aligned}\\ ] ]    similarly , the average payoff to player @xmath1 is @xmath223 .",
    "a time-@xmath224 history indicates the sequence of play from time @xmath225 until ( but not including ) time @xmath226 and is an element of @xmath227 , where    @xmath228    for @xmath229 . for @xmath230 ,",
    "we let @xmath231 , where @xmath232 is the  empty history , \" which indicates that the game has not yet begun .",
    "a behavioral strategy defines a player s actions ( probabilistically ) for any history of play leading up to the current move ( see * ? ? ?",
    "that is , behavioral strategies for players @xmath0 and @xmath1 , respectively , may be written in terms of the space of histories as maps ,    @xmath233    where @xmath234 denotes the disjoint union operator , and @xmath235 and @xmath236 denote the space of probability measures on @xmath50 and @xmath219 , respectively .",
    "these strategies may be written together more compactly as a map    @xmath237 & t\\textrm { is even } , \\\\",
    "\\sigma_{y}\\left[h^{t}\\right ] & t\\textrm { is odd}.\\end{cases}\\end{aligned}\\ ] ]    using @xmath214 , we define a sequence of measures , @xmath238 , on @xmath239 as follows : for @xmath240 and @xmath229 , let @xmath241 . for @xmath242 and @xmath243 , let    @xmath244    for @xmath245 , let @xmath246 be the measure on @xmath247 , which , for @xmath248 , is defined as    @xmath249    in a @xmath250-round game ( rounds @xmath55 through @xmath251 ) , the expected payoff to player @xmath0 is    @xmath252 \\nonumber \\\\ & \\quad\\quad\\quad\\quad \\,d\\sigma\\left(h_{\\leqslant 2t}^{2t+2},h_{2t+1}^{2t+2}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{2t+2},h_{1}^{2t+2}\\right)\\,d\\sigma\\left(\\varnothing , h_{0}^{2t+2}\\right ) \\nonumber \\\\ & = \\left(\\frac{1-\\lambda}{1-\\lambda^{2t+1}}\\right)\\sum_{t=0}^{t}\\lambda^{2t}\\int\\limits_{h^{2t+2}\\in\\mathcal{h}^{2t+2 } } u_{x}\\left(h_{2t}^{2t+2},h_{2t+1}^{2t+2}\\right ) \\nonumber \\\\ & \\quad\\quad\\quad\\quad \\,d\\sigma\\left(h_{\\leqslant 2t}^{2t+2},h_{2t+1}^{2t+2}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{2t+2},h_{1}^{2t+2}\\right)\\,d\\sigma\\left(\\varnothing , h_{0}^{2t+2}\\right ) \\nonumber \\\\ & = \\left(\\frac{1-\\lambda}{1-\\lambda^{2t+1}}\\right)\\sum_{t=0}^{t}\\lambda^{2t}\\int\\limits_{h^{2t+2}\\in\\mathcal{h}^{2t+2 } } u_{x}\\left(h_{2t}^{2t+2},h_{2t+1}^{2t+2}\\right ) \\nonumber \\\\ & \\quad\\quad\\quad\\quad \\,d\\sigma\\left(h_{\\leqslant 2t}^{2t+2},h_{2t+1}^{2t+2}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{2t+2},h_{1}^{2t+2}\\right)\\,d\\sigma\\left(\\varnothing , h_{0}^{2t+2}\\right ) \\nonumber \\\\ & = \\left(\\frac{1-\\lambda}{1-\\lambda^{2t+1}}\\right)\\sum_{t=0}^{t}\\lambda^{2t}\\int\\limits_{\\left(h_{2t}^{2t+2},h_{2t+1}^{2t+2}\\right)\\in\\mathcal{h}_{2t}^{2t+2}\\times\\mathcal{h}_{2t+1}^{2t+2 } } u_{x}\\left(h_{2t}^{2t+2},h_{2t+1}^{2t+2}\\right)\\,d\\nu_{2t+1}^{1}\\left(h_{2t}^{2t+2},h_{2t+1}^{2t+2}\\right ) \\nonumber \\\\ & = \\left(\\frac{1-\\lambda}{1-\\lambda^{2t+1}}\\right)\\sum_{t=0}^{t}\\lambda^{2t}\\int\\limits_{\\left(x , y\\right)\\in s_{x}\\times s_{y } } u_{x}\\left(x , y\\right)\\,d\\nu_{2t+1}^{1}\\left(x , y\\right ) .\\end{aligned}\\ ] ]    in particular , the limit    @xmath253    exists since @xmath78 and @xmath79 ( and hence @xmath44 ) are bounded .",
    "similarly , we define    @xmath254    our main technical lemma is an analogue of lemma 3.1 of @xcite :    [ lem : mainlemmastricti ] for any memory - one strategy , @xmath52 $ ] , and any @xmath255 ,    @xmath256\\left(e\\right)\\big]\\,d\\nu_{2t+1}^{1}\\left(x , y\\right ) & = \\sigma_{x}^{0}\\left(e\\right ) , \\end{aligned}\\ ] ]    where @xmath257 $ ] is the initial action of player @xmath0 .    by the definition of the measures @xmath258 ,",
    "we have    @xmath259\\left(e\\right)\\,d\\nu_{2t+1}^{1}\\left(x , y\\right ) & = \\nu_{2t+2}^{0}\\left(e\\right ) .\\end{aligned}\\ ] ]    therefore , it follows that    @xmath260\\left(e\\right)\\big]\\,d\\nu_{2t+1}^{1}\\left(x , y\\right ) \\nonumber \\\\ & = \\sum_{t=0}^{\\infty}\\lambda^{2t}\\big(\\nu_{2t}^{0}\\left(e\\right ) -\\lambda^{2}\\nu_{2t+2}^{0}\\left(e\\right)\\big ) \\nonumber \\\\ & = \\nu_{0}^{0}\\left(e\\right ) - \\lim_{t\\rightarrow\\infty}\\lambda^{2t+2}\\nu_{2t+2}^{0}\\left(e\\right ) \\nonumber \\\\ & = \\nu_{0}^{0}\\left(e\\right ) \\nonumber \\\\ & = \\sigma_{x}^{0}\\left(e\\right ) , \\end{aligned}\\ ] ]    which completes the proof .",
    "[ prop : mainpropstricti ] for any bounded , measurable function , @xmath261 ,    @xmath262\\left(s\\right)\\right]\\,d\\nu_{2t+1}^{1}\\left(x , y\\right ) & = \\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) .\\end{aligned}\\ ] ]    the result follows from lemma [ lem : mainlemmastricti ] and the dominated convergence theorem .",
    "we do not include the details here ; the argument is the same as the proof of proposition 1 of @xcite .",
    "using proposition [ prop : mainpropstricti ] , we now prove the first of our main results for strictly - alternating games :    suppose that    @xmath263\\left(s\\right ) - \\left(1-\\lambda^{2}\\right)\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right)\\end{aligned}\\ ] ]    holds for some bounded @xmath59 and for each @xmath60 and @xmath61 .",
    "then , if player @xmath0 moves first , the pair @xmath62\\right)$ ] allows @xmath0 to enforce the equation @xmath63 for every strategy of player @xmath1 .    if eq .",
    "( [ sieq : conditionstricti ] ) holds , then , by proposition [ prop : mainpropstricti ] and eqs .",
    "( [ sieq : objectivexstricti ] ) and ( [ sieq : objectiveystricti ] ) ,    @xmath264\\left(s\\right)\\right]\\,d\\nu_{2t+1}^{1}\\left(x , y\\right ) \\nonumber \\\\ & = \\left(1-\\lambda\\right)\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) , \\end{aligned}\\ ] ]    and it follows that @xmath63 .",
    "if @xmath1 moves first , then a sequence of moves , @xmath265 , may be rewritten as @xmath266 , consisting of an initial move by @xmath1 followed by a sequence of two - round pairs in which @xmath0 moves first and @xmath1 moves second .",
    "the average payoff to player @xmath0 for this sequence of play is then    @xmath267 \\nonumber \\\\ & = \\left(1-\\lambda\\right)\\left[g_{x}\\left(y_{0}\\right ) + \\sum_{t=0}^{\\infty}\\lambda^{2t+1}f_{x}\\left(x_{2t+1}\\right ) + \\sum_{t=0}^{\\infty}\\lambda^{2t+2}g_{x}\\left(y_{2t+2}\\right)\\right ] \\nonumber \\\\ & = \\left(1-\\lambda\\right)\\left[g_{x}\\left(y_{0}\\right ) + \\sum_{t=0}^{\\infty}\\lambda^{2t+1}\\big ( f_{x}\\left(x_{2t+1}\\right ) + \\lambda g_{x}\\left(y_{2t+2}\\right)\\big ) \\right ] \\nonumber \\\\ & = \\left(1-\\lambda\\right)\\left[g_{x}\\left(y_{0}\\right ) + \\sum_{t=0}^{\\infty}\\lambda^{2t+1}u_{x}\\left(x_{2t+1},y_{2t+2}\\right ) \\right ] .\\end{aligned}\\ ] ]    similarly , player @xmath1 has an average payoff of @xmath268 $ ] .",
    "the set of time-@xmath224 histories is then given by @xmath227 , where    @xmath269    for @xmath229 , i.e. obtained from eq .",
    "( [ sieq : historystricti ] ) by swapping @xmath50 and @xmath219 .",
    "similarly , behavioral strategies for players @xmath0 and @xmath1 , respectively , are defined as maps ,    @xmath270    where , again , @xmath231 denotes the  empty \" history . in this case",
    ", we define    @xmath237 & t\\textrm { is odd } , \\\\",
    "\\sigma_{y}\\left[h^{t}\\right ] & t\\textrm { is even}.\\end{cases}\\end{aligned}\\ ] ]    in terms of @xmath214 , the measures @xmath238 and @xmath258 are defined in the same way as they were in ",
    "[ si : subsubsec : xmovesfirst ] .    in a @xmath271-round game",
    "( rounds @xmath55 through @xmath272 ) , the expected payoff to player @xmath0 is    @xmath273 \\nonumber \\\\ & \\quad\\quad\\quad\\quad \\,d\\sigma\\left(h_{\\leqslant 2t-1}^{2t+1},h_{2t}^{2t+1}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{2t+1},h_{1}^{2t+1}\\right)\\,d\\sigma\\left(\\varnothing , h_{0}^{2t+1}\\right ) \\nonumber \\\\ & = \\left(\\frac{1-\\lambda}{1-\\lambda^{2t}}\\right)\\int\\limits_{h^{2t+1}\\in\\mathcal{h}^{2t+1 } } g_{x}\\left(h_{0}^{2t+1}\\right ) \\,d\\sigma\\left(h_{\\leqslant 2t-1}^{2t+1},h_{2t}^{2t+1}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{2t+1},h_{1}^{2t+1}\\right)\\,d\\sigma\\left(\\varnothing , h_{0}^{2t+1}\\right ) \\nonumber \\\\ & \\quad + \\left(\\frac{1-\\lambda}{1-\\lambda^{2t}}\\right)\\sum_{t=0}^{t-1}\\lambda^{2t+1}\\int\\limits_{h^{2t+1}\\in\\mathcal{h}^{2t+1 } } u_{x}\\left(h_{2t+1}^{2t+1},h_{2t+2}^{2t+1}\\right ) \\nonumber \\\\ & \\quad\\quad\\quad\\quad \\,d\\sigma\\left(h_{\\leqslant 2t-1}^{2t+1},h_{2t}^{2t+1}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{2t+1},h_{1}^{2t+1}\\right)\\,d\\sigma\\left(\\varnothing , h_{0}^{2t+1}\\right ) \\nonumber \\\\\\ & = \\left(\\frac{1-\\lambda}{1-\\lambda^{2t}}\\right)\\int\\limits_{h^{1}\\in\\mathcal{h}^{1 } } g_{x}\\left(h_{0}^{1}\\right ) \\,d\\sigma\\left(\\varnothing , h_{0}^{1}\\right ) \\nonumber \\\\ & \\quad + \\left(\\frac{1-\\lambda}{1-\\lambda^{2t}}\\right)\\sum_{t=0}^{t-1}\\lambda^{2t+1}\\int\\limits_{\\left(h_{2t+1}^{2t+3},h_{2t+2}^{2t+3}\\right)\\in\\mathcal{h}_{2t+1}^{2t+3}\\times\\mathcal{h}_{2t+2}^{2t+3 } } u_{x}\\left(h_{2t+1}^{2t+3},h_{2t+2}^{2t+3}\\right ) \\,d\\nu_{2t+2}^{1}\\left(h_{2t+1}^{2t+3},h_{2t+2}^{2t+3}\\right ) \\nonumber \\\\ & = \\left(\\frac{1-\\lambda}{1-\\lambda^{2t}}\\right)\\int\\limits_{y_{0}\\in s_{y } } g_{x}\\left(y_{0}\\right ) \\,d\\sigma_{y}^{0}\\left(y_{0}\\right ) \\nonumber \\\\ & \\quad + \\left(\\frac{1-\\lambda}{1-\\lambda^{2t}}\\right)\\sum_{t=0}^{t-1}\\lambda^{2t+1}\\int\\limits_{\\left(x , y\\right)\\in s_{x}\\times s_{y } } u_{x}\\left(x , y\\right ) \\,d\\nu_{2t+2}^{1}\\left(x , y\\right ) , \\end{aligned}\\ ] ]    where @xmath274 $ ] is the initial action of player @xmath1 .",
    "thus , we define player @xmath0 s average payoff as    @xmath275 .\\end{aligned}\\ ] ]    similarly , the expected payoff to player @xmath1 is    @xmath276 .\\end{aligned}\\ ] ]    once again , our main technical lemma is an analogue of lemma 3.1 of @xcite :    [ lem : mainlemmastrictii ] for any memory - one strategy , @xmath52 $ ] , and any @xmath255 ,    @xmath277\\left(e\\right)\\big]\\,d\\nu_{2t+2}^{1}\\left(x , y\\right ) & = \\lambda\\int\\limits_{y_{0}\\in s_{y}}\\sigma_{x}\\left[y_{0}\\right]\\left(e\\right)\\,d\\sigma_{y}^{0}\\left(y_{0}\\right ) , \\end{aligned}\\ ] ]    where @xmath68 $ ] is the initial action of player @xmath0 .    by the definition of @xmath258",
    ", we see that    @xmath278\\left(e\\right)\\,d\\nu_{2t+2}^{1}\\left(x , y\\right ) & = \\nu_{2t+3}^{0}\\left(e\\right ) .\\end{aligned}\\ ] ]    therefore , it follows that    @xmath279\\left(e\\right)\\big]\\,d\\nu_{2t+2}^{1}\\left(x , y\\right ) \\nonumber \\\\ & = \\sum_{t=0}^{\\infty}\\lambda^{2t+1}\\big(\\nu_{2t+1}^{0}\\left(e\\right ) -\\lambda^{2}\\nu_{2t+3}^{0}\\left(e\\right)\\big ) \\nonumber \\\\ & = \\lambda\\nu_{1}^{0}\\left(e\\right ) - \\lim_{t\\rightarrow\\infty}\\lambda^{2t+3}\\nu_{2t+3}^{0}\\left(e\\right ) \\nonumber \\\\ & = \\lambda\\nu_{1}^{0}\\left(e\\right ) \\nonumber \\\\ & = \\lambda\\int\\limits_{y_{0}\\in s_{y}}\\sigma_{x}\\left[y_{0}\\right]\\left(e\\right)\\,d\\sigma_{y}^{0}\\left(y_{0}\\right ) , \\end{aligned}\\ ] ]    which completes the proof .",
    "[ prop : mainpropstrictii ] for any bounded , measurable function , @xmath261 ,    @xmath280\\left(s\\right ) \\right ] \\,d\\nu_{2t+2}^{1}\\left(x , y\\right ) \\nonumber \\\\ & = \\lambda\\int\\limits_{y_{0}\\in s_{y}}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left[y_{0}\\right]\\left(s\\right)\\,d\\sigma_{y}^{0}\\left(y_{0}\\right ) .\\end{aligned}\\ ] ]    the result follows from lemma [ lem : mainlemmastrictii ] and the dominated convergence theorem .",
    "we do not include the details here ; the argument is the same as the proof of proposition 1 of @xcite .",
    "we are now in a position to prove the second of our main results for strictly - alternating games :    suppose that    @xmath281\\left(s\\right ) - \\left(1-\\lambda^{2}\\right)\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left[y_{0}\\right]\\left(s\\right)\\end{aligned}\\ ] ]    holds for some bounded @xmath59 and for each @xmath60 and @xmath71 .",
    "if player @xmath0 moves second , the pair @xmath72,\\sigma_{x}\\left[x , y\\right]\\right)$ ] allows @xmath0 to enforce the equation @xmath63 for every strategy of player @xmath1 .",
    "( [ sieq : conditionstrictii ] ) holds , then , for any initial action of player @xmath1 , @xmath282 , we have    @xmath283\\,d\\sigma_{y}^{0}\\left(y_{0}\\right ) \\nonumber \\\\ & = \\psi\\left(x\\right ) -",
    "\\lambda^{2}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}\\left[x , y\\right]\\left(s\\right ) - \\left(1-\\lambda^{2}\\right)\\int\\limits_{y_{0}\\in s_{y}}\\int\\limits_{s\\in",
    "s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left[y_{0}\\right]\\left(s\\right)\\,d\\sigma_{y}^{0}\\left(y_{0}\\right ) .\\end{aligned}\\ ] ]    therefore , by proposition [ prop : mainpropstrictii ] and eqs .",
    "( [ sieq : objectivexstrictii ] ) and ( [ sieq : objectiveystrictii ] ) , we see that , for each @xmath282 ,    @xmath284\\left(s\\right)\\,d\\sigma_{y}^{0}\\left(y_{0}\\right ) \\nonumber \\\\ & \\quad -\\left(1-\\lambda\\right)\\int\\limits_{y_{0}\\in s_{y}}\\big[\\alpha g_{x}\\left(y_{0}\\right ) + \\beta g_{y}\\left(y_{0}\\right ) + \\gamma\\big]\\,d\\sigma_{y}^{0}\\left(y_{0}\\right ) \\nonumber \\\\ & = \\left(1-\\lambda\\right)\\sum_{t=0}^{\\infty}\\lambda^{2t+1}\\int\\limits_{\\left(x , y\\right)\\in s_{x}\\times s_{y } } \\left [ \\psi\\left(x\\right ) -",
    "\\lambda^{2}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}\\left[x , y\\right]\\left(s\\right ) \\right ] \\,d\\nu_{2t+2}^{1}\\left(x , y\\right ) \\nonumber \\\\ & \\quad -\\left(1-\\lambda\\right)\\sum_{t=0}^{\\infty}\\lambda^{2t+1}\\left ( \\left(\\frac{1-\\lambda^{2}}{\\lambda}\\right)\\int\\limits_{y_{0}\\in s_{y}}\\big [ \\alpha g_{x}\\left(y_{0}\\right ) + \\beta g_{y}\\left(y_{0}\\right ) + \\gamma \\big]\\,d\\sigma_{y}^{0}\\left(y_{0}\\right ) \\right ) \\nonumber \\\\ & = \\left(1-\\lambda\\right)\\lambda\\int\\limits_{y_{0}\\in s_{y}}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left[y_{0}\\right]\\left(s\\right)\\,d\\sigma_{y}^{0}\\left(y_{0}\\right ) \\nonumber \\\\ & \\quad - \\left(1-\\lambda\\right)\\int\\limits_{y_{0}\\in s_{y}}\\big [ \\alpha g_{x}\\left(y_{0}\\right ) + \\beta g_{y}\\left(y_{0}\\right ) + \\gamma \\big]\\,d\\sigma_{y}^{0}\\left(y_{0}\\right ) , \\end{aligned}\\ ] ]    and it follows immediately that @xmath63 .",
    "in each round of a randomly - alternating game , player @xmath0 moves with probability @xmath12 and player @xmath1 moves with probability @xmath13 for some @xmath14 . for @xmath285 ,",
    "a time-@xmath224 history is an element of the space    @xmath286    where @xmath287 denotes the disjoint union of the action spaces of the players , @xmath50 and @xmath219 . as in ",
    "[ si : subsec : strict ] , we let @xmath231 , where @xmath232 indicates the  empty history . \" in terms of the space of all possible histories , @xmath288 , behavioral strategies for players @xmath0 and @xmath1 , respectively , are maps ,    @xmath289    these strategies may be written more compactly as a single map , @xmath290 , defined for @xmath291 and @xmath292 via @xmath293\\left(e\\right ) : = \\omega_{x}\\sigma_{x}\\left[h^{t}\\right]\\left(e\\cap",
    "s_{x}\\right ) + \\left(1-\\omega_{x}\\right)\\sigma_{y}\\left[h^{t}\\right]\\left(e\\cap s_{y}\\right)$ ] . furthermore , if @xmath294 for @xmath229 , then these two strategies , @xmath295 and @xmath296 , together generate a sequence of probability measures , @xmath297 , on @xmath298 for each @xmath76 , defined via eqs . ( [ sieq : mudef ] ) and ( [ sieq : nudef ] ) .",
    "consider the single - round payoff function for player @xmath0 , @xmath299 , defined by    @xmath300    the single - round payoff function for player @xmath1 , @xmath45 , is defined by replacing @xmath78 by @xmath80 and @xmath79 by @xmath81 in eq .",
    "( [ sieq : singleroundrandom ] ) . in a @xmath301-round game",
    "( rounds @xmath55 through @xmath224 ) , the expected payoff to player @xmath0 is then    @xmath302 \\,d\\sigma\\left(h_{\\leqslant t-1}^{t+1},h_{t}^{t+1}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{t+1},h_{1}^{t+1}\\right)\\,d\\sigma\\left(\\varnothing , h_{0}^{t+1}\\right ) \\nonumber \\\\ & = \\left(\\frac{1-\\lambda}{1-\\lambda^{t+1}}\\right)\\sum_{t=0}^{t}\\lambda^{t}\\int\\limits_{h^{t+1}\\in\\mathcal{h}^{t+1 } } u_{x}\\left(h_{t}^{t+1}\\right ) \\,d\\sigma\\left(h_{\\leqslant t-1}^{t+1},h_{t}^{t+1}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{t+1},h_{1}^{t+1}\\right)\\,d\\sigma\\left(\\varnothing , h_{0}^{t+1}\\right ) \\nonumber \\\\ & = \\left(\\frac{1-\\lambda}{1-\\lambda^{t+1}}\\right)\\sum_{t=0}^{t}\\lambda^{t}\\int\\limits_{h^{t+1}\\in\\mathcal{h}^{t+1 } } u_{x}\\left(h_{t}^{t+1}\\right ) \\,d\\sigma\\left(h_{\\leqslant t-1}^{t+1},h_{t}^{t+1}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{t+1},h_{1}^{t+1}\\right)\\,d\\sigma\\left(\\varnothing ,",
    "h_{0}^{t+1}\\right ) \\nonumber \\\\ & = \\left(\\frac{1-\\lambda}{1-\\lambda^{t+1}}\\right)\\sum_{t=0}^{t}\\lambda^{t}\\int\\limits_{h_{t}^{t+1}\\in\\mathcal{h}_{t}^{t+1 } } u_{x}\\left(h_{t}^{t+1}\\right ) \\ , d\\nu_{t}^{0}\\left(h_{t}^{t+1}\\right )",
    "\\nonumber \\\\ & = \\left(\\frac{1-\\lambda}{1-\\lambda^{t+1}}\\right)\\sum_{t=0}^{t}\\lambda^{t}\\int\\limits_{s\\in s_{x}\\sqcup s_{y } } u_{x}\\left(s\\right ) \\ , d\\nu_{t}^{0}\\left(s\\right ) .\\end{aligned}\\ ] ]    therefore , we define the average payoff of player @xmath0 to be    @xmath303    similarly , the expected payoff of player @xmath1 is    @xmath304    a memory - one strategy in the context of randomly - alternating games looks slightly different from that of strictly - alternating games .",
    "instead of simply reacting to the previous moves of the players , one also needs to know which player moved last since , in any given round , either @xmath0 or @xmath1 could move ( provided @xmath305 ) .",
    "therefore , a memory - one strategy for player @xmath0 consists of an action policy , @xmath83 $ ] , when @xmath0 moves @xmath31 in the previous round , and a policy , @xmath82 $ ] , when @xmath1 moves @xmath35 in the previous round .",
    "more succinctly , we let    @xmath306 & : = \\begin{cases}\\sigma_{x}^{x}\\left[s\\right ] & s\\in s_{x } , \\\\",
    "\\sigma_{x}^{y}\\left[s\\right ] & s\\in s_{y } .\\end{cases}\\end{aligned}\\ ] ]    one final time , our main technical lemma is an analogue of lemma 3.1 of @xcite :    [ lem : mainlemmarandom ] for memory - one strategies , @xmath83 $ ] and @xmath82 $ ] , and @xmath255 , we have    @xmath307\\left(e\\right)\\big]\\,d\\nu_{t}^{0}\\left(s\\right ) & = \\omega_{x}\\sigma_{x}^{0}\\left(e\\right ) , \\end{aligned}\\ ] ]    where @xmath308 $ ] is defined via eq .",
    "( [ sieq : xycombinedrandom ] ) .    by the definition of the sequence of measures , @xmath297 ,    @xmath309\\left(e\\right)\\,d\\nu_{t}^{0}\\left(s\\right ) & = \\nu_{t+1}^{0}\\left(e\\right ) .\\end{aligned}\\ ] ]    therefore , we see that    @xmath310\\left(e\\right)\\big]\\,d\\nu_{t}^{0}\\left(s\\right ) \\nonumber \\\\ & = \\sum_{t=0}^{\\infty}\\lambda^{t}\\big ( \\nu_{t}^{0}\\left(e\\right ) - \\lambda\\nu_{t+1}^{0}\\left(e\\right ) \\big ) \\nonumber \\\\ & = \\nu_{0}^{0}\\left(e\\right ) - \\lim_{t\\rightarrow\\infty}\\lambda^{t+1}\\nu_{t+1}^{0}\\left(e\\right ) \\nonumber \\\\ & = \\nu_{0}^{0}\\left(e\\right ) \\nonumber \\\\ & = \\omega_{x}\\sigma_{x}^{0}\\left(e\\right ) , \\end{aligned}\\ ] ]    which completes the proof .",
    "[ prop : mainproprandom ] for any bounded , measurable function , @xmath311 , with @xmath312 ,    @xmath313\\left(s'\\right)\\right]\\,d\\nu_{t}^{0}\\left(s\\right ) & = \\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) .\\end{aligned}\\ ] ]    the result follows from lemma [ lem : mainlemmarandom ] and the dominated convergence theorem .",
    "we do not include the details here ; the argument is the same as the proof of proposition 1 of @xcite .",
    "proposition [ prop : mainproprandom ] allows us to prove our main result for randomly - alternating games :    if , for some bounded @xmath59 ,    [ sieq : randomconds ]",
    "@xmath84\\left(s\\right ) -\\left(1-\\lambda\\right)\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) ; \\label{sieq : randomcondi } \\\\ \\alpha g_{x}\\left(y\\right ) + \\beta g_{y}\\left(y\\right ) + \\gamma & = -\\lambda \\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,\\sigma_{x}^{y}\\left[y\\right]\\left(s\\right ) -\\left(1-\\lambda\\right)\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) \\label{sieq : randomcondii}\\end{aligned}\\ ] ]    for each @xmath60 and @xmath61 , then the strategy @xmath85 , \\sigma_{x}^{y}\\left[y\\right]\\right)$ ] allows @xmath0 to enforce the equation @xmath63 for every strategy of player @xmath1 .",
    "( [ sieq : randomconds ] ) holds , then , by proposition [ prop : mainproprandom ] and eqs .",
    "( [ sieq : objectivexrandom ] ) and ( [ sieq : objectiveyrandom ] ) ,    @xmath314\\left(s'\\right)\\right]\\,d\\nu_{t}^{0}\\left(s\\right ) \\nonumber \\\\ & = \\left(1-\\lambda\\right)\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) , \\end{aligned}\\ ] ]    from which it follows that @xmath63 , as desired .",
    "suppose that @xmath0 wishes to enforce @xmath63 with    [ sieq : twopointrandomdef ] @xmath315 & = p^{x}\\left(x\\right)\\delta_{s_{1}}+\\big(1-p^{x}\\left(x\\right)\\big)\\delta_{s_{2 } } ; \\\\",
    "\\sigma_{x}^{y}\\left[y\\right ] & = p^{y}\\left(y\\right)\\delta_{s_{1}}+\\big(1-p^{y}\\left(y\\right)\\big)\\delta_{s_{2}}\\end{aligned}\\ ] ]    for some @xmath136 and @xmath137 in @xmath50 .",
    "consider the function , @xmath316 , defined by    @xmath317    then , in terms of @xmath318 , it must be the case that    @xmath319    therefore , provided @xmath320 and @xmath321 for each @xmath60 and @xmath61 , the two - point strategy defined by eq .",
    "( [ sieq : twopointrandomdef ] ) allows player @xmath0 to unilaterally enforce the relationship @xmath63 .",
    "suppose that @xmath0 wishes to enforce @xmath63 by using a deterministic strategy , which is defined in terms of a reaction function to the previous move of the game .",
    "that is , a deterministic memory - one strategy for player @xmath0 consists of an initial action , @xmath322 , and two reaction functions , @xmath194 and @xmath195 .",
    "player @xmath0 begins by using @xmath193 with certainty .",
    "if @xmath0 uses @xmath31 in the previous round and @xmath0 moves again , then @xmath0 plays @xmath323 in the subsequent round . on the other hand ,",
    "if @xmath1 moves @xmath35 in the previous round and @xmath0 follows this move , then @xmath0 plays @xmath324 in response to @xmath1 s action . for a deterministic strategy with these reaction functions , eq .",
    "( [ sieq : randomconds ] ) takes the form    @xmath325",
    "the results we give for the continuous donation game hold for any benefit and cost functions , @xmath24 and @xmath23 , and any interval of cooperation levels , @xmath21 = s_{x}=s_{y}$ ] . for the purposes of plotting feasible regions ( figs . [",
    "fig : feasibleregion ] and [ fig : regionsstrictiandii ] ) and for performing simulations ( figs .",
    "[ fig : twopointsimulation ] and [ fig : deterministicsimulation ] ) , we use for benefit and cost functions             in the strictly - alternating , continuous donation game when player @xmath0 moves first ( top ) and player @xmath1 moves first ( bottom ) .",
    "the shaded region represents the feasible payoffs when @xmath0 plays a two - point strategy ( only @xmath55 and @xmath22 ) .",
    "as the discounting factor , @xmath39 , gets smaller ( i.e. discounting stronger ) , the first move has more of a pronounced effect on the expected payoffs.[fig : regionsstrictiandii ] ]    note that these regions depend on the discounting factor , @xmath39 , due to the payoff asymmetries introduced by the sequential moves even for symmetric interactions . in contrast , in the randomly - alternating , continuous donation game , these regions do not depend on @xmath39 .      in the main text , we presented two - point autocratic strategies that are concentrated on just @xmath55 and @xmath22 . here , we give the technical requirements of the probability of initially cooperating , @xmath144 .",
    "@xmath334\\left(s\\right ) -\\left(1-\\lambda\\right)\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) ; \\label{sieq : extgenfirst } \\\\",
    "b\\left(y\\right ) + \\chi",
    "c\\left(y\\right ) + \\gamma & = -\\lambda \\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,\\sigma_{x}^{y}\\left[y\\right]\\left(s\\right ) -\\left(1-\\lambda\\right)\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) \\label{sieq : extgensecond}\\end{aligned}\\ ] ]                          [ eq : setown ] @xmath341\\left(s\\right ) -\\left(1-\\lambda\\right)\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) ; \\label{eq : setownfirst } \\\\",
    "b\\left(y\\right ) - \\gamma & = -\\lambda \\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,\\sigma_{x}^{y}\\left[y\\right]\\left(s\\right ) -\\left(1-\\lambda\\right)\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) \\label{eq : setownsecond}\\end{aligned}\\ ] ]            thus @xmath344 . therefore ,",
    "player @xmath0 can unilaterally set her own score to at most @xmath55 .",
    "however , it should be noted that , in contrast to the continuous donation game with simultaneous moves , it is possible for a player to set her own score ( to at most @xmath55 ) when moves alternate randomly .",
    "for example , if @xmath345 and @xmath346 , then player @xmath0 can unilaterally set @xmath347 using      where @xmath349 , provided @xmath192 is sufficiently close to @xmath113 .",
    "interestingly , however , if players move with equal probability , @xmath165 , then player @xmath0 can never set her own score : eq .",
    "( [ eq : setown ] ) implies that @xmath350 , which can never hold for @xmath165 and @xmath351 .",
    "even when a player can set her own score in the continuous donation game , this score can be at most @xmath55 ; thus , since a player can achieve at least @xmath55 by defecting in every round , such an equalizer strategy would never be attractive .",
    "we saw in ",
    "[ subsubsec : randomcdg ] that player @xmath0 can set @xmath109 for any @xmath352 . here , we show that , using eq .",
    "( [ eq : mainequationrandom ] ) , there are no other payoffs for player @xmath1 that @xmath0 can set unilaterally . indeed ,",
    "suppose    @xmath353\\left(s\\right ) -\\left(1-\\lambda\\right)\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) ; \\label{eq : setopponentfirst } \\\\",
    "-c\\left(y\\right ) - \\gamma & = -\\lambda \\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,\\sigma_{x}^{y}\\left[y\\right]\\left(s\\right ) -\\left(1-\\lambda\\right)\\omega_{x}\\int\\limits_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) \\label{eq : setopponentsecond}\\end{aligned}\\ ] ]                    here , we give the technical conditions on @xmath144 , the probability that @xmath0 cooperates in the first round , that must be satisfied for her to be able to enforce various linear payoff relationships ( extortionate , generous , and equalizer ) using a two - point autocratic strategy ."
  ],
  "abstract_text": [
    "<S> repeated games have a long tradition in the behavioral sciences and evolutionary biology . </S>",
    "<S> recently , strategies were discovered that permit an unprecedented level of control over repeated interactions by enabling a player to unilaterally enforce linear constraints on payoffs . here , </S>",
    "<S> we extend this theory of  zero - determinant \" ( or , more generally ,  autocratic \" ) strategies to alternating games , which are often biologically more relevant than traditional synchronous games . </S>",
    "<S> alternating games naturally result in asymmetries between players because the first move matters or because players might not move with equal probabilities . in a strictly - alternating game with two players , @xmath0 and @xmath1 , we give conditions for the existence of autocratic strategies for player @xmath0 when ( i ) @xmath0 moves first and ( ii ) @xmath1 moves first . </S>",
    "<S> furthermore , we show that autocratic strategies exist even for ( iii ) games with randomly - alternating moves . </S>",
    "<S> particularly important categories of autocratic strategies are extortionate and generous strategies , which enforce unfavorable and favorable outcomes for the opponent , respectively . </S>",
    "<S> we illustrate these strategies using the continuous donation game , in which a player pays a cost to provide a benefit to the opponent according to a continuous cooperative investment level . </S>",
    "<S> asymmetries due to alternating moves could easily arise from dominance hierarchies , and we show that they can endow subordinate players with more autocratic strategies than dominant players . </S>"
  ]
}