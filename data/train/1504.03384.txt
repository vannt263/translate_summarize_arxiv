{
  "article_text": [
    "we discuss an intuitive alternative to classical principal components analysis that selects the ( singular ) affine transformation of the original scatter , visualized as n points embedded within a p - dimensional euclidean space , that reduces its dimensionality to q @xmath0 p while attempting to reproduce all pair - wise , squared mahalanobis inter - point distances .",
    "we show that this criterion is not coordinate - free ; it places extra emphasis upon reproducing the squared euclidean distances of all n points from the origin .",
    "our origin - centric perspective on affine reduction of dimensionality encourages interpretation of the recovered scatter using either polar or cartesian coordinates .    in traditional principal component and",
    "coordinate approaches to reduction of dimensionality , the origin is conventionally placed at the geometric centroid of the overall scatter by subtracting the observed arithmetic mean value from each given coordinate .",
    "this convention can , optionally , be retained in the origin - centric approach discussed here . on the other hand , the impact of details such as how the given coordinates were originally scaled and intercorrelated are minimized in this new , alternative approach .",
    "this is accomplished by placing the given data scatter in its affine invariant canonical form , obenchain(1971 , 1972a ) .",
    "interestingly , this substitution makes reduction of dimensionality using conventional principal components analysis impossible ; all one - dimensional orthogonal projections of the revised data have the same variance , and any two mutually orthogonal projections are uncorrelated .",
    "in particular , this means that the ultimate impact of researcher initiatives , glaeser(2006 ) , in choice of included variables and of their initial scaling upon potential recovered configurations of low dimensionality is thereby greatly reduced .",
    "the format of the paper is as follows . in the next three sections , we introduce basic notation and define terminology related to euclidean distance calculations , matrix norms in linear algebra , and origin - centric",
    "coordinate concepts .",
    "sections [ sec : example1 ] and [ sec : example2 ] , then display two relatively simple numerical examples .",
    "we end this overview paper with some general discussion points in section [ sec : discussion ] .",
    "the final four sections , [ sec : affine invarcomm ] to [ sec : plarge ] , are somewhat more technical appendices covering historical background information and some relatively advanced observations and conjectures .",
    "when a n @xmath1 p matrix of finite real numbers , @xmath2 , is used as a cartesian coordinate representation of n points in euclidean space relative to p = 2 or more mutually orthogonal axes , the conventional view is that the location of the origin is not important .",
    "after all , the pythagorean theorem dictates that the squared distance between the i - th and j - th points in the scatter is given by @xmath3 where @xmath4 denotes the i - th row of @xmath2 . in the first line of the above expression ,",
    "note that only differences in coordinates between points are involved .",
    "it follows that @xmath5 is , by definition , invariant under shifts in the location of the origin resulting from simple ( additive ) translations of coordinates .",
    "the second line of equation ( [ eqn : sqdist ] ) shows an equivalent expression containing origin - centric terms .",
    "the first two terms are the squared euclidean distances of the i - th and j - th points from their current origin , @xmath6 .",
    "similarly , the full n @xmath1 n matrix of inter - point squared distances can be written as @xmath7 where @xmath8 is the n @xmath1 1 column vector that consists of the ordered elements of @xmath9 .",
    "in other words , the i - th element of @xmath8 is the @xmath10 term of equation ( [ eqn : sqdist ] ) .",
    "thus @xmath8 is the vector of squared euclidean distances of all n points from their current origin , @xmath6 .",
    "the @xmath11 matrix is symmetric , and its n diagonal elements are null .",
    "suppose now that a given @xmath2 matrix is to be optimally approximated by a n @xmath1 q matrix of finite real numbers , @xmath12 , where q @xmath0 p but q is at least 1 .",
    "specifically , suppose that the objective is to minimize the squared frobenius norm of the difference between the @xmath11 matrices computed from the @xmath2 and @xmath12 coordinates : @xmath13 where @xmath14 is the column vector of discrepancies in squared difference of points from the origin in @xmath2 and @xmath12 coordinates .    in the special case of primary interest here ,",
    "the @xmath15 outer - products matrix ( @xmath16 ) is what is know as an association matrix , @xmath17 , for `` individuals '' ( points ) , gower(1966 ) , while the @xmath18 inner - products matrix ( @xmath19 ) contains the corresponding adjusted sums - of - squares and cross - products for `` variables . ''",
    "the objective in principal component analysis ( pca ) is to minimize @xmath20 where the @xmath2 and @xmath12 matrices have each been `` centered '' as outlined below in section [ sec : affinermd ] .",
    "this particular point is more fully discussed in an appendix ; see section [ sec : center ] .    in any case , minimizing @xmath21 of equation ( [ eqn : sqdifnorm ] ) is potentially quite different from ordinary pca . minimizing @xmath21 places emphasis upon balancing two separate criteria : [ 1 ] reducing the size of the @xmath22 vector , which contains the discrepancies in _ squared distance from the origin _ for all n points within the original @xmath2 and derived @xmath12 configurations , and [ 2 ] reducing the pca norm of the difference in outer - product matrices .",
    "tension between these competing objectives make choice of @xmath12 so as to minimize @xmath21 of equation ( [ eqn : sqdifnorm ] ) an origin - centric approach .",
    "the _ singular value decomposition _ of a n @xmath1 p matrix consisting of the `` centered , '' real valued @xmath2 coordinates of n points in a euclidean space of dimension ( linear rank ) r can be written as : @xmath23 where the 1 @xmath1 n row vector @xmath24 is any generalized inverse of the n @xmath1 1 column vector of all ones , @xmath25 , the semi - orthogonal matrix @xmath26 is the n @xmath1 r matrix of standardized _ principal coordinates _",
    ", @xmath27 is a r @xmath1 r diagonal matrix of strictly positive singular values , and @xmath28 is a r @xmath1 p semi - orthogonal matrix of component _ direction cosines_. when r = p , the @xmath29 matrix becomes orthogonal ( and invertible ) ; @xmath30 of order p.    every choice for @xmath31 is such that @xmath32 ; it follows from ( [ eqn : svdcenter ] ) that the semi - orthogonal matrix @xmath26 is orthogonal to @xmath31 .",
    "this @xmath33 restriction assures that r @xmath34 .",
    "more complete information about this critical choice of initial translation is given in the appendix of section [ sec : center ] ; choice of @xmath31 determines the location of the origin , @xmath6 , of cartesian coordinates .",
    "affine reductions in dimensionality are those in which the recovered @xmath12 configuration is of the restricted form : @xmath35 where @xmath26 is the n @xmath1 r matrix of ( [ eqn : svdcenter ] ) and @xmath36 is a r @xmath1 q matrix of @xmath37 consisting of real scalars .",
    "in particular , any row of @xmath26 that is null assures that the corresponding row of @xmath12 will also be null ... corresponding to a point coincident with the origin , @xmath6 .",
    "one of two forms of preliminary data `` standardization '' are typically applied prior to performing traditional pca , but neither is nearly as `` drastic '' as replacing one s initial @xmath2 matrix by its mahalanobis principal coordinates matrix , @xmath26 , as in ( [ eqn : rqaffrmd ] ) .",
    "traditional `` mean centering '' uses the @xmath38 vector , with each of its n elements equal to 1/n , as choice of @xmath24 in ( [ eqn : svdcenter ] ) .",
    "traditional standardization to `` correlation form '' performs an addition step in which each column of the `` mean centered '' @xmath2 matrix is then divided by its sample standard deviation .",
    "this is essentially equivalent to the standardization in which the n elements in each column of @xmath2 are made to not only sum to zero but also to have sum - of - squares set equal to 1 ; on the other hand , this standardization still allows the different columns of @xmath2 to be ( linearly ) correlated or confounded .    in sharp contrast",
    ", the semi - orthogonal @xmath26 matrix of ( [ eqn : svdcenter ] ) is essentially r - dimensional from the perspective of traditional pca .",
    "each column of this @xmath26 matrix is orthogonal to the current choice of @xmath31 ( defining a mean or multivariate median measure of location ) , has sum - of - squares set equal to 1 , and is exactly uncorrelated with the derived coordinates along any direction strictly orthogonal to it .",
    "for example , consider the 1-dimensional case , q = 1 in ( [ eqn : rqaffrmd ] ) , where the @xmath12 and @xmath36 matrices become single column vectors , @xmath39 and @xmath40 .",
    "it follows that @xmath41 while the corresponding sum - of - squares is @xmath42 , which is determined solely by the squared length of the @xmath40 vector .",
    "similarly , any two different choices for this @xmath40 vector yield uncorrelated @xmath39 representations if and only if these two choices are mutually orthogonal vectors , @xmath43 .",
    "in other words , since pca can not be used to reduce the dimensionality of @xmath26 , one s primary hope may well be to adopt an origin - centric perspective based upon minimizing the squared norm of equation ( [ eqn : sqdifnorm ] ) .",
    "if none of the rows of the @xmath26 matrix of ( [ eqn : svdcenter ] ) is null , then the given scatter contains no points coincident with the origin , as determined by the current choice of @xmath31 vector . on the other hand",
    ", there will always be at least one point at the current origin whenever exactly one element of the current @xmath31 vector is a 1 and all other elements are null .    any null row of the @xmath26 matrix of ( [ eqn : svdcenter ] ) can be relocated to its first row simply by renumbering the n points in the initial scatter .",
    "the resulting @xmath44 vector of ( [ eqn : sqdifnorm ] ) that contains the squared euclidean distances of all n point from their current origin will then naturally have a zero in its first row .",
    "in fact , this @xmath44 vector will also then be the first column of the @xmath11 matrix of ( [ eqn : sqdistmtx ] ) , while its transpose will be the first row of this same matrix .",
    "when a @xmath26 matrix from ( [ eqn : svdcenter ] ) contains no null row , a null row can be added as , say , row n+1 .",
    "this augmented @xmath26 matrix is still semi - orthogonal , and @xmath45 is still the r @xmath1 r identify matrix . the corresponding augmented @xmath31 column vector ( @xmath46 )",
    "can be taken to have a zero as its final element , and the augmented @xmath11 matrix of ( [ eqn : sqdistmtx ] ) will have the original @xmath44 vector as the above the diagonal elements in its last column ... and its transpose in the bottom row .    in summary , the @xmath44 vector that contains the squared euclidean distances of all n original points from their current origin",
    "is either already contained within the original n @xmath1 n squared distances matrix , @xmath11 of ( [ eqn : sqdistmtx ] ) , or else it will appear within the corresponding ( n+1 ) @xmath1 ( n+1 ) augmented version of this matrix when a new point coincident with the origin is included .    in other words ,",
    "the @xmath44 vector is either an explicit or implicit part of every n @xmath1 n matrix of squared distances , @xmath11 of ( [ eqn : sqdistmtx ] ) . in sharp contrast with pca , efforts to minimize @xmath21 of ( [ eqn : sqdifnorm ] ) place special emphasis upon accurate reproduction of @xmath44 values within the recovered z - configuration .",
    "perhaps the most simple sort of `` interesting '' example for comparing pca with our origin - centric approach is depicted as h coordinates ( p=2 and n=6 ) in figure 1 .",
    "when reducing this configuration to a single dimension ( q=1 ) , a singular affine transformation can produce either  a pair of triplet points \" or else a `` triplet of pairs . '' in fact",
    ", these particular configurations happen to correspond to two of the three local minima of @xmath21 of equation ( [ eqn : sqdifnorm ] ) ; see figure 2 .",
    "this example is also interesting in the sense that , while the initial h - configuration contains no point(s ) at the origin , the optimal q=1 dimensional recovered configuration [ case ( c ) in figure 2 ] contains 2 points coincident with the origin .",
    "here we use the infamous longley(1972 ) dataset ( p=6 , n=16 ) to illustrate some key distinctions between the pca and affine , origin - centric methods of ( [ eqn : rqaffrmd ] ) for reduction of multivariate dimensionality . while longley used seven variables in his ill - conditioned regression model , here we use year = 1947 to 1962 only as labels for points , rather than as an exact  linear trend \" variable . the six us economic variables used here are @xmath47 gnp deflator , @xmath48 gnp , @xmath49 number unemployed , @xmath50 size of armed forces , @xmath51 total population and @xmath52 total employed .",
    "this example is rather typical of cases i have explored , especially when",
    "n greatly exceeds p. specifically , the optimal affine reduction in mahalanobis dimensionality depicted in figure 4 has a `` dyson swarm '' interpretation , featuring a characteristic  hole \" surrounding the explicit origin .",
    "in the terminology of glaeser(2006 ) , `` researcher initiatives '' can deliberately bias findings towards the perspective of one particular subset of stakeholders .",
    "for example , it is well know that including several different quantitative x - variables that are surrogate measures of a single construct in a pca tends to orient the first principal axis to represent that construct .",
    "the corresponding phenomena in an origin - centric analysis would be to include several points that are actually coincident , thereby placing greater emphasis upon recovering the distance of this composite from all other points within the scatter .",
    "origin - centric methods allow the scatter to be visualized much like a `` dyson swarm '' for a finite universe of n or fewer points .",
    "for example , a q=3 dimensional recovered scatter might be primarily viewed as a 2-dimensional small - scale conformal mapping where radial distance information is disregarded .",
    "alternatively , the size of each of the n plotting symbols displayed on this sort of  sky view \" map could represent some monotone function of its recovered radius .",
    "nonnegative matrix factorization ( nmf ) techniques rely upon locating the origin so that all n initial points have p strictly nonnegative coordinates .",
    "in other words , all initial points must lie on or within the boundaries of the `` first '' cartesian @xmath53-ant of p - dimensional euclidean space .",
    "similarly , the q dimensions to be recovered using nmf are to be represented as vectors emanating from the origin that have strictly nonnegative direction cosines because they point exclusively into this same first cartesian @xmath53-ant .",
    "linear algebra is typically used to manipulate data structures , consisting of vectors and matrices of real numbers , in multivariate statistical analyses .",
    "insights into the analytical geometry of such manipulations is provided by visualizing the data as consisting of a scatter of n points within a p - dimensional euclidean space .",
    "a fundamental property of euclidean space is that distance is computed from coordinates relative to orthogonal axes using the pythagorean theorem .",
    "a n @xmath1 p matrix of real numbers , @xmath54 , is said to represent a nonsingular affine transformation of an initial n @xmath1 p matrix of real numbers , @xmath2 , if and only if there exists a 1 @xmath1 p  translation \" vector @xmath55 and a nonsingular p @xmath1 p matrix @xmath36 of real values such that @xmath56 in particular , if any row of @xmath2 consists of all zeros , the corresponding row of @xmath54 will be @xmath55 .",
    "the notation of equation ( [ eqn : afftran ] ) differs slightly from that of obenchain(1971 ) simply because the @xmath2 and @xmath54 matrices have been transposed here .",
    "a statistic @xmath57 , consisting of a scalar , vector or matrix of real numbers , will be said to be affine invariant if and only if its numerical value when computed after any nonsingular affine transformation has been applied to a dataset is identical to its value before such transformation : @xmath58    the @xmath26 matrix of ( [ eqn : svdcenter ] ) is not uniquely determined .",
    "for example , any of the r columns of @xmath26 ( each n @xmath1 1 ) can always be multiplied by @xmath59 if the corresponding row of @xmath28 ( 1 @xmath1 p ) is also multiplied by @xmath59 . on the other hand , @xmath60 is an idempotent and symmetric ( n @xmath1 n ) matrix that is uniquely determined and corresponds to the orthogonal projection matrix ( linear operator ) that characterizes the column space of the @xmath61 matrix ; see rao(1973 ) , pages 46 - 48 .",
    "in fact , obenchain(1971 ) showed that @xmath60 and @xmath11 are equivalent `` maximal affine invariant '' statistics which can be viewed as a standardized , canonical form for a given ( n @xmath1 p ) data matrix of `` centered '' scalar values subject to nonsingular linear @xmath36 transformations , ( [ eqn : afftran ] ) .",
    "the @xmath60 and @xmath11 matrices are unique but distinct , and each can be computed from the other .",
    "pca focuses upon reproducing @xmath62 by decomposing it into ordered and additive components .",
    "pca fails to reduce dimensionality when applied to @xmath60 because all of its components are equally good or bad and , thus , can not be uniquely ordered .    by focusing upon reproducing @xmath11 instead of @xmath60",
    ", origin - centric methods can reduce the dimensionality of configurations that pca can not .",
    "there appear to be at least two separate parts to the price - one - has - to - pay to achieve affine invariance properties that ignore vagaries caused by analyst choice of variable scalings and/or confounding between variables .",
    "first of all , recovered configurations will not be additive ; the optimal solution of dimension ( q+1 ) usually does not exactly `` contain '' the optimal solution of dimension q. secondly , minimizing @xmath21 of equation ( [ eqn : sqdifnorm ] ) is a problem of constrained optimization subject to multiple local minima .",
    "fortunately , modern numerical search software , such as the `` optimx '' r - package of nash and varadhan(2011 ) , is now available to researchers .",
    "a n @xmath1 p matrix of real numbers , @xmath54 , will be said to be a `` centered '' version of a n @xmath1 p matrix of real numbers , @xmath2 , if and only if @xmath63 where the 1 @xmath1 n row vector @xmath64 is any generalized inverse of the n @xmath1 1 column vector of all ones , @xmath25 .",
    "in other words , any 1 @xmath1 n row vector of real values that sum to 1 , @xmath65 , is a valid choice for @xmath64 in ( [ eqn : center ] ) .",
    "the `` centering '' operation of equation ( [ eqn : center ] ) frequently yields @xmath54 coordinates that differ from those of the initial @xmath2 matrix . in these cases ,",
    "the location of the implicit origin , @xmath6 , has been shifted via a simple `` translation '' of @xmath54 coordinates .",
    "the unique moore - penrose inverse of @xmath25 , usually denoted by @xmath66 , is the row vector with each of its n entries equal to 1/n .",
    "this choice for @xmath64 corresponds to centering the @xmath2 matrix at its overall mean vector , i.e. at its traditional centroid .",
    "when @xmath67 and @xmath68 are two possibly different choices for the @xmath69 vector of ( [ eqn : center ] ) , the following equality is easily verified by direct multiplication and algebraic simplification : @xmath70 when @xmath71 , equation ( [ eqn : idempot ] ) shows that all valid choices for the @xmath69 vector of ( [ eqn : center ] ) yield a centering matrix , @xmath72 , that is idempotent and , thus , corresponds to a geometrical projection in n space that generally is oblique . in fact",
    ", the choice @xmath73 is the only choice that makes the @xmath74 matrix symmetric as well as idempotent , thus corresponding to a strictly orthogonal projection in n space .",
    "perhaps , an even more interesting result follows from equation ( [ eqn : idempot ] ) when @xmath67 and @xmath68 are distinct generalized inverses . in these cases , note that any valid , final choice of centering , as in equation ( [ eqn : center ] ) , will simply `` wipe - out '' and `` replace '' any and all previously applied choices of centering of form ( [ eqn : center ] ) . the corresponding implication for ( [ eqn : svdcenter ] )",
    "is that changing one s choice of @xmath31 vector typically changes the @xmath26 matrix so that it becomes orthogonal to the new @xmath31 .    to center an @xmath2 matrix at the point corresponding to its i - th row , the i - th element of @xmath69 would then be a 1 and all other elements would be null .",
    "a multivariate median vector can be defined , as in obenchain(1972a ) , using `` convex hull '' concepts to assure that the @xmath31 vector is an invariant function under all strictly nonsingular affine transformations of a given @xmath2 scatter , i.e. where no systematic reductions in dimensionality are being enforced . in direct analogy with the concept of a univariate median ,",
    "successive `` exterior '' convex hulls ( which are preserved under nonsingular affine transformations ) of the scatter initially spanning p - dimensional euclidean space would be determined and successively `` peeled away . ''",
    "whenever two or more points on an exterior hull are coincident , only one such point is set aside ( assigned a @xmath69 weight of zero ) at each stage of such peeling .",
    "the final convex hull remaining at the end of this sequence will contain neither any coincident points nor any strictly interior points .",
    "the affine invariant @xmath31 vector , which defines the corresponding affine commutative median vector , @xmath75 of equation ( [ eqn : afftran ] ) , gives equal , positive weight to each of the unique points on the innermost hull and zero weight to all other points .",
    "in this penultimate appendix , we comment on the role of mutually coincident points in determining the dimensionality of a given scatter .",
    "since coincident points clearly can not increase dimensionality and always remain coincident in the affine reduction formulation of ( [ eqn : rqaffrmd ] ) , it makes good sense computationally to limit attention to scatters of only distinct , non - coincident points .",
    "since no reasonable method will fail to exactly reproduce the zero diagonal elements of the @xmath11 matrix of ( [ eqn : sqdistmtx ] ) , minimizing the squared norm of equation ( [ eqn : sqdifnorm ] ) rightly focuses on minimizing the sum of the @xmath76 terms with @xmath77 , where n now denotes the total number of distinct points . on the other hand , individual terms in this summation",
    "could certainly be differently `` weighted '' to account for the presence or absence of additional points coincident with either the i - th or the j - th distinct point .    limiting attention to unique points and affine reduction methods",
    "also assures , when many variables are analyzed for a fixed number of points , that the maximum possible value of r will indeed equal @xmath78 in equation ( [ eqn : svdcenter ] ) . for an arbitrary configuration of n unique points",
    ", one then knows in advance that @xmath45 will ultimately become the @xmath79 identity matrix as the number of columns of @xmath2 is arbitrarily increased .",
    "furthermore , in this same limit , the corresponding @xmath60 matrix will also approach the @xmath80 matrix , which is the n @xmath1 n orthogonal projection matrix for the vector space orthogonal to @xmath69 .",
    "when @xmath82 , the large - p asymptotic h - configuration is that of n points equally spaced in @xmath81 dimensions , which corresponds to a sparse , high - dimensional dyson sphere with no point coincident with the origin .",
    "specifically , the squared distance between any 2 of these n points will be 2 , and the squared distance from each to the origin will be @xmath83 = @xmath84 .    when all of the elements of @xmath31 except one are zeros , the asymptotic configuration will depict that single point as being coincident with the origin while the remaining @xmath81 points are again equally spaced .",
    "while the squared distance between any two of these @xmath81 points will still be 2 , the squared distance from each of them to the origin point will now be @xmath83 = 1 .",
    "the first @xmath81 rows of the asymptotic @xmath26 matrix may then be any @xmath79 orthogonal matrix ( such as some permutation of the rows and columns of the @xmath85 matrix ) , while the final row is null .",
    "this configuration again spans @xmath81 dimensions and depicts another sparse , high - dimensional dyson sphere as well as its origin point .",
    "the author received extensive feedback from reviewers of his 1972 submission on this topic to _ biometrika _ as well as his 1973 submission to _ journal of multivariate analysis_. the current manuscript is brief and completely revised in organization and presention style .",
    "the basic concepts outlined here are unquestionably sound , and our objective of incorporating affine invariance and commutivity properties into algorithms for reduction of multivariable dimensionality is not `` impossible . ''",
    "thanks to modern statistical computing systems for graphical visualization and numerical search , our innovative origin - centric approach can be of much more `` practical interest '' today than it was 40 + years ago .",
    "dyson , fj . search for artificial stellar sources of infra - red radiation . _ science _ , 1960 , 131 , 1667 - 1668 .",
    "obenchain , rl .",
    "ice preference maps : nonlinear generalizations of net benefit and acceptability . _",
    "health services and outcomes research methodology _ , springerlink ( open access ) , 2008 , 8 , 31 - 56 .",
    "( two - dimensional , origin - centric maps of economic preferences . )",
    "schoenberg , ij .",
    "remarks to maurice freehet s article `` sur la definition axiomatique dune classe despaces vectoriels distancies applicables vectoriellement sur lespace de hilbert '' , _ ann .",
    "_ 1935 , 36 , 724 - 732 ."
  ],
  "abstract_text": [
    "<S> we consider statistical methods for reduction of multivariate dimensionality that have invariance and/or commutativity properties under the affine group of transformations ( origin translations plus linear combinations of coordinates along initial axes ) . </S>",
    "<S> the methods discussed here differ from traditional principal component and coordinate approaches in that they are origin - centric . because all cartesian coordinates of the origin are zero </S>",
    "<S> , it is the unique fixed point for subsequent linear transformations of point scatters . </S>",
    "<S> whenever visualizations allow shifting between and/or combining of cartesian and polar coordinate representations , as in biplots , the location of this origin is critical . </S>",
    "<S> specifically , origin - centric visualizations enhance the psychology of graphical perception by yielding scatters that can be interpreted as dyson swarms . </S>",
    "<S> the key factor is typically the analyst s choice of origin via an initial `` centering '' translation ; this choice determines whether the recovered scatter will have either no points depicted as being near the origin or else one ( or more ) points exactly coincident with this origin .    _ * keywords : affine transfomations , oblique and orthogonal projections , principal components and coordinates , multidimensional scaling , euclidean distance , cartesian and polar coordinates . * _ </S>"
  ]
}