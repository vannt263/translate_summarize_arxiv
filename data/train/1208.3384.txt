{
  "article_text": [
    "let @xmath0 be a set of @xmath1 points in @xmath2 , where @xmath7 is a small constant .",
    "let @xmath13 be a family of geometric `` regions , '' called _ ranges _ , in @xmath2 , each of which can be described algebraically by some fixed number of real parameters ( a more precise definition is given below ) .",
    "for example , @xmath13 can be the set of all axis - parallel boxes , balls , simplices , or cylinders , or the set of all intersections of pairs of ellipsoids . in the _",
    "@xmath13-range searching _ problem , we want to preprocess @xmath0 into a data structure so that the number of points of @xmath0 lying in a query range @xmath14 can be counted efficiently .",
    "similar to many previous papers , we actually consider a more general setting , the so - called _ semigroup model _",
    ", where we are given a weight function on the points in @xmath0 and we ask for the cumulative weight of the points in @xmath15 .",
    "the weights are assumed to belong to a semigroup , i.e. , subtractions are not allowed .",
    "we assume that the semigroup operation can be executed in constant time .",
    "in this paper we consider the case in which @xmath13 is a set of constant - complexity semialgebraic sets .",
    "we recall that a _ semialgebraic set _ is a subset of @xmath2 obtained from a finite number of sets of the form @xmath16 , where @xmath17 is a @xmath7-variate polynomial with integer coefficients , by boolean operations ( unions , intersections , and complementations ) .",
    "specifically , let @xmath18 denote the family of all semialgebraic sets in @xmath2 defined by at most @xmath19 polynomial inequalities of degree at most @xmath20 each .",
    "if @xmath21 are all regarded as constants , we refer to the sets in @xmath18 as _ constant - complexity semialgebraic sets _",
    "( such sets are sometimes also called _ tarski cells _ ) . by _ semialgebraic range searching _",
    "we mean @xmath18-range searching for some parameters @xmath21 ; in most applications the actual collection @xmath13 of ranges is only a restricted subset of some @xmath18 . besides being interesting in its own right",
    ", semialgebraic range searching also arises in several geometric searching problems , such as searching for a point nearest to a query geometric object , counting the number of input objects intersecting a query object , and many others .",
    "this paper focuses on the _ low storage _ version of range searching with constant - complexity semialgebraic sets  the data structure is allowed to use only linear or near - linear storage , and the goal is to make the query time as small as possible . at the other end of the spectrum we have the _ fast query _ version , where we want queries to be answered in polylogarithmic time using as little storage as possible .",
    "this variant is discussed briefly in section  [ sec : concl ] .    as is typical in computational geometry",
    ", we will use the _ real ram _ model of computation , where we can compute exactly with arbitrary real numbers and each arithmetic operation is executed in constant time .",
    "motivated by a wide range of applications , several variants of range searching have been studied in computational geometry and database systems at least since the 1980s .",
    "see @xcite for comprehensive surveys of this topic .",
    "the early work focused on the so - called _ orthogonal range searching _ , where ranges are axis - parallel boxes .",
    "after three decades of extensive work on this particular case , some basic questions still remain open .",
    "however , geometry plays little role in the known data structures for orthogonal range searching .",
    "the most basic and most studied truly geometric instance of range searching is with _ halfspaces _ , or more generally _",
    "simplices _ , as ranges .",
    "studies in the early 1990s have essentially determined the optimal trade - off between the worst - case query time and the storage ( and preprocessing time ) required by any data structure for simplex range searching .",
    "is assumed to be _ fixed _ and the implicit constants in the asymptotic notation may depend on @xmath7 .",
    "this is the setting in all the previous papers , including the present one .",
    "of course , in practical applications , this assumption may be unrealistic unless the dimension is really small .",
    "however , the known lower bounds imply that if the dimension is large , no efficient solutions to simplex range searching exist , at least in the worst - case setting . ]",
    "simplex range searching .",
    "lower bounds for this trade - off have been given by chazelle @xcite under the semigroup model of computation , where subtraction of the point weights is not allowed .",
    "it is possible that , say , the counting version of the simplex range searching problem , where we ask just for the number of points in the query simplex , might admit better solutions using subtractions , but no such solutions are known .",
    "moreover , there are recent lower - bound results when subtractions are also allowed ; see @xcite and references therein .",
    "we also refer to @xcite and references therein for recent lower bounds for the case where subtractions are also allowed .",
    "the data structures proposed for simplex range searching over the last two decades  @xcite match the known lower bounds within polylogarithmic factors .",
    "the state - of - the - art upper bounds are by ( i ) chan @xcite , who , building on many earlier results , provides a linear - size data structure with @xmath22 expected preprocessing time and @xmath3 query time , and ( ii ) matouek  @xcite , who provides a data structure with @xmath23 storage , @xmath24 query time , and @xmath25 preprocessing time .",
    "denotes an arbitrarily small positive constant .",
    "the implicit constants in the asymptotic notation may depend on it , generally tending to infinity as @xmath26 decreases to @xmath27 . ] a trade - off between space and query time can be obtained by combining these two data structures  @xcite .",
    "yao and yao  @xcite were perhaps the first to consider range searching in which ranges were delimited by graphs of polynomial functions .",
    "agarwal and matouek  @xcite have introduced a systematic study of semialgebraic range searching .",
    "building on the techniques developed for simplex range searching , they presented a linear - size data structure with @xmath28 query time , where @xmath29 . for @xmath30 ,",
    "this almost matches the performance for the simplex range searching , but for @xmath31 there is a gap in the exponents of the corresponding bounds .",
    "also see  @xcite for related recent developments .",
    "the bottleneck in the performance of the just mentioned range - searching data structure of @xcite is a combinatorial geometry problem , known as the _ decomposition of arrangements into constant - complexity cells_. here , we are given a set @xmath32 of @xmath33 algebraic surfaces in @xmath2 ( i.e. , zero sets of @xmath7-variate polynomials ) , with degrees bounded by a constant @xmath34 , and we want to decompose each cell of the arrangement @xmath35 ( see section  [ sec : cross ] for details ) into subcells that are constant - complexity semialgebraic sets , i.e. , belong to @xmath18 for some constants @xmath20 ( bound on degrees ) and @xmath19 ( number of defining polynomials ) , which may depend on @xmath7 and @xmath34 , but not on  @xmath33 .",
    "the crucial quantity is the total number of the resulting subcells over all cells of @xmath35 ; namely , if one can construct such a decomposition with @xmath36 subcells , with some constant @xmath37 , for every @xmath33 and @xmath32 , then the method of @xcite yields query time @xmath28 ( with linear storage ) .",
    "the only known general - purpose technique for producing such a decomposition is the so - called _ vertical decomposition _",
    "@xcite , which decomposes @xmath35 into roughly @xmath38 constant - complexity subcells , for @xmath39  @xcite .",
    "an alternative approach , based on _ linearization _ , was also proposed in  @xcite .",
    "it maps the semialgebraic ranges in @xmath2 to simplices in some higher - dimensional space and uses simplex range searching there . however , its performance depends on the specific form of the polynomials defining the ranges . in some special cases ( e.g. ,",
    "when ranges are balls in @xmath2 ) , linearization yields better query time than the decomposition - based technique mentioned above , but for general constant - complexity semialgebraic ranges , linearization has worse performance .    in a recent breakthrough , guth and katz  @xcite have presented a new space decomposition technique , called polynomial partitioning .",
    "for a set @xmath40 of @xmath1 points and a real parameter @xmath5 , @xmath41 , an _ @xmath5-partitioning polynomial _ for @xmath0 is a nonzero @xmath7-variate polynomial @xmath8 such that each connected component of @xmath42 contains at most @xmath11 points of @xmath0 , where @xmath43 denotes the zero set of  @xmath8 . the decomposition of @xmath2 into @xmath12 and the connected components of @xmath10",
    "is called a _ polynomial partition _ ( induced by @xmath8 ) . guth and",
    "katz show that an @xmath5-partitioning polynomial of degree @xmath9 always exists , but their argument does not lead to an efficient algorithm for constructing such a polynomial , mainly because it relies on ham - sandwich cuts in high - dimensional spaces , for which no efficient construction is known .",
    "our first result is an efficient randomized algorithm for computing an @xmath5-partitioning polynomial .",
    "[ thm : partition - algo ] given a set @xmath0 of @xmath1 points in @xmath2 , for some fixed @xmath7 , and a parameter @xmath44 , an @xmath5-partitioning polynomial for @xmath0 of degree @xmath9 can be computed in randomized expected time @xmath45 .",
    "next , we use this algorithm to bypass the arrangement - decomposition problem mentioned above .",
    "namely , based on polynomial partitions , we construct _ partition trees _  @xcite that answer range queries with constant - complexity semialgebraic sets in near - optimal time , using linear storage .",
    "an essential ingredient in the performance analysis of these partition trees is a recent combinatorial result of barone and basu @xcite , originally conjectured by the second author , which deals with the complexity of certain kinds of arrangements of zero sets of polynomials ( see theorem  [ t : basu ] ) . while there have already been several combinatorial applications of the guth - katz technique ( the most impressive being the original one in @xcite , which solves the famous erds s distinct distances problem , and some of the others presented in  @xcite ) , ours seems to be the first _ algorithmic _ application .",
    "we establish two range - searching results , both based on polynomial partitions . for the first result , we need to introduce the notion of _ @xmath46-general position _ , for an integer @xmath47 .",
    "we say that a set @xmath40 is in @xmath46-general position if no @xmath48 points of @xmath0 are contained in the zero set of a nonzero @xmath7-variate polynomial of degree at most @xmath46 , where @xmath49 .",
    "this is the number one expects for a `` generic '' point set .- variate polynomials of degree at most @xmath46 have at most @xmath50 distinct nonconstant monomials .",
    "the veronese map ( e.g. , see  @xcite ) maps @xmath2 to @xmath51 , and hyperplanes in @xmath51 correspond bijectively to @xmath48-variate polynomials of degree at most @xmath46 .",
    "it follows that any set of @xmath50 points in @xmath2 is contained in the zero set of a @xmath7-variate polynomial of degree at most @xmath46 , corresponding to the hyperplane in @xmath51 passing through the veronese images of these points .",
    "similarly , @xmath48 points in general position are not expected to have this property , because one does not expect their images to lie in a common hyperplane .",
    "see @xcite for more details . ]",
    "[ t : const - r ] let @xmath21 and @xmath52 be constants .",
    "let @xmath40 be an @xmath1-point set in @xmath53-general position , where @xmath53 is a suitable constant depending on @xmath54 , and @xmath26 .",
    "then the @xmath18-range searching problem for @xmath0 can be solved with @xmath55 storage , @xmath22 expected preprocessing time , and @xmath56 query time .",
    "we note that both here and in the next theorem , while the preprocessing algorithm is randomized , the queries are answered deterministically , and the query time bound is worst - case .    of course",
    ", we would like to handle arbitrary point sets , not only those in @xmath53-general position .",
    "this can be achieved by an infinitesimal perturbation of the points of @xmath0 . a general technique known as `` simulation of simplicity '' ( in the version considered by yap @xcite )",
    "ensures that the perturbed set @xmath57 is in @xmath53-general position .",
    "if a point @xmath58 lies in the interior of a query range @xmath59 , then so does the corresponding perturbed point @xmath60 , and similarly for @xmath61 in the interior of @xmath62 .",
    "however , for @xmath61 on the boundary of @xmath59 , we can not be sure if @xmath63 ends up inside or outside  @xmath59 .",
    "let us say that a _ boundary - fuzzy _ solution to the @xmath18-range searching problem is a data structure that , given a query @xmath64 , returns an answer in which all points of @xmath0 in the interior of @xmath59 are counted and none in the interior of @xmath62 is counted , while each point @xmath58 on the boundary of @xmath59 may or may not be counted . in some applications , we can think of the points of @xmath0 being imprecise anyway ( e.g. , their coordinates come from some imprecise measurement ) , and then boundary - fuzzy range searching may be adequate .    [",
    "c : fuzzy ] let @xmath21 , and @xmath52 be constants . then for every @xmath1-point set in @xmath2 , there is a boundary - fuzzy @xmath18-range searching data structure with @xmath55 storage , @xmath22 expected preprocessing time , and @xmath56 query time .    actually , previous results on range searching that use simulation of simplicity to avoid degenerate cases also solve only the boundary - fuzzy variant ( see e.g. @xcite ) .",
    "however , the previous techniques , even if presented only for point sets in general position , can usually be adapted to handle degenerate cases as well , perhaps with some effort , which is nevertheless routine . for our technique",
    ", degeneracy appears to be a more substantial problem because it is possible that a large subset of @xmath0 ( maybe even all of @xmath0 ) is contained in the zero set of the partitioning polynomial @xmath8 , and the recursive divide - and - conquer mechanism yielded by the partition of @xmath8 does not apply to this subset .    partially in response to this issue , we we next present a different data structure that , at a somewhat higher preprocessing cost , not only gets rid of the boundary - fuzziness condition but also has a slightly improved query time ( in terms of @xmath1 ) .",
    "the main idea is that we build an auxiliary recursive data structure to handle the potentially large subset of points that lie in the zero set of the partitioning polynomial .",
    "[ t : large - r ] let @xmath21 , and @xmath52 be constants . then the @xmath18-range searching problem for an arbitrary @xmath1-point set in @xmath2 can be solved with @xmath55 storage , @xmath65 expected preprocessing time , and @xmath66 query time , where @xmath67 is a constant depending on @xmath21 and  @xmath26 .",
    "we remark that the dependence of @xmath67 on @xmath20 , @xmath19 , and @xmath26 is reasonable , but its dependence on @xmath7 is superexponential .",
    "our algorithms work for the semigroup model described earlier . assuming that a semigroup operation can be executed in constant time",
    ", the query time remains the same as for the counting query .",
    "a reporting query  report the points of @xmath0 lying in a query range  also fits in the semigroup model , except one can not assume that a semigroup operation in this case takes constant time .",
    "the time taken by a reporting query is proportional to the cost of a counting query plus the number of reported points .",
    "our algorithm is based on the polynomial partitioning technique by guth and katz , and we begin by briefly reviewing it in section  [ sec : gk ] .",
    "next , in section  [ sec : algo ] , we describe the randomized algorithm for constructing such a partitioning polynomial .",
    "section  [ sec : cross ] presents an algorithm for computing the cells of a polynomial partition that are crossed by a semialgebraic range , and discusses several related topics .",
    "section  [ sec : range1 ] presents our first data structure , which is as in theorem  [ t : const - r ] .",
    "section  [ s : cad ] describes the method for handling points lying on the zero set of the partitioning polynomial , and section  [ sec : range2 ] presents our second data structure .",
    "we conclude in section  [ sec : concl ] by mentioning a few open problems .",
    "in this section we briefly review the guth - katz technique for later use .",
    "we begin by stating their result .",
    "[ t : gk ] given a set @xmath0 of @xmath1 points in @xmath2 and a parameter @xmath44 , there exists an @xmath5-partitioning polynomial for @xmath0 of degree at most @xmath9 ( for @xmath7 fixed ) .",
    "the degree in the theorem is asymptotically optimal in the worst case because the number of connected components of @xmath10 is @xmath68 for every polynomial @xmath8 ( see , e.g. , warren ( * ? ? ? * theorem  2 ) ) .",
    "the guth - katz proof uses the _",
    "polynomial ham sandwich _ theorem of stone and tukey  @xcite , which we state here in a version for finite point sets : _",
    "if @xmath69 are finite sets in @xmath2 and @xmath46 is an integer satisfying @xmath70 , then there exists a nonzero polynomial @xmath8 of degree at most @xmath46 that simultaneously bisects all the sets @xmath71 .",
    "_ here `` @xmath8 bisects @xmath71 '' means that @xmath72 in at most @xmath73 points of @xmath71 and @xmath74 in at most @xmath73 points of  @xmath71 ; @xmath8 might vanish at any number of the points of @xmath71 , possibly even at all of them .",
    "guth and katz inductively construct collections @xmath75 of subsets of @xmath0 . for @xmath76 , @xmath77 consists of at most @xmath78 pairwise - disjoint subsets of @xmath0 , each of size at most @xmath79 ; the union of these sets does not have to contain all points of @xmath0 .",
    "initially , we have @xmath80 .",
    "the algorithm stops as soon as each subset in @xmath81 has at most @xmath11 points .",
    "this implies that @xmath82 .",
    "having constructed @xmath83 , we use the polynomial ham - sandwich theorem to construct a polynomial @xmath84 that bisects each set of @xmath83 , with @xmath85 ( this is indeed an asymptotic upper bound for the smallest @xmath46 satisfying @xmath86 , assuming @xmath7 to be a constant ) . for every subset @xmath87 ,",
    "let @xmath88 and @xmath89 .",
    "we set @xmath90 ; empty subsets are not included in @xmath77 .",
    "the desired @xmath5-partitioning polynomial for @xmath0 is then the product @xmath91 .",
    "we have @xmath92 by construction , the points of @xmath0 lying in a single connected component of @xmath10 belong to a single member of @xmath81 , which implies that each connected component contains at most @xmath11 points of  @xmath0 .",
    "we begin by observing that @xmath93 is the number of all nonconstant monomials of degree at most @xmath46 in @xmath7 variables .",
    "thus , we fix a collection @xmath94 of @xmath95 such monomials .",
    "let @xmath96 be the corresponding _ veronese map _ , which maps a point @xmath97 to the @xmath48-tuple of the values at @xmath98 of the monomials from @xmath94 .",
    "for example , for @xmath99 , @xmath100 , and @xmath101 , we may use @xmath102 , where @xmath94 is the set of the eight monomials appearing as components of @xmath103 .",
    "let @xmath104 be the image of the given @xmath71 under this veronese map , for , @xmath105 . by the standard _ ham - sandwich theorem _",
    "( see , e.g. , @xcite ) , there exists a hyperplane @xmath106 in @xmath107 that simultaneously bisects all the @xmath108 s , in the sense that each open halfspace bounded by @xmath106 contains at most half of the points of each of the sets @xmath108 . in a more algebraic language",
    ", there is a nonzero @xmath48-variate linear polynomial , which we also call @xmath106 , that bisects all the @xmath108 s , in the sense of being positive on at most half of the points of each @xmath108 , and being negative on at most half of the points of each @xmath108",
    ". then @xmath109 is the desired @xmath7-variate polynomial of degree at most @xmath46 bisecting all the  @xmath71 s .",
    "in this section we present an efficient randomized algorithm that , given a point set @xmath0 and a parameter @xmath110 , constructs an @xmath5-partitioning polynomial . the main difficulty in converting the above proof of the guth - katz partitioning theorem into an efficient algorithm is the use of the ham - sandwich theorem in the possibly high - dimensional space @xmath107 .",
    "a straightforward algorithm for computing ham - sandwich cuts in @xmath107 inspects all possible ways of splitting the input point sets by a hyperplane , and has running time about @xmath111 .",
    "compared to this easy upper bound , the best known ham - sandwich algorithms can save a factor of about @xmath1 @xcite , but this is insignificant in higher dimensions .",
    "a recent result of knauer , tiwari , and werner  @xcite shows that a certain incremental variant of computing a ham - sandwich cut is @xmath112$]-hard ( where the parameter is the dimension ) , and thus one perhaps should not expect much better exact algorithms .    we observe that the exact bisection of each @xmath71 is not needed in the guth - katz construction ",
    "it is sufficient to replace the stone  tukey polynomial ham - sandwich theorem by a weaker result , as described below .",
    "we say that a polynomial @xmath8 is _ well - dissecting _ for a point set @xmath113 if @xmath72 on at most @xmath114 points of @xmath113 and @xmath74 on at most @xmath114 points of  @xmath113 .",
    "given point sets @xmath69 in @xmath2 with @xmath1 points in total , we present a las - vegas algorithm for constructing a polynomial @xmath8 of degree @xmath115 that is well - dissecting for at least @xmath116 of the @xmath71 s .    as in the above proof of the stone ",
    "tukey polynomial ham - sandwich theorem , let @xmath46 be the smallest integer satisfying @xmath70 .",
    "we fix a collection @xmath94 of @xmath48 distinct nonconstant monomials of degree at most @xmath46 , and let @xmath103 be the corresponding veronese map . for each @xmath117",
    ", we pick a point @xmath118 uniformly at random and compute @xmath119 .",
    "let @xmath106 be a hyperplane in @xmath107 passing through @xmath120 , which can be found by solving a system of linear equations , in @xmath121 time .",
    "if the points @xmath120 are not affinely independent , then @xmath106 is not determined uniquely ( this is a technical nuisance , which the reader may want to ignore on first reading ) . in order to handle this case , we prepare in advance , before picking the @xmath122 s , _ auxiliary _ affinely independent points @xmath123 in @xmath107 , which are in general position with respect to @xmath124 ; here we mean the `` ordinary '' general position , i.e. , no unnecessary affine dependences , that involve some of the @xmath125 s and the other points , arise .",
    "the points @xmath125 can be chosen at random , say , uniformly in the unit cube ; with high probability , they have the desired general position property .",
    "( if we do not want to assume the capability of choosing a random real number , we can pick the @xmath125 s uniformly at random from a sufficiently large discrete set . )",
    "if the dimension of the affine hull of @xmath120 is @xmath126 , we choose the hyperplane @xmath106 through @xmath120 and @xmath127 . if @xmath106 is not unique , i.e. , @xmath128 are not affinely independent with respect to @xmath129 , which we can detect while solving the linear system , we restart the algorithm by choosing @xmath123 anew and then picking new @xmath130 . in this way , after a constant expected number of iterations , we obtain the uniquely determined hyperplane @xmath106 through @xmath120 and @xmath127 as above , and we let @xmath131 denote the corresponding @xmath7-variate polynomial .",
    "we refer to these steps as one _ trial _ of the algorithm . for each @xmath71",
    ", we check whether @xmath8 is well - dissecting for @xmath71 .",
    "if @xmath8 is well - dissecting for only fewer than @xmath132 sets , then we discard @xmath8 and perform another trial .",
    "we now analyze the expected running time of the algorithm .",
    "the intuition is that @xmath8 is expected to well - dissect a significant fraction , say at least half , of the sets @xmath71 .",
    "this intuition is reflected in the next lemma .",
    "let @xmath133 be the indicator variable of the event : _",
    "@xmath71 is * not * well - dissected by @xmath8_.    [ l : exi ] for every @xmath134 , @xmath135 \\le 1/4 $ ] .",
    "let us fix @xmath136 and the choices of @xmath137 ( and thus of @xmath138 ) for all @xmath139 .",
    "let @xmath140 be the dimension of @xmath141 , the affine hull of @xmath142 .",
    "then the resulting hyperplane @xmath106 passes through the @xmath143-flat @xmath144 spanned by @xmath141 and @xmath145 , irrespective of which point of @xmath71 is chosen .",
    "if @xmath122 , the point chosen from @xmath71 , is such that @xmath146 lies on @xmath141 , then @xmath106 also passes through @xmath147 .",
    "put @xmath148 , and let us project the configuration orthogonally to a 2-dimensional plane @xmath149 orthogonal to @xmath144 .",
    "then @xmath144 appears as a point @xmath150 , and @xmath108 projects to a ( multi)set @xmath151 in @xmath149 .",
    "the random hyperplane @xmath106 projects to a random line @xmath152 in @xmath149 , whose choice can be interpreted as follows : pick @xmath153 uniformly at random ; if @xmath154 , then @xmath152 is the unique line through @xmath155 and @xmath156 ; otherwise , when @xmath157 , @xmath152 is the unique line through @xmath156 and @xmath158 ; by construction , @xmath159 . the indicator variable @xmath133 is @xmath160 if and only if the resulting @xmath152 has more than @xmath161 points of @xmath151 , counted with multiplicity , ( strictly ) on one side .",
    "the special role of @xmath158 can be eliminated if we first move the points of @xmath151 coinciding with @xmath156 to the point @xmath158 , and then slightly perturb the points so as to ensure that all points of @xmath151 are distinct and lie at distinct directions from @xmath156 ; it is easy to see that these transformations can not decrease the probability of @xmath162 .",
    "finally , we note that the side of @xmath152 containing a point @xmath163 only depends on the direction of the vector @xmath164 , so we can also assume the points of @xmath151 to lie on the unit circle around @xmath156 .    using ( a simple instance of ) the standard planar ham - sandwich theorem , we partition @xmath151 into two subsets @xmath165 and @xmath166 of equal size by a line through the center @xmath156",
    ". then we bisect @xmath165 by a ray from @xmath156 , and we do the same for @xmath166 .",
    "it is easily checked ( see figure  [ f : semi2-quarters ] ) that there always exist two of the resulting quarters , one of @xmath165 and one of @xmath166 ( the ones whose union forms an angle @xmath167 between the two bisecting rays ) , such that every line connecting @xmath156 with a point in either quarter contains at least @xmath168 points of @xmath151 on each side . referring to these quarters as `` good '' , we now take one of the bisecting rays , say that of @xmath165 , and rotate it about @xmath156 away from the good quarter of @xmath165 .",
    "each of the first @xmath169 points that the ray encounters has the property that the line supporting the ray has at least @xmath169 points of @xmath151 on each side .",
    "this implies that , for at least half of the points in each of the two remaining quarters , the line connecting @xmath156 to such a point has at least @xmath169 points of @xmath151 on each side .",
    "hence at most @xmath170 points of @xmath108 can lead to a cut that is not well - dissecting for  @xmath108 .",
    "we conclude that , still conditioned on the choices of @xmath137 , @xmath139 , the event @xmath162 has probability at most @xmath171 .",
    "since this holds for every choice of the @xmath137 , @xmath139 , the unconditional probability of @xmath162 is also at most @xmath171 , and thus @xmath135\\le 1/4 $ ] as claimed .",
    "hence , the expected number of sets @xmath71 that are not well - dissected by @xmath8 is @xmath172 = \\sum_{i=1}^k \\ex [ x_i ] \\le k/4.\\ ] ] by markov s inequality , with probability at least @xmath173 , at least half of the @xmath71 s are well - dissected by  @xmath8 .",
    "we thus obtain a polynomial that is well - dissecting for at least half of the @xmath71 s after an expected constant number of trials .",
    "it remains to estimate the running time of each trial .",
    "the points @xmath174 can be chosen in @xmath55 time .",
    "computing @xmath106 involves solving a @xmath175 linear system , which can be done in @xmath121 time using gaussian elimination .",
    "note that we do _ not _ actually compute the entire sets @xmath176 .",
    "no computation is needed for passing from @xmath106 to @xmath8we just re - interpret the coefficients . to check which of @xmath177 are well - dissected by @xmath8",
    ", we evaluate @xmath8 at each point of @xmath178 .",
    "first we evaluate each of the @xmath48 monomials in @xmath94 at each point of @xmath113 .",
    "if we proceed incrementally , from lower degrees to higher ones , this can be done with @xmath179 operations per monomial and point of @xmath113 , in @xmath180 time in total .",
    "then , in additional @xmath180 time , we compute the values of @xmath181 , for all @xmath182 , from the values of the monomials . putting everything together we obtain the following lemma .",
    "[ l : dissect ] given point sets @xmath69 in @xmath2 ( for fixed @xmath7 ) with @xmath1 points in total , a polynomial @xmath8 of degree @xmath115 that is well - dissecting for at least @xmath116 of the @xmath71 s can be constructed in @xmath183 randomized expected time .",
    "we now describe the algorithm for computing an @xmath5-partitioning polynomial @xmath8 .",
    "we essentially imitate the guth  katz construction , with lemma  [ l : dissect ] replacing the polynomial ham - sandwich theorem , but with an additional twist .",
    "the algorithm works in phases . at the end of the @xmath184-th phase , for @xmath185",
    ", we have a family @xmath186 of @xmath184 polynomials and a family @xmath77 of at most @xmath78 pairwise - disjoint subsets of @xmath0 , each of size at most @xmath187 .",
    "similar to the guth ",
    "katz construction , @xmath77 is not necessarily a partition of @xmath0 , since the points of @xmath188 do not belong to @xmath189 .",
    "initially , @xmath190 .",
    "the algorithm stops when each set in @xmath77 has at most @xmath11 points . in the @xmath184-th phase ,",
    "the algorithm constructs @xmath84 and @xmath77 from @xmath191 and @xmath83 , as follows .    at the beginning of the @xmath184-th phase ,",
    "let @xmath192 be the family of the `` large '' sets in @xmath193 , and set @xmath194 .",
    "we also initialize the collection @xmath195 to @xmath196 , the family of `` small '' sets in @xmath193",
    ". then we perform at most @xmath197 dissecting steps , as follows : after @xmath19 steps , we have a family @xmath198 of polynomials , the current set @xmath195 , and a subfamily @xmath199 of size at most @xmath200 , consisting of the members of @xmath201 that were not well - dissected by any of @xmath198 . if @xmath202 we choose , using lemma  [ l : dissect ] , a polynomial @xmath203 of degree at most @xmath204 ( with a suitable constant @xmath205 that depends only on @xmath7 ) that well - dissects at least half of the members of @xmath206 . for each @xmath207 , let @xmath208 and @xmath209 .",
    "if @xmath210 is well - dissected , i.e. , @xmath211 , then we add @xmath212 to @xmath195 , and otherwise , we add @xmath210 to @xmath213 .",
    "note that in the former case the points @xmath214 satisfying @xmath215 are `` lost '' and do not participate in the subsequent dissections . by lemma  [ l : dissect ] , @xmath216 .",
    "the @xmath184-th phase is completed when @xmath217 , in which case we set is not necessarily well - dissecting , because it does not control the sizes of subsets with positive or with negative signs . ]",
    "@xmath218 . by construction ,",
    "each point set in @xmath195 has at most @xmath187 points , and the points of @xmath0 not belonging to any set of @xmath195 lie in @xmath219 .",
    "furthermore , @xmath220 where again the constant of proportionality depends only on @xmath7 .",
    "since every set in @xmath83 is split into at most two sets before being added to @xmath77 , @xmath221 .",
    "if @xmath77 contains subsets with more than @xmath11 points , we begin the @xmath222-st phase with the current @xmath195 ; otherwise the algorithm stops and returns @xmath223 .",
    "this completes the description of the algorithm .",
    "clearly , @xmath224 , the number of phases of the algorithm , is at most @xmath225 .",
    "following the same argument as in  @xcite , and as briefly sketched in section  [ sec : gk ] , it can be shown that all points lying in a single connected component of @xmath10 belong to a single member of @xmath226 , and thus each connected component contains at most @xmath11 points of @xmath0 . since the degree of @xmath84 is @xmath227 , @xmath228 , and @xmath229 ,",
    "we conclude that @xmath230    as for the expected running time of the algorithm , the @xmath19-th step of the @xmath184-th phase takes @xmath231 expected time , so the @xmath184-th phase takes a total of @xmath232 expected time . substituting @xmath228 in the above bound and summing over all @xmath184 , the overall expected",
    "running time of the algorithm is @xmath45 .",
    "this completes the proof of theorem  [ thm : partition - algo ] .",
    "theorem  [ thm : partition - algo ] is employed for the preprocessing in our range - searching algorithms in theorems  [ t : const - r ] and  [ t : large - r ] . in theorem  [ t : const - r ]",
    "we take @xmath5 to be a large constant , and the expected running time in theorem  [ thm : partition - algo ] is @xmath55 .",
    "however , in theorem  [ t : large - r ] , we require @xmath5 to be a small fractional power of @xmath1 , say @xmath233 .",
    "it is a challenging open problem to improve the expected running time in theorem  [ thm : partition - algo ] to @xmath234 when @xmath5 is such a small fractional power of @xmath1 .",
    "the bottleneck in the current algorithm is the subproblem of evaluating a given @xmath7-variate polynomial @xmath8 of degree @xmath235 at @xmath1 given points ; everything else can be performed in @xmath236 expected time .",
    "finding the signs of @xmath8 at those points would actually suffice , but this probably does not make the problem any simpler .",
    "this problem of _ multi - evaluation _ of multivariate real polynomials has been considered in the literature , and there is a nontrivial improvement over the straightforward @xmath237 algorithm , due to nsken and ziegler @xcite . concretely , in the bivariate case ( @xmath99 ) , their algorithm can evaluate a bivariate polynomial of degree @xmath238 at @xmath1 given points using @xmath239 arithmetic operations .",
    "it is based on fast matrix multiplication , and even under the most optimistic possible assumption on the speed of matrix multiplication , it can not get below @xmath240 .",
    "although this is significantly faster than our naive @xmath237-time algorithm , which is @xmath241 in this bivariate case , it is still a far cry from what we are aiming at . however , its running time is still a far cry from what we are aiming at .",
    "let us remark that in a different setting , for polynomials over finite fields ( and over certain more general finite rings ) , there is a remarkable method for multi - evaluation by kedlaya and umans  @xcite achieving @xmath242 running time , where @xmath243 is the cardinality of the field .",
    "in this section we define the crossing number of a polynomial partition and describe an algorithm for computing the cells of a polynomial partition that are crossed by a semialgebraic range , both of which will be crucial for our range - searching data structures .",
    "we begin by recalling a few results on arrangements of algebraic surfaces .",
    "we refer the reader to @xcite for a comprehensive review of such arrangements .",
    "let @xmath32 be a finite set of algebraic surfaces in @xmath2 .",
    "the _ arrangement _ of @xmath32 , denoted by @xmath35 , is the partition of @xmath2 into maximal relatively open connected subsets , called _ cells _ , such that all points within each cell lie in the same subset of surfaces of @xmath32 ( and in no other surface ) .",
    "if @xmath244 is a set of @xmath7-variate polynomials , then with a slight abuse of notation , we use @xmath245 to denote the arrangement @xmath246 of their zero sets .",
    "we need the following result on arrangements , which follows from proposition  7.33 and theorem  16.18 in  @xcite .",
    "[ t : make - arrg ] let @xmath247 be a set of @xmath19 real @xmath7-variate polynomials , each of degree at most  @xmath20 .",
    "then the arrangement @xmath245 in @xmath2 has at most @xmath248 cells , and it can be computed in time at most @xmath249 . each cell is described as a semialgebraic set using at most @xmath250 polynomials of degree bounded by @xmath251 .",
    "moreover , the algorithm supplies an explicitly computed point in each cell .    a key ingredient for the analysis of our range - searching data structure is the following recent result of barone and basu  @xcite , which is a refinement of a series of previous studies ; e.g. , see  @xcite : see  @xcite :    [ t : basu ] let @xmath252 be a @xmath48-dimensional algebraic variety in @xmath2 defined by a finite set @xmath253 of @xmath7-variate polynomials , each of degree at most @xmath20 , and let @xmath244 be a set of @xmath19 polynomials of degree at most @xmath254 .",
    "then the number of cells of @xmath255 ( of all dimensions ) that are contained in @xmath252 is bounded by @xmath256 .",
    "let @xmath0 be a set of @xmath1 points in @xmath2 , and let @xmath8 be an @xmath5-partitioning polynomial for  @xmath0 .",
    "recall that the _ polynomial partition _",
    "@xmath257 induced by @xmath8 is the partition of @xmath2 into the zero set @xmath12 and the connected components @xmath258 of @xmath10 .",
    "as already noted , warren s theorem  @xcite implies that @xmath259 .",
    "we call @xmath260 the _ cells _ of @xmath261 ( although they need not be cells in the sense typical , e.g. , in topology ; they need not even be simply connected ) .",
    "@xmath261 also induces a partition @xmath262 of @xmath0 , where @xmath263 is the _ exceptional part _ , and @xmath264 , for @xmath265 , are the _ regular parts_. by construction , @xmath266 for every @xmath267 , but we have no control over the size of @xmath268this will be the source of most of our technical difficulties .    next , let @xmath59 be a range in @xmath269 .",
    "we say that @xmath59 _ crosses _ a cell @xmath270 if neither @xmath271 nor @xmath272 .",
    "the _ crossing number _ of @xmath59 is the number of cells of @xmath261 crossed by @xmath59 , and the _ crossing number _ of @xmath261 ( with respect to  @xmath269 ) is the maximum of the crossing numbers of all @xmath273 .",
    "similar to many previous range - searching algorithms  @xcite , the crossing number of @xmath274 will determine the query time of our range - searching algorithms described in sections  [ sec : range1 ] and  [ sec : range2 ] .",
    "[ l : cr ] if @xmath261 is a polynomial partition induced by an @xmath5-partitioning polynomial of degree at most @xmath46 , then the crossing number of @xmath261 with respect to  @xmath269 , with @xmath275 , is at most @xmath276 , where @xmath277 is a suitable constant depending only on  @xmath7 .",
    "let @xmath273 ; then @xmath59 is a boolean combination of up to @xmath19 sets of the form @xmath278 , where @xmath279 are polynomials of degree at most @xmath20 .",
    "if @xmath59 crosses a cell @xmath270 , then at least one of the ranges @xmath280 also crosses @xmath270 , and thus it suffices to establish that the crossing number of any range @xmath59 , defined by a single @xmath7-variate polynomial inequality @xmath281 of degree at most @xmath20 , is at most @xmath282 .",
    "we apply theorem  [ t : basu ] with @xmath283 , which is an algebraic variety of dimension @xmath284 , and with @xmath285 and @xmath286 , where @xmath8 is the @xmath5-partitioning polynomial . then , for each cell @xmath270 crossed by @xmath59",
    ", @xmath287 is a nonempty union of some of the cells in @xmath288 that lie in @xmath252 .",
    "thus , the crossing number of @xmath59 is at most @xmath289 .",
    "we need to perform the following algorithmic primitives ( for @xmath7 _ fixed _ as usual ) for the range - searching algorithms that we will later present :    * given an @xmath5-partitioning polynomial @xmath8 of degree @xmath235 , compute ( a suitable representation of ) the partition @xmath261 and the induced partition of @xmath0 into @xmath290 .",
    "+ by computing @xmath291 , using theorem  [ t : make - arrg ] , and then testing the membership of each point @xmath58 in each cell @xmath270 in time polynomial in  @xmath5 , the above operation can be performed in @xmath292 time , this would be the second step , together with an improved construction of an @xmath5-partitioning polynomial @xmath8 ( concretely , an improved multi - point evaluation procedure for @xmath8 ) as discussed at the end of section  [ sec : algo ] , needed to improve the preprocessing time in theorem  [ t : large - r ] . ]",
    "where @xmath293 .",
    "* given ( a suitable representation of ) @xmath261 as in ( a1 ) and a query range @xmath294 , i.e. , a range defined by a single @xmath7-variate polynomial @xmath17 of degree @xmath275 , compute which of the cells of @xmath261 are crossed by @xmath59 and which are completely contained in @xmath59 .",
    "+ we already have the arrangement @xmath291 , and we compute @xmath295 .",
    "for each cell of @xmath295 contained in @xmath296 , we locate its representative point in @xmath291 , and this gives us the cells crossed by @xmath59 .",
    "for the remaining cells , we want to know whether they are inside @xmath59 or outside , and for that , it suffices to determine the sign of @xmath17 at the representative points . using theorem  [ t : make - arrg ]",
    ", the above task can thus be accomplished in time @xmath297 , with @xmath293 .",
    "we are now ready to describe our first data structure for @xmath269-range searching , which is a constant fan - out ( branching degree ) partition tree , and which works for points in general position .",
    "let @xmath0 be a set of @xmath1 points in @xmath2 , and let @xmath298 be constants .",
    "we choose @xmath5 as a ( large ) constant depending on @xmath21 , and the prespecified parameter @xmath26 .",
    "we assume @xmath0 to be in @xmath53-general position for some sufficiently large constant @xmath299 .",
    "we construct a partition tree @xmath300 of fan - out @xmath301 as follows .",
    "we first construct an @xmath5-partitioning polynomial @xmath8 for @xmath0 using theorem  [ thm : partition - algo ] , and compute the partition @xmath261 of @xmath2 induced by @xmath8 , as well as the corresponding partition @xmath302 of @xmath0 , where @xmath259 . since @xmath5 is a constant , the ( a1 ) operation , discussed in section  [ sec : cross ] , performs this computation in @xmath55 time .",
    "we choose @xmath53 so as to ensure that it is at least @xmath303 , and then our assumption that @xmath0 is in @xmath53-general position implies that the size of @xmath304 is bounded by @xmath53 .",
    "we set up the root of @xmath300 , where we store    1 .",
    "the partitioning polynomial @xmath8 , and a suitable representation of the partition @xmath261 ; 2 .   a list of the points of the exceptional part @xmath268 ; and 3 .",
    "@xmath305 , the sum of the weights of the points of the regular part @xmath306 , for each @xmath267 .",
    "the partition polynomial @xmath8 , a suitable representation of the partition @xmath261 , a list of the points of the exceptional part @xmath268 , and @xmath305 , the sum of weights of all points of @xmath306 , for each @xmath267 .",
    "the regular parts @xmath306 are not stored explicitly at the root . instead ,",
    "for each @xmath306 we recursively build a subtree representing it .",
    "the recursion terminates , at leaves of @xmath300 , as soon as we reach point sets of size smaller than a suitable constant @xmath307 .",
    "the points of each such set are stored explicitly at the corresponding leaf of @xmath300 .    since each node of @xmath300 requires only a constant amount of storage and each point of @xmath0",
    "is stored at only one node of @xmath300 , the total size of @xmath300 is @xmath55 .",
    "the preprocessing time is @xmath22 since @xmath300 has depth @xmath308 and each level is processed in @xmath55 time .    to process a query range @xmath273 , we start at the root of @xmath300 and maintain a global counter which is initially set to @xmath27 . among the cells @xmath260 of the partition @xmath261 stored at the root , we find , using the ( a2 ) operation , those completely contained in @xmath59 , and those crossed by @xmath59 . actually , we compute a superset of the cells that @xmath59 crosses , namely , the cells crossed by the zero set of at least one of the ( at most @xmath19 ) polynomials defining @xmath59 .",
    "for each cell @xmath271 , we add the weight @xmath305 to the global counter .",
    "we also add to the global counter the weights of the points in @xmath309 , which we find by testing each point of @xmath268 separately .",
    "then we recurse in each subtree corresponding to a cell @xmath270 crossed by @xmath59 ( in the above weaker sense ) .",
    "the leaves , with point sets of size @xmath179 , are processed by inspecting their points individually . by lemma  [ l :",
    "cr ] , the number of cells crossed by any of the polynomials defining @xmath59 at any interior node of @xmath300 is at most @xmath310 , where @xmath311 is a constant independent of  @xmath5 .    the query time @xmath312 obeys the following recurrence : @xmath313      o(n ) & \\mbox{for $ n \\le n_0 $ , }      \\end{array } \\right .\\ ] ] it is well known ( e.g. , see  @xcite ) , and easy to check , that the recurrence solves to @xmath314 , for every fixed @xmath52 , with an appropriate sufficiently large choice of @xmath5 as a function of @xmath315 and @xmath26 , and with an appropriate choice of @xmath307 .",
    "this concludes the proof of theorem  [ t : const - r ] .",
    "now we consider the case where the points of @xmath0 are not necessarily in @xmath53-general position .",
    "as was mentioned in the introduction , we apply a general perturbation scheme of yap @xcite to the previous range - searching algorithm .",
    "yap s scheme is applicable to an algorithm whose input is a sequence of real numbers ( in our case , the @xmath316 point coordinates plus the coefficients in the polynomials specifying the query range ) .",
    "it is assumed that the algorithm makes decision steps by way of evaluating polynomials with rational coefficients taken from a finite set @xmath317 , where the input parameters are substituted for the variables .",
    "the algorithm makes a 3-way branching depending on the sign of the evaluation .",
    "the set @xmath317 does not depend on the input .",
    "the input is considered degenerate if one of the signs in the tests is  0 .",
    "yap s scheme provides a black box for evaluating the polynomials from @xmath317 that , whenever the actual value is @xmath27 , also supplies a nonzero sign , @xmath318 or @xmath319 , which the algorithm may use for the branching , instead of the zero sign .",
    "thus , the algorithm never `` sees '' any degeneracy .",
    "yap s method guarantees that these signs are consistent , i.e. , for every input , the branching done in this way corresponds to some infinitesimal perturbation of the input sequence , and so does the output of the algorithm ( in our case , the answer to a range - searching query ) .    for us",
    ", it is important that if the degrees of the polynomials in @xmath317 are bounded by a constant , the black box also operates in time bounded by a constant ( which is apparent from the explicit specification in @xcite ) .",
    "thus , applying the perturbation scheme influences the running time only by a multiplicative constant .",
    "it can be checked the range - searching algorithm presented above is of the required kind , with all branching steps based on the sign of suitable polynomials in the coordinates of the input points and in the coefficients of the polynomials in the query range , and the degrees of these polynomials are bounded by a constant . for producing the partitioning polynomial @xmath8 , we solve systems of linear equations , and thus the coefficients of @xmath8 are given by certain determinants obtained from cramer s rule . the computation of the polynomial partition and locating points in it is also based on the signs of suitable bounded - degree polynomials , as can be checked by inspecting the relevant algoritms , and similarly for intersecting a polynomial partition with the query range .",
    "the key fact is that all computations in the algorithm are of constant - bounded depth  each of the values ever computed is obtained from the input parameters by a constant number of arithmetic operations .",
    "we also observe that when yap s scheme is applied , the algorithm never finds more than @xmath53 points in the exceptional set @xmath268 ( in any of the nodes of the partition tree ) . indeed ,",
    "if @xmath320 input points lie in the zero set of a polynomial @xmath8 as in the algorithm , then a certain polynomial in the coordinates of these @xmath320 points vanishes ( see , e.g. , ( * ? ? ?",
    "* lemma  6.3 ) ) .",
    "thus , assuming that the algorithm found @xmath320 points on @xmath12 , it could test the sign of this polynomial at such points , and the black box would return a nonzero sign , which would contradict the consistency of yap s scheme .    after applying yap s scheme ,",
    "the preprocessing cost , storage , and query time remain asymptotically the same as in theorem  [ t : const - r ] ( but with larger constants of proportionality ) .",
    "since the output of the algorithm corresponds to some infinitesimally perturbed version of the input ( point set and query range ) , we obtain a boundary - fuzzy answer for the original point set .",
    "if the points of @xmath0 are not in @xmath53-general position , we perturb them infinitesimally using the general perturbation scheme of yap @xcite , so that the perturbed set is in @xmath53-general position",
    ". then we construct the above data structure on the perturbed point set . by answering the query for this perturbed set",
    ", we obtain a boundary - fuzzy answer for the original point set .",
    "the preprocessing cost , storage , and query time remain asymptotically the same as in theorem  [ t : const - r ] .",
    "this concludes the proof of corollary  [ c : fuzzy ] .",
    "as mentioned in the introduction , if we construct an @xmath5-partitioning polynomial @xmath8 for an arbitrary point set @xmath0 , the exceptional set @xmath263 may be large , as is schematically indicated in fig .",
    "[ f : semi2-patches ]  ( left ) .",
    "since @xmath268 is not partitioned by @xmath8 in any reasonable sense , it must be handled differently , as described below .",
    "following the terminology in  @xcite , we call a direction @xmath321 _ good _ for @xmath8 if , for every @xmath322 , the polynomial @xmath323 does not vanish identically ; that is , any line in direction @xmath324 intersects @xmath12 at finitely many points . as argued in  ( * ? ? ? * and pp .",
    "314315 ) , a random direction is good for @xmath8 with probability  1 . by choosing a good direction and rotating the coordinate system ,",
    "we assume that the @xmath325-direction , referred to as the _ vertical _ direction , is good for @xmath8 .    in order to deal with @xmath268 , we partition @xmath12 into finitely many pieces , called _ patches _ , in such a way that each of the patches is _ monotone _ in the vertical direction , meaning that every line parallel to the @xmath325-axis intersects it at most once .",
    "this is illustrated , in the somewhat trivial 2-dimensional setting , in fig .",
    "[ f : semi2-patches ] ( right ) : ( middle ) , there are five one - dimensional patches @xmath326 , plus four 0-dimensional patches .",
    "then we treat each patch @xmath149 separately : we project the point set @xmath327 orthogonally to the coordinate hyperplane @xmath328 , and we preprocess the projected set , denoted @xmath329 , for range searching with suitable ranges .",
    "these ranges are projections of ranges of the form @xmath330 , where @xmath331 is one of the original ranges . in fig .",
    "[ f : semi2-patches ]   ( right ) , ( middle ) , the patch @xmath332 is drawn thick , a range @xmath59 is depicted as a gray disk , and the projection @xmath333 of @xmath334 is shown as a thick segment in  @xmath335 .",
    "the projected range @xmath336 is typically more complicated than the original range @xmath59 ( it involves more polynomials of larger degrees ) , but , crucially , it is only @xmath337-dimensional , and @xmath337-dimensional queries can be processed somewhat more efficiently than @xmath7-dimensional ones , which makes the whole scheme work .",
    "we will discuss this in more detail in section  [ sec : range2 ] below , but first we recall the notion of _ cylindrical algebraic decomposition _ ( cad , or also _ collins decomposition _ ) , which is a tool that allows us to decompose @xmath12 into monotone patches , and also to compute the projected ranges  @xmath336 .    given a finite set @xmath247 of @xmath7-variate polynomials , a _",
    "cylindrical algebraic decomposition adapted to @xmath244 _ is a way of decomposing @xmath2 into a finite collection of relatively open _ cells _ , which have a simple shape ( in a suitable sense ) , and which refine the arrangement @xmath245 .",
    "we refer , e.g. , to ( * ? ? ?",
    "* chap .  5.12 ) for the definition and construction of the `` standard '' cad . here",
    "we will use a simplified variant , which can be regarded as the `` first stage '' of the standard cad , and which is captured by ( * ? ? ?",
    "* theorem  5.14 , algorithm  12.1 ) .",
    "we also refer to ( * ? ? ?",
    "* appendix  a ) for a concise treatment , which is perhaps more accessible at first encounter .    let @xmath244 be as above . to obtain the first - stage cad for @xmath8 ,",
    "one constructs a suitable collection @xmath338 of polynomials in the variables @xmath339 ( denoted by @xmath340 in @xcite ) . roughly speaking ,",
    "the zero sets of the polynomials in @xmath341 , viewed as subsets of the coordinate hyperplane @xmath335 ( which is identified with @xmath342 ) , contain the projection onto @xmath335 of all intersections @xmath343 , @xmath344 , as well as the projection of the loci in @xmath345 where @xmath345 has a vertical tangent hyperplane , or a singularity of some kind .",
    "the actual construction of @xmath341 is somewhat more complicated , and we refer to the aforementioned references for more details .     having constructed @xmath341 , the first - stage cad is obtained as the arrangement @xmath346 in @xmath2 , where the polynomials in @xmath341 are now considered as @xmath7-variate polynomials ( in which the variable @xmath325 is not present ) . in geometric terms , we erect a `` vertical wall '' in @xmath2 over each zero set within @xmath335 of a @xmath337-variate polynomial from @xmath341 , and the cad is the arrangement of these vertical walls plus the zero sets of @xmath347 .",
    "the first - stage cad is illustrated in fig .",
    "[ f : semi2-cad ] , for the same ( single ) polynomial as in fig .",
    "[ f : semi2-patches ]  ( left ) . in our algorithm",
    ", we are interested in the cells of the cad that are contained in some of the sero sets @xmath345 ; these are going to be the monotone patches alluded to above .",
    "we note that using the first - stage cad for the purpose of decomposing @xmath12 into monotone patches seems somewhat wasteful .",
    "for example , the number of patches in fig .",
    "[ f : semi2-patches ] is considerably smaller than the number of patches in the cad in fig .",
    "[ f : semi2-cad ] .",
    "but the cad is simple and well known , and ( as will follow from the analysis in section  [ sec : range2 ] ) possible improvements in the number of patches ( e.g.  using the vertical - decomposition technique  @xcite ) do not seem to influence our asymptotic bounds on the performance of the resulting range - searching data structure .",
    "the following lemma summarizes the properties of the first - stage cad that we will need ; we refer to ( * ? ? ?",
    "* theorem  5.14 , algorithm  12.1 ) for a proof .",
    "[ l : cad ] given a set @xmath348 $ ] of polynomials , each of degree at most  @xmath46 , there is a set @xmath338 of @xmath349 polynomials in @xmath350 $ ] , each of degree @xmath351 , which can be computed in time @xmath352 , such that the first - stage cad defined by these polynomials , i.e. , the arrangement @xmath346 in @xmath2 , has the following properties :    1 .",
    "( `` cylindrical '' cells ) for each cell @xmath353 of @xmath346 , there exists a unique cell @xmath354 of the @xmath337-dimensional arrangement @xmath355 in @xmath335 , such that one of the following possibilities occur : 1 .",
    "@xmath356 , where @xmath357 is a continuous semialgebraic function ( that is , @xmath353 is the graph of @xmath358 over @xmath354 ) .",
    "@xmath359 , where each @xmath360 , @xmath361 , is either a continuous semialgebraic real - valued function on @xmath354 , or the constant function @xmath362 , or the constant function @xmath363 , and @xmath364 for all @xmath365 ( that is , @xmath353 is a portion of the `` cylinder '' @xmath366 between two consecutive graphs ) .",
    "2 .   ( refinement property ) if @xmath367 , then @xmath368 , and thus each cell of @xmath346 is fully contained in some cell of @xmath369 .    returning to the problem of decomposing the zero set of the partitioning polynomial @xmath8 into monotone patches ,",
    "we construct the first - stage cad for @xmath286 , and the patches are the cells of @xmath346 contained in @xmath12 .",
    "if the @xmath325-direction is good for @xmath8 , then every cell of @xmath346 lying in @xmath12 is of type  ( a ) , and so if any cell of type  ( b ) lies in @xmath12 , we choose another random direction and construct the first - stage cad in that direction . putting everything together and using theorem  [ t : make - arrg ] to bound the complexity of @xmath346 , we obtain the following lemma .    [",
    "l : patches ] let @xmath8 be a @xmath7-variate polynomial of degree @xmath46 , and let us assume that the @xmath325-direction is good for @xmath8 .",
    "then @xmath12 can be decomposed , in @xmath370 time , into @xmath371 monotone patches , and each patch can be represented semialgebraically by @xmath370 polynomials of degree @xmath372 .",
    "the first - stage cad can also be used to compute the projection of the intersection of a range in @xmath18 with a monotone patch of @xmath8 .",
    "essentially , this is done by forming the arrangement of @xmath8 and the polynomials defining @xmath59 , and by collecting the monotone patches in this arrangement that are contained in @xmath12 ; see the full version  @xcite for more details .",
    "[ l : project ] let @xmath373 be the decomposition of the zero set of a @xmath7-variate polynomial @xmath8 of degree @xmath46 into monotone patches , as described in lemma  [ l : patches ] , and let @xmath59 be a semialgebraic set in @xmath18 , with @xmath374 . for every patch @xmath375 , the projection of @xmath376 in the @xmath325-direction can be represented as a member of @xmath377 , i.e. , by a boolean combination of at most @xmath378 polynomial inequalities in @xmath337 variables , each of degree at most @xmath379 , where @xmath380 and @xmath381 .",
    "the representation can be computed in @xmath382 time .",
    "the task of computing @xmath336 , the projection of @xmath330 , is similar to the operation ( a2 ) discussed in section  [ sec : cross ] . in more abstract terms",
    ", it can also be viewed as a quantifier elimination task : we can represent @xmath383 by a quantifier - free formula @xmath384 ( a boolean combination of polynomial inequalities ) ; then @xmath336 is represented by @xmath385 , and by eliminating @xmath386 we obtain a quantifier - free formula describing @xmath336 .",
    "more concretely , we use a procedure based on the first - stage cad ( lemma  [ l : cad ] ) and the arrangement construction ( theorem  [ t : make - arrg ] ) .    by definition",
    ", @xmath59 is a boolean combination of inequalities of the form @xmath387 , where @xmath279 are @xmath7-variate polynomials , each of degree at most @xmath275 .",
    "we set @xmath388 , we compute the set @xmath389 of @xmath337-variate polynomials as in lemma  [ l : cad ] , and the first - stage cad is then computed as the @xmath7-dimensional arrangement @xmath390 according to theorem  [ t : make - arrg ] .",
    "since by lemma  [ l : cad](ii ) , @xmath390 refines @xmath391 ( the first - stage cad from the preprocessing phase ) , each patch @xmath392 is decomposed into subpatches .",
    "since the sign of each @xmath393 is constant on each cell of @xmath394 , and thus on each cell of @xmath390 , @xmath330 is a disjoint union of subpatches .",
    "the projections of these subpatches into @xmath335 are cells of @xmath395 , and thus we obtain , in time @xmath382 , a representation of @xmath336 as a member of @xmath377 by theorem  [ t : make - arrg ] , where @xmath380 and @xmath396 .",
    "[ sec : range2 ]    we now describe our second data structure for @xmath269-range searching . compared to the first data structure from section  [ sec : range1 ] , this one works on arbitrary point sets , without the @xmath53-general position assumption , or , alternatively , without the fuzzy boundary constraint on the output , and has slightly better performance bounds .",
    "the data structure is built recursively , and this time the recursion involves both @xmath1 and  @xmath7 .",
    "let @xmath0 be a set of @xmath1 points in @xmath2 , and let @xmath20 and @xmath19 be parameters ( not assumed to be constant ) .",
    "the data structure for @xmath18-range searching on @xmath0 is obtained by constructing a partition tree @xmath300 on @xmath0 recursively , as above , except that now the fan - out of each node is larger ( and non - constant ) , and each node also stores an auxiliary data structure for handling the respective exceptional part . we need to set two parameters : @xmath397 and @xmath398 .",
    "neither of them is a constant in general ; in particular , @xmath5 is typically going to be a tiny power of  @xmath1 .",
    "the specific values of these parameters will be specified later , when we analyze the query time .",
    "we also note that there is yet another parameter in theorem  [ t : large - r ] , namely , the arbitrarily small constant @xmath52 entering the preprocessing time bound .",
    "however , @xmath26 enters the construction solely by the requirement that @xmath5 should be chosen smaller than @xmath399 , for a sufficiently large constant  @xmath205 .",
    "it will become apparent later in the analysis that @xmath400 can be assumed , provided that some other parameters are taken sufficiently large ; we will point this out at suitable moments .    when constructing the partition tree @xmath300 on an @xmath1-point set @xmath0 , we distinguish two cases . for @xmath401 ,",
    "@xmath300 consists of a single leaf storing all points of @xmath0 . for @xmath402",
    ", we construct an @xmath5-partitioning polynomial @xmath8 of degree @xmath235 , the partition @xmath261 of @xmath2 induced by @xmath8 , and the partition of @xmath0 into the exceptional part @xmath268 and regular parts @xmath403 , where @xmath259 . set @xmath404 and @xmath405 , for @xmath265 . the root of @xmath300 stores @xmath8 , @xmath261 , and the total weight @xmath305 of each regular part @xmath306 of @xmath0 , as before . still in the same way as before , we recursively preprocess each regular part @xmath306 for @xmath18-range searching ( or stop if @xmath406 ) , and attach the resulting data structure to the root as a respective subtree .",
    "a new feature of the second data structure is that we also preprocess the exceptional set @xmath268 into an auxiliary data structure , which is stored at the root .",
    "here we recurse on the dimension , exploiting the fact that @xmath268 lies on the algebraic variety @xmath12 of dimension at most @xmath407 .",
    "we choose a random direction @xmath324 and rotate the coordinate system so that @xmath324 becomes the direction of the @xmath325-axis .",
    "we construct the first - stage cad adapted to @xmath408 , according to lemma  [ l : cad ] and theorem  [ t : make - arrg ] .",
    "we check whether all the patches are @xmath325-monotone , i.e. , of type ( a ) in lemma",
    "[ l : cad](i ) ; if it is not the case , we discard the cad and repeat the construction , with a different random direction .",
    "this yields a decomposition of @xmath12 into a set @xmath409 of @xmath371 monotone patches , and the running time is @xmath370 with high probability .",
    "next , we distribute the points of @xmath268 among the patches : for each patch @xmath392 , let @xmath329 denote the projection of @xmath410 onto the coordinate hyperplane @xmath411 .",
    "we preprocess each set @xmath329 for @xmath377-range searching . here",
    "@xmath381 is the number of polynomials defining a range and @xmath412 is their maximum degree ; the constants hidden in the @xmath413 notation are the same as in lemma  [",
    "l : project ] . for simplicity",
    ", we treat all patches as being @xmath337-dimensional ( although some may be of lower dimension ) ; this does not influence the worst - case performance analysis .",
    "the preprocessing of the sets @xmath329 is done recursively , using an @xmath414-partitioning polynomial in @xmath342 , for a suitable value of  @xmath414 .",
    "the exceptional set at each node of the resulting `` @xmath337-dimensional '' tree is handled in a similar manner , constructing an auxiliary data structure in @xmath415 dimensions , based on a first - stage cad , and storing it at the corresponding node .",
    "the recursion on @xmath7 bottoms out at dimension @xmath160 , where the structure is simply a standard binary search tree over the resulting set of points on the @xmath416-axis .",
    "we remark that the treatment of the top level of recursion on the dimension will be somewhat different from that of deeper levels , in terms of both the choice of parameters and the analysis ; see below for details .",
    "this completes the description of the data structure , except for the choice of @xmath5 and @xmath307 , which will be provided later as we analyze the performance of the algorithm .",
    "let us assume that , for a given @xmath0 , the data structure for @xmath269-range searching , as described above , has been constructed , and consider a query range @xmath417 .",
    "the query is answered in the same way as before , by visiting the nodes of the partition tree @xmath300 in a top - down manner , except that , at each node that we visit , we also query with @xmath59 the auxiliary data structure constructed on the exceptional set @xmath268 for that node .",
    "specifically , for each patch @xmath149 of the corresponding collection @xmath409 , we compute @xmath418 , the weight of @xmath419 . if @xmath420 then @xmath421 , and if @xmath422 then @xmath418 is the total weight of @xmath327 .",
    "otherwise , i.e. , if @xmath59 crosses @xmath149 , then @xmath418 is the same as the weight of @xmath423 , where @xmath336 is the @xmath325-projection of @xmath330 , because @xmath149 is @xmath325-monotone . by lemma  [",
    "l : project ] , @xmath424 and can be constructed in @xmath382 time .",
    "we can find the weight of @xmath425 by querying the auxiliary data structure for @xmath329 with @xmath336 .",
    "we then add @xmath418 to the global count maintained by the query procedure .",
    "this completes the description of the query procedure .",
    "the analysis of the storage requirement and preprocessing time is straightforward , and will be provided later .",
    "we begin with the more intricate analysis of the query time .",
    "for now we assume that @xmath307 and @xmath5 have been fixed ; the analysis will later specify their values .",
    "a straightforward analysis shows that the size of the data structure is linear and that it can be constructed in time @xmath65 , for any constant @xmath426 , by choosing @xmath5 sufficiently large , so we focus on analyzing the query time .",
    "let @xmath427 denote the maximum overall query time for @xmath269-range searching on a set of @xmath1 points in @xmath2 .",
    "for @xmath428 and @xmath429 , @xmath430 . for @xmath431 and @xmath432 , @xmath433 because any range in @xmath434 is the union of at most @xmath435 intervals .",
    "finally , for @xmath436 and @xmath432 , an analysis similar to the one in section  [ sec : range1 ] gives the following recurrence for @xmath427 : @xmath437 @xmath438 where @xmath293 , @xmath277 is a constant depending on  @xmath7 , @xmath439 , and both @xmath440 and @xmath441 are bounded by @xmath442 with @xmath235 and @xmath443 .",
    "( these are rather crude estimates , but we prefer simplicity . ) the leading term of the recurrence relies on the crossing - number bound given in lemma  [ l : cr ] . in order to apply that lemma , we need that @xmath444 , which will be ensured by the choice of @xmath5 given below .",
    "the second term corresponds to querying the auxiliary data structures for the exceptional set @xmath268 .",
    "the last term covers the time spent in computing the cells of the polynomial partition crossed by the query range @xmath59 and for computing the projections @xmath336 for every @xmath445 ; here we assume that the choice of @xmath5 will be such that @xmath446 .",
    "ultimately , we want to derive that if @xmath298 are constants , the recurrence ( [ eq : qtime ] ) implies , with a suitable choice of @xmath5 and @xmath307 at each stage , @xmath447 where @xmath448 is a constant depending on @xmath449 , and @xmath19 . however , as was already mentioned , even if @xmath298 are constants initially , later in the recursion they are chosen as tiny powers of @xmath1 , and this makes it hard to obtain a direct inductive proof of  ( [ qt : good ] ) .",
    "instead , we proceed in two stages .",
    "first , in lemma  [ l : weakerq ] below we derive , without assuming @xmath298 to be constants , a weaker bound for @xmath427 , for which the induction is easier .",
    "then we obtain the stronger bound ( [ qt : good ] ) for constant values of @xmath298 by using the weaker bound for the @xmath337-dimensional queries on the exceptional parts , i.e. , for the second term in the recurrence  ( [ eq : qtime ] ) .",
    "[ l : weakerq ] for every @xmath450 there exists @xmath451 such that , with a suitable choice of @xmath5 and @xmath307 , @xmath452 for all @xmath453 ( with @xmath454 , say ) .",
    "\\(i ) this lemma may look similar to our first result on @xmath18-range searching , theorem  [ t : const - r ] , but there are two key differences  the lemma works for arbitrary point sets , with no general position assumption , and @xmath20 and @xmath19 are not assumed to be constants .",
    "\\(ii ) since query time @xmath55 is trivial to achieve , we may assume @xmath455 , for otherwise , the bound ( [ qt : bad ] ) in the lemma exceeds @xmath1 .",
    "the case @xmath431 is trivial because @xmath456 clearly implies  ( [ qt : bad ] ) , assuming that @xmath457 and that @xmath1 is sufficiently large so that @xmath458 .",
    "we assume that ( [ qt : bad ] ) holds up to dimension @xmath407 ( for all @xmath450 , @xmath20 , @xmath19 , and @xmath1 ) , and we establish it for dimension @xmath7 by induction on  @xmath1 .",
    "we consider @xmath451 yet unspecified but sufficiently large ; from the proof below one can obtain an explicit lower bound that  @xmath451 should satisfy .",
    "we set @xmath459 this value of @xmath307 is roughly the threshold where the bound ( [ qt : bad ] ) becomes smaller than @xmath1 .",
    "since we assume @xmath460 , our choice of @xmath5 satisfies the assumptions @xmath444 and @xmath446 , as needed in ( [ eq : qtime ] ) .    in the inductive step , for @xmath428 ,",
    "@xmath461 so we assume that @xmath432 and that the bound ( [ qt : bad ] ) holds for all @xmath462 . using the induction hypothesis , i.e. , plugging ( [ qt : bad ] ) into the recurrence ( [ eq : qtime ] ) , we obtain @xmath463 by the choice of @xmath5 , the first term of the right - hand side of ( [ eq : induct ] ) can be bounded by @xmath464 which is half of the bound we are aiming for .",
    "next , we bound the second term .",
    "we use the estimates @xmath465 , @xmath466 , and @xmath467 .",
    "then @xmath468 we choose @xmath469 where @xmath470 ; i.e. , we choose @xmath471 . since @xmath472 and @xmath473 , the fraction in ( [ eq : q - aux ] ) can be bounded by @xmath474 because @xmath454 .    finally , recall that @xmath293 , so our choice of @xmath451 ( again , choosing @xmath475 sufficiently large ) ensures that @xmath476 .",
    "hence , the right hand side in ( [ eq : induct ] ) is bounded by @xmath477 as desired .",
    "this establishes the induction step and thereby completes the proof of the lemma .",
    "now we want to obtain the improved bound ( [ qt : good ] ) , i.e. , @xmath478 , with @xmath479 , assuming that @xmath298 are constants and @xmath480 . to this end , in the top - level ( @xmath7-dimensional ) partition tree , we set @xmath481 , where @xmath482 is a suitable small constant to be specified later",
    ". then we use the result of lemma  [ l : weakerq ] with @xmath483 for processing the @xmath337-dimensional queries on the sets @xmath329 .",
    "thus , in the forthcoming proof , we do induction only on @xmath1 , while @xmath7 is fixed throughout .",
    "we choose @xmath397 sufficiently large ( we will specify this more precisely later on ) , and we assume that @xmath402 and that the desired bound ( [ qt : good ] ) holds for all @xmath462 . in the inductive step we estimate , using the recurrence ( [ eq : qtime ] ) , the induction hypothesis , and the bound in ( [ qt : bad ] ) , @xmath484 the first term simplifies to @xmath485 .",
    "thus , if we choose @xmath67 depending on @xmath486 ( which is a small positive constant still to be determined ) so that @xmath487 , then the first term will be at most half of the target value @xmath488 . thus , it suffices to set @xmath486 so that the remaining two terms are negligible compared to this value .    for the @xmath489 term , any @xmath490 will do .",
    "the second term can be bounded , as in the proof of lemma  [ l : weakerq ] , by @xmath491 thus , with @xmath492 , the term is at most @xmath493 . again",
    ", this establishes the induction step and concludes the proof of the final bound for the query time .",
    "we remark that our choice of @xmath486 requires us to choose @xmath494 making its dependence on @xmath7 super - exponential .",
    "first we derive a weaker bound for @xmath427 without assuming @xmath298 to be constants .",
    "namely , we prove that for every constant @xmath450 there exists a constant @xmath451 such that , with a suitable choice of @xmath5 and @xmath307 , @xmath452 for all @xmath453 ( with @xmath454 , say ) .",
    "we can assume that @xmath495 because otherwise the query time is trivially @xmath55 .",
    "we choose @xmath473 , which ensures that @xmath496 .",
    "next , we derive the stronger bound ( [ qt : good ] ) for constant values of @xmath298 by using this weaker bound for the @xmath337-dimensional queries on the projected exceptional parts , i.e. , for the second term in the recurrence  ( [ eq : qtime ] ) . in this stage , we choose @xmath497 for a sufficiently small constant @xmath498 .",
    "our choice of @xmath486 and @xmath451 implies that @xmath499 .",
    "additional details can be found in the full version  @xcite .",
    "let @xmath500 denote the size of the data structure on @xmath1 points in @xmath2 for @xmath269-range searching , with the settings of @xmath5 and @xmath307 as described above .",
    "for @xmath501 we have @xmath502 . for larger values of @xmath1 ,",
    "the space occupied by the root of the partition tree , not counting the auxiliary data structure for the exceptional part @xmath268 , is bounded by @xmath489 , where @xmath293 .",
    "furthermore , since @xmath500 is at least linear in @xmath1 , the total size of the auxiliary data structure constructed on @xmath268 is @xmath503 , where @xmath404 .",
    "we thus obtain the following recurrence for @xmath500 : @xmath504 for @xmath505 , and @xmath502 for @xmath401 . using @xmath506 , @xmath507 , and @xmath508 , for both types of choices of @xmath5",
    ", the recurrence easily leads to @xmath509 where the constant of proportionality depends on @xmath7 .",
    "it remains to estimate the preprocessing time ; here , finally , the parameter @xmath52 in theorem  [ t : large - r ] comes into play .",
    "let @xmath510 be a constant such that @xmath511 ( at all stages of the algorithm ) .",
    "as was remarked in the preceding analysis of the query time , we can make @xmath510 arbitrarily small , by adjusting various constants ( and , generally speaking and as already remarked above , the smaller @xmath510 , the worse constant @xmath448 we obtain in the query time bound ) .",
    "let @xmath512 denote the maximum preprocessing time of our data structure for @xmath18-range searching on @xmath1 points , with @xmath513 a constant as above . using the operation ( a1 ) of section  [ sec : cross ]",
    ", we spend @xmath292 time to compute @xmath514 and the partition of @xmath0 into the exceptional part and the regular parts , and we spend additional @xmath292 time to compute @xmath409 and @xmath329 for every @xmath515 , where @xmath293 . the total time spent in constructing the secondary data structures for all patches of @xmath409",
    "is bounded by @xmath516 .",
    "hence , we obtain the recurrence @xmath517 for @xmath402 , and @xmath518 for @xmath401 . using the properties @xmath506 and @xmath507",
    ", a straightforward calculation shows that @xmath519 where the constant of proportionality depends on @xmath7 .",
    "hence , by choosing @xmath520 , the preprocessing time is @xmath65 .",
    "this concludes the proof of theorem  [ t : large - r ] .",
    "this concludes the proof of theorem  [ t : large - r ] .",
    "we conclude this paper by mentioning a few open problems .",
    "\\(i ) a very interesting and challenging problem is , in our opinion , the fast - query case of range searching with constant - complexity semialgebraic sets , where the goal is to answer a query in @xmath521 time using roughly @xmath522 space .",
    "there are actually two , apparently distinct , issues .",
    "the standard approach to fast - query searching is to parameterize the ranges in @xmath13 by points in a space of a suitable dimension , say @xmath33 ; then the @xmath1 points of @xmath0 correspond to @xmath1 algebraic surfaces in this @xmath33-dimensional `` parameter space '' , and a query is answered by locating the point corresponding to the query range in the arrangement of these surfaces .",
    "first , the arrangement has @xmath523 combinatorial complexity , and one would expect to be able to locate points in it in polylogarithmic time with storage about @xmath524 .",
    "however , such a method is known only up to dimension @xmath525 , and in higher dimension , one again gets stuck at the arrangement decomposition problem , which was the bottleneck in the previously known solution of @xcite for the low - storage variant , as was mentioned in the introduction .",
    "it would be nice to use polynomial partitions to obtain a better point location data structure for such arrangements , but unfortunately , so far all of our attempts in this direction have failed .",
    "the second issue is , whether the point location approach just sketched is actually optimal .",
    "this question is exhibited nicely already in the simple instance of range searching with disks in the plane .",
    "the best known solution that guarantees logarithmic query time uses point location in @xmath526 and requires storage roughly @xmath527 , but it is conceivable that roughly quadratic storage might suffice .",
    "\\(ii ) our range - searching data structure for arbitrary point sets  the one with large fan - out  is so complex and has a rather high exponent in the polylogarithmic factor , because we have difficulty with handling highly degenerate point sets , where many points lie on low - degree algebraic surfaces .",
    "this issue appears even more strongly in combinatorial applications , and in that setting it has been dealt with only in rather specific cases ( e.g. , in dimension 3 ) ; see @xcite for initial studies .",
    "it would be nice to find a construction of suitable `` multilevel polynomial partitions '' that would cater to such highly degenerate input sets , as touched upon in @xcite .",
    "\\(iii ) another open problem , related to the construction of polynomial partitions , is the fast evaluation of a multivariate polynomial at many points , as briefly discussed at the end of section  [ sec : algo ] .",
    "p.  k. agarwal and j.  erickson , geometric range searching and its relatives , in : _ advances in discrete and computational geometry _ ( b.  chazelle , j.  e.  goodman and r.  pollack , eds . ) , ams press , providence , ri , 1998 , pp .",
    "156 .      p.",
    "k. agarwal , j.  matouek , m. sharir , on range searching with semialgebraic sets ii , in arxiv .",
    "s. barone and s. basu , refined bounds on the number of connected components of sign conditions on a variety , _ discrete comput .",
    "_ 47 ( 2012 ) , 577597 .",
    "s.  basu , r.  pollack , and m .- f .",
    "roy , on the number of cells defined by a family of polynomials on a variety , _ mathematika _ 43 ( 1996 ) , 120126 .",
    "b.  chazelle , h.  edelsbrunner , l.  j. guibas , and m.  sharir , a singly exponential stratification scheme for real semi - algebraic varieties and its applications , _ theoret .",
    "_ , 84 ( 1991 ) , 77105 . also in _ proc",
    "16th int . colloq . on automata ,",
    "languages and programming _ ( 1989 ) , pp .",
    "179193 .",
    "elekes , h. kaplan and m. sharir , on lines , joints , and incidences in three dimensions , _ j. combinat .",
    "theory , ser .",
    "a _ 118 ( 2011 ) , 962977 .",
    "l. guth and n. h. katz , algebraic methods in discrete analogs of the kakeya problem , _ advances math . _",
    "225 ( 2010 ) , 28282839 .",
    "l. guth and n. h. katz , on the erds distinct distances problem in the plane , in arxiv:1011.4105 .",
    "h. kaplan , j. matouek and m. sharir , simple proofs of classical theorems in discrete geometry via the guth ",
    "katz polynomial partitioning technique , _ discrete comput .",
    "geom . _ 48 ( 2012 ) , 499517 .",
    "h. kaplan , j. matouek , z. safernov and m. sharir , unit distances in three dimensions , _ combinat .",
    "_ 21 ( 2012 ) , 597610",
    ". k. kedlaya and ch .",
    "umans , fast modular composition in any characteristic , _ proc .",
    "49th annu .",
    "ieee sympos .",
    "sci . _ ( 2008 ) , 146155 .",
    "knauer , h. r. tiwari and d. werner , on the computational complexity of ham - sandwich cuts , helly sets , and related problems , _ proc .",
    "28th annu .",
    "aspects comput .",
    "( 2011 ) , 649660 .",
    "m. sharir and h. shaul , semi - algebraic range reporting and emptiness searching with applications , _ siam j. comput .",
    "_ 40 ( 2011 ) , 10451074",
    ". j. solymosi and t. tao , an incidence theorem in higher dimensions , _ discrete comput .",
    "_ 48 ( 2012 ) , 255280 .",
    "a. h. stone and j. w. tukey , generalized sandwich theorems , _ duke math",
    ". j. _ 9 ( 1942 ) , 356359 ."
  ],
  "abstract_text": [
    "<S> let @xmath0 be a set of @xmath1 points in @xmath2 . </S>",
    "<S> we present a linear - size data structure for answering range queries on @xmath0 with constant - complexity semialgebraic sets as ranges , in time close to @xmath3 . </S>",
    "<S> it essentially matches the performance of similar structures for simplex range searching , and , for @xmath4 , significantly improves earlier solutions by the first two authors obtained in  1994 . </S>",
    "<S> this almost settles a long - standing open problem in range searching .    </S>",
    "<S> the data structure is based on the polynomial - partitioning technique of guth and katz [ arxiv:1011.4105 ] , which shows that for a parameter @xmath5 , @xmath6 , there exists a @xmath7-variate polynomial @xmath8 of degree @xmath9 such that each connected component of @xmath10 contains at most @xmath11 points of @xmath0 , where @xmath12 is the zero set of @xmath8 . </S>",
    "<S> we present an efficient randomized algorithm for computing such a polynomial partition , which is of independent interest and is likely to have additional applications . </S>"
  ]
}