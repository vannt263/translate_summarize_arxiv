{
  "article_text": [
    "heterogeneous computing systems that consist of cpus and accelerators such as nvidia gpu @xcite or intel xeon phi @xcite are becoming prevalent",
    ". some of the most powerful supercomputers in the top500 list ( november 2015 ,  @xcite ) are heterogeneous at their node level .",
    "for example , a node of tianhe-2 ( no . 1 in top500 )",
    "comprises two intel ivybrigde cpus and three intel xeon phi co - processors ; a node of titan ( no . 2 in top500 )",
    "contains one amd opteron cpu and one nvidia tesla gpu .",
    "utilizing the computational power of all the available resources ( cpus + accelerators ) in heterogeneous systems is essential to achieve good performance .",
    "however , due to different performance characteristics of their processing elements , achieving a good workload distribution across multiple devices on heterogeneous systems is non - trivial @xcite .",
    "furthermore , optimal workload distribution is most likely to change for different applications , input problem sizes and available resources .",
    "determining the optimal system configuration ( including the number of threads , thread affinity , workload partitioning ratio for multi - core processors of the host and the accelerating devices ) using brute - force may be prohibitively time consuming .",
    "various approaches for workload distribution have been proposed .",
    "for example augonnet et al .",
    "@xcite propose a task scheduling library to handle the load balancing and the memory transfer .",
    "scogland et al .",
    "@xcite propose an adaptive worksharing library to schedule computational load across devices .",
    "ravi and agrawal @xcite propose a dynamic scheduling framework that splits tasks into smaller ones and distributes them across processing elements on heterogeneous systems .",
    "grewe and oboyle @xcite propose a static partitioning approach to distribute opencl programs on heterogeneous systems .",
    "however , so far not much research was focused on using meta - heuristics to optimize the workload distribution of data - parallel applications , which considers various parameters such as : the number of threads , the thread affinity , and the workload partitioning ratio for host cpus and co - processing devices .",
    "in this paper we propose an optimization approach that combines the combinatorial optimization and machine learning to determine near - optimal system configuration parameters of a heterogeneous system .",
    "we use simulated annealing as a combinatorial optimization approach to search for the optimal system configuration in the given parameter space , whereas for performance evaluation of the proposed system configurations during space exploration we use the boosted decision tree regression .",
    "the objective function that we aim to minimize is the application s execution time . to evaluate our approach we use a parallel application for dna sequence analysis on a platform that comprises two 12-core intel xeon e5 cpus and an intel xeon phi 7120p co - processor with 61 cores . using our optimization approach to determine the near - optimal system configuration we achieve a speedup of 1.74@xmath0 compared to the case when only the available resources of the host are used , and up to 2.18@xmath0 speedup compared to the case when all the resources of the accelerating device are used .",
    "* contributions : * the major contributions of this paper are :    * a combinatorial optimization approach to explore the large system configuration space ; * a supervised machine learning approach to evaluate the performance of parallel applications ; * an approach that combines the combinatorial optimization heuristic with machine learning to determine a near - optimal system configuration , such that the execution time is decreased ; * experimental evaluation of our approach ; * performance comparison of our approach that utilizes both cpus and accelerators , compared to cpu - only and accelerator - only approaches .    the rest of the paper is organized as follows .",
    "section [ sec : background ] provides background and motivation .",
    "section [ sec : framework ] describes the design and implementation of our optimization approach .",
    "section [ sec : evaluation ] presents our evaluation .",
    "this paper is compared and contrasted to the state - of - the - art related work in section [ sec : rw ] .",
    "we provide conclusions and discuss the future work in section [ sec : conclusion ] .",
    "in this section we will motivate the need for optimized workload distribution across heterogeneous devices . to illustrate and motivate the problem of workload distribution on heterogeneous platforms and to evaluate the proposed approach",
    ", we will measure the execution time of a dna sequence analysis application @xcite in a heterogeneous platform that is accelerated using an intel xeon phi co - processor .",
    "details related to the heterogeneous platform and the application used for experimentation will follow in the next sections .          a typical heterogeneous platform that is accelerated with the intel xeon phi is diagrammed in figure [ fig : emil - platform ] .",
    "such platforms may consist of one or two cpus on the host ( left - hand side of the figure ) , and one to eight accelerators ( right - hand side of the figure ) .",
    "the host cpus are of type intel xeon e5 , which consists of 12 cores , each of them supports two hardware threads that amounts to a total of 48 threads .",
    "the l3 cache is split in two parts , in total it features a 30 mb l3 cache .",
    "the xeon phi accelerator has 61 cores , where each core supports four hardware threads , in total 244 threads per co - processor @xcite .",
    "the xeon phi comes with a lightweight linux operating system ( @xmath1os ) that allows us to either run applications natively or offload them .",
    "one of the cores is used by the os , the remaining 60 cores are used for experimentation .",
    "the xeon phi has a unified l2 cache memory of 30.5 mb .",
    "one of the key features of the intel xeon phi is its vector processing units that are essential to fully utilize the co - processor @xcite . through the 512-bit wide simd registers it can perform 16 ( 16 wide @xmath0 32 bit ) single - precision or 8 ( 8 wide @xmath0 64 bit ) double - precision operations per cycle .",
    "the performance capabilities of the intel xeon phi have been investigated by different researches within different domains @xcite .      for motivation purposes , and later on for evaluation of our approach",
    "we have used a high performance data analytic application for dna sequence analysis @xcite that is based on finite automata and finds patterns ( so called motifs ) in large - scale dna sequences .",
    "it allows efficient use of the computational resources of the host and accelerating device .",
    "the dna sequence analysis application targets heterogeneous systems that are accelerated with the intel xeon phi co - processor , and is able to exploit both the thread- and simd - level parallelism .",
    "we measured the execution time of a dna sequence analysis application @xcite on a simple heterogeneous system that consists of two intel xeon cpus and one intel xeon phi co - processor .",
    "in reality , heterogeneous systems may consist of several different types of accelerators with different performance capabilities .",
    "we run these experiments with different input sizes and number of cpu threads . to highlight the work - distribution problem",
    "we vary the distribution ratio across host and device .",
    "figure [ fig : mot - case - study ] shows the results of our experiments .",
    "the x - axis indicates the work distribution ratio , for instance @xmath2 means that 60% of the work is mapped to the host cpus and the remaining 40% is mapped to the co - processor .",
    "the y - axis indicates the execution time , note that the values are normalized in a range from 1 - 10 . in the first experiment , depicted in fig .",
    "[ fig : mot - turkey-48 ] , we may observe that the lowest execution time is achieved when running on the cpu only . that is due to the relatively small input size used , where any work distribution makes the execution time be biased by the represented overhead . in the second experiment , shown in fig .",
    "[ fig : mot - human-48 ] , we used a larger input size , therefore running on the 48 threads of the cpu or on the co - processor only is not the most effective mapping .",
    "we may observe that a work distribution of @xmath3 or @xmath2 is much faster .",
    "figure [ fig : most - human-4 ] shows the results when using the same input size but the number of cpu threads is reduced to 4 .",
    "we may observe that the optimal work distribution is when we assign 70% of the work to the co - processor .",
    "please note that in these experiments we consider only 11 possible workload partition ratios ( @xmath4 ) . in real - world problems",
    "this ratio can be any number in the interval 0 - 100 .    from the above experiments we may see that the optimal workload distribution depends on the input size and the available resources .",
    "if we consider more features ( example , thread affinity , number of threads per core ) or multiple accelerators with different performance characteristics , the number of all possible system configurations increases dramatically .",
    "determining the optimal system configuration using brute - force may be prohibitively time expensive .",
    "the number of all possible system configurations is a product of parameter value ranges ,    @xmath5    where @xmath6 is a set of parameters and each @xmath7 has a value range @xmath8 .    in the next section we are going to propose an intelligent work distribution approach that is able to determine an optimal system configuration using combinatorial optimization and machine learning .    0.45        0.45     0.45",
    "one of the most compelling features of the intel xeon phi co - processor is the double advantage of transforming - and - tuning , which means that tuning an application on the intel xeon phi for scaling ( more cores and threads ) , vectorization and memory usage , stands to benefit an application when running on the intel xeon processors . therefore ,",
    "with not much programming investment application tailored for many - core intel xeon phi co - processors can benefit when running on multi - core intel xeon cpus , and vice - versa . to distribute the workload across the heterogeneous devices we use the offload programming model .",
    "we overlap the parts offloaded to the co - processor with the ones that are running on the host cpus , which mitigates the idle time for both cpus and accelerators .",
    "we target applications with `` divisible '' workload , which means that the workloads division can be adjusted arbitrarily .",
    "however , as seen in section [ sec : motivation ] , in heterogeneous systems that have processing units of different speed , finding an optimal partitioning ratio for a given workload is non - trivial .    in this section ,",
    "we describe our approach for determining the optimal system configuration parameters ( including number of threads , thread affinities , workload fraction ) of a heterogeneous systems .",
    "the goal of our approach is to propose a near - optimal system configuration such that the overall execution time is minimized .",
    "the system parameters and their possible values are listed in table [ table : sys - parameters ] .",
    ".the set of considered parameters and their values for our target system . [ cols=\"<,<,<\",options=\"header \" , ]",
    "efficient utilization of the combined computation power of the various computing units in heterogeneous systems requires optimal workload distribution .",
    "recent related work proposed various approaches for workload distribution across different devices in heterogeneous systems .",
    "coretsar @xcite is an adaptive worksharing library for workload scheduling across different devices .",
    "it is a directive based library that extends the accelerated openmp by introducing a cross - device worksharing directive .",
    "such directives enable the programmer to specify the association between the computation and data .",
    "the library evaluates the speed of each device statically , then use these indicators to split the workload across different devices .",
    "similarly ayguad et al .",
    "@xcite investigated the extension of openmp to allow workload distribution on future iterations based on the results of first static ones .",
    "these approaches tend to minimize the required source code changes .    in comparison ,",
    "starpu @xcite and ompss @xcite ( task block models ) require manual workload distribution by the developer , which may include significant structural source code changes .",
    "these powerful models for scheduling on heterogeneous systems are queue - based that basically split the workload into smaller tasks and queuing these tasks across the available resources . a similar approach based on priority queues",
    "is proposed by dokulili et al .",
    "@xcite .",
    "a dynamic scheduling framework that divides tasks into smaller ones is proposed by ravi and agrawal @xcite .",
    "these task are distributed across different processing elements in a task - farm way . while making scheduling decisions , architectural trade - offs , computation and",
    "communication patterns are considered .",
    "our approach considers only system runtime configuration and the input size that makes it a more general approach , which can be used with different applications and architecture .",
    "odajima et al .",
    "@xcite combines the pragma - based xcalablemp ( xmp ) @xcite programming language with starpu runtime system to utilize resources on each heterogeneous node for work distribution of the loop executions .",
    "xmp is used for work distribution and synchronization , whereas starpu is used for task scheduling .",
    "qilin @xcite is a programming system that is based on a regression model to predict the execution time of kernels .",
    "similarly to our approach , it uses off - line learning that is thereafter used in compile time to predict the execution time for different input size and system configuration .",
    "grewe and oboyle @xcite focus on workload distribution of opencl programs on heterogeneous systems .",
    "their static based partitioning uses static analysis for code features extraction , which are used to determine the best partitioning across the different devices .",
    "their approach relies on the architectural characteristics of a system .    in comparison to the aforementioned approaches ,",
    "in addition to using machine learning for evaluation of applications performance , we use combinatorial optimization to determine the near - optimal system configuration .",
    "in this paper we have proposed a combinatorial optimization approach that uses machine learning to determine the system configuration ( that is , the number of threads , thread affinity , and the dna sequence fraction for the host and device ) such that the overall execution time is minimized .",
    "we have observed that searching for the best system configuration using enumeration is time consuming , since it required many experiments . using simulated annealing to suggest at each _ iteration _ parameter values for the system configuration after 1000 iterations we determined a system configuration that results with a performance that is close to the performance of the system configuration determined with 19926 experiments of enumeration . by running only about 5% of experiments we were able to find a near - optimal system configuration .",
    "furthermore , we have proposed a machine learning approach that is able to predict the execution time for a system configuration .",
    "we have observed in our experiments that the average percent error of 4.2% ( 5.239% on the host , and 3.132% on the device ) of the performance prediction enables us to satisfactory suggest near to optimal system configurations . using the near optimal system configuration determined by the simulated annealing and machine learning we achieved a maximal speedup of @xmath9 compared to the case when all the cores of the host are used , and up to @xmath10 faster compared to the fastest execution time on the device .",
    "s.  benkner , s.  pllana , j.  traff , p.  tsigas , u.  dolinsky , c.  augonnet , b.  bachmayer , c.  kessler , d.  moloney , and v.  osipov , `` peppher : efficient and productive usage of hybrid computing systems , '' _ micro , ieee _ , vol .",
    "31 , no .  5 , pp . 2841 , 09 2011 .",
    "s.  mittal and j.  s. vetter , `` a survey of cpu - gpu heterogeneous computing techniques , '' _ acm comput .",
    "_ , vol .",
    "47 , no .  4 , pp . 69:169:35 , jul .",
    "[ online ] .",
    "available : http://doi.acm.org/10.1145/2788396    m.  sandrieser , s.  benkner , and s.  pllana , `` using explicit platform descriptions to support programming of heterogeneous many - core systems , '' _ parallel computing _",
    "38 , no . 1 - 2 , pp . 5256 , 01 2012 .",
    "c.  augonnet , s.  thibault , r.  namyst , and p .- a .",
    "wacrenier , `` starpu : a unified platform for task scheduling on heterogeneous multicore architectures , '' _ concurrency and computation : practice and experience _ , vol .",
    "23 , no .  2 ,",
    "pp . 187198 , 2011 .",
    "t.  r. scogland , w .- c .",
    "feng , b.  rountree , and b.  r. de  supinski , `` coretsar : adaptive worksharing for heterogeneous systems , '' in _",
    "supercomputing_.1em plus 0.5em minus 0.4emspringer , 2014 , pp .",
    "172186 .",
    "v.  t. ravi and g.  agrawal , `` a dynamic scheduling framework for emerging heterogeneous systems , '' in _ high performance computing ( hipc ) , 2011 18th international conference on_.1em plus 0.5em minus 0.4em ieee , 2011 , pp .",
    "110 .",
    "s.  memeti and s.  pllana , `` analyzing large - scale dna sequences on multi - core architectures , '' in _ 18th ieee international conference on computational science and engineering ( cse-2015)_.1em plus 0.5em minus 0.4emieee , 2015 .",
    " , `` accelerating dna sequence analysis using intel xeon phi , '' in _ pbio at the 2015 ieee international symposium on parallel and distributed processing with applications ( ispa)_.1em plus 0.5em minus 0.4emieee , 2015 .",
    "x.  tian , h.  saito , s.  preis , e.  n. garcia , s.  kozhukhov , m.  masten , a.  g. cherkasov , and n.  panchenko , `` practical simd vectorization techniques for intel xeon phi coprocessors , '' in _",
    "ipdps workshops_.1em plus 0.5em minus 0.4emieee , 2013 , pp .",
    "11491158 .",
    "a.  viebke and s.  pllana , `` the potential of the intel ( r ) xeon phi for supervised deep learning , '' in _ 2015 ieee 17th international conference on high performance computing and communications ( hpcc)_.1em plus 0.5em minus 0.4emieee , 2015 , pp .",
    "758765 .",
    "j.  dokulil , e.  bajrovic , s.  benkner , s.  pllana , m.  sandrieser , and b.  bachmayer , `` high - level support for hybrid parallel execution of c++ applications targeting intel xeon phi coprocessors . '' in _ iccs _ , ser .",
    "procedia computer science , vol .",
    "18.1em plus 0.5em minus 0.4emelsevier , 2013 , pp . 25082511 .",
    "l.  eeckhout and k.  d. bosschere , `` hybrid analytical - statistical modeling for efficiently exploring architecture and workload design spaces , '' in _ proceedings of the international conference on parallel architectures and compilation techniques _",
    ", 2001 , pp . 2534 .",
    "s.  pllana , s.  benkner , e.  mehofer , l.  natvig , and f.  xhafa , `` towards an intelligent environment for programming multi - core computing systems . '' in _ euro - par workshops _ ,",
    "lecture notes in computer science , vol .",
    "5415.1em plus 0.5em minus 0.4emspringer , 2008 , pp .",
    "141151 .",
    "s.  pllana , i.  brandic , and s.  benkner , `` a survey of the state of the art in performance modeling and prediction of parallel and distributed computing systems , '' _ international journal of computational intelligence research ( ijcir ) _ , vol .  4 , no .  1 , pp .",
    "1726 , 01 2008 .",
    "t.  fahringer , s.  pllana , and j.  testori , `` teuta : tool support for performance modeling of distributed and parallel applications , '' in _ computational science - iccs 2004 _ , ser .",
    "lecture notes in computer science.1em plus 0.5em minus 0.4emspringer berlin heidelberg , 2004 , vol .",
    "3038 , pp .",
    "456463 .",
    "f.  khan , y.  han , s.  pllana , and p.  brezany , `` an ant - colony - optimization based approach for determination of parameter significance of scientific workflows , '' in _ advanced information networking and applications ( aina ) , 2010 24th ieee international conference on _ , april 2010 , pp .",
    "12411248 .",
    "t.  d. braun , h.  j. siegel , n.  beck , l.  l. blni , m.  maheswaran , a.  i. reuther , j.  p. robertson , m.  d. theys , b.  yao , d.  hensgen _ et  al .",
    "_ , `` a comparison of eleven static heuristics for mapping a class of independent tasks onto heterogeneous distributed computing systems , '' _ journal of parallel and distributed computing _ , vol .",
    "61 , no .  6 , pp .",
    "810837 , 2001 .",
    "s.  memeti and s.  pllana , `` parem : a novel approach for parallel regular expression matching , '' in _ 17th international conference on computational science and engineering ( cse-2014 ) _ , dec 2014 , pp . 690697 .",
    "e.  ayguad , b.  blainey , a.  duran , j.  labarta , f.  martnez , x.  martorell , and r.  silvera , `` is the schedule clause really necessary in openmp ? '' in _ openmp shared memory parallel programming_.1em plus 0.5em minus 0.4emspringer , 2003 , pp .",
    "147159 .",
    "a.  duran , e.  ayguad , r.  m. badia , j.  labarta , l.  martinell , x.  martorell , and j.  planas , `` ompss : a proposal for programming heterogeneous multi - core architectures , '' _ parallel processing letters _ ,",
    "21 , no .  02 ,",
    "pp . 173193 , 2011 .",
    "t.  odajima , t.  boku , t.  hanawa , j.  lee , and m.  sato , `` gpu / cpu work sharing with parallel language xcalablemp - dev for parallelized accelerated computing , '' in _ parallel processing workshops ( icppw ) , 2012 41st international conference on_.1em plus 0.5em minus 0.4emieee , 2012 , pp .",
    "97106 .",
    "m.  nakao , j.  lee , t.  boku , and m.  sato , `` xcalablemp implementation and performance of nas parallel benchmarks , '' in _ proceedings of the fourth conference on partitioned global address space programming model_.1em plus 0.5em minus 0.4emacm , 2010 , p.  11 .",
    "luk , s.  hong , and h.  kim , `` qilin : exploiting parallelism on heterogeneous multiprocessors with adaptive mapping , '' in _ microarchitecture , 2009 .",
    "42nd annual ieee / acm international symposium on_.1em plus 0.5em minus 0.4emieee , 2009 , pp ."
  ],
  "abstract_text": [
    "<S> we describe an approach that uses combinatorial optimization and machine learning to share the work between the host and device of heterogeneous computing systems such that the overall application execution time is minimized . </S>",
    "<S> we propose to use combinatorial optimization to search for the optimal system configuration in the given parameter space ( such as , the number of threads , thread affinity , work distribution for the host and device ) . for each system configuration that is suggested by combinatorial optimization , we use machine learning for evaluation of the system performance . </S>",
    "<S> we evaluate our approach experimentally using a heterogeneous platform that comprises two 12-core intel xeon e5 cpus and an intel xeon phi 7120p co - processor with 61 cores . using our approach we are able to find a near - optimal system configuration by performing only about 5% of all possible experiments . </S>"
  ]
}