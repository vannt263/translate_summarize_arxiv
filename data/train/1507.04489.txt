{
  "article_text": [
    "the last decades have seen immense growth of the web , which now has an approximate size of over a billion http://www.internetlivestats.com/[web pages ] .",
    "the web provides people around the world with access to a host of information resources and serves uncountable use cases , such as gathering information , studying , making financial transactions , shopping , or booking hotels . to find relevant information in this huge information system , web users apply various information retrieval techniques .",
    "a very common  and probably the most basic and straight - forward  strategy consists of simply navigating between web pages by traversing the provided hyperlinks from one web page to another . in many cases",
    ", users also jump directly to other web pages by typing the _ url _ of the new target page in the browser address bar or by using a search engine and following one of the search results .",
    "these cases are typically referred to as _ teleportation _",
    "@xcite , as users `` teleport '' from the current web page to another one .",
    "the importance of web navigation is even further amplified by an alternative informational retrieval strategy  web search .",
    "ranking algorithms used by search engines are based on variants of pagerank  @xcite , which assigns weights based on hyperlinks .",
    "these ranking approaches assume a so - called random surfer  @xcite  a model of a user who traverses the web by following hyperlinks uniformly at random with a small chance of teleporting at each navigation step . in their original paper , page and brin",
    "@xcite suggested a damping factor of @xmath0 , meaning that , for each step , users traverse hyperlinks with a probability of @xmath1 , while exhibiting a probability of @xmath2 of teleporting to a page selected uniformly at random .",
    "the number of visits of an indefinitely navigating random surfer to each particular page is then a direct measure of page importance for web navigation and is used to rank search results",
    ".    * problem . *",
    "although the random surfer model has proven to be extremely useful in practice , only a few studies have analyzed the capabilities of this model to imitate real user behavior in different contexts . moreover , most of these studies concentrated on empirically analyzing the damping or teleportation factor ( such as  @xcite ) . in this work",
    ", we compare _ clickstream data of real users _ with the _ random surfer model_. in particular , we are interested in analyzing how real users assess the importance of web pages for navigation and how that assessment compares to that of the random surfer",
    ". moreover , we also study to what extent the navigation of human users is influenced by the modern search engines . to this end , we analyze page view counts , which also account for landing pages from search engines .    in particular we are interested in answering the following research questions :    * rq1 comparison of a random surfer with real users . *",
    ": :    to what extent does a random surfer with teleportation imitate user    navigation behavior ?",
    "* rq2 influence of search engines . * : :    how do search engines affect how users access and navigate websites ?    * approach & methods . * for our analysis , we first calculate the stationary distributions of a _ uniform _ random surfer , traversing the information network uniformly at random with a teleportation probability of @xmath2 .",
    "we then compare this stationary distribution with the stationary distribution of a _ pragmatic _ random surfer , who selects the links with a probability that is proportional to the transition counts from empirical data ( human users ) . for the pragmatic random surfer we again use @xmath2 teleportation probability .",
    "finally , we compare stationary distributions of both uniform and pragmatic random surfer with the stationary distribution ( normalized page view count distribution ) of a _ lateral _",
    "random surfer , which accounts for the lateral access from a search engine to a given website .    for the distribution comparison",
    "we calculate linear correlation factors and gini coefficients to investigate the alignment of distributions , and the distributions inequality , respectively .",
    "* contributions . *",
    "our high - level contribution is a better understanding of human navigation behavior and how it compares to a navigational model such as the random surfer model .",
    "methodologically , we compute and analyze stationary distributions using a set of standard measures with a clear interpretation in the context of web navigation .    empirically , we provide evidence that , despite its simplicity , a random surfer model is a very accurate model of basic human navigation behavior in our dataset .",
    "our results suggest that the general navigation behavior of users is very much in line with the random surfer model  both assess the navigational page importance in a similar and highly skewed way , meaning that just a few pages are extremely important .",
    "these results also hold for cases where website operators decide to provide specific navigational structures ( as in our dataset ) such as navigational hierarchies .",
    "users , as well as the random surfer , do not make any particular distinction between different types of links present on the website .",
    "however , the lateral access from search engines reduces the imbalances , at least for human users , and need therefore to be taken into account when modeling user navigational behavior .",
    "our work relies heavily on the random surfer model , which is a simple but well - studied model for modelling navigation on the web @xcite .",
    "apart from navigation , the random surfer model has also been applied to a variety of different problems such as graph generation and graph analysis . in particular , blume et al .",
    "@xcite used the model for the creation of web - graphs while @xcite have applied the model to detect community structures in networks .",
    "algorithms such as pagerank  @xcite or hits @xcite , use the random surfer as the basis for calculating node centralities in networks .",
    "pagerank includes a parameter to define the probability of teleportation for the random surfer .",
    "this parameter is often referred to as the _ damping - factor _",
    "@xmath3 , representing the probability that the random surfer traverses one of the links pointing away from the current node .",
    "with probability @xmath4 it jumps to a network node chosen uniformly at randomly and continues surfing from there . in 2010",
    ", researchers have empirically measured this factor by analyzing clicktrails of humans and reported an estimated damping factor between @xmath5 and @xmath6 for the entire web @xcite . in contrast , the damping factor for wikipedia has been determined to be between @xmath7 and @xmath8 . this difference in damping factors",
    "might be caused by the way users access wikipedia  they use search engines that point them directly to the article of interest , rendering additional navigational efforts unnecessary .",
    "researchers additionally investigated the connection between the damping factor and the convergence rate of the pagerank algorithm and found that it converges very fast for a value of @xmath0  @xcite .",
    "however , in this paper we investigate the influence of the damping factor onto the stationary distribution of the random surfers .",
    "@xcite presented a framework that was able to personalize pagerank on a very small set of user - based clickdata for websites .",
    "additionally , al - saffar and heileman @xcite compared these personalized and topic - sensitive pagerank results with results from the unbiased ( original ) pagerank and came to the conclusion , that both ways of personalizing the pagerank produce a considerable level of overlap in the top results . in particular , the authors conclude that biases , which do not rely on the underlying link structure of the network under investigation , are needed to further improve the personalization of pagerank . in this paper",
    "we are interested in the stationary distribution of pagerank personalized by observed user transitions .",
    "researchers also looked closely into modeling human navigation behavior , using this biased random surfer model .",
    "for example , west and leskovec @xcite investigated human click trails of a navigation game played by humans on wikipedia .",
    "participants were asked to navigate from a given start article in wikipedia to a specific target article , using as few clicks as possible . using the results of this study , west and leskovec @xcite designed different features for steering a probabilistic random surfer .",
    "they also compared paths produced by the biased random surfer with those of humans and found that navigation of humans was based mostly on popularity and similarity biases . in 2013 ,",
    "helic et al .",
    "@xcite compared click - trail characteristics of stochastically biased random surfers with those of humans .",
    "they concluded that biased random surfers can serve as valid models of human navigation .",
    "furthermore , singer et al .",
    "@xcite conducted experiments to find out whether human navigation is markovian , meaning that the next click of a user is only dependent on the most recent click .",
    "they showed that on a page level , human navigation can be best explained by first - order markov chains .",
    "this finding is particularly relevant for us , as it allows us to use simple biases which do not consider previously visited nodes of the random surfer for our experiments .",
    "* austria - forum . * in this paper we use change and click data from austria - forum , an austrian web encyclopedia which was initially created more than two decades ago and restructured in 2009 .",
    "austria - forum tries do distinguish itself from other well established web encyclopedias by providing mechanisms to counteract some specific drawbacks : for instance , austria - forum tries to fight against the apparent ( personal ) biases of anonymous contributions by having ( and enforcing ) approved and named authors as the only contributors to the knowledge base .",
    "authors are mostly academics well - established in their field , which has the positive aspect of thoroughness since they exhibit a personal interest not to produce literature of low quality .",
    "as the name suggests , the information published is geographically limited to all things concerning the country of austria .",
    "compared to other resources on the web , austria - forum tries to transmit the knowledge on a more granular level . not only",
    "does it provide users with several differently scoped articles , but also with entire digitized books as web books on a variety of different cultural and historical aspects of austria . in order to increase the amount of displayed content , austria - forum added the capability of including entire pages from different external domains into their wiki ( e.g. , of the german wikipedia ) .",
    "most of the interactions of a user with an encyclopedia are limited to single page views , usually generated by direct requests via a search engine . for other users , who are interested in browsing the website and learning more about austria",
    ", austria - forum has divided its content into several different categories , such as culture , people , scenery , nature and more , with the ultimate goal of keeping users engaged and increasing their session lengths as well as clicks on the website .",
    "the link structure of austria - forum mostly forms a huge hierarchy .",
    "arriving at the main page users can choose one of @xmath9 main categories and start navigating the hierarchy downwards to a specific topic ( e.g. , _",
    "main page / nature / fossils / amber _ ) .",
    "overall , nearly @xmath10 percent of all links within austria - forum can be categorized as hierarchical links .    * log data .",
    "* for our analysis we use data that was gathered by logging _",
    "http - requests _ on http://www.austria-forum.org , as well as other domains  such as the outdated http://www.austria-lexikon.atwhich link to it . the observation period of our logs consisted of @xmath11 days in april , may , and june of @xmath12 .",
    "table [ tab : dataset : httprequest ] lists the parts of the _ http - requests _ , which were logged and provides a typical example _ http - request _ of a successful access request to austria - forum .",
    "as we are mainly interested in user navigational behavior , we have extensively filtered the logs .",
    "first , we filtered the _ content - type _ to only include human - readable _ html _ pages , eliminating _",
    "xml _ , _ templates _ and _ attachments_. second , _ referrers _ and _ targets _ indicating admin or irregular user behavior , were removed .",
    "the removed logs included previewing an edit for a page , pressing the upload button to attach files to articles , or _",
    "rss - feed - requests_. third , we have only kept _",
    "requests _ which successfully transmitted a page to the user , indicated by the _ response code_. therefore , we have removed all _ requests _ with _ response codes _ other than @xmath13 ( ok ) .    in order to be able to identify pages with multiple _ urls",
    "_ , _ requests _ were normalized by removing the `` _ _ www .",
    "_ _ '' prefix as well as trailing slashes `` _ _ / _ _ '' when applicable .",
    "we stripped the data of all entries created by well known _",
    "user - agents _ of crawlers , such as googlebot , or whenever the _ user - agent _ contained a specific substring , such as _ crawl _ , _ slurp _ , _ spider _ or _ bot _ , which suggested bot activities .",
    "furthermore , to identify bots which do not want to be recognized as such , we removed all entries which had the same _ target _ as _ referrer _ , which is abnormal behavior as standard page - refreshes usually retains the last _ referrer_. as many bots leave the _ referrer _ in their _ requests _ empty , all sessions with @xmath14 clicks and more ( @xmath15 ) that had more than half of its _ referrers _ missing were removed . using this procedure , we removed a little over half ( @xmath16 ) of those sessions .",
    "the specific method that was used on the server to generate _ session - ids _ is unknown to us . as we assume that the _ remote - ip _ as well as cookies are likely considered for generating sessions , it is no simple task to combine , split , recreate and aggregate _ http - requests _ into navigational sessions .",
    "the number of _ session - ids _ exceeds the number of _ remote - ips _ by a large margin , which we presume is due to static _ ips _ of some users such as schools using the same _ ip _ for all students , and users with browser add - ons to increase anonymity ( so that no _ session - id _ can be mapped to that specific user ) . to make sure that sessions by the same user in different periods could be recognized as such",
    ", we introduced a time delta which  if exceeded between two requests  indicates the start of a new session .",
    "hence , a smaller delta increases the number of sessions ( figure [ fig : dataset : numsessions ] ) .",
    "decreasing delta too far would split sessions at pages where users spent a lot of time , even tough in reality the users were still active in their sessions .",
    "meiss et al .",
    "@xcite showed that separating _ http - requests _ ( which they gathered on the entire web ) into sessions , can not be done in a clean way solely based on timeouts .",
    "hence , they introduced the concept of logical sessions .",
    "in particular , users can have multiple logical session at the same time .",
    "for example : browsing domains consisting of mostly images in one tab while navigating on encyclopedias in others . depending on the domain , average time spent per page varies greatly , as images can be consumed much faster than textual content . in their research",
    "they identified a timeout of @xmath17 minutes as a good approximation of a logical user session .",
    "since users tend to browse austria - forum for research , information , self - improvement , or just to educate themselves further , their sessions can be seen as logical as long as the time between two requests is not exceedingly long .",
    "it can be assumed that the time users spend on a page in an encyclopedia can be substantially longer than on an average webpage , due to long ( and possibly ) complex articles .",
    "taking these factors into consideration , we found that setting our delta to @xmath18 minutes still split several sessions while granting our users enough time for longer page visits .",
    "with delta set to @xmath18 minutes , the average session was @xmath19 clicks long ( figure [ fig : dataset : avgsession ] ) .",
    "the distribution of sessions can be seen in figure [ fig : dataset : sessiondistr ] .",
    "it is apparent that the distribution is highly skewed and heterogeneous , indicating many short sessions of few clicks ( portrayed by many sessions which are situated low on the @xmath20-axis ) and a few very long sessions ( represented by a few sessions in the upper left corner ) .",
    "the short sessions are mostly users who were referred to austria - forum by a search engine and either instantly found the information they needed or ceased looking for the needed information on austria - forum .",
    "* crawling the link - structure . * to compare the navigation behavior of website visitors to the random surfer",
    ", we have crawled the whole link structure of austria - forum . to this end , we have developed a simple web crawler that we pointed towards the main page of the website , and which then recursively crawled and followed all encountered ( internal ) links by pursuing a breadth - first strategy .",
    "some of the encountered links were removed , such as all requests to display the raw wiki sources for each page that are easily identified by the _ skin = raw _ parameter in the _",
    "urls_. further , links to binary files , such as _ .mp3 _ , _ .mp4 _ , _ .jpg _ , and many more , have been removed as well , as we are only interested in the navigation behavior of users while browsing and exploring the underlying website .    * limitations .",
    "* we were not able to include the clicks of users within the web books of austria - forum in our study .",
    "further , to simplify the data preprocessing , we cut off active sessions at midnight",
    ".      * preliminaries . *",
    "mathematically , a random surfer is represented by a random walk on a weighted directed graph . thus , we start by introducing some basic notion for such random walks .",
    "let @xmath21 be the weighted adjacency matrix of a directed and weighted graph @xmath22 with @xmath23 if node @xmath24 points to node @xmath25 and @xmath26 otherwise .",
    "the value of @xmath27 represents the weight of the link from @xmath24 to @xmath25 .",
    "the weighted out - degree @xmath28 of a node @xmath25 is defined as the sum over the weights of outgoing links : @xmath29    let @xmath30 be a diagonal matrix of weighted out - degrees , so that @xmath31 if @xmath32 , otherwise we set @xmath33 .",
    "the matrix @xmath34 , defined as @xmath35 is than a transition matrix of a random walk on the weighted directed graph @xmath22 .",
    "an element @xmath36 of the matrix defines the probability of a random surfer moving from node @xmath24 to node @xmath25 .",
    "a stationary distribution of a random walk is defined as a probability of finding a random walker at a particular page in the limit of infinitely many steps .",
    "algebraically , the stationary distribution is equal to the right eigenvector corresponding to the largest eigenvalue of the transition matrix @xmath34 . if the graph @xmath22 is strongly connected and the transition matrix does not allow only periodic returns to a given state , then the largest eigenvalue of the matrix @xmath34 is @xmath37 , and the stationary distribution is unique . in the case of a graph @xmath22 that is not strongly connected , teleportation represents a simple technical solution as it connects each page to every other page with small weight .",
    "teleportation also guarantees that there are not exclusively periodic returns to any given state in the network since there is a constant small probability to remain at the current page after teleporting the surfer to exactly that page .",
    "thus , we therefore include teleportation in our calculations and calculate pagerank vectors of pages from @xmath22 .",
    "the calculation of the pagerank vector of the weighted adjacency matrix simplifies to ( details are given in e.g. , @xcite ) :    @xmath38    where @xmath39 $ ] is the damping factor .    * uniform random surfer . * for the uniform random surfer we use the graph @xmath22 , that we crawled from austria - forum .",
    "we do not set weights to hyperlinks for the uniform random surfer , thus we set @xmath40 if node @xmath24 points to node @xmath25 and @xmath26 otherwise .",
    "* pragmatic random surfer .",
    "* to create a weighted adjacency matrix containing information of user transitions we first filter out teleportations , meaning transitions which are not present in the adjacency matrix of the network .",
    "afterwards we account for user transitions that we observed in the network adjacency matrix . for that purpose",
    ", we apply sublinear scaling to the transition counts , which is a common scaling technique in the field of information retrieval  a word which occurs , for example , @xmath41 times in an document is not assumed to be @xmath41 times more significant than a word occurring only once .",
    "for navigation we can make an analogous assumption , meaning that @xmath41 observed transitions from page a to page b does not make this transition @xmath41 times more significant than a single transition from , for example , page a to page c. in many cases there are several links between any two pages and some of these links are prominently presented in the user interface ( e.g. , in the navigation bar ) inducing bias to the link selection process by users .    therefore , sublinear scaling seems to be an appropriate approach to account for such situations .",
    "we scale the transition counts in the following way .",
    "let @xmath42 be the number of transitions between pages @xmath24 and @xmath25 .",
    "we then calculate scaled transition count @xmath43 as :    @xmath44    after scaling down the transition counts we calculate the weighted adjacency matrix for the pragmatic random surfer in the following way .",
    "let @xmath45 be a matrix containing scaled transition counts , with @xmath46 being the scaled number of transitions between pages @xmath24 and @xmath25 .",
    "further , we define a vector @xmath47 which is a binary vector with @xmath48 if the page @xmath25 has been visited at least once by any of the users .",
    "otherwise we set @xmath49 . finally , let @xmath50 be a diagonal matrix with vector @xmath51 on the diagonal",
    ". then the adjacency matrix of a directed network weighted with the scaled user transition counts can be calculated as follows :    @xmath52    where @xmath53 is the adjacency matrix of the unweighted graph as used for the uniform random surfer . after removing all rows and columns consisting of only zeros",
    "this results in the adjacency matrix of the induced sub graph , which only includes nodes visited at least once by any user and all edges between those nodes ( independent if traversed by any user or not ) .",
    "now , the stationary distribution @xmath54 may be calculated as given by equation  [ eq : stat ] .",
    "* lateral random surfer .",
    "* we represent the lateral random surfer only through its stationary distribution .",
    "the stationary distribution of the lateral random surfer we calculate by simply normalizing page views we directly obtained from the server access logs .",
    "specifically , we do not have a random surfer in this case , but observe the resulting stationary distribution of an underlying random navigation process .",
    "the gini coefficient is a metric for measuring inequality of a distribution .",
    "it computes the area between the lorenz curve  @xcite and the uniform distribution .",
    "higher values indicate a larger difference and higher inequality . for our analyses ,",
    "we calculate the gini coefficient for the stationary distributions of all three random surfer types .",
    "in our experiments we are interested in comparing and analyzing the differences and commonalities between the uniform random surfer model , the pragmatic random surfer model and the lateral random surfer model ( cf .",
    "section  [ sec : random_surfer ] ) .",
    "we use the power iteration method  @xcite to calculated the pagerank vector . in the first experiments we set @xmath3 to a fixed value of @xmath0 .",
    "this correspond to teleportation probability of @xmath2 , analogously to the original pagerank algorithm  @xcite .",
    "hence , the damping factor corresponds to the probability of a user to keep navigating over adjacent pages at each step . in later experiments we analyze the influence of various values for @xmath3 .",
    "figure  [ fig : heat ] depicts the different correlations between the stationary distributions of all three random surfer models .",
    "in particular , the pearson correlation coefficient between the uniform and pragmatic random surfer of @xmath55@xmath56indicates nearly perfect positive correlation .",
    "thus , this correlation analysis shows that there is a considerable overlap between the behaviors of the uniform and pragmatic random surfer models . in conclusion",
    ", the uniform random surfer model appears to be a very good approximation of the pragmatic random surfer  which in our case represents a proxy for user behavior  on austria - forum .    on the other hand ,",
    "the uniform ( @xmath55@xmath57 ) and pragmatic ( @xmath55@xmath58 ) random surfer models exhibit only weak levels of correlation to the lateral random surfer .",
    "further , the heat maps depicted in figure  [ fig : heat ] strengthen our findings , as the lateral random surfer , representing users entering the website from for instance search engines , exhibits higher probabilities to visit pages which are rated as unimportant by the uniform or the pragmatic random surfer .",
    "in other words , they are pointed directly to specific pages without the need to navigate the hierarchy of the website .",
    "thus , search engines appear to reduce the need for users to navigate ( hierarchical ) website structures and therefore are an important factor to include in ( future ) analyses of user navigation behavior .    in further experiments we varied @xmath3 ( damping factor of pagerank ) and found that with lower values of @xmath3 ( e.g , @xmath59 ) the correlation between uniform and lateral random surfer increases from @xmath55@xmath57to @xmath60 , which suggests that higher teleportation probabilities better capture the lateral user access from search engines .",
    "however , at the same time the correlation between the pragmatic and the lateral random surfer decreases from @xmath55@xmath58to @xmath61 for @xmath59 while the correlation between the uniform and the pragmatic remains stable and above @xmath62 .",
    "this result suggests that the lateral access to a website can not be solely captured by a random surfer with teleportation .",
    "rather we need to extend this basic model .",
    "for example , we could use the basic model to also model navigational sessions . in this model teleportation probability increases with every new click to account for an increased likelihood of switching to a new session as the user makes progress in the current session .",
    "furthermore , we calculated and compared the ratios of stationary probabilities for each page and between all combination of three random surfer models to investigate commonalities and differences between them ( see figure  [ fig : biasfac ] ) .",
    "although the uniform and pragmatic random surfer models exhibit a pearson correlation coefficient of almost @xmath63 , there are a few pages with a ratio of @xmath64 or @xmath65 .",
    "this means that those pages are @xmath64 times more ( less ) important for the pragmatic random surfer than for the uniform random surfer .",
    "figure  [ fig : biasfac : unif_prag ] depicts a specific trend showing that pages with a low value in the stationary distribution of the uniform random surfer often obtain much higher values with the pragmatic random surfer .",
    "this difference is compensated by somewhat smaller importance for the pragmatic random surfer of the mid and high important pages for the uniform random surfer .    when comparing the ratios of the uniform and lateral random surfer models , we can see even stronger tendencies than in our previous analysis .",
    "the general shape of the differences remains the same , meaning less important pages for the uniform random surfer become more important for the lateral one , but the magnitude of the differences is larger now and goes in some cases up to @xmath66 .",
    "similar observation can be made for the most important pages for the uniform random surfer , which now become less important also in some cases by a factor of @xmath66 ( see figure  [ fig : biasfac : unif_lat ] ) .",
    "finally , figure  [ fig : biasfac : prag_lat ] depicts the ratios of the pragmatic random surfer compared to the lateral random surfer .",
    "again , we make a very similar observation as in the case of differences between the uniform and the lateral random surfer .",
    "the lorenz curves of the stationary distribution of all three random surfers are shown in figure  [ fig : gini ] .",
    "the uniform random surfer achieves a gini coefficient of  @xmath67 . with a value of  @xmath68 ,",
    "the pragmatic random resulted in a lower coefficient .",
    "this means that the inequality in the stationary distribution of the pragmatic random surfer is lower than that of the uniform random surfer . in other words ,",
    "the imbalances in the individual page importance are reduced as low importance page become more important , and vice versa highly important pages are less important for the pragmatic random surfer . finally , the lateral random surfer exhibits the comparatively lowest gini coefficient of @xmath69 . due to the bias towards more specific pages located in lower levels of the website hierarchy in the lateral random surfer ,",
    "this type of the random surfer is less likely to be directed towards highly popular pages as compared to the uniform random surfer .    for the uniform random surfer , followed by the pragmatic random surfer with @xmath68 .",
    "the lateral random surfer achieved the lowest gini coefficient ( @xmath69 ) .",
    "thus , search engines ( or other in - going links from external pages ) likely point users to very specific pages of the austria - forum , tackling the problem of directing users to high importance pages , helping to mitigate the influence of popular websites on navigation behavior . ]",
    "in this paper we presented new insights into the commonalities and differences between a uniform random surfer , a user clickstream biased ( pragmatic ) random surfer and a page visits biased ( lateral ) random surfer .",
    "we compared the navigation behavior of these three different random surfer models in an online encyclopedia , namely austria - forum . using empirical user data we showed that the random surfer represents a good approximation of navigational user behavior for the investigated website  allowing researches to conduct user navigation experiments using a simple random surfer without the need to collect user clickstreams . due to the low correlation between uniform and lateral random surfer",
    "we conclude , that the hierarchical structure of a website does not play such an important in role in terms of user navigation as it did before the rise of search engines .",
    "the majority of users enter the website using a search engine and leave after consuming the landing page .",
    "hence , the uniform random surfer model is a good approximation of user navigation as long as no search engines are involved .",
    "however , hierarchical structures are needed for most search engines to rank the results of search queries .",
    "nevertheless , the observed behavior leads to the question if website administrators should additionally provide page recommendations to keep users navigating their page .",
    "further experiments with varying teleportation probabilities ( i.e. , lower @xmath3 ) for the random surfer show that we can increase the correlation of stationary distributions between the uniform and lateral random surfer , but at the same time decrease the correlation between the pragmatic and the lateral random surfer .",
    "these differences in modeling navigational user behavior with and without search engines represent the directions for future work for modeling and hence optimizing navigational potential of a website .",
    "our results represent important insights for website administrators , search engine providers and researchers who want to broaden their understanding of user navigation and the models thereof .",
    "the contributions of this paper may serve as an interesting input to modify the models and for example link recommendation algorithms to influence navigational behavior of users . with this work we contribute to the analysis of user navigational behavior by ( i ) providing a comparison of random surfer model data with clickstream data , ( ii ) a thorough analysis of the differences between these random surfer models on a web encyclopedia and ( iii ) presenting a methodology that allows us to estimate the optimization potential of a website in terms of keeping users navigating on the website as long as possible",
    ".    * future work . * in future",
    ", we plan to verify our results on other websites where user clickstreams are available ( e.g. , the english wikipedia ) .",
    "furthermore , we want to use our model to test different types of biases introduced into the front end ( e.g. , recommendations of other pages ) of a website to analyze to which extent such biases are able to influence users in their navigation .",
    "another idea is to modify the order of recommendations in a recommendation network and analyze  based on the assumption that recommendations on the top are clicked more often  @xcite  the influence thereof .",
    "this research was in part funded by the fwf austrian science fund research project `` navigability of decentralized information networks '' ( p 24866 ) .",
    "we thank gerhard wurzinger for providing access to austria - forum server logs .",
    "s.  al - saffar and g.  heileman .",
    "experimental bounds on the usefulness of personalized and topic - sensitive pagerank . in _ web intelligence ,",
    "ieee / wic / acm international conference on _ , pages 671675 , nov 2007 .",
    "s.  brin and l.  page .",
    "the anatomy of a large - scale hypertextual web search engine . in _ proceedings of the seventh international conference on world wide web 7 _ , www7 , pages 107117 , amsterdam , the netherlands , the netherlands , 1998 .",
    "elsevier science publishers b. v.          d.  helic , m.  strohmaier , m.  granitzer , and r.  scherer .",
    "models of human navigation in information networks based on decentralized search . in _ proceedings of the 24th acm conference on hypertext and social media",
    "_ , ht 13 , pages 8998 , new york , ny , usa , 2013 .",
    "s.  d. kamvar , t.  h. haveliwala , c.  d. manning , and g.  h. golub .",
    "extrapolation methods for accelerating pagerank computations . in _ proceedings of the 12th international conference on world wide web _ , pages 261270 .",
    "acm , 2003 .",
    "m.  meiss , j.  duncan , b.  gonalves , j.  j. ramasco , and f.  menczer . what s in a session : tracking individual behavior on the web . in _ proceedings of the 20th acm conference on hypertext and hypermedia",
    "_ , pages 173182 .",
    "acm , 2009 .",
    "p.  pons and m.  latapy .",
    "computing communities in large networks using random walks . in p.  yolum , t.  gngr , f.  grgen , and c.  zturan , editors , _ computer and information sciences - iscis 2005 _ , volume 3733 of _ lecture notes in computer science _ , pages 284293 .",
    "springer berlin heidelberg , 2005 ."
  ],
  "abstract_text": [
    "<S> the random surfer model is a frequently used model for simulating user navigation behavior on the web . </S>",
    "<S> various algorithms , such as pagerank , are based on the assumption that the model represents a good approximation of users browsing a website . </S>",
    "<S> however , the way users browse the web has been drastically altered over the last decade due to the rise of search engines . </S>",
    "<S> hence , new adaptations for the established random surfer model might be required , which better capture and simulate this change in navigation behavior . in this article </S>",
    "<S> we compare the classical uniform random surfer to empirical navigation and page access data in a web encyclopedia . </S>",
    "<S> our high level contributions are ( i ) a comparison of stationary distributions of different types of the random surfer to quantify the similarities and differences between those models as well as ( ii ) new insights into the impact of search engines on traditional user navigation . </S>",
    "<S> our results suggest that the behavior of the random surfer is almost similar to those of users  as long as users do not use search engines . </S>",
    "<S> we also find that classical website navigation structures , such as navigation hierarchies or breadcrumbs , only exercise limited influence on user navigation anymore . </S>",
    "<S> rather , a new kind of navigational tools ( e.g. , recommendation systems ) might be needed to better reflect the changes in browsing behavior of existing users . </S>"
  ]
}