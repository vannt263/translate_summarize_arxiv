{
  "article_text": [
    "the merge of differential games and regime - switching models stems from a wide range of applications in communication networks , complex systems , and financial engineering .",
    "many problems arising in , for example , pursuit - evasion games , queueing systems in heavy traffic , risk - sensitive control , and constrained optimization problems , can be formulated as two - player stochastic differential games @xcite . in another direction ,",
    "recent applications for better describing the random environment leads to the use of the so - called regime - switching models ; see @xcite and many references therein . since for many problems arising in applications ,",
    "closed - form solutions are difficult to obtain . as a viable alternative , one",
    "is contended with numerical approximations @xcite .",
    "a systematic approach of numerical approximation for stochastic differential games was provided in @xcite using markov chain approximation methods .",
    "the major difficulty in dealing with such game problems is to prove the existence of the value of the game . to ensure the existence of saddle points , separability with respect to controls for objective function and the drift of the diffusion is required in @xcite",
    ". it would be nice to be able to relax the separability condition .",
    "markov chain approximations of stochastic differential games are indeed discrete markov games . in this paper",
    ", we aim to develop sufficient conditions for the existence of saddle point of discrete markov games . in the proof , we start with dynamic programming equation together with static game results obtained by sion @xcite and von neumann @xcite , discover the relations between static games and dynamic games by a series of inequalities .",
    "this approach enables us to treat non - separable discrete markov games with respect to controls . by virtue of results in discrete markov games",
    ", we can easily prove the existence of saddle points of discrete markov games arising in numerical approximations of stochastic differential games when a discretization parameter @xmath0 is used . as @xmath1",
    ", we are able to obtain the existence of saddle points of non - separable stochastic differential games using weak convergence techniques in @xcite and @xcite .",
    "the rest of the paper is arranged as follows .",
    "section ii begins with the formulation of the discrete markov games .",
    "section iii presents sufficient conditions for the existence of saddle points of discrete markov games for both ordinary control and relaxed control spaces , respectively .",
    "section iv applies the results in the discrete markov games to stochastic differential games .",
    "section v concludes the paper with further remarks .",
    "consider a two - player discrete markov zero - sum game .",
    "let @xmath2 be a finite state space of a markov chain , and @xmath3 be a collection of absorbing states .",
    "control space @xmath4 and @xmath5 for player @xmath6 and player @xmath7 are compact subsets of @xmath8 .",
    "[ for notational simplicity , we have chosen to treat real - valued controls in this paper . ]",
    "let @xmath9 be a controlled discrete - time markov chain , whose time - independent transition probabilities controlled by a pair of sequences @xmath10 is @xmath11 where @xmath12 denote the decision at time @xmath13 by player @xmath14 .",
    "[ adcon ] a control policy @xmath15 for the chain @xmath9 is admissible if @xmath16 if there is a function @xmath17 such that @xmath18 , then we refer to @xmath17 as a feedback control of player @xmath14 .",
    "given the running cost function @xmath19 , and the terminal cost function @xmath20 , the cost for an initial @xmath21 and an admissible control policy @xmath22 is defined by @xmath23,\\ ] ] where @xmath24 and @xmath25 is the expectation given that initial @xmath26 and control @xmath27 .    in the discrete markov game ,",
    "player @xmath6 wants to minimize the cost , while player @xmath7 wants to maximize .",
    "the two players have different information available depending on who makes the decision first ( or who `` goes first '' ) . using @xmath28 to denote the space of the admissible ordinary controls that player @xmath14 goes first .",
    "that is , for @xmath29 , there exists a sequence of measurable functions @xmath30 taking values in @xmath31 such that @xmath32 similarly , using @xmath33 to denote the collection of the admissible ordinary controls that player @xmath14 goes last , that is , @xmath34 is determined by a sequence of measurable functions @xmath35 taking values in @xmath31 such that @xmath36    to proceed , we define upper and lower values by @xmath37 @xmath38 respectively .",
    "it is obvious @xmath39 for @xmath40 .",
    "if the lower value and upper value are equal , then we say there exists a saddle point for the game , and its value is @xmath41    the corresponding dynamic programming equation is @xmath42 + c(x , r_1,r_2)\\},\\ ] ] @xmath43 + c(x , r_1,r_2)\\}.\\ ] ] practically , we can find @xmath44 and @xmath45 in ( [ uval ] ) and ( [ lval ] ) by solving ( [ udpe ] ) and ( [ ldpe ] ) using iterations .",
    "this is possible owing to the following lemma .",
    "the proof of this lemma can be found in ( * ? ? ?",
    "* lemma 2 ) , and a weaker form in @xcite .",
    "[ sdl ] @xmath9 is markov chain with state space @xmath2 , absorbing states @xmath46 , and transition probability @xmath47 .",
    "let there be a real number @xmath48 with @xmath49 @xmath50 is continuous in @xmath51 and @xmath52 , to each admissible control , @xmath27 , the cost @xmath53 is defined by ( [ cost1 ] ) .",
    "then @xmath53 is finite and solutions of ( [ udpe ] ) and ( [ ldpe ] ) are unique . for any initial value @xmath54 , the sequence @xmath55 + c(x , r_1,r_2)\\}\\ ] ] converges to @xmath56 , the unique solution of ( [ udpe ] ) as @xmath57 .",
    "analogously , for any initial @xmath58 , the sequence @xmath59 + c(x , r_1,r_2)\\}\\ ] ]    converges to @xmath60 , the unique solution of ( [ ldpe ] ) as @xmath57 .",
    "in this section , we provide sufficient conditions for the existence of saddle points in discrete markov games .",
    "an existence proof is established through a series of inequalities . in addition , the definition of relaxed controls is given as a generalization of ordinary controls .",
    "it is shown that saddle points always exist in relaxed control space .",
    "[ vc ] @xmath61 is said to be convex - concave with respect to @xmath62 , if @xmath63 is convex and @xmath64 is concave .",
    "next , we present a well - known minimax principle in static games , which was obtained by sion in @xcite .",
    "[ minmax ] let @xmath65 and @xmath66 be compact spaces , @xmath67 be a convex - concave function on @xmath68 , then @xmath69    one of following two assumptions are needed for the existence theorem .",
    "( h1 ) : :    @xmath47 and @xmath50 are    continuous and separable in @xmath51 and @xmath52 .",
    "( h2 ) : :    @xmath47 and @xmath50 are    convex - concave with respect to @xmath62 .",
    "[ st ] assume either ( h1 ) or ( h2 ) .",
    "@xmath9 is a markov chain as in lemma  [ sdl ] .",
    "let @xmath56 and @xmath60 be associated upper and lower values defined in ( [ uval ] ) and ( [ lval ] ) .",
    "then there exists a saddle points , that is , @xmath70    define two functions @xmath71 and @xmath72 by @xmath73 @xmath74 the dynamic programming equation of ( [ udpe ] ) and ( [ ldpe ] ) can be rewritten as @xmath75 @xmath76 under either assumption ( h1 ) or ( h2 ) , by lemma  [ minmax ] , @xmath77 let @xmath78 , then @xmath79 in particular , there exists @xmath80 , so that equal holds in ( [ st-2 ] ) , @xmath81 for @xmath82 given in ( [ st-3 ] ) , a series of inequalities follows , @xmath83 by virtue of ( [ st-3 ] ) , we conclude all inequalities are indeed equal in ( [ st-4 ] ) , and this implies @xmath84 note that @xmath85 for all @xmath86 .",
    "hence @xmath87 .",
    "the existence of the saddle point is established .",
    "the above theorem gives sufficient conditions for the existence of saddle points .",
    "we note that there always exist saddle points in _ relaxed control _ space with merely continuity assumed .",
    "[ rc ] a control policy @xmath88 for the chain @xmath9 is said to be a relaxed control policy , if @xmath89 is a probability measure on @xmath90 , a @xmath91-algebra of borel subsets of @xmath31 .",
    "more general definition of relaxed control is given by definition  [ dfn - rcon ] in the context of stochastic differential games .",
    "let @xmath92 and @xmath93 be collection of probability measure on @xmath94 and @xmath95 . slightly abusing notations , we generalize real function @xmath96 on @xmath97 into a function @xmath98 on @xmath99 as following @xmath100 using the notation of relaxed control representation ,",
    "the transition probability function is @xmath101 and the cost under the relaxed control policy @xmath102 is @xmath103.\\ ] ]    using @xmath104 to denote the space of admissible relaxed controls that player @xmath14 goes first .",
    "that is , for @xmath105 , there exists a sequence of measurable function @xmath106 taking values in @xmath107 such that @xmath108 analogously , using @xmath109 to denote the space of admissible relaxed controls that player @xmath14 goes last .",
    "that is , @xmath110 , there exists a sequence of measurable function @xmath111 taking values in @xmath107 such that @xmath112 the upper and lower values associated with relaxed control space are defined by @xmath113 @xmath114 respectively . to proceed ,",
    "we present another static game result obtained by von neumann @xcite .",
    "[ vonl ] let @xmath65 and @xmath66 be finite sets .",
    "let @xmath67 be a function on @xmath68 , @xmath115 and @xmath116 be probability measure on @xmath65 and @xmath66 , then @xmath117    [ rsad ] @xmath9 is a markov chain as in lemma  [ sdl ] with relaxed control used .",
    "assume @xmath118 and @xmath119 are continuous on @xmath97 .",
    "let @xmath120 and @xmath121 be associated upper and lower values of ( [ uvalr ] ) and ( [ lvalr ] ) .",
    "then there always exists a saddle point , that is @xmath122    define two functions @xmath123 and @xmath124 by @xmath125 @xmath126 then dynamic programming equation in relaxed control space can be written by @xmath127 @xmath128    note that @xmath129 is continuous in compact set @xmath97 .",
    "hence for @xmath130 , there exists a finite subset @xmath131 , such that @xmath132 @xmath133    forcing to the limit as @xmath134 in ( [ rsad-2 ] ) and ( [ rsad-3 ] ) , as well as using lemma  [ vonl ] , we have @xmath135    similarly , we obtain equality for function @xmath118 , @xmath136    equalities in ( [ rsad-4 ] ) and ( [ rsad-5 ] ) implies @xmath137 the rest of this proof is similar to the lines of inequalities ( [ st-4 ] ) .",
    "the details are omitted .",
    "in this section , we formulate stochastic differential games with regime switching . numerical methods using markov chain approximation leads to a sequence of discrete markov games discussed in the previous section .",
    "the use of theorem  [ st ] gives sufficient conditions for the existence of saddle points , and facilitates the proof .",
    "consider a two - player stochastic game of regime - switching diffusions .",
    "for a finite set @xmath138 , @xmath139 , @xmath140 , @xmath141 , the dynamic system is given by @xmath142 where for each @xmath143 , @xmath144 is a control for player @xmath14 , @xmath145 is a standard @xmath146-valued brownian motion , and @xmath147 is a continuous - time markov chain having state space @xmath148 with generator @xmath149 . let @xmath150 be a filtration , which might depend on controls , and which measures at least @xmath151 .",
    "we suppose that for each @xmath143 , @xmath144 is @xmath152-adapted taking values in a compact subset @xmath153 , which are called _",
    "admissible controls_. denote @xmath154 , which is symmetric and positive definite .",
    "let @xmath155 be a compact set that is the closure of its interior @xmath156 and @xmath157 be the first exit time of @xmath158 from @xmath159 with @xmath160 using a real number @xmath161 to denote the discount factor , let the cost function be @xmath162,{\\end{array}}\\ ] ] where @xmath163 and @xmath164 are functions representing the running cost and terminal cost , respectively , and @xmath165 denotes the expectation taken with the initial data @xmath166 and @xmath167 and given control process @xmath168 .",
    "next , we introduce the relaxed control representation ; see @xcite .",
    "[ dfn - rcon ] let @xmath169 be the @xmath170-algebra of borel subsets of @xmath171 .",
    "an _ admissible relaxed control _",
    "@xmath172 is a measure on @xmath173 such that @xmath174 ) = t$ ] for each @xmath175 .",
    "given a relaxed control @xmath172 , there is an @xmath176 such that @xmath177 .",
    "in fact , we can define @xmath178 ) } { \\delta}}$ ] for @xmath179 .",
    "to proceed , we need the following assumptions .    * for each @xmath180 , @xmath181 and @xmath182 are continuous functions on the compact set @xmath183 . * for each @xmath184 , the functions @xmath185 and @xmath186 are continuous on @xmath187 .",
    "* equation ( [ mod1 ] ) , where the controls are replaced by relaxed controls , has a unique weak sense solution ( i.e. , unique in the sense of in distribution ) for each admissible triple @xmath188 , where @xmath189 .",
    "* for any @xmath190 @xmath191 @xmath192 .",
    "* let @xmath193 the function @xmath194 is continuous as a mapping from @xmath195 to @xmath196 $ ] with probability one relative to the measure induced by any solution with initial condition @xmath197 , where @xmath195 denotes the space of functions that are right continuous and have left limits endowed with the skorohod topology , and @xmath196 $ ] is the interval @xmath198 compactified ( see @xcite ) . *",
    "the functions @xmath199 and @xmath200 are separable in @xmath51 and @xmath52 for every @xmath201 .",
    "that is , @xmath202 and @xmath203 .",
    "* the cost @xmath204 is convex - concave with respect to @xmath62 , and there exist @xmath146-valued continuous functions @xmath205 ( @xmath206 ) such that @xmath207    assumption ( a4 ) is used for construction of transition probabilities of the approximating markov chain .",
    "it requires that the diffusion matrix be diagonally dominated . if the given dynamic system does not satisfy ( a4 ) , then we can adjust the coordinate system to satisfy assumption ( a4 ) ; see @xcite .",
    "( a5 ) is a broad condition that is satisfied in most applications .",
    "the main purpose is to avoid the _ tangency _ problem discussed in @xcite .",
    "later , we will establish the existence of _ saddle points _ using either ( a6 ) or ( a7 ) in addition to ( a1)(a5 ) .",
    "condition ( a7 ) allows non - separable differential games with respect to controls .",
    "now we are ready to define upper values , lower values , and _ saddle points _ of differential games ; see @xcite for the corresponding definitions of systems without regime switching .",
    "let @xmath208 be collection of all admissible ordinary control with respect to @xmath209 .",
    "for @xmath210 , let @xmath211 such that @xmath17 are piecewise constant on the intervals @xmath212 , and @xmath213 is @xmath214-measurable .",
    "let @xmath215 denote the set of such piecewise constant controls for player @xmath6 that are determined by measurable real - valued functions @xmath216 @xmath217 we can define @xmath218 and the associated rule @xmath219 for player @xmath7 analogous to ( [ defcon1 ] ) .",
    "thus we can always suppose that if the control of ( for example ) player @xmath6 is determined by a form such as ( [ defcon1 ] ) .",
    "then ( in relaxed control terminology ) the law of @xmath220 for @xmath221 is determined recursively by past information @xmath222    [ defval1 ] for initial condition @xmath223 , define the upper and lower values for the game as @xmath224 @xmath225 if the lower and upper value are equal , then we say there exists a saddle point for the game , and its value is @xmath226      here , we will construct a two - component markov chain .",
    "the discretization of differential game leads to a sequence of discrete markov games .",
    "the approximation is of finite difference type .",
    "the basis of the approximation is a discrete - time , finite - state , controlled markov chain @xmath227 whose properties are _ locally consistent _ with that of ( [ mod1 ] ) .    for each @xmath228 ,",
    "let @xmath229 be a finite subset of @xmath187 such that @xmath230 as @xmath1 , where @xmath231 is a metric defined by @xmath232 let @xmath227 be a controlled discrete - time markov chain on a discrete state space @xmath233 with transition probabilities denoted by @xmath234 , where @xmath235 .",
    "we use @xmath236 to denote the actual control action for the chain at discrete time @xmath13 .",
    "suppose we have a positive function @xmath237 on @xmath238 such that @xmath239 as @xmath240 , but @xmath241 for each @xmath228 .",
    "we take an interpolation of the discrete markov chain @xmath242 by using interpolation interval @xmath243 .",
    "now we give the definition of local consistency .",
    "[ deflc1 ] let @xmath244 for @xmath197 and @xmath245 in @xmath246 and @xmath247 be a collection of well - defined transition probabilities for the two - component markov chain @xmath248 , approximation to @xmath249 .",
    "define the difference @xmath250 .",
    "assume @xmath251 .",
    "denote by @xmath252 , @xmath253 and @xmath254 the conditional expectation , covariance , and probability given @xmath255 .",
    "the sequence @xmath248 is said to be _ locally consistent _ with ( [ mod1 ] ) , for @xmath256 , if @xmath257    to approximate the cost defined in ( [ costfun1 ] ) , we define a cost function using the markov chain above .",
    "let @xmath258 the cost for @xmath259 and initial @xmath197 is @xmath260 , { \\end{array}}\\ ] ]    using @xmath261 to denote the space of the ordinary controls that player @xmath14 goes first , and its strategy is defined by measurable functions of the type similar to ( [ defcon1 ] ) .",
    "that is , for @xmath262 , @xmath263 is determined by @xmath264 by @xmath265 denote the collection of the ordinary controls that player @xmath14 goes last . for @xmath266 , @xmath263 is determined by @xmath267 the associated upper and lower values is defined as @xmath268 @xmath269      in this section , we present a local consistent discrete markov game of @xmath270 generated by central finite difference scheme for analysis purpose .",
    "under assumptions ( a1)(a5 ) together with either ( a6 ) or ( a7 ) , we can apply theorem  [ st ] to show the existence of saddle points for each @xmath0 . by forcing the limit @xmath240",
    ", the upper ( lower ) values converge to that of stochastic differential game by lemma  [ lem : conv ] , and it results in the existence of saddle points .",
    "first , the transition probabilities for @xmath270 are @xmath271 where @xmath272 set the interpolation interval as @xmath273 by ( a4 ) , @xmath274 .",
    "also , we have @xmath275 . to ensure that @xmath276 is always nonnegative , we require @xmath277 assume ( a1 ) , ( a2 ) , ( a4 ) , and @xmath0 satisfies ( [ asmp - h ] ) .",
    "the markov chain @xmath278 with transition probabilities @xmath279 and interpolation @xmath280 defined above is locally consistent with ( [ mod1 ] ) .",
    "the criterion in ( [ deflc2 ] ) can be verified through a series of calculations , thus details are omitted .",
    "[ sadptthm1 ] assume ( a1)(a5 ) , either ( a6 ) or ( a7 ) , and @xmath229 is a finite set defined above ( [ met ] ) . for @xmath281 and @xmath282 ,",
    "a markov chain is defined by ( [ transpb3 ] ) .",
    "let @xmath283 and @xmath284 be the associated upper and lower values defined in ( [ defupval2 ] ) and ( [ deflwval2 ] ) in the control spaces @xmath261 and @xmath285 .",
    "then there exists a saddle point @xmath286 provided @xmath0 satisfies ( [ asmp - h ] ) .",
    "the contraction condition ( [ sdl-1 ] ) satisfies for the discount factor @xmath287 .",
    "let @xmath288 @xmath289 assumptions ( a6 ) and ( a7 ) lead to ( h1 ) and ( h2 ) , respectively .",
    "the result holds applying theorem  [ st ] .",
    "although the proof of next lemma is rather complicated and not trivial , the proof is referred to weak convergence techniques in @xcite , @xcite , and @xcite due to the limit of space .",
    "[ lem : conv ] assume that the conditions of theorem  [ sadptthm1 ] are satisfied . then for the approximating markov chain , we have @xmath290 @xmath291    [ sadptthm4 ] assume the conditions of theorem  [ sadptthm1 ] are satisfied .",
    "then the differential game has saddle point in the sense @xmath292",
    "the key part of zero - sum game problems is existence of saddle point .",
    "this paper is devoted to sufficient condition for the existence of saddle point in discrete markov game .",
    "using dynamic programming equation method , we are able to use static game results of sion @xcite and von neumann @xcite to discover the sufficient conditions .",
    "a direct application is numerical methods for stochastic differential game problems .",
    "the transition probabilities used in ( [ transpb3 ] ) requires restriction ( [ asmp - h ] ) on @xmath0 .",
    "practically , we develop the transition probabilities by upward finite difference scheme , so that the generated one is well defined without restriction on @xmath0 .",
    "it can be routinely calculated to verify the local consistency .",
    "this kind of discrete markov game might have different upper and lower values for some @xmath0 .",
    "however , both the upper and lower values in this situation converge to the original saddle point of differential game @xmath293 by lemma  [ lem : conv ] and theorem  [ sadptthm4 ] .",
    "numerical examples in pursuit - evasion games are omitted due to the space limit , although the numerical results clearly verify our works .    for a regime - switching system",
    "in which the markov chain has a large state space , we may use the ideas of two - time - scale approach presented in @xcite ( see also @xcite and references therein ) to first reduce the complexity of the underlying system and then construct numerical solutions for the limit systems .",
    "optimal strategies of the limit systems can be used for constructing strategies of the original systems leading to near optimality .",
    "h. j. kushner , s. g. chamberlain , on stochastic differential games : sufficient conditions that a given strategy be a saddle point , and numerical procedures for the solution of the game , _ journal of mathematical analysis and applications _",
    ", * 26 * ( 1969 ) , 560 - 575 ."
  ],
  "abstract_text": [
    "<S> this work establishes sufficient conditions for existence of saddle points in discrete markov games . </S>",
    "<S> the result reveals the relation between dynamic games and static games using dynamic programming equations . </S>",
    "<S> this result enables us to prove existence of saddle points of non - separable stochastic differential games of regime - switching diffusions under appropriate conditions . </S>"
  ]
}