{
  "article_text": [
    "the theory of error - correcting codes is based on the efficient introduction of redundancy to given messages for protecting the information content against corruption .",
    "the theoretical foundations of this area were laid by shannon s seminal work  @xcite and have been developing ever since .",
    "one of the main results obtained in this field is the celebrated _ channel coding theorem _ stating that there exists a code such that the average message error probability @xmath2 , when maximum likelihood decoding is used , can be made arbitrarily small for sufficiently long messages below the _ channel capacity _ ; and will approach 1 above it .",
    "the channel coding theorem is based on unstructured random codes and impractical decoders such as maximum likelihood @xcite and typical set decoding  @xcite . in the case of structured codes",
    ", the critical code rate @xmath3 ( message information content / length of the encoded transmission ) may lie below the channel capacity , commonly termed _",
    "shannon s bound _ , even if optimal ( and typically impractical ) decoding methods are being used .",
    "the proximity of the critical code rate to shannon s limit provides an indication to the theoretical limitations of a given code .    in 1963",
    "gallager @xcite proposed a coding scheme which involves sparse linear transformations of binary messages that was forgotten soon after , in part due to the success of convolutional codes  @xcite and the computational limitations of the time .",
    "gallager codes have been recently rediscovered by mackay and neal ( mn ) , that independently proposed a closely related code  @xcite .",
    "variations of this family of codes , known as low density parity check ( ldpc ) codes , have displayed performance comparable ( and sometimes superior ) to other state - of - the - art codes .",
    "this family of codes has been thoroughly investigated in the information theory ( it ) literature ( e.g. , @xcite ) , providing a range of significant theoretical and practical results .    in parallel to studies carried out in the it community",
    ", a different approach has been used to study ldpc codes , using the established methods of statistical physics ( sp ) .",
    "this analysis , relying mainly on the replica symmetric analysis of diluted systems  @xcite , offers an alternative to information theory methods and has yielded some new results and insights @xcite . due to the growing interest in ldpc codes and",
    "their successful analysis via the methods of statistical physics , there is growing interest in the relationship between it and sp methods .",
    "as the two communities investigate similar problems , one may expect that standard techniques known in one framework would bring about new developments in the other , and vice versa .",
    "here we present a direct sp method to determine the critical noise level of gallager and mn error correcting codes , which allows us to focus on the differences between the various decoding criteria and their use for defining the critical noise level for which decoding is theoretically feasible .",
    "the paper is organized as follows : in section  [ sec : framework ] we introduce the general framework , notation and the quantities we focus on , while in section  [ sec : sp ] we will briefly describe the sp calculation . section  [ sec : qualitative ] describes qualitatively the emerging picture of the main quantities calculated for gallager s code while the corresponding picture for mn codes will be described in section  [ sec : mn ] . quantitative results for the critical noise level will be presented in section  [ sec : results ] followed by conclusions .",
    "in a general scenario , the @xmath4 dimensional boolean message @xmath5 is encoded to the @xmath6 dimensional boolean vector @xmath7 , and transmitted via a noisy channel , which is taken here to be a binary symmetric channel ( bsc ) characterized by an independent flip probability @xmath8 per bit ; other transmission channels may also be examined within a similar framework . at the other end of the channel ,",
    "the corrupted codeword is decoded utilizing the structured codeword redundancy .",
    "the first type of error correcting code that we focus on here , is gallager s linear code  @xcite .",
    "gallager s code is a low density parity check code defined by the a binary @xmath9 matrix @xmath10 $ ] , concatenating two very sparse matrices known to both sender and receiver , with the @xmath11 matrix @xmath12 being invertible .",
    "the matrix @xmath13 has @xmath14 non - zero elements per row and @xmath15 per column , and the code rate is given by @xmath16 .",
    "encoding refers to multiplying the original message @xmath17 with the @xmath18 matrix @xmath19 ( where @xmath20 $ ] ) , yielding the transmitted vector @xmath21 .",
    "note that all operations are carried out in ( mod 2 ) arithmetic . upon sending @xmath22 through the binary symmetric channel ( bsc ) with noise level @xmath8 ,",
    "the vector @xmath23 is received , where @xmath24 is the true noise .",
    "decoding is carried out by multiplying @xmath25 by @xmath13 to produce the syndrome vector @xmath26 ( @xmath27 , since @xmath28 ) . in order to reconstruct the original message @xmath17",
    ", one has to obtain an estimate @xmath29 for the true noise @xmath24 .",
    "first we select all @xmath29 that satisfy the parity checks @xmath30 : @xmath31 the ( restricted ) parity check set .",
    "the second type of error correcting code that we focus on here is the mackay - neal ( mn ) code  @xcite .",
    "an mn code is a low density parity check code defined by a binary @xmath32 matrix @xmath33 $ ] , concatenating two very sparse matrices known to both sender and receiver , with the @xmath34 matrix @xmath35 being invertible .",
    "the @xmath36 matrix @xmath37 has @xmath14 non - zero elements per row and @xmath15 per column , while @xmath35 has @xmath38 non - zero elements per row and column .",
    "the code rate is given by @xmath39 .",
    "encoding refers to multiplying the original message @xmath40 by the @xmath41 dense generator matrix @xmath42 , yielding the transmitted vector @xmath7 .",
    "note that all operations are carried out in ( mod2 ) arithmetic . upon sending @xmath7 through the binary symmetric channel ( bsc ) with noise level @xmath8 ,",
    "the vector @xmath43 is received , where @xmath44 is the true noise .",
    "decoding is carried out by multiplying @xmath45 by @xmath35 to produce the syndrome vector @xmath46 , where @xmath47 is the concatenated vector @xmath48 . in order to reconstruct the original message @xmath40",
    ", one has to obtain estimates @xmath47 for the true signal and noise @xmath49 .",
    "first we select all combinations of signal and noise @xmath47 that satisfy the parity checks @xmath50 : @xmath51 the ( restricted ) parity check set . to unify notation for gallager and mn codes",
    ", we will adopt the notation @xmath49 for the original noise ( and signal ) vector , and @xmath47 for the estimate of the noise ( and signal ) vector .",
    "any general decoding scheme then consists of selecting a vector @xmath52 from @xmath53 , on the basis of some noise ( and signal ) statistics criterion . upon successful decoding",
    "@xmath49 will be selected , while a decoding error is declared when a vector @xmath54 is selected . for each decoding scheme , the average _ block error probability _",
    "@xcite @xmath55 can be defined as a measure of error correcting ability for a given code ensemble , where @xmath56 is an indicator function returning @xmath57 if the proposition of the argument is true and @xmath58 , otherwise .",
    "for bsc , only the number of non - zero components characterizes the statistics of the noise .",
    "on the other hand , the signal bits in general have an equal probability for being 0 and 1 ( i.e. @xmath59 ) , which implies that they have no useful prior information for the estimation . in the following ,",
    "we therefore focus on decoding schemes based on the weight of a vector which is the average sum of the noise components @xmath60 . to obtain the error probability ,",
    "one averages the indicator function over all @xmath49 vectors drawn from some distribution and the code ensemble @xmath13 as denoted by @xmath61 .",
    "unfortunately , carrying out averages over the indicator function is difficult .",
    "therefore , the error probability  ( [ pe ] ) is usually upper - bounded by averaging over the _ number _ of vectors @xmath62 obeying a certain condition on the weight @xmath63 which characterizes the employed decoding scheme .",
    "alternatively , one can find the average number of vectors with a given weight value @xmath64 from which one can construct a complete weight distribution of noise vectors @xmath62 in @xmath65 . from this distribution one can",
    ", in principle , calculate a bound for @xmath66 and derive critical noise values above which successful decoding can not be carried out .    a natural and direct measure for the average number of states",
    "is the entropy of a system under the restrictions described above , that can be calculated via the methods of statistical physics .",
    "it was previously shown ( see e.g.  @xcite for technical details ) that this problem can be cast into a statistical mechanics formulation , by replacing the field @xmath67 by ( @xmath68 ) , and by adapting the parity checks correspondingly .",
    "the statistics of a noise vector @xmath29 is now described by its magnetization @xmath69 , @xmath70)$ ] , which is inversely linked to the vector weight in the @xmath71 $ ] representation .",
    "similarly , the statistics of a signal vector @xmath72 is now described by its magnetization @xmath73 , @xmath74)$ ] . with this in mind , we introduce the conditioned magnetization enumerator , for a given code and noise , measuring the noise vector magnetization distribution in @xmath75 @xmath76~. \\label{man}\\ ] ] to obtain the _ magnetization enumerator _ @xmath77 @xmath78 which is the entropy of the noise vectors in @xmath79 with a given @xmath80 , one carries out uniform explicit averages over all codes @xmath13 with given parameters @xmath81 ( and @xmath38 ) , and the weighted average over all possible noise vectors generated by the bsc , ( and all possible signal vectors ) i.e. , @xmath82 with @xmath59 .",
    "it is important to note that , in calculating the entropy , the average quantity of interest is the magnetization enumerator rather than the actual number of states . as physicists ,",
    "this is the natural way to carry out the averages for three main reasons : a ) the entropy obtained in this way is believed to be _ self - averaging _ , i.e. , its average value ( over the disorder ) coincides with its _ typical _ value .",
    "b ) this quantity is _ extensive _ and grows linearly with the system size .",
    "c ) this averaging distinguishes between _ annealed _ variables that are averaged or summed for a given set of _ quenched _ variables , that are averaged over later on . in this particular case ,",
    "summation over all @xmath47 vectors is carried for a _ fixed _ choice of code @xmath13 and vector @xmath49 ; averages over these variables",
    "are carried out at the next level .",
    "one should point out that in somewhat similar calculations , we showed that this method of carrying out the averages provides more accurate results in comparison to averaging over both sets of variables simultaneously  @xcite .    a positive magnetization enumerator",
    ", @xmath83 indicates that there is an exponential number of solutions ( in @xmath84 ) with magnetization @xmath80 , for typically chosen @xmath13 and @xmath49 , while @xmath85 indicates that this number vanishes as @xmath86 ( note that negative entropy is unphysical in discrete systems ) .    another important indicator for successful",
    "decoding is the overlap @xmath87 between the selected estimate @xmath88 , and the true noise @xmath44 :  @xmath89 , @xmath90)$ ] , with @xmath91 for successful ( perfect ) decoding .",
    "however , this quantity can not be used for decoding as @xmath44 is unknown to the receiver . the ( code and noise dependent ) noise overlap enumerator",
    "is now defined as : @xmath92 \\ , \\ ] ] and the average quantity being @xmath93 this measure is directly linked to the _ weight enumerator _",
    "@xcite , although according to our notation , averages are carried out distinguishing between annealed and quenched variables unlike the common definition in the it literature . however , as we will show below , the two types of averages provide identical results _ in this particular case_.    similarly , for mn - codes one defines the signal magnetization and weight enumerators as @xmath94\\ket_{\\bfa,\\vcc^o}\\\\ \\cw_s(\\om_s)&\\ev&{1\\ov n}\\bra\\ln\\left[\\tr_{\\vcc\\in\\ci^{\\rm r}_{\\rm pc } ( \\bfa,\\vcc^o)}\\de(\\om(\\vs,\\vs^o)\\m\\om_s)\\right]\\ket_{\\bfa,\\vcc^o}\\end{aligned}\\ ] ] in what follows , we perform all calculations as if both @xmath80 and @xmath87 ( and @xmath95 and @xmath96 for mn - codes ) , are constrained to particular values .",
    "as we will show , omitting a constraint in the final expressions can then easily be done by assigning the zero value to the corresponding lagrange multiplier .",
    "quantities of the type @xmath97 , with @xmath98 $ ] and @xmath99 , are very common in the sp of disordered systems ; the macroscopic order parameter @xmath100 is fixed to a specific value and may depend both on the disorder @xmath101 and on the microscopic variables @xmath102 . although we will not prove this here , such a quantity is generally believed to be _ self - averaging _ in the large system limit , i.e. , obeying a probability distribution @xmath103 .",
    "the direct calculation of @xmath104 is known as a _ quenched _ average over the disorder , but is typically hard to carry out and requires using the replica method  @xcite .",
    "the replica method makes use of the identity @xmath105/\\rn \\",
    "\\ket$ ] , by calculating averages over a product of partition function replicas . employing assumptions about replica symmetries and analytically continuing the variable @xmath106 to zero",
    ", one obtains solutions which enable one to determine the state of the system .    to simplify the calculation , one often employs the so - called _ annealed _ approximation , which consists of performing an average over @xmath107 first , followed by the logarithm operation",
    "this avoids the replica method and provides ( through the convexity of the logarithm function ) an upper bound to the quenched quantity : @xmath108~\\geq~ q_q(c)\\equiv{1\\ov m}{\\left\\langle     } \\ln[\\cz_y(c)]{\\right\\rangle } _",
    "y=\\lim_{\\rn \\!\\to\\!0 } { \\bra\\cz_y^\\rn ( c)\\ket_y\\m 1\\ov \\rn m}~. \\label{qaq}\\ ] ] the technical details of the calculation are similar to those in  @xcite .",
    "it turns out that it is useful to perform the gauge transformation @xmath109 , such that the averages over the code @xmath110 and noise / signal @xmath49 can be separated , @xmath111 becomes independent of @xmath49 , leading to an equality between the quenched and annealed results , @xmath112 . for any finite noise value @xmath8 one should multiply @xmath113 $ ] by the probability that a state obeys all parity checks @xmath114 $ ] given an overlap @xmath87 and a noise level @xmath8  @xcite . in calculating @xmath115 and @xmath116 , the @xmath117-functions fixing @xmath80 and @xmath87 ,",
    "are enforced by introducing lagrange multipliers @xmath118 and @xmath119 .",
    "carrying out the averages explicitly one then employs the saddle point method to extremize the averaged quantity with respect to the parameters introduced while carrying out the calculation .",
    "these lead , in both quenched and annealed calculations , to a set of saddle point equations that are solved either analytically or numerically to obtain the final expression for the averaged quantity ( entropy ) .",
    "the final expressions for the annealed entropy per noise degree of freedom for gallager codes , under both overlap ( @xmath87 ) and magnetization ( @xmath80 ) constraints , are of the form : @xmath120\\right)\\e\\ln\\!\\bra \\tr_{n=\\pm1}\\exp(n({{\\hat{\\om } } } \\e{{\\hat{m    } } } n^o))(1\\e nc_1^{k\\m1})^c\\ket_{n^o } - ( { { \\hat{\\om } } } \\om \\e { { \\hat{m    } } } m)~ , \\label{qa_g}\\ ] ] where @xmath121 has to be obtained from the saddle point equation @xmath122 .",
    "similarly , the final expression in the quenched calculation , employing the simplest replica symmetry assumption  @xcite , is of the form : @xmath123\\e { c\\ov k}\\int\\!\\left\\{\\prod_{k=1}^kdx_k\\pi(x_k)\\right\\}\\ln\\left[\\ha \\left(1\\e\\!\\prod_{k=1}^k\\!x_k\\right)\\right]\\nonumber\\\\ & & + \\!\\int\\!\\left\\{\\prod_{c=1}^cd\\htx_c{{\\hat{\\pi } } } ( \\htx_c)\\right\\}\\bra\\!\\ln\\left[\\tr_{n=\\pm1}\\exp(n(\\hat{\\om}\\e\\hat{m}n^o ) ) \\prod_{c=1}^c(1\\e n\\htx_c )   \\right]\\!\\ket_{n^o } - ( { { \\hat{\\om } } } \\om \\e { { \\hat{m    } } } m)~.   \\label{qq_g}\\end{aligned}\\ ] ] the probability distributions @xmath124 and @xmath125 emerge from the calculation ; the former represents a probability distribution with respect to the noise vector local magnetization  @xcite , while the latter relates to a field of conjugate variables which emerge from the introduction of @xmath117-functions while carrying out the averages ( for details see  @xcite ) .",
    "their explicit forms are obtained from the functional saddle point equations @xmath126 , @xmath127 , and all integrals are from @xmath128 to 1 .",
    "the final expressions for the annealed entropy per noise degree of freedom for mn - codes , under both signal and noise overlap ( @xmath129 ) and magnetization ( @xmath130 ) constraints , are of the form : @xmath131\\rh          -r(\\htm_sm_s\\e{{\\hat{\\om } } } _",
    "s\\om_s)-({{\\hat{m    } } } m\\e{{\\hat{\\om } } } \\om )                      \\nn\\\\    & & + r\\ln\\bra\\tr_{s=\\pm1}\\exp\\lh s({{\\hat{\\om } } } _ s+\\htm_s~s^o)\\rh(1+s\\htc_1)^c\\ket_{s^o }      + \\ln\\bra\\tr_{n=\\pm1}\\exp\\lh n({{\\hat{\\om } } } + { { \\hat{m    } } } ~n^o)\\rh(1+n\\htd_1)^l\\ket_{n^o } \\label{qa_m}\\end{aligned}\\ ] ] where @xmath132 have to be obtained from the saddle point equations @xmath133 . similarly , the final expression in the quenched calculation , employing the simplest replica symmetry assumption  @xcite , is of the form : @xmath134          + r\\int\\prod_{c=1}^cd\\htx_c~{{\\hat{\\pi } } } ( \\htx_c)\\bra\\ln\\lv\\tr_{s=\\pm1 }            \\exp(s({{\\hat{\\om } } } _",
    "s+\\htm_ss^o))\\prod_{c=1}^c(1\\e s\\htx_c)\\rv\\ket_{s^o}\\nn\\\\       & & -l\\int dyd\\hty~~\\rho(y){{\\hat{\\rho}}}(\\hty)~~\\ln[1\\e y\\hty ]          + ~~\\int\\prod_{l=1}^ld\\hty_l~{{\\hat{\\rho}}}(\\hty_l)~~\\bra\\ln\\lv\\tr_{n=\\pm1 }            \\exp(n({{\\hat{\\om } } } ~+{{\\hat{m    } } } ~n^o ) \\prod_{l=1}^l(1\\e n\\hty_l~)\\rv\\ket_{n^o } \\label{qq_m}\\end{aligned}\\ ] ] the probability distributions @xmath135 and @xmath136 emerge from the calculation ; the former represent probability distributions with respect to the signal / noise vector local magnetizations  @xcite , while the latter relate to fields of conjugate variables which emerge from the introduction of @xmath117-functions while carrying out the averages ( for details see  @xcite ) .",
    "their explicit forms are obtained from the functional saddle point equations @xmath137 , and all integrals are from @xmath128 to 1 .    enforcing a @xmath138-function corresponds to taking @xmath139 such that @xmath140 , while not enforcing it corresponds to putting @xmath139 to 0 . since @xmath141 ,",
    "follow from @xmath142 , all the relevant quantities can be recovered with appropriate choices of @xmath139 .",
    "( 140,100 ) ( 0 , 50)=50 ( 5 , 90 ) ( 35 , 95 ) ( 40 , 58 ) ( 50 , 58 ) ( 2 , 58 ) ( 64 , 58 ) ( 70 , 50)=50 ( 75 , 90 ) ( 105 , 95 ) ( 110 , 58 ) ( 120 , 58 ) ( 72 , 58 ) ( 134 , 58 ) ( 35 , 0)=50 ( 40 , 40 ) ( 70 , 45 ) ( 75 , 8) ( 85 , 8) ( 37 , 8) ( 99 , 8) ( 63,80 ) ( 127,80 ) ( 85,30 )",
    "we now discuss the qualitative behaviour of @xmath77 , and the interpretation of the various decoding schemes . to obtain separate results for @xmath77 and @xmath143",
    "we calculate the results of eqs.([qa_g ] ) and ( [ qq_g ] ) ( and eqs .",
    "( [ qa_m ] ) and ( [ qq_m ] ) ) , corresponding to the annealed and quenched cases respectively , setting @xmath144 to obtain @xmath77 and @xmath145 to obtain @xmath115 ( that becomes @xmath146 after gauging ) . in fig .",
    "[ fig:1 ] , we have qualitatively plotted the resulting function @xmath77 for relevant values of @xmath8 .",
    "@xmath77 ( solid line ) only takes positive values in the interval @xmath147 $ ] ; for even @xmath14 , @xmath77 is an even function of @xmath80 and @xmath148 .",
    "the maximum value of @xmath77 is always @xmath149 for gallager codes , and @xmath150 for mn codes .",
    "the true noise @xmath44 has ( with probability 1 ) the typical magnetization of the bsc : @xmath151 ( dashed - dotted line ) .",
    "the various decoding schemes can be summarized as follows :    * * maximum likelihood ( map ) decoding * - minimizes the block error probability  @xcite and consists of selecting the @xmath29 from @xmath152 with the highest magnetization . since the probability of error below @xmath153 vanishes , @xmath154 , and since @xmath155 , the critical noise level @xmath156 is determined by the condition @xmath157 . the selection process is explained in fig.[fig:1](a)-(c ) . *",
    "* typical pairs decoding * - is based on randomly selecting a @xmath29 from @xmath158 with @xmath159  @xcite ; an error is declared when @xmath160 is not the only element of @xmath158 .",
    "for the same reason as above , the critical noise level @xmath156 is determined by the condition @xmath157 . * * finite temperature ( mpm ) decoding * - an energy @xmath161 ( with @xmath162 ) according to nishimori s condition ( corresponding to the selection of an accurate prior within the bayesian framework ) .",
    "is attributed to each @xmath163 , and a solution is chosen from those with the magnetization that minimizes the free energy  @xcite . this procedure is known to minimize the _ bit error probability _ @xcite . using the thermodynamic relation @xmath164 , @xmath165 being the inverse temperature ( nishimori s condition corresponds to setting @xmath166 ) , the free energy of the sub - optimal solutions",
    "is given by @xmath167 ( for @xmath168 ) , while that of the correct solution is given by @xmath169 ( its entropy being 0 ) .",
    "the selection process is explained graphically in fig.[fig:1](a)-(c ) .",
    "the free energy differences between sub - optimal solutions relative to that of the correct solution in the current plots , are given by the orthogonal distance between @xmath77 and the line with slope @xmath170 through the point @xmath171 .",
    "solutions with a magnetization @xmath80 for which @xmath77 lies above this line , have a lower free energy , while those for which @xmath77 lies below , have a higher free energy . since negative entropy values are unphysical in discrete systems , only sub - optimal solutions with @xmath168 are considered .",
    "the lowest @xmath8 value for which there are sub - optimal solutions with a free energy equal to @xmath169 is the critical noise level @xmath172 for mpm decoding .",
    "in fact , using the convexity of @xmath77 and nishimori s condition , one can show that the slope @xmath173 for any value @xmath174 and any @xmath8 , and equals @xmath170 only at @xmath175 ; therefore , the critical noise level for mpm decoding @xmath176 is identical to that of map , in agreement with results obtained in the information theory community  @xcite .",
    "+ the statistical physics interpretation of finite temperature decoding corresponds to making the specific choice for the lagrange multiplier @xmath177 and considering the free energy instead of the entropy . in earlier work on mpm decoding in the sp framework",
    "@xcite , negative entropy values were treated by adopting different replica symmetry assumptions , which effectively result in changing the inverse temperature , i.e. , the lagrange multiplier @xmath118 .",
    "this effectively sets @xmath178 , i.e. to the highest value with non - negative entropy .",
    "the sub - optimal states with the lowest free energy are then those with @xmath178 .",
    "the central point in all decoding schemes , is to select the correct solution only on the basis of its magnetization .",
    "as long as there are no sub - optimal solutions with the same magnetization , this is in principle possible . as shown here , all three decoding schemes discussed above , manage to do so . to find whether at a given @xmath8 there exists a gap between the magnetization of the correct solution and that of the nearest sub - optimal solution",
    ", just requires plotting @xmath179 and @xmath180 , thus allowing a graphical determination of @xmath156 .",
    "since mpm decoding is done at nishimori s temperature , the simplest replica symmetry assumption is sufficient to describe the thermodynamically dominant state  @xcite . at @xmath156",
    "the states with @xmath181 are thermodynamically dominant , and the @xmath156 values that we obtain under this assumption are exact .",
    "for mn codes there is a way to obtain the _ exact _ expression for @xmath0 , in the case of unbiased messages , by employing a single highly plausible assumption .",
    "we first note that every the parity check bit @xmath182 is made up of a combination of @xmath14 unbiased ( i.e. @xmath59 ) signal bits , and @xmath38 biased ( i.e. @xmath183 ) noise bits . as a result ,",
    "every syndrome element @xmath184 is unbiased independently of the noise bit statistics .",
    "it is therefore plausible to assume that the noise bit statistics ( i.e. @xmath8 ) have no influence on the distribution of the parity check bits @xmath184 , and therefore on @xmath0 ( which only depends on the true noise through the @xmath184 ) .",
    "if this assumption is satisfied , one can invoke nishimori s condition to obtain an exact expression for @xmath0 . independently of the assumption , nishimori s condition gives the following identity for the thermodynamically dominant state : @xmath185 since states characterized by any magnetization value @xmath186 will become dominant for an appropriately chosen value of @xmath8 , and since we assume that @xmath0 is independent of @xmath8 , the identity @xmath187 must hold for any value of @xmath80 .",
    "furthermore , the maximum of @xmath77 is reached at @xmath188 with @xmath189 , and we have that @xmath190 where @xmath191 is the binary entropy per bit for vectors with bias @xmath8 . hence , under this assumption , we do not only obtain the exact expression for @xmath77 , but we see that the critical noise level @xmath156 is given by @xmath192 , saturating shannon s bound for this type of codes !    unfortunately , the assumption can not be verified easily without the replica method . to verify whether indeed @xmath193 , we have to take the derivative of expression  ( [ qq_m ] ) ( setting @xmath194 ) with respect to @xmath8 .",
    "it turns out that @xmath0 is only independent of @xmath8 , when @xmath195 is an even function of @xmath196 , which in turn requires that @xmath197 and @xmath124 are even functions of their arguments .",
    "numerical analysis shows , that this is the case for any @xmath198 or @xmath199 , while not so for @xmath200 or @xmath201 .",
    "this result is consistent with those reported in @xcite , i.e. that typical mn codes with @xmath198 or @xmath199 do saturate shannon s bound , while those with @xmath200 and @xmath201 do not .    intuitively this result can be understood in the following way .",
    "there are @xmath84 parity check bits and only @xmath202 signal bits , such that parity check bits , although individually unbiased , are not uncorrelated .",
    "these correlations do seem to have an effect on @xmath77 for @xmath200 and @xmath201 , while for @xmath198 and @xmath199 the signal bits seem to be `` scrambled '' enough in the parity checks for the correlations to be insignificant .",
    "note that this argument does not hold for gallager codes and mn codes with biased messages , where the parity check bits exclusively comprise biased bits , and are therefore biased themselves .",
    "they only become unbiased as @xmath203 for gallager codes ( for which it was already reported in the literature @xcite that such codes can saturate shannon s bound ) , and for @xmath203 or @xmath204 for mn codes .",
    "in fact , numerical analysis reveals that for @xmath198 and for @xmath199 we have that @xmath205 , @xmath206 , @xmath207 at least up to @xmath208 which is independent of @xmath8 .",
    "this allows us to calculate @xmath0 analytically from expression ( [ qq_m ] ) , and we recover , as expected , the exact expression ( [ mns ] ) .    for @xmath200 or @xmath201 , like in the case of gallager codes",
    ", one can only obtain @xmath209 numerically .",
    "the results of this procedure are presented in the next section .",
    "furthermore , for @xmath200 and for @xmath201 , we find that spontaneously @xmath210 for some values of @xmath211 , when no restriction is enforced ( i.e. for @xmath212 ) .",
    "this implies that one may improve the decoding performance by imposing the condition of unbiased signal ( similar to the conditions for typical set decoding ) , i.e. by adjusting the lagrange multiplier @xmath213 such that @xmath214 .",
    "unfortunately , this only happens for values of @xmath8 for which there is an exponential number of sub - optimal solutions @xmath215 with the same weight as @xmath49 , and imposing this constraint on the signal estimator only reduces this number , leaving it nevertheless , exponential .",
    "it was shown  @xcite that mn codes in principle contain sufficient information to saturate shannon s bound for unbiased messages . for codes with @xmath200 , or @xmath201 , some of this information",
    "is wasted in a region where errorless decoding is impossible anyway , such that shannon s bound is not saturated . for codes with @xmath198 , or @xmath199",
    ", our analysis indicates that all information is used optimally , and that shannon s bound can be theoretically saturated .",
    "our argument also explains the relative importance of the parameters @xmath14 and @xmath38 for the behaviour of the code in comparison with @xmath15 .",
    "some general comments can be made about the critical map ( or typical set ) values obtained via the annealed and quenched calculations . since @xmath216 ( for given values of @xmath14 , @xmath15 ( @xmath38 ) and @xmath8 ) , we can derive the general inequality @xmath217 . for all @xmath14 , @xmath15 ( @xmath38 ) values that we have numerically analyzed , for both annealed and quenched cases",
    ", @xmath153 is a non increasing function of @xmath8 , and @xmath156 is unique .",
    "the estimates of the critical noise levels @xmath218 , based on @xmath219 , are obtained by numerically calculating @xmath220 , and by determining their intersection with @xmath180 .",
    "this is explained graphically in fig.[fig:2](a ) .",
    "( 140,60 ) ( - 9 , 0)=60 ( -10 , 55 ) ( - 3 , 48 ) ( 2 , 54 ) ( 2 , 6 ) ( 75 , 7 ) ( 20 , 7 ) ( 32 , 7 ) ( 60 , 1 ) ( 62 , 27 ) ( 62 , 20 ) ( 55 , 6 )    ( -43,55 ) ( -35,30 )    [ cols=\"^,^,^,^,^\",options=\"header \" , ]",
    "in this paper we have shown how both weight and magnetization enumerators can be calculated using the methods of statistical physics in the case of regular ldpc codes .",
    "we study the role played by the _ magnetization enumerator _ @xmath77 in determining the achievable critical noise level for various decoding schemes .",
    "the formalism based on the magnetization enumerator @xmath0 offers a intuitively simple alternative to the weight enumerator formalism used in conjunction with typical pairs decoding in the it literature  @xcite .",
    "the sp based analysis employes the replica method given the very low critical values obtained by the annealed approximation calculation .",
    "furthermore , the powerfull gauge theory as proposed by nishimori  @xcite , proves that the replica symmetric assumption is correct ( at least at the critical noise level ) , and thus that the critical noise levels as obtained by our method are _",
    "exact_. although we have concentrated here on the critical noise level for the bsc , other channel types as well as other quantities of interest can be treated using a similar formalism .",
    "the predictions for the critical noise level are more optimistic than those reported in the it literature , and are up to numerical precision in agreement with those reported in  @xcite .",
    "we have also shown that the critical noise levels for typical pairs , map and mpm decoding must coincide , and we have provided an intuitive explanation to the difference between map and mpm decoding . finally , an extension of this analysis to mn codes reveals the mechanism which allows them to saturate shannon s limit for finite @xmath198 and for @xmath199 values ( if impractical algorithms such as maximum likelihood are used ) .",
    "this result , which is consistent with previous sp based analyses @xcite is considered as surprising in the it community",
    ".        0 c.e .",
    "shannon , bell sys .  tech .",
    "j. * 27 * 379 , 623 ( 1948 ) .",
    "a.j  viterbi and j.k .",
    "omura , principles of digital communication and coding mcgraw - hill book co. , singapore ( 1979 ) .",
    "s.  aji , h.  jin , a.  khandekar , d.j.c .  mackay and r.j .",
    "mceliece , in marcus , b. , rosenthal , j. ( eds ) : codes , systems and graphical models .",
    "springer verlag , new york , 195 ( 2001 ) .",
    "gallager , ire trans .",
    "theory * 8 * 21 ( 1962 ) .",
    "mackay , ieee trans .  on it",
    "* 45 * 399 ( 1999 )",
    ". t.  richardson , a.   shokrollahi , r.  urbanke , ieee trans .  on it *",
    "47 * 619 ( 2001 ) .",
    "m.  mezard , g.  parisi and m.a .",
    "virasoro , spin glass theory and beyond , world scientific publishing co. , singapore ( 1987 ) .",
    "h.  nishimori , statistical physics of spin glasses and information processing , oxford university press , oxford uk ( 2001 ) .",
    "y.  kabashima , t.  murayama and d.  saad , phys .",
    ", * 84 * , 1355 ( 2000 ) ; y.  kabashima , t.  murayama , d.  saad and r.  vincente , phys .  rev .",
    "e , * 62 * 1577 ( 2000 ) .",
    "r.  vicente , d.  saad and y.  kabashima , low density parity check codes : a statistical physics perspective in _ advances in imaging and electron physics _ , editor p.  hawkes , academic press , ny , in press ( 2002 ) .",
    "r.  vicente , d.  saad and y.  kabashima , europhys .  lett . * 51 * 698 ( 2000 ) .",
    "a.  montanari , eur .",
    "j.  b , * 23 * 121 ( 2001 )",
    ".    r.g .",
    "gallager , information theory and reliable communication , weily & sons , new york ( 1968 ) .",
    "y.  kabashima , n.  sazuka , k.  nakamura and d.  saad phys .",
    "e * 64 * art .",
    "046113 , ( 2001 ) m.  opper and d.  saad , advanced mean field methods - theory and practice , mit press , cambridge ma ( 2001 ) .",
    "y.  iba , jour .",
    "a * 32 * 3875 ( 1999 ) .",
    "mackay , on thresholds of codes , http://wol.ra.phy.cam.ac.uk/mackay/codestheory.html unpublished ( 2000 ) .",
    "y  kabashima , k.  nakamura , j.  van  mourik , statistical mechanics of typical set decoding : cond - mat/0106323 unpublished ( 2001 ) ."
  ],
  "abstract_text": [
    "<S> we determine the critical noise level for decoding low density parity check error correcting codes based on the magnetization enumerator ( @xmath0 ) , rather than on the weight enumerator ( @xmath1 ) employed in the information theory literature . </S>",
    "<S> the interpretation of our method is appealingly simple , and the relation between the different decoding schemes such as typical pairs decoding , map , and finite temperature decoding ( mpm ) becomes clear . </S>",
    "<S> in addition , our analysis provides an explanation for the difference in performance between mn and gallager codes . </S>",
    "<S> our results are more optimistic than those derived via the methods of information theory and are in excellent agreement with recent results from another statistical physics approach . </S>"
  ]
}