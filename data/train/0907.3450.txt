{
  "article_text": [
    "routines were written for the calculation of frequentist confidence intervals using the profile likelihood method .",
    "the package provides routines for the calculation of upper and lower limits , average limits ( sensitivity ) and related properties , taking uncertainties in background estimate and signal efficiency into account .",
    "the implementation considers seven different statistical models with different combinations of binomial , gaussian , poissonian or no uncertainties .",
    "for example in the gaussian background case , our package derives upper and lower limits on the signal strength for a poisson process with gaussian background expectation @xmath2 .",
    "it is also possible to construct hypothesis tests which take uncertainties into account .",
    "the statistical problems are treated using the @xmath3 .",
    "the package provides a @xmath4 class with accompanying examples .",
    "it can be used in compiled code , interactively via the root @xcite analysis framework , and from python .",
    "this is trolke version 2.0 .",
    "it adds to version 1 ( implemented in fortran and in c++ ) : hypothesis tests , a reworked user interface , documentation , examples and python support .",
    "this paper is organized as follows .",
    "first , the profile likelihood methods is summarized , section [ pfmethod ] ; second , it is shown how our routines can be used for optimization of statistical discovery or limit setting power , section [ optimization ] .",
    "the means for specification of the statistical model , and in general the class interface are described in section [ classdoc ] .",
    "frequentist limits are constructed from data such that when repeated with new data the limits _ cover _ the fixed but unknown parameter value @xmath5 with a frequency which converges to the requested probability , the confidence level @xmath6 .",
    "limit calculation methods are often based on the inversion of an hypothesis test , as described in e.g. @xcite@xcite@xcite , and we follow the same scheme .",
    "classical hypothesis tests investigate the validity of a default hypothesis , the _ null hypothesis _",
    "@xmath7 ; that an examined sample of data is compatible with background and we call the complementary hypothesis @xmath8 a _ discovery_. the profile likelihood method is based on the likelihood ratio tests statistic now described . for some observable @xmath9 , let us assume a probability density function @xmath10 depending on @xmath11 parameters @xmath12 of interest to the researcher ( such as the strengths of different signal sources ) , and @xmath13 additional nuisance parameters @xmath14 ( such as the strength of different background sources ) . for a set of @xmath15 independent observations @xmath16 the likelihood is @xmath17    the likelihood ratio test statistic is defined as @xmath18 where the denominator is the likelihood maximized over the whole @xmath19 space , while the nominator is maximized over the more restrictive null hypothesis space @xmath20 .",
    "the likelihood ratio @xmath21 is also known as the _ profile likelihood _ and is a stochastic function explicitly depending on the data ( and the null hypothesis ) but not the nuisance parameters .",
    "in general the inversion of a test to find the confidence region requires scanning over all possible signals , as described for example in @xcite . our routines instead make use of a very powerful result from mathematical statistics , that under some general conditions the distribution of @xmath22 converges to a chi - square distribution with @xmath11 degrees of freedom .",
    "although these conditions are not satisfied in the problem considered here it has been shown that its performance is surprisingly good , especially when , as here , nuisance parameters are included .",
    "the statistical performance of the profile likelihood method is studied in ref.@xcite .",
    "in this section we describe how our routines are used for optimization of analysis cuts , with the figure of merit being either stringent limits ( in case the signal is expected to be weak ) , or probability for discovery ( if the signal is expected to be strong ) .",
    "[ optimization ]      when a signal is expected to be weak enough so that significant discovery is unlikely , it is relevant to optimize the analysis for optimal limit setting power .",
    "this can be done by assuming no signal and minimizing the so - called _",
    "sensitivity_. for example with a 90% confidence level ( that is , @xmath2310% ) , let us denote a calculated upper limit @xmath24 .",
    "the sensitivity of the experiment is defined as the average upper limit in case of vanishing signal ; @xmath25 where @xmath26 is the poisson probability of observing @xmath27 events for background expectation @xmath28 , in absence of signal . for finding",
    "the optimal analysis cut we can assume without loss of generality that the background and signal expectations are monotonically decreasing functions of a cut @xmath29 : @xmath30 , and @xmath31 .",
    "the constant @xmath32 is the assumed normalisation of the signal at some arbitrary `` no cut '' level so that all uncertainties in the signal rate expectation are attributed to the signal detection efficiency @xmath33 .    as an example , let s consider an energy dependent spectrum of particles probed by a particle detector .",
    "for the physical _ test spectrum _ @xmath34 the expected number of observed signal events is @xmath35 the cross section @xmath36 determines the detection efficiency which is now a function of the energy @xmath37 , and @xmath38 is the exposure time . for the observation of @xmath27 events the _ model rejection factor _",
    "@xmath39 is defined as @xmath40 the upper limit can be written in terms of the test signal @xmath41 and the average limit on the signal strength , set by repeated independent experiments in case of vanishing signal is @xmath42 where @xmath43 is called the _ model rejection potential_.    our package provides @xmath44 through the method , and the upper limit @xmath24 ( and the lower limits ) through , where @xmath45 indicates a double precision value .      in order to reject @xmath7 with significance @xmath46 , the number of observed events @xmath47 must be equal to or higher than a _",
    "critical number _",
    "@xmath48 , where @xmath28 is the background expectation .",
    "the significance @xmath46 is the probability of observing @xmath49 or more events from a stochastic background with mean @xmath28 assuming vanishing signal .",
    "the part of sample space rejecting @xmath7 is called the _ critical region _ , while its complement is called the _ acceptance region_. in the constructed test the critical region is completely defined by @xmath49 .",
    "if the background expectation @xmath28 was completely known , we could find @xmath49 by solving @xmath50 where @xmath51 is the poisson distribution , but in general the background expectation is unknown and so we find the critical value by inverting the profile likelihood method . remembering that confidence regions are constructed such that the true but unknown signal strength @xmath52 is outside the confidence region with probability @xmath46 for any fixed @xmath52 we assume the hypothesis @xmath7 which means @xmath53 .",
    "the critical region is therefore defined as the subset of values @xmath27 which gives rise to limits not covering @xmath53 .",
    "that is , @xmath7 is rejected for observations that lead to lower limits @xmath54 larger than zero .",
    "the limits are monotonic in @xmath27 , so the hypothesis test is completely characterised by a critical number @xmath55 , and written @xmath56 .",
    "this critical number algorithm is implemented as the method .      assuming a specific signal strength @xmath57 , it is relevant to consider the probability of making a discovery .",
    "this is given by the _ power _ of the hypothesis test , @xmath58 .",
    "a signal hypothesis @xmath59 is said to be at the _ visibility threshold _ if it leads to a discovery with a pre - specified probability @xmath60 , for example 50% .",
    "discovery is claimed when @xmath61 , so in order to minimise the visibility threshold , signal is added to the ( background ) expectation until the probability for @xmath62 is at least @xmath60 .    for the case of vanishing uncertainties",
    ", the visibility threshold can be directly calculated@xcite from the poisson distribution by finding the smallest signal @xmath63 fulfilling @xmath64 or equivalently @xmath65 , where the critical value @xmath66 is that found using equation [ directp ] .",
    "the quantity @xmath63 is the visibility threshold for the signal expectation in case of vanishing uncertainties .",
    "the construction is shown in figure  [ discpic ] .",
    "[ optimdisc ] [ discoverexpl ]    , the visibility threshold @xmath67 is the smallest signal that is discovered with at least probability @xmath68 at significance @xmath46 . in this example , @xmath69.[discpic],title=\"fig:\",scaledwidth=80.0% ] +    uncertainties are accounted for through the critical number @xmath70 as function of significance and expectation number .",
    "a method similar to this has previously been described by punzi@xcite . as in equation",
    "[ simplecrit ] , signal is added to the ( background ) expectation until the probability for rejection of @xmath7 is at least @xmath60 .",
    "this means    @xmath71    where @xmath72 and @xmath73 represent the total uncertainties of background , and background plus signal respectively .",
    "equation [ critequ ] is solved numerically by finding the smallest allowed signal expectation @xmath74 and the solution is called @xmath67 . since the tested hypothesis @xmath7 assumes exactly @xmath53 , we do not include any uncertainty in the signal efficiency , while here the background estimate is assumed gaussian . the described procedure for finding the critical number in the presence of uncertainties is thus a function on the form @xmath75 , where @xmath72 is the background uncertainty .",
    "assuming that the uncertainties of signal efficiency and the background estimate are sufficiently uncorrelated and gaussian ( or exact ) , equation [ critequ ] becomes @xmath76    for the observation of @xmath27 events the _ model rejection factor _",
    "@xmath39 is defined as @xmath77 where @xmath78 is , as in section [ optimdisc ] , the expectation number of signal events for an assumed test signal .",
    "the optimal cut @xmath29 and the corresponding critical number @xmath55 is found by minimising the signal strength @xmath79 as function of the cut @xmath29 .",
    "the visibility threshold for the expected number of observed signal events for a fixed cut @xmath29 is @xmath80 the physical threshold signal strength is found in terms of the test spectrum ( in analogy with equation [ mrfanalogy ] ) by @xmath81 , or equivalently @xmath82 where @xmath83 is the _ model detection potential_. minimizing @xmath84 optimizes the analysis such that the signal strength required for detection ( with at least probability @xmath85 ) is minimized .",
    "our code provides the critical number and the @xmath67 through and .",
    "[ optimsection ] [ lundbergstat ]",
    "the library allows seven combinations of efficiency and background rate models , each presented here .",
    "once the model and its parameters are specified , the user can obtain limits , critical numbers and so on as explained in the subsequent sections .",
    "this model implements the case of gaussian background with expectation @xmath86 and standard deviation @xmath87 and gaussian efficiency with expectation @xmath88 and standard deviation @xmath89 .",
    "the integer @xmath27 is the number of observed events .",
    "this model implements the case of known background expectation @xmath28 and binomial signal efficiency .",
    "the integer @xmath91 is the number of observed events ( in the signal region ) out of the @xmath92 evaluated signal ( monte carlo ) events .",
    "the integer @xmath27 is the number of observed events .",
    "[ setpoissonbkgknowneff ] the background is either measured simultaneously with signal , from sidebands , or with separate background monte carlo .",
    "the real value @xmath93 is the size of the background region in terms of the size of the background regions .",
    "it can be used in two ways - either it s the ratio between the size of the background and the signal regions in case background is observed ( from sidebands ) , or in case background is determined from simulations ; the ratio between simulated and observed exposure time .",
    "the background in the signal region is estimated from @xmath93 and the integer @xmath94 , the number of observed events in background region .",
    "the integer @xmath27 is the number of observed events ; as always in the signal region .",
    "this model implements the case of binomial signal efficiency and poissonian background estimate . for an explanation of binomial efficiencies",
    ", please refer to section [ setknownbkgbinomeff ] , and for poissonian backgrounds to section [ setpoissonbkgknowneff ] .",
    "the integer @xmath27 is the number of observed events .",
    "this model implements the case of gaussian signal efficiency and poissonian background estimate . for an explanation of binomial efficiency",
    ", please refer to [ setpoissonbkgbinomeff ] , and for poissonian backgrounds to section [ setknownbkgbinomeff ] .",
    "the integer @xmath27 is the number of observed events .",
    "two options are offered to deal with cases where the maximum likelihood estimate ( mle ) is not in the physical region .",
    "bounding is controled with the method .",
    "the `` bounded likelihood '' option corresponds to the `` bounds for the physical region '' option in minuit / minos@xcite@xcite .",
    "unbounded likelihood allows the maximum likelihood estimate to be in the unphysical region .",
    "it has better coverage@xcite and is used by default .",
    "the latest versions of the code , its documentation and examples are freely available@xcite .",
    "the class makes use of a number of root @xcite routines for standard mathematical functions , the interactive interface and bindings which makes it easy to use our methods in python .",
    "examples of all functionality of the c++ class are included in our code and demonstrate its use with python , as interactive c++ , and as a compiled example program .",
    "g.  j.  feldman and r.  d.  cousins , phys .",
    "d * 57 * ( 1998 ) 3873 [ arxiv : physics/9711021 ] .",
    "a.  stuart and j.  k.  ord : kendall s advanced theory of statistics , vol .",
    "2 , classical inference and relationship , oxford university press , new york ( 1991 ) ."
  ],
  "abstract_text": [
    "<S> a c++ class was written for the calculation of frequentist confidence intervals using the profile likelihood method . </S>",
    "<S> seven combinations of binomial , gaussian , poissonian and binomial uncertainties are implemented . </S>",
    "<S> the package provides routines for the calculation of upper and lower limits , sensitivity and related properties . </S>",
    "<S> it also supports hypothesis tests which take uncertainties into account . </S>",
    "<S> it can be used in compiled c++ code , in python or interactively via the root analysis framework .    ,    ,    ,    confidence intervals , hypothesis tests , systematic uncertainties , poisson statistics 06.20.dk .    </S>",
    "<S> [ ]    * _ title of program : _ trolke version 2.0 * _ program available from : _ cpc program library , ... * _ licensing provisions : _ mit license * _ computer for which the program is designed : _ unix , gnu / linux , mac * _ operating systems under which the program has been tested : _ linux 2.6 ( scientific linux 4 and 5 , ubuntu 8.10 ) , darwin 9.0 ( mac - os x 10.5.8 ) * _ programming language used : _ iso c++ * _ memory required to execute with typical data : _ @xmath0 20 mb , * _ no . </S>",
    "<S> of bytes in distributed program , including initialization file , etc .. _ 1 mb * _ distribution format : _ tar file * _ keywords : _ confidence interval calculation , systematic uncertainties , profile likelihood * _ nature of the physical problem : _ the problem is to calculate a frequentist confidence interval on the parameter of a poisson process with statistical or systematic uncertainties in signal efficiency or background . * </S>",
    "<S> _ method of solution : _ profile likelihood method , analytical * _ typical running time : _ </S>",
    "<S> @xmath1 seconds per extracted limit . </S>"
  ]
}