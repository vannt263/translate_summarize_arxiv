{
  "article_text": [
    "controling decoherence is one of the key problems for making quantum information processing and quantum computation work . from the outset , when peter shor announced his algorithm @xcite , many physicists felt that somewhere there would be a price to pay for the miraculous exponential speedup .",
    "for example , if the algorithm would require exponentially good adherence to specifications for the quantum circuitry and exponentially low noise levels , it would have been totally useless .",
    "indeed it is far from easy to show that it does not make such requirements .    in this article",
    "we look at the simpler , but equally fundamental problem of quantum information transmission or storage .",
    "is it possible to encode the quantum data in such a way that even after some degradation they can be restored nearly perfectly by a suitable decoding operation ?",
    "assuming that the degrading decoherence effects are small to begin with , can restoration be made nearly perfect ?    for classical information",
    "it is very simple to do this , namely by redundant coding .",
    "if we want to send one bit through a noisy channel , we can reduce errors by sending it three times and deciding by majority vote which value we take at the output . clearly ,",
    "if errors have a small probability @xmath1 for a single channel , they will have order @xmath2 for the triple channel , because we go wrong only when two independent errors occur .",
    "unfortunately , such a scheme can not work in the quantum case because it involves a copying operation , which is forbidden by the no - cloning theorem @xcite .",
    "so we have to look for subtler ways of distributing quantum information among several systems and thereby reducing the probability of errors .",
    "indeed such schemes exist @xcite and are the subject of the exciting new field of quantum error correcting codes .",
    "the efficiency of such a scheme is measured by two parameters , namely how many uses of the noisy channel are required , and the error level after correction .",
    "the above simple classical scheme can be iterated to get the errors for a single bit down to @xmath3 with @xmath4 parallel uses of the channel .",
    "this is a large overhead to correct a single bit .",
    "better procedures work classically by coding several bits at a time , and one can manage to make errors as small as desired with only a finite overhead per bit .",
    "the minimal required overhead ( or rather its inverse ) is , in fact , the central quantity of the coding theory @xcite for noisy channels : one defines the _ capacity _ of a channel as the number of bit transmissions per use of the channel , in an optimal coding scheme for messages of length @xmath5 with the property that the error probability goes to zero in this limit .",
    "it is not a priori clear that the notion of channel capacity makes sense for quantum information , i.e. that the capacity of a channel which produces only small errors is nonzero and close to that of the ideal ( errorless ) channel .",
    "this is indeed not even evident from most existing presentations of the theory of quantum error correcting codes .",
    "papers which address this problem at least for special cases like depolarizing channels are @xcite and ( * ? ? ?",
    "* sec 7.16.2 ) while the general case is treated more recently in @xcite .",
    "the purpose of this paper is less the presentation of new results but to show in an elementary and self - contained way that small quantum errors can be corrected with an asymptotically small effort . to this",
    "end the paper is organized as follows .",
    "we first review the basic notions concerning quantum channels ( section [ sec : quantum - channels ] ) , and give an abstract definition of the capacity together with some elementary properties ( section [ sec : channel - capacities ] ) .",
    "then we discuss the theory of error correcting codes ( section [ sec : quant - error - corr ] ) and a particular scheme to construct such codes which is based on graph theory ( section [ sec : graph - codes ] ) . in section",
    "[ sec : discr - cont - error ] and [ sec : coding - random - graphs ] we apply this scheme to channel capacities and finally we draw our conclusions in section [ sec : conclusions ] .",
    "according to the rules of quantum mechanics , every kind of quantum systems is associated with a hilbert space @xmath6 , which for the purpose of this article we can take as finite dimensional . since even elementary particles require infinite dimensional hilbert spaces , this means that we are usually only trying to coherently manipulate a small part of the system .",
    "the simplest quantum system has a two dimensional hilbert space @xmath7 , and is called a _ qubit _ , for ` quantum bit ' .",
    "the observables of the system are given by bounded operators .",
    "this space will be denoted by @xmath8 .",
    "the preparations ( states ) are given by density operators @xmath9 , where the latter denotes the space of trace class operators on @xmath10 .",
    "of course , on finite dimensional hilbert spaces all linear operators are bounded _ and _ trace class .",
    "so we use this notation mostly to keep track of the distinction between spaces of observables and spaces of states .",
    "a _ quantum channel _ , which transforms input systems described by a hilbert space @xmath11 into output systems described by a ( possibly different ) hilbert space @xmath12 is represented mathematically by a _ completely positive , unital map _ @xmath13 .",
    "each @xmath0 can be written in the form @xcite @xmath14 where the @xmath15 are ( bounded ) operators @xmath16 , called _",
    "kraus operators_. the equivalence of this form to the condition of complete positivity is a simple consequence of the stinespring theorem @xcite .",
    "the physical interpretation of @xmath0 is the following .",
    "the expectation value of an @xmath17 measurement ( @xmath18 ) at the output side of the channel , on a system which is initially in the state @xmath19 is given in terms of @xmath0 by @xmath20 $ ] .",
    "alternatively we can introduce the map @xmath21 which is _ dual _ to @xmath0 , i.e. @xmath22 = { \\operatorname{tr}}[\\rho t(a)]$ ] .",
    "it is uniquely determined by @xmath0 ( and vice versa ) and we can say that @xmath23 represents the channel in the _ schrdinger picture _ , while @xmath0 provides the _ heisenberg picture _ representation .    let us consider now the special case that @xmath24 . for example @xmath0 describes the transmission of photons through an optical fiber or the storage in some sort of quantum memory . ideally we would prefer channels which do not affect the information at all , i.e. @xmath25 , the identity map on @xmath8 . we will call this case the",
    "_ ideal channel_. in real situations , however , interaction with the environment , i.e. additional , unobservable degrees of freedom , can not be avoided .",
    "the general structure of such a _ noisy channel _ is given by @xmath26 where @xmath27 is a unitary operator describing the common evolution of the system ( hilbert space @xmath6 ) and the environment ( hilbert space @xmath28 ) and @xmath29 is the initial state of the environment ( cf .",
    "figure [ fig : noisy - channel ] ) . note that each @xmath0 can be represented in this way ( this is again an easy consequence of the stinespring theorem ) ,",
    "however there are in general many possible choices for such an `` ancilla representation '' .    1    ( 16,6 ) ( -0.5,0 ) ( 4,0)(12,6 ) ( 7.5,1)(9.5,5 ) ( 2,4)(7.5,4 ) ( 9.5,4)(14,4 ) ( 5,2)0.5 ( 5,2)a ( 5.5,2)(7.5,2 ) ( 9.5,2)(11.5,2 ) ( 8.5,3 ) ( 1.9,4)@xmath30 ( 14.1,4)@xmath31",
    "as we have already pointed out in the introduction , the _ capacity _ of a quantum channel is , roughly speaking , the number of qubits transmitted per channel usage . in this section",
    "we will come to a more precise description .      as a first step we need a measure for the difference between a noisy channel @xmath32 and its ideal counterpart .",
    "there are several mathematical ways of expressing this , which turn out to be equivalent for our purpose .",
    "we find it most convenient to take a certain norm difference , i.e. , to consider @xmath33 as a quantitative description of the noise level in @xmath0 , where @xmath34 denotes a certain norm , called the norm of _ complete boundedness _",
    "( `` cb - norm '' for short ) .",
    "its physical meaning is that of the largest difference between probabilities measured in two experimental setups , differing only by the substitution of @xmath0 by @xmath35 .",
    "since this setup may involve further subsystems , and the measurement and preparation may be entangled with the systems under consideration , we have to take into account such additional systems in the definition of the norm . for a general linear operator @xmath36 we set @xmath37",
    "the cb - norm improves the sometimes annoying property of the usual operator norm that quantities like @xmath38 may increase with the dimension @xmath39 . on infinite dimensional hilbert spaces @xmath40 can be infinite although the supremum for every fixed @xmath41 is finite .",
    "a particular example for a map with such a behavior is the transposition .",
    "a map with finite cb - norm is therefore called completely bounded . in a finite dimensional setup",
    "each linear map is completely bounded . for the transposition @xmath42 on @xmath43",
    "we have in particular @xmath44 .",
    "the cb - norm has some nice features which we will use frequently .",
    "this includes its multiplicativity @xmath45 and the fact that @xmath46 for every channel . for more properties of the cb - norm",
    "we refer to @xcite .",
    "how can we reduce the error level @xmath33 ? as an example , consider a small unitary rotation , i.e. , @xmath47 , with @xmath48 small .",
    "then if we know @xmath49 , it is easy to correct @xmath0 by the inverse rotation , either before @xmath0 , as an `` encoding '' , or afterwards , as a `` decoding '' operation .",
    "more generally , we may use both , i.e. , we are trying to make the combination @xmath50 , by careful choice of the channels @xmath51 and @xmath52 . note that in this way we may look at channels @xmath0 , which have different input and output spaces , and hence can not be compared directly with the ideal channel on any system .",
    "for such channels there is no intrinsic way of defining `` errors '' as deviations from a desired standard .",
    "moreover , we are free to choose the hilbert space @xmath53 such that @xmath54 . for the product @xmath55 to be defined , it is then necessary that @xmath56 and @xmath57 .",
    "the best error level we can achieve deserves its own notation .",
    "we define @xmath58 where the infimum is taken over all encodings @xmath51 and decodings @xmath52 and @xmath59 is the dimension of the space @xmath53 . now for longer messages , e.g. , a message of @xmath60 qubits ( so that @xmath61 ) we need to use the channel more often . in the language of classical information theory , we are using longer code words , say of length @xmath41 . the error for coding @xmath60 qubits through @xmath41 uses of the channel @xmath0",
    "is then @xmath62",
    ". can we make this small while retaining a good rate @xmath63 of bits per channel ?",
    "clearly there will be a trade - off between rate and errors , which is the basis of the following definition .",
    "the notation @xmath64 , read `` floor @xmath65 '' , denotes the largest integer @xmath66 .",
    "[ def:1 ] @xmath67 is called _ achievable rate _ for @xmath0 , if @xmath68 the supremum of all achievable rates is called the _ quantum - capacity _ of @xmath0 and is denoted by @xmath69 .    because @xmath70 is always an achievable rate we have @xmath71 . on the other hand ,",
    "if every @xmath72 is achievable we write @xmath73 .",
    "often a coding scheme construction does not work for arbitrary integers , but only for specific values of @xmath41 , or the dimension of the coding space . however , this is no serious restriction , as the following lemma shows .",
    "[ lem:1 ] let @xmath74 be a strictly increasing sequence of integers such that @xmath75 .",
    "suppose @xmath76 are integers such that @xmath77 .",
    "then any @xmath78 is an admissible rate .",
    "moreover , if the errors decrease exponentially , in the sense that @xmath79 ( @xmath80 ) , then they decrease exponentially for all @xmath41 with rate @xmath81    let us introduce the notation @xmath82 , so @xmath83 .",
    "we pick @xmath84 such that @xmath85 .",
    "then for sufficiently large @xmath86 we have @xmath87 , and @xmath88 .",
    "now let @xmath89 , and consider the unique index @xmath90 such that @xmath91 .",
    "then @xmath92 and @xmath93 clearly , @xmath94 decreases as @xmath41 increases , because good coding becomes easier if we have more parallel channels and increases with @xmath59 , because if a coding scheme works for an input hilbert space @xmath53 , it also works at least as well for states supported on a lower dimensional subspace .",
    "hence @xmath95 .",
    "it follows that @xmath96 is an admissible rate .    with the exponential bound on @xmath97",
    "we find similarly that @xmath98 so that the liminf in ( [ gaprate ] ) is @xmath99 .",
    "since @xmath100 was arbitrary , we get the desired result .      to determine @xmath69 in terms of definition [ def:1 ] is fairly difficult , because optimization problems in spaces of exponentially fast growing dimensions are involved .",
    "this renders in particular each direct numerical approach practically impossible . in the classical situation ,",
    "i.e. if we transfer classical information through a classical channel @xmath101 , we can define a capacity quantity @xmath102 in the same way as above .",
    "an explicit calculation of @xmath102 , however , can be reduced , according to shannons `` noisy channel coding theorem '' @xcite , to an optimization problem over a low dimensional space , which does not involve the limit of inifinitely many parallel channels .",
    "a similar coding theorem for the quantum case is not yet known  this is the biggest open problem concerning channel capacities .",
    "nevertheless , there are some special cases in which the capacity can be computed explicity .",
    "the most relevant example is the ideal channel @xmath103 .",
    "if @xmath104 we can embed @xmath105 into @xmath106 , hence @xmath107 and we see that the rate @xmath108 can be achieved .",
    "intuitively we expect that this is the best what can be done , because it is impossible to embed a high- into a low - dimensional space .",
    "this intuition is in fact correct , i.e. we have @xmath109 for the ideal channel .",
    "a precise proof of this statement is , however , not so easy as it looks like and we skip the details here .",
    "maybe the most easy approach is to use the quantity @xmath110 ( where @xmath42 denotes the transposition ) , which is an upper bound on @xmath69 ( cf .",
    "@xcite or @xcite ) .",
    "the same idea can be used to show that the quantum capacity of a classical channel , or more generally a channel @xmath0 which uses classical information at an intermediate step , is zero .",
    "this is a reformulation of the `` no classical teleportation theorem '' ( cf . again",
    "@xcite ) .",
    "another useful relation concerns the concatenation of two general channels @xmath111 and @xmath112 : we transmit quantum information first through @xmath111 and then through @xmath112 .",
    "it is reasonable to assume that the capacity of the composition @xmath113 can not be bigger than the capacity of the channel with the smallest bandwidth .",
    "this conjecture is indeed true and known as the `` _ _ bottleneck inequality _ _ '' : @xmath114 alternatively we can use the two channels in parallel , i.e. we consider the tensor product @xmath115 . in this case the capacity of the resulting channel is at least as big as the sum of @xmath116 and @xmath117 , i.e. @xmath118 is _ superadditive _ : @xmath119 ( cf .",
    "@xcite for a proof of both statements ) . to decide whether @xmath118 is even additive , i.e. whether equality holds in ( [ eq:10 ] ) , is another big open question about channel capacities .",
    "the definition of capacity requires that we correct errors in a collection of @xmath41 parallel channels @xmath120 . here",
    "the tensor product means that successive uses of the channel are independent .",
    "for example , the physical system used as a carrier is freshly prepared every time we use the channel .",
    "this independence is important for error correcting schemes , because it prevents errors happening on different channels to `` conspire '' .",
    "suggestive as it may be , quantum mechanics cautions us to be very careful with this sort of language : just as we can not assign trajectories to quantum systems , it is problematic to speak about errors ` happening ' in one channel , in a situation where we must expect different classical pictures to ` occur ' in quantum mechanical superposition .",
    "this is to be kept in mind , when we now describe the theory of quantum error correcting codes in the sense of knill and laflamme @xcite , which is very much based on a classification of errors according the place where they occur .",
    "for example , the coding / decoding pair @xmath121 will typically have the property that @xmath122 , whenever the number of positions at which @xmath123 , i.e. , the number of errors , is small ( cf .",
    "figure [ fig : five - bit - code ] ) .    1    ( 15,6 ) ( 3,0)(5,6 ) ( 7,0.5)(8,5.5 ) ( 7,1.5)(8,1.5 ) ( 7,2.5)(8,2.5 ) ( 7,3.5)(8,3.5 ) ( 7,4.5)(8,4.5 ) ( 10,0)(12,6 ) ( 1,3)(3,3 ) ( 12,3)(14,3 ) ( 5,1)(7,1 ) ( 5,2)(7,2 ) ( 5,3)(7,3 ) ( 5,4)(7,4 ) ( 5,5)(7,5 ) ( 8,1)(10,1 ) ( 8,2)(10,2 ) ( 8,3)(10,3 ) ( 8,4)(10,4 ) ( 8,5)(10,5 ) ( 4,3 ) ( 11,3 ) ( 7.5,1)@xmath124 ( 7.5,2)@xmath124 ( 7.5,3)@xmath124 ( 7.5,4)@xmath124 ( 7.5,5)@xmath0 ( 2,3.2)@xmath30 ( 13,3.2)@xmath30    in our presentation of the knill - laflamme theory , we start from the error corrector s dream , namely the situation in which _ all the errors happen in another part of the system _ , where we do not keep any of the precious quantum information .",
    "this will help us to characterize the structure of the kind of errors which such a scheme may tolerate , or ` correct ' .",
    "of course , the dream is just a dream for the situation we are interested in : several parallel channels , each of which may be affected by errors .",
    "but the splitting of the system into subsystems , mathematically the decomposition of the hilbert space of the total system into a tensor product is something we may change by a suitable unitary transformation .",
    "this is then precisely the role of the encoding and decoding operations .",
    "the knill - laflamme theory is precisely the description of the situation where such a unitary , and hence a coding / decoding scheme exists .",
    "constructing such schemes , however , is another matter , to which we will turn in the next section .",
    "so consider a system split into @xmath125 , where the indices @xmath126 and @xmath127 stand for ` good ' and ` bad ' .",
    "we prepare the system in a state @xmath128 , where @xmath30 is the quantum state we want to protect .",
    "now come the errors in the form of a completely positive map @xmath129 . then according to the error corrector s dream",
    ", we would just have to discard the bad system , and get the same state @xmath30 as before .",
    "the hardest demands for realizing this come from pure states @xmath130 , because the only way that the restriction to the good system can again be @xmath131 is that the state after errors factorizes , i.e. @xmath132 this requires that @xmath133 where @xmath134 is some vector , which must be independent of @xmath135 if such an equation is to hold for all @xmath136 .",
    "conversely , condition ( [ fidream ] ) implies ( [ facterror ] ) for every pure state @xmath131 and , by convex combination , for every state @xmath30 .",
    "two remarks are in order .",
    "firstly , we have _ not _ required that @xmath137 .",
    "this would be equivalent to demanding that this scheme works with every @xmath138 , or indeed with every ( possibly mixed ) initial state of the bad system",
    ". this would be much too strong for a useful theory of codes .",
    "so later on we must insist on a proper initialization of the bad subsystem by a suitable encoding .",
    "secondly , if we have the condition ( [ fidream ] ) for the kraus operators of some channel @xmath0 , then it also holds for all channels whose kraus operators can be written as linear combinations of the @xmath139 .",
    "in other words , the `` set of correctible errors '' is naturally identified with the vector space of operators @xmath140 such that there is a vector @xmath141 with @xmath142 for all @xmath136 .",
    "this space will be called the _ maximal error space _ of the coding scheme , and will be denoted by @xmath143 .",
    "usually , a code is designed for a given error space @xmath144 .",
    "then the statement that these given errors are corrected simply becomes @xmath145 .",
    "the key observation , however , is that the space of errors is a vector space in a natural way , i.e. , if we can correct two types of errors , then we can also correct their _",
    "superposition_.      let us now consider the situation in which we want to send states of a small system with hilbert space @xmath146 through a channel @xmath147 .",
    "the kraus operators of @xmath0 lie in an error space @xmath148 , which we assume to be given .",
    "no more assumptions will be made about @xmath0 .",
    "our task is now to devise coding @xmath51 and decoding @xmath52 so that @xmath55 is the identity on @xmath149 .",
    "the idea is to realize the error corrector s dream by suitable encoding .",
    "the ` good ' space in that scenario is , of course , the space @xmath146 .",
    "we are looking for a way to write @xmath150 .",
    "actually , an isomorphism may be asking too much , and we look for an isometry @xmath151 .",
    "the encoding , written best in the schrdinger picture , is tensoring with an initial state @xmath138 as before , but now with an additional twist by @xmath49 : @xmath152 the decoding operation @xmath52 is again taking the partial trace over the bad space @xmath153 , after reversing of @xmath49 . since @xmath49 is only an isometry and not necessarily unitary we need an additional term to make @xmath52 unit preserving .",
    "the whole operation is is best written in the heisenberg picture : @xmath154 where @xmath155 is an arbitrary density operator .",
    "these transformations are successful , if the error space ( transformed by @xmath49 ) behaves as before , i.e. , if for all @xmath156 there are vectors @xmath157 such that , for all @xmath158 @xmath159 holds .",
    "this equation describes precisely the elements @xmath160 of the maximal error space .    to check that we really have @xmath161 for any channel @xmath162 with @xmath163",
    ", it suffices to consider pure input states @xmath131 , and the measurement of an arbitrary observable @xmath164 at the output : @xmath165      & = \\sum_{i } { \\operatorname{tr}}\\bigl [ u { |\\phi\\otimes \\omega\\rangle\\langle\\phi\\otimes \\omega|}u^ * f_i                            u(x \\otimes{\\if11\\idty\\else\\mathbb{1}\\fi } ) u^ * f_i\\bigr ]   \\nonumber\\\\    & = \\sum_{i } { \\operatorname{tr}}\\bigl [ { |\\phi\\otimes \\phi(f_i)\\rangle\\langle\\phi\\otimes \\phi(f_i)| } x \\otimes { \\if11\\idty\\else\\mathbb{1}\\fi}\\bigr ]        \\nonumber\\\\    & = \\langle\\phi , x \\phi\\rangle \\sum_{i}\\|\\phi(f_i)\\|^2    = \\langle\\phi , x\\phi\\rangle.\\end{aligned}\\ ] ] in the last equation we have used that @xmath166 , since @xmath167 , and @xmath52 each map @xmath168 to @xmath168 .",
    "the encoding @xmath51 defined in equation ( [ encodeu ] ) is of the form @xmath169 with the _ encoding isometry _",
    "@xmath170 given by @xmath171 if we just know this isometry and the error space we can reconstruct the whole structure , including the decomposition @xmath172 , and hence the decoding operation @xmath52 .",
    "a necessary condition for this , first established by knill and laflamme @xcite , is that , for arbitrary @xmath173 and error operators @xmath174 : @xmath175 holds with some numbers @xmath176 independent of @xmath177 .",
    "indeed , from ( [ eq:4 ] ) we immediately get this equation with @xmath178 .",
    "conversely , if the knill - laflamme condition ( [ klaf ] ) holds , the numbers @xmath176 serve as a ( possibly degenerate ) scalar product on @xmath179 , which upon completion becomes the ` bad space ' @xmath153 , such that @xmath180 is identified with a hilbert space vector @xmath181 .",
    "the operator @xmath182 is then an isometry , as used at the beginning of this section . to conclude , the knill - laflamme condition is necessary and sufficient for the existence of a decoding operation .",
    "its main virtue is that we can use it without having to construct the decoding explicitly .",
    "let us come back to the problem we are addressing in this paper . in that case",
    "the space @xmath183 is the @xmath41-fold tensor product of the system @xmath184 on which the noisy channels under consideration act .",
    "we say that a coding isometry @xmath185 _ corrects @xmath186 errors _ , if it satisfies the knill - laflamme condition ( [ klaf ] ) for the error space @xmath187 spanned linearly by all operators of the kind @xmath188 , where at most @xmath186 places we have a tensor factor @xmath189 .",
    "when @xmath190 and @xmath191 are both supported on at most @xmath186 sites , the product @xmath192 , which appears in the knill - laflamme condition involves @xmath193 sites .",
    "therefore we can paraphrase the condition by saying that @xmath194 for @xmath195 . from kraus operators in @xmath187",
    "we can build arbitrary channels of the kind @xmath196 , where at most @xmath186 of the tensor factors @xmath197 are channels different from @xmath198 .",
    "we will use this in the form that @xmath199 , whenever at most @xmath186 tensor factors are @xmath200 , and at least one of them is a difference of two channels .",
    "there are several ways to construct error correcting codes of this type ( see e.g. @xcite ) .",
    "most appropriate for our purposes is the scheme proposed in @xcite , which is quite easy to describe and admits a simple way to check the error correction condition .",
    "this will be the subject of the next section .",
    "the general scheme of graph codes works not just for qubits , but for any dimension @xmath39 of one site spaces .",
    "the code will have some number @xmath60 of input systems , which we label by a set @xmath164 , and , similarly @xmath41 output systems , labeled by a set @xmath201 .",
    "the hilbert space of the system with label @xmath202 will be denoted by @xmath203 although all these are isomorphic to @xmath204 , and are equipped with a special basis @xmath205 , where @xmath206 is an integer taken modulo @xmath39 . as a convenient shorthand ,",
    "we write @xmath207 for a tuple of @xmath206 , specified for every @xmath208 .",
    "thus the @xmath209 form a basis of the input space @xmath210 of the code .",
    "an operator @xmath140 , say , on the output space will be called _ localized _ on a subset @xmath211 of systems , if it is some operator on @xmath212 , tensored with the identity operators of the remaining sites .",
    "1    l5.5 cm    ( 16,8 ) ( 4,4 ) ( 0,0)0.2a ( 3.5;90)0.2b ( 3.5;18)0.2c ( 3.5;-54)0.2d ( 3.5;162)0.2e ( 3.5;232)0.2f ( 12,4 ) ( -3.5,-2)0.2a ( -3.5,2)0.2b ( 3.5,-2)0.2c ( 3.5,2)0.2d ( -2.5,0)0.2e ( 2.5,0)0.2f    the main ingredient of the code construction is now an undirected graph with vertices @xmath213 .",
    "the links of the graph are given by the adjacency matrix , which we will denote by @xmath214 .",
    "when we have @xmath215 input vertices and @xmath216 output vertices , this is an @xmath217 matrix with @xmath218 if node @xmath65 and @xmath219 are linked and @xmath220 otherwise .",
    "we do allow multiple edges , so the entries of @xmath214 will in general be integers , which can also be taken modulo @xmath39 .",
    "it is convenient to exclude self - linked vertices , so we always take @xmath221 .",
    "the graph determines an operator @xmath222 by the formula @xmath223 where the exponent contains the matrix element of @xmath214 @xmath224 because @xmath214 is symmetric , every term in this sum appears twice , hence adding a multiple of @xmath39 to any @xmath225 or @xmath226 will change the exponent in ( [ eq:27 ] ) by a multiple of @xmath227 , and thus will not change @xmath228 .",
    "the error correcting properties of @xmath228 are summarized in the following result @xcite .",
    "it is just the knill - laflamme condition with a special expression for the form @xmath229 , for error operators such that @xmath192 is localized on a set @xmath230 .",
    "let @xmath214 be a graph , i.e. , a symmetric matrix with entries @xmath231 , for @xmath232 .",
    "consider a subset @xmath211 , and suppose that the @xmath233-submatrix of @xmath214 is non - singular , i.e. , @xmath234 where congruences are @xmath235 .",
    "then , for every operator @xmath236 localized on @xmath230 , we have @xmath237    it will be helpful to use the notation for collections of variables , already present in ( [ graphexponent ] ) more systematically : for any subset @xmath238 we write @xmath239 for the collection of variables",
    "@xmath240 with @xmath241 . the kronecker - delta @xmath242 is defined to be zero if for any @xmath241 @xmath243 , and one otherwise . by @xmath244",
    "we mean the suitably restricted sum , i.e. , @xmath245 .",
    "the important sets to which we apply this notation are @xmath246 and @xmath247 .",
    "in particular , the condition on @xmath214 can be written as @xmath248 .",
    "consider now the matrix element @xmath249 since @xmath140 is localized on @xmath230 , the matrix element contains a factor @xmath250 for every @xmath251 , so we can write @xmath252 .",
    "therefore we can compute the sum ( [ bigsum4graph ] ) in stages : @xmath253 where @xmath254 is the sum over the @xmath255-variables , which , of course , still depends on the input variables @xmath256 and the variables @xmath257 at the error positions : @xmath258 the sums in the exponent can each be split into four parts according to the decomposition @xmath259 vs.  @xmath255 . the terms involving @xmath260 cancel because @xmath261 . the terms involving @xmath262 and @xmath263 are equal because @xmath214 is symmetric , and together give @xmath264 .",
    "the @xmath265 remain unchanged , but only give a phase factor independent of the summation variables .",
    "hence @xmath266 here we used at the first equation that the sum is a product of geometric series as they appear in discrete fourier transforms . at the second equality",
    "the main condition of the proposition enters : if @xmath267 vanishes for all @xmath268 as required by the delta - function then ( and only then ) the vector @xmath269 must vanish .",
    "but then the two terms in the exponent of the phase factor also cancel .    inserting this result into ( [ oeae ] ) , and using that @xmath270 , we find @xmath271 here the error operator is considered in the first line as an operator on @xmath272 , and as an operator on @xmath273 in the second line , by tensoring it with @xmath274 .",
    "this cancels the dimension factor @xmath275    all that is left to get an error correcting code is to ensure that the conditions of this proposition are satisfied sufficiently often .",
    "this is evident from combining the above proposition with the example at the end of section  [ sec : knila ] .",
    "let @xmath214 be a graph as in the previous proposition , and suppose that the @xmath233-submatrix of @xmath214 is non - singular for _ all _ @xmath211 with up to @xmath193 elements .",
    "then the code associated to @xmath214 corrects @xmath186 errors .",
    "two particular examples ( which are equivalent ! ) are given in figure [ fig : graphs ] .",
    "in both cases we have @xmath276 , @xmath277 and @xmath278 i.e. one input node , which can be chosen arbitrarily , five output nodes and the corresponding codes correct one error .",
    "the discrete error correction scheme described in the last section is not really designed to correct _ small _ errors : it corrects _ rare _ errors in multiple applications of the channel .",
    "a typical example of a small ( but not rare ) error is a small unitary rotation , @xmath47 .",
    "then @xmath33 can be small , but since the same small error happens to each of the parallel channels in @xmath120 , the error syndromes of discrete error correction at first sight do not seem to be appropriate at all . nevertheless , the discrete theory can be applied , and this is the content of the following proposition .",
    "it is the appropriate formulation of `` reducing the order of errors from @xmath1 to @xmath279 '' .",
    "[ pinomi ] let @xmath280 be a channel , and let @xmath121 be encoding and decoding channels for coding @xmath60 systems into @xmath41 systems .",
    "suppose that this coding scheme corrects @xmath186 errors , and that @xmath281 then @xmath282 where @xmath283 denotes the shannon entropy of the probability distribution @xmath284 .    into @xmath285 , we insert the decomposition @xmath286 and expand the product .",
    "this gives @xmath287 terms , containing tensor products with some number , say @xmath288 , of tensor factors @xmath289 and tensor factors @xmath198 on the remaining @xmath290 sites .",
    "now when @xmath291 , the error correction property makes the term zero .",
    "terms with @xmath292 we estimate by @xmath293 . collecting terms",
    "we get @xmath294 the rest then follows from the next lemma ( with @xmath295 ) .",
    "it treats the exponential growth in @xmath41 for truncated binomial sums .",
    "[ lem:3 ] let @xmath296 and @xmath297 such that @xmath298 . then , for all integers @xmath41 : @xmath299    for @xmath300 we can estimate the step function by an exponential , and get @xmath301 with @xmath302 .",
    "the minimum over all real @xmath303 is attained at @xmath304 .",
    "we get @xmath305 precisely when the conditions of the lemma are satisfied , in which case the bound is computed by evaluating @xmath306 .",
    "suppose now that we find a family of coding schemes with @xmath307 with fixed rate @xmath308 of inputs per output , and a certain fraction @xmath309 of errors being corrected .",
    "then we can apply the proposition and find that the errors can be estimated above by @xmath310 where @xmath39 is the hilbert space dimension of each input system .",
    "this goes to zero , and even exponentially to zero , as soon as the expression in parentheses is @xmath311",
    ". this will be the case whenever @xmath33 is small enough , or , more precisely , @xmath312 note in addition that we have for all @xmath313 @xmath314 hence the bound from equation ( [ eq:11 ] ) is implied by ( [ normsmall ] ) .",
    "the function appearing on the right hand side of ( [ normsmall ] ) looks rather complicated , so we will often replace it by a simpler one , namely @xmath315 where @xmath316 is the base of natural logarithms ; cf .",
    "figure [ fig : bounds1 ] .",
    "the proof of this inequality is left to the reader as exercise in logarithms .",
    "the bound is very good ( exact to first order ) in the range of small @xmath1 , in which we are most interested anyhow . in any case , from @xmath317 we can draw the same conclusion as from ( [ normsmall ] ) : exponentially decreasing errors , provided we can actually find code families correcting a fraction @xmath318 of errors",
    ". this will be the aim of the next section .",
    "( 15,10 ) ( 7.5,5 ) ) plotted as a function of @xmath318.,title=\"fig : \" ] ( 13.5,0.5)@xmath318 ( 12,8)@xmath319 ( 12,3.2)@xmath320",
    "our aim in this section is to apply the theory of graph codes to construct a family of codes with positive rate .",
    "it is not so easy to construct such families explicitly .",
    "however , if we are only interested in existence , and do not attempt to get the best possible rates , we can use a simple argument , which shows not only the existence of codes correcting a certain fraction of errors , but even that `` typical graph codes '' for sufficiently large numbers of inputs and outputs have this property . here",
    "`` typical '' is in the sense of the probability distribution , defined by simply setting the edges of the graph independently , and each according to the uniform distribution of the possible values of the adjacency matrix .",
    "for the random method to work we need the dimension of the underlying one site hilbert space to be a prime number .",
    "this curious condition is most likely an artefact of our method , and will be removed later on .",
    "we have seen that a graph code corrects many errors if certain submatrices of the adjacency matrix have maximal rank .",
    "therefore we need the following lemma .",
    "let @xmath39 be a prime , @xmath321 integers and let @xmath164 be an @xmath322-matrix with independent and uniformly distributed entries in @xmath323",
    ". then @xmath164 is singular over the field @xmath323 with probability at most @xmath324 .",
    "the sum of independent uniformly distributed random variables in @xmath323 is again uniformly distributed . moreover , since @xmath39 is prime , this distribution is invariant under multiplication by non - zero factors .",
    "hence if @xmath325 ( @xmath326)are independent and uniformly distributed , and @xmath327 are non - random constants , not of all of which are zero , @xmath328 is uniformly distributed .",
    "hence , for a fixed vector @xmath329 , the @xmath330 components @xmath331 are independent uniformly distributed random variables . hence the probability for @xmath332 for some fixed @xmath333 is @xmath334 .",
    "since there are @xmath335 vectors @xmath135 to be tested , the probability for _ some _ @xmath135 to yield @xmath332 is at most @xmath336 .",
    "[ prop:2 ] let @xmath39 be a prime , and let @xmath214 be a symmetric @xmath217-matrix with entries in @xmath323 , chosen at random such that @xmath337 and that the @xmath338 with @xmath339 are independent and uniformly distributed .",
    "let @xmath340 be the probability for the corresponding graph code _ not _ to correct @xmath186 errors ( with @xmath341 ) .",
    "then @xmath342    each error configuration is an @xmath193-element subset of the @xmath41 output nodes .",
    "according to proposition ... we have to decide , whether the corresponding @xmath343-submatrix of @xmath214 , connecting input and error positions with the remaining output positions , is singular or not .",
    "since this submatrix contains no pairs @xmath344 , its entries are independent and satisfy the conditions of the previous lemma . hence the probability that a particular configuration of @xmath316 errors goes uncorrected is at most @xmath345 .",
    "since there are @xmath346 possible error configurations among the outputs , we can estimate the probability of any @xmath193 site error configuration to be undetected as less than @xmath347 .",
    "using lemma [ lem:3 ] we can estimate the binomial as @xmath348 , which leads to the bound stated .",
    "in particular , if the right hand side of the inequality in ( [ pnotcorrect ] ) is negative , we get @xmath349 , so that there must be at least one matrix @xmath214 correcting @xmath186 errors .",
    "the crucial point is that this observation does not depend on @xmath41 , but only on the rate - like parameters @xmath63 and @xmath350 .",
    "let us make this behaviour a definition :    let @xmath39 be an integer .",
    "then we say a pair @xmath351 consisting of a _ coding rate _ @xmath352 and an _ error rate _",
    "@xmath318 is _ achievable _ , if for every @xmath41 we can find an encoding @xmath51 of @xmath353 @xmath39-level systems into @xmath41 @xmath39-level systems correcting @xmath354 errors",
    ".    then we can paraphrase the last proposition as saying that all pairs @xmath351 with @xmath355 are achievable .",
    "this is all the input we need for the next section , although a better coding scheme , giving larger @xmath352 or larger @xmath318 would also improve the rate estimates proved there .",
    "such improvements are indeed possible .",
    "e.g. for the qubit case ( @xmath356 it is shown in @xcite that there is allways a code which saturates the _ quantum gilbert - varshamov bound _",
    "@xmath357 which is slightly better than our result .",
    "but there are also known limitations , particularly the so - called _ hamming bound_. this is a simple dimension counting argument , based on the error correctors dream : assuming that the scalar product @xmath358 on the error space @xmath144 is non - degenerate , the dimension of the `` bad space '' is the same as the dimension of the error space .",
    "hence with the notations of section  [ sec : quant - error - corr ] we expect @xmath359 .",
    "we now take @xmath60 input systems and @xmath41 output systems of dimension @xmath39 each , so that @xmath360 and @xmath361 . for the space of errors happening at at most @xmath186 places",
    "we introduce a basis s follows : at each site we choose a basis of @xmath362 consisting of @xmath363 operators plus the identity .",
    "then a basis of @xmath144 is given by all tensor products with basis elements @xmath364 placed at @xmath365 sites .",
    "hence @xmath366 . for large @xmath41",
    "we estimate this as in lemma  [ pinomi ] as @xmath367 .",
    "hence the hamming bound becomes @xmath368 which ( with @xmath369 ) is just ( [ eq:8 ] ) with a factor @xmath370 on all errors .",
    "( 15,10 ) ( 7.5,5 ) ) .",
    "the allowed regions are below the respective curve.,title=\"fig : \" ] ( 13.5,0.5)@xmath318 ( 0.8,9)@xmath352    if we drop the nondegeneracy condition made above it is possible to find codes which break the hamming bound @xcite . in this case",
    ", however , we can consider the weaker _ singleton bound _",
    ", which has to be respected by those _ degenerate codes _ as well .",
    "it reads @xmath371 we omit its proof here ( see @xcite sect .",
    "12.4 instead ) .",
    "both bounds are plotted together with the rate achieved by random graph coding in in figure [ fig : bounds ] ( for @xmath372 ) .",
    "we are now ready to combine our discussion of channel - capacity from section [ sec : channel - capacities ] with the results about error correction we have derived in the previous sections .",
    "please note that most of the result presented here can be found in @xcite , in some cases with better bounds .",
    "we first look at the problem which motivated our study , namely estimating the capacity of a channel @xmath373 .",
    "[ oneprime ] let @xmath39 be a prime , and let @xmath0 be a channel on @xmath39-level systems .",
    "suppose that for some @xmath374 , @xmath375 then @xmath376    for every @xmath41 set @xmath377 , and @xmath378 , where @xmath352 is , up to a @xmath108 factor , the right hand side of ( [ qforprime ] ) , i.e. @xmath379 .",
    "this ensures that the right hand side of ( [ pnotcorrect ] ) is strictly negative , so there must be a code for @xmath39-level systems , with @xmath60 inputs and @xmath41 outputs , and correcting @xmath186 errors . to this code",
    "we apply proposition  [ pinomi ] , and insert the bound on @xmath380 into equation ( [ errorexpt ] ) .",
    "thus @xmath381 , even exponentially .",
    "this means that any number @xmath382 is an achievable rate . in other words",
    ", @xmath383 is a lower bound to the capacity .    if @xmath384 is small enough the quantity on the right hand side of equation ( [ qforprime ] ) is strictly positive ( cf .",
    "the dotted graph in figure [ fig : bounds ] ) .",
    "hence each channel which is sufficiently close to the identity allows ( asymptotically ) perfect error correction . beyond",
    "that we see immediately that @xmath385 is continous ( in the cb - norm ) at @xmath386 : since @xmath385 is smaller than @xmath108 and @xmath387 is continuous in @xmath318 with @xmath388 we find for each @xmath389 an @xmath384 exists , such that @xmath390 for all @xmath0 with @xmath391 . in other words if @xmath0 is arbitrarily close to the identity its capacity is arbitrarily close to @xmath108 . in corollary [ kor:1 ] below",
    "we will show the significantly stronger statement that @xmath118 is a lower semicontinuous function on the set of all channels .",
    "a crucial consequence of the ability to correct small errors is that we do not actually have to compute the limit defining the capacity : if we have a pretty good coding scheme for a given channel , i.e. , one that gives us @xmath392 , then we know the errors can actually be brought to zero , and the capacity is close to the nominal rate of this scheme , namely @xmath393 .",
    "[ prop:1 ] let @xmath0 be a channel , not necessarily between systems of the same dimension .",
    "let @xmath394 with @xmath395 a prime number , and suppose there are channels @xmath51 and @xmath52 encoding and decoding a @xmath395-level system through @xmath288 parallel uses of @xmath0 , with error @xmath396 .",
    "then @xmath397 moreover , @xmath385 is the least upper bound on all expressions of this form .",
    "we apply proposition  [ oneprime ] to the channel @xmath398 . with the random coding method",
    "we thus find a family of coding and decoding channels @xmath399 and @xmath400 from @xmath401 into @xmath402 systems , of @xmath395 levels each , such that @xmath403 this can be reinterpreted as an encoding of @xmath404-dimensional systems through @xmath405 uses of the channel @xmath0 ( rather than @xmath406 ) , which corresponds to a rate @xmath407 .",
    "we now argue exactly as in the proof of the previous proposition , with @xmath408 , so that @xmath409 by equation ( [ simplebound ] ) . by random graph coding",
    "we can achieve the coding ratio @xmath410 , and have the errors @xmath411 go to zero exponentially . since @xmath412 we can apply lemma [ lem:1 ] to the channel @xmath0 ( where the sequence @xmath413 is given by @xmath414 ) and find that the rate @xmath415 is achievable .",
    "this yields the estimate claimed in equation ( [ qforall ] ) .    to prove the second statement",
    "consider the function @xmath416 which associates to each real number @xmath417 the biggest prime @xmath418 with @xmath419 . from known bounds on the length of gaps between two consecutive primes @xcite",
    "denotes the @xmath420 prime and @xmath421 is the length of the gap between @xmath422 and @xmath423 it is shown in @xcite that @xmath424 is bounded by @xmath425 . ]",
    "it follows that @xmath426 holds , hence we get @xmath427 for an arbitrary @xmath428 , provided @xmath41 is large enough , but this implies @xmath429}{k }   < \\frac{\\log_2(1+\\delta')}{k}.\\ ] ] since we can choose an achievable rate @xmath96 arbitrarily close to the capacity @xmath385 this shows that there is for each @xmath389 a prime @xmath395 and a positive integer @xmath288 such that @xmath430 .",
    "in addition we can find a coding scheme @xmath51 , @xmath52 for @xmath431 such that equation ( [ eq:9 ] ) holds , i.e. the right hand side of ( [ qforall ] ) can be arbitrarily close to @xmath432 , and this completes the proof .",
    "this theorem allows us to derive very easily an important _ continuity property _ of the quantum capacity .",
    "it is well known that each function @xmath140 ( on a topological space ) which is given as the supremum of a set of real - valued , continuous functions is _ lower semicontinuous _ , i.e. the set @xmath433\\bigr)$ ] is open for each @xmath434 . since the right hand side of equation ( [ qforall ] )",
    "is continuous in @xmath0 and since @xmath69 is ( according to proposition [ prop:1 ] ) the supremum over such quantities , we get :    [ kor:1 ] @xmath435 is lower semi - continuous in cb - norm",
    ".      another consequence of theorem [ prop:1 ] concerns the rate with which the error @xmath436 decays in the limit @xmath437 .",
    "theorem [ prop:1 ] says , roughly speaking that we can achieve _ each rate _ @xmath438 by combining a coding scheme @xmath439 with subsequent random - graph coding @xmath440 .",
    "however , the error @xmath441 $ ] decays according to ( [ errorexpt ] ) and proposition [ prop:2 ] exponentially . a more precise analysis of this idea leads to the following ( cf . also the work hamada @xcite ) :    [ prop:3 ] if @xmath0 is a channel with quantum capacity @xmath385 and @xmath442 , then , for sufficiently large @xmath41 we have @xmath443 with a positive constant @xmath444 .",
    "we start as in theorem [ prop:1 ] with the channel @xmath445 and the quantity @xmath446 .",
    "however instead of assuming that @xmath447 holds , the full range @xmath448 is allowed for the error rate @xmath318 . using the same arguments as in the proof of theorem [ prop:1 ] we get an achievable rate @xmath449 and an exponential bound on the coding error : @xmath450 cf",
    ". equations ( [ errorexpt ] ) and ( [ eq:12 ] ) .    to calculate the exponential rate @xmath444 with which the coding error vanishes we have to consider the quantity @xmath451 where we have inserted inequality ( [ eq:13 ] ) .",
    "now we we can apply lemma [ lem:1 ] ( with the sequence @xmath452 ) , which shows that @xmath444 is positive , if the right hand side of ( [ eq:15 ] ) is .    what remains to show",
    "is that @xmath453 holds for each @xmath438 . to this end",
    "we have to choose @xmath454 and @xmath318 such that @xmath455 and @xmath456 .",
    "hence consider @xmath389 such that @xmath457 is an achievable rate .",
    "as in the proof of theorem [ prop:1 ] we can choose @xmath432 such that @xmath458 holds while @xmath97 is arbitrarily small . hence there is an @xmath459 such that @xmath455 implies @xmath460 .",
    "the statement therefore follows from the fact that there is a @xmath461 with @xmath462 for all @xmath463 and @xmath460 .",
    "in addition to the statement of proposition [ prop:3 ] we have just derived a lower bound on the error exponent @xmath444 .",
    "since we can not express the error rate @xmath318 as a function of @xmath464 and @xmath96 we can not specify this bound explicity",
    ". however we can plot it as a parametrized curve ( using equation ( [ eq:16 ] ) and ( [ eq:15 ] ) with @xmath318 as the parameter ) in the @xmath465-space .",
    "in figure [ fig : errexp ] this is done for @xmath466 , @xmath467 and several values of @xmath97 .",
    "( 15,10 ) ( 7.5,5 ) plotted for @xmath468 and different values of @xmath97.,title=\"fig : \" ] ( 13.5,0.5)@xmath96 ( 0.8,9)@xmath303 ( 12,8.7)@xmath469 ( 12,8)@xmath470 ( 12,7.3)@xmath471 ( 12,6.6)@xmath472      we can also tolerate finite errors in encoding .",
    "let @xmath473 denote the quantity defined exactly like the capacity , but with the weaker requirement that @xmath474 for large @xmath41 .",
    "obviously we have @xmath475 for each @xmath384 .",
    "regarded as a function of @xmath318 and @xmath0 this new quantity admits in addition the following continuity property in @xmath318 .",
    "@xmath476 .    by definition we can find for each @xmath477 a tuple @xmath478 and @xmath52 such that @xmath479 and @xmath480 holds .",
    "if @xmath481 is small enough , however , we find as in theorem [ prop:1 ] a random graph coding scheme such that @xmath482 hence the statement follows from continuity of @xmath126 and the fact that @xmath483 holds .    for a classical channel @xmath101",
    "even more is known about the similar defined quantity @xmath484 : if @xmath384 is small enough we can not achieve bigger rates by allowing small errors , i.e. @xmath485 .",
    "this is called the `` strong converse of shannon s noisy channel coding theorem '' @xcite .",
    "to check whether a similar statement holds in the quantum case is one of the big open problem of the theory .",
    "funding by the european union project equip ( contract ist-1999 - 11053 ) and financial support from the dfg ( bonn ) is greatfully acknowledged .",
    "p.  w. shor .",
    "_ algorithms for quantum computation : discrete logarithms and factoring_. in _ proc . of the 35th annual symposium on the foundations of computer science _",
    "( s.  goldwasser , editor ) , pages 124134 .",
    "ieee computer science , society press , los alamitos , california ( 1994 ) ."
  ],
  "abstract_text": [
    "<S> the theory of quantum error correction is a cornerstone of quantum information processing . </S>",
    "<S> it shows that quantum data can be protected against decoherence effects , which otherwise would render many of the new quantum applications practically impossible . in this paper </S>",
    "<S> we give a self contained introduction to this theory and to the closely related concept of quantum channel capacities . </S>",
    "<S> we show , in particular , that it is possible ( using appropriate error correcting schemes ) to send a non - vanishing amount of quantum data undisturbed ( in a certain asymptotic sense ) through a noisy quantum channel @xmath0 , provided the errors produced by @xmath0 are small enough .    </S>",
    "<S> this text is part of a volume entitled : `` _ _ coherent evolution in noisy environments _ _ '' to be published in _ </S>",
    "<S> lecture notes in physics _ , springer verlag , ` http://link.springer.de/series/lnpp/ ` , copyright : springer verlag , berlin , heidelberg , new york </S>"
  ]
}