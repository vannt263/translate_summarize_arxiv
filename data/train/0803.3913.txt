{
  "article_text": [
    "in probability theory it is customary to investigate two broad families of problems , ( i ) the convergence of sums of large numbers of random variables , and ( ii ) the estimation of likelihoods of deviations of those sums from their large number limits @xcite .",
    "the probability spaces of the random variables in question are usually fixed and one investigates how fast do properties of a sample drawn from the statistical population _ * converge * _ towards properties of that statistical population ( to be called population for brevity , later on ) .",
    "a good example of this is one of the most fundamental theorems of probability , the _ * law of large numbers * _ ( lln ) .",
    "the weak version can be stated ( see  @xcite for example ) as :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ let @xmath2 be an independent trials process , with finite expected value @xmath3 $ ] and variance @xmath4 .",
    "let @xmath5 .",
    "then @xmath6 , @xmath7 = 0 \\label{eq : lln}\\ ] ] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    noting that the quantity @xmath8 is nothing more than the sample mean , @xmath9 , the law of large numbers can be stated in words as `` for independent trials of a sample of a distribution with finite population mean , the sample mean should approach the population mean , as the number of trials ( i.e. size of the sample ) gets very large '' .    in this paper",
    "we pose questions in a different way .",
    "we consider a sequence of populations from discrete , finite probability spaces whose size ( to be termed number of outcomes in what follows ) increases .",
    "we draw a sample of a fixed size from each of these populations , and analyze under what conditions , and how quickly , do the properties of the samples _ * diverge * _ from properties of the populations . in effect",
    "we are increasing monotonically the number of outcomes available to each trial , while keeping the number of trials , of sample size ( @xmath0 ) constant .",
    "in other words we formulate the * _ * `` reverse '' of the law of large numbers*_*.    we illustrate this using a thought experiment based on a real life situation - betting on horses . each horse",
    "is given a unique label . here the random variable in question is the label of the winning horse , the number of outcomes @xmath1 is the number of horses in the race , and the sample size @xmath0 stands for the number of repetitions of the race .",
    "if the number of horses in the race is fixed ( @xmath10 ) then , if the number of race repetitions becomes large ( @xmath11 ) , the average label of the winning horse converges towards that of the expected value of the label of the winning horse .",
    "we have made the idealized assumption that the probability distribution itself remains fixed thus ignoring aging effects , weather changes , different tracks etc .",
    "now imagine that , as time progresses , new horses are added to the race indefinitely ( @xmath12 ) and that each time a new horse has been added , the same number of races ( @xmath13 ) is held .",
    "in this situation we intuitively perceive that the average label of the winning horse becomes less likely to be linked to the expected value of the label of the winning horse . in other words ,",
    "the variance of the average label of the winner will increase at a rate that depends on the number of horses that participate in the race and on the probability distribution that a given horse wins .",
    "another thought experiment to illustrate this idea is to think of an unbiased @xmath1-sided `` die '' .",
    "here we ask what value appears face up when we throw the die .",
    "if we think of the standard die , with @xmath14 , and consider @xmath15 throws , we would expect the average throw to be pretty close to the expected value of , in this case , @xmath16 .",
    "however , if we increase @xmath1 to larger and larger values , but keep @xmath0 fixed , we would no longer expect to always get sample means close to the population mean ( expected value ) .    in the above examples",
    ", we looked at one particular statistic - the sample mean .",
    "the law of large numbers , in equation ( [ eq : lln ] ) , tells us that the sample mean approaches the population mean as the number of trials increases .",
    "this is normally proven using chebyshev s inequality ( assuming that the variance , @xmath17 , is finite ) , which for the sample mean , is given by : @xmath18 \\leq \\frac{\\sigma^2}{n \\epsilon^2 } \\label{eq : cheby}\\ ] ] here we used the fact that the variance of the sample mean is given by : @xmath19 .",
    "chebyshev s inequality offers a sense of `` how large '' @xmath0 must be to see the desired convergence described by @xmath20 . for fixed @xmath0 and @xmath20",
    ", the variance of the random variable , @xmath21 , controls the bound on the probability of the sample mean being close to the population mean so bounds exceeding @xmath22 are `` loose '' .",
    "] .    in this paper , we look at probability distributions of finite discrete random variables .",
    "we consider what happens when additional outcomes are deemed possible , but the distribution still retains the same basic form . we then have , in essence , a sequence consisting of probability distributions that are all similar , but with higher terms in the sequence corresponding to those distributions with a higher number of outcomes ( @xmath1 ) .",
    "we also have corresponding sequences for the expected values , and variances of these distributions .",
    "we are interested in those such sequences of variances which diverge as the number of outcomes becomes large .",
    "then , from equation ( [ eq : cheby ] ) , and for fixed @xmath0 and @xmath20 , it is clear that sample means for the corresponding random variables would not be likely to be close to the expected values of those random variables .    therefore , we seek conditions for these sequences of variances to diverge as the number of outcomes becomes very large .",
    "we also attempt to determine classes of ( sequences of ) distributions that correspond to particular rates of divergence of the variance . in the course of this work we will use the terms probability measure and probability distribution interchangeably .",
    "we will call the sequences of distributions described above , as simply distributions ( that are functions of @xmath1 ) , and the sequences of variances as variances ( that are functions of @xmath1 ) .",
    "we will attempt to formulate our considerations and results in the axiomatic language of kolmogorov s theory of probability  @xcite .",
    "both the weak and the strong llns are proven without imposing any assumptions on the sample space @xmath23 and on the probability measure @xmath24 . instead one only assumes the existence of the first moment , in the case of the weak law , and both the first and the second moments in the case of the strong law @xcite .",
    "however , exploring the other extreme , namely the limit of the number of outcomes becoming very large ( @xmath12 ) subject to the sample size @xmath0 being fixed , does in fact require the knowledge of both the sample space and the probability measure .",
    "hence , we have to formulate assumptions about @xmath23 and @xmath24 .",
    "consider a finite discrete random variable @xmath21 with @xmath25 possible outcomes @xmath26 , with associated probabilities @xmath27 with @xmath28 .",
    "possible outcomes as we index from @xmath29 to @xmath1 .",
    "for compactness we will continue to use @xmath1 as the number of outcomes .",
    "indeed , as @xmath1 becomes very large , there is little difference between @xmath1 and @xmath25 . ] for our purposes it is necessary to define the probability distribution as an explicit function of the outcomes , @xmath30 .",
    "thus , we use a polynomial representation given by : @xmath31 here the numbers @xmath32 are like `` unnormalized '' probabilities and the normalization factor , @xmath33 , is given by : @xmath34 the coefficients , @xmath35 , are real numbers which can be computed by inverting the linear relationship in ( [ eq : probspace_gen ] ) and thus inverting the matrix @xmath36 . as @xmath37 is the vandermonde matrix  @xcite this can always be done ; thus , all finite discrete probability distributions can be represented in this form .",
    "we hope to look at random variables with more arbitrary outcomes in future work but for this paper , we look at a specific set of outcomes , @xmath38 . in this case ,",
    "equation ( [ eq : probspace_gen ] ) becomes : @xmath39 we then use the fact that @xmath40 , and call the quantities @xmath41 `` reduced probabilities '' .",
    "we can write the other coefficients @xmath42 in terms of the reduced probabilities : @xmath43 for @xmath44 . here",
    "@xmath45 is the inverse of @xmath46 .",
    "again , since @xmath37 is a vandermonde matrix it always invertible .",
    "we note that any quantities that describe the sample ( the sample mean , the variance of the sample mean , for example ) depend explicitly on the coefficients in ( [ eq : inverserel ] ) .",
    "we will see that , depending on those coefficients , we will obtain different large-@xmath1 behaviour of those quantities and , in particular , of the variance of the sample mean .",
    "some of these coefficients may be zero .",
    "for our analysis it is useful to use @xmath47 for the order of the polynomial in ( [ eq : probspace ] ) such that @xmath48 and @xmath49 for all @xmath50 .",
    "we will see that the variance of the sample mean scales differently with the number of outcomes depending on @xmath51 . both @xmath51 and the coefficients @xmath52 may vary as @xmath1 varies .",
    "recall that the variance of the sample mean depends on the variance of the underlying random variable .",
    "to look at the behaviour of the variance for different @xmath1 , we need to find a closed form expression for the inverse vandermonde matrix .",
    "furthermore we believe that the closed form expression for the inverse will be useful for other mathematical problems , like polynomial least square fitting , lagrange interpolation polynomials @xcite , and reconstruction of a statistical distribution from the moments of the distribution @xcite .",
    "the expression for the inverse was , to the best of our knowledge , previously unknown .",
    "we give it below .",
    "the inverse @xmath53 reads : @xmath54 here the polynomials , @xmath55 , satisfy the following recursion relations : @xmath56 for @xmath57 with @xmath58 .",
    "the lowest ten polynomials ( @xmath59 ) are listed in ( [ eq : pol1])-([eq : pol10 ] ) in appendix c. therein attached is also a piece of mathematica code that tests the validity of those expressions .",
    "the proof of ( [ eq : inversevandermonde ] ) is given in appendix b. note that rows with low ( @xmath22 , @xmath60 , @xmath61 ) and with high ( @xmath1 , @xmath62 , @xmath63 ) indices have a particularly simple form ; the complexity of the expression rises when the row index tends towards @xmath64 . setting @xmath65 in ( [ eq : inversevandermonde1 ] ) and @xmath66 in ( [ eq : inversevandermonde ] )",
    "we obtain : @xmath67    * note : * the inversion of the vandermonde matrix has applications in control theory @xcite , in signal processing problems @xcite and in systems theory @xcite . in order to solve the problem one typically makes use of the lagrange interpolation formula and finds the rows of the inverse matrix by computing the coefficients of the lagrange interpolation polynomials related to the matrix elements @xcite .",
    "an alternative approach was proposed in @xcite where the inverse matrix is expressed as a product of two matrices one of which is diagonal and the elements of the other one are given through certain recursion relations . in this way the total number of operations needed to invert is reduced from @xmath68 to @xmath69 .",
    "finally in @xcite one expresses the elements of the inverse through totally symmetric polynomials of the elements of the original matrix .",
    "our method of computing the inverse ( presented in appendix b ) is a way of actually solving the recursion relations from @xcite or summing up the totally symmetric polynomials analytically if the elements of the original matrix are certain real or complex powers of a constant or of an arithmetic progression . indeed , even though the elements of the original matrix are first powers of an arithmetic progression in our work i.e.  @xmath70 , the manipulations ( [ eq : matrixinverse])-([eq : matrixinverse1a ] ) can also be done analytically in the generic case of arbitrary powers , with little effort .",
    "thus , we believe , that our method is superior to the methods known in the literature and can be applied to produce more efficient numerical algorithms of use in the areas described above .",
    "now we fix @xmath71 , we draw a sample of size @xmath0 from the population described in ( [ eq : probspace ] ) and we conjecture that the quantities that describe the sample ( estimators of population parameters ) diverge from those that describe the population , if the number of outcomes @xmath1 becomes very large .",
    "to be specific , we analyze the variance of the sample mean , and we show that , except for very `` unusual distributions '' , it increases monotonically with @xmath1 , if @xmath1 is big enough , which implies that , for fixed @xmath0 , the sample mean diverges from the population mean when @xmath72 . in most computations below",
    "we will use asymptotic limits ( @xmath73 ) rather than exact results .",
    "however , deriving exact results is not an essential difficulty ; it amounts to performing more work , which is not necessary for our purposes .",
    "the variance of the sample mean reads : @xmath74 = \\frac{\\sigma^2}{n } : = \\frac{\\left<\\left(x - \\left < x\\right>\\right)^2\\right>}{n } = \\frac{\\left < x^2\\right > - \\left < x\\right>^2}{n } \\label{eq : samplevardef}\\ ] ] it depends on the variance , @xmath17 , of the random variable . using equation ( [ eq : probspace ] ) and faulhaber s formula ( [ eq : faulhaber ] ) , this variance can be written as : @xmath75 = \\frac{\\sum\\limits_{n=0}^{2{m}+4 } \\beta^{(1)}_n ( m+1)^n } { \\sum\\limits_{n=0}^{2{m}+2 } \\beta^{(2)}_n ( m+1)^n } \\label{eq : myvariance}\\end{aligned}\\ ] ] where @xmath76 where @xmath77 .",
    "the numbers , @xmath78 , are the bernoulli numbers .",
    "thus both the variance @xmath17 and the variance of the sample mean are rational functions of the number of outcomes @xmath1 .",
    "since we are only interested in the large-@xmath1 behaviour of the variance of the sample mean , we do not need to simplify expressions ( [ eq : coeffsratiofct0 ] ) and ( [ eq : coeffsratiofct ] ) for the coefficients but instead we only need to work out leading order terms in both the numerator and the denominator in ( [ eq : myvariance ] ) .",
    "thus , we assume that the order of the polynomial in ( [ eq : probspace ] ) is @xmath79 , meaning that the coefficent @xmath80 is non - zero and the last ( m - s ) coefficients , @xmath81 in the expansion ( [ eq : probspace ] ) , are zero . then the coefficients for the highest order terms in the numerator read : @xmath82    dividing the polynomials in ( [ eq : coeffsratiofct0 ] ) and ( [ eq : coeffsratiofct ] ) by one another we obtain the following expression for @xmath17 , for large @xmath1 : @xmath83 subbing this into equation ( [ eq : samplevardef ] ) will also give an expression for the variance of the sample mean as a function of @xmath1 .",
    "we now wish to examine whether @xmath17 converges or diverges for large @xmath1 .",
    "equation ( [ eq : variance ] ) can be rewritten as : @xmath84 \\label{eq : variance1}\\ ] ] as noted previously , it is possible for both the order , @xmath51 , and the coefficients , @xmath52 , to vary with @xmath1 .",
    "looking at the term in the square brackets , we notice that the first term ( @xmath85 ) will always dominate the third term ( @xmath1 ) and the second term ( @xmath86 ) will always dominate the fourth term ( @xmath87 ) .",
    "therefore we want to consider the large @xmath1 behaviour due to the first and second terms .",
    "the exact behaviour of the second term will depend on the distribution concerned , but we can identify four broad cases depending on the behaviour of the ratio @xmath88 in the large @xmath1 limit :    1 .",
    "@xmath89 2 .",
    "@xmath90 and @xmath91 3 .",
    "@xmath92 and @xmath93 4 .",
    "@xmath94 and @xmath95    the first case corresponds to when the limit of the ratio is finite .",
    "the second case is when the ratio grows in absolute value with @xmath1 but at a rate slower than @xmath1 .",
    "the third case is when the ratio grows with @xmath1 at a rate faster than @xmath1 .",
    "finally , the fourth case is when the ratio grows in absolute value with @xmath1 but is negative .",
    "we now consider each case separately .      in this case , we do not need to worry about the coefficients , and how they depend on @xmath1 to understand the large @xmath1 behaviour of the variance .",
    "it is clear that only the first term from equation ( [ eq : variance1 ] ) matters as @xmath72 .",
    "thus we have : @xmath96    now , let us consider three examples .",
    "firstly , @xmath51 does not depend on @xmath1 ; secondly , @xmath97 , i.e.  @xmath98 where @xmath99 ; and finally , @xmath100 , i.e.  @xmath101 where @xmath102 . from ( [ eq : case1 ] ) we see that in all three instances , both the variance and the variance of the sample mean ( for given @xmath0 ) diverge as the second , the first and the zeroth power of the number of outcomes respectively .",
    "that is , we have : @xmath103    we now go on to provide three explicit examples of such distributions . in all three examples , for fixed sample size @xmath0 ,",
    "the sample mean , or the estimator of the population mean , diverges from the population mean , yet at different rates .",
    "we describe these examples as _ * accelerating divergence * _ , _ * divergence * _ , and _ * decelerating divergence * _ , respectively .    [ [ accelerating - divergence ] ] accelerating divergence : + + + + + + + + + + + + + + + + + + + + + + + +    we generated a sequence of non - zero real parameters @xmath104 and computed the normalized probabilities @xmath105 from ( [ eq : probspace ] ) .",
    "we run over @xmath106 and for each value of @xmath51 we plot both the normalized probabilities , for @xmath107 , as a function of @xmath108 , and the variance of the distribution as a function of the number of outcomes @xmath1 , in the double logarithmic scale ( see figure [ fig : probvar ] ) .",
    "it is readily seen that the variance behaves asymptotically as the second power of the number of outcomes , and , in addition the asymptotic behaviour is attained quite quickly .",
    "* note : * we reiterate that this type of divergence is obtained for every distribution whose unnormalized probability distribution can be represented by a polynomial of order @xmath51 that does not depend on @xmath1 , when @xmath1 is large .",
    "[ [ divergence ] ] divergence : + + + + + + + + + + +    here we repeat the procedure from the previous point with one difference , namely that the number of parameters depends on the number of outcomes like equation ( [ eq : div ] ) . for the sake of simplicity",
    "let us take @xmath109 where @xmath110 .",
    "then , asymptotically , the unnormalized probabilities @xmath111 , and the norm @xmath33 , read @xmath112 , @xmath113 respectively .",
    "the probability distribution is plotted in the first graph of figure  [ fig : probvar1 ] . the first and second moments , and the variance read : @xmath114 in figure [ fig : probvar1 ] we plot the variance of the distribution as a function of the number of outcomes @xmath1 .",
    "now the variance diverges asymptotically as the first power of the number of outcomes . here",
    ", however , the asymptotic behaviour is attained much slower than in the previous case .",
    "* note : * we emphasize that this type of divergence is characteristic for every distribution whose probability function can be represented by a polynomial of order @xmath51 that behaves like the square root of the number of outcomes @xmath1 , for large @xmath1 . indeed , setting @xmath115 in ( [ eq : variance1 ] ) we get : @xmath116    [ [ decelerating - divergence ] ] decelerating divergence : + + + + + + + + + + + + + + + + + + + + + + + +    finally , we consider an exponential distribution @xmath117 for @xmath118 and @xmath119 . for large @xmath1 , the distribution can be well approximated by its taylor expansion truncated at the @xmath1^th^ order and as such , it would correspond to the polynomial form in equation ( [ eq : probspace ] ) . then @xmath120 and , in the large @xmath1 limit",
    ", the variance takes the following form : @xmath121 recall that equation ( [ eq : samplevarexp ] ) is only an approximation . in",
    "order to check the validity of that approximation , we plot the approximated variance of the sample mean @xmath122 along with the exact result in figure [ fig : samplevariance ] .",
    "we can see from the figure that the results do not differ by more than @xmath123 for @xmath124 .",
    "now the variance behaves asymptotically as the zeroth power of the number of outcomes and this behaviour is attained much faster than in the previous case .",
    "* note 1 : * again we stress that this type of divergence is characteristic for every distribution whose probability function is a polynomial whose order @xmath51 is proportional to the number of outcomes @xmath1 .",
    "indeed , setting @xmath125 in ( [ eq : variance ] ) we get : @xmath126    from the above discussion it is clear that the condition : @xmath127 is sufficient for the variance to exhibit divergent behaviour in the large @xmath1 limit .",
    "it is however an open question to specify both _ * necessary and sufficient conditions * _ for distributions to exhibit the behaviour specified above .",
    "one way of doing that , is to require that the last @xmath128 coefficients @xmath129 are equal to zero .",
    "this , from ( [ eq : inverserel ] ) , yields @xmath128 linearly independent linear equations for the unknown probabilities , given by : @xmath130 for @xmath131 .",
    "the solution to ( [ eq : syseq ] ) is given in ( [ eq : reducedprobabilitiesfinal1 ] ) along with ( [ eq : modesprobs ] ) and its proof is in appendix d.    [ [ summary - of - case-1 ] ] summary of case 1 + + + + + + + + + + + + + + + + +    an @xmath51-parameter family of unnormalized distributions is given by : @xmath132 for @xmath133 with the quantities @xmath134 being defined in ( [ eq : modesprobs ] ) .",
    "a probability distribution satisfying ( [ eq : reducedprobabilitiesfinal11 ] ) and the constraint ( [ eq : case1_constraint ] ) has a property that its variance @xmath17 , along with the variance of the sample mean @xmath135 ( for a given @xmath0 ) , exhibits an asymptotic behaviour as in ( [ eq : variance1 ] ) .",
    "this implies that the large-@xmath1 behaviour of the variance of the sample mean can range in a continuous fashion from a quadratic divergence @xmath136 to asymptotic convergence @xmath137 , for fixed sample size , @xmath0 .",
    "furthermore , if we assume the order of the polynomial in ( [ eq : probspace ] ) , @xmath51 , has a power law dependence on @xmath1 for large @xmath1 , of the form @xmath138 , with @xmath139 , then , from ( [ eq : variance1 ] ) , and for fixed @xmath0 the variance of the sample mean behaves as @xmath140 .",
    "we did some numerical testing of our results .",
    "for particular values of @xmath141 and @xmath142 we have found the solutions ( [ eq : modesprobs ] ) by solving numerically equations ( [ eq : syseq ] ) .",
    "subsequently we found the unnormalized probabilities from ( [ eq : reducedprobabilitiesfinal11 ] ) by taking arbitrarily @xmath143 and @xmath144 for @xmath145 .",
    "we plot the results in figure [ fig : probdistrsmodes ] .",
    "in addition , for a particular value of @xmath51 ( @xmath142 ) , and for @xmath146 , we computed numerically the variance of all the @xmath51 different probability distributions in ( [ eq : reducedprobabilitiesfinal11 ] ) and we plotted the results , as a function of @xmath1 in figure [ fig : variancenumplots ] as well .",
    "as we can see , the variance displays a quadratic dependence on the number of outcomes and the leading order coefficient fits in well with the result in ( [ eq : variance1 ] ) .      recalling section [ ss : large_m ] , case 2 includes all probability distributions that satisfy the following conditions : @xmath147 for this case , looking at equation ( [ eq : variance1 ] ) it is clear that only the first term is important for large @xmath1",
    ". thus one can use equation ( [ eq : case1 ] ) in the previous section and follow the discussion of divergence there .",
    "thus case 2 distributions will also exhibit divergence in the variance as @xmath72 .",
    "this implies , as before , that , for fixed @xmath0 , the large-@xmath1 behaviour of the variance of the sample mean can range in a continuous fashion from a quadratic divergence @xmath136 to asymptotic convergence @xmath137 .",
    "case 3 distributions are those that satisfy : @xmath148 unlike in previous cases , it is clear that now the second term in equation ( [ eq : variance1 ] ) will contribute to the variance in the large @xmath1 limit .",
    "however , the variance and the variance of the sample mean ( for fixed @xmath0 ) will still diverge as @xmath72 .",
    "but if the inequality in ( [ eq : case3_constraint2 ] ) is strict , then the second term in equation ( [ eq : variance1 ] ) now controls the exact behaviour of the divergence and it will be faster divergence than the maximum possible ( @xmath85 ) in the previous two cases .",
    "however , unlike in the previous cases , we do not analyze this behaviour any further .      in the previous three cases , for a given @xmath0 , the variance of the sample mean increases with the number of outcomes , which might imply that this holds for every distribution .",
    "however this is not the case .",
    "one can construct distributions such that the variance of the sample mean decreases with the number of outcomes .",
    "for example , take the ( unnormalized ) probability distriubtion given by : @xmath149 although this suggests a polynomial of order @xmath85 , for each @xmath1 , it can always be decomposed in a unique way into a polynomial of the form in ( [ eq : probspace ] ) . in this case",
    "the leading order term in the decomposition corresponds to @xmath150 .",
    "asymptotically , we get @xmath151 and the variance reads : @xmath152 hence the variance is inversely proportional to the square of the number of outcomes @xmath1 , for large @xmath1 .",
    "thus we have convergent behaviour for the variance .",
    "if we now solve for the ratio @xmath153 in equation ( [ eq : variance1 ] ) by requiring that the variance behaves like @xmath154 for large @xmath1 , then we get : @xmath155\\label{eq : ratio}\\ ] ]    this equation combined with the fact that @xmath156 confirms that the probability distribution in ( [ eq : counter_ex ] ) fits under case 4 as its satisfies the conditions given by : @xmath157    it is also possible to show that all distributions of the form @xmath158 where @xmath159 , like that in equation ( [ eq : counter_ex ] ) , will have a variance that converges as @xmath72 .",
    "these distributions are , however , quite unusual since most probabilities are assigned to very few outcomes .",
    "it is still an open question as to how many distributions will have variances that will exhibit convergent behaviour for a large number of outcomes .",
    "so far we used the variance as a measure of the `` width '' of the distribution .",
    "this may be unsatisfactory because for certain distributions the variance may not carry the relevant information - an example is the case where the variance does not exist .",
    "it is thus much more useful to compute percentiles of the distribution of the difference between the sample and the population mean , @xmath160 , and investigate the conditions under which they diverge . here",
    "@xmath161 is the mean of the random variable @xmath21 .",
    "recall that the @xmath162-percentile @xmath163 of random variable @xmath164 is defined as such a value of argument such that the cumulative distribution function ( cdf ) equals @xmath162% , i.e.   @xmath165 here @xmath166 .",
    "we denote by @xmath167 the normalization constant and we compute the cdf as follows : @xmath168 in ( [ eq : cdfsamplemean ] ) we used the definition of the cdf and the law of conditional probabilities , and we conditioned on the random variables in the sample , while we used equation ( [ eq : probspace ] ) in ( [ eq : cdfsamplemean1 ] ) . in ( [ eq : cdfsamplemean2 ] ) we neglected the indicator functions in the last term in parentheses , which we can do for large @xmath1 , and we summed over the @xmath108 values using the identity ( [ eq : sumovsimplexi ] ) and we summed over @xmath169 using elementary number theoretic identities .",
    "we also defined @xmath170 as the @xmath171 norm of the @xmath172 vector . in ( [ eq : cdfsamplemean3 ] ) we introduced the normalized @xmath0^th^ auto - convolution @xmath173 of the coefficients @xmath174 via : @xmath175    * note : * expression ( [ eq : cdfsamplemean4 ] ) uses an approximate identity ( [ eq : sumovsimplexi ] ) and is therefore only a starting point for analyzing the scaling of the percentiles of the difference between the sample mean and the population mean . in order to provide further insight into this problem one needs to compute the @xmath0^th^ autoconvolution from ( [ eq : nthautoconv ] ) , ( [ eq : inverserel ] ) and from the expression ( [ eq : inversevandermonde ] ) for the inverse vandermonde matrix .",
    "this will make it possible to uniquely classify distributions according to the asymptotic behaviour of their percentiles .",
    "we will accomplish that goal in future work .",
    "all finite discrete probability distributions may be represented by polynomials in the possible outcomes of their random variables , by inverting the relevant vandermonde matrix .",
    "we used this fact to examine the convergence of certain sample properties of finite discrete distributions .",
    "in particular , we considered families of probability distributions that had different numbers of outcomes ( @xmath1 ) but were otherwise similar .",
    "such families of distributions can be represented as sequences whose terms are indexed by @xmath1 .",
    "their variances can also be described as sequences in @xmath1 .    in this paper",
    "we considered the special case of integer outcomes @xmath176 .",
    "we calculated an expression for the variances of such families of distributions using large @xmath1 approximations , and then examined their behaviour as @xmath72 .",
    "we found conditions for _ divergence _ of the variance with increasing @xmath1 and gave some examples .",
    "we discussed some necessary and sufficient conditions for distributions to exhibit specific types of divergence .",
    "we also gave examples of families of distributions that _ did not _",
    "satisfy these conditions for divergence and whose variances actually _ converged _ as @xmath72 .",
    "finally , we have provided an expression for the cumulative distribution function ( cdf ) of the difference between the sample mean and the population mean .",
    "this expression can be used to analyze the asymptotic behaviour of the percentiles of the difference between the sample mean and the population mean as a function of the number of outcomes @xmath1 .    in obtaining the results , we derived many mathematical identities and they are listed in the appendices .",
    "we also derived an expression for the inverse of the vandermonde matrix used in this paper , which was previously unknown .",
    "we believe these formulae could be useful in many different fields .",
    "we hope , in future work , to generalize our results to arbitrary probability distributions , to quantify better what distributions these results apply to , as well as examine the behaviour of the variances of these distributions , for an increasing number of outcomes , relative to the mean .    in conclusion",
    ", this work should be relevant to situations where one must sample the distributions of finite discrete random variables .",
    "it highlights how adding new outcomes to such random variables ( without any change in the overall form of the probability distribution ) may still affect how the statistics converge , with increasing sample size , to the population properties .",
    "more importantly , we have proven that for certain finite discrete probability distributions when @xmath0 is kept _ fixed _",
    ", the variance of the sample mean actually _ diverges _ as @xmath72 .",
    "we termed this result as the _",
    "`` law of many outcomes '' _ , or alternatively , the _",
    "`` reverse of the law of large numbers''_.        [ appa ] in this appendix , we list certain identities used in the main body of the paper .",
    "the identities ( [ eq : faulhaber])-([eq : sumsimplexv_a ] ) all relate to sums of powers of integers over certain sets .",
    "the identities ( [ eq : binomidentity1])-([eq : binomidentity ] ) involve sums of binomial coefficients",
    ". then the remainder of this appendix is a generalization of the standard proof of the vandermonde determinant .",
    "this is used in appendix b to calculate the inverse of the vandermonde matrix used in this paper .",
    "here @xmath182 is the @xmath171-norm of the sequence @xmath183 , the symbol @xmath184 is the pochhammer symbol , and the coefficients @xmath185 read : @xmath186 for @xmath187 . here",
    "the numbers @xmath188 are multiplicities of elements of the sequence @xmath189 , i.e.  such numbers that the sequence @xmath189 falls into @xmath169 groups composed of equal elements , such that the first group has length @xmath190 , the second group length @xmath191 , up to the @xmath169^th^ group who has length @xmath192 .              where the coefficients @xmath201 are defined in ( [ eq : sumovsimplexiii ] ) .",
    "the identity ( [ eq : sumovsimplexiv ] ) follows from substituting @xmath202 for @xmath145 , from expanding the resulting power terms in binomial expansions , from applying ( [ eq : sumovsimplexii ] ) to sum over the sequences @xmath203 and from the identity ( [ eq : binomidentity ] ) .                where @xmath209 here the second bit on the right hand side in ( [ eq : sumsimplexv ] ) stands for the sum over ordered sequences bounded from below and above by @xmath210 and @xmath108 respectively and not bounded from below and above by @xmath211 and @xmath212 .",
    "here @xmath213 .",
    "let @xmath214 and @xmath215 and @xmath216 .",
    "then we have : @xmath217 note that for @xmath218 the term in parentheses on the right hand side equals unity .",
    "the quantities @xmath219 are polynomials of order @xmath220 in the variable @xmath221 with coefficients @xmath222 that depend on @xmath51 .",
    "following recursion relations hold @xmath223 for the polynomials and @xmath224 and for the coefficients of the polynomials . here",
    "@xmath225 .",
    "let @xmath226 and @xmath227 for @xmath228 .",
    "then we have : @xmath229 where the coefficients @xmath230 satisfy the following system of equations : @xmath231 for @xmath232 .",
    "the system of equations always has a unique solution . the identity ( [ eq : hypergeometriciden ] )",
    "is proven by elementary methods , i.e.  by reducing the sum to a common denominator and factoring out the numerator .",
    "it would be interesting to know if an analoguous identity exists in the case when the ratio of double factorials is replaced by a product of one or several ratios of that kind or of similar ones .",
    "* corollary * : define : @xmath233 and @xmath234 for @xmath235 .",
    "we term the quantities in ( [ eq : simplbulk ] ) and in ( [ eq : simplborder ] ) the sum over the bulk and over the border of a @xmath236 dimensional simplex , respectively .",
    "the sums over the border of the simplex read : @xmath238 the identities ( [ eq : sumbulkexpl ] ) and ( [ eq : sumborderexpl ] ) follow from an iterative application of the identity ( [ eq : hypergeometriciden ] ) .",
    "the sums are performed starting from the sum over the index with the lowest subscript and ending at the sum over the index with the biggest subscript .",
    "it will be interesting to find a generic formula related to a simplex of arbitrary dimension .",
    "in future work we will use the above results to conjecture the generic formula and prove that formula by induction .        for @xmath240 and @xmath241 .",
    "the above identity is proven by an iterative application of the chu - vandermonde identity @xcite . since the chu - vandermonde identity is closely related to the gauss s hypergeometric theorem @xcite , to dougall s formula @xcite , to thomae s theorem @xcite and to various other identities that involve generalized hypergeometric functions @xcite , it would be interesting to derive the many - dimensional analogues for those identities using our methods .",
    "@xmath252 } x_1^{\\left|\\vec{\\delta}-\\vec{\\xi}\\right| }   \\det\\left ( x_{p+1}^{j-1 +   \\sum\\limits_{\\theta=1}^a ( \\xi_\\theta 1_{j\\ge j_\\theta } + ( \\delta_\\theta - \\xi_\\theta)1_{j\\ge j_\\theta+1 } 1_{j_{\\theta+1}-j_\\theta \\ge 2 } ) }   \\right)_{p , j=1,1}^{m-1,m-1 }",
    "\\label{eq : genvandemondefull1}\\\\ & & = \\left(\\prod\\limits_{m\\ge j > i \\ge 1 } ( x_j - x_i)\\right ) \\cdot \\sum\\limits_{\\vec{\\xi}^{1 } \\in \\otimes_{\\theta^1=1}^{a^1 } [ 0,\\delta^{1}_{\\theta^1 } ] } \\cdot \\dots \\cdot \\sum\\limits_{\\vec{\\xi}^{m } \\in \\otimes_{\\theta^m=1}^{a^m } [ 0,\\delta^{a^m}_{\\theta^m } ] } \\prod\\limits_{p=1}^m x_p^{\\left|\\vec{\\delta}^{p}-\\vec{\\xi}^{p}\\right| } \\label{eq : genvandemondefull2}\\end{aligned}\\ ] ]    the sum on the right - hand - side in ( [ eq : genvandemondefull2 ] ) contains @xmath253 terms . here",
    "the parameters @xmath254 with @xmath255 for @xmath256 constitute a branching process and satisfy following recursion relations : @xmath257 for @xmath258 . the constraint , @xmath259 , holds where @xmath260 counts the number of consecutive adjacent elements in the sequence @xmath261 and @xmath262 counts the number of consecutive non - adjacent elements in the sequence @xmath261 . here @xmath263 .",
    "* proof : * we denote by @xmath264 a totally symmetric polynomial of order @xmath221 in the variables @xmath265 and @xmath266 and by @xmath267 for @xmath268 the power index of the matrix element .",
    "now , we multiply the first row of the determinant by minus unity and add to all following rows , i.e.  to the second , the third , up to the @xmath1^th^ row , we factor out a term @xmath269 from the @xmath162^th^ row , and , from the multi - linearity of the determinant , we get : @xmath270 in the next step we modify the @xmath108^th^ column , for @xmath268 .",
    "we multiply the first column by @xmath271 , the second column by @xmath272 , and so on and so forth , up to the @xmath273^th^ column by @xmath274 and add them all to the @xmath108^th^ column .",
    "it is not hard to see that we get : @xmath275 here in the first @xmath276 columns ( whose labels are @xmath277 ) we have single powers terms , whereas in the last @xmath278 columns ( whose labels are @xmath279 ) we have sums of @xmath280 power terms .",
    "thus at positions @xmath281 for @xmath248 the number of terms in the sums increases by @xmath282 whereas at all remaining positions , with @xmath283 , the number of terms in the sums increases by one .",
    "now we expand the determinant and we deduce , from the multi - linearity and antisymmetric property of the determinant that the sums at positions @xmath281 can run over the whole range of index values , whereas the sums at the remaining positions pick up only maximal values of the summation index . otherwise in the determinants that result from the expansion there are at least two columns that are proportional to each other , hence the determinants are zero . in other words",
    "we have : @xmath284 from this follows the result ( [ eq : genvandemondefull ] ) .",
    "the final result ( [ eq : genvandemondefull2 ] ) follows from iterating ( [ eq : genvandemondefull1 ] ) . *",
    "q.e.d*.    * example 1 : * take @xmath285 and @xmath286 .",
    "then we have : @xmath287= \\label{eq : genvandemonde1 } \\\\ & & \\left(\\prod\\limits_{m\\ge j > i\\ge 1 } ( x_j - x_i)\\right ) \\cdot \\sum\\limits_{1\\le i_1 < \\dots",
    "< i_{m - j } \\le m } \\prod\\limits_{q=1}^{m - j } x_{i_q } \\label{eq : genvandemonde2 } \\end{aligned}\\ ] ] the last step ( [ eq : genvandemonde2 ] ) is proven by mathematical induction in @xmath1 , for example .",
    "in ( [ eq : matrixinverse ] ) we expressed the inverse matrix as the transposed matrix of algebraic complements and in ( [ eq : matrixinverse1 ] ) we used identity ( [ eq : genvandemonde2 ] ) to compute the algebraic complements . in ( [ eq : matrixinverse1a ] ) we evaluated the sum of the product in a recursive way as follows : @xmath291 with @xmath292 .",
    "the last equality has been obtained by computing the sums @xmath293 recursively for @xmath294 .",
    "here we noticed that the result is an order-@xmath108 polynomial in the column number @xmath221 , with the coefficient at the @xmath162^th^ power of @xmath221 being a polynomials in @xmath1 of order @xmath295 .",
    "the later polynomials satisfy recursion relations ( [ eq : polynomialsrecurs ] ) , which we verified using mathematica using the piece of code provided in appendix c. changing the variables @xmath296 and @xmath297 yields expression ( [ eq : inversevandermonde ] ) .",
    "now , we prove formula ( [ eq : inversevandermonde1 ] ) .",
    "in ( [ eq : matrixinverse1 ] ) we write for @xmath298 and for some @xmath299 .",
    "we split the product under the sum into a product of @xmath300 products such that , in the @xmath162^th^ product , the index @xmath210 runs within the range @xmath301 for @xmath302 with @xmath303 .",
    "then we change variables @xmath304 for @xmath301 .",
    "then we assume that the column index @xmath221 satisfies the following inequality @xmath305 .",
    "this implies that in the first @xmath306 products ( from left to right ) , all the indicator functions equal zero , in the @xmath162^th^ product some indicator functions are zero and the others are one , and finally , in the last @xmath307 products all the indicator functions equal unity .",
    "this allows us to factor out the term @xmath308 from the product and absorb it into the prefactor in ( [ eq : matrixinverse1 ] ) thus producing the binomial coefficient .",
    "the remaining sum over the values of the @xmath210 indices is left unevaluated .",
    "it is possible to obtain the large @xmath1 limit of that sum easily .",
    "[ appc ] here we give closed form expressions for certain polynomials that are used to invert the vandermonde matrix .",
    "the expressions have been obtained by solving the recursion relations in ( [ eq : polynomialsrecurs ] ) .",
    "then we have : @xmath309 here we attach a piece of code in the symbolic computation language mathematica .",
    "this code solves the recursion relations ( [ eq : polynomialsrecurs ] ) and verifies the result ( [ eq : inversevandermonde ] ) for the inverse of the vandermonde matrix .",
    "we solve the system of equations ( [ eq : syseq ] ) by gaussian elimination .",
    "we eliminate the @xmath310^th^ row , for @xmath311 , apply the identity @xmath312 , divide the equation by @xmath313 and easily arrive at the following result : @xmath314 the rows correspond to @xmath315 ( from top to bottom ) and the columns correspond to @xmath316 ( from left to right ) . in the bottom row",
    "there are @xmath317 zeros in columns @xmath318 . for brevity",
    "we have dropped the argument @xmath1 in the @xmath319 polynomials , i.e.  we have @xmath320 .",
    "the coefficients @xmath321 read : @xmath322 the quantities @xmath323 are polynomials of order @xmath324 ; they satisfy the following recursion relations : @xmath325 for @xmath326 ( row - wise ) and @xmath327 ( column - wise ) subject to @xmath328 . here",
    "the coefficients @xmath329 are defined in ( [ eq : polynomcoeffs ] ) . the result ( [ eq : recurrelscoeffs ] ) follows from inserting ( [ eq : coeffsrecurrels2 ] ) into the second equality on the right hand side in ( [ eq : coeffsrecurrels ] ) and performing the sum over @xmath108 using ( [ eq : binomidentity2 ] ) .",
    "from ( [ eq : gausselim ] ) we see that the solution to the system of equations ( [ eq : syseq ] ) depends on @xmath51 parameters .",
    "we choose the first @xmath51 reduced probabilities @xmath330 as the parameters . in each equation in ( [ eq : syseq ] )",
    "we move the last @xmath51 terms onto the right - hand side and we obtain a system of @xmath331 equations with an upper triangular quadratic matrix . we eliminate the consecutive variables and obtain the following solution : @xmath332 where @xmath333 for @xmath334 and @xmath335 and subject to @xmath205 and @xmath336 the step ( [ eq : reducedprobabilitiesfinal])@xmath337([eq : reducedprobabilitiesfinal1 ] ) follows from the fact that @xmath338 . here we denoted : @xmath339 the sum in ( [ eq : mode ] ) contains @xmath340 terms .",
    "now we compute the matrix elements @xmath341 in ( [ eq : matrelems ] ) for big values of @xmath1 .",
    "we have : @xmath342 & \\mbox{if $ \\lim_{m\\rightarrow \\infty } \\frac{i}{m } = \\gamma > 0 $ }   \\end{array } \\right .",
    "\\label{eq : largemlimitmodes4}\\end{aligned}\\ ] ] in ( [ eq : largemlimitmodes ] ) we used ( [ eq : coeffsrecurrels2 ] ) along with ( [ eq : recurrelscoeffs ] ) to transform the quantities @xmath343 and ( [ eq : polynomialsrecurs ] ) along with ( [ eq : pol11 ] ) to transform the quantities @xmath319 . in ( [ eq : largemlimitmodes1 ] ) we neglected the lower order powers of @xmath1 , we simplified the expression , and we performed the sum over @xmath344 using the binomial expansion formula . in ( [ eq : largemlimitmodes2 ] ) we simplified the expression . in ( [ eq : largemlimitmodes3 ] ) we substituted for @xmath345 and simplified the expression .",
    "finally in ( [ eq : largemlimitmodes3 ] ) we performed the sum over @xmath162 in the case of big values of @xmath346 and we expressed that sum through the hypergeometric function otherwise . since the latter sum is a hypergeometric sum and since necessary and sufficient conditions for such sums to be expressed in closed form are known ( see @xcite and references therein ) it would be interesting to check if a closed form expression can be also found in the latter case .    now we compute the quantities in ( [ eq : mode ] ) in the large-@xmath1 limit .",
    "we insert the top result in ( [ eq : largemlimitmodes4 ] ) into ( [ eq : mode ] ) and we do the sums over the ordered sequences by using identity ( [ eq : sumsimplexv ] ) for @xmath347 and @xmath348 . the final result reads @xmath349 where : @xmath350 where @xmath351"
  ],
  "abstract_text": [
    "<S> the law of large numbers tells us that as the sample size ( @xmath0 ) is increased , the sample mean converges on the population mean , provided that the latter exists . in this paper , we investigate the opposite effect : keeping the sample size fixed while increasing the number of outcomes ( @xmath1 ) available to a discrete random variable . </S>",
    "<S> we establish sufficient conditions for the variance of the sample mean to increase monotonically with the number of outcomes , such that the sample mean _ `` diverges '' _ from the population mean , acting like an _ `` reverse '' _ to the law of large numbers . </S>",
    "<S> these results , we believe , are relevant to many situations which require _ sampling _ of statistics of certain finite discrete random variables . </S>"
  ]
}