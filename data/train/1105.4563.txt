{
  "article_text": [
    "@xmath0one hundred years ago , in 1911 , toeplitz obtained a  deep result on eigenvalues of infinite matrices of the form @xmath1 .",
    "we say that @xmath2 is an eigenvalue of @xmath3 if the matrix @xmath4 does not have a  bounded inverse , where @xmath5 denotes the infinite - dimensional identity matrix .",
    "toeplitz proved that , interestingly , the set of eigenvalues is the same as the image set @xmath6\\}$ ] , where @xmath7 note that @xmath8 is the fourier transform of the sequence @xmath9 . for a  finite @xmath10 matrix @xmath11 ,",
    "its eigenvalues are approximately equally distributed ( in the sense of hermann weyl ) as @xmath12 , where @xmath13 are the fourier frequencies .",
    "see the excellent monograph by @xcite for a  detailed account .",
    "covariance matrix is of fundamental importance in many aspects of statistics including multivariate analysis , principal component analysis , linear discriminant analysis and graphical modeling .",
    "one can infer dependence structures among variables by estimating the associated covariance matrices . in the context of stationary time series analysis , due to stationarity , the covariance matrix is toeplitz in that , along the off - diagonals that are parallel to the main diagonal , the values are constant .",
    "let @xmath14 be a  stationary process with mean @xmath15 , and denote by @xmath16 $ ] , @xmath17 , its autocovariances .",
    "then @xmath18 is the autocovariance matrix of @xmath19 . in the rest of the paper for simplicity",
    "we also call  ( [ eqsgnd28238 ] ) the covariance matrix of @xmath19 . in time",
    "series analysis it plays a  crucial role in prediction [ @xcite , @xcite ] , smoothing and best linear unbiased estimation ( blue ) . for example , in the wiener ",
    "kolmogorov prediction theory , one predicts  @xmath20 based on past observations @xmath21 if the covariances @xmath22 were known , given observations @xmath23 , the coefficients of the best linear unbiased predictor @xmath24 in terms of the mean square error @xmath25 are the solution of the discrete wiener ",
    "hopf equation @xmath26 where @xmath27 and @xmath28 , and we use the superscript @xmath29 to denote the transpose of a  vector or a  matrix . if @xmath22 are not known , we need to estimate them from the sample @xmath23 , and a  good estimate of @xmath30 is required . as another example , suppose now @xmath31 and we want to estimate it from @xmath23 by the form @xmath32 , where @xmath33 satisfy the constraint @xmath34 . to obtain the blue , one minimizes @xmath35 subject to @xmath34 , ensuring unbiasedness .",
    "note that the usual choice @xmath36 may not lead to blue .",
    "the optimal coefficients are given by @xmath37 , where @xmath38 ; see @xcite .",
    "again a  good estimate of @xmath39 is needed .",
    "given observations @xmath40 , assuming at the outset that @xmath41 , we can naturally estimate @xmath30 via plug - in by the sample version @xmath42 to judge the quality of a  matrix estimate , we use the operator norm .",
    "the term `` operator norm '' usually indicates a  class of matrix norms ; in this paper it refers to the @xmath43 operator norm or spectral radius defined as @xmath44 is a  real vector , and @xmath45 denotes its euclidean norm . for the estimate @xmath46 in  ( [ eqscovd29945 ] ) , unfortunately , because too many parameters or autocovariances are estimated and the signal - to - noise ratios are too small at large lags , this estimate is not consistent .",
    "@xcite showed that @xmath47 in probability . in section  [ secinconsistency ]",
    "we provide a  precise order of magnitude of @xmath48 and give explicit upper and lower bounds .",
    "the inconsistency of sample covariance matrices has also been observed in the context of high - dimensional multivariate analysis , and this phenomenon is now well understood , thanks to the results from random matrix theory .",
    "see , among others , @xcite , @xcite and @xcite .",
    "recently , there is a  surge of interest on regularized covariance matrix estimation in high - dimensional statistical inference .",
    "we only sample a  few works which are closely related to our problem . @xcite , @xcite and @xcite studied the banding and/or tapering methods , while @xcite and @xcite considered the regularization by thresholding . in most of these works ,",
    "convergence rates of the estimates were established .    however",
    ", none of the techniques used in the aforementioned papers is applicable in our setting since their estimates require multiple independent and identically distributed ( i.i.d . )",
    "copies of random vectors from the underlying multivariate distribution , though the number of copies can be far less than the dimension of the vector . in time",
    "series analysis , however , it is typical that only one realization is available . hence we shall naturally use the sample autocovariances . in a  companion paper , @xcite established a  systematic theory for @xmath49 and @xmath50 deviations of sample autocovariances . based on that , we adopt the regularization idea and study properties of the banded , tapered and thresholded estimates of the covariance matrices . @xcite and @xcite applied the banding and tapering methods to the same problem , but here we shall obtain a  better and optimal convergence rate .",
    "we shall point out that the regularization ideas of banding and tapering are not novel in time series analysis and they have been applied in nonparametric spectral density estimation .",
    "in this paper we use the ideas in @xcite and @xcite together with wu s ( @xcite ) recent theory on stationary processes to present a  systematic theory for estimates of covariance matrices of stationary processes .",
    "in particular , we shall exploit the connection between covariance matrices and spectral density functions and prove a  sharp convergence rate for banded covariance matrix estimates of stationary processes . using convergence properties of periodograms ,",
    "we derive a  precise order of magnitude for spectral radius of sample covariance matrices .",
    "we also consider a  thresholded covariance matrix estimator that can better characterize sparsity if the true covariance matrix is sparse . as a  main technical tool",
    ", we develop a  large deviation type result for quadratic forms of stationary processes using @xmath51-dependence approximation , under the framework of causal representations and physical dependence measures .",
    "the rest of this article is organized as follows . in section [ secinconsistency ]",
    "we introduce the framework of causal representation and physical dependence measures that are useful for studying convergence properties of covariance matrix estimates .",
    "we provide in section  [ secinconsistency ] upper and lower bounds for the operator norm of the sample covariance matrices .",
    "the convergence rates of banded / tapered and thresholded sample covariance matrices are established in sections  [ secbanding ] and [ secthresholding ] , respectively .",
    "we also conduct a  simulation study to compare the finite sample performances of banded and thresholded estimates in section  [ secsimulation ] .",
    "some useful moment inequalities are collected in section  [ sec6 ] . a  large deviation result about quadratic forms of stationary processes , which is of independent interest ,",
    "is given in section  [ secld ] .",
    "section [ secconclude ] concludes the paper .",
    "we now introduce some notation . for a  random variable @xmath52 and @xmath53",
    ", we write @xmath54 if @xmath55 , and use @xmath56 as a  shorthand for @xmath57 . to express centering of random variables concisely ,",
    "we define the operator @xmath58 as @xmath59 .",
    "hence @xmath60 . for a  symmetric real matrix @xmath61",
    ", we use @xmath62 and @xmath63 for its smallest and largest eigenvalues , respectively , and use @xmath64 to denote its operator norm or spectral radius . for a  real number @xmath65 , @xmath66 denotes its integer part and @xmath67 . for two real numbers @xmath68 , set @xmath69 and @xmath70 . for two sequences of positive numbers",
    "@xmath71 and @xmath72 , we write @xmath73 if there exists some constant @xmath74 such that @xmath75 for all @xmath76 . the letter @xmath77 denotes a  constant , whose values may vary from place to place .",
    "we sometimes add symbolic subscripts to emphasize that the value of @xmath77 depends on the subscripts .",
    "suppose @xmath78 is a  @xmath79 random matrix consisting of i.i.d .",
    "entries with mean 0 and variance  1 , which could be viewed as a  sample of size @xmath80 from some @xmath81-dimensional population ; then @xmath82 is the sample covariance matrix .",
    "if @xmath83 , then @xmath82 is not a  consistent estimate of the population covariance matrix ( which is the identity matrix ) in term of the operator norm .",
    "this is a  well - known phenomenon in random matrices literature ; see , for example , @xcite , section 5.2 in @xcite , @xcite and @xcite .",
    "however , the techniques used in those papers are not applicable here , because we have only one realization and the dependence within the vector can be quite complicated .",
    "thanks to the toeplitz structure of @xmath84 , our method depends on the connection between its eigenvalues and the spectral density , defined by @xmath85 the following lemma is a  special case of section 5.2 [ @xcite ] .    [ thmtoeplitz ] let @xmath86 be a  continuous symmetric function on @xmath87 $ ] . denote by @xmath88 and @xmath89 its minimum and maximum , respectively . define @xmath90 and the @xmath91 matrix @xmath92 ; then @xmath93    lemma  [ thmtoeplitz ] can be easily proved by noting that @xmath94 the sample covariance matrix  ( [ eqscovd29945 ] ) is closely related to the periodogram @xmath95 by lemma  [ thmtoeplitz ] , we have @xmath96 .",
    "asymptotic properties of periodograms have recently been studied by @xcite and @xcite . to introduce the result in the latter paper ,",
    "we assume that the process @xmath97 has the causal representation @xmath98 where @xmath99 is a  measurable function such that @xmath100 is well defined , and @xmath101 , are i.i.d",
    ". random variables . the framework ( [ eqcausal ] )",
    "is very general [ see , e.g. , @xcite ] and easy to work with . let @xmath102 be the set of innovations up to time  @xmath103 ; we write @xmath104 .",
    "let @xmath105 , be an i.i.d .",
    "copy of @xmath101 .",
    "define @xmath106 , obtained by replacing  @xmath107 in  @xmath108 by @xmath109 , and set @xmath110 .",
    "following @xcite , for @xmath53 , define @xmath111 in @xcite , the quantity @xmath112 is called _ physical dependence measure_. we make the convention that @xmath113 for @xmath114 . throughout the article",
    ", we assume the _ short - range dependence _",
    "condition @xmath115 . under a  mild condition on the tail sum @xmath116 ( cf .",
    "theorem  [ thminconsistency ] ) , @xcite obtained the weak convergence result @xmath117 where @xmath118 denotes the convergence in distribution , @xmath119 is the gumbel distribution with the distribution function @xmath120 , and @xmath121 . using this result",
    ", we can provide explicit upper and lower bounds on the operator norm of the sample covariance matrix .",
    "[ thminconsistency ] assume @xmath122 for some @xmath123 and @xmath41 .",
    "if @xmath124 and @xmath125 , then @xmath126 ^ 2 \\log t}{12\\theta_2 ^ 2 } \\leq\\lambda({\\hat\\sigma_{{{t } } } } ) \\leq10\\theta_2 ^ 2 \\log t \\biggr\\ } = 1.\\ ] ]    according to lemma  [ thmtoeplitz ] , we know @xmath127 . as an immediate consequence of theorem  [ thminconsistency ] , there exists a  constant @xmath74 such that @xmath128 = 1,\\ ] ] which means the estimate @xmath46 is not consistent , and the order of magnitude of @xmath48 is @xmath129 .",
    "earlier , @xcite also showed that the plug - in estimate @xmath130 is not consistent , namely , @xmath131 in probability .",
    "our proposition [ thminconsistency ] substantially refines this result by providing an exact order of magnitude of @xmath132 .",
    "@xcite showed that under suitable conditions , for linear processes with i.i.d .",
    "innovations , @xmath133 \\ } = 1 \\qquad\\mbox{almost surely.}\\ ] ] a  stronger version was found by @xcite for gaussian processes . based on  ( [ eqd306 ] )",
    ", we conjecture that @xmath134 @xcite established the following result on the maximum periodogram of a  sequence of i.i.d .",
    "standard normal random variables : @xmath135 in view of  ( [ eqlin ] ) and  ( [ eqturkman ] ) , we conjecture that @xmath136 also converges to the gumbel distribution after proper centering and rescaling .",
    "note that the gumbel convergence  ( [ eqturkman ] ) , where the maximum is taken over the entire interval @xmath137 $ ] , has a  different centering term from the one in  ( [ eqlin ] ) which is obtained over fourier frequencies .    if @xmath78 is a  @xmath138 random matrix consisting of i.i.d .",
    "entries , @xcite and @xcite proved a  strong convergence result for the largest eigenvalues of @xmath139 , in the paradigm where @xmath140 such that @xmath141 .",
    "see also @xcite and references therein . if in addition the entries of @xmath78 are i.i.d .",
    "complex normal or normal random variables , @xcite and @xcite presented an asymptotic distributional theory and showed that , after proper normalization , the limiting distribution of the largest eigenvalue follows the tracy  widom law [ @xcite ] . again , their methods depend heavily on the setup that there are i.i.d",
    ". copies of a  random vector with independent entries , and/or the normality assumption , so they are not applicable here .",
    "@xcite studied the limiting spectral distribution ( lsd ) of random toeplitz matrices whose entries on different sub - diagonals are i.i.d . @xcite considered the lsd of sample covariances matrices generated by a  sample which is temporally dependent .",
    "proof of theorem  [ thminconsistency ] for notational simplicity we let @xmath142 and @xmath143 .",
    "it follows immediately from  ( [ eqlin ] ) that for any @xmath144 @xmath145 = 1.\\ ] ] the result in  ( [ eqlin ] ) is not sufficient to yield an upper bound of @xmath146 . for this purpose",
    "we need to consider the maxima over a  finer grid and then use lemma  [ thmzygmund ] to extend to the maxima over the whole real line . set @xmath147 and @xmath148 for @xmath149 .",
    "define @xmath150 for some @xmath151 , and @xmath152 .",
    "let @xmath153 be the fourier transform of @xmath154 , and @xmath155 for the @xmath156-dependent sequence @xmath157 .",
    "by lemma 3.4 of @xcite , we have @xmath158 now partition the interval @xmath159 $ ] into blocks @xmath160 of size @xmath156 , where @xmath161 , and the last block may have size @xmath162 .",
    "define the block sum @xmath163 for @xmath164 .",
    "choose @xmath165 small enough such that for some @xmath166 , the inequality @xmath167 holds .",
    "we use truncation and define @xmath168 $ ] . using similar arguments as equation ( 5.5 ) [ @xcite ] and  ( [ eq9 ] ) , we have @xmath169\\biggr| = o_p ( ( \\log t)^{-1/2}).\\ ] ] observe that @xmath170 and @xmath171 are independent if @xmath172 .",
    "let @xmath173 denote the real part of a  complex number @xmath174 .",
    "split the sum @xmath175 into four parts @xmath176 and @xmath177 , @xmath178 similarly for the imaginary part of @xmath179 .",
    "since @xmath180 , by bernstein s inequality [ cf .",
    "@xcite ] , @xmath181 \\leq2\\exp\\biggl\\{-\\frac{({9}/{8})\\log t } { 1 + 3\\theta_2^{-1}\\sqrt{2\\log t } t^{\\gamma-1/2}}\\biggr\\}\\ ] ] for @xmath182 .",
    "it follows that @xmath183 = 0.\\ ] ] combining  ( [ eq8 ] ) ,  ( [ eq10 ] ) and  ( [ eq11 ] ) , we have @xmath184 = 1,\\ ] ] which together with lemma  [ thmzygmund ] implies that @xmath185 = 1.\\ ] ] the upper bound in theorem  [ thminconsistency ] is an immediate consequence in view of lemma  [ thmtoeplitz ] . for the lower bound",
    ", we use the inequality @xmath186 where @xmath187 is defined in  ( [ eqrho ] ) , and @xmath188 is its hermitian transpose . note that @xmath189 by bernstein s inequality on the derivative of trigonometric polynomials [ cf .",
    "@xcite , theorem 3.13 , chapter x ] , we have @xmath190 let @xmath191 .",
    "set @xmath192 . by lemma  [ thmtoeplitz ] and  ( [ eqfact4 ] ) , we know @xmath193 , and hence @xmath194 .",
    "if @xmath195 and @xmath196 , then for @xmath197 , we have @xmath198\\log t = ( 1-\\delta)\\pi\\underline{f } \\log t.\\vadjust{\\goodbreak}\\ ] ] since @xmath199 when @xmath197 , it follows that @xmath200 which implies that @xmath201 .",
    "the proof is completed by selecting @xmath202 small enough .    in the proof , as well as many other places in this article , we often need to partition an integer interval @xmath203\\subset{{\\mathbb{n}}}$ ] into consecutive blocks @xmath204 with the same size @xmath51 .",
    "since @xmath205 may not be a  multiple of @xmath51 , we make the convention that the last block @xmath206 has the size @xmath207 , and all the other ones have the same size @xmath51 .",
    "in view of lemma  [ thmtoeplitz ] , the inconsistency of @xmath46 is due to the fact that the periodogram @xmath208 is not a  consistent estimate of the spectral density @xmath209 . to estimate the spectral density consistently ,",
    "it is very common to use smoothing . in particular , consider the lag window estimate @xmath210 where @xmath211 is the bandwidth satisfying natural conditions @xmath212 and @xmath213 , and @xmath214 is a  symmetric kernel function satisfying @xmath215 correspondingly , we define the tapered covariance matrix estimate @xmath216_{1\\leq s , t\\leq{{t } } } = \\hat\\sigma_{{{t } } } \\star w_{{{t}}},\\ ] ] where @xmath217 is the hadamard ( or schur ) product , which is formed by element - wise multiplication of matrices .",
    "the term `` tapered '' is consistent with the terminology of the high - dimensional covariance regularization literature . however",
    ", the reader should not confuse this with the notion `` data taper '' that is commonly used in time series analysis .",
    "our tapered estimate parallels a  lag - window estimate of the spectral density with a  tapered window . as a  special case ,",
    "if @xmath218 is the rectangular kernel , then @xmath219 is the banded sample covariance matrix .",
    "however , this estimate may not be nonnegative definite . to obtain a  nonnegative definite estimate , by the schur product theorem in matrix theory [ @xcite ] , since @xmath46 is nonnegative definite , their schur product @xmath220 is also nonnegative definite if @xmath221_{1 \\le s , t \\leq t}$ ] is nonnegative definite .",
    "the bartlett or triangular window @xmath222 leads to a  positive definite weight matrix @xmath223 in view of @xmath224 where @xmath225 is the rectangular window .",
    "any kernel function having form  ( [ eqpos - def - mat ] ) must be positive definite . here",
    "we shall show that @xmath220 is a  consistent estimate of @xmath30 and establish a  convergence rate of @xmath226 .",
    "we first consider the bias . by the gergorin theorem [ cf .",
    "@xcite , theorem 6.1.1 ] , we have @xmath227 , where @xmath228|\\gamma_k| + \\frac{2}{t}\\sum_{k=1}^{b_{{{t } } } } k|\\gamma_k| + 2\\sum_{k = b_{{{t}}}+1}^{{{t}}-1}|\\gamma_k|.\\ ] ] the first term on the right - hand side in  ( [ eqbias ] ) is due to the choice of the kernel function , whose order of magnitude is determined by the smoothness of @xmath229 at zero . in particular , this term vanishes if @xmath229 is the rectangular kernel . if @xmath230 at @xmath231 and @xmath232 , @xmath233 , then @xmath234 if @xmath235 , @xmath236 if @xmath237 and @xmath238 if @xmath239 . generally , if @xmath240 , then @xmath241 as @xmath242 and @xmath243 .",
    "it is more challenging to deal with @xmath244 .",
    "if @xmath122 for some @xmath245 and @xmath41 , @xcite obtained @xmath246 the key step of their method is to use the inequality @xmath247 , @xmath248 since @xmath249 is a  trigonometric polynomial of order @xmath211 , we can bound its maximum by the maximum over a  fine grid .",
    "the following lemma is adapted from @xcite , theorem 7.28 , chapter x.    [ thmzygmund ] let @xmath250 $ ] be a  trigonometric polynomial of order @xmath80 . for any @xmath251 , @xmath144 and @xmath252 , let @xmath253 for @xmath254 ;",
    "then @xmath255    for @xmath144 , let @xmath256 for @xmath257 ; then by lemma  [ thmzygmund ] , @xmath258    [ thmbanded ] assume @xmath122 with some @xmath259 , @xmath41 , and @xmath260 .",
    "choose the banding parameter @xmath211 to satisfy @xmath261 , and @xmath262 , for some @xmath263 then for @xmath264 defined in  ( [ eqbias ] ) , and @xmath265 , @xmath266 = 1.\\ ] ] in particular , if @xmath267 and @xmath268 , then @xmath269.\\ ] ]    in view of  ( [ eqbias ] ) , to prove  ( [ eqtapered ] ) we only need to show that @xmath270 = 1.\\ ] ] by  ( [ eqtoeplitz1 ] ) and  ( [ eqgrid ] ) where we take @xmath271 , the problem is reduced to @xmath272 = 1.\\hspace*{-15pt}\\ ] ] by theorem  [ thmldquadratic ] ( where we take @xmath273 ) , for any @xmath274 , there exists a  constant @xmath275 such that @xmath276\\nonumber \\\\ & & \\qquad\\leq c_{p,\\beta } ( tb_{{{t}}})^{-p/4 } ( \\log t ) [ ( tb_{{{t}}})^{p/4}t^{-\\alpha\\beta p/2 } + tb_{{{t}}}^{p/2 - 1-\\alpha\\beta p/2 } + t]\\\\ & & \\qquad\\quad{}+ c_{p,\\beta } b_{{{t}}}^{-2}. \\nonumber\\end{aligned}\\ ] ] if  ( [ eqdecayrate ] ) holds , there exist a  @xmath151 such that @xmath277 and @xmath278 .",
    "it follows that by  ( [ eq32 ] ) , @xmath279 \\\\ & & \\qquad\\leq c_{p,\\beta } ( \\log t ) \\bigl[t^{\\gamma-\\alpha\\beta p/2 } + t^{1-p/4 } + t^{(p/4-\\alpha\\beta p/2)\\gamma-(p/4 - 1 ) } \\bigr ] + c_{p,\\beta}b_{{{t}}}^{-1 } \\\\ & & \\qquad= o(1).\\end{aligned}\\ ] ] therefore ,  ( [ eq7 ] ) holds and the proof of  ( [ eqtapered ] ) is complete .",
    "the last statement  ( [ eqbanded ] ) is an immediate consequence .",
    "details are omitted .",
    "[ rkcentering ] in practice , @xmath280 is usually unknown , and we estimate it by @xmath281 .",
    "let @xmath282 , and @xmath283 be defined as @xmath284 by replacing @xmath285 therein by @xmath286 . since @xmath287 , it is easily seen that @xmath288 .",
    "therefore , the results of theorem  [ thmbanded ] hold for @xmath289 as well .",
    "in the proof of theorem  [ thmbanded ] , we have shown that , as an intermediate step from  ( [ eq7 ] ) to  ( [ eqrandom ] ) , @xmath290 = 1.\\hspace*{-22pt}\\ ] ] the above uniform convergence result is very useful in spectral analysis of time series .",
    "@xcite obtained the weaker version @xmath291 under a  stronger assumption that @xmath292 for some @xmath293 .",
    "for linear processes , @xcite derived the asymptotic distribution of the maximum deviations of spectral density estimates .",
    "@xcite generalized their result to nonlinear processes and showed that the limiting distribution of @xmath294 is gumbel after suitable centering and rescaling , under stronger conditions than  ( [ eqdecayrate ] ) . with their result , and using similar arguments as theorem  [ thminconsistency ] , we can show that for some constant @xmath295 , @xmath296=1,\\ ] ] which means that the convergence rate we have obtained in ( [ eqrandom ] ) is optimal .",
    "[ rem5 ] the convergence rate @xmath297 in theorem  [ thmbanded ] is optimal .",
    "consider a  process @xmath97 which satisfies @xmath298 and when @xmath299 , @xmath300 where @xmath301 and @xmath302 is an even integer such that @xmath303 .",
    "consider the banded estimate @xmath220 with the rectangular kernel .",
    "as shown in the supplementary article [ @xcite ] , there exists a  constant @xmath304 such that @xmath305 = 1,\\ ] ] suggesting that the convergence rate given in  ( [ eqtapered ] ) of theorem  [ thmbanded ] is optimal .",
    "this optimality property can have many applications .",
    "for example , it can allow one to derive convergence rates for estimates of @xmath306 in the wiener ",
    "hopf equation , and the optimal weights @xmath307 in the best linear unbiased estimation problem mentioned in the .",
    "we now compare  ( [ eqwu2009 ] ) and our result . for @xmath308 , ( [ eqwu2009 ] )",
    "gives the order @xmath309 .",
    "our result  ( [ eqrandom ] ) is sharper by moving the bandwidth @xmath211 inside the square root .",
    "we pay the costs of a  logarithmic factor , a  higher order moment condition ( @xmath259 ) , as well as conditions on the decay rate of tail sum of physical dependence measures  ( [ eqdecayrate ] ) .",
    "note that when @xmath310 , the last two conditions of ( [ eqdecayrate ] ) hold automatically , so we merely need @xmath311 , allowing a  very wide range of @xmath211 . in comparison , for  ( [ eqwu2009 ] ) to be useful ,",
    "one requires @xmath312 .",
    "the convergence rate  ( [ eqwu2009 ] ) of @xcite parallels the result of @xcite in the context of high - dimensional multivariate analysis , which was improved in @xcite by constructing a  class of tapered estimates .",
    "our result parallels the optimal minimax rate derived in @xcite , though the settings are different .",
    "theorem  [ thmbanded ] uses the operator norm . for",
    "the frobenius norm see @xcite where a  central limit theory for @xmath313 and @xmath314 is established .",
    "in the context of time series , the observations have an intrinsic temporal order and we expect that observations are weakly dependent if they are far apart , so banding seems to be natural .",
    "however , if there are many zeros or very weak correlations within the band , the banding method does not automatically generate a  sparse estimate .",
    "the rationale behind the banding operation is sparsity , namely autocovariances with large lags are small , so it is reasonable to estimate them as zero . applying the same idea to the sample covariance matrix , we can obtain an estimate of @xmath30 by replacing small entries in @xmath46 with zero .",
    "this regularization approach , termed _",
    "hard thresholding _ , was originally developed in nonparametric function estimation .",
    "it has recently been applied by @xcite and @xcite as a  method of covariance regularization in the context of high - dimensional multivariate analysis .",
    "since they do not assume any order of the observations , their sparsity assumptions are permutation - invariant . unlike their setup , we still use @xmath116 [ cf .",
    "( [ eqtspdm ] ) ] and @xmath315 as our weak dependence conditions , where @xmath316 and @xmath317 is given in  ( [ eqmarzyg ] ) .",
    "this is natural for time series analysis .",
    "let @xmath318 , where @xmath319 is the constant given in lemma  [ thmmaximumdeviation ] .",
    "the thresholded sample autocovariance matrix is defined as @xmath320 with the convention that the diagonal elements are never thresholded .",
    "we emphasize that the thresholded estimate may not be positive definite .",
    "the following result says that the thresholded estimate is also consistent in terms of the operator norm , and provides a  convergence rate which parallels the banding approach in section  [ secbanding ] . in the proof",
    "we compare the thresholded estimate @xmath321 with the banded one @xmath322 for some suitably chosen @xmath211 .",
    "this is merely a  way to simplify the arguments .",
    "the same results can be proved without referring to the banded estimates .",
    "[ thmthresholding ] assume @xmath122 with some @xmath259 , @xmath41 , and @xmath323 , @xmath324 for some @xmath325 . if @xmath326 then @xmath327.\\ ] ]    condition  ( [ eqdecayrate2 ] ) is only required for lemma  [ thmmaximumdeviation ] .",
    "as commented by @xcite , it can be reduced to @xmath328 for linear processes .",
    "see remark  2 of their paper for more details .",
    "the key step for proving theorem  [ thmthresholding ] is to establish a  convergence rate for the maximum deviation of sample autocovariances .",
    "the following lemma is adapted from theorem 3 of @xcite , where the asymptotic distribution of the maximum deviation was also studied .",
    "[ thmmaximumdeviation ] assume the conditions of theorem  [ thmthresholding ] .",
    "then @xmath329 where @xmath330 .",
    "proof of theorem  [ thmthresholding ] let @xmath331 , and @xmath220 be the banded sample covariance matrix with the rectangular kernel . recall that @xmath332 from ( [ eqbias ] ) . by lemma  [ thmmaximumdeviation ] , we have @xmath333 write the thresholded estimate @xmath334 , where @xmath335 and @xmath336 on the other hand , @xmath337 the term @xmath338 is dominated by @xmath264 . by lemma  [ thmmaximumdeviation ] , we know @xmath339 for the remaining term @xmath340 , note that the number of @xmath22 such that @xmath341 and @xmath342 is bounded by @xmath343 ; therefore by lemma  [ thmmaximumdeviation ] @xmath344 putting  ( [ eq12 ] ) ,  ( [ eq14 ] ) ,  ( [ eq15 ] ) and ( [ eq16 ] ) together , the proof is complete .    if the mean @xmath280 is unknown , we need to replace @xmath285 by @xmath286 ( remark  [ rkcentering ] ) .",
    "since lemma  [ thmmaximumdeviation ] still holds when @xmath285 are replaced by @xmath286 [ @xcite ] , theorem  [ thmthresholding ] remains true for @xmath286 .",
    "the thresholded estimate is desirable in that it can lead to a  better estimate when there are a  lot of zeros or very weak autocovariances .",
    "unfortunately , due to technical difficulties , the theoretical result ( cf . theorem  [ thmthresholding ] ) does not reflect this advantage .",
    "we show by simulations that thresholding does have a  better finite sample performance over banding when the true autocovariance matrix is sparse .",
    "consider two linear processes @xmath345 and @xmath346 , where @xmath347 , and when @xmath348 @xmath349 for some @xmath350 and @xmath351 ; and @xmath352 s are taken as i.i.d .",
    "@xmath353 . let @xmath354 , @xmath355 , and @xmath356 , @xmath357 denote the autocovariances and autocovariance matrices of the two processes , respectively .",
    "it is easily seen that @xmath358 if @xmath359 is odd .",
    "in fact , @xmath360 can be obtained by interlacing two i.i.d .",
    "copies of @xmath97 . for a  given set of centered observations @xmath40 , assuming that its true autocovariance matrix is known , for a  fair comparison we choose the optimal bandwidth @xmath211 and threshold @xmath361 as @xmath362 the two parameters for the @xmath360 process are chosen in the same way . in all the simulations we set @xmath363 . for different combinations of the sample size  @xmath76 and the parameter",
    "@xmath364 which controls the decay rate of autocovariances , we report the average distances in term of the operator norm of the two estimates @xmath365 and @xmath366 from @xmath30 , as well as the standard errors based on 1000 repetitions . we also give the average bandwidth of @xmath365 . instead of reporting the average threshold for @xmath366 , we provide the average number of nonzero autocovariances appearing in the estimates , which is comparable to the average bandwidth of @xmath367 .",
    "@lc ccd2.8d2.8d2.8@ & & & + & & & + & & & & & & + 0.2 & 2.94 ( 1.17 ) & 9.55 ( 6.60 ) & 3.01 ( 1.22 ) & 13.4  ( 7.67 ) & 2.96(1.23 ) & 23.4  ( 13.1 ) + & 3.66 ( 1.07 ) & 5.40 ( 4.87 ) & 3.88 ( 1.14 ) & 7.39  ( 5.81 ) & 4.08  ( 1.17 ) & 12.5  ( 10.1 ) + & 6.98 ( 2.63 ) & & 8.12 ( 2.85 ) & & 10.57  ( 3.93 ) & + [ 3pt ] 0.5 & 1.52 ( 0.68 ) & 6.31 ( 4.58 ) & 1.38 ( 0.60 ) & 8.46  ( 5.57 ) & 1.15(0.50 ) & 11.9  ( 7.67 ) + & 1.90 ( 0.64 ) & 3.49 ( 2.56 ) & 1.89 ( 0.59 ) & 4.15  ( 3.07 ) & 1.74  ( 0.54 ) & 5.15  ( 3.27 ) + & 5.55 ( 2.37 ) & & 6.73 ( 2.91 ) & & 8.88  ( 3.28 ) & + [ 3pt ] @xmath368 & 0.82 ( 0.39 ) & 4.04 ( 2.33 ) & 0.69 ( 0.32 ) & 4.62  ( 2.47 ) & 0.52  ( 0.24 ) & 5.68  ( 3.06 ) + & 1.03 ( 0.38 ) & 2.24 ( 0.87 ) & 0.95 ( 0.32 ) & 2.29  ( 0.74 ) & 0.81  ( 0.29 ) & 2.58(0.83 ) + & 4.80 ( 2.14 ) & & 6.05 ( 2.25 ) & & 7.81  ( 2.64 ) & +    from table  [ tabx ] , we see that for the process @xmath97 , the banding method outperforms the thresholding one , but the latter does give sparser estimates . for the process",
    "@xmath360 , according to table  [ taby ] , we find that thresholding performs better than banding when the sample size is not very large ( @xmath369 ) , and yields sparser estimates as well .",
    "the advantage of thresholding in error disappears when the sample size is  500 . intuitively speaking ,",
    "banding is a  way to threshold according to the truth ( autocovariances with large lags are small ) , while thresholding is a  way to threshold according to the data .",
    "therefore , if the autocovariances are nonincreasing as for the process @xmath97 , or if the sample size is large enough , banding is preferable . if the autocovariances do not vary regularly as for the process @xmath360 and the sample size is moderate , thresholding is more adaptive . as a  combination , in practice we can use a  thresholding - after - banding estimate which enjoys both advantages .",
    "@lc ccd2.8d2.8d2.8@ & & & + & & & + & & & & & & + 0.2 & 3.33 ( 0.86 ) & 9.87 ( 6.89 ) & 3.54 ( 0.95 ) & 13.7  ( 7.67 ) & 3.61(1.07 ) & 24.7  ( 13.1 ) + & 3.15 ( 0.93 ) & 3.95 ( 3.50 ) & 3.43 ( 1.00 ) & 5.69  ( 4.72 ) & 3.75  ( 1.08 ) & 9.23  ( 8.04 ) + & 7.21 ( 4.28 ) & & 8.69 ( 4.79 ) & & 11.1  ( 5.31 ) & + [ 3pt ] 0.5 & 1.98 ( 0.61 ) & 7.26 ( 5.32 ) & 1.88 ( 0.59 ) & 9.95  ( 6.44 ) & 1.63(0.53 ) & 16.3  ( 10.1 ) + & 1.81 ( 0.60 ) & 2.93 ( 2.41 ) & 1.81 ( 0.59 ) & 3.44  ( 2.22 ) & 1.71  ( 0.54 ) & 4.64  ( 2.97 ) + & 5.88 ( 3.27 ) & & 7.25 ( 3.59 ) & & 9.25  ( 3.72 ) & + [ 3pt ] @xmath368 & 1.19 ( 0.41 ) & 5.31 ( 3.33 ) & 1.01 ( 0.35 ) & 6.20  ( 3.58 ) & 0.79  ( 0.28 ) & 8.28  ( 4.95 ) + & 1.02 ( 0.39 ) & 2.16 ( 0.65 ) & 0.92 ( 0.32 ) & 2.21  ( 0.57 ) & 0.80  ( 0.28 ) & 2.52  ( 0.77 ) + & 5.09 ( 2.77 ) & & 6.39 ( 2.79 ) & & 8.18  ( 2.91 ) & +    apparently our simulation is a  very limited one , because we assume that the true autocovariance matrices are known . practitioners would need a  method to choose the bandwidth and/or threshold from the data .",
    "although theoretical results suggest convergence rates of banding and thresholding parameters which lead to optimal convergence rates of the estimates , they do not offer much help for finite samples .",
    "the issue was addressed by @xcite incorporating the idea of risk minimization from @xcite and the technique of subsampling from @xcite , and by @xcite using the rule introduced in @xcite for selecting the bandwidth in spectral density estimation .",
    "an alternative method is to use the block length selection procedure in @xcite which is designed for spectral density estimation .",
    "we shall study other data - driven methods in the future .",
    "this section presents some moment inequalities that will be useful in the subsequent proofs . in lemma  [ lemmmtinq ]",
    ", the case @xmath370 follows from @xcite and the other case @xmath371 is due to @xcite .",
    "lemma  [ thmfacts ] is adopted from proposition 1 of @xcite .",
    "[ lemmmtinq ] let @xmath372 and @xmath373 ; let  @xmath374 , @xmath375 , be martingale differences , and @xmath376 for every @xmath103 .",
    "write @xmath377 .",
    "then @xmath378    it is convenient to use @xmath51-dependence approximation for processes with the form  ( [ eqcausal ] ) . for @xmath379 , define @xmath380 be the @xmath381-field generated by the innovations @xmath382 and the projection operator @xmath383 and @xmath384 . observe that @xmath385 is a  martingale difference sequence with respect to the filtration @xmath386 . for @xmath387 , define @xmath388 ; then @xmath389 [ see proposition 1 of @xcite for a  proof ] , and @xmath390 is an @xmath391-dependent sequence .",
    "[ thmfacts ] assume @xmath41 and @xmath372 .",
    "for @xmath392 , define @xmath393 .",
    "let @xmath394 be the physical dependence measure for the sequence  @xmath395",
    ". then @xmath396\\nonumber\\end{aligned}\\ ] ] @xmath397 where @xmath398",
    "in this section we prove a  result on probabilities of large deviations of quadratic forms of stationary processes , which take the form @xmath399 the coefficients @xmath400 may depend on @xmath76 , but we suppress @xmath76 from subscripts for notational simplicity . throughout this section",
    "we assume that @xmath401 , and @xmath402 when @xmath403 , where @xmath211 satisfies @xmath404 , and @xmath405 for some @xmath311 .",
    "large deviations for quadratic forms of stationary processes have been extensively studied in the literature . @xcite and @xcite obtained the _ large deviation principle _ [ @xcite ] for gaussian processes .",
    "@xcite considered the functional large deviation principle .",
    "@xcite obtained a  more accurate expansion of the tail probabilities .",
    "@xcite extended the results of @xcite to locally stationary gaussian processes .",
    "in fact , our result is more relevant to the so - called _ moderate deviations _ according to the terminology of @xcite .",
    "@xcite and @xcite obtained _ moderate deviation principles _ for quadratic forms of gaussian processes .",
    "@xcite studied moderate deviations of periodograms of linear processes . @xcite",
    "considered the cramr - type moderate deviation for spectral density estimates of gaussian processes ; see also @xcite .",
    "@xcite derived the cramr - type moderate deviation for maxima of periodograms under the assumption that the process consists of i.i.d .",
    "random variables .    for our purpose ,",
    "on one hand , we do not need a  result that is as precise as the moderate deviation principle or the cramr - type moderate deviation .",
    "on the other hand , we need an upper bound for the tail probability under less restrictive conditions .",
    "specifically , we would like to relax the gaussian , linear or i.i.d .",
    "assumptions which were made in the precedent works .",
    "@xcite provided a  result in this fashion under the assumption of boundedness of the cumulant spectra up to a  finite order . while this type of assumption holds under certain mixing conditions , the latter themselves are not easy to verify in general and many well - known examples are not strong mixing [ @xcite ] .",
    "we mean to impose alternative conditions through physical dependence measures , which are easy to use in many applications [ @xcite ] .",
    "furthermore , our result can be sharper ; see remark  [ rkrudzkis ] .",
    "our main tool is the @xmath51-dependence approximation . in the next lemma we use dependence measures to bound the @xmath406 norm of the distance between  @xmath407 and the @xmath51-dependent version @xmath408 .",
    "the proof and a  few remarks on the optimality of the result are given in the supplementary article [ @xcite ] .",
    "[ thmmappquadratic ] assume @xmath122 with @xmath409 , @xmath41 and @xmath410 .",
    "let @xmath411 and @xmath412 ; then @xmath413.\\end{aligned}\\ ] ]    the following theorem is the main result of this section .",
    "[ thmldquadratic ] assume @xmath122 , @xmath259 , @xmath41 , and @xmath260 .",
    "set @xmath414 .",
    "for any @xmath415 , let @xmath416 .",
    "assume that @xmath212 and @xmath417 for some @xmath311 .",
    "then for any @xmath418 , there exists a  constant @xmath419 such that @xmath420\\\\ & & \\qquad\\quad { } + c_{p , m,\\beta } b_{{{t}}}^{-m}.\\end{aligned}\\ ] ]    [ rkrudzkis ] @xcite proved that if @xmath421 for some @xmath422 , then @xmath423 which can be obtained by using markov inequality and ( [ eqfact5 ] ) under our framework .",
    "the upper bound given in theorem  [ thmldquadratic ] has a  smaller order of magnitude .",
    "we note that @xcite also proved a  stronger exponential inequality under strong moment conditions .",
    "they required the existence of every moment and the absolute summability of cumulants of every order .",
    "proof of theorem  [ thmldquadratic ] without loss of generality , assume @xmath424 .",
    "for @xmath274 , let @xmath425 , @xmath411 and @xmath426 by lemma  [ thmmappquadratic ] and  ( [ eqfact5 ] ) , we have @xmath427\\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\qquad \\leq c_{p , m } x_{{{t}}}^{-p/2 } ( tb_{{{t}}})^{p/4 } t^{-\\alpha \\sqrt{\\beta } p/2}. \\nonumber\\end{aligned}\\ ] ] split @xmath159 $ ] into blocks @xmath428 of size @xmath429 , and define @xmath430 by corollary 1.7 of @xcite and  ( [ eqfact5 ] ) , we know for any @xmath415 , there exists a  constant @xmath431 such that @xmath432\\nonumber\\\\[-2pt ] & & \\qquad\\leq\\sum_{k=1}^{b_{{{t } } } } p \\biggl(|{{\\mathbb{e}}}_0 q_{{{t}},k}| \\geq\\frac{x_{{{t}}}}{c_{p , m,\\beta } } \\biggr )   + \\biggl[\\frac{c_{p , m,\\beta } tm_{{{t}}}^{-1 } ( m_{{{t}}}b_{{{t}}})^{p/4 } } { ( tb_{{{t}}})^{p/4}}\\biggr]^{c_{p , m,\\beta } } \\nonumber\\\\[-9pt]\\\\[-9pt ] & & \\qquad\\quad{}+ c_{\\beta } \\exp\\biggl\\{\\frac{c_p^2 ( \\log b_{{{t } } } ) } { ( p+4)^2 e^{p/2 } \\theta_4 ^ 4}\\biggr\\ } \\nonumber\\\\[-2pt ] & & \\qquad\\leq \\sum_{k=1}^{b_{{{t } } } } p ( |{{\\mathbb{e}}}_0 q_{{{t}},k}| \\geq x_{{{t}}}/c_{p , m,\\beta } ) + c_{p , m,\\beta } ( b_{{{t}}}^{-m } + t^{-m}).\\nonumber\\end{aligned}\\ ] ] by lemma  [ thmldtntermediate ] , we have @xmath433 & & \\qquad\\leq c_{p , m,\\beta } x_{{{t}}}^{-p/2 } ( \\log t ) \\\\[-2pt ] & & \\qquad\\quad { } \\times\\bigl [ \\bigl(t^{\\sqrt{\\beta } } b_{{{t}}}\\bigr)^{p/4}t^{-\\alpha \\beta p/2 } + t^{\\sqrt{\\beta}}b_{{{t}}}^{p/2 - 1-\\alpha\\beta p/2 } + t^{\\sqrt{\\beta}}\\bigr ] . \\nonumber\\end{aligned}\\ ] ] combining  ( [ eq2 ] ) ,  ( [ eq3 ] ) and  ( [ eq4 ] ) , the proof is complete .",
    "[ thmldtntermediate ] assume @xmath122 with @xmath259 , @xmath41 , and @xmath260 .",
    "if @xmath434 satisfies @xmath435 for some @xmath144 , then for any @xmath151 , there exists a  constant @xmath436 such that @xmath437 & & { } \\times[(tb_{{{t}}})^{p/4}t^{-\\alpha\\beta p/2 } + tb_{{{t}}}^{p/2 - 1-\\alpha\\beta p/2 } + t].\\end{aligned}\\ ] ]    for @xmath438 , define @xmath439 , @xmath440 and @xmath441 let @xmath442 .",
    "note that @xmath443 . by lemma  [ thmmappquadratic ] and ( [ eqfact5 ] ) , @xmath444 \\leq c_{p,\\beta } ( \\log t)^{1/2 } x_{{{t}}}^{-p/2 } ( tb_{{{t}}})^{p/4 } t^{-\\alpha\\beta p/2}.\\hspace*{-22pt}\\ ] ]",
    "let @xmath445 be the smallest @xmath446 such that @xmath447 . for @xmath448",
    ", split @xmath159 $ ] into blocks @xmath449 of size @xmath450 .",
    "define @xmath451 by corollary 1.6 of @xcite and  ( [ eqfact5 ] ) , we have for any @xmath452 @xmath453 & \\leq & \\sum_{b=1}^{b_{{{t}},j } } p \\biggl[|{{\\mathbb{e}}}_0(r_{{{t}},j , b}-r_{{{t}},j , b}')| \\geq\\frac{x_{{{t}}}}{c j_{{{t}}}}\\biggr ] \\\\",
    "\\label{eq18 } & & { } + 2\\biggl[\\frac{64 c e^2\\theta_4 ^ 4tb_{{{t}}}j_{{{t}}}^2}{x_{{{t}}}^2}\\biggr]^{c/4}.\\end{aligned}\\ ] ] it is clear that for any @xmath415 , there exists a  constant @xmath454 such that the term in  ( [ eq18 ] ) is less than @xmath455 . for  ( [ eq17 ] ) , by lemma  [ thmmappquadratic ] and  ( [ eqfact5 ] ) @xmath456 \\\\ & & \\qquad \\leq c_{p,\\beta } { t}{(m_{{{t}},j})^{-1 } } \\cdot(\\log t)^{1/2}\\cdot x_{{{t}}}^{-p/2 } \\cdot(m_{{{t}},j}b_{{{t}}})^{p/4 } \\cdot m_{{{t}},j+1}^{-\\alpha p/2 } \\\\ & & \\qquad \\leq c_{p,\\beta } x_{{{t}}}^{-p/2}\\cdot(\\log t)^{1/2}tb_{{{t}}}^{p/4 } \\cdot(m_{{{t}},j})^{p/4 - 1-\\alpha\\beta p/2}.\\end{aligned}\\ ] ] depending on whether the exponent @xmath457 is positive or not , the term @xmath458 is maximized when @xmath459 or @xmath460 , respectively , and we have @xmath461 \\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\qquad \\leq c_{p,\\beta } x_{{{t}}}^{-p/2}\\cdot(\\log t)^{1/2 } \\cdot [ ( tb_{{{t}}})^{p/4}t^{-\\alpha\\beta p/2 } + t b_{{{t}}}^{p/2 - 1-\\alpha\\beta p/2 } ] . \\nonumber\\end{aligned}\\ ] ] combining  ( [ eq1 ] ) ,  ( [ eq17 ] ) ,  ( [ eq18 ] ) and ( [ eq25 ] ) , we have shown that @xmath462 . \\nonumber\\end{aligned}\\ ] ]    to deal with the probability concerning @xmath463 in ( [ eq29 ] ) , we split @xmath159 $ ] into blocks @xmath428 with size @xmath464 , and define the block sums @xmath465 similarly as  ( [ eq17 ] ) and  ( [ eq18 ] ) , there exists a  constant @xmath466 such that @xmath467 by lemma  [ thmldnn ] , we have @xmath468 and it follows that for some constant @xmath469 , @xmath470 the proof is completed by combining  ( [ eq29 ] ) and ( [ eq30 ] ) .    in the next lemma we consider @xmath407 when the restriction @xmath402 for @xmath403 is removed .",
    "to avoid confusion , we use a  new symbol .",
    "let @xmath471 for @xmath434 , define @xmath472,\\ ] ] where the supremum is taken over all arrays @xmath473 such that @xmath474 .",
    "we use @xmath475 and @xmath476 as shorthands for @xmath477 and @xmath478 , respectively .",
    "[ thmldnn ] assume @xmath122 with @xmath259 , @xmath41 , and @xmath260 .",
    "if @xmath434 satisfies @xmath479 for some @xmath144 , then for any @xmath151 , there exists a  constant @xmath436 such that @xmath480    let @xmath481 and @xmath482 . by lemma  [ thmmappquadratic ] and  ( [ eqfact5 ] ) , @xmath483 \\leq c_{p } x_{{{t}}}^{-p/2 } t^{p/2-\\alpha\\beta p/2}.\\ ] ]",
    "we claim that there exists a  constant @xmath436 such that @xmath484 therefore , the proof is complete by using @xmath485 + u(t , m_{{{t}}},x_{{{t}}}/2).\\ ] ]    we need to prove the claim  ( [ eq28 ] )",
    ". let @xmath486 satisfy @xmath487 .",
    "let @xmath488 , and note that @xmath489 .",
    "set @xmath490 .",
    "we consider @xmath491 for an arbitrary @xmath492 .",
    "set @xmath493 and @xmath494 .",
    "define @xmath495 and @xmath496 , @xmath497 similarly by replacing @xmath498 with @xmath499 .",
    "observe that @xmath500 and @xmath501 are independent for @xmath502 .",
    "we first consider @xmath503",
    ". split @xmath159 $ ] into blocks @xmath504 with size @xmath505 , and define @xmath506 .",
    "let @xmath507 satisfy @xmath508 and @xmath509 .",
    "since @xmath510 and @xmath511 are independent if @xmath512 , by corollary 1.6 of @xcite , ( [ eqfact5 ] ) and lemma  [ thmmappquadratic ] , similarly as ( [ eq17 ] ) and  ( [ eq18 ] ) , we know for any @xmath415 , there exists a  constant @xmath513 such that @xmath514 \\nonumber\\\\ & & \\qquad \\leq c_{p , m,\\delta,\\beta } y_{{{t}}}^{-m } + \\sum_{b=1}^{b_{{{t } } } } p(|{{\\mathbb{e}}}_0 w_{{{t}},b}| \\geq y_{{{t}}}/c_{m,\\delta } ) \\\\ & & \\qquad \\leq c_{p , m,\\delta,\\beta } y_{{{t}}}^{-m } + c_{p , m,\\delta,\\beta } y_{{{t}}}^{-p/2 } t m^{p/2 - 1-\\alpha\\beta p/2}.\\nonumber\\end{aligned}\\ ] ] now we deal with the term @xmath515 .",
    "split @xmath159 $ ] into blocks @xmath516 with size @xmath51 .",
    "define @xmath517 .",
    "let @xmath518 be the @xmath381-fields generated by @xmath519 , where @xmath520 .",
    "observe that @xmath521 is a  martingale sequence with respect to @xmath522 , and so are @xmath523 and @xmath524 .",
    "by lemma 1 of @xcite we know for any @xmath415 , there exists a  constant @xmath525 such that @xmath526 \\nonumber\\\\ & & \\qquad \\leq c_{m,\\delta } y_{{{t}}}^{-m } + 4p\\biggl[\\sum_{b=1}^{b_{{{t}}}^\\ast } { { \\mathbb{e}}}(r_{{{t}},b}^2|\\xi_{b-2 } ) > \\frac{y_{{{t}}}^2 } { ( \\log y_{{{t}}})^{3/2}}\\biggr]\\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\qquad\\quad{}+ \\sum_{b=1}^{b_{{{t}}}^\\ast } p\\biggl[|r_{{{t}},b}| \\geq\\frac{y_{{{t}}}}{\\log y_{{{t}}}}\\biggr]\\nonumber\\\\ & & \\qquad= : i_{{{t } } } + { \\mathit{ii}}_{{{t } } } + { \\mathit{iii}}_{{{t}}}.\\nonumber\\end{aligned}\\ ] ] since @xmath527 and @xmath528 are independent , @xmath529 has finite @xmath81th moment . using similar arguments as lemma  [ thmmappquadratic ]",
    ", we have @xmath530 and it follows that @xmath531 for the second term , let @xmath532 for @xmath533 ; we have @xmath534 \\nonumber\\\\[-8pt]\\\\[-8pt ] & = & \\sum_{1 \\leq s\\leq t \\leq{{t } } } a_{s , t,1 } x_{s,1}x_{t,1 } + \\sum_{1 \\leq s\\leq t \\leq{{t } } } a_{s , t,2 } x_{s,2}x_{t,2}.\\nonumber\\end{aligned}\\ ] ] by  ( [ eqfact1 ] ) and  ( [ eqfact4 ] ) , we know @xmath535 .",
    "it follows that the expectations of the two terms in ( [ eq5 ] ) are all less than @xmath536 , and @xmath537 + c_{\\beta } u\\biggl[t , \\lfloor m^\\beta\\rfloor , \\frac{y_{{{t}}}^2}{t ( \\log y_{{{t}}})^2}\\biggr].\\ ] ] combining  ( [ eq24 ] ) ,  ( [ eq19 ] ) ,  ( [ eq20 ] ) and ( [ eq21 ] ) , we have shown that @xmath491 is bounded from above by @xmath538 + c_{\\beta } u \\biggl[t , m , \\frac{y_{{{t}}}^2}{t ( \\log y_{{{t}}})^2}\\biggr]\\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\qquad{}+ c_{p , m,\\delta,\\beta } [ y_{{{t}}}^{-m } + y_{{{t}}}^{-p/2 } tm^{p/2 - 1-\\alpha\\beta p/2}\\nonumber\\\\ & & \\qquad\\hspace*{53pt } { } + y_{{{t}}}^{-p}(\\log y_{{{t}}})^p t^{p/2 + 1}m^{p/2 - 1-\\alpha\\beta p } ] .",
    "\\nonumber\\end{aligned}\\ ] ] since @xmath539 by ( [ eqfact5 ] ) , by applying  ( [ eq22 ] ) recursively to deal with the last term on the first line of  ( [ eq22 ] ) for @xmath540 times such that @xmath541 $ ] , we have @xmath542\\\\[-8pt ] & & \\qquad\\hspace*{107pt } { } + y_{{{t}}}^{-p}(\\log y_{{{t}}})^p t^{p/2",
    "+ 1}m^{p/2 - 1-\\alpha\\beta p } + y_{{{t}}}^{-m}\\bigr].\\hspace*{-25pt } \\nonumber\\end{aligned}\\ ] ] using the preceding arguments similarly , we can show that when @xmath543 @xmath544 \\leq c_{m , p,\\delta } [ z_{{{t}}}^{-p/2 } ( \\log t)t + z_{{{t}}}^{-p } ( \\log z_{{{t}}})^{p+1 } t^{p/2 + 1 } + z_{{{t}}}^{-m}].\\ ] ] the details of the derivation are omitted . applying  ( [ eq23 ] )",
    "recursively for at most @xmath545 times , we have the first bound for @xmath491 , @xmath546 + z_{{{t}}}^{-p/2 } ( \\log z_{{{t } } } ) t(m^{p/2 - 1-\\alpha\\beta p/2}+1)\\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\qquad\\quad\\hspace*{65.7pt } { } + z_{{{t}}}^{-p}(\\log z_{{{t}}})^{p+1 } t^{p/2 + 1}(m^{p/2 - 1-\\alpha\\beta p}+1 ) + z_{{{t}}}^{-m}\\}\\nonumber\\\\ & & \\qquad \\leq c_{p,\\delta,\\beta}^{j_{{{t}}}}(\\log z_{{{t}}})^{p+1 } ( z_{{{t}}}^{-p/2 } t + z_{{{t}}}^{-p } t^{p/2 + 1 } ) ( m^{p/2 - 1-\\alpha\\beta p/2}+1 ) .",
    "\\nonumber\\end{aligned}\\ ] ] now plugging  ( [ eq26 ] ) back into  ( [ eq22 ] ) for the last two terms on the first line and using the condition @xmath547 , we have @xmath548\\\\[-8pt ] & & { } + c_{p,\\delta,\\beta } [ y_{{{t}}}^{-p/2 } t ( m^{p/2 - 1-\\alpha\\beta p/2 } + 1 ) ] .\\nonumber\\end{aligned}\\ ] ] again by applying  ( [ eq27 ] ) for at most @xmath545 times , we obtain the second bound for @xmath491 : @xmath549 the proof of the claim  ( [ eq28 ] ) is complete .",
    "in this paper we use toeplitz s connection of eigenvalues of matrices and fourier transforms of their entries , and obtain optimal bounds for tapered covariance matrix estimates by applying asymptotic results of spectral density estimates .",
    "many problems are still unsolved ; for example , can we improve the convergence rate of the thresholded estimate in theorem  [ thmthresholding ] ? what is the asymptotic distribution of the maximum eigenvalues of the estimated covariance matrices ?",
    "we hope that the approach and results developed in this paper can be useful for other high - dimensional covariance matrix estimation problems in time series .",
    "such problems are relatively less studied compared to the well - known theory of random matrices which requires i.i.d . entries or multiple i.i.d . copies .",
    "we are grateful to an associate editor and the referees for their many helpful comments ."
  ],
  "abstract_text": [
    "<S> we obtain a  sharp convergence rate for banded covariance matrix estimates of stationary processes . </S>",
    "<S> a  precise order of magnitude is derived for spectral radius of sample covariance matrices . </S>",
    "<S> we also consider a  thresholded covariance matrix estimator that can better characterize sparsity if the true covariance matrix is sparse . as our main tool , we implement toeplitz [ _ math . ann . _ </S>",
    "<S> * 70 * ( 1911 ) 351376 ] idea and relate eigenvalues of covariance matrices to the spectral densities or fourier transforms of the covariances . </S>",
    "<S> we develop a  large deviation result for quadratic forms of stationary processes using approximation , under the framework of causal representation and physical dependence measures .    .    </S>"
  ]
}