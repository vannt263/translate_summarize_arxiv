{
  "article_text": [
    "the mobile ad hoc networks ( manets ) , a class of self - autonomous and flexible wireless networks , are highly appealing for lots of critical applications , like disaster relief , battlefield communications , d2d communications for traffic offloading , and coverage extension in future 5 g cellular networks @xcite .",
    "thus , understanding the fundamental performance limits of manets is of great importance to facilitate the application and commercialization of such networks @xcite . by now",
    ", extensive works have been devoted to the performance study of manets , which can be roughly classified into two categories , the ones with the consideration of practical limited buffer constraint and the ones without such consideration .    regarding the performance study for manets without the buffer constraint ,",
    "grossglauser and tse @xcite first explored the capacity scaling law , i.e. , how the per node throughput scales in the order sense as the number of network nodes increases , and demonstrated that with the help of node mobility a @xmath2 per node throughput is achievable in such networks . later , neely _",
    "@xcite studied the delay - throughput tradeoff issue in a manet under the independent and identically distributed ( i.i.d ) mobility model and showed that achievable delay - to - throughput ratio is lower bounded as @xmath3 ( where @xmath4 is the number of network nodes ) .",
    "@xcite then explored the delay - throughput tradeoff under a symmetric random walk mobility model , and showed that a @xmath5 average packet delay is incurred to achieve the @xmath2 per node throughput there .",
    "@xcite further studied the delay - throughput tradeoff under a general and unified mobility model , and revealed that there exists a critical value of delay below which the node mobility is not helpful for capacity improvement .",
    "recently , wang _",
    "_ explored the throughput and delay performance for manets with multicast traffic in @xcite , and further conducted the network performance comparison between the unicast and multicast manets in @xcite .",
    "those results indicate that the mobility can significantly decrease the multicast gain on per node capacity and delay , and thus weaken the distinction between the two traffic models .",
    "while the above works represent a significant progress in the performance study of manets , in a practical manet , however , the buffer size of a mobile node is usually limited due to both its storage limitation and computing limitation .",
    "thus , understanding the real achievable performance of manets under the practical limited buffer constraint is of more importance for the design and performance optimization of such networks . by now , some initial results have been reported on the performance study of manets under buffer constraint @xcite . specifically , herdtner and chong @xcite explored the throughput - storage tradeoff in manets and showed that the throughput capacity under the relay buffer constraint scales as @xmath6 ( where @xmath7 is the relay buffer size of a node ) .",
    "@xcite considered a manet with limited source buffer in each node , and derived the corresponding cumulative distribution function of the source delay .",
    "recently , the throughput and delay performance of manets are further explored under the scenarios where each node is equipped with an infinite source buffer and a shared limited relay buffer @xcite .",
    "the motivation of our study is to take a step forward in the practical performance modeling for manets . in particular",
    ", this paper focuses on a practical manet where each network node maintains a limited source buffer of size @xmath0 to store its locally generated packets and also a limited shared relay buffer of size @xmath1 to store relay packets for all other nodes .",
    "this buffer constraint is general in the sense it covers all the buffer constraint assumptions adopted in available works as special cases , like the infinite buffer assumption @xcite ( @xmath8 , @xmath9 ) , limited source buffer assumption @xcite ( @xmath10 ) , and limited relay buffer assumption @xcite ( @xmath11 ) . to the best of our knowledge",
    ", this paper represents the first attempt on the exact performance modeling for manets with the general limited - buffer constraint .",
    "the main contributions of this study are summarized as follows :    * based on the queuing theory and birth - death chain theory , we first develop a general theoretical framework to fully depict the source / relay buffer occupancy process in a manet with the general limited - buffer constraint , which applies to any distributed mac protocol and any mobility model that leads to the uniform distribution of nodes locations in steady state .",
    "* with the help of this framework , we then derive the exact expressions of several key network performance metrics , including achievable throughput , throughput capacity , and expected end - to - end ( e2e ) delay .",
    "we also provide the related theoretical analysis to reveal the fundamental network performance trend as the buffer size increases . *",
    "we further conduct case studies under two network scenarios and provide the corresponding theoretical / simulation results to demonstrate the efficiency and application of our theoretical framework .",
    "finally , we present extensive numerical results to illustrate both the impacts of buffer constraint on network performance and our theoretical findings .",
    "the remainder of this paper is organized as follows .",
    "section  [ section : preliminaries ] introduces preliminaries involved in this paper .",
    "the framework for the buffer occupancy process analysis is developed in section  [ section : framework ] .",
    "we derive exact expressions for throughput , throughput capacity and expected e2e delay in section  [ section : performance ] , and conduct case studies in section  [ section : case_studies ] .",
    "the numerical results and corresponding discussions are provided in section  [ section : numerical_results ] .",
    "finally , we conclude this paper in section  [ section : conclusion ] .",
    "in this section , we first introduce the system model , the general limited buffer constraint , the routing scheme and performance metrics involved in this study , and then present our overall framework for manet performance modeling under the general buffer constraint .      _ network model _ : we consider a time - slotted manet , which consists of @xmath4 nodes randomly moving in a torus network area following a `` uniform type '' mobility model . with such mobility model ,",
    "the location process of a node is stationary and ergodic with stationary distribution uniform on the network area , and the trajectories of different nodes are independent and identically distributed .",
    "it is notable that such `` uniform type '' mobility model covers many typical mobility models as special cases , like the i.i.d model @xcite , random walk model @xcite , and random direction model @xcite .",
    "_ traffic model _ : there are @xmath4 unicast traffic flows in the network , and each node is the source of one traffic flow and also the destination of another traffic flow .",
    "more formally , let @xmath12 denote the destination node of the traffic flow originated from node @xmath13 , then the source - destination pairs are matched in a way that the sequence @xmath14 is just a derangement of the set of nodes @xmath15 .",
    "the packet generating process at each node is assumed to a bernoulli process with mean rate @xmath16 , so that with probability @xmath16 a new packet is generated in each time slot . during a time slot the total amount of data that can be transmitted from a transmitter to its corresponding receiver",
    "is fixed and normalized to one packet .              as illustrated in fig .",
    "[ fig : buffer_constraint ] , we consider a general limited buffer constraint , where a node is equipped with a limited source buffer of size @xmath0 and a limited relay buffer of size @xmath1 .",
    "the source buffer is for storing the packets of its own flow ( locally generated packets ) and works as a fifo ( first - in - first - out ) source queue @xcite , while the relay buffer is for storing packets of all other @xmath17 flows and works as @xmath17 fifo virtual relay queues ( one queue per flow ) .",
    "when a packet of other flows arrives and the relay buffer is not full , the corresponding relay queue is dynamically allocated a buffer space ; once a head - of - line ( hol ) packet departs from its relay queue , this relay queue releases a buffer space to the common relay buffer .",
    "it is notable that the limited buffer constraint we consider is general in the sense it covers all the buffer constraint assumptions adopted in the available works as special cases .      regarding the packet delivery scheme , we consider the two - hop relay ( 2hr ) routing protocol .",
    "the 2hr scheme is simple yet efficient , and has been widely adopted in available studies on the performance modeling of manets @xcite .",
    "in addition to the conventional 2hr scheme without feedback , we also consider the 2hr scheme with feedback , which avoids packet loss caused by relay buffer overflow and thus can support the more efficient operation of buffer - limited manets .    without loss of generality , we focus on a tagged flow and denote its source node and destination node as @xmath18 and @xmath19 respectively .",
    "once @xmath18 gets access to wireless channel at the beginning of a time slot , it executes the 2hr scheme without / with feedback as follows .    1 .",
    "( * source - to - destination * ) + if @xmath19 is within the transmission range of @xmath18 , @xmath18 executes the source - to - destination operation .",
    "if the source queue of @xmath18 is not empty , @xmath18 transmits the hol packet to @xmath19 ; else @xmath18 remains idle .",
    "if @xmath19 is not within the transmission range of @xmath18 , @xmath18 randomly designates one of the nodes ( say @xmath20 ) within its transmission range as its receiver , and chooses one of the following two operations with equal probability . *",
    "( * source - to - relay * ) + _ without feedback _ : if the source queue of @xmath18 is not empty , @xmath18 transmits the hol packet to @xmath20 ; else @xmath18 remains idle .",
    "+ _ with feedback _ : @xmath20 sends a feedback to @xmath18 to indicate whether its relay buffer is full or not .",
    "if the relay buffer of @xmath20 is not full , @xmath18 executes the same operation as that without feedback ; else @xmath18 remains idle . *",
    "( * relay - to - destination * ) + if @xmath18 has packet(s ) in the corresponding relay queue for @xmath20 , @xmath18 sends the hol packet of the queue to @xmath20 ; else @xmath18 remains idle .",
    "the performance metrics involved in this paper are defined as follows .",
    "* throughput * : the _ throughput _ @xmath21 of a flow ( in units of packets per slot ) is defined as the time - average number of packets that can be delivered from its source to its destination .    * throughput capacity * : for the homogeneous finite buffer network scenario considered in this paper , the network level _ throughput capacity _ @xmath22 can be defined by the maximal achievable per flow throughput , i.e. , @xmath23 } t$ ] .    *",
    "end - to - end delay * : the _ end - to - end delay _ @xmath19 of a packet ( in units of slots ) is defined as the time it takes the packet to reach its destination after it is generated by its source , and we use @xmath24 to denote the expectation of @xmath19 .",
    "we show in fig .",
    "[ fig : framework ] our overall theoretical framework for manet performance modeling under the general limited buffer constraint , where @xmath25 , @xmath26 and @xmath27 denote the probability that a node gets an opportunity of source - to - destination , source - to - relay or relay - to - destination transmission , respectively .",
    "we can see from fig .",
    "[ fig : framework ] that for the performance modeling of @xmath21 , @xmath22 and @xmath24 , the key issue there is to determine the occupancy state distributions ( osds ) for both the source and relay buffers based on the basic parameters of @xmath28 .",
    "in particular , due to the different arrival / departure processes associated with the source buffer and relay buffer , a bernoulli / bernoulli/1/@xmath0 ( b / b/1/@xmath0 ) queuing model queue refers to that both the packet arrival and departure are bernoulli process , the number of server is 1 and the buffer size is @xmath0 . ]",
    "is applied to characterize the packet occupancy process in source buffer , while a birth - death chain is applied to model the complex packet occupancy process in relay buffer .",
    "finally , the fixed point ( fp ) theory is applied to deal with the coupling issue between the occupancy processes of source buffer and relay buffer under the scenario with feedback .",
    "in this section , we conduct the occupancy process analysis for both the source and relay buffers to determine their osds , which helps us to derive the performance metrics of @xmath21 , @xmath22 and @xmath24 . without loss of generality , we focus on a tagged node @xmath18 , and consider the scenarios without and with feedback separately .        regarding the source buffer of node @xmath18 , since in every time slot a new packet",
    "is generated with probability @xmath29 and a service opportunity arises with probability @xmath30 being determined as @xmath31 the occupancy process of source buffer can be modeled by a b / b/1/@xmath0 queue as illustrated in fig .",
    "[ fig : source_queue ] .     queuing model for source buffer.,width=336 ]",
    "let @xmath32 denote the probability that there are @xmath13 packets occupying the source buffer in the stationary state , then the stationary osd of the source buffer @xmath33 $ ] can be determined as @xcite @xmath34 where @xmath35 and @xmath36 is the normalization constant .",
    "notice that @xmath37 , where @xmath38 is a column vector of size @xmath39 with all elements being @xmath40 , we have @xmath41      we continue to analyze the occupancy process of the relay buffer in @xmath18 .",
    "let @xmath42 denote the number of packets in the relay buffer at time slot @xmath43 , then the occupancy process of the relay buffer can be regarded as a stochastic process @xmath44 on state space @xmath45 .",
    "notice that when @xmath18 serves as a relay in a time slot , the source - to - relay transmission and relay - to - destination transmission will not happen simultaneously .",
    "thus , suppose that the relay buffer is at state @xmath13 in the current time slot , only one of the following transition scenarios may happen in the next time slot :    * @xmath13 to @xmath46 ( @xmath47 ) : the relay buffer is not full , and a packet arrives at the relay buffer .",
    "* @xmath13 to @xmath48 ( @xmath49 ) : the relay buffer is not empty , and a packet departures from the relay buffer . *",
    "@xmath13 to @xmath13 ( @xmath50 ) : no packet arrives at and departures from the relay buffer .",
    "let @xmath51 denote the one - step transition probability from state @xmath13 to state @xmath52 ( @xmath53 ) , then the occupancy process @xmath44 can be modeled as a birth - death chain as illustrated in fig .",
    "[ fig : birth - death_chain ] .",
    "let @xmath54 denote the probability that there are @xmath13 packets occupying the relay buffer in the stationary state , the stationary osd of the relay buffer @xmath55 $ ] is determined as @xmath56 where @xmath57 is the one - step transition matrix of the birth - death chain defined as @xmath58 ,     \\label{eq : matrix}\\ ] ] and @xmath38 is a column vector of size @xmath59 with all elements being 1 .",
    "notice that @xmath60 , @xmath61 and @xmath62 for @xmath63 , the expressions ( [ eq : balance_eq])@xmath64([eq : matrix ] ) indicate that to derive @xmath65 , we need to determine the one - step transition probabilities @xmath66 and @xmath67 .",
    "[ lemma : transition_probability ] for the birth - death chain in fig .",
    "[ fig : birth - death_chain ] , its one - step transition probabilities @xmath66 and @xmath67 are determined as @xmath68    the proof is given in appendix  [ appendix : transition_probability ] .    by substituting ( [ eq : p_i_i+1 ] ) and ( [ eq : p_i_i-1 ] ) into ( [ eq : balance_eq ] ) and ( [ eq : normalization_eq ] ) , we can see that the stationary osd of the relay buffer is determined as @xmath69 where @xmath70 .      under the scenario with feedback , node @xmath18 can not execute a source - to - relay transmission when the relay buffer of its intended receiver is full ( with overflow probability @xmath71 ) , causing the correlation between the osd analysis of source buffer and that of relay buffer .",
    "it is notable , however , the overflow probability @xmath71 only affects the service rate @xmath30 of the source buffer and the arrival rate at the relay buffer , while the occupancy processes of the source buffer and relay buffer can still be modeled as the b / b/@xmath40/@xmath0 queue and the birth - death chain respectively .",
    "thus , based on the similar analysis as that in section  [ subsection : osd_nofeedback ] , we have the following corollary .",
    "[ corollary : osd_feedback ] for the network scenario with feedback , the osd @xmath72 of the source buffer and the osd @xmath65 of the relay buffer are determined as ( [ eq : osd_source ] ) and ( [ eq : osd_relay ] ) , where @xmath73 is given by ( [ eq : tau ] ) , and the service rate @xmath30 of the source buffer is evaluated as @xmath74    the proof is given in appendix  [ appendix : osd_feedback ] .",
    "corollary  [ corollary : osd_feedback ] indicates that for the evaluation of osds @xmath72 and @xmath65 , we need to determine the relay buffer overflow probability @xmath71 . from formula ( [ eq : osd_relay ] ) we have @xmath75 where @xmath76    we can see from ( [ eq : mu_s_fb])@xmath64([eq : pi_s_0 ] ) that ( [ eq : self - mapping ] ) is actually an implicit function of @xmath71 , which can be solved by applying the fixed point theory @xcite .",
    "we provide in appendix  [ appendix : fixed_point_iteration ] the detailed fixed - point iteration for solving @xmath71 .",
    "with the help of osds of source buffer and relay buffer derived in section  [ section : framework ] , this section focuses on the performance analysis of the concerned buffer limited manet in terms of its throughput , expected e2e delay and throughput capacity .",
    "regarding the throughput and expected e2e delay of a manet with the general limited buffer constraint , we have the following theorem .    [",
    "theorem : throughput_delay ] for a concerned manet with @xmath4 nodes , packet generating rate @xmath16 , source buffer size @xmath0 and relay buffer size @xmath1 , its per flow throughput @xmath21 and expected e2e delay @xmath24 are given by @xmath77 where @xmath78 ( resp .",
    "@xmath79 ) denotes the expected number of packets in the source buffer ( resp .",
    "relay buffer ) under the condition that the source buffer ( resp .",
    "relay buffer ) is not full , which is determined as @xmath80 and @xmath30 is determined by ( [ eq : mu_s_nf ] ) and ( [ eq : mu_s_fb ] ) for the scenarios without and with feedback respectively , @xmath73 , @xmath81 and @xmath65 are determined by ( [ eq : tau ] ) , ( [ eq : osd_source ] ) and ( [ eq : osd_relay ] ) , respectively .",
    "notice that packets of a flow are delivered to their destination through either one - hop transmission ( source - to - destination ) or two - hop transmission ( source - to - relay and relay - to - destination ) , so the per flow throughput @xmath21 can be derived by analyzing packet delivery rates of these two kinds of transmissions .",
    "regarding the expected e2e delay @xmath24 , it can be evaluated based on the analysis of expected source queuing delay and expected delivery delay of a tagged packet . for the detailed proof of this theorem",
    ", please refer to appendix  [ appendix : throughput_delay ] .    the formulas ( [ eq : throughput ] ) and ( [ eq : e2e_delay ] ) hold for both network scenarios without / with feedback , but different network scenarios will lead to different results of @xmath73 , @xmath81 and @xmath65 .",
    "based on the results of theorem  [ theorem : throughput_delay ] , we can establish the following corollary ( see appendix  [ appendix : feedback ] for the proof ) .",
    "[ corollary : feedback ] for a concerned manet with the general limited buffer constraint , adopting the feedback mechanism improves its throughput performance .      to determine the throughput capacity @xmath22",
    ", we first need the following lemma ( see appendix  [ appendix : as_lambda_increase ] for the proof ) .",
    "[ lemma : as_lambda_increase ] for a concerned manet with the general limited buffer constraint , its throughput @xmath21 increases monotonically as the packet generating rate @xmath29 increases .",
    "based on lemma  [ lemma : as_lambda_increase ] , we can establish the following theorem on throughput capacity .",
    "[ theorem : throughput_capacity ] for a concerned manet with @xmath4 nodes , source buffer size @xmath0 and relay buffer size @xmath1 , its throughput capacity @xmath22 is given by @xmath82    lemma  [ lemma : as_lambda_increase ] indicates that @xmath83 } t = \\lim\\limits_{\\lambda_s^{\\text{\\scriptsize + } } \\to 1 } t. \\label{eq : tc_lambda_1}\\ ] ] from ( [ eq : tau ] ) , ( [ eq : osd_source ] ) and ( [ eq : osd_relay ] ) we can see that @xmath84    combining ( [ eq : throughput ] ) , ( [ eq : tc_lambda_1 ] ) , ( [ eq : pi_s_0_lambda_1 ] ) and ( [ eq : pi_r_br_lambda_1 ] ) , the expression ( [ eq : throughput_capacity ] ) then follows .",
    "based on the theorem  [ theorem : throughput_delay ] and theorem  [ theorem : throughput_capacity ] , we have the following corollary regarding the limiting @xmath21 and @xmath24 as the buffer size tends to infinity ( see appendix  [ appendix : buffer_infinite ] for the proof ) .",
    "[ corollary : buffer_infinite ] for a concerned manet , its throughput increases as @xmath0 and/or @xmath1 increase , and as @xmath0 and/or @xmath1 tend to infinity , the corresponding limiting @xmath21 and @xmath24 are determined as ( 21 ) and ( 22 ) respectively , where @xmath85 .",
    "t= p_sd _ s + p_sr , & @xmath8 [ eq : t_bs_infinite ] + ( p_sd+p_sr)(1-_s(0 ) ) , & @xmath9 [ eq : t_br_infinite ] + \\{_s^,p_sd+p_sr}. & @xmath86 and @xmath9 [ eq : t_bs_br_infinite ]    [ eq : t_buffer_infinite ]    \\{d}= , & @xmath8 and @xmath87 + + , & @xmath8 and @xmath88 [ eq : d_bs_infinite ] + , & @xmath9 [ eq : d_br_infinite ] + , & @xmath8 , @xmath9 and @xmath89 [ eq : d_bs_br_infinite ]    we can see from the theorem  [ theorem : throughput_capacity ] that the throughput capacity of the concerned manet is the same for both the scenarios with and without feedback , and it is mainly determined by its relay buffer size @xmath1 .",
    "the corollary  [ corollary : buffer_infinite ] indicates that our throughput and delay results of ( [ eq : throughput])@xmath64([eq : e2e_delay ] ) are general in the sense that as @xmath0 tends to infinity , they reduce to the results in @xcite , while as both @xmath0 and @xmath1 tend to infinity , they reduce to the results in @xcite .",
    "in this section , we apply our theoretical framework to conduct performance analysis for two typical manet scenarios widely adopted in available studies , and present the corresponding theoretical / simulation results to demonstrate the efficiency and application of our framework .",
    "* cell - partitioned manet with local scheduling based mac ( ls - mac ) @xcite : * under this network scenario , the whole network area is evenly partitioned into @xmath90 non - overlapping cells . in each time",
    "slot one cell supports only one transmission between two nodes within it , and concurrent transmissions in different cells will not interference with each other .",
    "when there are more than one node in a cell , each node in this cell becomes the transmitter equally likely .",
    "for such a manet , the corresponding probabilities @xmath25 , @xmath26 and @xmath27 can be determined by the following formulas ( see appendix  [ appendix : basic_probabilities ] for derivations ) .",
    "@xmath91 @xmath92    * cell - partitioned manet with equivalence class based mac ( ec - mac ) @xcite : * in such a manet , the whole network area is evenly partitioned into @xmath90 non - overlapping cells , and each transmitter ( like the @xmath93 in fig .",
    "[ fig : transmission_range ] ) has a transmission range that covers a set of cells with horizontal and vertical distance of no more than @xmath94 cells away from the cell the transmitter reside in . to prevent simultaneous transmissions from interfering with each other ,",
    "the ec - mac is adopted . as illustrated in fig .",
    "[ fig : equivalence_class ] that with the ec - mac , all cells are divided into different ecs , and any two cells in the same ec have a horizontal and vertical distance of some multiple of @xmath95 cells .",
    "each ec alternatively becomes active every @xmath96 time slots , and each active cell of an active ec allows only one node in it ( if any ) to conduct data transmission .",
    "when there are more than one node in an active cell , each node in this cell becomes the transmitter equally likely . to enable as many number of concurrent transmissions to be scheduled as possible while avoiding interference among these transmissions ,",
    "@xmath95 should be set as @xcite @xmath97 where @xmath98 is a guard factor specified by the protocol model @xcite .",
    "for such a manet the corresponding probabilities @xmath25 , @xmath26 and @xmath27 are determined by the following formulas ( see appendix  [ appendix : basic_probabilities ] for derivations ) .",
    "@xmath99 @xmath100 where @xmath101 .      to validate our theoretical framework for manet performance modeling",
    ", a simulator was developed to simulate the packet generating , packet queuing and packet delivery processes under above two network scenarios @xcite .",
    "each simulation task runs over a period of @xmath102 time slots , and we only collect data from the last @xmath103 of time slots to ensure the system is in the steady state . in the simulator , the following two typical mobility models have been implemented :    * * i.i.d model @xcite : * at the beginning of each time slot , each node independently selects a cell among all cells with equal probability and then stays in it during this time slot . * * random walk ( rw ) model @xcite : * at the beginning of each time slot , each node independently selects a cell among its current cell and its @xmath104 adjacent cells with equal probability @xmath105 and then stays in it during this time slot .",
    "we summarize in fig .",
    "[ fig : validation ] the theoretical / simulation results for throughput and delay under the above two network scenarios , respectively . for each scenario",
    "we consider the network settings of ( @xmath106 ) , and for the scenario with the ec - mac protocol we set @xmath107 and @xmath108 there @xcite .",
    "notice that the theoretical results here are obtained by substituting ( [ eq : p_sd_ls ] ) and ( [ eq : p_sr_ls ] ) ( resp .",
    "( [ eq : p_sd_ec ] ) and ( [ eq : p_sr_ec ] ) ) into the theoretical framework in fig .",
    "[ fig : framework ] .    fig .",
    "[ fig : validation ] show clearly that the simulation results match well with the theoretical ones for all the cases considered here , which indicates that our theoretical framework is applicable to and highly efficient for the performance modeling of different buffer limited manets .",
    "we can see from fig .",
    "[ fig : throughput_ls ] and fig .",
    "[ fig : throughput_ec ] that for a manet with ls - mac or ec - mac , as the packet generating rate @xmath29 increases , the per flow throughput @xmath21 increases monotonically and finally converges to its throughput capacity @xmath22 , which agrees with the conclusions of lemma  [ lemma : as_lambda_increase ] and theorem  [ theorem : throughput_capacity ] .",
    "another interesting observation of fig .",
    "[ fig : throughput_ls ] and fig .",
    "[ fig : throughput_ec ] is that just as predicated by corollary  [ corollary : feedback ] and theorem  [ theorem : throughput_capacity ] , although adopting the feedback mechanism usually leads to a higher throughput , it does not improve the throughput capacity performance .    regarding the delay performance",
    ", we can see from fig .",
    "[ fig : delay_ls ] and fig .",
    "[ fig : delay_ec ] that in a manet with either ls - mac or ec - mac , the behavior of expected e2e delay @xmath24 under the scenario without feedback is quite different from that under the scenario with feedback . as @xmath29 increases , in the scenario without feedback",
    "@xmath24 first slightly increases and then decreases monotonically , while in the scenario with feedback @xmath24 first slightly increases , then decreases somewhat and finally increases monotonically .",
    "the results in fig .",
    "[ fig : validation ] indicate that although adopting the feedback mechanism leads to an improvement in per flow throughput , such improvement usually comes with a cost of a larger e2e delay .",
    "this is because that the feedback mechanism can avoid the packet dropping at a relay node , which contributes to the throughput improvement but at the same time makes the source / relay buffers tend to be more congested , leading to an increase in delay .",
    "based on the proposed theoretical framework , this section presents extensive numerical results to illustrate the potential impacts of buffer constraint on network performance .",
    "notice from section  [ subsection : validation ] that the performance behaviors of the ls - mac are quite similar to that of the ec - mac , in the following discussions we only focus on a manet with the ls - mac .",
    "we first summarize in fig .",
    "[ fig : t_d_vs_bs_br ] how @xmath21 and @xmath24 vary with @xmath0 and @xmath1 under the setting of ( @xmath109 , @xmath110 , @xmath111 ) . about the throughput performance",
    ", we can see from fig.[fig : throughput_vs_bs ] and fig.[fig : throughput_vs_br ] that just as predicated by corollary  [ corollary : buffer_infinite ] and corollary  [ corollary : feedback ] , @xmath21 increases as either @xmath0 or @xmath1 increases , and the feedback mechanism can lead to an improvement in @xmath21 .",
    "it is interesting to see that as @xmath0 increases , @xmath21 under the two scenarios without and with feedback converges to two distinct constants determined by ( 21a ) .",
    "as @xmath1 increases , however , @xmath21 under the two scenarios finally converges to the same constant determined by ( 21b ) . regarding the delay performance , fig .",
    "[ fig : delay_vs_bs ] shows that as @xmath0 increases , @xmath24 under the scenario without feedback quickly converges to a constant determined by ( 22b ) , while @xmath24 under the scenario with feedback monotonically increases to infinity , which agrees with the result of ( 22a ) .",
    "we can see from fig .",
    "[ fig : delay_vs_br ] that with the increase of @xmath1 , however , @xmath24 under the scenario without feedback monotonically increases , while @xmath24 under the scenario with feedback first decreases and then increases . similar to the throughput behavior in fig .",
    "[ fig : throughput_vs_br ] , fig .",
    "[ fig : delay_vs_br ] shows that as @xmath1 increases @xmath24 under the two scenarios also converges to the same constant determined by ( 22c ) .    the results in fig .",
    "[ fig : t_d_vs_bs_br ] indicate that @xmath0 and @xmath1 have different impacts on the network performance in terms of @xmath21 and @xmath24 . in particular , as @xmath0 increases , a notable performance gap between the scenarios without and with feedback always exist , where the throughput gap converges to a constant but the corresponding delay gap tends to infinity . as @xmath1 increases , however , the performance gap between the two scenarios tends to decrease to @xmath112 , which implies that the benefits of adopting the feedback mechanism are diminishing in manets with a large relay buffer size . a further careful observation of fig .",
    "[ fig : t_d_vs_bs_br ] indicates that although we can improve the throughput by increasing @xmath0 or @xmath1 , it is more efficient to adopt a large @xmath1 rather than a large @xmath0 for such improvement .",
    "for example , under the scenario without feedback , fig .",
    "[ fig : throughput_vs_bs ] shows that by increasing @xmath0 from @xmath40 to @xmath113 , @xmath21 can be improved from @xmath114 to @xmath115 ( with an improvement of @xmath116 ) ; while fig .  [",
    "fig : throughput_vs_br ] shows that by increasing @xmath1 from @xmath40 to @xmath113 , @xmath21 can be improved from @xmath117 to @xmath118 ( with an improvement of @xmath119 ) .",
    "to further illustrate how the impacts of buffer size on network performance are dependent on packet generating rate @xmath29 , we focus on a manet with feedback and summarize in fig .  [",
    "fig : t_d_vs_bs_br_lambda ] how its throughput and delay vary with @xmath29 and ( @xmath120 ) .",
    "we can see from fig .",
    "[ fig : t_bs_lambda ] and fig .",
    "[ fig : t_br_lambda ] that although in general we can improve @xmath21 by increasing either @xmath0 or @xmath1 , the degree of such improvement is highly dependent on @xmath29 . as @xmath29 increases ,",
    "the throughput improvement from @xmath1 monotonically increases , while the corresponding improvement from @xmath0 first increases and then decreases .",
    "[ fig : t_bs_lambda ] and fig .",
    "[ fig : t_br_lambda ] also show that as @xmath29 increases , @xmath21 under different settings of @xmath0 finally converges to the same constant ( i.e. , @xmath22 given by ( [ eq : throughput_capacity ] ) ) , while @xmath21 under a given setting of @xmath1 converges to a distinct constant of @xmath22 , which monotonically increases as @xmath1 increases .    regarding the joint impacts of @xmath29 and @xmath0 on delay performance",
    ", we can see clearly from fig .",
    "[ fig : d_bs_lambda ] that just as discussed in corollary  [ corollary : buffer_infinite ] , there exists a threshold of @xmath29 beyond which @xmath24 will increases to infinity as @xmath0 increases , while for a given @xmath29 less than the threshold , @xmath24 almost keeps as a constant as @xmath0 increases .",
    "about the joint impacts of @xmath29 and @xmath1 on delay performance , fig .",
    "[ fig : d_br_lambda ] shows that for a given setting of @xmath29 , there also exists a threshold for @xmath1 , beyond which @xmath24 almost keeps as a constant as @xmath1 increases .",
    "it is interesting to see that such threshold for @xmath1 and the corresponding delay constant tend to increase as @xmath29 increases .",
    "the results in fig .",
    "[ fig : d_br_lambda ] imply that a bounded @xmath24 can be always guaranteed in a manet as long as its source buffer size is limited .",
    "we summarize in fig .",
    "[ fig : tc_vs_br ] how throughput capacity @xmath22 varies with relay buffer size @xmath1 , where two network settings of ( @xmath121 ) and ( @xmath122 ) are considered .",
    "[ fig : tc_vs_br ] shows that as @xmath1 increases , @xmath22 first increases quickly and then gradually converges to a constant @xmath123 being determined by ( [ eq : throughput_capacity ] ) .",
    "this observation indicates that although the throughput capacity can be improved by adopting a larger relay buffer , in practical network design the relay buffer size should be set appropriately according to the requirement on network capacity such that a graceful tradeoff between network performance and networking cost can be achieved .",
    "it can be observed from fig .",
    "[ fig : tc_vs_br ] that @xmath22 is also dependent on the number of nodes @xmath4 , which motivates us to further explore the scaling law of throughput capacity in such a buffer limited manet .",
    "based on ( [ eq : throughput_capacity ] ) , ( [ eq : p_sd_ls ] ) and ( [ eq : p_sr_ls ] ) , the asymptotic throughput capacity is given by @xmath124 where @xmath125 .    from ( [ eq : scaling ] ) we can see that as @xmath126 tends to either @xmath112 or infinity , @xmath22 tends to @xmath112 , while if @xmath126 is fixed @xmath22 scales as @xmath127 as both @xmath4 and @xmath128 scale up . it is notable that in @xcite an upper bound of throughput ( with the notation @xmath129 ) was proposed for a manet with limited relay buffer , however , the scaling law developed here is an achievable one ( with the notation @xmath130 ) , which indicates that to achieve a non - vanishing throughput capacity in a manet with the general limited buffer constraint , the relay buffer size @xmath1 should grow at least linearly with the number of nodes @xmath4 . based on ( [ eq : throughput_capacity ] ) , we plot in fig .",
    "[ fig : tc_vs_n ] that how @xmath22 scales with @xmath4 under three typical buffer settings , i.e. , @xmath1 is fixed as a constant ( @xmath131 here ) , @xmath132 and @xmath133 .",
    "we can see from fig .  [",
    "fig : tc_vs_n ] that in general @xmath22 decreases as @xmath4 increases , and @xmath22 vanishes to @xmath112 when @xmath1 is fixed , while it converges to a non - zero constant when @xmath132 or @xmath133 .",
    "this paper explored , for the first time , the performance modeling for manets under the general limited buffer constraint .",
    "in particular , a complete and generally applicable theoretical framework was developed to capture the inherent buffer occupancy behaviors in such a manet , which enables the exact expressions to be derived for some fundamental network performance metrics , like the achievable throughput , expected e2e delay and throughput capacity .",
    "some interesting conclusions that can be drawn from this study are : 1 ) in general , adopting the feedback mechanism can lead to an improvement in the throughput performance , but such improvement comes with the cost of a relatively large delay ; 2 ) for the purpose of throughput improvement , it is more efficient to adopt a large relay buffer rather than a large source buffer ; 3 ) the throughput capacity is dominated by the relay buffer size ( rather than source buffer size ) and the number of nodes ; 4 ) to ensure that a buffer - limited manet is scalable in terms of throughput capacity , its relay buffer size should grow at least linearly with the number of network nodes .",
    "based on the transition scenarios , we can see @xmath66 is actually equal to the packet arrival rate @xmath134 of the relay buffer , so we just need to determine @xmath134 for the evaluation of @xmath66 .",
    "when @xmath18 serves as a relay , all other @xmath17 nodes ( except @xmath18 and its destination ) may forward packets to it .",
    "when one of these nodes sends out a packet from its source buffer , it will forward the packet to @xmath18 with probability @xmath135 .",
    "this is because with probability @xmath136 the packet is intended for a relay node , and each of the @xmath17 relay nodes are equally likely .",
    "thus , @xmath137 where @xmath138 denotes the packet departure rate of a source buffer .",
    "due to the reversibility of the b / b/1/@xmath0 queue , the packet departure process of the source buffer is also a bernoulli process with its departure rate @xmath138 being determined as @xmath139 then we have @xmath140        regarding the evaluation of transition probability @xmath67 , it is notable that @xmath67 just corresponds to the service rate @xmath141 of the relay buffer when it is at state @xmath13 . to determine @xmath141",
    ", we further decompose the state @xmath13 ( @xmath142 ) into @xmath13 sub - states @xmath143 as illustrated in fig .",
    "[ fig : state_breakdown ] , where @xmath144 denotes the number of non - empty relay queues in the relay buffer .",
    "let @xmath145 denote the service rate of the relay buffer when it is at sub - state @xmath146 , and let @xmath147 denote the probability that the relay buffer is at sub - state @xmath146 conditioned on that the relay buffer is at state @xmath13 , we then have @xmath148    we first derive the term @xmath145 in ( [ eq : mu_r_i ] ) .",
    "notice that with probability @xmath27 the node @xmath18 conducts a relay - to - destination transmission , and it will equally likely choose one of the @xmath17 nodes ( expect @xmath18 and its destination ) as its receiver .",
    "thus , when there are @xmath144 non - empty relay queues in the relay buffer , the corresponding service rate @xmath145 is determined as @xmath149    to determine the conditional probability @xmath147 , we adopt the following occupancy approach proposed in @xcite . first , for the relay buffer with @xmath13 packets , where each packet may be destined for any one of the @xmath17 nodes ( except @xmath18 and @xmath19 ) , the number of all possible cases @xmath150 is @xmath151 then , for the relay buffer with @xmath13 packets , where these packets are destined for only @xmath144 different nodes , the number of possible cases @xmath152 is @xmath153 finally , since the locations of nodes are independently and uniformly distributed , each case occurs with equal probability .",
    "according to the _ classical probability _ , we have @xmath154    substituting ( [ eq : mu_r_il ] ) and ( [ eq : p_l|i ] ) into ( [ eq : mu_r_i ] ) , @xmath67 is determined as @xmath155",
    "for the network scenario with feedback , node @xmath18 can not execute a source - to - relay transmission when the relay buffer of its intended receiver is full ( with overflow probability @xmath71 ) , thus the service rate @xmath30 of source buffer of node @xmath18 is given by @xmath156    based on the similar analysis as that in section  [ subsection : osd_nofeedback ] , the osd @xmath72 of source buffer here can also be determined by expression ( [ eq : osd_source ] ) , and the one - step transition probabilities of the birth - death chain of relay buffer can be determined as @xmath157 where @xmath158 denotes the packet arrival rate of the relay buffer when the relay buffer is not full . regarding the evaluation of @xmath134 , we have @xmath159 @xmath160 where @xmath138 denotes the packet departure rate of a source buffer , and ( [ eq : lambda_r+_fb ] ) follows from ( [ eq : lambda_s- ] ) .",
    "notice that the transition probabilities here are the same as that under the scenario without feedback , thus the osd @xmath65 of the relay buffer here can also be determined by expression ( [ eq : osd_relay ] ) .",
    "since @xmath71 is the fixed - point of equation ( [ eq : self - mapping ] ) , we apply the fixed - point iteration to solve @xmath71 .",
    "the detailed algorithm of the fixed - point iteration is summarized in algorithm  [ algorithm : fixed_point_iteration ] .",
    "+ basic network parameters @xmath28 ;   + relay buffer overflow probability @xmath71 ; set @xmath161 and @xmath162 ; @xmath163 ; @xmath164 ; @xmath165 ; @xmath166 ; @xmath167 ; @xmath168 ; @xmath71 ;",
    "let @xmath169 and @xmath170 denote the packet delivery rates at the destination of node @xmath18 through the one - hop transmission and the two - hop transmission respectively , then we have @xmath171 where @xmath138 denotes the packet departure rate of source buffer of @xmath18 . substituting ( [ eq : lambda_s- ] ) into ( [ eq : t1 ] ) and ( [ eq : t2 ] )",
    ", then ( [ eq : throughput ] ) follows from @xmath172 .    regarding the expected e2e delay @xmath24 , we focus on a tagged packet @xmath173 of node @xmath18 and evaluate its expected source queuing delay @xmath174 and expected delivery delay @xmath175 , respectively . for the evaluation of @xmath174",
    "we have @xmath176    let @xmath177 ( @xmath178 ) denote the probability that there are @xmath13 packets in the source buffer conditioned on that the source buffer is not full , then @xmath177 is determined as @xcite @xmath179 where @xmath180 is the normalization constant . since @xmath181",
    ", we have @xmath182 then @xmath78 is given by @xmath183    after moving to the hol in its source buffer , packet @xmath173 will be sent out by node @xmath18 with mean service time @xmath184 , and it may be delivered to its destination directly or forwarded to a relay .",
    "let @xmath185 denote the expected time that @xmath173 takes to reach its destination after it is forwarded to a relay , then we have @xmath186    based on the osd @xmath65 , @xmath79 is given by ( [ eq : relay_length ] ) .",
    "due to the symmetry of relay queues in a relay buffer , the mean number of packets in one relay queue is @xmath187 , and the service rate of each relay queue is @xmath188 .",
    "thus , @xmath185 can be determined as @xmath189 substituting ( [ eq : d_r ] ) into ( [ eq : delivery_delay ] ) , then ( [ eq : e2e_delay ] ) follows from @xmath190 .",
    "from expressions ( [ eq : mu_s_nf ] ) and ( [ eq : mu_s_fb ] ) , we can see that the for a given packet generating rate @xmath29 , the service rate @xmath30 of the source buffer under the scenario with feedback is smaller than that under the scenario without feedback . from ( [ eq : osd_source ] ) we have @xmath191 which indicates that @xmath81 under the scenario with feedback is smaller than that under the scenario without feedback .",
    "we let @xmath192 and substitute @xmath193 into ( [ eq : throughput ] ) , then @xmath21 can be expressed as @xmath194 where @xmath195 and @xmath196 . regarding the derivative of @xmath197",
    "we have @xmath198 where @xmath199 here ( [ eq : larger_0 ] ) is because that @xmath200 for @xmath201 .",
    "we can see from ( [ eq : pi_s_0_mu_s ] ) that @xmath81 increases as @xmath30 increases , and from ( [ eq : t_r])@xmath64([eq : larger_0 ] ) that @xmath21 increases as @xmath81 decreases .",
    "thus , we can conclude that @xmath21 under the scenario with feedback is larger than that under the scenario without feedback , which indicates that adopting the feedback mechanism improves the throughput performance .",
    "for the scenario without feedback , we know from ( [ eq : osd_source ] ) that @xmath202 thus , as @xmath29 increases , @xmath81 decreases which leads to an increase in @xmath21 ( refer to the analysis in appendix  [ appendix : feedback ] ) .    for the scenario with feedback , as @xmath29 increases , the manet tends to be more congested with a larger @xmath203 .",
    "thus , we know from ( [ eq : mu_s_fb ] ) that the corresponding @xmath30 decreases , and then from ( [ eq : pi_s_0_mu_s ] ) that @xmath81 decreases , leading to an increase in @xmath21 .",
    "from an intuitive point of view , a larger buffer implies that more packets can be stored and packet loss can be reduced , thus a higher throughput can be achieved .",
    "more formally , from ( [ eq : osd_source ] ) we have @xmath204 where ( [ eq : derivative_b_s ] ) follows since @xmath205 when @xmath206 and @xmath207 when @xmath89 .",
    "then we can conclude that as @xmath0 increases , @xmath81 decreases , leading to an increase in @xmath21 .",
    "let @xmath192 and substitute @xmath193 into ( [ eq : osd_relay ] ) , then we have @xmath208 where @xmath209 then we can conclude that as @xmath1 increases , @xmath71 decreases , leading to an increase in @xmath21 ( refer to expression ( [ eq : throughput ] ) ) .    regarding the infinite source buffer ( i.e. , @xmath210 ) , @xmath211 when @xmath87 , and we have @xmath212 according to the queuing theory @xcite , for a bernoulli / bernoulli queue ( i.e.",
    ", the buffer size is infinite ) , its queue length tends to infinity when the corresponding arrival rate is equal to or larger than the service rate .",
    "thus , we have @xmath213 , which leads that @xmath214 and @xmath215 .",
    "when @xmath89 , @xmath207 , and we have @xmath216 based on the analysis in appendix  [ appendix : throughput_delay ] , @xmath78 is determined as @xmath217 substituting ( [ eq : ls_bs_infinite ] ) into ( [ eq : e2e_delay ] ) we obtain ( [ eq : d_bs_infinite ] ) .",
    "regarding the infinite relay buffer ( i.e. , @xmath133 ) , from ( [ eq : osd_relay ] ) and ( [ eq : relay_length ] ) we have @xmath218 @xmath219 where ( [ eq : taylor_expansion ] ) and ( [ eq : taylor_expansion1 ] ) follow since @xmath220 is just the taylor - series expansion @xcite of @xmath221 , and ( [ eq : pi_r_infinite ] ) follows from the lhpital s rule @xcite . substituting ( [ eq : pi_r_infinite ] ) into ( [ eq : throughput ] )",
    "we obtain ( [ eq : t_br_infinite ] ) , and substituting ( [ eq : pi_r_infinite ] ) and ( [ eq : lr_br_infinite ] ) into ( [ eq : e2e_delay ] ) we obtain ( [ eq : d_br_infinite ] ) .    regarding the manet without buffer constraint ( i.e. , @xmath210 and @xmath133 ) , we can directly obtain ( [ eq : t_bs_br_infinite ] ) and ( [ eq : d_bs_br_infinite ] ) by combining the corresponding results of the infinite source buffer scenario and the infinite relay buffer scenario .",
    "for a cell - partitioned manet with ls - mac , the event that node @xmath18 gets an opportunity of source - to - destination ( resp .",
    "source - to - relay or relay - to - destination ) transmission in a time slot can be divided into the following sub - events : ( 1 ) its destination is ( resp . is not ) in the same cell with @xmath18 ; ( 2 ) other @xmath222 out of @xmath17 nodes are in the same cell with @xmath18 , while the remaining @xmath223 nodes are not in this cell ; ( 3 ) @xmath18 contends for the wireless channel access successfully .",
    "thus we have @xmath224 and @xmath225          m.  n. tehrani , m.  uysal , and h.  yanikomeroglu , `` device - to - device communication in 5 g cellular networks : challenges , solutions , and future directions , '' _ ieee commun . mag .",
    "_ , vol .",
    "52 , no .  5 ,",
    "pp . 8692 , 2014 .",
    "j.  andrews , s.  shakkottai , r.  heath , n.  jindal , m.  haenggi , r.  berry , d.  guo , m.  neely , s.  weber , s.  jafar , and a.  yener , `` rethinking information theory for mobile ad hoc networks , '' _ ieee commun . mag .",
    "_ , vol .",
    "46 , no .  12 , pp . 94101 , 2008 .",
    "a.  goldsmith , m.  effros , r.  koetter , m.  medard , and l.  zheng , `` beyond shannon : the quest for fundamental performance limits of wireless ad hoc networks , '' _ ieee commun .",
    "_ , vol .",
    "49 , no .  5 , pp . 195205 , 2011 .",
    "j.  liu , m.  sheng , y.  xu , j.  li , and x.  jiang , `` end - to - end delay modeling in buffer - limited manets : a general theoretical framework , '' _ ieee trans .",
    "wireless commun .",
    "_ , vol .  15 , no .  1 ,",
    "pp . 498511 , 2016 .",
    "j.  liu and y.  xu , `` c++ simulator : performance modeling for manets under general limited buffer constraint , '' [ online ] .",
    "available : https://www.researchgate.net/profile/jia_liu100 , 2015 .",
    "doi : 10.13140/rg.2.1.1266.8248 ."
  ],
  "abstract_text": [
    "<S> understanding the real achievable performance of mobile ad hoc networks ( manets ) under practical network constraints is of great importance for their applications in future highly heterogeneous wireless network environments . </S>",
    "<S> this paper explores , for the first time , the performance modeling for manets under a general limited buffer constraint , where each network node maintains a limited source buffer of size @xmath0 to store its locally generated packets and also a limited shared relay buffer of size @xmath1 to store relay packets for other nodes . </S>",
    "<S> based on the queuing theory and birth - death chain theory , we first develop a general theoretical framework to fully depict the source / relay buffer occupancy process in such a manet , which applies to any distributed mac protocol and any mobility model that leads to the uniform distribution of nodes locations in steady state . with the help of this framework , we then derive the exact expressions of several key network performance metrics , including achievable throughput , throughput capacity , and expected end - to - end delay . </S>",
    "<S> we further conduct case studies under two network scenarios and provide the corresponding theoretical / simulation results to demonstrate the application as well as the efficiency of our theoretical framework . finally </S>",
    "<S> , we present extensive numerical results to illustrate the impacts of buffer constraint on the performance of a buffer - limited manet .    mobile ad hoc networks , buffer constraint , throughput , delay , performance modeling . </S>"
  ]
}