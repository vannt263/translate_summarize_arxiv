{
  "article_text": [
    "it is typical in high energy physics ( hep ) to deal with classes of models , e.g. new physics extensions of the standard model ( sm ) , differing by the values of a set of ( typically continuous ) unknown parameters .    given a set of experimental measurements , one would like to define the region of the model parameter space that is in agreement with the data .",
    "this is what we refer to as _",
    "model inference_. the following ingredients are needed :    * a theoretical tool that predicts the expected values of the measured observables , given a point in the model parameter space ; * a multi - dimensional likelihood , built from the available measurements ; * and a statistical procedure that evaluates the level of agreement between the data and the predictions .",
    "while the first and second steps are not controversial , the third step is often polemical and is subject to some degree of arbitrariness .",
    "two main approaches are typically followed : bayesian , which computes the posterior probability of the expected values of the model parameters given the likelihood and a prior probability , and frequentist , which provides probability statements about possible values of the _ measurements _ given the observed data and assumed values of the model parameters .",
    "historically , most high energy physicists have preferred frequentist statistics because ( they say ) it allows one to extract statistical information from data without the need for subjective input . in this sense , these physicists are victim of the utopian idea of an analyst - free analysis , in which the  data speak for themselves \" , independently of the personal opinion and judgement of the physicists who perform the analysis .",
    "however , we are rudely awakened from this utopian dream on a daily basis as anybody who has had to evaluate a systematic uncertainty can confirm  . beyond this simple fact",
    ", we also tend to underestimate how strongly the subjective beliefs of the analyst enters the earlier stages of an analysis , as for instance when we _ define _ the form of the likelihood .",
    "physicists quote results as @xmath5 , where @xmath6 and @xmath7 summarize the result of , perhaps , a likelihood - ratio - based analysis , which already implies assumptions about the form of the likelihood  $ ] for the unknown @xmath8 as the 68% confidence region implies that we can define a one - to - one transformation @xmath9 such that the likelihood is gaussian in @xmath10 . ] .",
    "when estimating the systematic uncertainty , we typically sum the different contributions in quadrature , implying that the systematic errors are uncorrelated and , more importantly , that they may be treated as if they are statistical",
    ". this may be true of systematic uncertainties that arise ultimately from other statistics ; but many systematic uncertainties are  assigned \" based on judgement or official policy .",
    "we push this even further when we perform phenomenological analyses . while connecting the parameters of a model to the experimental observables , we often need to know a set of additional quantities ( theoretical nuisance parameters ) which are not measurable , but which may be known with some uncertainty through a theoretical calculation .",
    "this is the case , for instance , for the non - perturbative qcd parameters determined using lattice qcd calculations . in order to take into account the uncertainty on the predictions correctly ,",
    "a bayesian analyst would introduce a prior probability density function ( pdf ) for the theoretical nuisance parameters based on the best judgement of the theorist . while this is considered _ dangerously subjective _ in by many high energy physicists ,",
    "the same physicists consider it safe to modify the likelihood to take account of the theoretical uncertainty on predictions .",
    "this breaks the objective - frequentist - physicists paradigm twice : i ) the functional form used to account for theoretical uncertainty is no less subjective than the prior of a bayesian analysis and ii ) the likelihood loses its deep and precise meaning of that function obtained by inserting the observations into the probability density function describing possible observations .",
    "nobody ever did ( and it is likely that nobody ever will ) measure the theoretical nuisance parameters  indeed , many such parameters such as the factorization and renormalization scales are pure artifacts of our current reliance on perturbation theory in theoretical calculations . as a matter of fact , a physicist performing data analysis is forced to make assumptions .",
    "and there is nothing wrong with that as long as the assumptions are clearly stated .",
    "the problems come when the assumptions are hidden in the procedure and not transparent to the people not directly involved in the analysis .",
    "the contrasting attitudes described above can be summarized in terms of the following two perceived problems :    * for some high energy physicists , introducing a prior is unacceptable because it brings subjectivity into science .",
    "_ `` the origin of the problem lies in the very first bayesian assumption , namely that unknown model parameters are to be understood as mathematical objects distributed according to pdfs , which are assumed to be known : the priors .",
    "obviously , the choice of the priors can not be irrelevant ; hence , the bayesian treatment is doomed to lead to results which depend on the decisions made , necessarily on an unscientific basis , by the authors of a given analysis , for the choice of these extraordinary pdfs . ''",
    "_  @xcite .",
    "* for some statisticians , a meaningful statistical analysis is not possible in the absence of an analysis procedure that allows one to incorporate a priori knowledge in a coherent way . _",
    "`` the frequentist approach to hypothesis testing does not permit researchers to place probabilities of being correct on the competing hypotheses .",
    "this is because of the limitations on mathematical probabilities used by frequentists . for the frequentists",
    ", probabilities can only be defined for random variables , and hypotheses are not variables ( they are not observables ) ... this limitation for frequentists is a real drawback because the applied researcher would really like to be able to place a degree of belief on the hypothesis .",
    "he or she would like to see how the weight of evidence modifies his / her degree of belief ( probability ) on the hypothesis being true . '' _",
    "@xcite .",
    "the use of reference priors  @xcite is emerging as a concrete way to solve the two problems . while a detailed discussion of the reference priors is beyond the scope of this paper , we highlight here their most appealing properties .    the main concern against the use of a bayesian analysis in hep is related to a priori ignorance , more than a priori knowledge .",
    "whenever a priori knowledge is available ( e.g. the measurement of the luminosity , which is used to translate an observed signal yield into a cross section measurement ) , there is a general consensus that an _ evidence - based _",
    "prior should be used .",
    "the real issue is how we should parameterize `` ignorance '' .",
    "the use of a flat prior , a hep standard , is not quite the right answer .",
    "reference priors can be seen as a model of ignorance in the sense that , on average , they maximize the influence of the likelihood relative to the prior ; hence they are a solution to this problem . more precisely , for a given likelihood , the reference prior is the prior function that _ on average _ maximizes the asymptotic kullback - leibler divergence  @xcite between the prior and the posterior , hence enhancing the role of the likelihood ( the data ) over the prior .",
    "this is exactly the kind of behavior that we would like for a model of ignorance . and",
    "this is what we assume the flat prior does for us , when we use it .",
    "unfortunately , the flatness of the prior is not invariant under reparameterization . unlike the flat prior ,",
    "reference priors give reparameterization - invariant results in the cases typically considered in hep ( e.g. one - to - one transformations for which the jacobian is not singular  @xcite ) .",
    "the use of reference priors in hep has been recently proposed in ref .",
    "@xcite , where the application in the case of a counting experiment is discussed .",
    "this has been applied to real lhc data , in one of the cms supersymmetry ( susy ) searches  @xcite .    in the following , we apply the procedure described in ref .",
    "@xcite to two specific cases : i ) the determination of the parameters @xmath0 and @xmath11 ( at fixed @xmath12 and @xmath13 ) of a _ simplified",
    "_ ckm matrix and ii ) the determination of the parameters in the case of a susy model   and @xmath3 , fixing @xmath14 , @xmath15 , and positive @xmath16 . ] . in both cases , as an illustration , we limit the discussion to the determination of two parameters . the generalization to @xmath17 dimensions is computationally more demanding , but conceptually equivalent .",
    "in both cases , we start from one experimental measurement , for which the likelihood can be analytically modeled without too much arbitrariness .",
    "we briefly describe the derivation of the reference posterior , following ref .",
    "we then map the 1-d posterior into a @xmath4-d ( @xmath18 in our examples ) function of the model parameters , introducing the _ look - alike _ ( ll ) prescription .",
    "this function , based on a reference prior , can then be used as the prior in a recursive application of bayes theorem to include other measurements .",
    "when looking for a signal , produced by the process under study , we are confronted with a poisson count of a signal on top of a background coming from other physics processes .",
    "the likelihood for the signal , in the absence of a background , is described by a poisson function . in the presence of a background",
    "the likelihood asymptotically converges to a gaussian density . under these conditions ,",
    "the reference prior is jeffrey s prior for a poisson likelihood , @xmath19 .",
    "this is the case for the exclusive measurement of @xmath20 from @xmath21 decays .",
    "what one measures is the branching ratio @xmath22 , which is the related to the the absolute value of the ckm matrix element @xmath20 as : @xmath23 where evidence - based priors are available both for the width of the @xmath24 meson @xmath25 ( from other measurements ) and the @xmath26 form factor @xmath27 ( from theory ) .",
    "one can determine the reference posterior for the @xmath28 using @xmath29 .    for susy searches ,",
    "one looks for a signal yield @xmath30 in a signal - sensitive _ box _ , defined by a selection using signal - vs - background separating variables .",
    "one observes a yield @xmath31 , where @xmath16 is the background surviving the signal - enhancing selection .",
    "the expected background @xmath32 is estimated from a sideband region where no signal is expected , where the observed yield in the sideband is @xmath33 and the scaling factor @xmath34 is such that @xmath35 is the expected background yield in the sideband . in formulas :    * the likelihood is @xmath36 , * the prior for @xmath16 is @xmath37 and * the prior on @xmath30 is @xmath38 ,    where @xmath39 is the gamma function .",
    "once the 1-d reference - posterior is derived as described above , we translate this into an @xmath4-d function of the model parameters . while rigorous algorithms exist to build the @xmath4-d reference prior  @xcite , we follow here a computationally simpler _ heuristic _ construction , described below , which we call the _ look - alike prescription_.",
    "mapping the 1-d reference posterior to the @xmath4-d space of the model parameter under consideration could be achieved by demanding that the @xmath4-d pdf satisfy two requirements :    * all models predicting the same values for the parameter @xmath8 ( @xmath20 and @xmath30 in our two examples ) associated with the posterior density @xmath40 are equi - probable and * the @xmath4-d function should be such that it maps back to a 1-d function @xmath41 identical to the @xmath40 with which we started",
    ".    given the mapping @xmath42 predicted by the physics model , these requirements are sufficient to map @xmath40 to @xmath43 .",
    "we first write the @xmath4-d function as @xmath44 .",
    "the computation of @xmath45 goes as follows : @xmath46 where the last equality follows from the second condition .",
    "this implies that @xmath47 which is the surface of the region spanned by the look - alike ( ll ) models , that is , models giving the same value @xmath48  -d problem is the calculation of this surface term . ] .",
    "the case of @xmath20 is useful because it allows us to explain how this works in practice .",
    "all the models such that @xmath49 predict the same value of @xmath50 .",
    "this makes them ll models , by our definition .",
    "the ll domain is a circle centered at @xmath51 with radius @xmath52 .",
    "the @xmath4-d function is therefore , @xmath53 where @xmath54 is the reference posterior for @xmath50 .",
    "the function @xmath55 is then used as the prior to fit the ckm matrix  @xcite including the measurement of the ckm phase @xmath56 .",
    "this step gives the allowed region for @xmath0 and @xmath57 shown in the left plot of fig .",
    "[ fig : utres ] ) , which is to be compared to a similar plot obtained using flat priors for @xmath0 and @xmath57 ( right plot of fig .",
    "[ fig : utres ] ) .",
    "the results of these two calculations are consistent .",
    "however , the reference posterior for @xmath50 provides a more solid foundation for determining the prior to associate with the ckm parameters .     and",
    "@xmath57 , obtained using the reference posterior for @xmath20 and the ll prescription ( left ) , or using flat priors for @xmath58 and @xmath57 ( right).,title=\"fig : \" ]   and @xmath57 , obtained using the reference posterior for @xmath20 and the ll prescription ( left ) , or using flat priors for @xmath58 and @xmath57 ( right).,title=\"fig : \" ]    our second case study , which uses a simplified version of the msugra model , is more complicated since eq .",
    "[ eq : llcontour ] can not be solved analytically in the case of a generic search for new physics . in this case , the ll domain is given by all the models predicting the same expected signal yield @xmath30 .",
    "the expected signal yield as a function of the model parameters can be written as @xmath59 , where only the luminosity @xmath60 is a constant , while both the cross section @xmath7 and the efficiency of the applied selection @xmath61 depends on the features of the model ( e.g. the masses of the susy particles ) , and hence on the model parameters .",
    "the function @xmath62 can be computed from the susy lagrangian , while @xmath63 has a non - trivial dependence on the models , through several effects connected to the detector response .",
    "for instance , a model with large ( small ) mass differences would give a large ( small ) value of @xmath61 , since harder ( softer ) spectra for the visible particles produced in the susy decay chain will have larger ( smaller ) chance to survive the kinematic cuts .",
    "in general , the connection between the features of the model and the detector performance produces non - analytical iso - yield contours for the ll domains .",
    "this is illustrated in fig .",
    "[ fig : msugrall ] , where @xmath63 and @xmath64 are shown in the case of a hypothetical susy search  @xcite .",
    "and @xmath64 functions in the case of a hypothetical susy search  @xcite.,title=\"fig : \" ]   and @xmath64 functions in the case of a hypothetical susy search  @xcite.,title=\"fig : \" ]    on the other hand , all the iso - yield contours have infinite length , resulting in constant @xmath65 if one considers the full domain for @xmath2 and @xmath3 , and approximately constant if one uses a large - enough domain in practice   and @xmath3 , where the susy particles are so heavy that they decouple from the sm ones , effectively recovering the sm limit . ] .",
    "we can then take @xmath66 as a constant and show how the method works .",
    "it has to be clearly stated that this is an approximation , and that the computation of the surface term of eq .",
    "[ eq : llcontour ] is the main challenge in the applicability of the proposed method in its exact form ( see ref .",
    "@xcite for details ) .    for illustration , we take the cms low mass ( lm ) point  @xcite ( @xmath67 , @xmath68 as the _ true",
    "_ state of nature and we simulate the case of an experiment giving a result exactly at the expectation , for low ( 1 pb@xmath69 ) , moderate ( 100 pb@xmath69 ) , and large ( 500 pb@xmath69 ) statistics .",
    "figure  [ fig : msugraresult ] shows the 2-d function obtained by the ll prescription . with increasing sample size",
    ", the function shows a peak corresponding to the _ true _ value and to all its ( degenerate ) ll models , showing the consistency of the procedure .",
    "( left ) , 100 pb@xmath69 ( center ) , and 500 pb@xmath69 ( right ) integrated luminosity .",
    "we assume a _ measurement _ perfectly in agreement with the expectation from the true model , corresponding to @xmath67 , @xmath70 . ]",
    "we described the use of the reference prior to 1-d cases ( typical of a hep measurement ) and how this can be used to define an @xmath4-d function of the model , induced by the 1-d reference posterior , which may then be used as a prior for further applications ( e.g. to fit to model parameters ) .",
    "the connection between the 1-d posterior on a measurable quantity @xmath30 ( e.g. a signal yield on top of a background @xmath34 ) and an @xmath4-d function of a set of interesting parameters ( e.g. the parameters of a susy model ) is established through the look - alike prescription , which defines a heuristic procedure on the basis of two minimal conditions : i ) the models predicting the same expected value for the interesting variable @xmath30 are equi - probable and ii ) the @xmath4-d function should map back to the 1-d reference posterior for @xmath30 , from which we started .",
    "this requires the calculation of a surface term ( see eq .",
    "[ eq : llcontour ] ) , which can be performed numerically  @xcite .",
    "while in specific cases this choice of a prior might be in conflict with a subjective assessment that could favor one region of the parameter space over another , it should be stressed that this _ bayesian _ approach is likely to give the best frequentist performance because of the good frequentist properties of reference priors .",
    "we provided two simplified 2-d examples to illustrate the method , for which computational complications are absent or marginal .",
    "work is in progress to extend this procedure to more realistic cases  @xcite .",
    "the authors would like to thank j.  berger for the helpful suggestions and the interesting discussion ."
  ],
  "abstract_text": [
    "<S> we describe the application of model inference based on reference priors to two concrete examples in high energy physics : the determination of the ckm matrix parameters @xmath0 and @xmath1 and the determination of the parameters @xmath2 and @xmath3 in a simplified version of the cmssm susy model . </S>",
    "<S> we show how a 1-dimensional reference posterior can be mapped to the @xmath4-dimensional ( @xmath4-d ) parameter space of the given class of models , under a minimal set of conditions on the @xmath4-d function . </S>",
    "<S> this reference - based function can be used as a prior for the next iteration of inference , using bayes theorem recursively . </S>"
  ]
}