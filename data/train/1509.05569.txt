{
  "article_text": [
    "let @xmath0 , be a sequence of @xmath1-valued i.i.d .",
    "random vectors defined on a complete probability space @xmath2 and having the density @xmath3 with respect to the lebesgue measure .",
    "furthermore , @xmath4 denotes the probability law of @xmath5 , and @xmath6 is the mathematical expectation with respect to @xmath4 .",
    "our goal is to estimate the density @xmath3 at a given point @xmath7 using the observation @xmath8 , @xmath9 . as an estimator ,",
    "we mean any @xmath10-measurable mapping @xmath11 and the accuracy of an estimator is measured by the _ pointwise risk _ : @xmath12:= \\bigl({\\mathbb e}_f^{(n ) } \\bigl{\\vert}\\widehat { f}(x_0)-f(x_0)\\bigr{\\vert}^q \\bigr)^{{1}/{q } } , \\qquad q\\geq1 . \\ ] ]    the discussion of traditional methods and a part of the vast literature on the theory and application of the density estimation is given by devroye and gyrfi @xcite , silverman @xcite and scott  @xcite .",
    "we do not pretend here to provide with a detailed overview and mention only the results which are relevant for considered problems .",
    "the minimax and adaptive minimax multivariate density estimation with @xmath13-loss on particular functional classes was studied in bretagnolle and huber @xcite , ibragimov and khasminskii @xcite , devroye and lugosi @xcite , efroimovich @xcite , hasminskii and ibragimov @xcite , golubev @xcite , donoho _ et al . _",
    "@xcite , kerkyacharian , picard and tribouley @xcite , gin and guillou @xcite , juditsky and lambert - lacroix @xcite , rigollet  @xcite , massart  @xcite ( chapter  7 ) , samarov and tsybakov @xcite , birg @xcite , mason @xcite , gin and nickl  @xcite , chacn and duong @xcite and goldenshluger and lepski @xcite . in comte and lacour  @xcite ,",
    "the pointwise setting was first considered in the context of multidimensional deconvolution model .",
    "more recently , in goldenshluger and lepski @xcite , adaptive minimax upper bounds were proved for multivariate density estimation with @xmath13-risks on anisotropic nikolskii classes using a local ( pointwise ) procedure .",
    "the use of nikolskii classes allows to consider the estimation of anisotropic and inhomogeneous densities ; see ibragimov and khasminskii @xcite , goldenshluger and lepski @xcite and lepski @xcite .    in this paper , we focus on the problem of the minimax and adaptive minimax pointwise multivariate density estimation over the scale of anisotropic nikolskii classes .    _ minimax estimation_. in the framework of the minimax estimation , it is assumed that @xmath3 belongs to a certain set of functions @xmath14 , and then the accuracy of an estimator @xmath15 is measured by its _ maximal risk _ over @xmath14 : @xmath16:=\\sup _",
    "{ f\\in\\sigma } \\bigl({\\mathbb e}_f^{(n)}\\bigl{\\vert}\\widehat{f}(x_0)-f(x_0)\\bigr{\\vert}^q \\bigr)^{{1}/{q}},\\qquad q\\geq1.\\ ] ] the objective here is to construct an estimator @xmath17 which achieves the asymptotic of _ the minimax risk _ ( minimax rate of convergence ) : @xmath18\\asymp\\inf _ { \\widehat { f}}{{\\cal r}}_n^{(q ) } [ \\widehat{f},\\sigma ] : = \\varphi_n(\\sigma ) . \\ ] ] here , infimum is taken over all possible estimators .",
    "_ smoothness assumption_. let @xmath14 be either hlder classes @xmath19 or @xmath13-sobolev classes @xmath20 of univariate functions . here",
    ", @xmath21 represents the smoothness of the underlying density and @xmath22 is the index of the norm where the smoothness is measured .",
    "then @xmath23 \\\\[-8pt ] \\nonumber \\varphi_n \\bigl({{\\mathbb w}}(\\beta , p , l ) \\bigr)&= & n^{-{(\\beta-1/p)}/{(2(\\beta-1/p)+1)}},\\qquad \\beta>0 , 1<p < \\infty.\\end{aligned}\\ ] ] these minimax rates can be obtained from the results developed by donoho and low @xcite ; see also ibragimov and khasminskii @xcite , and hasminskii and ibragimov @xcite .",
    "let now @xmath24 where @xmath25 is an anisotropic hlder class determined by the smoothness parameter @xmath26 . in this case , @xmath27^{-1 } , \\qquad\\beta_i>0 , i=\\overline{1,d}.\\ ] ] the latter result can be obtained from kerkyacharian , lepski and picard @xcite , proposition  1 , in the framework of the gaussian white noise model .",
    "the similar minimax results will be established for pointwise multivariate density estimation in section  [ sec : minimaxresults ] ; see theorems  [ theo : minimaxlowerbound1 ] and  [ theo : minimaxupperbound ] .",
    "it is important to emphasize that minimax rates depend heavily on the dimension @xmath28 .",
    "let us briefly discuss how to reduce the influence of the dimension on the accuracy of estimation ( curse of dimensionality ) .",
    "the approach which have been recently proposed in lepski @xcite is to take into account the eventual independence structure of the underlying density .",
    "_ structural assumption_. note @xmath29 the set of all subsets of @xmath30 and @xmath31 the set of all partitions of @xmath32 completed by the empty set @xmath33 . for all @xmath34 and @xmath35 note also @xmath36 , @xmath37 , @xmath38 and put @xmath39 obviously , @xmath40 is the marginal density of @xmath41 and , to take into account the independence structure of the density @xmath3 , we consider the following set : @xmath42    in this paper , we focus on the problem of pointwise multivariate density estimation on anisotropic nikolskii classes .",
    "in particular , we will prove that the minimax rate on the class @xmath43 ( introduced in lepski @xcite , see the definition in section  [ sec : nikolskiiclasses ] ) for fixed @xmath44 , @xmath45^d$ ] , @xmath46 , @xmath47 , are given by @xmath48 . \\ ] ] if @xmath49 , then the structural assumption does not exist , that means formally @xmath50 , and we come to the rates given in ( [ eq : univariateminimaxrates ] ) .",
    "note that @xmath51 coincides with the set of densities belonging to @xmath19 and that @xmath52 contains the set of densities belonging to @xmath20 .",
    "if @xmath53 , @xmath54 , and @xmath55 we find again the rates given in ( [ eq : multivariateminimaxrates ] ) , and @xmath56 coincides with a set of densities belonging to @xmath25 .",
    "note however that if @xmath57 the latter rates can be essentially improved . indeed ,",
    "if , for instance , @xmath58 and @xmath59 , then @xmath60 and @xmath61 moreover , @xmath62 does not depend on the dimension @xmath28 .",
    "we remark that minimax rates ( accuracy of estimation ) depend heavily on the parameters @xmath63 and @xmath64 .",
    "their knowledge can not be often supposed in particular practice .",
    "it makes necessary to find an estimator whose construction would be parameter s free .",
    "_ adaptive minimax estimation_. in the framework of the adaptive minimax estimation the underlying density @xmath3 is supposed to belong to the given scale of functional classes @xmath65 .",
    "for instance , if @xmath66 , @xmath67 , or if @xmath68 , @xmath69 .",
    "the first question arising in the framework of the adaptive approach consists in the following : does there exists an estimator @xmath70 such that @xmath71 \\bigr\\ } < + \\infty \\qquad\\forall\\alpha\\in{{\\cal a}},\\ ] ] where @xmath72 is the minimax rate of convergence over @xmath73 .",
    "as it was shown in lepski @xcite for the gaussian white noise model , the answer of this question is negative if @xmath66 , @xmath67 .",
    "brown and low @xcite extended this result to the pointwise density estimation .",
    "further butucea @xcite extended the results of brown and low @xcite over the scale of @xmath13-sobolev classes @xmath20 . in section",
    "[ sec : optimality ] , we will prove that the answer is also negative for multivariate density estimation at a given point over the scale of anisotropic nikolskii classes @xmath43 .",
    "thus , for problems in which ( [ eq : adaptivoptimal ] ) does not hold we need first to find a family of normalizations @xmath74 and an estimator @xmath75 such that @xmath76 \\bigr\\ } < + \\infty \\qquad\\forall\\alpha\\in{{\\cal a}}.\\ ] ] any family of normalizations satisfying ( [ eq : adaptiv ] ) is called admissible and the estimator @xmath77 is called @xmath78-adaptive .",
    "next , we have to provide with the criterion of optimality allowing to select `` the best '' admissible family of normalizations , usually called adaptive rate of convergence .",
    "the first criterion was proposed in lepski @xcite and it was improved later in tsybakov @xcite and in klutchnikoff  @xcite .    in particular , in lepski @xcite and in butucea @xcite , it was shown that the adaptive rate of convergence for the considered problem is @xmath79 with respect to the criterion in lepski @xcite and tsybakov @xcite , respectively . here",
    ", @xmath80 is an arbitrary positive number .",
    "later klutchnikoff @xcite studied the pointwise adaptive minimax estimation over anisotropic hlder classes , in the gaussian white noise model . the consideration of anisotropic functional classes required to develop a new criterion of optimality . following this criterion ,",
    "klutchnikoff  @xcite proved that the adaptive rate of convergence is @xmath81 recently , comte and lacour @xcite found a similar form of admissible sequence for pointwise adaptive minimax estimation in the deconvolution model .    in section  [",
    "sec : adaptiveminimaxresults ] , we provide with minimax adaptive estimator in pointwise multivariate density estimation over the scale of anisotropic nikolskii classes .",
    "we will take into account not only the approximation properties of the underlying density but the eventual independence structure as well . to analyze the accuracy of the proposed estimator",
    ", we establish so - called pointwise oracle inequality proved in section  [ oracle - inequality - proof ] .",
    "we will also show that the adaptive rate of convergence is given by @xmath82 . \\ ] ] to assert the optimality of this family of normalizations , we generalize the criterion proposed in klutchnikoff @xcite ; see section  [ sec : optimality ] .",
    "_ organization of the paper_. in section  [ selection - oracle - inequality ] , we provide a measurable data - driven selection rule based on bandwidth selection of kernel estimators and we derive an oracle - type inequality for the selected estimator at a given point . in section  [ minimax - adaptive - estimation ] ,",
    "we treat the complete problem of minimax and adaptive minimax pointwise multivariate density estimation on a scale of anisotropic nikolskii classes taking into account the independence structure of the underlying density . in section  [ sec : discussion ]",
    ", we briefly compare our local method with the global one developed in lepski @xcite .",
    "proofs of all main results are given in section  [ proofs ] .",
    "proofs of technical lemmas are postponed to the .",
    "let @xmath83 be a fixed symmetric kernel satisfying @xmath84 , @xmath85 $ ] , , @xmath86 for all @xmath34 , @xmath87^d$ ] and @xmath35 put also @xmath88 then introduce the family of estimators @xmath89:= \\biggl\\{\\widehat{f}_{(h,{{\\cal p}})}^{(n)}(x_{0})= \\prod_{i\\in{{\\cal p}}}\\widehat{f}_{h_i}^{(n)}(x_{0,i } ) , ( h,{{\\cal p}})\\in ( 0,1]^d\\times{\\mathfrak{p}}\\biggr\\}. \\ ] ]    note first that @xmath90 is the parzen ",
    "rosenblatt estimator ( see , e.g. , rosenblatt  @xcite , parzen @xcite ) with kernel @xmath91 and multibandwidth @xmath92 .    next , the introduction of the estimator @xmath93 is based on the following simple observation .",
    "if there exists @xmath94 , the idea is to estimate separately each marginal density corresponding to @xmath95 .",
    "since the estimated density possesses the product structure , we seek its estimator in the same form .    below we propose a data driven selection from the family @xmath96 $ ] .",
    "to define our selection rule , we need to introduce some notation and quantities .",
    "_ auxiliary estimators . _ for @xmath34 and @xmath87^d$ ] put @xmath97 . \\ ] ]    introduce for @xmath34 and @xmath98^d$ ] auxiliary estimators @xmath99 note that the idea to use such auxiliary estimators , defined with the multibandwidth @xmath100 , appeared for the first time in kerkyacharian , lepski and picard @xcite , in the framework of the gaussian white noise model .",
    "we endow the set @xmath31 with the operation `` @xmath101 '' introduced in lepski @xcite : for any @xmath102 @xmath103 then we define for @xmath98^d$ ] and @xmath104 @xmath105    _ set of parameters_. our selection rule consists in choosing an estimator @xmath93 when the parameter @xmath106 belongs at most to the set @xmath107 $ ] defined as follows .",
    "let @xmath108 , @xmath109 $ ] , @xmath110 , be fixed numbers and let @xmath111^{{\\vert}i{\\vert}}$ ] , @xmath34 , be fixed multibandwidths .",
    "all these parameters will be chosen in accordance with our procedure .",
    "set also @xmath112 \\}$ ] and @xmath113 , where constants @xmath114 ,    s\\in{{\\mathbb n}}^ * , q\\geq1 $ ] , are given in section  [ constants ] .",
    "the explicit expressions of @xmath115 $ ] are too cumbersome and it is not convenient for us to present them right now .    for all @xmath34 and all integer @xmath116 introduce @xmath117^{|i|}\\dvt v_m^{(i)}v_{{\\mathfrak{h}}_i^{(i)}}\\leq v_{h_i } \\leq v_{m-1}^{(i)}v_{{\\mathfrak{h}}_i^{(i)}}\\bigr\\}\\cap\\prod_{i\\in i}\\biggl[\\frac{1}{n},\\bigl(v_m^{(i)}\\bigr)^{-{\\mathfrak{z}}}{\\mathfrak{h}}_i^{(i)}\\biggr ] , \\\\[-2pt ] { \\mathfrak{h}}_{m,2}^{(i)}&:=&\\bigl\\{h_i\\in ( 0,1]^{|i|}\\dvt v_m^{(i)}v_{\\mathrm{max}}\\leq v_{h_i}\\leq v_{m-1}^{(i)}v_{\\mathrm{max}}\\bigr\\ } \\cap\\prod_{i\\in i}\\biggl[\\frac{1}{n},\\bigl(v_m^{(i)}\\bigr)^{-{\\mathfrak{z}}}{\\mathfrak{h}}_i^{(i)}\\biggr ] , \\\\[-2pt ] { \\mathfrak{h}}^{(i)}&:=&\\biggl(\\bigcup_{m=1}^{m_n(i)}{\\mathfrak{h}}_{m,1}^{(i)}\\biggr)\\bigcup\\biggl(\\bigcup_{m=1}^{m_n(i)}{\\mathfrak{h}}_{m,2}^{(i)}\\biggr),\\end{aligned}\\ ] ] where @xmath118 , @xmath119 is the largest integer satisfying @xmath120\\geq   \\frac{\\ln(n)}{an}$ ] and @xmath121 , and @xmath122 is defined below .",
    "define finally @xmath123:= \\bigl\\{(h,{{\\cal p}})\\in(0,1]^d\\times{\\mathfrak{p}}\\dvt h_i \\in{\\mathfrak{h}}^{(i ) } , \\forall i\\in{{\\cal p}}\\bigr\\}. \\ ] ]    _ extra parameters .",
    "_ let @xmath124 and @xmath125 be arbitrary subsets of @xmath126^d$ ] and @xmath31 , respectively . the selection rule ( [ eq : selectionrule1])([eq : selectionrule2 ] ) below run over @xmath127:= ( \\overline { { \\mathfrak{h}}}\\times\\overline{{\\mathfrak{p } } } ) \\cap{\\mathfrak{h } }",
    "[ { \\mathfrak{p}}]$ ] and the reasons for introducing these extra parameters are discussed in remark  [ selectionrule ] . in particular , for measurability reasons , we will always suppose that @xmath124 is either a compact or a finite subset of @xmath126^d$ ] .",
    "set @xmath128^{d^2 - 1}$ ] , where @xmath129 } \\sup_{(\\eta,{{\\cal p}}')\\in\\overline{{\\mathfrak{h } } } [ \\overline{{\\mathfrak{p } } } ] } \\sup_{i\\in{{\\cal p}}\\circ{{\\cal p } } ' } \\bigl[2 \\widetilde{g}_{h_i\\vee\\eta_i}(x_{0,i } ) \\bigr ] .",
    "\\ ] ]    put also @xmath130 and , for @xmath131^d\\times{\\mathfrak{p}}$ ] , @xmath132\\vee \\biggl[\\frac{v_{\\mathrm{max}}}{\\inf_{i\\in { { \\cal p}}}v_{\\mathfrak{h}_i^{(i ) } } } \\biggr ] . \\ ] ]    define finally , for @xmath131^d\\times{\\mathfrak{p}}$ ] , @xmath133 ^ 2 \\{1\\vee\\ln\\delta(h,{{\\cal p } } ) \\}}{nv(h,{{\\cal p}})}},\\qquad v(h , { { \\cal p}}):=\\inf_{i\\in{{\\cal p}}}v_{h_i}. \\ ] ]      for @xmath131^d\\times{\\mathfrak{p}}$ ] introduce @xmath134 \\\\[-8pt ] \\nonumber & & \\quad:=\\sup _ { ( \\eta,{{\\cal p}}')\\in\\overline { { \\mathfrak{h } } } [ \\overline{{\\mathfrak{p } } } ] } \\bigl[\\bigl{\\vert}\\widehat{f}_{(h,{{\\cal p}}),(\\eta,{{\\cal p}}')}^{(n)}(x_{0})- \\widehat{f}_{(\\eta,{{\\cal p}}')}^{(n)}(x_{0})\\bigr{\\vert}-\\lambda _",
    "n(x_0 ) \\bigl\\{\\widehat{{{\\cal u}}}_{(\\eta,{{\\cal p}}')}(x_0)+ \\widehat{{{\\cal u}}}_{(h,{{\\cal p}})}(x_0 ) \\bigr\\ } \\bigr]_+.\\quad\\end{aligned}\\ ] ] define finally @xmath135 satisfying @xmath136 } \\bigl[\\widehat{\\delta}_{(h,{{\\cal p}})}(x_0)+2 \\lambda_n(x_0)\\widehat{{{\\cal u}}}_{(h,{{\\cal p}})}(x_0 ) \\bigr].\\ ] ] the selected estimator is @xmath137 .    similarly to section  2.1 in lepski @xcite it is easy to show that @xmath138 is @xmath10-measurable and that @xmath139 $ ] .",
    "it follows that @xmath140 is also a @xmath10-measurable random variable .",
    "[ selectionrule ] the necessity to introduce the extra parameters @xmath124 and @xmath141 is dictated by several reasons .",
    "the first one is computational namely the computation of @xmath142 and @xmath143 .",
    "however , the computational aspects of the choice of @xmath141 and @xmath124 are quite different .",
    "typically , @xmath124 can be chosen as an appropriate grid in @xmath126^d$ ] , for instance , dyadic one , that is sufficient for proving adaptive properties of the proposed estimator .",
    "the choice of @xmath141 is much more delicate .",
    "the reason of considering @xmath141 instead of @xmath31 is explained by the fact that the cardinality of @xmath31 grows exponentially with the dimension @xmath28 .",
    "therefore , if @xmath144 , for large values of @xmath28 our procedure is not practically feasible in view of huge amount of comparisons to be done . in the latter case , the interest of our result is theoretical .",
    "note also that the best attainable trade - off between approximation and stochastic errors depends heavily on both the number of observations and the effective dimension @xmath145 .",
    "thus , if @xmath146 is big the corresponding independence structure does not bring a real improvement of the estimation accuracy .",
    "so , in practice , @xmath141 is chosen to satisfy @xmath147 , @xmath148 .",
    "the choice of the parameter @xmath149 ( made by a statistician ) is based on the compromised between the sample size @xmath150 , the desirable quality of estimation and the number of computations .",
    "for instance , one can consider @xmath151 , that means that @xmath141 contains two elements , @xmath152 and @xmath153 .",
    "the latter case corresponds to the observations having independent components and it can be illustrated in example  [ ex : densityestimation ] below . on the other hand , in the case of low dimension @xmath28 , one can always take @xmath144 , since if @xmath154 , @xmath155 , @xmath156 , @xmath157 , @xmath158 , @xmath159 , etc .    other reasons are related to the possibility to consider various problems arising in the framework of minimax and minimax adaptive estimation and they will be discussed in detail in sections  [ sec : minimaxresults ] and [ sec : optimality ] . here , we only mention that the choice @xmath160 allows to study the adaptive estimation of a multivariate density on @xmath1 without taking into account eventual independence structure .",
    "we would like to emphasize that the latter problem was not studied in the literature .",
    "at last the introduction of @xmath141 allows to minimize the assumptions imposed on the density to be estimated .",
    "in particular , the oracle inequality corresponding to @xmath160 is proved over the set of bounded densities ; see corollary  [ cor : oracleinequality ] .    in spite of the fact that the construction of the proposed procedure does not require any condition on the density @xmath3 , the following assumption will be used for computing its risk : @xmath161:= \\bigl\\{f\\dvt \\sup_{{{\\cal p}},{{\\cal p}}'\\in\\overline{{\\mathfrak{p}}}}\\sup_{i\\in{{\\cal p}}\\circ{{\\cal p}}'}{\\vert}f_i{\\vert}_{\\infty } \\leq\\mathbf{f } , \\exists{{\\cal p}}\\in{\\mathfrak{p}}(f)\\cap \\overline{{\\mathfrak{p } } } \\bigr\\},\\qquad   0<\\mathbf{f}<+\\infty.\\ ] ] note that the considered class of densities is determined by @xmath125 and in particular , if @xmath162 , @xmath163&= & \\bigl\\{f\\dvt \\sup_{i\\in{{\\cal i}}_d } { \\vert}f_i{\\vert}_{\\infty}\\leq\\mathbf{f } \\bigr\\}\\subseteq { \\mathbb f}_d [ \\mathbf { f},\\overline{{\\mathfrak{p } } } ] , \\\\ { \\mathbb f}_d \\bigl[\\mathbf{f } , \\{\\overline{\\varnothing } \\ } \\bigr]&= & \\bigl\\ { f\\dvt { \\vert}f{\\vert}_{\\infty}\\leq\\mathbf{f } \\bigr\\ } , \\qquad { \\mathbb f}_d \\bigl[\\mathbf{f } , \\{{{\\cal p}}\\ } \\bigr]= \\bigl\\{f\\dvt \\sup_{i\\in{{\\cal p } } } { \\vert}f_i{\\vert}_{\\infty}\\leq\\mathbf{f } , { { \\cal p}}\\in{\\mathfrak{p}}(f ) \\bigr\\}.\\end{aligned}\\ ] ]      for @xmath34 and @xmath164^d\\times[0,1]^d$ ] introduce @xmath165\\,{\\mathrm{d}}u , \\ ] ] where here and later @xmath166 denotes the coordinate - vise product of @xmath167 .    for @xmath131^d\\times{\\mathfrak{p}}$ ]",
    "define @xmath168^d}{\\vert}{{\\cal b}}_{h_i,\\eta_i}(x_{0,i}){\\vert}$ ] .",
    "introduce finally , if exists @xmath169 , @xmath170\\dvt{{\\cal p}}\\in{\\mathfrak{p}}(f ) } \\biggl [ { { \\cal b}}_{(h,{{\\cal p}})}(x_0)+\\sqrt{\\frac{1\\vee\\ln\\delta(h,{{\\cal p}})}{nv(h,{{\\cal p } } ) } } \\biggr ] . \\ ] ] the quantity @xmath171 can be viewed as the optimal trade - off between approximation and stochastic errors provided by estimators involved in the selection rule .",
    "[ theo : oracleinequality ] let @xmath172^d$ ] and @xmath173 be arbitrary subsets such that @xmath127 $ ] is non - empty .",
    "then for any @xmath174 , any @xmath175 and any integer @xmath176 : @xmath177 \\leq\\alpha_1{\\mathfrak{r}}_n(f)+\\alpha_2 [ nv_{\\mathrm{max } } ] ^{-{1}/{2}}\\qquad \\forall f\\in{\\mathbb f}_d [ \\mathbf { f } , \\overline{{\\mathfrak{p } } } ] , \\ ] ] where @xmath178 and @xmath179 are given in the proof of the theorem .    considering the case @xmath180 and noting @xmath181 we come to the following consequence of theorem  [ theo : oracleinequality ] .",
    "[ cor : oracleinequality ] let assumptions of theorem  [ theo : oracleinequality ] be fulfilled . then , for all densities @xmath3 such that @xmath182 , @xmath183 \\leq\\alpha_1\\inf_{h\\in \\overline { { \\mathfrak{h}}}\\cap{\\mathfrak{h } } } \\biggl [ \\sup _ { \\eta\\in[0,1]^d}\\bigl{\\vert}{{\\cal b}}_{h,\\eta } ( x_{0})\\bigr { \\vert}+\\sqrt{\\frac{1\\vee\\ln ( { v_{\\mathfrak { h}}}/{v_{h } } ) } { nv_{h } } } \\biggr]+\\alpha_2 [ nv_{\\mathfrak{h } } ] ^{-{1}/{2}}.\\ ] ]    looking at the assertion of theorem  [ theo : oracleinequality ] and its corollary  [ cor : oracleinequality ] it is not clear what can be gained by taking into account eventual independence structure . this issue will be scrutinized in section  [ minimax - adaptive - estimation ] , but some conclusions can be deduced directly from the latter results .",
    "consider the following example .",
    "[ ex : densityestimation ] for any @xmath184 , put @xmath185}(t)+\\tfrac{1}{4 } \\mathbf { 1}_{(1/4,3/4]}(t)+ ( 1-t ) \\mathbf{1}_{(3/4,1]}(t ) \\bigr\\ } , \\ ] ] and define @xmath186 , @xmath35 .",
    "it is easily seen that @xmath187 is a probability density and the goal is to estimate @xmath188 , @xmath189 .",
    "choose @xmath190 , @xmath191 and let @xmath192 .",
    "put @xmath193 , @xmath194 and let @xmath195 . since , in this case , @xmath196 contains @xmath197 elements , our estimator can be computed in a reasonable time .    moreover , in accordance with the oracle - type inequality proved in theorem  [ theo : oracleinequality ] , the accuracy provided by the selected estimator is proportional to @xmath198/n}$ ] . on the other hand ,",
    "the pointwise risk of the kernel estimator with optimally chosen bandwidth and kernel is proportional to @xmath199/n}$ ] if the independence structure is not taken into account .",
    "as we see , the adaptation to eventual independence structure can lead to significant improvement of the constant .",
    "this shows that the proposed methodology has an interest beyond derivation of minimax rates , which is the subject of the next section .",
    "in this section , we provide with minimax and adaptive minimax estimation over a scale of anisotropic nikolskii classes .",
    "let @xmath200 denote the canonical basis in @xmath201 .",
    "let @xmath202 $ ] , @xmath203 and @xmath204 , @xmath205 .",
    "a function @xmath206 belongs to the anisotropic nikolskii class @xmath207  if @xmath208 here , @xmath209 denotes the kth order partial derivate of @xmath3 with respect to the variable @xmath210 , and @xmath211 is the largest integer strictly less than @xmath212 .",
    "the following collection @xmath213 was introduced in lepski @xcite in order to take into account the smoothness of the underlying density and its eventual independence structure simultaneously .",
    "@xmath214 where @xmath215 means that @xmath216    we remark that this collection of functional classes was used in the case of adaptive estimation , that is , when the partition @xmath217 is unknown .",
    "however , when the minimax estimation is considered ( @xmath64 is fixed ) , we do not need that condition ( [ eq : marginalenikolskii1 ] ) holds for any @xmath34 .",
    "it suffices to consider only @xmath218 belonging to @xmath64 , and we come to the following definition .",
    "[ def : nikolskiidensityminimax ] let @xmath219 $ ] , @xmath220 , @xmath221 , @xmath205 and @xmath222 .",
    "a probability density @xmath223 belongs to the class @xmath224 if @xmath225    let us now come back to the adaptive estimation . as it was discussed in remark  [ selectionrule ] , the adaptation is not necessarily considered with respect to @xmath31 . if @xmath226 is used instead of @xmath31 , the assumption ( [ eq : marginalenikolskii1 ] ) is too restrictive and can be weakened in the following way .",
    "denote @xmath227 and @xmath228 .",
    "[ def : nikolskiidensityadaptive ] let @xmath229 and @xmath230^d\\times\\overline{{\\mathfrak{p}}}$ ] be fixed .",
    "a probability density @xmath223 belongs to the class @xmath231 if @xmath232    some remarks are in order .",
    "\\(1 ) we note that if @xmath144 , then @xmath233 , but for some @xmath226 , one has @xmath234 @xmath235 .",
    "the latter inclusion shows that the condition ( [ eq : marginalenikolskii2 ] ) is weaker than @xmath236 .",
    "in particular , if @xmath160 , then @xmath237 .",
    "\\(2 ) note that if @xmath238 , then @xmath239 coincides with the class @xmath224 used for minimax estimation .",
    "but @xmath240 for all @xmath241 for any other choices of  @xmath242 .      for @xmath243^d\\times{\\mathfrak{p}}$ ]",
    "define @xmath244 as it will follow from theorems [ theo : minimaxlowerbound1 ] and [ theo : minimaxupperbound ] below @xmath245 is the minimax rate of convergence on @xmath246 .",
    "hence , similarly to the standard representation of minimax rates , the parameter  @xmath247 can be interpreted as a smoothness index corresponding to the independence structure .",
    "[ theo : minimaxlowerbound1 ] @xmath248^d\\times{\\mathfrak{p}}$ ] , @xmath249 , @xmath250 : @xmath251 \\bigr\\}\\geq c,\\ ] ] where infimum is taken over all possible estimators .",
    "note that the assertion of theorem  [ theo : minimaxlowerbound1 ] will be deduced from more general result established in proposition  [ theo : minimaxlowerbound ] below .",
    "it is also important to emphasize that if @xmath252 there is no uniformly consistent estimator for the considered problem and , to the best of our knowledge , this fact was not known before .",
    "let us provide an example with a density for which @xmath253 .",
    "suppose that @xmath49 and , therefore , @xmath55 ( no independence structure ) .",
    "for any @xmath254 , put @xmath255}(x ) .",
    "\\ ] ] some straightforward computations allows us to assert that @xmath256 , @xmath257 , if @xmath258 ( i.e. , @xmath259 ) , and that @xmath260 for some @xmath261 ( @xmath262 , @xmath263 ) .",
    "thus , in this case , one has @xmath253 .",
    "our goal now is to show that @xmath245 is the minimax rate of convergence on @xmath246 and that a minimax estimator belongs to the collection @xmath264 $ ] .",
    "in fact , we prove that the minimax estimator is @xmath265 with properly chosen kernel @xmath266 and bandwidth  @xmath267 .    for a given integer @xmath268 and a given symmetric lipschitz function @xmath269 satisfying @xmath270 $ ] and @xmath271 set @xmath272 furthermore , we use @xmath273 in the definition of estimators collection @xmath264 $ ] .",
    "the relation of kernel @xmath274 to anisotropic nikolskii classes is discussed in kerkyacharian , lepski and picard @xcite . in particular , it was shown that @xmath275    choose finally @xmath276 , where @xmath277 here , @xmath278    [ theo : minimaxupperbound ] for all @xmath279^d\\times[1,\\infty ] ^d\\times{\\mathfrak{p}}$ ] such that @xmath280 and all @xmath281 @xmath282 \\bigr\\}<\\infty . \\ ] ]    to get the statement of this theorem , we apply theorem  [ theo : oracleinequality ] with @xmath283 and @xmath284 . in view of the embedding theorem for anisotropic nikolskii classes ( formulated in the proof of lemma  [ lem : biasupperbound ] and available when @xmath280 ) , there exists a number @xmath285 such that @xmath286 $ ] .",
    "it makes possible the application of theorem  [ theo : oracleinequality ] .",
    "let us briefly discuss several consequences of theorems [ theo : minimaxlowerbound1 ] and [ theo : minimaxupperbound ] .",
    "first , if @xmath50 , we obtain the minimax rate on the anisotropic nikolskii class @xmath287 .",
    "in particular , if @xmath288 , @xmath289 , we find the minimax rate on the anisotropic hlder class @xmath25 given in ( [ eq : multivariateminimaxrates ] ) . if @xmath49 , then our results coincide with those presented in ( [ eq : univariateminimaxrates ] ) .",
    "next , in view of theorem  [ theo : minimaxlowerbound1 ] there is no consistent estimator for @xmath188 on @xmath287 if @xmath290 . on the other hand ,",
    "if @xmath291 and @xmath292 , then such estimator for @xmath188 does exist in view of theorem  [ theo : minimaxupperbound ] even if @xmath293 .",
    "note also that the condition @xmath294 is sufficient to find a consistent estimator on each functional class @xmath246 , @xmath217 , and that the same condition is necessary for the estimation over @xmath295 .",
    "it allows us to compare the influence of the independence structure on the accuracy of estimation .",
    "for example , we see that @xmath296    we conclude that the existence of an independence structure improves significantly the accuracy of estimation .",
    "we finish this section with the result being a refinement of theorem  [ theo : minimaxlowerbound1 ] .",
    "[ theo : minimaxlowerbound ] @xmath248^d\\times{\\mathfrak{p}}$ ] , @xmath249 , @xmath250 : @xmath297 \\bigr\\}\\geq c,\\end{aligned}\\ ] ] where infimum is taken over all possible estimators .",
    "[ rem : minimaxrate ] recall ( see section  [ sec : nikolskiiclasses ] ) that @xmath298 .",
    "hence , the statement of theorem  [ theo : minimaxupperbound ] remains true if one replaces @xmath299 by @xmath231 , @xmath229 .",
    "thus , proposition  [ theo : minimaxlowerbound ] together with theorem  [ theo : minimaxupperbound ] allows us to assert that @xmath300 is the minimax rate of convergence on @xmath239 .",
    "let @xmath229 , such that @xmath301 , be fixed .",
    "denote @xmath302 , @xmath303 , and @xmath304 .",
    "set @xmath305 , @xmath306 , and suppose additionally that @xmath307 .",
    "choose @xmath273 , @xmath308 and @xmath309 , @xmath110 , satisfying @xmath310 let @xmath124 be the dyadic grid in @xmath126^d$ ] and let @xmath311 , @xmath34 , be the projection on the dyadic grid in @xmath126^{|i|}$ ] of the multibandwith @xmath312 given by @xmath313 consider the estimator @xmath314 defined by the selection rule ( [ eq : selectionrule1])([eq : selectionrule2 ] ) , in section  [ sec : selectionrule ] .    for @xmath315^d\\times [ 1,\\infty]^d\\times\\overline{{\\mathfrak{p}}}$ ]",
    "introduce @xmath316    [ theo : adaptiveupperbound ] for any @xmath317^d\\times [ 1,\\infty]^d$ ] such that @xmath318 , any @xmath241 and any @xmath281 @xmath319 \\bigr\\}<\\infty . \\ ] ]    similarly to theorem  [ theo : minimaxupperbound ] , the proof of theorem  [ theo : adaptiveupperbound ] is mostly based on the result of theorem  [ theo : oracleinequality ] .",
    "the application of theorem  [ theo : oracleinequality ] is possible because @xmath320 $ ] for some @xmath285 that is guaranteed by the condition @xmath318 .",
    "we would like to emphasize that the construction of @xmath321 does not involved the knowledge of the parameters @xmath322 . using the modern statistical language",
    ", one can say that @xmath314 is fully adaptative .",
    "note , however , that the precision @xmath323 given by this estimator does not coincide with minimax rate of convergence @xmath324 whenever @xmath325 . in the next section",
    ", we prove that @xmath323 found in theorem  [ theo : adaptiveupperbound ] is an optimal payment for adaptation .",
    "let @xmath326 be the scale of functional classes where @xmath327 is a @xmath328-dimensional manifold and @xmath329 is a finite set .",
    "recall that the family @xmath330 of normalizations is called admissible if there exists an estimator @xmath331 such that @xmath332 \\bigr\\ } < + \\infty\\qquad \\forall(\\alpha , b)\\in{{\\cal a}}\\times{\\mathfrak{b}}.\\ ] ] the estimator @xmath77 is called @xmath333-adaptive .    in the considered problem , @xmath334 , @xmath335 and @xmath336^d\\times [ 1 , \\infty]^d\\dvt r ( \\beta , p,\\overline{\\varnothing } ) > 0 \\bigr\\},\\qquad { \\mathfrak{b}}= \\overline{{\\mathfrak{p}}}. \\ ] ] as it follows from theorem  [ theo : adaptiveupperbound ] @xmath337 is an admissible family of normalizations and the estimator @xmath338 is @xmath339-adaptive .",
    "let @xmath340 and @xmath341 be arbitrary families of normalizations and put @xmath342 define the set @xmath343\\subseteq { { \\cal a}}$ ] as follows : @xmath344:= \\bigl\\{\\alpha \\in{{\\cal a}}\\dvt \\lim_{n\\to\\infty}\\upsilon_n(\\alpha)=0 \\bigr\\}. \\ ] ] the set @xmath345 $ ] can be viewed as the set where the family @xmath346 `` outperforms '' the family @xmath333 .",
    "for any @xmath347 , introduce @xmath348:= \\bigl\\ { \\alpha\\in { { \\cal a}}\\dvt \\lim_{n\\to\\infty}\\upsilon_n ( \\alpha_0)\\upsilon_n(\\alpha , b)=\\infty , \\forall \\alpha_0\\in{{\\cal a}}^{(0 ) } [ \\widetilde{\\varpsi}/\\varpsi ] \\bigr \\}. \\ ] ] remark first that the set @xmath349 $ ] is the set where the family @xmath333 `` outperforms '' the family @xmath346 .",
    "moreover , the `` gain '' provided by @xmath78 with respect to @xmath346 on @xmath350 $ ] is much larger than its `` loss '' on @xmath345 $ ] .",
    "the idea led to the criterion of optimality formulated below is to say that @xmath333 is `` better '' than @xmath346 if there exists @xmath347 for which the set @xmath351 $ ] is much more `` massive '' than @xmath352 $ ] .",
    "[ def : adaptiveoptimality ] a family of normalizations @xmath333 is called adaptive rate of convergence if    @xmath333 is an admissible family of normalizations ;    for any admissible family of normalizations @xmath346 satisfying @xmath345\\neq \\varnothing$ ]    * @xmath345 $ ] is contained in a @xmath353-dimensional manifold , * there exists @xmath347 such that @xmath354 $ ] contains an open set of @xmath355 .",
    "if @xmath333 is an adaptive rate of convergence , then @xmath75 satisfying ( [ eq : adaptiv1 ] ) is called rate adaptive estimator .",
    "the aforementioned definition is inspired by klutchnikoff s criterion ; see klutchnikoff @xcite . indeed if @xmath356 the both definitions coincide .",
    "[ theo : adaptiveoptimality ] we can find no optimal rate adaptive estimator ( satisfying ( [ eq : adaptivoptimal ] ) in section  [ sec : introduction ] ) over the scale @xmath357 whenever @xmath358^d\\times[1,\\infty]^d\\times(0,\\infty)^d\\times\\overline { { \\mathfrak{p}}}\\dvt r ( \\beta , p,\\overline{\\varnothing } ) > 0 \\}$ ] contains at least two elements @xmath359 and @xmath360 such that @xmath361 .",
    "@xmath314 is rate adaptive estimator of @xmath362 and @xmath339 is the adaptive rate of convergence , in the sense of definition  [ def : adaptiveoptimality ] , over the scale @xmath363^d\\times[1,\\infty]^d\\times(0,\\infty ) ^d\\times \\overline{{\\mathfrak{p } } } ,",
    "r ( \\beta , p,\\overline{\\varnothing } ) > 0 \\bigr \\}. \\ ] ]    it is important to emphasize that our results cover a large class of problems in the framework of pointwise density estimation .",
    "in particular , if @xmath364 , we deduce that @xmath314 is rate adaptive estimator of @xmath188 over @xmath365^d\\times[1,\\infty]^d\\times ( 0,\\infty ) ^d , r ( \\beta , p,\\overline{\\varnothing } ) > 0 \\bigr\\}. \\ ] ] the adaptive rate of convergence for this problem is given by @xmath366 to the best of our knowledge , the latter result is new .",
    "it is precise and generalizes the results of butucea @xcite ( @xmath49 ) and comte and lacour @xcite for the deconvolution model when the noise variable is equal to zero .",
    "another interesting fact is related to the set of `` nuisance '' parameters where the adaptive rate of convergence @xmath367 coincides with the minimax one . in all",
    "known for us problems of pointwise adaptive estimation this set contains a single element . however , as it follows from theorem  [ theo : adaptiveoptimality ] , this set may contain several elements .",
    "indeed , if , for instance , @xmath158 and @xmath368 with @xmath369 , @xmath370 , @xmath371 , then @xmath314 is rate adaptive estimator of @xmath188 over @xmath372 ^ 4\\times[1,\\infty]^4\\times(0 , \\infty)^4\\times \\overline{{\\mathfrak{p } } } , r ( \\beta , p,\\overline{\\varnothing } ) > 0 \\bigr\\}. \\ ] ] in this case , the adaptive rate of convergence satisfies @xmath373 thus , in the considered example the aforementioned set contains two elements .",
    "finally , let us note that there is a `` @xmath374-price '' to pay for adaptation with respect to the structure of independence even if the smoothness parameters @xmath21 , @xmath375 and @xmath22 are known .",
    "this result follows from the bound ( [ eq : adaptivelowereq1 ] ) established in the proof of theorem  [ theo : adaptiveoptimality ] .",
    "the latter paper deals with the rate optimal adaptive estimation of a probability density under sup - norm loss .",
    "it is obvious that the estimator constructed in lepski @xcite is fully data - driven and can be also used in pointwise estimation .",
    "however , this estimator is neither minimax nor optimally minimax adaptive when pointwise estimation is considered .",
    "below , we discuss this issue in detail .",
    "_ oracle approach_. obviously , the use of a local method allows to control better the error of approximation since @xmath376 is smaller than @xmath377 .",
    "moreover , our local method controls better the stochastic error since @xmath378 is smaller than @xmath379 .",
    "the latter fact is explained by the use of different constructions of the selection rule .",
    "first , it concerns the choice of the regularization parameter @xmath92 . whereas lepski @xcite uses kernel convolution , we use the `` operation '' @xmath380 on the set of bandwidth parameters . next , in pointwise estimation , we select the parameter @xmath106 from very special set whose construction is new . it is important to emphasize that the consideration of the parameter set used in lepski @xcite is too `` rough '' in order to bring an optimal pointwise adaptive estimator . both reasons required the introduction of novel technical arguments for pointwise estimation with respect to those in lepski @xcite for estimation under sup - norm loss ; see the definition of our selection rule in section  [ sec : selectionrule ] , and the proofs of proposition  [ prop : empiricalupperbound1 ] , lemma  [ lem : empiricalupperbound ] and theorem  [ theo : oracleinequality ] in the next section .",
    "note , however , that the adaptation to eventual independence structure in both papers has rest upon the same methodology .",
    "the following example illustrates clearly how the quality of estimation provided by lepski s estimator can be significantly improved by application of our local method .",
    "considering the problem described in example  [ ex : densityestimation ] , we compare both methods .    * _ local method .",
    "_ we obtain from our local oracle inequality that @xmath381 * _ global method . _",
    "the best quality of estimation provided by theorem  1 in lepski @xcite is @xmath382    it is also important to emphasize that our theorem  [ theo : oracleinequality ] presents other advantages with respect to that in lepski @xcite .",
    "\\(a ) we derive our oracle - type inequality over the functional class @xmath383 $ ] which contains the class @xmath384 $ ] used in lepski @xcite that allows to obtain upper bounds under more general assumptions .",
    "for instance , if @xmath385 , we do not need that all marginals are uniformly bounded , that is not true when we use theorem  1 in lepski @xcite ; see our corollary  [ cor : oracleinequality ] above .",
    "\\(b ) the oracle - type inequality for sup - norm risk can not be used in general for other type of loss functions .",
    "contrary to this , the pointwise risk can be integrated that allows to obtain the results under @xmath13-loss ; see , for example , lepski , mammen and spokoiny @xcite and goldenshluger and lepski @xcite . in this context , the establishing of local oracle inequality with the term @xmath378 instead of @xmath379 is crucial .",
    "_ minimax adaptive estimation_. comparing the minimax rate of convergence defined by ( [ eq : minimaxrate ] ) , we find a price to pay for adaptation in the pointwise setting .",
    "this does not exist in the estimation under sup - norm loss .",
    "note nevertheless that this price to pay for adaptation is not unavoidable for all values of nuisance parameter @xmath359 .",
    "this explains the necessity of the introduction of the optimality criterion presented in section  [ sec : optimality ] .",
    "let us also compare our results with those obtained in lepski @xcite .",
    "consider that @xmath141 still contains the elements @xmath386 and @xmath387 defined in example  [ ex : densityestimation ] and that @xmath154 . put @xmath388 .",
    "* _ local method .",
    "_ in view of our results , our estimator @xmath338 achieves the following minimax rate of convergence : @xmath389 where infimum is taken over all possible estimators . *",
    "_ global method .",
    "_ in view of the results in lepski @xcite , the estimator @xmath390 proposed in the latter paper achieves the following minimax rate of convergence : @xmath391 where infimum is taken over all possible estimators .    thus , the application of the procedure from lepski @xcite for pointwise adaptive estimation leads to the logarithmic loss of accuracy everywhere , while our estimator is rate optimal for some values of nuisance parameter .",
    "the main technical tools used in the derivation of pointwise oracle inequality given in theorem  [ theo : oracleinequality ] are uniform bounds of empirical processes .",
    "we start this section with presenting of corresponding results those proof are postponed to the . in particular , we provide with the explicit expression of the constants @xmath115 , q\\geq1 $ ] , used in the selection rule ( [ eq : selectionrule1])([eq : selectionrule2 ] ) .",
    "our considerations here are mostly based on the results recently developed in lepski @xcite .",
    "set for any @xmath393 , @xmath115:= \\{3q+sq[1\\vee{\\mathfrak{z}}](1 + 1/\\underline{\\tau } ) \\}^ { { 1}/{2}}\\lambda_s^{(q)}$ ] , where @xmath394 , @xmath395= \\biggl\\ { \\biggl(10se^{s}+\\frac { 10sel_{\\mathbf{k}}}{{\\vert}\\mathbf{k}{\\vert}_{\\infty } } \\biggr)\\vee ( 48e ) \\biggr\\ } \\bigl[\\sqrt{7}+7\\sqrt{(1+q){\\vert}\\mathbf{k}{\\vert}_{\\infty}^s } \\bigr]c_{s,1}^{(q)}{\\vert}\\mathbf{k}{\\vert}_{\\infty}^s\\end{aligned}\\ ] ] and @xmath396\\vee1 $ ] .    here",
    ", @xmath397 is the smallest solution of the equation @xmath398 ^ 2 ) = 1 $ ] and @xmath399^{2 } } \\biggr ) } \\biggr]_+ + s\\sup_{\\delta > \\delta _ * } \\frac{1}{\\delta^{2 } } \\biggl[1+\\ln { \\biggl(\\frac { 9216(s+1)\\delta } { s^*(\\delta ) } \\biggr ) } \\biggr]_+,\\\\ s^*(\\delta)&:=&\\frac{(6/\\pi ^2)}{1+[\\ln \\delta]^2}. \\ ] ]      let @xmath400 , and let @xmath401 , be a sequence of @xmath402-valued i.i.d .",
    "random vectors defined on a complete probability space @xmath2 and having the density @xmath403 with respect to the lebesgue measure .",
    "later on @xmath404 denotes the probability law of @xmath405 and @xmath406 is the mathematical expectation with respect to @xmath404 .",
    "assume that @xmath407 where @xmath408 is a given number .",
    "set @xmath409 ) ^{-2}$ ] and @xmath410\\subseteq \\biggl[\\frac{1}{n},1 \\biggr]^s,\\qquad { \\mathfrak{h}}_s^{(q)}(n):= \\bigl\\{h\\in{{\\cal h}}_n^{(s ) } \\dvt nv_h\\geq \\bigl[a_s^{(q ) } \\bigr]^{-1}\\ln(n ) \\bigr\\}.\\end{aligned}\\ ] ]    for any @xmath411 , @xmath412 and @xmath413 set also @xmath414 , \\qquad\\widetilde{g}_h(y_0):=1\\vee \\biggl[n^{-1}\\sum_{i=1}^{n}\\bigl { \\vert}k_h(y_i - y_0)\\bigr{\\vert}\\biggr ] , \\\\ { { \\cal u}}_h^{(u)}(y_0)&:=&\\sqrt { \\frac{[g_h(y_0)]^2}{nv_h } \\biggl\\{1\\vee\\ln \\biggl(\\frac{v_{h^{(\\mathrm{max})}}}{v_h } \\biggr)+u \\biggr\\}}.\\end{aligned}\\ ] ]    for a given @xmath412 consider the empirical processes @xmath415,\\qquad h\\in { { \\cal h}}_n^{(s ) } , \\\\ \\overline{\\xi}_h^{(n)}(y_0)&:=&n^{-1 } \\sum_{i=1}^{n } \\bigl[\\bigl{\\vert}k_{h } ( y_i - y_0 ) \\bigr{\\vert}- { \\mathbb e}_{g}^{(n ) } \\bigl\\ { \\bigl{\\vert}k_h ( y_i - y_0 ) \\bigr{\\vert}\\bigr\\ } \\bigr],\\qquad h\\in { { \\cal h}}_n^{(s)}.\\end{aligned}\\ ] ]    [ prop : empiricalupperbound1 ] for all @xmath175 , all integer @xmath176 and all number @xmath416 satisfying @xmath417 @xmath418_+ \\bigr\\}^q \\leq c_s^{(q)}(\\mathbf{k } , \\mathbf{g } ) [ nv_{h^{(\\mathrm{max } ) } } ] ^{- { q}/{2}}\\mathrm{e}^{-u } ; \\\\ \\mathrm{(ii)}&&\\quad { \\mathbb e}_g^{(n ) }",
    "\\biggl\\{\\sup_{h\\in{\\mathfrak{h}}_s^{(q)}(n ) } \\biggl[\\bigl{\\vert}\\overline{\\xi}_h^{(n)}(y_0 ) \\bigr{\\vert}-\\frac{1}{2}g_h(y_0 ) \\biggr]_+ \\biggr\\}^q \\leq c_s^{(q)}(\\mathbf{k},\\mathbf{g } ) [ nv_{h^{(\\mathrm{max } ) } } ] ^{- { q}/{2}}\\mathrm{e}^{-u } ; \\\\ \\mathrm{(iii)}&&\\quad \\bigl({\\mathbb e}_g^{(n ) } \\bigl\\{\\sup _ { h\\in{\\mathfrak{h}}_s^{(q)}(n ) } \\bigl[g_h(y_0)-2 \\widetilde{g}_h(y_0 ) \\bigr]_+ \\bigr\\}^q \\bigr)^ { { 1}/{q}}\\leq2 \\bigl[c_s^{(q)}(\\mathbf{k } , \\mathbf{g } ) \\bigr]^ { { 1}/{q } } [ nv_{h^{(\\mathrm{max } ) } } ] ^{-{1}/{2}}\\mathrm{e}^{-u / q}.\\end{aligned}\\ ] ]    the expression of the constant @xmath419 is given in the proof of the proposition .        for @xmath34 and @xmath87^d$ ]",
    "set @xmath420,\\\\ g(x_0)&:=&\\sup_{(h,{{\\cal p}})\\in\\overline{{\\mathfrak{h } } } [ \\overline{{\\mathfrak{p } } } ] } \\sup_{(\\eta,{{\\cal p}}')\\in\\overline{{\\mathfrak{h } } } [ \\overline{{\\mathfrak{p } } } ] } \\sup_{i\\in{{\\cal p}}\\circ { { \\cal p}}'}g_{h_i\\vee\\eta_i}(x_{0,i}).\\end{aligned}\\ ] ] for any @xmath131^d\\times{\\mathfrak{p}}$ ] put @xmath421 ^ 2 \\{1\\vee\\ln \\delta ( h,{{\\cal p } } ) \\}}{nv(h,{{\\cal p}})}}. \\ ] ] define also @xmath422 and @xmath423}\\sup _ { ( \\eta,{{\\cal p}}')\\in\\overline{{\\mathfrak{h } } } [ \\overline{{\\mathfrak{p } } } ] } \\sup_{i\\in{{\\cal p}}\\circ{{\\cal p } } ' } \\bigl[\\bigl{\\vert}\\xi_{h_i\\vee\\eta_i}^{(n)}(x_{0,i})\\bigr{\\vert}-\\lambda \\bigl\\ { { { \\cal u}}_{(h,{{\\cal p}})}(x_0)+{{\\cal u}}_{(\\eta,{{\\cal p}}')}(x_0 ) \\bigr\\ } \\bigr]_+ . \\ ] ]    [ lem : empiricalupperbound ] set @xmath424 . for any @xmath175 there exist constants @xmath425 , such that @xmath426 , @xmath427 $ ] , @xmath428 $ ] , @xmath94 , @xmath429^{-{1}/{2 } } ; \\\\",
    "\\mathrm{(ii)}&&\\quad \\bigl({\\mathbb e}_f^{(n ) } \\bigl[g(x_0)-\\overline{g}_n(x_0 ) \\bigr]_+^{2q } \\bigr)^{1/2q}\\leq\\mathbf{c}_2 [ nv_{\\mathrm{max } } ] ^{-{1}/{2 } } ; \\\\ \\mathrm{(iii)}&&\\quad \\bigl({\\mathbb e}_f^{(n)}\\bigl{\\vert}\\overline { \\mathbf{f}}_n(x_0)\\bigr{\\vert}^{2q } \\bigr)^{1/2q}\\leq\\mathbf{c}_3;\\\\ \\mathrm{(iv)}&&\\quad \\bigl ( { \\mathbb e}_f^{(n)}\\bigl{\\vert}\\widehat{{{\\cal u}}}_{(h,{{\\cal p}})}(x_{0 } ) \\bigr{\\vert}^{2q } \\bigr)^{1/2q}\\leq\\mathbf{c}_4 { { \\cal u}}_{(h,{{\\cal p}})}(x_0).\\end{aligned}\\ ] ]      we divide the proof into several steps .",
    "\\(1 ) let @xmath430 $ ] , @xmath94 , be fixed . by the triangle inequality , we have @xmath431+\\bigl{\\vert}\\widehat{f}_{(h,{{\\cal p}})}^{(n)}(x_0)-f(x_0 )",
    "\\bigr{\\vert}.\\nonumber\\end{aligned}\\ ] ] here , we have used that @xmath432 and the definition of @xmath433 .    in what follows",
    ", we will use the inequality : for @xmath434 and @xmath435 , @xmath436 here and later , we assume that the product and the supremum over empty set are equal to one and zero , respectively .",
    "\\(2 ) since @xmath94 , using ( [ eq : productinequality ] ) we have @xmath437 \\\\[-8pt ] \\nonumber & \\leq & d \\bigl(\\max \\bigl\\{\\overline{g}_{n}(x_{0 } ) , \\mathbf{f } \\bigr\\ } \\bigr)^{d-1 } \\bigl[{{\\cal b}}_{(h,{{\\cal p}})}(x_0)+ \\xi_{n}(x_0)+2\\lambda{{\\cal u}}_{(h,{{\\cal p}})}(x_0 ) \\bigr],\\end{aligned}\\ ] ] since @xmath438 and @xmath439 , @xmath440 .",
    "\\(3 ) set @xmath441^{d(d-1)}$ ] . for any @xmath442",
    "$ ] , we get from the inequality ( [ eq : productinequality ] ) @xmath443    introduce , for all @xmath34 and all @xmath444^d$ ] , @xmath445 .",
    "put also @xmath446 .",
    "for any @xmath442 $ ] and any @xmath447 , in view of ( [ eq : productinequality ] ) , @xmath448 for the last inequality , we have used that @xmath94 and , therefore , for any @xmath444^d$ ] and any @xmath449 @xmath450    \\(4 ) applying the triangle inequality , we get since @xmath451 and @xmath452 , for any @xmath453 $ ] , @xmath454    put @xmath455^{d-1}$ ] and @xmath456}{{\\cal u}}_{(\\eta,{{\\cal p}}')}(x_{0})$ ] .",
    "we obtain that @xmath457_+ \\nonumber \\\\ & & \\quad\\quad { } + 3\\lambda\\overline{\\mathbf{f}}_n^{(1)}\\widetilde { \\mathbf { f}}_n^{(2 ) } \\bigl\\{\\sup_{(\\eta,{{\\cal p}}')\\in\\overline{{\\mathfrak{h } } } [ \\overline { { \\mathfrak{p } } } ] } \\bigl[{{\\cal u}}_{(\\eta,{{\\cal p}}')}(x_{0})-\\widehat{{{\\cal u}}}_{(\\eta,{{\\cal p}}')}(x_{0 } ) \\bigr]_+ \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\hspace*{73pt } { } + \\bigl[{{\\cal u}}_{(h,{{\\cal p}})}(x_{0})-\\widehat{{{\\cal u}}}_{(h,{{\\cal p}})}(x_{0 } ) \\bigr]_+ \\bigr\\ } ; \\\\ & & \\widehat{\\delta}_{(h,{{\\cal p}})}(x_0)\\nonumber\\\\ & & \\quad\\leq\\overline{\\mathbf { f}}_n(x_0 ) \\bigl\\ { { { \\cal b}}_{(h,{{\\cal p}})}(x_0)+ \\xi_n(x_0)+ \\bigl[g(x_0)-\\overline { g}_n(x_0 ) \\bigr]_+ \\bigr\\},\\nonumber\\end{aligned}\\ ] ] where @xmath458 , since @xmath459 , @xmath460 , \\ ] ] and @xmath461_+\\leq m(\\max\\{a , b\\})^{m-1}[a - b]_+$ ] , @xmath462 , @xmath463 .",
    "\\(5 ) finally , we deduce from ( [ eq : pointwiseloss1 ] ) , ( [ eq : pointwiseloss2 ] ) and ( [ eq : pointwiseloss3 ] ) , using again @xmath459 , that @xmath464 \\\\[-8pt ] \\nonumber & & \\quad\\leq3\\overline{\\mathbf { f}}_n(x_0 ) \\bigl\\ { { { \\cal b}}_{(h,{{\\cal p}})}(x_0)+{{\\cal u}}_{(h,{{\\cal p}})}(x_0)+ \\widehat { { { \\cal u}}}_{(h,{{\\cal p}})}(x_{0})+\\xi_n(x_0)+ \\bigl[g(x_0)-\\overline { g}_n(x_0 ) \\bigr]_+ \\bigr\\}.\\qquad\\quad\\end{aligned}\\ ] ]    by the cauchy ",
    "schwarz inequality @xmath465_+^{2q } \\bigr)^{{1}/{(2q)}}\\bigr].\\end{aligned}\\ ] ] applying lemma  [ lem : empiricalupperbound ] , @xmath466^{-{1}/{2 } } \\bigr ] , \\ ] ] and we come to the assertion of theorem  [ theo : oracleinequality ] with @xmath467 and @xmath468 .",
    "the result formulated in lemma  [ lem : minimaxlowerbound ] below is a direct consequence of the general bound obtain in kerkyacharian , lepski and picard @xcite , proposition  7 .",
    "let @xmath469^d\\times{\\mathfrak{p}}$ ] and @xmath281 be fixed .",
    "[ lem : minimaxlowerbound]suppose that there exists @xmath470 such that @xmath471 is absolutely continuous with respect to @xmath472 and @xmath473 ^ 2 & \\leq & c<\\infty.\\end{aligned}\\ ] ] then , for all @xmath175 , @xmath474 \\bigr\\}\\\\ & & \\qquad\\geq \\frac{1}{2 } \\bigl(1-\\sqrt { c/(c+4 ) } \\bigr),\\end{aligned}\\ ] ] where infimum is taken over all possible estimators .",
    "set @xmath475 and let @xmath476 .",
    "it is easily seen that one can find @xmath477 such that @xmath478 \\\\[-8pt ] \\nonumber   \\underline{l}_i&:=&2 \\wedge l_i,\\qquad   i=\\overline{1,d}.\\end{aligned}\\ ] ]    let @xmath479 be such that @xmath480 and @xmath481 such that @xmath482 , @xmath483 , @xmath484 , and @xmath485 .",
    "define @xmath486 where @xmath487 , @xmath488 , if @xmath489 , will be chosen later .",
    "note that @xmath490 if @xmath491    introduce @xmath492^{-1}\\exp \\bigl(-x_i^2/2\\sigma^2 \\bigr ) \\bigr\\ } \\biggl \\{\\prod_{i\\in i } \\bigl[2\\pi \\sigma ^2 \\bigr]^{-1}\\exp \\bigl(-x_i^2/2 \\sigma^2 \\bigr)+g(x_i ) \\biggr\\}.\\ ] ] it is obvious that there exists @xmath493 such that if @xmath494 then @xmath495 for any @xmath35 .",
    "note also that the condition @xmath484 implies that @xmath496 .",
    "we conclude that @xmath497 is a probability density .",
    "furthermore , assumptions ( [ eq : minimaxlowerbound0])([eq : minimaxlowerbound1 ] ) and the definition of @xmath498 allow us to assert that @xmath499 .",
    "we remark that @xmath500 then assumption ( [ eq : lowerboundassumption1 ] ) of lemma  [ lem : minimaxlowerbound ] is fulfilled when @xmath501 .    since @xmath502 ,",
    "are i.i.d .",
    "random fields and @xmath503 it is easily check that @xmath504 ^ 2 & \\leq & \\biggl[1 + \\frac{2}{f_{0,i}(x_{0,i})}a_n^2 \\biggl(\\prod _ { j=1}^m\\delta _ { j , n } \\biggr){\\vert}g { \\vert}_2^{2 m } \\biggr]^n \\\\ & \\leq&\\exp \\biggl [ \\frac{2{\\vert}g{\\vert}_2^{2m}}{f_{0,i}(x_{0,i})}na_n^2 \\biggl(\\prod _ { j=1}^m\\delta _ { j , n } \\biggr ) \\biggr ] , \\ ] ] for @xmath150 large enough . here , we have used that @xmath505 $ ] and that @xmath506 for @xmath150 large enough .",
    "since @xmath507=1 $ ] , assumption  ( [ eq : lowerboundassumption2 ] ) of lemma  [ lem : minimaxlowerbound ] is fulfilled if @xmath508 - 1\\leq c. \\ ] ] the latter inequality holds if @xmath509^{-1}\\ln ( c+1 ) } , \\qquad c_2^{*}:=\\frac{2{\\vert}g{\\vert}_2^{2m}}{f_{0,i}(x_{0,i})}.\\ ] ]    to finalize our proof , we study separately two cases : @xmath510 and @xmath511 .",
    "note first that @xmath512 , where @xmath513    \\(1 ) _ case _ @xmath510 . solving the system",
    "@xmath514 we obtain @xmath515^ { { 1}/{(1 - 1/s_i-1/2\\beta_i)}}. \\ ] ] it is easily seen that @xmath516 , if @xmath489 and one can choose @xmath517 .",
    "we conclude that , if @xmath510 , lemma  [ lem : minimaxlowerbound ] is applicable with @xmath518 .",
    "\\(2 ) _ case _ @xmath252 .",
    "we choose @xmath519 , where the constant @xmath520 satisfies @xmath521 . solving the system @xmath522 note that one can choose @xmath520 such that @xmath523 and @xmath517 .",
    "since @xmath524 , we obtain the following solution : @xmath525    we conclude that , if @xmath252 , lemma  [ lem : minimaxlowerbound ] is applicable with @xmath526 .",
    "this completes the proof of proposition  [ theo : minimaxlowerbound ] .",
    "the proof of theorems [ theo : minimaxupperbound ] and [ theo : adaptiveupperbound ] is based on application of theorem  [ theo : oracleinequality ] .",
    "note that in view of the embedding theorem for anisotropic nikolskii classes ( formulated in the proof of lemma  [ lem : biasupperbound ] ) , there exists a number @xmath527 such that @xmath528 if @xmath292 or such that @xmath529 if @xmath318 .",
    "it makes possible the application of theorem  [ theo : oracleinequality ] .",
    "the result formulated in lemma  [ lem : biasupperbound ] below is a consequence of theorem  6.9 in nikolskii @xcite .",
    "let @xmath268 be a fixed integer and @xmath229 be a fixed set of partitions of @xmath30 .",
    "let @xmath530 , where @xmath531^d$ ] , @xmath303 , @xmath532^d$ ] satisfy @xmath280 and @xmath533 .",
    "[ lem : biasupperbound ] there exists @xmath534 such that @xmath535^d\\times[0,1]^d,\\end{aligned}\\ ] ] where @xmath536 is defined in section  [ sec : oracleinequality ] , @xmath537 , @xmath538 and @xmath539 .",
    "the proof of this lemma is given in the .      for all @xmath95 , consider the following system of equations : @xmath540 and let @xmath541 denotes its solution .",
    "one can easily check that @xmath542 here , we have used that @xmath543 .",
    "we note that @xmath544 for all @xmath150 large enough . to get the statement of the theorem",
    ", we will apply theorem  [ theo : oracleinequality ] with @xmath545 , @xmath546 , @xmath110 , @xmath547 if @xmath95 and @xmath548 if @xmath549 , @xmath550 , @xmath551 , @xmath283 .",
    "thus , @xmath552 $ ] is non - empty for @xmath150 large enough and we get @xmath553\\leq \\alpha_1 ( \\mathbf{c}\\overline{l}\\vee1 ) \\biggl [ \\sup _ { i\\in{{\\cal p}}}\\sum_{i\\in i } \\mathbf{h}_i^{\\beta_i(i)}+\\sup_{i\\in{{\\cal p}}}\\sqrt { \\frac { 1}{nv_{\\mathbf{h}_i } } } \\biggr]+\\alpha_2 \\sup_{i\\in{{\\cal p } } } \\sqrt { \\frac { 1}{nv_{\\mathbf{h}_i}}},\\ ] ] where @xmath554 . here",
    ", we have used lemma  [ lem : biasupperbound ] and the definition of @xmath555 .",
    "we deduce from ( [ eq : minimaxbandwidth1 ] ) and ( [ eq : minimaxupperbound1 ] ) @xmath556\\leq \\bigl[2\\alpha_1 ( \\mathbf{c}\\overline{l}\\vee1 ) + \\alpha _ 2 \\bigr]\\sup_{i\\in{{\\cal p } } } n^{-{\\gamma_i(\\beta , p)}/{(2\\gamma_i(\\beta , p)+1)}}= \\bigl[2 \\alpha_1 ( \\mathbf{c}\\overline{l}\\vee1 ) + \\alpha _ 2 \\bigr]n^{-{r}/{(2r+1)}}\\ ] ] and the assertion of theorem  [ theo : minimaxupperbound ] follows .      set @xmath557^d\\times [ 1,\\infty ] ^d$ ] such that @xmath318 , @xmath303 , @xmath281 , and @xmath530 .",
    "let us first note the following simple fact . if @xmath558 and @xmath559 , we easily prove that @xmath560 ; see , for example , lepski @xcite , proof of theorem  3 , for more details .",
    "thus , in view of lemma  [ lem : biasupperbound ] , @xmath561^d.\\ ] ]    recall that @xmath562 , @xmath34 , is the projection on the dyadic grid in @xmath126^{|i|}$ ] of @xmath312 given in ( [ eq : maximalebandwidth ] ) and note that @xmath563 for @xmath150 large enough .",
    "thus , @xmath552 $ ] is non - empty and one can apply theorem [ theo : oracleinequality ] .",
    "if @xmath564 , then it is obvious that @xmath565 and that @xmath566 .",
    "thus , in view of the definition of the multibandwidths @xmath567 , @xmath95 , @xmath568 .",
    "it follows from theorem  [ theo : oracleinequality ] and ( [ eq : adaptiveupperbound1 ] ) @xmath569\\leq \\alpha_1 ( \\mathbf { c}\\overline{l}\\vee1 ) \\biggl [ \\sup _ { i\\in{{\\cal p}}}\\sum_{i\\in i } \\bigl ( \\mathfrak{h } _ i^{(i ) } \\bigr)^{\\beta_{\\mathrm{max}}}+\\sup _ { i\\in{{\\cal p}}}\\sqrt{\\frac { 1}{nv_{\\mathfrak{h } _",
    "i^{(i ) } } } } \\biggr]+\\alpha_2 [ nv_{\\mathrm{max } } ] ^{-{1}/{2 } } , \\ ] ] where @xmath554 . since @xmath570",
    ", we conclude that there exists a constant @xmath571 such that @xmath572 \\leq c \\bigl[\\alpha_1 ( \\mathbf { c}\\overline{l}\\vee1 ) ( d+1)+ \\alpha_2 \\bigr]n^{-{r_{\\mathrm{max}}}/{(2r_{\\mathrm{max}}+1)}}.\\ ] ]    if @xmath573 we solve , for all @xmath95 , the system @xmath574 the solution is @xmath575 \\\\[-8pt ] \\nonumber   l(i)&=&\\prod _ { i\\in i}l_i^{{1}/{\\beta_i(i)}},\\qquad i\\in i , i\\in { { \\cal p}}.\\end{aligned}\\ ] ] it is easily seen that @xmath576 $ ] for @xmath150 large enough . replacing @xmath92 by its projection @xmath577 on the dyadic grid @xmath124",
    ", one has @xmath578 $ ] for @xmath150 large enough .",
    "we deduce from theorem  [ theo : oracleinequality ] and ( [ eq : adaptiveupperbound1 ] ) @xmath579 \\leq\\alpha_1 \\biggl [ \\mathbf { c}\\sup_{i\\in{{\\cal p}}}\\sum _",
    "{ i\\in i}l_i\\bar{h}_i^{\\beta_i(i)}+ \\sup_{i\\in { { \\cal p}}}\\sqrt{\\frac{\\ln(n)}{nv_{\\bar{h}_i } } } \\biggr]+ \\alpha_2 [ nv_{\\mathrm{max } } ] ^{-{1}/{2}}.\\ ] ]    the assertion of theorem  [ theo : adaptiveupperbound ] follows from ( [ eq : adaptiveupperbound2 ] ) , ( [ eq : adaptiveminimaxbandwidth1 ] ) and ( [ eq : adaptiveupperbound3 ] ) .        to get the assertion of theorem  [ theo : adaptiveoptimality ] , we use the following lemma which is due to an oral communication with o. lepski .",
    "this result can be viewed as a generalization of lemma  [ lem : minimaxlowerbound ] .",
    "let @xmath557^d\\times [ 1,\\infty ] ^d$ ] such that @xmath318 , @xmath303 , @xmath281 and @xmath580^d\\times[1,\\infty]^d$ ] such that @xmath581 , @xmath582 , @xmath583 be fixed .",
    "[ lem : adaptivelowerbound ] set @xmath584 and @xmath585 two sequences such that @xmath586 .",
    "suppose that exist @xmath587 and @xmath588 such that @xmath471 is absolutely continuous with respect to @xmath472 and @xmath589 ^ 2\\leq \\frac{b_n}{a_n}.\\ ] ] then , for any @xmath175 , @xmath590\\geq\\frac{1}{2},\\end{aligned}\\ ] ] where infimum is taken over all possible estimators .    the proof of this lemma is given in the .",
    "\\(1 ) set @xmath591 , @xmath592 , @xmath593 and @xmath594 such that @xmath595 .",
    "for any @xmath596 such that @xmath597 , there exists @xmath598 satisfying : @xmath599 , @xmath600 \\\\[-8pt ] \\nonumber & & \\hspace*{22pt}\\qquad{}+\\sup_{f\\in n_2 } { \\mathbb e}_f^{(n ) } \\bigl\\{n^{\\tau } \\bigl|\\widetilde { f}_n(x_0)-f(x_0 ) \\bigr| \\bigr\\}^q \\biggr]\\geq c(\\tau).\\end{aligned}\\ ] ]    let us prove ( [ eq : adaptivelowereq1 ] ) .",
    "the proof is based on lemma  [ lem : adaptivelowerbound ] where we put @xmath601^{-1/q } \\biggl ( \\frac{n}{\\ln(n ) } \\biggr)^ { { r_1}/{(2r_1 + 1)}},\\qquad b_n:= \\bigl[2c(\\tau ) \\bigr]^{-1/q}n^{\\tau } , \\ ] ] and the constant @xmath598 will be specified later .    similarly to the proof of proposition  [ theo : minimaxlowerbound ] , set @xmath602 and define @xmath603 , where @xmath604 is chosen in such way that @xmath605 let also @xmath497 be given in ( [ eq : f1 ] ) .",
    "it is obvious that there exists a constant @xmath606 such that @xmath607 if @xmath494 and @xmath608    assumptions of lemma  [ lem : adaptivelowerbound ] are , respectively , fulfilled if @xmath609^{1/q } \\biggl(\\frac{\\ln ( n)}{n } \\biggr)^{{r_1}/{(2r_1 + 1)}},\\nonumber\\\\ c_1^{*}&:= & ( \\sigma\\sqrt { 2\\pi } ) ^{m - d}\\bigl { \\vert}g(0)\\bigr{\\vert}^{m}\\prod_{i\\notin i } \\exp \\bigl(-x_{0,i}^2/2\\sigma^2 \\bigr ) ; \\\\   \\exp \\biggl[\\frac{2{\\vert}g{\\vert}_2^{2m}}{f_{0,i}(x_{0,i})}na_n^2 \\biggl(\\prod _ { l=1}^m\\delta _ { l , n } \\biggr ) \\biggr]&\\leq&n^{\\tau } \\biggl(\\frac{n}{\\ln(n ) } \\biggr ) ^{-{r_1}/{(2r_1 + 1)}}. \\nonumber\\end{aligned}\\ ] ] the latter inequality , in its turn , holds if @xmath610^{-1 } \\biggl(\\tau- \\frac{r_1}{2r_1 + 1 } \\biggr)},\\qquad c_2^{*}:=\\frac{2{\\vert}g{\\vert}_2^{2m}}{f_{0,i}(x_{0,i})}.\\ ] ]    solving the system @xmath611 we obtain @xmath612^{{1}/{(1 - 1/s_i-1/2\\beta_i)}}. \\ ] ] it is easily seen that @xmath516 , if @xmath489 .",
    "the choice @xmath613^{q}$ ] , completes the proof of the inequality ( [ eq : adaptivelowereq1 ] ) .",
    "it follows the assertion ( i ) of theorem  [ theo : adaptiveoptimality ] .",
    "\\(2 ) let us recall the definition of the set @xmath614 , which is the set of `` nuisance '' parameters for the considered problem .",
    "@xmath615^d\\times [ 1 , \\infty]^d\\dvt r ( \\beta , p,\\overline{\\varnothing } ) > 0 \\bigr\\ } , \\qquad{\\mathfrak{b}}:= \\overline{{\\mathfrak{p}}}. \\ ] ]    let @xmath616 be an admissible family of normalizations and let @xmath617 be @xmath616-adaptive estimator .",
    "define @xmath618&:= & \\bigl\\ { ( \\beta , p ) \\in{{\\cal a}}\\dvt \\lim_{n\\to\\infty}\\upsilon_n ( \\beta , p ) = 0 \\bigr\\ } , \\\\",
    "\\upsilon_n ( \\beta , p ) & : = & \\inf_{{{\\cal p}}\\in\\overline{{\\mathfrak{p}}}}\\upsilon _ n ( \\beta , p,{{\\cal p } } ) , \\qquad\\upsilon_n ( \\beta , p,{{\\cal p}}):= \\frac{\\widetilde{\\psi}_n ( \\beta , p,{{\\cal p}})}{\\psi _ n ( \\beta , p,{{\\cal p}})},\\end{aligned}\\ ] ] where @xmath339 is given in ( [ eq : adaptiverate ] ) . for any @xmath241 put also @xmath619:= \\bigl\\ { ( \\beta , p ) \\in{{\\cal a}}\\dvt \\lim_{n\\to\\infty}\\upsilon_n ( \\beta _ 0,p_0 ) \\upsilon_n ( \\beta , p,{{\\cal p}})=\\infty , \\forall ( \\beta _ 0,p_0 ) \\in{{\\cal a}}^{(0 ) } [ \\widetilde{\\varpsi}/\\varpsi ] \\bigr\\}. \\ ] ] in the slight abuse of the notation , we will use later @xmath620 instead of @xmath323 , @xmath621 .    for",
    "any @xmath622 $ ] introduce @xmath623    let us first note that @xmath624 for any @xmath625 $ ] .",
    "indeed , if @xmath626 then @xmath622 $ ] contradicts to @xmath627 is a minimax rate of convergence .",
    "moreover , for any @xmath628 , there exists @xmath629 and @xmath241 such that @xmath630 .",
    "it suffices to choose @xmath64 such that @xmath631 , @xmath632 , and @xmath633 , @xmath634 , @xmath635 .",
    "\\(3 ) our goal now is to prove that for any @xmath636 $ ] we have @xmath637    set @xmath638 and @xmath639 such that @xmath640 . applying the inequality ( [ eq : adaptivelowereq1 ] ) with @xmath641 , @xmath642 and @xmath643",
    ", we get for any @xmath596 satisfying @xmath644 @xmath645 \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\quad\\geq c(\\tau).\\end{aligned}\\ ] ] furthermore , by definition of @xmath617 and @xmath646 , there exist constants @xmath647 such that for all @xmath150 large enough @xmath648    note that @xmath649 that follows from @xmath650 $ ] as well as the definition of @xmath651 .",
    "thus , we obtain in view of ( [ eq : optimal2 ] ) that @xmath652 it yields together with ( [ eq : optimal1 ] ) and ( [ eq : optimal3 ] ) that @xmath653    recall that @xmath654 . since @xmath655 we get for some @xmath656 satisfying @xmath657 that @xmath658 for @xmath150 large enough .",
    "hence , we obtain in view of ( [ eq : optimal4 ] ) @xmath659 furthermore , since @xmath660 is a minimax rate of convergence , there exists a constant such that @xmath661^{-{r_0}/{(2r_0 + 1)}}\\ ] ] for all @xmath150 large enough .",
    "we deduce from ( [ eq : optimal5 ] ) and ( [ eq : optimal6 ] ) that @xmath662 .",
    "\\(4 ) let @xmath663 $ ] and @xmath664 $ ] be arbitrary pairs of parameters .",
    "let also @xmath386 and @xmath387 be defined in ( [ eq : outperformrate ] ) where @xmath665 is replaced by @xmath666 and @xmath667 , respectively .",
    "then necessarily @xmath668 indeed , assume that @xmath669 . noting that @xmath670 , in view of the definition of @xmath387 we deduce from ( [ eq : resultstep2 ] ) with @xmath671 and @xmath672 that @xmath673 this contradicts to @xmath674 $ ] .",
    "the case @xmath675 is traited similarly .",
    "\\(5 ) we are now in position to prove theorem  [ theo : adaptiveoptimality ] .    first ,",
    "if @xmath676\\neq \\varnothing $ ] , we deduce from ( [ eq : outperformrate1 ] ) that there exists @xmath677 such that @xmath678.\\ ] ] here , as previously , @xmath679 .",
    "recall that , for @xmath680^d\\times{\\mathfrak{p}}$ ] , @xmath681 thus , obviously @xmath682 \\bigr)\\leq2d-1.\\ ] ]    next , let @xmath683 be a partition satisfying @xmath684 .",
    "we deduce from ( [ eq : resultstep2 ] ) that @xmath685 \\supseteq \\bigl\\ { ( \\beta , p ) \\in{{\\cal a}}\\dvt r_0<r \\bigl(\\beta , p,{{\\cal p}}^ * \\bigr)<r_{\\mathrm{max } } \\bigr\\},\\ ] ] where @xmath686 is defined in ( [ eq : optimal7 ] ) .",
    "thus , @xmath687 $ ] contains an open set of @xmath355 since @xmath688 is continuous .",
    "this together with ( [ eq : optimal8 ] ) completes the proof of the theorem .",
    "our goal is to establish a uniform bound for the empirical process @xmath689 .",
    "note that the considered family of random fields is a particular case of the generalized empirical processes studied in lepski @xcite . we get the assertions of proposition  [ prop : empiricalupperbound1 ] from the theorem @xmath690 in the latter paper since it allows us to assert that , for any @xmath413 , @xmath175 and any integer @xmath176",
    "@xmath691_+ \\bigr \\}^q \\leq c_s^{(q)}(\\mathbf{k},\\mathbf{g } ) [ nv_{h^{(\\mathrm{max } ) } } ] ^{-{q}/{2}}\\mathrm{e}^{-u } , \\nonumber\\\\ & & { { \\cal u}}^{(u , q)}(n , h , y_0 ) \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\quad:=c(\\mathbf{k},s , q)\\sqrt { \\frac { g_h(y_0)}{nv_h } \\biggl\\{1\\vee\\ln \\biggl(\\frac { v_{h^{(\\mathrm{max})}}}{v_h } \\biggr)+2\\ln \\bigl(2+\\ln g_h(y_0 ) \\bigr)+u \\biggr\\ } } \\\\ & & \\quad\\quad { } + \\frac{c(\\mathbf { k},s , q)}{nv_h } \\biggl\\{1\\vee\\ln \\biggl(\\frac { v_{h^{(\\mathrm{max})}}}{v_h } \\biggr)+2\\ln \\bigl(2+\\ln g_h(y_0 ) \\bigr)+u \\biggr\\}. \\nonumber\\end{aligned}\\ ] ] the constants @xmath419 and @xmath692 are given later .",
    "thus , we only have to check the assumptions of theorem @xmath690 in lepski @xcite and to match the notation used in the present paper and in the latter one .",
    "we divide this proof into several steps .",
    "\\(1 ) for our case , we first consider that @xmath262 , @xmath693 , @xmath694 , @xmath695 , @xmath696 , @xmath697 and @xmath698    obviously , assumption @xmath690(i ) in lepski @xcite is fulfilled . using assumption ( [ eq : kernelasumption ] ) ( see section  [ sec : kernel ] of the present paper ) , we get @xmath699^s$ ] and @xmath700    thus , we easily check that , for any @xmath701 and any @xmath702 , @xmath703",
    "\\biggl \\{\\exp \\bigl(s\\varrho_n^{(s)}\\bigl(h , h'\\bigr ) \\bigr)-1+\\frac{l_\\mathbf{k}^{(s)}}{{\\vert}\\mathbf{k}{\\vert}_{\\infty}^s } \\bigl(\\exp \\bigl(\\varrho _ n^{(s ) } \\bigl(h , h'\\bigr ) \\bigr)-1 \\bigr ) \\biggr\\}. \\ ] ] it implies that assumption @xmath690(ii ) in lepski @xcite holds with @xmath704    furthermore , assumption @xmath705 in lepski @xcite holds with @xmath706 and @xmath707 since @xmath708 and assumption @xmath709 in lepski @xcite is not needed since @xmath710 .",
    "\\(2 ) thus , the application of the theorem @xmath690 in lepski @xcite is possible .",
    "let us first compute the constants which appear in its proof .",
    "@xmath711^{2 } } \\biggr ) } \\biggr]_+ + \\sup_{\\delta > \\delta _ * } \\delta^{-2}s \\biggl[1+\\ln { \\biggl(\\frac{9216(s+1)\\delta } { [ s^*(\\delta ) ] } \\biggr ) } \\biggr]_+\\\\ & : = & c_s ; \\\\ c_d&=&se^s+\\frac{sel_\\mathbf{k}}{{\\vert}\\mathbf{k}{\\vert}_{\\infty}},\\qquad c_{d , b}= \\sqrt{2c_d}\\vee \\bigl[(2/3 ) ( c_d\\vee8e ) \\bigr ] , \\\\   \\lambda _ 1&=&4\\sqrt { 2ec_d } , \\lambda_2=(16/3 ) ( c_d\\vee8e ) . \\ ] ]    next , we have to compute the quantities involved in the description of @xmath712",
    ". @xmath713,\\qquad   c_{s,1}^{(q)}:=\\bigl[144s\\delta _ * ^{-2}+5q+3 + 36c_s\\bigr]\\vee1 . \\ ] ]    since @xmath714 , are identically distributed , putting @xmath715 , @xmath710 and @xmath716 , we have @xmath717:=g_h(y_0),\\\\    f_n&=&\\sup _ { h\\in{{\\cal h}}_n^{(s)}}g_h(y_0)\\leq1\\vee\\mathbf{g } { \\vert}\\mathbf{k}{\\vert}_{1}^s ; \\\\ { { \\cal u}}_{\\mathbf{r}}^{(u , q)}(n,\\mathfrak{h } ) & \\leq&{{\\cal u}}^{(u , q)}(n , h , y_0),\\qquad c(\\mathbf{k},s , q):=\\bigl[(10c_d)\\vee ( 48e)\\bigr]c_{s,1}^{(q ) } { \\vert}\\mathbf{k}{\\vert}_{\\infty}^s .",
    "\\ ] ] here , we have used that @xmath718 .",
    "thus , we come to the inequality ( [ eq : empiricalupperbound1 ] ) with @xmath719 , @xmath720 .",
    "\\(3 ) if @xmath721 and @xmath722 , since @xmath723 , one has @xmath724 \\\\[-8pt ] \\nonumber & \\leq&7(1+q){\\vert}\\mathbf { k}{\\vert}_{\\infty}^s.\\end{aligned}\\ ] ]    put finally @xmath725:=c(\\mathbf{k},s , q)\\sqrt { 7 } \\{\\sqrt{7(1+q){\\vert}\\mathbf{k}{\\vert}_{\\infty}^s}+1 \\}$ ] .",
    "since @xmath726^{-1}\\geq1 $ ] , the assertion  ( i ) of proposition  [ prop : empiricalupperbound1 ] follows from ( [ eq : empiricalupperbound1 ] ) and ( [ eq : empiricalupperbound2 ] ) .",
    "let us now prove the assertions ( ii ) and ( iii ) of proposition  [ prop : empiricalupperbound1 ] .",
    "\\(4 ) first , in view of the definition of @xmath727 , we get the assertion ( ii ) from the assertion ( i ) of proposition  [ prop : empiricalupperbound1 ] since @xmath728 and @xmath729\\sqrt{(1+q)a_s^{(q)}}=1/2 $ ] . here",
    ", we have used that if @xmath266 satisfies the assumption ( [ eq : kernelasumption ] ) , see section  [ sec : kernel ] , @xmath730 satisfies it as well and , therefore , proposition  [ prop : empiricalupperbound1](i ) is applicable to the process @xmath731 .",
    "next , using the trivial inequality @xmath732 , @xmath733 , we easily check that @xmath734_+\\qquad \\forall h\\in{\\mathfrak{h}}_{a_s}^{(s)}(n).\\end{aligned}\\ ] ] assertion ( iii ) of proposition  [ prop : empiricalupperbound1 ] follows from assertion ( ii ) and ( [ eq : empiricalupperbound21 ] ) .",
    "note first that , for any @xmath735 $ ] , any @xmath453 $ ] and any @xmath736 @xmath737\\dvt",
    "nv_{h_i}\\geq \\bigl[a_{{\\vert}i\\cap i'{\\vert}}^{(2q ) } \\bigr]^{-1}\\ln(n ) \\biggr\\ } , \\ ] ] where @xmath738 $ ] , @xmath739 .    set @xmath740 $ ] . to get the assertions of lemma  [ lem : empiricalupperbound ] , we apply proposition  [ prop : empiricalupperbound1 ] with @xmath741 , @xmath742 , @xmath743 , @xmath744 , @xmath745 , @xmath746 , @xmath747 , @xmath748 , @xmath749 , @xmath750 , @xmath751 .    recall that @xmath227 . in view of the definition of @xmath127",
    "$ ] , we easily check that @xmath752_+ , \\ ] ] with @xmath753\\in[1,2q\\ln(n)]$ ] , since @xmath754 and @xmath121 , @xmath755 .",
    "therefore , it follows from the assertion ( i ) of proposition  [ prop : empiricalupperbound1 ] , since @xmath756 , @xmath757_+ \\bigr\\}^{2q } \\bigr)^{{1}/{(2q ) } } \\\\ & & \\quad\\leq \\bigl\\{c_{{\\vert}i\\cap i'{\\vert}}^{(2q)}(\\mathbf{k},\\mathbf { g } ) \\bigr \\}^{{1}/{(2q ) } } [ nv_{\\mathrm{max } } ] ^{-{1}/{2 } } \\bigl(2^{{\\mathfrak{z}}{\\vert}i\\cap i'{\\vert}/2 } \\bigr)^{-m\\vee l } \\bigl(2^{1/2 } \\bigr)^{-m\\wedge l } ; \\\\ & & \\bigl({\\mathbb e}_f^{(n)}\\bigl{\\vert}\\xi_n(x_0 ) \\bigr{\\vert}^{2q } \\bigr)^ { { 1}/{(2q)}}\\leq \\mathbf{c}_1 [ nv_{\\mathrm{max } } ] ^{-{1}/{2}},\\\\   \\mathbf { c}_1&:=&\\sum _ { { { \\cal p}}\\in\\overline{{\\mathfrak{p}}}^*}\\sum_{i\\in{{\\cal p } } } \\bigl \\{c_{{\\vert}i{\\vert}}^{(2q)}(\\mathbf{k},\\mathbf{f } ) \\bigr\\}^ { { 1}/{(2q ) } } \\biggl[\\frac { 2^{[({\\mathfrak{z}}|i|)\\wedge1]/2}}{2^{[({\\mathfrak{z}}|i|)\\wedge1]/2}-1 } \\biggr ] . \\ ] ]    similarly , applying proposition  [ prop : empiricalupperbound1](iii ) and using the trivial inequality @xmath758_+\\leq\\sup_i[x_i - y_i]_+$ ] , we obtain the assertion ( ii ) of lemma  [ lem : empiricalupperbound ] with @xmath759 .",
    "next , it is easily seen that @xmath760_+ \\biggr)\\\\ & & { } + 3g(x_0 ) , \\ ] ] and that @xmath761^{d^2}. \\ ] ] thus , we get assertion ( iii ) of lemma  [ lem : empiricalupperbound ] from assertion ( ii ) of proposition  [ prop : empiricalupperbound1 ] with @xmath762/2}}{2^{[({\\mathfrak{z}}|i|)\\wedge1]/2}-1 } \\biggr ] \\biggr ) + 8 \\bigl(1\\vee\\mathbf{f}{\\vert}\\mathbf{k}{\\vert}_1^d \\bigr ) \\biggr]^{d^2}. \\ ] ]    similarly , we obtain assertion ( iv ) of lemma  [ lem : empiricalupperbound ] with @xmath763/2}}{2^{[({\\mathfrak{z}}|i|)\\wedge 1]/2}-1 } \\biggr ] \\biggr ) + 3 \\bigl(1\\vee\\mathbf{f}{\\vert}\\mathbf{k}{\\vert}_1^d \\bigr ) . \\ ] ] this completes the proof of lemma  [ lem : empiricalupperbound ] .",
    "the proof of this lemma is based on the embedding theorem for anisotropic nikolskii classes ; see , for example , theorem  6.9 in nikolskii @xcite .",
    "let @xmath582 and @xmath764 be fixed .",
    "set @xmath538 and @xmath765 , where @xmath539 , @xmath549 .",
    "since @xmath766 there exists @xmath767 such that @xmath768    introduce the family of @xmath769 matrices @xmath770 , and @xmath771 is zero matrix . for any @xmath164^d\\times[0,1]^d$ ] , using a telescopic sum and the triangle inequality , we get @xmath772\\,{\\mathrm{d}}u\\biggr |.\\end{aligned}\\ ] ]    for @xmath773 put @xmath774\\,{\\mathrm{d}}u_j.\\end{aligned}\\ ] ] if @xmath775 , then @xmath776 , if not we put @xmath777^j:=u - u_je_j , u\\in{{\\mathbb r}}^{{\\vert}i{\\vert}}$ ] , and we have @xmath778^j+(h_i\\vee\\eta_i-\\eta_i)e_{j-1}u \\bigr ) \\bigr]\\,{\\mathrm{d}}u_j \\\\ & & { } + \\int_{{{\\mathbb r } } } \\mathbf{k}(u_j ) \\bigl[f_i \\bigl(x_{0,i}+ [ \\eta_i u ] ^j+(h_i\\vee\\eta_i-\\eta_i)e_{j-1}u \\bigr ) \\\\ & & \\hspace*{52pt}{}-f_i \\bigl(x_{0,i}+\\eta_i u+(h_i\\vee\\eta_i-\\eta_i)e_{j-1}u \\bigr ) \\bigr]\\,{\\mathrm{d}}u_j.\\end{aligned}\\ ] ]    thus , in view of the triangle inequality , @xmath779 here , we have used taylor expansions of @xmath780 , the product structure of @xmath781 , the fubini theorem that @xmath782^d$ ] and ( [ eq : kernelorthogonality ] ) ; see section  [ sec : minimaxresults ] .",
    "we have also used that @xmath783 is compactly supported on @xmath784 $ ] and that @xmath785 .      put @xmath786 and @xmath787:=\\sup_{f\\in n_1}{\\mathbb e}_f^{(n ) } \\bigl\\{a_n \\bigl|\\widetilde{f}_n(x_0)-f(x_0 ) \\bigr|",
    "\\bigr\\}^q + \\sup_{f\\in n_2 } { \\mathbb e}_f^{(n ) } \\bigl\\{b_n \\bigl|\\widetilde { f}_n(x_0)-f(x_0 ) \\bigr| \\bigr\\}^q . \\ ] ] it is easily seen that @xmath788\\geq{{\\cal r}}_n^{(1 ) } [ a_n , b_n,\\widetilde{f},f ] $ ] and that @xmath789\\geq{\\mathbb e}_{f_1}^{(n ) } \\bigl\\ { |t_n-1 | \\bigr\\}+\\frac{b_n}{a_n}{\\mathbb e}_{f_0}^{(n ) } \\{t_n \\}.\\end{aligned}\\ ] ] here , we have used the triangle inequality and the assumption @xmath790 and @xmath791 .",
    "we obtain @xmath789\\geq{\\mathbb e}_{f_0}^{(n ) } \\{c_n\\wedge z_n \\}\\geq\\tfrac{1}{2 } \\bigl[c_n+1-\\sqrt { { \\mathbb e}_{f_0}^{(n ) } \\{c_n - z_n \\}^2 } \\bigr].\\end{aligned}\\ ] ] here , we have used the trivial equality @xmath792 , that @xmath793 and the cauchy ",
    "schwarz inequality . using the third assumption",
    ", we also have @xmath794 . finally , for @xmath150 large enough , @xmath795\\geq \\frac{1}{2 } \\bigl[c_n+1-\\sqrt{c_n^2-c_n } \\bigr]\\geq\\frac{1}{2}. \\ ] ]",
    "the author is grateful to o. lepski and the anonymous referees for their very useful remarks and suggestions ."
  ],
  "abstract_text": [
    "<S> in this paper , we study the problem of pointwise estimation of a multivariate density . </S>",
    "<S> we provide a data - driven selection rule from the family of kernel estimators and derive for it a pointwise oracle inequality . using the latter bound , we show that the proposed estimator is minimax and minimax adaptive over the scale of anisotropic nikolskii classes . </S>",
    "<S> it is important to emphasize that our estimation method adjusts automatically to eventual independence structure of the underlying density . </S>",
    "<S> this , in its turn , allows to reduce significantly the influence of the dimension on the accuracy of estimation ( curse of dimensionality ) . </S>",
    "<S> the main technical tools used in our considerations are pointwise uniform bounds of empirical processes developed recently in lepski [ _ math . </S>",
    "<S> methods statist . _ </S>",
    "<S> * 22 * ( 2013 ) 8399 ] .    </S>",
    "<S> ./style / arxiv - general.cfg </S>"
  ]
}