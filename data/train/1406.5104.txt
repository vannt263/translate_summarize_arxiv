{
  "article_text": [
    "mathematically , shannon entropy of a variable @xmath0 , defined as @xmath1 @xcite , is a well - defined quantity when @xmath0 is discrete , taking distinct values @xmath2 with probabilities @xmath3 .",
    "this is not the case when @xmath0 is sampled from a continuous probability distribution where an equivalent definition would just give infinity @xcite .",
    "nonetheless , there exists a generalization of mutual information ( mi ) of two variables @xmath0 and @xmath4 with joint probability distribution @xmath5 and corresponding marginals @xmath6 and @xmath7 : @xmath8 from discrete to continuous joint probability distribution @xmath9 which is well - behaved @xcite .",
    "however , given discrete ordered pair ( @xmath10 ) sampled from an unknown joint probability distribution over continuous variables , we would have to approximate the true ( continuous ) distribution from it . at the level of probability ,",
    "this is achieved by binning and discretizing the range of values of the variables .",
    "+ while this is carried out straightforwardly , there are pitfalls in simple generalization to mutual information .",
    "the key problem is that mutual information depends in a significant way on the discretization parameters , even when the number of points is very large .",
    "we show this with the following simple but general example .",
    "consider ordered pairs @xmath11 from a joint distribution with the only requirement that @xmath12 for @xmath13 and likewise for @xmath14 s . if the entire range of @xmath0 and @xmath4 is considered as a single segment for discretization , @xmath15 and @xmath16 then the joint probability distribution @xmath17 and hence the marginals are also unity for the corresponding @xmath0 and @xmath4 ranges .",
    "it can be immediately seen that the mutual information is zero .",
    "now , for the other extreme , we choose the interval widths @xmath18 and @xmath19 such that there is at most one point lying within each interval ( for both the variables ) .",
    "we can always do this by selecting @xmath20 and @xmath21 . in that case",
    ", the discretized joint probability in each rectangular cell is @xmath22 if it is occupied and 0 otherwise . in much the same way the marginal probability in each interval is either @xmath22 or 0 for both @xmath0 and @xmath4 .",
    "fig ( [ full - mi ] ) shows how would be done in the general case ( note that interval widths there are not uniform ) .",
    "-direction ( @xmath4-direction ) there is exactly one point within it .",
    "this corresponds to a maximum possible mutual information of @xmath23 . _",
    "_ ]    we have then the mutual information : @xmath24 thus , for a set of @xmath25 observations from a joint probability distribution , the mutual information can vary between 0 and @xmath26 depending on the size of the binning .",
    "what is most striking about this is that _ this is true regardless of the true mutual information of the underlying joint probability distribution_. as the upper bound grows with the size @xmath25 , having a larger sample number does not solve the fundamental problem of the inherent ambiguity of defining mutual information using discrete data points . +      recognizing this basic limitation , we wish to consider the implications of different choices of binning in estimating mutual information @xcite .",
    "we want to understand the underlying biases and the possible deviation of mathematical properties from that of the original definition .",
    "+ in general , mutual information increases as we increase the number of partitions of the space .",
    "we can see that in fig ( [ mi - v - bin-1 ] ) the variation of the estimated mutual information for two multivariate gaussian random variables with the number of bins ( assuming fixed bin length ) for different sample sizes @xmath25 .",
    "the plotted values for the estimated mi comes from the average taken over 50 samples . in the supplement , we prove a general result stating that the doubling of partition size would increase the mutual information between two variables for an arbitrary set of samples",
    ". however , this by itself would not be an issue if we are considering reverse engineering in networks as long as the rankings of estimated mutual information between variables is preserved with respect to their true values +    0.45     0.45     there are other biases and errors that are introduced by the choice of the partitioning scheme that we will consider here . broadly , partitioning of the two dimensional space of variables @xmath0 and @xmath4",
    "fall into two general categories : uniform number of bins ( @xmath27 ) where the number of divisions of both axis is identical , uniform width where the width of each partition ( @xmath28 ) is identical for both variables , and uniform frequency where the number of points falling into each partition ( for each variable ) variable is fixed .. we will now turn to each of these specific methods .      here",
    "each axis of the space is split into equal number of uniform segments .",
    "the advantage of this method is that it works well when the data is distributed reasonably evenly across the range of each axis which happens when the density of points falls off sharply outside of the confined region under consideration .",
    "+ however , the difficulty arises with probability densities that have a fat tail , where the spread is wide but the majority of points are still lying within a smaller region .",
    "a binning of this sort would then be finer for points in the periphery but coarser in the denser regions , thus tending to underestimate the mutual information from the latter areas .",
    "we demonstrate this by estimating the entropy for two samples , the first of which comes from the exponential family , @xmath29 with @xmath30 and the second a multivariate gaussian in two - variables @xmath31 where @xmath32 and @xmath33 .",
    "each set consists of 200 points , and the barplots of distributions ( fig.([id - np],[nid - np ] ) ) across a uniform @xmath34 grid show that while the multivariate normal is spread quite smoothly across the entire surface , it falls off in the other for @xmath35 .",
    "the mutual information can be theoretically computed in these two cases : @xmath36 where @xmath37 is the digamma function and @xmath38 which evaluate to @xmath39 and @xmath40 but the estimated mutual information from the above binning leads to @xmath41 and @xmath42 .",
    "+ the reason for the severe underestimation in the first case is precisely the fact that there is a closer clustering of points within a smaller region where this type of binning tends to be ` too wide ' and averaging the finer distinctions . in the multivariate normal case ,",
    "this difference is not so striking , and the estimation is far more accurate .",
    "0.43     0.43     0.43     0.43     0.43     0.43       the other standard approach to choosing a grid on the two dimensional space of points is to set the width of every partition on both axes to be a constant . as the spread of the two variables is in general different ,",
    "the total number of partitions need not be the same .",
    "the idea behind this is that the width represents the distance over which points are considered to fall within the same discrete category .",
    "it may be set based on estimates of noise in the sample , or , where available , prior knowledge of the form of the joint distribution .",
    "+ there is however a fundamental problem with this approach : setting the widths to be a constant destroys the scaling invariance of the theoretical definition of mutual information for continuous variables . in eq .",
    "( [ mi - c ] ) , the integral is invariant under the transformation @xmath43 which corresponds to scaling the metric of the y - axis by a constant .",
    "it must be noted that this is not an incidental property of the integral but one that is central to the usefulness of mutual information , i.e. , mere scaling of the underlying space should not , and does not , alter the relative information between two variables .",
    "+ choosing binning styles with equal widths implies that scaling the points along one direction in the space would change the number of partitions on its axis , which changes the estimated mutual information .",
    "the effect of this can be easily observed by considering samplings from two multivariate normal distributions in two dimensions that differ only by the scaling of the y - axis by a factor of @xmath44 ( fig .",
    "( [ g1 ] ) and fig .",
    "( [ g2 ] ) . by definition",
    ", the scale - invariance implies equal mutual information but the requirement of setting equal widths ( unity in this case ) leads fewer bins in the second case and consequent underestimation of its value .      in this case ,",
    "the boundaries of the partitions for a given variable are chosen such that each division contains an equal number of points .",
    "the general advantage of this method is that , unlike the above two , every row or column in the grid would contain equal number of points , eliminating the problem highlighted in fig ( [ id - np],[nid - np ] ) .",
    "however , this would skew joint distributions that have strong association between two variables to a more uniform shape , causing an underestimation in mutual information .",
    "we can see this with the mixed - gaussian distribution with three modes ( fig .",
    "( [ ef ] ) ) where the effect of choosing the equal frequency partitioning on a @xmath34 grid flattens the peak in the center spreading the probability over a wider region , leading to a decrease in mutual information .",
    "+ it is thus clear from the examples above that the standard types of partitioning is in general unsatisfactory in terms of obtaining reasonable and consistent mutual information scores .",
    "it should be noted that although our examples consider discrete binning of the data , the kernel - based estimation of mutual information @xcite has the same fundamental problem .",
    "while it is not as pronounced as it is with direct binning , the width of the kernel in that case is equivalent to the width of the bins here ( equal - width partition ) . the same is true with estimators like the k - nearest neighbors @xcite where the scores depend on the parameter corresponding to the number of neighbors .",
    "data - driven reverse - engineering of genetic networks uses pairwise association between genes to determine true interactions among them .",
    "information theory is applied effectively for this task by estimating the mutual information between every pair of network node variables and reconstructing the network based on the relative rankings of the different edge scores @xcite . a distinct advantage being that mutual information detects all forms of associations while correlation - based measures perform well only with linear relations .",
    "+ we propose a novel method of partitioning of space in the context of network reverse - engineering that aims to reduce the biases created by the standard techniques .",
    "this includes choosing grid sizes that take into consideration ( a ) overall spread of the data among all variables ( b ) spread of the values of the pair of node variables in question ( c ) dependence of numerical estimation of mutual information on this spread ( d ) appropriate normalization using the entropy of each variable .",
    "+ given set @xmath45 of n node variables and m samples , we choose first a standard partition width @xmath46 , where @xmath47 , and @xmath48 is an integer parameter that represents the minimum number of partitions and @xmath49 is the empirical standard deviation of the @xmath0 variable values .",
    "+ for any two node variables @xmath0 and @xmath4 whose mutual information we want to estimate , the number of bins @xmath50 and @xmath51 are obtained using the following algorithm ( see fig . [ alg ] ) .",
    "in addition to @xmath48 , we have another integer parameter @xmath52 that sets the maximum number of partitions .",
    "+     +    steps 1 - 3 may look complicated but the idea is simple enough : we prefer to maintain the bin widths constant as long as their numbers lie between @xmath48 and @xmath52 .",
    "this is primarily in recognition of the fact that spread of the node variable is a measure of the strength of the interactions : if the values are nearly the same , the uniform width approach would select fewer partitions .",
    "however , to ensure that the distribution is not skewed when the spread of one or both is large ( or too small ) , we need to correspondingly _ rescale both variables _ to force them to lie within that range .",
    "heuristically , the two limits @xmath48 and @xmath52 ensure that the relative values of mutual information are not under- or over - estimated . + * normalization measure * : + step 5 was motivated by two considerations .",
    "first , we note that a proper normalization is required when having different bin sizes .",
    "if , for example , there is a node variable with a small spread but happens to have a strong direct interaction with another node , the binning scheme would then ` overcorrect ' for the small spread .",
    "we overcome that by such a normalization scheme .",
    "second , we recognize that what is significant in reverse - engineering is not the absolute value of mutual - information but the mi relative to the information content of the two node variables . the inequality @xmath53 captures the fact that this quantity represents that part of the information that is shared between the nodes .",
    "the fraction of what is shared should serve as a better indicator of true interaction than their absolute values .",
    "+      we assess the algorithm by studying its performance on _ in - silico _ networks against that of standard methods ( see section [ meth ] for more details ) .",
    "the initial comparison is with respect to the estimation method using only uniform bin size or uniform bin number .",
    "evaluation of the performance is done by plotting the precision - recall curve ( fig .",
    "( [ pr - uvnu ] ) ) ( see section [ meth ] for more details on their definition ) .",
    "it can be clearly seen that , at any given value of recall , the precision is significantly higher when using adaptive non - uniform discretization .",
    "we also consistently found better results regardless of the size or the topology of the network or its dynamics .",
    "+    0.45   and @xmath54 refer to the total number of nodes and true edges in the network.__,title=\"fig : \" ]    0.45   and @xmath54 refer to the total number of nodes and true edges in the network.__,title=\"fig : \" ]    0.5   and @xmath54 refer to the total number of nodes and true edges in the network.__,title=\"fig : \" ]     + our method performed better even against standard mutual - information based approaches such as kernel estimation and dpi ( aracne ) @xcite and the k - nearest neighbor algorithm ( with dpi ) @xcite ( fig .",
    "( [ knn - aracne ] ) ) .    0.45   and @xmath54 refer to the total number of nodes and true edges in the network.__,title=\"fig : \" ]    0.45   and @xmath54 refer to the total number of nodes and true edges in the network.__,title=\"fig : \" ]     + for biological data sets , we considered the gene regulatory network of _ e. coli _ , and the expression data for it from the dream 5 challenge @xcite . in this case , the set of transcription factors is known , and the aim is to determine their targets .",
    "thus our binning choice should reflect this prior knowledge and the algorithm was modified accordingly ( described in the supplement ) .",
    "of the set of 2000 interactions we evaluated , of which only 111 represented true regulatory interactions , our method clearly performed better than the standard method of discretization ( fig .",
    "[ ec - c1 ] ) .",
    "we constructed synthetic networks obeying power - law degree - distribution with the r package _ igraph_. the data was generated by carrying out numerical integration of the hill - kinetic equations corresponding to the network topology until global steady state was reached .",
    "each sample in the data set corresponds to the steady state value of all variables .",
    "different samples correspond to steady states of different equations obtained with set of parameters comes from a uniform distribution .",
    "+ the precision - recall curve ( prc ) is used to evaluate these networks , where precision and recall are given by : @xmath55 + @xmath56 and tp= true positives ( the number of correct interactions identified ) , fp= number of pairs incorrectly identified , and fn = number of interactions that were unidentified . in general , there is a trade - off between precision and recall , as we slide the threshold parameter .",
    "we have described and detailed significant problems with the definition and estimation of mutual information , a quantity that is central to information theory .",
    "we argue that this issue is of a theoretical nature leading to an inherent arbitrariness in its estimation from a discrete set of points .",
    "moreover , the the errors introduced by the standard forms of partitions of space is explicitly demonstrated with examples . + by formulating a novel adaptive partitioning algorithm for reverse engineering of networks",
    ", we further show the impact of these estimation biases in a real - world context where mutual information is applied extensively .",
    "the superior performance of the method over standard approaches on both in - silico and real biological networks is not only an advancement in that field , but also clearly implies the necessity to carefully understand the problems with estimating mutual information .",
    "+ the applications of information theory to various fields have grown enormously in recent decades as the concepts have become central to areas such as physics , communications and signaling , inference theory , multiple biological sciences , pattern recognition and artificial intelligence@xcite .",
    "we believe that a thorough investigation of the fundamental issues involved in the subject would be immensely beneficial to all of their applications .",
    "we show that doubling the partition number along one of the directions leads to a non - negative change in the mutual information . starting with a division of the 2d space into @xmath57 blocks we bisect each of the @xmath58 units along the @xmath59axis to create @xmath60 cells . the mutual information : @xmath61 where @xmath62 is the fraction of particles lying in the rectangular cell @xmath63 .",
    "after bisection , we have a new probability distribution @xmath64 ( dropping the double - index subscript ) where @xmath65 , such that @xmath66 for @xmath67",
    ". we will show that for every original cell , its contribution to mi is exceeded by the sum of the contributions of the bisected components and thus obtain a stronger version of our required result .",
    "to prove : @xmath68 which reduces to , @xmath69 substituting @xmath70 , @xmath71 straightforward rearrangements of the terms leads to , @xmath72 which is equivalent to demonstrating that :    @xmath73    for @xmath74 .",
    "the left hand side is nothing but kl - divergence between two distributions on two element set with probabilities @xmath75 and @xmath76 , which is always positive .",
    "we used a modification of the general algorithm for the tf - target identification in the _ e. coli _ expression data set . as the set of transcription factors",
    "are known , the binning adjustments can be limited to the targets here and thus our technique is significantly simplified . as before @xmath77 ,",
    "where @xmath47 , and @xmath78 and @xmath79 represent the minimum and maximum number of bins .",
    "+ * step 1 * : fix @xmath80 + * step 2 * : if @xmath81 , then reset @xmath82 . + * step 3 * : if @xmath83 , then @xmath84 . + * step 4 * : once the binning is fixed , we proceed to calculate the number of points falling within each rectangle , and the discretized form of mutual information between the two variables .",
    "+ * step 5 * : we normalize the mutual information by dividing by @xmath85 , where @xmath86 and @xmath87 are the entropies of @xmath0 and @xmath4 calculated using the same bin numbers @xmath50 and @xmath51 respectively .",
    "yeung m.k . ,",
    "tegnr j. , collins j.j . , * reverse engineering gene networks using singular value decomposition and robust regression * , _ proc natl acad sci usa _ , * 99(9 ) * : 6163 - 6168 ( 2002 ) .",
    "hecker m.,lambeck s. , toepfer s.,van someren e. , guthke r. , * gene regulatory network inference : data integration in dynamic models  a review * , biosystems * 96 * 86103 ( 2009 ) markowetz f.,span r. , * inferring cellular networks  a review * , _ bmc bioinformatics _ * 8 * ( suppl 6):s5 ( 2007 ) bansal m.,belcastro v. , alberto ambesi - impiombato1 , di bernardo d. , * how to infer gene networks from expression profiles * , _ molecular systems biology _ * 3*:78 ( 2007 ) hendricks d.m . , hendriks m.m .",
    "w. b.,eilers p.",
    "h. c.,smildeac a.k . ,",
    "hoefslootac huub c. j.,*reverse engineering of metabolic networks , a critical assessment * , _ mol .",
    "_ , * 7 * , 511 ( 2011 ) liang s , fuhrman s and somogyi r. , * reveal , a general reverse engineering algorithm for inference of genetic network architectures * , _ pac symp biocomput _ , 18 ( 1998 ) butte a.j.,kohane i.s . ,",
    "* mutual information relevance networks : functional genomic clustering using pairwise entropy measurements . * , _ pac symp biocomput._,*5 * 415 ( 2000 ) reshef d.n . , reshef y.a . ,",
    "finucane h.k . ,",
    "grossman s.r . , mcvean g. , turnbaugh p.j . , lander e.s . , mitzenmacher m. , sabeti p.c .",
    ", * detecting novel associations in large data sets * , _ science _ * 334 * ( 6062 ) : 1518 ( 2011 ) faith j.j . , hayete b.,thaden j.t.,mogno i. , wierzbowski j. , cottarel g.,kasif s. , collins j.j . ,",
    "gardner t.s .",
    ", * large - scale mapping and validation of escherichia coli transcriptional regulation from a compendium of expression profiles * , _ plos biol _ * 5(1 ) * : e8 .",
    "margolin a.a . , wang k. , califano nemenman i , * multivariate dependence and genetic networks inference * , _ iet syst biol . _ * 4(6 ) * : 428 shannon c.e . , * the mathematical theory of communication * , _ bell syst",
    "journal _ , * 27 * , 379 ( 1948 ) .",
    "lesne a.,*shannon entropy : a rigorous notion at the crossroads between probability , information theory , dynamical systems and statistical physics * , _ mathematical structures in computer science _ , * 24 * , si 03 , 24031 ( 2014 ) de matos simoes r. , emmert - streib f. , * influence of statistical estimators of mutual information and data heterogeneity on the inference of gene regulatory networks * _ plos one _ * 6(12 ) * : e29279 ( 2011 ) moon y.i . , rajagopalan b. , lall u.,*estimation of mutual information using kernel density estimators * , _ phys . rev .",
    "* 52 * , 2318 ( 1995 ) margolin a.a .",
    ", nemenman i. , basso k. , wiggins c. , stolovitzky g. , dalla favera r. , califano a. , * aracne : an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context * , _ bmc bioinformatics _ * 7 * ( suppl 1):s7 kraskov a.,stgbauer h. , grassberger p. , * estimating mutual information * , _ phys .",
    "e _ * 69 * , 066138 ( 2004 ) chow ck , liu cn , * approximating discrete probability distributions with dependence trees*,_ieee trans . inf .",
    "thy._,*14(3 ) * , 462 ( 1968 ) marbach _ et al _ , * wisdom of crowds for robust gene network inference * , _ nature methods _ , * 9 * , 796 ( 2012 ) jaynes e.t . , * information theory and statistical mechanics * , _ phys . rev .",
    "_ , * 106 * , 620 ( 1957 ) adami c. , * information theory in molecular biology * , _ physics of life reviews _ , * 1(1 ) * , 3 ( 2004 ) maasoumi e. , * a compendium to information theory in economics and econometrics * , * 12 ( 2 ) * , 137 ( 1993 ) pereira f. , * formal grammar and information theory : together again ? * , _ phil .",
    "a _ , * 358 * , 1239 ( 2000 ) tishby n. , pereira f.c . , bialek w. , * the information bottleneck method * , _ the 37th annual allerton conference on communication , control , and computing _ , 368377 ( 1999 ) studholme c. , hill d.l.g .",
    ", hawkes d.j .",
    ", * an overlap invariant entropy measure of 3d medical image alignment * _ pattern recognition _ * 32(1 ) * 7186 ( 1999 )"
  ],
  "abstract_text": [
    "<S> we identify fundamental issues with discretization when estimating information - theoretic quantities in the analysis of data . </S>",
    "<S> these difficulties are theoretical in nature and arise with discrete datasets carrying significant implications for the corresponding claims and results . here </S>",
    "<S> we describe the origins of the methodological problems , and provide a clear illustration of their impact with the example of biological network reconstruction . </S>",
    "<S> we propose an algorithm ( shared information metric ) that corrects for the biases and the resulting improved performance of the algorithm demonstrates the need to take due consideration of this issue in different contexts .    </S>",
    "<S> this is investigated in the context of network inference @xcite where information - theoretic methods have been extensively applied @xcite . despite its ubiquity , general systematic analysis of the techniques and their underlying assumptions have been few @xcite.although information entropy , and its variations such as the joint or conditional entropy , is well - defined for discrete variables , its formulation for continuous probability distribution is far from unambiguous . </S>",
    "<S> the flexibility in this definition lies at the heart of the issue when applying it consistently to different physical systems . </S>",
    "<S> specifically , entropy estimation in continuous cases requires discretization of the variable values , and the calculation results are not invariant to the choice of discretization . with the focus on reverse - engineering , </S>",
    "<S> we describe the fundamental issues with information - theoretic methods , construct examples that highlight them , and propose an algorithm to remedy the situation . </S>"
  ]
}