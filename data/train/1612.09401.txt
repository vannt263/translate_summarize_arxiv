{
  "article_text": [
    "action recognition is an important problem in computer vision due to its wide applications in video surveillance , human computer interfaces , robotics , etc . despite significant research efforts over the past few decades",
    "@xcite , accurate recognition of human actions from rgb video sequences is still an unsolved problem . with the advent of easy - to - use and low - cost depth sensors such as ms kinect sensors ,",
    "human action recognition from rgb - d ( red , green , blue and depth ) data has attracted increasing attention and many applications have been developed  @xcite in recent years , due to the advantages of depth information over conventional rgb video , e.g. being insensitive to illumination changes and reliable to estimate body silhouette and skeleton  @xcite .",
    "since the first work  @xcite reported in 2010 , many methods  @xcite have been proposed using specifically hand - crafted feature descriptors extracted from depth .",
    "as the extraction of skeletons from depth maps  @xcite has become increasingly robust , more and more hand - designed skeleton features  @xcite have been devised to capture spatial configuration , and dynamic time warpings ( dtws ) , fourier temporal pyramid ( ftp ) or hidden markov models ( hmms ) are employed to model temporal information",
    ". however , these hand - crafted features are always shallow and dataset - dependent .",
    "recently , recurrent neural networks ( rnns )  @xcite have also been adopted for action recognition from skeleton data .",
    "rnns tend to overemphasize the temporal information especially when the training data is not sufficient , leading to overfitting . up to date",
    ", it remains unclear how skeleton sequences could be effectively represented and fed to deep neural networks for recognition .",
    "for example , one can conventionally consider a skeleton sequence as a set of individual frames with some form of temporal smoothness , or as a subspace of poses or pose features , or as the output of a neural network encoder .",
    "which one among these and other possibilities would result in the best representation in the context of action recognition is not well understood .    in this paper",
    ", we present an effective yet simple method that represent both spatial configuration and dynamics of joint trajectories into three texture images through color encoding , referred to as joint trajectory maps ( jtms ) , as the input of convnets for action recognition .",
    "such image - based representation enables us to fine - tune existing convnets models trained on imagenet for classification of skeleton sequences without training the whole deep networks afresh .",
    "the three jtms are complimentary to each other , and the final recognition accuracy is improved largely by a late score fusion method .",
    "one of the challenges in action recognition is how to properly model and use the spatio - temporal information .",
    "the commonly used bag - of - words model often ignores spatial information . on the other hand ,",
    "hmms or rnns based methods are likely to overstress the temporal information .",
    "the proposed method addresses this challenge in a novel way by encoding as much the spatio - temporal information as possible ( without a need to decide which one is important and how important it is ) into images , and employing convnets to learn the discriminative one .",
    "consequently , the proposed method outperformed the start - of - the - art methods on popular benchmark datasets .",
    "the main contributions of this paper include :    * a compact , effective yet simple image - based representation is proposed to represent the spatio - temporal information carried in the @xmath0 skeleton sequences into three @xmath1 images by encoding the dynamics of joint trajectories into three complementary joint trajectory maps . * to overcome the drawbacks of convnets not being rotation - invariant , and to make the proposed method suitable for cross - view action recognition , it is proposed to rotate the skeleton data to not only mimic the multiple views but also to augment data effectively for training . *",
    "the proposed method was evaluated on four popular public benchmark datasets , namely , the large ntu rgb+d dataset  @xcite , msrc-12 kinect gesture dataset ( msrc-12 )  @xcite , g3d dataset  @xcite and utd multimodal human action dataset ( utd - mhad )  @xcite , and achieved the state - of - the - art recognition results .",
    "this paper is an extension of the works presented in  @xcite . unlike  @xcite where skeletons are assumed to have been sufficiently sampled and",
    "discrete joints are drawn onto images using a pen whose size is properly set , this paper employs joint trajectories and proposes to rotate skeletons to mimic multiple views for cross - view action recognition and data augmentation .",
    "in addition , this paper adopts multiply score fusion to improve the final recognition accuracy .",
    "extensive experiments and detailed analysis are also presented in this paper .",
    "the rest of this paper is organized as follows .",
    "an overview of related works is given in section  [ relatedwork ] .",
    "details of the proposed method are described in section  [ proposedmethod ] .",
    "evaluation of the proposed method on four datasets and analysis of the results are reported in section  [ experiments ] .",
    "section  [ conclusion ] concludes the paper with remarks .",
    "an extensive review on rgb - d based action recognition is beyond the scope of this paper .",
    "readers are referred to  @xcite for a comprehensive survey . in this section ,",
    "the work related to the proposed method is briefly reviewed , including skeleton - based 3d action representation and deep learning based action recognition .",
    "skeleton based 3d action representation can be generally divided into three categories  @xcite : joints , groups of joints , and joint dynamics .",
    "joint representation captures the correlation of the body joints by extracting spatial descriptor  @xcite , geometric descriptor  @xcite or key poses  @xcite .",
    "the groups of joints aim to detect the discriminative subsets of joints to differentiate actions .",
    "methods such as  @xcite focus on mining the subsets of most discriminative joints or consider the correlation of predefined subsets of joints .",
    "joint dynamics focuses on modeling the dynamics of either subsets or all joints of a skeleton . in  @xcite 3d trajectories of joints",
    "are projected into three 2d trajectories , and histogram of oriented displacement is calculated to describe the three 2d trajectories , with each displacement in the trajectory voting its length in the histogram of orientation angles .",
    "chaudhry et al .",
    "@xcite divided the fully body skeleton into several body parts represented by joints , including the upper body , lower body , left / right arms and left / right legs .",
    "a shape context feature is computed by considering the directions of a set of equidistant points sub - sampled over the segments of each body part .",
    "a skeleton sequence is finally represented as a set of time series of features such as position , tangent and shape context feature .",
    "these time series are further divided into several temporal scales , and each individual feature series is modeled using a linear dynamic system .",
    "the estimated parameters of all series are used to describe the dynamics of the skeleton sequence . in  @xcite a skeleton sequence",
    "is modeled as a continuous and differentiable function of the body joint locations over time .",
    "the local 3d body pose is characterized by the current joint locations and differential properties like speed and acceleration of the joints .",
    "slama et al .",
    "@xcite represented each action sequence as a linear dynamic system that produces 3d joint trajectories .",
    "autoregressive moving average model was adopted to represent the dynamics by means of observability matrix which embeds the parameters of the model . in  @xcite the dynamic forest model was proposed and a set of autoregressive trees was adopted .",
    "each node in the probabilistic autoregressive tree stores a multivariate normal distribution with a fixed covariance matrix , and the set of gaussian posteriors estimated by the forest are used to calculate the forest posterior .",
    "shao et al .",
    "@xcite proposed to use a class of integral invariants to describe motion trajectories by calculating the line integral of a class of kernel functions at multiple scales along the motion trajectory . in  @xcite",
    "the authors represented the 3d coordinates of joints and their changes over time as a trajectory in the riemannian manifold , and the action recognition is formulated as the problem of computing the similarity between the shape of trajectories . in this paper , we propose to use color to encode the dynamics of trajectories , and model the spatial - temporal information carried in a skeleton sequence through shape and textures .",
    "convnets are used to learn deep hierarchy features .",
    "the exiting deep learning approaches to action recognition can be generally divided into four categories based on how an input sequence is represented and fed to a deep neural network .",
    "the first category views a video either as a set of still images  @xcite or as a short and smooth transition between similar frames  @xcite , and each color channel of the images is fed to one channel of a convnet .",
    "although suboptimal , considering the video as a bag of static frames gives reasonable results . the second category is to represent a video as a volume and extends convnets to a third , temporal dimension  @xcite replacing 2d filters with 3d ones .",
    "so far , this approach has produced little benefits , probably due to the lack of annotated training data .",
    "the third category is to treat a video as a sequence of images and feed the sequence to a rnn  @xcite .",
    "a rnn is typically considered as memory cells , which are sensitive to both short as well as long term patterns .",
    "it parses the video frames sequentially and encodes the frame - level information in their memory .",
    "however , using rnns has not given an improvement over temporal pooling of convolutional features  @xcite or over hand - crafted features .",
    "the last category is to represent a video in one or multiple compact images and adopt available trained convnet architectures for fine - tuning  @xcite .",
    "this approach has achieved state - of - the - art results on many rgb and depth / skeleton datasets .",
    "the proposed method falls into this category .",
    "the proposed method consists of four major components , as illustrated in fig .",
    "[ fig : framework ] , rotation to mimic the multiple views , construction of three jtms as the input of the convnets in three orthogonal planes from skeleton sequences , training the three convnets to learn discriminative features , and multiply score fusion for final classification . in the following sections , the four components are detailed .",
    "a skeleton is often represented by a set of joints in 3d space with respect to the real - world coordinate system centered at the optical central of the rgb - d camera . by rotating the skeleton data",
    ", it can 1 ) mimic multi - views for cross - view action recognition ; 2 ) enlarge the data for training and overcome the drawback of convnets usually being not view - invariant .",
    "the rotation was performed with a fixed step of @xmath2 along the polar angle @xmath3 and azimuthal angle @xmath4 , in the range of @xmath5 $ ] for @xmath3 and @xmath6 $ ] for @xmath4 .",
    "the ranges of @xmath3 and @xmath4 would cover the possible views considering that the jtms are generated by projecting the trajectories onto the three orthogonal planes as detailed below .",
    "let @xmath7 be the transform around @xmath8 axis ( right - handed coordinate system ) and @xmath9 be the transform around @xmath10 axis .",
    "the coordinates @xmath11 of a joint at @xmath12 after rotation can be expressed as @xmath13^ \\mathrm { t }   = \\mathbf tr_{y}\\mathbf tr_{x } \\begin{bmatrix }   x , y , z , 1 \\\\       \\end{bmatrix}^ \\mathrm { t } \\ ] ] where @xmath14 and +    @xmath15 @xmath16 @xmath17 @xmath18      we argue that an effective jtm should have the following properties to keep the spatial - temporal information of an action :    * the joints or group of joints should be distinct in the jtm such that the spatial information of the joints is well reserved .",
    "* the jtm should encode effectively the temporal evolution , i.e. trajectories of the joints , including the direction and speed of joint motions .",
    "* the jtm should be able to encode the difference in motion among the different joints or parts of the body to reflect how the joints are synchronized during the action .",
    "specifically , a jtm can be recursively defined as follows @xmath19 where @xmath20 is a function encoding the spatial - temporal information at frame or time - stamp @xmath21 .",
    "since a jtm is accumulated over the period of an action , @xmath20 has to be carefully defined such that the jtm for an action sample has the required properties discussed above and the accumulation over time has little adverse impact on the spatial - temporal information that has already been encoded in the jtm .",
    "this paper proposes to use hue , saturation and brightness to encode the spatial - temporal motion patterns .",
    "assume an action @xmath22 has @xmath23 frames of skeletons and each skeleton consists of @xmath24 joints .",
    "the skeleton sequence is denoted as @xmath25 , where @xmath26 is a vector of joint coordinates of frame @xmath21 , and @xmath27 is the @xmath0 coordinates of the @xmath28 joint in frame @xmath21 .",
    "the skeleton trajectory @xmath29 for an action of @xmath23 frames consists of the trajectories of all joints and is defined as : @xmath30 where @xmath31 , and the @xmath32 joint trajectory is @xmath33 .",
    "a simple form of function @xmath20 would be @xmath34 , that is , @xmath35    the skeleton trajectory is projected to three orthogonal planes , i.e. three cartesian planes of the real world coordinates of the camera , to form three jtms .",
    "[ fig1 ] shows the three projected trajectories of the right hand joint for action ",
    "right hand draw circle ( clockwise ) \" in the utd - mhad dataset .",
    "it can be seen that the spatial information of this joint over the period of the action is well represented in the jtms but the direction of the motion is lost .      to capture the motion direction in the jtm",
    ", it is proposed to use hue to  color \" the joint trajectories over the action period .",
    "different colormaps may be chosen . in this paper , the jet colormap , ranging from blue to red , and passing through the colors cyan , yellow , and orange , is adopted .",
    "let the color of a joint trajectory be @xmath36 , and the length of the trajectory be @xmath37 , and @xmath38 be the color at position @xmath39 of a trajectory .",
    "for the @xmath40 trajectory @xmath41 from @xmath42 to @xmath43 , a color @xmath44 , where @xmath45 is assigned to location @xmath39 of the joint trajectory , making the entire trajectory colored over the period of the sequence as illustrated in fig .",
    "herein , a trajectory with color is denoted as @xmath46 and the function @xmath20 becomes : @xmath47 fig .",
    "[ fig3 ] shows the front jtm of action `` right hand draw circle ( clockwise ) '' in the utd - mhad  @xcite dataset .",
    "sub - figure ( 1 ) is joint trajectories and sub - figure ( 2 ) is the trajectories with motion direction being encoded with hue .",
    "the color variations along the trajectories represent the motion direction .",
    "many actions , especially complex actions , often involve multiple body parts and these body parts move in a coordinating manner .",
    "it is important to capture such coordination in the jtms . to distinguish different body parts ,",
    "multiple colormaps are employed .",
    "body parts can be defined at different levels of granularity .",
    "for example , each joint can be considered independently as a  part \" and is assigned to one colormap , or several groups of joints can be defined and all joints in each group are assigned to the same colormap and colormaps are chosen randomly to each group . since arms and legs often move more than other body parts , a body is divided into three parts in this paper . according to the joint configuration for kinect v1 skeleton as shown in fig .",
    "[ skl ] , the left body part consists of left shoulder , left elbow , left wrist , left hand , left hip , left knee , left ankle and left foot , the right body part consists of right shoulder , right elbow , right wrist , right hand , right hip , right knee , right ankle and right foot and the middle part consists of head , neck , torso and hip center .",
    "the three parts are assigned to three colormaps ( @xmath48 ) respectively , where @xmath49 is the same as @xmath36 , i.e. the jet colormap , @xmath50 is a colormap with reversely - ordered colors of @xmath49 , and @xmath51 is a gray - scale map ranging from light gray to black .",
    "let the trajectory encoded by multiple colormaps be @xmath52 .",
    "function @xmath20 can be expressed as : @xmath53 the effect of encoding body parts with different colors for action `` right hand draw circle ( clockwise ) '' is illustrated in fig .",
    "[ fig3 ] , sub - figure ( 3 ) .",
    "motion magnitude is one of the important factors in human motion . for an action ,",
    "large magnitude of motion is likely to carry discriminative information .",
    "this paper proposes to encode the motion magnitude of joints into saturation and brightness so that the changes in motion would result in texture in the jmts .",
    "such texture is expected to be beneficial for convnets to learn discriminative features . for joints with high motion magnitude or speed ,",
    "high saturation will be assigned .",
    "specifically , the saturation is set to range from @xmath54 to @xmath55 .",
    "given a trajectory , its saturation @xmath56 along the path of the trajectory could be calculated as @xmath57 where @xmath58 is the speed of @xmath59th joint at the @xmath21th frame .",
    "@xmath60 let a trajectory modulated by saturation be @xmath61 , function @xmath20 is refined as : @xmath62 for the sample example in fig .  [ fig3 ] , the encoding effect can be seen in the sub - figures ( 4 ) , where the slow motion becomes diluted ( e.g. trajectory of knees and ankles ) while the fast motion becomes saturated ( e.g. the green part of the circle ) .    to further enhance the motion patterns in the jtms",
    ", the brightness is modulated by the speed of joints . given a trajectory @xmath63 whose speed is @xmath58 , its brightness @xmath64 is computed as @xmath65 where @xmath66 and @xmath67 represent the range of the brightness .",
    "let @xmath68 be the trajectory with brightness and function @xmath20 is then updated to : @xmath69 the effect of brightness modulation can be seen in sub - figure ( 5 ) of the example shown in in fig .",
    "[ fig3 ] , where texture becomes apparent ( e.g. the yellow parts of the circle ) .",
    "finally , let @xmath70 be the trajectory after encoding the motion magnitude into both saturation and brightness .",
    "function @xmath20 can be expressed as : @xmath71 as illustrated in fig .",
    "[ fig3 ] , sub - figure ( 6 ) , the motion variation enriches the texture in the final jtm .      after constructing the three jtms on three orthogonal image planes ,",
    "three convnets are fine - tuned individually , each convnet is an alexnet  @xcite .",
    "the fine - tuning procedure is similar to the one in  @xcite .",
    "the network weights are learned using the mini - batch stochastic gradient descent with the momentum being set to 0.9 and weight decay being set to 0.0005 .",
    "all hidden weight layers use the rectification ( relu ) activation function . at each iteration",
    ", a mini - batch of 256 samples is constructed by sampling 256 shuffled training samples .",
    "the images are resized to 256 @xmath72 256 .",
    "the learning rate is set to @xmath73 for training from scratch and set to @xmath74 for fine - tuning with pre - trained models on ilsvrc-2012 , and then it is decreased according to a fixed schedule . for each convnet",
    "the training undergoes 100 cycles and the learning rate decreases every 30 cycles .",
    "for all experiments , the dropout regularization ratio was set to 0.9 in order to reduce complex co - adaptations of neurons in the nets for both networks .      given a testing skeleton sequence ( sample ) , three jtms",
    "are generated and fed into the three convnets respectively .",
    "multiply score fusion is used to combine the outputs from the individual convnets .",
    "specifically , the score vectors outputted by the three convnets are multiplied in an element - wise way , and the max score in the resultant vector is assigned as the probability of the test sequence .",
    "the index of this max score corresponds to the recognized class label .",
    "the proposed method was evaluated on four public benchmark datasets : the large ntu rgb+d dataset  @xcite , msrc-12 kinect gesture dataset  @xcite , g3d  @xcite and utd - mhad  @xcite .",
    "experiments were conducted on the effectiveness of individual encoding scheme in the proposed method , the effectiveness of rotation , the role of fine - tuning , and the multiply score fusion compared with the max and average score fusion methods .",
    "the final recognition results were compared with the state - of - the - art reported on the same datasets . in all experiments ,",
    "the saturation and brightness range from 0% @xmath75 100% ( mapped to 0 @xmath75 255 in the jtm images ) .",
    "the effectiveness of different encoding schemes ( as illustrated in fig .  [ fig3 ] ) was evaluated on the g3d dataset , and the recognition accuracies are listed in table  [ steps ] .",
    ".comparison of the different encoding schemes on the g3d dataset in terms of recognition accuracy.[steps ] [ cols=\"^,^,^,^,^\",options=\"header \" , ]",
    "this paper addresses the problem of human action recognition by applying convnets to skeleton sequences .",
    "an effective method is proposed to project the joint trajectories to three orthogonal jtms to encode the spatial - temporal information into texture patterns .",
    "the three jtms are complementary to each other .",
    "such image - based representation enables us to fine - tune the existing convnets models trained on image data for classification of skeleton sequences , without training the deep convnets afresh .",
    "the experimental results on the four datasets have shown the efficacy of the proposed encoding scheme .",
    "extension of the proposed method to on - line action recognition is the focus of future work .",
    "w.  li , z.  zhang , and z.  liu , `` expandable data - driven graphical modeling of human actions based on salient postures , '' _ circuits and systems for video technology , ieee transactions on _ , vol .",
    "18 , no .  11 , pp . 14991510 , 2008 .",
    "h.  wang , a.  klser , c.  schmid , and c .- l .",
    "liu , `` dense trajectories and motion boundary descriptors for action recognition , '' _ international journal of computer vision _ , vol .",
    "103 , no .  1 ,",
    "6079 , 2013 .",
    "v.  kantorov and i.  laptev , `` efficient feature extraction , encoding , and classification for action recognition , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2014 , pp .",
    "25932600 .",
    "b.  ni , p.  moulin , x.  yang , and s.  yan , `` motion part regularization : improving action recognition via trajectory selection , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2015 , pp .",
    "36983706 .",
    "l.  liu , l.  shao , x.  li , and k.  lu , `` learning spatio - temporal representations for action recognition : a genetic programming approach , '' _ ieee transactions on cybernetics _ , vol .",
    "46 , no .  1 ,",
    "pp . 158170 , 2016 .",
    "l.  wang , y.  xiong , z.  wang , y.  qiao , d.  lin , x.  tang , and l.  van  gool , `` temporal segment networks : towards good practices for deep action recognition , '' in _",
    "european conference on computer vision _ , 2016 , pp .",
    "2036 .",
    "j.  shotton , a.  fitzgibbon , m.  cook , t.  sharp , m.  finocchio , r.  moore , a.  kipman , and a.  blake , `` real - time human pose recognition in parts from single depth images , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2011 , pp",
    ". 12971304 .",
    "m.  zanfir , m.  leordeanu , and c.  sminchisescu , `` the moving pose : an efficient 3d kinematics descriptor for low - latency action recognition and detection , '' in _ proc .",
    "ieee international conference on computer vision ( iccv ) _ , 2013 , pp .",
    "27522759 .",
    "m.  a. gowayyed , m.  torki , m.  e. hussein , and m.  el - saban , `` histogram of oriented displacements ( hod ) : describing trajectories of human joints for action recognition , '' in _ ijcai _ , 2013 , pp .",
    "13511357 .",
    "p.  wang , w.  li , p.  ogunbona , z.  gao , and h.  zhang , `` mining mid - level features for action recognition based on effective skeleton representation , '' in _ proc .",
    "international conference on digital image computing : techniques and applications ( dicta ) _ , 2014 , pp .",
    "l.  xia , c .- c .",
    "chen , and j.  aggarwal , `` view invariant human action recognition using histograms of 3d joints , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition workshops ( cvprw ) _",
    ", 2012 , pp . 2027 .",
    "r.  chaudhry , f.  ofli , g.  kurillo , r.  bajcsy , and r.  vidal , `` bio - inspired dynamic 3d discriminative skeletal features for human action recognition , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition workshops _ , 2013 , pp .",
    "471478 .",
    "m.  devanne , h.  wannous , s.  berretti , p.  pala , m.  daoudi , and a.  del  bimbo , `` 3-d human action recognition by shape analysis of motion trajectories on riemannian manifold , '' _ ieee transactions on cybernetics _ ,",
    "45 , no .  7 , pp . 13401352 , 2015 .",
    "r.  vemulapalli , f.  arrate , and r.  chellappa , `` r3dg features : relative 3d geometry - based skeletal representations for human action recognition , '' _ computer vision and image understanding _ , vol .",
    "155  166 , 2016 .",
    "v.  bloom , d.  makris , and v.  argyriou , `` g3d : a gaming action dataset and real time action recognition evaluation framework , '' in _ proc . ieee computer society conference on computer vision and pattern recognition workshops ( cvprw ) _ , 2012 , pp .",
    "c.  chen , r.  jafari , and n.  kehtarnavaz , `` utd - mhad : a multimodal dataset for human action recognition utilizing a depth camera and a wearable inertial sensor , '' in _ image processing ( icip ) , 2015 ieee international conference on _ , 2015 , pp .",
    "168172 .",
    "y.  hou , z.  li , p.  wang , and w.  li , `` skeleton optical spectra based action recognition using convolutional neural networks , '' _ ieee transactions on circuits and systems for video technology _ , pp . 15 , 2016 .",
    "c.  ellis , s.  z. masood , m.  f. tappen , j.  j. laviola  jr , and r.  sukthankar , `` exploring the trade - off between accuracy and observational latency in action recognition , '' _ international journal of computer vision _ , vol .",
    "101 , no .  3 , pp .",
    "420436 , 2013 .",
    "d.  wu and l.  shao ,",
    "`` leveraging hierarchical parametric networks for skeletal joints based action segmentation and recognition , '' in _ proceedings of the ieee conference on computer vision and pattern recognition _ , 2014 ,",
    ". 724731 .",
    "f.  ofli , r.  chaudhry , g.  kurillo , r.  vidal , and r.  bajcsy , `` sequence of the most informative joints ( smij ) : a new representation for human skeletal action recognition , '' _ journal of visual communication and image representation _ , vol .  25 , no .  1 ,",
    "pp . 2438 , 2014 .",
    "i.  lillo , a.  soto , and j.  carlos  niebles , `` discriminative hierarchical modeling of spatio - temporally composable human activities , '' in _ proceedings of the ieee conference on computer vision and pattern recognition _",
    ", 2014 , pp . 812819 .",
    "a.  shahroudy , t.  t. ng , q.  yang , and g.  wang , `` multimodal multipart learning for action recognition in depth videos , '' _ ieee transactions on pattern analysis and machine intelligence _ , vol .",
    "38 , no .",
    "10 , pp . 21232129 , 2016 .",
    "a.  m. lehrmann , p.  v. gehler , and s.  nowozin , `` efficient nonlinear markov models for human motion , '' in _ proceedings of the ieee conference on computer vision and pattern recognition _ , 2014 , pp .",
    "13141321 .          s.",
    "ji , w.  xu , m.  yang , and k.  yu , `` 3d convolutional neural networks for human action recognition , '' _ pattern analysis and machine intelligence , ieee transactions on _ , vol .  35 , no .  1 ,",
    "pp . 221231 , 2013 .",
    "j.  donahue , l.  anne  hendricks , s.  guadarrama , m.  rohrbach , s.  venugopalan , k.  saenko , and t.  darrell , `` long - term recurrent convolutional networks for visual recognition and description , '' in _ cvpr _ , 2015 , pp . 26252634 .",
    "p.  wang , w.  li , z.  gao , j.  zhang , c.  tang , and p.  ogunbona , `` action recognition from depth maps using deep convolutional neural networks , '' _ human - machine systems , ieee transactions on _ , vol .",
    "46 , no .  4 , pp .",
    "498509 , 2016 .",
    "a.  krizhevsky , i.  sutskever , and g.  e. hinton , `` imagenet classification with deep convolutional neural networks , '' in _ proc .",
    "annual conference on neural information processing systems ( nips ) _ , 2012 , pp .",
    "11061114 .",
    "s.  yang , c.  yuan , w.  hu , and x.  ding , `` a hierarchical model based on latent dirichlet allocation for action recognition , '' in _ pattern recognition ( icpr ) , 2014 22nd international conference on_.1em plus 0.5em minus 0.4emieee , 2014 , pp .",
    "26132618 .",
    "l.  zhou , w.  li , y.  zhang , p.  ogunbona , d.  t. nguyen , and h.  zhang , `` discriminative key pose extraction using extended lc - ksvd for action recognition , '' in _ proc . international conference on digital image computing : techniques and applications ( dicta)_.1em plus 0.5em minus 0.4emieee , 2014 , pp .",
    "18 .",
    "( s14 ) received the be degree in network engineering from nanchang university , nanchang , china , in 2010 , and received the ms degree in communication and information system from tianjin university , tianjin , china , in 2013 .",
    "he is currently pursuing the phd degree with the school of computing and information technology , university of wollongong , australia .",
    "his current research interests include computer vision and machine learning .",
    "wanqing li received his phd in electronic engineering from the university of western australia .",
    "he is an associate professor and co - director of advanced multimedia research lab ( amrl ) of university of wollongong , australia .",
    "his research areas are 3d computer vision , 3d multimedia signal processing and medical image analysis .",
    "li is a senior member of ieee .",
    "received the be degree in electronic information engineering from north university of china , taiyuan , china , in 2012 and received the ms degree in communication and information system from north university of china , taiyuan , china , in 2015 .",
    "he is currently pursuing the ph.d degree with school of electronic information engineering , tianjin university , china .",
    "his current research interests include computer vision and machine learning .",
    "( m11 ) received the b.eng .",
    "degree in electronic engineering from xidian university , xian , china , in 1991 , and the m.eng . and",
    "ph.d degrees both in communication and information system from tianjin university , tianjin , china , in 2003 and 2009 , respectively .",
    "since 2006 , he has been an associate professor of school of electronic and information engineering , tianjin university .",
    "his research interests include computer vision , artificial intelligence and multimedia signal processing"
  ],
  "abstract_text": [
    "<S> convolutional neural networks ( convnets ) have recently shown promising performance in many computer vision tasks , especially image - based recognition . </S>",
    "<S> how to effectively apply convnets to sequence - based data is still an open problem . </S>",
    "<S> this paper proposes an effective yet simple method to represent spatio - temporal information carried in @xmath0 skeleton sequences into three @xmath1 images by encoding the joint trajectories and their dynamics into color distribution in the images , referred to as joint trajectory maps ( jtm ) , and adopts convnets to learn the discriminative features for human action recognition . </S>",
    "<S> such an image - based representation enables us to fine - tune existing convnets models for the classification of skeleton sequences without training the networks afresh . </S>",
    "<S> the three jtms are generated in three orthogonal planes and provide complimentary information to each other . </S>",
    "<S> the final recognition is further improved through multiply score fusion of the three jtms . </S>",
    "<S> the proposed method was evaluated on four public benchmark datasets , the large ntu rgb+d dataset , msrc-12 kinect gesture dataset ( msrc-12 ) , g3d dataset and utd multimodal human action dataset ( utd - mhad ) and achieved the state - of - the - art results .    </S>",
    "<S> shell : action recognition based on joint trajectory maps with convolutional neural networks    action recognition , trajectory , color encoding , convolutional neural network . </S>"
  ]
}