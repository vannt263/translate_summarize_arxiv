{
  "article_text": [
    "modelling the transport and dispersion of atmospheric pollutants is important in applied meteorological research , air - quality modelling for regulatory bodies and emergency - response applications .",
    "numerical models have been used successfully to simulate the spread of radiactive clouds after the fukushima nuclear accident in 2011 @xcite , and for evaluating the impact of volcanic ash on aviation following the 2010 and 2011 eruptions of the eyjafjallajkull and grmsvtn volcanoes on iceland @xcite .",
    "the name atmospheric dispersion model @xcite , originally designed to predict the spread of radiactive plumes after the chernobyl disaster @xcite , is a highly versatile numerical model developed and used by the uk met office in a wide range of applications , see e.g. @xcite .",
    "providing fast - yet - accurate and reliable predictions is crucial , in particular in emergency - response situations , where model outputs have to be passed on to decision makers in a timely fashion . at the heart of name , a stochastic differential equation ( sde )",
    "describes the evolution of the distributions of position and velocity of the transported particles in the plume .",
    "this sde is solved with a monte carlo method , which simulates the propagation of a large number of model particles in a turbulent velocity field .",
    "an efficient monte carlo algorithm and fast timestepping methods for integrating the trajectories of the individual particles are crucial for fast and precise forecasts . to assess the performance of a model",
    ", it is desirable to minimise the total computational cost for a given level of accuracy ( measured by the root - mean - square error ) in the prediction of a particular quantity of interest , such as the mean particle position or the concentration field at a given time .",
    "recently , the multilevel monte carlo ( mlmc ) method @xcite ( see @xcite for a comprehensive review ) has been used successfully in a wide range of applications from mathematical finance @xcite to uncertainty quantification in subsurface flow @xcite .",
    "let @xmath0 denote the upper bound ( or tolerance ) on the root - mean - square error of the numerical method .",
    "this error consists of a deterministic discretisation error ( bias ) and a statistical error due to the limited number of model particles . to reduce both error components",
    ", the standard monte carlo ( stmc ) method usually requires an asymptotic cost @xmath1 since @xmath2 model particles are propagated over @xmath3 timesteps . for a first - order method ,",
    "the number of timesteps ( for a given simulation duration ) is @xmath4 and the central limit theorem implies @xmath5 , since the statistical error decreases @xmath6 . in total",
    ", this results in an asymptotic cost @xmath7 .",
    "in contrast , the mlmc algorithm can achieve significantly better scaling @xmath8 by introducing a hierarchy of additional , coarser levels with @xmath9 timesteps . on each pair of subsequent levels , paths with two different timestep sizes but the same random noise",
    "are used to calculate the same approximation to a particular idealised trajectory . by summing up the contributions on all levels with a telescoping sum , the expected value on the original finest level with @xmath3 timesteps is recovered .",
    "this reduces the overall cost for two reasons .",
    "firstly , the cost of one path calculation on a coarser level is proportional to the ( smaller ) number of timesteps on this level .",
    "in addition , only differences between subsequent levels are computed .",
    "those differences have a much smaller variance and can be evaluated with a smaller number of samples . the overall reduction in computational cost",
    "is quantified in more detail in the complexity theorem from @xcite , which is reviewed later in this paper .",
    "the absolute runtime also depends on the constants @xmath10 and @xmath11 , which are very sensitive to the numerical timestepping method .",
    "this has recently been demonstrated for a set of simpler model problems in @xcite .",
    "the relative size of those constants is particularly important for relatively loose tolerances , which are typical in operational atmospheric dispersion applications .",
    "building on @xcite , the aim of this work is to investigate the performance enhancements that can be achieved with mlmc and improved timestepping algorithms in atmospheric modelling .",
    "this is a challenging problem for several reasons : firstly , the sde is nonlinear and the coefficients vary strongly or even diverge in parts of the domain .",
    "when simulating vertical dispersion in a neutrally stable atmospheric boundary layer , the `` profiles '' for the turbulent velocity fluctuations @xmath12 and velocity decorrelation time @xmath13 have singularities near the ground and at the top of the domain and need to be regularised appropriately .",
    "in addition , suitable boundary conditions have to be applied to ensure that the model particles do not leave the atmospheric boundary layer .",
    "finally , commonly used quantities of interest ( in particular the particle concentration ) are expressed as the expected value of a function which is not lipschitz continuous and needs to be approximated correctly .",
    "all those issues are addressed in this paper .    while reflective boundary conditions for a one - dimensional diffusion process of the form @xmath14 have previously been treated by adding a non - decreasing  reflection \" function ( local time ) to the particle position ( see e.g.  @xcite ) ,",
    "this method can not be directly applied to the system of two coupled sdes for velocity and position that we study here .",
    "instead , we use an approach similar to the _ impact law _ described for piecewise - smooth dynamical systems in @xcite .",
    "more specifically , to treat reflective boundary conditions for sdes , we follow the work in @xcite , who give an algorithm for elastic reflection at the top and bottom of the domain for a one - dimensional ( vertical ) dispersion model .",
    "the physical justification and implementation of various boundary conditions for atmospheric dispersion models is further discussed in ( * ? ? ?",
    "11 ) and the references given there .",
    "care has to be taken when using reflective boundary conditions in a mlmc context since trajectories of particles on subsequent levels might diverge . to ensure the strong convergence of paths on subsequent levels",
    ", we consider an equivalent problem without boundary conditions , which can be obtained by periodically extending the domain .",
    "this new approach only requires the inclusion of factors of @xmath15 in the coupling between random numbers on the coarse and fine levels .    to predict particle concentrations , we replace the expected value of the indicator function by a suitable smoothing polynomial , matching the first @xmath16 moments of the indicator function . as discussed in @xcite , any additional errors introduced by this process",
    "can be systematically controlled and we confirm numerically that they are of the same size as the bias and statistical error from the monte carlo method .    several advanced timestepping methods for sdes have been discussed in the literature ( see e.g. @xcite ) . as a reference method , we use the simple symplectic euler integrator , which is implemented in many operational atmospheric dispersion models .",
    "this integrator is very similar to the well - known euler ",
    "maruyama method @xcite and has the same restrictions on the maximal timestep size , which become more severe at the bottom of the boundary layer due to the small velocity decorrelation time . to avoid those stability issues",
    ", we also investigate the performance of an improved timestepping method based on geometric langevin methods @xcite .",
    "this method had previously been applied in the context of mlmc methods for simpler , linear model problems in @xcite .",
    "similar splitting methods for langevin dynamics are also discussed in the context of molecular dynamics in @xcite .",
    "our numerical results confirm that , for tight tolerances , due to its asymptotic scaling with @xmath17 the mlmc algorithm always outperforms a standard monte carlo method .",
    "this difference in performance is particularly pronounced if the particles spend less time close to the ground where the profiles @xmath13 and @xmath12 have large variations . for looser tolerances ,",
    "the standard monte carlo algorithm can be faster than mlmc .",
    "however , it is very sensitive to the timestepping method and using the geometric langevin method can result in speedups of more than one order of magnitude , in particular if particles are released close to the ground .",
    "an alternative way to avoid stability issues due to small velocity decorrelation times at the bottom of the boundary layer is adaptive timestepping .",
    "two adaptive mlmc algorithms are described and analysed in @xcite .",
    "the authors of @xcite either use a sample averaged error to construct a mesh hierarchy , which is used for all realisations , or adapt the timestep size for each path independently , again via an error estimator . in this work ,",
    "we focus on stability issues and therefore employ a simple heuristic based on the local velocity decorrelation time .",
    "the implementation of the adaptive mlmc algorithm that we use is described in @xcite .",
    "we find that adaptive timestepping can further reduce the cost for the symplectic euler integrator .",
    "however , for the geometric langevin method , our numerical experiments seem to suggest that uniform timestepping methods lead to a shorter overall solution time .    to obtain realistic absolute performance numbers , all results in this paper were obtained with a freely available object - oriented c++ code @xcite , which can be downloaded under the gpl license .    [ [ structure ] ] structure +",
    "+ + + + + + + +    this paper is organised as follows : in section [ sec : models ] , we introduce the stochastic model for simulating particle transport and dispersion in the stationary inhomogeneous turbulence in the boundary layer and describe the underlying sde for particle transport and dispersion .",
    "section [ sec : algorithms ] introduces the timestepping methods , in particular the geometric langevin integrator , and contains a review of the mlmc algorithm with particular focus on its computational complexity .",
    "the proper treatment of reflective boundary conditions in the context of mlmc is discussed in section [ sec : boundaryconditions ] and concentration estimates with suitable smoothed indicator functions are analysed in section [ sec : smoothingpolynomials ] . in section [ sec : results ] , we present numerical results for three quantities of interest : the mean particle position , the concentration at a particular location and the probability density function of particle position .",
    "this includes comparisons between the stmc and the mlmc methods so as to identify the most efficient combination .",
    "the impact of the regularisation height on the results and adaptive timestepping methods are discussed in section [ sec : adaptivity ] .",
    "we finally conclude and outline ideas for further work in section [ sec : conclusion ] .",
    "some more technical details are relegated to the appendices , where we analyse our methods based on the theory of modified equations @xcite and present some mathematical derivations related to the approximation of indicator ( box ) functions with smoothing polynomials .",
    "dispersion models predict the spread and transport of atmospheric pollutants in a given velocity field , i.e.   the dispersed material is treated as a passive non - interacting tracer .",
    "usually , this velocity field is obtained from the output of a numerical weather prediction ( nwp ) model .",
    "since the nwp model has a finite grid resolution , the total velocity field @xmath18 can be split into two components .",
    "the evolution of the large - scale flow , which is resolved by the grid , is described by the navier ",
    "stokes equations and simulated as a deterministic velocity field @xmath19 in the dynamical core of the model .",
    "in contrast , unresolved turbulence is described by an additional component @xmath20 , which is not known in detail and whose properties and effects can only be described statistically . in general",
    ", the velocity can be decomposed as    2 u(x , t ) & = v(x , t ) + u(x , t ) , & u(x , t ) = v(x , t )    and angular brackets @xmath21 denote the ensemble average .",
    "for an observable quantity @xmath22 , the ensemble average is defined by @xmath23 where @xmath24 is the @xmath25 realisation of @xmath26 , i.e.  particle transport in one particular realisation of the turbulent velocity component @xmath20 .",
    "lagrangian dispersion models describe the motion of atmospheric tracer particles in turbulent atmospheric flow fields by a stochastic differential equation ( sde ) : each particle follows the mean flow @xmath19 and turbulence is simulated by adding a random velocity component @xmath27 . at equilibrium ,",
    "the lagrangian velocity @xmath27 of particles which pass through point @xmath28 at time @xmath29 agrees in distribution with the turbulent background velocity field @xmath20 . for simplicity , we assume that the background flow field vanishes and will set @xmath30 in the following .    in @xcite , several criteria for the selection of models for simulating particle trajectories in turbulent flows are discussed ( see also @xcite for an overview ) . for simplicity , we assume here that turbulence in each space direction can be treated independently and only consider the vertical component of the turbulent motion in this article ; studying the more general three - dimensional case is the topic of further research . the following one - dimensional model for particle dispersion in a stationary inhomogeneous turbulent flow",
    "is derived in @xcite : @xmath31 \\frac{\\partial \\sigma_u^2(x_t)}{\\partial x}\\,dt +   \\sqrt{\\frac{2\\sigma_u^2(x_t)}{\\tau(x_t)}}\\,dw_t,\\qquad dx_t = u_t\\,dt . \\label{generalised}\\ ] ] here @xmath27 is the lagrangian vertical velocity fluctuation , @xmath32 is the particle s position and @xmath33 is a brownian motion . to complete the description in eq .",
    "( [ generalised ] ) , initial conditions for @xmath27 and @xmath32 at time @xmath34 need to be specified .",
    "for stationary turbulence , @xmath20 and @xmath35 agree in distribution for any two times @xmath29 and @xmath36 .",
    "the velocity variance is @xmath37 where @xmath36 is an arbitrary reference time . using kolmogorov similarity theory @xcite ,",
    "the lagrangian local velocity decorrelation timescale @xmath13 can be expressed in terms of the mean rate of dissipation of turbulent kinetic energy @xmath38 as @xmath39 @xcite .",
    "although for homogeneous turbulence , @xmath13 is identical to the lagrangian velocity autocorrelation time of @xmath27 , this is not true in the more general case of inhomogeneous turbulence considered here .    the term proportional to @xmath40 in eq .",
    "( [ generalised ] ) arises from the `` well - mixed condition '' @xcite , which prevents the unphysical spatial agglomeration of particles in an initially homogeneous concentration field .",
    "the well - mixed condition requires the equilibrium @xmath41-distribution of particles in the model to be the same as the distribution of all air parcels .",
    "mathematically this is equivalent to requiring that the equilibrium distribution or invariant measure @xmath42 is uniform in space and , conditional on @xmath43 , is the same as the distribution of @xmath20 .",
    "the latter is independent of @xmath29 because of our stationarity assumption and is here assumed to be gaussian i.e. @xmath44 .    to simplify notation",
    "we introduce the following abbreviations    3 ( x ) & , & ( x ) & , & & -    so that eq .",
    "( [ generalised ] ) can be written more compactly as @xmath45 to complete this model , suitable vertical profiles for @xmath46 and @xmath47 have to be chosen . for",
    "a neutrally stable surface layer and horizontally homogeneous turbulence , the authors of @xcite derive the expression @xmath48 for the velocity decorrelation time .",
    "if the turbulent eddy size is only constrained by the ground , then a typical eddy size is @xmath49 .",
    "hence , this relationship expresses the fact that on average it takes a time @xmath50 for a particle to decorrelate by going around one eddy . as we will see below",
    ", the fact that the decorrelation timescale @xmath47 vanishes linearly for @xmath51 has important implications on the performance of the model . for the surface layer , the authors of @xcite also suggest @xmath52 where @xmath53 is the friction velocity .",
    "there is considerable uncertainty in the exact form of the profiles further away from the surface . rather than exploring a wide range of different parametrisations",
    ", we concentrate on one representative case , which allows us to quantify the impact of variations in @xmath12 on the algorithms discussed here . in this paper",
    ", we use the form of @xmath12 suggested in @xcite for neutral and stable conditions . in summary",
    ", the following profiles are used to describe the propagation of particles in a boundary layer of depth @xmath54 :    3 _ u(x ) & = _ u _ ( 1 - ) ^ , & ( x ) & = _ , & x , [ eqn : profiles ]    and the constants are set to @xmath55 , @xmath56 , @xmath57 .",
    "those profiles are shown in fig .",
    "[ fig : profiles ] ; as discussed in section [ sec : regularisation ] , @xmath13 ( or @xmath58 ) needs to be regularised near the bottom boundary . since",
    "@xmath12 and @xmath13 are only defined within the boundary layer , suitable boundary conditions that restrict the particles to the interval @xmath59 $ ] need to be enforced .",
    "different boundary conditions for atmospheric dispersion models are discussed in @xcite . here",
    "we assume that when a particle hits the boundary , it is reflected elastically ( see fig .",
    "[ fig : reflection_elastic ] ) .",
    "mathematically this can be formulated as in @xcite .",
    "if at some time @xmath60 a particle hits the lower ( @xmath61 ) or the upper ( @xmath62 ) boundary , we use @xmath63 with initial conditions at @xmath34 , it should be noted that , under the assumption that @xmath47 is bounded from below by a non - zero positive constant and that @xmath46 and @xmath47 are sufficiently smooth , it is possible to show existence and uniqueness of a solution for the inhomogeneous model for all @xmath64 .",
    "the key idea is to find a suitable lyapunov function and then follow the theory developed in @xcite ; including the details of the proof is beyond the scope of this paper .",
    "given eqs .",
    "( [ generalisedsim ] ) and an initial condition , it is now possible to calculate any functional of the path @xmath65 .",
    "any such functional @xmath66 is referred to as a quantity of interest ( qoi ) in the following .",
    "of particular interest in practical applications is the concentration field at a given time , which can be approximated by the probability of @xmath32 lying in one of the boxes of a predetermined grid .",
    "mathematically for a box @xmath67 , this probability can be expressed as the expected value of the indicator function @xmath68 which is @xmath69 for @xmath70 and @xmath71 otherwise .",
    "indeed , such piecewise averaged concentration fields are one of the main outputs of widely used dispersion models such as name .    in this paper , we concentrate on calculating the box - averaged concentration @xmath72 } ( x_t ) \\right]$ ] for some @xmath73 , i.e.  the fraction of particles that land in a specified interval @xmath74 \\subset [ 0,h]$ ] .",
    "as we will show in section [ sec : pdf ] , it is possible to generalise this to calculate the piecewise constant concentration field at the final time by considering a vector of indicator functions . since it is easier to predict , as a second quantity of interest , we will also consider the mean particle position @xmath75 $ ] .      in eq .",
    "( [ generalised ] ) , the profiles @xmath46 and @xmath47 have singularities or vanish at the boundaries @xmath61 and @xmath62 .",
    "consequently , @xmath76 diverges for @xmath77 and @xmath78 for @xmath51 .",
    "the latter restricts the timestep in numerical methods to an infinitely small value .",
    "it turns out that the issue is not merely the large value of @xmath58 , which could be treated by integrating a larger part of the equation exactly .",
    "the function @xmath79 also has an infinitely large gradient near the ground , which leads to more serious stability issues . in order to deal with these singularities ,",
    "the functions @xmath47 and @xmath46 have to be regularised .",
    "for this , we use the same approach as the met office name model by imposing a hard cutoff    2 ( x ) & =    ( _ ) & x < _ , + ( h - _ ) & x > h- _ ,     & _ u(x ) & =    _ u(_)&x < _ , + _ u(h - _ ) & x > h- _ ,    [ eqn : regularisation ]    where @xmath80 is some small regularisation constant .",
    "this is shown for @xmath81 in fig .",
    "[ fig : profiles ] .",
    "we will study the impact of @xmath82 on the results in section [ sec : sensitivity_regularisation ] .",
    "timestepping methods for sdes and especially the langevin equation are described in @xcite . to solve the sde ( [ generalisedsim ] ) numerically ,",
    "we use two explicit timestepping methods that are both of weak order one for smooth problems ( i.e. the bias error for fixed travel time grows linearly with the timestep size ) .",
    "the simulated time interval @xmath83 $ ] is split into @xmath3 intervals of size @xmath84 and , for any @xmath85 , the quantity @xmath86 denotes the numerical approximation of @xmath87 at time @xmath88 .",
    "the first timestepping method is the symplectic euler method given by @xmath89 for each timestep @xmath90 , the random number @xmath91 , independently of all previous timesteps . due to its simplicity",
    "it is very popular in operational models , such as the met office s name code , and it will serve as the benchmark in the following .",
    "it is referred to as `` symplectic '' because , when applied to a hamiltonian system of ordinary differential equations , it inherits a symplectic structure from the hamiltonian system .",
    "the method in ( [ eqn : methodsymplecticeuler ] ) is only stable if @xmath92 , which leads to the constraint @xmath93 on the timestep size . for large values of @xmath79 , which occur close to the lower boundary @xmath51",
    ", the timestep size has to be reduced and this increases the computational cost of the method .",
    "this problem can be mitigated in adaptive timestepping algorithms , which will be discussed in section [ sec : adaptivity ] .",
    "the geometric langevin method @xcite defined by @xmath94 avoids this stability issue .",
    "as above , the random variables @xmath95 i.i.d .",
    "this method was introduced in the context of mlmc in @xcite and referred to as `` symplectic euler / ornstein  uhlenbeck splitting method '' since , for constant @xmath12 and @xmath58 , the @xmath96 equations are solved exactly as the ornstein  uhlenbeck process @xmath97 . the formulation in eq .",
    "( [ eqn : methodsymplecticeulerou ] ) is slightly more general in that the potential function @xmath98 also depends on the velocity @xmath96 .      in a standard monte carlo ( stmc )",
    "simulation , @xmath2 independent trajectories @xmath99 are computed , each associated with a particular i.i.d .",
    "realisation of the gaussian increments @xmath100 , @xmath101 , in or .",
    "a quantity of interest ( qoi ) is evaluated for each trajectory .",
    "possible qois are the final particle position or a variable which is one if the particle falls into a defined interval and zero otherwise .",
    "the expected value of the qoi can then be estimated by averaging the @xmath2 realisations of the qoi . in the first example",
    "the expectation value is the mean particle position ; in the second case it is the fraction of particles which fall into the chosen interval .",
    "we will only consider functionals of the solution @xmath102 at the final time @xmath103 as qois to analyse the cost of the stmc method .",
    "in particular , let @xmath104 .",
    "given integer constants @xmath105 and",
    "@xmath106 , we approximate @xmath107 by @xmath108 where @xmath109 is the numerical approximation of the particle position @xmath32 at the final time @xmath110 , obtained with @xmath111 timesteps of size @xmath112 .",
    "the stmc estimator with @xmath113 samples for @xmath114 $ ] is given by @xmath115 due to the linearity of the expectation , @xmath116=\\mathbb{e}\\left[\\mathcal{p}^{(i)}_l\\right]=\\mathbb{e}\\left[\\mathcal{p}_l\\right]$ ] .",
    "it is also easy to show that the total mean - squared error of the stmc estimator in eq .",
    "( [ eqn : stmcestimator ] ) is given by @xmath117\\right)^2\\right ]   =   \\left(\\mathbb{e}\\left[\\mathcal{p}_l\\right]-\\mathbb{e}\\left[\\mathcal{p}\\right]\\right)^2 + \\frac{1}{n_l}\\text{var}\\left[\\mathcal{p}_l\\right].\\label{eqn : stmcerror}\\ ] ] the first term on the right hand side of eq .",
    "( [ eqn : stmcerror ] ) is the square of the numerical bias and , for the first - order methods described in eqs .",
    "( [ eqn : methodsymplecticeuler ] ) and ( [ eqn : methodsymplecticeulerou ] ) above , this bias grows linearly with the timestep size : @xmath118\\propto h_l\\propto m_l^{-1}$ ] .",
    "the second term is the ( mean square ) statistical error , which is proportional to @xmath119 . to limit the total mean - squared error to @xmath120 ( where @xmath0 is a fixed tolerance ) , it is sufficient to choose @xmath121 and @xmath122 such that each of the two terms on the right hand side of eq .",
    "( [ eqn : stmcerror ] ) is smaller than @xmath123 .",
    "as already discussed in the introduction , this choice leads to @xmath124 and @xmath125 , resulting in a total cost of the stmc method @xmath126 the size of the constant @xmath10 depends on the timestepping method . as we will argue in the following",
    ", the mlmc approach can lead to improved asymptotic scaling with asymptoptic cost proportional to @xmath17 , which is the optimal computational complexity for a monte carlo method .",
    "we generalise the notation from the previous section by considering an arbitrary level @xmath127 with @xmath128 timesteps of size @xmath129 and @xmath130 monte carlo samples . on each level",
    ", we define the random variable @xmath131 where @xmath132 is the approximation of the particle position @xmath102 at time @xmath133 , now calculated with a timestep size @xmath134 .",
    "@xmath135 is the value of this random variable for the @xmath136-the sample .",
    "the key idea for the mlmc approximation @xcite is that @xmath137 $ ] can be written as the following telescoping sum : @xmath138 = \\sum\\limits_{\\ell=1}^l \\mathbb{e}\\left [ \\mathcal{p}_\\ell - \\mathcal{p}_{\\ell-1 } \\right ] + \\mathbb{e}\\left [ \\mathcal{p}_0 \\right ] .",
    "\\label{eqn : telescoping_sum}\\ ] ] the mlmc estimator is then defined by @xmath139 where @xmath140",
    "since the expected value is linear , the mlmc estimator does not introduce any additional bias and @xmath141 = \\sum_{\\ell=1}^l \\mathbb{e}\\left [ \\mathcal{p}_\\ell - \\mathcal{p}_{\\ell-1 } \\right ] + \\mathbb{e}\\left [ \\mathcal{p}_0 \\right ] = \\mathbb{e}\\left [ \\mathcal{p}_l \\right ] = \\mathbb{e}\\left [ \\hat{\\mathcal{p}}^{(\\text{stmc})}_l \\right].\\ ] ] the estimators @xmath142 on two subsequent levels @xmath143 and @xmath144 are independent : even though they are evaluated with the same timestep size , the samples @xmath145 required to calculate @xmath146 and @xmath147 in eq .",
    "( [ eqn : yhatell ] ) are generated with different random numbers .",
    "due to this independence of the estimators @xmath142 the mean - square error of @xmath148 is given by @xmath149\\right)^2\\right ]   =   \\left(\\mathbb{e}\\left[\\mathcal{p}_l\\right]-\\mathbb{e}\\left[\\mathcal{p}\\right]\\right)^2 + \\sum_{\\ell=0}^{l}\\frac{1}{n_\\ell}\\text{var}\\left[y_\\ell\\right],\\label{eqn : mlmcerror}\\ ] ] which should be compared to the corresponding expression for stmc in eq .",
    "( [ eqn : stmcerror ] ) . to calculate @xmath146 on each level @xmath150 and to evaluate the mlmc estimator in eq .",
    "( [ eqn : mlmcestimator ] ) , @xmath151 samples of random numbers @xmath152 , for each timestep @xmath153 are generated .",
    "for the @xmath136th sample , both a path with @xmath154 timesteps and a path with @xmath155 timesteps are calculated for the _ same _ driving brownian motion @xmath33 .",
    "the difference @xmath156 between the qoi on the two paths is averaged according to eq .",
    "( [ eqn : yhatell ] ) . on the coarsest level @xmath157 , the standard mc estimator with @xmath158 samples and @xmath106 timesteps is used .",
    "the two main advantages of the mlmc algorithm are :    * since @xmath159 and hence @xmath160 , paths on the coarse levels require fewer timesteps and are cheaper to evaluate . in the case",
    "we consider here , it can be shown that the computational cost is concentrated on the coarsest level with @xmath161 timesteps , independent of @xmath105 and of the fine level timestep size . * instead of calculating the quantity of interest itself ,",
    "only differences @xmath162 of the qoi between subsequent levels are evaluated .",
    "those differences have a smaller variance than @xmath163 . as can be seen from eq .",
    "( [ eqn : mlmcerror ] ) , this has a direct impact on the total error .    as discussed in detail in @xcite , for a given root - mean - square error @xmath0",
    ", it is now possible to choose the @xmath130 such that the total cost @xmath164 is minimised .",
    "this is quantified in the following simplified version of the complexity theorem proved in @xcite .    with the mlmc setting as above and if there exist estimators @xmath146 and positive constants @xmath165 such that    a.   @xmath166\\right| \\leq c_1 h_\\ell,$ ] b.   @xmath167 = \\left \\ { \\begin{array}{lcc } \\mathbb{e}[\\mathcal{p}_0 ] & & \\text { if } \\quad   \\ell=0,\\\\ \\mathbb{e}[\\mathcal{p}_\\ell-\\mathcal{p}_{\\ell-1 } ] & & \\text { if } \\quad \\ell>0 , \\end{array } \\right .$ ] c.   @xmath168 \\leq c_2 n_\\ell^{-1}h_\\ell^2,$ ] d.   @xmath169 , the computational complexity of @xmath146 , is bounded by @xmath170 ,",
    "then there exists a positive constant @xmath11 such that for all @xmath171 there are values @xmath105 and @xmath172 for which @xmath173 satisfies    @xmath174 \\right)^2 \\right ] < \\epsilon^2,$ ]    with a computational complexity @xmath175 with bound    @xmath176    condition ( ii ) is obviously true with our definition of @xmath146 . conditions ( i ) and ( iv ) are easy to satisfy and they hold for the two timestepping methods considered in the article .",
    "however , the quadratic variance decay in condition ( iii ) requires the correct coupling of paths between subsequent levels .",
    "the random variables @xmath177 in eqs .",
    "( [ eqn : methodsymplecticeuler ] ) and ( [ eqn : methodsymplecticeulerou ] ) that are used for calculating the paths on two coupled levels , have to be chosen correctly . for the symplectic euler method in eq .",
    "( [ eqn : methodsymplecticeuler ] ) , this can be achieved by using a simple brownian bridge , i.e.  combining the random variables @xmath177 and @xmath178 on one level to obtain a random variable @xmath179 on the next coarser level as @xmath180 as shown in @xcite , for the geometric langevin method in eq .",
    "( [ eqn : methodsymplecticeulerou ] ) , this is achieved by using @xmath181 as is common in the mlmc literature , in the numerical section below , we carefully check condition ( iii ) by plotting the variance @xmath182 = n_\\ell \\cdot \\text{var}[\\hat{y}_{\\ell , n_\\ell}]$ ] as a function of the step size @xmath134 .",
    "as described in section [ sec : regularisation ] , we assume that particles are reflected elastically at the top and bottom of the domain . as shown in @xcite ,",
    "this can be accounted for in the timestepping method by simply checking if a particle has left the domain after each timestep , and , if necessary , replacing @xmath183 ( or @xmath184 at the top boundary ) and @xmath185 in accordance with eq .",
    "( [ reflectlower ] ) .",
    "this is shown schematically in fig .",
    "[ fig : reflection_elastic ] .",
    "0.49     0.49    however , since the paths on subsequent levels are coupled in mlmc , care has to be taken to prevent the fine and coarse paths from diverging , which would result in violation of condition ( iii ) in the complexity theorem .",
    "this can be achieved by modifying eqs .",
    "( [ eulercoupled ] ) and ( [ symeulercoupled ] ) appropriately .",
    "the key idea is illustrated by the following thought experiment , which we first explain for one reflective boundary ( in section [ sec : top_reflection ] we show that the same treatment works for both boundaries by considering periodic extensions ) : imagine extending the domain of @xmath186 to the whole real line and making it equivalent to the problem without boundary conditions .",
    "for this , an extended sde in the variables @xmath187 and @xmath188 is formulated , which is related to the initial one by @xmath189 where @xmath190 and @xmath191 is the number of reflections up to time @xmath29 .",
    "let @xmath192 and @xmath193 be some functions which are defined for positions @xmath194 and any velocity @xmath96 . for the sde    2 du_t & = a(x_t , u_t)dt + b(x_t ) dw_t , & dx_t & = u_t dt , [ eqn : problem_nonextended ]    with reflection at @xmath61 , the equivalent extended sde is    2 d_t & = a(_t,_t)dt + b(_t ) dw_t , & d_t & = _ t dt .",
    "[ eqn : problem_extended ]    the functions @xmath26 and @xmath67 in eq .",
    "( [ eqn : problem_extended ] ) are related to @xmath195 and @xmath196 in eq .",
    "( [ eqn : problem_nonextended ] ) by    2 a(_t,_t ) & =    a(_t,_t ) & _ t 0 , + - a(- _ t,- _ t ) & _ t < 0 ,     & b(_t ) & =    b(_t ) & _ t 0 , + b(- _ t ) & _ t < 0 .    [ eqn : drift_diffusion ]    in fig .",
    "[ fig : reflection_schematic ] , both the solution @xmath197 of the extended sde ( [ eqn : problem_extended ] ) and the solution @xmath32 of the original sde ( [ eqn : problem_nonextended ] ) are plotted .",
    "the solutions are related by eq .",
    "( [ eqn : reflection ] ) .",
    "one possible approach would now be to use the extended sde ( [ eqn : problem_extended ] ) , which does not have any boundary conditions , and then reconstruct the variables @xmath27 , @xmath32 by eq .",
    "( [ eqn : reflection ] ) .",
    "however , it turns out that this is not necessary , and we can instead use the original set of equations if we carefully adapt the way the random variables are coupled in the mlmc algorithm .      to achieve this , we derive some relations between the extended and the original variables and the sdes in eqs .",
    "( [ eqn : problem_nonextended ] ) and ( [ eqn : problem_extended ] ) . discretising eq .",
    "( [ eqn : reflection ] ) gives @xmath198 where @xmath199 . by using this relation in eq .",
    "( [ eqn : drift_diffusion ] ) , we obtain    2 a(_n,_n ) & = s_n a(s_n _ n , s_n _ n ) = s_n a(x_n , u_n ) , & b(_n ) & = b ( s_n _",
    "n ) = b ( x_n ) .",
    "now consider the fine path on a mlmc level with timestep size @xmath200 .",
    "discretising the extended model in eq .",
    "( [ eqn : problem_extended ] ) with the symplectic euler method gives    2 _ n + 1 & = _",
    "n + a(_n,_n ) h + b(_n ) _ n , & _ n + 1 & = _",
    "n + 1 h ,    where @xmath201 i.i.d . replacing @xmath202 by @xmath203 according to eq .  ( [ eqn : xnun ] )",
    "results in an equation for the original variables",
    "@xmath204 and @xmath205 @xmath206 to distinguish fine and coarse levels , we use the superscripts `` @xmath207 '' and `` @xmath208 '' on the reflection factors . multiplying both sides by @xmath209 and defining @xmath210 ,",
    "the timestepping scheme can be expressed as @xmath211 the same equation can be written down on the next coarser level , where we replace @xmath212 , @xmath213 etc .",
    "note that @xmath214 equals @xmath215 if there is a reflection at time @xmath216 or @xmath69 otherwise . hence the factors @xmath214 in eq .",
    "( [ eqn : reflected_equation ] ) take care of the elastic reflection described above : if @xmath217 , velocity and position @xmath218 get replaced by @xmath219 .",
    "in addition , the random forcing term proportional to @xmath220 contains an additional factor @xmath221 .",
    "this could be taken into account by sampling @xmath222 and multiplying each sample by the correct factor @xmath221 as in eq .",
    "( [ eqn : reflected_equation ] ) .",
    "however , since the normal distribution is symmetric and @xmath223 , on each individual level , the same result is obtained by directly using a random variable @xmath224 and replacing @xmath225 to obtain @xmath226 formally the random variables @xmath177 and @xmath227 are related by @xmath228 and agree in distribution since @xmath223 . to couple the fine and coarse path correctly ,",
    "it is necessary to require that the random variable @xmath229 on the _ coarse _ paths fulfils the conditions in eqs .",
    "( [ eulercoupled ] ) and ( [ symeulercoupled ] ) . for the euler scheme",
    ", this means that @xmath230 using eq .",
    "( [ eqn : coupled_samples ] ) and the corresponding relation @xmath231 , this implies that reflection can be taken into account by replacing eq .",
    "( [ eulercoupled ] ) by @xmath232 a similar argument shows that for the geometric langevin method ( [ symeulercoupled ] ) needs to be replaced by @xmath233 since this treatment of the reflective boundary conditions does not change the distribution of the normal random variables used in the coarse step , no extra bias is added and the telescoping sum ( [ eqn : telescoping_sum ] ) is preserved .      to treat elastic reflection at both the top and bottom boundary",
    ", periodic extensions of the domain can be used . for @xmath234 ,",
    "let @xmath235 if @xmath236 , @xmath237 and @xmath238 be a function that maps @xmath186 to @xmath239 .",
    "similarly to eq .",
    "( [ eqn : drift_diffusion ] ) , the extended coefficients can be defined as    2 a(_t,_t ) & =    a((_t),_t ) & ( _ t ) 0 , + - a(- ( _ t),- _ t ) & ( _ t ) < 0 ,     & b(_t ) & =    b((_t ) ) & ( _ t ) 0 , + b(- ( _ t ) ) & ( _ t ) < 0 .",
    "it is easy to verify that the function @xmath240 reduces the problem to the case of reflecting only at @xmath61 and the same analysis as in section [ sec : reflection_analysis ] applies .",
    "therefore , no further changes are required in eqs .",
    "( [ eqn : euler_coupled_treatment ] ) and ( [ eqn : splitting_coupled_treatment ] ) and @xmath241 counts reflections at both boundaries .    fig .",
    "[ sympleulerouboundspetreat ] shows the variance @xmath168 $ ] of the difference process as a function of the timestep size . as can be seen from this plot , the quadratic decay required for condition ( iii ) in the complexity theorem",
    "is recovered . in the same figure",
    ", we also show the variance decay with naive ( and incorrect ) coupling of the paths at the reflective boundaries , i.e.  when setting @xmath242 . due to the symmetry properties of the gaussian increments",
    ", this still leads to the same unbiased estimators on each level , satisfying assumptions ( i ) , ( ii ) and ( iv ) , but the variance of the difference decays with a rate that is not even linear and violates condition ( iii ) .    formally the discontinuity in the function @xmath243 in the extended model might cause problems since the drift function is not continuous at @xmath61 . this problem could be fixed by using a smooth regularisation in section [ sec : regularisation ] , which would ensure that higher derivatives of @xmath46 and @xmath47 vanish at @xmath244 . however , as fig .",
    "[ sympleulerouboundspetreat ] demonstrates , it can be confirmed numerically that the method works for the model considered here even with the sharp regularisation in eq .",
    "( [ eqn : regularisation ] ) .",
    "[ conc_sub_sec ] the concentration of particles which land in an interval @xmath74\\subset [ 0,h]$ ] can be expressed as the expected value of the indicator function defined in section  [ sec : models ] , i.e.  @xmath72 } ( x_t ) \\right]$ ] . however , since the indicator function is not continuous , this leads to problems in the mlmc method : it manifests itself in the fact that the variance on subsequent levels only decays linearly with the step size and condition ( iii ) in the complexity theorem is violated ( this is consistent with the fact that the modified - equation analysis in @xcite , which is used to prove the complexity theorem there , also assumes that the quantity of interest is lipschitz continuous ) . the numerical results below ( figs .",
    "[ varianceratessymplecticeuler01 ] and [ varianceratessymplecticeulerou01 ] ) confirm that this is indeed the case .",
    "as we will demonstrate now , this issue can be fixed by approximating the indicator function by a suitable smooth function ; any errors introduced by this approximation can be quantified and minimised systematically .      in order to recover the quadratic variance decay rates and satisfy condition ( iii ) , we construct a smooth function that approximates the indicator function as described in @xcite . by linearity , it is possible to write @xmath245 } ( x_t ) \\right ] = \\mathbb{e } \\left [ \\theta(x_t - b ) \\right ] - \\mathbb{e } \\left [ \\theta(x_t - a ) \\right ] \\qquad \\text{with}\\quad \\theta(x ) = \\begin{cases}1 & \\text{for}\\quad x\\le0,\\\\0&\\text{otherwise}.\\end{cases } \\label{conc}\\ ] ] in @xcite , to approximate the step function @xmath246 the authors define",
    "@xmath247 here , @xmath248 is a polynomial of degree at most @xmath249 such that @xmath250 , @xmath251 and the first @xmath16 moments of @xmath248 over the interval @xmath252 $ ] agree with the moments of the step function @xmath246 on the same interval .",
    "this is guaranteed if @xmath253 we assume that @xmath16 is chosen such that the density @xmath254 of the particles at the final time is @xmath16 times continuously differentiable on @xmath255 $ ] for some @xmath256 and @xmath257 with @xmath258 \\subset [ s_0,s_1].$ ]    with @xmath259 as defined in eq .",
    "( [ eqn : gr ] ) , it can be shown that @xmath260 } \\left| \\mathbb{e } \\left [ \\theta(x_t - s ) \\right ] - \\mathbb{e } \\left [ g_r \\left ( \\frac{x_t - s}{\\delta } \\right ) \\right ] \\right| \\leq c\\cdot \\delta^{r + 1},\\ ] ] for some constant @xmath261 and all @xmath262 $ ] @xcite . by choosing @xmath263 and @xmath16 appropriately , it is possible to approximate any qoi based on the indicator function to arbitrary accuracy .",
    "more specifically , @xmath264 } ( x_t)=\\theta(x_t - b)-\\theta(x_t - a)$ ] is approximated by @xmath265}(x_t ) \\equiv",
    "g_r \\left ( \\frac{x_t - b}{\\delta } \\right )   - g_r \\left ( \\frac{x_t - a}{\\delta } \\right ) .",
    "\\label{eqn : smoothedindicator}\\ ] ] this function is plotted for @xmath266 and @xmath267 and different polynomial degrees @xmath16 in figs .",
    "[ fig:0.1 ] and [ 0.02 ] .",
    "since ( in contrast to the indicator function ) @xmath268}$ ] is lipschitz continuous , we expect to recover quadratic variance decay rates in mlmc .",
    "this is confirmed numerically in section [ sec : smoothing_sensitivity ] .",
    ".5    .5      to quantify the error introduced by the smoothing process described in the previous section , we analyse the weak and strong errors of the problem with the smoothed indicator function . for ease of notation , we write @xmath269}(x)$ ] and @xmath270}(x)$ ] and denote by @xmath271 and @xmath272 the monte carlo estimates of @xmath273 $ ] and @xmath274 $ ] , which can be obtained either using stmc or mlmc estimators with stepsize @xmath275 . after some straightforward algebra ( see [ weakapp ] ) we obtain a bound on the bias ( or weak ) error @xmath276 - \\mathbb{e}[\\hat{p}^{r,\\delta}_l ] \\right| \\leq 2 c\\cdot \\delta^{r + 1 } + \\left| \\mathbb{e}[p^{r,\\delta } ] - \\mathbb{e}[p^{r,\\delta}_l ] \\right| .",
    "\\label{weak}\\ ] ] in this equation , the second term describes the bias error introduced by the timestepping method .",
    "it is @xmath277 for the first - order methods used in this work .",
    "the total mean - square error is @xmath278 \\right)^2 \\right ] & \\leq \\text{var } ( \\hat{p}^{r,\\delta}_l ) + \\left ( \\mathbb{e}[p^{r,\\delta}_l ] -\\mathbb{e}[p^{r,\\delta } ] \\right)^2 + 4 c^2 \\cdot\\delta^{2(r + 1)}\\\\&\\qquad+ 4 c\\cdot \\delta^{r + 1 } \\left| \\mathbb{e}[p^{r,\\delta}_l ] -\\mathbb{e}[p^{r,\\delta } ] \\right| , \\end{split}\\label{strong}\\end{gathered}\\ ] ] where @xmath279 and @xmath16 are as described before and the quantity @xmath280 -\\mathbb{e}[p^{r,\\delta}]\\big|\\propto h_l$ ] is the timestepping error .    from the strong - error bound",
    ", it can be observed that it suffices to let @xmath281 or @xmath282 to ensure that the last two terms are dominated by the first two terms which represent the sampling error and the discretisation error as in the case of the indicator function without smoothing .",
    "therefore , it is possible to systematically eliminate the smoothing error for practical calculations by choosing suitable @xmath16 and @xmath263 .",
    "however , care has to be taken since the variance of @xmath283 increases as the approximation to the indicator function improves .",
    "this can be observed numerically , for @xmath282 , in fig .",
    "[ varianceratessymplecticeulerou01 ] .",
    "the behaviour of @xmath182 $ ] for @xmath281 is similar .",
    "we now describe several numerical experiments to systematically quantify errors and to compare the efficiencies of the single and multilevel estimators with both timestepping methods .",
    "results for three quantities of interest are presented : the particle position @xmath102 at the final time @xmath103 , the concentration in an interval @xmath74 $ ] and a piecewise constant approximation of the concentration field over the entire boundary layer .",
    "the latter is of particular interest in practical applications . in all cases ,",
    "we first check the quadratic variance decay required in condition ( iii ) of the complexity theorem and then calculate the total computational cost as a function of the tolerance @xmath0 for the root - mean - square error .",
    "the number of timesteps @xmath106 for the coarsest level is chosen in advance ( according to stability constraints ) , while the number of levels @xmath105 is chosen so that the bias error is of size @xmath284 ( see @xcite for details ) . to limit the total mean square error to @xmath120 , the second term in ( [ eqn : mlmcerror ] )",
    "is also reduced below @xmath123 by adaptively choosing the number of samples @xmath130 using on - the - fly estimators for @xmath182 $ ] , see eqn .",
    "( 21 ) in @xcite .",
    "all results were generated with a freely available object - oriented c++ code developed by the authors that can be downloaded under the gpl license from https://bitbucket.org/em459/mlmclangevin .",
    "the numerical results reported here were obtained with the version which has been archived as @xcite .",
    "the code was compiled with version  4.8.4 of the gnu c++ compiler and run sequentially on an intel i5 - 4460 cpu with a clock speed of 3.20ghz .    in the numerical experiments , we use @xmath285 and a boundary - layer depth of @xmath286 in eq .",
    "( [ eqn : profiles ] ) .",
    "all times , positions and velocities are expressed in units of the reference distance @xmath287 , reference velocity @xmath288 and reference time @xmath289  minutes .",
    "particles are released at @xmath290 ( corresponding to a height of @xmath291 above ground ) with a velocity of @xmath292 ( i.e. , an upward release speed of @xmath293 ) , but we also study the impact of the release height on performance in section [ sec : pdf ] . some sample trajectories for this set - up are shown in fig .",
    "[ fig : trajectories ] .",
    "$ ] and the interval @xmath74 $ ] used for the concentration calculation are shown on the right . ]",
    "unless explicitly stated otherwise , the regularisation height is @xmath294 . in this case , @xmath47 does not exceed a value of @xmath295 , which is consistent with the choice in the met office name model .",
    "the impact of @xmath82 on the results is quantified in section [ sec : sensitivity_regularisation ] .      since it is not affected by the additional complications due to smoothing of the indicator function , we first consider the expected value of the particle position at the final time , @xmath296 $ ] . for both numerical methods , we use @xmath297 timesteps on the coarsest level and a final time @xmath298 ( corresponding to about @xmath299 minutes ) .",
    "the validity of condition ( iii ) in the complexity theorem is confirmed numerically in fig .",
    "[ varianceratesposition ] where we plot the variance of @xmath300 for decreasing timestep size @xmath134 . for both numerical methods ,",
    "the rate is quadratic , @xmath182\\propto h_\\ell^2 $ ] .",
    "we observe that the symplectic euler ( se ) method has a smaller variance than the geometric langevin method ( gl ) except for the largest timestep sizes .",
    "however , we also find that for a fixed value of @xmath134 , the bias error for the gl method is around @xmath301 smaller than for the se algorithm .    in fig .",
    "[ costratesposition ] , the total computational costs of the stmc and mlmc estimators for both discretisation methods are plotted as functions of the root - mean - square error tolerance @xmath0 .",
    "the stmc method shows an asymptotic scaling proportional to @xmath302 for both discretisation schemes , as discussed in section [ sec : stmccostanalysis ] .",
    "the cost of the mlmc method is proportional to @xmath17 in both cases , as predicted by the complexity theorem in section [ sec : mlmccostanalysis ] .",
    "however , for a fixed @xmath0 the balance between bias and statistical error is different for the two discretisation methods : for fixed @xmath134 , the gl method has a smaller bias but larger variance error , so that , for a given @xmath0 , the se method will require a smaller timestep . for the se method ,",
    "the maximal allowed timestep size is restricted by stability constraints , whereas for the gl algorithm there are no such restrictions .    comparing only the mlmc results among themselves ,",
    "both discretisation schemes perform similarly with only small differences . for the stmc algorithm ,",
    "on the other hand , the gl method is clearly superior to the se method by almost an order of magnitude across the range of tolerances @xmath0 considered . we conclude that while for larger tolerances ( @xmath303 ) the stmc method with gl timestepping is the most efficient , for small tolerances mlmc ( with either discretisation scheme ) leads to significant speed - ups .",
    ".5    .5      to estimate the concentration in a given interval @xmath74\\subset [ 0,1]$ ] , we calculate the expected value of the indicator function at the final time , i.e. @xmath304}(x_t)\\right]$ ] .",
    "the following results were obtained with an interval of width @xmath305 centred at @xmath306 ( i.e.  @xmath307 and @xmath308 ; see fig .  [",
    "fig : trajectories ] ) .",
    "the centre of the interval roughly matches the expected value of @xmath102 calculated in the previous section , @xmath75=0.1301\\pm 4\\cdot10^{-4}$ ] .",
    ".5    .5    as discussed in section [ sec : smoothingpolynomials ] , to estimate concentrations with the mlmc algorithm it is useful to replace the discontinuous indicator function @xmath264}$ ] by the smooth function @xmath268}$ ] defined in eq .",
    "( [ eqn : smoothedindicator ] ) . in the following ,",
    "we numerically quantify the errors introduced by this approximation and confirm the results from the theoretical analysis in section [ eqn : indicatorerroranalysis ] . to verify condition ( iii ) in the complexity theorem and show that smoothing indeed leads to the correct variance decay , we plot in figs .",
    "[ varianceratessymplecticeulerou01 ] and [ varianceratessymplecticeuler01 ] the variances of @xmath309 , for both timestepping methods , as functions of the timestep size @xmath134 .",
    "the quantities of interest are @xmath268}(x_t)$ ] with @xmath310 , for three different values of @xmath16 , as well as the indicator function @xmath264}$ ] .",
    "these are the functions plotted in fig .",
    "[ fig:0.1 ] . for both plots the tolerance on the root - mean - square",
    "is fixed to @xmath311 .",
    "we observe quadratic dependence @xmath182\\propto h_\\ell^2 $ ] for the smoothed qois , while for the non - smooth indicator function the variance depends linearly on @xmath134 .",
    "for the gl method , the rates seem to be even superquadratic for larger timestep sizes .",
    "the absolute value of the variance grows as @xmath16 increases and this is intuitively expected since for larger @xmath16 the function @xmath312}^{r,\\delta}$ ] approximates the non - smooth indicator function better .    to show that the error introduced by replacing the indicator function by a smooth approximation is indeed small",
    ", we tabulate estimates of the expected values of the indicator function and of @xmath268}$ ] , for different values of @xmath16 , in tab .  [",
    "tab : comparison_to_indicatorfunction ] .",
    "as can be seen from the last two columns of this table , the difference is less than @xmath313 in all cases .",
    "note that we are only requiring the root mean square error of the estimator @xmath314}$ ] to be less than @xmath311 .",
    "a particular instance of the estimator may therefore have a larger error , so that we can conclude that the smoothing error is negligible for the choices of @xmath263 and @xmath16 in tab .  [",
    "tab : comparison_to_indicatorfunction ] .",
    ".estimates of the expected values for the indicator function and the smoothed function @xmath315 for different polynomial degrees @xmath16 ; in all cases @xmath310 and @xmath316 .",
    "the last two columns show the difference @xmath317}(x_t)\\right]-\\mathbb{e}\\left[\\mathbbm{1}_{[a , b]}(x_t)\\right]\\big|$ ] between the smoothed functional and the indicator function . [ cols= \" < , > , > , > , > , > \" , ]     looking at the stmc algorithm",
    ", we note again that the performance is improved dramatically by using the gl method instead of se .",
    "this improvement is particularly dramatic for small release heights where the gl algorithm is about @xmath318 faster than the se method , which agrees with the speed - ups observed for other quantities of interest in the previous sections .",
    "the difference is less pronounced for higher release heights , but even for @xmath319 gl timestepping reduces the solution time by around @xmath320 .",
    "the reason for this is the reduction in bias error due to better treatment of the large and strongly varying profile @xmath79 by the gl method which enables us to use a larger timestep .    for the mlmc algorithm",
    ", the performance depends less on the timestepping method , with the se giving slightly better results .",
    "similar to the stmc algorithm , the total runtime is reduced as the release height increases .",
    "the relative performance gains of mlmc over stmc also depend on @xmath321 .",
    "while for the lowest release height , the mlmc - se method is only @xmath322 faster than stmc - gl , the speed - up is @xmath323 for @xmath319 .    in summary ,",
    "compared to the reference stmc - se algorithm used in many lagrangian atmospheric dispersion models , both the new gl timestepping method and the mlmc algorithm reduce the runtime significantly when computing concentration fields .",
    "since the velocity decorrelation time @xmath47 varies strongly over the boundary layer and limits the timestep size near the ground , we also investigate potential improvements from adaptive timestepping methods . by using small timesteps only in those parts of the domain where @xmath47 is large , those methods can potentially reduce the overall runtime . for stmc adaptive timestepping",
    "is easy to implement and is currently used in the name dispersion model .",
    "adaptive timestepping methods can also be used in the mlmc algorithm .",
    "we briefly review the technique proposed in @xcite and adapt it for the timestepping methods used here .      as the largest possible value of @xmath47 depends on the regularisation height @xmath82 introduced in section [ sec : regularisation ] , we first investigate the impact of this parameter on our results . as before ,",
    "the first thing to check is the quadratic variance decay @xmath182\\propto h_\\ell^2 $ ] required for condition ( iii ) of the complexity theorem . in figs .",
    "[ symeuleroureg ] and [ symeulerreg ] , the variance is shown as a function of timestep size @xmath134 for both timestepping methods as @xmath82 is varied .",
    "in both cases , the quantity of interest is the final particle position @xmath102 and the same set - up as in section [ sec : particleposition ] is used . for gl , the number of timesteps on the coarsest level is @xmath324 and up to @xmath325 levels are used . for se ,",
    "the timestep sizes are limited by stability constraints , i.e.  @xmath326 } \\left\\ { \\lambda(x ) \\right\\ } = c/ \\lambda ( \\epsilon_{\\text{reg}})$ ] for some constant @xmath327 .",
    "this restriction becomes more severe as the size of the regularisation parameter decreases . for @xmath328 and @xmath329",
    ", we use the same set - up as for the gl methods , but for @xmath330 a larger number of @xmath331 on the coarsest level and a reduced number of @xmath332 is used to ensure that the method is stable on all levels .",
    ".5    .5    from those plots , it can be observed that the variance decay is indeed quadratic for @xmath333 for the values of @xmath134 considered , but @xmath182\\propto h_\\ell$ ] for the smallest @xmath82 .",
    "this deterioration in the variance decay rate can be explained using the theory of modified equations @xcite in [ sec : modifiedequations ] : since @xmath334 for @xmath51 , the variance decay rate is quadratic only if @xmath335 is not too large .",
    "this is because for larger @xmath134 such that @xmath336 , heuristically we can only hope for linear variance decay with @xmath182 \\propto h_\\ell$ ] since the size of the term @xmath337 in eq .",
    "( [ eqn : modifiedequations ] ) is @xmath338 and not @xmath339 and therefore the modified equation expansion breaks down",
    ". however , asymptotically , as @xmath134 goes to @xmath71 ( for fixed @xmath340 , we recover the expected quadratic variance decay rate @xmath182 \\propto h_\\ell^2 $ ] as soon as @xmath341 .",
    "we stress , however , that for the regularisation height used in all experiments above , which roughly agrees with what is used in the met office name model , the variance indeed behaves like @xmath182\\propto h_\\ell^2 $ ] for practically relevant values of @xmath134 and hence condition ( iii ) in the complexity theorem is satisfied .    for both discretisation methods",
    "the main reason for the increase in the variance is the large value of @xmath58 relative to the timestep size when the particle is close to the lower boundary . by decreasing the timestep size ,",
    "the variance decreases but at the same time the total cost increases .",
    "we therefore now look at how this effect can be mitigated with adaptive timestepping .",
    "various methods for adaptive timestepping in the mlmc method have been proposed in the literature @xcite . instead of using a fixed timestep @xmath200 for all timesteps , in an adaptive algorithm",
    "the timestep size is adjusted at every time @xmath342 .",
    "here we use @xmath343 where @xmath205 is the current particle position and @xmath344 is a reference height .",
    "since @xmath79 decreases with height , this choice guarantees that the product of the adaptive timestep size and @xmath345 never exceeds @xmath346 , which can then be chosen such that the se method is stable . since the telescoping sum in eq .",
    "( [ eqn : telescoping_sum ] ) is preserved , this choice of adaptive timestep is independent of the mlmc level and therefore does not introduce any additional bias @xcite . since @xmath79 is a decreasing function of @xmath186 ,",
    "it is only necessary to adapt the timestep size for particles below the reference height @xmath344 .",
    "however , since @xmath347 close to the ground , it is still necessary to regularise @xmath79 as described in section [ sec : regularisation ] . without regularisation ,",
    "the timestep size can become arbitrarily small , and it can take an infinite amount of time to calculate even a single trajectory .    when using adaptivity within mlmc , the coarse and fine timesteps are not necessarily nested",
    ". however , it is easy to adapt the mlmc algorithm to account for this @xcite . for this",
    ", the time interval @xmath83 $ ] is divided into a number of intervals @xmath348 $ ] such that @xmath349 , @xmath350 and each of the points @xmath351 is either a fine or a coarse time point ( see fig .",
    "[ fig : adaptivetimesteps ] , which has been adapted from fig .  1 in @xcite ) .",
    "more explicitly , define @xmath352 a normal random variable @xmath353 is associated with each interval @xmath348 $ ] .",
    "then , for each coarse or fine time interval @xmath354 $ ] ( where @xmath355 ) , those random variables can be combined to construct a random increment @xmath356 with the correct distribution . for se with reflection ,",
    "the expression for the coarse path is @xmath357 here , the reflection factor is @xmath358 , where , as before , @xmath359 counts the number of reflections up to time @xmath351 .",
    "the corresponding expression @xmath360 for the fine path is the same as in ( [ eqn : adaptivityincrementeuler ] ) , with the only difference that the reflection factors @xmath361 and @xmath362 do not appear in this case . since @xmath363 is a sum of gaussian random variables , it is easy to see that this variable has a variance of @xmath364 and can be used instead of @xmath365 for the velocity increment in ( [ eqn : methodsymplecticeuler ] ) .",
    "the crucial observation is that if a fine interval overlaps with a coarse interval , they share some of the random increments and this ensures the correct coupling between fine and coarse paths .",
    "the expression in ( [ eqn : adaptivityincrementeuler ] ) reduces to the standard expression for the case that the coarse points coincide with fine points . for gl , the expression in ( [ eqn : adaptivityincrementeuler ] ) has to be modified to @xmath366}{2\\lambda(x(\\tau_j))}}\\\\ & \\qquad\\qquad \\cdot \\exp\\biggl [ -\\sum_{k = j+1}^{j_+-1}\\lambda(x(\\tau_k))\\cdot(\\tau_{k+1}-\\tau_k ) \\biggr ] \\bigg\\}. \\end{aligned } \\label{eqn : adaptivityincrementsplitting}\\ ] ] this increment replaces @xmath367}{2 \\lambda(x_n)}}\\xi_n$ ] in ( [ eqn : methodsymplecticeulerou ] ) .",
    "again the corresponding expression for the fine path is obtained from eq .",
    "( [ eqn : adaptivityincrementsplitting ] ) by removing the reflection factors @xmath361 and @xmath362 .",
    "it can be verified that this is equivalent to ( [ symeulercoupled ] ) in the case that the coarse timesteps coincide with fine timesteps .",
    "we now present some numerical results to quantify potential improvements from adaptive timestepping .",
    "the adaptive mlmc algorithm described in the previous section is used to calculate the expected value of the particle position @xmath102 at the final time with the same set - up as in section [ sec : particleposition ] and @xmath368 .",
    "as before , we first confirm that condition ( iii ) in the complexity theorem is satisfied .",
    "the variance @xmath182 $ ] as a function of the timestep size @xmath134 is shown for both se and gl integrators in figs .",
    "[ fig : variance_adaptivityse ] and [ fig : variance_adaptivitygl ] .",
    "as expected , both for the uniform and adaptive timestepping methods , the variance decays quadratically with the ( maximal ) timestep size , @xmath182\\propto h_\\ell^2 $ ] . in both cases ,",
    "adaptive timestepping reduces the variance for a given @xmath134 .    the total computational cost for both methods",
    "is compared in figs .",
    "[ fig : cost_adaptivityse ] and [ fig : cost_adaptivitygl ] .",
    "while the results for se are as expected and adaptive timestepping reduces the overall cost , the opposite can be observed for gl ; here uniform timestepping reduces the runtime ( albeit not by much as @xmath369 ) . looking at the bias error for a given ( maximal ) timestep size , we find that for the se method this bias is about @xmath370 smaller with adaptive timestepping .",
    "this and the fact that the variance is reduced ( see fig .  [",
    "fig : variance_adaptivityse ] ) explains the results in fig .",
    "[ fig : cost_adaptivityse ] . for the gl method , on the other hand ,",
    "adaptive timestepping _ increases _ the bias by about @xmath371 .",
    "this is a counter - intuitive result , since all individual timesteps in the adaptive algorithm are smaller than for the corresponding uniform implementation .",
    "for a ( deterministic ) ode , it would then be easy to prove that adaptivity reduces the discretisation error .",
    "for the sde considered here , however , the theoretical analysis is significantly harder and beyond the scope of this work .",
    "to exclude any bugs in the code , we have carried out several tests .",
    "for example , we have confirmed that for the corresponding ode equations ( @xmath372 ) adaptivity reduces the bias error also for the gl method .",
    "the phenomenon appears to be linked to the divergence of @xmath79 close to the ground and might require careful tuning of both @xmath344 and @xmath82 to see any benefits from adaptive timestepping .",
    ".5    .5    .5    .5",
    "in this paper , we presented two improvements to monte carlo algorithms for the solution of sdes encountered in atmospheric dispersion modelling : the geometric langevin ( gl ) method uses a splitting approach to avoid numerical instabilities due to very small velocity decorrelation times close to the ground .",
    "multilevel monte carlo reduces the algorithmic complexity as a function of the tolerance @xmath0 on the root - mean - square error from @xmath302 to @xmath17 .",
    "both methods were applied to the simulation of the vertical spread and diffusion of particles in a turbulent boundary layer .",
    "the intricacies of the application considered here requires careful adaptation of the algorithms to account for suitable boundary conditions at the top and bottom of the atmosphere and to treat the divergence of the inverse velocity decorrelation time near the ground . when predicting particle concentrations , a smoothed indicator function has to be used and we confirmed that the additional errors introduced by the smoothing are small .",
    "if the initial condition is chosen such that particles are released at a relatively low height , the gl algorithm reduces the computational cost ( for the same accuracy ) by around at least an order of magnitude for all quantities of interest considered in our numerical experiments ( as compared to symplectic euler ) .",
    "the main reason for this is a significant reduction in the bias error since the gl algorithm is able to deal with large values of the inverse velocity decorrelation time @xmath79 . for small tolerances",
    "@xmath0 , the mlmc algorithm leads to further speed - ups , which are particularly pronounced if the particles are released at a larger height . when calculating piecewise constant approximations to the particle concentration field , the mlmc algorithm is nearly three times faster than the standard monte carlo algorithm even when used in combination with the improved gl timestepping method .    in a preliminary study we also explored the use of adaptive timestepping and find that this can lead to a further , but less dramatic , reduction in runtime for the symplectic euler method .",
    "the unexpected results observed for the gl algorithm require further investigation and careful tuning of parameters .    of central importance for the application of the mlmc algorithm",
    "is the correct dependence of the multilevel variance on the timestep size .",
    "numerically we observed the correct behaviour , but a theoretical proof is more challenging due to the non - smooth regularisation of the profile functions .",
    "although this problem can be addressed by using an equivalent smooth regularisation instead , a proof relies on further technical details such as boundedness of all moments of @xmath27 , which would then allow the application of the modified equation analysis in @xcite .",
    "the treatment of reflective boundary conditions introduces discontinuities , which do not have any adverse effects on our numerical results but require a careful treatment in a rigorous mathematical analysis . since the focus of this work is the introduction of new numerical methods to atmospheric dispersion modelling , this would be beyond the scope of this article .",
    "in addition to investigating those mathematical details more rigorously , there are various ways of extending our work .",
    "one obvious avenue to explore is the use of quasi monte carlo methods ( qmcs ) , which potentially allow a reduction of the computational complexity beyond the standard monte carlo limit of @xmath17 , which is set by the central limit theorem ( see e.g. @xcite ) . by using a randomly shifted point lattice , any additional bias from the qmc sampling",
    "can be removed .",
    "so far we have treated turbulence in all space directions independently and focussed on motion in the vertical direction where the atmospheric conditions vary strongly .",
    "although similar approximations are made in operational models , ultimately we would like to apply our approach to a full three - dimensional scenario , for example to study the global spread of ash clouds , which would require the use of a more complicated , 3d turbulence model described in @xcite .",
    "one particular question to be addressed is as to whether the separation of particle pairs by the resolved flow field will have any impact on the efficiency of mlmc .",
    "it is our hope that eventually operational models such as name will make use of the multilevel monte carlo method .",
    "name models a plethora of additional physical effects such as gravitational settling , chemical interactions , radioactive decay chains and gamma radiation from non - local radioactivity , which are computationally expensive .",
    "while in this paper the multilevel approach was described in terms of a hierarchy of levels of increasing timestep size , the first coarsening step might consist of using the same timestep size but not including all physical processes .",
    "conceptually this is somewhat similar to the difference between @xmath373- and @xmath200- refinement in finite element methods .",
    "the phd of grigoris katsiolides is supported by an epsrc case studentship , which is partially funded by the met office .",
    "our theoretical tools for proving the complexity theorem rely on the theory of modified equations @xcite and their application to the mlmc method as described in @xcite ; this approach is an alternative to the usual strong convergence proofs .",
    "we discuss this analysis here since it can be used to justify the use of a regularisation cut - off at the upper and lower boundary as outlined in section [ sec : boundaryconditions ] .",
    "the key idea is as follows : under suitable conditions , the numerical solution @xmath205 of the initial sde ( [ generalisedsim ] ) is the weak second - order approximation of the solution of a set of modified equations  recall that @xmath205 converges only with order one to the original equations . if those modified equations exist , it can be shown that condition ( iii ) in the complexity theorem holds @xcite .    for our model ,",
    "the modified equations have the form @xmath374 the functions @xmath375 , @xmath376 , @xmath377 and @xmath378 depend on the numerical timestepping method and can be expressed explicitly in terms of @xmath47 and @xmath46 . however , these modified equations are only a first - order approximation of eq .",
    "( [ generalisedsim ] ) if the @xmath379 terms in are indeed small .",
    "unfortunately , this is not the case near the boundary of the domain . in particular , by expanding    2 v_1^(u)(x , u ) & = x^-2f^(v , u)(u ) +  , & v_1^(x)(x , u ) & = x^-1f^(v , x)(u ) +  , + _",
    "1^(u)(x , u ) & = x^-3/2f^(,u)(u ) +  , & _ 1^(x)(x ,",
    "u ) & = x^-1/2f^(,x)(u ) +     it can be shown that these terms diverge at the lower boundary ( @xmath51 ) , for both the symplectic euler and geometric langevin .",
    "similar expressions can be derived at the upper boundary ( @xmath77 ) , but for simplicity we do not write them down here .    however ,",
    "if we regularise the profiles @xmath47 and @xmath46 as described in section [ sec : regularisation ] , then the divergent terms @xmath380 are replaced by the constant @xmath381 .",
    "thus , the terms @xmath375 , @xmath376 , @xmath377 and @xmath378 can all be made @xmath338 by a suitable choice of @xmath82 .",
    "the existence of the modified equations then implies the quadratic variance decay required by condition ( iii ) in the complexity theorem , under the condition that @xmath96 has bounded moments .",
    "this can be seen in fig .",
    "[ symeuleroureg ] : unless @xmath82 is chosen too small , the variance decay is indeed quadratic .",
    "to derive inequality , we first consider the following difference between the expected values of the indicator function @xmath382 and the smoothed out function @xmath315 : @xmath383 - \\mathbb{e}[p^{r,\\delta } ] \\right|   & \\leq \\textstyle \\left| \\mathbb{e } \\left [ \\theta ( x_t - b ) \\right ] - \\mathbb{e } \\left [ g_r \\left ( \\frac{x_t - b}{\\delta } \\right ) \\right ] \\right| + \\left| \\mathbb{e } \\left [ \\theta ( x_t - a ) \\right ] - \\mathbb{e } \\left [ g_r \\left ( \\frac{x_t - a}{\\delta } \\right ) \\right ] \\right| \\leq   2 c \\delta^{r + 1}.\\label{eqn : rdeltabound1 } \\end{aligned}\\ ] ] using this expression and @xmath384 , the bound on the bias ( or weak error ) in follows from the triangle inequality @xmath383 - \\mathbb{e}[\\hat{p}^{r,\\delta}_l ] \\right| & \\leq \\left| \\mathbb{e}[p ] - \\mathbb{e}[p^{r,\\delta } ] \\right| + \\left| \\mathbb{e}[p^{r,\\delta } ] - \\mathbb{e}[\\hat{p}^{r,\\delta}_l ] \\right| \\leq 2 c \\delta^{r + 1 } + \\left| \\mathbb{e}[p^{r,\\delta } ] - \\mathbb{e}[p^{r,\\delta}_l ] \\right|.\\end{aligned}\\ ] ] to prove , we write @xmath385 =   \\left (    \\hat{p}^{r,\\delta}_l - \\mathbb{e}[p^{r,\\delta}_l ] \\right ) + \\left (    \\mathbb{e}[p^{r,\\delta}_l ] - \\mathbb{e}[p^{r,\\delta } ] \\right ) + \\left (    \\mathbb{e}[p^{r,\\delta } ] - \\mathbb{e}[p ] \\right)\\,.\\ ] ] now , using the fact that @xmath386=\\mathbb{e}[p^{r,\\delta}_l]$ ] it is easy to see that @xmath387 \\right)^2 \\right ] & = \\text{var } ( \\hat{p}^{r,\\delta}_l ) + \\left ( \\mathbb{e}[p^{r,\\delta}_l ] - \\mathbb{e}[p^{r,\\delta } ] \\right)^2 + \\left(\\mathbb{e}[p^{r,\\delta}]-\\mathbb{e}[p]\\right)^2 \\\\ & + 2\\left(\\mathbb{e}[p^{r,\\delta}_l]-\\mathbb{e}[p^{r,\\delta}]\\right)\\left(\\mathbb{e}[p^{r,\\delta}]-\\mathbb{e}[p]]\\right ) .",
    "\\end{aligned}\\ ] ] the desired result then follows from the bound in : @xmath388 \\right)^2 \\right ] \\leq \\text{var } ( \\hat{p}^{r,\\delta}_l ) + \\left ( \\mathbb{e}[p^{r,\\delta}_l ] -\\mathbb{e}[p^{r,\\delta } ] \\right)^2 + 4 c^2 \\delta^{2(r + 1 ) } + 4 c \\delta^{r + 1 } \\left| \\mathbb{e}[p^{r,\\delta}_l ] -\\mathbb{e}[p^{r,\\delta } ] \\right|\\ ] ]"
  ],
  "abstract_text": [
    "<S> a common way to simulate the transport and spread of pollutants in the atmosphere is via stochastic lagrangian dispersion models . </S>",
    "<S> mathematically , these models describe turbulent transport processes with stochastic differential equations ( sdes ) . </S>",
    "<S> the computational bottleneck is the monte carlo algorithm , which simulates the motion of a large number of model particles in a turbulent velocity field ; for each particle , a trajectory is calculated with a numerical timestepping method . </S>",
    "<S> choosing an efficient numerical method is particularly important in operational emergency - response applications , such as tracking radioactive clouds from nuclear accidents or predicting the impact of volcanic ash clouds on international aviation , where accurate and timely predictions are essential . in this paper </S>",
    "<S> , we investigate the application of the multilevel monte carlo ( mlmc ) method to simulate the propagation of particles in a representative one - dimensional dispersion scenario in the atmospheric boundary layer . </S>",
    "<S> mlmc can be shown to result in asymptotically superior computational complexity and reduced computational cost when compared to the standard monte carlo ( stmc ) method , which is currently used in atmospheric dispersion modelling . to reduce the absolute cost of the method also in the non - asymptotic regime , </S>",
    "<S> it is equally important to choose the best possible numerical timestepping method on each level . to investigate this </S>",
    "<S> , we also compare the standard symplectic euler method , which is used in many operational models , to an improved timestepping algorithm based on a geometric langevin approach .    </S>",
    "<S> atmospheric dispersion modelling , multilevel monte carlo , stochastic differential equations , numerical timestepping methods </S>"
  ]
}