{
  "article_text": [
    "image decomposition , variational calculus , cartoon image , texture image , image compression , feature extraction , latent fingerprint image processing , optical character recognition , fingerprint recognition .",
    "feature extraction , denoising and image compression are key issues in computer vision and image processing .",
    "we address these main tasks based on the paradigm that an image can be regarded as the addition or montage of several meaningful components .",
    "image decomposition methods attempt to model these components by their properties and to recover the individual components using an algorithm .",
    "relevant component images include geometrical objects which have piece - wise constant values or a smooth surface like e.g. the characters in figure [ fig : examplesimulatedlatent ] ( b ) or components which are filled with an oscillating pattern like e.g. the fingerprint in [ fig : examplesimulatedlatent ] ( c ) .",
    "based on these observations , we define the following goals :    * goal 1 : the cartoon component @xmath0 contains only geometrical objects with a very smooth surface , sharp boundaries and no texture . *    * goal 2 : the texture component @xmath1 contains only geometrical objects with oscillating patterns and @xmath1 shall be both smooth and sparse . *    * goal 3 : three - part decomposition and reconstruction @xmath2 . *    how does achieving these goals",
    "serve the tasks of feature extraction , denoising and compression ?    extremely efficient representations of the cartoon image @xmath0 and texture image @xmath1 exist .",
    "these two component images are highly compressible as discussed with full details in section [ sec : compression ] .",
    "depending on the application , @xmath0 or @xmath1 , or both can be considered as feature images . for the application to latent fingerprints",
    ", we are especially interested in the texture image @xmath1 as a feature for fingerprint segmentation and all subsequent processing steps .",
    "example results for the very challenging task of latent fingerprint segmentation are given in section [ sec : featextract ] .",
    "in optical character recognition ( ocr ) , pre - processing includes the removal of complex background and the isolation of characters .",
    "after three - part decomposition and depending on the scale of the characters , the cartoon image @xmath0 contains the information of interest for ocr ( see figure [ fig : examplesimulatedlatent ] ( j ) ) , and the background is fractionized into @xmath1 and @xmath3 simultaneously in the minimization procedure . as a consequence from the requirements imposed on @xmath0 and @xmath1 , noise and small scale objects",
    "are driven into the residual image @xmath3 during the dismantling of @xmath4 .",
    "therefore , the image @xmath5 can be regarded as a denoised version of @xmath4 and the degree of denoising can be steered by the choice of parameters .",
    "the paper is organized as follows . in section [ sec : notation ] , we begin by describing notation and preliminaries . after having established these prerequisites , we define the dg3pd model in section [ sec : dg3pd ] and in section [ sec : relatedwork ] , we explain its relation to existing models in the literature for two - part and three - part decomposition . in section [ sec : solutiondg3pd ] , we describe an iterative , numerical algorithm which solves the dg3pd model for practical applications to discrete , 2-dimensional images . in section [ sec : comparisonpriorart ] , we perform a detailed comparison of the dg3pd method to state - of - the - art decomposition approaches",
    ". applications of dg3pd , especially feature extraction and image compression , are the topic of section [ sec : applications ] .",
    "discussion and conclusion are given in section  [ sec : conclusion ] .",
    "an overview over the algorithm and an additional comparison is given in the appendix .",
    "for simplification , we use a bold symbol to denote the coordinates of a two - dimensional signal , e.g. @xmath6 \\ , , { { \\boldsymbol \\omega}}= ( \\omega_1 \\ , , \\omega_2)$ ] and @xmath7 $ ] . a two - dimensional image @xmath8 : \\omega \\rightarrow \\mathbb r_+$ ] , the discretization of the continuous version @xmath9 ( i.e. @xmath8 = f({{\\mathbf x } } ) \\mid_{{{\\mathbf x}}= { { \\mathbf k}}\\in \\omega}$ ] ) , is specified on the lattice : @xmath10",
    "let @xmath11 be the euclidean space whose dimension is given by the size of the lattice @xmath12 , i.e. @xmath13 . the 2d discrete fourier transform @xmath14 acting on @xmath8 $ ] is @xmath15 ~\\stackrel{\\mathcal f}{\\longleftrightarrow}~ f(e^{j { { \\boldsymbol \\omega } } } )    = \\sum_{{{\\mathbf k}}\\in \\omega } f[{{\\mathbf k } } ] \\cdot e^{-j \\langle { { \\mathbf k}}\\ , , { { \\boldsymbol \\omega}}\\rangle_{\\ell_2}},\\ ] ] where @xmath16 is defined on the lattice : @xmath17 \\times \\big [ - \\frac{m}{2 } \\ , , \\frac{m}{2 } \\big ] \\subset \\mathbb z^2   \\big\\ } \\,,\\ ] ] i.e. @xmath18 ^ 2.$ ]    [ [ forward - and - backward - difference - operators ] ] forward and backward difference operators : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    given the matrix @xmath19 the forward and backward difference operators with periodic boundary condition in convolution and matrix forms and their fourier transform are explained in table  [ tab : forwardbackwarddifference ] .    [",
    "[ discrete - directional - derivative ] ] discrete directional derivative : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    .forward / backward difference with periodic boundary condition in convolution / matrix form and their fourier transform .",
    "@xmath20 and @xmath21 are the transposed matrices of @xmath22 and @xmath23 , respectively .",
    "[ tab : forwardbackwarddifference ] [ cols=\"^,^,^\",options=\"header \" , ]     let @xmath24 $ ] be the discrete forward gradient operator with @xmath25 and @xmath26 are defined in table [ tab : forwardbackwarddifference ] .",
    "the discrete derivative operator following the direction @xmath27^\\text{t}$ ] with @xmath28 is defined as @xmath29 thus , the discrete directional gradient operator is @xmath30_{l \\in [ 0 , l-1]}.\\ ] ]      the continuous total variation norm has been defined in @xcite . due to the discrete nature of images ,",
    "we define its discrete version with forward difference operators as @xmath31\\big)^2 + \\big(\\partial_y^+ u[{{\\mathbf k}}]\\big)^2 } .\\ ] ]    we extend it into multi - direction @xmath32 with the discrete directional gradient operator ( [ eq : disdirgrad ] ) : @xmath33)^2 }   = \\norm { \\sqrt{\\sum_{l=0}^{l-1 } \\big(\\cos \\frac{\\pi l}{l } { { \\mathbf u}}{{\\mathbf{d}_{\\mathbf n}^{\\text t}}}+ \\sin \\frac{\\pi l}{l } { { \\mathbf{d_m}}}{{\\mathbf u}}\\big)^2 } } _ { \\ell_1}.\\ ] ] the discrete anisotropic total variation norm in a matrix form is @xmath34      [ [ discrete - g - norm ] ] discrete g - norm : + + + + + + + + + + + + + + + +    meyer @xcite has proposed a space @xmath35 of continuous functions to measure oscillating functions ( texture and noise ) .",
    "the discrete version of the g - norm has been introduced by aujol and chambolle in @xcite .",
    "we rewrite it with the matrix form of the forward difference operators as @xmath36_{l \\in [ 1,2 ] } \\in x^2    \\bigg\\}.\\ ] ]    [ [ discrete - directional - g - norm ] ] discrete directional g - norm : + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we extend ( [ eq : disgnorm ] ) into multi - directions @xmath37 with the directional difference operator to obtain the discrete directional g - norm as @xmath38   } _ { \\displaystyle \\leftrightarrow~ v[{{\\mathbf k } } ] = \\sum_{s=0}^{s-1 } \\partial_s^+ g_s [ { { \\mathbf k } } ] \\ , , \\forall { { \\mathbf k}}\\in \\omega }   \\,,~ \\big [ { { \\mathbf g}}_s \\big]_{s = 0}^{s-1 } \\in x^s    \\bigg\\}.\\ ] ]",
    "we define the dg3pd model for discrete directional three - part decomposition of an image into cartoon , texture and residual parts as @xmath39 } \\leq \\delta    \\,,~ { { \\mathbf f}}= { { \\mathbf u}}+ { { \\mathbf v}}+ { { \\boldsymbol \\epsilon}}\\big\\},\\ ] ] where @xmath40 is the curvelet transform @xcite with the index set @xmath41 . please note that by setting the parameter @xmath42 in ( [ eq : dtv - dg3part ] ) , we obtain a two - part decomposition which can be considered as a special case of the dg3pd model .",
    "next , we discuss how the dg3pd model relates to existing decomposition models .",
    "in this section , we give an overview over related work in two - part and three - part image decomposition in chronological order .      in 1989 ,",
    "mumford and shah @xcite have proposed piece - wise smooth ( for image restoration ) and piece - wise constant ( for image segmentation ) models by minimizing the energy functional .",
    "this approach can be considered as a precursor for subsequent image decomposition models with texture components . however , due to the hausdorff 1-dimensional measure @xmath43 in @xmath44 , it poses a challenging or even np - hard problem in optimization to minimize the mumford and shah functional .",
    "later , based on the mumford and shah model , chan and vese @xcite have proposed an active contour for image segmentation which is solved by a level set method @xcite .      in 1992 , rudin , osher , and fatemi @xcite pioneered image decomposition with a two - part model for denoising .      the model defined by meyer in 2001 @xcite for two - part decomposition in the continuous setting is comprised in the dg3pd model for the special case of @xmath45 and @xmath46 in the discrete domain .      in 2003 , vese and osher @xcite solved meyer s model for two - part decomposition in the continuous setting and they proposed to approximate the @xmath47-norm in the g - norm by the @xmath48-norm and to apply the penalty method for reformulating the constraint . for practical application to images , they discretized their solution .",
    "this approach is extended in @xcite .",
    "aujol and chambolle in 2005 @xcite adapted the work by meyer for discrete two - part decomposition ( see ( 5.49 ) in @xcite ) and they used the penalty method for the constraint . their model is included in the dg3pd model with parameters @xmath45 , @xmath49 and applying the supremum norm to the wavelet coefficients of the oscillating pattern , i.e. @xmath50 , instead of the curvelet coefficients @xmath51 as in the dg3pd model .",
    "moreover , aujol and chambolle proposed a model for discrete three - part decomposition ( see ( 6.59 ) in @xcite ) which measures texture by the g - norm and noise by the supremum norm of wavelet coefficients , and the penalty method for the constraint .",
    "different from vese and osher as well as our approach explained later , they describe the g - norm for capturing texture using the indicator function defined on a convex set and they obtain the solution by chambolle s projection onto this convex set .",
    "their model is included in the dg3pd model for parameters @xmath45 , @xmath52 and using wavelets instead of curvelets for the residual as before .",
    "starck _ et al . _",
    "@xcite introduced a model for two - part decomposition based on a dictionary approach .",
    "their basic idea is to choose one appropriate dictionary for piecewise smooth objects ( cartoon ) and another suitable dictionary for capturing texture parts .      in 2006 , aujol _ et al . _",
    "@xcite proposed a two - part decomposition of an image into a structure component and a texture component using gabor functions for the texture part .",
    "gilles @xcite has proposed a three - part image decomposition in 2007 which is similar to the aujol - chambolle model @xcite , but g - norm is used as a measurement of the residual ( or noise ) instead of besov space @xmath53 with a local adaptability property .",
    "their argument is that the more a function is oscillatory , the smaller is the g norm",
    ". then , they propose a new `` merged - algorithm '' with a combination of a local adaptivity behavior and besov space .      in 2007 ,",
    "maragos and evangelopoulos @xcite have proposed a two - part decomposition model which relies on energy responses of a bank of 2d gabor filters for measuring the texture component .",
    "they discuss the connection between meyer s oscillating functions @xcite , gabor filters @xcite and am - fm image modeling @xcite .      in 2010 , buades _",
    "@xcite derived a nonlinear filter pair for two - part decomposition into cartoon and texture parts .",
    "further models for two - part decomposition are listed in table 1 of @xcite .      in 2011 , maurel _ et al . _",
    "@xcite proposed a decomposition approach which models the texture component by local fourier atoms . for fingerprint textures ,",
    "chikkerur _ et al . _",
    "@xcite proposed in 2007 the application of local fourier analysis ( or short time fourier transform , stft ) for image enhancement .",
    "however , the usefulness of local fourier analysis for capturing texture information depends on and is limited by the level of noise in the corresponding local window , see figure 2c in @xcite for an example in which stft enhances some regions successfully and fails in other regions .      a model for discrete three - part decomposition of fingerprint images",
    "has recently been proposed by thai and gottschlich in 2015 @xcite with the aim of obtaining a texture image @xmath1 which serves as a useful feature for estimating the region - of - interest ( roi ) . the g3pd model is included in the dg3pd model by choosing @xmath54 and replacing the directional g - norm in the dg3pd model by the @xmath55-norm of curvelet coefficients ( multi - scale and multi - orientation decomposition ) to capture texture .",
    "however , a disadvantage of the @xmath55-norm of curvelet coefficients is a tendency to generate the halo effect on the boundary of the texture region due to the scaling factor in curvelet decomposition ( see figure 3(d ) in @xcite ) , whereas the directional g - norm in the dg3pd model is capable to capture oscillating patterns ( cf .",
    "@xcite ) without the halo effect .      in section [ sec : dtvnorm ] , we introduced the discrete directional total variation norm and in section [ sec : dgnorm ] , we introduced the discrete directional g - norm .",
    "please note the aspect of summation over multiple directions in equations ( [ eq : disdirtvnorm ] ) and ( [ eq : disdirgnorm ] ) .",
    "the term directional total variation has previously been used by bayram and kamasak @xcite for defining and computing the tv - norm in only one specific direction .",
    "they have treated the special case of images with one globally dominant direction and addressed those by two - part decomposition and for the purpose denoising .",
    "zhang and wang @xcite proposed an extension of the work by bayram and kamasak for denoising images with more than one dominant direction .",
    "now , we present a numerical algorithm for obtaining the solution of the dg3pd model stated in ( [ eq : dtv - dg3part ] ) . given @xmath56 , denote @xmath57 as the indicator function on the feasible convex set @xmath58 of ( [ eq : dtv - dg3part ] ) , i.e. @xmath59    by analogy with the work of vese and osher , we consider the approximation of g - norm with @xmath55 norm and the anisotropic version of directional total variation norm . the minimization problem in ( [ eq : dtv - dg3part ] ) is rewritten as @xmath60_{s=0}^{s-1 }",
    "\\big )     = { \\mathop{\\rm argmin}}_{\\big ( { { \\mathbf u}}\\ , , { { \\mathbf v}}\\ , , { { \\boldsymbol \\epsilon}}\\ , , \\big [ \\mathbf{g}_s \\big]_{s=0}^{s-1 } \\big ) \\in x^{s+3 } }    \\bigg\\ { \\sum_{l=0}^{l-1 } \\norm { \\cos\\big ( \\frac{\\pi l}{l } \\big ) { { \\mathbf u}}{{\\mathbf{d}_{\\mathbf n}^{\\text",
    "t}}}+ \\sin\\big ( \\frac{\\pi l}{l } \\big ) { { \\mathbf{d_m}}}{{\\mathbf u}}}_{\\ell_1 }      \\notag    \\\\ &    + \\mu_1 \\sum_{s=0}^{s-1 } \\norm{\\mathbf{g}_s}_{\\ell_1 } + \\mu_2 \\norm{{{\\mathbf v}}}_{\\ell_1 } + g^ * \\big ( \\frac{{{\\boldsymbol \\epsilon}}}{\\delta } \\big )    ~\\text{s.t.}~     \\begin{cases }     { { \\mathbf f}}= { { \\mathbf u}}+ { { \\mathbf v}}+ { { \\boldsymbol \\epsilon}}\\\\     { { \\mathbf v}}= \\displaystyle \\sum_{s=0}^{s-1 } \\big [ \\cos\\big ( \\frac{\\pi s}{s } \\big ) { { \\mathbf g}}_s { { \\mathbf{d}_{\\mathbf n}^{\\text t}}}+ \\sin\\big ( \\frac{\\pi s}{s } \\big ) { { \\mathbf{d_m}}}{{\\mathbf g}}_s \\big ]    \\\\     \\end{cases }    \\bigg\\ } .   \\end{aligned}\\ ] ]    to simplify the calculation , we introduce two new variables : @xmath61 equation ( [ eq : dtv - dg3part_rewrite ] ) is a constrained minimization problem . the augmented lagrangian method ( alm ) is applied to turn ( [ eq : dtv - dg3part_rewrite ] ) into an unconstrained one as @xmath62_{l=0}^{l-1 } \\",
    ", ,   \\big [ { { \\mathbf w}}_s \\big]_{s=0}^{s-1 } \\ , , \\big [ { { \\mathbf g}}_s \\big]_{s=0}^{s-1 } \\big ) \\in x^{l+2s+3 } }   \\mathcal l \\big ( { { \\mathbf u}}\\ , , { { \\mathbf v}}\\ , , { { \\boldsymbol \\epsilon}}\\ , , \\big [ { { \\mathbf r}}_l \\big]_{l=0}^{l-1 } \\ , ,   \\big [ { { \\mathbf w}}_s \\big]_{s=0}^{s-1 } \\ , , \\big [ { { \\mathbf g}}_s \\big]_{s=0}^{s-1 } \\ ; ; \\big [ \\boldsymbol{\\lambda}_{\\boldsymbol{1 } l } \\big]_{l=0}^{l-1 } \\ , ,   \\big [ \\boldsymbol{\\lambda}_{\\boldsymbol{2}s } \\big]_{s=0}^{s-1 } \\ , , \\boldsymbol{\\lambda_3 } \\ , , \\boldsymbol{\\lambda_4 } \\big ) \\,,\\ ] ] where the lagrange function is @xmath63 + \\frac{\\boldsymbol{\\lambda_3}}{\\beta_3 } } ^2_{\\ell_2 }   + \\frac{\\beta_4}{2 } \\norm { { { \\mathbf f}}- { { \\mathbf u}}- { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } } _ { \\ell_2}^2 .\\end{aligned}\\ ] ]    due to the minimization problem with multi - variables , we apply the alternating directional method of multipliers to solve ( [ eq : dtv - dg3part_alm ] ) .",
    "its minimizer is numerically computed through iterations @xmath64 @xmath65_{l=0}^{l-1 } \\",
    ", ,   \\big [ { { \\mathbf w}}_s^{(t ) } \\big]_{s=0}^{s-1 } \\ , , \\big [ { { \\mathbf g}}_s^{(t ) } \\big]_{s=0}^{s-1 } \\big ) }                      \\notag   ~=~   \\\\   & { \\mathop{\\rm argmin}}~ \\mathcal l \\big ( { { \\mathbf u}}\\ , , { { \\mathbf v}}\\ , , { { \\boldsymbol \\epsilon}}\\ , , \\big [ { { \\mathbf r}}_l \\big]_{l=0}^{l-1 } \\ , ,   \\big [ { { \\mathbf w}}_s \\big]_{s=0}^{s-1 } \\ , , \\big [ { { \\mathbf g}}_s \\big]_{s=0}^{s-1 } \\;;~ \\big [ \\boldsymbol{\\lambda}_{\\boldsymbol{1 } l}^{(t-1 ) } \\big]_{l=0}^{l-1 } \\ , ,   \\big [ \\boldsymbol{\\lambda}_{\\boldsymbol{2}s}^{(t-1 ) } \\big]_{s=0}^{s-1 } \\ , , \\boldsymbol{\\lambda}_{\\mathbf 3}^{(t-1 ) } \\ , , \\boldsymbol{\\lambda}_{\\mathbf 4}^{(t-1 ) } \\big)\\end{aligned}\\ ] ]    and the lagrange multipliers are updated after every step @xmath66 with a rate @xmath67 .",
    "we initialize @xmath68_{l=0}^{l-1 } = \\big [ { { \\mathbf w}}_s^{(0 ) } \\big]_{s=0}^{s-1 } = \\big [ { { \\mathbf g}}_s^{(0 ) } \\big]_{s=0}^{s-1 }   = \\big[\\boldsymbol{\\lambda}_{\\mathbf{1}l}^{(0)}\\big]_{l=0}^{l-1 } = \\big[\\boldsymbol{\\lambda}_{\\mathbf{2}a}^{(0)}\\big]_{a=0}^{s-1 }   = \\boldsymbol{\\lambda}_{\\mathbf 3}^{(0 ) } = \\boldsymbol{\\lambda}_{\\mathbf 4}^{(0 ) } = \\boldsymbol 0 $ ] . in each iteration",
    ", we first solve the following six subproblems in the listed order and then we update the four lagrange multipliers :    * the `` @xmath69_{l=0}^{l-1}$]-problem '' : * fix @xmath70 , @xmath71 , @xmath72 , @xmath73_{s=0}^{s-1}$ ] , @xmath74_{s=0}^{s-1}$ ] and @xmath75_{l=0}^{l-1 } \\in x^{l } }   \\bigg\\ { \\sum_{l=0}^{l-1 } \\norm { { { \\mathbf r}}_l } _ { \\ell_1 }    + \\frac{\\beta_1}{2 } \\sum_{l=0}^{l-1 } \\norm { { { \\mathbf r}}_l - \\cos\\big ( \\frac{\\pi l}{l } \\big ) { { \\mathbf u}}{{\\mathbf{d}_{\\mathbf n}^{\\text t}}}-",
    "\\sin\\big ( \\frac{\\pi l}{l } \\big ) { { \\mathbf{d_m}}}{{\\mathbf u}}+ \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol{1 } l}}{\\beta_1 } } ^2_{\\ell_2 }   \\bigg\\}\\ ] ] due to its separability , we consider the problem at @xmath76 . the solution of ( [ eq : sub : r ] ) is @xmath77 the operator @xmath78 is defined in @xcite .    *",
    "the `` @xmath73_{s=0}^{s-1}$]-problem '' : * fix @xmath70 , @xmath71 , @xmath72 , @xmath69_{l=0}^{l-1}$ ] , @xmath74_{s=0}^{s-1}$ ] and @xmath79_{s=0}^{s-1 } \\in x^{s } }   \\bigg\\ {     \\mu_1 \\sum_{s=0}^{s-1 } \\norm{{{\\mathbf w}}_s}_{\\ell_1 }    + \\frac{\\beta_2}{2 } \\sum_{s=0}^{s-1 } \\norm{{{\\mathbf w}}_s - { { \\mathbf g}}_s + \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol{2}s}}{\\beta_2}}^2_{\\ell_2 }   \\bigg\\}\\ ] ]    similarly , the solution of ( [ eq : sub : w ] ) for each separable problem @xmath80 is @xmath81    * the `` @xmath74_{s=0}^{s-1}$]-problem '' : * fix @xmath70 , @xmath71 , @xmath72 , @xmath69_{l=0}^{l-1}$ ] , @xmath73_{s=0}^{s-1}$ ] and @xmath82_{s=0}^{s-1 } \\in x^s }   \\bigg\\ { \\frac{\\beta_2}{2 } \\sum_{s=0}^{s-1 } \\norm{{{\\mathbf w}}_s - { { \\mathbf g}}_s + \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol{2}s}}{\\beta_2}}_{\\ell_2}^2    + \\frac{\\beta_3}{2 } \\norm { { { \\mathbf v}}- \\sum_{s=0}^{s-1 } \\big [ \\cos\\big ( \\frac{\\pi s}{s } \\big ) { { \\mathbf g}}_s { { \\mathbf{d}_{\\mathbf n}^{\\text t}}}+ \\sin\\big ( \\frac{\\pi s}{s } \\big ) { { \\mathbf{d_m}}}{{\\mathbf g}}_s \\big ] + \\frac{\\boldsymbol{\\lambda_3}}{\\beta_3 } } _ { \\ell_2}^2   \\bigg\\}\\ ] ]    for the discrete finite frequency coordinates @xmath83 \\in { { \\mathcal i}}$ ] , let be @xmath84 = \\big [ e^{j{{\\boldsymbol{\\omega_1 } } } } \\ , , e^{j{{\\boldsymbol{\\omega_2 } } } } \\big]$ ] .",
    "we denote by @xmath85 and @xmath86 the discrete fourier transforms of @xmath87 \\ , , \\lambda_{2a}[\\boldsymbol k ] \\",
    ", , v[\\boldsymbol k ] \\",
    ", , g_s[\\boldsymbol k ] $ ] and @xmath88 $ ] , respectively . due to the separability , the solution of ( [ eq : sub : g ] ) is obtained for @xmath80 as    @xmath89\\ ] ]    with @xmath90   \\big [ \\sin \\frac{\\pi a}{s } ( { { \\mathbf{z_1}}}- 1 ) + \\cos \\frac{\\pi a}{s } ( { { \\mathbf{z_2}}}- 1 ) \\big ]    \\bigg]^{-1 }   \\ , ,   \\\\   & \\mathcal b({{\\mathbf z } } ) ~=~    \\beta_2 \\big [ w_a({{\\mathbf z } } )   + \\frac{\\lambda_{2a}({{\\mathbf z } } ) } { \\beta_2 } \\big ]   ~+~ \\beta_3 \\big [ \\sin\\big ( \\frac{\\pi a}{s } \\big ) ( { { \\mathbf z}_{\\mathbf 1}^{-1}}-1 ) + \\cos\\big ( \\frac{\\pi a}{s } \\big ) ( { { \\mathbf z}_{\\mathbf 2}^{-1}}-1 ) \\big ] \\times   \\\\ &   \\bigg [ v({{\\mathbf z } } ) - \\sum_{s=[0\\,,s-1 ] \\backslash \\{a\\ } }    \\big [ \\cos\\big ( \\frac{\\pi s}{s } \\big ) ( { { \\mathbf{z_2}}}-1 )    + \\sin\\big ( \\frac{\\pi s}{s } \\big ) ( { { \\mathbf{z_1}}}-1 ) \\big ] g_s({{\\mathbf z } } )   + \\frac{\\lambda_3({{\\mathbf z}})}{\\beta_3 } \\bigg ] \\ , .    \\end{aligned}\\ ] ]    * the `` @xmath71-problem '' : * fix @xmath70 , @xmath72 , @xmath69_{l=0}^{l-1}$ ] , @xmath73_{s=0}^{s-1}$ ] , @xmath74_{s=0}^{s-1}$ ] and @xmath91 - \\frac{\\boldsymbol{\\lambda_3}}{\\beta_3 } \\bigg ) } ^2_{\\ell_2 } \\notag   \\\\ & \\qquad \\qquad \\qquad    + \\frac{\\beta_4}{2 } \\norm { { { \\mathbf v}}- \\bigg ( { { \\mathbf f}}- { { \\mathbf u}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\bigg ) } _ { \\ell_2}^2   \\big\\}\\end{aligned}\\ ] ] the solution of ( [ eq : sub : v ] ) is defined as @xmath92 with @xmath93 - \\frac{\\boldsymbol{\\lambda_3}}{\\beta_3 } \\bigg )   + \\frac{\\beta_4}{\\beta_3 + \\beta_4 } \\bigg ( { { \\mathbf f}}- { { \\mathbf u}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\bigg).\\ ] ]    * the `` @xmath70-problem '' : * fix @xmath71 , @xmath72 , @xmath69_{l=0}^{l-1}$ ] , @xmath73_{s=0}^{s-1}$ ] , @xmath74_{s=0}^{s-1}$ ] and @xmath94    we denote @xmath95 and @xmath96 as the discrete fourier transforms of @xmath97 \\ , , \\epsilon[\\boldsymbol k ] \\ , , \\lambda_4[\\boldsymbol k ] \\",
    ", , r_l[\\boldsymbol k ] $ ] and @xmath98 $ ] , respectively .",
    "this ( [ eq : sub : u ] ) is solved in the fourier domain by    @xmath99\\ ] ]    with @xmath100    \\big [ \\sin\\big ( \\frac{\\pi l}{l } \\big ) ( { { \\mathbf{z_1}}}-1 ) + \\cos\\big ( \\frac{\\pi l}{l } \\big ) ( { { \\mathbf{z_2}}}-1 ) \\big ]    \\bigg]^{-1 } \\",
    ", ,   \\\\   \\mathcal y({{\\mathbf z } } ) & =    \\beta_4 \\big [ f({{\\mathbf z } } ) - v({{\\mathbf z } } ) - \\mathcal{e}({{\\mathbf z } } ) + \\frac{\\lambda_4({{\\mathbf z}})}{\\beta_4 } \\big ]   + \\beta_1 \\sum_{l=0}^{l-1 } \\big [ \\sin \\big ( \\frac{\\pi l}{l } \\big ) ( { { \\mathbf z}_{\\mathbf 1}^{-1}}-1 ) + \\cos \\big ( \\frac{\\pi l}{l } \\big ) ( { { \\mathbf z}_{\\mathbf 2}^{-1}}-1 ) \\big ]   \\big [ r_l({{\\mathbf z } } ) + \\frac{\\lambda_{1l}({{\\mathbf z}})}{\\beta_1 } \\big ] .\\end{aligned}\\ ] ]    * the `` @xmath72-problem '' : * fix @xmath70 , @xmath71 , @xmath69_{l=0}^{l-1}$ ] , @xmath73_{s=0}^{s-1}$ ] , @xmath74_{s=0}^{s-1}$ ] and @xmath101",
    "let @xmath102 be the inverse curvelet transform @xcite .",
    "the minimization of ( [ eq : sub : e ] ) is solved by ( cf .",
    "@xcite ) @xmath103 or by the projection method with the component - wise operators @xmath104    * update lagrange multipliers * @xmath105_{l=0}^{l-1 } \\ , , \\big[\\boldsymbol{\\lambda}_{\\mathbf{2}a}\\big]_{a=0}^{s-1 }     \\ , , \\boldsymbol{\\lambda_3}\\ , ,   \\boldsymbol{\\lambda_4 } \\big ) \\in x^{l+s+2}$ ] : @xmath106 \\big )       \\\\",
    "\\boldsymbol{\\lambda}_{\\mathbf{4}}^{(t ) } & ~=~ \\boldsymbol{\\lambda}_{\\mathbf{4}}^{(t-1 ) }      ~+~ \\gamma \\beta_4 \\big ( { { \\mathbf f}}- { { \\mathbf u}}- { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}\\big )      \\end{aligned}\\ ] ]    * choice of parameters *    due to the @xmath55-norms in the minimization problem ( [ eq : dtv - dg3part_alm ] ) which corresponds to the shrinkage operator with parameters @xmath107 and @xmath108 , these are defined as @xmath109 } \\big )   \\quad \\text{and } \\quad   \\mu_2 = c_{\\mu_2 } ( \\beta_3 + \\beta_4 ) \\cdot \\max_{{{\\mathbf k}}\\in \\omega } \\big ( \\abs{t_{{\\mathbf v}}[{{\\mathbf k } } ] } \\big),\\end{aligned}\\ ] ] where @xmath110 $ ] and @xmath111 $ ] are defined in ( [ eq : sub : solution : wa ] ) and ( [ eq : sub : solution : tv ] ) , respectively .",
    "note that the choice of @xmath112 and @xmath113 is adapted to specific images .    in order to balance between the smoothing terms and the updated terms for the solutions of the @xmath114-problem in ( [ eq : sub : solution : ga ] ) , the @xmath71-problem in ( [ eq : sub : solution : v ] ) and the @xmath70-problem in ( [ eq : sub : solution : u ] ) , we choose @xmath115    the choice of @xmath116 mainly impacts the smoothness and sparsity of the texture @xmath71 . the first row of figure [ fig : dg3pd : barbara ] shows the effect of selecting the threshold @xmath42 which corresponds to a two - part decomposition , i.e. the residual image @xmath117 in ( d ) .",
    "this case also demonstrates the limitation of all two - part decomposition approaches : for this choice of @xmath116 , very small scale objects are assigned to the texture image @xmath71 in figure [ fig : dg3pd : barbara ] ( b ) which is obvious in its binarization @xmath118 shown in ( c ) . in order to remove these and to yield a smoother and sparser texture @xmath71",
    ", one can increase the value of @xmath116 , say e.g. by choosing @xmath119 .",
    "the effect of this choice can be seen in the binarized version @xmath118 in figure [ fig : dg3pd : barbara ] ( g ) and small scale objects are moved to the residual image @xmath72 in ( h ) .",
    "therefore , the value of @xmath116 defines the level of the residual  @xmath72 .",
    "as stated before , the main objective of the dg3pd model is to achieve the following three goals ( cf .",
    "section [ sec : introduction ] ) :    * goal 1 : @xmath70 contains only geometrical objects with a very smooth surface , sharp boundaries and no texture . *",
    "goal 2 : @xmath71 contains only objects with sparse oscillating patterns and @xmath71 shall be both smooth and sparse .",
    "* goal 3 : perfect reconstruction of @xmath120 , i.e. @xmath121 .    based on these criteria we compare the proposed dg3pd model in this section with the state - of - the - art methods using the original barbara image .",
    "we highlight selected regions for an improved conspicuousness of the differences between the considered methods , cf .",
    "figure [ fig : originalimage ] :    * images without noise : rudin , osher , and fatemi ( rof ) @xcite , vese and osher ( vo ) @xcite , starck , elad , and donoho ( sed ) @xcite and tv - gabor ( tvg ) by aujol _ et al .",
    "_ @xcite models .",
    "* images suffering from i.i.d .",
    "gaussian noise @xmath122 : the aujol and chambolle ( ac ) model @xcite .    for better visibility of differences between the various models ,",
    "we show decomposition results for the rof , vo , sed , tvg and dg3pd models for two magnified parts of the original image ( cf .",
    "figure [ fig : originalimage ] ( b , c ) ) in figures [ fig : comparisonmethods : barbara_crop1 ] and [ fig : comparisonmethods : barbara_crop2 ] .    to the best of our knowledge ,",
    "we observe two main differences between the compared models and the proposed dg3pd model :    * two - part decomposition instead of three - part decomposition . *",
    "quadratic penalty method ( qpm ) for solving the constrained minimization instead of alm",
    ".    * goal 1 : cartoon @xmath70 . * regarding the cartoon @xmath70",
    ", we observe that the vo and sed models still contain texture on the scarf ( cf .",
    "figure [ fig : comparisonmethods : barbara_crop1 ] ( b ) and ( c ) , respectively ) . for the sed",
    ", the cartoon @xmath70 is blurred and there are some small scale objects under the table ( cf .",
    "figure [ fig : comparisonmethods : barbara_crop2 ] ( c ) ) . comparing all five methods , vo and sed are furthest away from achieving the first goal , whereas rof and tvg generate better cartoon images in terms of smoother surfaces without texture and sharper boundaries .",
    "recently , schaeffer and osher @xcite suggested a two - part decomposition approach .",
    "note that the cartoon image by their decomposition which is shown in figure 7 ( a ) of @xcite also contains texture and does not meet the first goal .",
    "the cartoon images produced by the dg3pd method come closest to the first goal , cf .",
    "figure [ fig : comparisonmethods : barbara_crop1 ] ( i , m ) and figure [ fig : comparisonmethods : barbara_crop2 ] ( e ) .",
    "* goal 2 : texture @xmath71 . * concerning the texture @xmath71 , among the state - of - the - art methods , the decomposition by the sed model results in the sparsest texture ( cf .",
    "figure [ fig : comparisonmethods : barbara_crop1 ] ( g ) and figure [ fig : comparisonmethods : barbara_crop2 ] ( h ) ) , while the texture images of the rof , vo and tvg have more coefficients different from zero .",
    "in addition , the texture component obtained by the rof model also contains some geometry information which should have been assigned to the cartoon component , see figure [ fig : comparisonmethods : barbara_crop1 ] ( e ) and figure [ fig : comparisonmethods : barbara_crop2 ] ( f ) .",
    "the dg3pd model yields an even sparser texture than the sed model due to the @xmath123 in the minimization ( [ eq : dtv - dg3part ] ) , see the binarized versions with threshold `` 0 '' for visualization in figure [ fig : comparisonmethods : barbara_crop1 ] ( o ) or figure [ fig : dg3pd : barbara ] ( g ) .",
    "* goal 3 : reconstruction by summation of all components .",
    "* figures [ fig : comparison : barbara : penaltyalm ] and [ fig : comparison : tm20_1_1:penaltyalm ] illustrate the effects of qpm and alm .",
    "the decomposition by the rof model results in a relatively large error @xmath124 which contains geometry and texture information , see @xcite and figure [ fig : comparison : barbara : penaltyalm ] ( i ) . in the vo model ,",
    "the error @xmath125 is reduced in comparison to the rof model , but some information still remains in the error image , see figure [ fig : comparison : barbara : penaltyalm ] ( n ) . in case of the dg3pd model with the alm based approach for solving the constrained minimization , the error @xmath126 is significantly reduced and numerically the error tends to @xmath127 as the number of iterations increases . for a comparison to rof and vo using the same detail , see figure [ fig : comparison : barbara : penaltyalm ] ( o ) for a visualization of the error after 20 iterations and ( p ) after 60 iterations . the error for the whole image after 20 and 60 iterations is displayed in figure [ fig : dg3pd : barbara ] ( j ) and ( k ) , respectively . to the best of our knowledge , this effect can be explained by using alm for solving the constrained minimization instead of qpm .",
    "for more details about qpm and alm , we refer the reader to @xcite , @xcite , and chapter 3 in @xcite .    * comparison with aujol and chambolle .",
    "* figure [ fig : comparisonac ] illustrates a situation in which the image suffers from i.i.d .",
    "gaussian noise @xmath122 with @xmath128 , and compares dg3pd with the ac model @xcite for three - part decomposition .",
    "it shows that under `` heavy '' noise , our dg3pd model still meets the criteria for cartoon @xmath70 and texture @xmath71 , i.e.    * our cartoon @xmath70 contains smooth surfaces with sharp edges and no texture , cf .",
    "figure [ fig : comparisonac ] ( e ) .",
    "however , the cartoon @xmath70 from the ac model is blurry with texture on the scarf , cf . figure [ fig : comparisonac ] ( a ) . *",
    "our texture @xmath71 is sparse and smooth , cf .",
    "figure [ fig : comparisonac ] ( f ) and its binarization ( h ) . however , the texture from the ac model is not sparse , see figure [ fig : comparisonac ] ( b ) .",
    "however , there is a limitation for both methods : the noise image @xmath72 contains some pieces of information due to the value of @xmath116 which defines the level of the noise .",
    "similar to @xcite , we modify the classical threshold for curvelet coefficients , i.e. @xmath129 , with a weighting parameter @xmath130 as follows @xmath131 and @xmath132 is total number of curvelet coefficients .",
    "* summary .",
    "* we observe that the dg3pd method meets all three requirements much more closely than the other methods for images without noise , like the original barbara image . and",
    "in particular , for images with additive noise , the dg3pd method still achieves all three goals as shown in the comparison with aujol and chambolle .     and 20 iterations for the third and 60 for the fourth column , and the other parameters are the same as in figure [ fig : dg3pd : barbara ] . the relative error ( y - axis ) versus the number of iterations ( x - axis ) is illustrated in ( m ) .",
    "the first row shows that the vo and the dg3pd models can achieve good reconstructed images , cf .",
    "( b , c , d ) , in comparison with the original magnified image ( a ) . as mentioned in @xcite , the error image from the vo model ( n ) contains much less geometry and texture than the one from the rof model .",
    "however , the error image from our model is much further reduced in comparison to the vo model . after 20 iterations",
    "some pieces of information still remain in the error image , cf .",
    "( o ) . as the number of iterations increases , the error numerically tends to @xmath127 , cf .",
    "( p ) after 60 iterations .",
    ", title=\"fig:\",scaledwidth=11.0% ]     +     +   +",
    "here , we limit ourselves to consider three important applications of the dg3pd method : feature extraction , denoising and image compression .      depending on the specific field of application ,",
    "the cartoon or texture , or both can be viewed as feature images . for the application of dg3pd to fingerprints , we are especially interested in the texture image @xmath1 as a feature for subsequent processing steps like segmentation , orientation field estimation @xcite and ridge frequency estimation @xcite and fingerprint image enhancement @xcite .",
    "the first of these processing steps is to separate the foreground from the background @xcite .",
    "the foreground area ( or region - of - interest ) contains the relevant information for a fingerprint comparison .",
    "segmentation is still a challenging problem for latent fingerprints @xcite which are very low - quality fingerprints lifted from crime scenes .",
    "both the foreground and background area can contain noise on all scales , from small objects or dirt on the surface , to written or printed characters ( on paper ) and large scale objects like an arc drawn by the forensic examiner .",
    "standard fingerprint segmentation methods can not cope with this variety of noise , whereas the texture image by decomposition with the dg3pd method crops out to be an excellent feature for estimating the region - of - interest .",
    "figure [ fig : latenthowto ] depicts a detailed example of the latent fingerprint segmentation by the dg3pd decomposition . in figure",
    "[ fig : latentsegmentation ] , we show further examples of segmentation results obtained using the texture image extracted by the dg3pd method and morphological postprocessing as described in @xcite .      the dg3pd model can be used for denoising images with texture , because noise and small scale objects are moved into the residual image @xmath3 during the decomposition of @xmath4 due to the supremum norm of the curvelet coefficients of @xmath3 .",
    "therefore , the image @xmath133 can be regarded as a denoised version of @xmath4 and the degree of denoising can be steered by the choice of parameters , especially @xmath116 . for @xmath42 which is equal to two - part decomposition , we obtain the original image again . as we increase @xmath116 , more noise is driven into @xmath3 and thereby removed from @xmath134 . denoising images with texture , in particular with texture parts on different scales , is a relevant problem which we plan to address in future works .",
    "based on the dg3pd model , we propose a novel approach to image compression .",
    "the core idea is to perform image decomposition by the dg3pd method first , and subsequently to compress the three component images by three different algorithms , each particularly suited for compressing the specific type of image .",
    "this scheme can be used for lossy as well as lossless compression .      as stated in our definition of goals ,",
    "the cartoon image consists of geometric objects with a very smooth or piecewise constant surface and sharp edges .",
    "this special kind of images is high compressible and a very effective approach is based on diffusion .",
    "anisotropic diffusion @xcite is useful for many purposes in image processing e.g. fingerprint image enhancement by oriented diffusion filtering @xcite .    the basic idea of diffusion based compression is store information for only a few sparse locations which encode the edges of the cartoon image .",
    "the surface areas are inpainted using a linear or nonlinear diffusion process .",
    "please note that the cartoon image obtained by the dg3pd method is much better suited for this type of compression due to the property of sharper edges between geometric objects in comparison to the cartoon images of the other decomposition approaches .",
    "moreover , some difficulties and drawbacks of diffusion based compression for arbitrary images do not apply to this special case .",
    "in general , it is a challenging question how and where to select locations for diffusion seed points . in our case",
    ", this task is easily solvable , because of the sharp edges between in homogeneous regions in the dg3pd cartoon image .",
    "this allows for an extremely sparse selection of locations on corners and edges .",
    "image compression with edge - enhancing anisotropic diffusion ( eed ) has been studied by galic _",
    "_ @xcite and has been improved by schmaltz _",
    "compression of cartoon - like images with homogeneous diffusion has been analyzed by mainberger _",
    "a viable alternative to diffusion based compression of cartoon images is a dictionary based approach @xcite in which the dictionary is optimized for cartoon images .",
    "another very promising possibility to compress the dg3pd cartoon component is the usage of linear splines over adaptive triangulations which has been proposed in the work of demaret _ et al .",
    "_ @xcite .",
    "tailor - made solutions are available for texture image compression , and especially for compressing oscillating patterns like e.g. fingerprints .",
    "larkin and fletcher @xcite achieved a compression rate of 1:239 for a fingerprint image using amplitude and frequency modulated ( am - fm ) functions .",
    "they decompose a fingerprint image into four parts and this idea can be applied to the texture image @xmath71 obtained by the dg3pd method :    @xmath135 $ ]    each of the four components is again highly compressible and can be stored with only a few bytes ( see figure 5 in @xcite ) .",
    "this is remarkable and we would like offer another perspective on the am - fm model . storing a minutiae template can be viewed as a lossy form of fingerprint compression .",
    "the minutiae of a fingerprint are locations where ridges ( dark lines ) end or bifurcate . and a template stores the locations and directions of these minutiae .",
    "several algorithms have been proposed for reconstructing the orientation field ( of ) from a minutia template @xcite .",
    "the continuous phase @xmath136 can be derived from the unwrapped reconstructed of and the spiral phase @xmath137 directly constructed from the minutiae template . choosing appropriate values for @xmath138 and @xmath139 leads to a fingerprint image .",
    "a survey of further methods for reconstructing fingerprints from their minutiae template is given in @xcite .",
    "an alternative way of lossy fingerprint image compression is wavelet scalar quantization ( wsq ) @xcite which has been a compression standard for fingerprints used by the federal bureau of investigation in the united states .",
    "see figure [ fig : componentcompression ] ( f - h ) for application example of wsq to the texture of the barbara image .",
    "a third , very good compression possibility is dictionary learning @xcite with optimization of the dictionary for the texture component @xmath71 . for fingerprint images ,",
    "this problem has recently been studied by shao _",
    "_ @xcite .      for image compression using dg3pd , we propose the following steps in this order : first , image decomposition @xmath2 .",
    "second , a tailor - made , lossy , high compression of the cartoon component @xmath0 and the texture component @xmath1 .",
    "third , decompressing @xmath0 and @xmath1 in order to compute the compression residual image @xmath140 , where @xmath141 is the cartoon image and @xmath142 the texture image after decompression .",
    "fourth , compression of @xmath143 .    in step two and four",
    ", the term `` compression '' denotes the whole process including coefficient quantization and symbol encoding ( see @xcite for scalar quantization , huffman coding , lz77 , lzw and many other standard techniques ) .",
    "let be @xmath144 the difference between the cartoon component before and after compression , i.e. the compression error , and @xmath145 , then we can rewrite @xmath146 .",
    "hence , the residual image @xmath143 computed in step four contains the residual component @xmath3 plus the compression errors of the other two components .",
    "now , lossless compression can be achieved by lossless compression of @xmath143 .",
    "if the goal is lossy compression with a certain target quality or target compression rate , this can be achieved by adapting the lossy compression of @xmath143 accordingly .",
    "see figure [ fig : componentcompression ] for the effects of different compression rates on the decompressed cartoon @xmath141 and the decompressed texture @xmath142 .",
    "an additional advantage of decompression beginning with @xmath141 , followed by @xmath142 and finally @xmath147 is the fast generation of a preview image which mimics the effects of interlacing . in a scenario with limited bandwidth for data transmission , e.g. sending an image to a mobile phone , the user can be shown a preview based on the compressed , transmitted and decompressed @xmath0 image . during the transmission of the compressed @xmath1 and @xmath143 , the user can decide whether to continue or abort the transmission .",
    "the dg3pd model is a novel method for three - part image decomposition .",
    "we have shown that the dg3pd method achieves the goals defined in the introduction much better than other relevant image decomposition approaches .",
    "the dg3pd model lays the groundwork for applications such as image compression , denoising and feature extraction for challenging tasks such as latent fingerprint processing .",
    "we follow in the footsteps of aujol and chambolle @xcite who pioneered three - part decomposition and dg3pd generalizes their approach .",
    "we believe that three - part decomposition is the way forward to address many important problems in image processing and computer vision .",
    "@xcite asked in 2010 : `` can images be decomposed into the sum of a geometric part and a textural part ? '' our answer to that question is : no if an image contains other parts than cartoon and texture , i.e. noise or small scale objects .",
    "consider e.g. the noisy barbara image in figure  [ fig : comparisonac ]  ( d ) . if the sum of the cartoon and texture images shall reconstruct the input image @xmath4 , a two - part decomposition has to assign the noise parts either to the cartoon or to the texture component . in principle , not even the best two - part decomposition model can fully achieve both goals regarding the desired properties of the cartoon and texture component simultaneously .",
    "the solution is that noise and small scale objects which do not belong to the cartoon or texture have to be allotted to a third component .    in our future work",
    "we intend to optimize the dg3pd method for specific applications , especially image compression and latent fingerprint processing .",
    "issues for improvement include the data - driven , automatic parameter selection and the convergence rate ( can the same decomposition be achieved in fewer iterations ? ) furthermore , we plan to explore and evaluate specialized compression approaches for cartoon , texture and residual images .",
    "d.h thai is supported by the national science foundation under grant dms-1127914 to the statistical and applied mathematical sciences institute . c.",
    "gottschlich gratefully acknowledges the support of the felix - bernstein - institute for mathematical statistics in the biosciences and the niedersachsen vorab of the volkswagen foundation",
    ".    10    d.h .",
    "thai , s.  huckemann , and c.  gottschlich . filter design and performance evaluation for fingerprint image segmentation . ,",
    "january 2015 .",
    "l.  rudin , s.  osher , and e.  fatemi .",
    "nonlinear total variation based noise removal algorithms .",
    ", 60(1 - 4):259268 , november 1992 .",
    "y.  meyer . .",
    "american mathematical society , boston , ma , usa , 2001 .",
    "aujol and a.  chambolle .",
    "dual norms and image decomposition models . , 63(1):85104 , june 2005 .",
    "e.  cands , l.  demanet , d.  donoho , and l.  ying .",
    "fast discrete curvelet transforms .",
    ", 5(3):861899 , september 2006 .",
    "j.  ma and g.  plonka .",
    "the curvelet transform .",
    ", 27(2):118133 , march 2010 .",
    "d.  mumford and j.  shah .",
    "optimal approximations by piecewise smooth functions and associated variational problems . , 42(5):577685 , july 1989 .",
    "chan and l.a .",
    "active contours without edges . , 10(2):266277 , february 2001 .",
    "s.  osher and j.a .",
    "fronts propagating with curvature - dependent speed : algorithms based on hamilton - jacobi formulations .",
    ", 79(1):1249 , november 1988 .",
    "vese and s.  osher . modeling textures with total variation minimization and oscillatory patterns in image processing .",
    ", 19(1 - 3):553572 , december 2003 .",
    "vese and s.  osher .",
    "image denoising and decomposition with total variation minimization and oscillatory functions . , 20(1 - 2):718 , january 2004 .",
    "starck , m.  elad , and d.l .",
    "image decomposition via the combination of sparse representations and a variational approach .",
    ", 14(10):15701582 , october 2005 .",
    "aujol , g.  gilboa , t.  chan , and s.  osher .",
    "structure - texture image decomposition - modeling , algorithms , and parameter selection .",
    ", 67(1):111136 , april 2006 .",
    "j.  gilles",
    ". noisy image decomposition : a new structure , texture and noise model based on local adaptivity .",
    ", 28(3):285295 , july 2007 .",
    "p.  maragos and g.  evangelopoulos .",
    "leveling cartoons , texture energy markers , and image decomposition . in _ proc .",
    "mathematical morphology _ , pages 125138 , rio de janeiro , brazil , october 2007 .    c.  gottschlich .",
    "curved - region - based ridge frequency estimation and curved gabor filters for fingerprint image enhancement . , 21(4):22202227 , april 2012 .",
    "havlicek , d.s .",
    "harding , and a.c .",
    "multidimensional quasi - eigenfunction approximations and multicomponent am - fm models . , 9(2):227242 , february 2000 .",
    "larkin and p.a .",
    "fletcher . a coherent framework for fingerprint analysis : are fingerprints holograms ?",
    ", 15(14):86678677 , 2007 .",
    "a.  buades , t.m .",
    "morel , and l.a .",
    "fast cartoon + texture image filters . , 19(8):19781986 , august 2010 .",
    "p.  maurel , j .- f .",
    "aujol , and g.  peyre .",
    "locally parallel texture modeling .",
    ", 4(1):413447 , 2011 .",
    "s.  chikkerur , a.  cartwright , and v.  govindaraju .",
    "fingerprint image enhancement using stft analysis .",
    ", 40(1):198211 , 2007 .",
    "c.  gottschlich and c .- b .",
    "oriented diffusion filtering for enhancing low - quality fingerprint images .",
    ", 1(2):105113 , june 2012 .",
    "thai and c.  gottschlich .",
    "global variational method for fingerprint segmentation by three - part decomposition .",
    ", accepted .",
    "i.  bayram and m.e . kamasak . a directional total variation .",
    "in _ proc . eusipco _ , pages 265269 , bucharest , romania , august 2012 .",
    "i.  bayram and m.e .",
    "kamasak . directional total variation .",
    ", 19(12):781784 , december 2012 .",
    "h.  zhang and y.  wang .",
    "edge adaptive directional total variation .",
    ", pages 12 , november 2013 .",
    "h.  schaeffer and s.  osher . a low patch - rank interpretation of texture . ,",
    "6(1):226262 , february 2013 .",
    "r.  courant .",
    "variational methods for the solution of problems of equilibrium and vibrations . , 49(1):123 , 1943 .",
    "s.  boyd , n.  parikh , e.  chu , b.  peleato , and j.  eckstein . distributed optimization and statistical learning via the alternating direction method of multipliers .",
    "3(1):1122 , january 2011 .    m.  fortin and r.  glowinski . .",
    "north - holland pub . ,",
    "amsterdam , netherlands , 1983 .    c.  gottschlich , p.  mihilescu , and a.  munk .",
    "robust orientation field estimation and extrapolation using semilocal line sensors . , 4(4):802811 , december 2009 .",
    "a.  sankaran , m.  vatsa , and r.  singh .",
    "latent fingerprint matching : a survey .",
    ", 2:9821004 , september 2014 .",
    "j.  weickert . .",
    "teubner , stuttgart , germany , 1998 .",
    "i.  galic , j.  weickert , m.  welk , a.  bruhn , a.  belyaev , and h .-",
    "image compression with anisotropic diffusion .",
    ", 31(2 - 3):255269 , july 2008 .",
    "c.  schmaltz , p.  peter , m.  mainberger , f.  ebel , j.  weickert , and a.  bruhn .",
    "understanding , optimising , and extending data compression with anisotropic diffusion .",
    ", 108(3):222240 , july 2014 .",
    "m.  mainberger , a.  bruhn , j.  weickert , and s.  forchhammer .",
    "edge - based compression of cartoon - like images with homogeneous diffusion . ,",
    "44(9):18591873 , september 2011 .",
    "m.  elad and m.  aharon .",
    "image denoising via sparse and redundant representations over learned dictionaries . , 15(12):37363745 ,",
    "december 2006 .",
    "l.  demaret , n.  dyn , and a.  iske .",
    "image compression by linear splines over adaptive triangulations .",
    ", 86(7):16041616 , july 2006 .",
    "l.  oehlmann , s.  huckemann , and c.  gottschlich .",
    "performance evaluation of fingerprint orientation field reconstruction methods .",
    "in _ proc . iwbf _ , pages 16 , gjovik , norway , march 2015 .    c.  gottschlich and s.  huckemann . separating the real from the synthetic : minutiae histograms as fingerprints of fingerprints .",
    ", 3(4):291301 , december 2014 .",
    "t.  hopper , c.  brislawn , and j.  bradley .",
    "gray - scale fingerprint image compression specification .",
    "technical report , federal bureau of investigation , february 1993 .",
    "g.  shao , y.  wu , a.  yong , x.  liu , and t.  guo .",
    "fingerprint compression based on sparse representation .",
    ", 23(2):489501 , february 2014 .",
    "d.  salomon . .",
    "springer , london , uk , fourth edition edition , 2007 .",
    "[ alg : dg3pd ]      @xmath148   \\big [ \\sin \\frac{\\pi a}{s } ( { { \\mathbf{z_1}}}- 1 ) + \\cos \\frac{\\pi a}{s } ( { { \\mathbf{z_2}}}- 1 ) \\big ]   \\bigg]^{-1 }   \\ , ,   \\\\   & \\mathcal b({{\\mathbf z } } ) ~=~   \\beta_2 \\big [ w_a({{\\mathbf z } } )   + \\frac{\\lambda_{2a}({{\\mathbf z } } ) } { \\beta_2 } \\big ]   ~+~ \\beta_3 \\big [ \\sin\\big ( \\frac{\\pi a}{s } \\big ) ( { { \\mathbf z}_{\\mathbf 1}^{-1}}-1 ) + \\cos\\big ( \\frac{\\pi a}{s } \\big ) ( { { \\mathbf z}_{\\mathbf 2}^{-1}}-1 ) \\big ] \\times   \\\\ &   \\bigg [ v({{\\mathbf z } } ) - \\sum_{s=[0\\,,s-1 ] \\backslash \\{a\\ } }   \\big [ \\cos\\big ( \\frac{\\pi s}{s } \\big ) ( { { \\mathbf{z_2}}}-1 )   + \\sin\\big ( \\frac{\\pi s}{s } \\big ) ( { { \\mathbf{z_1}}}-1 ) \\big ] g_s({{\\mathbf z } } )   + \\frac{\\lambda_3({{\\mathbf z}})}{\\beta_3 } \\bigg ] \\ , ,   \\\\   & \\mathcal x({{\\mathbf z } } ) =   \\bigg [ \\beta_4 \\mathbf{1_{mn } } + \\beta_1 \\sum_{l=0}^{l-1 } \\big [ \\sin\\big ( \\frac{\\pi l}{l } \\big ) ( { { \\mathbf z}_{\\mathbf 1}^{-1}}- 1 )    + \\cos\\big ( \\frac{\\pi l}{l } \\big ) ( { { \\mathbf z}_{\\mathbf 2}^{-1}}-1 ) \\big ]   \\big [ \\sin\\big ( \\frac{\\pi l}{l } \\big ) ( { { \\mathbf{z_1}}}-1 ) + \\cos\\big ( \\frac{\\pi l}{l } \\big ) ( { { \\mathbf{z_2}}}-1 ) \\big ]   \\bigg]^{-1 } \\ , ,   \\\\   & \\mathcal y({{\\mathbf z } } ) =   \\beta_4 \\big [ f({{\\mathbf z } } ) - v({{\\mathbf z } } ) - \\mathcal{e}({{\\mathbf z } } ) + \\frac{\\lambda_4({{\\mathbf z}})}{\\beta_4 } \\big ]   + \\beta_1 \\sum_{l=0}^{l-1 } \\big [ \\sin \\big ( \\frac{\\pi l}{l } \\big ) ( { { \\mathbf z}_{\\mathbf 1}^{-1}}-1 ) + \\cos \\big",
    "( \\frac{\\pi l}{l } \\big ) ( { { \\mathbf z}_{\\mathbf 2}^{-1}}-1 ) \\big ]   \\big [ r_l({{\\mathbf z } } ) + \\frac{\\lambda_{1l}({{\\mathbf z}})}{\\beta_1 } \\big ] .\\end{aligned}\\ ] ] * choice of parameters * @xmath149 } \\big ) \\,,~   \\mu_2 = c_{\\mu_2 } ( \\beta_3 + \\beta_4 ) \\cdot \\max_{{{\\mathbf k}}\\in \\omega } \\big ( \\abs{t_{{\\mathbf v}}[{{\\mathbf k } } ] } \\big )   \\text {   and   }   \\beta_2 = c_2 \\beta_3 \\ , , \\beta_3 = \\frac{\\theta}{1 - \\theta } \\beta_4 \\ , , \\beta_1 = c_1 \\beta_4.\\end{aligned}\\ ] ]"
  ],
  "abstract_text": [
    "<S> we consider the task of image decomposition and we introduce a new model coined directional global three - part decomposition ( dg3pd ) for solving it . as key ingredients of the dg3pd model </S>",
    "<S> , we introduce a discrete multi - directional total variation norm and a discrete multi - directional g - norm . </S>",
    "<S> using these novel norms , the proposed discrete dg3pd model can decompose an image into two parts or into three parts . </S>",
    "<S> existing models for image decomposition by vese and osher , by aujol and chambolle , by starck et al . , and </S>",
    "<S> by thai and gottschlich are included as special cases in the new model . </S>",
    "<S> decomposition of an image by dg3pd results in a cartoon image , a texture image and a residual image . </S>",
    "<S> advantages of the dg3pd model over existing ones lie in the properties enforced on the cartoon and texture images . </S>",
    "<S> the geometric objects in the cartoon image have a very smooth surface and sharp edges . the texture image yields oscillating patterns on a defined scale which is both smooth and sparse . </S>",
    "<S> moreover , the dg3pd method achieves the goal of perfect reconstruction by summation of all components better than the other considered methods . </S>",
    "<S> relevant applications of dg3pd are a novel way of image compression as well as feature extraction for applications such as latent fingerprint processing and optical character recognition . </S>"
  ]
}