{
  "article_text": [
    "given a set of skill requirements ( called task @xmath0 ) , a set of experts who have expertise in one or more skill , along with a social or professional network of the experts , the team formation problem is to identify a competent and highly collaborative team .",
    "this problem in the context of a social network was first introduced by @xcite and has attracted recent interest in the data mining community @xcite .",
    "a closely related and well - studied problem in operations research is the assignment problem . here ,",
    "given a set of agents and a set of tasks , the goal is to find an agent - task assignment minimizing the cost of the assignment such that exactly one agent is assigned to a task and every task is assigned to some agent .",
    "this problem can be modeled as a maximum weight matching problem in a weighted bipartite graph .",
    "in contrast to the assignment problem , the team formation problem considers the underlying social network , which for example models the previous collaborations among the experts , while forming teams .",
    "the advantage of using such a social network is that the teams that have worked together previously are expected to have less communication overhead and work more effectively as a team .",
    "the criteria explored in the literature so far for measuring the effectiveness of teams are based on the shortest path distances , density , and the cost of the minimum spanning tree of the subgraph induced by the team . here",
    "the density of a subgraph is defined as the ratio of the total weight of the edges within the subgraph over the size of the subgraph .",
    "teams that are well connected have high density values .",
    "methods based on minimizing diameter ( largest shortest path between any two vertices ) or cost of the spanning tree have the main advantage that the teams they yield are always connected ( provided the underlying social network is connected )",
    ". however , diameter or spanning tree based objectives are not robust to the changes ( addition / deletion of edges ) in the social network .",
    "as demonstrated in @xcite using various performance measures , the density based objective performs better in identifying well connected teams . on the other hand",
    ", maximizing density may give a team whose subgraph is disconnected .",
    "this happens especially when there are small groups of people who are highly connected with each other but are sparsely connected to the rest of the graph .",
    "existing methods make either strong assumptions on the problem that do not hold in practice or are not capable of incorporating more intuitive constraints such as bounding the total size of the team .",
    "the goal of this paper is to consider the team formation problem in a more realistic setting and present a novel formulation based on a generalization of the densest subgraph problem .",
    "our formulation allows modeling of many realistic requirements such as ( i ) inclusion of a designated team leader and/or a group of given experts , ( ii ) restriction on the size or more generally cost of the team ( iii ) enforcing _ locality _ of the team , e.g. , in a geographical sense or social sense , etc .",
    "in fact most of the future directions pointed out by @xcite are covered in our formulation .",
    "the first work @xcite in the team formation problem in the presence of a social network presents greedy algorithms for minimizing the diameter and the cost of the minimum spanning tree ( mst ) induced by the team .",
    "while the greedy algorithm for minimizing the diameter has an approximation guarantee of two , no guarantee is proven for the mst algorithm . however ,",
    "@xcite impose the strong assumption that a skill requirement of a task can be fulfilled by a single person ; thus a more natural requirement such as `` at least @xmath4 experts of skill @xmath5 are needed for the task '' can not be handled by their method .",
    "this shortcoming has been addressed in @xcite , which presents a 2-approximation algorithm for a slightly more general problem that can accommodate the above requirement .",
    "however , both algorithms can not handle an upper bound constraint on the team size . on the other hand ,",
    "the solutions obtained by all these algorithms ( including the mst algorithm ) can be shown to be connected subgraphs if the underlying social graph is connected .",
    "two new formulations are proposed in @xcite based on the shortest path distances between the nodes of the graph .",
    "the first formulation assumes that experts from each skill have to communicate with every expert from the other skill and thus minimizes the sum of the pairwise shortest path distances between experts belonging to different skills .",
    "they prove that this problem is np - hard and provide a greedy algorithm with an approximation guarantee of two .",
    "the second formulation , solvable optimally in polynomial time , assumes that there is a designated team leader who has to communicate with every expert in the team and minimizes the sum of the distances only to the leader .",
    "the main shortcoming of this work is its restrictive assumption that _ exactly _ one expert is sufficient for each skill , which implies that the size of the found teams is always upper bounded by the number of skills in the given task , noting that an expert is allowed to have multiple skills .",
    "they exploit this assumption and ( are the first to ) produce top-@xmath4 teams that can perform the given task .",
    "however , although based on the shortest path distances , neither of the two formulations does guarantee that the solution obtained is connected .",
    "in contrast to the distance or diameter based cost functions , @xcite explore the usefulness of the density based objective in finding strongly connected teams . using various performance measures ,",
    "the superiority of the density based objective function over the diameter objective is demonstrated .",
    "the setting considered in @xcite is the most general one until now but the resulting problem is shown to be np hard . the greedy algorithms that they propose have approximation guarantees ( of factor 3 ) for two special cases .",
    "the teams found by their algorithms are often quite large and it is not straightforward to modify their algorithms to integrate an additional upper bound constraint on the team size .",
    "another disadvantage is that subgraphs that maximize the density under the given constraints need not necessarily be connected .",
    "recently @xcite considered an _",
    "team formation problem where tasks arrive in a sequential manner and teams have to be formed minimizing the ( maximum ) load on any expert across the tasks while bounding the coordination cost ( a free parameter ) within a team for any given task .",
    "approximation algorithms are provided for two variants of coordinate costs : diameter cost and steiner cost ( cost of the minimum steiner tree where the team members are the terminal nodes ) .",
    "while this work focusses more on the load balancing aspect , it also makes the strong assumption that a skill is covered by the team if there exists at least one expert having that skill .",
    "all of the above methods allow only binary skill level , i.e. , an expert has a skill level of either one or zero .",
    "we point out that many methods have been developed in the operations research community for the team formation problem , @xcite , but none of them explicitly considers the underlying social or professional connections among the experts .",
    "there is also literature discussing the social aspects of the team formation @xcite and their influence on the evolution of communities , e.g. , @xcite .",
    "now we formally define the _ team formation _ problem that we address in this paper .",
    "let @xmath1 be the set of @xmath6 experts and @xmath7 be the weighted , undirected graph reflecting the relationship or previous collaboration of the experts @xmath1 .",
    "then non - negative , symmetric weight @xmath8 connecting two experts @xmath9 and @xmath10 reflects the level of compatibility between them .",
    "the set of skills is given by @xmath11 .",
    "each expert is assumed to possess one or more skills .",
    "the non - negative matrix @xmath12 specifies the skill levels of all experts in each skill .",
    "note that we define the skill level on a continuous scale . if an expert @xmath9 does not have skill @xmath10 , then @xmath13 .",
    "moreover , we use the notation @xmath14 for the @xmath15th column of @xmath16 , i.e. the vector of skill levels corresponding to skill @xmath10 . a task @xmath0",
    "is given by the set of triples @xmath17 , where @xmath18 , specifying that at least @xmath19 and at most @xmath20 of skill @xmath21 is required to finish the given task .",
    "+ * generalized team formation problem . * given a task @xmath0 , the generalized team formation problem is defined as finding a team @xmath3 of experts maximizing the _ collaborative compatibility _ and satisfying the following constraints :    * * inclusion of a specified group : * a predetermined group of experts @xmath22 should be in @xmath23 . *",
    "* skill requirement : * at least @xmath19 and at most @xmath20 of skill @xmath21 is required to finish the task @xmath0 . * * bound on the team size : * the size of the team should be smaller than or equal to @xmath24 , i.e. , @xmath25 . *",
    "* budget constraint : * total budget for finishing the task is bounded by @xmath26 , i.e. , @xmath27 , where @xmath28 is the cost incurred on expert @xmath9 . *",
    "* distance based constraint : * the distance ( measured according to some non - negative , symmetric function , @xmath29 ) between any pair of experts in @xmath23 should not be larger than @xmath30 , i.e. , @xmath31 .",
    "* discussion of our generalized constraints . * in contrast to existing methods , we also allow an upper bound on each skill and on the total team size . if the skill matrix is only allowed to be binary as in previous work , this translates into upper and lower bounds on the number of experts required for each skill . using vertex weights",
    ", we can in fact encode more generic constraints , e.g. , having a limit on the total budget of the team .",
    "it is not straightforward to extend existing methods to include any upper bound constraints .",
    "up to our knowledge we are the first to integrate upper bound constraints , in particular on the size of the team , into the team formation problem .",
    "we think that the latter constraint is essential for realistic team formation .",
    "our general setting also allows a group of experts around whom the team has to be formed .",
    "this constraint often applies as the team leader is usually fixed before forming the team .",
    "another important generalization is the inclusion of _ distance _",
    "constraints for any general distance function .",
    "such a constraint can be used to enforce locality of the team e.g. in a geographical sense ( the distance could be travel time ) or social sense ( distance in the network ) . another potential application",
    "are mutual incompatibilities of team members e.g.on a personal level , which can be addressed by assigning a high distance to experts who are mutually incompatible and thus should not be put together in the same team .",
    "we emphasize that all constraints considered in the literature are special instances of the above constraint set . + * measure of collaborative compatiblity . * in this paper we use as a measure of collaborative compatibility a generalized form of the density of subgraphs , defined as @xmath32 where @xmath33 is the non - negative weight of the edge between @xmath9 and @xmath10 and @xmath34 is defined as @xmath35 , with @xmath36 being the positive weight of the vertex @xmath9 .",
    "we recover the original density formulation , via @xmath37 .",
    "we use the relation , @xmath38 , where @xmath39 is the degree of vertex @xmath9 and @xmath40 . + * discussion of density based objective . * as pointed out in @xcite , the density based objective possesses useful properties like strict monotonicity and robustness . in case of the density based objective , if an edge gets added ( because of a new collaboration ) or deleted ( because of newly found incompatibility ) the density of the subgraphs involving this edge necessarily increases resp.decreases , which is not true for the diameter based objective .",
    "in contrast to density based objective , the impact of small changes in graph structure is more severe in the case of diameter objective @xcite .",
    "the generalized density that we use here leads to further modeling freedom as it enables to give weights to the experts according to their expertise . by giving smaller weight to those with high expertise",
    ", one can obtain solutions that not only satisfy the given skill requirements but also give preference to the more competent team members ( i.e.the ones having smaller weights )",
    ". + * problem formulation . * using the notation introduced above , an instance of the team formation problem based on the generalized density can be formulated as @xmath41 note that the upper bound constraints on the team size and the budget can be rewritten as skill constraints and can be incorporated into the skill matrix @xmath16 accordingly .",
    "thus , without loss of generality , we omit the budget and size constraints from now on , for the sake of brevity .",
    "moreover , since @xmath42 is required to be part of the solution , we can assume that @xmath43 , otherwise the above problem is infeasible .",
    "the distance constraint also implies that any @xmath44 for which @xmath45 , for some @xmath46 , can not be a part of the solution .",
    "thus , we again assume wlog that there is no such @xmath44 ; otherwise such vertices can be eliminated without changing the solution of problem .",
    "+ our formulation is a generalized version of the classical densest subgraph problem ( dsp ) , which has many applications in graph analysis , e.g. , see @xcite .",
    "the simplest version of dsp is the problem of finding a densest subgraph ( without any constraints on the solution ) , which can be solved optimally in polynomial time @xcite .",
    "the densest-@xmath4-subgraph problem , which requires the solution to contain exactly @xmath4 vertices , is a notoriously hard problem in this class and has been shown not to admit a polynomial time approximation scheme @xcite .",
    "recently , it has been shown that the densest subgraph problem with an upper bound on the size is as hard as the densest-@xmath4-subgraph problem @xcite .",
    "however , the densest subgraph problem with a lower bound constraint has a 2-approximation algorithm @xcite .",
    "it is based on solving a sequence of unconstrained densest subgraph problems .",
    "they also show that there exists a linear programming relaxation for this problem achieving the same approximation guarantee .",
    "recently @xcite considered the following generalized version of the densest subgraph problem with lower bound constraints in the context of team formation problem : @xmath47 where @xmath16 is the _ binary _ skill matrix .",
    "they extend the greedy method of @xcite and show that it achieves a 3-approximation guarantee for some special cases of this problem .",
    "@xcite recently improved the approximation guarantee of the greedy algorithm of @xcite for problem ( [ eq : teamproblb ] ) to a factor 2 .",
    "the time complexity of this greedy algorithm is @xmath48 , where @xmath6 is the number of experts and @xmath49 is the minimum number of experts required . + * direct integration of subset constraint .",
    "* the subset constraint can be integrated into the objective by directly working on the subgraph @xmath50 induced by the vertex set @xmath51 .",
    "note that any @xmath52 that contains @xmath42 can be written as @xmath53 , for @xmath54 .",
    "we now reformulate the team formation problem on the subgraph @xmath50 .",
    "we introduce the notation @xmath55 , and we assume wlog that the first @xmath56 entries of @xmath1 are the ones in @xmath57 . the terms in problem (",
    "[ eq : teamprob ] ) can be rewritten as @xmath58 moreover , note that we can write : @xmath59 , where @xmath60 denotes the degree of vertex @xmath9 restricted to the subset @xmath42 in the original graph . using the abbreviations , @xmath61 , @xmath62 , @xmath63 , we rewrite the team formation problem as @xmath64 where for all @xmath65",
    ", the bounds were updated as @xmath66 .",
    "note that here we already used the assumption : @xmath67 .",
    "the constraint , @xmath68 , has been introduced for technical reasons required for the formulation of the continuous problem in section [ sec : equiv_cont_prob ] .",
    "the equivalence of problem to follows by considering either @xmath42 ( if feasible ) or the set @xmath69 , where @xmath70 is an optimal solution of , depending on whichever has higher density .    to the best of our knowledge there is no greedy algorithm with an approximation guarantee to solve problem ( [ eq : teamprobsim ] ) . instead of designing a greedy approximation algorithm for this discrete optimization problem",
    ", we derive an _",
    "equivalent _ continuous optimization problem in section [ sec : forte ] .",
    "that is , we reformulate the discrete problem in continuous space while preserving the optimality of the solutions of the discrete problem .",
    "the rationale behind this approach is that the continuous formulation is more flexible and allows us to choose from a larger set of methods for its solution than for the discrete one .",
    "although the resulting continuous problem is as hard as the original discrete problem , recent progress in continuous optimization @xcite allow us to find a locally optimal solution very efficiently .",
    "in this section we present our method , _ formation of realistic teams _ ( , for short ) to solve the team formation problem , which is rewritten as , using the continuous relaxation .",
    "we derive in three steps :    1 .",
    "derive an equivalent unconstrained discrete problem ( [ eq : teamprobuncstr ] ) of the team formation problem ( [ eq : teamprobsim ] ) via an _ exact penalty _ approach .",
    "2 .   derive an equivalent continuous relaxation ( [ eq : teamprobcont ] ) of the unconstrained problem by using the concept of _ lovasz extensions_. 3 .",
    "compute the solution of the continuous problem ( [ eq : teamprobcont ] ) using the recent method ratiodca from _",
    "fractional programming_.      a general technique in constrained optimization is to transform the constrained problem into an equivalent unconstrained problem by adding to the objective a penalty term , which is controlled by a parameter @xmath71 .",
    "the penalty term is zero if the constraints are satisfied at the given input and strictly positive otherwise .",
    "the choice of the regularization parameter @xmath72 influences the tradeoff between satisfying the constraints and having a low objective value .",
    "large values of @xmath72 tend to enforce the satisfaction of constraints . in the following",
    "we show that for the team formation problem ( [ eq : teamprobsim ] ) there exists a value of @xmath72 that guarantees the satisfaction of all constraints .",
    "+ let us define the penalty term for constraints of the team formation problem ( [ eq : teamprobsim ] ) as @xmath73 note that the above penalty function is zero only when @xmath74 satisfies the constraints ; otherwise it is strictly positive and increases with increasing infeasibility .",
    "the special treatment of the empty set is again a technicality required later for the lovasz extensions , see section [ sec : equiv_cont_prob ] .",
    "for the same reason , we also replace the constant terms @xmath75 and @xmath76 in ( [ eq : teamprobsim ] ) by @xmath77 and @xmath78 respectively , where @xmath79 and @xmath80 .",
    "+ the following theorem shows that there exists an unconstrained problem equivalent to the constrained optimization problem ( [ eq : teamprobsim ] ) .",
    "[ thm : teamprobuncstr ] the constrained problem ( [ eq : teamprobsim ] ) is equivalent to the unconstrained problem @xmath81 for @xmath82 , where @xmath83 is any feasible set of problem ( [ eq : teamprobsim ] ) such that @xmath84 and @xmath85 is the minimum value of infeasibility , i.e. , @xmath86 , if @xmath74 is infeasible .",
    "we define @xmath87 .",
    "note that maximizing ( [ eq : teamprobsim ] ) is the same as minimizing @xmath88 subject to the constraints of ( [ eq : teamprobsim ] ) . for any feasible subset @xmath74 ,",
    "the objective of ( [ eq : teamprobuncstr ] ) is equal to @xmath88 , since the penalty term is zero .",
    "thus , if we show that _ all _ minimizers of ( [ eq : teamprobuncstr ] ) satisfy the constraints then the equivalence follows .",
    "suppose , for the sake of contradiction , that @xmath89 , if @xmath90 ) is a minimizer of ( [ eq : teamprobuncstr ] ) and that @xmath91 is infeasible for problem ( [ eq : teamprobsim ] ) .",
    "since @xmath92 and @xmath93 , we have under the given condition on @xmath72 , @xmath94 which leads to a contradiction because the last term is the objective value of ( [ eq : teamprobuncstr ] ) at @xmath83",
    ".      we will now derive a tight continuous relaxation of problem ( [ eq : teamprobuncstr ] ) .",
    "this will lead us to a minimization problem over @xmath95 , which then can be handled more easily than the original discrete problem .",
    "the connection between the discrete and the continuous space is achieved via thresholding . given a vector @xmath96",
    ", one can define the sets @xmath97 by thresholding @xmath98 at the value @xmath99 . in order to go from functions on sets to functions on continuous space , we make use of the concept of lovasz extensions .",
    "( lovasz extension)[def : lovasz ] let @xmath100 be a set function with @xmath101 , and let @xmath102 be ordered in ascending order @xmath103 .",
    "the lovasz extension @xmath104 of @xmath105 is defined by @xmath106    note that @xmath107 for all @xmath108 , i.e.@xmath109 is indeed an extension of @xmath105 from @xmath110 to @xmath111 ( @xmath112 ) . in the following , given a set function @xmath113 , we will denote its lovasz extension by @xmath109 .",
    "the explicit forms of the lovasz extensions used in the derivation will be dealt with in section [ sec : algo ] .    in the following theorem",
    "we show the equivalence for [ eq : teamprobsim ] .",
    "a more general result showing equivalence for fractional set programs can be found in @xcite .",
    "[ thm : teamprobcont ] the unconstrained discrete problem ( [ eq : teamprobuncstr ] ) is equivalent to the continuous problem @xmath114 for any @xmath115 .",
    "moreover , optimal thresholding of a minimizer @xmath116 , @xmath117 yields a set @xmath70 that is optimal for problem ( [ eq : teamprobuncstr ] ) .",
    "let @xmath118 .",
    "then we have @xmath119 where in the first step we used the fact that @xmath120 and @xmath121 are extensions of @xmath122 and @xmath123 , respectively .",
    "below we first show that the above inequality also holds in the other direction , which then establishes that the optimum values of both problems are the same .",
    "the proof of the reverse direction will also imply that a set minimizer of the problem ( [ eq : teamprobuncstr ] ) can be obtained from any minimizer @xmath124 of ( [ eq : teamprobcont ] ) via optimal thresholding .",
    "+ we first show that the optimal thresholding of any @xmath125 yields a set @xmath74 such that @xmath126 has an objective value at least as good as the one of @xmath98 .",
    "this holds because @xmath127 the third step follows from the fact that @xmath98 is non - negative ( @xmath128 ) and ordered in ascending order , i.e. , @xmath129 .",
    "since @xmath130 is non - negative , the final step implies that @xmath131 thus we have @xmath132    from inequality ( [ eq : optthres ] ) , it follows that optimal thresholding of @xmath124 yields a set that is a minimizer of problem ( [ eq : teamprobuncstr ] ) .",
    "the team formation problem ( [ eq : teamprobsim ] ) is equivalent to the problem ( [ eq : teamprobcont ] ) if @xmath72 is chosen according to the condition given in theorem [ thm : teamprobuncstr ] .",
    "this directly follows from theorems [ thm : teamprobuncstr ] and [ thm : teamprobcont ] .",
    "while the continuous problem is as hard as the original discrete problem , recent ideas from continuous optimization @xcite allow us to derive in the next section an algorithm for obtaining locally optimal solutions very efficiently .",
    "we now describe an algorithm for ( approximately ) solving the continuous optimization problem ( [ eq : teamprobcont ] ) .",
    "the idea is to make use of the fact that the fractional optimization problem ( [ eq : teamprobcont ] ) has a special structure : as we will show in this section , it can be written as a special ratio of difference of convex ( d.c . ) functions , i.e. it has the form @xmath133 where the functions @xmath134 and @xmath135 are positively one - homogeneous convex functions is said to be positively one - homogeneous if @xmath136 . ] and numerator and denominator are nonnegative .",
    "this reformulation then allows us to use a recent first order method called ratiodca @xcite .    in order to find the explicit form of the convex functions , we first need to rewrite the penalty term as @xmath137 , where @xmath138 using this decomposition of @xmath139",
    ", we can now write down the functions @xmath134 and @xmath135 as @xmath140 where @xmath141 , @xmath142 , @xmath143 denotes the lovasz extension of @xmath144 , and @xmath145    using the functions @xmath134 and @xmath135 defined above , the problem ( [ eq : teamprobcont ] ) can be rewritten in the form .",
    "the functions @xmath134 and @xmath135 are convex and positively one - homogeneous , and @xmath146 and @xmath147 are nonnegative .",
    "the denominator of is given as @xmath148 and the numerator is given as @xmath149 using prop.2.1 in @xcite and the decomposition of @xmath139 introduced earlier in this section , we can decompose @xmath150 .",
    "the lovasz extension of @xmath151 is given as @xmath152 and let @xmath143 denote the lovasz extension of @xmath144 ( an explicit form is not necessary , as shown later in this section ) .",
    "the equality between and then follows by simple rearranging of the terms .",
    "the nonnegativity of the functions @xmath153 and @xmath154 follows from the nonnegativity of denominator and numerator of and the definition of the lovasz extension .",
    "moreover , the lovasz extensions of any set function is positively one - homogeneous @xcite .",
    "finally , the convexity of @xmath155 and @xmath156 follows as they are a non - negative combination of the convex functions @xmath157 and @xmath158 for some @xmath159 .",
    "the function @xmath160 is well - known to be convex @xcite . to show the convexity of @xmath161",
    ", we will show that the function @xmath144 is submodular is submodular if for all @xmath162 , @xmath163 .",
    "the convexity then follows from the fact that a set function is submodular if and only if its lovasz extension is convex @xcite . for the proof of the submodularity of the first two sums one uses the fact that the pointwise minimum of a constant and a increasing submodular function is again submodular .",
    "writing @xmath164 , the last sum can be written as @xmath165 . using @xmath166 ,",
    "we can write its lovasz extension as @xmath167 which is a sum of a linear term and a convex term .    the reformulation of the problem in the form enables us to apply a modification of the recently proposed ratiodca @xcite , a method for the _ local _ minimization of objectives of the form on the whole @xmath95 .",
    "@xmath168 , @xmath169 @xmath170 + @xmath171 , @xmath172 @xmath173 @xmath174    given an initialization @xmath175 , the above algorithm solves a sequence of convex optimization problems ( line 3 ) .",
    "note that we do not need an explicit description of the terms @xmath176 and @xmath177 , but only elements of their sudifferential @xmath178 resp . @xmath179 .",
    "the explicit forms of the subgradients are given in the appendix .",
    "the convex problem ( line 3 ) then has the form @xmath180 where @xmath181 .",
    "note that is a _ non - smooth _ problem .",
    "however , there exists an equivalent smooth dual problem , which we give below .",
    "[ lem : inner_problem ] the problem is equivalent to    @xmath182    where @xmath183 with @xmath184 , @xmath185 denotes the projection on the positive orthant and @xmath186 is the simplex @xmath187 .",
    "first we use the homogenity of the objective in the inner problem to eliminate the norm constraint .",
    "this yields the equivalent problem @xmath188 we derive the dual problem as follows : @xmath189 where @xmath184 .",
    "the optimization over @xmath190 has the solution @xmath191 plugging @xmath190 into the objective and using that @xmath192 , we obtain the result",
    ".    the smooth dual problem can be solved very efficiently using recent scalable first order methods like fista @xcite , which has a guaranteed convergence rate of @xmath193 , where @xmath4 is the number of steps done in fista .",
    "the main part in the calculation of fista consists of a matrix - vector multiplication . as the social network is typically sparse , this operation costs @xmath194 , where @xmath56 is the number of non - zeros of @xmath195 .",
    "ratiodca @xcite , produces a strictly decreasing sequence @xmath196 , i.e. , @xmath197 , or terminates .",
    "this is a typical property of fast local methods in non - convex optimization .",
    "moreover , the convex problem need not be solved to full accuracy ; we can terminate the convex problem early , if the current @xmath196 produces already sufficent descent in @xmath198 .",
    "as the number of required steps in the ratiodca typically ranges between 5 - 20 , the full method scales to large networks .",
    "note that convergence to the global optimum of ( [ eq : fracset ] ) can not be guaranteed due to the non - convex nature of the problem . however , we have the following quality guarantee for the team formation problem .",
    "[ th : quality - guarantee ] let @xmath83 be a feasible set for the problem and @xmath72 is chosen as in theorem [ thm : teamprobuncstr ] .",
    "let @xmath199 denote the result of ratiodca after initializing with the vector @xmath200 , and let @xmath201 denote the set found by optimal thresholding of @xmath199 .",
    "either ratiodca terminates after one iteration , or produces @xmath201 which satisfies all the constraints of the team formation problem ( [ eq : teamprobsim ] ) and @xmath202    ratiodca generates a decreasing sequence @xmath203 such that @xmath197 until it terminates @xcite .",
    "we have @xmath204 , if the algorithm does not stop in one step . as shown in theorem ( [ thm : teamprobcont ] ) optimal thresholding of @xmath205 yields a set @xmath206 that achieves smaller objective on the corresponding set function .",
    "since the chosen value of @xmath72 guarantees the satisfaction of the constraints , @xmath207 has to be feasible .",
    "recall that our team formation problem based on the density objective is rewritten as the following gdsp after integrating the subset constraint : @xmath208 note that here we do not require the additional constraint , @xmath68 , that we added to . in this section",
    "we show that there exists a linear programming ( lp ) relaxation for this problem .",
    "the lp relaxation can be solved optimally in polynomial time and provides an upper bound on the optimum value of gdsp .",
    "in practice such an upper bound is useful to check the quality of the solutions found by approximation algorithms . +    the following lp is a relaxation of the generalized densest subgraph problem ( [ eq : teamprobsim2 ] ) .",
    "@xmath209 where @xmath210 , @xmath211 is the set of edges induced by @xmath212 .",
    "the following problem is equivalent to ( [ eq : teamprobsim2 ] ) , because ( i ) for every feasible set @xmath74 of , there exist corresponding feasible @xmath213 given by @xmath214 , @xmath215 , with the same objective value and ( ii ) an optimal solution of the following problem always satisfies @xmath216 .",
    "@xmath217    relaxing the integrality constraints and using the substitution , @xmath218 and @xmath219 , we obtain the relaxation : @xmath220    since this problem is invariant under scaling , we can fix the scale by setting the denominator to 1 , which yields the equivalent lp stated in the theorem .",
    "note that the solution @xmath124 of the lp ( [ eq : lp ] ) is , in general , not integral , i.e. , @xmath221 .",
    "one can use standard techniques of randomized rounding or optimal thresholding to derive an integral solution from @xmath124 .",
    "however , the resulting integral solution may not necessarily give a subset that satisfies the constraints of .",
    "in the special case when there are only lower bound constraints , i.e. , problem ( [ eq : teamproblb ] ) , one can obtain a feasible set @xmath74 for problem ( [ eq : teamproblb ] ) by thresholding @xmath124 ( see ) according to the objective of .",
    "this is possible in this special case because there is always a threshold @xmath222 which yields a non - empty subset @xmath223 ( in the worst case the full set @xmath212 ) satisfying all the lower bound constraints . in our experiments on problem , we derived a feasible set from the solution of lp in this fashion by choosing the threshold that yields a subset that satisfies the constraints and has the highest objective value .",
    "note that the lp relaxation ( [ eq : lp ] ) is vacuous with respect to upper bound constraints in the sense that given @xmath224 that does not satisfy the upper bound constraints of the lp ( [ eq : lp ] ) one can construct @xmath225 , feasible for the lp by rescaling @xmath98 without changing the objective of the lp .",
    "this implies that one can always transform the solution of the unconstrained problem into a feasible solution when there are @xmath226 upper bound constraints .",
    "however , in the presence of lower bound or subset constraints , such a rescaling does not yield a feasible solution and hence the lp relaxation is useful on the instances of with at least one lower bound or a subset constraint ( i.e. , @xmath227 ) .",
    "we now empirically show that consistently produces high quality compact teams .",
    "we also show that the quality guarantee given by theorem [ th : quality - guarantee ] is useful in practice as our method often improves a given sub - optimal solution .",
    "since we are not aware of any publicly available real world datasets for the team formation problem , we use , as in @xcite , a scientific collaboration network extracted from the dblp database .",
    "similar to @xcite , we restrict ourselves to four fields of computer science : databases ( ) , theory ( ) , data mining ( ) , artificial intelligence ( ) . conferences that we consider for each field are given as follows : db = \\{sigmod , vldb , icde , icdt , pods } , t = \\{soda , focs , stoc , stacs , icalp , esa } , dm = \\{www , kdd , sdm , pkdd , icdm , wsdm } , ai = \\{ijcai , nips , icml , colt , uai , cvpr}.    for our team formation problem , the skill set is given by @xmath228\\ { , , , } .",
    "any author who has at least three publications in any of the above 23 conferences is considered to be an expert . in our dblp co -",
    "author graph , a vertex corresponds to an expert and an edge between two experts indicates prior collaboration between them .",
    "the weight of the edge is the number of shared publications .",
    "since the resulting co - author graph is disconnected , we take its largest connected component ( of size 9264 ) for our experiments . directly solving",
    "the non - convex problem ( [ eq : teamprobcont ] ) for the value of @xmath72 given in theorem [ thm : teamprobuncstr ] often yields poor results .",
    "hence in our implementation of  we adopt the following strategy .",
    "we first solve the unconstrained version of problem ( [ eq : teamprobcont ] ) ( i.e. , @xmath229 ) and then iteratively solve ( [ eq : teamprobcont ] ) for increasing values of @xmath72 until all constraints are satisfied . in each iteration ,",
    "we increase @xmath72 only for those constraints which were infeasible in the previous iteration ; in this way , each penalty term is regulated by different value of @xmath72 . moreover , the solution obtained in the previous iteration of @xmath72 is used as the starting point for the current iteration .         [",
    "fig : times ] -0.2 cm    in this section we perform a quantitative evaluation of our method in the special case of the team formation problem with lower bound constraints and @xmath230 ( problem ) .",
    "we evaluate the performance of our method against the greedy method proposed in @xcite , refered to as .",
    "similar to the experiments of @xcite , an expert is defined to have a skill level of 1 in skill @xmath10 , if he / she has a publication in any of the conferences corresponding to the skill @xmath10 .",
    "as done in @xcite , we create random tasks for different values of skill size , @xmath231 . for each value of @xmath4",
    "we sample @xmath4 skills with replacement from the skill set @xmath232 = \\ { , , , } .",
    "for example if @xmath233 , a sample might contain \\ { , , } , which means that the random task requires at least two experts from the skill  and one expert from the skill . in figure 1 , we show for each method the densities , sizes and runtimes for the different skill sizes @xmath4 , averaged over 10 random runs . in the first plot , we also show the optimal values of the lp relaxation in .",
    "note that this provides an upper bound on the optimal value of .",
    "we can obtain feasible solutions from the lp relaxation of via thresholding ( see section [ sec : lprel ] ) , which are shown in the plot as .",
    "furthermore , the plots contain the results obtained when the solutions of  and   are used as the initializations for   ( in each of the @xmath72 iteration ) .",
    "the plots show that  always produces teams of higher densities and smaller sizes compared to  and .",
    "furthermore , produces better results than the greedy method in several cases in terms of densities and sizes of the obtained teams .",
    "the results of + and + further show that our method is able improve the sub - optimal solutions of  and  significantly and achieves almost similar results as that of which was started with the unconstrained solution of . under the worst - case assumption that the upper bound on computed using the lp is the optimal value , the solution of is @xmath234 optimal ( depending on @xmath4 ) .",
    "[ tb : qualteams ]    [ cols= \" < , < ,",
    "< , < \" , ]     [ table : teams ] -0.2 cm    in this experiment , we assess the quality of the teams obtained for several tasks with different skill requirements .",
    "here we consider the team formation problem ( [ eq : teamprobsim ] ) in its more general setting .",
    "we use the generalized density objective of where each vertex is given a rank @xmath235 , which we define based on the number of publications of the corresponding expert . for each skill",
    ", we rank the experts according to the number of his / her publications in the conferences corresponding to the skill . in this way",
    "each expert gets four different rankings ; the total rank of an expert is then the minimum of these four ranks .",
    "the main advantage of such a ranking is that the experts that have higher skill are given preference , thus producing more competent teams .",
    "note that we choose a relative measure like rank as the vertex weights instead of an absolute quantity like number of publications , since the distribution of the number of publications varies between different fields .",
    "in practice such a ranking is always available and hence , in our opinion , should be incorporated .",
    "furthermore , in order to identify the main area of expertise of each expert , we consider his / her relative number of publications . each expert is defined to have a skill level of 1 in skill @xmath10 if he has more than 25% of his / her publications in the conferences corresponding to skill @xmath10 . as a distance function between authors ,",
    "we use the shortest path on the _ unweighted version _ of the dblp graph , i.e. two experts are at a distance of two , if the shortest path between the corresponding vertices in the unweighted dblp graph contains two edges . note that in general the distance function can come from other general sources beyond the input graph , but here we had to rely on the graph distance because of lack of other information .    in order to assess the _ competence _ of the found teams , we use the list of the 10000 most cited authors of citeseer @xcite . note that in contrast to the skill - based ranking discussed above , this list is only used in the evaluation and _ not _ in the construction of the graph .",
    "we compute the average inverse rank as in @xcite as @xmath236 , where @xmath4 is the size of the team and @xmath237 is the rank of expert @xmath9 on the citeseer list of 10000 most cited authors",
    ". for authors not contained on the list we set @xmath238 .",
    "we also report the densities of the teams found in order to assess their _",
    "compatibility_.    we create several tasks with various constraints and compare the teams produced by ,  and  ( feasible solution derived from the lp relaxation ) .",
    "note that in our implementation we extended the algorithm of @xmath239 to incorporate general vertex weights , using dinkelbach s method from fractional programming @xcite .",
    "the results for these tasks are shown in table 1 .",
    "we report the upper bound given by the lp relaxation , density value , @xmath240 as well as number and sizes of the connected components .",
    "furthermore , we give the names and the citeseer ranks of the team members who have rank at most 1000 .",
    "note that could only be applied to some of the tasks and failed to find a feasible team in several cases .    as a first task",
    "we show the unconstrained solution where we maximize density without any constraints .",
    "note that this problem is optimally solvable in polynomial time and all methods find the optimal solution .",
    "the second task asks for at least three experts with skill . here",
    "again all methods return the same team , which is indeed optimal since the lp bound agrees with the density of the obtained team .",
    "next we illustrate the usefulness of the additional modeling freedom of our formulation by giving an example task where obtaining meaningful , connected teams is not possible with the lower bound constraints alone .",
    "consider a task where we need at least four experts having skill ( task 3 ) .",
    "for this , all methods return the same disconnected team of size seven where only four members have the skill .",
    "the other three experts possess skills  and and are densely connected among themselves .",
    "one can see from the lp bound that this team is again optimal .",
    "this example illustrates the major drawback of the density based objective which while preferring higher density subgraphs compromises on the connectivity of the solution .",
    "our further experiments revealed that the subgraph corresponding to the skill is less densely connected ( relative to the other skills ) and forming coherent teams in this case is difficult without specifying additional requirements . with the help of subset and distance based constraints supported by",
    ", we can now impose the team requirements more precisely and obtain meaningful teams . in task 4",
    ", we require that andrew y. ng is the team leader and that all experts of the team should be within a distance of two from each other in terms of the underlying co - author graph .",
    "the result of our method is a densely connected and highly ranked team of size four with a density of 3.89 .",
    "note that this is very close to the lp bound of 3.91 .",
    "the feasible solution obtained by  is worse than our result both in terms of density and @xmath240 .",
    "the greedy method can not be applied to this task because of the distance constraint . in task 5",
    "we choose bernhard schoelkopf as the team leader while keeping the constraints from the previous task .",
    "out of the three methods , only  can solve this problem .",
    "it produces a large disconnected team , many members of which are highly skilled experts from the skill and have strong connections among themselves . to filter these densely connected members of high expertise , we introduce a budget constraint in task 6 , where we define the cost of the team as the total number of publications of its members .",
    "again this task can be solved only by  which produces a compact team of four well - known  experts .",
    "a slightly better solution is obtained when  is initialized with the infeasible solution of the lp relaxation as shown ( only in this task ) .",
    "this is an indication that on more difficult instances of , it pays off to run  with more than one starting point to get the best results .",
    "the solution of the lp , possibly infeasible , is a good starting point apart from the unconstrained solution of .",
    "tasks 7 , 8 and 9 provide some additional teams found by  for other tasks involving upper and lower bound constraints on different skills . as noted in section [ sec : lprel ] the lp bound is loose in the presence of upper bound constraints and this is also the reason why it was not possible to derive a feasible solution from the lp relaxation in these cases . in fact the lp bounds for these tasks remain the same even if the upper bound constraints are dropped from these tasks .",
    "by incorporating various realistic constraints we have made a step forward towards a realistic formulation of the team formation problem .",
    "our method finds qualitatively better teams that are more compact and have higher densities than those found by the greedy method @xcite .",
    "our linear programming relaxation not only allows us to check the solution quality but also provides a good starting point for our non - convex method .",
    "however , arguably , a potential downside of a density - based approach is that it does not guarantee connected components .",
    "a further extension of our approach could aim at incorporating `` connectedness '' or a relaxed version of it as an additional constraint .",
    "we gratefully acknowledge support from the excellence cluster mmci at saarland university funded by the german research foundation ( dfg ) and the project nolepro funded by the european research council ( erc ) .",
    "the subgradient of @xmath241 is given by @xmath242 , where @xmath243 is the indicator function of the largest entry of @xmath98 .",
    "for the subgradient of @xmath244 , using prop . 2.2 . in @xcite",
    ", we obtain for the subgradient @xmath245 of the terms of the form @xmath246 , @xmath247 defining @xmath248 , an element of the subgradient of the second term of @xmath244 is given as @xmath249 , where @xmath166 and @xmath250 where @xmath251 , if @xmath252 ; -1 if @xmath253 ; @xmath254 $ ] , if @xmath255 . in total",
    ", we obtain for the subgradient @xmath256 of @xmath177 , @xmath257"
  ],
  "abstract_text": [
    "<S> given a task @xmath0 , a set of experts @xmath1 with multiple skills and a social network @xmath2 reflecting the compatibility among the experts , _ team formation _ is the problem of identifying a team @xmath3 that is both competent in performing the task @xmath0 and compatible in working together . </S>",
    "<S> existing methods for this problem make too restrictive assumptions and thus can not model practical scenarios . </S>",
    "<S> the goal of this paper is to consider the team formation problem in a realistic setting and present a novel formulation based on densest subgraphs . </S>",
    "<S> our formulation allows modeling of many natural requirements such as ( i ) inclusion of a designated team leader and/or a group of given experts , ( ii ) restriction of the size or more generally cost of the team ( iii ) enforcing _ locality _ of the team , e.g. , in a geographical sense or social sense , etc . </S>",
    "<S> the proposed formulation leads to a generalized version of the classical densest subgraph problem with cardinality constraints ( dsp ) , which is an np hard problem and has many applications in social network analysis . in this paper </S>",
    "<S> , we present a new method for ( approximately ) solving the generalized dsp ( gdsp ) . </S>",
    "<S> our method , , is based on solving an _ equivalent _ continuous relaxation of gdsp . </S>",
    "<S> the solution found by our method has a quality guarantee and always satisfies the constraints of gdsp . </S>",
    "<S> experiments show that the proposed formulation ( gdsp ) is useful in modeling a broader range of team formation problems and that our method produces more coherent and compact teams of high quality . </S>",
    "<S> we also show , with the help of an lp relaxation of gdsp , that our method gives close to optimal solutions to gdsp .    </S>",
    "<S> [ data mining ] [ graph algorithms ] </S>"
  ]
}