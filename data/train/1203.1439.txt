{
  "article_text": [
    "during the last decades , much scientific interest has been devoted to the characterization and modeling of many natural and artificial systems that exhibit so - called emergent behavior .",
    "these systems , referred to as complex systems , are suitably described through their networks of contacts , that is , in terms of nodes ( representing the system s components ) and edges ( standing for their interactions ) , which allows to catch their essential features in a simple and general representation .",
    "complex networks @xcite have therefore become an important , largely used , framework for the understanding of both dynamical and topological aspects of systems such as the brain @xcite , protein - protein interaction networks @xcite , internet and the www @xcite .    in the meanwhile ,",
    "it has also become clear that many of the mentioned networks , particularly those which are described by a power law degree distribution @xmath0 ( scale - free networks @xcite ) , are only partially known .",
    "think , for instance , in online social networks like facebook or twitter , which are made up of millions of heterogeneous and non - identical nodes .",
    "in such large networks , a complete map is hardly available and difficult to get @xcite .",
    "thereby , providing efficient tools for their exploration has become a crucial challenge . in general ,",
    "network features are discovered by means of algorithms based on search and traffic routing @xcite . in many cases ,",
    "the latter can be performed by means of moving `` agents '' , which explore the topological space and recover information .",
    "nonetheless , it is still a key issue the investigation and characterization of the efficiency of different strategies @xcite as far as the quality and quantity of information gathered are concerned .",
    "on the other hand , it has also been shown that local topological metrics , like the degree of a node , greatly affect dynamical properties of complex networks .",
    "this is the case of immunization algorithms , which are more effective the larger the degree of the vaccinated node is @xcite . as a matter of fact ,",
    "one of the best strategies is to immunize a neighbor of a randomly chosen node instead of the node itself .",
    "this is because a randomly chosen node has degree @xmath1 , while a neighbor would have degree @xmath1 with probability @xmath2 .",
    "another striking example closely related to the problem here addressed in which the degree of the nodes determines dynamical properties is the scaling law characterizing flow fluctuations in complex networks @xcite .",
    "admittedly , the mean traffic @xmath3 and its standard deviation @xmath4 can be related through the simple scaling form @xmath5 @xcite .",
    "however , the latter relation , which was previously thought to be universal with @xmath6 being between @xmath7 and @xmath8 , is not satisfied for all values of @xmath1 , i.e. , the exponent is not universal and depends , among other factors , on the degree of the nodes @xcite .    in this paper , we address the problem of network exploration from the point of view of a single node from which an agent is sent through the network in order to collect information , henceforth understood as the fraction of nodes visited when the walker gets back home .",
    "our aim is to find out an optimal strategy to maximize both the number of visited nodes and the chance to meet again the starting point , independently of which is the choice for the latter . to this end , we consider an arbitrary ( heterogeneous ) network of @xmath9 nodes and a single agent ( explorer or walker ) initially located on a given node ( home - node ) , and let it move during a time frame @xmath10 , the walker s lifetime . every time the agent comes back to the starting point , all the nodes it has visited until that moment are marked as visited and the total information gathered is updated",
    "obviously , it could also be possible to send several agents at once , but it has been demonstrated for several similar situations @xcite that increasing the number of walkers ( and reducing their lifetime proportionally ) does not produce better results .",
    "consequently , we focus on the performance of single agents .",
    "the most important novelty of our proposal is that the agents are not markovian random walkers , nor a modified version of random walks dynamics in which additional rules ( for instance , preferential or self - avoiding random walks @xcite ) are introduced .",
    "indeed , we introduce a parameter @xmath11 which governs how likely it is for a walker , at each time step , to go forward or backward ( with respect to the walker s home ) .",
    "thus , by changing the value of this parameter , the two probabilities can be tuned and hence different strategies are defined . in one limiting case , the walkers will tend to move back home , whereas in the other limiting setting , they will tend to move away from home . in between these two asymptotic behaviors",
    ", we recover a classical random walk , for which all directions are equally probable .",
    "we explore different strategies and their dependencies with both the degree of the home nodes and the walkers lifetimes .",
    "moreover , we show that it is possible to built up an adaptive algorithm whose efficiency in terms of the information gathered and the quality of the reconstructed network is , in general , the best .",
    "the rest of the paper is organized as follows .",
    "section  [ section2 ] introduces the model which is characterized in sections  [ section3]-[section4 ] .",
    "our proposal for an adaptive strategy is presented in section  [ section5 ] . in section  [ section6 ]",
    "we present the application of the algorithms previously discussed to the reconstruction of the degree distribution .",
    "finally , the last section ( sec .  [ section7 ] ) is devoted to round off the paper .",
    "let us first discuss a baseline model in which a given set of walkers explore the network starting from a home node .",
    "as previously discussed , in order to collect the results of walkers exploration , they should go back home .",
    "therefore , we introduce two probabilities when the walker is at a given node , provided it has tracked the information about the path followed from the home - node to the current position .",
    "these two probabilities correspond to the forward ( f ) and backwards ( b ) motion along the already tracked path and read , respectively , as : @xmath12 \\label{pf},\\\\\\nonumber\\\\ p_b(k_i ) & = & 1 / [ 1 + q^2(k_i -1 ) ] \\label{pb},\\end{aligned}\\ ] ] where the label @xmath13 indicates the node that the explorer is going to leave and @xmath14 is its degree .",
    "these equations stand for every step whenever the agent is not in the starting node @xmath15 the home , @xmath16 @xmath15 . in the latter case ,",
    "i.e. , while at home , it can only go forward , thus at that position we have @xmath17 and @xmath18 .        from eqs .",
    "( [ pf])-([pb ] ) , we recover the pure random walk ( without any bias , i.e. , all possible directions are equally probable ) for @xmath19 . for very large values of the parameter @xmath11 , no backward step is allowed .",
    "consequently the explorers can get back to their starting node only by chance , through a different path , not being aware that they are coming back , but being able to recognize where they are ( at home ) .",
    "conversely , when @xmath11 goes to @xmath20 , after the first move , no more steps forward are allowed .",
    "therefore , only the first neighbors of the starting node can be explored .",
    "we also consider that the walker s lifetime is @xmath10 steps , which represents the time allowed for the network exploration before the dynamics stops .",
    "we define the information gathered as the fraction of nodes marked as visited after @xmath10 time steps : @xmath21 , where @xmath22 is the number of visited nodes and @xmath9 is the size of the network .",
    "moreover , if the agent is not at home at time @xmath10 , the new nodes visited after its last return to the home node are not computed in @xmath22 ( i.e. , we consider that only the information brought counts ) .",
    "we first discuss the expected behavior of @xmath23 at the two limiting values of @xmath11 ( very high or very small ) . on one hand , for very low @xmath11 values only the nearest neighbors are visited and hence @xmath23 will be small independently of @xmath10 .",
    "on the other hand , for very large values of @xmath11 the walkers only return to home by chance , being the search also inefficient provided the exploration time is not very large ( see next section ) .",
    "then , if we fix the total number of steps we can expect that the information collected will have a maximum as a function of @xmath11 .",
    "therefore , there should exist , for any given network , a precise value @xmath24 such that , if we average over all the possible choices of the home - node and over many realizations of the dynamical exploration , the mean information @xmath25 is maximal . in other words , there is no other value @xmath26 for which @xmath27 , where @xmath28 stands for the mean performed over all the nodes in the network and @xmath29 for the average over many realizations .",
    "the previous analysis indicates that the best efficiency in terms of maximal recovery of information can only be obtained for two values of @xmath30 . in the next section",
    ", we explore the dependency of @xmath23 on the network properties ( as given by the degree of the home node ) and walkers lifetimes .",
    "admittedly , when this time is very long ( @xmath31 ) we should expect to recover most information by setting @xmath32 .",
    "however , even if this is the best choice on average , it might not be the case when the home of the walker is at a low degree node .",
    "on the other hand , for shorter searching times , a value of @xmath33 gives almost the same performance for @xmath23 , but this time the results are independent of the degree of the home node and @xmath25 is a global maximum @xmath15 the caveat is that @xmath30 can not be known a priori .",
    "in this section we study the dependency between the information gathered by an agent and @xmath11 , for different choices of the home - node and for different values of the walkers lifetimes @xmath10 .",
    "hereafter we will use as a benchmark a scale free network of @xmath34 nodes and mean degree @xmath35 generated by the uncorrelated configuration model @xcite .",
    "we however note that all results reported are valid for any network with a power - law degree distribution provided that it does not have a tree - like topology .",
    "actually , the only relevant difference in the case of a tree - like network is that we will observe a different behavior for large values of @xmath11 .",
    "this is because leaves would make very difficult for a walker to come back through a different path making their performance very poor , even for very large values of @xmath10 and for very large degrees of the home nodes .    in fig.[fig1a ] the information @xmath36 is plotted as a function of @xmath11 for several home - nodes and a searching duration of @xmath37 steps .",
    "as it is clearly shown , starting from small values of the parameter @xmath11 , @xmath36 initially increases but soon afterwards there is an abrupt decay to give way to a new increase as @xmath11 grows further .",
    "for very large values of @xmath11 , the information gathered saturates to an asymptotic value .",
    "interestingly enough , as seen in the figure , the amount of information gathered for both very small values of @xmath11 and when @xmath38 , as well as the size of the abrupt decay , depend on the degree of the node from which the walker started the exploration .",
    "however , there exists a universal value of @xmath39 at which almost all curves corresponding to different degrees of the home node collapse , i.e. , there is a local maximum which is roughly independent of the connectivity of the home node . nevertheless , whether this point is also a global maximum for @xmath40 or just a local one depends on the degree of the initial node .",
    "indeed , when the home - node is highly connected , for this searching duration , an agent performs better for @xmath41 , but if this is not the case , @xmath42 gives the optimum efficiency .",
    "( averaged over 3000 realizations ) gathered by a walker during a searching time @xmath43 as a function of the @xmath11 parameter .",
    "each curve refers to a different home - node and different colors and line styles refer to different degrees of the starting node . from the top to bottom : @xmath44 ( dashed black line ) , @xmath45 ( solid red line ) , @xmath46 ( dotted purple line ) , @xmath47 ( solid yellow line ) , @xmath48 ( dot - dashed green line ) , @xmath49 ( solid light blue ) , @xmath50 ( dashed blue line ) . in the inset : the same quantity in a linear scale . ]",
    "gathered by a walker performing its search starting from any home - node during a time lag of @xmath10 steps , as a function of the @xmath11 parameter .",
    "the mean is performed over all the nodes in the network and averaging over 100 realizations for each .",
    "different colors and line styles refer to different durations of the searching . from the bottom to the top : @xmath51 ( light blue dot - dashed line ) , @xmath52 ( red solid line ) , @xmath53 ( dashed purple line ) , @xmath54 ( dotted green line ) , @xmath55 ( dot - dashed yellow line ) , @xmath56 ( solid black line ) , @xmath57 ( dashed blue line ) and @xmath58 ( dotted light blue line ) . in the inset : zoom of the peak .",
    "notice that @xmath42 displays a small shift increasing @xmath10 , up to @xmath43 when it reaches an asymptotic value . ]    in fig.[fig2a ] we plot the same quantity as in fig.[fig1a ] but averaged over all the possible home - nodes ( then the dependency with the degree washes out ) and considering different lifetimes @xmath10 .",
    "the figure makes it more clear that at @xmath39 the value of @xmath59 is a global maximum unless @xmath10 is many times larger than the network size @xmath9 .",
    "this definitively means that if we are interested in the information an agent may gather for a very long searching time , what we have to do is to set @xmath38 .",
    "otherwise , if we are interested in more realistic situations where there can be limitations on the duration of the exploration ( for instance , due to energy constraints ) , the best choice would be to set @xmath39 .",
    "the latter option has a caveat , however : the precise value of @xmath42 depends in an unknown way on the topological features of the underlying network .",
    "nevertheless , one can obtain useful insights into the problem by inspecting how the behavior of a walker changes when @xmath11 varies .",
    "looking more carefully to the results plotted in fig.[fig2a ] , one can distinguish three regions that qualitatively correspond to the three distinct behaviors of the walker . in the first one , for @xmath60",
    ", @xmath59 monotonously increases as a function of @xmath11 ; in the second one , @xmath59 experiences an abrupt decay ; whereas the third region shows that @xmath59 starts to increase again , until it saturates to a value that depends on @xmath10 .",
    "it is easy to realize that the first increase corresponds to small enough values of @xmath11 . in this region ,",
    "the walker moves just a few hops away home and consequently it takes only a few steps to get back home .",
    "the larger the value of @xmath11 is , the longer the mean path covered by the walker will be . since for very small values of @xmath11 the exploration is local , the relevance of the home - node degree is very high ( see fig.[fig1a ] ) . then , increasing @xmath11 , we are allowing the walker to explore farther nodes , that is to collect new information , and the initial differences due to the degree of the home - node become progressively smaller . at @xmath39",
    "they have almost vanished .    in the second region , for @xmath11 slightly larger than @xmath42 , the walker often gets lost and its performance is , on average , less efficient . in other words , the explorer wastes an important fraction of the lifetime @xmath10 gathering information that it will not be able to bring back home before the time is over . the precise value at which this start to occurs is slightly affected by the duration of the exploration , as shown in the inset of fig.[fig2a ] .",
    "this can be explained as a combination of two factors . on the one hand , to increase @xmath11 means to increase the number of nodes visited , but also the risk to get lost .",
    "indeed , if an agent is performing a long trip and it is going to bring a lot of information back home , when the searching time is suddenly over , the loss is big . on the other hand ,",
    "the very first trips are those that provides the largest fraction of new information since the majority of nodes are being visited for the first time .",
    "thus , getting lost after a couples of returns causes a much worse loss than if the same happens after a few round trips .",
    "again it is a matter of balance and the optimum value @xmath42 is smaller when the lifetime is shorter .",
    "the second region ends at a value of @xmath11 for which the previous balance is the worst possible one , thus giving raise to another increase , which marks the start of the third region . here , for even larger values of @xmath11",
    ", it begins to be quite frequent that , wandering across the network almost randomly , the explorer returns to its home - node through a different path just by chance .",
    "this new behavior entails a new increasing of @xmath59 due to the fact that this kind of random returns start to balance the inefficiency of the walkers that get lost .",
    "the likelihood of these events increases with @xmath11 and it is maximum when @xmath41 , that is , when @xmath61 at each time step .",
    "the previous dependency of @xmath59 on the walker s lifetime @xmath10 defines two optimal values for @xmath11 , either @xmath62 takes its maximum value at @xmath63 or at @xmath64 .",
    "however , we stress again that for @xmath65 , the walker gets back home by chance ( recall that for these values of @xmath11 the backward probability @xmath61 )",
    ". consequently the asymptotic values of @xmath59 in the @xmath66 limit strongly depends on the degree of the home nodes ( see fig.[fig1a ] ) .",
    "therefore , setting @xmath63 could be a better choice even when @xmath10 is large enough . in order to be able to take advantage of the agents behavior at @xmath42 , we need to characterize deeper the transition that occurs for that value of the parameter . to this end , in the next section we focus on the behavior of some dynamical quantities which display a relevant change around @xmath42 .",
    "( black line ) and backward @xmath67 ( red line ) taken by a walker during a time lag of @xmath43 steps .",
    "the mean is performed over all the nodes and averaging over @xmath53 realizations for each of them . in the first inset ( above ) : zoom around the value of @xmath11 at which the two curves get apart . in the second one ( below ) : the ratio @xmath68 in the same range . according to the arguments discussed in this section",
    ", the peak should lie between the to values indicated with the dashed lines ( @xmath69 $ ] ) and this is in a good agreement with what we can observe in fig.[fig2a ] . ]    in fig.[fig3a ] we plot the average maximum number of sequential steps backward ( @xmath67 ) and forward ( @xmath70 ) that a walker takes in a time lag @xmath43 as a function of @xmath11 .",
    "these two quantities , estimated by averaging over many realizations and over all the possible home - nodes , give a useful picture of the transition between the first and the second regimes previously described .",
    "they initially increase together , then @xmath67 start increasing slower than @xmath70 , it reaches a maximum and start decreasing , asymptotically going to zero . notice that for small @xmath11 the value of @xmath70 is small .",
    "consequently , @xmath67 is bounded ( even if @xmath71 ) since , when an agent is back to its home , no more steps backward can be taken . the value of @xmath11 for which @xmath67 and @xmath70 take the maximum value before getting apart roughly corresponds to @xmath42 .",
    "it is when the walker goes as far as possible from its starting point , being still able to come back on its own steps . increasing @xmath11",
    "a little bit further provokes that the number of steps forward exceeds that of steps backward and the home - node is not recovered any more , so that the searching efficiency rapidly decreases .",
    "this phenomenology helps us to find out an heuristic definition for the peak .",
    "it is indeed possible to state that @xmath42 is the precise value of @xmath11 for which a walker is allowed to take enough steps forward to be able to visit a large region of the network , but at the same time it is also allowed to take enough steps backward so as to return to its home not by chance .    admittedly , it is possible to translate this heuristic statement into a quantitative condition starting from one simple observation . there exists , for any @xmath1 , a value of @xmath11 such that @xmath72 and from eqs .",
    "( [ pf])-([pb ] ) we know that this value is @xmath73 .",
    "if @xmath74 it is guaranteed that @xmath75 @xmath76 , so the mean path is short and the explorer will come back to home very often . if @xmath77 , the situation is the opposite , @xmath78 @xmath76 , so for the agent it is very difficult to recover its home .",
    "therefore , the conclusion is that the peak lies between these two extremal values .",
    "a reasonable estimation could be obtained by imposing that @xmath79 on average while an explorer walks around . at each time step , the probability that a walker is on a node of degree @xmath1 is @xmath80 , where @xmath81 is the degree distribution of the considered network .",
    "hence , this condition can be rewritten as @xmath82 thus we obtain the estimator @xmath83 in fig.[qstar - qp ] we have plotted @xmath30 against @xmath42 for several networks of different sizes and different topologies ( degree distributions ) finding a very good agreement in all of the considered cases .",
    "it can be confirmed that the precise value of @xmath42 only depends on the first and second moment of the degree distribution , while no explicit dependence on the network size can be observed , at least for finite @xmath9 .    ) against the measured value of @xmath42 for several networks .",
    "all the networks have been generated by the uncorrelated configuration model changing the exponent @xmath84 of the degree distribution together with the maximum degree @xmath85 and the minimum degree @xmath86 , varying from quite heterogeneous topologies to random regular graphs .",
    "different symbols stand for different network sizes : squares for @xmath87 , circles for @xmath88 , and triangles for @xmath89 .",
    "each group of symbols corresponds to a given set of parameters . from the smallest value of @xmath42 we have : \\{@xmath84=1.5 , @xmath85=50 , @xmath86=2 } ( purple ) ; random regular network with @xmath90 ( blue ) ; \\{@xmath84=2.5 , @xmath85=50 , @xmath86=2 } ( yellow ) ; \\{@xmath84=2.5 , @xmath85=30 , @xmath86=2 } ( light blue ) ; random regular with @xmath1=5 ( green ) ; \\{@xmath84=0.1 , @xmath85=5 , @xmath86=2 } ( red ) ;",
    "random regular with @xmath1=3 ( black ) .",
    "the values of @xmath42 have been measured for an exploring time @xmath10=@xmath9 . ]    in order to complete this phenomenological picture it can be useful to look at another quantity strictly related with what we have said in the previous paragraphs . in fig.[fig4a ] we plot the mean time that a walker needs to come back to its home - node ( @xmath91 ) as a function of @xmath11 . in this case",
    "we did not set a lifetime .",
    "we then let @xmath92 walkers wander through the network starting from a given node .",
    "each time an agent recovers its home it is not allowed to leave it anymore and the duration of the trip is recorded .",
    "we wait until every walker has come back and calculate the average return time @xmath93 , where @xmath94 $ ] stands for the considered home - node .",
    "finally we average over all the possible starting nodes .",
    "what we obtain is a curve that closely resembles that of the order parameter in a second order phase transition , with the critical point located slightly above @xmath42 .",
    "furthermore , if we look at the dispersion of the values of @xmath95 we recover a behavior quite similar to that of the susceptibility , i.e. , a divergence at the critical point @xcite .",
    "actually , the divergence takes place very close to @xmath42 , but even closer to the value of @xmath11 for which the average number of consecutive backward steps is maximum ( see the inset in fig.[fig3a ] ) . with a slightly larger value of @xmath11 ,",
    "the return time starts to rapidly increase , with a corresponding abrupt increment in the dispersion .",
    "this indicates that , even if the trip duration uses to be small , sometimes - with a probability that increases by increasing @xmath11 - the agent needs a very long time in order to reach his / her home - nose .",
    "thus , a lot of information is lost if the process is stopped before the explorer is able to complete its last journey .",
    "again , this scenario corroborates the intuition that @xmath42 is the maximum value of @xmath11 able to guarantee that the walker will not get lost .    )",
    "that a walker starting from any node in the network needs to come back to its home - node as a function of @xmath11 .",
    "the average is performed over all the nodes , and for each of them over @xmath55 realizations . in the first inset ( above ) : on the left , the same quantity represented in a log scale with error bars ( standard deviation among home - nodes ) ; in the second one ( below ) : the relative standard deviation of the values @xmath93 . ]",
    "for any given network we are now able to predict where the peak is located , given the first and the second moments of the degree distribution .",
    "however , we are interested in developing a searching strategy that can be useful when we have no information at all about the underlying topology . in this section",
    ", we are going to set up an adaptive algorithm aimed at optimizing the performance of an agent exploring a heterogeneous network in a number of steps @xmath10 that is equal to ( or less than ) the number of nodes @xmath9 .",
    "the basic idea is simple .",
    "we have a walker and a value of @xmath11 associated to it .",
    "we let it wander and when it is at home again we evaluate the contribution of this last round trip to the information gathered until that moment and , if necessary , the value of @xmath11 is modified . in order to build up such an algorithm ,",
    "three main elements are needed .",
    "the first one is an appropriate quantitative way to evaluate the performance of the agents .",
    "the second one is a criterion to decide whether or not @xmath11 would be modified .",
    "finally , the adaptive rule applies whenever the choice is to change the value of @xmath11 .",
    "this third element is an algorithm able to connect what the agent has learned about the network until its last return , the efficiency of its performance and the current value of @xmath11 in order to provide a new , more suitable , value for the parameter .",
    "let us start with the first element . since the aim of the exploration is to collect the maximum amount of information in a fixed time frame , to be efficient means to visit as many new nodes as possible per unit of time ( step ) .",
    "the final efficiency of a searching process can thus be defined as @xmath96 .",
    "this definition can be expressed as a function of the number of round trips . if we indicate with @xmath97 the time of the @xmath98-@xmath99 return of the explorer ( @xmath100 ) , we have @xmath101 , where",
    "@xmath102 stands for the number of visited nodes after @xmath97 steps ( @xmath103 ) .",
    "it is also possible to measure the efficiency of a single trip as @xmath104/(t_r - t_{r-1})]$ ] , but this is not a very useful procedure as @xmath105 is very noisy .",
    "therefore , in order to compare the performance at time @xmath97 with that at time @xmath106 it is better to consider the efficiency variation @xmath107 .",
    "hence , a good criterion to decide whether a change of @xmath11 is needed is @xmath108 .",
    "notice that if we start with a small value of @xmath11 , the number of steps forward and backward will be the same ( see fig.[fig3a ] ) and the explorer will pass on each visited node at least two times .",
    "therefore the first return time @xmath109 will be twice the number of steps ahead that the walker was allowed to take .",
    "the maximum number of different nodes that the agent may have visited during its trip is therefore equal to the number of steps it took forward .",
    "this happens whenever the walker does not cross each link more than twice ( forward and backward ) .",
    "thus , the efficiency has an upper bound , @xmath110 , that can be easily reached for any small value of @xmath11 when the explorer performs its first trip .",
    "in particular , for @xmath111 we surely have @xmath112 since only one step forward is allowed and the agent will visit one node in two time steps . consequently , we expect @xmath113 to start from a value very close to @xmath7 and then necessarily decreases .",
    "hence , changing @xmath11 has the effect of decelerating the decay of @xmath114 , or at most , to make @xmath114 reach a stationary value .     takes the initial value @xmath115 .",
    "the notation is simplified in order to make the diagram easier to read : @xmath113 is indicated as @xmath116 and @xmath102 just as @xmath22 . ]",
    "when @xmath11 is varied , we should also take special care in not letting the agent to get lost .",
    "for this reason , since the real value of @xmath42 is unknown , we need to start from a very small value of @xmath11 in order to ensure that @xmath117 . then",
    ", we want to let @xmath11 increase in a controlled way .",
    "hence , we need to fix an upper bound for @xmath11 based on the information the agent is recovering about the degree of the visited nodes . a first , very simple election could be to use the estimator of @xmath42 provided by eq.([qstar ] ) .",
    "one can replace the probabilities @xmath118 with the visit frequencies @xmath119 , where @xmath13 is the node index , @xmath120 the number of times the walker has visited that node , and @xmath121 the elapsed time ( number of steps ) .",
    "thus we obtain the empirical estimator @xmath122 -1}},\\ ] ] where @xmath123 is the number of visited nodes at time @xmath121 .",
    "obviously , when @xmath124 this empirical estimator is equal to the estimator ( [ qstar ] ) .",
    "the problem , however , is that this is not an upper bound .",
    "actually , the degree distribution the walker recovers during the first trips is very noisy and @xmath125 fluctuates a lot . in some cases , it takes values quite smaller than the real @xmath42 .",
    "this would prevent the explorer from increasing @xmath11 trapping him / her in the neighborhood of the starting node .",
    "therefore , we need a quantity that satisfies the following requirements :    1 .",
    "it has to be less noisy than @xmath125 ; 2 .",
    "it has to take values smaller than @xmath42 very unlikely ; 3 .",
    "when evaluated over the whole network , its value has to be close to that of @xmath42 ; 4 .",
    "it has to be the same as @xmath42 and @xmath125 when we consider a homogeneous network .    to satisfy the first requirement",
    ", we need to avoid to use the frequencies @xmath126 taking into account all the visited nodes with the same weight , regardless of how many times they have been visited .",
    "so we are looking for an appropriate function @xmath127 of the degrees of the visited nodes , such that @xmath128 .",
    "we propose the following expression that satisfies all the requirements : @xmath129 notice that in general @xmath130 , where the equality holds in the case homogeneous networks .",
    "therefore , we have @xmath131^{-1/2}.\\ ] ] with all the previous remarks , the adaptive algorithm can be formulated as follows ( see fig .",
    "[ fig5a ] ) :    * set @xmath132 and let the agent perform its first round trip . *",
    "calculate @xmath133 and let the agent perform another trip . *",
    "calculate the new value of the efficiency and check if @xmath134 .",
    "if it is not the case , let the agent explore again , until the condition @xmath108 is satisfied .",
    "* calculate @xmath127=@xmath135 and then @xmath136 .",
    "* check if @xmath137 , where @xmath138 is a small positive quantity ( in general @xmath139 is a good choice ) .",
    "* if the condition ( 5 ) is satisfied , update the value of @xmath11 adding @xmath138 : @xmath140 .",
    "* if the condition ( 5 ) is not satisfied , but @xmath141 , update the value of @xmath11 so that @xmath142 . * if @xmath143 then : * * if @xmath144 then @xmath145 , * * if @xmath146 then @xmath147 .    figure  [ fig6a ] shows results for the final efficiency @xmath148 and the information gathered @xmath149 for the three best strategies : the adaptive one , @xmath41 and @xmath39 ( although this is not really a strategy since we need to know the precise value of @xmath42 ) .",
    "both quantities confirm that , unless @xmath10 is more than twice the network size @xmath150 , the best performance is obtained for @xmath39 .",
    "nevertheless , our adaptive strategy gives results that are very close to those obtained for @xmath39 and always better than those obtained for @xmath65 ( at least for @xmath151 ) both in terms of efficiency and in terms of the total amount of information recovered .",
    "all these results are coherent with the description of the walkers behavior commented on in the previous section . in particular",
    ", it is reasonable that when @xmath152 the efficiency initially increases with @xmath10 since in this case the shorter the searching duration , the larger the probability that an agent gets lost . on the contrary , for @xmath42 and the adaptive strategy , which precisely aims at capturing the behavior of the agents at @xmath42 , the information is mainly collected by means of quite short round trips .",
    "consequently , increasing the searching time reduces the efficiency because it increases the chance to visit many times the same nodes . in any case , when @xmath31 and @xmath153 , the problem of visiting already visited nodes becomes relevant also for the strategy @xmath65 .",
    "finally , it is worth stressing that while for @xmath152 , the dispersion among the values @xmath154 and @xmath155 for different home - nodes is very high , in the case of the other two strategies , the same does not happen .",
    "this is a clear indication of the fact that the adaptive strategy recovers one of the most interesting features of the agents behavior at @xmath42 , namely , the homogeneity of the performance starting from different home - nodes .",
    "we next discuss one potential application of the searching strategies previously discussed .",
    "this would also allow for a better distinction of what strategy is the best .",
    "= @xmath156 as a function of the searching time @xmath10 in the case of three searching strategies ( averaged over all the nodes and @xmath157 realizations for each of them ) : @xmath65 ( blue tringles ) , @xmath39 ( red squares ) and the adaptive strategy ( black circles ) .",
    "bottom panel : mean information @xmath59 as a function of @xmath10 , again for the three best searching strategies ( represented with the same colors as above ) .",
    "error bars represent the dispersion ( standard deviation ) among the values obtained for different home - nodes . ]",
    "an important global descriptor of every network is its degree distribution @xmath158 .",
    "however , this information is not always at hand .",
    "for instance , suppose you belong to a network of which you only know your local neighborhood ( like an online social network or a city map ) .",
    "the problem is then to know what is your position in the network as far as the degree is concerned or to make an exploration that allow you to gather information about the entire map . in other words , we want to study if the sample of nodes visited by an agent is more or less representative of the global system , at least with regard to its @xmath158 .    in fig.[fig7a ]",
    "we plot the number of nodes of degree @xmath1 , @xmath159 , found in a typical realization of the different strategies , for two different values of @xmath10 and for different choices of home - nodes .",
    "as we expected , the usual random walker and the agent with @xmath152 are very bad when the home - node has a small degree ( red curves ) . on the contrary , the performance of the adaptive protocol and that of the walker when @xmath39 are almost not affected by the walkers lifetimes ( at least for the considered values ) and by the degree of the home - node .",
    "note that panels ( a ) and ( b ) represent the common situation in which a random walker starting at a lowly connected home node gets lost .",
    "indeed , for such cases , the only information brought back is the degree of the node from which the walker started the exploration of the network .",
    "however , as it is also appreciated in the figure , when the home node has a relative high degree , setting @xmath152 constitutes the best strategy for an accurate estimation of @xmath159 . nevertheless ,",
    "as the walker `` does not know ''",
    "what is the connectivity of its home node in relation to the rest of the network , the latter strategy seems to be , as a rule of thumb , a bad choice .",
    "additionally , the figure also shows that in general what is difficult for an agent to recover are the most peripheral nodes of the network .",
    "consequently , the nodes with a small degree are usually under represented while the heavy tail of the degree distribution is reconstructed with high accuracy .    in order to quantify the accuracy of the reconstructed networks",
    ", we calculate the kullback - leibler divergence or relative entropy @xcite , a non - symmetric measure of the difference between two probability distributions .",
    "this is a standard method to evaluate how different an experimentally estimated distribution is from the real one . for the probability distributions @xmath160 and @xmath161 of a discrete random variable their kl divergence is defined to be @xmath162 where @xmath158 is the real distribution and @xmath163 the estimated one . using this measure",
    ", we explore how the accuracy of the reconstruction depends on the searching strategy , the walkers lifetimes and the degree of the home node . in what follows ,",
    "we report results for the mean values , averaged over many realizations , and for the deviations around the means .    in fig.[fig8a ] , panels ( a)-(b ) , we plot @xmath164 as a function of @xmath10 for four different strategies ( including the standard random walk ) and two different starting nodes ( corresponding to , respectively , maximum and minimum degree , ) . as expected , @xmath165 when @xmath166 , in all the considered cases . the @xmath39 strategy and the adaptive protocol",
    "perform much better than the other two settings , with less dispersion and a very much weaker dependence on the degree of the home node .",
    "hence , these last two strategies are more suited if we aim at recovering @xmath158 , especially when @xmath10 is not too long . moreover , even if they both are good , the adaptive strategy is better than @xmath39 , with a very small dispersion .",
    "thus , although it is not possible to perform better that @xmath39 in terms of nodes visited , the adaptive strategy does better in terms of the accuracy of @xmath163 , that is , when it comes to reconstruct @xmath158 .",
    "we have also analyzed the dependency of @xmath164 on the degree of the home nodes for fixed values of @xmath10 .",
    "figure[fig8a ] , panels ( c)-(d ) , displays @xmath164 as a function of @xmath1 for all the strategies , in the case of a short lifetime ( @xmath167 ) .",
    "differences among strategies are really noteworthy , while for the larger lifetime ( @xmath43 ) we verified that they persist just in the case of quite small degrees of the home nodes .",
    "finally , the adaptive strategy is in general the best option , being @xmath39 slightly better only in the case of home nodes with degree @xmath168 .",
    "in this paper , we have presented a model for network search and exploration in which walkers evaluate at each time step whether to go farther from a home node or get back with the information retrieved up to that moment .",
    "these probabilities depend on a single parameter @xmath11 , that has been shown to exhibit an optimal value , @xmath169 ( @xmath19 corresponds to the markovian random walk limit ) for exploration times comparable to the system size .",
    "when the walkers are allowed to explore the network indefinitely or during long times , the optimal value turns out to be @xmath66 .",
    "however , although the amount of information recovered for the latter choice could be maximal , the results are highly dependent on the degree of the home node : the smaller the degree of the node assigned to the walker , the less information the walker can get back home . as a matter of fact , for most of the nodes ( recall that in a scale - free network most of the nodes are poorly connected ) , @xmath66 is not the best strategy .    capitalizing on the behavior of the walkers as a function of @xmath11 , we have also proposed an alternative algorithm in which the agents are allowed to tune the value of the parameter @xmath11 to optimize the information retrieved . through numerical simulations , we have shown that this mechanism allows an exploration as efficient as that performed setting @xmath39 . nevertheless , the adaptive scheme has the advantage that the value of @xmath11 is changed dynamically , and therefore it overcomes the problem of fixing an a priori unknown optimal value @xmath42 .",
    "we believe that this adaptive search protocol could be a valuable addition to the current literature as it performs optimally with a minimum ( local ) information about the network structure .    as a demonstration of the potentialities of the algorithms explored in this work ,",
    "we have made use of the different searching strategies to address the problem of network discovery . as expected , the adaptive mechanism is the one whose performance , in terms of the quality and quantity of the information retrieved , is the best . whether or not these kinds of strategies can be further developed and applied to the exploration of real networks is out of the scope of the present paper , but we identify at least two scenarios in which they can be useful : the discovery of new connections in communication networks and the exploration of planar networks ( i.e. , city networks ) using minimal local information .",
    "we therefore hope that our work guide future research along these lines .    the work has received financial support from spanish micinn ( grants fis2009 - 13730 and fis2011 - 25167 ) , from generalitat de catalunya ( 2009sgr00838 ) , from the fet - open project dynanets ( grant no .",
    "233847 ) funded by the european commission , and from comunidad de aragn ( fmi22/10 ) .",
    "l.p . was supported by the generalitat de catalunya through the fi program and also acknowledges hospitality of isi torino , where part of this work was performed ."
  ],
  "abstract_text": [
    "<S> finding efficient algorithms to explore large networks with the aim of recovering information about their structure is an open problem . here , we investigate this challenge by proposing a model in which random walkers with previously assigned home nodes navigate through the network during a fixed amount of time . </S>",
    "<S> we consider that the exploration is successful if the walker gets the information gathered back home , otherwise , no data is retrieved . </S>",
    "<S> consequently , at each time step , the walkers , with some probability , have the choice to either go backward approaching their home or go farther away . </S>",
    "<S> we show that there is an optimal solution to this problem in terms of the average information retrieved and the degree of the home nodes and design an adaptive strategy based on the behavior of the random walker . </S>",
    "<S> finally , we compare different strategies that emerge from the model in the context of network reconstruction . </S>",
    "<S> our results could be useful for the discovery of unknown connections in large scale networks . </S>"
  ]
}