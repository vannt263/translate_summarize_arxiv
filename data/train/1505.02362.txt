{
  "article_text": [
    "we invite the reader to participate in the following visual search tasks .",
    "there are two search tasks on page .",
    "find the oddball image in each of the two configurations .",
    "based on the time taken for each of the tasks , identify which of the two is easier .    among the two search tasks on page , most subjects find task 1 the easier , and task 2 the tougher",
    ". visual search performance , as measured by the time taken to find the oddball image , should depend on the `` similarity '' of the two images .",
    "one has the natural hypothesis :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ @xmath1 the more `` dissimilar '' the two images , the shorter the time taken to find the oddball image .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    to test such a hypothesis , one needs a quantification of the notion of `` dissimilarity '' between two images . sripati and",
    "olson @xcite proposed one such measure based on neuronal responses ( to the images ) in the inferotemporal ( it ) cortex of the macaque brain .",
    "they conducted experiments to 1 ) find the time taken by human subjects in visual search for a number of image pairs , and 2 ) record neuronal responses to the same images from the monkey it cortex .",
    "they found quantitative evidence in support of @xmath1 based on their notion of dissimilarity .",
    "we now describe their experiments and recall their findings to set the stage for this paper .",
    "the experiments of sripati and olson @xcite were the following .    1 .",
    "six human subjects were shown a picture as in figure [ fig : fig1a ] on page .",
    "six images were placed at the vertices of a regular hexagon , with one image being different from the others . to be specific ,",
    "let @xmath2 and @xmath3 be two images .",
    "one of these two was picked randomly with equal probability and was placed at one of the six locations randomly , again with equal probability .",
    "the other image was placed in the remaining five locations .",
    "the subjects were required to identify the correct half ( left or right ) of the plane where the oddball image was located .",
    "the subjects were advised to indicate their decision  as quickly as possible without guessing \" @xcite . the time taken to make a decision after the onset of the image",
    "was recorded .",
    "this experiment was repeated on the same subject and across subjects .",
    "the average reaction time across trials , denoted @xmath4 , was recorded .",
    "thus @xmath4 is the estimate of the ( symmetrised ) decision time to distinguish between @xmath2 and @xmath3 .",
    "similar estimates were obtained for several pairs of images .",
    "2 .   for capturing neuronal responses to images , sripati and olson conducted a set of experiments on macaque monkeys .",
    "see @xcite for details .",
    "a single image @xmath2 ( respectively , @xmath3 ) was displayed on the screen , and the neuronal firings elicited by @xmath2 ( respectively , @xmath3 ) on a set of it neurons were recorded across multiple sessions .",
    "the neuronal representation of the image @xmath2 was taken to be the vector of average firing rates indexed by the neurons .",
    "this is denoted @xmath5 , where @xmath6 is the number of tapped neurons .",
    "similarly , the neuronal representation of image @xmath3 was estimated and denoted as the vector @xmath7 .",
    "the measure of dissimilarity between the two images @xmath2 and @xmath3 was then taken to be the @xmath0-distance normalised by the number of neurons : @xmath8 they obtained the scatter plot @xmath9 shown in fig .",
    "[ fig : l1_vs_behavioural ] , where @xmath10 varied across image pairs , and observed a remarkably high correlation @xmath11 , thereby providing evidence in support of a quantitative version of @xmath1 .    .",
    "sripati and olson @xcite observed a high correlation of @xmath12 between the inverse of reaction time and their proposed @xmath0 distance between the neuronal firing vectors . ]    for a detailed discussion of how neural activity in monkey visual cortex can be used to predict human search performance ,",
    "we refer the reader to @xcite , @xcite .",
    "the experiments of sripati and olson @xcite and figure [ fig : l1_vs_behavioural ] suggest a natural question of interest to researchers in information and decision theory .",
    "one does anticipate that @xmath4 is negatively correlated with some notion of dissimilarity between @xmath13 and @xmath7 , say @xmath14 .",
    "figure [ fig : l1_vs_behavioural ] suggests @xmath15 however , we know of no decision theoretic basis for @xmath14 to be @xmath16 .",
    "what is an appropriate @xmath14 ?",
    "familiarity with wald s sequential probability ratio test @xcite immediately suggests that a relation like ( [ qn : hypothesis 1 ] ) should arise , but with perhaps relative entropy poisson point processes with rate vector @xmath13 taken with respect to the probability measure associated with rate vector @xmath7 .",
    "] , or its variant , in place of @xmath16 . a variant may be called for because of the possibility of controlled actions . to see why ,",
    "let us summarize the decision problem in the form of a question :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ one of the six images is odd .",
    "what would the prefrontal cortex ( the decision center of the brain ) do if it got observations ( firings of neurons ) from the human analogue of the it cortex , and could control the eye ( to gaze at one of the six objects ) ?",
    "the goal is to minimise the time to decide the oddball image and its location , yet keep errors within desired limits . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    one can model this decision problem as a sequential hypothesis testing problem with control .",
    "naghshvar and javidi , earlier in @xcite and more recently in @xcite , call such a problem active sequential hypothesis testing ( asht ) .",
    "asht suggests a natural candidate that we shall propose for @xmath14 .",
    "there is however one important modeling issue that we wish to bring to the attention of the reader .",
    "figure [ fig : l1_vs_behavioural ] shows that the average reaction times in the experiments are between 250 ms and 1000 ms .",
    "however , it is known that a switch in focus from one search location to another has a cost per switch that ranges from tens of ms to sometimes even higher than 100 ms @xcite . to account for this ,",
    "we extend asht to a setting with switching costs , and show that the @xmath14 appropriate for the setting without switching costs works equally well with switching costs .    as with @xmath0 distance , so with our proposed @xmath14 , and indeed , with other natural dissimilarity indices like relative entropy and chernoff entropy is roughly @xmath17 @xcite . when the decision is to be made after a fixed number of samples , where the number of samples is fixed upfront to meet a certain error tolerance criteria , the required number of samples is roughly @xmath18 .",
    "] , table [ table : correlation of different neuronal metrics ] indicates that all these dissimilarity measures have similar high correlation with the behavioural index , correlation values are based on scatter plots arising from _ ordered _ pairs of images .",
    "this explains why @xmath19 correlation value in the table ( obtained from 24 points in the scatter plot ) is marginally different from the correlation indicated in figure [ fig : l1_vs_behavioural ] ( and obtained from 12 symmetrised points in the plot ) . ] .",
    "given that all these dissimilarity indices yield high correlation with the reaction times , does our proposed @xmath20 candidate stand out in some way ?",
    "it is certainly grounded in a decision - theoretic framework as we shall soon see .",
    "but is there some experimental evidence in favour of our proposed @xmath20 candidate ? we address this question as well and propose a method to rank order the dissimilarity measures in their ability to explain the experimental data of sripati and olson @xcite .",
    ".correlation with different information measures [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     [ table : glrt_values ]",
    "we modelled the visual search task of sripati and olson @xcite as an active sequential hypothesis testing problem ( asht ) .",
    "we extended the asht results of chernoff @xcite to the case with switching costs .",
    "we showed that adding switching costs does not affect the asymptotic growth rate of the total cost .",
    "the asht model suggests a dissimilarity index between pairs of images .",
    "the inverse of the asymptotic growth rate of the total cost in the asht model is proposed as a dissimiliarity index between pairs of images .",
    "we derived expressions for computing the proposed dissimilarity index for the specific search task considered by sripati and olson @xcite .",
    "the proposed dissimilarity index is a function of the neuronal firing rates elicited by the images in the infero temporal cortex of macaque monkeys .",
    "correlation study indicated that the proposed index is as good as @xmath19 and other dissimilarity measures such as the chernoff entropy and the relative entropy ( kl ) .",
    "equality of means testing indicated that the equality of means hypothesis should be rejected , and this can be done with overwhelming confidence .",
    "equality of means testing procedure is perhaps a rather stringent test",
    ". what would be an appropriate test if , say , we can leave one group out ? does our proposed neuronal dissimilarity index pass such a less stringent test ?",
    "can we leave two groups out ? which two ?",
    "we do not yet have a principled way to address these questions and instead decided to stick to the strictest test .",
    "the statistics associated with the equality of means testing , however , suggested a ranking of the dissimilarity measures .",
    "we proposed three different statistics .",
    "each measures the spread across groups of the group sample means .",
    "one of them is the familiar am / gm ratio .",
    "the ranking was consistent across the three different statistics .",
    "our proposed index was ranked first , relative entropy ( kl divergence ) and chernoff entropy were a close second and third , and @xmath19 was a somewhat distant fourth .",
    "the decision times were tested for the gamma distribution and the test passed for two - third of the groups .",
    "the shape parameter for the distributions of delay , estimated via the method of moments , was close to 3 .",
    "in our work , we took only valid trials , i.e. , those where the decisions made by the subjects were correct .",
    "we also assumed that the error probability tolerance were the same across subjects .",
    "it would be interesting to model speed - accuracy tradeoffs and see how they vary across individuals .",
    "it would also be interesting to explore how they vary for a single subject under different incentive settings .",
    "extension of asht to the case when no prior information is available about the images , where the subject has to actively learn @xmath21 and @xmath22 on - the - fly , is an interesting learning problem that is currently under study .",
    "we will now show some desirable properties of the log - likelihood ratio processes under the policy @xmath24 .",
    "these properties are analogous to those of classical sequential hypothesis testing , but their analyses are more involved because actions introduce 1 ) dependency in the log - likelihood ratio increments , and 2 ) the increments are no longer identically distributed .",
    "the properties we will establish will be useful in forthcoming proofs .",
    "define @xmath25 .",
    "we then have @xmath26 . here",
    ", @xmath27 is the increment in the process associated with the log - likelihood ratio of @xmath28 with respect to @xmath29 at time @xmath30 .",
    "we now show that under assumptions ( i ) and ( iib ) , and under policy @xmath24 , the log - likelihood ratio processes are well behaved in the following sense : the log - likelihood ratio of the true hypothesis @xmath29 with respect to any other hypothesis @xmath28 has a positive drift .",
    "this will be made precise in proposition [ prop : exponential decay llr process ] . towards that",
    ", we first establish the following lemmas .",
    "[ lemma : likelihood ratio property conditioned on actions ] assume ( i ) and ( iib ) .",
    "fix @xmath31 , @xmath32 such that @xmath33 .",
    "let @xmath34 .",
    "we then have , for all @xmath35 , @xmath36 < 1 \\;\\;\\ ; \\hfill \\forall n.\\end{aligned}\\ ] ]    the following sequence of inequalities hold : @xmath37\\\\   \\nonumber & = \\int_{x \\in \\mathcal{x } } \\left(\\frac{q_{j}^{a}(x)}{q_{i}^{a}(x)}\\right)^{s } q_{i}^{a}(x ) dx\\\\   \\nonumber & =   \\int_{x \\in \\mathcal{x } } \\left(q_{j}^{a}(x)\\right)^{s } \\left(q_{i}^{a}(x)\\right)^{1-s } dx \\\\ & <",
    "\\left ( \\int_{x \\in \\mathcal{x } } q_{j}^{a}(x ) dx \\right)^{s } \\left ( \\int_{x \\in \\mathcal{x } } q_{j}^{a}(x ) dx \\right)^{1-s } \\label{eqn : holders ineq}\\\\   \\nonumber & = 1.\\end{aligned}\\ ] ] the strict inequality in ( [ eqn : holders ineq ] ) follows from hlder s inequality and the fact that @xmath34 implies @xmath38 and @xmath39 are not linearly related .",
    "the above result was obtained by conditioning on the action @xmath40 to lie in the desirable set @xmath41 .",
    "the result is independent of the underlying policy , because when conditioned on the current action @xmath40 , the observation is independent of the policy .",
    "recall that @xmath42 is the non - stopping variant of @xmath43 .",
    "further , recall from assumption ( iib ) that we have @xmath44 .",
    "now we show that , under assumption ( iib ) and policy @xmath42 , a similar result holds , but without conditioning on the action @xmath40 .",
    "first , let us define @xmath45 the fact that @xmath46 is evident from lemma [ lemma : likelihood ratio property conditioned on actions ] .",
    "[ lemma : likelihood ratio property under policy ] assume ( i ) and ( iib ) .",
    "consider the policy @xmath42 .",
    "fix @xmath31 .",
    "we then have , for all @xmath47 , @xmath48 \\le \\rho_{ij}(s ) < 1 \\ ; \\ ; \\ ; \\hfill \\forall n , \\forall j \\ne i.\\end{aligned}\\ ] ]    the following sequence of inequalities hold as described after the last inequality .",
    "\\nonumber & = e_{i } \\left [ e_{i } \\left [ e^{s\\delta z_{ji}(n ) } \\vert x^{n-1},a^{n-1 } , a_{n } \\right ] \\vert x^{n-1},a^{n-1 } \\right]\\\\ \\label{eqn : lemma rho_ij(s ) equation 3 } & =   \\sum_{a \\in \\mathcal{a } } p_{i}(a_{n } = a\\vert x^{n-1 } a^{n-1 } ) e_{i } \\left[e^{s\\delta z_{ji}(n ) } \\vert a_{n } = a \\right]\\\\ \\nonumber & \\le p_{i}(a_{n } \\in \\mathcal{a}_{ij}\\vert x^{n-1 } a^{n-1 } ) \\max_{a \\in \\mathcal{a}_{ij } } e_{i } \\left[e^{s\\delta z_{ji}(n ) } \\vert a_{n } = a\\right]\\\\ \\label{eqn : lemma rho_ij(s ) equation 4 } & \\hspace{0.5cm}+ ( 1-p_{i}(a_{n } \\in \\mathcal{a}_{ij}\\vert x^{n-1 } a^{n-1}))\\\\ \\nonumber & \\le \\eta",
    "\\beta \\left(\\max_{a \\in \\mathcal{a}_{ij}}\\rho_{ij}^{a}(s)\\right)+ ( 1-\\eta \\beta)\\\\ & < 1.\\end{aligned}\\ ] ] equality ( [ eqn : lemma rho_ij(s ) equation 3 ] ) holds because conditioned on @xmath50 , @xmath51 is independent of the remaining history . inequality ( [ eqn : lemma rho_ij(s ) equation 4 ] ) holds because , when @xmath52 , we have @xmath53 .",
    "the penultimate inequality is a consequence of the fact that , under @xmath23 , one will choose an action @xmath34 with probability at least @xmath54 .",
    "we now proceed to show an inequality analogous to the chernoff bound for the log - likelihood ratio . in classical sequential hypothesis testing , due to independence of samples across time , the expectation of the likelihood ratio can be split as the product of the expectation of the likelihood ratio increments , as follows : @xmath55 = \\prod_{k=1}^{n } e_{i } \\left[e^{s\\delta z_{ji}(n ) } \\right].\\end{aligned}\\ ] ] the same decomposition is not valid in asht because actions introduce dependency in the likelihood ratio increments across time .",
    "however , we can obtain an upper bound of the product form .",
    "[ lemma : likelihood ratio decomposition ] assume ( i ) and ( iib ) .",
    "consider policy @xmath42 .",
    "fix @xmath31 .",
    "we then have , for all @xmath56 , @xmath57 \\le ( \\rho_{ij}(s))^{n } \\ ; \\ ; \\ ; \\hfill \\forall n , \\forall j \\ne i.\\end{aligned}\\ ] ]    once again , we proceed through the chain of inequalities all of which are now self - evident : @xmath58\\\\ & = e_{i } \\left [ e_{i } \\left [ e^{s z_{ji}(n-1)}e^{s\\delta z_{ji}(n ) } \\vert x^{n-1},a^{n-1 } \\right ] \\right]\\\\ & =   e_{i } \\left[e^{s z_{ji}(n-1 ) } e_{i } \\left[e^{s\\delta z_{ji}(n)}\\vert x^{n-1},a^{n-1 } \\right ]   \\right ] \\\\ & = \\rho_{ij}(s ) e_{i } \\left[e^{s z_{ji}(n-1)}\\right ] \\text{\\hfill ( from lemma \\ref{lemma : likelihood ratio property under policy})}\\\\ & \\le ( \\rho_{ij}(s))^{n},\\end{aligned}\\ ] ] where the last inequality follows by induction .",
    "we now show an exponential decay property of the log - likelihood process which primarily stems from the anticipated negative drift in @xmath59 for @xmath60 .",
    "let us alert the reader that in the following proposition we deal with @xmath61 .",
    "[ prop : exponential decay llr process ] assume ( i ) and ( iib ) .",
    "consider policy @xmath42 .",
    "fix @xmath31 .",
    "there exist constants",
    "@xmath62 and @xmath63 such that @xmath64 @xmath65 is independent of @xmath31 , but @xmath66 may depend on @xmath31 .",
    "this follows from the previous lemmas via the following : @xmath67\\\\   \\label{eqn : exponential decay llr process inequality 2 } & \\le e^{sk } \\sum_{j \\ne i } ( \\rho_{ij}(s))^{n}\\\\   \\nonumber & \\le e^{sk } \\cdot ( m-1 ) \\cdot \\max_{j\\ne i } ( \\rho_{ij}(s))^{n}\\\\   \\nonumber & = c_{k } e^{-\\gamma n } ,   \\end{aligned}\\ ] ] where @xmath68 , and @xmath69 .",
    "the inequality in ( [ eqn : exponential decay llr process inequality 3 ] ) is due to the union bound , the inequality in ( [ eqn : exponential decay llr process inequality 1 ] ) is due to chernoff s bound with @xmath47 , and the inequality in ( [ eqn : exponential decay llr process inequality 2 ] ) is due to lemma [ lemma : likelihood ratio decomposition ] .    we now show that under the hypothesis @xmath70 , the @xmath71 process eventually settles at @xmath31 .",
    "indeed we show something stronger .",
    "let us define @xmath72 the time at which @xmath71 meets its eventuality of settlement at @xmath31 .",
    "this random variable has a tail that decays exponentially fast , as shown next .",
    "[ lemma : exponential decay of ti ] assume ( i ) and ( iib ) .",
    "consider policy @xmath42 .",
    "fix @xmath31 .",
    "then there exist @xmath73 and @xmath74 , both finite and possibly dependent on @xmath31 , such that @xmath75    by the union bound @xmath76 the assertion now follows from proposition [ prop : exponential decay llr process ] .",
    "thus far we have considered the policy @xmath42 which never stops .",
    "we now show that the policy @xmath23 stops in finite time .",
    "[ prop : finite stopping time ] assume ( i ) and ( iib ) .",
    "consider the policy @xmath23 .",
    "fix @xmath31 .",
    "we then have @xmath77    we consider @xmath78 for analysis .",
    "recall that @xmath79 , and hence it is sufficient to show that @xmath80 from proposition [ prop : exponential decay llr process ] , we know that , for a suitable constant @xmath81 , @xmath82 since this bound is summable , by the borel - cantelli lemma , @xmath83 which is stronger than the assertion ( [ eqn : stopping time pi_i finite ] ) .",
    "propositions [ prop : exponential decay llr process ] and [ prop : finite stopping time ] are the ones that will be used in the sequel .",
    "the proof relies on a standard change of measure argument .",
    "let @xmath84 denote the event that the policy @xmath23 declares @xmath28 as the true hypothesis .",
    "@xmath85 the second equality holds because we have shown in proposition [ prop : finite stopping time ] that the stopping time is finite with probability 1 .",
    "the inequality ( [ eqn : proof of propostion prob of wrong detection equation 4 ] ) follows because @xmath86 implies @xmath87 , that is , @xmath88 .",
    "we assume ( i ) and ( iib ) .",
    "all statements in this proof are under @xmath70 and under _ sluggish procedure a_. we follow the proof technique of chernoff ( * ? ? ?",
    "2 ) . chernoff s proof technique does not go through completely because unlike in _ procedure a _ , the next action in _ sluggish procedure a _ is not conditionally independent of the previous action , given the current likelihood values .",
    "a similar issue was addressed by nitinawarat and veeravalli in @xcite , in the context of markovian observation model , and we will adapt their proof technique to our setting .",
    "let us first setup some notation .",
    "fix @xmath89 .",
    "define @xmath90 where @xmath91 is as defined in ( [ eqn : optimal_lambda ] ) .",
    "let @xmath92 be as defined by ( [ eqn : d_i ] ) , i.e. , @xmath93 . under the _ sluggish procedure a _ ,",
    "the transition probability matrix @xmath94 of the action process @xmath40 at time @xmath30 is given by    @xmath95    it is easy to verify that the stationary distribution associated with @xmath94 is @xmath96 .",
    "define @xmath97 , the @xmath98-field generated by the random variables @xmath99 .",
    "we now upper bound the expected time to make a decision under _ sluggish procedure a _ as follows : @xmath100 & \\le e_{i}\\left[\\tau(\\pi_{sa}^{i}(l,\\eta))\\right]\\\\   \\nonumber & = \\sum_{n \\ge 0 } p_{i } \\left(\\tau(\\pi_{sa}^{i}(l,\\eta ) ) > n\\right)\\\\    \\nonumber & \\le \\frac{(1+\\epsilon ) \\log ( l(m-1))}{d_{i}}\\\\ \\label{eqn : bounding expected stopping time equation 3 } & \\hspace{0.5 cm}+ \\sum_{n \\ge \\tilde{n } } p_{i } \\left(\\tau(\\pi_{sa}^{i}(l,\\eta ) ) > n\\right ) ,   \\end{aligned}\\ ] ] where @xmath101 to complete the proof , we will now show that for any @xmath102 , the second term on the right - hand side of ( [ eqn : bounding expected stopping time equation 3 ] ) goes to zero as @xmath103 .",
    "indeed , we claim that each term in the summation decays exponentially with @xmath30 with an exponent that does not depend on @xmath104 .",
    "assuming the claim , the tail sum vanishes as @xmath103 , because @xmath105 .",
    "this suffices to complete the proof of theorem [ theorem : upper bound on stopping time of sa ] .",
    "we now proceed to prove the claim .",
    "observe that @xmath106    fix one @xmath33 .",
    "( the same analysis holds for other @xmath32 . )",
    "then @xmath107 + \\epsilon ' \\right ) \\right .",
    "\\\\    \\nonumber & \\hspace{1.2 cm } + \\sum_{k=1}^{n } \\left(e_{i } \\left [ \\delta z_{ij}(k)\\vert \\mathcal{f}_{k-1}\\right ] - d_{ij } + \\epsilon ' \\right ) \\\\",
    "\\nonumber & \\hspace{1.2 cm } +   n \\left(d_{ij } - 2\\epsilon ' \\right ) \\le \\log ( m-1)l \\bigg ) \\\\    \\nonumber & \\le p_{i}\\left ( \\sum_{k=1}^{n } \\left ( \\delta z_{ij}(k ) - e_{i } \\left [ \\delta z_{ij}(k)\\vert \\mathcal{f}_{k-1}\\right ] + \\epsilon ' \\right ) < 0 \\right ) \\\\",
    "\\nonumber & \\hspace{0.7 cm } + p_{i } \\left ( \\sum_{k=1}^{n } \\left(e_{i } \\left [ \\delta z_{ij}(k)\\vert \\mathcal{f}_{k-1}\\right ] - d_{ij } + \\epsilon ' \\right ) < 0 \\right ) \\\\",
    "\\label{eqn : log likelihood ratio z_ij equation 2 } &   \\hspace{0.7 cm } + p_{i } \\left ( n ( d_{ij } - 2\\epsilon ' ) \\le \\log(l(m-1 ) )   \\right).\\end{aligned}\\ ] ] look at the first probability term in ( [ eqn : log likelihood ratio z_ij equation 2 ] ) .",
    "each entry within the summation has a positive mean and , from chernoff s bounding technique in ( * ? ? ?",
    "2 ) , there exists a @xmath108 such that @xmath109 + \\epsilon ' \\right ) < 0 \\right ) \\le e^{-n b(\\epsilon')}.\\end{aligned}\\ ] ]    the third probability term is @xmath110 if we choose an @xmath111 small enough such that @xmath112 , for all @xmath113 .",
    "indeed , any @xmath111 satisfying @xmath114 suffices .",
    "so set @xmath115 .",
    "we now proceed to show that the second term also decays exponentially to zero .",
    "let @xmath116 be as defined in ( [ eqn : ti ] ) .",
    "for a suitably chosen @xmath117 , and we will soon indicate how to choose it , we have @xmath118 - d_{ij } + \\epsilon ' \\right ) < 0 \\right )   \\\\ & \\le p_{i } \\left ( \\sum_{k=1}^{n } \\left(e_{i } \\left [ \\delta z_{ij}(k)\\vert \\mathcal{f}_{k-1}\\right ] - d_{ij } + \\epsilon ' \\right ) < 0,~",
    "t_{i } \\le n\\epsilon '' \\right)\\\\ & \\hspace{0.7 cm } + p_{i}(t_{i } > n \\epsilon'').\\end{aligned}\\ ] ] from lemma [ lemma : exponential decay of ti ] , the second probability term on the right - hand side decays exponentially with @xmath30 . to show that the first probability term on the right - hand side decays exponentially with @xmath30 , we use a technique of nitinawarat and veeravalli ( *",
    "* ( 6.23 ) ) .",
    "first , we indicate how to choose @xmath117 .",
    "define @xmath119 - d_{ij}\\\\ & = \\min_{a \\in \\mathcal{a } } d(q_{i}^{a}\\vert q_{j}^{a } ) - d_{ij}.\\end{aligned}\\ ] ] since @xmath120 is the @xmath91-weighted average of @xmath121 , we have @xmath122 .",
    "choose @xmath117 small enough so that @xmath123 .",
    "we then have @xmath124 - d_{ij } + \\epsilon ' \\right ) < 0,~ t_{i } \\le n\\epsilon '' \\right ) \\\\   & = p_{i } \\left(\\sum_{k=1}^{\\lfloor n \\epsilon '' \\rfloor } \\left(e_{i } \\left [ \\delta z_{ij}(k)\\vert \\mathcal{f}_{k-1}\\right ] - d_{ij } + \\epsilon ' \\right ) \\right.\\\\   & \\hspace{1.2 cm}+ \\sum _",
    "{ k= \\lfloor n \\epsilon '' \\rfloor + 1}^{n } \\left(e_{i } \\left [ \\delta z_{ij}(k)\\vert \\mathcal{f}_{k-1}\\right ] - d_{ij } + \\epsilon ' \\right )   < 0,\\\\   &   \\hspace{1.2 cm } t_{i }",
    "\\le n\\epsilon '' \\bigg)\\\\   & \\le p_{i } \\left(\\lfloor n \\epsilon '' \\rfloor ( \\tilde{c}+\\epsilon ' ) \\right.\\\\   &   \\hspace{1.2 cm } + \\sum_{k= \\lfloor n \\epsilon '' \\rfloor + 1}^{n } \\left(e_{i } \\left [ \\delta z_{ij}(k)\\vert \\mathcal{f}_{k-1}\\right ] - d_{ij } + \\epsilon ' \\right )   < 0 , \\\\   & \\hspace{1.2 cm } t_{i } \\le n\\epsilon '' \\bigg)\\\\   & \\le p_{i } \\left ( \\sum_{k= \\lfloor n \\epsilon '' \\rfloor + 1}^{n } \\left(e_{i } \\left [ \\delta z_{ij}(k)\\vert \\mathcal{f}_{k-1}\\right ] - d_{ij } +   \\tilde{\\epsilon } \\right )   < 0 , \\right . \\\\   &   \\hspace{1.2 cm } t_{i } \\le n\\epsilon '' \\bigg)\\\\   & \\le \\tilde{p}_{i } \\left ( \\sum_{k=\\lfloor n \\epsilon '' \\rfloor + 1}^{n } \\left(e_{i } \\left [ \\delta z_{ij}(k)\\vert \\mathcal{f}_{k-1}\\right ] - d_{ij}+ \\tilde{\\epsilon } \\right ) < 0 \\right)\\\\   & \\le c e^{-n\\tilde{b}(\\tilde{\\epsilon } ) } , { \\addtocounter{equation}{1}\\tag{\\theequation}}\\label{eqn : exponential decay stationary markov process equation 5}\\end{aligned}\\ ] ] for some @xmath125 and some @xmath126 .",
    "the second inequality follows from the fact that @xmath127 - d_{ij}$ ] , for all @xmath128 .",
    "the third inequality follows from the choice of @xmath129 and the fact that @xmath130 @xmath131 is a new measure under which actions are taken according to _ sluggish procedure a _ but assuming @xmath132 , and the observations are conditionally independent of past observations and actions , given the current action .",
    "consequently , under @xmath131 , the action process @xmath40 is a stationary markov chain with transition probability matrix @xmath133 . by the ergodic theorem and concentration inequalities for markov chains @xcite",
    ", this term also decays exponentially with @xmath30 , which is ( [ eqn : exponential decay stationary markov process equation 5 ] ) .",
    "we will focus only on @xmath134 and will determine @xmath135 the case @xmath136 can be handled similarly and is omitted . using ( [ eqn : kl1 ] ) - ( [ eqn : kl3 ] ) , we can simplify the minimisation in ( [ eqn : optimum di ] ) by considering three regions for @xmath32 as follows : @xmath137 observe that the second term is always greater than or equal to the other two terms , and hence can be removed from the minimisation .",
    "thus , @xmath138 we now perform the maximisation over @xmath139 in two steps .",
    "first , let us fix @xmath140 and optimise over the distribution of @xmath141 among the other actions . since @xmath142 we have @xmath143 and @xmath144 thus both the terms within braces in ( [ eqn : optimum d simplified 2 ] ) are lesser than or equal to the corresponding terms for equal distribution of @xmath141 among the other actions .",
    "the optimisation problem is now reduced to a single variable optimisation of the form @xmath145 second , we now perform the optimisation in ( [ eqn : optimum d simplified 3 ] ) over @xmath146 .",
    "the first term in the minimisation is increasing or non - increasing in @xmath146 depending on @xmath147 or @xmath148 , respectively .",
    "the second term is decreasing in @xmath146 .",
    "_ 1 ) _ suppose @xmath149 , then the two terms viewed as linear functions over @xmath146 cross each other , and so the maximum will be achieved at the point of equality , i.e. , @xmath150 solving for @xmath146 yields @xmath151    _ 2 ) _ suppose @xmath148 , then the maximum is achieved at @xmath152 .",
    "then @xmath153 , and @xmath154 since @xmath155 .",
    "the computation of our proposed neuronal index requires a computation of the relative entropy rate between two poisson point processes from estimates of their rates .",
    "the relative entropy between two poisson point processes with rates @xmath156 and @xmath157",
    "is @xmath158 let @xmath159 be the number of spikes observed in time slot @xmath128 , @xmath160 , of duration @xmath161 on the @xmath162 process , @xmath163 .",
    "the empirical firing rate is then @xmath164 .",
    "a natural estimate for ( [ eqn : kl distance poisson ] ) , based on the observations , would be to substitute @xmath165 by their respective empirical estimates @xmath166 , to get      a little reflection suggests that this is a bad estimate , for there is a positive probability that @xmath168 , yielding @xmath169 = \\infty $ ] .",
    "estimate ( [ eqn : relative entropy plug - and - play estimator ] ) is thus biased ( though consistent ) .",
    "our approach is to obtain estimates for each of the terms in ( [ eqn : kl distance poisson ] ) with minimal bias .",
    "unbiased and maximum likelihood estimates for the third and fourth terms on the right hand side of ( [ eqn : kl distance poisson ] ) are the respective empirical firing rates themselves .",
    "let us therefore now study the second term .",
    "we may assume that the firings are independent , given @xmath170 and @xmath171 .",
    "thus we may look for an estimator of the form @xmath172 which has expectation @xmath173 $ ] . for this to be close to the desired @xmath174",
    ", we look for a function @xmath175 such that @xmath176 \\approx \\log r_{2}$ ] .",
    "the difficulty is due to the @xmath177 artifact .",
    "we consider a simple fix of adding a nonzero offset to the empirical estimate , i.e. , we consider estimates of the form @xmath178 .",
    "figure [ fig : optimum_theta_different_rates ] shows the optimum offset @xmath179 for different firing rates @xmath180 when @xmath181 .",
    "the optimum offset @xmath179 can be seen to converge to 0.5 for large @xmath180 .",
    "further , the convergence is quite fast , @xmath179 is close to 0.5 for all @xmath180 greater than 3 .",
    "hence in this work we use @xmath182 as the offset , thus resulting in an estimator for @xmath183 of the form @xmath184 . for a general @xmath30 and @xmath161",
    "we then have @xmath185 \\approx \\log(ntr)$ ] , which in turn implies",
    "@xmath186 \\approx \\log(r)$ ] .",
    "thus an estimator for a general @xmath30 and @xmath161 would be @xmath187 .",
    "the estimator for the second term in ( [ eqn : kl distance poisson ] ) is then @xmath188 .",
    "one could look for better estimators with the offset being a function of the observed empirical means . in this work we stick to the constant offset estimator , with the constant offset being @xmath182 , as it is reasonable to assume that the neurons have a firing rate greater than @xmath189 spikes / second ( @xmath30 = 24 , @xmath161 = 250 ms ) , thus putting them in the firing rate regime where @xmath182 is a good offset for near unbiasedness .",
    "the values @xmath161 = 250ms and @xmath30 = 24 correspond to the neuronal recording time and the number of repetitions in the neuronal recording experiment of sripati and olson @xcite .    to address the first term of ( [ eqn : kl distance poisson ] ) we consider estimates of the form @xmath190 such that @xmath191 \\cong r_{1 } \\log r_{1}.\\end{aligned}\\ ] ] expanding the expectation above for @xmath181 , we obtain , @xmath191 & = \\sum_{k=0}^{\\infty } k g(k ) \\frac{{r_{1}}^{k } e^{-r_{1}}}{k!}\\\\   & = r_{1 } \\sum_{k=1}^{\\infty } g(k)\\frac{r_{1}^{k-1 } e^{-r_{1}}}{(k-1)!}\\\\   & = r_{1 } e_{r_{1}}\\left[g(\\hat{r}_{1}+1)\\right].\\end{aligned}\\ ] ]",
    "thus we want a @xmath192 such that @xmath193 \\cong \\log r_{1}$ ] . from the discussion on the second term",
    ", we know that @xmath194 \\sim \\log r_{1}$ ] , and hence a good choice for @xmath192 would be @xmath195 . thus our estimate for the first term for a general @xmath30 and @xmath161 is @xmath196    therefore our combined estimate for the relative entropy rate in ( [ eqn : kl distance poisson ] ) , based on the average firing rate estimates @xmath197 and @xmath198 and obtained over a time of duration @xmath199 is @xmath200^{+ } & \\text{if } \\hat{r}_{1 } \\ge \\frac{1}{2nt}\\\\     \\hat{r_{2 } } & \\text{otherwise}.   \\end{cases}\\end{aligned}\\ ] ] relative entropy being a convex function of its arguments , the plug - in estimator of ( [ eqn : relative entropy plug - and - play estimator ] ) would always have a positive bias .",
    "naturally , an unbiased estimator would have a smaller value than ( [ eqn : relative entropy plug - and - play estimator ] ) , and our proposed estimator does satisfy this requirement .",
    "in figure [ fig : kl distance estimator ] we plot the estimator bias for different @xmath201 pairs for @xmath30 = 24 and @xmath161 = 250 ms , motivated by the specific neuronal experimental data of sripati and olson @xcite . from figure",
    "[ fig : kl distance estimator ] we can see that our proposed estimator has low estimation error for most @xmath201 .",
    "estimation error is relatively large only when @xmath156 is large and @xmath157 is close to zero ."
  ],
  "abstract_text": [
    "<S> neuroscientists have recently shown that images that are difficult to find in visual search elicit similar patterns of firing across a population of recorded neurons . the @xmath0 distance between firing rate vectors associated with two images </S>",
    "<S> was strongly correlated with the inverse of decision time in behaviour . but why should decision times be correlated with @xmath0 distance ? what is the decision - theoretic basis ? in our decision theoretic formulation , we modeled visual search as an active sequential hypothesis testing problem with switching costs . </S>",
    "<S> our analysis suggests an appropriate neuronal dissimilarity index which correlates equally strongly with the inverse of decision time as the @xmath0 distance . </S>",
    "<S> we also consider a number of other possibilities such as the relative entropy ( kullback - leibler divergence ) and the chernoff entropy of the firing rate distributions . </S>",
    "<S> a more stringent test of equality of means , which would have provided a strong backing for our modeling fails for our proposed as well as the other already discussed dissimilarity indices . however , test statistics from the equality of means test , when used to rank the indices in terms of their ability to explain the observed results , places our proposed dissimilarity index at the top followed by relative entropy , chernoff entropy and the @xmath0 indices . </S>",
    "<S> computations of the different indices requires an estimate of the relative entropy between two poisson point processes . </S>",
    "<S> an estimator is developed and is shown to have near unbiased performance for almost all operating regions . </S>"
  ]
}