{
  "article_text": [
    "comparing measurements is fundamental to the sciences , and so it is not surprising that ordering , bounding , and optimizing real - valued expressions is central to mathematics .",
    "a host of computational methods have been developed to support such reasoning , using symbolic or numeric methods , or both .",
    "for example , there are well - developed methods of determining the satisfiability or unsatisfiability of linear inequalities @xcite @xcite , polynomial inequalities @xcite , nonlinear inequalities involving functions that can be approximated numerically @xcite @xcite , and inequalities involving convex functions @xcite .",
    "the `` satisfiability modulo theories '' framework @xcite @xcite provides one way of integrating such methods with ordinary logical reasoning and proof search ; integration with resolution theorem proving methods has also been explored @xcite @xcite .",
    "interactive theorem provers like isabelle @xcite and hol light @xcite now incorporate various such methods , either constructing correctness proofs along the way , or reconstructing them from appropriate certificates .",
    "( for a small sample , see @xcite @xcite @xcite @xcite . )",
    "such systems provide powerful tools to support interactive theorem proving .",
    "but , frustratingly , they often fail when it comes to fairly routine calculations , leaving users to carry out explicit calculations painstakingly by hand .",
    "consider , for example , the following valid implication : @xmath0 the inference is not contained in linear arithmetic or even the theory of real - closed fields .",
    "the inference is tight , so symbolic or numeric approximations to the exponential function are of no use . backchaining using monotonicity properties of addition , multiplication , and exponentiation",
    "might suggest reducing the goal to subgoals @xmath1 and @xmath2 , but this introduces some unsettling nondeterminism .",
    "after all , one could just as well reduce the goal to    * @xmath3 and @xmath4 , or * @xmath5 and @xmath6 , or even * @xmath7 and @xmath8 .    and yet",
    ", the inference is entirely straightforward . with the hypothesis @xmath9 in mind",
    ", you probably noticed right away that the terms @xmath10 and @xmath11 can be compared ; similarly , the comparison between @xmath12 and @xmath13 leads to comparisons between @xmath14 and @xmath15 , then @xmath16 and @xmath17 , and so on .",
    "the method we propose is based on such heuristically guided forward reasoning , using properties of addition , multiplication , and the function symbols involved .",
    "as is common for resolution theorem proving , we try to establish the theorem above by negating the conclusion and deriving a contradiction .",
    "we then proceed as follows :    * put all terms involved into a canonical normal form .",
    "this enables us to recognize terms that are the same up to a scalar multiple , and up to associativity and commutativity of addition and multiplication . *",
    "iteratively call specialized modules to learn new comparisons between subterms , and add these new comparisons to a common `` blackboard '' structure , which can be accessed by all modules .",
    "the theorem is verified when any given module derives a contradiction using this common information .",
    "the procedure fails when none of the modules can learn anything new .",
    "we will see in section  [ section : examples ] that the method is far from complete , and may not even terminate . on the other hand , it is flexible and extensible , and easily verifies a number of inferences that are not obtained using more principled methods . as a result , it provides a useful complement to more conventional approaches .",
    "we have designed and implemented modules to learn comparisons from the additive and multiplicative structure of terms , a module to instantiate axioms involving arbitrary functions symbols , and special - purpose modules for common functions like min , max , absolute value , exp , and log .",
    "the additive and multiplicative modules have two different implementations , with different characteristic strengths and weaknesses .",
    "the first uses a natural but naive fourier - motzkin elimination , and the second uses more refined geometric techniques .",
    "our prototype implementation , written in python , is available online :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ https://github.com/avigad/polya _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    we have named the system `` polya , '' after george plya , in recognition of his work on inequalities as well as his thoughtful studies of heuristic methods in mathematics ( e.g.  @xcite @xcite ) .",
    "the general idea of deriving inequalities by putting terms in a normal form and combining specialized modules is found in avigad and friedman @xcite , which examines what happens when the additive and multiplicative fragments of real arithmetic are combined .",
    "this is analogous to the situation handled by smt solvers , with the added twist that the languages in question share inequality symbols and multiplication by constant coefficients in addition to the equality symbol .",
    "avigad and friedman show that the universal fragment remains decidable even if both theories include multiplication by rational constants , while the full first - order theory is undecidable .",
    "the former decidability result , however , is entirely impractical , for reasons discussed there .",
    "rather , it is the general framework for combining decision procedures and the use of canonical normal forms that we make use of here .    the outline of the paper is as follows . in section  [ section : framework ] ,",
    "we describe the general blackboard architecture which is the shared interface for the different modules , and the canonical form for terms . in section",
    "[ section : fourier : motzkin ] , we describe the implementation of the additive and multiplicative modules based on the fourier - motzkin algorithm , whereas in section  [ section : geometric ] we describe the implementation based on existing tools from discrete geometry . in section  [ section : functions ] , we describe a module that instantiates general axioms , and in section  [ section : other : modules ] we describe more specialized modules that contribute information to the blackboard . in section  [ section : examples ] , we provide a number of examples that help characterize the method s strengths and weaknesses .",
    "finally , in section  [ section : conclusions ] , we discuss some of the many ways that the method can be extended , as well as ways in which the implementation may be improved .",
    "this paper is a revised and expanded version of the conference paper @xcite .",
    "the extensions described in this paper , chiefly the additional modules described in section  [ section : other : modules ] , are due to avigad and lewis .",
    "more detailed descriptions of some of the representations and algorithms can be found in lewis ms thesis @xcite .",
    "we wish to consider terms , such as @xmath18 , that are built up from variables and rational constants using addition , multiplication , integer powers , and function application . to account for the associativity of addition and multiplication",
    ", we view sums and products as multi - arity rather than binary operations",
    ". we account for commutativity by imposing an arbitrary ordering on terms , and ordering the arguments accordingly .",
    "importantly , we would also like to easily identify the relationship between terms @xmath19 and @xmath20 where @xmath21 , for a nonzero rational constant @xmath22 .",
    "for example , we would like to keep track of the fact that @xmath23 is twice @xmath24 . towards that end ,",
    "we distinguish between `` terms '' and `` scaled terms '' : a scaled term is just an expression of the form @xmath25 , where @xmath19 is a term and @xmath22 is a rational constant .",
    "we refer to `` scaled terms '' as `` s - terms '' for brevity .",
    "we define the set of _ terms _ @xmath26 and _ s - terms _ @xmath27 by mutual recursion : @xmath28 here @xmath12 ranges over a set of _ variables _ , @xmath29 ranges over a set of _ function symbols _ , @xmath30 , and @xmath31",
    ".    thus we view @xmath18 as an s - term of the form @xmath32 , where @xmath19 is the product @xmath33 , @xmath34 is a sum of three s - terms , and @xmath35 is the result of applying @xmath29 to the single s - term @xmath36 .",
    "note that there is an ambiguity , in that we can also view the coefficient @xmath37 as the s - term @xmath38 .",
    "this ambiguity will be eliminated when we define a notion of _ normal form _ for terms .",
    "the notion extends to s - terms : an s - term is in normal form when it is of the form @xmath25 , where @xmath19 is a term in normal form .",
    "( in the special case where @xmath39 , we require @xmath19 to be the term @xmath40 . ) we also refer to terms in normal form as _",
    "canonical _ , and similarly for s - terms .    to define the notion of normal form for terms",
    ", we fix an ordering @xmath41 on variables and function symbols , and extend that to an ordering on terms and s - terms . for example",
    ", we can arbitrarily set the term @xmath40 to be minimal in the ordering , then variables , then products , then sums , and finally function applications , recursively using lexicographic ordering on the list of arguments ( and the function symbol ) within the latter three categories .",
    "the set of terms in normal form is then defined inductively as follows :    * @xmath42 are terms in normal form .",
    "* @xmath43 is in normal form provided @xmath44 , each @xmath45 is in normal form , and @xmath46 .",
    "* @xmath47 is in normal form provided each @xmath45 is in normal form , and @xmath48 .",
    "* @xmath49 is in normal form if each @xmath50 is .",
    "the details are spelled out in avigad and friedman @xcite . that paper provides an explicit first - order theory , @xmath51 , expressing commutativity and associativity of addition and multiplication , distributivity of constants over sums , and so on , such that the following two properties hold :    1 .   for every term @xmath19",
    ", there is a unique s - term @xmath52 in canonical form , such that @xmath51 proves @xmath53 .",
    "2 .   two terms @xmath34 and @xmath35 have the same canonical normal form if and only if @xmath51 proves @xmath54",
    ".    the results can be straightforwardly extended to terms with arbitrary integer exponents .",
    "for example , the term @xmath18 is expressed canonically as @xmath55 , where the constant in the additive term @xmath56 has been factored so that the result is in normal form .",
    "the semantics we have chosen for expressions @xmath57 when @xmath58 is negative or zero is that such an expression is assumed to denote a real number , but in case @xmath19 is @xmath59 we make no further assumptions about the value of @xmath57 .",
    "thus , for example , we do not combine exponents when putting @xmath60 into canonical form , though @xmath61 is reduced to @xmath62 .",
    "we leave it to the multiplicative module to deal with negative exponents appropriately when the base is known to be nonzero .",
    "the two clauses above provide an axiomatic characterization of what it means for terms to have the same canonical form . as discussed in section  [ section : conclusions ] , extending the reach of our methods requires extending the notion of a canonical form to include additional common operations .",
    "we now turn to the blackboard architecture , which allows modules to share information in a common language . to the addition module",
    ", multiplication is a black box ; thus it can only make sense of additive information in the shared pool of knowledge .",
    "conversely , the multiplication module can not make sense of addition . but both modules can make sense of information in the form @xmath63 , where @xmath34 and @xmath35 are subterms occurring in the problem .",
    "the blackboard enables modules to communicate facts of this shape .",
    "when the user asserts a comparison @xmath64 to the blackboard , @xmath19 is first put in canonical form , and names @xmath65 are introduced for each subterm . it is convenient to assume that @xmath66 denotes the canonical term @xmath40 . given the example in the last section , the method could go on to define @xmath67 in that case , @xmath68 represents @xmath18 .",
    "any subterm common to more than one term is represented by the same name . separating terms in this way",
    "ensures that each module can focus on only those definitions that are meaningful to it , and otherwise treat subterms as uninterpreted constants .",
    "now any comparison @xmath69 between canonical s - terms , where @xmath70 denotes any of @xmath71 , or @xmath72 , translates to a comparison @xmath73 , where @xmath45 and @xmath74 name canonical terms .",
    "but this , in turn , can always be expressed in one of the following ways :    * @xmath75 or @xmath76 , or *",
    "@xmath77 , where @xmath78 and @xmath79 .",
    "the blackboard therefore maintains the following data :    * a defining equation for each @xmath45 , and * comparisons between named terms , as above .",
    "note that this means that , _ a priori _ , modules can only look for and report comparisons between terms that have been `` declared '' to the blackboard .",
    "this is a central feature of our method : the search is deliberately constrained to focus on a small number of terms of interest .",
    "the architecture is flexible enough , however , that modules can heuristically expand that list of terms at any point in the search .",
    "for example , our addition and multiplication modules do not consider distributivity of multiplication over addition , beyond multiplication of rational scalars .",
    "but if a term @xmath80 appears in the problem , a module could heuristically add the identity @xmath81 , adding names for the new terms as needed .",
    "( bb ) at ( 0,2 ) [ rectangle , draw ] ; ( lin ) [ above left = of bb , rectangle , draw ] ; ( nonlin ) [ above right = of bb , rectangle , draw ] ; ( ax ) [ below = of bb , rectangle , draw ] ; ( exp ) [ below left = of bb , rectangle , draw ] ; ( min ) [ right = of bb , rectangle , draw ] ; ( cc ) [ left = of bb , rectangle , draw ] ; ( abs ) [ below right = of bb , rectangle , draw ] ; ( root ) [ above = of bb , rectangle , draw ] ; ( bb ) [ bend left=20 ] to node ( lin ) ; ( bb ) [ bend left=20 ] to node ( nonlin ) ; ( bb ) [ bend left=20 ] to node ( ax ) ; ( bb ) [ bend left=20 ] to node ( root ) ; ( bb ) [ bend left=20 ] to node ( exp ) ; ( bb ) [ bend left=5 ] to node ( min ) ; ( bb ) [ bend left=5 ] to node ( cc ) ; ( bb ) [ bend left=20 ] to node ( abs ) ; ( lin ) [ bend left=20 ] to node ( bb ) ; ( nonlin ) [ bend left=20 ] to node ( bb ) ; ( ax ) to [ bend left=20 ] node ( bb ) ; ( root ) to [ bend left=20 ] node ( bb ) ; ( exp ) to [ bend left=20 ] node ( bb ) ; ( min ) to [ bend left=5 ] node ( bb ) ; ( cc ) to [ bend left=5 ] node ( bb ) ; ( abs ) to [ bend left=20 ] node ( bb ) ;    ( abs ) to node ( ax ) ; ( exp ) to node ( ax ) ; ( root ) to node ( bb ) ; ( bb ) to node ( ax ) ;    to verify an implication , the user asserts the hypotheses to the blackboard , together with the negation of the conclusion .",
    "individual modules then take turns learning new comparisons from the data , and asserting them to the blackboard as well , until a contradiction is obtained , or no further conclusions can be drawn .",
    "the setup is illustrated by figure [ fig : bbarch ] .",
    "notice that this is essentially the nelson - oppen architecture @xcite @xcite , in which ( disjoint ) theories communicate by means of a shared logical symbol , typically equality . here , the shared language is instead assumed to contain the list of comparisons @xmath82 , and multiplication by rational constants .",
    "now suppose a module asserts an inequality like @xmath83 to the blackboard .",
    "it is the task of the central blackboard module to check whether the assertion provides new information , and , if so , to update its database accordingly .",
    "the task is not entirely straightforward : for example , the blackboard may already contain the inequality @xmath84 , but absent sign information on @xmath85 or @xmath86 , this does not imply @xmath83 , nor does the converse hold .",
    "however , if the blackboard includes the inequalities @xmath84 and @xmath87 , the new assertion is redundant .",
    "if , instead , the blackboard includes the inequalities @xmath84 and @xmath88 , the new inequality should replace the second of these . a moment",
    "s reflection shows that at most two such inequalities need to be stored for each pair @xmath45 and @xmath74 ( geometrically , each represents a half - plane through the origin ) , but comparisons between @xmath45 or @xmath74 and @xmath59 should be counted among these .",
    "there are additional subtleties : a weak inequality such as @xmath89 paired with a disequality @xmath90 results in a strong inequality ; a pair of weak inequalities @xmath89 and @xmath91 should be replaced by an equality ; and , conversely , a new equality can subsume previously known inequalities .",
    "the interactions , while not conceptually difficult , are intricate , and care is needed to get the details right .",
    "below , we will sometimes refer to the terms @xmath45 as the `` problem terms , '' that is , the terms that are registered with the blackboard as objects of comparison .      for each pair of problem terms @xmath45 and @xmath74 , we have noted that the blackboard stores the strongest comparison(s ) known to hold between them . sometimes another representation of this information is useful",
    ": we can ask for the range of @xmath22 such that @xmath92 is known to hold , and the values of @xmath22 for which the inequality is strict , as well as the dual questions with @xmath93 replaced by @xmath94 . a moment",
    "s reflection shows that if @xmath95 and @xmath96 , then @xmath92 for every value @xmath22 between @xmath97 and @xmath98 .",
    "thus , the range of coefficients @xmath22 for which such a comparison is known form a closed interval , of one of the forms @xmath99 $ ] , @xmath100 , @xmath101 $ ] , or @xmath102 .",
    "moreover , the comparison can be weak or strict at each finite endpoint , as well as weak or strict in the interior .",
    "these possibilities are not entirely independent : for example , if the comparison is strict at either endpoint , it will be strict in the interior .",
    "the blackboard s methods are capable of returning such a representation of the comparisons that hold between @xmath45 and @xmath74 , in both the @xmath93 and @xmath94 directions .",
    "more detail can be found in @xcite .",
    "this representation is currently used by the minimum module , described in section  [ subsection : minimum ] .",
    "the fourier - motzkin algorithm @xcite is a quantifier - elimination procedure for the theory of the structure @xmath103 , that is , the real numbers as an additive ordered group .",
    "nothing changes essentially if we add to the language of that theory the constant @xmath40 and scalar multiplication by @xmath22 , for each rational @xmath22 .",
    "here we see that the method can be used to infer comparisons between variables from additive data , and that this can be transported to the multiplicative setting as well .",
    "the fourier - motzkin additive module begins with the comparisons @xmath77 stored in the blackboard , where @xmath70 is one of @xmath104 ( disequalities are not used ) .",
    "it also makes use of comparisons @xmath75 , and all definitions @xmath105 in which the right - hand side is a sum .",
    "the goal is to learn new comparisons of the form @xmath77 or @xmath75 .",
    "the idea is simple : to learn comparisons between @xmath45 and @xmath74 , we need only eliminate all the other variables . for example ,",
    "suppose , after substituting equations , we have the following three inequalities : @xmath106 eliminating @xmath85 from the first two equations we obtain @xmath107 , from which we can conclude @xmath108 .",
    "eliminating @xmath85 from the last two equations we obtain @xmath109 , from which we can conclude @xmath110 .",
    "more generally , eliminating all the variables other than @xmath45 and @xmath74 gives the projection of the convex region determined by the constraints onto the @xmath111 plane , which determines the strongest comparisons for @xmath45 and @xmath74 that are implied by the data .",
    "constants can be represented using the special variable @xmath112 , which can be treated as any other variable . thus eliminating all variables except for @xmath45 and @xmath66 yields all comparisons between @xmath45 and a constant .",
    "the additive module simply carries out the elimination for each pair @xmath113 , @xmath114 . in general",
    ", fourier - motzkin elimination can require doubly - exponential time in the number of variables . with a bit of cleverness",
    ", one can use previous eliminations to save some work , but for a problem with @xmath58 subterms , one is still left with @xmath115-many instances of fourier - motzkin with up to @xmath58 variables in each .",
    "it is interesting to note that for the examples described in section  [ section : examples ] , the algorithm performs reasonably well . in section  [ section : geometric ] , however , we describe a more efficient approach .",
    "the fourier - motzkin multiplication module works analogously : given comparisons @xmath77 or @xmath75 and definitions of the form @xmath116 , the module aims to learn comparisons of the first two forms .",
    "the use of fourier - motzkin here is based on the observation that the structure @xmath103 is isomorphic to the structure @xmath117 under the map @xmath118 . with some translation , the usual procedure works to eliminate variables in the multiplicative setting as well . in the multiplicative",
    "setting , however , several new issues arise .",
    "first , the multiplicative module only makes use of terms @xmath45 which are known to be strictly positive or strictly negative .",
    "the multiplicative module thus executes a preprocessing stage which tries to infer new sign information from the available data .",
    "for example , given the definition @xmath119 and the sign information @xmath120 and @xmath121 , one can infer @xmath122 and assert this comparison to the blackboard .",
    "the processing phase also infers straightforward inequalities that hold even when sign information is not available ; for example , it infers @xmath123 whenever @xmath124 and @xmath125 are known , even if the signs of @xmath74 and @xmath126 are not known .",
    "this preprocessing somewhat compensates for the module s need for sign information .",
    "however , it is not robust ; the more systematic way to accommodate this constraint requires case splitting on the signs of variables .",
    "polya is able to do this in limited settings ; see the discussion in section  [ section : conclusions ] .",
    "second , the inequalities that are handled by the multiplicative module are different from those handled by the additive module , in that terms can have a rational coefficient . for example , we may have an inequality @xmath127 ; here , the multiplicative constant @xmath37 would correspond to an additive term of @xmath128 in the additive procedure .",
    "this difference makes it difficult to share code between the additive and multiplicative modules , since it prevents the logarithmic transformation from being carried out explicitly .",
    "but these rational coefficients are easy to handle in the multiplicative module .",
    "finally , the multiplicative elimination may produce information that can not be asserted directly to the blackboard , such as a comparison @xmath129 or @xmath130 . in that case",
    ", we have to pay careful attention to the signs of @xmath45 and @xmath74 and their relation to @xmath131 to determine which facts of the form @xmath77 can be inferred .",
    "we compute exact roots of rational numbers when possible , so a comparison @xmath132 translates to @xmath133 when @xmath45 and @xmath74 are known to be positive . as a last resort , faced with a comparison like @xmath134",
    ", we use a rational approximation of @xmath135 to try to salvage useful information .",
    "although the fourier - motzkin modules perform reasonably well on small problems , they are unlikely to scale well .",
    "the problem is that many of the inequalities that are produced when a single variable is eliminated are redundant , or subsumed by the others .",
    "thus , by the end of the elimination , the algorithm may be left with hundreds or thousands of comparisons of the form @xmath136 , for different values of @xmath22 .",
    "some optimizations are possible , such as using simplex based methods ( e.g.  @xcite ) to filter out some of the redundancies . in this section , however , we show how methods of computational geometry can be used to address the problem more directly . on many problems in our test suite ,",
    "performance is roughly the same .",
    "but on some problems of moderate complexity ( e.g. example [ eq:8i ] in section [ section : examples ] ) we have found our implementation of the geometric approach to be much faster than the fourier - motzkin approach .",
    "the two methods begin to differ noticeably when the number of problem terms is between 15 and 20 .",
    "geometric methods provide an alternative perspective on the task of eliminating variables . for real variables @xmath45 and constants @xmath137 , a linear inequality @xmath138 determines a half - space in @xmath139 ; when @xmath140 , as in the homogenized inequalities in our current problem , the defining hyperplane of the half - space contains the origin .",
    "a set of @xmath58 homogeneous inequalities determines an unbounded pyramidal polyhedron in @xmath141 with vertex at the origin , called a `` polyhedral cone . ''",
    "( equalities , represented as @xmath142-dimensional hyperplanes , simply reduce the dimension of the polyhedron . )",
    "the points inside this polyhedron represent solutions to the inequalities .",
    "the problem of determining the strongest comparisons between @xmath45 and @xmath74 then reduces to finding extremal ratios of the @xmath113-th and @xmath114-th coordinates of points inside the polyhedron .",
    "we use the following well - known theorem of computational geometry ( see ( * ? ? ?",
    "* section 1.1 ) ) :    a set @xmath143 is a finite intersection of closed homogeneous linear halfspaces ( an _ @xmath144-polyhedron _ ) if and only if it is a finitely generated conical combination of vectors ( a _ @xmath145-polyhedron _ ) .    a description of a @xmath145-polyhedron is said to be a _ @xmath145-representation _ of the polyhedron , and similarly for @xmath144-polyhedrons ; there are a number of effective methods to convert between representations .",
    ".45    .45    the comparisons and additive equalities stored in the central blackboard essentially describe an @xmath144-representation of a polyhedron . after constructing the corresponding @xmath145-representation ,",
    "it is easy to pick out the implied comparisons as follows . for every pair of variables @xmath45 and @xmath74 , project the set of vertices to the @xmath146 plane by setting all the other coordinates to @xmath59 .",
    "if there is anything to be learned , all ( nonzero ) vertices must fall in the same halfplane ; find the two outermost points ( as in figure [ fig : geo : projection : b ] ) and compute their slopes to the origin .",
    "these slopes determine the coefficients @xmath22 in two comparisons @xmath77 , and the relative position of the two vertices determine the inequality symbols in place of @xmath70 .",
    "we chose to use avis _ lrs _ implementation of the reverse - search algorithm @xcite to carry out the geometric computations .",
    "vertex enumeration algorithms typically assume convexity of the polyhedron : that is , all inequalities are taken to be weak . as it is essential for us to distinguish between @xmath147 and @xmath148",
    ", we use a trick taken from dutertre and de moura ( * ? ? ?",
    "* section 5 ) .",
    "namely , given a set of strict inequalities @xmath149 , we introduce a new variable @xmath150 with constraints @xmath151 and @xmath152 , and generate the corresponding polyhedron .",
    "the @xmath153 hyperplane is assumed to be infeasible .",
    "if , in the vertex representation , every vertex has a zero @xmath150-coordinate , then the inequalities are only satisfiable when @xmath154 , which implies that the system with strict inequalities is unsatisfiable .",
    "otherwise , a comparison @xmath136 is strict if and only if every vertex on the hyperplane @xmath155 has a zero @xmath150 coordinate , and weak otherwise .      as with the fourier - motzkin method , multiplicative comparisons @xmath156 can be handled in a similar manner , by restricting to terms with known sign information and taking logarithms .",
    "once again , there is a crucial difference from the additive setting : taking the logarithm of a comparison @xmath157 with @xmath158 , one is left with an irrational constant @xmath159 , and the standard computational methods for vertex enumerations can not perform exact computations with these terms .",
    "to handle this situation we introduce new variables to represent the logarithms of the prime numbers occurring in these constant terms .",
    "let @xmath160 represent the prime factors of all constant coefficients in such a problem , and for each @xmath161 , let @xmath162 be a variable representing @xmath163 .",
    "we can then rewrite each @xmath157 as @xmath164 . taking logarithms of all such inequalities",
    "produces a set of additive inequalities in @xmath165 variables . in practice ,",
    "the factorization problems are small and do not create a bottleneck for our algorithm .    in order to find the strongest comparisons between @xmath45 and @xmath74 , we can no longer project to the @xmath146 plane , but",
    "instead must look at the @xmath166 hyperplane .",
    "the simple arithmetical comparisons to find the two strongest comparisons are no longer applicable ; we face the harder problem of converting the vertex representation of a polyhedron to a half - space representation .",
    "this problem is dual to the conversion in the opposite direction , and the same computational packages are equipped to solve it .",
    "experimentally , we have found fukuda s _ cdd _ implementation of motzkin s double description method @xcite to be faster than _ lrs _ for this procedure .",
    "the inferences captured by the addition and multiplication modules constitute a fragment of the theory of real - closed fields , roughly , that theory `` minus '' the distributivity of multiplication over addition @xcite .",
    "recall , however , that we have also included arbitrary function symbols in the language .",
    "an advantage to our framework is that we do not have to treat function terms as uninterpreted constants ; rather , we can seamlessly add modules that ( partially ) interpret these symbols and learn relevant inequalities concerning them .    to start with ,",
    "a user may wish to add axioms asserting that a particular function @xmath29 is nonnegative , monotone , or convex .",
    "for example , the following axiom expresses that @xmath29 is nondecreasing : @xmath167 given such an axiom , polya s axiom module searches for useful instantiations during the course of a search , and may thus learn useful information .    specifically , given a list of universal axioms in variables @xmath168 ,",
    "the instantiation module searches for relevant assignments @xmath169 , where each @xmath137 is a constant and each @xmath170 is a subterm in the given problem .",
    "each axiom is then instantiated with these assignments , and added to the central blackboard as a set of disjunctive clauses .",
    "as the search progresses , elements of these clauses are refuted ; if only one remains , it is added to the blackboard , as a new piece of information available to all the modules .",
    "the task is a variant of the classic matching problem , but there are at least three aspects of our framework that present complications .",
    "first , given that we consider terms with a rational scalar multiplicative constant , the algorithm has to determine those values .",
    "so , in the example above , @xmath12 and @xmath13 can be instantiated to an s - term @xmath171 for any @xmath22 , when such an instantiation provides useful information .",
    "second , we need to take into account the associativity and commutativity of operations like addition and multiplication , so , for example , a term @xmath172 can be unified with a term @xmath173 found in the blackboard in multiple ways . finally ,",
    "although the framework is built around the idea of restricting attention to subterms occurring in the original problem , at times it is useful to consider new terms .",
    "for example , given the axiom @xmath174 it is clearly a good idea to instantiate @xmath12 and @xmath13 to @xmath45 and @xmath74 , respectively , whenever @xmath175 , @xmath176 , and @xmath177 all appear in the blackboard , even if the term @xmath178 does not .    in short ,",
    "we wish to avoid difficult calculations of rational constants , expensive matching up to associativity and commutativity ( see e.g.  @xcite ) , and unrestrained creation of new terms , while at the same time making use of potentially useful instantiations .",
    "the solution we adopted is to use function terms to trigger and constrain the matching process , an idea commonly used by smt solvers @xcite @xcite . given a universal axiom @xmath179 , @xmath180 is first converted into clausal normal form , and each clause @xmath181 is treated separately .",
    "we take the _ trigger set _ of @xmath181 to be the set of all functional subterms contained in @xmath180 .",
    "a straightforward unification procedure finds all assignments that map each trigger element to a ( constant multiple of a ) problem term , and these assignments are used to instantiate the full clause @xmath181 .",
    "the instantiated clause is asserted to the central blackboard , which checks for satisfied and falsified literals .",
    "for @xmath182 a term containing unification variables @xmath183 and @xmath184 an assignment mapping @xmath185 , the problem of matching @xmath186 to a problem term @xmath187 is nontrivial : the matching must be done modulo equalities stored in the blackboard . for example , if @xmath188 , @xmath189 , and @xmath190 , then given the assignment @xmath191 , the term @xmath192 should be matched to @xmath193 .",
    "we thus combine a standard unification algorithm , which suggests candidate assignments to the variables occurring in an axiom , with gaussian elimination over additive and multiplicative equations , to find the relevant matching substitutions .",
    "in addition to the axiom module , which interprets user - defined functions , polya incorporates a number of modules which interpret built - in functions .",
    "some of these modules simply assert axioms to the axiom module , and allow it to handle instantiation .",
    "other modules derive information that is too specialized to be handled by the generic axiom module .",
    "these modules therefore assert identities , comparisons , and clauses the the blackboard based on special features of the functions and terms they are designed to handle .",
    "polya s blackboard does not enforce that a function must have the same output given equal inputs .",
    "this property is known as _ congruence closure_. the well - known union - find data structure and its variations ( e.g.  @xcite @xcite ) provides an efficient way to maintain these equalities in a database .",
    "this maintenance is not a bottleneck for our algorithm , though , and a more naive approach works well .",
    "polya runs a congruence closure module that searches for pairs of problem terms with the same function symbol and arity .",
    "if the blackboard implies that each corresponding pair of arguments are equal , the module asserts that the terms are themselves equal .",
    "the runtime of this module is negligible compared to that of the arithmetical modules , so implementing a more structured method is not a priority .",
    "handling terms such as @xmath194 can be difficult , as this expression is undefined when @xmath195 .",
    "canonization must avoid unsound reductions such as simplifying @xmath196 to @xmath12 . on the other hand , when @xmath197 is known , additional reductions and inferences can be carried out .",
    "the canonizer interprets terms @xmath198 as @xmath199 , where @xmath200 is , in turn , interpreted as a function term @xmath201 , where @xmath58 is a positive integer constant .",
    "reasoning with these functions can largely be handled by the axiom instantiation module , such that for even @xmath58 , inferences about @xmath201 will be made only if @xmath19 is known to be positive .",
    "the @xmath58th root module guarantees that the proper axioms for a given problem have been added to the blackboard .",
    "the module finds a list of @xmath58 such that @xmath202 appears as some problem term , and axiomatizes the behavior of @xmath203 appropriately for each @xmath58 .",
    "if @xmath58 is even , the axioms @xmath204 are added to the instantiation module . if @xmath58 is odd , the axiom @xmath205 is added .",
    "these conditional identities provide a sound way of reasoning with fractional exponents .      without computing any exact or approximate values",
    ", we can describe the exponential function @xmath206 as a positive , strictly increasing function defined on all of @xmath207 . the module which interprets this function adds axioms asserting these properties to the axiom instantiation module .",
    "additionally , the exponential function satisfies the identities @xmath208 for scalar @xmath22 .",
    "these can not be axiomatized in a way that the instantiation module will recognize , so the exponential module searches for terms of the appropriate forms and adds equalities as appropriate .",
    "note that this operation is potentially expensive , in that it adds extra terms and multiplicative identities to the blackboard .",
    "the natural logarithm function @xmath209 has axioms and identities dual to the exponential . since @xmath210 is only defined on the positive reals , these axioms are defined conditionally .",
    "that is , the module asserts the axiom @xmath211 to the instantiation module , and only adds identities when the arguments are known to be positive .",
    "the minimum function @xmath212 is interpreted in the standard way : it returns the value of one of its arguments @xmath213 such that @xmath214 for all @xmath215 .",
    "terms involving @xmath216 are canonized in a manner similar to the way that sums are canonized : the arguments are listed according to the underlying term order , and a scalar is brought outside the function so that the first argument is an s - term with coefficient 1 . because the minimum function does not have a fixed arity , it can not be handled by the general axiom module .    for each problem term @xmath19 of the form @xmath217 in the blackboard @xmath218 ,",
    "the minimum module asserts that @xmath219 for @xmath220 .",
    "as it is useful to find as much sign information as possible for the multiplicative module , the minimum module also checks for @xmath221 if @xmath222 for all @xmath113 ; if so , it asserts that @xmath223 as well .    the module must also account for the fact that @xmath224 is the _",
    "smallest _ number less than or equal to all of its arguments .",
    "if for some constant @xmath225 and problem term @xmath52 we have @xmath226 for all @xmath215 , then we also know that @xmath227 .",
    "the minimum module uses the blackboard s methods for finding implied coefficient ranges to find , for each problem term @xmath52 , an interval @xmath99 $ ] for which @xmath228 $ ] implies @xmath226 holds for all @xmath215 .",
    "if such an interval exists , the module determines whether the inequalities are strict at the endpoints , and asserts the relevant information to the blackboard .",
    "polya has a specialized module for interpreting the absolute value function . the absolute value of an s - term is canonized by bringing the coefficient outside the absolute value , so that the argument is an s - term with coefficient 1 .",
    "basic properties of @xmath229 are handled by asserting the following axioms to the axiom module :    @xmath230    the axiom module can not handle the triangle inequality in full generality , and so the absolute value module handles this task on its own .",
    "specifically , the module adds comparisons of the forms @xmath231 adding these comparisons indiscriminately would necessitate creating new problem terms @xmath232 for each argument not already present in the blackboard , which is not likely to be fruitful . the absolute value module takes a more subtle approach , only learning these comparisons if for each @xmath114 , either @xmath232 is already a problem term , or the sign of @xmath74 is known ( in which case @xmath232 is replaced with @xmath233 as appropriate ) .",
    "this approach does not seem to miss any inferences that the indiscriminate approach would capture , since the comparisons learned will only be useful if something is known about each absolute value .",
    "the procedure , however , puts additional stress on the modules for arithmetic : for example , the presence of a term @xmath234 can result in four additional linear inequalities with three terms common to all of them .",
    "sometimes , only minimal information about a function is needed to complete a proof ; for instance , it may suffice to know that @xmath235 or @xmath236 .",
    "polya s built - in functions module will add simple axioms like this for a variety of common functions .",
    "of course , one could create new modules to interpret any of these functions individually , and add more information than the basic properties used here .",
    "the goal of this module is to expand polya s breadth more so than its depth .",
    "the built - in functions module currently axiomatizes @xmath237 and @xmath238 as bounded between @xmath239 and @xmath40 , @xmath240 as equal to @xmath241 , and @xmath242 as bounded between @xmath243 ( strictly ) and @xmath12 ( weakly ) .",
    "the current distribution of polya includes a number of examples that are designed to illustrate the method s strengths , as well as some of its weaknesses . for comparison",
    ", we verified a number of these examples in isabelle , trying to use isabelle s automated tools as much as possible .",
    "these include `` auto , '' an internal tableau theorem prover which also invokes a simplifier and arithmetic reasoning methods , and sledgehammer @xcite @xcite , which heuristically selects a body of facts from the local context and background library , and exports it to various provers .",
    "we also sent some of the inferences directly to the smt solver z3 @xcite .",
    "we report on these results below .",
    "we also tried a number of these problems with metitarski @xcite and acl2 @xcite , which are discussed in section  [ section : conclusions ] .      to start with",
    ", polya handles inferences involving linear real inequalities , which are verified automatically by many interactive theorem proving systems .",
    "it can also handle purely multiplicative inequalities such as @xmath244 which are not often handled automatically .",
    "it can solve problems that combine the two , like these : @xmath245 it also handles inferences that combine such reasoning with axiomatic properties of functions , such as : @xmath246 isabelle s auto and sledgehammer fail on all of these but ( [ eq:4 ] ) and ( [ eq:5 ] ) , which are proved by resolution theorem provers .",
    "sledgehammer can verify more complicated variants of ( [ eq:4 ] ) and ( [ eq:5 ] ) by sending them to z3 , but fails on only slightly altered examples , such as : @xmath247 z3 gets most of these when called directly , but also fails on ( [ eq:7 ] ) and ( [ eq:8 ] ) . moreover , when handling nonlinear equations , z3 `` flattens '' polynomials , which makes a problem like ( [ eq:3p5 ] ) extremely difficult .",
    "it takes z3 a couple of minutes when the exponents @xmath37 and @xmath248 in that problem are replaced by @xmath249 and @xmath250 , respectively .",
    "polya verifies all of these problems in a fraction of a second , and is insensitive to the exponents in ( [ eq:3p5 ] ) .",
    "it is also unfazed if any of the variables above are replaced by more complex terms .",
    "polya has built - in knowledge about functions such as @xmath251 , @xmath210 , @xmath252 , @xmath253 , @xmath254 , @xmath255 , and @xmath256 .",
    "it verifies examples like these : @xmath257{u^9v^4 } > u^3 v\\end{gathered}\\ ] ] it can also handle examples that combine such functions , such as these : @xmath258 z3 fails on ( [ eq:8a ] ) , ( [ eq:8b ] ) , ( [ eq:8d ] ) , and ( [ eq:8i ] ) , even when the relevant properties of @xmath251 , @xmath210 , etc .  are given as axioms .",
    "given the right properties , however , it succeeds on the others .",
    "similarly , isabelle s auto tactic does well on problems that can combine rules for common functions with linear arithmetic ; it solves ( [ eq:8cc ] ) , ( [ eq:8d ] ) , ( [ eq:8f ] ) , and ( [ eq:8h ] ) , with the additional information that it should case split on the sign of the terms inside the absolute value on ( [ eq:8d ] ) .",
    "it fails when @xmath259 is replaced by @xmath260 in ( [ eq:8h ] ) .",
    "sledgehammer verified ( [ eq:8c ] ) using the resolution theorem prover vampire , but neither auto nor sledgehammer solves the others .",
    "polya succeeds examples such as @xmath261 mentioned in the introduction .",
    "sledgehammer verifies this using resolution , and slightly more complicated examples by calling z3 with the monotonicity of @xmath251 .",
    "sledgehammer restricts z3 to linear arithmetic so that it can reconstruct proofs in isabelle , so to verify ( [ eq:9 ] ) it provides z3 with the monotonicity of the power function as well . when called directly on this problem with this same information",
    ", however , z3 resorts to nonlinear mode , and fails .",
    "sledgehammer fails on an example that arose in connection with a formalization of the prime number theorem , discussed in @xcite : @xmath262 z3 verifies it when called directly .",
    "sledgehammer also fails on these @xcite : @xmath263 z3 gets ( [ eq:11 ] ) but not ( [ eq:12 ] ) . neither sledgehammer nor",
    "z3 get these : @xmath264 polya verifies all of the above easily .",
    "the following problem was once raised on the isabelle mailing list : @xmath265 this inference is verified by z3 as well as sledgehammer , but both fail when @xmath12 and @xmath13 in the conclusion are replaced by @xmath266 and @xmath267 , respectively .",
    "polya is insensitive to the exponent .",
    "let us consider two examples that have come up in recent isabelle formalizations @xcite .",
    "billingsley @xcite shows that if @xmath29 is any function from a measure space to the real numbers , the set of continuity points of @xmath29 is borel . formalizing the proof involved verifying the following inequality : @xmath268 sledgehammer and z3 fail on this , while polya verifies it easily .",
    "the second example involves the construction of a sequence @xmath269 in an interval @xmath270 with the property that for every @xmath271 , @xmath272 .",
    "the proof required showing that @xmath269 approaches @xmath273 from the right , in the sense that for every @xmath274 , @xmath275 for @xmath276 sufficiently large .",
    "a little calculation shows that @xmath277 is sufficient .",
    "we can implicitly restrict the domain of @xmath29 to the integers by considering only arguments @xmath278 ; thus the required inference is @xmath279 sledgehammer and z3 do not capture this inference , and the isabelle formalization was tedious .",
    "polya verifies it immediately .",
    "when restricted to problems involving linear arithmetic and axioms for function symbols , the behavior of z3 and polya is similar , although z3 is much more efficient .",
    "as the examples above show , polya s advantages show up in problems that combine multiplicative properties with either linear arithmetic or axioms involving function symbols .",
    "in addition , adding certain axioms to z3 can cause unexpected interactions : the axioms @xmath280 and @xmath281 jointly cause z3 to fail , even on problems that do not involve any absolute values .",
    "for the kinds of problems described in this section , time constraints are not a serious issue .",
    "polya solves a test suite of 81 problems , including the ones discussed here , in about 8.5 seconds on an ordinary desktop ( with an intel i7 - 3770 4 core cpu at 3.4 ghz ) , using the polytope packages , the full set of modules , and a set of standard axioms .",
    "as noted in sections  [ subsection : exponential ] and [ subsection : absolute ] , however , the exponential and absolute value modules put additional stress on the arithmetic modules .",
    "problem  ( [ eq:8i ] ) comes close to the limit of what the fourier - motzkin procedures can handle , and polya takes more than a minute on that problem using those procedures .",
    "if we eliminate that problem and two similar ones from the test suite , polya solves the remainder with the fourier - motzkin procedures in about 13.5 seconds .",
    "moreover , instructing polya not to solve problem ( [ eq:9 ] ) without using the exponential module reduces the total to less than 11 seconds . under the same conditions",
    ", polya solves the test suite in 6 seconds using the polytope packages .",
    "we expect that various optimizations and improvements are possible .    in a prior version of this paper @xcite ,",
    "our test suite included only 51 problems that could be solved without invoking any of the modules described in section  [ section : other : modules ] other than the congruence closure module .",
    "polya solved these in about 2 seconds on an ordinary desktop using the polytope packages , and in about 5.5 seconds using fourier - motzkin .",
    "test files for isabelle , z3 , metitarski , and acl2 , as well as more precise benchmark results , can be found in the distribution .",
    "keymaera is a verification tool for hybrid systems that combines automated deduction , real - algebraic methods , and computer algebra @xcite @xcite . among other applications",
    ", it has been used to verify control systems for transportation systems .",
    "the current version of keymaera uses z3 and mathematica as a backend for solving the algebraic problems it generates .",
    "these algebraic problems are often well - suited for polya s approach .",
    "we obtained a collection of 4442 problems generated by keymaera .",
    "with a 3 second timeout and case splitting disabled , polya was able to verify the unsatisfiability of 4252 ( 96% ) in about six minutes .",
    "( with case splitting enabled , polya solves an additional 15 problems , but runs for about ten minutes . )",
    "while we were unable to obtain direct comparisons , the experimental results in @xcite report a similar percentage of examples solved by the best available methods .",
    "of course , polya fails on wide classes of problems where other methods succeed .",
    "it is much less efficient than the best linear solvers , for example , and should not be expected to scale to large industrial problems .",
    "polya has other shortcomings .",
    "recall that the multiplicative module only takes advantage of equations where the signs of all terms are known . when called directly , the module fails to make the trivial inference @xmath282 the preprocessing step described in section [ subsection : fm : multiplicative ] enables polya to prove this , but this preprocessing is not robust , and minor adjustments cause polya to fail : @xmath283    the problem just described is easily solved by case splitting on the signs of @xmath13 and @xmath284 .",
    "this is an instance of a general heuristic : it is often useful to split on the signs of problem terms involved in multiplicative terms , when the signs of these terms are not known .",
    "there are other situations where a case split can help when polya is stuck .",
    "for example , one can split on comparisons in a binary minimum or maximum : polya proves @xmath285 from either @xmath286 or @xmath287 , but not outright .",
    "similarly , it is generally useful to split on the sign of an absolute value .",
    "we have implemented a mechanism whereby modules can suggest useful case splits for the system to try , as the system carries out nested splits to a user - defined maximum depth .",
    "the current implementation is naive and inefficient , however , and needs to be improved ( see the discussion in the next section ) .",
    "polya s strength comes from the fact that rules and axioms are limited to a small list of `` terms of interest '' stored in the blackboard , allowing modules to contribute information in a flexible way while avoiding combinatorial explosion . but",
    "this results in a kind of `` tunnel vision , '' causing polya to miss inferences that require passage through auxiliary terms .",
    "for example , polya fails to validate @xmath288 because it does not consider the intermediate term @xmath289 .",
    "if this term is added to the blackboard , polya easily infers @xmath290 , and then @xmath291 .",
    "users can specify such additional terms to consider when posing a problem .",
    "generally speaking , however , it is not an easy task to determine automatically what terms should heuristically be added to the blackboard , and when .",
    "another shortcoming , in contrast to methods which begin by flattening polynomials , is that polya does not , _ a priori _ , make use of distributivity at all , beyond the distributivity of multiplication by a rational constant over addition .",
    "of course , it is by ignoring distributivity that we make the problem modular and tractable ; this ignorance is a basic feature of the system , in some sense .",
    "however , this leads to some unfortunate consequences .",
    "any reasonable theorem prover for the theory of real - closed fields can easily establish @xmath292 which can also be obtained simply by writing the left - hand side as @xmath293 .",
    "but , as pointed out by avigad and friedman @xcite , the method implemented by polya is , in fact , nonterminating on this example .",
    "one advantage of the method described here is that it should not be difficult to generate proof certificates that can be verified independently and used to construct formal derivations within client theorem provers .",
    "in fact , with only minor modifications to the code , we have implemented rudimentary proof tracing , taking variable eliminations in the fourier motzkin modules as primitive proof steps . for procedures using real - closed fields ,",
    "this is much more difficult ; see @xcite @xcite .",
    "we tried a number of our test problems in metitarski @xcite , which combines resolution theorem proving with procedures for real - closed fields as well as symbolic approximations to transcendental functions .",
    "we found that metitarski does well on problems in the language of real - closed fields , but not with axioms for interpreted functions , nor with the examples with @xmath251 .",
    "an interesting heuristic method , implemented in acl2 , is described in @xcite .",
    "that method is considerably different from ours ; for example , it flattens polynomial terms .",
    "working with acl2 involves importing `` books '' that not only define the concepts in a given domain , but also configure acl2 s automation to adopt suitable proof strategies .",
    "we experimented with acl2 on some of the problems in our test suite , with what we took to be a reasonable set of imports .",
    "( we are grateful to grant passmore for guidance here . ) in this context , acl2 solved 21 out of the 39 of our benchmark problems that involve only arithmetic .",
    "when it came to problems involving extra function symbols , we found that acl2 was sensitive to the amount of background information provided ; it did well with individual properties , such as the property that a function is monotone , but fared less well with large batteries of facts about log and exp .",
    "it seems likely , however , that acl2 can be made to perform better on our benchmarks with a more finely tuned default .",
    "it also seems likely that polya would benefit by incorporating some of acl2 s heuristics .",
    "( the preliminary tests described in this paragraph can be found in the polya repository . )",
    "we envision numerous extensions to our method .",
    "one possibility is to implement more efficient case splitting and conflict - driven clause learning ( cdcl ) search , as do contemporary smt solvers .",
    "for example , recall that the multiplicative routines only work insofar as the signs of subterms are known .",
    "it is often advantageous , therefore , to split on the signs on subterms .",
    "the current implementation of polya can do so naively , but contemporary mechanisms for backtracking assumptions are vastly more efficient .",
    "similarly , making the addition and multiplication modules incremental would streamline this as well .",
    "there are many ways our implementation could be optimized , and , of course , we would gain efficiency by moving from python to a compiled language like c++ .",
    "we find it encouraging , however , that even our unoptimized prototype performs well on interesting examples .",
    "it seems to us to be more important , therefore , to explore extensions of these methods , and try to capture wider classes of inequalities .",
    "this includes reasoning with powers and logarithms to an arbitrary base ; reasoning about the integers as a subset of the reals ; reasoning about common functions , such as trigonometric functions ; and heuristically allowing other natural moves in the search , such as flattening or factoring polynomials , when helpful .",
    "we would also like to handle second - order operators like integrals and sums , and interact better with external theorem proving methods .",
    "we emphasize again that this method is not designed to replace conventional methods for proving linear and nonlinear inequalities , which are typically much more powerful and efficient in their intended domains of application .",
    "rather , our method is intended to complement these , capturing natural but heterogeneous patterns of reasoning that would otherwise fall through the cracks .",
    "what makes the method so promising is that it is open - ended and extensible .",
    "additional experimentation is needed to determine how well the method scales and where the hard limitations lie .",
    "c.  n. jones , e.  c. kerrigan , j.  m. maciejowski .",
    "equality set projection : a new algorithm for the projection of polytopes in halfspace representation .",
    "technical report , department of engineering , university of cambridge , march 2004 ."
  ],
  "abstract_text": [
    "<S> we describe a general method for verifying inequalities between real - valued expressions , especially the kinds of straightforward inferences that arise in interactive theorem proving . </S>",
    "<S> in contrast to approaches that aim to be complete with respect to a particular language or class of formulas , our method establishes claims that require heterogeneous forms of reasoning , relying on a nelson - oppen - style architecture in which special - purpose modules collaborate and share information . </S>",
    "<S> the framework is thus modular and extensible . </S>",
    "<S> a prototype implementation shows that the method works well on a variety of examples , and complements techniques that are used by contemporary interactive provers . </S>"
  ]
}