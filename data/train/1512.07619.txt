{
  "article_text": [
    "high - dimensional models have become increasingly popular in the last two decades .",
    "much research has been conducted on estimation of these models .",
    "however , inference about parameters in these models is much less understood , although the literature on inference is growing quickly ; see the list of references below .",
    "in particular , despite its practical relevance , there is almost no research on the problem of construction of simultaneous confidence bands on many target parameters in these models ( with one exception being @xcite ) . in this paper",
    "we provide a solution to this problem by constructing simultaneous confidence bands for parameters in a very general framework of moment condition models , allowing for many functional parameters , where each parameter itself can be an infinite - dimensional object , and the number of parameters can be much larger than the sample size of available data . as a substantive application , we apply the results to provide simultaneous confidence bands for parameters in a functional logistic regression model , which includes the so called distributional regression and conditional transformation models as special cases .",
    "( in particular , this contribution goes much beyond @xcite , which considers the special case of many scalar parameters ) .    specifically , we consider the problem of estimating the set of parameters @xmath3}$ ] in the moment condition model @xmath4 = 0 , \\quad { { u}}\\in { \\mathcal{u } } , \\",
    "j \\in [ { { \\tilde p}}],\\ ] ] where @xmath5 is a random element that takes values in a measurable space @xmath6 according to the probability measure @xmath7 , and @xmath8 and @xmath9:=\\{1,\\dots,{{\\tilde p}}\\}$ ] are sets of indices .",
    "for each @xmath10 and @xmath11 $ ] , @xmath12 is a known score function , @xmath13 is a scalar parameter of interest , and @xmath14 is a potentially high - dimensional ( or infinite - dimensional ) nuisance parameter . assuming that a random sample of size @xmath1 , @xmath15 , from the distribution of @xmath5 is available together with suitable estimators @xmath16 of @xmath17 for @xmath10 and @xmath11 $ ] , we aim to construct simultaneous confidence bands for @xmath3}$ ] that are valid uniformly over a large class of probability measures @xmath7 , say @xmath18 .",
    "specifically , for each @xmath10 and @xmath11 $ ] , we construct an appropriate estimator @xmath19 of @xmath13 along with an estimator of the standard deviation of @xmath20 , @xmath21 , such that @xmath22 \\right)- ( 1-\\alpha ) \\right| = o(1),\\ ] ] where @xmath23 and @xmath24 is an appropriate critical value , which we choose to construct using a multiplier bootstrap method .",
    "the left- and the right - hand sides of the inequalities inside the probability statement then can be used as bounds in simultaneous confidence bands for @xmath13 s . in this paper",
    ", we are particularly interested in the case when @xmath0 is potentially much larger than @xmath1 and @xmath25 is an uncountable subset of @xmath26 , so that for each @xmath11 $ ] , @xmath27 is an infinite - dimensional ( that is , functional ) parameter .",
    "this general framework covers a broad variety of applications .",
    "for example , consider a finite - dimensional generalized linear model for a response variable @xmath28 and covariates @xmath29 and @xmath30 given by @xmath31 =   \\lambda(d\\theta_0+x'\\beta_0),\\ ] ] where @xmath29 is a scalar , @xmath30 is a @xmath32-vector ( @xmath32 is potentially large ) , @xmath33 is a known link function , @xmath34 is a parameter of interest , and @xmath35 is a nuisance parameter .",
    "this model is a particular case of our general framework with the moment condition @xmath36 = 0,\\ ] ] where @xmath25 is a singleton , @xmath37 , @xmath38 and @xmath39 for @xmath10 and @xmath11 $ ] , and @xmath40 .",
    "another example fitting into our framework is a logistic regression model with functional response data @xmath41 = { { \\lambda}}(d'\\theta_u+x'\\beta_u ) , \\ \\",
    "u\\in { \\mathcal{u}},\\ ] ] where @xmath29 is now a @xmath0-vector with @xmath0 being potentially much larger than @xmath1 , @xmath42 is a @xmath0-vector of parameters of interest , @xmath43 $ ] is a set of indices , @xmath44 for some constants @xmath45 and all @xmath10 , and @xmath33 is the logistic link function defined by @xmath46 for all @xmath47 .",
    "here we have @xmath48 infinite - dimensional parameters @xmath49 , @xmath50 .",
    "this example is important because it demonstrates that our methods can be used for inference about the whole distribution of the response variable @xmath28 given @xmath29 and @xmath30 in a high - dimensional setting , and not only about some particular features of it such as mean or median .",
    "this model is called a distribution regression model in @xcite and a conditional transformation model in @xcite , who argue that the model provides a rich class of models for conditional distributions , and offers a useful generalization of traditional proportional hazard models as well as a useful alternative to quantile regression .",
    "we develop inference methods for many functional parameters of this model in detail in section [ sec : application ] .    in the presence of high - dimensional nuisance parameters ,",
    "construction of valid confidence bands is delicate .",
    "high - dimensionality requires relying upon regularization that leads to lack of asymptotic linearization of the estimators .",
    "this lack of asymptotic linearization in turn typically translates into severe distortions in coverage probability of the confidence bands constructed by traditional techniques that are based on perfect model selection ; see @xcite , @xcite , @xcite , @xcite .    to deal with this problem , we consider moment conditions @xmath51=0 , \\quad { { u}}\\in { \\mathcal{u } } , \\ j \\in [ { { \\tilde p}}]\\ ] ] based on score functions @xmath52 with an additional near orthogonality property that makes them immune to first - order changes in the value of the nuisance parameter , namely @xmath53\\bigg\\}\\right|_{r=0}\\approx 0 , \\quad \\ u \\in { \\mathcal{u } } ,",
    "\\ j\\in[{{\\tilde p}}],\\ ] ] for all @xmath54 in an appropriate set where @xmath55 denotes the derivative with respect to @xmath56 .",
    "we shall often refer to this property as the _ neyman orthogonality _",
    ", since in low - dimensional parametric settings the orthogonality property originates in the work of neyman on the @xmath57 test in the 50s .    for example , in the finite - dimensional generalized linear model ( [ leadingexample ] ) , a score function with such an orthogonality property is @xmath58 where the nuisance parameter is @xmath59 , and @xmath60 $ ] for @xmath61 .",
    "it satisfies the moment condition and also satisfies the near orthogonality condition ( [ defortho ] ) since @xmath62\\big\\}\\right|_{\\beta=\\beta_0}=-{{\\mathrm{e}}}_p\\big[f^2_0\\ { d - x'\\gamma_0\\}x\\big ] = 0,\\\\ & \\left.\\partial_\\gamma\\big\\{{{\\mathrm{e}}}_p[\\psi(w,\\theta_0,\\beta_0,\\gamma)]\\big\\}\\right|_{\\gamma=\\gamma_0}=-{{\\mathrm{e}}}_p\\big[\\{y - \\lambda(d\\theta_0+x'\\beta_0 ) \\}x\\big ] = 0,\\end{aligned}\\ ] ] where the first line holds by the definition of @xmath63 , and the second by ( [ leadingexample ] ) .",
    "because of this orthogonality property , we can exploit the moment conditions based on these new score functions to construct a regular , @xmath64-consistent , estimator of @xmath34 even if non - regular , regularized or post - regularized , estimators of @xmath35 and @xmath63 are used to cope with high - dimensionality .",
    "then we can construct confidence bands for @xmath34 based on this regular estimator .",
    "our general approach , which is developed in section [ sec : general ] , can be described as follows .",
    "first , we transform the moment conditions into those based on the score functions with the near orthogonality property , and use these new moment conditions to construct an estimator @xmath19 of @xmath13 for all @xmath10 and @xmath11 $ ] .",
    "second , under appropriate regularity conditions , we establish a bahadur representation for @xmath19 s .",
    "third , employing the bahadur representation , we are able to derive a suitable gaussian approximation for the distribution of @xmath19 s .",
    "importantly , the gaussian approximation is possible even if both @xmath0 and the dimension of the index set @xmath25 , @xmath65 , are allowed to grow with @xmath1 , and @xmath0 asymptotically remains much larger than @xmath1 .",
    "finally , from the gaussian approximation , we construct simultaneous confidence bands using a multiplier bootstrap method .",
    "this approach makes use of the results on high - dimensional central limit and bootstrap theorems established in @xcite , @xcite , @xcite , @xcite , and @xcite .",
    "although regularity conditions underlying our approach can be verified for many models defined by moment conditions , for illustration purposes , we explicitly verify these conditions for the logistic regression model with functional response data ( [ def : functionallogistic ] ) in section [ sec : application ] .",
    "we also examine the performance of the proposed procedures in a monte carlo simulation study and provide an example based on real data in section [ sec : simulations ] .",
    "in addition , in the supplementary material , we discuss the construction of simultaneous confidence bands based on a double - selection estimator .",
    "this estimator does not require to explicitly construct the new score functions but nonetheless is first - order equivalent to the estimator based on such functions .",
    "we also develop new results for @xmath66-penalized @xmath67-estimators in section [ functionallassosection ] to handle functional data and criterion functions that depend on nuisance functions for which only estimates are available ( for brevity of the paper , generic results are deferred to appendix [ sec : generic results ] of the supplementary material , and section [ functionallassosection ] only contains results that are relevant for the logistic regression model studied in section [ sec : application ] ) .",
    "specifically , we develop a method to select penalty parameters for these estimators and extend the existing theory to cover functional data to achieve rates of convergence and sparsity guarantees that hold uniformly over @xmath68 .",
    "the ability to allow both for functional data and for nuisance functions is crucial in the implementation and in theoretical analysis of the methods proposed in this paper .",
    "orthogonality conditions like that in have played an important role in statistics and econometrics . in low - dimensional settings , a similar condition was used by neyman in @xcite and @xcite while in semiparametric models the orthogonality conditions were used in @xcite , @xcite , @xcite , @xcite and @xcite . in high - dimensional settings ,",
    "@xcite and @xcite were the first to use the orthogonality condition ( [ defortho ] ) in a linear instrumental variables model with many instruments .",
    "related ideas have also been used in the literature to construct confidence bands in high - dimensional linear models , generalized linear models , and other non - linear models ; see @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite .",
    "we contribute to this quickly growing literature by providing procedures to construct _ simultaneous _ confidence bands for _ many infinite - dimensional _ parameters identified by moment conditions .",
    "in this section , we formally introduce the model and state our results under high - level conditions . in the next section",
    ", we will apply these results to construct simultaneous confidence bands for many infinite - dimensional parameters in the logistic regression model with functional response data .",
    "we are interested in a set of parameters @xmath69}$ ] where for each @xmath70 and @xmath11=\\{1,\\dots,{{\\tilde p}}\\}$ ] , we have @xmath71 , a convex subset of @xmath72 . here",
    "@xmath25 is possibly an uncountable set of indices , and @xmath0 is potentially large .",
    "we assume that for each @xmath73 and @xmath74 $ ] , the parameter @xmath75 satisfies the moment condition @xmath76 = 0,\\ ] ] where @xmath5 is a random element that takes values in a measurable space @xmath77 , with law determined by a probability measure @xmath78 , @xmath14 is a nuisance parameter with @xmath79 , a convex set equipped with a norm @xmath80 , and the score function @xmath81 is a measurable map ( where we equip @xmath82 and @xmath83 with their borel @xmath84-fields ) . here",
    "@xmath85 is some set of probability measures on @xmath77 .",
    "note that our formulation allows the nuisance parameters @xmath14 to be infinite - dimensional ( i.e. functions ) .",
    "we focus on the estimation of @xmath3}$ ] using a random sample @xmath15 from the distribution of @xmath5 .",
    "we assume that for each @xmath10 and @xmath11 $ ] , the nuisance parameter @xmath17 can be estimated by @xmath86 using the same data @xmath15 . in the next section ,",
    "we discuss examples where @xmath87 s are based on lasso or post - lasso methods ( although other modern regularization and post - regularization methods can be applied ) . for each @xmath10 and @xmath11 $ ]",
    ", we construct the estimator @xmath88 of @xmath89 as an approximate @xmath90-solution in @xmath91 to a sample analog of the moment condition ( [ eq : ivequation ] ) , that is , @xmath92 }   \\left\\ { \\big|{{\\mathbb{e}_n } } [ \\psi_{uj}(w , \\check \\theta_{uj } , { \\widehat}\\eta_{uj } ) ] \\big| - \\inf_{\\theta \\in \\theta_{uj}}\\big|{{\\mathbb{e}_n } } [ \\psi_{{{u}}j}(w , \\theta , { \\widehat}\\eta_{uj } ) ] \\big| \\right\\ } { \\leqslant}\\epsilon_n = o(\\delta_n n^{-1/2}),\\ ] ] where @xmath93 is some sequence of positive constants converging to zero .",
    "let @xmath94 be a strictly positive ( and finite ) constant , and for each @xmath10 and @xmath11 $ ] , let @xmath95 be some subset of @xmath83 , whose properties are specified below in assumptions . as discussed before",
    ", we rely on the following near orthogonality condition :    for each @xmath73 and @xmath11 $ ] , we say that @xmath96 obeys the near orthogonality condition with respect to @xmath97 if the following conditions hold : the gateaux derivative map @xmath98:=   \\left .",
    "\\partial_r   \\bigg\\{{{\\mathrm{e}}}_p \\big [   \\psi_{{{u}}j } ( w , \\theta_{{{u}}j } , \\eta_{uj}+ r ( \\eta - \\eta_{uj } ) )    \\big ] \\bigg\\}\\right|_{r=\\bar r}\\ ] ] exists for all @xmath99 and @xmath100 and ( nearly ) vanishes at @xmath101 , namely , @xmath102\\big|{\\leqslant}c_0\\delta_n n^{-1/2},\\ ] ] for all @xmath103 .    if the original score functions @xmath12 do not satisfy this near orthogonality condition , we have to transform them into score functions @xmath52 that satisfy this condition . at the end of this section , we describe two methods to obtain score functions @xmath52 .",
    "together these methods cover a wide variety of applications .",
    "let @xmath104 and @xmath105 be some strictly positive ( and finite ) constants , and let @xmath106 be some positive integer .",
    "also , let @xmath107 and @xmath108 be some sequences of positive constants , possibly growing to infinity , where @xmath109 for all @xmath110 .",
    "denote @xmath111}\\big|\\sqrt{n}{{\\mathbb{e}_n}}[\\psi_{uj}(w , \\theta_{uj } , \\eta_{uj } ) ] \\big|\\right],\\quad j_{{{u}}j } : =   \\left.\\partial_\\theta\\big\\ { { { \\mathrm{e}}}_p [ \\psi_{{{u}}j } ( w , \\theta , \\eta_{uj})]\\big\\}\\right|_{\\theta=\\theta_{uj}}.\\end{aligned}\\ ] ] the quantity @xmath112 measures how rich the process @xmath113\\}$ ] is .",
    "in many applications , it satisfies @xmath114 for some constant @xmath115 .",
    "the quantity @xmath116 measures the degree of identifiability of @xmath13 by the moment condition . in many applications , it is bounded in absolute value from above and away from zero .",
    "we are now ready to state our main regularity conditions .",
    "[ ass : s1 ] for all @xmath117 , @xmath118 , @xmath10 , and @xmath11 $ ] , the following conditions hold : ( i ) the true parameter value @xmath89 obeys ( [ eq : ivequation ] ) , and @xmath119 contains a ball of radius @xmath120 centered at @xmath89 .",
    "( ii ) the map @xmath121 $ ] is twice continuously gateaux - differentiable on @xmath122 .",
    "( iii ) the moment function @xmath96 obeys the near orthogonality condition given in definition 2.1 for the set @xmath123 .",
    "( iv ) for all @xmath124 , @xmath125| { \\geqslant}2^{-1}|j_{uj } ( \\theta- \\theta_{u j})| \\wedge c_0 $ ] , where @xmath126 satisfies @xmath127 . (",
    "v ) for all @xmath128 , @xmath129 , and @xmath130 ,    * @xmath131{\\leqslant}c_0   ( |\\theta-\\theta_{u j}|\\vee \\| \\eta - \\eta_{u j}\\|_e)^{\\omega}$ ] , * @xmath132| { \\leqslant}b_{1n } \\|\\eta-\\eta_{uj}\\|_e $ ] , * @xmath133| { \\leqslant}b_{2n } ( |\\theta-\\theta_{uj}|^2 \\vee \\|\\eta-\\eta_{uj}\\|_{e}^2)$ ] .",
    "assumption [ ass : s1 ] is mild and standard in moment condition problems .",
    "assumption [ ass : s1](i ) requires @xmath13 to be sufficiently separated from the boundary of @xmath82 .",
    "assumption [ ass : s1](iii ) is discussed above .",
    "assumption [ ass : s1](iv ) implies sufficient identifiability of @xmath13",
    ". assumptions [ ass : s1](ii , v ) are smoothness conditions .",
    "assumption [ ass : s1](ii ) is rather weak because it only requires differentiability of the function @xmath134 $ ] and does not require differentiability of the function @xmath135 .",
    "next , we state conditions related to the estimators @xmath136 , @xmath10 and @xmath11 $ ] .",
    "let @xmath137 and @xmath138 be some sequences of positive constants converging to zero .",
    "also , let @xmath139 , @xmath140 , and @xmath141 be some sequences of positive constants , possibly growing to infinity , where @xmath142 and @xmath143 for all @xmath110 .",
    "finally , let @xmath144 be some constant .",
    "[ ass : as ] for all @xmath117 and @xmath145 , the following conditions hold : ( i ) with probability at least @xmath146 , we have @xmath147 for all @xmath10 and @xmath11 $ ] .",
    "( ii ) for all @xmath10 , @xmath11 $ ] , and @xmath148 , @xmath149 ( iii ) for all @xmath10 and @xmath11 $ ] , we have @xmath150 .",
    "( iv ) the function class @xmath151 ,   \\theta \\in \\theta_{uj } , \\eta \\in { \\mathcal{t}}_{uj } \\}$ ] is suitably measurable and its uniform entropy numbers obey @xmath152 where @xmath153 is a measurable envelope for @xmath154 that satisfies @xmath155 .",
    "( v ) for all @xmath156 , we have @xmath157 . ( vi ) the complexity characteristics @xmath158 and @xmath159 satisfy    * @xmath160 , * @xmath161 , * @xmath162 .",
    "assumption [ ass : as ] provides sufficient conditions for the estimation of the nuisance parameters @xmath163}$ ] .",
    "it shows that the choice of the sets @xmath164 is delicate : setting @xmath164 large , on the one hand , makes it easy to satisfy assumption [ ass : as](i ) but , on the other hand , yields large values of @xmath158 and @xmath165 making it difficult to satisfy assumption [ ass : as](vi ) .",
    "suitable measurability of @xmath154 , required in assumption [ ass : as](iv ) , is a mild condition that is satisfied in most practical cases ; see appendix [ subsec : notation ] for clarifications .",
    "the index @xmath159 captures the complexity of the class of functions @xmath154 and typically grows with @xmath65 , @xmath0 , and @xmath166 s .",
    "in particular , in the case of approximately sparse models , like a logistic regression model with functional response data studied in section [ sec : application ] , @xmath159 can be typically set up - to a constant as the sum of the dimension of the approximating model , the dimension of the selected model , and the dimension of @xmath25 .",
    "however , we note that our conditions potentially cover other frameworks , where assumptions other than approximate sparsity are used to make the estimation problem manageable .",
    "we stress that the class @xmath154 does not need to be donsker because its uniform entropy numbers are allowed to increase with @xmath1 .",
    "this is important because allowing for non - donsker classes is necessary to deal with high - dimensional nuisance parameters .",
    "note also that our conditions are very different from the conditions imposed in various settings with nonparametrically estimated nuisance functions ; see , e.g. , @xcite , @xcite , and @xcite .",
    "the following theorem is our first main result in this paper :    [ theorem : semiparametric ] under assumptions [ ass : s1 ] and [ ass : as ] , for an estimator @xmath167}$ ] that obeys equation ( [ eq : analog ] ) , we have @xmath168)\\ ] ] uniformly over @xmath145 , where @xmath169 and @xmath170 $ ] .",
    "the uniform bahadur representation derived in theorem [ theorem : semiparametric ] is useful for the construction of simultaneous confidence bands for @xmath171}$ ] as in ( [ unifcoverage ] ) .",
    "for this purpose , we apply new high - dimensional central limit and bootstrap theorems that have been recently developed in a sequence of papers @xcite , @xcite , @xcite , @xcite , and @xcite . to apply these theorems , we make use of the following regularity condition .",
    "let @xmath172 be a sequence of positive constants converging to zero . also , let @xmath173 , @xmath174 , @xmath175 , @xmath176 , and @xmath177 be some sequences of positive constants , possibly growing to infinity , where @xmath178 , @xmath179 , and @xmath180 for all @xmath110 .",
    "in addition , from now on , we assume that @xmath181 .",
    "denote by @xmath182 an estimator of @xmath183 , with @xmath184 and @xmath185 being suitable estimators of @xmath186 and @xmath187 .",
    "[ ass : osr ] for all @xmath117 and @xmath145 , the following conditions hold : ( i ) the function class @xmath188   \\}$ ] is suitably measurable and its uniform entropy numbers obey @xmath189 where @xmath190 is a measurable envelope for @xmath191 that satisfies @xmath192 .",
    "( ii ) for all @xmath193 and @xmath194 , we have @xmath195 { \\leqslant}c_0l_n^{k-2}$ ] .",
    "( iii ) the function class @xmath196 \\}$ ] satisfies with probability @xmath197 : @xmath198 for all @xmath199 and @xmath200 for all @xmath201 .",
    "this assumption is technical , and its verification in applications is rather standard . for the gaussian approximation result below , we actually only need the first and the second part of this assumption .",
    "the third part will be needed for establishing validity of the simultaneous confidence bands based on the multiplier bootstrap procedure .",
    "next , let @xmath202}$ ] denote a tight zero - mean gaussian process indexed by @xmath203 $ ] with covariance operator given by @xmath204 $ ] for @xmath205 and @xmath206 $ ] .",
    "we have the following corollary of theorem [ theorem : semiparametric ] , which is our second main result in this paper .    [ cor : general clt ] suppose that assumptions [ ass : s1 ] , [ ass : as ] , and [ ass : osr](i , ii ) hold .",
    "in addition , suppose that the following growth conditions hold : @xmath207 , @xmath208 , and @xmath209 . then @xmath210}|\\sqrt n\\sigma_{uj}^{-1}(\\check\\theta_{uj}-\\theta_{uj})| { \\leqslant}t \\right ) - { { \\mathrm{p}}}_p\\left(\\sup_{u\\in\\mathcal{u},j\\in[\\tilde{p}]}|\\mathcal{n}_{u j}| { \\leqslant}t\\right ) \\right| = o(1)\\ ] ] uniformly over @xmath211 .    based on corollary [ cor : general clt ] , we are now able to construct simultaneous confidence bands for @xmath13 s as in ( [ unifcoverage ] )",
    ". in particular , we will use the gaussian multiplier bootstrap method employing the estimates @xmath212 of @xmath213 . to describe the method , define the process @xmath214 } = \\left ( \\frac{1}{\\sqrt{n}}\\sum_{i=1}^n\\xi_i{\\widehat}\\psi_{uj}(w_i)\\right)_{u\\in{\\mathcal{u } } , j\\in [ { { \\tilde p}}]}\\ ] ] where @xmath215 are independent standard normal random variables which are independent from the data @xmath15 .",
    "then the multiplier bootstrap critical value @xmath24 is defined as the @xmath216 quantile of the conditional distribution of @xmath217}|\\widehat{\\mathcal{g}}_{u j}|$ ] given the data @xmath15 . to prove validity of this critical value for the construction of simultaneous confidence bands of the form ( [ unifcoverage ] )",
    ", we will impose the following additional assumption .",
    "let @xmath218 be a sequence of positive constants converging to zero .",
    "[ ass : variance ] for all @xmath219 and @xmath211 , @xmath220}\\left|\\frac{{\\widehat}{\\sigma}_{u j}}{\\sigma_{u j } } - 1\\right|>\\varepsilon_n\\right){\\leqslant}\\delta_n.\\ ] ]    the following corollary establishing validity of the multiplier bootstrap critical value @xmath24 for the simultaneous confidence bands construction is our third main result in this paper .    [",
    "theorem : general bs ] suppose that assumptions [ ass : s1 ]  [ ass : variance ] hold .",
    "in addition , suppose that the growth conditions of corollary [ cor : general clt ] hold .",
    "finally , suppose that @xmath221 , and @xmath222 .",
    "then @xmath223\\right ) = 1-\\alpha - o(1)\\ ] ] uniformly over @xmath211 .      here",
    "we discuss several methods for generating orthogonal scores in a wide variety of settings , including the classical neyman s construction . in",
    "what follows , since the argument applies to each @xmath224 and @xmath225 , it is convenient to omit the indices @xmath224 and @xmath225 and also to use the subscript @xmath226 to indicate the true values of the parameters . for simplicity",
    "we also focus the discussion on the exactly orthogonal case . with these simplifications",
    ", we can restate the orthogonality condition as follows : we say that the score @xmath227 obeys the neyman orthogonality condition with respect to @xmath228 if the following conditions hold : the gateaux derivative map @xmath229:=   \\left .",
    "\\partial_r   \\bigg\\{{{\\mathrm{e}}}_p \\big [   \\psi ( w , \\theta_0 , \\eta_0 + r ( \\eta - \\eta_0 )    \\big ] \\bigg\\}\\right|_{r=\\bar r}\\ ] ] exists for all @xmath99 and @xmath230 and vanishes at @xmath101 , namely , @xmath231",
    "= 0,\\ ] ] for all @xmath232 .      in likelihood settings with finite - dimensional parameters ,",
    "the construction of orthogonal equations was proposed by neyman @xcite who used them in construction of his celebrated @xmath57-statistic .-",
    "statistic , or the orthogonal score statistic , had been explicitly used for testing ( and also for setting up estimation ) in high - dimensional sparse models in @xcite .",
    "the discussion of neyman s construction here draws on @xcite . ]",
    "suppose that the log - likelihood function associated to observation @xmath5 is @xmath233 , where @xmath234 is the target parameter and @xmath235 is the nuisance parameter . under regularity conditions , the true parameter values @xmath34 and @xmath35",
    "obey @xmath236=0 , \\quad { { \\mathrm{e}}}[\\partial_{\\beta } \\ell ( w , \\theta_0 , \\beta_0 ) ] = 0.\\ ] ] now consider the new score function @xmath237 where the nuisance parameter is @xmath238 @xmath239 is the @xmath240 _ orthogonalization _ parameter matrix whose true value @xmath241 solves the equation @xmath242 and @xmath243\\big\\vert_{\\theta = \\theta_0 ; \\",
    "\\beta = \\beta_0}.\\ ] ] provided that @xmath241 is well - defined , we have by ( [ eq : foc lik ] ) that @xmath244 = 0,\\ ] ] where @xmath245 .",
    "moreover , it is trivial to verify that under standard regularity conditions the score function @xmath227 obeys the near orthogonality condition ( [ eq : cont ] ) exactly ( i.e. , with @xmath246 ) , i.e. @xmath247 \\big \\vert_{\\eta   = \\eta_0 } = 0.\\ ] ] note that in this example , @xmath241 not only creates the necessary orthogonality but also creates the _ efficient score _ for inference on the target parameter @xmath248 , as emphasized by neyman .",
    "the neyman s construction can be extended to semi - parametric models , where the nuisance parameter @xmath249 is a function . in this case , the original score functions @xmath250 corresponding to the log - likelihood function @xmath251 associated to observation @xmath5 can be transformed into efficient score functions @xmath227 that obey the exact orthogonality condition ( [ eq : cont2 ] ) by projecting the original score functions onto the orthocomplement of the tangent space induced by the nuisance parameter @xmath249 ; see chapter 25 of @xcite for a detailed description of this construction .",
    "note that the projection may create additional nuisance parameters , so that the new nuisance parameter @xmath252 could be of larger dimension than @xmath249 .",
    "other relevant references include @xcite , @xcite , @xcite , and @xcite .",
    "the approach is related to neyman s construction in the sense that the score @xmath227 arising in this model is actually the neyman s score arising in a one - dimensional least favorable parametric subfamily ; see chapter 25 of @xcite for details .",
    "next , consider a conditional moment restrictions framework studied by chamberlain @xcite : @xmath253 = 0,\\ ] ] where @xmath30 and @xmath5 are random vectors with @xmath30 being a sub - vector of @xmath5 , @xmath254 is a finite - dimensional parameter whose true value @xmath34 is of interest , @xmath255 is a functional nuisance parameter mapping the support of @xmath30 into a convex set @xmath256 whose true value is @xmath257 , and @xmath258 is a known function with values in @xmath259 for @xmath260 and @xmath261 .",
    "this framework is of interest because it covers an extremely rich variety of models , without having to explicitly rely on the likelihood formulation .",
    "here we would like to build a ( generalized ) score function @xmath262 for estimating @xmath263 , the true value of parameter @xmath248 , where @xmath252 is a new nuisance parameter with true value @xmath264 , that obeys the near orthogonality condition .",
    "to this end , let @xmath265 $ ] be a function mapping @xmath266 into @xmath259 and let @xmath267 \\vert_{v = h_0(x)}$ ] be a @xmath268 matrix of its derivatives .",
    "we will set @xmath269 where @xmath270 is a function mapping the support of @xmath30 into the space of @xmath271 matrices , @xmath272 , and @xmath273 is the function mapping the support of @xmath30 into the space of @xmath274 matrices , @xmath275 .",
    "assume that the true value @xmath276 of parameter @xmath270 satisfies @xmath277 where @xmath278 is a @xmath271 matrix of measurable transformations of @xmath30 , @xmath279 is the @xmath274 identity matrix , and @xmath280 is a @xmath274 non - identity matrix with the property : @xmath281 where @xmath282 is the true value of parameter @xmath273 .",
    "for example , @xmath283 can be chosen to be an orthogonal projection matrix : @xmath284 .",
    "\\end{aligned}\\ ] ] then an orthogonal score for the problem above can be constructed as @xmath285[.5pt]{\\varphi(x)}_{\\text{``instrument \" } }       \\underbracket[.5pt][.5pt ] { \\sigma^{-1/2}(x)}_{\\text{weight } } \\underbracket[.5pt][.5pt]{m(z , \\theta , h(x))}_{\\text{residual } } , \\quad \\eta = ( h , \\varphi , \\sigma).\\ ] ] it is straightforward to check that under mild regularity conditions that the score function @xmath227 satisfies @xmath286 = 0 $ ] for @xmath287 and also obeys the exact orthogonality condition .",
    "furthermore , by setting @xmath288\\vert_{\\theta = \\theta_0}\\big ) ' , \\quad \\sigma_{0}(x )   =    { { \\mathrm{e}}}\\big [ m(w , \\theta_{0 } , h_{0}(x ) ) m(w , \\theta_{0 } , h_{0}(x ) ) ' |x\\big],\\ ] ] and using @xmath283 suggested above , we obtain the efficient score @xmath227 that yields an estimator of @xmath34 achieving the semi - parametric efficiency bound , as calculated by chamberlain @xcite .",
    "in this section we apply our main results to a logistic regression model with functional response data .",
    "we consider a response variable @xmath289 that induces a functional response @xmath290 by @xmath291 for a set of indices @xmath292 $ ] and some constants @xmath293 .",
    "we are interested in the dependence of this functional response on a @xmath0-vector of covariates , @xmath294 , controlling for a @xmath32-vector of additional covariates @xmath295 .",
    "we allow both @xmath0 and @xmath32 to be ( much ) larger than the sample size of available data , @xmath1 .    for each @xmath68 , we assume that @xmath296 satisfies the generalized linear model with the logistic link function @xmath297 = { { \\lambda}}(d'\\theta_u + x'\\beta_u)+r_u\\ ] ] where @xmath298 is a vector of parameters of interest",
    ", @xmath299 is a vector of nuisance parameters , @xmath300 is an approximation error , @xmath301 is a logistic link function defined by @xmath302 for all @xmath303 , and @xmath304 is the distribution of the triple @xmath305 . as in the previous section ,",
    "we construct simultaneous confidence bands for the parameters @xmath3}$ ] based on a random sample @xmath306 from the distribution of @xmath305 .",
    "observe that for each @xmath10 and @xmath11 $ ] , the standard score function for estimating the coefficient @xmath13 based on ( [ eq : mainlogisticmodel ] ) is given by @xmath307\\setminus j } ' , \\beta'_u)'\\big)-r_u\\big\\}d_j,\\ ] ] where @xmath308 and @xmath309\\setminus j}',x')$ ] , so that @xmath310 = 0 $ ] .",
    "however , this score function does not satisfy the desired near orthogonality condition in general .",
    "we therefore proceed to construct an appropriate score function using an approach from section [ rem : obtaining orthogonality condition ] .",
    "specifically , for each @xmath10 and @xmath11 $ ] , define the coefficients @xmath311\\ ] ] where @xmath312(1 - { { \\mathrm{e}}}_p[y_u\\mid d , x])$ ] , so that @xmath313=0.\\ ] ] also , denote @xmath314\\setminus j}',\\beta_u')'$ ] .",
    "then a score function @xmath96 is @xmath315 where the nuisance parameter is @xmath316 .",
    "as we demonstrate in the proof of theorem [ theorem : inferencealg1 ] below , this function satisfies the desired near orthogonality condition .",
    "( observe that when @xmath317 almost surely , we have @xmath318 , so that we could define the weights @xmath319 using the alternative formula @xmath320 , which was used , in particular , in the introduction .",
    "when @xmath321 with positive probability , however , two expressions are not the same .",
    "we find it more convenient to work with the formula @xmath322 . )",
    "next , we discuss possible estimators of @xmath17 .",
    "first , if @xmath29 and @xmath30 are chosen appropriately , @xmath300 is asymptotically negligible , so it can be estimated by @xmath323 , the identically zero function of @xmath29 and @xmath30 .",
    "second , for @xmath324 , we consider an estimator @xmath325 defined as a post - regularization weighted least squares estimator corresponding to the problem ( [ eq : gamma definition ] ) .",
    "third , for @xmath326 , we consider a plug - in estimator @xmath327\\setminus j}',\\widetilde \\beta_u')'\\ ] ] where @xmath328 and @xmath329 are suitable estimators of @xmath330 and @xmath331 .",
    "in particular , we assume that @xmath328 and @xmath332 are post - regularization maximum likelihood estimators corresponding to the log - likelihood function @xmath333 where @xmath334 the details of the estimators @xmath328 , @xmath329 , and @xmath335 are given in algorithm 1 below . the results in this paper can also be easily extended to the case where @xmath328 , @xmath329 , and @xmath335 are replaced by penalized maximum likelihood estimators @xmath336 and @xmath337 and penalized weighted least squares estimator @xmath338 , respectively .    to sum up , our estimator of @xmath17 is @xmath339 .",
    "substituting this estimator into the score function @xmath52 gives @xmath340 and the sample analog ( [ eq : analog ] ) of the moment condition can be implemented as @xmath341 \\big|.\\ ] ] the algorithm is summarized as follows .",
    "( based on the score function . ) for each @xmath68 and @xmath11 $ ] : + _ step 1_. run post-@xmath66-penalized logistic estimator ( [ postl1logistic ] ) of @xmath342 on @xmath29 and @xmath30 to compute @xmath343 .",
    "+ _ step 2_. define the weights @xmath344 . + _",
    "step 3_. run the post - lasso estimator ( [ estpostlasso ] ) of @xmath345 on @xmath346 to compute @xmath335 .",
    "+ _ step 4_. compute @xmath347 in .",
    "+ _ step 5_. solve ( [ os : step3 ] ) with @xmath348 defined in to compute @xmath349 .",
    "next , we specify our regularity conditions . for all @xmath10 and @xmath11 $ ] , denote @xmath350 . also , denote @xmath351 .",
    "let @xmath352 , @xmath353 , and @xmath354 be some strictly positive ( and finite ) constants where @xmath355 .",
    "also , let @xmath93 and @xmath356 be some sequences of positive constants converging to zero .",
    "finally , let @xmath357 and @xmath358 be some sequences of positive constants , possibly growing to infinity , where @xmath359 and @xmath360 for all @xmath1 .",
    "[ ass : parameters ] for all @xmath10 , we have @xmath361}\\|\\gamma_u^j\\|{\\leqslant}c_1 $ ] and @xmath362}\\sup_{\\theta\\in\\theta_{u j}}|\\theta|{\\leqslant}c_1 $ ] . in addition , for all @xmath363 , we have @xmath364 .",
    "finally , for all @xmath10 and @xmath11 $ ] , @xmath82 contains a ball of radius @xmath365 centered at @xmath13 .",
    "[ ass : sparsity ] there exist @xmath366 and @xmath367 , @xmath10 and @xmath11 $ ] , such that for all @xmath10 , @xmath368}\\|\\bar \\gamma_u^j\\|_0{\\leqslant}s_n$ ] and @xmath362}(\\|\\bar \\gamma_u^j-\\gamma_u^j\\|+s_n^{-1/2}\\|\\bar \\gamma_u^j-\\gamma_u^j\\|_1){\\leqslant}c_1 ( s_n\\log a_n / n)^{1/2}$ ] .",
    "[ ass : density ] the conditional pdf of @xmath28 given @xmath369 is bounded by @xmath354 .",
    "assumptions [ ass : parameters]-[ass : density ] are mild and standard in the literature .",
    "in particular , assumption [ ass : parameters ] requires the parameter spaces @xmath82 to be bounded , and also requires that for each @xmath10 and @xmath11 $ ] , the parameter @xmath13 to be sufficiently separated from the boundaries of the parameter space @xmath82 .",
    "assumption [ ass : sparsity ] requires approximate sparsity of the model .",
    "note that in assumption [ ass : sparsity ] , given that @xmath367 s exist , we can and will assume without loss of generality that @xmath370 for some @xmath371 , where @xmath372 is allowed to depend on @xmath224 and @xmath225 .",
    "assumption [ ass : density ] can be relaxed at the expense of more technicalities .",
    "[ ass : covariates ] for all @xmath10 , we have ( i ) @xmath373{\\geqslant}c_1 $ ] , ( ii ) @xmath374\\wedge { { \\mathrm{e}}}_p[|f_u^2 d_j x_k^j|^2]){\\geqslant}c_1 $ ] , and ( iii ) @xmath375^{1/3}\\log^{1/2 } a_n { \\leqslant}\\delta_n n^{1/6}$ ] .",
    "in addition ,",
    "( iv ) @xmath376{\\leqslant}c_1 $ ] , ( v ) @xmath377}|z_u^j|^{2q}]^{1/(2q)}$ ] , ( vi ) @xmath378 , ( vii ) @xmath379\\}^{1/(2q)}$ ] , ( viii ) @xmath380 , and ( ix ) @xmath381 .",
    "this assumption requires that there is no multicollinearity between covariates in vectors @xmath29 and @xmath30 .",
    "in addition , it imposes constraints on various moments of covariates .",
    "since these constraints might be difficult to grasp , at the end of this section , in corollary [ cor : simple example ] , we provide an example for which these constraints simplify into easily interpretable conditions .",
    "[ ass : approximation error ] for all @xmath10 , we have ( i ) @xmath382{\\leqslant}c_1 { { \\mathrm{e}}}_p[r_u^2]$ ] , ( ii ) @xmath383{\\leqslant}c_1 s_n \\log a_n / n$ ] , ( iii ) @xmath362}|{{\\mathrm{e}}}_p[r_uz_u^j]|{\\leqslant}\\delta_n n^{-1/2}$ ] , and ( iv ) @xmath384 almost surely .",
    "in addition , with probability @xmath385 , ( v ) @xmath386}({{\\mathbb{e}_n}}[(r_u z_u^j / f_u)^2 ] + { { \\mathbb{e}_n}}[r_u^2/f_u^6]){\\leqslant}c_1 s_n\\log a_n / n$ ] .",
    "this assumption requires the approximation error @xmath300 to be sufficiently small . under assumption",
    "[ ass : covariates ] , the first condition of assumption [ ass : approximation error ] holds if the approximation error is such that @xmath387 $ ] almost surely for some constant @xmath115 .    under specified assumptions ,",
    "our estimator @xmath388}$ ] satisfies the following uniform bahadur representation theorem .",
    "[ theorem : inferencealg1 ] suppose that assumptions [ ass : parameters ]  [ ass : approximation error ] hold for all @xmath304 .",
    "in addition , suppose that the following growth condition holds : @xmath389 .",
    "then for the estimator @xmath390}$ ] satisfying , we have @xmath391)\\ ] ] uniformly over @xmath304 , where @xmath392 , @xmath393 $ ] , and @xmath116 is defined in .",
    "this theorem allows us to establish a gaussian approximation result for the supremum of the process @xmath394\\}$ ] :    [ cor : logistic clt ] suppose that assumptions [ ass : parameters ]  [ ass : approximation error ] hold for all @xmath304 .",
    "in addition , suppose that the following growth conditions hold : @xmath389 , @xmath395 , and @xmath396 . then @xmath210}|\\sqrt n\\sigma_{uj}^{-1}(\\check\\theta_{uj}-\\theta_{uj})| { \\leqslant}t \\right ) - { { \\mathrm{p}}}_p\\left(\\sup_{u\\in\\mathcal{u},j\\in[\\tilde{p}]}|\\mathcal{n}_{u j}| { \\leqslant}t\\right ) \\right| = o(1)\\ ] ] uniformly over @xmath304 , where @xmath397}$ ] is a tight zero - mean gaussian process indexed by @xmath398 $ ] with the covariance operator given by @xmath399 $ ] for @xmath205 and @xmath400 $ ] .    based on this corollary , we are now able to construct simultaneous confidence bands for the parameters @xmath13 .",
    "observe that @xmath401,\\ ] ] and so it can be estimated by @xmath402\\ ] ] for all @xmath10 and @xmath11 $ ] .",
    "in addition , @xmath403 $ ] , and so it can be estimated by @xmath404\\ ] ] for all @xmath10 and @xmath11 $ ] . moreover , as in section [ sec : general ] , for all @xmath10 and @xmath11 $ ] , define @xmath405 , and let @xmath24 be the @xmath216 quantile of the conditional distribution of @xmath406}|{\\widehat}{\\mathcal g}_{u j}|$ ] given the data @xmath15 where the process @xmath407}$ ] is defined in",
    ". then we have    [ cor : logistic bands ] suppose that assumptions [ ass : parameters ]  [ ass : approximation error ] hold for all @xmath304 .",
    "in addition , suppose that the following growth conditions hold : @xmath389 , @xmath395 , @xmath396 , and @xmath408 .",
    "then @xmath409\\right ) = 1-\\alpha - o(1)\\ ] ] uniformly over @xmath304 .    to conclude this section , we provide an example for which conditions of corollary [ cor : logistic bands ] are easy to interpret .",
    "recall that @xmath410 .",
    "[ cor : simple example ] suppose that assumptions [ ass : parameters ]  [ ass : density ] , [ ass : covariates](i , ii , iv ) , and [ ass : approximation error](i , ii , iv , v ) hold for @xmath355 for all @xmath304 .",
    "in addition , suppose that @xmath411\\}^{1/(2q)}{\\leqslant}c_1 $ ] and @xmath386}\\|\\gamma_u^j\\|_1{\\leqslant}c_1 $ ] .",
    "finally , suppose that @xmath412 , @xmath413 , and @xmath406}|{{\\mathrm{e}}}_p[r_u z_u^j]| = o ( ( n\\log a_n)^{-1/2})$ ] . then holds uniformly over @xmath304 .",
    "when constructing the confidence bands based on , we find in simulations that it is beneficial to replace the estimators @xmath414 of @xmath415 by @xmath416 where @xmath417 $ ] is an alternative consistent estimator of @xmath415 .",
    "we note that the theory developed here is applicable for different estimators that construct the new score function with the desired orthogonality condition implicitly .",
    "for example , the double selection idea yields an implementation of an estimator that is first - order equivalent to the estimator based on the score function .",
    "the algorithm yielding the double selection estimator is as follows .",
    "( based on double selection ) for each @xmath68 and @xmath11 $ ] : + _ step @xmath418_. run post-@xmath66-penalized logistic estimator ( [ postl1logistic ] ) of @xmath342 on @xmath29 and @xmath30 to compute @xmath343 .",
    "+ _ step @xmath419_. define the weights @xmath420 . + _",
    "step @xmath421_. run the lasso estimator ( [ estlasso ] ) of @xmath345 on @xmath422 to compute @xmath338 .",
    "+ _ step @xmath423_. run logistic regression of @xmath342 on @xmath424 and all the selected variables in steps @xmath418 and @xmath421 + to compute @xmath425 .    as mentioned by a referee , it is surprising that the double selection procedure has uniform validity .",
    "the use of the additional variables selected in step 3 , through the first order conditions of the optimization problem , induces the necessary near - orthogonality condition .",
    "we refer to the supplementary material for a more detailed discussion .",
    "another implementation for which the theory developed here applies is to replace step 5 in algorithm 1 with a one - step procedure .",
    "this relates to the debiasing procedure proposed in @xcite to the case when the set @xmath25 is a singleton . in this case instead of minimizing the criterion ( [ os : step3 ] ) in step 5 , the method makes a full newton step from the initial estimate ,    _ step @xmath426_. compute @xmath427.$ ] the theory developed here directly apply to those estimators as well .",
    "in this section , we define the estimators @xmath428 , @xmath332 , and @xmath325 , which were used in the previous section , and study their properties .",
    "we consider the same setting as that in the previous section .",
    "the results in this section rely upon a set of new results for @xmath66-penalized @xmath67-estimators with functional data presented in appendix [ sec : generic results ] of the supplementary material .      here",
    "we consider the generalized linear model with the logistic link function and functional response data .",
    "as explained in the previous section , we assume that @xmath328 and @xmath332 are post - regularization maximum likelihood estimators of @xmath330 and @xmath331 corresponding to the log - likelihood function @xmath429 defined in . to define these estimators ,",
    "let @xmath430 and @xmath431 be @xmath66-penalized maximum likelihood ( logistic regression ) estimators @xmath432 + \\frac{\\lambda}{n}\\|{\\widehat}\\psi_u(\\theta',\\beta')'\\|_1\\right)\\ ] ] where @xmath433 is a penalty level and @xmath434 a diagonal matrix of penalty loadings .",
    "we choose parameters @xmath433 and @xmath434 according to algorithm 3 described below . using the @xmath66-penalized estimators @xmath430 and @xmath431",
    ", we then define post - regularization estimators @xmath435 and @xmath329 by @xmath436   \\ \\ : \\ \\ { \\mathrm{supp}}(\\theta,\\beta)\\subseteq { \\mathrm{supp}}({\\widehat}\\theta_u,{\\widehat}\\beta_u).\\ ] ] we derive the rate of convergence and sparsity properties of @xmath435 and @xmath329 as well as of @xmath437 and @xmath431 in theorem [ thm : rateestimatedlassologistic ] below . recall that @xmath438 .",
    "[ algfunc ] choose @xmath439 $ ] and @xmath440 ( in practice , we set @xmath441 and @xmath442 )",
    ". define @xmath443 with @xmath444 . to select @xmath434 ,",
    "choose a constant @xmath445 as an upper bound on the number of loops and proceed as follows : ( 0 ) let @xmath446 , @xmath447 , and initialize @xmath448\\}^{1/2}$ ] for @xmath449 $ ] .",
    "( 1 ) compute @xmath450 and @xmath343 based on @xmath451\\})$ ] . ( 2 ) set @xmath452\\}^{1/2}.$ ] ( 3 ) if @xmath453 , report the current value of @xmath434 and stop ; otherwise set @xmath454 and go to step ( 1 ) .",
    "[ thm : rateestimatedlassologistic ] suppose that assumptions [ ass : parameters ]  [ ass : approximation error ] hold for all @xmath304 .",
    "in addition , suppose that the penalty level @xmath433 and the matrices of penalty loadings @xmath434 are chosen according to algorithm [ algfunc ] .",
    "moreover , suppose that the following growth condition holds : @xmath389 .",
    "then there exists a constant @xmath455 such that uniformly over all @xmath118 with probability @xmath456 , @xmath457 and the estimators @xmath437 and @xmath431 are uniformly sparse : @xmath458 .",
    "also , uniformly over all @xmath118 , with probability @xmath456 , @xmath459      here we consider the weighted linear model for @xmath10 and @xmath11 $ ] .",
    "using the parameter @xmath367 appearing in assumption [ ass : sparsity ] , it will be convenient to rewrite this model as @xmath460 = 0\\ ] ] where @xmath461 is an approximation error , which is asymptotically negligible under assumption [ ass : sparsity ] . as explained in the previous section",
    ", we assume that @xmath335 is a post - regularization weighted least squares estimator of @xmath324 ( or @xmath367 ) . to define this estimator ,",
    "let @xmath462 be an @xmath66-penalized ( weighted lasso ) estimator @xmath463 + \\frac{\\lambda}{n}\\|{\\widehat}\\psi_{u j}\\gamma\\|_1 \\right)\\ ] ] where @xmath433 and @xmath464 are the associated penalty level and the diagonal matrix of penalty loadings specified below in algorithm 4 and where @xmath465 s are estimated weights . as in algorithm 1 in the previous section , we set @xmath466 .",
    "using @xmath462 , we define a post - regularized weighted least squares estimator @xmath467 \\ \\ : \\ { \\mathrm{supp}}(\\gamma)\\subseteq { \\mathrm{supp}}({\\widehat}\\gamma_u^j).\\ ] ] we derive the rate of convergence and sparsity properties of @xmath335 as well as of @xmath462 in theorem [ thm : rateestimatedlassolinear ] below .",
    "[ algfunc2 ] choose @xmath439 $ ] and @xmath440 ( in practice ,",
    "we set @xmath441 and @xmath442 ) . define @xmath443 with @xmath468 . to select @xmath469 ,",
    "choose a constant @xmath470 as an upper bound on the number of loops and proceed as follows : ( 0 ) set @xmath447 and @xmath471\\}^{1/2}$ ] .",
    "( 1 ) compute @xmath338 and @xmath325 based on @xmath472\\})$ ] . ( 2 ) set @xmath473\\}^{1/2}.$ ] ( 3 ) if @xmath474 , report the current value of @xmath475 and stop ; otherwise set @xmath454 and go to step ( 1 ) .",
    "[ thm : rateestimatedlassolinear ] suppose that assumptions [ ass : parameters ]  [ ass : approximation error ] hold for all @xmath304 .",
    "in addition , suppose that the penalty level @xmath433 and the matrices of penalty loadings @xmath469 are chosen according to algorithm [ algfunc2 ] .",
    "moreover , suppose that the following growth condition holds : @xmath389 .",
    "then there exists a constant @xmath455 such that uniformly over all @xmath118 with probability @xmath456 , @xmath476}\\sup_{u\\in\\mathcal{u } } \\| { \\widehat}\\gamma_u^j - \\bar\\gamma_{u}^j\\| { \\leqslant}\\bar c \\sqrt{\\frac{s_n\\log a_n}{n } } \\ \\mbox{and } \\ \\",
    "\\displaystyle \\max_{j\\in[{{\\tilde p } } ] } \\sup_{u\\in\\mathcal{u}}\\|{\\widehat}\\gamma_u^j-\\bar\\gamma_{u}^j\\|_1   { \\leqslant}\\bar c",
    "\\sqrt{\\frac{s_n^2 \\log a_n}{n}},\\end{array}\\ ] ] and the estimator @xmath338 is uniformly sparse , @xmath362}\\sup_{u\\in \\mathcal{u}}\\|{\\widehat}\\gamma_u^j \\|_0   { \\leqslant}\\bar c   s_n$ ] . also ,",
    "uniformly over all @xmath118 , with probability @xmath456 , @xmath477}\\sup_{u\\in \\mathcal{u } } \\| \\widetilde \\gamma_u^j -\\bar\\gamma_u^j\\| { \\leqslant}\\bar c",
    "\\sqrt{\\frac{s_n \\log a_n}{n } } , \\text { and }    \\ \\   \\displaystyle \\max_{j\\in[{{\\tilde p}}]}\\sup_{u\\in\\mathcal{u}}\\|\\widetilde \\gamma_u^j-\\bar\\gamma_{u}^j\\|_1   { \\leqslant}\\bar c \\sqrt{\\frac{s_n^2\\log a_n}{n}}.\\ ] ]",
    "in this section we provide a simulation study to investigate the finite sample properties of the proposed estimators and the associated confidence regions .",
    "we report only the performance of the estimator based on the double selection procedure due to space constraints and note that it has very similar to the performance of the estimator based on score functions with near orthogonality property",
    ". we will compare the proposed procedure with the traditional estimator that refits the model selected by the corresponding @xmath66-penalized m - estimator ( naive post - selection estimator ) .",
    "we consider a logistic regression model with functional response data where the response @xmath478 for @xmath479 a compact set .",
    "we specify two different designs : ( 1 ) a location model where @xmath480 where @xmath481 is distributed as a logistic random variable , the first component of @xmath482 is the intercept and the other @xmath483 components are distributed as @xmath484 with @xmath485 ; ( 2 ) a location - shift model where @xmath486 where @xmath481 is distributed as a logistic random variable , @xmath487 where @xmath488 is a @xmath32-vector distributed as @xmath484 with @xmath485 , and @xmath489 has non - negative components .",
    "such specification implies that for each @xmath479 @xmath490 in our simulations we will consider @xmath491 and @xmath492 . for the location model ( design 1 ) we will consider two different choices for @xmath35 : ( i ) @xmath493 for @xmath494 , and ( ii ) @xmath495 for @xmath496 with the intercept coefficient @xmath497 .",
    "( these choices ensure @xmath498 and that @xmath499 is around zero in design 2(ii ) . )",
    "we set @xmath500 . for design 1",
    "we have @xmath501 $ ] and for design 2 we have @xmath502 $ ] .",
    "the results are based on 500 replications ( the bootstrap procedure is performed 5000 times for each replication ) .",
    "we report the ( empirical ) rejection frequencies for confidence regions with 95% nominal coverage .",
    "that is , the fraction of simulations the confidence regions of a particular method did not cover the true value ( thus .05 rejection frequency is the ideal performance ) .",
    "we report the rejection frequencies for the proposed estimator and the post - naive selection estimator .",
    "table [ tab : mc1 ] presents the performance of the methods when applied to construct a confidence interval for a single parameter ( @xmath503 and @xmath25 is a singleton ) .",
    "since the setting is not symmetric we investigate the performance for different components . specifically , we consider @xmath504 for @xmath505 .",
    "first consider the location model ( design 1 ) .",
    "the difference between the performance of the naive estimator for design 1(i ) and 1(ii ) highlights its fragile performance which is highly dependent on the unknown parameters . in design 1(i )",
    "the naive method achieve ( pointwise ) rejection frequencies between .032 and .162 when the nominal level is .05 .",
    "however , in the design 1(ii ) the range goes from 0.018 to 0.904 .",
    "we also note that it is important to look at the performance of each component and avoid averaging across components ( large @xmath225 components are essentially not in the model , indeed for @xmath506 we obtain rejection frequencies very close to .05 regardless of the model selection procedure ) .",
    "in contrast the proposed estimator exhibits a more robust behavior . for design 1(i ) the rejection frequencies are between .028 and .062 while for design 1(ii ) the rejection frequencies of the proposed estimator were between 0.044 and 0.056 .",
    "table [ tab : mc2 ] presents the performance for simultaneous confidence bands of the form @xmath507 $ ] for @xmath508 $ ] where @xmath509 is a point estimate , @xmath510 is an estimate of the pointwise standard deviation , and @xmath511 is a critical value that accounts for the uniform estimation . for the point estimate",
    "we consider the proposed estimator and the post - naive selection estimator which have estimates of standard deviation .",
    "we consider two critical values : from the multiplier bootstrap ( mb ) procedure and the bonferroni ( bf ) correction ( which we expect to be conservative ) .",
    "for each of the four different designs ( 1(i ) , 1(ii ) , 2(i ) and 2(ii ) described above ) , we consider four different choices of @xmath398 $ ] .",
    "table [ tab : mc2 ] displays rejection frequencies for confidence regions with 95% nominal coverage ( and again @xmath512 would be the ideal performance ) .",
    "the simulation results confirms the differences between the performance of the methods and overall the proposed procedure is closer to the nominal value of @xmath512 .",
    "the proposed estimator performed within a factor of two to the nominal value in 10 out of the 16 designs considered ( and 13 out 16 within a factor of three ) .",
    "the post - naive selection estimator performed within a factor of two only in 3 out of the 16 designs when using the multiplier bootstrap as critical value ( 7 out of 16 within a factor of three ) and similarly with the bonferroni correction as the critical value .",
    ".we report the rejection frequencies of each method for ( pointwise ) confidence intervals for each @xmath513 . for design 1 we used @xmath514 and for design 2 we used @xmath515 .",
    "the results are based on 500 replications .",
    "[ cols=\"^,^,^,^,^,^,^,^,^,^,^,^,^ \" , ]      in this section we illustrate the applicability of the tools proposed in this work with data on us presidential approval ratings used in @xcite .",
    "there several economic and political factors that impact presidential approval ratings . in this illustration",
    ", we are interested on the impact of unemployment rates and on the impact of time in office on the approval rate of a sitting president",
    ". however , the impact of such factors might not be homogeneous and in fact depend on current ratings .",
    "for example , a sitting president is likely to have a fraction of voters who would support him regardless of economic factors .",
    "thus , a low unemployment rate might not have an effect when approval ratings are low and have a significant effect when approval ratings are high .",
    "this would imply a different effect on different parts of the conditional distribution of the approval rating .    to study the distributional effect of these factors we use a logistic regression model with functional data as described in section [ sec : application ] .",
    "letting @xmath28 denote the approval rating , we define @xmath516 to be the binary variable that indicates if the approval rating is below the threshold @xmath517 $ ] .",
    "for each level of approval rating @xmath479 we estimate the model @xmath518 = \\lambda ( \\theta_{u , unemp}d_{unemp } + \\theta_{u , time}d_{time}+x'\\beta_u ) + r_u\\ ] ] where @xmath519 denotes the unemployment rate , @xmath520 the number of months the president has been in office , @xmath521 a ( small ) approximation error , and @xmath30 denotes several additional control variables .",
    "in addition to the linear terms for the variables used in @xcite , we also consider interactions among controls .",
    "therefore , for each @xmath479 we have a generalized linear model using logistic link function with 160 variables and 603 observations .",
    "we construct simultaneous confidence bands for both coefficients ( @xmath522 ) uniformly over @xmath523 .",
    "although @xmath524 for every @xmath523 , the full model ( applying logistic regression with all regressors ) led to numerical instabilities and other numerical failures . we proceed to construct ( asymptotically ) valid confidence regions based on the double selection procedure for functional logistic regression .",
    "figure [ fig : empfirst ] displays the estimation results . specifically , the figure displays point estimates of each coefficient for every @xmath523 ( solid line ) , pointwise confidence intervals ( dotted line ) , and uniform confidence bands ( dot - dash lines ) .",
    "point estimates account for model selection mistakes and are computed based the double selection procedure . for @xmath525 coverage ,",
    "the pointwise critical value is taken to be @xmath526 from the normal approximation and the critical value for uniform confidence bands ( uniformly over both coefficients and over @xmath479 ) was calculated to be @xmath527 based on 5000 repetitions of the multiplier bootstrap .    at 95% confidence level , the uniform confidence band rule out  no effect \" over @xmath25 for both variables . indeed , the straight line at @xmath226 is not contained in the uniform confidence bands for either variable .",
    "next consider the process of the unemployment coefficient .",
    "the analysis suggests that the unemployment rate has an overall negative effect on the approval rate of a sitting president ( as the coefficient is positive increasing the probability to be below a threshold ) .",
    "regarding time - in - office , the effect also seems to be predominantly negative .",
    "however , the impact is not homogeneous across @xmath10 .",
    "indeed , the lowest value of the upper confidence band ( 0.007 , @xmath528 ) is smaller than the largest value of the lower confidence band ( @xmath529 , @xmath530 ) , see the circles in the plot of the process of the time - in - office coefficient .",
    "the impact seems to be greater for the lower and higher values of @xmath531 while the effect of seems negligible in the range of @xmath532 $ ] . in particular , at 95% level , no effect is ruled out for large values of @xmath224 .",
    "based on the multiplier bootstrap procedure with 5000 repetitions . for both coefficients ,",
    "the lowest value of the upper confidence band is smaller than the largest value of the lower confidence band . , title=\"fig:\",scaledwidth=49.0% ]   based on the multiplier bootstrap procedure with 5000 repetitions . for both coefficients , the lowest value of the upper confidence band is smaller than the largest value of the lower confidence band .",
    ", title=\"fig:\",scaledwidth=49.0% ]",
    "throughout the paper , the symbols @xmath533 and @xmath534 denote probability and expectation operators with respect to a generic probability measure .",
    "if we need to signify the dependence on a probability measure @xmath7 , we use @xmath7 as a subscript in @xmath535 and @xmath536 . in the proofs ,",
    "we sometimes also use @xmath7 as a subscript for random variables as in @xmath537 .",
    "note also that we use capital letters such as @xmath5 to denote random elements and use the corresponding lower case letters such as @xmath488 to denote fixed values that these random elements can take . for a positive integer @xmath538 , @xmath539",
    "$ ] denotes the set @xmath540    we denote by @xmath541 the ( random ) empirical probability measure that assigns probability @xmath542 to each @xmath543 .",
    "@xmath544 denotes the expectation with respect to the empirical measure , and @xmath545 denotes the empirical process @xmath546 , that is , @xmath547\\ } ,   \\ \\   { { \\mathrm{e}}}_p [ f ( w ) ] : = \\int f(w ) dp(w),\\]]indexed by a class of measurable functions @xmath548 ; see @xcite . in what follows",
    ", we use @xmath549 to denote the @xmath550 norm ; for example , we use @xmath551 and @xmath552 . for a vector @xmath553 , @xmath554 denotes the @xmath555-norm \" of @xmath556 , that is , the number of non - zero components of @xmath556 , @xmath557 denotes the @xmath66-norm of @xmath556 , that is , @xmath558 , and @xmath559 denotes the euclidean norm of @xmath556 , that is , @xmath560 .",
    "we say that a class of functions @xmath561 , where @xmath562 , is suitably measurable if it is an image admissible suslin class , as defined in @xcite , p 186 .",
    "in particular , @xmath563 is suitably measurable if @xmath564 is measurable and @xmath565 is a polish space equipped with its borel @xmath84-field , see @xcite , p 186 .",
    "the following lemma is a generalization of the main result in @xcite to many matrices .",
    "the proof of the lemma is given in the supplementary material .",
    "[ thm : rv34 ] let @xmath25 denote a finite set and @xmath566 , @xmath567 , be independent ( across i ) random vectors such that @xmath568 with @xmath569 and @xmath570)^{1/2 } { \\leqslant}k$ ] . furthermore , for @xmath571 ,",
    "define @xmath572 then , @xmath573 { \\right]}\\right|\\right ] \\lesssim \\delta_n^2 + \\delta_n \\sup_{\\|\\theta\\|_0{\\leqslant}k , \\|\\theta\\| = 1 , u\\in{\\mathcal{u } } } \\sqrt{{{\\mathbb{e}_n}}{{\\mathrm{e}}}[(\\theta'x_{u})^2]}\\ ] ] up - to a universal constant .",
    "in this appendix , we use @xmath115 to denote a strictly positive constant that is independent of @xmath1 and @xmath304 .",
    "the value of @xmath115 may change at each appearance .",
    "also , the notation @xmath574 means that @xmath575 for all @xmath1 and some @xmath115 .",
    "the notation @xmath576 means that @xmath577 .",
    "moreover , the notation @xmath578 means that there exists a sequence @xmath579 of positive numbers such that ( i ) @xmath580 for all @xmath1 , ( ii ) @xmath581 is independent of @xmath304 for all @xmath1 , and ( iii ) @xmath582 as @xmath583 .",
    "finally , the notation @xmath584 means that for all @xmath585 , there exists @xmath115 such that @xmath586 for all @xmath1 .",
    "using this notation allows us to avoid repeating `` uniformly over @xmath304 '' many times in the proofs of theorem [ theorem : semiparametric ] and corollaries [ cor : general clt ] and [ theorem : general bs ] . throughout this appendix",
    ", we assume that @xmath219 .",
    "we split the proof into five steps .",
    "* step 1 . *",
    "( preliminary rate result ) . we claim that with probability @xmath587 , @xmath588}| \\check \\theta_{uj } - \\theta_{uj}| \\lesssim b_{1n } \\tau_n.\\ ] ] by definition of @xmath19 , we have for each @xmath589 and @xmath11 $ ] , @xmath590\\big| { \\leqslant}\\inf_{\\theta \\in \\theta_{uj}}\\big| { { \\mathbb{e}_n } } [ \\psi_{u j}(w , \\theta , { \\widehat}\\eta_{uj } ) ] \\big| + \\epsilon_n,\\ ] ] which implies via the triangle inequality that uniformly over @xmath73 and @xmath11 $ ] , with probability @xmath456 , @xmath591   \\right|_{\\theta=\\check \\theta_{u j}}\\big |{\\leqslant}\\epsilon_n + 2 i_1 + 2 i_2 \\lesssim   b_{1 n}\\tau_n , \\ \\ \\mbox{where}\\ ] ] @xmath592,\\theta \\in \\theta_{uj } } \\big | { { \\mathbb{e}_n}}[\\psi_{{{u}}j}(w , \\theta , { \\widehat}\\eta_{uj } ) ] - { { \\mathbb{e}_n } } [ \\psi_{uj}(w , \\theta , \\eta_{uj } ) ] \\big | \\lesssim   b_{1n}\\tau_n ,",
    "\\\\ i_2 & : =     \\sup_{u \\in \\mathcal{u},j\\in[{{\\tilde p}}],\\theta \\in \\theta_{uj } }   \\big | { { \\mathbb{e}_n } } [ \\psi_{{{u}}j}(w , \\theta , \\eta_{uj } ) ] - { { \\mathrm{e}}}_p [ \\psi_{{{u}}j}(w , \\theta , \\eta_{uj } ) ] \\big | \\lesssim   \\tau_n.\\end{aligned}\\ ] ] and the bounds on @xmath593 and @xmath594 are derived in step 2 ( note also that @xmath595 by construction of the estimator and assumption [ ass : as](vi ) ) . since by assumption",
    "[ ass : s1](iv ) , @xmath596 does not exceed the left - hand side of ( [ eq : rate proof ] ) , @xmath597}|j_{{{u}}j}|\\gtrsim 1 $ ] , and by assumption [ ass : as](vi ) , @xmath598 , we conclude that @xmath599}| \\check \\theta_{uj } - \\theta_{uj}|   \\lesssim \\left(\\inf_{u \\in \\mathcal{u } , j\\in[{{\\tilde p } } ] } |j_{{{u}}j}|\\right)^{-1 }   b_{1 n } \\tau_n \\lesssim b_{1 n } \\tau_n,\\ ] ] with probability @xmath456 yielding the claim of this step .",
    "* step 2 . *",
    "( bounds on @xmath593 and @xmath594 ) we claim that with probability @xmath587 , @xmath600 to show these relations , observe that with probability @xmath456 , we have @xmath601 and @xmath602 , where @xmath603 ,   \\theta \\in \\theta_{uj } , \\eta \\in { \\mathcal{t}}_{uj } }   \\big | { { \\mathbb{e}_n}}[\\psi_{{{u}}j}(w , \\theta , \\eta ) ] - { { \\mathrm{e}}}_p [ \\psi_{uj}(w , \\theta , \\eta ) ]   \\big | , \\\\ i_{1b } & : =     \\sup_{u \\in \\mathcal{u } , j \\in [ { { \\tilde p } } ] , \\theta \\in \\theta_{uj } , \\eta \\in { \\mathcal{t}}_{uj } }   \\big | { { \\mathrm{e}}}_p [ \\psi_{u j}(w , \\theta , \\eta ) ] - { { \\mathrm{e}}}_p [ \\psi_{uj}(w , \\theta , \\eta_{uj } ) ]   \\big |.\\end{aligned}\\ ] ] to bound @xmath604 , we employ taylor s expansion : @xmath605 , \\theta \\in \\theta_{uj } , \\eta \\in { \\mathcal{t}}_{uj } , r \\in [ 0,1 ) }    \\partial_r   { { \\mathrm{e}}}_p \\big [   \\psi_{{{u}}j } ( w , \\theta ,",
    "\\eta_{uj}+ r ( \\eta - \\eta_{uj } ) )   \\big ] \\\\ & { \\leqslant}b_{1n }   \\sup_{{{u}}\\in { \\mathcal{u } } , j\\in [ { { \\tilde p } } ] , \\eta \\in { \\mathcal{t}}_{uj } } \\| \\eta - \\eta_{uj}\\|_e{\\leqslant}b_{1 n}\\tau_n , \\ ] ] by assumptions [ ass : s1](v ) and [ ass : as](ii ) .    to bound @xmath606 , we apply the maximal inequality of lemma [ lemma : cck ] to the class @xmath154 defined in assumption [ ass : as ] to conclude that with probability @xmath456 , @xmath607 here we used : @xmath608 for all @xmath199 with @xmath609 by assumption [ ass : as](iv ) ; @xmath610 by assumption [ ass : as](v ) ; @xmath611 and @xmath143 by the choice of @xmath158 and @xmath165 .",
    "in turn , the right - hand side of ( [ eq : thm2.1-step2 ] ) is bounded from above by @xmath612 by assumption [ ass : as](vi ) since @xmath613 and @xmath614 combining presented bounds gives the claim of this step .",
    "* step 3 . * ( linearization ) here we prove the claim of the theorem .",
    "fix @xmath10 and @xmath11 $ ] . by definition of @xmath19 , we have @xmath615\\big| { \\leqslant}\\inf_{\\theta \\in \\theta_{uj } } \\sqrt{n } \\big|   { { \\mathbb{e}_n}}[\\psi_{u j}(w , \\theta , { \\widehat}\\eta_{uj } ) ]",
    "\\big|+ \\epsilon_n\\sqrt n.\\ ] ] also , for any @xmath129 and @xmath616 , we have @xmath617 = \\sqrt n{{\\mathbb{e}_n}}[\\psi_{u j}(w,\\theta_{u j},\\eta_{u j } ) ] - \\mathbb g_n \\psi_{u j}(w,\\theta_{u j},\\eta_{u j})\\label{eq : thm 2.1 step 3 first}\\\\ & \\qquad   - \\sqrt n\\big({{\\mathrm{e}}}_p[\\psi_{u j}(w,\\theta_{u j},\\eta_{u j } ) ] - { { \\mathrm{e}}}_p[\\psi_{u j}(w,\\theta,\\eta)]\\big ) + \\mathbb g_n\\psi_{u j}(w,\\theta,\\eta).\\notag\\end{aligned}\\ ] ] moreover , by taylor s expansion of the function @xmath618 $ ] , @xmath619 - { { \\mathrm{e}}}_p[\\psi_{u j}(w,\\theta_{u j},\\eta_{u j } ) ] \\label{eq : thm 2.1 step 3 second}\\\\ & \\qquad = j_{u j}(\\theta - \\theta_{u j } ) + \\mathrm{d}_{u , j,0}[\\eta - \\eta_{u j } ] + \\left.\\partial_r^2 { { \\mathrm{e}}}_p[w,\\theta_{u j } + r(\\theta - \\theta_{u j}),\\eta_{u j } + r(\\eta - \\eta_{u j})]\\right|_{r = \\bar r}\\notag\\end{aligned}\\ ] ] for some @xmath620 . substituting this equality into , taking @xmath621 and @xmath622 , and using gives @xmath623 + j_{uj }   ( \\check \\theta_{u j } - \\theta_{u j } ) + \\mathrm{d}_{u , j,0}[{\\widehat}\\eta_{uj } -\\eta_{uj } ] \\big | \\notag \\\\   & \\qquad { \\leqslant}\\epsilon_n \\sqrt{n }   +    \\inf_{\\theta \\in \\theta_{uj } } \\sqrt{n } |   { { \\mathbb{e}_n}}[\\psi_{uj}(w , \\theta , { \\widehat}\\eta_{uj } ) ] | + |ii_1(u , j)| + |ii_2(u , j)|,\\label{eq : theorem 2.1 second line}\\end{aligned}\\ ] ] where @xmath624\\right|_{\\theta=\\check\\theta_{uj},\\eta={\\widehat}\\eta_{uj}}\\right|,\\\\   ii_{2 } ( u , j ) & : = \\left.{\\mathbb{g}_n}\\big (     \\psi_{uj}(w , \\theta , \\eta)- \\psi_{uj}(w , \\theta_{uj } , \\eta_{uj } ) \\big)\\right|_{\\theta=\\check\\theta_{uj},\\eta={\\widehat}\\eta_{uj } } .\\end{aligned}\\ ] ]",
    "it will be shown in step 4 that @xmath625}\\big ( |ii_1(u , j)| + |ii_2(u , j)|\\big ) = o_p(\\delta_n).\\ ] ] in addition , it will be shown in step 5 that @xmath626 }   \\inf_{\\theta \\in \\theta_{uj } } \\sqrt{n } |   { { \\mathbb{e}_n}}[\\psi_{uj}(w , \\theta , { \\widehat}\\eta_{uj } ) ] | = o_p(\\delta_n).\\ ] ] moreover , @xmath627 by construction of the estimator . therefore , the expression in is @xmath628 .",
    "further , @xmath629}\\big|\\mathrm{d}_{u , j,0}[{\\widehat}\\eta_{uj } -\\eta_{uj } ] \\big|=   o_p(\\delta_n n^{-1/2})\\ ] ] by the near orthogonality condition since @xmath630 for all @xmath10 and @xmath11 $ ] with probability @xmath456 by assumption [ ass : as](i ) .",
    "therefore , assumption [ ass : s1](iv ) gives @xmath631}\\big | j_{uj}^{-1 }   \\sqrt{n }   { { \\mathbb{e}_n}}[\\psi_{uj}(w , \\theta_{uj } , \\eta_{uj } ) ] +   \\sqrt{n } ( \\check \\theta_{uj } - \\theta_{uj } ) \\big | = o_p(\\delta_n).\\ ] ] the asserted claim now follows by dividing both parts of the display above by @xmath632 ( under the supremum on the left - hand side ) and noting that @xmath632 is bounded below from zero uniformly over @xmath10 and @xmath11 $ ] by assumptions [ ass : as](iii ) and [ ass : as](v ) .",
    "* step 4 . *",
    "( bounds on @xmath633 and @xmath634 ) . here",
    "first , with probability @xmath456 , @xmath635}|ii_{1}(u , j)| & { \\leqslant}\\sqrt{n }   b_{2n }   \\sup_{u \\in \\mathcal{u } , j \\in [ { { \\tilde p } } ] } |\\check\\theta_{uj}-\\theta_{uj}|^2 \\vee \\|{\\widehat}\\eta_{uj } - \\eta_{uj}\\|_e^2   \\lesssim   \\sqrt{n }   b_{1 n}^2 b_{2n }   \\tau_n^2 \\lesssim \\delta_n,\\end{aligned}\\ ] ] where the first inequality follows from assumptions [ ass : s1](v ) and [ ass : as](i ) , the second from step 1 and assumptions [ ass : as](ii ) and [ ass : as](vi ) , and the third from assumption [ ass : as](vi ) .",
    "second , with probability @xmath456 , @xmath636}|ii_{2}(u , j)|   \\lesssim   \\sup_{f \\in \\mathcal{f}_2 } | { \\mathbb{g}_n}(f)|\\ ] ] where @xmath637 ,   \\eta \\in { \\mathcal{t}}_{uj } , |\\theta-\\theta_{uj}| { \\leqslant}c b_{1 n } \\tau_n   \\big \\}\\ ] ] for sufficiently large constant @xmath115 . to bound @xmath638",
    ", we apply lemma [ lemma : cck ] .",
    "observe that @xmath639 , |\\theta-\\theta_{uj}|{\\leqslant}c b_{1 n}\\tau_n , \\eta \\in   { \\mathcal{t}}_{uj } }    { { \\mathrm{e}}}_p \\left [    ( \\psi_{uj}(w,\\theta,\\eta ) - \\psi_{uj}(w , \\theta_{uj},\\eta_{uj}))^2   \\right ] \\\\ & { \\leqslant}\\sup_{u \\in \\mathcal{u } , j \\in [ { { \\tilde p } } ] ,   |\\theta-\\theta_{uj}|{\\leqslant}c b_{1 n}\\tau_n , \\eta \\in   { \\mathcal{t}}_{uj } }    c_0 ( |\\theta-\\theta_{uj}| \\vee \\|\\eta-\\eta_{uj}\\|_e)^\\omega   \\lesssim ( b_{1 n } \\tau_n)^{\\omega},\\end{aligned}\\ ] ] where we used assumption [ ass : s1](v ) and assumption [ ass : as](ii ) .",
    "also , observe that @xmath640 by assumption [ ass : as](vi ) since @xmath641 .",
    "therefore , an application of lemma [ lemma : cck ] with an envelope @xmath642 and @xmath643 for sufficiently large constant @xmath115 gives with probability @xmath456 , @xmath644 since @xmath645 and @xmath646 by assumption [ ass : as](iv ) and @xmath647 by lemma [ lemma : andrews ] because @xmath648 for @xmath649 defined in assumption [ ass : as](iv ) .",
    "the claim of this step now follows from an application of assumption [ ass : as](vi ) to bound the right - hand side of ( [ eq : thm2.1eqx ] ) .",
    "* step 5 . * here we prove .",
    "for all @xmath10 and @xmath11 $ ] , let @xmath650 $ ] .",
    "then @xmath651 } | \\bar   \\theta_{u j } - \\theta_{u j } | = o_p ( { { \\rm u_n}}/\\sqrt{n})$ ] since @xmath652}|\\sqrt{n}{{\\mathbb{e}_n}}[\\psi_{uj}(w_{u j},\\theta_{uj},\\eta_{uj})]|]$ ] and @xmath116 is bounded in absolute value below from zero uniformly over @xmath10 and @xmath11 $ ] by assumption [ ass : s1](iv ) .",
    "therefore , @xmath653 for all @xmath10 and @xmath11 $ ] with probability @xmath456 by assumption [ ass : s1](i ) . hence , with the same probability , for all @xmath10 and @xmath11 $ ] , @xmath654 \\big| { \\leqslant}\\sqrt{n } \\big|   { { \\mathbb{e}_n}}[\\psi_{uj}(w , \\bar   \\theta_{uj } , { \\widehat}\\eta_{uj } ) ] \\big|,\\ ] ] and so it suffices to show that @xmath655 } \\sqrt{n } \\big|   { { \\mathbb{e}_n}}[\\psi_{uj}(w , \\bar\\theta_{u j } , { \\widehat}\\eta_{uj } ) ] \\big| = o_p(\\delta_n).\\ ] ] to prove , for given @xmath10 and @xmath11 $ ] , substitute @xmath656 and @xmath657 into and use taylor s expansion in .",
    "this gives @xmath658 \\big| & { \\leqslant}\\sqrt{n } \\big|   { { \\mathbb{e}_n}}[\\psi_{uj}(w , \\theta_{uj } , \\eta_{uj } ) ] + j_{uj } ( \\bar   \\theta_{uj } - \\theta_{uj } ) + { \\mathrm{d}_{u , j,0}[{\\widehat}\\eta_{uj } - \\eta_{uj } ] } \\big| \\\\ & \\quad + |\\widetilde{ii}_1(u , j)| + |\\widetilde{ii}_{2}(u , j)|\\end{aligned}\\ ] ] where @xmath659 and @xmath660 are defined as @xmath633 and @xmath634 in step 3 but with @xmath19 replaced by @xmath661 .",
    "then , given that @xmath651 } | \\bar   \\theta_{u j } - \\theta_{u j } | \\lesssim { { \\rm u_n}}\\log n/\\sqrt n$ ] with probability @xmath456 , the argument in step 4 shows that @xmath662 } \\big ( |\\widetilde{ii}_1(u , j)| + |\\widetilde{ii}_2(u , j)|\\big ) = o_p(\\delta_n).\\ ] ] in addition , @xmath663 + j_{uj } ( \\bar   \\theta_{uj } - \\theta_{uj } ) = 0\\ ] ] by the definition of @xmath664 and @xmath665}|\\mathrm{d}_{u , j,0}[{\\widehat}\\eta_{uj } - \\eta_{uj}]| = o_p(\\delta_n n^{-1/2})$ ] by the near orthogonality condition .",
    "combining these bounds gives , so that the claim of this step follows , and completes the proof of the theorem .",
    "to prove the asserted claim , we will apply lemma 2.4 in @xcite .",
    "denote @xmath666 } \\big|n^{1/2 } \\sigma_{u j}^{-1}(\\check{\\theta}_{u j } - \\theta_{u j})\\big|.\\ ] ] under our assumptions , @xmath667 , and so given that @xmath668 and @xmath179 , it follows that @xmath669 .",
    "hence , since @xmath670 = 1 $ ] , assumption [ ass : osr](i ) and corollary 2.2.8 in @xcite imply that @xmath671}|\\mathcal{n}_{u j}|\\right ] \\lesssim \\sqrt{\\varrho_n \\log ( a_n l_n ) } \\lesssim \\sqrt{\\varrho_n \\log a_n}.\\ ] ] further , theorem [ theorem : semiparametric ] shows that @xmath672}|\\mathbb{g}_n \\bar{\\psi}_{u j}|\\right| = o_p(\\delta_n),\\ ] ] and theorem 2.1 in @xcite , together with assumptions [ ass : osr](i , ii ) , shows that one can construct a version @xmath673 of @xmath217}|\\mathcal{n}_{u j}|$ ] such that @xmath674}|\\mathbb{g}_n \\bar{\\psi}_{u j}| - \\widetilde{z}_n   \\right| = o_p\\left(\\frac{l_n \\varrho_n \\log a_n } { n^{1/2 - 1/q } } + \\frac{l_n^{1/3}(\\varrho_n \\log a_n)^{2/3}}{n^{1/6}}\\right).\\ ] ] combining ( [ eq : cor2.1 - 1 ] ) and ( [ eq : cor2.1 - 2 ] ) gives @xmath675 ) and ( [ eq : cor2.1 - 3 ] ) imply @xmath676 under our growth conditions @xmath677 , @xmath678 , and @xmath679 ; note that formally their lemma 2.4 requires @xmath680 to be the supremum of an empirical process but this requirement is not used in the proof .",
    "the asserted claim now follows by substituting the definitions of @xmath680 and @xmath673 .",
    "denote @xmath681 } |{\\widehat}{\\mathcal{g}}_{u j}| .",
    "$ ] for all @xmath682 , let @xmath683 be the @xmath684 quantile of @xmath217 } |\\mathcal{n}_{u j}|$ ] .",
    "we proceed in several steps .    * step 1 . * here we show that @xmath683 satisfies the bound @xmath685 } |\\mathcal{n}_{u j}|\\right ] + \\sqrt{2\\log(1/\\vartheta)}\\ ] ] for all @xmath682 . indeed , recall that @xmath686 = 1 $ ] for all @xmath523 and @xmath687 $ ]",
    ". therefore , this bound follows from borell s inequality ; see proposition a.2.1 in @xcite .",
    "* step 2 . * here we show that for any @xmath682 and @xmath688 , @xmath689 } |\\mathcal{n}_{u j}|\\right]\\ ] ] for some absolute constant @xmath690 .",
    "indeed , given that @xmath686 = 1 $ ] for all @xmath523 and @xmath687 $ ] , this bound follows from corollary 2.1 in @xcite .",
    "* step 3 . * here we show that @xmath691}\\big|\\frac{1}{\\sqrt{n}}\\sum_{i=1}^n \\xi_i\\bar{\\psi}_{u j}(w_i)\\big| \\right| = o_p\\left ( \\bar{\\delta}_n   \\sqrt{\\bar{\\varrho}_n\\log\\bar{a}_n } \\right).\\ ] ] indeed , the left - hand side of ( [ eq : cor2.2 - 1 ] ) is bounded from above by @xmath692}\\left| \\widehat{\\mathcal{g}}_{u j } - \\frac{1}{\\sqrt{n}}\\sum_{i=1}^n \\xi_i \\bar{\\psi}_{u j}(w_i ) \\right| = \\sup_{u\\in\\mathcal{u},j\\in[\\tilde{p}]}\\left| \\frac{1}{\\sqrt{n}}\\sum_{i=1}^n \\xi_i ( { \\widehat}{\\psi}_{u j}(w_i ) - \\bar{\\psi}_{u j}(w_i ) ) \\right|.\\ ] ] conditional on @xmath15 , @xmath693 is zero - mean gaussian with variance @xmath694{\\leqslant}\\bar{\\delta}_n^2 $ ] with probability at least @xmath197 by assumption [ ass : osr](iii ) .",
    "thus , with the same probability , @xmath695 \\lesssim   \\bar{\\delta}_n   \\sqrt{\\bar{\\varrho}_n\\log \\bar{a}_n}\\ ] ] by assumption [ ass : osr](iii ) and corollary 2.2.8 in @xcite . since @xmath696 , ( [ eq : cor2.2 - 1 ] ) follows .",
    "* step 4 . * here",
    "we show that one can construct a version @xmath673 of @xmath217}|\\mathcal{n}_{u j}|$ ] such that @xmath697 } \\big| \\frac{1}{\\sqrt{n } } \\sum_{i=1}^n \\xi_i \\bar{\\psi}_{u j}(w_i ) \\big| - \\widetilde{z}_n   \\right| = o_p\\left(\\frac{l_n \\varrho_n \\log a_n}{n^{1/2 - 1/q } } + \\frac{l_n^{1/2}(\\varrho_n \\log a_n ) ^{3/4}}{n^{1/4}}\\right).\\ ] ] indeed , as was discussed in the proof of corollary [ cor : general clt ] , we have @xmath698 and @xmath699 = 1 $ ] .",
    "therefore , the claim follows from theorem 2.2 in @xcite combined with assumption [ ass : osr](i , ii ) .",
    "* step 5 . * here we show that there exists a sequence of positive constants @xmath700 such that @xmath701 and @xmath702 indeed , steps 3 and 4 imply that @xmath703 where @xmath704 also , as in the proof of corollary [ cor : general clt ] , @xmath705 \\lesssim ( \\varrho_n\\log a_n)^{1/2}$ ] .",
    "hence , @xmath706 = o(1)$ ] under our conditions , and so there exists a sequence of positive constants @xmath707 such that @xmath708 but @xmath709 = o(1)$ ] .",
    "further , let @xmath710 observe that @xmath711 and @xmath712 the last display implies that with probability at least @xmath713 , @xmath714 hence , with the same probability , using the bounds in steps 1 and 2 , we obtain for some sequence of positive constants @xmath700 such that @xmath715 , @xmath716 since @xmath709 = o(1)$ ] and @xmath717)^2 = o(1)$ ] by assumption .",
    "the claim of this step follows .",
    "* step 6 . * here we complete the proof .",
    "we have @xmath718 } |\\sqrt{n } { \\widehat}{\\sigma}_{u j } ^{-1 } ( \\check{\\theta}_{u j } - \\theta_{u j})| { \\leqslant}c_\\alpha \\big ) & = { { \\mathrm{p}}}_p\\big ( |\\sqrt{n } \\sigma_{u j } ^{-1 } ( \\check{\\theta}_{u j } - \\theta_{u j})| { \\leqslant}c_\\alpha { \\widehat}{\\sigma}_{u j } / \\sigma_{u j } , \\ \\forall u\\in{\\mathcal{u}},j\\in[{{\\tilde p}}]\\big)\\\\ &   { \\leqslant}{{\\mathrm{p}}}_p\\big ( \\sup_{u\\in\\mathcal{u } , j\\in[\\tilde{p } ] } |\\sqrt{n } \\sigma_{u j } ^{-1 } ( \\check{\\theta}_{u j } - \\theta_{u j})| { \\leqslant}c_\\alpha ( 1 + \\varepsilon_n ) \\big ) + o(1)\\\\ &   { \\leqslant}{{\\mathrm{p}}}_p\\big ( \\sup_{u\\in\\mathcal{u } , j\\in[\\tilde{p } ] } |\\sqrt{n } \\sigma_{u j } ^{-1 } ( \\check{\\theta}_{u j } - \\theta_{u j})| { \\leqslant}c^0_{\\alpha   - \\vartheta_n }   \\big ) + o(1)\\\\ &   = 1- \\alpha + \\vartheta_n + o(1 ) = 1-\\alpha + o(1)\\end{aligned}\\ ] ] where the third line follows by assumption [ ass : variance ] , the fourth by step 5 , and the fifth by corollary [ cor : general clt ] .",
    "similar arguments also give the same bound from the other side .",
    "therefore , @xmath719 } |\\sqrt{n } { \\widehat}{\\sigma}_{u j } ^{-1 } ( \\check{\\theta}_{u j } - \\theta_{u j})| { \\leqslant}c_\\alpha \\right ) = 1-\\alpha + o(1).\\ ] ] this completes the proof .      in this appendix",
    ", we use @xmath722 and @xmath115 to denote strictly positive constants that depend only on @xmath353 and @xmath354 ( but do not depend on @xmath1 , @xmath224 , @xmath225 , or @xmath304 ) .",
    "the values of @xmath722 and @xmath115 may change at each appearance .",
    "also , the notation @xmath574 means that @xmath575 for all @xmath1 and some @xmath115 .",
    "the notation @xmath576 means that @xmath577 .",
    "moreover , the notation @xmath578 means that there exists a sequence @xmath579 of positive numbers such that ( i ) @xmath580 for all @xmath1 , ( ii ) @xmath581 is independent of @xmath304 for all @xmath1 , and ( iii ) @xmath582 as @xmath583 .",
    "finally , the notation @xmath723 means that for any @xmath115 , we have @xmath724 . using this notation allows us to avoid repeating `` uniformly over @xmath304 '' and `` uniformly over @xmath10 and @xmath11 $ ] '' many times in the proofs of theorem [ theorem : inferencealg1 ] and corollaries [ cor : logistic clt ]  [ cor : simple example ] .",
    "observe that for all @xmath10 and @xmath11 $ ] , we have @xmath725\\lesssim 1 $ ] by assumptions [ ass : parameters ] and [ ass : covariates ] .",
    "we use this fact several times in the proof without further notice .",
    "for @xmath10 and @xmath11 $ ] , define @xmath726 so that @xmath727 , and @xmath83 is convex .",
    "endow @xmath83 with a norm @xmath80 defined by @xmath728 } \\vee \\|\\eta^{(2)}\\| \\vee \\|\\eta^{(3)}\\|,\\quad \\eta = ( \\eta^{(1)},\\eta^{(2)},\\eta^{(3 ) } ) \\in t_{u j}.\\ ] ] further , recall that @xmath351 and define @xmath729 and @xmath730 for sufficiently large @xmath115 .",
    "first , we verify assumption [ ass : s1](i ) . to bound @xmath112 , below we",
    "establish the following inequality : @xmath731 recall that @xmath732(1-{{\\mathrm{e}}}_p[y_u\\mid d , x]),\\ ] ] and so @xmath733 .",
    "in addition , @xmath734 & = { { \\mathrm{e}}}_p\\big[f_{u_2}^2\\big(x^j(\\gamma_{u_1}^j - \\gamma_{u_2}^j)\\big)\\big(d_j - x^j\\gamma_{u_2}^j-(d_j - x^j\\gamma_{u_1}^j)\\big)\\big]\\notag\\\\ & = -{{\\mathrm{e}}}_p\\big[f_{u_2}^2\\big(x^j(\\gamma_{u_1}^j - \\gamma_{u_2}^j)\\big)(d_j - x^j\\gamma_{u_1}^j)\\big ] \\notag\\\\ & = -{{\\mathrm{e}}}_p\\big[(f_{u_2}^2-f_{u_1}^2)\\big(x^j(\\gamma_{u_1}^j - \\gamma_{u_2}^j)\\big)(d_j - x^j\\gamma_{u_1}^j)\\big]\\notag \\\\ & = -{{\\mathrm{e}}}_p\\big[(f_{u_2}^2-f_{u_1}^2)\\big(x^j(\\gamma_{u_1}^j - \\gamma_{u_2}^j)\\big)z_{u_1}^j\\big]\\label{eq : gamma - lipshitz - derivation}\\end{aligned}\\ ] ] where the first line follows from adding and subtracting @xmath424 , the second from the equality @xmath735=0 $ ] , the third from the equality @xmath736=0 $ ] , and the fourth from @xmath737 .",
    "now , by the cauchy - schwarz inequality , the expression in ( [ eq : gamma - lipshitz - derivation ] ) is bounded in absolute value by @xmath738\\cdot{{\\mathrm{e}}}_p\\big[(f_{u_1}^2-f_{u_2}^2)^2(z_{u_1}^j)^2\\big]\\big)^{1/2}\\\\   & \\qquad \\lesssim \\big({{\\mathrm{e}}}_p\\big[f_{u_2}^2\\big(x^j(\\gamma_{u_1}^j-\\gamma_{u_2}^j)\\big)^2\\big]\\cdot{{\\mathrm{e}}}_p\\big[(f_{u_1}^2-f_{u_2}^2)^2(z_{u_1}^j)^2\\big]\\big)^{1/2}\\\\ & \\qquad \\lesssim |u_2-u_1|\\big({{\\mathrm{e}}}_p\\big[f_{u_2}^2\\big(x^j(\\gamma_{u_1}^j-\\gamma_{u_2}^j)\\big)^2\\big]\\big)^{1/2}\\end{aligned}\\ ] ] where the second line follows from @xmath739\\lesssim \\|\\gamma_{u_1}^j - \\gamma_{u_2}^j\\|^2\\lesssim { { \\mathrm{e}}}_p[f_{u_2}^2(x^j(\\gamma_{u_1}^j-\\gamma_{u_2}^j))^2]$ ] , which holds by assumption [ ass : covariates ] , and the third line follows from ( [ eq : f - lipshitz ] ) .",
    "hence , @xmath740)^{1/2}\\lesssim |u_2-u_1| , $ ] and so @xmath741\\big)^{1/2}\\lesssim |u_2 - u_1|.\\ ] ] therefore , @xmath742 and so ( [ eq : gamma - lipshitz ] ) follows .    next , let @xmath743\\colon g\\in { \\mathcal{g}}_1\\big\\},\\\\ & { \\mathcal{g}}_{3,j } = \\big\\{(y , d , x)\\mapsto d_j - x^j\\gamma_u^j\\colon u\\in { \\mathcal{u}}\\big\\},\\quad j\\in[{{\\tilde p}}].\\end{aligned}\\ ] ] then the function class @xmath744\\}$ ] satisfies @xmath745}{\\mathcal{g}}_{3j}).\\ ] ] observe that @xmath746 is a vc - subgraph class with index bounded by @xmath115 , and so by theorem 2.6.7 in @xcite , its uniform entropy numbers obey @xmath747 where @xmath748 is its envelope .",
    "in addition , lemma [ lemma : partialoutcovering ] implies that the uniform entropy numbers of @xmath749 obey the same inequalities with the same envelope @xmath750 ( but possibly different constant @xmath115 ) .",
    "moreover , for any @xmath10 and @xmath11 $ ] , by assumptions [ ass : parameters ] and [ ass : sparsity ] and the triangle inequality , @xmath751 because by assumption [ ass : covariates ] , @xmath752 .",
    "therefore , ( [ eq : gamma - lipshitz ] ) and lemma [ lem : linear classes ] with @xmath753 imply that for all @xmath11 $ ] , the uniform entropy numbers of @xmath754 obey @xmath755 where @xmath756 is its envelope , and so lemma [ lemma : andrews ] gives that the uniform entropy numbers of @xmath757}{\\mathcal{g}}_{3,j}$ ] obey the same inequalities with the same envelope @xmath758 .",
    "hence , lemma [ lemma : andrews ] also shows that the uniform entropy numbers of @xmath759 obey @xmath760 where @xmath761 is its envelope .",
    "now observe that @xmath762 and that @xmath763 uniformly over @xmath764 by assumption [ ass : covariates ] .",
    "therefore , it follows from lemma [ lemma : cck ] that @xmath765}\\big|\\sqrt{n}{{\\mathbb{e}_n}}[\\psi_{uj}(w , \\theta_{uj } , \\eta_{uj } ) ] \\big|\\big]\\\\ & \\lesssim \\log^{1/2}(a_n m_{n,1 } ) + n^{-1/2 + 1/q}m_{n,1 } \\log(a_n m_{n,1})\\lesssim \\log^{1/2}(a_n m_{n,1})(1+\\delta_n)\\lesssim \\sqrt{\\log a_n}\\end{aligned}\\ ] ] where the last two inequalities follow from assumption [ ass : covariates ] and the facts that @xmath766 and that @xmath767 , which is another consequence of assumption [ ass : covariates ] .",
    "hence , assumption [ ass : parameters ] implies that for all @xmath10 and @xmath74 $ ] , @xmath82 contains a ball of radius @xmath768 centered at @xmath13 for all sufficiently large @xmath1 for any constant @xmath94 .",
    "therefore , assumption [ ass : s1](i ) holds .",
    "next , assumption [ ass : s1](ii ) follows from the observation that for all @xmath10 and @xmath11 $ ] , the map @xmath135 is twice continuously gateaux - differentiable on @xmath769 , and so is the map @xmath134 $ ] .    to verify the near orthogonality condition in assumption [ ass : s1](iii ) , note that for all @xmath10 , @xmath11 $ ] , and @xmath770 with @xmath771 , we have @xmath772 = { { \\mathrm{e}}}_p\\big[r_{u}z_u^j - \\lambda'(z_u^j\\theta_{u j } + x^j\\beta_u^j)z_u^jx^j\\big(\\eta^{(2 ) } - \\beta_u^j - \\theta_{u j}(\\eta^{(3)}-\\gamma_u^j)\\big)\\big]\\ ] ] where we used the equality @xmath773=0 $ ] .",
    "in addition , @xmath774|{\\leqslant}\\delta_n n^{-1/2}$ ] by assumption [ ass : approximation error ] .",
    "further , recall that @xmath775=0 $ ] and observe that @xmath776(1 - { { \\mathrm{e}}}_p[y_u\\mid d , x])\\\\ & = ( \\lambda(d'\\theta_u + x'\\beta_u ) + r_u ) ( 1 - \\lambda(d'\\theta_u + x'\\beta_u ) - r_u)\\\\ & = \\lambda'(d'\\theta_u + x'\\beta_u ) + r_u - r_u^2 - 2r_u\\lambda(d'\\theta_u + x'\\beta_u)\\end{aligned}\\ ] ] where we used the equality @xmath777 , which holds for all @xmath778 .",
    "hence , @xmath779\\big|\\\\ & \\qquad \\lesssim \\big({{\\mathrm{e}}}_p\\big[(r_u z_u^j)^2\\big]\\cdot { { \\mathrm{e}}}_p\\big[\\big(x^j(\\eta^{(2 ) } - \\beta_u^j - \\theta_{u j}(\\eta^{(3)}-\\gamma_u^j))\\big)^2\\big]\\big)^{1/2}\\\\ & \\qquad \\lesssim \\big({{\\mathrm{e}}}_p[r_u^2]\\big)^{1/2}\\big(\\|\\eta^{(2 ) } - \\beta_u^j\\| + \\|\\eta^{(3 ) } - \\gamma_u^j\\|\\big ) \\lesssim s_n\\log",
    "a_n / n\\lesssim \\delta_n n^{-1/2}\\end{aligned}\\ ] ] where the second line follows from the cauchy - schwarz inequality and the observations that @xmath780 and that @xmath781 for all @xmath47 , and the third line from assumptions [ ass : covariates ] and [ ass : approximation error ] ( the last inequality holds because @xmath782 by assumption [ ass : covariates ] ) . also , when @xmath622 , we have @xmath783| = 0 $ ] , and so assumption [ ass : s1](iii ) holds .",
    "next , we verify assumption [ ass : s1](iv ) .",
    "fix @xmath68 and @xmath11 $ ] . observe that @xmath784\\\\ & = -{{\\mathrm{e}}}_p\\big[f_u^2 |z_u^j|^2\\big ] + { { \\mathrm{e}}}_p\\big[(r_u -r_u^2 - 2r_u \\lambda(d'\\theta_u + x'\\beta_u))|z_u^j|^2\\big].\\end{aligned}\\ ] ] hence , by assumptions [ ass : parameters ] , [ ass : covariates ] and [ ass : approximation error ] and the cauchy - schwarz inequality , @xmath785{{\\mathrm{e}}}_p[|z_u^j|^4]\\big)^{1/2}=c_1 + o(1),\\ ] ] and also @xmath786 uniformly over @xmath10 and @xmath11 $ ] .",
    "in addition , @xmath787 = j_{uj}(\\theta-\\theta_{uj})+\\frac{1}{2}\\partial_\\theta^2\\big.\\big\\{{{\\mathrm{e}}}_p[\\psi_{uj}(w,\\theta,\\eta_{uj})]\\big\\}\\big|_{\\theta = \\bar\\theta}(\\theta-\\theta_{uj})^2\\ ] ] for some @xmath788 . moreover , for all @xmath129 , we have @xmath789|{\\leqslant}{{\\mathrm{e}}}_p[|z_u^j|^3 ] \\lesssim 1 $ ] by assumptions [ ass : parameters ] and [ ass : covariates ] since @xmath790 for all @xmath47 .",
    "these inequalities together imply assumption [ ass : s1](iv ) .",
    "next , we verify assumption [ ass : s1](v ) with @xmath791 and @xmath792 for sufficiently large @xmath115 .",
    "fix @xmath10 , @xmath11 $ ] , @xmath793 $ ] , @xmath129 , and @xmath794 .",
    "we consider the case @xmath771 , and the other case is similar .",
    "denote @xmath795 then @xmath796 since @xmath797 for all @xmath47 .",
    "in addition , @xmath798 \\lesssim { { \\mathrm{e}}}_p[r_u^2]{\\leqslant}\\|\\eta - \\eta_{u j}\\|_e^2,\\quad { { \\mathrm{e}}}_p[(x^j(\\eta^{(3 ) } - \\gamma_u^j))^2]\\lesssim \\|\\eta^{(3 ) } - \\gamma_u^j\\|^2{\\leqslant}\\|\\eta - \\eta_{u j}\\|_e^2\\end{aligned}\\ ] ] by assumptions [ ass : approximation error ] and [ ass : covariates ] , respectively .",
    "thus , @xmath799\\lesssim \\|\\eta - \\eta_{u j}\\|_e^2 $ ] . also , @xmath800 & { \\leqslant}{{\\mathrm{e}}}_p\\big[(z_u^j)^2\\big ] \\cdot { { \\mathrm{e}}}_p \\big [ ( ( d_j - x^j\\eta^{(3)})\\theta +   x^j \\eta^{(2 ) } - z_u^j \\theta_{u j } - x^j \\beta_u^j)^2\\big]\\\\ & \\lesssim { { \\mathrm{e}}}_p \\big [ ( ( d_j - x^j\\eta^{(3)})\\theta +   x^j \\eta^{(2 ) } - z_u^j \\theta_{u j } - x^j \\beta_u^j)^2\\big]\\\\ & \\lesssim { { \\mathrm{e}}}_p\\big[(x^j ( \\eta^{(2 ) } - \\beta_u^j))^2\\big ] + { { \\mathrm{e}}}_p\\big[(d_j ( \\theta - \\theta_{u j}))^2\\big ] + { { \\mathrm{e}}}_p\\big[(x^j(\\eta^{(3)}\\theta - \\gamma_u^j \\theta_{u j}))^2\\big]\\\\ & \\lesssim \\|\\eta^{(2 ) } - \\beta_u^j\\|^2 + |\\theta - \\theta_{u j}|^2 + { { \\mathrm{e}}}_p\\big[(x^j \\eta^{(3)}(\\theta - \\theta_{u j}))^2\\big ] + { { \\mathrm{e}}}_p\\big[(x^j ( \\eta^{(3 ) } - \\gamma_u^j)\\theta_{u j})^2\\big]\\\\ & \\lesssim \\|\\eta^{(2 ) } - \\beta_u^j\\|^2 + |\\theta - \\theta_{u j}|^2 + \\|\\eta^{(3 ) } - \\gamma_u^j\\|^2 \\lesssim \\|\\eta - \\eta_{u j}\\|_e^2 + |\\theta - \\theta_{u j}|^2\\end{aligned}\\ ] ] where the first line follows from the cauchy - schwarz inequality , the second from @xmath801\\lesssim 1 $ ] , the third from the triangle inequality , the fourth from assumption [ ass : covariates ] and the triangle inequality , and the fifth from assumptions [ ass : parameters ] and [ ass : covariates ] and the fact that @xmath802 .",
    "therefore , assumption [ ass : s1](@xmath556-a ) holds .    to verify assumption [ ass : s1](@xmath556-b ) , observe that under our conditions , @xmath803 = { { \\mathrm{e}}}_p\\big[\\partial_r\\psi_{u j}(w,\\theta,\\eta_{u j } + r ( \\eta - \\eta_{u j}))\\big].\\ ] ] further , denote @xmath804 then @xmath805 and so @xmath806 = { { \\mathrm{e}}}_p[i_{2,1 } ] + { { \\mathrm{e}}}_p[i_{2,2 } ] + { { \\mathrm{e}}}_p[i_{2,3}].\\ ] ] now , observe that @xmath807\\lesssim { { \\mathrm{e}}}_p\\big[|x^j(\\eta^{(3 ) } - \\gamma_u^j)|\\big ] \\lesssim \\big({{\\mathrm{e}}}_p\\big[|x^j(\\eta^{(3 ) } - \\gamma_u^j)|^2\\big]\\big)^{1/2 } \\lesssim \\|\\eta - \\eta_{u j}\\|_e\\ ] ] where the first inequality holds since @xmath780 , the second by jensen s inequality , and the third by assumption [ ass : covariates ] . also , by the cauchy - schwarz inequality , @xmath808{\\leqslant}\\big({{\\mathrm{e}}}_p[r_u^2]\\cdot { { \\mathrm{e}}}_p\\big[(z_{u j } - r x^j(\\eta^{(3 ) } - \\gamma_u^j))^2\\big]\\big)^{1/2}\\lesssim \\|\\eta - \\eta_{u j}\\|_e\\ ] ] where the second inequality follows from @xmath809)^{1/2}{\\leqslant}\\|\\eta - \\eta_{u j}\\|_e$ ] .",
    "moreover , since @xmath797 for all @xmath810 , the cauchy - schwarz inequality gives @xmath811 \\lesssim \\big({{\\mathrm{e}}}_p\\big[(z_u^j - r x^j(\\eta^{(3 ) } - \\gamma_u^j))^2\\big ] { { \\mathrm{e}}}_p\\big[(x^j(\\eta^{(2 ) } - \\beta_u^j ) - \\theta x^j(\\eta^{(3 ) } - \\gamma_u^j))^2\\big]\\big)^{1/2}\\lesssim \\|\\eta - \\eta_{u j}\\|_e.\\ ] ] therefore , assumption [ ass : s1](@xmath556-b ) holds .    to verify assumption [ ass : s1](@xmath556-c ) , denote @xmath812 so that @xmath813 , @xmath814 , and @xmath815 .",
    "now , observe that since @xmath797 for all @xmath303 , @xmath816\\lesssim \\sqrt{{{\\mathrm{e}}}_p[r_u^2]}\\|\\eta^{(3 ) } - \\gamma_u^j\\| + \\|\\eta^{(3 ) } - \\gamma_u^j\\|(\\|\\eta^{(2 ) } - \\beta_u^j\\| + \\|\\eta^{(3 ) } - \\gamma_u^j\\|)\\lesssim \\|\\eta - \\eta_{u j}\\|_e^2\\ ] ] by the cauchy - schwarz inequality , the triangle inequality , and assumptions [ ass : parameters ] and [ ass : covariates ] . similarly , @xmath817\\lesssim \\|\\eta - \\eta_{u j}\\|_e^2 $ ] .",
    "in addition , since @xmath790 for all @xmath47 , @xmath818&\\lesssim \\|\\eta - \\eta_{u j}\\|_e^2 + \\big({{\\mathrm{e}}}_p\\big[(z_u^j - r x^j(\\eta^{(3 ) } - \\gamma_u^j))^2\\big]{{\\mathrm{e}}}_p\\big[(x^j(\\eta^{(2 ) } - \\beta_u^j ) - \\theta x^j(\\eta^{(3 ) } - \\gamma_u^j))^4\\big]\\big)^{1/2}\\\\ & \\lesssim \\|\\eta - \\eta_{u j}\\|_e^2 + \\|\\eta - \\eta_{u j}\\|_e^2 \\lesssim \\|\\eta - \\eta_{u j}\\|_e^2\\end{aligned}\\ ] ] by the arguments used above , the cauchy - schwarz inequality , and assumption [ ass : covariates ] . also , the terms in",
    "@xmath819 $ ] arising from differentiation of @xmath820 can be bounded similarly .",
    "therefore , assumption [ ass : s1](@xmath556-c ) holds .",
    "next , we verify assumption [ ass : as](i ) .",
    "observe that by theorems [ thm : rateestimatedlassologistic ] and [ thm : rateestimatedlassolinear ] , with probability @xmath456 , @xmath821 @xmath822 } \\|\\widetilde \\gamma_{u}^j - \\gamma_{u}^j\\| \\lesssim \\sqrt{s_n\\log a_n / n } , \\ \\",
    "\\mbox{and } \\ \\",
    "\\sup_{u\\in{\\mathcal{u } } , j\\in[{{\\tilde p } } ] } \\|\\widetilde \\gamma_{u}^j\\|_0 \\lesssim s_n.\\ ] ] in addition , @xmath823\\setminus j}',\\widetilde \\beta_u')'$ ] , and so uniformly over @xmath10 and @xmath11 $ ] , with probability @xmath456 , @xmath824 and @xmath825 . moreover , uniformly over @xmath10 and @xmath11 $ ] , with probability @xmath456 , @xmath826 by assumption [ ass : sparsity ] and the triangle and the cauchy - schwarz inequalities . therefore ,",
    "assumption [ ass : as](i ) holds .",
    "in addition , assumption [ ass : as](ii ) holds by construction of @xmath827 and since @xmath383{\\leqslant}c_1 s_n\\log a_n /n$ ] , which in turn follows from assumption [ ass : approximation error ] . also , assumption [ ass : as](iii ) holds by construction of @xmath827 .",
    "next , we establish the entropy bound of assumption [ ass : as](iv ) with @xmath828 and @xmath829 for sufficiently large constant @xmath830 ( recall that @xmath351 ) .",
    "let @xmath831 \\ ] ] for sufficiently large @xmath115 .",
    "moreover , recall that @xmath832 and let @xmath833,\\theta\\in\\theta_{u j},\\eta\\in\\mathcal{t}_{u j}\\setminus \\eta_{u j}\\big\\},\\\\ & { \\mathcal{f}}_{1,2 } = \\big\\{w\\mapsto \\psi_{u j}(w,\\theta,\\eta_{u j})\\colon u\\in{\\mathcal{u } } , j\\in[{{\\tilde p}}],\\theta\\in\\theta_{u j}\\big\\}.\\end{aligned}\\ ] ] then @xmath834 and @xmath835}{\\mathcal{g}}_{5,j } ) - \\lambda(\\cup_{j\\in[{{\\tilde p}}]}{\\mathcal{g}}_{5,j}))\\cdot ( \\cup_{j\\in[{{\\tilde p}}]}{\\mathcal{g}}_{3,j})\\end{aligned}\\ ] ] where @xmath746 , @xmath749 , and @xmath754 , @xmath11 $ ] , are defined above , because @xmath836 .",
    "a bound for the uniform entropy numbers of @xmath746 is established above in ( [ eq : g1 entropy bound ] ) . also , @xmath837 is a union over @xmath838 vc - subgraph classes with indices @xmath839 , and so is @xmath840 .",
    "hence , by lemma [ lemma : andrews ] , @xmath841 where @xmath842 } \\sup_{\\gamma\\in \\mathbb{r}^{{{\\tilde p}}- 1 + p}\\colon \\|\\gamma - \\gamma_u^j\\|_1 { \\leqslant}c\\sqrt{s_n}\\tau_n}\\big(2|d_j - x^j\\gamma|\\big)\\ ] ] is an envelope of @xmath843 . observe that @xmath844 } |z_u^j| + \\|x\\|_\\infty c\\sqrt{s_n}\\tau_n$ ] , and so @xmath845 by assumption [ ass : covariates ] ( observe that @xmath846 and @xmath359 ) .",
    "next we turn to @xmath847 .",
    "bounds for the uniform entropy numbers of @xmath749 and @xmath757}{\\mathcal{g}}_{3,j}$ ] are established above .",
    "consider @xmath848 for @xmath11 $ ] .",
    "note that for all @xmath849 , @xmath850 by , , and assumption [ ass : parameters ] .",
    "therefore , for all @xmath851 such that @xmath852 and @xmath853 , and all @xmath849 , @xmath854 hence , lemma [ lem : linear classes ] implies that for all @xmath11 $ ] , the uniform entropy numbers of @xmath855 obey @xmath856 where @xmath857 is its envelope . hence , by lemma [ lemma : andrews ] , @xmath858 where @xmath859}|z_u^j|+m_{n,2}^{-1}(\\|d\\|_\\infty \\vee \\|x\\|_\\infty ) ) $ ] is an envelope of @xmath847 that satisfies @xmath860 by assumption [ ass : covariates ] and the cauchy - schwarz inequality . applying lemma [ lemma : andrews ] one more time finally shows that the uniform entropy numbers of @xmath649 obey ( [ eq : f1 entropy bound ] ) with constants specified above and with an envelope @xmath861 satisfying @xmath862 .",
    "next , we verify assumption [ ass : as](v ) .",
    "fix @xmath10 , @xmath11 $ ] , @xmath129 , and @xmath863 .",
    "then @xmath864&={{\\mathrm{e}}}_p\\big[{{\\mathrm{e}}}_p\\big[\\big(y_u - \\lambda\\big((d_j - x^j\\eta^{(3)})\\theta + x^j\\eta^{(2)}\\big ) -",
    "\\eta^{(1)}\\big)^2 \\mid d , x\\big ] ( d_j - x^j\\eta^{(3)})^2\\big]\\\\ & { \\geqslant}{{\\mathrm{e}}}_p[f_u^2(d_j - x^j\\eta^{(3)})^2]{\\geqslant}c\\end{aligned}\\ ] ] where the first inequality follows from the fact that for any random variable @xmath481 , the function @xmath865 $ ] is minimized at @xmath866 $ ] and in this case @xmath867 , and the second inequality follows from assumption [ ass : covariates ] . in addition , @xmath868{\\leqslant}{{\\mathrm{e}}}_p[(d_j - x^j\\eta^{(3)})^2 ] \\lesssim 1\\ ] ] by assumptions [ ass : parameters ] and [ ass : covariates ] .",
    "therefore , assumption [ ass : as](v ) holds .",
    "finally , we verify assumption [ ass : as](vi ) .",
    "the condition ( a ) holds by construction of @xmath869 and @xmath165 . to verify the condition ( b ) observe that @xmath870 by assumption [ ass : covariates ] .",
    "in addition , @xmath871 because @xmath872 , which is established above , and @xmath873 , which holds by assumption [ ass : covariates ] .",
    "the condition ( b ) follows .",
    "the condition ( c ) holds because @xmath874 as in the verification of the condition ( b ) .",
    "this completes the verification of assumptions [ ass : s1 ] and [ ass : as ] and thus completes the proof of the theorem .",
    "the asserted claim will follow from corollary [ cor : general clt ] as long as we can verify its conditions .",
    "assumptions [ ass : s1 ] and [ ass : as ] were verified in the proof of theorem [ theorem : inferencealg1 ]",
    ". therefore , it suffices to verify assumption [ ass : osr](i , ii ) and the growth conditions of corollary [ cor : general clt ] .",
    "first , we verify assumption [ ass : osr](i ) .",
    "recall the function class @xmath744\\}$ ] defined in the proof of theorem [ theorem : inferencealg1 ] , where it is also proven that its uniform entropy numbers obey with an envelope @xmath875 satisfying @xmath762 . also , note that assumption [ ass : s1](iv ) gives @xmath876 for all @xmath10 and @xmath11 $ ] , and that assumption [ ass : as](v ) gives @xmath877\\lesssim 1 $ ] for all @xmath10 and @xmath11 $ ] .",
    "hence , @xmath878 and so lemma [ lemma : andrews ] implies that the uniform entropy numbers of @xmath879 obey @xmath880 where its envelope @xmath190 satisfies @xmath881 .",
    "thus , assumption [ ass : osr](i ) holds with @xmath882 , @xmath883 , and @xmath884 .",
    "next , we verify assumption [ ass : osr](ii ) . for @xmath194 , @xmath10 , and",
    "@xmath11 $ ] , we have @xmath885\\lesssim { { \\mathrm{e}}}_p\\big[|d_j - x^j\\gamma_u^j|^k\\big]\\lesssim 1\\ ] ] by assumptions [ ass : parameters ] and [ ass : covariates ] since @xmath886 , @xmath781 for all @xmath47 , and @xmath780 .",
    "thus , assumption [ ass : osr](ii ) holds with the same @xmath887 since @xmath359 .    finally , with our choice of @xmath888 and @xmath889 , the growth conditions of corollary [ cor : general clt ] hold by assumption .",
    "this completes the proof .",
    "the asserted claim will follow from corollary [ theorem : general bs ] as long as we can verify its conditions .",
    "assumptions [ ass : s1 ] and [ ass : as ] were verified in the proof of theorem [ theorem : inferencealg1 ] .",
    "assumption [ ass : osr](i , ii ) was verified in the proof of corollary [ cor : logistic clt ] .",
    "therefore , it suffices to verify assumptions [ ass : osr](iii ) and [ ass : variance ] and the growth conditions of corollary [ theorem : general bs ] .",
    "we split the proof into six steps . in steps 1 - 3 , we verify assumption [ ass : variance ] . in steps 4 and 5 ,",
    "we verify assumption [ ass : osr](iii ) . in step 6 , we verify the growth conditions of corollary [ theorem : general bs ]",
    ".    * step 1 . * here we show that @xmath890 uniformly over @xmath10 and @xmath11 $ ] . for @xmath891 , @xmath892 , @xmath893 , and @xmath11 $ ] , define @xmath894.\\end{aligned}\\ ] ] then @xmath895 $ ] and @xmath896 for all @xmath10 and @xmath11 $ ] .",
    "therefore , by the triangle inequality , @xmath897 define @xmath898,\\theta\\in\\theta_{u j},\\eta = ( \\eta^{(1)},\\eta^{(2)},\\eta^{(3)})\\in\\mathcal{t}_{u j}\\setminus \\eta_{u j}\\big\\}.\\end{gathered}\\ ] ] then by assumption [ ass : as](i ) , with probability @xmath456 , @xmath899 - { { \\mathrm{e}}}_p[f(w)]\\big|\\ ] ] for all @xmath10 and @xmath11 $ ] .",
    "in addition , @xmath900 , where the function class @xmath837 is introduced in the proof of theorem [ theorem : inferencealg1 ] .",
    "moreover , @xmath901 uniformly over @xmath10 , @xmath11 $ ] , @xmath129 , and @xmath902 by assumptions [ ass : parameters ] . hence ,",
    "applying lemmas [ lemma : andrews ] and [ lem : bounded lipschitz classes ] with @xmath903 shows that the uniform entropy numbers of @xmath904 obey @xmath905 where @xmath906 is its envelope , and @xmath907 is defined in the proof of theorem [ theorem : inferencealg1 ] . also , recall that @xmath908 , which is established in the proof of theorem [ theorem : inferencealg1 ] , and so @xmath909\\big)^{4/q}\\\\ & \\qquad{\\leqslant}\\big({{\\mathrm{e}}}_p\\big[\\max_{1{\\leqslant}i{\\leqslant}n}|\\widetilde f_{1,1}(w_i)|^{q/2}\\big]\\big)^{4/q } + \\big({{\\mathrm{e}}}_p\\big[\\max_{1{\\leqslant}i{\\leqslant}n}\\big(\\frac{\\|d_i\\|_\\infty\\vee\\|x_i\\|_\\infty}{m_{n,2 } n^{2/q}}\\big)^{q/4}|\\widetilde f_{1,1}(w_i)|^{q/2}\\big]\\big)^{4/q}\\\\ & \\qquad \\lesssim",
    "n^{2/q}m_{n,1}^2 + n^{4/q}\\big({{\\mathrm{e}}}_p\\big[\\big(\\frac{\\|d\\|_\\infty\\vee \\|x\\|_\\infty}{m_{n,2 } n^{2/q}}\\big)^{q/2}\\big]\\cdot { { \\mathrm{e}}}_p\\big[|\\widetilde f_{1,1}(w)|^q\\big]\\big)^{2/q}\\lesssim n^{2/q}m_{n,1}^2\\end{aligned}\\ ] ] where the first line follows from the triangle inequality , and the second from the cauchy - schwarz inequality and assumption [ ass : covariates ] .",
    "in addition , @xmath763 for all @xmath910 . hence , lemma [ lemma : cck ] implies that @xmath911 - { { \\mathrm{e}}}_p[f(w)]\\big|\\lesssim \\sqrt{\\frac{s_n\\log a_n}{n } } + \\frac{m_{n,1}^2s_n\\log a_n}{n^{1 - 2/q } } = o(\\log^{-1}a_n)\\ ] ] with probability @xmath456 by assumption [ ass : covariates ] and the growth condition @xmath912 .",
    "next , using the same arguments as those used to verify assumption [ ass : s1](@xmath556-a ) in theorem [ theorem : inferencealg1 ] shows that @xmath913 and the right - hand of this inequality is bounded from above by @xmath914 uniformly over @xmath10 and @xmath11 $ ] with probability @xmath456 , as demostrated in the proof of theorem [ theorem : inferencealg1 ] . in turns ,",
    "@xmath915 by assumption . combining presented bounds",
    "gives the claim of this step .",
    "* step 2 . * here we show that @xmath916 - { { \\mathrm{e}}}_p[\\psi_{u j}^2(w,\\theta_{u j},\\eta_{u j } ) ] = o_p(\\log^{-1 } a_n)\\ ] ] uniformly over @xmath10 and @xmath11 $ ] .",
    "the proof of this claim is similar to that in step 1 , where the main difference is that instead of @xmath917 in the function class @xmath904 , we set @xmath918 , with the resulting function class having the same envelope and its uniform entropy numbers obeying the same bounds as those derived fo @xmath904 ( up - to a possibly different constants ) .",
    "* step 3 . * here we finish the verification of assumption [ ass : variance ] .",
    "observe that @xmath919 and @xmath920\\lesssim 1 $ ] for all @xmath10 and @xmath11 $ ] by assumptions [ ass : s1](iv ) and [ ass : as](v ) .",
    "hence , @xmath921 , and so @xmath922+j_{u j}^{-2}\\big|{{\\mathbb{e}_n}}[\\psi_{u j}^2(w,\\widetilde\\theta_{u j},{\\widehat}\\eta_{u j } ) ] - { { \\mathrm{e}}}_p[\\psi_{u j}^2(w,\\theta_{u j},\\eta_{u j})]\\big|\\\\ & \\lesssim \\big|{\\widehat}j_{u j } - j_{u j}\\big| + \\big|{{\\mathbb{e}_n}}[\\psi_{u j}^2(w,\\widetilde\\theta_{u j},{\\widehat}\\eta_{u j } ) ] - { { \\mathrm{e}}}_p[\\psi_{u j}^2(w,\\theta_{u j},\\eta_{u j})]\\big| = o_p(\\log^{-1}a_n)\\end{aligned}\\ ] ] uniformly over @xmath10 and @xmath11 $ ] by steps 1 and 2 . therefore ,",
    "assumption [ ass : variance ] holds for some @xmath923 and @xmath924 satisfying @xmath925 and @xmath926 .",
    "* step 4 . * here we show that the inequality concerning the entropy numbers of @xmath927 in assumption [ ass : osr](iii ) holds with @xmath928 , @xmath929 , and @xmath930 . by construction of @xmath212 , the function class @xmath931\\}$ ]",
    "contains at most @xmath932 functions ( as @xmath224 varies , new functions appear only as @xmath224 crosses one of the observations @xmath933 ) .",
    "also , it follows from ( [ eq : entropy numbers f0 ] ) in the proof of corollary [ cor : logistic clt ] that the entropy numbers of @xmath934\\}$ ] obey @xmath935 with probability @xmath456 .",
    "hence , @xmath936 with probability @xmath456 .",
    "the claim of this step follows .",
    "* step 5 . * here we show that the second part of assumption [ ass : osr](iii ) , that is , that with probability @xmath197 , we have @xmath937 for all @xmath201 , holds for some @xmath938 and @xmath924 satisfying @xmath939 and @xmath930 . by the triangle inequality , @xmath940 we bound two terms on the right - hand side of this inequality in turn . to bound the first term ,",
    "observe that @xmath941 uniformly over @xmath10 and @xmath11 $ ] by steps 1 and 3 and since @xmath919 and @xmath942 , which is discussed in step 3 .",
    "also , as established in the proof of theorem [ theorem : inferencealg1 ] , the uniform entropy numbers of the function class @xmath943\\}$ ] obey with an envelope @xmath875 satisfying @xmath762 .",
    "moveover , @xmath944\\lesssim 1 $ ] uniformly over @xmath945 by assumption [ ass : as](v ) .",
    "therefore , lemma [ lem : maximal inequality 2 ] shows that @xmath946}{{\\mathbb{e}_n}}[\\psi_{u j}^2(w,\\theta_{u j},\\eta_{u j})]\\big ] & \\lesssim 1 + n^{-1/2 + 1/q}m_{n,1}\\big(\\sqrt{\\log a_n } + n^{-1/2 + 1/q}m_{n,1 } \\log a_n\\big)\\\\ & \\lesssim 1 + n^{-1 + 2/q}m_{n,1}^2\\log a_n\\lesssim 1,\\end{aligned}\\ ] ] where the second inequality follows from assumption [ ass : covariates ] .",
    "hence , @xmath947 uniformly over @xmath10 and @xmath11 $ ] .    to bound the second term , define @xmath948 , \\theta\\in\\theta_{u j } , |\\theta - \\theta_{u j}|{\\leqslant}\\sqrt{cs_n\\log a_n / n } , \\eta\\in\\mathcal t_{u j}\\big\\}\\ ] ] for sufficiently large constant @xmath830 and @xmath164 appearing in assumption [ ass : as ] .",
    "then @xmath949 , and so lemma [ lemma : andrews ] together with the bound for the uniform entropy numbers of @xmath649 established in the proof of theorem [ theorem : inferencealg1 ] imply that the uniform entropy numbers of @xmath950 obey @xmath951 where @xmath952 is its envelope satisfying @xmath953 .",
    "in addition , assumption [ ass : as](i ) together with step 1 in the proof of theorem [ theorem : semiparametric ] imply that with probability @xmath456 , @xmath954 for all @xmath10 and @xmath11 $ ] ( recall that in the proof of theorem [ theorem : inferencealg1 ] , we set @xmath955 and @xmath956 ) . also , assumptions [ ass : s1](@xmath556-a ) and [ ass : as](ii ) show that @xmath944\\lesssim s_n\\log a_n / n$ ] uniformly over @xmath957 .",
    "hence , it follows from lemma [ lem : maximal inequality 2 ] that @xmath958\\big ] & \\lesssim s_n\\log a_n / n + n^{-1/2 + 1/q}m_{n,1}\\big(n^{-1/2}s_n\\log a_n + n^{-1/2 + 1/q}m_{n,1}s_n\\log a_n\\big)\\\\ & \\lesssim n^{-1 + 2/q}m_{n,1}^2s_n\\log a_n.\\end{aligned}\\ ] ] hence , @xmath959 uniformly over @xmath10 and @xmath11 $ ] by assumption [ ass : covariates ] .",
    "combining presented bounds gives the asserted claim and completes the verification of assumption [ ass : osr ] .",
    "* step 6 . * recall that the growth conditions of corollary [ cor : general clt ] were verified in the proof of corollary [ cor : logistic clt ] , where we set @xmath882 and @xmath960 .",
    "the other growth conditions of corollary [ theorem : general bs ] , @xmath961 and @xmath962 hold because we have @xmath963 , @xmath964 , @xmath965 , and @xmath966 .",
    "this completes the proof of the corollary .      to prove the asserted claim",
    ", we will apply corollary [ cor : logistic bands ] .",
    "below we will verify assumptions [ ass : covariates](iii , v , vi , vii , viii , ix ) , [ ass : approximation error](iii ) , and the growth conditions of corollary [ cor : logistic bands ] .",
    "set @xmath967\\big)^{1/(2q ) } \\ \\ \\ \\mbox{and } \\ \\ \\ \\bar c_n : = 1+\\sup_{u\\in { \\mathcal{u } } , j\\in [ { { \\tilde p } } ] } \\|\\gamma_u^j\\|_1\\ ] ] so that @xmath968 and @xmath969 by assumption .",
    "observe that for all @xmath10 and @xmath11 $ ] , @xmath970 then @xmath971\\big)^{1/3 } \\lesssim \\bar c_n\\big({{\\mathrm{e}}}_p\\big[(\\|d\\|_\\infty\\vee \\|x\\|_\\infty)^6\\big]\\big)^{1/3}\\lesssim \\bar c_n\\bar m_n^2 \\lesssim 1.\\ ] ] therefore , given that @xmath972 by assumption , it follows that assumption [ ass : covariates](iii ) holds for some @xmath973 satisfying @xmath389 .    also , @xmath974}|z_u^j|^{2q}\\right]\\right)^{1/(2q)}\\lesssim",
    "\\bar c_n\\bar m_n \\lesssim 1,\\ ] ] and so assumption [ ass : covariates](v ) holds with @xmath975 for sufficiently large constant @xmath115 .",
    "in addition , since @xmath976 , assumption [ ass : covariates](vi ) holds for some @xmath973 satisfying @xmath389 .",
    "further , assumption [ ass : covariates](vii ) holds with @xmath977 by definition of @xmath978 .",
    "in addition , since @xmath979 , assumption [ ass : covariates](viii ) holds for some @xmath973 satisfying @xmath389 . also , assumption [ ass : covariates](ix ) holds for some @xmath973 satisfying @xmath389 since @xmath980 , @xmath981 , @xmath982 , and @xmath355 .    moreover , since @xmath406}|{{\\mathrm{e}}}_p[r_u z_u^j]| = o((n\\log a_n)^{-1/2})$ ] , assumption [ ass : approximation error](iii ) holds for some @xmath973 satisfying @xmath389 .",
    "finally , the growth conditions @xmath395 and @xmath396 hold because @xmath983 , @xmath984 , and @xmath985 .    thus , there exists @xmath973 such that assumptions [ ass : covariates](iii , v , vi , vii , viii , ix ) and [ ass : approximation error](iii ) as well as all growth conditions of corollary [ cor : logistic bands ] are satisfied .",
    "since all other conditions of corollary [ cor : logistic bands ] are assumed , the asserted claim follows from that in corollary [ cor : logistic bands ] .      in this appendix",
    ", we use @xmath115 to denote a strictly positive constant that is independent of @xmath1 and @xmath304 .",
    "the value of @xmath115 may change at each appearance .",
    "also , the notation @xmath574 means that @xmath575 for all @xmath1 and some @xmath115 .",
    "the notation @xmath576 means that @xmath577 .",
    "moreover , the notation @xmath578 means that there exists a sequence @xmath579 of positive numbers such that ( i ) @xmath580 for all @xmath1 , ( ii ) @xmath581 is independent of @xmath304 for all @xmath1 , and ( iii ) @xmath582 as @xmath583 .",
    "finally , the notation @xmath986 means that for any @xmath585 , there exists @xmath115 such that @xmath987 for all @xmath1 , and the notation @xmath988 means that @xmath989 .",
    "using this notation allows us to avoid repeating `` uniformly over @xmath304 '' many times in the proofs of theorems [ thm : rateestimatedlassologistic ] and [ thm : rateestimatedlassolinear ] .      in this proof",
    ", we will rely upon results in appendix [ sec : generic results ] .",
    "in particular , the asserted claims will follow from an application of lemmas [ lemma : lassomrateraw ] , [ lemma : lassomsparsity ] , and [ lemma : postlassomrateraw ] ( with some extra work ) . to follow the notation in appendix [ sec : generic results ] , define @xmath990 and @xmath991 and redefine @xmath992 , @xmath993 , and @xmath994 . also , define @xmath995 as a solution to the following equation : @xmath996 since @xmath997 is increasing , for each value of @xmath998 , @xmath999 is uniquely defined",
    ". then @xmath330 satisfies with @xmath1000 for @xmath248 being a vector in @xmath1001 and @xmath1002 being a function of @xmath998 .",
    "similarly , @xmath437 satisfies where @xmath1003 and @xmath1004 , the identically zero function of @xmath998 .    to apply lemmas [ lemma : lassomrateraw ] , [ lemma : lassomsparsity ] , and [ lemma : postlassomrateraw ]",
    ", we need to verify assumption [ ass : m ] .",
    "in addition , one of the conditions in these lemmas is that holds with probability @xmath456 .",
    "verification of this condition will be done with the help of lemma [ thm : choicelambda ] , which in turn relies upon condition wl .",
    "therefore , below we also verify this condition .",
    "we first verify condition wl with @xmath1005 and @xmath1006 .",
    "observe that since @xmath43 $ ] , we have for any @xmath1007 $ ] that @xmath1008 , and so @xmath90 and @xmath1009 satisfy the inequality @xmath1010 , which is the first requirement of condition wl .",
    "further , as in front of condition wl in appendix [ sec : generic results ] , let @xmath1011\\big)\\cdot x_u.\\end{aligned}\\ ] ] then @xmath1012 .",
    "in addition , since @xmath1013 , we have @xmath1014 also , since @xmath1015 , assumption [ ass : covariates](ii , iii ) yields @xmath1016 .",
    "moreover , assumption [ ass : covariates](iv ) yields @xmath1017)^{1/3}\\lesssim1 $ ] uniformly over @xmath10 and @xmath1018 $ ] .",
    "therefore , condition wl(i ) holds for some @xmath1019 satisfying @xmath1020 .",
    "assumption [ ass : covariates](i , iv ) also implies that uniformly over @xmath10 and @xmath1018 $ ] , @xmath1021 { \\leqslant}{{\\mathrm{e}}}_p[|x_{u k}|^2]\\lesssim 1\\text { and } { { \\mathrm{e}}}_p[|s_{u k}|^2 ] = { { \\mathrm{e}}}_p[|f_u x_{u k}|^2]\\gtrsim 1,\\ ] ] and so condition wl(ii ) holds for some @xmath1022 and @xmath455 depending only on the constants in assumption [ ass : covariates ] .    to verify condition wl(iii ) , we apply lemma [ primitivewl ] . observe that @xmath1023 and the class of functions @xmath1024 with @xmath1025 is vc - subgraph with index bounded by some @xmath115 .",
    "also , @xmath998 does not depend on @xmath224 , and by assumption [ ass : covariates](iv , vii , viii ) , @xmath1026\\lesssim 1 $ ] uniformly over @xmath1018 $ ] and @xmath1027)^{1/(2q)}\\lesssim ( \\delta_n n^{1/2 - 1/q})^{1/2}$ ] .",
    "moreover , by assumption [ ass : density ] , @xmath1028 = |u - u'| $ ] uniformly over @xmath205 .",
    "therefore , lemma [ primitivewl ] with @xmath1029 replacing @xmath352 implies that condition wl(iii ) holds with @xmath1030 and some @xmath1019 satisfying @xmath1031 where the last assertion follows from @xmath1032 , established above , and @xmath1033 , which holds by @xmath389 .",
    "next we verify assumption [ ass : m ] .",
    "it is well - known that the function @xmath1034 is convex almost surely , which is the first requirement of assumption [ ass : m ] .",
    "further , let us verify assumption [ ass : m](b ) . by condition wl(iii ) , which was verified above , we have with probability @xmath456 that @xmath1035| =   o(1)$ ] uniformly over @xmath68 and @xmath1018 $ ]",
    "so , it follows from ( [ ulbounds2 ] ) that with the same probability we have @xmath1036 = ( 1-o(1)){{\\mathrm{e}}}_p[s_{uk}^2]$ ] uniformly over @xmath68 and @xmath1018 $ ] , and so assumption [ ass : m](b ) holds for some @xmath924 , @xmath1037 , and @xmath1038 satisfying @xmath930 , @xmath1039 , and @xmath1040 for any @xmath1041 such that @xmath1042 { \\leqslant}{\\widehat}\\psi_{u kk}^2 \\lesssim 1\\text { with probability $ 1-o(1)$ uniformly over $ u\\in{\\mathcal{u}}$ and $ k\\in[p]$}.\\ ] ] thus , it suffices to verify . in the case",
    "@xmath1043 , we have by lemma [ lemma : cck ] and assumption [ ass : covariates](i , iv , vii , viii ) that @xmath1044 = ( 1-o(1)){{\\mathrm{e}}}[x_{u k}^2]$ ] with probability @xmath456 uniformly over @xmath10 and @xmath1018 $ ] .",
    "thus , holds since in this case , @xmath1045=\\frac{1-o(1)}{4}{{\\mathrm{e}}}_p[x_{uk}^2]\\lesssim 1\\ ] ] and @xmath1046 { \\geqslant}{{\\mathrm{e}}}[f_u^2 x_{u k}^2 ] = { { \\mathrm{e}}}[s_{u k}^2]$ ] ( recall that @xmath1047 ) with probability @xmath456 uniformly over @xmath10 and @xmath1018 $ ] .    to establish ( [ eq : loadreq ] ) for @xmath1048 , we proceed by induction . assuming that holds when the number of loops in algorithm [ algfunc ] is @xmath1049 , we can complete the proof of the theorem to show that @xmath1050 with probability @xmath456 uniformly over @xmath10 for @xmath1051 .",
    "then for @xmath1052 , we have by the triangle inequality that @xmath1053   \\big)^{1/2 } \\\\   & { \\leqslant}\\big ( \\|\\lambda(x_u'\\theta_u)-\\lambda(x_u'\\widetilde \\theta_u)\\|_{{\\mathbb{p}_n},2 } +   \\|r_u\\|_{{\\mathbb{p}_n},2}\\big)\\cdot \\max_{1{\\leqslant}i{\\leqslant}n}\\| x_{ui}\\|_\\infty   \\lesssim_p \\delta_n\\end{aligned}\\ ] ] uniformly over @xmath10 and @xmath1018 $ ] since @xmath1054 by assumption [",
    "ass : covariates](vii ) , @xmath1055 by assumption [ ass : approximation error](v ) , @xmath1056 by assumption [ ass : covariates](viii ) , and the fact that @xmath997 is @xmath1057-lipschitz ( observe that @xmath360 , and so @xmath1058 ) .",
    "thus , ( [ eq : loadreq ] ) holds with the number of loops in algorithm [ algfunc ] being @xmath1059 .",
    "this completes verification of assumption [ ass : m](b ) .    to verify assumption [ ass : m](a ) , note that for any @xmath1060 , @xmath1061 and so @xmath1062'\\delta & { \\leqslant}\\|r_u/\\sqrt{w_u}\\|_{{\\mathbb{p}_n},2}\\|\\sqrt{w_u}x_u'\\delta\\|_{{\\mathbb{p}_n},2 } \\\\   & { \\leqslant}c_n \\|\\sqrt{w_u}x_u'\\delta\\|_{{\\mathbb{p}_n},2}\\end{aligned}\\ ] ] where the first line follows from the cauchy - schwarz inequality , and the second holds with probability @xmath1063 for some @xmath1064 satisfying @xmath1065 by assumption [ ass : approximation error ] .",
    "thus , assumption [ ass : m](a ) follows for given @xmath1064 and @xmath1066 .    to verify assumption [ ass : m](c ) , note that lemma o.2 in @xcite imply that for any @xmath10 , @xmath1067 , and @xmath1068 , @xmath1069 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ] - { { \\mathbb{e}_n}}[\\partial_\\theta m_u(y_u , x_u,\\theta_u)]'\\delta \\\\ & \\qquad + 2\\|a_u/\\sqrt{w_u}\\|_{{\\mathbb{p}_n},2}\\|\\sqrt{w_u}x_u'\\delta\\|_{{\\mathbb{p}_n},2 } { \\geqslant}\\big(\\|\\sqrt{w_u}x_u'\\delta\\|_{{\\mathbb{p}_n},2}^2\\big)\\wedge\\big(\\bar q_{a_u}\\|\\sqrt{w_u}x_u'\\delta\\|_{{\\mathbb{p}_n},2}\\big)\\end{aligned}\\ ] ] where @xmath1070)^{3/2}}{{{\\mathbb{e}_n}}[w_u|x_u'\\delta|^3]}.\\ ] ] next , we bound @xmath1071 .",
    "fix some arbitrary value of @xmath998 . consider the case that @xmath1072 .",
    "then @xmath1073 , and so combining the mean - value theorem and shows that for some @xmath1074 , @xmath1075 now , since the function @xmath1076 is unimodal , @xmath1077 further , observe that @xmath1078 and @xmath1079 in addition , by assumption [ ass : approximation error ] , @xmath1080 , so that @xmath1081 .",
    "thus , @xmath1082 similarly , the same inequality can be obtained in the case that @xmath1083 .",
    "conclude that @xmath1084 with probability at least @xmath1063 uniformly over @xmath10 .",
    "therefore , assumption [ ass : m](c ) holds for any @xmath1085 with @xmath1086 , @xmath1065 and @xmath1087 defined in .",
    "next , we apply lemma [ lemma : lassomrateraw ] .",
    "we have to verify the condition on @xmath1087 required in the lemma . to do so , recall that @xmath1088 where @xmath1089 then @xmath1087 defined in equals @xmath1090 where @xmath1091 and @xmath1092 are defined similarly .",
    "to bound @xmath1091 , we have @xmath1093}^{1/2}}{\\max_{1{\\leqslant}i{\\leqslant}n}\\| x_{u i}\\|_\\infty \\|\\delta\\|_1 } \\gtrsim_p \\inf _ { \\delta \\in a_{u,1 } } \\frac{{{\\mathbb{e}_n}}{\\left[}w_{u}| x_u'\\delta|^2{\\right]}^{1/2}}{n^{1/(2q)}m_{n,2 } \\|\\delta\\|_1}\\\\ & { \\geqslant}\\inf _ { \\delta \\in a_{u,1 } } \\frac{{{\\mathbb{e}_n}}{\\left[}w_{u}| x_u'\\delta|^2{\\right]}^{1/2}}{n^{1/(2q)}m_{n,2 } ( 1 + 2\\tilde c)\\sqrt { s_n } \\|\\delta_{t_u}\\| } { \\geqslant}\\frac{\\bar \\kappa_{2\\tilde c}}{n^{1/(2q)}m_{n,2 } ( 1 + 2\\tilde c)\\sqrt { s_n}}\\end{aligned}\\ ] ] uniformly over @xmath10 by assumption [ ass : covariates](viii ) and definition of @xmath1094 . by lemma [ lemma : fse ] ,",
    "sparse eigenvalues of order @xmath1095 , for some sequence @xmath1096 , are bounded away from zero and from above so that @xmath1094 is bounded away from zero with probability @xmath456 .",
    "conclude that @xmath1097 uniformly over @xmath1098 where the second inequality holds by assumption [ ass : covariates](viii ) and the third by assumption [ ass : covariates](vi ) ( when we apply assumption [ ass : covariates](vi ) , we use the fact that @xmath1099 , which in turn follows from assumption [ ass : covariates](i ) ) . next , to bound @xmath1092 , we have @xmath1100}^{1/2}}{\\max_{1{\\leqslant}i{\\leqslant}n}\\| x_{u i}\\|_\\infty \\|\\delta\\|_1 } \\gtrsim_p \\inf _ { \\delta \\in a_{u,2 } } \\frac{{{\\mathbb{e}_n}}{\\left[}w_{u}| x_u'\\delta|^2{\\right]}^{1/2}}{n^{1/(2q)}m_{n,2 } \\|\\delta\\|_1}\\\\ & { \\geqslant}\\frac{\\lambda}{3n c_n}\\frac{\\ell c - 1}{c}\\frac{\\|\\widehat\\psi_{u0}^{-1}\\|_\\infty^{-1}}{n^{1/(2q)}m_{n,2}}\\gtrsim_p \\frac{\\lambda}{c_n n^{1 + 1/(2q)}m_{n,2}}\\end{aligned}\\ ] ] uniformly over @xmath10 since @xmath1101 with probability @xmath456 .",
    "substituting @xmath1102 and @xmath1103 gives @xmath1104 uniformly over @xmath10 .",
    "moreover , @xmath1105 since @xmath1106 with probability @xmath456 .",
    "hence , since @xmath766 , the condition on @xmath1087 required in lemma [ lemma : lassomrateraw ] is satisfied with probability @xmath456 .",
    "in addition , note that holds with probability @xmath456 by lemma [ thm : choicelambda ] . therefore , applying lemma [ lemma : lassomrateraw ] gives @xmath1107 with probability @xmath456 uniformly over @xmath10 .",
    "the second inequality in gives the second inequality in the first asserted claim of the theorem . to transform the first inequality in into the first inequality in the first asserted claim of the theorem ( and also to prove other claims ) , we apply lemma [ lemma : lassomsparsity ] .",
    "we have to verify . to do so , note that @xmath1108 by assumption [ ass : covariates](vii , viii ) and since @xmath360 .",
    "also , note that uniformly over @xmath1109 and @xmath1110 in @xmath1111 with @xmath1112 , we have @xmath1113 thus , with probability @xmath456 , @xmath1114 uniformly over @xmath1115 and @xmath1098 .",
    "also , since @xmath1116 by assumption [ ass : approximation error ] and @xmath1117 , @xmath1118 see the expression for @xmath1119 above in this proof .",
    "therefore , for some constant @xmath115 , @xmath1120 with probability @xmath1121 uniformly over @xmath10 for some @xmath1122 satisfying @xmath1123 . hence , since @xmath1124 with probability @xmath456 for some @xmath1096 sufficiently slowly by lemma [ lemma : fse ] , lemma [ lemma : lassomsparsity ] implies that @xmath1125 with probability @xmath456 , which is the second asserted claim of the theorem .    in turn , since @xmath1125 with probability @xmath456 , lemma [ lemma : fse ] also establishes that @xmath1126 with probability @xmath456 uniformly over @xmath10 , where the inequality follows from assumption [ ass : covariates](i ) . combining these inequalities with",
    "gives the first inequality in the first asserted claim of the theorem .",
    "it remains to prove the claim about the estimators @xmath435 .",
    "we apply lemma [ lemma : postlassomrateraw ] .",
    "we have to verify the condition ( [ qreq : postselection ] ) on @xmath1087 required in the lemma . to do so , we first bound @xmath1087 from below for @xmath1127 where @xmath115 is a constant such that @xmath1128 with probability @xmath456 uniformly over @xmath531 .",
    "we have @xmath1129}^{3/2}}{{{\\mathbb{e}_n}}{\\left[}w_{u}| x_u'\\delta|^3{\\right ] } } { \\geqslant}{\\displaystyle \\inf _ { \\delta \\in a_u } } \\frac{{{\\mathbb{e}_n}}{\\left[}w_{u}| x_u'\\delta|^2{\\right]}^{1/2}}{{\\displaystyle \\max_{1{\\leqslant}i{\\leqslant}n}}\\| x_{u i}\\|_\\infty \\|\\delta\\|_1 } \\\\ & { \\geqslant}{\\displaystyle \\inf _ { \\|\\delta\\|_0{\\leqslant}cs_n } } \\frac{{{\\mathbb{e}_n}}{\\left[}w_{u}| x_u'\\delta|^2{\\right]}^{1/2}}{{\\displaystyle \\max_{1{\\leqslant}i{\\leqslant}n}}\\| x_{u i}\\|_\\infty \\sqrt{cs_n}\\|\\delta\\|_2 } \\gtrsim_p\\frac{\\sqrt{{\\phi_{{\\rm min}}(cs_n , u)}}}{\\sqrt{s_n}n^{1/(2q)}m_{n,2}}\\gtrsim \\frac{\\log^{1/4}a_n}{\\delta_n^{1/2 } n^{1/4}}\\end{aligned}\\ ] ] uniformly over @xmath10 , where the inequality preceding the last one follows from assumption [ ass : covariates](vii ) and the definition of @xmath1130 , and the last one follows from assumption [ ass : covariates](viii ) and the observation that by lemma [ lemma : fse ] , @xmath1131 is bounded away from zero with probability @xmath456 uniformly over @xmath10 .",
    "next we bound from above the right - hand side of ( [ qreq : postselection ] ) .",
    "it follows by ( [ auxmuupper ] ) that uniformly over @xmath10 with probability @xmath456 , @xmath1132-   { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ] \\lesssim s_n \\log a_n / n\\ ] ] since @xmath1133 , @xmath1134 , and @xmath1135 with probability @xmath456 .",
    "furthermore , @xmath1065 and @xmath1136\\|_\\infty { \\leqslant}\\sup_{u\\in{\\mathcal{u}}}\\|\\widehat \\psi_{u0}\\|_\\infty\\|\\widehat \\psi_{u0}^{-1}{{\\mathbb{e}_n}}[s_u]\\|_\\infty \\lesssim \\lambda / n\\ ] ] with probability @xmath456 by the choice of @xmath433 ; see lemma [ thm : choicelambda ] .",
    "hence , it follows that the right - hand side of ( [ qreq : postselection ] ) is bounded up - to a constant by @xmath1137 with probability @xmath456 uniformly over @xmath10 . since @xmath1138 ( see assumption [ ass : covariates](viii ) and recall that @xmath360 ) and @xmath766 , the condition ( [ qreq : postselection ] ) on @xmath1087 required in lemma [ lemma : postlassomrateraw ] holds with probability @xmath456 uniformly over @xmath10 . hence , lemma [ lemma : postlassomrateraw ] implies that @xmath1139 with probability @xmath456 uniformly over @xmath10 . finally , as in the case of @xmath437 s",
    ", we also have @xmath1140 with probability @xmath456 uniformly over @xmath10 , which gives the last asserted claim and completes the proof of the theorem .",
    "the strategy of this proof is similar to that of theorem [ thm : rateestimatedlassologistic ] . in particular",
    ", we will rely upon results in appendix [ sec : generic results ] with @xmath25 and @xmath32 replaced by @xmath1141 $ ] and @xmath1142 , respectively , where for @xmath1143 , we set @xmath1144 , @xmath1145\\setminus j}',x')'$ ] , @xmath1146 , @xmath1147 , @xmath1148 , @xmath1149 , @xmath1150 , and @xmath1151 .",
    "note that for all @xmath1152 , we have that @xmath1153 satisfies where @xmath1154 for @xmath248 being a vector in @xmath1155 and @xmath1002 being a pair @xmath1156 of functions of @xmath29 and @xmath30 .",
    "similarly , @xmath1157 satisfies where @xmath1158 and @xmath1159 , the identically zero function of @xmath29 and @xmath30 .",
    "we first verify condition wl with @xmath1160 @xmath468 , and the following semi - metric @xmath1161 on @xmath1162 : for all @xmath1163 and @xmath1164 in @xmath1162 , @xmath1165 if @xmath1166 and @xmath1167 otherwise .",
    "observe that @xmath1168 for all @xmath585 .",
    "also , note that @xmath1169 by assumption [ ass : covariates](vi , viii ) , and so @xmath1170 since @xmath1171 by assumption [ ass : covariates](i , vii , viii )",
    ". thus , @xmath90 and @xmath1009 satisfy the inequality @xmath1172 , which is the first requirement of condition wl .",
    "next , we verify condition wl(i ) . as in front of condition",
    "wl in appendix [ sec : generic results ] , for @xmath1163 , let @xmath1173 then the inequality @xmath1174 , which holds uniformly over @xmath1175 , implies that @xmath1176)^{1/3}\\phi^{-1}(1-\\gamma/2pn_n ) \\lesssim ( { { \\mathrm{e}}}_p [ |z_u^jx^j_k|^3])^{1/3}\\log^{1/2 } a_n{\\leqslant}\\delta_n n^{1/6}\\ ] ] uniformly over @xmath1152 and @xmath1177 $ ] , where the second inequality holds by assumption [ ass : covariates](iii ) .",
    "hence , condition wl(i ) holds for some @xmath1019 satisfying @xmath1178 .    to verify condition wl(ii ) , note that by assumption [ ass : covariates](ii ) , we have @xmath1179\\gtrsim 1 $ ] and @xmath1180",
    "{ \\leqslant}{{\\mathrm{e}}}_p [ |z_u^jx^j_k|^2 ] { \\leqslant}{{\\mathrm{e}}}_p [ |z_u^j|^4 + |x^j_k|^4 ] \\lesssim 1\\ ] ] uniformly over @xmath1181 and @xmath1177 $ ] by assumption [ ass : covariates](iv ) .    to verify condition wl(iii ) , we use the decomposition @xmath1182 for @xmath1183 and @xmath1184 in @xmath1162 . by ( [ eq : f - lipshitz ] ) and ( [ eq : gamma - lipshitz ] ) we have @xmath1185 uniformly over @xmath205 and @xmath11 $ ] .",
    "therefore , uniformly over @xmath1183 and @xmath1184 in @xmath1162 such that @xmath1186 , we have @xmath1187 since @xmath1188}\\sup_{u\\in{\\mathcal{u } } } |z_{ui}^j|^2 ] { \\leqslant}n^{1/q}m_{n,1}^2 $ ] and @xmath1189}\\|x^j_i\\|_\\infty^2 ] { \\leqslant}n^{1/q}m_{n,2}^2 $ ] by assumption [ ass : covariates](v , vii ) , we have by markov s inequality that with probability @xmath456 , @xmath1190 } |{{\\mathbb{e}_n}}[s_{{{\\tilde u}}k}-s_{{{\\tilde u } } ' k}]| \\lesssim   \\delta_n n^{-1/2}.\\ ] ] in addition , uniformly over @xmath1191 with @xmath1192 and @xmath1177 $ ] , @xmath1193\\big)^{1/2}\\cdot \\big({{\\mathrm{e}}}_p[(s_{{{\\tilde u}}k}+s_{{{\\tilde u } } ' k})^2]\\big)^{1/2}\\\\ & \\lesssim \\big ( ( m_{n,1}^2 + m_{n,2}^2)(p+{{\\tilde p}})^{1/2}\\epsilon_n\\big)^{1/2}\\lesssim \\delta_n.\\end{aligned}\\ ] ] further , let @xmath1194 denote a minimal @xmath90-net for @xmath25 . using ( [ lipsf ] ) and",
    "( [ eq : extras ] ) , we obtain that with probability @xmath456 , @xmath1195 , k \\in[\\bar p ] } |({{\\mathbb{e}_n}}-{{\\mathrm{e}}}_p)[s_{u j k}^2]|   \\lesssim   \\sup_{u\\in { \\mathcal{u}}^\\epsilon } \\max_{j\\in [ { { \\tilde p } } ] , k \\in[\\bar p ] } |({{\\mathbb{e}_n}}-{{\\mathrm{e}}}_p)[s_{u j",
    "k}^2]| + \\delta_n.\\ ] ] to bound the first term on the right - hand side of this inequality , we apply lemma [ thm : rv34 ] with @xmath1196 and @xmath32 replaced by @xmath1197 and @xmath1198 , respectively , and @xmath753 , where @xmath1199 i } ) ' = - f_{u i}^2 z_{u i}^j ( x_i^j)'$ ] for @xmath1143 and @xmath1115 . with @xmath1200,k \\in[\\bar p ] } s_{u j k i}^2 \\right ] { \\leqslant}{{\\mathrm{e}}}_p\\left [ \\max_{1{\\leqslant}i{\\leqslant}n } \\sup_{u\\in{\\mathcal{u}},j\\in[{{\\tilde p } } ] } |z_{ui}^j|^2\\|x_i^j\\|_\\infty^2\\right ] \\lesssim n^{2/q}(m_{n,1}^4 + m_{n,2}^4),\\ ] ] which holds by assumption [ ass : covariates](v , vii ) , the lemma yields @xmath1201 , k \\in[\\bar p ] } \\big|({{\\mathbb{e}_n}}-{{\\mathrm{e}}}_p)[s_{u j k}^2]\\big| & \\lesssim_p n^{-1/2}n^{1/q}(m_{n,1}^2 + m_{n,2}^2 ) \\log a_n\\lesssim \\delta_n",
    "\\log^{1/2}a_n = o(1)\\end{aligned}\\ ] ] by assumption [ ass : covariates](vi ) and ( viii ) .",
    "thus , condition wl(iii ) holds with some @xmath924 and @xmath1019 satisfying @xmath930 and @xmath1202 .",
    "next , we verify assumption [ ass : m ] .",
    "the function @xmath1203 is convex almost surely , which is the first requirement of assumption [ ass : m ] .",
    "further , to verify assumption [ ass : m](a ) , note that @xmath1204'\\delta=   - \\big({\\widehat}f_u^2 \\bar r_{uj } + ( { \\widehat}f_u^2 - f_u^2)z_u^j\\big)\\cdot x^j\\delta,\\ ] ] so that by the cauchy - schwarz and triangle inequalities , since @xmath1205 , we have @xmath1206'\\delta| \\\\ & \\qquad { \\leqslant}\\big(\\|{\\widehat}f_u\\bar r_{uj}\\|_{{\\mathbb{p}_n},2}+\\|({\\widehat}f_u^2 - f_u^2)z_u^j/{\\widehat}f_u\\|_{{\\mathbb{p}_n},2}\\big)\\cdot \\|\\sqrt{w_u } x^j\\delta\\|_{{\\mathbb{p}_n},2}. \\ ] ] to bound @xmath386}\\|{\\widehat}f_u\\bar r_{uj}\\|_{{\\mathbb{p}_n},2}$ ] , note that @xmath1207 , and so lemma [ controlruj ] shows that with probability @xmath456 , @xmath822}\\|{\\widehat}f_u\\bar r_{uj}\\|_{{\\mathbb{p}_n},2 } { \\leqslant}\\sup_{u\\in{\\mathcal{u } } , j\\in[{{\\tilde p}}]}\\|\\bar r_{uj}\\|_{{\\mathbb{p}_n},2}\\lesssim ( s_n\\log a_n / n)^{1/2}.\\ ] ] also , by lemma [ controlextra ] , with probability @xmath456 , @xmath1208 } \\|({\\widehat}f_u^2 - f_u^2)z_u^j/{\\widehat}f_u\\|_{{\\mathbb{p}_n},2 } \\lesssim ( s_n\\log a_n / n)^{1/2}.\\ ] ] hence , assumption [ ass : m](a ) holds for some @xmath924 and @xmath1064 satisfying @xmath930 and @xmath1065 .    to prove assumption [ ass : m](b ) , as in appendix [ sec : generic results ] , for @xmath1209 , let @xmath1210\\})$ ] where @xmath1211)^{1/2}$ ] , @xmath1177 $ ] .",
    "note that by condition wl(ii , iii ) , which is verified above , @xmath1212 with probability @xmath456 uniformly over @xmath1152 and @xmath1177 $ ] . now , suppose that @xmath1043 ( even though algorithm [ algfunc2 ] requires @xmath1048 ) .",
    "then uniformly over @xmath10 , @xmath11 $ ] , and @xmath1177 $ ] with probability @xmath456 , @xmath1213\\big)^{1/2}\\gtrsim \\big({{\\mathbb{e}_n}}[f_u^4(d_j x_k^j)^2]\\big)^{1/2}\\gtrsim 1\\end{aligned}\\ ] ] where the second inequality follows from the observation that @xmath1214 with probability @xmath587 uniformly over @xmath1115 and @xmath10 ( see in the proof of lemma [ controlextra ] ) , and the third from the same derivations as those used to obtain condition wl(ii , iii ) . also , uniformly over @xmath10 , @xmath11 $ ] , and @xmath1177 $ ] , @xmath1215)^{1/2}\\lesssim_p n^{1/(2q)}m_{n,2}\\ ] ] by assumption [ ass : covariates](vii ) since @xmath1216 .",
    "therefore , assumption [ ass : m](b ) holds with some @xmath924 , @xmath1037 , and @xmath1038 satisfying @xmath930 , @xmath1217 , and @xmath1218 .    to establish assumption [ ass : m](b ) for @xmath1048 , which is required by algorithm [ algfunc2 ]",
    ", we proceed by induction . assuming that assumption [ ass : m](b ) holds with some @xmath924 , @xmath1037 , and @xmath1038 satisfying @xmath930 , @xmath1217 , and @xmath1218 when the number of loops in algorithm [ algfunc2 ] is @xmath1049",
    ", we can complete the proof of the theorem to show that @xmath1219 with probability @xmath456 uniformly over @xmath10 and @xmath11 $ ] for @xmath1051 .",
    "thus , by the triangle inequality , @xmath1220 with probability @xmath456 uniformly over @xmath10 and @xmath11 $ ] since @xmath1221 uniformly over @xmath10 and @xmath11 $ ] . then for @xmath1052 , we have uniformly over @xmath10 , @xmath11 $ ] , and @xmath1177 $ ] , @xmath1222   \\big)^{1/2 } - \\big ( { { \\mathbb{e}_n } } [   f_u^4 ( x_k^j)^2 ( d^j - x^j\\gamma^j_u)^2    ]   \\big)^{1/2 } \\big|\\\\   & { \\leqslant}\\big| \\big({{\\mathbb{e}_n } } [ { \\widehat}f_u^4 ( x_k^j)^2 ( x^j(\\widetilde\\gamma^j_u-\\gamma^j_u))^2    ]   \\big)^{1/2 } - \\big ( { { \\mathbb{e}_n } } [ ( { \\widehat}f_u^2 - f_u^2)^2 ( x_k^j)^2 ( d^j - x^j\\gamma^j_u)^2 ]   \\big)^{1/2 } \\big|\\\\   & \\lesssim \\big (   \\|{\\widehat}f_u x^j(\\widetilde \\gamma_u^j - \\gamma_u^j)\\|_{{\\mathbb{p}_n},2 } +   \\|({\\widehat}f_u^2 - f_u^2)z_u^j/{\\widehat}f_u\\|_{{\\mathbb{p}_n},2 } \\big)\\cdot \\max_{1{\\leqslant}i{\\leqslant}n}\\| x^j\\|_\\infty   \\\\   & \\lesssim_p n^{1/(2q)}m_{n,2}(s_n^2\\log a_n^2/n)^{1/2 } n^{1/(2q)}m_{n,2 } = n^{-1/2 + 1/q } m_{n,2}^2 s_n\\log a_n\\\\ & \\lesssim \\delta_n \\log^{1/2 } a_n = o(1 )   \\end{aligned}\\ ] ] where the second line follows from the triangle inequality and the observation that @xmath1223 , the third from @xmath1224 and @xmath1015 , the fourth from and , and the fifth from assumption [ ass : covariates](viii ) .",
    "thus , for @xmath1048 , assumption [ ass : m](b ) holds for some @xmath924 , @xmath1037 , and @xmath1038 satisfying @xmath930 , @xmath1217 , and @xmath1040 .",
    "further , assumption [ ass : m](c ) holds with @xmath1225 and @xmath1226 for any @xmath1227 since for any @xmath1143 and @xmath1228 , we have @xmath1229 - { { \\mathbb{e}_n}}[m_{{\\tilde u}}(y_{{\\tilde u}},x_{{\\tilde u}},\\theta_{{\\tilde u } } ) ] = - { { \\mathbb{e}_n}}[{\\widehat}f_u^2(d_j - x^j\\bar \\gamma_u^j)x^j\\delta ] + 2^{-1}{{\\mathbb{e}_n}}[({\\widehat}f_u x^j\\delta)^2]\\ ] ] and @xmath1230{\\geqslant}{{\\mathbb{e}_n}}[{\\widehat}f_u ( x^j\\delta)^2 ] = \\|\\sqrt{w_u}x_{{\\tilde u}}'\\delta\\|_{{\\mathbb{p}_n},2}\\ ] ] where we used @xmath1231 .",
    "we are now ready to apply lemma [ lemma : lassomrateraw ] .",
    "observe that by lemma [ thm : choicelambda ] , @xmath433 satisfies with probability @xmath456 .",
    "also , as established in in the proof of lemma [ controlextra ] , @xmath1232 with probability @xmath456 uniformly over @xmath1115 and @xmath10 .",
    "therefore , since lemma [ lemma : fse ] implies that for some @xmath1233 satisfying @xmath1096 , @xmath1234 with probability @xmath456 uniformly over @xmath1152 , it follows that @xmath1235 with probability @xmath456 .",
    "in addition , @xmath1236 and @xmath1237 with probability @xmath456 . therefore",
    ", applying lemma [ lemma : lassomrateraw ] gives @xmath1238 with probability @xmath456 uniformly over @xmath10 and @xmath11 $ ] .",
    "the second inequality in gives the second inequality in the first asserted claim of the theorem . to transform the first inequality in into the first inequality in the first asserted claim of the theorem ( and also to prove other claims ) , we apply lemma [ lemma : lassomsparsity ] .",
    "we have to verify . to do so , note that for @xmath1143 , we have @xmath1239'\\delta|{\\leqslant}|{\\widehat}f_u x^j({\\widehat}\\theta_{{\\tilde u}}-\\theta_{{\\tilde u}})|\\cdot |{\\widehat}f_ux^j\\delta|.\\ ] ] therefore , by the cauchy - schwarz inequality and since @xmath1207 , @xmath1240 with probability @xmath456 uniformly over @xmath1143 for some @xmath1122 satisfying @xmath1123 .",
    "thus , since @xmath1241 for some @xmath1096 with probability @xmath456 by lemma [ lemma : fse ] , it follows from lemma [ lemma : lassomsparsity ] that @xmath1242 with probability @xmath456 uniformly over @xmath10 and @xmath11 $ ] , which is the second asserted claim of the theorem .    in turn , with probability @xmath456 , uniformly over @xmath68 and @xmath11 $ ] , we have @xmath1243 combining these inequalities with gives the first inequality in the first asserted claim of the theorem .",
    "it remains to prove the claim about the estimators @xmath335 .",
    "we apply lemma [ lemma : postlassomrateraw ] .",
    "the condition ( [ qreq : postselection ] ) on @xmath1244 required in the lemma holds almost surely since @xmath1245 . also , it follows from ( [ auxmuupper ] ) that uniformly over @xmath10 and @xmath11 $ ] with probability @xmath456 , @xmath1246 - { { \\mathbb{e}_n}}[m_{{\\tilde u}}(y_{{\\tilde u}},x_{{\\tilde u}},\\theta_{{\\tilde u } } ) ]   \\lesssim s_n \\log a_n / n\\ ] ] since @xmath1133 , @xmath406}\\|{\\widehat}\\gamma_u^j-\\bar\\gamma_u^j\\|_1\\lesssim ( s_n^2\\log a_n / n)^{1/2}$ ] , and @xmath406 } \\|\\widehat\\psi_{uj0}\\|_\\infty\\lesssim 1 $ ] with probability @xmath456 .",
    "furthermore , @xmath1065 and @xmath1247\\|_\\infty { \\leqslant}\\sup_{{{\\tilde u}}\\in{\\widetilde{\\mathcal{u}}}}\\|\\widehat \\psi_{{{\\tilde u}}0}\\|_\\infty\\|\\widehat \\psi_{{{\\tilde u}}0}^{-1}{{\\mathbb{e}_n}}[s_{{{\\tilde u}}}]\\|_\\infty \\lesssim \\lambda / n\\ ] ] with probability @xmath456 by the choice of @xmath433 ; see lemma [ thm : choicelambda ] .",
    "in addition , uniformly over @xmath1152 with probability @xmath456 , we have @xmath1248 and @xmath1249 for arbitrarily large @xmath115 .",
    "hence , by lemma [ lemma : postlassomrateraw ] , @xmath1250 with probability @xmath456 uniformly over @xmath10 and @xmath11 $ ] . finally , as in the case of @xmath462 s , we also have @xmath1251 with probability @xmath456 uniformly over @xmath10 and @xmath11 $ ] , which gives the last asserted claim and completes the proof of the theorem .",
    "see supplementary material .",
    "10    andrews , d.w.k . ( 1994 ) .",
    "asymptotics for semiparametric econometric models via stochastic equicontinuity . , 62(1):4372 .",
    "belloni , a. , chen , d , chernozhukov , v. , and hansen , c. ( 2012 ) . sparse models and methods for optimal instruments with an application to eminent domain . , 80:23692429 .",
    "arxiv , 2010 .",
    "belloni , a. and chernozhukov , v. ( 2011 ) .",
    "@xmath66-penalized quantile regression for high dimensional sparse models . , 39(1):82130 .",
    "arxiv , 2009 .",
    "belloni , a. and chernozhukov , v. ( 2013 ) .",
    "least squares after model selection in high - dimensional sparse models . , 19(2):521547 .",
    "arxiv , 2009 .",
    "belloni , a. , chernozhukov , v. , and hansen , c. ( 2010 ) .",
    "lasso methods for gaussian instrumental variables models .",
    "arxiv , 2010 .",
    "belloni , a. , chernozhukov , v. , and hansen , c. ( 2013 ) .",
    "inference for high - dimensional sparse econometric models .",
    ", iii:245295 .",
    "arxiv , 2011 .",
    "belloni , a. , chernozhukov , v. , and hansen , c. ( 2014 ) .",
    "inference on treatment effects after selection amongst high - dimensional controls .",
    ", 81:608650 .",
    "arxiv , 2011 .",
    "belloni , a. , chernozhukov , v. , and kato , k. ( 2013 ) .",
    "robust inference in high - dimensional approximately sparse quantile regression models .",
    "arxiv , 2013 .",
    "belloni , a. , chernozhukov , v. , and kato , k. ( 2015 ) .",
    "uniform post selection inference for lad regression models and other z - estimators . , ( 102):7794 .",
    "arxiv , 2013 .",
    "belloni , a. , chernozhukov , v. , and wang , l. ( 2011 ) .",
    "square - root - lasso : pivotal recovery of sparse signals via conic programming .",
    ", 98(4):791806 .",
    "arxiv , 2010 .",
    "belloni , a. , chernozhukov , v. , fernndez - val , i. , and hansen , c. ( 2013 ) .",
    "program evaluation with high - dimensional data .",
    "arxiv , 2013 .",
    "belloni , a. , chernozhukov , v. , and wang , l. ( 2014 ) .",
    "pivotal estimation via square - root lasso in nonparametric regression . , 42(2):757788 .",
    "arxiv , 2013 .",
    "berlemann , m. , enkelmann , s. , and kuhlenkasper , t. ( 2014 ) . unraveling the relationship between presidential approval and the economy : a multidimensional semiparametric approach . .",
    "bickel , p. , ritov , y. , and tsybakov , a. ( 2009 ) .",
    "simultaneous analysis of lasso and dantzig selector .",
    ", 37(4):17051732 .",
    "arxiv , 2008 .",
    "chamberlain , g. ( 1992 ) .",
    "efficiency bounds for semiparametric regression . , 60:567596 .",
    "chernozhukov , v. , chetverikov , d. , and kato , k. ( 2013 ) .",
    "gaussian approximations and multiplier bootstrap for maxima of sums of high - dimensional random vectors .",
    ", 41(6):27862819 .",
    "arxiv , 2012 .",
    "chernozhukov , v. , chetverikov , d. , and kato , k. ( 2014 ) .",
    "anti - concentration and honest , adaptive confidence bands . , 42(5):17871818 .",
    "arxiv , 2013 .",
    "chernozhukov , v. , chetverikov , d. , and kato , k. ( 2014 ) .",
    "central limit theorems and bootstrap in high dimensions .",
    "arxiv , 2014 .",
    "chernozhukov , v. , chetverikov , d. , and kato , k. ( 2014 ) .",
    "gaussian approximation of suprema of empirical processes .",
    ", 42(4):15641597 .",
    "arxiv , 2012 .",
    "chernozhukov , v. , chetverikov , d. , and kato , k. ( 2015 ) .",
    "comparison and anti - concentration bounds for maxima of gaussian random vectors .",
    ", 162:4770 .",
    "chernozhukov , v. , chetverikov , d. , and kato , k. ( 2015 ) .",
    "empirical and multiplier bootstraps for suprema of empirical processes of increasing complexity , and related gaussian couplings .",
    "arxiv , 2015 .",
    "chernozhukov , v. , fernndez - val , i. , and melly , b. ( 2013 ) .",
    "inference on counterfactual distributions .",
    ", 81:22052268 .",
    "chernozhukov , v. , hansen , c. , and spindler , m. ( 2015 ) .",
    "post - selection and post - regularization inference in linear models with very many controls and instruments .",
    ", 105:486490 .",
    "dudley , r. ( 1999 ) .",
    ", volume  63 of _ cambridge studies in advanced mathematics_. cambridge university press , cambridge .",
    "hothorn , t. , kneib , t. , and bhlmann , p. ( 2014 ) .",
    "conditional transformation models . , 76:327 .",
    "javanmard , a. and montanari , a. ( 2014 ) .",
    "confidence intervals and hypothesis testing for high - dimensional regression . , 15:28692909 .",
    "arxiv , 2013 .",
    "javanmard , a. and montanari , a. ( 2014 ) .",
    "hypothesis testing in high - dimensional regression under the gaussian random design model : asymptotic theory .",
    ", 60:65226554 .",
    "arxiv , 2013 .",
    "jing , b .- y . ,",
    "shao , q .- m . , and wang , q. ( 2003 ) .",
    "self - normalized cramer - type large deviations for independent random variables .",
    ", 31(4):21672215 .",
    "kosorok , m. ( 2008 ) . .",
    "series in statistics .",
    "springer , berlin .",
    "ledoux , m. and talagrand , m. ( 1991 ) . .",
    "ergebnisse der mathematik undihrer grenzgebiete , springer - verlag .",
    "leeb , h. and ptscher , b. ( 2008 ) .",
    "can one estimate the unconditional distribution of post - model - selection estimators ?",
    ", 24(2):338376 .",
    "leeb , h. and ptscher , b. ( 2008 ) .",
    "recent developments in model selection and related areas .",
    ", 24(2):319322 .",
    "leeb , h. and ptscher , b. ( 2008 ) .",
    "sparse estimators and the oracle property , or the return of hodges estimator . , 142(1):201211 .",
    "linton , o. ( 1996 ) .",
    "edgeworth approximation for minpin estimators in semiparametric regression models .",
    ", 12(1):3060 .",
    "negahban , s. , ravikumar , p. , wainwright , p. , and yu , b. ( 2012 ) . a unified framework for high - dimensional analysis of m - estimators with decomposable regularizers .",
    ", 27(4):538557 .",
    "arxiv , 2010 .",
    "newey , w. ( 1990 ) .",
    "semiparametric efficiency bounds .",
    ", 5(2):99135 .",
    "newey , w. ( 1994 ) .",
    "the asymptotic variance of semiparametric estimators .",
    ", 62(6):13491382 .",
    "neyman , j. ( 1959 ) .",
    "optimal asymptotic tests of composite statistical hypotheses . .",
    "neyman , j. ( 1979 ) .",
    "@xmath720 tests and their use . , 41:121 .",
    "ning , y. and liu , h. ( 2014 ) . a general theory of hypothesis tests and confidence regions for sparse high dimensional models .",
    "arxiv , 2014 .",
    "pisier , g. ( 1999 ) . ,",
    "volume  94 .",
    "cambridge university press .",
    "ptscher , b. and leeb , h. ( 2009 ) . on the distribution of penalized maximum likelihood estimators",
    ": the lasso , scad , and thresholding . , 100(9):20652082 .",
    "robins , j. and rotnitzky , a. ( 1995 ) .",
    "semiparametric efficiency in multivariate regression models with missing data .",
    ", 90(429):122129 .",
    "rudelson , m. and vershynin , r. ( 2008 ) . on sparse reconstruction from fourier and gaussian measurements .",
    ", 61:10251045 .",
    "van  de geer , s. , bhlmann , p. , ritov , y. , and dezeure , r. ( 2014 ) . on",
    "asymptotically optimal confidence regions and tests for high - dimensional models . , 42:11661202 .",
    "arxiv , 2013 .",
    "van  der vaart , a. ( 1998 ) . .",
    "cambridge university press .",
    "van  der vaart , a. and wellner , j. ( 1996 ) . .",
    "springer series in statistics .",
    "zhang , c .-",
    "h , and zhang , s. ( 2014 ) .",
    "confidence intervals for low - dimensional parameters with high - dimensional data . , 76:217242 .",
    "arxiv , 2012 .",
    "zhao , t. , kolar , m. , and liu , h. ( 2014 ) . a general framework for robust testing and confidence regions in high - dimensional quantile regression .",
    "arxiv , 2014 .",
    "supplementary material for  uniformly valid post - regularization confidence regions for many functional parameters in @xmath721-estimation framework \"",
    "[ controlruj ] suppose that assumptions [ ass : parameters ]  [ ass : approximation error ] hold for all @xmath304 .",
    "then for @xmath1252 , we have with probability @xmath456 that @xmath662}{{\\mathbb{e}_n}}[\\bar r_{uj}^2 ] \\lesssim s_n\\log a_n / n\\ ] ] uniformly over @xmath304 .    [ controlextra ]",
    "suppose that assumptions [ ass : parameters ]  [ ass : approximation error ] hold for all @xmath304 .",
    "then with probability @xmath456 , we have @xmath1253 } \\|({\\widehat}f_u^2 - f_u^2)z_u^j/{\\widehat}f_u\\|_{{\\mathbb{p}_n},2 } \\lesssim ( s_n\\log a_n / n)^{1/2}\\ ] ] uniformly over @xmath304 .",
    "[ lemma : fse ] suppose that assumptions [ ass : parameters ]  [ ass : approximation error ] hold for all @xmath304 .",
    "then for @xmath1096 slowly enough , we have @xmath1254 uniformly over @xmath304 .      by assumption [",
    "ass : sparsity ] , we have that @xmath1255}\\|\\bar\\gamma_u^j\\|_0 { \\leqslant}s_n$ ] and @xmath1256}\\big(\\|\\bar \\gamma_u^j-\\gamma_u^j\\| + s_n^{-1/2}\\|\\bar\\gamma_u^j-\\gamma_u^j\\|_1\\big){\\leqslant}c_1(s_n\\log a_n / n)^{1/2}.\\ ] ] also , by ( [ eq : gamma - lipshitz2 ] ) , we have @xmath1257 for some constant @xmath1258 uniformly over @xmath205 . by the triangle inequality , @xmath662 } { { \\mathbb{e}_n}}[\\bar r_{uj}^2 ]",
    "{ \\leqslant}\\sup_{u\\in{\\mathcal{u}},j\\in[{{\\tilde p}}]}| ( { { \\mathbb{e}_n}}-{{\\mathrm{e}}}_p)[\\bar r_{uj}^2]| + \\sup_{u\\in{\\mathcal{u}},j\\in[{{\\tilde p}}]}{{\\mathrm{e}}}_p[\\bar r_{uj}^2].\\ ] ]    consider the class of functions @xmath1259\\}$ ] and @xmath1260 for @xmath11 $ ] and @xmath1261 $ ] being a subset of the components of @xmath1262 with @xmath1263 .",
    "since @xmath1264 for some @xmath372 , it follows that @xmath1265,|t|{\\leqslant}s_n}{\\mathcal{g}}_{j , t}$ ] .",
    "also , we have @xmath1266 for all @xmath205 , @xmath11 $ ] , and @xmath1261 $ ] . therefore , for fixed @xmath225 and @xmath565 , we have @xmath1267 where @xmath1268}\\|\\gamma_u^j\\|_1\\{p+{{\\tilde p}}\\}^{1/2}l_\\gamma \\lesssim a_n$ ] and we will set @xmath1269 .",
    "therefore , we have for the envelope @xmath1270}\\|\\bar\\gamma_u^j-\\gamma_u^j\\|_1 ^ 2)$ ] that for all @xmath199 and all finitely - discrete probability measures @xmath1271 , @xmath1272,|t|{\\leqslant}s } \\log\\left(\\epsilon \\|g\\|_{q,2 } , { \\mathcal{g}}_{j , t}^2 , \\|\\cdot\\|_{q,2}\\right)\\\\ & \\lesssim s_n\\log a_n + \\log n\\left(\\epsilon / m ,   { \\mathcal{u } } , d_{\\mathcal{u}}\\right )   \\\\ & \\lesssim   s_n\\log a_n +   \\log ( a_n/\\epsilon ) \\lesssim s_n\\log(a_n/\\epsilon).\\end{aligned}\\ ] ] by lemma [ lemma : cck ] , since @xmath1273}\\|\\bar\\gamma_u^j-\\gamma_u^j\\|_1 ^ 2\\right ) \\lesssim n^{-1 + 1/q}m_{n,2}s^2_n\\log a_n,\\ ] ] we have with probability @xmath456 that @xmath1274 } |({{\\mathbb{e}_n}}-{{\\mathrm{e}}}_p)[\\bar r_{uj}^2]| & \\lesssim \\sqrt { \\frac{s_n\\log a_n \\sup_{u\\in{\\mathcal{u}},j\\in[{{\\tilde p}}]}{{\\mathrm{e}}}_p[\\bar r_{uj}^4]}{n } } + \\frac{s_n n^{-1 + 1/q}m_{n,2}s_n^2\\log^2 a_n}{n}\\\\ & \\lesssim \\sqrt{\\frac{s_n\\log",
    "a_n}{n}}\\frac{s_n\\log a_n } { n } + \\delta_n\\frac{s_n\\log a_n}{n}\\lesssim \\frac{s_n\\log a_n}{n}\\end{aligned}\\ ] ] where we used that @xmath1275 , @xmath1276 , @xmath1277 { \\leqslant}c_1\\|\\xi\\|^4 $ ] by assumption [ ass : covariates](iv ) , @xmath1278 by assumption [ ass : sparsity ] , @xmath1279 implied by assumption [ ass : covariates](viii ) .",
    "finally , the result follows since @xmath1280 = { { \\mathrm{e}}}_p[\\{x^j(\\gamma_u^j-\\bar \\gamma_u^j)\\}^2 ] \\lesssim \\|\\gamma_u^j-\\bar\\gamma_u^j\\|^2 \\lesssim s_n\\log a_n / n$ ] by assumption [ ass : sparsity ] .",
    "recall that @xmath466 and that by theorem [ thm : rateestimatedlassologistic ] , we have @xmath1281 and @xmath1282 with probability @xmath456 . also , @xmath1283 by assumption [ ass : covariates](vii , viii ) since @xmath360 .",
    "thus , for @xmath1284 and @xmath1285 , we have with probability @xmath456 that @xmath1286}|\\tilde t_{ui}-t_{ui}|{\\leqslant}\\delta_n^{1/2 } = o(1)$ ] , and so @xmath1287 uniformly over @xmath10 and @xmath1115 as in .",
    "hence , the inequality @xmath1288 , which holds for all @xmath1289 $ ] , implies that with probability @xmath456 , latexmath:[\\[\\label{multiplicative }    since @xmath1080 by assumption [ ass : approximation error ] and @xmath1291 by the definition of @xmath1292 and since @xmath780 .",
    "therefore , with probability @xmath456 , @xmath1293 uniformly over @xmath10 and @xmath11 $ ] .",
    "hence , it suffices to show that with probability @xmath456 , @xmath662}\\|(\\widehat f_u^2 - f_u^2)z_u^j / f_u\\|_{{\\mathbb{p}_n},2}\\lesssim ( s_n\\log a_n / n)^{1/2}.\\ ] ]    next , as in ( [ eq : gamma - lipshitz ] ) , we have uniformly over @xmath205 that @xmath1294 , and so , given that @xmath1295 , we have by assumption [ ass : covariates](vii ) that @xmath1296 moreover , as in , we have uniformly over @xmath205 that @xmath1297",
    ".    further , observe that for @xmath1298 , the inequality @xmath1299 implies that @xmath1300 also , by assumptions [ ass : parameters ] , [ ass : sparsity ] , and [ ass : covariates](vii ) , @xmath1301 with probability @xmath456 uniformly over @xmath10 and @xmath1115 .",
    "thus , applying the inequality above with @xmath1302 gives @xmath1303 with probability @xmath456 uniformly over @xmath10 and @xmath1115 .",
    "so , @xmath1304\\lesssim \\exp(n^{1/(2q)}m_{n,2}\\sqrt{s_n\\log n})\\ ] ] with probability @xmath456 uniformly over @xmath10 .    in addition , let @xmath1305 and let @xmath1194 be an @xmath1306-net of @xmath25 with @xmath1307 .",
    "for all @xmath1115 , let @xmath1308 be a value of @xmath1309 such that @xmath1310 .",
    "note that @xmath1311 does not vary with @xmath224 on any interval @xmath1312\\subset{\\mathcal{u}}$ ] as long as @xmath1313 $ ] for all @xmath1115 .",
    "also , since @xmath1314 , with probability @xmath456 , each interval @xmath1315 $ ] with @xmath1316 contains at most one value of @xmath1308 s by assumption [ ass : density ] .",
    "now , @xmath1317}{{\\mathbb{e}_n}}[({\\widehat}f_u^2 - f_u^2)^2(z_u^j / f_u)^2 ] \\lesssim \\sup_{u\\in{\\mathcal{u}}^\\epsilon}\\max_{j\\in[{{\\tilde p}}]}{{\\mathbb{e}_n}}[({\\widehat}f_u^2 - f_u^2)^2(z_u^j / f_u)^2 ] \\\\ & \\qquad + \\sup_{u\\in{\\mathcal{u}},j\\in[{{\\tilde p}}]}\\inf_{u'\\in{\\mathcal{u}}^\\epsilon}\\big|{{\\mathbb{e}_n}}[({\\widehat}f_u^2 - f_u^2)^2(z_u^j / f_u)^2-({\\widehat}f_{u'}^2 - f_{u'}^2)^2(z_{u'}^j / f_{u'})^2]\\big| ,   \\end{aligned}\\ ] ] and uniformly over @xmath11 $ ] and @xmath1318 such that @xmath1319 , we have with probability @xmath456 that @xmath1320\\big|   \\\\ & \\quad { \\leqslant}\\big|{{\\mathbb{e}_n}}[\\{({\\widehat}f_u^2 - f_u^2)^2-({\\widehat}f_{u'}^2 - f_{u'}^2)^2\\}(z_u^j / f_u)^2]\\big|+\\big|{{\\mathbb{e}_n}}[({\\widehat}f_{u'}^2 - f_{u'}^2)^2\\{(z_u^j / f_u)^2-(z_{u'}^j / f_{u'})^2\\}]\\big|\\\\ & \\quad \\lesssim \\big|{{\\mathbb{e}_n}}[\\{(f_{u'}^2 - f_u^2)(z_u^j / f_u)^2]\\big|+\\big|{{\\mathbb{e}_n } } [ f_{u'}^4\\{(z_u^j / f_u)^2-(z_{u'}^j / f_{u'})^2\\}]\\big|\\\\ & \\quad\\lesssim |u'-u|{{\\mathbb{e}_n}}[(z_u^j / f_u)^2]+\\big|{{\\mathbb{e}_n } } [ ( f_{u'}^4/f_u^2)|\\{z_u^j - z_{u'}^j\\}\\{z_u^j+z_{u'}^j\\}|]\\big|+\\big|{{\\mathbb{e}_n } } [ ( f_{u'}^2/f_u^2)(z_{u'}^j)^2(f_{u'}^2-f_u^2)]\\big|\\\\ & \\quad\\lesssim_p |u'-u|\\cdot\\big(n^{1/q}m_{n,1}^2+n^{1/(2q)}m_{n,2}(p+{{\\tilde p}})^{1/2}n^{1/(2q)}m_{n,1}\\big)\\cdot{{\\mathbb{e}_n}}[f_u^{-2}].\\end{aligned}\\ ] ] thus , by the choice of @xmath1306 , and since with probability @xmath456 each interval @xmath1315 $ ] with @xmath1316 contains at most one value of @xmath1308 s , we have with probability @xmath1121 that @xmath662}\\inf_{u'\\in{\\mathcal{u}}^\\epsilon}\\big|{{\\mathbb{e}_n}}[({\\widehat}f_u^2 - f_u^2)^2(z_u^j / f_u)^2-({\\widehat}f_{u'}^2 - f_{u'}^2)^2(z_{u'}^j / f_{u'})^2]\\big| \\lesssim s_n\\log a_n / n.\\ ] ] further by ( [ multiplicative ] ) and , with probability @xmath456 , @xmath1321}{{\\mathbb{e}_n}}[({\\widehat}f_u^2 - f_u^2)^2(z_u^j / f_u)^2 ]   & \\lesssim \\sup_{u\\in{\\mathcal{u}}^\\epsilon , j\\in[{{\\tilde p}}]}{{\\mathbb{e}_n } } [ \\lambda'(t_{ui})^2|\\tilde t_{ui}-t_{ui}|^2(z_u^j / f_u)^2]\\\\ & \\quad + \\sup_{u\\in{\\mathcal{u}}^\\epsilon , j\\in[{{\\tilde p}}]}{{\\mathbb{e}_n}}[r_u^2(z_u^j / f_u)^2]\\\\ & \\lesssim \\max_{j\\in [ { { \\tilde p}}]}\\sup_{u\\in{\\mathcal{u}}^\\epsilon,\\|\\delta\\|_0{\\leqslant}cs_n , \\|\\delta\\|=1 } { { \\mathbb{e}_n}}[\\{(d',x')\\delta\\}^2(z^j_u)^2 ] s_n\\log a_n / n \\\\ & \\quad +   s_n\\log a_n / n   \\end{aligned}\\ ] ] for @xmath115 large enough , where we used that @xmath1322 \\lesssim s_n\\log a_n / n$ ] with probability @xmath456 by assumption [ ass : approximation error ] , and @xmath1281 and @xmath1323 with probability @xmath456 .",
    "therefore , since @xmath1324{\\leqslant}{{\\mathrm{e}}}_p[\\{(d',x')\\delta\\}^4]^{1/2}{{\\mathrm{e}}}_p[(z^j_u)^4]^{1/2 } \\lesssim 1,\\ ] ] to establish the statement of the lemma it suffices to show that with probability @xmath456 , @xmath1325}\\sup_{u\\in{\\mathcal{u}}^\\epsilon,\\|\\delta\\|_0{\\leqslant}cs_n , \\|\\delta\\|=1 } |({{\\mathbb{e}_n}}-{{\\mathrm{e}}}_p)[\\{(d',x')\\delta\\}^2(z^j_u)^2]| \\lesssim 1.\\ ] ] to do so , we will apply lemma [ thm : rv34 ] with @xmath25 replaced by @xmath1326 $ ] and @xmath1327 replaced by @xmath1328 .",
    "we have @xmath1329\\big)^{1/2 } { \\leqslant}n^{1/q } \\big({{\\mathrm{e}}}_p\\big[\\max_{u\\in{\\mathcal{u}}^\\epsilon}\\|z_u^j ( d',x')'\\|_\\infty^{q}\\big]\\big)^{1/q}\\\\   & { \\leqslant}n^{1/q } \\big({{\\mathrm{e}}}_p[\\|(d',x')'\\|_\\infty^{2q}]{{\\mathrm{e}}}_p[\\|z_u^j\\|_\\infty^{2q}]\\big)^{1/(2q ) } { \\leqslant}n^{1/q}m_{n,2}m_{n,1}\\end{aligned}\\ ] ] by assumption [ ass : covariates](v , vii ) .",
    "also , @xmath1330 } { { \\mathrm{e}}}_p [ ( z_u^j(d',x')\\delta)^2 ] \\lesssim 1\\ ] ] by assumption [ ass : covariates](iv ) . then ,",
    "by lemma [ thm : rv34 ] we have for @xmath1331 that @xmath1330}|({{\\mathbb{e}_n}}-{{\\mathrm{e}}}_p)[(z_u^j(d',x')\\delta)^2]| \\lesssim_p    \\tilde \\delta_n^2 + \\tilde\\delta_n.\\ ] ] now , @xmath1332 so that @xmath1333 using assumption [ ass : covariates](vi , viii , ix ) and since @xmath389 , we have @xmath1334 and so @xmath1335 this completes the proof .      both results follow from lemma [ thm : rv34 ] .",
    "we provide a proof only for the first result ( the second result is simpler and follows similarly ) .",
    "recall that by assumption [ ass : covariates](i ) , @xmath1336 also , observe that for any @xmath1289 $ ] , we have @xmath1337 therefore , since @xmath1338(1 - { { \\mathrm{e}}}[y_u\\mid d , x])$ ] , by assumption [ ass : density ] , for any @xmath205 , we have @xmath1339|\\big)^{1/2 } { \\leqslant}\\big(c_1|u ' - u|\\big)^{1/2}.\\ ] ] hence , since @xmath1096 , with probability @xmath1121 uniformly over @xmath205 and @xmath1340 with @xmath1341 and @xmath1342 , we have @xmath1343 by assumption [ ass : covariates](vii ) .",
    "thus , for @xmath1344 we have with probability @xmath456 that @xmath1345    now , let @xmath1194 be an @xmath1306-net of @xmath25 such that @xmath1346",
    ". we will apply lemma [ thm : rv34 ] with @xmath25 replaced by @xmath1194 , @xmath1347 , and @xmath998 replaced by @xmath1348 . since @xmath1349",
    ", we have @xmath1350\\big)^{1/2 } { \\leqslant}\\big({{\\mathrm{e}}}_p\\big[\\max_{1{\\leqslant}i{\\leqslant}n}\\|(d_i',x_i')'\\|_\\infty^2\\big]\\big)^{1/2}{\\leqslant}n^{1/(2q)}m_{n,2}\\end{aligned}\\ ] ] by assumption [ ass : covariates](vii ) . also , @xmath1351 { \\leqslant}\\sup_{\\|\\delta\\|_0{\\leqslant}\\ell_n s_n , \\|\\delta\\|=1 } { { \\mathrm{e}}}_p[\\{(d',x')\\delta\\}^2 ] { \\leqslant}\\sqrt{c_1}\\ ] ] by assumption [ ass : covariates](iv ) .",
    "thus , applying lemma [ thm : rv34 ] gives @xmath1352|   \\lesssim_p    \\tilde \\delta_n^2 + \\tilde \\delta_n\\ ] ] where @xmath1353 finally , by assumption [ ass : covariates](viii ) , @xmath1354 since @xmath1355 slowly enough and @xmath1032 by assumption [ ass : covariates](ii , iii ) . combining presented bounds gives the asserted claim",
    "for @xmath1356 , let @xmath1357 . also , for @xmath1358 , let @xmath1359 and @xmath1360 . by symmetrization inequality , lemma 6.3 in @xcite , we have @xmath1361 { \\right]}\\right|\\right ] { \\leqslant}2 { { \\mathrm{e}}}\\left [ { { \\mathrm{e}}}\\left [ \\sup_{(\\theta , u)\\in \\mathcal{t } } \\left| \\sum_{i=1}^n \\varepsilon_i(\\theta'x_{ui})^2\\right| \\mid x\\right]\\right]\\ ] ] where @xmath1362 and @xmath1363 is a sequence of independent rademacher random variables that are independent of @xmath30 .",
    "a consequence of lemma 4.5 in @xcite ( see equation ( 4.8 ) ) gives @xmath1364 { \\leqslant}(\\pi/2)^{1/2 } { { \\mathrm{e}}}\\left [ \\sup_{(\\theta , u)\\in \\mathcal{t } } \\left| \\sum_{i=1}^n g_i(\\theta'x_{ui})^2\\right| \\mid x\\right]\\ ] ] where @xmath1365 is a sequence of independent standard normal random variables that are independent of @xmath30 . in turn",
    ", an application of dudley s integral gives @xmath1366 { \\leqslant}8 \\int_0^{\\rm diam(\\mathcal{t})}\\log^{1/2}n(\\mathcal{t},d,\\epsilon)d\\epsilon\\ ] ] where @xmath1367 using that @xmath1368 , and @xmath1369 is the corresponding gaussian semi - metric .",
    "furthermore , we have @xmath1370 , so that @xmath1371 now , for any @xmath1372 and @xmath1373 in @xmath1374 , we have @xmath1375 where we let @xmath1376 .",
    "this implies that @xmath1377 therefore , since @xmath1378 , we have @xmath1379 note that @xmath1380 and @xmath1381 where @xmath1382 and @xmath1383 .",
    "it follows from lemma 3.9 in @xcite that @xmath1384 for all @xmath585 and some universal constant @xmath1385 .",
    "moreover , as in the discussion after lemma 3.9 in @xcite , we have @xmath1386 for all @xmath585 and all @xmath1356 with @xmath1387 , so that @xmath1388 for all @xmath585 .",
    "therefore , @xmath1389 up - to a universal constant where in the third inequality , we used the fact that integrating by parts gives @xmath1390 collecting the terms , we obtain @xmath1391    therefore , since @xmath1392)^{1/2}$ ] , setting @xmath1393 gives @xmath1394 { \\right]}\\right|\\right]\\\\    & \\lesssim \\frac{\\delta_n{{\\mathrm{e}}}[m r]}{k \\sqrt n } { \\leqslant}(\\delta_n / k ) ( { { \\mathrm{e}}}[m^2])^{1/2 } ( { { \\mathrm{e}}}[r^2/n])^{1/2}{\\leqslant}\\delta_n ( e[r^2/n])^{1/2}\\\\ & \\lesssim   \\delta_n \\big(i_2 + \\sup_{\\|\\theta\\|_0{\\leqslant}k , \\|\\theta\\| = 1 , u\\in { \\mathcal{u } } } { { \\mathbb{e}_n}}{{\\mathrm{e}}}[(\\theta'x_{u})^2]\\big)^{1/2}.\\end{aligned}\\ ] ] thus , because @xmath1395 implies @xmath1396 , we have @xmath1397}\\ ] ] up - to an absolute constant .",
    "this completes the proof .",
    "in this section we discuss in details and provide formal results for the double selection estimator for logistic regression with functional response data .",
    "( based on double selection ) for each @xmath68 and @xmath11 $ ] : + _ step 1_. run post-@xmath66-penalized logistic estimator ( [ postl1logistic ] ) of @xmath342 on @xmath29 and @xmath30 to compute @xmath343 .",
    "+ _ step 2_. define the weights @xmath420 . + _",
    "step 3_. run the lasso estimator ( [ estlasso ] ) of @xmath345 on @xmath422 to compute @xmath338 .",
    "+ _ step 4_. run logistic regression of @xmath342 on @xmath424 and all the selected variables in steps 1 and 2 + to compute @xmath425 .",
    "the following result establishes the bahadur representation for the double selection estimator ( analog to theorem 3.1 for score functions ) .",
    "[ theorem : inferencealg2 ] suppose that assumptions [ ass : parameters ]  [ ass : approximation error ] hold for all @xmath304 .",
    "then , the estimator @xmath390}$ ] , based on the double selection , obeys as @xmath1398 @xmath1399)\\ ] ] uniformly over @xmath10 , where @xmath1400^{-1}$ ] .",
    "the analysis is reduced to the proof of theorem [ theorem : inferencealg1 ] .",
    "let @xmath1401 for which by theorems [ thm : rateestimatedlassologistic ] and [ thm : rateestimatedlassolinear ] satisfies @xmath406}|{\\widehat}t_{uj}|\\lesssim s_n$ ] with probability @xmath456 .",
    "therefore step 3 is a post - selection logistic regression which yields an initial rate of convergence @xmath1402\\setminus j}-\\theta_{u[{{\\tilde p}}]\\setminus j } \\| + \\|\\bar\\beta_u-\\beta_u\\| \\lesssim ( s_n\\log a_n / n)^{1/2}$ ] .",
    "moreover , by the first order condition of step 3 we have @xmath1403\\setminus j}'\\bar\\theta_{u[{{\\tilde p}}]\\setminus j}+x'\\bar \\beta_u)\\ } ( d_j , x^j_{{\\widehat}t_{uj}})']=0\\ ] ] so that any linear combination yields zero . by setting the parameters",
    "@xmath1404\\setminus j},\\bar\\theta_{u[{{\\tilde p}}]\\setminus j}',\\bar\\beta_u')$ ] , and @xmath1405 , we recover the setting in the proof of theorem [ theorem : inferencealg1 ] .",
    "the rest of the proof follows similarly .",
    "the double selection procedure benefits from additional variables selected in step 2 .",
    "the ( estimated ) weights used in the equation ensure that selection will ensure a near orthogonality condition that is required to remove first order bias .",
    "in contrast , ( naive ) post-@xmath66-logistic regression does not select such variables which in turn translates in to first order bias in the estimation of @xmath75 .",
    "we stress that step 2 is tailored to the estimation of each coefficient @xmath75 which enables the additional adaptivity .",
    "the double selection achieves orthogonality conditions relative to all selected variables in finite samples .",
    "although first - order equivalent to other estimator discussed here , this additional orthogonality could potentially lead to a better finite sample performance . to provide intuition why , consider the logistic regression case with @xmath1406 and @xmath1407 for simplicity . in this case",
    "we have @xmath1408 = \\lambda(d\\theta_0 + x'\\beta_0 ) \\",
    "\\ \\mbox{and let } \\",
    "\\ f = \\lambda'(d\\theta_0 + x'\\beta_0).\\ ] ] letting @xmath1409 be the lasso estimate of @xmath1410 on @xmath1411 we have that the one step estimator @xmath1412^{-1}{{\\mathbb{e}_n}}[\\{y - \\lambda(d{\\widehat}\\theta + x'{\\widehat}\\beta))\\}(d - x'{\\widehat}\\gamma)]\\ ] ] is an approximate solution for the moment condition @xmath1413 = 0.\\ ] ] indeed , it is one newton step from @xmath1414 .",
    "our proposed estimator based on estimated score functions defines @xmath1415 as an exact solution for ( [ newmoment ] ) , namely @xmath1416 = 0.\\ ] ] the double selection achieves that implicitly .",
    "indeed , letting @xmath1417 , the first order condition of running a logistic regression of @xmath28 on @xmath29 and @xmath1418 yields @xmath1419 = 0\\ ] ] where @xmath1420 is the solution of the logistic regression . by multiplying the vector @xmath1421",
    ", the relation above implies @xmath1422 = 0.\\ ] ] since @xmath1423 ( the condition @xmath1424 ensures that @xmath1425 is a good approximation of @xmath35 ) . note that ( [ foc ] ) provides a more robust orthogonality condition and does not need to explicitly create the new score functions as the other two methods",
    "in this section , we establish a set of results for @xmath66-penalized m - estimators with functional data and high - dimensional parameters .",
    "these results are used in the proofs of theorems [ thm : rateestimatedlassologistic ] and [ thm : rateestimatedlassolinear ] and may be of independent interest .",
    "we start with specifying the setting .",
    "consider a data generating process with a functional response variable @xmath290 and observable covariates @xmath1426 satisfying for each @xmath1427 , @xmath1428,\\ ] ] where @xmath330 is a @xmath32-dimensional vector of parameters , @xmath999 is a nuisance parameter that captures potential misspecification of the model , and @xmath1429 is a known function . here for all @xmath10 , @xmath296 is a scalar random variable and @xmath998 is a @xmath1430-dimensional random vector with @xmath1431 for some @xmath32 .",
    "we assume that the solution @xmath330 is sparse in the sense that the process @xmath1432 satisfies @xmath1433 because the model ( [ a : eqmainfunc ] ) allows for the nuisance parameter @xmath999 , such sparsity assumption is very mild and formulation ( [ a : eqmainfunc ] ) encompasses many cases of interest including approximately sparse models .    throughout this section , we assume that @xmath1 i.i.d .",
    "observations , @xmath1434 , from the distribution of @xmath1435 are available to estimate @xmath1436 . in addition , we assume that an estimate @xmath1437 of the nuisance parameter @xmath999 is available for all @xmath10 . using the estimate @xmath1437 , we use the criterion function @xmath1438 as a proxy for @xmath1439 .",
    "we allow for the case where @xmath32 is much larger than @xmath1 .",
    "since @xmath32 is potentially larger @xmath1 , and the parameters @xmath330 are assumed to be sparse , we consider an @xmath66-penalized @xmath1429-estimator ( lasso ) of @xmath330 : @xmath1440 + \\frac{\\lambda}{n}\\|{\\widehat}\\psi_u\\theta\\|_1\\right)\\ ] ] where @xmath433 is a penalty level and @xmath1041 a diagonal matrix of penalty loadings .",
    "further , for each @xmath523 , we also consider a post - regularized ( post - lasso ) estimator of @xmath330 : @xmath1441 \\ \\ : \\ \\ { \\mathrm{supp}}(\\theta)\\subseteq \\widehat t_u\\ ] ] where @xmath1442 .",
    "we assume that for each @xmath10 , the matrix of penalty loadings @xmath1041 is chosen as an appropriate estimator of the following `` ideal '' matrix of penalty loadings : @xmath1443 , where @xmath1444\\big)^{1/2},\\ ] ] and @xmath1445 denotes a sub - gradient of the function @xmath1446 with respect to the @xmath538th coordinate of @xmath248 and evaluated at @xmath1447 .",
    "the properties of @xmath1041 will be specified below in lemmas .",
    "also , we assume that the penalty level @xmath433 is chosen such that with high probability , @xmath1448 \\right\\|_\\infty,\\]]where @xmath1449 is a fixed constant . when @xmath1450 is a singleton , the condition is similar to that in @xcite , @xcite , and @xcite .",
    "when @xmath25 is a continuum of indices , a similar condition was previously used in @xcite in the context of @xmath66-penalized quantile regression",
    ". for @xmath10 , denote @xmath1451 .",
    "let @xmath1037 and @xmath1038 be some constants satisfying @xmath1452 .",
    "also , let @xmath1453 where for any diagonal matrix @xmath1454 , we denote @xmath1455 .",
    "let @xmath137 be a sequence of positive constants converging to zero , and let @xmath1456 be a sequence of random variables .",
    "also , let @xmath1457 be some weights satisfying @xmath1458 almost surely .",
    "finally , let @xmath1459 be some random subset of @xmath1001 and @xmath1087 be a random variable possibly depending on @xmath1459 , where both @xmath1459 and @xmath1087 are specified in the lemmas below . to state our results in this section , we need the following assumption :    [ ass : m ] the function @xmath1460 is convex almost surely , and with probability at least @xmath197 , the following inequalities hold for all @xmath10 :    * @xmath1461'\\delta|{\\leqslant}c_n\\|\\sqrt{w_{u } } x_u'\\delta\\|_{{\\mathbb{p}_n},2}$ ] for all @xmath1060 ; * @xmath1462 ; * for all @xmath1463",
    ", @xmath1464 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ] -{{\\mathbb{e}_n}}[\\partial_{\\theta } m_u(y_u , x_u,\\theta_u)]'\\delta + 2c_n\\|\\sqrt{w_{u } } x_u'\\delta\\|_{{\\mathbb{p}_n},2 } \\\\ & \\qquad { \\geqslant}\\left\\{\\|\\sqrt{w_{u } } x_u'\\delta\\|_{{\\mathbb{p}_n},2}^2\\right\\ } \\wedge \\left\\ { \\bar q_{a_u}\\|\\sqrt{w_{u } } x_u'\\delta\\|_{{\\mathbb{p}_n},2}\\right\\}.\\end{aligned}\\ ] ]    in many applications one can take the weights to be @xmath1465 but we allow for more general weights since it is useful for our results on the weighted lasso with estimated weights .",
    "also , in applications , we typically have @xmath1466 .",
    "assumption [ ass : m](a ) bounds the impact of estimating the nuisance functions uniformly over @xmath10 .",
    "the loadings @xmath1041 are assumed larger ( but not too much larger ) than the ideal choice @xmath1467 defined in ( [ idealloading ] ) .",
    "this is formalized in assumption [ ass : m](b ) .",
    "assumption [ ass : m](c ) is an identification condition that will be imposed for particular choices of @xmath1459 and @xmath1087 .",
    "it relates to conditions in the literature derived for the case of a singleton @xmath25 and no nuisance functions , see the restricted strong convexity ( a ) and ( c ) could have been stated with @xmath1468 instead of @xmath1469 . ]",
    "used in @xcite and the non - linear impact coefficients used in @xcite and @xcite .",
    "define the restricted eigenvalue @xmath1470 where @xmath1471 . also , define minimum and maximum spare eigenvalues @xmath1472 the following results establish the rate of convergence and a sparsity bound for the @xmath66-penalized estimator @xmath430 defined in ( [ adef : lassofunc ] ) as well as the rate of convergence for the post - regularized estimator @xmath435 defined in ( [ adef : postfunc ] ) .",
    "[ lemma : lassomrateraw ] suppose that assumption [ ass : m ] holds with @xmath1473 and @xmath1474 .",
    "in addition , suppose that @xmath433 satisfies condition ( [ eq : reg ] ) with probability @xmath197 . then , with probability at least @xmath1475 , we have for all @xmath10 that @xmath1476    [ lemma : lassomsparsity ] in addition to conditions of lemma [ lemma : lassomrateraw ] , suppose that with probability @xmath197 , we have for some random variable @xmath1122 and all @xmath10 and @xmath1477 that @xmath1478\\}'\\delta\\big| { \\leqslant}l_n\\|x_u'\\delta\\|_{{\\mathbb{p}_n},2}.\\ ] ] further , for all @xmath10 , let @xmath1479 . then with probability at least @xmath1480 , we have for all @xmath10 that @xmath1481 where @xmath1482 and @xmath1483 .",
    "[ lemma : postlassomrateraw ] suppose that assumption [ ass : m ] holds with @xmath1484 and @xmath1485 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u)]\\big)_+^{1/2},\\notag\\\\ & \\quad \\big ( \\frac{\\sqrt{\\widehat s_u+s_u}\\|{{\\mathbb{e}_n}}[\\partial_\\theta m_u(y_u , x_u,\\theta_u , a_u)]\\|_\\infty}{\\sqrt{{\\phi_{{\\rm min}}(\\widehat s_u+s_u , u ) } } } + 3c_n\\big)\\bigg\\}.\\label{qreq : postselection}\\end{aligned}\\ ] ] then with probability at least @xmath1486 , we have for all @xmath10 that @xmath1487 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u)]\\big)_+^{1/2 } \\\\ & \\quad +   \\frac{\\sqrt{\\widehat s_u+s_u}\\|{{\\mathbb{e}_n}}[\\partial_\\theta m_u(y_u , x_u,\\theta_u , a_u)]\\|_\\infty}{\\sqrt{{\\phi_{{\\rm min}}(\\widehat s_u+s_u , u ) } } } + 3c_n.\\end{aligned}\\ ] ] in addition , with probability at least @xmath197 , we have for all @xmath10 that @xmath1132 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ]   { \\leqslant}\\frac{\\lambda l}{n }   \\|{\\widehat}\\theta_u - \\theta_u\\|_1\\sup_{u\\in{\\mathcal{u}}}\\|\\widehat \\psi_{u0}\\|_\\infty\\label{auxmuupper}.\\ ] ]    a key requirement in lemmas [ lemma : lassomrateraw ] and [ lemma : lassomsparsity ] is that @xmath433 satisfies ( [ eq : reg ] ) with high probability .",
    "therefore , below we provide a choice of @xmath433 and a set of conditions under which the proposed choice of @xmath433 satisfies this requirement .",
    "let @xmath1488 denote a metric on @xmath1489 .",
    "also , let @xmath1490 moreover , let @xmath1022 and @xmath455 be some strictly positive constants .",
    "finally , @xmath1491 , @xmath1492 , and @xmath1493 be some sequences of positive constants , where @xmath1202 .",
    "* condition wl . * _ the constants @xmath90 and @xmath1009 satisfy the inequality @xmath1494 and the following conditions hold : + ( i ) @xmath1495 } } ( { { \\mathrm{e}}}_p[|s_{uk}|^3])^{1/3}\\phi^{-1}(1-\\gamma/\\{2p n_n\\ } ) { \\leqslant}\\varphi_n n^{1/6}$ ] ; + ( ii ) @xmath1496 { \\leqslant}\\bar c$ ] , for all @xmath68 and @xmath1018 $ ] ; + ( iii ) with probability at least @xmath197 , @xmath1497\\|_\\infty{\\leqslant}\\varphi_n n^{-1/2},\\text { and } { \\displaystyle \\sup_{d_\\mathcal{u}(u , u'){\\leqslant}\\epsilon_n }   \\max_{k\\in [ p ] } } \\big||{{\\mathrm{e}}}_p[s_{uk}^2-s_{u'k}^2]| + |({{\\mathbb{e}_n}}-{{\\mathrm{e}}}_p)[s_{uk}^2]|\\big|{\\leqslant}\\varphi_n.\\ ] ] _    let @xmath1498 where @xmath1499 ( with @xmath1500 ) is a confidence level associated with the probability of event ( [ eq : reg ] ) , and @xmath1501 is a slack constant .",
    "the following lemma shows that this choice of @xmath433 satisfies with high probability under condition wl .",
    "[ thm : choicelambda ] suppose that condition wl holds .",
    "in addition , suppose that @xmath433 satisfies for some @xmath1501 and @xmath1502 $ ] .",
    "then @xmath1503\\|_\\infty \\right ) { \\geqslant}1-\\gamma - o(\\gamma)-\\delta_n.\\ ] ]    condition wl(iii ) is of high level .",
    "therefore , to conclude this section , we present a lemma that gives easy to verify conditions that imply condition wl(iii ) .",
    "[ primitivewl ] suppose that for all @xmath10 , @xmath1504 and @xmath1505 where @xmath28 is a random variable and @xmath1024 is a vc - subgraph class of functions bounded by one with index @xmath1506 for some constant @xmath1507 .",
    "in addition , suppose that for all @xmath10 , we have @xmath1508)\\cdot x$ ] .",
    "moreover , suppose that @xmath1509}{{\\mathrm{e}}}_p[x_k^4 ] { \\leqslant}\\bar c$ ] , @xmath1510 } { { \\mathrm{e}}}_p[s_{uk}^2 ] { \\leqslant}\\bar c$ ] , and @xmath1511^{1/q } { \\leqslant}k_n$ ] , for some constants @xmath1512 and @xmath1513 and a sequence of constants @xmath141 .",
    "finally , suppose that @xmath1514{\\leqslant}c_u|u - u'|^\\nu$ ] for any @xmath1515 and some constants @xmath1516 and @xmath115 .",
    "then we have with probability at least @xmath1517 that @xmath1518\\|_\\infty \\lesssim \\big(\\frac{\\log ( n p k_n)}{n^{1 + \\nu/2}}\\big)^{1/2 } + \\frac{k_n\\log ( n p k_n)}{n^{1 - 1/q}}\\label{eq : prim ver 1}\\\\ &    \\sup_{u\\in\\mathcal{u}}\\max_{k\\in p}|({{\\mathbb{e}_n}}-{{\\mathrm{e}}}_p)[s_{u k}^2]|   \\lesssim \\big(\\frac { \\log ( n p k_n)}{n}\\big)^{1/2 }   + \\frac{k_n^2\\log(n p k_n)}{n^{1 - 2/q}}\\label{eq : prim ver 2}\\\\ &   \\max_{k\\in[p]}|{{\\mathrm{e}}}_p[s_{u k}^2-s_{u ' k}^2]|   \\lesssim d_{\\mathcal{u}}(u , u')^{\\nu/4}\\label{eq : prim ver 3}\\end{aligned}\\ ] ] up - to constants that depend only on @xmath1519 , @xmath352 , and @xmath1516 .",
    "for @xmath10 , let @xmath1520 and @xmath1521 $ ] . throughout the proof",
    ", we will assume that the events ( a ) , ( b ) , and ( c ) in assumption [ ass : m ] as well as the event hold .",
    "these events hold with probability at least @xmath1475 .",
    "we will show that the inequalities in the statement of lemma [ lemma : lassomrateraw ] hold under these events .    by definition of @xmath336 , we have @xmath1522 + \\frac{\\lambda}{n}\\|\\widehat\\psi_u{\\widehat}\\theta_u\\|_1   { \\leqslant}{{\\mathbb{e}_n}}[m_u(y_u , x_u , \\theta_u ) ] + \\frac{\\lambda}{n}\\|\\widehat\\psi_u\\theta_u\\|_1 $ ] .",
    "thus , @xmath1523 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ] & { \\leqslant}\\frac{\\lambda}{n}\\|\\widehat\\psi_u\\theta_u\\|_1 - \\frac{\\lambda}{n}\\|\\widehat\\psi_u{\\widehat}\\theta_u\\|_1\\notag \\\\ & { \\leqslant}\\frac{\\lambda}{n}\\|\\widehat\\psi_u\\delta_{u , t_u}\\|_1 - \\frac{\\lambda}{n } \\|\\widehat\\psi_u\\delta_{u , t_u^c}\\|_1 \\notag\\\\ & { \\leqslant}\\frac{\\lambda l}{n}\\|\\widehat\\psi_{u0}\\delta_{u , t_u}\\|_1 - \\frac{\\lambda \\ell}{n } \\|\\widehat\\psi_{u0}\\delta_{u , t_u^c}\\|_1.\\label{qq : upperbound}\\end{aligned}\\ ] ] moreover , by convexity of @xmath1524 , we have @xmath1525 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ]   & { \\geqslant}{{\\mathbb{e}_n}}[\\partial_{\\theta } m_u(y_u , x_u,\\theta_u)]'\\delta_u \\\\ & { \\geqslant}-\\frac{\\lambda}{n}\\frac{1}{c}\\|\\widehat\\psi_{u0}\\delta_{u}\\|_1 -c_n\\|\\sqrt{w_{u } } x_u'\\delta_u\\|_{{\\mathbb{p}_n},2}\\notag\\end{aligned}\\ ] ] where the second inequality holds by assumption [ ass : m](a ) and @xmath1526 since @xmath1527-s_{u , n}\\}'\\delta_u| \\nonumber \\\\   & { \\leqslant}|s_{u , n}'\\delta_u| + |\\{{{\\mathbb{e}_n}}[\\partial_{\\theta } m_u(y_u , x_u,\\theta_u)]-s_{u , n}\\}'\\delta_u|   \\nonumber \\\\ & { \\leqslant}\\|\\widehat\\psi_{u0}^{-1}s_{u , n } \\|_\\infty \\|\\widehat\\psi_{u0}\\delta_u\\|_1 + c_n\\|\\sqrt{w_{u } }   x_u'\\delta_u\\|_{{\\mathbb{p}_n},2 } \\nonumber \\\\ & { \\leqslant}\\frac{\\lambda}{n}\\frac{1}{c}\\|\\widehat\\psi_{u0}\\delta_{u}\\|_1 + c_n\\|\\sqrt{w_{u } } x_u'\\delta_u\\|_{{\\mathbb{p}_n},2}. \\label{useful}\\end{aligned}\\ ] ]    combining ( [ qq : upperbound ] ) and ( [ qq : lowerbound ] ) , we have @xmath1528 and for @xmath1529 , we have @xmath1530 now , suppose that @xmath1531 , namely @xmath1532 .",
    "then @xmath1533 and so @xmath1534 since @xmath1535 .",
    "also , @xmath1536 and so @xmath1537 therefore , @xmath1538 as long as @xmath1531 .",
    "in addition , if @xmath1539 , then @xmath1540 hence , in both cases , we have @xmath1541    next , for every @xmath523 , since @xmath1542 , it follows that @xmath1543 , and we have @xmath1544 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ] -{{\\mathbb{e}_n}}[\\partial_{\\theta } m_u(y_u , x_u,\\theta_u)]'\\delta_u + 2c_n\\|\\sqrt{w_{u } } x_u'\\delta_u\\|_{{\\mathbb{p}_n},2 } \\\\ & \\quad { \\leqslant}\\big(l+\\frac{1}{c}\\big)\\frac{\\lambda}{n}\\|\\widehat\\psi_{u0}\\delta_{u , t_u}\\|_1   + 3c_n\\|\\sqrt{w_{u } } x_u'\\delta_u\\|_{{\\mathbb{p}_n},2 } \\\\ & \\quad   { \\leqslant}\\big(l+\\frac{1}{c}\\big)\\frac{\\lambda}{n}\\|\\widehat\\psi_{u0}\\|_\\infty\\left\\{i_u + ii_u \\right\\}+3c_n\\|\\sqrt{w_{u } } x_u'\\delta_u\\|_{{\\mathbb{p}_n},2 } \\\\",
    "& \\quad { \\leqslant}\\big\\{\\big(l+\\frac{1}{c}\\big)\\|\\widehat\\psi_{u0}\\|_\\infty\\frac{\\lambda\\sqrt{s}}{n\\bar\\kappa_{2\\tilde c}}+ 6\\tilde c c_n\\big\\}\\|\\sqrt{w_{u } } x_u'\\delta_u\\|_{{\\mathbb{p}_n},2},\\end{aligned}\\ ] ] where the second line follows from assumption [ ass : m](c ) , the third from ( [ qq : upperbound ] ) , ( [ useful ] ) , and @xmath1545 , the fourth from @xmath1546 and ( [ boundfirstl1 ] ) , and the fifth from definitions of @xmath1547 , @xmath1548 , and @xmath1549 .",
    "thus , as long as @xmath1550 which is assumed , we have @xmath1551 this gives the first asserted claim .",
    "the second asserted claim follows from @xmath1552 this completes the proof .      for @xmath10 ,",
    "let @xmath1521 $ ] . throughout the proof",
    ", we will assume that the events ( a ) , ( b ) , and ( c ) in assumption [ ass : m ] as well as the events and hold .",
    "these events hold with probability at least @xmath1480 .",
    "we will show that the inequalities in the statement of lemma [ lemma : lassomsparsity ] hold under these events .    by definition of the estimator @xmath430 ,",
    "there is a subgradient @xmath1553 $ ] of @xmath1554 $ ] , such that for every @xmath225 with @xmath1555 , @xmath1556)_j| = \\lambda / n.\\ ] ] therefore , we have @xmath1557)_{{\\widehat}t_u}\\|\\\\   & { \\leqslant}\\|(\\widehat\\psi_{u}^{-1}s_{u , n})_{{\\widehat}t_u}\\| + \\|(\\widehat\\psi_{u}^{-1}\\ { { { \\mathbb{e}_n}}[\\partial_\\theta m_u(y_u , x_u,\\theta_u)]-s_{u , n}\\})_{{\\widehat}t_u}\\|\\\\ & \\quad+\\|(\\widehat\\psi_{u}^{-1}\\ { { { \\mathbb{e}_n}}[\\partial_\\theta m_u(y_u , x_u,{\\widehat}\\theta_u)-\\partial_\\theta m_u(y_u , x_u,\\theta_u)]\\})_{{\\widehat}t_u}\\| \\\\ & { \\leqslant}\\|\\widehat\\psi_{u}^{-1}\\widehat\\psi_{u0}\\|_\\infty \\|\\widehat\\psi_{u0}^{-1 } { { \\mathbb{e}_n}}[s_{u , n}]\\|_\\infty \\sqrt{{\\widehat}s_u}+\\|\\widehat\\psi_u^{-1}\\|_\\infty c_n \\sup_{\\|\\delta\\|=1,\\|\\delta\\|_0{\\leqslant}{\\widehat}s_u}\\|\\sqrt{w_u}x_u'\\delta\\|_{{\\mathbb{p}_n},2 } \\\\ & \\quad+ \\|\\widehat\\psi_{u}^{-1}\\|_\\infty \\sup_{\\|\\delta\\|=1,\\|\\delta\\|_0{\\leqslant}{\\widehat}s_u}|\\ { { { \\mathbb{e}_n}}[\\partial_\\theta m_u(y_u , x_u,{\\widehat}\\theta_u)-\\partial_\\theta m_u(y_u , x_u,\\theta_u)]\\}'\\delta|\\\\ & { \\leqslant}\\frac{\\lambda}{c\\ell n}\\sqrt{{\\widehat}s_u } + \\frac{\\|\\widehat\\psi_{u0}^{-1}\\|_\\infty}{\\ell } \\ { c_n   + l_n\\}\\sup_{\\|\\delta\\|=1,\\|\\delta\\|_0{\\leqslant}{\\widehat}s_u}\\|x_u'\\delta\\|_{{\\mathbb{p}_n},2}\\end{aligned}\\ ] ] where the first inequality follows from the triangle inequality , the second from assumption [ ass : m](a ) , and the third from assumption [ ass : m](b ) and inequalities and .",
    "now , recall that @xmath1558 .",
    "in addition , note that @xmath1559 .",
    "thus , we have @xmath1560 consider any @xmath1561 , and suppose that @xmath1562 . by the sublinearity of the maximum sparse eigenvalue ( lemma 3 in @xcite ) , for any integer @xmath1563 and constant @xmath1564",
    ", we have @xmath1565 where @xmath1566 denotes the ceiling of @xmath1037 .",
    "therefore , @xmath1567 since @xmath1568 for any @xmath571 .",
    "therefore , we have @xmath1569 which violates the condition that @xmath1570 . therefore",
    ", we have @xmath1571 . in turn , applying ( [ eq : sparsityl ] ) once more with @xmath1571 we obtain @xmath1572 the result follows by minimizing the bound over @xmath1570 .      the second asserted claim , inequality , follows from the observation that with probability at least @xmath197 , for all @xmath10 , we have that @xmath1573 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ] { \\leqslant}{{\\mathbb{e}_n}}[m_u(y_u , x_u,{\\widehat}\\theta_u ) ] - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ] \\\\ & \\qquad { \\leqslant}\\frac{\\lambda}{n}\\|\\widehat\\psi_u \\theta_u\\|_1 - \\frac{\\lambda}{n}\\|\\widehat\\psi_u\\widehat\\theta_u\\|_1 { \\leqslant}\\frac{\\lambda}{n }   \\|{\\widehat}\\theta_u - \\theta_u\\|_1 \\cdot \\sup_{u\\in{\\mathcal{u}}}\\|\\widehat \\psi_{u}\\|_\\infty { \\leqslant}\\frac{\\lambda l}{n }   \\|{\\widehat}\\theta_u - \\theta_u\\|_1 \\cdot \\sup_{u\\in{\\mathcal{u}}}\\|\\widehat \\psi_{u0}\\|_\\infty,\\end{aligned}\\ ] ] where the first inequality holds by the definition of @xmath328 , the second by the definition of @xmath437 , the third by the triangle inequality , and the fourth by assumption [ ass : m](ii ) .    to prove the first asserted claim , assume that the events ( a ) , ( b ) , and ( c ) in assumption [ ass : m ] hold .",
    "these events hold with probability at least @xmath197 .",
    "we will show that the asserted claim holds under these events .    for @xmath10 ,",
    "let @xmath1574 , @xmath1575 $ ] , and @xmath1576 . by the inequality in assumption [ ass : m](c ) , we have @xmath1577 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ] -{{\\mathbb{e}_n}}[\\partial_{\\theta } m_u(y_u , x_u,\\theta_u)]'\\tilde\\delta_u + 2c_n\\tilde t_u \\\\ & { \\leqslant}{{\\mathbb{e}_n}}[m_u(y_u , x_u,\\widetilde \\theta_u ) ] - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ] + \\|s_{u , n}\\|_\\infty \\|\\tilde\\delta_u\\|_1 + 3c_n\\tilde t_u\\\\ & { \\leqslant}{{\\mathbb{e}_n}}[m_u(y_u , x_u,\\widetilde \\theta_u ) ] - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u ) ] + \\tilde t_u\\big ( \\frac{\\sqrt{\\widehat s_u+s_u}\\|s_{u , n}\\|_\\infty}{\\sqrt{{\\phi_{{\\rm min}}(\\widehat s_u+s_u , u ) } } } + 3c_n\\big)\\end{aligned}\\ ] ] where the second inequality holds by calculations as in ( [ useful ] ) , and the third inequality follows from @xmath1578 next , if @xmath1579 , then @xmath1580 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u)]\\}_+^{1/2 } + \\frac{\\bar q_{a_u}}{2}\\tilde t_u,\\ ] ] so that @xmath1581 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u)]\\}_+^{1/2}$ ] .",
    "on the other hand , if @xmath1582 , then @xmath1583 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u)]\\ } + \\tilde t_u\\left ( \\frac{\\sqrt{\\widehat s_u+s_u}\\|s_{u , n}\\|_\\infty}{\\sqrt{{\\phi_{{\\rm min}}(\\widehat s_u+s_u ) } } } + 3c_n\\right).\\ ] ] since for positive numbers @xmath1002 , @xmath1584 , @xmath722 , inequality @xmath1585 implies @xmath1586 , we have @xmath1587 - { { \\mathbb{e}_n}}[m_u(y_u , x_u,\\theta_u)]\\}_+^{1/2 } + \\left ( \\frac{\\sqrt{\\widehat s_u+s_u}\\|s_{u , n}\\|_\\infty}{\\sqrt{{\\phi_{{\\rm min}}(\\widehat s_u+s_u ) } } } + 3c_n\\right).\\ ] ] in both cases , the inequality in the asserted claim holds .",
    "this completes the proof .      for brevity of notation",
    ", denote @xmath1588 . also , let @xmath1589 denote the event that the inequalities in condition wl(iii ) hold .",
    "then @xmath1590 .",
    "further , by the triangle inequality , @xmath1591\\|_\\infty & { \\leqslant}\\max_{u\\in\\mathcal{u}^\\epsilon } \\| { \\widehat}\\psi^{-1}_{u 0 } { { \\mathbb{e}_n}}[s_u ] \\|_\\infty\\label{eq : lemma lambda choice first}\\\\ &   \\quad + \\sup_{u\\in\\mathcal{u}^\\epsilon , u'\\in\\mathcal{u},d_\\mathcal{u}(u , u'){\\leqslant}\\epsilon } \\| { \\widehat}\\psi^{-1}_{u 0 } { { \\mathbb{e}_n}}[s_u ] - { \\widehat}\\psi^{-1}_{u'0 } { { \\mathbb{e}_n } } [ s_{u ' } ] \\|_\\infty\\notag\\end{aligned}\\ ] ] where @xmath1592 is a minimal @xmath1306-net of @xmath1450 so that @xmath1593 .    for each @xmath1594 and @xmath1595 , we apply lemma [ lemma : mdsn ] with @xmath1596 , @xmath1597 , and @xmath1598 , where @xmath1599 is a small enough constant that can be chosen to depend only on @xmath1022 and @xmath455 .",
    "then condition wl(i , ii ) implies that @xmath1600 where @xmath1601)^{1/2}/({{\\mathrm{e}}}_p[z_1 ^ 3])^{1/3}$ ] , and so applying lemma [ lemma : mdsn ] , the union bound , and the inequality @xmath1602 gives @xmath1603 } } \\frac{|\\sqrt{n}{{\\mathbb{e}_n } } [ s_{uk } ] |}{\\sqrt{{{\\mathbb{e}_n}}[s_{uk}^2 ] } } > \\phi^{-1}\\big(1-\\mbox{$\\frac{\\gamma}{2p n_n}$}\\big ) \\right )   { \\leqslant}2pn_n \\cdot \\frac{\\gamma}{2p n_n}\\cdot\\big ( 1 + o(\\varphi_n^{1/3})\\big ) { \\leqslant}\\gamma+ o(\\gamma)\\ ] ] since @xmath1202 .",
    "also , observe that @xmath1604\\|_\\infty   =   \\sup_{u\\in\\mathcal{u}^\\epsilon}\\max_{k\\in[p ] } \\frac{|{{\\mathbb{e}_n } } [ s_{uk } ] |}{\\sqrt{{{\\mathbb{e}_n}}[s_{uk}^2]}}.\\ ] ] therefore , implies that with probability at least @xmath1605 , @xmath1606\\|_\\infty { \\leqslant}n^{-1/2}\\phi^{-1}\\left(1 - \\frac{\\gamma}{2p n_n}\\right)\\ ] ]    further , by the triangle inequality , @xmath1607 - { \\widehat}\\psi^{-1}_{u'0 } { { \\mathbb{e}_n } } [   s_{u ' } ] \\|_\\infty   \\notag\\\\ & \\qquad \\qquad { \\leqslant}{\\displaystyle   \\sup_{u\\in\\mathcal{u}^\\epsilon , u'\\in\\mathcal{u},d_\\mathcal{u}(u , u'){\\leqslant}\\epsilon } } \\| ( { \\widehat}\\psi^{-1}_{u 0 } - { \\widehat}\\psi^{-1}_{u'0 } ) { \\widehat}\\psi_{u 0 } \\|_\\infty \\| { \\widehat}\\psi^{-1}_{u 0}{{\\mathbb{e}_n } } [   s_{u}]\\|_\\infty \\label{eqtri2}\\\\ & \\qquad \\qquad",
    "\\qquad +   { \\displaystyle \\sup_{u , u'\\in\\mathcal{u},d_\\mathcal{u}(u , u'){\\leqslant}\\epsilon } } \\| { { \\mathbb{e}_n } } [   s_{u}-   s_{u ' } ] \\|_\\infty\\|{\\widehat}\\psi^{-1}_{u'0 } \\|_\\infty.\\label{eqtri8}\\end{aligned}\\ ] ] to control the expression in ( [ eqtri2 ] ) , note that by condition wl(ii ) , on the event @xmath1589 , @xmath1608 is bounded away from zero uniformly over @xmath523 and @xmath1018 $ ] .",
    "thus , we have uniformly over @xmath523 and @xmath1018 $ ] that @xmath1609 on the event @xmath1589 .",
    "moreover , we have @xmath1610}\\big| \\{{{\\mathbb{e}_n}}[s_{uk}^2]\\}^{1/2}-\\{{{\\mathbb{e}_n}}[s_{u'k}^2]\\}^{1/2}\\big| \\\\ & \\qquad\\qquad{\\leqslant}\\sup_{u , u'\\in\\mathcal{u},d_\\mathcal{u}(u , u'){\\leqslant}\\epsilon}\\max_{k\\in[p ] } \\big(|{{\\mathbb{e}_n}}[s_{uk}^2]-{{\\mathbb{e}_n}}[s_{u'k}^2]|\\big)^{1/2 } \\notag \\\\ & \\qquad\\qquad   { \\leqslant}\\sup_{u , u'\\in\\mathcal{u},d_\\mathcal{u}(u , u'){\\leqslant}\\epsilon}\\max_{k\\in[p ] } \\big(2|({{\\mathbb{e}_n}}-{{\\mathrm{e}}}_p)[s_{uk}^2]|+|{{\\mathrm{e}}}_p[s_{uk}^2-s_{u'k}^2]|\\big)^{1/2}\\lesssim \\varphi_n^{1/2}\\notag\\end{aligned}\\ ] ] on the event @xmath1589 .",
    "thus , relations ( [ eqaux37a ] ) and ( [ eqaux37 ] ) imply that @xmath1611 on the event @xmath1589 .",
    "also , using standard bounds for the tails of gaussian random variables gives @xmath1612 thus , on the intersection of events @xmath1589 and , we have @xmath1613\\|_\\infty   \\lesssim ( \\varphi_n / n)^{1/2}\\sqrt{\\log(p n_n/\\gamma)}.\\ ] ] finally , on the event @xmath1589 , we have that the expression in satisfies @xmath1614\\|_\\infty\\|{\\widehat}\\psi^{-1}_{u'0 } \\|_\\infty { \\leqslant}\\varphi_n n^{-1/2}.\\ ] ]    it follows that on the intersection of events @xmath1589 and , for @xmath1 large enough , we have @xmath1615 - { \\widehat}\\psi^{-1}_{u'0 } { { \\mathbb{e}_n } } [   s_{u ' } ] \\|_\\infty{\\leqslant}\\frac{c ' - c}{c}\\cdot \\phi^{-1}\\left(1 - \\frac{\\gamma}{2p n_n}\\right),\\ ] ] where we again used standard tail bounds for the tails of gaussian random variables . the asserted claim now follows by recalling the inequality and noting that @xmath1590 and that holds with probability at least @xmath1605",
    ".      for @xmath1616 $ ] , let @xmath1617\\colon u \\in \\mathcal{u}\\big\\},\\\\ & \\mathcal{g}_j = \\big\\{(y , x)\\mapsto x_j^2\\zeta_u^2\\colon u \\in \\mathcal{u } \\big\\}\\end{aligned}\\ ] ] where @xmath1618 $ ] .",
    "note that the function @xmath1619 is an envelope both for @xmath1620 and for @xmath1621 for all @xmath11 $ ] . by assumption",
    ", @xmath1622 can be chosen to satisfy @xmath1623 .",
    "because @xmath1624 is a product of a vc - subgraph class of functions with index bounded by @xmath1506 and a single function , lemma [ lemma : andrews](1 ) implies that its uniform entropy numbers obey @xmath1625 also , lemma [ lemma : partialoutcovering ] implies that the uniform entropy numbers of @xmath1626 obey @xmath1627 further , since @xmath1628 , @xmath1629 is an envelope for @xmath1630 , and the uniform entropy numbers of @xmath1631 obey for all @xmath1007 $ ] , @xmath1632 where the first and the second lines follow from lemma [ lemma : andrews](2 ) , and the third from ( [ cnb1 ] ) .",
    "hence , lemma [ lemma : andrews](2 ) implies that the uniform entropy numbers of @xmath1633}\\mathcal{g}_j$ ] obey @xmath1634 where @xmath1635 is its envelope . therefore ,",
    "since @xmath1636 and @xmath1637{\\leqslant}\\bar c$ ] by assumption , lemma [ lemma : cck ] implies that with probability at least @xmath1517 , @xmath1638|   \\lesssim \\sqrt{\\frac{\\log ( n p k_n)}{n } } + \\frac{n^{2/q}k_n^2}{n}\\log(n p k_n),\\ ] ] which gives .    to verify , note that @xmath1639}{{\\mathrm{e}}}_p [ x_j^2(\\zeta_u-\\zeta_{u'})^2]&\\displaystyle { \\leqslant}\\sup_{d_{\\mathcal{u}}(u , u'){\\leqslant}1/n } \\max_{j\\in [ p]}{{\\mathrm{e}}}_p [ x_j^2(y_u - y_{u'})^2 ] \\\\ & { \\leqslant}\\sup_{d_{\\mathcal{u}}(u , u'){\\leqslant}1/n } \\max_{j{\\leqslant}p}\\{{{\\mathrm{e}}}_p [ x_j^4]\\}^{1/2}\\{{{\\mathrm{e}}}_p[(y_u - y_{u'})^4]\\}^{1/2 } \\\\   & \\lesssim   \\sup_{d_{\\mathcal{u}}(u , u'){\\leqslant}1/n}|u - u'|^{\\nu/2 } \\lesssim n^{-\\nu/2}.\\end{aligned}\\ ] ] therefore , lemma [ lemma : cck ] implies that we have with probability at least @xmath1517 , @xmath1640\\|_\\infty & = \\frac{1}{\\sqrt{n } }   \\sup_{d_{\\mathcal{u}}(u , u'){\\leqslant}1/n } \\max_{j\\in p}|{\\mathbb{g}_n } ( x_j(\\zeta_u-\\zeta_{u'}))|\\\\   & \\lesssim \\sqrt{\\frac{\\log(n p k_n)}{n^{1 + \\nu/2 } } } + \\frac{n^{1/q}k_n\\log(n p k_n)}{n},\\end{aligned}\\ ] ] which gives .    finally , to verify note that uniformly over @xmath205 and @xmath1616 $",
    "] , we have @xmath1641 \\big)^{1/2}\\cdot\\big({{\\mathrm{e}}}[s_{u j}^2]+{{\\mathrm{e}}}_p[s_{u ' j}^2]\\big)^{1/2}\\\\ & \\lesssim   \\big({{\\mathrm{e}}}_p [ x_j^2(y_u - y_{u'})^2]\\big)^{1/2 }",
    "\\lesssim \\big({{\\mathrm{e}}}_p [ x_j^4]\\big)^{1/4}\\cdot\\big({{\\mathrm{e}}}_p[(y_u - y_{u'})^4]\\big)^{1/4 }    \\lesssim d_{\\mathcal{u}}(u , u')^{\\nu/4}.\\end{aligned}\\ ] ] this completes the proof .",
    "let @xmath1642 be a sequence of independent copies of a random element @xmath1643 taking values in a measurable space @xmath1644 according to a probability law @xmath7 .",
    "let @xmath563 be a set of suitably measurable functions @xmath1645 , equipped with a measurable envelope @xmath1646 .",
    "[ lemma : andrews]work with the setup above .",
    "+ ( 1 ) let @xmath1647 be a vc subgraph class with a finite vc index @xmath538 or any other class whose entropy is bounded above by that of such a vc subgraph class , then the uniform entropy numbers of @xmath1647 obey @xmath1648 ( 2 ) for any measurable classes of functions @xmath1647 and @xmath1649 mapping @xmath1650 to @xmath1651 , @xmath1652 ( 3 ) for any measurable class of functions @xmath563 and a fixed function @xmath1653 mapping @xmath1650 to @xmath1651 , @xmath1654 ( 4 ) given measurable classes @xmath1655 and envelopes @xmath1656 , @xmath1657 , mapping @xmath1650 to @xmath1651 , a function @xmath1658 such that for @xmath1659 , @xmath1660 , @xmath1661 , and fixed functions @xmath1662 , the class of functions @xmath1663 satisfies @xmath1664    see lemma l.1 in @xcite .",
    "[ lemma : partialoutcovering ] let @xmath1665 denote a class of measurable functions @xmath1666 with a measurable envelope @xmath1622 .",
    "for a given @xmath1667 , let @xmath1668 be the function @xmath1669 where @xmath1670 is a regular conditional probability distribution over @xmath1671 conditional on @xmath1672 .",
    "set @xmath1673 and let @xmath1674 be an envelope for @xmath1675 .",
    "then , for @xmath1676 , @xmath1677 where @xmath1271 belongs to the set of finitely - discrete probability measures over @xmath1650 such that @xmath1678 , and @xmath1679 belongs to the set of finitely - discrete probability measures over @xmath1680 such that @xmath1681 . in particular , for every @xmath1682 and any @xmath571 , @xmath1683    see lemma l.2 in @xcite .",
    "[ lem : linear classes ] consider a mapping @xmath1684 from @xmath1685^k$ ] into @xmath1686 and the class of functions @xmath1687 mapping @xmath1686 into @xmath1688 where @xmath1689 is @xmath1038-lipschitz .",
    "assume that @xmath1690 for all @xmath1691 for some constant @xmath830 .",
    "then , for any @xmath1692 the uniform entropy numbers of @xmath563 satisfy @xmath1693 where @xmath1694 , @xmath1695 , is its envelope .",
    "consider any @xmath1696 .",
    "there exist @xmath1691 such that @xmath1697 and @xmath1698 for all @xmath1695 .",
    "therefore , since @xmath1699 is @xmath1038-lipschitz , we have @xmath1700 by definition of the envelope @xmath1701 .",
    "thus , for any finitely discrete probability measure @xmath1271 on @xmath1001 , @xmath1702 recall that since @xmath1703 we have @xmath1704 where the last inequality follows from standard volume arguments .",
    "furthermore , for any @xmath1705 we have @xmath1706 .",
    "therefore @xmath1707 .",
    "[ lem : bounded lipschitz classes ] let @xmath1647 be a class of functions with an envelope @xmath1622 . also , let @xmath1708 be an @xmath1038-lipschitz function bounded in absolute value by a constant @xmath67 .",
    "assume that for some positive constants @xmath354 and @xmath1709 , the uniform entropy numbers of @xmath1647 obey @xmath1710 then for any constant @xmath1711 , the uniform entropy numbers of the class of functions @xmath1712 obey @xmath1713 where @xmath1714 is its envelope .",
    "the result follows from the observation that for any @xmath1715 and any finitely - discrete probability measure @xmath1271 , @xmath1716 so that if @xmath1647 can be covered by @xmath538 balls of radius @xmath1717 ( in the @xmath1718 norm ) , then @xmath1719 can be covered by @xmath538 balls of radius @xmath1720 ( in the same norm ) .",
    "[ lemma : mdsn ] let @xmath1721,@xmath1722 , @xmath1723 be independent , zero - mean random variables and @xmath1724 $ ] .",
    "let @xmath1725 @xmath1726 \\right \\}^{1/2 } \\big / \\left \\{\\frac{1}{n } \\sum_{i=1}^n { { \\mathrm{e}}}[|z_i|^{2+\\mu } ] \\right\\}^{1/\\{2+\\mu\\}}>0\\ ] ] and @xmath1727 .",
    "then for some absolute constant @xmath1385 , @xmath1728    let @xmath1642 be a sequence of independent copies of a random element @xmath1643 taking values in a measurable space @xmath1644 according to a probability law @xmath7 .",
    "let @xmath563 be a set of suitably measurable functions @xmath1645 , equipped with a measurable envelope @xmath1646 .",
    "[ lemma : cck ] work with the setup above .",
    "suppose that @xmath1729 is a measurable envelope for @xmath1647 with @xmath1730 for some @xmath1731 .",
    "let @xmath1732 and @xmath1733 be any positive constant such that @xmath1734 .",
    "suppose that there exist constants @xmath1735 and @xmath1736 such that @xmath1737 then @xmath1738 { \\leqslant}k   \\left ( \\sqrt{v\\sigma^{2 } \\log \\left ( \\frac{a \\| f \\|_{p,2}}{\\sigma } \\right ) } + \\frac{v\\| m \\|_{p , 2}}{\\sqrt{n } } \\log \\left ( \\frac{a \\| f \\|_{p,2}}{\\sigma } \\right ) \\right),\\ ] ] where @xmath1739 is an absolute constant .",
    "moreover , for every @xmath1740 , with probability @xmath1741 , @xmath1742 + k(q ) \\big [ ( \\sigma + n^{-1/2 } \\| m \\|_{p , q } ) \\sqrt{t } +   \\alpha^{-1 }   n^{-1/2 } \\| m \\|_{p,2}t \\big ] , \\",
    "\\forall \\alpha > 0,\\end{gathered}\\ ] ] where @xmath1743 is a constant depending only on @xmath352 . in particular , setting @xmath1744 and @xmath1745 , with probability @xmath1746 , @xmath1747 where @xmath1748 and @xmath1749 is a constant depending only on @xmath352 and @xmath722 .",
    "[ lem : maximal inequality 2 ] work with the setup above .",
    "suppose that the conditions of lemma [ lemma : cck ] are satisfied .",
    "then @xmath1750\\|_{\\mathcal{f}}\\big ] - \\sup_{f\\in{\\mathcal{f}}}{{\\mathrm{e}}}_p[f^2(w)]{\\leqslant}\\frac{k \\|m\\|_{p,2}}{\\sqrt n}\\left(\\sigma\\sqrt{v\\log\\left(\\frac{a\\|f\\|_{p,2}}{\\sigma}\\right ) } + \\frac{v\\|m\\|_{p,2}\\log\\left(\\frac{a\\|f\\|_{p,2}}{\\sigma}\\right)}{\\sqrt{n } } \\right)\\end{aligned}\\ ] ] where @xmath1739 is an absolute constant .",
    "the proof of the asserted claim coincides one - by - one with that given for the corresponding inequality in lemma 2.2 of @xcite , with the constant 3 replaced everywhere by the constant 2 . at the end of the proof , the entropy integral @xmath1751 is bounded by @xmath1752 under our condition on the uniform entropy numbers of @xmath1647 ."
  ],
  "abstract_text": [
    "<S> in this paper we develop procedures to construct simultaneous confidence bands for @xmath0 potentially infinite - dimensional parameters after model selection for general moment condition models where @xmath0 is potentially much larger than the sample size of available data , @xmath1 . </S>",
    "<S> this allows us to cover settings with functional response data where each of the @xmath0 parameters is a function . </S>",
    "<S> the procedure is based on the construction of score functions that satisfy certain orthogonality condition . </S>",
    "<S> the proposed simultaneous confidence bands rely on uniform central limit theorems for high - dimensional vectors ( and not on donsker arguments as we allow for @xmath2 ) . to construct the bands , </S>",
    "<S> we employ a multiplier bootstrap procedure which is computationally efficient as it only involves resampling the estimated score functions ( and does not require resolving the high - dimensional optimization problems ) . </S>",
    "<S> we formally apply the general theory to inference on regression coefficient process in the distribution regression model with a logistic link , where two implementations are analyzed in detail . </S>",
    "<S> simulations and an application to real data are provided to help illustrate the applicability of the results . </S>"
  ]
}