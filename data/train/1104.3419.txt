{
  "article_text": [
    "_ multi  trial error / erasure ( mtee ) _ decoding or _ generalized minimum distance ( gmd )",
    "_ decoding @xcite is a technique which applies multiple decoding trials of an error / erasure decoder on each received word , each time with a different number of erased most unreliable symbols .",
    "the ideas behind this approach are to not let unreliable received symbols interfere the decoding process and to exhaustively try the set of most promising erasure patterns .",
    "mtee decoding performs surprisingly well , especially when the channel is in good shape .",
    "this is naturally the case when we consider concatenated codes . here",
    ", the inner code and the channel can be considered jointly as a _ super channel _ which , due to the inner decoder s error  correcting capabilities , has low symbol error probability .",
    "we investigate a particular concatenated code construction which is widely used in practice and standards , e.g. the consultative committee for space data system s ( ccsds ) telemetry channel @xcite . in this construction ,",
    "the inner code is a convolutional code with a _ maximum likelihood ( ml ) _ decoder .",
    "the outer code is a traditional _ reed ",
    "solomon ( rs ) _ code .",
    "we stress that the inner code needs to be _ tailbited _ to insulate channel error events to single symbols of the outer received word .",
    "our target is to minimize the residual codeword error probability after decoding .",
    "we consider _ threshold erasing _ , which means that each output of the inner ml decoder is measured against a set of @xmath3 real thresholds @xmath6 , @xmath7 .",
    "if the reliability of the symbol ( which is an output of the inner ml decoder ) falls below threshold @xmath8 in decoding trial @xmath9 , @xmath10 , then the symbol is erased and replaced by the _ erasure marker _ @xmath11 .",
    "the threshold erasing method dates back to blokh and zyablov @xcite and is different from the _ symbol erasing",
    "_ method used in forney s original work about gmd decoding .",
    "there , the received symbols are ordered according to their reliabilities and an increasing number of most unreliable received symbols is erased in each of the @xmath12 decoding trials .    currently , the most powerful technique for algebraic decoding of rs codes is the _ guruswami  sudan ( gs ) _ list decoder @xcite .",
    "it can be parametrized to obtain error / erasure tradeoff factors @xmath1 in the range @xmath13 .",
    "@xmath1 expresses the relative cost of errors compared to erasures in terms of required _ hamming distance_. generally , increasing the _ multiplicity parameter _",
    "@xmath14 brings along higher list decoding radius , increased decoding complexity , and smaller @xmath1 .",
    "we will elaborate the latter fact in the course of the paper .",
    "the gs decoder has been extended to a soft  input algorithm by ktter and vardy in their award  winning 2003 paper @xcite .",
    "their algorithm is based on setting the multiplicity of each interpolation point in the gs decoder according to the reliability of the corresponding received symbol .",
    "another promising approach for soft  input decoding of rs codes has recently been published by nguyen et .",
    "@xcite and is based on _ rate ",
    "distortion theory_. in our work , we investigate the potential of threshold erasing , when the outer code is decoded in multiple trials with the gs decoder .",
    "the results are based on our previous papers @xcite , in which we consider outer bmd decoding ( @xmath0 ) of _ bose  chaudhuri  hocquenghem _ codes and outer decoding of _ interleaved reed ",
    "solomon ( irs ) _ codes ( @xmath15 , @xmath16 ) , respectively .    for the sake of completeness we should also mention other publications on related topics , e.g. maximization of the decoding radius of concatenated block codes with an outer @xmath1decoder using threshold erasing @xcite and symbol erasing @xcite .",
    "outer list decoders have already been considered by nielsen @xcite , but with the aim of maximizing the decoding radius of the concatenated code construction .",
    "an overview of the different erasing techniques with an arbitrary number of decoding trials is given in @xcite .",
    "the rest of the paper is organized as follows . in section  [ sec : conc ] , we describe structure and threshold  based mtee decoding of the aforementioned concatenated code construction .",
    "we use results from @xcite to derive optimal threshold locations for outer decoding with @xmath13 in section  [ sec : thresholds ] . here and in the rest of the paper , _ optimal _",
    "means _ minimizing the residual codeword error probability_. section  [ sec : nonconstant ] deals with the gs decoder s non  constant @xmath1 and shows how our result from section  [ sec : thresholds ] can be applied nevertheless .",
    "optimal threshold locations are used in section  [ sec : sim ] to plot error probability curves of an exemplary concatenated code .",
    "it will turn out , that for the considered setting the high  complexity gs decoder is in many cases not worth the effort and multiple trials of low ",
    "complexity bmd decoding yield comparable or even lower residual codeword error probabilities .",
    "we conclude our paper in section  [ sec : conclusions ] .",
    "a concatenated code @xmath17 consists of an _ inner code _ @xmath18 and an _ outer code _ @xmath19 . the resulting concatenated code @xmath20 is binary and , w.l.o.g .",
    ", we restrict ourselves to this most practical case .    the information vector @xmath21 is encoded into an outer codeword @xmath22 of the outer code . each @xmath23ary symbol @xmath24 , @xmath25 ,",
    "can be interpreted as a binary vector @xmath26 of length @xmath27 .",
    "these vectors serve as information for the inner code and are encoded into inner codewords @xmath28 . arranging the @xmath29 as columns of a matrix gives the codeword matrix of the concatenated code @xmath20 , which is transmitted over a _ binary symmetric channel ( bsc ) _ with crossover probability @xmath30 .",
    "the receiver obtains erroneous columns @xmath31 , which are fed into the ml decoder for @xmath32 .",
    "it returns inner codeword estimates @xmath33 .",
    "the information parts @xmath34 are extracted from the @xmath35 and mapped to symbols @xmath36 .",
    "the resulting vector @xmath37 is the input for the mtee decoder of @xmath38 .",
    "the mtee decoder performs erasing with the threshold set @xmath39 , .",
    "it calculates a _ reliability value _",
    "@xmath40 for every received symbol @xmath41 according to @xmath42 and @xmath43 is applied in the following manner : @xmath44 @xmath45 .",
    "note that the particular calculation of the reliability value stems from ( * ? ? ?",
    "* corollary to theorem 1 ) and results in decision regions which minimize both the error- and the error  or  erasure probability of the outer decoder at the same time .",
    "result of the erasing procedure is the _ input list _ @xmath46 , in which .",
    "each element of the input list is fed into the outer decoder with and multiplicity @xmath14 .",
    "since we allow the outer decoder to be a list decoder , each decoding trial potentially returns a result list @xmath47 .",
    "these lists are merged into the _ overall _ result list @xmath48 .",
    "we have a decoding success whenever @xmath49 .",
    "as a starting point for our derivation of the optimal threshold locations we generalize ( * ? ? ?",
    "* theorem 1 ) .",
    "several cases are possible when a single received symbol @xmath50 , which could be either correct ( @xmath51 ) or erroneous ( ) , is considered .",
    "first , the symbol might be correct and never erased by any threshold .",
    "we denote the probability of this event by @xmath52 second , the symbol might be erroneous and never erased , the probability of this event is @xmath53 third , the symbol might be erased by every threshold in @xmath43 , in this case we do not distinguish whether it is correct or not and denote the probability by @xmath54 the last two cases are for correct and erroneous symbols that are not erased by thresholds @xmath55 , but erased by all ( larger ) thresholds @xmath56 .",
    "the corresponding probabilities are @xmath57 it is clear that these probabilities must sum up to one , i.e. @xmath58 .    since it is similar to the derivation of ( * ? ? ?",
    "* theorem 1 ) , we omit the generalized derivation here and immediately state the following theorem .",
    "[ thm : conditions ] if the outer decoder has error / erasure tradeoff factor @xmath1 , @xmath13 , and can correct up to ( including ) @xmath59 erasures , then the following conditions are necessary and sufficient for an optimal mtee threshold set . @xmath60 and @xmath61 for @xmath43 fulfilling these conditions ,",
    "the residual codeword error probability @xmath62 can be approximated by @xmath63    in case of bmd- and many other decoders @xmath64 .",
    "however , we will see later that for the gs decoder we might also require smaller values of @xmath59 .",
    "following @xcite , we state simple approximations for the probabilities of theorem  [ thm : conditions ] in our previous paper @xcite .",
    "we repeat them in lemma  [ lemma : approx ] to clarify the further derivation of the optimal threshold set .",
    "the lemma is based on spherical approximations of the inner code s voronoi cells and the exponential error bounds for erasure schemes derived by forney @xcite , which generalize gallager s error exponents for the bsc @xcite .",
    "[ lemma : approx ] simple approximations of the probabilities @xmath65 and @xmath66 are given by @xmath67 @xmath68 , where @xmath69 is gallager s error exponent for ml decoding of a code with rate @xmath70 and transmission over a bsc .",
    "@xmath71 , @xmath72 , is the corresponding optimization parameter .",
    "the conditions from theorem  [ thm : conditions ] and the approximations from lemma  [ lemma : approx ] allow to obtain analytic formulae for the optimal threshold locations .",
    "their number @xmath12 , the rate @xmath70 of the inner code and @xmath1 are parameters . inserting the approximations into the conditions results in the following system of @xmath12 recurrent equations .",
    "@xmath73 @xmath74 and , @xmath75 , @xmath76 equations ( [ eqn : eqn1 ] ) , ( [ eqn : eqn2 ] ) , and ( [ eqn : eqn3 ] ) allow to prove our main theorem .",
    "[ thm : locationbd ] the optimal threshold set @xmath77 for mtee decoding of a concatenated code with an inner ml decoder and an outer decoder with error / erasure tradeoff factor @xmath1 , @xmath78 , is given by @xmath79 where @xmath69 is gallager s error exponent for the bsc , @xmath71 is the corresponding optimization parameter , @xmath80 , and @xmath81    the statement follows from the unique solution of the recurrence relation ( [ eqn : eqn1 ] ) , ( [ eqn : eqn2 ] ) , and ( [ eqn : eqn3 ] ) for @xmath82 .",
    "[ cor : locationbmd ] for outer bmd decoding , i.e. @xmath0 , the optimal threshold set is given by @xmath83    the statement follows from the unique solution of the recurrence relation ( [ eqn : eqn1 ] ) , ( [ eqn : eqn2 ] ) , and ( [ eqn : eqn3 ] ) for @xmath0 .",
    "corollary  [ cor : locationbmd ] coincides with a result of blokh and zyablov @xcite .",
    "thus , we obtain their threshold location formula as a special case of our main theorem  [ thm : locationbd ] .",
    "[ fig : thresholds ] shows the optimal threshold sets for @xmath84 , @xmath85 , @xmath86 , and @xmath87 .",
    "each line represents one threshold set , darker color of the curve means larger @xmath1 .",
    "the optimal threshold set for outer bmd decoding ( @xmath0 , see corollary  [ cor : locationbmd ] ) is given as a reference .",
    "note that @xmath88 is constant for fixed @xmath1 and @xmath12 , other crossover probabilities @xmath30 of the bsc simply scale the threshold locations by a factor .     and corollary  [ cor : locationbmd ] for @xmath84 , @xmath85 , @xmath86 , and @xmath87 .",
    "]    it is easy to prove that @xmath8 is non - increasing with decreasing @xmath1 , a fact which can also be observed in fig .",
    "[ fig : thresholds ] .",
    "this means that with decreasing @xmath1 , the number of erased symbols generally becomes smaller .",
    "we could have expected such a behavior since with decreasing @xmath1 , the relative cost of errors decreases and thereby also the effect of erasing unreliable received symbols .",
    "we can use theorem  [ thm : conditions ] to obtain an approximation of the residual codeword error probability after mtee decoding with an optimal threshold set obtained by theorem  [ thm : locationbd ] . to do so , we use the second term from ( [ eqn : pe ] ) and write @xmath89 inserting the approximation of @xmath90 from lemma  [ lemma : approx ] gives @xmath91 in which we can replace @xmath92 as given by theorem  [ thm : locationbd ] for @xmath82 or corollary  [ cor : locationbmd ] for @xmath0 , respectively .",
    "this results in the following theorem and its corollary .",
    "[ thm : pe ] the residual codeword error probability of mtee decoding of a concatenated code with an inner ml decoder , an outer decoder with error / erasure tradeoff factor @xmath1 , @xmath78 , maximal number of correctable erasures @xmath59 , and an optimal threshold set @xmath77 can be approximated by @xmath93    for traditional outer bmd decoding , i.e. @xmath0 and @xmath64 , we have the approximation @xmath94    so far , we assumed that @xmath1 is constant for any number of erased symbols .",
    "this is true for bmd decoders but not for the gs decoder as we will see in the following section",
    "the _ decoder capability function _ ( _ dcf _ , a constraint on the number @xmath95 of erasures and the number @xmath96 of errors , that can be corrected concurrently ) of a bmd decoder is @xmath97 for @xmath95 erasures , @xmath98 , the decoder fails to correct @xmath99 or more errors .",
    "the indeed constant @xmath1 for any number of erasures is given by the negative reciprocal value of @xmath100 s slope , i.e. @xmath101 the situation is different for the gs decoder . for simplicity , we restrict ourselves to the best ( in terms of achievable list decoding radius ) case , i.e. multiplicity @xmath102 .",
    "it s dcf is @xmath103 resulting in @xmath104 and @xmath105 which is a strictly monotonic increasing function of @xmath95 and thereby not usable in theorem  [ thm : locationbd ] .",
    "we will now show that near ",
    "optimal threshold locations for the gs decoder can be calculated using theorem  [ thm : locationbd ] .",
    "it is straightforward to see that for any @xmath95 , a decoder with radius @xmath106 can be transformed into a decoder with radius @xmath107 by simply discarding all decoding results with @xmath95 erasures and @xmath108 errors .",
    "this fact and the monotonicity of @xmath109 allow to conclude that any tangent of @xmath106 at @xmath110 , @xmath111 , specifies a _ tangent decoder _ with radius @xmath112 and constant error / erasure tradeoff factor @xmath113 that can be imitated by the gs list decoder .",
    "its maximum number of correctable erasures @xmath114 is obtained by solving @xmath115 for @xmath95 and taking the floor of the result .    since @xmath116 is independent of @xmath95 ,",
    "theorems  [ thm : locationbd ] and [ thm : pe ] can be applied with @xmath116 and @xmath114 to obtain optimal threshold locations and residual codeword error probabilities for tangent decoders which can be imitated by the gs decoder .",
    "the optimal tangent decoder is determined by @xmath117 which is independent of the the ml error exponent .",
    "thus , tangent decoders determined by ( [ eqn : optkappa ] ) are optimal for all bsc crossover probabilities .",
    "[ fig : sim ]    let us consider the outer rs code @xmath118 with gs decoder .",
    "we consider @xmath119 outer decoding trials .",
    "based on ( [ eqn : optkappa ] ) , table  [ tab : tangentdecoders ] states the parameters of the corresponding optimal tangent decoders .",
    ".optimal tangent decoders for @xmath119 .",
    "[ cols=\"^,^,^,^\",options=\"header \" , ]     as inner code , we assume a tailbited rate @xmath85 convolutional code with ml decoder .",
    "this allows to use theorem  [ thm : pe ] in order to plot the solid red residual codeword error curves for outer gs decoding in fig .",
    "[ fig : sim ] .",
    "additionally , we consider outer bmd decoding and allow the decoder to be run @xmath120 times ( dashed blue curves ) .",
    "we observe that the gain of tangent decoding diminishes for growing @xmath12 .",
    "since both residual codeword error probabilities ( optimal tangent decoder and bmd decoder ) converge to the same value , i.e. @xmath121 ( dash  dotted black curve ) , we conclude that for every number @xmath5 of outer gs decoding trials , there exists a number @xmath122 of outer bmd decoding trials that achieves either the same or lower residual codeword error probability .",
    "this allows to trade a number of high  complexity gs decoding trials for a ( generally larger ) number of low ",
    "complexity bmd decoding trials , extending the options of the system designer .",
    "we generalized our results from @xcite to the case of arbitrary error / erasure tradeoff factors @xmath1 in the range @xmath13 .",
    "we derived formulae for optimal thresholds applicable in mtee decoding , our generalization allows to use the gs list decoder for the outer code . based on our derivation",
    ", we gave approximations of the residual codeword error probability after outer decoding for the full range of @xmath1 .",
    "this allowed to compare outer gs list decoding with traditional , low  complexity , bmd decoding .",
    "our main result is that for the particular concatenated coding scheme under consideration ( outer rs code , inner convolutional code with ml decoding , e.g. used in@xcite ) , @xmath4 trials of outer bmd decoding can outperform @xmath5 trials of gs decoding if @xmath122 .",
    "this is interesting for practical applications , since bmd decoders have low computational complexity and are widely deployed .        c.  senger , v.  r. sidorenko , m.  bossert , and v.  v. zyablov , `` optimal thresholds for gmd decoding with @xmath123extended bounded distance decoders , '' in _ proc .",
    "symp . on inform .",
    ", austin , tx , usa , june 2010 , pp",
    ". 11001104 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1109/isit.2010.5513698            v.  guruswami and m.  sudan , `` improved decoding of reed - solomon and algebraic - geometric codes , '' _ ieee trans .",
    "inform . theory _",
    "it-45 , no .  6 , pp .",
    "17551764 , september 1999 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1109/18.782097    r.  koetter and a.  vardy , `` algebraic soft - decision decoding of reed ",
    "solomon codes , '' _ ieee trans .",
    "inform . theory _",
    "it-49 , no .  11 , pp . 28092825 ,",
    "november 2003 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1109/tit.2003.819332    p.  s. nguyen , h.  d. pfister , and k.  r. narayanan , `` on multiple decoding attempts for reed ",
    "solomon codes , '' _ ieee trans .",
    "inform . theory _",
    "it-57 , no .  2 ,",
    "pp . 668691 , february 2011 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1109/tit.2010.2095202    c.  senger , v.  r. sidorenko , and v.  v. zyablov , `` on generalized minimum distance decoding thresholds for the awgn channel , '' in _ proc .",
    "xii symposium problems of redundancy in information and control systems _ , st . petersburg , russia , may 2009 , pp",
    ". 155163 .",
    "[ online ] .",
    "available : http://k36.org/redundancy2009/proceedings.pdf    c.  senger , v.  r. sidorenko , m.  bossert , and v.  v. zyablov , `` decoding generalized concatenated codes using interleaved reed ",
    "solomon codes , '' in _ proc .",
    "symp . on inform .",
    "toronto , on , canada , july 2008 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1109/isit.2008.4595300      v.  r. sidorenko , c.  senger , m.  bossert , and v.  v. zyablov , `` single - trial adaptive decoding of concatenated codes , '' in _ proc .",
    "international workshop on algebraic and combinatorial coding theory _ ,",
    "pamporovo , bulgaria , june 2008 .",
    "[ online ] .",
    "available : http://www.moi.math.bas.bg/acct2008/b44.pdf    v.  r. sidorenko , a.  chaaban , c.  senger , and m.  bossert , `` on extended forney  kovalev gmd decoding , '' in _ proc .",
    "symp . on inform .",
    "theory _ , seoul , korea , july 2009 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1109/isit.2009.5205900    v.  r. sidorenko , c.  senger , m.  bossert , and v.  v. zyablov , `` single  trial decoding of concatenated codes using fixed or adaptive erasing , '' _ advances in mathematics of communications ( amc ) _ , vol .  4 , no .  1 ,",
    "pp . 4960 , february 2010 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.3934/amc.2010.4.49      j.  h. weber and k.  a.  s. abdel - ghaffar , `` reduced gmd decoding , '' _ ieee trans .",
    "inform . theory _",
    "it-49 , no .  4 , pp . 10131027 , april 2003 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1109/tit.2003.809504"
  ],
  "abstract_text": [
    "<S> traditionally , multi  trial error / erasure decoding of _ reed  solomon ( rs ) _ codes is based on _ bounded minimum distance ( bmd ) _ decoders with an erasure option . </S>",
    "<S> such decoders have error / erasure tradeoff factor @xmath0 , which means that an error is twice as expensive as an erasure in terms of the code s minimum distance . </S>",
    "<S> the _ guruswami  </S>",
    "<S> sudan ( gs ) _ list decoder can be considered as state of the art in algebraic decoding of rs codes . besides an erasure option , it allows to adjust @xmath1 to values in the range @xmath2 . </S>",
    "<S> based on previous work @xcite , we provide formulae which allow to optimally ( in terms of residual codeword error probability ) exploit the erasure option of decoders with arbitrary @xmath1 , if the decoder can be used @xmath3 times . </S>",
    "<S> we show that bmd decoders with @xmath4 decoding trials can result in lower residual codeword error probability than gs decoders with @xmath5 trials , if @xmath4 is only slightly larger than @xmath5 . </S>",
    "<S> this is of practical interest since bmd decoders generally have lower computational complexity than gs decoders . </S>"
  ]
}