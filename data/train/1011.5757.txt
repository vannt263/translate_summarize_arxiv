{
  "article_text": [
    "stigler @xcite developed an asymptotic result for the trimmed mean without requiring continuity of the underlying distribution function associated with the observations .",
    "this result was extended to non - degenerate @xmath0-statistics based on trimmed samples in borovskikh and weber @xcite .",
    "an alternative method for developing robust versions of @xmath0-statistics is to consider the statistic formed by trimming the kernel values , rather than the observations upon which the statistic is based .",
    "this idea is discussed in , for example , serfling @xcite , choudhury and serfling @xcite and gijbels , janssen and veraverbeke @xcite . in this paper",
    ", we use the generalized @xmath2-statistic representation developed in serfling @xcite to obtain an asymptotic result for trimmed @xmath0-statistics under quite general conditions .",
    "we will not require continuity of the relevant , associated distribution at the truncation points .",
    "let @xmath3 be independent identically distributed random variables , taking values in a measurable space @xmath4 and having common distribution @xmath5 let @xmath6 be a symmetric function from @xmath7 to @xmath8 and denote by @xmath9 the right - continuous distribution function of the random variable @xmath10 .",
    "set @xmath11 and let @xmath12 be an enumeration of the values of @xmath13 taken over the @xmath14 @xmath15-tuples in @xmath16 note that these random variables @xmath17 are , in general , dependent .",
    "let @xmath18 denote the ordered values of @xmath19 .",
    "the original @xmath0-statistic is defined as an average taken over the @xmath20 possible outcomes @xmath21 , that is , @xmath22 where the empirical distribution function @xmath23 of @xmath0-statistical structure is defined by @xmath24 and @xmath25 denotes the indicator of the set @xmath26 . for any @xmath27 ,",
    "let @xmath28 $ ] , where @xmath29 $ ] denotes the largest integer less than or equal to @xmath30 if @xmath31 , then put @xmath32 the trimmed versions of @xmath0 are based on trimming the second sum in ( 1 ) , @xmath33 or on trimming of the range of integration in ( [ for1 ] ) , @xmath34 with @xmath35 and @xmath36 where @xmath37 , \\gamma= \\alpha,\\beta.$ ] for the results that follow , it is important to note that the lower bound for the integral in ( [ for4 ] ) is included and the upper bound excluded .",
    "this is critical since @xmath38 is a step function . with this constraint ,",
    "we are able to obtain the asymptotic distribution of @xmath39 without imposing any conditions on the nature of @xmath40 in lemma [ lem2.3 ] , we show that @xmath41 thus , @xmath42 and @xmath43 differ in terms of their divisors , and there are possible subtle differences in the number of summands .    a class of generalized @xmath2-statistics , which includes ( [ for3 ] ) and ( [ for4 ] ) , was introduced by serfling  @xcite .",
    "the trimmed @xmath0-statistics ( [ for3 ] ) and ( [ for4 ] ) are directly connected with generalized lorenz curves , which are important in financial mathematics ( see , for example , goldie @xcite , helmers and zitikis  @xcite ) .    clearly , @xmath44 is an unbiased estimator of @xmath45 in the case @xmath46 and @xmath47 @xmath38 reduces to the usual empirical distribution function . define the left - continuous quantile function @xmath48 for any distribution function  @xmath40 the empirical quantile function @xmath49 has the form @xmath50 a large number of authors have studied the weak convergence of such @xmath2-statistics in the case @xmath51 a partial list consists of chernoff _ et al . _",
    "@xcite , bickel @xcite , shorack @xcite , stigler @xcite , csrgo _ et al . _",
    "@xcite , griffin and pruitt @xcite , cheng @xcite , mason and shorack @xcite . for @xmath52 , under various sets of regularity conditions , asymptotic normality of various types of generalized @xmath2-statistics has been investigated by silverman @xcite , serfling @xcite , akritas @xcite , janssen _",
    "et al . _",
    "@xcite , helmers and ruymgaart @xcite , gijbels _ et al .",
    "_  @xcite and hssjer @xcite .    in the aforementioned papers , for @xmath53",
    ", the results always assumed that @xmath54 is continuous or smooth .",
    "however , in modern statistical robust procedures and for bootstrap procedures , results allowing for the discontinuity of the underlying distribution function @xmath54 are needed .",
    "we study the asymptotic behavior of @xmath55 and @xmath56 for any @xmath57 without imposing the requirement of continuity .",
    "the conditions of our theorem and the limit random variable are defined via the values of quantile function @xmath58 at the points @xmath59 and @xmath60 existing results handle the cases where @xmath61 our main result is derived without this assumption of continuity .",
    "we represent the trimmed @xmath0-statistic as a sum of classical @xmath0-statistics with bounded , non - degenerate kernels plus some smaller terms and then we apply standard results to such statistics .    for convenience , in what follows , for the distribution function @xmath62",
    "we denote the smallest quantile @xmath63 and the largest quantile @xmath64 as , respectively , @xmath65 and @xmath66 with @xmath67 .",
    "let @xmath68 note that @xmath69 and @xmath70 are valid for all @xmath71 and the following events coincide : @xmath72 introduce the functional @xmath73 , where @xmath74\\,\\mathrm{d}h_f(x)\\ ] ] and the following functions with @xmath75 : @xmath76 \\nonumber\\\\ & & { } - \\bigl [ ei\\ { h(x , x_2,\\ldots , x_m ) < \\xi^+_\\alpha\\}\\bigl(h(x , x_2,\\ldots , x_m ) - \\xi^+_\\alpha\\bigr)+\\alpha\\xi^+_\\alpha\\bigr ] -\\theta,\\nonumber\\\\ g_\\alpha(x ) & = & ei\\{h(x , x_2,\\ldots , x_m ) < \\xi^+_\\alpha\\}-\\theta _ \\alpha , \\qquad   \\theta_\\alpha = h_f(\\xi^+_\\alpha-),\\\\ g_\\beta(x ) & = & ei\\{h(x , x_2,\\ldots , x_m ) \\leq\\xi^-_\\beta\\}-\\theta _ \\beta \\nonumber\\\\ & = & 1-\\theta_\\beta- ei\\{h(x , x_2,\\ldots , x_m ) > \\xi^-_\\beta\\},\\qquad   \\theta_\\beta = h_f(\\xi^-_\\beta).\\nonumber\\end{aligned}\\ ] ] note that for all @xmath77 and @xmath75 , we have @xmath78 let @xmath79 and @xmath80    [ teo1.1 ] if @xmath81 then for any underlying distribution function @xmath82 , we have @xmath83 where @xmath84 is a trivariate gaussian random vector with mean vector zero and covariance matrix @xmath85    [ cor1.2 ] for any underlying distribution function @xmath54 , we have , when @xmath86 , @xmath87 where @xmath84 is a trivariate gaussian random vector defined as in theorem [ teo1.1 ] .    [ cor1.3 ] suppose that the quantile function @xmath88 is continuous at the points @xmath59 and @xmath60 if @xmath89 then @xmath90    for the simple case @xmath91 , the functions in ( [ for7 ] ) reduce to @xmath92 a useful application of the theorem for the @xmath93 case is for the kernel @xmath94 @xmath95 this provides the asymptotic behavior of a natural , alternative robust version of the sample variance .",
    "we will now develop explicit expressions for the terms in a more interesting example .",
    "let @xmath96 with @xmath52 .",
    "let @xmath97 be the distribution function of @xmath98 and let @xmath99 then @xmath100 and @xmath101}y\\,\\mathrm{d}h_f(y ) \\nonumber\\\\ & = & i\\{\\xi^+_\\alpha\\leq x \\leq\\xi^-_\\beta\\ } x ( f(x))^{m-1 } - \\int_{[\\xi^+_\\alpha,\\xi^-_\\beta ] } y ( f(y))^{m-1 } \\,\\mathrm{d } f(y ) \\nonumber \\\\ & & { } + \\int_{[\\xi^+_\\alpha,\\xi^-_\\beta ] } \\bigl(i\\{x < y\\ } - f(y-)\\bigr)y \\,\\mathrm{d}(f(y))^{m-1 } , \\nonumber\\\\ g_\\alpha(x ) & = & i\\{x < \\xi^+_\\alpha\\}(f(\\xi^+_\\alpha-))^{m-1 } - ( f(\\xi^+_\\alpha-))^{m } ,   \\nonumber\\\\ g_\\beta(x ) & = & i\\{x \\leq \\xi^-_\\beta\\}(f(\\xi^-_\\beta))^{m-1}-(f(\\xi^-_\\beta))^{m}.\\end{aligned}\\ ] ] in addition , @xmath102 ^ 2\\\\ & & { } + 2eg_{\\alpha\\beta}(x ) [ \\xi^+_\\alpha g_\\alpha(x ) - \\xi^-_\\beta g_\\beta(x)],\\\\ \\sigma_{g_\\alpha}^2 & = & ( f(\\xi^+_\\alpha-))^{2m-1}\\bigl(1 - f(\\xi^+_\\alpha-)\\bigr),\\qquad   \\sigma_{g_\\beta}^2 = ( f(\\xi^-_\\beta))^{2m-1}\\bigl(1 - f(\\xi ^-_\\beta)\\bigr ) , \\\\ eg_{\\alpha}(x)g_{\\beta}(x ) & = & ( f(\\xi^+_\\alpha-)f(\\xi^-_\\beta ) ) ^{m-1 } f(\\xi^+_\\alpha- ) \\bigl(1 - f(\\xi^-_\\beta)\\bigr )   , \\\\",
    "eg_{\\alpha\\beta}(x)g_{\\alpha}(x ) & = & ( f(\\xi^+_\\alpha-))^{m } \\int _ { [ \\xi^+_\\alpha,\\xi^-_\\beta ] } \\bigl(1 - f(y-)\\bigr)y\\ , \\mathrm{d}(f(y))^{m-1 } \\nonumber \\\\ & & { } - ( f(\\xi^+_\\alpha-))^{m } \\int_{[\\xi^+_\\alpha,\\xi^-_\\beta ] } y ( f(y))^{m-1}\\ , \\mathrm{d } f(y),\\\\ eg_{\\alpha\\beta}(x)g_{\\beta}(x ) & = & ( f(\\xi^-_\\beta ) ) ^{m-1}\\bigl(1-f(\\xi^-_\\beta)\\bigr ) \\int_{[\\xi^+_\\alpha,\\xi^-_\\beta ] } y ( f(y))^{m-1}\\ , \\mathrm{d } f(y ) \\nonumber \\\\ & & { } + ( f(\\xi^-_\\beta))^{m-1}\\bigl(1-f(\\xi^-_\\beta)\\bigr ) \\int_{[\\xi^+_\\alpha,\\xi^-_\\beta ] } f(y- ) y\\ , \\mathrm{d}(f(y))^{m-1}.\\end{aligned}\\ ] ]    consider the distribution function @xmath103 then @xmath104 , \\qquad \\sigma^2_g > 0\\end{aligned}\\ ] ] and the limiting behavior is given by @xmath105    however , for the simpler distribution function @xmath106 we have @xmath107 , \\qquad \\sigma^2_g > 0\\end{aligned}\\ ] ] and we get the asymptotic behavior covered by janssen _ et al . _  @xcite , @xmath108",
    "the following two lemmas are key results for the proof .      for @xmath114 , write @xmath115 since @xmath116 ,",
    "@xmath117 = @xmath118 and , by ( [ for6 ] ) , @xmath119 we can write @xmath120\\\\[-8pt ] & & { } - \\delta\\xi_\\beta i\\{n^-_\\beta < n_\\beta\\}(n^-_\\beta - n_\\beta ) .\\end{aligned}\\ ] ] note that @xmath121 and @xmath122 from ( [ for6 ] ) , we have @xmath123 @xmath124 hence , in ( [ for9 ] ) , @xmath125 equation ( [ for8 ] ) follows from ( [ for9 ] ) and ( [ for10 ] ) .",
    "this proves lemma [ lem2.1 ] .",
    "we shall estimate @xmath129 and @xmath130 taking into account the values of the distribution function  @xmath131 at @xmath132 with @xmath133 figures [ fig1 ] and [ fig2 ] illustrate the different situations that need to be considered .",
    "* estimating @xmath142*. noting that @xmath143 , we write @xmath144 it is clear that if @xmath145 , then @xmath146 a.s .",
    "let @xmath147 , as is the case in fig .",
    "[ fig2 ] . in this case ,",
    "@xmath148 and we can write @xmath149 since @xmath150 hence , we always have the relation a.s .",
    "to estimate @xmath151 , we note first that if @xmath152 , then the indicator @xmath153 for all @xmath154 therefore , we have the inequalities @xmath155\\\\[-8pt ] & \\leq & i\\{n_\\alpha < n^-_\\alpha\\}(n^-_\\alpha - n_\\alpha ) ( \\xi^-_\\alpha- h_{nn_\\alpha})i\\{\\xi^-_\\alpha\\geq h_{nn_\\alpha } \\}.%\\nonumber\\end{aligned}\\ ] ]",
    "further , we shall apply the technique used in smirnov @xcite with a probability inequality from hoeffding @xcite ( or see , for example , serfling @xcite , pages 75 and 201 ) .",
    "thus , @xmath156 with some positive constants @xmath157 and @xmath158 depending only on @xmath159 and @xmath160 further , @xmath161 @xmath162 for any small values of @xmath163 , by the definition of the smallest @xmath164-quantile @xmath165 under the conditions of the lemma , @xmath166 as @xmath167 hence , @xmath168 in probability as @xmath169    next , we consider @xmath170 by definition , @xmath171 and since @xmath172 and @xmath173 , it follows that the indicator @xmath174 for @xmath175 and we can write @xmath176 in ( [ for13 ] ) , we need to consider two cases : @xmath177 and @xmath178 in the first case , @xmath179 and we have the weak convergence @xmath180 as @xmath181 and the following estimates which are similar to ( [ for12 ] ) : @xmath182 where @xmath183 in addition , @xmath184 for any small values of @xmath163 because of the definition of the largest @xmath59-quantile @xmath185 hence , in the case @xmath179 , we have @xmath186 in probability as @xmath169 in the second case in ( [ for13 ] ) , @xmath187 and we have the representation @xmath188 where @xmath189 and @xmath190 ) = \\mathrm{o}(n^{-1/2 } ) $ ] as , but the positive term @xmath191 is unbounded . therefore , in this case , we shall apply the estimate ( [ for14 ] ) with @xmath192 instead of @xmath193 that is , @xmath194 @xmath195 @xmath196 since the distribution function @xmath54 is continuous from the right at the point @xmath197 it follows that @xmath198 for any small @xmath199 and sufficiently large  @xmath200 hence , in the second case , @xmath201 and ( [ for14 ] ) is replaced by the inequality @xmath202 which provides the desired convergence @xmath203 in probability as @xmath167 thus , we have proven that @xmath204 in probability as @xmath167    * estimating @xmath205*. noting that @xmath206 , we write @xmath207 here , by analogy with ( [ for12 ] ) , we have @xmath208\\\\[-8pt ] & & \\quad   =   p\\ { h_n(\\xi^-_\\beta-\\varepsilon ) - h(\\xi^-_\\beta-\\varepsilon ) \\geq",
    "n^{-1}n_\\beta- h(\\xi^-_\\beta-\\varepsilon)\\ } \\nonumber\\\\ & & \\quad   \\leq c_1 \\exp\\ { -c_2",
    "n \\theta^2_\\beta(\\xi^-_\\beta,\\varepsilon ) \\}%\\nonumber\\end{aligned}\\ ] ] with @xmath209 and by analogy with ( [ for15 ] ) , @xmath210 here , we need to consider two cases : @xmath211 and @xmath212 in the first case , we apply the inequality ( [ for17 ] ) with sufficiently small @xmath213 in the second case , we use ( [ for17 ] ) again , but with parameter @xmath214 , as in ( [ for16 ] ) , to get @xmath215 since the distribution function @xmath54 has a limit from the left at the point @xmath216 and @xmath217 . in this result , we have @xmath218 in probability as @xmath167    finally , we consider @xmath219 since @xmath220 , we write @xmath221 & = & - i\\{n^-_\\beta < n_\\beta\\}\\sum_{i = n^-_\\beta+1}^{n_\\beta } ( \\xi^+_\\beta- h_{ni})i\\{\\xi^-_\\beta < h_{ni } < \\xi^+_\\beta\\ } i\\ { n^-_\\beta < i \\leq\\dot n^+_\\beta\\}\\nonumber\\\\[-1pt ] & & { } + i\\{n^-_\\beta",
    "< n_\\beta\\}\\sum_{i = n^+_\\beta+1}^{n_\\beta}(h_{ni } - \\xi^+_\\beta)i\\{h_{ni } > \\xi^+_\\beta\\ } i\\ { i > \\dot n^+_\\beta\\ } \\nonumber\\\\[-1pt ] & = & -\\bar j^-_\\beta+ \\bar j^+_\\beta.\\end{aligned}\\ ] ] if @xmath222 , then @xmath223 a.s .",
    "now , assume that @xmath224 in this case , @xmath225 and we have @xmath226 since @xmath227 hence , we always have @xmath223 a.s . to estimate @xmath228 ,",
    "we write @xmath229 and apply the estimates ( [ for13])([for16 ] ) with @xmath230 instead of @xmath231 we have @xmath232 in probability as @xmath233 and hence @xmath234 in probability as @xmath167      proof of theorem [ teo1.1 ] let @xmath235 be a @xmath236-statistic of the form ( [ for1 ] ) with the kernel @xmath237 \\nonumber\\\\ & & { } -   \\bigl [ i\\ { h(x_1,\\ldots , x_m ) < \\xi^+_\\alpha\\}\\bigl(h(x_1,\\ldots , x_m ) - \\xi^+_\\alpha\\bigr)+\\alpha\\xi^+_\\alpha\\bigr ] .",
    "\\nonumber\\end{aligned}\\ ] ] we see that @xmath238 it is not difficult to verify for this function that @xmath239 and @xmath240 ; in addition , @xmath241 , by the condition of the theorem .",
    "hence , the kernel @xmath242 is non - degenerate and , by the central limit theorem for @xmath236-statistics with such bounded kernels , we have the weak convergence @xmath243 as @xmath181 ( see , for example , borovskikh @xcite ) . by the same central limit theorem , we have @xmath244 and @xmath245 as @xmath167 under the conditions of the theorem , we have @xmath246 if @xmath247 ( in this case , @xmath248 ) and @xmath249 if @xmath250 ( in this case , @xmath251 ) .",
    "further , it is easy to prove that the covariances @xmath252 as @xmath181 , where @xmath253 now , apply lemma [ lem2.2 ] to complete the proof of theorem [ teo1.1 ] .",
    "choudhury , j. and serfling , r.j .",
    "generalized order statistics , bahadur representations and sequential nonparametric fixed - width confidence intervals .",
    "_ j. statist .",
    "plann . inference _",
    "* 19 * 269282 ."
  ],
  "abstract_text": [
    "<S> we adapt the techniques in stigler [ _ ann . </S>",
    "<S> statist . _ </S>",
    "<S> * 1 * ( 1973 ) 472477 ] to obtain a new , general asymptotic result for trimmed @xmath0-statistics via the generalized @xmath1-statistic representation introduced by serfling [ _ ann . </S>",
    "<S> statist . _ </S>",
    "<S> * 12 * ( 1984 ) 7686 ] . unlike existing results </S>",
    "<S> , we do not require continuity of an associated distribution at the truncation points . </S>",
    "<S> our results are quite general and are expressed in terms of the quantile function associated with the distribution of the @xmath0-statistic summands . </S>",
    "<S> this approach leads to improved conditions for the asymptotic normality of these trimmed @xmath0-statistics . </S>"
  ]
}