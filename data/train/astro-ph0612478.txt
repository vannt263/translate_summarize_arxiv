{
  "article_text": [
    "the large - scale structure of the universe is one of the most powerful probes of the universe .",
    "the structure of the galaxy distribution is a consequence of how our universe began , how it has been evolved with time , and what the universe is made of .",
    "galaxy distributions are inherently statistical , and methods of quantifying them are not uniquely given .",
    "the counts - in - cells ( cic ) analysis , which we consider in this paper , is one of the most simple methods among them . after quantifying the observed galaxy distributions by some statistical quantity ,",
    "the cosmological parameters are estimated by that quantity .    according to the observations of the temperature anisotropy of the cosmic microwave background radiation ( cmb ) , such as the wilkinson microwave anisotropy probe ( wmap ) @xcite and magnitude - redshift relation of type ia sne ( snia ) @xcite , the cosmological",
    "constant is necessary to account for the behavior of the universe .",
    "however , in order to understand the evolution of structures , it is also important to explore structures in different epochs .",
    "galaxy distributions probe more recent universe than observations such as cmb and snia .",
    "recent galaxy redshift surveys , such as the aat two - degree field galaxy redshift survey ( 2dfgrs ) and the sloan digital sky survey ( sdss ) reveal the large - scale structure of the mostly present universe @xcite . by combining the data of the galaxy distributions and other observations like wmap , many cosmological parameters are accurately estimated @xcite .",
    "one of recent trends of the parameter estimation is to use a number of independent observations in order to improve constraints of the parameters as accurate as possible .",
    "other one is to constrain the cosmological parameters from independent observations in order to make cross - checks of a cosmological model .",
    "the latter one is important because the assumed cosmological model is not guaranteed to be correct .",
    "for example , the dark energy is introduced just as a parameter , not knowing the deep nature . on the other hand ,",
    "there are many efforts to explain an acceleration of the universe without introducing dark energy .",
    "people are trying to explain the acceleration of the universe by , for example , a back reaction due to super - horizon density fluctuations , modifications of gravity , and so on @xcite .    in estimating cosmological parameters from independent observations , some of the parameters can not be determined with good accuracy because of possible weak signals or degeneracies between parameters .",
    "for example , when we consider the cosmological parameter estimation from the cmb , the free streaming dumping due to neutrinos is less significant than that in the present large - scale structure .",
    "when we consider the cosmological parameter estimation from the large - scale structure , the silk dumping due to baryons and the free streaming due to neutrinos show similar dumping in the power spectrum on small scales .",
    "each observation excels others at estimating some parameters but is not good at estimating other parameters .    in this paper",
    ", we consider parameter estimations using only a cic analysis of the large - scale structure . in the cic analysis",
    ", one needs a smoothing function , which is a function of distance from a center of each cell .",
    "usually , the top - hat function and the gaussian function are used . the top - hat function is often used for counting galaxies in each cells .",
    "the gaussian smoothing function is used when we need to smooth out small - scale clustering and to obtain large - scale properties of clustering .",
    "for example , @xcite used a gaussian - like smoothing function for that purpose .",
    "although top - hat and gaussian functions are simple , they are not necessarily optimal for estimating cosmological parameters . in this study",
    ", we investigate effects of the choice of smoothing functions .",
    "we introduce a series of smoothing functions : the @xmath0-weight epanechnikov kernels .",
    "the top - hat function and the gaussian function are two special cases in this series .",
    "since this function has intermediate properties between these two functions , we expect that it is useful to search for better function in analyzing the large - scale structure .",
    "since the @xmath0-weight epanechnikov kernel has a finite support , its fourier counterpart of the kernel , @xmath2 , oscillates as a function of @xmath3 .",
    "this property leads us to expect a possibility that we can find a specific smoothing function which is sensitive to oscillating features in the power spectrum , such as the baryon acoustic oscillations ( bao ) .",
    "this paper is organized as follows . in   [",
    "sec : cic - epa ] , we briefly summarize the cic analysis and the @xmath0-weight epanechnikov kernels . in   [ sec : fisher ] , our methods using the covariance matrix in analytic form with the fisher information matrix are explained . in   [ sec : results ] , we present numerical results of our study . conclusions and",
    "discussion are given in ",
    "[ sec : discussion ] .",
    "we consider a cic analysis of the galaxy distribution on large scales .",
    "the cic analysis is one of the methods to analyze the large - scale structure .",
    "first of all , a number of cells are randomly distributed in a survey volume and the number of galaxies are counted in each cell .",
    "next , the moments , or semi - invariants , are calculated from the numbers of galaxies in those cells .",
    "the cic analysis has an advantage that it is simpler to analyze than more complex statistics such as the two - point correlation function and the power spectrum , etc .",
    "behaviors of the statistical errors are also studied well @xcite .",
    "the cic analysis was developed by @xcite and applied to the iras and stromo - apm redshift survey @xcite . in these papers , they measured a count probability distribution function , @xmath4 , which is a probability that a cell contains @xmath5 galaxies in a spherical cell .",
    "they obtained the second moment of the distribution function from likelihood fitting of the distribution function to an analytic log - normal function .",
    "recently , a skewed log - normal function is used as an improved analytic function @xcite . in this study",
    ", we simply consider the second moments of the galaxy counts , which directly obtained by averaging the square of galaxy counts @xcite .",
    "the cic analysis is related to the smoothed density field with a smoothing function @xmath6 : @xmath7 where @xmath8 is a 3-dimensional density contrast and @xmath9 is a smoothing scale . in this paper",
    ", we use a normalization @xmath10 this normalization is adopted in such a way that top - hat smoothing function has a normalization , @xmath11 , @xmath12 .",
    "when the function is not a top - hat one , this normalization is just a convention .",
    "the second moment of the density contrast is given by @xcite @xmath13 where @xmath14 is the two - point correlation function , @xmath15 is the power spectrum , and @xmath16 is a fourier counterpart of the smoothing function , which is a real function for a spherical smoothing function .",
    "similarly , the higher - order moments , @xmath17 , @xmath18 , @xmath19 are given by higher - order correlation functions and polyspectra .",
    "the density contrast @xmath8 is a smooth function of space , while the count of galaxy is a discrete number .",
    "we consider the case that galaxies are counted in each cell with a weight function @xmath20 , which is a same function we introduced above as a smoothing function .",
    "each galaxies are counted with a weight according to the distance from centers of cells .",
    "the count of galaxies @xmath5 in a cell is defined by @xmath21 where @xmath22 is a position of each galaxies , and @xmath23 is a center of the cell . for a top - hat smoothing function , the above quantity exactly corresponds to a number of galaxies in a sphere of radius @xmath9 , and @xmath5 is a non - negative integer . in general smoothing functions , @xmath5 is not necessarily an integer , despite its notation .",
    "hereafter we call @xmath5 a weighted count .    in a case of the top - hat smoothing function ,",
    "relations between moments of the smoothed density contrast and moments of the galaxy counts are given in @xcite .",
    "we need to generalize such relations to the cases of general smoothing function .",
    "we derive those relations in appendix  [ ap : moments - counts ] .",
    "the second moment of the density contrast is related to the galaxy counts by equation  ( [ eq : sigma ] ) , @xmath24 where @xmath25 is the weighted count averaged over all cells , @xmath26 is the second moment of the weighted count , and @xmath27 the right hand side of equation  ( [ eq:50 ] ) are given only by observable quantities .",
    "the second term is a shot noise term .",
    "relations between higher - order moments of the density contrast and that of weighted counts are given in the appendix  [ ap : moments - counts ] , although we focus only on the second moments below .",
    "the choice of the smoothing function @xmath6 remains arbitrary in the analysis explained above . the top - hat function @xmath28 where @xmath29 is a heaviside step function ,",
    "is usually adopted in the cic analysis .",
    "another choice is a gaussian function , @xmath30 in this study , we introduce a series of smoothing functions which has an intermediate properties of the two : the @xmath0-weight epanechnikov kernel .",
    "this series of functions are defined by @xmath31 in this smoothing function with positive weight @xmath0 , the weight is large near the center of cells and small near the edge of cells . in the case",
    "@xmath32 , this kernel is the top - hat function of equation  ( [ eq:70 ] ) .",
    "the original epanechnikov kernel @xcite corresponds to @xmath1 , and the @xmath0-weight kernel of @xmath33 is a generalized kernel of the original one .",
    "the fourier counterparts of the epanechnikov kernels are given by @xmath34 since the @xmath0-weight epanechnikov kernel has a finite support , its fourier counterpart @xmath2 oscillates as a function of @xmath3 .",
    "one can expect a possibility that there is a specific smoothing function which is sensitive to a certain physical feature in the power spectrum , such as the baryon acoustic oscillations ( bao ) .    in the @xmath0-weight epanechnikov kernels with a large weight @xmath0 , the weight near the edge of the cells , @xmath35 is very small",
    ". therefore the characteristic radius of the kernel is not given by the radius of the support @xmath9 .",
    "instead , it is useful to define an effective radius @xmath36 of the @xmath0-weight epanechnikov kernel as a characteristic radius : @xmath37^{1/2 }    = \\left(\\frac{3}{2m+5}\\right)^{1/2}r .",
    "\\label{eq : reff}\\ ] ] when we take the limit of @xmath38 fixing the effective radius @xmath36 , the @xmath0-weight epanechnikov kernel is shown to be reduced to the gaussian function @xmath39 @xcite . therefore , the series of @xmath0-weight epanechnikov kernels contain both the top - hat function ( @xmath32 ) and the gaussian function ( @xmath40 ) as special cases .",
    "although taking a simple limit of @xmath41 results in divergent expressions in this paper because of our normalization convention , the derived observable quantities are still regular in this limit .",
    "the main purpose of this study is to find an appropriate smoothing function .",
    "since the degrees of freedom in choosing the smoothing function are infinitely large , we constrain ourselves in searching an optimal weight @xmath0 of the @xmath0-weight epanechnikov kernels . to this end",
    ", we use the method of fisher information analysis .",
    "this analysis is a method to theoretically estimate expected parameter bounds that can be achieved with an unbiased estimator @xcite .",
    "this analysis is often used in order to estimate how well one can constrain cosmological parameters in a given observation ( * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* etc . ) .",
    "the fisher information matrix @xmath42 is defined by @xmath43 where @xmath44 is a likelihood function of model parameters @xmath45 when a set of data @xmath46 is given .",
    "the average is taken over assumed distribution of data , which is specified by a fiducial model with a set of parameters @xmath45 . when the likelihood function has the maximum at a set of fiducial model parameters , the first derivatives of the likelihood should vanishes .",
    "the second derivatives specify how the likelihood function is peaked at the maximum point .",
    "thus , the fisher matrix is a useful quantity to estimate how one can constrain model parameters in a likelihood analysis .",
    "in fact , when only one parameter @xmath47 is estimated , fixing other parameters , there is a cramr - rao inequality @xcite , @xmath48 where @xmath49 is a deviation of that parameter , and the right hand side of equation  ( [ eq : bound ] ) is a square of a standard deviation . in the limit of a very large data set ,",
    "the inequality becomes an equality .",
    "therefore , the diagonal elements of a fisher matrix offer criteria of how powerful a given analysis is .",
    "when multiple parameters are simultaneously estimated , there is a generalized correspondence , @xmath50 in the limit of a very large data set .",
    "therefore , expected parameter bounds by a given data set can be estimated by calculating a fisher matrix .    according to the bayes theorem , the likelihood function in equation  ( [ eq:120 ] )",
    "is given by @xmath51 where @xmath52 is the conditional probability distribution function of the data @xmath46 for a given set of parameters @xmath53 , @xmath54 is the prior distribution function of parameters . the prior distribution function of data @xmath55 plays a role of just a normalization in the bayes theorem .",
    "we assume in the below that there is not any prior knowledge of the parameters . in that case , the prior distribution function @xmath54 is constant , and @xmath56 as functions of parameters @xmath45 . in equation  ( [ eq:120 ] ) , @xmath44 can be replaced by @xmath52 . when the distribution of data @xmath46 is given by a multivariate gaussian function , @xmath57 , \\label{eq : lf}\\ ] ] where @xmath5 is the dimension of the data vector @xmath46 , i.e. , the number of data .",
    "the @xmath58 matrix @xmath59 is a covariance matrix given by @xmath60 where the average is taken over data @xmath46 , which distribution is given by a set of model parameters @xmath45 .",
    "thus , the covariance matrix explicitly depends on model parameters @xmath45 . the fisher matrix for a multivariate gaussian distribution of equation  ( [ eq : lf ] ) is given by @xcite @xmath61    + \\frac{\\partial\\langle\\boldsymbol{x}\\rangle^t }    { \\partial\\theta_i}\\boldsymbol{c}^{-1 }    \\frac{\\partial\\langle\\boldsymbol{x}\\rangle}{\\partial\\theta_j}. \\label{eq:140}\\ ] ]    in reality , the distribution of data is generally not a multivariate gaussian . even in that case ,",
    "fisher matrix of equation  ( [ eq:140 ] ) is still useful to estimate the expected parameter bounds .",
    "in fact , @xcite compares the fisher information matrix analysis and the markov chain monte carlo ( mcmc ) method by using a simulation . according to their results",
    ", the fisher matrix analysis and mcmc method agrees well , when the likelihood function is not much different from a ( multivariate ) gaussian function .",
    "when the likelihood function is sufficiently peaked at the maximum , the fisher matrix analysis gives a good prediction for expected parameter bounds .",
    "the fisher matrix is calculated by equation  ( [ eq:140 ] ) , once a covariance matrix @xmath59 is obtained as a function of model parameters .",
    "we use a second moment of the cic as a set of data @xmath46 . for a fixed smoothing function , the second moments @xmath62 is a function of a smoothing radius , @xmath9 .",
    "we assume that we have a set of data which consists of second moments with various @xmath9 , and the model parameters are estimated by a maximum likelihood analysis .",
    "therefore , the data vector is given by @xmath63^{\\rm t } , \\label{eq:150}\\ ] ] where @xmath64 are a given set of smoothing radii .",
    "the values of the smoothing radii are chosen so that the density fluctuations are modeled by linear theory and we treat the problem as analytic as possible .",
    "thus the minimum value of the smoothing radius @xmath65 can not be arbitrarily small .",
    "on the other hand , the smoothing radius can not be arbitrarily large because the radius can not be larger than a survey size .",
    "the number of data , which is the same as the number of smoothing radii , can be arbitrary chosen .",
    "the larger the number of data is , the tighter the parameters are constrained .",
    "however , second moments with slightly different smoothing radii do not have quite independent information .",
    "this property is taken into account in our analysis as we will see below .",
    "the matrix elements of the covariance matrix we need is therefore given by @xmath66      \\left [        \\sigma^2(r_j ) -        \\left\\langle \\sigma^2(r_j ) \\right\\rangle      \\right ]    \\right\\rangle .",
    "\\label{eq:160}\\ ] ] the calculation of this covariance matrix is not trivial . we develop a method to analytically calculate this matrix under certain approximations , which is technically a main elaboration of this work .",
    "the details are described in appendix  [ ap : covariance - matrix ] .",
    "the statistical distribution of the second moments depends on the individual properties of galaxy samples , such as the density of galaxies , the size of the survey volume , etc .",
    "these properties are taken into account in the calculation of the covariance matrix . in the calculation",
    ", we allow the volume of a cell can be overlapped to that of another cell .",
    "therefore , the number of cells placed in the survey volume is not limited .",
    "we adopt an approximation that a survey volume has a spherical shape with a radius @xmath67 .",
    "the boundary effects of the survey volume are neglected .",
    "these approximations are useful for an analytical tractability of the calculation ( appendix  [ ap : covariance - matrix ] ) .",
    "the first sample we consider is the one which is similar to the main galaxy sample of sdss .",
    "we refer this sample as mg . in this sample ,",
    "the number density of galaxies is set to be @xmath68 .",
    "the survey size is set by a radius @xmath69 .",
    "the second sample is the one which is similar to the luminous red galaxy sample of sdss .",
    "we refer this sample as lrg .",
    "this sample is characterized by @xmath70 and @xmath71 .",
    "the redshifts of galaxies in both samples are not large and we simply neglect redshift evolution of galaxy clustering .",
    "we also neglect the bias for simplicity , although the real samples in the sdss has a certain bias .",
    "the qso sample in the sdss has very sparse density @xcite and we do not consider a sample of this kind . we do not mean to make mg and lrg to resemble the actual sdss survey . instead , we intend to contrast two different types of sample .",
    "since we neglect the redshift evolution of clustering and the bias , the power spectrum of both samples are identical .",
    "the main difference is the survey volume and the number density , which are decisive factors in cosmological parameter estimations .    in the fisher analysis",
    ", we need to assume maximum likelihood estimates of parameters , which is called fiducial model parameters .",
    "we adopt the fiducial parameters as @xmath72 , where @xmath73 is the matter density parameter , @xmath74 is a fraction of the density against the matter density , @xmath75 is the neutrino density parameter , @xmath76 is the hubble constant normalized by @xmath77 , @xmath78 is the spectral index of the primordial power spectrum , and @xmath79 is the standard normalization of the density fluctuations .",
    "the bias factor of both samples , mg and lrg , are assumed to be unity . in order to obtain the power spectrum of the present universe , we calculate the transfer function by the cmbfast code @xcite . normalization of the power spectrum is determined by setting @xmath79 . to ensure that the typical scale of fluctuations should not be in strongly nonlinear regime , we only use effective smoothing radii of equation  ( [ eq : reff ] ) which satisfies @xmath80 .",
    "the largest smoothing radii should be fairly smaller than the survey size , since we neglect boundary effects of the survey volume . in our calculation",
    "below , the largest radii are chosen as @xmath81 for the mg and @xmath82 for the lrg .",
    "linearly equal spacings of smoothing radii @xmath83 in equation  ( [ eq:150 ] ) are adopted .",
    "the number of smoothing radii @xmath5 are varied in the following analysis .",
    "the number of cells placed in the survey volume @xmath84 are given by @xmath85 .",
    "in figure  [ fig : fig1 ] , we show the second moments @xmath86 and their statistical errors as functions of @xmath36 for both the mg and the lrg .",
    "these are analytically given by equations  ( [ eq : variance ] ) and ( [ eq : b21 ] ) .",
    "in this figure , the solid line is the second moment of the fiducial model , which is common to both samples , dashed line is an expected error for the mg and dot - dashed line is an error for the lrg .",
    "relatively flat errors on larger scales are dominated by cosmic variance , which are less for the lrg than the mg because of the larger sampling volume .",
    "a little decrease of the error in mg around @xmath87 is due to the boundary effect which is not properly taken into account in our analytic calculation . on scales where the boundary effect is significant , errors due to",
    "the cosmic variance is already larger than the signal , and we do not have to worry about the boundary effect . increasing errors toward smaller scales",
    "are due to the shot noise , which is less for the mg because the mg is denser than the lrg .",
    "as mentioned above , we only use the large scales , @xmath88 , where the errors are dominated by cosmic variance , and thus the lrg has larger signal to noise ratio than that of the mg .    in figure  [",
    "fig : fig1 ] , there is a little decrease in the cosmic variance at @xmath89 in the case of the mg sample .",
    "this is caused by our approximation to neglect the boundary effects as described in appendix  [ ap : covariance - matrix ] .",
    "therefore , when @xmath9 becomes comparable to @xmath67 , the cosmic variance is underestimated . however , the signal is already dominated by the cosmic variance in this regime , and this effect does not affect the results .",
    "the number of cells placed in the survey volume @xmath90 are given by @xmath85 , as mentioned in the previous section .",
    "the number affects the results through a factor @xmath91 appearing in equation  ( [ eq : b21 ] ) .",
    "the first line of equation  ( [ eq : b21 ] ) represents the shot noise , the second line the shot noise from overlapping regions , and the third line the cosmic variance . in increasing the numbers of cells for both the mg and the lrg , the shot noises decrease as mentioned by @xcite .",
    "however , the shot noise from overlapping regions becomes dominant on small scales @xmath92 @xmath93 mpc .",
    "in addition , the statistical erros are dominated by the cosmic variances on @xmath94 @xmath93 mpc , and the factor appearing in the third line of equation  ( [ eq : b21 ] ) is @xmath95 0.01 at most .",
    "therefore , we can find from equation  ( [ eq : b21 ] ) that the numbers of cells are sufficient and that increasing the number of cells does not affect the following results : the statistical error does not diminish more than @xmath96 if the number of cells is increased .    on the other hand , in decreasing the number of cells , scales dominated by the shot noise become larger , and the signal to noise ratio diminishes . for the mg , decreasing the number of cells to one tenth of the present number does not affect the signal to noise ratio so much .",
    "however , decreasing the number to one hundredth significantly lowers the ratio .",
    "therefore , the number of cells is enough for the cosmic variance to dominate the shot noise on @xmath97 @xmath93 mpc .",
    "the shot noise contributes the error only @xmath98 on that scale . for the lrg , decreasing to one tenth significantly reduces the signal to noise ratio , since the shot noise is comparable to the cosmic variance on scales of @xmath99 @xmath93 mpc .",
    "a hundred times larger number of cells than the present number is necessary to suppress the shot noise contribution to the same level as the mg on @xmath97 @xmath93 mpc .",
    "therefore , increasing the number of cells enlarges the signal to noise ratio on scales of @xmath100 @xmath93 mpc and would slightly tighten constraints of the parameters .",
    "figure  [ fig : fig2 ] shows how the matter density parameter and the baryon fraction are constrained by plotting the diagonal elements of the corresponding fisher matrix as functions of the numbers of data , i.e. , the number of smoothing radius @xmath5",
    ". this number can be arbitrarily large because this number is artificially chosen .",
    "for larger numbers of data , the fisher diagonal elements are larger and expected error bounds become smaller .",
    "however , the fisher diagonal elements cease to increase for sufficiently large numbers of data , because the second moments of similar smoothing radii do not carry independent information .",
    "therefore , the saturation values of the fisher diagonal elements for the large numbers of data indicate the expected error bound from the analysis of second moments .    according to this figure ,",
    "the mg with about 400 data points is enough to obtain nearly minimum errors for both @xmath73 and @xmath101 .",
    "that means increasing the numbers of data above 400 is not efficient . in the lrg ,",
    "about 600 data points are enough .",
    "the lrg can constrain the cosmological parameters more tightly than the mg sample , because of the large volume . for both the mg and the lrg , expected errors for other parameters have similar tendencies .",
    "the saturation values are different for different @xmath0 , which shows effects of smoothing functions for the parameter estimation .",
    "the fisher diagonal elements in both parameters are largest when we use @xmath1 ( original ) epanechnikov kernel . using the top - hat and gaussian functions are nearly worst among @xmath0-weight epanechnikov kernels .",
    "improvements of the expected errors are about 14% for the lrg and 11% for the mg",
    "( in each case ) .",
    "although the improvement is not so significant , using the epanechnikov kernel is definitely better than using top - hat and gaussian kernels as a smoothing function .",
    "the reason why the epanechnikov kernel is better than top - hat and gaussian kernel will be discussed in the next section .",
    "there is another suggestion in this figure .",
    "for example , expected errors for @xmath102 by the top - hat ( @xmath32 ) function are almost the same as @xmath103 by the @xmath1 epanechnikov function in every case . in this case",
    ", optimizing the smoothing function has the same effect as increasing the data points with respect to the parameter estimation . in practice , increasing data points increases computational costs of evaluating the likelihood function . using the optimized smoothing function",
    "has an advantage in this respect .    in figure",
    "[ fig : fig2 ] , the expected errors for weights @xmath32 and @xmath1 are quite different in both the mg and the lrg .",
    "it is natural to consider non - integer weights to looking for more optimal function .",
    "figure  [ fig : fig6 ] shows the dependence of the fisher diagonal elements for @xmath73 against the weight @xmath0 .",
    "it follows from this figure that @xmath104 kernel is slightly better than the @xmath1 kernel for both the mg and the lrg .    to test the effect of bao in the power spectrum ,",
    "we compare the fisher matrix elements with and without the baryonic component in the power spectrum .",
    "figure  [ fig : nobaryon ] shows a result .",
    "panel  ( a ) shows a dependence of the value of fisher matrix element @xmath105 with the baryonic component .",
    "the fiducial model of the panel  ( a ) is the same as that explained in ",
    "[ sec : fiducial ] .",
    "panel  ( b ) shows a same dependence as the panel  ( a ) but in the pure cdm model .",
    "the fiducial parameters in this panel are assumed to be @xmath106 . in the panel",
    "( b ) , we use the fitting formula of @xcite to calculate the transfer function in the pure cdm model .",
    "if the bao plays a main role in the improvement of parameter constraints , it is expected that the pure cdm model does not show any dependences on weight of the kernels , which is not found in this study .",
    "therefore , we conclude that the improvements come from other reasons , such as an overall envelope of the smoothing function or covariances .",
    "in addition , if the oscillation feature is the main reason , we expect the constraint for baryon fraction parameter is especially tightened , which is also not found in this study .",
    "therefore , the fact that the epanechnikov kernel of @xmath1 gives the tightest constraints for every parameter also supports this conclusion .",
    "figure  [ fig : fig3 ] and figure  [ fig : fig4 ] demonstrate expected parameter bounds for the lrg and for the mg , respectively . in both figures ,",
    "solid lines represent @xmath107 confidence ellipsoids when we carry out two - parameter likelihood analysis fixing all the other parameters .",
    "dashed lines show the @xmath107 confidence ellipsoids when we carry out likelihood analysis for the all parameters at a time and marginalized over the all parameters but two . in all cases ,",
    "the lrg can constrain the parameters more tightly than the mg , because the survey volume is larger in lrg .",
    "the expected parameter bounds in the case all the other parameters are marginalized over are much broader than in the case of just fitting only two parameters .",
    "parameter bounds for @xmath108 , @xmath76 , and @xmath109 are especially broadened . this is mainly because there are degeneracies among these parameters , which one can notice in the figures  [ fig : fig3 ] and [ fig : fig4 ] .",
    "therefore , simultaneous determination of all the parameters considered here is not efficient when only the second moments are used .",
    "it is rather preferable to consider that such degenerate parameters are sufficiently constrained by other observations .",
    "figure  [ fig : fig5 ] shows the parameter bounds in the case that @xmath76 and @xmath109 are fixed . dashed lines are @xmath107 confidence ellipsoids for the mg .",
    "the solid lines are for the lrg .",
    "one sees that the expected bounds are much tighter than previous figures , and degeneracies between parameters are resolved .",
    "we consider the cic analysis of the large - scale galaxy distribution .",
    "we estimate the expected parameter bounds from the second moments by means of the fisher matrix analysis , considering sdss - like surveys as working examples . in this analysis",
    ", we investigate a series of smoothing functions , expecting that there is an optimal smoothing function with respect to the parameter bounds .",
    "we derive an analytic form of the covariance matrix . as a result",
    ", we found that it is possible to improve the parameter bounds by using an optimized kernel ; the epanechnikov kernel gives a better parameter bounds than traditional top - hat and gaussian kernels .",
    "as previous study shows , the lrg sample is more suitable than the mg sample for parameter estimation because of the larger observational volume .",
    "we carried out two other tests to investigate the reason why the epanechnikov kernel gives the tightest constraints among all generalized epanechnikov kernels .",
    "first , we test the hypothesis that the oscillating phases in the power spectrum and that in smoothing kernels are synchronized with each other .",
    "it seems this hypothesis is not realistic because of the comparison in figure  [ fig : nobaryon ] .",
    "actually , we do not find clear evidence of the phase synchronization , directly comparing the both oscillations .",
    "second , we test the hypothesis that the signal to noise ratio significantly depends on the shape of the kernels . as a result",
    ", we do not find signficant difference between the top - hat smoothing function and the epanechnikov kernels .",
    "therefore , we have not identify a clear reason why the epanechnikov kernel is the best , which remains to be studied in the future work .    from our results ,",
    "the following points are notable for parameter estimation .",
    "about 400 and 600 different smoothing scales are sufficient to minimize the parameter bounds for the mg sample and lrg sample , respectively . due to the covariance between data with different smoothing scales ,",
    "too many data with different smoothing radii have a redundant information .",
    "in addition , the parameters @xmath110 , @xmath76 , and @xmath109 degenerate in the parameter estimation .",
    "this degeneracy is due to the fact that varying these parameters similarly change the shape of the power spectrum on scales of interest .    in this analysis",
    ", we do not explicitly consider redshift - space distortion effects . in treating an actual galaxy distributions , radial distances",
    "are measured by redshifts , and the redshift - space clustering of galaxies is the observable @xcite . in equations  ( [ eq : b21 ] ) and ( [ eq : b22 ] ) , integrations over @xmath111 and @xmath112 do not have anything to do with a line - of - sight direction .",
    "thus , integrations of equations  ( [ eq : same ] ) and ( [ eq : diff ] ) results in equations  ( [ eq : xibarsame ] ) and ( [ eq : xibardiff ] ) .",
    "in addition , we can take @xmath113-axis as a line - of - sight direction in integrating over @xmath114 .",
    "therefore , we find that this modifies the covariance matrix in such a way that an additional factor is added to the cosmic variance . as a result ,",
    "the last terms of equations  ( [ eq : b21 ] ) and ( [ eq : b22 ] ) are multiplied by a factor @xmath115 , where @xmath116 is a redshift - space distortion factor and is approximately given by @xmath117 , and @xmath118 is the linear bias factor .",
    "therefore , the redshift - space effects are absorbed in the normalization of the power spectrum .    in appendix",
    "[ ap : moments - counts ] , we derive relations between higher - order moments , and galaxy counts for an arbitrary smoothing function .",
    "although we analyze only second moment in this paper , higher - order moments provide additional information on cosmology .",
    "one can expect the possibility to search for an optimal smoothing function for the higher - order moments in cic analysis . by combining the second moment and higher - order moments",
    ", one can break the degeneracy between the bias @xmath118 and the normalization @xmath79 and reduce other degeneracies in parameters @xcite .",
    "theoretical predictions for the higher - order moments can be found in @xcite . in a case involving bias parameter , relations between reduced moments of galaxies and that of matter are given in @xcite .",
    "however , analytical treatment of the covariance matrix for higher - order moments will be more involving . in that case",
    ", some numerical evaluation of the covariances would be a realistic method .    in the case of evaluating the power spectrum @xmath15 of the 2dfgrs ,",
    "10 simulated realizations are used to take into account non - linear effects , redshift - space effects , and geometric effects @xcite . to obtain an accurate covariance matrix of @xmath15",
    ", they need about 1000 realizations .",
    "it is not realistic to run full n - body simulations , and they use realizations of random gaussian fields for that purpose .",
    "otherwise , one can use the pthalos code to generate the mock galaxy distribution that are based on the conjunction of a halo model and a second - order perturbation theory @xcite .",
    "in addition , when we carry out the likelihood analysis with many parameters , the grid - based likelihood analysis is also unrealistic because of the cost of cpu time .",
    "recently many teams use the mcmc method @xcite to obtain the maximum likelihood of parameters in a reasonable time scale .",
    "we wish to thank seiko inoue for her help in earlier stages of this work .",
    "we acknowledge the cmbfast code which is publicly available . t.m .",
    "acknowledges support from the jsps grant - in - aid for scientific research , 18540260 , 2006 .",
    "in this section , we obtain a expression of a second moment of density contrast in terms of statistics of numbers of galaxies in a cell , following a similar procedure given by @xcite .",
    "first , we divide the cells into a series of infinitesimal volumes , @xmath119 , as shown in figure  [ fig : fig8 ] .",
    "a number of galaxies , @xmath120 , in an infinitesimal volume @xmath119 is either 0 or 1 .",
    "therefore , @xmath121 where @xmath122 is a mean number density of galaxies in the universe .",
    "the count of galaxies @xmath5 defined by equation  ( [ eq:40 ] ) is given by @xmath123 where the origin of coordinates is taken at the center of the cell @xmath124 .",
    "the mean value of the count is given by @xmath125 where @xmath126 .",
    "similarly , a mean square of @xmath5 is calculated as @xmath127 therefore , we obtain a relation between the number of galaxies and the second moment by using equation  ( [ eq : variance ] ) @xmath128 where @xmath129 is given by equation  ( [ eq:60 ] ) .",
    "below , we need a generalized quantity @xmath130 which is defined by @xmath131 in the case of @xmath0-weight epanechnikov kernel , this quantity is analytically calculated and is given by @xmath132 where @xmath133 is the gamma function . for the top - hat smoothing function ( @xmath32 ) ,",
    "the quantity @xmath130 is simply unity for any @xmath134 .      a similar relation for the third moments , or its reduced quantity skewness , can be found . in calculating @xmath135",
    ", there exist a term with a weight of @xmath136 .",
    "we need to define another kind of galaxy count by @xmath137 : which corresponds to a weighted count with a smoothing function @xmath138 .",
    "the mean value of this count is given by @xmath139 in the following , we also need a quantity , @xmath140 where @xmath141 is the two - point correlation function and we define @xmath142 note that @xmath143 .",
    "we are ready to calculate @xmath144 for an arbitrary smoothing function .",
    "it is given by @xmath145 where @xmath146 is an ensemble average of the third power of a smoothed field and corresponds to a volume average of the three - point correlation function ,",
    "@xmath147 : @xmath148 the skewness parameter is defined by @xmath149 by using equations  ( [ eq:2nd - cross - moment ] ) - ( [ eq : averaged-3pt ] ) , we obtain @xmath150      the fourth moment , or its reduced quantity kurtosis , is similarly calculated as above .",
    "we define @xmath151 where @xmath152 is defined by @xmath153^{-1}. %   \\nonumber \\\\",
    "\\label{eq : zeta}\\end{aligned}\\ ] ] the fourth moment of galaxy count @xmath154 is obtained as @xmath155 where @xmath156 is a volume average of the four - point correlation function , @xmath157 , and is given by @xmath158 the reduced kurtosis is defined by @xmath159 therefore , by using equations  ( [ eq:2nd - cross - moment ] ) and ( [ eq:3rd - cross - moment ] ) - ( [ eq : averaged-4pt ] ) , we obtain @xmath160      \\left [        \\left\\langle n^2 \\right\\rangle -        \\left\\langle n \\right\\rangle \\overline{w } -        \\left\\langle n \\right\\rangle^2      \\right]^{-3}\\end{aligned}\\ ] ]",
    "in this appendix , we derive an analytic expression of the covariance matrix .",
    "some complication arises to take overlappings of cells into account . we assume a locally poisson process in the overlapping regions for simplicity , following @xcite .",
    "the definition of the covariance matrix is given by equation  ( [ eq:160 ] ) . in the following ,",
    "we denote the galaxy count with a smoothing radius @xmath83 by @xmath161 .",
    "individual cells are labeled by @xmath162 and @xmath163 is a galaxy count in a cell @xmath164 which has a smoothing radius @xmath83 .",
    "a label @xmath164 is used for a group cells having radii @xmath83 and a label @xmath116 is for group of cells having radii @xmath165 .",
    "the second moment of the density contrast is related to galaxy counts by equation  ( [ eq:50 ] ) .",
    "the mean square of the galaxy count is given by @xmath166 where @xmath167 is the number of cells of radius @xmath83 .",
    "we assume that the mean galaxy count @xmath168 is accurately approximated by @xmath169 , where @xmath170 , and that the uncertainty of the mean number density @xmath122 is sufficiently small .",
    "this assumption corresponds to the case when we know a precise selection function from another observation and a sufficiently accurate mean number density from that selection function .",
    "therefore , if we estimate mean numbers of galaxies from a same data set , the above assumption is inaccurate . by combining equations",
    "( [ eq:50 ] ) , ( [ eq:160 ] ) , and ( [ eq : b10 ] ) , the expression of the covariance matrix is obtained .",
    "after some calculation , we have @xmath171 ,    \\label{eq : b2 } \\\\    c_{ij }    & = &    \\frac{1}{\\left\\langle n_i \\right\\rangle^2 \\left\\langle n_j \\right\\rangle^2 }    \\left [      \\frac{1}{v^2 } \\int_v d^3r_\\alpha d^3r_\\beta \\ ,      \\left\\langle { n_{i,\\alpha}}^2 { n_{j,\\beta}}^2 \\right\\rangle -      \\left\\langle",
    "n_i^2 \\right\\rangle \\left\\langle n_j^2 \\right\\rangle    \\right ] , \\label{eq : b3}\\end{aligned}\\ ] ] where @xmath172 indicates a survey volume and @xmath173 is a product s mean value of the squared galaxy counts in two different cells . in this study",
    ", we consider that cells are located randomly in a spherical survey volume by following @xcite .",
    "then , the sums over cells can be replaced by integrations over survey volume , as @xmath174 . however , in equation  ( [ eq : b2 ] ) , we can divide @xmath175 into two cases depending on @xmath176 or not .",
    "@xmath177 is a term that comes from a case of @xmath176 and represents an averaged value of biquadratic weighted counts over all cells .",
    "the second term comes from a case where @xmath178 holds .",
    "an additional factor @xmath179 in front of this term should be present because of the following reason : the number of cases satisfying @xmath178 is @xmath180 therefore , the sum is replaced by the volume integration as @xmath181 .",
    "@xmath182 is a theoretically expected square mean of number count related with the variance by equation  ( [ eq : sigma ] ) .    to calculate each term",
    ", we define a similar notation as equation ( [ eq : same ] ) : @xmath183 where @xmath141 is the two - point correlation function and @xmath111 and @xmath112 are centers of two cells .",
    "equation  ( [ eq : same ] ) considers correlations in a same cell . on the other hand ,",
    "equation ( [ eq : diff ] ) considers correlations in two different cells .",
    "we also use similar notations for the three- and four - point correlation functions . in a case considering correlations in a same cell , we use equation  ( [ eq : zeta ] ) and @xmath184^{-1 } ,    \\label{eq : eta}\\end{aligned}\\ ] ] where we abbreviate the four - point correlation function @xmath157 as @xmath185 . to consider correlations in two different cells whose centers are located at @xmath186 , we use @xmath187^{-1},\\\\ \\overline{\\zeta}_{\\alpha\\beta\\beta}^{(p , r , s ) } & \\equiv &      \\int d^3r_ad^3r_cd^3r_d \\ ,       \\zeta_{acd }      \\ { w(|\\boldsymbol{r}_a-\\boldsymbol{r}_\\alpha| ; r_i ) \\}^{p+1 }       \\ { w(|\\boldsymbol{r}_c-\\boldsymbol{r}_\\beta| ; r_j ) \\}^{r+1 }    \\nonumber \\\\    & & \\hspace{1em } \\times      \\ { w(|\\boldsymbol{r}_d-\\boldsymbol{r}_\\beta| ; r_j ) \\}^{s+1 }    \\nonumber \\\\    & & \\times    \\left [      \\int d^3r_a \\ ,       \\ { w(|\\boldsymbol{r}_a-\\boldsymbol{r}_\\alpha| ; r_i ) \\}^{p+1 }      \\int d^3r_c \\ ,       \\ { w(|\\boldsymbol{r}_c-\\boldsymbol{r}_\\beta| ; r_i ) \\}^{r+1 }    \\right .    \\nonumber \\\\    & & \\hspace{1em } \\times    \\left .",
    "\\int d^3r_d \\ ,       \\ { w(|\\boldsymbol{r}_d-\\boldsymbol{r}_\\beta| ; r_j ) \\}^{s+1 }    \\right]^{-1},\\\\ \\overline{\\eta}_{\\alpha\\alpha\\beta\\beta}^{(p , q , r , s ) } & \\equiv &      \\int d^3r_ad^3r_bd^3r_cd^3r_d \\ ,       \\eta_{abcd }      \\ { w(|\\boldsymbol{r}_a-\\boldsymbol{r}_\\alpha| ; r_i ) \\}^{p+1 }       \\ { w(|\\boldsymbol{r}_b-\\boldsymbol{r}_\\alpha| ; r_i ) \\}^{q+1 }    \\nonumber \\\\    & & \\hspace{1em } \\times      \\ { w(|\\boldsymbol{r}_c-\\boldsymbol{r}_\\beta| ; r_j ) \\}^{r+1 }      \\ { w(|\\boldsymbol{r}_d-\\boldsymbol{r}_\\beta| ; r_j ) \\}^{s+1 }    \\nonumber \\\\    & & \\times    \\left [      \\int d^3r_a \\ ,       \\ { w(|\\boldsymbol{r}_a-\\boldsymbol{r}_\\alpha| ; r_i ) \\}^{p+1 }      \\int d^3r_b \\ ,       \\ { w(|\\boldsymbol{r}_b-\\boldsymbol{r}_\\alpha| ; r_j ) \\}^{q+1 }    \\right .",
    "\\nonumber \\\\    & & \\hspace{1em } \\times    \\left .",
    "\\int d^3r_c \\ ,       \\ { w(|\\boldsymbol{r}_c-\\boldsymbol{r}_\\beta| ; r_i ) \\}^{r+1 }      \\int d^3r_d \\ ,       \\ { w(|\\boldsymbol{r}_d-\\boldsymbol{r}_\\beta| ; r_j ) \\}^{s+1 }    \\right]^{-1 } ,    \\label{eq : four}\\end{aligned}\\ ] ] where we abbreviate the three - point correlation function @xmath147 as @xmath188 .    the first term in equation  ( [ eq : b2 ] ) is calculated in the same manner as in appendix  [ ap : moments - counts ]",
    "then , we obtain @xmath189 , \\label{eq : b8}\\end{aligned}\\ ] ] where @xmath190 represents a summation over every infinitesimal volumes @xmath119 in a cell @xmath164 .    from equation  ( [ eq : sigma ] ) , the last term in both equations ( [ eq : b2 ] ) , ( [ eq : b3 ] ) is given by @xmath191    a derivation of the second term in equation  ( [ eq : b2 ] ) is complicated because of overlappings of cells .",
    "first of all , the integration is divided into two ranges of @xmath192 depending on whether cells are overlapping or not , i.e. @xmath193 , where @xmath194 . on the one hand , for cell pairs that are not overlapped to each other , we calculate @xmath195 in the same way as equation ( [ eq : b8 ] ) .",
    "then , we obtain @xmath196 .",
    "\\label{eq : b10}\\end{aligned}\\ ] ]    on the other hand , for cell pairs that are overlapped to each other , we calculate by following @xcite .",
    "a configuration of cells are shown in figure  [ fig : fig7 ] .",
    "we assume that the galaxy distribution within overlapped cells is locally poisson process .",
    "we divide each cell into infinitesimal volumes as before and consider two cases depending on whether each infinitesimal volume @xmath119 is included in a overlapped region or not .",
    "then , the summations in equation  ( [ eq : b10 ] ) is divided into @xmath197 we introduce other notations to show the results @xmath198 where each subscript i , ii , and iii represents an integration over each region i , ii , and iii , respectively , and @xmath199 .",
    "after some calculations , we obtain @xmath200    \\nonumber \\\\    & & +    \\overline{n}^3    \\left [      \\left ( \\overline{v}_{\\rm i}^{(1,0 ) } \\right)^2      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,2 ) } +      \\overline{v}_{\\rm i}^{(2,0 ) }       \\left ( \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,1 ) } \\right)^2 +      \\left ( \\overline{v}_{\\rm i}^{(1,0 ) } \\right)^2      \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,2 ) } +      \\overline{v}_{\\rm i}^{(2,0 ) }      \\left ( \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) } \\right)^2    \\right .",
    "\\nonumber \\\\    & & \\hspace{1em } +    \\left ( \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0 ) } \\right)^2    \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,2 ) } +    \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(2,0 ) }    \\left ( \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) } \\right)^2 +    2 \\overline{v}_{\\rm i}^{(2,0 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,1 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) } +    2 \\overline{v}_{\\rm i}^{(1,0 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,2 ) }    \\nonumber \\\\    & & \\hspace{1em } +    4 \\overline{v}_{\\rm i}^{(1,0 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,1 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) } +    2 \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(2,0 ) }    \\left(\\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,1)}\\right)^2 +    2 \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,1 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,1 ) } +    2 \\left(\\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0)}\\right)^2    \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,2 ) }    \\nonumber \\\\    & & \\hspace{1em } +    \\left .      2 \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(2,0 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,1 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) } +      4 \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,1 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) } +      2 \\overline{v}_{\\rm i}^{(1,0 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,2 ) }    \\right .",
    "\\nonumber \\\\    & & \\hspace{1em } +    \\left",
    ".      4 \\overline{v}_{\\rm i}^{(1,0 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,1 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,0 ) }    \\right ]    \\nonumber \\\\    & & +    \\overline{n}^4    \\left [      \\left (        \\overline{v}_{\\rm i}^{(1,0 ) }        \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,2 ) }      \\right)^2 +      \\left (        \\overline{v}_{\\rm i}^{(1,0 ) }        \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) }      \\right)^2 +      \\left (        \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0 ) }        \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) }      \\right)^2 +      2\\left ( \\overline{v}_{\\rm i}^{(1,0 ) } \\right)^2      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,1 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) }    \\right .",
    "\\nonumber \\\\    & & \\hspace{1em } +    2\\overline{v}_{\\rm i}^{(1,0 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0 ) }    \\left (      \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) }    \\right)^2 +    4\\overline{v}_{\\rm i}^{(1,0 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,1 ) }    \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) } +    \\left (      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,1 ) }    \\right)^2    \\nonumber \\\\    & & \\hspace{1em } +    \\left .",
    "2 \\left ( \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0 ) } \\right)^2      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,1 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i\\hspace{-.1em}i } ^{(0,1 ) } +      2\\overline{v}_{\\rm i}^{(1,0 ) }      \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(1,0 ) }      \\left ( \\overline{v}_{\\rm i\\hspace{-.1em}i}^{(0,1 ) } \\right)^2     \\right ] .",
    "\\label{eq : b16}\\end{aligned}\\ ] ]    it is straightforward to evaluate @xmath201 terms that are integrated over region @xmath202 in the above equation . for example , by using the fourier transformation , we have @xmath203 in an overlapped region , where @xmath204 on the other hand , for @xmath201 terms that are integrated over non - overlapping region , it is not a good way to evaluate equation  ( [ eq : b13 ] ) and ( [ eq : b15 ] ) directly , because it seems we need numerical calculations in this expression .",
    "however , we can analytically subtract a contribution of the overlapping region from an integration over a whole cell .",
    "first , note that an integration over a non - overlapped region has nothing to do with a shape of an overlapping cell .",
    "therefore , the contribution from the overlapped region can be calculated by replacing the overlapping cell by the top - hat smoothing function having same center and radius as the overlapping cell .",
    "then , we obtain @xmath205 where @xmath206 , @xmath207 , and @xmath208 is the fourier transformation of the top - hat function .    in the case of the @xmath0-weight epanechnikov kernel , for example",
    ", we can use equation  ( [ eq:110 ] ) for @xmath209 or @xmath210 . for @xmath211 or @xmath212 , a square of the @xmath0-weight epanechnikov kernel",
    "is related to the @xmath213-weight epanechnikov kernel by a following relation : @xmath214 therefore , we can use @xmath215    by using equations  ( [ eq : b2 ] ) , ( [ eq : b3 ] ) , ( [ eq : b8 ] ) - ( [ eq : b10 ] ) , ( [ eq : b16 ] ) - ( [ eq : b20 ] ) and by approximating @xmath216 , we finally obtain @xmath217    \\nonumber \\\\    & & +    \\frac{1}{v^2 }     \\left (      1 - \\frac{1}{n_{{\\rm cell},i } }    \\right )    \\int_{r_{\\alpha\\beta}\\le 2r_i } d^2r_\\alpha d^3r_\\beta \\",
    ",    \\frac{1}{\\langle n_i \\rangle^4 }     \\left\\langle { n_{i,\\alpha}}^2{n_{i,\\beta}}^2 \\right\\rangle_{\\rm overlap }    \\nonumber \\\\    & & +    \\frac{1}{v^2 }     \\left (      1 - \\frac{1}{n_{{\\rm cell},i } }    \\right )    \\int_{r_{\\alpha\\beta}>2r_i}d^3r_\\alpha d^3r_\\beta\\ ,    \\left [      \\frac{\\left(\\overline{w}\\right)^2}{\\langle n_i\\rangle^2 }      \\overline{\\xi}_{\\alpha\\beta}^{(1,1 ) } +      4\\frac{\\overline{w}}{\\langle n_i\\rangle }      \\overline{\\xi}_{\\alpha\\beta}^{(1,0 ) } +      4\\overline{\\xi}_{\\alpha\\beta}^{(0,0 ) }    \\right ] ,    \\nonumber \\\\",
    "\\label{eq : b21 } \\\\",
    "c_{ij }    & = &    \\frac{1}{v^2 }    \\int_{r_{\\alpha\\beta}\\le r_i+r_j } d^3r_\\alpha d^3r_\\beta \\ ,    \\frac{1}{\\langle n_i \\rangle^2 \\langle n_j \\rangle^2 }    \\left\\langle      { n_{i,\\alpha}}^2 { n_{j,\\beta}}^2    \\right\\rangle_{\\rm overlap }    \\nonumber \\\\    & & +    \\frac{1}{v^2 }    \\int_{r_{\\alpha\\beta}>r_i+r_j}d^3r_\\alpha d^3r_\\beta\\ ,    \\left [      \\frac{\\left(\\overline{w}\\right)^2}{\\langle n_i\\rangle\\langle n_j\\rangle }      \\overline{\\xi}_{\\alpha\\beta}^{(1,1 ) } +      2\\left (        \\frac{\\overline{w}}{\\langle n_i\\rangle }        \\overline{\\xi}_{\\alpha\\beta}^{(1,0 ) } +        \\frac{\\overline{w}}{\\langle n_j\\rangle }        \\overline{\\xi}_{\\alpha\\beta}^{(0,1 ) }      \\right ) +      4\\overline{\\xi}_{\\alpha\\beta}^{(0,0 ) }    \\right ] ,    \\nonumber \\\\    \\label{eq : b22}\\end{aligned}\\ ] ] where @xmath218    \\nonumber \\\\    & & -    \\frac{2}{\\overline{n}{v_i}^2{v_j}^2 }    \\frac{1}{v }    \\int^{r_i+r_j}_04\\pi r^2dr \\ ,    \\left [      \\int \\frac{d^3k_1}{(2\\pi)^3 } \\ ,",
    "\\tilde{w}(k_1r_i )      \\left\\ { v_j \\tilde{u}_{\\rm th}(k_1r_j ) \\right\\ }      \\frac{\\sin k_1r}{k_1r }    \\right .",
    "\\nonumber \\\\    & & \\hspace{1em } \\times    \\left .",
    "\\int \\frac{d^3k_2}{(2\\pi)^3 } \\ ,      \\tilde{w}(k_2r_i ) \\tilde{w}(k_2r_j )      \\frac{\\sin k_2r}{k_2r }      \\int \\frac{d^3k_3}{(2\\pi)^3 } \\ ,      \\left\\ { v_i \\tilde{u}_{\\rm th}(k_3r_i ) \\right\\ }      \\tilde{w}(k_3r_j ) \\frac{\\sin k_3r}{k_3r }    \\right ] .",
    "\\nonumber \\\\",
    "\\label{eq : b23}\\end{aligned}\\ ] ]",
    "to calculate equations  ( [ eq : same ] ) and ( [ eq : diff ] ) numerically , it is convenient to go forward more analytically . by using the inverse fourier transformation @xmath219 equation  ( [ eq : same ] ) becomes @xmath220 where @xmath126 .",
    "similarly , equation  ( [ eq : diff ] ) becomes @xmath221 then , the integration over non - overlapped region appeared in equation ( [ eq : b22 ] ) becomes @xmath222 ,    \\nonumber \\\\",
    "\\label{eq : xibardiff}\\end{aligned}\\ ] ] because we assume that a survey volume has a spherical shape .",
    "bardeen ,  j.  m. , bond ,  j.  r. , kaiser ,  n. , & szalay ,  a.  s. 1986 , , 304 , 15 697 bernardeau ,  f. 1994a , , 291 , 697 bernardeau ,  f. 1994b , , 433 , 1 carroll ,  s.  m. , felice ,  a.  d. , duvvuri ,  v. , easson ,  d.  a. , trodden ,  m. , & turner ,  m.  s. 2005 , , 71 , 063513 catelan ,  p. , & moscardini ,  l. 1994 , , 426 , 14 colless ,  m. 2003 , preprint ( astro - ph/0305051 ) colombi ,  s. 1994 , , 435 , 536 colombi ,  s. , bouchet ,  f.  r. , & schaeffer ,  r. 1995 , , 96 , 401 cramr ,  h. 1946 , mathematical methods of statistics ( princeton : princeton university press ) christensen ,  n. , meyer ,  r. , knox ,  l. , & luecy ,  b. , 2001 , class .",
    "quantum grav . , 18 , 2677 efstathiou ,  g. , kaiser ,  n. , saunders ,  w. , lawrence ,  a. , rowan - robinson ,  m. , ellis ,  r.  s. , & frenk ,  c.  s. 1990 , , 247 , 10 efstathiou ,  g. 1995 , , 276 , 1425 eisenstein ,  d.  j. , 2001 , , 122 , 2267 epanechnikov ,  v.  a. 1969 , theory of probability and its applications , 14 , 153 flanagan ,  e.  e. 2005 , 71 , 103521 gaztaaga ,  e. & yokoyama ,  j. , 1993 , , 403 , 450 kaiser ,  n. 1987 , , 227 , 1 kendall ,  m.  g. , & stuart ,  a. 1996 , the advanced theory of statistics , vol.2 ( 4th ed . ; london : griffin ) loveday ,  j. , efstathiou ,  g. , peterson ,  b.  a. , & maddox ,  s.  j. 1992 , , 400 , l43 matsubara ,  t. , & szalay ,  a.  s. 2002 , , 574 , 1 matsubara ,  t. 2002 , , 615 , 573 mukhanov ,  v.  f. , abramo ,  l.  r.  w. , & brandenberger ,  r.  h. , 1997 , , 78 , 1624 navarro ,  i. & acoleyen ,  k.  v. , 2006 , j. cosmol .",
    "phys , 0609 , 006 nojiri ,  s. , & odintsov ,  s.  d. , 2005 , phys .",
    "b631 , 1 percival ,  w.  j. , 2001 , , 327 , 1297 perotto ,  l. , lesgourfues ,  j. , hannestad ,  s. , tu ,  h. & wong ,  y.  y.  y. 2006 , j. cosmol .",
    ", 0610 , 013 peebles ,  p.",
    "j.  e. 1980 , the large - scale structure of the universe ( princeton : princeton university press ) perlmutter ,  s. , 1999 , , 517 , 565 pope ,  a.  c. , 2004 , , 607 , 655 rsnen ,  s. 2006 , class .",
    "quantum grav . , 23 , 1823 riess ,  a.  g. , 1998 , , 116 , 1009 richards ,  g.  t. , 2002 , , 123 , 2945 scoccimarro ,  r. & sheth ,  r.  k. , 2002 , , 329 , 629 sefusatti ,  e. , crocce ,  m. , pueblas ,  s. & scoccimarro ,  r. 2006 , , 74 , 023522 seljak ,  u. , & zaldarriaga ,  m. 1996 , , 469 , 437 seljak ,  u. , 2005 , 71 , 103515 spergel ,  d.  n. , 2003 , , 148 , 175 spergel ,  d.  n. , 2006 , , submitted ( astro - ph/0603449 ) strauss ,  m.  a. , 2002 , , 124 , 1810 szapudi ,  i. , & colombi ,  s. 1996 , , 470 , 131 szapudi ,  i. , & pan ,  j. 2004 , , 602 , 26 takada ,  m. , komatsu ,  e. , & futamase ,  t. , 2006 , , 73 , 083520 tegmark ,  m. , taylor ,  a. , & heavens ,  a. 1997 , , 480 , 22 tegmark ,  m. 1997 , , 79 , 3806 tegmark ,  m. , 2004 , , 69 , 103501 ueda ,  h. , & yokoyama ,  j. 1996 , , 280 , 754 verde ,  l. , 2003 , , 148 , 195 york ,  d.  g. , 2000 , , 120 , 1579"
  ],
  "abstract_text": [
    "<S> a method of counts - in - cells analysis of galaxy distribution is investigated with arbitrary smoothing functions in obtaining the galaxy counts . </S>",
    "<S> we explore the possiblity of optimizing the smoothing function , considering a series of @xmath0-weight epanechnikov kernels . </S>",
    "<S> the popular top - hat and gaussian smoothing functions are two special cases in this series . in this paper </S>",
    "<S> , we mainly consider the second moments of counts - in - cells as a first step . </S>",
    "<S> we analytically derive the covariance matrix among different smoothing scales of cells , taking into account possible overlaps between cells . </S>",
    "<S> we find that the epanechnikov kernel of @xmath1 is better than top - hat and gaussian smoothing functions in estimating cosmological parameters . as an example , we estimate expected parameter bounds which comes only from the analysis of second moments of galaxy distributions in a survey which is similar to the sloan digital sky survey . </S>"
  ]
}