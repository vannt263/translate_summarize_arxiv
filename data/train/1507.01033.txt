{
  "article_text": [
    "covariation between two assets is a crucial quantity in finance .",
    "fundamental examples include optimal asset allocation and risk management . in the past few years , using the increasing amount of high - frequency data available , many papers have been published about estimating this covariance .",
    "suppose that the latent log - price of two arbitrary assets @xmath0 follows a continuous it process @xmath1 where @xmath2 are random processes , and @xmath3 and @xmath4 are standard brownian motions , with ( random ) high - frequency correlation @xmath5 .",
    "econometrics usually seeks to infer the _ integrated covariation _",
    "@xmath6 earlier results were focused on estimating the integrated variance of a single asset , starting from the probabilistic point of view ( genon - catalot and jacod ( 1993 ) , jacod ( 1994 ) ) .",
    "barndorff - nielsen and shephard ( 2001 , 2002 ) introduced the problem in econometrics .",
    "adapted to two dimensions , if each process is observed simultaneously at ( possibly random ) times @xmath7 , @xmath8 ,  , @xmath9 the _ realized covariation _",
    "@xmath10_t$ ] is defined as the sum of cross log returns @xmath11_t = \\sum_{\\tau_{i , n } \\leq t } \\delta x_{\\tau_{i , n}}^{(1 ) } \\delta x_{\\tau_{i , n}}^{(2)},\\end{aligned}\\ ] ] where for any positive integer @xmath12 , @xmath13 corresponds to the increment of the @xmath14th process between the last two sampling times . as the observation intervals @xmath15 get closer ( and the number of observations @xmath16 goes to infinity ) , @xmath17_t \\overset{{\\mathbb{p}}}{\\rightarrow } \\langle x^{(1 ) } , x^{(2 ) } \\rangle_t$ ] ( see e.g. theorem i.4.47 in jacod and shiryaev ( 2003 ) ) . furthermore ,",
    "when the observation times @xmath18 are independent of the prices process @xmath19 , its estimation error follows a mixed normal distribution ( jacod and protter ( 1998 ) , zhang ( 2001 ) , mykland and zhang ( 2006 ) ) .",
    "this gives us insight on how to estimate the integrated covariation .",
    "however , in practice , these two assumptions are usually not satisfied .",
    "the observation times of the two assets are rarely _ synchronous _ and there is _ endogeneity _ in the price sampling times .",
    "the first issue has been studied for a long time .",
    "the lack of synchronicity often creates undesirable effects in inference .",
    "if we sample at very high frequencies , we observe the epps effect ( epps ( 1979 ) ) , i.e. the correlation estimates are drastically decreased compared to an estimate with sparse observations .",
    "hayashi and yoshida ( 2005 ) introduced the so - called _ hayashi - yoshida estimator _ ( hy ) @xmath20 where @xmath21 are the observation times of the @xmath14th asset . note that if the observations of both processes occur simultaneously , ( [ volest ] ) and ( [ hy ] ) are equal .",
    "the consistency of this estimator was achieved in hayashi and yoshida ( 2005 ) and hayashi and kusuoka ( 2008 ) .",
    "the corresponding central limit theorems were investigated in hayashi and yoshida ( 2008 , 2011 ) under strong predictability of observation times , which is a more restrictive assumption than only assuming they are stopping times but still allows some dependence between prices and observation times .",
    "recently , koike ( 2014 , 2016 ) extended the pre - averaged hayashi - yoshida estimator first under predictability of observation times , and then under a more general endogenous setting of stopping times .",
    "other examples of high - frequency covariance estimators can be found in zhang ( 2011 ) , barndorff - nielsen et al .",
    "( 2011 ) , at - sahalia et al .",
    "( 2010 ) , christensen et al .",
    "( 2010 , 2013 )",
    ".    in a general one - dimensional endogenous model , the asymptotic behaviour of the realized volatility ( [ volest ] ) has been investigated in the case of sampling times given by hitting times on a grid ( fukasawa ( 2010a ) , robert and rosenbaum ( 2011 , 2012 ) , fukasawa and rosenbaum ( 2012 ) ) . due to the regularity of those three models",
    "( see the discussion in the latter paper ) , they do nt obtain any bias in the limit distribution of the normalized error . also , the case of strongly predictable stopping times is treated in hayashi et al .",
    "( 2011 ) . finally , two general results ( fukasawa ( 2010b ) , li and al .",
    "( 2014 ) ) showed that we can identify and estimate the asymptotic bias .",
    "the primary goal of this paper is to bias - correct the hy .",
    "note that estimating the bias is more challenging than in the volatility case because observations are asynchronous .",
    "in particular , the estimator will involve a quantity that can be considered as the _ tricity _ of li et al .",
    "( 2014 ) , but with a more intricate definition because of the asynchronicity in sampling times .",
    "this new definition can be seen as an analogy with the generalization of the rv estimator ( [ volest ] ) by the hy estimator ( [ hy ] ) .",
    "another very important issue to address is the estimation of the asymptotic standard deviation .",
    "first , because the model is more general than in the no - endogeneity work , the theoretical asymptotic variance will be different .",
    "consequently , a new variance estimator , which takes into proper account the endogeneity , will be given .",
    "the authors want to take no position on the joint distribution of the log - return and the next observation time that corresponds to an asset price change because they know that their unknown relationship is most likely contributing to the bias and the variance of the high - frequency covariance s estimate when we ( wrongly ) assume full independence between the price process and observation times . for this purpose",
    ", they introduce the _ hitting boundary process with time process _ ( hbt ) model .    finally , techniques developed in the proofs are innovative in the sense that they reduce the normalized error of the hayashi - yoshida estimator to a discrete process , which is locally a uniformly ergodic homogeneous markov chain .",
    "thus , the problem can be solved locally , and because we assume that the volatility of assets is continuous , the error of approximation between the local markov structure and the real structure of the normalized error vanishes asymptotically .",
    "this technique is not problem - specific , and it can very much be applied to other estimators dealing with temporal data .",
    "the paper is organized as follows .",
    "we introduce the hbt model in section 2 .",
    "examples covered by this model are given in section 3 .",
    "the main theorem of this work , the limit distribution of the normalized error is given in section 4 .",
    "estimators of the asymptotic bias and variance are provided in section 5 .",
    "we carry out numerical simulations in section 6 to corroborate the theory .",
    "proofs are developed in appendix .",
    "we first introduce the model in @xmath22-dimension .",
    "we assume that for any positive integer @xmath12 , @xmath23 is the next arrival time ( after @xmath24 ) that corresponds to an actual change of price .",
    "in particular , several trades can occur at the same price @xmath25 between @xmath24 and @xmath23 , but no trade can occur with a price different than @xmath25 before @xmath23 .",
    "we also assume that @xmath19 is the efficient ( log ) price of the security of interest .",
    "in addition , we assume that the observations are noisy and that we observe @xmath26 where the microstructure noise @xmath27 can be expressed as a known function of the observed prices @xmath28 . as an example , robert and rosenbaum ( 2012 ) showed in @xmath29 in p. 5 that the model with uncertainty zones can be written with that noise structure if we assume that we know the friction parameter @xmath30 .",
    "finally , we define @xmath31 as the tick size , and we assume that the observed price @xmath25 lays on the tick grid , i.e. there exists positive integers @xmath32 such that @xmath33 .    empirically , no economical model based on rational behaviors of agents on the stock markets , that shed light on the relationship between the efficient return @xmath34 and time before the next price change @xmath35 , has won unanimous support .",
    "when arrival times are independent of the asset price , it follows directly from the continuous it - assumption that the dependence structure is such that the return @xmath34 is a function of @xmath36 .",
    "the longer we wait , the bigger the variance of the return is expected to be . in this paper , we take the opposite point of view by building a model in which @xmath24 is defined as a function of the efficient price path . for that purpose",
    ", we define the _ observation time process _ @xmath37 that will drive the observation times .",
    "we also define the _ down process _ @xmath38 and the _ up process _ @xmath39 .",
    "note that for any @xmath40 , we assume that @xmath41 and @xmath42 are functions on @xmath43 .",
    "we also assume that the down process takes only negative values and that the up process takes only positive values .",
    "a new observation time will be generated whenever one of those two processes is hit by the increment of the observation time process .",
    "then , the increment of the observation time process will start again from @xmath44 , and the next observation time will be generated whenever it hits the up or the down process .",
    "figure [ illustration ] illustrates the hbt model .",
    "formally , we define @xmath45 and for any positive integer @xmath12 as @xmath46}^{(t ) } \\notin \\big [ d_{t }    \\left ( t - \\tau_{i-1 } \\right ) , u_{t } \\left(t - \\tau_{i-1 } \\right )   \\big ] \\big\\},\\end{aligned}\\ ] ] where @xmath47 } : = y_b - y_a$ ] .",
    "note that if the observation time process @xmath37 is equal to the price process @xmath19 itself , then the price will go up ( respectively go down ) whenever it hits the up process ( down process ) .",
    "note also that if the time process , the up process and the down process are independent of the efficient price process , then the arrival times are independent of the efficient price process .",
    "we assume that the two - dimensional process @xmath48 is an it - process .",
    "section @xmath49 provides examples of the literature identifying the observation time process , the down process and the up process .",
    "generalizing to two dimensions is straightforward . we define @xmath50 for @xmath51 to be the observation time process associated with the @xmath14th price process , @xmath52 the up process , @xmath53 the down process , and the arrival times @xmath54 generated by ( [ generateobstimes ] ) .",
    "we also define the four dimensional process @xmath55 , and assume @xmath56 follows an it - process with volatility @xmath57 in particular , we have @xmath58 , where @xmath59 is a four dimensional standard brownian motion ( for @xmath60 and @xmath61 such that @xmath62 , @xmath63 is independent of @xmath64 ) .",
    "if we set @xmath65 , then the integrated covariance ( or quadratic covariation ) process is given by @xmath66 .",
    "let @xmath67 be the associated correlation process of @xmath56 , i.e. for @xmath68 and @xmath61 we set @xmath69 . finally , it is useful sometimes to see @xmath56 as a four dimensional vector expressed as in equations ( [ ito1 ] ) and ( [ ito2 ] ) .",
    "for @xmath70 we define the volatility of the @xmath14th process as @xmath71 , we can thus express @xmath72 as @xmath73 where @xmath74 is a standard brownian motion , which typically depends on @xmath75 for @xmath76 .",
    "we insist on the fact that estimators of covariance and associated asymptotic variance given in this paper do nt require any knowledge of the structure of the observation time process , the up process and the down process .",
    "nonetheless , for financial and economic interpretation purposes , the reader might be interested in getting an idea on how those processes behave in practice .",
    "we provide in this section several examples from the literature as well as possible extensions of the model with uncertainty zones of robert and rosenbaum ( 2011 ) that can be expressed as hbt models .",
    "[ hittingbarrier ] ( hitting constant boundaries ) the simplest endogenous semi - parametric model we can think of is a model where the time process @xmath37 is equal to the price process @xmath19 , and times are generated by hitting a constant barrier .",
    "formally , it means that there exists a two - dimensional parameter @xmath77 such that the up process is equal to @xmath78 and the down process is equal to @xmath79 .",
    "we do nt assume noise in that model .",
    "[ hittingbarriernoise ] ( hitting constant boundaries of the tick size ) one issue with example [ hittingbarrier ] is that the efficient price @xmath80 , which is observed because no microstructure noise is assumed in the model , is not necessarily a modulo of the tick size @xmath81 if @xmath78 and @xmath79 are not multiples of @xmath81 . to make example [ ex1 ] feasible in practice",
    ", we assume here that the constant barriers @xmath78 and @xmath79 are respectively equal to the tick size @xmath81 and its additive inverse @xmath82 .",
    "we also assume that @xmath83 .",
    "[ hittingbarriernoisejump ] ( hitting constant boundaries of the jump size ) the issue with example [ hittingbarriernoise ] is that the absolute jump size of the observed price @xmath25 is @xmath81 . on the contrary ,",
    "in practice the absolute jump size can actually be bigger than the tick size @xmath81 . in the notation of robert and rosenbaum ( 2011 ) , for any positive integer @xmath12",
    ", we introduce a discrete variables @xmath84 which corresponds to the observed price jump s tick number between @xmath85 and @xmath23 , with @xmath86 .",
    "we assume that @xmath84 is bounded .",
    "the arrival times are defined recursively as @xmath87 and for any positive integer @xmath12 as @xmath88 we assume that @xmath84 are iid and independent of the other quantities . we finally assume that @xmath83 .",
    "the up and down processes are piecewise constant in @xmath89 and constant in @xmath90 , defined for any @xmath91 as @xmath92\\\\ u_t ( s )   = & l_{i-1 } \\alpha   & \\text { for }   t \\in ( \\tau_{i-1 } , \\tau_i]\\end{aligned}\\ ] ]    [ uncertaintyzones ] ( model with uncertainty zones ) we go one step further than example [ hittingbarriernoisejump ] and introduce now the model with uncertainty zones of robert and rosenbaum ( 2011 ) . in a frictionless market",
    ", we can assume that a trade with change of price @xmath25 will occur whenever the efficient price process crosses one of the mid - tick values @xmath93 or @xmath94 .",
    "in that case , if the efficient price process hits the former value , we would observe an increment of the observed price @xmath95 and if it hits the former value , we would observe a decrement @xmath96 .",
    "there are two reasons why in practice such a frictionless model is too simplistic .",
    "the first reason is that the absolute value of the increment ( or the decrement ) of the observed price can be bigger than the tick size @xmath81 and was already pointed out in example [ hittingbarriernoisejump ] .",
    "we will thus keep the notation @xmath84 in this example .",
    "the second reason is that the frictions induce that the transaction will not exactly occur when the efficient process is equal to the mid - tick values . for this purpose in the notation of robert and rosenbaum ( 2012 ) , let @xmath97 be a parameter that quantifies the aversion to price changes of the market participants .",
    "if we let @xmath98 be the value of @xmath19 rounded to the nearest multiple of @xmath81 , the sampling times are defined recursively as @xmath87 and for any positive integer @xmath12 as @xmath99 the observed price is equal to the rounded efficient price @xmath100 .",
    "the time process @xmath37 is again equal to the price process @xmath19 itself in this model .",
    "the up and down processes are piecewise constant in @xmath89 and constant in @xmath90 , defined for any @xmath91 as @xmath101\\\\ u_t ( s )   = & l_{i-1 } \\alpha \\mathbf{1 } _ { \\ { x_{\\tau_{i-1 } } > x_{\\tau_{i-2 } } \\ } } + \\left ( 2 \\eta + l_{i-1 } - 1 \\right ) \\alpha \\mathbf{1 } _ { \\ { x_{\\tau_{i-1 } } < x_{\\tau_{i-2 } } \\ } } & \\text { for }   t \\in ( \\tau_{i-1 } , \\tau_i]\\end{aligned}\\ ] ] where @xmath102 is the indicator function of a. note that in the case where @xmath103 , we are back to example [ hittingbarriernoisejump ] .",
    "[ irregulargrid ] ( times generated by hitting an irregular grid model ) the fourth model we are looking at is called _ times generated by hitting an irregular grid model_. we follow the notation of fukasawa and rosenbaum ( 2012 ) and consider the irregular grid @xmath104 , with @xmath105 .",
    "we set @xmath106 and for @xmath107 @xmath108 where @xmath109 is the set obtained by removing @xmath110 from @xmath111 .",
    "we can rewrite it as an element of the hbt model where the time process is equal to the price process , and for all @xmath91 the up and down processes are defined as @xmath112\\\\ u_t ( s )   = & p_{k+1 } - p_k & \\text { for } t \\in ( \\tau_{i-1 } , \\tau_i ] , \\end{aligned}\\ ] ] where @xmath14 is the ( random ) index such that @xmath113 .",
    "[ autoregressive ] ( structural autoregressive conditional duration model ) there have been several drafts for this model .",
    "we follow here a former version ( renault et al . ( 2009 ) ) , because we can directly express it as an element of the hbt model ) of the hbt model as a first hitting - time of a unique barrier instead of the first hitting time of one of two barriers as in the latter version of renault et al .",
    "( 2014 ) would nt change much the proofs of this paper , but we chose the two - boundaries setting because it seems more natural if interpretation of time processes , up processes and down processes is needed . ] . in the structural autoregressive conditional duration model , the time @xmath85 when the next event occurs",
    "is given by @xmath114 and for @xmath115 @xmath116 where @xmath117 is a standard brownian motion ( not necessarily independent of @xmath19 ) .",
    "expressed as an element of the hbt model , we have that the time process @xmath37 is equal to the brownian motion @xmath117 and for all @xmath91 @xmath118\\\\ u_t ( s )   = & \\tilde{c}_{\\tau_{i-1 } } \\text { for } & t \\in ( \\tau_{i-1 } , \\tau_i ] .\\end{aligned}\\ ] ]      the model with uncertainty zones of robert and rosenbaum ( 2011 ) introduced in example [ uncertaintyzones ] , which is semi - parametric , assumes that the observed price is the efficient price rounded to the nearest tick value @xmath119 and thus the noise is equal to @xmath120 if the last trade increased the price and @xmath121 if the last trade decreased the price . in particular",
    ", the noise is auto - correlated and correlated to the efficient price . because of this specific noise distribution",
    ", it is directly possible to estimate the underlying friction parameter @xmath30 without any data pre - processing such as preaveraging ( see robert and rosenbaum ( 2012 ) ) .",
    "we believe the model with uncertainty zones is a very interesting starting point , because all the endogenous and noise structure of the model is reduced to the estimation of the @xmath22-dimensional friction parameter @xmath30 .",
    "nevertheless , as this semi - parametric model wants to be the simplest , it suffers from several issues .",
    "we will investigate two of them in the following .",
    "first , the model does nt allow for asymmetric information between the buyers and the sellers .",
    "define @xmath122 and @xmath123 , which are respectively the aversion to a positive price change and a negative price change . as a positive price change means that a buyer decided to put an order at the best ask price and a negative price change corresponds to a seller that puts an order at the best bid price ( if we assume that cancel and repost orders are not the reason why the price changed ) , the difference @xmath124 can be seen as a measure of information asymmetry .",
    "we define @xmath45 and recursively for @xmath12 any positive integer @xmath125 note that the hbt class contains this model and that it can be directly fitted if we slightly modify @xmath126 in robert and rosenbaum ( 2012 ) to estimate @xmath122 and @xmath123 .",
    "one possible application would be to build a test of asymmetric information @xmath127 .",
    "this is beyond the scope of this paper .",
    "one other issue is that the authors do nt do any model checking in their work . according to their empirical work ( see pp .",
    "359 - 361 of robert and rosenbaum ( 2011 ) ) , the estimated values for @xmath30 are stable accross days for the ten french assets tested .",
    "stability of @xmath30 favors their model but by doing so , the model does nt allow any other structure than the full - endogeneity for the sampling times . even if the true structure of sampling times is ( mostly )",
    "independent of the asset price , we will still estimate an @xmath30 that will be stable across days .",
    "if we allow the time process to be different from the price process itself , we can estimate the correlation @xmath128 between them and see how endogenous the sampling times are ( the bigger @xmath129 is , the more endogenous the sampling times are ) .",
    "we would need to add more general microstructure noise in the model , and thus this is left for further work .",
    "without loss of generality , we fix the horizon time @xmath130 , and we consider @xmath131 $ ] to represent the course of an economic event , such as a trading day .",
    "we first introduce the definition of stable convergence , which is a little bit stronger than usual convergence in distribution and needed for statistical purposes of inference , such as the prediction value of the high - frequency covariance and the construction of a confidence interval at a given confidence level .",
    "we suppose that the random processes @xmath56 , @xmath132 and @xmath133 are adapted to a filtration @xmath134 .",
    "let @xmath135 be a sequence of @xmath136-measurable random variables .",
    "we say that @xmath135 converges stably in distribution to @xmath137 as @xmath138 if @xmath137 is measurable with respect to an extension of @xmath136 so that for all @xmath139 and for all bounded continuous refers to continuity with respect to the skorokhod topology of @xmath140 $ ] .",
    "nevertheless , we can also use continuity given by the sup - norm , because all our limits are in @xmath141 $ ] .",
    "one can look at chapter @xmath142 of jacod and shiryaev ( 2003 ) as a reference . for further definition of stable convergence",
    ", one can look at rnyi ( 1963 ) , aldous and eagleson ( 1978 ) , chapter 3 ( p. 56 ) of hall and heyde ( 1980 ) , rootzn ( 1980 ) , and section 2 ( pp .",
    "169 - 170 ) of jacod and protter ( 1998 ) . ]",
    "functions @xmath143 , @xmath144 \\rightarrow { \\mathbb{e}}\\left [ \\mathbf{1}_a f \\left ( z \\right ) \\right]$ ] as @xmath138 .    in the setting of section 2",
    ", the target of inference , the integrated covariation , can be written for all @xmath145 $ ] as @xmath146 we are providing now the asymptotics .",
    "we want to make the number of observations go to infinity asymptotically .",
    "the idea is to scale and thus keep the structure that drives the next return and the next observation time , while making the tick size vanish ( and thus the number of observations explode on @xmath131 $ ] ) .",
    "formally , we let the tick size @xmath31 and we define the observation times @xmath147 such that for @xmath51 we have @xmath148 and for @xmath12 any positive integer @xmath149 \\big\\ } .\\ ] ] we define the hy estimator when the tick size is equal to @xmath81 as @xmath150 we now give the assumptions needed to prove the central limit theorem of ( [ hy0 ] ) . we need to introduce some definitions for this purpose",
    "in view of the different models introduced in section @xmath151 , there are three different possible assumptions regarding the correlation between the time processes @xmath37 and the price processes @xmath19 .",
    "the first possibility is that they can be equal for all @xmath152 . in this case",
    "we define @xmath153 as the smallest eigen - value of @xmath154 .",
    "the second scenario is that for one @xmath155 we have @xmath156 , but the other time process is different from its associated price process . in that case , we define @xmath153 the smallest eigen - value of @xmath157 .",
    "the third possible setting is that the time process is different from its associated asset price for both assets , and we let @xmath153 the smallest eigen - value of @xmath133 in that case .",
    "assumption @xmath158 provides conditions on the price processes @xmath159 and @xmath160 , the time processes @xmath161 and @xmath162 as well as their covariance matrix @xmath133 .",
    "there are two types of assumptions in @xmath158 .",
    "first , we want to get rid of the drift in the proofs , and this will be done using condition @xmath158 together with the girsanov theorem and local arguments ( see e.g. pp.158 - 161 in mykland and zhang ( 2012 ) ) .",
    "this is a very standard assumption in the literature of financial econometrics .",
    "furthermore , we assume that the covariance matrix @xmath133 is continuous .",
    "the drift @xmath132 , the volatility matrix @xmath133 and the ( four dimensional ) brownian motion @xmath59 are adapted to a filtration @xmath163 . also , @xmath132 is integrable and locally bounded .",
    "furthermore , @xmath133 is continuous .",
    "finally , we assume that @xmath164}{\\inf } \\lambda_t^{\\min } > 0 $ ] a.s .",
    "( robustness to jumps in volatility ) the proof techniques , holding the volatility constant on small blocks , require the `` continuity of volatility '' .",
    "this is the same strategy as in mykland and zhang ( 2009 ) and mykland ( 2012 ) where the volatility process follows a continuous it process . nonetheless , following the same line of reasoning as for the proof of remark [ rkjumps ]",
    ", we can add a finite number of jumps in the volatility matrix .",
    "the proof of theorem [ main1 ] will break in the case of infinite number of jumps in @xmath133 .",
    "the following condition roughly assumes that both time processes ca nt be equal to each other , even on a very small time interval . specifically , we will assume that there is a constant strictly smaller than @xmath22 such that the module of the _ instantaneous high - frequency correlation _",
    "@xmath165 ca nt be bigger than this constant . in practice",
    ", assumption @xmath166 is harmless .    for all",
    "@xmath167 $ ] we have @xmath168 ,     \\end{aligned}\\ ] ] where @xmath169 .",
    "the next assumption deals with the down process @xmath41 and the up process @xmath42 .",
    "it is clear that @xmath41 and @xmath42 have to be known with information at time @xmath89 , which is why we assume that they are adapted to @xmath170 .",
    "the rest of assumption @xmath171 is very technical and we only try to be as general as we can with respect to the proof techniques we will use . the reader should understand assumption @xmath171 as `` assume the worst dependence structure possible between the return @xmath34 and the time increment @xmath36 , knowing that they follow the hbt model '' .",
    "we insist once again on the fact that we only make the dependence structure as bad as we can in our model so that we can investigate how biased the hy estimator can be in practice , and how much the estimates of the variance assuming no endogeneity are wrong .",
    "for both assets @xmath51 , define the couple of the down process and the up process @xmath172 and let @xmath173 .",
    "we assume that @xmath174 is adapted to @xmath134 .",
    "moreover , there exists two non - random constants @xmath175 such that a.s . for any @xmath167 $ ] and for any @xmath91 @xmath176 furthermore",
    ", there exists non - random constants @xmath177 and @xmath178 such that a.s .",
    "@xmath179 @xmath180 @xmath181 ^ 2 \\text { s.t . } 0 < u",
    "< v , \\text { }   &   \\| g_{v } - g_{u } \\|_{\\infty } \\leq k | v - u |^{d } ,   \\end{aligned}\\ ] ] where @xmath182 of constants defined in assumption @xmath171 @xmath183 for any @xmath184 , we define @xmath185 to be the functional subspace of @xmath186 @xmath187 such that @xmath188 , @xmath189 satisfies ( [ a3 g ] ) , ( [ a3compact ] ) , ( [ a3der ] ) and ( [ a3sup ] ) . when there is no room for confusion , we use @xmath111 .",
    "assumption ( a3 ) is equivalent to @xmath190 \\text { , } g_t \\in \\mathcal{g } ( c).\\ ] ]    the advised reader will have noticed that example [ hittingbarriernoisejump ] , example [ uncertaintyzones ] , example [ irregulargrid ] and example [ autoregressive ] , where time processes are piecewise - constant and may depend on @xmath191 , do nt follow assumption @xmath171 .",
    "the adaptation of theorem [ main1 ] proofs in those examples is discussed in appendix [ adaptationproofs ] .",
    "we have made the choice not to state more general conditions to keep tractability of assumption @xmath171 .",
    "the last assumption is only technical , and also appears in the literature ( mykland and zhang ( 2012 ) , li et al .",
    "( 2014 ) ) .",
    "the filtration @xmath170 is generated by finitely many brownian motions .",
    "we can now state the main theorem .",
    "[ main1 ] assume @xmath192 .",
    "then , there exist processes @xmath193 and @xmath194 adapted to @xmath163 such that stably in law as the tick size @xmath195 , @xmath196 where @xmath197 is a brownian motion independent of the underlying @xmath198-field . the asymptotic bias @xmath193 and the asymptotic variance @xmath194 are defined in section @xmath199 and estimated in section @xmath200 .",
    "[ pathbiased ] ( path - bias ) note that the asymptotic bias term @xmath193 on the right - hand side of ( [ theorem ] ) does nt mean that the hayashi - yoshida estimator is _ biased _ , but rather _ path - biased_. the latter is a weaker statement which means that once we have seen a path , there is a _ bias _ for the hy estimator on this specific path of value @xmath193 . in practice",
    ", we only get to see one path and thus _ bias _ and _ path - bias _ can be confused easily .",
    "when doing simulations , we can observe many paths and the reader should keep in mind that the _ path - bias _ will be different for each path .",
    "in addition , note that if we assume that @xmath133 is bounded and bounded away from @xmath44 on @xmath201 $ ] , there is no _ bias _ in theorem [ main1 ] because @xmath202 = 0 $ ] .",
    "( convergence rate ) at first glance , the convergence rate @xmath203 looks different from the optimal rate of convergence @xmath204 we obtain in the no - endogeneity case .",
    "this is merely a change of perspective because we are looking from the tick size point - of - view .",
    "actually , if for @xmath51 we define @xmath205 as the number of observations before @xmath89 of the @xmath14th asset and the sum of observations of both processes @xmath206 , we have that @xmath207 is exactly of order @xmath208 .",
    "thus , if we define the expected number of observations @xmath209 $ ] , we obtain the optimal rate of convergence @xmath210 in ( [ theorem ] ) .",
    "[ rkjumps ] ( robustness to jumps in price processes ) we assume that we add a jump component to the price process @xmath211 for @xmath51 , where @xmath212 denotes a @xmath213-dimensional finite activity jump process and @xmath214 is either zero ( no jump ) or a real number indicating the size of the jump at time @xmath89 .",
    "we follow exactly the setting of p. 2 in andersen et al .",
    "we assume that @xmath212 is a general poisson process independent of the other quantities . under the same assumptions",
    "the conclusion of theorem [ main1 ] remains valid .",
    "the proof can be found in appendix [ proofjumps ] .",
    "the infinitely many jumps case is complex and beyond the scope of this paper .",
    "this was already the case in the @xmath22-dimensional case ( see remark @xmath215 in p. @xmath216 of li et al .",
    "( 2014 ) ) .",
    "( grid on the original non - log scale ) theorem [ main1 ] covers the particular case where @xmath19 corresponds to the log - price and observations are obtained when the price on the original scale hits a boundary .",
    "this can be done by a reparametrization of @xmath217 by @xmath218 .",
    "( arbitrary number of assets ) the authors chose for simplicity to work only with two assets , but they conjecture that this result would stay true for an arbitrary number of assets , and that our proofs would adapt to show it , at the cost of more involved notations and definitions .",
    "assume that we have a consistent estimator is consistent means that @xmath219 @xmath220 of the bias @xmath221 .",
    "such estimator will be provided in section @xmath200 .",
    "we define the new estimator @xmath222 of high - frequency covariance as the estimate obtained when removing the bias estimate @xmath220 from the hayashi - yoshida estimator @xmath223 with the bias - corrected estimator @xmath222 , we get rid of the asymptotic bias and keep the same asymptotic variance as we can see in the following corollary .",
    "assume @xmath192 . then , stably in law as @xmath195 , @xmath224      we warn the reader interested in implementing the bias - corrected estimator that this section is highly technical and we advise her to go directly to section [ estimation ] and refer to this section only for the definitions .",
    "on the contrary , if the reader wants to understand the main ideas of the proofs , she should take this section as a reference .",
    "we also want to emphasize on the fact that the theoretical values of asymptotic bias and asymptotic variance found at the end of this section are rather abstract and do nt shed easily light on how the change of parameters @xmath133 and @xmath225 in the model would influence the asymptotic bias and asymptotic variance .",
    "the main purpose of this paper is that we do nt need to know the theoretical values in order to compute the estimators in section [ estimation ] .",
    "we need to introduce some definitions in order to compute the theoretical asymptotic bias @xmath193 and the asymptotic variance term @xmath194 .",
    "we first need to rewrite the hy estimator ( [ hy0 ] ) in a different way . for any positive integer @xmath12 , consider the @xmath12th sampling time of the first asset @xmath226 .",
    "we define two random times , @xmath227 and @xmath228 , which are functions of @xmath226 and all the observation times of the second asset @xmath229 , and which correspond respectively to the closest sampling time of the second asset that is strictly smaller than @xmath226 is not a @xmath230-stopping time , which will not be a problem in the proofs ] , and the closest sampling time of the second asset that is ( not necessarily strictly ) bigger than @xmath226 as @xmath231 we consider @xmath232 the increment of the second asset between @xmath227 and @xmath233 @xmath234}^{(2)}. \\end{aligned}\\ ] ] rearranging the terms in ( [ hy0 ] ) gives us ( except for a few terms at the edge ) @xmath235    the representation in ( [ hy01 ] ) is very useful in the sense that it gives a natural order between the terms in the sum . nevertheless , any term of this sum is a priori correlated with the other terms .",
    "we will rearrange once again the terms in ( [ hy01 ] ) , so that each term is only correlated with the previous and the next term of the sum . in this case",
    ", we say that they are _",
    "1-correlated_. for this purpose , we need to introduce some notation .",
    "we remind the reader that @xmath236 is the two - dimensional vector of sampling times , where for each @xmath51 the @xmath14th component @xmath237 is equal to the sequence of sampling times associated with the @xmath14th asset .",
    "we will construct a subsequence @xmath238 of @xmath239 that also depends on the observation times of the second asset @xmath240 , and will be such that we can write the hayashi - yoshida estimator as a 1-correlated sum similar to ( [ hy01 ] ) , except the new sampling times @xmath241 will replace the original observation times @xmath242 .",
    "the new sampling times @xmath241 are obtained using the following algorithm .",
    "we define @xmath243 , and recursively for @xmath12 any nonnegative integer @xmath244 in words , if we sit at the observation time @xmath241 of the first asset , we wait first to hit an observation time of the second asset , and we then choose the next strictly bigger observation time of the first asset . in analogy with ( [ tau-0s ] ) , ( [ tau-0 ] ) , ( [ tau+0 ] ) and ( [ inc-+0 ] ) , we define the following times @xmath245}^{(2 ) } \\text { for } i \\geq 1.\\end{aligned}\\ ] ] first , observe that , except for maybe a few terms at the edge , we can rewrite ( [ hy01 ] ) as @xmath246 also , we define the following compensated increments of the hy estimator @xmath247 note that they are compensated in the sense that they are centered ( if we decompose @xmath248 into a left ( @xmath249 ) , a central and a right ( @xmath250 ) part and condition the expectation , this is straightforward to show ) . similarly , we can show that they are 1-correlated .",
    "the idea of the proof is the following .",
    "if we consider the volatility matrix @xmath133 and the grid function @xmath225 to be constant over time , we can express the conditional returns of the normalized error of hy as a homogeneous markov chain ( of order 1 ) , show that the markov chain is uniformly ergodic and thus use results in the limit theory of markov chains ( see , e.g. , meyn and tweedie ( 2009 ) ) to show that it has a stationary distribution .",
    "then , we prove that we can approximate locally the returns of the normalized error when the volatility matrix and grid function are not constant by the returns when holding them constant on a small block . finally , using limit theory techniques developed in mykland and zhang ( 2012 ) together with standard probability results of conditional distribution ( see , e.g. , breiman ( 1992 ) )",
    ", we can bound uniformly in time the error of the returns when holding the volatility matrix and grid function constant .    based on the definitions introduced in appendix [ appdef ]",
    ", we can define the _ instantaneous variance _ of the normalized hy estimate s error ( [ psiav1 ] ) , which depends on the volatility matrix @xmath251 and the grid @xmath252 . similarly , we also define the _ instantaneous covariance _ between the normalized hy s error and the first asset price ( [ psiac1 ] ) , and the _ instantaneous covariance _ between the error and the second asset price ( [ psiac2 ] ) .",
    "finally , we define the _ instantaneous 1-correlated time _ , which is the approximation of @xmath253 $ ] , where if @xmath254 is a @xmath134-stopping time , @xmath255 $ ] is defined as the conditional distribution of @xmath256 given @xmath257 .",
    "@xmath258,\\\\ \\label{psiac1 } \\psi^{ac1 } ( \\tilde{\\sigma } , \\tilde{g } , x , u ) & : = & { \\mathbb{e}}\\big [   \\tilde{n}_2 \\delta \\tilde{x}_{\\tilde{\\tau}_2^{1c}}^{(1 ) } \\big ] , \\\\",
    "\\label{psiac2 } \\psi^{ac2 } ( \\tilde{\\sigma } , \\tilde{g } , x , u ) & : = & { \\mathbb{e}}\\big [   \\tilde{n}_2 \\delta \\tilde{x}_{\\tilde{\\tau}_2^{1c,-,+}}^{(2 ) } \\big ] , \\\\",
    "\\label{psitau } \\psi^{\\tau } ( \\tilde{\\sigma } , \\tilde{g } , x , u ) & : = & { \\mathbb{e}}\\big [ \\delta \\tilde{\\tau}_2^{1c } \\big].\\end{aligned}\\ ] ]    the reader might expect @xmath259 in lieu of @xmath260 in ( [ psiav1 ] ) , ( [ psiac1 ] ) , ( [ psiac2 ] ) and ( [ psitau ] ) .",
    "actually , we can not use @xmath259 directly from the definition because the corresponding time @xmath261 .",
    "we would need to set it to @xmath262 to alter the definition of ( [ psiav1 ] ) , ( [ psiac1 ] ) , ( [ psiac2 ] ) and ( [ psitau ] ) , which we have chosen not to do for the sake of clarity .",
    "set @xmath263 and for any positive integer @xmath12 @xmath264}^{(4 ) } ,   \\tilde{\\tau}_{i}^{1c } - \\tilde{\\tau}_{i}^{1c,- } \\big ) .\\end{aligned}\\ ] ] for any nonnegative integer @xmath12 , we consider @xmath265 the distribution of @xmath266 .",
    "we also introduce the notation @xmath267 . by the strong markov property of brownian motion",
    ", we can show that @xmath266 is a homogeneous markov chain ( of order @xmath22 ) on the state space @xmath268 . in the following lemma",
    ", we show that there exists a stationary distribution of @xmath265 .",
    "[ distribexists ] let @xmath269 be a four - dimensional vector such that @xmath184 and consider @xmath251 a constant volatility matrix such that @xmath270 and @xmath271 a constant grid .",
    "then , there exists a stationary distribution @xmath272 .",
    "the proof of lemma [ distribexists ] can be found in the appendix ( proof of lemma [ approxdistrib ] ) .",
    "the next definition is the average ( regarding the stationary distributions ) of the instantaneous variance , covariances and 1-correlated time . for any @xmath273 ,",
    "@xmath274 we introduce the notation @xmath275 and consider the following quantities needed to compute the asymptotic bias and variance .",
    "@xmath276 we express now @xmath277 the quantity integrated to obtain the asymptotic variance .",
    "@xmath278 @xmath279 the asymptotic bias is defined as @xmath280 where @xmath281    ( asymptotic bias ) looking at the expressions for @xmath282 and @xmath283 , one can be tempted to think that because of the @xmath284 term in @xmath285 , the bias will increase drastically when both assets are highly correlated . in this case , the reader should keep in mind that the second term of @xmath282 , when integrated with respect to @xmath286 , and @xmath283 , when integrated with respect to @xmath287 , will be roughly of the same magnitude , with opposite signs , and thus there is no explosion of asymptotic bias .",
    "we chose the above asymptotic bias representation because it is straightforward to build estimators from it .",
    "we can also express the asymptotic bias differently .",
    "for this purpose , we can rewrite the log - price process as @xmath288 where @xmath289 and @xmath290 are independent brownian motions .",
    "let @xmath291 be the part of @xmath160 that is not correlated with @xmath159 .",
    "we can express the asymptotic bias as @xmath292 . in this case ,",
    "@xmath293 and @xmath294 where @xmath295 is defined in the proofs .",
    "we can show that this limit exists , and does not explode when both assets are highly correlated .",
    "we need to introduce some new notations .",
    "we recall that @xmath296 is the number of observations corresponding to the first asset before @xmath22 and we also define @xmath297 the number of 1-correlated observations before 1 , i.e. @xmath298 . in practice ,",
    "the first step is to transform the returns of the first asset @xmath299 into 1-correlated returns @xmath300 using algorithm ( [ algo1c ] ) . then , for each asset , we will chop the data into @xmath301 blocks and on each block @xmath302 we will estimate @xmath303 , @xmath304 and @xmath305 , pretending that the volatility matrix @xmath133 and grid @xmath225 are block - constant .    because there is asynchronicity in the observation times , the blocks of each asset are not exactly equal .",
    "let @xmath306 be the block size .",
    "for the first asset , we consider _ block _ @xmath307 $ ] , _ block _ @xmath308 $ ] , etc .",
    "for the second asset , we let _ block _ @xmath309 $ ] , _ block _ @xmath310 $ ] , etc .",
    "in the following , we will say @xmath311 when @xmath312 .",
    "similarly , we say @xmath313 when @xmath314 .",
    "finally , we define @xmath315 if @xmath316 .",
    "first , we estimate the volatility of both assets using the corrected estimator in li et al .",
    "( 2014 ) . to do this",
    ", we need to define an estimate of the spot volatility on each block for each asset @xmath51 by @xmath317 then , we estimate the asymptotic bias of the volatility via @xmath318 we obtain the bias - corrected estimators of volatility on each block : @xmath319 then , we estimate the correlation between both assets using the _ naive _ hy estimator @xmath320 we then build an estimator of the compensated increments of the hy estimator , following the definition in ( [ compensated ] ) , @xmath321 the next step is to estimate the instantaneous variance ( [ psiav1 ] ) , both instantaneous covariances ( [ psiac1 ] ) and ( [ psiac2 ] ) and the instantaneous 1-correlated time ( [ psitau ] ) on each block .",
    "this is done by taking the sample average of the corresponding estimated quantities .",
    "note that we do nt directly estimate @xmath322 , @xmath323 , @xmath324 and @xmath325 , but rather a scaling version of them , i.e. @xmath326 , @xmath327 , @xmath328 and @xmath329 . in practice",
    ", we can always assume @xmath330 by scaling @xmath225 by the tick size , and thus we match the definitions of the following estimators with ( [ psiav1])-([psitau ] ) .",
    "for the sake of simplicity , we assume that the number of 1-correlated observations of the last block @xmath301 is also @xmath306 . in practice , this will be most likely different from @xmath306 , and thus the denominator of ( [ estphiav])-([estphitau ] ) will have to be changed so that it is equal to the number of 1-correlated observations in this last block .",
    "the estimates are given by @xmath331 we estimate now the quantities ( [ k1 ] ) and ( [ kperp ] ) as @xmath332 we follow ( [ ab1 ] ) and ( [ ab2 ] ) to estimate the bias integrated terms @xmath333 and @xmath334 on each block @xmath335 for the variance term @xmath277 , we decide not to use the direct definition in ( [ av ] ) because it can provide negative estimates .",
    "instead , we will be using the following estimator @xmath336 we define the final estimators of asymptotic bias and asymptotic variance as @xmath337 as a corollary of theorem @xmath22 , we obtain the following result , which states the consistency of ( [ estab ] ) and ( [ estav ] ) .    [ estcor ]",
    "there exists a choice of the block size @xmath306 can be found in the proofs of theorem 1 ] such that when @xmath195 , we have @xmath338 in particular , in view of corollary 2 , the bias - corrected estimator @xmath339 is such that @xmath340    ( exchanging @xmath159 and @xmath160 ) when estimating the asymptotic bias and the asymptotic variance , we considered one specific asset to be @xmath159 and the other one to be @xmath160 .",
    "we could exchange @xmath159 and @xmath160 , and find new estimators @xmath341 and @xmath342 according to the previous definitions .",
    "one could then take @xmath343 ( respectively @xmath344 ) as final estimators of asymptotic bias ( asymptotic variance ) .",
    "( optimal block size ) in practice , the optimal block size @xmath306 is not straightforward to choose . on the one hand , @xmath306 should be as small as possible so that the volatility matrix @xmath133 and the grid @xmath225 are almost constant on each block , and thus ( [ estphiav])-([estphitau ] ) are less biased .",
    "on the other hand , we need as many observations as we can on each block , so that the variance of approximations ( [ estphiav])-([estphitau ] ) is not too big .",
    "we are facing here the usual bias - variance tradeoff .",
    "we consider four different settings in this part . we describe here the first one .",
    "we assume the same setting as the toy model described in example [ hittingbarrier ] , in two dimensions .",
    "thus , there exists a four - dimensional parameter @xmath345 such that for any @xmath40 and any @xmath91 , @xmath346 , @xmath347 , @xmath348 and @xmath349 .",
    "we assume that the two - dimensional price process @xmath350 has a null - drift .",
    "also , we assume that the volatility of the first process is @xmath351 where @xmath352 and the volatility of the second process @xmath353 where @xmath354 , and that the correlation between both assets is @xmath355 .",
    "we set @xmath356 .",
    "according to this rule , a change of price occurs whenever the price of the first ( respectively second ) asset increases by @xmath357 ( @xmath358 ) or decreases by @xmath359 ( @xmath359 ) .",
    "finally , we assume that the price processes @xmath350 and the time processes @xmath360 are equal .",
    "the second setting is similar to the first setting , except that we assume now a stochastic volatility heston model .",
    "specifically , we assume that @xmath361 where the constant high - frequency covariance between @xmath74 and @xmath362 is fixed to @xmath363 , and @xmath364 are uncorrelated with each other .",
    "we choose to work with drift @xmath365 , and to add leverage effect @xmath366 are selected to be @xmath367 . finally , @xmath368 , the volatility of volatility @xmath369 , and the volatility starting values @xmath370 .",
    "we consider now the third setting , which goes one step further than the previous setting .",
    "we assume a jump - diffusion model for both the price and the volatility .",
    "formally , we assume that @xmath371 where the jumps @xmath372 follow a @xmath215-dimensional poisson process with intensity @xmath373 @xmath374 .",
    "the jump sizes are taken to be @xmath22 or @xmath375 with probability @xmath376 for price processes , and @xmath377 or @xmath378 with half - probability for volatility processes .    in the fourth",
    "setting , we consider another model of arrival times , namely example [ uncertaintyzones ] .",
    "we set the tick size @xmath379 and the friction parameter @xmath380 . price and",
    "volatility processes are assumed to follow the same model as in the second setting .",
    "we simulate price processes and observation times for 10 years of @xmath381 business days .",
    "we choose @xmath382 for settings 2 to 4 .",
    "we provide in table [ num ] a summary of the comparison results between hy and the bias - corrected hy .",
    "as expected from the theory , the rmse is improved when using the bias - corrected estimator in example [ hittingbarrier ] . in example",
    "[ uncertaintyzones ] , the bias - corrected hy does nt seem to perform better than hy .",
    "we conjecture that there is no asymptotic bias in example [ uncertaintyzones ] , and that this is the reason why we do nt observe any difference between the two estimators in that simple model .",
    "in addition , the sample bias is almost the same when using hy and the bias - corrected estimator for the four different settings , which is also expected from remark [ pathbiased ] .",
    "furthermore , this sample bias tends to @xmath44 , which comes from the fact that both estimators are consistent .",
    "finally , the standardized feasible statistic ( [ feasiblestat ] ) in the first setting is reported in table [ tablefeasiblestat ] and plotted in figure [ plotfeasiblestat ] .",
    "we have introduced in this paper the hbt model , and we have shown that it is more general than some of the endogenous models of the literature .",
    "this model can be extended to a model including more general noise structure in observations , and even noise in sampling times .",
    "this is investigated in potiron ( 2016 ) .    under this model ,",
    "we have proved the central limit theorem of the hayashi - yoshida estimator .",
    "our main theorem states that there is an asymptotic bias .",
    "accordingly , we built a bias - corrected hy estimator .",
    "we also computed the theoretical standard deviation , and we provided consistent estimates of it .",
    "numerical simulations corroborate the theory .",
    "the techniques used for the proof of the main theorem can be applied to more general models and to other problems such as the estimation of the integrated variance of noise , integrated betas , etc . in particular , independence between the efficient price process and the noise",
    "is not needed in the model .",
    "as long as we can approximate the joint distribution of the noise and the returns by a markov chain , ideas of our proof can be used .",
    "this is also studied in potiron ( 2016 ) .",
    "we define in this section some quantities assuming the volatility matrix @xmath133 and the grid function @xmath225 are constant . for that purpose ,",
    "let @xmath383 be a four dimensional wiener process , @xmath269 a four - dimensional vector such that @xmath184 and @xmath251 a constant volatility matrix such that the associated @xmath384 , which is the analog of @xmath153 defined in section @xmath385 when we replace @xmath133 by @xmath251 , is stritcly bigger than @xmath44 and @xmath271 a constant grid function . in analogy with the definition of the grid function @xmath225 in @xmath171",
    ", we assume that @xmath252 can be written in terms of the down and up functions of both assets , i.e. @xmath386 where for each @xmath51 we have @xmath387 .",
    "also , we introduce @xmath268 the subspace of @xmath388 defined as @xmath389 if we set @xmath390 and the corresponding sampling times of both assets @xmath391 , where for @xmath51 we have @xmath392 , we define the observation times of the first asset as @xmath393 and recursively for @xmath12 any positive integer @xmath394 \\big\\ } .\\ ] ] these stopping times will be seen as approximations of the observation times of the first asset when we hold the volatility matrix @xmath133 and the grid @xmath225 constant .",
    "we will always start our approximation at a _",
    "1-correlated _ observation time @xmath395 , which corresponds to an observation time of the first asset . as the sampling times of the second asset",
    "are not synchronized with the ones from the first asset , we need two more quantities @xmath396 to approximate the observation times of the second asset .",
    "they correspond respectively to the increment of the second asset s time process @xmath162 since the last observation of the second asset occured and the time elapsed since the last observation time of the second asset .",
    "we define @xmath397 , @xmath398 \\big\\},\\ ] ] and for any integer @xmath399",
    "@xmath400 \\big\\ } .\\ ] ] similarly , we define the analogs of ( [ tau-0s])-([tau-0 ] ) , ( [ tau+0 ] ) , ( [ inc-+0 ] ) , ( [ algo1c ] ) , ( [ tau1c-0s])-([tau1c-0 ] ) , ( [ tau1c+0 ] ) , ( [ inc1c-+0 ] ) and ( [ compensated ] ) respectively as @xmath401 , @xmath402 , @xmath403 , @xmath404 , @xmath405 , @xmath406 and @xmath407 by putting tildes on the quantities in the definitions .      without loss of generality , we choose to work under the third scenario defined in section @xmath408 , i.e. the asset price is different from the time process for both assets .",
    "because we shall prove stable convergence , and because of the local boundedness of @xmath198 ( because by ( a1 ) @xmath198 is continuous ) , and that @xmath409 } \\lambda_t^{\\min } > 0 $ ] we can without loss of generarality assume that for all @xmath167 $ ] there exists some nonrandom constants @xmath410 and @xmath411 such that for any eigen - value @xmath412 of @xmath133 we have @xmath413 by using a standard localization argument such that the one used in section 2.4.5 of mykland and zhang ( 2012 ) .",
    "one can further supress @xmath414 as in section @xmath415 ( pp .",
    "1407 - 1409 ) of mykland and zhang ( 2009 ) , and act as if @xmath416 is a martingale .",
    "we define the subspace @xmath417 of matrices of dimension @xmath418 such that @xmath419 , for any eigen - value @xmath420 of @xmath421 , we have @xmath422 and @xmath423 $ ] . by ( [ a2rho34 ] ) of @xmath166 and ( [ smsp ] ) , we will assume in the following that @xmath424 $ ] , @xmath425 .",
    "we define @xmath426 the process ( of dimension @xmath418 ) on @xmath43 such that @xmath427,\\\\        \\sigma_t^p & = & \\sigma_1 & \\forall t \\in [ 1,\\infty ) .",
    "\\end{array }     \\right .\\ ] ] define now @xmath428 the process such that for all @xmath40 @xmath429 because @xmath428 and @xmath416 have the same initial value and follow the same stochastic differential equation on @xmath131 $ ] , they are equal for all @xmath167 $ ] . for simplicity , we keep from now on the notation @xmath416 for @xmath428 .    in the following , @xmath430 will be defining a constant which does not depend on @xmath12 or @xmath191 , but that can vary from a line to another .",
    "also , we are going to use the notation @xmath431 as a subtitute of @xmath432 , where @xmath433 can take various names , such that @xmath434 and so on .",
    "let @xmath435 a ( not strictly ) increasing non - random sequence such that @xmath436 to keep notation as simple as possible , we define @xmath437 , @xmath438 , @xmath439 .",
    "we also let @xmath440 , where @xmath167 $ ] .",
    "also , we recall the notation @xmath441 finally , for @xmath442 , we define @xmath443 . we show that these quantities tend to 0 almost surely in the following lemma .",
    "we can follow the proof of lemma @xmath445 in robert and rosenbaum ( 2012 ) to prove that for @xmath446 , @xmath447 . then",
    ", we can notice that a.s .",
    "@xmath448 to deduce that @xmath449 .",
    "to show that @xmath450 , define the process @xmath137 such that @xmath451 and @xmath452 we have @xmath453}^{(2 ) } + z_{\\tau_{i-1,n}^{1c } } & \\forall t \\in [ \\tau_{i-1,n}^{1c } , \\tau_{i-1,n}^{1c,+}],\\\\      \\delta x_{[\\tau_{i-1,n}^{1c,+},t]}^{(1 ) } + z_{\\tau_{i-1,n}^{1c,+ } } & \\forall t \\in [ \\tau_{i-1,n}^{1c,+ } , \\tau_{i , n}^{1c } ] .",
    "\\end{array }     \\right .\\ ] ] substituting @xmath416 in lemma 4.5 of robert and rosenbaum s proof by our @xmath137 , we can follow the same reasoning .",
    "the only main change will be that in their notation @xmath454 , but this tends to 0 by ( [ hnalphan ] ) .",
    "[ s ] let @xmath143 be a bounded random process such that for all non - random sequence @xmath456 , if @xmath457 , then @xmath458 . let also a random sequence @xmath459 such that @xmath460",
    ". then we have @xmath461 that @xmath462    as @xmath143 is bounded , convergence in @xmath463 implies convergence in @xmath464 for any @xmath465 .",
    "hence it is sufficient to show that @xmath466 .",
    "let @xmath467 and @xmath468 , we want to show that @xmath469 such that @xmath470 , we have @xmath471 @xmath472 non - random @xmath473 such that @xmath474 . also , @xmath469 such that @xmath470 , @xmath475 .",
    "thus @xmath476",
    "we aim to define the approximations of observation times on blocks",
    "@xmath477 \\right)_{i \\geq 0}.\\ ] ] we need some definitions first .",
    "let @xmath478 a sequence of independent 4-dimensional brownian motions ( i.e. for each @xmath12 , @xmath479 is a 4-dimensional brownian motion ) , independent of everything we have defined so far .",
    "we define @xmath480 , @xmath481 } & \\forall t \\in [ 0 , \\delta \\tau_{i+1,n}^{h}],\\\\",
    "\\delta w_{[\\tau_{i , n}^{h},\\tau_{i+1,n}^{h } ] } + c_{t- \\delta \\tau_{i+1,n}^{h}}^{(i ) } & \\forall t \\geq \\delta \\tau_{i+1,n}^{h } ,     \\end{array }     \\right .\\ ] ] and @xmath482}^{(4 ) } , \\tau_{i , n}^h - \\tau_{i , n}^{h,- }   \\right).\\ ] ] to keep symmetry in notations , we define for all integers @xmath12 and @xmath191 positive integers , @xmath483 consisting of the observation times of the process 1 after @xmath484 , substracting the value of @xmath484 , i.e. @xmath485 where @xmath486 is the ( random ) index on the original grid of process 1 corresponding to @xmath484 ( @xmath487 ) . for process 2 , we define @xmath488 and for integers @xmath489 , @xmath490 , where @xmath491 is the index on the original grid of process 2 corresponding to the smallest observation time of process 2 bigger ( not necessarily strictly ) than @xmath484 .",
    "we also define @xmath492 , @xmath493 , @xmath494 , @xmath495 , @xmath496 , @xmath497 , @xmath498 , @xmath499 , @xmath500 , @xmath501 following the construction we used to define ( [ tau-0s ] ) , ( [ tau-0 ] ) , ( [ tau+0 ] ) , ( [ algo1c ] ) , ( [ tau1c-0s ] ) , ( [ tau1c-0 ] ) and ( [ tau1c+0 ] )",
    ". we also set @xmath502}^{(4 ) } , \\tau_{i , n}^{h } - \\tau_{i , n}^{h,- }   \\right).\\ ] ]    [ esptauk ] for @xmath503 , any real @xmath504 , any positive integer @xmath12 and @xmath191 , any non - negative integer @xmath505 , we have @xmath506 such that @xmath507 \\leq c_{l}^+ \\alpha_n^{2l},\\end{aligned}\\ ] ] where @xmath508 and @xmath509 \\leq c_{l}^+ \\alpha_n^{2l}.\\end{aligned}\\ ] ]    for @xmath510 , because of ( [ esptauk ] ) and ( [ smsp ] ) , we can deduce ( [ esptauk1 ] ) using well - known result on exit zone of a brownian motion ( see for instance borodin and salminen ( 2002 ) ) .",
    "( [ esptauk2 ] ) can be deduced using dubins - schwarz theorem for continuous local martingale ( see , e.g. th .",
    "@xmath511 in revuz and yor ( 1999 ) ) .",
    "if @xmath512 writing @xmath513 and working those two terms , we can obtain ( [ esptauk1 ] ) and ( [ esptauk2 ] ) .",
    "let @xmath468 and @xmath527 .",
    "@xmath528 we take the @xmath529 and use ( [ sumtightcond ] ) .",
    "we obtain @xmath530 we now tend @xmath531 and conclude using lemma [ numb ] .",
    "the second statement is proved in the same way .      for any brownian motion @xmath534",
    ", by the scale property we have that @xmath535 .",
    "thus , if we define @xmath536 \\}$ ] and @xmath537 \\}$ ] , we have that @xmath538 \\ } \\overset{\\mathcal{l}}{= } \\alpha^{-2 } \\tau_{\\alpha}.\\end{aligned}\\ ] ] we deduce that @xmath539 we can prove the lemma based on the way we proved ( [ scale1 ] ) , at the cost of 2-dimension definitions that would be more involved and straightforward applications of strong markov property of brownian motions that we wo nt write , so that we do nt lose ourselves in the technicality of this proof .",
    "we introduce the number of points in the @xmath12th block in the @xmath14th process as the following @xmath540 we also introduce the total number of points in the @xmath12th block @xmath541 .",
    "we show now that we can control uniformly the error of the approximations of the observation times .",
    "first step : we define @xmath548 .",
    "we show in this step that @xmath549 we define the accumulated time of approximated durations , i.e. @xmath550 using lemma [ esptauk ] together with lemma [ numb ] , @xmath551 such that @xmath552 we define @xmath553 and @xmath554 $ ] , @xmath555 a slight modification of the proof of lemma [ snk ] will conclude .",
    "second step : we show that we can do a localization in the number of observations in the i - th block , i.e. there exists a non - random @xmath556 such that @xmath557 converges uniformly ( in @xmath12 ) towards @xmath44 and @xmath556 increasing at most linearly with @xmath306 , i.e. we have @xmath558 where @xmath559 .    to prove ( [ step2 ] ) , we need some definitions .",
    "define for @xmath546 the order of observation times @xmath560 and the order of the approximated observation times @xmath561 in the following way .",
    "let @xmath562 the sorted set of all observation times ( corresponding to process 1 and 2 ) strictly greater than @xmath484 .",
    "then for @xmath489 , we will set @xmath563 if the j - th observation time in @xmath564 corresponds to an observation of the first process and @xmath565 if it corresponds to an observation of the second process .",
    "similarly , we set @xmath566 the sorted set of all approximated times @xmath567 .",
    "@xmath568 are defined in the same way .",
    "there exists a @xmath569 such that for all integers @xmath570 : @xmath571 indeed , let @xmath572 the ( random ) index such that @xmath573 .",
    "conditionally on @xmath574 , we know that @xmath575 if @xmath576}^{(4)}$ ] crosses @xmath577 or @xmath578 before @xmath579}^{(3)}$ ] crosses @xmath580 or @xmath581 . using ( [ a2rho34 ] ) of ( a2 ) and ( [ smsp ] ) , we can easily bound away from 0 this probability , thus we deduce ( [ p ] ) . now , using ( [ algo1c ] ) together with ( [ p ] ) and strong markov property of brownian motions , we deduce ( [ step2 ] ) .",
    "third step : let @xmath582 such that @xmath583 , @xmath584 $ ] and @xmath585 .",
    "we define @xmath586 , where @xmath59 is a standard brownian motion .",
    "we show that @xmath587 \\leq \\gamma^{(l ) } \\left ( \\epsilon \\right)\\end{aligned}\\ ] ] where @xmath588 .    in order to show ( [ tauappstep2 ] ) ,",
    "let @xmath589 @xmath590 by ( [ a3 g ] ) and ( [ a3der ] ) of ( a3 ) , we have @xmath591 . conditionally on @xmath592 , using strong markov property of brownian motions , we can show that @xmath593 \\overset{\\epsilon \\rightarrow 0}{\\rightarrow } 0 $ ] using theorem @xmath213 in potzelberger and wang ( 2001 ) for instance .",
    "fourth step : let @xmath594 .",
    "we show here that @xmath595 = o_p^u \\left (   \\alpha_n^{2l } \\right).\\end{aligned}\\ ] ] the idea is to show that by recurrence in @xmath505 , @xmath596 $ ] can be arbitrarily small when @xmath191 grows .",
    "it is then a straightforward analysis exercise to use the localization in second step and choose a different sequence @xmath597 if necessary , that will still be non - random increasing and following ( [ infty ] ) and ( [ hnalphan ] ) , so that the sum in ( [ tauappstep3 ] ) will be also arbitrarily small .",
    "let s start with @xmath598 and @xmath599 .",
    "@xmath600 = { \\mathbb{e}}\\left [ \\big| \\tau_{i,1,n}^{(k ) } -   \\tilde{\\tau}_{i,1,n}^{(k ) } \\big|^l \\mathbf{1}_{e_{i , n } } \\right ] + { \\mathbb{e}}\\left [ \\big| \\tau_{i,1,n}^{(k ) } -   \\tilde{\\tau}_{i,1,n}^{(k ) } \\big|^l \\mathbf{1}_{e_{i , n}^c } \\right],\\ ] ] where @xmath601 with @xmath602}{\\sup } \\big|   \\delta x_{[\\tau_{i , n}^h , s]}^{(1 ) } - \\delta \\tilde{x}_{[\\tau_{i , n}^h , s]}^{(1 ) } \\big| < \\eta_{1,n } \\bigg\\},\\ ] ] @xmath603}{\\sup } \\big\\|    g_s^{(1 ) } - g_{\\tau_{i , n}^h}^{(1 ) } \\big\\|_{\\infty } < \\eta_{1,n } \\bigg\\},\\ ] ] @xmath604 , @xmath605 and @xmath606 \\right)^{1/2}.$ ] by ( [ scale1 ] ) and ( [ tauappstep2 ] ) , @xmath607 \\leq c \\alpha_n^{2l } \\left ( \\gamma^{(l ) } \\left(2 q_n \\right ) + \\gamma^{(l ) } \\left(- 2 q_n \\right )   \\right).\\ ] ] using cauchy - schwarz inequality and lemma [ esptauk ] , @xmath608 \\leq c \\alpha_n^{2l } { \\mathbb{p}}\\left ( e_{i , n}^c \\right)^{1/2 } \\leq   c \\alpha_n^{2l } \\left ( { \\mathbb{p}}\\left ( \\left ( e_{i , n}^{(1 ) } \\right)^c \\right ) + { \\mathbb{p}}\\left ( \\left ( e_{i , n}^{(2 ) } \\right)^c \\right ) \\right)^{1/2}.\\ ] ] on the one hand , @xmath609}{\\sup } \\big|    \\delta x_{[\\tau_{i , n}^h , s]}^{(1 ) } - \\delta \\tilde{x}_{[\\tau_{i , n}^h , s]}^{(1 ) } \\big| \\right]\\\\   & \\leq & c \\left ( \\eta_{1,n } \\right)^{-1 } \\underset{1 \\leq u , v \\leq 4}{\\max } { \\mathbb{e}}\\left [ \\left ( \\int_{\\tau_{i , n}^h}^{\\tau_{i , n}^h + \\tau_{i,1,n}^{(1 ) } \\vee    \\tilde{\\tau}_{i,1,n}^{(1 ) } } \\left ( \\sigma_s^{u , v } - \\sigma_{\\tau_{i , n}^h}^{u , v } \\right)^2 ds \\right)^{1/2 } \\right ] \\\\   & \\leq & c \\left ( \\eta_{1,n } \\right)^{-1 } \\underset{1 \\leq u , v \\leq 4}{\\max } { \\mathbb{e}}\\left [ \\left ( \\left ( \\tau_{i,1,n}^{(1 ) } \\vee    \\tilde{\\tau}_{i,1,n}^{(1 ) } \\right ) s \\left ( \\sigma^{u , v } , s_n^h \\vee \\tilde{s}_n^h \\right)^2 \\right)^{1/2 } \\right ] \\\\   & \\leq & c \\left ( \\eta_{1,n } \\right)^{-1 } \\left ( { \\mathbb{e}}\\left [ \\tau_{i,1,n}^{(1 ) } \\vee \\tilde{\\tau}_{i,1,n}^{(1 ) } \\right ] \\right)^{1/2 } z_n \\\\   & \\leq & c z_n^{1/2}.\\end{aligned}\\ ] ] where we used markov inequality in the first inequality , conditional burkholder - davis - gundy inequality in the second inequality , cauchy - schwarz inequality in the fourth inequality , lemma [ esptauk ] in the last inequality .",
    "on the other hand , @xmath610}{\\sup } \\big\\|    g_s^{(1 ) } - g_{\\tau_{i , n}^h}^{(1 ) } \\big\\|_{\\infty } \\right ] \\\\   & \\leq & c \\left ( \\eta_{1,n } \\right)^{-1 } { \\mathbb{e}}\\left [ \\left ( \\tau_{i,1,n}^{(1 ) } \\vee \\tilde{\\tau}_{i,1,n}^{(1 ) } \\right)^d \\right ] \\\\   & \\leq & c \\alpha_n^{d-1/2}.\\end{aligned}\\ ] ] where we used markov inequality in the first inequality , ( [ a3sup ] ) of ( a3 ) in the second inequality , lemma [ esptauk ] in the last inequality . in summary",
    ", we have @xmath611 \\leq c \\alpha_n^{2l } \\left ( \\gamma^{(l ) } \\left(2 q_n \\right ) + \\gamma^{(l ) } \\left(- 2 q_n \\right )   + z_n^{1/2 } + \\alpha^{d-1/2 } \\right).\\ ] ] which we can make arbitrarily small , because @xmath612 by first step together with lemma [ s ] and the continuity of @xmath198 ( a1 ) . the case with @xmath613",
    "is very similar .",
    "finally , for @xmath614 , the same kind of computation techniques , using in addition ( [ a3der ] ) of ( a3 ) , will work .",
    "fifth step : prove that uniformly ( in @xmath12 ) @xmath615 to show ( [ tauappstep4 ] ) , let @xmath616 .",
    "we define the ( random ) index @xmath617 such that @xmath618 . modifying suitably @xmath597",
    "if needed , there exists ( using fourth step ) a sequence @xmath619 such that @xmath620 using ( [ 5a ] ) and ( [ 5b ] ) , we can verify ( [ tauappstep4 ] ) by recurrence .",
    "sixth step : we prove here ( [ tauapp1 ] ) and ( [ tauapp2 ] ) . using lemma [ esptauk ] and ( [ tauappstep4 ] ) we obtain @xmath621 = { \\mathbb{e}}\\left [ \\big| \\delta \\tau_{i , j , n}^{1c } -    \\delta \\tilde{\\tau}_{i , j , n}^{1c } \\big|^l \\mathbf{1 } _ { \\ { \\forall j \\leq m_n , o_{i , j , n } = \\tilde{o}_{i , j , n } \\ } } \\right ] + o_p^u \\left ( \\alpha_n^{2l } \\right).\\ ] ] the first term on the right part of the inequality can be bounded by @xmath622\\ ] ] @xmath623 \\bigg).\\ ] ] both terms can be treated with the same trick . using the second step and lemma [ esptauk ] ,",
    "the first term is equal to @xmath624   + o_p^u \\left(\\alpha_n^{2l } \\right).\\ ] ] the sum is obviously bounded by @xmath625.\\ ] ] and using ( [ tauappstep3 ] ) , we prove ( [ tauapp1 ] )",
    ". we can deduce ( [ tauapp2 ] ) with the same kind of computations .",
    "let @xmath295 the interpolated normalized error , i.e. @xmath626}^{(1 ) }   \\delta x_{[\\tau_{i-1,n}^{1c,- } \\wedge t,\\tau_{i , n}^{1c,+ } \\wedge t]}^{(2 ) } - \\int_0^t \\sigma_s^{(1 ) } \\sigma_s^{(2 ) } \\rho_s^{1,2 } ds \\right).\\ ] ] @xmath627 corresponds exactly to the normalized error of the hayashi - yoshida estimator if we observe the price of both assets at time @xmath89 .",
    "we recall the definition of @xmath628            first step : approximating with holding volatility constant .",
    "set @xmath635 where @xmath636 is the i - th component of the vector a. we want to show that : @xmath637\\ ] ] @xmath638 + o_p \\left ( 1 \\right).\\ ] ] noting @xmath639 and @xmath640 , it is sufficient to show that @xmath641 \\overset{{\\mathbb{p}}}{\\rightarrow } 0,\\ ] ] that we can rewrite as @xmath642 \\overset{{\\mathbb{p}}}{\\rightarrow } 0 $ ] . using lemma [ sumtight ] , it is sufficient to show that @xmath524 : @xmath643 \\overset{{\\mathbb{p}}}{\\rightarrow } 0.\\ ] ] thus , it is sufficient to show the convergence @xmath644 of this quantity , i.e. that @xmath645 \\rightarrow 0.\\ ] ] we have that @xmath646 where @xmath647 and @xmath648 .",
    "we have that @xmath649 where @xmath650 @xmath651 let s show that @xmath652 \\rightarrow 0 $ ] .",
    "we can write it as @xmath653 , where @xmath654 we want to show that @xmath655   \\rightarrow 0 $ ] .",
    "we define : @xmath656    using cauchy - schwarz inequality , we deduce : @xmath657 & = & { \\mathbb{e}}\\left [ \\left ( e_{i , n}^{(1 ) } + e_{i , n}^{(2 ) } \\right )    \\left ( e_{i , n}^{(1 ) } - e_{i , n}^{(2 ) } \\right ) \\mathbf{1 } _ {   \\ { \\tau_{i-1,n}^s < t \\ } } \\right]\\\\ & \\leq & \\left ( { \\mathbb{e}}\\left [ \\left ( e_{i , n}^{(1 ) } + e_{i , n}^{(2 ) } \\right)^2 \\right ]   { \\mathbb{e}}\\left [ \\left ( e_{i , n}^{(1 ) } - e_{i , n}^{(2 ) } \\right)^2 \\mathbf{1 } _ {   \\ { \\tau_{i-1,n}^s < t \\ } } \\right ]    \\right)^{1/2}.   \\end{aligned}\\ ] ]    using cauchy - schwarz inequality together with burkholder - davis - gundy inequality and lemma [ esptauk ] , we obtain that : @xmath658 = o^u \\left ( \\alpha_n^4 \\right).\\ ] ] where @xmath545 stands for `` uniformly in @xmath659 '' .",
    "another application of cauchy - schwarz inequality gives us @xmath660\\ ] ] @xmath661 { \\mathbb{e}}\\left [ \\left (   \\delta x_{\\tau_{i , n}^{1c,-,+}}^{(2 ) } \\right)^4 \\right ] \\right)^{1/2}.\\ ] ] using once again cauchy - schwarz inequality together with burholder - davis - gundy inequality and lemma [ esptauk ] , we obtain that : @xmath662 = o^u \\left ( \\alpha_n^4 \\right).\\ ] ] similarly , we compute using conditional burkholder - davis - gundy in first inequality , cauchy - schwarz in third inequality , lemma [ snk ] , lemma [ s ] and lemma [ esptauk ] together with the continuity of @xmath198 ( a1 ) in last equality .    @xmath663\\ ] ] @xmath664 \\right]\\\\ & = & { \\mathbb{e}}\\left [ \\mathbf{1 } _ {   \\ { \\tau_{i-1,n}^s < t \\ } } { \\mathbb{e}}_{\\tau_{i-1,n}^{1c } } \\left [ \\left ( \\int_{\\tau_{i-1,n}^{1c}}^{\\tau_{i , n}^{1c } }   \\left ( \\left ( \\sigma_{s } - \\sigma_{\\tau_{i-1,n}^{s } } \\right ) dw_s \\right)^{(1 ) } \\right)^4 \\right ] \\right]\\\\ & \\leq & c \\sup_{1 \\leq j , l \\leq 4 } { \\mathbb{e}}\\left [ \\mathbf{1 } _",
    "{   \\ { \\tau_{i-1,n}^s < t \\ } } { \\mathbb{e}}_{\\tau_{i-1,n}^{1c } } \\left[\\left (   \\int_{\\tau_{i-1,n}^{1c}}^{\\tau_{i , n}^{1c } }   \\left(\\sigma_{s}^{j , l } - \\sigma_{\\tau_{i-1,n}^{s}}^{j , l } \\right)^2 ds \\right)^2 \\right ] \\right]\\\\ & = & c \\sup_{1 \\leq j , l \\leq 4 } { \\mathbb{e}}\\left [ \\mathbf{1 } _ {   \\ { \\tau_{i-1,n}^s < t \\ } } \\left ( \\int_{\\tau_{i-1,n}^{1c}}^{\\tau_{i , n}^{1c } }   \\left(\\sigma_{s}^{j , l } - \\sigma_{\\tau_{i-1,n}^{s}}^{j , l } \\right)^2 ds \\right)^2 \\right]\\end{aligned}\\ ] ] @xmath665 + o^u \\left(\\alpha_n^4 \\right ) \\\\ & \\leq & c \\left ( { \\mathbb{e}}\\left [ \\left ( \\delta \\tau_{i , n}^{1c } \\right)^4 \\right ] { \\mathbb{e}}\\left [ \\sup_{1 \\leq j , l \\leq 4 } \\left ( s \\left ( \\sigma^{j , l } , s_n^{h }   \\right ) \\right)^8 \\right ] \\right)^{1/2 } + o^u \\left(\\alpha_n^4 \\right)\\\\ & = & o^u \\left(\\alpha_n^4 \\right).\\end{aligned}\\ ] ] with the same kind of computations , we show that @xmath666 \\rightarrow 0 $ ] , and we also can show @xmath667 \\rightarrow 0 $ ] , @xmath668 \\rightarrow 0 $ ] ( thus we have also that @xmath669 \\rightarrow 0 $ ] ) and @xmath670 \\rightarrow 0.\\ ] ]    second step : approximating using @xmath671 instead of @xmath672 .",
    "we set @xmath673 we want to show that @xmath674\\ ] ] @xmath675 + o_p \\left ( 1 \\right).\\ ] ] using the same kind of computations as in the first step together with lemma [ tauapp ] , we conclude .",
    "third step : express the result as a function of @xmath322 . using lemma [ scale ] in last equality",
    ", we deduce for any integer @xmath676 such that @xmath677 that @xmath678\\\\ & = & \\int_{{\\mathbb{r}}^2 } \\psi^{av } \\left(\\sigma_{\\tau_{i-1,n}^h } , \\alpha_n g_{\\tau_{i-1,n}^h } ,   x , v \\right ) d \\tilde{\\pi}_{i , u-2,n } \\left ( x , v \\right ) \\\\ & = & \\alpha_n^4 \\int_{{\\mathbb{r}}^2 } \\psi^{av } \\left(\\sigma_{\\tau_{i-1,n}^h } , g_{\\tau_{i-1,n}^h } , \\alpha_n^{-1 } x , \\alpha_n^{-2 } v \\right )   d \\tilde{\\pi}_{i , u-2,n } \\left ( x , v \\right).\\end{aligned}\\ ] ]      we define the transition functions of the markov chains @xmath682 defined in ( [ zi ] ) . for @xmath683 , @xmath684 ( borelians of @xmath685 ) @xmath686 first step : we prove that @xmath687 , @xmath188 , the state space @xmath685 is @xmath688-small , i.e. there exists a non - trivial measure @xmath688 on @xmath689 such that @xmath690 , @xmath691 .",
    "let @xmath692 \\times [ u_a , u_b]$ ] .",
    "we are choosing @xmath688 such that @xmath693 outside @xmath694 \\times [ 3 , 4]$ ] .",
    "thus , without loss of generality , we have that @xmath695 \\times [ u_a , u_b ] \\subset [ - \\frac{g^-}{4 } , \\frac{g^-}{4 } ] \\times [ 3 , 4]$ ] .",
    "we want to show that @xmath696 such that uniformly @xmath697    there are two useful ways to rewrite @xmath698 .",
    "the first one is : @xmath699 where @xmath700 and @xmath701 are independent , @xmath702 $ ] and @xmath703 ( because @xmath704 ) , @xmath705 the other way to rewrite it is : @xmath706    where @xmath707 and @xmath708 are independent . for @xmath709 a standard brownian motion , @xmath710 , we denote the exiting - zone time of the brownian motion @xmath711 and @xmath712 the density of @xmath713 .",
    "we also define @xmath714 the distribution of @xmath715 conditioned on @xmath716 .",
    "finally , let @xmath717 the distribution of @xmath713 conditioned on @xmath718 .",
    "all the formulas can be found in borodin and salminen ( 2002 ) .",
    "consider the spaces @xmath719 , @xmath720 .",
    "the functions @xmath721 are continuous on @xmath722 and positive .",
    "thus , for all compact set @xmath723 , we have @xmath724 we can bound below @xmath725 where @xmath726}^{3 , \\perp } \\big| < \\frac{g^- \\sigma^- }   { 4 \\left(\\sigma^+ \\right)^2 } \\big\\},\\\\   e_2 & = & \\big\\ { \\underset{k+1 \\leq s \\leq \\tilde{\\tau}_2^{(2)}}{\\sup } \\big| \\tilde{x}_s^{(3 ) } \\big| \\leq \\frac{\\epsilon}{5 } \\text { , }    \\tilde{\\tau}_2^{(2 ) } \\in [ k+2 , k+3 ] \\big\\ } , \\\\",
    "e_3 & = & \\big\\ { \\forall s \\in [ \\tilde{\\tau}_2^{(2 ) } , k+4 ] \\text { } \\tilde{x}_{s}^{(3 ) } \\in [ d_1 ( k ) , u_1 ( k ) ] \\text { , }    \\tilde{x}_{k+4}^{(3 ) } \\in [ u_1 ( k ) - 2 \\epsilon , u_1 ( k ) - \\epsilon ] \\big\\ } \\\\   & & \\bigcap \\big\\ { \\underset{\\tilde{\\tau}_2^{(2 ) } \\leq s \\leq k+4}{\\sup } \\big| \\delta \\tilde{x}_{[\\tilde{\\tau}_2^{(2)},s]}^{(4 ) } \\big| < \\frac{g^-}{12 } \\big\\ } , \\\\",
    "e_4 & = & \\big\\ { \\tilde{\\tau}_1^{(1 ) } \\in [ u_a + \\tilde{\\tau}_2^{(2 ) } , u_b + \\tilde{\\tau}_2^{(2 ) } ] \\text { , } \\underset{k+4 \\leq s \\leq \\tilde{\\tau}_1^{(1)}}{\\inf } \\delta \\tilde{x}_{[k+4,s]}^{(3 ) } >    - 2 \\epsilon   \\big\\ } \\\\   & & \\bigcap \\big\\ {   \\underset{k+4 \\leq s \\leq \\tilde{\\tau}_1^{(1)}}{\\sup } \\big|    \\delta \\tilde{x}_{[\\tilde{\\tau}_2^{(2)},s]}^{(4 ) } \\big| < g^- \\text { , } \\delta \\tilde{x}_{[\\tilde{\\tau}_2^{(2)},\\tilde{\\tau}_1^{(1)}]}^{(4 ) } \\in [ x_a , x_b ] \\big\\ } ,   \\end{aligned}\\ ] ] where @xmath727",
    ". using extensively bayes formula , we can rewrite @xmath728 where @xmath729 , @xmath730 , and also @xmath731 , @xmath732 and @xmath733 .",
    "we prove that @xmath734 is uniformly bounded away from @xmath44 . using ( [ m ] ) , ( [ w11 ] ) , ( [ w12 ] ) and ( [ delta ] )",
    ", we deduce that @xmath735 where @xmath736 conditionally on @xmath737 , @xmath738 and @xmath739 are independent .",
    "thus , we deduce @xmath740 using markov property of brownian motions , we obtain that the right part of the inequality is equal to @xmath741 where @xmath742 , @xmath743 , which is uniformly ( in @xmath744 , @xmath198 and @xmath189 ) bounded away from 0 using ( [ m ] ) and ( [ compact ] ) .",
    "we prove that @xmath745 is uniformly bounded away from @xmath44 .",
    "conditionally on @xmath746 , the two quantities of @xmath747 are independent .",
    "thus , we bound below @xmath745 ( the same way we did for @xmath734 ) by @xmath748 @xmath749 which is uniformly bounded away from 0 using ( [ m ] ) together with ( [ compact ] ) .",
    "we prove that @xmath750 is uniformly bounded away from @xmath44 . using ( [ m ] ) , ( [ w11 ] ) , ( [ w12 ] ) and ( [ delta ] )",
    ", we deduce that @xmath751 where @xmath752}^{3 , \\perp } \\big| < \\frac{g^-}{2 \\sigma^{+ } }    \\text { , } \\underset{k+2",
    "\\leq s \\leq k+3}{\\sup } \\big| \\delta \\tilde{b}_{[\\tilde{\\tau}_1^{(2 ) } , s]}^{3 , \\perp } \\big| \\geq \\frac{g^+}{\\delta \\sigma^{- } } +    \\frac{\\epsilon}{5 \\sigma^+ \\delta } \\big\\}.   \\end{aligned}\\ ] ] conditionally on @xmath753 , @xmath754 and @xmath755 are independent .",
    "thus , we deduce @xmath756 using markov property of brownian motions , we obtain that the right part of the inequality conditioned on @xmath757}^{3,\\perp } \\big|   e_1 \\bigcap e_0 \\bigcap \\ { \\tilde{z}_0 = ( x , u ) \\ } \\}$ ] is equal to @xmath758}^{3,\\perp } , - \\frac{g^+}{2 \\sigma^+ } , \\frac{g^+}{2 \\sigma^+ } , t \\right ) dt \\right)\\ ] ] @xmath759 where @xmath760 is the ( conditional ) distribution of @xmath761}^{3,\\perp } + b_1 $ ] conditioned on @xmath762}^{3,\\perp}}^{-\\frac{g^-}{2 \\sigma^+ } , \\frac{g^-}{2 \\sigma^+ } } \\geq 1 \\bigg\\}.\\ ] ] using the definition of @xmath747 together with ( [ m ] ) and ( [ compact ] ) , we have @xmath750 which is uniformly bounded away from 0 .    we prove that @xmath763 is uniformly bounded away from @xmath44 . using ( [ w21 ] ) and ( [ w22 ] ) , we deduce that @xmath764 where @xmath765}^{(4 ) } \\big| <     \\frac{\\epsilon \\sigma^-}{5 \\sigma^{+ } \\sigma^{(4 ) } } \\big\\ } , \\\\",
    "e_3^{(2 ) } & = & \\big\\ { \\forall s \\in [ \\tilde{\\tau}_2^{(2 ) } , k+4 ] \\text { } \\delta \\tilde{b}_{[\\tilde{\\tau}_2^{(2 ) } , s]}^{4 , \\perp } \\in    [ y_3^{(1 ) } , y_3^{(2 ) } ] \\text { , }    \\delta \\tilde{b}_{[\\tilde{\\tau}_2^{(2 ) } , k+4]}^{4 , \\perp } \\in [ y_3^{(3 ) } , y_3^{(4 ) } ] \\big\\ } ,   \\end{aligned}\\ ] ] with @xmath766 , @xmath767 , @xmath768 , as well as @xmath769 . conditionally on @xmath770 , @xmath771 and @xmath772 are independent .",
    "thus , we deduce @xmath773 @xmath774 using markov property of brownian motions , we obtain that the right part of the inequality conditioned on @xmath775 is equal to @xmath776 @xmath777 which is uniformly bounded away from 0 using ( [ m ] ) , ( [ delta ] ) and ( [ compact ] ) .",
    "we prove that @xmath778 . using ( [ w11 ] ) and ( [ w12 ] )",
    ", we deduce that @xmath779 where @xmath780 \\text { , } \\tilde{x}_{\\tilde{\\tau}}^{(3 ) } = u_1 ( k ) \\big\\ } , \\\\",
    "e_4^{(2 ) } & = & \\big\\ { \\underset{k+4 \\leq s \\leq \\tilde{\\tau}}{\\sup } \\big| \\delta \\tilde{b}_{[k+4,s]}^{3 , \\perp } \\big| < \\frac{5 g^- }   { 6 \\sigma^{(4 ) } \\left ( 1 - \\left ( \\rho^{3,4 } \\right)^2 \\right)^{1/2 } } \\text { , } \\delta \\tilde{b}_{[l+4,\\tilde{\\tau}]}^{3 , \\perp }    \\in [ y_4^{(1 ) } , y_4^{(2 ) } ] \\big\\ } ,   \\end{aligned}\\ ] ] @xmath781}^{(3 ) } = - 2 \\epsilon \\}$ ] , @xmath782}^{(4 ) } - \\rho^{3,4 } \\sigma^{(4 ) } \\left ( \\sigma^{(3 ) } \\right)^{-1 }   \\left ( u_1 ( k ) - \\tilde{x}_{k+4}^{(3 ) } \\right ) } { \\sigma^{(4 ) } \\left ( 1 - \\left ( \\rho^{3,4 } \\right)^2 \\right)^{1/2}},\\ ] ] and @xmath783}^{(4 ) } - \\rho^{3,4 } \\sigma^{(4 ) } \\left ( \\sigma^{(3 ) } \\right)^{-1 }   \\left ( u_1 ( k ) - \\tilde{x}_{k+4}^{(3 ) } \\right ) } { \\sigma^{(4 ) } \\left ( 1 - \\left ( \\rho^{3,4 } \\right)^2 \\right)^{1/2}}$ ] .",
    "we have @xmath784 @xmath785 the first term on the right part of the equation is uniformly bounded away from 0 ( borodin and salminen ( 2002 ) ) . because @xmath786 is a function of @xmath787 and @xmath701 is independent with @xmath787 , @xmath786 and @xmath788 are independent .",
    "thus the second term on the right conditioned on @xmath789 can be expressed as : @xmath790 where @xmath791 .",
    "we have that @xmath792 and @xmath793 are dominated by @xmath794 . using this together with ( [ m ] ) , ( [ delta ] ) and ( [ compact ] )",
    ", we deduce that @xmath795 .",
    "second step : we prove that @xmath796 . to show this , we bound the term as @xmath797   \\leq 2 { \\mathbb{e}}\\left [ \\left ( \\delta \\tilde{x}_{\\tilde{\\tau}_2^{1c}}^{(1 ) }   \\delta \\tilde{x}_{\\tilde{\\tau}_2^{1c,-,+}}^{(2 ) } \\right)^2 + \\left ( \\tilde{\\zeta}^{1,2 } \\delta \\tilde{\\tau}_2^{1c } \\right)^2 \\right].\\ ] ] the second term in the right hand - side of the inequality is uniformly bounded using ( [ m ] ) and lemma [ esptauk ] . using successively cauchy - schwarz and burholder - davis - gundy inequality , ( [ m ] ) and lemma [ esptauk ] , we can also bound uniformly the first term . the other term of ( [ psiav1 ] ) can be bounded in the same way .",
    "third step : define @xmath798 and @xmath799 prove that @xmath800 , there exists a measure @xmath801 such that @xmath802 @xmath803 to show this , we use first step together with @xmath804 @xmath805 ( meyn and tweedie ( 2009 ) ) .",
    "we obtain that there exists @xmath801 where @xmath806 and @xmath807 .",
    "thus , we deduce : @xmath808 @xmath809 we want to show that @xmath810 , @xmath469 such that @xmath470 : @xmath811 @xmath812    the rest is a straightforward analysis exercise .",
    "let @xmath468 .",
    "@xmath813 such that @xmath814 .",
    "choosing @xmath815 , we first use the triangular inequality , and then split the sum of the left part of ( [ mark2 ] ) in two parts , one up to @xmath816 and the other one up to n. we use ( [ mark1 ] ) in the second part to obtain ( [ mark2 ] ) .",
    "fourth step : proving the lemma .",
    "let @xmath817 . from lemma [ sumtight ] , we just have to show that @xmath818 @xmath819 tends to 0 in probability . using third step together with standard results on regular conditional distributions",
    "( see for instance section @xmath199 ( pp .",
    "@xmath820 ) in breiman ( 1992 ) ) , we prove the lemma .",
    "first step : defining @xmath823 \\right)^{-1 } \\right ] , \\\\",
    "a_1 & : = & \\alpha_n^2 \\sum_{i \\in a_n } { \\mathbb{e}}_{\\tau_{i-1,n}^h } \\left [ h_n \\phi^{av } \\left(\\sigma_{\\tau_{i-1,n}^h } , g_{\\tau_{i-1,n}^h } \\right )   \\delta \\tau_{i , n}^h \\left ( u_{i , n } \\right)^{-1 } \\right ] .",
    "\\end{array }     \\right .\\ ] ] we have that @xmath824 . to show this , in light of lemma [ tauapp ]",
    ", we have that @xmath825 - u_{i , n } \\bigg| \\leq h \\left ( n \\right ) c_n,\\ ] ] where @xmath826 tends to 0 in probability . from this",
    ", we can easily show that @xmath824 .",
    "[ [ computation - of - the - limits - of - langle - mn - rangle_t - langle - mn - x1-rangle_t - and - langle - mn - x2-rangle_t ] ] computation of the limits of @xmath828 , @xmath829 and @xmath830 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    @xmath831 + o_p ( 1 ) \\\\ &",
    "= & \\alpha_n^{-2 } \\sum_{i \\in a_n } { \\mathbb{e}}_{\\tau_{i-1,n}^h } \\left [ \\sum_{u=2}^{h_n } \\left ( n_{(i-1)h_n + u }",
    "\\right)^2 + 2 n_{(i-1)h_n + u }   n_{(i-1)h_n + u+1 } \\right ] + o_p ( 1 ) \\\\ & = & \\alpha_n^{2 } \\sum_{i \\in a_n } \\sum_{j=0}^{h_n - 2 } \\int_{{\\mathbb{r}}^2 } \\psi^{av } \\left ( \\sigma_{\\tau_{i-1,n}^h } , g_{\\tau_{i-1,n}^h } ,   \\alpha_n^{-1 } x , \\alpha_n^{-2 } u \\right ) d \\tilde{\\pi}_{i-1,j , n } \\left ( x , u \\right ) + o_p ( 1),\\end{aligned}\\ ] ]      we deduce ( using lemma [ approxdistrib ] in first equality and lemma [ approxtau ] in third equality ) @xmath832 \\right)^{-1 } \\right ] + o_p ( 1)\\\\ & = & \\sum_{i \\in a_n } { \\mathbb{e}}_{\\tau_{i-1,n}^h } \\left [   \\phi_{\\tau_{i-1,n}^h}^{av } \\delta \\tau_{i , n}^h \\left ( \\phi_{\\tau_{i , n}^h}^{\\tau } \\right)^{-1 } \\right ] + o_p ( 1).\\end{aligned}\\ ] ]            we follow the idea in 1-dimension in pp .",
    "155 - 156 of mykland and zhang ( 2012 ) , and define an auxiliary martingale @xmath837 where @xmath838 is defined in ( [ x1perp ] ) . using , we deduce @xmath839 hence , we choose @xmath840 by the same techniques that we used to compute , we have that @xmath841 using and we compute @xmath842 hence , we choose @xmath843 by @xmath844 , there exists @xmath845 such that the @xmath846 brownian motions @xmath847 generate the filtration @xmath848 . to show that @xmath849 tends to 0 in probability",
    ", we decompose @xmath850 where @xmath851 belongs to the space spanned by @xmath852 , @xmath853 is orthogonal to this space . by what precedes",
    ", we have clearly @xmath854 tends to 0 in probability .",
    "also , @xmath853 is a martingale that is , conditionally on the observations times of both processes , independent of @xmath855 .",
    "thus we also deduce that @xmath856 converges to 0 in probability .",
    "we can now compute @xmath857 by letting @xmath858 we deduce using theorem 2.28 in mykland and zhang ( 2012 ) that stably in law as @xmath859 , @xmath860 we have just shown theorem [ main1 ] .",
    "now , we express the asymptotic bias @xmath861 differently as @xmath862 we thus deduce the expression of @xmath282 and @xmath283 .",
    "the proof of corollary [ estcor ] follows in the same way as the proof of theorem [ main1 ] .",
    "we hold constant the asymptotic variance and the asymptotic bias on blocks of size @xmath306 .",
    "moreover , we can see that @xmath304 , @xmath305 and @xmath303 are uniformly consistent estimators under the constant model .",
    "we discuss in this section how to adapt the proofs of theorem [ main1 ] when considering example [ hittingbarriernoisejump ] up to example [ autoregressive ] . in that case",
    ", the hbt can be defined for each @xmath51 as @xmath7 and recursively as @xmath863}^{(t , k ) } \\notin \\big [ \\alpha_n d_{t , n}^{(k ) } \\big ( t - \\tau_{i-1,n}^{(k ) } \\big ) , \\alpha_n u_{t , n}^{(k ) } \\big(t - \\tau_{i-1,n}^{(k ) } \\big )   \\big ] \\big\\}\\end{aligned}\\ ] ] for any positive integer @xmath12 . in ( [ generateobstimesdiscussion ] ) ,",
    "the grid @xmath864 depends on @xmath191 , thus the term @xmath217 in the asymptotic variance obtained in theorem [ main1 ] will have a different interpretation .",
    "indeed , @xmath217 will be seen as a ( possibly multidimensional ) continuous time - varying parameter which generates ( [ generateobstimesdiscussion ] ) instead of the scaled grid function itself . in particular , the approximations will not be carried with holding @xmath865 constant on each block , but rather with holding @xmath225 constant on each block .",
    "also , for any fixed @xmath167 $ ] , @xmath217 will not be a function on @xmath43 , but a simple vector .",
    "the reader can refer to potiron ( 2016 ) for the notion of time - varying parameter .",
    "note that assumption ( a@xmath151 ) is only used in lemma [ tauapp ] and lemma [ approxdistrib ] .",
    "thus , lemma [ tauapp ] and lemma [ approxdistrib ] are the only parts in the proof which need to be adapted .",
    "[ [ example - hittingbarriernoisejump - hitting - constant - boundaries - of - the - jump - size ] ] example [ hittingbarriernoisejump ] ( hitting constant boundaries of the jump size ) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    for each asset @xmath866 we define the jump sizes as @xmath867 .",
    "we assume that @xmath868 and @xmath869 are independent of each other .",
    "we have that @xmath870 for @xmath871 $ ] .",
    "we also have a non - time varying parameter @xmath872 .",
    "as the jump size @xmath867 are iid and independent of the other quantities , we can consider the same @xmath867 when making local approximations .",
    "note that in lemma [ tauapp ] , the proof is made recursively for each observation time of the block .",
    "thus a `` jump '' of @xmath865 is not a problem when it happens exactly at observation times , as long as the same jump is also made in the approximation block . since @xmath867 is assumed to be bounded , it is straightforward to adapt the proof of lemma [ tauapp ] .",
    "we discuss now how to adapt the proof of lemma [ approxdistrib ] . to do that",
    ", we consider the markov chain @xmath873}^{(2 ) } ,   \\tilde{\\tau}_{i}^{1c } - \\tilde{\\tau}_{i}^{1c,-}$ ] , @xmath874 , @xmath875 , where @xmath876 is such that @xmath877 , @xmath878 is such that @xmath879 , @xmath880 and @xmath881 are iid sequences independent of each other which follows respectively the distribution of @xmath882 and @xmath883",
    ". then , everything follows the same way as in the proof of lemma [ approxdistrib ] .",
    "this model is very similar to example [ hittingbarriernoisejump ] , except that the sequence @xmath867 is obtained as a function of @xmath884 , where @xmath885 corresponds to the continuous time - varying parameter @xmath886 of the @xmath14th asset introduced in p. 5 of robert and rosenbaum ( 2012 ) .",
    "we thus consider @xmath887 .",
    "the proof of lemma [ tauapp ] can be extended using the convenient construction of @xmath867 provided in p. 11 of robert and rosenbaum ( 2012 ) .",
    "we extend this construction in two - dimension assuming that @xmath888 and @xmath889 are independent .",
    "as example [ uncertaintyzones ] is slightly more involved than example [ hittingbarriernoisejump ] , the markov chain @xmath266 needs to include also the type of previous price change ( increment or decrement ) for each asset .",
    "we thus consider @xmath873}^{(2 ) } ,   \\tilde{\\tau}_{i}^{1c } - \\tilde{\\tau}_{i}^{1c,-}$ ] , @xmath874 , @xmath890 , and can follow the same line of reasoning as in lemma [ approxdistrib ] .",
    "[ [ example - irregulargrid - times - generated - by - hitting - an - irregular - grid - model ] ] example [ irregulargrid ] ( times generated by hitting an irregular grid model ) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    in this case , the parameter @xmath891 is non time - varying .",
    "lemma [ tauapp ] can be adapted easily . to show lemma [ approxdistrib ] ,",
    "a further condition is needed on @xmath892 .",
    "we assume that there exists a positive number @xmath893 such that for any non - negative number @xmath505 and any @xmath894 we have @xmath895 .",
    "we also define the markov chain @xmath873}^{(2 ) } ,   \\tilde{\\tau}_{i}^{1c } - \\tilde{\\tau}_{i}^{1c,- } , l^{(1 ) } , l^{(2 ) } \\big)$ ] , where @xmath896 is the index such that there exists a non - negative number @xmath897 with @xmath898 , and @xmath899 is the index such that there exists a non - negative number @xmath897 with @xmath900 . under this assumption",
    ", we can show lemma [ approxdistrib ] .",
    "[ [ example - autoregressive - structural - autoregressive - conditional - duration - model ] ] example [ autoregressive ] ( structural autoregressive conditional duration model ) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    we assume that the mixing variables @xmath901 and @xmath902 are interpolated by time - varying continuous stochastic parameters @xmath903 .",
    "we have that @xmath904 . the central limit theorem in example [ autoregressive ]",
    "can be obtained as a straightforward corollary of theorem [ main1 ] .",
    "if we define for any @xmath91 the grid functions @xmath905 , the only difference between the hbt model ( [ generateobstimes ] ) and the structural acd model ( [ autoregressiveacd ] ) is that we hold the grid between two observations in the latter model . in view of this specific assumption which implicates that the quantities of approximation are closer to the approximated quantities than under the hbt model , the proof of lemma [ tauapp ] simplifies .",
    "the proof of lemma [ approxdistrib ] remains unchanged as it deals only with quantities of approximation .",
    "we update in this section the proof in the jump case model ( [ jumpmodel ] ) .",
    "the idea is to exclude all the blocks where we observe a jump .",
    "such blocks will be finitely counted , and we will have at most one jump ( either for @xmath906 or for @xmath907 but not for both prices at the same time ) in each block . this is the main difference with the one - dimensional case .",
    "we introduce the notation @xmath908 \\big\\}.\\ ] ] the proof of lemma [ snk ] can be adapted because of the finiteness of jumps .",
    "the proof of lemma [ s ] remains unchanged .",
    "lemma [ esptauk ] and lemma [ numb ] remains true in view of the finiteness of jumps .",
    "lemma [ sumtight ] and lemma [ scale ] do nt need any change .",
    "we modify lemma [ tauapp ] as follows .",
    "let @xmath465 , we have that @xmath909 = o_p \\left ( \\alpha_n^{2l } \\right )   \\end{aligned}\\ ] ] and @xmath910 = o_p \\left ( \\alpha_n^{2l } \\right )   \\end{aligned}\\ ] ] the proof remains unchanged in view of the independence assumption between jumps and the other quantities .",
    "lemma [ termsvanishing ] stays true with no further change .",
    "we introduce the new following lemma to be inserted between lemma [ termsvanishing ] and lemma [ holdingconst ] in the proofs .",
    "starting from lemma [ holdingconst ] up to the end of the proof of theorem [ main1 ] , in view of lemma [ lemmajumps ] , we can use `` @xmath914 '' in lieu of `` @xmath915 '' .",
    "we have thus proved that theorem [ main1 ] is robust to jumps .",
    "barndorff - nielsen , o.e .",
    "hansen , a. lunde and n. shephard ( 2011 ) multivariate realised kernels : consistent positive semi - definite estimators of the covariation of equity prices with noise and non - synchronous trading , _ journal of econometrics _ 162 , 149 - 169 .",
    "barndorff - nielsen , o.e . and n. shephard ( 2002 ) econometric analysis of realized volatility and its use in estimating stochastic volatility models .",
    "_ journal of the royal statistical society _ b 64 , 253 - 280 .",
    "christensen , k. , s. kinnebrock and m. podolskij ( 2010 ) pre - averaging estimators of the ex - post covariance matrix in noisy diffusion models with non - synchronous data , _ journal of econometrics _ 159 , 116 - 133 .",
    "christensen , k. , m. podolskij and m. vetter ( 2013 ) on covariation estimation for multivariate continuous it semimartingales with noise in non - synchronous observation schemes , _ journal of multivariate analysis _ , 120 , 59 - 84 .",
    "hayashi , t. , j. jacod and n. yoshida .",
    "irregular sampling and central limit theorems for power variations : the continuous case .",
    "_ annales de linstitut henri poincar probabilits et statistiques _ 47 , 1197 - 1218 .",
    "mykland , p.a .",
    "and l. zhang ( 2012 ) the econometrics of high frequency data . in m. kessler , a. lindner and m. srensen ( eds . ) ,",
    "_ statistical methods for stochastic differential equations _ , pp .",
    "109 - 190 .",
    "chapman nad hall / crc press .                           and with @xmath916 .",
    "the black stochastic process represents @xmath19 , the red line stands for @xmath917 and the blue line for @xmath918 .",
    "furthermore , we assume that @xmath919 . the second observation @xmath920 is obtained when @xmath19 crosses the red line for the first time . ]      .summary statistics based on simulated endogenous data of @xmath22 , @xmath200 and @xmath921 years .",
    "the rmse in the table corresponds to the square root of the squared distance between the estimated value and the true value @xmath922 .",
    "hy stands for the usual hayashi - yoshida estimator ( [ hy ] ) , and bchy represents the bias - corrected estimator ( [ biascorrected ] ) . [",
    "cols=\"^,^,^,^,^,^\",options=\"header \" , ]"
  ],
  "abstract_text": [
    "<S> when estimating high - frequency covariance ( quadratic covariation ) of two arbitrary assets observed asynchronously , simple assumptions , such as independence , are usually imposed on the relationship between the prices process and the observation times . in this paper , we introduce a general endogenous two - dimensional nonparametric model . because an observation is generated whenever an auxiliary process called _ observation time process </S>",
    "<S> _ hits one of the two boundary processes , it is called the _ hitting boundary process with time process _ ( hbt ) model . </S>",
    "<S> we establish a central limit theorem for the hayashi - yoshida ( hy ) estimator under hbt in the case where the price process and the observation price process follow a continuous it process . </S>",
    "<S> we obtain an asymptotic bias . </S>",
    "<S> we provide an estimator of the latter as well as a bias - corrected hy estimator of the high - frequency covariance . </S>",
    "<S> in addition , we give a consistent estimator of the associated standard error . + * keywords * : asymptotic bias ; asynchronous times ; endogenous model ; hayashi - yoshida estimator ; high - frequency data ; quadratic covariation ; time endogeneity + * jel codes * : c01 ; c02 ; c13 ; c14 ; c22 ; c32 ; c58    [ main1]corollary [ main1]corollary [ main1]definition [ main1]proposition [ main1]definition [ main1]lemma [ main1]lemma [ main1]lemma [ main1]definition [ main1]definition [ main1]definition [ main1]lemma [ main1]lemma [ main1]lemma [ main1]lemma [ main1]lemma [ main1]lemma [ main1]lemma [ main1]lemma [ main1]lemma [ main1]lemma [ main1]lemma [ main1]lemma    [ continuousass]remark [ continuousass]remark [ continuousass]remark [ continuousass]remark [ continuousass]remark [ continuousass]remark [ continuousass]remark [ continuousass]remark [ continuousass]remark [ continuousass]remark [ continuousass]remark [ continuousass]remark [ continuousass]remark [ continuousass]remark    [ hittingbarrier]example [ hittingbarrier]example [ hittingbarrier]example [ hittingbarrier]example [ hittingbarrier]example </S>"
  ]
}