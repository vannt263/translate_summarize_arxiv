{
  "article_text": [
    "the subject of time series clustering is an active research area with applications in many fields . finding similarity between time series frequently plays a central role in many applications .",
    "in fact , time series clustering problems arise in a natural way in a wide variety of fields , including economics , finance , medicine , ecology , environmental studies , engineering , and many others .",
    "a recent work , developed by @xcite , uses a clustering model to develop a discriminant analysis of stochastic cepstra .",
    "time series clustering is , in general , not an easy task due to the potential complexity of the data and the difficulty of defining an adequate notion of similarity between time series .    in @xcite , and subsequently in @xcite ,",
    "there are three approaches to time series clustering : methods based on the comparison of raw data , methods based on parameters from models adjusted to the data , and feature - based methods where the similarity between time series is measured through features extracted from the data .",
    "the first clustering approach compares of raw data and may not be computationally scalable for long time series .",
    "the second approach , based on parameters , is one of the most frequently used .",
    "however , it has the limitation of requiring a parametric model and this might suffer from model misspecification .",
    "@xcite present an r package ( tsclust ) for time series clustering with a wide variety of alternative procedures .    here , we consider the problem of clustering stationary time series and our proposal is based on using the spectral density as the central feature for classification purposes . to build a clustering method one needs to measure the similarity between the spectral densities .",
    "our method uses the total variation ( tv ) distance as a measure of dissimilarity , which was proposed in @xcite .",
    "this distance requires the use of normalized spectral densities , which is equivalent to standardizing the time series so that their variances are equal to one .",
    "thus , it is the distribution of the power across different frequencies of the time series that is considered the fundamental feature for clustering purposes rather than the magnitude of the oscillations .    in @xcite ,",
    "the tv distance was used to build a dissimilarity matrix consisting of the distances between all the spectral densities , which was then fed into a classical hierarchical agglomerative algorithm with the complete and average linkage functions .",
    "the method introduced in this work which we call the hierarchical spectral merger ( hsm ) method , is a new clustering algorithm that takes advantage of the spectral theory of time series .",
    "the key difference with classical hierarchical agglomerative clustering is that every time a cluster is updated , a new representative ( new estimated spectral density ) is computed .",
    "each time two clusters are joined in the hsm procedure , the information available in all the series belonging to both clusters is merged to produce a new estimate of the common spectral density for the new cluster .",
    "the proposed approach is appealing because it is intuitive and the updated spectral estimates are smoother , less noisy and hence give better estimates of the tv distance .",
    "thus , every time two clusters merge , the dissimilarity matrix reduces its size in one unit . in contrast , for the classical hierarchical agglomerative algorithm the dissimilarity matrix is the same throughout the procedure , and the distances between clusters at each step are calculated using linear combinations of the individual distances ; the linear combination used depends on the linkage function that is chosen ( single , complete , average , ward , etc . ) .",
    "these methods are based on geometrical ideas which , in some cases , may not be meaningful for clustering time series , since a linear combination of the individual distances may not have a clear meaning in terms of the spectral densities .",
    "we will present two applications of the hsm method : one to data coming from wave - height measurements in oceanography and the other to electroencephalogram ( eeg ) data .",
    "some of the numerical experiments described in section 3 are related to these applications .",
    "the rest of the paper is organized as follows : section [ sec2 ] describes the hierarchical spectral merger procedure .",
    "section 3 presents some numerical experiments which compare the hsm method with some of the existing algorithms and considers the problem of deciding how many clusters there are in a given sample .",
    "finally , section 4 gives some examples of the use of the hsm algorithm .",
    "the paper ends with some discussion of the results and some ideas about future work .",
    "our goal is to develop a method that finds groups or clusters that represent spectrally synchronized time series .",
    "the algorithm we introduce , known as the hierarchical spectral merger ( hsm ) method , uses the tv distance as a dissimilarity measure and proposes a new clustering procedure .",
    "this algorithm is a modification of the usual agglomerative hierarchical procedure , taking advantage of the spectral point of view for the analysis of time series .",
    "the first question when building a clustering algorithm is how to measure the dissimilarity between the objects one is considering . in our case , this amounts to measuring the dissimilarity between the spectral densities estimated from the original time series , for which we use the tv distance between the normalized spectra . in what follows ,",
    "section [ sec2 - 1 ] presents the tv distance while section [ sec2 - 2 ] describes in detail the hsm method .      in general",
    ", the tv distance can be defined for any pair of probability measures that live on the same @xmath0-algebra of sets .",
    "we will be focus here in the case where these probability measures are defined on the real line and have density functions with respect to the lebesgue measure .",
    "the tv distance between two probability densities , @xmath1 and @xmath2 , is defined as @xmath3    equation ( [ tvd_1 ] ) suggests a graphical interpretation of the tv distance . if @xmath1 and @xmath2 are probability density functions and @xmath4 then @xmath5 and this means that the common area below the two densities is equal to @xmath6 , which corresponds to the shaded area in figure [ fig1 ] . when the area shared by the two densities increases then the tv distance decreases .    .",
    "]    since spectral densities are not probability densities , they have to be normalized by dividing the estimated spectral density by the sample variance @xmath7 , since @xmath8 .",
    "thus , we denote @xmath9 to be the normalized estimated spectral density .",
    "in comparison with other similarity measures , the tv distance has some desirable properties .",
    "( 1 ) the tv distance is a pseudo metric .",
    "it satisfies the symmetry condition and the triangle inequality , which are two reasonable properties expected from a similarity measure . in this sense",
    ", the tv distance may be a better choice than the kullback - leibler ( kl ) divergence ( although one can symmetrize the kl divergence ) .",
    "( 2 ) the tv distance is bounded , @xmath10 and can be interpreted in terms of the common area between two densities .",
    "having a bounded range ( @xmath11 $ ] ) is a desirable feature , since this gives a very intuitive sense to the values attained by the similarity measure .",
    "a value near @xmath12 means that the densities are similar while a value near @xmath13 indicates they are highly dissimilar . in contrast , both the @xmath14 distance and the kullback - leibler divergence are not bounded above and thus lack this intuitive interpretation .",
    "there are two general families of clustering algorithms : partitioning and hierarchical . among partitioning algorithms , the k - means and k - medoids are",
    "the most commonly used .",
    "@xcite proposed a k - means fuzzy clustering method based on wavelets coefficients and made a comparison with other k - means algorithms .",
    "for the hierarchical clustering algorithms , the typical examples are agglomerative with single - linkage or complete - linkage [ @xcite ] .",
    "storage and computational properties of the hierarchical clustering methods are reviewed in @xcite .",
    "the hierarchical spectral merger algorithm has two versions : the first , known as _ single version _ , updates the spectral estimate of the cluster from a concatenation of the time series , and the second , known as _",
    "average version _ , updates the spectral estimate of the cluster from a weighted average of the spectral estimate obtained from each signal in the cluster .",
    "* _ hierarchical spectral merger algorithm . _ * let @xmath15 be a set of time series .",
    "the procedure starts with @xmath16 clusters , each cluster being a single time series . + * step 1 .",
    "* suppose there are k clusters .",
    "for each cluster , estimate the spectral density ( using some smoothing or averaging method ) and represent each cluster by a common normalized spectral density @xmath17 , @xmath18 . + * step 2 .",
    "* compute the tv distance between these @xmath19 spectral densities . + * step 3 . *",
    "find the two clusters that have smallest tv distance . + * step 4 .",
    "* merge the time series in the two clusters with the smallest tv distance and replace the two clusters with the newly combined single cluster .",
    "+ * step 5 .",
    "* repeat steps 1 - 4 until there is only one cluster left .    in step 1 , at the first iteration the spectral density for each time series is initially estimated using the smoothed periodogram . in our case",
    "we used a lag window estimator with a parzen window .",
    "in further iterations , however , the way the common spectral density is obtained depends on the version of the algorithm .",
    "when two clusters merge , there are two options , either ( 1 ) for the single version , we concatenate the signals in both clusters and compute the smoothed periodogram with the concatenated signal ; or ( 2 ) for the average version , we take the weighted average over all the estimated spectra for each signal in the new cluster as the new estimated spectra .",
    "l * algorithm : * +   +    1 .",
    "initial clusters : @xmath20 , @xmath21 , @xmath22 .",
    "+ dissimilarity matrix entry between clusters @xmath23 and @xmath24 , + @xmath25 tv distance between the corresponding estimated normalized spectral densities @xmath26 using the signals in each cluster .",
    "2 .   * for * @xmath19 @xmath27 @xmath28 3 .",
    "@xmath29 @xmath30find the closest clusters 4 .",
    "@xmath31 + @xmath30join the closest clusters 5 .",
    "@xmath32 @xmath30delete rows and columns @xmath33 6 .   * for * @xmath24 @xmath27 @xmath34 7 .",
    "@xmath35 @xmath30compute new distances 8 .",
    "* end * 9 .",
    "@xmath36 @xmath30new matrix @xmath37 and new clusters 10 .",
    "* end *     +   +    _ * remarks . * _ ( 1 ) the value in step 3 represents the `` cost '' of joining two clusters , i.e. , having @xmath38 clusters versus @xmath19 clusters .",
    "if a significantly large value is observed , then it may be reasonable to choose @xmath19 clusters instead of @xmath38 .",
    "( 2 ) both versions of the algorithm compute the tv distance between the new and the old clusters based on updated estimated spectral densities , which is the main difference with classical hierarchical algorithms . while a hierarchical algorithm has a dissimilarity matrix of size @xmath39 during the whole procedure ,",
    "the proposed method reduces this size to @xmath40 at the @xmath19-th iteration .",
    "table [ algo ] gives a summary of the hierarchical merger algorithm .",
    "_ * illustration . * _ consider two different ar(2 ) models with their spectra concentrated at 10 hertz , however , one also contains power at 21 hertz while the other has power at 40 hertz .",
    "we simulated three time series for each process , 10 seconds of each one with a sampling frequency of @xmath41 hertz ( @xmath42 ) .",
    "figure [ f36a ] shows the estimated spectra for each series and figure [ f36b ] shows by different colors ( red and black ) which one belongs to the first or second process .",
    "if we only look at the spectra , it is hard to recognize the number of clusters and their memberships .",
    "the method might have difficulty in clustering some cases , like the red and purple spectra .",
    "the step - by - step result of the hsm method is shown in figure [ f37 ] .",
    "we start with six clusters ; at the first iteration we find the closest spectra , represented in figure [ f37c ] with the same color ( red ) .",
    "after the first iteration we merge these time series and get @xmath43 estimated spectra , one per cluster , figure [ f37d ] shows the estimated spectra where the new cluster is represented by the dashed red curve .",
    "we can follow the procedure in figures [ f37e ] , , and . in the end",
    ", the proposed clustering algorithm reaches the correct solution , figures [ f37i ] and [ f36b ] coincide .",
    "also , the estimated spectra for the two clusters , figure [ f37j ] , is better than any of the initial spectra and we can identify the dominant frequency bands for each cluster .",
    "we now investigate the finite sample performance of the hsm clustering algorithm .",
    "first , we explain the simulation methods based on the spectrum that we will use in some of the experiments .",
    "then , we present the results of the experiments , assuming that the number of clusters is known . finally , we explore the case of unknown number of clusters and possible criteria to choose it .",
    "_ simulation based on a parametric family of spectral densities .",
    "_        there exist several parametric families of spectral densities of frequent use in oceanography , which have an interpretation in terms of the behavior of sea waves ( @xcite ) .",
    "motivated by the applications , we will simulate time series ( gaussian process ) using spectra from one of these families . this methodology",
    "is already implemented by @xcite in the wafo toolbox for matlab .",
    "an example of a group of parametric densities is the jonswap ( joint north - sea wave project ) spectral family , which is given by the formula @xmath44 where @xmath2 is the acceleration of gravity , @xmath45 if @xmath46 and @xmath47 otherwise ; @xmath48 and @xmath49 .",
    "the parameters for the model are the significant wave height @xmath50 , which is defined as 4 times the standard deviation of the time series , and the spectral peak period @xmath51 , which is the period corresponding to the modal frequency of the spectrum .",
    "figure [ jonsspec ] shows some examples of this family with different values for the parameters @xmath51 and @xmath50 .",
    "+ _ simulation based on ar(2 ) processes . _",
    "consider the second order auto - regressive ar(2 ) model which is defined as @xmath52 where @xmath53 is a white noise process .",
    "the characteristic polynomial for this model is @xmath54 .",
    "the roots of the polynomial equation ( assumed with magnitude bigger than @xmath13 for causality ) indicate the properties of the oscillations .",
    "if the roots , denoted @xmath55 and @xmath56 are complex - valued then they must be complex - conjugates , i.e. , @xmath57 .",
    "these roots have a polar representation @xmath58 where @xmath59 denotes the sampling frequency ( in hertz ) ; @xmath60 is the amplitude or magnitude of the root ( @xmath61 for causality ) ; and @xmath62 is the frequency index ( @xmath63 ) .",
    "the spectrum of the ar@xmath64 process with polynomial roots as above will have peak frequency at @xmath62 .",
    "the peak becomes broader as @xmath65 , and it becomes narrower as @xmath66 .    .",
    "bottom : realizations from the corresponding ar(2 ) process . ]",
    "then , given @xmath67 , we take @xmath68 where @xmath69 .",
    "if one computes the roots of the characteristic polynomial with the coefficients in , they satisfy .    to illustrate the type of oscillatory patterns that can be observed in time series from processes with corresponding spectra , we plot in figure [ f2 ] the spectral densities ( top ) for different values of @xmath62 , @xmath70 and @xmath71 hertz ; and examples of generated time series ( bottom ) .",
    "larger values of @xmath62 gives rise to faster oscillations ( higher frequencies ) of the signal .",
    "we consider two different experiments .",
    "the first one is motivated by applications in oceanography , where the differences between spectra could be produced by a small change in the modal frequency .",
    "the second experiment was designed to test if the algorithms are able to distinguish between unimodal and bimodal spectra .",
    "for all the experiments , the lengths of the time series were @xmath72 and @xmath73 .    * * experiment 1 * is based on two different jonswap ( joint north - sea wave project ) spectra ( i.e. two clusters ) .",
    "the spectral densities considered have significant wave height @xmath50 equal to @xmath74 , the first has a peak period @xmath51 of @xmath75 while for the second @xmath76 .",
    "figure [ se1 ] exhibits the jonswap spectra , showing that the curves are close to each other .",
    "five series from each spectrum were simulated and @xmath77 replicates of this experiment were made . in this case the sampling frequency was set to 1.28 hertz , which is a common value for wave data recorded using sea buoys .",
    "this experiment was carried out in @xcite to compare several clustering procedures . *",
    "* experiment 2 * is based on the ar@xmath64 process .",
    "let @xmath78 , @xmath79 , be ar(2 ) processes with @xmath80 for all @xmath24 and peak frequency @xmath81 for @xmath79 , respectively .",
    "@xmath82 represents a latent signal oscillating at a pre - defined band .",
    "define the observed time series to be a mixture of these latent ar@xmath64 processes . @xmath83 where @xmath84 is gaussian white noise",
    ", @xmath85 is a signal with oscillatory behavior generated by the linear combination @xmath86 and @xmath87 is the number of clusters . in this experiment , we set @xmath88 , with @xmath89 and @xmath90 .",
    "we simulate five replicates of each signal @xmath91 , so , we have three clusters with five members each .",
    "figure [ se2 ] plots the three different spectra . for this experiment @xmath92 replicates were made , and the sampling frequency was set to 1 hertz .      to compare clustering results",
    ", we must take into account the  quality of the clustering \" produced which depends on both the similarity measure and the clustering algorithm used .",
    "the hsm method has two main features : the use of the tv distance as a similarity measure and the hierarchical spectral merger algorithm .",
    "the hsm method will be compared with the usual hierarchical agglomerative clustering algorithm using the complete linkage function , which is one of the standard clustering procedures used in the literature .",
    "@xcite proposed two simulation tests to compare the performance of several dissimilarity measures for time series clustering .",
    "we compare the hsm method with competitors that were based on the spectral density and performed well in prtega daz and vilar s experiments .",
    "in addition , we also considered the distance based on the cepstral coefficients , which was used in @xcite , and the symmetric version of the kulback - leibler divergence , that was used in a hierarchical clustering algorithm in @xcite .",
    "let @xmath93 be the periodogram for time series @xmath94 , at frequencies @xmath95 with @xmath96 $ ] , and @xmath97 be the normalized periodogram , i.e. @xmath98 , with @xmath99 the sample variance of time series @xmath94 ( notice that @xmath100 ) .",
    "the estimator of the spectral density @xmath101 is the smoothed periodogram using a parzen window with bandwidth equal to @xmath102 , normalized by dividing by @xmath99 .",
    "the dissimilarity criteria in the frequency domain considered were :    * the euclidean distance between the normalized estimated spectra : @xmath103 * the euclidean distance between the logarithm of the normalized estimated spectra : @xmath104 * the square of the euclidean distance between the cepstral coefficients @xmath105 where , @xmath106 and @xmath107 .",
    "* the symmetric kullback - leibler distance between the normalized estimated spectra : @xmath108    we also added the clustering method proposed by @xcite , that uses the tv distance in a hierarchical clustering algorithm .",
    "all these dissimilarity measures were compared with the hsm method using normalized estimated spectra .    to evaluate the rate of success , we considered the following index which has been already used for comparing different clustering procedures [ @xcite , @xcite ] .",
    "let @xmath109 and @xmath110 , be the set of the @xmath2 true groups and a @xmath19-cluster solution , respectively .",
    "then , @xmath111 where @xmath112 .",
    "note that this similarity measure will return 0 if the two clusterings are completely dissimilar and 1 if they are the same .    in the comparative study ,",
    "each simulation setting was replicated n times , and the rate of success for each one was computed .",
    "the mean values for this index are shown in tables [ exp1jons ] and [ exp2ar2 ] , and boxplots of the values obtained are shown in figures [ bpexp1jons ] and [ bpexp2ar ] .",
    "the simulation settings were the same in all cases and the clustering algorithm is hierarchical with the complete link function ( similar results are obtained with the average link ) . for the hsm method , we used the notation hsm1 when we used the single version , and hsm2 when we used the average version .",
    "the clustering method of @xcite is denoted by tv .",
    "cccccccc experiment 1 & +   + @xmath113 & np & lnp & cep & tv & skl & hsm1 & hsm2 +   + 500 & 0.979 & 0.772 & 0.597 & 0.988 & 0.994 & 0.989 & 0.988 + 1000 & 0.998 & 0.851 & 0.825 & 0.999 & 0.999 & 0.999 & 0.999 + 2000 & 1 & 0.932 & 0.908 & 1 & 1 & 1 & 1 +    cccccccc experiment 2 & +   + @xmath113 & np & lnp & cep & tv & skl & hsm1 & hsm2 +   + 500 & 0.864 & 0.949 & 0.895 & 0.930 & 0.952 & 0.836 & 0.838 + 1000 & 0.961 & 0.996 & 0.974 & 0.990 & 0.994 & 0.983 & 0.983 + 2000 & 0.995 & 1 & 0.999 & 0.999 & 0.999 & 0.999 & 0.999 +   +    we can see from the boxplots corresponding to * experiment 1 * that the cep distance has many values smaller than @xmath114 even in the case of @xmath115 . in * experiment 2 *",
    ", the hsm method did not have a good performance for small - sized time series .",
    "it is necessary to have @xmath116 , for the hsm method to identify the clusters more precisely .",
    "the np distance has the worst performance overall .",
    "in general , the rates of success for the hsm methods are very close to one . in some cases",
    "the hsm method has the best results , and when it is not the case , the rates obtained by the hsm method are close to the best . the methods based on logarithms , such as the lnp and cep , have in some cases a good performance but in others their performance is very poor .",
    "compared to the symmetric kullback - leibler distance , there is no clear winner but the method proposed here still has the advantage of being easily interpretable because the kl ( or symmetric kl ) can not indicate if the dissimilarity value is large since it belongs to the range @xmath117 .      for real data",
    "the number of clusters is usually unknown .",
    "thus , an objective criterion is needed to determine the optimal number of clusters .",
    "as mentioned in step 3 of our algorithm , the tv distance computed before joining two clusters can be used as a criterion .",
    "we present two options for selecting the number of clusters .",
    "the first is an empirical criterion while the second one is based on a bootstrap procedure .",
    "consider the following experimental design , similar to that of * experiment 2*. let @xmath78 be an ar(2 ) process with @xmath118 for all @xmath24 and peak frequencies @xmath119 and @xmath120 for @xmath121 , respectively .",
    "define the observed time series to be a mixture of these latent ar@xmath64 processes .",
    "@xmath122 where @xmath84 is gaussian white noise , @xmath85 is a signal with oscillatory behavior generated by the linear combination @xmath86 , @xmath87 is the number of spectrally synchronized groups or clusters and @xmath123 denotes the number of replicates of each signal @xmath91 .",
    "figure [ f6 ] displays the graphs corresponding to the minimum values of the tv distance between clusters as a function of the number of clusters ; figure [ f6a ] corresponds to the experimental design just described ; figure [ f6b ] corresponds to the experimental design with the same coefficients as the first one but @xmath124 , @xmath125 and @xmath126 draws ; figure [ f6c ] corresponds to a design with @xmath124 , @xmath125 and @xmath126 draws , with coefficients @xmath127 finally , in figure [ f6d ] we set @xmath128 , @xmath129 and @xmath126 draws but the coefficients @xmath130 are drawn from a dirichlet distribution with parameters @xmath131 . all these curves are decreasing and the speed of decrease slows down after the true number of clusters , even when the signals involved in each experiment are different .",
    "this `` elbow '' that seems to appear with the true number of clusters can be used as a empirical criteria to decide the number of clusters .",
    "analogous results were obtained with several different simulation schemes .",
    "similar criteria are frequently used in cross validation methods . in this sense",
    "we propose this empirical criteria to get the number of possible clusters in real data analysis .",
    "the second option is based on a bootstrap procedure to approximate the distribution of the tv distance between estimated spectral densities , that was proposed in @xcite and will be reported in detail in a different manuscript . here",
    ", we will use this methodology to approximate the distribution of the total variation distance between two clusters .",
    "then , we use this approximated distribution to choose a threshold for the tv distance between estimated spectra to decide whether or not the clusters should be merged .",
    "the algorithm proposed in @xcite to obtain a bootstrap sample of the tv distance is the following .    1 .   from @xmath132 and @xmath133 , estimate @xmath134 and @xmath135 and take @xmath136 2 .",
    "[ a3 ] draw @xmath137 i.i.d random variables , then estimate @xmath138 using also the smoothed periodogram .",
    "[ a4 ] the bootstrap spectral density will be @xmath139 4 .",
    "repeat [ a3 ] and [ a4 ] and estimate @xmath140 using the bootstrap spectral densities , i.e. , @xmath141 where @xmath142 , @xmath143 are two bootstrap spectral densities using different replicates of the process @xmath144 .    the bootstrap spectral density presented in [ a3 ] and [ a4 ]",
    "is motivated by the method presented in @xcite .",
    "@xcite shows that this procedure produces a consistent estimation of the distribution of the tv distance . to extend this procedure to choose the number of clusters ,",
    "first we need to note that due to the hierarchical structure of the algorithms used in all the methods proposed , the test following test are equivalent : @xmath145 since the @xmath146 clusters are built by joining two of the @xmath19 clusters .",
    "in addition , we will use this option in the method presented by @xcite to select the number of clusters and compare with the hsm method .",
    "the distribution of the total variation distance between two clusters depends on the clustering procedure .",
    "when using the hsm method we aim to approximate the distribution of the distance between the mean spectra in each cluster while for the hierarchical clustering with the tv distance , we need to produce samples from each cluster to approximate the distribution of the distance calculated through the link function",
    ".    the procedure of this test will be :    * run the clustering procedure , either the hsm method or hierarchical clustering with average or complete linkage . *",
    "identify the two clusters that are joined to get the @xmath146 clusters .",
    "* under the null hypothesis where the two clusters should be merged , denote the common representative spectral estimate to be @xmath147 . *",
    "simulate the spectra with the bootstrap procedure to compute the tv distance .",
    "we consider two cases : * * when using the hsm method simulate two spectral densities from the common spectra @xmath1 and compute the tv distance between them .",
    "repeat this procedure @xmath60 times . *",
    "* when using hierarchical clustering with the tv distance simulate two sets of spectral densities of size @xmath148 and @xmath149 from the common spectra @xmath1 , where @xmath150 are the number of members in cluster @xmath151 ( clusters to be joined ) . compute the link function ( complete or average ) between these two sets of spectra using the tv distance . distance .",
    "* run the test with the bootstrap sample .    _",
    "* remark . * _ notice that this test assumes that there exits a common spectra @xmath1 within each cluster . in practice ,",
    "it is possible that the spectra in one cluster could vary slightly and in that setting we could cast this under mixed effects model ( @xcite ) .    to investigate the performance of this procedure , we used * experiments 1 * and * 2*. we considered the tv distance to feed a hierarchical algorithm with two different link functions , namely , average and complete . also , we considered the hsm method with the average version .",
    "in this case , we use @xmath77 replicates for each experiment .    tables [ exp1nc ] and [ exp2nc ] present the proportion of times that the null hypothesis is rejected . to reject we used the bootstrap quantile of probability @xmath152 . we did not expect to have a proportion of rejection equal to @xmath152 , since in the case of using the complete or average link , these values are not a direct observation of the tv distance .",
    "however , we expect to have a good performance . in general",
    ", it could be possible to overestimate the number of clusters .",
    "ccccc experiment 1 & +   + test & @xmath152 & complete & average & hsm +   + 1 cluster vs 2 clusters & 0.01 & 1 & 1 & 1 + & 0.05 & 1 & 1 & 1 + & 0.1 & 1 & 1 & 1 + 2 clusters vs 3 clusters & 0.01 & 0.052 & 0.154 & 0.008 + & 0.05 & 0.206 & 0.492 & 0.058 + & 0.1 & 0.382 & 0.670 & 0.164 +    in * experiment 1 * the true number of clusters is @xmath153 . from table",
    "[ exp1nc ] , we observe that all methods rejected the hypothesis of one cluster , at all the significance levels .",
    "this means that the procedures did not underestimate the number of clusters . to test @xmath153 versus @xmath74 clusters ,",
    "the proportion of rejection is high when we used the average link function , except in the case @xmath154 .",
    "if we used the complete link , the results are better .",
    "however , the best results are given by the hsm method .",
    "ccccc experiment 2 & +   + test & @xmath152 & complete & average & hsm +   + 2 clusters vs 3 clusters & 0.01 & 0.968 & 1 & 0.25 + & 0.05 & 1 & 1 & 0.924 + & 0.1 & 1 & 1 & 0.998 + 3 clusters vs 4 clusters & 0.01 & 0.072 & 0.18 & 0.002 + & 0.05 & 0.228 & 0.924 & 0.050 + & 0.1 & 0.376 & 0.998 & 0.106 +    in * experiment 2 * the true number of clusters is @xmath74 .",
    "this is a more a difficult case , since the spectra are very close . from table",
    "[ exp2nc ] when testing 2 versus 3 clusters , we observe that the complete and average link functions did not underestimate the number of clusters .",
    "however , the hsm method did not distinguish 3 clusters at a level @xmath154 , but the results are better at higher levels . for testing 3 versus 4 clusters , hsm performed the best , followed by the complete link .",
    "again it was necessary to have a small value of @xmath152 in order that the average link gave a reasonable performance .",
    "figure [ pvaluestest ] shows the p - values obtained comparing the value from each simulation with the bootstrap distribution .",
    "we confirm the fact that the underestimation of the number of clusters has low probability , almost zero in some cases , for the three methods .",
    "when the number of clusters to test is the correct one , @xmath153 in * experiment 1 * and @xmath74 in * experiment 2 * , the p - values are widely distributed in the case of the complete link and hsm method . with the average link ,",
    "the p - values are smaller compared to the other methods . in general , this test has a good performance when one uses the complete link or the hsm method .",
    "we developed the _ hsmclust _ package written in r that implements our proposed clustering method .",
    "the package can be downloaded from http://ucispacetime.wix.com/spacetime#!project-a/cxl2 .",
    "* example 1 : eeg data . *",
    "our first data example is the resting - state eeg data from a single subject .",
    "the goal here is to cluster resting - state eeg signals from different channels that are spectrally synchronized , i.e. , that show similar spectral profiles .",
    "this subject is from the healthy population and the eeg clustering here will serve as a  standard \" to which the clustering of stroke patients ( with severe motor impairment ) will be compared .",
    "data were collected at 1000 hz and pre - processed in the following way .",
    "the continuous eeg signal was low - pass filtered at 100 hz , segmented into non - overlapping 1 second epochs , and detrended . the original number of channels 256 had to be reduced to 194 because of the presence of artifacts that could not be corrected ( e.g. , loose leads ) .",
    "the eeg channels were grouped into @xmath155 pre - defined regions in the brain as specified in @xcite : prefrontal ( left - right ) , dorsolateral prefrontal ( left - right ) , pre - motor ( left - right ) , supplementary motor area ( sma ) , anterior sma , posterior sma , primary motor region ( left - right ) , parietal ( left - right ) , lateral parietal ( left - right ) , media parietal ( left - right ) and anterior parietal ( left - right ) .",
    "figure [ f1 ] shows the locations of these regions on the cortical surface .",
    "we present the results for subject blak at epoch 25 of the resting state .",
    "the interpretations will employ the usual division in frequency ranges for the analysis of spectral densities of eeg data : delta ( 0.1 - 3 hertz ) , theta ( 4 - 7 hertz ) , alpha ( 8 - 12 hertz ) , beta ( 13 - 30 hertz ) and gamma ( 31 - 50 hertz ) .",
    "figure [ e21 ] shows the minimum value of the tv distance , in this case the `` elbow '' appears around @xmath156 clusters .",
    "we analize the results for 7 clusters as well , in this case the channels in two of the clusters were grouped into one since there were no significant evidence to reject 6 clusters over 7 .",
    "figure [ e22 ] and [ e23 ] show the shape of the mean normalized spectra by cluster and the location at the cortical surface .",
    "many of the channels at the occipital and left premotor regions belong to cluster @xmath156 ( pink ) , which is dominated by frequencies at the theta and alpha bands ( 4 - 12 hz ) .",
    "cluster @xmath153 ( red ) is conformed by the channels at the right premotor region and this cluster is only influenced by the delta band ( 0 - 4 hz ) .",
    "clusters 1 ( black ) and 5 ( sky blue ) are the only ones with influence of the beta band and they are located at the left motor and left anterior parietal regions .",
    "the hsm method captures the behavior of the eeg during the resting state through the cluster membership of the eeg channels .",
    "in addition , the hsm method also identifies the frequency bands that primarily drive the formation of the clusters .",
    "the clusters produced are consistent for the most part with the anatomical - based parcellation of the cortical surface and thus cluster formation based on the spectra of the eegs could be used to recover the spatial structure of the underlying brain process    * example 2 .",
    "sea waves data . * as a second example we consider wave - height data from the coastal data information program ( cdip ) buoy 160 ( 44098 for the national data buoy center ) situated off the coast of new hampshire , usa , at a water depth of 76.5 m. , when a storm took place in december 2010 .",
    "the data correspond to a period of 69 hours , divided into 138 intervals of 30 minutes and recorded with a frequency of 1.28 hz , between the 26th and the 29th of december .",
    "the use of stochastic processes for the analysis and modeling of sea waves has a long history , starting with the work of @xcite and @xcite .",
    "a model commonly used is that stationary gaussian random process . for this",
    "particular sea waves data , the presence of a storm implies that the sea surface will be very unstable and the hypothesis of stationarity will only be valid for short periods of time .",
    "sea - height data from buoys are usually divided into short intervals , between 20 and 30 minutes of duration , which are considered to be long enough to get a reasonable estimation of the spectral density , and short enough for stationarity to hold . for each interval ,",
    "several numerical parameters are calculated from the estimated spectral density , which give a summary of the sea conditions .",
    "two very important ones are the significant wave height and the peak frequency , or equivalently , the peak period .",
    "the former is a standard measure of sea severity and is defined as four times the standard deviation of the time series .",
    "the latter is just the modal spectral frequency , or the corresponding period .",
    "figure [ f - olas1 ] ( left ) presents the evolution of both parameters for the time interval being considered .         in",
    "@xcite a segmentation method for long time series based on a clustering procedure was proposed and applied to a similar problem , but in a different location and different sea conditions .",
    "we will apply the same method with the clustering procedure introduced in this work .",
    "the main idea is that the spectral density should be able to identify the time intervals coming from the same stationary process .",
    "thus , since the data are already divided into 30-minute intervals , a clustering procedure on the corresponding spectral densities should identify intervals having similar oscillatory behavior .",
    "if these intervals are contiguous in time , then they are considered part of a longer stationary interval .",
    "more details on the procedure can be found in @xcite .    as in the previous example , the trajectory for the minimum tv distance ( figure [ f - olas1 ] , right ) is used to get a first estimate for the number of clusters , which in this case is 15 .",
    "a bootstrap test supports this choice ( p - value = 0.01 ) .",
    "the segmentation resulting from this clustering is shown in figure [ f - olas2 ] , where the different clusters correspond to different colors in the vertical lines .",
    "it is interesting to compare these results with a similar analysis of a different data set in @xcite , event thought the clustering procedures differ . in that case , for a time series of 96 hours recorded in waimea bay , hawaii in january , 2003 , only 5 or 6 clusters were detected , depending on the linkage function ( average or complete ) used for the hierarchical agglomerative procedure . during the period studied for the hawaii data there is also a storm , but of a much smaller magnitud , with a significant wave height always below 5 m. in contrast , for the data considered in this paper , significant wave height surpasses 7 m. at the peak of the storm .",
    "the intensity of the storm is a possible factor in the presence of more clusters of shorter duration .",
    "table [ t - olas1 ] gives the duration of consecutive intervals within a common cluster , with a mean value of 2.23 h and a median of 1.5 h.    .frequency table for the duration of consecutive intervals within a common cluster .",
    "[ cols=\"^,^,^,^,^,^,^,^,^,^,^ \" , ]     figure [ f - olas3 ] presents the normalized spectral densities for the 15 clusters .",
    "the graphics show that bimodal spectral densities characterize some clusters , even though in some cases the secondary mode is much smaller than the main one .",
    "bimodal spectra correspond to the presence of a second train of waves with different dominating frequency , and the presence of this secondary train of waves , even if it is small , is captured by the method as an important feature of the spectra . in other cases",
    "there are differences on the dispersion of the spectral density or in the location of the modal frequency .",
    "the procedure employed yields a spectral characterization of the different clusters , which can be linked to the statistical characteristics of their duration , something which is useful for the design of marine structures and energy converters .",
    "a new clustering procedure for time series based on the spectral densities and the total variation ( tv ) distance , the hierarchical spectral merger ( hsm ) algorithm , was introduced . using numerical experiments ,",
    "the proposed hsm method was compared with other available procedures , and the results show that its performance comparable to the best , in addition to having an intuitive interpretation .",
    "applications to two data from different scientific fields were also presented , showing that the method has wide applicability in many different areas .",
    "however , the method is not free from limitations and further developments are needed .",
    "the fact that each cluster has a characteristic spectral density , with respect to which all distances are measured , may provide a way of correcting classification mistakes that occur due to the evolution of the clusters .",
    "this methodology would give a more robust clustering method .",
    "the software wafo developed by the wafo group at lund university of technology , sweden , available at http://www.maths.lth.se/matstat/wafo was used for the calculation of all spectral densities and associated spectral characteristics .",
    "the data for station 160 were furnished by the coastal data information program ( cdip ) , integrative oceanographic division , operated by the scripps institution of oceanography , under the sponsorship of the u.s .",
    "army corps of engineers and the california department of boating and waterways ( http://cdip.ucsd.edu/ ) .",
    "this work was partially supported by 1 ) conacyt , mxico , scholarship as visiting research student , 2 ) conacyt , mxico , proyectos 169175 anlisis estadstico de olas marinas , fase ii and 234057 anlisis espectral , datos funcionales y aplicaciones , and 3 ) centro de investigacin en matemticas ( cimat ) , a.c .",
    "eun and ortega wish to thank prof pedro c. alvarez esteban for several fruitful conversations on the methodology proposed on this paper .",
    "c. eun wishes to thank to uc irvine space time modeling group for the invitation to collaborate as a visiting scholar in their research group .",
    "the research conducted at the uc irvine space - time modeling group ( pi : ombao ) is supported in part by the national science foundation division of mathematical sciences and the division of social and economic sciences .",
    "the authors thank dr .",
    "steven c. cramer of the uc irvine department of neurology for sharing the eeg data that was used in this paper .",
    "this work was done while j.o .",
    "was visiting , on sabbatical leave from cimat and with support from conacyt , mxico , the departamento de estadstica e i.o",
    ". , universidad de valladolid . their hospitality and support",
    "is gratefully acknowledged .",
    "brodtkorb , p.  a. , johannesson , p. , lindgren , g. , rychlik , i. , rydn , j. , and sj , e. ( 2010 ) .",
    "wafo - a matlab toolbox for analysis of random waves and loads . in _ proceedings of the 10th international offshore and polar engineering conference _ , volume  3 , pages 343350 , seattle , usa .",
    "gavrilov , m. , anguelov , d. , indyk , p. , and motwani , r. ( 2000 ) .",
    "mining the stock market : which measure is best . in _ in proceedings of the 6 th acm intl conference on knowledge discovery and data mining _ , pages 487496 ."
  ],
  "abstract_text": [
    "<S> we present a new method for time series clustering which we call the hierarchical spectral merger ( hsm ) method . </S>",
    "<S> this procedure is based on the spectral theory of time series and identifies series that share similar oscillations or waveforms . </S>",
    "<S> the extent of similarity between a pair of time series is measured using the total variation distance between their estimated spectral densities . at each step of the algorithm , </S>",
    "<S> every time two clusters merge , a new spectral density is estimated using the whole information present in both clusters , which is representative of all the series in the new cluster . </S>",
    "<S> the method is implemented in an r package _ hsmclust_. we present two applications of the hsm method , one to data coming from wave - height measurements in oceanography and the other to electroencefalogram ( eeg ) data .    </S>",
    "<S> * keywords : * hierarchical spectral merger clustering , time series clustering , hierarchical clustering , total variation distance , time series , spectral analysis . </S>"
  ]
}