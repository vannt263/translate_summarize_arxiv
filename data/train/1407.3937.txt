{
  "article_text": [
    "the modern era of high quality nn interactions started when the long term studies of the nijmegen group culminated in a succesfull least squares fit with a statistically significant @xmath1  @xcite after implementation of many small but crucial effects and @xmath0 inconsistent data were excluded . since then , subsequent analyses have been carried out  @xcite having @xmath2 and with the purpose of being used in _ ab initio _ nuclear structure calculations . as is well known  @xcite any least - squares fit , corresponds to @xmath3 minimization @xmath4 where @xmath5 is a fitted observable , @xmath6 the corresponding statistical error bar and @xmath7 the theoretical model depending on fitting parameters @xmath8 .",
    "the procedure assumes that the statistical uncertainties of the fitted data can be modeled by a probability distribution ; namely independent normally distributed data @xmath9 an assumption based on counting a large number of events in nn scattering experiments .",
    "the assumption of a finite number of normally distributed data is an indispensable prerequisite for both a meaningful uncertainty estimates from a phenomenological fit and any subsequent and reliable error propagation .",
    "fortunately , normality can be checked _ a posteriori _ in probabilistic terms and within a given confidence level by application of a variety of statistical tests , which naturally become more stringent with the number of data .",
    "of course , individually checking the probability distribution of over 6700 data points , involving over 300 experiments , some dating back more than 60 years , is rather impractical .",
    "however , if a model fitted to the data is flexible enough to accurately reproduce them , the normality of the experimental data implies that discrepancies between theory and experiment , known as _ residuals _ , must follow a standard normal distribution , i.e. @xmath10 once a fit has been made , testing eq .",
    "( [ eq : normalresiduals ] ) is straightforward . despite its simplicity ,",
    "normality testing has not been a common practice in nuclear interactions fitting ( an early discussion on normality was however conducted in ref .",
    "@xcite ) .    in a recent publication",
    "@xcite we presented a new phenomenological nucleon - nucleon ( nn ) potential that accurately describes 6713 scattering data from 1950 to 2013 upgrading much of the previous works and increasing the statistics .",
    "this was done with an eye put on the determination of the uncertainties in the fitted nn interaction itself and their consequences in nuclear physics , for which little is still known ( see however @xcite ) and statistical methods offer the most natural framework . on a more general level ,",
    "a growing concern on the statistical analysis of nuclear theory and its predictive power has been initiated  ( see e.g. @xcite for general and instructive overviews and references therein ) . we have applied some of the well known normality tests to three of our nn potentials , including the delta - shell potential with one pion exchange ( ds - ope )  @xcite , ( chiral ) two pion exchange ( ds-@xmath11tpe )  @xcite and a gaussian potential with ope  @xcite and found the normality condition to hold in all of them  @xcite .",
    "the lack of normality would clearly signal an inconsistency in the fitting analysis and might be used as a guide to unveil systematic errors both in the data as well as in the model .",
    "it is thus foreseeable that normality tests will be regarded as an important ingredient in the design of nn interactions statistically inferred from scattering data ( see e.g. @xcite for a posteriori analysis of @xcite ) .    in our previous works",
    "the covariance matrix method was used to propagate errors . in the present note",
    "we discuss the robustness of our results using monte carlo techniques and the bootstrap method  @xcite .",
    "while these methods have succesfully been exploited ( see e.g.  @xcite for related studies within @xmath12 scattering error analyses ) to our knowledge they have never been implemented within the context of the nn force , so our presentation will be intentionally pedagogical .",
    "we also outline interesting consequences regarding strategies for error propagation in nuclear physics .",
    "in the standard covariance method one starts with a least squares fit  eq .",
    "( [ eq : chi2 ] ) .",
    "once the condition of normality , eq .",
    "( [ eq : normalresiduals ] ) , has been checked  @xcite and _ assuming _ normality of errors in the fitting parameters we are in position to propagate the statistical uncertainties into the potential parameters and any calculation that takes this potential parameters as an input .",
    "the error matrix @xmath13 of the potential parameters @xmath14 can be calculated by inverting the hessian matrix @xmath15 which can be used to obtain confidence intervals for the parameters and correlations among them .",
    "any quantity that can be calculated as a function of the potential parameters @xmath16 can be provided with an statistical error bar @xmath17 with the customary expression @xmath18 a good approximation to eq.([eq : hessianmat ] ) can be found in  @xcite which has been used with eq.([eq : covarianceerrors ] ) to estimate statistical uncertainties of phase - shifts , scattering amplitudes , deuteron properties , form factors , matrix elements and skyrme parameters  @xcite .",
    "however the derivatives in eq.([eq : covarianceerrors ] ) , depending on the functional form of @xmath19 , may be hard to calculate analytically .",
    "if one contemplates numerical evaluation this requires a repeated evaluation of the function @xmath19 at several values of the fitting parameters , which for a large number of parameters ( typically 30 - 40 @xcite ) may also be a costly procedure   must be smaller than the statistical @xmath20 which are usually quite small . for instance , the evaluation of the hessian numerically for our fits @xcite requires to compute crossed derivatives , which turned out to be highly unstable for large number of parameters .",
    "this is why we prefered to compute the derivatives analytically and use in passing the highly efficient levenberg - marquardt minimization algorithm where a stable ( definite positive ) approximation to the hessian is exploited  @xcite . ] .",
    "the calculation of derivatives can be avoided by drawing random numbers following a multivariate normal distribution determined by the covariance matrix @xmath21 , @xmath22 this generates a family of potential parameters and calculate @xmath19 with each potential .",
    "this monte carlo method directly propagates uncertainties , however a multivariate normal probability distribution to all the parameters is assumed which may not always be the case for the _ true _ distribution of parameters .",
    "the bootstrap is a monte carlo technique that allows to find the most likely parameters probability distribution and propagate statistical uncertainties and correlations into any function @xmath19  @xcite ( see also @xcite ) . in our case",
    "the deviations between the theoretical model and the experimental data are normal statistical fluctuations the procedure corresponds to generate replicas of the observed data which are meant to simulate a fictitious experiment .",
    "thus , for every experimental data point @xmath5 with uncertainty @xmath6 one generates @xmath23 `` synthetic '' random points @xmath24 distributed as @xmath25 , i.e. @xmath26 where @xmath27 are standard normal and independent variables,@xmath28 and @xmath29 .",
    "this will generate @xmath23 independent databases with the same number of data as the original one .",
    "each synthetic database will represent a snapshot of the random fluctuations inherent to the experimental processes .",
    "a least squares fit to every generated database , @xmath30 ( @xmath31 ) , featuring a maximum likelihood estimate can be made and a family of parameters @xmath32 will be obtained as @xmath33 then , the most likely theory parameters are @xmath34 . the corresponding joined or marginal probability distributions can be obtained by binning the outcoming parameter samples . this allows to compute any function of the theoretical model parameters @xmath35 at a set of points @xmath36 .",
    "thus , the mean and variance can be computed for large @xmath23 as usual , @xmath37 \\ , ,   \\label{eq : variance}\\end{aligned}\\ ] ] the correlation coefficient of two different observables is @xmath38 } { \\sqrt{e\\left[(f - e(f))^2 \\right]}\\sqrt{e\\left[(g - e(g))^2 \\right ] } } \\ , , \\end{aligned}\\ ] ] so that @xmath39 is the correlation matrix . for asymmetric or skewed distributions",
    ", it may be better to define the @xmath40 asymmetric coverage by excluding @xmath41 of the upper and lower values of the distribution instead of the variance definition , eq .",
    "( [ eq : variance ] ) . at any rate we always check this possibility before errors are quoted .    while the bootstrap method requires to perform @xmath23 repeated fits",
    ", it is a competitive alternative to determine errors and correlations when the covariance matrix itself is not directly available nor used in the minimization method  @xcite .",
    "again , we stress that this method to generate snapshots of the statistical fluctuations is justified since the condition of eq.([eq : normalresiduals ] ) has been checked to a significant confidence level .",
    "we apply the different methods to the @xmath0 self - consistent database presented in ref .",
    "@xcite where @xmath42 .",
    "the potential used for this analysis has the form @xmath43 the long range piece @xmath44 contains a charge - dependent ( cd ) one pion exchange ( ope ) with a fixed @xmath45  @xcite ) and electromagnetic ( em ) corrections which are kept fixed throughout the fitting process .",
    "the short component was inspired by avils  @xcite ( see also @xcite ) and reads @xmath46 \\ , ,   \\label{eq : potential - short}\\end{aligned}\\ ] ] where @xmath47 are the set of operators in the extended av18 basis  @xcite , @xmath48 are fitting parameters and @xmath49 with @xmath50 .",
    "the fit is carried out more effectively in terms of some low and independent partial waves contributions to the potential @xmath51 from which all other higher partial waves are consistently deduced ( see ref .",
    "the delta - shell potential reduces the computational effort enormously , so a large number of fits can easily be undertaken .    for the bootstrap analysis we took @xmath52 samples of the @xmath53 data and refitted the parameters of the ds - ope potential ( denoted by @xmath51 ) which was used to determine the database",
    "this generates @xmath23 independent sets of most likely parameters to each synthetic database @xmath54 , @xmath55 . from there",
    "any function of the fitted parameters and the inherent correlations can be determined .    in figure",
    "[ fig : correlation ] we show the correlation matrix of the ds - ope potential parameters obtained with the standard covariance matrix method and the bootstrap method .",
    "it is not obvious , though most wellcome , that both covariance and bootstrap methods give fairly similar results , although small correlations are overestimated by the covariance matrix .",
    "the main difference between both methods is in the @xmath56-@xmath57 coupled channel .",
    "the monte carlo bootstrap simulation results in very small correlations between the @xmath56 and @xmath58 partial wave parameters and stronger correlations between @xmath58 and @xmath57 ; in contrast the covariance matrix method gives opposite results .",
    "these discrepancies could be related to the fitting of the deuteron binding energy where the approximation used for the hessian matrix might be outside of its range of validity .",
    "in fact , the monte carlo generated @xmath56 , @xmath58 and @xmath57 parameters show large asymmetries as can clearly be seen in figure [ fig : j1distributions ] .",
    "we compare in fig .",
    "[ fig : pserrorsbars ] the propagation of statistical uncertainties into phase - shifts by three methods : i ) the standard covariance matrix method , ii ) the equivalent monte carlo implementation of the covariance matrix using the multivariate normal distribution of eq .",
    "( [ eq : multinormal ] ) with @xmath52 and iii ) the boostrap method also with @xmath52 samples .",
    "the first and the second methods should produce the same results for a sufficietnly large number of parameter samples . so the agreement between eq.([eq : covarianceerrors ] ) and the monte carlo sampling of parameters eq .",
    "( [ eq : multinormal ] ) reflects the large @xmath23 value with the same @xmath21 .",
    "although the bootstrap method tends to give slightly larger error bars the difference with the other two methods is not significant . as mentioned above",
    ", one potential advantage of the bootstrap method is that it relaxes the assumption of normally distributed fitted parameters , a feature which proves relevant for asymmetric or skewed distributions .",
    "we find that the asymmetries seen in figure [ fig : j1distributions ] do not significanly propagate to the corresponding phase shifts .    as a matter of principle the monte carlo simulation of data gives the most reliable uncertainty propagation , but considering that performing a large number of full - length fits to data can be computationally expensive the covariance matrix methods are a fairly good and extremely useful approximation which will be exploited in future work .",
    "the propagation of statistical errors of nuclear forces stemming from the finite precision and number of experimental nn scattering data requires in the first place passing a normality test .",
    "however , even in this favourable case the actual calculation may be computationally demanding because of a practical need of repeating large scale computations .",
    "it is thus important to explore methods where the number of calculations can be kept to a minimum . in the standard covariance matrix method one needs the evaluation of the hessian as well as the derivatives of the object function",
    "whose uncertainties are evaluated with respect to the theoretical model parameters . as an alternative the monte carlo method based on explicit knowledge of the hessian can profitably be used as it avoids the computation of derivatives ( analytical or numerical ) and automatically implements in any snapshot the inherent correlations in the fitting parameters .",
    "the previous methods assume a multivariate normal distribution of the fitting parameters .",
    "we have thus analyzed the more ellaborated bootstrap method which also rests on the normality test and is based on a multiple minimization to a synthetic set of data generated by the distribution of the most likely estimate of the model parameters . while this approach assumes normality of the experimental data but not of the fitting parameters , it allows to handle possible skewness in the parameter distributions .",
    "our bootstrap analysis confirms the error and correlations already found by the covariance method ."
  ],
  "abstract_text": [
    "<S> ' '' ''    we use the monte carlo bootstrap as a method to simulate pp and np scattering data below pion production threshold from an initial set of over 6700 experimental mutually @xmath0 consistent data . </S>",
    "<S> we compare the results of the bootstrap , with 1020 statistically generated samples of the full database , with the standard covariance matrix method of error propagation . </S>",
    "<S> no significant differences in scattering observables and phase shifts are found . </S>",
    "<S> this suggests alternative strategies for propagating errors of nuclear forces in nuclear structure calculations . </S>"
  ]
}