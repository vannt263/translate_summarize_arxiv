{
  "article_text": [
    "centralized algorithms for solving optimization problems rely on the existence of a central computational unit powerful enough to solve the problem in a timely manner , and they render useless in case we lack such a unit . also such algorithms become unviable when it is impossible to form the problem in a centralized manner , for instance due to structural constraints including privacy requirements . in cases like these ,",
    "distributed optimization algorithms are the only resort for solving optimization problems , e.g. , see @xcite . in this paper",
    "we are interested in devising efficient distributed algorithms for solving convex optimization problems in the form    [ eq : eop ] @xmath0    where @xmath1 , @xmath2 , @xmath3 with @xmath4 and @xmath5 for all @xmath6 . here",
    "@xmath7 denotes the component - wise inequality .",
    "this problem can be seen as a combination of @xmath8 coupled subproblems , each of which is defined by an objective function @xmath9 and by constraints that are expressed by @xmath10 and matrices @xmath11 and @xmath12 .",
    "furthermore , we assume that these subproblems are only dependent on a few elements of @xmath13 , and that they are loosely coupled .",
    "the structure in such problems is a form of partial separability , which implies that the hessian of the problem is sparse , see e.g. , @xcite and references therein .",
    "existing distributed algorithms for solving , commonly solve the problem using a computational network with @xmath8 computational agents , each of which is associated with its own local subproblem .",
    "the graph describing this computational network has the node set @xmath14 with an edge between any two nodes in case they need to communicate with one another .",
    "the existence of an edge also indicates existence of coupling among the subproblems associated to neighboring agents .",
    "this graph is referred to as the _ computational _ graph of the algorithm and matches the coupling structure in the problem , which enables us to solve the problem distributedly while providing complete privacy among the agents .    among different algorithms for solving problems like distributedly , the ones based on first order methods are among the simplest ones .",
    "these algorithms are devised by applying gradient / subgradient or proximal point methods to the problem or an equivalent reformulations of it , see e.g. , @xcite . in this class , algorithms that are based on gradient or subgradient methods , commonly require simple local computations . however , they are extremely sensitive to the scaling of the problem , see e.g. , @xcite .",
    "algorithms based on proximal point methods alleviate the scaling sensitivity issue , see e.g. , @xcite , but this comes at a price of more demanding local computations and/or more sophisticated communication protocols among agents , see e.g. , @xcite .    despite the effectiveness of this class of algorithms , they generally still require many iterations to converge to an accurate solution . in order to improve the convergence properties of the aforementioned algorithms , there has recently been a surge of interest in devising distributed algorithms using second order methods , see e.g. , @xcite . in @xcite , the authors propose a distributed optimization algorithm based on a lagrangian dual decomposition technique which enables them to use second order information of the dual function to update the dual variables within a dual interior - point framework . to this end , at each iteration , every agent solves a constrained optimization problem for updating local primal variables and then communicates with all the other agents to attain the necessary information for updating the dual variables .",
    "this level of communication is necessary due to the coupling in the considered optimization problem .",
    "the authors in @xcite present a distributed newton method for solving a network utility maximization problem .",
    "the proposed method relies on the special structure in the problem , which is that the objective function is given as a summation of several decoupled terms , each of which depends on a single variable .",
    "this enables them to utilize a certain matrix splitting method for computing newton directions distributedly . in @xcite",
    "the authors put forth distributed primal and primal - dual interior - point methods that rely on proximal splitting methods , particularly admm , for solving for primal and primal - dual directions , distributedly .",
    "this then allows them to propose distributed implementations of their respective interior - point methods .",
    "one of the major advantages of the proposed algorithms in @xcite lies in the fact that the required local computations are very simple .",
    "these approaches are based on inexact computations of the search directions , and they rely on first order or proximal methods to compute these directions .",
    "generally the number of required iterations to compute the directions depends on the desired accuracy , and in case they require high accuracy for the computed directions , this number can grow very large .",
    "this means that commonly the computed directions using these algorithms are not accurate , and particularly the agents only have approximate consensus over the computed directions .",
    "this inaccuracy of the computed directions can also sometimes adversely affect the number of total primal or primal - dual iterations for solving the problem .    in this paper",
    "we propose a distributed primal - dual interior - point method and we evade the aforementioned issues by investigating another distributed approach to solve for primal - dual directions . to this end we borrow ideas from so - called message - passing algorithms for exact inference over probabilistic graphical models , @xcite . in this class of inference methods , message - passing algorithms are closely related to non - serial dynamic programming , see e.g. , @xcite .",
    "non - serial dynamic programming techniques , unlike serial dynamic programming , @xcite , that are used for solving problems with chain - like or serial coupling structure , are used to solve problems with general coupling structure .",
    "specifically , a class of non - serial dynamic programming techniques utilize a tree representation of the coupling in the problem and use similar ideas as in serial techniques to solve the problem efficiently , see e.g. , @xcite .",
    "we here also use a similar approach for computing the primal - dual directions . as we will see later ,",
    "this enables us to devise distributed algorithms , that unlike the previous ones compute the exact directions within a finite number of iterations .",
    "in fact , this number can be computed a priori , and it only depends on the coupling structure in the problem .",
    "unfortunately these advantages come at a cost .",
    "particularly , these algorithms can only be efficiently applied to problems that are sufficiently sparse .",
    "furthermore , for these algorithms the computational graphs can differ from the coupling structure of the problem , and hence they can only provide partial privacy among the agents .",
    "the approach presented in this paper is also closely related to multi - frontal factorization techniques for sparse matrices , e.g. , see @xcite .",
    "in fact we will show that the message - passing framework can be construed as a distributed multi - frontal factorization method using fixed pivoting for certain sparse symmetric indefinite matrices . to the best knowledge of the authors",
    "the closest approach to the one put forth in this paper is the work presented in @xcite .",
    "the authors for these papers , propose an efficient primal - dual interior - point method for solving problems with a so - called nested block structure . specifically , by exploiting this structure , they present an efficient way for computing primal - dual directions by taking advantage of parallel computations when computing factorization of the coefficient matrix in the augmented system at each iteration . in this paper , we consider a more general coupling structure and focus on devising a distributed algorithm for computing the search directions , and we provide assurances that this can be done even when each agent has a limited access to information regarding the problem , due to privacy constraints .",
    "next we first define some of the common notations used in this paper , and in section  [ sec : cpp ] we put forth a general description of coupled optimization problems and describe mathematical and graphical ways to express the coupling in the problem . in section [ sec : chordal ] we review some concepts related to chordal graphs .",
    "these are then used in section  [ sec : omp ] to describe distributed optimization algorithms based on message - passing for solving coupled optimization problems .",
    "we briefly describe the primal - dual interior - point method in section [ sec : pdipm ] . in section [ sec : dpdipm ] , we first provide a formal mathematical description for loosely coupled problems and then we show how primal - dual methods can be applied in a distributed fashion for solving loosely coupled problems . furthermore , in this section we discuss how the message - passing framework is related to multi - frontal factorization techniques .",
    "we test the performance of the algorithm using a numerical example in section  [ sec : number ] , and finish the paper with some concluding remarks in section [ sec : conclude ] .",
    "we denote by @xmath15 the set of real scalars and by @xmath16 the set of real @xmath17 matrices .",
    "with @xmath18 we denote a column vector of all ones .",
    "the set of @xmath19 symmetric matrices are represented by @xmath20 .",
    "the transpose of a matrix @xmath21 is denoted by @xmath22 and the column and null space of this matrix is denoted by @xmath23 and @xmath24 , respectively .",
    "we denote the set of positive integers @xmath25 with @xmath26 .",
    "given a set @xmath27 , the matrix @xmath28 is the @xmath29-@xmath30 matrix that is obtained by deleting the rows indexed by @xmath31 from an identity matrix of order @xmath32 , where @xmath33 denotes the number of elements in set @xmath34 .",
    "this means that @xmath35 is a @xmath33- dimensional vector with the components of @xmath13 that correspond to the elements in @xmath34 , and we denote this vector with @xmath36 .",
    "with @xmath37 we denote the @xmath38th element of vector @xmath39 at the @xmath40th iteration .",
    "also given vectors @xmath39 for @xmath41 , the column vector @xmath42 is all of the given vectors stacked .",
    "consider the following convex optimization problem @xmath43 where @xmath44 for all @xmath6 .",
    "we assume that each function @xmath45 is only dependent on a small subset of elements of @xmath13 .",
    "particularly , let us denote the ordered set of these indices by @xmath46 .",
    "we also denote the ordered set of indices of functions that depend on @xmath47 with @xmath48 . with this description of coupling within the problem , we can now rewrite the problem in  , as @xmath49 where @xmath50 is a @xmath29@xmath30 matrix that is obtained from an identity matrix of order @xmath32 by deleting the rows indexed by @xmath51 .",
    "the functions @xmath52 are lower dimensional descriptions of @xmath45s such that @xmath53 for all @xmath54 and @xmath6 . for instance consider the following optimization problem @xmath55 and let us assume that @xmath56 , @xmath57 , @xmath58 , @xmath59 , @xmath60 , @xmath61 and @xmath62 . with this dependency description we then have @xmath63 , @xmath64 , @xmath65 , @xmath66 , @xmath67 , @xmath68 , @xmath69 and @xmath70 .",
    "this problem can then be written in the same format as in as @xmath71 the formulation of coupled problems as in enables us to get a more clear picture of the coupling in the problem .",
    "next we describe how the coupling structure in   can be expressed graphically using undirected graphs .      a graph @xmath72 is specified by its vertex and edge sets @xmath73 and @xmath74 , respectively .",
    "the coupling structure in can be described using an undirected graph with node or vertex set @xmath75 and the edge set @xmath76 with @xmath77 if and only if @xmath78 .",
    "we refer to this graph , @xmath79 , as the _ coupling graph _ of the problem .",
    "notice that all sets @xmath80 induce complete subgraphs on the coupling graph of the problem .",
    "another graph that sheds more light on the coupling structure of the problem is the so - called _ sparsity graph _ , @xmath81 , of the problem .",
    "this graph is also undirected , though with node or vertex set @xmath82 and the edge set @xmath83 with @xmath84 if and only if @xmath85 .",
    "similarly , all sets @xmath86 induce complete subgraphs on the sparsity graph of the problem .",
    "let us now reconsider the example in  .",
    "the sparsity and coupling graphs for this problem are illustrated in figure [ fig : sg ] , on the left and right respectively .",
    "it can then be verified that all @xmath86s and @xmath80s induce complete graphs over coupling and sparsity graphs , respectively .",
    "as we will see later graph representations of the coupling structure in problems play an important role in designing distributed algorithms for solving coupled problems and gaining insight regarding their distributed implementations .",
    "specifically , chordal graphs and their characteristics play a major role in the design of our proposed algorithm .",
    "this is the topic of the next section .",
    "a graph @xmath87 with vertex set @xmath73 and edge set @xmath74 is chordal if every of its cycles of length at least four has a chord , where a chord is an edge between two non - consecutive vertices in a cycle , ( * ? ? ?",
    "4 ) . a clique of @xmath72 is a _ maximal _",
    "subset of @xmath73 that induces a complete subgraph on @xmath72 .",
    "consequently , no clique of @xmath72 is entirely contained in any other clique , @xcite .",
    "let us denote the set of cliques of @xmath72 as @xmath88 .",
    "there exists a tree defined on @xmath89 such that for every @xmath90 with @xmath91 , @xmath92 is contained in all the cliques in the path connecting the two cliques in the tree .",
    "this property is called the clique intersection property , and trees with this property are referred to as clique trees . for instance",
    "the graph on the left in figure [ fig : sg ] is chordal and has five cliques , namely @xmath93 , @xmath94 , @xmath95 , @xmath96 and @xmath97 .",
    "a clique tree over these cliques is given in figure [ fig : sc ] .",
    "this tree then satisfies the clique intersection property , e.g. , notice that @xmath98 and the only clique in the path between @xmath99 and @xmath100 , that is @xmath101 , also includes @xmath102 .",
    "chordal graphs and their corresponding clique trees play a central role in the design of the upcoming algorithms . for chordal graphs",
    "there are efficient methods for computing cliques and clique trees .",
    "however , the graphs that we will encounter , particularly the sparsity graphs , do not have to be chordal . as a result , next and for the sake of completeness we first review simple heuristic methods to compute a chordal embedding of such graphs , where a chordal embedding of a graph @xmath87 is a chordal graph with the same vertex set and an edge set @xmath103 such that @xmath104 .",
    "we will also explain how to compute its cliques and the corresponding clique tree .",
    "greedy search methods are commonly used for computing chordal embeddings of graphs , where one such method is presented in algorithm  [ alg : embed ] , @xcite , @xcite .",
    "the graph @xmath72 with the returned edge set @xmath74 will then be a chordal graph .",
    "this algorithm also computes the set of cliques of the computed chordal embedding which are returned in the set @xmath105 .",
    "notice that @xmath106 in steps 4 , 5 and 6 is defined based on the most recent description of the sets @xmath107 and @xmath108 .",
    "the criterion used in step 3 of the algorithm for selecting a vertex is the so - called _ min - degree criterion_. there exist other versions of this algorithm that utilize other criteria , e.g. , _",
    "min - weight _ , _ min - fill _ and _ weighted - min - fill_. having computed a chordal embedding of the graph and its clique set , we will next review how to compute a clique tree over the computed clique set .",
    "assume that a set of cliques for a chordal graph @xmath72 is given as @xmath109 . in order to compute a clique tree over the clique set",
    "we need to first define a weighted undirected graph , @xmath110 , over @xmath111 with edge set @xmath112 where @xmath113 if and only if @xmath114 , where the assigned weight to this edge is equal to @xmath115 . a clique tree over @xmath116 can be computed by finding any maximum spanning tree of the aforementioned weighted graph .",
    "this means finding a tree in the graph that contains all its nodes and edges with maximal accumulated weight .",
    "an algorithm to find such a tree is presented in algorithm  [ alg : span ] , @xcite , @xcite .",
    "the tree described by the vertex set @xmath107 and edge set @xmath108 is then a clique tree .",
    "we will now discuss distributed optimization using message - passing .",
    "in this section , we describe a distributed optimization algorithm based on message - passing .",
    "particularly , we focus on the building blocks of this algorithm , namely we will provide a detailed description of its computational graph , messages exchanged among agents , the communication protocol they should follow and how they compute their corresponding optimal solutions . the convergence and computational properties of such methods , within exact inference over probabilistic graphical models , are extensively discussed in ( * ? ? ?",
    "13 ) . for the sake of completeness and future reference",
    ", we here also review some of these results and provide proofs for these results using the unified notation in this paper , in the appendix .",
    "consider the optimization problem in .",
    "let @xmath117 denote the chordal sparsity graph for this problem and let @xmath118 and @xmath119 be its set of cliques and a corresponding clique tree , respectively .",
    "it is possible to devise a distributed algorithm for solving this problem that utilizes the clique tree @xmath120 as its computational graph .",
    "this means that the nodes @xmath121 act as computational agents and collaborate with their neighbors that are defined by the edge set @xmath108 of the tree .",
    "for example , the sparsity graph for the problem in has five cliques and a clique tree over these cliques is illustrated in figure  [ fig : sc ] .",
    "this means the problem can be solved distributedly using a network of five computational agents , each of which needs to collaborate with its neighbors as defined by the edges of the tree , e.g. , agent 2 needs to collaborate with agents @xmath122 .        in order to specify the messages exchanged among these agents , we first assign different terms of the objective function in to each agent",
    "a valid assignment in this framework is that @xmath45 can only be assigned to agent @xmath123 if @xmath124 .",
    "we denote the ordered set of indices of terms of the objective function assigned to agent @xmath123 by @xmath125 . for instance , for the problem in , assigning @xmath126 and @xmath127 to agent 2 would be a valid assignment since @xmath128 and hence @xmath129 .",
    "notice that the assignments are not unique and for instance there can exist agents @xmath123 and @xmath40 with @xmath130 so that @xmath124 and @xmath131 making assigning @xmath45 to agents @xmath123 or @xmath40 both valid . also for every term of the objective function there will always exist an agent that it can be assigned to , which is proven in the following proposition .",
    "for each term @xmath45 of the objective function , there always exists a @xmath132 for which @xmath124 .    recall that each set @xmath86 induces a complete subgraph on the sparsity graph , @xmath81 , of the problem . then by definition of cliques , @xmath86 is either a subset of a clique or is a clique of the sparsity graph .",
    ".,width=222 ]    before we continue with the rest of the algorithm description , we first need to define some new notations that are going to be extensively used in the following .",
    "consider figure [ fig : ct ] which illustrates a clique tree @xmath119 for a given sparsity graph @xmath81 .",
    "each node in the tree is associated to a clique of @xmath81 and let @xmath133 denote the set of indices of cliques that are on the node @xmath134-side of edge @xmath135 .",
    "similarly , @xmath136 denotes the same but for the ones on the @xmath123-side of @xmath137 .",
    "also we denote the set of indices of variables in the cliques specified by @xmath133 by @xmath138 , i.e. , @xmath139 .",
    "similarly the set of indices of variables in cliques specified by @xmath136 is denoted by @xmath140 .",
    "the set of all indices of objective function terms that are assigned to nodes specified by @xmath133 is represented by @xmath141 , i.e. , @xmath142 , and the ones specified by @xmath136 with @xmath143 . in order to make the newly defined notations more clear ,",
    "let us reconsider the example in and its corresponding clique tree in figure [ fig : sc ] , and let us focus on the @xmath144 edge .",
    "for this example then @xmath145 , @xmath146 , @xmath147 , @xmath148 , @xmath149 and @xmath150 . with the notation defined",
    ", we will now express the messages that are exchanged among neighboring agents . particularly , let @xmath134 and @xmath123 be two neighboring agents ,",
    "then the message sent from agent @xmath134 to agent @xmath123 , @xmath151 , is given by @xmath152 where @xmath153 is the so - called separator set of agents @xmath134 and @xmath123 . as a result , for agent @xmath134 to be able to send the correct message to agent @xmath123 it needs to wait until it has received all the messages from its neighboring agents other than @xmath123 . hence , the information required for computing a message also sets the communication protocol for this algorithm .",
    "specifically , it sets the ordering of agents in the message - passing procedure in the algorithm , where messages can only be initiated from the leaves of the clique tree and upwards to the root of the tree , which is referred to as an upward pass through the tree .",
    "for instance , for the problem in and as can be seen in figure  [ fig : sc ] , @xmath154",
    ". then the message to be sent from agent 2 to agent 1 can be written as @xmath155 which can only be computed if agent 2 has received the messages from agents 4 and 5 .",
    "the message , @xmath151 , that every agent @xmath123 receives from a neighboring agent @xmath134 in fact summarizes all the necessary information that agent @xmath123 needs from all the agents on the @xmath134-side of the edge @xmath156 .",
    "particularly this message provides the optimal value of @xmath157 as a function of the variables that agents @xmath134 and @xmath123 share , i.e. , @xmath158 .",
    "this is shown in the following theorem .",
    "[ thm : thm2 ] consider the message sent from agent @xmath134 to agent @xmath123 as defined in .",
    "this message can also be equivalently rewritten as @xmath159    see ( * ? ? ?",
    "10.3 ) or appendix [ app : app3 ] .    with this description of messages and at the end of an upward - pass through the clique tree ,",
    "the agent at the root of the tree , indexed @xmath160 , will have received messages from all its neighbors .",
    "consequently , it will have all the necessary information to compute its optimal solution by solving the following optimization problem @xmath161 the next theorem proves the optimality of such a solution .",
    "[ thm : thm3 ] the equation in can be rewritten as @xmath162 which means that @xmath163 denotes the optimal solution for elements of @xmath13 specified by @xmath164 .",
    "see ( * ? ? ?",
    "10.2 , prop . 13.1 ) or appendix [ app : app4 ]    let us now assume that the agent at the root having computed its optimal solution @xmath163 , sends messages @xmath165 and the computed optimal solution @xmath166 to its children , i.e. , to all agents @xmath167 . here",
    "@xmath166 denotes the optimal solution computed by agent @xmath160 .",
    "then all these agents , similar to the agent at the root , will then have received messages from all their neighbors and can compute their corresponding optimal solution as @xmath168 notice that since @xmath163 is optimal , the additional regularization term in will not affect the optimality of the solution .",
    "all it does is to assure that the computed optimal solution by the agent is consistent with that of the root .",
    "this observation also allows us to rewrite as    @xmath169 this means that the root does not need to compute nor send the message @xmath165 to its neighbors and it suffices to only communicate its computed optimal solution .",
    "the same procedure is executed downward through the tree until we reach the leaves , where each agent @xmath134 , having received the computed optimal solution by its parent , i.e. , @xmath170 , computes its optimal solution by @xmath171 where @xmath172 denotes the index for the parent of agent @xmath134 . as a result by the end of one upward - downward",
    "pass through the clique tree ,",
    "all agents have computed their corresponding optimal solutions , and hence , at this point , the algorithm can be terminated .",
    "furthermore , with this way of computing the optimal solution , it is always assured that the solutions computed by parents and the children are consistent with one another .",
    "since this is the case for all the nodes in the clique tree , it follows that we have consensus over the network .",
    "a summary of this distributed approach is given in algorithm  [ alg : mp ] .    by the end of the downward",
    "pass all agents have computed their optimal solutions and the algorithm is terminated .",
    "[ rem : rem1 ] _ notice that in case the optimal solution of is unique , then we can drop the regularization term in since the computed optimal solutions by the agents will be consistent due to the uniqueness of the optimal solution . _",
    "so far we have provided a distributed algorithm to compute a consistent optimal solution for convex optimization problems in the form .",
    "however , this algorithm relies on the fact that we are able to eliminate variables and compute the optimal objective value as a function of the remaining ones in closed form .",
    "this capability is essential , particularly for computing the exchanged messages among agents and in turn limits the scope of problems that can be solved using this algorithm .",
    "we will later show how the described algorithm can be incorporated within a primal - dual interior - point method to solve general convex optimization problems , distributedly .",
    "[ rem : rem2 ] _ the message - passing scheme presented in this section is in fact a recursive algorithm and it terminates within a finite number of steps or after an upward - downward pass . let us define , @xmath173 , the height of a tree as the maximum number of edges in a path from the root to a leaf .",
    "this number then tells us how many steps it will take to perform the upward - downward pass through the tree . as a result ,",
    "the shorter the tree the fewer the number of steps we need to take to complete a pass through the tree and compute the solution . due to this fact , and since given a tree we can choose any node to be the root , having computed the clique tree we can improve the convergence properties of our algorithm by choosing a node as the root that gives us the minimum height . _          as was discussed above , the clique tree of the sparsity graph of a coupled problem , defines the computational graph for the distributed algorithm that solves it .",
    "given the sparsity graph for the problem , one of the ways for computing a chordal embedding and a clique tree for this graph is through the use of algorithms  [ alg : embed ] and [ alg : span ] .",
    "particularly , using these algorithms allows one to automate the procedure for producing a clique tree for any given sparsity graph , with possibly different outcomes depending on the choice of algorithms .",
    "however , it is important to note that sometimes manually adding edges to the sparsity graph or its chordal embedding can enable us to shape the clique tree to our benefit and produce more suitable distributed solutions . in this case , though , extra care must be taken .",
    "for instance , it is important to assure that the modified sparsity graph is still a reasonable representation of the coupling in the problem and that the generated tree satisfies the clique intersection property , and is in fact a clique tree , as this property has been essential in the proof of the theorems presented in this section .",
    "we illustrate this using an example . consider the following coupled optimization problem    [ eq : example1 ] @xmath174    this problem can be equivalently rewritten as @xmath175 where @xmath176 for @xmath177 , are the indicator functions for the constraints in  , respectively , defined as @xmath178",
    "this problem is in the same format as .",
    "let us assume that we intend to produce a distributed algorithm for solving this problem using message - passing that would take full advantage of parallel computations . without using any intuition regarding the problem and/or incorporating any particular preference regarding the resulting distributed algorithm , we can produce the chordal sparsity graph for this problem as depicted in the top graph of figure [ fig : ex1 ] .",
    "a clique tree for this sparsity graph can be computed using algorithms [ alg : embed ] and [ alg : span ] , which is illustrated in the bottom plot of figure [ fig : ex1 ] . a distributed algorithm based on this computational graph",
    "does not take full advantage of parallel computations .        in order to produce a distributed algorithm that better facilitates the use of parallel computations , it is possible to modify the sparsity graph of the problem as shown in figure [ fig : ex2 ] , the top graph , where we have added additional edges , marked with dashed lines , to the graph while preserving its chordal property .",
    "notice that by doing so , we have virtually grouped variables @xmath179@xmath180 , that couple the terms in the objective function and constraints , together .",
    "the corresponding clique tree for this graph is illustrated in figure [ fig : ex2 ] , the bottom graph .",
    "notice that due to the special structure in the clique tree , within the message - passing algorithm the computation of the messages generated from agents 14 can be done independently , and hence in parallel .",
    "so using this clique tree as the computational graph of the algorithm enables us to fully take advantage of parallel computations .",
    "next we briefly describe a primal - dual interior - point method for solving convex optimization problems , and then we investigate the possibility of devising distributed algorithms based on these methods for solving loosely coupled problems .",
    "consider the following convex optimization problem @xmath181 where @xmath182 , @xmath183 and @xmath184 with @xmath185 and @xmath186 . under the assumption that we have constraint qualification , e.g. , that there exist a strictly feasible point",
    ", then @xmath187 , @xmath188 and @xmath189 constitute a primal - dual optimal solution for if and only if they satisfy the kkt optimality conditions for this problem , given as    [ eq : convexineqkktp1 ] @xmath190    a primal - dual interior - point method computes such a solution by iteratively solving linearized perturbed versions of where is modified as @xmath191 with @xmath192 , @xcite .",
    "particularly , for this framework , at each iteration @xmath38 given primal and dual iterates @xmath193 , @xmath194 and @xmath195 so that @xmath196 and @xmath197 for all @xmath198 , the next update direction is computed by solving the linearization of    [ eq : convexineqkktpd ] @xmath199    at the current iterates , given as    [ eq : qappineqkktpd ] @xmath200    where    [ eq : res ] @xmath201    define @xmath202 , @xmath203 , @xmath204 and @xmath205 . by eliminating @xmath206 as @xmath207 we can rewrite as @xmath208 which has a lower dimension than , and unlike the system of equations in , is symmetric .",
    "this system of equations is sometimes referred to as the augmented system .",
    "it is also possible to further eliminate @xmath209 in and then solve the so - called normal equations for computing @xmath210 .",
    "however , this commonly destroys the inherent structure in the problem , and hence we abstain from performing any further elimination of variables .",
    "the system of equations in also expresses the optimality conditions for the following quadratic program @xmath211 and hence , we can compute @xmath209 and @xmath210 also by solving  . having computed @xmath209 and @xmath210 , @xmath206",
    "can then be computed using , which then allows us to update the iterates along the computed directions .",
    "a layout for a primal - dual interior - point is given in algorithm [ alg : pd ] .",
    "@xmath212 @xmath213 @xmath214    [ rem : nonsingular ] _ notice that in order for the computed directions to constitute a suitable search direction , the coefficient matrix in needs to be nonsingular .",
    "there are different assumptions that guarantee such property , e.g. , that @xmath215 , _",
    "@xcite_. so , we assume that the problems we consider satisfy this property .",
    "_    there are different approaches for computing proper step sizes in the 5th step of the algorithm .",
    "one of such approaches ensures that @xmath216 for @xmath198 and @xmath217 , by first setting @xmath218 and conducting a backtracking line search as below +    @xmath219    with @xmath220 and @xmath221 initialized as @xmath222 .",
    "moreover , in order to ensure steady decrease of the primal and dual residuals , the back tracking is continued as    @xmath219    where @xmath223 $ ] .",
    "the resulting @xmath221 ensures that the primal and dual iterates remain feasible at each iteration and that the primal and dual residuals will converge to zero , @xcite .",
    "[ rem : infeas ] _ the primal - dual interior - point method presented in algorithm [ alg : pd ] , is an infeasible long step variant of such methods , _",
    "@xcite_. there are other alternative implementations of primal - dual methods that particularly differ in their choice of search directions , namely short - step , predictor - corrector and mehrotra s predictor - corrector .",
    "the main difference between the distinct primal - dual directions , commonly arise due to different approaches for perturbing the kkt conditions , specially through the choice of @xmath224 , _",
    "@xcite_. this means that for the linear system of equations in , only the right hand side of the equations will be different and hence the structure of the coefficient matrix in remains the same for all the aforementioned variants .",
    "consequently , all the upcoming discussions will be valid for other such variants .",
    "_    next we provide a formal description of loosely coupled problems and will show how we can devise a distributed primal - dual interior - point method for solving these problems using message - passing .",
    "in this section we put forth a distributed primal - dual interior - point method for solving loosely coupled problems .",
    "particularly , we first provide a formal description for loosely coupled problems and then give details on how to compute the primal - dual directions and proper step sizes , and how to decide on terminating the algorithm distributedly .",
    "consider the convex optimization problem in .",
    "we can provide mathematical and graphical descriptions of the coupling structure in this problem , as in section [ sec : cpp ] .",
    "the only difference is that the coupling structure will in this case concern the triplets @xmath225 and @xmath11 instead of single functions @xmath45 .",
    "similar to we can reformulate   as    [ eq : ddeops ] @xmath226    where in this formulation , the functions @xmath227 and @xmath228 are defined in the same manner as the functions @xmath229 , @xmath230 with @xmath231 , and the matrices @xmath232 are defined by removing unnecessary columns from @xmath11 where @xmath233 and @xmath234 for all @xmath6 .",
    "furthermore , we assume that the loose coupling in the problem is such that the sparsity graph of the problem is such that for all cliques in the clique tree , we have @xmath235 and that @xmath236 is small in comparison to the cliques sizes .    from now on",
    "let us assume that the chordal sparsity graph of the problem in has @xmath237 cliques and that @xmath119 defines its corresponding clique tree . using the guidelines discussed in section [ sec : omp ]",
    ", we can then assign different subproblems that build up to each node or agent in the tree .",
    "as we will show later , our proposed distributed primal - dual method utilizes this clique tree as its computational graph .",
    "before we go further and in order to make the description of the messages and the message - passing procedure simpler let us group the equality constraints assigned to each agent @xmath123 as @xmath238 where    [ eq : localequality ] @xmath239    for @xmath240 , where @xmath241 .",
    "we can then rewrite the problem in as    [ eq : deopseq1 ] @xmath242    where the coefficient matrices @xmath243 are obtained by permuting the columns of the matrices @xmath244 .",
    "next we solve by applying the primal - dual method in algorithm [ alg : pd ] to and will discuss how it can be done distributedly within a primal - dual framework .",
    "the computational burden of each iteration of a primal - dual interior - point method is dominated by primal - dual directions computation .",
    "we hence start by describing a distributed algorithm for calculating these directions using message - passing .",
    "computing the primal - dual directions requires solving the linear system of equations in   where for the problem in @xmath245 with @xmath246 @xmath247 with @xmath248 , @xmath249 where @xmath250 with @xmath251 and @xmath252 with @xmath253 the key for devising a distributed algorithm based on a primal - dual interior - point method , is to exploit the structure in this linear system of equations that also expresses the optimality conditions for the following quadratic program    [ eq : qappeqlogpd ] @xmath254    which can be rewritten as    [ eq : qappeqlogpd1 ] @xmath255    where @xmath256 with @xmath257 . in order to assure that the property in remark [ rem : nonsingular ] also holds for the problem in , we need to make assumptions regarding the subproblems assigned to each agent , which is described in the following lemma .",
    "[ lem : lemd ] the condition in remark [ rem : nonsingular ] holds for the problem in , if @xmath258 for all subproblems @xmath259 .",
    "the condition in remark [ rem : nonsingular ] is equivalent to @xmath260 since @xmath261 for all @xmath6 , this condition can be equivalently rewritten as @xmath262 \\cap \\left [ \\bigcap_{i=1}^q \\mathcal n\\left(\\mathbf a^i e_{c_i}\\right )    \\right ] = \\ { 0 \\}.\\end{aligned}\\ ] ] by arranging the terms in and using associative property of the intersection operator , we can equivalently reformulate it as @xmath263 = \\ { 0 \\}.\\end{aligned}\\ ] ] notice that the @xmath264s are constructed such that they have full row rank .",
    "now let @xmath265 for all @xmath266 , and assume that there exists @xmath267 such that @xmath268.\\end{aligned}\\ ] ] this then implies that for any @xmath269 it must hold that @xmath270 for all @xmath266 , or equivalently @xmath271 for all @xmath266 , since @xmath264s have full row rank . under the assumption that @xmath267 , then for some @xmath272 , @xmath273 .",
    "therefore , @xmath274 and @xmath275 for some @xmath134 .",
    "this is in contradiction to the assumption that @xmath265 for all @xmath266 .",
    "this completes the proof .",
    "we can rewrite as the following unconstrained optimization problem @xmath276 where @xmath277 is the polyhedral set defined by the @xmath134th equality constraint in and @xmath278 is its corresponding indicator function .",
    "the problem in is in the same form as .",
    "notice that the coupling structure in this problem remains the same during the primal - dual iterations .",
    "furthermore , the coupling structure for this problem is such that we can solve it by performing message - passing over the clique tree for the sparsity graph of  . considering the subproblem assignments discussed in section [ sec : loose ] , at each iteration of the primal - dual method",
    ", each agent will have the necessary information to form their corresponding quadratic subproblems and take part in the message passing framework .",
    "let us now focus on how the exchanged messages can be computed and what information needs to be communicated within the message passing procedure .",
    "firstly , notice that each @xmath229 describes an equality constrained quadratic program .",
    "consequently , computing the exchanged messages for solving  , requires us to compute the optimal objective value of equality constrained quadratic programs parametrically as a function of certain variables .",
    "we next put forth guidelines on how this can be done efficiently .",
    "consider the following quadratic program @xmath279 where @xmath280 , @xmath281 , @xmath282 with @xmath283 , @xmath284 , and that @xmath285 . without loss of generality",
    "assume that we intend to solve this optimization problem parametrically as a function of @xmath286 .",
    "this means that we want to solve the following optimization problem @xmath287 the optimality conditions for this problem are given as @xmath288 notice that for the problem in @xmath289 is nonsingular , which is shown in the following lemma .",
    "[ lem : lemrank ] consider the problem in , and assume that @xmath284 and @xmath285 .",
    "then @xmath289 is nonsingular .",
    "firstly notice that under the assumption in the lemma , the optimality condition for , given as @xmath290 has a unique solution and its coefficient matrix is nonsingular .",
    "this means that @xmath291 or equivalently @xmath292 since @xmath293 is positive semidefinite , we can rewrite it as @xmath294 where assuming @xmath295 , @xmath296 and has full column rank .",
    "then the condition in can be rewritten as @xmath297 furthermore , since @xmath298 and @xmath299 are orthogonal complements , we have @xmath300 , which enables us to rewrite as @xmath301 which is equivalent to @xmath289 being nonsingular .",
    "this completes the proof .    by lemma [ lem : lemrank ]",
    ", we can then solve as @xmath302 having computed the optimal solution parametrically as a function of @xmath286 , we can now compute the optimal objective value as a convex quadratic function of @xmath286 , @xmath303 , by simply substituting @xmath304 from in the objective function of .",
    "we can now discuss the computation and content of the messages .",
    "firstly notice that each of the constraints in can be written as @xmath305 for now assume that @xmath306 and @xmath307 are full row rank for all @xmath259 . also recall that for the problem in the message to be sent from agent @xmath134 to its parent @xmath172 is given as @xmath308 then ,",
    "for this problem , all the exchanged messages define quadratic functions as described above , which is shown in the following theorem .",
    "[ thm : thm63 ] consider the message description given in . for the problem in ,",
    "all the exchanged messages are quadratic functions .",
    "we prove this using induction , where we start with the agents at the leaves . for every agent @xmath309 , the computed message to be sent to the corresponding parent",
    "can be computed by solving    [ eq : thmqp ] @xmath310    parametrically as a function of @xmath311 . under the assumption stated in lemma [ lem : lemd ] ,",
    "@xmath258 . as a result",
    "the assumption in lemma [ lem : lemrank ] holds for and hence we can use the procedure discussed above to solve the problem parametrically . consequently the messages sent from the leaves are quadratic functions .",
    "now consider an agent @xmath134 in the middle of the tree and assume that all the messages received by this agent are quadratic functions of the form @xmath312 then this agent can compute the message to be sent to its parent , by solving    [ eq : qpmij ] @xmath313    with @xmath314 , parametrically as a function of @xmath315 .",
    "notice that the assumption in lemma [ lem : lemd ] implies that @xmath316 .",
    "this means that the assumption in lemma [ lem : lemrank ] would also be satisfied and hence the computed message to the parent would be a quadratic function .",
    "this completes the proof .",
    "notice that sending the message @xmath151 to agent @xmath123 requires agent @xmath134 to send the data matrices that define the quadratic function . following the steps of the message - passing method discussed in section  [ sec : omp ]",
    ", we can now compute the primal variables direction , @xmath209 , distributedly .",
    "it now remains to discuss how to compute the dual variables directions , @xmath317 for @xmath318 , and @xmath319 for @xmath320 .",
    "we will next show that in fact it is possible to compute the optimal dual variables direction during the downward pass of the message - passing algorithm .",
    "firstly recall that during the upward pass each agent @xmath134 , except the agent at the root , having received all the messages from its children forms and solves it parameterically as a function of @xmath315 by first computing @xmath321 as described above , and then communicating the parametric optimal objective value as the message to the parent .",
    "notice that defines the optimality conditions for given @xmath315 or equivalently the optimality conditions of without the regularization term , which we are allowed to neglect since by the assumption in lemma [ lem : lemd ] the optimal solution of is unique , see remark [ rem : rem1 ] .",
    "as a result this agent having received @xmath322 from its parent can use to compute its optimal primal solution .",
    "as we will show later the computed dual variables in during this process will also be optimal for .",
    "the agent at the root can also compute its optimal dual variables in a similar manner .",
    "particularly , this agent having received all the messages from its children can also form the problem in . notice that since @xmath323 then @xmath324 . as a result   for this agent becomes @xmath325 which is the optimality condition for",
    "consequently , the dual variables computed by this agent when calculating its optimal primal variables will in fact be optimal for the problem in .",
    "the next theorem shows that the computed primal directions @xmath326 and dual directions @xmath327 using this approach then satisfy the optimality conditions for the complete problem in   and hence constitute a valid update direction , i.e. , we can choose @xmath328 and @xmath329 .",
    "[ thm : thm5 ] if each agent @xmath259 computes its corresponding optimal primal and dual variables directions , @xmath330 , using the procedure discussed above , then the calculated directions by all agents constitute an optimal primal - dual solution for the problem in .",
    "we prove this theorem by establishing the connection between the message - passing procedure and row and column manipulations on the kkt optimality conditions of .",
    "so let us start from the leaves of the tree .",
    "from the point of view of agents @xmath331 we can rewrite as    [ eq : agenti ] @xmath332    where @xmath333 , @xmath334 with @xmath335 , @xmath336 with @xmath337 , @xmath338 , @xmath339 , @xmath340 and @xmath341 with @xmath342 .",
    "in other words , in this formulation the variables @xmath286 , @xmath343 and @xmath304 denote the variables present only in the subproblems assigned to the leaves , the variables that appear in both these subproblems and subproblems assigned to all the other agents and the variables that are not present in the subproblems assigned to the leaves , respectively . furthermore , each of the terms in the sum in and the constraints in denote the cost functions and equality constraints that are assigned to the @xmath134th agent .",
    "the kkt optimality conditions for this problem can be written as    @xmath344 which by conducting column and row permutations can be rewritten as @xmath345 by lemma [ lem : lemrank ] , the blocks @xmath346 are all nonsingular and hence we can define @xmath347 with @xmath348 .",
    "if we pre - multiply by @xmath349 , we can rewrite it as    [ eq : thmitopar ] @xmath350    where    [ eq : thmitopar - b ] @xmath351    notice that considering the definitions in and , the matrices @xmath352 and @xmath353 in and are the same , and hence the terms @xmath354 and @xmath355 in are the data matrices that define the quadratic and linear terms of the message sent from each of the leaves to its parent , and the additional terms @xmath356 and @xmath357 merely assure that the messages are communicated to the corresponding parents . by performing the pre - multiplication above",
    "we have in fact pruned the leaves of the tree , and have eliminated the variables that are only present in their respective subproblems .",
    "we can now conduct the same procedure outlined in  , that is repartitioning of variables and performing row and column permutations , for the parents that all their children have been pruned , using  .",
    "we continue this approach until we have pruned all the nodes in the tree except for the root , as    [ eq : thmitor ] @xmath358    where what remains to solve is the optimality conditions for the problem of the agent at the root , given in , in .",
    "notice that this procedure is in fact the same as the upward pass in algorithm [ alg : mp ] .",
    "at this point we can solve and back substitute the solution in the equations in with the reverse ordering of the upward pass , which corresponds to the downward pass through the clique tree in algorithm [ alg : mp ] . with this",
    "we have shown the equivalence between applying the message - passing algorithm to and solving the kkt conditions of this problem by performing row / column manipulations , and hence have completed the proof .    finally , during the downward pass and by",
    ", each agent having computed its primal variables direction @xmath359 , can compute the dual variables directions corresponding to its inequality constraints by @xmath360 for all @xmath361 .",
    "_ notice that the proposed message - passing algorithm for computing the primal - dual directions relies on the assumption that @xmath316 for all @xmath259 , and the conditions in lemma [ lem : lemd ] describe a sufficient condition for this assumption to hold .",
    "however , the aforementioned assumption can still hold even if the conditions in lemma [ lem : lemd ] are not satisfied , in which case the proposed algorithm can still be used .",
    "_    _ it is also possible to use a feasible primal interior - point method for solving the problem in . for a primal interior - point method , unlike a primal - dual one , at first the kkt optimality conditions are equivalently modified by eliminating the dual variables corresponding to the inequality constraints , using the perturbed complementarity conditions as in .",
    "then the resulting nonlinear system of equations is solved using the newton method , iteratively , _",
    "@xcite_. at each iteration of a feasible primal interior - point method , we only need to update the primal variables , where their corresponding update direction is computed by solving a linear system of equations similar to .",
    "in fact , applying a primal interior - point method to the problem in would then , at each iteration , require solving a linear system of equations that will have the same structure as the one we solve in a primal - dual interior - point method .",
    "hence , we can use the same message - passing procedure discussed above to compute the primal variables directions within a primal framework .",
    "primal interior - point methods are known to perform worse than their primal - dual counterparts . however , since we do not need to compute dual variables directions at each iteration , we can relax the rank condition on the equality constraints .",
    "this is because this condition has solely been used for the proof of theorem [ thm : thm5 ] , and only concerns the computations of the dual variables .",
    "_    the distributed algorithm for computing the primal - dual directions in this section relies on the seemingly restrictive rank conditions that @xmath362 , @xmath306 and @xmath307 are all full row rank for all @xmath259 .",
    "next we show that these conditions do not affect the generality of the algorithm and in fact they can be imposed by conducting a preprocessing of equality constraints .",
    "we can impose the necessary rank conditions by conducting a preprocessing on the equality constraints , prior to application of the primal - dual method .",
    "this preprocessing can be conducted distributedly over the same tree used for computing the search directions .",
    "let us assume that the constraints assigned to each of the agents at the leaves , i.e. , all @xmath309 , are given as @xmath363 and that @xmath364 and that @xmath365 .",
    "every such agent can then compute a rank revealing qr factorization for @xmath366 as @xmath367 where @xmath368 is an orthonormal matrix and @xmath369 with @xmath370 . as a result the constraints in can be equivalently rewritten as @xmath371 where @xmath372 once each agent at the leaves has computed the reformulation of its equality constraints , it will then remove the equality constraints defined by the second row equations in from its equality constraints , and communicates them to its parent . at this point the equality constraints assigned to each agent @xmath134 at the leaves , becomes @xmath373 where @xmath374 and @xmath375 are both full row rank . then",
    "every parent that has received all the equality constraints from its children , appends these constraints to its own set of equality constraints , and performs the same procedure as was conducted by the agents at the leaves .",
    "this process is then continued until we reach the root of the tree .",
    "the agent at the root will then conduct the same reformulation of its corresponding equality constraints and removes the unnecessary trivial equality constraints .",
    "notice that at this point the equality constraints for all agents satisfy the necessary rank conditions , and hence the preprocessing is accomplished after an upward pass through the tree .    in a similar manner as in the proof of theorem [ thm : thm5",
    "] , it can be shown that the preprocessing procedure presented in this section ( except for the removal of trivial constraints by the agent at the root ) can be viewed as conducting column permutations on the coefficient matrix of the equality constraints and pre - multiplying it by a nonsingular matrix .",
    "consequently , this preprocessing of the equality constraints , does not change the feasible set .    in the proof of theorem [ thm : thm5 ] we described the equivalence between applying the message - passing scheme in algorithm [ alg : mp ] to the problem in and solving its corresponding kkt system through column and row manipulations .",
    "inspired by this discussion , and before we describe distributed implementations of other components of the primal - dual interior - point method in algorithm [ alg : pd ] , we explore how the message - passing algorithm in [ alg : mp ] can be construed as a multi - frontal factorization technique .",
    "let us compactly rewrite the kkt system in as @xmath376 then can be written as @xmath377 where @xmath378 is a permutation matrix . in the proof of theorem [ thm : thm5 ] we showed that by pre - multiplying by @xmath349 , we can block upper - triangulate the kkt system as in , i.e. , @xmath379 is block upper - triangular .",
    "this was in fact equivalent to the first stage of the upward pass in algorithm [ alg : mp ] , which corresponds to sending messages from the agents at the leaves of the tree to their parents .",
    "if we now in this stage multiply @xmath379 from the right by @xmath380 , it is straightforward to verify that we arrive at @xmath381{square.eps}}}\\end{matrix } \\end{array } \\end{bmatrix},\\end{aligned}\\ ] ] and as a result we have block - diagonalized @xmath382 , where we have @xmath383 blocks on the diagonal .",
    "notice that the first @xmath224 blocks on the diagonal are the matrices @xmath384 for @xmath385 that are known to each of the agents at the leaves .",
    "furthermore , the information needed to form @xmath349 is distributedly known by the agents at the leaves , since we can write @xmath349 as @xmath386 this then means that not only it is possible to block - triangulate @xmath382 in the first stage of the upward pass as in , but also the information that is needed to do so is distributed among the involved agents and is based on their local information .",
    "it is possible to continue this procedure by block - triangulating the last diagonal block in right hand side of as below @xmath387{square.eps}}}\\end{matrix }   \\end{array } \\end{bmatrix}\\times \\\\\\begin{bmatrix } \\begin{array}{c : c }   i \\ \\ & 0 \\\\ \\hdashline 0 & \\begin{matrix } \\vspace{-3mm}\\\\\\bar p_2 \\end{matrix }   \\end{array } \\end{bmatrix}^t \\begin{bmatrix } \\begin{array}{c : c }   i   \\ \\ & 0 \\\\ \\hdashline 0 & \\begin{matrix } \\vspace{-3mm}\\\\\\bar q_2 \\end{matrix }   \\end{array } \\end{bmatrix}^t =    \\begin{bmatrix } \\begin{array}{c : c }   \\begin{matrix } \\blacksquare & & & \\\\ & \\blacksquare & & \\\\ & & \\hspace{1 mm } \\ddots \\   \\ & \\\\ & & & \\blacksquare \\end{matrix } & 0 \\\\ \\hdashline 0 & \\begin{matrix}\\begin{array}{c : c : c : c : c } \\blacksquare & 0 & \\dots & 0 & 0 \\\\\\hdashline 0 & \\blacksquare & \\dots & 0 & 0   \\\\\\hdashline \\vdots & \\vdots & \\hspace{1 mm } \\ddots \\   \\ & 0 & 0 \\\\\\hdashline 0 & 0 & 0 & \\blacksquare & 0 \\\\\\hdashline 0 & 0 & 0 & 0 & \\begin{matrix}\\vspace{-3mm}\\\\\\hspace{1mm}{\\mathord{\\includegraphics[height=6ex]{square.eps}}}\\end{matrix } \\end{array } \\end{matrix } \\end{array } \\end{bmatrix}\\end{gathered}\\ ] ] where similar to the previous stage @xmath388 is a permutation matrix and @xmath389 is computed using a similar approach as @xmath349 . here",
    "the newly generated small diagonal blocks are the matrices @xmath384 with @xmath134 being indices of the parents of the leaves that have received all messages from their children .",
    "this step of block - diagonalization can be accomplished after the second step of the upward pass in the clique tree .",
    "we can continue this procedure upwards through the tree until we have @xmath237 blocks on the diagonal at which point we have arrived at the root of the tree .",
    "so having finished the upward pass we have computed @xmath390 with @xmath237 diagonal elements that are the matrices @xmath384 for @xmath259 .",
    "notice that this means that by the end of an upward pass through the tree we have in fact computed an indefinite block @xmath391 factorization of @xmath382 where both the computation and storage of the factors are done distributedly over the clique tree .",
    "_ as was shown in this section , the message - passing scheme can be viewed as a distributed multi - frontal indefinite block @xmath391 factorization technique that relies on fixed pivoting .",
    "this reliance is in conformance with and dictated by the structure in the problem which can in turn make the algorithm vulnerable to numerical problems that can arise , e.g. , due ill - posed subproblems .",
    "such issues can be addressed using regularization and/or dynamic pivoting strategies . here , however , we abstain from discussing such approaches as the use of them in a distributed setting is beyond the scope of this paper . _",
    "so far we have described a distributed algorithm for computing the primal - dual directions . in the next section we put forth a distributed framework for computing proper step sizes for updating the iterates , and we will also propose a distributed method for checking the termination condition at every iteration .      in this section , we first propose a distributed scheme for computing proper step sizes that relies on the approach described in section [ sec : pdipm ] .",
    "this scheme utilizes , the clique tree used for calculating the primal - dual directions , for computing the step size . similar to the message - passing procedure discussed in the previous section ,",
    "in this scheme we also start the computations from the leaves of the tree .",
    "the proposed scheme comprises of two stages . during the first stage",
    "a step size bound is computed that assures primal and dual feasibility , with respect to the inequality constraints , of the iterates , and then during the second stage a back tracking line search is conducted for computing the step size which also assures persistent decrease of primal and dual residual norms . within the first stage",
    ", let each leaf of the tree , @xmath134 , firstly compute its bound @xmath392 by performing a local line search .",
    "this means that initially every agent at the leaves computes    @xmath393    and then performs a local line search based on its corresponding inequality constraints , i.e. , @xmath394 for @xmath361 , to compute +    @xmath395    with @xmath220 and @xmath392 initialized as @xmath396 .",
    "these agents will also compute the quantities @xmath397 with @xmath398 defined as in and @xmath399 these will be used in the second stage of the step size computation .",
    "once all leaves have computed their corresponding @xmath392 , @xmath400 and @xmath401 , they send these quantities to their parents where they will also conduct a similar line search and similar computations as the ones performed in the leaves .",
    "specifically , let agent @xmath402 be a parent to some leaves .",
    "then the only differences between the computations conducted by this agent and the leaves are in that the line search above is initialized as @xmath403 and that @xmath404 using this procedure each agent communicates its computed @xmath392 , @xmath405 and @xmath401 upwards through the tree to the root . once the root has received all the computed step size bounds from its children / neighbors , it can then compute its local step size bound in the same manner",
    ". however , the computed bound at the root , @xmath406 , would then constitute a bound on the step size for updating the iterates which ensures primal and dual feasibility for the whole problem .",
    "furthermore the computed @xmath407 and @xmath407 at the root will then constitute the norm of the primal and dual residuals for the whole problem computed at the iterates at iteration @xmath38 .",
    "this finishes the first stage of the step size computation . the second stage ,",
    "is then started by communicating this step size bound downwards through the tree until it reaches the leaves .",
    "at which point each agent at the leaves computes the quantities @xmath408 and @xmath408 as above with the updated local iterates using the step size @xmath406 .",
    "these quantities are then communicated upwards through the tree to the root where each agent having received these quantities from all its children computes its corresponding @xmath408 and @xmath408 as in using the updated local iterates .",
    "once the root have received all information from its children it can also compute its corresponding quantities which correspond to the primal and dual residuals for the whole problem computed at the updated iterates using the step size @xmath406 .",
    "then in case @xmath409 we set @xmath410 and the same procedure is repeated .",
    "however if the condition above is not satisfied , the step size computation is completed and we can choose @xmath411 , which is then communicated downwards through the tree until it reaches the leaves . at this point all agents have all the necessary information to update their local iterates .",
    "notice that since all the agents use the same step size , the updated local iterates would still be consistent with respect to one another .",
    "having updated the iterates , it is now time to decide on whether to terminate the primal - dual iterations . in order to make this decision distributedly",
    ", we can use a similar approach as for the step size computation .",
    "particularly , similar to the approach above , the computations are initiated from the leaves where each leaf @xmath134 computes the norm of its local surrogate duality gap as @xmath412 the leaves then communicate these computed quantities to their corresponding parents , which will then perform the following computations @xmath413 this approach is continued upwards through the tree until we reach the root . the computed quantity by the root , i.e. , @xmath414 ,",
    "will then be equal to the surrogate duality gap for the whole problem .",
    "this quantity together with @xmath415 , @xmath416 , which was computed during the step size computation , are used by the agent at the root to decide whether to terminate the primal - dual iterations . in case",
    "the decision is to not to terminate the iterations , then the computed surrogate duality gap is propagated downwards through the tree until it reaches the leaves of the tree , which then enables each of the agents to compute the perturbation parameter , @xmath224 , and form their respective subproblems for the next primal - dual iteration .",
    "however , in case the decision is to terminate , then only the decision will then be propagated downwards through the tree .    by now we have put forth a distributed primal - dual interior - point method for solving loosely coupled problems . in the next section we summarize the proposed algorithm and discuss its computational properties .",
    "let us reconsider the problem in .",
    "as was mentioned before , this problem can be seen as a combination of @xmath8 subproblems each of which is expressed by the objective function @xmath417 and equality and inequality constraints defined by @xmath418 , @xmath419 and @xmath420 , respectively .",
    "given such a problem and its corresponding sparsity graph @xmath81 , in order to set up the proposed algorithm , we first need to compute a chordal embedding for the sparsity graph .",
    "having done so , we compute the set of cliques @xmath421 for this chordal embedding and a clique tree over this set of cliques . with",
    "the clique tree defined , we have the computational graph for our algorithm , and we can assign each of the subproblems to a computational agent , using the guidelines discussed in section [ sec : omp ] . at this point",
    "we can perform the preprocessing procedure presented in section [ sec : preprocess ] , if necessary , and apply our proposed distributed algorithm as summarized below to the reformulated problem .",
    "@xmath422 ; @xmath423 for all @xmath361 ; @xmath424 ;    as can be seen from the summary of the algorithm above , at each iteration of the primal - dual method we need to perform several upward - downward passes through the clique tree , one for computing the primal variables direction , one to make decision regarding terminating the algorithm and/or for updating the perturbation parameter and several for computing a proper step size .",
    "notice that among the required upward - downward passes , the one conducted for computing the primal and dual variables directions is by far the most computationally demanding one .",
    "this is because at every run of this upward - downward pass each agent needs to form , which requires inverting its corresponding @xmath384 .",
    "since primal - dual interior point methods commonly converge to a solution within 3050 iterations , the computational burden for each agent is dominated by at most @xmath425 factorizations that it has to compute within the run of the primal - dual algorithm .",
    "also notice that the required number of upward - downward passes for computing the step size , depend on the back - tracking parameters @xmath426 and @xmath427 and it is possible to reduce this number by tuning these parameters carefully .",
    "furthermore , for the final iterations of the primal - dual method , also known as quadratic convergence phase , there would be no need for any back - tracking operation .",
    "let us assume that the height of the tree is equal to @xmath173 and that the total number of upward - downward passes that is required to accomplish the second stage of step size computations is equal to @xmath428 . then assuming that the primal - dual method converges within 50 iterations",
    ", the total number of upward - downward passes would mount to @xmath429 and hence the algorithm converges after @xmath430 steps of message passing . also within the run of this distributed algorithm each agent",
    "would then need to compute a factorization of a small matrix at most @xmath425 times and communicate with its neighbors @xmath431 times .",
    "_ as was discussed in remark [ rem : infeas ] the primal - dual method used in this paper is an infeasible long step primal - dual method , which requires solving or only once at each iteration .",
    "however in predictor - corrector variants of primal - dual methods , computing the search directions requires solving or twice with different @xmath432 terms .",
    "this means that distributed algorithms based on message - passing that rely on predictor - corrector primal - dual methods would need two upward - downward passes to compute the search directions .",
    "however , despite the change of @xmath432 , the matrices @xmath384 formed by each agent during the upward - pass of the message - passing remains the same for both of the mentioned upward - downward passes .",
    "consequently , each agent by caching the factorization of @xmath384 at each iteration of the primal - dual method can significantly reduce the computational burden of the second upward - downward pass .",
    "notice that considering the discussion in section [ sec : fact ] , this approach is equivalent to the caching of the factorization of the coefficient matrix of _ .",
    "next we illustrate the performance of the algorithm using a numerical experiment .",
    "in this section , we investigate the performance of the algorithm using an example . to this end",
    "we consider a flow problem over a tree where having received input flows from the leaves of the tree , i.e. , @xmath433 for all @xmath309 , the collective of agents are to collaboratively provide an output flow from the root of the tree that is as close as possible to a given reference , @xmath434 .",
    "we assume that each agent @xmath134 in the tree produces an output flow @xmath9 that depends on the flow it receives from its children and the use of its buffer which is described using its buffer flow @xmath435 , where a positive @xmath435 suggests borrowing from the buffer and a negative @xmath435 suggests directing flow into the buffer .",
    "furthermore , there exists a cost associated with the use of the buffer and a toll for using each edge for providing flow to respective parents .",
    "the setup considered in this section is depicted in figure [ fig : num1 ] , that is based on a tree with 7 agents .",
    "we intend to provide the requested output flow from the tree while accepting the input flow to the leaves , with minimum collective cost for the agents in the network .",
    "this problem can be formulated as    @xmath436    where @xmath437 with @xmath438 , the parameters @xmath439 , @xmath440 and @xmath441 denote the buffer use cost , the toll on outgoing edge and the buffer use capacity for each agent @xmath134 , respectively , and @xmath442 denotes the cost incurred on the agent at the root for providing a flow that deviates from the requested output flow . here",
    "we assume that the values of the parameters @xmath439 , @xmath441 , @xmath442 are private information for each agent , which makes it impossible to form the centralized problem .",
    "let us now rearrange the terms in the cost function and rewrite the problem as    [ eq : numericalexample ] @xmath443    this problem can now be seen as a combination of @xmath438 coupled subproblems where each of the subproblems is defined by each of the @xmath237 terms in the cost function and each of the @xmath237 constraint sets .",
    "the clique tree for the sparsity graph of this problem is illustrated in figure [ fig : num2 ] and has the same structure as the flow network . as a result , this problem can be solved distributedly using the proposed message - passing algorithm while respecting the privacy of all agents .",
    "we have solved 50 instances of the problem in where the parameters are chosen randomly with uniform distribution such that @xmath444 , @xmath445 , @xmath446 , @xmath447 , @xmath448 and @xmath449 .",
    "the parameters describing the stopping criteria for all instances are chosen to be the same and are given as @xmath450 and @xmath451 , and for all cases the initial iterates are chosen to be @xmath452 and @xmath453 . also the parameters used for computing the step sizes are chosen to be @xmath454 and @xmath455 . in the worst case",
    "the primal - dual algorithm converged after 14 iterations .",
    "the convergence behavior of the algorithm for this instance of the problem is studied by monitoring the primal and dual residuals , the surrogate duality gap and the distance to the optimal solution , as depicted in figure [ fig : conv ] . as expected",
    "the behavior resembles that of a primal - dual method .",
    "the optimal solution @xmath187 used for generating figure [ fig : conv]-c is computed using yalmip toolbox , @xcite .        also the worst case total number of backtracking steps for computing step sizes was equal to 7 , which was also obtained for this instance of the problem .",
    "so in total we required @xmath456 steps of message - passing to converge to the optimal solution out of which only 42 steps required agents to compute a factorization and the rest were computationally trivial .",
    "notice that during the run of this distributed algorithm , each agent needed to compute a factorization of a small matrix only 14 times and required to communicate with its neighbors @xmath457 times .",
    "we also tested the performance of the algorithm using a larger flow problem .",
    "the tree used for describing this problem was of height @xmath458 and was generated such that all agents , except the ones at the leaves , would have two children . a tree generated in this manner then comprises of @xmath459 nodes and the problem defined on this tree has 65534 variables .",
    "the parameters that were used for defining the problem and that were used in the algorithm were chosen in the same manner as above .",
    "for this problem the primal - dual algorithm converged after 27 iterations and required a total of 21 backtracking steps .",
    "the distributed algorithm hence converged after @xmath460 steps during which each agent required computing @xmath461 factorizations and needed to communicate with its neighbors @xmath462 times .",
    "in this paper we proposed a distributed optimization algorithm based on a primal - dual interior - point method .",
    "this algorithm can be used for solving loosely coupled problems , as defined in section [ sec : loose ] .",
    "our proposed algorithm relies solely on second order optimization methods , and hence enjoys superior convergence properties in comparison to other existing distributed algorithms for solving loosely coupled problems .",
    "specifically , we showed that the algorithm converges to a very high accuracy solution of the problem after a finite number of steps that entirely depends on the coupling structure in the problem , particularly the length of the clique tree of its corresponding sparsity graph .",
    "we prove this theorem by induction .",
    "firstly , note that for all neighboring agents @xmath134 and  @xmath123 , @xmath463 \\cup \\left ( c_i \\setminus s_{ij } \\right).\\end{aligned}\\ ] ] moreover @xmath464 and @xmath465 where is because the clique tree is assumed to satisfy the clique intersection property",
    ". these properties can also be verified for the clique tree in figure [ fig : sc ] . for instance let us consider agent 2 for which we have @xmath466",
    "\\cup \\left ( c_2 \\setminus s_{21 } \\right)\\\\ & = \\left ( v_{42 } \\setminus s_{24}\\right ) \\cup \\left ( v_{52 } \\setminus s_{25}\\right ) \\cup \\left ( c_2 \\setminus s_{21 } \\right ) \\\\ & = \\left ( \\ { 3 , 6 , 7 \\ } \\setminus \\ { 3 \\ } \\right ) \\cup \\left ( \\ { 3 , 8 \\ } \\setminus \\ { 3 \\ } \\right ) \\cup \\left ( \\ { 1 , 3 , 4 \\ } \\setminus \\ { 1 , 4 \\ } \\right)\\\\ & =   \\ { 6 , 7 \\ } \\cup \\ { 8 \\ } \\cup \\ { 3 \\ } , \\end{split}\\ ] ] where as expected from and , the three sets making @xmath467 are jointly disjoint .",
    "we start the induction by first showing that holds for all the messages originating from the leaves of the tree , i.e. , for all @xmath309 .",
    "this follows because for these nodes @xmath468 and hence @xmath469 .",
    "now let us assume that @xmath134 is a node in the middle of the tree with neighbors @xmath470 , see figure [ fig : ct ] , and that @xmath471 then can be rewritten as @xmath472 note that @xmath473 with @xmath474 .",
    "this is guaranteed since each component of the objective function is assigned to only one agent .",
    "then by and we have @xmath475 now we can merge all the minimum operators together and , by , rewrite as @xmath476 which completes the proof .      using theorem [ thm : thm2 ] ,",
    "we can rewrite as @xmath477 where we have assumed that @xmath478 .",
    "note that @xmath479 .",
    "then by we can push the _ minimum _ operators together and rewrite   as @xmath480 moreover , since @xmath481 and that @xmath482 , we can further simplify   as @xmath483 which completes the proof .",
    "p.  l. combettes and j .- c .",
    "proximal splitting methods in signal processing . in _",
    "fixed - point algorithms for inverse problems in science and engineering _ , volume  49 of _ springer optimization and its applications _ , pages 185212 .",
    "springer new york , 2011 .",
    "s.  khoshfetrat  pakazad , a.  hansson , and m.  s. andersen .",
    "distributed interior - point method for loosely coupled problems . in _ proceedings of the 19th ifac world congress _ , cape town , south africa , august 2014 .",
    "summers and j.  lygeros . distributed model predictive consensus via the alternating direction method of multipliers . in _ 50th annual allerton conference on communication , control , and computing _ , pages 7984 , 2012 ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose a distributed algorithm for solving loosely coupled problems with chordal sparsity which relies on primal - dual interior - point methods . </S>",
    "<S> we achieve this by distributing the computations at each iteration , using message - passing . in comparison to already existing distributed algorithms for solving such problems </S>",
    "<S> , this algorithm requires far less number of iterations to converge to a solution with high accuracy . </S>",
    "<S> furthermore , it is possible to compute an upper - bound for the number of required iterations which , unlike already existing methods , _ only _ depends on the coupling structure in the problem . </S>",
    "<S> we illustrate the performance of our proposed method using a set of numerical examples .    distributed optimization ; primal - dual interior - point method ; message - passing ; high precision solution . </S>"
  ]
}