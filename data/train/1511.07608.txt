{
  "article_text": [
    "in this article , we describe our research prototype system that can pick piled waste from a conveyor belt . the motivation for this prototype is grounded in the existing industrial robotic application of our company : robotic waste sorting .",
    "zenrobotics robots have been sorting waste on industrial waste processing sites since 2014 . at one of our sites ,",
    "4200 tons of construction and demolition waste has been processed . of that waste ,",
    "2300 tons of metal , wood , stone and concrete objects have been picked up from the conveyor by our sorting robots .",
    "performance of the robot in this environment is critical for paying back the investment .",
    "currently the robots are able to identify , pick and throw objects of up to 20 kg in less than 1.8 seconds , 24/7 . the current generation robot was taught to grasp objects using human annotations and a reinforcement learning algorithm as mentioned in @xcite .",
    "robotic recycling is rapidly growing , and is already transforming the recycling industry .",
    "robots ability to recognize , grasp and manipulate an extremely wide variety of objects is crucial . in order to provide this ability in a cost - effective way , new training methods which do not rely on hardcoding or human annotation",
    "will therefore be required .",
    "for example , changing the shape of the gripper or adding degrees of freedom might require all picking logic to be rewritten or at least labor - intensive retraining unless the system is able to learn to use the new gripper or degrees of freedom by itself .",
    "we have chosen to tackle a small subproblem of the whole sorting problem : learning to pick objects autonomously .",
    "this problem differs from the more studied problems of `` cleaning a table by grasping '' @xcite and bin picking @xcite in several ways : 1 ) the objects are novel and there is a large selection of different objects .",
    "objects can be broken irregularly . in effect",
    ", anything can ( and probably will ) appear on the conveyor eventually .",
    "2 ) the objects are placed on the conveyor belt by a random process and easily form random piles .",
    "3 ) on the other hand , this problem is made slightly easier by the fact that it is not necessary to be gentle to the objects ; fragile objects will likely have been broken by previous processes already .",
    "scratching or colliding with objects does not cause problems as long as the robot itself can tolerate it ( see fig .",
    "[ fig : gripper ] ) .",
    "our solution starts with no knowledge of the objects and works completely autonomously to learn how to make better pickups using feedback , for example from sensors in the gripper like opening or force feedback . in the following sections",
    ", we will first describe the system in detail , describe our experiments with the system and conclude .",
    "in this section we describe our prototype system in detail .",
    "the hardware of our system consists of a waste merry - go - around ( fig .",
    "[ fig : merry - go - around ] ) , a 3d camera ( asus xtion ) , and a gantry type robot ( a prototype version of our product model ) .",
    "the gantry robot includes a wide - opening gripper and a large - angle compliance system ( fig .  [",
    "fig : gripper ] ) .",
    "the gripper has evolved in previous versions of our product step by step to be morphologically well - adapted to the task .",
    "the gripper is position - controllable and has a sensor giving its current opening .",
    "in addition to the gripper opening , the robot has four degrees of freedom , the @xmath0 coordinates and rotation around the vertical axis ( i.e. , the gripper always faces down ) .      in our prototype system , we make use of our product s existing software modules that handle conveyor tracking and motion planning to execute a pick for a given",
    ", a data structure similar to the rectangle representation of jiang et al .",
    "@xcite containing gripper @xmath0 coordinates , gripper angle , and gripper opening for grasping an object . in our prototype , we replace those modules of our product that use information from line cameras to decide where to grip .",
    "recently several methods have been developed ( see @xcite and the references therein ) for calibrating sensors to robots . for the present prototype , we use a simplified automatic procedure for calibrating the 3d camera s",
    "@xmath1 coordinates to the gantry @xmath0 coordinates ( fig .",
    "[ fig : grippermask ] ) . the gripper s angle and opening parameters are calibrated separately using known gripper geometry parameters .",
    "coordinate of the tip of the closed gripper is detected from each position and stored with the corresponding gantry @xmath0 coordinates ( the 3d camera image and detected gripper tip for one position is shown in the image ) .",
    "a projective transformation @xmath2 is fitted to the data . ]      the 3d camera image , [ fig : linesearch ] , and [ fig : handle - evaluation ] show depth images from an earlier version of our prototype using a higher resolution industrial ensenso n20 depth sensor instead of the asus xtion that was used in the expreriments reported here . ]",
    "is projected using gpu into an isometric heightmap defined on gantry @xmath3 coordinates ( fig .",
    "[ fig : dcam - projection ] ) .",
    "the projection code marks pixels that are occluded by objects to their maximum possible heights and additionally generates a mask indicating such unknown pixels .",
    "the handle generation happens in two stages : first , we exhaustively search through all _ closed handles _ , that is , gripper configurations where each finger of the gripper touches the heightmap and the heightmap rises between the two points ( fig .",
    "[ fig : linesearch ] ) .",
    "the full set of closed handles are weighted by the sum @xmath4 + [ h(s_1 - 1\\textnormal { pixel})-h(s_1)]\\ ] ] of height differences at the gripper contact points shown in fig .",
    "[ fig : linesearch ] .",
    "a sample of 200 handles is generated using probabilities proportional to the weights .",
    "after this , each handle in the sample is duplicated for all possible extra - openings allowed by the heightmap ( taking into account the nonlinear movement of the gripper as it opens and closes ) and the maximum opening of the gripper .",
    "this completes the hard - coded stage of handle generation .    for every handle of the first stage",
    ", features are generated from the heightmap around the handle .",
    "the features are based on    * @xmath5 pixel ( @xmath6 cm ) slices of the heightmap aligned at the left finger , center , and right finger of the gripper ( including a margin of 4 cm around the rectangle inside the gripper fingers ) , * the opening of the handle and extra opening to be applied when grasping , and * the height of the handle ( which is subtracted from the heightmap slices so as to yield translation invariant features ) .    of these",
    ", the image features are further downsampled and transformed by a dual - tree complex wavelet transform @xcite to yield the inputs for a random forest that is trained to classify the handles into those that succeed and those that fail .",
    "the handle that gets the best score ( most votes from the random forest ) is chosen for picking ( except when its score is below 0.1 in which case it is only attempted with a 5% probability in order to avoid picking the empty belt for aesthetic reasons ) . when there is no trained model available , a random handle from the output of the first stage is chosen for picking .          during each picking attempt",
    ", the system monitors the gripper opening and if the gripper closes ( almost ) completely before completing the throw , it is determined that the object has slipped and the pick is aborted .",
    "this post - verification signal yields the necessary feedback for training .",
    "the features and result of each pick attempt are stored and a background process reads these training samples periodically and trains a new handle model based on all collected data .",
    "when a new model is trained , the system starts using it on the next pick attempt .",
    "the immediate feedback from failed and successful attempts allows the system to learn quickly and autonomously and to adapt to novel objects .",
    "in this experiment , the conveyor under the system was cleared for calibration , the calibration was run , and the conveyor was started at a slow constant speed . when there were objects coming under the robot ,",
    "the picking software was started .",
    "the system started picking with just the hard - coded first stage model .",
    "after every 100 pick attempts , the system trained the second - stage model using data from all pick attempts from the beginning and started using the newly trained model on subsequent picks . for technical reasons related to data collection ,",
    "the system was paused briefly every 15 minutes .",
    "the results of this experiment are shown in fig .",
    "[ fig : exper23]a .",
    "the same experiment was repeated running the training every 10 seconds .",
    "the results are shown in fig .",
    "[ fig : exper23]b . from these results , it is clear that the immediate feedback from post - verification allows autonomous learning that can be very fast .",
    "a )    b )      in this experiment , the conveyor under the system was cleared for calibration , the calibration was run , and after moving the conveyor until there were objects in the working area , the picking software was started .",
    "then , the conveyor movement was controlled manually , moving it short distances at a time , so as to let the robot pick the conveyor clean .",
    "the system started picking using just the hard - coded first stage model and the second stage model was trained on data from all picking attempts from the beginning every 10 seconds . the picking performance improved during the experiment as in the other experiments .",
    "although somewhat more pick attempts will fail than on a constantly moving conveyor , the system will retry picking any objects left on the working area until it succeeds .",
    "the accompanying video shows how , after some training , the system clears a large pile from the conveyor ( fig .",
    "[ fig : emptying ] ) .",
    "we have demonstrated a prototype system that is able to pick a pile of novel waste objects from a conveyor and which has autonomously learned to select better points to pick from .",
    "we have shown that performing this task with a 4-dof robot with a single camera not on top of the system is possible .",
    "it is easy to think of several ways to improve the performance of the system . for",
    "the picking the conveyor clean -task , simply adding better edges to the conveyor and making the working area slightly larger would help - currently the working area is very limited due to the 3d camera used .",
    "the machine learning algorithm used is very simple . enlarging",
    "the set of candidate handles could boost performance significantly and would be easy to parallelize on the gpu .",
    "it would also be possible to make the hard - coded first stage less conservative regarding shadows .    on the other hand",
    ", it would be possible to address some of the specific types of errors that were observed :    * grasping shadow : our current handle model does not make use of the mask indicating areas with unknown height ( i.e. , areas occluded by objects from the 3d camera s point of view ) ; using this information in the features would allow learning to better handle the shadows ; alternatively two 3d cameras could be used to reduce shadows * grasping at object ( corner ) that just came in range : this could be improved by additional logic to avoid handles at the edge * grasping at empty belt : when there are no objects , small variations of the conveyor height , small particles , or sensor noise may yield handles ; we have reduced such pick attempts by avoiding picking ( except by small probability ) when the score of the best handle is below certain threshold * thin objects : the postverification may yield incorrect failure signal when grasping a thin object and the system may learn to avoid picking thin objects ; this shows the importance of the feedback signal * heavy stones slipping : could use slower throw , adding throw acceleration as another degree of freedom for the generated handles .    on the other hand , with this system , the point of diminishing returns is quickly reached because the system can retry picks that failed .",
    "the difference between an 80% success rate and 90% success rate is relatively minor , as opposed to the same difference in a line scanning system where 80% would mean double the number of unpicked objects from 90% .    at the moment",
    ", the cycle time of the prototype , around 6 seconds , is a far cry from our production system s 1.8 s cycle time .",
    "however , there is no fundamental reason why such a cycle time could not be reached by this type of system ; the difference is mostly caused by the prototype being very conservative about when the images are taken and not being yet optimized .",
    "more interesting extensions of the systems in terms of practical applicability would be , e.g , learning to control the conveyor in order to maximize some function of the amount of picked material and the percentage of objects that get picked ; sorting objects by some characteristic while picking , and learning to carefully pick one object at a time . in the current setup , the last one was not a problem ; two - or - more - object picks were rare but this may be more related to the size of the objects and the gripper .",
    "the authors would like to thank the zenrobotics team of research assistants for helping in this work , especially risto sirvi for supervising many of the experiments and risto sirvi and sara vogt for annotating experiment data .",
    "the authors would also like to thank risto bruun , antti lappalainen , arto liuha , and ronald tammepld for discussions and plc work , timo tossavainen for many discussions , and risto bruun , juha koivisto , and jari siitari for hardware work .",
    "this work also makes use of the contributions of the whole zenrobotics team through the parts of our product that were reused in this prototype .",
    "t.  j. lukka , t.  tossavainen , j.  v. kujala , and t.  raiko , `` zenrobotics recycler ",
    "robotic sorting using machine learning , '' in _ proceedings of the international conference on sensor - based sorting ( sbs ) _ , 2014 .",
    "d.  rao , q.  v. le , t.  phoka , m.  quigley , a.  sudsang , and a.  y. ng , `` grasping novel objects with depth segmentation , '' in _ proceedings of the international conference on intelligent robots and systems ( iros ) _ , 2010 , pp . 25782585 .",
    "y.  domae , h.  okuda , y.  taguchi , k.  sumi , and t.  hirai , `` fast graspability evaluation on single depth maps for bin picking with general grippers , '' in _ proceedings of the international conference on robotics and automation ( icra ) _ , 2014 , pp",
    ". 19972004 .",
    "d.  holz , m.  nieuwenhuisen , d.  droeschel , j.  stckler , a.  berner , j.  li , r.  klein , and s.  behnke , `` active recognition and manipulation for mobile robot bin picking , '' in _ gearing up and accelerating cross - fertilization between academic and industrial robotics research in europe_.1em plus 0.5em minus 0.4emspringer , 2014 , pp .",
    "133153 .",
    "m.  nieuwenhuisen , d.  droeschel , d.  holz , j.  stuckler , a.  berner , j.  li , r.  klein , and s.  behnke , `` mobile bin picking with an anthropomorphic service robot , '' in _ proceedings of the international conference on robotics and automation ( icra ) _ , 2013 , pp .",
    "23272334 .",
    "y.  jiang , s.  moseson , and a.  saxena , `` efficient grasping from rgbd images : learning using a new rectangle representation , '' in _ proceedings of the international conference on robotics and automation ( icra ) _ , 2011 , pp .",
    "33043311 .",
    "v.  pradeep , k.  konolige , and e.  berger , `` calibrating a multi - arm multi - sensor robot : a bundle adjustment approach , '' in _ proceedings of international symposium on experimental robotics ( iser ) _ , 2014 , pp ."
  ],
  "abstract_text": [
    "<S> we present a research picking prototype related to our company s industrial waste sorting application . </S>",
    "<S> the goal of the prototype is to be as autonomous as possible and it both calibrates itself and improves its picking with minimal human intervention .    </S>",
    "<S> the system learns to pick objects better based on a feedback sensor in its gripper and uses machine learning to choosing the best proposal from a random sample produced by simple hard - coded geometric models .    </S>",
    "<S> we show experimentally the system improving its picking autonomously by measuring the pick success rate as function of time .    </S>",
    "<S> we also show how this system can pick a conveyor belt clean , depositing 70 out of 80 objects in a difficult to manipulate pile of novel objects into the correct chute .    </S>",
    "<S> we discuss potential improvements and next steps in this direction . </S>"
  ]
}