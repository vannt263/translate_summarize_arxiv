{
  "article_text": [
    "the major aim of neutrino astrophysics is to contribute to the understanding of the origin of high energy cosmic rays .",
    "a point - like neutrino signal of cosmic origin would be an unambiguous signature of hadronic processes , unlike @xmath0-rays which can also be created in leptonic processes .",
    "neutrino telescopes are ideal instruments to monitor the sky and look for the origin of cosmic rays because they can be continuously operated .",
    "the detection of cosmic neutrinos is however very challenging because of their small interaction cross - section and because of a large background of atmospheric neutrinos .",
    "parallel measurements using neutrino and electromagnetic observations ( the so - called `` multi - messenger '' approach ) can increase the chance to discover the first neutrino signals by reducing the trial factor penalty arising from observation of multiple sky regions and over different time periods . in a longer term perspective",
    ", the multi - messenger approach also aims at providing a scheme for a phenomenological interpretation of the first possible detections .",
    "the search of occasional flares with a high - energy neutrino telescope is motivated by the high variability which characterizes the electromagnetic emission of many neutrino candidate sources .",
    "resent results obtained by the icecube collaboration  @xcite indicate that high - energy neutrino telescopes have reached a sensitivity to neutrino fluxes which is comparable to the observed high energy gamma - ray fluxes of blazars in the brightest states ( e.g. the flares of markarian 501 in 1997  @xcite and markarian 421 in 2000/2001  @xcite ) . with the assumption that the possibly associated neutrino emission would be characterized by a flux enhancement comparable to what is observed in gamma - rays in such states ,",
    "neutrino flares could be extracted from the sample of neutrino - like events with a reasonable significance .",
    "these astrophysical neutrinos can be searched for in several ways .",
    "one of the methods for a neutrino point source search is to look for events coming from a restricted angular region , which could be identified with a known astrophysical object .",
    "finding neutrino point sources in the sky means to locate an excess of events from a particular direction over the background of atmospheric neutrinos and muons .",
    "these events might present additional features that distinguish them from background , for example a different energy spectrum or time structure . for sources which manifest large time variations in the emitted electromagnetic radiation",
    ", the signal - to - noise ratio can be increased by testing smaller time windows around the flare ( a time - dependent search ) . in principle",
    "there are two approaches to neutrino time - dependent searches :    * * triggered flare search * : looking directly for photon - neutrino correlations using specific source lightcurves from multi - wavelength ( mwl ) observations  @xcite . *",
    "* untriggered flare search * : a generalized search ( mwl data ) for neutrino flares , motivated but not associated with mwl observations , which are scarce and not available for all sources during complete periods .",
    "in addition , there could be a time lag between observed photon flares and the associated neutrino flares . in the",
    "extreme cases high energy photons could be entirely absorbed during periods of the highest photon production in the source  @xcite .",
    "this approach however entails a higher trial factor penalty than triggered flare searches . as a merit , neutrino flares which are not accompanied by observed electromagnetic counterparts",
    "are not automatically excluded .",
    "this approach is also less dependent on models for the correlation between the neutrino and the electromagnetic emission and not dependent on the availability of multi - wavelength information .    here",
    "we develop a method that is well suited for an intermediate approach in which `` periods of interest '' can be a priori selected on the basis of multiwavelength data .",
    "the neutrino sample can then be scanned looking for significant structures , in a way which is less dependent on models predicting different correlations with a given wavelength .",
    "an untriggered unbinned flare search was first developed and applied to icecube data , using a compact list of pre - defined source directions  @xcite . a time - clustering algorithm",
    "@xcite , and the unbinned maximum likelihood method  @xcite are the basis of this analysis .",
    "such a method finds the most significant flare in a long period .",
    "the number of trials coming from all combinations of event times is increased , reducing the significance . however , for flares sufficiently shorter than the total observation period , the time clustering algorithm is more sensitive than a time - integrated analysis .    in this paper , we propose an extension of the method described in  @xcite . by including in the likelihood a signal term",
    "which describes the contribution of many small clusters of signal - like events , our algorithm can extract not only the most significant flare , but also less significant clusters of events distributed over weak flares .",
    "these weaker flares could be separated by any distance in time and will be very difficult to detect or even can not be detected with other methods  @xcite .",
    "the paper is structured as follows .",
    "the algorithm is described in section 2 . in section",
    "3 we apply the method to a simulated neutrino search for one flare and a few weak flares separated in time . a short discussion about the algorithm performance is presented in section 4 .",
    "conclusions are given in section 5 .",
    "in this section , we first describe the time - clustering algorithm , then we shortly recall the unbinned maximum likelihood method  @xcite and finally we propose our new algorithm .          the time clustering algorithm  @xcite selects the most significant cluster of events in time and returns the mean time and width of the corresponding flare",
    "the basic idea is shown in figure  [ figure1 ] . in a first step ,",
    "the method selects the most promising flare candidates over different time windows ( @xmath1 ) , which are given by the combination of the times of signal - like events from the analyzed data set .",
    "a signal - like event is defined as having @xmath2 , where @xmath3 and @xmath4 is the background and the signal probability density function ( pdf ) as defined for the time - integrated method  @xcite , only the spatial and energy terms in the pdf s are included . ] .",
    "each combinations of these event times defines the start and end time ( @xmath5 and @xmath6 ) of a candidate flare time window ( @xmath7 ) . for each @xmath1 , a significance parameter ( the test statistic ) @xmath8",
    "is then calculated as defined in  @xcite .",
    "larger values of @xmath8 correspond to data less compatible with the null hypothesis ( i.e. zero expected signal events in the data sample tested ) . finally , the algorithm returns the best @xmath8 , @xmath9 , corresponding to the most significant time window over the entire data period analyzed .",
    "the unbinned maximum likelihood method  @xcite defines the test statistic parameter by : @xmath10 , \\label{lambda2}\\ ] ] where @xmath11 is the source location , @xmath12 and @xmath13 are the best estimates of the number of signal events and source spectral index , respectively , which are found by maximizing the likelihood @xmath14 :    @xmath15    where @xmath16 is the number of all events in the data sample .",
    "the background pdf is given by : @xmath17 where @xmath18 describes the space distribution of events at a given region of the sky with the solid angle @xmath19 , @xmath20 is the energy distribution and @xmath21 describes the background time distribution .",
    "these pdfs can be calculated purely from data .",
    "in general , due to analysis cuts , earth absorption effects and the detector geometry , the spatial probability @xmath22 and the energy probability @xmath20 depend on zenith , @xmath23 , and azimuth , @xmath24 .",
    "the time probability @xmath25 is defined by : @xmath26 where @xmath27 is a normalization constant for the whole data taking period .",
    "the properties of signal events are taken from a dedicated monte carlo ( mc ) signal simulations .",
    "the signal pdf , @xmath28 is given by : @xmath29 where the spatial probability @xmath30 is a gaussian function of @xmath31 , the space angular difference between the source location @xmath11 and each event s reconstructed direction @xmath32 , and @xmath33 the angular error estimate of the reconstructed track .",
    "the energy probability @xmath20 , constructed from signal simulation , is a function of the event energy estimator @xmath34 , the zenith coordinate @xmath23 , and the assumed energy spectral index of the source @xmath35 ( such that @xmath36 ) .",
    "@xmath21 is the time probability which generally is a constant value ( i.e. taken to be uniform in time ) if no flare structure is assumed . for each time window",
    "tested ( @xmath37 ) , the time probability is given by : @xmath38 where @xmath39 is the arrival time of the @xmath40 event and @xmath41 is the heavyside step function .",
    "note , that by using this definition for the time probability in the likelihood @xmath14 , we count only events which fall inside the current time window @xmath42 ( i.e. the signal pdf @xmath28 is zero outside the selected time window ) .",
    "as shown in  @xcite the unbinned likelihood method will preferentially find shorter flares , making it less powerful for flares of durations longer than roughly one day .",
    "the solution to this problem is to use a marginalization term @xmath43 in the likelihood @xmath14  @xcite .",
    "this gives a more uniform exposure to find flares of different widths and leads to a redefinition of the test statistic : @xmath44 .",
    "\\label{lambda3}\\ ] ]      we propose here some extensions to the above mentioned procedures to identify a series of weak flares by incorporating this information into the likelihood function .",
    "this is done by restricting the search to doublets of signal - like events , and using the value of the test - statistic of these individual flare candidates as their weights in a stacking - like calculation of the global maximum likelihood .",
    "first , we extract all doublets that can be formed out of all signal - like events ( @xmath45 ) over the entire data taking period @xmath27 .",
    "this step serves to isolate all possible ( and smallest ) time windows that compose the signal contribution in the tested data sample ( the total number being @xmath46 ) .",
    "we call these time windows `` data segments '' . note , that by construction , there could be a certain degree of overlap between different data segments if larger event multiplicity will be studied , see figure  [ figure2 ] top .",
    "the choice of doublets is physics - motivated , because for a neutrino detector like icecube , the signal expectation is not much more than a few signal neutrinos per year from the strongest astrophysical sources  @xcite .",
    "moreover , we focus on weak multiple flares .",
    "then for each time window @xmath1 a minimization of @xmath47 as defined in eq .",
    "( 2 ) is performed , with @xmath48 and @xmath49 as free parameters , and the individual test statistic @xmath50 is calculated .",
    "this step serves to estimate the possible signal contribution in each data segment .",
    "all time windows are then sorted according to @xmath50 , as it is shown in figure  [ figure2 ] ( middle ) .",
    "some of these data segments will contain real signal events and some of them are likely due to background fluctuations .",
    "our aim is to extract the optimal ( best suited ) number of data segments ( @xmath51 ) which compose the total signal contribution injected in the overall period @xmath27 .    for this purpose ,",
    "we propose a modification of the single - source likelihood function ( eq.(2 ) ) by including a signal term ( @xmath52 ) describing the contribution of each data segments : @xmath53 where @xmath54 is the number of data segments in to which the overall signal contribution can be decomposed ( a free parameter @xmath55 ) and @xmath16 is the total number of events in the time period @xmath27 .",
    ". some of these segment will include signal contribution , others background fluctuations only ; middle : sorted values of the test statistic for each data segment from a maximization of the likelihood in eq .",
    "( 2 ) as a function of the data segment index @xmath54 .",
    "bottom : evolution of the test statistic from a maximization of the likelihood in eq .",
    "( 8) as a function of the number of data segments being stacked following eq .",
    "the maximum value of this parameters defines the optimal number of data segments to be stacked @xmath51.,scaledwidth=45.0% ]    in other words , in order to include the contribution to the signal from multiple flares , the one - source signal term @xmath3 is being replaced by the sum of signal sub - terms over @xmath54 data - segments : @xmath56 where @xmath57 is a weight which describes the strength ( significance ) of the doublet contained in each data segment .",
    "this weight should be proportional to the expected number of neutrino events seen in the detector . as we will show later",
    "the test statistic is quite well correlated with the true number of injected signal events .",
    "thus we take @xmath58 .    the likelihood given in eq .",
    "( [ llh_unbinned2 ] ) in combination with eq .",
    "( 9 ) is usually used in stacking searches for different types of astrophysical point sources  @xcite , but here the individual sources are data segments of the signal - like events found in the data from the same object .",
    "the stacking method uses the fact that signal and background increase differently when observations for multiple sources ( or flares ) are being added . stacking multiple flares",
    "can therefore suppress the overall background and hence can increase the signal sensitivity .    in order to estimate the optimal number of data segments @xmath51 for a given number of @xmath54 segments ( starting from @xmath59 ) we minimize the @xmath60 with @xmath61 and @xmath35 as free parameters .",
    "the minimization returns the best estimates for the number of signal events @xmath62 and for the spectral index of the source @xmath63 , and the `` global '' test statistic is calculated from :    @xmath64 . \\label{lambda}\\ ] ]    then , the optimal number of data segments to be stacked ( @xmath51 ) is chosen according to the maximum of @xmath65 ( see figure  [ figure2 ] bottom ) . as a result ,",
    "the following important parameters are extracted :    * @xmath51 : the optimal number of segments which compose the signal contribution over the time @xmath27 .",
    "the optimal set could be either subsequent in time , forming one significant cluster of events ( one flare ) for a given source location , or theses segments can be distributed among a few ( sometimes less significant ) flares separated in time .",
    "this is shown in figure  [ figure2 ]  ( top ) .",
    "* @xmath62 : the total number of expected signal events summed over the @xmath51 individual segments .",
    "* @xmath66 : the spectral index of the source ( the flare ) , assumed to be the same for each @xmath51 segments .",
    "* @xmath67 : the maximum value of the test statistic calculated with the modified likelihood function of eq .",
    "( [ lambda ] ) .",
    "* @xmath68 : the flare duration calculated for @xmath51 segments .",
    "this is here defined as the time between the start time of the first data segment and the end time of the last data segment .",
    "the overall significance of the optimal configuration @xmath51 can be determined using mc simulations by applying the same procedure to a large number of simulated data samples .",
    "this will automatically account for effects of trial factors .",
    "the trial factors arise from testing different time windows for the same source direction . in order to represent a background - only observation ,",
    "the properties of the data events ( e.g. zenith , azimuth , time , reconstruction error and energy estimator ) are sampled from their distributions .",
    "data of neutrino experiments with a signal flux can be simulated by injecting signal events on top of the background data .",
    "the method described in section  2 has been applied to 10,000 mc background samples ( scrambled sky maps ) .",
    "background events were randomly chosen reproducing realistic pdf s ( energy , angular resolution ) extracted from  @xcite .",
    "more precisely , the number of background events in a given declination band ( @xmath69 ) is estimated from @xmath70 , where @xmath71 is the number of background events in a bin and @xmath72 and @xmath73 are the solid angles of the band and bin , respectively .",
    "assuming @xmath74 background events for declination @xmath75 as in  @xcite and @xmath76 days we are left with 355 events distributed in a declination band of size @xmath77 .",
    "the angular reconstruction error @xmath33 of each event was generated based on the cumulative spread function from  @xcite with a median resolution of about @xmath78 and assuming that @xmath79 does not depend on the energy of the reconstructed event .",
    "this assumption in general may not be true , but it wo nt affect the results of this test .",
    "the same number of scrambled maps were generated for signal events injected on top of the background ( mc background plus signal simulations ) .",
    "a neutrino point source at declination @xmath80 was considered .",
    "signal events were injected around this declination @xmath81 along a band @xmath82   and with azimuth randomly chosen from @xmath83 to @xmath84 .",
    "individual event directions were smeared according to the point spread function ( psf ) from  @xcite with a median angular resolution of about @xmath78 .",
    "we simulate signal strengths following poisson statistics with mean values of 4 , 8 , 9 and 12 signal events .",
    "the energy pdf follows what was found for an @xmath85 energy spectrum in  @xcite . for each mc signal sample ( scrambled sky map ) , signal events were randomly injected inside a time window defined by various flare durations , in the range from 0.01 day to 30 days .",
    "the most of the results presented in this paper was obtained considering a total period of @xmath76 days .",
    "this is motivated by the fact that an obvious application of this method is to test periods of interests , preselected with the help of multi - wavelengths data .",
    "we tested the method for the three following cases which are also illustrated in figure  [ figure3 ] .",
    "* * example  1 * : signal events ( with poisson - mean=8 ) are injected inside a 9 days time window . the starting point of the flare is randomly chosen over a data taking period @xmath27 of @xmath86 days .",
    "an example of a physics case corresponding to this configuration is the reported @xmath0-ray flare from the crab nebula  @xcite , @xcite , @xcite .",
    "note , that this case would correspond to a rather  strong  flare .",
    "as we can see for example from  @xcite , the number of events required for the discovery of such a flare is larger than 7 in case of a search with an unknown burst duration .",
    "* * example  2 * : the total number of signal events ( poisson - mean=8 ) is the same as in example  1 , but individual events are injected over two time windows of duration 4.5 and 9 days , respectively and 22 days apart .",
    "the average number of injected signal events is the same for each flare ( poisson - mean=4 ) .",
    "the expected number of events required for the discovery depends on the flare duration and it is smaller for the flare with shortest duration . in other words",
    "we can think of this example as a case with a `` strong '' flare and one weaker flare .",
    "these two flares are separated in time , but they can also be treated as one long period of enhanced emission with a duration about of 35 days .",
    "standard point source search methods applied to this case will find only the strongest flare i.e. the first one .",
    "this is because standard methods use the one - source likelihood function given by eq .",
    "( [ llh_unbinned ] ) and can look only for a minimum corresponding to the most significant cluster of events from a given source location . *",
    "* example  3 * : the total number of signal events ( poisson mean=8 ) is the same as in previous examples , but individual events are injected over three time windows with duration of 4.5 days , 4.5 days and 9 days , respectively .",
    "each flare is simulated with a similar strength with poisson - mean 3 , 3 and 2 , respectively .",
    "this example describes three `` weak '' flares .",
    "note that the number of events required to claim discovery for each of them at a @xmath87 level is larger than 4 , as we can see from @xcite   the standard deviation is defined according to @xmath88 with @xmath89 denoting the standard deviation of the gaussian distribution .",
    "thus 4.5 and 9 days width of the flare corresponds to @xmath90 about 1.3 and 2.6 days or to 0.0035 and 0.0070 year , respectively .",
    "thus for the flare with a gaussian mean time @xmath91 we need about 4 events for discovery using the method labeled by `` assumed burst time ( energy ) '' in figure 4 of @xcite . ] . in other words such individual weak flares can not be found at a @xmath92 level by the standard point sources search methods .      in figure  [ figure4 ] the distribution of the most important parameters i.e. the number of signal events @xmath12 , the spectral index @xmath66 and the optimal number of data segments ( i.e. signal - like doublets ) @xmath93 and their correlations as obtained by mc simulations are presented for the background - only simulations and the background plus signal cases .",
    "the number of injected signal events follows a poisson distribution with a mean of 8 .",
    "events are injected over a time window of 9 days duration .",
    "the pure background case illustrates how signal - like flares can be mimicked by pairs of events ( sometimes also triplets ) distributed over very short time windows with durations of less than a day .",
    "the signal plus background plots show that the proposed method finds the right flare i.e. it recovers the true values of the spectral index ( 2 ) , the number of injected signal events ( poisson - mean 8 events ) and the flare duration   ( 9 days ) .",
    "in addition , the flare can be decomposed into about 8 data segments , see figure  [ figure4 ] ( d ) .         in figure",
    "[ figure5 ] ( a ) the correlation of the global test statistic @xmath67 as a function of the number of injected signal events @xmath94 is shown .",
    "the solid line represents a linear fit to the mean values of the test statistic calculated for a fixed number of injected signal events .",
    "a linear correlation is found between the test statistic and number of injected signal events .",
    "this justifies using the test statistic as a weight in the modified likelihood @xmath95 of eq .",
    "we also checked the results obtained when all weights are fixed to one as well as to the square of the test statistic .",
    "we find that such modifications lead to slightly worse results i.e. we observed a 5 - 10% worse agreement between the true and the estimated values of @xmath62 and @xmath96 .    in figure  [ figure5 ] ( b )",
    "the number of signal events is shown as a function of the optimal number ( @xmath51 ) of data segments which compose the flare . as expected , the number of signal events increases when more segments are being added .",
    "the distribution shows a maximum corresponding to the true number of injected signal events ( the true poisson - mean of 8) .",
    "the inset in figure  [ figure5 ] ( b ) shows the gaussian fit to the estimated number of signal events , @xmath12 with a mean value of 8.2 , which is good agreement with the true value at a level of about 2.5% .",
    "the proposed algorithm can therefore recover the most important parameters characterizing flares , like the duration , the source spectral index and the number of injected signal events with uncertainties not larger than a few percent . in other words",
    "the proposed algorithm can  decompose the flare into small data segments which contain signal - like doublets and can effectively reject background events from the entire data period .                      in figure  [ figure6 ]  ( a ) we show the distribution of the optimal number of data segments @xmath51 as a function of the corresponding flare duration @xmath97 as defined in section 2.3 . in figure  [ figure6 ]",
    "( b ) the best fit spectral index @xmath66 is shown as a function of the estimated number of signal events @xmath12 . also in this case the proposed algorithm recovers the overall flare duration , the source spectral index and the number of injected signal events .",
    "however , for this particular case , the differences between the true and the estimated values of the physics parameters obtained from the minimization are slightly worse ( about @xmath98 ) .",
    "this is because for the larger flare durations we should expect a larger contamination of background events .    in figure  [ figure6 ] ( c ) the distribution of the mean time @xmath99 calculated for each ( @xmath100 )",
    "signal - like doublet is shown .",
    "an accumulation of signal - like doublets for a time period below 5 days and between 25 and 35 days is visible , corresponding to the first and the second flare , respectively .",
    "the proposed algorithm can therefore find not only the most significant flare , but also the weaker one separated in time .",
    "such a flare would not be detected by other existing methods ( like  @xcite ) .                     by repeating the minimization with the modified likelihood @xmath95 for a fixed number of @xmath54 data segments _ sorted in time _",
    "( starting from @xmath59 and ending with @xmath101 ) , we can get more information about the  internal  structure of the flare .",
    "for example , in figure  [ figure6 ] ( d ) changes of the global test statistic as a function of the flare duration @xmath102   of data segments , the flare duration is defined as the time between the start time of the first in time data segment and the end time of the last data segment . ] calculated for @xmath103 data segments is shown .",
    "the test statistic increases when more segments are added in time , but finally reaches a saturation for the time corresponding to the overall period of enhancement emission ( 35 days ) .",
    "this behavior is strongly correlated with the distribution presented in figure  [ figure6 ]  ( c ) .",
    "for the first flare ( below 5 days ) and second flare ( from 25 to 35 days ) the increase of the global test statistic in time is much larger than during the period corresponding to the 22 days time gap . during this last period",
    "larger variations can also be observed , which is an indication for background fluctuations .",
    "a similar behavior is seen for the average number of signal events @xmath104 as a function of the flare duration ( figure  [ figure6 ]  ( e ) ) .",
    "note that both distributions presented in figure  [ figure6 ]  ( d ) and ( e ) are averaged over different mc realizations .",
    "for completeness , figure  [ figure6 ]  ( f ) shows the average spectral index @xmath105 for a large number of different mc realizations as a function of time .",
    "the average best fit spectral index is about 2.2 and differs by about 8.5% from the true value ( @xmath106 ) .",
    "similarly to the previous distributions , the fluctuations of the spectral index are strongly reduced during the periods corresponding to the injected signal .",
    "the effect is particularly visible for the second flare , between 25 days up to 35 days .",
    "we conclude that the proposed algorithm can recover the global parameters describing the flares and provide additional information about the time development , their duration and the number of signal events per individual flare , even when they alone are below the threshold for detection .",
    "in this case we simulated three individual weak flares .",
    "each flare can not be individually detected at a @xmath92 level by using the standard point source search methods . in principle , if all events could be injected into a single flare of duration about 28 days ( @xmath107 year ) the algorithm proposed in  @xcite would yield a discovery . for a flare of such a duration ,",
    "more than about 7 events are needed for discovery at a @xmath87 level using the method labeled by assumed burst time ( energy ) in figure  4 of  @xcite .",
    "however , the flare will be found only if these 7 events will form _ one cluster of events compact in time_. this is because the unbinned maximum likelihood method with a single - source likelihood function can only search for a maximum which corresponds to the most significant flare ( cluster of events ) from a point source .",
    "this is certainly not the case for this example , where 8 events are distributed among three individual and well separated flares .",
    "thus , such a structure can not be detected at @xmath92 level by the standard method .",
    "figure  [ figure7 ] ( a ) and ( b ) show that also in this case the method can recover the true values of the spectral index ( @xmath108 ) , the mean number of injected signal events ( 8) and the total flare duration ( 28 days ) .",
    "in addition , the overall signal injection can be decomposed into about 8 data segments ( doublets ) . sorting these data segments in time we obtain the distribution _ of individual flares _ in time as shown in figure  [ figure7 ] ( c ) .",
    "three flares can be clearly distinguished , with a duration of about 5 days , 5 days and 10 days , respectively .",
    "the average value of the test statistic and the average number of signal events from the best fit ( of the likelihood @xmath95 ) is presented in figure  [ figure7 ]  ( d )  and  ( e ) .",
    "we observe a similar behavior as in the example  2 .",
    "however , due to a smaller time gap between individual flares , a factor 4 smaller than for the flares studied in the example  2 , the structures are less pronounced . note that the distributions presented in figure  [ figure7 ]  ( d ) and ( e ) start to saturate at a point corresponding to the overall period of enhancement emission ( above 28 days ) .",
    "finally , in figure  [ figure7 ] ( f ) the average spectral index @xmath109 as a function of time is shown .",
    "the source spectral index has a value of about 2.2 and differs by about 10% from the true value ( @xmath106 ) .",
    "fluctuations of the spectral index also increase for times greater than the total flare duration ( above 28 days ) .",
    "this example demonstrates that the proposed algorithm can find a few weak flares separated in time , which can not be found by other standard methods  @xcite .",
    "in this section we calculate the number of events needed for discovery ( i.e. the discovery potential ) for the cases of example  1 , 2 and  3 and for different flares durations @xmath97 and overall data periods @xmath27 .",
    "the discovery potential is defined as the average number of signal events required to achieve a p - value less than @xmath110 ( one - sided @xmath92 ) in 50% of the trials .",
    "the comparison below gives us an idea about the performance of the proposed method and its limitations .         in figure  [ figure8 ]",
    "we show the distribution of the global test statistic @xmath67 for mc background - only simulations ( a ) and for mc background - plus - signal simulations ( b ) , with signal events distributed according to a poisson distribution with mean 4 , 8 and 12 ( the case of example  1 : one flare with duration 9 days ) . from figure  [ figure8 ]  ( a )",
    "we can estimate the @xmath111 threshold for a @xmath112 execss in the background only case , which is 101 .",
    "the @xmath92 threshold was calculated for a band of @xmath77  ) does not show changes in the @xmath92 threshold . ]",
    "centered at declination @xmath80 and for an overall data period of @xmath76 days . from figure  [ figure8 ]  ( b )",
    "we can see that this threshold is passed in 50% of trials when the average number of added signal events is 8 .",
    "the discovery potential is therefore about 8 events .    in figure  [ figure9 ]  ( a ) the global test statistic distribution for the case of example  1 , 2  and  3",
    "the median is 101 , 96 and 91 , respectively , which means that the number of events required for discovery ( assuming a threshold of 101 ) is @xmath113 , @xmath114 and @xmath115 .",
    "note that we have a similar number of events required for discovery for example 2 and example 3 in which signal events are injected over a few flares , but such cases can not be tested with the method presented in  @xcite .    in figure  [ figure9 ]  ( b ) the discovery potential as a function of different overall data periods is shown .",
    "the number of events required for discovery as expected depends on the overall data period @xmath27 considered .",
    "this is because the number of signal - like events increases with time and therefore also leads to a higher @xmath87 threshold .",
    "for example , for an overall data period of @xmath86 days the average number of signal - like events is 5 , while it is 43 for a data period of @xmath116 days .",
    "such changes in the number of signal - like events lead to an increase of the @xmath92 threshold from 101 to 180 . as a consequence",
    "the number of events needed for discovery increases by about 63% , from 8.0 up to 13 for a flare with a duration of 9 days . comparing with the results presented in  @xcite where we need about 9 events for discovery for a method using unknown burst time with energy pdf and one year data period ( figure  4 in  @xcite ) , we see that our method requires about 44% more events for discovery in case all events are injected in one single flare ( example 1 ) .",
    "this is because our algorithm stacks also background fluctuations , and thus leads to a higher @xmath87 threshold than the threshold obtained by a single - source likelihood based method .",
    "however , it must be noticed that this comparison is only qualitative , since the signal - to - background ratio , which reflects the detector efficiency and signal properties used in both simulations , is different in the two cases .",
    "a more quantitative comparison of both two methods has to be achieved on the same simulated data set . as we also expect , the number of events needed for discovery decreases , when we consider flares with shorter duration .",
    "for example , for a flare with duration of 30 days , 1 day , 0.1 day and 0.01 day in average about 9 , 6 , 5 and 4 events are needed for discovery within @xmath76 days . note that in this case for flares with shorter duration ( below 0.1 days ) the number of events is smaller than the number of events for a time - integrated analysis , see figure  [ figure9 ]  ( b ) for the method labeled `` time integrated analysis ( energy+space ) '' .    in figure  [ figure9 ]  ( b )",
    "the results of calculations for conditions of example 2 and 3 are also shown .",
    "in general , we see a similar trend i.e. the number of events needed for discovery increases when a larger overall data period is studied .",
    "it is also seen that for example  2 the number of events for discovery is smaller than for a single flare with similar duration .",
    "however , care must be taken in such a comparison because , as we already pointed out before , multiple combinations of individual flares can not be found by the standard point source search algorithm as proposed in  @xcite .",
    "this is especially true for example  3 . in other words ,",
    "the performance of the method improves when we study more flares distributed in time , especially if they are weak .    up to now",
    "we also do not exploit the fact that the algorithm provides us information about the number of individual flares distributed in time or even about the number of data segments which compose one flare or a few individual flares separated in time .",
    "using such information , we can calculate a better sensitivity . by dividing the sensitivity by the number of flares or data segments @xmath51",
    ", we can calculate a sensitivity per individual flare or even per segment . for examples presented here ( which correspond to signal - like doublets )",
    "the number of @xmath51 is about 8 and the number of individual flares is larger than 1 , hence the sensitivity can be improved by about the same factor .",
    "we have presented a method to search for neutrino flares from point sources without an a priori assumed time structure .",
    "the method considers only data segments which contain signal - like doublets , and uses a test - statistic term as their weights in a stacking - like calculation for the global maximum likelihood .",
    "we have shown that this method can recover the true values of the source spectral index , the flare duration , and the total number of injected signal events within uncertainties not larger than 10% .",
    "in addition , our algorithm provides relevant physics information about the distribution of flares in time and their internal structures .",
    "this information can be used to calculate a sensitivity per individual flare , which is usually better than the sensitivity obtained from the other methods .    for standard cases ( one  strong  flare ) , the discovery potential of the method is about 44% worse than the standard point source analysis with unknown duration of the flare .",
    "this is because our method stacks all significant background fluctuations in a given period of data and leads to a higher threshold for discovery .",
    "however even in such a case , the number of events required for discovery is smaller compared to a time - integrated search as soon as the flare duration is less than a few hours . when the number of individual flares analyzed is increased the number of events needed for discovery decreases , especially in the case of a few weak flares distributed over a longer period ( from a few days up to 100 days ) .",
    "such cases of a few weak flares can not be discovered by the standard point search algorithm  @xcite .",
    "we would like to thank a. kappes and c. spiering for useful discussions .",
    "we acknowledge the support from the young investigators program of the helmholtz association ."
  ],
  "abstract_text": [
    "<S> a method for a time - dependent search for flaring astrophysical sources which can be potentially detected by large neutrino experiments is presented . </S>",
    "<S> the method uses a time - clustering algorithm combined with an unbinned likelihood procedure . by including in the likelihood function a signal term which describes the contribution of many small clusters of signal - like events </S>",
    "<S> , this method provides an effective way for looking for weak neutrino flares over different time - scales . </S>",
    "<S> the method is sensitive to an overall excess of events distributed over several flares which are not individually detectable . for standard cases ( one flare ) </S>",
    "<S> the discovery potential of the method is worse than a standard time - dependent point source analysis with unknown duration of the flare by a factor depending on the signal - to - background level . </S>",
    "<S> however , for flares sufficiently shorter than the total observation period , the method is more sensitive than a time - integrated analysis .    </S>",
    "<S> ss    neutrino , time - dependent searches , neutrino experiments </S>"
  ]
}