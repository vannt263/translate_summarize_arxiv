{
  "article_text": [
    "with fast - growing computer technology , monte carlo ( mc ) simulations have with much success been used to study various statistical systems including neural networks , problems in biology and chemistry , lattice - gauge theories and optimisation problems in various areas , not to mention statistical physics , to study the properties of phase transitions and critical phenomena .",
    "most mc simulations concentrate on importance sampling for the canonical or microcanonical gibbs ensemble , introduced by metropolis _",
    "et al _ @xcite .",
    "the thermodynamic average , @xmath0 , of an observable @xmath1 can be estimated @xcite as @xmath2 where @xmath3 represents a configuration at time @xmath4 of a system with hamiltonian @xmath5 , @xmath6 is the inverse temperature ( with boltzmann constant @xmath7 ) , @xmath8 an averaging time ( with @xmath9 ) , and @xmath10 a sampling probability .",
    "if @xmath10 is chosen to be constant , very few samples contribute significantly to the sums in the above equation , and a very long time is required to get a reasonable estimate of @xmath0 .",
    "importance sampling comes in if one chooses @xmath10 as the boltzmann weight @xmath11 .",
    "it is generally a good sampling algorithm , but can fail to access all the parts of the phase space in available computer time . indeed , in many situations , this approach or similar ones face severe ergodicity problems if there exist many high barriers between all the possible lowest- ( or nearly - lowest- ) energy configurations , as , e.g. , in certain lennard - jones systems ( see , e.g. , @xcite ) and in spin glasses ( see , e.g. , @xcite ) , to cite only two examples from statistical physics .    to overcome these , at least for a large part , it has been suggested that it could be more efficient to reconstruct the gibbs ensemble from a simulation with other ensembles ( e.g. , a so - called `` multicanonical mc simulation '' ) than to simulate it directly ( see @xcite and references therein ) .",
    "one of these approaches goes under the name of the _ entropy sampling monte carlo method _ ( esmc ) .",
    "it works as follows .",
    "let the probability of occurence of a configuration @xmath12 with energy @xmath13 be denoted as @xmath10 , and the probability of occurence of a state with energy @xmath13 as @xmath14 .",
    "the term `` state '' stands here for the set of all configurations that have the same energy .",
    "they are related to each other through @xmath15 where i have introduced the entropy , @xmath16 , of the state with energy @xmath13 .",
    "their number is @xmath17 . in the metropolis mc method @xcite ,",
    "the canonical distribution of states is obtained , along with ergodicity , by a markovian sequence in which the transition probabilities , @xmath18 and @xmath19 , between a pair of configurations @xmath12 and @xmath20 are determined by the _ detailed balance _",
    "condition @xmath21}{\\exp[-\\beta e(x)]}\\,\\ , .\\ ] ] it can be shown rigorously that , in the case of a traditional mc simulation , this condition ensures a simulation of the system with an equilibrium distribution which is just the gibbs distribution @xcite .",
    "the esmc method is , however , based on the probability distribution of states , in which the probability of occurence of a configuration with energy @xmath13 is proportional to the exponential of the _ negative _ entropy , @xmath22 in a esmc simulation the probability of occurence of a configuration with energy @xmath13 is therefore anti - proportional to the number of configurations with that energy . in this way , the probabilities of occurence of all states equal the same constant .",
    "an mc algorithm that does the job is one that is based on the detailed balance condition @xmath23}{\\exp[-s(e(x))/k]}\\,\\ , .\\ ] ] in all other aspects , the formalism of the esmc procedure follows then the usual metropolis procedure .",
    "it is therewith easy to show ( using the methods exhibited , e.g. , in @xcite ) that the esmc algorithm simulates the system in such a way that all states occur with the same probability .",
    "hence , the algorithm provides for a ( one - dimensional ) _ random walk through the system s energy space_.    in this spirit , monte carlo sampling with respect to unconventional ensembles has received some attention ( see , e.g. , @xcite and references therein ) in recent years . in the `` multicanonical ensemble ''",
    "approach @xcite , one samples configurations such that the exact reconstruction of canonical expectation values becomes feasible for a desired temperature range .",
    "multicanonical and related sampling has allowed considerable gains in situations with `` supercritical '' slowing down , such as ( i ) first order phase transitions @xcite ( for a recent review see , e.g. , @xcite ) , ( ii ) systems with conflicting constraints , such as spin glasses @xcite or proteins @xcite .",
    "the reconstruction of canonical expectation values requires knowledge of the entropy values of the / an important part of the energy range ( see equation ( [ erg ] ) ) , but leaves innovative freedom concerning the optimal shape @xcite .",
    "considerable practical experience exists only for algorithms where one samples such that ( a ) the probability density is flat in a desired energy range @xmath24 , and ( b ) each configuration of fixed energy @xmath13 appears with the same likelihood . it should be noted that condition ( b ) is non  trivial . a simple algorithm @xcite exists to achieve ( a ) , but which gives up ( b ) .",
    "exact connection to the canonical ensemble is then lost .",
    "such algorithms are interesting particularly for hard optimisation problems , but may be unsuitable for canonical statistical physics .",
    "the present paper focuses on achieving ( a ) and ( b ) . to achieve a flat energy distribution , the appropriate unnormalised weight factor in equation ( [ erg ] )",
    "is @xmath16 .",
    "however , before simulations , the entropy function @xmath16 is usually not known . otherwise we would have solved the problem in the first place . presumably , reluctance about simulations with an a  priori unknown weight factor is the main reason why the earlier umbrella sampling @xcite never became popular in statistical physics .    in the more recent papers [ 930 ]",
    "it has been suggested to overcome this loophole by simulating with approximate entropy values , obtained by guessing or a short gibbs run , and then successively simulating with ever better estimates of the real entropy .",
    "the underlying assumptions have , however , up to now never been shown to hold rigorously , nor is there anything known on convergence properties .",
    "in this paper i propose an algorithm from which the entropy can be obtained in the large - time limit without attention `` by hand '' .",
    "i have applied the algorithm to the infinite - range , the two - dimensional and the three - dimensional ferromagnet , spin glass , and for the search of the global minimum of the generalisation error in some on - line learning model which exhibits local minima besides a global one . in this letter , however , for illusatration and brevity , i concentrate mainly on the infinite - range ferromagnet . for definiteness",
    ", i will formulate the algorithm for ising spin systems , containing a total number of @xmath25 spins .",
    "i will enumerate the different states of the system by their energy , going from smallest to largest in value .",
    "let @xmath26 denote the energy of the state with label @xmath27 , say @xmath28 ( so that @xmath29 is the total number of energy levels ) .",
    "let furthermore @xmath30 be the ( estimated ) entropy of the state with label @xmath27 , at time @xmath31 . at time @xmath32 ,",
    "i initialise @xmath33 for all @xmath27 .",
    "we will see below that only entropy differences matter in the algorithm so that the initialisation constant can in principle be chosen arbitrarily .",
    "the initialisation to zero is , however , preferable in the actual implementation of the algorithm on a computer , as mentioned below .",
    "the _ free energy monte carlo _ ( femc )",
    "algorithm then works as follows .",
    "let us assume that , at time @xmath31 , the system is in configuration @xmath12 , with energy @xmath34 , i.e. , with label @xmath35 .",
    "then , go through the following steps at time @xmath36 :    1 .",
    "select one spin index @xmath37 for which the spin @xmath38 is considered for flipping ( @xmath39 ) .",
    "2 .   calculate the transition probability @xmath40 to pass from configuration @xmath12 to configuration @xmath20 which is obtained from @xmath12 by effectuating the considered spin flip .",
    "[ in this present form the algorithm is still rather an `` entropy monte carlo '' than a `` free energy monte carlo '' algorithm ; i will dwell on the full version of the latter below . ]",
    "draw a random number , @xmath41 , uniformly distributed between zero and one .",
    "4 .   if @xmath42 , flip the spin , otherwise do not flip it . in any case ,",
    "the configuration of spins obtained at the end of step 4 .  is counted as the `` new configuration '' , @xmath43 .",
    "now update the values of the entropy ( @xmath44 ) : @xmath45 where @xmath46 is a pre - chosen positive function which is sufficiently small in the large - time limit , @xmath35 the label of energy of the configuration @xmath12 , and @xmath47 denotes the kronecker symbol .",
    "go to 1 . or end .",
    "let us just note here that by the choice of @xmath48 as above , i ensured that the simulation verifies a detailed balance condition `` locally '' , i.e. , at every time step .",
    "furthermore , it can be proven @xcite that the algorithm converges indeed towards the entropy function of the system in the infinite - time limit .",
    "let us finally note that a fter every time step , one should imagine , using equation ( [ step5 ] ) , that the `` zero '' ( baseline of the entropy values ) has been shifted upwards .",
    "the entropy may then be obtained as a time average over instantaneous entropy values , and normalising these values with the help of the total number of configurations , @xmath49 .",
    "the above version of the algorithm does not deserve to be called an femc algorithm just yet , as only the entropy enters .",
    "however , if one wants to detect the minima ( or maxima ) in the energy space , it may be useful to change the transition probability of the algorithm to read : @xmath50 where now the transition probability does not depend solely on ( instantaneous ) entropy differences , but on ( instantaneous ) _ free energy _ differences , @xmath51 being the `` inverse temperature '' as usual .",
    "if @xmath51 is large , the temperature is small , and the system stays preferably in configurations with low energy ( if one were to take @xmath51 small or even negative ( ! ) one stays obviously preferably in configurations with high energy ) .",
    "this can be illustrated in particular at the beginning of the algorithm , when the entropy differences are zero , and one performs a gradient descent algorithm towards a local or global minimum out of which one is then taken by a gradual increase in ( instantaneous ) entropy differences . in the following illustrations of the algorithm ,",
    "i will , however , consider again the @xmath52 case only , for simplicity .",
    "i have applied the algorithm to the infinite - range , the two - dimensional and the three - dimensional ferromagnet to see how well the simplest version of the algorithm ( the `` @xmath52 femc algorithm '' ) performs on obtaining the entropy values of the considered systems and on overcoming energy barriers .",
    "more specifically , in the case of the infinite - range ferromagnet , where i know the entropy ( or number of configurations ) exactly , i have investigated the convergence to the correct values of the entropy as well as the passage times ( `` tunneling times '' ) between the `` all - spins up '' and `` all - spins down '' ground states .",
    "the values of @xmath53 that i use are between @xmath54 and @xmath55 .",
    "certainly , @xmath53 should tend to zero with increasing @xmath31 to obtain even more accurate values of the entropy .",
    "however , the smaller @xmath53 is already in the earlier stages of the algorithm , the longer it takes to reach the asymptotic stage .",
    "if one takes @xmath53 too small at the start of the algorithm , one risks to never leave , during the time of the simulation , the regime where effectively one samples according to performing a random walk in configuration space , as the differences in the entropy values will stay too small in the available simulation time .",
    "a good way to measure whether one has reached the asymptotic regime of the algorithm yet or not is to keep track of the sampled energies : if the histogram of the energies , averaged over a long enough period of time , is flat , asymptotics are reached .",
    "some comments on the large-@xmath53 limit are also in place . for @xmath53 of order @xmath56 or larger ,",
    "the transition probability ( [ tp ] ) of accepting a move becomes essentially @xmath57 or @xmath56 , as the differences in estimated entropy values for the different levels become larger than @xmath56 , hence the argument of the @xmath58 .",
    "this has the following consequences .",
    "if , e.g. , one is at time @xmath31 , say , in a configuration of the level @xmath59 , and the values of the estimated entropy values at the adjacent levels @xmath60 are @xmath61 , then moves are ( essentially ) accepted iff the level of the considered update , @xmath62 , is @xmath63 .",
    "the algorithm can be viewed as putting a brick of height @xmath53 at every time step onto a wall which is building up during the process .",
    "if the height of the wall at the adjacent place ( level ) whereto the move at time @xmath36 is considered is lower , the move is accepted with probability @xmath64 , if the wall is of equal height , the move is accepted with probability @xmath65 , and else it is ( essentially always ) rejected .",
    "it is easy to notice that on average the wall will be of equal height for all levels if one substracts a running ( increasing ) baseline .",
    "this leads to the observed fact that all energy levels occur with equal probability , albeit the fact that the weight factors in the algorithm are not proportional to the true entropy values ( on average ) .",
    "i have considered systems which contained @xmath66 spins where @xmath67 .",
    "i have compared runs where the `` tunneling times '' where measured from the beginning with ones where the tunneling times of the first @xmath68 ( @xmath69 ) monte carlo steps ( mcs ; defined as usual as the time needed to update all @xmath25 spins in the system ) were not taken into account .",
    "the ( expected ) experience from these runs is that the distribution of tunneling times , its mean ( @xmath70 ) and random mean square ( rms ) value ( @xmath71 ) remained essentially unaltered .",
    "however , to be on the safe side , i have not counted the tunnelings observed during the first @xmath72 mcs in the runs whose results are displayed in the following . in all of the different runs , the histogram of the energies , averaged at the same time than the ( instantaneous ) entropy values , is flat , i.e. , fluctuates around the mean number of sampled configurations per energy to within at most a small fraction of a percent for small system sizes and up to at most @xmath73 for the largest systems considered .",
    "the results shown in figure  1 have been obtained with a total number of @xmath74 mcs .",
    "i have fixed @xmath53 to equal @xmath75 , @xmath76 , and @xmath77 , respectively .",
    "this implies that the values @xmath70 and @xmath71 , the mean and the rms value of the tunneling times , have been obtained for @xmath55 from 149338 values for @xmath78 to 659 values for @xmath79 , for @xmath80 from 148726 values for @xmath78 to 1218 values for @xmath79 , for @xmath54 from 146682 values for @xmath78 to 1826 values for @xmath79 . to check for statistical reliability of the data ,",
    "i have also performed slightly shorter and longer runs .",
    "the error bars that i have got from these runs , at fixed averaging times ( of the instantaneous entropy ) , are smaller than the size of the symbols in the figures .",
    "the distributions for the tunneling times , @xmath4 , themselves are , however , intrinsically very broad ( their width is of the order of their mean ) with an accordingly long tail , possibly power - law - like . in the runs displayed in",
    "the figures of this paper , at most @xmath81 tunneling events with times above @xmath82 occured for @xmath83 , this number rapidly decreasing with system size to at most @xmath84 such events for @xmath85 .",
    "the statistics for the larger systems may , indeed , be insufficiant because of the long tail of the distribution ( the effect of a reduction of the measured @xmath70 can clearly be seen in figure  1 for the runs with @xmath80 and @xmath86 respectively @xmath87 spins ) .",
    "however , the resulting error should not alter the results significantly .",
    "i have fitted straight lines ( by eyesight ) to the data points in figure  1 , corresponding to the fits @xmath88 , for the different values of @xmath53 .",
    "because of higher statistical reliablitity of the results of the smaller size systems these have been taken account more than the ones of the larger size systems .",
    "the results for the fit parameters are @xmath89 remember that the exponent for a random walk in energy space is @xmath90 from the general results on one - dimensional random walks . in",
    "the above runs , we obtain that the width of the distribution is of the order of its mean ; this can be noted easily already for @xmath91 , where one knows the ( power - law - like ) distribution of the tunneling times and its properties analytically .    in all of the above simulations ,",
    "i have compared the obtained values for the entropy with the true ones ( that can be easily obtained exactly [ see , e.g. , @xcite ] . depending on the value of @xmath53 , on the number of times that i averaged over the ( estimated instantaneous ) entropy values and on the total time of the simulation , i got more and less accurate results . in any case , for the runs of figure  1 , the error was typically of the order of @xmath53 .",
    "in figure  1 , a comparison of the entropy values , obtained for a system containing @xmath92 spins , using the algorithm with @xmath80 and running it for a total of 50960 mcs , with the exact values is shown .    as can be seen from figure  2 ,",
    "the matching of the values ( of the number of configurations , not of the entropy  ! ) is quite impressive , taking into account the fact that there are @xmath93 configurations .",
    "i have also compared it in the figure to the values obtained by a run with a larger number of mcs , namely 1040960 mcs , but performing a local random walk in configuration space . in this last run ,",
    "i have counted the configurations during the run and normalised the sum of all the hits to @xmath93 .",
    "it is easily seen from the figure that , in contrast to the femc algorithm ( with much fewer mcs  ! ) , ergodicity has been lost , configurations with energy @xmath26 for @xmath94 have not even been sampled  !    in conclusion , in this paper ,",
    "i have introduced a new algorithm in the spirit of the proposals of simulations with `` multicanonical ensembles '' .",
    "i have simulated the infinite - range ferromagnet to obtain the entropy function and to investigate the `` tunneling times '' of getting from one energy minimum to another one .",
    "the results are very encouraging : ( i)the scaling of the `` tunneling times '' with the system size are roughly the ones of a random walk in energy space ; ( ii ) the entropy function of the considered systems could be obtained roughly within errors of order @xmath53 in the used computer time ; ( iii ) more importantly , ergodicity could be retained in all the considered cases in the used computer time ( @xmath95 mcs at most ) . in particular , the last fact , the retaining of the ergodicity , should allow for a calculation of physical quantities , such as correlation functions , through equation ( [ erg ] ) near zero temperature where conventional mc simulations fail .",
    "it is also interesting to use the full femc algorithm ( with nonvanishing @xmath51 ) .",
    "more results with the latter shall be published elsewhere @xcite .",
    "it is particularly interesting to determine the best choice of the parameters @xmath53 and @xmath51 and of their ratio to overcome energy barriers in the least amount of time and to explore the energy space for minima or more generally extrema .",
    "also , more analytical details and properties of the algorithm can be obtained for the case of the infinite - range ferromagnet @xcite .",
    "it shall be interesting to apply the algorithm in the cases where hitherto ergodicity problems have not allowed to obtain results .",
    "one last application of the algorithm should be mentioned here .",
    "constructing a general model of on - line learning is an important challenge in the theory of learning and its application .",
    "a plausible definition of the goal of supervised learning from examples is to find a weight vector @xmath96 that minimises the generalisation error , @xmath97 . in an on - line learning algorithm ,",
    "the learner receives a single new example at each time step and is unable to store previous examples in memory .",
    "the conventional on - line algorithm is based on the gradient of the instantaneous error @xcite . for a sufficiently small learning rate",
    ", it converges to a local minimum of @xmath97 but not necessarily to the global one .",
    "more importantly , it is not applicable to learning of boolean functions or of other discrete valued functions which are extremely useful for decision and classification tasks .",
    "recently , an _ on - line gibbs algorithm _ has been proposed @xcite as the first on - line algorithm that guarantees convergence to the minimal generalisation error for non - smooth systems , in particular for systems with discrete valued outputs or threshold hidden units .",
    "the price that is paid is an increased complexity of the computation at each presentation of examples . in particular , for systems in which the generalisation error has local minima , the on - line gibbs algorithm may require a slow annealing schedule of the temperature variable , used in the algorithm , which might yield a slow global convergence rate .",
    "in addition , the algorithm relies on the possibility of updating the weights by small increments .",
    "consequently , it is inapplicable to systems with _",
    "discrete valued weights_. in the case of the femc algorithm , gradient descent and escaping from minima can be combined naturally ( see equation  ( [ femc ] ) ) so that the femc may offer a valuable alternative to optimise the learning procedure .",
    "serious questions concerning on - line learning are still open , most importantly the one is on the _ global convergence rate _ , which is yet unknown in general .",
    "n.  metropolis , a.w .",
    "rosenbluth , m.n .",
    "rosenbluth , a.h .",
    "teller , and e.  teller , _ j.  chem .",
    "_  * 21 * ( 1953 ) 1087 .",
    "fosdick , _ methods comput .",
    "_  * 1 * ( 1963 ) 245 .",
    "see j.p .",
    "valeau and d.n .",
    "card , _ j.  chem",
    ".  phys . _  * 57 * ( 1972 ) 5457 .",
    "torrie and j.p .",
    "valleau , _",
    "j.  comput .",
    "_  * 23 * ( 1977 ) 187 . k.  binder and a.p .",
    "young , _ rev .",
    "* 58 * ( 1986 ) 801 .",
    "m.  mzard , g.  parisi , and m.a .",
    "virasoro , _ spin glasses and beyond _ , world scientific , singapore ( 1987 ) .",
    "fischer and j.a .",
    "hertz , _ spin glasses _ , cambridge university press , cambridge  ( 1991 )",
    ". h.  rieger , _ monte carlo studies of ising spin glasses and random field systems _ , in : _ annual reviews of computational physics ii _",
    ", d.  stauffer ( ed . ) , world scientific , singapore ( 1995 ) .",
    "berg , _ hep - lat/9503019 _ , _ j.  stat .",
    "phys . _  * 82 * ( 1996 ) 323 .",
    "van  kampen , _",
    "stochastic processes in physics and chemistry _ , north - holland , amsterdam@xmath98oxford@xmath98new york@xmath98tokyo ( 1981 ) .",
    "b.  berg and t.  neuhaus , _ phys .",
    "* 267 * ( 1991 ) 249 .",
    "b.  berg and t.  neuhaus , _ phys .",
    "lett . _  * 68 * ( 1992 ) 9 . b.  berg and t.  celik , _ phys .  rev",
    ".  lett . _  * 69 * ( 1992 ) 2292 . b.  berg and t.  celik , _ int .  j.  mod.phys .",
    "c _  * 3 * ( 1992 ) 1251 .",
    "lyubartsev , a.a .",
    "martsinowski , s.v .",
    "shevkunov , and p.n .",
    "vorontsov  velyaminow , _",
    "j.  chem .",
    "phys . _  * 96 * ( 1992 ) 1176 .",
    "e.  marinari and g.  parisi , _ europhys .",
    "lett . _  * 19 * ( 1992 ) 451",
    ". b.  berg , _ int .",
    "j.  mod .",
    "c _  * 3 * ( 1992 ) 311 .",
    "a. hller , _ z.  phys",
    "* 88 * ( 1992 ) 79 .",
    "b. hesselbo and r. stinchcombe , _ phys .",
    "rev.lett._  * 74 * ( 1995 ) 2151 . c.  borgs and s.  kappler , _ phys .",
    "* 171 * ( 1992 ) 2011 .",
    "b.  berg , u.  hansmann , and t.  neuhaus , _",
    "z.  phys .",
    "b _  * 90 * ( 1993 ) 229 .",
    "b.  grossmann and m.l .",
    "laursen , _ nucl.phys .",
    "b _  * 408 * , ( 1993 ) 637 .",
    "k.  rummukainen , _ nucl .",
    "* 390 * ( 1993 ) 621 .",
    "a.  billoire , t.  neuhaus , and b.  berg , _",
    "nucl.phys .",
    "* 396 * ( 1993 ) 779 .",
    "a.  billoire , t.  neuhaus , and b.  berg , _",
    "nucl.phys .",
    "* 413 * ( 1994 ) 795 .",
    "j.  lee , _ phys .",
    "_  * 71 * ( 1993 ) 211 [ and erratum * 71 * ( 1993 ) 2353 ] .",
    "b.  berg , u.  hansmann , and y.  okamoto , _",
    "j.  phys.chem._  * 99 * ( 1995 ) 2236 .",
    "u.  hansmann and y.  okamoto , _ j.  comput .",
    "_  * 14 * ( 1993 ) 1333 . m",
    "hao and h.a .",
    "scheraga , _ j.  phys",
    ".  chem . _  * 98 * ( 1994 ) 4940 . b.  berg , u.  hansmann , and t.  celik , _ phys .",
    "b _  * 50 * ( 1994 ) 16444 .",
    "w.  kerler and p.  rehberg , _ phys .",
    "e _  * 50 * ( 1994 ) 4220 .",
    "w.  janke and s.  kappler , _ phys .",
    "_  * 74 * ( 1995 ) 212",
    ". w.  janke , _ recent developments in monte  carlo simulations of first - order phase transitions _",
    ", in _ computer simulations studies in condensed matter physics vii _ ( proceedings in physics 78 , pp .",
    "2944 ) , d.p .",
    "landau , k.k .",
    "mon , and h .- b .",
    "schttler ( eds ) , springer , berlin@xmath98heidelberg@xmath98new york@xmath98london@xmath98paris@xmath98tokyo ( 1994 )",
    ". b.  berg , _ nature _",
    "* 361 * ( 1993 ) 708 .",
    "thill , unpublished .",
    "pearson , _ phys .",
    "b _  * 26 * ( 1982 ) 6285 .",
    "seung , h.  sompolinsky , and n.  tishby , _ phys .",
    "* 45 * ( 1992 ) 6056 .",
    "s.  haykin , _ neural networks : a comprehensive foundation _ , macmillan college , new york ( 1994 ) .",
    "t.  heskes and b.  kappen , _ phys .",
    "rev .  a _",
    "* 44 * ( 1991 ) 2718 .",
    "kim and h.  sompolinsky , _ phys .",
    "lett . _  * 76 * ( 1996 ) 3021 ."
  ],
  "abstract_text": [
    "<S> i propose a new algorithm , a _ </S>",
    "<S> free energy monte carlo algorithm _ , for calculations where conventional monte carlo simulations struggle with ergodicity problems . </S>",
    "<S> the simplest version of the proposed algorithm allows for the determination of the entropy function of statistical systems and/or performs entropy sampling at sufficiently large times . </S>",
    "<S> i also mention how this algorithm can be used to explore the system s energy space , in particular for minima . </S>",
    "<S> + pacs numbers : 05.50.+q , 11.15.ha , 64.60.fr , 75.50.hk , 87.10.+e , 02.60.pn . , 02.70.lq , 05.20.-y +    = 10000    2 </S>"
  ]
}