{
  "article_text": [
    "in the era of data deluge , massive amounts of _ raw data _ are generated at an unprecedented scale by mobile applications , sensors , and scientific experiments .",
    "the vast majority of these read - only data are stored as application - specific files containing millions  if not billions  of records . _",
    "data exploration _ is the initial step in extracting knowledge from these data .",
    "aggregate statistics are computed in order to assess the quality of the raw data , before a thorough investigation on transformed data is performed .",
    "the main goal of data exploration is to determine if the time - consuming data transformation and in - depth analysis are necessary .",
    "thus , data exploration does not have to be exact . as long as accurate _",
    "estimates _ that guide the decision process are generated , its goal is achieved .",
    "this allows for an extensive set of optimization strategies that reduce i / o and cpu utilization to be employed .",
    "however , if the detailed analysis is triggered , the work performed during exploration should allow for _ incremental _ extension . in order to illustrate these concepts",
    ", we provide an example from a real application in astronomy .",
    "* motivating example .",
    "* the palomar transient factory ( ptf ) project  @xcite aims to identify and automatically classify transient astrophysical objects such as variable stars and supernovae in real - time . a list of potential transients  or candidates ",
    "is extracted from the images taken by the telescope during a night .",
    "they are stored as a table in one or more fits files .",
    "the initial stage in the identification process is to execute a series of aggregate queries over the batch of extracted candidates .",
    "this corresponds to data exploration .",
    "the general ` sql ` form of the queries is :    select aggregate(expression ) as agg from candidate where predicate having agg < threshold    where _ aggregate _ is sum , count , or average and _ threshold _ is a verification parameter .",
    "these queries check certain statistical properties of the entire batch and are executed in sequence ",
    "a query is executed only if all the previous queries are satisfied .",
    "if the candidate batch passes the verification criteria , an in - depth analysis is performed for individual candidates . the entire process ",
    "verification and in - depth analysis  is executed by querying a postgresql database  only after the candidates are loaded from the original fits files .",
    "this workflow is highly inefficient for two reasons .",
    "first , the verification can not start until data are loaded .",
    "second , if the batch does not pass the verification , both the time spent for loading and the storage used for data replication are wasted .",
    "* raw data processing .",
    "* to reduce the high upfront database loading cost , multiple raw data processing systems have been recently introduced  @xcite .",
    "they are extensions of the external table mechanism supported by standard database servers  @xcite .",
    "these systems execute ` sql ` queries directly over raw data while optimizing the conversion process into the format required by the query engine ( figure  [ fig : scanraw ] ) .",
    "this eliminates loading and provides instant access to data  verification can start immediately in our example .",
    "however , since verification consists of more than a single query , the overall time incurred by raw data processing can be larger than in a database because full access to the raw data is required for every query .",
    "several systems  @xcite provide a dynamic tradeoff between the time to access data and the query execution time by adaptively loading a portion of the data during processing .",
    "this allows for gradually improved query execution times while reducing the amount of storage for replication .",
    "however , these systems are data - agnostic and can not identify uninteresting patterns early in the processing .",
    "this results in wasted cpu and storage resources .    *",
    "online aggregation .",
    "* since the goal of data exploration  batch verification in our example  is only to determine if the individual candidate in - depth analysis is necessary , it is not mandatory to evaluate each query in the sequence to completion . as early as the relationship between the aggregate and the verification threshold can be accurately inferred , the query can be stopped .",
    "this relationship can be determined by using only an estimate of the aggregate .",
    "if the aggregate ` agg `  or its estimate  is larger than the threshold , the verification fails and no in - depth analysis is required .",
    "otherwise , we can proceed to the subsequent query in the verification .",
    "online aggregation ( ola )  @xcite provides a sound framework to reason about the aggregate estimation involved in verification .",
    "the main idea in ola is to estimate the query result based on a sample of the data .",
    "in addition to the estimator , ola defines a principled method to derive confidence bounds that permit the correct identification of the relationship with the threshold .",
    "the estimator and the bounds are computed from a sample much smaller in size than the overall dataset , thus reducing the execution time of a verification query tremendously ( figure  [ fig : ola ] ) .",
    "the existing ola solutions have strict requirements imposed by the sampling procedure .",
    "data shuffling  @xcite is considered the standard procedure to extract samples of increasing size from a dataset .",
    "shuffling generates a permutation of the data as a query preprocessing step such that a runtime sequential scan results in random samples of increasing size .",
    "however , shuffling creates a secondary copy of the data and incurs significant processing time  even more than loading .",
    "* problem & approach . * at high - level ,",
    "our objective is to _ optimally execute exploration over raw data in a shared - memory multi - core environment where i / o operations are overlapped with extraction and several chunks can be processed concurrently while minimizing resource utilization_. in our concrete example , this corresponds to low execution time for the verification process without incurring any loading cost .",
    "our approach is to seamlessly integrate online aggregation into raw data processing such that we cumulate their benefits .",
    "figure  [ fig : ola - raw : high - level ] illustrates the intuition behind the proposed ola - raw solution with respect to standard database processing ( dbms ) , online aggregation ( ola ) , and raw data processing with adaptive loading ( raw ) , respectively . similar to raw , ola - raw distributes data loading across the query workload .",
    "notice , though , that loading in raw  and , by extension , in ola - raw  corresponds to caching data in memory , not necessarily materializing on secondary storage .",
    "the same idea is extended to shuffling . instead of randomly permuting all the data before performing online aggregation , ola - raw partitions shuffling across the queries in the workload .",
    "moreover , loading and shuffling are combined incrementally such that loaded data do not require further shuffling . essentially , _ ola - raw provides a resource - aware parallel mechanism to adaptively extract and incrementally maintain samples from raw data_. the end goal is to reduce the high upfront cost of loading ( dbms ) and shuffling ( ola ) , and to minimize the amount of data accessed by raw , as long as estimates are accepted by the user ",
    "the general situation in data exploration .",
    "* challenges . *",
    "the realization of ola - raw poses a series of difficult challenges .",
    "first and foremost , an efficient sampling mechanism targeted at raw data has to be devised .",
    "the sampling mechanism has to work in - place , over data in the original format .",
    "it has to minimize the amount of raw data read and/or extracted into the processing representation since these are the fundamental limitations of raw data processing .",
    "given our focus on parallel processing , the sampling mechanism has to cope with the so called `` inspection paradox ''  @xcite .",
    "since the estimate is correlated with the extraction time , the order in which chunks are considered has to be the same with the extraction scheduling order .",
    "the second challenge is defining and analyzing estimators for the sampling mechanism . in order to be amenable to online aggregation",
    ", the estimators have to be integrated in the sampling mechanism and they have to support incremental computation over samples of increasing size .",
    "a third challenge corresponds to the incremental maintenance of samples . since extracting samples from raw data is expensive , a mechanism that preserves them in memory for further use in subsequent queries and maintains them incrementally is necessary .",
    "this has to be realized efficiently  the goal is to compute the estimate as fast as possible , not to maintain the sample . from an implementation perspective , the integration of online aggregation into a resource - aware raw data processing system is always challenging because of the complex interactions between i / o , extraction , sampling , and estimation .",
    "* contributions . *",
    "the main contribution of this paper is a novel bi - level sampling scheme for ola - raw that addresses the aforementioned challenges .",
    "ola - raw sampling is query - driven and performed exclusively in - situ during query execution , without data reorganization . in order to avoid the expensive",
    "conversion cost , ola - raw builds and maintains incrementally a memory - resident bi - level sample synopsis .",
    "these are achieved through a series of technical contributions detailed in the following :    we define online aggregation over raw data in a multi - core shared - memory setting ( section  [ sec : preliminaries ] ) .",
    "we provide a parallel chunk - level sampling mechanism that avoids the inherent inspection paradox ( section  [ sec : chunk - sampling ] ) .",
    "we introduce a novel parallel bi - level sampling scheme that supports continuous estimation  not only at chunk boundaries  during the online aggregation process ( section  [ sec : bilevel - sampling ] ) .",
    "we devise a resource - aware policy to determine the optimal chunk sample size for the proposed bi - level sampling scheme ( section  [ sec : ola - raw - sampling ] ) .",
    "we design a memory - resident bi - level sample synopsis that is built and maintained incrementally following a variance - driven strategy ( section  [ sec : synopsis ] ) .",
    "we implement ola - raw inside a state - of - the - art in - situ data processing system and evaluate its performance across several real and synthetic datasets and file formats .",
    "we investigate the importance of each ola - raw component as well as the overall solution .",
    "our results ( section  [ sec : experiments ] ) show that ola - raw chooses the sampling plan that minimizes the execution time and guarantees the required accuracy for each query in a given workload .",
    "in this section , we introduce query processing over raw data and online aggregation .",
    "we define the online aggregation over raw data problem and identify the challenges to be addressed by a coherent solution that integrates the two .",
    "raw data processing is depicted in figure  [ fig : scanraw ] .",
    "the input to the process is a raw file from a non - volatile storage device , e.g. , disk or ssd , a schema that can include optional attributes , and a procedure to extract tuples with the given schema from the raw file .",
    "the output is a tuple representation that can be processed by the query engine and , possibly , is cached in memory . in the ` read ` stage ,",
    "data are read from the original raw file , chunk - by - chunk , using the file system s functionality .",
    "a chunk contains multiple records and represents the unit of processing . without additional information about the structure or the content  stored inside the file or in some external structure ",
    "the entire file has to be read the first time it is accessed . `",
    "extract ` transforms tuples from raw format into the processing representation based on the schema provided and using the extraction procedure given as input to the process .",
    "there are two main tasks in ` extract ` .",
    "the first is to identify the schema attributes and output a vector containing the starting position for every attribute in the tuple  or a subset , if the query does not access all the attributes .",
    "second , attributes are converted from the raw format to their corresponding binary type and mapped to the processing representation of the tuple ",
    "the record in a row - store , or the array in column - stores , respectively . at the end of ` extract ` , data are loaded in memory and ready for query processing . in this paper , we consider parallel raw data processing in the context of the scanraw operator  @xcite and nodb  @xcite .",
    "scanraw overlaps the i / o operations with ` extract ` over multiple chunks in a super - scalar pipeline architecture , i.e. , multiple chunks are extracted concurrently .",
    "nodb caches binary chunks in memory to avoid subsequent extraction .",
    "we consider online aggregation over a single table @xmath0 stored in some arbitrary sequential raw format , e.g. , csv , json , or fits , and general aggregate queries of the form :    select aggregate(expression ) from t where predicate    where _ aggregate _ is one of sum , count , or average and _ expression _ is a numeric expression , such as @xmath1 or @xmath2 , that involves one or more columns of @xmath0 .",
    "these aggregation functions are the most commonly used in practice .",
    "online aggregation over a single raw data source is a fundamental problem arising not only in queries that explicitly involve a single table ",
    "this is the standard scenario in raw data processing  but also in queries on `` star '' schemas that consist of a massive `` fact '' table  which is sampled  and many smaller `` dimension '' tables  which are cached in memory . in general , the proposed methods apply to queries that involve joins between multiple tables , provided that sampling is performed on exactly one raw data source and each join attribute is a foreign key .",
    "_ group by _ queries can also be handled using the methods in this paper by simply treating each group as a separate query and running all the queries simultaneously .",
    "a group - specific version of the _ predicate _ that accepts only tuples from that particular group is required for each separate query .",
    "in addition to the query , an online aggregation user is typically required to specify two parameters .",
    "accuracy @xmath3 _ determines when the query can be stopped .",
    "different from one - time estimation  @xcite that might produce inaccurate estimates not satisfying a given @xmath3 , ola is an iterative process in which a series of estimators with improving accuracy are generated .",
    "this is accomplished by including more data in estimation , i.e. , increasing the sample size , from one iteration to another . as more data are processed towards computing the result",
    ", the accuracy of the estimator improves accordingly ( figure  [ fig : ola ] ) .",
    "the _ estimation time interval @xmath4 _ specifies how often the estimate and corresponding confidence bounds are computed .",
    "the user can decide to stop the query at any time  even when the accuracy is not satisfied  based on the returned estimate and confidence bounds .",
    "extracting random samples of increasing size at runtime is a complex time - consuming process  @xcite .",
    "this is the reason why existing procedures require a certain level of preprocessing . in offline sampling ,",
    "a series of samples with progressively increasing size  the largest one being the entire dataset  are taken , e.g. , blinkdb  @xcite .",
    "these samples are stored and processed as independent entities .",
    "offline tuple - based shuffling  @xcite guarantees that a runtime sequential scan produces samples of increasing size .",
    "in addition to preprocessing time , the offline methods incur a heavy storage overhead .",
    "these are in contrast with the requirements of in - situ data processing .",
    "chunk - level  @xcite , i.e. , block - level  @xcite or cluster  @xcite , sampling samples over the chunk space instead of the tuple space .",
    "this can be done efficiently online  randomly permute the processing order of chunks  without any preprocessing .",
    "however , chunk - level sampling incurs a higher processing cost because all the tuples inside a chunk have to be included in estimation .",
    "while this may be irrelevant for database processing , it is of great importance for in - situ processing due to the ` extract ` stage .    in this paper",
    ", we consider chunk - level sampling in the context of parallel raw data processing , specifically the scanraw operator .",
    "this creates problems because the random chunk order interacts with parallel processing .",
    "this , in turn , can trigger the inspection paradox which makes sampling - based estimation impossible .",
    "the only solution that addresses this problem in a distributed mapreduce setting is given in  @xcite .",
    "it defines a multivariate distribution that incorporates several timing parameters in addition to the aggregate chunk value .",
    "since we focus on multi - thread parallelism in a shared - memory setting , the timing parameters are too similar to have a discriminative effect .",
    "moreover , we can take advantage of the centralized shared - memory environment to eliminate the inspection paradox without resorting to expensive distributed synchronization .",
    "in this section , we give a simple solution that extends chunk - level sampling to parallel online aggregation over raw data . as far as we know ,",
    "this is the first attempt to parallelize chunk - level sampling in a shared - memory setting .",
    "chunk - level sampling can be implemented similarly to a random data scan .",
    "the random order in which chunks are read from storage is determined before query execution starts ( figure  [ fig : sampling - generation ] ) . at runtime ,",
    "chunks are fully processed by computing the aggregate function and any additional statistics required for estimation over all the tuples in the chunk .",
    "essentially , a single value is generated for the entire chunk .",
    "for example , if ` sum(b ) ` has to be estimated in figure  [ fig : sampling - generation ] , the value corresponding to chunk 2 is @xmath5 .",
    "this is what is used in estimation . at each step , the chunks processed represent a simple random sample without replacement over the space of all chunks in @xmath0 . as more",
    "chunks are processed , the size of the sample increases .",
    "this guarantees that the accuracy of the estimate improves , i.e. , the width of the confidence bounds shrinks",
    ".    chunk - level sampling does not require any preprocessing , thus it fits perfectly in the in - situ raw data processing setting .",
    "it also minimizes the number of chunks read from storage when compared to tuple - based sampling .",
    "however , the accuracy of chunk - level sampling can be orders of magnitude lower than that of tuple - based sampling for the same number of processed tuples  @xcite .",
    "this is of critical importance for in - situ processing because the gap between i / o bandwidth and cpu utilization is less wide than in standard databases`extract ` can be a time - consuming cpu task .",
    "consider , for example , processing a json file with a deep schema .",
    "extracting all the objects from a chunk can easily become the bottleneck , making the entire process cpu - bound .",
    "since chunk - level sampling requires more tuples to be processed in order to achieve the same accuracy , it is very likely that it also incurs a higher execution time than tuple - based sampling .",
    "parallel in - situ processing systems overlap ` read ` and ` extract ` , while also performing multiple ` extract ` instances concurrently . as long as sufficient cpu threads are available ,",
    "multiple chunks can be extracted in parallel . due to variations in extraction time across chunks , e.g. , different number of tuples , length of attributes , predicate selectivity , the order in which chunks are returned by ` extract ` can be different from the predefined random order .",
    "this renders chunk - level sampling estimation impossible due to the inspection paradox .",
    "the only solution to avoid this problem is to reorder the chunks before they are included in the estimation  add a synchronization barrier after ` extract ` .",
    "for example , in figure  [ fig : sampling - generation ] chunk - level estimation is possible only after chunk 2 is extracted , even though chunks 3 and 1 have already been processed ",
    "they are scheduled after chunk 2 .",
    "while reordering eliminates the inspection paradox , it can exacerbate the standard error swings characteristic to chunk - level sampling  @xcite .",
    "moreover , it can introduce variable - length gaps , i.e. , step behavior , in estimation  there can be long time intervals over which there is no change in the estimator .",
    "these diminish the applicability of chunk - level sampling to parallel online aggregation over raw data .",
    "in this section , we introduce a novel bi - level sampling scheme for parallel online aggregation .",
    "the proposed scheme differs significantly from bi - level bernoulli sampling  @xcite  the only work that applies bi - level sampling to databases we are aware of  in which the goal is to extract a one - time bernoulli sample with rate @xmath6 .",
    "our objective is to design an incremental sampling procedure that supports adaptive sample size increase in order to achieve continuous accuracy improvement .",
    "we propose the following bi - level sampling scheme .",
    "chunks are read in a predetermined random order similar to chunk - level sampling . however , instead of aggregating all the tuples in the chunk into a single value that becomes a surrogate for the chunk , a secondary sampling process is performed over the tuples in the chunk .",
    "this is realized by randomly shuffling the order in which tuples are extracted .",
    "independent orders are used across chunks . since",
    "this is done in memory , no significant overhead is incurred .",
    "figure  [ fig : sampling - generation ] depicts the entire procedure .    at each step during the process ,",
    "the set of sampled tuples correspond to a bi - level  or two - stage ",
    "sample without replacement  @xcite .",
    "this provides more flexibility over chunk - level sampling since estimates can be computed at any point in the process  not only at chunk boundaries .",
    "moreover , the sample size can be increased either by including more chunks or more tuples inside a chunk .",
    "it is important to notice that bi - level sampling degenerates to chunk - level sampling when all the tuples inside a chunk are included in the sample .",
    "this is likely to happen when there is high variability inside a chunk .",
    "when tuples inside a chunk are similar , however , bi - level sampling allows for the chunk to be represented by a much smaller number of tuples .",
    "this has the potential to dramatically reduce the cost of ` extract ` in raw data processing .",
    "the downside of bi - level sampling is the larger number of parameters .",
    "in addition to the number of chunks , the number of sampled tuples inside each chunk has to be specified .",
    "however , these are determined dynamically in online aggregation , thus , this is not a real problem .      as in the case of chunk - level sampling ,",
    "when bi - level sampling is applied to parallel online aggregation over raw data , the inspection paradox can invalidate the entire sampling procedure .",
    "the impact of the inspection paradox is further aggravated by the different number of tuples extracted across chunks .",
    "for example , consider a highly - variable chunk followed by a uniform one ( chunk 2 and 3 in figure  [ fig : sampling - generation ] ) .",
    "although chunk 2 is scheduled before chunk 3 , fewer tuples from chunk 3 have to be extracted and included in estimation . as a result , chunk 3  even chunk 1 in figure  [ fig : sampling - generation ] ",
    "is extracted before chunk 2 . in the case of chunk - level sampling ,",
    "an estimate can be generated only after chunk 2 finishes  the estimate includes chunk 3 and 1 , as well .",
    "while exactly the same conditions apply to bi - level sampling , the secondary sampling process inside chunks provides additional opportunities not to delay estimation  an essential requirement in online aggregation .",
    "a major contribution of this paper is a novel solution for continuous estimation .",
    "we devise a mechanism that enforces the existence of samples from all the chunks in ` extract ` at any estimation time interval @xmath4 .",
    "each ` extract ` thread is configured with a timing parameter @xmath7 that specifies when samples from the chunk have to be produced .",
    "this can happen multiple times during the execution of ` extract ` . since chunks are scheduled for extraction sequentially",
    ", this guarantees that samples are extracted in order .",
    "the number of tuples included in the sample , however , can vary based on the properties of the chunk .",
    "this is illustrated in figure  [ fig : sampling - generation ] where 3 tuples are sampled from chunk 3 , while only 2 tuples from chunk 2 and 1 , respectively .",
    "as long as the timing parameter @xmath7 is smaller than @xmath4 , improved estimates can be generated .",
    "@xmath7 is  in a sense  related to the variables @xmath8 and @xmath9 in  @xcite .",
    "however , instead of including it in the estimation snapshot , we use timing to enforce the bi - level sampling process and its corresponding estimation .",
    "the overhead incurred by the timing mechanism is minimal and reduces to inspecting a timer after groups of several tuples ",
    "each tuple , in the extreme  are extracted .",
    "we focus on the estimator for the ` sum ` aggregate . `",
    "count ` is identical to ` sum ` with @xmath10 .",
    "as shown in  @xcite , only minor modifications have to be made for complex aggregates such as ` average ` , ` variance ` , or standard deviation .",
    "the notation used in our analysis is shown in table  [ tbl : notation ] .",
    "it adapts the notation for bernoulli sampling used in  @xcite to sampling without replacement .",
    ".notation for bi - level sampling used throughout the paper . [ cols=\"<,<\",options=\"header \" , ]      the experimental results confirm that ola - raw bi - level sampling outperforms external tables and chunk - level sampling . in the best case ,",
    "ola - raw achieves the required accuracy in as little as @xmath11 of the time required by external tables to answer the query exactly and chunk - level sampling to achieve the same accuracy .",
    "this happens in a heavily cpu - bound setting where the bottleneck is the number of processed tuples .",
    "the worst scenario for ola - raw is a low selectivity query in an i / o - bound context with a sufficiently large number of threads . due to the sampling overhead ,",
    "both bi - level and chunk - level sampling are slower than external tables .",
    "the results also prove that resource - aware bi - level sampling is the most adaptable scheme to the processing environment while a sample synopsis of less than @xmath12 in size can provide a reduction of more than @xmath13 in execution time across a sequence of correlated queries .",
    "our main contribution is to integrate online aggregation in raw data processing .",
    "thus , these two lines of research  raw data processing and online aggregation  are the most relevant to our work .",
    "we discuss the relationship between ola - raw bi - level sampling and these two research areas in the following .",
    "* raw data processing . * at a high level , we can group raw data processing into two categories . in the first category , we have extensions to traditional database systems that allow raw file processing inside the execution engine .",
    "examples include external tables  @xcite and various optimizations that eliminate the requirement for scanning the entire file to answer the query  @xcite .",
    "modern database engines ",
    "e.g. , oracle , mysql , impala  provide external tables as a feature to directly query flat files using sql without paying the upfront cost of loading the data into the system .",
    "nodb  @xcite enhances external tables by extracting only the attributes required in the query and caching them in memory for use in subsequent queries .",
    "data vaults  @xcite and sds / q  @xcite apply the same idea of query - driven just - in - time caching to scientific repositories . while the proposed sample synopsis inherits in - memory caching , it caches samples rather than full columns .",
    "adaptive partial loading  @xcite materializes the cached data in nodb to secondary storage before query execution starts  loading is query - driven .",
    "scanraw  @xcite is a super - scalar adaptive external tables implementation that materializes data only when i / o resources are available .",
    "instant loading  @xcite introduces vectorized simd implementations for tokenizing .",
    "raw  @xcite and its extensions vida  @xcite generate ` extract ` operators just - in - time for the underlying data file and the incoming query .",
    "the second category is organized around hadoop mapreduce which processes natively raw data by including the ` extract ` code in the map and reduce functions .",
    "invisible loading  @xcite focuses on eliminating the ` extract ` code by loading the already converted data inside a database . while similar to adaptive partial loading , instead of saving all the tuples into the database , only a fraction of tuples are stored for every query .",
    "none of these solutions supports sampling over raw data and estimation  the central contribution of this work .    *",
    "online aggregation .",
    "* the database online aggregation literature has its origins in the seminal paper by hellerstein et al .",
    "we can broadly categorize this body of work into system design  @xcite , online join algorithms  @xcite , online algorithms for estimations other than join  @xcite , and methods to derive confidence bounds  @xcite .",
    "the distributed online aggregation literature is not as rich .",
    "luo et al .",
    "@xcite extend the ripple join algorithm  @xcite to a distributed setting .",
    "wu et al .",
    "@xcite extend online aggregation to distributed p2p networks .",
    "they introduce a synchronized sampling estimator over partitioned data that requires data movement from storage nodes to processing nodes . in subsequent work ,",
    "wu et al .",
    "@xcite tackle online aggregation over multiple queries .",
    "the third piece of relevant work is online aggregation in mapreduce ( hadoop or spark ) .",
    "blinkdb  @xcite implements a multi - stage approximation mechanism based on pre - computed sampling synopses of multiple sizes , while earl  @xcite and abs  @xcite use bootstrapping to produce multiple estimators from the same sample .",
    "iolap  @xcite models online aggregation as incremental view maintenance with uncertainty propagation .",
    "sample+seek  @xcite introduces measure - biased sampling to provide error guarantees for ` group by ` queries with many groups .",
    "quickr  @xcite injects single - pass samplers in query execution plans to generate one - time approximate results . with almost no exceptions ,",
    "all of this work is based on tuple - based sampling .",
    "the inadequacy of this type of sampling for database processing has been recognized in  @xcite where cardinality estimators based on chunk - level sampling are introduced .",
    "this type of sampling is later applied to parallel online aggregation in hadoop  @xcite .",
    "the only application of bi - level bernoulli sampling to database processing is given in  @xcite .",
    "the last two solutions are the closest to ola - raw and they are discussed in detail throughout the paper .",
    "our main contribution to online aggregation is the design of parallel bi - level sampling estimators that avoid the inspection paradox .",
    "in this paper , we present ola - raw , a bi - level sampling scheme for parallel online aggregation over raw data .",
    "ola - raw sampling is query - driven and performed exclusively in - situ during query execution , without data reorganization . in order to avoid the expensive conversion cost , ola - raw builds and",
    "maintains incrementally a memory - resident bi - level sample synopsis .",
    "we implement ola - raw inside a modern in - situ data processing system and evaluate its performance across several real and synthetic datasets and file formats .",
    "our results confirm that ola - raw bi - level sampling outperforms external tables and chunk - level sampling  by as much as @xmath13  and leads to a focused data exploration process that avoids unnecessary work and discards uninteresting data . in future work",
    ", we plan to perform a thorough investigation of the estimator sensitivity to the chunk size .",
    "this is a well - known problem for bi - level sampling .",
    "adaptive solutions that change the chunk size dynamically at runtime are an interesting direction to pursue ."
  ],
  "abstract_text": [
    "<S> in - situ processing has been proposed as a novel data exploration solution in many domains generating massive amounts of raw data , e.g. , astronomy , since it provides immediate sql querying over raw files . </S>",
    "<S> the performance of in - situ processing across a query workload is , however , limited by the speed of full scan , tokenizing , and parsing of the entire data . </S>",
    "<S> online aggregation ( ola ) has been introduced as an efficient method for data exploration that identifies uninteresting patterns faster by continuously estimating the result of a computation during the actual processing  the computation can be stopped as early as the estimate is accurate enough to be deemed uninteresting . however </S>",
    "<S> , existing ola solutions have a high upfront cost of randomly shuffling and/or sampling the data . in this paper </S>",
    "<S> , we present ola - raw , a bi - level sampling scheme for parallel online aggregation over raw data . </S>",
    "<S> sampling in ola - raw is query - driven and performed exclusively in - situ during the runtime query execution , without data reorganization . </S>",
    "<S> this is realized by a novel resource - aware bi - level sampling algorithm that processes data in random chunks concurrently and determines adaptively the number of sampled tuples inside a chunk . in order to avoid the cost of repetitive conversion from raw data , ola - raw builds and maintains a memory - resident bi - level sample synopsis incrementally . </S>",
    "<S> we implement ola - raw inside a modern in - situ data processing system and evaluate its performance across several real and synthetic datasets and file formats . </S>",
    "<S> our results show that ola - raw chooses the sampling plan that minimizes the execution time and guarantees the required accuracy for each query in a given workload . </S>",
    "<S> the end result is a focused data exploration process that avoids unnecessary work and discards uninteresting data . </S>"
  ]
}