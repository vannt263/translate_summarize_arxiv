{
  "article_text": [
    "we characterize the boundedness of hankel operators in three and more complex variables in terms of the @xmath7 norm of the symbol of the operator . in one complex variable ,",
    "this and related facts are the circle of ideas around nehari s theorem . in the case of more than one complex variable , there are different types of hankel operators , and we only consider the so called little hankel operators ; little in the sense that the projection used in the definition is onto the smallest natural choice of subspaces of @xmath9 to use .",
    "the structure of these hankel operators is more intricate due to the more complicated structure of the hardy spaces @xmath10 in the product domain and their duals , as identified by s .- y .",
    "chang and r.  fefferman [ @xcite,@xcite , @xcite ] .",
    "some of the tools that have proved to be so flexible and powerful in the one parameter situation apparently have no analog in the higher parameter case ; these spaces remain , to a significant degree , poorly understood .",
    "we prove the natural statement about the boundedness of little hankel operators in an arbitrary number of complex variables .",
    "namely , the hankel operator with symbol @xmath4 is bounded iff the projection of @xmath4 into product hardy space is in product @xmath7 .",
    "central to this paper is the result of s.  ferguson and m.  lacey @xcite that established a similar characterization for hankel operators of two complex variables .",
    "the current proof is inductive in nature , and one can use the classical one variable statements of our theorem as the base case in the induction .",
    "in particular the methods of @xcite are not sufficient to prove the theorem in this paper ; the inductive argument is the essential new argument in this paper .",
    "recall that @xmath11 has the orthogonal decomposition @xmath12 .",
    "let @xmath13 be the corresponding orthogonal projections onto the analytic / antianalytic spaces .    in @xmath14 variables ,",
    "let @xmath15 be the same projections acting on the @xmath16th coordinate , @xmath17 .",
    "for functions @xmath18 , let @xmath19 it is clear that @xmath9 has the orthogonal decomposition into @xmath20 we take @xmath21 to be the function from @xmath22 that is identically @xmath23 .",
    "it is clear that @xmath24 .    for a function @xmath4",
    ", we set the _ hankel operator with symbol @xmath4 _ to be @xmath25 , defined as a map from @xmath0 to @xmath3 .",
    "@xmath26 is the projection from @xmath9 onto @xmath3 .",
    "clearly , this operator depends only on @xmath27 .",
    "[ t.hankel ] we have the equivalence of norms @xmath28    here @xmath29 is the ( analytic ) bounded mean oscillation space , dual to @xmath8 , as identified by s .- y .  chang and r.  fefferman .",
    "this theorem has two well known equivalences .",
    "one is in terms of the commutator @xmath30,\\operatorname h_2],\\cdots , \\operatorname h_n],\\ ] ] in which @xmath31 is the operator of pointwise multiplication by @xmath4 , and @xmath32 denotes the hilbert transform computed in the @xmath16th coordinate .",
    "the commutator is a sum of @xmath33 hankel operators , each coming from one of the @xmath33 orthants of @xmath34 . in particular ,",
    "if the _ signature _ of @xmath35 is @xmath36 , a straightforward computation shows that @xmath37 thus , the upper bound for the hankel operators @xmath38 immediately extends to an @xmath39 operator norm for the commutators .",
    "conversely , assuming the commutator is bounded on @xmath2 , a number of hankel operators with the same symbol are also bounded .",
    "namely , the hankel operators are from @xmath40 to @xmath41 . thus the lower bound follows .",
    "that is , we have @xmath42 the latter space is the _ real _ @xmath7 space .",
    "a second equivalence is in essence a dual statement to the estimates above , and hence is a statement about @xmath8 .",
    "it gives us a _ weak factorization _ result for that space , namely @xmath43 where the right hand side is the projective tensor product of @xmath44 .",
    "this equality plays a role in our proof , and so we return to it below .    for the proof ,",
    "the strategy is one of induction on the number of parameters in a manner analogous to the overall strategy of ferguson and lacey @xcite , which addresses the two parameter case .",
    "the upper bound on @xmath45 in ( [ e.hankel ] ) is in fact easy to obtain , a fact which is easiest to see via the trivial inclusion in ( [ e.weak ] ) .",
    "thus , the real difficulty in our theorem lies in the lower bound on @xmath45 . here , there is a bound which follows from the one parameter theory , namely that the operator norm of @xmath46 is bounded below by the `` rectangular @xmath7 '' norm of @xmath4 .",
    "it is well known that the rectangular @xmath7 norm is essentially smaller than the @xmath7 norm .",
    "ferguson and lacey @xcite showed how to use the journ lemma @xcite to pass from this essentially smaller norm to the @xmath7 norm of chang and fefferman .",
    "a formulation of the journ lemma for rectangles in three and higher parameters is due to j.  pipher @xcite , but the direct application of this lemma can not succeed in a proof of our theorem .",
    "the reasons are both technical and heuristic .",
    "relying on just the rectangular @xmath7 norm in three and more parameters does not take advantage of the subtle way that the @xmath14 parameter @xmath7 space is built up from the @xmath47 parameter space .",
    "we find that this point of view , and a form of journ s lemma we need , as stated in section  [ s.journe ] , are implicit in the paper of j.  pipher .",
    "to use the journ lemma , we need to make a definition of @xmath48 , which is applied to a function in the @xmath14 parameter setting . our induction argument then , in proving the lower bound in the @xmath14 parameter setting , is to first derive the weaker bound of @xmath48 . and then prove the correct @xmath7 bound , assuming that the @xmath48 norm of the symbol is sufficiently small .",
    "by @xmath49 we mean that there is an absolute constant @xmath50 for which @xmath51 .",
    "@xmath50 is allowed to depend upon relevant parameters .",
    "we are indebted to j.  pipher for sharing some of her insights into the journ lemma , and to the referee for a quick and helpful report .",
    "the upper bound @xmath52 can be seen by a soft proof . consider the hankel operator @xmath46 , @xmath53 since the product of @xmath44 functions is in @xmath10 , we see that the integral above admits the upper bound of @xmath54 .",
    "this is the upper half of theorem  [ t.hankel ] .",
    "we turn to the weak factorization result . for @xmath55",
    ", @xmath56 closed subspaces of @xmath9 , we define the projective tensor product @xmath57 by @xmath58 observe that that ( [ bnorm1 ] ) implies that the hankel operator with symbol @xmath4 is bounded if and only if the function @xmath59 is in the dual of @xmath60 . therefore , the weak factorization equivalence ( [ e.weak ] ) is equivalent to our main theorem .",
    "that is , we have the equivalence @xmath61",
    "we begin with some preliminary definitions and calculations in the one parameter setting which carry over naturally to the higher parameter setting . the proofs in the rest of the paper use analytic wavelets constructed by y. meyer @xcite which are compact in frequency .",
    "let @xmath62 be a schwartz function with @xmath63 and @xmath64 supported on @xmath65 $ ] .",
    "therefore the wavelets and projections have the nice decay estimates @xmath66    let @xmath67 denote the dyadic intervals on @xmath68 .",
    "for an interval @xmath69 , define @xmath70 where @xmath71 denotes the center of @xmath72 .",
    "note that the functions @xmath73 are well localized to the interval @xmath72 .",
    "@xmath74 y.  meyer has shown that we can choose @xmath62 so that @xmath75 form an orthonormal basis on @xmath0 .",
    "another useful property of these functions is that we have the littlewood - paley inequalities , @xmath76    we are now ready to define a characterization of product @xmath29 due to s.- y. chang and r. fefferman @xcite .",
    "let @xmath77 be the dyadic rectangles .",
    "for a rectangle @xmath78 , define @xmath79 we say @xmath80 iff @xmath81^{\\frac12 } < \\infty\\ ] ] where @xmath82 is an open set in @xmath34 of finite measure .",
    ", as we are using analytic wavelets . real @xmath7 has a similar definition , provided one uses wavelets that form a basis for @xmath11 .",
    "] we denote this supremum by @xmath83 .",
    "it is a theorem of chang and fefferman that this definition coincides with the norm of the dual to @xmath8 .",
    "we now define a weaker notion , which we dub @xmath48 . for a collection of rectangles @xmath84 , set the _ shadow _ of @xmath85 , to be @xmath86 we say that @xmath85 has @xmath47 parameters iff there is a coordinate @xmath87 and a dyadic interval @xmath72 so that for all @xmath88 , we have @xmath89 .",
    "we then define @xmath90^{\\frac12}.\\ ] ] here , we note that the definition depends only upon the projection @xmath59 . in two dimensions ,",
    "this reduces to a notion that is just slightly weaker than the notion of rectangular @xmath7 , which is well known to be essentially smaller than the @xmath7 norm .",
    "an essential part of the argument is to use the induction hypothesis to show that we have the lower bound @xmath91 this amounts to the assertion that @xmath92 an inequality we will demonstrate by relying on the truth of theorem  [ t.hankel ] in the @xmath47 parameter setting .    given a symbol @xmath93 of @xmath14 variables , we assume that @xmath4 is analytic in all variables and has @xmath94 .",
    "we also take as given a set @xmath85 of rectangles in @xmath95 of @xmath96 parameters .",
    "thus associated to @xmath85 are the dyadic interval @xmath72 and the collection @xmath97 as in the definition .",
    "we assume that @xmath98 , @xmath99 , and for all @xmath88 we have @xmath100 and @xmath101 .",
    "our claim is then that the function @xmath102 has @xmath60 norm @xmath103 , which , together with @xmath104 , certainly proves ( [ e.n-1 > ] ) .",
    "thus it suffices to show the claim .",
    "now , since for each @xmath88 , we have @xmath105 , and @xmath106 we can utilize factorization results in both @xmath107 and @xmath108 . for @xmath107 ,",
    "we use the classical inner outer factorization to conclude that @xmath109 concerning the function @xmath110 , by our choice of @xmath85 and the square function characterization of the hardy space , we observe that @xmath110 has @xmath111 norm at most a constant . by the induction hypothesis and , in particular , the assertion that @xmath112 , we can write @xmath113 hence , writing @xmath114\\cdot\\bigl[w_i^{(2 ) } ( x_1)\\phi_k(x')\\bigr]\\ ] ] we see that our claim holds .",
    "this completes the proof of the lower bound .",
    "an example of carleson shows that the @xmath48 bound is essentially smaller than the @xmath7 norm .",
    "in particular , some tool is needed to pass to the larger norm . that tool is a journ lemma , which we detail in the next section .",
    "we can assume that @xmath115 and seek an absolute lower bound on @xmath45 . in the course of the proof , we will need absolute positive constants @xmath116 , and @xmath117 .",
    "other parameters , termed `` diagonalization parameters '' , are introduced to gain convergent geometric series .",
    "the parameters used for these will be denoted with the letter @xmath118 with various subscripts .",
    "we assume that @xmath119 , for otherwise we have an absolute lower bound on @xmath45 .",
    "take a set of rectangles @xmath85 which achieves the supremum in the definition of the @xmath7 norm of @xmath56 .",
    "we can assume , after a harmless dilation , that @xmath120 .",
    "we will show that @xmath121b}.2.\\ge{}\\delta_3.\\ ] ] here we use the notation @xmath122=\\sum_{r\\in\\mathcal u}v_r\\otimes v_r$ ] , and so @xmath122b=\\sum_{r\\in\\mathcal u}\\ip b , v_r.v_r$ ] . establishing the lower bound on",
    "the norm of the hankel operator will require some careful analysis which centers around a variety of paraproducts , proper formulation , and application of a lemma due to journ which is specified in section  [ s.journe ] .    from the discussion in section  [ s.journe ] , there is a set @xmath123 , satisfying several conditions , among them @xmath124",
    "take the collection of rectangles @xmath125 and @xmath126 to be @xmath127 we shall prove that for absolute @xmath128 , @xmath129b\\overline { \\operatorname p[\\mathcal u]b}.2.\\ge\\delta_2 , \\\\",
    "\\label{e.v < } \\norm \\operatorname p^{\\ominus}\\operatorname p[\\mathcal v]b\\overline { \\operatorname p[\\mathcal u]b}.2.\\lesssim{}\\delta_{\\text{journ\\'e}}^{1/2 } , \\\\ \\label{e.w < } \\norm \\operatorname p^{\\ominus}\\operatorname p[\\mathcal w]b\\overline { \\operatorname p[\\mathcal u]b}.2.\\le{}k_{\\delta_{\\text{journ\\'e}}}\\delta_{-1}.\\end{gathered}\\ ] ] the last inequality holds with a constant that depends only on @xmath130 .",
    "thus , fixing first @xmath130 sufficiently small and then @xmath131 proves ( [ e.lower ] ) .",
    "the first two estimates are trivial , as we indicate now .",
    "first , note that the fourier transform of @xmath132 b}^2 $ ] is symmetric , so that @xmath133b\\overline { \\operatorname p[\\mathcal u]b}.2.\\ge2^{-n}\\norm \\operatorname p[\\mathcal u]b.4.^2.\\ ] ] the @xmath134 norm has a lower bound , due to the fact that we have taken the shadow of @xmath85 to have measure approximately one and the validity of the littlewood - paley inequalities .",
    "thus , @xmath135b .2 . \\\\{}= { } & \\sum_{r\\in\\mathcal u } \\abs{\\ip b , v_r.}^2 \\\\{}\\le { } & \\norm \\bigl[\\sum_{r\\in\\mathcal u } \\frac",
    "{ \\abs{\\ip b , v_r.}^2}{\\abs r } \\ind r \\bigr]^{1/2}.4 .",
    "\\\\{}\\lesssim { } &   \\norm \\operatorname p[\\mathcal u]b .4 .. \\end{aligned}\\ ] ] this proves ( [ e.u > ] ) .",
    "second , use the control on the size of @xmath136 to see that @xmath137b .2.^2+\\norm",
    "\\operatorname p[\\mathcal v]b.2.^2=\\abs { \\sh{\\mathcal   u}}+\\norm \\operatorname p[\\mathcal v]b.2.^2\\le{}\\abs v\\le{}(1+\\delta_{\\text{journ\\'e}})\\abs { \\sh{\\mathcal   u } } .\\ ] ] thus , @xmath138b.2.^2\\le{}\\delta_{\\text{journ\\'e}}$ ] .",
    "by the john - nirenberg inequality , we see that @xmath138b.4.\\le{}\\delta_{\\text{journ\\'e}}^{1/4}$ ] .",
    "hence , we can prove ( [ e.v < ] ) as follows .",
    "@xmath139b\\overline { \\operatorname p[\\mathcal u]b}.2.\\le { }      \\norm \\operatorname p[\\mathcal u]b.4.\\norm \\operatorname p[\\mathcal v]b.4.\\lesssim { } \\delta_{\\text{journ\\'e}}^{1/2}.\\ ] ]      the principal inequality is ( [ e.w < ] ) , and it requires a sustained analysis to verify .",
    "it is imperative to observe that the term @xmath140b}\\operatorname p[\\mathcal u]b$ ] has a sizable cancellation as a sum over wavelets .",
    "if @xmath141 and @xmath142 are two dyadic rectangles with @xmath143 for any @xmath144 , then we would have @xmath145 this is due to the fact that in the @xmath16th coordinate , the fourier transform is not supported in @xmath146 .",
    "thus , we can replace the definition of @xmath126 by : @xmath147 it is also imperative to observe that even with this restricted definition , the shadows of @xmath85 and @xmath126 will , in general , overlap .",
    "this overlap will be controlled by the journ lemma and additional orthogonality considerations .",
    "nevertheless , the sum should be analyzed along the lines of a product of two functions which are nearly supported on disjoint sets .",
    "the technique for doing this is via sums known generically as paraproducts . in @xmath14 parameters , the paraproducts admit different degeneracies , as measured in the amount of orthogonality present in the sums .",
    "it is the purpose of the following definitions to quantify these paraproducts .",
    "given a subset @xmath148 , write @xmath149 iff for indices @xmath150 , we have @xmath151 , whereas for indices @xmath152 , we have @xmath153 .",
    "set @xmath154 the remainder of the proof is devoted to the assertion that @xmath155    this objective can only be met with additional diagonalizations of the sums .",
    "applying the journ lemma as stated in lemma  [ l.journe-n-1 ] , we can decompose @xmath85 into collections @xmath156 , for @xmath157 , for which we have @xmath158 for @xmath159 , and @xmath160b.bmo.\\le{}k_{\\delta_{\\text{journ\\'e}}}2^{(n+1)d_1}\\norm b.bmo_{-1 } ( \\otimes_1^n\\mathbb c_+).\\lesssim2^{(n+1)d_1}\\delta_{-1}.\\ ] ] in what follows , we shall suppress the dependence of these inequalities on the choice of @xmath130 , which comes only through this application of journ s lemma .",
    "also the ( large ) power of @xmath161 is of no particular consequence . from another part of the estimate we can pick up a factor of @xmath162 for arbitrarily large @xmath163 .    for integers",
    "@xmath164 , set @xmath165 in this notation , and below , we will suppress the dependence upon @xmath161 , as this parameter does not directly enter into any of the estimates .",
    "we shall show that @xmath166 this estimate proves ( [ e.zx < ] ) .",
    "orthogonality enters into the estimate in the following way .",
    "suppose we are given two pairs of rectangles @xmath167 and @xmath168 in @xmath169 .",
    "in addition , suppose @xmath170 for some @xmath150 .",
    "we conclude that the functions @xmath171 and @xmath172 are orthogonal .",
    "this is seen by examining the fourier supports of the wavelets .",
    "therefore , for @xmath173-tuples of integers @xmath174 , we define @xmath175 here , for simplicity , we have assumed that @xmath176 for notational convenience .",
    "we will continue with this assumption throughout .",
    "all estimates will clearly be invariant under appropriate permutation of coordinates . in light of the orthogonality above ,",
    "it is the case that @xmath177    at this point , we can abandon orthogonality considerations altogether in estimating this last sum . in the sums",
    "@xmath178 we have the functions @xmath179 , which can be dominated as @xmath180^{1/2}\\abs { v_{r'}\\overline{v_r}}\\lesssim { } & [ ( \\zeta_{r'}*\\ind { r ' } ) ( \\zeta_r * \\ind r ) ] ^2 \\\\{}\\lesssim{}&\\operatorname m\\ind r(c(r'))^{n}\\zeta_{r'}*\\ind { r'},\\end{aligned}\\ ] ] where we take @xmath181 is arbitrary , though the implied constant will depend upon the choice of @xmath163 .",
    "@xmath182 is an effective measure of the distance between @xmath142 and @xmath141 , as @xmath142 will always have dimensions which are smaller or comparable to those of @xmath141 .",
    "of course , for @xmath183 , we have @xmath184 .",
    "thus , @xmath185 the top line holds for all large integers @xmath163 .",
    "thus in the argument below we can accrue some bounded number of positive powers of @xmath186 and not place our desired estimate in jeopardy .",
    "hence , to obtain ( [ e.zxd < ] ) it is enough for us to show that @xmath187 as the terms @xmath188 are sums of indicator sets of rectangles , we can appeal to facts about carleson measures and , in particular , the john - nirenberg inequalities to control these sums .",
    "there is a final diagonalization to make . for @xmath173-tuples of natural numbers @xmath189 , set @xmath190 where @xmath191 .",
    "the leading term of the last line suggests that indeed @xmath192 is a diagonalization parameter .    with the relative sizes of @xmath142 and @xmath141 fixed by the choice of @xmath148 and by the choice of @xmath192 ,",
    "observe that for each @xmath142 , there can be at most @xmath193 possible choices of @xmath141 so that @xmath194 .",
    "again , we can afford to lose some bounded number of powers of @xmath195 in our estimates .",
    "we take @xmath196 let @xmath197 be such that @xmath198 . we would need to consider @xmath193 possible choices for this function .",
    "below , we will consider just some arbitrary choice of this function @xmath199 , and then merely sum over the possible choices of @xmath199 , accruing a harmless term of @xmath193 .",
    "set @xmath200    the specific estimate we prove is : @xmath201 this is summed over @xmath189 to prove ( [ e.2dd ] ) , and so will complete our proof .",
    "the proof of this inequality is taken up in the next subsection .",
    "we achieve an exponential decay in parameters @xmath202 .",
    "we shall rely repeatedly on the estimates @xmath203 the first of these has the critical gain by a factor of @xmath204 , as follows from ( [ e.u_d_1bmo ] ) .",
    "the second estimate follows from the fact that @xmath4 is in @xmath7 and that the rectangles @xmath142 in @xmath205 are contained in @xmath206 since @xmath207 for some @xmath208 . here",
    "@xmath209 is the strong maximal function .    at this point",
    "we recap the notations .",
    "* @xmath210 .",
    "* @xmath161 is associated to the measure of embeddedness of rectangles @xmath211 .",
    "* @xmath212 is a ( crude ) measure of the separation between the rectangles @xmath213 and @xmath159 for @xmath164 .",
    "* @xmath148 is that set of coordinates for which one has some orthogonality .",
    "* @xmath174 specifies the side lengths of @xmath142 for those coordinates @xmath150 .",
    "* @xmath189 specifies how much bigger @xmath141 is than @xmath142 in the coordinates @xmath150 .",
    "* @xmath198 and @xmath214 for @xmath215 , otherwise for @xmath216 , @xmath217 .",
    "* @xmath218 .",
    "the argument varies depending upon the cardinality of @xmath148 . while we can formalize issues in a way that is uniform with respect to @xmath219 , we present four subsections , to emphasize the differences that come about due to the increasing number of parameters .",
    "the key point is that the sum in ( [ e.2do ] ) simplifies considerably , as all the side lengths of @xmath142 are specified by the parameter @xmath221 . in particular , the rectangles @xmath222 occurring in the sum in ( [ e.defzy ] ) are pairwise disjoint .",
    "thus , the @xmath39 norm in ( [ e.2do ] ) will simplify to @xmath223 as @xmath224 has @xmath225 norm one , the supremum above is bounded by @xmath226 . then sum over @xmath174 and use ( [ e.use1 ] ) to see that @xmath227 recall that we can tolerate a few positive powers of @xmath228 .",
    "this case is complete .",
    "now , the rectangles @xmath230 are only permitted to vary in the last coordinate .",
    "that is , the corresponding sums are as complex as those of one parameter carleson measures .",
    "so we can explicitly compute @xmath231 with the specific way the innermost sum is formed , observe that @xmath232 the first estimate is obvious , while the second estimate follows from the fact that the rectangles @xmath233 are contained in @xmath234 in this last display , set the last coordinate of @xmath192 to be zero . applying these observations , cauchy - schwarz , ( [ e.use2 ] ) , and @xmath115 we see that @xmath235 this completes this case .      the argument in this case",
    "could be adapted to treat the general case .",
    "we would like to indicate the additional difficulty that one faces in this case .",
    "the side lengths of @xmath142 are fixed for those coordinates in @xmath237 , and completely specified by @xmath174 .",
    "the remaining side lengths of @xmath142 are then permitted to vary .",
    "thus , the ways that two possible choices of @xmath238 can intersect are as general as the intersections of two dyadic rectangles of dimension @xmath239 .    nevertheless , one can implement a method of proof that follows the lines of the case @xmath229 , provided one takes advantage of the john - nirenberg inequality , which we now state in the form used . for rectangles @xmath240 and non - negative constants @xmath241 for which @xmath242 for all open sets @xmath243 ,",
    "we have @xmath244 we use this to obtain the following extensions of the inequalities ( [ e.use1 ] ) and ( [ e.use2 ] ) . in the first place",
    ", we have @xmath245^{1/2 } .p.\\lesssim { } 2^{2nd_2},\\qquad 1<p<\\infty.\\ ] ] this is available to us from the fact that @xmath224 is in @xmath225 with norm one .",
    "a similar fact is @xmath246^{1/2 } .p.\\lesssim{}\\delta_{-1 }",
    "2^{2nd_2},\\qquad 1<p<\\infty.\\ ] ] the important features of these estimates are that they are independent of @xmath192 , uniform in @xmath174 , and in the second estimate we have the gain of @xmath131 .",
    "now , the second estimate does not immediately follow from a @xmath225 estimate , due to the fact that we have a mismatch between @xmath222 and @xmath247 in ( [ e.use2 ] ) . due to the john - nirenberg inequality , ( [ e.use2 ] ) will follow from the estimate @xmath248 as this estimate is uniform in the choice of @xmath249 , it provides a bound for a carleson measure to which the john - nirenberg inequality applies . for a given @xmath250 , it is the case that for all rectangles @xmath142 that contribute to this sum , the rectangle @xmath233 is contained in a set which is given in the first place by a strong maximal function applied to @xmath249 .",
    "set @xmath251 for an appropriate choice of @xmath252 .",
    "this set , so constructed , will contain a translation of @xmath142 which is contained in @xmath233 . the point to keep in mind",
    "is that @xmath233 is @xmath253 times longer than @xmath142 in the coordinate @xmath150 .",
    "thus , in that coordinate , we should apply a one dimensional maximal function with threshold @xmath254 .",
    "namely , for @xmath255 , we inductively define @xmath256 for appropriate constant @xmath252 , we will have @xmath257 . and we certainly have @xmath258 .",
    "this completes the proof of ( [ e.use2 ] ) .",
    "estimates ( [ e.use1 ] ) and ( [ e.use2 ] ) are not in themselves enough to complete the proof , as there is no decay in the quantity @xmath259 .",
    "but , they do show that @xmath260^{1/2 } .4.\\\\",
    "\\label{e.use3 } \\lesssim{}&\\norm \\biggl [ \\sum_{r'\\in \\mathcal y(j , d_2,\\overrightarrow{d_3 } ) } \\frac{\\beta(r')^2 } { { \\abs { r ' } } } \\ind { r ' }   \\biggr]^{1/2 } .8.\\norm \\biggl [ \\sum_{r'\\in \\mathcal y(j , d_2,\\overrightarrow{d_3 } ) } \\frac{\\beta(\\pi(r'))^2 } { { \\abs { \\pi(r ' ) } } } \\ind { r ' }   \\biggr]^{1/2 } .8.\\\\\\nonumber   \\lesssim{}&2^{4nd_2}\\delta_{-1 } .",
    "\\end{aligned}\\ ] ] namely , we have an estimate on the @xmath134 norm that is uniform with respect to @xmath192 .",
    "this will permit us to select a set which decays with respect to this parameter . on this set , we will not attempt to estimate the @xmath39 norm in ( [ e.2do ] ) .",
    "the set we take is @xmath261 here , we use the strong maximal function @xmath262 .",
    "this set has measure @xmath263 , due to the large @xmath264 norms we have in ( [ e.use3 ] ) .    to complete the argument in this case",
    ", it suffices to show that @xmath265 we will expand the square on the left hand side . integrating @xmath266 over @xmath267",
    ", we will lose a factor of @xmath268 .",
    "but from @xmath269 we will gain a factor of @xmath270 .",
    "specifically , @xmath271 this estimate follows from the definition of the set @xmath272 and ( [ e.use1 ] ) and ( [ e.use2 ] ) .      in this case , both @xmath221 and @xmath192 are not present , and the rectangles @xmath142 and @xmath233 have comparable lengths in all coordinates .",
    "but we do have ( [ e.use1 ] ) and ( [ e.use2 ] ) , and they directly prove the desired estimate @xmath274^{1/2 } .4 .",
    "\\norm \\biggl [ \\sum_{r'\\in \\mathcal y(\\emptyset , d_2 ) } \\frac{\\beta(\\pi(r'))^2 } { { \\abs { \\pi(r ' ) } } } \\ind { r ' }   \\biggr]^{1/2 } .4 .",
    "\\\\{}\\lesssim{}&\\delta_{-1 } 2^{4nd_2}.\\end{aligned}\\ ] ] and this completes this case .",
    "we state a version of the lemma of journ @xcite that is implicit in pipher s extension @xcite , and interfaces well with our notion of a restricted @xmath7 norm , namely @xmath48 .",
    "we first state the lemma in a purely geometric fashion , and then return to a formulation that is more specific to our needs in this paper .",
    "[ l.few-small ] for all @xmath279 , we can select @xmath280 with @xmath281 , for which we have the uniform estimate @xmath282 the implied constants in these estimates depend only on dimension and the choices of @xmath283 .    consider a collection of rectangles @xmath85 in which all the first coordinates are the same .",
    "then the embeddedness is necessarily of order @xmath284 .",
    "this example shows that the lemma above must be formulated in this fashion .",
    "we begin the proof with a careful description of how to select the set @xmath136 .",
    "if we were not too concerned about the upper bound on the measure of @xmath136 , in other words if the bound @xmath285 were enough , then we could simply take @xmath286 . for our needs , however , this choice of @xmath136 is completely inappropriate .",
    "we need the notion of _ shifted dyadic grids _ , which is a modification of an observation due to m.  christ defined as follows .",
    "the definition of the grids depends upon a choice of integer @xmath287 , and we will set @xmath288 . for integers @xmath289 , and @xmath290 ,",
    "let @xmath291 one checks that @xmath292 is a grid .",
    "indeed , it suffices to assume @xmath293 and that @xmath294 .",
    "checking the grid structure can be done by induction . and",
    "it suffices to check that the intervals in @xmath295 of length one are a union of intervals in @xmath295 of length @xmath296 .",
    "one need only check this for the interval @xmath297 .",
    "but certainly @xmath298    what is more important concerns the collections @xmath299 . for each dyadic interval @xmath300 , @xmath301 . for instance ,",
    "@xmath302 for all integers @xmath303 , regardless of how big @xmath303 is .",
    "] moreover , the maximal function @xmath304 maps @xmath305 into @xmath306 , it is routine to check that @xmath307 dominates an absolute multiple of the usual maximal function , thus , proving that it satisfies the weak type inequality . ] with norm at most @xmath308 .",
    "in fact we need the finer estimate , valid for all choices of @xmath309 and integers @xmath310 , @xmath311 for all subsets @xmath82 of the real line of finite measure and some constant @xmath50 .",
    "this will be an effective estimate since the value of @xmath310 we will consider is @xmath312 . to see this estimate , note that @xmath313)\\abs u.\\end{aligned}\\ ] ]    the main line of the argument can now begin .",
    "we take @xmath314 for an integer @xmath287 .",
    "we use the maximal functions @xmath304 , but only in the last step of the induction .",
    "initialize @xmath315 , so that we use backwards induction .",
    "inductively define @xmath316 where the subscript on the maximal functions denotes the coordinate in which the maximal function is applied .",
    "then it is the case that @xmath317 , where the constant @xmath50 depends only on the dimension @xmath14 .",
    "now pass to a further subset @xmath318 such that for all @xmath319 , we have @xmath320 and if it is the case that @xmath321 , then we have the stronger inequality @xmath322 .",
    "we term this assumption `` separation of scales '' in the first coordinate . under these assumptions ,",
    "estimate ( [ e.few-small ] ) reduces to @xmath323 sufficiency is seen by noting that obtaining separation of scales necessitates dividing the rectangles into approximately @xmath324 subclasses . then multiplying by @xmath325 , one is able to sum over all scales @xmath303 .",
    "our strategy is to define , for dyadic intervals @xmath72 , sets @xmath326 that are disjoint in @xmath72 , contained in @xmath327 , and for which @xmath328 for an appropriate maximal function @xmath209 , where the implied constant is permitted to depend upon @xmath329 and dimension @xmath330 .",
    "it will in fact be of the order @xmath331 .",
    "an appeal to the fefferman - stein maximal inequalities @xcite will then prove ( [ e.frozen ] ) .",
    "the sets @xmath332 are defined to be @xmath333 , where @xmath334 by our separation of scales , the minimal dyadic interval @xmath335 that contributes to this union contains @xmath336 and satisfies @xmath337    we need to show that if @xmath338 is a dyadic rectangle with @xmath339 , then @xmath340 , and hence it ca nt be among those rectangles that contribute to @xmath341 .",
    "this will be accomplished by the following device .",
    "we will show that @xmath342 as @xmath343 , and this is the grid we use in the final step in the construction of @xmath136 , we conclude that the rectangle @xmath344 is inside of @xmath345 .",
    "even @xmath346 , therefore we see that @xmath340 , as desired .",
    "we continue with the language of probability .",
    "let @xmath353 be the probability spaces @xmath354 and let @xmath355 be normalized lebesgue measure on @xmath356 .",
    "the first of the relevant sequence of random variables on these spaces is @xmath357 since @xmath339 , @xmath358 , and applying the proposition , @xmath359 .",
    "continuing by reverse induction , define for @xmath360 @xmath361 induction gives us the conclusion that @xmath362 .",
    "this implies ( [ e.will-do ] ) by inspection of definitions and so completes the proof .",
    "we need a certain variant of the previous lemma .",
    "given a set of rectangles @xmath85 , we let @xmath363 be a map from @xmath85 to the reals greater than one . and",
    "we take @xmath364 which is simply a choice of coordinates .",
    "based on these two data , for any subset @xmath365 we set @xmath366    [ l.journe ] fix @xmath367 . for any collection of rectangles",
    "@xmath85 with finite shadow , we can select @xmath368 , and data @xmath369 and @xmath370 so that the following conditions hold . @xmath371",
    "the implied constant in the last line depends only on @xmath372 and dimension .",
    "the essential points for us are that the set @xmath136 is not much larger than the shadow of @xmath85 , and that the rectangles @xmath88 , after a dilation _ uniform in all coordinates _ by the embeddedness quantity , is contained in the enlarged set @xmath136 .",
    "we find that the embeddedness quantity in the last line requires a large negative power , but that is a completely harmless fact in the context of the application we have in mind .",
    "again , the fact that the dyadic intervals distinguish certain points causes some difficulties for us , and we appeal to the shifted dyadic intervals ( [ e.shifted-grids ] ) of the previous subsection , though our needs are not so refined in the current context .",
    "let @xmath373 be the union of the dyadic intervals with the two collections @xmath374 . for any interval @xmath72 of the real line",
    ", we can find an interval @xmath375 with @xmath376 . indeed , let @xmath377 be the maximal dyadic interval contained in @xmath378 with @xmath379 .",
    "if @xmath380 we are done , so assume that this is not the case .",
    "we necessarily have @xmath381 , so that one of the two intervals @xmath382 contains @xmath72 .",
    "both of these intervals are in @xmath373 , so we are done .",
    "the method of proof requires that we apply lemma  [ l.few-small ] , although we find it necessary to apply it both inductively and to a wide range of possible collections of rectangles .",
    "in fact , it is useful to us that this lemma applies not just to collections of a subset @xmath383 such that the shadow of @xmath85 is of finite measure .",
    "it also applies to all possible subsets of @xmath85 .",
    "we apply lemma  [ l.few-small ] to @xmath384 .",
    "thus , we get a set @xmath385 , with @xmath386 , so that for @xmath387 we have the conclusion of lemma  [ l.few-small ] holding .",
    "we then construct @xmath388 .",
    "set @xmath389    the inductive stage of the construction is this . for @xmath390 ,",
    "given @xmath391 , we apply lemma  [ l.few-small ] to get a set @xmath392 satisfying @xmath393 the embedding function for rectangles @xmath394 is @xmath395 and the conclusion of ( [ e.few-small ] ) holds .",
    "the collection @xmath396 is then taken to consist of all rectangles of the form @xmath397 where @xmath394 and @xmath398 satisfies @xmath399      the definition of the embedding function is not so straight forward .",
    "it is taken to be @xmath402 where @xmath403 are inductively defined below .",
    "the function @xmath404 is taken to be the coordinate in which the infimum for the embedding function is achieved .",
    "set @xmath405 . in the inductive step , for @xmath390 ,",
    "set @xmath406 . for @xmath407 ,",
    "let @xmath408 where @xmath409 is the rectangle with @xmath410 for @xmath411 , and for @xmath412 , @xmath413 is the element of @xmath373 of maximal length such that @xmath414 now , take @xmath415 to be the largest value of @xmath416 for which we have the inequality @xmath417 . let us see that this definition of @xmath418 makes sense .",
    "this last inequality is strict for @xmath419 , and as @xmath420 increases , @xmath421 decreases , so @xmath415 is a well defined quantity .",
    "then define @xmath422 , and for our use below , set @xmath423 .",
    "the choices above prove our lemma , as we show now . for each rectangle @xmath88 ,",
    "it is clear that @xmath424 .",
    "take @xmath277 .",
    "if we consider the sets @xmath425 as in ( [ e.f ] ) , then , by lemma  [ l.few-small ] applied in the @xmath426th coordinate , @xmath427 while we have a very good estimate for the shadow of @xmath428 , a corresponding good estimate for an arbitrary subset @xmath429 seems very difficult to obtain .",
    "but it is a consequence of our construction that the rectangle @xmath430 is a rectangle which agrees with @xmath141 in the coordinates @xmath411 and , for coordinates @xmath412 , is expanded by at most @xmath431 .",
    "hence , we have the estimate @xmath432 this follows from the weak @xmath305 bound for the maximal function in one dimension , applied in each coordinate separately .",
    "it is in this last step that we lose the large power of the embeddedness .",
    "our proof is complete .",
    "[ l.journe-n-1 ] given a function @xmath4 with finite @xmath48 norm and a collection of rectangles @xmath85 whose shadow has finite measure , the following construction is possible . for all @xmath433 ,",
    "there is a set @xmath368 with @xmath434 .",
    "to each @xmath88 , there is a quantity @xmath435 so that @xmath436    for the proof , we apply lemma  [ l.journe ] . to check the conclusion of the lemma",
    ", we take a subset @xmath365 consisting of rectangles with @xmath437 .",
    "we then have @xmath438 this is all we need to prove lemma  [ l.journe-n-1 ] ."
  ],
  "abstract_text": [
    "<S> @xmath0 denotes the hardy space of square integrable functions analytic in each variable separately . </S>",
    "<S> let @xmath1 be the natural projection of @xmath2 onto @xmath3 . a hankel operator with symbol @xmath4 is the linear operator from @xmath0 to @xmath3 given by @xmath5 . </S>",
    "<S> we show that @xmath6 where the right hand norm is s .- y .  </S>",
    "<S> chang and r.  fefferman product @xmath7 . </S>",
    "<S> this fact has well known equivalences in terms of commutators and the weak factorization of @xmath8 . in the case of two complex variables , </S>",
    "<S> this is due to ferguson and lacey @xcite . </S>",
    "<S> while the current proof is inductive , and one can take the one complex variable case as the basis step , it is heavily influenced by the methods of ferguson and lacey . </S>",
    "<S> the induction is carried out with a particular form of a lemma due to journ @xcite , which occurs implicitly in the work of j.  pipher @xcite . </S>"
  ]
}