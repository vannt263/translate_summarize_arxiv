{
  "article_text": [
    "stochastic simulation methods have become increasingly widespread as a means of simulating and analyzing biochemical reaction kinetics@xcite .",
    "the chemical master equation , which governs the reaction kinetics for well - mixed systems , forms the basis for the stochastic simulation algorithm ( ssa ) , proposed by gillespie @xcite .",
    "ssa models a reaction system as a continuous time markov model ( ctmm ) in which states of the system are defined by counts of reactants present at a given point in time and transitions between states correspond to individual reaction events .",
    "this ssa approach is valuable in part because it provides a model of reaction noise , which can become significant for reaction networks on cellular scales  @xcite .",
    "furthermore , ssa models can provide significant computational advantages over continuum models for networks characterized by extremely large sets of possible reaction intermediates .",
    "the computational value of the ssa approach lies in the fact that for a large class of networks , the random walk visits only a small fraction of the state space before equilibrium is established . as a result , kinetics on complicated networks can be simulated `` on the fly , '' requiring explicit construction of the ctmm network only in the immediate vicinity of those states visited on a given trajectory .",
    "this property is an essential requirement for any feasible simulation algorithm , since the size of the state space describing the master equation is astronomical even for modest system sizes .",
    "successful applications of ssa include gene regulatory networks  @xcite and self - assembly of complicated structures , such as virus capsids @xcite .",
    "furthermore , the ssa approach has now been adopted by several approaches for whole - cell modeling  @xcite and modeling generic complex reaction networks  @xcite .",
    "the relaxation time of the ssa can , however , be extremely sensitive to the transition rates controlling the reaction kinetics .",
    "a pure ssa model has difficulty with stiff reaction systems , i.e. , those where important events occur in parallel on very different time scales . in such cases ,",
    "a simulation can become bogged down by sampling fast events to the exclusion of the slow events .",
    "hybrid discrete / stochastic models  @xcite can resolve this problem in some domains , but not when the fast reactions make use of too many intermediates to allow them to be modeled continuously .",
    "one important example of such a stiff reaction system is the breaking of bond networks , where individual bonds may break and repair repeatedly before a sufficiently large bond group is broken to fracture the network .",
    "another form of stiff ssa network occurs near the critical concentration of a self - assembly system , where high - order nucleation events can be orders of magnitude slower than individual binding reactions . in these stiff systems ,",
    "an ssa model can become `` trapped '' for many steps in a small subset of the state space , resulting in negligible simulation progress for long periods of time .     and @xmath0 .",
    "( b ) the probability landscape for the model .",
    "ssa is slow whenever the invariant density for the corresponding markov chain is irregular . here",
    ", the ssa takes @xmath1 steps to reach vertex 3 .",
    "( c ) ctmm model of a trimer assembly system with three subunits .",
    "graph of possible configurations joined by reaction rates .",
    "states in which the trimer is broken are surrounded by solid lines and others by dashed lines . ]    to understand these `` trapped '' systems , it is useful to consider the graph theoretic representation of the ssa method .",
    "an ssa model is represented by a graph in which each node corresponds to one possible state of the full model .",
    "edges connect nodes whose states can be reached from one another by a single reaction event , e.g. , two molecules binding to one another . at each simulation step , ssa considers only the immediate neighbors of the current state . as a result , the simulation is prone to traps that can result from irregularities in the invariant density of the embedded markov chain ( emc ) implemented by ssa for a given ctmm .",
    "for example , consider a 3-state ctmm represented by a simple path ( fig .",
    "[ ssa](a ) ) , where the backward transition rate @xmath2 is much larger than the forward transition rate @xmath0 . the average number of ssa steps to reach state 3 from initial state 1",
    "is @xmath1 because once ssa visits state 2 , it will jump to state 3 only a @xmath3 fraction of the time .",
    "nodes 1 and 2 collectively define a trapped subgraph from which the model must escape . in general , for an @xmath4-path , where each forward rate @xmath0 is smaller than the backward rate @xmath2 , ssa takes @xmath5 steps to traverse the path ( see theorem [ ssacon ] for an analogous problem ) .",
    "one way such a trapped subgraph can arise in a physical system is through models of the breakage of bond networks .",
    "[ ssa](c ) shows the graph arising from a model of the breakage of a three - cycle bond network , which behaves similarly to the 3-state ctmm by establishing a trapped inner graph of four states  the unbroken state and three states with a single broken bond  from which the model must escape to reach any broken network state .",
    "we can alternatively understand the trapping problem in terms of a probability landscape view of a reaction system .",
    "the ssa is sluggish whenever its equilibrium landscape is irregular , consisting of valleys and hills .",
    "the broader and deeper these are , the slower ssa becomes .",
    "to overcome the presence of traps or landscape irregularity , we propose two _ non - local _ simulation algorithms that rely on the spectral decomposition of the kolmogorov matrix ( for a ctmm ) or the transition matrix ( for the embedded markov chain ( emc ) ) .",
    "these eigenvalues and their associated eigenvectors describe global modes of relaxation of the full graph or any of its sub - graphs . since eigenvalues are global properties of a graph , spectral methods are much less sensitive to local landscape traps .",
    "these methods can be applied to quickly sample first passage times on small ctmm graphs such as those in fig .",
    "[ ssa ] or to sample escape times from trapped subgraphs when the full model is prohibitively large .",
    "previous attempts at simulating rare events include the forward flux sampling ( ffs ) technique of allen _",
    "et al._@xcite and related methods @xcite .",
    "the approach breaks a rare event into a series of relatively more probable stages and uses estimates of waiting times for the successive stages to develop an aggregate transition rate for the full event .",
    "this aggregate rate can then be used to approximate the first passage time density as a single exponential random variable . however , while the exponential tail dominates the density for stiff systems and is therefore a highly accurate approximation in many cases , the true probability density has a peak at short times followed by a mixed exponential tail .",
    "the methods developed in the present work , by contrast to the ffs - like methods , sample first passage times from the entire density to within arbitrary an error bound .",
    "recently , another method called the slow - scale ssa was proposed by cao _",
    "et al._@xcite , which relies on a technique called the partial equilibrium approximation ( pea ) .",
    "pea essentially assumes that the set of fast reactions are always in equilibrium and the method approximates transition rates between slowly varying reactant species by their expected value in the partial equilibrium state .",
    "while these methods can provide significant benefits for some ctmms , there are several limitations in using pea or similar approximations for arbitrary graphs .",
    "first , a clear distinction between fast and slow species may not be obvious in a given problem .",
    "for example , in rule - based simulation of bond networks , stiffness is built in through the association / dissociation rates of individual bonds rather than being species dependent .",
    "secondly , these methods always need to be supplemented with approximations involved in computing the mean values of the reaction propensities .",
    "furthermore , pea will be inaccurate whenever fluctuations in the reaction propensities within the partial equilibrium state are comparable to their mean values .",
    "the goal of the present work is to develop efficient methods for some important classes of stiff ssa model for which the above techniques are unsuitable , with a particular emphasis on models important to simulations of self - assembly reactions .",
    "the methods proposed in this paper can be applied to markov processes on arbitrary graphs .",
    "furthermore , they can be made accurate to within arbitrary error bounds .",
    "the remainder of this paper is organized as follows : section [ notation ] sets up some basic notation and a description of the sampling problem for general ctmm . in section [ spec1 ] we introduce a spectral method which relies on the eigen decomposition of the master equation describing the ctmm .",
    "we use a complete spectral decomposition of the first passage time density and rejection sampling to return sample first passage times for arbitrary ctmms . in section [ spec2 ]",
    "we introduce another spectral method which works as a hybrid between the purely local ssa and the completely nonlocal master equation method .",
    "the latter method proceeds by adaptively constructing a basis in which to simulate the markov chain until the system state has relaxed to its slowest eigenvector .",
    "if first - passage out of the trapped subgraphs does not occur by that time , we use the appropriate eigenvalue to sample the time to first - passage as an exponential random variable . in section [ ad ]",
    "we introduce a method for automated discovery of trapped regions in stiff markov models .",
    "this technique allows efficient implementation of spectral methods for large state spaces by isolating regions repeatedly visited by a given random trajectory and using spectral sampling to escape any such subgraph . in section [ bondnet ] we present theoretical results on the time complexity of ssa for bond networks followed by experiments on some special classes of bond networks to compare the simulation efficiency of each method discussed . in section [ nucllim ]",
    "we evaluate the automated discovery variants of the method by applying them to models of a nucleation - limited assembly system with a state space too large to explicitly construct .",
    "section [ discussion ] concludes the paper with a discussion of results and directions for future research .",
    "the ssa identifies reaction kinetics for networks of biochemical subunits as a markov process governed by an appropriate _ chapman - kolmogorov _ equation or , equivalently , its differential version - the master equation .",
    "let @xmath6 be the state space for the ctmm , each node representing a possible state for the simulated system .",
    "the time evolution of probability densities is governed by a _ kolmogorov _",
    "matrix @xmath7 , which specifies the transition rates @xmath8 from the state @xmath9 to @xmath10 .",
    "@xmath11 where , @xmath12 denotes the probability to be in state @xmath10 at time @xmath13 .",
    "the matrix elements @xmath8 satisfy two necessary conditions :    1 .",
    "@xmath14 for @xmath15 .",
    "2 .   @xmath16 .    under these conditions",
    ", it is well known that the matrix has a steady state solution @xmath17 that is an eigenvector of @xmath7 with eigenvalue zero and that all initial distributions relax to @xmath18 in the limit of long times  @xcite .",
    "in addition , we will require @xmath7 to satisfy the _ detailed balance _",
    "condition , which states that at equilibrium , the sum of probability current exchanged between any pair of states @xmath19 is zero , i.e. , @xmath20 .",
    "this in turn allows one to define a scalar product on the state space such that @xmath7 is _ self - adjoint _ : @xmath21 this condition ensures that we can construct an orthogonal _ eigenbasis _ and compute time evolved versions of any given initial probability distribution using spectral decomposition .",
    "given a kolmogorov matrix @xmath7 on a state space @xmath22 and an arbitrary initial state @xmath23 , the first - passage time @xmath24 is a random variable which gives the time at which the trajectory first reaches any state in some subset of the state space @xmath25 .",
    "the standard method of solving a first passage problem is to set up the master equation for @xmath26 with an absorbing boundary over @xmath27 ( zero dirichlet boundary condition )  @xcite .",
    "let @xmath28 be a projection operator onto the subspace @xmath26 and let @xmath4 be the cardinality of @xmath26 .",
    "then , @xmath29 is the effective kolmogorov matrix that governs time evolution over @xmath26 . from detailed balance ,",
    "@xmath30 is self - adjoint over @xmath31 .",
    "hence , the eigenvectors of @xmath30 form a complete basis @xmath32 .",
    "a consequence of the spectral theorem is the completeness relation for the properly normalized eigenbasis , i.e. , @xmath33 . given any vector @xmath34 : @xmath35      in terms of the vertex set basis , the completeness relation over @xmath31 is @xmath36 , where @xmath37 is the projector onto vertex state @xmath38 . given an initial probability density @xmath39 the probability for state @xmath40 evolves as : @xmath41\\end{aligned}\\ ] ] the transition to an element @xmath42 outside of @xmath26 , is governed by the following equation : @xmath43\\end{aligned}\\ ] ] the probability for a first passage to the state @xmath44 between @xmath13 and @xmath45 is hence given by @xmath46 .      in this section we describe a method for returning a sample time from the computed first - passage density @xmath47 to any state @xmath42 .",
    "a general method for sampling from complicated distributions is to use the method of rejection sampling , which first chooses a random variable from a convenient envelope density and accepts or rejects the sample based on a second random sample that depends on the tightness of the envelope fit .",
    "the rejection rate is low if the envelope curve closely approximates the given curve .",
    "a simple envelope curve is provided by a pure exponential of the most slowly decaying eigenvalue , with a coefficient equal to the sum of all positive terms @xmath48 in the computed density @xmath49 . however , there is no guarantee that the rejected part is small .",
    "since each eigen mode encloses an area @xmath50 , cancellations between near - degenerate eigenvalues can in principle lead to a high rejection ratio .",
    "we therefore present a method for choosing an envelope curve @xmath51 which eliminates these cancellations .",
    "furthermore , in section [ menet ] we show that the envelope curve is exact for bond networks generated by cycle graphs @xmath52 .",
    "we sample from @xmath51 using a decomposition into a discrete mixture of densities @xmath53 and an efficient rejection step . here",
    "@xmath54 are constants , one for each component @xmath55 of the envelope curve @xmath51 .",
    "the next theorem proves that the density @xmath56 can be sampled efficiently using a rejection method .",
    "[ rratio ] the expected rejection ratio for @xmath56 is bounded from above by 1.5 .    we will use a simple exponential @xmath57 $ ] as the envelope function . in order to minimize @xmath58 we choose @xmath59 such that @xmath60 and @xmath61 where @xmath62 is defined implicitly by the condition @xmath63 these constraints yield a unique solution @xmath64 . since @xmath65 for @xmath66 , the slope of @xmath67 $ ] monotonically increases to @xmath68 as @xmath69 .",
    "the corresponding envelope rate then satisfies @xmath70 .",
    "the rejection ratio is given by : @xmath71\\left(1-\\left(\\frac{\\lambda_{\\alpha}}{\\lambda_{\\alpha+1}}\\right)^{2}\\right)\\nonumber\\\\ & = & \\left[\\frac{\\lambda_{\\alpha}+ \\lambda_{\\alpha+1}}{\\lambda_{\\alpha+1}}\\right]^{2}\\exp\\left[-\\frac{\\lambda_{\\alpha}^{2}}{\\lambda_{\\alpha}+ \\lambda_{\\alpha+1}}t_{*}\\right]\\leq 4\\exp{\\left[2\\frac{x^{2}\\ln{[x]}}{(1-x^{2})}\\right]}\\end{aligned}\\ ] ] where @xmath72 .",
    "to upper - bound @xmath58 , note that the exponent increases monotonically with @xmath73 and its maximum is @xmath74})/(1-x^{2 } ) = -1 $ ] .",
    "this bound finally gives us @xmath75 .",
    "as a final comment , we note that for general graphs the average time complexity of this algorithm is dominated by the computation of the eigenvectors and eigenvalues , which gives us the following theorem :    the average time complexity for spectral decomposition of the master equation is @xmath76 for a graph of @xmath4 vertices  @xcite .",
    "the efficiency of the ssa is dependent on the relaxation time of the embedded markov chain ( emc ) .",
    "we use this observation to modify the basis in which the emc is simulated .",
    "the standard method of executing a random walk is to consider the transition between adjacent states , each of which is localized at a vertex of the ctmm .",
    "however , correct simulation only requires that these states form a basis , not that they are orthogonal .",
    "if we can choose a set of states which are increasingly likely to appear during the simulation of the markov chain , we are unlikely to make repeated visits to the same state . in order to identify such a basis starting from an initial state @xmath77 , we first identify the transition matrix for an embedded markov chain that correctly describes the given ctmm . consider the vertex set @xmath78 and the basis constructed from @xmath26 , @xmath79 . at",
    "any given time @xmath13 , let the state of the time - evolved markov chain be @xmath80 .",
    "let @xmath81 be the vertex subset populated by the current state vector .",
    "we construct the emc for the subgraph induced by @xmath82 at each step of the algorithm . given the projection of the kolmogorov matrix @xmath30 over the vertex set @xmath26 , choose @xmath83 to be the effective rate of transition to the next state and choose an exponentially distributed random time step @xmath84 with mean waiting time @xmath85 .",
    "then , @xmath86 is the laplacian governing the emc and @xmath87 is the effective transition matrix at that time step .",
    "the next state vector is chosen to be @xmath88 .",
    "the reason for choosing this particular value of @xmath89 is to ensure that no term in @xmath90 becomes negative , a necessary condition for a transition matrix .    .",
    "at each step , direct transitions to the absorbing vertex ( grey ) are computed according to the kolmogorov matrix . ]",
    "the choice of next state is consistent with the master equation governing the ctmm .",
    "rewrite the master equation in terms of the @xmath91 basis ( where the other @xmath92 linearly independent basis vectors can be chosen arbitrarily ) : @xmath93 since there is a unique decomposition for any vector in terms of a linearly independent basis set , eq .",
    "[ emceq ] proves that starting from @xmath94 the next state is uniquely determined to be @xmath95 .        in general",
    ", the next state @xmath95 will have a total probability @xmath96 , due to possible transitions out of the subgraph .",
    "we check if that is the case by generating a @xmath97 $ ] random variable @xmath98 to compare with @xmath99 .",
    "if @xmath100 , the next state is still trapped inside the subgraph and we normalize it as @xmath101 .",
    "@xmath102 is used to generate the next state in the simulation .",
    "this sequence will continue until the state has relaxed to its slowest eigen vector @xmath103 , such that @xmath104 to within a user - defined relative error @xmath105 .",
    "once that state is achieved , we just need one more exponentially distributed random sample time @xmath84 with mean @xmath106 to escape the network .",
    "ssa chooses a stochastic trajectory by sampling both the next neighbor and the time for the next step at random .",
    "the emc method , on the other hand , evolves deterministically in our modified basis and only the time between transitions is stochastic . at each time step ,",
    "transition to the absorbing boundary states is governed by the matrix elements connecting each of the transient states to the absorbing boundary .",
    "the advantage of such an approach is that it allows us to automatically compute the most slowly decaying eigenvector during the simulation . for completeness",
    ", we note the following result :    for a graph of degree bounded by @xmath107 and @xmath26 of cardinality @xmath4 , each step of this algorithm takes @xmath108 time .",
    "as previously mentioned , stiffness in markov model graphs results from repeated visits by a typical random trajectory to a small subset of vertices of the entire graph .",
    "since the performance of spectral methods is sensitive to the size of the vertex set , it would prove useful if we could somehow identify these `` trapped '' subgraphs for stiff markov models and apply spectral methods directly to those . in this section",
    "we present one such method , which we call `` automated discovery '' ( ad ) and which we show to be formally applicable to arbitrary bounded - degree graphs .",
    "let there be a state space @xmath22 over which a ctmm is defined and consider a subgraph @xmath109 with vertex set @xmath110 and edge set @xmath111 .",
    "starting from an initial state @xmath112 , we are interested in the time @xmath24 to first passage out of @xmath26 .",
    "consider the subgraph @xmath113 induced by the vertex set @xmath114 visited by a random trajectory executing the ssa random walk before it escapes @xmath26 and let @xmath115 be the cardinality of @xmath116 . if @xmath117 is the number of steps a ssa random walk takes to escape @xmath26 , then a markov model will show simulation stiffness whenever the expected values satisfy , @xmath118",
    "< < e[t_{fi}]\\ ] ] since this would imply certain vertices in @xmath116 are being visited repeatedly .",
    "ad works by progressively sampling larger regions of @xmath26 until it identifies a subgraph @xmath119 induced by a vertex set @xmath120 such that @xmath121 . once @xmath119 is identified either of the spectral methods can be used directly over @xmath119 .",
    "the method will be efficient as long as @xmath122 and the number of steps taken to identify @xmath119 is comparable to the computational cost of using spectral sampling over @xmath119 . formally , @xmath113 can be exactly discovered by repeatedly enlarging the discovered graph to include the last vertex outside @xmath119 visited by the trajectory . if spectral sampling for a graph of vertex set size @xmath4 works in time @xmath123 , this procedure would ensure that implementing spectral sampling in conjunction with automated discovery takes @xmath124 steps . the stiffness condition ( eqn .  [ stiffad ] ) would usually ensure that this procedure is still efficient . *",
    "b * another method for discovering the trapped subgraph would be to implement the ssa random walk for a specified number of steps @xmath125(depending on the size of the vertex set @xmath4 ) .",
    "since eigenvalue methods are in general @xmath126 , we can implement ssa until @xmath127 for some constant @xmath58 , to discover the trapped subgraph @xmath128 and then use spectral sampling to escape the discovered graph .",
    "this alternative approach could be less efficient in some circumstances , but would guarantee that the overhead for spectral sampling is no more than a constant factor beyond that of the standard ssa .",
    "[ adpcode ] shows the pseudocode for implementing ad for a given graph by this method .",
    "the algorithm generates a sample trajectory using ssa till such time that the trajectory spends @xmath126 steps within a trapped graph @xmath128 of vertex set cardinality @xmath129 .",
    "then either of the spectral methods described in section [ spec1 ] or [ spec2 ] are used to sample the first passage outside @xmath128 , to a vertex @xmath130 .",
    "in general the state of the system at the time of first passage outside @xmath128 will be a discrete probability mixture of more than one vertices .",
    "in such cases , the vertex @xmath130 is randomly selected in accordance with the appropriate probability weight .",
    "the algorithm then resumes ssa execution over the enlarged graph @xmath131.*e * further investigation is , however , required to search for algorithms that may further improve the performance of ad . in section [ latticead ]",
    "we prove that for at least one important class of graphs , namely models of chemically reacting species , we can indeed reduce the time complexity to its optimal value to within a constant factor , _",
    "i.e. _ , @xmath132 .",
    "in order to validate the methods , we instantiate them for some specific challenging systems . we begin by demonstrating the non - ad variants of the methods for the problem of sampling the time required to break a network of bonds .",
    "this problem is an example of a stiff ssa on a generally small graph .",
    "it is also of independent interest because of its importance in modeling self - assembly processes on long time scales .",
    "given such a system , we are interested here in the first passage time to the subset of states corresponding to disconnected graphs @xmath133 .",
    "since each bond can occur in two states , intact or broken , a network of @xmath107 bonds can be represented as a vertex on a unit hypercube in @xmath107 dimensions .",
    "the state space generated by the bond network before it becomes disconnected will usually be a truncated unit hypercube .",
    "an n - cycle @xmath52 generates the simplest non - trivial example , where the absorbing boundary is placed at all points on the hypercube at distance 2 from the fully - connected state .",
    "fig.[ssa](c ) illustrates this absorbing boundary for @xmath134 .",
    "given a @xmath107-bond network , we will represent the @xmath135 bond - breaking rate by @xmath136 and association or binding rate by @xmath137 .",
    "it is convenient to represent a vertex on this hypercube by a binary @xmath107-tuple @xmath138 , where @xmath139 implies that the @xmath135 bond is intact ( see fig .",
    "[ ssa](c ) for the graph corresponding to a trimer ) . from here on , we will use the notation @xmath140 for the vector describing a state of the model with only the @xmath135 bond broken .",
    "for such a graph , the time complexity of each ssa step is @xmath141 . in the rest of this paper we will use this model of truncated hypercubes to represent bond networks .",
    "morris and sinclair@xcite have proven that in the case of unweighted graphs , a random walk on a hypercube truncated by a hyperplane relaxes to equilibrium in polynomial time bounded by @xmath142 for any @xmath143 . however , as we have argued in the introduction , the mean _ hitting time _",
    ", i.e. , the number of random walk steps between a pair of vertices , can be extremely sensitive to the parameters governing the walk .",
    "we formalize this observation in the theorem  [ ssacon ] below , which bounds the expected number of ssa steps before the network is disconnected .",
    "let @xmath144 .",
    "[ ssacon ] the expected number of ssa steps required to break a @xmath145-connected network with @xmath146 and @xmath147 is @xmath148 .",
    "a detailed proof of the theorem is provided in the appendix . figs .",
    "[ cnssasteps ] and [ znssasteps ] provide an empirical demonstration of the theorem .",
    "[ cnssasteps ] analyzes the number of steps required in 100 trials of the ssa algorithm for simulating the breakage of a set of cycle graphs @xmath149 ranging in size from three to seven .",
    "each model was examined using ratios of forward to backward rate from 1 to 20 in increments of 1 .",
    "breakage times for the cycle graphs increase linearly with rate ratio , although they also fall monotonically with cycle size ( fig .",
    "[ cnssasteps](a ) ) . fig .",
    "[ znssasteps ] analyzes the number of steps required to break k - connected hypercube graphs of dimensions @xmath150 .",
    "[ znssasteps](a ) also shows that the slope of a log - log plot approaches the predicted exponent @xmath151 .",
    "[ cnssasteps](b ) and [ znssasteps](b ) suggest why a spectral approach might be effective  as the reaction rate increases , steps to first passage behave more like a geometric random variable ( as mean @xmath152 , standard deviation @xmath153 mean ) , as expected for a slowly decaying eigen mode of the transition matrix .",
    "more detailed explanations of the simulation protocol for these figures is provided in section [ netmod ] .    .",
    "( a ) average number of steps @xmath154 ( b ) relative deviation @xmath155    .",
    "( a ) a @xmath156 plot of the average number of steps @xmath157 versus rate ratio @xmath89 ( b ) relative deviation @xmath155        we illustrate the master equation spectral method using the cycle graph @xmath52 as an example .",
    "this is a graph of @xmath4 vertices and @xmath4 edges , connected together in a loop such that exactly two edges need to be removed to disconnect the graph ( called a _ separation pair _ ) .",
    "the state space is @xmath158 . in this case",
    ", the subspace @xmath159 defines the absorbing boundary and the subspace @xmath160 defines the space of _ transient _ states .",
    "we begin with the most general form for @xmath30 , the projection of @xmath7 onto the subspace @xmath161 .",
    "@xmath162    in what follows , we assume that all the eigenvalues of @xmath30 are negative ( as they must be over the subset of _ transient states _ since @xmath163 ensures any positive probability density decays to zero ) and that the set of rates @xmath164 and @xmath165 are positive ( ensured by property 1 of @xmath7 ) . for economy of notation , let us define @xmath166 . also , in what follows we assume that the bond indices have been labeled such that @xmath167 . in the case of a @xmath52 network , the @xmath168 distribution can be efficiently sampled due to certain properties of the eigenvalue distribution and the form of the eigenvectors .",
    "since the sampling technique for a general ctmm will be an extension of this special case , it will be helpful to illustrate the method by investigating the spectral properties of @xmath52 .",
    "the next few results establish bounds on the eigenvalues of @xmath30 as a special case of the interlacing eigenvalue theorem  @xcite .",
    "the @xmath169 eigenvalues @xmath170 of the matrix @xmath30 in eq .",
    "[ cnmat ] satisfy the following :    1 .   if @xmath171 then @xmath172 is an eigenvalue of @xmath30 .",
    "if @xmath10 such diagonal elements are identical then the eigenvalue is @xmath173-fold degenerate .",
    "there is at least one eigenvalue of @xmath30 in the interval @xmath174 .",
    "the _ eigenvalue _ condition @xmath175 implies that the eigenvalues @xmath176 are the zeroes of an @xmath177 order polynomial : @xmath178 we establish bounds on the roots by calculating the sign of @xmath179 over the set of points @xmath180 .    1 .",
    "each term inside the summation sign in @xmath179 contains @xmath181 factors of @xmath182 .",
    "hence @xmath172 is an @xmath173-fold degenerate eigenvalue . in what follows",
    "we assume that the remaining @xmath183 are all distinct .",
    "2 .   the sign of the function @xmath179 at @xmath184 is @xmath185 .",
    "hence @xmath186 encloses at least one root of @xmath179 .",
    "the eigenvectors of @xmath30 @xmath187 are mutually orthogonal for the set of non - degenerate eigenvalues . in the case of non - degenerate eigenvalues ( @xmath188 ) , these eigenvectors are : @xmath189 where @xmath190 is a normalization constant . for degenerate eigenvalues , an orthogonal basis can always be chosen using the _ gram - schmidt _ procedure . as will become apparent later , however , these eigenvalues do not contribute to the sampling in the case of a first - passage problem beginning with the unbroken loop @xmath191 .",
    "[ dismix ] the envelope curve @xmath51 defined by our method is identical to the first passage density for a @xmath52 network .    beginning with an unbroken state at @xmath192",
    ", the probability the model occupies a given state @xmath10 at time @xmath13 is given by : @xmath193 = \\sum_{\\alpha=0}^{n}c_{\\alpha , n}\\exp[-\\lambda_{\\alpha}t]\\ ] ] where @xmath194 is an eigenvector of @xmath195 with eigenvalue @xmath68 .",
    "note that only those @xmath196 contribute , for otherwise @xmath197 .",
    "assuming @xmath198 , the coefficients satisfy @xmath199 for @xmath200 . since the partial sum @xmath201 , all other partial sums satisfy @xmath202 .",
    "these observations provide a means of decomposing the probability density into the following discrete mixture with positive coefficients : @xmath203-\\exp[-\\lambda_{\\alpha + 1}t])\\ ] ] since @xmath204 , the combined rate of decay to any one of the broken states is given by : @xmath205 where , @xmath206 and @xmath207 - \\exp[-\\lambda_{\\alpha+1}t])\\ ] ]      although our methods can in principle sample escape times from any subnetwork of a ctmm graph , we have validated them here for the specific case of breaking networks of bonds due to the importance of this problem for self - assembly modeling . in rule - based models of self - assembly",
    ", a simulation is initialized with a set of assembly subunits , each with a complement of pre - specified binding sites . as the simulation progresses ,",
    "the system evolves into a state with an assembly of disjoint networks .",
    "the binding interactions between two disconnected pieces of the network usually occurs on a slower scale than individual bond breaking reactions@xcite . for bi - connected networks ,",
    "however , the association rate within a connected network is much larger than the bond breaking rate since there is no entropy penalty in associating bonds between constituent subunits .",
    "such models allow for a natural partitioning of the state space into subgraphs corresponding to the bi - connected components of the entire network .",
    "the first set of experiments that we performed were on such bi - connected networks .",
    "the simplest non - trivial example of a bi - connected bond network is the graph generated by an @xmath4-cycle ( @xmath52 ) .",
    "more complicated networks of @xmath4 bonds can be viewed as special cases of a truncated unit hypercube in @xmath4 dimensions .",
    "we therefore carried out simulations for the network generated by @xmath52 as well as the full hypercube ( @xmath208 ) .",
    "theorem [ ssacon ] guarantees that the expected number of ssa steps for a @xmath145-connected network of @xmath107 bonds is @xmath209 , where @xmath210 is some combinatorial function dependent on the topology of the network .",
    "each model is parameterized by a rate of bond formation , @xmath2 , and a rate of bond breaking , @xmath0 .",
    "these values were varied in different simulations .",
    "each of the bonds had different binding / breaking rates but the ratio was maintained at the same order of magnitude for each simulation .",
    "specifically , for a @xmath107 bond network @xmath211 and @xmath212 .",
    "these slight variations in rates from bond to bond were used to avoid giving our methods an unfair advantage , as they will generally be more efficient when the transition matrix has degenerate eigenvalues .",
    "we conducted a series of simulations to determine the performance of the ssa , master equation , and emc methods for bond network first - passage times .",
    "all simulations were implemented in mathematica .",
    "run time simulations were executed on a macintosh machine with a 1.8ghz g5 processor and 512 mb ram . for the emc based spectral method",
    ", we allowed each component of the state vector to converge within a relative error of @xmath213 .",
    "each data point reported was the average over 500 simulations except for run time data , which were averaged over 100 simulations .",
    "we first examined the efficiency of the master equation method by assessing the number of rejection steps needed to sample each first - passage time .",
    "we carried out simulations for cycle graphs ( @xmath149 ) varying the cycle length from 3 to 7 and the rate ratio @xmath214 from 1 to 20 in increments of 1 .",
    "these experiments were then repeated for unit hypercubes ( @xmath215 ) with dimension varied from 2 to 5 and rate ratio @xmath214 from 1 to 10 in increments of 1 . for each condition , we recorded the number of rejection steps required for each of 500 simulations and computed the mean and standard deviation across the 500 trials .",
    "we next examined the number of steps required by the emc method for sampling times to network breakage .",
    "we examined the same models as those used to validate the master equation method : cycles of length 3 to 7 with rate ratios from 1 to 20 in increments of 1 and hypercubes of dimension 2 to 5 with rate ratios from 1 to 10 in increments of 1 .",
    "we similarly recorded the number of emc steps required for each of 500 simulations and computed the mean and standard deviation across the 500 trials .",
    "we also computed the fraction of models that reached the first passage time before relaxing to the slowest decay mode .",
    "we next tested the total run time of each of the three methods on a broader set of parameter ranges .",
    "we evaluated run times for each method for cycle networks of sizes 3 through 7 .",
    "we performed two sets of evaluations for each .",
    "the first set varied the rate ratio @xmath214 from 500 to 5000 in increments of 500 to provide a broad view of the relative run times of the three methods .",
    "these numbers span ranges of values likely for protein assemblies .",
    "for example , zlotnick _ _ et al.__@xcite have estimated a binding free energy of @xmath216 kcal / mole for ode based simulation of the kinetics of the hepatitis b virus , which yields @xmath217 .",
    "we then examined ratios of ssa to master equation and ssa to emc run times for each data point based on averages over 100 simulations per parameter set . in a second set of experiments , designed to give a finer view of where each method is dominant in parameter space",
    ", we varied the rate ratio @xmath214 from 30 to 300 in increments of 30 .",
    "we then identified the most efficient of the three methods for each point , again using averaged run times over 100 trials per data point .",
    "we then performed analogous experiments for hypercube graphs in order to test performance on networks with higher connectivity . for each graph @xmath218 to @xmath219",
    ", we carried out simulations for rate ratio @xmath214 from 3 to 30 in increments of 3 .",
    "we were limited to small ratios because the ssa method becomes prohibitively costly for high - connectivity networks at higher ratios .",
    "each simulation was repeated 100 times to yield average run times for each parameter set and for each of the three methods . for each parameter",
    "set , we computed the ratio of run times for ssa versus master equation and ssa versus emc .",
    "we further evaluated which of the three methods produced the shortest average run time for each parameter set .",
    "we first present results on the efficiency of the rejection sampling scheme for the master equation method .",
    "the expected run time of the method is proportional to the expected number of trials needed to produce a successful sample .",
    "a low number of steps is therefore preferable , with a value of one being ideal .",
    "[ cnmesteps](a ) shows the rejection ratio for cycle graphs @xmath220 through @xmath221 .",
    "the mean number of rejection steps is consistently below 1.5 , as expected from theorem [ dismix ] and [ rratio ] .",
    "the number of rejection steps drops with increasing rate ratio but increases with increasing cycle length .",
    "these results together establish the efficiency of the method .",
    "[ cnmesteps](b ) shows that the method is also robust , with standard deviation consistently below 0.9 for the experiments shown here .",
    "the standard deviation also decreases with increasing rate ratio but increases with cycle size .",
    "[ znmesteps](a ) shows mean numbers of rejection steps for hypercube graphs .",
    "since the envelope curve for hypercubes is not exact , these experiments provide information about how well the method performs for more general networks .",
    "the hypercube graphs also yield mean numbers of rejection steps consistently below 1.5 .",
    "the number of steps generally falls with increasing rate ratio .",
    "[ znmesteps](b ) shows the method also to be robust for hypercube graphs , with standard deviations consistently below 1.0 and following similar trends to the means .",
    "( a ) average number of steps @xmath154 ( b ) standard deviation @xmath222     ( a ) average number of steps @xmath154 ( b ) standard deviation @xmath222    next , we performed identical experiments to study the performance of the emc - based spectral method .",
    "[ cnemcsteps](a ) shows mean numbers of emc steps for cycle graphs .",
    "the number of steps remains consistently below 6 .",
    "the values rise sharply at the lowest rate ratios , but quickly level off to approximately 4 - 5 , depending on the cycle length . figs .",
    "[ cnemcsteps ] ( b ) and ( c ) provide the explanation for this feature . for small rate ratio ,",
    "multiple eigen modes are responsible for the decay ( see part ( c ) ) , which corresponds to increasing emc steps before first passage , similar to ssa . however , as rate ratio increases further , relaxation time to the slowest eigen mode becomes smaller than the average first passage time and the method automatically samples breaking times according to the slowest eigen mode ( fig [ cnemcsteps](c ) ) .",
    "this feature is evident in part ( b ) of the figures , which measure the standard deviation . at high rate ratio",
    "the `` trajectory '' is almost deterministic , i.e. , it always takes the same number of steps to break the network .",
    "this happens because the state almost always relaxes to the slowest eigen mode before escaping the subgraph , hence giving a low value for @xmath223 at high rate ratio .",
    "[ znemcsteps ] shows comparable results for hypercube graphs .",
    "[ znemcsteps](a ) shows that mean numbers of steps drop substantially between ratios 1 and 2 but quickly level off to an apparent constant for each graph .",
    "the number of steps increases with increasing hypercube dimension .",
    "figs .  [ znemcsteps](b ) and ( c ) again show that the method has high variability for low rate ratios , where multiple eigen modes contribute significantly to the time distribution and the method must behave similarly to the standard ssa . at higher ratios , though , the slowest mode quickly dominates and the number of steps required becomes highly reproducible .",
    "( a ) average number of steps @xmath154 ( b ) standard deviation @xmath224 ( c ) fraction of times the trajectory escapes before relaxing to the slowest decay mode . ]     ( a ) average number of steps @xmath154 ( b ) standard deviation @xmath224(c ) fraction of times the trajectory escapes before relaxing to the slowest decay mode . ]",
    "we next examined total run times of the three methods , beginning with the cycle graphs @xmath134 to @xmath225 .",
    "[ cyclefig ] plots results of the emc and master equation methods relative to the basic ssa . fig .",
    "[ cyclefig](a ) shows ratios of run times for standard ssa to the master equation method .",
    "the ratio grows rapidly with increasing rate ratio , although it falls with increasing cycle size .",
    "[ cyclefig](b ) shows the comparison of ssa to the emc method .",
    "the ssa : emc ratio likewise peaks for large rate ratios and small cycle sizes .",
    "the emc method appears generally superior to the master equation method , beginning to dominate at a lower rate ratio and reaching a higher peak .",
    "[ cyclefig](c ) shows for a narrower rate range where each of the three methods dominates .",
    "the emc method is the fastest for most of the range examined , with the standard ssa superior at the extreme of low ratios and large cycle sizes .",
    "( a ) ratio of ssa to master equation run times ( b ) ratio of ssa to emc run times ( c ) region in 2d parameter space where each method is optimal ]     ( a ) ratio of ssa to master equation run times ( b ) ratio of ssa to emc run times ( c ) region in 2d parameter space where each method is optimal ]    we then examined run times on the hypercube graphs @xmath226 to @xmath227 .",
    "[ cubefig](a ) shows run time ratios for ssa versus the master equation method and fig .",
    "[ cubefig](b ) for ssa versus the emc method .",
    "both spectral methods show sizable improvements over the pure ssa method for larger rate ratios and higher hypercube dimensions .",
    "ssa appears much more sensitive to rate ratio as compared to the spectral methods . even for a rate ratio of 30 ,",
    "the spectral methods were more than three orders of magnitude more efficient than ssa for @xmath219 .",
    "for hypercubes , unlike cycle graphs , the master equation method appears generally more efficient than the emc - based method , even for small rate ratios .",
    "fig.[cubefig](c ) shows where each method is dominant .",
    "the master equation method is dominant for most of the parameter range examined , with the ssa method superior at the limit of lowest degree and smallest rate ratios and the emc dominant for low degree and higher rate ratios .",
    "this result is expected from fig . [ znssasteps](a ) , since the average number of steps seems to increase monotonically with the connectivity of the graph for the emc - based method .",
    "the efficiency of the master equation method , on the other hand , depends primarily upon the size of the complete graph , since matrix diagonalization is the eventual efficiency bottleneck .",
    "in this section , we apply the ad variants of the methods to a different system type also motivated by self - assembly modeling .",
    "the rate of a self - assembly processes is often limited by the time required to build the first stable multi - subunit complex , called a nucleus , which then acts as a seed for assembly of the rest of a larger structure . because partially formed nuclei are unstable , considerable trial - and - error may be needed before one reaches completion .",
    "the time to complete a single nucleus can thus be orders of magnitude longer than the inter - subunit binding rate .",
    "these nucleation - limited assembly systems are one example of the broader class of stiff models for chemically reacting species .",
    "the state space of any such a system can be represented as a lattice corresponding to the populations individual species .",
    "these models are similar to those treated in earlier studies of accelerated ssa methods @xcite .",
    "we apply one such model , representing the formation of simple trimeric nuclei , to demonstrate and evaluate the ad variants of the spectral methods .      the second model we consider is again an assembly of bond networks where monomers ( @xmath9 ) with two identical binding sites combine to form dimers ( @xmath107 ) and trimers ( @xmath13 ) . in order to show stiffness with respect to a single parameter",
    ", the trimers were assumed to be completely stable .",
    "if the total number of monomer subunits is @xmath4 , the state space is the intersection of the plane @xmath228 with the positive octant of the 3 dimensional lattice formed by integer counts of the monomer ( @xmath229 ) , dimer ( @xmath230 ) and trimer ( @xmath231 ) populations .",
    "let us represent each vertex of this graph by the pair @xmath232 .",
    "the reaction propensities @xmath233 to reach the vertex @xmath234 from @xmath235 are ( to within an overall constant ) @xmath236 where @xmath237 is an entropy penalty due to the finite volume of the system .",
    "we initialize the system at the state @xmath238 for a given monomer count @xmath4 and sample the first passage time until the trimer count reaches a given value .",
    "this system will show stiffness if the parameter @xmath239 is small . for small @xmath240 , which corresponds to low concentration and/or small binding energy , trimer formation will be much slower than dimer breaking / binding reactions .",
    "efficient simulation over an integer lattice , where one pair of species react on a much faster timescale than the others requires a partitioning of the entire lattice into subgraphs with fixed trimer count ( since trimer formation occurs on a much longer timescale than monomer - dimer reactions ) .",
    "these subgraphs are simple paths with vertex set @xmath241)\\}$ ] , where @xmath242 represents the fixed trimer count and square brackets represent the largest integer smaller than the enclosed expression .",
    "[ pathpcode ] presents a procedure for implementing automated discovery on such graphs which works in optimal time , to within a small constant factor ( the vertices are represented by dimer count for simplicity ) .        at each step of automated discovery",
    "the method enlarges the graph by a factor proportional to its present length .",
    "the scale factor @xmath9 can be optimized for any given sampling algorithm to optimize run time .",
    "for example , if a given spectral sampling algorithm works in time @xmath243 , where @xmath4 is the cardinality of the vertex set ; total number of steps used in automated discovery of a graph sized @xmath244 can be bounded from above by the following quantity @xmath245 , @xmath246}}m^{n\\alpha } \\leq \\frac{n_i^{\\alpha}m^{2\\alpha } -1}{m^\\alpha -1 } \\nonumber\\\\ & \\leq & c n_{i}^{\\alpha } \\textrm { for } m = 2^{1/(\\alpha+1)}\\end{aligned}\\ ] ] where , @xmath247 . in general the master equation based method works in @xmath126 , however for simple paths the kolmogorov matrix is sparse and effective power is expected to be more like @xmath248 . since @xmath245 is more sensitive to deviations for smaller values of @xmath9 , we chose @xmath249 in the experiments reported here .",
    "the method reported here can in principle be generalized for arbitrary lattice graphs in @xmath107 dimensions .",
    "the size of the discovered graph in such cases would overestimate the actual trapped graph by a factor of @xmath250 , for a scaling factor @xmath9 . for small dimensions",
    ", this may still be more efficient than the method discussed in section [ ad ] which exactly samples the trapped subgraph .",
    "we performed two sets of experiments to compare the performance of spectral methods with ssa .",
    "the first set of experiments compared the master equation method implemented in conjunction with automated discovery for the trimer model with ssa .",
    "each experiment compared the ratio of run times for sampling first passage times to reach a trimer count @xmath251 , starting from an initial monomer count @xmath4 .",
    "the state space was partitioned into subgraphs corresponding to fixed trimer counts and ad was used to identify the trapped regions for spectral decomposition .",
    "we then performed a total of 50 comparative run time simulations varying @xmath4 from 1000 to 9000 in steps of 2000 and varying @xmath240 from @xmath252 to @xmath253 in steps of @xmath254 .",
    "all run times were averaged over 50 samples . the scale factor for ad was set at 1.3 .",
    "the second set of experiments compared the run time ratio for the emc based method and ssa for first passage time to reach a trimer count @xmath251 , starting from an initial monomer count @xmath4 .",
    "the state space was again partitioned into subgraphs of fixed trimer counts .",
    "ad was not required for these simulations since the method automatically selects the trapped region of the subgraph according to the evolving probability distribution .",
    "we then performed a total of 25 comparative run time simulations varying @xmath4 from 1000 to 9000 in steps of 2000 and varying @xmath240 from @xmath255 to @xmath256 in steps of @xmath257 .",
    "all run times were averaged over 50 samples . for the spectral method , each component of the slowest eigenvector was allowed to relax to within a relative error of 0.01 and an absolute error of @xmath258 .",
    "we first present results for the master equation method run times as we vary the stiffness parameter @xmath240 .",
    "fig [ latticefig](a ) shows the behavior for 5 different initial monomer counts @xmath4 .",
    "small @xmath240 values correspond to a stiff model , since the average dimer count varies approximately as @xmath259 and the ratio of the rate of dimer formation to trimer formation varies as @xmath260 .",
    "[ latticefig](a ) demonstrates the efficiency of the master equation method .",
    "the method shows large gains in the domain of small @xmath240 and small @xmath4 , with relative performance dropping rapidly with increasing @xmath240 and more slowly with increasing @xmath4 .",
    "next we present results for the ratio of ssa / emc method run times as we vary @xmath240 and @xmath4 .",
    "[ latticefig](b ) shows the behavior for 5 different initial monomer counts @xmath4 .",
    "the emc method is effective at substantially larger values of @xmath240 than is the master equation method .",
    "as is to be expected , the spectral methods do not scale as well as the usual ssa method with increasing @xmath4 .",
    "even for relatively large networks , though , the performance gain obtained by spectral sampling is appreciable .",
    "the reason for this is that for most cases the slowest eigen mode is reasonably well approximated by a vector populating only a small fraction of the subgraph vertices . as a result",
    "we can look at the emc method as a generalization of other accelerated sampling schemes which only use one vertex , the mean value of the slowest decay mode , as in the pea based methods .",
    "we have investigated the problem of efficiently simulating stochastic reaction models and introduced two methods for accelerating sampling on problems characterized by multiple time scales .",
    "both methods are based on spectral analysis of ctmms equivalent to the ssa model .",
    "we have applied these methods in the present work to two special cases of these models that are important to simulations of molecular self - assembly : sampling times to break multiply - connected bond networks and simulating growth in nucleation - limited assembly systems .",
    "collectively , these two applications demonstrate the use of the proposed spectral methods on small ctmm graphs known _ a priori _ and on automatically discovered subgraphs of large ctmms .",
    "we have shown theoretically and empirically that the new methods are substantially more robust to variations in the ratios of reaction rates than is the basic ssa method for these problems .    while we have applied these methods here to models used in self - assembly simulations ,",
    "the basic methods can be expected to have much broader application .",
    "both methods can be applied to sample first passage times for any arbitrary subset of states of any ssa ctmm graph .",
    "both can also be applied to sample escape times from any subgraph of such a graph , using automated discovery to identify `` trapped '' regions of the ctmm graph .",
    "the latter distinction is important because ctmm graphs for complicated biological systems are generally far too large to represent explicitly .",
    "these spectral methods might be extended to incorporate `` on the fly '' graph construction techniques , like those used by rule - based methods widely used for ssa simulations  @xcite .",
    "the emc method , especially , would seem to be a candidate for such an extension . for example , if at each iteration , instead of adding all the possible next neighbors to the system state , we add only a subset of them depending upon their transition probabilities then we will get a natural , _ non - local _ generalization of the ssa .",
    "such an approach could provide a precise and general method for pruning full ssa graphs to achieve more efficient pathway sampling in extremely large state spaces .        in this appendix , we prove thm .",
    "[ ssacon ] , which helps us establish the relative efficiency of the spectral methods to the standard ssa .",
    "before we prove the theorem , we need to establish some preliminary results .",
    "let @xmath261 . to construct the transition matrix @xmath262",
    ", ssa identifies the negative of the diagonal element of the kolmogorov matrix @xmath263 as the inverse of the mean waiting time at each ssa step and the matrix @xmath264 as the graph laplacian .",
    "therefore , @xmath265 . since ssa simulates a periodic markov chain @xmath262 , the graph is bipartite and the two step chain @xmath266 is reducible into @xmath267 . here , @xmath268 is the projection of @xmath266 over the subspace of states with an even number of bonds broken @xmath269 and @xmath270 is the projection over @xmath271 .",
    "since both @xmath268 and @xmath270 are irreducible and aperiodic , the ergodic theorem applies to each one separately and if @xmath272 is the eigenvector of @xmath262 with eigenvalue 1 , the vectors @xmath273 and @xmath274 are the equilibrium distributions for @xmath268 and @xmath270 , respectively , up to a normalization constant . to bound the mean hitting time @xmath275 , from @xmath276 to the set @xmath277 , we first apply the common technique of constructing another graph with vertex set @xmath278 , where all vertices in @xmath277 are truncated to a single vertex @xmath279 and @xmath280 .",
    "the edge weights for edges from @xmath281 to @xmath279 are chosen as @xmath282 , which will leave @xmath275 unchanged from that of the original graph .",
    "we must further specify the edge weights from @xmath279 to any states with @xmath151 broken bonds . in order to ensure that the markov chain still obeys detailed balance , we require that @xmath283 and @xmath284",
    ". the resulting modified graph will then have the same hitting time @xmath275 as the original graph .",
    "[ ctime]for an ergodic markov chain , the cover time @xmath285 between any two states @xmath286 and @xmath287 satisfies  @xcite @xmath288=e[t_{\\bm{i}\\bm{j } } ] + e[t_{\\bm{j}\\bm{i } } ] = 1/(\\pi_{\\bm{j}}pr[t_{\\bm{j}\\bm{j}}>t_{\\bm{i}\\bm{j}}])\\ ] ]      1 .",
    "if @xmath286 and @xmath289 are two neighboring states with @xmath10 and @xmath290 bonds broken , respectively , then @xmath291 for any @xmath292 .",
    "2 .   for any initial state @xmath286 containing @xmath10 broken bonds , the @xmath10-step transition probability to @xmath276",
    "is bounded from below by @xmath293 .",
    "3 .   let @xmath294 be any stopping time for the transition matrix @xmath262 with expectation value @xmath295=\\sum_{n=1 } n pr[t = n]=\\sum_{n=0}pr[t > n]$ ] .",
    "for any integer @xmath296 consider the expectation value of @xmath294 for the @xmath297-step transition matrix @xmath298 defined as @xmath299 = \\sum_{n } n pr[(n-1)*l < t \\leq n*l ] = \\sum_{n=0 } pr[t > n*l]$ ] .",
    "then , @xmath300 - 1)\\leq e[t ] \\leq l e^{(l)}[t]$ ] .    1 .",
    "the transition probability corresponding to the matrix element connecting @xmath286 to @xmath287 is : @xmath301 2 .",
    "first consider any state @xmath302 with one bond broken : @xmath303 assume @xmath304 for all @xmath10 broken bond states @xmath305 , then @xmath306 since @xmath307 , the assertion holds for all @xmath308 by induction .",
    "3 .   we can prove the upper bound as follows : @xmath309&= & \\sum_{n=1 } \\left ( \\sum_{m=1}^{l } ( ( n-1)l + m)pr[t=((n-1)l + m)]\\right)\\nonumber \\\\ & \\leq & \\sum_{n=1 } n*l\\left(\\sum_{m=1}^{l}pr[t=((n-1)l + m)]\\right)\\nonumber \\\\ & \\leq & l\\sum_{n=1 } n pr [ ( n-1)l <",
    "t \\leq n*l ] \\nonumber \\\\ & \\leq & l e^{(l)}[t]\\nonumber \\\\\\end{aligned}\\ ] ] we can similarly prove the lower bound : @xmath309&= & \\sum_{n=1 } \\left ( \\sum_{m=1}^{l } ( ( n-1)l + m)pr[t=((n-1)l + m)]\\right)\\nonumber \\\\ & \\geq&\\sum_{n=1 } ( n-1)*l\\left(\\sum_{m=1}^{l}pr[t=((n-1)l + m)]\\right ) \\nonumber \\\\   & \\geq & l\\sum_{n=1 } n pr [ ( n-1)l < t \\leq n*l ] - l \\nonumber \\\\ & \\geq & l(e^{(l)}[t]-1)\\end{aligned}\\ ] ]      the lower bound is trivial since at least @xmath145 bonds must be repaired before any disconnected state can reach @xmath276 . consider the @xmath311 step probability for transition from @xmath279 to @xmath276 .",
    "let @xmath312 be the transition matrix restricted to the set @xmath313 , i.e. , @xmath314 the probability of a trajectory starting at @xmath315 reaching @xmath276 in @xmath145 steps or less is given by @xmath316&= & 1-\\sum_{\\bm{j}\\in\\tilde{v}}\\tilde{q}_{\\bm{j},\\bm{i}}^{k}=\\sum_{n=1}^{k}\\left(\\sum_{l\\in\\tilde{v } } q_{\\bm{0},\\bm{l}}\\tilde{q}_{\\bm{l},\\bm{i}}^{n-1}\\right)\\nonumber \\\\ & \\geq & q_{\\bm{0},\\bm{b}}^{k}>(1+d / r)^{-k}\\end{aligned}\\ ] ] where we have used lemma [ qbounds ] part ( 2 ) .",
    "let us define @xmath317 . in terms of @xmath318 , the previous inequality and lemma [ qbounds ] part",
    "( 3 ) imply @xmath319&= & 1- pr[t_{\\bm{0}\\bm{b}}\\leq n*k]\\leq(1-p)^{n}\\nonumber \\\\",
    "\\rightarrow e^{(k)}[t_{\\bm{0}\\bm{b } } ] & \\leq & \\sum_{n=1}^{\\infty}(1-p)^{n}=1/p\\nonumber \\\\",
    "e^{(k)}[t_{\\bm{0}\\bm{b } } ] & \\leq & ( 1+d / r)^{k } \\nonumber \\\\ \\rightarrow e[t_{\\bm{0}\\bm{b } } ] & \\leq & k(1+d / r)^{k}\\end{aligned}\\ ] ]    an immediate consequence of the previous lemma is that for @xmath145 even @xmath320 \\leq ( k/2 ) ( 1+d / r)^{k } + 1\\ ] ] similarly , if @xmath145 is odd , using the fact that @xmath321=0 $ ] we get @xmath322 \\leq e[t_{\\bm{0}\\bm{b}}]/2 + 1 \\leq \\frac{k}{2}(1+d / r)^{k } + 1\\ ] ] let us define the equilibrium probability for @xmath279 as @xmath323 , then @xmath324 we can finally compute upper ( @xmath325 ) and lower ( @xmath326 ) bounds on the hitting time @xmath275 which are asymptotically equivalent in the limit @xmath327 .",
    "the following theorem implies that @xmath328 is monotonically decreasing in @xmath89 and @xmath329  @xcite .      in order to apply lemma [ ctime ] to bound the hitting time we need to look at graphs with @xmath145 odd or even separately .",
    "if @xmath145 is even we can apply lemma [ ctime ] directly to @xmath331 for the 2-step chain @xmath332 .",
    "however , if @xmath145 is odd , we need to consider the cover time between @xmath279 and each state @xmath302 with exactly one broken bond .",
    "then , using the fact @xmath333 , we get : @xmath334 & = & 1 + \\frac{1}{\\sum_{\\nu}b_{\\nu}}\\sum_{\\mu}b_{\\mu}e[t_{\\bm{b}\\hat{\\bm{\\mu}}}]\\end{aligned}\\ ] ]    since @xmath335 = \\sum_{n > m } pr[t_{\\bm{b}\\bm{b}}=n]pr[t_{\\bm{0}\\bm{b}}=m]$ ] , for the @xmath145-step chain discussed in lemma [ atime ] we get : @xmath336 & \\leq & \\sum_{n=1}^\\infty \\left(\\frac{d}{r(1+d / r)}\\right)^{n } = d / r\\nonumber \\\\ \\rightarrow pr[t_{\\bm{b}\\bm{b}}>t_{\\bm{0}\\bm{b } } ] & \\geq & 1 - d / r\\end{aligned}\\ ] ] also , @xmath337 \\geq pr[t_{\\bm{b}\\bm{b}}>t_{\\bm{0}\\bm{b } } ] \\geq 1 - d / r$ ] .",
    "suppose @xmath145 is even .",
    "then we can estimate the cover time @xmath338 using lemma [ ctime ] .",
    "@xmath339&\\geq & 2*e^{(2)}[t_{\\bm{b}\\bm{0}}]-2 = 2*\\left ( \\frac{1}{\\tilde{\\pi}_{\\bm{b}}pr[t_{\\bm{b}\\bm{b}}>t_{\\bm{0}\\bm{b } } ] } - e^{(2)}[t_{\\bm{0}\\bm{b } } ] -1\\right ) \\nonumber \\\\ & \\leq & 2*e^{(2)}[t_{\\bm{b}\\bm{0 } } ] = 2*\\left ( \\frac{1}{\\tilde{\\pi}_{\\bm{b}}pr[t_{\\bm{b}\\bm{b}}>t_{\\bm{0}\\bm{b } } ] } - e^{(2)}[t_{\\bm{0}\\bm{b } } ] \\right)\\end{aligned}\\ ] ] an analogous argument for odd @xmath145 on using eq .",
    "[ kodd ] gives , @xmath339&\\geq & 1 + \\frac{1}{\\sum_{\\nu}b_{\\nu}}\\sum_{\\mu}b_{\\mu}\\left(\\frac{2}{\\tilde{\\pi}_{\\bm{b}}pr[t_{\\bm{b}\\bm{b}}>t_{\\hat{\\bm{\\mu}}\\bm{b } } ] } -2*e^{(2)}[t_{\\hat{\\bm{\\mu}}\\bm{b}}]-2\\right)\\nonumber \\\\ & \\leq & 1 + \\frac{1}{\\sum_{\\nu}b_{\\nu}}\\sum_{\\mu}b_{\\mu}\\left(\\frac{2}{\\tilde{\\pi}_{\\bm{b}}pr[t_{\\bm{b}\\bm{b}}>t_{\\hat{\\bm{\\mu}}\\bm{b } } ] } -2*e^{(2)}[t_{\\hat{\\bm{\\mu}}\\bm{b}}]\\right)\\end{aligned}\\ ] ] finally , using lemma [ ctime ] and [ atime ] we get for all @xmath145 , @xmath339 & \\geq & 2\\frac{1 - \\left(k/2(1 + d / r)^{k}+2\\right)\\tilde{\\pi}_{\\bm{b}}}{\\tilde{\\pi}_{\\bm{b}}}\\nonumber \\\\ & \\leq & 2\\frac { ( 1-d / r)^{-1 } - \\left((k-1)/2 \\right)\\tilde{\\pi}_{\\bm{b}}}{\\tilde{\\pi}_{\\bm{b}}}\\end{aligned}\\ ] ]",
    "let @xmath286 and @xmath340 be two graphs with @xmath341 and @xmath342 bonds broken respectively . since we are interested in computing the invariant distribution for the irreducible components @xmath268 and @xmath270 , we first compute each matrix element connecting @xmath286 to @xmath287 : @xmath343 similarly , @xmath344 detailed balance then implies that @xmath345 since @xmath346 we can deduce that for any state @xmath286 with @xmath341 bonds broken , with @xmath347 , the invariant probability @xmath348 . let , @xmath349 be the state with @xmath151 bonds broken for which @xmath350 is maximized .",
    "the choice of matrix elements imposed by detailed balance implies @xmath351 .",
    "also , since lemma [ qbounds ] implies @xmath352 we get for all values of @xmath145 : @xmath353 finally , using the lower bound on @xmath354 $ ] computed in preceding theorem we get @xmath339&\\geq & 2\\frac{1 - \\left(k/2(1 + d / r)^{k}+2\\right)\\tilde{\\pi}_{\\bm{b}}}{\\tilde{\\pi}_{\\bm{b}}}\\nonumber \\\\ & \\geq & p(d , k)*r^{k-1 } \\textbf { $ \\forall$ } r > r_{0}\\end{aligned}\\ ] ] where @xmath355 and @xmath356 .",
    "99 c. v. rao , d. m. wolf , and a. p. arkin , nature * 420 * , 231 ( 2002 ) .",
    "d. t. gillespie , j. comput .",
    "* 22 * , 403 ( 1976 ) .",
    "d. t. gillespie , j. phys .",
    "* 81 * , 2340 ( 1977 ) .",
    "h. h. mcadams , and a arkin , proc .",
    "sci . * 94 * , 814 ( 1997 ) .",
    "b. berger , p. w. shor , l. tucker - kellog , and j. king , proc .",
    "usa * 91 * , 7732 ( 1994 ) .",
    "t. zhang , and r. schwartz , biophys .",
    "j. * 90 * , 57 ( 2006 ) .",
    "k. takahashi , t. sakurada , k. kaizu , t. kitamaya , s. arjunam , t. ishida , g. bereczki , d. ito , m. sugimoto , t. komori , o. seiji , and m. tomita , genome informatics * 14 * 294 ( 2003 ) . c. j. morton - firth , and d. bray , j. theor .",
    "biol . * 192 * , 117 ( 1998 )",
    ". m. l. blinov , j. r. faeder , b. goldstein , and w. s. hlavacek , bioinformatics * 17 * , 3289 ( 2004 ) .",
    "l. lok , and r. brent , nat .",
    "* 23 * , 131 ( 2005 ) .",
    "d. t. gillespie , j. chem .",
    "* 115(4 ) * , 1716 ( 2001 ) .",
    "e. haseltine , and j. rawlings , j. chem .",
    "* 117 * , 6959 ( 2002 ) .",
    "p. ceres , and a. zlotnick , biochemistry * 41 * , 11525 ( 2002 ) .",
    "r. j. allen , p. b. warren , and p. r. ten wolde , phys .",
    "lett . * 94 * , 018104 ( 2005 ) .",
    "g. e. crooks , and d. chandler , phys .",
    "e * 64 * , 0261091 ( 2001 ) . c. dellago , p. g. bolhuis , and p. l. geissler , adv .",
    "phys . * 123 * , 1 ( 2002 ) .",
    "y. cao , d. t. gillespie , and l. r. petzold , j. chem .",
    "* 122 * , 014116 ( 2005 ) .",
    "y. cao , d. t. gillespie , and l. r. petzold , j. comput .",
    "206 * , 395 ( 2005 ) .",
    "n. g. van kampen , stochastic processes in physics and chemistry ( north - holland , amsterdam 1981 ) .",
    "w. h. press , s. a. teukolsky , w. t. vetterling , b. p. flannery , numerical recipes : the art of scientific computing ( cambridge univ . press ,",
    "cambridge 2007 ) .",
    "b. morris , and a. sinclair , siam j. comput . * 34 * , 195 ( 2005 ) .",
    "r. a. horn , and c. a. johnson , matrix analysis ( cambridge univ .",
    "press , cambridge 1985 ) .",
    "a. zlotnick , j. m. johnson , p. w. wingfield , s. j. stahl , and d. endres , biochemistry * 38 * , 14644 ( 1999 ) .",
    "d. aldous , and j. a. fill , reversible markov chains and random walks on graphs ( 2001 ) .",
    "http://www.stat.berkeley.edu/@xmath357aldous/rwg/book.html c. m. bender , and s. a. orszag , advanced mathematical methods for scientists and engineers ( mcgraw - hill book company , 1978 ) ."
  ],
  "abstract_text": [
    "<S> models of reaction chemistry based on the stochastic simulation algorithm ( ssa ) have become a crucial tool for simulating complicated biological reaction networks due to their ability to handle extremely complicated networks and to represent noise in small - scale chemistry . </S>",
    "<S> these methods can , however , become highly inefficient for stiff reaction systems , those in which different reaction channels operate on widely varying time scales . in this paper , we develop two methods for accelerating sampling in ssa models : an exact method and a scheme allowing for sampling accuracy up to any arbitrary error bound . </S>",
    "<S> both methods depend on analysis of the eigenvalues of continuous time markov models that define the behavior of the ssa . </S>",
    "<S> we show how each can be applied to accelerate sampling within known markov models or to sub - graphs discovered automatically during execution . </S>",
    "<S> we demonstrate these methods for two applications of sampling in stiff ssas that are important for modeling self - assembly reactions : sampling breakage times for multiply - connected bond networks and sampling assembly times for multi - subunit nucleation reactions . </S>",
    "<S> we show theoretically and empirically that our eigenvalue methods provide substantially reduced sampling times for a large class of models used in simulating self - assembly . </S>",
    "<S> these techniques are also likely to have broader use in accelerating ssa models so as to apply them to systems and parameter ranges that are currently computationally intractable . </S>"
  ]
}