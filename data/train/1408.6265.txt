{
  "article_text": [
    "studies of the variability in astronomical sources can reveal aspects that are not accessible to imaging , which is limited by the angular resolution of current instruments .",
    "for example , variability can be used to set limits on the sizes of the emitting regions through causality arguments ( e.g. , * ? ? ? * ) , to determine the size of the broad line region in active galactic nuclei ( e.g. , * ? ? ? * ) , or to detect extrasolar planets ( e.g. , * ? ? ? * ) among many other applications . in this paper",
    "we describe the practical implementation of a cross - correlation technique to determine the location of the gamma - ray emission site in blazars , by studying the relation between the variability in the radio and gamma - ray bands . for this purpose",
    "we are carrying out a blazar monitoring program with the owens valley radio observatory ( ovro ) 40 meter telescope @xcite and the large area telescope ( lat ) on board of the _ fermi gamma - ray space telescope _",
    "( _ fermi _ , * ? ? ? * ) .",
    "our approach is to search for correlated variability between these two energy bands , which would enable us to determine the location of the gamma - ray emission regions relative to the radio emission regions .",
    "the study of cross - correlations between two energy bands presents a number of challenges from the data analysis and statistical point of view : among these are uneven sampling , non - equal error bars , and short time duration of the light curves .",
    "the techniques we develop here should be useful for other applications .",
    "related methods have been presented in the literature , for example the study of cross - correlations with unevenly sampled light curves has an extensive literature about its application to reverberation mapping ( e.g. , * ? ? ?",
    "these methods present a detailed treatment of the estimation of cross - correlations and time lags , but not of the estimation of significance of the observed correlations , a critical aspect for the interpretation of cross - correlation results .",
    "the literature abounds with claims of statistically significant correlations that are not backed up by rigorous statistical analyses .",
    "this paper presents a detailed discussion of the methods used for our investigation of time - correlation between radio and gamma - ray activity in blazars , which is discussed in @xcite . here",
    "we present a description of the monte carlo method used to estimate the significance of cross - correlations between unevenly sampled time series using the method of @xcite . in order to estimate the distribution of cross - correlations in two uncorrelated data streams we need a model for the light curves .",
    "a commonly used model for time variability in blazars and other agns is a simple power - law power spectral density ( psd @xmath0 ) , as has been measured for a small number of sources at various wavelengths ( e.g. , * ? ? ?",
    "? * ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "the results presented in @xcite are of particular interest for the ovro blazar monitoring program . in their paper",
    ", they find a value of @xmath1 for bright bl lacs and @xmath2 for bright fsrqs in the gamma - ray band . in the radio band",
    "a number of publications have measured @xmath3 .",
    "it has been found that @xmath4 for 3c279 at 14.5 ghz @xcite using a fit to the psd for an 11 year light curve .",
    "additional indirect estimates for the psd power - law index are obtained by @xcite using structure function fits . for five sources ,",
    "they obtain values of @xmath5 to @xmath6 , where @xmath7 is the exponent on the structure function @xmath8 .",
    "the same method is used for 51 sources by @xcite who found that most values of @xmath7 lie between 0.6 and 1.8 , while a couple are closer to 0 .",
    "however , the often assumed relation between the exponents of the psd and the structure function ( @xmath9 ) is only valid under special conditions , not necessarily found in real data sets @xcite .",
    "the structure function has been widely used in blazar variability studies but its interpretation is not straightforward , as has been recently discussed by @xcite .",
    "these authors used simulations to demonstrate that many of the features in the structure function are associated with the length and sampling patterns of the light curves rather than anything of statistical significance .",
    "for these reasons , values obtained from the structure function can only be taken as a rough measure of the properties of the time series , and therefore we do not use them here .",
    "instead we fit the psds directly .",
    "we start by giving a brief description of the data sets used ( section [ observations ] ) , and then provide detailed descriptions of the methods in sections [ psd_estimation_method ] and [ cross_corr_method ] . in section [ psd_estimation_method ] we describe our approach to the critical problem of estimating a model for the light curves to use with the monte carlo significance estimate . here",
    "we describe an implementation of the method of @xcite that contains some important modifications . in section [ cross_corr_method ]",
    "we provide a description of a number of modifications we propose to common methods used to estimate the significance of cross - correlations .",
    "we give a justification for the use of the local normalization @xcite in the @xcite method , demonstrate the strong dependence of the significance estimate on the model light curves and introduce a bootstrap method to estimate the error in the cross - correlation significance estimates .",
    "we close the paper with a summary of our main findings and recommendations for the use of this and related techniques ( section [ conclusions ] ) .",
    "an important aspect of this work is the use of a statistically well - defined data set , where long light curves are used independent of the flaring state of the object .",
    "a fatal trap that many authors fall into is that of `` cherry picking '' the data by selecting small intervals of data .",
    "this approach can produce spurious levels of significance for the cross - correlations , and hence can not be used to draw conclusions about blazar populations , or the long term behaviour of individual sources .",
    "the methods we discuss in this paper can be adapted to use with any data set , but since we are describing a particular implementation , our simulated data sets are generated making some choices related to the intended application .",
    "these choices are motivated by the data sets associated with our blazar monitoring program in the radio and gamma - ray bands .",
    "these data sets are described in detail in @xcite and here we only summarize their main properties .",
    "a radio observation for each one of the monitored blazars is attempted twice per week , but because of the effects of weather and other technical problems we obtain unevenly sampled light curves @xcite . _ fermi _ observes the whole sky once every three hours @xcite , but because of the highly varying nature of blazars in gamma - rays , sources may sometimes fall below that detection threshold , resulting in upper limits for a given integration period .",
    "we consider gamma - ray light curves with a time binning of one week , which allows us to detect about 100 sources most of the time .",
    "we have upper limits for about 30% of the data . at this level",
    "we find that treating the upper limits as non - observations does not have important effects in the measured time lags or significance of cross - correlations for the cases with interesting values of the cross - correlation significance @xcite .",
    "this behaviour could be a result of the particular properties of the light curves we considered in that study , such as long time scales for the variability compared to the gaps created by ignoring the upper limits or the power spectral densities , and it might not hold in other situations . we thus obtain unevenly sampled gamma - ray light curves as the ones we discuss here .",
    "we begin with a brief summary of the standard methods used for the estimation of the psd and then move to the uneven sampling and short time series cases .",
    "this discussion is based on the method presented in @xcite which is modified to suit our dataset and the range of psds we fit .",
    "additional justification of the need for binning and interpolation of the light curves is given in section [ rebin_interp_reasons ] .",
    "we also present an example of the application of our method to a simulated light curve , and a number of tests using real data sampling for simulated light curves that demonstrate the accuracy of the fitting procedure under different conditions .",
    "the real data sampling is based on the data set presented in @xcite , which have 4 year 15 ghz radio light curves from the ovro 40 meter telescope blazar monitoring program , and 3 year gamma - ray light curves from the lat on board of _ fermi_. a study of the effect of increasing the number of simulations in the fitting procedure is performed to guide our choice of parameters for the data analysis .",
    "a summary of the method , with emphasis on the improvements we add to the original formulation is given in section [ conclusions ] .",
    "we define a time series as a time ordered sequence of triplets @xmath10 , where @xmath11 is the observation time , @xmath12 is the measured value of the quantity of interest ( e.g. , flux density , photon flux , etc . ) , and @xmath13 is an estimate of the observational error associated with the measurement .",
    "we assume that the time series is sorted in time and @xmath14 . for the frequency and @xmath12 for time series data , e.g. , flux density , photon flux , etc .",
    "]    an estimation of the psd can be obtained through the periodogram , which is conventionally defined as the squared modulus of the discrete fourier transform : @xmath15 ^ 2 + \\left [ \\sum_{i=1}^{n } f_i \\sin(2 \\pi \\nu_k t_i ) \\right]^2\\ ] ] where the periodogram is evaluated at the discrete set of frequencies @xmath16 for @xmath17 for @xmath18 even , or @xmath19 for @xmath18 odd , @xmath20 is the nyquist frequency and @xmath21 , see footnote is consistent with the definition of the discrete fourier transform @xcite and allows us to make use of the fast fourier transform algorithm to increase the speed of the computations . ] .    estimating the psd in this way requires sampling a continuous time series at discrete times for a finite amount of time .",
    "the sampling operation is equivalent to multiplication of the time series by a dirac comb , while sampling for a finite time corresponds to a multiplication by a rectangular observing window .",
    "these two multiplications appear as convolutions in frequency space : the original spectrum is convolved with the fourier transform of the dirac comb and of the rectangular window . as a final step",
    "we only look at a discrete set of frequencies which is equivalent to multiplication by a dirac comb in frequency space .    ignoring the effect of sampling with a dirac comb in the frequency domain , and omitting normalization factors , we find that the periodogram is given by @xmath22 where @xmath23 is the fourier transform of the time series @xmath24",
    ", @xmath25 is the fourier transform of the dirac comb with sampling interval @xmath26 , and @xmath27 is the fourier transform of the sampling window function , which is by default a rectangular window , and @xmath28 denotes convolution .    as a result of the convolution with the dirac comb",
    ", we do not have access to the original spectrum but a modified version that repeats periodically .",
    "another distortion comes from the convolution with the sampling window function , which modifies the shape of the original spectrum , and finally we only look at discrete set of frequencies .",
    "all these factors have to be taken into account when analysing data and interpreting the results .",
    "the periodic repetition of the spectrum gives rise to aliasing , in which high frequency components are mistaken as low frequency components .",
    "convolution with a window function can be a serious problem when the sidelobes of the frequency window function lie on regions of the spectrum where the power is much higher than at the frequency of interest  this is the origin of the red - noise leakage problem .",
    "having the spectrum sampled at a number of discrete frequencies can be problematic if we are searching for narrow spectral components which can be smeared or missed .    for the case of evenly sampled time",
    "series , psd estimation amounts to using the discrete fourier transform ( dft ) along with periodogram or frequency averaging to decrease the noise which is distributed as a @xmath29 for a single frequency component .",
    "each of these averaging processes can reduce the variance at the price of reduced spectral resolution .",
    "for example , in the case of frequency or periodogram averaging of @xmath30 components the resulting distribution is @xmath31 , which reduces the variance by a factor of @xmath32 with respect to the non - averaging case .",
    "the application of these methods is straightforward in the case of long time series , where a good estimate of the psd can be obtained at the expense of reduced frequency resolution .",
    "nonetheless , problems of aliasing and red - noise leakage can still complicate the analysis of broadband signals like the simple power - law psds we fit to our data ( @xmath33 ) , for the reasons outlined below .",
    "for relatively flat spectra ( @xmath34 from 0 to 2 ) aliasing can be a problem as high frequency power above the nyquist frequency contaminates low frequencies .",
    "this problem is less serious for steep spectra ( @xmath35 ) , that have relatively small amounts of power at high frequencies .",
    "but in this case red - noise leakage can flatten the high frequency part of the spectrum : power from low frequencies contaminates the low amplitude high frequency parts of the spectrum through sidelobes on the sampling window functions . to reduce the effects of these problems a combination of filters and sampling window functions",
    "can be used ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "when working with time series data , problems often arise because the time series is unevenly sampled and relatively short .",
    "uneven sampling requires the use of a different estimate of the periodogram : the best known alternatives are the deeming periodogram @xcite and the lomb - scargle periodogram @xcite .",
    "the lomb - scargle periodogram is well suited to the detection of periodic signals in white noise , because its statistical properties are well understood . for the analysis of broadband signals ,",
    "the deeming periodogram is often used for reasons that are mainly historical as it does not present any real advantages .",
    "these two methods allow us to obtain an estimate of the periodogram for unevenly sampled time series directly , but do not provide a way to correct for distortions produced by the sampling window functions , which can modify the shape of the periodogram significantly as explained below .",
    "the method we present here was originally developed and described in detail in @xcite .",
    "we describe the main steps here to highlight the differences between theirs and our implementation .    1 .",
    "obtain the periodogram for the light curve and bin it in frequency to reduce scatter .",
    "the periodogram is given by a frequency binned version of the following expression @xmath36 ^ 2 + \\left [ \\sum_{i=1}^{n } f_i \\sin(2",
    "\\pi \\nu_k t_i ) \\right]^2 \\right ) \\ ] ] where the frequencies are @xmath16 for @xmath37 for @xmath18 even , or @xmath38 for @xmath18 uneven .",
    "the minimum frequency is @xmath39 , the maximum frequency is the nyquist frequency @xmath40 , and @xmath21 .",
    "the multiplicative factor is a normalization , such that the integral from @xmath41 to @xmath42 is equal to the variance contributed to the light curve in this frequency range .",
    "the evenly sampled time series @xmath24 is obtained from the original one by interpolation onto a regular grid .",
    "this interpolated time series is first multiplied by an appropriate sampling window in order to reduce red - noise leakage .",
    "a justification of these steps is given in sections [ rebin_interp_reasons ] and [ spectral_window ] .",
    "2 .   choose a psd model to test against the data .",
    "in this case we are fitting power - laws of the form @xmath33 but this can be generalized to any functional dependence . for",
    "the given model simulate @xmath30 time series , where @xmath30 is a large number that allows us to represent a variety of possible realizations of this psd model .",
    "these and all the simulated light curves used in this work are generated using the method described in @xcite , which randomizes both the amplitude and phase of the fourier transform coefficients consistent with the statistical properties of the periodogram .",
    "3 .   for each simulated light curve apply the same sampling , add observational noise , and interpolate into the same even grid . calculate the periodogram for each one .",
    "from these @xmath30 periodograms determine the mean periodogram and its associated error as the scatter at each frequency bin .",
    "4 .   using the mean periodogram and errors obtained in step ( iii )",
    "construct a @xmath43-like test , defined by @xmath44 ^ 2}{\\delta \\overline{p_{\\rm sim}}(\\nu)^2}\\ ] ] where @xmath45 is the periodogram of the observed light curve , @xmath46 and @xmath47 are the mean and scatter in the periodogram obtained from the simulated light curves , and @xmath48 is the @xmath49 of the observed light curve when compared to the simulations for a given psd model .",
    "this @xmath48 is then compared to the simulated distribution of @xmath43 for which we can obtain @xmath30 samples , @xmath50 , by replacing the @xmath45 term by the periodogram of the simulated light curves , @xmath51 , in equation [ chi2_definition ] .",
    "the fraction of the distribution for which @xmath52 is the significance level at which the tested psd model can be rejected , also known as the @xmath53-value .",
    "thus a high value of this percentage represents a good fit , while a low one corresponds to a poor fit .",
    "the process described above can be repeated for a number of models with different parameters .",
    "the final step consists of selecting the best model fit as the one with the highest value of @xmath53 . as with any statistical procedure",
    ", a measurement of the uncertainty in the parameters of the model needs to be given . in this point",
    "we depart from the original formulation and provide uncertainties based on monte carlo simulations of the model fitting process ( as described in section [ uncertainty_estimate ] ) .",
    "the most significant differences with the original implementation are the use of sampling window functions to reduce red - noise leakage and the monte carlo estimation of fitting uncertainties .",
    "another difference is that we simulate the effects of aliasing by simulating light curves with high frequency components with a sampling period of 1 day , instead of adding a constant noise term to the psd of the simulated light curves as in the original formulation .",
    "the high frequency cut at 1 day@xmath54 is justified in our implementation by the small amount of power seen at higher frequencies specially in the radio band .",
    "intraday variable sources show variability in short time scales @xcite , but even in these cases the amplitude of the variability is only a few percent for most sources @xcite . at gamma - rays",
    "this is not necessarily true as fast variability has been observed , but given that gamma - ray photon fluxes correspond to mean values of long integrations of at least a week for most blazars , the effects of fast variability are less important as they are averaged out .",
    "other applications where fast variability is expected might require a higher frequency cut , making this approach impractical .",
    "another important difference , although less important conceptually , is the use of the fast fourier transform to perform the computations , which substantially decreases computing time .",
    "further discussions of the most important elements of the method are given below .",
    "this step is very important when estimating steep psds .",
    "it is easy to get mislead by intuition developed from the behavior of window functions for evenly sampled time series , but it turns out that window functions for unevenly sampled data do not behave in the same way .",
    "an example is presented in figure [ window_uneven ] , where we show the frequency response of a uneven sampling pattern with rectangular and hanning windows , for the periodogram of power - law psds with different values of @xmath34 from 0 to 5 .",
    "these window functions are @xmath55    @xmath56            from figure [ window_uneven ] it can be seen that even though we can calculate the periodogram directly for an unevenly sampled time series the results we obtain are very noisy and do not vary much among different values of @xmath34 .",
    "the main problem is that all the psds with @xmath57 look very similar , showing almost the same slope when fitted with a linear function after a log - log transformation .",
    "this is problematic as the fitting procedure relies on the differences between different psd power - law indices to choose the best model .",
    "doing the same exercise for a time series with the same time length and number of data points but with even sampling we obtain the results shown in figure [ window_even ] . in this case",
    "the results are much less noisy and the estimated psds look different from each other even for very steep psds .",
    "this allows for better discrimination and is required to find an upper limit to the source power - law exponent of the psd .",
    "the problems associated with the window functions become evident when trying to apply the fitting method using unevenly sampled data , and show up as an inability to find an upper limit to the power - law exponent @xmath34 due to the lack of difference between the estimated psds for the simulated data .",
    "this problem can be solved by the use of interpolation and an appropriate window function , a subject that is discussed in section [ spectral_window ] .",
    "figures [ window_uneven ] and [ window_even ] illustrate the limited use we can make of direct psd fitting , even for the case of long time series . in this case",
    ", red - noise leakage makes it impossible to recover the right power - law index for steep psds .",
    "the subject of windowing of unevenly sampled data is briefly discussed in @xcite . in particular figure 3 in @xcite",
    "shows a few example window functions for the cases of even and uneven sampling using the classic periodogram .",
    "that figure illustrate the very different sidelobe structure that is obtained for the uneven sampling case , which is at the root of the problem described here .    to clarify this point",
    ", we also include the window functions for our test data along with the results of applying the hanning window .",
    "an examination of figure [ window_even_uneven_example ] helps us understand the results described below . in conventional fourier analysis ,",
    "window functions change the frequency response of the sampling , changing the sidelobe structure and thus helping mitigate the effects of red - noise leakage and aliasing .",
    "this behavior can be seen when using evenly sampled data sets , where the sidelobe structure is regular and decays as frequency increases .",
    "the case for uneven sampling is very different : the shapes of the window functions explains the strong red - noise leakage seen in the simulations and the increased noise . in the case of even sampling",
    "we recover the results of conventional fourier analysis , with all the known properties of window functions .        for the reasons described above we use linear interpolation and rebinning to interpolate the unevenly sampled light curves to a regular grid , thus allowing for the psd fitting .",
    "one fundamental difference between the implementation of the method of @xcite and ours is that we use window functions to reduce the effects of red - noise leakage .",
    "we found that this is necessary when dealing with steep power spectral densities , like those found in blazar studies . in our first attempts to fit the psds we found that with a rectangular window we were not able to set an upper limit to the value of @xmath34 and were only able to set a lower limit",
    "the upper limit on @xmath34 is necessary to constrain the significance of cross - correlations , as will be described in section [ cross_corr_method ] . in this section",
    "we explain the origin of that problem and the solution we implemented .    for broadband time",
    "series a big problem is the leakage of power through far sidelobes of the spectral window response .",
    "this problem is evident when dealing with high dynamic range psds , such as steep power - laws . for these power - law psds , it is seen as a flattening of the high frequency part of the periodogram due to power leaking from low frequency part which has much higher power . in practical terms , it means that after some critical value of the power - law index all the periodograms have a flat slope which does not depend strongly on the psd ( figures [ window_uneven ] and [ window_even ] ) .",
    "most of this high frequency power is actually coming from low frequencies through sidelobes of the window function .",
    "one way to deal with this problem is by using window functions with low level sidelobes ; some details about their application to our data set are presented below .",
    "[ [ spectral - window - functions - for - our - data - sets - best_window ] ] spectral window functions for our data sets [ best_window ] + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    there is a great variety of window functions , which differ mainly in the width of their main lobe , the maximum level , and the fall - off rate of the sidelobes . the ideal window function will depend on the application and some experimentation might be necessary",
    ". properties of various window functions can be found elsewhere ( e.g. , * ? ? ?",
    "* )    we tried a number of them and compared their performance in recovering steep psds .",
    "we found that among the ones tested the most suitable one was the hanning window , which is able to recover a steep spectrum in a range that allows us to fit our light curves . among the special characteristics of this window",
    "are its low sidelobe level , more than @xmath58 db below main lobe , and the fast fall - off at @xmath59 db / decade . as a downside the hanning window has a broader main lobe at 3 db ( @xmath60 ) when compared to the rectangular window ( @xmath61 ) , where @xmath62 is the length of the time series .",
    "the effect of different windows is illustrated in figure [ window_steep_psds ] , which shows the periodogram for a series of steep psds .",
    "from the figure it is also clear why other window functions fail to distinguish between steep psds , and thus are not suitable to use with this method .",
    "the results of figure [ window_steep_psds ] can be understood by comparing the properties of the window functions shown in table [ windows_properties ] @xcite .",
    "the reduction of the red - noise leakage when using the hanning window allows us to discriminate between different steep power - law indices of the psd , and is due to the low level and fast fall - off its sidelobes .",
    ".properties of selected window functions [ cols=\"^,^,^,^ \" , ]     [ repeatability_table ]",
    "here we deal with the statistical problem of quantifying the significance of the cross - correlation between two time series , in the case of uneven sampling and non - uniform measurement errors .",
    "the two time series are assumed to contain no upper or lower limits .",
    "our basic data sets are two time series we call a and b. these time series are time ordered sequences of triplets @xmath63 with @xmath64 and @xmath65 with @xmath66 . in both cases @xmath67 is the observation time , @xmath68 is the measured value of a quantity of interest ( e.g. flux density , photon flux , etc . ) and @xmath69 an estimate of the observational error associated with the measurement .",
    "since the time interval between successive samples is not uniform and the a and b time series are not sampled simultaneously , we need to resort to some kind of time binning in order to measure the cross - correlation .",
    "the cross - correlation between two unevenly sampled time series can be measured using a number of different approaches .",
    "the usual approach is to generalize a standard method and use time binning to deal with the uneven sampling .",
    "here we consider two methods that are commonly encountered in the literature : the discrete correlation function @xcite and the local cross - correlation function ( e.g. , * ? ? ?",
    "a number of other alternatives have been used to handle the problem of measuring the correlation between unevenly sampled time series . among them",
    "are the interpolated cross - correlation function ( iccf ; * ? ? ?",
    "* ) , inverse fourier transform of the cross - spectrum @xcite and the @xmath70-transformed cross - correlation function @xcite .",
    "we do not explore these alternative methods in this work .",
    "these methods provide a way of estimating the cross - correlation coefficients , but do not provide an estimate of the associated statistical significance , which is discussed in section [ crosscorr_sig ] .",
    "the two most commonly found alternatives are presented below .",
    "the discrete correlation function was proposed by @xcite and developed in the context of reverberation mapping studies . for two time series @xmath71 and @xmath72",
    ", we first calculate the unbinned discrete correlation for each of the pairs formed by taking one data point from each time series @xmath73 where @xmath74 and @xmath75 are the mean values for the time series , and @xmath76 and @xmath77 are the corresponding standard deviations .",
    "this particular value , @xmath78 , is associated with a time lag of @xmath79 .",
    "the discrete cross - correlation is estimated within independent time bins of width @xmath26 , by averaging the unbinned values within each bin , @xmath80    the uncertainty in the binned discrete cross - correlation is given by the scatter in the unbinned values for each time bin , and is given by @xmath81 ^ 2 \\right ) ^{1/2}\\ ] ] in the expressions above the sum is over the @xmath30 pairs for which @xmath82 , where @xmath83 is the time lag , and all the bins have at least two data points in order to get a well - defined error . in practice",
    "it is recommended to choose @xmath30 much larger than 2 to reduce the effect of statistical fluctuations .    in this case , the mean and standard deviation use all the data points in a given time series , but the dcf for a given time lag only includes overlapping samples .",
    "this particular choice for normalization produces values of the dcf which are not restricted to the usual @xmath84 $ ] interval of standard correlation statistics .",
    "this immediately challenges the interpretation of the amplitude of the dcf as a valid measure of the cross - correlation and invalidates the use of standard statistical tests developed for other correlation statistics , forcing us to find alternative ways to estimate the significance of correlations .",
    "a modification that corrects this normalization problem but not the significance evaluation issue is described below .      motivated by the normalization problems presented by the dcf",
    ", some authors have proposed a different prescription ( e.g. , * ? ? ? * ) . in this case",
    ", we only consider the samples that overlap with a certain coarse grain of the time delays , which is equivalent to the width of time bins @xmath26 .",
    "hence , we have @xmath85 where the sum is over the @xmath30 pairs of indices @xmath86 such that @xmath82 . the averages ( @xmath87 and @xmath88 ) and standard deviations ( @xmath89 and @xmath90 ) are also over the @xmath30 overlapping samples only .",
    "the main motivation for using this expression instead of the dcf is that we recover cross - correlation coefficients that are bound to the @xmath84 $ ] interval .",
    "this latter property is a result of using only the overlapping samples to compute the means and standard deviations , which in effect reduces the problem to a standard cross - correlation bounded to @xmath84 $ ] , as a consequence of the cauchy - schwarz inequality .",
    "additionally , @xcite shows that the lccf can determine time lags more accurately than the dcf in simulated data sets .",
    "these are certainly desirable properties , but as explained in section [ crosscorr_sig ] , they do not solve the estimation of significance problem .      in section [ compare_methods ]",
    "we perform a series of tests designed to help us compare the detection efficiency of the dcf and lccf . in looking at these results ,",
    "it is useful to consider the relation between those two correlation measures .    from our previous discussions",
    ", we can see that the only difference between the dcf and lccf is in the values used for the means and standard deviations . in the case of the dcf ,",
    "the mean and standard deviation are calculated from the complete time series ( @xmath91 for the means and @xmath92 for the standard deviations ) , while for the lccf only the overlapping samples at each time lag are used ( @xmath93 for the means and @xmath94 for the standard deviations ) .",
    "it can be shown that the two are related at a given time lag by @xmath95 this linear relation has coefficients that depend on the sampling pattern and the overlap between the two time series at different time lags . for long stationary time series ,",
    "the means and variances of the overlapping and complete time series will be identical and the dcf will equal the lccf . for short or non - stationary time series , the coefficients will make the dcf different from the lccf .",
    "deviations of the multiplicative coefficient @xmath96 from 1 change the amplitude of the dcf , while deviations of the additive coefficient @xmath97 from 0 change the zero - point of the dcf .",
    "the combination of these variations explains why the dcf is not bounded to the @xmath84 $ ] interval as is the lccf , and can also explain why they have different detection efficiencies .",
    "the standard method used by the reverberation mapping community @xcite , uses bootstrapping and randomization to generate slightly modified versions of the original data set , in order to quantify the uncertainty in the location of the cross - correlation peak .",
    "a modified data set is constructed by the application of two procedures .",
    "the first is `` random subset selection '' , in which a bootstrapped light curve is constructed by randomly selecting with replacement samples from the original time series . in the second , we perturb the selected flux measurements by `` flux randomization '' , in which normally distributed noise with a variance equal to the measured variance",
    "is added to the measured fluxes .",
    "each of these modified data sets is cross - correlated using the method of choice and a value for the cross - correlation peak of interest is measured . by repeating this for many randomized data sets , a distribution of measured time lags for the cross - correlation peaks",
    "is obtained .",
    "this distribution is used to construct a confidence interval for the position of the peak .",
    "there has been some discussion in the literature about the effects of detrending the light curves in order to improve the accuracy of the time lag estimates .",
    "@xcite strongly recommended removing at least a linear trend from the light curves .",
    "his results are based on simulations with even sampling and do not directly apply to uneven sampling as shown by @xcite .",
    "they find that detrending does not improve accuracy in unevenly sampled datasets , and produces large errors in some cases .",
    "based on that finding , we have decided not to detrend our light curves .",
    "we emphasize that care must be taken when correlating time series where long term trends are present , as these are guaranteed to produce large values of the cross - correlation coefficient .",
    "our studies are mostly concerned with the correlation between periods of high activity in different energy bands for light curves that appear to have a detectable  quiescent \" level .",
    "this is generally true for gamma - ray light curves , but is not always true for radio light curves .",
    "radio light curves showing a single dominant increasing or decreasing linear trend should be analyzed with care , as they can produce spurious correlations . in our opinion ,",
    "the best remedy for those cases is to collect longer light curves .      a complete quantification of the cross - correlation needs an estimate of its statistical significance . in our case , we need to consider the intrinsic correlation between adjacent samples of a given time series , which are produced by the presence of flare - like features ; a distinctive characteristic of blazar light curves .",
    "this behavior can be modeled statistically by red - noise stochastic processes ( e.g. , @xcite in the radio and optical , @xcite in the x - rays , and @xcite in gamma - rays ) .",
    "red - noise processes are characterized by their psd , show variability at all time scales , and appear as time series in which flare - like features are a common phenomenon .",
    "the frequent appearance of flares means that high correlation coefficients between any two energy bands are to be expected , even in the absence of any relation between the processes responsible for their production .",
    "to illustrate this point figure [ example_simulated_light_curves ] shows simulated light curves with power - law power spectral densities ( psd @xmath98 ) .",
    "in fact , every time we cross - correlate two time series , each of which has a flare , we will get a peak in the cross - correlation at some time lag . then quantifying the chances of such peak being",
    "just a random occurrence is of critical importance .",
    "the problem is further complicated by the uneven sampling and non - uniform errors , so the only feasible method is to use monte carlo simulations .",
    "standard methods are not suitable for this analysis , as they assume that the individual data points are uncorrelated",
    ". the effect of ignoring the correlations will lead to an overestimate of the significance of the cross - correlations and to an erroneous physical interpretation .    in figure",
    "[ example_xcorr_simulated_light_curves ] , we show the results of cross - correlating the independently simulated light curves from figure [ example_simulated_light_curves ] , which have different values of the power - law exponent for the psd . it can be seen that correlating light curves with steep psd , which show frequent flare - like features , can result in high cross - correlation coefficients that have nothing to do with a physical relation between the light curve pairs .",
    "the results illustrate how common it is to get high cross - correlations for unrelated light curves with steep psds and the dangers of interpreting them as signs of a physical connection .",
    "standard statistical tests that assume uncorrelated data are equivalent to the case of white noise time series ( psd @xmath99 ) , which is illustrated in the upper panels of figure [ example_xcorr_simulated_light_curves ] . since blazar light curves are more similar to simulated light curves with steep psds , it is easy to see how misleading it is to use statistical tests that ignore the long term correlations in the individual time series .          to estimate the significance of the cross - correlation coefficients , we use a monte carlo method to estimate the distribution of random cross - correlations , that uses simulated time series with statistical properties similar to the observations .",
    "these and related ideas have been applied by several authors ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "the details of the procedure vary from author to author , so we provide a detailed description of our implementation to enable others to evaluate and reproduce our analysis .    the algorithmic description of the method we use to measure the significance of the time lags is as follows :    1 .",
    "we calculate the cross - correlation coefficients between the unevenly sampled time series using one of the methods described in section [ crosscorr_alt ] .",
    "2 .   using an appropriate model for the psds at each energy band , we simulate time series with the given noise properties and sampled exactly as the data .",
    "the resulting flux densities are perturbed by adding noise according to the observational errors .",
    "we calculate the cross - correlation coefficients of the simulated light curve pairs using the same method as for the real data .",
    "we repeat the previous step for a large number of radio / gamma - ray simulated light curve pairs and accumulate the resulting cross - correlation coefficients for each time lag .",
    "4 .   for each time",
    "lag bin , the distribution of the simulated cross - correlation coefficients is used to estimate the significance levels of the data cross - correlation coefficients .",
    "an additional detail is that the gamma - ray time series are the result of long integrations , so each simulated data point is generated by averaging the required number of samples to replicate the time binning . for the radio light curves , the integrations are so short that the closest sample can be chosen .",
    "figure [ example_xcorr_data ] shows the application of the method for an example using simulated data with the sampling pattern from our monitoring program .",
    "we use @xmath100 in both bands for the dcf and the lccf . in both cases ,",
    "the cross - correlation coefficient at each time lag is represented by the black dots and the distribution of random cross - correlations by the colored dotted lines . a time lag @xmath101 means the gamma - ray emission lags the radio , while @xmath102 represents the opposite .",
    "the red lines contain 68.27% of the random cross - correlations , so we refer to them as the @xmath103 lines , the orange lines contains 95.45% ( @xmath104 ) , and the green lines contains 99.73% ( @xmath105 ) lines or significance levels ] .",
    "the colored contours provide a quick way to evaluate the significance of the cross - correlation and are used for this purpose throughout this paper . in this case , although the amplitudes are relatively high for both the dcf and lccf , the significance is not even 2@xmath106 indicating only marginal evidence of a correlation .",
    "+          we use both dcf and lccf in our tests , to determine quantitatively which is the best for the problem of detecting significant correlations between two time series .",
    "the comparison is made in terms of detection efficiency of correlations , at a given significance level , and a maximum time lag error .",
    "for the tests , we simulate a time series with a very fine time resolution and make two copies , one for each band , in which the only difference is a known time lag and the different sampling pattern , which is taken from example light curves from our monitoring program .    in all the cases , we bin the cross - correlation with @xmath107 days and model the time series with a psd @xmath108 , which is also used for the monte carlo evaluation of the significance .",
    "we use @xmath109 uncorrelated time series to estimate the distribution of random cross - correlations and significance , and use these results to estimate the significance of cross - correlation for 1000 correlated time series .",
    "this enables us to determine the significance of the correlations and the error in the recovered time lag .",
    "this corresponds to the ideal case of a perfect intrinsic correlation , which is only distorted by the time lag and different sampling of the two time series .",
    "the case is also ideal with respect to the significance evaluation , as we perfectly know the model for the light curves .",
    "it is important to keep these points in mind and to realize that the actual detection efficiencies could be much lower than what we find through these tests .      as a check of the method and to help the reader",
    "understand the results , we first test our ability to detect correlations in a very simple case . in this case a time series with a uniform sampling period of 3 days is correlated with a copy of itself without any delay or noise .",
    "an example of the simulated data set along with the results for the dcf and lccf is shown in figure [ example_sim_data_perfect ] .",
    "the same procedure is repeated for all simulated time series with known time lag and correlation properties , and the fraction of detected lags at the known lag ( @xmath110 ) with a given significance level is reported as an efficiency in figure [ efficiency_perfect ] .    , uniform and identical sampling , zero time lag and no noise .",
    "the upper panel shows the two time series which overlap perfectly in this case .",
    "the lower panel has the results of the dcf and lccf for this case .",
    "the vertical lines show the position of the most significant peak with color corresponding to the method used .",
    "horizontal color lines mark the amplitude of the most significant peak for each method .",
    "the most striking difference between the two methods is the normalization which is not restricted to the @xmath84 $ ] interval in the case of the dcf.,width=340 ]     significance.,width=340 ]    in this case , we recover most of the time lags at the right value and the behaviors of the dcf and lccf are very similar .",
    "the values of the coefficients of the linear relation for @xmath111 ( equation [ dcf_lccf_linrel ] ) , are very close to the case when the dcf and lccf are equal ( figure [ coeff_linear_perfect ] ) .",
    "day , for the case of _ uniform and identical sampling for both time series , zero lag and no noise_. upper panel is the multiplicative factor , which is very close to 1 in most cases .",
    "lower panel is the additive constant which is very close to 0 .",
    "these values make dcf @xmath112 lccf which makes the results of both methods very similar as can be seen in figure [ efficiency_perfect].,title=\"fig:\",width=340 ]   day , for the case of _ uniform and identical sampling for both time series , zero lag and no noise_. upper panel is the multiplicative factor , which is very close to 1 in most cases .",
    "lower panel is the additive constant which is very close to 0 .",
    "these values make dcf @xmath112 lccf which makes the results of both methods very similar as can be seen in figure [ efficiency_perfect].,title=\"fig:\",width=340 ]      we now study a case with sampling taken from the ovro 40 meter blazar monitoring program and _ fermi_-lat data set .",
    "again we add no noise to the simulations and have zero lag between the two light curves , so the only difference is in the sampling pattern . in this case , a source was observed for two years with the ovro 40 meter telescope at 15 ghz with a nearly twice per week sampling @xcite .",
    "the gamma - ray data for the same source has one observation per week and a one year time duration @xcite .",
    "an example of simulated data with this sampling is shown in figure [ example_sim_data_short ] ( upper panel ) , along with the results for the cross - correlation ( lower panel ) . in this case the radio sampling ( blue dots ) covers a longer time span than the gamma - ray one ( red dots ) .",
    ", for the case  short data set \" .",
    "upper panel shows the two time series , which have some small differences produced by the different sampling at each waveband .",
    "lower panel has the results of the dcf and lccf for this case .",
    "the vertical lines show the position of the most significant peak with color corresponding to the method used .",
    "horizontal color lines mark the amplitude of the most significant peak for each method . in this example",
    "the lccf recovers the right time lag , but the dcf finds a spurious time lag.,width=340 ]        figure [ efficiency_short ] shows that in this case we only recover a fraction of the time lags at a @xmath105 significance .",
    "this is because the dcf often finds the most significant peak at a lag different from zero ( fig .",
    "[ peak_dist_short ] ) .",
    "moreover some of those spurious lags are of high statistical significance .",
    "we still get some significant peaks at lags different from zero for the lccf , but at a much smaller rate .         to understand how we can get small values of the dcf at zero lag while still having large values of the lccf",
    ", we can take a look at the distributions of the coefficients of the linear relation ( equation [ dcf_lccf_linrel ] ) , shown in figure [ coeff_linear_short ] .",
    "the multiplicative coefficient should be one in the ideal case , but instead it has a broad distribution ( upper panel ) .",
    "the additive coefficient should be zero in the ideal case , but it also has a broad distribution ( lower panel ) .",
    "this can effectively reduce the value of the correlation coefficient or make its distribution broader , either way reducing its discriminating power .",
    "this effect is seen in figure [ dist_dcf_and_lccf_short ] , which shows the distribution of cross - correlation coefficients at @xmath111 days . in the figure ,",
    "the distribution of random cross - correlations is represented with a dotted line and the one for correlated data with a solid line .",
    "the upper panel is for the dcf and the lower panel for the lccf .",
    "the vertical green line represents the @xmath105 significance threshold amplitude for cross - correlation coefficients .",
    "the fraction of cross - correlations for correlated data ( solid line ) that is to the right of the green line is approximately equal to the detection efficiency .. these cases are not excluded from the histogram . ]",
    "it can be seen that this fraction is much larger for the lccf , as a result of increased scatter in the distribution of the dcf when compared to the lccf of correlated data , for the reasons presented earlier .",
    "day , for the case of the  short data set \" .",
    "upper panel is the multiplicative factor , which has a very broad distribution , different from 1 in most cases .",
    "lower panel is the additive constant which also has a very broad distribution , different from the ideal case of 0 .",
    "these values show the dcf to be different from the lccf and have a role in producing spurious highly significant peaks in the correlation.,title=\"fig:\",width=340 ]   day , for the case of the  short data set \" .",
    "upper panel is the multiplicative factor , which has a very broad distribution , different from 1 in most cases .",
    "lower panel is the additive constant which also has a very broad distribution , different from the ideal case of 0 .",
    "these values show the dcf to be different from the lccf and have a role in producing spurious highly significant peaks in the correlation.,title=\"fig:\",width=340 ]     day , for the case of the  short data set \" .",
    "upper panel is for the dcf and lower panel for the lccf .",
    "both panels show the distribution of random cross - correlations with a dotted line and for correlated data with a solid line .",
    "points with cross - correlation coefficient to the right of the vertical green line have a significance of at least @xmath105.,width=340 ]      we make the same comparison using a data set with radio light curves of 4 years time duration sampled about twice a week , and gamma - ray light curves with a 3 year time duration and weekly sampling .",
    "we again consider the case with no noise and zero lag between the two light curves , so the only difference is in the sampling pattern .",
    "an example of a simulated data set with this sampling is shown in figure [ example_sim_data_long ] ( upper panel ) , along with the results for the cross - correlation ( lower panel ) .",
    "comparison of the results of this section with the shorter dataset test ( section [ test_short_data_set ] ) , can give us an idea of the variation of the relative power to detect correlations in different data sets .",
    "as in the case of the  short data set \" , we find that the efficiency of detection strongly depends on the method used .",
    "figure [ efficiency_long ] shows that the lccf recovers the right time lag at high significance for all the cases , while the dcf does so in only about 15% of the cases .",
    "an examination of figure [ peak_dist_long ] shows that the dcf produces spurious correlation peaks with a wide distribution . as in the case of the  short data set \" ,",
    "some of those spurious peaks have high statistical significance .",
    "a comparison of figures [ efficiency_short ] and [ efficiency_long ] shows that the performance of both methods improves as expected when using longer time series .",
    "however , as can be seen from figure [ peak_dist_long ] , the dcf produces a large fraction of spurious statistically significant correlation peaks , while the lccf recovers a significant correlation at @xmath111 in all cases .",
    "figure [ coeff_linear_long ] shows the distribution of the coefficients for the linear relation between the dcf and lccf ( equation [ dcf_lccf_linrel ] ) .",
    "we again see that they significantly differ from the ideal case of a stationary time series .",
    "this provides an explanation for the difference between these two estimators of the correlation . as for the case of the `` short data set '' ,",
    "we also look at the distribution of cross - correlation coefficients for the uncorrelated and correlated data sets at @xmath111 ( figure [ dist_dcf_and_lccf_long ] ) . we again see the broad distribution of correlation coefficients for the dcf of correlated data sets , while a much narrower distribution for the lccf , demonstrating the better discriminating power of the lccf .",
    "day , for the case of the  long data set \" .",
    "upper panel is the multiplicative factor , which has a very broad distribution , different from 1 in most cases .",
    "lower panel is the additive constant which also has a very broad distribution , different from the ideal case of 0 .",
    "these values show the dcf to be different from the lccf and have a role in producing spurious highly significant peaks in the correlation.,title=\"fig:\",width=340 ]   day , for the case of the  long data set \" .",
    "upper panel is the multiplicative factor , which has a very broad distribution , different from 1 in most cases .",
    "lower panel is the additive constant which also has a very broad distribution , different from the ideal case of 0 .",
    "these values show the dcf to be different from the lccf and have a role in producing spurious highly significant peaks in the correlation.,title=\"fig:\",width=340 ]     day , for the case of the  long data set \" .",
    "both panels show the distribution of random cross - correlations with dotted line and the one for correlated data with solid line .",
    "points with cross - correlation coefficient to the right of the vertical green line have a significance of at least @xmath105 .",
    "upper panel is for the dcf and lower panel for the lccf.,width=340 ]      additional tests were performed introducing various time lags for the time series and measuring the efficiency of detection for the dcf and lccf .",
    "they all show the same qualitative information and are thus not included here . in all cases",
    "the lccf outperforms the dcf and the efficiency of detection improves when using a longer time duration dataset .",
    "these results demonstrate that the lccf is the more efficient method for recovering time lags with high significance .",
    "in this section , we describe some additional issues that should be considered when estimating the significance of cross - correlations using the monte carlo test we have devised , or similar methods .",
    "the error on the significance estimate has been mostly ignored in the literature , while the dependence of the significance estimate on the model light curves - when not fully appreciated - can lead to significance tests that are not consistent with the basic statistical properties of blazar light curves .",
    "another effect not considered here has recently been raised by @xcite . in their paper",
    ", they propose a method to simulate light curves that reproduces not only the power spectral density , but also the power density function of the flux measurements .",
    "this method is an improvement on @xcite , that produces gaussian distributed fluxes and can provide a better approximation to light curves that have non - gaussian probability density functions . for our data",
    ", this can be the case for gamma - ray light curves but it is not of much concern for the radio light curves .      as illustrated in figure",
    "[ example_xcorr_simulated_light_curves ] , the distribution of random cross - correlation coefficients will depend on the model used for the simulated light curves . in order to better appreciate that dependence ,",
    "we have estimated the significance of the cross - correlation for an example using simulated data with the sampling pattern from our monitoring program ( same as figure [ example_xcorr_data ] ) .",
    "we have used 10,000 simulated light curves with psd @xmath0 for @xmath113 , @xmath114 and @xmath115 .",
    "figure [ significance_various_models ] presents the results in the form introduced in figure [ example_xcorr_data ] . as in figure",
    "[ example_xcorr_simulated_light_curves ] , we observe an increase in the amplitude of the random cross - correlation when steeper power spectral densities are used in the simulations .",
    "this manifests as increased scatter in the distribution of random cross - correlations and a lower significance estimate for the cross - correlations .",
    "the dependence of the results on the particular model of the light curves illustrates the importance of a proper characterization of the light curves variability , a subject we discussed in section [ psd_estimation_method ] .    ) .",
    "we use @xmath113 ( upper panel ) , @xmath116 ( central panel ) and @xmath100 ( lower panel ) .",
    "the black dots represent the lccf for the data , while the color contours the distribution of random cross - correlations obtained by the monte carlo simulation with red for @xmath103 , orange for @xmath104 and green for @xmath105 .",
    "the increased amplitude of random cross - correlations is evident for steeper psds.,title=\"fig:\",width=340 ] ) .",
    "we use @xmath113 ( upper panel ) , @xmath116 ( central panel ) and @xmath100 ( lower panel ) .",
    "the black dots represent the lccf for the data , while the color contours the distribution of random cross - correlations obtained by the monte carlo simulation with red for @xmath103 , orange for @xmath104 and green for @xmath105 .",
    "the increased amplitude of random cross - correlations is evident for steeper psds.,title=\"fig:\",width=340 ] ) .",
    "we use @xmath113 ( upper panel ) , @xmath116 ( central panel ) and @xmath100 ( lower panel ) .",
    "the black dots represent the lccf for the data , while the color contours the distribution of random cross - correlations obtained by the monte carlo simulation with red for @xmath103 , orange for @xmath104 and green for @xmath105 .",
    "the increased amplitude of random cross - correlations is evident for steeper psds.,title=\"fig:\",width=340 ]      it is expected that the precision of the significance estimates will increase as the number of simulated light curve pairs increases . in order to get an estimate on the expected error in our significance estimate , due to the finite number of simulations , we have divided a full simulation with 100,000 simulated light curve pairs into independent subsets , and provide independent estimates for each of them .",
    "the idea is to observe the scatter when a small number of simulations is used and compare its variation as more simulations are included .",
    "the original simulation is divided in two halves which are subsequently divided into two .",
    "the process is repeated until the number of simulations in each subset is small enough that results have a very large scatter , and do not give us reliable significance estimates .",
    "for all sources we find that the results of a test with smaller number of simulations is less precise than the one using all the simulations . in all cases ,",
    "the average gives the result of the complete simulation , an expected result since together they encode the same information .",
    "as expected , the scatter is much smaller when a large number of simulations is used .",
    "an example is presented in figure [ example_crosscorr_error ] , which clearly shows the reduction in the scatter as the number of simulated light curve pairs is increased . with less than 1,000 simulations",
    "the scatter is of a few percentage points , and gets to about 0.4% for more than 10,000 simulations .",
    "the process described above could in principle be used to obtain an error estimate , but instead we compute a more conventional bootstrap estimate of the standard error , following the procedure described below ( this is applied in * ? ? ?",
    "for the time lag of interests , we have @xmath18 values of the random cross - correlations obtained from the @xmath18 simulated light curves . from these @xmath18",
    "random cross - correlations 1,000 bootstrap samples are obtained , each one giving a different significance estimate .",
    "the sample standard deviation of these bootstrap replications is used as the error in the significance estimate .",
    "an example of the distribution of bootstrapped estimates is shown in figure [ example_crosscorr_error_bootstrap ] .",
    "we think this error estimate is a required step of any monte carlo estimate of the significance , and we recommend the adoption of this or equivalent procedures - an issue that has surprisingly been up to now ignored by all authors .",
    "we presented a description of a monte carlo method to estimate the significance of cross - correlations between two unevenly sampled time series .",
    "we demonstrated the dependence of the significance estimates on the model of the light curves , and presented a method based on @xcite , that allow us to determine the best fit for a simple power - law power spectral density model for a light curve .",
    "an improved way of dealing with the effects of red - noise leakage is implemented .",
    "this method uses interpolation and windowing with a hanning window , and provides the ability to fit steep psds like those found in our data sets .",
    "we demonstrated that windowing is essential to obtain an upper limit on the value of the psd power - law index .",
    "an upper limit is required for meaningful cross - correlation significance estimates , which depend on the model used for the light curves .",
    "the method used for error estimation of the best fit was modified for one which decouples the goodness of fit estimate from the estimation of confidence intervals , and that can indicate the presence of biases in the fitting procedure .",
    "the method was evaluated using simulated data sets and found to be accurate with a typical error in @xmath34 of less than @xmath117 , for cases in which the signal power is large compared to observational noise .",
    "the performance of the method is degraded when fitting time series in which the signal power is comparable to the observational noise . in these cases , the procedure fails to provide a reliable constraint on the shape of the psd , a situation we can consider when analysing our data set by using the neyman construction to obtain confidence intervals .",
    "we also checked the repeatability of the best fit value when running the procedure multiple times , and find that it improves when using a large number of simulated light curves ( @xmath30 ) .",
    "for an example using the ovro data set , we find that big improvements are expected when going from @xmath30=100 to @xmath30=1,000 , but any further increase provides a small improvement , and might not be worth the increased computational time .    finally , we described the problem of estimating the cross - correlation for unevenly sampled time series .",
    "we have shown that high values of the cross - correlation coefficients for red - noise time series are ubiquitous , and that any method that aims at quantifying the significance of correlation coefficients for light curves having flare - like features needs to take this into account .",
    "we have described a general monte carlo method to estimate the significance of cross - correlation coefficients between two wavebands .",
    "a number of tests aimed at measuring the effectiveness of a particular cross - correlation method have been performed to compare the lccf and the dcf . given the absence of a physical model for the expected correlations , the method can not be used to give a definitive value of the detection efficiency , but it can be used to compare different alternatives .",
    "the main result is that the lccf has a much larger detection efficiency than the dcf when trying to recover a linear correlation .",
    "the dcf has the additional problem of producing a large fraction of spurious high significance time correlations , which could be mistaken as real correlations .",
    "this problem is less important for the lccf especially when long time series are used .",
    "the origin of the difference , and the lack of discriminating power for the dcf , seems to originate in the short duration or non - stationarity of the time series involved . in conclusion ,",
    "we recommend the use of the lccf as a tool to search for correlations .",
    "we also show that the significance of the cross - correlation coefficients is strongly dependent on the power - law slope of the psd , which makes characterization of the light curves critical .",
    "we investigate the error on the estimated significance by repeating the analysis using different numbers of simulations . especially in cases",
    "where high significances are claimed , we suggest using a bootstrap estimate of the error on the significance and reporting its value as part of the analysis results . the results of the application of this method to a data set combining data from the ovro monitoring program and _ fermi _ large area telescope are presented in @xcite .",
    "the ovro program is supported in part by nasa grants nnx08aw31 g and nnx11a043 g and nsf grants ast-0808050 and ast-1109911 . support from mpifr for upgrading the ovro 40-m telescope receiver is acknowledged .",
    "w.m . thanks jeffrey scargle , james chiang , iossif papadakis and glenn jones for discussions .",
    "the national radio astronomy observatory is a facility of the national science foundation operated under cooperative agreement by associated universities inc .",
    "th was supported in part by the jenny and antti wihuri foundation and by the academy of finland project number 267324 .",
    "we thank the anonymous referee for constructive comments that greatly improved the presentation of some sections of this paper .",
    "charbonneau , d. , brown , t.  m. , latham , d.  w. , & mayor , m.  2000 , apjl , 529 , l45 chatterjee , r. , jorstad , s.  g. , marscher , a.  p. , et al .",
    "2008 , apj , 689 , 79 coles , w. , hobbs , g. , champion , d.  j. , manchester , r.  n. , & verbiest , j.  p.  w.  2011 , mnras , 418 , 561                                          uttley , p. , edelson , r. , mchardy , i.  m. , peterson , b.  m. , & markowitz , a.  2003 , apjl , 584 , l53 van der klis , m.  1989 , fourier techniques in x - ray timing . in timing neutron stars ( eds .",
    "h. gelman and e. p. j. van den heuvel ) pp .",
    "new york : kluwer academic / plenum publishers    wagner , s.  j. , & witzel , a.  1995 , ara&a , 33 , 163 wall , j.  v. , jenkins , c.  r. , ellis , r. , et al .",
    "2003 , practical statistics for astronomers , by j.v .  wall and c.r .",
    "jenkins .",
    "cambridge observing handbooks for research astronomers , vol .  3 .",
    "cambridge , uk : cambridge university press , 2003"
  ],
  "abstract_text": [
    "<S> we present a practical implementation of a monte carlo method to estimate the significance of cross - correlations in unevenly sampled time series of data , whose statistical properties are modeled with a simple power - law power spectral density . </S>",
    "<S> this implementation builds on published methods , we introduce a number of improvements in the normalization of the cross - correlation function estimate and a bootstrap method for estimating the significance of the cross - correlations . </S>",
    "<S> a closely related matter is the estimation of a model for the light curves , which is critical for the significance estimates . </S>",
    "<S> we present a graphical and quantitative demonstration that uses simulations to show how common it is to get high cross - correlations for unrelated light curves with steep power spectral densities . </S>",
    "<S> this demonstration highlights the dangers of interpreting them as signs of a physical connection . </S>",
    "<S> we show that by using interpolation and the hanning sampling window function we are able to reduce the effects of red - noise leakage and to recover steep simple power - law power spectral densities . </S>",
    "<S> we also introduce the use of a neyman construction for the estimation of the errors in the power - law index of the power spectral density . </S>",
    "<S> this method provides a consistent way to estimate the significance of cross - correlations in unevenly sampled time series of data .    </S>",
    "<S> [ firstpage ]    methods : data analysis  methods : statistical  techniques : miscellaneous </S>"
  ]
}