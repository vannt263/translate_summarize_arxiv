{
  "article_text": [
    "the minkowski ( @xmath4 ) metric is inarguably one of the most commonly used quantitative distance ( dissimilarity ) measures in scientific and engineering applications .",
    "the minkowski distance between two vectors @xmath5 and @xmath6 in the @xmath7-dimensional euclidean space , @xmath3 , is given by    @xmath8    three special cases of the @xmath4 metric are of particular interest , namely , @xmath9 ( city - block metric ) , @xmath10 ( euclidean metric ) , and @xmath11 ( chessboard metric ) . given the general form ( [ equ_lp ] ) , @xmath9 and @xmath10 can be defined in a straightforward fashion , while @xmath11 is defined as    @xmath12    the minkowski metric enjoys the property of being translation invariant , i.e. , @xmath13 for all @xmath14 . since in many applications",
    "the data space is euclidean , the most natural choice of metric is @xmath10 , which has the added advantage being isotropic ( rotation invariant ) .",
    "for example , when the input vectors stem from an isotropic vector field , e.g. , a velocity field , the most appropriate choice is to use the @xmath10 metric so that all vectors are processed in the same way , regardless of their orientation @xcite .",
    "however , @xmath10 has the drawback of a high computational cost due to the multiplication and square root operations . as a result , @xmath9 and @xmath11",
    "are often used as alternatives .",
    "although these metrics are computationally more efficient , they deviate from @xmath10 significantly .    due to the translation invariance of @xmath4",
    ", it suffices to consider @xmath15 , i.e. , the distance from the point @xmath16 to the origin .",
    "therefore , in the rest of the paper , we will consider approximations to @xmath17 rather than @xmath18 .",
    "let @xmath19 , defined on @xmath3 , be an approximation to @xmath20 ( euclidean norm ) .",
    "we assume that @xmath19 is a continuous and absolutely homogeneous function .",
    "recall that @xmath19 is called absolutely homogeneous ( of degree one ) if @xmath21    we note that all variants of @xmath19 we consider in this paper satisfy these assumptions . as a measure of the quality of the approximation of @xmath19 to @xmath20 we",
    "define the maximum relative error ( mre ) as    @xmath22    using the homogeneity of @xmath20 and @xmath19 , can be written as    @xmath23    where @xmath24 is the unit hypersphere of @xmath3 with respect to the euclidean norm .",
    "furthermore , by the continuity of @xmath19 , we can replace the supremum with maximum in and write    @xmath25    we will use as the definition of mre throughout .",
    "mukherjee @xcite recently introduced a class of distance functions called weighted @xmath0-cost distances that generalize @xmath1-neighbor @xcite , octagonal @xcite , and @xmath0-cost @xcite distances .",
    "he proved that weighted @xmath0-cost distances form a family of metrics and derived an approximation for the euclidean norm in @xmath2 . here",
    "we briefly review the @xmath0-cost norm .",
    "the @xmath0-cost norm @xcite defines two points in the rectangular grid as neighbors when their respective hypercubes ( or hypervoxels ) share a hyperplane of any dimension .",
    "the cost associated with these points can be at most @xmath0 , @xmath26 , such that if two consecutive points on a shortest path share a hyperplane of dimension @xmath27 , the distance between them is taken as @xmath28 .",
    "there are @xmath7 distinct @xmath0-cost norms defined by    @xmath29    where @xmath30 is the @xmath31-th absolute largest component of @xmath16 ,",
    "i.e. , @xmath32 is a permutation of @xmath33 such that @xmath34 .",
    "the mre of this norm is given by @xcite    @xmath35    mukherjee generalized the @xmath0-cost norm as follows @xcite :    @xmath36    where @xmath37 s are non - negative real constants .",
    "based on this weighted norm , he then derived an approximation for @xmath20 using the following weight assignment : @xmath38 for @xmath26 .",
    "note that @xmath39 consistently underestimates @xmath20 and the corresponding mre is given by @xcite    @xmath40    in a recent study @xcite , we examined various euclidean norm approximations in detail and compared their average and maximum errors using numerical simulations . here",
    "we show that two of those approximations , namely barni _ et al .",
    "_ s norm @xcite and seol and cheun s norm @xcite , are viable alternatives to @xmath39 .",
    "barni _ et al . _",
    "@xcite formulated a generic approximation for @xmath20 as    @xmath41    where @xmath42 and @xmath43 are approximation parameters .",
    "note that a non - increasing ordering and strict positivity of the component weights , i.e. , @xmath44 is a necessary and sufficient condition for @xmath45 to define a norm @xcite .",
    "barni _ et al .",
    "_ showed that the minimization of ( [ equ_max_err ] ) is equivalent to determining the weight vector @xmath46 and the scale factor @xmath47 that solve the following minimax problem :    @xmath48    where @xmath49 .",
    "the optimal solution and its mre are given by    @xmath50    note the striking similarity between and .",
    "interestingly , a similar but less rigorous approach had been published earlier by ohashi @xcite .",
    "it should also be noted that several authors approached the problem from a euclidean distance transform perspective and derived similar approximations for the @xmath51- and @xmath52-dimensional cases , see for example @xcite and @xcite .",
    "furthermore , computation of weighted ( chamfer ) distances in arbitrary dimensions on general point lattices is discussed in @xcite .",
    "more recently , seol and cheun @xcite proposed an approximation of the form    @xmath53    where @xmath54 and @xmath55 are strictly positive parameters to be determined by solving the following @xmath56 linear system    @xmath57    where @xmath58 is the expectation operator .",
    "seol and cheun estimated the optimal values of @xmath54 and @xmath55 using @xmath59 @xmath7-dimensional vectors whose components are independent and identically distributed , standard gaussian random variables . in @xcite , we demonstrated that a fixed number of samples from the unit hypersphere gives biased estimates for the mre .",
    "the basic reason behind this is the fact that a fixed number of samples fail to suffice as the dimension of the space increases .",
    "it is easy to see that @xmath45 and @xmath60 fit into the general form    @xmath61    which is a weighted @xmath62 norm .",
    "for @xmath45 the weights are @xmath63 and @xmath64 , whereas for @xmath60 they are @xmath65 and @xmath66 .",
    "clearly , @xmath45 has a more elaborate design in which each component is assigned a weight proportional to its ranking ( absolute value ) .",
    "however , this weighting scheme also presents a drawback in that a full ordering of the component absolute values is required .",
    "@xmath45 and @xmath60 can also be written as linear combinations of the @xmath62 and @xmath67 norms , as in .",
    "@xmath62 overestimates the @xmath20 norm , whereas @xmath67 underestimates it @xcite .",
    "therefore , it is natural to expect a suitable linear combination of @xmath62 and @xmath67 to give an approximation to @xmath20 better than either of them @xcite .",
    "note that rosenfeld and pfaltz @xcite obtained a @xmath51-dimensional approximation by combining @xmath62 and @xmath67 nonlinearly as follows : @xmath68 .",
    "due to their formulations , the mres for @xmath39 and @xmath45 can be calculated analytically using and , respectively . in figure [ fig_max_err ]",
    "we plot the theoretical errors for these norms for @xmath69 .",
    "it can be seen that @xmath45 is not only more accurate than @xmath39 , but also it scales significantly better .",
    "maximum relative errors for @xmath39 and @xmath45 ]    the operation counts for each norm are given in table [ tab_cost ] ( * abs * : absolute value , * comp * : comparison , * add * : addition , * mult * : multiplication , * sqrt * : square root ) .",
    "the following conclusions can be drawn :    * @xmath45 and @xmath39 have the highest computational cost due to the fact that they require sorting of the absolute values of the vector components .",
    "* @xmath60 has the lowest computational cost among the approximate norms .",
    "a significant advantage of this norm is that it requires only two multiplications regardless of the value of @xmath7 .",
    "* @xmath60 can be used to approximate @xmath71 ( squared euclidean norm ) using an extra multiplication . on the other hand ,",
    "the computational cost of @xmath45 ( @xmath39 ) is higher than that of @xmath71 due to the extra absolute value and sorting operations involved .    .",
    "[ tab_cost ] operation counts for the norms [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     in table [ tab_avg_max_err ] we display the percentage average and maximum errors for @xmath60 , @xmath45 , and @xmath39 for @xmath72 . average relative error ( are ) is defined as    @xmath73    where @xmath74 is a finite subset of the unit hypersphere @xmath75 , and @xmath76 denotes the number of elements in @xmath74 . an efficient way to pick a random point on @xmath75",
    "is to generate @xmath7 independent gaussian random variables @xmath77 with zero mean and unit variance .",
    "the distribution of the unit vectors    @xmath78    will then be uniform over the surface of the hypersphere @xcite .",
    "for each approximate norm , the are and mre values were calculated over an increasing number of points , @xmath79 ( that are uniformly distributed on the hypersphere ) until the error values converge , i.e. , the error values do not differ by more than @xmath80 in two consecutive iterations .    in table",
    "[ tab_avg_max_err ] , the error values under the column  @xmath81 \" were obtained using the aforementioned iterative scheme , whereas those under the column ",
    "@xmath39 \" are taken from @xcite",
    ". motivated by the fact that @xmath39 consistently underestimates @xmath20 , we also experimented with a normalized form of this approximate norm given by @xmath82 .",
    "note that @xmath83 for @xmath84 .",
    "note that for @xmath39 and @xmath45 , two types of maximum error were considered : empirical maximum error ( @xmath85 ) , which is calculated numerically over @xmath74 and the theoretical maximum error ( @xmath86 ) , which is calculated analytically using and , respectively .    by examining table",
    "[ tab_avg_max_err ] , the following observations can be made regarding the maximum error :    * the most accurate approximation is @xmath45 .",
    "this is because this norm is designed to minimize the maximum error . *",
    "the proposed normalization is quite effective since the resulting norm , @xmath87 , is , on the average , only @xmath88% less accurate than @xmath45 , whereas both @xmath39 @xmath89 and @xmath39 @xmath90 are , on the average , about @xmath91% less accurate than @xmath45 . *",
    "the least accurate approximations are @xmath39 and @xmath60 for @xmath92 and @xmath93 , respectively . * as @xmath7 is increased , the error increases in all approximations .",
    "however , as can also be seen in fig .",
    "[ fig_max_err ] , the error grows faster in some approximations than others . * for @xmath45 ,",
    "the empirical and theoretical errors agree almost perfectly in all cases , which demonstrates the validity of the presented iterative error calculation scheme .",
    "as for @xmath39 , the agreement in each case is close , but not as close as that observed in @xmath45 .",
    "we have confirmed that using a smaller convergence threshold ( @xmath94 ) alleviates this problem at the expense of increased computational cost .",
    "on the other hand , with respect to average error we can see that :    * @xmath60 is the most accurate approximation .",
    "this is because this norm is designed to minimize the average error .",
    "* @xmath39 @xmath89 and @xmath39 @xmath90 are the least accurate approximations .",
    "furthermore , the errors given by mukherjee are lower than those that we obtained ( over @xmath3 ) , and the discrepancy between the outcomes of the two error calculation schemes increases as @xmath7 is increased .",
    "the optimistic average error values given by mukherjee are due to the fact that his approximation was primarily intended for use in digital geometry and hence the calculations were performed in @xmath2 ( rather than @xmath3 ) using a very small number of points ranging from @xmath95 to @xmath96 @xcite .",
    "in fact , mukherjee used progressively fewer points with increasing @xmath7 to calculate the error values . in @xcite",
    ", we demonstrated that more points are required in higher dimensions to obtain unbiased error estimates .    in the calculation of @xmath87",
    ", we assumed that the optimal scaling factor for @xmath39 is the same as that of @xmath45 , i.e. , @xmath97 . in order to check this assumption",
    ", we performed a one - dimensional grid search over @xmath98 $ ] for each @xmath7 value .",
    "the results are shown in table [ tab_avg_max_err_grid ] .",
    "it can be seen that :    * @xmath99 is significantly more accurate than @xmath100 with respect to both are and mre . * @xmath99 and @xmath45 have almost identical mres .",
    "since @xmath45 is analytically optimized for the maximum error it can be concluded that @xmath99 can reach the same optimality by means of a suitable scaling factor . *",
    "interestingly , @xmath99 is more accurate than @xmath45 with respect to are .",
    "this could be due to the fact that the two approximations take different paths towards minimizing the mre .",
    "in this paper , we examined the weighted @xmath0-cost norm recently proposed by mukherjee @xcite with respect to its ability to approximate the euclidean norm in @xmath3 .",
    "we evaluated the average and maximum errors of this norm using numerical simulations and compared the results to those of two other well - known euclidean norm approximations .",
    "the results demonstrated that , because it was designed for digital geometry applications in @xmath2 , the original weighted @xmath0-cost norm is not particularly suited to approximate the euclidean norm in @xmath3 .",
    "it is also shown , however , that when normalized with an appropriate scaling factor , mukherjee s norm becomes competitive with an analytically optimized approximation with respect to both average and maximum relative errors .",
    "this work was supported by grants from the louisiana board of regents ( leqsf2008 - 11-rd - a-12 ) and us national science foundation ( 0959583 , 1117457 ) .",
    "the authors are grateful to the anonymous reviewers for their insightful suggestions and constructive comments that improved the quality and presentation of this paper .",
    "m. barni , f. bartolini , f. buti , and v. cappellini , `` optimum linear approximation of the euclidean norm to speed up vector median filtering , '' proceedings of the 2nd ieee international conference on image processing , pp . 362365 , 1995 ."
  ],
  "abstract_text": [
    "<S> mukherjee ( pattern recognition letters , vol . </S>",
    "<S> 32 , pp . </S>",
    "<S> 824831 , 2011 ) recently introduced a class of distance functions called weighted @xmath0-cost distances that generalize @xmath1-neighbor , octagonal , and @xmath0-cost distances . </S>",
    "<S> he proved that weighted @xmath0-cost distances form a family of metrics and derived an approximation for the euclidean norm in @xmath2 . in this note </S>",
    "<S> we compare this approximation to two previously proposed euclidean norm approximations and demonstrate that the empirical average errors given by mukherjee are significantly optimistic in @xmath3 . </S>",
    "<S> we also propose a simple normalization scheme that improves the accuracy of his approximation substantially with respect to both average and maximum relative errors . </S>"
  ]
}