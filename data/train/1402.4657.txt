{
  "article_text": [
    "_  remember that all models are wrong ; the practical question is how wrong do they have to be to not be useful . \" _  @xcite this quote , by george e.p .",
    "box , a statistician and a pioneer in the areas of quality control and bayesian inference , well applies to the nuclear many - body problem . when it comes to nuclear modeling , uncertainties abound .",
    "indeed , the nuclear interaction , strongly influenced by in - medium effects , is not perfectly known , and the same can be said about many operators associated with observables .",
    "in addition the many - body equations are difficult to crack , which forces nuclear modelers to introduce simplifying assumptions .",
    "the need for uncertainty estimates in papers involving theoretical calculations of physical quantities has been long recognized in the atomic - physics community .",
    "the current situation has been well captured by an editorial in physical review a  @xcite :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ it is all too often the case that the numerical results are presented without uncertainty estimates .",
    "authors sometimes say that it is difficult to arrive at error estimates . should this be considered an adequate reason for omitting them ? [  ] there is a broad class of papers where estimates of theoretical uncertainties can and should be made .",
    "papers presenting the results of theoretical calculations are expected to include uncertainty estimates for the calculations whenever practicable , and especially under the following circumstances : ( 1 ) if the authors claim high accuracy , or improvements on the accuracy of previous work ; ( 2 ) if the primary motivation for the paper is to make comparisons with present or future high precision experimental measurements .",
    "( 3 ) if the primary motivation is to provide interpolations or extrapolations of known experimental measurements .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    this demand applies equally well , if not even more so , in nuclear theory , where we have not a well settled _",
    "ab - initio _ starting point at hand .",
    "we are dealing almost everywhere with effective theories justified in terms of general arguments , but whose parameters are basically unknown and often can not be deduced from _ ab - initio _ modeling .",
    "consequently , those parameters are often determined by fits to empirical data .",
    "this immediately raises the question of the predictive power of such phenomenologically adjusted theories ; hence , there is a need for error estimates of the predicted values .",
    "we have here particularly in mind effective interactions or energy functionals for nuclear structure and dynamics .",
    "these are usually fitted to large sets of experimental data .",
    "the technique of least - squares fitting , involved in these adjustments , opens immediately the door to the well developed strategies for error estimates from statistical ( or regression ) analysis  @xcite .",
    "this is the least we can do , and should do , towards delivering error estimates .",
    "besides mere error estimates , statistical analysis is a powerful instrument to acquire deeper insights into models , e.g. , by determining weakly and strongly constrained parameters or correlations between different observables .",
    "however , a purely statistical analysis is not sufficient , as it does not cover what is called the systematic errors , that is , missing aspects of the modeling .",
    "thus a broad discussion of extrapolation errors must also address systematic errors .",
    "unfortunately , systematic errors are just those which can not be dealt with in systematic manner .",
    "it takes a deep insight into the related exact and approximate theories to have a presentiment of possible pitfalls in a fit .    in the following ,",
    "we address all three aspects : error estimates by statistical analysis , attempts to assess systematic errors , and uncovering inter - dependencies by correlation analysis .",
    "a number of examples will be provided .",
    "some of the questions addressed are :    1 .   how to estimate systematic and statistical errors of calculated quantities ? 2",
    "what is model s information content ?",
    "3 .   how to validate and verify theoretical extrapolations ?",
    "4 .   what data are crucial for better constraining current nuclear models ?    a secondary objective of this guide is to set the stage for the upcoming focus issue of journal of physics g on  enhancing the interaction between nuclear experiment and theory through information and statistics , \" which will contain many excellent examples of uncertainty quantification in nuclear modeling .",
    "we hope that these notes will serve as a useful guide for nuclear theorists , especially those who have not yet embarked on the uncertainty - quantification journey . in this context",
    ", we strongly recommend a recent essay by saltelli and funtowicz  @xcite on modeling issues at the science / policy interface ; we found their checklist to aid in the responsible development and use of models particularly insightful .",
    "the proposed seven - rule checklist helps understanding the different sources of uncertainty and their relative importance  @xcite :    rule 1 : : :    _ use models to clarify , not to obscure_. many - parameter descriptions    can be used at an interim stage on the way to understanding but a fit    seldom provides an answer . remember the quote by von neumann :  _ with    four parameters i can fit an elephant , and",
    "with five i can make him    wiggle his trunk _ \" ? .",
    "models should explain and simplify , but not make    a situation more confused .",
    "rule 2 : : :    _ adopt an ",
    "assumption hunting \" attitude .",
    "_ are model assumptions    expressly stated or implicit / hidden ? what in the model is assumed to    be irrelevant ?",
    "rule 3 : : :    _ detect pseudoscience .",
    "_ be sure that uncertainties have not been    twisted to provide desired results .",
    "rule 4 : : :    _ find sensitive assumptions before they find you .",
    "_ carry out    technically sound sensitivity studies .",
    "rule 5 : : :    _ aim for transparency .",
    "_ fellow scientists should be able to replicate    the results of your analysis .",
    "rule 6 : : :    _ do nt just  do the sums right , \" but  do the right sums \" _  to address    the relevant uncertainties .",
    "rule 7 : : :    _ focus the analysis .",
    "_ sensitivity analysis of a many - parameter system    can not be done by merely changing one parameter at a time .",
    "these notes are structured as follows . in sec .",
    "[ sec : generalerrors ] , we discuss the notion of statistical and systematic errors . section [ sec : chi2 ] summarizes the technique of least - squares optimization and shows how to estimate statistical errors . in sec .",
    "[ sec : systematic ] , we discuss systematic errors and employ two pedagogical models to illustrate basic concepts . in sec .",
    "[ sec : correl ] , we come back to statistical analysis and show how it allows us to acquire deeper insights into model s information content .",
    "section [ sec : examples ] contains selected examples from recent work .",
    "in general , there are no surefire prescriptions for assigning error bars to theory .",
    "model uncertainties have various sources , some are rooted in experimental errors , some in model deficiencies .",
    "as well put by albert tarantola  @xcite :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the predicted values can not , in general , be identical to the observed values for two reasons : measurement uncertainties and model imperfections .",
    "these two very different sources of error generally produce uncertainties with the same order of magnitude , because , due to the continuous progress of scientific research , as soon as new experimental methods are capable of decreasing the experimental uncertainty , new theories and new models arise that allow us to account for the observations more accurately . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    while the mutual interaction between experiment and theory resulting in a mutual reduction of uncertainties better applies to atomic theory , as theoretical uncertainties usually dominate experimental ones in nuclear modeling , the positive feedback described in the above quotation constitutes the situation we all should be striving to .",
    "_ _ is usually quantifiable for many models .",
    "namely , when the model is based on parameters that were fitted to large datasets , the quality of that fit is an indicator of the statistical uncertainty of the model s predictions .",
    "the commonly employed tool to estimate statistical errors is the regression analysis .",
    "section  [ sec : chi2 ] shows how to estimate statistical errors by means of weighted least squares .",
    "_ _ is due to imperfect modeling : deficient parametrizations , wrong assumptions , and missing physics due to our lack of knowledge . since in most cases",
    "the perfect ( exact , reference ) model is not available , systematic errors are extremely difficult to estimate . especially in the context of huge extrapolations ,",
    "no perfect strategy exists to assess systematic errors , as some model features that are unimportant in the known regions may become amplified , or even dominant , in the new domains .",
    "some commonly used ways to assess systematic model errors are discussed in sec .  [",
    "sec : systematic ] .    in all optimization problems ,",
    "the key element of the approach is the appropriate definition of the so - called penalty function .",
    "this function , which depends on model parameters , experimental data , and most often also on pre - defined parameters specified by the modelers , gives us a one - dimensional measure of the quality of the fit . by definition ,",
    "model parameters leading to a smaller value of the penalty function are considered to be superior to those leading to a larger value .",
    "the optimization process is thus reduced to a minimization of the penalty function .",
    "one can not underestimate , and one should never forget about , a possible fundamental influence of the definition of the penalty function on the results of the optimization process . through this definition , a researcher may indeed exert influence on the modeling ",
    "this effect is as ubiquitous and fundamental as the influence of an observer on a quantum system investigated .    for an exact model , the task",
    "is reduced to the optimization problem , in which model s parameters are determined by comparing predicted observables with carefully selected set of data .",
    "for such a perfect model , the systematic error is zero , and the total error is statistical , that is , it is given predominantly by the quality of the measurement of the key data determining the model .",
    "moreover , exact models are characterized by an independence , or a weak dependence , of the final result on the definition of the penalty function  @xcite .    in practice ,",
    "nuclear models are imperfect , as most effective models are , and the total uncertainty is usually dominated by systematic effects .",
    "how useful is it , therefore , to compute statistical uncertainties of an imperfect model ?",
    "there are , in fact , several good reasons to embark on such a task :    1 .",
    "statistical analysis yields uncertainties of model parameters .",
    "in particular , by studying statistical errors on parameters one can assess whether the dataset used to constrain the model is adequate ( in terms of quality and quantity ) .",
    "2 .   statistical analysis can be used to compare different mathematical formulations / assumptions and benchmark different approaches . in this case , it is essential to use the same set of fit observables .",
    "3 .   the covariance matrix of the parameters tells us whether adding more data makes sense .",
    "if the dataset is sufficiently diverse ( that is , it allows us to probe all directions in the model s parameter space ) and large , the model may become over - constrained , and the resulting statistical uncertainties may become small . in such a case , by inspecting the non - statistical behavior of residuals ( which are the differences between the observed and the estimated values ) one can assess sources of missing model features leading to systematic errors .",
    "4 .   statistical method allows one to estimate the maximum model s accuracy on a class of observables .",
    "if a higher accuracy is required , further model refinements are needed .",
    "5 .   by assessing statistical errors of extrapolated quantities",
    ", one can make a statement whether a model carries any useful information content in an unknown domain .",
    "6 .   by using bayesian inference , one can test model s adequacy as additional data are added , or additional evidence is acquired ( for some recent nuclear examples , see , e.g. , refs .",
    "@xcite ) . 7 .",
    "the covariance matrix of the parameters enables one to compute correlations between various observables predicted within a model .",
    "this is a very useful tool when making new predictions and guiding future experiments @xcite .",
    ".   a comparison of propagated statistical errors with residuals can be one of the most powerful indicators of presence of missing aspects of the model  @xcite .",
    "let us consider a model having @xmath0 parameters @xmath1 that are fitted to @xmath2 measured observables @xmath3 ( @xmath4 ) .",
    "the steps are : define a penalty function , minimize it with respect to the parameters @xmath5 , construct the covariance matrix of the parameters , and then apply the covariance matrix to estimate errors of predictions by associating them with uncertainties in the parameter values .",
    "the commonly used penalty function is the objective function , by which we begin .",
    "we define the function for the parameter fit as  @xcite @xmath6 where @xmath7 stands for the calculated values , @xmath8 for experimental data , and @xmath9 for adopted errors .",
    "( it is to be noted , that when dealing with observables that change by orders of magnitude ( yields , half - lives ) , one must use @xmath10 rather than @xmath11 in eq .",
    "( [ chi2 ] ) . ) the model is thus defined not only by the equations that are used to calculate the predicted observables ( that is , mathematical formulation and assumed model space ) , but also by the dataset @xmath12 and adopted errors @xmath13 used to determine the parameters .",
    "the adopted errors are determined as follows .",
    "each one is the sum of three components : @xmath14 since the set of fit observables is usually divided into types ( masses , radii ,  ) , errors are adopted for each data type separately .",
    "the experimental error , @xmath15 , is whatever the experimentalists or evaluators quote in their datasets .",
    "the numerical error associated with the chosen computational approach , @xmath16 , is also generally small , but may not be such for models based on , e.g. , basis expansion methods  @xcite . in those cases , the numerical error needs to be estimated .",
    "the remaining part , @xmath17 , is the theoretical error due to inherent deficiencies of the model .    a judicious choice of the adopted errors @xmath17 is the crucial ingredient to the method for model development . in practice",
    ", the residuals of predicted observables should be confined to the range defined by @xmath17 .",
    "if only statistical errors are present , the residuals are stochastically distributed . since",
    "nuclear models are not perfect , however , trends in the residuals will appear due to systematic errors .",
    "if different types of observables are present in the dataset , adopted errors have to be defined for each type .",
    "for example , typical nuclear fits use one value of @xmath17 for binding energies , another one for r.m.s .",
    "radii , and so forth .",
    "each @xmath17 carries the same dimension as the observable @xmath7 thus rendering each contribution to dimensionless . in this way ,",
    "different types of observables are combined into one penalty function .",
    "the inverse square root @xmath18 defines the relative weight , wherewith the observable @xmath7 enters the optimization problem . by changing the values of @xmath19",
    ", one can control the impact of a particular observable , or a type of observables , on the resulting parametrization .",
    "it needs hardly be said that a certain degree of arbitrariness in choosing the weights @xmath19 is inevitable , as they can be set individually for every observable . in some cases ,",
    "the weights vary from datum to datum @xcite , while in many cases equal weights @xmath19 are chosen for all observables of a given type .",
    "clearly , there is no  obvious \" choice here  @xcite , and various optimization protocols ( driven by physics strategies ) are possible .",
    "this ambiguity is one of the primary reasons for a proliferation of parametrizations in nuclear structure theory .",
    "fortunately , there is one guiding principle that comes to the rescue .",
    "remember that in the case of statistical fluctuations there is a consistency between the distribution of residuals and the adopted error .",
    "namely , the rules of statistical analysis require that the total penalty function at the minimum should be normalized to @xmath20 , i.e. , the average @xmath21 per degree of freedom should be one : @xmath22 this condition provides an overall scale for the normalization of the penalty function at the minimum and removes some of the arbitrariness in choosing the weights .",
    "now , the basic idea is to tune the @xmath17 so that it is consistent with the distribution of residuals , even if this distribution is non - statistical .",
    "the relative weights between the types of observables can thus be determined by requiring that the average for each type is @xmath23 where @xmath24 is the number of data points of a given type .",
    "it is thus clear that the values @xmath25 obeying the normalization condition ( [ onorm ] ) can not be chosen from the onset , but have to be determined iteratively during the optimization process . in practice ,",
    "the conditions ( [ cnorm ] ) or ( [ onorm ] ) are seldom fulfilled exactly .",
    "for example , it often happens that one wants to study variations of a fit while keeping the adopted errors fixed @xcite , which inevitably changes the normalization condition ( [ cnorm ] ) . in order to deal with such situations ,",
    "we introduce a global scale factor @xmath26 such that @xmath27 this amounts to a global readjustment @xmath28 which establishes correct normalization for @xmath29 , but leaves the relative weights untouched .",
    "if experimental and numerical errors are small compared to theoretical uncertainties , i.e. , @xmath30 , assumption ( [ chi2min ] ) defines a trivial scale factor , which does not impact the minimum @xmath31 . in the following",
    ", we shall carry through all expressions with the scale factor @xmath26 .",
    "this means that the standard rules of statistical analysis will apply to the normalized @xmath29 .",
    "assumption ( [ chi2min ] ) , through its triviality is , in fact , the only one that does not depend on the researcher s choice . in this way",
    ", the normalization of at its minimum value at @xmath31 is fixed by definition .",
    "this implies that one deals here with a model that is fundamentally inaccurate and can not describe simultaneously all the data within the experimental and numerical errors alone .",
    "as it has been noted previously , in the case of negligible experimental and numerical errors , the minimization of does not depend on the condition ( [ chi2min ] ) ; hence , the scale @xmath26 can be computed after determining @xmath31 .    in principle , an auxiliary scale factor @xmath32 can be introduced for each data type , if the adopted theoretical errors are being adjusted during the optimization process .",
    "this amounts to a readjustment @xmath33 for @xmath34 in each optimization step .",
    "the situation is particularly simple if one assumes the same weights for each data type . in this case",
    "the value of @xmath32 in a given step can be obtained directly from the condition ( [ onorm ] ) .",
    "such an iterative adjustment , leading eventually to @xmath35 , is recommended if the researcher has no intuition about the expected theoretical error , and/or experimental and numerical errors are not negligible ( see ref .",
    "@xcite for a practical realization of an iterative adjustment of @xmath36 using the maximum likelihood method . ) in practical situations , however , this is seldom the case , and a global scaling ( [ chi2min ] ) following the minimization is fully adequate .    another extreme case is the one when experimental / numerical errors are so large that they mask the theoretical error entirely , and thus one can set @xmath37 .",
    "this case is often encountered in curve fitting of experimental data .",
    "in such a situation the value of @xmath38 provides a direct estimate of the quality of the fit .",
    "the optimum parametrization @xmath31 is the one that minimizes the penalty function , in particular , the @xmath39 function , with the minimum value of @xmath40 .",
    "a global model optimization becomes very involved when several categories of fit - observables are considered .",
    "such optimization procedures are expensive , as they require a large number of model evaluations .",
    "consequently , it is always useful for the global optimization to have preliminary estimates for the parameter values and their errors .",
    "an efficient pre - optimization method , particularly convenient if observables are linear functions of model parameters , is the linear regression algorithm employing the singular value decomposition ( svd ) .",
    "this method has been used in the context of mass fits  @xcite , single - particle energies  @xcite , and pre - optimization of novel functionals  @xcite .",
    "the advantage of the svd approach is that it can provide an efficient and accurate assessment of model s error pertaining to a selected category of observables .",
    "in addition , it provides an estimate of the effective size of the model parameter space  @xcite .",
    "many least - square solvers included in optimization packages contain an svd truncation of the parameter space .",
    "usually , most of the model space produces observables which are far from reality .",
    "therefore , one needs to confine the model space to a `` physically reasonable '' domain around the minimum @xmath31 . within this domain",
    "there is a range of `` reasonable '' parametrizations @xmath5 that can be considered as delivering a decent fit , that is , @xmath41 ( see sec .  9.8 of ref .",
    "as this range is usually rather small , we can expand @xmath39 as @xmath42{.1mm}{1.2em}}}_{\\,{\\boldsymbol{p}}_0},\\end{aligned}\\ ] ] that is , @xmath43 is the hessian matrix of at the minimum @xmath31 .",
    "the reasonable parametrizations thus fill the confidence ellipsoid given by @xmath44 see sec .",
    "9.8 of ref .",
    "@xcite and fig .  [ domain ] .     the schematic illustration of a physically reasonable domain around the @xmath45 minimum at @xmath46.,scaledwidth=70.0% ]      given a set of parameters @xmath5",
    ", any observable @xmath47 can be within the model uniquely computed as @xmath48 .",
    "the value of @xmath47 thus varies within the confidence ellipsoid , and this results in some uncertainty @xmath49 of a. let us assume , for simplicity , that the observable varies weakly with @xmath5 , such that one can linearize it in the relevant range , that is , @xmath50{.1mm}{1.2em}}}_{\\,{\\boldsymbol{p}}_0}.\\ ] ] let us , furthermore , associate a weight @xmath51 with each parameter set  @xcite .",
    "the prescription for assigning an error to the predicted value @xmath52 is the following formula : @xmath53 where @xmath54 is the covariance matrix . upon the assumption that the fitted observables @xmath55 depend only linearly on parameters @xmath5 , the covariance matrix",
    "is simply related to the hessian matrix as [ mcovar ] = s^-1 = s(^t ) ^-1 , where [ jacobian ] _",
    "i = is the jacobian matrix , which is inversely proportional to the adopted errors .",
    "if the condition ( [ chi2min ] ) is met with @xmath56 , the expression for the covariance matrix simplifies to @xmath57 see table  [ tab : chis ] , middle column .",
    "in particular , by taking @xmath58 , one obtains the expression for the statistical error of the model parameter @xmath59 : @xmath60 .",
    "we note that if the fitted observables weakly depend on some parameters , the hessian matrix becomes almost singular and the covariance matrix becomes ill - conditioned .",
    "in such a case , errors or all predicted values ( [ predicted_error ] ) become unreasonably large .",
    "this shows again that observables that weakly depend on model parameters should not be fitted and parameters that have small impact on the results should be removes from the model by proper pre - optimization procedures , see sec .",
    "[ sec:2.2.2 ] and discussion in sec .",
    "ii.b of ref .",
    "@xcite .",
    "the hessian ( @xmath61 ) , covariance ( @xmath54 ) , and jacobian ( @xmath62 ) matrices constitute the basic ingredients of the statistical - error analysis , and thus should be routinely computed following the optimization process .",
    "it is worth noting that the hessian matrix , @xmath63 , increases linearly with the number @xmath2 of data points constraining the model .",
    "this is best visible in the case of identical observables @xmath64 accompanied with identical adopted errors @xmath65 , whereupon one has [ identical ] _ = ( _ p___0 ) ( _ p___0 ) .",
    "therefore , the statistical uncertainty ( [ predicted_error ] ) does decrease with the number @xmath2 of data points constraining the model .",
    "indeed , if our model were exact @xmath66 , by taking a very large number @xmath2 of fit observables , the model observables would be determined with an arbitrary accuracy , that is , @xmath67 and the precision would improve as the square root of the number of measurements ( data points ) , see eq .",
    "( 4.12 ) of ref .",
    "@xcite . in general , as the number of uncorrelated data points grows and the number of parameters stays fixed , the confidence intervals become tighter .",
    "this does not mean , of course , that by increasing @xmath2 we can make predictions more accurate . at some point , adding more fit observables makes little sense as the model error becomes dominated by the systematic error , see sec .",
    "[ sec : systematic ] .",
    "naturally , the precision of an exact model also improves when all experimental data are determined with smaller and smaller uncertainties @xmath68 .",
    "however , when the model is inaccurate and the theoretical errors dominate , the normalization condition ( [ chi2min ] ) applied to observables of the same type , assuming identical weights , gives : @xmath69 that is , typical adopted theoretical errors are of the order of a typical residual , and can not be further decreased .",
    "a systematic error of a theoretical model is a consequence of missing physics and/or poor modeling . since in most cases",
    "the perfect model is not available , systematic errors are very difficult to estimate .",
    "to get some idea about systematic uncertainties , especially in the context of extrapolations , one can adopt the following strategies :    analysis of residuals : :    study the distribution of residuals for a given observable . for a    perfect model ,",
    "one should see a statistical distribution . in most    practical cases , however , one does see systematic trends .",
    "these often    allow us to guess the underlying missing physics , see    sec .",
    "[ sec : illust ] for examples .",
    "analysis of inter - model dependence : :    make a number of predictions @xmath70 of an observable    @xmath71 using a set of @xmath72 reasonable and    sufficiently different models @xmath73    @xmath74 _ well calibrated to existing data _ and    based on different theoretical assumptions / optimization protocols .    assuming that the biases introduced in different models are    independent",
    ", one hopes that some randomization of systematic errors    would take place .",
    "the predicted model - averaged value of an observable    @xmath71 can be written as :    @xmath75    with the corresponding systematic error    @xmath76    which provides the scale of the model uncertainty .",
    "comparison with existing data : :    the systematic errors of fit observables can be estimated by    optimizing the model using a large number data points to guarantee    that the statistical error is small . then compute the r.m.s .",
    "deviation    @xmath77 from the known experimental    data for a given type of observables ( e.g. , masses or radii ) .",
    "the    systematic error of a predicted observable @xmath71    belonging to this type should be at least of the order of    @xmath77 .",
    "it is recommended to combine the strategies above by investigating both @xmath78 and @xmath77 .",
    "having estimated the systematic and statistical error ( [ predicted_error ] ) , the predicted observable @xmath71 can be written as @xmath79 let us emphasize again that the proposed analysis of adopted errors ( and hidden systematic errors ) does not fully allow us to estimate the contribution of the systematic error to extrapolations , as the available data usually constrain only a limited region of the model parameter space .      in this section , methodologies used to estimate",
    "statistical and systematic errors are illustrated by means of schematic examples .",
    "those are followed in sec .",
    "[ sec : examples ] by references to recent studies aiming at uncertainty quantification in the context of realistic nuclear modeling .      in this example",
    ", we illustrate the concept of statistical and systematic errors using theoretically generated pseudo - data  @xcite : @xmath80 where @xmath81 stands for a magnitude of an odd - even staggering of a physical quantity ( mass , radius , ... ) , @xmath82 represents a white noise with zero mean ( for both @xmath83-even and @xmath83-odd ) and finite variance @xmath84 and @xmath2 ( an even number ) is a number of data points .",
    "it is assumed that @xmath85 and @xmath86 . to interpret the dataset ( [ oed ] ) we employ two models of one fitted observable :    model a : : :    @xmath87    ( @xmath88 ) .",
    "model b : : :    @xmath89    ( @xmath90 ) .",
    "let us begin with model a. it corresponds to a typical situation , in which the nuclear model is imperfect , and experimental errors are small .",
    "the minimization of @xmath39 yields @xmath91 , and the condition ( [ chi2min ] ) yields @xmath92 . the resulting jacobian matrix ( [ jacobian ] ) is @xmath93 ; hence , the covariance matrix ( [ mcovar ] ) becomes @xmath94 .",
    "this is consistent with the discussion in sec .",
    "[ datapoints ] : the statistical uncertainty ( [ predicted_error ] ) decreases with the number @xmath2 of data points constraining the model . the estimated statistical error on the odd - even staggering , @xmath95 ,",
    "can become very small if one takes very many data points .",
    "this of course does not mean that our prediction is accurate .",
    "indeed , by inspecting the residuals of model a shown in fig .  [ oes](a ) , one immediately concludes that their distribution is _ not _ statistical .",
    "this suggests the presence of a large systematic error that can be estimated as @xmath96 .",
    "consequently , for model a , @xmath97 .",
    "odd - even staggering residuals for model a ( top ) and model b ( bottom ) .",
    "the gray band indicates the variance of the data noise.,scaledwidth=70.0% ]    by inspecting the pattern of the residuals of model a , one concludes that this model is not adequate , and this leads to a two - parameter model b. here , the minimization of @xmath39 yields @xmath98 , and the condition ( [ chi2min ] ) gives @xmath99 .",
    "the resulting jacobian matrix ( [ jacobian ] ) is @xmath100 ; hence , the covariance matrix ( [ mcovar ] ) becomes @xmath101 , where @xmath102 is a ( 2@xmath1032 ) unity matrix .",
    "figure  [ oes](b ) shows the corresponding residuals : they are statistically distributed around zero .",
    "this tells us that model b is perfect , and its error is statistical : @xmath104 .      in this example",
    ", we test the @xmath39-optimization by using theoretically - generated pseudo - data . to this end , @xmath105 even - even nuclei with @xmath106 listed in the audi - wapstra mass tables were computed with the skyrme functional sv - bas  @xcite using the axial hf+bcs approach .",
    "their binding energies were taken as pseudo - data to which a four - parameter ( @xmath107 ) ldm model for the total binding energy , @xmath108 was optimized .",
    "the adopted theoretical error on @xmath109 of 3.8 mev was tuned according to eq .",
    "( [ cnorm ] ) .",
    ".[ldmtable ] parameters of the ldm mass model ( [ ldm ] ) optimized to sv - bas masses (  fitted \" ) compared to sv - bas ldm constants obtained by means of the leptodermous expansion  @xcite .",
    "all values in mev . [ cols=\"^,^,^,<\",options=\"header \" , ]",
    "10                                  a.  ekstrm , g.  baardsen , c.  forssn , g.  hagen , m.  hjorth - jensen , g.  r. jansen , r.  machleidt , w.  nazarewicz , t.  papenbrock , j.  sarich , and s.  m. wild .",
    "optimized chiral nucleon - nucleon interaction at next - to - next - to - leading order . , 110:192502 , 2013 .",
    "m.  stoitsov , m.  kortelainen , s.  k. bogner , t.  duguet , r.  j. furnstahl , b.  gebremariam , and n.  schunck . microscopically based energy density functionals for nuclei using the density matrix expansion : implementation and pre - optimization . , 82:054307 , 2010 ."
  ],
  "abstract_text": [
    "<S> this guide offers suggestions / insights on uncertainty quantification of nuclear structure models . </S>",
    "<S> we discuss a simple approach to statistical error estimates , strategies to assess systematic errors , and show how to uncover inter - dependencies by correlation analysis . </S>",
    "<S> the basic concepts are illustrated through simple examples . by providing theoretical error bars on predicted quantities and using statistical methods to study correlations between observables , theory can significantly enhance the feedback between experiment and nuclear modeling . </S>"
  ]
}