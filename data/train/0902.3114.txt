{
  "article_text": [
    "we assume the reader is familiar with fountain codes , lt - codes and belief propagation ( bp ) decoding . for details ,",
    "the reader is referred to @xcite , @xcite .",
    "we consider lt - codes with parameters @xmath3 , where @xmath0 is the message length and @xmath4 is the degree distribution of the output symbols during encoding . an important set to consider is the set of output symbols of degree @xmath5 ( the _ ripple _ ) .",
    "the size of the ripple varies during the decoding process , as high - degree output symbols become of degree @xmath5 after the removal of their edges , and as ripple elements become useless after the recovering of their unique neighbor .",
    "the decoding is in error if and only if the ripple becomes empty before all the input symbols are recovered .",
    "a natural question is thus whether we can track the size of the ripple , in the expectation , during the decoding process .",
    "karp et al .",
    "@xcite proved that the expected ripple size is linear in @xmath0 throughout most of the decoding process .",
    "their asymptotic analytic expressions for the expected ripple size can be found in section [ prelim ] .",
    "they also derive an expression for the expected _ cloud _ size throughout decoding , where the cloud is defined at each decoding step as the set of output symbols of degree strictly higher than @xmath5 .    in this paper , we extend their analysis in two ways .",
    "first , we consider higher moments of the cloud and ripple size in order to upper bound the error probability of the lt decoder .",
    "more specifically , we use similar methods to derive an expression for the variance of the ripple size and prove that it is also linear in @xmath0 throughout most of the decoding process . we can then use this expression together with the expression for the expectation to offer a guarantee for successful decoding , as follows : if , for fixed lt - code parameters , @xmath6 is the expectation and @xmath7 is the standard deviation of the ripple size when @xmath8 symbols are unrecovered , then if the function @xmath9 for some parameter @xmath10 never takes negative values , we can upper bound the error probability of the lt decoder by the probability that the ripple size deviates from its mean by more than @xmath10 standard deviations .",
    "second , we take the first step towards an analytic finite - length analysis of the lt decoder , by providing exact expressions for the expectation ( variance ) of the ripple size up to @xmath11 ( constant ) terms .",
    "this is done by considering lower - order terms in the difference equations , but also by getting tight bounds on the discrepancy introduced by approximating difference equations by differential equations .",
    "it is worthy to note that the expressions we deal with are valid for `` most of the decoding process , '' that is , the analysis breaks down when the number of unrecovered symbols is no longer a constant fraction of @xmath0 .",
    "this is no issue , however , when one considers raptor codes , which need only a constant fraction of the input symbols to be recovered by the lt decoder @xcite .",
    "let @xmath8 be the number of unrecovered ( _ undecoded _ ) input symbols at a given decoding step . define the decoder to be in state @xmath12",
    "if the cloud size is @xmath10 and the ripple size is @xmath13 at this decoding step . to each state @xmath12 , we can associate the probability @xmath14 of the decoder being in this state .",
    "define the _ state generating function _ of the lt decoder when @xmath8 symbols are undecoded as @xmath15 the following theorem by karp et al .",
    "gives a recursion for the state generating function of the lt decoder .",
    "+    @xcite suppose that the original code has @xmath0 input symbols and that @xmath16 output symbols have been collected for decoding .",
    "further , denote by @xmath17 @xmath18 the probability that an output symbol is of degree @xmath19 where @xmath20 is the maximum degree of an output symbol .",
    "then we have for @xmath21 @xmath22 ,   \\end{split}\\ ] ] where for @xmath23 @xmath24 } { \\left [ \\begin{array}{c } k-2\\\\ d-2\\\\ \\end{array } \\right]}}{1 - u \\sum_{d=1}^d \\omega_d d \\frac{\\left [ \\begin{array}{c } k - u\\\\ d-1\\\\ \\end{array } \\right]}{\\left [ \\begin{array}{c } k\\\\ d\\\\ \\end{array } \\right ] } - \\sum_{d=1}^d \\omega_d \\frac{\\left [ \\begin{array}{c } k - u\\\\ d\\\\ \\end{array}\\right]}{\\left [ \\begin{array}{c } k\\\\ d\\\\ \\end{array}\\right]}},\\ ] ]    and @xmath25 : = \\binom{a}{b } b!,\\ ] ] and @xmath26 further , @xmath27",
    "+    this recursion gives a way to compute the probability of a decoding error at each step of the bp decoding as @xmath28 and the overall error probability of the decoder as @xmath29    if we approximate the lt process by allowing output symbols to choose their neighbors with replacement during encoding , @xmath30 becomes : @xmath31 where @xmath32    with this assumption , karp et al .",
    "use the recursion to derive difference equations for the expected size of the ripple and the cloud , and further approximate these difference equations by differential equations that they solve to get closed - form expressions for the expected ripple and cloud size .",
    "formally , let @xmath6 denote the expected number of output symbols in the ripple , and @xmath33 denote the expected number of output symbols in the cloud , when @xmath8 input symbols are undecoded , where @xmath8 is assumed to be a constant fraction of the total number of input symbols @xmath0 .",
    "then the following theorem shows that @xmath6 is linear in @xmath0 for an appropriate choice of the lt code parameters .",
    "+    @xcite[exp ] consider an lt - code with parameters @xmath3 and assume @xmath34 symbols have been collected for decoding . during bp decoding , let @xmath33 and @xmath6 be respectively the expected size of the cloud and ripple as a function of the number @xmath8 of undecoded input symbols . then",
    ", under the assumptions that @xmath8 is a constant fraction of @xmath0 and @xmath35 we have @xmath36    in what follows , we let @xmath37 be a continuous approximation of @xmath38 a normalized version of @xmath39 @xmath37 can be shown to be the solution of the differential equation @xmath40 with initial condition @xmath41 and is given by @xmath42 with @xmath43    similarly , we define @xmath44 as a continuous approximation of @xmath45 @xmath44 is the solution of @xmath46 with initial condition @xmath47 and is given by @xmath48 with @xmath49    then we can write @xmath50",
    "let @xmath51 be the variance of the ripple size as a function of the number of undecoded symbols @xmath8 . in what follows we will always assume that @xmath8 is a constant fraction of @xmath0 .",
    "@xmath51 is given by @xmath52 where we define @xmath53 it is thus enough to find an expression for @xmath54 to get an expression for @xmath55 we start by differentiating both sides of the recursion ( [ recursion ] ) twice with respect to @xmath56 and evaluating at @xmath57 this gives us a recursion for @xmath58 @xmath59 .",
    "\\end{split}\\ ] ] before we can proceed with solving this difference equation , we need to find expressions for the second - order derivatives @xmath60 and",
    "@xmath61 we do so by following exactly the same method that we are currently outlining for an expression for @xmath62 define @xmath63 let @xmath64 be a continuous approximation of the normalized function @xmath65 it can be shown that @xmath64 is the solution of the differential equation @xmath66 with initial condition @xmath67 and is given by the expression @xmath68 with @xmath69 similarly , let @xmath70 be a continuous approximation of @xmath71 it is the solution of @xmath72 with initial condition @xmath73 and an expression for it is @xmath74 with @xmath75 then the following theorem gives closed - form expressions for @xmath76 and @xmath77 +    [ ml ] @xmath78    as for the `` dirt '' term @xmath79,\\ ] ] it does not involve derivatives and we can not use the same method to find an expression for it independant the state generating function . however , we can bound it under an assumption on the ripple size . more specifically",
    ", it is not difficult to prove that for @xmath80 , the dirt term is of constant order . in what follows ,",
    "we assume that the size of the ripple does not go below the constant @xmath81 .",
    "replacing @xmath76 and @xmath82 by their expressions and bounding the dirt term in the recursion ( [ n_rec ] ) , we obtain the following difference equation for @xmath58    @xmath83    note that @xmath54 as defined in equation ( [ defn ] ) can be as large as a constant fraction of @xmath84 .",
    "we thus need to normalize @xmath54 if we want to say something meaningful about the difference @xmath85 we define @xmath86 to be the _ fraction _ of undecoded symbols , and let @xmath87 be a normalized version of @xmath62 we similarly normalize the other functions of @xmath8 and represent them as functions of @xmath88 : @xmath89 normalizing equation ( [ n_difference ] ) and replacing the functions @xmath90 by their continuous approximations , we obtain @xmath91 neglecting lower - order terms , we approximate @xmath92 by the function @xmath93 which satisfies @xmath94 with initial condition @xmath95 +    [ claim1 ] for any @xmath88 on which @xmath92 is defined , @xmath92 and @xmath93 differ by a term of the order of @xmath96 +    we skip the proof of this and subsequent claims for reasons of space , and refer the reader to the final version of this paper .",
    "we further approximate the discrete function @xmath93 by the continuous function @xmath97 and @xmath98 by the first - order derivative of @xmath99 .",
    "@xmath99 satisfies the differential equation @xmath100 with initial condition @xmath101 +    [ claim2 ] for any @xmath88 on which @xmath93 is defined , @xmath93 and @xmath99 differ by a term of the order of @xmath96 +    the general solution of the differential equation ( [ diffnhat ] ) is given by @xmath102 where the value of the constant @xmath103 can be found to be , by the initial conditions , @xmath104 by claims [ claim1 ] and [ claim2 ] we thus have @xmath105 where @xmath99 is given by equation ( [ nhat ] ) .",
    "this gives us an expression for @xmath106 up to a term of the order of @xmath0 : @xmath107 comparing this expression to that for @xmath108 given by equations ( [ r_hat ] ) and ( [ r ] ) , it is easy to see that these two expressions agree up to terms of the order of @xmath0 , so that the variance of the ripple size @xmath109 is of the order of @xmath0",
    ". +    consider an lt - code with parameters @xmath3 and let @xmath7 be the standard deviation of the ripple size throughout bp decoding",
    ". then @xmath110",
    "our ultimate goal is to be able to bound the error probability of the decoder as a function of @xmath0 , without the assumption that @xmath0 goes to infinity .",
    "we thus need to find an expression for the variance of the ripple size , instead of simply determining its order . for this purpose",
    ", we must find an expression for @xmath54 up to terms of constant order , and an expression for @xmath6 up to terms of the order of @xmath96 we illustrate the analysis for @xmath62 from the recursion given by equation ( [ n_rec ] ) , we proceed by first , assuming that the ripple size does not go below @xmath111 so that the `` dirt '' term is of the order of @xmath2 ; and second , replacing @xmath112 @xmath113 @xmath114 and @xmath82 by finer approximations as follows : @xmath115 where @xmath116 is a discrepancy term introduced by approximating @xmath33 by @xmath117 and @xmath118 are defined similarly .",
    "these discrepancy terms are all of the order of @xmath2 and are given by the following expressions .",
    "@xmath119    where @xmath120 and @xmath121 are constants for most of the decoding process and are given by @xmath122    these expressions are obtained by the same method that we are now following to obtain a more precise approximation of @xmath62    the next step is to write a recursion for @xmath92 which is exact up to terms of the order of @xmath123 we then approximate @xmath92 by @xmath93 which satisfies the same recursion except that we neglect terms of the order of @xmath124 : @xmath125    [ claim3 ] for any @xmath88 on which @xmath92 is defined , @xmath92 and @xmath93 differ by a term of the order of @xmath126 +    we further approximate @xmath93 by @xmath99 which satisfies the differential equation ( [ diffnhat ] ) and is given by expression ( [ nhat ] ) . a more careful analysis of the discrepancy beween @xmath99 and @xmath93 leads to the following claim : +    [ claim4 ] for any @xmath88 on which @xmath93 is defined ,",
    "@xmath93 and @xmath99 differ by a term of the order of @xmath96 + more precisely , @xmath127 where @xmath128 \\cdot \\prod_{j = i+1}^{k(1-x)-1}\\left(1-\\frac{2}{k(1-j / k)}\\right)+o(1/k^2 ) .",
    "\\end{split}\\ ] ]    by claims [ claim3 ] and [ claim4 ] we thus have @xmath129 where @xmath99 is given by equation ( [ nhat ] ) . using the resulting expression for @xmath54 , and the expression for @xmath6 given by equation ( [ precise_vals ] ) , we finally get an expression for the variance of the ripple size up to terms of constant order .",
    "+    consider an lt - code with parameters @xmath3 and overhead @xmath130 and let @xmath51 be the variance of the ripple size throughout bp decoding .",
    "then @xmath131    figure [ capsol ] shows a plot of the expected ripple size and the functions @xmath132 and @xmath133 given by equation ( [ hc ] ) , throughout the decoding process , for an lt - code with @xmath134 and @xmath135 and with the `` capped soliton '' degree distribution @xmath136,\\ ] ] inspired from luby s ideal soliton distribution @xcite .",
    "the plot also shows the result of real simulations of this code , and confirms that the problem zones of the decoder are those predicted by the functions @xmath137 : the closer they are to the @xmath88-axis , the more probable it is that the decoder fails .",
    "as can be seen , there is a fair chance that the decoder fails when the fraction of decoded input symbols is between 0 and 0.2 , and there is a very good chance that the decoder fails when the fraction of decoded input symbols is close to 0.95 .",
    "we have given an analytic expression for the variance of the ripple size throughout the lt decoding process .",
    "this expression is asymptotically of the order of @xmath0 , and we have expressed it as a function of @xmath0 as a first step toward finite - length analysis of the lt decoding . the next step is to work around the assumption that @xmath8 is a `` constant fraction '' of @xmath0 . then we would obtain a guarantee for successful decoding as a function of the lt - code parameters and overhead for practical values of @xmath0 .",
    "this would then allow us to solve the corresponding design problem , namely to choose degree distributions that would make the function @xmath138 stay positive for as large a value of @xmath10 as possible , for a fixed code length @xmath0 ."
  ],
  "abstract_text": [
    "<S> we analyze the second moment of the ripple size during the lt decoding process and prove that the standard deviation of the ripple size for an lt - code with length @xmath0 is of the order of @xmath1 together with a result by karp et . </S>",
    "<S> al stating that the expectation of the ripple size is of the order of @xmath0 @xcite , this gives bounds on the error probability of the lt decoder . </S>",
    "<S> we also give an analytic expression for the variance of the ripple size up to terms of constant order , and refine the expression in @xcite for the expectation of the ripple size up to terms of the order of @xmath2 , thus providing a first step towards an analytic finite - length analysis of lt decoding . </S>"
  ]
}