{
  "article_text": [
    "in many practical problems in the sciences and applied sciences , the features of most interest can not be observed directly , but have to be inferred from other , observable quantities . in the simplest approximation , which works surprisingly well in a wide range of cases and often suffices , there is a _ linear _ relationship between the features of interest and the observed quantities .",
    "if we model the _ object _ ( the traditional shorthand for the features of interest ) by a function @xmath4 , and the derived quantities or _ image _ by another function @xmath5 , we can cast the problem of inferring @xmath4 from @xmath5 as a _ linear inverse problem _ , the task of which is to solve the equation @xmath6 this equation and the task of solving it make sense only when placed in an appropriate framework . in this paper",
    ", we shall assume that @xmath4 and @xmath5 belong to appropriate function spaces , typically banach or hilbert spaces , @xmath7 , @xmath8 , and that @xmath9 is a bounded operator from the space @xmath10 to @xmath11 .",
    "the choice of the spaces must be appropriate for describing real - life situations .    the observations or _ data _ , which we shall model by yet another function , @xmath12 , are typically not exactly equal to the image @xmath13 , but rather to a distortion of @xmath5 .",
    "this distortion is often modeled by an _ additive noise _ or _ error term _ @xmath14 , i.e. @xmath15 moreover , one typically assumes that the `` size '' of the noise can be measured by its @xmath16-norm , @xmath17 if @xmath14 is a function on @xmath18 .",
    "( in a finite - dimensional situation , one uses @xmath19 instead . ) our only `` handle '' on the image @xmath5 is thus via the observed @xmath12 , and we typically have little information on @xmath20 beyond an upper bound on its @xmath16-norm @xmath21 .",
    "( we have here implicitly placed ourselves in the `` deterministic setting '' customary to the inverse problems community . in the stochastic",
    "setting more familiar to statisticians , one assumes instead a bound on the variance of the components of @xmath14 . )",
    "therefore it is customary to take @xmath22 ; even if the `` true images '' @xmath5 ( i.e. the images @xmath23 of the possible objects @xmath4 ) lie in a much smaller space , we can only know them up to some ( hopefully ) small @xmath16-distance .",
    "we shall consider in this paper a whole family of possible choices for @xmath10 , but we shall always assume that these spaces are subspaces of a basic hilbert space @xmath24 ( often an @xmath16-space as well ) , and that @xmath9 is a bounded operator from @xmath24 to @xmath25 .",
    "in many applications , @xmath9 is an integral operator with a kernel representing the response of the imaging device ; in the special case where this linear device is translation - invariant , @xmath9 reduces to a convolution operator .",
    "to find an estimate of @xmath4 from the observed @xmath12 , one can minimize the _ discrepancy _",
    "@xmath26 , @xmath27 functions that minimize @xmath26 are called _ pseudo - solutions _ of the inverse problem .",
    "if the operator @xmath9 has a trivial null - space , i.e. if @xmath28 , there is a unique minimizer , given by @xmath29 , where @xmath30 is the adjoint operator . if @xmath31 it is customary to choose , among the set of pseudo - solutions , the unique element @xmath32 of minimal norm , i.e. @xmath33 .",
    "this function belongs to @xmath34 and is called the _ generalized solution _ of the inverse problem . in this case",
    "the map @xmath35 is called the _ generalized inverse _ of @xmath9 .",
    "even when @xmath36 is not invertible , @xmath37 is well - defined for all @xmath12 such that @xmath38 .",
    "however , the generalized inverse operator may be unbounded ( for so - called _ ill - posed problems _ ) or have a very large norm ( for _ ill - conditioned problems _ ) . in such instances",
    ", it has to be replaced by bounded approximants or approximants with smaller norm , so that numerically stable solutions can be defined and used as meaningful approximations of the true solution corresponding to the exact data .",
    "this is the issue of _",
    "the definition of a pseudo - solution ( or even , if one considers equivalence classes modulo @xmath39 , of a generalized solution ) makes use of the inverse of the operator @xmath36 ; this inverse is well defined on the range @xmath40 of @xmath41 when @xmath36 is a strictly positive operator , i.e. when its spectrum is bounded below away from zero . when the spectrum of @xmath36 is not bounded below by a strictly positive constant , @xmath42",
    "is not closed , and not all elements of @xmath43 lie in @xmath44 .",
    "in this case there is no guarantee that @xmath45 ; even if @xmath46 belongs to @xmath44 , the unboundedness of @xmath47 can cause severe numerical instabilities unless additional measures are taken .",
    "this blowup or these numerical instabilities are `` unphysical '' , in the sense that we know a priori that the true object would not have had a huge norm in @xmath24 , or other characteristics exhibited by the unconstrained `` solutions '' . a standard procedure to avoid these instabilities or to _ regularize _ the inverse problem is to modify the functional to be minimized , so that it incorporates not only the discrepancy , but also the a priori knowledge one may have about the solution .",
    "for instance , if it is known that the object is of limited `` size '' in @xmath24 , i.e. if @xmath48 , then the functional to be minimized can be chosen as @xmath49 where @xmath50 is some positive constant called the _",
    "regularization parameter_. the minimizer is given by @xmath51 where @xmath52 denotes the identity operator .",
    "the constant @xmath50 can then be chosen appropriately , depending on the application .",
    "if @xmath9 is a compact operator , with singular value decomposition given by @xmath53 , where @xmath54 and @xmath55 are the orthonormal bases of eigenvectors of @xmath56 and @xmath57 , respectively , with corresponding eigenvalues @xmath58 , then ( [ tikh ] ) can be rewritten as @xmath59 this formula shows explicitly how this regularization method reduces the importance of the eigenmodes of @xmath57 with small eigenvalues , which otherwise ( if @xmath60 ) lead to instabilities .",
    "if an estimate of the `` noise '' is known , i.e. if we know a priori that @xmath61 with @xmath62 , then one finds from ( [ tikh - b ] ) that @xmath63 where @xmath64 as @xmath65 .",
    "this means that @xmath50 can be chosen appropriately , in an @xmath66-dependent way , so that the error in estimation @xmath67 converges to zero when @xmath66 ( the estimation of the noise level ) shrinks to zero .",
    "this feature of the method , usually called _ stability _ , is one that is required for any regularization method .",
    "it is similar to requiring that a statistical estimator is consistent .",
    "note that the `` regularized estimate '' @xmath68 of ( [ tikh - b ] ) is linear in @xmath12 .",
    "this means that we have effectively defined a linear regularized estimation operator that is especially well adapted to the properties of the operator @xmath9 ; however , it proceeds with a `` one method fits all '' strategy , independent of the data .",
    "this may not always be the best approach .",
    "for instance , if @xmath24 is an @xmath16-space itself , and @xmath9 is an integral operator , the functions @xmath69 and @xmath70 are typically fairly smooth ; if on the other hand the objects @xmath4 are likely to have local singularities or discontinuities , an approximation of type ( [ tikh - b ] ) ( effectively limiting the estimates @xmath68 to expansions in the first @xmath71 , with @xmath72 determined by , say , @xmath73 for @xmath74 ) will of necessity be a smoothened version of @xmath4 , without sharp features .",
    "other classical regularization methods with quadratic constraints may use quadratic sobolev norms , involving a few derivatives , as the `` penalty '' term added to the discrepancy .",
    "this introduces a penalization of the highly oscillating components , which are often the most sensitive to noise .",
    "this method is especially easy to use in the case where @xmath9 is a convolution operator , diagonal in the fourier domain . in this case",
    "the regularization produces a smooth cut - off on the highest fourier components , independently of the data .",
    "this works well for recovering smooth objects which have their relevant structure contained in the lower part of the spectrum and which have spectral content homogeneously distributed across the space or time domain .",
    "however , the fourier domain is clearly not the appropriate representation for expressing smoothness properties of objects that are either spatially inhomogeneous , with varying `` local frequency '' content , and/or present some discontinuities , because the frequency cut - off implies that the resolution with which the fine details of the solution can be stably retrieved is necessarily limited ; it also implies that the achievable resolution is essentially the same at all points ( see e.g. the book @xcite for an extensive discussion of these topics ) .",
    "the problems with the standard regularization methods described above are well known and several approaches have been proposed for dealing with them .",
    "we propose in this paper a regularization method that , like the classical methods just discussed , minimizes a functional obtained by adding a penalization term to the discrepancy ; typically this penalization term will _ not _ be quadratic , but rather a weighted @xmath0-norm of the coefficients of @xmath4 with respect to a particular orthonormal basis in @xmath24 , with @xmath75 . more precisely , given an orthonormal basis @xmath76 of @xmath24 , and given a sequence of strictly positive weights @xmath77 , we define the functional @xmath78 by @xmath79    for the special case @xmath80 and @xmath81 for all @xmath82 ( we shall write this as @xmath83 , where @xmath84 is the sequence with all entries equal to 1 ) , this reduces to the functional ( [ tikh ] ) . if we consider the family of functionals @xmath85 , keeping the weights fixed at @xmath50 , but decreasing @xmath86 from 2 to 1 , we gradually _ increase _ the penalization on `` small '' coefficients ( those with @xmath87 ) while simultaneously _ decreasing _ the penalization on `` large coefficients '' ( for which @xmath88 ) .",
    "as far as the penalization term is concerned , we are thus putting a lesser penalty on functions @xmath4 with large but few components with respect to the basis @xmath76 , and a higher penalty on sums of many small components , when compared to the classical method of ( [ tikh ] ) .",
    "this effect is the more pronounced the smaller @xmath86 is . by taking @xmath89 , and especially for the limit value @xmath90 , the proposed minimization procedure thus promotes sparsity of the expansion of @xmath4 with respect to the @xmath91 .",
    "( we shall not consider @xmath92 here , because then the functional ceases to be convex . )",
    "the bulk of this paper deals with algorithms to obtain minimizers @xmath93 for the functional ( [ funct - gen ] ) , for general operators @xmath9 . in the special case where @xmath9 happens to be diagonal in the @xmath91basis , @xmath94 ,",
    "the analysis is easy and straightforward . introducing the shorthand notation @xmath95 for @xmath96 and @xmath97 for @xmath98",
    ", we have then @xmath99 ~.\\ ] ] the minimization problem thus uncouples into a family of 1-dimensional minimizations , and is easily solved .",
    "of particular interest is the almost trivial case where ( i ) @xmath9 is the identity operator , ( ii ) @xmath100 and ( iii ) @xmath90 , which corresponds to the practical situation where the data @xmath12 are equal to a noisy version of @xmath4 itself , and we want to remove the noise ( as much as possible ) , i.e. we wish to _ denoise _ @xmath12 . in this case",
    "the minimizing @xmath101 is given by @xmath102 where @xmath103 is the ( nonlinear ) thresholding operator from @xmath104 to @xmath104 defined by @xmath105 ( we shall revisit the derivation of ( [ simple ] ) below . for simplicity",
    ", we are assuming that all functions are real - valued .",
    "if the @xmath95 are complex , a derivation similar to that of ( [ simple ] ) then leads to a complex thresholding operator , which is defined as @xmath106 ; see remark [ 2 - 5 ] below . )    in more general cases , especially when @xmath9 is not diagonal with respect to the @xmath91basis , it is not as straightforward to minimize ( [ funct - gen ] ) .",
    "an approach that promotes sparsity with respect to a particular basis makes sense only if we know that the objects @xmath4 that we want to reconstruct do indeed have a sparse expansion with respect to this basis . in the next subsection",
    "we list some situations in which this is the case and to which the algorithm that we propose in this paper could be applied .",
    "this is the application that was the primary motivation for this paper .",
    "wavelets provide orthonormal bases of @xmath107 with localization in space and in scale ; this makes them more suitable than e.g. fourier expansions for an efficient representation of functions that have space - varying smoothness properties .",
    "appendix [ wavbes ] gives a very succinct overview of wavelets and their link with a particular family of smoothness spaces , the besov spaces .",
    "essentially , the besov space @xmath108 is a space of functions on @xmath109 that `` have @xmath110 derivatives in @xmath111 '' ; the index @xmath112 provides some extra fine - tuning .",
    "the precise definition involves the moduli of continuity of the function , defined by finite differencing , instead of derivatives , and combines the behavior of these moduli at different scales .",
    "the besov space @xmath108 is well - defined as a complete metric space even if the indices @xmath113 are @xmath114 , although it is no longer a banach space in this case .",
    "functions that are mostly smooth , but that have a few local `` irregularities '' , nevertheless can still belong to a besov space with high smoothness index .",
    "for instance , the 1-dimensional function @xmath115 can belong to @xmath116 for arbitrarily large @xmath110 , provided @xmath117 .",
    "( note that this same example does not belong to any of the sobolev spaces @xmath118 with @xmath119 , mainly because these can be defined only for @xmath120 . )",
    "wavelets provide unconditional bases for the besov spaces , and one can express whether or not a function @xmath4 on @xmath109 belongs to a besov space by a fairly simple and completely explicit requirement on the absolute values of the wavelet coefficients of @xmath4 .",
    "this expression becomes particularly simple when @xmath121 ; as reviewed in appendix [ wavbes ] , @xmath122 if and only if ( see appendix [ wavbes ] ) @xmath123 depends on @xmath124 and is defined by @xmath125 , and where @xmath126 stands for the scale of the wavelet @xmath127 .",
    "( the @xmath128 in the formula for @xmath129 is due to the choice of normalization of the @xmath127 , @xmath130 . ) for @xmath131 , @xmath132 is an equivalent norm to the standard besov norm on @xmath108 ; we shall restrict ourselves to this case in this paper .",
    "it follows that minimizing the variational functional for an inverse problem with a besov space prior falls exactly within the category of problems studied in this paper : for such an inverse problem , with operator @xmath9 and with the a priori knowledge that the object lies in some @xmath133 , it is natural to define the variational functional to be minimized by @xmath134 which is exactly of the type @xmath135 , as defined in ( [ funct - gen ] ) . for the case",
    "where @xmath9 is the identity operator , it was noted already in @xcite that the wavelet - based algorithm for denoising of data with a besov prior , derived earlier in @xcite , amounts exactly to the minimization of @xmath136 , where @xmath9 is the identity operator and the @xmath91basis is a wavelet basis ; the denoised approximant given in @xcite then coincides exactly with ( [ simple ] , [ stau ] ) .",
    "it should be noted that if @xmath137 , and if we are interested in functions that are mostly smooth , with possible jump discontinuities ( or other `` irregularities '' ) on smooth manifolds of dimension 1 or higher ( i.e. not point irregularities ) , then the besov spaces do not constitute the optimal smoothness space hierarchy . for @xmath138 , for instance , functions @xmath4 that are @xmath139 on the square @xmath140 ^ 2 $ ] , except on a finite set of smooth curves , belong to @xmath141 ^ 2)$ ] , but not to @xmath142 ^ 2)$ ] for @xmath143 . in order to obtain more efficient ( sparser ) expansions of this type of functions ,",
    "other expansions have to be used , using e.g. ridgelets or curvelets ( @xcite , @xcite ) .",
    "one can then again use the approach in this paper , with respect to these more adapted bases .",
    "the framework of this paper applies to enforcing sparsity of the expansion of the solution on any orthonormal basis .",
    "we provide here three examples which are particularly relevant for applications , but this is of course not limitative .",
    "the first example is the case where it is known a priori that the object to be recovered is sparse in the fourier domain , i.e. @xmath4 has only a few nonzero fourier components .",
    "it makes then sense to choose a standard fourier basis for the @xmath91 , and to apply the algorithms explained later in this paper .",
    "( they would have to be adapted to deal with complex functions , but this is easily done ; see remark [ 2 - 5 ] below . ) in the case where @xmath9 is the identity operator , this is a classical problem , sometimes referred to as `` tracking sinusoids drowned in noise '' , for which many other algorithms have been developed .    for other applications ,",
    "objects are naturally sparse in the original ( space or time ) domain",
    ". then our framework can be used again if we expand such objects in a basis formed by the characteristic functions of pixels or voxels .",
    "once the inverse problem is discretized in pixel space , it is regularized by penalizing the @xmath3-norm of the object with @xmath144 .",
    "possible applications include the restoration of astronomical images with scattered stars on a flat background .",
    "objects formed by a few spikes are also typical of some inverse problems arising in spectroscopy or in particle sizing . in medical imaging ,",
    "@xmath3-norm penalization with @xmath86 larger than but close to @xmath145 has been used e.g. for the restoration of tiny blood vessels @xcite .",
    "the third example refers to the case where @xmath9 is compact and the use of svd expansions is a viable computational approach , e.g. for the solution of relatively small - scale problems or for operators that can be diagonalized in an analytic way . as already stressed above , the linear regularization methods as given e.g. by ( [ tikh - b ] )",
    "have the drawback that the penalization or cut - off eliminates the components corresponding to the smallest singular values , independently of the type of data . in some instances",
    ", the most significant coefficients of the object may not correspond to the largest singular values ; it may then happen that the object possesses significant coefficient beyond the cut - off imposed by linear methods . in order to avoid the elimination of such coefficients , it is preferable to use instead a nonlinear regularization analogous to ( [ simple ] , [ stau ] ) , with basis functions @xmath91 replaced by the singular vectors @xmath70 . the theorems in this paper show that the _ thresholded svd expansion _",
    "@xmath146 which is the minimizer of the functional ( [ funct - gen ] ) with @xmath100 and @xmath90 , provides a regularized solution that is better adapted to these situations .      in a hilbert space @xmath24 , a frame @xmath147 is a set of vectors for which there exist constants @xmath148 so that , for all @xmath149 , latexmath:[\\[b^{-1 } \\sum_{n\\in \\n } |\\left < v,\\psi_n\\right>|^2 \\leq \\|v\\|^2 \\leq a^{-1 } \\sum_{n \\in \\n }    @xmath24 , but the frame vectors @xmath151 are typically not linearly independent .",
    "frames were first proposed by duffin and schaeffer in @xcite ; they are now used in a wide range of applications .",
    "for particular choices of the frame vectors , the two frame bounds @xmath152 and @xmath153 are equal ; one has then , for all @xmath154 , @xmath155 in this case , the frame is called _ tight_. an easy example of a frame is given by taking the union of two ( or more ) different orthonormal bases in @xmath24 ; these unions always constitute tight frames , with @xmath156 equal to the number of orthonormal bases used in the union .",
    "frames are typically `` overcomplete '' , i.e. they still span all of @xmath24 even if some frame vectors are removed .",
    "it follows that , given a vector @xmath157 in @xmath24 , one can find many different sequences of coefficients such that @xmath158 among these sequences , some have special properties for which they are preferred .",
    "there is , for instance , a standard procedure to find the unique sequence with minimal @xmath159-norm ; if the frame is tight , then this sequence is given by @xmath160 , as in ( [ frame-1 ] ) .",
    "the problem of finding sequences @xmath161 that satisfy ( [ frame - v ] ) can be considered as an inverse problem .",
    "let us define the operator @xmath9 from @xmath162 to @xmath24 that maps a sequence @xmath163 to the element @xmath164 of @xmath24 by @xmath165 then solving ( [ frame - v ] ) amounts to solving @xmath166 .",
    "note that this operator @xmath9 is associated with , but not identical to what is often called the `` frame operator '' .",
    "one has , for @xmath149 , @xmath167 for @xmath168 , the sequence @xmath169 is given by @xmath170 in this framework , the sequence @xmath171 of minimum @xmath159-norm that satisfies ( [ frame - v ] ) is given simply by @xmath172 .",
    "the standard procedure in frame lore for the construction of @xmath173 can be rewritten as @xmath174 , so that @xmath175 in this case .",
    "this last formula holds because this inverse problem is in fact well - posed : even though @xmath176 , there is a gap in the spectrum of @xmath36 between the eigenvalue 0 and the remainder of the spectrum , which is contained in the interval @xmath177 $ ] ; the operator @xmath56 has its spectrum completely within @xmath177 $ ] . in practice",
    ", one always works with frames for which the ratio @xmath178 is reasonably close to 1 , so that the problem is not only well - posed but also well - conditioned .",
    "it is often of interest , however , to find sequences that are sparser than @xmath173 .",
    "for instance , one may know a priori that @xmath157 is a `` noisy '' version of a linear combination of @xmath151 with a coefficient sequence of small @xmath179-norm . in this case",
    ", it makes sense to determine a sequence @xmath180 that minimizes @xmath181 a problem that falls exactly in the category of problems described in subsection 1.3 . note that although the inverse problem for @xmath9 from @xmath182 to @xmath24 is well - defined , this need not be the case with the restriction @xmath183 from @xmath184 to @xmath24 .",
    "one can indeed find tight frames for which @xmath185 , so that for arbitrarily large @xmath186 and arbitrarily small @xmath66 , one can find @xmath187 , @xmath188 with @xmath189 , yet @xmath190 . in a noisy situation , it therefore may not make sense to search for the sequence with minimal @xmath179norm that is `` closest '' to @xmath157 ; to find an estimate of the @xmath179sequences of which a given @xmath157 is known to be a small perturbation , a better strategy is to compute the minimizer @xmath191 of ( [ frame-3 ] ) .    minimizing the functional ( [ frame-3 ] ) as an approach to obtain sequences that provide sparse approximations @xmath192 to @xmath157 was proposed and applied to various problems by chen , donoho and saunders @xcite ; in the statistical literature , least - squares regression with @xmath179-penalty is known as the `` lasso '' @xcite .",
    "the algorithm in this paper provides thus an alternative to linear and quadratic programming techniques for these problems , which all amount to minimizing ( [ frame-3 ] ) .",
    "given an operator @xmath9 from @xmath24 to itself ( or , more generally , from @xmath24 to @xmath193 ) , and an orthonormal basis @xmath194 , our goal is to find minimizing @xmath101 for the functionals @xmath78 defined in section 1.3 .",
    "the corresponding variational equations are @xmath195 when @xmath196 and @xmath9 is not diagonal in the @xmath91-basis , this gives a coupled system of nonlinear equations for the @xmath197 , which it is not immediately clear how to solve . to bypass this problem",
    ", we shall use a sequence of `` surrogate '' functionals that are each easy to minimize , and for which we expect , by a heuristic argument , that the successive minimizers have our desired @xmath101 as a limit .",
    "these surrogate functionals are introduced in section 2 below . in section 3",
    "we then show that their successive minimizers do indeed converge to @xmath101 ; we first establish weak convergence , but conclude the section by proving that the convergence also holds in norm . in section 4",
    "we show that our proposed iterative method is _ stable _ , in the sense given in subsection 1.2 : if we apply the algorithm to data that are a small perturbation of a `` true image '' @xmath198 , then the algorithm will produce @xmath101 that converge to @xmath199 as the norm of the perturbation tends to zero .      exploiting the sparsity of",
    "the expansion on a given basis of an unknown signal , in order to assist in the estimation or approximation of the signal from noisy data , is not a new idea .",
    "the key role played by sparsity to achieve superresolution in diffraction - limited imaging was already emphasized by donoho @xcite more than a decade ago . since the seminal paper by donoho and johnstone @xcite , the use of thresholding",
    "techniques for sparsifying the wavelet expansions of noisy signals in order to remove the noise ( the so - called `` denoising '' problem ) has been abundantly discussed in the literature , mainly in a statistical framework ( see e.g. the book @xcite ) . of particular importance for the background of this paper is the article by chambolle et al .",
    "@xcite , which provides a variational formulation for denoising , through the use of penalties on a besov - norm of the signal ; this is the perspective adopted in the present paper .",
    "several attempts have been made to generalize the denoising framework to solve inverse problems .",
    "to overcome the coupling problem stated in the preceding subsection , a first approach is to construct wavelet- or `` wavelet - inspired '' bases that are in some sense adapted to the operator to be inverted . the so - called wavelet - vaguelette decomposition ( wvd ) proposed by donoho @xcite , as well as the twin vaguelette - wavelet decomposition method @xcite , and also the deconvolution in mirror wavelet bases @xcite can all be viewed as examples of this strategy . for the inversion of the radon transform , lee and lucier",
    "@xcite formulated a generalization of the wvd decomposition that uses a variational approach to set thresholding levels .",
    "a drawback of these methods is that they are limited to special types of operators @xmath9 ( essentially convolution - type operators under some additional technical assumptions ) .",
    "other papers have explored the application of galerkin - type methods to inverse problems , using an appropriate but fixed wavelet basis @xcite . the underlying intuition is again that if the operator lends itself to a fairly sparse representation in wavelets , e.g. if it is an operator of the type considered in @xcite , and if the object is mostly smooth with some singularities , then the inversion of the truncated operator will not be too onerous , and the approximate representation of the object will do a good job of capturing the singularities . in @xcite ,",
    "the method is made adaptive , so that the finer - scale wavelets are used where lower scales indicate the presence of singularities .",
    "the mathematical framework in this paper has the advantage of not pre - supposing any particular properties for the operator @xmath9 ( other than boundedness ) or the basis @xmath200 ( other than its orthonormality ) .",
    "we prove , in complete generality , that generalizing tikhonov s regularization method from the @xmath159-penalty case to a @xmath179-penalty ( or , more generally , a weighted @xmath0-penalty with @xmath75 ) provides a proper regularization method for ill - posed problems in a hilbert space @xmath201 , with estimates that are independent of the dimension of @xmath201 ( and are thus valid for infinite - dimensional separable @xmath201 ) . to our knowledge , this is the first proof of this fact .",
    "moreover , we derive a landweber - type iterative algorithm that involves a denoising procedure at each iteration step and provides a sequence of approximations converging in norm to the variational minimizer , with estimates of the rate of convergence in particular cases . this algorithm was derived previously in @xcite , using , as in this paper , a construction based on `` surrogate functionals '' . during the final editing of the present paper , our attention",
    "was drawn to the independent work by figueiredo and nowak @xcite , who , working in the different ( finite - dimensional and stochastic ) framework of maximum penalized likelihood estimation for inverting a convolution operator acting on objects that are sparse in the wavelet domain , derive essentially the same iterative algorithm as in @xcite and this paper .",
    "it is the combined presence of @xmath202 ( which couples all the equations ) and the nonlinearity of the equations that makes the system ( [ variational ] ) unpleasant .",
    "for this reason , we borrow a technique of optimization transfer ( see e.g. @xcite and @xcite ) and construct surrogate functionals that effectively remove the term @xmath202 .",
    "we first pick a constant @xmath203 so that @xmath204 , and then we define the functional @xmath205 which depends on an auxiliary element @xmath206 of @xmath24 . because @xmath207 is a strictly positive operator , @xmath208 is strictly convex in @xmath4 for any choice of @xmath206 . if @xmath209 , we are allowed to set @xmath210 ; for simplicity , we will restrict ourselves to this case , without loss of generality since @xmath9 can always be renormalized .",
    "we then add @xmath211 to @xmath135 to form the following `` surrogate functional '' @xmath212 + \\|g\\|^2 + \\|a\\|^2 - \\| k a \\|^2\\end{aligned}\\ ] ] where we have again used the shorthand @xmath213 for @xmath214 , and implicitly assumed that we are dealing with real functions only . since @xmath208 is strictly convex in @xmath4 , @xmath215 is also strictly convex in @xmath4 , and has a unique minimizer for any choice of @xmath206 .",
    "the advantage of minimizing ( [ sur ] ) in place of ( [ variational ] ) is that the variational equations for the @xmath95 decouple . we can then try to approach the minimizer of @xmath135 by an iterative process which goes as follows : starting from an arbitrarily chosen @xmath216 , we determine the minimizer @xmath217 of ( [ sur ] ) for @xmath218 ; each successive iterate @xmath219 is then the minimizer for @xmath4 of the surrogate functional ( [ sur ] ) anchored at the previous iterate , i.e. for @xmath220 .",
    "the iterative algorithm thus goes as follows @xmath221 to gain some insight into this iteration , let us first focus on two special cases .    in the case where @xmath222 ( i.e. the functional @xmath78 reduces to the discrepancy only )",
    ", one needs to minimize @xmath223 this leads to @xmath224 this is nothing else than the so - called landweber iterative method , the convergence of which to the ( generalized ) solution of @xmath225 is well - known ( @xcite ; see also @xcite , @xcite ) .    in the case where @xmath226 and @xmath80 , the @xmath227-th surrogate functional reduces to @xmath228",
    "the minimizer is now @xmath229 ~,\\ ] ] i.e. we obtain a damped or regularized landweber iteration ( see e.g. @xcite ) .",
    "the convergence of the function @xmath219 defined by ( [ damlan ] ) follows immediately from the estimate @xmath230 , showing that we have a contractive mapping , even if @xmath176 .    in these two special cases",
    "we thus find that the @xmath219 converge as @xmath231 .",
    "this permits one to hope that the @xmath219 will converge for general @xmath232 as well ; whenever this is the case the difference @xmath233 between @xmath234 and @xmath235 tends to zero as @xmath231 , suggesting that the minimizer @xmath219 for the first functional could well tend to a minimizer @xmath101 of the second . in section 3",
    "we shall see that all this is more than a pipe - dream ; i.e. we shall prove that the @xmath219 do indeed converge to a minimizer of @xmath78 .",
    "in the remainder of this section , we derive an explicit formula for the computation of the successive @xmath219 .",
    "we first discuss the minimization of the functional ( [ sur ] ) for a generic @xmath236 . as already noticed , the variational equations for the @xmath95 decouple . for @xmath237 ,",
    "the summand in ( [ sur ] ) is differentiable in @xmath95 , and the minimization reduces to solving the variational equation @xmath238_{\\gamma } ) ~;\\ ] ] since for any @xmath239 and any @xmath237 , the real function @xmath240 is a one - to - one map from @xmath241 to itself , we thus find that the minimizer of ( [ sur ] ) satisfies @xmath242_{\\gamma } ) ~,\\ ] ] where @xmath243 is defined by @xmath244    when @xmath90 , the summand of ( [ sur ] ) is differentiable in @xmath95 only if @xmath245 ; except at the point of non - differentiability , the variational equation now reduces to @xmath246_{\\gamma } ) ~.\\ ] ] for @xmath247 , this leads to @xmath248_{\\gamma } - \\ag/2 $ ] ; for consistency we must impose in this case that @xmath249_{\\gamma } > \\ag/2 $ ] . for @xmath250",
    ", we obtain @xmath251_{\\gamma}+\\ag/2 $ ] , valid only when @xmath249_{\\gamma } < -\\ag/2 $ ] .",
    "when @xmath249_{\\gamma}$ ] does not satisfy either of the two conditions .",
    "i.e. when @xmath252_{\\gamma}| \\leq \\ag/2 $ ] , we put @xmath253 .",
    "summarizing , @xmath254_{\\gamma } ) ~,\\ ] ] where the function @xmath255 from @xmath241 to itself is defined by @xmath256 ( note that this is the same nonlinear function as encountered earlier in section 1.3 , in definition ( [ stau ] ) . )",
    "the following proposition summarizes our findings , and proves ( the case @xmath90 is not conclusively proved by the variational equations above ) that we have indeed found the minimizer of @xmath215 :    [ prop-2 - 1 ] suppose the operator @xmath9 maps a hilbert space @xmath24 to another hilbert space @xmath193 , with @xmath257 , and suppose @xmath12 is an element of @xmath193 .",
    "let @xmath194 be an orthonormal basis for @xmath24 , and let @xmath258 be a sequence of strictly positive numbers .",
    "pick arbitrary @xmath259 and @xmath236 .",
    "define the functional @xmath215 on @xmath24 by @xmath260 then @xmath215 has a unique minimizer in @xmath24 .",
    "+ this minimizer is given by @xmath261 , where the operators @xmath262 are defined by @xmath263 with the functions @xmath243 from @xmath104 to itself given by ( [ s - pneq1 ] , [ s - peq1 ] ) .",
    "for all @xmath264 , one has @xmath265    _ proof : _ the cases @xmath237 and @xmath90 should be treated slightly differently .",
    "we discuss here only the case @xmath90 ; the simpler case @xmath237 is left to the reader .      for later reference",
    "it is useful to point out that    [ ss - non - exp ] the operators @xmath262 are non - expansive , i.e. @xmath279 , @xmath280    _ proof : _ as shown by ( [ def - ss ] ) , @xmath281 which means that it suffices to show that , @xmath282 , and all @xmath283 , latexmath:[\\[\\label{s - non - exp }    @xmath243 is the inverse of the function @xmath285 ; since @xmath285 is differentiable with derivative uniformly bounded below by 1 , ( [ s - non - exp ] ) follows immediately in this case .",
    "+ if @xmath90 , then @xmath255 is not differentiable in @xmath286 or @xmath287 , and another argument must be used . for the sake of definiteness ,",
    "let us assume @xmath288 .",
    "we will just check all the possible cases .",
    "if @xmath289 and @xmath290 have the same sign and @xmath291 , then @xmath292 . if @xmath293 and @xmath294 , then @xmath295 . if @xmath294 and @xmath296 , then @xmath297 .",
    "a symmetric argument applies to the case @xmath298 and @xmath299 . finally , if both @xmath300 and @xmath301 are less than @xmath302 , we have @xmath303 .",
    "this establishes ( [ s - non - exp ] ) in all cases .",
    "having found the minimizer of a generic @xmath215 , we can apply this to the iteration ( [ iter ] ) , leading to    [ cor-2 - 2 ] let @xmath24 , @xmath193 , @xmath9 , @xmath12 , @xmath304 and @xmath305 be as in proposition [ prop-2 - 1 ] .",
    "pick @xmath216 in @xmath24 , and define the functions @xmath219 recursively by the algorithm ( [ iter ] ) . then @xmath306    _ proof : _ this follows immediately from proposition [ prop-2 - 1 ] . @xmath307    [ op - d ] in the argument above , we used essentially only two ingredients : the ( strict ) convexity of @xmath308 , and the presence of the negative @xmath309 term in this expression , canceling the @xmath310 in the original functional .",
    "we can use this observation to present a slight generalization , in which the identity operator used to upper bound @xmath311 is replaced by a more general operator @xmath312 that is diagonal in the @xmath91basis , @xmath313 and that still gives a strict upper bound for @xmath314 , i.e. satisfies @xmath315 in this case , the whole construction still carries through , with slight modifications ; the successive @xmath219 are now given by @xmath316_{\\gamma}}{d_{\\gamma } } \\right ) ~~.\\ ] ] introducing the notation @xmath317 for the sequence @xmath318 , we can rewrite this as @xmath319 \\right ) ~.\\ ] ] for the sake of simplicity of notation , we shall restrict ourselves to the case @xmath320 .",
    "[ 2 - 5 ] if we deal with complex rather than real functions , and the @xmath321 , @xmath322 are complex quantities , then the derivation of the minimizer of @xmath323 has to be adapted somewhat . writing @xmath324 , with @xmath325 , @xmath326 , and likewise @xmath327 , we find , instead of ( [ sur ] ) , @xmath328 + \\|g\\|^2+\\|a\\|^2-\\|ka\\|^2~.\\ ] ] minimizing over @xmath329 and @xmath330 leads to @xmath331 and @xmath332 . if we extend the definition of @xmath333 to complex arguments by setting @xmath334 , then this still leads to @xmath335_{\\gamma } \\right)$ ] , as in ( [ solcomp - pneq1 ] , [ solcomp - peq1 ] ) .",
    "the arguments of the different proofs still hold for this complex version , after minor and straightforward modifications .",
    "in this section we discuss the convergence of the sequence @xmath336 defined by ( [ f - n ] ) .",
    "the main result of this section is the following theorem :    [ th-3 - 1 ] let @xmath9 be a bounded linear operator from @xmath24 to @xmath193 , with norm strictly bounded by @xmath145 . take @xmath337 $ ] , and let @xmath262 be the shrinkage operator defined by ( [ def - ss ] ) , where the sequence @xmath258 is uniformly bounded below away from zero , i.e. there exists a constant @xmath338 such that @xmath339 @xmath340 .",
    "then the sequence of iterates @xmath341 with @xmath216 arbitrarily chosen in @xmath24 , converges strongly to a minimizer of the functional @xmath342 where @xmath343 denotes the norm @xmath344^{1/p } ~,~ 1 \\leq p \\leq 2~.\\ ] ] if either @xmath237 or n@xmath345 , then the minimizer @xmath101 of @xmath78 is unique , and every sequence of iterates @xmath219 converges strongly to @xmath101 , regardless of the choice of @xmath216 .    by `` strong convergence '' we mean convergence in the norm of @xmath24 , as opposed to weak convergence",
    "this theorem will be proved in several stages .",
    "to start , we prove weak convergence , and we establish that the weak limit is indeed a minimizer of @xmath78 .",
    "next , we prove that the convergence holds in norm , and not only in the weak topology . to lighten our formulas",
    ", we introduce the shorthand notation @xmath346 with this new notation we have @xmath347 .",
    "to prove weak convergence of the @xmath348 , we apply the following theorem , due to opial @xcite :    [ thm_opial ] let the mapping @xmath349 from @xmath24 to @xmath24 satisfy the following conditions :    1 .",
    "@xmath349 is non - expansive : @xmath350 , @xmath351 , 2 .",
    "@xmath349 is asymptotically regular : @xmath352 , @xmath353{~ }   0 $ ] , 3 .",
    "the set @xmath354 of the fixed points of @xmath349 in @xmath355 is not empty",
    ".    then , @xmath352 , the sequence @xmath356 converges weakly to a fixed point in @xmath354 .",
    "opial s original proof can be simplified ; we provide the simplified proof ( still mainly following opial s approach ) in appendix [ opial ] .",
    "( the theorem is slightly more general than what is stated in theorem [ thm_opial ] in that the mapping @xmath349 need not be defined on all of space ; it suffices that it map a closed convex subset of @xmath24 to itself  see appendix [ opial ] .",
    "@xcite also contains additional refinements , which we shall not need here . )",
    "one of the lemmas stated and proved in the appendix will be invoked in its own right , further below in this section ; for the reader s convenience , we state it here in full as well :    [ lem-3 - 2 ] suppose the mapping @xmath357 from @xmath24 to @xmath24 satisfies the conditions ( i ) and ( ii ) in theorem [ thm_opial ] .",
    "then , if a subsequence of @xmath358 converges weakly in @xmath24 , then its limit is a fixed point of @xmath357 .    in order to apply opial s theorem to our nonlinear operator @xmath359",
    ", we need to verify that it satisfies the three conditions in theorem [ thm_opial ] .",
    "we do this in the following series of lemmas .",
    "we first have    [ nonexp ] the mapping @xmath359 is non - expansive , i. e. @xmath350 @xmath360    _ proof : _ it follows from lemma [ ss - non - exp ] that the shrinkage operator @xmath361 is non - expansive .",
    "hence we have @xmath362 because we assumed @xmath363 .",
    "this verifies that @xmath359 satisfies the first condition ( i ) in theorem [ thm_opial ] . to verify the second condition",
    ", we first prove some auxiliary lemmas .",
    "[ cost2 ] both @xmath364 and @xmath365 are non - increasing sequences .    _",
    "proof : _ for the sake of convenience , we introduce the operator @xmath366 , so that @xmath367 .",
    "because @xmath368 is the minimizer of the functional @xmath369 and therefore @xmath370 we obtain @xmath371 on the other hand @xmath372    [ unifbddness ] suppose the sequence @xmath258 is uniformly bounded below by a strictly positive number .",
    "then the @xmath373 are bounded uniformly in @xmath227 .    _",
    "proof : _ since @xmath340 , uniformly in @xmath374 , for some @xmath338 , we have @xmath375 by lemma [ cost2 ] .",
    "hence the @xmath219 are bounded uniformly in the @xmath376-norm . since @xmath377\\ \\vvert f \\vvert_{\\mathbf{w},p}^p \\leq c^{-2/p } \\vvert f\\vvert_{\\mathbf{w},p}^{2-p}\\ \\vvert f \\vvert_{\\mathbf{w},p}^p = c^{-2/p } \\vvert f \\vvert_{\\mathbf{w},p}^2\\ , \\ ] ] we also have a uniform bound on the @xmath373",
    ".    [ series ] the series @xmath378 is convergent .    _",
    "proof : _ this is a consequence of the strict positive - definiteness of @xmath379 , which holds because @xmath380 .",
    "we have , for any @xmath381 , @xmath382 where @xmath152 is a strictly positive lower bound for the spectrum of @xmath383 . by lemma [ cost2 ] , @xmath384 = \\phi_{\\mathbf{w},p}(f^{0})-\\phi_{\\mathbf{w},p}(f^{n+1 } ) \\leq \\phi_{\\mathbf{w},p}(f^{0})~,\\ ] ] where we have used that @xmath385 is a non - increasing sequence .",
    "+ it follows that @xmath386 is bounded uniformly in @xmath72 , so that the infinite series converges .    as an immediate consequence",
    ", we have that    [ asyreg ] the mapping @xmath387 is asymptotically regular , i.e. @xmath388    we can now establish the following    the sequence @xmath389 , @xmath390 converges weakly , and its limit is a fixed point for @xmath359 .    _",
    "proof : _ since , by lemma [ unifbddness ] , the @xmath391 are uniformly bounded in @xmath227 , it follows from the banach - alaoglu theorem that they have a weak accumulation point . by lemma [ lem-3 - 2 ] , this weak accumulation point is a fixed point for @xmath359 .",
    "it follows that the set of fixed points of @xmath359 is not empty .",
    "since @xmath359 is also non - expansive ( by lemma [ nonexp ] ) and asymptotically regular ( by lemma [ asyreg ] ) , we can apply opial s theorem ( theorem [ th-3 - 1 ] above ) , and the conclusion of the proposition follows .    by the following proposition",
    "this fixed point is also a minimizer for the functional @xmath78 .",
    "[ fix - min ] a fixed point for @xmath387 is a minimizer for the functional @xmath78 .    _",
    "proof : _ if @xmath392 , then by proposition [ prop-2 - 1 ] , we know that @xmath101 is a minimizer for the surrogate functional @xmath393 , and that , @xmath394 , @xmath395 observing that @xmath396 , and @xmath397 we conclude that , @xmath394 , @xmath398 , which shows that @xmath101 is a minimizer for @xmath399 .",
    "the following proposition summarizes this subsection .",
    "[ prop - wk - conv ] ( weak convergence ) make the same assumptions as in the statement of theorem [ th-3 - 1 ] .",
    "then , for any choice of the initial @xmath216 , the sequence @xmath400 converges weakly to a minimizer for @xmath78 .",
    "if either n@xmath401 or @xmath237 , then @xmath78 has a unique minimizer @xmath101 , and all the sequences @xmath336 converge weakly to @xmath101 , regardless of the choice of @xmath216 .",
    "_ proof : _ the only thing that hasnt been proved yet above is the uniqueness of the minimizer if @xmath402 or @xmath237 .",
    "this uniqueness follows from the observation that @xmath403 is strictly convex in @xmath4 if @xmath237 , and that @xmath404 is strictly convex in @xmath4 if @xmath402 . in both these cases @xmath78 is thus strictly convex , so that it has a unique minimizer .",
    "if one has the additional prior information that the object lies in some closed convex subset @xmath405 of the hilbert space @xmath24 , then the iterative procedure can be adapted to take this into account , by replacing the shrinkage operator @xmath406 by @xmath407 , where @xmath408 is the projector on @xmath405 . for example , if @xmath409 , then @xmath405 could be the cone of functions that are positive almost everywhere . the results in this subsection can be extended to this case ; a more general version of theorem [ thm_opial ] can be applied , in which @xmath349 need not be defined on all of @xmath24 , but only on @xmath410 ; see appendix [ opial ] .",
    "we would however need to either use other tools to ensure , or assume outright that the set of fixed points of @xmath411 is not empty ( see also @xcite ) .",
    "if @xmath78 is strictly convex , then one can prove the weak convergence more directly , as follows . by the boundedness of the @xmath219 ( lemma [ unifbddness ] )",
    ", we must have a weakly convergent subsequence @xmath412 .",
    "by lemma [ asyreg ] , the sequence @xmath413 must then also be weakly convergent , with the same weak limit @xmath414 .",
    "it then follows from the equation @xmath415_\\g \\right)~,\\ ] ] together with @xmath416 , that @xmath414 must be the fixed point @xmath101 of t. since this holds for any weak accumulation point of @xmath336 , the weak convergence of @xmath336 to @xmath101 follows .",
    "the proof of lemma [ unifbddness ] is the only place , so far , where we have explicitly used @xmath417 .",
    "if it were possible to establish a uniform bound on the @xmath373 by some other means ( e.g. by showing that the @xmath418 are bounded uniformly in @xmath227 ) , then we could dispense with the restriction @xmath417 , and proposition [ prop - wk - conv ] would hold for all @xmath259 .      in this subsection we shall prove that the convergence of the successive iterates @xmath419 holds not only in the weak topology , but also in the hilbert space norm .",
    "again , we break up the proof into several lemmas . for the sake of convenience",
    ", we introduce the following notations @xmath420 here and below , we use the notation _ w_@xmath421@xmath422 as a shorthand for _ weak limit_.    [ ku ] @xmath423 for @xmath424  .    _",
    "proof : _ since @xmath425 and @xmath426 by lemma [ asyreg ] , we have @xmath427 and hence also @xmath428 since @xmath429 is non - expansive ( lemma [ ss - non - exp ] ) , we have @xmath430 therefore the `` max '' in ( [ cvtozero ] ) can be dropped , and it follows that @xmath431 because @xmath432 where @xmath203 is a finite constant ( by lemma [ unifbddness ] ) , we obtain @xmath433 which tends to zero by ( [ cv2 ] ) .",
    "the inequality @xmath434 then implies that @xmath435 .",
    "[ ifkcomp ] note that if @xmath9 is a compact operator , the weak convergence to @xmath436 of the @xmath437 automatically implies that @xmath438 tends to @xmath436 as @xmath227 tends to @xmath439 , so that we do nt need lemma [ ku ] in this case .",
    "if @xmath9 had a bounded inverse , we could conclude from @xmath440 that @xmath441 .",
    "if this is not the case , however , and thus for all ill - posed linear inverse problems , we need some extra work to show the norm convergence of @xmath219 to @xmath101 .    for @xmath5 given by ( [ redef2 ] ) , @xmath442 for @xmath443 .    _",
    "proof : _ we have @xmath444 where we used the non - expansivity of @xmath429 ( lemma [ ss - non - exp ] ) .",
    "the result follows since both terms in this last bound tend to zero for @xmath443 because of lemma [ ku ] and ( [ cvaux ] ) .",
    "[ lm-3 - 16 ] if for some @xmath236 , and some sequence @xmath445 , w@xmath446 and @xmath447 then @xmath448 for @xmath424 .    _",
    "proof : _ the argument of the proof is slightly different for the cases @xmath90 and @xmath237 , and we treat the two cases separately .",
    "+ we start with @xmath237 .",
    "since the sequence @xmath449 is weakly convergent , it has to be bounded : there is a constant @xmath153 such that @xmath450 , @xmath451 , and hence also @xmath452 , @xmath453 .",
    "next , we define the set @xmath454 ; since @xmath236 , this is a finite set .",
    "we then have @xmath455 , that @xmath456 and @xmath457 are bounded above by @xmath458 . recalling the definition of @xmath459 , and observing that , because @xmath417 , @xmath460 $ ] if @xmath461 , we have @xmath462 \\right)^{-1 } |v^n_{\\g}| \\\\ & \\leq & \\left ( 1 + c \\ , p(p-1 ) / [ 2(2b)^{2-p } ] \\right)^{-1 } |v^n_{\\g}|~;\\end{aligned}\\ ] ] in the second inequality , we have used that @xmath463 , a consequence of the non - expansivity of @xmath464 ( see lemma [ ss - non - exp ] ) to upper bound the derivative @xmath465 on the interval @xmath466 $ ] by the inverse of the lower bound for @xmath467 on the same interval ; in the last inequality we used the uniform lower bound on the @xmath468 , i.e. @xmath469 . rewriting @xmath470 \\right)^{-1}= c'<1 $ ] , we have thus , @xmath471 , @xmath472 on the other hand , since @xmath473 is a finite set , and the @xmath474 tend to zero weakly as @xmath227 tends to @xmath439 , we also have @xmath475 this proves the proposition for the case @xmath237 .",
    "+ for @xmath90 , we define a finite set @xmath476 so that latexmath:[$\\sum _ { \\g \\in \\gamma \\setminus \\gamma_{_{\\!0 } } }    lower bound on the @xmath468 .",
    "because this is a finite set , the weak convergence of the @xmath474 implies that @xmath478{~ }   0 $ ] , so that we can concentrate on @xmath479 only .",
    "+ for each @xmath227 , we split @xmath480 into two subsets : @xmath481 . if @xmath482 , then @xmath483 ( since @xmath484 ) , so that @xmath485 .",
    "it follows that @xmath486 it remains to prove only that the remaining sum , latexmath:[$\\sum_{\\g \\in \\widetilde{\\gamma}_{_{\\!1,n } } }    @xmath424 .",
    "+ if @xmath275 and @xmath488 , then @xmath489 , so that @xmath490 and @xmath491 have the same sign ; it then follows that @xmath492 this implies that @xmath493 since @xmath494{~ } 0 $ ] , we know on the other hand that @xmath495 when @xmath227 exceeds some threshold , @xmath72 , which implies that @xmath496 is empty when @xmath497 .",
    "consequently @xmath498 for @xmath497 .",
    "this completes the proof for the case @xmath90 .",
    "combining the lemmas in this subsection with the results of the previous subsection gives a complete proof of theorem [ th-3 - 1 ] as stated at the start of this section .",
    "in the preceding section , we devised an iterative algorithm that converges towards a minimizer of the functional @xmath499 for simplicity , let us assume , until further notice , that either @xmath237 or @xmath500 , so that there is a unique minimizer .    in this section",
    ", we shall discuss to what extent this minimizer is acceptable as a _",
    "regularized solution _ of the ( possibly ill - posed ) inverse problem @xmath225 .",
    "of particular interest to us is the _ stability _ of the estimate .",
    "for instance , if @xmath500 , we would like to know to what extent the proposed solution , in this case the minimizer of @xmath78 , deviates from the ideal solution @xmath199 if the data are a ( small ) perturbation of the image @xmath501 of @xmath199 .",
    "( if @xmath176 , then there exist other @xmath4 that have the same image as @xmath199 , and the algorithm might choose one of those  see below . ) in this discussion both the `` size '' of the perturbation and the weight of the penalty term in the variational functional , given by the coefficients @xmath502 , play a role .",
    "we argued earlier that we need @xmath503 in order to provide a meaningful estimate if e.g. @xmath9 is a compact operator ; on the other hand , if @xmath504 , then the presence of the penalty term will cause the minimizer of @xmath78 to be different from @xmath199 .",
    "we therefore need to strike a balance between the respective weights of the perturbation @xmath505 and the penalty term .",
    "let us first define a framework in which we can make this statement more precise .    because we shall deal in this section with data functions @xmath12 that are not fixed , we adjust our notation for the variational functional to make the dependence on @xmath12 explicit where appropriate : with this more elaborate notation , the right hand side of , for instance , ( [ phimu2 ] ) is now @xmath506 .",
    "( because we work with one fixed operator @xmath9 , the dependence of the functional on @xmath9 remains `` silent '' . ) in order to make it possible to vary the weight of the penalty term in the functional , we introduce an extra parameter @xmath50 .",
    "we shall thus consider the functional @xmath507 its minimizer will likewise depend on all these parameters . in its full glory , we denote it by @xmath508 ; when confusion is impossible we abbreviate this notation . in particular , since @xmath304 and @xmath86 typically will not vary in the limit procedure that defines stability , we may omit them in the heat of the discussion .",
    "notice that the dependence on @xmath304 and @xmath50 arises only through the product @xmath509 .        if the @xmath468 tend to @xmath439 , or more precisely , if @xmath516 then the embedding of @xmath517 in @xmath24 is compact .",
    "( this is because the identity operator from @xmath518 to @xmath24 is then the norm ",
    "limit in @xmath519 , as @xmath520 , of the finite rank operators @xmath521 defined by @xmath522 , where @xmath523 . ) in this case , general compactness arguments can be used to show that ( [ desired - res ] ) can be achieved .",
    "( see also further below . )",
    "we are , however , also interested in the general case , where the @xmath468 need not grow unboundedly .",
    "the following theorem proves that we can then nevertheless choose the dependence @xmath524 so that ( [ desired - res ] ) holds :    [ regthm ] assume that @xmath9 is a bounded operator from @xmath24 to @xmath193 with @xmath209 , that @xmath1 and that the entries in the sequence @xmath258 are bounded below uniformly by a strictly positive number @xmath525 .",
    "assume that either @xmath237 or @xmath526 .",
    "for any @xmath527 and any @xmath528 , define @xmath529 to be the minimizer of @xmath530 .",
    "if @xmath513 satisfies the requirements @xmath531 then we have , for any @xmath532 , @xmath533 = 0 ~,\\ ] ] where @xmath534 is the unique element of minimum @xmath535norm in @xmath536 .",
    "note that under the conditions of theorem [ regthm ] , @xmath534 must indeed be unique : if @xmath237 , then the @xmath535norm is strictly convex , so that there is a unique minimizer for this norm in the hyperspace @xmath537 ; if @xmath90 , our assumptions require @xmath500 .",
    "note also that if @xmath500 ( whether or not @xmath90 ) , then necessarily @xmath538 .    to prove theorem [ regthm",
    "] , we will need the following two lemmas :    [ lm-4 - 1 ] the functions @xmath243 from @xmath104 to itself , defined by ( [ s - pneq1 ] , [ s - peq1 ] ) for @xmath237 , @xmath90 , respectively , satisfy @xmath539    _ proof : _ for @xmath90 , the definition ( [ s - peq1 ] ) implies immediately that @xmath540 , so that the proposition holds for @xmath541 . for @xmath542 , @xmath543 .    for @xmath237 , @xmath544 , where @xmath545 satisfies @xmath546 , and @xmath547 .",
    "it follows that @xmath548 , and @xmath549 @xmath550 @xmath551 .",
    "@xmath552    [ lm - conv ] if the sequence of vectors @xmath553 converges weakly in @xmath24 to @xmath157 , and @xmath554 @xmath555 , then @xmath553 converges to @xmath157 in the @xmath24norm , i.e. @xmath556 .    _ proof : _ it is a standard result that if _ w_@xmath421@xmath557 , and @xmath558 , then @xmath559 .",
    "we thus need to prove only that @xmath558 .",
    "since the @xmath70 converge weakly , they are uniformly bounded .",
    "it follows that the @xmath560 are bounded uniformly in @xmath561 and @xmath374 by some finite number @xmath203 .",
    "define @xmath562 .",
    "since , for @xmath563 , @xmath564 , it follows that @xmath565 because the @xmath468 are uniformly bounded below by @xmath338 , we obtain @xmath566 so that it suffices to prove that this last expression tends to @xmath436 as @xmath561 tends to @xmath439 .",
    "define now @xmath567 . clearly @xmath568 ; since @xmath569 , it follows by the dominated convergence theorem that @xmath570 . since @xmath571{~ } 0 ~,\\ ] ] the lemma follows .",
    "we are now ready to proceed to the    _ proof of _ theorem 4.1 : let s assume that @xmath524 satisfies the requirements ( [ mu - req ] ) .",
    "we first establish weak convergence .",
    "for this it is sufficient to prove that if @xmath572 is a sequence in @xmath193 such that @xmath573 , where @xmath574 is a sequence of strictly positive numbers that converges to zero as @xmath424 , then _",
    "w_@xmath421@xmath575 , where @xmath576 is the unique minimizer of @xmath577 ( as predicted , we have dropped here the explicit indication of the dependence of @xmath578 on @xmath304 and @xmath86 ; these parameters will keep fixed values throughout this proof .",
    "we will take the liberty to drop them in our notation for @xmath579 as well , when this is convenient . ) for the sake of convenience , we abbreviate @xmath580 as @xmath581 .",
    "+ then the @xmath582 are uniformly bounded in @xmath24 by the following argument : @xmath583 \\leq   \\frac{1}{c } \\left ( \\frac{\\epsilon_n^2}{\\mu_n}+\\vvert f^\\dagger \\vvert_{\\mathbf{w},p}^p \\right ) ~ , \\label{fmuubd}\\end{aligned}\\ ] ] where we have used , respectively , the bound ( [ bdl2ban ] ) , the fact that @xmath584 minimizes @xmath585 , @xmath586 and the bound @xmath587 . by the assumption ( [ mu - req ] )",
    ", @xmath588 tends to zero for @xmath589 and hence can be bounded by a constant independent of @xmath227 .",
    "it follows that the sequence @xmath590 has at least one weak accumulation point , i.e. there exists a subsequence      even when @xmath90 and @xmath631 , it may still be the case that , for any @xmath532 , there is a unique element @xmath534 of minimal norm in @xmath632 .",
    "( for instance , if @xmath9 is diagonal in the @xmath633basis , with some zero eigenvalues , then the unique minimizer @xmath534 in @xmath626 is given by setting to zero all the components of @xmath199 corresponding to @xmath374 for which @xmath634 . ) in this case the proof still applies , and we still have norm  convergence of the @xmath635 to @xmath534 if @xmath524 satisfies ( [ mu - req ] ) and @xmath636 .",
    "the regularization theorem of the previous subsection gives no information on the rate at which the regularized solution approaches the exact solution when the noise ( as measured by @xmath66 ) decreases to zero .",
    "such rates are not available in the general case , but can be derived under additional assumptions , discussed below . for the remainder of this section",
    "we shall assume that the operator @xmath9 is invertible on its range , i.e. that @xmath500 .",
    "suppose that the unknown exact solution of the problem , @xmath199 , satisfies the constraint @xmath637 , where @xmath638 is given ; in other words , we know a priori that the unknown solution lies in the ball around the origin with radius @xmath639 in the banach space @xmath640 ; we shall denote this ball by @xmath641 . if we also know",
    "that @xmath12 lies within a distance @xmath66 of @xmath501 in @xmath193 , then we can localize the exact solution within the set @xmath642 the diameter of this set is a measure of the uncertainty of the solution for a given prior and a given noise level @xmath66 .",
    "the maximum diameter of @xmath354 , namely diam(@xmath354)=@xmath643 is bounded by @xmath644 , where @xmath645 , defined by @xmath646 is called the _ modulus of continuity _ of @xmath647 under the prior .",
    "( we have once more dropped the explicit reference in our notation to the dependence on @xmath304 and @xmath86 . )",
    "if ( [ compact - emb ] ) is satisfied , then the ball @xmath641 is compact in @xmath24 , and it follows from a general topological lemma ( see e.g. @xcite ) that @xmath648 when @xmath649 ; the uncertainty on the solution thus vanishes in this limit .",
    "however , this topological argument , which holds for any regularization method enforcing the prior @xmath637 , does not tell us anything about the rate of convergence of any specific method .",
    "in what follows , we shall systematically assume that ( [ compact - emb ] ) is satisfied .",
    "we shall also make additional assumptions that will make it possible to derive more precise convergence results .",
    "our specific regularization method consists in taking the minimizer @xmath650 of the functional @xmath651 given by ( [ phimu ] ) as an estimate of the exact solution @xmath199 , where we leave any links between @xmath50 and @xmath66 unspecified for the moment .",
    "( because of the compactness argument above , we could conceivably dispense with ( [ mu - req ] ) ; see below . )",
    "an upper bound on the reconstruction error @xmath652 , valid for all @xmath12 such that @xmath653 , as well as uniformly in @xmath199 , is given by the following _ modulus of convergence _ : @xmath654 the decay of this modulus of convergence as @xmath655 is governed by the decay of the modulus of continuity ( [ mc ] ) , as shown by the following proposition .",
    "[ bestcv ] the modulus of convergence ( [ modcv ] ) satisfies @xmath656 where @xmath657 and @xmath645 is defined by ( [ mc ] )  .",
    "_ proof : _ we first note that @xmath658 because @xmath650 is the minimizer of @xmath659 and @xmath660 .",
    "it follows that @xmath661 or , equivalently , @xmath662 with @xmath663 and @xmath664 given by ( [ primes ] ) .",
    "the modulus of convergence ( [ modcv ] ) can then be bounded as follows , using the triangle inequality . indeed , for any @xmath665 and @xmath666 , we have @xmath667 and @xmath668 and we immediately obtain from the definition of ( [ mc ] ) the upper bound in ( [ stability ] ) . to derive the lower bound ,",
    "observe that for the particular choice @xmath669 , the minimizer @xmath650 of the functional ( [ phimu ] ) is @xmath670 .",
    "the desired lower bound then follows immediately upon inspection of the two definitions ( [ mc ] ) and ( [ modcv ] ) .",
    "let us briefly discuss the meaning of the previous proposition .",
    "the modulus of continuity @xmath645 yields the best possible convergence rate for any regularization method that enforces the error bound and the prior constraint defined by ( [ mc ] ) .",
    "proposition [ bestcv ] provides a relation between the modulus of continuity and the convergence rate @xmath671 of the specific regularization method considered in this paper , which is defined by the minimization of the functional ( [ phimu ] ) .",
    "optimizing the upper bound in ( [ stability ] ) suggests the choice @xmath672 , yielding @xmath673 and @xmath674 . with these choices ,",
    "we ensure that @xmath675 when @xmath676 , i.e. that the problem is _ regularized _ , provided we can show that the modulus of continuity tends to zero with @xmath66 .",
    "moreover , once we establish its rate of decay ( see below ) , we know that our regularization method is ( nearly ) optimal in the sense that the modulus of convergence ( [ modcv ] ) will decay _ at the same rate as the optimal rate _ given by the modulus of stability @xmath645  ( we call it _ nearly _ optimal because , although the rate of decay is optimal , the constant multiplier probably is not . )",
    "note that because of the assumption of compactness of the ball @xmath641 ( which amounts to assuming that ( [ compact - emb ] ) is satisfied ) , we achieve regularization even in some cases where @xmath677 does not tend to zero for @xmath655 , which is a case not covered by theorem [ regthm ] .    in order to derive upper or lower bounds on @xmath645 , we must know more information about the operator @xmath9 .",
    "the following proposition illustrates how such information can be used .",
    "[ convrate - gen ] suppose that there exist sequences @xmath678 and @xmath679 satisfying @xmath680 and such that , for all @xmath5 in @xmath24 , @xmath681 then the following upper and lower bounds hold for @xmath645 : @xmath682~ , \\\\",
    "\\label{upperbound } m(\\epsilon,\\rho ) & \\leq & \\min_{\\gamma = \\gamma_{_{\\!1 } } \\cup \\gamma_{_{\\!2 } } } \\sqrt { \\frac{\\epsilon^2}{\\min_{\\g \\in \\gamma_{_{\\!1}}}b_\\g } + \\frac{\\rho^2}{\\min_{\\g \\in \\gamma_{_{\\!2}}}\\ag^{2/p } } } ~.\\end{aligned}\\ ] ]    _ proof : _ to prove the lower bound , we need only exhibit one particular @xmath5 such that @xmath683 and @xmath684 , for which @xmath685 is given by the right hand side of ( [ lowerbound ] ) .",
    "for this we need only identify the index @xmath686 such that , @xmath687 , @xmath688 and choose @xmath689 .",
    "then @xmath690 and @xmath691 ; on the other hand , @xmath692 equals the right hand side of ( [ lowerbound ] ) .    on the other hand , for any partition of @xmath693 into two subsets , @xmath694 , and any @xmath695",
    ", we have @xmath696 \\sum_{\\g \\in \\gamma_{_{\\!1 } } } b_\\g |h_\\g|^2 + \\max_{\\g ' \\in \\gamma_{_{\\!2 } } } [ w_{\\g'}^{-2/p}][\\max_{\\g '' \\in \\gamma_{_{\\!2 } } } w_{\\g '' }    & \\le & \\max_{\\g ' \\in \\gamma_{_{\\!1 } } } [ b_{\\g'}^{-1 } ] \\epsilon^2 + \\max_{\\g ' \\in \\gamma_{_{\\!2 } } } [ w_{\\g'}^{-2/p } ] \\rho^2 ~.\\end{aligned}\\ ] ] since this is true for any partition @xmath697 , we still have an upper bound , uniformly valid for all @xmath698 , if we take the minimum over all such partitions . the upper bound on @xmath645 then follows upon taking the square root .",
    "to illustrate how proposition [ convrate - gen ] could be used , let us apply it to one particular example , in which we choose the @xmath699basis with respect to which the @xmath700norm is defined to be a wavelet basis @xmath701 . as already pointed out in subsection 1.4.1 the besov spaces @xmath702",
    "can then be identified with the banach spaces @xmath518 for the particular choice @xmath703 is assumed to be non - negative . for @xmath704 , the banach norm @xmath403",
    "then coincides with the besov norm latexmath:[$\\vvert f \\vvert_{s , p } = \\left [ \\sum_{\\lambda \\in \\lambda } w_{\\lambda }    an inverse problem for the operator @xmath9 with such a besov prior .",
    "if we assume that the operator @xmath9 has particular smoothing properties , then we can use these to derive bounds on the corresponding modulus of continuity , and thus also on the rate of convergence for our regularization algorithm .",
    "in particular , let us assume that the operator @xmath9 is a smoothing operator of order @xmath706 , a property which can be formulated as an equivalence between the norm @xmath707 and the norm of @xmath5 in a sobolev space of negative order @xmath708 , i.e. in a besov space @xmath709 ( see e.g. @xcite , @xcite , @xcite , @xcite ) .",
    "in other words , we assume that for some @xmath710 , there exist constants @xmath711 and @xmath712 , such that , for all @xmath713 , @xmath714 the decay rate of the modulus of continuity is then characterized as follows",
    ".    if the operator @xmath9 satisfies the smoothness condition ( [ ell ] ) , then the modulus of continuity @xmath645 , defined by @xmath715 satisfies @xmath716 where @xmath717 , and @xmath525 and @xmath203 are constants depending on @xmath129 and @xmath706 only .",
    "_ proof : _ by ( [ ell ] ) , the operator @xmath9 satisfies ( [ extrak ] ) with @xmath718 and @xmath719 .",
    "it then follows from ( [ lowerbound ] ) that @xmath720 ~;\\ ] ] if @xmath721 could take on all positive real values , then one easily computes that this max - min would be given for @xmath722/(\\alpha + \\sigma)$ ] , and would be equal to @xmath723 . because @xmath724 is constrained to take only the values in @xmath725 , the max - min is guaranteed only to be within a constant of this bound ( corresponding to an integer neighbor of the optimal @xmath289 ) , which leads to the lower bound in ( [ m ] ) .    for the upper bound ( [ upperbound ] ) , we must partition the index set . splitting @xmath726 into @xmath727 and @xmath728",
    ", we find that @xmath729 the minimizing partition for @xmath726 thus corresponds with the minimizing @xmath730 for the right hand side of this expression .",
    "this value for @xmath730 is an integer neighbor of @xmath731/(\\alpha + \\sigma)$ ] , which leads to the upper bound in ( [ m ] ) .",
    "the stability estimates we have derived are standard in regularization theory for the special case @xmath80 ; they were first extended to the case @xmath732 in @xcite .",
    "they show the interplay between the smoothing order of the operator characterized by @xmath706 and the assumed smoothness of the solutions characterized by @xmath733 ( for besov spaces , we recall that this amounts to solutions having @xmath110 derivatives in @xmath734 ) . for @xmath735 close to one , the problem is mildly ill - posed , whereas the stability degrades for large @xmath706 .",
    "note that if the bound ( [ ell ] ) were replaced by another one , in which the decay of the @xmath736 and @xmath737 was given by an exponential decay in @xmath738 ( instead of the much slower decaying negative power @xmath739 ) of ( [ ell ] ) , then the modulus of continuity would tend to zero only as an inverse power of @xmath740 .",
    "this is the so - called _ logarithmic continuity _ which has been extensively discussed in the case @xmath80 , and which extends , as shown by an easy application of proposition [ convrate - gen ] , to @xmath741 .",
    "we provide a simple illustration of the behavior of the algorithms based on minimizing @xmath742 and @xmath743 for a two - dimensional deconvolution problem , considering a class of objects consisting of small bright sources on a dark background .",
    "the image is discretized on a @xmath744 array , denoted by @xmath4 . the convolution operator @xmath9 is implemented by multiplying the discrete fourier transform ( dft ) of @xmath4 by a low - pass , radially symmetrical filter and then taking the inverse dft to obtain the data @xmath745 ( data were zero padded on a larger @xmath746 array when taking dfts ) .",
    "the filter was equal ( in the fourier domain ) to the convolution with itself of the characteristic function of a disk with radius equal to @xmath747 times the maximum frequency determined by the image grid sampling ; this filter provides a discrete model of a diffraction - limited imaging system with incoherent light .",
    "pseudo - random poisson noise was added to the data array @xmath12 , for a total number of @xmath748 photons , corresponding to about @xmath749 photons for the data pixel with the maximum intensity .",
    "the top of figure 1 shows the object @xmath4 ( four ellipses of axis @xmath750 or @xmath751 pixels , slightly smoothed to avoid blocking effects ) and the data @xmath745 .",
    "the figure also shows intensity distributions along two lines in the object and data arrays ; along the horizontal line we see how two close sources in @xmath4 give rise to a joint blur in @xmath12 .",
    "the bottom of figure 1 shows the reconstructions obtained after 2000 steps of the iterative thresholded landweber algorithm , which accurately approximate the minimizers of @xmath752 and @xmath753 .",
    "the parameters @xmath754 and @xmath755 are selected separately for each case , in order to achieve a good balance between sharpness and ringing and noise .    as expected for an example of this type ,",
    "the minimizer of @xmath752 does a better job at resolving the two close sources on the horizontal line ; it also gives a better concentration of the source lying along the vertical line .",
    "because the object @xmath4 is positive , we can apply remark 3.12 and use @xmath756 instead of @xmath757 , where @xmath758 is the projection onto the convex cone of @xmath744 arrays that take only non - negative values .",
    "the results are shown in figure 2 ; on the top is the @xmath759-th iterate for the case with @xmath758 , with the case @xmath90 ( left ) and @xmath80 ( right ) . in each case",
    "we used the same values of @xmath754 and @xmath755 as for the reconstructions without positivity constraint , which are shown for comparison on the bottom of figure 2 .",
    "exploiting the positivity constraint leads to better resolution and less ringing for this example , where the background is zero .",
    "figure 3 gives a different view of the same solutions , with a compressed gray scale ranging from @xmath760 ( darker ) to @xmath761 ( lighter ) of the maximum intensity in the original object .",
    "this has the effect of highlighting the ringing effects and the noise . both ringing and noise",
    "are seen to be less pronounced for the minimizer of @xmath752 ( top left ) than that of @xmath753 .",
    "although the introduction of the positivity constraint removes the ringing phenomenon ( top of figure 3 ) , we nevertheless see that noise is better suppressed with @xmath90 .    to produce figures 1 to 3 , the same program was used in every case ; the only change was the choice of the nonlinear operator applied at the @xmath227-th iteration step to @xmath762 .",
    "for realistic applications on data of this type , more sophisticated algorithms exist . with the @xmath159penalty , for instance",
    ", the reconstructions in our simple example can be obtained directly by a regularized fourier deconvolution .",
    "these examples are included to illustrate the differences that can be achieved by the choice of @xmath86 , and do not constitute a claim that the iterative algorithms discussed in this paper are optimal .",
    "the `` data '' in this example are also only simple - minded caricatures of quasi point - sources data sets .",
    "while similar examples may have applications in astronomy , most natural images have a much richer structure .",
    "however , as is abundantly documented , the wavelet transforms of natural images tend to have distributions that are sparse .",
    "a similar improvement in accuracy can be expected by applying @xmath179 rather than @xmath159 penalizations on the wavelet coefficients in inverse problems involving natural images , similar to the gain achieved in denoising with a soft thresholding rather than with a quadratic penalty .",
    "the algorithm proposed in this paper can be generalized in several directions , some of which we list here , with brief comments .",
    "the penalization functionals @xmath403 we have used are symmetric , i.e. they are invariant under the exchange of @xmath4 for @xmath763 .",
    "we can equally well consider penalization functionals that treat positive and negative values of the @xmath95 differently .",
    "if @xmath764 and @xmath765 are two sequences of strictly positive numbers , then we can consider the problem of minimizing the functional @xmath766_+^p + ( w^-_\\gamma ) [ \\fg]_-^p)\\ ] ] where , for @xmath767 .",
    "one easily checks that all the arguments in this paper can be applied equally well ( after some straightforward modifications ) to the general functional ( [ asfunct ] ) , provided we replace the thresholding functions @xmath768 in the iterative algorithm by @xmath769 , where , for @xmath237 , @xmath770_+^{p-1 } - \\frac{p}{2}\\ , w^- [ x]_-^{p-1 } ~,\\ ] ] and for @xmath90 , @xmath771    the above applies when the @xmath95 are all real ; a generalization to complex @xmath95 is not straightforward .",
    "when dealing with complex functions , one could generalize the penalization @xmath772 to @xmath773 , where the weight coefficients have been replaced by strictly positive @xmath774periodic @xmath775functions on the @xmath145torus @xmath776 .",
    "it turns out , however , that the variational equation for @xmath777 then no longer uncouples from that for @xmath778 ( as it does in the case where @xmath779 is a constant ) , leading to a more complicated `` generalized thresholding '' operation in which the absolute value and phase of the complex number @xmath780 are given by a system of coupled nonlinear equations .    when the @xmath781basis is chosen to be a wavelet basis , then we saw in subsection 1.4.1 that is is possible to make the @xmath627norm equivalent to the besov - norm @xmath782 , by choosing the weight for @xmath783 to be given by @xmath784 , where @xmath126 is the scale of wavelet @xmath785 .",
    "the label @xmath786 contains much more information than just the scale , however , since it also indicates the location of the wavelet , as well as its `` species '' ( i.e. exactly which combination of @xmath145-dimensional scaling functions and wavelets is used to construct the product function @xmath785 ) .",
    "one could choose the @xmath787 so that certain regions in space are given extra weight , or on the contrary de - emphasized , depending on prior information . in pixel space ,",
    "prior information on the support of the object to be reconstructed can be easily enforced by simply setting the corresponding weights to very small values , or by choosing very large weights outside the object support .",
    "this type of constraint is of uttermost importance to achieve superresolution in inverse problems in optics and imaging ( see e.g. @xcite ) . when thresholding in the wavelet domain , a constraint on the object support can be enforced in a similar way due to the good spatial localization of the wavelets .",
    "if no a priori information is known , one could even imagine repeating the wavelet thresholding algorithm several times , adapting the weights @xmath787 after each pass , depending on the results of the previous pass ; this could be used , e.g. , to emphasize certain locations at fine scales if coarser scale coefficients indicate the possible existence of an edge .",
    "the results of this paper guarantee that each pass will converge .    in this paper",
    "we have restricted ourselves to penalty functions that are weighted @xmath0norms of the @xmath788 .",
    "the approach can be extended naturally to include penalty functions that can be written as sums , over @xmath82 , of more general functions of @xmath95 , so that the functional to be minimized is then written as @xmath789 the arguments in this paper will still be applicable to this more general case if the functions @xmath790 are convex , and satisfy some extra technical conditions , which ensure that the corresponding generalized component  shrinkage functions @xmath791 are still non - expansive ( used in several places ) , and that , for some @xmath792 , @xmath793 ( used in lemma [ lm-3 - 16 ] ) . to ensure that both conditions are satisfied , it is sufficient to choose functions @xmath794 that are convex , with a minimum at @xmath436 and e.g. twice differentiable , except possibly at @xmath436 ( where they should nevertheless still be left and right differentiable ) , and for which @xmath795 on @xmath796 , where @xmath797 is a neighborhood of @xmath436 .",
    "we conclude this paper with some comments concerning the numerical complexity of the algorithm .    at each iteration step",
    ", we must compute the action of the operator @xmath36 on the current object estimate , expressed in the @xmath798basis . in a finite - dimensional setting where the solution is represented by a vector of length @xmath72 , this necessitates in principle a matrix multiplication of complexity @xmath799 , if we neglect the cost of the shrinkage operation in each iteration step .",
    "after sufficient accuracy is attained and the iterations are stopped , the resulting @xmath800 must be transformed back into the standard representation domain of the object function , except in the special case where the @xmath801 are already the basis for the standard representation ( e.g. , if the @xmath801 correspond to the pixel representation for images ) .",
    "this adds one final @xmath799matrix multiplication . in this scenario ,",
    "the total cost equals that of the classical landweber algorithm on the basis of a comparable number of iterations .",
    "since landweber s algorithm typically requires a substantial number of iterations , it follows that this method can become computationally competitive with the @xmath802 svd algorithms only when @xmath72 is large compared to the number of iterations necessary .",
    "several methods have been proposed in the literature to accelerate the convergence of landweber s iteration , which could be used for the present algorithm as well . for instance , one could use some form of preconditioning ( using the operator @xmath312 of the remark [ op - d ] ) or group together @xmath561 landweber iteration steps and apply thresholding only every @xmath561 steps ( see e.g. the book @xcite ) .",
    "much more substantial gains can be obtained when the operator @xmath57 can be implemented via fast algorithms . in a first important class of applications ,",
    "the matrix + @xmath803 is sparse ; if , for instance , there are only @xmath804 non vanishing entries in this matrix , then standard techniques to deal with the action of sparse matrices will reduce the cost of each iteration step to @xmath804 instead of @xmath799 . if the @xmath91basis is a wavelet basis , this is the case for a large class of integro - differential operators of interest ( see e.g. @xcite ) . even if @xmath57 is sparse in the @xmath91basis , but has an even simpler expression in another basis , and if the transforms back and forth between the two bases can be carried out via fast algorithms , then it may be useful to implement the action of @xmath57 via these back  and  forth transformations .",
    "for instance , if the object is of a type that will have a sparse representation in a wavelet basis , and the operator @xmath57 is a convolution operator , then we can pick the @xmath91basis to be a wavelet basis , and implement the operator @xmath57 by doing , successively , a fast reconstruction from wavelet coefficients , followed by a fft , a multiplication in the fourier domain , an inverse fft , and a wavelet transform , for a total complexity of @xmath805 .",
    "one can obtain similar complexity estimates if the algorithm is modified to not only take the nonlinear thresholding into account , but also additional projections @xmath758 on a convex set , such as the cone of functions that are a.e .",
    "positive ; in this case , after the thresholding operation , one needs to carry out an additional fast reconstruction from , say , the wavelet domain , take the positive part , and then perform the fast transform back , without affecting the @xmath805 complexity estimate .",
    "the situations described above cover several applications of great practical relevance , in which we expect this algorithm will prove itself to be an attractive competitor to other fast techniques for large - scale inverse problems with sparsity constraints .",
    "we thank albert cohen , rich baraniuk , mario bertero , brad lucier , stphane mallat and especially david donoho for interesting and stimulating discussions .",
    "we also would like to thank rich baraniuk for drawing our attention to @xcite .",
    "ingrid daubechies gratefully acknowledges partial support by nsf grants dms-0070689 and dms-0219233 , as well as by afosr grant f49620 - 01 - 1 - 0099 , whereas research by christine de mol is supported by the `` action de recherche concerte '' nb 02/07 - 281 and iap - network in statistics p5/24 .    a    f. abramovich and b. w. silverman , _ wavelet decomposition approaches to statistical inverse problems .",
    "_ biometrika * 85 * ( 1998 ) , 115129 .",
    "m. bertero and p. boccacci , _ introduction to inverse problems in imaging _",
    ", institute of physics , bristol , 1998 .",
    "m. bertero and c. de mol , _ super - resolution by data inversion _ , in : progress in optics ( vol .",
    "xxxvi ) , e. wolf , ed . ,",
    "elsevier , amsterdam , 1996 , pp .",
    "129178 .",
    "g. beylkin , r. coifman and v. rokhlin , _ fast wavelet transforms and numerical algorithms i. _ comm .",
    "pure appl . math .",
    "* 44 * ( 1991 ) , 141183 .",
    "e. j. cands and d. l. donoho , _ recovering edges in ill - posed inverse problems : optimality of curvelet frames .",
    "statist . *",
    "30 * ( 2000 ) , 784842 .",
    "a. chambolle , r. a. devore , n .- y .",
    "lee and b. j. lucier , _ nonlinear wavelet image processing : variational problems , compression , and noise removal through wavelet shrinkage .",
    "_ ieee trans .",
    "image processing * 7 * ( 1998 ) , 319335 .",
    "s. chen , d. donoho and m. saunders , _ atomic decomposition by basis pursuit _",
    "siam review * 43 * ( 2001 ) , 129159 .",
    "a. cohen , _ wavelet methods in numerical analysis .",
    "_ , handbook of numerical analysis , vol .",
    "vii , p. g. ciarlet and j. l. lions eds . , elsevier , amsterdam , 2000 .",
    "a. cohen , m. hoffmann and m. reiss , _ adaptive wavelet galerkin methods for linear inverse problems .",
    "_ preprint , 2002 .    c. de mol and m. defrise , _ a note on wavelet - based inversion methods _ , in : _ inverse problems , image analysis and medical imaging _ , m. z. nashed and o. scherzer eds , series `` contemporary mathematics '' vol . 313 , pp . 8596 , american mathematical society , 2002 .",
    "a. r. de pierro , _ a modified expectation maximization algorithm for penalized likelihood estimation in emission tomography .",
    "_ ieee trans . med .",
    "* 14 * ( 1995 ) , 132137 .",
    "r. devore , _ nonlinear approximation .",
    "_ acta numerica ( 1998 ) , 199 .    v.",
    "dicken and p. maass , _ wavelet - galerkin methods for ill - posed problems .",
    "ill - posed problems * 4 * ( 1996 ) 203222 .",
    "d. donoho , _ superresolution via sparsity constraints .",
    "_ siam j. math",
    "23 * ( 1992 ) , 13091331 .",
    "d. donoho , _ nonlinear solution of linear inverse problems by wavelet - vaguelette decomposition .",
    "_ appl . comp .",
    "harmonic anal .",
    "* 2 * ( 1995 ) , 101126 .",
    "d. donoho , _ orthonormal ridgelets and linear singularities .",
    "_ siam j. math .",
    "31 * ( 2000 ) , 10621099 .",
    "d. donoho and i. johnstone , _ ideal spatial adaptation via wavelet shrinkage .",
    "_ biometrika * 81 * ( 1994 ) , 425455 .    r. j. duffin and a. c. schaeffer , _ a class of nonharmonic fourier series .",
    "_ trans . am .",
    "* 72 * ( 1952 ) , 341366 .",
    "b. eicke , _ iteration methods for convexly constrained ill - posed problems in hilbert space .",
    "* 13 * ( 1990 ) , 413429 .",
    "h. w. engl , m. hanke and a. neubauer , _ regularization of inverse problems _ , kluwer , dordrecht , 1996 .",
    "m. figueiredo and r. nowak , _ an em algorithm for wavelet - based image restoration _ , ieee transactions on image processing . to appear in july 2003 .",
    "j. kalifa , s. mallat and b. roug , _ deconvolution by thresholding in mirror wavelet bases .",
    "_ ieee trans .",
    "on image processing * 12 * ( 2003 ) , 446457 .",
    "l. landweber , _ an iterative formula for fredholm integral equations of the first kind . _ am . j. math . *",
    "73 * ( 1951 ) , 615624 .",
    "k. lange , d. r. hunter and i. yang , _ optimization transfer algorithms using surrogate objective functions .",
    "_ j. comp .",
    "* 9 * ( 2000 ) , 159 .",
    "lee and b. j. lucier , _ wavelet methods for inverting the radon transform with noisy data . _",
    "ieee trans .",
    "image processing * 10 * ( 2001 ) , 7994 .",
    "m. li , h. yang and h. kudo , _ an accurate iterative reconstruction algorithm for sparse objects : application to 3-d blood - vessel reconstruction from a limited number of projections .",
    "biol * 47 * ( 2002 ) , 25992609 .",
    "a. k. louis , p. maass and a. rieder , _ wavelets : theory and applications _ , wiley , chichester , 1997 .",
    "s. mallat , _ a wavelet tour of signal processing _ , 2nd edition , academic press , san diego , 1999 .",
    "y. meyer , _ wavelets and operators _ , cambridge university press , 1992 .",
    "r. nowak and m. figueiredo , _ fast wavelet - based image deconvolution using the em algorithm .",
    "_ conference record of the thirty - fifth asilomar conference on signals , systems and computers , vol .",
    "1 , pp . 371375 , 2001 .",
    "z. opial , _ weak convergence of the sequence of successive approximations for nonexpansive mappings . _",
    "* 73 * ( 1967 ) , 591597 .",
    "r. tibshirani , _ regression shrinkage and selection via the lasso .",
    "_ j. royal statist .",
    "b * 58 * ( 1996 ) , 267288 .",
    "we give a brief review of basic definitions of wavelets and their connection with besov spaces .",
    "this will be a sketch only ; for details , we direct the reader to e.g. @xcite .    for simplicity",
    "we start with dimension 1 . starting from a ( very special ) function @xmath806 we define@xmath807 and we assume that the collection @xmath808 constitutes an orthonormal basis of @xmath809 . for all wavelet bases",
    "used in practical applications , there also exists an associated _ scaling function _",
    "@xmath810 , which is orthogonal to its translates by integers , and such that , for all @xmath811 , @xmath812 where the @xmath813 are defined analogously to the @xmath814 . typically , the functions @xmath810 and @xmath806 are very well localized , in the sense that @xmath815 , @xmath816 ; one can even choose @xmath810 and @xmath806 such that they are supported on a finite interval .",
    "this can be achieved with arbitrary finite smoothness , i.e. for any preassigned @xmath817 , one can find such @xmath810 and @xmath806 that are moreover in @xmath818 .",
    "because of ( [ mra ] ) , one can consider ( inhomogeneous ) wavelet expansions , in which not all scales @xmath819 are used , but a cut - off is introduced at some coarsest scale , often set at @xmath820 .",
    "more precisely , we shall use the following wavelet expansion of @xmath821 , @xmath822 wavelet bases in higher dimensions can be built by taking appropriate products of one - dimensional wavelet and scaling functions .",
    "such @xmath823-dimensional bases can be viewed as the result of translating ( by elements @xmath561 of @xmath824 ) and dilating ( by integer powers @xmath819 of 2 ) of not just one , but several ( finite in number ) `` mother wavelets '' , typically numbered from 1 to @xmath825 .",
    "it will be convenient to abbreviate the full label ( including @xmath819 , @xmath561 and the number of the mother wavelet ) to just @xmath786 , with the convention that @xmath826 .",
    "we shall again cut off at some coarsest scale , and we shall follow the convenient slight abuse of notation used in @xcite that sweeps up the coarsest-@xmath819 scaling functions ( as in ( [ inhmra ] ) ) into the @xmath127 as well .",
    "we thus denote the complete @xmath823-dimensional , inhomogeneous wavelet basis by @xmath827 .",
    "it turns out that @xmath827 is not only an orthonormal basis for @xmath107 , but also an unconditional basis for a variety of other useful banach spaces of functions , such as hlder spaces , sobolev spaces and , more generally , besov spaces .",
    "again , we review only some basic facts ; a full study can be found in e.g. @xcite .",
    "the besov spaces @xmath108 consist , basically , of functions that `` have @xmath110 derivatives in @xmath734 '' ; the parameter @xmath112 provides some additional fine - tuning to the definition of these spaces .",
    "the norm @xmath828 in a besov space @xmath829 is traditionally defined via the _ modulus of continuity _ of @xmath4 in @xmath830 , of which an additional weighted @xmath831-norm is then taken , in which the integral is over different scales",
    ". we shall not give its details here ; for our purposes it suffices that this traditional besov norm is equivalent with a norm that can be computed from wavelet coefficients .",
    "more precisely , let us assume that the original 1-dimensional @xmath810 and @xmath806 are in @xmath818 , with @xmath832 , that @xmath833 , and define the norm @xmath834 by @xmath835 , that is , there exist strictly positive constants @xmath152 and @xmath153 such that @xmath836 the condition that @xmath837 is imposed to ensure that @xmath108 is a subspace of @xmath107 ; we shall restrict ourselves to this case in this paper . from ( [ triple ] )",
    "one can gauge the fine - tuning role played by the parameter @xmath112 in the definition of the besov spaces .",
    "a particularly convenient choice , to which we shall stick in the remainder of this paper , is @xmath838 , for which the expression simplifies to latexmath:[\\[\\vvert f \\vvert_{_{s , p } } = \\left ( \\sum_{\\lambda \\in \\lambda } 2^{\\sigma p|\\lambda| } ~    notation , we shall drop the extra index @xmath112 wherever it normally occurs , on the understanding that @xmath838 when we do so .    when @xmath840 , the besov spaces can still be defined as complete metric spaces , although they are no longer banach spaces ( because ( [ triple ] ) no longer is a norm ) , this allows for more local variability in local smoothness than is typical for functions in the usual hlder or sobolev spaces .",
    "for instance , a real function @xmath4 on @xmath104 that is piecewise continuous , but for which each piece is locally in @xmath841 , can be an element of @xmath842 , despite the possibility of discontinuities at the transition from one piece to the next , provided @xmath843 is sufficiently small , and some technical conditions are met on the number and size of the discontinuities , and on the decay at @xmath439 of @xmath4 .",
    "wavelet bases are thus closely linked to a rich class of smoothness spaces ; they also provide a good tool for high accuracy nonlinear approximation of a wide variety of functions .",
    "for instance , if the bounded function @xmath4 on @xmath140 $ ] has only finitely many discontinuities , and is @xmath841 elsewhere , then one can find a way of renumbering ( dependent on @xmath4 itself ) the wavelets in the standard wavelet expansion of @xmath4 , so that the distance in , say , @xmath844)$ ] between @xmath4 and the first @xmath72 terms of this reordered wavelet expansion , decreases proportionally to @xmath845 .",
    "if @xmath110 is large , it follows that a very accurate approximation to @xmath4 can be obtained with relatively few wavelets ; this is possible because the smooth patches of the piecewise continuous @xmath4 will be well approximated by coarse scale wavelets , which are few in number ; to capture the behavior of @xmath4 near the discontinuities much more localized finer scale wavelets are required , but only those wavelets located exactly near the discontinuities will be needed , which amounts again to a small number .    in higher dimensions , @xmath137 ,",
    "the suitability of wavelets is influenced by the dimension of the manifolds on which singularities occur .",
    "if the singularities in the functions of interest are solely point singularities , then expansions using @xmath72 wavelets can still approximate such functions with distances that decrease like @xmath845 , depending on their behavior away from the singularities . if , however , we are interested in @xmath4 that may have , e.g. discontinuities along manifolds of dimension higher than 0 , then such wavelet approximations are not optimal . for instance , if @xmath846 is piecewise @xmath847 , with possible jumps across the boundaries of the smoothness domains , which are themselves smooth ( say , @xmath847 again ) curves , then @xmath72-term wavelet approximations to @xmath4 can not achieve an error rate decay faster than @xmath848 , regardless of the value of @xmath849 .",
    "it follows that whenever we are faced with an inverse problem that needs regularization , in which the objects to be restored are expected to be mostly smooth , with very localized lower dimensional areas of singularities , we can expect that their expansions into wavelets will be sparse .",
    "this sparsity can be expressed by requiring that the wavelet coefficients ( possibly with some scale - dependent weight ) have a finite ( or small ) @xmath0-norm , with @xmath850 , or equivalently that the besov - equivalent norm @xmath851 is finite ( or small ) , where @xmath852 is exactly of the form @xmath853 defined in ( [ funct - gen ] ) .",
    "we provide here the proof of the theorem needed to establish the weak convergence of the iterative algorithm .",
    "the theorem is given in @xcite ; we give a simplified proof here ( see the remark at the end ) , which nevertheless still follows the main lines of opial s paper .      1 .",
    "@xmath349 is non - expansive : @xmath855  , 2 .",
    "@xmath349 is asymptotically regular : @xmath856{~ } 0,\\ \\forall v \\in { \\cal c}$ ]  , 3 .   the set @xmath354 of the fixed points of @xmath349 in @xmath405 is not empty  .              _",
    "proof : _ because of the non - expansivity of @xmath349 ( assumption ( i ) ) , we have @xmath871 @xmath872 @xmath873 @xmath872 @xmath874 . hence , @xmath875 it then follows from lemma [ fp1 ] that @xmath876 or @xmath877 .",
    "_ proof : _ suppose _ w_@xmath421@xmath881 .",
    "since , by the assumption ( ii ) of asymptotic regularity , @xmath882 , we have @xmath883 . by lemma [ fp2 ] , it follows that @xmath884 , i.e. that @xmath885 is in @xmath880 .                    since @xmath906",
    ", we obtain from lemma [ fp1 ] that @xmath907 @xmath908 on the other hand , because @xmath909 and @xmath910 are each a subsequence of a convergent sequence , @xmath911 = @xmath912 and @xmath913 = @xmath914 .",
    "it follows that @xmath915 @xmath916 . in a completely analogous way ( working with the subsequence @xmath917 instead of @xmath918 ) one",
    "derives the opposite strict inequality .",
    "since both can not be valid simultaneously , the assumption of the existence of two different weak accumulation points for @xmath919 is false .",
    "it is essential to require that the set @xmath880 is not empty since there are asymptotically regular , non - expansive maps that possess no fixed point .",
    "however , the only place where we used this assumption was in showing that the @xmath921 were bounded .",
    "if one can prove this boundedness by some other means ( e.g. by a variational principle as we did in the iterative algorithm ) , then we automatically have a weakly convergent subsequence @xmath922 , and thus , by lemma [ fp3 ] , an element of @xmath880 .",
    "the simplification of the original argument of @xcite ( obtained through deriving the contradiction in the proof of theorem [ fpthm ] ) avoids having to appeal to the convexity of @xmath880 ( which is true but not immediately obvious ) and having to introduce the auxiliary sets @xmath923 used in @xcite ."
  ],
  "abstract_text": [
    "<S> we consider linear inverse problems where the solution is assumed to have a sparse expansion on an arbitrary pre  assigned orthonormal basis . </S>",
    "<S> we prove that replacing the usual quadratic regularizing penalties by weighted @xmath0- penalties on the coefficients of such expansions , with @xmath1 , still regularizes the problem . </S>",
    "<S> if @xmath2 , regularized solutions of such @xmath3-penalized problems will have sparser expansions , with respect to the basis under consideration . to compute the corresponding regularized solutions we propose an iterative algorithm which amounts to a landweber iteration with thresholding ( or nonlinear shrinkage ) applied at each iteration step . </S>",
    "<S> we prove that this algorithm converges in norm . </S>",
    "<S> we also review some potential applications of this method . </S>"
  ]
}