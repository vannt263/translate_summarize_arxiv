{
  "article_text": [
    "the cox - ingersoll - ross process @xmath0 is determined by the following stochastic differential equation ( sde)@xmath1 where @xmath2 are positive constants , and @xmath3 is a scalar brownian motion . due to @xcite",
    "this process has become very popular in financial mathematical applications .",
    "the cir process is used in particular as volatility process in the heston model @xcite .",
    "it is known ( @xcite , @xcite ) that for @xmath4 there exists a unique strong solution @xmath5 of ( [ in1 ] ) for all @xmath6 .",
    "the cir  process @xmath7 is positive in the case @xmath8 and nonnegative in the case @xmath9 moreover , in the last case the origin is a reflecting boundary .    as a matter of fact , ( [ in1 ] )",
    "does not satisfy the global lipschitz assumption .",
    "the difficulties arising in a simulation method for ( [ in1 ] ) are connected with this fact and with the natural requirement of preserving nonnegative approximations . a lot of approximation methods for the cir processes are proposed . for an extensive list of articles on this subject",
    "we refer to @xcite and @xcite . besides @xcite and @xcite",
    "we also refer to @xcite , where a number of discretization schemes for the cir process can be found .",
    "further we note that in @xcite a weakly convergent fully implicit method is implemented for the heston model . exact simulation of ( [ in1 ] ) is considered in @xcite ( see @xcite as well ) .    in this paper , we consider uniform pathwise approximation of @xmath0 on an interval @xmath10 $ ] using the doss - sussmann transformation ( @xcite , @xcite , @xcite ) which allows for expressing any trajectory of @xmath0 by the solution of some ordinary differential equation that depends on the realization of @xmath11 the approximation @xmath12 will be uniform in the sense that the path - wise error will be uniformly bounded , i.e.@xmath13 where @xmath14 is fixed in advance .",
    "in fact , by simulating the first - passage times of the increments of the wiener process to the boundary of an interval and solving this ode , we approximately construct a generic trajectory of @xmath15 such kind of simulation is more simple than the one proposed in @xcite and moreover has the advantage of uniform nature .",
    "let us consider the simulation of a standard brownian motion @xmath16 on a fixed time grid @xmath17 although @xmath16 may be even exactly simulated at the grid points , the usual piecewise linear interpolation@xmath18 is not uniform in the sense of ( [ uni ] ) .",
    "put differently , for any ( large ) positive number @xmath19 there is always a positive probability ( though possibly small ) that@xmath20 therefore , for path dependent applications for instance , such a standard , even exact , simulation method may be not desirable and a uniform method preserving ( [ uni ] ) may be preferred .",
    "we note that the original ds results rely on a global lipschitz assumption that is not fulfilled for ( [ in1 ] ) .",
    "we therefore have introduced the ds formalism that yields a corresponding ode which solutions are defined on random time intervals . if @xmath21 gets close to zero however , the ode becomes intractable for numerical integration and so , for the parts of a trajectory @xmath22 that are close to zero , we are forced to use some other ( not ds ) approach . for such parts",
    "we here propose a different uniform simulation method .",
    "another restriction is connected with the condition @xmath23 we note that the case @xmath24 is more general than the case @xmath25 that ensures positivity of @xmath22 and stress that in the literature virtually all convergence proofs for methods for numerical integration of ( [ in1 ] ) are based on the assumption @xmath26 we expect that the results here obtained for @xmath24 can be extended to the case where @xmath27 however in a highly nontrivial way . therefore , the case @xmath28 will be considered in a subsequent work .",
    "the next two sections are devoted to ds formalism in connection with ( [ in1 ] ) and to some auxiliary propositions . in sections  4 and 5",
    "we deal with the one - step approximation and the convergence of the proposed method , respectively .",
    "section  6 is dedicated to the uniform construction of trajectories close to zero .",
    "* 2.1 * due to the doss - sussmann approach ( @xcite , @xcite , @xcite , @xcite ) , the solution of ( [ in1 ] ) may be expressed in the form@xmath29 where @xmath30 is some deterministic function and @xmath31 is the solution  of some ordinary differential equation depending on the part @xmath32 of the realization @xmath33 of the wiener process @xmath11    let us recall the doss - sussmann formalism according to @xcite , v.28 . in @xcite one consideres the stratonovich sde @xmath34 the function @xmath30 is found from the equation @xmath35 and @xmath31 is found from the ode@xmath36    it turns out that application of the ds formalism after the lamperti transformation @xmath37 ( see @xcite ) leads to more simple equations .",
    "the lamperti transformation yields the following sde with additive noise@xmath38 let us seek the solution of ( [ ds8 ] ) in the form @xmath39 in accordance with ( [ ds1])-([ds7 ] ) . because the ito and stratonovich forrms of equation ( [ ds8 ] ) coincide , we have@xmath40 the function @xmath41 is found from the equation @xmath42 i.e.,@xmath43 and @xmath44 is found from the ode@xmath45 from ( [ ds2 ] ) , ( [ ds3 ] ) , and solution of ( [ ds4 ] ) , we formally obtain the solution @xmath46 of ( [ ds8]):@xmath47 hence@xmath48 * 2.2 * since the doss - sussmann results rely on a global lipschitz assumption that is not fulfilled for ( [ in1 ] ) , solution ( [ ds10 ] ) has to be considered only formally . in this section",
    "we therefore give a direct proof of the following more precise result .",
    "[ proposition 1 ] let @xmath49 let @xmath50 be the following stopping time : @xmath51 then equation ( [ ds4 ] ) has a unique solution @xmath44 on the interval @xmath52 the solution @xmath46 of ( [ ds8 ] ) is expressed by formula ( [ ds9 ] ) on this interval , and @xmath0 is expressed by ( [ ds10 ] ) .",
    "let @xmath53 be the solution of the sde system @xmath54 which satisfies the initial conditions @xmath55 then @xmath56 is a solution of ( [ ds8 ] ) on the interval @xmath57 consider the function @xmath58 clearly , @xmath59 on @xmath57 due to ito s formula , we get@xmath60 i.e. , the function @xmath61 is a solution of ( [ ds4 ] ) .",
    "the uniqueness of @xmath44 follows from the uniqueness of @xmath15    * 2.3 * so far we were starting at the moment @xmath62 .",
    "it is useful to consider the doss - sussmann transformation with an arbitrary initial time @xmath63 ( which even may be a stopping time , for example , @xmath64 ) . in this case",
    ", we obtain instead of ( [ ds4 ] ) for@xmath65 the equation @xmath66 with @xmath67 given by ( [ ds8a ] ) .",
    "* 3.1 * let us consider in view of ( [ ds15 ] ) solutions of the ordinary differential equations@xmath69 which are given by@xmath70^{1/2},\\",
    "t\\geq t_{0}. \\label{os2}\\ ] ]    in the case @xmath71 i.e. , @xmath72 we have : if @xmath73 then @xmath74 as @xmath75 and if @xmath76 then @xmath77 as @xmath78 further @xmath79 is a solution of ( [ os1 ] ) .",
    "in the case @xmath80 the solution @xmath81 under @xmath75 for any @xmath82 we note that the case @xmath83 is more general than the case @xmath25 ( we recall that in the latter case @xmath84,@xmath85 ) .    in the case @xmath86 the solution @xmath87 is convexly decreasing under not too large @xmath88 .",
    "it attains zero at the moment @xmath89 given by@xmath90 and @xmath91    in what follows we deal with the case @xmath92 * 3.2*. our next goal is to obtain estimates for solutions of the equation @xmath93 ( cf .",
    "( [ ds15 ] ) ) for a given continuous function @xmath94    [ lemma 2 ] let @xmath95 let @xmath96 be two solutions of ( [ os4 ] ) such that @xmath97 on @xmath98,$ ] for some @xmath99 with @xmath100 _ _",
    "then__@xmath101    we have@xmath102 from here@xmath103ds\\\\ \\leq(y^{2}(t_{0})-y^{1}(t_{0}))^{2},\\end{gathered}\\ ] ] whence ( [ os06 ] ) follows .",
    "[ l2 * ]  it is known that for @xmath104 the bessel process bes@xmath105 has the representation@xmath106 where @xmath16 is standard brownian motion , @xmath107 a.s . , and that in particular @xmath108 ( see @xcite ; for @xmath109 the representation of bes@xmath110 is less simple and involves the concept of local time . ) from this fact it is not difficult to show that for @xmath24 the solution of ( [ ds8 ] ) may be represented as @xmath111 thus , with @xmath112 it holds that@xmath113 for @xmath114 @xmath115 and that in particular @xmath116 is continuous and of bounded variation . from this",
    "it follows that ( [ val ] ) holds for @xmath117 when @xmath24 and @xmath118 is an arbitrary brownian trajectory , and then inequality ( [ os06 ] ) in lemma [ lemma 2 ] goes through for @xmath119    * 3.3 * now consider ( [ os4 ] ) for a continuous function @xmath120 satisfying@xmath121 for some @xmath14 and @xmath100 along with ( [ os1 ] ) , ( [ os4 ] ) with ( [ os5 ] ) , we further consider the equations@xmath122 let us assume that @xmath123 and consider an @xmath124 to be specified below , that satisfies @xmath125 the solutions of ( [ os1 ] ) , ( [ os4 ] ) with ( [ os5 ] ) , ( [ os6 ] ) , and ( [ os7 ] ) are denoted by @xmath126 , and @xmath127 respectively , where @xmath128 is given by ( [ os2 ] ) . by using ( [ os2 ] )",
    "we derive straightforwardly that@xmath129^{1/2}-\\frac{\\sigma}{2}r,\\ t_{0}\\leq t\\leq t_{0}+\\theta,\\label{os9}\\\\ y^{+}(t )   &   = [ ( y_{0}-\\frac{\\sigma}{2}r)^{2}e^{-k(t - t_{0})}+\\frac{2\\alpha}{k}(1-e^{-k(t - t_{0})})]^{1/2}+\\frac{\\sigma}{2}r,\\ t_{0}\\leq t\\leq t_{0}+\\theta .",
    "\\label{os10}\\ ] ] note that @xmath130 and @xmath131 @xmath132 due to the comparison theorem for odes ( see , e.g. , @xcite , ch .",
    "3 ) , the inequality@xmath133 which is fulfilled in view of ( [ os5 ] ) for @xmath134 then implies that@xmath135 the same inequality holds for @xmath136 replaced by @xmath137 we thus get@xmath138    [ proposition 3 ] let @xmath139 the inequalities ( [ os5 ] ) and ( [ os8 ] ) be fulfilled for a fixed @xmath124 and let @xmath140 we then have @xmath141 in particular , @xmath142 _ _ is independent of__@xmath143 and @xmath144 ( provided ( [ os8 ] ) holds ) .",
    "we estimate the difference @xmath145 it holds@xmath146 where@xmath147^{1/2}.\\ ] ] further,@xmath148 using the inequality @xmath149 for any @xmath150 and @xmath151 we get @xmath152 whence@xmath153 therefore@xmath154 from ( [ os15 ] ) we have that@xmath155 and so due to ( [ os14 ] ) we get@xmath156 since @xmath157 for any @xmath158 and @xmath159 under ( [ os8 ] ) , we obtain @xmath160 from this and ( [ os12 ] ) , ( [ os13 ] ) follows with @xmath161    [ corr ] under the assumptions of proposition  [ proposition 3 ] , we get by taking @xmath162@xmath163 where @xmath164 and @xmath165 only depend on the parameters of the cir process under consideration and the time horizon  @xmath166",
    "let us suppose that for @xmath167 @xmath168 is known exactly . in fact , @xmath169 may be considered as a realization of a certain stopping time .",
    "consider @xmath170 on some interval @xmath171 $ ] with @xmath172 given by the ode ( cf .",
    "( [ ds15])),@xmath173 assume that@xmath174 due to ( [ ds17 ] ) , the solution @xmath0 of ( [ in1 ] ) on @xmath171 $ ] is obtained via@xmath175 though equation ( [ os19 ] ) is ( just ) an ode , it is not easy to solve it numerically in a straightforward way because of the non - smoothness of @xmath11 we are here going to construct an approximation @xmath176 of @xmath177 via proposition  [ proposition 3 ] . to this end",
    "we simulate the point @xmath178 by simulating @xmath179 as being the first - passage ( stopping ) time of the wiener process @xmath180 @xmath181 to the boundary of the interval @xmath182.$ ] so , @xmath183 for @xmath184 and , moreover , the random variable @xmath185 which equals either @xmath186 or @xmath187 with probability @xmath188 is independent of the stopping time @xmath189 a method for simulating the stopping time @xmath179 is given in subsection  [ sim ] below .",
    "proposition [ proposition 3 ] and corollary [ corr ] then yield,@xmath190 where @xmath176 is the solution of the problem @xmath191 that is given by ( [ os2 ] ) with @xmath192 we so have , @xmath193 where due to ( [ os16]),@xmath194 we next introduce the one - step approximation @xmath195 of @xmath196 on @xmath197 $ ] by@xmath198 since @xmath199 if @xmath200 and @xmath201 if @xmath202 the one - step approximation ( [ os17 ] ) for @xmath203 is given by@xmath204{l}$r\\xi_{m}$ \\ \\ with $ p(\\xi_{m}=\\pm1)=1/2,$ if $ t_{m+1}=t_{m}+\\theta_{m}<t_{0}+t,$\\\\ $ \\zeta_{m}$ \\ \\ \\ if $ t_{m+1}=t_{0}+t,$\\end{tabular } \\ \\ \\ \\ \\right . \\nonumber\\end{gathered}\\ ] ] with @xmath205 being drawn from the distribution of@xmath206 where @xmath16 is an independent standard brownian motion .",
    "for details see subsection  [ sim ] below .",
    "we so have the following theorem .",
    "[ theorem 4 ] for the one - step approximation @xmath207 due to the exact starting value @xmath208 @xmath209 @xmath168 @xmath209 @xmath210 we have the one step error@xmath211      for simulating @xmath179 we utilize the distribution function@xmath213 where @xmath50 is the first - passage time of the wiener process @xmath214 to the boundary of the interval @xmath215.$ ] a very accurate approximation @xmath216 of @xmath217 is the following one:@xmath218@xmath219{c}\\dfrac{2}{\\sqrt{2\\pi t^{3}}}(e^{-\\dfrac{1}{2t}}-3e^{-\\dfrac{9}{2t}}+5e^{-\\dfrac{25}{2t}}),\\ 0<t\\leq\\dfrac{2}{\\pi},\\\\ \\dfrac{\\pi}{2}(e^{-\\dfrac{\\pi^{2}t}{8}}-3e^{-\\dfrac{9\\pi^{2}t}{8}}+5e^{-\\dfrac{25\\pi^{2}t}{8}}),\\ t>\\dfrac{2}{\\pi } , \\end{array } \\right.\\ ] ] and it holds@xmath220 ( see for details @xcite , ch . 5 , sect . 3 and appendix a3 ) . now simulate a random variable @xmath221 uniformly distributed on @xmath222,$ ] then compute @xmath223 which is distributed according to @xmath224 that is , we have to solve the equation @xmath225 for instance by newton s method or any other efficient solving routine .",
    "next set @xmath226    for simulating @xmath212 in ( [ os180 ] ) we observe that ( [ con ] ) is equivalent with@xmath227 we next sample @xmath228 from the distribution function @xmath229 where @xmath230 is the known conditional distribution function ( see @xcite , ch . 5 , sect . 3)@xmath231 and set @xmath232 the simulation of the last step looks rather complicated and may be computationally expensive .",
    "however it is possible to take for @xmath233 simply any value between @xmath186 and @xmath234 e.g. zero .",
    "this may enlarge the one - step error on the last step but does not influence the convergence order of the elaborated method .",
    "indeed , if we set @xmath233 to be zero , for instance , on the last step , we get @xmath235 instead of ( [ os180 ] ) , and @xmath236    we have in any step @xmath237 the random number of steps before reaching",
    "@xmath238 say @xmath239 is finite with probability one , and @xmath240 for details see @xcite , ch . 5 , lemma 1.5 .",
    "in a heuristic sense this means that , if we have convergence of order @xmath241 we obtain accuracy @xmath242 for an ( expected ) number of steps @xmath243 similar to the standard euler scheme .",
    "in this section we develop a scheme that generates approximations @xmath244 @xmath245 @xmath246 @xmath247 where @xmath248 and @xmath249 are realizations of a sequence of stopping times , and show that the global error in approximation @xmath250 is in fact an aggregated sum of local errors , i.e. , @xmath251 with @xmath252  @xmath253 provided that @xmath254 for @xmath255 and so @xmath256    let us now describe an algorithm for the solution of ( [ in1 ] ) on the interval @xmath10 $ ] in the case @xmath95 suppose we are given @xmath257 and @xmath144 such that@xmath258 for the initial step we use the one - step approximation according to the previous section and thus obtain ( see ( [ os180 ] ) and ( [ os018]))@xmath259 where @xmath260 suppose that @xmath261 we then go to the next step and consider the expression @xmath262 where @xmath263 is the solution of the problem ( see ( [ os19]))@xmath264 now , in contrast to the initial step , the value @xmath265 is unknown and we are forced to use @xmath266 instead .",
    "therefore we introduce @xmath267 as the solution of the equation ( [ ct3 ] ) with initial value @xmath268 from the previous step we have that @xmath269 @xmath270 hence , due to lemma  [ lemma 2 ] , @xmath271 let @xmath272 be the first - passage time of the wiener process @xmath273 to the boundary of the interval @xmath182.$ ] if @xmath274 then set @xmath275 else set @xmath276 in order to approximate @xmath267 for @xmath277 let us consider along with equation ( [ ct3 ] ) the equation@xmath278 due to proposition 3 and corollary [ corr ] it holds that@xmath279 and so by ( [ os18 ] ) we have@xmath280 we also have ( see ( [ ct2]))@xmath281 where@xmath282 we so define the approximation@xmath283 and then set@xmath284{l}\\ $ r\\xi_{1}$ \\ \\ with $ p(\\xi_{1}=\\pm1)=1/2,$ if $ t_{2}=t_{1}+\\theta_{1}<t_{0}+t,$\\\\ $ \\zeta_{1}$ \\ \\ \\ if $ t_{2}=t_{0}+t,$\\end{tabular } \\ \\ \\ \\ \\right .   , \\nonumber\\end{gathered}\\ ] ] cf .",
    "( [ os180 ] ) and ( [ con ] ) .",
    "we thus end up with a next approximation @xmath285 such that@xmath286    from the above description it is obvious how to proceed analogously given a generic approximation sequence of approximations @xmath287 @xmath288 with @xmath289 that satisfies by assumption@xmath290 indeed , consider the expression @xmath291 where @xmath292 is the solution of the problem @xmath293 for a @xmath294 to be determined@xmath295 since @xmath296 is unknown we consider @xmath297 as the solution of the equation ( [ ct03 ] ) with initial value @xmath298 due to ( [ ct02 ] ) and lemma 2 again , we have@xmath299 in order to approximate @xmath297 for @xmath300 we consider the equation@xmath301 by repeating the procedure ( [ r1])-([r8 ] ) we arrive at @xmath302 satisfying@xmath303 with@xmath304    in principle it is possible to use the distribution function @xmath305  ( see ( [ frakq ] ) ) for constructing @xmath195 for @xmath306 however , we rather consider for @xmath307 the approximation@xmath308 where ( a ) for @xmath309 @xmath310 is an arbitrary continuous function satisfying@xmath311 and ( b ) for @xmath312 one may take @xmath313 as a result we get similar to ( [ mod ] ) an insignificant increase of the error,@xmath314    let us consolidate the above procedure in a concise way .      * _ set _ @xmath315 * _ let the point _ @xmath316 _ be known for an _",
    "@xmath317 _ simulate independent random variables _ @xmath318 _ with _",
    "@xmath319and @xmath320 as described in subsection [ sim ] .",
    "_ if _ @xmath321 set @xmath322 else set @xmath323 * _ solve equation ( [ r09 ] ) on the interval _",
    "$ ] with solution @xmath325 and set@xmath326{l}$r\\xi_{n}$ \\ \\ if $ t_{n+1}<t_{0}+t,$\\\\ $ 0 $ \\ \\ \\ if $ t_{n+1}=t_{0}+t.$\\end{tabular } \\ \\ \\ \\ \\ \\right.\\ ] ]    so , under the assumption ( [ ct1 ] ) we obtain the estimate ( [ r10 ] ) ( possibly enlarged with a term @xmath327 ) .",
    "the next theorem shows that if a trajectory of @xmath0 under consideration is positive on @xmath10,$ ] then the algorithm is convergent on this trajectory .",
    "we recall that in the case @xmath25 almost all trajectories are positive , hence in this case the proposed method is almost surely convergent .",
    "[ theorem 8 ] let @xmath328 ( i.e. , @xmath83 ) .",
    "then for any positive trajectory @xmath84 _ on _ @xmath10 $ ] the proposed method is convergent on this trajectory . in particular",
    ", there exist @xmath329 depending on the trajectory @xmath330 only , and @xmath331 depending on @xmath332 such that @xmath333 for any @xmath334 so in particular ( [ ct1 ] ) is fulfilled for all @xmath335 and the estimate ( [ r10 ] ) implies that for any @xmath336@xmath337    let us define@xmath338 and let @xmath334 we then claim that for all @xmath339 @xmath340 for @xmath341 we trivially have @xmath342 now suppose by induction that @xmath343 for @xmath344then due to ( [ r11 ] ) we have@xmath345 because of ( [ sec ] ) .",
    "thus , since @xmath346 it follows that @xmath347 this proves ( [ ind ] ) and the convergence for @xmath348    [ remark 9 ] . in the case where @xmath349 trajectories will reach zero with positive probability , that is convergence on such trajectories is not guaranteed by theorem  [ theorem 8 ] .",
    "so it is important to develop some method for continuing the simulations in cases of very small @xmath350 one can propose different procedures , for instance , one can proceed with standard sde approximation methods relying on some known scheme suitable for small @xmath21 ( e.g. see @xcite ) .",
    "however , the uniformity of the simulation would be destroyed in this way .",
    "we therefore propose in the next section a uniform simulation method that may be started in a value @xmath208 close to zero .",
    "henceforth we assume that @xmath351 let us suppose that @xmath352 and consider conditions that guarantee that @xmath353 under @xmath354 of course in the case @xmath355 this is trivially fulfilled , and we thus consider the case @xmath356",
    "yielding@xmath357^{1/2}-\\frac{\\sigma r}{2}.\\ ] ] we so need@xmath358 since we are interested in properties of algorithms when @xmath359 we may further assume w.l.o.g .",
    "that @xmath360 i.e. @xmath361 under assumption ( [ ar ] ) , ( [ cp1 ] ) is obviously fulfilled when @xmath362 if @xmath363 we need@xmath364 which is fulfilled if@xmath365 note that ( [ ar ] ) is equivalent with @xmath366 @xmath367 and so ( [ cp11 ] ) is the condition we were looking for .",
    "conversely , if @xmath368 then @xmath369 @xmath327 with positive probability .",
    "in view of the above considerations , one may carry out the algorithm of subsection  [ simal ] as long as ( [ cp11 ] ) is fulfilled .",
    "let us say that @xmath370 was the last step where ( [ cp11 ] ) was true .",
    "then the aggregated error of @xmath250 due to the algorithm up to step @xmath370 may be estimated by ( cf .",
    "( [ ct1 ] ) and ( [ ct02])),@xmath371    let us recall that our primal goal is a scheme where @xmath372 almost surely and uniformly in @xmath373 in this respect , and in particular in the case @xmath374 where trajectories may attain zero with positive probability , it is not recommended to carry out scheme [ simal ] all the way through until ( [ cp11 ] ) is not satisfied anymore . indeed , if the trajectory attains zero , the worst case almost sure error bound would then be when all @xmath375 would be close to @xmath376 hence of order @xmath377 that is , no convergence on such trajectories .",
    "we therefore propose to perform scheme [ simal ] up to a ( stopping ) index @xmath378 defined by@xmath379 where @xmath380 is a positive constant and @xmath381 is to be determined suitably",
    ". a pragmatic choice would be @xmath382 ( see remark  [ ma ] ) .",
    "due to ( [ cz1 ] ) and ( [ epsn ] ) with @xmath370  replaced by @xmath383 we then have,@xmath384 for some constant @xmath385    let us now fix a realization @xmath386 and consider two solutions of equation ( [ in1 ] ) starting at the moment @xmath387 from @xmath388 ( known value ) and @xmath389 ( true but unknown value ) , denoted by @xmath390 and @xmath391 respectively , let @xmath392 @xmath393 be the first time at which the solution @xmath394 of ( [ in1 ] ) attains the level @xmath395 hence@xmath396 a construction of the distribution function of @xmath397 is worked out in section [ tetax ] .",
    "let us now denote @xmath398 with @xmath399 ( for simplicity and w.l.og .",
    "we assume that @xmath400 we then naturally set @xmath401 the solutions @xmath390 and @xmath402 correspond to two solutions @xmath403 and @xmath404 of ( [ os4 ] ) with @xmath405 @xmath406 starting in @xmath407 and @xmath408 respectively . due to lemma [ lemma 2 ] ,",
    "see remark [ l2 * ] , and ( [ cz2 ] ) it thus follows that@xmath409 and in particular@xmath410 in contrast to the previous steps we now specify the behavior of @xmath411 on @xmath412 $ ] by @xmath413 which we actually do not know . however , we do know that @xmath414 @xmath395 and that @xmath415 is bounded on @xmath412 $ ] by @xmath416 therefore , if we just take a straight line @xmath417  that connects the points @xmath418 and @xmath419 as an approximation for @xmath420 then @xmath421 @xmath422 by ( [ ba1 ] ) and ( [ balke ] ) we then also have @xmath423 thus , the accuracy of the approximation to @xmath424 for @xmath425 outside the band @xmath426 is of order @xmath427 and for @xmath428 inside the band @xmath429 of order @xmath430 but , at the boundary point @xmath431 @xmath432 the accuracy is of order @xmath433 again . finally , the scheme may be continued from the state @xmath434 with the algorithm of subsection [ simal ] .",
    "[ ma ] from the above construction it is clear that for @xmath382 in ( [ cz1 ] ) the accuracy for @xmath435 outside the band @xmath436 and for @xmath428 inside the band @xmath437 are of the same order .",
    "however , an exponent @xmath438 would give a higher accuracy outside the band @xmath439 and at the exit points of the band @xmath440 while inside the band the accuracy is worse but uniformly bounded by @xmath441      in order to carry out the above simulation method for trajectories near zero we have to find the distribution function of @xmath442 where @xmath443 is the first - passage time of the trajectory @xmath444 to the level @xmath445 for this it is more convenient to change notation and to write ( [ in1 ] ) in the form@xmath446 where without loss of generality we take the initial time to be @xmath447 the function@xmath448 is the solution of the first boundary value problem of parabolic type ( @xcite , ch .",
    "3)@xmath449 with initial data@xmath450 and boundary conditions@xmath451 to get homogeneous boundary conditions we introduce @xmath452 the function @xmath453 then satisfies:@xmath454@xmath455 the problem ( [ z5])-([z6 ] ) can be solved by the method of separation of variables . in this way",
    "the sturm - liouville problem for the confluent hypergeometric equation ( the kummer equation ) arises .",
    "this problem is rather complicated however .",
    "below we are going to solve an easier problem as a good approximation to ( [ z5])-([z6 ] ) .",
    "along with ( [ z1 ] ) , let us consider the equations@xmath456 with @xmath457 it is not difficult to prove the following inequalities@xmath458 according to ( [ z9 ] ) , we consider three boundary value problems : first ( [ z2])-([z4 ] ) and next similar ones for the equations@xmath459 from ( [ z9 ] ) it follows that@xmath460 hence@xmath461 where @xmath462    as the band @xmath463 for a certain @xmath464 is narrow due to small enough @xmath234 the difference @xmath465 will be small and so we can consider the following problem@xmath466@xmath467 as a good approximation of ( [ z5])-([z6 ] ) .",
    "henceforth we write @xmath468 by separation of variables we get as elementary independent solutions to ( [ z10 ] ) , @xmath469 where@xmath470 it can be verified straightforwardly that the solution of ( [ z13 ] ) can be obtained in terms of bessel functions of the first kind ( e.g. see @xcite ) , @xmath471 with @xmath472 since @xmath473 has to be bounded for @xmath474 we may take ( regardless the sign of @xmath475 ( ! ) ) @xmath476 in our setting we have @xmath71 i.e. @xmath477    the following derivation of a fourier - bessel series for @xmath453 is standard but included for convenience of the reader .",
    "denote the positive zeros of @xmath478 by @xmath479 for example , @xmath480 then the ( homogeneous ) boundary condition @xmath481 yields@xmath482 and we have@xmath483 by the well - known orthogonality relation@xmath484 we get by setting @xmath485 @xmath486 now set@xmath487 for @xmath62 we have due to the initial condition @xmath488@xmath489 so for any @xmath490@xmath491 further it holds that@xmath492 by well - known identities for bessel functions ( e.g. see @xcite ) , and ( [ chi2 ] ) thus becomes @xmath493 so , from @xmath494 ( [ chi0 ] ) ( [ chi ] ) , ( [ chi1 ] ) , ( [ chi3 ] ) , and ( [ ser ] ) we finally obtain@xmath495   \\,,\\text { \\ \\ } 0\\leq x\\leq l.\\label{fb1}\\ ] ]        we now consider some numerical examples concerning @xmath500 in ( [ fb1 ] ) and @xmath501 given by ( [ fb1 ] ) due to ( [ kap ] ) .",
    "note that actually in ( [ fb1 ] ) the function @xmath502 only depends on @xmath503 and @xmath504 that is , @xmath502 depends on @xmath503 and the product @xmath505 let us consider a cir process with @xmath506 @xmath507 @xmath508 and let us take @xmath509 we then compare @xmath510 which is given by ( [ fb1 ] ) for @xmath511 due to ( [ gam ] ) ( see example  [ test ] ) , with @xmath501 given by ( [ fb1 ] ) for @xmath512 due to ( [ kap ] ) .",
    "the results are depicted in figure  [ plot ] .",
    "the sums corresponding to ( [ fb1 ] ) are computed with five terms ( more terms did not give any improvement ) .      for practical applications",
    "it is useful to normalize ( [ fb1 ] ) in the following way .",
    "let us treat @xmath475 as essential but fixed parameter , introduce as new parameters @xmath514 and consider the function@xmath515   \\,,\\ \\ 0<\\widetilde { x}\\leq1,\\text { \\ \\ } \\widetilde{t}\\geq0,\\ ] ] that is connected to ( [ fb1 ] ) via@xmath516 for simulation of @xmath397 we need to solve the equation@xmath517.\\ ] ] for this we set @xmath518 and solve the normalized equation @xmath519 and then take@xmath520 note that @xmath521 we have plotted in figure  [ normal ] the normalized function @xmath522 for @xmath523"
  ],
  "abstract_text": [
    "<S> the doss - sussmann ( ds ) approach is used for uniform simulation of the cox - ingersoll - ross ( cir ) process . </S>",
    "<S> the ds formalism allows to express trajectories of the cir process through solutions of some ordinary differential equation ( ode ) depending on realizations of a wiener process involved . by simulating the first - passage times of the increments of the wiener process to the boundary of an interval and solving the ode , </S>",
    "<S> we uniformly approximate the trajectories of the cir process . in this respect special attention </S>",
    "<S> is payed to simulation of trajectories near zero . from a conceptual point of view the proposed method </S>",
    "<S> gives a better quality of approximation ( from a path - wise point of view ) than standard , or even exact simulation of the sde at some discrete time grid .    </S>",
    "<S> * ams 2000 subject classification . * </S>",
    "<S> primary 65c30 ; secondary 60h35 .    </S>",
    "<S> * keywords*. cox - ingersoll - ross process , doss - sussmann formalism , bessel functions , confluent hypergeometric equation . </S>"
  ]
}