{
  "article_text": [
    "bayesian networks are a class of _ graphical models _ , which allow an intuitive representation of the probabilistic structure of multivariate data using graphs @xcite .",
    "they are composed by two parts :    * a set of random variables @xmath0 describing the features of the data .",
    "the probability distribution of @xmath1 is called the _ global distribution _ of the data , while the ones associated with each @xmath2 are called _ local distributions_. * a _ directed acyclic graph _ ( dag ) , denoted @xmath3 .",
    "each node @xmath4 is associated with one variable @xmath5 , and they are often referred to interchangeably .",
    "the directed arcs @xmath6 that connect them represent direct stochastic dependencies ; so if there is no arc connecting two nodes , the corresponding variables are either marginally independent or conditionally independent given a subset of the remaining variables .    in other words ,",
    "each local distribution is associated with a single node @xmath5 and depends only on its parents ( i.e. the nodes @xmath7 in @xmath1 such that @xmath8 , usually denoted by @xmath9 ) .",
    "this property , which is known as the _ markov property _ of bayesian networks @xcite , specifies the form of the decomposition of the global distribution into the local ones : @xmath10 in principle there are many possible choices for both the global and the local distribution functions , depending on the nature of the data and the aims of the analysis .",
    "however , literature have focused mostly on two cases : the _ discrete case _",
    "@xcite , in which both the global and the local distributions are multinomial random variables , and the _ continuous case _",
    "@xcite , in which the global distribution is multivariate normal and the local distributions are univariate normal random variables . in the first case ,",
    "the parameters of interest are the _ conditional probabilities _ associated with each variable , usually represented as _ conditional probability tables _ ( cpts ) ; in the latter , the parameters of interest are the _ partial correlation coefficients _ between each variable and its parents .",
    "the task of fitting a bayesian network is called _ learning _ , a term borrowed from expert systems theory and artificial intelligence , and in general is implemented in two steps .",
    "the first step consists in finding the graph structure that encodes the conditional independencies present in the data .",
    "ideally it should coincide with the dependence structure of the global distribution , or it should at least identify a distribution as close as possible to the correct one in the probability space .",
    "this step is called _ network structure _ or simply _ structure learning _ @xcite , and is similar in approaches and terminology to model selection procedures for classical statistical models .",
    "several algorithms have been presented in literature for this problem , thanks to the application of many results from probability , information and optimisation theory . despite the ( sometimes confusing ) variety of theoretical backgrounds and terminology",
    "they can all be traced to only three approaches : _ constraint - based _ ( which are based on conditional independence tests ) , _ score - based _ ( which are based on goodness - of - fit scores ) and _ hybrid _ ( which combine the previous two approaches ) .",
    "the second step is called _ parameter learning _ and , as the name suggests , deals with the estimation of the parameters of the global distribution . assuming the graph structure is known from the previous step , this can be done efficiently by estimating the parameters of the local distributions .    in literature",
    "there are several studies on the performance of bayesian network structure learning algorithms ; one of the most extensive performed in recent years is presented in @xcite .",
    "the focus of these studies is almost always the heuristics the learning algorithms are based on , i.e. the maximisation algorithms used in score - based algorithms or the techniques for learning the dependence structure associated with each node in constraint - based algorithms .",
    "the influence of the other components of the overall learning strategy , such as the conditional independence tests ( and the associated type i error threshold ) or the network scores ( and the associated parameters , such as the equivalent sample size ) , is usually not investigated .",
    "however , limiting such studies to the performance of heuristics poses serious doubts on their conclusions , because the decisions made by the heuristics are based on the values of the statistical criteria they use to extract information from the data .",
    "therefore , it is important to choose a conditional independence test or a network score presenting a good behaviour for the data at hand and to tune it appropriately .    for this reason , in this paper we will investigate the behaviour of permutation conditional independence tests and tests based on shrinkage estimators for discrete data .",
    "these two classes of tests are usually not considered in literature , where the asymptotic @xmath11 tests based on pearson s @xmath12 @xcite and mutual information @xcite are the _ de facto _ standard . in particular",
    ", we will study the permutation pearson s @xmath12 test and the permutation mutual information test described in @xcite , and the shrinkage test based on the estimator for the mutual information presented in @xcite .",
    "we will now introduce the conditional independence tests whose performance will be considered in section [ sec : traditional ] .",
    "since we are limiting ourselves to discrete data , both the global and the local distributions are assumed to be multinomial , and the latter are represented as conditional probability tables .",
    "conditional independence tests and network scores for discrete data are functions of these conditional probability tables through the observed frequencies @xmath13 for the random variables @xmath14 and @xmath15 and all the configurations of the levels of the conditioning variables @xmath16 .",
    "two classic conditional independence tests used in the analysis of contingency and probability tables are :    * _ mutual information _ : an information - theoretic distance measure defined as @xmath17 it is proportional to the log - likelihood ratio test @xmath18 ( they differ by a @xmath19 factor , where @xmath20 is the sample size ) and is related to the deviance of the tested models . *",
    "_ pearson s @xmath21 _ : pearson s @xmath12 test for contingency tables , @xmath22    the asymptotic null distribution is @xmath11 with @xmath23 degrees of freedom in both cases . for a detailed analysis of their properties",
    "we refer the reader to @xcite and @xcite .",
    "the main limitation of these tests is the rate of convergence to their limiting distribution , which is particularly problematic when dealing with small samples and sparse contingency tables .",
    "this situation , which is often referred to as `` small @xmath20 , large @xmath24 '' , is very common in many settings in which bayesian networks are used ( such as gene expression and omics data ) .",
    "the mutual information and pearson s @xmath12 tests can also be performed by conditioning on a sufficient statistic and using the permutation distribution as the null distribution @xcite .",
    "the observed significance values are then computed with a _",
    "conditional monte carlo _",
    "( cmc ) simulation , as detailed in @xcite :    1 .   compute the value of the test statistic for the original data set , and denote it with @xmath25 ; 2 .",
    "perform the following steps for a suitable number @xmath26 of times , usually between @xmath27 and @xmath28 : 1 .",
    "randomly permute the observations presenting the same configuration of the conditioning variables @xmath16 ; this is typically done by applying the permutation algorithm from @xcite to the contingency tables associated with the configurations of @xmath16 ; 2 .",
    "compute the test statistic on the resulting data , and denote it with @xmath29 , @xmath30 ; 3 .",
    "compute the significance value of @xmath25 as @xmath31    both the permutation algorithm by @xcite and the conditional independence tests considered in this paper have the marginal totals @xmath32 and @xmath33 as sufficient statistics , so they can be computed efficiently .",
    "the main advantage of permutations tests is that they do not require a large sample size or particular distributional assumptions to perform well , because they operate conditioning on the available data @xcite .",
    "therefore , they perform better than the parametric tests usually found in literature , because they are not limited by the rate of convergence to the respective asymptotic distributions .",
    "however , the computer time required by the generation of the permutations of the data and by the repeated evaluation of the test statistic have prevented their widespread use in many settings in which high - dimensional problems are the norm .      in high - dimensional , multivariate problems ,",
    "the maximum likelihood estimator is known to be inefficient and displays a considerable instability for most reasonable , finite sample sizes .",
    "this phenomenon , which is known as the `` curse of dimensionality '' , is caused by the exponential increase in the number of parameters as the number of variables increase .",
    "these issues can be explained as a consequence of the inadmissibility of the maximum likelihood estimator for the mean of multivariate distributions discovered by @xcite and investigated by @xcite .",
    "a solution is provided in the form of a _ regularised estimator _ , which includes some bias in order to increase the overall performance of the estimator .",
    "since the natural parameters of the test statistics we are considering are the probabilities @xmath34 associated with the observed frequencies @xmath35 , we will denote such an estimator as @xmath36 and the maximum likelihood estimator as @xmath37 .",
    "the regularised estimator is then defined as a linear combination of the maximum likelihood estimator and a _ target distribution _ with probabilities @xmath38 , which is usually chosen to be uniform ( i.e. @xmath39 ) : @xmath40.\\end{aligned}\\ ] ] such an estimator is called a _ shrinkage estimator _ , because @xmath41 is shrunk towards @xmath42 in the parameter space ; @xmath43 is likewise called the _",
    "shrinkage coefficient_.    a closed - form estimator for @xmath43 has been derived by @xcite as the value that minimises the mean squared error of @xmath44 .",
    "@xcite derived its expression for multinomial probabilities , with the aim of defining an improved entropy estimator @xcite ; it has the form @xmath45 the application of this result to the mutual information test leads to the definition of the corresponding _ shrinkage mutual information test _ , which is based on the shrinkage estimator @xmath44 instead of the usual maximum likelihood estimator @xmath41 .",
    "it has the form @xmath46 the observed significance value can still be computed using the asymptotic @xmath11 distribution used for the classic mutual information test , for two reasons .",
    "first , @xcite proved that @xmath47 converges to zero as the sample size diverges , which means that the shrinkage test @xmath48 and the classic parametric test @xmath49 have the same asymptotic behaviour .",
    "furthermore , the shrinkage mutual information test is still a log - likelihood ratio test .",
    "the only difference is in the number of the parameters , as both the null and the observed distributions gain an additional parameter , @xmath43 .",
    "therefore , according to @xcite the asymptotic distribution of the shrinkage test is again @xmath11 with @xmath23 degrees of freedom .",
    "we will now investigate the behaviour of the permutation conditional independence tests and shrinkage tests introduced in the previous section , using the parametric tests as a reference .",
    "five performance indicators will be taken into consideration :    * the posterior density of the network for the data it was learned from , as a measure of goodness of fit .",
    "it is known as the _ bayesian dirichlet equivalent _ score ( bde ) from @xcite and has a single parameter , the _ equivalent sample size _ , which can be thought of as the size of an imaginary sample supporting the prior distribution .",
    "the equivalent sample size will be set to @xmath50 as suggested in @xcite ; * the bic score @xcite of the network for the data it was learned from , again as a measure of goodness of fit ; * the posterior density of the network for a new data set , as a measure of how well the network generalises to new data ; * the bic score of the network for a new data set , again as a measure of how well the network generalises to new data ; * the structural hamming distance ( shd ) between the learned and the true structure of the network , as a measure of the quality of the learned dependence structure @xcite .",
    "these indicators will be estimated for each test , using the bnlearn r package @xcite as follows :",
    "1 .   generate a sample from the true probability distribution of the alarm network from @xcite .",
    "alarm contains @xmath51 nodes and @xmath52 arcs , for a total of @xmath53 parameters , and is frequently used as a benchmark in the literature of bayesian networks @xcite ; 2 .",
    "learn a network structure with the ( mmhc ) hybrid algorithm @xcite using one of the conditional independence tests under investigation and the bde score .",
    "this learning strategy has been shown to be one of the most effective up to date ; it combines the max - min parents and children ( mmpc ) constraint - based algorithm with a score - based hill climbing search .",
    "two thresholds are considered for the type i error of the tests : @xmath54 and @xmath55 .",
    "since results are very similar , they are reported only for @xmath54 for brevity ; 3 .   learn a second network structure from the same data with the asymptotic , parametric test based either on pearson s @xmath12 or on the maximum likelihood estimator for the mutual information , depending on which test was used in the previous step ; 4 .   repeat the previous two steps using the bic score instead of bde ; 5 .",
    "compute the relevant performance indicators for each pair of network structures , and the differences are standardised to express the relative difference over the values obtained with the asymptotic tests .",
    "in particular , bde will be only considered for networks learned in step 2 and bic for networks learned in step 4 .",
    "these steps will be repeated @xmath56 times for each sample size .",
    "the data set needed to assess how well the network generalises to new data is generated again from the true probability structure of the alarm network and contains @xmath57 observations .",
    "the parameters of the network , which are the elements of the conditional probability tables associated with the nodes of the networks , are estimated using the corresponding empirical frequencies .",
    "nonparametric conditional independence tests , and permutation tests in particular , provide a feasible alternative to the corresponding parametric tests in a wide range of situations .",
    "( on the right ) tests .",
    "the black dot in each box - plot represents the median.,scaledwidth=90.0% ]    the effects of the properties of the permutation pearson s @xmath12 and the permutation mutual information tests on bayesian network structure learning are shown in figure [ fig : permtest ] and figure [ fig : permshd ] .",
    "first , we can clearly see from the box - plots in figure [ fig : permtest ] that the use of permutation tests results in network structures with higher scores for all the considered sample sizes ( @xmath58 , @xmath27 , @xmath59 and @xmath28 ) .",
    "this is also true when considering the new data set , meaning that the network structures learned with these tests are better for predicting the behaviour of new samples .",
    "as expected , improvements in the bic and bde scores are particularly significant for low sample sizes ; the probability structure of the alarm network has @xmath53 parameters , which means that the ratios between the number of observations and the number of parameters are @xmath60 , @xmath61 , @xmath62 and @xmath63 respectively .",
    "it is also interesting to note that , even though the performance of parametric tests improves with the sample size , both permutation tests appear to improve at a faster rate .",
    "in fact , in all plots in figure [ fig : permtest ] the relative improvement for samples of size @xmath28 is greater than the corresponding improvement for samples of size @xmath64 , regardless of the score we are considering or the data set it is computed from .",
    "( on the right ) tests .",
    "the black dot in each box - plot represents the median.,scaledwidth=90.0% ]    on the other hand , the network structures learned with permutation tests considered in this section are often not as close to the true network structure as the ones learned with the corresponding parametric tests .",
    "this is can be clearly seen from the box - plots in figure [ fig : permshd ] , which show that in the majority of simulations the relative difference between the shd values is negative ( i.e. the shd associated with the parametric test is smaller than the shd associated with the permutation test ) .",
    "permutation tests outperform parametric tests only for samples of size @xmath28 .",
    "the comparatively poor performance of permutation tests in terms of shd can be attributed to the conditioning on the observed sample that characterises them .",
    "most of the samples considered in this analysis are too small to provide an adequate representation of the true probability structure of the alarm network , as evidenced by the ratios between their sample sizes and the number of parameters .",
    "therefore , the network structures learned with permutation tests from these samples are able to capture only part of the true dependence structure .",
    "the arcs that are most likely to be missed , however , are those that represent the weakest dependence relationships ; otherwise the networks would not be able to fit new data so well .    in conclusion",
    ", permutation tests result in better network structures than the corresponding parametric tests , both in terms of goodness of fit and in how well the networks are able to generalise to new data .",
    "however , if the focus of the analysis is the structure of the network itself ( such as when the bayesian network is considered as a causal model ) parametric tests may be preferable for small samples .",
    "the shrinkage mutual information test has a completely different behaviour than the permutation tests covered above .",
    "as expected from a test based on a regularised estimator , the networks learned using shrinkage tests do not fit the data as well as the networks learned with the corresponding maximum likelihood tests .",
    "this can be clearly seen from the box - plots in figure [ fig : shtest ] .",
    "the relative differences in the bic and bde scores are almost never positive for either the data the networks have been learned from or the new data , in particular for samples of size @xmath50 and @xmath65 .",
    "such small samples are most likely to result in sparse contingency tables , and therefore in high values of the shrinkage coefficient , as soon as a few conditioning variables are included in the tests .",
    "larger samples are less affected by the regularisation of the shrinkage estimator , because the shrinkage coefficient converges to zero as the number of observations diverges @xcite .",
    "this means that for larger samples ( i.e. @xmath66 , @xmath67 and @xmath58 ) the behaviour of the shrinkage mutual information test approaches the one of the classic mutual information test , as can be seen from the increasingly small difference between the two in terms of bic and bde scores .",
    "an important side effect of the regularisation performed by the shrinkage estimator is the reduction of the structural distance from the true network structure for small samples .",
    "we can see from figure [ fig : shshd ] that the shrinkage test outperforms the test based on the maximum likelihood estimator ; there is a systematic improvement for sample sizes @xmath50 , @xmath65 and @xmath56 ( i.e. shd is smaller for the shrinkage test ) . as the sample size increases , the behaviour of the shrinkage test approaches again the one of the corresponding maximum likelihood test .",
    "these simulations confirm the results produced with shrinkage tests for many `` small @xmath20 , large @xmath24 '' problems , such as those studied in @xcite and @xcite , which have led to a widespread use of shrinkage tests in biology and genetics .",
    "in this paper we investigated how the use of permutation tests instead of parametric ones affects the performance of bayesian network structure learning from discrete data , while also covering shrinkage tests .",
    "permutation tests result in better network structures than the corresponding parametric tests , both in terms of goodness of fit and in how well the networks are able to generalise to new data .",
    "shrinkage tests , on the other hand , outperform both parametric and permutation tests in the quality of the network structure itself , which is closer to the true dependence structure of the data ."
  ],
  "abstract_text": [
    "<S> in literature there are several studies on the performance of bayesian network structure learning algorithms . </S>",
    "<S> the focus of these studies is almost always the heuristics the learning algorithms are based on , i.e. the maximisation algorithms ( in score - based algorithms ) or the techniques for learning the dependencies of each variable ( in constraint - based algorithms ) . in this paper </S>",
    "<S> we investigate how the use of permutation tests instead of parametric ones affects the performance of bayesian network structure learning from discrete data . </S>",
    "<S> shrinkage tests are also covered to provide a broad overview of the techniques developed in current literature .    </S>",
    "<S> * keywords : * bayesian networks , conditional independence tests , permutation tests , shrinkage tests . </S>"
  ]
}