{
  "article_text": [
    "let us consider a regression model in the continuous time with the levy noise @xmath0 where @xmath1 is an unknown @xmath2 function , @xmath3 is some unobserved noise and @xmath4 is the noise intensity .",
    "the problem is to estimate the function @xmath5 on the observations @xmath6 when @xmath7 . in this paper",
    "we consider the estimation problem in the adaptive setting , i.e. when the regularity of @xmath5 is unknown .",
    "note that if @xmath3 is the brownian motion , then we obtain the well known `` signal+white noise '' model ( see , for example , @xcite , @xcite , @xcite and etc ) .",
    "it should be noted also that the model is very popular in the statistical radio - physics .",
    "this is the estimation problem of the signal @xmath5 , observed under the white noise , when the signal noise ratio goes to infinity . in this paper",
    "we assume that the noise @xmath3 is the levy process with unknown distribution @xmath8 on the skorokhod space @xmath9 $ ] . we know only that this distribution beings to some distribution family @xmath10 specified below .    by making use of the robust estimation approach developed for nonparametric problems in @xcite we set the robust risks as @xmath11 where @xmath12 is an estimate ,",
    "i.e. any function of @xmath6 and @xmath13    the goal of this paper is to develop the sharp model selection method for estimating the unknown signal @xmath5 .",
    "the interest to such statistical procedures can be explained by the fact that they provide adaptive solutions for the nonparametric estimation through the sharp non - asymptotic oracle inequalities which give non asymptotic upper bound for the quadratic risk including the minimal risk over chosen estimate family with some coefficient closed to one ( see , for example , @xcite for discrete time and @xcite for the continuous time ) .",
    "the origin of the model selection method goes back to early seventies with the pioneering papers by akaike @xcite and mallows @xcite who suggested to use penalizing in a log - likelihood type criterion .",
    "barron , birg , massart @xcite , massart @xcite and kneip @xcite developed a non - asymptotic model selection method which enables one to derive non - asymptotic oracle inequalities for the nonparametric regression models with gaussian disturbances .",
    "unfortunately , these methods can not be applied to the non gaussian regression models , since the estimators for the fourier coefficients in such cases are not independent random variables . by these reasons to estimate the function in non - gaussian regression models we use the model selection method developed by @xcite for nongaussian heteroscedastic regression models in discrete time .    in constructing the sharp model selection procedures , in this paper",
    ", we will use the approach close to that of the papers @xcite , @xcite , @xcite , @xcite developed for the estimation of a @xmath14 - periodic function in the continuous time on the large time interval , i.e. @xmath15 note , that for any @xmath16 setting @xmath17 , we can represent this model as a model with small parameter of form @xmath18 where @xmath19 and @xmath20 .",
    "main difference this model from the original one is that the jumps are small , i.e. @xmath21 but we have not such property in the model .",
    "therefore , unfortunately , we can not use directly the method developed for the estimation problem on the large time interval to the model .",
    "so , the main goal of this paper is to develop a new sharp model selection method for the problem estimation function @xmath5 as @xmath7 .",
    "as an application of the sharp model selection method in this paper we consider the signals number detection problem for the model . in many areas of science and technology the problems",
    "arise how to select the number of freedom degrees for a statistical model that most adequately describes phenomenons under studies @xcite",
    ". an important class of such problems is the detection problems of the signal number with unknown parameters in the noise .",
    "for example , in the signal multi - path information transmission there is a detection problem for the number of rays in a multipath channel .",
    "this problem is often reduced to the detection of the signals number . as a result ,",
    "effective detection signals number algorithms can significantly improve the noise immunity in the data transmission over a multipath channel @xcite . in all these paper the signals number detection problems are considered only for observation with white nose . in this paper",
    "we consider this problem for non gaussian noise with jumps given by .",
    "the rest of the paper is organized as follows . in section [ sec : tr ] we transform the observation model to delete the large jumps . in section [ sec : mo ] we construct the sharp model selection procedure . in section",
    "[ sec : mrs ] we give the main results on non - asymptotic estimation . in section [ sec : adpest ] we give the results on asymptotic robust efficiency . in sections [ sec :",
    "lobn ] and [ sec : upbn ] we study the lower and upper bounds for the asymptotic risks respecttively . in section [ sec : numsgn ] we study the signals number detection problem through the model selection method . in section [ sec : siml ] we give the simulations results . section [ sec : pr ] contains the proofs of all main results . in appendix",
    "we bring all proofs for auxiliary results .",
    "in this paper the noise process @xmath3 is defined by the following levy process @xmath22 here , @xmath23 and @xmath24 are some constants , @xmath25 is a standard brownian motion , @xmath26 is the jump measure with the deterministic compensator @xmath27 , @xmath28 is some positive measure on @xmath29 , ( see , for example @xcite for details ) .",
    "@xmath30 note that @xmath31 may be equal to @xmath32 . in the sequel",
    "we will denote by @xmath8 the distribution of the process @xmath3 in the skorokhod space @xmath33 $ ] and by @xmath34 we denote all these distributions for which the parameters @xmath23 and @xmath24 satisfy the conditions @xmath35 where the bounds @xmath36 and @xmath37 are such that for any @xmath38 @xmath39    first of all , we need to eliminate the large jumps in the observations , i.e. we transform this model as @xmath40 the parameter @xmath41 will be chosen later .",
    "so , we obtain that @xmath42 where @xmath43 the functions @xmath44 and @xmath45 with the truncated threshold @xmath46 .",
    "let @xmath47 be an orthonormal basis in @xmath48 $ ] with @xmath49 .",
    "we assume that this basis is uniformly bounded , i.e. for some constant @xmath50 , which may be depend on @xmath4 , @xmath51 where @xmath52 $ ] and @xmath53 $ ] denotes integer part of @xmath54 .",
    "for example , we can take the trigonometric basis defined as @xmath55 and for @xmath56 @xmath57 \\sin(\\omega_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}}x)\\quad\\mbox{for odd}\\quad j\\ , , \\end{array } \\right.\\ ] ] where the frequency @xmath58 $ ] .",
    "moreover , note that for any @xmath59 \\to\\bbr$ ] function @xmath60 from @xmath48 $ ] , the integrals @xmath61 are well defined with @xmath62 , @xmath63 , @xmath64 where @xmath65 , @xmath66 and @xmath67 . in the sequel",
    "we denote by @xmath68 .    to estimate the function @xmath5 we use the following fourier serie @xmath69 where @xmath70",
    "these coefficients can be estimated by the following way .",
    "the first we estimate as @xmath71 and for @xmath56 @xmath72 taking into account here that for such @xmath73 the integral @xmath74 we obtain from that these fourier coefficients can be represented as @xmath75 setting @xmath76 we obtain that for any @xmath77 @xmath78    now , according to the selection model approach developed in @xcite - @xcite we need to define for any @xmath79 the following functions    @xmath80    where @xmath81 and @xmath82 .",
    "[ pr.sec : mapr.0 ] the following upper bound holds .",
    "@xmath83^{n}}{u\\in[0,1]^{n}}{\\lower.25ex\\hbox{$\\scriptstyleu\\in[0,1]^{n}$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleu\\in[0,1]^{n}$}}}}\\left\\vert b_{{\\mathchoice{1,\\varepsilon}{1,\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle1,\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle1,\\varepsilon$}}}}(u ) \\right\\vert \\le \\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$ } } } } \\,.\\ ] ]    taking into account that @xmath84 and @xmath85 for @xmath56 we immediately the upper bound .    before the formulation we recall the novikov inequalities , @xcite , also referred to as the bichteler ",
    "jacod inequalities , see @xcite , providing bounds moments of supremum of purely discontinuous local martingales for @xmath86    @xmath87    where @xmath88 is some positive constant .",
    "now , for any @xmath89 we set @xmath90    [ pr.sec : mapr.1 ] for any fixed truncated model parameter @xmath91 and for any vector @xmath92 with @xmath93 @xmath94 where @xmath95 .",
    "we estimate the function @xmath96 for @xmath97 $ ] by the weighted least squares estimator @xmath98 where @xmath99 $ ] , the weights @xmath100 belong to some finite set @xmath101 from @xmath59^n$ ] , @xmath102 is defined in and @xmath103 in .",
    "now we set @xmath104 where @xmath105 is the cardinal number of @xmath101 . in the sequel",
    "we assume that @xmath106 .",
    "now we chose the truncating parameter @xmath107 as    @xmath108    to choose a weight sequence @xmath109 in the set @xmath101 we use the empirical quadratic risk , defined as @xmath110 which in our case is equal to @xmath111 since the fourier coefficients @xmath112 are unknown , we replace the terms @xmath113 by @xmath114 where @xmath115 is a some estimate for the variance parameter @xmath116 from .",
    "if it is known we set @xmath117 if non this estimator will be prescribed later .    finally , to choose the weights we will minimize the following cost function @xmath118 where @xmath119 is some threshold which will be specified later and the penalty term @xmath120 note that , if the @xmath121 is known then the penalty is defined as @xmath122    here @xmath115 is a some estimator for the variance from the condition @xmath123 .",
    "we define the model selection procedure as @xmath124 where @xmath125 we recall that the set @xmath101 is finite so @xmath126 exists . in the case when @xmath126 is not unique we take one of them .",
    "now , we specify the weight coefficients @xmath127 . consider a numerical grid of the form @xmath128 where @xmath129 \\,.\\ ] ]    we assume that both the parameters @xmath130 and @xmath131 are functions of @xmath132 , i.e. @xmath133 and @xmath134 , such that @xmath135 & \\lim_{{\\mathchoice{{\\varepsilon}\\to 0}{{\\varepsilon}\\to 0}{\\lower.25ex\\hbox{$\\scriptstyle{\\varepsilon}\\to 0 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle{\\varepsilon}\\to 0$}}}}\\varsigma^{*}_{{\\mathchoice{{\\varepsilon}}{{\\varepsilon}}{\\lower.25ex\\hbox{$\\scriptstyle{\\varepsilon}$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle{\\varepsilon}$}}}}\\varpi_{{\\mathchoice{{\\varepsilon}}{{\\varepsilon}}{\\lower.25ex\\hbox{$\\scriptstyle{\\varepsilon}$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle{\\varepsilon}$}}}}=0 \\quad\\mbox{and}\\quad \\lim_{{\\mathchoice{{\\varepsilon}\\to 0}{{\\varepsilon}\\to 0}{\\lower.25ex\\hbox{$\\scriptstyle{\\varepsilon}\\to 0 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle{\\varepsilon}\\to 0$}}}}\\,{\\varepsilon}^{-\\delta}\\varpi_{{\\mathchoice{{\\varepsilon}}{{\\varepsilon}}{\\lower.25ex\\hbox{$\\scriptstyle{\\varepsilon}$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle{\\varepsilon}$}}}}\\,=+\\infty \\end{array } \\right.\\ ] ] for any @xmath119 .",
    "one can take , for example , for @xmath136 @xmath137 where @xmath138 is some fixed constant and the threshold @xmath37 is introduced in .",
    "for each @xmath139 , we introduce the weight sequence @xmath140 where @xmath141 , @xmath142 here @xmath143 $ ] , @xmath144 now we define the set @xmath101 as @xmath145    note , that these weight coefficients are used in @xcite for continuous time regression models to show the asymptotic efficiency .    in the sequel",
    "we need to estimate the variance parameter @xmath116 from . to this end we set for any @xmath146 @xmath147 + 1}{j=[1/\\varepsilon]+1}{\\lower.25ex\\hbox{$\\scriptstylej=[1/\\varepsilon]+1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej=[1/\\varepsilon]+1$}}}}\\,{\\widehat}{t}^2_{{\\mathchoice{j,\\varepsilon}{j,\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstylej,\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej,\\varepsilon$}}}}\\ , , \\quad n=1/\\varepsilon^{2}\\,,\\ ] ] where @xmath148 are the estimators for the fourrier coefficients with respect to the trigonometric basis , i.e. @xmath149    [ re.sec:mo.1 ]",
    "note that the similar sharp oracle inequalities was obtained before in the papers @xcite and @xcite for the nonparametric regression models in the discrete and continuous times respectively . in this paper",
    "we obtain these inequalities for the model selection procedures based on any arbitrary orthogonal basic function .",
    "we use the trigonometric function only to estimate the noise intensity @xmath121 .",
    "first we set the following constant which will be used to describe the rest term in the oracle inequalities .",
    "we set    @xmath150    where @xmath151    we start with the sharp oracle inequalities .",
    "[ th.sec:mrs.1 ] assume that for the model the condition holds .",
    "then for any @xmath152 , the estimator of @xmath5 given in satisfies the following oracle inequality @xmath153    [ co.sec:oi.1 ] assume that for the model the condition holds .",
    "if the variance parameter @xmath121 is known , then for any @xmath152 , the estimator of @xmath5 given in with the truncate parameter @xmath154 satisfies the following oracle inequality @xmath155    we need to study the estimate .",
    "[ pr.sec : mapr.3 ] assume that in the model the unknown function @xmath1 is continuously differentiable .",
    "then , for any @xmath146 @xmath156 where @xmath157 .    the proof of this proposition is given in section [ sec : pr ] .",
    "it is clear that in the case when @xmath158 were obtain that    @xmath159    now using this proposition we can obtain the following inequality .",
    "[ th.sec:mrs.20 ] assume that for the model the condition holds and the unknown function @xmath1 is continuously differentiable .",
    "then the procedure with @xmath158 , for any @xmath152 , satisfies the following oracle inequality @xmath160 \\label{sec : mrs.1 + }   & + \\varepsilon^2   \\frac{\\psi_{{\\mathchoice{q,\\varepsilon}{q,\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyleq,\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq,\\varepsilon$}}}}+(\\vert\\dot{s}\\vert+1)^{2 } g_{{\\mathchoice{1,q}{1,q}{\\lower.25ex\\hbox{$\\scriptstyle1,q$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle1,q$}}}}+g_{{\\mathchoice{2,q}{2,q}{\\lower.25ex\\hbox{$\\scriptstyle2,q$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2,q$}}}}}{\\delta}\\,,\\end{aligned}\\ ] ] where @xmath161    now we study the robust risks defined in for the procedure .    moreover , we assume also that the upper bound for the basis functions in may be dependent on @xmath162 , i.e. @xmath163 , such that for any @xmath164 @xmath165    [ th.sec:mrs.2 ] assume that for the model the condition holds and the unknown function @xmath1 is continuously differentiable",
    ". then robust risks of the procedure with @xmath158 , for any @xmath152 , satisfy the following oracle inequality @xmath166 where the term @xmath167 is such that under the conditions and for any @xmath168 and @xmath38 @xmath169",
    "now we study the asymptotically efficience properties for the procedure , with respect to the robust risks defined by the distribution family  . to this end",
    "we assume that the unknown function belongs to the following ellipsoid in @xmath170 @xmath171\\,:\\ , \\sum_{{\\mathchoice{j=1}{j=1}{\\lower.25ex\\hbox{$\\scriptstylej=1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej=1$}}}}^{\\infty}\\,a_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}}\\,\\theta^2_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}}\\,\\le \\r\\}\\ ] ] where @xmath172\\right)^{2i}$ ] .",
    "it is easy to see that in the case when the functions @xmath173 are trigonometric , then this set coincides with the sobolev ball @xmath174 \\,:\\,\\sum_{{\\mathchoice{j=0}{j=0}{\\lower.25ex\\hbox{$\\scriptstylej=0 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej=0$}}}}^k\\,\\|f^{(j)}\\|^2\\le \\r\\}\\,,\\ ] ] where @xmath175 and @xmath176 are some parameters , @xmath177 $ ] is the set of @xmath178 times continuously differentiable functions @xmath179\\to\\bbr$ ] such that @xmath180 for all @xmath181 . similarly to @xcite we will show here that the asymptotic sharp lower bound for the robust risk is given by @xmath182    note that this is the well - known pinsker constant obtained for the nonadaptive filtration problem in `` signal + small white noise '' model ( see , for example , @xcite ) .    let @xmath183 be the set of all estimators @xmath184 measurable with respect to the sigma - algebra @xmath185 generated by the process .",
    "[ th.sec:ef.1 ] for the distribution family  .",
    "the robust risks admit the following lower bound @xmath186 where @xmath187 .",
    "we set the parameter @xmath188 in as function of @xmath189 , i.e. @xmath190 is such that @xmath191 for any @xmath38 .",
    "for example , we can take @xmath192 .",
    "[ th.sec:ef.2 ] assume that the conditions hold .",
    "then model selection procedure admits the following asymptotic upper bound @xmath193    theorem  [ th.sec:ef.1 ] and theorem  [ th.sec:ef.2 ] imply the following result    [ co.sec:mr.1 ] under the conditions theorem  [ th.sec:ef.2 ] @xmath194    [ re.sec.mrs.1 ] it is well known that the optimal ( minimax ) risk convergence rate for the sobolev ball @xmath195 is @xmath196 ( see , for example , @xcite ) .",
    "we see here that the efficient robust rate is @xmath197 , i.e. if the distribution upper bound @xmath198 as @xmath199 we obtain the more rapid rate with respect to @xmath196 , and if @xmath200 as @xmath7 we obtain the more slow rate . in the case",
    "when @xmath37 is constant the robuste rate is the same as the classical non robuste convergence rate .",
    "firstly , note , that for any fixed @xmath201 @xmath202 now for any fixed @xmath203 we set @xmath204 \\quad\\mbox{and}\\quad \\check{\\r}=(1-\\check{\\gamma})\\r\\,.\\ ] ] using this definition we introduce the parametric family @xmath205 as @xmath206    to define the bayesian risk we choose a prior distribution on @xmath207 as @xmath208 where @xmath209 are i.i.d .",
    "gaussian @xmath210 random variables and the coefficients @xmath211 denoting by @xmath212 the distribution of the random variables @xmath213 on @xmath207 we introduce the bayes risk as @xmath214    furthermore , for any function @xmath60 , we denote by @xmath215 its projection in @xmath48 $ ] onto @xmath216 , i.e. @xmath217 since @xmath218 is a convex and closed set in @xmath48 $ ] , this project exists and unique for any function @xmath219 $ ] and , moreover , @xmath220 so , setting @xmath221 , we obtain that @xmath222 taking into account now that @xmath223 we obtain @xmath224 and @xmath225 therefore , in view of @xmath226 as to the last term in this inequality , in appendix we show that for any @xmath227 @xmath228    now it is easy to see that @xmath229 where @xmath230 so , in view of lemma  [ le.sec:app.3 ] and reminding that @xmath231 we obtain @xmath232 & = \\frac{1}{v_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}}}\\ , \\sum_{j=1}^{d}\\,\\frac{s^{*}_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$ } } } } } { s^{*}_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}}+\\,1 } = \\frac{1}{v_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}}}\\ , \\sum_{j=1}^{d}\\ , \\left ( 1 - \\frac{j^k}{d^k_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$ } } } } } \\right ) \\,.\\end{aligned}\\ ] ] therefore , using now the definition , the inequality and the limit , we obtain that @xmath233 taking here limit as @xmath234 implies theorem  [ th.sec:ef.1 ] .",
    "first we suppose that the parameters @xmath235 , @xmath175 in and @xmath37 in are known .",
    "let the family of admissible weighted least squares estimates @xmath236 given by . consider the pair @xmath237\\ ] ] where @xmath238 and @xmath239 satisfy the conditions in .",
    "denote the corresponding setimate as @xmath240 note that for sufficiently small @xmath189 the pair @xmath241 belongs to the set .",
    "[ th.sec:up.1 ] the estimator @xmath242 admets the following asymptotic upper bound @xmath243    * proof . * substituting and taking into account the definition one gets @xmath244 where @xmath245 .",
    "note now that for any @xmath246 the expectation @xmath247 and , in view of the upper bound , @xmath248 therefore , @xmath249 where @xmath250 .",
    "setting @xmath251 we obtain that for each @xmath252 @xmath253 one can check directly here that @xmath254 where the coefficient @xmath255 is given in .",
    "moreover , due to the condition @xmath256 therefore , @xmath257 to estimate the last term in the right hand of , we set @xmath258 it is easy to check that @xmath259 therefore , taking into account that by the definition of the pinsker constant in @xmath260 , we arrive at the inequality @xmath261 hence theorem  [ th.sec:up.1 ] .      combining theorem  [ th.sec:up.1 ] and theorem  [ th.sec:mrs.2 ] yields theorem  [ th.sec:ef.2 ] .",
    "in this section we apply the model selection procedure the following problem from the statistical signals theory .",
    "assume that the observed through some noise unknown signal in the model has the following form @xmath262 where @xmath173 are orthonormal known basis functions in @xmath263 , but the signals number @xmath264 and the coefficients @xmath265 are unknown .",
    "the problem consists to estimation of @xmath264 on the observation . in the statistical radio - physics",
    "this mens that we need to detect the number of received signals @xmath173 in multipath connection channels . in this case",
    "the coefficients @xmath265 are the signal amplitudes .    for this problem we use the lse family @xmath266 defined as @xmath267 this estimate can be obtained from with the weights @xmath268 .",
    "the number of estimators @xmath269 is a some function of @xmath189 , i.e. @xmath270 , such that @xmath271 for any @xmath38 . as a risk for the signals number",
    "we use @xmath272 where the risk @xmath273 is defined in and @xmath274 is some integer number ( maybe random ) from the set @xmath275 . in this case",
    "the cost function has the following form .",
    "@xmath276 so , for this problem the lse model selection procedure is defined as @xmath277    note that theorem [ th.sec:mrs.2 ] implies that the robust risks of the procedure with @xmath158 , for any @xmath152 , satisfy the following oracle inequality @xmath278 where the last term satisfies the property .",
    "in this section we report the results of a monte carlo experiment to assess the performance of the proposed model selection procedure .",
    "in we chose @xmath279 with @xmath280 , @xmath281j$ ] .",
    "we simulate the model @xmath282    the frequency of observations per period equals @xmath283 .",
    "we use the weight sequence as proposed in galtchouk and pergamenshchikov ( 2009 ) for a discrete time model : @xmath284 and @xmath285 $ ] .",
    "we calculated the empirical quadratic risk defined as    @xmath286 and the relative quadratic risk @xmath287 the expectations was taken as an average over @xmath288 replications , i.e. @xmath289    we used the cost function with @xmath290    : empirical risks    [ cols=\"<,^,>\",options=\"header \" , ]     [ re.sec:siml.1 ] it should be noted that the lse procedure is more appropriate than shrinkage method for such number detection problem .",
    "first note that @xmath291 where @xmath292 . it should be noted that @xmath293    to study the last term in the right hand side of the inequality we set for any function @xmath60 from @xmath48 $ ] @xmath294 note that that for @xmath56 we random variables @xmath295 .",
    "so , @xmath296 by the ito formula we can write that for any function @xmath60 from @xmath48 $ ] @xmath297 where @xmath298 .",
    "so , taking into account that @xmath299 we obtain that @xmath300 so , setting @xmath301 we obtain that @xmath302 so , we obtain that @xmath303 where @xmath304 .",
    "moreover , taking into account that for any @xmath60 , @xmath305 from @xmath48 $ ] @xmath306 we get @xmath307 & = \\check{\\varkappa}_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}\\ , \\sum^{n}_{{\\mathchoice{i , j=2}{i , j=2}{\\lower.25ex\\hbox{$\\scriptstylei , j=2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylei , j=2$}}}}u_{{\\mathchoice{i}{i}{\\lower.25ex\\hbox{$\\scriptstylei$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylei$}}}}\\,u_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}}\\,\\left(\\int^{1}_{{\\mathchoice{0}{0}{\\lower.25ex\\hbox{$\\scriptstyle0 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle0$}}}}\\,\\phi_{{\\mathchoice{i}{i}{\\lower.25ex\\hbox{$\\scriptstylei$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylei$}}}}(t)\\phi_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}}(t)\\ , \\,\\d t\\right)^{2 } = \\check{\\varkappa}_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}\\,.\\end{aligned}\\ ] ] thus , @xmath308 now , to estimate the second term in the inequality note that in view of the inequality for any bounded function @xmath60 and any @xmath309 @xmath310 & \\le 24\\varrho^{4}_{{\\mathchoice{1}{1}{\\lower.25ex\\hbox{$\\scriptstyle1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle1$}}}}\\int^{1}_{{\\mathchoice{0}{0}{\\lower.25ex\\hbox{$\\scriptstyle0 $ } }",
    "{ \\lower0.25ex\\hbox{$\\scriptscriptstyle0$}}}}f^{2}(t)\\d t + c^{*}_{{\\mathchoice{4}{4}{\\lower.25ex\\hbox{$\\scriptstyle4 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle4$}}}}\\left ( \\left(\\pi(h^{2}_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}})\\,\\int^{1}_{{\\mathchoice{0}{0}{\\lower.25ex\\hbox{$\\scriptstyle0 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle0$}}}}f^{2}(t)\\d t\\right)^{2 } + \\pi(h^{4}_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}})\\,\\int^{1}_{{\\mathchoice{0}{0}{\\lower.25ex\\hbox{$\\scriptstyle0 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle0$}}}}f^{4}(t)\\d t   \\right)\\,,\\end{aligned}\\ ] ] i.e. @xmath311 now it is easy to see that through the holder inequality the term @xmath312 can be estimated as @xmath313 from here and the inequality it follows that @xmath314 and , therefore , @xmath315 this implies that @xmath316 thus , the ito formula implies @xmath317 in the same way we calculate @xmath318 & = \\varrho^{2}_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2$}}}}\\pi(h^{4}_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}})\\,\\int^{1}_{{\\mathchoice{0}{0}{\\lower.25ex\\hbox{$\\scriptstyle0 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle0$}}}}\\,\\psi^{2}_{{\\mathchoice{t}{t}{\\lower.25ex\\hbox{$\\scriptstylet$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylet$}}}}\\d t \\le \\pi(x^{2})(a/\\varepsilon)^{2}\\,\\left(\\phi^{*}\\right)^{4}\\,\\#(u)\\,.\\end{aligned}\\ ] ]    so , we obtain that @xmath319 similarly we obtain that @xmath320 this implies the upper bound .      first note , that we can rewrite the empirical squared error in as follows @xmath321 where @xmath322 .",
    "now using the definition of @xmath323 in we obtain that @xmath324 where @xmath325 and @xmath326 . setting @xmath327 we can rewrite as @xmath328 where @xmath329 , the exact penalization is defined in and the functions @xmath330 and @xmath331 are defined in .",
    "it should be noted that for the truncates parameter the bound implies @xmath332 where @xmath333 .",
    "let @xmath334 be a fixed sequence in @xmath101 and @xmath335 be as in .",
    "substituting @xmath336 and @xmath335 in the equation , we obtain @xmath337 & + 2\\varepsilon^2 b_{{\\mathchoice{1,\\varepsilon}{1,\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle1,\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle1,\\varepsilon$}}}}(\\varpi)+2 m_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}}(\\varpi)\\nonumber\\\\[2 mm ] & + 2\\varepsilon \\sqrt{p_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}}({\\widehat}{\\lambda } ) } \\frac{b_{{\\mathchoice{2,\\varepsilon}{2,\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle2,\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2,\\varepsilon$}}}}({\\widehat}{u})}{\\sqrt{\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}}}- 2\\varepsilon \\sqrt{p_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}}(\\lambda_0 ) }   \\frac{b_{{\\mathchoice{2,\\varepsilon}{2,\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle2,\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2,\\varepsilon$}}}}(u_{{\\mathchoice{0}{0}{\\lower.25ex\\hbox{$\\scriptstyle0 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle0$}}}})}{\\sqrt{\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}}}\\nonumber \\\\[2mm]\\label{sec : pr.4 } & -   \\delta   { \\widehat}{p}_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}}({\\widehat}{\\lambda})+ \\delta { \\widehat}{p}_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}}(\\lambda_0)\\end{aligned}\\ ] ] where @xmath338 , @xmath339 and @xmath340 . note that by @xmath341 the inequality @xmath342 implies that for any @xmath343 @xmath344 from the bound it follows that for @xmath345 @xmath346 & +   \\varepsilon^2 |{\\widehat}{\\varkappa } -\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}| ( |{\\widehat}{\\lambda}|^2 + |\\lambda_0|^2 + 4\\vert\\lambda\\vert_{{\\mathchoice{*}{*}{\\lower.25ex\\hbox{$\\scriptstyle*$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle*$}}}})+ 2   \\delta p_\\varepsilon(\\lambda_0)\\,,\\end{aligned}\\ ] ] where @xmath347 .",
    "it should de noted that through we can estimate this term as @xmath348 taking into account that @xmath349 , we can rewrite the previous bound as @xmath350 & +   \\frac{6\\varepsilon^2 \\vert\\lambda\\vert_{{\\mathchoice{*}{*}{\\lower.25ex\\hbox{$\\scriptstyle*$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle*$}}}}}{n } |{\\widehat}{\\varkappa } -\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}| + 2   \\delta p_\\varepsilon(\\lambda_0).\\end{aligned}\\ ] ] to estimate the second term in the right hand side of this inequality we introduce @xmath351 moreover , note that @xmath352 where @xmath353 .",
    "therefore , thanks to we obtain that for any nonrandom @xmath354 @xmath355 to estimate this function for a random vector we set @xmath356 so , through the inequality @xmath357 it is clear that the last term here can be estimated as @xmath358 where @xmath359 .",
    "moreover , note that , for any @xmath360 , @xmath361 where @xmath362 .",
    "taking into account now , that for any @xmath363 the components @xmath364 , we can estimate the last term as in , i.e. @xmath365 similarly , setting @xmath366 we obtain @xmath367 by the same way we find that @xmath368 and , for any @xmath369 , @xmath370 so , from we get @xmath371 therefore , taking into account that @xmath372 , the term @xmath373 can be estimated as @xmath374 using this bound in we obtain @xmath375 &   + \\frac{2\\varepsilon^{2}\\,\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}}{1 - 3\\delta } +   \\frac{6\\varepsilon^{2}\\,\\vert\\lambda\\vert_{{\\mathchoice{*}{*}{\\lower.25ex\\hbox{$\\scriptstyle*$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle*$}}}}}{(1 - 3\\delta ) } |{\\widehat}{\\varkappa } -\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}| + \\frac{2\\delta}{(1 - 3\\delta ) } p_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}}(\\lambda_0).\\end{aligned}\\ ] ] moreover , for @xmath376 we can rewrite this inequality as @xmath377 &   + 4\\varepsilon^{2}\\,\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$ } } } } +   12\\varepsilon^{2}\\,\\vert\\lambda\\vert_{{\\mathchoice{*}{*}{\\lower.25ex\\hbox{$\\scriptstyle*$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle*$ } } } } |{\\widehat}{\\varkappa } -\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}| +   4\\delta\\ , p_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}}(\\lambda_0)\\,.\\end{aligned}\\ ] ] using here the bounds , , we obtain that @xmath378 &   + 4\\varepsilon^{2}\\,\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$ } } } } +   12\\varepsilon^{2}\\,\\vert\\lambda\\vert_{{\\mathchoice{*}{*}{\\lower.25ex\\hbox{$\\scriptstyle*$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle*$ } } } } \\e_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}\\,|{\\widehat}{\\varkappa } -\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}| +   \\frac{2\\delta}{1 - 3\\delta}\\ , p_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$}}}}(\\lambda_0)\\,.\\end{aligned}\\ ] ] now , lemma  [ le.sec:a.1-06-11-01 ] implies directly the inequality .",
    "hence theorem [ th.sec:mrs.1 ] .",
    "@xmath379      we use here the same method as in @xcite . first",
    ", note that from the definitions and we obtain @xmath380 where @xmath381 so , we have @xmath382 + 1}{j=[1/\\varepsilon]+1}{\\lower.25ex\\hbox{$\\scriptstylej=[1/\\varepsilon]+1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej=[1/\\varepsilon]+1$}}}}\\,t^2_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$ } } } } + 2 \\check{m}_{{\\mathchoice{\\varepsilon}{\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon$ } } } } + \\varepsilon^{2 } \\sum^n_{{\\mathchoice{j=[1/\\varepsilon]+1}{j=[1/\\varepsilon]+1}{\\lower.25ex\\hbox{$\\scriptstylej=[1/\\varepsilon]+1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej=[1/\\varepsilon]+1$}}}}\\,(\\eta^{a}_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}})^{2 } \\,,\\ ] ] where @xmath383 + 1}{j=[1/\\varepsilon]+1}{\\lower.25ex\\hbox{$\\scriptstylej=[1/\\varepsilon]+1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej=[1/\\varepsilon]+1$}}}}\\,t_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}}\\,\\eta^{a}_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}}$ ] .",
    "note that for the continiously differentiable functions ( see , for example , lemma a.6 in @xcite ) the fourrier coefficients @xmath384 for any @xmath162 satisfy the following inequality @xmath385 + 1}{j=[1/\\varepsilon]+1}{\\lower.25ex\\hbox{$\\scriptstylej=[1/\\varepsilon]+1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej=[1/\\varepsilon]+1$}}}}\\,t^2_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$ } } } } \\le   4\\varepsilon\\left(\\int^{1}_{{\\mathchoice{0}{0}{\\lower.25ex\\hbox{$\\scriptstyle0 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle0$}}}}\\vert\\dot{s}(t)\\vert \\d t\\right)^{2 } \\le 4\\varepsilon \\vert\\dot{s}\\vert^{2 } \\,.\\ ] ] the term @xmath386 can be estimated by the same way as in , i.e. @xmath387 + 1}{j=[1/\\varepsilon]+1}{\\lower.25ex\\hbox{$\\scriptstylej=[1/\\varepsilon]+1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej=[1/\\varepsilon]+1$}}}}\\,t^{2}_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$ } } } } \\le   4\\varepsilon^{3}\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}\\vert\\dot{s}\\vert^{2}\\,.\\ ] ] moreover , taking into account that for @xmath56 the expectation @xmath388 we can represent the last term in as @xmath389 + 1}{j=[1/\\varepsilon]+1}{\\lower.25ex\\hbox{$\\scriptstylej=[1/\\varepsilon]+1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej=[1/\\varepsilon]+1$}}}}\\,(\\eta^{a}_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}})^{2 } = \\varepsilon^{2}\\,\\check{\\varkappa}_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}(n-[1/\\varepsilon ] ) + \\varepsilon \\ , b_{{\\mathchoice{2,\\varepsilon}{2,\\varepsilon}{\\lower.25ex\\hbox{$\\scriptstyle2,\\varepsilon$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2,\\varepsilon$}}}}(x ' ) \\,,\\ ] ] where the function @xmath390 is defined in and @xmath391 .",
    "we remind that @xmath392 $ ] . therefore , in view of proposition we obtain @xmath393 + 1}{j=[\\sqrt{1/\\varepsilon}]+1}{\\lower.25ex\\hbox{$\\scriptstylej=[\\sqrt{1/\\varepsilon}]+1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej=[\\sqrt{1/\\varepsilon}]+1$}}}}\\,\\eta^2_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$ } } } } -\\sigma_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$ } } } } \\right\\vert \\le   2\\varepsilon\\ , \\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$ } } } } + \\varepsilon \\sqrt{u_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}}+\\frac{\\sqrt{6\\varkappa_{{\\mathchoice{q}{q}{\\lower.25ex\\hbox{$\\scriptstyleq$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyleq$}}}}}}{\\vert\\lambda\\vert_{{\\mathchoice{*}{*}{\\lower.25ex\\hbox{$\\scriptstyle*$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle*$ } } } } } \\,.\\ ] ] so , we obtain the bound .",
    "hence proposition [ pr.sec : mapr.3 ]",
    ".    * acknowledgements . *",
    "the research is funded by the academic d.i .",
    "mendeleev fund program of the tomsk state university ( research project nu",
    "8.1.55.2015 l ) .",
    "first , setting @xmath401 , we obtain that @xmath402 moreover , note that one can check directly that @xmath403 so , for sufficiently small @xmath189 we obtain that @xmath404 where @xmath405 , @xmath406 and @xmath407 through the correlation inequality ( see , proposition a.1 in @xcite ) we can get that for any @xmath86 @xmath408 as @xmath7 . therefore , for any @xmath227 using the chebychev inequality for @xmath409 we obtain that @xmath410 hence the equality .          where @xmath1 is any arbitrary nonrandom square integrated function , i.e. from @xmath412 $ ] and @xmath413 is the levy process of the form with nonzero constants @xmath23 and @xmath24 .",
    "we denote by @xmath414 and @xmath415 the distributions of the processes @xmath6 and @xmath3 on the skorokhod space @xmath416 $ ] .",
    "now for any @xmath417 and @xmath418 from @xmath416 $ ] we set @xmath419 where @xmath420 is the continuous part of the process @xmath418 in @xmath416 $ ] , i.e. @xmath421 and for any @xmath422 and any measurable @xmath423 from @xmath424 @xmath425,\\gamma ) = \\sum_{{\\mathchoice{0\\le s\\le t}{0\\le s\\le t}{\\lower.25ex\\hbox{$\\scriptstyle0\\le s\\le t$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle0\\le s\\le t$}}}}\\,\\chi_{{\\mathchoice{\\{\\delta x_{{\\mathchoice{s}{s}{\\lower.25ex\\hbox{$\\scriptstyles$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyles$}}}}\\in\\varrho_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2$}}}}\\gamma\\}}{\\{\\delta x_{{\\mathchoice{s}{s}{\\lower.25ex\\hbox{$\\scriptstyles$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyles$}}}}\\in\\varrho_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2$}}}}\\gamma\\}}{\\lower.25ex\\hbox{$\\scriptstyle\\{\\delta x_{{\\mathchoice{s}{s}{\\lower.25ex\\hbox{$\\scriptstyles$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyles$}}}}\\in\\varrho_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2$}}}}\\gamma\\}$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\{\\delta x_{{\\mathchoice{s}{s}{\\lower.25ex\\hbox{$\\scriptstyles$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyles$}}}}\\in\\varrho_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2$}}}}\\gamma\\}$ } } } } \\,.\\ ] ] now we study the measures @xmath414 and @xmath415 in @xmath416 $ ] .",
    "* proof . *",
    "note that to show this proposition it suffices to check that for any @xmath429 any @xmath430 for @xmath431 @xmath432 taking into account that the processes @xmath433 and @xmath413 have the independent homogeneous increments , to this end one needs to check only that for any @xmath434 and @xmath435 @xmath436 to check this equality note that the process @xmath437 is the gaussian martingale .",
    "from here we directly obtain the squation . hence proposition [ pr.sec : app.1++ ] .      in this section",
    "we consider the following continuous time parametric regression model @xmath438 where @xmath439 with the unknown parameters @xmath440 and the process @xmath3 is defined in .",
    "note now that according to proposition [ pr.sec : app.1++ ] the distribution @xmath441 of the process is absolutely continuous with respect to the @xmath415 on @xmath33 $ ] and the corresponding radon - nikodym derivative is @xmath442 where @xmath443 is arbitrary function from @xmath33 $ ] .",
    "let @xmath444 be a prior density on @xmath445 having the following form : @xmath446 where @xmath447 is some continuously differentiable density in @xmath29 .",
    "moreover , let @xmath448 be a continuously differentiable @xmath449 function such that , for each @xmath450 , @xmath451 where @xmath452 for any @xmath453 measurable integrable function @xmath454 we denote @xmath455 & = \\int_{\\bbr^d}\\,\\int_{{\\mathchoice{{{\\cal x}}}{{{\\cal x}}}{\\lower.25ex\\hbox{$\\scriptstyle{{\\cal x}}$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle{{\\cal x}}$}}}}\\ , h(x,\\theta)\\,f(x,\\theta)\\,\\phi(\\theta)\\d \\p_{{\\mathchoice{\\xi}{\\xi}{\\lower.25ex\\hbox{$\\scriptstyle\\xi$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\xi$}}}}(x)\\ , \\d \\theta\\,,\\end{aligned}\\ ] ] where @xmath456 $ ] .",
    "* proof . *",
    "first of all note that , the density on the process @xmath461 is bounded with respect to @xmath462 and for any @xmath450 @xmath463 now , we set @xmath464 taking into account the condition and integrating by parts yield @xmath465 & = \\int_{{{\\cal x}}\\times\\bbr^{d-1}}\\left(\\int_{\\bbr}\\ , g^{\\prime}_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}}(\\theta)\\ , f(x,\\theta)\\phi(\\theta)\\d \\theta_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}}\\right)\\left(\\prod_{i\\neq j}\\d \\theta_i\\right)\\,\\p_{{\\mathchoice{\\xi}{\\xi}{\\lower.25ex\\hbox{$\\scriptstyle\\xi$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\xi$}}}}(\\d x ) = \\lambda_{{\\mathchoice{j}{j}{\\lower.25ex\\hbox{$\\scriptstylej$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylej$}}}}\\,.\\end{aligned}\\ ] ] now by the bouniakovskii - cauchy - schwarz inequality we obtain the following lower bound for the quadratic risk @xmath466 to study the denominator in the left hand of this inequality note that in view of the reprentation @xmath467 therefore , for each @xmath468 , @xmath469 and @xmath470 taking into account that @xmath471 we get @xmath472 hence lemma  [ le.sec:app.3 ] .        bichteler k. , jacod j. _ calcul de malliavin pour les diffusions avec sauts : existence dune densit dans le cas unidimensionnel_. sminaire de probabilit , xvii , lecture notes in math . , * 986 * , springer , berlin , 1983 , 132157 .      el - behery i.n . and macphie r.h .",
    "( 1978 ) maximum likelihood estimation of the number , directions and strengths of point radio sources from variable baseline interferometer data .",
    "_ ieee transactions on antennas and propagation _ , * 26 * ( 2 ) , 294  301 .",
    "flaksman , a.g .",
    "( 2002 ) adaptive signal processing in antenna arrays with allowance for the rank of the impule - response matrix of a multipath channel _ izvestiya vysshikh uchebnykh zavedenij .",
    "radiofizika _ , * 45 * ( 12 ) , 1064  1077 .",
    "galtchouk , l. and pergamenshchikov , s. ( 2013 ) uniform concentration inequality for ergodic diffusion processes observed at discrete times . _ stochastic processes and their applications _ , * 123 * , 91109          galtchouk , l. and pergamenshchikov , s. ( 2009 ) adaptive asymptotically efficient estimation in heteroscedastic nonparametric regression via model selection , _",
    "/ hal-00326910/fr/_.          konev v. v. and pergamenshchikov s. m. sequential estimation of the parameters in a trigonometric regression model with the gaussian coloured noise .",
    "_ statistical inference for stochastic processes _ * 6 * ( 2003 ) 215235 .",
    "konev v. v. and pergamenshchikov s. m. nonparametric estimation in a semimartingale regression model .",
    ". _ journal of mathematics and mechanics of tomsk state university _ * 3 * ( 2009 ) 2341 .",
    "konev v. v. and pergamenshchikov s. m. nonparametric estimation in a semimartingale regression model .",
    "part 2 . robust asymptotic efficiency .",
    "_ journal of mathematics and mechanics of tomsk state university _ * 4 * ( 2009 ) 3145 .",
    "manelis , b.v .",
    "( 2007 ) algorithms for tracking and demodulation of the mobile communication signal in the conditions of the indiscriminating multipath propagation , _ radiotekhnika _ , 4 , 1621 ( in russian ) .",
    "trifonov a.p .",
    ", kharin a.v .",
    ", chernoyarov o.v .",
    ", kalashnikov k. s. ( 2015 ) determining the number of radio signals with unknown phases . _ international journal on communications antenna and propagation _ , * 5 * ( 6 ) , 367374 .          trifonov a.p . , kharin a.v .",
    ", chernoyarov o.v .",
    "( 2016 ) estimation of the number of orthogonal signals with unknown parameters .",
    "_ journal of communications technology and electronics _ , * 61 * ( 9 ) , 1026 1033 ."
  ],
  "abstract_text": [
    "<S> we consider a nonparametric robust estimation problem in the continuous time for the functions observed on the fixed time interval with a noise defined by the levy processes with jumps . </S>",
    "<S> an adaptive model selection procedure is proposed . </S>",
    "<S> a sharp non - asymptotic oracle inequalities for the robust risks is obtained and the robust efficiency is shown . </S>",
    "<S> we apply this procedure to signals number detection problem in the multipath connection channel .    </S>",
    "<S> _ msc : _ </S>",
    "<S> primary 62g08 , secondary 62g05    _ keywords _ : non - asymptotic estimation ; robust risk ; model selection ; sharp oracle inequality ; asymptotic efficiency . </S>"
  ]
}