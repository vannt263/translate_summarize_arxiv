{
  "article_text": [
    "shape - constrained nonparametric maximum likelihood estimators provide an intriguing alternative to kernel - based density estimators .",
    "for example , one can compare the standard histogram with the grenander estimator for a decreasing density .",
    "rules exist to pick the bandwidth ( or bin width ) for the histogram to attain optimal convergence rates , cf . @xcite . on the other hand ,",
    "the grenander estimator gives a piecewise constant density , or histogram , but the bin widths are now chosen completely automatically by the estimator .",
    "furthermore , the bin widths selected by the grenander estimator are naturally locally adaptive [ @xcite ; @xcite ] .",
    "similar comparisons can also be made between the log - concave nonparametric mle and the kernel density estimator with , say , the gaussian kernel .",
    "the grenander estimator was first introduced in @xcite and has been considered extensively in the literature since then .",
    "a recent review of the history of the problem appears in @xcite .",
    "the latter paper establishes that the grenander estimator converges to a true strictly decreasing density at a rate of @xmath2 in the @xmath3 norm .",
    "other rates have also been derived over the years , most notably , convergence at a point at a rate of @xmath0 if the true density is locally strictly decreasing [ @xcite ; @xcite ] and at a rate of @xmath1 if the true density is locally flat [ @xcite ; @xcite ] .    as noted in @xcite ; @xcite , the `` success story '' of maximum likelihood estimators is their robustness .",
    "namely , let @xmath4 denote the space of decreasing densities on @xmath5 . next , let @xmath6 denote the true density and @xmath7 denote the density closest to @xmath6 in the kullback ",
    "leibler sense .",
    "that is , @xmath8 we will call the density @xmath7 the kl projection density of @xmath6 , or the kl projection for short . note that if @xmath9 then @xmath10 .",
    "@xcite showed that the density @xmath7 exists , and that the grenander estimator converges to @xmath7 when the observed samples come from the true density @xmath6 , regardless if @xmath9 .",
    "similar results were proved for the log - concave maximum likelihood estimator in @xcite ; @xcite ; @xcite ; @xcite .    in order to understand the local behavior of the grenander estimator when , we first need to define regions where @xmath6 is considered to be miss- and well - specified .",
    "let @xmath11 denote the cumulative distribution function of @xmath7 defined in  ( [ linedefkl ] ) .",
    "the regions where @xmath12 are then the regions where @xmath6 is misspecified , and @xmath6 is considered to be well specified otherwise .",
    "note that , if @xmath6 is misspecified in a region , it may still be decreasing on some portion of this region ; see , for example , figure  [ figmisseg ] .     and @xmath13 .",
    "the two left panels show the c.d.f . and density , for example , ( [ lineeg1 ] ) while the two right panels show the c.d.f . and density , for example , ( [ lineeg2 ] ) .",
    "@xmath14 ( resp . ,",
    "@xmath6 ) is shown in black , and @xmath11 ( resp .",
    ",  @xmath7 ) is shown in gray , but only if different from the truth ( namely @xmath14 and @xmath6 , resp . ) . ]",
    "let @xmath15 denote the grenander estimator of a decreasing density .",
    "we show here that at a point where the density is misspecified the rate of convergence of @xmath15 to @xmath7 is @xmath1 , and we also identify the limiting distribution .",
    "this is not in contradiction with the results of @xcite : the slower @xmath0 global convergence rate simply comes from locally curved well - specified regions . to be more specific ,",
    "if the density @xmath6 is misspecified at a point , then @xmath11 must be linear ( and @xmath7 is flat ) , and in regions where @xmath7 is flat the rate of convergence is @xmath1 .",
    "in fact , the @xmath1 rate holds at all flat regions of @xmath7 , irrespective of whether these are miss- or well - specified .",
    "the complete result is given in section  [ secpointwise ] , where some properties of @xmath7 are also discussed .",
    "next , we consider convergence of linear functionals .",
    "let @xmath16 in section  [ seclinear ] , we show that @xmath17 , and we again identify the limiting distribution . notably , the limit is made up of two _ independent _ terms : a  mean - zero gaussian term and a second term with nonzero mean . furthermore , the second term is present only if the density has well - specified locally flat regions .",
    "our results apply to a wide range of kl projections with both strictly curved and flat regions .",
    "the work in the strictly curved case follows from the rates of convergence of @xmath18 to the empirical distribution function established in @xcite .",
    "however , as mentioned above , this is only for the well - specified regions of  @xmath6 .",
    "a related work here is that of @xcite , who consider functionals in the strictly curved case but at the distribution function level .    in section  [ secentropy ]",
    ", we go beyond the linear setting , and consider convergence of the entropy functional in the misspecified case .",
    "the limit in this case is gaussian , irrespective of the local properties of @xmath7 .",
    "most proofs appear in section  [ secproofs ] and some technical details are given in @xcite . throughout",
    ", our results are illustrated by reproducible simulations .",
    "code for these is available online at http://www.math.yorku.ca/~hkj/[www.math.yorku.ca/  hkj/ ] .",
    "to our best knowledge , previous work on rates of convergence under misspecification in the shape - constrained context is limited to the rates established in @xcite and @xcite , as well as the more recent results of @xcite . in @xcite ,",
    "the pointwise asymptotic distribution under misspecification was derived for the log - concave probability mass function .",
    "the implications of the new results obtained here are as follows .",
    "first , we now understand that @xmath7 will be made up of local well specified and misspecified regions , and that the rate of convergence in the misspecified regions is always @xmath1 .",
    "we conjecture that this type of behavior will be seen in other situations , such as the log - concave setting for @xmath19 .",
    "that is , the rate of convergence in misspecified regions will be @xmath1 whereas in well - specified regions the rate of convergence will depend on whether locally the density lies on the boundary or the interior of the underlying space . in the log - concave @xmath19 case ,",
    "this `` interior '' rate is known to be @xmath20 [ @xcite ] .",
    "the interesting case of @xmath21 is more mysterious though , as the relationship between the slower boundary points and faster interior points is harder to identify .",
    "secondly , we show that linear functionals ( as well as the nonlinear entropy functional ) converge at rate @xmath1 , and we also conjecture that this behavior will continue to hold for other shape constraints .",
    "let @xmath22 .",
    "our results show that @xmath23 therefore , global rates of _ divergence _ are @xmath1 for linear functionals in the misspecified case . a similar statement also holds for the entropy functional , and here the random @xmath24 term is always gaussian .",
    "such results are well understood in parametric settings , and are key in power calculations .",
    "the exact conditions necessary for ( [ linepower ] ) to hold are given in section  [ seclinear ] for @xmath25 and in section  [ secentropy ] for the entropy .",
    "our work can also be easily extended to locally misspecified settings such as those studied in @xcite .",
    "lastly , the fact that the limiting distribution of the linear functional @xmath26 depends on properties of @xmath7 , whereas the limiting distribution of the entropy functional is always gaussian , makes the entropy functional potentially more appealing in terms of testing procedures .",
    "hypothesis testing based on functionals was considered , for example , in @xcite and @xcite .",
    "the latter reference develops the `` trace test '' which depends on a nearly linear functional , the variance . both ,",
    "however , are developed in the context of log - concavity , and it would be of great interest to extend the results presented here to that setting , particularly for higher dimensions .",
    "properties of the kl projection onto the space of log - concave densities were studied in @xcite .",
    "when onto the space of decreasing densities , the behavior is a little easier to characterize .",
    "[ teopatilea ] let @xmath6 be a density with support on  @xmath27 with @xmath28 .",
    "let @xmath11 denote the least concave majorant of @xmath14 .",
    "then the left derivative of @xmath29 , satisfies the inequality , for all decreasing densities @xmath30 .",
    "the density @xmath7 satisfying @xmath31 for all @xmath32 is called the `` pseudo - true '' density by @xcite .",
    "if we additionally assume that @xmath33 and @xmath34 are both finite , then this @xmath7 is also the unique minimizer of the kullback  leibler divergence @xmath35 see @xcite , page  95 , for more details . in",
    "what follows , we continue to refer to @xmath7 as defined in theorem  [ teopatilea ] , as the kl projection , even if it comes from the slightly more general definition of @xcite .",
    "thus , in our setting , we have a complete graphical representation of the distribution function @xmath11 of the kl projection .",
    "this representation makes it possible to calculate @xmath7 in many cases .",
    "it also allows us to easily visualize the various @xmath14 which yield the same @xmath7 .",
    "moreover , the representation is key in understanding the behavior of the estimator , both on the finite sample and asymptotic levels . therefore , for a function @xmath36 we define the operator @xmath37 to denote the ( left ) derivative of the least concave majorant of @xmath36 .",
    "when the least concave majorant is restricted to a set @xmath38 $ ] , we will write @xmath39}(g)$ ] .    let @xmath40 denote the support of @xmath6 .",
    "we write @xmath41 , where @xmath42 and @xmath43 .",
    "since @xmath6 is a density , it follows that @xmath14 is continuous , as is @xmath11 and , therefore , @xmath44 is a closed set and @xmath45 is open . for a fixed point @xmath46 , we thus know that @xmath47 lies in some open interval .",
    "indeed , let @xmath48 and @xmath49 .",
    "then @xmath50 with @xmath51 .",
    "two examples are given in figure  [ figmisseg ] .",
    "for the first example , we have @xmath52 $ , \\vspace*{2pt}\\cr x-0.25 , & \\quad$x \\in(0.5,1]$.}\\end{aligned}\\ ] ] here , @xmath53 and @xmath54\\cup\\{1\\}$ ] . for the second example , we have @xmath55\\cup[0.6,1]$ , \\vspace*{2pt}\\cr 0.04 , & \\quad$x \\in(0.4,0.6)$.}\\end{aligned}\\ ] ] here , @xmath56 and @xmath57\\cup\\{1\\}$ ] .",
    "the next proposition gives some additional properties of the kl projection .",
    "[ propklprop ] the density , @xmath7 , satisfies the following :    fix @xmath46 and define @xmath58 as above .",
    "then @xmath59 , and @xmath7 is constant on @xmath60 $ ] and satisfies the mean - value property @xmath61    suppose that @xmath62 .",
    "then @xmath63    for any increasing function @xmath64 , @xmath65 .",
    "let @xmath66 and let @xmath67 .",
    "then @xmath68    point ( 3 ) above tells us that if @xmath36 is increasing then @xmath69 .",
    "point ( 4 ) is marshall s lemma [ @xcite ] .",
    "the proof of proposition [ propklprop ] appears in @xcite .",
    "suppose that @xmath70 are independent and identically distributed with density @xmath6 on @xmath71 .",
    "let @xmath15 denote the grenander estimator of a decreasing density @xmath72 where @xmath4 denotes the class of decreasing densities on @xmath5 , and @xmath73}(x_i)$ ] denotes the empirical distribution function .",
    "the next theorem is our first main result .",
    "[ teomisslocal ] fix a point @xmath46 , and let @xmath38 $ ] denote the largest interval  @xmath74 containing @xmath47 such that @xmath75 is linear on @xmath74 . let @xmath76 denote a standard brownian bridge process on @xmath77 $ ] , and let @xmath78 for @xmath79",
    ". then @xmath80 } \\bigl({\\mathbb u}^{\\mathrm{mod}}_{f_0 } \\bigr ) ( x_0),\\end{aligned}\\ ] ] where @xmath81 \\cap\\mathcal{w}$ , \\vspace*{2pt}\\cr -\\infty , & \\quad$u \\in[a , b ] \\cap\\mathcal{m}$.}\\end{aligned}\\ ] ] if it happens that @xmath38\\cap\\mathcal{w } = \\{a , b\\}$ ] , then @xmath82 where @xmath83 is a standard normal random variable and @xmath84.\\end{aligned}\\ ] ]    recall that @xcite , corollary  5.6 , shows that the rate of convergence ( in hellinger distance ) of @xmath85 to @xmath7 is @xmath0 .",
    "the above theorem shows that the _ local _ rate of convergence will be @xmath86 where the kl projection is flat . when the kl density is curved , the kl density and true density are actually equal , and hence the convergence rate from the correctly specified case applies .",
    "the next formulation of the limiting process is similar to that of @xcite for a density with a flat region on @xmath38 $ ] .",
    "[ remmisslocal ] let @xmath87 .",
    "since @xmath11 is linear on @xmath38 $ ] the limiting distribution may also be expressed as @xmath88 } \\bigl({\\mathbb u}^{\\mathrm{mod}}_{f_0 } \\bigr ) ( x_0 ) & = & \\frac{1}{b - a } \\biggl\\ { z+ \\sqrt{p_0 } \\operatorname{gren } \\bigl({\\mathbb u}^{\\mathrm{mod } } \\bigr ) \\biggl ( \\frac{x_0-a}{b - a } \\biggr ) \\biggr\\},\\end{aligned}\\ ] ] where @xmath83 is a mean zero normal random variable with variance @xmath89 , @xmath76 is an independent standard brownian bridge , and @xmath90\\cap\\mathcal{w}-a \\bigr)/(b - a)$ , \\vspace*{2pt}\\cr -\\infty , & \\quad$u \\in \\bigl([a , b ] \\cap\\mathcal{m}-a \\bigr)/(b - a)$.}\\end{aligned}\\ ] ] notably , if @xmath38\\cap\\mathcal{w } = \\{a , b\\}$ ] , then @xmath91 .     vs. the true quantiles of the limiting @xmath92 distributions at the point @xmath93 for @xmath6 given by ( [ lineeg1 ] ) in the top row ( @xmath94 and ( [ lineeg2 ] ) in the bottom row ( @xmath95 ) .",
    "the sample size varies from @xmath96 to @xmath97100,000 .",
    "the straight line goes through the origin and has slope one .",
    "each plot is based on @xmath98 samples . ]",
    "figure  [ figmisspoint ] illustrates the theory .",
    "the convergence is surprisingly fast , although it appears to be a little slower in the second example ( [ lineeg2 ] ) .",
    "we conjecture that this difference is caused by the presence / absence of the strictly curved region of  @xmath6 .",
    "proof of theorem [ teomisslocal ] by the switching relation [ @xcite ] , we have @xmath99 & & \\qquad = p \\bigl(\\mathop{\\operatorname{argmax}}_{z\\geq0 } \\bigl\\{{\\mathbb f}_n(z)- \\bigl(\\hat f_0(x_0)+n^{-1/2}t \\bigr)z \\bigr\\ }",
    "< x \\bigr ) \\\\[-1pt ] & & \\qquad = p \\bigl(\\mathop{\\operatorname{argmax}}_{z\\geq0 } \\bigl\\{\\sqrt{n } \\bigl({\\mathbb f}_n(z)-{\\mathbb f}_n(a)- \\bigl(f_0(z)-",
    "f_0(a ) \\bigr ) \\bigr ) \\\\[-1pt ] & & \\hspace*{83pt } { } + \\sqrt{n } \\bigl(f_0(z)-f_0(a)- \\hat f_0(x_0 ) ( z - a ) \\bigr)-tz \\bigr\\ } < x \\bigr).\\end{aligned}\\ ] ] we now look more closely at the `` second '' term .",
    "that is , @xmath100 noting that @xmath101 , since @xmath102\\cap\\mathcal{w}$ ] . on the other hand , for all @xmath103 \\cap\\mathcal{m}$ ] , we have @xmath104 .",
    "furthermore , @xmath11 is concave with derivative @xmath105 [ at any point @xmath106 , and hence @xmath107 for all @xmath108 . for @xmath109\\cap\\mathcal{w}$",
    "] this is an equality , and a strict inequality otherwise .",
    "therefore , the weak limit of @xmath110 is @xmath111 , for all @xmath109 $ ] . for @xmath112\\cap\\mathcal{w}$ ] , the limit of this process is always @xmath113 and , therefore , the maximum must occur inside of @xmath38 $ ] . by the argmax continuous mapping theorem [ @xcite , theorem 3.2.2 ,",
    "page 287 ] , @xmath114 } \\bigl\\ { { \\mathbb u}_{f_0}^{\\mathrm{mod}}(z ) - tz \\bigr\\ } < x \\bigr ) = p \\bigl(\\operatorname{gren}_{[a , b ] } \\bigl({\\mathbb u}_{f_0}^{\\mathrm{mod } } \\bigr ) ( x_0 ) < t \\bigr)\\end{aligned}\\ ] ] by switching again .",
    "when @xmath38\\cap\\mathcal{w } = \\{a , b\\}$ ] , then the least concave majorant is simply the line joining @xmath115 and @xmath116 , with slope equal to @xmath117 a gaussian random variable with mean zero and variance @xmath118 \\\\   & & \\qquad   =   \\hat f_0(x_0 ) \\biggl [ \\frac{1}{b - a } -\\hat f_0(x_0 ) \\biggr].\\end{aligned}\\ ] ]    proof of remark [ remmisslocal ] recall that @xmath11 is linear on @xmath38 $ ] .",
    "therefore , for @xmath119 $ ] , we can write @xmath120 , where @xmath121 since all variables are jointly gaussian , a careful calculation of the covariances reveals that @xmath122 and @xmath123 are independent ( also as processes ) , and @xmath122 is mean - zero gaussian with variance @xmath89 .",
    "furthermore , @xmath124 this decomposition is similar to that of @xcite , exercise  2.2.11 , page  32 .",
    "now , note that the grenander operator satisfies @xmath39}(g)(x ) = \\beta+ \\frac{\\gamma}{b - a } \\operatorname{gren}_{[0,1]}(h ) ( \\frac{t - a}{b - a } ) $ ] if @xmath125 .",
    "it follows that @xmath88 } ( { \\mathbb u}_{\\widehat f_0 } ) ( x_0 ) & = & \\frac{1}{b - a } z+ \\frac{\\sqrt{p_0}}{b - a}\\operatorname { gren}({\\mathbb u } ) \\biggl(\\frac{x_0-a}{b - a } \\biggr)\\end{aligned}\\ ] ] with @xmath126 defined as in the remark .",
    "the full result follows since , @xmath127 .",
    "consider a density @xmath6 with support @xmath40 and let @xmath7 denote its kl projection .",
    "we write @xmath128 , where @xmath129 denotes the portion of the support where @xmath7 is curved and @xmath130 denotes the portion of the support where @xmath7 is flat . by definition of @xmath131 as well as",
    "proposition  [ propklprop ] , the kl projection can be written as @xmath132 on @xmath131 , where the intervals are disjoint and each is of the form @xmath133 $ ] .",
    "our results for linear functionals hold under the following assumptions :    the support , @xmath40 , of @xmath6 is bounded .    when the kl projection is curved , @xmath134 .",
    "the true density is strictly positive : @xmath135 .",
    "when the kl projection is flat , @xmath136 is finite in ( [ defklform ] ) .",
    "let @xmath137 and define @xmath26 by ( [ defmug ] ) .",
    "then we require that @xmath36 satisfy the following conditions :    @xmath138 .",
    "@xmath139 for some @xmath140 .    in order to state our main result for linear functionals",
    ", we need to define the following functions : @xmath141 , \\nonumber\\\\[-9pt]\\label{linedefg }   \\\\[-9pt ] \\bar{g}_j&= & ( b_j - a_j)^{-1 } \\int_{a_j}^{b_j } g(x)\\,dx\\nonumber\\end{aligned}\\ ] ] and @xmath142 thus , @xmath143 are the local averages of the function @xmath36 , and each @xmath144 is a localized version of @xmath36 .",
    "[ teolinear ] suppose that the density @xmath6 satisfies conditions , ,  and  .",
    "consider a function @xmath137 which satisfies conditions and  .",
    "let @xmath145 denote independent brownian bridges , @xmath78 , and define @xmath146 as in theorem [ teomisslocal ] .",
    "then @xmath147 where @xmath148 .",
    "furthermore , @xmath149 also , if @xmath150 , then @xmath151 .     with @xmath152 vs. the true quantiles of the limiting @xmath92 distribution for @xmath6 given in ( [ lineeg2 ] ) , with @xmath153 . ]",
    "it follows that @xmath154 will converge to a gaussian limit for true density ( [ lineeg2 ] ) but not for ( [ lineeg1 ] ) , as the latter has well - specified flat regions . a simulation for ( [ lineeg2 ] ) is shown in figure  [ figmissmean ] .",
    "the proof of theorem  [ teolinear ] is given in section  [ secproofs ] .",
    "the simulations show that there appears a systematic bias prior to convergence ( the empirical quantiles appear on the @xmath155-axis in figure  [ figmissmean ] , the negative bias translates to a left - shift in the plot ) .",
    "the proof of proposition  [ curved ] shows that one source of the bias is the term @xmath156 .",
    "when @xmath157 , this term is the only source of bias , and from @xcite , it converges to zero at a rate of at least @xmath158 .",
    "since ( 3 ) of proposition [ propklprop ] also holds at the empirical level , similar behavior will be seen for all increasing functions @xmath36 .",
    "the results of theorem [ teolinear ] also show that @xmath159 is asymptotically normal with variance @xmath160 if @xmath40 has no _ well - specified flat _ regions . additionally , if @xmath161 , then @xmath162 and the model is well specified . in this case",
    ", @xmath26 has the same asymptotic distribution as the empirical estimator @xmath163 ( see also proposition  [ curved ] ) .",
    "this shows that the maximum likelihood estimator is asymptotically efficient , as in the strictly curved case the family of decreasing densities is complete , and hence the `` naive estimator '' @xmath163 is asymptotically efficient [ @xcite , example 4.7 ] .",
    "finally , we make a few comments on the assumptions required for theorem  [ teolinear ] to hold .",
    "the assumptions which we use on @xmath164 are , and .",
    "these are quite standard assumptions in the literature for the strictly curved setting ; see , for example , @xcite ; @xcite ; @xcite ; @xcite ; @xcite . in the misspecified region ,",
    "the required assumptions are  and  .",
    "note also that by remark  [ reml2 ] , the assumption is required in the result .",
    "additional discussions of these assumptions , including directions for future research , are provided in the @xcite .    to further illustrate these assumptions , as well as theorem  [ teolinear ]",
    ", we consider the examples ( [ lineeg1 ] ) and ( [ lineeg2 ] ) .",
    "in example ( [ lineeg1 ] ) , we have that @xmath165}(x)+0.5\\,1_{(0.5,1]}(x).\\end{aligned}\\ ] ] the conditions and are clearly satisfied , as is since @xmath166 .",
    "lastly ,  holds with @xmath167 , i_2 = ( 0.5 , 1]$].applying theorem  [ teolinear ] for @xmath152 , we find that @xmath168}(x)+\\break 0.25\\,1_{(0.5,1]}(x)$ ] , and @xmath169 [ hence @xmath170 .",
    "therefore , @xmath171 where @xmath172 are independent brownian bridges as defined in theorem  [ teolinear ] .",
    "notably , the limit has a non - gaussian component .",
    "example ( [ lineeg2 ] ) can be analyzed similarly .",
    "here , @xmath173}(x)+0.75\\,1_{(0.25,1]}(x).\\end{aligned}\\ ] ] again , the conditions and clearly hold . on @xmath174",
    "$ ] , we have @xmath175 and , therefore , condition holds . on @xmath176",
    "$ ] we have @xmath177 , and hence also holds . applying theorem  [ teolinear ] for @xmath152 , we find that @xmath178}(x)+ ( 5/8 ) 1_{(0.25,1]}(x)$ ] , and @xmath179 [ hence @xmath180 .",
    "therefore , @xmath181 that is , the limit is zero - mean gaussian with variance @xmath182 .",
    "[ reml2 ] marginal properties of the process @xmath183 were studied in @xcite .",
    "the results include marginal densities and moments , including @xmath184 = 0.5(x^2/(1-x)+(1-x)^2/x)$ ] .",
    "it follows that @xmath185 = \\int_0 ^ 1(1-x)^2/x \\,dx = \\infty$ ] , and hence the limiting process @xmath186 exists only for @xmath187 for @xmath140 .",
    "we would therefore not expect convergence of @xmath26 for @xmath139 with @xmath188 $ ] .",
    "entropy measures theamount of disorder or uncertainty in a system and is closely related to the kullback  leibler divergence .",
    "let @xmath189 denote the entropy functional .",
    "a review of testing and other applications of entropy appears , for example , in @xcite .",
    "[ teoentropy ] suppose that @xmath7 is bounded , the support of @xmath6 is also bounded , and that @xmath190 .",
    "then @xmath191 where @xmath83 is a standard normal random variable and @xmath192    the proof is made up of two key pieces : ( 1 ) tight bounds on the likelihood ratio from lemma [ lemmalogratio ] and ( 2 ) specialized equalities which hold for the grenander estimator .    [",
    "lemmalogratio ] suppose that @xmath7 is bounded , the support of @xmath6 is also bounded , and that @xmath190 .",
    "then @xmath193    we note that the conditions we require here are stronger than those of @xcite , corollary 5.6 .",
    "however , under those conditions @xcite establishes convergence rates on @xmath194 , which is not sufficient for our purposes .",
    "the condition that @xmath195 is bounded above was also used in the study of misspecification in @xcite , section  10.4 . the condition that the support of @xmath6 is bounded is the strongest , whereas the condition that @xmath7 is bounded may be relaxed somewhat .",
    "we discuss this further in @xcite .",
    "proof of lemma [ lemmalogratio ] we first show that @xmath196 for any function  @xmath197 .",
    "this follows since @xmath198 with equality at finitely many touch points , and also @xmath15 is constant between all touch points .",
    "thus , letting @xmath199 enumerate the ( random ) points of touch , we have @xmath200 with @xmath201 and @xmath202 .",
    "a similar argument also establishes that @xmath203 for @xmath204 , it follows that @xmath205 the first term is @xmath206 by lemma [ lemmalogratio ] .",
    "the second term has a gaussian limit with variance @xmath207 . by ( [ line ] ) [ with @xmath208 this is equal to @xmath209 .     vs. the true quantiles of the limiting @xmath92 distribution for @xmath6 given in ( [ lineeg1 ] ) , with @xmath210 .",
    "]    a simulation of this result is shown in figure  [ figmissentropy ] based on the true density  ( [ lineeg1 ] ) .",
    "the kl projection of ( [ lineeg1 ] ) is given in ( [ lineeg1kl ] ) .",
    "one can easily check that the conditions of theorem  [ teoentropy ] are satisfied in this case .",
    "note that this density has well - specified flat regions and , therefore , linear functionals that do not ignore @xmath211 should have non - gaussian terms in their limit ; see , for example , ( [ lineeg1meanlimit ] ) for the case when @xmath152 . on the other hand , the entropy functional will _",
    "always _ result in a gaussian limit .",
    "the simulations exhibit a systematic positive bias .",
    "the proof shown above reveals the cause : the term @xmath212 since @xmath15 is the  mle . in the plots",
    "the quantiles of @xmath213 are shown on the axis , and these quantiles appear to be shifted to the right  that is , they are larger than the quantiles of the limiting gaussian distribution .",
    "we anticipate that extensions of this work to other one - dimensional shape - constrained models , such as the log - concave and convex decreasing constraints , are within reach , although certain technical difficulties will need to be overcome .",
    "in particular , the results of @xcite for convex models should yield some results for convex decreasing densities under misspecification .",
    "the grenander estimator has a particular simplicity of form , which we have exploited here .",
    "some progress for the log - concave setting has already been made in @xcite , albeit for the discrete ( i.e. , probability mass function ) setting .",
    "we conjecture that statements such as ( [ linepower ] ) will continue to hold for other shape - constraints in @xmath19 for linear functionals .",
    "similar results for higher - dimensional shape - constrained models seem premature in view of the current lack of rate of convergence results even when the model is correctly specified .",
    "we now present the proof for theorem [ teolinear ] .",
    "we proceed by proving convergence results for the different types of behaviours of the density separately ( curved , flat , misspecified ) , and combine the results together at the end .",
    "we believe that the intermediate results are of independent interest to the reader , and we also hope that this approach makes the proof more accessible .      we first suppose that the true density @xmath6 satisfies the conditions introduced in @xcite .    [ curved ] suppose that @xmath6 satisfies conditions and , and that @xmath36 satisfies condition",
    ". then @xmath214 where @xmath83 is a standard normal random variable and @xmath215 .",
    "we note that this result is similar to that in @xcite .    without loss of generality",
    ", we assume that @xmath216 $ ] .",
    "let @xmath217 denote the empirical estimator of @xmath25 .",
    "using fubini , we have @xmath218 \\,dx \\biggr{\\vert}\\\\ & \\leq & \\biggl\\{\\int _",
    "{ \\mathcal{s}_c } \\bigl|g'(x)\\bigr| \\,dx \\biggr\\ } \\sup _ { x\\in\\mathcal{s}_c}\\bigl| \\widehat f_n(x)-{\\mathbb f}_n(x)\\bigr|.\\end{aligned}\\ ] ] from the results of @xcite [ see also @xcite , corollary 2.2 ] , we have that @xmath219 } \\sqrt{n}| \\widehat f_n(x)-{\\mathbb f}_n(x)| = o_p(n^{-1/6 } \\log^{2/3 } n)$ ] .",
    "therefore , @xmath220 from which the result follows .",
    "suppose next that @xmath221 .",
    "that is , the true density is piecewise constant decreasing and can be expressed as @xmath222 } ( x),\\ ] ] where @xmath223 , @xmath224 is finite , and @xmath225 where the sets @xmath226 $ ] are disjoint .",
    "indeed , we have @xmath227 for @xmath228 .",
    "note that @xmath229 . also , let @xmath230 denote independent standard brownian bridge processes ( each defined on @xmath77 $ ] ) , and",
    "let @xmath231 be an independent multivariate normal with mean zero and covariance @xmath232 for @xmath233 .",
    "[ step ] suppose that @xmath6 is as in ( [ defstep ] ) .",
    "then @xmath234 converges weakly to @xmath235 in @xmath236 for any @xmath237 , where @xmath238    a pointwise version of proposition [ step ] was originally proved in @xcite . here , we extend these results to convergence in @xmath239 , which is a much stronger statement , requiring tight bounds on the tail behaviour at a point of the kind proved in @xcite , theorem  2.1 . in the case of the decreasing probability mass function",
    ", @xmath240 convergence has been established in @xcite .",
    "an immediate corollary of this work is convergence of the linear functionals @xmath26 ; see corollary [ corstep ] below .",
    "@xcite , theorem 4.1 , shows that for @xmath6 equal to the uniform density on @xmath77 $ ] we have @xmath241 where @xmath76 is again a standard brownian bridge process on @xmath77 $ ] .",
    "this is an immediate corollary of proposition [ step ] with @xmath177 . on the other hand , @xcite",
    "[ see also @xcite ] shows that @xmath242 and hence convergence of @xmath234 to @xmath243 in @xmath244)$ ] fails .",
    "see also remark  [ reml2 ] .",
    "[ corstep ] suppose that @xmath6 takes the form ( [ defstep ] ) with bounded support @xmath245 and with @xmath136 finite .",
    "suppose further that @xmath36 satisfies condition .",
    "then @xmath246 , where @xmath247 with @xmath248 and @xmath249 defined in ( [ linedefg ] ) .    in",
    "what follows , unless stated otherwise , we assume that @xmath250 $ ] .    [ lemahstronger ] suppose that @xmath6 is as in ( [ defstep ] ) with a discontinuity at a point @xmath251 .",
    "then , for all @xmath252 , @xmath253    it was shown in @xcite , theorem  2 , that @xmath254 where @xmath255 is the left derivative of the least concave majorant ( over @xmath256 ) of the process @xmath257 where the rate function is equal to @xmath258    here , @xmath259 denotes a standard two - sided poisson process . the result in @xcite , theorem 2 ,",
    "is established by a `` switching '' argument similar to that in the proof of theorem [ teomisslocal ] .",
    "the switching argument can also be extended to this situation even if @xmath260 . a  similar argument",
    "may also be used to show convergence in finite - dimensional distributions as well .",
    "we next show convergence of the supremum norm @xmath261 this is done by ( 1 ) showing that the convergence in ( [ lineahmainresult ] ) also holds in @xmath262 , and ( 2 ) showing that this implies convergence of the supremum norm ( as above ) .",
    "both of these steps follow exactly the same argument as the proof of theorem 1.1 in @xcite , and we therefore omit the details .    [ lemexpbounds ] suppose that @xmath6 is decreasing on @xmath256 and flat on @xmath263 $ ] and fix @xmath264 .",
    "then , for any @xmath265 and @xmath266 , there exists a constant @xmath267 such that @xmath268 for all @xmath269 . also , @xmath270\\ ] ] and otherwise the probability is equal to zero .",
    "let @xmath271 , and we write @xmath272 . by the switching relation , @xmath273 } \\bigl\\{{\\mathbb f}_n(s)- \\bigl(f_0(x)+n^{-1/2}t \\bigr)s \\bigr \\}>x \\bigr ) \\\\ & & \\qquad = p \\bigl(\\mathop{\\operatorname{argmax}}_{s\\in[0,1 ] } \\bigl\\{{\\mathbb f}_n(a ,",
    "s)- \\bigl(f_0(a+)+n^{-1/2}t \\bigr ) ( s - a ) \\bigr\\}>x \\bigr ) \\\\ & & \\qquad \\leq p \\bigl(\\bigl\\{{\\mathbb f}_n(a ,",
    "s)\\geq \\bigl(f_0(a+)+n^{-1/2}t \\bigr ) ( s - a)\\bigr\\},\\mbox { for some } s\\in(x,1 ] \\bigr ) \\\\ & & \\qquad = p \\biggl(\\frac{{\\mathbb f}_n(a , s)}{f_0(a , s)}\\geq\\frac { ( f_0(a+)+n^{-1/2}t)(s - a)}{f_0(a , s ) } , \\mbox { for some } s \\in(x,1 ] \\biggr ) \\\\ & & \\qquad = p \\biggl(\\frac{{\\mathbb f}_n(a , s)}{f_0(a , s)}\\geq1+\\frac { n^{-1/2}t}{f_0(a+ ) } , \\mbox { for some } s\\in(x,1 ] \\biggr ) \\\\ & & \\qquad \\leq p \\biggl(\\sup_{s\\in(x,1]}\\frac{{\\mathbb f}_n(a , s)}{f_0(a , s)}\\geq1 + \\frac{n^{-1/2}t}{f_0(a+ ) } \\biggr).\\end{aligned}\\ ] ] since @xmath274 is a binomial random variable , we can bound the above using @xcite , inequality 10.3.2 , page  416 , with @xmath275 and @xmath276 .",
    "it therefore follows that @xmath277}\\frac{{\\mathbb f}_n(a , s)}{f_0(a , s)}\\geq1 + \\frac{n^{-1/2}t}{f_0(a+ ) } \\biggr ) \\\\ & & \\qquad \\leq \\exp \\biggl\\{-n f_0(a , x ) h \\biggl(1 + \\frac { n^{-1/2}t}{f_0(a+ ) }",
    "\\biggr ) \\biggr\\ } \\\\ & & \\qquad = \\exp \\biggl\\{- \\frac{t^2 ( x - a)}{2f_0(a+ ) } \\psi \\biggl(\\frac { n^{-1/2}t}{f_0(a+ ) } \\biggr ) \\biggr\\ } \\\\ & & \\qquad \\leq \\exp \\biggl\\{- \\frac{t(x - a)}{2 } \\frac { t / f_0(a+)}{1+(t / f_0(a+))/(3\\sqrt{n } ) } \\biggr\\}.\\end{aligned}\\ ] ] write @xmath278 and note that for all @xmath269 we have @xmath279 which is a increasing function of @xmath280 .",
    "fix @xmath265 and let @xmath281 . then , with @xmath282 we have that @xmath283    we handle the other side in a similar manner .",
    "@xmath284 } \\bigl\\{{\\mathbb f}_n(s ,",
    "b)- \\bigl(f_0(b)-n^{-1/2}t \\bigr ) ( x - b ) \\bigr\\}<x \\bigr ) \\\\ & & \\qquad \\leq p \\biggl(\\frac{{\\mathbb f}_n(s , b)}{f_0(s , b)}\\leq1-\\frac { n^{-1/2}t}{f_0(b ) } , \\mbox { for some } s \\in[0,x ) \\biggr ) \\\\ & & \\qquad \\leq p \\biggl(\\inf_{s\\in[0,x)}\\frac{{\\mathbb f}_n(s , b)}{f_0(s , b)}\\leq1- \\frac{n^{-1/2}t}{f_0(b ) } \\biggr).\\end{aligned}\\ ] ] we now bound this using the martingale inequality from @xcite , lemma 2.3 .",
    "@xmath285 now , note that since @xmath85 is a density , we only consider @xmath286 .",
    "therefore , we bound only @xmath287 for @xmath288 $ ] , for which we have that thus , it follows that @xmath289    let @xmath290 and @xmath291 .",
    "[ lemsteppointexp ] suppose that @xmath6 is flat on @xmath263 $ ] and fix @xmath264 , and fix @xmath292 .",
    "then , there exists a constant @xmath293 such that @xmath294 & \\leq & c ( b - x)^{-\\alpha/2 } , \\\\",
    "e \\bigl [ \\bigl{\\vert}\\sqrt{n } \\bigl(\\hat{f}_n(x)-f_0(x ) \\bigr)_+ \\bigr{\\vert}^\\alpha \\bigr ] & \\leq & c ( x - a)^{-\\alpha/2}\\end{aligned}\\ ] ] with the second bound valid only for @xmath295 , for some @xmath296 .    using the bounds obtained in lemma [ lemexpbounds ] , we find that @xmath297 \\\\ & & \\qquad = \\int _ 0^\\infty\\alpha t^{\\alpha-1 } p \\bigl(\\sqrt{n }",
    "\\bigl(\\hat{f}_n(x)-f_0(x ) \\bigr)_{- } > t \\bigr ) \\,dt \\\\ & & \\qquad = \\int_0^{n^{1/2}f_0(x ) } \\alpha t^{\\alpha-1 } p \\bigl ( \\hat{f}_n(x ) <",
    "f_0(x)-n^{-1/2}t \\bigr ) \\,dt \\\\ & & \\qquad \\leq \\int_0^\\infty\\alpha t^{\\alpha-1 } \\exp \\biggl\\{- \\frac { t^2(b - x)}{2f_0(b ) } \\biggr\\}\\,dt \\\\ & & \\qquad = \\gamma(1+\\alpha/2 ) \\biggl(\\frac{2f_0(b)}{b - x } \\biggr)^{\\alpha/2}.\\end{aligned}\\ ] ] for the second inequality , we first fix @xmath265 .",
    "we then have @xmath298 \\\\ & & \\qquad = \\int _",
    "0^\\infty\\alpha t^{\\alpha-1 } p \\bigl(\\sqrt{n } \\bigl(\\hat{f}_n(x)-f_0(x ) \\bigr)_{+ } > t \\bigr ) \\,dt \\\\ & & \\qquad = \\int_0^{t_0 } \\alpha t^{\\alpha-1 } p \\bigl ( \\hat{f}_n(x)>f_0(x)+n^{-1/2 } t \\bigr ) \\,dt \\\\ & & \\quad\\qquad { } + \\int_{t_0}^\\infty\\alpha t^{\\alpha-1 } p \\bigl(\\hat{f}_n ( x)>f_0(x)+n^{-1/2 } t \\bigr ) \\,dt \\\\ & & \\qquad \\leq t_0^\\alpha+ \\int_{t_0}^\\infty \\alpha t^{\\alpha-1 } \\exp \\biggl\\{- c_0\\frac{t(x - a)}{2 } \\biggr \\}\\,dt \\\\ & & \\qquad \\leq t_0^\\alpha+ \\gamma(\\alpha+1 ) \\biggl ( \\frac { 2}{c_0(x - a ) } \\biggr)^{\\alpha}.\\end{aligned}\\ ] ] now , recall that @xmath299 takes the form @xmath300 .",
    "therefore , we obtain the bounds @xmath301 as long as @xmath302 for some choice of @xmath303 .",
    "we optimize the entire quantity in @xmath304 to find that @xmath305 & \\leq & a_\\alpha \\biggl(\\frac{f_0(b)}{x - a } \\biggr)^{\\alpha/2}\\end{aligned}\\ ] ] for some new constant @xmath306 .",
    "now , in order for this optimized bound to hold , we need @xmath307 , and @xmath308 the latter translates to @xmath309 by using @xmath310 .",
    "proof of proposition [ step ] the outline of the proof is as follows .",
    "we first require pointwise convergence , which follows from @xcite , theorem 6.4 .",
    "one can also easily extend this to convergence in finite - dimensional distributions .",
    "the particular form of the limit follows from the following decomposition of a ( time - transformed ) brownian bridge , which is a generalization of @xcite , exercise 2.2.11 , page 32 .",
    "let @xmath311 denote any distribution function with compact support , which , without loss of generality , we assume to be @xmath77 $ ] .",
    "let @xmath312 .",
    "let @xmath313 denote independent brownian bridges .",
    "then @xmath314\\\\[-8pt ] & & \\hspace*{42pt } { } + \\sqrt{f(b_i)- f(a_i ) } { \\mathbb u}_i \\biggl ( \\frac{f(t)-f(a_i)}{f(b_i)- f(a_i ) } \\biggr ) \\biggr\\ } 1_{(a_i , b_i ] } ( t),\\nonumber\\end{aligned}\\ ] ] where @xmath315 .",
    "recall that the grenander operator satisfies @xmath316 .",
    "also note that @xmath14 is linear on @xmath317 $ ] by assumption .",
    "therefore , from @xcite , the limit of @xmath318 at a point @xmath319 $ ] can be written as @xmath320 } \\bigl({\\mathbb v } \\bigl(f_0(t ) \\bigr ) \\bigr ) & = & \\delta{\\mathbb v } \\bigl(f(a_i ) \\bigr ) \\frac{1}{b_i - a_i } + \\sqrt{p_i } \\operatorname{gren } \\biggl({\\mathbb u}_i \\biggl(\\frac { t - a_i}{b_i - a_i }",
    "\\biggr ) \\biggr ) \\\\ & = & \\frac{1}{b_i - a_i } \\biggl\\ { \\delta{\\mathbb v } \\bigl(f(a_i )",
    "\\bigr ) + \\sqrt{p_i } \\operatorname{gren } ( { \\mathbb u}_i ) \\biggl(\\frac { t - a_i}{b_i - a_i } \\biggr ) \\biggr\\}\\end{aligned}\\ ] ] from the above characterization . finally , @xmath321 as in proposition [ step ] .",
    "the second step is to show that the process @xmath322 is tight in @xmath323 .",
    "for this , we first need a characterization of compact sets in @xmath323 for @xmath324 .",
    "these appear , for example , in @xcite , page 298 [ see also @xcite ] . for @xmath325 bounded , a set @xmath326 is relatively compact if for all @xmath327 :    @xmath328 ,    @xmath329 .",
    "we want to show that for each @xmath330 we can find a compact subset @xmath331 of @xmath323 such that @xmath332 .",
    "thus , we want to show that @xmath333 and @xmath334 as @xmath335 , for every @xmath336 .",
    "to show the first of these , we proceed as follows : for @xmath6 as in ( [ defstep ] ) , @xmath337 } \\bigl| { \\mathbb s}_n ( x ) \\bigr|^{\\alpha } \\,dx\\ ] ] and hence we have @xmath338 } \\bigl| { \\mathbb s}_n ( x ) \\bigr|^{\\alpha } \\,dx > m / j \\biggr).\\ ] ] thus , it suffices to show that @xmath339 } \\bigl| { \\mathbb s}_n ( x ) \\bigr|^{\\alpha } \\,dx >",
    "m \\biggr ) \\rightarrow0\\ ] ] as @xmath340 for each fixed @xmath263 $ ] with @xmath6 flat on @xmath263 $ ] .",
    "now , @xmath341 } \\bigl| { \\mathbb s}_n ( x ) \\bigr|^{\\alpha } \\,dx > m \\biggr ) & \\le & p \\biggl ( \\int_{(a , a+\\tilde{c}_0/n ] } \\bigl| { \\mathbb s}_n ( x ) \\bigr|^{\\alpha } \\,dx > m/2 \\biggr ) \\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } + p \\biggl ( \\int_{(a+ \\tilde{c}_0/n , b ] } \\bigl| { \\mathbb s}_n ( x ) \\bigr|^{\\alpha } \\,dx > m/2 \\biggr ) \\nonumber\\end{aligned}\\ ] ] and we handle each term separately . from lemma  [ lemahstronger ] , it follows that @xmath342 } \\bigl| { \\mathbb s}_n ( x ) \\bigr|^{\\alpha } \\,dx & = & \\int_{(a , a+\\tilde{c}_0/n ] } n^{\\alpha/2 } \\bigl| \\hat{f}_n ( x ) - f_0 ( x ) \\bigr|^{\\alpha } \\,dx \\nonumber\\\\[-8pt]\\\\[-8pt ] & = & n^{\\alpha/2 } \\tilde{c}_0 n^{-1 } o_p ( 1 ) = o_p ( 1)\\nonumber\\end{aligned}\\ ] ] for @xmath343 . for the second term , we use markov s inequality , lemma  [ lemsteppointexp ] and fubini s theorem to get @xmath344 } \\bigl| { \\mathbb s}_n ( x ) \\bigr|^{\\alpha } \\,dx > m/2 \\biggr ) \\nonumber \\\\ & & \\qquad \\leq \\frac{2}{m } 2^{\\alpha-1 } \\biggl \\{\\int_{(a+ \\tilde{c}_0/n , b ] } e \\bigl| { \\mathbb s}_n ( x)_+ \\bigr|^{\\alpha }",
    "\\,dx + \\int_{(a+ \\tilde{c}_0/n , b ] } e \\bigl| { \\mathbb s}_n ( x)_- \\bigr|^{\\alpha } \\,dx \\biggr\\ } \\\\ & & \\qquad \\le \\frac{2^\\alpha c}{m } \\biggl\\{\\int_{(a , b ] } ( x - a)^{-\\alpha/2 } \\,dx + \\int_{(a , b ] } ( b - x)^{-\\alpha/2 } \\,dx \\biggr\\ } \\leq\\widetilde c / m\\nonumber \\ ] ] for some new , finite , constant @xmath345 depending on @xmath346 , noting that @xmath347 . combining ( [ lineboundfirstterm ] ) and ( [ lineboundsecondterm ] ) yields ( [ tightnesspart1 ] ) for our choice of @xmath6 .",
    "now , to prove ( [ tightnesspart2 ] ) . since @xmath348 is constant for @xmath349",
    "$ ] for each @xmath350 , the processes @xmath351 , are piecewise monotone , and hence the convergence in @xmath352)$ ] for @xmath353 and each @xmath354 follows as in @xcite , corollary 2 , page 1260 .",
    "we conclude that ( [ tightnesspart2 ] ) holds , and hence @xmath355 is tight in @xmath356 when @xmath347 .",
    "proof of corollary [ corstep ] convergence follows immediately by continuity of the linear functional @xmath357 by hlder s inequality .",
    "we need only check the final form , that is , @xmath358 is equal to @xmath359      we next consider the case that @xmath360 can be written in the form ( [ defklform ] ) with condition .",
    "let @xmath361 , denote independent standard brownian bridge processes ( each defined on @xmath77 $ ] ) , and for each @xmath350 define @xmath362 as in remark [ remmisslocal ] with @xmath363 $ ] replacing @xmath38 $ ] .",
    "also , let @xmath231 be an independent multivariate normal with mean zero and covariance @xmath232 for @xmath233 , where @xmath364 .",
    "[ stepmiss ] suppose that @xmath7 satisfies conditions and with @xmath365 and that @xmath36 satisfies condition .",
    "then @xmath234 converges weakly to @xmath366 in @xmath323 for @xmath367 , where @xmath368}(x).\\end{aligned}\\ ] ]    [ corstepmiss ] suppose that @xmath7 satisfies conditions and with and that @xmath36 satisfies condition .",
    "then @xmath369 , where @xmath370 with @xmath144 and @xmath248 defined as in ( [ linedefg ] ) .",
    "the proof of these results is very close to that of proposition [ step ] , and we omit any details which are the same .",
    "the difference lies in the following modifications to lemmas [ lemahstronger ] and [ lemexpbounds ] .",
    "note that we add the additional requirement that @xmath6 be bounded below .",
    "[ lemahstrongermiss ] fix a point @xmath371 and let @xmath38 $ ] denote the largest interval @xmath74 such that @xmath372 and @xmath7 is constant on @xmath74 .",
    "then , for all @xmath252 , @xmath373    by the switching relation , it follows that @xmath374 } \\bigl\\{{\\mathbb f}_n(z)- \\bigl(\\hat f_0(b)+t \\bigr)z \\bigr\\}<a+u / n \\bigr ) \\\\ & & \\qquad = p \\bigl(n \\bigl(\\mathop{\\operatorname{argmax}}_{z\\in[0,1 ] } \\bigl \\{{\\mathbb f}_n(z)- \\bigl(\\hat f_0(b)+t \\bigr)z \\bigr\\}-a \\bigr)<u \\bigr)\\end{aligned}\\ ] ] and the inner process @xmath375 } \\bigl\\ { { \\mathbb f}_n(z)- \\bigl(\\hat f_0(b)+t \\bigr)z",
    "\\bigr\\}-a \\bigr ) \\\\ & & \\qquad = \\mathop{\\operatorname{argmax}}_{h\\geq - n a } \\bigl\\{{\\mathbb f}_n(a+h / n)-",
    "\\bigl(t+\\hat f_0(b ) \\bigr ) ( a+h / n ) \\bigr\\ } \\\\ & & \\qquad = \\mathop{\\operatorname{argmax}}_{h\\geq - n a } \\bigl\\{{\\mathbb v}_n(h ) \\bigr\\ } , \\ ] ] where @xmath376 , with @xmath377 and @xmath378 .    now , the term @xmath379 is binomial with mean @xmath380",
    ". therefore , @xmath381 converges to a centered poisson random variable with mean @xmath382 .",
    "a similar argument may be used to show convergence as a process of @xmath383 , where @xmath384 is a poisson process with rate @xmath385 . the second piece",
    ", @xmath386 satisfies @xmath387\\cap \\mathcal{w } - a \\bigr\\}$ , \\vspace*{2pt}\\cr < 0 , & \\quad$h \\in",
    "n \\bigl\\{[a , b]\\cap\\mathcal{m } - a \\bigr\\}$.}\\end{aligned}\\ ] ] thus , if for all @xmath388 @xmath389 then the limit of @xmath386 is @xmath390 if @xmath391 and is equal to @xmath113 otherwise [ we will call this setting case ( a ) ] . if the above assumption is not true [ we will call this setting case ( b ) ] , then @xmath392 for all @xmath393 . in case ( a )",
    ", it follows that the limit of @xmath394 is equal to 0 at @xmath391 and is equal to @xmath113 otherwise",
    ". therefore , @xmath395 here . in case",
    "( b ) , the limit of @xmath394 is a centered ( a.k.a .",
    "compensated ) poisson process with rate @xmath382 .",
    "we therefore have that , in case ( a ) , @xmath396 and in case ( b ) , @xmath397 which gives us pointwise convergence in distribution in both cases .",
    "lastly , note that @xmath398 is a constant , and @xmath399 is decreasing in  @xmath280 by definition . therefore , @xmath400 suppose that @xmath7 is flat on @xmath263 $ ] and fix @xmath264 .",
    "assume also that @xmath401 } f_0(x ) = \\alpha_0>0 $ ] , and let @xmath402 .",
    "then , for any @xmath265 and @xmath266 , there exists a constant @xmath403 such that @xmath404 for all @xmath269 .",
    "also , for all @xmath405 $ ] , @xmath406 and otherwise the probability is equal to zero .",
    "let @xmath271 , and we write @xmath407 . repeating the argument for the proof of lemma [ lemexpbounds ]",
    ", we obtain that @xmath408 & & \\qquad \\leq p \\biggl(\\frac{{\\mathbb f}_n(a , s)}{f_0(a , s)}\\geq\\frac { ( \\hat\\theta+n^{-1/2}t)(s - a)}{f_0(a , s ) } , \\mbox { for some } s\\in(x,1 ] \\biggr ) \\\\[-2pt ] & & \\qquad \\leq p \\biggl(\\sup_{s\\in(x,1]}\\frac{{\\mathbb f}_n(a , s)}{f_0(a , s ) } \\geq \\inf _ { s\\in(x,1]}\\frac{(\\hat\\theta + n^{-1/2}t)(s - a)}{f_0(a , s ) } \\biggr ) \\\\[-2pt ] & & \\qquad \\leq p \\biggl(\\sup_{s\\in(x,1]}\\frac{{\\mathbb f}_n(a , s)}{f_0(a , s)}\\geq\\inf _ { s\\in(x,1]}\\frac{(\\hat\\theta + n^{-1/2}t)(s - a)}{\\widehat f_0(a , s ) } \\biggr ) \\\\[-2pt ] & & \\qquad = p \\biggl(\\sup_{s\\in(x,1]}\\frac{{\\mathbb f}_n(a , s)}{f_0(a , s)}\\geq1 + \\frac{n^{-1/2}t}{\\hat\\theta } \\biggr)\\end{aligned}\\ ] ] since @xmath409 with equality at @xmath410 . applying the exponential bounds for binomial variables as before , we find that @xmath277}\\frac{{\\mathbb f}_n(a , s)}{f_0(a , s)}\\geq1 + \\frac{n^{-1/2}t}{\\hat\\theta } \\biggr ) \\\\[-2pt ] & & \\qquad \\leq \\exp \\biggl\\{-n f_0(a , x ) h \\biggl(1 + \\frac{n^{-1/2}t}{\\hat \\theta } \\biggr ) \\biggr\\ } \\\\[-2pt ] & & \\qquad \\leq \\exp \\biggl\\{- \\biggl[\\inf _ { x\\in[a , b ] } \\frac{f_0(x)}{\\hat \\theta } \\biggr ] \\frac{t(x - a)}{2 } \\frac{t/\\hat\\theta}{1+(t/\\hat\\theta ) /(3\\sqrt{n } ) } \\biggr\\}.\\end{aligned}\\ ] ] therefore , assuming that @xmath411}\\frac{f_0(x)}{\\hat\\theta } = \\hat c_0 > 0 $ ] , we can repeat the same argument as for lemma ( [ lemexpbounds ] ) .",
    "we handle the other side in a similar manner : @xmath412 & \\leq & p \\biggl(\\inf_{s\\in[0,x)}\\frac{{\\mathbb f}_n(s , b)}{f_0(s , b)}\\leq1- \\frac{n^{-1/2}t}{\\hat\\theta } \\biggr).\\end{aligned}\\ ] ] we again bound this using the martingale inequality from @xcite , lemma 2.3 : @xmath413 & & \\qquad \\leq \\exp \\biggl\\{-n f(x , b ) h \\biggl(1-\\frac{n^{-1/2}t}{\\hat\\theta } \\biggr ) \\biggr\\ } \\\\[-2pt ] & & \\qquad = \\exp \\biggl\\{- \\biggl [ \\inf_{x\\in[a , b ] } \\frac{f_0(x)}{\\hat\\theta } \\biggr ] \\frac{t^2(b - x)}{2\\hat\\theta } \\psi \\biggl(-\\frac { n^{-1/2}t}{\\hat\\theta } \\biggr ) \\biggr\\}.\\end{aligned}\\ ] ]      proof of theorem [ teolinear ] to illustrate the method of proof , we consider a simplified case .",
    "since @xmath414 for some @xmath140 and @xmath355 converges in @xmath356 the proof easily extends to a general setting .",
    "suppose then that @xmath415 $ ] and @xmath416 $ ] , so that the support is @xmath417 $ ] .",
    "furthermore , we assume that on @xmath130 we have @xmath177 .",
    "let @xmath418 .",
    "then @xmath419 where @xmath420 . from assumptions and",
    ", it follows that @xmath421 as in proposition [ curved ] .",
    "next , let @xmath422 , and let @xmath423 for @xmath119 $ ] .",
    "lastly , let @xmath424 . then for @xmath425 $ ] , @xmath426 and we also define @xmath427 .",
    "therefore , @xmath428 is equal to @xmath429 from the definition of @xmath430 and of @xmath431 .",
    "the weak limit of @xmath432 can be established similarly as in theorem [ teomisslocal ] and remark [ remmisslocal ] .",
    "the outline of the rest of the proof proceeds as follows :    joint weak convergence of @xmath433 to a gaussian limit .",
    "joint weak convergence of @xmath434 via the switching relation .",
    "we have that @xmath435 where in proposition [ stepmiss ] we showed that the first term on the right - hand side is tight in @xmath436 .",
    "the second term on the right - hand side is a tight constant and , therefore , @xmath437 is also tight in @xmath436 .    from ( 1 ) and",
    "( 3 ) , we obtain marginal tightness of the terms @xmath438 in @xmath256 and @xmath439 in @xmath436 , which implies joint tightness in @xmath440 .",
    "the full result now follows by the continuous mapping theorem .",
    "lastly , we note that since @xmath441 at @xmath442 and @xmath431 is constant on @xmath38 $ ] then @xmath443 .",
    "the author thanks valentin patilea for sharing a copy of his thesis , takumi saegusa for pointing out a small error in one of the proofs and the referees for a number of helpful suggestions . parts of this work were completed while the author was visiting the university of washington and the university of heidelberg , and the author thanks both institutions for their hospitality and financial travel support , and in particular , tilmann gneiting for match funding .",
    "the author also thanks jon wellner for generous contributions to this work ."
  ],
  "abstract_text": [
    "<S> under the assumption that the true density is decreasing , it is well known that the grenander estimator converges at rate @xmath0 if the true density is curved [ _ sankhy ser . </S>",
    "<S> a _ </S>",
    "<S> * 31 * ( 1969 ) 2336 ] and at rate @xmath1 if the density is flat [ _ ann . </S>",
    "<S> probab . _ </S>",
    "<S> * 11 * ( 1983 ) 328345 ; _ canad . </S>",
    "<S> j. statist . _ </S>",
    "<S> * 27 * ( 1999 ) 557566 ] . in the case </S>",
    "<S> that the true density is misspecified , the results of patilea [ _ ann . statist . _ </S>",
    "<S> * 29 * ( 2001 ) 94123 ] tell us that the global convergence rate is of order @xmath0 in hellinger distance . here , we show that the local convergence rate is  @xmath1 at a point where the density is misspecified . </S>",
    "<S> this is not in contradiction with the results of patilea [ _ ann . </S>",
    "<S> statist . _ </S>",
    "<S> * 29 * ( 2001 ) 94123 ] : the global convergence rate simply comes from locally curved _ well - specified _ regions . </S>",
    "<S> furthermore , we study global convergence under misspecification by considering linear functionals . </S>",
    "<S> the rate of convergence is @xmath1 and we show that the limit is made up of two independent terms : a mean - zero gaussian term and a second term ( with nonzero mean ) which is present only if the density has well - specified locally flat regions . </S>"
  ]
}