{
  "article_text": [
    "with the popularity of online social networks ( osns ) , viral marketing has become a powerful method for companies to promote sales . in 2003 , kempe et al .",
    "@xcite first formulated the influence maximization problem : given a network @xmath5 and an integer @xmath0 , how to select a set of @xmath0 nodes in @xmath5 so that they can trigger the largest influence cascade under a predefined influence propagation model .",
    "the selected nodes are often referred to as _",
    "seed nodes_. kempe et al . proposed the _ independent cascade ( ic ) _ model and the _ linear threshold ( lt ) _ model to describe the influence propagation process .",
    "they also proved that the influence maximization problem under these two models is np - hard and a natural greedy algorithm could return @xmath6-approximate solutions for any @xmath7 .",
    "recently , tang et al .",
    "@xcite presented an algorithm with @xmath1 approximation guarantee with probability at least @xmath2 , and runs in time @xmath8 .    recognizing that companies are competing in a viral marketing , a thread of work studied the competitive influence maximization problem under a series of competitive influence propagation models , where multiple sources spread the information in a network simultaneously ( e.g. , @xcite ) .",
    "many of these work assumed that there are two companies competing with each other and studied the problem from the `` follower s perspective '' . here , the `` follower '' is the player who selects seed nodes with the knowledge that some nodes have already been selected by its opponent .",
    "for example , in the viral marketing , a company introducing new products into an existing market can be regarded as the follower and the set of consumers who have already purchased the existing product can be treated as the nodes influenced by its competitor . briefly speaking ,",
    "the problem of _ competitive influence maximization ( cim ) _ is defined as the following : suppose we are given a network @xmath5 and the set of _ seed nodes _ selected by our competitor , how to select the _",
    "seed nodes _ for our product in order to trigger the largest influence cascade ?",
    "these optimization problems are np - hard in general .",
    "therefore , the selection of seed nodes is relied either on computationally expensive greedy algorithms with @xmath1 approximation guarantee , or on heuristic algorithms with no approximation guarantee .    to the best of our knowledge ,",
    "for the cim problem , there exists no algorithm with both @xmath1 approximation guarantee and practical runtime efficiency .",
    "furthermore , besides the existing models , we believe that there will be more competitive influence propagation models proposed for different applications in the future .",
    "therefore , we need a _",
    "general framework _ that can solve the competitive influence maximization problem under a variety of propagation models .",
    "* contributions*. we make the following contributions :    * we define a _ general competitive independent cascade ( gcic ) _ model and formally formulate the _ competitive influence maximization ( cim ) _ problem . * for the cim problem under a predefined gcic model , we provide a _ two - phase competitive influence maximization ( tcim ) _ algorithmic framework generalizing the algorithm in @xcite .",
    "tcim returns a @xmath1-approximate solution with probability at least @xmath2 , and runs in @xmath9 , where @xmath4 depends on specific propagation model , seed - set size @xmath0 and network @xmath5 .",
    "* we analyze the performance of tcim under three specific influence propagation models of the gcic model as reported in literature @xcite and @xcite .",
    "* we conduct extensive experiments on real - world datasets to demonstrate the efficiency and effectiveness of tcim .",
    "in particular , when @xmath10 , @xmath11 and @xmath12 , tcim returns solutions comparable with those returned by the previous state - of - the - art greedy algorithms , but tcim runs _ up to four orders of magnitude",
    "faster_.    this is the outline of our paper .",
    "background and related work are given in section [ sec : related ] .",
    "we define the _ general competitive independent cascade _ model and the _ competitive influence maximization _ problem in section [ sec : problem ] .",
    "we present the tcim framework in section [ sec : solution ] and analyze the performance of tcim under various influence propagation models in section [ sec : application ] .",
    "we compare tcim with the greedy algorithm with performance guarantee in section [ sec : comparison ] , and show the experimental results in section [ section : experiments ] .",
    "section [ sec : conclusion ] concludes .",
    "* single source influence maximization . * in the seminal work  @xcite , kempe et al . proposed the _ independent cascade ( ic ) model _ and the _ linear - threshold ( lt ) model _ and formally defined the _ influence maximization problem_. in the ic model , a network @xmath5 is given as @xmath13 and each edge @xmath14 is associated with a probability @xmath15 .",
    "initially , a set of nodes @xmath16 are _ active _ and @xmath16 is often referred to as the _ seed nodes_. each active node @xmath17 has a single chance to influence its inactive neighbor @xmath18 and succeeds with probability @xmath15 .",
    "let @xmath19 be the expected number of nodes @xmath16 could activate , the _ influence maximization problem _ is defined as how to select a set of @xmath0 nodes such that @xmath19 is maximized .",
    "this problem , under both the ic model and the lt model , is np - hard .",
    "however , kempe et al .",
    "@xcite showed that if @xmath19 is a monotone and submodular function of @xmath16 , a greedy algorithm can return a solution within a factor of @xmath1 for any @xmath20 , in polynomial time .",
    "the research on this problem went on for around ten years ( e.g. , @xcite ) , but it is not until very recently , that borgs et al .",
    "@xcite made a breakthrough and presented an algorithm that simultaneously maintains the performance guarantee and significantly reduces the time complexity .",
    "recently , tang et al .",
    "@xcite further improved the method in @xcite and presented an algorithm tim / tim@xmath21 , where _ tim _ stands for _ two - phase influence maximization_. it returns a @xmath1-approximate solution with probability at least @xmath2 and runs in time @xmath8 , where @xmath22 and @xmath23 .    * competitive influence maximization .",
    "* we review some work that modeled the competition between two sources and studied the influence maximization problem from the `` _ follower s perspective _ '' . in general , the majority of these works considered competition between two players ( e.g. , two companies ) , and the `` follower '' is the player who selects the set of _ seed nodes _ with the knowledge of the seed nodes selected by its competitor . in @xcite , carnes et al . proposed the _ distance - based model _ and the _ wave propagation model _ to describe the influence spread of competing products and considered the influence maximization problem from the follower s perspective .",
    "bharathi et al .",
    "@xcite proposed an extension of the single source ic model and utilized the greedy algorithm to compute the best response to the competitor .",
    "motivated by the need to limit the spread of rumor in the social networks , there is a thread of work focusing on how to maximize rumor containment ( e.g. , @xcite ) .",
    "for example , budak et al .",
    "@xcite models the competition between the `` bad '' and `` good '' source .",
    "they focused on minimizing the number of nodes end up influenced by the `` bad '' source .",
    "in this section , we first introduce the `` _ _ general competitive independent cascade ( gcic ) _ _ '' model which models the influence propagation of two competing sources in the same network . based on the gcic model",
    ", we then formally define the _ competitive influence maximization ( cim ) _ problem .",
    "let us first define the _ general competitive independent cascade ( gcic ) _ model .",
    "a social network can be modeled as a directed graph @xmath13 with @xmath24 nodes and @xmath25 edges .",
    "users in the social network are modeled as nodes while directed edges between nodes represent the interaction between users .",
    "a node @xmath18 is a neighbor of node @xmath17 if there is an edge from @xmath17 to @xmath18 in @xmath5 .",
    "every edge @xmath26 is associated with a length @xmath27 and a probability @xmath15 denoting the influence node @xmath17 has on @xmath18 . for @xmath28 ,",
    "we assume @xmath29 and @xmath30 . for the ease of presentation",
    ", we assume the length of all edges is @xmath31 .",
    "our algorithm and analysis can be easily extended to the case where edges have nonuniform lengths .",
    "denote source @xmath32 and source @xmath33 as two sources that simultaneously spread information in the network @xmath5 .",
    "a node @xmath34 could be in one of these three states : @xmath16 , @xmath35 and @xmath36 .",
    "nodes in state _ s _ , the _ susceptible state _ ,",
    "have not been influenced by any source .",
    "nodes in state @xmath35 ( resp .",
    "@xmath36 ) are influenced by source @xmath32 ( resp .",
    "@xmath33 ) . once a node becomes influenced , it can not change its state .",
    "initially , source @xmath32 and source @xmath33 can each specify a set of seed nodes , which we denote as @xmath37 and @xmath38 .",
    "we refer to nodes in @xmath39 ( resp .",
    "@xmath40 ) as _ seeds _ or _ initial adopters _ of source @xmath32 ( resp .",
    "@xmath33 ) . following the previous work that modeled the competitive influence propagation ( e.g. , @xcite )",
    ", we also assume @xmath41 .    as in the single source",
    "_ independent cascade ( ic ) _ model , an influenced node @xmath17 influences its neighbor @xmath18 with probability @xmath15 and we say each edge @xmath26 is _ active _ with probability @xmath15 .",
    "we can first determine the set of _ active _ edges @xmath42 by generating a random number @xmath43 $ ] for every edge @xmath26 , and select @xmath44 when @xmath45 .",
    "let @xmath46 be the shortest distance from @xmath18 to @xmath17 through edges in @xmath47 and assume @xmath48 if @xmath18 can not reach @xmath17 through active edges .",
    "moreover , let @xmath49 be the shortest distance from nodes in @xmath50 to node @xmath17 through edges in @xmath47 .",
    "for a given @xmath47 , we say a node @xmath18 is a _ nearest initial adopter _ of @xmath17 if @xmath51 and @xmath52 . in the gcic model , for a given @xmath47 , a node @xmath17 will be in the same state as that of one of its _ nearest initial adopters _ at the end of the influence propagation process .",
    "the expected influence of @xmath40 is the expected number of nodes in state @xmath36 at the end of the influence propagation process , where the expectation is taken over the randomness of @xmath47 .",
    "specific influence propagation model of the gcic model will specify how the influence propagates in detail , including the tie - breaking rule for the case where both nodes in @xmath39 and @xmath40 are nearest initial adopters of a node .    moreover , we make the following assumptions about the gcic model",
    ". given @xmath39 , let @xmath53 be conditional probability that node @xmath17 will be influenced by source @xmath33 when @xmath40 is used as the seed set for source @xmath33 .",
    "we assume that @xmath53 is a monotone and submodular function of @xmath54 for all @xmath55 .",
    "formally , for any seed set @xmath37 , @xmath56 and node @xmath57 , we have @xmath58 and @xmath59 hold for all @xmath55 .",
    "let @xmath60 be the expected influence of @xmath40 given @xmath39 , because @xmath61 , @xmath60 is also a monotone and submodular function of @xmath54 .",
    "we call this the _ general competitive independent cascade _ model because for any given graph @xmath62 and @xmath38 , the expected influence of @xmath40 given @xmath63 equals to the expected influence of @xmath40 in the single source ic model .",
    "note that there are some specific instances of the gcic model , for example , the _ distance - based model _ and the _ wave propagation model _ @xcite .",
    "we will elaborate on them in later sections .      given a directed graph @xmath5 , a specific instance of the _ general competitive independent cascade _ model ( e.g. , the distance - based model ) , and seeds @xmath39 for source @xmath32 ,",
    "let us formally define the _ competitive influence maximization _ problem .",
    "suppose we are given a specific instance of the _ general competitive independent cascade _ model ( e.g. , the distance - based model ) , a graph @xmath62 and the seed set @xmath64 for source @xmath32 , find a set @xmath65 of @xmath0 nodes for source @xmath33 such that the expected influence of @xmath65 given @xmath39 is maximized , i.e. , @xmath66    for the above problem , we assume @xmath67 .",
    "otherwise , we can simply select all nodes in @xmath68 .",
    "the _ competitive influence maximization _ ( cim ) problem is np - hard in general . in this paper ,",
    "our goal is to provide an approximate solution to the cim problem with an approximation guarantee and at the same time , with practical run time complexity .",
    "in this section , we present the _ two - phase competitive influence maximization ( tcim ) _ algorithm to solve the _ competitive influence maximization _ problem .",
    "we extend the tim / tim@xmath21 algorithm  @xcite , which is designed for the single source influence maximization problem , to a general framework for the cim problem under any specific instance of the _ general competitive independent cascade _ model , while maintaining the @xmath6 approximation guarantee and practical efficiency .",
    "let us first provide some basic definitions and give the high level idea of the tcim .",
    "then , we provide a detailed description and analysis of the two phases of the tcim algorithm , namely the _ parameter estimation and refinement _ phase , and the _ node selection _ phase .",
    "motivated by the definition of `` rr sets '' in @xcite and @xcite , we define the _ reverse accessible pointed graph ( rapg)_. we then design a _ scoring system _ such that for a large number of random rapg instances and given seed sets @xmath39 and @xmath40 , the average score of @xmath40 for each rapg instance is a good approximation of the expected influence of @xmath40 given @xmath39 .",
    "let @xmath69 be the shortest distance from @xmath17 to @xmath18 in a graph @xmath70 and assume @xmath71 if @xmath17 can not reach @xmath18 in @xmath70 .",
    "let @xmath72 be the shortest distance from nodes in set @xmath16 to node @xmath18 through edges in @xmath70 , and assume @xmath73 if @xmath74 or @xmath75 but there are no paths from nodes in @xmath16 to @xmath18 .",
    "we define the _ reverse accessible pointed graph ( rapg ) _ and the random rapg instance as the following .    for a given node @xmath18 in @xmath5 and a subgraph @xmath70 of @xmath5 obtained by removing each edge",
    "@xmath44 in @xmath5 with probability @xmath76 , let @xmath77 be the reverse accessible pointed graph ( rapg ) obtained from @xmath18 and @xmath70 .",
    "the node set @xmath78 contains @xmath55 if @xmath79 . and",
    "the edge set @xmath80 contains edges on all shortest paths from nodes in @xmath78 to @xmath18 through edges in @xmath70 .",
    "we refer to @xmath18 as the `` root '' of @xmath81 .",
    "let @xmath82 be the distribution of @xmath70 induced by the randomness in edge removals from @xmath5 .",
    "a random rapg instance @xmath81 is a reverse accessible pointed graph ( rapg ) obtained from a randomly selected node @xmath34 and an instance of @xmath70 randomly sampled from @xmath82 .",
    "figure [ fig : rapg ] shows an example of a random rapg instance @xmath77 with @xmath83 and @xmath84 .",
    "the `` root '' of @xmath81 is node @xmath85 .",
    "contains @xmath86 nodes and @xmath87 directed edges each represented by an arrow .",
    "the random subgraph @xmath70 is obtained from @xmath5 by removing @xmath88 directed edges represented by dashed arrows , i.e. , @xmath89 , @xmath90 and @xmath91 . from @xmath70 and the randomly selected `` root '' node @xmath92 , we get the random rapg instance @xmath77 where @xmath83 and @xmath93.,scaledwidth=30.0% ]    now we present the _ scoring system_. for a random rapg instance @xmath77 obtained from @xmath18 and @xmath94 ,",
    "the score of a node set @xmath40 in @xmath81 is defined as follows .",
    "[ def : score ] suppose we are given a random rapg instance @xmath77 obtained from @xmath18 and @xmath94 .",
    "the score of a node set @xmath40 in @xmath81 , denoted by @xmath95 , is defined as the probability that node @xmath18 will be influenced by source @xmath33 when 1 ) the influence propagates in graph @xmath70 with all edges being `` active '' ; and 2 ) @xmath96 and @xmath97 are seed sets for source @xmath32 and @xmath33 .",
    "recall that for the _ general competitive independent cascade _ model , we assume that for any node @xmath55 , the conditional probability @xmath53 is a monotone and submodular function of @xmath98 .",
    "it follows that , for any given @xmath39 and @xmath81 , @xmath95 is also a monotone and submodular function of @xmath54 .",
    "furthermore , we define the marginal gain of the score as follows .    for a random rapg instance @xmath81 with root @xmath18 ,",
    "we denote @xmath99 as the marginal gain of score if we add @xmath100 to the seed set @xmath40 .    from the definition of gcic model and",
    "that of the rapg , we know that for any rapg instance @xmath81 obtained from @xmath18 and @xmath70 , @xmath81 contains all nodes that can possibly influence @xmath18 and all shortest paths from these nodes to @xmath18 .",
    "hence , for any given @xmath39 , @xmath40 and node @xmath100 , once an instance @xmath81 is constructed , the evaluation of @xmath95 and @xmath101 can be done based on @xmath81 without the knowledge of @xmath70 .    from definition [ def :",
    "score ] , for any @xmath54 , the expected value of @xmath95 over the randomness of @xmath81 equals to the probability that a randomly selected node in @xmath5 can be influenced by @xmath40 .",
    "formally , we have the following lemma .",
    "[ lemma : eisb ] for given seed set @xmath39 and @xmath40 , we have @xmath102\\ ] ] where the expectation of @xmath103 $ ] is taken over the randomness of @xmath81 , and @xmath104 is the number of nodes in @xmath5 , or @xmath22 .",
    "now we provide the chernoff - hoeffding bound in the form that we will frequently use throughout this paper .",
    "[ lemma : hoeffding ] let @xmath105 be the summation of @xmath106 i.i.d .",
    "random variables bounded in @xmath107 $ ] with a mean value @xmath108 .",
    "then , for any @xmath109 , @xmath110&\\leq   \\exp\\big(-\\frac{\\delta^2}{2+\\delta}\\cdot \\theta\\mu\\big),\\\\ \\pr[x<(1-\\delta)\\theta\\mu]&\\leq   \\exp\\big(-\\frac{\\epsilon^2}{2}\\cdot \\theta\\mu\\big).\\end{aligned}\\ ] ]    by lemma [ lemma : eisb ] and chernoff - hoeffding bound , for a sufficiently large number of random rapg instances , the average score of a set @xmath40 in those rapg instances could be a good approximation to the expected influence of @xmath40 in @xmath5 .",
    "the main challenge is how to determine the number of rapg required , and how to select seed nodes for source @xmath33 based on a set of random rapg instances .",
    "similar to the work in @xcite , tcim consists of two phases as follows .    1 .   _",
    "parameter estimation and refinement _ : suppose @xmath65 is the optimal solution to the _ competitive influence maximization problem _ and let @xmath111 be the expected influence of @xmath65 given @xmath39 . in this phase , tcim estimates and refines a lower bound of @xmath112 and uses the lower bound to derive a parameter @xmath106 .",
    "node selection _ : in this phase , tcim first generates a set @xmath113 of @xmath106 random rapg instances of @xmath5 , where @xmath106 is a sufficiently large number obtained in the previous phase . using the greedy approach , tcim returns a set of seed nodes @xmath40 for source @xmath33 with the goal of maximizing @xmath114 .",
    "algorithm [ algo : node selection ] shows the pseudo - code of the _ node selection _ phase .",
    "given a graph @xmath5 , the seed set @xmath39 of source @xmath32 , the seed set size @xmath0 for source @xmath33 and a constant @xmath106 , the algorithm returns a seed set @xmath40 of @xmath0 nodes for source @xmath33 with a large influence spread .",
    "in line [ algo : node selection start]-[algo : node selection : initmg ] , the algorithm generates @xmath106 random rapg instances and initializes @xmath115 for all nodes @xmath116 .",
    "then , in line [ algo : node selection : ite s ] - [ algo : node selection : ite e ] , the algorithm selects seed nodes @xmath40 iteratively using the greedy approach with the goal of maximizing @xmath114 .",
    "generate a set @xmath113 of @xmath106 random rapg instances .",
    "[ algo : node selection start ] let @xmath117 for all @xmath118 .",
    "[ algo : node selection : initmg ] initialize the seed set @xmath119.[algo : node selection : ite s ] identity the node @xmath120 with largest @xmath121 .",
    "add @xmath122 to @xmath40 . //",
    "update @xmath123 as @xmath124 // for all @xmath125 .",
    "let @xmath126 .",
    "[ algo : node selection : mgs ] @xmath127 @xmath128 .",
    "[ algo : node selection : mge ] [ algo : node selection : ite e ] @xmath40 [ algo : node selection end ]    * generation of rapg instances . *",
    "we adapt the randomized breadth - first search used in borg et al.s method  @xcite and tang et al.s algorithm  @xcite to generate random rapg instances .",
    "we first randomly pick a node @xmath129 in @xmath5 . then",
    ", we create a queue containing a single node @xmath129 and initialize the rapg instance under construction as @xmath130 . for all @xmath55 ,",
    "let @xmath131 be the shortest distance from @xmath17 to @xmath129 in the current @xmath81 and let @xmath132 if @xmath17 can not reach @xmath129 in @xmath81 .",
    "we iteratively pop the node @xmath18 at the top of the queue and examine its incoming edges . for each incoming neighbor @xmath17 of @xmath18 satisfying @xmath133 , we generate a random number @xmath134 $ ] . with probability @xmath15 ( i.e. @xmath135 )",
    ", we insert @xmath44 into @xmath81 and we push node @xmath17 into the queue if it has not been pushed into the queue before . if we push a node @xmath17 of @xmath39 into the queue while examining the incoming edge of a node @xmath18 with @xmath136 , we terminate the breadth - first search after we have examined incoming edges of all nodes whose distance to @xmath129 in @xmath81 is @xmath137 . otherwise , the breadth - first search terminates naturally when the queue becomes empty .",
    "if reverse the direction of all edges in @xmath81 , we obtain an accessible pointed graph with `` root ''",
    "@xmath129 , in which all nodes are reachable from @xmath129 . for this reason , we refer to @xmath129 as the `` root '' of @xmath81",
    ".    * greedy approach .",
    "* let @xmath138 for all @xmath54 .",
    "line [ algo : node selection : ite s]-[algo : node selection : ite e ] in algorithm [ algo : node selection ] uses the greedy approach to select a set of nodes @xmath40 with the goal of maximizing @xmath139 .",
    "since the function @xmath95 is a monotone and submodular function of @xmath54 for any rapg instance @xmath81 , we can conclude that @xmath139 is also a monotone and submodular function of @xmath54 for any @xmath113 .",
    "hence , the greedy approach in algorithm [ algo : node selection ] could return a @xmath140 approximation solution  @xcite .",
    "formally , let @xmath65 be the optimal solution , the greedy approach returns a solution @xmath40 such that @xmath141 .    * the `` marginal gain vector '' . * during the greedy selection process",
    ", we maintain a vector @xmath142 such that @xmath143 holds for current @xmath40 and all @xmath144 .",
    "we refer to @xmath142 as the `` _ marginal gain vector _ '' .",
    "the initialization of @xmath142 could be done during or after the generation of random rapg instances , whichever is more efficient . at the end of each iteration of the greedy approach ,",
    "we update @xmath142 .",
    "suppose in one iteration , we expand the previous seed set @xmath145 by adding a node @xmath122 and the new seed set is @xmath146 . for any rapg instance @xmath81 such that @xmath147 , we would have @xmath148 for all @xmath149 . and for any rapg instance @xmath81 such that @xmath150 , for all @xmath144 , we would have @xmath151 and the marginal gain of score can not be further decreased .",
    "to conclude , for a given rapg instance @xmath77 and a node @xmath152 , @xmath153 differs from @xmath154 only if @xmath155 and @xmath156 .",
    "hence , to update @xmath123 as @xmath124 for all @xmath144 , it is not necessary to compute @xmath153 for all @xmath157 and @xmath158 .",
    "note that for any rapg instance @xmath81 , @xmath159 implies @xmath155 and @xmath160 .",
    "therefore , line [ algo : node selection : mgs]-[algo : node selection : mge ] do the update correctly",
    ".    * time complexity analysis .",
    "* let @xmath161 $ ] be the expected number of random numbers required to generate a random rapg instance , the time complexity of generating @xmath106 random rapg instances is @xmath162)$ ] .",
    "let @xmath163 $ ] be the expected number of edges in a random rapg instance , which is no less than the expected number of nodes in a random rapg instance .",
    "we assume that the initialization and update of @xmath142 takes time @xmath164)$ ] . here",
    ", @xmath165 depends on specific influence propagation model and may also depend on @xmath0 and @xmath5 .",
    "in each iteration , we go through @xmath123 for all nodes @xmath149 and select a node with the largest value , which takes time @xmath166 .",
    "hence , the total running time of algorithm [ algo : node selection ] is @xmath167 + c\\theta\\cdot \\mathbb{e}\\left[|e_r|\\right])$ ] . moreover , from the fact that @xmath163\\leq \\mathbb{e}[n_r]$ ] and @xmath165 , the total running time can be written in a more compact form as @xmath168).\\ ] ] in section [ sec : application ] , we will show the value of @xmath4 and provide the total running time of the tcim algorithm for several influence propagation models .    * the approximation guarantee . * from lemma [ lemma : eisb ]",
    ", we see that the larger @xmath106 is , the more accurate is the estimation of the expected influence .",
    "the key challenge now becomes how to determine the value of @xmath106 , i.e. , the number of rapg instances required , so to achieve certain accuracy of the estimation .",
    "more precisely , we would like to find a @xmath106 such that the node selection algorithm returns a @xmath6-approximation solution .",
    "at the same time , we also want @xmath106 to be as small as possible since it has the direct impact on the running time of algorithm [ algo : node selection ] .    using the chernoff - hoeffding bound",
    ", the following lemma shows that for a set @xmath113 of sufficiently large number of random rapg instances , @xmath169 could be an accurate estimate of the influence spread of @xmath40 given @xmath39 , i.e. , @xmath60 .",
    "[ lemma : theta requirement ] suppose we are given a set @xmath113 of @xmath106 random rapg instances , where @xmath106 satisfies @xmath170 then , with probability at least @xmath2 , @xmath171 holds for all @xmath54 with @xmath0 nodes .",
    "first , let @xmath40 be a given seed set with @xmath0 nodes .",
    "let @xmath172 $ ] , @xmath138 can be regarded as the sum of @xmath106 i.i.d .",
    "variables with a mean @xmath108 . by lemma [ lemma : eisb ] , we have @xmath173 .",
    "thus , by chernoff - hoeffding bound , @xmath174 \\\\ = & \\pr\\left[\\left|f_\\mathcal{r}(s_b|s_a)-\\theta\\cdot \\mu\\right|      \\geq \\frac{\\epsilon opt}{2n\\mu}\\cdot \\theta\\mu\\right ] \\\\",
    "\\leq & 2\\exp\\left(-\\frac{(\\frac{\\epsilon opt}{2n\\mu})^2 }      { 2+\\frac{\\epsilon opt}{2n\\mu}}\\!\\cdot\\!\\theta\\mu\\right ) \\!=\\ ! 2\\exp\\left(-\\frac{\\epsilon^2 opt^2}{8n^2\\mu+2\\epsilon n opt }      \\!\\cdot\\ ! \\theta\\right)\\\\ \\leq & 2\\exp\\left(-\\frac{\\epsilon^2 opt}{(8 + 2\\epsilon)\\cdot n}\\cdot \\theta\\right ) \\leq n^{-\\ell}/\\binom{n}{k}.\\end{aligned}\\ ] ] the last step follows by inequality ( [ eq : theta requirement ] ) .",
    "there are at most @xmath175 node set @xmath54 with @xmath0 nodes . by union bound , with probability",
    "at least @xmath2 , inequality ( [ eq : theta estimate accuracy ] ) holds for all @xmath54 with @xmath0 nodes .    for the value of @xmath106 in algorithm [ algo : node selection ]",
    ", we have the following theorem .    [",
    "theorem : theta requirement ] given that @xmath106 satisfies inequality ( [ eq : theta requirement ] ) , returns a solution with @xmath1 approximation with probability at least @xmath2 .",
    "suppose we are given a set @xmath113 of @xmath106 random rapg instances where @xmath106 satisfies inequality ( [ eq : theta requirement ] ) .",
    "let @xmath40 be the set of nodes returned by algorithm [ algo : node selection ] and let @xmath65 be the set that maximizes @xmath176 . as we are using a @xmath140 greedy approach to select @xmath40 , we have @xmath141 .",
    "let @xmath177 be the optimum seed set for source @xmath33 , i.e. , the set of nodes that maximizes the influence spread of @xmath33 .",
    "we have @xmath178 .    by lemma",
    "[ lemma : theta requirement ] , with probability at least @xmath2 , we have @xmath179 holds simultaneously for all @xmath54 with @xmath0 nodes",
    ".    thus , we can conclude @xmath180 which completes the proof .",
    "by theorem [ theorem : theta requirement ] , let @xmath181 , we know algorithm [ algo : node selection ] returns a @xmath1-approximate solution for any @xmath182 .",
    "the goal of our parameter estimation algorithm is to find a lower bound @xmath183 of @xmath112 so that @xmath184 . here ,",
    "the subscript `` e '' of @xmath185 is short for `` estimated '' .",
    "* lower bound of @xmath112 . *",
    "we first define graph @xmath186 as a subgraph of @xmath5 with all edges pointing to @xmath39 removed , i.e. , @xmath187 . let @xmath188 . then , we define a probability distribution @xmath189 over the nodes in @xmath68 , such that the probability mass for each node is proportional to its number of incoming neighbors in @xmath190 .",
    "suppose we take @xmath0 samples from @xmath191 and use them to form a node set @xmath192 with duplicated nodes eliminated .",
    "a natural lower bound of @xmath112 would be the expected influence spread of @xmath192 given the seeds for source @xmath32 is @xmath39 , i.e. , @xmath193 .",
    "furthermore , any lower bound of @xmath193 is also a lower bound of @xmath112 . in the following lemma ,",
    "we present a lower bound of @xmath193 .",
    "[ lemma : lower bound opt ] let @xmath81 be a random rapg instance and let @xmath194 .",
    "we define the width of @xmath81 , denoted by @xmath195 , as the number of edges in @xmath5 pointing to nodes in @xmath196 .",
    "then , we define @xmath197 we have @xmath198\\leq \\sigma(s_b^+|s_a)$ ] , where the expectation of @xmath199 $ ] is taken over the randomness of @xmath81 .",
    "let @xmath192 be a set formed by @xmath0 samples from @xmath191 with duplicated nodes eliminated and suppose we are given a random rapg instance @xmath81 .",
    "let @xmath200 be the probability that @xmath192 overlaps with @xmath196 .",
    "for any @xmath192 , we have @xmath201 by definition of the scoring system . moreover , if @xmath192 overlaps with @xmath196 , we would have @xmath202 .",
    "hence , @xmath203 holds and @xmath204\\leq n\\cdot \\mathbb{e}[f_r(s_b^+|s_a)]=\\sigma(s_b^+|s_a)$ ] follows from lemma [ lemma : eisb ] . furthermore , suppose we randomly select @xmath0 edges from @xmath205 and form a set @xmath206 .",
    "let @xmath207 be the probability that at least one edge in @xmath206 points to a node in @xmath196 .",
    "it can be verified that @xmath208 . from the definition of @xmath195 , we have @xmath209 .",
    "therefore , we can conclude that @xmath210=\\mathbb{e}[p_2(r)]=\\mathbb{e}[p_1(r ) ] \\leq \\sigma(s_b^+|s_a)/n,\\ ] ] which completes the proof .",
    "let @xmath211 $ ] .",
    "then , lemma [ lemma : lower bound opt ] shows that @xmath185 is a lower bound of @xmath112 .",
    "* estimation of the lower bound .",
    "* by lemma [ lemma : lower bound opt ] , we can estimate @xmath185 by first measuring @xmath212 on a set of random rapg instances and then take the average of the estimation . by chernoff - hoeffding bound , to obtain an estimation of @xmath185 within @xmath213 $ ] relative error with probability at least @xmath2 ,",
    "the number of measurements required is @xmath214 .",
    "the difficulty is that we usually have no prior knowledge about @xmath185 . in @xcite , tang et al .",
    "provided an adaptive sampling approach which dynamically adjusts the number of measurements based on the observed sample value .",
    "suppose @xmath63 , the lower bound @xmath185 we want to estimate equals to the lower bound of maximum influence spread estimated in @xcite .",
    "hence , we apply tang et al.s approach directly and algorithm [ algo : estimate lb ] shows the pseudo - code that estimates @xmath185 .",
    "let @xmath215 .",
    "let @xmath216 .",
    "generate a random rapg instance @xmath81 and calculate @xmath217 .",
    "update @xmath218 .",
    "@xmath219 . @xmath220 .    for algorithm [ algo : estimate lb ]",
    ", the theoretical analysis in @xcite can be applied directly and the following theorem holds . for the proof of theorem [",
    "theorem : lb star ] , we refer interested readers to @xcite .    [",
    "theorem : lb star ] when @xmath221 and @xmath222 , algorithm [ algo : estimate lb ] returns @xmath223 $ ] with at least @xmath2 probability , and has expected running time @xmath224 .",
    "furthermore , @xmath225<12/lb_\\text{e}$ ] .    * running time of the node selection process .",
    "* we have shown how to estimate a lower bound of @xmath112 , now we analyze assuming @xmath226 . from @xmath227 and",
    "theorem [ theorem : theta requirement ] , we know returns a @xmath1-approximate solution with high probability .",
    "now we analyze the running time of algorithm [ algo : node selection ] .",
    "the running time of building @xmath106 random rapg instances is @xmath162)=o(\\frac{\\lambda}{lb_\\text{e}^ * } \\cdot \\mathbb{e}[n_r])$ ] where @xmath161 $ ] is the expected number of random numbers generated for building a random rapg instance .",
    "the following lemma shows the relationshp between @xmath185 and @xmath161 $ ] .",
    "[ lemma : erand leq lb ] @xmath228 $ ] .    for",
    "a given rapg instance @xmath81 , recall that @xmath195 is defined as the number of edges in @xmath5 pointing to any node @xmath55 such that @xmath118 and @xmath229 .",
    "if we generate a random number for an edge @xmath26 during the generation of @xmath81 , we know @xmath230 and @xmath231 . hence , the number of random number generated during the generation of @xmath81 is no more than @xmath195 and we have @xmath161\\leq \\mathbb{e}[w(r)]$ ] .",
    "moreover , we can conclude that @xmath232 \\leq & n\\cdot\\mathbb{e}\\left[\\frac{w(r)}{m}\\right ] \\leq n\\cdot\\sum_r \\left(\\pr(r)\\cdot \\frac{w(r)}{m'}\\right ) \\\\",
    "\\leq & n\\cdot\\sum_r \\left(\\pr(r)\\cdot \\alpha(r)\\right ) = n\\cdot\\mathbb{e}[\\alpha(r)],\\end{aligned}\\ ] ] which completes the proof .    based on theorem [ theorem : lb star ] showing @xmath233=o(1/lb_\\text{e})$ ] and lemma [ lemma : erand leq lb ] showing @xmath234\\cdot n / m$ ]",
    ", we can conclude that @xmath235/lb_\\text{e}^*\\right]=o(1+m / n)$ ] .",
    "recall that the greedy selection process in algorithm [ algo : node selection ] has time complexity @xmath236)$ ] .",
    "let @xmath237 , the total running time of algorithm [ algo : node selection ] becomes @xmath238/lb_\\text{e}^{*}\\big ) \\!=\\!o\\left(c(\\ell\\!+\\!k)(m\\!+\\!n)\\log n/\\epsilon^{2}\\right)$ ] .      as discussed before ,",
    "if the lower bound of @xmath112 is tight , our algorithm will have a short running time .",
    "the current lower bound @xmath185 is no greater than the expected influence spread of a set of @xmath0 independent samples from @xmath189 , with duplicated eliminated .",
    "hence , @xmath185 is often much smaller than the @xmath112 . to narrow the gaps between the lower",
    "bound we get in algorithm [ algo : estimate lb ] and @xmath112 , we use a greedy algorithm to find a seed set @xmath145 based on the limited number of rapg instances we have already generated in algorithm [ algo : estimate lb ] , and estimate the influence spread of @xmath145 with a reasonable accuracy .",
    "then , the intuition is that we can use a creditable lower bound of @xmath239 or @xmath240 , whichever is larger , as the _ refined _ bound .",
    "algorithm [ algo : refine lb ] describes how to refine the lower bound .",
    "uses the greedy approach to find a seed set @xmath145 based on the rapg instances generated in algorithm [ algo : estimate lb ] .",
    "intuitively , @xmath145 should have a large influence spread when used as seed set for source @xmath33 .",
    "line [ algo : refine lb : influence s]-[algo : refine lb : influence e ] estimates the expected influence of @xmath145 , i.e. @xmath239 . by lemma [ lemma : eisb ] , let @xmath241 be a set of rapg instances , @xmath242 is an unbiased estimation of @xmath239 .",
    "algorithm [ algo : refine lb ] generates a sufficiently large number of rapg instances and put them into @xmath241 such that @xmath243 holds with high probability .",
    "then , with high probability , we have @xmath244 .",
    "we use @xmath245 as the refined lower bound of @xmath112 , which will be used to derive @xmath106 in algorithm [ algo : node selection ] .",
    "the subscript `` r '' of @xmath246 stands for `` refinement '' .",
    "let @xmath247 be the set of rapg instances generated in algorithm [ algo : estimate lb ] .",
    "let @xmath248 for all @xmath118.[algo : refine lb : greedy s ] initialize the seed set @xmath249 .",
    "identity the node @xmath250 with largest @xmath251 .",
    "add @xmath122 to @xmath145 .",
    "update @xmath252 as @xmath124 for all @xmath125 .",
    "[ algo : refine lb : greedy e ] @xmath253{\\ell\\cdot \\epsilon^2/(\\ell+k)}$ ] [ algo : refine lb : influence s ] @xmath254 @xmath255 generate a set @xmath241 of @xmath256 random rapg instances .",
    "let @xmath257 .",
    "[ algo : refine lb : influence e ] [ algo : refine lb : f def ] @xmath245    * theoretical analysis . * we now prove that algorithm [ algo : refine lb ] returns @xmath258 $ ] with a high probability .",
    "[ lemma : lb plus ] if @xmath223 $ ] , algorithm [ algo : refine lb ] returns @xmath258 $ ] with at least @xmath2 probability .    as @xmath245 and @xmath259 , it is suffice to show @xmath260 holds with probability at least @xmath2 . by line [ algo : refine lb : f def ] in algorithm [ algo : refine lb ] ,",
    "we know @xmath260 if and only if @xmath261 . let @xmath262 $ ] , by lemma [ lemma : eisb ] , we have @xmath263 . since @xmath264 is the summation of @xmath265 i.i.d .",
    "random variable with mean @xmath108 , by @xmath266 , @xmath259 and chernoff bound , @xmath267 \\\\ \\leq & \\pr\\left[\\sum_{r\\in\\mathcal{r''}}f_r(s_b'|s_a)-\\mu\\theta '                   \\geq \\frac{opt\\epsilon'}{n\\mu}\\cdot \\mu\\theta'\\right]\\\\ \\leq & \\exp\\left(-\\frac{\\left(\\frac{opt\\epsilon'}{n\\mu}\\right)^2 }                  { 2+\\frac{opt\\epsilon'}{n\\mu}}\\cdot \\mu\\theta'\\right ) \\!=\\ !",
    "\\exp\\left(-\\frac{opt^2\\epsilon'^2}{2n^2\\mu+opt\\epsilon'n}\\cdot \\theta'\\right)\\\\ \\leq & \\exp\\left(-\\frac{opt\\epsilon'^2}{(2+\\epsilon')n }              \\cdot \\frac{\\lambda'}{lb_\\text{e}^*}\\right ) \\leq \\exp\\left(-\\frac{\\epsilon'^2\\lambda'}{(2+\\epsilon')n}\\right ) \\leq \\frac{1}{n^\\ell}.\\end{aligned}\\ ] ] the last inequality holds since @xmath254 and this completes the proof",
    ".    * time complexity .",
    "* we now analyze the time complexity of algorithm [ algo : refine lb ] .",
    "the running time of line [ algo : refine lb : greedy s]-[algo : refine lb : greedy e ] depends on @xmath268 .",
    "theorem [ theorem : lb star ] shows that the expected running time of is @xmath224 , which means that the total number of edges in all rapg instances is at most @xmath224 .",
    "hence , in lines [ algo : refine lb : greedy s]-[algo : refine lb : greedy e ] of algorithm [ algo : refine lb ] , the running time for the initialization and update of @xmath269 would be @xmath270 . and",
    "the running time of line [ algo : refine lb : greedy s]-[algo : refine lb : greedy e ] would be @xmath271 .",
    "the running time of the line [ algo : refine lb : influence s]-[algo : refine lb : influence e ] is @xmath272\\cdot \\mathbb{e}[n_r]\\right)$ ] , because we generate @xmath273 rapg instances and the running time of calculating @xmath274 for an rapg instance @xmath77 is linear with @xmath275 . as @xmath225=o(12/lb)$",
    "] holds from theorem [ theorem : lb star ] and @xmath276\\leq lb_\\text{e}$ ] holds from lemma [ lemma : erand leq lb ] , we can conclude that @xmath277\\cdot \\mathbb{e}[n_r]\\right ) & = o\\left(\\frac{\\lambda'}{lb_\\text{e}}\\cdot \\mathbb{e}[n_r]\\right)\\\\ & \\hspace{-1.2 in } = o\\left(\\frac{\\lambda'}{lb_\\text{e}}\\cdot \\left(1+\\frac{m}{n}\\right)lb_\\text{e}\\right ) = o(\\ell ( m+n)\\log n/\\epsilon'^2).\\end{aligned}\\ ] ]    to make sure that algorithm [ algo : refine lb ] has the same time complexity as algorithm [ algo : node selection ] , the value of @xmath278 must satisfy @xmath279 . in",
    "tim / tim@xmath21  @xcite that returns approximation solution for single source influence maximization problem under the ic model , tang et al .",
    "set @xmath280{\\ell\\cdot\\epsilon^2/(k+\\ell)}$ ] for any @xmath281 .",
    "note that for a special case of the _ general competitive independent cascade _ model where @xmath63 , the influence propagation model is actually the single source ic model .",
    "hence , we also set @xmath280{\\ell\\cdot\\epsilon^2/(k+\\ell)}$ ] for any @xmath281 .",
    "note that @xmath282 , it could be verified that @xmath283{\\ell\\cdot\\epsilon^2/(k+\\ell)}\\geq \\sqrt{\\ell/(c(\\ell+k))}\\epsilon$ ] holds for any @xmath281 .",
    "based on lemma [ lemma : lb plus ] and the time complexity analysis above , we have the following theorem .    given @xmath225=o(12/lb_\\text{e})$ ] and @xmath223 $ ] , algorithm [ algo : refine lb ] returns @xmath258 $ ] with at least @xmath2 probability and runs in @xmath284 expected time .    if @xmath285 , let @xmath286 , the total running time of algorithm [ algo : node selection ] is still @xmath287",
    ".      now we are in the position to put algorithm [ algo : node selection]-[algo : refine lb ] together and present the complete tcim algorithm . given a network @xmath5 , the seed set @xmath39 for the source @xmath32 together with parametric values @xmath0 , @xmath288 and @xmath7 , tcim returns a @xmath1 solution with probability at least @xmath2 .",
    "first , algorithm [ algo : estimate lb ] returns the estimated lower bound of @xmath112 , denoted by @xmath240 .",
    "then , we feed @xmath240 to algorithm [ algo : refine lb ] and get a refined lower bound @xmath246 .",
    "finally , algorithm [ algo : node selection ] returns a set @xmath40 of @xmath0 seeds for source @xmath33 based on @xmath286 random rapg instances .",
    "algorithm [ algo : all ] describes the pseudo - code of tcim as a whole .",
    "@xmath289 @xmath290 @xmath291 @xmath292 @xmath286 @xmath293 @xmath40    we use @xmath289 as the input parameter value of @xmath288 for algorithm [ algo : node selection]-[algo : refine lb ] . by setting this , algorithm [ algo : node selection]-[algo : refine lb ] each fails with probability at most @xmath294 .",
    "hence , by union bound , tcim succeeds in returning a @xmath1 approximation solution with probability at least @xmath2 .",
    "moreover , the total running time of tcim is @xmath287 , because algorithm [ algo : node selection]-[algo : refine lb ] each takes time at most @xmath287 . in conclusion",
    ", we have the following theorem .",
    "tcim returns @xmath1-approximate solution with probability at least @xmath2 .",
    "the time complexity is @xmath9 .",
    "in this section , we describe some special cases of the gcic model and provide detailed analysis about tcim for these models .",
    "to show the generality of the gcic model , we use the _ campaign - oblivious independent cascade model _ in @xcite , the _ distance - based model _ and _ wave propagation model _ in @xcite as specific propagation models . for each specific model , we first briefly describe how the influence propagates , give examples of score in a simple rapg instance as shown in figure [ fig : rapg only ] , and analyze the time complexity of the tcim algorithm .     nodes and @xmath295 edges .",
    "node @xmath88 is a seed of source @xmath32.,scaledwidth=17.0% ]      budak et al .",
    "@xcite introduced the _ campaign - oblivious independent cascade model ( coicm ) _ extending the single source ic model .",
    "the influence propagation process starts with two sets of active nodes @xmath39 and @xmath40 , and then unfolds in discrete steps . at step @xmath296 ,",
    "nodes in @xmath39 ( resp .",
    "@xmath40 ) are activated and are in state @xmath35 ( resp .",
    "@xmath36 ) .",
    "when a node @xmath17 first becomes activated in step @xmath297 , it gets a single chance to activate each of its currently uninfluenced neighbor @xmath18 and succeeds with the probability @xmath15 .",
    "budak et al .",
    "assumed that one source is prioritized over the other one in the propagation process , and nodes influence by the dominant source always attempt to influenced its uninfluenced neighbors first .",
    "here we assume that if there are two or more nodes trying to activate a node @xmath18 at a given time step , nodes in state @xmath36 ( i.e. , nodes influenced by source @xmath33 ) attempt first , which means source @xmath33 is prioritized over source @xmath32 .",
    "* examples of score .",
    "* suppose we are given seed sets @xmath39 and @xmath40 and a set of active edges @xmath47 .",
    "in coicm , a node @xmath17 will be influenced by source @xmath33 if and only if @xmath298 .",
    "for the rapg instance @xmath81 in figure [ fig : rapg only ] , if @xmath299 and otherwise .",
    "* analysis of tcim algorithm . *",
    "recall that while analyzing the running time of tcim , we assume that if we have a set @xmath113 of @xmath106 rapg instances , the time complexity for the initialization and update of the `` marginal gain vector '' @xmath142 is @xmath300)$ ] .",
    "we now show that @xmath301 for coicm .",
    "suppose we are selecting nodes based on a set @xmath113 of @xmath106 rapg instances .",
    "the initialization of @xmath142 takes time @xmath302)$ ] as for any rapg instance @xmath81 , we have @xmath229 for all @xmath303 and @xmath304 otherwise .",
    "suppose in one iteration , we add a node @xmath122 to the set @xmath145 and obtain a new seed set @xmath305 .",
    "recall that we define in the greedy approach . for every rapg instance @xmath306 and for all @xmath144",
    ", we would have @xmath307 and @xmath308 and hence we need to update @xmath123 correspondingly .",
    "for each rapg instance @xmath81 , it appears in @xmath247 in at most one iteration .",
    "hence , the total time complexity of the initialization and update of the `` marginal gain vector '' takes time @xmath309)$ ] .",
    "it follows that the running time of tcim is @xmath8 .",
    "carnes et al .",
    "proposed the _ distance - based model _ in @xcite .",
    "the idea is that a consumer is more likely to be influenced by the early adopters if their distance in the network is small .",
    "the model governs the diffusion of source @xmath32 and @xmath33 given the initial adopters for each source and a set @xmath42 of active edges .",
    "let @xmath310 be the shortest distance from @xmath17 to @xmath50 along edges in @xmath47 and let @xmath311 if there are no paths from @xmath17 to any node in @xmath50 .",
    "for any set @xmath312 , we define @xmath313 as the number of nodes in @xmath16 at distance @xmath310 from @xmath17 along edges in @xmath47 .",
    "given @xmath39 , @xmath40 and a set of active edge @xmath47 , the probability that node @xmath17 will be influenced by source @xmath33 is @xmath314 thus , the expected influence of @xmath40 is @xmath315,\\ ] ] where the expectation is taken over the randomness of @xmath47 .",
    "* examples of the score . *",
    "suppose we are given a random rapg instance @xmath81 shown in figure [ fig : rapg only ] .",
    "if @xmath316 , we would have @xmath317 .",
    "suppose @xmath318 , we have @xmath319 , @xmath320 and @xmath321 .",
    "hence the probability that node @xmath296 will be influenced by source @xmath33 is @xmath322 and we have @xmath323 . for @xmath324 or @xmath325",
    ", one can verify that @xmath326 .",
    "* analysis of tcim algorithm .",
    "* we now show that @xmath327 for the distance - based model . in the implementation of tcim under the distance - based model , for each rapg instance @xmath77 with `` root '' @xmath129",
    ", we keep @xmath328 for all @xmath329 and @xmath330 in the memory .",
    "moreover , we keep track of the value @xmath331 and @xmath332 for current @xmath40 and put them inside the memory .",
    "then , for any given rapg instance @xmath77 and a node @xmath152 , we have @xmath333 if @xmath334 and @xmath335 otherwise . in each iteration , for each rapg instance @xmath81 , the update of @xmath331 and @xmath332 after expanding previous seed set @xmath40 by adding a node could be done in @xmath336 . moreover , for any @xmath81 and @xmath152 , the evaluation of @xmath153 could also be done in @xmath336 . there are @xmath337 rapg instances with the total number of nodes being @xmath302)$ ] . hence , in @xmath0 iterations , it takes @xmath338)$ ] in total to initialize and update the marginal gain vector .",
    "substituting @xmath4 with @xmath339 in @xmath9 , the running time of the tcim algorithm is @xmath340 .",
    "carnes et al . also proposed the wave propagation model in @xcite extending the single source ic model .",
    "suppose we are given @xmath39 , @xmath40 and a set of active edges @xmath47 , we denote @xmath341 as the probability that node @xmath17 gets influenced by source @xmath33 .",
    "we also let @xmath342 be the shortest distance from seed nodes to @xmath17 through edges in @xmath47 .",
    "let @xmath343 be the set of neighbors of @xmath17 whose shortest distance from seed nodes through edges in @xmath47 is @xmath344 .",
    "then , carnes et al .",
    "@xcite defines @xmath345 the expected number of nodes @xmath40 can influence given @xmath39 is @xmath346,\\ ] ] where the expectation is taken over the randomness of @xmath47 .",
    "* examples of score .",
    "* for a random rapg instance @xmath81 shown in figure [ fig : rapg only ] , as for the distance - based model , we have @xmath317 if @xmath316",
    ". suppose @xmath324 , source @xmath33 would influence node @xmath347 and @xmath92 with probability @xmath31 , influence node @xmath31 with probability @xmath348 and influence node @xmath296 with probability @xmath349 .",
    "hence , @xmath350 .",
    "suppose @xmath325 , source @xmath33 would influence node @xmath351 and @xmath92 with probability @xmath31 , influence node @xmath296 with probability @xmath348 .",
    "hence , @xmath352 .",
    "moreover , one can verify that @xmath353 .",
    "* analysis of tcim algorithm .",
    "* we now show that for a greedy approach based on a set of @xmath106 random rapg instances , it takes @xmath354)$ ] in total to initialize and update the `` marginal gain vector '' . in each iteration of the greedy approach , for each rapg instance @xmath77 and each node @xmath152",
    ", it takes @xmath355)$ ] to update the marginal gain vector .",
    "since there are @xmath106 rapg instances each having at most @xmath104 nodes and the greedy approach runs in @xmath0 iteration , it takes at most @xmath354)$ ] in total to initialize and update the marginal gain vector . substituting @xmath356 into @xmath357",
    ", we can conclude that the running time of tcim is @xmath358 .",
    "in this section , we compare tcim to the greedy approach with monte - carlo method .",
    "we denote the greedy algorithm as _ greedymc _ , and it works as follows . the seed set @xmath40 is set to be empty initially and the greedy selection approach runs in @xmath0 iterations . in the @xmath359-th iteration , _ greedymc _ identifies a node @xmath360 that maximizes the marginal gain of influence spread of source @xmath33 , i.e. , maximizes @xmath361 , and put it into @xmath40 .",
    "every estimation of the marginal gain is done by @xmath129 monte - carlo simulations .",
    "greedymc _ runs in at least @xmath362 time .    in @xcite , tang et al .",
    "provided the lower bound of @xmath129 that ensures the @xmath1 approximation ratio of this method for single source influence maximization problem .",
    "we extend their analysis on _ greedymc _ and give the following theorem .",
    "[ th : monte carlo r ] for the competitive influence maximization problem , greedymc returns a @xmath1-approximate solution with at least @xmath363 probability , if @xmath364    let @xmath40 be any node set that contains at most @xmath0 nodes in @xmath68 and let @xmath365 be the estimation of @xmath60 computed by @xmath129 monte - carlo simulations .",
    "then , @xmath366 can be regarded as the sum of @xmath129 i.i.d .",
    "random variable bounded in @xmath107 $ ] with the mean value @xmath60 . by chernoff - hoeffding bound , if @xmath129 satisfies ineq .",
    "( [ eq : monte carlo r ] ) , it could be verified that @xmath367 $ ] is at least @xmath368 .",
    "given @xmath5 and @xmath0 , _ greedymc _ considers at most @xmath369 node sets with sizes at most @xmath0 . applying the union bound , with probability at least @xmath2",
    ", we have latexmath:[\\[\\label{eq : monte carlo accuracy }    for all sets @xmath40 considered by the greedy approach . under the assumption that @xmath365 for all set @xmath40 considered by _",
    "greedymc _ satisfies inequality ( [ eq : monte carlo accuracy ] ) , _ greedymc _ returns a @xmath1-approximate solution . for the detailed proof of the accuracy of _ greedymc _ , we refer interested readers to @xcite ( proof of lemma 10 ) .",
    "* remark : * suppose we know the exact value of @xmath112 and set @xmath129 to the smallest value satisfying ineq .",
    "( [ eq : monte carlo r ] ) , the time complexity of _ greedymc _ would be @xmath371 . given that @xmath372 , the time complexity of _ greedymc _ is at least @xmath373 .",
    "therefore , if @xmath374 , tcim is much more efficient than _",
    "greedymc_. if @xmath375 , the time complexity of tcim is still competitive with _ greedymc_. since we usually have no prior knowledge about @xmath112 , even if @xmath376 , tcim is still a better choice than the _ greedymc_.",
    "here , we present experimental results on three real - world networks to demonstrate the effectiveness and efficiency of the tcim framework",
    ".    * datasets . *",
    "our datasets contain three real - world networks : ( i ) a _ facebook - like social network _ containing @xmath377 users and @xmath378 directed edges  @xcite .",
    "( ii ) the _ nethept network _ , an academic collaboration network including @xmath379 nodes and @xmath380 undirected edges  @xcite . (",
    "iii ) an _ epinions social network _ of the who - trust - whom relationships from the consumer review site epinions  @xcite .",
    "the network contains @xmath381 directed `` trust '' relationships among @xmath382 users . as the _ weighted ic _ model in @xcite , for each edge @xmath26 , suppose the number of edges pointing to @xmath18 is @xmath383 , we set @xmath384 .    * propagation models .",
    "* for each dataset listed above , we use the following propagation models : the _ campaign - oblivious independent cascade model ( coicm ) _ , _ distance - based model _ and _ wave propagation model _ as described in section [ sec : application ] .    * algorithms . *",
    "we compare tcim with two greedy algorithms and a previously proposed heuristic algorithm , they are :    * * celf * : a efficient greedy approach based on a `` lazy - forward '' optimization technique  @xcite .",
    "it exploits the monotone and submodularity of the object function to accelerate the algorithm . * * celf++ * : a variation of celf which further exploits the submodularity of the influence propagation models  @xcite .",
    "it avoids some unnecessary re - computations of marginal gains in future iterations at the cost of introducing more computation for each candidate seed set considered in the current iteration . * * singlediscount * : a simple degree discount heuristic initially proposed for single source influence maximization problem  @xcite . for the cim problem , we adapt this heuristic method and select @xmath0 nodes iteratively . in each iteration , for a given set @xmath39 and current @xmath40 , we select a node @xmath17 such that it has the maximum number of outgoing edges targeting nodes not in @xmath50 .    for the tcim algorithm ,",
    "let @xmath113 be all rapg instances generated in algorithm [ algo : node selection ] and let @xmath40 be the returned seed set for source @xmath33 , we report @xmath385 as the estimation of @xmath60 .",
    "for other algorithms tested , we estimate the influence spread of the returned solution @xmath40 using @xmath386 monte - carlo simulations . for each experiment",
    ", we run each algorithm three times and report the average results .",
    "* parametric values . * for tcim ,",
    "the default parametric values are @xmath387 , @xmath388 , @xmath389 , @xmath390 . for celf and celf++ , for each candidate seed set @xmath40 under consideration , we run @xmath391 monte - carlo simulations to estimate the expected influence spread of @xmath40 .",
    "we set @xmath391 following the practice in literature ( e.g. , @xcite ) one should note that the value of @xmath129 required in all of our experiment is much larger than @xmath392 by theorem [ th : monte carlo r ] . for each dataset ,",
    "the seed set @xmath39 for source @xmath32 is returned by the tcim algorithm with parametric values @xmath63 , @xmath393 and @xmath390 .    * results on facebook - like",
    "network : * we first compare tcim to celf , celf++ and the singlediscount heuristic on the _ facebook - like social network_.    figure [ fig : fblike influence vs k ] shows the expected influence spread of @xmath40 selected by tcim and other methods .",
    "one can observe that the influence spread of @xmath40 returned by tcim , celf and celf++ are comparable .",
    "the expected influence spread of the seeds selected by singlediscount is slightly less than other methods .",
    "interestingly , there is no significant difference between the expected influence spread of the seeds returned by tcim with @xmath388 and @xmath394 , which shows that the quality of solution does not degrade too quickly with the increasing of @xmath7 .",
    "figure [ fig : fblike time vs k ] shows the running time of tcim , celf and celf++ , with @xmath0 varying from @xmath31 to @xmath395 .",
    "note that we did not show the running time of singlediscount because singlediscountit is a heuristic method and the expected influence spread of the seeds returned is inferior to the influence spread of the seeds returned by the other three algorithms .",
    "figure [ fig : fblike time vs k ] shows that among three influence propagation models , as compared to celf and celf++ , tcim runs _ two to three orders of magnitude faster _ if @xmath388 and _ three to four orders of magnitude faster _",
    "when @xmath394 .",
    "celf and celf++ have similar running time because most time is spent to select the first seed node for source @xmath33 and celf++ differs from celf starting from the selection of the second seed .     under _ campaign - oblivious independent cascade model ( cocim )",
    "_ , _ distance - based model _ and _ wave propagation model_. ( @xmath387 , @xmath390 ) ]     under _ campaign - oblivious independent cascade model ( cocim ) _ , _ distance - based model _ and _ wave propagation model_. ( @xmath387 , @xmath390 ) ]    * results on large networks : * for _ nethept _ and _ epinion _ , we experiment by varying @xmath0 , @xmath396 and @xmath7 to demonstrate the efficiency and effectiveness of the tcim .",
    "we compare the influence spread of tcim to singlediscount heuristic only , since celf and celf++ do not scale well on larger datasets .",
    "figure [ fig : large influence vs k ] shows the influence spread of the solution returned by tcim and singlediscount , where the influence propagation model is the _ wave propagation model_. we also show the value of @xmath185 and @xmath246 returned by the lower bound estimation and refinement algorithm . on both datasets ,",
    "the expected influence of the seeds returned by tcim exceeds the expected influence of the seeds return by singlediscount .",
    "moreover , as in tim / tim@xmath21  @xcite , for every @xmath0 , the lower bound @xmath246 improved by algorithm [ algo : refine lb ] is significant larger than the lower bound @xmath185 returned by algorithm [ algo : estimate lb ] . when the influence propagation model is coicm or the _ distance - based model _ , the results are similar to that in figure [ fig : large influence vs k ] .",
    "figure [ fig : large time vs k ] shows the running time of tcim , with @xmath0 varying from @xmath31 to @xmath395 . as in @xcite , for every influence propagation model , when @xmath397 , the running time of tcim is the largest . with the increase of @xmath0",
    ", the running time tends to drop first , and it may increase slowly after @xmath0 reaches a certain number .",
    "this is because the running time of tcim is mainly related to the number of rapg instances generated in algorithm [ algo : node selection ] , which is @xmath286 .",
    "when @xmath0 is small , @xmath246 is also small as @xmath112 is small . with the increase of @xmath0 ,",
    "if @xmath246 increases faster than the decrease of @xmath398 , @xmath106 decreases and the running time of tcim also tends to decrease . from figure",
    "[ fig : large time vs k ] , we see that tcim is especially efficient when @xmath0 is large .",
    "moreover , for every @xmath0 , among three models , the running time of tcim based on the _ campaign - obilivous independent cascade model _ is the smallest while the running time of tcim based on the _ wave propagation model _ is the largest .",
    "this is consistent with the analysis of the running of tcim in section [ sec : application ] .",
    "figure [ fig : large time vs epsilon ] shows that the running time of tcim decreases quickly with the increase of @xmath7 , which is consistent with its @xmath9 time complexity .",
    "when @xmath11 , tcim finishes within 7 seconds for _ nethept _ dataset and finishes within 23 seconds for _ epinion _ dataset .",
    "this implies that if we do not require a very tight approximation ratio , we could use a larger @xmath7 as input and the performance of tcim could improve significantly .",
    "figure [ fig : large time vs sa ] shows the running time of tcim as a function of the seed - set size of source @xmath32 . for any given influence propagation model , when @xmath396 increases , @xmath112 decreases and @xmath246 tends to decrease . as a result , the total number of rapg instances required in the node selection phase increases and consequently , the running time of tcim also increases .",
    "figure [ fig : mem time vs k ] shows the memory consumption of tcim as a function of @xmath0 . for any @xmath0",
    ", tcim based on _ campaign - oblivious independent cascade model _ consumes the least amount of memory because we only need to store the nodes for each rapg instance .",
    "tcim based on _ wave propagation model _ consumes the largest amount of memory because we need to store both the nodes and edges of each rapg instance . for the _ distance - based model _ , we do not need to store the edges of rapg instances , but need to store some other information for each rapg instance ; therefore , the memory consumption is in the middle .",
    "for all three propagation models and on both datasets , the memory requirement drops when @xmath0 increases because the number of rapg instances required tends to decrease .",
    "in this work , we introduce a `` _ _ general competitive independent cascade ( gcic ) _ _ '' model and define the `` _ _ competitive influence maximization ( cim ) _ _ '' problem . we then present a _ two - phase competitive influence maximization ( tcim ) _ framework to solve the cim problem under gcic model .",
    "tcim returns @xmath1-approximate solutions with probability at least @xmath2 and has time complexity @xmath9 , where @xmath4 depends on specific influence propagation model and may also depend on @xmath0 and graph @xmath5 . to the best of our knowledge ,",
    "this is the first general algorithmic framework for the _ competitive influence maximization ( cim ) _ problem with both performance guarantee and practical running time .",
    "we analyze tcim under the _ campaign - oblivious independent cascade model _ in @xcite , the _ distance - based model _ and the _ wave propagation model _ in @xcite . and we show that , under these three models , the value of @xmath4 is @xmath336 , @xmath339 and @xmath399 respectively .",
    "we provide extensive experimental results to demonstrate the efficiency and effectiveness of tcim .",
    "the experimental results show that tcim returns solutions comparable with those returned by the previous state - of - the - art greedy algorithms , but it runs _ up to four orders of magnitute faster _ than them . in particular , when @xmath10 , @xmath400 and @xmath12 , given the set of @xmath395 nodes selected by the competitor , tcim returns the solution within @xmath295 minutes for a dataset with @xmath382 nodes and @xmath381 directed edges .",
    "j.  kostka , y.  a. oswald , and r.  wattenhofer , `` word of mouth : rumor dissemination in social networks , '' in _ structural information and communication complexity_.1em plus 0.5em minus 0.4emspringer , 2008 ."
  ],
  "abstract_text": [
    "<S> given the popularity of the viral marketing campaign in online social networks , finding an effective method to identify a set of most influential nodes so to compete well with other viral marketing competitors is of upmost importance . </S>",
    "<S> we propose a _ </S>",
    "<S> `` general competitive independent cascade ( gcic ) '' _ model to describe the general influence propagation of two competing sources in the same network . </S>",
    "<S> we formulate the _ `` competitive influence maximization ( cim ) '' _ problem as follows : under a prespecified influence propagation model and that the competitor s seed set is known , how to find a seed set of @xmath0 nodes so as to trigger the largest influence cascade ? </S>",
    "<S> we propose a general algorithmic framework tcim for the cim problem under the gcic model . </S>",
    "<S> tcim returns a @xmath1-approximate solution with probability at least @xmath2 , and has an efficient time complexity of @xmath3 , where @xmath4 depends on specific propagation model and may also depend on @xmath0 and underlying network @xmath5 . to the best of our knowledge , </S>",
    "<S> this is the first general algorithmic framework that has both @xmath1 performance guarantee and practical efficiency . </S>",
    "<S> we conduct extensive experiments on real - world datasets under three specific influence propagation models , and show the efficiency and accuracy of our framework . </S>",
    "<S> in particular , we achieve up to four orders of magnitude speedup as compared to the previous state - of - the - art algorithms with the approximate guarantee . </S>"
  ]
}