{
  "article_text": [
    "at present there is a commonly accepted viewpoint that our world is complex and correlated . for this reason systems with long - range interactions ( and/or with long - range memory ) and natural sequences with non - trivial information content",
    "have been the focus of a large number of studies in different fields of science over the past several decades .",
    "some of the most peculiar manifestations of this concept are dna and protein sequences  @xcite .",
    "one of the efficient methods to investigate the correlated systems is based on the decomposition of the space of states into a finite number of parts labeled by definite symbols .",
    "this procedure , referred to as a coarse graining , is accompanied by the loss of short - range memory between states of system but does not affect and does not damage its robust invariant statistical properties on large scales .",
    "the most frequently used method of the decomposition is based on the introduction of two parts of the phase space . in other words , it consists in mapping the two parts of states onto two symbols , say 0 and 1 .",
    "thus , the problem is reduced to investigating the statistical properties of the symbolic binary sequences .",
    "this method is applicable for the examination of both discrete and continuous systems  @xcite .",
    "there are many methods for describing the complex dynamical systems and random sequences connected with them : correlation function , fractal dimensions , multi - point probability distribution functions , and many others .",
    "one of the most convenient characteristics serving to the purpose of studying complex dynamics is the entropy  @xcite .",
    "being a measure of the information content and redundancy in a sequence of data it is a powerful and popular tool in examination of the complexity phenomena .",
    "it has been used for the analysis of a number of different dynamical systems .",
    "a standard method of understanding and describing statistical properties of real physical systems or random sequences of data can be represented as follows .",
    "first of all , we need to analyze the sequence to find the correlation functions or the probabilities of words occurring , with the length @xmath1 exceeding the correlation length @xmath2 but being shorter than the length @xmath3 of the sequence , @xmath4 at the same time , the number @xmath5 of different words of the length @xmath1 composed in the alphabet containing @xmath6 letters has to be much less than the number @xmath7 of words in the sequence , @xmath8 the next step is to express the correlation properties of the sequence in terms of the conditional probability function ( cpf ) of the markov chain , see below eq .",
    "( [ soglas ] ) .",
    "note , the markov chain should be of order @xmath0 , which is supposed to be longer than the correlation length , @xmath9 this is the critical requirement because the correlation length of natural sequence of interest ( e.g. , written or dna texts ) is usually of the same order as the length of sequences .",
    "none of inequalities ( [ strong])([strong3 ] ) can be fulfilled .",
    "really , the lengths of words that could represent correctly the probability of words occurring are 4 - 5 letters for a real natural text of the length @xmath10 ( written on an alphabet containing 27 - 30 letters and symbols ) or of order of 20 symbols for a coarse - grained text represented by means of a binary sequence .",
    "so , it is clear that the method described above can only describe the random sequences with short correlation lengths and is not suited for analyzing the systems with long - range correlations . the latter issue will be the subject of our interest .",
    "we suppose that all we need for constructing the sequence with long - range correlations are the pair correlation functions .",
    "we use the developed method  @xcite for constructing the conditional probability function presented by means of the pair correlator which makes it possible to calculate analytically the entropy of the sequence .",
    "it should be stressed that we suppose that the correlations are weak but not short .",
    "the scope of the paper is as follows .",
    "first , we discuss briefly @xmath0-step additive markov chain model  @xcite and , supposing that the correlations between symbols in the sequence are weak , we express the conditional probability function by means of the pair correlation function . in the next section",
    "we represent the differential entropy in terms of the conditional probability function of the markov chain and express the entropy as the sum of squares of the pair correlators .",
    "then we discuss some properties of the results obtained .",
    "next , a fluctuation contribution to the entropy due to finiteness is examined .",
    "the application of the developed theory to some specific dna sequences of nucleotides is considered . in conclusion ,",
    "some remarks on directions in which the research can be progressed are presented .",
    "consider a sequence @xmath11 of real random variables @xmath12 taken from the finite alphabet @xmath13 , @xmath14 .",
    "the sequence @xmath15 is _ @xmath0-step markov chain _ ( also referred to as the higher - order or @xmath0-th - order markov chain  @xcite ) if it possesses the following property : the probability of symbol  @xmath16 to have a certain value @xmath17 under the condition that the values of all previous symbols are specified depends only on the values of @xmath0 previous symbols , @xmath18 & & = p(a_i = a|a_{i - n},\\ldots , a_{i-2},a_{i-1 } ) .",
    "\\nonumber\\end{aligned}\\ ] ] sometimes the number @xmath0 is also referred to as the _ memory length _ of the markov chain . the conditional probability function ( cpf )",
    "@xmath19 determines completely all statistical properties of the markov chain and the method of its iterative numerical construction . if the sequence , whose statistical properties we would like to analyze is assigned , the conditional probability function of the @xmath0-th order can be found by a standard method , @xmath20 where @xmath21 and @xmath22 are the probabilities of the @xmath23-word @xmath24 and @xmath0-word @xmath25 occurring , consequently .",
    "the markov chain determined by eq .",
    "( [ def_mark ] ) is a _ homogeneous _ sequence because its conditional probability does not depend explicitly on @xmath26 , i.e. , is independent of the position of symbols @xmath27 in the chain .",
    "it depends only on the values of @xmath27 and their positional relationship .",
    "the homogeneous sequences are _ stationary _ : the average value of any function @xmath28 of @xmath29 arguments @xmath30 & & = \\lim_{m\\to\\infty}\\frac{1}{m } \\sum_{i=0}^{m-1 } f(a_{i+r_1},\\ldots , a_{i+r_1+\\ldots+r_{s } } ) .",
    "\\nonumber\\end{aligned}\\ ] ] depends on @xmath31 differences between the indexes . in other words ,",
    "all statistically averaged functions of random variables are _ shift - invariant_.    we assume that the chain is _ ergodic_. according to the markov theorem ( see , e.g. , ref .",
    "@xcite ) , this property is valid for the homogenous markov chains if the strict inequalities , @xmath32 are fulfilled for all possible values of the arguments in function ( [ def_mark ] ) .",
    "hereafter we use the shorter notation @xmath33 for @xmath0-word @xmath34 .",
    "it follows from the ergodicity that correlations between any blocks of symbols in the chain go to zero when the distance between them goes to infinity .",
    "the other consequence of ergodicity is the possibility to use one random sequence as an equitable representative of the ensemble of chains and to do averaging over the sequence , eq .",
    "( [ epsilon - av ] ) , instead of the ensemble averaging .",
    "below we consider an important class of binary random sequences with symbols  @xmath16 taking on two values , say @xmath35  and  @xmath36 , @xmath37 . the conditional probability to find @xmath26-th element @xmath38 in the _",
    "binary _ @xmath0-step markov sequence depending on @xmath0 preceding elements @xmath33 is a set of @xmath39 numbers : @xmath40 & & p(0|a_{i - n}^{i-1 } ) = 1- p(1|a_{i - n}^{i-1}).\\end{aligned}\\ ] ] conditional probability ( [ prob ] ) of the binary sequence of random variables @xmath41 can be represented exactly as a _",
    "finite _ polynomial series : @xmath42 where the statistical averages @xmath43 are taken over sequence  ( [ epsilon - av ] ) , @xmath44 is the family of _ memory functions _ and @xmath45 is the relative average number of unities in the sequence . the representation of eq .",
    "( [ prob ] ) in the form eq .",
    "( [ prob_series ] ) results from the simple identical equalities , @xmath46 and @xmath47 , for an arbitrary function @xmath48 defined on the set @xmath49 .",
    "the first term in eq .",
    "( [ prob_series ] ) is responsible for generation of uncorrelated white - noise sequences .",
    "taking into account the second term proportional to @xmath50 we can reproduce correctly correlation properties of the chain up to the second order . in this case",
    "all the correlators of higher orders can be expressed through the products of the binary correlators . in what follows",
    "we will only use the first two terms , which determine the so - called _ additive _ markov chains  @xcite .",
    "they are in some sense analogous to autoregressive models  @xcite .",
    "a particular form of the conditional probability function of additive markov chain is the step - wise memory function , @xmath51 the probability @xmath52 of having the symbol @xmath38 after @xmath0-word @xmath33 containing @xmath53 unities , @xmath54 , is a linear function of @xmath53 and is independent of the arrangement of symbols in the word @xmath55 .",
    "the parameter @xmath56 characterizes the strength of correlations in the system .",
    "there is a rather simple relation between the memory function @xmath57 ( hereafter we will omit the subscript @xmath36 of @xmath50 ) and the pair correlation function of the binary additive markov chain .",
    "there were suggested two methods for finding the @xmath57 of a sequence with a known pair correlation function .",
    "the first  @xcite is based on the minimization of a `` distance '' between the markov chain generated by means of the sought - for memory function and the initial given sequence of symbols with a known correlation function .",
    "the minimization equation yields the relationship between the correlation and the memory functions , @xmath58 where the normalized correlation function @xmath59 is given by @xmath60 the second method for deriving eq .",
    "( [ main ] ) is the completely probabilistic straightforward calculation  @xcite .",
    "equation  ( [ main ] ) , despite its simplicity , can be analytically solved only in some particular cases : for one- or two - step chains , markov chain with step - wise memory function and so on . to avoid the difficulties in solving eq .",
    "( [ main ] ) we suppose that correlations in the sequence are weak .",
    "it means that all components of the normalized correlation function are small , @xmath61 , with the exception of @xmath62 .",
    "so , taking into account that in the sum of eq .",
    "( [ main ] ) the leading term is @xmath63 and all the others are small , we can obtain an approximate solution for the memory function in the form of the series @xmath64 the equation for the conditional probability function in the first approximation with respect to small functions @xmath61 , takes the form @xmath65 this formula provides a very important tool for constructing a sequence with a given pair correlation function .",
    "note that the @xmath26-independence of function @xmath66 guarantees homogeneity and stationarity of the sequence under consideration ; the finiteness of @xmath0 together with eq .",
    "( [ ergo_m ] ) provides its ergodicity .",
    "the correlation and memory functions are mutually complementary characteristics of a random sequence in the following sense .",
    "the numerical analysis of a given random sequence enables one to determine directly the correlation function rather than the memory function . on the other hand ,",
    "it is possible to construct a random sequence using the memory function , but not the correlation one , in the general case .",
    "therefore , the memory function permits one to get a deeper insight into the intrinsic properties of the correlated systems .",
    "equation  ( [ approx cp ] ) shows that in the limit of weak correlations both functions play the same role .",
    "the concept of additive markov chain was extensively used earlier for studying the random sequences with long - range correlations .",
    "the examples and references can be found in  @xcite .",
    "in order to estimate the entropy of infinite stationary sequence @xmath15 of symbols @xmath12 one could use the block entropy , @xmath67 here @xmath68 is the probability to find the @xmath1-word @xmath69 in the sequence .",
    "the differential entropy , or entropy per symbol , is given by @xmath70 and specifies the degree of uncertainty of the @xmath71-th symbols observing if the preceding @xmath1 symbols are specified .",
    "the source entropy ( or shannon entropy ) is the differential entropy at the asymptotic limit , @xmath72 .",
    "this quantity measures the average information per symbol if _ all _ correlations , in the statistical sense , are taken into account .",
    "the differential entropy @xmath73 can be presented in terms of the conditional probability function . to show this we have to rewrite eq .",
    "for the block of length @xmath74 , expressing @xmath75 via the conditional probability , and after a bit of algebra we obtain @xmath76 here @xmath77 is the conditional ( not averaged ) entropy or the amount of information contained in the @xmath71-th symbol of the sequence conditioned on @xmath1 previous symbols , @xmath78 so , the differential entropy @xmath73 of a random sequence is presented as a generalization of the standard conditional entropy @xmath79 to the multi - symbol event @xmath80 .",
    "the conditional probability @xmath81 at @xmath82 , @xmath83 can be obtained in the first approximation in parameter @xmath84 from eq .   by means of a simple probabilistic reasoning .",
    "taking into account the weakness of correlations , @xmath85 $ ] , one can expand the right - hand side of eq .",
    "in taylor series up to the second order in @xmath84 , @xmath86 , where the derivatives are taken at the `` equilibrium point '' @xmath87 and @xmath88 is the entropy of uncorrelated sequence , @xmath89 upon using eq .   for averaging @xmath77 and in view of @xmath90 ,",
    "the differential entropy of the sequence becomes @xmath91 if the block length exceeds the memory length , @xmath92 , the conditional probability @xmath81 depends only on @xmath0 previous symbols , see eq .",
    "( [ def_mark ] ) .",
    "then , it is easy to show from   that the differential entropy remains constant at @xmath93 .",
    "the second line of eq .",
    "is consistent with the first one because in the first approximation in @xmath84 the correlation function vanishes at @xmath92 together with the memory function .",
    "the final expression , the main result of the paper , for the differential entropy of the stationary ergodic binary weakly correlated random sequence is @xmath94    it follows from eq .",
    "( [ entromain ] ) that the additional correction to the entropy @xmath88 of uncorrelated sequence is the negative and monotonously decreasing function of @xmath1 .",
    "it is the anticipated result  the correlations reduce entropy . the conclusion is not sensitive to the sign of correlations : persistent correlations , @xmath95 , describing the `` attraction '' of symbols of the same kind , and anti - persistent correlations , @xmath96 , corresponding to the attraction between `` 0 '' and `` 1 '' , provide the corrections of the same negative sign .",
    "if the correlation function is constant at @xmath97 , the entropy is a linear decreasing function of the argument @xmath1 up to the point @xmath0 ; the result is coincident with that obtained in  @xcite ( in the limit of weak correlations ) for the markov chain model with step - wise memory function  ( [ prob step ] ) .    .",
    "the solid line is the analytical result , eq .",
    "( [ entromain ] ) , for correlation function @xmath98 , whereas the dots correspond to direct evaluation of the same eq .",
    "( [ entromain ] ) for the numerically constructed sequence ( of the length @xmath99 and the cut - off parameter @xmath100 ) by means of conditional probability function  ( [ approx cp ] ) and the numerically evaluated correlation function @xmath59 of the constructed sequence . the dashed line is the differential entropy with fluctuation correction described by eq .",
    "( [ entrofin ] ) .",
    ", scaledwidth=48.0% ]    as an illustration of result ( [ entromain ] ) , in fig .",
    "[ n_c20 ] we present the plot of the differential entropy versus the length @xmath1 .",
    "both numerical and analytical results ( the dotted and solid curves ) are presented for the power - law correlation function @xmath98 . the cut  off parameter @xmath101 of the power - law function for numerical generation of the sequence , coinciding with the memory length of the chain , is @xmath102 .",
    "the good agreement between the curves at @xmath103 is the manifestation of adequateness of the additive markov chain approach for studying the entropy properties of random chains .",
    "the relative average number of unities @xmath45 , correlation functions and other statistical characteristics of random sequences are deterministic quantities in the limit of their infinite lengths only .",
    "it is a direct consequence of the law of large numbers .",
    "if the sequence length @xmath3 is finite , the set of numbers @xmath104 can not be considered anymore as ergodic sequence . in order to restore its status",
    "we have to introduce the _ ensemble _ of finite sequences @xmath105 .",
    "yet , we would like to retain the right to examine _ finite _ sequences by using a single finite chain .",
    "so , for a finite chain we have to replace definition  ( [ def_cor1 ] ) of the correlation function by the following one , @xmath106 now the correlation functions and @xmath45 are random quantities which depend on the particular realization of the sequence @xmath104 .",
    "their fluctuations can contribute to the entropy of finite random chains even if the correlations in the random sequence are absent .",
    "it is well known that the order of relative fluctuations of additive random quantity ( as , e.g. , the correlation function eq .",
    "( [ corfin ] ) ) is @xmath107 .    below we give more rigorous justification of this explanation and show its applicability to our case .",
    "let us present the correlation function @xmath108 as the sum of two components , @xmath109 where the first summand @xmath110 is the correlation function determined by eqs .",
    "( [ def_cor1 ] ) and ( [ corfin ] ) , obtained by averaging over the sequence with respect to index @xmath26 , enumerating the elements @xmath12 of sequence @xmath15 ; and the second one , @xmath111 , is a fluctuation ",
    "dependent contribution .",
    "function @xmath112 can be also presented as the ensemble average @xmath113 due to the ergodicity of the sequence .",
    "now we can find a relationship between variances of @xmath108 and @xmath111 . taking into account eq .",
    "( [ correlsquar ] ) and the properties @xmath114 at @xmath115 and @xmath113 we have @xmath116    the mean fluctuation of squared correlation function @xmath117 is @xmath118 & & \\!\\!\\ ! \\frac{1}{(m - r)^2}\\langle\\!\\!\\!\\sum_{n , m=0}^{m - r-1}\\!\\!\\!(a_n-\\bar{a})(a_{n+r}-\\bar{a } ) ( a_m-\\bar{a})(a_{m+r}-\\bar{a})\\rangle . \\nonumber\\end{aligned}\\ ] ]    taking into account that only the terms with @xmath119 give nonzero contribution to the result and neglecting correlations between elements @xmath120 , @xmath121    we obtain for the normalized correlation function    @xmath122    note that eq .",
    "( [ fluctfin ] ) is obtained by means of averaging over the ensemble of chains .",
    "this is the shortest way to obtain the desired result . at the same time , for numerical simulations we have used only the averaging over the chain as is seen from eq .",
    "( [ corfin ] ) , where the summation over sites @xmath26 of the chain plays the role of averaging .",
    "note also that the different symbols @xmath16 in eq .",
    "( [ fluct ] ) are correlated .",
    "it is possible to show that contribution of their correlations to @xmath123 is of order @xmath124 .",
    "the fluctuating part of entropy , proportional to @xmath125 , should be subtracted from eq .",
    "( [ entromain ] ) , which is only valid for the infinite chain .",
    "thus , eqs .",
    "( [ correlsquar1 ] ) and  ( [ fluctfin ] ) yield the differential entropy of the _ finite _ binary weakly correlated random sequences @xmath126.\\ ] ]    it is clear that in the limit @xmath127 this function transforms into eq .",
    "( [ entromain ] ) . when @xmath128 , the last term in rhs of eq .",
    "( [ entrofin ] ) takes the form @xmath129 and describes the linearly decreasing entropy .",
    "the squared correlation function @xmath130 is normally a decreasing function of @xmath131 , whereas function @xmath132 is an increasing one .",
    "hence , the terms @xmath133 and @xmath134 $ ] being concave and convex functions , respectively , describe the competitive contributions to the entropy .",
    "it is not possible to analyze all particular cases of their relationship .",
    "therefore we indicate here the most interesting ones taking in mind monotonically decreasing correlation functions .",
    "an example of such type of function , @xmath135 , was considered above .",
    "if the correlations are extremely small and compared with the inverse length @xmath3 of the sequence , @xmath136 , the fluctuating part of the entropy exceeds the correlation part nearly for all values of @xmath137 .    with the increasing of @xmath3 ( or correlations ) , when the inequality @xmath138 is fulfilled ,",
    "there is at list one point where the contribution of fluctuation and correlation parts of the entropy are equal . for monotonically decreasing function",
    "@xmath59 there is only one such point . comparing the functions in square brackets in eqs .",
    "( [ entrofin ] ) we find that they are equal at some @xmath139 , which hereafter will be referred to as a stationarity length .",
    "if @xmath140 , the fluctuations of the correlation function are negligibly small with respect to its magnitude , hence the finite sequence may be considered as quasi - stationary one . at @xmath141",
    "the fluctuations are of the same order as the genuine correlation function @xmath142 . here",
    "we have to take into account the fluctuation correction due to the finiteness of the random chain . at @xmath143",
    "the fluctuating contribution exceeds the correlation one .",
    "the other important parameter of the random sequence is the memory length @xmath0 .",
    "if the length @xmath0 is less than @xmath144 , we have no difficulties to calculate the entropy of the finite sequence , which can be considered as quasi - stationary .",
    "this case is illustrated in fig .",
    "[ n_c20 ] where the good agreement between the analytical and numerical curves at @xmath103 is clearly seen .",
    "if the memory length exceeds the stationarity length , @xmath145 , we have to take into account the fluctuation correction to the entropy . the entropy with this correction is shown in fig .  [ n_c20 ] by the dashed line .",
    "two types of different relationships between memory length @xmath0 and stationarity length @xmath144 are shown in fig .",
    "[ two_corr ] .",
    "note that at @xmath92 the entropy does not change .",
    "two solid points in the figure correspond to the equality @xmath146 .",
    "-independent contributions to the entropy , @xmath147 , see eq .",
    "( [ entrofin ] ) , for two different memory lengths marked by two solid dots .",
    "both lines correspond to exponential correlator @xmath148 . for the dashed line @xmath149 and correlation length",
    "is @xmath150 .",
    "the dotted line represents a sequence with @xmath151 and @xmath152 .",
    "the solid line is the fluctuation correction @xmath153\\,/\\ , 2\\ln 2 $ ] .",
    ", title=\"fig:\",scaledwidth=48.0% ]",
    "it is known that any dna text is written by four `` characters '' , specifically by adenine ( a ) , cytosine ( c ) , guanine ( g ) , and thymine ( t )",
    ". therefore , there are three nonequivalent types of the dna text mapping onto one - dimensional binary sequences of zeros and unities .",
    "the first of them is the so - called purine - pyrimidine rule , \\{a , g } @xmath154 0 , \\{c , t } @xmath154 1 .",
    "the second one is the hydrogen - bond rule , \\{a , t } @xmath154 0 , \\{c , g } @xmath154 1 . and , finally , the third is \\{a , c } @xmath154 0 , \\{g , t } @xmath154 1 .     for the coarse - grained dna text of _ bacillus subtilis , complete genome _",
    "@xcite , for three nonequivalent kinds of mapping .",
    "dotted , dashed , and dash - dotted lines correspond to the purine - pyrimidine mapping , \\{a , g } @xmath154 0 , \\{c , t } @xmath154 1 ; hydrogen - bond rule mapping , \\{a , t } @xmath154 0 , \\{c , g } @xmath154 1 ; and \\{a , c } @xmath154 0 , \\{g , t } @xmath154 1 , respectively .",
    "the solid line describes the non - correlated brownian diffusion , @xmath155.,title=\"fig:\",scaledwidth=42.0% ]    in order to understand which kind of mapping is more appropriate for calculating the entropy , we consider all three kinds of mapping  @xcite . as an example , the variance @xmath156 for the coarse - grained text of _ bacillus subtilis , complete genome _",
    "@xcite , is displayed in fig .",
    "[ f12 ] for all possible types of mapping .",
    "the different kinds of mapping reveal and emphasize various types of physical attractive correlations between the nucleotides in the dna , such as the strong purine - purine and pyrimidine - pyrimidine persistent correlations ( the upper curve ) , and the correlations caused by the weaker attraction a@xmath157 t and c@xmath157 g ( the middle curve ) . in what follows",
    "we will use the purine - pyrimidine coarse - grained mapping , which corresponds to the strongest correlations .",
    "vs length @xmath1 for r3 chromosome of _ drosophila melanogaster _ dna of length @xmath158 .",
    "the solid line is obtained by using eq .",
    "( [ entromain ] ) with numerically evaluated correlation function eq .",
    "( [ def_cor1 ] ) .",
    "the dashed line is the differential entropy , eqs .",
    "( [ entro_block ] ) and ( [ entro_diff ] ) , plotted by using the numerical estimation of probability @xmath159 of the @xmath1-blocks occurring in the same sequence .",
    "the dots are the differential entropy ( normalized by division by 2 ) of the same sequence , eqs .",
    "( [ entro_block ] ) and ( [ entro_diff ] ) , without coarse - graining , i.e. , for four - letter dna sequence . ,",
    "scaledwidth=48.0% ]    in order to evaluate the entropy of dna sequence using eq .",
    "( [ entromain ] ) at first we have to calculate the normalized correlation function given by eq .",
    "( [ def_cor1 ] ) , where each random variable @xmath16 after mapping takes on the values @xmath35 or @xmath36 .",
    "the result of such calculation for r3 chromosome of _ drosophila melanogaster _ dna of length @xmath160 is shown in fig .",
    "[ graph2 ] by the solid line .",
    "the abrupt deviation of the dashed line from the upper curves at @xmath161 is the result of violation of inequality  ( [ strong2 ] ) and the manifestation of rapidly growing errors in the entropy estimation by using the probability @xmath162 of the @xmath1-blocks occurring .",
    "the dotted curve shows that the violation of strong inequality  ( [ strong2 ] ) for four - letter sequence begins at smaller value of @xmath1 than for two - letter ( binary ) sequence .    .",
    "the solid line is obtained by using the equation similar to eq .",
    "( [ entromain ] ) with numerically evaluated correlation functions .",
    "the dashed line is the entropy with the fluctuation correction .",
    ", scaledwidth=48.0% ]    the theory of additive markov chains presented here can be applied to the chains with @xmath6-valued space of states . in our case @xmath163 . using the formula similar to eq .",
    "( [ entrofin ] ) we evaluate the entropy for _ homo sapiens _ chromosome y , locus nw 001842422 .",
    "the result of calculation is shown in fig .",
    "[ h_nw_001842422 ] .",
    "it is clearly seen that the entropy in interval @xmath164 takes on the constant value , @xmath165 .",
    "it means that for @xmath166 _ all _ correlations , in the statistical sense , are taken into account , or , in other words , the memory length of the _ homo sapiens _",
    "chromosome y is of the order of @xmath167 . at @xmath168 the entropy",
    "evidently should be constant as well .",
    "the presented deviation is the consequence of many different reasons such as the nonadditivity of the sequence under study , the violation of supposed weakness of correlations , and many others .",
    "we believe that , along with the memory length , the asymptotic value of the entropy @xmath169 at @xmath170 ( the shannon source entropy ) can be the important characteristics of the living species .",
    "this paper is the first application of the theory based on the additive markov chains approach for describing the dna sequences .",
    "it is evident that we need a more systematic and extensive study of the real biological sequences .",
    "we have supposed that correlations are weak .",
    "however , our preliminary study evidences that when correlations are not weak , a strong short - range part in the interaction of symbols changes in eq .",
    "( [ entromain ] ) the numerical coefficient before the term @xmath171 at @xmath172",
    "our consideration can be generalized to the markov chain with the infinite memory length @xmath0 . in this case",
    "we have to impose a condition on the decreasing rate of the correlation function and the conditional probability function at @xmath173 .",
    "another generalization , which may be important for biological applications  @xcite , is the non - homogenous markov chains . in this case",
    "the conditional probability function @xmath174 has to be the function of the position @xmath26 of symbol @xmath16 , @xmath175                                      seifert ,  m. , gohr ,  a. , strickert ,  m. , grosse ,  i. , 2012 .",
    "parsimonious higher - order hidden markov models for improved array - cgh analysis with applications to arabidopsis thaliana , plos computational biology , 8 , e1002286 ."
  ],
  "abstract_text": [
    "<S> we analyze the structure of dna molecules of different organisms by using the additive markov chain approach . transforming nucleotide sequences into binary strings , we perform statistical analysis of the corresponding `` texts '' . </S>",
    "<S> we develop the theory of @xmath0-step additive binary stationary ergodic markov chains and analyze their differential entropy . supposing that the correlations are weak we express the conditional probability function of the chain by means of the pair correlation function and represent the entropy as a functional of the pair correlator . </S>",
    "<S> since the model uses two point correlators instead of probability of block occurring , it makes possible to calculate the entropy of subsequences at much longer distances than with the use of the standard methods . </S>",
    "<S> we utilize the obtained analytical result for numerical evaluation of the entropy of coarse - grained dna texts . </S>",
    "<S> we believe that the entropy study can be used for biological classification of living species . </S>"
  ]
}