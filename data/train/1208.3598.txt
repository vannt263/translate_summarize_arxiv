{
  "article_text": [
    "codes , proposed by arikan @xcite , are proved to achieve the symmetric capacities of the binary - input discrete memoryless channels ( b - dmcs ) .",
    "this capacity - achieving code family is based on a technique called channel polarization . by performing the channel splitting and channel combining operations on independent copies of a given b - dmc ,",
    "a set of synthesized binary - input channels can be obtained .",
    "let @xmath0 denote the symmetric capacity of a b - dmc @xmath1 .",
    "it is proved in @xcite that : with @xmath2 uses of @xmath1 , @xmath3 , when @xmath4 is large enough , it is possible to construct @xmath4 synthesized channels such that @xmath5 of them are completely unreliable and @xmath6 of them are noiseless . by transmitting free bits ( called information bits ) over the noiseless channels and transmitting a sequence of fixed bits ( called frozen bits ) over the others , polar codes can achieve the symmetric capacity under a successive cancellation ( sc ) decoder with both encoding and decoding complexity @xmath7 . in @xcite , it is proved that the block error probability of polar code under sc decoding satisfies @xmath8 for any @xmath9 when code length @xmath4 is large enough and code rate @xmath10 .",
    "furthermore , it was shown by korada et al .",
    "@xcite that the error exponent @xmath11 can be arbitrarily close to 1 for large @xmath4 with a general construction using larger kernel matrices than the @xmath12 matrix proposed by arikan .",
    "to construct polar codes , the channel reliabilities can be calculated efficiently using bhattacharyya parameters for binary - input erasure channels ( becs ) @xcite .",
    "but for channels other than becs , density evolution is required @xcite .",
    "more practical methods for calculating the channel reliabilities are discussed in @xcite and @xcite , and these techniques are extended to input channels @xcite .",
    "the channel polarization phenomenon is believed to be universal in many other applications , such as parallel communications @xcite @xcite , coded modulation systems @xcite , multiple access communications @xcite @xcite , source coding @xcite @xcite , information secrecy @xcite @xcite and other settings .",
    "although polar codes have astonishing asymptotic performance , the finite - length performance of polar code under sc decoding is not satisfying . with the factor graph representation of polar codes , a belief propagation",
    "( bp ) decoder is introduced by arian in @xcite . and in @xcite , hussami et .",
    "al . show that bp decoder significantly can outperform sc decoder , and point out that , for channels other than bec , the schedule of message passing in bp plays an important role .",
    "and they also show that the performance of bp decoder can be further improved by utilization of overcomplete factor graph representations over bec . unfortunately ,",
    "due to the sensitivity of bp decoder to message - passing schedule , this is not realized on other channels . in @xcite a linear programming ( lp ) decoder is introduced without any schedule , and also , by using the overcomplete representations can improve the performance of lp decoder . but lp decoder can not work on channels other than bec .",
    "maximum likelihood ( ml ) decoders are implemented via viterbi and bcjr algorithms on the codeword trellis of polar codes @xcite , but because of their high complexity , they can only work on very short code blocks .",
    "successive cancellation ( sc ) decoding of polar codes essentially shares the same idea with the recursive decoding of rm codes @xcite . like the recursive decoders",
    "can be improved by using a list @xcite or a stack @xcite , sc can also be enhanced in the same way .    as an improved version of sc , successive cancellation list ( scl ) decoding algorithm",
    "is introduced to approach the performance of maximum likelihood ( ml ) decoder with an acceptable complexity @xcite , @xcite . and",
    "later , an other improved decoding algorithm based on sc named successive cancellation stack ( scs ) decoding algorithm is proposed whose computational complexity will decrease with the increasing of signal - to - noise ratio ( snr ) and can be very close to that of the sc decoding in the high snr regime @xcite .",
    "compared with scl , scs will have a much lower computational complexity .",
    "but it comes at the price of much larger space complexity and it will fail to work when the stack is too small . combining the ideas of scl and scs ,",
    "a new decoding algorithm named successive cancellation hybrid ( sch ) is proposed in this paper , and it can achieve a better trade - off between computational complexity and space complexity . in this paper , all the three improved sc decoding algorithms , scl , scs and sch ,",
    "are described under a unified manner of a path searching procedure on the code tree .",
    "further , to reduce the complexity , a pruning technique is proposed to avoid unnecessary path searching operations .",
    "the remainder of the paper is organized as follows .",
    "section [ section_preliminaries ] reviews the basics of polar coding and describes the sc decoding algorithm as a path searching procedure on a code tree using _ a posteriori _ probabilities ( apps ) as metrics .",
    "then the three improved successive cancellation ( isc ) decoding algorithms and the pruning technique are introduced in section [ section_isc ] .",
    "section [ section_simulations ] provides the performance and complexity analysis based on the simulation results of polar codes under isc decoders with different parameters .",
    "finally , section [ section_conclusion ] concludes the paper .",
    "in this paper , we use blackboard bold letters , such as @xmath13 and @xmath14 , to denote sets , and use @xmath15 to denote the number of elements in @xmath13 .",
    "we write the cartesian product of @xmath13 and @xmath14 as @xmath16 , and write the @xmath17-th cartesian power of @xmath13 as @xmath18 .",
    "we use calligraphic characters , such as @xmath19 to denote a event . and let @xmath20 denote the event that @xmath19 is not happened .",
    "we use notation @xmath21 to denote a @xmath4-dimension vector @xmath22 and @xmath23 to denote a subvector @xmath24 of @xmath21 , @xmath25 .",
    "particularly when @xmath26 , @xmath23 is a vector with no elements in it and the empty vector is denoted by @xmath27 .",
    "we write @xmath28 to denote the subvector of @xmath21 with odd indices ( @xmath29 ; @xmath30 is odd ) .",
    "similarly , we write @xmath31 to denote the subvector of @xmath21 with even indices ( @xmath29 ; @xmath30 is even ) . for example , for @xmath32 , @xmath33 , @xmath34 and @xmath35 .",
    "further , given a index set @xmath36 , @xmath37 denote the subvector of @xmath21 which consists of @xmath38s with @xmath39 .",
    "only square matrices are involved in this paper , and they are denoted by bold letters .",
    "the subscript of a matrix indicates its size , e.g. @xmath40 represents a @xmath41 matrix @xmath42 .",
    "we write the kronecker product of two matrices @xmath42 and @xmath43 as @xmath44 , and write the @xmath17-th kronecker power of @xmath42 as @xmath45 .",
    "let @xmath46 denote a b - dmc with input alphabet @xmath13 and output alphabet @xmath47 . since the input is binary , @xmath48 .",
    "the channel transition probabilities are @xmath49 , @xmath50 , @xmath51 .    for code length @xmath52 , @xmath53 , and",
    "information length @xmath54 , i.e. code rate @xmath55 , the polar coding over @xmath1 proposed by arikan can be described as follows :    after channel combining and splitting operations on @xmath4 independent uses of @xmath1 , we get @xmath4 successive uses of synthesized binary input channels @xmath56 , @xmath57 , with transition probabilities @xmath58 where @xmath59 and the source block @xmath60 are supposed to be uniformly distributed in @xmath61 .",
    "let @xmath62 denote the probability of maximum - likelihood ( ml ) decision error of one transmission on @xmath63 , @xmath64 where @xmath65 , @xmath66 and the indicator function @xmath67 and @xmath68 is the module-@xmath69 addition .",
    "the reliabilities of polarized channels @xmath70 are usually measured by ( [ equ_pe ] ) , and can be evaluated using bhattacharyya parameters @xcite for binary erasure channels ( becs ) or density evolution @xcite for other channels .    to transmit a binary message block of @xmath54 bits , the @xmath54 most reliable polarized channels @xmath70 with indices",
    "@xmath39 are picked out for carrying these information bits ; and transmit a fixed bit sequence called frozen bits over the others .",
    "the index set @xmath71 is called information set and @xmath72 . and the complement set of @xmath36 is called frozen set and is denoted by @xmath73 .    alternatively , the polar coding can be described as follow : a binary source block @xmath60 which consists of @xmath54 information bits and @xmath74 frozen bits is mapped to a code block @xmath75 via @xmath76 . the matrix @xmath77 , where @xmath78 $ ] and @xmath79 is the bit - reversal permutation matrix .",
    "the binary channel @xmath80 are then sent into channels which are obtained by @xmath4 independent uses of @xmath1 .",
    "as mentioned in @xcite , polar codes can be decoded by successive cancellation ( sc ) decoding algorithm .",
    "let @xmath81 denote the estimate of the source block @xmath60 .",
    "after receiving @xmath82 , the bits @xmath83 are determined successively with index @xmath84 from @xmath85 to @xmath4 in the following way : @xmath86 where @xmath87 the block error rate ( bler ) of this sc decoding is upper bounded by @xmath88    this successive decoding can be represented as a path searching process on a code tree . for a polar code with code length @xmath4 , the corresponding code tree",
    "@xmath89 is a full binary tree .",
    "more specifically , @xmath89 can be represented as a 2-tuple @xmath90 where @xmath91 and @xmath92 denote the set of nodes and the set of edges respectively , @xmath93 , @xmath94 .",
    "the depth of a node @xmath95 is the length of the path from the root to the node .",
    "the set of all nodes at a given depth @xmath96 is denoted by @xmath97 , @xmath98 .",
    "the root node has a depth of zero .",
    "all the edges @xmath99 are partitioned into @xmath4 levels @xmath100 , @xmath101 , such that the edges in @xmath100 incident with the nodes at depth @xmath102 and the nodes at depth @xmath103 . except the nodes at the @xmath4-th depth @xmath104 , each @xmath105 has two descendants which belong to @xmath106 , and the two corresponding edges are label as @xmath107 and @xmath85 respectively .",
    "the nodes @xmath108 are called leaf nodes . fig .",
    "[ fig_tree ] gives a simple example of code tree with @xmath109 .",
    "a @xmath84-length decoding path @xmath110 consists of @xmath84 edges , with @xmath111 , @xmath112 .",
    "a vector @xmath113 is used to depict the above decoding path , where @xmath38 is corresponding to the binary label of edge @xmath114 .",
    "the reliability of a decoding path @xmath113 can be measured using _ a posteriori _",
    "probability @xmath115    the apps can be regarded as normalized versions of the channel transition probabilities defined in ( [ equ_polarized_channels ] ) .",
    "the two kinds of probabilities are related by a multiplicative factor @xmath116 . by eliminating the factor ,",
    "the apps take values in a more stable range , and all the decoding paths with the same lengths have the sum probability equals to one , i.e. @xmath117 this property will help in understanding the path searching procedure in the code tree and is more suitable for hardware implementation .",
    "similar to the recursive expressions of ( [ equ_polarized_channels ] ) given in @xcite , the apps can also be calculated recursively . for any @xmath118 , @xmath2 , @xmath119 , @xmath120 @xmath121    sc decoding",
    "can be seen as a greedy search algorithm on the code tree . in each level , only the one of two edges with larger probability is selected for further processing .    .",
    "the bold branches show a decoding path of sc with @xmath122 . ]",
    "the red bold edges in fig .",
    "[ fig_tree ] shows the sc decoding path .",
    "the number written next to each of the nodes provides the app metric of the decoding path from the root to that node .",
    "the nodes which are extended during the sc decoding procedure are represented by the numbered circles , and the corresponding numbers indicate the processing order .",
    "the black circles represent the nodes which are visited ( whose app metric is calculated ) but failed in competition for further exploring . and the gray ones are those which are not visited during the searching process . in the example , four times of calculations of equation ( [ equ_app ] ) are required , one for each level .",
    "however , the decoding path is not guaranteed to be the most probable one . as shown in the example",
    ", the one labeled @xmath123 has the largest probability of all the @xmath4-length paths , but it failed in the competition at the first level .    for further practical considerations , we use the logarithmic apps as the path metrics : @xmath124 for @xmath125 , the path metric can be recursively calculated as @xmath126 and @xmath127    where function @xmath128 is the jacobian logarithm and @xmath129 , @xmath130 .",
    "then , the decision function of sc in ( [ equ_sc_h ] ) is rewritten as @xmath131    using the space - efficient structure @xcite to implement a sc decoder , the time and space complexity are @xmath132 and @xmath133 respectively .",
    "the performance of sc is limited by the bit - by - bit decoding strategy . since whenever a bit is wrongly determined , there is no chance to correct it in the future decoding procedure .",
    "theoretically , the performance of the maximum _ a posteriori _ probability ( map ) decoding ( or equivalently ml decoding , since the inputs are assumed to be uniformly distributed ) can be achieved by traversing all the @xmath4-length decoding paths in the code tree @xmath89 . but this brute - force traverse takes exponential complexity and is difficult to be implemented .",
    "two improved decoding algorithms called successive cancellation list ( scl ) decoding and successive cancellation stack ( scs ) are proposed in @xcite @xcite and @xcite .",
    "both of these two algorithms allow more than one edge to be explored in each level of the code tree . during the scl(scs )",
    "decoding , a bunch of candidate paths will be obtained and stored in a list(stack ) . since for every single candidate path ,",
    "the metric calculations and bit determinations are still performed bit - by - bit successively , scl and scs can be regarded as two improved versions of conventional sc decoding .    in this section",
    ", we will restate scl and scs under a unified framework with the help of app metrics and the code tree representations . then to overcome the own shortages of scl and scs , a new hybrid decoding algorithm named successive cancellation hybrid ( sch ) decoding is proposed .",
    "furthermore , to reducing the computational complexities , we propose a pruning technique to eliminate the unnecessary calculations during the path searching procedure on the code tree .      .",
    "]    as an enhanced version of sc , the successive cancellation list ( scl ) decoder @xcite @xcite searches level - by - level on the code tree , which is just the same with sc .",
    "however , unlike sc where only one path is reserved after processing at each level , scl allows at most @xmath134 candidate paths to be further explored at the next level .",
    "scl can be regarded as a breadth - first searching on the code tree @xmath135 with a searching width @xmath134 . at each level",
    ", scl doubles the number of candidates by appending a bit @xmath107 or a bit @xmath85 to each of the candidate paths , and then selects at most @xmath134 ones with largest metrics and stores them in a list for further processing at the next level .",
    "finally , when reaching the leaf nodes , the binary labels @xmath21 corresponding to the edges in path @xmath136 which has the largest metric in the list , are assigned to the estimated source vector @xmath81 .",
    "let @xmath137 denotes the set of candidate paths corresponding to the level-@xmath84 of code tree in a scl decoder .",
    "the @xmath137s are stored and updated in a list structure .",
    "the scl decoding algorithm with searching width @xmath134 , denoted by scl(@xmath134 ) , can be described as follows :    ( a.1 ) initialization .",
    "a null path is included in the initial list and its metric is set to zero , i.e. @xmath138 , @xmath139 .",
    "( a.2 ) expansion . at the @xmath84-th level of the code tree ,",
    "the number of candidate paths in the list are doubled by concatenating new bits @xmath140 taking values of @xmath107 and @xmath85 respectively , that is , @xmath141    for each @xmath142 , the corresponding path metric(s ) are updated according to ( [ equ_metric_info_or_froz ] ) , ( [ equ_metric_odd ] ) and ( [ equ_metric_even ] ) .    ( a.3 ) competition .",
    "if the number of paths in the list after ( a.2 ) is no more than @xmath134 , just skip this step ; otherwise , reserve the @xmath134 paths with the largest metrics and delete the others .",
    "( a.4 ) determination .",
    "repeat ( a.2 ) and ( a.3 ) until level-@xmath4 is reached .",
    "then , the decoder outputs the estimated source vector @xmath143 , where @xmath21 is the binary labels of the path with the largest metric in the list .    fig .",
    "[ fig_scl ] gives a simple example of the tree searching under scl decoding with @xmath144 .",
    "compare with sc in fig .",
    "[ fig_tree ] , scl find the most probable path @xmath123 .",
    "but the times of metric computations is increased from four to seven .",
    "scl maintains @xmath134 decoding paths simultaneously , each path consumes a @xmath133 space , the space complexity of scl then is @xmath145 . during the decoding process at each level ,",
    "each of the @xmath134 candidates is copied once and extended to two new paths , these copy operations require @xmath145 computations .",
    "moreover , since the code tree has @xmath4 levels , a direct implementation of scl decoder will take @xmath146 computations . in @xcite , a so called `` lazy copy '' technique based on the memory sharing structure among the candidate paths",
    "is introduced to reduce this copy complexity .",
    "therefore , the scl decoder can be implemented with computational complexity @xmath147 .",
    "note that , the path metric ( [ equ_metric_info_or_froz ] ) of a certain decoding path with binary label vector @xmath113 will not be smaller than that of any of its descendants , i.e. for any @xmath148 and @xmath149 , @xmath150    hence , if the metric of a @xmath4-length decoding path is larger than that of another path with length @xmath151 , it must also be larger than the metric of any of the @xmath4-length descendant path of the latter .",
    "so rather than waiting after processing at each level , we can keep on searching along the single candidate path until its metric is no longer the largest . once a @xmath4-length path is found with the largest metric among all the candidate paths ,",
    "its binary label vector is simply output as the final estimation , the unnecessary computations for extending other paths are then saved",
    ".    the scs decoder @xcite uses a ordered stack @xmath152 to store the candidate paths and tries to find the optimal estimation by searching along the best candidate in the stack .",
    "whenever the top path in the stack which has the largest path metric reaches length @xmath4 , the decoding process stops and outputs this path . unlike the candidate paths in the list of scl which always have the same length , the candidates in the stack of scs have difference lengths",
    "let @xmath153 denote the maximal the stack @xmath152 in scs decoder .",
    "a little different from the original scs in @xcite , an additional parameter @xmath134 is introduced to limit the number of extending paths with certain length in decoding process .",
    "a counting vector @xmath154 is used to record the number of the popping paths with specific length , i.e. @xmath155 means the number of popped paths with length-@xmath84 during the decoding process .    the scs decoding algorithm with the searching width @xmath134 and",
    "the maximal stack depth @xmath153 , denoted by scs @xmath156 , is summarized as follows :    ( b.1 ) initialization : push the null path into stack and set the corresponding metric @xmath139 .",
    "initialize the counting vector @xmath157 with all - zeros , and the instantaneous stack depth @xmath158 .",
    "( b.2 ) popping : pop the path @xmath159 from the top of stack , and if the path is not null , set @xmath160 .",
    "( b.3 ) expansion : if @xmath140 is a frozen bit , i.e. @xmath161 , simply extend the path to @xmath162 ; otherwise , if @xmath140 is an information bit , extend current path to @xmath163 and @xmath164",
    ". then calculate path metric(s ) by ( [ equ_metric_info_or_froz ] ) , ( [ equ_metric_odd ] ) and ( [ equ_metric_even ] ) .",
    "( b.4 ) pushing : for information bit @xmath165 , if @xmath166 , delete the path from the bottom of the stack .",
    "then push the two extended paths into the stack .",
    "otherwise , for frozen bit @xmath140 , push the path @xmath167 into stack directly .",
    "( b.5 ) competition : if @xmath168 , delete all the paths with length less than or equal to @xmath169 from the stack @xmath152 .",
    "( b.6 ) sorting : resort paths in the stack from top to bottom in descending metrics .",
    "( b.7 ) determination : if the top path in the stack reaches to the leaf node of the code tree , pop it from the stack .",
    "the decoding algorithm stops and outputs @xmath143 as the decision sequence .",
    "otherwise go back and execute step ( b.2 ) .",
    "[ fig_scs ] gives a simple example of the tree searching under scs .",
    "compare with scl in fig .",
    "[ fig_scl ] , scs can also find the most probable path @xmath123 with two fewer metric computations .",
    "similar to sc and scl , the space efficient structure and `` lazy copy '' technique are applied in the implementation of scs decoders .",
    "the time and space complexity of scs are @xmath147 and @xmath170 respectively . however , under the same searching width @xmath134 , the actual computations of scs@xmath171 will be much fewer than that of scl@xmath171 when workding in the moderate or high snr regime .",
    "compared with scl , scs decoding can save a lot of unnecessary computations especially when working in the high signal - to - noise ( snr ) regime @xcite .",
    "however , the stack used in scs consumes a much larger space than scl . theoretically , to prevent performance deterioration",
    ", the stack depth @xmath153 needs to be as large as @xmath172 , thus the space complexity will becomes @xmath173 .",
    "fortunately , as shown in @xcite , a much smaller stack - depth @xmath153 is enough for moderate and high snr regimes .",
    "but the most appropriate value of @xmath153 is relied on the specific snr and is hard to determine .    in this paper ,",
    "a new hybrid decoding algorithm called successive cancellation hybrid ( sch ) is proposed .",
    "sch , as the name suggests , is a hybrid of scl and scs .",
    "sch has two working modes called _ on - going _ and _ waiting_. at first , sch decoder works on the on - going mode , it searches along the best candidate path using a ordered stack just the same as that scs does .",
    "but when the stack is about to be full , sch stops searching forward and switches to the waiting mode . under the waiting mode , sch turns to extend the shortest path in the stack until all the candidate paths in the stack have the same length .",
    "the processing under waiting mode is somewhat similar to scl and it decreases the number of paths in stack .",
    "then , sch switches back to the on - going mode again . fig . [ fig_sch ] gives a graphic illustration .",
    "this decoding procedure goes on until an @xmath4-length path appears at the top of the stack .",
    "the sch algorithm with the searching width @xmath134 , the maximal stack depth @xmath153 , denoted by sch @xmath174 , is summarized as follows :    ( c.1 ) initialization : push the null path into stack @xmath152 and set the corresponding metric @xmath139 . initialize the counting vector @xmath175 with all - zeros , and the instantaneous stack depth @xmath158 .",
    "the working mode flag @xmath176 is set to @xmath107 , where @xmath107 denote the on - going mode and @xmath85 denote the waiting mode .",
    "( c.2 ) popping : when @xmath177 , pop the path @xmath159 from the top of stack ; else when @xmath178 , pop the path @xmath159 with the shortest path length in the stack . then",
    ", if the popped path is not null , i.e. @xmath179 , set @xmath160 .",
    "( c.3 ) expansion : if @xmath140 is a frozen bit , i.e. @xmath180 , simply extend the path to @xmath181 ; otherwise , if @xmath140 is an information bit , i.e. @xmath39 , extend current path to @xmath163 and @xmath164",
    ". then calculate path metric(s ) by ( [ equ_metric_info_or_froz ] ) , ( [ equ_metric_odd ] ) and ( [ equ_metric_even ] ) .",
    "( c.4 ) pushing : for information ( frozen ) bit @xmath140 , push the new two paths ( one path ) into the stack .",
    "( c.5 ) competition : if @xmath168 , delete all the paths with length less than or equal to @xmath169 from the stack @xmath152 .",
    "( c.6 ) mode switching : when @xmath177 and @xmath182 , switch @xmath178 ; when @xmath178 and all the candidate pathes in the stack have equal lengths , @xmath178 ;    ( c.7 ) sorting : resort paths in the stack from top to bottom in descending metrics .",
    "( c.8 ) determination : if the top path in the stack reaches to the leaf node of the code tree , pop it from the stack .",
    "the decoding algorithm stops and outputs @xmath143 as the decision sequence .",
    "otherwise go back and execute step ( c.2 ) .",
    "the time and space complexity of sch are @xmath147 and @xmath170 respectively .",
    "the actual computations of sch decoding is less than that of scl but is usually more than that of scs .    for sch decoding ,",
    "since no path is dropped when the stack is about to be full , the performance will not affected by @xmath153 . however ,",
    "when decoder stays in the waiting mode , unnecessary computations will be taken . and the smaller the maximum stack depth is @xmath153 , the more likely the decoder will switch to the waiting mode .",
    "so , the computational complexity grows with the decreasing of @xmath153 . to have enough space for waiting mode",
    ", the minimum value of @xmath153 is @xmath183 . particularly , when @xmath184 , sch(@xmath134,@xmath153 ) is equivalent to scl(@xmath134 ) ; and when @xmath185 , sch(@xmath134,@xmath153 ) is equivalent to scs(@xmath134,@xmath153 ) .",
    "candidates divide the probability space into @xmath134 partitions . ]    during the path searching on the code tree , the candidate paths with too small metrics and their descendants will hardly have the chance to be reserved in the future process . in this subsection",
    ", we propose a pruning technique to reduce the computational complexity of the improved successive cancellation decoding algorithms .",
    "an additional vector @xmath186 is used to record the pruning reference for each level , where @xmath187 is the largest metric of all the traversed @xmath84-length decoding paths on the code tree .",
    "more specifically , for scl decoding , @xmath188 and equivalently , for scs and sch , @xmath187 is set to the metric of the first @xmath84-length path popped off the stack .",
    "we introduce a new parameter called probability ratio threshold @xmath189 . during the processing at level-@xmath84 on the code tree",
    ", a @xmath84-length path with metric smaller than @xmath190 is dropped directly .",
    "recall that the path metrics are defined as the logarithmic apps ( [ equ_metric_info_or_froz ] ) .",
    "therefore , the pruned paths are those whose apps @xmath191    intuitively , the correct path will possibly be dropped in this pruning operation . in the following part of this subsection ,",
    "an upperbound of the additional performance deterioration brought by @xmath189 is derived and a conservative configuration of @xmath189 is given .",
    "hereafter , scl , scs and sch are collectively referred to as improved successive cancellation ( isc ) decoding algorithms .",
    "the block error event of polar code with information set @xmath36 under isc decoding is defined as @xmath192    by introducing pruning operations , the error events can be classified into two kinds .",
    "the first kind is the correct path is not lost until the final decision phase , i.e. the correct path is contained in the final list(or stack ) but does not have the largest metric .",
    "the second kind is the correct path is lost before the decision step .",
    "so , the block error rate ( bler ) of isc can be decomposed as @xmath193 where @xmath194 means the correct path loss .",
    "the event @xmath195 can be further decomposed as @xmath196 where @xmath197 is the event that the correct path is not lost until the processing at the @xmath84-th level .",
    "there are three kinds of event which will lead to path loss at the @xmath84-th level .",
    "the first is brought by the searching width limitation , i.e. the correct path is excluded from the @xmath134 best paths in @xmath84-th decoding step , and is denoted by @xmath198 .",
    "the second is brought by the maximum probability ratio limitation , i.e. the metric of the correct path is much smaller than that of the best one , and is denoted by @xmath199 .",
    "the third is brought by the maximum stack depth limitation , which only exist in the scs decoding that the correct path is abandoned when the path length equals @xmath84 and the metric is much smaller than the maximum one at that moment , and this event is denoted by @xmath200 .",
    "then @xmath201 for scl , sch decoding or scs with a large enough stack depth @xmath153 , @xmath202 .",
    "the additional bler performance deterioration brought by pruning is @xmath203    during the processing on the code tree @xmath89 , we will have at most @xmath134 paths at level-@xmath84 with apps @xmath204 which is calculated by ( [ equ_app ] ) , and @xmath205 without loss of generality , we assume that @xmath206 . by the assumption that the one of these paths is the correct path , the @xmath134 probability divided the whole probability space into @xmath134 parts as shown in fig . [ fig_prob_space ] .",
    "the event of correct path loss in the pruning processing at the @xmath84-th level has a probability @xmath207    for each of these eliminated paths , the corresponding probability @xmath208 where @xmath209 .",
    "so we have @xmath210    the additional error probability brought by @xmath189 is upper bounder by @xmath211    given a tolerable performance deterioration @xmath212 , the value of @xmath189 can be determined as @xmath213    in most cases , since the upperbound in ( [ equ_ptau_upperbound ] ) is very loose , the accrual performance deterioration is usually far less than @xmath212 .",
    "the configuration of @xmath189 in ( [ equ_tau_value ] ) is very conservative .",
    "in this section , the performance and complexity of the improved successive cancellation ( isc ) decoding algorithms will be discussed .    to simplify the complexity evaluation of polar decoding",
    ", we measure the average computational complexity in terms of the number of metric recursive operations , which are defined in ( [ equ_metric_odd ] ) or ( [ equ_metric_even ] ) .",
    "for example , the computational complexity of sc decoder is @xmath214 .",
    "[ fig_diff_len_performance ] gives the simulation results with code length @xmath4 set as @xmath215 and @xmath216 , and the code rate @xmath217 . and",
    "[ fig_diff_rate_performance ] shows the bler performances with code rate @xmath218 set as @xmath219 and @xmath220 , and the code length @xmath4 is fixed to @xmath215 .",
    "the lowerbounds of bler performance under maximum - likelihood ( ml ) decoding are obtained by performing scl(@xmath221 ) decoding and counting the number of times the decoded codeword is more likely than the transmitted one .",
    "the probability ratio threshold @xmath189 for pruning operation is set by ( [ equ_tau_value ] ) with @xmath222 . as shown in the figures , under proper configurations ,",
    "all the three decoding algorithms can achieve the performance very close to that of ml decoding .",
    "the average computational complexities under different decoding algorithms with code length @xmath223 and code rate @xmath217 are shown in fig .",
    "[ fig_diff_dec_complexity ] .",
    "we can see that the complexity of sch is not monotonically decreasing with the increasing of snr .",
    "this is because the switching between the two working modes is relied on the certain code construction and searching procedures .",
    "however , sch always has a much lower computational complexity than that of scl .",
    "although it needs more computations than scs , sch occupies less memory space without any deterioration in performance .",
    "in fact , under some specific configurations , sch can be equivalent to the other two decoding algorithms : when @xmath184 , sch(@xmath134 , @xmath183 ) is equivalent to scl(@xmath134 ) ; and when @xmath153 is very large , sch(@xmath134 , @xmath153 ) is equivalent to scs(@xmath134 , @xmath153 ) ; therefore , sch can achieve a better trade - off between computational complexity and space complexity .",
    "furthermore , by applying the pruning technique introduced in section [ subsec_prune ] , the computational complexity can be significantly reduced and very close to that of sc in the moderate and high snr regime .",
    "compared with sc , isc decoding algorithms introduce three more parameters : the searching width @xmath134 , the maximum stack depth @xmath153 and probability ratio threshold for pruning @xmath189 . in the following part of this section",
    ", we will analysis the impacts on performance and complexity of this three parameters one - by - one .      ]    ]    fig .",
    "[ fig_diff_l_performance ] gives the performance comparisons under scl decoding with different @xmath134 .",
    "the code length and code rate are set as @xmath223 and @xmath224 respectively .",
    "the searching width @xmath134 varies from @xmath85 ( equivalent to sc ) to @xmath225 .",
    "note that , scl(@xmath134 ) is equivalent to sch(@xmath134 , @xmath183 ) and scs(@xmath134 , @xmath153 ) with a large enough @xmath153 .",
    "the affects brought by different @xmath134 in scl decoding are the same with that in scs and sch .",
    "the larger the searching width is , the less probable to lose the correct path , i.e. @xmath226 in ( [ equ_event_ci ] ) is a decreasing function of @xmath134 . but according to the results depicted in fig .",
    "[ fig_diff_l_complexity ] , the computational complexity is approximately proportional to @xmath134 . as shown in fig .",
    "[ fig_diff_l_performance ] , @xmath227 is good enough for @xmath223 and @xmath224 .      ]    for polar codes under scs decoding , a too small value of the maximum stack depth @xmath153 will lead to significant deterioration on performance . as shown in fig .",
    "[ fig_diff_d_performance ] , @xmath153 need to be larger than @xmath215 for scs decoding . but for sch , the different configurations of @xmath153 no longer affect the bler performance but the computational complexity . as shown in fig .",
    "[ fig_diff_d_complexity ] , the computational complexity of sch is decreasing with the increasing of @xmath153 .",
    "although it needs more computations than scs , sch occupies less memory space without any deterioration in performance .",
    "compared with scl , sch has much lower computational complexity and only require a little more memory space .",
    "in fact , under some specific configurations , sch can be equivalent to the other two decoding algorithms : when @xmath184 , sch(@xmath134 , @xmath183 ) is equivalent to scl(@xmath134 ) ; and when @xmath153 is very large , sch(@xmath134 , @xmath153 ) is equivalent to scs(@xmath134 , @xmath153 ) ; hence , sch can achieve a better trade - off between computational complexity and space complexity .    ]      ]    ]    fig .",
    "[ fig_diff_tau_performance ] and fig .",
    "[ fig_diff_tau_complexity ] give simulations of polar codes with code length @xmath223 code rate @xmath224 over binary - input additive gaussian noise channels ( bawgncs ) .",
    "the codes are decoded by sch decoders with @xmath227 , @xmath228 and @xmath189 varies from @xmath85 to @xmath229 . as shown in the figures ,",
    "the computational complexity will be reduced when the increasing of @xmath189 , while the bler performance will be deteriorated with a too small @xmath189 .",
    "larger values of @xmath189 such as @xmath230 will introduce little deterioration in performance , but will lead to larger complexities .",
    "however , when the codes work in a moderate signal - to - noise ratio ( snr ) regime such as @xmath231db where the bler is less than @xmath232 , the computational complexity differences of sc and sch decoding under different @xmath189 in the simulated regime tends to negligible as shown in fig .",
    "[ fig_diff_tau_complexity ] .",
    "the successive cancellation ( sc ) decoding algorithm of polar codes and its improved versions , successive cancellation list ( scl ) and successive cancellation stack ( scs ) are restated as path searching procedures on the code tree of polar codes . combining the ideas of scl and scs ,",
    "a new decoding algorithm named successive cancellation hybrid ( sch ) is proposed , which can achieve a better trade - off between computational complexity and space complexity . to avoid unnecessary path searching ,",
    "a pruning technique which is suitable for all improved successive cancellation ( isc ) decoders is proposed .",
    "performance and complexity analysis based on simulations show that , with the help of the pruning technique , all the isc decoders can have a performance very close to that of maximum - likelihood ( ml ) decoding , and the computational complexities can be very close to that of sc in the moderate and high signal - to - noise ratio ( snr ) regime .",
    "e.  arikan , `` channel polarization : a method for constructing capacity - achieving codes for symmetric binary - input memoryless channels , '' _ ieee trans .",
    "inf . theory _",
    "55 , no . 7 , pp . 3051 - 3073 , jul ."
  ],
  "abstract_text": [
    "<S> as improved versions of successive cancellation ( sc ) decoding algorithm , successive cancellation list ( scl ) decoding and successive cancellation stack ( scs ) decoding are used to improve the finite - length performance of polar codes . </S>",
    "<S> unified descriptions of sc , scl and scs decoding algorithms are given as path searching procedures on the code tree of polar codes . </S>",
    "<S> combining the ideas of scl and scs , a new decoding algorithm named successive cancellation hybrid ( sch ) is proposed , which can achieve a better trade - off between computational complexity and space complexity . </S>",
    "<S> further , to reduce the complexity , a pruning technique is proposed to avoid unnecessary path searching operations . </S>",
    "<S> performance and complexity analysis based on simulations show that , with proper configurations , all the three improved successive cancellation ( isc ) decoding algorithms can have a performance very close to that of maximum - likelihood ( ml ) decoding with acceptable complexity . </S>",
    "<S> moreover , with the help of the proposed pruning technique , the complexities of isc decoders can be very close to that of sc decoder in the moderate and high signal - to - noise ratio ( snr ) regime .    </S>",
    "<S> polar codes , successive cancellation decoding , code tree , tree pruning . </S>"
  ]
}