{
  "article_text": [
    "organizations including the census bureau , medical establishments , and internet companies collect and publish statistical information  @xcite .",
    "the census bureau may , for instance , publish the result of a query such as : `` how many individuals have incomes that exceed $ 100,000 ? '' . an implicit hope in this approach",
    "is that aggregate information is sufficiently anonymous so as not to breach the privacy of any individual .",
    "unfortunately , publication schemes initially thought to be `` private '' have succumbed to privacy attacks  @xcite , highlighting the urgent need for mechanisms that are _ provably _ private .",
    "the differential privacy literature  @xcite has proposed a rigorous and quantifiable definition of privacy , as well as provably privacy - preserving mechanisms for diverse applications including statistical queries , machine learning , and pricing .",
    "informally , for @xmath3 $ ] , a randomized mechanism is @xmath4-differentially private if changing a row of the underlying database  the data of a single individual  changes the probability of every mechanism output by at most an @xmath4 factor .",
    "larger values of @xmath4 correspond to greater levels of privacy .",
    "differential privacy is typically achieved by adding noise that scales with @xmath4 .",
    "while it is trivially possible to achieve any level of differential privacy , for instance by always returning random noise , this completely defeats the original purpose of providing useful information . on the other hand ,",
    "returning fully accurate results can lead to privacy disclosures  @xcite . _",
    "the goal of this paper is to identify , for each @xmath3 $ ] , the optimal ( i.e. , utility - maximizing ) @xmath4-differentially private mechanism . _",
    "we consider databases with @xmath5 rows drawn from a finite domain @xmath6 .",
    "every row corresponds to an individual .",
    "two databases are _ neighbors _ if they coincide in @xmath7 rows .",
    "a _ count query _",
    "@xmath8 takes a database  @xmath9 as input and returns the result @xmath10 that is the number of rows that satisfy a fixed , non - trivial predicate on the domain @xmath6 .",
    "such queries are also called predicate or subset - sum queries ; they have been extensively studied in their own right  @xcite , and form a basic primitive from which more complex queries can be constructed  @xcite .    a randomized mechanism with a ( countable ) range @xmath11 is a function @xmath12 from @xmath13 to @xmath11 , where @xmath14 is the probability of outputting the response @xmath15 when the underlying database is @xmath16 . for @xmath17 $ ]",
    ", a mechanism @xmath12 is _ @xmath4-differentially private _ if the ratio @xmath18 lies in the interval @xmath19 $ ] for every possible output @xmath20 and pair @xmath21 of neighboring databases .",
    "( we interpret @xmath22 as @xmath23 . ) intuitively , the probability of every response of the privacy mechanism  and hence the probability of a successful privacy attack following an interaction with the mechanism  is , up to a controllable @xmath4 factor , independent of whether a given user `` opts in '' or `` opts out '' of the database .",
    "a mechanism is _ oblivious _ if , for all @xmath20 , @xmath24 whenever @xmath25  if the output distribution depends only on the query result .",
    "most of this paper considers only oblivious mechanisms ; for optimal privacy mechanism design , this is without loss of generality in a precise sense ( see section  [ sec : oblivious ] ) .",
    "the notation and definitions above simplify for oblivious mechanisms and count queries .",
    "we can specify an oblivious mechanism via the probabilities @xmath26 of outputting a response @xmath27 for each query result @xmath28 ; @xmath4-differential privacy is then equivalent to the constraint that the ratios @xmath29 lie in the interval @xmath19 $ ] for every possible output @xmath20 and query result @xmath30 .",
    "the _ @xmath4- geometric mechanism _ is defined as follows .",
    "when the true query result is @xmath31 , the mechanism outputs @xmath32 .",
    "@xmath33 is a random variable distributed as a two - sided geometric distribution : @xmath34=\\frac{1-\\alpha}{1+\\alpha } \\alpha^{|z|}$ ] for every integer  @xmath35 .",
    "this ( oblivious ) mechanism is @xmath4-differentially private because the probabilities of adjacent points in its range differ by an @xmath4 factor and because the true answer to a count query differs by at most one on neighboring databases .",
    "this paper pursues strong and general utility guarantees . just as differential privacy guarantees protection against every potential attacker , independent of its side information , we seek mechanisms that guarantee near - optimal utility to _ every _ potential user , independent of its side information and preferences .",
    "we now formally define preferences and side information .",
    "we model the preferences of a user via a _ loss function _ @xmath36 ; @xmath37 denotes the user s loss when the query result is @xmath38 and the mechanism s ( perturbed ) output is @xmath15 .",
    "we allow @xmath36 to be arbitrary , subject only to being nonnegative , and nondecreasing in @xmath39 for each fixed  @xmath38 .",
    "for example , the loss function @xmath39 measures mean error , the implicit measure of ( dis)utility in most previous literature on differential privacy .",
    "two among the many other natural possibilities are @xmath40 , which essentially measures variance of the error ; and the binary loss function @xmath41 , defined as @xmath42 if @xmath43 and @xmath23 otherwise .",
    "we model the side information of a user as a prior probability distribution @xmath44 over the query results @xmath28 .",
    "this prior represents the beliefs of the user , which might stem from other information sources , previous interactions with the mechanism , introspection , or common sense .",
    "we emphasize that we are _ not _ introducing priors to weaken the definition of differential privacy ; we use the standard definition of differential privacy ( which makes no assumptions about the side information of an attacker ) and use a prior only to discuss the _ utility _ of a ( differentially private ) mechanism to a potential user .    now consider a user with a prior @xmath44 and loss function @xmath36 and an oblivious mechanism @xmath12 with range @xmath11 . for a given input @xmath16 with query result @xmath45 ,",
    "the user s expected loss is @xmath46 , where the expectation is over the coin flips internal to the mechanism . the user s prior then yields a measure of the mechanism s overall ( dis)utility to the the user :    @xmath47    this is simply the expected loss over the coin tosses of the mechanism and the prior .",
    "we can then define the _ optimal _ @xmath4-differentially private mechanism for a user as one that minimizes the user - specific objective function ( [ eq : utility ] ) .",
    "could a single mechanism be good simultaneously for all users ? a crucial observation for an affirmative answer is that a user has the power to post - process the output of a privacy mechanism , and that such post - processing can decrease the user s expected loss .",
    "fix a database size @xmath5 that is odd .",
    "consider a user with the binary loss function @xmath48 and prior @xmath49 , @xmath50 for all @xmath51 , that interacts with the @xmath4-geometric mechanism . without post - processing ,",
    "i.e. , when the user accepts the mechanism s outputs at face value , the user s expected loss is @xmath52 .",
    "if the user maps outputs of the geometric mechanism that are at least @xmath53 to @xmath5 and all other outputs to @xmath42 , it effectively induces a new mechanism with the much smaller expected loss of @xmath54 .    in general , a ( randomized ) _ remap _ of a mechanism @xmath12 with range @xmath11 is a probabilistic function @xmath55 , with @xmath56 denoting the probability that the user reinterprets the mechanism s",
    "response @xmath57 as the response @xmath20 .",
    "a mechanism @xmath12 and a remap @xmath55 together induce a new ( @xmath4-differentially private ) mechanism @xmath58 with @xmath59 .",
    "we assume that a ( rational ) user with prior @xmath60 and loss function @xmath36 , interacting with a publicly known mechanism @xmath12 , employs a remap @xmath55 that induces the mechanism @xmath58 that minimizes its expected loss   over all such remaps .",
    "it is well known ( e.g.  ( * ? ? ?",
    "* chapter 9 ) ) and easy to see that , among all possible ( randomized ) remappings , the optimal one follows from applying bayes rule and then minimizing expected loss .",
    "precisely , for each response @xmath15 of @xmath12 , compute the posterior probability over query results : for every @xmath61 , @xmath62 . then , choose the query result @xmath63 that minimizes expected loss subject to the posterior and set @xmath64 and @xmath65 for @xmath66 .",
    "this remap is simple , deterministic , and can be computed efficiently .",
    "1 in [ fig : factor ]    our main result is that for every @xmath3 $ ] , _ the @xmath4-geometric mechanism is simultaneously optimal for every rational user . _",
    "[ thm : main ] let @xmath67 denote the @xmath4- geometric mechanism for some database size @xmath68 and privacy level @xmath3 $ ] , and let @xmath69 denote an optimal remap of @xmath67 for the user @xmath1 with prior @xmath60 and ( monotone ) loss function @xmath36",
    ". then @xmath70 minimizes @xmath1 s expected loss   over all oblivious , @xmath4-differentially private mechanisms with range @xmath71 .",
    "this is an extremely strong utility - maximization guarantee : _ every _ potential user @xmath1 , no matter what its side information and preferences , derives as much utility from the geometric mechanism as it does from interacting with a differentially private mechanism @xmath2 that is optimally tailored to @xmath1 .",
    "we reiterate that the prior from the utility model plays no role in the definition of privacy , which is the standard , worst - case ( over adversaries with arbitrary side - information and intent ) guarantee provided by differential privacy .",
    "we emphasize that while the geometric mechanism is user - independent ( all users see the same distribution over responses ) , different users remap its responses in different ways , as informed by their individual prior distributions and loss functions .",
    "rephrasing theorem  [ thm : main ] , for every user there is an optimal mechanism for it that factors into a user - independent part  the @xmath4-geometric mechanism  and a user - specific computation that can be delegated to the user .",
    "( see figure  [ fig : factor ] . )",
    "theorem  [ thm : main ] shows how to achieve the same utility as a user - specific optimal mechanism without directly implementing one .",
    "direct user - specific optimization would clearly involve several challenges .",
    "first , it would require advance knowledge or elicitation of user preferences , which we expect is impractical in most applications . and",
    "even if a mechanism was privy to the various preferences of its users , it would effectively need to answer the same query in different ways for different users , which in turn degrades its differential privacy guarantee .    in theorem  [ thm : main ]",
    ", the restriction to oblivious mechanisms is , in a precise sense , without loss of generality .",
    "( see section  [ sec : oblivious ] . )",
    "the restriction to the range @xmath71 effectively requires that the mechanism output is a legitimate query result for some database ; this type of property is called `` consistency '' in the literature ( e.g.  @xcite ) .",
    "differential privacy is motivated in part by the provable impossibility of absolute privacy against attackers with arbitrary side information  @xcite .",
    "one interpretation of differential privacy is : no matter what prior distribution over databases a potential attacker has , its posterior after interacting with a differentially private mechanism is almost independent of whether a given user `` opted in '' or `` opted out '' of the database  @xcite .",
    "below we discuss the papers in the differential privacy literature closest to the present work ; see  @xcite for a recent , thorough survey of the state of the field .",
    "dinur and nissim  @xcite showed that for a database with @xmath5 rows , answering @xmath72 randomly chosen subset count queries with @xmath73 error allows an adversary to reconstruct most of the rows of the database ( a blatant privacy breach ) ; see dwork et al .",
    "@xcite for a more robust impossibility result of the same type .",
    "most of the differential privacy literature circumvents these impossibility results by focusing on interactive models where a mechanism supplies answers to only a sub - linear ( in @xmath5 ) number of queries .",
    "count queries ( e.g.  @xcite ) and more general queries ( e.g.  @xcite ) have been studied from this perspective .",
    "blum et al .  @xcite take a different approach by restricting attention to count queries that lie in a restricted class ; they obtain non - interactive mechanisms that provide simultaneous good accuracy ( in terms of worst - case error ) for all count queries from a class with polynomial vc dimension .",
    "kasiviswanathan et al .",
    "@xcite give further results for privately learning hypotheses from a given class .",
    "the use of abstract `` utility functions '' in mcsherry and talwar  @xcite has a similar flavor to our use of loss functions , though the motivations and goals of their work and ours are unrelated .",
    "motivated by pricing problems , mcsherry and talwar  @xcite design differentially private mechanisms for queries that can have very different values on neighboring databases ( unlike count queries ) ; they do not consider users with side information ( i.e. , priors ) and do not formulate a notion of mechanism optimality ( simultaneous or otherwise ) .",
    "finally , in recent and independent work , mcsherry and talwar ( personal communication , october 2008 ) also apply linear programming theory in the analysis of privacy mechanisms . again",
    ", their goal is different : they do not consider a general utility model , but instead ask how expected error must scale with the number of queries answered by a differentially private mechanism .",
    "this section proves theorem  [ thm : main ] .",
    "the proof has three high - level steps .    1 .   for a given user @xmath1",
    ", we formulate the problem of determining the differentially private mechanism that minimizes expected loss as a solution to a linear program ( lp ) .",
    "the objective function of this lp is user - specific , but the feasible region is not .",
    "2 .   we identify several necessary conditions met by every privacy mechanism that is optimal for some user .",
    "3 .   for every privacy mechanism that satisfies these conditions ,",
    "we construct a remap @xmath55 such that @xmath74 . by assumption",
    ", a rational user employs an `` optimal remap '' of @xmath67 , so the mechanism induced by this map must be optimal for the user @xmath1 .    fix a database size @xmath5 and a privacy level @xmath4 .",
    "theorem  [ thm : main ] is trivially true for the degenerate cases of @xmath75 .",
    "so , we assume that @xmath76 . for every fixed user with loss function @xmath36 and prior @xmath60 ,",
    "the formulation of privacy constraints in section  [ sec : dp ] together with the objective function   yields the following lp whose solution is an optimal mechanism for this user .",
    "@xmath77    since the lp is bounded and feasible , we have the following ( e.g.  @xcite ) .",
    "[ lem : lp ] every user - specific lp has an optimal solution that is a vertex .",
    "for the rest of this section , fix a user with prior @xmath44 and a loss function @xmath37 that is monotone in @xmath39 for every @xmath78 .",
    "fix a mechanism @xmath12 that is optimal for this user , and also a vertex of the polytope of the user - specific lp .",
    "vertices can be uniquely identified by the set of all constraints that are tight at the vertex .",
    "this motivates us to characterize the _ state of constraints _ ( slack or tight ) of mechanisms that are optimal for some user .",
    "we now begin the second step of the proof .",
    "we will view @xmath12 as a @xmath79-matrix where rows correspond to query results ( inputs ) and columns correspond to query responses ( outputs ) .",
    "we state our necessary conditions in terms of an @xmath80 _ constraint _ matrix  @xmath81 associated with the mechanism @xmath12 .",
    "row @xmath38 of the constraint matrix corresponds to rows @xmath38 and @xmath82 of the corresponding mechanism .",
    "every entry of @xmath83 , for @xmath84 , @xmath85 takes on exactly one of four values . if @xmath86 then @xmath87 . if @xmath88 , then there are three possibilities . if @xmath89 then @xmath90 . if @xmath91 then @xmath92 .",
    "otherwise @xmath93 .    [ cols=\"^,^,^,^,^,^,^\",options=\"header \" , ]     [ f : simmech ]    we are now ready to prove theorem  [ thm : imposs ] .",
    "theoremthm : imposs by the previous lemma and the definitions of @xmath94 and @xmath95 , the mechanism @xmath12 must have the form in figure [ f : simmech ] . because @xmath12 is @xmath96-differentially private and as @xmath97 and @xmath98 differ in exactly two rows , columns @xmath5 and @xmath99 yield the following inequalities : @xmath100 , and @xmath101 . adding the two inequalities",
    ", we have : @xmath102 . because all the entries of @xmath12 are probabilities , we have @xmath103 .",
    "so it must be that @xmath104 . by a similar argument applied to the databases @xmath105 } and @xmath106",
    ", we can show that @xmath107 .",
    "thus , the probability masses on @xmath36 when the underlying databases are @xmath97 and @xmath108 are @xmath109 and @xmath110 respectively . but",
    "this violates privacy because , the two databases differ in exactly one row but the two probabilities are not within a factor @xmath111 of each other .",
    "we proposed a model of user utility , where users are parametrized by a prior ( modeling side information ) and a loss function ( modeling preferences ) .",
    "theorem  [ thm : main ] shows that for every fixed count query , database size , and level of privacy , there is a single simple mechanism that is simultaneously optimal for all rational users .",
    "are analogous results possible for other definitions of privacy , such as the additive variant of differential privacy ( see  @xcite ) ?",
    "is an analogous result possible for other types of queries or for multiple queries at once ? when users have priors over databases ( theorem  [ thm : imposs ] ) , are any positive results ( such as simultaneous _ approximation _ ) achievable via a single mechanism ?",
    "we thank preston mcafee , john c. mitchell , rajeev motwani , david pennock and the anonymous referees .",
    "l.  backstrom , c.  dwork , and j.  kleinberg .",
    "wherefore art thou r3579x ? : anonymized social networks , hidden patterns , and structural steganography . in",
    "_ proceedings of the 16th international conference on world wide web ( www ) _ , pages 181190 , 2007 .",
    "b.  barak , k.  chaudhuri , c.  dwork , s.  kale , f.  mcsherry , and k.  talwar .",
    "privacy , accuracy , and consistency too : a holistic solution to contingency table release . in _ proceedings of the 26th acm sigact - sigmod - sigart symposium on principles of database systems ( pods ) _ , pages 273282 , 2007 .",
    "a.  blum , c.  dwork , f.  mcsherry , and k.  nissim .",
    "practical privacy : the sulq framework . in _ proceedings of the 24th acm sigact - sigmod - sigart symposium on principles of database systems ( pods ) _ , pages 128138 , 2005 .          c.  dwork .",
    "differential privacy . in _ proceedings of the 33rd annual international colloquium on automata , languages , and programming ( icalp )",
    "_ , volume 4051 of _ lecture notes in computer science _ ,",
    "pages 112 , 2006 .    c.  dwork .",
    "differential privacy : a survey of results . in _",
    "5th international conference on theory and applications of models of computation ( tamc ) _ , volume 4978 of _ lecture notes in computer science _ , pages 119 , 2008 .    c.  dwork , f.  mcsherry , k.  nissim , and a.  smith . calibrating noise to sensitivity in private data analysis . in _",
    "third theory of cryptography conference ( tcc ) _ , volume 3876 of _ lecture notes in computer science _ , pages 265284 , 2006 .      c.  dwork and k.  nissim .",
    "privacy - preserving datamining on vertically partitioned databases . in _",
    "24th annual international cryptology conference ( crypto ) _ , volume 3152 of _ lecture notes in computer science _ , pages 528544 , 2004 .",
    "s.  p. kasiviswanathan , h.  k. lee , k.  nissim , s.  raskhodnikova , and a.  smith .",
    "what can we learn privately ?",
    "in _ proceedings of the 49th annual ieee symposium on foundations of computer science ( focs ) _ , pages 531540 , 2008 ."
  ],
  "abstract_text": [
    "<S> a mechanism for releasing information about a statistical database with sensitive data must resolve a trade - off between utility and privacy . </S>",
    "<S> publishing fully accurate information maximizes utility while minimizing privacy , while publishing random noise accomplishes the opposite . </S>",
    "<S> privacy can be rigorously quantified using the framework of _ differential privacy _ , which requires that a mechanism s output distribution is nearly the same whether or not a given database row is included or excluded . </S>",
    "<S> the goal of this paper is strong and general utility guarantees , subject to differential privacy .    </S>",
    "<S> we pursue mechanisms that guarantee near - optimal utility to every potential user , independent of its side information ( modeled as a prior distribution over query results ) and preferences ( modeled via a loss function ) . </S>",
    "<S> our main result is : for each fixed count query and differential privacy level , there is a _ geometric mechanism _ </S>",
    "<S> @xmath0  a discrete variant of the simple and well - studied laplace mechanism  that is _ simultaneously expected loss - minimizing _ for every possible user , subject to the differential privacy constraint . </S>",
    "<S> this is an extremely strong utility guarantee : _ every _ potential user @xmath1 , no matter what its side information and preferences , derives as much utility from @xmath0 as from interacting with a differentially private mechanism @xmath2 that is optimally tailored to  @xmath1 . </S>",
    "<S> more precisely , for every user  @xmath1 there is an optimal mechanism  @xmath2 for it that factors into a user - independent part ( the geometric mechanism  @xmath0 ) followed by user - specific post - processing that can be delegated to the user itself .    </S>",
    "<S> the first part of our proof of this result characterizes the optimal differentially private mechanism for a fixed but arbitrary user in terms of a certain basic feasible solution to a linear program with constraints that encode differential privacy . </S>",
    "<S> the second part shows that all of the relevant vertices of this polytope ( ranging over all possible users ) are derivable from the geometric mechanism via suitable remappings of its range . </S>"
  ]
}