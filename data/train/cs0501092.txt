{
  "article_text": [
    "for many problems , a team of vehicles can accomplish an objective more efficiently and more effectively than a single vehicle can .",
    "some examples include target intercept  @xcite , search  @xcite , terrain mapping  @xcite , object manipulation  @xcite , surveillance , and space - based interferometry . for these problems , it is desirable to design a multi - vehicle cooperative control strategy",
    ".    there is a large literature on cooperative control .",
    "work from team theory  @xcite considers the case where team members have different information and the objective function is quadratic .",
    "cooperative estimation for reconnaissance problems is considered in  @xcite . in  @xcite mixed integer linear programming",
    "is used for multi - vehicle target assignment and intercept problems .",
    "hierarchical methods are used for cooperative rendezvous in  @xcite and for target assignment and intercept in  @xcite .",
    "a review from the machine learning perspective is presented in  @xcite .",
    "there are several recent compilations of cooperative control articles in  @xcite .    in this paper",
    ", we propose a hybrid systems approach for modeling and cooperative control of multi - vehicle systems .",
    "we use the class of hybrid systems called mixed logical dynamical systems  @xcite , which are governed by difference equations and logical rules and are subject to linear inequality constraints .",
    "the main motivation for using mixed logical dynamical systems is their ability to model a wide variety of multi - vehicle problems and the ease of modifying problem formulations . in our approach",
    ", a problem is modeled as a mixed logical dynamical system , which we represent as a mixed integer linear program ( milp ) .",
    "then , to generate a cooperative control strategy for the system , the milp is solved using ampl  @xcite and cplex  @xcite .",
    "posing a multi - vehicle control problem in a milp framework involves modeling the vehicle dynamics and constraints , modeling the environment , and expressing the objective . to demonstrate the modeling procedure and our approach , we consider control problems involving cornell s multi - vehicle system called roboflag .",
    "for an introduction to roboflag , see the papers from the invited session on roboflag in the proceedings of the 2003 american control conference  @xcite .",
    "our focus is to find optimal solutions using a flexible methodology , which is why we use milp .",
    "however , because milp is in the np - hard computation class  @xcite , the methods may not be fast enough for real - time control of systems with large problem formulations . in this case , the methods can be used to explore optimal cooperative behavior and as benchmarks to evaluate the performance of heuristic or approximate methods . in section  [ sec : discussion ] , we discuss several methods for reducing the computational requirements of our milp approach so that it can be more readily used in real - time applications .",
    "our approach for multi - vehicle control , first presented in  @xcite , was developed independently from a similar approach developed by richards et .",
    "al .  @xcite .",
    "next , we list some of the noteworthy aspects of our approach .",
    "first , the environment which we demonstrate our methods involves an adversarial component .",
    "we model the intelligence of the adversaries with state machines .",
    "second , our approach allows multiple , possibly nonuniform , time discretizations .",
    "discretizing continuous variables in time is necessary for milp formulations . using many time steps results in large milps that require a considerable amount of computation time to solve .",
    "support for nonuniform discretizations in time allows the use of intelligent time step selection algorithms for the generation of more efficient milp problem formulations  @xcite .",
    "finally , because we include the vehicle dynamics in the problem formulation , the resulting trajectories are feasible , which is advantageous because they can be applied directly to the multi - vehicle system .",
    "in order to express the vehicle dynamics efficiently in our milp formulation , we restrict the control input to each vehicle in a way that allows near - optimal performance , as presented in  @xcite .",
    "the paper is organized as follows : first , we consider vehicle problems that have relatively simple formulations",
    ". then we add features in each section until we arrive at the roboflag multi - vehicle problems . in section  [ vehicle_dynamics ]",
    ", we introduce the dynamics of the vehicles used to motivate our approach , and we formulate and solve a single vehicle minimum control effort trajectory generation problem .",
    "we build upon this in section  [ sec : avoidance ] adding obstacles that must be avoided . in section  [ sec : dd ] , we show how to generate optimal team strategies for roboflag problems . in section  [ sec : ctime ] , we perform an average case computational complexity study on our approach .",
    "finally , in section  [ sec : discussion ] , we discuss our methods and ways in which they can be be applied .",
    "all files for generating the plots found in this paper are available online  @xcite .",
    "multi - vehicle control problems involving the wheeled robots of cornell s robocup team  @xcite are used to motivate the methods presented in this paper . in this section ,",
    "we show how to simplify their nonlinear governing equations using a procedure from  @xcite .",
    "the result is a linear set of governing equations coupled by a nonlinear constraint on the control input , which admits feasible vehicle trajectories and allows near - optimal performance .",
    "we then show how to represent the simplified system in a milp problem formulation .",
    "each vehicle has a three - motor omni - directional drive , which allows it to move along any direction irrespective of its orientation .",
    "the nondimensional governing equations of each vehicle are given by @xmath0 +    \\left [ \\begin{array}{c }      \\dot{x}(t ) \\\\",
    "\\dot{y}(t ) \\\\",
    "\\frac{2ml^2}{i}\\dot{\\theta}(t )     \\end{array } \\right ] =    \\mathbf{u}(\\theta(t),t),\\ ] ] where @xmath1 , @xmath2,\\ ] ] and @xmath3 . in these equations , @xmath4 are the coordinates of the vehicle on the playing field , @xmath5 is the orientation of the vehicle , @xmath6 is the @xmath5-dependent control input , @xmath7 is the mass of the vehicle , @xmath8 is the vehicle s moment of inertia , @xmath9 is the distance from the drive to the center of mass , and @xmath10 is the voltage applied to motor @xmath11 .",
    "the set of admissible voltages @xmath12 is given by the unit cube , and the set of admissible control inputs is given by @xmath13 .",
    "these governing equations are coupled and nonlinear . to simplify them ,",
    "we replace the set @xmath14 with the maximal @xmath15-independent set found by taking the intersection of all possible sets of admissible controls .",
    "the result is a @xmath15-independent control input , denoted @xmath16 , that is subject to the inequality constraints @xmath17 and @xmath18 .    using the restricted set as the set of allowable control inputs , the governing equations decouple and",
    "are given by @xmath0 +    \\left [ \\begin{array}{c }      \\dot{x}(t ) \\\\",
    "\\dot{y}(t ) \\\\",
    "\\frac{2ml^2}{i}\\dot{\\theta}(t )     \\end{array } \\right ] =    \\left [ \\begin{array}{c }      u_x(t ) \\\\",
    "u_y(t ) \\\\",
    "u_\\theta(t )     \\end{array } \\right].\\ ] ] the constraints on the control input couple the degrees of freedom .    to decouple the @xmath15 dynamics , we set @xmath19 . then the constraint on the control input becomes @xmath20 now the equations of motion for the translational dynamics of the vehicle are given by @xmath21 subject to equation  ( [ nl_u_constraint ] ) . in state space form ,",
    "equation  ( [ eqn : gov ] ) is @xmath22 , where @xmath23 is the state and @xmath24 is the control input .    by restricting the admissible control inputs we have simplified the governing equations in a way that allows near optimal performance as shown in  @xcite .",
    "this procedure allows real - time calculation of many near - optimal trajectories and has been successfully used by cornell s robocup team  @xcite .    to represent the governing equations in a milp framework , we discretize the control input in time and require it be constant between time steps .",
    "the result is a set of linear discrete time governing equations .",
    "let @xmath25 be the number of discretization steps for the control input @xmath26 , let @xmath27 $ ] be the time at step @xmath28 , and let @xmath29>0 $ ] be the time between steps @xmath28 and @xmath30 , for @xmath31 .",
    "the discrete time governing equations are given by    @xmath32 = \\mathbf{a}[k ] \\mathbf{x}_u[k ]     + \\mathbf{b}[k ] \\mathbf{u}[k ] ,    \\label{disdyn}\\ ] ]    where @xmath33 = \\mathbf{x}(t_u[k])$ ] , @xmath34 = \\mathbf{u}(t_u[k])$ ] , @xmath35 =      \\left [ \\begin{array}{cccc }      1 & 0 & 1-e^{-t_u[k ] } & 0 \\\\       0 & 1 & 0 & 1-e^{-t_u[k ] } \\\\       0 & 0 & e^{-t_u[k ] } & 0 \\\\       0 & 0 & 0 & e^{-t_u[k ] }      \\end{array } \\right ] ,    \\nonumber\\end{aligned}\\ ] ] @xmath36 =      \\left [ \\begin{array}{cc }      t_u[k]-1+e^{-t_u[k ] } & 0 \\\\       0 & t_u[k]-1+e^{-t_u[k ] } \\\\       1-e^{-t_u[k ] } & 0 \\\\       0 & 1-e^{-t_u[k ] }      \\end{array } \\right ] ,    \\nonumber\\end{aligned}\\ ] ] @xmath33 = ( x_u[k],y_u[k],\\dot{x}_u[k],\\dot{y}_u[k])$ ] , and @xmath34 = ( u_{x}[k],u_{y}[k])$ ] .",
    "the coefficients @xmath37 $ ] and @xmath38 $ ] are functions of @xmath28 because we have allowed for nonuniform time discretizations .",
    "because there will be several different time discretizations used in this paper , we use subscripts to differentiate them . in this section",
    ", we use the subscript @xmath39 to denote variables associated with the discretization in the control input @xmath26 .",
    "the discrete time governing equations can be solved explicitly to obtain @xmath40&{}={}&x_u[0 ] +    \\left(1-e^{-t_u[k]}\\right)\\dot{x}_u[0 ]    \\nonumber\\\\    & & { + } \\:\\sum_{i=0}^{k-2 }     \\left (      \\left(t_u[i ] - 1 + e^{-t_u[i]}\\right ) u_{x}[i ]     \\right.\\nonumber\\\\    & & { + } \\:\\left.\\left(1-e^{t_u[i+1 ] - t_u[k]}\\right )    \\left(1-e^{-t_u[i]}\\right ) u_{x}[i ]    \\right)\\nonumber\\\\    & & { + } \\:\\left(t_u[k-1]-1+e^{-t_u[k-1]}\\right)u_{x}[k-1],\\nonumber\\end{aligned}\\ ] ] @xmath41&{}={}&e^{-t_u[k ] } \\dot{x}_u[0]\\nonumber\\\\    & & { + } \\:\\sum_{i=0}^{k-2 } \\left(e^{t_u[i+1]-t_u[k ] }    \\left(1-e^{-t_u[i]}\\right)u_{x}[i]\\right)\\nonumber\\\\    & & { + } \\:\\left(1-e^{-t_u[k-1]}\\right)u_{x}[k-1],\\nonumber \\end{aligned}\\ ] ] and similarly for @xmath42 $ ] and @xmath43 $ ] .",
    "in later sections of this paper it will be necessary to represent the position of the vehicle at times between control discretization steps , in terms of the control input .",
    "because the set of governing equations is linear , given the discrete state @xmath33 $ ] and the control input @xmath34 $ ] , we can calculate the vehicle s state at any time @xmath44 using the following equations : @xmath45 + ( 1 - e^{t_u[k ] - t } ) \\dot{x}_u[k]\\nonumber\\\\    & & { + } \\:(t - t_u[k ] - 1 + e^{t_u[k ] - t } ) u_{x}[k],\\nonumber\\\\    \\dot{x}(t)&{}= { } & ( e^{t_u[k ] - t } ) \\dot{x}_u[k ]    + ( 1 - e^{t_u[k ] - t } )   u_{x}[k ] ,    \\label{inbetween}\\end{aligned}\\ ] ] where @xmath28 satisfies @xmath27 \\leq t \\leq t_u[k+1]$ ] . if the time discretization of the control input is uniform , @xmath46 = t_u$ ] for all @xmath47 , then @xmath48 .",
    "the other components of the vehicle s state , @xmath49 and @xmath50 , can be calculated in a similar way .    the control input constraint given by equation  ( [ nl_u_constraint ] )",
    "can not be expressed in a milp framework because it is nonlinear . to incorporate this constraint",
    "we approximate it with a set of linear inequalities that define a polygon .",
    "the polygon inscribes the region defined by the nonlinear constraint .",
    "we take the conservative inscribing polygon to guarantee that the set of allowable controls , defined by the region , is feasible .",
    "we define the polygon by the set of @xmath51 linear inequality constraints @xmath52 \\sin \\frac{2 \\pi m}{m_u } +     u_{y}[k ] \\cos \\frac{2 \\pi m}{m_u } \\leq \\cos \\frac{\\pi}{m_u}\\nonumber\\\\     & & \\forall m \\in \\ { 1,\\ldots , m_u \\ } ,    \\label{linconstraint}\\end{aligned}\\ ] ] for each step @xmath53 .    to illustrate the approach , we consider the following minimum control effort trajectory generation problem . given a vehicle governed by equations  ( [ disdyn ] ) and  ( [ linconstraint ] ) , find the sequence of control inputs @xmath54\\}_{k=0}^{n_u-1}$ ] that transfers the vehicle from starting state @xmath55 to finishing state @xmath56 and minimizes the cost function @xmath57| + |u_{y}[k]| \\right ) .",
    "\\label{mincontrolcost1}\\end{aligned}\\ ] ] to convert the absolute values in the cost function to linear form , we introduce auxiliary continuous variables @xmath58 $ ] and @xmath59 $ ] and the inequality constraints @xmath60 \\leq u_{x}[k ] \\leq z_x[k]\\nonumber\\\\ & & -z_y[k ] \\leq u_{y}[k ] \\leq z_y[k ] .",
    "\\label{slackconstraints}\\end{aligned}\\ ] ] minimizing @xmath58 $ ] subject to the inequalities @xmath61 \\leq z_x[k]$ ] and @xmath61 \\geq -z_x[k]$ ] is equivalent to minimizing @xmath62|$ ] ( similarly for @xmath63|)~\\cite{bertsimas97}$ ] . using the auxiliary variables , the cost function can be written as a linear function , @xmath64 + z_y[k ] \\right ) .",
    "\\label{mincontrolcost2}\\end{aligned}\\ ] ] the resulting optimization problem ( minimize  ( [ mincontrolcost2 ] ) subject to  ( [ disdyn ] ) ,  ( [ linconstraint ] ) ,  ( [ slackconstraints ] ) , and the boundary conditions ) is in milp form .",
    "because binary variables do not appear in the problem formulation , it is a linear program and is easily solved to obtain the optimal sequence of control inputs .",
    "the solution for an example instance is shown in figure  [ mincontrol1 ] .     plane .",
    "the circle and dotted line denote the initial position and velocity , respectively .",
    "the square denotes the final position .",
    "figures  ( b)(d ) show the time histories of the control inputs , the positions , and the velocities , respectively .",
    "the solid lines in figures  ( b)(d ) represent @xmath65 components and the dotted lines represent @xmath66 components .",
    "the values for the parameters are @xmath67 , @xmath68 , @xmath29 = 0.3 $ ] for all @xmath28 , @xmath69 , and @xmath70 . ]",
    "in vehicle control , it is necessary to avoid other vehicles , stationary and moving obstacles , and restricted regions . in this section , we show how to formulate and solve these avoidance problems using milp .",
    "we start by showing a milp method to guarantee circular obstacle avoidance at @xmath71 discrete times .",
    "the version of this method developed in  @xcite , and a similar version developed independently in in  @xcite , uniformly distributes obstacle avoidance times . here",
    "we present a version of the method that allows nonuniform distributions of obstacle avoidance times .",
    "the subscript @xmath72 is used to denote variables associated with the time discretization for obstacle avoidance . for step @xmath28 ,",
    "taken to be an element of the set @xmath73 , let @xmath74 $ ] be the time at which obstacle avoidance is enforced .",
    "let @xmath75 denote the radius of the obstacle .",
    "let @xmath76,y_{obst}[k])$ ] denote the coordinates of its center at time @xmath74 $ ] .",
    "we approximate the obstacle with a polygon , denoted @xmath77 $ ] , defined by a set of @xmath78 inequalities .",
    "the polygon is given by @xmath79&{}:={}&\\ { \\mbox { } ( \\bar{x},\\bar{y } ) : \\nonumber\\\\    & & ( \\bar{x}-x_{obst}[k ] ) \\sin \\frac{2 \\pi m}{m_{o}}\\nonumber\\\\    & & { + } \\:(\\bar{y}-y_{obst}[k ] ) \\cos \\frac{2 \\pi m}{m_{o } }       \\leq r_{obst}\\nonumber\\\\    & & \\forall m \\in \\{1,\\ldots , m_{o}\\ } \\mbox { } \\}.    \\label{obst_con1}\\end{aligned}\\ ] ] to guarantee obstacle avoidance at time @xmath74 $ ] , the coordinates of the vehicle must be outside the region @xmath77 $ ] .",
    "this avoidance condition can be written as @xmath80,y_o[k ] ) \\notin \\mathcal{o}[k]$ ] , where @xmath80,y_o[k])$ ] are the coordinates of the vehicle at time @xmath74 $ ] . here",
    "@xmath81 = x(t_o[k])$ ] and @xmath82=y(t_o[k])$ ] are expressed in terms of the control inputs using equation  ( [ inbetween ] ) .    because at least one constraint defining the region @xmath77 $ ] must be violated in order to avoid the obstacle",
    ", the avoidance condition is equivalent to the following condition : @xmath83-x_{obst}[k ] ) \\sin \\frac{2 \\pi m}{m_{o}}\\nonumber\\\\     & & { + } \\:(y_o[k]-y_{obst}[k ] ) \\cos \\frac{2 \\pi m}{m_{o } } >      r_{obst}.\\end{aligned}\\ ] ]    to express this avoidance constraint in a milp problem formulation , it must be converted to an equivalent set of linear inequality constraints .",
    "we do so by introducing auxiliary binary variable @xmath84 \\in \\ { 0,1 \\}$ ] and the following @xmath78 inequality constraints , @xmath85-x_{obst}[k ] ) \\sin \\frac{2 \\pi m}{m_{o}}\\nonumber\\\\    & & { + } \\:(y_o[k]-y_{obst}[k ] ) \\cos \\frac{2 \\pi m}{m_{o } }    > r_{obst } - h b_m[k]\\nonumber\\\\    & & \\forall m \\in \\ { 1,\\ldots , m_{o } \\ } , \\end{aligned}\\ ] ] where @xmath86 is a large positive number taken to be larger than the maximum dimension of the vehicle s operating environment plus the radius of the obstacle .",
    "if @xmath84 = 1 $ ] , the right hand side of the inequality is a large , negative number that is always less than the left hand side . in this case ,",
    "the inequality is inactive because it is trivially satisfied .",
    "if @xmath84= 0 $ ] , the inequality is said to be active because it reduces to an inequality from the existence condition above . for obstacle avoidance , at least one of the constraints in equation  ( [ avoidconstraints1 ] )",
    "must be active . to enforce this , we introduce the following inequality constraint into the problem formulation , @xmath87 \\leq m_{o}-1 .",
    "\\label{avoidconstraints2}\\end{aligned}\\ ] ]    therefore , to enforce obstacle avoidance at time @xmath74 $ ] , the set of binary variables @xmath88\\}_{m=1}^{m_o}$ ] and the constraints given by equations  ( [ avoidconstraints1 ] ) and  ( [ avoidconstraints2 ] ) are added to the milp problem formulation .",
    "consider the example problem from section  [ vehicle_dynamics ] with obstacles . in this problem , we want to transfer the vehicle from start state @xmath89 to finish state @xmath90 in time @xmath91 using minimal control effort while avoiding obstacles . to enforce obstacle avoidance at each time in the set @xmath92\\}_{k=1}^{n_o}$",
    "] , we augment the milp formulation in section  [ vehicle_dynamics ] with the set of binary variables @xmath88\\}_{m=1}^{m_o}$ ] , constraints  ( [ avoidconstraints1 ] ) , and constraint  ( [ avoidconstraints2 ] ) for all @xmath28 in the set @xmath73 .    distributing the avoidance times uniformly ( uniform gridding ) , as in  @xcite , results in a trajectory that avoids obstacles at each discrete time in the set , but",
    "the trajectory can collide with obstacles between avoidance times .",
    "this is shown for an example instance in figure  [ mineffortobst](a ) .",
    "in this example , the trajectory intersects the obstacle between the sixth and seventh avoidance time steps .",
    "a simple method to eliminate this behavior is to represent the obstacle with a polygon that is larger than the obstacle",
    ". then distribute obstacle avoidance times uniformly such that the sampling time is small enough to guarantee avoidance .",
    "in general , this is not a desirable approach because it results in large milps that require significant computational effort to solve .",
    "s along the trajectory denote the avoidance points @xmath80,y_o[k])$ ] .",
    "figure  ( a ) is the original solution .",
    "figure  ( b ) is the solution after two steps of the iterative obstacle avoidance algorithm .",
    "the @xmath93 s are the avoidance points added to the milp formulation by the iterative algorithm .",
    "the values for the parameters are @xmath67 , @xmath94 , @xmath29 = 0.3 $ ] for all @xmath28 , @xmath95 , @xmath96 , @xmath74 = k t$ ] , @xmath97 , and @xmath98 .",
    ", width=336 ]    a better approach is to select the avoidance times intelligently . in  @xcite , we have developed an iterative milp algorithm that does this .",
    "we summarize this algorithm here .",
    "first , pick an initial set of times @xmath92\\}_{k=1}^{n_o}$ ] at which obstacle avoidance will be enforced . then , formulate and solve the milp as described above representing the obstacles with polygons slightly larger than the obstacles .",
    "next , check the resulting trajectory for collisions with any of the obstacles ( not the polygons which represent them in the milp ) . if there are no collisions , terminate the algorithm .",
    "if there is a collision , compute the time intervals for which collisions occur denoting the time interval for collision @xmath11 by @xmath99 .",
    "for each interval @xmath11 , pick a time within the interval , such as @xmath100 . at each of these times add obstacle avoidance constraints to the milp formulation . then , solve the augmented milp repeating the procedure above ( first checking if the resulting trajectory intersects any obstacles , etc . ) until a collision free trajectory is found .",
    "figure  [ mineffortobst](b ) shows the effectiveness of this algorithm after two iterations .",
    "to motivate our multi - vehicle methods , we apply them to simplified versions of the roboflag game  @xcite , which we call roboflag drills because they serve as practice for the real game .",
    "the drills involve two teams of robots , the defenders and the attackers , on a playing field with a circular region of radius @xmath101 at its center called the defense zone , as shown in figure  [ drill ] .",
    "the attackers objective is to fill the defense zone with as many attackers as possible .",
    "the defenders objective is to deny as many attackers from entering the defense zone as possible without entering the zone themselves .",
    "we consider defensive drill problems in which each attacker has a fixed intelligence governed by a state machine .",
    "the goal is to design a team control strategy for the defenders that maximizes the number of attackers denied from the defense zone . in this section ,",
    "we use milp methods to generate such strategies .",
    "we consider two versions of the defensive drill each with a different set of laws governing attacker intelligence .    to start , we consider one - on - one defensive drill problems .",
    "this is the simplest case and involves one defender and one attacker .",
    "although this case is not particularly interesting , we start with it for notational clarity .",
    "next , we generalize to the case involving @xmath102 defenders and @xmath103 attackers , which is a straightforward extension .",
    "the defender is governed by the discrete time dynamical system from section  [ vehicle_dynamics ] @xmath104 = \\mathbf{a}[k ] \\mathbf{x}_u[k ]     + \\mathbf{b}[k ]    \\mathbf{u}[k]\\nonumber\\\\    & & \\mathbf{x}_u[0 ] = \\mathbf{x}_s\\nonumber\\\\    & & u_{x}[k ] \\sin \\frac{2 \\pi m}{m_u } +     u_{y}[k ] \\cos \\frac{2 \\pi m}{m_u } \\leq     \\cos \\frac{\\pi}{m_u}\\nonumber\\\\     & & \\forall m \\in \\ { 1,\\ldots , m_u \\}\\nonumber \\\\    & & \\forall k \\in \\ { 1,\\ldots , n_u \\}.    \\label{defdyn2}\\end{aligned}\\ ] ]    the attacker has two discrete modes : attack and inactive .",
    "when in attack mode , it moves toward the defense zone at constant velocity along a straight line path .",
    "the attacker , initially in attack mode at the beginning of play , transitions to inactive mode if the defender intercepts it or if it enters the defense zone .",
    "once inactive , the attacker does not move and remains inactive for the remainder of play .",
    "these dynamics are captured by the following discrete time equations and state machine @xmath105 = p[k ] + v_p t_a[k ] a[k]\\nonumber\\\\    & & q[k+1 ] = q[k ] + v_q t_a[k ] a[k ]    \\label{attdyn1}\\end{aligned}\\ ] ] @xmath106 = \\left\\ {    \\begin{array}{ll }      1 & \\mbox{if ( $ a[k]=1 $ ) } \\\\        & \\mbox{and ( not in defense zone ) } \\\\         & \\mbox{and ( not intercepted ) } \\\\      0 & \\mbox{if ( $ a[k]=0$)}\\\\        & \\mbox{or ( in defense zone ) } \\\\        & \\mbox{or ( intercepted ) }",
    "\\end{array } \\right . \\\\    & & \\forall k \\in \\ { 1,\\ldots , n_a \\ } \\nonumber\\end{aligned}\\ ] ]        with initial conditions @xmath107 = p_s$ , $ q[0 ] = q_s$ , and $ a[0 ] = 1 $ } ,      \\label{attdyn2}\\end{aligned}\\ ] ] where @xmath108 is the number of samples , @xmath109 , @xmath110>0 $ ] is the time between samples @xmath28 and @xmath30 , @xmath111,q[k])$ ] is the attacker s position at time @xmath112 = \\sum_{i=0}^{k-1 } t_a[i]$ ] , @xmath113 is its constant velocity vector , and @xmath114 \\in \\{0,1 \\}$ ] is a discrete state indicating the attacker s mode .",
    "the attacker is in attack mode when @xmath114 = 1 $ ] and inactive mode when @xmath114 = 0 $ ] .",
    "the attacker state machine is shown in figure  [ sm1 ] . here",
    "we use the subscript @xmath115 to denote the time discretization for the attacker s dynamics .",
    "+ * _ defense zone _ *    because the defender wants to keep the attacker from entering the defense zone , a binary variable indicating whether or not the attacker is inside the defense zone is introduced .",
    "this variable is used to define the attacker state machine precisely .",
    "we denote the binary variable with @xmath116 \\in \\ { 0,1 \\}$ ] .",
    "when the attacker is in the defense zone at step @xmath28 , @xmath116=1 $ ] . when the attacker is outside the defense zone at step @xmath28 , @xmath116=0 $ ] .",
    "similar to the approach used to define obstacles , the defense zone is approximated using a polygon @xmath117 defined by a set of @xmath118 inequalities @xmath119 the association between @xmath116 $ ] and @xmath117 is @xmath120 = 1 ) \\iff ( p[k],q[k ] ) \\in \\mathcal{g}.    \\label{gamma1}\\ ] ] if the defender keeps the binary variable @xmath116 $ ] equal to @xmath121 for all @xmath122 , it has successfully denied the attacker from the region @xmath117 and thus from the defense zone .",
    "however , in order to use the binary variable @xmath116 $ ] in the problem formulation , we must enforce the logical constraint given by equation  ( [ gamma1 ] ) . to enforce this constraint in milp ,",
    "we convert it into an equivalent set of inequality constraints .",
    "we introduce the binary variable @xmath123\\in \\ { 0,1 \\}$ ] to indicate whether or not the @xmath7th constraint of @xmath117 is satisfied by the attacker with position @xmath111,q[k])$ ] .",
    "this association is made by introducing the logical constraint @xmath124 = 1 \\right ) \\iff \\nonumber\\\\    & & \\left (    p[k ] \\sin \\frac{2 \\pi m}{m_{dz } } + q[k ] \\cos \\frac{2 \\pi m}{m_{dz } } \\leq     r_{dz }     \\right).\\end{aligned}\\ ] ] as shown in appendix  [ logicconvert ] , it is equivalent to the following set of inequalities @xmath125 \\sin \\frac{2 \\pi m}{m_{dz } }    + q[k ] \\cos \\frac{2 \\pi m}{m_{dz}}\\nonumber\\\\    & & \\;\\;\\;\\;\\leq r_{dz } + h ( 1-g_m[k])\\nonumber\\\\    & & p[k ] \\sin \\frac{2 \\pi m}{m_{dz } }    + q[k ] \\cos \\frac{2 \\pi m}{m_{dz}}\\nonumber\\\\     & & \\;\\;\\;\\;\\geq r_{dz } + \\epsilon - ( h+\\epsilon ) g_m[k ] ,    \\label{gammacon1}\\end{aligned}\\ ] ] where @xmath126 is a small positive number and @xmath86 is a large positive number such that the left hand sides of the inequalities are bounded from above by @xmath86 and from below by @xmath127 .    using binary variable @xmath123 $ ] , we can write equation  ( [ gamma1 ] ) as @xmath128 = 1 ) \\iff\\nonumber\\\\    & & ( g_m[k ] = 1\\;\\;\\;\\ ;    \\forall m \\in \\{1,\\ldots , m_{dz } \\ } ) ,    \\label{gamma2}\\end{aligned}\\ ] ] which is equivalent to the inequality constraints @xmath129 - \\gamma[k ] \\geq 0\\;\\;\\;\\ ;      \\forall m \\in \\ { 1,\\ldots , m_{dz } \\}\\nonumber\\\\      & & \\sum_{i=1}^{m_{dz}}(1-g_i[k ] ) + \\gamma[k ] \\geq 1 ,     \\label{gammacon2}\\end{aligned}\\ ] ] as shown in appendix  [ logicconvert ] .",
    "the logical constraint given by equation  ( [ gamma1 ] ) is equivalent to the inequality constraints given by equations  ( [ gammacon1 ] ) and  ( [ gammacon2 ] ) .",
    "therefore , we can include the indicator variable @xmath116 $ ] in the milp formulation by also including the binary variables @xmath130 \\}_{m=1}^{m_a}$ ] and constraints  ( [ gammacon1 ] ) and  ( [ gammacon2 ] ) . +",
    "* _ intercept region _",
    "*    to define what it means for a defender to intercept an attacker , we introduce an intercept region @xmath131 $ ] rigidly attached to the defending robot .",
    "the intercept region is a polygon defined by a set of @xmath132 inequalities .",
    "if an attacker is in this polygon , it is considered intercepted . for the defender with",
    "coordinates @xmath133,y_a[k])$ ] , the intercept region is given by @xmath134&{}:= { } & \\ { \\mbox { } ( \\bar{x},\\bar{y}):\\nonumber\\\\     & & ( \\bar{x } - x_a[k ] ) \\sin \\frac{2 \\pi m}{m_i } +     ( \\bar{y } - y_a[k ] ) \\cos \\frac{2 \\pi m}{m_i } \\leq r_i\\nonumber\\\\    & & \\forall m \\in \\{1,\\ldots , m_i\\ } \\mbox { } \\ } ,   \\end{aligned}\\ ] ] where @xmath135 = x(t_a[k])$ ] and @xmath136 = y(t_a[k])$ ] are calculated using equation  ( [ inbetween ] ) , and @xmath137 is the inscribed radius of the polygon .",
    "the binary variable @xmath138 \\in \\{0,1\\}$ ] is introduced to indicate whether or not the attacker is inside the defender s intercept region .",
    "the association is made with the following logical constraint @xmath139 = 1 \\iff ( p[k],q[k ] ) \\in \\mathcal{i}[k].\\end{aligned}\\ ] ] using techniques similar to those used for @xmath116 $ ] , we convert this constraint into an equivalent set of inequality constraints as follows : for each of the inequalities defining the intercept region , we associate a binary variable @xmath140 \\in \\ { 0,1 \\}$ ] by introducing the logical constraint @xmath141 = 1 \\right ) \\iff \\nonumber\\\\       & & \\left((p[k ] - x_a[k ] ) \\sin \\frac{2 \\pi m}{m_i}\\right.\\nonumber \\\\       & & { + } \\:\\left.(q[k ] - y_a[k ] ) \\cos \\frac{2 \\pi m}{m_i } \\leq      r_{i}\\right),\\end{aligned}\\ ] ] where @xmath111,q[k])$ ] are the coordinates of the attacking robot . if @xmath140 = 1 $ ] , the coordinates of the attacking robot satisfy the @xmath7th inequality defining the intercept region . if @xmath140 = 0 $ ] , the @xmath7th inequality is not satisfied .",
    "similar to equation  ( [ gequiv ] ) , we can express this logic constraint as the set of inequalities @xmath142 - x_a[k ] ) \\sin \\frac{2 \\pi m}{m_i }     + ( q[k ] - y_a[k ] ) \\cos \\frac{2 \\pi m}{m_i}\\nonumber\\\\     & & \\;\\;\\;\\;\\leq r_i +   h(1-d_m[k])\\nonumber\\\\    & & ( p[k ] - x_a[k ] ) \\sin \\frac{2 \\pi m}{m_i }     + ( q[k ] - y_a[k ] ) \\cos \\frac{2 \\pi m}{m_i}\\nonumber\\\\     & & \\;\\;\\;\\;\\geq r_i + \\epsilon - ( h+\\epsilon ) d_m[k ] .",
    "\\label{deltacon1}\\end{aligned}\\ ] ] using the binary variables @xmath140 $ ] we can write equation  ( [ intercept1 ] ) as @xmath143 = 1 \\iff     ( d_m[k ] = 1 & \\forall m \\in \\{1,\\ldots , m_i \\}).\\end{aligned}\\ ] ] considering both directions of this equivalence , as done for @xmath116 $ ] above , we find that the statement is equivalent to the following set of inequality constraints @xmath144 - \\delta[k ] \\geq 0\\;\\;\\;\\ ;    \\forall m \\in \\ { 1,\\ldots , m_i\\}\\nonumber\\\\    & & \\sum_{i=1}^{m_i}(1-d_i[k ] ) + \\delta[k ] \\geq 1 .",
    "\\label{deltacon2}\\end{aligned}\\ ] ] we can use @xmath138 $ ] in our problem formulation if we include the binary variables @xmath145\\}_{m=1}^{m_a}$ ] and the inequalities constraints given by equations  ( [ deltacon1 ] ) and  ( [ deltacon2 ] ) .",
    "+   + * _ state machine and objective function _ *    with the indicator variables @xmath116 $ ] and @xmath138 $ ] defined , we revisit the attacker state machine and define it more precisely with the following state equation    , using binary variables @xmath138 $ ] and @xmath116$].,width=240 ]    @xmath146 = \\left\\ { \\begin{array}{ll } 1 & \\mbox{if $ a[k]=1 $ and $ \\gamma[k]=0$}\\\\    & \\mbox{and $ \\delta[k]=0 $ } \\\\ 0 & \\mbox{if $ a[k]=0 $ or $ \\gamma[k]=1$}\\\\    & \\mbox{or $ \\delta[k]=1 $ } , \\end{array } \\right . \\label{asgov2}\\end{aligned}\\ ] ]    which is shown in figure  [ sm2 ] .",
    "the state equations can be written as the logical expression @xmath147 = 1 ) \\iff$}\\nonumber\\\\    & & \\mbox{$(a[k]=1 $ and $ \\gamma[k]=0 $ and $ \\delta[k]=0)$ } ,    \\label{asgovlogic}\\end{aligned}\\ ] ] which is equivalent to the set of inequality constraints @xmath106 + \\delta[k ] \\leq 1\\nonumber\\\\    & & a[k+1 ] - a[k ] \\leq 0\\nonumber\\\\    & & a[k+1 ] + \\gamma[k ] \\leq 1\\nonumber\\\\    & & a[k ] - \\delta[k ] - \\gamma[k ] - a[k+1 ] \\leq 0 ,    \\label{attdyn3}\\end{aligned}\\ ] ] as shown in appendix  [ logicconvert ] .",
    "we have defined the dynamics of the defenders and the attackers , and we have converted these dynamics to milp form . the final step in formulating defensive drill 1 is to introduce an objective function that captures the defender s desire to deny the attacker from entering the defense zone .",
    "this objective is achieved by minimizing the binary variable @xmath116 $ ] over the duration of the drill , which is captured by minimizing the function @xmath148.\\end{aligned}\\ ] ] we set the duration of the drill such that @xmath149 \\geq \\sqrt { \\frac{p_s^2 + q_s^2}{v_p^2 + v_q^2 } } .\\end{aligned}\\ ] ] this allows the attacker enough time to reach the defense zone if it is not intercepted .",
    "in addition to intercepting the attacker , we would like to conserve fuel as a secondary objective .",
    "one way to achieve this is to add a small penalty on the control effort to the objective function as follows : @xmath148     + \\epsilon \\sum_{k = 0}^{n_u-1 }     \\left ( |u_{x}[k]| + |u_{y}[k]| \\right ) ,    \\label{objective3}\\end{aligned}\\ ] ] where @xmath126 is taken to be a small positive number because we want the minimization of the binary variable @xmath116 $ ] to dominate .",
    "we use the procedure outlined in section  [ vehicle_dynamics ] to write equation  ( [ objective3 ] ) in milp form .",
    "+ * _ summary and example _ *    we have formulated defensive drill 1 as the following optimization problem : minimize  ( [ objective3 ] ) subject to defender dynamics  ( [ defdyn2 ] ) ; attacker dynamics  ( [ attdyn1 ] ) ,  ( [ attdyn2 ] ) , and  ( [ attdyn3 ] ) for all @xmath150 ; the constraints for the @xmath116 $ ] indicator variable  ( [ gammacon1 ] ) and  ( [ gammacon2 ] ) for all @xmath151 and for all @xmath152 ; the constraints for the @xmath138 $ ] indicator variable  ( [ deltacon1 ] ) , and  ( [ deltacon2 ] ) for all @xmath153 and for all @xmath154 ; and the avoidance constraints for the defense zone  ( [ avoidconstraints1 ] ) and  ( [ avoidconstraints2 ] ) for all @xmath155 and for all @xmath156 .    the solution to an instance of this problem is shown in figure  [ 1d1a ] .",
    "for this instance , the defender denies the attacker from the defense zone ( shaded polygon ) by intercepting it . each asterisk along the attacker s trajectory denotes the position of the attacker at sample time @xmath112 $ ] .",
    "the white polygons along the defender s trajectory denotes the intercept region @xmath131 $ ] at time @xmath112 $ ] .",
    "s along the attacker s trajectory denote the attacker s position for each time @xmath112 $ ] .",
    "the polygons along the defender s trajectory denote the intercept region @xmath131 $ ] for each time @xmath112 $ ] .",
    "the @xmath157 s denote obstacle avoidance points .",
    ", width=288 ]          the dynamics of the defender are the same as the defender dynamics in section  [ sec : oneonone ] .",
    "the dynamics of the attacker are the same as the attacker dynamics in defensive drill 1 , but with an additional state called retreat .",
    "if a defender is too close to the attacker , the attacker enters the retreat state and reverses direction .",
    "while retreating , if the defender is far enough away , the attacker returns to attack mode .",
    "these dynamics are captured by the following discrete time equations and state machine : @xmath105 = p[k ] + v_p t_a[k ] a_1[k]\\nonumber\\\\    & & \\;\\;\\;\\;-\\ : v_p t_a[k ] a_2[k]\\nonumber\\\\    & & q[k+1 ] = q[k ] + v_q ta[k ] a_1[k]\\nonumber\\\\     & & \\;\\;\\;\\;-\\ : v_q t_a[k ] a_2[k ]     \\label{dd2attdyn1}\\end{aligned}\\ ] ] @xmath158 = \\left\\ {    \\begin{array}{ll }      1 &            \\mbox{if } [ \\mbox{($a_1[k]=1 $ and $ a_2[k]=0 $ ) } \\\\         & \\mbox{or ( $ a_1[k]=0 $ and $ a_2[k]=1 $ ) } ] \\\\         & \\mbox{and ( not scored ) } \\\\        & \\mbox{and ( not intercepted ) } \\\\         & \\mbox{and ( not in warning region ) } \\\\      0 & \\mbox{otherwise }    \\end{array } \\right.\\\\    & & a_2[k+1 ] = \\left\\ {    \\begin{array}{ll }      1 &            \\mbox{if } [ \\mbox{($a_1[k]=0 $ and $ a_2[k]=1 $ ) or }   \\\\        & \\mbox{($a_1[k]=1 $ and $ a_2[k]=0 $ ) } ] \\\\        & \\mbox{and ( not scored ) } \\\\        & \\mbox{and ( not intercepted ) } \\\\        & \\mbox{and ( in warning region ) } \\\\      0 & \\mbox{otherwise }    \\end{array } \\right.\\end{aligned}\\ ] ] for all @xmath159 and subject to the constraint @xmath160 + a_2[k ] \\leq 1\\end{aligned}\\ ] ] and the initial conditions",
    "@xmath161 = p_s$ , $ q[0 ] = q_s$ , $ a_1[0 ] = 1 $ , $ a_2[0 ] = 0$}.     \\label{dd2attic}\\end{aligned}\\ ] ] the state machine is shown in figure  [ sm3 ] .",
    "the attacker needs two binary state variables because it has three discrete modes of operation : attack , retreat , and inactive .",
    "these modes are represented by @xmath162,a_2[k ] ) = ( 1,0)$ ] , @xmath162,a_2[k ] ) = ( 0,1)$ ] , and @xmath162,a_2[k ] ) = ( 0,0)$ ] , respectively .",
    "because the state @xmath162,a_2[k ] ) = ( 1,1)$ ] is not needed , we impose the inequality constraint given by equation  ( [ dd2ascon1 ] ) .    to determine if the defender is too close to the attacker , a warning region is introduced .",
    "the warning region @xmath163 $ ] is a polygon defined by a set of inequalities similar to the intercept region @xmath131 $ ] .",
    "we introduce binary auxiliary variables @xmath164 $ ] and @xmath165 $ ] , and we introduce inequality constraints similar to equations  ( [ deltacon1 ] ) and  ( [ deltacon2 ] ) .",
    "the result is the following association for indicator variable @xmath165 $ ] : if @xmath165 = 1 $ ] , the defender is in the attacker s warning region at step @xmath28 , otherwise , @xmath165 = 0 $ ] . the attacker state machine can be written as the set of inequality constraints @xmath158 - a_1[k ] + a_2[k ] + \\gamma[k ] + \\delta[k ] + \\omega[k ]      \\geq 0\\nonumber\\\\    & & a_1[k+1 ] + a_1[k ] - a_2[k ] + \\gamma[k ] + \\delta[k ] +        \\omega[k ] \\geq 0\\nonumber\\\\     & & a_2[k+1 ] + a_1[k ] - a_2[k ] + \\gamma[k ] + \\delta[k ] -       \\omega[k ] \\geq -1\\nonumber\\\\    & & a_2[k+1 ] - a_1[k ] + a_2[k ] + \\gamma[k ] + \\delta[k ] -       \\omega[k ] \\geq -1\\nonumber\\\\     & & a_1[k+1 ] + a_1[k ] + a_2[k ] \\leq 2\\nonumber\\\\     & & a_1[k+1 ] - a_1[k ] - a_2[k ] \\leq 0\\nonumber\\\\    & & a_1[k+1 ] + \\gamma[k ] \\leq 1\\nonumber\\\\    & & a_1[k+1 ] + \\delta[k ] \\leq 1\\nonumber\\\\    & & a_1[k+1 ] + \\omega[k ] \\leq 1\\nonumber\\\\     & & a_2[k+1 ] - a_1[k ] - a_2[k ] \\leq 0\\nonumber\\\\     & & a_2[k+1 ] + a_1[k ] + a_2[k ] \\leq 2\\nonumber\\\\    & & a_2[k+1 ] + \\gamma[k ] \\leq 1\\nonumber\\\\    & & a_2[k+1 ] + \\delta[k ] \\leq 1\\nonumber\\\\      & & a_2[k+1 ] - \\omega[k ] \\leq 0 .",
    "\\label{dd2asineq}\\end{aligned}\\ ] ]    similar to defense drill 1 , defense drill 2 can be posed as a milp .",
    "the solution of an example instance is shown in figure  [ dd2_1d1a_1 ] .    ,",
    "@xmath166 , @xmath167 , @xmath168 , @xmath169 , @xmath170 , @xmath171 , @xmath172 , @xmath173 , and @xmath174.,width=336 ]      to generalize the problem formulation to @xmath102 defenders and @xmath103 attackers , we need to add more variables .",
    "defender @xmath11 , where @xmath175 , has state @xmath176 $ ] , control input @xmath177 $ ] , and slack variables @xmath178 $ ] and @xmath179 $ ] .",
    "attacker @xmath180 , where @xmath181 , has state @xmath182,q_j[k],a_j[k])$ ] and constant velocity vector @xmath183 . the binary variable @xmath184 $ ] equals @xmath185 if and only if attacker @xmath180 is in polygon @xmath117 at step @xmath28 . the binary variable @xmath186 $ ] equals @xmath185 if and only if attacker @xmath180 is in defender @xmath11 s intercept region @xmath187 $ ] at step @xmath28 . the binary variables",
    "@xmath188 $ ] , @xmath189 $ ] , and @xmath190 $ ] follow a similar trend . for defensive drill 2 ,",
    "we also need @xmath191 = 1 $ ] if and only if defender @xmath11 is in attacker @xmath180 s warning region @xmath192 $ ] at step @xmath28 .",
    "and similarly for the binary variable @xmath193 $ ] .    with the variables for the general case defined ,",
    "inequality constraints are added to the formulation in a similar way as those derived for the one - on - one case .",
    "for example , the constraints identifying @xmath184 = 1 $ ] with @xmath182,q_j[k])\\in\\mathcal{g}$ ] are @xmath194 - \\gamma_j[k ] \\geq 0\\;\\;\\;\\ ;      \\forall m \\in \\ { 1,\\ldots , m_{dz } \\}\\nonumber\\\\      & & \\sum_{l=1}^{m_{dz}}(1-g_{lj}[k ] )        + \\gamma_j[k ] \\geq 1,\\nonumber\\end{aligned}\\ ] ] for all @xmath195 and for all @xmath196 .    and finally , the objective function is given by @xmath197     + \\epsilon \\sum_{i=1}^{n_d } \\sum_{k = 0}^{n_u-1 }     \\left ( |u_{xi}[k]| + |u_{yi}[k]| \\right).\\end{aligned}\\ ] ]",
    "results for example instances of defensive drill 1 are shown in figure  [ 1d3a ] .     and @xmath198 .",
    "for figures  ( c ) and ( d ) , @xmath199 and @xmath200 . in figures",
    "( a ) and ( c ) , the defenders deny all attackers from the defense zone . in figures  ( b ) and ( d ) , an attacker enters the defense zone . , width=336 ]    results for defensive drill 2 are shown in figure  [ dd2_1d2a_1 ] .",
    "[ sec : dd2general ]",
    "in this section , we explore the average case complexity of defensive drill 1 by solving randomly generated instances .",
    "each instance is generated by randomly picking parameters from a uniform distribution over the intervals defined below .",
    "each milp is solved using ampl  @xcite and cplex  @xcite on a pc with intel piii 550mhz processor , 1024 kb cache , 3.8 gb ram , and red hat linux .",
    "for all instances solved , processor speed was the limiting factor , not memory .    to generate the initial condition @xmath201 and the constant velocity vector @xmath113 for each attacker we pick @xmath202 , @xmath203 , and @xmath204 randomly from a uniform distribution over the intervals @xmath205 $ ] , @xmath206 , and @xmath207 $ ] , respectively .",
    "the parameters are then given by @xmath208    to generate the initial condition @xmath209 for each defender , we pick @xmath210 , @xmath211 , @xmath212 , and @xmath213 randomly from a uniform distribution over the intervals @xmath214 $ ] , @xmath206 , @xmath215 $ ] , and @xmath206 , respectively .",
    "the defender s initial condition is then given by @xmath216    we take the playing field to be circular with radius @xmath217 , and we set the radius of the defense zone to be @xmath218 .",
    "the intervals used to generate the instances are @xmath219 $ ] , @xmath220 $ ] , and @xmath221 $ ] .",
    "we take the attacker velocity to be @xmath222 .    in figure",
    "[ acomplexity ] , we plot the fraction of instances solved versus computation time for the case where the cost function includes the number of attackers that enter the defense zone plus a penalty on the control effort . this cost function is given by equation  ( [ eqn : objective ] ) with @xmath223 . in figure",
    "[ acomplexity2 ] , we plot the fraction of instances solved versus computation time for the case where the cost function includes only the number of attackers that enter the defense zone . this cost function is given by equation  ( [ eqn : objective ] ) with @xmath224 .",
    "as these figures show , the case where the cost function only includes the number of attackers that enter the defense zone is less computationally intensive than the case where the cost function also includes a penalty on the control effort .",
    "for example , for the case where @xmath225 , @xmath226 , and @xmath227 , 50% of the problems are solved in 3.5 seconds . however , for the case where @xmath228 , @xmath226 , and @xmath227 , 50% of the problems are solved in 78 seconds .",
    "when @xmath225 in the cost function , the solver stops once a set of trajectories for the defenders is found that results in the minimum number of attackers entering the defense zone .",
    "this trajectory is often not the most efficient trajectory with respect to the control effort of the defenders . for the case",
    "where @xmath223 , once a set of defender trajectories is found that results in the minimum number of attackers entering the defense zone the solver continues to search .",
    "the solver searches until it finds a set of defender trajectories that not only results in the minimum number of attackers entering the defense zone but also uses the defender control effort in the most efficient way .    in figure",
    "[ expgrowth ] , we plot the computation time necessary to solve 50% of the randomly generated instances versus the size of the attacker set . for all instances considered ,",
    "the defender set is of constant size ( @xmath229 ) .",
    "we plot the data for both cost functions considered above ( @xmath225 and @xmath223 ) .",
    "this figure shows that the computation time grows exponentially with the number of vehicles in the attacker set .    ) with @xmath230 ) .",
    "we consider instances with defender set of size three ( @xmath229 ) and attacker sets of size @xmath231 . to generate each curve , 200 random instances were solved .",
    "the parameters are @xmath166 , @xmath232 , @xmath233 , @xmath234 , and @xmath235 . , width=307 ]    ) with @xmath236 ) .",
    "we consider instances with defender set of size three ( @xmath229 ) and attacker sets of size @xmath237 . to generate each curve",
    ", 200 random instances were solved .",
    "the parameters are @xmath166 , @xmath232 , @xmath233 , @xmath234 , and @xmath235.,width=307 ]    ) .",
    "each square denotes a data point for the case where the cost function is the number of attackers that enter the defense zone plus a penalty on each defender s control effort ( @xmath223 case ) .",
    "each asterisk denotes a data point for the case where the cost function is the number of attackers that enter the defense zone ( @xmath225 case ) .",
    "the solid lines denote fitted exponential functions to these data .",
    ", width=307 ]",
    "in this paper , we showed how to use milps to model and generate strategies for multi - vehicle control problems .",
    "the milp formulation is very expressive and allows all aspects of the problem to be taken into account .",
    "this includes the dynamic equations governing the vehicles , the dynamic equations governing the environment , the state machine governing adversary intelligence , logical constraints , and inequality constraints .",
    "the solution to the resulting milp is the optimal team strategy for the problem .",
    "as shown by our average case complexity study , the milp method becomes computational burdensome for large problems and thus , for these cases , is not suitable for real - time applications .",
    "there are several steps that can be taken to make the milp approach applicable for real - time multi - vehicle control applications .",
    "one approach is to solve the milps faster .",
    "this can be done by using a more powerful computer or by distributing the computation over a set of processors . for the multi - vehicle control problems",
    ", it may be advantageous to distribute the computation over the set of vehicles .",
    "distributed methods for solving milps have been considered in  @xcite .",
    "another approach is to move all , or some components of , the computational burden offline .",
    "this can be done by formulating the problem as a multi - parametric milp .",
    "a multi - parametric milp is a milp formulated using a set of parameters each allowed to take on values over an interval .",
    "this problem is much more computationally intensive than the milp problems considered in this paper .",
    "however , because the computation is performed offline , this is not an issue unless the computation takes an unreasonable amount of time . with the solution to the multi - parametric milp",
    ", a table can be formed and used to look up optimal team strategies for the multi - vehicle system in real time .",
    "multi - parametric milp control problems can be solved using the multi - parametric toolbox  @xcite .",
    "finally , we discuss efficient milp formulations as a way of decreasing computational requirements . the computational effort required to solve a milp depends most on the number of binary variables used in its milp problem formulation .",
    "thus , reducing the number of binary variables is advantageous . in this paper ,",
    "our motivating problem required three different time discretizations .",
    "the discretizations included one for the control input to the vehicles , one for obstacle avoidance , and one for attacker intercept . with each discretization step , a set of binary variables",
    "must be added to the milp formulation . in most of the instances solved in this paper , we discretized time uniformly .",
    "however , we posed the milp in a general way such that nonuniform time discretizations could be used .",
    "this allows for intelligent time distribution selection , which can significantly reduce the required computational effort to solve a problem . in  @xcite",
    ", we developed several iterative milp techniques for intelligent discretization step selection .",
    "[ [ logicconvert ] ]    in this appendix , we illustrate how to convert a logic expression into an equivalent set of inequalities using the procedure from  @xcite . first the logic expression is converted into a conjunction of disjunctions , called conjunctive normal form ( cnf ) , by applying tautologies .",
    "for example , let the variables @xmath238 be binary variables .",
    "the expression @xmath239 is in cnf .",
    "once we have converted the logic expression into cnf we can easily write each disjunction as an inequality constraint that must be satisfied in order for the disjunction to be true .",
    "for example , the second disjunction of equation  ( [ lc1 ] ) , @xmath240 or @xmath241 , is true if and only if @xmath242 .",
    "therefore , equation  [ lc1 ] is true if and only if the following inequalities hold @xmath243      first consider the ( @xmath244 ) direction of equation  ( [ gamma2 ] ) . replacing implication with disjunction we have @xmath245 = 1 ) \\mbox { or } \\nonumber\\\\     & & ( g_m[k_a ] = 1\\;\\;\\;\\ ;    \\forall m \\in \\{1,\\ldots , m_{dz } \\})\\end{aligned}\\ ] ] and distributing the or we have @xmath246 = 0 \\mbox { or } g_m[k_a ] = 1     \\right)\\;\\;\\;\\ ;    \\forall m \\in \\ { 1,\\ldots , m_{dz}\\}\\end{aligned}\\ ] ] which is equivalent to @xmath247 = 0 \\mbox { or } g_1[k_a ] = 1 \\right)\\nonumber\\\\    & & \\mbox{and } \\left ( \\gamma[k_a ] = 0       \\mbox { or } g_2[k_a ] = 1 \\right)\\nonumber\\\\    & & \\vdots\\nonumber\\\\    & & \\mbox{and } \\left ( \\gamma[k_a ] = 0 \\mbox { or } g_{m_{dz}}[k_a ] = 1      \\right).\\end{aligned}\\ ] ] this expression is in cnf , therefore it is equivalent to the following set of inequality constraints @xmath248 ) + g_m[k_a ]   \\geq 1\\;\\;\\;\\ ;       \\forall m \\in \\ { 1,\\ldots , m_{dz } \\}.",
    "\\end{aligned}\\ ] ] now consider the ( @xmath249 ) direction of equation  ( [ gamma2 ] )",
    ". replacing implication with disjunction @xmath245 = 1 ) \\mbox { or } \\nonumber\\\\     & & \\neg ( g_m[k_a ] = 1\\;\\;\\;\\;\\forall m \\in \\{1,\\ldots , m_{dz } \\})\\end{aligned}\\ ] ] and distributing the negation we have @xmath250 = 1 \\right )     \\mbox { or }     \\left (     \\exists m \\mbox { such that }    g_m[k_a ] = 0     \\right).\\end{aligned}\\ ] ] which is equivalent to @xmath247 = 1 \\right)\\nonumber\\\\    & & \\mbox{or } \\left ( g_1[k_a ] = 0 \\right)\\nonumber\\\\    & & \\mbox{or } \\left ( g_2[k_a ] = 0 \\right)\\nonumber\\\\    & & \\vdots\\nonumber\\\\    & & \\mbox{or } \\left ( g_{m_{dz}}[k_a ] = 0 \\right).\\end{aligned}\\ ] ] this expression , which is a disjunction , is in cnf and therefore is equivalent to the following inequality @xmath251 ) + \\gamma[k_a ] \\geq 1.\\end{aligned}\\ ] ]      first consider the @xmath252 direction of equation  ( [ asgovlogic ] ) . replacing implication with the equivalent disjunction we have @xmath253 = 0 ) \\mbox { or } \\nonumber\\\\    & & \\left ( a[k_a]=1 \\mbox { and } \\gamma[k_a]=0 \\mbox { and }     \\delta[k_a]=0     \\right ) \\end{aligned}\\ ] ] and distributing or over and we have @xmath254 = 0 \\mbox { or }   \\delta[k_a]=0 \\right)\\nonumber\\\\    & & \\mbox{and } \\left ( a[k_a+1 ] = 0 \\mbox { or }   a[k_a]=1 \\right)%    \\nonumber\\\\    & & \\mbox{and } \\left ( a[k_a+1 ] = 0 \\mbox { or }   \\gamma[k_a]=0 \\right).\\end{aligned}\\ ] ] now that the expression is in cnf we can easily write it as a set of inequality constraints .",
    "@xmath255 ) + \\left ( 1-\\delta[k_a ] \\right ) \\geq 1\\nonumber\\\\    & & \\left ( 1-a[k_a+1 ) \\right ) + a[k_a ] \\geq 1\\nonumber\\\\    & & \\left ( 1-a[k_a+1 ) \\right ) + \\left ( 1-\\gamma[k_a ]",
    "\\right ) \\geq 1 .",
    "\\label{asineq1}\\end{aligned}\\ ] ] now consider the other direction @xmath256 of equation  ( [ asgovlogic ] ) .",
    "replacing the implication with disjunction we have @xmath257 = 1 ) \\mbox { or } \\nonumber\\\\     & & \\neg \\left ( \\delta[k_a ] = 0 \\mbox { and } a[k_a ] = 1 \\mbox { and }     \\gamma[k_a ] = 0 \\right ) \\end{aligned}\\ ] ] and distributing the negation we have @xmath258 = 1 \\mbox { or } a[k_a ] = 0 \\mbox { or } \\gamma[k_a ] = 1     \\mbox { or } a[k_a+1 ] = 1\\end{aligned}\\ ] ] this disjunction is equivalent to the flowing inequality @xmath258 + ( 1-a[k_a ] ) + \\gamma[k_a ] + a[k_a+1 ] \\geq 1 .",
    "\\label{asineq2}\\end{aligned}\\ ] ] in summary , we have taken the governing equations for the attacker s binary state  ( [ asgov2 ] ) and derived an equivalent set of inequalities :  ( [ asineq1 ] ) and  ( [ asineq2 ] ) which can be simplified to the inequalities given by equation  ( [ attdyn3 ] ) .",
    "we thank j.  ousingsawat for helpful comments and encouragement .",
    "1 r. c. arkin and g. a. bekey , eds .",
    ", `` special issue on robot colonies , '' _ autonomous robots _ , vol .",
    "4(1 ) , 1997 .",
    "r. w. beard , t. w. mclain , m. a. goodrich , and e.p .",
    "anderson , `` coordinated target assignment and intercept for unmanned air vehicles , '' _ ieee trans .",
    "991922 , dec . 2002 .",
    "r. w. beard and v. stepanyan , `` information consensus in distributed multiple vehicle coordinated control , '' _ proc .",
    "ieee conf .",
    "decision and control _ , maui , hawaii , dec .",
    "2003 , pp . 20292034 .",
    "r. w. beard and t.  w.  mclain , `` multiple uav cooperative search under collision avoidance and limited range communication constraints , '' _ proc .",
    "ieee conf .",
    "decision and control _ , maui , hawaii , dec .",
    "2003 , pp . 2530 .",
    "t. balch and l. e. parker , eds .",
    ", `` special issue on heterogeneous multirobot systems , '' _ autonomous robots _ , vol .",
    "8(3 ) , 2000 . j. s. bellingham , m. tillerson , m. alighanbari , and j. p. how , `` cooperative path planning for multiple uavs in dynamic and uncertain environments , '' _ proc .",
    "ieee conf .",
    "decision and control _ , las vegas , nevada , dec .",
    "2002 , pp . 28162822 .",
    "a. bemporad and m. morari , `` control of systems integrating logic , dynamics , and constraints , '' _ automatica _ , vol .",
    "407428 , mar .",
    "d. bertsimas and j. n. tsitsiklis , _ introduction to linear optimization _ , athena scientific , belmont , massachusetts , 1997 .",
    "s.  h.  breheny , r.  dandrea , and j.  c.  miller , `` using airborne vehicle - based antenna arrays to improve communications with uav clusters , '' _ proceedings .",
    "42nd ieee conference on decision and control _ , dec .",
    "2003 , pp .",
    "m.  campbell , r.  dandrea , d.  schneider , a.  chaudhry , s.  waydo , j.  sullivan , j.  veverka , and a.  klochko , `` roboflag games using systems based , hierarchical control , '' _ proceedings of the american control conference _ , june 46 , 2003 , pp .",
    "c. g. cassandras and w. li , `` a receding horizon approach for solving some cooperative control problems , '' _ proc .",
    "ieee conf .",
    "decision and control _ , las vegas , neveda , dec .",
    "2002 , pp . 37603765 .",
    "r.  dandrea and r.  m.  murray , `` the roboflag competition , '' _ proceedings of the american control conference _ ,",
    "june 46 , 2003 , pp .",
    "r.  dandrea and m.  babish , `` the roboflag testbed , '' _ proceedings of the american control conference _ ,",
    "june 46 , 2003 , pp .",
    "r.   dandrea , t.  kalmr - nagy , p.  ganguly , and m.  babish , `` the cornell robocup team , '' in g. kraetzschmar , p. stone , t. balch eds .",
    ", _ robot soccer worldcup iv , lecture notes in artificial intelligence _ , springer , 2001 . m.  g.  earl and r.  dandrea , `` a study in cooperative control : the roboflag drill , '' _ proceedings of the american control conference _ , anchorage , alaska may 810 , 2002 , pp .  18111812",
    ". m. g. earl and r. dandrea , `` modeling and control of a multi - agent system using mixed integer linear programming , '' _ proc .",
    "ieee conf .",
    "decision and control _ , las vegas , neveda , dec .",
    "2002 , pp .",
    "107111 . m.  g.  earl and r.  dandrea , `` iterative milp methods for vehicle control problems , '' _ proc .",
    "ieee conf .",
    "decision and control _ , atlantis , paradise island , bahamas , dec",
    "all files for generating the plots found in this paper are available online at ` http://control.mae.cornell.edu/earl/milp1 ` r.  fourer , d.  m.  gay , b.  w.  kernighan , `` ampl  a modeling language for mathematical programming , '' danvers , mass . ,",
    "boyd & fraser , 1993 .",
    "m. r. garey and d. s. johnson .",
    "_ computers and intractability : a guide to the theory of np - completeness_. w. h. freeman and company , 1979 .",
    "y. ho and k. chu , `` team decision theory and information structures in optimal control problems ",
    "part 1 , '' _ ieee trans .",
    "automatic control _",
    "ac-17 , pp . 1522 , 1972 .",
    "_ ilog ampl cplex system version 7.0 user s guide _ , 2000 , ` http://www.ilog.com/products/cplex/ ` .",
    "m. kvasnica , p. grieder , m. baotic , and m. morari , `` multi parametric toolbox ( mpt ) , '' _ hybrid systems : computation and control , lecture notes in computer science _ ,",
    "volume 2993 , springer verlag , pennsylvania , philadelphia , usa , march 2003 , pp .",
    "448462 , ` http://control.ee.ethz.ch/\\simmpt ` .",
    "m.  di marco , a.  garulli , a.  giannitrapani , a.  vicino a , `` simultaneous localization and map building for a team of cooperating robots : a set membership approach , '' _ ieee transactions on robotics and automation _ , vol .  19 ( 2 ) , pp",
    ".  238249 , apr .",
    "j. marschak and r. radner , _ econonomic theory of teams_. yale university press , 1972 .",
    "d.  q.  mayne , j.  b.  rawlings , c.  v.  rao , and p.  o.  m.  scokaert , `` constrained model predictive control : stability and optimality , '' _ automatica _ , vol .",
    "36 , pp .",
    "789814 , 2000 . t. w. mclain , p. r. chandler , s. rasmussen , and m. pachter , `` cooperative control of uav rendezvous , '' _ proc .",
    "american control conference _",
    ", arlington , va , june 2001 , pp . 23092314 .",
    "r. murphey and p. m. pardalos , eds . , _ cooperative control and optimization _",
    ", boston : kluwer academic , 2002 . t. kalmr - nagy , r. dandrea , and p. ganguly .",
    "`` near - optimal dynamic trajectory generation and control of an omnidirectional vehicle , '' _ robotics and autonomous systems _",
    "46 , pp . 4764 , 2004 .",
    "j.  ousingsawat and m.  e.  campbell , `` establishing optimal trajectories for multi - vehicle reconnaissance , '' _ aiaa guidance , navigation and control conference _ , 2004 .",
    "t. l. ralphs , `` parallel branch and cut for capacitated vehicle routing , '' _ parallel computing _",
    "29(5 ) , pp .  607629 , may 2003 .",
    "a. richards , j. bellingham , m. tillerson , and j. how , `` co - ordination and control of multiple uavs , '' _ aiaa conf . guidance navigation and control _ , august 2002 .",
    "a. richards and j. p. how , `` aircraft trajectory planning with collision avoidance using mixed integer linear programming , '' in _ proc .",
    "american control conf .",
    "a.  richards , t.  schouwenaars , j.   p.  how and e.  feron , `` spacecraft trajectory planning with avoidance constraints using mixed - integer linear programming , '' _ journal of guidance , control , and dynamics _ , vol .",
    "755764 , july  august 2002 .",
    "p. stone and m. veloso , `` multiagent systems : a survey from a machine learning perspective , '' _ autonomous robots _ , vol .",
    "345383 , 2000 .",
    "_ layered learning in multiagent systems : a winning approach to robotic soccer_. mit press , 2000 .",
    "p. stone , m. asada , t. balch , r. dandrea , m. fujita , b. hengst , g. kraetzschmar , p. lima , n. lau , h. lund , d .",
    "polani , p .",
    "scerri , s. tadokoro , t .",
    "weigel , and g. wyeth , `` robocup-2000 : the fourth robotic soccer world championships , '' _ ai magazine _ , vol .",
    "22(1 ) , pp .  1138 , spring 2001",
    ". t.  g.  sugar and v.  kumar , `` control of cooperating mobile manipulators , '' _ ieee transactions on robotics and automation _",
    ", vol .  18 ( 1 ) , pp .  94103 ,",
    "f. d. torrisi , a. bemporad , and d. mignone .",
    "hysdel  a language for describing hybrid systems .",
    "technical report aut00 - 03 , eth zurich , 2000 . ` http://control.ethz.ch/\\simhybrid/hysdel ` m. l. tyler and m. morari , `` propositional logic in control and monitoring problems , '' _ automatica _ , vol .",
    "565 - 582 , 1999 .",
    "h. p. williams , _ model building in mathematical programming _ , john wiley and sons , third edition , 1993 ."
  ],
  "abstract_text": [
    "<S> we present methods to synthesize cooperative strategies for multi - vehicle control problems using mixed integer linear programming . </S>",
    "<S> complex multi - vehicle control problems are expressed as mixed logical dynamical systems . </S>",
    "<S> optimal strategies for these systems are then solved for using mixed integer linear programming . </S>",
    "<S> we motivate the methods on problems derived from an adversarial game between two teams of robots called roboflag . </S>",
    "<S> we assume the strategy for one team is fixed and governed by state machines . </S>",
    "<S> the strategy for the other team is generated using our methods . finally , we perform an average case computational complexity study on our approach .    </S>",
    "<S> cooperative robotics , multi - vehicle systems , mixed integer linear programming , robot motion planning , path and trajectory planning , hybrid systems , mathematical optimization . </S>"
  ]
}