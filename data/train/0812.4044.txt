{
  "article_text": [
    "this paper is about learning to make decisions in partial feedback settings where the payoff of only one choice is observed rather than all choices . as an example , consider an internet site recommending ads or other content based on such observable quantities as user history and search engine queries , which are unique or nearly unique for every decision . after the ad is displayed , a user either clicks on it or not .",
    "this type of feedback differs critically from the standard supervised learning setting since we do nt observe whether or not the user would have clicked had a different ad beed displayed instead .    in an online version of the problem , a policy chooses which ads to display and uses the observed feedback to improve its future ad choices .",
    "a good solution to this problem must explore different choices and properly exploit the feedback .",
    "the problem faced by an internet site , however , is more complex .",
    "they have observed many interactions historically , and would like to exploit them in forming an initial policy , which may then be improved by further online exploration . since",
    "exploration decisions have already been made , online solutions are not applicable . to properly use the data ,",
    "we need _ non - interactive _",
    "methods for learning with partial feedback .",
    "this paper is about constructing a family of algorithms for non - interactive learning in such partial feedback settings .",
    "since any non - interactive solution can be composed with an exploration policy to form an algorithm for the online learning setting , the algorithm proposed here can also be used online .",
    "indeed , some of our experiments are done in an online setting .",
    "here is a formal description of non - interactive data generation :    1 .",
    "some unknown distribution @xmath4 generates a feature vector @xmath5 and a vector @xmath6 , where @xmath7 $ ] is the reward of the @xmath8-th action , @xmath9 .",
    "only @xmath5 is revealed to the learner .",
    "2 .   an existing policy chooses an action @xmath10 .",
    "the reward @xmath11 is revealed .",
    "the goal is to learn a policy @xmath12 for choosing action @xmath13 given @xmath5 , with the goal of maximizing the expected reward with respect to @xmath4 , given by @xmath14.\\ ] ] we call this a _ partial label problem _ ( defined by ) @xmath4 .      probably the simplest approach is to regress on the reward @xmath11 given @xmath5 and @xmath13 , and then choose according to the largest predicted reward given a new @xmath5 .",
    "this approach reduces the partial label problem to a standard regression problem .    a key technique for analyzing such a reduction is _",
    "regret analysis _ , which bounds the `` regret '' of the resulting policy in terms of the regressor s `` regret '' on the problem of predicting @xmath11 given @xmath5 and @xmath13 .",
    "here _ regret _ is the difference between the largest reward that can be achieved on the problem and the reward achieved by the predictor ; or  defined in terms of losses  the difference between the incurred loss and the smallest achievable loss .",
    "one analyzes excess loss ( i.e. , regret ) instead of absolute loss so that the bounds apply to inherently noisy problems .",
    "it turns out that the simple approach above has regret that scales with the square root of the regressor s regret ( see section  [ sec : simple ] for a proof ) . recalling that the latter is upper bounded by 1 ,",
    "this is undesirable .",
    "another natural approach is to use the technique in  @xcite . given a distribution @xmath15 over the actions given @xmath5 , the idea is to transform each partial label example @xmath16 into an importance weighted multiclass example @xmath17 , where @xmath18 is the cost of not predicting label @xmath13 on input @xmath5 .",
    "these examples are then fed into any importance weighted multiclass classification algorithm , with the output classifier used to make future predictions .",
    "section  [ sec : simple ] shows that when @xmath15 is uniform , the resulting regret on the original partial label problem is bounded by @xmath2 times the importance weighted multiclass regret , where @xmath2 is the number of choices .",
    "the importance weighted multiclass classification problem can , in turn , be reduced to binary classification , but all known conversions yield worse bounds than the approach presented in this paper .",
    "we propose the @xmath0 algorithm for reducing the partial label problem to binary classification , allowing one to reuse any existing , fully supervised binary classification algorithm for the partial label problem .",
    "the @xmath0 uses the following trick , which is easiest to understand in the case of @xmath19 choices ( covered in section  [ s : two ] ) . when the observed reward @xmath11 of choice @xmath13 is low , we essentially pretend that the other choice @xmath20 was chosen and a different reward @xmath21 was observed . precisely how this is done and why , is driven by the regret analysis .",
    "this basic trick is composable in a binary tree structure for @xmath22 , as described in section  [ sec : offset - tree ] .",
    "the @xmath0 achieves computational efficiency in two ways : first , it improves the dependence on @xmath2 from @xmath23 to @xmath3 .",
    "it is also an oracle algorithm , which implies that it can use the implicit optimization in existing learning algorithms rather than a brute - force enumeration over policies , as in the exp4 algorithm  @xcite .",
    "we prove that the @xmath0 policy regret is bounded by @xmath24 times the regret of the binary classifier in solving the induced binary problems .",
    "section  [ sec : lower - bound ] shows that no reduction can provide a better guarantee , giving the first nontrivial lower bound for learning reductions .",
    "since the bound is tight and has a dependence on @xmath2 , it shows that the partial label problem is inherently different from standard fully supervised learning problems like @xmath2-class classification .",
    "section  [ sec : simple ] analyzes several alternative approaches .",
    "an empirical comparison of these approaches is given in section  [ sec : experimental ] .",
    "the problem considered here is a non - interactive version of the contextual bandit problem ( see @xcite for background on the bandit problem ) .",
    "the interactive version has been analyzed under various additional assumptions  @xcite , including payoffs as a linear function of the side information  @xcite .",
    "the exp4 algorithm  @xcite has a nice assumption - free analysis .",
    "however , it is intractable when the number of policies we want to compete with is large .",
    "it also relies on careful control of the action choosing distribution , and thus can not be applied to historical data , i.e. , non - interactively .",
    "sample complexity results for policy evaluation in reinforcement learning  @xcite and contextual bandits  @xcite show that empirical risk minimization type algorithms can find a good policy in a non - interactive setting .",
    "the results here are mostly orthogonal to these results , although we do show in section  [ sec : sc ] that a constant factor improvement in sample complexity is possible using the offset trick",
    ".    the banditron algorithm  @xcite deals with a similar setting but does not address several concerns that the @xmath0 addresses : ( 1 ) the banditron requires an interactive setting ; ( 2 ) it deals with a specialization of our setting where the reward for one choice is @xmath25 , and @xmath26 for all other choices ; ( 3 ) its analysis is further specialized to the case where linear separators with a small hinge loss exist ; ( 4 ) it requires exponentially in @xmath2 more computation ; ( 5 ) the banditron is not an oracle algorithm , so it is unclear , for example , how to compose it with a decision tree bias .",
    "transformations from partial label problems to fully supervised problems can be thought of as learning methods for dealing with sample selection bias  @xcite , which is heavily studied in economics and statistics .",
    "this section reviews several basic learning problems and the @xmath27 method  @xcite used in the construction .",
    "a _ @xmath2-class classification _ problem is defined by a distribution @xmath28 over @xmath29 , where @xmath30 is an arbitrary feature space and @xmath31 is a label space with @xmath32 .",
    "the goal is to learn a classifier @xmath33 minimizing the _ error rate _ on @xmath28 , @xmath34 = { \\mathbf{e}}_{(x , y)\\sim q}[\\,{\\mathbf{1}}({c(x)\\neq y})],\\ ] ] given training examples of the form @xmath35 . here",
    "@xmath36 is the indicator function which evaluates to 1 when its argument is true , and to 0 otherwise .",
    "importance weighted classification is a generalization where some errors are more costly than others .",
    "formally , an _ importance weighted classification _",
    "problem is defined by a distribution @xmath37 over @xmath38 . given training examples of the form @xmath39 , where @xmath40 is the cost associated with mislabeling @xmath5 , the goal is to learn a classifier @xmath33 minimizing the _ importance weighted loss _ on @xmath37 , @xmath41 $ ] .",
    "a folk theorem  @xcite says that for any importance weighted distribution @xmath37 , there exists a constant @xmath42 $ ] such that for any classifier @xmath43 , @xmath44 = \\frac{1}{\\overline{w } } { \\mathbf{e}}_{(x , y , w)\\sim p}[w \\cdot { \\mathbf{1}}(c(x)\\neq y)],\\ ] ] where @xmath28 is the distribution over @xmath29 defined by @xmath45 marginalized over @xmath40 .",
    "in other words , choosing @xmath46 to minimize the error rate under @xmath28 is equivalent to choosing @xmath46 to minimize the importance weighted loss under @xmath37 .",
    "the @xmath27 method  @xcite can be used to resample the training set drawn from @xmath37 using rejection sampling on the importance weights ( an example with weight @xmath40 is accepted with probability proportional to @xmath40 ) , so that the resampled set is effectively drawn from @xmath28 .",
    "then , any binary classification algorithm can be run on the resampled set to optimize the importance weighted loss on @xmath37 .",
    "@xmath27 runs a base classification algorithm on multiple draws of the resampled set , and averages over the learned classifiers when making importance weighted predictions ( see @xcite for details ) . to simplify the analysis",
    ", we do not actually have to consider separate classifiers .",
    "we can simply augment the feature space with the index of the resampled set and then learn a single classifier on the union of all resampled data .",
    "the implication of this observation is that we can view @xmath27 as a machine that maps importance weighted examples to unweighted examples .",
    "we use this method in algorithms  [ alg : binary_train ] and [ alg : filter_bandit ] below .",
    "this section deals with the special case of @xmath19 actions .",
    "we state the algorithm , prove the regret bound ( which is later used for the general @xmath2 case ) , and state a sample complexity bound . for simplicity",
    ", we let the two action choices in this section be @xmath25 and @xmath47 .",
    "the @xmath48 algorithm is a reduction from the 2-class partial label problem to binary classification .",
    "the reduction operates per example , implying that it can be used either online or offline .",
    "we state it here for the offline case .",
    "the algorithm reduces the original problem to binary importance weighted classification , which is then reduced to binary classification using the @xmath27 method described above .",
    "a base binary classification algorithm @xmath49 is used as a subroutine .",
    "the key trick appears inside the loop in algorithm  [ alg : binary_train ] , where importance weighted binary examples are formed .",
    "the offset of @xmath50 changes the range of importances , effectively reducing the variance of the induced problem .",
    "this trick is driven by the regret analysis in section  [ binary - regret - theorem ] .",
    "set @xmath51 @xmath52 .",
    "this section proves a regret transform theorem for the @xmath48 reduction .",
    "informally , _ regret _",
    "measures how well a predictor performs compared to the best possible predictor on the same problem .",
    "regret transform _ shows how the regret of a base classifier on the induced ( binary classification ) problem controls the regret of the resulting policy on the original ( partial label ) problem .",
    "thus a regret transform bounds only excess loss due to suboptimal prediction .",
    "@xmath48 transforms partial label examples into binary examples .",
    "this process implicitly transforms the distribution @xmath4 defining the partial label problem into a distribution @xmath53 over binary examples , via a distribution over importance weighted binary examples .",
    "note that even though the latter distribution depends on both @xmath4 and the action - choosing distribution @xmath54 , the induced binary distribution @xmath53 depends only on @xmath4 .",
    "indeed , the probability of label 1 given @xmath5 and @xmath55 , according to @xmath53 , is @xmath56 \\\\ & = { \\mathbf{1}}(r_1>\\frac{1}{2})\\left|r_1-\\frac{1}{2}\\right| +   { \\mathbf{1}}(r_{-1}<\\frac{1}{2})\\left|r_{-1}-\\frac{1}{2}\\right|,\\end{aligned}\\ ] ] independent of @xmath54 .",
    "the _ binary regret _ of a classifier @xmath57 on @xmath53 is given by @xmath58 where the min is over all classifiers @xmath59 .",
    "the _ importance weighted regret _ is definited similarly with respect to the importance weighted loss . for the @xmath19 partial label case ,",
    "the policy that a classifier @xmath46 induces is simply the classifier .",
    "the regret of policy @xmath46 is defined as @xmath60 where @xmath61,\\ ] ] is the value of the policy .    the theorem below states that the policy regret is bounded by the binary regret .",
    "we find it surprising because strictly less information is available than in binary classification .",
    "note that the lower bound in section  [ sec : lower - bound ] implies that no reduction can do better .",
    "redoing the proof with the offset set to @xmath26 rather than @xmath50 also reveals that @xmath62 bounds the policy regret , implying that the offset trick gives a factor of 2 improvement in the bound .    finally , note that the theorem is quantified over all classifiers , which includes the classifier returned by @xmath49 in the last line of the algorithm .    _",
    "( @xmath48 regret)[ttwo ] _ for all @xmath63-class partial label problems @xmath4 and all binary classifiers @xmath46 , @xmath64 furthermore , there exists @xmath4 such that for all values @xmath65 $ ] there exists @xmath46 such that @xmath66 ( i.e. the bound is tight ) .",
    "we first bound the partial label regret of @xmath46 in terms of importance weighted regret , and then apply known results to relate the importance weighted regret to binary regret .",
    "conditioned on a particular value of @xmath5 , we either make a mistake or we do not . if no mistake is made , then the regrets of both sides are @xmath26 , and the claim holds trivially .",
    "assume that a mistake is made .",
    "without loss of generality , @xmath67 and label @xmath47 is chosen .",
    "the expected importance weight of label @xmath47 is given by @xmath68\\\\ & = { \\mathbf{e}}_{\\vec{r } \\sim d|x } \\left [ \\left(\\frac{1}{2 } - r_1\\right)_{+}+ \\left(r_{-1 } - \\frac{1}{2}\\right)_{+}\\right ] \\end{aligned}\\ ] ] where we use the operator @xmath69 .",
    "the difference in expected importance weights between label @xmath25 and label @xmath47 is @xmath70 \\\\ &   -{\\mathbf{e}}_{\\vec{r}\\sim d|x } \\left [ \\left(\\frac{1}{2 } - r_1\\right)_{+}+ \\left(r_{-1 } - \\frac{1}{2}\\right)_{+}\\right ] \\\\ & =   { \\mathbf{e}}_{\\vec{r}\\sim d|x } \\left [ \\left(\\frac{1}{2 } - r_{-1}\\right)+ \\left(r_1 - \\frac{1}{2}\\right)\\right ] \\\\ & =   { \\mathbf{e}}_{\\vec{r}\\sim d|x } [ r_1 - r_{-1 } ] = { \\operatorname{reg}}_{\\eta } ( c , d|x).\\end{aligned}\\ ] ] this shows that the importance weighted regret of the binary classifier is the policy regret .",
    "the folk theorem from section  [ basic ] ( see @xcite ) says that the importance weighted regret is bounded by the binary regret , times the expected importance .",
    "the latter is @xmath71 = { \\mathbf{e}}_{\\vec{r } \\sim d|x } \\left[\\ , |r_1 - 1/2| + |r_{-1 } - 1/2|\\ , \\right]\\leq 1,$ ] since both @xmath72 and @xmath73 are bounded by 1 .",
    "this proves the first part of the theorem .    for the second part ,",
    "notice that the proof of the first part can be made an equality by having a reward vector @xmath74 for each @xmath5 always , and letting the classifier predict label @xmath25 with probability @xmath75 over the draw of @xmath5 .",
    "in this section we deal with the case of large @xmath2 .",
    "the technique in the previous section can be applied repeatedly using a tree structure to give an algorithm for general @xmath2 .",
    "consider a maximally balanced binary tree on the set of @xmath2 choices , conditioned on a given observation @xmath5 .",
    "every internal node in the tree is associated with a classification problem of predicting which of its two inputs has the larger expected reward . at each node",
    ", the same offsetting technique is used as in the binary case described in section  [ s : two ] .    for an internal node @xmath76 ,",
    "let @xmath77 denote the set of leaves in the subtree @xmath78 rooted at @xmath76 .",
    "every input to a node is either a leaf or a winning choice from another internal node closer to the leaves .",
    "fix a binary tree @xmath79 over the choices @xmath80    the training algorithm , @xmath0 , is given in algorithm  [ alg : filter_bandit ] .",
    "the testing algorithm defining the predictor is given in algorithm  [ alg : filter_policy ] .",
    "* return * unique action @xmath13 for which every classifier @xmath81 from @xmath13 to root prefers @xmath13 .",
    "the theorem below gives an extension of theorem  [ ttwo ] for general @xmath2 .",
    "for the analysis , we use a simple trick which allows us to consider only a single induced binary problem , and thus a single binary classifier @xmath46 .",
    "the trick is to add the node index as an additional feature into each importance weighted binary example created algorithm  [ alg : filter_bandit ] , and then train based upon the union of all the training sets .    as in section",
    "[ s : two ] , the reduction transforms a partial label distribution @xmath4 into a distribution @xmath53 over binary examples . to draw from @xmath53 ,",
    "we draw @xmath82 from @xmath4 , an action @xmath13 from the action - choosing distribution @xmath54 , and apply algorithm  [ alg : filter_bandit ] to transform @xmath83 into a set of binary examples ( up to one for each level in the tree ) from which we draw uniformly at random . note that @xmath53 is independent of @xmath54 , as explained in the beginning of section  [ s : two ] .",
    "denote the policy induced by the offset - test algorithm using classifier @xmath46 by @xmath84 .",
    "for the following theorem , the definitions of regret are from section  [ s : two ] .    _",
    "( @xmath0 regret ) _ [ otr ] for all @xmath2-class partial label problems @xmath4 , for all binary classifiers @xmath46 , @xmath85 \\\\ & \\leq ( k-1){\\operatorname{reg}}_e(c , q_d),\\end{aligned}\\ ] ] where @xmath86 ranges over the @xmath1 internal nodes in @xmath79 , and @xmath13 and @xmath20 are its inputs determined by @xmath46 s predictions .",
    "section  [ sec : lower - bound ] shows that no reduction can give a better regret transform theorem . with a little bit of side information , however , we can do better : the offset minimizing the regret bound turns out to be the median value of the reward given @xmath5 .",
    "thus , it is generally best to pair choices which tend to have similar rewards .",
    "note that the algorithm need not know how well @xmath46 performs on @xmath53 .",
    "the proof below can be reworked with the offset set to @xmath26 , resulting in a regret bound which is a factor of @xmath63 worse .",
    "we fix @xmath5 , taking the expectation over the draw of @xmath5 at the end .",
    "the first step is to show that the partial label regret is bounded by the sum of the importance weighted regrets over the binary prediction problems in the tree .",
    "we then apply the costing analysis  @xcite to bound this sum in terms of the binary regret .",
    "the proof of the first step is by induction on the nodes in the tree .",
    "we want to show that the sum of the importance weighted regrets of the nodes in any subtree bounds the regret of the output choice for the subtree .",
    "the hypothesis trivially holds for one - node trees .",
    "consider a node @xmath87 making an importance weighted decision between choices @xmath13 and @xmath20 .",
    "the expected importance of choice @xmath13 is given by @xmath88 \\\\ & = { \\mathbf{e}}_{\\vec{r } \\sim d|x } [ ( r_a - 1/2)_+ + ( 1/2 - r_{a'})_+ ] .\\end{aligned}\\ ] ] it is important to note that , by construction , only two actions can generate examples for a given internal node . without loss of generality , assume that @xmath20 has the larger expected reward .",
    "the expected importance weighted binary regret @xmath89 of the classifier s decision is either @xmath26 if it predicts @xmath20 , or @xmath90",
    "\\\\   & -{\\mathbf{e}}_{\\vec{r}\\sim d|x } \\left [ \\left(r_{a } - 1/2\\right)_{+ } + \\left(1/2 - r_{a ' } \\right)_{+ } \\right ] \\\\",
    "= & { \\mathbf{e}}_{\\vec{r}\\sim d|x } [ 1/2 - r_{a } + r_{a ' } - 1/2 ]   = { \\mathbf{e}}_{\\vec{r}\\sim d|x } [ r_{a ' } - r_{a}]\\end{aligned}\\ ] ] if the classifier predicts @xmath13 .",
    "let @xmath78 be the subtree rooted at node @xmath76 , and let @xmath13 be the choice output by @xmath78 on @xmath5 . if the best choice in @xmath77 comes from the subtree @xmath91 producing @xmath13 , the policy regret of @xmath78 is given by @xmath92 - { \\mathbf{e}}_{\\vec{r}\\sim d|x } [ r_a ] \\\\ & = { \\operatorname{reg}}({l } )   \\leq \\sum_{u \\in l}{\\operatorname{wreg}}_u \\leq \\sum_{u\\in { t_v}}{\\operatorname{wreg}}_u.\\end{aligned}\\ ] ] if on the other hand the best choice comes from the other subtree @xmath93 , we have @xmath94 - { \\mathbf{e}}_{\\vec{r}\\sim d|x } [ r_a ] \\\\ & = { \\operatorname{reg}}({r } ) + { \\mathbf{e}}_{\\vec{r}\\sim d|x } [ r_{a ' } ] - { \\mathbf{e}}_{\\vec{r}\\sim d|x } [ r_a ] \\\\",
    "& \\leq \\sum_{u\\in r } { \\operatorname{wreg}}_{u } + { \\operatorname{wreg}}_v \\leq \\sum_{u\\in { t_v } } { \\operatorname{wreg}}_u,\\end{aligned}\\ ] ] proving the induction .",
    "the induction hypothesis applied to @xmath79 tells us that @xmath95 . according to the costing theorem discussed in section  [ basic ] ,",
    "the importance weighted regret is bounded by the unweighted regret on the resampled distribution , times the expected importance .",
    "the expected importance of deciding between actions @xmath13 and @xmath20 is @xmath96 \\leq 1\\end{aligned}\\ ] ] since all rewards are between 0 and 1 . noting that @xmath97 , we thus have @xmath98 completing the proof for any @xmath5 .",
    "taking the expectation over @xmath5 finishes the proof .",
    "the setting above is akin to boosting  @xcite : at each round @xmath99 , a booster creates an input distribution @xmath100 and calls an oracle learning algorithm to obtain a classifier with some error @xmath101 on @xmath100 .",
    "the distribution @xmath100 depends on the classifiers returned by the oracle in previous rounds .",
    "the accuracy of the final classifier is analyzed in terms of @xmath101 s .",
    "the binary problems induced at internal nodes of an offset tree depend , similarly , on the classifiers closer to the leaves .",
    "the performance of the resulting partial label policy is analyzed in terms of the oracle s performance on these problems .",
    "( notice that theorem  [ otr ] makes no assumptions on the error rates on the binary problems ; in particular , it does nt require them to be bounded away from @xmath50 . )    for the analysis , we use the simple trick from the beginning of this subsection to consider only a single binary classifier .",
    "the theorem is quantified over all classifiers , and thus it holds for the classifier returned by the algorithm . in practice , one can either call the oracle multiple times to learn a separate classifier for each node ( as we do in our experiments ) , or use iterative techniques for dealing with the fact that the classifiers are dependent on other classifiers closer to the leaves .",
    "this section shows that no method for reducing the partial label setting to binary classification can do better .",
    "first we formalize a learning reduction which relies upon a binary classification oracle .",
    "the lower bound we prove below holds for all such learning reductions .",
    "all learning reductions work on a per - example basis , and that is the representation we work with here .",
    "we are now ready to state the lower bound .    for all reductions @xmath102 ,",
    "there exists a partial label problem @xmath4 and an oracle @xmath103 such that @xmath104 where @xmath105 is the binary distribution induced by @xmath93 on @xmath4 , and @xmath106 is the policy resulting from @xmath107 using @xmath103 .",
    "the proof is by construction .",
    "we choose @xmath4 to be uniform over @xmath2 examples , with example @xmath8 having 1 in its @xmath8-th component of the reward vector , and zeros elsewhere .",
    "the corresponding feature vector consists of the binary representation of the index with reward 1 .",
    "let the action - choosing distribution be uniform .",
    "the reduction @xmath93 produces some simulatable sequence of advice calls when the observed reward is 0 .",
    "the oracle ignores all advice calls from @xmath93 and chooses to answer all queries with zero error rate according to this sequence .",
    "there are two cases : either @xmath93 observes @xmath26 reward ( with probability @xmath108 ) or it observes reward @xmath25 ( with probability @xmath109 ) . in the first case , the oracle has @xmath26 error rate ( and , hence @xmath26 regret ) . in the second case ,",
    "it has error rate ( and regret ) of at most @xmath25 .",
    "thus the expected error rate of the oracle on @xmath105 is at most @xmath109 .",
    "the inverse reduction @xmath107 has access to only the unlabeled example @xmath5 and the oracle @xmath103 .",
    "since the oracle s answers are independent of the draw from @xmath4 , the output action has reward @xmath26 with probability @xmath108 and reward @xmath25 with probability @xmath109 , implying a regret of @xmath108 with respect to the best policy . this is a factor of @xmath24 greater than the regret of the oracle , proving the lower bound .",
    "this section analyzes two simple approaches for reducing partial label problems to basic supervised learning problems .",
    "these approaches have been discussed previously , but the analysis is new .",
    "the most obvious approach is to regress on the value of a choice as in algorithm  [ alg : bandit_regression ] , and then use the argmax classifier as in algorithm  [ alg : max_policy ] .",
    "instead of learning a single regressor , we can learn a separate regressor for each choice .",
    "let @xmath51 @xmath110 .",
    "* return * @xmath111    the squared error of a regressor @xmath112 on a distribution @xmath37 over @xmath113 is denoted by @xmath114 the corresponding regret is given by @xmath115 .",
    "the following theorem relates the regret of the resulting predictor to that of the learned regressor .    for all @xmath2-class partial label problems @xmath4 and all squared - error regressors",
    "@xmath116 , @xmath117 where @xmath118 is the regression distribution induced by algorithm  [ alg : bandit_regression ] on @xmath4 , and @xmath119 is the argmax policy based on @xmath116 .",
    "furthermore , there exist @xmath4 and @xmath120 such that the bound is tight .",
    "the theorem has a square root , which is undesirable , because the theorem is vacuous when the right hand side is greater than 1 .",
    "let @xmath119 choose some action @xmath13 with true value @xmath121 $ ] .",
    "some other action @xmath122 may have a larger expected reward @xmath123 .",
    "the squared error regret suffered by @xmath116 on @xmath13 is @xmath124=(v_{a}-f(x , a))^{2}$ ] .",
    "similarly for @xmath122 , we have regret @xmath125 . in order for @xmath13 to be chosen over @xmath126 , we must have @xmath127 .",
    "convexity of the two regrets implies that the minima is reached when @xmath128 , where the regret for each of the two choices is @xmath129 .",
    "the regressor need not suffer any regret on the other @xmath130 arms .",
    "thus with average regret @xmath131 a regret of @xmath132 can be induced , completing the proof of the first part .",
    "for the second part , note that an adversary can play the optimal strategy outlined above achieving the bound precisely .",
    "zadrozny  @xcite noted that the partial label problem could be reduced to importance weighted multiclass classification .",
    "after algorithm  [ alg : iw_bandit ] creates importance weighted multiclass examples , the weights are stripped using costing ( the rejection sampling on the weights discussed in section  [ basic ] ) , and then the resulting multiclass distribution is converted into a binary distribution using , for example , the all - pairs reduction  @xcite ) .",
    "the last step is done to get a comparable analysis .",
    "let @xmath51 @xmath133    all - pairs - train uses a given binary learning algorithm  ` learn ` to distinguish each pair of classes in the multiclass distribution created by costing .",
    "the learned classifier @xmath46 predicts , given @xmath5 and a distinct pair of classes @xmath134 , whether class @xmath8 is more likely than @xmath135 given @xmath5 . at test time",
    ", we make a choice using all - pairs - test , which takes @xmath46 and an unlabeled example @xmath5 , and returns the class that wins the most pairwise comparisons on @xmath5 , according to @xmath46 .",
    "* return * @xmath136 .",
    "a basic theorem applies to this approach .",
    "[ thm : iw_bandit ] for all @xmath2-class partial label problems @xmath4 and all binary classifiers @xmath46 , _ @xmath137 _ where @xmath84 is the _ iwc - test _ policy based on @xmath46 and @xmath53 is the binary distribution induced by _ iwc - train _ on @xmath4 .",
    "the proof first bounds the policy regret in terms of the importance weighted multiclass regret .",
    "then , we apply known results for the other reductions to relate the policy regret to binary classification regret .",
    "fix a particular @xmath5 .",
    "the policy regret of choosing action @xmath13 over the best action @xmath126 is @xmath138-{\\mathbf{e}}_{r\\sim d|x}[r_{a}]$ ] .",
    "the importance weighted multiclass loss of action @xmath13 is @xmath139 since the loss is proportional to @xmath140 with probability @xmath141 .",
    "this implies the importance weighted regret of @xmath142,\\ ] ] which is the same as the policy regret .",
    "the importance weighted regret is bounded by the unweighted regret , times the expected importance ( see @xcite ) , which in turn is bounded by @xmath2 .",
    "multiclass regret on @xmath2 classes is bounded by binary regret times @xmath24 using the all - pairs reduction  @xcite , which completes the proof .",
    "relative to the @xmath0 , this theorem has an undesirable extra factor of @xmath2 in the regret bound .",
    "while this factor is due to the all - pairs reduction being a weak regret transform , we are aware of no alternative approach for reducing multiclass to binary classification that in composition can yield the same regret transform as the @xmath0 .",
    "[ cols=\"<,>,>,^,^,^,^,^,^ \" , ]     we conduct two sets of experiments . the first set compares the offset tree with the two approaches from section  [ sec : simple ] .",
    "the second compares with the banditron  @xcite on the dataset used in that paper .",
    "ideally , this comparison would be with a data source in the partial label setting .",
    "unfortunately , data of this sort is rarely available publicly , so we used a number of publicly available multiclass datasets  @xcite and allowed queries for the reward ( @xmath25 or @xmath26 for correct or wrong ) of only one value per example .",
    "error rates ( in % ) of @xmath0 versus the regression approach using two different base regression algorithms ( left ) and @xmath0 versus importance sampling ( right ) on several different datasets using decision trees as a base classifier learner.,title=\"fig : \" ]   error rates ( in % ) of @xmath0 versus the regression approach using two different base regression algorithms ( left ) and @xmath0 versus importance sampling ( right ) on several different datasets using decision trees as a base classifier learner.,title=\"fig : \" ]    for all datasets , we report the average result over 10 random splits ( fixed for all methods ) , with @xmath143 of the dataset used for training and @xmath144 for testing .",
    "figure  [ fig : comparison ] shows the error rates ( in % ) of the @xmath0 plotted against the error rates of the regression ( left ) and the importance weighting ( right ) .",
    "decision trees ( j48 in weka  @xcite ) were used as a base binary learning algorithm for both the @xmath0 and the importance weighting . for the regression approach , we learned a separate regressor for each of the @xmath2 choices .",
    "( a single regressor trained by adding the choice as an additional feature performed worse . ) m5p and reptree , both available in weka  @xcite , were used as base regression algorithms .",
    "the @xmath0 clearly outperforms regression , in some cases considerably .",
    "the advantage over importance weighting is moderate : often the performance is similar and occasionally it is substantially better .",
    "we did not perform any parameter tuning because we expect that practitioners encountering partial label problems may not have the expertise or time for such optimization .",
    "all datasets tested are included .",
    "note that although some error rates appear large , we are choosing among @xmath2 alternatives and thus an error rate of less than @xmath145 gives an advantage over random guessing .",
    "dataset - specific test error rates are reported in table  [ t1 ] .",
    "the banditron  @xcite is an algorithm for the special case of the problem where one of the rewards is @xmath25 and the rest are @xmath26 .",
    "the sample complexity guarantees provided for it are particularly good when the correct choice is separated by a multiclass margin from the other classes .",
    "we chose the binary perceptron as a base classification algorithm since it is the closest fully supervised learning algorithm to the banditron .",
    "exploration was done according to epoch - greedy  @xcite instead of epsilon - greedy ( as in the banditron ) , motivated by the observation that the optimal rate of exploration should decay over time .",
    "the banditron was tested on one dataset , a 4-class specialization of the reuters rcv1 dataset consisting of 673,768 examples .",
    "we use precisely the same dataset , made available by the authors of @xcite .",
    "since the banditron analysis suggests the realizable case , and the dataset tested on is nearly perfectly separable , we also specialized the @xmath0 for the realizable case .",
    "in particular , in the realizable case we can freely learn from every observation implying it is unnecessary to importance weight by @xmath146 .",
    "we also specialize epoch - greedy to this case by using a realizable bound , resulting in a probability of exploration that decays as @xmath147 rather than @xmath148 .",
    "the algorithms are compared according to their error rate . for the banditron ,",
    "the error rate after one pass on the dataset was @xmath149 .",
    "for the realizable @xmath0 method above , the error rate was @xmath150 .",
    "for the fully agnostic version of the @xmath0 , the error rate was @xmath151 .",
    "these results suggest there is some tradeoff between being optimal when there is arbitrary noise , and performance when there is no or very little noise . in the no - noise situation ,",
    "the realizable @xmath0 performs substantially superior to the banditron .",
    "we have analyzed the tractability of learning when only one outcome from a set of @xmath2 alternatives is known , in the reductions setting .",
    "the @xmath0 approach has a worst - case dependence on @xmath24 ( theorem  [ otr ] ) , and no other reduction approach can provide a better guarantee ( section  [ sec : lower - bound ] ) . furthermore , with an @xmath152 computation , the @xmath0 is qualitatively more efficient than all other known algorithms , the best of which are @xmath23 .",
    "experimental results suggest that this approach is empirically promising .",
    "the algorithms presented here show how to learn from one step of exploration . by aggregating information over multiple steps",
    ", we can learn good policies using binary classification methods .",
    "a straightforward extension of this method to deeper time horizons @xmath79 is not compelling as @xmath24 is replaced by @xmath153 in the regret bounds . due to the lower",
    "bound proved here , it appears that further progress on the multi - step problem in this framework must come with additional assumptions .",
    "we would like to thank tong zhang , alex strehl , and sham kakade for helpful discussions .",
    "we would also like to thank shai shalev - shwartz for providing data and helping setup a clean comparison with the banditron .",
    "10 n. abe , a. biermann , and p. long .",
    "reinforcement learning with immediate rewards and linear hypotheses , _ algorithmica _ , 37(4 ) : 263293 , 2003 .",
    "using confidence bounds for exploitation - exploration tradeoffs , _ journal of machine learning research _ , 3 : 397422 , 2002 .",
    "p. auer , n. cesa - bianchi , y. freund , and r. schapire . gambling in a rigged casino : the adversarial multi - armed bandit problem , _ proceedings of the 36th annual symposium on foundations of computer science _ ( focs ) , 322331 , 1995 .",
    "p. auer , n. cesa - bianchi , and p. fischer .",
    "finite time analysis of the multi - armed bandit problem , _ machine learning _ , 47 : 235256 , 2002 .",
    "b. edelman , m. ostrovsky and m. schwarz .",
    "internet advertising and the generalized second - price auction : selling billions of dollars worth of keywords , _ american economic review _ , vol 97 , 242259 , 2007 .    b. edelman and m. schwarz .",
    "optimal auction design in a multi - unit environment : the case of sponsored search auctions._acm conference on electronic commerce _ , 2007 .",
    "s. kakade , s. shalev - schwartz , and a. tewari .",
    "efficient bandit algorithms for online multiclass prediction , _ proceedings of the 25th international conference on machine learning _ ( icml ) , 2008 .",
    "e. even - dar , s. mannor , and y. mansour .",
    "action elimination and stopping conditions for the multi - armed bandit and reinforcement learning problems , _ journal of machine learning research _ , 7 : 10791105 , 2006 .    y. freund and r. schapire .",
    "a decision - theoretic generalization of online learning and an application to boosting , journal of computer and system sciences , 55(1 ) : 119139 , 1997 .",
    "t.  hastie and r.  tibshirani .",
    "classification by pairwise coupling , _ annals of statistics _ , 26(2 ) : 451471 , 1998 .",
    "( also in _ advances in neural information processing systems _",
    "( nips ) , 10 : 507513 , 1998 . )    j.  heckman .",
    "sample selection bias as a specification error , _ econometrica _ , 47(1 ) : 153161 , 1979 .",
    "m. kearns , y. mansour , and a. y. ng .",
    "approximate planning in large pomdps via reusable trajectories , _ advances in neural information processing systems _",
    "( nips ) , 12 , 2000 .    s. kulkarni . on bandit problems with side observations and learnability , _ proceedings of the 31st allerton conference on communication , control , and computing _ , 8392 , 1993 .",
    "j. langford .",
    "tutorial on practical prediction theory for classification , _ journal of machine learning research _ , 6(3 ) : 273306 , 2005 .    j. langford and a. beygelzimer .",
    "sensitive error correcting output codes , _ proceedings of the 18th annual conference on learning theory _ ( colt ) , 158172 , 2005 .",
    "j. langford , l. li , and a. strehl .",
    "vowpal wabbit online learning software .",
    "available at ` http://hunch.net/  vw ` .",
    "j. langford and t. zhang .",
    "the epoch - greedy algorithm for contextual multiarmed bandits , nips 2007 .",
    "s. pandey , d. agarwal , d. chakrabati , v. josifovski .",
    "bandits for taxonomies : a model based approach , sdm 2007 .",
    "h. robbins . some aspects of the sequential design of experiments , _ bulletins of the american mathematical society _ , 58 : 527535 , 1952 .",
    "a. strehl , c. mesterham , m. littman , and h. hirsh .",
    "experience - efficient learning in associative bandit problems , icml 2006 , 889896 .",
    "c. blake and c. merz , uci repository of machine learning databases .",
    "university of california , irvine .    c. c. wang , s. kulkarni , and h. vincent poor , bandit problems with side observations , _ ieee transactions on automatic control _ , 50(5 ) , 2005 .",
    "i. witten and e. frank .",
    "data mining : practical machine learning tools with java implementations , 2000 : ` http://www.cs.waikato.ac.nz/ml/weka/ ` .",
    "m. woodruff .",
    "a one - armed bandit problem with concomitant variates , jasa , 74 ( 368 ) : 799806 , 1979 .",
    "b. zadrozny , ph.d .",
    "thesis , university of california , san diego , 2003 .",
    "b. zadrozny , j. langford , and n. abe . cost sensitive learning by cost - proportionate example weighting , _ proceedings of the 3rd ieee international conference on data mining _ ( icdm ) , 435442 , 2003 .",
    "this section proves a simple sample complexity bound on the performance of @xmath48 .",
    "for ease of comparison with existing results , we specialize the problem set to partial label _ binary classification _ problems where one label has reward @xmath25 and the other label has reward @xmath26 .",
    "note that this is not equivalent to assuming realizability : conditioned on @xmath5 , any distribution over reward vectors @xmath74 and @xmath154 is allowed .    comparing the bound with standard results in binary classification ( see , for example , @xcite ) , shows that the bounds are identical , while eliminating the offset trick weakens the performance by a factor of roughly 2 .      _",
    "( @xmath48 sample complexity)[ttwo : sample ] _ let the action choosing distribution be uniform . for all partial label binary classification problems @xmath4 and all sets of binary classifiers @xmath155 , after observing a set @xmath156 of @xmath157 examples drawn independently from @xmath4 , with probability at least @xmath158 , @xmath159 .",
    "furthermore , if the offset is set to @xmath26 , then latexmath:[\\[\\begin{aligned }     first note that for partial label binary classification problems , the @xmath48 reduction recovers the correct label .",
    "since all importance weights are @xmath25 , no examples are lost in converting from importance weighted classification to binary classification .",
    "consequently , the occam s razor bound on the deviations of error rates implies that , with probability @xmath158 , for all classifiers @xmath161 , @xmath162 , where the induced distribution @xmath53 is @xmath4 with the two reward vectors encoded as binary labels . observing that @xmath163 finishes the first half of the proof .    for the second half , notice that rejection sampling reduces the number of examples by a factor of two in expectation ; and with probability at least @xmath164 , this number is at least @xmath165 . applying the occam s razor bound with probability of failure @xmath166 ,",
    "gives @xmath167 taking the union bound over the two failure modes proves that the above inequality holds with probability @xmath168 .",
    "observing the equivalence @xmath169 gives us the final result .",
    "the sample complexity bound provides a stronger ( absolute ) guarantee , but it requires samples to be independent and identically distributed .",
    "the regret bound , on the other hand , provides a relative assumption - free guarantee , and thus applies always ."
  ],
  "abstract_text": [
    "<S> we present an algorithm , called the @xmath0 , for learning to make decisions in situations where the payoff of only one choice is observed , rather than all choices . </S>",
    "<S> the algorithm reduces this setting to binary classification , allowing one to reuse of any existing , fully supervised binary classification algorithm in this partial information setting . </S>",
    "<S> we show that the offset tree is an optimal reduction to binary classification </S>",
    "<S> . in particular , it has regret at most @xmath1 times the regret of the binary classifier it uses ( where @xmath2 is the number of choices ) , and no reduction to binary classification can do better . </S>",
    "<S> this reduction is also computationally optimal , both at training and test time , requiring just @xmath3 work to train on an example or make a prediction .    </S>",
    "<S> experiments with the @xmath0 show that it generally performs better than several alternative approaches .    </S>",
    "<S> supervised learning , active learning bandits , reinforcement learning , interactive learning . </S>"
  ]
}