{
  "article_text": [
    "the whittle likelihood @xcite is a pseudo - maximum likelihood estimator , which is commonly used for estimating the parameters of stochastic processes from realized temporal or spatial observations @xcite .",
    "the method is popular due to its computational efficiency , using fast fourier transforms ( ffts ) to approximate the likelihood in @xmath0 operations , where @xmath1 is the length of the observed series .",
    "this is in contrast to maximum likelihood which requires the inversion of a covariance matrix , in general a @xmath2 operation , or @xmath3 with a regularly sampled stationary process as the covariance matrix is toeplitz .",
    "the whittle likelihood is known to commonly produce biased parameter estimates for finite sample sizes @xcite .",
    "this occurs because the whittle likelihood uses the periodogram  a nave and biased spectral density estimate ; and this bias will translate into the parameter estimates .",
    "the bias in the periodogram is attributed to _ blurring _ , sometimes also referred to as _ leakage _ @xcite , which occurs because the spectral density estimate is from a finitely - observed sample , where this sample can be viewed as a truncation of an infinite sample .",
    "the edge - effects of this truncation cause energy in the spectral density estimate to  leak \" from high to low energy regions in the frequency domain . typically proposed solutions to reducing bias in parameter estimates are to taper or difference the observed series @xcite , but these operations come at the expense of reducing the degrees of freedom in the data , and it is not always clear how much one should taper or difference .",
    "we propose an additional solution , which is to quantify the expected artifacts from blurring directly into the theoretical spectral density , and then compare this quantity with the observed spectral density estimate in the likelihood .",
    "for continuous stochastic processes , there is the added problem of aliasing ( see also @xcite ) , which is attributed to the effect of finitely sampling the observations at fixed time periods .",
    "using the whittle likelihood to fit such observations to the spectral density of the continuous process creates a further source of bias , as the spectral density estimate will be contaminated by frequencies higher than the observed sampling rate .",
    "our de - biased approach on the other hand naturally accounts for the effects of aliasing and blurring in one operation , while retaining the same @xmath0 computational efficiency as standard whittle likelihood .",
    "we note that accounting for aliasing ( and not blurring ) in the standard whittle likelihood will in general require a numerical approximation to an integral , to fold in energy from high frequencies into the modeled spectrum . in such cases ,",
    "the whittle likelihood will become slower to implement than our de - biased method .",
    "we prove consistency of our method , under more relaxed assumptions than are required for standard whittle likelihood , as differentiability of the spectrum is now no longer strictly required .",
    "this comes at the cost of a reduced rate of convergence , namely @xmath4 relative to the normal rate of @xmath5 .",
    "we argue however that the de - biased whittle is preferred in application due its superior finite - sample performance in terms of bias reduction , and not for its asymptotic properties where whittle likelihood is already known to be efficient @xcite .",
    "we demonstrate through simulation studies , using the matrn process @xcite , that the observed bias in parameter estimates for moderate sample sizes is often orders of magnitude lower with the de - biased method , while the variance remains the same , such that the overall estimation error is much reduced .",
    "we demonstrate how our de - biasing method can be efficiently combined with tapering and/or differencing procedures , and show how applying the de - biased form of the whittle likelihood virtually always reduces the average bias and error of parameter estimates , no matter what choice of taper or differencing operator is made , and often by a large amount .",
    "in this sense , our results build on those of @xcite , who advocate the use of tapering and differencing procedures when blurring effects are most pronounced , specifically when the rate of spectral decay is faster than @xmath6 , where @xmath7 denotes frequency .",
    "small sample effects observed when using the whittle likelihood have also been explored by @xcite .",
    "dahlhaus showed inconsistency of both standard whittle estimates , as well as conditional likelihood estimates , when the characteristic root of the time series is approaching unity at the rate @xmath8 .",
    "tapered estimates were shown not to exhibit the same effect .",
    "our results correct for bias , the cause of the inconsistency observed in @xcite , whilst outperforming tapered estimators .",
    "other methods have been proposed for bias correction , see @xcite .",
    "taniguchi assumes that the time series is generated by an autocovariance that has the form of a parametric class of models , where the decay of the autocovariance is sufficiently swift .",
    "the form of the bias correction requires analytic computation , and is only designed for estimating a scalar parameter .",
    "the ideas proposed are interesting , but are not automated and generalized unlike ours , and require user intervention .",
    "there have also been alternative pseudo - maximum likelihood methods proposed in the time domain ( e.g.  @xcite ) , which use circulant embedding to achieve @xmath0 computational efficiency , and we contrast with this approach in a simulation study .    the paper is organized as follows . in section  [ s : prelim ]",
    "we provide necessary preliminaries for stationary processes .",
    "section  [ s : whittle ] formalizes maximum and whittle likelihood for second - order processes .",
    "section  [ whittle - real ] introduces the de - biased whittle likelihood .",
    "we then discuss theoretical properties of our estimator in section  [ s : prop ] .",
    "section  [ whittle - taper ] incorporates differencing and tapering into the de - biased approach . in section  [ s : simulations ] we perform simulation studies comparing with the state - of - the - art .",
    "concluding remarks are in section  [ s : conclusions ] .",
    "the appendix contains the proof of consistency for the de - biased whittle likelihood .",
    "in this paper we assume the stochastic process of interest is modeled in continuous time , however , we present our notation and equations in such a way that results can be easily adjusted for discrete processes .",
    "continuous processes are considered in order that we may address bias effects from both aliasing and blurring . with",
    "discrete processes aliasing is no longer an issue , assuming the discrete process is not sub - sampled .",
    "blurring is still very much an issue however , and the de - biased whittle likelihood can be used to remove bias effects from blurring in this case , in exactly the same way as for continuous processes .",
    "we assume that the fourier transform of the process has a jointly gaussian distribution , in order to prove asymptotic consistency of our proposed inference method .",
    "it is important to point out that this assumption is not as strict as it may seem .",
    "processes that are non - gaussian in the time domain may in fact have fourier transforms with approximately gaussian distributions for sufficiently large sample size .",
    "this is a consequence of a central limit theorem , see @xcite , who also provides formal conditions when the gaussian assumption is asymptotically valid .",
    "@xcite provide practical examples which satisfy such conditions .",
    "we define @xmath9 as the infinite sequence obtained from a zero - mean continuous - time process @xmath10 , that is @xmath11 , where @xmath12 is the sampling interval and @xmath13 . assuming that the process is second - order stationary , we define the autocovariance sequence by @xmath14 for @xmath15 , where @xmath16 is the expectation operator .",
    "the power spectral density of @xmath9 forms a fourier pair with the autocovariance sequence , and is defined via @xmath17 the angular frequency @xmath18 $ ] is given in radians . for a length @xmath1 sample @xmath19 , a simple , but statistically inconsistent , estimate of @xmath20",
    "is the periodogram  denoted @xmath21which is the squared absolute value of the discrete fourier transform ( dft ) defined as @xmath22.\\ ] ] using the cramr spectral representation theorem we can write @xmath23 in terms of orthogonal increments @xmath24 where @xmath25 where @xmath26 .",
    "note that because @xmath9 is a discrete sequence , @xmath27 has already been aliased .",
    "thus there may be departures between @xmath20 and the continuous - time process spectral density , which we denote as @xmath28 , and can be defined for @xmath29 by @xmath30 where @xmath31 ( for @xmath32 ) is the continuous - time process autocovariance , which is related to @xmath33 via @xmath34 when @xmath15 .",
    "it follows that @xmath35 for @xmath18 $ ] .",
    "thus contributions to @xmath28 outside of the range of frequencies @xmath36 are said to be  folded \" or  wrapped \" into @xmath20 .",
    "we have defined both @xmath20 and @xmath28 here , as both quantities are important in separating the contributions of aliasing and blurring in spectral estimation .",
    "consider a sample @xmath37 observed from a zero - mean gaussian process , @xmath38 , where @xmath39 is a length-@xmath40 vector , and @xmath41 is the @xmath42 theoretical covariance matrix that @xmath43 would take , under the assumption that it is a sample drawn from the proposed model .",
    "exact maximum likelihood inference can be performed by evaluating the log - likelihood given by @xmath44 where @xmath45 denotes the transpose of @xmath43 , and the superscript ",
    "@xmath46 \" is the matrix inverse .",
    "the determinant of @xmath47 is denoted by @xmath48 .",
    "we have removed additive constants not affected by @xmath49 in  .",
    "the optimal choice of @xmath39 for our chosen model to characterize the observed data is then found by maximizing the likelihood function @xcite @xmath50 because the time - domain maximum likelihood is known to have optimal properties , any other estimator will be compared with the properties of this quantity .",
    "a standard technique to avoiding expensive matrix inversions , is to approximating equation   in the frequency domain , following the seminal work of @xcite .",
    "this approach approximates @xmath51 using a fourier representation , and utilizes the special properties of toeplitz matrices . for a single series of observations the whittle likelihood , denoted @xmath52 , once discretized ,",
    "is given by @xmath53,\\ ] ] where @xmath54 is the parametric form of the theoretical spectrum of the continuous - time process , defined in equation  , and @xmath55 is the set of discrete fourier frequencies : @xmath56 .",
    "the subscript  @xmath57 \" in @xmath52 is used to denote  whittle . \"",
    "we note that sometimes this summation is made over positive or nonnegative frequencies only , which then drops the factor of @xmath58 in equation  .",
    "asymptotically this makes no difference , however for finite samples , it is better to sum over both positive and negative fourier frequencies , thus ensuring the degrees of freedom in the periodogram are correctly aggregated .",
    "the whittle likelihood _ approximates _ the time - domain likelihood when @xmath59 $ ] , i.e. @xmath60 , and this statement can be made precise , see  @xcite .",
    "however its computational cost is @xmath61 versus @xmath62 for the time - domain likelihood .",
    "we note there have also been recent advances in constructing @xmath61 time - domain approximations to maximum likelihood ( see  @xcite ) , and we compare performance in a simulation study in section  [ s : simulations ] .",
    "the whittle likelihood utilizes the periodogram , @xmath63 , which is an inconsistent and biased measure of the continuous time process spectral density , due to the blurring caused by blurring and aliasing effects @xcite .",
    "aliasing results from the discrete sampling of the continuous - time process to generate an infinite sequence , whereas blurring is associated with the truncation of the infinite sequence @xmath9 over a finite time interval .",
    "the desirable properties of the whittle likelihood rely on the _ asymptotic _ behavior of the periodogram for very large sample sizes",
    ". the bias of the periodogram for finite samples however , will translate into biased parameter estimates of the whittle likelihood , as has been widely reported ( see e.g.  @xcite ) .",
    "we therefore define an alternative pseudo - maximum likelihood function given by @xmath64 , \\\\",
    "\\label{fejerkernel } \\overline s_{x}(\\omega;\\bm{\\theta})&=&\\int_{-\\pi/\\delta}^{\\pi/\\delta } { s}_{x}(\\nu;\\bm{\\theta}){\\cal f}_{n,\\delta}\\left(\\nu-\\omega\\right)\\;d\\nu , \\quad { \\cal f}_{n,\\delta}(\\omega)=\\frac{\\delta}{2\\pi n}\\frac{\\sin^2 ( n \\omega\\delta/2)}{\\sin^2(\\omega\\delta/2)},\\end{aligned}\\ ] ] where the subscript  @xmath65 \" stands for  de - biased . \" here @xmath66 is the _ expected _ periodogram , which is the convolution of the true modeled spectrum with the fejr kernel @xmath67 , such that @xmath68 @xcite .",
    "we call @xmath66 the _ blurred _ spectrum and equation   the _ de - biased _ whittle likelihood .",
    "the set @xmath55 is defined as in equation  .",
    "while the concept of using the blurred spectrum @xmath66 in equation   is simple , the key innovation of our method lies in how it is efficiently computed without losing the @xmath0 computational efficiency of the likelihood estimator .",
    "if we directly use equation  , then this integral would usually need to be approximated by discretization , and could be computationally expensive .",
    "however we employ the useful trick that a frequency domain convolution can be converted exactly into a time domain multiplication .",
    "specifically , @xmath66 can be efficiently computed by working with the fourier pair of the blurred spectrum , which is the expectation of the _ biased autocovariance estimator _ , defined by @xmath69 for @xmath70 , such that @xmath71 the sequence @xmath72 can then be computed exactly from the theoretical autocovariance sequence in @xmath73 operations by @xmath74 combining equations   and",
    ", it follows that the blurred spectrum @xmath66 is exactly given by @xmath75 see also @xcite . then to compute the de - biased whittle likelihood",
    ", we only need to evaluate @xmath76 at the @xmath1 discrete fourier frequencies of @xmath55 used in equation  .",
    "therefore @xmath76 can be exactly computed from @xmath77 for @xmath78 using a discrete fourier transform in @xmath79 operations , where care must be taken to subtract the variance term , @xmath80 , to avoid double counting the main diagonal in the covariance matrix .",
    "this efficient computation been made possible by transforming the frequency - domain convolution in equation   into a time - domain multiplication , where the multiplication involves combining the autocovariance sequence with the triangle kernel @xmath81 .",
    "both aliasing and blurring effects are automatically accounted for in equation  ; the effect of _ aliasing _ is accounted for by sampling the theoretical autocovariance function at discrete times , while the effect of _ blurring _ , due to the truncation of the sample to finite length , is accounted for by the triangle kernel .",
    "one of the useful features of the de - biased whittle likelihood is that it can be directly computed from the model for the autocovariance of the stochastic process , @xmath82 , in @xmath0 operations , without having to derive the analytical form of the spectral density , @xmath83 .",
    "this makes the method are more directly applicable alternative to the standard maximum likelihood approach of  .",
    "if the closed form of the autocovariance sequence is unknown however , then we can inverse fourier transform the theoretical spectrum of the process to approximate the autocovariance sequence numerically ( by discretizing the integral in equation  ) , where this approximation can be made more accurate by oversampling the spectrum .",
    "subsequently we would compute the discrete fourier transform of this sequence , evaluated at the observed sample lags , multiplied by the triangle kernel ( as in equation  ) , to recover an estimate of @xmath84 , still in @xmath0 operations .    computing the whittle likelihood with the aliased , but not blurred , spectrum @xmath85defined in equation  is more complicated , as this seldom has an analytic form for continuous processes , and must be instead approximated by either explicitly wrapping in contributions from frequencies higher than the nyquist as in  , or via an approximation to the fourier transform in equation  .",
    "this is in contrast to the de - biased whittle likelihood , where the effect of aliasing and blurring can be computed exactly in one operation , as in equation  .",
    "the de - biased whittle likelihood is therefore generally quicker to implement than standard whittle likelihood using an aliased spectrum .",
    "it is known that standard whittle likelihood provides a consistent estimator of the spectrum @xcite . in this section ,",
    "we establish consistency and related properties of the de - biased whittle likelihood .",
    "the main difficulty in the proof is that , although the de - biased whittle likelihood accounts for the bias of the periodogram , there is still present the broadband correlation between frequencies of the periodogram caused by the fejr kernel .",
    "this is what prevents the de - biased whittle likelihood being exactly equal to the time - domain maximum likelihood for gaussian data .    to establish consistency , we need to bound the asymptotic behavior of this correlation .",
    "the statement is provided below in theorem 1 , with the proof provided in the appendix . the proof is composed of three propositions which provide bounds , in turn , for the covariance of the dft , the variance of linear combinations of the periodogram , and finally the score and hessian of the de - biased whittle likelihood .",
    "together these establish that the de - biased whittle likelihood is a consistent estimator converging with probability , at a rate @xmath86 .",
    "this theorem requires weaker assumptions than for standard whittle likelihood , as it does _ not _ require the assumptions that the spectrum is differentiable in @xmath7 and is near - constant over the width of the fejr kernel .",
    "assume that the infinite sequence @xmath9 is a zero - mean second - order stationary discrete process where @xmath66 , defined in equation  , is twice differentiable in @xmath87 .",
    "assume that the spectral density of @xmath9 is bounded above by the finite value @xmath88 and below by the non - zero value @xmath89 .",
    "then the estimator @xmath90 for a sample @xmath19 , with @xmath91 being the de - biased whittle likelihood defined in equation  , satisfies @xmath92    this result requires that the spectrum , @xmath20 , is bounded from above and below , and that the de - biased whittle likelihood , @xmath91 , is twice differentiable in @xmath39 .",
    "standard theory shows that the standard whittle likelihood approach is consistent with a @xmath93 rate if the spectrum is twice differentiable in @xmath7 and bounded below and above by a non - zero constant ( see @xcite ) .",
    "therefore while the rate of convergence we prove is slower than that for the standard whittle likelihood , our method of proof requires weaker assumptions .",
    "furthermore , the key innovation of the de - biased whittle likelihood is that it performs significantly better than standard whittle likelihood for finite sample sizes , as we shall demonstrate . in practice",
    ", we can see that the variances of the standard and de - biased whittle estimators will behave similarly , as sums of weighted periodograms will behave similarly whether weighted by quantities involving @xmath94 or @xmath20 .",
    "we investigate this in more detail in section  [ s : simulations ] through simulation studies .",
    "theorem 1 establishes that @xmath95 is a consistent estimator .",
    "having established consistency , we can use this result to obtain variance estimates of the de - biased whittle estimators . note that for simplicity , and without loss of generality , we set @xmath96 for the remainder of this section . from equations  , and in the appendix we see that @xmath97 where @xmath98 .",
    "the matrix @xmath99 is defined entrywise by @xmath100 and can be approximated  numerically , if the analytic form is not known  by evaluating the hessian at @xmath95 . the remaining term , @xmath101 , is the likelihood score , and to estimate its variance we use equation  , expressing the partial derivative in each element of @xmath39 separately to obtain @xmath102 where we have defined @xmath103 in deriving this expression we have made use of the fact that the @xmath104 term is deterministic and therefore does not contribute to the variance .",
    "as we have established consistency for @xmath95 we can now use the invariance principle of maximum likelihood to construct an estimator of the variance , that is @xmath105 because @xmath95 is consistent we may first take @xmath106 , and then to estimate the covariance of the periodogram we approximate the integral @xmath107 where @xmath108 is the dirichlet kernel defined by @xmath109 the off - diagonal terms of @xmath110 , namely @xmath111 , can be found in exactly the same way . then substituting into  , along with the hessian , provides estimates of the variance of the estimators .",
    "normality of @xmath95 follows because proposition 3 in section s.2 of the appendix shows that @xmath112 converges in probability to a positive constant , while @xmath113 is a gaussian quadratic form where the diagonalized representation does not put too much mass at any individual variate ; thus the sum will be a gaussian random variable .",
    "tapering and differencing are often suggested as two methods for improving whittle estimates @xcite . here in this section",
    "we outline how the de - biased whittle likelihood can be combined with either of these procedures .      to ameliorate spectral blurring of the periodogram , a standard approach is to pre - multiply the data sequence with some weighting function known as a data taper @xcite .",
    "the taper is chosen to have spectral properties such that blurring will be minimized , and the variance of the spectral estimate at each frequency is reduced ; however this comes at the expense of increasing correlation between neighboring frequencies .",
    "the tapered whittle likelihood corresponds to replacing the direct spectral estimator formed from @xmath63 in equation   with one using the taper @xmath114 @xmath115 where @xmath116 is real - valued . setting @xmath117 recovers the periodogram estimate of equation  . in the parametric setting we then compute @xmath118.\\ ] ] we call this the _ tapered whittle likelihood _ , where the subscript ",
    "@xmath119 \" denotes that a taper has been used .",
    "@xcite demonstrated that for certain discrete processes it is beneficial to use this estimator , rather than the standard whittle likelihood , for parameter estimation ",
    "particular when the spectrum exhibits a large dynamic range .",
    "nevertheless , tapering in itself will _ not _ remove all blurring effects , and the issue of aliasing for continuous sampled processes remains .",
    "a useful feature of our de - biasing procedure is that we can combine the method with tapering , to further reduce bias estimates in the maximum likelihood estimation . to do this",
    "we define the likelihood given by @xmath120 , \\\\",
    "\\nonumber \\overline{s}_{x}(\\omega;h,\\bm{\\theta})&=&\\int_{-\\pi/\\delta}^{\\pi/\\delta } { s}_{x}(\\nu;\\bm{\\theta}){\\cal h}_{\\delta}\\left(\\nu-\\omega\\right)\\;d\\nu ,   \\quad { \\cal h}_{\\delta}(\\omega)=\\delta \\left|\\sum_{t=1}^n h_t \\exp(-{\\ensuremath{\\mathrm{i}}}\\omega t \\delta ) \\right|^2.\\end{aligned}\\ ] ] we call this the _ tapered de - biased whittle likelihood _ , and it can be computed exactly and efficiently using a similar @xmath0 calculation to equation   to find @xmath121 from the time domain @xmath122 in equation  , @xmath123 is now a tapered spectral estimate , and @xmath121 is the theoretical form for the _ expected _ tapered spectral estimate given @xmath49 and @xmath124 .",
    "accounting for the exact taper used in @xmath121 accomplishes debiasing .",
    "we note that the time - domain kernel @xmath125 can be pre - computed ( unless it has a known analytic form ) which requires @xmath3 operations , but this can be stored for each taper and data - length @xmath1 , and does not have to be recomputed each time when performing numerical optimization , as it will remain fixed .",
    "the computation then involves a fourier transform after multiplying the taper kernel with the autocovariance sequence .",
    "thus the tapered de - biased whittle likelihood is still in practice an @xmath0 pseudo - maximum likelihood estimator .    with the modifications to the whittle likelihood we have proposed , the practitioner is free to select between a tapered or periodogram spectral estimate in the same way as before , but can now account for finite sample bias effects by using the de - biased likelihood approximation .",
    "both the de - biased tapered and de - biased periodogram likelihoods have their merits , but these trade - offs are different with _ nonparametric _ spectral density estimation than they are with _ parametric _ model estimation .",
    "for example , although tapering _ decreases _ the variance of nonparametric estimates at each frequency , it conversely can _ increase _ the variance of estimated parameters .",
    "this is because the taper is reducing degrees of freedom in the data , which increases correlations between local frequencies . on the other hand ,",
    "the periodogram creates broadband correlations between frequencies , especially for processes with a high dynamic range . in such instances , even though the de - biased whittle likelihood accounts for the expected blurring , the broadband correlation can lead to increased parameter errors as compared with tapered ( and de - biased ) estimates .",
    "we explore these effects in greater detail through monte carlo simulations in section  [ s : simulations ] , and demonstrate that whether one tapers or not , the de - biasing step significantly reduces bias and error .",
    "another method of reducing the effects of blurring on whittle estimates is to fit parameters to the differenced process instead .",
    "this was illustrated in numerical simulations performed in @xcite , where the whittle likelihood was found to perform poorly with fractionally differenced processes that were more smooth , but improved when working with the differenced process .",
    "whittle likelihood using the differenced process proceeds as follows .",
    "define @xmath126 = @xmath127 , both in terms of the theoretical process and the observed sample .",
    "the whittle likelihood is then performed by maximizing @xmath128 , \\quad \\textrm{where } \\quad \\widetilde s_{y}(\\omega;\\bm\\theta)=4\\sin^2\\left(\\frac{\\omega}{2}\\right)\\widetilde s_{x}(\\omega;\\bm\\theta ) , \\label{whittle_differenced}\\ ] ] and @xmath129 is the periodogram of the sample , @xmath130 , where one degree of freedom has been lost by differencing , such that the fourier frequencies are now @xmath131 the de - biased whittle likelihood is also straightforward to compute from @xmath130 @xmath132,\\\\ \\overline{s}_{y}(\\omega;\\bm{\\theta})&=2\\delta\\cdot\\re\\left\\{\\sum_{\\tau=0}^{n-1}\\left(1-\\frac{\\tau}{n}\\right)s_{y}(\\tau;\\bm{\\theta})\\exp(-{\\ensuremath{\\mathrm{i}}}\\omega\\tau\\delta)\\right\\}-\\delta\\cdot s_{y}(0;\\bm{\\theta}),\\nonumber\\end{aligned}\\ ] ] where @xmath133 from direct calculation .",
    "this likelihood is still an @xmath0 operation to evaluate , as computing @xmath134 is @xmath73 , and the rest of the calculation is the same as in equation  . differencing and tapering",
    "can also be easily combined , with both the standard and de - biased whittle likelihood .",
    "furthermore , differencing can be applied multiple times if desired .    to see theoretically how differencing can reduce the variance of the estimators ,",
    "we explore how the score of the likelihood behaves in the de - biased whittle likelihood .",
    "the score is zero mean ( for any finite @xmath1 ) , and the variance ( as derived in equation   of the appendix ) can be bounded by @xmath135 where @xmath136 and @xmath137 are upper bounds on the spectrum and the partial derivative of the blurred spectrum respectively , and @xmath138 is a lower bound on the blurred spectrum .",
    "the significance of equation   is that the magnitude of the variance of the score is controlled by the dynamic range of the spectrum .",
    "a high dynamic range increases the value of the first ratio in the bound @xmath139 .",
    "this suggests differencing a sampled process with steep spectral slopes , as reducing this ratio will reduce the variance of the estimators , taking care to omit the zero frequency from the fit .",
    "differencing multiple times however will send @xmath138 to zero , and at some point the ratio will increase and lead to inferior estimates .",
    "we explore the merits of differencing in more detail in the next section .",
    "in this section we investigate the effectiveness of de - biasing the whittle likelihood in a monte carlo study using data from a matrn process , comparing across different frequency domain estimators . all matlab code to exactly replicate the simulations in this section can be found at www.ucl.ac.uk/statistics/research/spg/software .",
    "the matrn process  @xcite , is a three - parameter continuous gaussian stochastic process defined by its spectral density @xmath140 the parameter @xmath141 controls the magnitude of the variability , @xmath142 controls the damping timescale , and @xmath143 controls the rate of spectral decay or equivalently the smoothness or differentiability of the process . when @xmath144 , the power spectrum of the process will exhibit a high dynamic range , and we can expect the periodogram to be a poor estimator of the spectral density due to blurring .",
    "conversely , when @xmath145 then we can expect departures between the periodogram and the continuous spectral density because of aliasing . for this reason we will investigate the performance of estimators over a range of @xmath146 values .",
    "we choose to investigate the matrn as it is a simple yet flexible continuous stochastic process .",
    "the matrn is in some sense a continuous - time analogue of an autoregressive fractionally integrated moving average ( arfima ) model @xcite , where @xmath146 in the matrn behaves similarly to the difference parameter ( usually denoted as @xmath147 ) in an arfima .",
    "this allows us to draw parallels with the simulation findings of @xcite , who report large errors in standard whittle likelihood approximations when @xmath148 .",
    "in figure  [ whittle2fig ] we display the bias and standard deviation of the different whittle estimators for the three parameters @xmath149 where @xmath146 varies from [ 0.6,2.5 ] in intervals of 0.1 .",
    "we fix @xmath150 and @xmath151 . for each value of @xmath146",
    ", we simulate 10,000 series of length @xmath152 , and use these monte carlo replicates to calculate bias and standard deviation for each estimator .",
    "we implement several different whittle estimators : standard whittle likelihood  , tapered whittle likelihood  , and differenced whittle likelihood  .",
    "in addition , for each of these we implement the de - biased version ( equations , , and , respectively ) .",
    "the choice of data taper is the discrete prolate spheroidal sequence ( dpss ) taper @xcite , with bandwidth parameter equal to 4 .",
    "we note that the performance of tapered versions of the likelihood , relative to other estimators , was found to be broadly similar across different choices of bandwidth .",
    "we also performed a combined differenced and tapered version of the standard and de - biased whittle likelihood , as discussed in section  [ ss : differencing ] , but these results are not included here as performance was virtually identical to tapering without differencing .",
    "the optimization is performed in matlab using ` fminsearch ` , and uses identical settings for all likelihoods , where initialized guesses for the slope and amplitude are found by performing least squares on the spectral slope , and the initial guess for the damping parameter @xmath153 is set at a mid - range value of 100 times the rayleigh frequency ( i.e. @xmath154 . )    the first column in figure  [ whittle2fig ] , displays the absolute bias of each type of whittle estimator for each matrn parameter .",
    "solid lines represent standard approaches ( black for periodogram , red for tapered , and green for differenced ) ; then with dashed - lines we display the performance of the respective de - biased versions . in general using the de - biased method",
    "reduces the observed absolute bias with each parameter .",
    "exceptions only occur in two instances where the bias of the tapered and differenced whittle likelihoods crosses zero when estimating the amplitude parameter @xmath141 , which causes a  dip \" when the absolute value is taken .",
    "note that the absolute biases are displayed on a log10 scale , such that we can in many instances see bias reduction of over a factor of 10 , representing over a 90% reduction in bias .",
    "the `` u '' shape over @xmath146 that we observe with the standard whittle likelihood using the periodogram , and less so with the tapered method , corresponds to the contamination of aliasing for small @xmath146 and blurring for large @xmath146 . differencing ameliorates the blurring effects for high @xmath146 , but not the aliasing effects for low @xmath146 .",
    "de - biased methods , particularly when combined with differencing , are seen to remove bias most consistently across the full range of @xmath146 values .",
    "the second column in figure  [ whittle2fig ] displays the standard deviations of the estimates .",
    "in general these are seen to be broadly comparable between all methods , where methods that do not difference suffer from reduced performance for high @xmath146 .",
    "the dip when estimating @xmath146 for low values with standard methods is because of boundary effects in the optimization . here",
    "the estimate of @xmath146 is not permitted to go below 0.5 , and the optimization typically converges to the lower bound of 0.5 when @xmath155 such that the estimate is biased , but not variable . note that as we have averaged over 10,000 replicates , the standard error of the bias estimates can be easily observed by dividing the corresponding standard deviations by @xmath156 , and we can see that the bias reductions using the de - biased approach are highly significant .",
    "the third column in figure  [ whittle2fig ] displays the root mean square error ( rmse ) , thus combining information from the first two columns . with standard methods ,",
    "the observed biases are in general larger than the standard deviations , so the shapes of the rmse curves generally follow that of the absolute biases , except in the instances discussed earlier for the amplitude parameter .",
    "the de - biased methods are now seen to be mostly unbiased such that standard deviation is the main contribution to the rmse .",
    "overall , reductions in error by an order of magnitude are observed in places , and in general the de - biased methods improve upon the standard method with only a few exceptions .    finally , we aggregate all information in figure  [ whittle2fig ] to produce the average mean , standard deviation , and rmse for each likelihood estimator , which we present in table  [ aggregate ] . here",
    "we have averaged across all parameter estimates of @xmath149 , and over the full range of @xmath146 considered . to not skew the results in favor of the estimation of any particular parameter",
    ", we have averaged the _ percentage _ ( rather than absolute ) bias , standard deviation , and rmse across all the results .",
    "we can see that of all the estimators , the de - biased whittle likelihood using the differenced process performs best in each measure .",
    "overall , of the three procedures  de - biasing , tapering and differencing  de - biasing is the single procedure that yields the greatest overall improvement in parameter estimation .",
    ".[aggregate ] aggregated results from figure  [ whittle2fig ] , where we average the percentage bias , standard deviation ( s.d . ) , and root mean square error ( rmse ) across all estimates of @xmath149 , and over the full range of @xmath146 considered . [ cols=\"<,^,>,<,>,<,>,<,^\",options=\"header \" , ]     the de - biased whittle likelihood and the method of @xcite return estimation errors that are very close to the optimal maximum likelihood .",
    "standard whittle likelihood performs extremely poorly due to the blurring effects of using the periodogram .",
    "the method of @xcite requires an order of magnitude more processing time than the de - biased and standard whittle likelihood . to speed up the @xcite method ,",
    "we have included results with a faster version which uses only 1 hutchinson trace estimator ( as opposed to the 50 used in the example code ) , but this method is still slower than the de - biased whittle likelihood and now yields slightly worse estimation accuracy .",
    "overall , the reported biases are very small compared to the standard deviations , except for standard whittle likelihood .",
    "the standard error of the bias is the standard deviation divided by the square root of the number of replicates , i.e. @xmath156 . therefore the standard errors of the biases are often as large as the biases themselves , and no significance should be placed on the ordering of estimators in terms of bias , other than the poor performance of standard whittle likelihood .",
    "indeed , this type of matrn process produces time series that appear nonstationary ( as the damping parameter @xmath153 is extremely small ) , and as documented by @xcite , standard whittle likelihood performs poorly in such scenarios . with the de - biased whittle likelihood",
    "however , the properties of the periodogram are corrected , and there is no advantage to be gained by using tapers .",
    "the @xcite method is numerically more complicated to implement than the de - biased whittle likelihood .",
    "whereas our method can be implemented in just a few lines of code , the circulant embedding method requires several more , particularly as random numbers must be generated for the hutchinson trace estimators .",
    "furthermore , the online code provided in the scalagauss package is only for estimating one unknown parameter ; it is not clear how the code generalizes to estimate all 3 matrn parameters , as we have performed in the previous experiment in figure  [ whittle2fig ] .",
    "in this paper we have derived properties of using the whittle likelihood with finite samples , this yielding unique insights into the governing mechanism of whittle estimates . to improve the inference procedure ,",
    "we have proposed the usage of the de - biased whittle likelihood for estimating the parameters of second - order stationary stochastic processes .",
    "the method adjusts the standard whittle likelihood by replacing the model for the theoretical spectrum with the corresponding  blurred \" spectral estimate , which quantifies expected blurring and aliasing artifacts in estimating spectra from observed samples .",
    "the proposed method significantly reduces bias and estimation error typically observed with standard whittle likelihood approaches , while still keeping computations highly efficient , as evidenced in a monte carlo study comparing with state of the art alternatives .",
    "the method is shown to be consistent , using relatively weak assumptions .",
    "furthermore , the de - biased whittle likelihood can also be combined with tapering or differencing the data , as is commonly performed in the literature , to further reduce bias and error in parameter estimates .",
    "a key methodological direction of future work is to extend the use of the whittle likelihood to multivariate processes , as well as to nonstationary time series . while the concept of implementing the blurred theoretical spectrum extends relatively easily , finding a form for its efficient computation is in general non - trivial .",
    "furthermore , to establish consistency with such processes , the proof we provide in the appendix would have to be adjusted accordingly .",
    "we wish to thank dr jeffrey j. early for useful discussions , and for providing comments and corrections for this paper .",
    "we prove theorem 1 via three propositions .",
    "for conciseness , in this document only we drop the @xmath157 subscript notation from @xmath158 and @xmath159 .",
    "assume that the sequence @xmath9 is a zero - mean second - order stationary process with spectral density @xmath160 .",
    "assume that the spectral density of @xmath9 is bounded above by the finite value @xmath161 .",
    "then the covariance of the discrete fourier transform ( dft ) of a sample @xmath19 , defined by @xmath162 is bounded , for some choice of @xmath163 ( where @xmath164 ) , by @xmath165\\right\\},\\end{aligned}\\ ] ] where @xmath166 , @xmath167 and @xmath168 .",
    "we start by defining the dirichlet kernel as @xmath169 we will make use of two properties of the dirichlet kernel .",
    "first , we have from  ( * ? ? ?",
    "* theorem 15.2 ) that : @xmath170 second , we have from  ( * ? ? ?",
    "* lemma 5 ) that @xmath171 we now quantify the correlation of the fourier transform between frequencies @xmath172 and @xmath173 .",
    "this takes the form of @xmath174 without loss of generality we take @xmath175 , which constrains @xmath176 .",
    "we assume that @xmath177 can be upper bounded by @xmath161 , i.e. @xmath178 , and therefore note that @xmath179 we now implement a change of variables , recalling the periodicity of the integrand , rewriting this integral as @xmath180 we note that because we have assumed that @xmath181 is sufficiently large we can split up the range of integration .",
    "specifically we define the range @xmath182 note that @xmath183 is a free variable and only enters into our method of bounding , conditional on the choice of @xmath184 and @xmath185 .",
    "we therefore have that we can split up the integral as @xmath186 we shall now bound these individual contributions one - by - one where we use combinations of the relationships given in equations   and  .",
    "we start by considering @xmath187 for the first term @xmath188 we use condition   @xmath189\\,d\\omega'\\\\ & = \\frac{\\pi}{2 n \\delta_\\omega } \\left[\\log \\frac{\\pi-\\delta_{\\omega}}{\\pi}-\\log \\frac{\\omega_p}{\\omega_p+\\delta_{\\omega}}\\right ] \\le\\frac{\\pi}{2 n \\delta_\\omega}\\left[\\log\\left(1 + \\frac{\\delta_\\omega}{\\omega_p}\\right)-\\log \\frac{\\pi}{\\pi-\\delta_\\omega}\\right]\\\\ & \\le\\frac{\\pi}{2 n \\delta_\\omega}\\left[\\frac{\\delta_{\\omega}}{\\omega_p}-\\log \\frac{\\pi}{\\pi-\\delta_\\omega}\\right]= \\frac{\\pi}{2 n\\omega_p}-\\frac{\\pi}{2n\\delta_\\omega}\\log\\frac{\\pi}{\\pi-\\delta_\\omega } = \\frac{1}{4j_p}-\\frac{\\pi}{2n\\delta_\\omega}\\log\\frac{\\pi}{\\pi-\\delta_\\omega}.\\end{aligned}\\ ] ] for the next term @xmath190 we use the periodicity of the dirichlet kernel and condition   @xmath191\\,d\\omega ' \\\\ & = \\frac{\\pi}{2 n}\\frac{1}{2\\pi-\\delta_\\omega}\\left[\\log\\frac{\\pi}{\\pi-\\delta_{\\omega}}-\\log\\frac { \\pi-\\delta_\\omega}{\\pi}\\right]=\\frac{\\pi}{n(2\\pi-\\delta_\\omega)}\\log\\frac{\\pi}{\\pi-\\delta_{\\omega}}.\\end{aligned}\\ ] ] this establishes the behaviour of the first integral .",
    "for @xmath192 we use both   and   @xmath193 \\le\\frac{1}{\\pi^2(|j_1-j_2|-j_p)}\\left[\\log(j_p)+{\\mathcal o}(1)\\right].\\end{aligned}\\ ] ] the bound on the third term uses condition   @xmath194\\ , d\\omega=\\frac{\\pi}{2n\\delta_\\omega}\\left[-\\log\\left(\\frac{\\omega_p}{\\delta_\\omega-\\omega_p}\\right )   + \\log\\left(\\frac{\\delta_\\omega-\\omega_p}{\\omega_p}\\right)\\right]\\\\ & = \\frac{\\pi}{n\\delta_\\omega}\\log\\left(\\frac{\\delta_\\omega-\\omega_p}{\\omega_p}\\right)=   \\frac{\\pi}{n\\delta_\\omega}\\log\\left(\\frac{\\delta_\\omega}{\\omega_p}-1\\right)\\le \\frac{\\pi}{n\\omega_p } = \\frac{1}{2j_p}.\\end{aligned}\\ ] ] the fourth term resembles the second term , and thus takes the form of @xmath195.\\end{aligned}\\ ] ] finally , we have that the fifth integral takes the form of @xmath196 as @xmath197 , the @xmath198 terms in @xmath188 , @xmath190 and @xmath199 sum to a negative value and can hence be ignored .",
    "the proposition follows by summing the remaining terms in the integral .",
    "assume that the sequence @xmath9 is a zero - mean second - order stationary process with spectral density @xmath160 .",
    "assume that the spectral density of @xmath23 is bounded above by the finite value @xmath161 .",
    "for a sample @xmath19 , and a given choice of @xmath200 , linear combinations of the periodogram have a variance that aggregates according to @xmath201}{3n\\pi^2 } \\right].\\ ] ] furthermore the optimal choice corresponds to @xmath202 in which case we obtain that @xmath203}{3n\\pi^2 } \\right ] \\\\ & = a_{\\max}^2\\|s\\|^2_{\\infty }   \\frac{3}{n^{2/3}}\\left\\{1+o(1)\\right\\}.\\end{aligned}\\ ] ]      we shall now determine what this aggregates to .",
    "we start by writing @xmath205 using the fact that the fourier transform of a gaussian process is also gaussian we may use isserlis theorem and so obtain that @xmath206 thus it follows that @xmath207 we therefore find that @xmath208 using proposition 1 , it follows that @xmath209\\right\\}^2\\\\ & \\leq \\frac{1}{n^2}\\sum_{j_1=1}^{\\lfloor n/2 \\rfloor}\\sum_{j_2=j_1 + 2j_p+1}^{\\lfloor n/2 \\rfloor } \\|s\\|^2_{\\infty}\\left\\{\\frac{2}{j_p^2}+\\frac{8}{\\pi^4(|j_1-j_2|-j_p)^2}\\left[\\log^2(j_p)+{\\mathcal o}(\\log(j_p))\\right]\\right\\}\\\\ & = \\|s\\|^2_{\\infty}\\left(\\widetilde{c}_{12}^{(1)}+\\widetilde{c}_{12}^{(2)}\\right).\\end{aligned}\\ ] ] first we note that @xmath210 then we bound the second term @xmath211\\\\ & \\le \\frac{8\\left[\\log^2(j_p)+{\\mathcal o}(\\log(j_p))\\right]}{n^2\\pi^4 } \\sum_{j_1=1}^{\\lfloor n/2 \\rfloor}\\sum_{\\tau=2j_p+1}^{\\lfloor n/2 -j_1\\rfloor } \\frac{1}{(\\tau - j_p)^2}\\\\ & \\le \\frac{4\\left[\\log^2(j_p)+{\\mathcal o}(\\log(j_p))\\right]}{n\\pi^4 } \\sum_{\\tau = j_p+1}^{\\lfloor n/2-j_p \\rfloor } \\frac{1}{\\tau^2}\\le \\frac{4\\left[\\log^2(j_p)+{\\mathcal o}(\\log(j_p))\\right]}{n\\pi^4 } \\sum_{\\tau=1}^{\\infty } \\frac{1}{\\tau^2}\\\\&=\\frac{4\\left[\\log^2(j_p)+{\\mathcal o}(\\log(j_p))\\right]}{n\\pi^4}\\zeta(2)= \\frac{4\\left[\\log^2(j_p)+{\\mathcal o}(\\log(j_p))\\right]}{n\\pi^4}\\frac{\\pi^2}{6},\\end{aligned}\\ ] ] where we have used a bound based on the riemann zeta function at an argument of 2 @xmath212 thus it follows that @xmath213.\\end{aligned}\\ ] ] finally , as @xmath214 the first statement of the proposition follows . to select the optimal order of @xmath215",
    "we see that : @xmath216\\rightarrow x_{\\mathrm { opt}}^3=n,\\quad   \\rightarrow x_{\\mathrm { opt}}=n^{1/3}.\\ ] ] the optimal rate is therefore achieved if we select @xmath217 .",
    "assume that the sequence @xmath9 is a zero - mean second - order stationary process with spectral density @xmath160 .",
    "for a sample @xmath19 , we define the frequency domain likelihood as @xmath218 .",
    "\\label{seq : likelihood}\\end{aligned}\\ ] ] assume that we chose @xmath219 and that the frequency domain likelihood @xmath220 has two continuous derivatives in @xmath221 .",
    "assume that the spectral density of @xmath23 is bounded above by the finite value @xmath88 and below by the non - zero value @xmath89 .",
    "then the score @xmath222 and the hessian @xmath223 , the derivatives of equation  , satisfy @xmath224 and @xmath225    we start by noting that @xmath226.\\end{aligned}\\ ] ] if we calculate expectations then @xmath227=0.\\end{aligned}\\ ] ] furthermore , using proposition 2 , the variance of the score takes the form of @xmath228 where @xmath229 and @xmath230 . we can therefore conclude using chebychev s inequality that we can fix @xmath231 such that @xmath232 we may therefore deduce that @xmath233 as @xmath234\\\\ \\nonumber & = -\\sum_{\\omega\\in \\omega}\\left [ -\\frac{\\left(\\frac{\\partial \\bar s\\left(\\omega ; \\theta\\right ) } { \\partial \\theta } \\right)^2}{\\bar s^2\\left(\\omega ; \\theta\\right)}+\\frac{\\frac{\\partial^2 \\bar s\\left(\\omega ; \\theta\\right ) } { \\partial \\theta^2 } } { \\bar s\\left(\\omega ; \\theta\\right)}\\right]\\\\ & \\qquad -\\sum_{\\omega\\in \\omega}\\left [ 2\\frac{\\left(\\frac{\\partial \\bar s\\left(\\omega ; \\theta\\right ) } { \\partial \\theta } \\right)^2}{\\bar s^3\\left(\\omega ; \\theta\\right)}-\\frac{\\frac{\\partial^2 \\bar s\\left(\\omega ; \\theta\\right ) } { \\partial \\theta^2 } } { \\bar s^2\\left(\\omega ; \\theta\\right)}\\right]\\hat s\\left(\\omega\\right).\\end{aligned}\\ ] ] thus we may note that @xmath235 furthermore , we have that , @xmath236\\hat s\\left(\\omega\\right)\\right\\}.\\end{aligned}\\ ] ] we define @xmath237 in this instance we can bound the variance , using proposition 2 , by @xmath238 we can therefore again conclude using chebychev s inequality that @xmath239 this yields the second result .",
    "we let @xmath240 lie in a ball centred at @xmath49 with radius @xmath241 .",
    "we additionally define the hessian matrix @xmath242 @xmath243 then @xmath244 inverting this equation for @xmath245 , and using that @xmath246 , we obtain with the assumption on continuity on @xmath247 that @xmath248 where as usual @xmath249 is the matrix of all ones , see @xcite . additionally define @xmath250 thus it follows that @xmath251^{-1}\\frac{1}{n}\\frac{\\partial } { \\partial \\theta}\\ell_d\\left(\\bm{\\theta}\\right)\\nonumber\\\\ & = -\\left[\\frac{1}{n}{\\bm{h}}\\left(\\bm{\\theta}\\right)+{\\cal o}_p\\left ( { \\mathbf{j}}\\frac{1}{n^{1/3}}\\right)+o_p({\\mathbf{j}})\\right]^{-1}{\\cal o}_p\\left ( \\frac{1}{n^{1/3}}\\right)\\nonumber\\\\ & = \\left[\\frac{1}{n}{\\bm{h}}\\left(\\bm{\\theta}\\right)\\right]^{-1}\\left[\\mathbf{i}+o_p(1)+{\\cal o}_p\\left ( \\frac{1}{n^{1/3}}\\right)\\right ] { \\cal o}_p\\left ( \\frac{1}{n^{1/3}}\\right)\\nonumber\\\\ & = { \\cal o}_p\\left ( \\frac{1}{n^{1/3}}\\right),\\end{aligned}\\ ] ] using proposition 3 , and applying slutsky s theorem @xcite , which yields the result ."
  ],
  "abstract_text": [
    "<S> the whittle likelihood is a computationally efficient pseudo - maximum likelihood inference procedure which is known to produce biased parameter estimates for large classes of time series models . </S>",
    "<S> we propose a method for de - biasing whittle likelihood parameter estimates for second - order stationary stochastic processes . </S>",
    "<S> we demonstrate how to compute the de - biased whittle likelihood in the same @xmath0 computational efficiency as standard whittle likelihood . </S>",
    "<S> we prove that the method is consistent , and demonstrate its superior performance in simulation studies . </S>",
    "<S> we also demonstrate how the method can be easily combined with standard methods of bias reduction , such as tapering and differencing , to further reduce bias in parameter estimates .    </S>",
    "<S> # 1    1    1    0    1    * the de - biased whittle likelihood for second - order stationary stochastic processes *    _ keywords : _ periodogram ; aliasing ; blurring ; tapering ; differencing ; matrn process </S>"
  ]
}