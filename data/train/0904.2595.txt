{
  "article_text": [
    "in chess , as in other popular strategic board games , players have different styles .",
    "for example , in chess some players are more `` positional '' and other more `` tactical '' , and this difference in style will affect their move choice in any given board position , and more generally their overall plan .",
    "the problem we tackle in this paper is that of applying machine learning to teach a computer to discriminate between players based on their style . before we explain our methodology , we briefly review the method of temporal difference learning , which is central to our approach .",
    "temporal difference learning @xcite is a machine learning technique , originating from the seminal work of samuel @xcite , in which learning occurs by minimising the differences between predictions and actual outcomes of a temporal sequence of observations .",
    "samuel @xcite used the game of checkers as a vehicle to study the feasibility of a computer learning from experience .",
    "although the program written by samuel did not achieve master strength , it was the precursor of the checkers program chinook @xcite , which was the first computer program to win a match against a human world champion .",
    "( see @xcite for a detailed , but less technical , description of the machine learning in samuel s checkers program . ) tesauro @xcite demonstrated the power of this technique by showing that temporal difference learning , combined with using a neural network , can enable a program to learn to play backgammon at an expert level through self - play . following this approach ,",
    "there have been similar efforts in applying this technique to the games of chess @xcite , go @xcite , othello @xcite and chinese chess @xcite .",
    "self - play is time consuming , so it is natural to try to make use of existing game records of strong players to train the evaluation function , as in @xcite ( in which , however , the temporal difference training did not employ minimax lookahead ) .",
    "learning from game records has also been used in the game of go @xcite to extract patterns for move prediction , using methods other than temporal difference learning .",
    "here our aim is not necessarily to train a computer to be a competent game player , but rather to teach it to play in the style of a particular player , learning this from records of games played by that player .",
    "( in principle , the system could learn by interacting with the player but , when sufficient game records exist , learning can generally be accomplished faster and more conveniently off - line . )",
    "it is important to note that information available during learning should _ not _ include any meta - features such as the date when the game was played , the name of the opening variation played , or the result of the game .",
    "all the learning module observes is the sequence of moves played in each game .",
    "looking at it from a different perspective , we can view the problem as one of classification .",
    "assume that we train the computer to play in the styles of two chess players , say kasparov and kramnik .",
    "the problem can then be reformulated as follows : by inspecting the record of a game played between kasparov and kramnik , can the computer detect , with some confidence , which player was playing with the white pieces and which with the black pieces ?    at an even higher level , the problem can be recast as a turing test for chess @xcite , where a computer may fool a human that it is a human player . in some sense",
    "this may already be true for the strongest available computer chess programs @xcite , as computers have already surpassed humans in their playing strength , mainly due to increased computing power and relying on brute - force calculations .",
    "moreover , there seems to be a high correlation between the choices made by top human chess grandmasters and world class chess engines ( see @xcite ) .    we will not discuss the turing test debate further and , from now on , we will concentrate on the classification problem within the domain of chess .",
    "as far as we know , this is a new problem , and in this paper we suggest tackling it using temporal difference learning . all previous uses of temporal difference learning in games ( some of which are cited above ) attempt to learn the weights of an evaluation function in order to improve the play of a computer program . in our scenario",
    "we still attempt to learn the weights of an evaluation function , but the objective is to imitate the style of a given player rather than improve the program s play .",
    "of course , if the player under consideration is very strong , for example kasparov or kramnik , then the resulting program is likely to improve ; but the method could also be used to learn the evaluation functions of weaker players .",
    "the learning algorithm described in section  [ sec : learn - eval ] , based on sutton s td(0 ) @xcite , corresponds to the simplest rule , which updates only the current predictions .",
    "we note that a more general formulation proposed by sutton is td(@xmath0 ) ; this utilises a decay factor @xmath0 between 0 and 1 , and forces the algorithm to also take into account earlier predictions . to accelerate the training , we utilise both an adaptive learning rate and a momentum term @xcite , as we describe in subsection  [ subsec :",
    "adapt ] . in section",
    "[ sec : exp ] we present a proof of concept , where we attempt to learn the styles of two recent chess world champions , kasparov and kramnik , and we make use of the learnt feature weights to guess , in a game played between the two players , who was white and who was black . despite some encouraging results , there are also some fundamental limitations of our approach for defining a player s `` style '' . in particular ,",
    "as pointed out to us by chess grandmaster pablo san segundo @xcite , our choice of features ( described in subsection  [ subsec : setup ] ) is probably too low - level , since all strong players seek to optimise the placement of their pieces and maintain a combination of pieces according to sound tactical and positional criteria . on a higher level",
    ", it is tempting to classify kasparov as a more `` tactical '' player and kramnik as a more `` positional '' player .",
    "however , these concepts are difficult to formulate in a precise manner and , moreover , it is not clear how to translate them into an algorithmic framework .",
    "we discuss these and other issues in subsection  [ subsec : limits ] . in section  [ sec : conc ] we give our concluding remarks .",
    "temporal difference learning @xcite has been widely used to tune the evaluation function component of computer game playing programs @xcite , for example , in @xcite .",
    "the evaluation function is the component of a computer game playing program that maintains the board features that are statically evaluated by the program . by combining state - of - the - art minimax tree search @xcite and game specific heuristics ,",
    "computer game playing programs have achieved world - class level , surpassing human performance in backgammon , othello , checkers and chess .",
    "it is noteworthy that computer go programs still only play at amateur level , but employing recent advances in monte carlo methods appears to be a promising approach for improving their performance @xcite .",
    "from now on we will concentrate on chess and we assume that the essence of a player s style can be described by the relative weighting of the features of an evaluation function",
    ". we will focus on the task of tuning the weights of the evaluation function using a collection of the player s game records . in the context of chess , many useful features have been proposed @xcite ; however , as we will discuss in subsection  [ subsec : setup ] , the choice of features is not easy , and we have incorporated some novel features relating to pawn structures and influence areas within the board , in addition to the conventional ones .",
    "tuning an evaluation function from game records in the context of improving a computer s performance is a well - know approach @xcite , but employing it in the context of learning a player s style is novel . in subsection  [ subsec : adapt ] we show how to accelerate the training by adapting the learning rate and adding a momentum term .",
    "let us assume , without loss of generality , that we are learning white s evaluation function , and that an evaluation function @xmath1 defines the value of a game position @xmath2 as the weighted sum of the values @xmath3 for each game feature @xmath4 , with weights @xmath5 , i.e. @xmath6 where the values @xmath3 are measured in units of a hundredth of a pawn ( i.e. the value of a single pawn is @xmath7 ) .",
    "all weights are constrained to be positive , and the weight of the material balance feature is kept constant at @xmath8 , so that all other weights are relative to material balance .",
    "we use the term _ feature vector _ for the vector of weights @xmath5 .",
    "the problem of tuning the evaluation function is that of learning the values of the weights @xmath5 that maximise the number of correct predictions of moves made by the given player .",
    "usually , the objective is to tune the evaluation function of a game playing program in order to improve the `` strength '' of the program .",
    "the relative `` strength '' of a program can be measured by its performance when playing against another program ( which is often the previous version of the same program prior to tuning its evaluation function ) .",
    "we convert the value @xmath9 for a game position @xmath2 into a win probability @xmath10 by applying the logistic function ( also known as the sigmoid function ) to @xmath1 , i.e. @xmath11 where @xmath12 is a constant , chosen here to be @xmath13 .",
    "the learning rule we use for adjusting the weights @xmath5 is the _ delta learning rule _ for perceptrons @xcite .",
    "we assume that initially @xmath14 for all @xmath4 , i.e. all the features are assigned equal weights .",
    "let @xmath2 be a game position with white to move , and let @xmath15 be white s win probability .",
    "( recall that we have assumed we are learning the evaluation function from white s perspective . )",
    "now let @xmath16 be the position with white to move after white s and black s next moves have been replayed from the game record , and let @xmath17 be the win probability for @xmath16 .",
    "( in other words , @xmath16 is the resulting position after two further ply have been replayed from the game record . )",
    "the weights at time @xmath18 are updated using gradient descent , according to the following formula : @xmath19 where @xmath20 is a small positive constant , called the _ learning rate _ , and @xmath21 ( we note that @xmath22 is the derivative of the logistic function . )    in @xcite , the learning rate @xmath23 was set to @xmath24 , although a learning rate of @xmath25 is often recommended in the literature @xcite . in our experiments , we chose @xmath26 as the initial learning rate ( see subsection  [ subsec : adapt ] for more details ) .",
    "after each time they are updated , the weights could be normalised so that they sum to @xmath8 , but we preferred simply to fix the weight of the material balance feature at @xmath8 . the logic underlying",
    "this decision is that it is customary to measure the value of a chess position in terms of pawn units .",
    "so , for example , a positional advantage can outweigh a deficit in material . in `` quiet '' positions , where there are",
    "no hidden tactics and the positional factors are balanced , the value of a position can be measured by the material balance of the pieces on the board . in practice ,",
    "the material balance of a position often dominates the evaluation function @xmath27 but chess would not be an interesting game if this were always the case .",
    "we note that the rule ( [ eq : delta ] ) is a td(0 ) temporal difference update rule @xcite , since @xmath28 is the difference between the win probability @xmath29 after the player s and opponent s moves have been made and the win probability @xmath30 of the position before the moves are made .",
    "there are two possibilities when evaluating the win probability @xmath30 : ( i ) the minimax move that the program would choose is the same as the actual move made by the player from the game record , or ( ii ) the program would choose a different move . in case ( i ) the adjustments made to the weights are the same as they would be in self - play , the assumption being that predictions become more accurate as the game progresses . in case ( ii )",
    "the adjustments made to the weights are such that the program will tend to more closely reflect the style of the actual moves made by the player .      a typical value used for the learning rate is @xmath26 , but we can also consider individual adaptive learning rates @xmath31 for each weight @xmath32 .",
    "the method we used is similar to that in @xcite ( see also @xcite for related methods ) , which uses multiplicative increases and decreases of the rates .",
    "these are specified by @xmath33 where the constants @xmath34 and @xmath35 control the rate of increase and decrease , respectively ; typically one takes @xmath36 and @xmath37 .",
    "we restricted the learning rates so that the minimum allowed value was @xmath13 and the maximum was @xmath8 ; initially they were set at the minimum @xmath13 .",
    "we smoothed the gradient by adding a momentum term @xcite ( see also @xcite ) , by setting @xmath38 where @xmath39 is the momentum parameter .",
    "typically @xmath40 is between @xmath41 to @xmath42 @xcite ; we chose @xmath40 to be @xmath43 . the update rule ( [ eq : delta ] ) is now modified to @xmath44    we note that the momentum can also be viewed as giving the procedure memory that decays over time , somewhat akin to the more general td(@xmath0 ) .",
    "in the following subsections we describe a proof - of - concept experiment , where our task was to learn the styles of two recent chess world champions , kasparov and kramnik .",
    "the resulting evaluation functions were tested by trying to discriminate between the two players from records of games between them .    in subsection  [ subsec : setup ]",
    "we describe the components of the underlying chess program used in the experiment , and in subsection  [ subsec : eval ] we describe the evaluation methodology we used to determine how well the learned evaluation functions discriminate between the two players . in subsection",
    "[ subsec : results ] we discuss the results , and in subsection  [ subsec : limits ] we consider the limitations of our experiment and suggest how further progress can be made .      in order to carry out the experiment to learn the feature weights for a player s evaluation function , we first implemented a chess playing program in matlab . a comparable implementation in a programming language like c ( possibly using open - source software )",
    "would be considerably faster ( and thus allow deeper searches ) ; however , we chose to use matlab , firstly because of its convenience for experimentation in the early stages of working on the problem , but also for the challenge of implementing a chess program in matlab .",
    "the computations were carried out using windows xp , running on a desktop pc with a 3.6 ghz intel pentium 4 processor and 2 gb of ram .",
    "the components of the program included :    1 .",
    "a parser for inputting moves from pgn ( portable game notation ) files containing the game records .",
    "2 .   a bitboard representation of the chess board @xcite , and a bitboard move generator @xcite .",
    "3 .   a tree - search module , which implements the widely used negascout variation of the alpha - beta pruning minimax algorithm @xcite .",
    "the implementation includes quiescence search and a transposition table @xcite .",
    "an evaluation function that returns the value of a game position .    for testing the learning algorithm , we chose 140 features :    1 .",
    "the first 13 features were : material balance , pseudo - mobility @xcite , piece - square value tables from @xcite , having a bishop pair @xcite , having a knight pair , preference for a single bishop over a single knight , preference for a single knight over a single bishop , king safety in the form of having castled ( with queens on the board ) , non - aversion to doubled pawns , preference for saddling the opponent with doubled pawns @xcite , having a queen - side majority , having a king - side majority , and the relative expansion factor .",
    "( the expansion factor is an idea of chess master alexander shashin , and is computed as the sum over the ranks of the number of the player s pieces on the rank multiplied by the rank .",
    "the relative expansion factor is the difference between the expansion factors for the two players @xcite . )",
    "the next 9 features were related to 9 complexes of squares , defined by the four corners of the surrounding rectangle of each complex ; for each complex , we measure the preference for ( or aversion to ) occupying ( or the opponent occupying ) the complex .",
    "the complexes are : ( 1 ) a1,a3,c1,c3 , ( 2 ) d1,d3,e1,e3 , ( 3 ) f1,f3,h1,h3 , ( 4 ) a4,a5,c4,c5 , ( 5 ) d4,d5,e4,e5 , ( 6 ) f4,f5,h4,h5 , ( 7 ) a6,a8,c6,c8 , ( 8) d6,d8,e6,e8 and ( 9 ) f6,f8,h6,h8 .",
    "the next 112 features relate to the preference for 112 adjacent pawn structures .",
    "the final 6 features are : ( 1 ) isolated d - pawn , ( 2 ) no c - pawn and a non - isolated pawn on d4 , ( 3 ) no e - pawn , a c - pawn and a non - isolated pawn on d4 , ( 4 ) the maroczy bind ( pawns on c4 and e4 with no d - pawn ) , ( 5 ) no d - pawn and no pawn on c4 but a pawn on e4 , and ( 6 ) semi - open c - file , i.e. no c - pawn but a non - isolated d - pawn not on d4 .",
    "we note that our choice of features could be viewed as a limitation , since it is debateable whether they can adequately capture a player s style @xcite . this is discussed in subsection  [ subsec : limits ] .",
    "we close this subsection by mentioning a few practical considerations :    * for training purposes we considered only moves 5 - 35 from a game record in order to avoid early opening and endgames moves , which are normally dealt with using pre - computed lookup tables and separate evaluation functions .",
    "* for computational reasons the program performs a minimax search only to a depth of three ply , with check extensions and quiescence search taking into account all captures and checks at the first ply . *",
    "as we were concentrating on kasparov s and kramnik s evaluation functions , training was carried out using a collection of 1967 of kasparov s games and 1738 of kramnik s , and validation was carried out using 123 games between kasparov and kramnik .",
    "the standard evaluation technique of using separate training and validation sets @xcite was employed .",
    "we trained the weights of the evaluation functions for the two players , @xmath45 ( kasparov ) and @xmath46 ( kramnik ) , using random selections of 1000 of each of their games .",
    "testing was done using the entire validation set of 123 games .",
    "we measure the absolute error between the current position @xmath2 and the position @xmath16 resulting after another two ply from the game record @xmath47 have been replayed as @xmath48 where @xmath49 is the estimated win probability as defined in ( [ eq : logistic ] ) , and @xmath50 is the evaluation function trained for player @xmath51 .",
    "this measure is natural in this context since it is precisely this quantity that temporal difference learning , as defined in ( [ eq : delta ] ) , is attempting to minimise .    given a game @xmath47 and a player @xmath51 , let @xmath52 be the set of positions considered in the game @xmath47 where white is to move , and let @xmath53 be those where black is to move .",
    "we assume , without loss of generality , that we are considering the game from white s perspective , whether @xmath51 is white or black . the absolute error for the game",
    "is then defined as @xmath54    we emphasise that @xmath51 refers to the evaluation function @xmath50 in ( [ eq : abs ] ) and may or may not be the player that was actually playing white in @xmath47 .",
    "we define the _ mean absolute error _ ( mae ) of the feature vector to be @xmath55 divided by the number of positions in @xmath52 .    assuming , without loss of generality , that @xmath45 was white in the game @xmath47 , we classify @xmath47 as a _",
    "hit _ for player @xmath45 with opponent @xmath46 if @xmath56 where @xmath57 is a threshold value , i.e. if we can correctly identify @xmath45 as white in the game @xmath47 because the absolute error for @xmath47 is less with @xmath45 playing white than with @xmath46 playing white .",
    "if @xmath45 was actually black , the definition is still valid provided we consider the game from black s perspective , i.e. if @xmath52 is replaced by @xmath53 in ( [ eq : wg ] ) .",
    "the _ hit ratio _",
    "@xmath58 for player @xmath45 with opponent @xmath46 is defined as @xmath59 where @xmath60 is the validation set of test games played between @xmath45 and @xmath46 , and @xmath61 is the cardinality of @xmath60 ( cf .",
    "@xcite ) ; the hit ratio can be viewed as a measure of classification accuracy .",
    "we emphasise that if @xmath45 was white in @xmath47 then the summation in ( [ eq : wg ] ) is taken over @xmath52 , but if @xmath45 was black it is taken over @xmath53 ; thus @xmath62 is computed from @xmath45 s perspective , i.e. from white s perspective if @xmath45 was white and from black s perspective if @xmath45 was black . in general @xmath63 , since @xmath64 is computed from @xmath46 s perspective .",
    "we are therefore able to distinguish @xmath45 s and @xmath46 s styles if both @xmath65 and @xmath66 by a specified margin .",
    "we note that if , for example , @xmath65 but @xmath67 , then the classifier can discriminate between the players when the games are examined from @xmath45 s perspective , but not when they are examined from @xmath46 s perspective .",
    "this situation is obviously undesirable since , when attempting to classify a new game between the two players , we do not have the benefit of knowing in advance which player was white and which was black .",
    "we trained and tested our algorithm on the games of kasparov and kramnik , as described at the end of subsection  [ subsec : setup ] .",
    "figure  [ fig : mae ] shows the moving averages of the mae of the feature vectors during training .",
    "we see that , after the first 50 or so games , the mae is relatively stable and is quite similar for the two players .",
    "it is important that the maes do not differ by too much , in order to avoid any bias in the testing ; in these tests the difference between the mae of the two vectors over the training period was , on average , approximately @xmath68 , i.e. less than @xmath69 .",
    "figure  [ fig : weights ] shows the difference between the feature vectors of the two players , where positive values indicate features for which the weights are higher for kasparov s vector and negative values features for which they are higher for kramnik s vector .",
    "there are four features for each player for which that player has the higher weight and the difference is greater than @xmath70 ; we now briefly discuss these . for kapsparov",
    ", they are : the piece - square value tables , preference to saddle the opponent with doubled pawns , and the two complexes defined by squares a1,a3,c1,c3 ( white s queen - side ) and squares f6,f8,h6,h8 ( black s king - side ) .",
    "the difference in weight for the piece - square value tables may be due to these being learnt from self - play @xcite , where games are generally decided as a result of tactical play , which is closer to kasparov s highly dynamic style .",
    "the weight differences for the two complexes may indicate kasparov s tendency as white to attack black s king , which normally castles on the king - side , and as black to opt for an attack on white s king when the players castle on opposite wings . for kramnik ,",
    "the four features are : preference for the bishop pair , the relative expansion factor , and the two complexes defined by squares f4,f5,h4,h5 ( the central king - side ) and squares f1,f3,h1,h3 ( white s king - side ) . the relative expansion factor and the preference for the central king - side",
    "may be related to kramnik s preference for manoeuvering on the king - side , and the preference for white s king - side may indicate his preference for keeping his king safe , especially when he is white . regarding the pawn structure features",
    ", there is only one for each player for which the weight difference is greater than @xmath71 . for kasparov , it is feature ( iv)(5 ) in subsection  [ subsec : setup ] ( with a difference of @xmath72 ) , which may indicate his preference for a pawn on e4 and the absence of a pawn on d4 . for kramnik ,",
    "it is feature ( iv)(2 ) in subsection  [ subsec : setup ] ( with a difference of @xmath73 ) , which may indicate his preference for a pawn on d4 and the absence of a pawn on c4 .",
    "these differences may reflect their preferred openings , since these often determine the middle game pawn structure .     moving averages of the mae of the feature vectors during training for kasparov and kramnik , width=566,height=377 ]    although these observations are interesting , it is clear that , as discussed above , the features we are using are not sufficient to fully capture the different styles of the two players .",
    "moreover , the weights on their own do not tell the full story , as some features may tend to have higher values than others . in our case , however , apart from material balance ( which has a fixed value ) , the values of all the other features are normally less than the value of a pawn .",
    "nevertheless , in this context , feature selection , i.e. determining the dominant features in each player s evaluation function , may be useful .",
    "the difference between kasparov s and kramnik s feature vectors , width=566,height=377 ]    in order to optimise the results , we chose to test the trained feature vectors just on moves 25 to 35 from the validation set of 123 games .",
    "this choice was motivated by the fact that we expected the differences in style to be most noticeable in proper middle game positions .",
    "in particular , we were not attempting to capture their individual opening preferences , which are easily detected at the meta - level , for example , by comparing opening sequences to an opening book database .",
    "nevertheless , the choice of opening does reflect style to some degree and pawn structures often persist until the endgame . as pointed out to us by chess grandmaster pablo",
    "san segundo @xcite , the choice of opening does not always correlate with style as there may be other considerations when choosing an opening , such as playing against a specific opponent or the tournament situation of the player .    in figure",
    "[ fig : class ] we show @xmath74 as the continuous line and @xmath64 as the broken line , where the threshold @xmath75 was set to zero , the start move was varied from 25 to 35 , and the end move was fixed at 35 .",
    "the mean of @xmath74 is @xmath76 , and the mean of @xmath64 is @xmath77 , which clearly shows the potential of the method .",
    "moreover , we note that the mean value of the difference between the mae for @xmath45 and @xmath46 from @xmath45 s perspective when counting the hits for @xmath74 is @xmath78 , while from @xmath46 s perspective when counting the hits for @xmath64 it is @xmath79 .",
    "classification accuracy for games between kasparov and kramnik , width=566,height=377 ]    despite this moderate success , we could not replicate this result for the games of topalov ( @xmath80 ) , another former world champion , under the same training regime .",
    "although we obtained the value of @xmath81 as the mean of @xmath82 , the very low value of @xmath83 was obtained for @xmath84 .",
    "correspondingly , although we obtained the value of @xmath85 as the mean of @xmath86 , the low value of @xmath87 was obtained for @xmath88 .",
    "it is possible that 1000 games are not enough to train the weights for topalov s feature vector .",
    "evidence for this is that the average differences during training between the mae of topalov s feature vector and both kasparov s and kramnik s was approximately @xmath89 , i.e. more than @xmath90 .",
    "however , as mentioned above , the average difference between the mae of kasparov s and kramnik s feature vectors was only @xmath68 , less than @xmath69",
    ". moreover , the mae of topalov s feature vector was diverging rather than converging as the training increased . the failure to train an adequate feature vector for topalov may partly be due to the limitations of the features we have selected , and possibly also to other limitations of our approach , as discussed in the next subsection .      as noted in the introduction ,",
    "our choice of features for classifying players styles is probably too low - level , since strong players will normally play strong moves in any position @xcite .",
    "it is possible that a higher level abstraction of a player s style would emerge from a substantial increase in the number of features ( deep blue had approximately 8000 features @xcite ) , given a sufficient increase in computing power .",
    "an example of such emergence is the `` positional '' 37th move ( be4 ) played by deep blue against kasparov in their rematch in 1997 ; this move unsettled kasparov for the rest of the match , which he subsequently lost .",
    "we are unsure what the best approach may be for capturing higher level elements of playing style , such as `` positional '' versus `` tactical '' , within an algorithmic framework .",
    "one possible way forward for recognising positions as tactical may be indicated by the observation that tactical ability requires strong calculation .",
    "we note that a wide range of chess manuals promote improvement of tactical ability through puzzles ( many of which are available in electronic form ) that can readily be solved with the aid of a powerful computer chess program . on the other hand ,",
    "fewer puzzles for improving `` positional '' ability exist , and their solution often involves a _ plan _ rather than an individual move ; such a solution , in the form of a plan , is not readily obtainable with the aid of current computer chess technology , which puts the emphasis on brute - force calculation rather than on any form of planning .",
    "another possibility is to design and include higher level features that better capture playing style , but we leave this as a possible direction for future research .",
    "the aim of this research was to use machine learning to capture the style of human chess players and use this knowledge to discriminate between players by inspecting records of games played between them .",
    "we have presented some preliminary results using a conventional chess engine architecture combined with the method of temporal difference learning .",
    "this has yielded some success , as described in subsection  [ subsec : results ] .",
    "although we believe that the methodology we have presented is sound and potentially viable , we have also uncovered some fundamental issues that need to be addressed if further progress is to be made .",
    "in particular , it would be desirable to capture higher level concepts , such as `` tactical '' versus `` positional '' , and to be able to classify the choices players make during a game according to the degree to which that they match these concepts .",
    "since methods used in the domain of chess frequently transfer to other strategic board games , it would be interesting to try our approach on games such as checkers and go .",
    "we conclude with the speculative suggestion that there may be even wider domains of application to , for example , learning profiles of agents from records of sequences of their actions .",
    "breuker , j.w.h.m .",
    "uiterwijk , and h.j .",
    "van den herik .",
    "information in transposition tables . in h.j .",
    "van den herik and j.w.h.m .",
    "uiterwijk , editors , _ advances in computer chess 8 _ , pages 199211 .",
    "university of maastricht , maastricht , 1997 .",
    "t.  kojima and a.  yoshikawa .",
    "acquisition of go knowledge from game records . in j.",
    "frnkranz and m.  kubat , editors , _ machines that learn to play games _ , pages 179204 .",
    "nova science publishers , huntington , ny , 2001 .",
    "marsland and y.  bjrnsson . from minimax to manhattan . in h.j .",
    "van den herik and h.  iida , editors , _ games in ai research _ , pages 517 .",
    "institute for knowledge and agent technology ikat , university of maastricht , 2000 .",
    "h.  mannen and m.a . wiering . learning to play chess using td(lambda)-learning with database games . in _ proceedings of the belgian - dutch conference on machine learning ( benelearn04 ) _ , pages 7279 , brussels , 2004 .",
    "l.  pellen .",
    "how not to imitate a human being : an essay on passing the turing test . in r.",
    "epstein , g.  roberts , and g.  beber , editors , _ chess skill in man and machine _ , pages 431446 .",
    "springer science + business media , new york , ny , 2008 .",
    "schraudolph , p.  dayan , and t.j .",
    "temporal difference learning of position evaluation in the game of go . in _ advances in neural information processing systems ( nips )",
    "_ , pages 817824 , denver , co , 1994 .    d.  stern , r.  herbrich , and t.  graepel .",
    "bayesian pattern ranking for move prediction in the game of go . in _ proceedings of international conference on machine learning ( icml ) _ ,",
    "pages 873880 , pittsburgh , pa . , 2006 .",
    "j.  schaeffer , m.  hlynka , and v.  jussila .",
    "temporal difference learning applied to a high - performance game - playing program . in _ proceedings of international joint conference on artificial intelligence ( ijcai ) _ ,",
    "pages 529534 , seattle , washington , 2001 .",
    "d.  silver , r.s .",
    "sutton , and m.  mller .",
    "reinforcement learning of local shape in the game of go . in _ proceedings of international joint conference on artificial intelligence ( ijcai ) _ , pages 10531058 , hyderabad , india , 2007 .",
    "trinh , a.s .",
    "bashi , and n.  deshpande .",
    "temporal difference learning in chinese chess . in _ international conference on industrial and engineering applications of artificial in telligence and expert systems ( iea / aie ) _ , pages 612618 , castelln , spain , 1998 ."
  ],
  "abstract_text": [
    "<S> we describe a preliminary investigation into learning a chess player s style from game records . the method is based on attempting to learn features of a player s individual evaluation function using the method of temporal differences , with the aid of a conventional chess engine architecture . </S>",
    "<S> some encouraging results were obtained in learning the styles of two recent chess world champions , and we report on our attempt to use the learnt styles to discriminate between the players from game records by trying to detect who was playing white and who was playing black . </S>",
    "<S> we also discuss some limitations of our approach and propose possible directions for future research . </S>",
    "<S> the method we have presented may also be applicable to other strategic games , and may even be generalisable to other domains where sequences of agents actions are recorded .    _ </S>",
    "<S> keywords : _ temporal difference learning , evaluation function , game records , player s style , computer chess </S>"
  ]
}