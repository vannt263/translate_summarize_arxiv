{
  "article_text": [
    "due to the shift to content - oriented internet , information - centric networking ( icn )  @xcite was proposed to ameliorate the pressure on current network infrastructure .",
    "icn architecture extensively uses in - network caching to reduce network traffic and improve content delivery efficiency .",
    "compared to the conventional edge caching , which is usually designed to maximize the local ( byte ) hitrate , in - network caching is fundamentally different because network topology and cache collaboration play an important role in both algorithm design and system evaluation  @xcite . in other words , simply optimizing local performance in a cache network does not necessarily drive the whole system to its optimal state .    as an active research field",
    ", there is abundant analytical work in icn  @xcite which significantly improved the understanding on the functional relation among system performance , traffic flow and network topology . moving to collaborative caching ,",
    "similarly , many practical caching algorithms were proposed and analyzed  @xcite in various settings .",
    "nonetheless , two important aspects of future cache networks have long been overlooked .",
    "firstly , considering that caching is universal and content is pervasive in an icn context , it is reasonable to assume that multiple autonomous systems ( as ) with different interest participate in a cache network .",
    "meanwhile , some big content providers like google and facebook , along with akamai , also actively build up a wide range of content distribution networks by connecting to or even directly deploying storage in isp networks .",
    "it is foreseeable that in the near future our core network will transform into a complex content network consisting of heterogeneous caches @xcite .",
    "the motivation for collaboration is to get additional benefits from others , but caches might be unwilling to sacrifice their own performance for purely altruistic reasons . even within a single isp network , where we can reasonably assume all the nodes are obedient ,",
    "sacrificing certain caches in order to pursue the `` global welfare '' is not always acceptable or even not safe . because it may cause severe regional performance problem , especially if the cache is installed at a critical position in the system .",
    "the immediate cascading effects can spread fast and wide in the network , further causes much larger damage than anticipated @xcite .",
    "however , most previous work simply maximizes the aggregated utility under the strong assumption of all others being fully obedient .",
    "consequently , global optimum usually results in performance degradation on certain nodes and might not be acceptable to all nodes . in this paper , we argue that collaboration should be based on fairness . while global optimum is attractive , it is more important to guarantee that every node will be better off collaborating together than working alone so each part of the network will be improved at the same time and function properly . rather than simply optimizing the aggregated benefits , we find it more preferable to maximize the additional benefit from collaboration . in other words , we study how to improve the overall system performance without downgrading any individual , as the following example shows .",
    "* example . *",
    "_ we use the mini caching system described in fig.[fig : example ] as a simple example to illustrate our problem space .",
    "_    _ case 1 : greedy strategy _ lets each cache optimize its own performance locally . because @xmath0 and @xmath1 have the same demands , each will be cached with @xmath2 chance , giving an average utility @xmath3 for each cache .",
    "the outgoing traffic from each cache is @xmath4 .",
    "for the whole caching system , the possible content in two caches are @xmath5 , @xmath6 , @xmath7 and @xmath8 , each has a probability @xmath9 .",
    "therefore , we have the average utility @xmath10 .",
    "_ case 2 : global strategy _ tries to maximize the aggregated utility of the whole system . by caching all the objects ,",
    "the overall cache utilization is improved due to no duplicates in the system , leading to the highest @xmath11 .",
    "however , the performance of cache @xmath12 drops from @xmath13 to @xmath14 comparing to the greedy strategy .",
    "meanwhile , the outgoing traffic from cache @xmath12 also increases by 2 , which might cause potential congestion problem in the network .",
    "_ case 3 : fair strategy _ emphasizes the basis of collaboration . comparing to the previous two strategies , the overall utility @xmath15 is between the greedy one and global one .",
    "though @xmath16 of a fair strategy is not as high as the global one , we can see the overall system performance is improved and nobody gets worse off because of collaboration .",
    "secondly , collaboration is mostly achieved by explicitly or implicitly exchanging messages , which inevitably introduces communication overhead .",
    "the knowledge of how the collaboration overhead grow on a network is extremely valuable for network researchers and engineers in evaluating communication systems and designing protocols @xcite .",
    "nonetheless , the collaboration overhead is either overlooked or overly - simplified in the previous work , and is especially poorly understood on general topologies . in order to simplify the analysis , most previous work introduce a strong assumption on the topological regularity and often use structured networks ( e.g. line , tree , grid and etc . ) in the cost analysis . despite of being closed - form , these analytical results in general",
    "can hardly be applied to more realistic network settings . because the topologies in real - life are far from being structured and regular , e.g. isp networks , ases topologies and internet @xcite .",
    "these realistic networks are usually characterized by their degree distribution and other graph properties such as diameter , centrality , clustering coefficient and etc .",
    "both the wide deployment and the active research of content networks urge us to deepen our understanding on the cost of collaboration and its relation with aforementioned network topological properties",
    ".     represents the aggregated demands satisfied by the whole caching system .",
    "similarly , @xmath17 and @xmath18 represent the demands satisfied by cache @xmath19 and cache @xmath12 respectively .",
    "@xmath20 represents the outgoing traffic due to uncached content .",
    "three caching strategies ( greedy , global and fair ) are presented.,width=332 ]    with an increased interest on collaborative caching and with continuous efforts in deploying various content networks , in this paper , we investigate above two questions : ( 1 ) how to design a collaborative caching strategy which embraces both efficiency and fairness ; ( 2 ) how much the collaboration overhead costs on general topologies .",
    "specifically , our contributions are as follows    * we formulate the in - network caching problem as a nash bargaining game .",
    "our solution guarantees provable pareto efficiency and proportional fairness .",
    "* we derive the functional relation of collaboration overhead on general topologies , and theoretically show the collaboration is practically constrained within a small neighborhood due to its exponential growth in cost .",
    "* we experimentally show the collaboration is highly localized on realistic isp topologies .",
    "the optimal neighborhood is usually less than three hops , and can be further reduced if larger cache is used . * our results",
    "show that while collaborative caching can be beneficial , the benefits only apply when collaborating with a small neighborhood .",
    "the rest of the paper is organized as follows .",
    "section  [ sec : model ] describes the model and section  [ sec : bargain ] presents the formulation of in - network caching game .",
    "section  [ sec : convex ] derives the centralized solution and investigates the communication overhead .",
    "section  [ sec : projsub ] derives the distributed algorithm of the solution with a convergence proof .",
    "section  [ sec : fairness ] investigates the fairness in in - network caching game .",
    "section  [ sec : exp ] evaluates the proposed algorithm thoroughly with different simulation settings and section  [ sec : related ] discusses the related work .",
    "finally section  [ sec : conclusion ] concludes the paper .",
    "we assume a content network whose topology can be represented as a graph @xmath21 , where @xmath22 is the set of nodes characterized with their degree distribution @xmath23 .",
    "@xmath24 denotes the probability that a node has exactly degree @xmath25 . for each node @xmath26 , it is equipped with cache of size @xmath27 .",
    "we denote @xmath28 as the set of content objects . for each @xmath29 , we associate two parameters : @xmath30 and @xmath31 .",
    "@xmath30 is the object size and @xmath31 is its aggregated demand ( e.g. , requests per second ) observed from all the clients connected to @xmath32 .",
    "we do not assume that any node has global knowledge of the whole network .",
    "instead , a node is only aware of the information within its neighborhood by collaborating with its neighbors ( not necessarily directly connected ) .",
    "collaboration is characterized by the scope that a node can collaborate with others , namely by its search strength , and we use @xmath33 to represent @xmath32 s search radius measured in hops .",
    "@xmath33 uniquely defines a neighborhood for each @xmath32 , which we denote as @xmath34 , where @xmath35 measures the length of the shortest path between @xmath32 and @xmath36 .",
    "let s further define @xmath37 , which represents the set of nodes who have @xmath32 in their neighborhoods .",
    "apparently , with homogeneous search radius , we have @xmath38 . allowing heterogeneous search radius indicates the neighborhood relation is not symmetric , so @xmath39 and @xmath40 may not be the same in most cases .",
    "assume that there is a distributed / centralized caching algorithm to manage these networked caches .",
    "such an algorithm is also referred as a caching strategy which can be decomposed into `` caching decision '' and `` retrieving decision '' .",
    "these two parts solve `` what to cache '' and `` where to fetch '' respectively .",
    "to model such caching strategy , we use two vector decision variables : @xmath41 and @xmath42 .",
    "@xmath43 denotes whether @xmath32 caches @xmath44 , and @xmath45 denotes whether @xmath32 retrieves the object @xmath44 from @xmath36 . in the model , we relax the integer constraints on @xmath41 and @xmath42 to allow both to be real values . due to the nature of one - dimension _ bin packing problem",
    "_ , the relaxation renders only one fractional object per cache @xcite . considering the total number of cached objects is big , the induced impact on a cache from one partial object is almost negligible , especially when the object is not the most popular one .",
    "therefore , such relaxation provides a tight and optimistic bound of the original _ 0 - 1 integer programming _ problem and also significantly simplifies our analysis .",
    "besides , it leads to a even better intuitive explanation since a content file is usually divided into many smaller pieces ( i.e. chunks ) in practice to improve the transmission efficiency .",
    "allowing real values makes it possible to represent that only a fraction of the file is cached or retrieved therefore the model is more realistic . for a partial object",
    ", the beginning of a fraction is always at the zero offset in a file , further discussion on this can be found in section [ sec : discuss ] .",
    "because a caching strategy is essentially a mapping which by definition can be viewed as a function of its subscript , we have the following definition .",
    "a caching strategy for a network @xmath46 is a tuple of functions @xmath47 where @xmath48 $ ] and @xmath49 $ ] .",
    "the family of all such tuples is denoted as @xmath50 , which represents the whole space of all caching strategies .",
    "a caching strategy for a node @xmath32 is defined as @xmath51 , where @xmath52 $ ] and @xmath53 $ ] are the partial functions of @xmath41 and @xmath42 with domains restricted to @xmath54 and @xmath55 respectively .",
    "note `` @xmath56 '' above represents cartesian product when applying to sets .",
    "for the content that a node can not store due to its capacity limit , it may try to fetch them from nearby neighbors .",
    "therefore a node can always get some extra benefit by collaborating , and it would be beneficial if such utility is maximized . from a practical perspective , an optimal caching strategy is considered a good strategy if we have    1 .",
    "pareto efficiency is achieved in the collaboration .",
    "well - defined fairness is achieved among the nodes .",
    "these two requirements are proposed based on the following considerations .",
    "first , as system resources are scarce and valuable , being pareto efficient guarantees no system resource is wasted .",
    "however , pareto efficient solution may not be unique in vector optimization . from an individual node s perspective",
    ", one important motivation to collaborate is obtaining extra benefit .",
    "as we have argued , it is hard to justify that a node is altruistic and willing to sacrifice his own performance for a global optimum .",
    "second requirement emphasizes that maximizing the utility from collaboration should not hurt individual performance , so a certain well - defined fairness must be achieved .",
    "bargaining game is a game theoretical model for analyzing how players collaborate to allocate certain shared resource .",
    "the process of collaboration is called bargaining .",
    "if the agreement can not be reached during bargaining , the situation is referred as negotiation breakdown .",
    "the original bargaining game is a two - player game , but it can be easily extended to multiple players .    in a bargaining game , there can be multiple pareto efficient solutions .",
    "nash proved  @xcite that there is only one unique solution which satisfies all the four axioms as follows : ( 1 ) pareto optimality ; ( 2 ) scale invariance ; ( 3 ) symmetry ; ( 4 ) independence of the irrelevant alternatives .",
    "such a solution is called nash bargaining solution ( nbs ) .",
    "nbs is an axiomatic solution and is agnostic about the actual mechanism through which the agreement is reached .",
    "instead , it only concerns the eventual outcome of a bargaining process by solving the following optimization problem .",
    "@xmath57 eq.([eq : nash:1 ] ) is called nash product .",
    "@xmath58 is the initial disagreement value for the player @xmath59 .",
    "the disagreement value is defined as the worst payoff a player would accept , any value lower than that will break down the negotiation",
    ". please refer to @xcite for more details on bargaining games .",
    "a node serves client requests by storing popular content in local cache .",
    "due to its storage capacity limit , the local cache needs to be used wisely .",
    "however , a node s utility can be improved with neighbors help . from network perspective , the aggregated capacity in a cache network is a resource shared by all the nodes .",
    "collaboration thus indicates a node should also take others needs into account while optimizing its own utility .",
    "practically , this means local caching decision should be made via negotiation . in the following ,",
    "we give the formal definition of in - network caching game and its solution .",
    "an in - network caching game is a tuple @xmath60 , where @xmath61 contains all the utility values obtainable via collaboration , @xmath62 contains all the disagreement values leading to a negotiation breakdown .    in in - network caching context , a node only stops collaborating with others if it can not be better - off than simply using its own cache .",
    "so disagreement value @xmath63 is easy to estimate .",
    "let @xmath64 be the pareto frontier of set @xmath65 , which is a concave function with closed compact convex domain .",
    "a game is considered fair iff its outcome is fair .",
    "therefore ,    a fair collaborative game is a game @xmath66 with nash bargaining solution , namely a function @xmath67 such that @xmath68 uniquely maximizes @xmath69 .    by definition ,",
    "the solution satisfies the aforementioned four axioms . besides",
    ", nbs is the only solution that provides proportional gains with respect to the nadir point of the bargaining set  @xcite ; we will discuss this again in section  [ sec : fairness ] .    to solve the problem more efficiently , especially when",
    "multiple players get involved , the product of terms is usually translated into its equivalent summation form . by taking logarithm of the objective function ( [ eq : nash:1 ] )",
    ", we have @xmath70 .",
    "therefore nbs can also be obtained by solving the following equivalent problem @xmath71",
    "we first derive the centralized solution to expose the structure of collaboration , from which we show neighborhood plays a key role in the optimization process .",
    "then we carry on the analysis on communication overhead due to collaboration .",
    "given node @xmath32 , its utility can be defined as:@xmath72 first term represents the utility gained by locally cached content and the second one represents the utility gained by neighbors help .",
    "the second term also indicates that the gain of retrieving remote content decreases as the distance increases . from a practical perspective",
    ", it indicates that a node prefers fetching from the closest source to avoid long delay or extra traffic .",
    "note that any form of eq .",
    "which is affine is possible , the form above is not the only possibility . without loss of generality ,",
    "we assume unit object size @xmath73 , also let @xmath74 for simplicity of expression .",
    "plugging in eq.([eq : util ] ) , then the optimization problem based on the bargaining framework is @xmath75 subject to @xmath76 , \\quad",
    "\\forall v_i \\in v , o_k \\in o \\label{eq : int2 } \\\\    & y_{i , j , k } \\in [ 0,1 ] , \\quad \\forall v_i , v_j \\in v , o_k \\in o \\label{eq : int1}\\end{aligned}\\ ] ] constraint ( [ eq : cache ] ) means the content stored at a node can not exceed its cache capacity .",
    "constraint ( [ eq : fsb ] ) says @xmath32 can retrieve @xmath44 from @xmath36 only if @xmath36 cached it ; it also says @xmath32 can not get more than @xmath36 can offer .",
    "constraint ( [ eq : dst ] ) simplifies the data scheduling by constraining a node to retrieve maximum one complete object in a cache period",
    ". constraints ( [ eq : int2 ] ) and ( [ eq : int1 ] ) impose the domain of decision variables .",
    "one technical detail needs special caution is the concavity of the object function  ( [ eq : nash : max ] ) . generally speaking",
    ", the composite of a logarithmic function and an arbitrary function does not necessarily preserve concavity .",
    "however , lemma [ thm:0 ] shows the object function under our investigation is indeed concave .",
    "[ thm:0 ] the problem ( [ eq : nash : max ] ) is a convex optimization problem .",
    "the proof is trivial . since @xmath77 in eq .",
    "( [ eq : util ] ) is affine and positive , non - negative weighted sum of @xmath77 is still affine and positive .",
    "all the affine functions are log - concave .",
    "so the objective function ( [ eq : nash : max ] ) is concave .",
    "in addition , all the constraints ( [ eq : cache])([eq : dst])([eq : fsb])([eq : int2 ] ) and ( [ eq : int1 ] ) are affine .",
    "therefore , problem ( [ eq : nash : max ] ) is a convex optimization problem .",
    "[ eq : thm : kkt ] in a fair collaborative game , for the optimal caching strategy @xmath78 of node @xmath32 , there exist non - negative vectors @xmath79 , @xmath80 , @xmath81 , @xmath82 and @xmath83 , such that @xmath84 where @xmath85 and @xmath86 .",
    "theorem [ eq : thm : kkt ] exposes the internal structure of collaboration , its proof is rather straightforward and can be found in the appendix . calculating @xmath78 for node @xmath32 requires the information from @xmath87 , e.g. @xmath88 , the kkt multiplier associated with constraint ( [ eq : fsb ] ) .",
    "actually , the first equation in eq.([eq : kkt : sys ] ) indicates @xmath88 is the only multiplier shared in neighborhood , others are local variables . @xmath89 can be viewed as the `` shadow price '' of transferring @xmath44 from @xmath36 to @xmath32 , which is a `` cost '' for @xmath32 but an `` income '' for @xmath36 .",
    "thus term @xmath90 is @xmath32 s total income from serving @xmath44 to those in @xmath40 .",
    "( [ eq : alc:1 ] ) indicates that if total income due to @xmath44 increases , @xmath32 tends to cache it .",
    "meanwhile , eq .  ( [ eq : alc:2 ] ) suggests that if the cost @xmath89 increases , @xmath32 tends to stop retrieving @xmath44 from @xmath36 .",
    "as we can see , the explanation of the results matches our intuition very well .",
    "the whole equation system has @xmath91 variables and same number of equations",
    ". the computation overhead can be considerably high if the content set and network are big , which motivates us to look for a more scalable distributed algorithm in section [ sec : projsub ] .",
    "note though a distributed solution can significantly accelerate the calculations by parallelism , it will not reduce the overall computation complexity and the performance gain is at the price of increased traffic by exchanging information .",
    "the amount of exchanged information will not be less than that in a centralized solution and the collaboration structure are very similar .",
    "the growth of such communication overhead of a distributed solution will be thoroughly analyzed on various networks in section [ sec : comovh ] .",
    "a centralized solution has several obvious drawbacks in its actual use .",
    "first , it suffers from high computation complexity even with moderate problem size .",
    "second , it is not robust enough due to its single point failure . third , it is not adaptive enough under network dynamics . hence we need to translate the centralized solution into a distributed one by decomposition techniques . in this section ,",
    "we show how to derive the distributed solution from the equivalent dual problem and present our fair in - network caching ( fin ) algorithm .    to solve an equation system",
    ", each node can be viewed as a subsystem .",
    "if they simply optimize locally , all the calculations in each subsystem are independent from those in other subsystems .",
    "however , variables and constraints due to collaboration make such calculations dependent , therefore they couple a subsystem with others .",
    "such variables and constraints are referred as _ complicating variables and constraints _",
    "@xcite .    as discussed in section  [ sec : convex ] , constraint ( [ eq : fsb ] ) is the only complicating constraint coupling a node with its neighbors . to decompose the objective function ,",
    "we first rewrite original problem ( [ eq : nash:2 ] ) into its equivalent convex form .",
    "@xmath92 then we apply lagrangian dual relaxation .",
    "lagrangian dual relaxation provides a non - trivial lower - bound of primal ; the difference between the dual and the primal is called _",
    "duality gap_. in some cases , duality gap can be zero if certain conditions are met as we show below .",
    "the lagrangian @xmath93 associated with objective ( [ eq : nash:9 ] ) is defined as follows @xmath94    \\ ] ] @xmath83 is the dual variable associated with eq.([eq : nash:9 ] ) .",
    "then the lagrangian dual function @xmath95 is as follows @xmath96 given @xmath88 , let @xmath97 and @xmath98 be the unique minimizers for the lagrangian ( [ eq : dual:1 ] ) over all @xmath41 and @xmath42",
    ". then the dual function ( [ eq : dual:2 ] ) can be rewritten as @xmath99 . by maximizing the dual function",
    ", we can reduce the duality gap .",
    "the lagrangian dual problem of the primal ( [ eq : nash:9 ] ) is defined as follows @xmath100 the constraints for the dual problem are the same as those of the primal except constraint ( [ eq : fsb ] ) which is already included in the dual objective function .",
    "obviously there must exist a solution @xmath101 which satisfies all the constraints . also because the objective function ( [ eq : nash:9 ] ) is convex and all the constraints ( [ eq : cache])([eq : dst])([eq : int2 ] ) and ( [ eq : int1 ] ) are affine , slater s condition holds , and the duality gap is zero .",
    "thus when the dual problem ( [ eq : nash:5 ] ) reaches its maximum , the primal problem also reaches its minimum .",
    "the optimal solution for primal problem ( [ eq : nash:9 ] ) can be derived from the optimal solution for dual problem ( [ eq : nash:5 ] ) .",
    "as we have shown , a node subsystem can be successfully decoupled from the others in the same neighborhood with lagrangian dual decomposition .",
    "each node @xmath32 now only needs to optimize its utility locally for a given @xmath88 by calculating @xmath102 to help dual problem converge to its optimum , we can use standard projected subgradient method  @xcite to derive the distributed collaborative caching algorithm .",
    "let @xmath103 and @xmath104 denote the subgradient and subdifferential of dual function @xmath105 at point @xmath88 respectively .",
    "then for every @xmath106 we have @xmath107 vector @xmath108 points to the direction where @xmath105 increases fastest . in each iteration",
    ", node @xmath32 needs to solve the subsystem ( [ eq : dual:3 ] ) to update dual variable @xmath88 .",
    "@xmath25 represents the @xmath109 iteration .",
    "@xmath110 is the step - size in the @xmath109 iteration which can be determined by several standard methods  @xcite .",
    "projected subgradient method projects @xmath88 on its constraint ( @xmath83 ) in each iteration , and we use @xmath111 as a shorthand for the euclidean projection of a point on @xmath112 .",
    "eventually @xmath113 when @xmath114 .",
    "the primal solution can be constructed from optimum @xmath115 .",
    "note that feasibility is not necessarily needed in every iteration .",
    "[ eq : thm : converge ] algorithm [ alg : prjgrt ] converges to its optimum as the sequence @xmath117 ...",
    "@xmath118 converges , if a diminishing step size is used such that @xmath119 and @xmath120 .    with theorem [ eq : thm :",
    "converge ] , we can easily show the validity of the proposed algorithm [ alg : prjgrt ] by showing fin converges to the optimum with a decreasing step size .",
    "the proof is fairly standard and can be found in the appendix .",
    "collaboration is meant to improve a node s knowledge on the content distribution within its neighborhood , which further helps the nodes make better caching decisions together . however , as there is no free lunch for optimization , the improvement on caching performance is at the price of extra network traffic .",
    "the collaboration inevitably introduces communication overhead .",
    "however , in the prior research , such overhead are either overlooked or overly simplified by using highly regular structures such as lines and trees . though the cost analysis can be significantly simplified , the strong assumption on topological regularity is rather disturbing since it prevents us from applying any conclusion to a more general network setting where the topology can be very flexible .",
    "so far , the cost of collaboration is especially poorly understood on general network topologies . in this section ,",
    "we present how we derive the functional relation between the collaboration overhead and the underlying topological structures only using a general graph model @xmath21 presented in section [ sec : model ] .",
    "note that even though fin is used as an example , the analysis in the following generally applies to any collaborative caching algorithm with few modifications . by investigating the fin algorithm presented in section [ sec : projsub ]",
    ", we can see that the communication overhead due to calculating @xmath88 originate from two parts .",
    "the first part is induced by replying the queries from the nodes having @xmath32 in their neighborhood , namely @xmath40 .",
    "the second part is induced by collecting information from the nodes in @xmath32 s own neighborhood , namely @xmath39 . given the communication overhead is measured by the number of exchanged messages , and the overhead @xmath121 of node @xmath32 can be calculated as @xmath122 scalar @xmath123 in eq .",
    "( [ eq : ovh:1 ] ) represents a constant factor for communication overhead , and can be understood as message size or other protocol - dependent factors . for system level overhead , we have the following theorem .",
    "[ thm:1 ] in a network @xmath21 where node @xmath32 has a neighborhood @xmath39 uniquely determined by its search radius @xmath33 , the system communication overhead @xmath124 due to collaboration for calculating optimal caching strategy equals @xmath125    system level communication overhead is the aggregation of individual overheads from all the nodes , therefore @xmath126 given @xmath127 , neighborhood relation can be written as a tuple @xmath128 .",
    "calculating @xmath129 is equivalent to counting how many tuples there are in the whole system .",
    "obviously , @xmath130 , i.e. , as long as there is a tuple @xmath131 for @xmath39 , there must be a tuple @xmath132 for some @xmath133 , and vice versa . using double counting technique",
    ", we can show @xmath134 .",
    "therefore , eq .  ( [ eq : ovh:2 ] ) can be rewritten as @xmath135 eliminating @xmath40 will greatly facilitate following proofs .",
    "clearly , the system level communication overhead is @xmath136 .",
    "theorem  [ thm:1 ] shows it is a function of the aggregated neighborhood size , so we do not need to consider @xmath40 in the calculation even when search radius is heterogeneous . to focus on the functional relation between overhead and neighborhood",
    ", we fix the network size @xmath137 and content set size @xmath138 , and let @xmath139 for the purpose of simplicity .",
    "[ thm:2 ] in a network @xmath21 where a node s average neighborhood size equals @xmath140 , system communication overhead equals @xmath141 .",
    "it is trivial by noticing @xmath142 .    for a node @xmath32",
    ", we can organize its neighborhood @xmath39 into @xmath33 concentric circles according to the neighbor s distance to @xmath32 .",
    "we denote @xmath143 as the average number of @xmath144-hop neighbors on the @xmath145 circle .",
    "obviously , @xmath146 .",
    "[ thm:3 ] in a random network @xmath21 where nodes have average search radius @xmath144 , the induced system overhead @xmath147 by increasing the average search radius by 1 equals @xmath148^{r } \\times z_1 \\label{eq : nb : t1}\\end{aligned}\\ ] ]    lemma  [ thm:2 ] shows system overhead is a function of average neighborhood size . knowing how neighborhood grows as a function of search radius is the first step for the following proof .",
    "calculating @xmath149 , namely its directly connected neighbors , is trivial and equals a node s average degree .",
    "let @xmath150 denote the mean of a given degree variable @xmath25 .",
    "then we have @xmath151 however , calculating @xmath143 @xmath152 is not as straightforward as @xmath149 since degree distribution for a node s neighbor is not the same as general degree distribution for the whole network .",
    "let @xmath36 be one of @xmath32 s next - hop neighbors . actually , @xmath36 s degree distribution @xmath153 is proportional to both @xmath32 s degree and general degree distribution  @xcite .",
    "since we should not count the link which leads back to @xmath32 , then we have @xmath154 = \\frac{(k+1 ) p_{k+1}}{\\sum_{m } m p_m}\\end{aligned}\\ ] ] therefore , @xmath36 s average degree , or in other words , the average number of emerging links from @xmath36 equals @xmath155 because we did not assume @xmath36 is on any specific concentric circle except @xmath156 , we can use the same logic above to calculate arbitrary @xmath144-hop neighbors as follows @xmath157 from eq .",
    "( [ eq : nb : zk ] ) , we can further calculate @xmath158 .",
    "as we already know @xmath159 , by applying replacement recursively , we can rewrite eq .",
    "( [ eq : nb : zk ] ) as @xmath160^{r-1 } \\times z_1 \\label{eq : nb : zr}\\end{aligned}\\ ] ] when system increases the average search radius from @xmath144 to @xmath161 , the system overhead increases from @xmath162 to @xmath163 . with lemma [ thm:2 ]",
    ", we can calculate the difference @xmath147 by @xmath164 from eq .",
    "( [ eq : nb : zr ] ) and ( [ eq : nb : zp ] ) , we get eq .",
    "( [ eq : nb : t1 ] ) . we do not intend to give a detailed proof due to the space limitations , please refer to  @xcite which has more thorough discussions on graph topological properties .    given a search radius , theorem  [ thm:3 ] shows that the increase in overhead depends on the ratio between the number of two - hop and one - hop neighbors , and it applies to any general network with arbitrary degree distribution .",
    "the overhead only converges if there are less two - hop neighbors than first - hop ones , i.e. , @xmath165 , which actually implies the graph is not connected and has multiple components  @xcite .    in erds - rnyi random network @xmath166 ,",
    "@xmath167 is the average node degree .",
    "the induced system overhead @xmath147 by increasing average search radius by 1 and the overall system overhead @xmath124 are calculated as @xmath168    in erds - rnyi random network , the degree distribution @xmath24 is given by the following formula @xmath169 if @xmath170 , the binomial distribution above converges to the poisson distribution in its limit .",
    "@xmath171 with dobiski s formula , the @xmath172 moment of a variable with poisson distribution can be calculated as eq .",
    "( [ eq : nb:5 ] ) shows .",
    "@xmath173 denotes _ stirling numbers of the second kind _",
    "@xcite which represents the number of ways to partition a set of @xmath174 objects into @xmath25 non - empty subsets , and is known for calculating @xmath175 .",
    "@xmath176 from eq .",
    "( [ eq : nb:5 ] ) and eq .",
    "( [ eq : nb : zr ] ) , we have @xmath177 from theorem  [ thm:3 ] and eq .",
    "( [ eq : nb:7 ] ) , we have eq .  ( [ eq : thm : dlt ] ) proved .",
    "( [ eq : nb:7 ] ) shows that @xmath149 , @xmath178 , @xmath179 ... form a geometric series , thus the system overhead @xmath124 can be easily derived by calculating the summation of this series .    * summary * : theorem [ thm:3 ] conveys an important message on collaborative caching , and shows that the collaboration overhead grows exponentially on general connected topologies . because most natural graphs like internet and isp networks have @xmath180  @xcite , theorem  [ thm:3 ] means collaboration has to be restricted to a very small neighborhood to keep overhead reasonable .",
    "it is also worth noting the conclusion does not depend on a specific utility function but applies to any general optimization process on the graph which requires coordination with neighbors  @xcite .",
    "pareto efficiency does not indicate fairness . in this section , we study the fairness in caching games .",
    "we consider three well - defined and justified fairness metrics  @xcite . as the most important one ,",
    "the proportional fairness is properly modified to fit into our scenario , and the corresponding proof is provided .",
    "let @xmath181 and @xmath182 denote the achieved utility and the worst utility of @xmath32 respectively , then we have the following    egalitarian fairness ( @xmath183 ) : egalitarian fairness is achieved iff @xmath184 , we have @xmath185 .    max - min fairness ( @xmath186 ) : given a performance metric @xmath187 , max - min fairness is achieved iff @xmath188 .",
    "[ def : propfair ] proportional fairness ( @xmath189 ) : @xmath190 is proportionally fair iff @xmath191 .",
    "@xmath183 pursues the absolutely same amount of improvement on each node , and usually leads to a pareto inefficient solution . @xmath189 and @xmath186 are widely used in traffic engineering .",
    "@xmath186 pursues the fairness which maximizes the node with the worst utility , while @xmath189 is a generalization of kalai  smorodinsky solution which pursues both proportional improvement on all nodes and maximizing the utility from collaboration  @xcite .",
    "[ thm:4 ] in a fair collaborative game @xmath60 , the optimal caching strategy @xmath190 achieves @xmath189 .    because @xmath190 is the optimal caching solution , namely @xmath192 .",
    "let @xmath193 . for @xmath194 to reach its maximum , the necessary and sufficient first order condition is @xmath195 .",
    "@xmath196 such that @xmath197 .",
    "then @xmath198 we have @xmath199 sum over all the @xmath26 , we have @xmath200 by definition [ def : propfair ] , strategy @xmath190 is proportionally fair .",
    "the original form of @xmath189 is very similar to that in our definition [ def : propfair ] except @xmath201 is dropped in the formula , therefore can be viewed as a special case of definition [ def : propfair ] with @xmath202 . instead of copying the exact form , we adapted the definition of @xmath189 in our scenario .",
    "we argue that the original definition of @xmath189 used in traffic engineering ( e.g. @xcite ) is improper in in - network caching context .",
    "the reason is due to the key difference between in - network caching and traffic engineering . in traffic engineering",
    ", the bandwidth of a flow can reduce to zero . nonetheless in in - network caching ,",
    "the worst case would be `` stopping collaboration with neighbors but using a node s own local cache '' , so the utility value shall never reach zero . with the original definition of @xmath189 , a nbs only achieves @xmath189 when the disagreement point is placed exactly at zero , which indicates `` fully obedient '' therefore fails to reflect a node s bargaining power ( e.g. due to its cache capacity and topological position ) and its intrinsic selfishness .",
    "the adapted version says , that any change in a proportionally fair caching strategy will be detrimental and cause a decrease in the overall benefit from collaboration .",
    "[ thm:5 ] in a fair collaborative game @xmath60 with optimal strategy @xmath190 , @xmath183 is sufficient for @xmath186 , i.e. @xmath203 .",
    "we prove the theorem by contradiction .",
    "let s assume solution @xmath190 is egalitarian fair , but not max - min fair .",
    "@xmath204 is the corresponding utility value",
    ".    let s further assume another solution @xmath205 which achieves max - min fair , and @xmath206 is its utility value . in a fair collaborative game , based on the nature of nash bargaining framework , both @xmath207 and @xmath190 are pareto optimal .    by definition",
    ", max - min fair solution indicates that @xmath208 by definition , egalitarian fair solution indicates that @xmath209 ( [ eq : pf:1 ] ) , ( [ eq : pf:2 ] ) @xmath210 @xmath211 inequality ( [ eq : pf:3 ] ) contradicts with the fact that @xmath190 is pareto optimal .",
    "so the assumption does not hold .",
    "@xmath190 must be both egalitarian fair and max - min fair",
    ". i.e. @xmath203 .",
    "theorem  [ thm:4 ] guarantees the optimal caching strategy to achieve @xmath189 of a broader sense .",
    "though @xmath183 is seldom used due to pareto inefficiency , theorem  [ thm:5 ] guarantees that as long as @xmath183 is achieved in a fair game @xmath60 , @xmath186 is also achieved at the same time .",
    "we experimented with three isp topologies ( sprint , at&t and ntt ) , and two graph generative models with different parameters : barabsi - albert ( ba ) model and erds - rnyi ( er ) model . the configurations are @xmath212 , @xmath213 , @xmath214 and @xmath215  @xcite .",
    "for content objects ,  @xcite shows that youtube videos popularity follows weibull distribution with shape parameter @xmath216 , and the average file size is 8.4  mb .",
    "we use these values in our evaluation to capture the characteristics of realistic settings .",
    "fig.[fig : nbsz:1 ] plots the cumulative distribution function ( cdf ) of optimal neighborhood .",
    "surprisingly , though each node s search radius is preset to the network diameter , the actual neighborhood shrinks significantly after convergence . in all isp networks , over 80% of nodes have a neighborhood of no more than 3 hops .",
    "[ fig : nbsz:2 ] shows the cdf of the distance of retrieving a content measured in number of hops ; note the content served by local cache is also included ( i.e. @xmath217 ) .",
    "more impressively , at least 60% of the non - local content is served by the directly - connect neighbors in both 2  gb and 4  gb cases ; only minuscule amount is retrieved from those neighbors further than 2 hops .",
    "the result also indicates the optimal neighborhood gets even smaller with larger caches .",
    "[ fig : nbsz:3 ] plots a heatmap of the percent of served content as a function of both search radius and cache size on sprint network .",
    "@xmath218-axis is the cache size and @xmath219-axis is the search radius , numbers on the grid represent the fraction of the content served .",
    "given a cache size configuration , the fraction of served content drops quickly as distance increases .",
    "however , increasing cache size also increases the fraction of locally served content ( at @xmath220 ) , but reduces the need of collaboration . _",
    "further investigation strongly indicates the collaboration is highly localized in a small neighborhood due to the highly skewed content popularity distribution . _ in other words , if non - local content is popular enough to be worth fetching remotely , it is highly likely to discover it in the nearby neighbors",
    ". inspired by the observation above , instead of letting the neighborhood shrink to its optimum in optimization process , we let the neighborhood grow step by step in the actual fin algorithm implementation .",
    "the neighborhood growth stops when there is no further benefits .",
    "this mechanism can save us from the traffic burst due to exchanging messages in the beginning phase of the algorithm .",
    "table  [ tb:1 ] summarizes the results on three isp networks . though interesting , thorough study on",
    "the relation between content and topology is beyond the scope of this paper and is reserved as future study .",
    "content overlapping calculates the percent of same content in two different caches , it is an indicator of content diversity in cache networks .",
    "we also examined the average content overlapping among the caches and noticed another interesting phenomenon  _ content overlapping positively correlates to the cache size configuration_. e.g. , the average overlapping is 37.8% for 2  gb cache size configuration , and 62.3% for 4",
    "namely , there is less content overlapping with small cache size configuration since the nodes need more collaboration from each other to improve their performance .",
    "therefore there is a high degree of content diversity in the neighborhood . with big caches ,",
    "every node can practically store most of the popular content hence requires less help from the neighbors , which further renders a high degree of content overlapping .",
    "in essence , this phenomenon is consistent with our understanding from the experiments in fig .",
    "[ fig : nbsz:3 ] .    .growth rate of collaboration overhead @xmath147 and average optimal search radius @xmath221 on different isp networks . [ cols=\"<,<,<,<\",options=\"header \" , ]      fig .",
    "[ fig : convergence:1 ] shows that the aggregated utility converges as the number of iterations increases on sprint network .",
    "for ease of comparison , the utility has been normalized by its maximum .",
    "larger caches lead to slower convergence rate , because more cached items implies a longer negotiation process among nodes . given a cache configuration , the convergence rate is influenced by the speed at which information can spread in the network .",
    "upper and lower part in fig .",
    "[ fig : convergence:2 ] show the convergence rate on both isp and synthetic networks .",
    "as expected , larger isp networks lead to longer convergence time , but the increase is slower than linear .",
    "similar results were also observed in synthetic ones .",
    "though subgradient method is known for its sensitivity to step size , actually both constant and diminishing step size behaved rather stably in our experiments due to the algorithmic choice on small neighborhoods .",
    "other more robust methods like  @xcite will be studied in future work .      to measure caching performance",
    ", we use two well - defined metrics byte hitrate ( bhr ) and footprint reduction ( fpr ) .",
    "bhr is a conventional metric to measure saving on inter - domain traffic , while fpr is the reduction on the product of traffic volume and distance which measures saving on network traffic . for comparison , we choose lru as the baseline ,",
    "also implement another simple en - route caching heuristic called nearby search ( ns ) .",
    "ns has a tunable search radius , thus a node can communicate and retrieve content from other nodes in a neighborhood defined by the radius .",
    "ns makes its caching decision independently by optimizing locally instead of via negotiation .",
    "we use 1-hop and 4-hop search radius configuration in our experiments , and denote them as ns1 and ns4 respectively .",
    "[ fig : perf:1 ] shows lru has the worst bhr , whereas our fair in - network caching algorithm ( fin ; algorithm 1 ) has the best . by increasing the search radius ,",
    "ns4 achieves better bhr , but fin consistently remains at least 16% better than ns4 over all the networks .",
    "[ fig : perf:2 ] shows ns4 has worse fpr ( less than 40% ) than ns1 and fin , indicating the gain in bhr is achieved at the price of sacrificing fpr due to increased traffic .",
    "ns is still far away from pareto efficiency despite of being significantly better than lru .",
    "fin can easily achieve 16% improvement on bhr and 47% on fpr in all the cases .",
    "the results indicate fin reduced much more traffic than other caching strategies and is able to achieve better performance with lower cost .",
    "though we explicitly considered the fairness in the modeling part , we implicitly assumed all the participants would run the same prescribed algorithm . in reality , the situation can be different from this assumption",
    ". there might be deviant nodes who simply do not run fin algorithm . in this case",
    ", those nodes can be safely excluded from the collaboration without causing any harm to the system since their resources are unavailable .",
    "a more troublesome case is that the deviant nodes free - ride their neighbors by being dishonest or refusing to serve .",
    "the counterpart can certainly choose to stop the collaboration if it finds out that no extra benefits can be obtained .",
    "eventually the system will retreat back to the non - collaborative mode if everyone does so .",
    "this cascading effect apparently leads to another equilibrium where the whole system suffers from pareto inefficiency .",
    "we do not intend to cover all the possible cases in this short discussion .",
    "designing a sound and complete strategyproof scheme to enforce the obedience is already out of the scope of this paper and is reserved for the future work .",
    "the linear relaxation in the model is mainly for reducing the complexity in computation and analysis , and it only brings marginal impact on both optimal caching solution and its actual performance .",
    "meanwhile , it leads to an interesting discussion on the partial caching problem on cache networks which heavily relies on the chunk - level modeling . for a partially cached object , assuming that a fraction always starts from the offset zero is equivalent to implicitly assuming that the beginning of a file is more popular than the end .",
    "this assumption may hold for certain type of media files like videos @xcite but is problematic in general and can not be applied to arbitrary context without serious justification @xcite . furthermore",
    ", if chunk - level popularity is taken into account , how the collaborative caching copes with partial caching is another big question .",
    "however , according to our knowledge , the research on chunk - level analysis is severely lacking in the current literature .",
    "prior work  @xcite focused on studying the functional relation between system performance and traffic flows to characterize a cache network . though admission control and replacement policy were explicitly studied on different topologies , collaboration and its related protocol design",
    "were mostly overlooked .",
    "recent work indicates two diametrically opposed viewpoints on collaborative caching . on one hand , @xcite held a sceptical stance on the general in - network caching approach , @xcite further presents the negative result by showing non - collaborative edge caches are sufficient for most of the gains . on the other hand ,",
    "evidence in  @xcite shows collaboration can indeed improve cache performance .",
    "the opposing viewpoints are likely due to the different assumptions in modeling ; @xcite assumed a strict k - ary tree structure with a single data source at the root , whereas  @xcite showed assumption of such regular topological structure does not hold in isp networks . besides , content is universal and may be retrieved from multiple sources in icn context @xcite . following this line of research , the recent work @xcite focused more on certain system and design parameters ( e.g. topological and routing properties ) and investigated their impacts on the effectiveness of collaborative caching in order to gain a holistic understanding .",
    "@xcite explicitly or implicitly studied the collaborative caching .",
    "@xcite studied in - network caching in game theory framework by modeling the problem as pure strategic games and analyzed the equilibrium . however , in all these formulations , there is a clear _ social optimum _",
    "( i.e. , the aggregated utility of all nodes ) which measures cache system efficiency .",
    "the work above also showed this social optimum is seldom reached due to lack of coordination and nodes inherent selfishness , and the induced inefficiency is quantified with _ price of anarchy_. fairness is unfortunately overlooked .",
    "even though fairness has been studied in other context like wireless network and traffic engineering @xcite , based on our knowledge , there is no prior work studied how fairness should be properly defined on a cache network and how such fairness can be achieved via protocol design .",
    "furthermore , the impact from the network topological properties on algorithm design and caching performance attracts more and more attention in icn community .",
    "recent work@xcite realized the severe limitation of regular topologies and started moving to more general network topological settings .",
    "however , the work on the cost analysis of collaborative caching is severely lacking in the new context .    comparing to the prior work , our paper is fundamentally different in three aspects .",
    "first , in - network caching problem is modeled as a bargaining game and solved with convex optimization .",
    "second , well - defined fairness is explicitly taken into account in the protocol design .",
    "third , collaboration is carefully defined and the induced overhead is thoroughly analyzed on general topologies .",
    "we explicitly defined and studied the fair collaborative games on cache networks .",
    "we solved the problem in nash bargaining framework via convex optimization .",
    "our analysis on collaboration showed its cost grows exponentially whereas the benefit vanishes quickly , therefore collaboration should be constrained to a limited neighborhood .",
    "our proposed fin algorithm achieved good performance with guaranteed convergence , pareto efficiency and proportional fairness , on both synthetic and realistic networks .",
    "our results show that while collaborative caching is beneficial , the benefits only apply when collaborating with a small neighborhood .",
    "obviously caching decision space @xmath222 \\subset \\mathbb{r}_+$ ] is a nonempty , compact and convex set .",
    "since the objective function ( [ eq : nash : max ] ) is a continuously differentiable concave function , and all the constraints on the variables are affine , karush - kuhn - tucker ( kkt ) conditions are necessary and sufficient for the existence of an optimal solution .    to derive the optimum of a function with constraints , we first derive the lagrangian @xmath223 of eq .",
    "( [ eq : nash : max ] ) .",
    "let @xmath79 , @xmath80 , @xmath81 , @xmath82 and @xmath83 be the kkt multipliers associated with constraints .",
    "their subscripts are self - explained by the corresponding constraints associated with .",
    "then we have @xmath224 note we dropped constraints @xmath225 and @xmath226 in making the lagrangian because constraints ( [ eq : dst ] ) and ( [ eq : fsb ] ) make them redundant . in the following derivation ,",
    "we let @xmath85 and @xmath86 for the simplicity of representation . for the objective function to reach its optimum , first order necessary and sufficient conditions are @xmath227 with complementary slackness @xmath228        to prove convergence , we first prove the gradient of the dual function is bounded by a constant @xmath232 , namely the dual function @xmath233 is k - lipschitz continuous .",
    "second , we show that given the diminishing step size , the euclidean distance between the optimum @xmath234 and the best value @xmath235 achieved in all previous iterations converges to zero in limit .",
    "since the primal ( [ eq : nash:9 ] ) is strictly convex and all constraints are linear , dual @xmath233 is strictly concave and differentiable .",
    "@xmath236 by mean value theorem , there exists @xmath237 such that @xmath238 by cauchy ",
    "schwarz inequality , let @xmath239 , we have @xmath240 @xmath241 above denotes the euclidean norm . therefore , @xmath233 is k - lipschitz continuous and lipschitz constant @xmath242 .",
    "let @xmath115 denote the maximizer of dual function @xmath233 , then @xmath243 inequality ( [ eq : pff : prj ] ) comes from the fact that projection of a point onto @xmath112 makes it closer to the optimal point in @xmath112 .",
    "apply inequality  ( [ eq : pff:23 ] ) recursively , we have @xmath244 because @xmath245 and @xmath246 , and let @xmath247 , then @xmath248 @xmath249 if we choose a diminishing step size which lets @xmath250 and @xmath251 , then @xmath252 .",
    "( e.g. we can let @xmath253 , then @xmath251 and @xmath254 . )",
    "since the duality gap is zero , eventually the primal problem will converge to its optimum when its dual problem converges .",
    "s.  boyd , l.  vandenberghe , `` convex optimization '' , in _ cambridge university press _ , 2009 .",
    "chun , c.  kamalika , w.  hoeteck , et al .",
    "`` selfish caching in distributed systems : a game - theoretic analysis '' , in _ acm podc _ , 2004 ."
  ],
  "abstract_text": [
    "<S> information - centric networking extensively uses universal in - network caching . </S>",
    "<S> however , developing an efficient and fair collaborative caching algorithm for selfish caches is still an open question . </S>",
    "<S> in addition , the communication overhead induced by collaboration is especially poorly understood in a general network setting such as realistic isp and autonomous system networks . in this paper , we address these two problems by modeling the in - network caching problem as a nash bargaining game . </S>",
    "<S> we show that the game is a convex optimization problem and further derive the corresponding distributed algorithm . </S>",
    "<S> we analytically investigate the collaboration overhead on general graph topologies , and theoretically show that collaboration has to be constrained within a small neighborhood due to its cost growing exponentially . </S>",
    "<S> our proposed algorithm achieves at least 16% performance gain over its competitors on different network topologies in the evaluation , and guarantees provable convergence , pareto efficiency and proportional fairness . </S>"
  ]
}