{
  "article_text": [
    "a common and substantial problem in hydrology is that of estimating the return period of extreme floods .",
    "an accurate estimate of extreme floods is of interest in various circumstances , particularly with respect to important civil infrastructure .",
    "the design and construction of bridges and roads is often dependent on accurate understanding of river behavior during extreme events .",
    "changes in land use , especially in the urban environment , create increasingly more impervious surfaces .",
    "this leads to larger and more frequent floods , putting more stresses on flood control structures , such as levees and dams .",
    "climate change alters local precipitation patterns and magnitudes .",
    "this influences water resource management of reservoirs and rivers , affecting operation of hydroelectric power plants and river transport .",
    "the management , operation , and maintenance of this critical infrastructure relies on accurate flood predictions , including predictions for ungauged catchments based on data from gauged river catchments .",
    "one of the first approaches to regional flood estimation was the _ index flood method _ , first proposed by @xcite .",
    "it was designed to deal with cases where little or no at - site data is available for flood assessment by borrowing strength from similar ( e.g.  neighboring ) gauged catchments .",
    "the method consists of two main steps , namely , regionalization , which includes the identification of geographically and climatologically homogeneous regions , and the specification of a regional standardized flood frequency curve for a @xmath0-year return period . in section  [ sec : model ]",
    "a mathematical formalization of the index flood method is used to motivate some of the elements of our proposed model .",
    "the index flood method is still widely used today , and further developments of the method were presented in  @xcite and  @xcite . starting with the work of  @xcite , various bayesian extensions have been proposed  @xcite .",
    "although these papers show the usefulness of bayesian methods , they all derive rather directly from the classical index flood method , their main goal is usually to improve the estimation of the index flood coefficient , and they all rely solely on annual maxima .",
    "this work improves on the above studies in many important ways : the power relationship used to estimate the index flood coefficients is instead employed in the priors for the parameters of the gumbel distribution , which we have chosen as the distribution for the observations .",
    "we use carefully chosen meteorological and topographical covariates , including catchment areas and covariates based on precipitation and temperature measurements , motivated by the work of  @xcite . in summary",
    ", we believe that our work provides a coherent and comprehensive bayesian model , making better use of the available data and prior knowledge .",
    "we propose a bayesian hierarchical model for monthly instantaneous extreme flow data from several river catchments .",
    "the topographical and climatic covariates facilitate the process of extrapolating the model to ungauged river catchments .",
    "several novelties in statistical modeling and inference for flood data are presented here : we use monthly rather than yearly maxima , making better use of the available data .",
    "we use a latent gaussian model ( lgm , see e.g.  @xcite ) incorporating seasonal dependence , borrowing strength across months .",
    "the lgm allows the use of the computationally efficient mcmc split samling algorithm  @xcite , while still being sufficiently general to allow for realistic modeling .",
    "we use penalised - complexity priors  @xcite for the hyperparameters of the model , which avoids overfitting , letting the prior knowledge together with the data decide the appropriate level of model complexity .",
    "we do a thorough prior eliciation for the regression coefficients of our model , making good use of availiable prior knowledge . to demonstrate that the proposed model predicts well for ungauged catchments , we perform a cross - validation study , where we leave river @xmath1 out and predict based on the model estimated from the other rivers except @xmath1 , for each of the eight rivers .",
    "we proceed as follows : section  [ sec : data ] presents the data and the hydrological aspects of the problem .",
    "section  [ sec : model ] introduces the full hierarchical model and provides explanations of the modelling assumptions , and a description of the posterior inference .",
    "section  [ sec : results ] summarizes the results obtained from applying the model to the data .",
    "finally , section  [ sec : conclusion ] contains the conclusions drawn from the study and some ideas for future research .",
    "the streamflow data consist of monthly maximum instantaneous discharges from eight river catchments in iceland .",
    "table [ stationtable ] lists the identification number , name and the size of each catchment .",
    "even though stations vhm45 and vhm204 have the same name ( vatnsdalsa ) , they correspond to different catchments . the time series were between 20 and 80 years long ( in most cases between 40 and 60 years ) .",
    "figure  [ fig : iceland ] shows the locations of the eight catchments .",
    ".characteristics of the catchments used in the study .",
    "the station identifications , river names and catchment areas were provided by the icelandic meteorological office . [",
    "cols=\"<,<,^,<,<,^\",options=\"header \" , ]     [ stationtable ]        figure  [ fig : meanplot ] shows the sample mean of the maximum monthly instantaneous flow for each river .",
    "the catchments have a seasonal behavior characterised by lower discharge during winter and higher discharge during spring / summer .",
    "the high discharge during spring / summer is mainly due to rising temperatures and snow melt , but the specific timing of the snow melt period varies somewhat for these catchments .     for each river .",
    "]      for each catchment , the following topographic and climatic covariates were considered for extrapolating to ungauged catchments :    * catchment area : * the area of the river catchment in @xmath2 .",
    "* average precipitation : * the averaged monthly precipitation over the entire catchment . to construct this covariate the precipitation on a 1 km by 1 km grid over the whole of iceland",
    "was obtained  @xcite , which was then integrated over the catchment area .",
    "finally , the average over all years was found within each month .",
    "* maximum daily precipitation : * daily precipitation over the catchment area within each month was acquired using the same method as for the average precipitation .",
    "the value corresponding to the day with the highest precipitation , cumulated over the catchment , was chosen , then the average over all years was found within each month .    *",
    "accumulated precipitation : * the accumulated precipitation over the catchment since the start of the hydrological year ( september ) .",
    "this covariate was potentially useful for explaining high discharge attributed to snow melt .",
    "* average positive temperature : * temperature is available on the same grid as precipitation .",
    "these values were obtained in the same manner as the average precipitation within each month , with negative values truncated to zero .",
    "* maximum positive temperature : * these values were calculated in a similar way to the maximum precipitation values , with the difference being that negative temperature values were truncated to zero .",
    "the gumbel distribution is a common choice for extreme value data , due to its theoretical foundations  @xcite .",
    "we performed an anderson  darling goodness - of - fit test for the gumbel distribution , for each river and month .",
    "the resulting @xmath3-values are shown in figure [ fig : pvalues ] .",
    "the empirical distribution of the @xmath3-values is close to standard uniform , which suggests that the gumbel distribution fits the observed data reasonably well .",
    "we performed a preliminary analysis of the statistical relationship between maximum instantaneous flow and the topographical and meteorological factors described in section [ sec : data ] .",
    "the preliminary analysis was carried out as follows .",
    "first , maximum likelihood ( ml ) estimates for both the location and scale parameters of the gumbel distribution were obtained at all @xmath4 rivers and every month @xmath5 .",
    "we then fitted log - linear models where the ml estimates of the location and scale parameters , respectively , acted as the response , and all combinations of the aforementioned covariates are assessed .",
    "this preliminary analysis revealed a strongly significant log - linear relationship between the ml estimates of the location parameter and catchment area , average precipitation , maximum precipitation and accumulated precipitation .",
    "the analysis further showed a strong multicollinearity between average precipitation , maximum precipitation and accumulated precipitation .",
    "however , non - significant log - linear relationships were observed between the ml estimates and both average and maximum positive temperature . based on these results and by using a step - wise log - linear model selection algorithm based on aic score , it was decided to include both catchment area ( @xmath6 ) and maximum daily precipitation ( @xmath7 ) as predictive covariates for location parameters .",
    "analogous results also hold for the scale parameter .",
    "-values from a anderson - darling goodness of fit test for the gumbel distribution . ]      in this section , we present the proposed three - level bayesian hierarchical model . at the data level , the observed maxima of instantaneous flow @xmath8 for river @xmath1 , month @xmath5 , and year @xmath9 is assumed to follow a gumbel distribution : @xmath10 where @xmath11 and @xmath12 are the location and scale parameters , respectively . as seen from equation  ,",
    "these parameters are allowed to differ between both months and rivers . at the latent level ,",
    "the logarithm of the parameters @xmath11 and @xmath12 are modeled with a linear regression model within each month , incorporating meteorological and topographical covariates .",
    "this approach is inspired by the index flood method , where a linear model is specified for the logarithm of the mean yearly flow maxima , and is similar to the model for yearly maxima of @xcite .",
    "we build seasonal dependence into the model , letting latent parameters in neighboring months be _ a priori _ positively correlated .",
    "full details of the model are given below .",
    "let @xmath13 and @xmath14 . the linear model for @xmath15",
    "is given by @xmath16 where the @xmath17 s are centered log covariates ( except @xmath18 for all @xmath1 and @xmath5 ) and the random effect terms @xmath19 are given a prior enforcing seasonal behavior , described below .",
    "this model can be written in matrix form , as follows .",
    "collect the covariates in the matrix @xmath20 , such that the first @xmath21 rows of @xmath20 contain the covariates for river @xmath22 over each of the @xmath21 months , the next @xmath21 rows contain the covariates for river @xmath23 , and so on .",
    "let @xmath24 denote the columns of @xmath20 , and let @xmath25 and @xmath26 further , @xmath27 , and let @xmath28 , @xmath29 and @xmath30 contain the @xmath15 , @xmath31 and @xmath32 , ordered such that they line up with @xmath33 and @xmath34 .",
    "then we may write @xmath35 the model for @xmath36 is similar , with the same covariates , but different coefficients @xmath37 and @xmath38 and error term @xmath39 , and can be written in matrix form as @xmath40 to obtain a latent gaussian model we must specify multivariate normal priors for the coefficients @xmath37 , @xmath38 , @xmath41 and @xmath42 . for @xmath37 and @xmath41",
    "we fix @xmath43 , @xmath44 , @xmath45 and @xmath46 and set @xmath47 where the choices of @xmath43 , @xmath44 , @xmath45 and @xmath46 are explained in section  [ sec : elic - inform - priors ] .",
    "let @xmath48 , @xmath49 be the random intercepts ( @xmath50 ) or slopes ( @xmath51 ) of covariate @xmath52 over the @xmath21 months , and define @xmath53 similarly .",
    "we assume the following priors for @xmath38 and @xmath42 , encoding seasonal dependence : @xmath54 where @xmath55 and @xmath56 are unknown variance parameters and @xmath57 is an @xmath58 circular precision matrix that has the vector @xmath59 = s \\cdot [ 1 \\quad -2(\\kappa^2 + 2 ) \\quad \\kappa^4 + 4\\kappa^2 + 6 \\quad",
    "-2(\\kappa^2 + 2 ) \\quad 1 ] \\ ] ] on its diagonal band  @xcite , where @xmath60 is a constant ensuring that the inverse of the precision matrix is a correlation matrix .",
    "we have fixed @xmath61 to the value @xmath62 , giving the prior correlation of 0.67 between neighboring months , which seems reasonable based on our prior knowledge .",
    "note that @xmath60 is a function of @xmath61 , e.g.  for @xmath62 , @xmath63 .",
    "we here present the priors for the regression coefficients @xmath37 and @xmath41 .",
    "for each @xmath64 , @xmath65 and @xmath66 will be given equal priors , since they enter the model in a similar way .",
    "the priors specified below are written in terms of @xmath66 .",
    "as explained in section  [ sec : full - hier - model ] , @xmath41 should be given a multivariate normal prior .",
    "we will assume that the elements @xmath66 are _ a priori _ independent , so we need to set independent normal priors for the individual coefficients @xmath67 .",
    "we start by considering the coefficient @xmath68 corresponding to the logarithm of the size of the catchment area .",
    "first , note that negative values of @xmath68 make little sense , as this corresponds to a larger area giving lower maximum flows than a smaller area , other things being equal . to interpret the effects of varying positive values for @xmath68 , consider precipitation events ( rainy clouds ) moving over the area .",
    "each event will have a smaller spatial extent than the catchment area itself , when the catchment area is large ; and a hypothetical increase of the catchment area corresponding to given precipitation event will lead to a smaller fraction of the area being covered by precipitation .",
    "this gives a `` clustering effect '' : smaller catchment areas will have a larger proportion covered by precipitation events than larger catchment areas .",
    "since the value @xmath69 corresponds to a completely uniform distribution of precipitation ( which is physically implausible ) , this means than @xmath68 is highly likely to be less than one . in other words",
    ", values @xmath70 correspond to an effect of area which increases larger than linearly , which is unrealistic for the abovementioned reasons .",
    "based on the above , we believe that the most sensible values for @xmath68 are in the interval @xmath71 .",
    "we propose that the normal prior density for @xmath68 is such that the probability of negative values is @xmath72 and the probability of values greater than one is @xmath72 .",
    "these values result in a prior mean of @xmath73 and a prior standard deviation of @xmath74 .",
    "considering the effect of precipitation given a fixed area , a similar line of argument can be given for the parameter @xmath75 corresponding to maximum daily precipitation : higher maximum daily precipitation should result in higher flows , so the parameter should be positive . also , @xmath70 is unrealistic for similar reasons as explained above for @xmath68 : natural clustering effects make super - linear effects of precipitation unlikely .",
    "accordingly , @xmath75 is given the same @xmath76 prior as @xmath68 .",
    "since the data should provide good information for the intercept parameter @xmath77 , there is less of a need to specify an informative prior here .",
    "we have therefore chosen a normal density with mean zero and variance @xmath78 as an uninformative prior for the intercept .      in this section ,",
    "we describe the selection of priors for the hyperparameters @xmath79 and @xmath80 .",
    "we start by considering priors for @xmath81 .",
    "note first that @xmath81 can be regarded as a flexibility parameter : @xmath82 corresponds to a restricted model where we set @xmath83 , i.e.  the _ base model _",
    "@xmath84 without correlated random effects .",
    "@xcite provide a useful framework for selecting prior densities for flexibility parameters such as @xmath81 : penalised complexity ( pc ) priors .",
    "the ideas behind pc priors are thoroughly described in @xcite , but we give a short review here .",
    "pc priors are constructed based on four underlying principles .",
    "the first principle is occam s razor : we should prefer the simpler base model unless a more complex model is really needed .",
    "the second principle is using the kullback - leibler divergence ( kld ) as a measure of complexity  @xcite , where @xmath85 is used to measure the distance between the base model ( @xmath82 ) and the more complex model corresponding to @xmath86 ( the factor @xmath87 is introduced for convenience , giving simpler mathematical derivations ) .",
    "the third principle is that of constant - rate penalisation , which is natural if there is no additional knowledge suggesting otherwise .",
    "this corresponds to an exponential prior on the distance scale @xmath88 .",
    "note that defining the prior on the distance scale implies that pc priors are invariant to reparameterization .",
    "the fourth and final principle is _ user - defined scaling _ ,",
    "i.e.  that the user should use ( weak ) prior knowledge about the size of the parameter to select the parameter of the exponential distribution .",
    "@xcite provide both theoretical results and simulation studies showing the pc priors good robustness properties and strong frequentist performance .",
    "we shall specify independent priors for each component @xmath89 of @xmath81 and each component @xmath90 of @xmath91 .",
    "note that this entails specifying separate base models for each component . while the ideal approach would be to specify an overall multivariate pc prior corresponding to the base model",
    ", we view this as beyond the scope of this article .",
    "it is easy to derive that the pc prior approach results in exponential priors for both the @xmath89 and @xmath92 in this case , see  @xcite for details , so it only remains to specify the scaling , i.e.  the choices of parameters of the respective exponential distributions .",
    "the parameter @xmath93 is the standard deviation of the mean zero monthly intercepts @xmath94 , representing the monthly deviations from the overall intercept @xmath77 . since our model is on a logarithmic scale , the values @xmath95 and @xmath96 correspond to factors @xmath97 and @xmath98 , respectively , for @xmath99 .",
    "accordingly , @xmath100 should be considered to be a wide 95% probability interval .",
    "the value of @xmath93 giving this interval is @xmath101 .",
    "we take @xmath102 as the 0.95 quantile of the prior for @xmath93 , giving a mean of @xmath103 and a rate of @xmath104 for the exponential prior for @xmath93 .",
    "a similar argument can be given for @xmath105 , and we give it the same prior as @xmath93 .",
    "since @xmath106 , @xmath107 , @xmath108 and @xmath109 have similar roles in the model , they will given identical , independent , priors .",
    "we write in terms of @xmath106 below , with the understanding that the three other priors are identical .",
    "it is convenient to use a tail - area argument to specify the scaling .",
    "first , consider the sum of the `` fixed effect '' parameter @xmath68 and the `` random effect '' parameter @xmath110 for some month @xmath5 .",
    "for the reasons described in section  [ sec : elic - inform - priors ] , most of the prior mass of this sum should be between zero and one , but the addition of the random effects term will of course increase the variance , so the masses allowed below zero and above one should be larger than the 5% used in section  [ sec : elic - inform - priors ] .",
    "we consider 10% prior mass below zero ( and 10% above one ) for @xmath111 to give a relatively large mass outside the interval @xmath71 .",
    "this corresponds to a prior standard deviation of approximate @xmath112 for each @xmath110 .",
    "since this is a high value , it should be in the upper tail of the prior for @xmath106 : we thus specify that 99% of the mass of @xmath106 should be below the value @xmath112 , giving a rate of approximately @xmath113 ( and a mean of approximately @xmath114 ) for the exponential prior for @xmath106 .    in lack of prior knowledge suggesting otherwise , we give equal priors to @xmath92 and @xmath115 .",
    "the prior for @xmath92 can be specified in a more straightforward manner using a direct tail - area argument : considering the scale of the problem , it seems highly likely that @xmath92 should be less than ten , so we put the 0.99-quantile of the exponential prior at the value ten .",
    "the result is a rate of @xmath116 ( and a mean of @xmath117 ) .",
    "as latent models were imposed on both the location and scale parameters of the data density , approximation methods such as the integrated nested laplace approximation  @xcite were inapplicable in our setting .",
    "therefore , mcmc methods were necessary to make posterior inference .",
    "however , standard mcmc methods such as single site updating converged slowly and mixed poorly since many model parameters were heavily correlated in the posterior . for these reasons ,",
    "all posterior inference was carried out by using the more efficient mcmc split sampler  @xcite .",
    "the mcmc split sampler is a two - block gibbs sampling scheme designed for lgms , where tailored metropolis ",
    "hastings strategies are implemented within in both blocks .",
    "the sampling scheme is well suited to infer lgms with non - gaussian data density where latent models are imposed on both the location and scale parameters .",
    "the main idea of the mcmc split sampler is to split the latent gaussian parameters into two vectors , called the `` data - rich '' block and the `` data - poor '' block .",
    "the data - rich block consists of the parameters that enter directly into the likelihood function , in our case the location parameters @xmath11 and the scale parameters @xmath12 , for @xmath118 and @xmath119 .",
    "the data - poor block consists of the remaining parameters ( in our case , including the regression parameters and hyperparameters ) .",
    "an efficient block gibbs sampling scheme can then be implemented by sampling from the full conditional distributions of each block . for the data - poor block",
    ", it turns out that the full conditional is multivariate gaussian , so sampling can be done quickly using a version of the one - block sampler of  @xcite .",
    "the data - rich block can also be sampled efficiently , for details see @xcite .",
    "the model described in section  [ sec : model ] was fitted using the mcmc split sampler , with 30000 iterations , discarding a burn - in of 10000 .",
    "runtime on a modern desktop ( ivy bridge intel core i7 - 3770k , 16 gb ram and solid state hard drive ) , was approximately one hour .",
    "all the calculations were done using ` r ` .",
    "figure [ fig : priorvspost_regression ] shows prior densities ( in orange ) together with posterior densities ( light blue ) for the regression coefficients @xmath120 and @xmath121 .",
    "the posteriors look close to being normally distributed .",
    "we see that the intercepts ( figures [ fig : beta0 ] and [ fig : alpha0 ] ) are well identified , with modes close to @xmath122 and @xmath123 , respectively , even though they have a vague prior .",
    "this is as expected , since the intercepts correspond to an overall , `` average '' level which should be relatively easy to infer .",
    "the posteriors for the regression coefficients @xmath68 and @xmath124 , corresponding to log catchment area , ( figures [ fig : beta1 ] and [ fig : alpha1 ] ) , look similar , though the posterior for @xmath124 ( in the model for log scale ) is slightly wider .",
    "both have a mode of around 0.75 , and most of the posterior mass in the region between 0.5 and 1 .",
    "posteriors for @xmath75 and @xmath125 , corresponding to maximum daily precipitation ( figures [ fig : beta2 ] and [ fig : alpha2 ] ) are wider than those for @xmath68 and @xmath124 , with most of the mass in the region between 0.4 and 1.5 .",
    "the posterior mode of @xmath75 is around 0.9 , while the posterior mode of @xmath125 is close to 1.0 .",
    "figure  [ fig : priorvspost_hyper ] shows prior and posterior densities for all eight hyperparameters of the model .",
    "we see that the hyperparameters for the random effects standard deviations @xmath126 and @xmath127 ( @xmath128 ) are all shrunk somewhat towards zero .",
    "however , the posterior mode is larger than zero for all hyperparameters , particularly for @xmath108 , where there is very little mass close to zero . for the standard deviations @xmath129 and @xmath107 most of the posterior mass is between 0 and 0.1 , while @xmath105 and @xmath93 ( corresponding to the random intercepts ) have most of their posterior mass between 0 and 0.5 .",
    "posteriors for @xmath92 and @xmath115 ( the two residual noise standard deviations of the model ) are well identified , even though they were given an very weakly informative prior .",
    "the posterior modes of @xmath92 and @xmath115 are close to 0.5 .",
    "figure [ fig : seasonal ] shows the seasonal effects , together with 80% pointwise credible intervals .",
    "it seems like there is some evidence for a seasonal effect for @xmath130 ( the intercept of the location model ) , and @xmath131 and @xmath132 ( corresponding to catchment area ) , while this is not so clear for the other parameters .",
    "this is consistent with what was seen in figure  [ fig : priorvspost_hyper ] , particularly when comparing the posterior for @xmath108 with the corresponding seasonal effect for @xmath132 .",
    "[ fig : sigmatau ]    the left panels of figure [ fig : cdfqq ] show empirical cumulative distribution functions ( cdfs ) together with cdfs predicted from the model , for three randomly chosen river / month - combinations .",
    "the right panels show corresponding pp plots , i.e.  the empirical cdf is plotted against the cdf predicted from the model for each river and each month .",
    "uncertainty bands correspond to pointwise 95% credible intervals .",
    "the model seems to fit the data reasonably well .",
    "finally , we performed a cross - validation study , by leaving each river out in turn , estimating the full model based on the remaining seven rivers , and predicting for the left - out river .",
    "figures  [ fig : leaveout1 ] and [ fig : leaveout2 ] show the results for all eight rivers . since the aim is to predict extremes , we do not consider prediction of the lower quantiles , but focus on the median and the 90th percentile",
    ". the limited number of data points ( around 50 ) for each river - month combination would make estimation of higher sample quantiles such as 0.95 or 0.99 too noisy .",
    "the model seems to predict reasonably well overall , particularly when taking into account that the model was fitted based on only seven river catchments , and that these are a purely out - of - sample predictions based on sparse data .",
    "the worst prediction is for river vhm19 , which is the smaller river catchment in our data set , and is also somewhat untypical , with smallest discharge levels overall .",
    "it is therefore perhaps not surprising that prediction fails somewhat here .",
    "for all the other rivers , however , the predicitive accuracy is in our view about as good as can be expected .",
    "we have proposed a bayesian hierarchical model for monthly maxima of instantaneous flow .",
    "since the number of sites is often small ( as in the data used here ) , the ability to borrow strength between months is very important . rather than performing twelve ( one for each month )",
    "independent linear regressions at the latent level , we fitted a linear mixed model using information jointly from all months and all sites .",
    "the use of penalised complexity priors was helpful , giving a good balance between prior information and sparse data .",
    "a thorough account of the prior elicitation for both regression coefficients and hyperparameters was given .",
    "we argue that the use of pc priors make hyperprior elicitation easier : the principle of user - defined scaling gives a useful framework for thinking about priors for hyperparameters in complex models .",
    "based on a preliminary analysis , it was shown that the gumbel distribution fits the data well in most cases .",
    "however , the generalised extreme value distribution is often selected as a model for block extrema , due to its theoretic basis and it containing the gumbel distribution as a special case . future research on models for monthly maxima of instantaneous flow should involve assuming the generalised extreme value distribution at the data level .",
    "assuming the same shape parameter across months would be a sensible starting point .",
    "if that is not sufficient , then assuming that each month has its own shape parameter would be a sensible extension .",
    "a crucial aspect of the proposed model is its capacity to predict monthly maxima of instantaneous flow at ungauged sites , provided that catchment covariates are available .",
    "the model could also be used to predict annual maxima of instantaneous flow at ungauged sites .",
    "the bayesian approach allows for taking parameter uncertainty into account , while also helping to reduce uncertainty by using the regularising priors that are selected here .",
    "the result is reasonably good predictions compared to observed data .",
    "we thank hvard rue , andrea riebler , daniel simpson and philippe crochet for many helpful comments and suggestions .",
    "the data was provided by the icelandic meteorological office .",
    "the study was partly funded by the university of iceland research fund .",
    "philippe crochet . estimating the flood frequency distribution for ungauged catchments using an index flood procedure .",
    "application to ten catchments in northern iceland . technical report ,",
    "icelandic meteorological office , 2012 .",
    "philippe crochet , tmas jhannesson , trausti jnsson , oddur sigursson , helgi bjrnsson , finnur plsson , and idar barstad . estimating the spatial distribution of precipitation in iceland using a linear model of orographic precipitation .",
    "_ journal of hydrometeorology _ , 80 ( 6):0 12851306 , 2007 .",
    "finn lindgren , hvard rue , and johan lindstrm .",
    "an explicit link between gaussian fields and gaussian markov random fields : the stochastic partial differential equation approach .",
    "_ journal of the royal statistical society : series b ( statistical methodology ) _ , 730 ( 4):0 423498 , 2011 .        hvard rue , sara martino , and nicolas chopin .",
    "approximate bayesian inference for latent gaussian models by using integrated nested laplace approximations . _ journal of the royal statistical society : series b ( statistical methodology ) _ , 710 ( 2):0 319392 , 2009",
    ".    daniel  p simpson , thiago  g martins , andrea riebler , geir - arne fuglstad , hvard rue , and sigrunn  h srbye .",
    "penalising model component complexity : a principled , practical approach to constructing priors .",
    "_ arxiv preprint arxiv:1403.4630 _ , 2014 ."
  ],
  "abstract_text": [
    "<S> we propose a comprehensive bayesian hierarchical model for monthly maxima of instantaneous flow in river catchments . </S>",
    "<S> the gumbel distribution is used as the probabilistic model for the observations , which are assumed to come from several catchments . </S>",
    "<S> our suggested latent model is gaussian and designed for monthly maxima , making better use of the data than the standard approach using annual maxima . at the latent level , </S>",
    "<S> linear mixed models are used for both the location and scale parameters of the gumbel distribution , accounting for seasonal dependence and covariates from the catchments . </S>",
    "<S> the specification of prior distributions makes use of penalised complexity ( pc ) priors , to ensure robust inference for the latent parameters . </S>",
    "<S> the main idea behind the pc priors is to shrink toward a base model , thus avoiding overfitting . </S>",
    "<S> pc priors also provide a convenient framework for prior elicitation based on simple notions of scale . </S>",
    "<S> prior distributions for regression coefficients are also elicited based on hydrological and meteorological knowledge . </S>",
    "<S> posterior inference was done using the mcmc split sampler , an efficient gibbs blocking scheme tailored to latent gaussian models . </S>",
    "<S> the proposed model was applied to observed data from eight river catchments in iceland . </S>",
    "<S> a cross - validation study demonstrates good predictive performance .    </S>",
    "<S> # 1    0    0    1    0    * a bayesian hierarchical model for monthly maxima of instantaneous flow *    _ keywords : _ latent gaussian models , extreme values , hydrology , penalised complexity priors </S>"
  ]
}