{
  "article_text": [
    "we study the interplay between markov chains on a high - dimensional data set @xmath12 and the inner workings of spectral methods .",
    "there are many different methods , see e.g. the work of belkin & niyogi @xcite , coifman & lafon @xcite , coifman & maggioni @xcite , donoho & grimes @xcite , roweis & saul @xcite and tenenbaum , de silva & langford @xcite .",
    "we propose a natural operation on the data which will enhance the effectivity of these methods .",
    "usually , these techniques proceed by imposing a markov chain on the data set and analyzing diffusion on the arising graph .",
    "a popular and natural choice for the markov chain is to declare that the probability @xmath13 to move from point @xmath2 to @xmath3 is @xmath14 where the value of @xmath15 needs to be chosen depending on the given data as it induces a natural length scale @xmath16 which should match the distance between neighbouring points .",
    "if the number of random jumps tends to infinity , the probability of being in a particular point is uniformly distributed and contains no more information on the geometry : the stationary solution @xmath17    it is not difficult to see that the initial states converging to the stationary state as slowly as possible are of particular intrinsic interest because they are exploiting geometric bottlenecks in the data to avoid rapid mixing . starting from the seminal work of cheeger @xcite",
    ", it is now understood that the first ( nontrivial ) eigenfunction of the laplacian will change its sign at a region of geometrical significance ( see figure 1 ) .",
    "given @xmath18 eigenfunctions on the graph , we may use them to construct the embedding @xmath19    at this level of generality , it is not possible to make any qualitative statements about the quality of the embedding depending on the data set and @xmath18 .",
    "however , it has been shown that in practice already a very small number of eigenfunction is able to reliably extract relevant geometric features from the data set .",
    "we are assuming that the point set @xmath20 comes from a ( possibly very low - dimensional ) manifold embedded in @xmath21 .",
    "the following example is representative : assume we are given a point @xmath22 embedded in a point cloud given in figure 2 .",
    "( 0,1 ) circle [ radius=0.03 ] ; ( 1,0 ) circle [ radius=0.03 ] ; ( 1,1 ) circle [ radius=0.03 ] ; ( 1,2 ) circle [ radius=0.03 ] ;    ( -1,1 ) circle [ radius=0.03 ] ; ( 0,1 ) (-1 , 1 ) ;    ( 0,1 ) (1 , 0 ) ; ( 0,1 ) (1 , 1 ) ; ( 0,1 ) (1 , 2 ) ; ( 1,1 ) (1 , 2 ) ; ( 1,1 ) (1 , 0 ) ; ( 1,1 ) (1 , 0 ) ; at ( -0.3,0.7 ) @xmath22 ; ( 1,2 ) to[out=325,in=35 ] ( 1,0 ) ; at ( -1.3,0.7 ) @xmath23 ;    at ( 1.1,2.1 ) @xmath24 ; at ( 1.03,1 ) @xmath25 ; at ( 1.1,-0.1 ) @xmath26 ;    given such a local structure , one would certainly assume that @xmath27 belong to points on the manifold , which are close to each other ; @xmath23 is close to @xmath22 but not close to any of the other points .",
    "it seems that , whatever the hidden manifold @xmath28 may be , the guess @xmath29 is much more reasonable than @xmath30 .",
    "as it turns out , there is a very simple trick that allows to detect such structures .",
    "consider the probability of being in one of the five points after 1 and 2 steps of a random walk starting in @xmath22 .",
    "[ cols=\"<,^,^,^,^ , > \" , ]     the minimum can be interpreted as a measure of how easy it is to reach a certain point in _ both _ one and two steps starting from @xmath22",
    ". if an adjacent point is relatively easy to reach in one step but impossible or very difficult to reach in two , then that point may be as close or even closer to @xmath22 as other points but it will not be close to those other points .",
    "it should be emphasized that for this reasoning to be valid we need to ensure that    * the random walk is not lazy : it must not be possible to remain at a position and * that the random walk is interconnected enough .    for markov chains created using the isotropic kernels with a gaussian weight ,",
    "the second condition is always satisfied and the first one can be readily satisfied by setting @xmath6 for all @xmath31 ( and rescaling the other elements in the column ) .      formally , our algorithm may be described as follows .",
    "assume we are given @xmath12 and an associated markov chain described by the matrix @xmath32 .",
    "the matrix @xmath33 will be created as follows : we obtain the matrix @xmath7 by setting @xmath6 and rescaling every column of @xmath5 so that to we are once again given a transition matrix .",
    "@xmath33 is then given by @xmath34 we may then proceed with an analysis of the data set using @xmath33 instead of @xmath5 .",
    "it seems that @xmath35 is most effective in practice but there are certainly cases where a larger @xmath18 may prove advantageous .",
    "the method provides a tool to identify erroneous edges in graph structures satisfying the natural analogue of a manifold assumption for the point cloud : no point has too many neighbours and neighbours of neighbours of neighbours tend to be neighbours or at least close .",
    "it needs to be emphasized that the method relies strongly on the structure / kernel used in spectral embedding . in the ( unweighted ) example below , the method would remove the dashed line , which may or may not be reasonable  for the relevant applications we have in mind , the method will always start from a _ complete , weighted _ graph and the method will assign new weights to the edges .",
    "( 0,1 ) circle [ radius=0.03 ] ; ( 1,0 ) circle [ radius=0.03 ] ; ( 1,1 ) circle [ radius=0.03 ] ; ( 1,2 ) circle [ radius=0.03 ] ;    ( -1,1 ) circle [ radius=0.03 ] ; ( -2,2 ) circle [ radius=0.03 ] ; ( -2,0 ) circle [ radius=0.03 ] ; ( -2 , 0 )  ( -2,2 )  ( -1,1 )  ( -2,0 ) ; ( 0,1 ) (-1 , 1 ) ;    ( 0,1 ) (1 , 0 ) ; ( 0,1 ) (1 , 1 ) ; ( 0,1 ) (1 , 2 ) ; ( 1,1 ) (1 , 2 ) ; ( 1,1 ) (1 , 0 ) ; ( 1,1 ) (1 , 0 ) ;    ( 1,2 ) to[out=325,in=35 ] ( 1,0 ) ;      there is a lot of work on the fundamental problem of analyzing graphs with respect to erroneous edges ( see e.g. @xcite ) .",
    "we emphasize that our approach should not been seen from that perspective because it crucially relies on the particular structure arising from the analysis of point clouds in @xmath36 by means of a nonvanishing kernel .",
    "it will , without further adaptation , not be useful in the more general graph setting : for example , it is easy to see that on the lattice @xmath37 with the natural edge relation @xmath38 the method will remove all edges",
    ". however , it is certainly conceivable that there are natural ways ( for instance weighting the edges proportional to @xmath39 ) , the method might also be useful in that context .",
    "as for the special problem of spectral embeddings , there is paper of david & averbuch @xcite whose approach is very different from ours .      the purpose of this section is a simple argument quantifying the ability of our method to detect and correct errors ",
    "an explicit example is given in the next section .",
    "the model is as follows : let @xmath40 be an unweighted graph on @xmath41 vertices such that for every @xmath42 the number of points at distance @xmath43 from @xmath44 is at most @xmath45 .",
    "let @xmath46 be the transition matrix of the ( non - lazy ) random walk on @xmath47 .",
    "now we create a random perturbation @xmath48 of @xmath46 by randomly adding edges .",
    "let @xmath49 be a fixed parameter and create @xmath48 by additionally connecting every pair of vertices @xmath50 with probability @xmath51 and taking @xmath48 to be the transition matrix of the non - lazy random walk on the enlarged graph .",
    "let @xmath33 be the modified markov chain obtained from @xmath48 using our method with @xmath35 .",
    "we note that @xmath33 may separate connections which have not been randomly added ( see the example of the lattice ) , however , it is certainly very successful at removing those that have been added .",
    "when using a gaussian kernel on point clouds in applications , the triangle inequality will already guarantee that such structures can not arise and one can expect @xmath33 to rarely mistake an edge for an error .",
    "+ our main statement gives an upper bound on the expected number of random edges that have been added and are not being removed by @xmath33 .",
    "setting @xmath52 for @xmath15 small , it implies that up to @xmath53 random edges will be completely filtered out with high likelihood @xmath54 .",
    "current techniques @xcite for the generalized problem on graphs seem to be effective up to the same order ( i.e. work for a number of randomly added edges that is linear in the number of vertices ) .    the number @xmath55 of vertices @xmath56",
    "with @xmath57 satisfies @xmath58    we start by analyzing the implications of @xmath59 let us abbreviate @xmath60 and @xmath61 .",
    "@xmath62 implies that @xmath63 and @xmath64 are not connected by an edge .",
    "@xmath65 implies that in @xmath48 there is both an edge between @xmath63 and @xmath64 as well as an edge @xmath66 with @xmath67 and @xmath68 .",
    "the edge @xmath69 must be a randomly added edge but the status of the edges @xmath67 and @xmath68 can not be deduced .",
    "we proceed with a case distinction depending on which edges have been there originally",
    ". +    ( 0,0 ) circle [ radius=0.03 ] ; ( 1,0 ) circle [ radius=0.03 ] ; ( 0.5,0.866 ) circle [ radius=0.03 ] ; at ( 0.5,-0.2 ) case 1 ; at ( 1.1,0 ) @xmath64 ; at ( -0.1,0 ) @xmath63 ; at ( 1/2,0.87 ) @xmath66 ; ( 0,0 )  ( 1,0 )  ( 0.5 , 0.866 )  ( 0,0 ) ;    ( 0,0 ) circle [ radius=0.03 ] ; ( 1,0 ) circle [ radius=0.03 ] ; ( 0.5,0.866 ) circle [ radius=0.03 ] ; at ( 0.5,-0.2 ) case 2 ; at ( 1.1,0 ) @xmath64 ; at ( -0.1,0 ) @xmath63 ; at ( 1/2,0.87 ) @xmath66 ; ( 0,0 )  ( 1,0 ) ; ( 1,0 )  ( 0.5 , 0.866 )  ( 0,0 ) ;    ( 0,0 ) circle [ radius=0.03 ] ; ( 1,0 ) circle [ radius=0.03 ] ; ( 0.5,0.866 ) circle [ radius=0.03 ] ; at ( 1.1,0 ) @xmath64 ; at ( -0.1,0 ) @xmath63 ; at ( 1/2,0.87 ) @xmath66 ; ( 0,0 )  ( 1,0 )  ( 0.5 , 0.866 ) ; ( 0.5 , 0.866 )  ( 0,0 ) ; at ( 1.75,-0.2 ) case 3 ; ( 2.5,0 ) circle [ radius=0.03 ] ; ( 3.5,0 ) circle [ radius=0.03 ] ; ( 3,0.866 ) circle [ radius=0.03 ] ; at ( 3.6,0 ) @xmath64 ; at ( 2.5 - 0.1,0 ) @xmath63 ; at ( 2.5 + 1/2,0.87 ) @xmath66 ; ( 3 , 0.866 )  ( 2.5,0 )  ( 3.5 , 0 ) ; ( 3.5,0 )  ( 3 , 0.866 ) ;    _ case 1 . _",
    "all three edges @xmath69 , @xmath67 and @xmath68 have been added by the random process . in this case adding the random edges has given rise to a triangle .",
    "it is easily seen by linearity of expectation that the expected number of triangles is given by @xmath70 and every rectangle accounts for three pairs of @xmath71 which will not be filtered out .",
    "+ _ case 2 . _",
    "the edge @xmath69 has been added but @xmath67 and @xmath68 did already exist .",
    "this implies that @xmath64 is at distance 2 from @xmath63 .",
    "the number of random connections emanating from @xmath63 is given by a binomial distribution with distribution @xmath72 and @xmath73 is the degree of @xmath63 in the original graph . for every such new edge",
    "the probability of connecting to one of the less than @xmath74 vertices at distance at most 2 from @xmath63 is at most @xmath75 and thus assuming the worst case @xmath76 and using the reproducing property of the binomial distribution , we are able to simpify the arising expression @xmath77 this computation is for a fixed vertex @xmath63 , using the linearity of expectation bounds the number of errors introduced through case 2 by @xmath78    _ case 3 . _",
    "the edge @xmath69 and one of the two edges @xmath67 or @xmath68 has been added while the other one did already exist .",
    "we change our point of view .",
    "fixing a vertex @xmath66 , what can be said about the probability that there is another vertex @xmath63 such that both edges @xmath79 and @xmath69 have been added for some @xmath64 at distance 1 from @xmath63 ?    ( 0,1 ) circle [ radius=0.03 ] ; ( 1,0 ) circle [ radius=0.03 ] ; ( 1,0.5 ) circle [ radius=0.03 ] ; ( 1,1 ) circle [ radius=0.03 ] ; ( 1,1.5 ) circle [ radius=0.03 ] ; ( 1,2 ) circle [ radius=0.03 ] ;    ( 0,1 ) (1 , 0 ) ; ( 0,1 ) (1 , 0.5 ) ; ( 0,1 ) (1 , 1 ) ; ( 0,1 ) (1 , 1.5 ) ; ( 0,1 ) (1 , 2 ) ;    ( 2,2.3 ) (1 , 2 ) ; ( 2,2.1 ) (1 , 2 ) ; ( 2,1.9 ) (1 , 2 ) ;    ( 2,1.8 ) (1 , 1.5 ) ; ( 2,1.6 ) (1 , 1.5 ) ; ( 2,1.4 ) (1 , 1.5 ) ;    ( 2,1.2 ) (1 , 1 ) ; ( 2,1 ) (1 , 1 ) ; ( 2,0.8 ) (1 , 1 ) ;    ( 2,0.6 ) (1 , 0.5 ) ; ( 2,0.4 ) (1 , 0.5 ) ; ( 2,0.2 ) (1 , 0.5 ) ;    ( 2,0.1 ) (1 , 0 ) ; ( 2,-0.1 ) (1 , 0 ) ; ( 2,-0.3 ) (1 , 0 ) ;    at ( 0,1 ) @xmath63 ; ( 2,1 ) ellipse ( 0.5 cm and 1.5 cm ) ; ( 2.2 , 1 )  ( 3,0.5 ) ; at ( 3,0.5 ) any of these vertices close to @xmath63 ? ;    let now @xmath66 be fixed and assume that the randomly added edges adjacent to @xmath44 are @xmath80 have been added .",
    "note that again @xmath81 let us fix @xmath82 .",
    "we are then interested in the probability that another randomly added edge is connecting @xmath83 and one of the @xmath74 points at distance at most 2 from @xmath66 .",
    "the number of added eges adjacent to @xmath83 is again @xmath84 using again the reproducing property of the binomial distribution as above , we are able to simpify the arising expression @xmath77 this describes the distribution of numbers of tuples @xmath85 , where @xmath64 is at distance at most 2 from @xmath63 .",
    "however , we are not limited to constructing such a path over @xmath83 since we have many @xmath86 at our disposal .",
    "indeed , there are @xmath66 possible vertices , which implies that the total number of edges @xmath87 , where @xmath64 is at distance at most 2 from @xmath66 is distributed like a random sum of random variables @xmath88 a basic result due to wald @xcite is as follows : given a random number @xmath55 of i.i.d .",
    "variables @xmath89 , their sum @xmath90 satisfies @xmath91 in particular , this immediately implies that @xmath92 summing over all @xmath93 vertices gives the result .",
    "we study a series of classification problems .",
    "since we are interested in the effectiveness of the method and not in the effectiveness of various spectral methods , we will fix one of the simplest spectral methods by defining the quadratic form to be @xmath94 where @xmath95 will be either @xmath13 or @xmath10 . the markov chain @xmath5",
    "will be created using the classical isotropic gaussian kernel with a parameter @xmath15 ( the precise value will be explicitely noted in each application ) @xmath96 the matrix @xmath33 will be created as above ( with @xmath35 for classification examples and @xmath97 for error correction ) . as for the embedding , we will always chose the simplest possible one into two - dimensional space @xmath98 where @xmath99 are the first two eigenfunctions .",
    "each classification problems will be given as a point cloud @xmath100 and we shall assume that each coordinate has equal importance : this is done by dividing every coordinate by the standard deviation of that coordinate among all @xmath93 points .",
    "we emphasize that we are not at all interested in obtaining competitive result  we study the effect of the method ( better results could , for example , be immediately obtained by considering more than two eigenfunctions for an embedding ) .",
    "all data sets have been taken from the uci machine learning depository .",
    "the challenge is to automatically detect the origin of 178 wines ( each of which is given by the quantities of 13 chemical constitutents ) grown by three different cultivars in the same region in italy .",
    "the classical approach ( using @xmath101 ) is very successful at this task , the preconditioning matrix has little effect .",
    "it should be noted that the preconditioner successfully contracts the red and the green region ( which is yet again accomplished by regularizing the diffusion distance within those regions ) .          one is given 303 data samples , each of which gives 13 attributes ( age , cholesterol ,  ) .",
    "the task is to classify the existence or absence of heart disease .",
    "the classical embedding ( using @xmath101 ) manages some separation , the matrix @xmath33 decreases the diffusion distance within the subset of healthy patients ( green ) which allows for a more uniform embedding .",
    "the error rate ( using a half space as classifier in both cases ) is unaffected .",
    "the data set contains 569 elements , each of which quantifies 10 aspects of a tumor  the task is to identify a tumor as benign or malign .",
    "this is a data set where the classical embedding already works very well ( @xmath102 ) : using a half space as classifier , the error rate is a mere 5.9% and the picture shows a clear separation into two cluster .",
    "the preconditioner achieves a slightly cleaner separation and reduces to error ( being again allowed one half space as a classifier ) to 4.2% .",
    "this is another standard binary classification task .",
    "an array of antennas is trying to find structure in the ionosphere and there are 34 possible settings ; those settings , which are able to detect structure are good whereas other settings are bad. the dataset is comprised of 351 elements .",
    "we observe again the same behavior as above ; the unmodified embedding has a smooth transition between the two points : the method ( here with @xmath97 ) manages to contract the sets of good and bad points , respectively , and increase their distance .",
    "note that the method manages to contract almost all red outliers !",
    "the pictures shown use the canonical 3d embedding @xmath103          finally , we consider the method with respect to correcting random errors .",
    "consider the set of points in the shape of a circle @xmath104 spectral methods perform very well and are able to reproduce the underlying shape .",
    "we assume that @xmath105 and randomize the adjacency matrix by picking @xmath18 random edges and defining the weight of that edge to be 1 .",
    "+ the following example show the same randomly perturbed set as embedded by @xmath5 and @xmath33 ( with @xmath97 ) .",
    "@xmath33 is able to maintain the topological structure rather well .",
    "we remark that our method is not the unique one with that property ; the theorem about error correcting also holds , for example , for the pointwise product @xmath106 it is certainly conceivable that another implementation of the underlying idea of exploiting local topology could yield even better results and we consider this to be a very interesting problem . + * acknowledgement . *",
    "the author is indebted to raphy coifman for extensive discussions .",
    "d. liben - nowell and j. kleinberg .",
    "the link prediction problem for social networks .",
    "proceedings of the twelfth international conference on information and knowledge management , cikm 03 , page 556 - 559 , new york , ny , usa , 2003 ."
  ],
  "abstract_text": [
    "<S> spectral methods have proven to be a highly effective tool in understanding the intrinsic geometry of a high - dimensional data set @xmath0 . </S>",
    "<S> the key ingredient is the construction of a markov chain on the set , where transition probabilities depend on the distance between elements , for example where for every @xmath1 the probability of going from @xmath2 to @xmath3 is proportional to @xmath4 we propose a method which increases the self - consistency of such markov chains before spectral methods are applied . instead of directly using a markov transition matrix @xmath5 , </S>",
    "<S> we set @xmath6 and rescale , thereby obtaining a transition matrix @xmath7 modeling a non - lazy random walk . </S>",
    "<S> we then create a new transition matrix @xmath8 by demanding that for fixed @xmath9 the quantity @xmath10 be proportional to @xmath11 we consider several classical data sets , show that this simple method can increase the efficiency of spectral methods and prove that it can correct randomly introduced errors in the kernel . </S>"
  ]
}