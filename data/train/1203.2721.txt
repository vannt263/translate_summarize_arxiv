{
  "article_text": [
    "in a @xmath5-user multiple - access channel ( mac ) , each user regards the signals of other users as interference .",
    "when the number of users @xmath5 is large , each user has a very low signal - to - interference - and - noise ratio ( sinr ) @xcite .",
    "for this reason , spreading is usually employed as an sinr amplifier for each user , such as the conventional code - division multiple - access ( cdma ) @xcite and interleave - division multiple - access ( idma ) systems @xcite .    in the cdma and idma systems ,",
    "each information bit is spread _",
    "independently_. specifically , in the cdma system each information bit is spread by multiplying a binary vector into a length-@xmath2 bit - vector , which is then interleaved by a bit - level interleaver .",
    "since each information bit has @xmath2 independent receiving observations , the despreading ( des ) will output an ameliorated signal with a sufficient large sinr for a further outer decoding ( if there is a channel code as an outer code ) . in the idma system , a chip - level interleaving is jointly performed on multiple bit - vectors instead of the bit - level interleaving in the cdma system @xcite . as the number of bit - vectors for interleaving is large",
    ", the idma in fact becomes a multi - user sparse - graph code that is appropriate for iterative decoding @xcite .",
    "for this reason , the idma under an iterative chip - by - chip decoding provides a lower bit error rate ( ber ) than the conventional cdma @xcite@xcite .",
    "simulations in @xcite showed that at the low ber region , the ber of the uncoded idma system can converge to that of single - user transmission with bpsk modulation .",
    "the ber of single - user transmission with bpsk modulation is the performance upper bound for both of the cdma and idma systems , since in both systems the independent spreading of each information bit implies that each user employs a repetition code .    in this paper",
    ", we propose a finite field spreading scheme for a synchronous mac with gaussian noise and equal - power users . for each user , every @xmath0 information bits are spread _ jointly _ into a length-@xmath1 vector by @xmath2 multiplications on gf(@xmath3 ) .",
    "a chip - level interleaving is then performed to generate the transmitted vector to the mac . at the receiver",
    ", a multi - user iterative decoding is performed on a single factor graph to recover the information vector of each user . in our scheme , due to the joint spreading ,",
    "each information bit is dispersed into @xmath1 transmitted symbols , and the finite field despreading ( ff - des ) of each bit can take advantage of @xmath1 independent receiving observations . to show the performance gain of joint spreading quantitatively",
    ", we analyze the extrinsic information transfer ( exit ) function of the ff - des .",
    "we show that the asymptotic slope of this exit function increases as @xmath0 increases and is in fact the absolute slope of the ber curve at the low ber region .",
    "this means that by increasing the length @xmath0 of information bits for joint spreading , a larger absolute slope of the ber curve is achieved . for @xmath4 , the ber curve of the finite field spreading",
    "has a larger absolute slope than that of the single - user transmission with bpsk modulation .    -user finite field spreading multiple - access system.,width=3 ]",
    "figure  [ fig : transmitter ] illustrates a block diagram of the transmitter of @xmath5-user finite field spreading multiple - access system .",
    "the length-@xmath6 information vector @xmath7 , of user @xmath8 is first mapped into a length-@xmath9 vector @xmath10 over gf(@xmath3 ) , i.e. , every @xmath0 information bits are mapped into a field element by mapping @xmath11 . here",
    "gf@xmath12 is a finite field with a primitive element @xmath13 , and @xmath14 can be an arbitrary bijection from @xmath15 to gf(@xmath3 ) .",
    "each element @xmath16 , in @xmath17 is spread by length-@xmath2 spreading vector @xmath18 over gf(@xmath3 ) into @xmath19 , where the multiplication is on gf(@xmath3 ) . here",
    "@xmath18 can be an arbitrary vector over gf(@xmath3 ) with @xmath20 .",
    "the output field vector after multiplication , denoted as @xmath21 , is demapped into binary vector @xmath22 , i.e. , each field element is demapped into @xmath0 bits by demapping @xmath23 , where @xmath24 is the inverse transform of @xmath14 .",
    "vector @xmath25 , referred to as chip vector , is interleaved by a length-@xmath26 chip - level interleaver @xmath27 and is multiplied by amplitude @xmath28 to generate the transmitted vector @xmath29 , to the gaussian mac . here",
    "@xmath30 is the energy per information bit , and @xmath31 is the symbol energy per transmission due to code rate @xmath32 of each user .",
    "the chip - level interleaving should be different for each user as in the idma system @xcite .",
    "the receiver receives a superimposed signal vector @xmath33 with @xmath34 where @xmath35 is a zero - mean gaussian variable with one - side power spectral density @xmath36 . here",
    ", we assume that the symbols from the @xmath5 users are synchronous .",
    "an iterative multi - user decoding is performed to recover information vectors @xmath37 .    to simplify the description , the mapping , multiplication of spreading vector , and demapping in the dotted box in fig .",
    "[ fig : transmitter ] is referred to as finite field spreading .",
    "it should be noted that by the finite field spreading over gf@xmath38 , the spreading of @xmath0 information bits is performed jointly , and each information bit is dispersed into @xmath1 transmitted symbols .",
    "thus , the ff - des of each information bit can take advantage of @xmath1 independent receiving observations .",
    "conventional spreading schemes , such as the cdma and idma where the information bit is spread independently , are special cases of the finite field spreading with @xmath39 .",
    "due to the chip - level interleaving , as length @xmath9 is large , the @xmath5-user finite field spreading multiple - access can be regarded as a @xmath5-user sparse - graph code which can be decoded iteratively on a single factor graph . in this section",
    ", we give an iterative decoding algorithm of the finite field spreading multiple - access on a single factor graph . in section  [ sec : factor ] , we represent the @xmath5-user finite field spreading and the mac by a single factor graph . in section  [ sec : iterative ] , we give the iterative decoding algorithm .",
    ".,width=3 ]    since each user has the same encoding process , the factor graph of each user is the same .",
    "we only illustrate the factor graph of user @xmath8 in fig .",
    "[ fig : factorfinite ] .",
    "there are three kinds of nodes in the graph : variable , mapping , and sum nodes .",
    "let @xmath40 , and @xmath41 be five node sets that include the nodes below letters  @xmath42 , \"  @xmath43 , \"  @xmath44 , \"  @xmath45 , \" and  @xmath41 \" in fig .",
    "[ fig : factorfinite ]",
    ". the variable node in @xmath42 corresponds to an information bit .",
    "the variable node in @xmath44 corresponds to a symbol in gf(@xmath3 ) .",
    "the mapping node in @xmath43 or @xmath45 denotes a mapping relation between a gf(@xmath3 ) symbol and @xmath0 bits .",
    "the sum node in @xmath41 , associated with a received symbol , denotes a superposition of the transmitted symbols from @xmath5 users .",
    "note that the sum node connects the remaining @xmath46 user s factor graphs .",
    "edges connecting variable nodes in @xmath44 and mapping nodes in @xmath45 are labeled by elements of spreading vector @xmath18 . during encoding and decoding",
    ", the message should multiply the labeled element or its inverse when passing across one of these edges .",
    "the iterative decoding is performed on the factor graph in fig .",
    "[ fig : factorfinite ] and is accomplished by efficient local decoding at all the nodes and interactions . the input and output of local decoding at each node",
    "is denoted by a log - likelihood ratio ( llr ) . since the decoding of each user is performed in parallel and is the same , we only give decoding algorithm for user @xmath8 .",
    "a single decoding iteration includes the local decoding at the sum node in @xmath41 , deinterleaving , and the ff - des in fig .",
    "[ fig : factorfinite ] . for the local decoding at the sum node in @xmath41",
    ", we employ the low - complexity elementary signal estimation ( ese ) algorithm given in @xcite .",
    "for the ff - des , we give a maximum a posteriori probability ( map ) decoding algorithm .",
    "after a number of iterations , a hard decision is performed to recover the information vector .",
    "let @xmath47 , denote a priori llr of @xmath48 in ( [ eq : receive ] ) to the @xmath49-th , @xmath50 , sum node in @xmath41 . by regarding @xmath51 as a gaussian variable",
    ", this sum node performs a local decoding and outputs an extrinsic llr of @xmath52 as @xcite @xmath53 which will be deinterleaved as a priori llr for the ff - des .",
    "after deinterleaving , we obtain a priori llr @xmath54 , for each chip of user @xmath8 .",
    "the ff - des will calculate an extrinsic llr @xmath55 based on the priori llrs @xmath56 , by the local decoding at the nodes in @xmath57 , subsequently .    since the decoding operation for each chip is the same , to simplify our description , we only introduce the calculation of extrinsic llr @xmath58 , performed on the subgraph associated with the first variable node in @xmath44 of fig .",
    "[ fig : factorfinite ] .",
    "let @xmath59 denote the @xmath0 chip - llr inputs to the @xmath60-th , @xmath61 , mapping node in @xmath45 and @xmath62 denote the associated received symbols ( @xmath63 is the deinterleaved form of @xmath64 ) .",
    "this mapping node performs a local decoding to transform chip llrs to field symbol llr vector @xmath65 of @xmath66 as @xmath67 where @xmath68 takes the @xmath69-th bit of the demapped vector @xmath70 .",
    "here we use a posteriori probability of zero element 0 as the denominator in a field symbol llr .",
    "let @xmath71 denote the joint vector of @xmath72 .",
    "similarly , we have denotation @xmath73 .",
    "based on the @xmath74 field symbol llr vectors @xmath75 , the first variable node in @xmath44 performs a local decoding to calculate the extrinsic llr vector @xmath76 @xmath77 of @xmath78 as @xmath79 where @xmath80 is a length-@xmath81 zero vector and @xmath82 is the inverse of @xmath83 in gf(@xmath3 ) .",
    "the @xmath84-th , @xmath85 , mapping node in @xmath45 transforms the extrinsic symbol llr vector @xmath86 to extrinsic chip llrs of @xmath87 as @xmath88 these extrinsic chip llrs will be interleaved to update the priori llrs of the sum node decoding in ( [ eq : ese ] ) .",
    "the hard decision is performed on the output from the mapping node in @xmath43 to the variable node in @xmath42 . using a similar principle as in ( [ eq : variable - node ] )",
    ", the first variable node in @xmath44 calculates a total posteriori llr vector @xmath89 of @xmath90 as @xmath91 the first mapping node in @xmath43 transforms this field symbol llr vector to @xmath0 bit llrs using a similar principle as in ( [ eq : symbol - bit ] ) @xmath92 for bit decision .",
    "note that the mapping node in @xmath43 does not provide any message to the variable node in @xmath44 during the iterative decoding .",
    "here we give a bit decision algorithm , in which the hard decision is performed on the llrs of information bits in ( [ eq : bitdecision ] ) .",
    "the hard decision can also be performed on the field symbol llr in ( [ eq : symboldecision ] ) to obtain an estimation of @xmath90 .",
    "to show the performance gain of joint spreading quantitatively , we analyze the exit function of the ff - des . in section  [ sec : appexit ] , we give an approximate exit function and show that this exit function asymptotically approaches a line . in section  [ sec :",
    "slope ] , we derive the asymptotic slope of the exit function .      the exit function describes a relation between the priori input and the extrinsic output of a decoding .",
    "both the input and the output of the decoding are measured by mutual information or llr mean value based on the gaussian approximation @xcite . in this section ,",
    "we give an approximate exit function of the ff - des using the measure of llr mean value .",
    "the exit function of ff - des describes the relation between the mean value of a priori chip llr and that of the extrinsic chip llr .",
    "generally , this exit function is determined by the realizations of a specific chip , mapping @xmath14 , and spreading vector @xmath18 . here",
    "we consider random chip , random mapping @xmath14 , and random spreading vector @xmath18 , all of which are uniformly generated from all their possible realizations .",
    "we derive an expected exit function that is an average for all the possible chip , mapping , and spreading vector realizations .    since as stated in section  [ sec",
    ": decoding ] , the decoding operation for each chip of each user is the same , we omit superscript @xmath93 to consider the chip @xmath94 , in our analysis .",
    "the exit function is the function between @xmath95 $ ] and @xmath96,i\\neq \\ell$ ] , @xmath97 , where @xmath98 $ ] takes the expectation of a random variable .    combining ( [ eq : bit - symbol ] ) , ( [ eq : variable - node ] ) , and ( [ eq : symbol - bit ] ) in the ff - des , we write @xmath99 as a function of @xmath100 , @xmath101 , @xmath102 where @xmath103 .    by the gaussian approximation @xcite@xcite , @xmath104 @xmath105 , i.i.d . , and @xmath106 , where @xmath107 denotes the gaussian distribution with mean @xmath108 and variance @xmath109 .",
    "based on ( [ eq : des ] ) , the exit function becomes @xmath110\\nonumber\\\\ \\",
    "\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ & & = e[c_{(\\ell-1)s+n}\\log\\frac{\\sum_{\\lambda\\in \\textrm{gf}(2^s)}(1\\!+\\!\\gamma_n^{-1}(\\lambda))e^{\\rho(\\lambda)}}{\\sum_{\\lambda\\in \\textrm{gf}(2^s)}(1\\!-\\!\\gamma_n^{-1}(\\lambda))e^{\\rho(\\lambda)}}]\\nonumber\\\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ & & = e[\\log\\frac{\\sum_{\\lambda\\in \\textrm{gf}(2^s)}(1\\!+c_{(\\ell-1)s+n}\\gamma_n^{-1}(\\lambda))e^{\\rho(\\lambda)}}{\\sum_{\\lambda\\in \\textrm{gf}(2^s)}(1\\!-c_{(\\ell-1)s+n}\\gamma_n^{-1}(\\lambda))e^{\\rho(\\lambda)}}]\\nonumber\\\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ & & = e[\\log\\frac{(1\\!+c_{(\\ell-1)s+n}\\gamma_n^{-1}(\\gamma_{\\ell}))e^{\\rho(\\gamma_\\ell)}+\\sum_{\\lambda\\in \\textrm{gf}(2^s),\\lambda\\neq\\gamma_{\\ell}}(1\\!+c_{(\\ell-1)s+n}\\gamma_n^{-1}(\\lambda))e^{\\rho(\\lambda)}}{(1\\!-c_{(\\ell-1)s+n}\\gamma_n^{-1}(\\gamma_{\\ell}))e^{\\rho(\\gamma_\\ell)}+\\sum_{\\lambda\\in \\textrm{gf}(2^s),\\lambda\\neq\\gamma_{\\ell}}(1\\!-c_{(\\ell-1)s+n}\\gamma_n^{-1}(\\lambda))e^{\\rho(\\lambda)}}]\\nonumber\\\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ & & = e[\\log\\frac{2e^{\\rho(\\gamma_\\ell)}\\!+\\!\\sum_{\\lambda\\in \\textrm{gf}(2^s),\\lambda\\neq\\gamma_{\\ell}}(1\\!+\\!c_{(\\ell-1)s+n}\\gamma_n^{-1}(\\lambda))e^{\\rho(\\lambda)}}{\\sum_{\\lambda\\in \\textrm{gf}(2^s),\\lambda\\neq\\gamma_{\\ell}}(1\\!-c_{(\\ell-1)s+n}\\gamma_n^{-1}(\\lambda))e^{\\rho(\\lambda)}}]\\label{eq : exit1}\\\\ \\ \\ \\ \\ \\ \\ \\ \\ & & = e[2\\rho(\\gamma_\\ell)]+e[\\log\\frac{1+\\frac{1}{2}\\sum_{\\lambda\\in \\textrm{gf}(2^s),\\lambda\\neq\\gamma_{\\ell}}(1\\!+\\!c_{(\\ell-1)s+n}\\gamma_n^{-1}(\\lambda))e^{\\rho(\\lambda)-\\rho(\\gamma_\\ell)}}{\\frac{1}{2}\\sum_{\\lambda\\in \\textrm{gf}(2^s),\\lambda\\neq\\gamma_{\\ell}}(1\\!-c_{(\\ell-1)s+n}\\gamma_n^{-1}(\\lambda))e^{\\rho(\\lambda)+\\rho(\\gamma_\\ell)}}]\\nonumber\\\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ & & = s(l-1)m_a - e[\\log(\\sum_{\\lambda\\in\\lambda^-}e^{\\rho(\\gamma_\\ell)+\\rho(\\lambda)})]+e[\\log(1+\\sum_{\\lambda\\in\\lambda^+}e^{-(\\rho(\\gamma_\\ell)-\\rho(\\lambda))})].\\label{eq : exit}\\end{aligned}\\ ] ] eq .",
    "( [ eq : exit1 ] ) is from the fact @xmath111 since @xmath112 is the correct symbol . in ( [ eq : exit ] ) ,",
    "the first term is from @xmath113 due to @xmath114 . in the second and third terms , @xmath115 and @xmath116 .",
    "it holds that @xmath117 , @xmath118 , where @xmath119 takes the cardinality of a set .",
    "now we give an approximation for the exit function in ( [ eq : exit ] ) .",
    "for @xmath120 , we have @xmath121 similarly , for @xmath122 , we have @xmath123    vector @xmath124 in ( [ eq : rho- ] ) and ( [ eq : rho+ ] ) is a bit - wise correlation between the binary vectors for the correct symbol and an error symbol .",
    "due to random chip @xmath125 , random mapping @xmath14 , and random spreading element @xmath126 , this bit - wise correlation vector is approximately uniformly distributed on the set that includes all the binary vector in @xmath15 except all - one vector @xmath127 .",
    "let set @xmath128 include all the binary-@xmath129 vectors of length @xmath0 except @xmath130 , and @xmath131 include all the binary-@xmath129 vectors of length @xmath0 except @xmath132 .",
    "let @xmath133 denote the uniform distribution on set @xmath134 .",
    "we have the following approximation of the exit function ( [ eq : exit ] ) @xmath135+e[\\log(1+\\sum_{j=1}^{2^{s-1}-1}e^{-\\sum_{i=1}^{l-1}{\\mbox{\\boldmath$r$}}_{j , i}^\\prime{\\mbox{\\boldmath$\\hbar$}}_i^\\textrm{t}})]\\triangleq \\varphi(m_a)\\label{eq : exitapp}\\end{aligned}\\ ] ] where @xmath136 , are i.i.d . with @xmath137 .",
    "vectors @xmath138 , @xmath139 , are i.i.d . with @xmath140 .",
    "elements @xmath141 , in @xmath142 , are all i.i.d . with @xmath143 .    to see the accuracy of the approximation in ( [ eq : exitapp ] ) , figs .",
    "[ fig : exit8 ] and [ fig : exit16 ] illustrate the exit function in ( [ eq : exit ] ) and @xmath144 in ( [ eq : exitapp ] ) for @xmath145 and @xmath146 by monte carlo simulations .",
    "we see that @xmath144 is in fact a tight upper bound of the exit function .",
    "the ratio between @xmath144 and the exit function is less than 1.06 for @xmath147 in both figures .",
    "based on this fact , in the rest analysis of this paper , we employ approximate exit function @xmath144 of the ff - des .",
    "moreover , we have the following observation on the approximate exit function .",
    "there exists a cutoff point @xmath148 usually less than 1 . for @xmath149 , every curve of the approximate exit function in figs .",
    "[ fig : exit8 ] and [ fig : exit16 ] asymptotically approaches a line .",
    "the asymptotic slope of the approximate exit function increases as @xmath0 increases .",
    "this means that by joint spreading for @xmath0 information bits , an sinr gain is obtained with respect to that of @xmath39 .",
    "this sinr gain will be enhanced as length @xmath0 increases .",
    "furthermore , by comparing fig .",
    "[ fig : exit8 ] and fig .",
    "[ fig : exit16 ] we can see that given @xmath0 , the asymptotic slope of the approximate exit function for @xmath150 is larger than that for @xmath151 .",
    "this is due to that as spreading length @xmath2 increases , the advantage of joint spreading is enlarged .",
    "although we have focused on the asymptotic slope of the exit function of the ff - des when @xmath152 is large above , the exit function at @xmath152 near 0 is also noteworthy .",
    "if the number of users @xmath5 is large , due to a large multi - user interference , at the beginning of decoding iteration the extrinsic output of the ese is always very small .",
    "this requires the exit function of the ff - des to be sufficiently large at @xmath152 near 0 , or else the iterative decoding would fail at the beginning of iteration . as revealed in @xcite and @xcite , conventional spreading scheme is widely used in the mac since it can provide a large exit function at @xmath152 near 0 .",
    "we see that in figs .",
    "[ fig : exit8 ] and [ fig : exit16 ] , the finite field spreading can provide a similar exit function as that of the conventional spreading scheme ( @xmath39 ) at @xmath153 , and can also work in the environment of large multi - user interference .",
    "( dashed lines ) of the ff - des for @xmath151 and @xmath146.,width=3 ]     ( dashed lines ) of the ff - des for @xmath150 and @xmath146.,width=3 ]      section  [ sec : appexit ] has shown that when @xmath152 is larger than cutoff point @xmath148 , the approximate exit function of ff - des asymptotically approaches a line . in this section",
    ", we analyze this slope by deriving the asymptotic differential of @xmath144 in ( [ eq : exitapp ] ) .",
    "[ thm : diversity ] let @xmath154 be a function of @xmath0 and @xmath2 .",
    "let @xmath155 be a constant .",
    "suppose that @xmath156 holds for @xmath149 , we have @xmath157 where @xmath158 with integer set @xmath159 .    to prove theorem  [ thm : diversity ] , we first prove the following lemma .",
    "[ lem : lim ] let @xmath160 be a constant .",
    "let @xmath161,\\widehat{r}_{j , i}\\in\\{-1,0,1\\},j=1, ... ,n$ ] , be i.i.d .",
    "random vectors with @xmath162 , and @xmath163 for all @xmath164 .",
    "let @xmath165 be a length-@xmath69 vector whose elements are i.i.d . with gaussian distribution @xmath166 .",
    "it holds that @xmath167}{\\mu}=0.\\label{eq : lemma}\\ ] ]    _ proof : _ we first have @xmath168\\!\\!\\!\\!\\!\\!\\!&&\\leq e[\\log(a+\\sum_{j=1}^ne^{\\widehat{{\\mbox{\\boldmath$r$}}}_j\\widehat{{\\mbox{\\boldmath$\\hbar$}}}^\\textrm{t}-w(\\widehat{{\\mbox{\\boldmath$r$}}}_j)\\mu } ) ] \\nonumber\\\\ & & \\leq e[\\log((n+1)\\max\\{a , e^{|\\widehat{{\\mbox{\\boldmath$r$}}}_1\\widehat{{\\mbox{\\boldmath$\\hbar$}}}^\\textrm{t}-w(\\widehat{{\\mbox{\\boldmath$r$}}}_1)\\mu|}, ... ,e^{|\\widehat{{\\mbox{\\boldmath$r$}}}_n\\widehat{{\\mbox{\\boldmath$\\hbar$}}}^\\textrm{t}-w(\\widehat{{\\mbox{\\boldmath$r$}}}_n)\\mu|}\\})]\\nonumber\\\\ & & \\leq \\log(n+1)+e[\\log a+\\sum_{j=1}^n|\\widehat{{\\mbox{\\boldmath$r$}}}_j\\widehat{{\\mbox{\\boldmath$\\hbar$}}}^\\textrm{t}-w(\\widehat{{\\mbox{\\boldmath$r$}}}_j)\\mu|]\\nonumber\\\\ & & = \\log(a(n+1))\\!+\\!n\\sum_{k=1}^me[|\\widehat{{\\mbox{\\boldmath$r$}}}_1\\widehat{{\\mbox{\\boldmath$\\hbar$}}}^\\textrm{t}\\!\\!-\\!w(\\widehat{{\\mbox{\\boldmath$r$}}}_1)\\mu|\\ |w^+(\\widehat{{\\mbox{\\boldmath$r$}}}_1)\\!=\\!k]\\textrm{pr}(w^+(\\widehat{{\\mbox{\\boldmath$r$}}}_1)\\!=\\!k)\\nonumber\\\\ & & = \\log(a(n+1))\\!+\\!2n\\sum_{k=1}^m\\sqrt{\\frac{k\\mu}{\\pi}}\\textrm{pr}(w^+(\\widehat{{\\mbox{\\boldmath$r$}}}_1)\\!=\\!k ) \\label{eq : jifen}\\\\ & & \\leq\\log(a(n+1))\\!+\\!2n\\sqrt{\\frac{m\\mu}{\\pi } } \\nonumber\\end{aligned}\\ ] ] where ( [ eq : jifen ] ) is due to that under the condition @xmath169 , @xmath170 holds for each realization of @xmath171 .",
    "thus , @xmath172}{\\mu}\\leq\\lim_{\\mu\\rightarrow + \\infty}\\frac{\\log(a(n+1))\\!+\\!2n\\sqrt{\\frac{m\\mu}{\\pi}}}{\\mu } = 0.\\nonumber\\end{aligned}\\ ] ] the lemma is proved .",
    "_ proof of theorem  [ thm : diversity ] : _ let @xmath173 be the set of subscripts that maximize the hamming weight of joint vector @xmath174 in ( [ eq : exitapp ] ) . given an element of @xmath175 , we have set @xmath176 .    since @xmath177 holds as @xmath178 by assumption , using ( [ eq : exitapp ] ) we have @xmath179}{m_a}+\\lim_{m_a\\rightarrow+\\infty}\\frac{e[\\log(1\\!+\\!\\sum_{j=1}^{2^{s-1}-1}e^{-\\sum_{i=1}^{l-1}{\\mbox{\\boldmath$r$}}_{j , i}^\\prime{\\mbox{\\boldmath$\\hbar$}}_i^\\textrm{t}})]}{m_a}\\nonumber\\\\ & & = s(l-1)-\\lim_{m_a\\rightarrow+\\infty}\\frac{e[\\log(\\sum_{j=1}^{2^{s-1}}e^{\\sum_{i=1}^{l-1}{\\mbox{\\boldmath$r$}}_{j , i}{\\mbox{\\boldmath$\\hbar$}}_i^\\textrm{t}})]}{m_a}\\label{eq:0lim1}\\\\ & & = s(l-1)-\\lim_{m_a\\rightarrow+\\infty}\\frac{e[\\sum_{i=1}^{l-1}{\\mbox{\\boldmath$r$}}_{j^*,i}{\\mbox{\\boldmath$\\hbar$}}_i^\\textrm{t}]}{m_a}-\\lim_{m_a\\rightarrow+\\infty}\\frac{e[\\log(|\\jmath^*|+\\sum_{j=1,j\\not\\in \\jmath^*}^{2^{s-1}}e^{-\\sum_{i=1}^{l-1}({\\mbox{\\boldmath$r$}}_{j^*,i}-{\\mbox{\\boldmath$r$}}_{j , i}){\\mbox{\\boldmath$\\hbar$}}_i^\\textrm{t}})]}{m_a}\\nonumber\\\\ & & = s(l-1)-e[\\sum_{i=1}^{l-1}w({\\mbox{\\boldmath$r$}}_{j^*,i})]\\label{eq:0lim2}\\\\ & & = s(l-1)-\\sum_{k=1}^{(s-1)(l-1)}k\\textrm{pr}(\\sum_{i=1}^{l-1}w({\\mbox{\\boldmath$r$}}_{j^*,i})=k)\\nonumber\\\\ & & = s(l-1)-\\sum_{k=1}^{(s-1)(l-1)}k(\\textrm{pr}(\\sum_{i=1}^{l-1}w({\\mbox{\\boldmath$r$}}_{j^*,i})\\leq k)-\\textrm{pr}(\\sum_{i=1}^{l-1}w({\\mbox{\\boldmath$r$}}_{j^*,i})\\leq k-1))\\nonumber\\\\ & & = s(l\\!-\\!1)-(s\\!-\\!1)(l\\!-\\!1)\\textrm{pr}(\\sum_{i=1}^{l\\!-\\!1}w({\\mbox{\\boldmath$r$}}_{j^*,i})\\leq ( s\\!-\\!1)(l\\!-\\!1))+\\sum_{k=1}^{(s\\!-\\!1)(l\\!-\\!1)}\\textrm{pr}(\\sum_{i=1}^{l\\!-\\!1}w({\\mbox{\\boldmath$r$}}_{j^*,i})\\leq k\\!-\\!1)\\nonumber\\\\ & & = l-1+\\sum_{k=1}^{(s-1)(l-1)}\\textrm{pr}(\\sum_{i=1}^{l-1}w({\\mbox{\\boldmath$r$}}_{1,i})\\leq k-1, ... ,\\sum_{i=1}^{l-1}w({\\mbox{\\boldmath$r$}}_{2^{s-1},i})\\leq k-1)\\nonumber\\\\ & & = l-1+\\sum_{k=1}^{(s-1)(l-1)}\\left(\\textrm{pr}(\\sum_{i=1}^{l-1}w({\\mbox{\\boldmath$r$}}_{1,i})\\leq k-1)\\right)^{2^{s-1}}\\label{eq : iid}\\\\ & & = l-1+\\frac{1}{(2^s-1)^{(l-1)2^{s-1}}}\\sum_{k=1}^{(s-1)(l-1)}\\left(\\sum_{(n_1, ...",
    ",n_{l-1})\\in \\theta(k-1)}\\prod_{i=1}^{l-1}\\binom{s}{n_i}\\right)^{2^{s-1}}.\\label{eq : diversityproof}\\end{aligned}\\ ] ] eq .",
    "( [ eq:0lim1 ] ) is from lemma  [ lem : lim ] .",
    "( [ eq:0lim2 ] ) is due to that elements of @xmath180 are i.i.d .",
    "with distribution @xmath181 and lemma  [ lem : lim ] .",
    "( [ eq : iid ] ) is due to that @xmath182 , are i.i.d .. eq .  ( [ eq : diversityproof ] )",
    "is due to that @xmath183 , are i.i.d . with @xmath184 .",
    "the theorem is proved .    for @xmath39",
    ", @xmath185 is the slope of the exit function of the des for the conventional spreading scheme of idma @xcite . the last term in ( [ eq : diversityproof ] )",
    "is the slope gain from the joint spreading .",
    "in this section , we show that the asymptotic slope of approximate exit function analyzed in section  [ sec : slope ] in fact is the absolute slope of ber curve at the low ber region .",
    "we verify our analysis by ber monte carlo simulations for practical finite field multiple - access systems .",
    "let @xmath186 be the exit function of the ese ( appendix  [ app : ese ] ) .",
    "the mean of extrinsic llr converges to infinity as the number of iteration increases if and only if @xmath187 holds for @xmath188 @xcite , where @xmath189 is the inverse function of @xmath190 in ( [ eq : exitapp ] ) . since @xmath191 ( lemma  [ lem : eselim ] in appendix  [ app : ese ] ) and @xmath192 , to converge to infinite mean of llr",
    ", @xmath193 should approach infinity .",
    "this is due to that no channel code is employed for each user .",
    "since for a given @xmath194 , @xmath195 is a decreasing function of spreading length @xmath2 , @xmath187 holds for @xmath188 as @xmath2 is sufficiently large and @xmath196 . in this case",
    ", the mean of the extrinsic llr converges to infinity as the number of iteration increases . due to @xmath197 from lemma  [ lem : eselim ] , the asymptotic ber of hard decision at the information node in @xmath42 is estimated as @xcite @xmath198 where we have used @xmath199 as @xmath194 is large , @xmath200 , and @xmath201 is referred to as a standard slope .",
    "note that we have used slope @xmath202 instead of @xmath154 in ( [ eq : ber ] ) since the hard decision is performed based on the total llr in ( [ eq : bitdecision ] ) other than the extrinsic llr in ( [ eq : symbol - bit ] ) .    ) -user finite field spreading multiple - access systems with @xmath145 and @xmath146 .",
    "the information vector length is @xmath203 and the number of decoding iteration is 50.,width=2 ]    in fact as the ber approaches 0 , the upper bound in ( [ eq : ber ] ) is very tight .",
    "( [ eq : ber ] ) indicates that at the low ber region , the ber curve is approximate to a line with absolute slope @xmath204 .",
    "since @xmath205 holds for an arbitrary @xmath2 , at the low ber region , the ber curve of conventional spreading scheme @xmath206 always converges to that of ( single - user ) uncoded bpsk transmission .",
    "unfortunately , this predicament can not be improved by increasing spreading length @xmath2 . in our work , since @xmath207 holds for @xmath208 , the ber curve of finite field spreading with @xmath208 has a larger absolute slope than that of single - user transmission with bpsk modulation , and the absolute slope of the ber curve increases as @xmath0 increases .",
    "in addition , there is a special case of @xmath209 , i.e. , code rate of each user is 1 .",
    "it is easy to show that in this case , the ber can never approach 0 for the number of users @xmath210 due to code rate 1 of each user . for single - user ( @xmath211 ) finite field spreading multiple - access , since @xmath212 for an arbitrary @xmath0 , at the low ber region , the absolute slope of the ber curve approaches that of single - user transmission with bpsk modulation .",
    "we verify our analysis above , obtained based on the gaussian approximation and the approximation of ( [ eq : exitapp ] ) , by ber monte carlo simulations on practical systems .",
    "we consider @xmath213-user finite field spreading multiple - access system with @xmath145 and @xmath146 .",
    "[ fig : ber ] illustrates ber curves obtained by monte carlo simulations .",
    "since the exit function theory is based on the assumption of infinite code length @xcite , in our simulations we employ a large code length with the information vector length of @xmath203 .",
    "the number of decoding iteration is 50 .",
    "both mapping @xmath214 and the chip - level interleaving are random , and the ber curve illustrates an average ber for all the possible mapping and interleaving realizations .",
    "we use horizontal coordinate @xmath193 and vertical coordinate @xmath215 ( natural logarithm ) .",
    "we see that at the low ber region , all ber curves are approximate to lines .",
    "we compare the absolute slopes of ber curves at low ber region in fig .",
    "[ fig : ber ] with standard slope @xmath204 obtained by theorem  [ thm : diversity ] in table  [ tab : berslope ] .",
    "the difference is less than @xmath216 for all the comparison pairs .",
    "the two curves for @xmath39 overlap with each other and converge to the ber curve of single - user transmission with bpsk modulation .",
    "curves for @xmath217 have larger absolute slopes than that of single - user transmission with bpsk modulation .",
    "all these phenomenons coincide with our analysis .",
    "[ tab : berslope ]    .comparison between absolute slopes of ber curves at low ber region in fig .",
    "[ fig : ber ] and @xmath204 [ cols=\"^,^,^,^,^,^,^,^,^ \" , ]",
    "in this paper , we proposed a finite field spreading scheme for the mac , in which the spreading for multiple bits is performed jointly by the finite field multiplication . under the iterative decoding ,",
    "an sinr gain is obtained during the joint spreading .",
    "the multi - user finite field spreading multiple - access achieves a lower ber than that of the single - user transmission with bpsk modulation under the iterative decoding .",
    "we considered the finite field spreading multiple - access system without channel coding for each user .",
    "if there is a channel code employed as an outer code for each user , our exit function analysis of the ff - des is also available from the theory of concatenated code @xcite .",
    "there are still a number of problems in connection with our work that seem to deserve further investigation . in our analysis",
    ", we considered an average exit function and asymptotic slope for all the mapping and interleaving .",
    "in fact , different mapping and interleaving have different exit functions that provide different ber performance .",
    "design of spreading and interleaving to achieve better ber performance is an interesting future work .    in the field field spreading of fig .",
    "[ fig : factorfinite ] , every @xmath0 information bits are spread into @xmath2 length-@xmath0 vectors , each of which can be regarded as a codeword of a rate-1 code .",
    "these @xmath2 rate-1 codes constitute a finite field spreading code with rate @xmath32 .",
    "the @xmath2 multiplications on finite field can be regarded as @xmath2 rate-1 encoding operations that determine the @xmath2 rate-1 codes .",
    "these rate-1 encoding can also realized by other methods , or we can employ codes with rate less than 1 to achieve a better exit transfer performance .",
    "all these problems deserve further investigations .",
    "using ( [ eq : receive ] ) and ( [ eq : ese ] ) , the exit function of the ese is derived as @xmath218\\!\\!\\!\\!\\!\\!\\!&&=e[\\frac{2\\sqrt{\\frac{e_b}{l}}x_t^{(k)}\\left(y_t-\\sqrt{\\frac{e_b}{l}}\\sum_{i=1,i\\neq k}^k\\tanh(\\frac{l^{a}(x^{(i)}_t)}{2})\\right)}{\\frac{e_b}{l}\\sum_{i=1,i\\neq k}^k\\left(1-(\\tanh(\\frac{l^{a}(x^{(i)}_t)}{2}))^2\\right)+\\frac{n_0}{2}}]\\nonumber\\\\ & & = e[\\frac{2\\frac{e_b}{l}+2\\frac{e_b}{l}x_t^{(k)}\\sum_{i=1,i\\neq k}^k\\left(x_t^{(i)}-\\tanh(\\frac{l^{a}(x^{(i)}_t)}{2})\\right)+2\\sqrt{\\frac{e_b}{l}}x_t^{(k)}z_t}{\\frac{e_b}{l}\\sum_{i=1,i\\neq k}^k\\left(1-(\\tanh(\\frac{l^{a}(x^{(i)}_t)}{2}))^2\\right)+\\frac{n_0}{2}}]\\nonumber\\\\ & & = e[\\frac{4}{2\\sum_{i=1,i\\neq k}^k\\left(1-(\\tanh(\\frac{x^{(i)}_tl^{a}(x^{(i)}_t)}{2}))^2\\right)+{l}/{\\frac{e_b}{n_0}}}]\\label{eq : esexit1}\\\\ & & = e[\\frac{4}{2\\sum_{i=1}^{k-1}\\left(1-(\\tanh ( \\hbar_i))^2\\right)+{l}/{\\frac{e_b}{n_0}}}]\\triangleq \\phi(m_a,\\frac{e_b}{n_0})\\nonumber\\end{aligned}\\ ] ] where @xmath219 are i.i.d . with @xmath220 .",
    "( [ eq : esexit1 ] ) is due to that @xmath221 is independent of @xmath222 , and @xmath35 .",
    "note that @xmath186 is an average exit function of the ese for all the possible transmitted symbols .",
    "_ proof : _ the upper bound is from the fact @xmath224 .",
    "we prove the equality in the upper bound .",
    "let @xmath225 be a constant .",
    "we have @xmath226 where ( [ eq : lemma2 - 1 ] ) is from monotone increasing of @xmath227 for @xmath228 , and ( [ eq : lemma2 - 2 ] ) is from chebyshev inequality . using the squeeze theorem",
    "we obtain @xmath229 .",
    "the lemma is proved .",
    "s. y. chung , t. j. richardson , and r. l. urbanke ,  analysis of sum - product decoding of low - density parity - check codes using a gaussian approximation , \" _ ieee trans .",
    "inf . theory _ ,",
    "657 - 670 , feb . 2001 .",
    "t. wo and p. a. hoeher ,  universal coding approach for superposition mapping , \" _ in proc .",
    "6th international symposium on turbo codes and iterative information processing ( istc 2010 ) _ , pp .",
    "324 - 328 , france , sept . 2010"
  ],
  "abstract_text": [
    "<S> finite field spreading scheme is proposed for a synchronous multiple - access channel with gaussian noise and equal - power users . for each user , </S>",
    "<S> @xmath0 information bits are spread _ jointly _ into a length-@xmath1 vector by @xmath2 multiplications on gf(@xmath3 ) . </S>",
    "<S> thus , each information bit is dispersed into @xmath1 transmitted symbols , and the finite field despreading ( ff - des ) of each bit can take advantage of @xmath1 independent receiving observations . to show the performance gain of joint spreading quantitatively , an extrinsic information transfer ( exit ) function analysis of the ff - des </S>",
    "<S> is given . </S>",
    "<S> it shows that the asymptotic slope of this exit function increases as @xmath0 increases and is in fact the absolute slope of the bit error rate ( ber ) curve at the low ber region . </S>",
    "<S> this means that by increasing the length @xmath0 of information bits for joint spreading , a larger absolute slope of the ber curve is achieved . for @xmath4 , the ber curve of the finite field spreading </S>",
    "<S> has a larger absolute slope than that of the single - user transmission with bpsk modulation .    </S>",
    "<S> finite field spreading , exit function , multiple - access channel , cdma , idma </S>"
  ]
}