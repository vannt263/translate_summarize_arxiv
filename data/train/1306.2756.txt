{
  "article_text": [
    "let @xmath167 be the set of random variables on a bn , where @xmath17 is in the topological ordering .",
    "the conditional probability is given by @xmath168 , where @xmath169 is the set of parents of @xmath15 . in this section ,",
    "we prove two theorems  @xcite that has been used in the derivation of the main result in the main manuscript .    * theorem 1 ( the chain rule for bayesian networks ) . * _ for any index @xmath170",
    ", we have _",
    "@xmath171    _",
    "proof_. @xmath172 in the derivation of the main result , we used this theorem as @xmath173 , because @xmath174 , where @xmath65 is chosen to satisfy @xmath175 .",
    "* theorem 2 ( consistency of the specification of bn ) . * _ if @xmath176 is a subset of @xmath177 and @xmath16 is a subset of @xmath176 ( @xmath178 ) , we have _ @xmath179    _",
    "proof_. @xmath180 in the derivation of the main result , we used this theorem as @xmath181 , because @xmath182 , where @xmath183 is chosen to satisfy @xmath184 .",
    "in ref .  @xcite , schreiber introduced the transfer entropy for stochastic dynamics with two variables @xmath185 and @xmath186 , where @xmath187 ( @xmath188 ) denotes the state of the system @xmath189 ( @xmath190 ) at time @xmath191 .",
    "the transfer entropy from @xmath190 to @xmath189 is defined by @xmath192 here , @xmath193 characterizes the information flow from @xmath189 to @xmath190 ; in fact , @xmath193 is given by the difference between the entropy rate in @xmath189 and that under the condition of @xmath190 : @xmath194 where the entropy rate in @xmath189 and that under the condition of @xmath190 , @xmath195 and @xmath196 , are defined as @xmath197 $ ] and @xmath198 $ ] , respectively .",
    "the quantity @xmath199 in our main result is defined as @xmath200 which equals the transfer entropy @xmath201 .",
    "we consider the following multidimensional over - damped langevin equation : @xmath202 @xmath203 where @xmath204 ( @xmath205 ) denotes a dynamical variable . with small time interval @xmath206 , we discretize the dynamical variables as @xmath207 .",
    "we write @xmath208 . when @xmath209 is fixed , we obtain the conditional probability @xmath210 in terms of the stratonovich product : @xmath211 , \\label{forwardpath}\\end{aligned}\\ ] ] where @xmath212 , @xmath213 , @xmath214 , and @xmath215 is the prefactor which does not depend on @xmath216  @xcite .",
    "we stress that we use the mid - point rule only for @xmath217 .",
    "we define the conditional probability of the backward process @xmath218 as @xmath219 .",
    "\\label{backwardpath}\\end{aligned}\\ ] ]        figure  [ figsupple : langevin ] shows the bayesian network ( bn ) corresponding to the multidimensional langevin equation [ eqs .",
    "( [ langevin1 ] ) , ( [ langevin2 ] ) and ( [ langevin3 ] ) ] for the time interval between @xmath220 and @xmath221 .",
    "thus we have @xmath222 . from eqs .",
    "( [ forwardpath ] ) and ( [ backwardpath ] ) , we obtain @xmath223 : @xmath224 the definition of the heat flux in system @xmath217 by sekimoto  @xcite is given by @xmath225 .",
    "we then compare @xmath226 with @xmath223 as @xmath227 \\\\ & = o(\\delta t ) , \\end{aligned}\\ ] ] where we used @xmath228 with @xmath229 because of the independence of the noises [ eq .",
    "( [ langevin2 ] ) ] .",
    "therefore , our definition of the entropy change in the heat baths on the bn ( _ i.e. _ , @xmath223 ) is equivalent to the sekimoto s definition ( _ i.e. _ , @xmath230 ) up to @xmath231 .",
    "we consider systems under repeated feedback control .",
    "figure  [ figsupple : repeated ] shows the bn corresponding to the repeated feedback control discussed by horowitz and vaikuntanathan  @xcite .",
    "there are system @xmath25 and memories @xmath232 with @xmath233 ( @xmath234 ) .",
    "measurements are performed on system @xmath25 at time @xmath235 , where @xmath235 is the natural number such as @xmath236 .",
    "the state of @xmath25 at time @xmath235 is given by @xmath237 , where the measurement outcome is stored in @xmath238 .",
    "the states of @xmath25 under feedback control can then depend on @xmath238 after time @xmath235 .",
    "we have @xmath239 and @xmath240 , and therefore @xmath241 , @xmath242 , @xmath243 , and @xmath244 according to the main result , we obtain the following generalized jarzynski equality : @xmath245\\right>= 1 .",
    "\\label{bayesian jarzynski}\\ ] ]    on the other hand , the equality derived by horowitz and vaikuntanathan  @xcite is given by @xmath246 \\right > = 1 , \\label{horowitz jarzynski}\\ ] ] where @xmath80 is our definition of the transfer entropy that is given by @xmath243 and @xmath6 is the inverse temperature of the heat bath .",
    "@xmath247 is the dissipated work that is given by @xmath248 , where @xmath249 is the canonical equilibrium distribution for fixed control parameter .",
    "@xmath250 is equivalent to @xmath251 such that @xmath252 .",
    "therefore , our result can reproduce the result obtained by horowitz and vaikuntanathan in ref .",
    "@xcite , when the initial and final states of the system are in thermal equilibrium .",
    "in the adaptation model in the main manuscript , we consider the following master equations : @xmath253 where the transition rate is given by @xmath254 . \\label{transition rate}\\ ] ] in the following , we show that @xmath223 is equal to @xmath255 .",
    "we note that @xmath256 holds because of the normalization of the probability distribution .",
    "we rewrite eq .",
    "( [ mastersup1 ] ) as @xmath257 p^{x}_{0}(t ) + \\omega_{1 , 0}^{x } ( f^x_{1}(t ) ) .",
    "\\label{master}\\end{aligned}\\ ] ] when @xmath258 and @xmath259 are constants , we get the solution of eq .",
    "( [ master ] ) as @xmath260 , \\label{solution}\\end{aligned}\\ ] ] where @xmath261 is defined as @xmath262    the state of @xmath125 ( @xmath121 ) at time @xmath144 ( @xmath263 ) describes @xmath142 ( @xmath143 ) with @xmath264 .",
    "we set the interaction between the memory @xmath265 and the output system @xmath266 as follow .",
    "let @xmath148 at time @xmath267 be @xmath268 and let @xmath122 at time @xmath151 be @xmath269 where @xmath270 .",
    "substituting @xmath271 into the solution of eq .",
    "( [ solution ] ) , we have the conditional probabilities @xmath272 : @xmath273 ,   \\label{so1}\\\\ p(m_{k+1}=0|m_{k}=1,o_k = j ' ) & = & q_{j ' } - q_{j'}\\exp \\left [ -\\omega_{j ' }   \\delta \\right ] ,   \\label{so2}\\\\ p(m_{k+1}=1|m_{k}=i',o_k = j ' ) & = & 1- p(m_{k+1}=0|m_{k}=i',o_k = j ' ) , \\label{so3}\\end{aligned}\\ ] ] where @xmath274 , @xmath275 and @xmath276 .",
    "substituting @xmath277 into eq .",
    "( [ solution ] ) , we also have the conditional probabilities @xmath278 : @xmath279   \\label{so4}\\\\ p(o_{k+1}=0|o_{k}=1,m_{k}=j ' , m_{k+1}=k ' ) & = & q'_{j'k ' } - q'_{j'k ' } \\exp \\left [ -\\omega'_{j'k ' } \\delta \\right ]   \\label{so5}\\\\ p(o_{k+1}=1|o_{k}=i',m_{k}=j ' , m_{k+1}=k')&=&1-   p(o_{k+1}=0|o_{k}=i ' , m_{k}=j ' , m_{k+1}=k ' ) , \\label{so6}\\end{aligned}\\ ] ] where @xmath280 and @xmath281 .",
    "we assume that the conditional probabilities of backward process @xmath282 and @xmath283 are defined as @xmath284 and @xmath285 with @xmath286 , respectively .    from eqs .",
    "( [ transition rate ] ) , ( [ so1 ] ) , ( [ so2 ] ) and ( [ so3 ] ) , we have @xmath223 with @xmath265 : @xmath287 \\\\ & = \\left\\ { \\begin{array}{ll }      0   & ( m_{k+1}=0 , m_{k}=0 , o_{k}=j'))\\\\      \\ln q_{j ' } -\\ln(1-q_{j ' } ) & ( m_{k+1}=0 , m_{k}=1 , o_{k}=j ' ) \\\\       \\ln ( 1- q_{j ' } ) -\\ln q_{j ' } & ( m_{k+1}=1 , m_{k}=0 , o_{k}=j')\\\\      0   & ( m_{k+1}=1 , m_{k}=1 , o_{k}=j')\\\\    \\end{array } \\right . \\\\ & = \\begin{array}{ll } -\\beta^m ( f_{l',j ' } -f_{i',j ' } ) & ( m_{k+1}=l ' , m_{k}=i ' , o_{k}=j ' ) ,   \\end{array}\\end{aligned}\\ ] ] where @xmath288 . from eqs .",
    "( [ transition rate ] ) , ( [ so4 ] ) , ( [ so5 ] ) and ( [ so6 ] ) , we have @xmath223 with @xmath266 : @xmath289 \\\\ & = \\left\\ { \\begin{array}{ll }      0   & ( o_{k+1}=0 , o_{k}=0 , m_{k}=j ' , m_{k+1}=k ' ) \\\\      \\ln q'_{j'k ' } -\\ln(1-q'_{j'k ' } ) & ( o_{k+1}=0 , o_{k}=1 , m_{k}=j ' , m_{k+1}=k ' ) \\\\       \\ln ( 1- q'_{j'k ' } ) -\\ln q'_{j'k ' } & ( o_{k+1}=1 , o_{k}=0 , m_{k}=j ' , m_{k+1}=k ' ) \\\\      0   & ( o_{k+1}=1 , o_{k}=1 , m_{k}=j ' , m_{k+1}=k ' ) \\\\    \\end{array } \\right .",
    "\\\\ & = \\begin{array}{ll } -\\beta^o ( f'_{l',j'k ' } -f'_{i',j'k ' } ) & ( o_{k+1}=l ' , o_{k}=i ' , m_{k}=j ' , m_{k+1}=k ' ) ,   \\end{array}\\end{aligned}\\ ] ] where @xmath290 , we reach the conclusion that @xmath223 is given by the effective free - energy difference .",
    "we set the parameters of the numerical illustration in fig .  5 of the main manuscript as follows : @xmath291 , @xmath292 , @xmath293 , @xmath294 , @xmath295 , @xmath296 , @xmath297 , @xmath298 , @xmath299 , @xmath300 , @xmath301 and @xmath302 .",
    "in this case , we have @xmath303 , @xmath304 , @xmath305 and @xmath306 .",
    "we note that the value of @xmath307 in fig .",
    "5 of the main manuscript is close to @xmath126 when the initial states are close to the stationary distribution of the output system , which is similar to the probabilities @xmath308 , @xmath309 , @xmath310 and @xmath311 .",
    "99 k. sekimoto , _ stochastic energetics _",
    "( springer , new york , 2010 ) .",
    "u. seifert , rep .",
    "prog . phys . * 75 * , 126001 ( 2012 ) . c. jarzynski , phys .",
    "lett . * 78 * , 2690 ( 1997 ) .",
    "d. j. evans , e. g. d. cohen , and g. p. morriss , phys . rev",
    ". lett . * 71 * , 2401 ( 1993 ) .",
    "g. e. crooks , j. stat .",
    "* 90 * , 1481 ( 1998 ) .",
    "j. l. lebowitz and h. spohn , j. stat . phys . * 95 * , 333 ( 1999 ) . c. jarzynski , j. stat .",
    "phys . * 98 * , 77 ( 2000 ) .",
    "d. j. evans and d. j. searles , adv .",
    "* 51 * , 1529 ( 2002 ) .",
    "j. c. maxwell , _ theory of heat , _",
    "( appleton , london , 1871 ) .",
    "l. szilard , z. phys .",
    "* 53 * , 840 ( 1929 ) .",
    "_ maxwell s demon 2 : entropy , classical and quantum information , computing _ , edited by h. s. leff and a. f. rex ( princeton university press , princeton , nj , 2003 ) .",
    "t. sagawa and m. ueda , phys .",
    "lett . * 104 * , 090602 ( 2010 ) . t. sagawa and m. ueda , phys .",
    "lett . * 109 * , 180602 ( 2012 ) .",
    "s. toyabe , t. sagawa , m. ueda , e. muneyuki , and m. sano , nat .",
    "physics * 6 * , 988 ( 2010 ) .",
    "r. landauer , science * 272 * , 1914 ( 1996 ) .",
    "t. sagawa and m. ueda , phys .",
    "lett . * 100 * , 080403 ( 2008 ) ; * 102 * , 250602 ( 2009 ) ; * 106 * , 189901(e ) ( 2011 ) .",
    "h. touchette and s. lloyd , phys .",
    "* 84 * , 1156 ( 2000 ) .",
    "f. j. cao , l. dinis , and j. m. r. parrondo , phys .",
    "lett . * 93 * , 040603 ( 2004 ) .",
    "h. touchette and s. lloyd , physica ( amsterdam ) * 331a * , 140 ( 2004 ) .",
    "k. h. kim and h. qian , phys . rev .",
    "e * 75 * , 022102 ( 2007 ) .",
    "f. j. cao and m. feito , phys .",
    "e * 79 * , 041118 ( 2009 ) .",
    "f. j. cao , m. feito , and h. touchette , physica ( amsterdam ) * 388a * , 113 ( 2009 ) .",
    "y. fujitani and h. suzuki , j. phys .",
    ". jpn . * 79 * , 104003 ( 2010 ) . j. m. horowitz and s. vaikuntanathan , phys",
    "e. * 82 * , 061120 , ( 2010 ) .",
    "m. ponmurugan , phys .",
    "e * 82 * , 031129 ( 2010 ) .",
    "y. morikuni and h. tasaki , j. stat . phys . * 143 * , 1 ( 2011 ) .",
    "s. w. kim , t. sagawa , s. de liberato , and m. ueda , phys .",
    "* 106 * , 070401 ( 2011 ) .",
    "s. ito and m. sano , phys .",
    "e * 84 * , 021123 ( 2011 ) .",
    "j. m. horowitz and j. m. r. parrondo , europhys .",
    "95 * , 10 005 ( 2011 ) .",
    "d. abreu and u. seifert , europhys .",
    "lett . * 94 * , 10 001 ( 2011 ) .",
    "s. vaikuntanathan and c. jarzynski , phys . rev .",
    "e * 83 * , 061120 ( 2011 ) .",
    "j. m. horowitz and j. m. r. parrondo , new j. phys .",
    "* 13 * , 123019 ( 2011 ) .",
    "l. granger and h. kantz , phys .",
    "e * 84 * , 061110 ( 2011 ) .",
    "m. esposito and c. van den broeck , europhys .",
    "lett . * 95 * , 40 004 ( 2011 ) .",
    "t. sagawa and m. ueda , phys .",
    "e. * 85 * , 021104 ( 2012 )",
    ". t. munakata and m. l. rosinberg , j. stat .",
    "( 2012 ) p05010 .",
    "m. esposito and g. schaller , europhys . lett . * 99 * , 30 003 ( 2012 ) .",
    "d. abreu and u. seifert , phys .",
    "lett . * 108 * , 030601 ( 2012 ) .",
    "s. lahiri , s. rana , and a. m. jayannavar , j. phys .",
    "* 45 * , 065002 ( 2012 ) .",
    "t. sagawa , prog .",
    ". phys . * 127 * , 1 ( 2012 ) .",
    "f. j. cao and m. feito , entropy * 14 * , 834 ( 2012 ) . j. m. horowitz , t. sagawa and j. m. r. parrondo , phys .",
    "lett . * 111 * , 010602 ( 2013 ) .",
    "a. kundu , phys .",
    "e * 86 * , 021107 ( 2012 ) .",
    "m. bauer , d. abreu and u. seifert j. phys .",
    "a : math . theor .",
    "* 45 * 162001 ( 2012 ) .",
    "d. mandal and c. jarzynski , proc .",
    "natl . acad .",
    ", * 109 * 11641 ( 2012 )",
    ". s. still , d. a. sivak , a. j. bell and g. e. crooks , phys .",
    "109 , 120604 ( 2012 ) p. strasberg , g. schaller , t. brandes , and m. esposito , phys .",
    "lett . * 110 * , 040601 ( 2013 ) .",
    "a. c. barato , d. hartich and u. seifert , phys .",
    "e * 87 * , 042104 ( 2013 ) t. munakata and m. l. rosinberg , j. stat .",
    "( 2013 ) p06014 .",
    "a. c. barato and u. seifert , europhys .",
    "* 101 * , 60 001 ( 2013 ) .",
    "d. mandal , h. t. quan and c. jarzynski , phys .",
    "lett . * 111 * , 030602 ( 2013 ) .",
    "a. c. barato , d. hartich and u. seifert , j. stat .",
    "phys . * 153 * 460 ( 2013 ) .",
    "a. brut , a. arakelyan , a. petrosyan , s. ciliberto , r. dillenschneider , and e. lutz , nature ( london ) * 483 * , 187 ( 2012 ) . f. v. jensen , _ bayesian networks and decision graphs _ , information science and statistics ( springer , berlin , 2001 ) . t. schreiber , phys .",
    "* 85 * , 461 ( 2000 ) .",
    "k. sekimoto , j. phys .",
    "* 66 * , 1234 ( 1997 ) .",
    "j. mehl , b. lander , c. bechinger , v. blickle and u. seifert , phys .",
    "lett . * 108 * , 220601 ( 2012 ) .",
    "t. speck , v. blickle , c. bechinger and u. seifert , europhys .",
    "* 79 * , 30 002 ( 2007 ) .",
    "f. tostevin and p. r. ten wolde , phys .",
    "* 102 * , 021801 ( 2009 ) .",
    "p. mehta , s. goyal , t. long , b. l. bassler , and n. s. wingreen , mol .",
    "syst . biol . * 5 * , 325 ( 2009 ) .",
    "r. cheong , a. rhee , c. j. wang , i. nemenman , and a. levchenko , science * 334 * : 354 ( 2011 ) .",
    "y. tu , t. s. shimizu , and h. c. berg , proc .",
    "natl acad .",
    "usa * 105 * , 14855 ( 2008 ) .",
    "g. lan , p. sartori , s. neumann , v. sourjik , and y. tu , nat . phys . * 8 * , 422 ( 2012 ) . o. brandman and t. meyer , science . * 322 * , 390 ( 2008 ) .",
    "v. y. chernyak , m. chertkov , and c. jarzynski , j. stat .",
    "( 2006 ) p08001 .",
    "k. sekimoto , prog .",
    ". suppl . * 130 * , 17 ( 1998 ) ."
  ],
  "abstract_text": [
    "<S> we study nonequilibrium thermodynamics of complex information flows induced by interactions between multiple fluctuating systems . characterizing nonequilibrium dynamics by causal networks ( i.e. , bayesian networks ) , we obtain novel generalizations of the second law of thermodynamics and the fluctuation theorem , which include an informational quantity characterized by the topology of the causal network . </S>",
    "<S> our result implies that the entropy production in a single system in the presence of multiple other systems is bounded by the information flow between these systems . </S>",
    "<S> we demonstrate our general result by a simple model of biochemical adaptation .    _ </S>",
    "<S> introduction._nonequilibrium equalities for small thermodynamic systems such as molecular motors have been intensively investigated in the last two decades  @xcite . </S>",
    "<S> the second law of thermodynamics can be derived from the jarzynski equality  @xcite and the fluctuation theorems ( fts )  @xcite . </S>",
    "<S> the second law is expressed in terms of the ensemble average of the entropy production @xmath0 : @xmath1 where @xmath2 describes the ensemble average . </S>",
    "<S> we note that @xmath0 reduces to the difference in the free - energy change @xmath3 and the work @xmath4 performed on the system such that @xmath5 , when the system is attached to a single heat bath with inverse temperature @xmath6 , and the initial and final states are in thermal equilibrium .    on the other hand , in the presence of feedback control by maxwell s demon  @xcite </S>",
    "<S> , the second law seems to be violated ; i.e. , @xmath7 can be negative . </S>",
    "<S> for such cases , the second law has been generalized as @xmath8 where @xmath9 is the mutual information that is exchanged between the system and the demon  @xcite . </S>",
    "<S> such a maxwell s demon has been experimentally demonstrated with a colloidal particle  @xcite . </S>",
    "<S> while the relationship between information and thermodynamics has been studied in several simple setups with the demon  @xcite , the general theory has been elusive for more complex cases in which multiple systems exchange information many times .    in this letter </S>",
    "<S> , we derive a novel nonequilibrium equality in the presence of complex information flows between multiple stochastic systems . </S>",
    "<S> our result involves a new informational term that is characterized by the topology of the causal structure of the dynamics . </S>",
    "<S> the informational quantity consists of the initial correlation between the target system and other systems , the information transfer from the system to others during the dynamics , and the final correlation between them . </S>",
    "<S> our result can reproduce inequality ( [ information thermodynamics ] ) for special cases . in order to describe nonequilibrium dynamics of multiple systems </S>",
    "<S> , we use bayesian networks ( bns )  @xcite that topologically represent the causal structure of the dynamics .    our theory is applicable to quite a broad class of nonequilibrium dynamics such as an information transfer between multiple brownian particles and information processing in autonomous nanomachines . </S>",
    "<S> we illustrate our result by a chemical model of biological adaptation with time - delayed feedback . </S>",
    "<S> our result implies that information processing plays a crucial role in biochemical reactions .    _ </S>",
    "<S> bayesian networks._first ,     under the influence of other systems.,width=321 ]    we briefly discuss the basic concepts of bns [ see also fig .  [ </S>",
    "<S> fig : bayesianshematic](a ) ] . </S>",
    "<S> let @xmath10 be the set of random variables that are associated with the nodes of a bn , where @xmath11 is the number of the nodes . when an edge @xmath12 exists , there is a causal relationship from @xmath13 to @xmath14 , where we say that @xmath13 is a parent of @xmath15 . </S>",
    "<S> we denote by @xmath16 the set of parents of @xmath15 . here </S>",
    "<S> , the order of @xmath17 is determined by the causal relationship in the bn such that @xmath14 can not be a parent of @xmath13 if @xmath18 . </S>",
    "<S> this order is referred to as the topological ordering . </S>",
    "<S> we characterize stochastic dynamics in the bn by the conditional probability @xmath19 that describes the probability of @xmath15 under the condition of a particular realization of @xmath16 . </S>",
    "<S> we write @xmath20 , where @xmath21 is the empty set . </S>",
    "<S> because of the chain rule in the probability theory , we obtain the joint probability distribution of the all random variables  @xcite : @xmath22 the ensemble average of the arbitrary function @xmath23 is defined as @xmath24 .        </S>",
    "<S> we next describe how we use bns to describe stochastic dynamics [ see also fig .  [ </S>",
    "<S> fig : bayesianshematic](b ) ] . </S>",
    "<S> we consider a situation in which system @xmath25 interacts with other systems . </S>",
    "<S> the probability distribution of all the systems for the entire process is given by eq . </S>",
    "<S> ( [ definition of joint probability ] ) , where @xmath15 corresponds to a state of a system at a particular time . </S>",
    "<S> @xmath26 consists of all states in the time evolution of both system @xmath25 and other systems .    </S>",
    "<S> we also use the notation @xmath25 to describe the time evolution of system @xmath25 ; we write @xmath27 ( @xmath28 ) , where @xmath29 is the state of system @xmath25 at time @xmath30 , and @xmath31 is the symbol of the subset . </S>",
    "<S> we assume that @xmath32 is a parent of @xmath33 . </S>",
    "<S> we also assume that @xmath29 can not be a parent of @xmath34 for @xmath35 . </S>",
    "<S> we note that the time evolution of @xmath25 is characterized by the chain @xmath36 .    for instance , </S>",
    "<S> fig .  </S>",
    "<S> [ fig : bayesian](a ) shows an expansion of a single - molecule gas , which can be described by the bn shown in fig .  </S>",
    "<S> [ fig : bayesian](b ) . </S>",
    "<S> this bn shows the time evolution such that @xmath37 , where @xmath38 and @xmath39 , respectively , describe the initial and final positions of the particle . in fig .  </S>",
    "<S> [ fig : bayesian](c ) , we illustrate the szilard engine  @xcite that is a standard model of maxwell s demon . </S>",
    "<S> figure  [ fig : bayesian](d ) shows the corresponding bn , where @xmath40 describes a memory state that is correlated with @xmath38 . </S>",
    "<S> this bn shows the time evolution of the total system @xmath41 .    </S>",
    "<S> _ entropy production and mutual information._we introduce the entropy production in stochastic thermodynamics in terms of the bn . </S>",
    "<S> we assume that system @xmath25 is coupled to heat baths with inverse temperatures @xmath42 @xmath43 . </S>",
    "<S> let @xmath44 be the heat absorbed by @xmath25 from the @xmath45th bath . </S>",
    "<S> because of the standard definition in stochastic thermodynamics  @xcite , the entropy production in @xmath25 is given by @xmath46 , where @xmath47 ( @xmath48 ) is the initial ( final ) state of @xmath25 and @xmath49 is the entropy change in the baths . </S>",
    "<S> let @xmath50 be the entropy change in the baths from time @xmath30 to @xmath51 such that @xmath52 . </S>",
    "<S> in quite a broad class of nonequilibrium dynamics including multidimensional langevin dynamics ( see the supplemental material ) , @xmath50 satisfies the detailed ft  @xcite : @xmath53 where @xmath54 is defined as @xmath55 with @xmath56 indicating the relative complement of two sets . </S>",
    "<S> @xmath54 means the set of random variables which affect the time evolution of @xmath25 from states @xmath29 to @xmath33 [ see also fig .  [ </S>",
    "<S> fig : bayesianshematic](b ) ] . </S>",
    "<S> @xmath57 describes the probability distribution of backward paths .    </S>",
    "<S> we next introduce mutual information that plays a crucial role in this study . </S>",
    "<S> let @xmath58 , @xmath59 and @xmath60 be arbitrary sets of random variables . </S>",
    "<S> we define @xmath61 , where we write @xmath62 . </S>",
    "<S> its ensemble average @xmath63 is the mutual information between @xmath58 and @xmath59 under the condition of @xmath60 .    _ </S>",
    "<S> main result._in order to discuss the main result , we introduce set @xmath64 , where @xmath65 is chosen to satisfy @xmath66 [ see also fig .  [ </S>",
    "<S> fig : bayesianexample](a ) ] . here , @xmath67 is the history of the other systems that can affect the final state @xmath68 . </S>",
    "<S> we denote the elements of @xmath67 as @xmath69 , where @xmath70 are in the topological ordering .     and </S>",
    "<S> @xmath71 . </S>",
    "<S> @xmath67 is the history of other systems that can affect the final state @xmath68 . </S>",
    "<S> @xmath71 describes the variables correlated with the initial state @xmath38 . </S>",
    "<S> ( b ) an example of bn that describes three - body interactions.,width=302 ]    we now state the main result of this letter . in the foregoing setup </S>",
    "<S> , we have a new generalization of the integral ft ( ift ) : @xmath72 \\right > = 1 . </S>",
    "<S> \\label{bayesian jarzynski equality}\\ ] ] here , the key quantity @xmath73 is the informational quantity characterized by the topology of the bn : @xmath74 where @xmath75 and @xmath76 , with @xmath77 indicating the intersection . here </S>",
    "<S> , @xmath78 characterizes the initial correlation between @xmath25 and the other systems , while @xmath79 characterizes the final correlation that remains at the end of the dynamics . on the other hand , @xmath80 is the transfer entropy  @xcite that characterizes the information transfer into @xmath81 from @xmath25 during the dynamics ( see the supplemental material ) . </S>",
    "<S> for example , in the case of fig .  </S>",
    "<S> [ fig : bayesianexample ]  </S>",
    "<S> ( b ) , we obtain @xmath82 , @xmath83 , @xmath84 , @xmath85 and @xmath86 </S>",
    "<S> . we will discuss the proof of eq .  </S>",
    "<S> ( [ bayesian jarzynski equality ] ) later .    by using the jensen inequality for convex functions , i.e. , @xmath87\\rangle\\geq\\exp[\\langle{g}\\rangle]$ ] , </S>",
    "<S> we obtain @xmath88 which is a novel generalization of the second law of thermodynamics for subsystem @xmath25 in the presence of complex information flows .    in the following , </S>",
    "<S> we illustrate that our main result ( [ bayesian jarzynski equality ] ) can reproduce known nonequilibrium relations for special cases in a unified way , and moreover , can lead to new generalizations of the ift .    _ </S>",
    "<S> example 1._we consider        the markov chain shown in fig .  </S>",
    "<S> [ fig : bayesian2](a ) . </S>",
    "<S> we have @xmath89 and @xmath90 , and therefore @xmath91 , @xmath92 , and @xmath93 . </S>",
    "<S> we then reproduce the conventional ift : @xmath94\\right>=1 $ ] , which leads to inequality ( [ second law ] ) .    _ </S>",
    "<S> example 2._we next consider a system with feedback control shown in fig .  [ fig : bayesian2](b ) , where @xmath40 describes a state of the memory . </S>",
    "<S> state @xmath38 is measured by the memory , and the outcome @xmath40 is used for the feedback control . </S>",
    "<S> we have @xmath95 and @xmath90 , and therefore @xmath96 , @xmath92 , @xmath97 , and @xmath98 . </S>",
    "<S> we then reproduce a generalized ift obtained in ref .  </S>",
    "<S> @xcite : @xmath99\\right>=1 $ ] , which leads to inequality ( [ information thermodynamics ] ) . </S>",
    "<S> we note that in the case of the discrete repeated feedback , a previous result  @xcite can be derived from eqs . </S>",
    "<S> ( [ bayesian jarzynski equality ] ) and ( [ bayesian information thermodynamics ] ) ( see the supplemental material ) .    _ </S>",
    "<S> example 3._we next consider the two - dimensional langevin equation that describes an interaction between two brownian particles : @xmath100 where @xmath101 is time , @xmath102 and @xmath103 are friction coefficients , @xmath104 and @xmath105 are mechanical forces , and @xmath106 and @xmath107 are independent white - gaussian noises with variances @xmath108 and @xmath109 , respectively . </S>",
    "<S> let @xmath110 be an infinitesimal time interval . </S>",
    "<S> we discretize the dynamics as @xmath111 and @xmath112 , and introduce the corresponding bn by fig .  [ fig : bayesian2 ] ( c ) where system @xmath25 corresponds to one particle with coordinate @xmath113 . </S>",
    "<S> we then have @xmath114 and @xmath90 , and therefore @xmath115 , @xmath92 , @xmath116 [ @xmath117 , and @xmath118 . </S>",
    "<S> we note that @xmath119 , where @xmath120 is the heat absorbed by system @xmath25 from the bath  @xcite ( see the supplemental material for details ) .    in this case , </S>",
    "<S> inequality ( [ bayesian information thermodynamics ] ) implies that the entropy production of one particle is bounded by the information flow into the other particle and the final correlation with it . </S>",
    "<S> as shown in the supplemental material , such a result is valid for multidimensional cases , in general , which enables us to characterize the entropy production in one particle that interacts with multiple particles in terms of information exchanges between them . </S>",
    "<S> we note that the entropy production in a single particle of a multidimensional langevin system is closely related to experiments on the role of the hidden degrees of freedom  @xcite .    </S>",
    "<S> _ model of biological adaptation._we next discuss an application of our general result to a biochemical system . </S>",
    "<S> the significance of information processing in biochemical networks has been presented , for example , in refs .  </S>",
    "<S> @xcite . </S>",
    "<S> in particular , feedback control plays a key role in biological adaptations such as bacterial chemotaxis  @xcite . </S>",
    "<S> we show that the free - energy difference is bounded by an informational quantity in the presence of a chemical feedback loop in a simple model of adaptation with the time - delay effect  @xcite .     and memory @xmath121 . </S>",
    "<S> for instance , @xmath122 at time @xmath123 depends on @xmath40 and @xmath124.,width=321 ]    the model is characterized by a negative feedback loop between two systems : output system @xmath125 and memory system @xmath121 ( see fig .  </S>",
    "<S> [ fig : bayesian3 ]  ( a ) ) . </S>",
    "<S> we assume that each of @xmath125 and @xmath121 has a binary state described by @xmath126 or @xmath127 . </S>",
    "<S> this model is described by the following master equations : @xmath128 where @xmath129 and @xmath130 are , respectively , the probabilities of the states @xmath126 and @xmath131 with @xmath132 at time @xmath101 . the transition rate @xmath133 ( @xmath134 ) is assumed to be @xmath135 \\right\\},\\ ] ] where @xmath136 is a time constant , @xmath137 is the inverse temperature of a heat bath coupled to @xmath25 , @xmath138 is the effective free energy of the state @xmath139 at time @xmath101 , @xmath140 is a barrier that satisfies @xmath141 . </S>",
    "<S> this transition rate is well established in chemical reaction models  @xcite .    </S>",
    "<S> let @xmath142 ( @xmath143 ) be the state of @xmath125 ( @xmath121 ) at time @xmath144 ( @xmath145 ) , where @xmath146 is the time interval with @xmath147 . </S>",
    "<S> the feedback loop between @xmath125 and @xmath121 is described by @xmath148 ( @xmath122 ) that depends on @xmath142 ( @xmath143 ) [ see also fig .  [ </S>",
    "<S> fig : bayesian3](c ) ] ; we assume that @xmath148 depends on @xmath142 at time @xmath149 , and that @xmath122 depends on @xmath150 and @xmath143 at time @xmath151 . </S>",
    "<S> the @xmath143 dependence of @xmath122 describes the effect of time - delayed feedback .    by applying eqs . </S>",
    "<S> ( [ fin mutual information])([bayesian information thermodynamics ] ) to the bn in fig .  </S>",
    "<S> [ fig : bayesian3](b ) , we obtain two inequalities in the time evolution from @xmath152 to @xmath153 : @xmath154 @xmath155 where @xmath156 is equal to the effective free - energy difference in this system ( see supplemental material ) . </S>",
    "<S> the right - hand sides of eqs . </S>",
    "<S> ( [ 2-shanon ] ) and ( [ 3-shanon ] ) are the changes in the two - body and three - body shannon entropies , respectively . </S>",
    "<S> this three - body shannon entropy includes the states of different times @xmath40 and @xmath124 . </S>",
    "<S> this is a crucial difference between the conventional thermodynamics and our result . </S>",
    "<S> we numerically illustrate the validity of eq . </S>",
    "<S> ( [ 3-shanon ] ) in fig .  </S>",
    "<S> [ fig : bayesian4 ] . </S>",
    "<S> we stress that these bounds are calculated from the probability distribution that can be experimentally measured in principle  @xcite .    . </S>",
    "<S> we set the initial states to @xmath157 . </S>",
    "<S> the amount of @xmath158 is close to @xmath126 when the initial states are close to the stationary state of this system . </S>",
    "<S> the parameter set is noted in supplemental material.,width=340 ]    _ derivation of the main result._from the definition of @xmath73 in eqs . </S>",
    "<S> ( [ partition])([transfer entropy ] ) , we obtain @xmath159 \\nonumber\\\\ \\!&=\\ ! </S>",
    "<S> \\ln \\frac{p(x_1)p(x_n , \\mathcal{c})}{p(x_n)p(x_1|{\\rm pa}(x_1))\\prod_{l=1}^{n ' } p(c_l|{\\rm pa}(c_l))}\\nonumber\\\\ \\!&=\\ ! </S>",
    "<S> \\ln \\frac{p(x_1)p(x_n , \\mathcal{c})\\prod_{k=2}^{n}p(x_{k}|{\\rm pa}(x_{k}))}{p(x_n)p(x , \\mathcal{c})}. \\label{calculation}\\end{aligned}\\ ] ] we then use mathematical properties of bns  @xcite : @xmath160 and @xmath161 ( see the supplemental material ) . from eqs . </S>",
    "<S> ( [ definition of joint probability ] ) , ( [ definition of heat ] ) and ( [ calculation ] ) , we arrive at the main result ( [ bayesian jarzynski equality ] ) @xmath162 \\right > \\!&=\\!\\sum_{\\mathcal{a } } p(\\mathcal{d}|\\mathcal{c},x)\\prod_{k=2}^{n } p_b(x_{k-1}| x_{k } , \\mathcal{b}^{k})p(x_n,\\mathcal{c } ) \\nonumber\\\\ \\!&=\\!\\ 1 , \\label{derivation}\\end{aligned}\\ ] ] where @xmath163 . here , we used @xmath164 ( @xmath165 ) and the normalization of the probability .    _ </S>",
    "<S> conclusion._in general causal networks , we have derived a novel generalization of the ift [ eq .  </S>",
    "<S> ( [ bayesian jarzynski equality ] ) ] . </S>",
    "<S> we have obtained a generalized second law of thermodynamics  ( [ bayesian information thermodynamics ] ) , which sets a fundamental bound on the entropy production of a single system in the presence of multiple other systems , where the exchanged information between these systems plays a crucial role .    </S>",
    "<S> we are grateful to m. sano , h. hayakawa , m. l. rosinberg , j. m. horowitz , k. kanazawa and h. tasaki for valuable comments . </S>",
    "<S> we acknowledge yitp at kyoto university . </S>",
    "<S> this work was supported by a grants - in - aid from jsps ( grant no . </S>",
    "<S> 24@xmath1668593 ) , by jsps kakenhi grant no . </S>",
    "<S> 25800217 , and by the platform for dynamic approaches to living system from mext , japan . </S>"
  ]
}