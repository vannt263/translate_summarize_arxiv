{
  "article_text": [
    "one of the most important techniques in learning about the functioning of the brain has involved examining neuronal activity in laboratory animals under varying experimental conditions .",
    "neural information is represented and communicated through series of action potentials , or spike trains , and the central scientific issue in many studies concerns the physiological significance that should be attached to a particular neuron firing pattern in a particular part of the brain .",
    "in addition , a major relatively new effort in neurophysiology involves the use of multielectrode recording , in which responses from dozens of neurons are recorded simultaneously .",
    "much current research focuses on the information that may be contained in the interactions among neurons .",
    "of particular interest are spiking events that occur across neurons in close temporal proximity , within or near the typical one millisecond accuracy of the recording devices . in this paper",
    "we provide a point process framework for analyzing such nearly synchronous events .",
    "the use of point processes to describe and analyze spike train data has been one of the major contributions of statistics to neuroscience .",
    "on the one hand , the observation that individual point processes may be considered , approximately , to be binary time series allows methods associated with generalized linear models to be applied [ cf .",
    "brillinger ( @xcite , @xcite ) ] . on the other hand ,",
    "basic point process methodology coming from the continuous - time representation is important both conceptually and in deriving data - analytic techniques [ e.g. , the time - rescaling theorem may be used for goodness of fit and efficient spike train simulation ; see brown et al .",
    "( @xcite ) ] .",
    "the ability to go back and forth between continuous time , where neuroscience and statistical theory reside , and discrete time , where measurements are made and data are analyzed , is central to statistical analysis of spike trains . from the discrete - time perspective ,",
    "when multiple spike trains are considered simultaneously it becomes natural to introduce loglinear models [ cf .",
    "martignon et al .",
    "( @xcite ) ] and a widely read and hotly debated report by schneidman et al .",
    "( @xcite ) examined the extent to which pairwise dependence among neurons can capture stimulus - related information .",
    "a fundamental limitation of much of the work in this direction , however , is its reliance on stationarity .",
    "the main purpose of the framework described below is to handle the nonstationarity inherent in stimulus - response experiments by introducing appropriate loglinear models while also allowing passage to a continuous - time limit .",
    "the methods laid out here are in the spirit of ventura , cai and kass ( @xcite ) , who proposed a  bootstrap test of time - varying synchrony , but our methods are different in detail and our framework is much more general",
    ".     units . on each trial",
    "there are several dark bands , which constitute bursts of network activity sometimes called `` up states . ''",
    "up state epochs vary across trials , indicating they are not locked to the stimulus . ]",
    "statistical modeling of point process data focuses on intensity functions , which represent the rate at which the events occur , and often involve covariates [ cf .",
    "brown et al .",
    "( @xcite ) , kass , ventura and brown ( @xcite ) , paninski et al .",
    "( @xcite ) and references therein ] .",
    "a basic distinction is that of _ conditional _ versus _ marginal _ intensities : the conditional intensity determines the event rate for a given realization of the process , while the marginal intensity is the expectation of the conditional intensity across realizations . in neurophysiological experiments stimuli are often presented repeatedly across many trials , resulting in many replications of the multiple sequences of spike trains .",
    "this is the situation we concern ourselves with here , and it is illustrated in figure [ fig1 ] , part a , where the responses of a single neuron for 120 trials are displayed : each line of the raster plot shows a single spike train , which is the neural response on a single trial . the experiment that generated these data",
    "is described in section [ sec : example ] .",
    "the bottom panel in part a of figure  [ fig1 ] displays a smoothed peristimulus time histogram ( psth ) , which summarizes the trial - averaged response by pooling across trials . as we explain in greater detail in section [ sec : overview ] , scientific questions and statistical analyses may concern either within - trial responses ( conditional intensities ) or trial - averaged responses ( marginal intensities ) .",
    "a point process evolves in continuous time but , as we have noted , it is convenient for many statistical purposes to consider a discretized version .",
    "decomposing time into bins of width @xmath0 , we may define a binary time series to be 1 for every time bin in which an event occurs , and 0 for every bin in which an event does not occur .",
    "it is not hard to show that , under the usual regularity condition that events occur discretely ( i.e. , no two events occur at the same time ) , the likelihood function of the binary time series approximates the likelihood of the point process as @xmath1 . for a pair of point processes ,",
    "the discretized process is a time series of @xmath2 polytomous variables indicating , in each time bin , whether an event of the first process occurred , an event of the second process occurred , or both , or neither .",
    "this suggests analyzing nearly synchronous events based on a loglinear model with cell probabilities that vary across time .",
    "intuitive as such procedures may be , their point process justification is subtle : the standard regularity condition forbids two processes having synchronous events , so it is not obvious how we might obtain convergence to a point process ( as @xmath1 ) for discrete - process likelihoods that incorporate synchrony .    one way out of this impasse is to introduce a marked point process framework in which each event / mark could be of three distinct types : first process , second process , or both .",
    "the standard marked point process requires modification , however , because it fails to accommodate independence as a special case .",
    "under independence , the discretized events for each process occur with probability of order @xmath3 , while the synchronous events occur with probability of order @xmath4 as @xmath1 .",
    "we refer to this as a _ sparsity _ condition , and the generalization to multiple processes involves a _",
    "hierarchical sparsity _ condition .",
    "once we introduce a family of marked point processes indexed by @xmath0 , we can guarantee hierarchical sparsity . not only does this allow , as it must , the special case of independence models , but it also makes the conditional intensity for neuron @xmath5 depend only on the history for neuron @xmath5 , asymptotically ( as @xmath1 ) .",
    "this in turn avoids confounding the dependence described by the loglinear model and greatly reduces the dimensionality of the problem .",
    "we require two very natural regularity conditions based on well - known neurophysiology : the existence of a refractory period , during which the neuron can not spike again , and smoothness of the conditional intensity across time .",
    "it would be possible , and sometimes advantageous , instead to model dependence through the individual - neuron conditional intensity functions .",
    "the loglinear modeling approach used here avoids this step .      in a series of experiments performed by one of us ( kelly , together with dr .",
    "matthew smith ) , visual images were displayed at resolution @xmath6 pixels on a computer monitor , while the neural responses in the primary visual cortex of an anesthetized monkey were recorded .",
    "each of 98 distinct images consisted of a sinusoidal grating that drifted in a particular direction for 300 milliseconds , and each was repeated 120 times .",
    "each repetition of the complete sequence of stimuli lasted approximately 30 seconds .",
    "this kind of stimulus has been known to drive cells in the primary visual cortex since the nobel prize - winning work of hubel and wiesel in the 1960s . with improved technology and advanced analytical strategies , much more precise descriptions of neural response",
    "are now possible .",
    "a small portion of the data from 5 repetitions of many stimuli is shown in part c of figure [ fig1 ] .",
    "the details of the experiment and recording technique are reported in kelly et al .",
    "( @xcite ) .",
    "a total of 125 neural `` units '' were obtained , which included about 60 well - isolated individual neurons ; the remainder were of undetermined origin ( some mix of 1 or more neurons ) .",
    "the goal was to discover the interactions among these units in response to the stimuli .",
    "each neuron will have its own consistent pattern of responses to stimuli , as illustrated in parts a and b of figure [ fig1 ] .",
    "synchronous spiking across neurons is relatively rare .",
    "however , in each of the 5 blocks within part c of figure [ fig1 ] ( each block corresponding to a single trial ) several dark bands of activity across most neurons may be seen during the trial .",
    "these bands correspond to what are often called network `` up '' states , and are often seen under anesthesia . for discussion and references",
    "see kelly et al .",
    "( @xcite ) .",
    "it would be of interest to separate the effects of such network activity from other synchronous activity , especially stimulus - related synchronous activity .",
    "the framework in this paper provides a foundation for statistical methods that can solve such problems .",
    "we begin with some notation .",
    "suppose we observe the activity of an ensemble of @xmath7 neurons labeled @xmath8 to @xmath7 over a time interval @xmath9 , where @xmath10 is a constant .",
    "let @xmath11 denote the total number of spikes produced by neuron @xmath5 on @xmath9 where @xmath12 .",
    "the resulting ( stochastic ) sequence of spike times is written as @xmath13 . for the moment we focus on the case @xmath14 , but other values of @xmath7 are of interest and with contemporary recording technology @xmath15",
    "is not uncommon , as in the experiment in section  [ sec : example ] .",
    "let @xmath16 be a constant such that @xmath17 is a multiple of @xmath0 ( for simplicity ) .",
    "we divide the time interval into bins of width @xmath0 .",
    "define @xmath18 if neuron @xmath5 has a spike in the time bin @xmath19 and @xmath20 otherwise .",
    "because of the existence of a  refractory period for each neuron , there can be at most 1 spike in @xmath19 from the same neuron if @xmath0 is sufficiently small .",
    "then writing @xmath21 the data would involve spike counts across trials [ e.g. , the number of trials on which @xmath22 @xmath23 . the obvious statistical tool for analyzing spiking dependence is loglinear modeling and associated methodology .",
    "three complications make the problem challenging , at least in principle .",
    "first , there is nonstationarity : the probabilities vary across time .",
    "the data thus form a  sequence of @xmath24 contingency tables .",
    "second , absent from the above notation is a possible dependence on spiking history .",
    "such dependence is the rule rather than the exception .",
    "let @xmath25 denote the set of values of @xmath26 , where @xmath27 , and @xmath28 are multiples of @xmath0 .",
    "thus , @xmath29 is the history of the binned spike train up to time @xmath30 . we may wish to consider conditional probabilities such as @xmath31 for @xmath32 .",
    "third , there is the possibility of precisely timed lagged dependence ( or time - delayed synchrony ) : for example , we may want to consider the probability @xmath33 where @xmath34 may be distinct . similarly , we might consider the conditional probability @xmath35 in principle , we would want to consider all possible combinations of lags . even for @xmath14 neurons , but",
    "especially as we contemplate @xmath36 , strong restrictions must be imposed in order to have any hope of estimating all these probabilities from relatively sparse data in a small number of repeated trials . to reduce model dimensionality , we suggest four seemingly reasonable tactics : ( i ) considering models with only low - order interactions , ( ii ) assuming the probabilities @xmath37 or @xmath38 vary smoothly across time @xmath30 , ( iii )  restricting history effects to those that modify a neuron s spiking behavior based on its own past spiking , and then ( iv ) applying analogues to standard loglinear model methodology .",
    "combining these , we obtain tractable models for multiple binary time series to which standard methodology , such as maximum likelihood and smoothing , may be applied . in modeling synchronous spiking events as loglinear time series , however , it would be highly desirable to have a continuous - time representation , where binning becomes an acknowledged approximation . we therefore also provide a theoretical point process foundation for the discrete multivariate methods proposed here .",
    "it is important to distinguish the probabilities @xmath39 and @xmath40 .",
    "the former are trial - averaged or _ marginal _ probabilities , while the latter are within - trial or _ conditional _ probabilities .",
    "both might be of interest but they quantify different things . as an extreme example suppose , as sometimes is observed , each of two neurons has highly rhythmic spiking at an approximately constant phase relationship with an oscillatory potential produced by some large network of cells . marginally these neurons will show strongly dependent spiking . on the other hand , after taking account of the oscillatory rhythm by conditioning on each neuron s spiking history and/or a  suitable within - trial time - varying covariate , that dependence may vanish .",
    "such a  finding would be informative , as it would clearly indicate the nature of the dependence between the neurons .",
    "in section [ sec : analysis ] we give a less dramatic but similar example taken from the data described in section [ sec : example ] .",
    "we treat marginal and conditional analyses separately .",
    "our use of two distinct frameworks is a consequence of the way time resolution will affect continuous - time approximations .",
    "we might begin by imagining the situation in which event times could be determined with infinite precision . in this case",
    "it is natural to assume , as is common in the point process literature , that no two processes have simultaneous events .",
    "as we indicate , this conception may be applied to marginal analysis .",
    "however , the event times are necessarily recorded to fixed accuracy , which becomes the minimal value of @xmath0 , and @xmath0 may be sufficiently large that simultaneous events become a practical possibility .",
    "many recording devices , for example , store neural spike event times with an accuracy of 1 millisecond . furthermore , the time scale of physiological synchrony ",
    "the proximity of spike events thought to be physiologically meaningful  is often considered to be on the order of @xmath41 milliseconds [ cf .",
    "grn , diesmann and aertsen ( @xcite , @xcite ) and grn ( @xcite ) ] . for within - trial analyses of synchrony , the theoretical conception of simultaneous ( or synchronous ) spikes across multiple trials therefore becomes important and leads us to the formalism detailed below .",
    "the framework we consider here provides one way of capturing the notion that events within @xmath0 milliseconds of each other are essentially synchronous .",
    ", when false positive rate is set at 10% . in top plot",
    "the joint spikes are from the history - independent model , as in ( [ loglin2.marginal ] ) , while in the bottom plot they are as in ( [ loglin2.conditional ] ) , including the network covariate in the history term .",
    "part roc curves for the models in part  .",
    "parts , , and are similar to parts and but for the second pair of neurons . ]",
    "the rest of this article is organized as follows .",
    "section [ sec2 ] presents the methodology in three subsections : sections [ sec21 ] and [ sec22 ] introduce marginal and conditional methods in the simplest case , while section [ sec : loglinear ] discusses the use of loglinear models and associated methodology for analyzing spiking dependence . in section [ sec : analysis ] we illustrate the methodology by returning to the example of section [ sec : example ] .",
    "the main purpose of our approach is to allow covariates to take account of such things as the irregular network rhythm displayed in figure [ fig1 ] , so that synchrony can be understood as either related to the network effects or unrelated .",
    "figure [ fig2 ] displays synchronous spiking events for two different pairs of neurons , together with accompanying fits from continuous - time loglinear models . for both pairs",
    "the independence model fails to account for synchronous spiking .",
    "however , for one pair the apparent excess synchrony disappears when history effects are included in the loglinear model , while in the other pair they do not , leading to the conclusion that in the second case the excess synchrony must have some other source .",
    "theory is presented in sections [ sec : process][sec : conditional ] .",
    "we add some discussion in section [ sec7 ] .",
    "all proofs in this article are deferred to the .",
    "in this section we present our continuous - time loglinear modeling methodology .",
    "we begin with the simplest case of @xmath42 neurons , presenting the main ideas in sections [ sec21 ] and [ sec22 ] for the marginal and conditional cases , respectively , in terms of the probabilities @xmath43 , @xmath44 , etc .",
    ", for all @xmath45 .",
    "we show how we wish to pass to the continuous - time limit , thereby introducing point process technology and making sense of continuous - time smoothing , which is an essential feature of our approach . in section [ sec : loglinear ] we reformulate using loglinear models , and then give continuous - time loglinear models for @xmath14 . our analyses in section [ sec : analysis ]",
    "are confined to @xmath42 and @xmath14 because of the paucity of higher - order synchronous spikes in our data .",
    "our explicit models for @xmath14 should make clear how higher - order models are created .",
    "we give general recursive formulas in sections [ sec : marginal ] and [ sec : conditional ] .",
    "the null hypothesis @xmath46 is a statement that both neurons spike in the interval @xmath47 , on the average , at the rate determined by independence .",
    "defining @xmath48 by @xmath49 we may rewrite ( [ eq:2.1 ] ) as @xmath50 as in ventura , cai and kass ( @xcite ) , to assess @xmath51 , the general strategy we follow is to ( i ) smooth the observed - frequency estimates of @xmath52 , @xmath53 and @xmath54 across time @xmath30 , and then ( ii ) form a suitable test statistic and compute a @xmath55-value using a bootstrap procedure . we may deal with time - lagged hypotheses similarly , for example",
    ", for a lag @xmath56 , we write @xmath57\\\\ [ -8pt ]   & = & p^1_1 ( t ) p^2_1 ( t+ \\delta h ) \\zeta(t , t + \\delta h),\\nonumber\\end{aligned}\\ ] ] then smooth the observed - frequency estimates for @xmath58 as a function of  @xmath30 , form an analogous test statistic and find a @xmath55-value .    to formalize this approach",
    ", we consider counting processes @xmath59 corresponding to the point processes @xmath60 , @xmath61 ( as in section [ sec : overview ] with @xmath42 ) . under regularity conditions ,",
    "the following limits exist : @xmath62 consequently , for small @xmath0 , we have @xmath63 the smoothing of the observed - frequency estimates for @xmath64 may be understood as producing an estimate @xmath65 for @xmath66 .",
    "the null hypothesis in  ( [ eq:2.1 ] ) becomes , in the limit as @xmath67 , @xmath68 or , equivalently , @xmath69 the lag @xmath70 case is treated similarly . under mild conditions , theorems [ tm:4.3 ] and [ tm:4.2 ] of section [",
    "sec : marginal ] show that the above heuristic arguments hold for a continuous - time regular marked point process .",
    "this in turn gives a rigorous asymptotic justification ( as @xmath71 ) for estimation and testing procedures such as those in steps ( i ) and ( ii ) mentioned above , following ( [ eq:2.63 ] ) , and illustrated in section  [ sec : analysis ] .      to deal with history effects , equation ( [ eq:2.7 ] )",
    "is replaced with @xmath72 where @xmath25 , @xmath73 , are , as in section [ sec1 ] , the binned spiking histories of neurons 1 and 2 , respectively , on the interval @xmath74 .",
    "analogous to ( [ eq:2.63 ] ) , the null hypothesis is @xmath75 we note that there are two substantial simplifications in ( [ eq:2.8 ] ) .",
    "first , @xmath76 , which says that neuron @xmath5 s own history @xmath25 is relevant in modifying its spiking probability ( but not the other neuron s history ) .",
    "second , @xmath77 does not depend on the spiking history @xmath78 .",
    "this is important for what it claims about the physiology , for the way it simplifies statistical analysis , and for the constraint it places on the point process framework .",
    "physiologically , it decomposes excess spiking into history - related effects and stimulus - related effects , which allows the kind of interpretation alluded to in section [ sec1 ] and presented in our data analysis in section  [ sec : analysis ] .",
    "statistically , it improves power because tests of @xmath51 effectively pool information across trials , thereby increasing the effective sample size .",
    "consider counting processes @xmath59 , @xmath73 , as in section [ sec21 ] . under regularity conditions ,",
    "the following limits exist for @xmath79 : @xmath80 where @xmath81 and @xmath82 . for sufficiently small @xmath0 , we have @xmath83 for all @xmath84 . again following ventura , cai and kass ( @xcite ) ,",
    "we may smooth the observed - frequency estimates of @xmath85 to produce an estimate of @xmath86 , and smooth the observed - frequency estimates of @xmath87 to produce estimates of @xmath88 , @xmath73 . letting @xmath67 in ( [ eq:2.8 ] ) , we obtain @xmath89 consequently , for sufficiently small @xmath0 , a conditional test of @xmath90 for all  @xmath91 becomes a test of the null hypothesis @xmath92 for all @xmath30 or , equivalently , in this conditional case we have the same null hypothetical statement as ( [ h0xi1 ] ) .    in attempting to make equation ( [ eq:2.83 ] ) rigorous",
    ", a difficulty arises : for a  regular marked point process , the function @xmath93 need not be independent of the spiking history .",
    "this would create a fundamental mismatch between the discrete data - analytical method and its continuous - time limit .",
    "the key to avoiding this problem is to enforce the sparsity condition ( [ eq : sparse2 ] ) . specifically , the probabilities @xmath94 are of order @xmath3 , while the probabilities @xmath95 are of order @xmath4 .",
    "this also allows independence models within the marked point process framework .",
    "section [ sec : conditional ] proposes a class of marked point process models indexed by @xmath0 and provides results that validate the heuristics above .",
    "we now reformulate in terms of loglinear models the procedures sketched in sections [ sec21 ] and [ sec22 ] for @xmath42 neurons , and then indicate the way generalizations proceed when @xmath96 .    in the marginal case of section [ sec21 ] ,",
    "it is convenient to define @xmath97 equation ( [ eq:2.7 ] ) implies that @xmath98 =   a \\log [ p^1_1 ( t ) ] +   b \\log [ p^2_1 ( t ) ] + ab   \\log [ \\zeta ( t ) ] \\ ] ] for all @xmath99 and @xmath84 and in the continuous - time limit , using ( [ eq:2.2 ] ) , we write @xmath100\\ ] ] for @xmath79 . the null hypothesis",
    "may then be written as @xmath101 = 0\\qquad\\forall   t\\in [ 0 , t).\\ ] ] in the conditional case of section 2.2 , we similarly define @xmath102 we may rewrite ( [ eq:2.8 ] ) as the loglinear model @xmath103 =   a \\log [ p^1_1 ( t| \\bar{\\mathcal h}_t^1 ) ] +   b \\log [ p^2_1 ( t| \\bar{\\mathcal h}_t^2 ) ] + ab \\log [ \\zeta ( t ) ] \\ ] ] for all @xmath99 and @xmath84 and in the continuous - time limit we rewrite ( [ eq:2.84 ] ) in the form @xmath104\\ ] ] for @xmath79 .",
    "the null hypothesis may again be written as in ( [ eq : h0log.xi ] ) .",
    "rewriting the model in loglinear forms ( [ loglinear2 ] ) , ( [ loglin2.marginal ] ) , ( [ loglinear2h ] ) and ( [ loglin2.conditional ] ) allows us to generalize to @xmath105 neurons .",
    "for example , with the obvious extensions of the previous definitions , for @xmath14 neurons the two - way interaction model in the continuous - time marginal case becomes @xmath106 & = &    \\log [ p^1_1 ( t ) ] +    \\log [ p^2_1 ( t ) ] +     \\log [ p^3_1 ( t ) ] \\nonumber\\\\ [ -8pt]\\\\ [ -8pt ] & & { } + ab   \\log \\bigl [ \\zeta_{\\{1,2\\ } } ( t ) \\bigr ] + ac   \\log \\bigl [ \\zeta_{\\{1,3\\ } } ( t ) \\bigr ] + bc   \\log \\bigl [ \\zeta_{\\{2,3\\ } } ( t ) \\bigr]\\nonumber\\end{aligned}\\ ] ] for all @xmath32 and @xmath84 , and @xmath107 & = &    \\log [ \\lambda^1 ( t ) ] +    \\log [ \\lambda^2 ( t ) ] +     \\log [ \\lambda^3 ( t ) ] \\\\ & & { } +    \\log \\bigl [ \\xi_{\\{1,2\\ } } ( t ) \\bigr ] +    \\log \\bigl [ \\xi_{\\{1,3\\ } } ( t ) \\bigr ] + \\log \\bigl [ \\xi_{\\{2,3\\ } } ( t ) \\bigr]\\nonumber\\end{aligned}\\ ] ] for all @xmath108 $ ] .",
    "the general form of ( [ loglinear3 ] ) is given by equation ( [ eq:4.91 ] ) in section  [ sec : marginal ] .",
    "in the conditional case , the two - way interaction model becomes @xmath109 & = &   a \\log [ p^1_1 ( t|\\bar{\\mathcal h}_t ) ] +   b \\log [ p^2_1 ( t|\\bar{\\mathcal h}_t ) ] + c \\log [ p^3_1 ( t|\\bar{\\mathcal h}_t ) ] \\nonumber\\\\ [ -8pt]\\\\ [ -8pt ] & & { } + ab   \\log \\bigl [ \\zeta_{\\{1,2\\ } } ( t ) \\bigr ] + ac   \\log \\bigl [ \\zeta_{\\{1,3\\ } } ( t ) \\bigr ] + bc   \\log \\bigl [ \\zeta_{\\{2,3\\ } } ( t ) \\bigr]\\nonumber\\end{aligned}\\ ] ] for all @xmath32 and @xmath84 and in continuous time , @xmath110 & = &    \\log [ \\lambda^1 ( t|{\\mathcal h}_t ) ] +    \\log [ \\lambda^2 ( t|{\\mathcal h}_t ) ] +     \\log [ \\lambda^3 ( t|{\\mathcal h}_t ) ] \\\\ & & { } +    \\log \\bigl [ \\xi_{\\{1,2\\ } } ( t ) \\bigr ] +    \\log\\bigl [ \\xi_{\\{1,3\\ } } ( t ) \\bigr ] + \\log \\bigl [ \\xi_{\\{2,3\\ } } ( t ) \\bigr]\\end{aligned}\\ ] ] for all @xmath108 $ ] . in either the marginal or conditional case",
    ", the null hypothesis of independence may be written as @xmath111 = 0\\qquad \\forall t\\in ( 0 , t ] , 1\\leq i < j \\leq 3.\\ ] ] on the other hand , we could include the additional term @xmath112 $ ] and use the null hypothesis of no three - way interaction @xmath113=0 \\qquad",
    "\\forall t\\in ( 0 , t].\\ ] ]    these loglinear models offer a simple and powerful way to study dependence among neurons when spiking history is taken into account .",
    "they have an important dimensionality reduction property in that the higher - order terms are asymptotically independent of history . in practice , this provides a huge advantage : the synchronous spikes are relatively rare ; in assessing excess synchronous spiking with this model , the data may be pooled over different histories , leading to a much larger effective sample size . the general conditional model in equation ( [ eq:5.76 ] ) retains this structure .",
    "an additional feature of these loglinear models is that time - varying covariates may be included without introducing new complications . in section [ sec : analysis ] we use a covariate to characterize the network up states , which are visible in part  c of figure [ fig1 ] , simply by including it in calculating each of the individual - neuron conditional intensities @xmath114 and @xmath115 in ( [ loglin2.conditional ] ) .    sometimes , as in the data we analyze here , the synchronous events are too sparse to allow estimation of time - varying excess synchrony and we must assume it to be constant , @xmath116 for all @xmath30 .",
    "thus , for @xmath42 , the models of ( [ loglinear2 ] ) or ( [ loglinear2h ] ) take simplified forms in which @xmath77 is replaced by the constant @xmath117 and we would use different test statistics to test the null hypothesis @xmath118 . to distinguish the marginal and conditional cases , we replace @xmath77 by @xmath119 in ( [ loglinear2h ] ) and then also write @xmath120 . moving to continuous time , which is simpler computationally , we write @xmath121 , estimate @xmath93 and @xmath122 , and test @xmath123 and @xmath124 .",
    "specifically , we apply the loglinear models ( [ loglinear2 ] ) , ( [ loglin2.marginal ] ) , ( [ loglinear2h ] ) and ( [ loglin2.conditional ] ) in two steps .",
    "first , we smooth the respective psths to produce smoothed curves @xmath125 , as in parts a and b of figure [ fig1 ] .",
    "second , ignoring estimation uncertainty and taking @xmath126 , we estimate the constant @xmath117 .",
    "using the point process representation of joint spiking ( justified by the results in sections [ sec : marginal ] and [ sec : conditional ] ) , we may then write @xmath127 where the sum is over the joint spike times @xmath128 and @xmath129 is replaced by the right - hand side of ( [ loglin2.marginal ] ) , in the marginal case , or ( [ loglin2.conditional ] ) , in the conditional case .",
    "it is easy to maximize the likelihood @xmath130 analytically : setting the left - hand side to @xmath131 , in the marginal case we have @xmath132 where @xmath133 is the number of joint ( synchronous ) spikes ( the number of terms in the sum ) , while in the conditional case we have the analogous formula @xmath134 and setting to 0 and solving gives @xmath135 and @xmath136 which , in both cases , is the ratio of the number of observed joint spikes to the number expected under independence .",
    "we apply ( [ eq : zetahat ] ) and ( [ eq : zetahath ] ) in section [ sec : analysis ] . to test @xmath137 and @xmath138",
    ", we use a bootstrap procedure in which we generate spike trains under the relevant null - hypothetical model .",
    "this is carried out in discrete time , and requires all 4 cell probabilities @xmath139 or @xmath140 at every time @xmath141 .",
    "these are easily obtained by subtraction using @xmath142 , @xmath143 , and @xmath144 or , in the conditional case , @xmath145 , @xmath146 , and @xmath147 . as we said above",
    ", @xmath126 is obtained from the preliminary step of smoothing the psth .",
    "similarly , the conditional intensities @xmath148 are obtained from smooth history - dependent intensity models such as those discussed in kass , ventura and brown ( @xcite ) . in the analyses reported here we have used fixed - knot splines to describe variation across time @xmath30 .    in the case of 3 or more neurons the analogous estimates and cell probabilities",
    "must , in general , be obtained by a version of iterative proportional fitting . for @xmath14 , to test the null hypothesis ( [ h02way ] ) , we follow the steps leading to ( [ eq : zetahat ] ) and ( [ eq : zetahath ] ) . under the assumption of constant @xmath149 , we obtain @xmath150 and @xmath151 in section [ sec : analysis ] we fit ( [ loglinear3 ] ) and report a bootstrap test of the hypothesis ( [ h02way ] ) using the test statistic @xmath152 in ( [ eq : zetahat123 ] ) .",
    "we applied the methods of section [ sec : loglinear ] to a subset of the data described in section [ sec : example ] and present the results here .",
    "we plan to report a more comprehensive analysis elsewhere .",
    "we took @xmath153 milliseconds ( ms ) , which is a commonly - used window width in studies of synchronous spiking .",
    "raster plots of spike trains across repeated trials from a pair of neurons are shown in parts a and b of figure [ fig2 ] , with synchronous events indicated by circles .",
    "below each raster plot is a smoothed psth , that is , the two plots show smoothed estimates @xmath154 and @xmath155 of @xmath156 and @xmath157 in ( [ eq:2.2 ] ) , the units being spikes per second .",
    "smoothing was performed by fitting a generalized additive model using cubic splines with knots spaced 100 ms apart . specifically , we applied poisson regression to the count data resulting from pooling the binary spike indicators across trials : for each time bin the count was the number of trials on which a spike occurred . to test @xmath51 under the model in ( [ loglin2.marginal ] ) , we applied ( [ eq : zetahat ] ) to find @xmath158 .",
    "we then computed a parametric bootstrap standard error of @xmath158 by generating pseudo - data from model ( [ loglin2.marginal ] ) assuming @xmath159 .",
    "we generated 1000 such trials , giving 1000 pseudo - data values of @xmath158 , and computed the standard deviation of those values as a standard error , to obtain an observed @xmath160-ratio test statistic of 3.03 ( @xmath161 according to asymptotic normality ) .",
    "the highly significant @xmath160 ratio shows that there is excess sychronous spiking beyond what would be expected from the varying firing rates of the two neurons under independence .",
    "however , it does not address the source of the excess synchronous spiking .",
    "the excess synchronous spiking could depend on the stimulus or , alternatively , it might be due to the slow waves of population activity evident in part ( c ) of figure 1 , the time of which vary from trial to trial and therefore do not depend on the stimulus . to examine the latter possibility",
    ", we applied a within - trial loglinear model as in ( [ loglin2.conditional ] ) except that we incorporated into the history effect not only the history of each neuron but also a covariate representing the population effect . specifically , for neuron @xmath5 ( @xmath73 ) we used the same generalized additive model as before , but with two additional variables .",
    "the first was a variable that , for each time bin , was equal to the number of neuron @xmath5 spikes that had occurred in the previous 100 ms .",
    "the second was a variable that , for each time bin , was equal to the number of spikes that occurred in the previous 100 ms across the whole population of neurons , other than neurons 1 and 2 .",
    "we thereby obtained fitted estimates @xmath162 and @xmath163 of @xmath164 and @xmath165 .",
    "note that the fits for the independence model , defined by applying ( [ h0xi1 ] ) to ( [ eq:2.84 ] ) , now vary from trial to trial due to the history effects . applying ( [ eq : zetahath ] ) , we found @xmath166 , and then again computed a bootstrap standard error of @xmath167 by creating 1000 trials of pseudo - data , giving @xmath168 , for a  @xmath160-ratio of @xmath169 , which is clearly not significant .",
    "raster plots for a different pair of neurons are shown in parts ( e ) and ( f ) of figure [ fig2 ] . the same procedures were applied to this pair . here , the @xmath160-ratio for testing @xmath51 under the marginal model was 3.77 ( @xmath170 ) , while that for testing @xmath51 under the conditional model remained highly significant at 3.57 ( @xmath171 ) with @xmath172 .",
    "in other words , using the loglinear model methodology , we have discovered two pairs of v1 neurons with quite different behavior .",
    "for the first pair , synchrony can be explained entirely by network effects , while for the second pair it can not ; this suggests that , instead , for the second pair , some of the excess synchrony may be stimulus - related .",
    "we also compared the marginal and conditional models ( [ loglin2.marginal ] ) and ( [ loglin2.conditional ] ) using roc curves .",
    "specifically , for the binary joint spiking data we used each model to predict a  spike whenever the intensity was larger than a  given constant : for the marginal case whenever @xmath173 , and for the conditional case whenever @xmath174 . the choice of constants @xmath175 and @xmath176 reflect trade - offs between false positive and true positive rates ( analogous to type i error and power ) and as we vary the constants , the plot of true vs. false positive rates forms the roc curve . to determine the true and false positive rates , we performed ten - fold cross - validation , repeatedly fitting from 90% of the trials and predicting from the remaining 10% of the trials .",
    "the two resulting roc curves are shown in part d of figure [ fig2 ] , labeled as `` no history '' and `` history , '' respectively . to be clear , in the two cases we included the terms corresponding , respectively , to @xmath93 and @xmath177 and in the history case we included both the auto - history and the network history variables specified above .",
    "the roc curve for the conditional model strongly dominates that for the marginal model , indicating far better predictive power .",
    "in part  c of figure [ fig2 ] we display the true positive joint spike predictions when the false - positive rate was held at 10% .",
    "these correctly - predicted joint spikes may be compared to the complete set displayed in parts a and b of the figure .",
    "the top display in part c , labeled `` no history , '' shows that only a few joint spikes were correctly predicted by the marginal model , while the large majority were correctly predicted by the conditional model .",
    "furthermore , the correctly predicted joint spikes are spread fairly evenly across time .",
    "in contrast , the roc curves for the second pair of neurons , shown in part ( g ) of figure [ fig2 ] , are close to each other : inclusion of the history effects ( which were statistically significant ) did not greatly improve predictive power . in ( g ) , the correctly predicted synchronous spikes are clustered in time , with the main cluster occurring near a peak in the individual - neuron firing - rate functions shown in the two smoothed psths in parts ( e ) and ( f ) .",
    "taking all of the results together , our analysis suggests that the first pair of neurons produced excess synchronous spikes solely in conjunction with network effects , which are unrelated to the stimulus , while for the second pair of neurons some of the excess synchronous spikes occurred separately from the network activity and were , instead , stimulus - related .",
    "we also tried to assess whether 2-way interactions were sufficient to explain observed 3-way events by fitting the no-3-way interaction model given by ( [ loglinear3 ] ) , and then testing the null hypothesis in ( [ h02way ] ) .",
    "we did this for a  particular set of 3 neurons , whose joint spikes are displayed in figure [ fig3 ] .",
    "the method is analogous to that carried out above for pairs of neurons , in the sense that the test statistic was @xmath152 given by ( [ eq : zetahat123 ] ) and a parametric bootstrap procedure , based on the fit of ( [ loglinear3 ] ) , was used to compute an approximate @xmath55-value .",
    "fitting of ( [ loglinear3 ] ) required an iterative proportional fitting procedure , which we will describe in detail elsewhere .",
    "we obtained @xmath178 , indicating no significant 3-way interaction .",
    "in other words , for these three neurons , 2-way excess joint spiking appears able to explain the occurrence of the 3-way joint spikes .",
    "however , as may be seen in figure [ fig3 ] , there are very few 3-way spikes in the data .",
    "we mention this issue again in our discussion .",
    "in this section a class of marked point processes for modeling neural spike trains is briefly surveyed . these models",
    "take into account the possibility of two or more neurons firing in synchrony ( i.e. , at the same time ) .",
    "consider an ensemble of @xmath7 neurons labeled  @xmath8 to @xmath7 .",
    "for @xmath10 , let @xmath179 denote the total number of spikes produced by this ensemble on the time interval @xmath9 and let @xmath180 denote the specific spike times .",
    "for each @xmath181 , we write @xmath182 to denote the event that a spike was fired ( synchronously ) at time @xmath183 by ( and only by ) the @xmath184 , @xmath185 , @xmath186 neurons .",
    "we observe that @xmath187 forms a marked point process on the interval @xmath188 with @xmath189 as the mark space satisfying @xmath190 we follow daley and vere - jones ( @xcite ) , page 249 , and define the conditional intensity function of @xmath191 as @xmath192 where @xmath193 is the hazard function for the location of the first spike @xmath194 , @xmath195 the hazard function for the location of the second spike @xmath196 conditioned by @xmath197 , and so on , while @xmath198 is the conditional probability mass function of @xmath199 given @xmath200 , and so on .",
    "it is also convenient to write @xmath201 for all @xmath202 .",
    "the following proposition and its proof can be found in daley and vere - jones  ( @xcite ) , page 251 .",
    "[ pn:8.1 ] let @xmath191 be as in ( [ eq:8.1 ] )",
    ". then the density of @xmath203 is given by @xmath204 \\exp\\biggl [ -\\sum_{\\kappa\\in { \\mathcal k } } \\int_0^t \\lambda ( t , \\kappa| { \\mathcal h}_t)\\,dt \\biggr].\\end{aligned}\\ ] ]",
    "in this section we ( i ) provide a  justification of the limiting statements in ( [ eq:2.2 ] ) and ( ii ) generalize to higher - order models .",
    "we also note that lagged dependence can be accommodated within our framework , treating the case @xmath42 .      in this subsection",
    "we prove that the heuristic arguments of section [ sec2 ] for marginal methods hold under mild conditions .",
    "consider @xmath205 neurons labeled @xmath8 to  @xmath7 .",
    "for @xmath10 , let @xmath179 denote the total number of spikes produced by these @xmath7 neurons on the time interval @xmath188 and let @xmath206 denote the specific spike times .",
    "for each @xmath207 , we write @xmath208 to represent the event that a spike was fired at time @xmath183 by neuron @xmath209 where @xmath210 .",
    "we observe from section [ sec : process ] that @xmath211 forms a marked point process on the interval @xmath188 with mark space @xmath212 . following the notation of section [ sec : process ] , let @xmath213 denote the conditional intensity function of the point process @xmath191 .",
    "we assume that the following two conditions hold :    _ condition _",
    "there exists a strictly positive refractory period for each neuron in that there exists a constant @xmath214 such that @xmath215 if there exists some @xmath216 such that @xmath217",
    ".    _ condition _ ( ii ) . for each @xmath218 and @xmath219 ,",
    "the conditional intensity function @xmath220 is a continuously differentiable function in @xmath221 over the simplex @xmath222 .",
    "if @xmath223 , then condition ( i ) implies that there is at most 1 spike from each neuron in a bin of width @xmath0 . conditions ( i ) and ( ii ) also imply that the marked point process is regular in that ( exactly ) synchronous spikes occur only with probability  0 . theorem [ tm:4.3 ] below gives the limiting relationship between the bin probabilities of the induced discrete - time process and the conditional intensities of the underlying continuous - time marked point process .",
    "[ tm:4.3 ] suppose that conditions and hold , @xmath224 and @xmath225",
    ". then @xmath226,\\end{aligned}\\ ] ] where @xmath227 as @xmath1 and @xmath228 , etc . here",
    "the expectation is taken with respect to @xmath229 .",
    "theorem [ tm:4.3 ] validates the heuristics stated in ( [ eq:2.2 ] ) where @xmath42 , @xmath230,\\\\ \\lambda^{1 , 2 } ( t ) & = & \\frac{1}{2 } \\sum_{1\\leq i_1\\neq i_2\\leq 2 } e \\bigl [ \\lambda \\bigl ( t , ( i_2)| \\ { ( t , ( i_1))\\ } \\cup { \\mathcal h}_t \\bigr ) \\lambda ( t , ( i_1)| { \\mathcal h}_t ) \\bigr].\\end{aligned}\\ ] ]    next we construct the discrete - time loglinear model induced by the above marked point process .",
    "first define recursively for @xmath231 , @xmath232\\\\ [ -8pt ] \\vdots & & \\nonumber \\\\",
    "\\zeta_{\\{i_1 , \\ldots , i_k\\ } } ( t_m ) & = & \\frac { \\delta^{-k } p^{i_1,\\ldots , i_k}_{1,\\ldots , 1 } ( t_m ) } { \\prod_{\\xi\\subsetneq \\{i_1,\\ldots , i_k\\ } } \\zeta_{\\xi } ( t_m ) } \\nonumber\\\\ \\eqntext{\\forall 1\\leq i_1 < \\cdots < i_k \\leq \\nu , 2\\leq k\\leq \\nu.}\\end{aligned}\\ ] ] we further define @xmath233 where @xmath234 , whenever the expression on the right - hand side of ( [ eq:4.57 ] ) is well defined .",
    "the following is an immediate corollary of theorem [ tm:4.3 ] .",
    "[ cy:4.5 ] let @xmath235 and @xmath236 be as in ( [ eq:4.57 ] ) . then with the notation and assumptions of theorem [ tm:4.3 ] , we have @xmath237,\\\\ \\xi_{\\{i_1 , \\ldots , i_k\\ } } ( t ) & = & \\biggl [ k !   \\prod_{\\xi\\subsetneq \\{i_1,\\ldots , i_k\\ } } \\zeta_\\xi ( t )   \\biggr]^{-1}\\\\ & & { } \\times \\sum_{\\{j_1,\\ldots , j_k\\ } = \\{i_1,\\ldots , i_k\\ } }   e   \\prod_{l = 1}^k \\bigl [ \\lambda \\bigl ( t , ( j_k)| \\ { ( t , ( j_1))\\}\\\\   & & \\hphantom{{}\\times \\sum_{\\{j_1,\\ldots , j_k\\ } = \\{i_1,\\ldots , i_k\\ } }   e   \\prod_{l = 1}^k \\bigl [ \\lambda \\bigl ( } \\cup \\cdots \\cup \\ { ( t , ( j_{k-1}))\\ } \\cup { \\mathcal h}_t \\bigr )   \\bigr],\\end{aligned}\\ ] ] whenever the right - hand sides are well defined .",
    "it is convenient to define @xmath238 . for @xmath239 and",
    "not all  0 , define @xmath240 where @xmath241 if and only if @xmath242 .",
    "then using the notation of ( [ eq:4.90 ] ) , the corresponding loglinear model induced by the above marked point process is @xmath243\\nonumber\\\\ & & \\qquad=\\log [ p^{i_1 , \\ldots , i_k}_{1 , \\ldots , 1 } ( t_m ) ] \\\\ & & \\qquad= \\sum_{i=1}^\\nu a_i \\log [ p^i_1 ( t_m ) ] + \\sum_{\\xi\\subseteq \\{1,\\ldots , \\nu\\ } : |\\xi| \\geq 2 }   \\biggl(\\prod_{j\\in \\xi } a_j\\biggr ) \\log [ \\zeta_\\xi ( t_m ) ] \\nonumber\\end{aligned}\\ ] ] for all @xmath244 . under conditions ( i ) and",
    "( ii ) , corollary [ cy:4.5 ] shows that @xmath245 is continuously differentiable .",
    "this gives an asymptotic justification for smoothing the estimates of @xmath246 , @xmath247 .",
    "this subsection considers the lag @xmath70 case for two neurons labeled 1 and 2 .",
    "let @xmath248 be integers such that @xmath249 .",
    "as in ( [ eq:1.35 ] ) , we write @xmath250\\qquad \\forall a , b\\in \\{0,1\\},\\ ] ] where @xmath251 and @xmath252 .",
    "analogous to theorem [ tm:4.3 ] , we have the following results for the lag case .",
    "[ tm:4.2 ] suppose conditions and hold",
    ". then @xmath253,\\ ] ] where @xmath254 and @xmath255 as @xmath71 for some constant @xmath256 . here",
    "the expectation is taken with respect to @xmath257 ( and hence also @xmath229 ) .",
    "let @xmath258 be defined as in ( [ eq:2.42 ] ) . then with the notation and assumptions of theorem [ tm:4.2 ] , we have @xmath259\\\\ [ -8pt ] & & \\hspace*{20pt}\\qquad= \\frac { e [ \\lambda ( t+\\tau , ( 2)| \\ { ( t , ( 1))\\ } \\cup { \\mathcal h}_{t+\\tau } ) \\lambda ( t , ( 1)| { \\mathcal h}_t ) ] } { e [ \\lambda ( t+\\tau , ( 2)| { \\mathcal h}_{t+\\tau } ) ] e [ \\lambda ( t , ( 1)|{\\mathcal h}_t ) ] } \\qquad \\forall 0\\leq t < t-\\tau,\\nonumber\\end{aligned}\\ ] ] whenever the right - hand side is well defined .",
    "we observe from conditions ( i ) and ( ii ) that the right - hand side of ( [ eq:4.78 ] ) is continuously differentiable in @xmath30 .",
    "again this provides an asymptotic justification for smoothing the estimate of @xmath260 , with respect to @xmath30 , when @xmath0 is small .",
    "this section is analogous to section [ sec : marginal ] , but treats the conditional case .",
    "we ( i ) provide a justification of the limiting statements in ( [ eq:2.83 ] ) and ( ii ) generalize to higher - order models .",
    "we again also note that lagged dependence can be accommodated within our framework , treating the case @xmath42 .",
    "this subsection considers @xmath261 neurons labeled @xmath8 to @xmath7 .",
    "we model the spike trains generated by these neurons on @xmath188 by a marked point process @xmath191 with mark space @xmath262 here , for example , the mark @xmath263 denotes the event that neuron @xmath184 ( and only this neuron ) spikes , @xmath264 denotes the event that neuron @xmath184 and neuron @xmath265 ( and only these two neurons ) spike in synchrony ( i.e. , at the same time ) , and the mark @xmath266 denotes the event that all @xmath7 neurons spike in synchrony .",
    "let @xmath267 denote the total number of spikes produced by these neurons on @xmath268 , @xmath269 , and let @xmath270 denote the specific spike times . for each @xmath207",
    ", let @xmath271 be the mark associated with @xmath183",
    ". then @xmath203 can be expressed as @xmath272    given @xmath273 , we write @xmath274 @xmath275 denotes the spiking history of neuron @xmath5 on @xmath74 . the conditional intensity function @xmath276 , @xmath79 and @xmath277 , of the marked point process @xmath191 is defined to be @xmath278\\\\ [ -8pt ] \\lambda ( t , ( i_1 , \\ldots , i_k)| { \\mathcal h}_t ) & = & \\delta^{k-1 } \\gamma_{\\{i_1 , \\ldots , i_k\\ } } ( t ) \\prod_{j=1}^k \\lambda^{i_j } ( t| { \\mathcal h}^{i_j}_t)\\qquad\\forall   t\\in [ 0 , t),\\nonumber\\end{aligned}\\ ] ] where @xmath16 is a constant , @xmath279 s are functions depending only on @xmath30 and the @xmath280 s are conditional intensity functions depending only on the spiking history of neuron @xmath5 .",
    "we take @xmath281 to be identically equal to 1 .    from ( [ eq:5.6 ] ) , we note that the above marked point process model is not a  single marked point process but rather a family of marked point processes indexed by @xmath0 . in the sequel , we let @xmath67 .",
    "we further assume that the following two conditions hold :    _ condition _ ( iii ) .",
    "there exists a strictly positive refractory period for each neuron in that there is a constant @xmath214 such that , for @xmath282 and @xmath79 , @xmath283    _ condition _ ( iv ) . for each @xmath284 and @xmath285 , @xmath286 is a continuously differentiable function in @xmath221 over the simplex @xmath222 .",
    "following section [ sec22 ] , we divide the time interval @xmath188 into bins of width  @xmath0 . for simplicity , we assume that @xmath17 is a multiple of @xmath0 .",
    "let @xmath231 and @xmath287 , @xmath288 , be as in section [ sec1 ] .",
    "if @xmath289 for all @xmath290 , and @xmath291 otherwise , for some subset @xmath292 , we write @xmath293 it should be observed that although the above definitions of @xmath294 and @xmath295 differ from those given in section [ sec : overview ] , they are equivalent .",
    "we note that the conditional intensity functions @xmath296 in ( [ eq:5.6 ] ) depend on the bin width @xmath0 .",
    "this is necessary in order to preserve the natural hierarchical sparsity conditions given by @xmath297 = o(\\delta^k),\\ ] ] as @xmath1 for all @xmath298 , @xmath225 .",
    "[ tm:5.3 ] consider the marked point process @xmath191 as in ( [ eq:5.5 ] ) with conditional intensity function satisfying ( [ eq:5.6 ] ) . then under conditions and",
    ", we have @xmath299 \\prod_{j=1}^2 [ \\lambda^{i_j } ( t_m | \\bar{\\mathcal h}_{t_m}^{i_j } ) ] + o(\\delta^3),\\end{aligned}\\ ] ] and in general , @xmath300 + o(\\delta^{k+1})\\end{aligned}\\ ] ] for sufficiently small @xmath0 where @xmath295 and @xmath301 are defined by ( [ eq:5.34 ] ) .    the following is an immediate corollary of theorem [ tm:5.3 ] .",
    "it gives an asymptotic justification for equation ( [ eq:2.8 ] ) in section [ sec22 ] .",
    "[ cy:5.1 ] with the notation and assumptions of theorem [ tm:5.3 ] , we have for @xmath42 , @xmath302 for sufficiently small @xmath303 uniformly over @xmath304 , @xmath305 where @xmath306 .",
    "we now use theorem [ tm:5.3 ] to construct a loglinear model ( for the above spike train data ) whose higher - order coefficients are asymptotically independent of past spiking history .",
    "first define recursively @xmath307\\\\ [ -8pt ] \\vdots & & \\nonumber \\\\",
    "\\zeta_{\\{i_1 , \\ldots , i_k\\ } } ( t_m | \\bar{\\mathcal h}_{t_m } ) & = & \\frac { \\delta^{-k } p^{i_1 , \\ldots , i_k}_{1 , \\ldots , 1 } ( t_m | \\bar{\\mathcal h}_{t_m } )   } { \\prod_{\\xi \\subsetneq \\{i_1,\\ldots , i_k\\ } } \\zeta_{\\xi } ( t_m | \\bar{\\mathcal h}_{t_m } ) } \\qquad \\forall 1\\leq i_1<\\cdots < i_k\\leq \\nu.\\nonumber\\end{aligned}\\ ] ]    it follows from theorem [ tm:5.3 ] and ( [ eq:5.7 ] ) that for sufficiently small @xmath0 , @xmath308 whenever @xmath309 and @xmath310 , assuming that terms on the right - hand side are well defined .",
    "the practical importance of these results lies in the fact that the coefficients @xmath311 with @xmath310 are asymptotically ( as @xmath67 ) independent of @xmath312 , the spiking history of the neurons .",
    "it is convenient to define @xmath313 . for @xmath239 and",
    "not all  0 , define @xmath314 where @xmath315 if and only if @xmath316 .",
    "then the induced loglinear model is @xmath317\\nonumber \\\\ [ -8pt]\\\\ [ -8pt ] & & \\hspace*{20pt}\\qquad= \\sum_{i=1}^\\nu a_i \\log [ p^i_1 ( t_m | \\bar{\\mathcal h}_{t_m } ) ] + \\sum_{\\xi \\subseteq \\{1,\\ldots , \\nu\\ } : |\\xi| \\geq 2 } \\biggl(\\prod_{j\\in \\xi } a_j\\biggr ) \\log [ \\zeta_\\xi ( t_m | \\bar{\\mathcal h}_{t_m } ) ] \\nonumber\\end{aligned}\\ ] ] for all @xmath244 where the second term on the right - hand side of  ( [ eq:5.76 ] ) is asymptotically ( as @xmath67 ) independent of the spiking history @xmath312 .",
    "this subsection considers @xmath42 neurons labeled 1 , 2 and let @xmath318 be a constant denoting the spike lag .",
    "we model the spike train generated by the two neurons on @xmath188 by a  marked point process @xmath191 as in ( [ eq:8.1 ] ) with mark space @xmath319 .",
    "the marks @xmath320 are interpreted as before as isolated ( i.e. , nonsynchronous ) spikes .",
    "however , now @xmath321 is interpreted to be neuron 1 spiking first and then neuron 2 spiking second after a delay of @xmath322 time units .",
    "the mark @xmath321 is used to model a precise time - delayed synchronous spiking of lag @xmath322 between the 2 neurons .",
    "let @xmath179 denote the number of times the three marks occur on @xmath9 and @xmath323 be the specific spike times . for each @xmath207 ,",
    "let @xmath271 be the mark associated with @xmath183 .",
    "then @xmath273 can be decomposed into @xmath324 , where @xmath325\\\\ [ -8pt ] { \\mathcal h}_{t+\\tau}^2 & = & \\bigl\\ { s\\dvtx ( s , \\kappa)\\in { \\mathcal h}_{t+\\tau } \\mbox{where } \\kappa\\in \\{(2 ) , ( 1,2)\\ } \\bigr\\}.\\nonumber\\end{aligned}\\ ] ] to be definite , @xmath326 means neuron 1 spikes at time @xmath327 and neuron  2 spikes at time @xmath328 .",
    "the conditional intensity function @xmath276 , @xmath79 and @xmath277 , of the marked point process @xmath191 is defined to be @xmath329\\\\ [ -8pt ] \\lambda ( t , ( 1,2 ) | { \\mathcal h}_t ) & = & \\delta \\gamma ( t , t+\\tau ) \\lambda^1(t | { \\mathcal h}^1_t ) \\lambda^2(t + \\tau | { \\mathcal h}_{t+\\tau}^2 ) \\qquad\\forall t\\in [ 0 , t),\\nonumber\\end{aligned}\\ ] ] where @xmath16 is a constant , @xmath330 is a continuously differentiable function in  @xmath30 on the interval @xmath331 , and @xmath332 , @xmath333 are conditional intensity functions depending only on the spiking history of neuron @xmath8 up to time @xmath30 and on the spiking history of neuron @xmath334 up to time @xmath335 , respectively .    as in section [ sec1 ] ,",
    "we divide the time interval @xmath188 into bins of width @xmath336 .",
    "let @xmath337 be as in ( [ eq:5.34 ] ) where , for simplicity , we assume that  @xmath0 is chosen such that @xmath338 are integers satisfying @xmath339 and @xmath340 .",
    "recall that , by definition , @xmath341    [ tm:5.2 ] consider the marked point process @xmath191 as in ( [ eq:5.3 ] ) with conditional intensity function satisfying ( [ eq:5.4 ] ) .",
    "let @xmath342 be integers satisfying @xmath339 and @xmath343 . then under conditions and , we have @xmath344 p^1_1 ( t_m | \\bar{\\mathcal h}_{t_m}^1 ) p^2_1 ( t_{m+h } | \\bar{\\mathcal h}_{t_{m+h}}^2 ) + o(\\delta^3)\\ ] ] for sufficiently small @xmath0 .",
    "the practical significance of theorem [ tm:5.2 ] is that @xmath345 does not depend on the spiking history of the 2 neurons .",
    "this implies that a statistic based on @xmath346 can be constructed to test the null hypothesis @xmath51 that there is no time - delayed spiking synchrony at lag @xmath322 between the 2 neurons .",
    "we have described an approach to assessing spike train synchrony using loglinear models for multiple binary time series . we tried to motivate the application of loglinear modeling technology in section [ sec1 ] , emphasizing two features of individual neural response : stimulus - induced nonstationarity that remains time - locked across trials , and within - trial effects that are history - dependent , with timing that varies across trials .",
    "these were incorporated into the models by including for individual neurons both time - varying marginal effects , which stay the same across trials , and history - dependent terms ; interaction terms were treated separately . in section [ sec : analysis ] we presented results for two pairs of neurons . for both pairs there was evidence of excess synchronous spiking beyond that explained by stimulus - induced changes in individual - neuron firing rates . in one pair , network activity , represented as history dependence , was sufficient to account for excess synchronous spiking , but the other pair displayed excess synchronous spiking that remained highly statistically significant even after network effects were incorporated , indicating stimulus - related synchrony .",
    "our theoretical results provided a  continuous - time point process foundation for the methods , justifying both our use of smoothing and our derivation of the excess - synchrony estimators @xmath347 and @xmath348 .",
    "assessment of synchrony via continuous - time loglinear models is closely related to the unitary - event analysis of grn , diesmann and aertsen ( @xcite , @xcite ) .",
    "unitary event analysis assumes each neuron follows a locally - stationary poisson process , which has been shown to be somewhat conservative in the sense of providing inflated @xmath55-values in the presence of non - poisson history dependence .",
    "its main purpose is to identify stimulus - locked excess synchrony .",
    "because the loglinear models could be viewed as generalizations of locally - stationary poisson models , they could extend unitary - event analysis to cases in which it seems desirable to account more explicitly for stimulus and history effects .",
    "this is a topic for future research .",
    "we also provided an example of testing for 3-way interaction .",
    "the results we gave in section [ sec : analysis ] for a particular triple of neurons indicated no evidence of excess 3-way joint spiking above that explained by 2-way joint spiking .",
    "a systematic finding along these lines , examining large numbers of neurons , would be consistent with findings of schneidman et al .",
    "( @xcite ) . however , as may be seen from figure  [ fig3 ] , 3-way joint spikes are very sparse . a careful study of the power to detect 3-way joint spiking in contexts like the one considered here could be quite helpful .",
    "we plan to carry out such a study and report it elsewhere .",
    "we have restricted history effects to individual neurons by assuming , first , that each neuron s history excludes past spiking of the other neurons under consideration and , second , that the interaction effects are independent of history .",
    "this greatly simplifies the modeling and avoids confounding the interaction effects with cross - neuron effects .",
    "while it would be possible , in principle ( by modifying the hierarchical sparsity condition ) , to allow history - dependence within interaction effects , we see no practical benefit of doing so . with the two additional , highly plausible assumptions used here , we get both tractable discrete - time methods and a sense in which the methods may be understood in continuous time . a key element of our formalism is the requirement of hierarchical sparsity , as in the special case of equation  ( [ eq : sparse2 ] ) and more generally in section [ sec61 ] ( preceding theorem [ tm:5.3 ] ) .",
    "this corresponds to the practical reality that two - way synchronous spikes are rare , as in figure  [ fig2 ] , and three - way spikes are even rarer , as in figure [ fig3 ] .",
    "some form of sparsity seems to us essential .",
    "[ after our article was accepted we became aware that solo ( @xcite ) had attempted to develop likelihoods for point processes having synchronous events , but because his approach does not incorporate sparsity we have been unable to understand how it could be used in the kind of applications we have described here .",
    "] it is somewhat inelegant to have a sequence of marked processes ( indexed by @xmath0 ) , but this appears to be the best that can be achieved by starting with very natural discrete - time loglinear models .",
    "an alternative would be to use more standard point process models with short time - scale cross - neuron effects .",
    "presumably , similar results could be obtained , but the relationship between these different approaches is also a subject for future research .",
    "a quite different technology involves permutation - style assessment via `` dithering '' or `` jittering '' of individual spike times [ cf .",
    "geman et al .",
    "( @xcite ) , grn ( @xcite ) ] .",
    "synchrony is one of the deep topics in computational neuroscience and its statistical identification is subtle for many reasons , including inaccuracies in reconstruction of spike timing from the complicated mixture of neural signals picked up by the recording electrodes [ e.g. , harris et al .",
    "( @xcite ) , ventura ( @xcite ) ] .",
    "it is likely that multiple approaches will be needed to grapple with varying neurophsyiological circumstances .",
    "proof of theorem [ tm:4.3 ] for simplicity , we shall consider only the case for @xmath42 .",
    "the proof for other values of @xmath7 is similar though more tedious .",
    "we observe from proposition [ pn:8.1 ] that @xmath349 \\nonumber \\\\ & & \\qquad\\quad { } \\times e^{-\\sum_{j=1}^2 \\int_0^{t_{m+1 } } \\lambda ( w , ( j ) |",
    "{ \\mathcal h}_w)\\,dw}\\,ds_{k+1}\\,ds_k \\cdots\\,ds_1.\\nonumber\\end{aligned}\\ ] ] condition ( i ) implies that the summations @xmath350 in ( [ eq : a.10 ] ) contain a finite number of summands .",
    "hence , letting @xmath67 , the right - hand side of  ( [ eq : a.10 ] ) equals @xmath351\\\\ & & \\qquad{}\\times e^{-\\sum_{j=1}^2 \\int_0^{t_{m+1 } } \\lambda ( w , ( j ) | { \\mathcal h}_w)\\,dw}\\,ds_{k+1}\\,ds_k \\cdots\\,ds_1.\\nonumber\\end{aligned}\\ ] ] using condition ( ii ) and the taylor expansion , we have @xmath352 uniformly over @xmath353 . consequently , ( [ eq : a.20 ] ) equals @xmath354\\\\ & & \\hphantom{\\sum_{k= 0}^{2 \\lceil t/\\theta\\rceil }   \\sum_{i_1,\\ldots , i_k\\in \\{1,2\\ } } \\lim_{\\delta \\rightarrow 0 } \\biggl\\{}{}\\times e^{-\\sum_{j=1}^2 \\int_0^{t_m } \\lambda ( w , ( j ) | { \\mathcal h}_w)\\,dw}\\,ds_{k+1}\\,ds_k\\,\\cdots\\,ds_1 + o(\\delta)\\biggr\\}\\\\ & & \\qquad= e [ \\lambda ( t , ( 1 ) |{\\mathcal h}_t],\\end{aligned}\\ ] ] since @xmath355 and @xmath356 . using a similar argument",
    ", we have @xmath357 \\nonumber \\\\ & & { } \\times e^{-\\sum_{j=1}^2 \\int_0^{t_{m+1 } } \\lambda ( w , ( j)| { \\mathcal h}_w)\\,dw}\\,ds_{k+2}\\,ds_{k+1}\\,ds_k\\,\\cdots\\,ds_1 \\nonumber \\\\ & \\rightarrow & \\frac{1}{2 } \\bigl\\ { e \\bigl [ \\lambda \\bigl(t , ( 2 ) | \\{(t , ( 1 ) ) \\ } \\cup { \\mathcal h}_t \\bigr ) \\lambda ( t , ( 1)| { \\mathcal h}_t )   \\bigr]\\\\ & & \\hphantom{\\frac{1}{2 } \\bigl\\ { } { } + e \\bigl [ \\lambda \\bigl(t , ( 1 ) | \\{(t , ( 2))\\ } \\cup { \\mathcal h}_t \\bigr ) \\lambda ( t , ( 2)| { \\mathcal h}_t ) \\bigr ] \\bigr\\}\\end{aligned}\\ ] ] and @xmath358 \\rightarrow e [ \\lambda ( t , ( 1 ) |{\\mathcal h}_t]$ ] as @xmath1 .    proof of theorem [ tm:4.2 ] for simplicity , define @xmath359 for all @xmath360 .",
    "we observe from proposition [ pn:8.1 ] that @xmath361\\\\ & & \\hspace*{-4pt}\\qquad\\quad{}\\times \\lambda ( s_{j+1 } , ( 1)| \\ { ( s_1 , ( i_1 ) ) , \\ldots , ( s_j , ( i_j ) ) \\ } ) \\nonumber \\\\ & & \\hspace*{-4pt}\\qquad\\quad { } \\times \\biggl [ \\prod_{l= 1}^j \\lambda ( s_l , ( i_l)| \\ { ( s_1 , ( i_1 ) ) , \\ldots , ( s_{l-1 } , ( i_{l-1 } ) ) \\ } ) \\biggr ] \\nonumber \\\\ & & \\hspace*{-4pt}\\qquad\\quad { } \\times e^{-\\sum_{\\ell = 1}^2 \\int_0^{t_{m+1 } } \\lambda ( w , ( \\ell ) | { \\mathcal h}_w)\\,dw}\\,ds_{j+k+2}\\,ds_{j+k+1}\\,\\cdots\\,ds_{j+2}\\ , ds_{j+1}\\,ds_j\\,\\cdots\\,ds_1 \\\\ & & \\hspace*{-4pt}\\qquad\\rightarrow   e \\bigl [ \\lambda \\bigl(t+\\tau , ( 2 ) | \\{(t , ( 1 ) ) \\ }",
    "\\cup { \\mathcal h}_t \\bigr ) \\lambda ( t , ( 1)| { \\mathcal h}_t )   \\bigr]\\end{aligned}\\ ] ] as @xmath1 .",
    "theorem [ tm:4.2 ] follows since @xmath362 as @xmath363 .",
    "proof of theorem [ tm:5.3 ] for simplicity , we only consider the case @xmath42 .",
    "let @xmath364 and @xmath365 , where @xmath366 .",
    "we observe from ( [ eq:5.6 ] ) that @xmath367 , and @xmath368 for sufficiently small @xmath0 where @xmath369 denotes the distribution function of @xmath370 . here",
    "@xmath371 , @xmath372 , etc .",
    "this proves the first statement of theorem [ tm:5.3 ] .",
    "next we observe that @xmath373 \\lambda^1 ( t_m | \\bar{\\mathcal h}^1_{t_m } ) \\lambda^2 ( t_m | \\bar{\\mathcal h}^2_{t_m } ) p (   \\bar{\\mathcal h}_{t_m } ) + o(\\delta ) p (   \\bar{\\mathcal h}_{t_m})\\end{aligned}\\ ] ] for sufficiently small @xmath0 .",
    "this proves theorem [ tm:5.3 ] .",
    "proof of theorem [ tm:5.2 ] we observe that @xmath374 is a many - to - one mapping and from ( [ eq:5.4 ] ) that @xmath375 for sufficiently small @xmath0 .",
    "we further observe that @xmath376\\\\ [ -8pt ] p^2_1 ( t_{m+h } | { \\mathcal h}_{t_{m+h}}^2 ) & = & p \\bigl ( x^1 ( t_m)=0 , x^2(t_{m+h})=1 | { \\mathcal h}_{t_{m+h}}^2 \\bigr ) + o(\\delta^2 ) \\nonumber \\\\ & = & \\delta   \\lambda^2 ( t_{m+h } | { \\mathcal h}^2_{t_{m+h } } ) + o(\\delta^2)\\nonumber \\\\ & = & \\delta   \\lambda^2 ( t_{m+h } | \\bar{\\mathcal h}^2_{t_{m+h } } ) + o(\\delta^2).\\nonumber\\end{aligned}\\ ] ] thus , it follows from ( [ eq : a.32 ] ) and ( [ eq : a.34 ] ) that @xmath377 p^1_1 ( t_m | \\bar{\\mathcal h}_{t_m}^1 ) p^2_1 ( t_{m+h } | \\bar{\\mathcal h}_{t_{m+h}}^2 ) + o(\\delta^3)\\end{aligned}\\ ] ] for sufficiently small @xmath0 .",
    "this proves theorem [ tm:5.2 ] .",
    "brown , e. n. , barbieri , r. , eden , u. t. and frank l. m. ( 2004 ) .",
    "likelihood methods for neural spike train data analysis . in _",
    "computational neuroscience : a comprehensive approach _ 253286 .",
    "crc press , london .",
    "harris , k. d. , henze , d. a. , csicsvari , j. , hirase , h. and buzsaki , g. ( 2000 ) .",
    "accuracy of tetrode spike separation as determined by simultaneous intracellular and extracellular measurements .",
    "_ j. neurophysiol .",
    "_ * 84 * 401414 .",
    "kelly , r. c. , smith , m. a. , samonds , j. m. , kohn , a. , bonds , a. b. , movshon , j.  a. and lee , t. s. ( 2007 ) .",
    "comparison of recordings from microelectrode arrays and single electrodes in the visual cortex .",
    "_ j. neurosci .",
    "_ * 27 * 261264 .",
    "martignon , l. , deco , g. , laskey , k. , diamond , m. , freiwald , w. and vaadia , e. ( 2000 ) .",
    "neural coding : higher - order temporal patterns in the neurostatistics of cell assemblies . _ neural comput . _",
    "* 12 * 26212653 .",
    "paninski , l. , brown , e. n. , iyengar , s. and kass , r. e. ( 2009 ) .",
    "statistical models of spike trains . in _",
    "stochastic methods in neuroscience _",
    "( c. liang and g. j. lord , eds . ) 278303 .",
    "clarendon press , oxford ."
  ],
  "abstract_text": [
    "<S> neural spike trains , which are sequences of very brief jumps in voltage across the cell membrane , were one of the motivating applications for the development of point process methodology . </S>",
    "<S> early work required the assumption of stationarity , but contemporary experiments often use time - varying stimuli and produce time - varying neural responses . </S>",
    "<S> more recently , many statistical methods have been developed for nonstationary neural point process data . </S>",
    "<S> there has also been much interest in identifying synchrony , meaning events across two or more neurons that are nearly simultaneous at the time scale of the recordings . </S>",
    "<S> a natural statistical approach is to discretize time , using short time bins , and to introduce loglinear models for dependency among neurons , but previous use of loglinear modeling technology has assumed stationarity . we introduce a succinct yet powerful class of time - varying loglinear models by ( a ) allowing individual - neuron effects ( main effects ) to involve time - varying intensities ; ( b ) also allowing the individual - neuron effects to involve autocovariation effects ( history effects ) due to past spiking , ( c ) assuming excess synchrony effects ( interaction effects ) do not depend on history , and ( d )  assuming all effects vary smoothly across time . using data from the primary visual cortex of an anesthetized monkey , we give two examples in which the rate of synchronous spiking can not be explained by stimulus - related changes in individual - neuron effects . in one example </S>",
    "<S> , the excess synchrony disappears when slow - wave `` up '' states are taken into account as history effects , while in the second example it does not . </S>",
    "<S> standard point process theory explicitly rules out synchronous events . to justify our use of continuous - time methodology </S>",
    "<S> , we introduce a framework that incorporates synchronous events and provides continuous - time loglinear point process approximations to discrete - time loglinear models .    ,    . </S>"
  ]
}