{
  "article_text": [
    "tagsets used in existing corpora have usually been designed to satisfy the needs of specific projects .",
    "a tagset used for robust parsing will tend to stress distributional properties , whereas a corpus within a lexical resource specially designed for human interaction ( which might include a human oriented dictionary ) will most likely distinguish word classes along traditional linguistic lines .    the tool described in this paper performs tagset mapping with manually written rules to introduce a standardised morphosyntactic tagset .",
    "standardisation of tagsets has been a goal of some contemporary projects ( e.g. @xcite and the text encoding initiative @xcite ) ; at the same time , it has been the object of much controversy because of the obvious advantages of tailoring tagsets to project needs .",
    "looking at the problem from a larger perspective than that of isolated projects , a uniform tagset has the following advantages :    * * objectivisation and standardisation of similar information * : millions of words have been analysed in the past , using different annotation schemes .",
    "especially the manually analysed linguistic data is expensive to produce and extremely valuable . with a standardised tagset , linguistic information from different corpora of the same language",
    "can be _ reused _ and thus merged into a large data base .",
    "such data bases improve the performance of statistical methods and are a useful resource for the production of balanced corpora . * * shared use of language resources * : corpus manipulation tools such as retrieval tools can be applied to merged resources in a uniform format without much customisation .",
    "as well , users of these tools will find it easier to work with a corpus tagged in a standardised tagset .",
    "now , they have to memorize only _ one _ scheme of tag classes ( class names , class semantics , exceptions ) , as opposed to several schemes for several corpora before . * * comparison of annotation schemes * : a comparison of the granularity and degree of similarity of tagsets can be carried out more objectively , once the mapping results are available .",
    "the validation of the suggestions of the lre - project eagles is an application in this field .",
    "we believe that standards are important for the linguistic community , especially from the point of view of reusablility .",
    "of course , there are limits : proposals for standard tagsets should be regarded as approaches towards a neutral platform between projects and different theories , rather than as ready - made tagsets that will never be changed .",
    "it is important indeed that standards and their support tools be flexible about possible extensions and improvements .",
    "the more general problem of retagging has been approached with tools like ica @xcite , a public domain retagging tool which uses sgml as interlingua .",
    "we also know of current work at leeds university on mapping tagsets , though this work is concerned with the mapping of syntactic structure encoded in corpora @xcite .",
    "when designing the architecture of a standardised tagset , we implemented the following constructs as they provide considerable advantages compared to the the traditional flat word labels .    *",
    "as the tagset is * constraint - based * , a flexible generalisation is possible over all atomic constraints and combinations of constraints . as a formal grammar is used to define syntactically well - formed specifications of word forms , we can regard our standard tagset as a _ specification language_. + example : the specification denotes 3rd person auxiliary verbs . *",
    "the tagset is also * typed * , which adds to the naturalness of the specifications of wordforms and helps discover semantic errors in specifications ( inconsistent combinations of features , wrong values for features ) . in our implementation , we follow the closed - world - assumption , which leads to a coherent interpretation for underspecified and/or negated descriptions .",
    "+ example : is a syntactically correct , + + + but ill - typed specification , as the types v ( verb ) and gen ( genitive ) are not type compatible .",
    "* the tagset can be easily * modified * because its manually written definition is compiled into a system internal format .",
    "as the design of a tagset involves a cycle with feedback phases , including manual tagging and the writing of guidelines , there will be frequent modifications to the tagset , especially in the initial phase .",
    "the eagles expert group ( cf .",
    "@xcite ) suggested an inventory of features and values for a standardised morphosyntactic tagset for european languages ; there are different layers , depending on language specificity as well as on application specificity . for the design of a standardised tagset in a specific language ,",
    "relevant features and values are to be chosen from the inventory . fig .",
    "[ tgraph ] shows a detail of the tentative english tagset we designed and used for our tests .",
    "the type relations are divided into hierarchical ( pos ) features and non - hierarchical features ( mo / sy ) .",
    "mapping tags of an existing , flat - labeled tagset or source annotation scheme to tags of a specification language ( target annotation scheme ) is an instance of the retagging problem .",
    "it is straightforward only in the trivial cases 1:1 ( renaming ) and n:1 . in the latter case ,",
    "the physical tagset makes finer distinctions than the target annotation scheme .",
    "this case introduces no problem for the mapping itself even if not all information contained in the corpus can be accessed .",
    "unfortunately , what we usually find in the mapping business is a mixture of two more problematic cases :    the physical tagset can not support a distinction intended by the specification language , e.g. as the distinction gender in fig .",
    "[ 1:n ] . therefore , there is a lack of information : the corpus annotation does not provide the wanted distinction .",
    "there is an overlap between tag classes , as illustrated in fig .",
    "[ n : m ] . in the example",
    "case , the source annotation scheme includes special indefinite pronouns like _ anybody _ into the normal common nouns , whereas some word forms ( _ color _ ) are ( wrongly ! ) tagged as adjectives in the source annotation scheme but as common nouns in the target annotation scheme .",
    "we opted for symbolic mapping rules[multiblock footnote omitted ] and designed two kinds of mapping rules to deal with the discrepancies indicated above .    *",
    "* class coverage rules * describe a correspondence of source and target annotation classes .",
    "the rule format is as follows : for each physical tag , the equivalent expression in the specification language is named .",
    "+ example : = @xmath0 + + the word forms that are annotated with the physical tag nn are `` common singular nouns or mass nouns '' in the terms of the specification language . + * the * exception lexicon * provides a treatment of the individual discrepancy areas of case n : m , in order to deal with noise from unsharp mappings .",
    "specific lexical items can be reclassified , i.e. their standard mapping can be overridden .",
    "( notation : the sign @xmath1 stands for `` out of '' ) they can be reclassified in a different target annotation scheme class instead ( sign @xmath2 stands for `` into '' ) .",
    "+ example : the following exception lexicon entry expresses that the target tag for wordforms _ anybody , nothing  _ in fig .",
    "[ n : m ] should not be the standard reading for nn ( common singular nouns or mass nouns ) , but should be described as an indefinite pronoun relating to persons .",
    "+ @xmath1 [ pos =  nn  ] @xmath2 [ pos = pron & antec = prs & type = indef ] .",
    "the exception lexicon lookup takes place after the mapping of the class coverages . for more details , see @xcite .",
    "after the compilation of the mapping rules , the system keeps the information in a data structure called an mtree ( mapping tree ) , see fig .",
    "[ mtree ] , which shows the verb mappings for upenn .",
    "there is an mtree for each physical tagset regarded .",
    "mtrees contain a subset of the information contained in the type graph ( see fig .",
    "[ ttree ] ) , namely only those distinctions of the original type graph that are distinguishable in the physical tagset .",
    "the new terminals ( boxes with thick lines in fig .",
    "[ mtree ] ) in this pruned type graph correspond to physical tags ( encircled tag names ) .    within the rule set",
    ", the system keeps track of consistency .",
    "warnings are issued in case of one of the following inconsistencies which might occur during the construction of an mtree :    * * definition holes * : either target or source annotation schemes are not covered by a mapping rule ( classes have been forgotten by the person writing the mapping rules ) . *",
    "* nondisjunctiveness of classes * : a target annotation class has several source annotation correspondences .",
    "although this might be an instance of case n:1 , a warning is issued , because most such cases occur due to a conceptual error . * * hierarchical inconsistency * : instead of keeping a clear distinction between terminal classes and nonterminal classes , an odd mapping assigns terminal status to ancestors of classes that are terminals themselves . in fig .",
    "[ mtree ] , the correspondence specified by the dashed arrow introduces a hierarchical inconsistency , as it assigns a physical tag ( vbn ) to a class ( con ) that can not be terminal because its daughters ( past and pres ) already are .",
    "system support includes    * compilation of the tagset definition : useful for tagsets with many non - hierarchical , i.e. combinatory features ( which would have to be multiplied out manually otherwise . ) * compilation of mapping rules : consistency checks ( cf .",
    "section [ cc ] ) .",
    "* interpretation of specifications : each specification is syntactically and semantically checked , and the corresponding ( set of ) physical tag(s ) is computed , using the mtree information . due to 1:n and/or n : m cases ( unsharp mapping ) , there can be noise ( i.e. groups of word forms which do _ not _ conform to the specification ) in the output . in these cases ,",
    "the system anticipates the noise to be expected and informs the user .",
    "warnings about noise are essential for a correct interpretation of the output .",
    "+ noisy word classes can be deduced from the mtree : in the mtree given in fig .",
    "[ mtree ] , we can see that target specification inf ( infinitives ) will always induce noise from finite forms , namely subjunctive and imperative forms , because the physical class vb does not distinguish between these groups ( case 1:n ) .",
    "for test purposes , we wrote mapping rules for the upenn and susanne tagsets . the number of coverage rules is equivalent to the number of physical tags .",
    "rules are easy to formulate , once users have got used to the class semantics of the standard tag set .",
    "information input are tagging guidelines , if the source annotation scheme comes with a comprehensive description of the intended class semantics , or corpus queries otherwise , which is more time consuming .",
    "we wrote exemplary exception lexicon entries for auxiliary verbs and some for noun exceptions , but more work can be put into the exception lexicon to improve the accuracy in the lexically determinable cases of discrepancies .",
    "apart from being used for the validation of the eagles standard for english and german , the tool has been integrated into a corpus query system ( christ 94 , schulze 94 ) to allow for `` more abstract '' and corpus independent queries",
    ". a typical query ( content verbs in infinitive or primary auxiliaries in past tense ) to a specific corpus ( here : upenn ) looks like this :          we get the information that the system will query for tags vb , vbd , vbn ( with lexical constraints ) in the upenn corpus ; however , we must expect to find _ finite _ content verbs ( namely imperative and subjunctive forms ) in our output ( 1:n case ) .          in our opinion , _",
    "peter s _ should be regarded as one nominal item ( with genitive as value for the case attribute ) , whereas _ he _ and _ s _ should be kept as two words .",
    "we are thinking about designing a rule construct to express this kind of word bundelling with conditional features .        a modular and flexible architecture for an integrated corpus query system . in : _ proceedings of complex94 _",
    "( 3rd conference on computational lexicography and text research ) .",
    "budapest , hungary , jul . 1994 ."
  ],
  "abstract_text": [
    "<S> many different tagsets are used in existing corpora ; these tagsets vary according to the objectives of specific projects ( which may be as far apart as robust parsing vs. spelling correction ) . in many situations , </S>",
    "<S> however , one would like to have uniform access to the linguistic information encoded in corpus annotations without having to know the classification schemes in detail . </S>",
    "<S> this paper describes a tool which maps unstructured morphosyntactic tags to a constraint - based , typed , configurable specification language , a `` standard tagset '' . </S>",
    "<S> the mapping relies on a manually written set of mapping rules , which is automatically checked for consistency . in certain cases , </S>",
    "<S> unsharp mappings are unavoidable , and noise , i.e. groups of word forms _ not _ conforming to the specification , will appear in the output of the mapping . </S>",
    "<S> the system automatically detects such noise and informs the user about it .    </S>",
    "<S> the tool has been tested with rules for the upenn tagset @xcite and the susanne tagset @xcite , in the framework of the eagles validation phase for standardised tagsets for european languages . </S>"
  ]
}