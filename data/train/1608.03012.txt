{
  "article_text": [
    "the regression relationship between a response variable and one or more predictor variables constitutes the target of many statistical methodologies .",
    "the most basic form is linear regression , where all variables are real - valued , and the conditional mean of the response variable is linear in the predictors .",
    "the linear regression model is quite flexible , includes polynomial fits and categorical predictor variables , among others , and remains one of the most popular tools for data analysis .",
    "in addition to the superb interpretability of linear models and simple model fitting via least squares , powerful inferential methods , with well - established theory , are available for estimation and testing .",
    "linear regression ideas also motivate local polynomial smoothing , which is a localized version , further adding to their vast applicability .    in recent years , as data types are becoming more complex , attention has turned to regression in more abstract settings .",
    "the importance of the analysis of such object data has recently been highlighted in .",
    "a setting that is increasingly encountered is that of a response variable taking values in a metric space which may or may not have algebraic structure .",
    "the presence of a metric provides a natural connection to the work of , where the frchet mean is defined for random elements of a metric space as a direct generalization of the standard mean , which is defined by integration over a probability space .",
    "this generalization has been increasingly exploited in statistical analyses due to its flexibility .",
    "specifically , no ambient vector space needs to be assumed and only a distance between data objects is required .",
    "one important class of random objects , which has been extensively studied , consists of observations on a finite - dimensional differentiable riemannian manifold . due to local euclidean properties of the space",
    ", one can mimic both parametric ( global ) and nonparametric ( local ) regression techniques for standard euclidean data quite effectively .",
    "intrinsic models for geodesic regression , semiparametric regression and local kernel regression have been proposed , along with an extrinsic regression model in a recent preprint .    in this paper , however , we focus on a more general case of random objects , where only distances between response objects are computable . to our knowledge , in general metric spaces ,",
    "the only global or parametric model which has been proposed is that of , where data are represented as scores in a euclidean space based on their pairwise distances , followed by the use of classical regression techniques .",
    "this method requires a complicated  backscoring \" step , where vectors in euclidean space are then represented in the original metric space , and its theoretical properties have not been studied .",
    "local regression methods on generic metric spaces are limited to nadaraya - watson type estimators and lack a comprehensive asymptotic analysis .",
    "thus , there is a need for additional statistical models to tackle this novel type of data , and we present here methodology and theory that will be useful for the analysis of complex random objects .    specifically , we consider regression relationships between responses which are complex random objects and vectors of real - valued predictors . to this end , a global regression relation is defined as a generalization of multiple linear regression . as the proposed regression approach for random objects incorporates the geometry implied by the metric and can be viewed as an extension of the frchet mean , we refer to it as frchet regression .",
    "global frchet regression provides an improvement on the global method of , as the proposed model defines the regression directly on the object space and does not require backscoring .",
    "we also propose local frchet regression , which generalizes local linear modeling to a framework where responses are random objects , extending the nonparametric regression methodology for object data beyond the existing local constant smoothers .",
    "a first task in the development of local frchet regression is to define an appropriate population model , which serves as target to which the fitted local frchet regression converges .",
    "we establish consistency and rates of convergence for both global and local frchet regression .",
    "the proposed global frchet regression model is introduced in section  [ sec : regress ] , and theory quantifying the convergence rates of these estimators is given in section  [ sec : theory ] , along with some concrete examples which satisfy the necessary regularity conditions .",
    "all proofs can be found in the appendix . in the special case",
    "that the space @xmath1 of the random objects is a hilbert space , a limiting distribution can be obtained , as demonstrated in section  [ sec : hilbert ] .",
    "the extension to local frchet regression is the topic of section  [ sec : local ] .",
    "our primary application examples deal with samples of probability distributions and correlation matrices , which are illustrated with data from demography and neuroimaging , with details in sections  [ sec : density ] and [ sec : correlation ] , respectively , where we also include a discussion of practical issues , such as a suitable notion of the coefficient of determination @xmath2 when the responses are random objects . for the space of probability distributions , we utilize the wasserstein metric to conduct a simulation experiment as well as analyze the evolution of mortality profiles for two countries .",
    "for the application where responses are correlation matrices , we examine the relationship between functional connectivity in the brain , as quantified by pairwise correlations of fmri signals , with age as predictor .",
    "lastly , although the proposed methodology does not require any particular metric structure , it is nevertheless applicable to structured spaces such as manifolds . to demonstrate this , the local frchet regression technique is also illustrated with simulated manifold data on the sphere @xmath3 in section  [ sec : sphere ] .",
    "we consider a random process @xmath4 , where @xmath5 and @xmath6 take values in @xmath7 and @xmath1 , respectively . here",
    "@xmath8 is a metric space @xmath8 with metric @xmath9 and @xmath10 is the joint distribution of @xmath5 and @xmath6 on @xmath11 .",
    "we denote the marginal distributions of @xmath5 and @xmath6 as @xmath12 and @xmath13 , respectively , and assume that @xmath14 and @xmath15 exist , with @xmath16 positive definite .",
    "the conditional distributions @xmath17 and @xmath18 are also assumed to exist . in this general",
    "setting , we refer to @xmath6 as a random object .",
    "the usual notions of mean and variance were generalized to random objects in metric spaces in , where @xmath19 were defined , now commonly referred to as frchet mean and frchet variance , respectively .",
    "building on these concepts , we introduce the frchet regression function of @xmath6 given @xmath20 , @xmath21 where we refer to @xmath22 as the ( conditional ) frchet function . for the special case @xmath23 ,",
    "various nonparametric regression methods have been developed which are based on kernel or local linear polynomial fitting , splines or other smoothers .",
    "a basic statistical task is to fit a global regression model for response @xmath6 and predictor @xmath5 , in order to provide ease of implementation and interpretation and allow for good options for overall inference and testing .",
    "fitting of such a global model also does not require the choice of a tuning parameter , as all local fitting methods do , since global models are fitted under the assumption that there is no bias .",
    "given that no algebraic structure is assumed , it is not feasible to directly generalize parametric models to a parametric function on @xmath1 , as has been done in the special case when @xmath1 is a riemannian manifold .",
    "however , an alternative solution that we will develop is to recharacterize the standard multiple linear regression model as a function of weighted frchet means , where the weights have a known form and vary with @xmath24 .",
    "we begin by considering the standard setup for linear regression , for which @xmath23 , and then write @xmath25 in ( [ eq : frechet_regression ] ) . the model for linear regression",
    "is @xmath26 where the scalar intercept @xmath27 and slope vector @xmath28 are the solutions @xmath29 ^ 2\\dx.\\ ] ] similar to the frchet mean , the goal is to recharacterize the regression values in ( [ eq : lin ] ) as minimizers of weighted least squares problems , where the weights depend on predictor values and the squared distances depend on response values .",
    "the following arguments demonstrate this development .",
    "setting @xmath14 , @xmath30 and @xmath31 $ ] , the normal equations for the right - hand side of ( [ eq : lin_ls ] ) then lead to @xmath32 with solutions @xmath33 and @xmath34 plugging these values into ( [ eq : lin ] ) , @xmath35 where the weight function @xmath36 is @xmath37 because @xmath38 , the last line of ( [ eq : int_weight ] ) reveals that the standard linear regression function value @xmath39 is the solution @xmath40,\\ ] ] where @xmath41 is the standard euclidean metric .",
    "this alternative formulation of the linear regression function provides the key to defining the proposed global frchet regression function @xmath42 on an arbitrary metric space @xmath8 , by simply replacing the euclidean metric @xmath41 , which is the default metric for real valued responses , by a more general metric @xmath9 that is suitable for responses in @xmath1 .",
    "the model for frchet regression then becomes @xmath43.\\ ] ]    hence , generalizing multiple linear regression to the case of a metric - value response is achieved by viewing the regression function as a weighted frchet mean , with the weights that are derived from those of the corresponding standard linear regression . note that @xmath44 , implying that @xmath45 , which means that the frchet regression function passes through the point @xmath46 .",
    "assume that @xmath47 , @xmath48 , are independent .",
    "we take the standard approach to estimate the minimizer in ( [ eq : mp ] ) by substituting the empirical distribution @xmath49 for @xmath50 in the integral in ( [ eq : mp ] ) .",
    "additionally , the unknown parameters @xmath51 and @xmath16 in ( [ eq : weight ] ) are replaced by their empirical estimates @xmath52 and @xmath53 , respectively .",
    "the empirical weights @xmath54 then lead to the estimator @xmath55 of @xmath56 for @xmath57 , where @xmath58",
    "we first consider the estimation of the regression relation in ( [ eq : mp ] ) by the corresponding estimator in ( [ eq : mp_est ] ) in the case of a totally bounded metric space @xmath8 .",
    "recall the functions @xmath59 , \\quad m_n(\\om , x ) : = n\\inv \\sn s_{in}(x)d^2(y_i , \\om).\\ ] ] with regard to the objects in ( [ eq : mp ] ) and ( [ eq : mp_est ] ) , we require the following assumptions for a fixed @xmath57 .    * the objects @xmath56 and",
    "@xmath60 exist and are unique , the latter almost surely , and , for any @xmath61 , * for @xmath62 small enough , @xmath63 where @xmath64 is the @xmath65-ball centered at @xmath56 and @xmath66 is the covering number for @xmath64 using open balls of radius @xmath67 .",
    "* there exist @xmath68 , @xmath69 and @xmath70 , possibly depending on @xmath24 , such that , whenever @xmath71 , we have @xmath72 .    assumption ( p0 )",
    "is common to establish the consistency of an @xmath73-estimator such as @xmath60 ; see chapter 3.2 in .",
    "in particular , it ensures that weak convergence of the empirical process @xmath74 to the population process @xmath73 in turn implies convergence of their minimizers .",
    "furthermore , existence follows immediately if @xmath1 is compact .",
    "the conditions on the covering number in ( p1 ) and curvature in ( p2 ) arise from empirical process theory and control the behavior of @xmath75 near the minimum in order to obtain a rate of convergence .",
    "we also consider uniform convergence results for predictor values @xmath24 , requiring stronger versions of the above assumptions .",
    "let @xmath76 be the euclidean norm on @xmath7 and @xmath77 .",
    "* almost surely , for all @xmath78 , the objects @xmath56 and @xmath60 exist and are unique .",
    "additionally , for any @xmath61 , @xmath79 and there exists @xmath80 such that @xmath81 * the entropy integral for the space @xmath1 is finite , i.e. @xmath82 * there exist @xmath83 , @xmath84 , and @xmath85 , possibly depending on @xmath86 , such that @xmath87    the following examples of classes of random objects correspond to the applications and simulations that will be discussed in sections  [ sec : density ] , [ sec : correlation ] and [ sec : sphere ] .",
    "[ exm : wass ] take @xmath1 to be the set of probability distributions @xmath10 on @xmath88 such that @xmath89 , equipped with the wasserstein metric @xmath90 . for two such distributions @xmath10 and @xmath91 , the wasserstein distance is given by @xmath92 where @xmath93 and @xmath94 are the quantile functions corresponding to @xmath10 and @xmath91 , respectively .",
    "[ exm : correlation ] take @xmath1 as the set of correlation matrices of a fixed dimension @xmath95 , i.e. symmetric , positive definite @xmath96 matrices with unit diagonal , and equip @xmath1 with the frobenius metric , @xmath97 .",
    "[ exm : manifold ] let @xmath1 be a ( bounded ) riemannian manifold of dimension @xmath95 and let @xmath9 be the geodesic distance implied by the riemannian metric .",
    "propositions  [ prop : wass ] and [ prop : correlation ] in the appendix demonstrate that all of the above assumptions are satisfied for the random objects in examples 1 and 2 .",
    "for example 3 , proposition  [ prop : manifold ] shows that ( p1 ) and ( u1 ) hold automatically and , if uniqueness holds ( ( p0 ) and ( u0 ) , respectively ) , then the other assumptions ( ( p2 ) and ( u2 ) , respectively ) are equivalent to the hessian on the tangent space at @xmath56 being positive definite at @xmath98 .",
    "uniqueness of frchet means for manifolds is challenging in general , but can be guaranteed under certain circumstances , for example restricting the support of the underlying distribution @xmath13 .",
    "alternatively , one can consider local frchet means or frchet mean sets . in all of these examples",
    ", we have @xmath99 in ( p2 ) and ( u2 ) .",
    "thus , for manifolds , local curvatures do not influence the convergence rates below .",
    "the following two results demonstrate the consistency of the estimation and give the rate of convergence .",
    "all proofs are in the appendix .",
    "[ lma : con ] suppose ( p0 ) holds and @xmath1 is bounded . then , for any fixed @xmath100 , @xmath101 . for @xmath77 , if ( u0 ) holds then @xmath102 .",
    "[ thm : rate ] suppose that , for a fixed @xmath57 , ( p0)(p2 ) hold . then @xmath103 furthermore , for a given @xmath77 , if ( u0)(u2 ) hold , @xmath104    we remark that , if @xmath105 in ( p2 ) and @xmath106 in ( u2 ) , which is the case when @xmath1 is a euclidean space , this result gives the usual parametric convergence rate of @xmath107 . in general ,",
    "the rate of convergence is determined by the local geometry near the minimum as quantified in ( p2 ) and ( u2 ) .",
    "the proof of the pointwise result follows along the lines of theorem 3.2.5 in which deals with @xmath73-estimators , where some additional considerations are needed to deal with the necessary estimation of the mean and covariance of @xmath5 .",
    "the uniform result is more difficult , as an uncountable number of @xmath73-estimators are considered simultaneously and no parametric form of the regression function is available .",
    "a case of particular interest arises in the field of functional data , where the observed objects are functions and are usually assumed to be ( almost surely ) square - integrable , e.g. , @xmath108 $ ] ) .",
    "classical examples of functional data include daily or monthly precipitation curves or growth curves for children .",
    "going beyond functional data as responses , we more generally assume that @xmath1 is a separable hilbert space with inner product @xmath109 and corresponding norm @xmath110 . as before ,",
    "let @xmath10 be a distribution on @xmath111 with @xmath4 .",
    "the following development is for object spaces that are separable hilbert spaces , enabling linear operations .",
    "first , we show that , under mild assumptions on the moments of @xmath10 , the minimizing objects in ( [ eq : mp ] ) and ( [ eq : mp_est ] ) can be given explicitly . unsurprisingly , for the case of functional data , the minimizer of ( [ eq : mp_est ] ) corresponds exactly to the estimator given in .",
    "we will use the following notation . for @xmath112 ,",
    "let @xmath113 be the @xmath114-fold cartesian product of @xmath1 , with inner product @xmath115 for @xmath116 , so that @xmath113 is also a hilbert space .",
    "for @xmath117 a @xmath118 matrix , @xmath57 , @xmath119 and @xmath120 , we define @xmath121 with elements @xmath122 , @xmath123 and @xmath124 with elements @xmath125 .",
    "[ thm : hilbert1 ] a. let @xmath4 and suppose that @xmath126 .",
    "then there exist unique elements @xmath127 and @xmath128 which satisfy , for all @xmath119 and @xmath129 , @xmath130 with @xmath15 and defining @xmath131 and @xmath132 , the solution to ( [ eq : mp ] ) is @xmath133    b. define estimators @xmath134 , , @xmath135 and @xmath136 .",
    "the solution of ( [ eq : mp_est ] ) is given by @xmath137    results and demonstrate that explicit solutions of the minimization problems that define the frchet regression are available for the case of responses that are random objects in hilbert space .",
    "moreover , in this situation one can also obtain limiting distributions , as follows .",
    "[ thm : hilbert2 ] set @xmath138 and @xmath139 . under the assumptions of theorem  [ thm : hilbert1 ] , @xmath140 where ` @xmath141 ' denotes weak convergence and @xmath142 is a zero mean gaussian process on @xmath143 .",
    "the covariance structure of @xmath142 is defined by projection covariances @xmath144 , where @xmath145 , @xmath146 is the covariance matrix of the vector defined in ( [ eq : z_vector ] ) in the appendix and @xmath147 can be constructed using the expressions in ( [ eq : l_alpha ] ) in the appendix .",
    "we next consider weak convergence of the process @xmath148 as @xmath24 varies in @xmath7 . for any @xmath149 ,",
    "define the function space @xmath150 with norm @xmath151 .",
    "we have the following corollary of theorem  [ thm : hilbert2 ] .",
    "[ cor : hilbert ] let @xmath77 be arbitrary , and define @xmath152 . under the assumptions of theorem  [ thm : hilbert1 ]",
    ", @xmath153 additionally , there is a zero - mean gaussian process @xmath154 on @xmath155 such that @xmath156 where @xmath157 is restricted to @xmath155 .",
    "these results show that one can take advantage of the additional structure that is available in the case of hilbertian objects to obtain limit distributions of the estimates .",
    "limit distributions are not available for general object spaces due to the lack of a linear structure . generally , even for the simpler case of frchet means , limit results can not be directly obtained . for random objects that fall on manifolds satisfying certain regularity conditions , limit theorems",
    "can be obtained after mapping the random objects into a linear space @xmath7 and then obtaining a @xmath158variate limit distribution .",
    "as the success of nonparametric regression methods over the last decades has shown , there is sometimes the need for local rather than global fitting of regression functions , which is more flexible but on the other hand requires choosing a tuning parameter that balances bias and variance .",
    "similarly , the proposed frchet regression analysis can be extended from the global setting as described in the previous sections to a local version .",
    "the idea is to adopt the concepts of local linear regression , which has been established for real - valued responses , and then to extend them to the case where responses are random objects , in analogy to the developments in section  [ ss : frechet ] for global frchet regression .    for ease of representation ,",
    "we consider here the case of a scalar predictor @xmath159 , where @xmath160 ; the local method can also be developed for any @xmath161 with @xmath162 .",
    "the target is again ( [ eq : frechet_regression ] ) , where we make no structural assumptions on @xmath42 .",
    "consider the preliminary case @xmath23 , and again write @xmath163 . in this case , the local linear estimate of @xmath39 is @xmath164 , where @xmath165 with @xmath166 here , @xmath167 is a smoothing kernel that corresponds to a probability density and @xmath168 is a bandwidth . in this sense ,",
    "the estimates @xmath169 and @xmath170 can be viewed as @xmath73-estimators of @xmath171 ^ 2{\\rm d}f_x(z ) .\\ ] ]    defining @xmath172 $ ] , @xmath173 $ ] and @xmath174 , the solutions to ( [ eq : local_target ] ) are @xmath175 this means that @xmath176 can be viewed as an estimator of the intermediate target @xmath177{\\rm d}f(z , y ) \\label{eq : local_sol2 } \\\\ & = e[s(x , x , h)y ] \\nonumber\\end{aligned}\\ ] ] for the weight function @xmath178\\right\\}.\\ ] ] observing that @xmath179 it follows that @xmath180 in ( [ eq : local_sol2 ] ) corresponds to a localized frchet mean , @xmath181 .",
    "\\label{eq : local_smooth}\\ ] ] the minimizer @xmath180 in ( [ eq : local_smooth ] ) can be viewed as a smoothed version of the true regression function , with the bias @xmath182 as @xmath183 . under mild assumptions on the kernel and distribution @xmath10 ,",
    "this bias is @xmath184 , which follows from a taylor expansion argument .",
    "now we are in a position to define the local regression concept for random objects @xmath185 , in analogy to the global frchet regression",
    ". specifically , ( [ eq : local_smooth ] ) can be generalized by defining @xmath186 $ ] , where the dependency on @xmath187 is through the bandwidth sequence @xmath188 , and then setting @xmath189 in contrast to euclidean spaces or riemannian manifolds , no version of a taylor expansion argument is available on general metric spaces @xmath1 .",
    "so one can ask why this weighted frchet mean provides a good approximation to the conditional mean in ( [ eq : frechet_regression ] ) .",
    "it turns out that this is due to the fact ( shown in the proof of theorem  [ thm : local_bias ] below ) that @xmath190\\dy = { \\rm d}f_{y|x}(x , y ) + o(h^2),\\ ] ] so that minimizing @xmath191 is approximately the same as minimizing the conditional frchet function @xmath22 .",
    "the target @xmath192 can be estimated by using preliminary estimates @xmath193 , @xmath194 , and the empirical weights @xmath195.\\ ] ] then , setting @xmath196 , the local frchet regression estimate is @xmath197 while this local estimation technique is novel for general metric space data , it is of interest to compare it to other local estimators that have been previously considered for spaces with additional structure , specifically the intrinsic local polynomial ( ilpr ) estimator for manifold data proposed in .",
    "these authors consider covariance matrices as objects to be regressed against scalar predictors .",
    "whereas the ilpr estimator requires various technical steps involving exponential , logarithmic and parallel transport maps on the manifold , one advantage of the methodology proposed here is its simplicity , only requiring one to be able to compute distances between data objects . in terms of computation on manifolds",
    ", the current method also enjoys the distinct advantage of requiring optimization only for a single object , unlike the ilpr for which one has to fit both intercept and derivative terms .",
    "it is of course also much more general , providing consistent estimators in unstructured metric spaces .    for a concrete comparison of frchet regression with the ilpr , take @xmath1 to be the space of covariance matrices with @xmath9 being the log - euclidean metric , that is , @xmath198 , where @xmath97 is the frobenius metric and @xmath199 is the inverse of the matrix exponential exp",
    ". in this case , both",
    "the ilpr and local frchet regression estimates can be computed analytically . for a sample @xmath200 , with @xmath201 a positive definite covariance matrix ,",
    "both methods yield the estimate @xmath202 where @xmath203 . that these two methods coincide is not altogether surprising due to the metric being the euclidean metric on transformed matrices .",
    "however , it shows that in this situation local frchet regression gives a sensible and intuitive estimate which coincides with the previously established manifold - based estimator .    turning back to theory , in order to obtain the rate of convergence for the quantity @xmath204",
    ", we need to quantify the convergence of the bias term @xmath205 and the stochastic term @xmath206 .",
    "this requires the assumptions below .",
    "recall that . for simplicity ,",
    "we assume the marginal density @xmath207 of @xmath5 , within the joint distribution @xmath10 , to have unbounded support , and consider points @xmath100 for which @xmath208 .",
    "we need the following assumptions .    *",
    "the kernel @xmath167 is a probability density function , symmetric around zero .",
    "furthermore , defining @xmath209 , @xmath210 and @xmath211 are both finite . * the object @xmath56 exists and is unique .",
    "for all @xmath187 , @xmath192 and @xmath212 exist and are unique , the latter almost surely . additionally , for any @xmath61 , @xmath213 * the marginal density @xmath207 of @xmath5 , as well as the conditional densities @xmath214 of , exist and are twice continuously differentiable , the latter for all @xmath215 , and @xmath216 .",
    "additionally , for any open @xmath217 , @xmath218 is continuous as a function of @xmath24 .",
    "* there exists @xmath219 , @xmath220 and @xmath221 such that @xmath222 provided @xmath223 .",
    "* there exists @xmath224 , @xmath225 and @xmath226 such that @xmath227 \\geq c_2d(\\om , \\tlp(x))^{\\beta_2},\\ ] ] provided @xmath228 .",
    "assumptions ( k0 ) and ( l1 ) are common in local regression estimation and imply that the smoothed marginal distribution @xmath229 converges to @xmath230 as @xmath183 , while ( l2 ) and ( l3 ) provide the rate for the bias and stochastic terms , respectively . while ( l1 ) is a distributional assumption , ( l2 ) and ( l3 ) can be shown to hold for examples  [ exm : wass][exm : manifold ] in section  [ sec : theory ] using arguments similar to those in propositions  [ prop : wass][prop : manifold ] in the appendix . in these cases , it is easy to verify that @xmath231 , @xmath232 and @xmath233 arbitrary , @xmath234 , are admissible in ( l2 ) and ( l3 ) .",
    "we now state our main results for local frchet regression , where the first result is for the bias , the second for the stochastic deviation and the corollary combines these results .",
    "[ thm : local_bias ] if ( k0 ) , ( l0 ) , ( l1 ) , ( l2 ) and ( p1 ) hold , then @xmath235 as @xmath236",
    ".    [ thm : local_frechet ] if ( k0 ) , ( l0 ) , ( l3 ) and ( p1 ) hold , and if @xmath183 and @xmath237 , then @xmath238.\\ ] ]    [ cor : cor2 ] under the assumptions of theorem  [ thm : local_bias ] and theorem  [ thm : local_frechet ] , among bandwidth sequences @xmath239 , the optimal sequence is obtained for and yields the rate @xmath240    we note that for @xmath241 , one obtains the result @xmath242\\ ] ] that is familiar for local regression with real valued responses , and with @xmath243 leads to the rate @xmath244 while the above results are pointwise , we remark that the same rate will hold uniformly in @xmath24 over compact intervals by suitably strengthening assumptions ( l0 ) , ( l2 ) and ( l3 ) .",
    "consider the space @xmath1 of distribution functions equipped with the wasserstein metric , as outlined in example  [ exm : wass ] in section 3 . to implement the minimization required by ( [ eq : mp_est ] ) using a sample @xmath200 , @xmath245 , of covariates and densities ,",
    "first define @xmath246 to be the quantile function corresponding to @xmath247 , for any @xmath119 , and let @xmath248 be the inverse map , mapping quantile functions to their associated distribution . set @xmath249 , where the weights @xmath250 are given in ( [ eq : emp_weights ] ) .",
    "note that @xmath251 is a function on @xmath252 $ ] .",
    "then the frchet regression estimator is @xmath253 where we refer to the proof of proposition  [ prop : wass ] in the appendix for details .",
    "now , let @xmath254 , @xmath255 be an equispaced grid on @xmath252 $ ] and let @xmath256 .",
    "then compute @xmath257 subject to the constraint @xmath258 .",
    "this optimization problem is a quadratic program and can be solved using a variety of techniques .",
    "the solution @xmath259 represents a discretized version of the approximation of the quantile function @xmath260 .      to assess the performance of the global frchet regression estimator in ( [ eq : mp_est ] )",
    ", it is first necessary to determine a generative model in order to simulate the data .",
    "the space of distributions with the wasserstein metric provides an ideal setting for this .",
    "the responses @xmath6 are distributions with quantile functions @xmath261 and the predictors are random variables @xmath262 . for notational simplicity , the quantile function corresponding to @xmath6 will also be denoted as @xmath6 .",
    "the regression function is @xmath263 where @xmath264 is the standard normal quantile function , @xmath265 , @xmath266 and @xmath267 , @xmath268 .",
    "this corresponds to the response distributions being , on average , a normal distribution with parameters that depend linearly on @xmath24 .",
    "the random response @xmath6 is generated conditional on @xmath5 by adding noise to the quantile functions . in the first setting ,",
    "the distribution parameters @xmath269 and @xmath270 are independently sampled , and the corresponding distribution is @xmath271 . in the second setting , after sampling the distribution parameters as in the previous setting , the resulting distribution is  transported \" in wasserstein space following a simplified version of the algorithm outlined in section 8.1 of .",
    "specifically , random transport maps @xmath272 ( increasing diffeomorphisms of the real line ) are generated by sampling uniformly from the collection of transport maps @xmath273 , for @xmath274 , with @xmath275 .",
    "this second setting is significantly more complex , as the observed distributions are no longer gaussian .",
    "random samples of pairs @xmath200 , @xmath245 were generated by sampling @xmath276 , setting @xmath277 , @xmath278 , @xmath279 and @xmath280 , and following the above procedure for the two simulation settings . in the first",
    "setting , the parameter variances were set at @xmath281 and @xmath282 . in the second ,",
    "the values were @xmath283 and @xmath284 , with @xmath285 used for generating the transport maps . in each setting , @xmath286 runs were executed for three sample sizes @xmath287 . for the @xmath95-th simulation of a particular sample size , let @xmath288 denote the fitted quantile function .",
    "the quality of the estimation was measured quantitatively by the integrated squared errors @xmath289    in the first simulation setting , we verify that frchet regression is performing as expected by comparing to the best - case scenario where one knows the finite - dimensional generating model .",
    "that is , one computes the mean @xmath290 and standard deviation of @xmath291 of the distribution @xmath201 and linear regresses them against @xmath292 , while restricting the estimates of @xmath267 and @xmath293 such that the regression line is positive on @xmath294 $ ] .",
    "thus , one can compare this  oracle \" linear regression with frchet regression by computing its integrated squared error for each simulation run .",
    "these errors for each method are shown in boxplots in figure  [ fig : ise_boxplot_low ] , where it is clear that frchet regression performs just as well as the oracle procedure .",
    "in fact , sign - rank tests were performed to test the hypothesis of no difference between the methods for each sample size , with the smallest of the three @xmath161-values being @xmath295 .    [ 2.4 in ] boxplots of integrated squared errors for @xmath286 simulation runs and three sample sizes @xmath187 .",
    "the left panel compares frchet regression ( fr ) with the oracle linear regression ( or ) , while the right shows results only for frchet regression.,title=\"fig : \" ] [ 2.4 in ] boxplots of integrated squared errors for @xmath286 simulation runs and three sample sizes @xmath187 .",
    "the left panel compares frchet regression ( fr ) with the oracle linear regression ( or ) , while the right shows results only for frchet regression.,title=\"fig : \" ]    in the second simulation setting , the random transportation renders the oracle linear regression technique above inadmissable , since the standard deviation of the transported distribution no longer has a linear relationship with @xmath5 .",
    "however , the global frchet regression model still holds true .",
    "figure  [ fig : ise_boxplot_hi ] shows the decreasing integrated squared errors for increasing sample sizes , demonstrating the validity and utility of our method for this regression setting .",
    "many studies and analyses have been motivated by a desire to understand human longevity .",
    "of particular interest is the evolution of the distributions of age - at - death over calendar time .",
    "the human mortality database provides such data in the form of yearly lifetables , differentiated by country .",
    "currently , this database includes yearly mortality and population data for 37 countries that are available at link:<www.mortality.org>[<www.mortality.org > ] .    for a given country and calendar year",
    ", the probability distribution for mortality can be represented by its density .",
    "a first step is to estimate this density from the data in the lifetables for a specified country . consider a country for which lifetables are available for the years @xmath296 , @xmath245 .",
    "for integer - valued ages @xmath297 , @xmath298 , the lifetable provides the size of the population @xmath299 which is at least @xmath297 years old , normalized so that @xmath300 .",
    "these values can be used to construct a histogram for age - at - death , which in turn can be smoothed using a local linear smoother to obtain an estimate of the density .",
    "this smoothing step was performed in ` matlab ` using the ` hades ` package , available at < http://www.stat.ucdavis.edu/hades/>[<http://www.stat.ucdavis.edu/hades/ > ] .",
    "each density was estimated for ages in the interval @xmath301 $ ] , with a smoothing bandwidth of @xmath302 .",
    "[ 2.2 in ] [ 2.2 in ] [ 2.2 in ]    as an initial example , we consider the data for chile , which has mortality data available for the years 19922008 .",
    "using the procedure outlined above , mortality density estimates @xmath201 were obtained for the years @xmath303 , @xmath304 .",
    "these estimates are shown as a heat map in figure  [ fig : chile ] , linearly interpolating between years for continuity . the variation from year to year",
    "is marked by a steady increase in both the location and height of the peak in mortality .",
    "the frchet regression fits using calendar year as predictor for linear ( @xmath305 ) and quadratic ( @xmath306 ) models are shown in figures  [ fig : chile_lin ] and [ fig : chile_quad ] , respectively .",
    "similar to the least squares regression plane , these fits provide a smooth visualization of the evolution of mortality and remove the noise that is visible in the raw density data .",
    "there seems to be little gain in fitting a quadratic model , as the frchet regression fits with linear and quadratic predictors are very similar .",
    "leave - one - out prediction errors were 0.088 for the linear fit and 0.0972 for the quadratic fit , indicating that the simpler linear model is indeed preferable .",
    "next , we consider the data for luxembourg , with mortality lifetable data ranging from 19602009",
    ". the density estimates for these years are shown in figure  [ fig : lux_dens ] .",
    "we see a slightly more complicated evolution of mortality for luxembourg compared to chile . for example , the mode of the density does not steadily increase over the years ; rather , the mode seems to carve out a curved path . figure  [ fig : lux_lin ] and [ fig : lux_quad ] show the frchet regression fits for the linear and quadratic model , i.e. @xmath305 for the linear model and @xmath306 for the quadratic model .",
    "the quadratic fit is better at capturing the shape of the peak dynamics observed in the raw sample of densities .",
    "the adjusted frchet @xmath2 values are 0.9714 and 0.9748 for the linear and quadratic models , respectively .",
    "these extensions of the coefficient of variation are introduced in the next subsection . to further assess the quality of each model , leave - one - out prediction errors were computed , resulting in an average prediction error of 0.5629 for the linear model and 0.2709 for the quadratic model .",
    "hence , the quadratic model seems to be indeed better for both fitting and prediction .",
    "[ 2.2 in ] [ 2.2 in ] [ 2.2 in ]      many of the standard inferential tools that are available for ordinary linear regression depend on the algebraic structure of @xmath88 , and thus can not be directly extended to the proposed frchet regression for metric - valued data .",
    "however , one tool which does generalize is the coefficient of determination , @xmath2 .",
    "recall that , in multiple regression with real valued responses , @xmath2 may be interpreted as the fraction of variance of the response which can be explained by a linear relationship with the predictor variables , i.e. @xmath307 using the generalized notion of variance in ( [ eq : frechet_mv ] ) and the sample frchet mean @xmath308 a corresponding frchet @xmath2 coefficient of determination can be defined as @xmath309}{v_\\oplus},\\ ] ] where @xmath310 is the frchet variance defined in ( [ eq : frechet_mv ] ) .",
    "given a random sample @xmath200 , @xmath245 , the value @xmath311 can be estimated by @xmath312 this statistic can then be used in a similar manner as the ordinary coefficient of determination @xmath2 to perform inference and model selection .    in the current setting of frchet regression ,",
    "the null hypothesis of no effect is equivalent to testing @xmath313 , for which the estimate @xmath314 can be used as a test statistic . in order to obtain a @xmath161-value ,",
    "a permutation test can be performed .",
    "first , the values @xmath292 , @xmath315 are permuted to form a new sample @xmath316 , @xmath317 . for each new predictor sample ,",
    "a frchet regression is fitted , using the pairs @xmath318 , and the value @xmath314 is computed for each of these regression fits . by performing a large number of such permutations and fits , one then obtains an empirical approximation of the null distribution of the test statistic and a @xmath161-value by calculating the quantile of the actually observed @xmath314 within this null distribution .",
    "another potential application of the coefficient @xmath319 is model selection , where one can mimic the use of the adjusted @xmath2 in linear regression by fitting frchet regression models that use various subsets of the predictor variables . for a fitted submodel @xmath320 using @xmath321 predictor values ,",
    "the adjusted frchet @xmath2 is then @xmath322 let @xmath323 be the class of submodels using @xmath114 predictors , @xmath324 .",
    "computing @xmath325 the final model can then be taken as @xmath326 .",
    "another alternative for model selection is to minimize prediction error , which can be estimated by @xmath327-fold cross validation .",
    "here we consider a space of random objects @xmath1 which consists of correlation matrices , i.e. the space of square @xmath96 symmetric positive semidefinite matrices with unit diagonal , for some positive integer @xmath95 , and equip @xmath1 with the frobenius metric @xmath97 .",
    "correlation matrices have been studied previously from the random object perspective under different metrics . from a sample @xmath200 , @xmath328 , the minimization in ( [ eq : mp_est ] )",
    "can be reformulated by setting @xmath329 and computing ( see proof of proposition  [ prop : correlation ] in the appendix for details ) @xmath330 thus , the problem is reduced to finding the correlation matrix which is nearest to the matrix @xmath331 .",
    "this problem has been well studied , and in our implementations we used the alternating projections algorithm , written by nicholas higham and available at < https://nickhigham.wordpress.com/2013/02/13/the-nearest-correlation-matrix/>[<https://nickhigham.wordpress.com/2013/02/13/the-nearest-correlation-matrix/ > ] , to carry out this optimization .      in recent years",
    ", the problem of identifying functional connectivity between brain voxels or regions has received a great deal of attention , especially for resting state fmri .",
    "subjects are asked to relax while undergoing a fmri brain scan , where blood - oxygen - level dependent signals are recorded and then processed to yield voxel - specific time courses of signal strength .",
    "the connectivity between brain regions is usually quantified by the temporal correlation between representative time signals of the two regions .",
    "higher levels of correlation are reflective of higher connectivity , giving rise to the question which subject - specific factors might explain observed variations in connectivity . when considering @xmath332 brain regions , the resulting number of pairwise correlations is @xmath333 , so that standard statistical models are inadequate for investigating the relationship between several predictors and the connectivity response .",
    "frchet regression can be employed to directly addresses this issue by viewing the functional connectivity measurements in a natural way as random elements of the space of correlation matrices .",
    "the data for our analysis come from a study of 174 cognitively normal elderly patients , each of whom underwent an fmri scan at the uc davis imaging research center .",
    "preprocessing of the recorded bold ( blood oxygenation - level - dependent ) signals was implemented by adopting the standard procedures of slice - timing correction , head motion correction and normalization , in addition to linear detrending to account for signal drift and band - pass filtering to include only frequencies between 0.01 and 0.08 hz .",
    "of particular interest regarding functional connectivity in the resting state is the so - called default - mode network ( dmn ) , including the study of age - related effects ; see the review article and references therein .",
    "one study investigated disruptions between anterior - posterior components in the dmn as subjects age .",
    "part of their findings indicated a decrease in connectivity between a seed region in the left ventral medial prefrontal cortex ( lvmpfc ) and three other voxels located within the right vmpfc / orbitofrontal ( rvmpfc ) , left ventral posterior cingulate cortex ( lvpcc ) and right precuneus / pcc ( rppcc ) regions , respectively .    to construct a connectivity correlation matrix for each subject , signals at these @xmath334 locations",
    "were extracted and their temporal correlations computed .",
    "these signals are taken over the interval [ 0 , 470 ] ( in seconds ) , with @xmath335 measurements available at 2 second intervals .",
    "hence , for the @xmath336th subject , the data are in the form of an @xmath337 signal matrix @xmath338 where the rows correspond to consecutive time points and the columns to distinct voxels . define @xmath339 and @xmath340 .",
    "the connectivity correlation matrix @xmath201 for the @xmath336th subject as it is routinely calculated for analyzing connectivity in fmri has the elements @xmath341^{1/2}}.\\ ] ]    [ 2.34 in ] [ 2.34 in ] + [ 2.34 in ] [ 2.34 in ] + [ 2.34 in ] [ 2.34 in ]    in our regression model , we use age as a predictor of connectivity and fit both linear and quadratic models , i.e. @xmath342 and @xmath343 , where @xmath344 is the age of subject @xmath336 , @xmath345 . one notable difference between the current data and those used in is the age range .",
    "the current analysis includes only elderly subjects , aged 64 to 94 years , while included subjects between 19 and 80 years of age .",
    "it has been observed previously that age - related effects are more difficult to detect in later years .",
    "thus , the goal for our analysis is to investigate if the decreases in connectivity observed in are also found among a group of strictly elderly subjects , or whether a different pattern is present altogether .",
    "figure  [ fig : dmn_con ] illustrates the regression results for each component of the lower subdiagonal of the correlation matrix .",
    "a @xmath161-value for each model was computed , along with an estimated mean - square prediction error ( mspe ) as calculated by five - fold cross validation , averaged over 50 runs .",
    "the linear model had a @xmath161-value of @xmath346 , with a mspe of @xmath347 and an @xmath348 .",
    "the quadratic model was a much better fit , with a @xmath161-value of @xmath349 , a mspe of @xmath350 and @xmath351 .",
    "these results indicate that age - related changes in connectivity are more subtle in later years , with subjects over 85 demonstrating greater connectivity between some regions than younger subjects between the ages of 75 and 85 . while some studies have found",
    "increased connectivity with age , our quadratic model reveals that simple linear associations between age and connectivity may be inadequate in describing these dynamics , particularly within the subpopulation of the elderly .",
    "as a final illustration , we implement the local frchet regression for a situation where the random object responses lie in a riemannian manifold object space . specifically , let @xmath352 be the unit sphere in @xmath353 , with geodesic distance @xmath354 and consider the regression function @xmath355 which maps a spiral on the sphere . to generate a random sample @xmath200 , @xmath245 ,",
    "@xmath356 was first sampled , followed by a bivariate normal random vector @xmath357 on the tangent space @xmath358 .",
    "finally , with @xmath76 being the euclidean norm , @xmath359 random samples of size @xmath287 were generated under two noise scenarios , with 200 runs for each simulation . in both noise scenarios ,",
    "the components of @xmath357 were independent , with each having a variance of @xmath360 and @xmath361 in the low and high noise scenarios , respectively .",
    "figure  [ fig : sphere_samples ] shows two sample data sets of size 50 for the two noise scenarios .    [ 2.4 in ] [ 2.4 in ]    for estimation , a grid of bandwidths @xmath362 was used for the smoothing , with @xmath167 being the epanechnikov kernel . in addition to the local frchet regression method , we also implemented local constant smoothing as a comparison , using the same bandwidth grid and kernel .",
    "the necessary optimization was performed using the trust regions algorithm as implemented in the manopt toolbox for matlab .",
    "while we found this to be an adequate computational tool for our simulations , it may be necessary in some scenarios to implement a stochastic optimization scheme , such as the annealing algorithm demonstrated in .    to compare local frchet regression with local constant smoothing , for each combination of noise setting and sample size , the mean integrated squared error ( mise ) of each method was computed across the grid of bandwidths , and the minimum value is shown in table  [ tab : sphere_mise ] .",
    "we see that local frchet regression outperforms local constant smoothing in every setting .",
    "additionally , one can get a sense of the bias of the different fits by taking frchet averages of the fits @xmath60 across simulations , for a grid of levels @xmath363 $ ] .",
    "for example , these averaged local frchet and local constant regression fits , using the bandwidths which minimize mise , are shown in figure  [ fig : sphere_fits ] for the high noise setting with @xmath364 .",
    "again , the local frchet method is found to be superior , especially in terms of performance near the boundaries .",
    ".best mise values for local frchet regression ( lf ) and local constant ( lc ) fits .",
    "the minimizing bandwidth is shown in parentheses.[tab : sphere_mise ] [ cols=\"<,<,^,^\",options=\"header \" , ]     [ 2.4 in ] [ 2.4 in ]",
    "the proposed frchet regression provides a tool for the analysis of random objects as they are increasingly encountered in modern data analysis .",
    "we provide theoretical justifications including rates of convergence for this approach for which we have developed global and local versions . for practical applications of the global frchet regression model",
    ", we have also introduced the concept of the frchet coefficient of determination , @xmath365 , and its potential for use in model selection .",
    "we focus in this paper on estimation , and future work will be needed to develop formal tests , confidence sets and predictor selection .    for the development of the local version of frchet regression makes it proved necessary to revisit what is meant by the concept of a local regression and to clarify what the target is . in examples local frchet regression proved competitive with previously discussed methods for special object spaces .",
    "an interesting special case for which we derive limit distributions is the case of responses that live in a hilbert space , such as functional data .",
    "the regression approach for responses that are general random objects has a wide range of applications and specifically includes responses that lie in a riemannian manifold as a special case .",
    "for this special case , we show that our general and straightforward approach is not only theoretically competitive but also works well in simulations .",
    "our examples demonstrate some of the possibilities for distributions and correlation matrices as responses .",
    "other examples might include networks , trees or whole brain connectivity matrices , where it is often of interest to describe the dependency of such objects on covariates .",
    "extensions that fall within the framework that we outline also include linear models that are related to linear regression , such as analysis of variance and , more generally , regression models that include indicators among the predictors .",
    "for any distribution @xmath119 , let @xmath246 be the corresponding quantile function . similarly , @xmath367 is the distribution corresponding to @xmath368 .",
    "let @xmath369 , @xmath370 and @xmath371 be the @xmath372 inner product , norm and distance on @xmath252 $ ] , respectively . since @xmath373 is finite , the riesz representation theorem implies the existence of an element @xmath374 $ ] such that @xmath375 for all @xmath368 .",
    ". then properties of the @xmath372 distance imply @xmath377 yielding the solutions @xmath378 which exist and are unique by convexity of @xmath379 for any @xmath57 , hence proving ( p0 ) and ( u0 ) .",
    "additionally , @xmath56 is characterized by @xmath380 for all @xmath368 .",
    "consequently , we may take @xmath381 , @xmath99 and @xmath382 and @xmath383 arbitrary in ( p2 ) and ( u2 ) .",
    "lastly , since quantile functions are monotone , ( u1 ) and ( p1 ) follow from theorem 2.7.5 in .      here",
    ", @xmath6 is an @xmath96 correlation matrix .",
    "denote the elements of @xmath6 as @xmath385 , @xmath386 .",
    "let @xmath387 , @xmath388 and @xmath389 be the frobenius inner product , norm and distance , respectively .",
    "let @xmath390 and @xmath391 .",
    "then properties of the frobenius distance imply that @xmath392 yielding the solutions @xmath393 which exist and are unique by the convexity of @xmath1 for any @xmath57 , hence proving ( p0 ) and ( u0 ) .",
    "additionally , @xmath56 is characterized by @xmath394 for all @xmath119 .",
    "consequently , we may take @xmath382 and @xmath383 arbitrary , @xmath381 and @xmath99 in ( p2 ) and ( u2 ) .",
    "lastly , ( u1 ) and ( p1 ) follows since @xmath1 is a bounded subset of the larger finite - dimensional euclidean space of @xmath96 matrices .",
    "[ prop : manifold ] the space @xmath8 defined in example  [ exm : manifold ] satisfies ( p1 ) and ( u1 ) .",
    "let @xmath395 be the tangent bundle at @xmath247 and @xmath396 and @xmath397 be the exponential and logarithmic manifold maps at @xmath247 . for @xmath398",
    ", define @xmath399 if ( p0 ) holds and @xmath400 is positive definite , then ( p2 ) holds .",
    "similarly , if ( u0 ) holds then @xmath401 implies ( u2 ) , where @xmath402 is the smallest eigenvalue of a square matrix @xmath117 .",
    "assumption ( u1 ) follows since @xmath1 is bounded and of finite dimension , and ( p1 ) follows as a weaker condition .",
    "if ( p0 ) holds , let @xmath403 be the injectivity radius at @xmath56 and consider @xmath247 such that @xmath404 .",
    "taking @xmath405 , @xmath406 for some @xmath407 between @xmath98 and @xmath408 . since @xmath409 and @xmath410 is continuous , the condition on @xmath411 implies ( p2 ) with @xmath105 .",
    "similar arguments using the other conditions show that @xmath106 in ( u2 ) is permissible .      throughout , the symbol @xmath141 will denote weak convergence and the notation @xmath412 denotes the space of bounded functions on @xmath1 .",
    "the ordinary euclidean norm on @xmath7 will be denoted by @xmath76 and the frobenius norm by @xmath413 . for simplicity of notation , when @xmath24 is fixed , the dependence of objects such as @xmath73 , @xmath42 , etc . on @xmath24 will be dropped .",
    "we first consider fixed @xmath57 . by corollary 3.2.3 in , convergence of @xmath414 to zero in probability",
    "is sufficient . to do this",
    ", we show @xmath415 in @xmath412 and apply 1.3.6 of .",
    "this weak convergence is proved ( see theorem 1.5.4 of ) by showing that      begin with i ) . set @xmath418\\ ] ] and define @xmath419 then , for all @xmath119 , @xmath420 and @xmath421 so @xmath422 . also , setting @xmath423 we have @xmath424",
    ". then @xmath425 for all @xmath119 , since @xmath426 and @xmath427 are both @xmath428 . using the triangle inequality ,",
    "we have proven i ) .",
    "hence , for any @xmath429 and @xmath430 , we have @xmath431 .      for the uniform result , consider the process @xmath439 , so @xmath440 for any @xmath57 . by theorem 1.5.4 in , it suffices to show that , for any @xmath441 and as @xmath442 , @xmath443 because @xmath444 , it suffices to show that @xmath445 is uniformly continuous for @xmath78 and that , as @xmath442 , @xmath446    let @xmath62 and @xmath24 , @xmath447 with @xmath448 . from the form of @xmath73 , it is clear that @xmath449 as @xmath442 .",
    "assumption ( u0 ) then implies that @xmath42 is continuous at @xmath24 , and thus uniformly continuous over @xmath78 . to show ( [ eq : hmp_cont ] ) , let @xmath61 and suppose @xmath450 with @xmath451 , @xmath452 .",
    "then ( u0 ) and the form of @xmath74 imply that @xmath453 and the result follows when @xmath442 .",
    "let @xmath57 being fixed and write @xmath454 .",
    "we follow the proof of theorem 3.2.5 in with a few modifications .",
    "a key component of this proof is the process @xmath455 .",
    "let @xmath456 and @xmath457 be as in ( [ eq : si_weights ] ) .",
    "then @xmath458 this quantity needs to be controlled for small @xmath459 .",
    "first , let @xmath426 and @xmath460 be as defined in ( [ eq : ws ] ) . to control the first term on the right - hand side of ( [ eq : v_expand ] ) , observe that @xmath461 so that the left hand side is @xmath462 .",
    "using this fact , we can define @xmath463 for @xmath464 , so that @xmath465 as @xmath466 .",
    "next , to control the second term on the right - hand side of ( [ eq : v_expand ] ) uniformly over small @xmath459 , define the functions @xmath467 as @xmath468d^2(y , \\om)\\ ] ] and the function class @xmath469 an envelope function for @xmath470 is @xmath471 , and @xmath472 .",
    "define @xmath473 to be the entropy integral given in ( p1 ) , so that @xmath474 . then , theorems 2.7.11 and 2.14.2 of and ( p1 ) imply that , for small enough @xmath65 , @xmath475^{1/2}}{\\sqrt{n}},\\ ] ] so that the left - hand side is @xmath476 .",
    "hence , combining ( [ eq : v_expand ] ) , ( [ eq : diff_bound2 ] ) and the definition of @xmath477 , for small @xmath65 , @xmath478 for some @xmath479 .    to finish , set @xmath480 and @xmath481 choose @xmath68 to satisfy ( p2 ) and also small enough that ( p1 ) holds for all @xmath482 and set @xmath483 .",
    "for any integer @xmath484 , @xmath485 where @xmath465 as discussed previously and the second term goes to zero by lemma  [ lma : con ] . for each @xmath297 in the sum on the right - hand side of ( [ eq : bound ] )",
    ", we have , so this sum is bounded by @xmath486 because @xmath70 , the last series converges and hence this probability can be made small by choosing @xmath484 large .",
    "this proves the desired result that @xmath487 .      using the definition of @xmath493 in ( [ eq : si_weights ] ) , we can bound the second term on the right - hand side of ( [ eq : v_expand ] ) by @xmath494\\right|.\\end{aligned}\\ ] ] define the functions @xmath495 and @xmath496 , @xmath497 , as @xmath498 and the classes of functions @xmath499 the functions @xmath500 and @xmath501 are envelopes for @xmath502 and @xmath503 , respectively , and @xmath504 and @xmath505 are both @xmath506 .",
    "let @xmath507 be the entropy integral in ( u2 ) , so @xmath474 for small @xmath65 .",
    "for such @xmath65 , theorems 2.7.11 and 2.14.2 of @xcite provide the bound @xmath508^{1/2}}{\\sqrt{n } } = o(\\delta n^{-1/2}).\\nonumber\\end{aligned}\\ ] ] again , by combining ( [ eq : v_expand ] ) , ( [ eq : diff_bound3 ] ) and ( [ eq : diff_bound4 ] ) , for small @xmath65 , @xmath509 for some constant @xmath510 .",
    "this bound , together with ( u2 ) , the uniform result in lemma  [ lma : con ] and the fact that @xmath492 , can be used to obtain the result , similar to the pointwise case .",
    "recall the notation introduced in section  [ sec : hilbert ] .",
    "observe that , when @xmath247 ranges over @xmath1 , the object @xmath511 is a continuous linear operator under the assumption @xmath512 , so the existence and uniqueness of @xmath513 follows by the riesz representation theorem .",
    "the same is true for the operator @xmath514 , hence the existence and uniqueness of @xmath432 .",
    "next @xmath515    \\label{eq : ip_eq }   \\\\    & = { \\langle \\gamma_0 , \\om \\rangle } + e{\\langle ( x - \\mu)y , ( x - \\mu)^t\\si\\inv \\om \\rangle}_p \\nonumber\\\\    & = { \\langle \\beta_0 , \\om \\rangle } + { \\langle ( x - \\mu)^t\\si\\inv\\gamma_1 , \\om \\rangle } \\nonumber\\\\    & = { \\langle \\beta_0 + \\beta_1^t(x-\\mu ) , \\om \\rangle}.\\nonumber\\end{aligned}\\ ] ] set @xmath516 as in ( [ eq : mp_hilsol ] ) and observe that @xmath517 .",
    "then , by expanding the square , we have @xmath518 hence , the middle term vanishes using ( [ eq : ip_eq ] ) and we must have @xmath519 .",
    "as a weighted least squares problem , the empirical solution to ( [ eq : mp_est ] ) is clearly , which gives the proposed solution in ( [ eq : mp_est_hilsol ] ) .",
    "first , let @xmath520 and define @xmath138 and @xmath521 . by theorem 1.8.4 in chapter 1.8 of",
    ", we only need to prove that , for all @xmath522 , for the limiting process @xmath142 and that @xmath523 is asymptotically finite dimensional .",
    "the latter condition follows from the fact that @xmath524 and @xmath525 are @xmath428 and by the assumptions on the moments of @xmath526 .",
    "we will now prove the first condition .",
    "this will require the definitions below , for any @xmath527 matrix @xmath117 and symmetric @xmath118 matrix @xmath528 : @xmath529    let @xmath522 be fixed .",
    "define the @xmath118 matrices @xmath530 and @xmath531 with elements @xmath532 , and the vector @xmath533 with elements @xmath534 .",
    "also , define the vector @xmath535 with elements @xmath536 and the @xmath118 matrix @xmath383 with elements @xmath537 .",
    "let @xmath538 then , @xmath539 are independently and identically distributed with expected value @xmath540 @xmath541 \\rightsquigarrow \\mathcal{n}(0 , c_\\alpha).\\ ] ]    next , for @xmath542 , @xmath543 , @xmath91 a symmetric @xmath118 matrix and @xmath544 a @xmath118 matrix , define the function @xmath545_{jk}\\left(h_{jk } - a_jc_{k+1}\\right).\\ ] ] then @xmath546 and , similarly , @xmath547 .",
    "let @xmath147 be the gradient vector of @xmath548 evaluated at @xmath549 .",
    "the elements of @xmath147 can be computed as follows .",
    "let @xmath550 denote the kronecker product , @xmath551 be the vector of zeros with a single 1 in the @xmath552th entry , and @xmath553 be the @xmath118 matrix of zeros with a single 1 in the @xmath554th entry .",
    "set @xmath555 let @xmath556 be the @xmath552th column of @xmath557 and set @xmath558 .",
    "the vector @xmath147 can be formed using the values @xmath559 then , the @xmath65-method yields @xmath560    again , set @xmath520 .",
    "the first display in the corollary follows since @xmath561 is bounded by @xmath562 for the second result , note that lemmas 1.5.2 , 1.5.3 and theorem 1.5.4 of can be generalized to the space @xmath563 .",
    "then , we need to show that @xmath157 is asymptotically tight and that , for any finite collection @xmath564 , @xmath565 converges weakly to the corresponding marginals of @xmath154 .    for simplicity , take @xmath566 .",
    "similar to the proof of theorem  [ thm : hilbert2 ] , for fixed @xmath119 , define @xmath530 , @xmath567 and @xmath568 with elements @xmath569 . also , define @xmath570 , @xmath571 with elements @xmath572 , and set @xmath573 . then @xmath539 are independent with the same distribution and @xmath574 .",
    "letting @xmath575 , we have @xmath541 \\rightsquigarrow n(0 , c_\\om).\\ ] ] for @xmath576 , @xmath577 and @xmath91 a @xmath118 symmetric matrix , define @xmath578 it is easy to verify that @xmath579 and @xmath580 .",
    "define @xmath581 to be the gradient of @xmath582 evaluated at @xmath549 and set @xmath583 .",
    "then the bivariate delta method gives @xmath584 the process @xmath154 is characterized by the distribution of its marginals , as given above .    for tightness",
    ", first let @xmath585 be given , define an orthonormal basis @xmath586 for @xmath1 and let @xmath587 for any integer @xmath507 and @xmath119 . by combining theorem  [ thm : hilbert1 ] and lemma 1.8.1 of",
    ", there exists finite @xmath588 such that , with @xmath589 , @xmath590 note that @xmath591 so that , for any @xmath68 , @xmath592 by again combining theorem  [ thm : hilbert1 ] with lemma 1.8.1 of .",
    "this means that @xmath593 is tight by theorem 1.5.7 of , since @xmath594 takes values on the finite - dimensional euclidean space spanned by the first @xmath588 basis functions @xmath595 . for @xmath596 , define @xmath597 then there exists a compact set @xmath598 such that @xmath599 and , hence ,",
    "@xmath600 so @xmath157 is asymptotically tight .      for completeness , we include the elementary results of auxiliary lemma  [ lma : muj ] and its proof , which are well - known .",
    "the quantities of interest are @xmath601 , @xmath602 and the estimators @xmath603 , for @xmath604 .",
    "the statements regarding @xmath608 and @xmath609 follow from ( k0 ) and ( l1 ) using a second - order taylor expansions of the densities @xmath207 and @xmath214 .",
    "furthermore , @xmath610 is clear .",
    "next , @xmath611 so @xmath612 , proving the result for the @xmath613 .",
    "first , we will show that @xmath614 for all @xmath24 such that @xmath208 . for any open",
    "set @xmath615 , set @xmath616 by assumption , both @xmath617 and @xmath510 are continuous",
    ". then , for any @xmath618 , @xmath619 proving the claim .    next , using lemma  [ lma : muj ] @xmath620 where the error term is uniform over @xmath215 .",
    "hence , using the previously established fact that @xmath614 , @xmath621 where the error term is now uniform over @xmath119 . by ( l0 ) , we then have @xmath622 as @xmath236 .",
    "next , define @xmath623 and set @xmath624 .",
    "let @xmath625 denote the indicator function .",
    "then , for any @xmath626 , following similar arguments as the proof of theorem  [ thm : rate ] and using ( l2 ) , there exists @xmath479 such that , for large @xmath187 , @xmath627 which converges since @xmath221 .",
    "thus , for some @xmath626 , we have @xmath628 for large @xmath187 .        to begin , write @xmath631 $ ] .",
    "then the difference @xmath632 can be written as @xmath633d^2(y_i , \\om )    \\label{eq : l_expand}\\\\    & \\hspace{1.5 cm } + \\frac{1}{n}\\sn\\left(s_i(x , h)d^2(y_i , \\om ) - e\\left[s_i(x , h)d^2(y_i , \\om)\\right]\\right).\\nonumber    \\end{aligned}\\ ] ] observe that @xmath634 , where @xmath635 using the results of lemma  [ lma : muj ] , it follows that @xmath636 and @xmath637 . since @xmath638 & = o(h^j ) \\\\",
    "e\\left[k_h^2(x_i - x)(x_i - x)^{2j}d^4(y_i,\\om)\\right ] & = o(h^{2j-1 } )    \\end{aligned}\\ ] ] it follows that the first term in ( [ eq : l_expand ] ) is @xmath639 .",
    "one also finds that @xmath640 , so that the second term in ( [ eq : l_expand ] ) is also @xmath639    so far , we have shown that @xmath641 for any @xmath119 , since @xmath237 . according to theorem 1.5.4 in",
    ", the last thing we need to show is that , for any @xmath68 @xmath642 since @xmath643 and @xmath640 , @xmath644 .",
    "then , @xmath645 .",
    "similarly , @xmath646 , which verifies the above .",
    "we adopt similar arguments as in the proof of theorem  [ thm : rate ] , with some adjustments . set @xmath647 and define @xmath648 . letting @xmath649 we have @xmath650\\right)\\right|.\\nonumber\\end{aligned}\\ ] ] since @xmath426 and @xmath460 from ( [ eq : ws2 ] ) are @xmath639 and @xmath651 , respectively , and using the fact that @xmath652,the first term on the right - hand side of ( [ eq : t_expand ] ) is @xmath653 , where the @xmath435 term is independent of @xmath247 and @xmath192 .",
    "thus , we can define @xmath654d_i(\\om , x)\\right| \\leq r\\delta(nh)^{-1/2}\\right\\}\\ ] ] for @xmath464 , so that @xmath465 .",
    "next , to control the second term on the right - hand side of ( [ eq : t_expand ] ) , define the functions @xmath655 by @xmath656d^2(y , \\om)\\ ] ] and the corresponding function class @xmath657 an envelope function for @xmath658 is @xmath659 and @xmath660 . using this fact together with theorems 2.7.11 and 2.14.2 of and ( p1 ) , for small @xmath65 , @xmath661\\right|\\right ) = o(\\delta(nh)^{-1/2}).\\ ] ] combining this with ( [ eq : t_expand ] ) and the definition of @xmath477 ,",
    "@xmath662 where @xmath663 is the indicator function for the set @xmath477 and @xmath617 is a constant depending on @xmath664 and the entropy integral in ( p1 ) .",
    "to finish , set @xmath665 and define @xmath666 choose @xmath667 satisfying ( l2 ) and such that ( p1 ) is satisfied for any @xmath668 .",
    "set @xmath669 . for any integer @xmath73 , @xmath670 where the last term goes to zero for any @xmath68 by lemma  [ lma : local_consistent ] .",
    "since @xmath671 on @xmath672 , this implies that the sum on the right - hand side of ( [ eq : bound2 ] ) is bounded by @xmath673 which converges since @xmath226 .",
    "hence , @xmath674.\\ ] ]"
  ],
  "abstract_text": [
    "<S> increasingly , statisticians are faced with the task of analyzing complex data that are non - euclidean and specifically do not lie in a vector space . to address the need for statistical methods for such data , we introduce the concept of frchet regression . </S>",
    "<S> this is a general approach to regression when responses are complex random objects in a metric space and predictors are in @xmath0 . </S>",
    "<S> we develop generalized versions of both global least squares regression and local weighted least squares smoothing . </S>",
    "<S> the target quantities are appropriately defined population versions of global and local regression for the case of metric - space valued responses . </S>",
    "<S> we derive asymptotic rates of convergence for the corresponding sample based fitted regressions to the population targets under suitable regularity conditions by applying empirical process methods . </S>",
    "<S> for the special case of random objects that reside in a hilbert space , for example regression models with vector predictors and functional data or more general hilbert space valued data as responses , we obtain a limit distribution . </S>",
    "<S> the proposed methods have broad applicability . </S>",
    "<S> illustrative examples include responses that consist of probability distributions and correlation matrices , and we demonstrate the proposed global frchet regression for demographic and brain imaging data . </S>",
    "<S> local frchet regression is also illustrated via a simulation with response data which lie on the sphere . </S>"
  ]
}