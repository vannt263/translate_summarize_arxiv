{
  "article_text": [
    "we consider the iterative solution of large - scale discrete ill - posed problems @xmath1 where the norm @xmath2 is the 2-norm of a vector or matrix , and the matrix @xmath3 is extremely ill conditioned with its singular values decaying gradually to zero without a noticeable gap .",
    "this kind of problem arises in many science and engineering areas , such as signal processing and image restoration , typically when discretizing fredholm integral equations of the first - kind @xcite .",
    "in particular , the right - hand side @xmath4 is affected by noise , caused by measurement or discretization errors , i.e. , @xmath5 where @xmath6 represents the gaussian white noise vector and @xmath7 denotes the noise - free right - hand side , and it is supposed that @xmath8 . because of the presence of noise @xmath9 in @xmath4 and the ill - conditioning of @xmath3 , the naive solution @xmath10 of is meaningless and far from the true solution @xmath11 , where the superscript @xmath12 denotes the moore - penrose generalized inverse of a matrix .",
    "therefore , it is necessary to use regularization to determine a best possible approximation to @xmath11 @xcite .",
    "the solution of can be analyzed by the svd of @xmath3 : @xmath13 where @xmath14 and @xmath15 are orthogonal matrices , and the entries of the diagonal matrix @xmath16 are the singular values of @xmath3 , which are assumed to be simple throughout the paper and labelled in decreasing order @xmath17 . with , we obtain @xmath18 throughout the paper , we assume that @xmath19 satisfies the discrete picard condition : on average , the coefficients @xmath20 decay faster than the singular values . to be definitive , for simplicity we assume that these coefficients satisfy a widely used model in the literature , e.g. , ( * ? ?",
    "* and 153 ) and @xcite : @xmath21    let @xmath22 be the transition point such that @xmath23 which can be written as @xmath24 , the solution of the modified problem that replaces @xmath3 by its best rank @xmath0 approximation @xmath25 in ( [ eq1 ] ) , where @xmath26 , @xmath27 and @xmath28 .",
    "remarkably , @xmath29 is the minimum - norm least squares solution of the perturbed problem that replaces @xmath3 in by its best rank @xmath0 approximation @xmath30 , and the best possible tsvd solution of by the tsvd method is @xmath31 @xcite .",
    "a number of approaches have been proposed for determining @xmath22 , such as discrepancy principle , discrete l - curve and generalized cross validation ; see , e.g. , @xcite for comparisons of the classical and new ones . in our numerical experiments",
    ", we use the l - curve criterion in the tsvd method and hybrid lsqr .",
    "the tsvd method has been widely studied ; see , e.g. , @xcite .    for a small and moderate , the tsvd method has been used as a general - purpose reliable and efficient numerical method for solving . as a result",
    ", we will take the tsvd solution @xmath31 as a standard reference when assessing the regularizing effects of iterative solvers and accuracy of iterates under consideration in this paper .    as well known , it is generally not feasible to compute svd when is large . in this case ,",
    "one typically projects onto a sequence of low dimensional krylov subspaces and gets a sequence of iterative solutions @xcite .",
    "the conjugate gradient ( cg ) method has been used when @xmath3 is symmetric definite @xcite .",
    "as a cg - type method applied to the semidefinite linear system @xmath32 or the normal equations system @xmath33 , the cgls algorithm has been studied ; see @xcite and the references therein .",
    "the lsqr algorithm @xcite , which is mathematically equivalent to cgls , has attracted great attention , and is known to have regularizing effects and exhibits semi - convergence ( see @xcite , @xcite , and also @xcite ) : the iterates tend to be better and better approximations to the exact solution @xmath34 and their norms increase slowly and the residual norms decrease . in later stages , however , the noise @xmath9 starts to deteriorate the iterates , so that they will start to diverge from @xmath34 and instead converge to the naive solution @xmath35 , while their norms increase considerably and the residual norms stabilize .",
    "such phenomenon is due to the fact that a projected problem inherits the ill - conditioning of .",
    "that is , as the iterations proceed , the noise progressively enters the solution subspace , so that a small singular value of the projected problem appears and the regularized solution is deteriorated .",
    "as far as an iterative solver for solving is concerned , a central problem is whether or not a pure iterative solver has already obtained a best possible regularized solution at semi - convergence , namely whether or not the regularized solution at semi - convergence is at least as accurate as @xmath31 .",
    "as it appears , for krylov subspace based iterative solvers , their regularizing effects critically rely on how well the underlying @xmath0-dimensional krylov subspace captures the @xmath0-dimensional dominant right singular subspace of @xmath3 . the richer information the krylov subspace contains on the @xmath0-dimensional dominant right singular subspace , the less possible a small ritz value of the resulting projected problem appears and thus the better regularizing effects the solver has .",
    "to precisely describe the regularizing effects of an iterative solver , we introduce the term of _ full _ or _ partial _ regularization : if the iterative solver itself computes a best possible regularized solution at semi - convergence , it is said to have the full regularization ; in this case , no additional regularization is needed . here , as defined in the abstract , a best possible regularized solution means that it is at least as accurate as the best regularized solution obtained by the truncated singular value decomposition ( tsvd ) method .",
    "otherwise , it is said to have the partial regularization ; in this case , in order to compute a best possible regularized solution , its hybrid variant , e.g. , a hybrid lsqr , is needed that combines the solver with additional regularization @xcite , which aims to remove the effects of small ritz values , and expand the krylov subspace until it captures all the dominant svd components needed and the method obtains a best possible regularized solution .",
    "the study of the regularizing effects of lsqr and cgls has been receiving intensive attention for years ; see @xcite and the references therein .",
    "however , there has yet been no definitive result or assertion on their full or partial regularization .",
    "to proceed , we need the following definition of the degree of ill - posedness , which follows hofmann s book @xcite and has been commonly used in the literature , e.g. , @xcite : if there exists a positive real number @xmath36 such that the singular values satisfy @xmath37 , then the problem is termed as mildly or moderately ill - posed if @xmath38 or @xmath39 ; if @xmath40 with @xmath41 considerably , @xmath42 , then the problem is termed severely ill - posed .",
    "it is clear that the singular values @xmath43 of a severely ill - posed problem decay exponentially at the same rate @xmath44 , while those of a moderately or mildly ill - posed problem decay more and more slowly at the decreasing rate @xmath45 approaching one with increasing @xmath46 , which , for the same @xmath46 , is smaller for the moderately ill - posed problem than it for the mildly ill - posed problem .",
    "other minimum - residual methods have also gained attention for solving . for problems with @xmath3 symmetric , minres and its preferred variant mr - ii",
    "are alternatives and have been shown to have regularizing effects @xcite .",
    "when @xmath3 is nonsymmetric and multiplication with @xmath47 is difficult or impractical to compute , gmres and its preferred variant rrgmres are candidates @xcite .",
    "the hybrid approach based on the arnoldi process was first introduced in @xcite , and has been studied in @xcite .",
    "recently , gazzola _",
    "et al_. @xcite have studied more methods based on the lanczos bidiagonalization , the arnoldi process and the nonsymmetric lanczos process for the severely ill - posed problem .",
    "they have described a general framework of the hybrid methods and present krylov - tikhonov methods with different parameter choice strategies employed .    in this paper , we focus on lsqr .",
    "we derive bounds for the 2-norm distance between the underlying @xmath0-dimensional krylov subspace and the @xmath0-dimensional right singular space .",
    "there has been no rigorous and quantitative result on the distance before .",
    "the results indicate that the @xmath0-dimensional krylov subspace captures the @xmath0-dimensional dominant right singular space better for severely and moderately ill - posed problems than for mildly ill - posed problems . as a result",
    ", lsqr has better regularizing effects for the first two kinds of problems than for the third kind . by the bounds and the analysis on them , we draw a definitive conclusion that lsqr generally has only the partial regularization for mildly ill - posed problems , so that a hybrid lsqr with additional explicit regularization is needed to compute a best possible regularized solution .",
    "we also use the bounds to derive an estimate for the accuracy of the rank @xmath0 approximation , generated by lanczos bidiagonalization , to @xmath3 , which is closely related to the regularization of lsqr .",
    "our results help to further understand the regularization of lsqr , though they appear less sharp .",
    "in addition , we derive a bound on the diagonal entries of the bidiagonal matrices generated by the lanczos bidigonalization process , showing how fast they decay .",
    "numerical experiments confirm our theory that lsqr has only the partial regularization for mildly ill - posed problems and a hybrid lsqr is needed to compute best possible regularized solutions .",
    "strikingly , the experiments demonstrate that lsqr has the full regularization for severely and moderately ill - posed problems .",
    "our theory gives a partial support for the observed general phenomena . throughout the paper ,",
    "all the computation is assumed in exact arithmetic .",
    "since cgls is mathematically equivalent to lsqr , all the assertions on lsqr apply to cgls .",
    "this paper is organized as follows . in section [ sectionmain ]",
    ", we describe the lsqr algorithm , and then present our theoretical results on lsqr with a detailed analysis . in section [ sectionexp ] ,",
    "we report numerical experiments to justify the partial regularization of lsqr for mildly ill - posed problems .",
    "we also report some definitive and general phenomena observed .",
    "finally , we conclude the paper in section [ sectioncon ] .    throughout the paper",
    ", we denote by @xmath48 the @xmath0-dimensional krylov subspace generated by the matrix @xmath49 and the vector @xmath50 , by @xmath51 the frobenius norm of a matrix , and by @xmath52 the identity matrix with order clear from the context .",
    "lsqr for solving is based on the lanczos bidiagonalization process , which starts with @xmath53 and , at step ( iteration ) @xmath0 , computes two orthonormal bases @xmath54 and @xmath55 of the krylov subspaces @xmath56 and @xmath57 , respectively .",
    "define the matrices @xmath58 and @xmath59 .",
    "then the @xmath0-step lanczos bidiagonalization can be written in the matrix form @xmath60 where @xmath61 denotes the @xmath62-th canonical basis vector of @xmath63 and the quantities @xmath64 and @xmath65 denote the diagonal and subdiagonal elements of the @xmath66 lower bidiagonal matrix @xmath67 , respectively . at iteration @xmath0",
    ", lsqr computes the solution @xmath68 with @xmath69 note that @xmath70 .",
    "we get @xmath71    as stated in the introduction , lsqr exhibits semi - convergence at some iteration : the iterates @xmath72 become better approximations to @xmath34 until some iteration @xmath0 , and the noise will dominate the @xmath72 after that iteration .",
    "the iteration number @xmath0 plays the role of the regularization parameter .",
    "however , semi - convergence does not necessarily mean that lsqr finds a best possible regularized solution as @xmath67 may become ill - conditioned before @xmath73 but @xmath72 does not yet contain all the needed @xmath22 dominant svd components of @xmath3 . in this case , in order to get a best possible regularized solution",
    ", one has to use a hybrid lsqr method , as described in the introduction .",
    "the significance of is that the lsqr iterates can be interpreted as the minimum - norm least squares solutions of the perturbed problems that replace @xmath3 in by its rank @xmath0 approximations @xmath74 , whose nonzero singular values are just those of @xmath67 .",
    "if the singular values of @xmath67 approximate the @xmath0 large singular values of @xmath3 in natural order for @xmath75 , then lsqr must have the full regularization , and the regularized solution @xmath76 is best possible and is as comparably accurate as the best possible regularized solution @xmath31 by the tsvd method .",
    "hansen s analysis @xcite shows that the lsqr iterates have the filtered svd expansions : @xmath77 where @xmath78 , and @xmath79 are the singular values of @xmath67 . in our context , if we have @xmath80 for some @xmath73 , the factors @xmath81 , @xmath82 are not small , meaning that @xmath72 is already deteriorated and becomes a poorer regularized solution , namely , lsqr surely does not have full regularization . as a matter of fact , in terms of the best possible solution @xmath31",
    ", it is easily justified that the full regularization of lsqr is equivalent to requiring that the singular values of @xmath67 approximate the @xmath0 largest singular values of @xmath3 in natural order for @xmath75 , so it is impossible to have @xmath80 for @xmath73 .",
    "the regularizing effects of lsqr critically depend on what @xmath83 mainly contains and provides .",
    "note that the eigenpairs of @xmath84 are the squares of singular values and right singular vectors of @xmath3 , and the tridiagonal matrix @xmath85 is the projected matrix of @xmath84 onto the subspace @xmath83 , which is obtained by applying the symmetric lanczos tridiagonalization process to @xmath84 starting with @xmath86 @xcite .",
    "we have a general claim deduced from @xcite and exploited widely in @xcite : the more information the subspace @xmath83 contains on the @xmath0 dominant right singular vectors , the more possible and accurate the @xmath0 ritz values approximate the @xmath0 largest singular values of @xmath3 ; on the other hand , the less information it contains on the other @xmath87 right singular vectors , the less accurate a small ritz value is if it appears . for our problem , since the small singular values of @xmath3 are clustered and close to zero , it is expected that a small ritz value will show up as @xmath0 grows large , and it starts to appear more late when @xmath83 contains less information on the other @xmath87 right singular vectors . in this sense , we say that lsqr has better regularizing effects since @xmath72 contains more dominant svd components .    using the definition of canonical angles @xmath88 between the two subspaces @xmath89 and @xmath90 of the same dimension @xcite , we have the following theorem , which shows how well the subspace @xmath56 , on which lsqr and cgls work , captures the @xmath0-dimensional dominant right singular space .    [ thm2 ]",
    "let the svd of @xmath3 be , and assume that its singular values are distinct and satisfy @xmath40 with @xmath41 .",
    "let @xmath91 be the subspace spanned by the columns of @xmath92 , and @xmath93 .",
    "then @xmath94 with the @xmath95 matrix @xmath96 to be defined by and @xmath97    _ proof_. let @xmath98 consist of the first @xmath99 columns of @xmath100 defined in .",
    "we see @xmath101 is spanned by the columns of the @xmath102 matrix @xmath103 with @xmath104 partition the matrices @xmath105 and @xmath106 as follows : @xmath107 where @xmath108 .",
    "since @xmath109 is a vandermonde matrix with @xmath43 distinct for @xmath110 , it is nonsingular .",
    "thus , by the svd of @xmath3 , we have @xmath111 with @xmath112 define @xmath113 . then @xmath114 and the columns of @xmath115 form an orthonormal basis of @xmath116 .",
    "write @xmath117 . by definition",
    ", we obtain @xmath118 which proves and indicates that @xmath119 is monotonically increasing with respect to @xmath120 .",
    "we next estimate @xmath120 .",
    "we have @xmath121 so we need to estimate @xmath122 .",
    "it is easily justified that the @xmath123-th column of @xmath124 consists of the coefficients of the lagrange polynomial @xmath125 that interpolates the elements of the @xmath123-th canonical basis vector @xmath126 at the abscissas @xmath127 .",
    "consequently , the @xmath123-th column of @xmath128 is @xmath129 from which we obtain @xmath130 since @xmath131 is monotonic for @xmath132 , it is bounded by @xmath133 .",
    "furthermore , let @xmath134 .",
    "then for @xmath135 and @xmath41 we have @xmath136 by absorbing those higher order terms into @xmath137 .",
    "note that in the above numerator we have @xmath138 and @xmath139 it is then easily seen that their product is @xmath140 on the other hand , by definition , the denominator @xmath141 in is exactly one for @xmath142 , and it is strictly bigger than one for @xmath143 .",
    "therefore , for any @xmath0 , we have @xmath144 . from this and",
    "it follows that @xmath145 therefore , for @xmath146 and @xmath41 considerably , from we have @xmath147    * remark 2.1 *  we point out that should not be sharp . as we have seen from the proof , the factor @xmath148 seems intrinsic and unavoidable , but the factor @xmath149 in is an overestimate and",
    "can certainly be reduced .",
    "is an overestimate since @xmath133 for @xmath123 not near to @xmath0 is considerably smaller than @xmath150 , but we replace all them by their maximum @xmath151 .",
    "in fact , our derivation clearly illustrates that the smaller @xmath123 is , the smaller @xmath133 than @xmath152 .",
    "recall the discrete picard condition .",
    "then @xmath153 we observe that @xmath154 almost remains constant for @xmath73 . for @xmath155 , note that all the @xmath156 almost remain the same .",
    "thus , we have @xmath157 , meaning that @xmath116 does not capture @xmath158 as well as it does for @xmath73 .",
    "* remark 2.2 *  the theorem can be extended to moderately ill - posed problems with the singular values @xmath159 considerably and @xmath0 not big since , in a similar manner to the proof of theorem  [ thm2 ] , we can obtain by the first order taylor expansion @xmath160 which , unlike @xmath161 for severely ill - posed problems , depends on @xmath0 and increases slowly with @xmath0 for @xmath39 considerably .",
    "however , for mildly ill - posed problems , from above we have @xmath162 considerably for @xmath163 .",
    "* remark 2.3 *  a combination of and and the above analysis indicate that @xmath116 captures @xmath158 better for severely ill - posed problems than for moderately ill - posed problems .",
    "there are two reasons for this .",
    "the first is that the factors @xmath164 are basically fixed constants for severely ill - posed problems as @xmath0 increases , and they are smaller than the counterparts for moderately ill - posed problems unless the degree @xmath36 of its ill - posedness is far bigger than one and @xmath0 small .",
    "the second is that the factor @xmath165 is smaller for severely ill - posed problems than the factor @xmath151 for moderately ill - posed problems for the same @xmath0 .",
    "* remark 2.4 *  the situation is fundamentally different for mildly ill - posed problems : firstly , we always have @xmath162 substantially for @xmath166 and any @xmath0 , which is considerably bigger than @xmath165 for moderately ill - posed problems for the same @xmath0 .",
    "secondly , @xmath167 defined by is closer to one than that for moderately ill - posed problems for @xmath75 .",
    "thirdly , for the same noise level @xmath168 and @xmath169 , we see from the discrete picard condition and the definition of @xmath22 that @xmath22 is bigger for a mildly ill - posed problem than that for a moderately ill - posed problem . all of them show that @xmath116 captures @xmath158 _ considerably better _ for severely and moderately ill - posed problems than for mildly ill - posed problems for @xmath75 . in other words , our results illustrate that @xmath116 contains more information on the other @xmath87 right singular vectors for mildly ill - posed problems , compared with severely and moderately ill - posed problems .",
    "the bigger @xmath0 , the more it contains .",
    "therefore , @xmath116 captures @xmath158 more effectively for severely and moderately ill - posed problems than mildly ill - posed problems .",
    "that is , @xmath116 contains more information on the other @xmath87 right singular vectors for mildly ill - posed problems , making the appearance of a small ritz value more possible before @xmath73 and lsqr has better regularizing effects for the first two kinds of problems than for the third kind .",
    "note that lsqr , at most , has the full regularization , i.e. , there is no ritz value smaller than @xmath170 for @xmath73 , for severely and moderately ill - posed problems .",
    "our analysis indicates that lsqr generally has only the partial regularization for mildly ill - posed problem and a hybrid lsqr should be used .    *",
    "remark 2.5 *  relation and @xmath167 indicate that @xmath116 captures @xmath158 better for severely ill - posed problems than for moderately ill - posed problems .",
    "there are two reasons for this .",
    "first , the all the @xmath164 are basically a fixed constant @xmath44 for severely ill - posed problems , which is smaller than those ratios for moderately ill - posed problems unless @xmath36 is rather big and @xmath0 small .",
    "second , the quantities @xmath171 for severely ill - posed problems are smaller than the corresponding @xmath165 for moderately ill - posed problems .",
    "let us investigate more and get insight into the regularization of lsqr .",
    "define @xmath172 which measures the quality of the rank @xmath0 approximation @xmath173 to @xmath3 .",
    "based on , we can derive the following estimate for @xmath174 .",
    "[ thm3 ] assume that is severely or moderately ill posed .",
    "then @xmath175    _ proof_. let @xmath25 be the best rank @xmath0 approximation to @xmath3 with respect to the 2-norm , where @xmath26 , @xmath27 and @xmath28 .",
    "since @xmath173 is of rank @xmath0 , the lower bound in is trivial by noting that @xmath176 .",
    "we now prove the upper bound . from ,",
    "we obtain @xmath177 it is easily known that @xmath178 with @xmath179 having orthonormal columns .",
    "then by the definition of @xmath119 we obtain @xmath180    numerically , it has been extensively observed in the literature that the @xmath174 decay as fast as @xmath181 and , more precisely , @xmath182 for severely ill - posed problems ; see , e.g. , @xcite .",
    "they mean that the @xmath173 are very good rank @xmath0 approximations to @xmath3 .",
    "recall that the tsvd method generates the best regularized solution @xmath183 . as a result , if @xmath184 , the lsqr iterate @xmath185 is reasonably close to the tsvd solution @xmath31 for @xmath170 is reasonably small .",
    "this means that lsqr has the full regularization and does not need any additional regularization to improve @xmath76 . as our experiments will indicate in detail , these observed phenomena are of generality for both severely and moderately ill - posed problems and thus should have strong theoretical supports .",
    "compared to the observations , our appears to be a considerrable overestimate .",
    "we next present some results on @xmath186 appearing in . if @xmath187 , the lanczos bidiagonalization process terminates , and we have found @xmath0 exact singular triples of @xmath3 @xcite . in our context , since @xmath3 has only simple singular values and @xmath4 has components in all the left singular vectors , early termination is impossible in exact arithmetic , but small @xmath186 is possible .",
    "we aim to investigate how fast @xmath186 decays .",
    "we first give a refinement of a result in @xcite .",
    "[ thm1 ] let @xmath188 be the svd of @xmath67 , where @xmath189 and @xmath190 are orthogonal , and @xmath191 , and define @xmath192 and @xmath193 .",
    "then @xmath194    _ proof_. from and @xmath195 , we obtain @xmath196 so holds . from",
    ", we get @xmath197 note that @xmath198 .",
    "then we get @xmath199    we remark that it is an inequality other than the equality in a result of @xcite similar to .    in combination with the previous results and remarks , this theorem shows that once @xmath186 becomes small for not big @xmath0 , the @xmath0 singular values of @xmath67 may approximate the large singular values of @xmath3 , and it is more possible that no small one appears for severely ill - posed problems and moderately ill - posed problems .    as our final result , we establish an intimate and interesting relationship between @xmath186 and @xmath174 , showing how fast @xmath186 decays .",
    "[ thm4 ] it holds that @xmath200    _ proof_. with the notations as in theorem  [ thm1 ] , we have @xmath201 .",
    "so , by , we have @xmath202 note that @xmath203 .",
    "therefore , from we obtain @xmath204    the theorem indicates that @xmath186 decays at least as fast as @xmath174 , which , in turn , means that @xmath186 may decrease in the same rate as @xmath181 , as observed in @xcite for severely ill - posed problems .",
    "in this section , we report numerical experiments to illustrate the the regularizing effects of lsqr .",
    "we will demonstrate that lsqr has the full regularization for severely and moderately ill - posed problems , stronger phenomena than our theory proves , but it only has the partial regularization for mildly ill - posed problems , in accordance with our theory , for which a hybrid lsqr is needed to compute best possible regularized solutions .",
    "we choose several ill - posed examples from hansen s regularization toolbox @xcite .",
    "all the problems arise from the discretization of the first kind fredholm integral equation @xmath205 for each problem we use the codes of @xcite to generate a @xmath206 matrix @xmath3 , true solution @xmath34 and noise - free right - hand @xmath19 . in order to simulate the noisy data",
    ", we generate the gaussian noise vector @xmath9 whose entries are normally distributed with mean zero . defining the noise level @xmath207",
    ", we use @xmath208 , respectively , in the test examples . to simulate exact arithmetic ,",
    "the full reorthogonalization is used during the lanczos bidiagonalization process .",
    "we remind that , as far as ill - posed problem is concerned , our primary goal consists in justifying the regularizing effects of iterative solvers , which are _ unaffected by sizes _ of ill - posed problems and only depends on the degree of ill - posedness . therefore , for this purpose , as extensively done in the literature ( see , e.g. , @xcite and the references therein )",
    ", it is enough to test not very large problems .",
    "indeed , for @xmath99 large , say , 1,0000 and more , we have observed completely the same behavior as that for @xmath99 not large , e.g. , @xmath209 used in this paper . a reason for using @xmath99 not large is because such choice makes it practical to fully justify the regularization effects of lsqr by comparing it with the tsvd method , which suits only for small and/or medium sized problems for computational efficiency .",
    "all the computations are carried out in matlab 7.8 with the machine precision @xmath210 under the microsoft windows 7 64-bit system .",
    "we consider the following two severely ill - posed problems @xcite .",
    "* example 1 *  this problem shaw arises from one - dimensional image restoration , and can be obtained by discretizing the first kind fredholm integral equation with @xmath211 $ ] as both integration and domain intervals .",
    "the kernel @xmath212 and the solution @xmath213 are given by @xmath214 @xmath215    * example 2 *  this problem wing has a discontinuous solution and is obtained by discretizing the first kind fredholm integral equation with @xmath216 $ ] as both integration and domain intervals .",
    "the kernel @xmath212 , the solution @xmath213 and the right - hand side @xmath217 are given by @xmath218 @xmath219    these two problems are severely ill - posed , whose singular values @xmath40 with @xmath220 for shaw and @xmath221 for wing , respectively .    in figure",
    "[ fig : res ] , we display the curves of the sequences @xmath174 and @xmath186 with @xmath222 , respectively .",
    "they illustrate that the quantities @xmath174 decrease as fast as @xmath181 and both of them level off at the level of @xmath223 for @xmath0 no more than 20 , and after that these quantities are purely round - offs and are reliable no more .",
    "moreover , the curves of quantities @xmath186 always lie below those of @xmath174 , which coincides with theorem [ thm4 ] .",
    "we can see that the decaying curves with different noise levels are almost the same .",
    "furthermore , we observe that @xmath182 for severely ill - posed problems , indicating that the @xmath173 are very good rank @xmath0 approximations to @xmath3 with the approximate accuracy @xmath181 and that @xmath67 does not become ill - conditioned before @xmath73 . as a result ,",
    "the regularized solutions @xmath72 become better approximations to @xmath34 until iteration @xmath22 , and they are deteriorated after that iteration . at iteration @xmath22 , @xmath76 only captures the @xmath22 dominant svd components of @xmath3 and suppress the other @xmath224 svd components , so that it is a best possible regularized solution . as a result ,",
    "the pure lsqr has the full regularization for severely ill - posed problems",
    ". we will give a more direct justification on these assertions in section 3.3 .    in figure  [ fig2 ] , we plot the relative errors @xmath225 with different noise levels for these two problems . obviously",
    ", lsqr exhibits semi - convergence phenomenon .",
    "moreover , for smaller noise level , we get better regularized solutions at the cost of more iterations , as expected .",
    ", @xmath181 and @xmath186 for the problem shaw with @xmath226 ( left ) and @xmath227 ( right ) ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath174 and @xmath181 for the problem wing with @xmath227 ( left ) and @xmath228 ( right).,width=264,height=188 ]    ( a )    , @xmath181 and @xmath186 for the problem shaw with @xmath226 ( left ) and @xmath227 ( right ) ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath174 and @xmath181 for the problem wing with @xmath227 ( left ) and @xmath228 ( right).,width=264,height=188 ]    ( b )    , @xmath181 and @xmath186 for the problem shaw with @xmath226 ( left ) and @xmath227 ( right ) ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath174 and @xmath181 for the problem wing with @xmath227 ( left ) and @xmath228 ( right).,width=264,height=188 ]    ( c )    , @xmath181 and @xmath186 for the problem shaw with @xmath226 ( left ) and @xmath227 ( right ) ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath174 and @xmath181 for the problem wing with @xmath227 ( left ) and @xmath228 ( right).,width=264,height=188 ]    ( d )     with respect to @xmath222 for the problems shaw ( left ) and wing ( right).,width=264,height=188 ]    ( a )     with respect to @xmath222 for the problems shaw ( left ) and wing ( right).,width=264,height=188 ]    ( b )      we now consider the following two moderately ill - posed problems @xcite .",
    "* example 3 *  this problem heat arises from the inverse heat equation , and can be obtained by discretizing volterra integral equation of the first kind , a class of equations that is moderately ill - posed , with @xmath216 $ ] as integration interval .",
    "the kernel @xmath229 with @xmath230    * example 4 *  this problem is the famous phillips test problem .",
    "it can be obtained by discretizing the first kind fredholm integral equation with @xmath231 $ ] as both integration and domain intervals .",
    "the kernel @xmath212 , the solution @xmath213 and the right - hand side @xmath217 are given by @xmath232 @xmath233 @xmath234    , @xmath181 and @xmath186 for the problem heat with @xmath226 ( left ) and @xmath227 ( right ) ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath174 and @xmath181 for the problem phillips with @xmath227 ( left ) and @xmath228 ( right).,width=264,height=188 ]    ( a )    , @xmath181 and @xmath186 for the problem heat with @xmath226 ( left ) and @xmath227 ( right ) ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath174 and @xmath181 for the problem phillips with @xmath227 ( left ) and @xmath228 ( right).,width=264,height=188 ]    ( b )    , @xmath181 and @xmath186 for the problem heat with @xmath226 ( left ) and @xmath227 ( right ) ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath174 and @xmath181 for the problem phillips with @xmath227 ( left ) and @xmath228 ( right).,width=264,height=188 ]    ( c )    , @xmath181 and @xmath186 for the problem heat with @xmath226 ( left ) and @xmath227 ( right ) ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath174 and @xmath181 for the problem phillips with @xmath227 ( left ) and @xmath228 ( right).,width=264,height=188 ]    ( d )    from figure  [ fig3 ] , we see that @xmath174 decreases as fast as @xmath181 , and @xmath186 decays as fast as @xmath174 .",
    "however , slightly different from severely ill - posed problems , we can observe that the @xmath174 may not be so close to the @xmath181 , as reflected by the thick rope formed by three lines . by comparing the behavior of @xmath174 for severely and moderately ill - posed problem ,",
    "we come to the conclusion that the @xmath0-step lanczos bidiagonalization may generate more accurate rank @xmath0 approximation for severely ill - posed problems than for moderately ill - posed problems , namely , the rank @xmath0 approximation @xmath173 may be more accurate for severely ill - posed problems than for moderately ill - posed problems .",
    "nonetheless , we have seen that , for the test moderately ill - posed problems , all the @xmath174 are still excellent approximations to the @xmath181 , so that lsqr still has the full regularization .    in figure  [ fig4 ]",
    ", we depict the relative errors of @xmath72 , and observe analogous phenomena to those for severely ill - posed problems .",
    "a distinction is that now lsqr needs more iterations for moderately ill - posed problems with the same noise level .     with respect to @xmath222 for the problems heat ( left ) and phillips ( right).,width=264,height=188 ]    ( a )     with respect to @xmath222 for the problems heat ( left ) and phillips ( right).,width=264,height=188 ]    ( b )      for the previous four severely and moderately ill - posed problems , we now compare the regularizing effects of the pure lsqr and the hybrid lsqr with the additional tsvd regularization used within projected problems .",
    "we show that lsqr has the full regularization and no additional regularization is needed , which is based on the observation that at semi - convergence the regularized solution by lsqr is as accurate as that obtained by the hybrid lsqr for each problem .    in the sequel , we only report the results for the noise level @xmath227 .",
    "results for other @xmath235 are analogous and thus omitted .",
    "figures  [ fig5 ] ( a)-(b ) and figures  [ fig6 ] ( a)-(b ) indicate that the relative errors of approximate solutions obtained by the two methods reach the same minimum level , and the hybrid lsqr simply stabilizes the regularized solutions with the minimum error .",
    "this means that the pure lsqr itself has already found a best possible regularized solution at semi - convergence and no additional regularization is needed .",
    "so it has the full regularization .",
    "our task is to determine such @xmath0 , which is the iteration where @xmath236 starts to increase dramatically while its residual norm remains almost unchanged .",
    "the l - curve criterion fits nicely into this task . in these examples ,",
    "we also choose @xmath237 for the pure lsqr .",
    "figure  [ fig5 ] ( c ) and figures  [ fig6 ] ( c)-(d ) show that the regularized solutions are generally very good approximations to the true solutions .",
    "however , we should point out that for the problem wing with a discontinuous solution , the large relative error indicates that the regularized solution is a poor approximation to the true solution , as depicted in figure  [ fig5 ] ( d ) .",
    "such phenomenon is due to the fact that the regularization of lsqr and its hybrid variants is unsuitable for the ill - posed problems with discontinuous solutions . for such kind of problems ,",
    "more reasonable regularization is total variation regularization , which takes the form @xmath238 with @xmath239 some @xmath240 matrix and @xmath241 the 1-norm @xcite .     with respect to lsqr and lsqr with additional tsvd regularization for @xmath227 ;",
    "( c)-(d ) : the regularized solutions @xmath242 for the pure lsqr for the problems shaw ( left ) and wing ( right).,width=264,height=188 ]    ( a )     with respect to lsqr and lsqr with additional tsvd regularization for @xmath227 ; ( c)-(d ) : the regularized solutions @xmath242 for the pure lsqr for the problems shaw ( left ) and wing ( right).,width=264,height=188 ]    ( b )     with respect to lsqr and lsqr with additional tsvd regularization for @xmath227 ; ( c)-(d ) : the regularized solutions @xmath242 for the pure lsqr for the problems shaw ( left ) and wing ( right).,width=264,height=188 ]    ( c )     with respect to lsqr and lsqr with additional tsvd regularization for @xmath227 ; ( c)-(d ) : the regularized solutions @xmath242 for the pure lsqr for the problems shaw ( left ) and wing ( right).,width=264,height=188 ]    ( d )     obtained by the pure lsqr and lsqr with the additional tsvd regularization for @xmath227 ; ( c)-(d ) : the regularized solutions @xmath242 for the pure lsqr for the problems heat ( left ) and phillips ( right).,width=264,height=188 ]    ( a )     obtained by the pure lsqr and lsqr with the additional tsvd regularization for @xmath227 ; ( c)-(d ) : the regularized solutions @xmath242 for the pure lsqr for the problems heat ( left ) and phillips ( right).,width=264,height=188 ]    ( b )     obtained by the pure lsqr and lsqr with the additional tsvd regularization for @xmath227 ; ( c)-(d ) : the regularized solutions @xmath242 for the pure lsqr for the problems heat ( left ) and phillips ( right).,width=264,height=188 ]    ( c )     obtained by the pure lsqr and lsqr with the additional tsvd regularization for @xmath227 ; ( c)-(d ) : the regularized solutions @xmath242 for the pure lsqr for the problems heat ( left ) and phillips ( right).,width=264,height=188 ]    ( d )    in what follows , we compare the regularizing effects of the pure lsqr and hybrid lsqr for mildly ill - posed problems , showing that lsqr has only the partial regularization and a hybrid lsqr should be used for this kind of problem to improve the regularized solution by lsqr at semi - convergence .",
    "* example 5 *  the problem deriv2 is mildly ill - posed , which is obtained by discretizing the first kind fredholm integral equation with @xmath216 $ ] as both integration and domain intervals .",
    "the kernel @xmath212 is green s function for the second derivative : @xmath243 and the solution @xmath213 and the right - hand side @xmath217 are given by @xmath244    figure  [ fig7 ] ( a ) shows that the relative errors of approximate solutions by the hybrid lsqr reach a considerably smaller minimum level than those by the pure lsqr , a clear indication that lsqr has the partial regularization .",
    "as we have seen , the hybrid lsqr expands the krylov subspace until it contains enough dominant svd components and , meanwhile , additional regularization effectively dampen the svd components corresponding to small singular values .",
    "for instance , the semi - convergence of the pure lsqr occurs at iteration @xmath245 , but it is not enough . as the hybrid lsqr shows , we need a larger six dimensional krylov subspace @xmath246 to construct a best possible regularized solution .",
    "we also choose @xmath237 for the pure lsqr and the hybrid lsqr .",
    "figure  [ fig7 ] ( b ) indicates that the regularized solution obtained by the hybrid lsqr is a considerably better approximation to @xmath34 than that by the pure lsqr , especially in the non - smooth middle part of @xmath34 .     and the regularized solution @xmath242 with respect to lsqr and lsqr with the additional tsvd regularization for the problem deriv2 and @xmath227.,width=264,height=188 ]    ( a )     and the regularized solution @xmath242 with respect to lsqr and lsqr with the additional tsvd regularization for the problem deriv2 and @xmath227.,width=264,height=188 ]    ( b )",
    "for large - scale discrete ill - posed problems , lsqr and cgls are commonly used methods .",
    "these methods have regularizing effects and exhibit semi - convergence .",
    "however , if a small ritz value appears before the methods capture all the needed dominant svd components , the methods have only the partial regularization and must be equipped with additional regularization so that best possible regularized solutions can be found . otherwise , lsqr has the full regularization and can compute best possible regularized solutions without additional regularization needed .",
    "we have proved that the underlying @xmath0-dimensional krylov subspace captures the @xmath0 dimensional dominant right singular space better for severely and moderately ill - posed problems than for mildly ill - posed problems .",
    "this makes lsqr have better regularization for the first two kinds of problems than for the third kind .",
    "furthermore , we have shown that lsqr generally has only the partial regularization for mildly ill - posed problems .",
    "numerical experiments have demonstrated that lsqr has the full regularization for severely and moderately ill - posed problems , stronger than our theory predicts , and it has the partial regularization for mildly moderately ill - posed problems , compatible with our assertion .",
    "together with the observations @xcite , it appears that the excellent performances of lsqr on severely and moderately ill - posed problems generally hold .    as for future work , it is more appealing to derive an accurate estimate for @xmath120 other than @xmath247 , as it plays a crucial role in analyzing the accuracy @xmath174 of the rank @xmath0 approximation , generated by lanczos bidiagonalization , to @xmath3 .",
    "accurate bounds for @xmath174 are the core of completely understanding the regularizing effects of lsqr , but our bound for @xmath174 is conservative and is expected to be improved on substantially . since cgls is mathematically equivalent to lsqr , our results apply to cgls as well .",
    "our current work has helped to better understand the regularization of lsqr and cgls .",
    "but for a complete understanding of the intrinsic regularizing effects of lsqr and cgls , we still have a long way to go , and more research is needed .",
    "we thank the three referees very much for their valuable suggestions and comments , which made us improve the presentation of the paper .",
    ", _ ill - conditioning of the truncated singular value decomposition , tikhonov regularization and their applications to numerical partial differential equations_. numer .",
    "linear algebra appl . , 18 ( 2011 ) , pp ."
  ],
  "abstract_text": [
    "<S> lsqr , a lanczos bidiagonalization based krylov subspace iterative method , and its mathematically equivalent cgls applied to normal equations system , are commonly used for large - scale discrete ill - posed problems . </S>",
    "<S> it is well known that lsqr and cgls have regularizing effects , where the number of iterations plays the role of the regularization parameter . </S>",
    "<S> however , it has long been unknown whether the regularizing effects are good enough to find best possible regularized solutions . here </S>",
    "<S> a best possible regularized solution means that it is at least as accurate as the best regularized solution obtained by the truncated singular value decomposition ( tsvd ) method . in this paper </S>",
    "<S> , we establish bounds for the distance between the @xmath0-dimensional krylov subspace and the @xmath0-dimensional dominant right singular space . </S>",
    "<S> they show that the krylov subspace captures the dominant right singular space better for severely and moderately ill - posed problems than for mildly ill - posed problems . </S>",
    "<S> our general conclusions are that lsqr has better regularizing effects for the first two kinds of problems than for the third kind , and a hybrid lsqr with additional regularization is generally needed for mildly ill - posed problems . exploiting the established bounds </S>",
    "<S> , we derive an estimate for the accuracy of the rank @xmath0 approximation generated by lanczos bidiagonalization . </S>",
    "<S> numerical experiments illustrate that the regularizing effects of lsqr are good enough to compute best possible regularized solutions for severely and moderately ill - posed problems , stronger than our theory predicts , but they are not for mildly ill - posed problems and additional regularization is needed .    </S>",
    "<S> ill - posed problem , regularization , lanczos bidiagonalization , lsqr , cgls , hybrid    65f22 , 65j20 , 15a18 </S>"
  ]
}