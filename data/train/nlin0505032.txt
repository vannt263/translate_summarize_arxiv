{
  "article_text": [
    "evolutionary game dynamics is a fast developing field , with applications in biology , economics , sociology and anthropology .",
    "background material and countless references can be found in the monographs by weibull @xcite , fudenburg & levine @xcite , samuelson @xcite , hofbauer & sigmund hs1 , gintis @xcite , cressman @xcite and vincent & brown @xcite or in the survey paper by hofbauer & sigmund @xcite .",
    "the standard ingredients of evolutionary game dynamics are a population of players , an @xmath0-person game , a set of strategies and a rule to update the distribution of strategies from one generation to the next . within this general",
    "setting several variations are possible : time can be discrete or continuous , populations can be finite or infinite , the game can have a finite or infinite number of strategies .",
    "also , there are several choices for the updating rule , the most popular of which are adaptive dynamics ( see e.g. diekmann @xcite ) and replicator dynamics , introduced by taylor & jonker @xcite . in this paper",
    "we consider a model with continuous time , an infinite population and a 2-person game , where each participant has a continuum of strategies to choose from .",
    "the update rule we use is the replicator dynamics , with deterministic mutations .",
    "although this model has been alluded to by dieckmann @xcite , where a hierarchy of evolutionary models is presented , its details have not been worked out before .",
    "the strategy space that we consider is a subset of @xmath1 , which in all applications is compact . in section 2",
    "we first consider replicator dynamics with a deterministic mutation term on a finite set of strategies .",
    "using a procedure that is familiar in statistical mechanics , we make a transition to an infinite , continuous , strategy - space .",
    "the state - space of the model is then no longer discrete , but consists of distributions over the strategies .",
    "we derive a partial differential equation , together with appropriate boundary conditions , that describes the time - evolution of this distribution , given an initial distribution . without the mutation term ,",
    "the equation we derive was previously studied by cressman @xcite and oechsler & riedel @xcite .",
    "our addition of a mutation term is new and leads to completely different dynamics .    in section 3 ,",
    "the equation is applied to symmetric 2x2 games , where we need to extend the original two - strategy set to a continuous one .",
    "this can be done by allowing for strategies that play one of the pure strategies with a certain probability .",
    "we compare our results with those of  vaughan @xcite , who analyses the replicator dynamics for the pure strategies , to which a stochastic perturbation term is added , leading to a fokker - planck equation .",
    "there are similarities between the two models , but also striking differences . in the stochastic mutation version",
    ", there is always only one attracting , stationary , distribution , which for small mutations converges to a point - distribution ( dirac - delta function ) . in other words ,",
    "all players eventually use the same strategy . in the deterministic mutation version , however , we find the possibility of two attracting stationary distributions existing simultaneously . also , in certain cases the limiting distribution for small mutations is not concentrated on a point , but has the whole strategy space as support .    a more complicated example , namely the ultimatum game ,",
    "is treated in section 4 . in this game ,",
    "a sum of money is to be split by two players .",
    "the first player proposes the split and the second player then has the choice to accept the split or refuse , in which case both players get nothing .",
    "the solution offered by standard game theory is for the second player to accept any amount ( something is always better than nothing ) and for the first player , therefore , to offer the lowest possible amount . in our model",
    "we find that the offers converge to a gauss - like distribution around a mean that is not equal to zero .",
    "the position of the mean and the width of the distribution seem to converge to zero when the rate of mutation vanishes .",
    "however , this convergenge is slow , so that even for very small values of the mutation rate , the average offer is well above zero .",
    "also , the dynamics shows two time - scales . a random starting distribution is initially attracted to a member of a certain set of distributions , which can have an average offer much larger than zero .",
    "then , on a time - scale inversely proportional to the rate of mutation , the solution converges to the , unique , stationary solution .    in section 5",
    "we discuss the results and suggest some topics for further research .",
    "the equation for the replicator dynamics with continuous strategy space will be derived by a limiting process , starting from the equations for the discrete case .    following hofbauer and sigmund @xcite",
    ", we consider an infinite population of players and a set of strategies @xmath2 .",
    "when a player @xmath3 opts for strategy @xmath4 against @xmath5 who uses @xmath6 , the payoff to @xmath3 is taken to be @xmath7 and the payoff to @xmath8 is @xmath9 consequently , if @xmath10 is the fraction of the whole population that at time @xmath11 plays the strategy @xmath6 , the average payoff to each player using @xmath4 is equal to @xmath12 the average payoff for the whole population therefore is @xmath13 now in the course of time , the fraction @xmath14 changes at a rate which is proportional to the difference between the payoff to @xmath14 and the average payoff for the whole population .",
    "in addition we assume that for each player of @xmath15 there is a transition probability per unit time to make a spontaneous transfer to strategy @xmath4 at a rate given by @xmath16 . in this way",
    "the _ discrete replicator equation with mutation _ is derived : @xmath17 it is easy to show that @xmath18 for all @xmath11 if @xmath19    in transforming to a continous strategy space , we replace the discrete index @xmath20 by a continuous variable @xmath21 and the variables @xmath22 by a probability distribution @xmath23 .",
    "the payoff matrix @xmath24 must now be replaced by a payoff function @xmath25 , which gives the payoff to strategy @xmath26 when playing strategy @xmath27 .",
    "eq.([drep ] ) now takes the form @xmath28 in which the mutation term is equal to @xmath29\\,\\mathrm{d}s^{\\prime } .",
    "\\label{mut}\\]]the average payoff for strategy @xmath26 and the total average payoff are given by @xmath30and @xmath31let us now restrict ourselves to mutations in which only small changes in the strategies occur and apply the method which is used to derive the fokker - planck equation from a master equation @xcite .",
    "for simplicity of presentation , we restrict ourselves to the case of a one - dimensional strategy space . define @xmath32 by @xmath33 and write the mutation rate as a function of @xmath26 and @xmath32@xmath34and so @xmath35assume now that @xmath36 varies slowly in the first variable @xmath37 and that due to the mutations only small variations in the strategies will occur .",
    "then @xmath36 is only nonvanishing when @xmath32 is small . in the mutation term",
    "( [ mut ] ) , which can be written as @xmath38\\,\\mathrm{{d}\\xi , }   \\label{mut3}\\]]we can now expand the dependence on the first variable in powers of @xmath32 and obtain @xmath39\\,\\mathrm{{d}\\xi . }",
    "\\notag\\end{aligned}\\]]because @xmath40p(s , t)\\mathrm{{d}% \\xi = 0}$ ] , the first and last term cancel , so that to second order we are left with @xmath41 in which @xmath42we will further simplify the equations by assuming that the average change in strategy due to mutations is equal to zero , so @xmath43 and that the average of the square of this change is constant , so @xmath44    the final form of the _ continuous replicator equation _ ( [ crep ] ) _ _  _ _ then becomes @xmath45where we have restored the correct dimensionality of the strategy space by replacing @xmath46 by the _ n_-dimensional laplace operator .",
    "@xmath23 should satisfy @xmath47 and @xmath48d@xmath49 should be equal to unity at all times .",
    "this last condition is fulfilled when we choose neumann , or reflecting , boundary conditions :    @xmath50    where @xmath51 is the normal to the boundary @xmath52 of the domain @xmath53 .    indeed , integrating ( [ rep ] ) over @xmath54 and using ( [ bound ] ) we find @xmath55showing that if @xmath56 then @xmath57 for all times . in the case",
    "that @xmath58 , condition ( [ bound ] ) is not required to ensure that @xmath59 remain constant in time .",
    "equation ( [ rep ] ) is a nonlinear reaction - diffusion equation , where the reaction term @xmath60 is nonlocal . on the function space of twice continuous space - differentiable and once time - differentiable functions",
    ", we can show that the solution of ( rep ) exists for all times .",
    "this follows from the assumption that @xmath61 is bounded on @xmath54 , so that @xmath62    @xmath63    @xmath64 .",
    "standard comparison theorems for parabolic equations ( pao @xcite ) complete the proof .",
    "also , by standard positivity results for parabolic equations , it can be shown that the when the initial distribution @xmath65 then @xmath47 for all times @xmath66    numerical simulations suggest that even stronger results hold .",
    "in particular , we suspect that the solution of eqs.([rep ] ) , ( [ bound ] ) is uniformly ( in space and time ) bounded in terms of the sup - norm of the initial distribution . for one - dimensional strategy spaces , we speculate that the solution will always converge to a stationary solution .    for @xmath67 , eq.([rep ] ) has been studied by cressman @xcite and oechsler & riedel @xcite .",
    "they show that eq.([rep ] ) has a unique solution , for all times , on a large space of distributions , containing amongst others the dirac - delta distributions .",
    "in symmetric @xmath68 games there are two possible strategies , denoted by @xmath69 and @xmath70 . the payoff to player @xmath3 is given by the payoff matrix    @xmath71=    [ cols=\"<,<,<\",options=\"header \" , ]     .",
    "the discrete replicator dynamics associated with this game consists of an infinite population where a fraction @xmath72 plays the pure strategy @xmath69 and a a fraction @xmath73 plays the pure strategy @xmath70 .",
    "the payoffs to strategies @xmath69 and @xmath70 are given by : @xmath74the average payoff to the total population is then @xmath75with a mutation rate matrix of the form @xmath76 , @xmath77 and using @xmath78 , this leads to the following equation for @xmath79@xmath80where @xmath81 and @xmath82 .",
    "the solutions of eq.([discrrep ] ) for @xmath83 are summarised in figure 1 .",
    "a typical example of a game in the quadrant @xmath84 is the classic prisoners dilemma , where @xmath85 .",
    "the strategy @xmath69 corresponds to defect and strategy @xmath70 to cooperate. figure 1 shows that for @xmath86 the discrete replicator dynamics eq.([discrrep ] ) predicts a final outcome of @xmath87 , @xmath88 , or all",
    "defect. the effect of the mutation is to shift the stable solution to a slightly lower value of @xmath89 .",
    "the hawk - dove game ( also known as chicken ) has @xmath90 , where now strategy @xmath69 corresponds to hawk ( or never back down ) and @xmath70 to dove ( allways back down ) .",
    "when the cost @xmath91 to the loser of a hawk - hawk fight is larger than the gain @xmath92 a hawk makes when confronting a dove , we have @xmath93 .",
    "it follows from eq.([discrrep ] ) that for @xmath58 the solution tends to the stable equilibrium @xmath94 , describing a population where the strategies co - exist .",
    "also in this case , the effect of the mutation term is restricted to a small shift in the location of the stable equilibrium .",
    "the quadrant with @xmath95 is the domain of the coordination games , exemplified by the situation @xmath96 in a coordination game it is advantageous for both players to play the same strategy . in a @xmath68 game",
    ", this leads to two equilibria .",
    "note , however , that in the example mentioned here the situation where both play strategy @xmath69 is superior to the one where both play @xmath97 for @xmath67 there are two stable solutions and one unstable one , and the final outcome depends on the initial situation .",
    "when @xmath98 the solution will ultimately tend to @xmath99 , otherwise to @xmath87 .",
    "in other words , when the initial fraction of strategy @xmath69 players is too small , the final population will consist exclusively of strategy @xmath70 players , even though this is the less attractive of the two equilibria .",
    "in the case of coordination games , the effect of mutation can qualitatively change this picture . with the above given values of @xmath100 and @xmath101 ,",
    "we have plotted the right - hand side of eq.([discrrep ] ) for several values of @xmath102 .",
    "( figure 2 ) .    ) , width=264 ]    from this picture it follows that for values of @xmath103 larger than a critical value @xmath104 ( in this example @xmath105 ) the only equilibrium left is the optimal one near @xmath87 , which is also the globally attracting solution .      in @xcite , eq.([discrrep ] ) is studied , where instead of a deterministic mutation term , a small noise term is added .",
    "this leads to the stochastic equation :    @xmath106    where @xmath107 and @xmath108 denotes a wiener process with zero mean and unit variance .    in this model , the mutation from one strategy to another does not happen at a fixed rate , as in the model described by eq.([discrrep ] ) , but rather the fraction @xmath72 is changed by a small random amount per time - step . to describe the outcome of eq.([discrstoch ] ) , we consider the evolution of the probability density @xmath109 the probability that at time @xmath11 the fraction of strategy @xmath69 players lies in the interval @xmath110 $ ] is given by @xmath111 .",
    "the equation for @xmath112 is the fokker - planck equation @xcite : @xmath113 we assume reflecting boundaries , which yield as boundary conditions : @xmath114 eq.([fp1 ] ) with conditions ( [ bcfp ] ) has a unique , attracting , stationary distribution @xmath115 @xcite .    it is easy to see that this equilibrium distribution is given by @xmath116 where the constant @xmath91 is determined by the condition @xmath117 .",
    "differentiating @xmath115 once yields @xmath118from which it follows that the extrema of @xmath115 are the zeroes of @xmath119 , which are the equilibria of the discrete replicator equation ( discrrep ) with @xmath67 .",
    "differentiating once more gives @xmath120so at an equilibrium point @xmath121 we have that @xmath122 with @xmath123 .",
    "therefore , a stable equilibrium of eq.([discrrep ] ) with @xmath67 corresponds to a maximum of @xmath115 , and an unstable equilibrium to a minimum .    in the limit @xmath124",
    ", the stationary distribution @xmath125 will tend to a point - distribution , where the total probability is concentrated on one point . in the case of the hawk - dove game and the prisoners dilemma",
    "it is clear that this point - distribution is concentrated on the unique stable equilibrium of the corresponding discrete replicator equation . for coordination games",
    ", there are two stable equilibria in the discrete case . correspondingly , the stationary distribution has two local maximuma , namely at @xmath126 and at @xmath127 . in @xcite",
    "it is proved that for @xmath128 one of these two maxima will eventually dominate .",
    "the equilibrium that finally emerges is the one which has the largest basin of attraction in the discrete case , and is known in the game - theory literature as the risk - dominant equilibrium .",
    "the two strategy set of @xmath68 games can be extended to a continuum of strategies , each of which indicated by a real number @xmath129.$ ] for the payoff function @xmath130 we choose a simple interpolation between the four payoff values of the symmetric @xmath68 game : @xmath131    this game can be considered as the underlying discrete @xmath68 game where now mixed strategies are allowed , in the following sense .",
    "a strategy @xmath132 $ ] means that the player will use pure strategy @xmath69 with probability @xmath133 .",
    "we now assume that two players , using strategies @xmath133 and @xmath134 respectively , at one encounter play each other a large number of times .",
    "eq.([mpay ] ) then gives the expectation value of the payoff to the first player . because our players will soon become aware of the law of large numbers , they wo nt bother with playing against each other , but at an encounter simply settle for the payoff given by eq.([mpay ] ) , making this a deterministic game .",
    "the expressions for @xmath135 and @xmath136 are easy to calculate : @xmath137 in which @xmath138is the average strategy .",
    "then @xmath139and @xmath140where @xmath3 and @xmath8 are the same parameters as defined in section 3.1 .",
    "eq.([rep ] ) for @xmath141 now becomes : @xmath142 with boundary conditions : @xmath143 and an intial distribution @xmath144 .      as was noted before , when considering eq.([full ] ) without mutation , i.e. with @xmath67 , it is not necessary to impose the boundary conditions ( bcpd ) in order to ensure that @xmath145d@xmath133 remain constant . in @xcite",
    "it is shown that @xmath146has a unique solution for all @xmath147 . in this subsection",
    "we will analyse the asymptotic behaviour of the solution of eq.([geenmut1d ] ) as @xmath148 .",
    "firstly , the equation for the average @xmath149 is given by : @xmath150 where @xmath151d@xmath133 .",
    "the factor @xmath152 is always positive .",
    "for the four different regions of the @xmath153 parameter plane , as illustrated in figure 1 , eq.([xstreep ] ) implies the following .",
    "@xmath154 : in this case @xmath155 for all @xmath11 , so @xmath149 is an increasing function . because @xmath156 for @xmath157 $ ] , the distribution will accumulate at @xmath127 and @xmath158 .",
    "@xmath159 : eq.([xstreep ] ) now has an attractive fixed point at @xmath160 .",
    "therefore , @xmath161",
    "@xmath162 : similar to @xmath69 , but now @xmath163 .",
    "@xmath164eq.([xstreep ] ) has a repelling fixed point at @xmath165 .",
    "it follows that @xmath166 if @xmath167 and @xmath168 if @xmath169    in the cases @xmath69 , @xmath170 and @xmath171 the limiting distributions @xmath172 are point - distributions concentrated on one of the endpoints of the domain @xmath173 $ ] .",
    "this is comparable with the results in the model described in section 3.2 when @xmath124 : eventually all players will play either one or the other of the pure strategies .",
    "the situation is quite different for case @xmath70 , i.e. for hawk - dove type games .",
    "we will show that in this case , @xmath174 depends on the initial condition @xmath175 , but is in general non - zero on all of @xmath173 $ ] .",
    "this is a dramatic difference with the above mentioned model .",
    "there , the population is divided into a fraction @xmath176 of the population who play pure strategy @xmath69 and the rest who play strategy @xmath70 . in our model , where the players have access to a continuum of mixed strategies , we do not find that everybody plays the mixed strategy @xmath177 ( play strategy @xmath69 with probability @xmath176 ) , as might be expected .",
    "rather , the final outcome is a population who s members play a broad range of strategies , although the average value of the strategies played is @xmath160 .",
    "the details are as follows .",
    "every distribution @xmath178 with @xmath179 is a solution of eq.([geenmut1d ] ) .",
    "we will now show that this set of distributions is attractive.let @xmath180 .",
    "the solution of eq.(geenmut1d ) then is @xmath181 using @xmath182d@xmath127 and writing @xmath183d@xmath11 , it follows that @xmath184 therefore @xmath185 differentiating relation ( [ lambda ] ) with respect to @xmath11 yields @xmath186 using @xmath187 , and eq.([lambda ] ) , this reduces to @xmath188 since @xmath189 , then @xmath190d@xmath191 either tends to a finite limit or diverges . using the change of variable @xmath192 ,",
    "we can write :    @xmath193    therefore , when @xmath194 , then @xmath195 by a similar argument , when @xmath196 then @xmath197 .",
    "since @xmath189 is neither @xmath198 nor @xmath199 , it follows that @xmath200 is finite .",
    "therefore , as @xmath201 the solution eq.([solgeenmut2 ] ) tends to @xmath202 which is clearly not a point - distribution .",
    "the value of @xmath203 can be found from eq.([solxstreep ] ) , which in the limit @xmath201 reads : @xmath204this equation for @xmath203 can be solved numerically for given values of @xmath3 and @xmath8 and a given initial distribution @xmath175 . in figure 3 , two examples , both with @xmath205 and @xmath206 are given for different initial distributions , shown in the left column . in the right column the final distributions are plotted .",
    "numerical experiments show that all solutions of the full equation ( full ) converge to a time - independent solution .",
    "the equation for these stationary solutions is given by : @xmath207 @xmath208 rather than giving a definition of @xmath209 in terms of @xmath178 , we take @xmath209 to be a free parameter and impose the conditions ( statbound ) . integrating eq .",
    "( [ fullstat ] ) over @xmath133 from @xmath198 to @xmath199 then yields : @xmath210 assuming that @xmath211 , the equality @xmath212 then follows automatically .",
    "let @xmath213 and @xmath214 .",
    "then the solution of eq .",
    "( fullstat ) is given by : @xmath215+b\\,bi[-s(% \\overline{x})\\kappa ( \\overline{x})(x-\\overline{x } ) ] ,   \\label{solgen}\\]]where the airy functions @xmath216 and @xmath217 are the standard linearly independent solutions of @xmath218 .",
    "these functions are plotted in figure 4 .     and",
    "@xmath217,width=264 ]    the position @xmath219 of the first maximum of @xmath216 is indicated by a vertical line segment .",
    "the curve for @xmath217 is dashed . imposing the boundary conditions @xmath220 gives @xmath221+b\\,bi^{\\prime } [ s(\\overline{x})\\kappa ( \\overline{x})\\overline{x}]=0\\]]@xmath222+b\\,bi^{\\prime } [ s(\\overline{x})\\kappa ( \\overline{x})(\\overline{x}-1)]=0,\\]]so that a non - trivial solution only exists if @xmath209 is a solution to the eigenvalue equation : @xmath223bi^{\\prime } [ s(% \\overline{x})\\kappa ( \\overline{x})(\\overline{x}-1)]-bi^{\\prime } [ s(\\overline{% x})\\kappa ( \\overline{x})\\overline{x}]ai^{\\prime } [ s(\\overline{x})\\kappa ( % \\overline{x})(\\overline{x}-1)]=0 .",
    "\\label{eigenval}\\]]corresponding to a solution @xmath209 of eq .",
    "( [ eigenval ] ) , we find that the solution ( [ solgen ] ) can be written as : @xmath224ai[s(% \\overline{x})\\kappa ( \\overline{x})(\\overline{x}-x)]-ai^{\\prime } [ s(\\overline{% x})\\kappa ( \\overline{x})\\overline{x}]bi[s(\\overline{x})\\kappa ( \\overline{x})(% \\overline{x}-x ) ] ) ,   \\notag\\end{gathered}\\]]in which @xmath225 is determined by the normalisation condition .",
    "we found that , although the eigenvalue equation ( [ eigenval ] ) can have many solutions , there will be at most three that correspond to a distribution ( [ solspec ] ) with the property that @xmath226 for all @xmath227 $ ] . for values of a and b in the regions i and ii of figure 1 , typified by pd- and hd - games",
    ", there is only one solution .",
    "the distributions calculated for @xmath228 are shown in figure 5 .",
    "for the pd - case the parameters are @xmath229 @xmath230 and @xmath231 for the hd - case they are @xmath232 @xmath233 and @xmath234 for ( a , b)@xmath235 , _",
    "i.e. , _ for coordination games , there exist three solutions for this value of @xmath103 .",
    "the corresponding distributions are plotted in one picture ( figure 6 ) .        with @xmath236 and @xmath237",
    "we find for the average strategies @xmath238 @xmath239 and @xmath240    we now study the behaviour of the solution of ( [ fullstat ] ) and ( statbound ) for @xmath124 .",
    "first consider the case that @xmath241 as @xmath124 . from figure 4",
    "it is clear that if @xmath242 , then @xmath243\\rightarrow \\infty $ ] , @xmath244 $ ] remains bounded and @xmath245\\rightarrow 0 $ ] , as @xmath246 .",
    "this implies that @xmath209 can only be a solution of eq.([eigenval ] ) if @xmath247\\rightarrow 0 $ ] . from figure 4",
    ", it then follows that @xmath248 , where @xmath249 is the smallest positive solution of @xmath250 so that @xmath251 and @xmath252 .",
    "more precisely , we have : @xmath253this solution is consistent with the assumption @xmath254 if and only if @xmath255 , as in the prisoners dilemma and the cooperation game .",
    "the corresponding asymptotic expression for @xmath178 becomes : @xmath256=c\\,ai[(\\frac{a}{\\sigma } % ) ^{1/3}(1-x)-\\eta _ { 0}].\\]]note that for @xmath124 this distribution becomes sharply peaked at @xmath127 , with the width of the peak proportional to @xmath257 .    by a similar reasoning",
    ", it is found that for @xmath258 ( as in the cooperation game ) there exists a solution such that @xmath259\\]]as @xmath124 .    in the previous section we found that for @xmath67 the hawk - dove game and the cooperation game have solutions with @xmath260 , which we call a central solution .",
    "this motivates us to look for solutions for which @xmath261 remains bounded as as @xmath124 .",
    "we therefore assume that @xmath262where @xmath263 is as yet unknown . substituting eq.([asxtreep ] ) into eq.([eigenval ] ) and taking the limit @xmath124 yields : @xmath264bi^{\\prime } [ \\frac{a}{b - a}\\alpha ^{1/3}]-bi^{\\prime } [ \\frac{b}{b - a}\\alpha ^{1/3}]ai^{\\prime } [ \\frac{a}{b - a}% \\alpha ^{1/3}]=0 ,   \\label{alpha}\\]]where @xmath265 is understood to mean @xmath266 .",
    "this is the equation from which @xmath267 must be solved .",
    "although eq.(alpha ) has many zeroes , only one corresponds to a positive distribution given by : @xmath268ai[\\alpha ^{1/3}(x-\\beta ) ] -ai^{\\prime } [ \\beta \\alpha ^{1/3}]bi[\\alpha ^{1/3}(x-\\beta ) ] ) , \\label{palpha}\\]]with @xmath269 for @xmath270 and @xmath271 ( a hawk - dove game ) , it is plotted in figure 7 .",
    ", width=226 ]    we note that eqs .",
    "( [ alpha ] ) and ( [ palpha ] ) are invariant under @xmath272 , @xmath273 .",
    "therefore , as @xmath124 , we find the same central solution for the coordination game with @xmath236 and @xmath237 . from numerical simulations we find , however , that the central solution is stable in the hawk - dove game , but unstable in the coordination game .",
    "away from the limit @xmath124 , we can track the fate of the central solution as @xmath103 grows .",
    "since the full eigenvalue - equation ( eigenval ) is not invariant under @xmath274 , @xmath273 , the situation is different for hawk - dove games as opposed to coordination games . for hawk - dove games ,",
    "we find that the central solution persists for all values of the diffusion coefficient @xmath103 . however , for coordination games we find that above a critical value @xmath104 of @xmath103 , the unstable central solution disappears , together with one of the two stable solutions , leaving only one attracting , stationary solution . when @xmath275 , the solution at @xmath127 remains , and when @xmath276 , the solution near @xmath126 survives .",
    "this can be summarised by saying that for large enough values of @xmath102 , the only attracting solution is a stationary solution near the risk - dominated solution of the discrete equation .",
    "the bifurcation process is illustrated in figure 8,where for two values of @xmath103 the left - hand - side of eq.([eigenval ] ) is plotted as a function of @xmath277 for @xmath278 this function has three zeroes , whereas for @xmath279 there is only one@xmath280 this closely resembles the situation in the discrete case as described in section 2 .",
    "however , the critical values for @xmath103 in the discrete case and in the continuous case are not comparable ( @xmath281 vs. @xmath282 ) .          here",
    "we summarise and compare the results of the three types of games , using the discrete model , the discrete model with a stochastic term and the continuous model with deterministic mutation .",
    "the prisoners dilemma is straightforward . in the discrete case",
    "the population will eventually play all defect .",
    "this does not change when the strategy - space is made continuous and adding deterministic mutation simply changes the limiting delta - distribution to a finite peak with width proportional to @xmath257 .",
    "the contrast with the corresponding stochastic equation is that there the width of the peak is narrower and proportional to @xmath283 .    in the discrete version of the coordination game ,",
    "the population will eventually play either @xmath99 or @xmath87 , where the final outcome depends on the intial condition .",
    "if the mutation rate is larger than a certain threshhold , only the stable solution around the risk - dominant solution remains .",
    "this result remains the same in the continuous case .",
    "depending on the initial distribution of strategies , the final distribution will be sharply peaked ( width of peak proportional to @xmath257 ) around either @xmath126 or @xmath127 . when the mutation rate becomes larger than a critical value ,",
    "only the distribution around the risk - dominant solution remains .",
    "we note that this critical value is much smaller in the continuous case than in the discrete case .",
    "the stochastic equation has only one , attracting , stationary solution .",
    "when the mutation rate @xmath103 is small , this distribution is almost completely concentrated around the risk dominant solution , where again the width of the distribution is proportional to @xmath284 .",
    "the hawk - dove game shows the following behaviour . in the discrete case",
    ", there is an asymptotically stable solution for all values of @xmath77 , which for @xmath67 has the value @xmath285 .",
    "the stochastic equation has a unique attracting stationary solution , peaked around @xmath286 and with a width proportional to @xmath283 . without mutation , @xmath67 ,",
    "the continuous equation has an asymptotically stable invariant set of solutions , consisting of all distributions @xmath178 with average @xmath287 .",
    "depending on the initial distribution , the solution converges to a member of this set .",
    "when the mutation term is added , @xmath77 , only one , attracting , solution remains . in the limit @xmath124",
    ", this solution converges to ( [ palpha ] ) .",
    "this solution is not concentrated on a single point , but has the whole interval @xmath173 $ ] as support . such a solution is sometimes referred to as polymorphic . for small @xmath103 ,",
    "numerical experiments show that a starting distribution initially converges to a distribution close to the solution it would reach if @xmath67 , but then slowly ( on a time - scale of @xmath288 ) evolves to the unique limiting solution .",
    "this behaviour resembles that of a singulary perturbed ordinary differential equation , which in the unperturbed case has an attracting set of fixed points , and where after adding the perturbation , the attracting invariant set survives . in this invariant set",
    "we would have , in this analogy , one attracting fixed point left .",
    "this game has attracted a great deal of interest , mainly as a model to explain the occurrence of strong reciprocity in populations of supposedly selfish individuals.(binmore @xcite , fehr & gachter @xcite ) . here",
    "`` strong reciprocity '' means the willingness to share , but also to punish egotistical behaviour in others , even at a cost to oneself .",
    "see bowles & gintis @xcite .",
    "the game is played by two players .",
    "the first player is given a certain amount of money and proposes a split of this money with the second player .",
    "this second player has the choice between accepting the offer , or rejecting it , in which case neither of the two players will receive anything .",
    "an obvious strategy for the second player is to accept every offer , since something is better than nothing .",
    "realising this , the first player will maximise his share by offering the lowest possible amount to the second player .",
    "this ( combined ) strategy is sometimes referred to as the rational solution  ( page & nowak @xcite ) , the subgame - perfect equilibrium  ( seymour @xcite ) or the strategy of homo economicus  ( bowles & gintis bo ) .",
    "an evolutionary version of this game , taking into account mutations , was studied in @xcite and by nowak et al .",
    "@xcite , using adaptive dynamics . in adaptive dynamics models ,",
    "the population is assumed to always be monomorphic , _",
    "i.e. _ , everybody plays the same strategy . every now and then",
    ", a mutant is introduced .",
    "if the strategy of the mutant is more succesful than the resident strategy , it will quickly spread in the population , thus becoming the new resident strategy . for the ultimatum game",
    "it was found that in the absence of any restrictions , the solution of the adaptive dynamics model indeed converged to the rational solution .",
    "the ultimatum game was also studied by seymour @xcite , using replicator dynamics .",
    "he included mutations as a given , exogeneous term and found that other solutions can emerge , far from the  subgame - perfect solution  , depending on the form and intensity of the mutation function .",
    "we model the ultimatum game as follows .",
    "the strategy space is @xmath289\\times \\lbrack 0,1]$ ] , where a stategy @xmath290 means that the player , in the role of nr . 1",
    ", will offer a fraction @xmath133 , while in the role of nr .",
    "2 he will reject any offer lower than @xmath291 .    in one round , the players will play the role of nr . 1 and nr . 2 alternately .",
    "this leads to a payoff function giving the payoff to strategy @xmath26 when playing strategy @xmath27 ( the factor @xmath292 has been omitted ) : @xmath293 in which the heaviside function is defined by @xmath294    before writing down the full replicator equation ( [ rep ] ) for this case we first introduce a number of abbreviations : @xmath295which are normalised as @xmath296@xmath297 and @xmath298 are defined by @xmath299so that @xmath300 in terms of these functions the local and global averages take the form @xmath301and @xmath302with @xmath303at last the replicator equation becomes @xmath304p(x , y , t)+   \\label{ugrep } \\\\ & & + \\sigma \\delta p(x , y , t ) ,   \\notag\\end{aligned}\\]]in which @xmath305 is the two - dimensional laplace operator .",
    "the boundary condition is @xmath306 in what follows we will restrict ourselves to solutions which can be written as the product of two normalised functions of @xmath307 and of @xmath308 respectively .",
    "it  then necessarily follows that @xmath309with this restriction we easily show , by integrating eq.([ugrep ] ) over @xmath310 , that @xmath311h(x , t)+\\sigma \\frac{% \\partial ^{2}h(x , t)}{\\partial x^{2}}.   \\label{hrep}\\]]the boundary conditions are @xmath312integration over @xmath133 of eq.([ugrep ] ) leads to @xmath313v(y , t)+\\sigma \\frac{% \\partial ^{2}v(y , t)}{\\partial y^{2 } } ,   \\label{vrep}\\]]with boundary conditions @xmath314we note that for @xmath67 these equations are the same as those studied in @xcite , where it is assumed that there are two separate populations of players , one where all members always play the role of nr . 1 and the other with nr . 2 players .      for @xmath67",
    "the equations become : @xmath315h(x , t )   \\notag \\\\",
    "\\frac{\\partial v(y , t)}{\\partial t } & = & [ r(y , t)-c_{2}(t)]v(y , t ) .",
    "\\label{nomut}\\end{aligned}\\]]similar to the hawk - dove game , we identify a set of stationary solutions : @xmath316where @xmath317 is an arbitrary function with @xmath318d@xmath319 and @xmath320 is the dirac-@xmath321 distribution .",
    "the solution ( [ stat ] ) is easily checked , by noting that @xmath322 and that @xmath323 .",
    "we have also used @xmath324 .",
    "the interpretation of this solution is clear : player nr .",
    "1 always offers @xmath209 , so player nr . 2",
    "will always receive this amount , as long as his acceptence threshhold is below @xmath209 .",
    "the average payoff is therefore @xmath325 and any distribution of the @xmath291-values below @xmath209 is stationary , given this distribution of @xmath133 .",
    "the limit @xmath326 corresponds to the subgame - perfect solution .    to show that ( [ stat ] )",
    "represents an attracting set of solutions , we use the same reasoning as in section 3.3.1 , and find @xmath327=\\int_{0}^{1}h_{0}(x)\\,\\exp [ ( 1-x)\\int_{0}^{t}q(x , t^{\\prime } ) \\,\\mathrm{d}% t^{\\prime } ] \\,\\mathrm{d}x\\equiv h(t )   \\label{expc1}\\]]@xmath328   \\label{huitdr}\\]]@xmath329=\\int_{0}^{1}v_{0}(y)\\,\\exp [ \\int_{0}^{t}r(x , t^{\\prime } ) \\,\\mathrm{d}% t^{\\prime } ] \\,\\mathrm{d}y\\equiv v(t )   \\label{expc2}\\]]@xmath330 .",
    "\\label{vuitdr}\\]]by differentiating eq .",
    "( [ expc1 ] ) and ( [ expc2 ] ) , respectively , we obtain : @xmath331\\,\\mathrm{d}x \\label{c1}\\]]@xmath332\\,\\mathrm{d}y . \\label{c2}\\]]assuming that @xmath333 converges to a stationary distribution ( as all numerical results show )",
    ", then @xmath334 converges to a function with a finite number of isolated local maxima .",
    "one of these , say @xmath335 , is the absolute maximum , and it follows from eq.([huitdr ] ) that @xmath336 converges to @xmath337 . from eq.([qr ] ) it follows that @xmath298 converges to @xmath338 and @xmath333 converges to @xmath339 , with @xmath225 a normalization constant . from eq.([cc ] ) it follows that @xmath340 converges to @xmath341 and @xmath342 to @xmath209.the above considerations show that if the solution of eq.([nomut ] ) converges to a stationary solution , it must be a member of the invariant set ( [ stat ] ) .",
    "however , the value of @xmath209 can not be predicted from the above formula s",
    ". numerical solution of eq.([nomut ] ) shows that for random initial distributions of @xmath343 and @xmath344 on the whole interval @xmath345,$ ] the functions @xmath336 and @xmath333 indeed approach the form of eq.([stat ] ) for @xmath201 .",
    "the average strategy @xmath346 based on @xmath347 simulations , takes values between @xmath348 and @xmath349 with a mean value equal to @xmath350 and a standard deviation of @xmath351 we note that a uniform distribution of both @xmath343 and @xmath344 also leads to a value of @xmath352      we have found numerically that when @xmath77 , all solutions of the full equations ( [ hrep ] ) and ( [ vrep ] ) tend to a unique solution of the stationary equations : @xmath353h(x)=0   \\label{hh}\\]]and @xmath354v(y)=0 .",
    "\\label{vh}\\]]the boundary values are those of eqs.([hbnd ] ) and([vbnd]).unfortunately , we have not been able to find closed form expressions for the solutions of these equations .",
    "there are two ways to approximate the stationary solution , which lead to the same result .",
    "first , we numerically solved the full equations([hrep ] ) and ( [ vrep ] ) , by discretising space , solving the resulting coupled set of ordinary differential equations and considering the solution as @xmath355 . in the second method , we define the following seven functions @xmath356 in terms of these functions and with @xmath357 , the stationary equations can now be written as @xmath358f_{1}(x )   \\notag \\\\ \\frac{df_{3}(x)}{dx } & = & f_{4}(x )   \\notag \\\\ \\frac{df_{4}(x)}{dx } & = & -k[f_{6}(x)-c_{2}]f_{3}(x )   \\label{feq7 } \\\\",
    "\\frac{df_{5}(x)}{dx } & = & f_{3}(x )   \\notag \\\\ \\frac{df_{6}(x)}{dx } & = & -xf_{1}(x )   \\notag \\\\ \\frac{df_{7}(x)}{dx } & = & -f_{1}(x )   \\notag\\end{aligned}\\]]these equation can be solved numerically by starting the integration from the following values at @xmath127@xmath359and using a standard routine to arrive at the values of these functions in @xmath360 the numbers ( @xmath361,@xmath362,@xmath363,@xmath364 are as yet unknown .",
    "they should be chosen in such a way that the boundary conditions at @xmath126 be satisfied , _",
    "i.e. , _ @xmath365this matching of four numbers by varying four other numbers should be possible in many ways .",
    "it turns out , however , that the requirement of positivity of @xmath366 and @xmath367 in the whole interval @xmath173 $ ] makes the solution unique .",
    "a root finding routine of mathematica does the job . for @xmath368 the stationary solutions @xmath369 and @xmath370",
    "are shown in figure 9 .    ) and",
    "( [ vh ] ) for @xmath371,width=453 ]    we note that @xmath372 has a gauss - like distribution around a mean value @xmath373 , while @xmath370 is approximated by the right half of a gaussian , with its maximum at @xmath374 . for smaller values of @xmath103 , the value of @xmath375 and the width of the peak of the @xmath369-distribution decrease , but the shape of the distributions is otherwise unchanged .",
    "for values of  @xmath103 down to @xmath376 we have calculated the @xmath103-dependence of @xmath377 in figure 10     as function of @xmath378,width=226 ]    a log - log plot of this dependence is shown .",
    "a good fit of the data points is given by @xmath379 .",
    "the numerical solution of the full time dependent equations reveals a dynamical pattern similar to the hawk - dove game of section 2 .",
    "initially a distribution approaches the attracting set ( [ stat ] ) , after which it slowly converges to the unique stationary solution , on a time - scale of @xmath380 .",
    "in this paper we have generalised the replicator dynamics of games with deterministic mutations , as described in @xcite , to the situation where players have access to a continuous strategy space . the resulting equation ( [ rep ] )",
    "has a well defined solution , which , however , is not easy to analyse in general .",
    "our first example , the continuous version of @xmath68 symmetric games , already illustrates a number of interesting and perhaps unexpected features of this equation . although there is no a priori reason to believe that the continuous and the discrete strategy version of the same @xmath68 game have anything to do with each other , the similarities between some results warrant our surprise at the differences in others . the continuous prisoners dilemma and the coordination game behave similar to their discrete case counterparts :",
    "the final state is a monomorphic distribution , where every player in the population plays one of the two pure strategies .",
    "the extension to a continuous strategy space and the inclusion of mutation ( which has the form of a diffusion term ) only leads to the existence of small variations around the single peak of the final distribution .",
    "also in the continuous coordination game we encounter , as in the discrete case , a threshold value for the mutation term separating a regime with two attracting solutions from one where only a single attractor exists .",
    "the difference occurs in the hawk - dove game . in the discrete version",
    "there is a stable equilibrium with hawks and doves coexisting . in the continuous version",
    "this does not translate into a monomorphic distribution around the mixed strategy corresponding to this equilibrium .",
    "rather , in the unique limiting distribution the whole range of mixed strategies from pure hawk to pure dove is represented .",
    "the attraction to this stationary solution occurs on two time scales . on a fast time scale ,",
    "the solution is attracted to the set of distributions with average corresponding to the equilibrium mixed strategy of the discrete case .",
    "then , on a slow time scale proportional to the inverse of the mutation rate , the solution converges to the unique attractor .",
    "this two timescales phenomenon was observed in numerical simulations , and is currently awaiting a more thorough analysis . also , there are many interesting games with three or more strategies ( for instance rock , scissors , paper ) of which the continuous version can hold more surprises.the results of the second example , the ultimatum game , are of great interest to the debate around strong reciprocity and how it could have evolved .",
    "our model shows that replicator dynamics and a small mutation term can lead to a final outcome far from the subgame - perfect solution .",
    "take , for instance , a mutation rate of @xmath381 so in every time - interval , all players vary their strategies according to the cold rules of self - interest , after which a small fraction of @xmath382 of the population , change their strategy just a little bit .",
    "then we find that an initial population consisting almost entirely of cynical misers ( accept everything and offer nothing ) , eventually turns into a world where the average offer is more than @xmath383 !",
    "this surprising result can be explained in the following way .",
    "consider a situation where all proposers offer only a small share to their opponent and these opponents all have an acceptance threshhold lower than this offer .",
    "now , due to mutation , some acceptors will demand a share that is slightly larger than what is being offered .",
    "normally , this would be a suicidal strategy .",
    "however , also due to mutation , there will be amongst the proposers a small set who are willing to offer slightly more than their colleagues .",
    "on the one hand , these fairer - minded proposers earn slightly less from the bulk of the acceptors , but on the other hand they are the only ones to profit from the small group of high - minded mutants on the acceptor - side .",
    "the net result can be that the second effect dominates and that there will be a tendency towards higher offers .",
    "for sufficiently small mutation rates the dynamics of the ultimatum game show the same structure with two timescales as the continuous hawk - dove game .",
    "an initial distribution is quickly attracted to a distribution where the offers are sharply peaked , and then slowly converges to the unique stationary solution .    in this case too , a more rigorous mathematical analysis is required for a better understanding of the model . in particular it would be nice to be able to calculate the value of the exponent in the formula relating the mutation rate and the average value of the offers , which in this paper we derived from numerical simulations",
    ". for this purpose singular perturbation theory seems to be an appropriate tool .",
    "furthermore , we have only considered mutation rates that are the same for the proposers as for the acceptors .",
    "differentiating between these may also lead to a fuller understanding .",
    "diekmann , o. , _ a beginners guide to adaptive dynamics , _ in _ mathematical modelling of population dynamics , _",
    "r.rudnicki , ed . , 47 - 86 .",
    "banach center publications , vol.63 , institute of mathematics , polish academy of sciences ."
  ],
  "abstract_text": [
    "<S> a partial differential equation is derived , describing the replicator dynamics with mutations of games with a continuous strategy space . </S>",
    "<S> this equation is then applied to continuous versions of symmetric 2x2 games , such as the prisoners dilemma , hawk - dove and coordination games , and to the ultimatum game . in the latter case </S>",
    "<S> , we find that adding even a small mutation term to the replicator equation leads to a solution where the average offer is significantly larger than zero . </S>"
  ]
}