{
  "article_text": [
    "uncovering the nature of dark energy in the universe is perhaps the greatest challenge facing cosmologists in coming years . in recent months many proposed experiments to probe dark energy have been defined , especially in response to a call for white papers by the dark energy task force set up jointly in the us by the nsf , nasa and doe .",
    "these propose a variety of techniques to constrain dark energy parameters , including the luminosity distance ",
    "redshift relation of type ia supernovae ( sne - ia ) , the angular - diameter distance  redshift and expansion rate  redshift relations measured by baryon acoustic oscillations , and use of weak gravitational lensing to probe the growth rate of structures .    following on from heritage of cmb anisotropy studies ,",
    "the standard tool used to illustrate the power of a given instrument or survey is a plot of the projected parameter errors around one or more fiducial models , estimated using a fisher information matrix approach or likelihood analysis of monte carlo simulated data ( knox 1995 ; jungman et al .",
    "1996 ; zaldarriaga , spergel & seljak 1997 ; bond , efstathiou & tegmark 1997 ; efstathiou & bond 1999 ) .",
    "typically , a projection of the parameter uncertainties onto a two - parameter equation - of - state model for dark energy is deployed , showing how tightly parameters are expected to be constrained around , for instance , the cosmological constant model .",
    "the implication is intended to be that if the true values lie outside those error ellipses , then the survey will be able to exclude the cosmological constant model .",
    "however , the principal goal of such surveys is usually identified as being the discovery of dark energy evolution .",
    "this is not a parameter estimation question , but rather one of _ model selection _ ( jeffreys 1961 ; mackay 2003 ; gregory 2005 ) , where one seeks to compare cosmological models with different numbers of variable parameters . within the framework of bayesian inference , the statistical machinery to make such comparisons exists , and",
    "is based around statistics known as the bayesian evidence and the bayes factor .",
    "the bayes factor has the literal interpretation of measuring the change in relative probabilities of two models in light of observational data , updating the prior relative model probabilities to the posterior relative model probabilities .",
    "in this paper we use bayesian model selection tools to assess the power of different proposed experiments .",
    "our method is related to the expected posterior odds ( expo ) forecasting recently developed by trotta ( 2005 ) .",
    "the main difference is that he takes the present observational constraints on the extended model , and seeks to estimate the fraction of that parameter space within which that model can be distinguished from a simpler embedded model .",
    "by contrast , we take a theoretically - motivated view of the parameter space of interest , and seek the locations within that parameter space corresponding to dark energy models which are distinguishable from a cosmological constant by a given experiment .",
    "we also differ computationally , in that as well as using approximate techniques , we use the nested sampling algorithm of skilling ( 2004 ) , as implemented by mukherjee , parkinson & liddle ( 2006 ) , to compute the evidences accurately numerically .    the paper is organized as follows . in section  [ bsf ]",
    "we introduce model selection in the bayesian framework .",
    "section  [ surveys ] describes the dark energy surveys we make model selection forecasts for , and section  [ results ] presents the results .",
    "we conclude in section  [ conclusions ] .",
    "we consider some additional technical details and review the standard parameter forecast procedure in two appendices .",
    "the bayesian model selection framework has now been described in a variety of places ( jaffe 1996 ; mackay 2003 ; marshall , hobson & slosar 2003 ; saini , weller & bridle 2004 ; gregory 2005 ; trotta 2005 ; mukherjee et al .  2006 ) and we will keep our account brief .    in this context , a model is a choice of parameters to be varied to fit the data , its predictions being reflected in the prior ranges for those parameters . a model selection statistic aims to set up a tension between model complexity and goodness of fit to the observed data , ultimately providing a ranked list of models based on their probabilities in light of data . within bayesian inference , the appropriate statistic is the _",
    "bayesian evidence _",
    "@xmath0 ( also known as the marginal likelihood ) , which is the probability of the data given the model in question .",
    "it is given by integrating the likelihood @xmath1 over the set of parameters @xmath2 of model @xmath3 , in light of data @xmath4 , i.e. @xmath5 where the prior @xmath6 is normalized to unity .",
    "the evidence is thus the average likelihood of the model over its prior parameter space . rather than focusing simply on the best - fit parameters ( which will always tend to favour the most complex model available )",
    ", it additionally rewards models with good predictiveness .    by bayes",
    "theorem the evidence updates the prior model probability to the posterior model probability .",
    "the ratio of the evidences of two models , @xmath7 and @xmath8 , is known as the bayes factor ( kass & raftery 1995 ) : @xmath9 note that the prior model probabilities are to be chosen in the bayesian approach , and different people may have different opinions as to those .",
    "nevertheless , everyone will agree on whether the bayes factor led to their original belief becoming more or less tenable relative to another model in light of the data . in describing results from bayes factors , it is common to presume that the prior model probabilities are equal , and we shall follow that practice ; anyone who thinks otherwise can readily recalculate the posterior relative model probability .",
    "the bayesian evidence provides a ranked list of the models in terms of their probabilities , obviating the need to specify an arbitrary significance level as in frequentist chi - squared tests .",
    "nevertheless one still has to decide how big a difference will be regarded as significant . a useful guide as to what constitutes a significant difference between models is given by the jeffreys scale ( jeffreys 1961 ) ; labelling as @xmath7 the model with the higher evidence , it rates @xmath10 as ` not worth more than a bare mention ' , @xmath11 as ` substantial ' , @xmath12 ` strong ' to ` very strong ' and @xmath13 as ` decisive ' .",
    "note that @xmath14 corresponds to odds of 1 in about 150 , and @xmath15 to odds of 1 in 13 .      in order to forecast the power of an experiment for model selection , we ask the following question : given a well - motivated simpler model embedded in a larger parameter space , how far away does the true model",
    "have to lie in order that the experiment is able to exclude the simpler model ?",
    "there are many such cases present in cosmology , for example @xmath16cdm in the space of evolving dark energy models , the question of whether we live in a spatially - flat universe , or whether the initial power spectrum of perturbations is exactly scale invariant , or exactly a power law , etc . here",
    "we will use the dark energy as a worked example .",
    "the bayesian evidence of models with dark energy has been computed from current observational datasets by several authors ( saini et al .",
    "2004 ; bassett , corasaniti & kunz 2004 ; mukherjee et al .",
    "2006 ) , all finding that the simple @xmath16cdm model is the preferred fit to present data .",
    "our aim here is to forecast its outcome in light of future datasets , in order to assess the power of those surveys for model selection .",
    "our procedure is as follows .",
    "we first select an experimental configuration .",
    "we then consider a set of ` fiducial models ' characterized by parameter values @xmath17 , which we shall consider in turn to be the true model . for each choice of fiducial model in our dark energy space we generate a set of simulated data @xmath4 with the properties expected of that experiment .",
    "we then compute the evidences of the two models we seek to distinguish , here the @xmath16cdm model and the general dark energy model . for definiteness , we choose to assess a set of dark energy experiments by their ability to distinguish a @xmath16cdm model from a two - parameter dark energy model with equation of state given by @xmath18 where @xmath19 and @xmath20 are constants and @xmath21 is the scale factor .",
    "although the latter is sometimes referred to as the linder parametrization based on its use in linder ( 2003 ) , it appears to have been first introduced by chevallier & polarski ( 2001 ) .",
    "here @xmath17 refers to all the parameters of the model , but we are principally interested in the dependence of the bayes factor on the extra parameters characterizing the extended model , here @xmath19 and @xmath20 .",
    "our main plots therefore show the difference in log evidence between the @xmath16cdm model and the two - parameter evolving dark energy model , plotted in the @xmath19@xmath20 plane .",
    "this is the bayes factor plot , which is presented in section [ results ] for different dark energy surveys , with contours showing different levels at which the two models can be distinguished by data simulated for each experiment .",
    "in general the bayes factor is a function of all the fiducial parameters , not just the dark energy ones . for the dark energy application this dependence turns out to be unimportant , but for completeness we discuss some issues relating to this in appendix  a.    use of the bayes factor plots to quantify experimental capabilities is quite distinct , both philosophically and operationally , from the use of parameter error forecasts",
    "; for readers unfamiliar with the latter we provide a short review in appendix  b. we highlight the advantages of the bayes factor approach as follows :    1 .",
    "most experiments , particularly dark energy experiments , are motivated principally by model selection questions , e.g.  does the dark energy density evolve , and so should be quantified by their ability to answer such questions .",
    "2 .   in bayes",
    "factor plots , the data are simulated at each point of the dark energy parameter space that is to be confronted with the simpler @xmath16cdm model , whereas parameter error forecasts are plotted around only selected fiducial models ( often just one ) . in particular , in the latter case",
    "the data are usually simulated for a model that people hope to exclude , rather than the true model which would allow that exclusion .",
    "3 .   the bayesian model selection procedure accords special status to the @xmath16cdm model as being a well - motivated lower - dimensional model , which in bayesian terms is rewarded for its predictiveness in having a smaller prior volume . parameter estimation analyses do not recognize a special status for such models , e.g.  the same criterion would be used to exclude @xmath22 as @xmath23 .",
    "model selection criteria provide a more stringent condition for acceptance of new cosmological parameters than parameter estimation analyses .",
    "model selection analyses can also accrue positive support for the simpler model , whereas parameter estimation methods can only conclude consistency of the simpler model .",
    "4 .   in parameter error studies , it is necessary that the simple model is embedded as a special case of the second model . while the models we discuss here are indeed of that type , the bayes factor could also be used to compare non - nested models ( e.g.  two different types of isocurvature perturbation ) . 5 .",
    "although it is not essential to do so , most parameter estimation forecasts assume a gaussian likelihood in parameter space , while the bayes factor plot uses the full likelihood .",
    "set against these advantages , the only disadvantages of the bayes factor method are that it is computationally more demanding , and that its conceptual framework has yet to become as familiar as that of parameter estimation .",
    "we use the nested sampling algorithm ( skilling 2004 ; mukherjee et al .",
    "2006 ) , which is fast enough to enable exact evaluations of the evidence for many fiducial parameter values . for comparison",
    "we also compute results with the savage ",
    "dickey method outlined in trotta ( 2005 ) , using a fisher matrix approximation to the likelihood about the true model , given as equation  ( [ fish ] ) in appendix  b. we discuss how the results from the two methods compare in one case , and present our main results using the more accurate nested sampling method",
    ".      the bayes factor can be found by calculating the evidences of the two models independently , and then taking their ratio .",
    "this method requires integration over the extra cosmological parameters , which does not feature in the savage  dickey method .",
    "here we use our implementation of the nested sampling algorithm ( as described in mukherjee et al .",
    "2006 ) to perform the integration .",
    "to quickly summarize , the algorithm ( skilling 2004 ) recasts the problem as a one - dimensional integral in terms of the remaining ` prior mass ' @xmath24 , where @xmath25 .",
    "the integral becomes @xmath26 where @xmath27 is the likelihood @xmath1 .",
    "the algorithm samples the prior a large number of times , assigning an equal prior mass to each sample .",
    "the samples are then ordered by likelihood , and the integration follows as the sum of the sequence , @xmath28 where the lowest likelihood sample goes into the sum , and is discarded to be replaced by a new sample selected under the condition that it lies above the likelihood of the discarded sample . in this way the algorithm works its way in to the highest likelihood peak .",
    "we compute the evidences using 300 live points , averaging over six repetitions of the calculation .",
    "this requires approximately @xmath29 likelihood evaluations per evidence computation .",
    "bayes factors for two nested models can be computed using the savage",
    " dickey density ratio ( dickey 1971 ; verdinelli & wasserman 1995 ; see trotta 2005 for an application to cosmological model selection ) . assuming a gaussian approximation to the likelihood , the savage ",
    "dickey formula of an extended model @xmath8 with two free model parameters ( @xmath30,@xmath31 ) and flat priors ( @xmath32 ) , versus a simpler model @xmath7 with @xmath33 and @xmath34 , is @xmath35 where @xmath36 is the marginalized @xmath37 fisher matrix evaluated at @xmath38 .",
    "our conventions are defined in appendix  b , and we have used the hat sign for the extended model parameters to emphasize that the bayes factors directly compare the fiducial models of the parameter estimation analysis to the simpler nested model .    in our specific case ,",
    "@xmath8 consists of all dark energy models parametrized by different values of @xmath19 and @xmath20 , while @xmath7 is the cosmological constant model which is nested in @xmath8 with @xmath39 and @xmath40 .",
    "we use equation  ( [ savage ] ) to compute the bayes factor as function of @xmath19 and @xmath20 , to determine the range of dark energy models that a given experiment is able to distinguish from @xmath16cdm .    from equation  ( [ savage ] )",
    "we can see that the bayes factor depends on two multiplicative terms , namely an exponential factor and an overall amplitude .",
    "the former accounts for the distance in the parameter space of the model @xmath8 from @xmath7 in units of the forecasted parameter uncertainty . the latter accounts for the fraction of the accessible prior volume of the extended model @xmath8 in light of the data , and hence this factor penalizes the model @xmath8 for having a large parameter space compared to model @xmath7 . as shown in trotta ( 2005 ) , this factor can be interpreted as an estimate of the informative content of the data , @xmath41 being the order of magnitude by which the prior volume of model @xmath8 will be reduced by the arrival of the forecasted data .",
    "we have simulated observational data for two types of future dark energy experiments : luminosity distance probes made through the measurement of type ia supernovae , and angular - diameter distance measurements from baryonic acoustic oscillations ( bao ) .",
    "some of the experiments considered have weak lensing parts too ( snap , jedi , alpaca ) , but we do not derive dark energy constraints from simulated weak lensing measurements here . note that all these experiments are presently undergoing optimization of their survey structure which may improve their science return .    for the sne - ia",
    ", we compared four different surveys . the cfht supernovae legacy survey ( snls )",
    "is already underway but we consider the full five - year survey , while the supernovae acceleration probe ( snap ) and the joint efficient dark energy investigation ( jedi ) satellite missions , plus the advanced liquid - mirror probe for astrophysics , cosmology and asteroids ( alpaca ) ground - based survey , are all proposed experiments . for all experiments we assumed the same spread in magnitude @xmath42 of the supernovae , representing the combined effect of measurement error and intrinsic dispersion in the light - curve corrected luminosity [ the intrinsic dispersion alone was recently estimated as 0.12 mag by snls ( astier et al .",
    "we used the number distribution of sne - ia with redshift for the different surveys as outlined in the literature ; the total numbers used are 700 , 2000 , 13000 and 86000 for snls ( pritchet et al .",
    "2004 ; astier et al .",
    "2006 ) , snap ( aldering et al .",
    "2004 ) , jedi ( crotts et al .",
    "2005 ) and alpaca ( corasaniti et al .  2005 ) respectively .",
    "we also assumed all surveys would have support from an extra 300 nearby sne - ia observed by ground - based telescopes in the redshift range @xmath43 , which also had a slightly smaller spread in magnitude ( @xmath44 ) .",
    "we assumed no systematic errors in any of the magnitudes , only statistical errors ( except for one comparison case shown later ) .",
    "for the baryonic acoustic oscillations we compared two different surveys , the ground - based wide - field fibre - fed multi - object spectrograph ( wfmos ) and the satellite mission jedi ( jedi will perform both a sn - ia survey and a bao survey ) .",
    "the bao surveys measure both angular - diameter distance @xmath45 and the hubble parameter @xmath46 in a series of redshift bins .",
    "we calculated the expected errors of the measurements in each bin using the fisher matrix approach of seo & eisenstein ( 2003 ) , marginalizing over the physical matter density @xmath47 .    in order to obtain accurate results from experiments of these types ,",
    "it is necessary that strong degeneracies with the matter density are removed by bringing in constraints from other sources .",
    "we make the assumption that by the time these surveys are operative , data compilations including planck satellite observations will have provided a measurement of @xmath48 to an accuracy of @xmath49 ( see for example pogosian et al .",
    "we include such a measurement by adding an extra term to the likelihood centred around the fiducial density parameter value . in the absence of such external information",
    ", dark energy surveys would give a much poorer return .",
    "we will briefly explore the effect of varying this assumption in section  [ s : variations ] .",
    "similarly in the bao case we assume a 1% measurement uncertainty on @xmath50 ( see for example tegmark et al .",
    "2000 ) .",
    "the model priors are the parameter ranges over which the evidence integral is carried out . ordinarily in model selection",
    "these are supposed to be the wide priors seen as appropriate when the model was first considered , and not those motivated by current data .",
    "if one allows the model priors to ` follow the data ' into a small region of parameter space , then model selection calculations will always be inconclusive in the long term , as this requires each new experiment to exclude a model again on its own , rather than the cumulative effect of all observations .",
    "the precise results for the bayes factor will have some dependence on the choice of priors ( see below ) , though the effect of the choices on model comparison or on survey comparison is diminished as the same priors are used for the common model parameters and the same priors are used for each survey being compared .",
    "our choices are as follows .",
    "we only consider flat universes , so that @xmath51 .",
    "for the model priors , we impose the prior ranges @xmath52 and @xmath53 on the interesting parameters , and @xmath54 and @xmath55 on the other parameters ( the hubble parameter is needed only for the baryon oscillation probes ) .",
    "the fiducial values for @xmath48 and @xmath56 are taken to be 0.27 and 0.7 respectively .",
    "note that for the phenomenological two - parameter evolving dark energy model , the model priors on @xmath19 and @xmath20 that we have chosen to work with are somewhat arbitrary .",
    "however if the prior space were reduced for instance by a factor of 2 , that would increase the @xmath57 of the evolving dark energy model by at most @xmath58 , and this would not significantly affect our contours or conclusions which are based on differences in @xmath57 of 2.5 and 5 .",
    "we make a brief investigation of some prior dependences in section  [ s : variations ] .",
    "one should note that our conclusions also depend to some extent on our chosen dark energy parametrization being able to describe the true model .",
    "one could consider more general cases , such as the four - parameter models of corasaniti & copeland ( 2003 ) and linder & huterer ( 2005 ) .",
    "for the purpose of assessing the power of an experimental proposal , it seems reasonable to presume that experiments capable of distinguishing two - parameter models are likely also to be better under other parametrizations .",
    "if the effect of dark energy were in fact a non - smooth variation in the equation of state and a non - smooth variation of the expansion history with redshift , then our results are too optimistic ; the validity of reparametrizing the observables , which are the expansion history in different redshift bins as measured by the surveys , into ( @xmath19,@xmath20 ) would need to be tested when the data arrive .",
    "aspects of parametrization have been explored in wang & tegmark ( 2004 ) and bassett et al .",
    "we begin by comparing our two methods of computing the bayes factor , focussing on the snap mission supernova survey .",
    "the bayes factor plots are shown in figure  [ fig : snap ] . in the left panel",
    "we plot isocontours of bayes factors in the @xmath59@xmath60 plane inferred from the nested sampling method .",
    "the plot shows the generic structure expected of bayes factor plots . in the central region ,",
    "the simulated data are for models very close to @xmath16cdm , so that model gives a good fit and is further rewarded for its predictiveness , giving a positive bayes factor which would support @xmath16cdm over the dark energy model . at the zero contour ( the innermost one plotted ) the models fare equally well , and",
    "then at greater distances the dark energy model becomes favoured .",
    "if the true parameters lie outside those contours , snap will be able to exclude @xmath16cdm at the probability corresponding to the contour level .",
    "we see a strong degeneracy between the two parameters , meaning that supernova data are not good at constraining models in this particular parameter direction .",
    "this same degeneracy shows up in the usual fisher matrix error projection method .",
    "its precise direction depends on the redshift distribution of the supernovae .",
    "cdm as the true model .",
    "the contour levels indicate 68% and 95% .",
    "while this figure uses the full likelihood , in this case a gaussian approximation using the fisher matrix gives essentially identical results.,width=302 ]    in the right panel we plot the projected bayes factor contours derived from the savage ",
    "dickey formula for the same experimental characteristics and priors assumed in the previous case .",
    "we see that this method gives generally good agreement with the nested sampling computation , indicating that our calculations are robust .",
    "some slight differences are apparent , but this is expected as our version of the savage ",
    "dickey method employs a gaussian approximation for the likelihood which may become poor at large distances from @xmath16cdm , with the fisher matrix method underestimating the covariance matrix . for parameter estimation",
    "this is not a major concern , since deviations from the gaussian approximation occur in the tail of the likelihood distribution , and quoted errors usually refer to the @xmath61 confidence intervals .",
    "however model selection calculations rely on good modelling well into the tails of the distribution .    having verified that our methods give similar results , henceforth we will show results from the nested sampling method , since although it is computationally more intensive it does not assume a gaussian likelihood .",
    "+   +   +      in this paper we are strongly advocating use of bayes factor plots to quantify experimental capabilities , for the reasons enumerated in section  [ ss : list ] .",
    "it is useful to see explicitly what differences this gives as compared to the traditional parameter forecast approach , and so figure  [ fig : snap2 ] shows a plot of likelihood contours , obtained from a markov chain monte carlo analysis of data simulated for the snap supernova survey , using precisely the same assumptions as figure  [ fig : snap ] , and assuming that @xmath16cdm is the true model .",
    "we see they share the same general shape , and that the same principal parameter degeneracy is picked out .",
    "obviously the two plots are conceptually very different and so caution is needed in comparing .",
    "we see that the bayes factor contours are significantly wider , indicating that model selection sets a more stringent condition for dark energy evolution to be supported by the data .",
    "indeed , the 95% fisher parameter contour lies within the @xmath62 contour where model selection gives the models equal probability , hence by using the fisher matrix plot we could rule out @xmath16cdm with data that actually favours it .",
    "it is fairly generic for that to be the case , indicating that 95% parameter estimation ` results ' tend not to be robust under more sophisticated statistical analyses .",
    "this is a manifestation of lindley s ` paradox ' as discussed by trotta ( 2005 )  that parameter values rejected under a frequentist test can nevertheless be favoured by bayesian model selection .",
    "we now turn to a comparison of the six dark energy surveys described above .",
    "we stress once more that this comparison considers the statistical uncertainties alone , and several of these experiments are likely to be limited by systematics .",
    "the criteria that enable the systematics to be most effectively minimized are likely to be different from those giving experiments raw statistical power .",
    "further we are working under the limitation of the particular @xmath19@xmath20 parametrization ; dark energy in reality could be different .",
    "figure  [ fig : all ] shows the six surveys , the upper four being supernova surveys and the lower two being the baryon acoustic oscillation surveys .",
    "the innermost contoured region is where the evidence of the @xmath16cdm model is greater than that of the evolving dark energy model ( @xmath63 ) .",
    "the outer contours show @xmath64 and @xmath65 so that the data provides strong evidence in favour of the evolving dark energy model . as with parameter",
    "estimation contours , the smaller the contours the more powerful the experiment is .",
    "as expected , we see a range of constraining powers depending on the scale of the experiments .",
    "we also see that they broadly share the same principal degeneracy direction , with slight rotations visible from the different probing of redshift bins .",
    "the massive size of the expected alpaca dataset gives it the smallest contour area amongst sn - ia experiments , with its more limited redshift range making its degeneracy more vertical .",
    "the baryon oscillation probes share almost the same principal degeneracy as the sne - ia ; although they use the angular - diameter distance rather than the luminosity distance these two are related by the reciprocity relation and hence follow the same degeneracy shape if the uncertainties in each redshift bin follow the same shape . a probe which partly included the growth of structure , such as weak lensing ,",
    "would be expected to have a somewhat different degeneracy ; this has been shown using fisher parameter contours for the snap lensing survey though the rotation is still smaller than one would like .",
    "note that the logarithms of the bayes factors are additive , so if more than one of these surveys happen , or if there are two independent parts to a survey , then their bayes factor plots can be added together to give a net bayes factor plot .",
    "in addition to plotting bayes factor contours , one can further compress the information on how powerful an experiment is by computing the area within a particular contour level , to give a single ` figure - of - merit ' .",
    "table  [ tab : areas ] summarizes these areas , expressed in coordinate units , for the six experiments , showing the area where @xmath66 exceeds @xmath67 .",
    "note that this corresponds to the parameter area in which an experiment _ can not _ strongly exclude @xmath16cdm , and hence small numbers are better . for a more extensive discussion of figures - of - merit for optimization of dark energy surveys , in a parameter estimation rather than model selection framework , see bassett ( 2005 ) and bassett , parkinson & nichol ( 2005 ) .",
    ".two experimental figures - of - merit : the areas in the @xmath59@xmath60 plane where @xmath66 exceeds @xmath67 , and the value of @xmath66 at @xmath68 and @xmath69 .",
    "the former measures the region of parameter space where the experiment would not be able to exclude the @xmath16cdm model , while the latter measures the strength with which the experiment would support @xmath16cdm were it the true model .",
    "the @xmath66 are additive between surveys and for independent probes of dark energy within the same survey . [ cols=\"<,^,^\",options=\"header \" , ]      we now consider the possibility of the experiments ruling out the dark energy model in favour of @xmath16cdm , rather than the opposite which we have focussed on thus far . unlike parameter estimation methods , bayesian model selection can offer positive support in favour of the simpler model .",
    "because the simpler model is nested within the dark energy model , it can never fit the data better , but it can benefit from the volume effect of its smaller parameter space .",
    "all one needs to do is read off the bayes factor for the case where the fiducial model is @xmath16cdm .",
    "table  [ tab : areas ] shows @xmath66 at @xmath68 and @xmath69 , i.e.  when @xmath16cdm is the true model .",
    "we find that this value is above 2.5 for all surveys , and above 5 for several of them .",
    "thus many of the surveys are capable of accumulating strong evidence supporting @xmath16cdm over evolving dark energy .",
    "this can be seen as another figure of merit quantifying the power of experiments .",
    "note again that the @xmath66 are additive between surveys and for independent probes of dark energy within the same survey .    note that the absolute value of this figure of merit is more sensitive to the prior ranges chosen for the dark energy parameters , which set the volume factor .",
    "however the relative comparison of surveys is again not affected by this .",
    "bayes factor forecasts for snap assuming different external knowledge of @xmath70 .",
    "contours are again shown for @xmath71 , @xmath67 and @xmath65 .",
    "a gaussian external constraint on @xmath70 is assumed , of width 0.03 ( top panel ) reflecting approximately the current level of uncertainty on it , and 0.003 ( lower panel ) reflecting an optimistic outcome.,title=\"fig:\",width=302 ] +   bayes factor forecasts for snap assuming different external knowledge of @xmath70 .",
    "contours are again shown for @xmath71 , @xmath67 and @xmath65 .",
    "a gaussian external constraint on @xmath70 is assumed , of width 0.03 ( top panel ) reflecting approximately the current level of uncertainty on it , and 0.003 ( lower panel ) reflecting an optimistic outcome.,title=\"fig:\",width=302 ]      we end by examining the effect of varying some of the assumptions that went into the calculations , focussing on the snap supernova survey for definiteness .",
    "we do this in three ways , one by changing the presumed knowledge on @xmath48 that complements the dark energy survey , one by looking at an alternative prior in the dark energy model space , and finally by altering the assumed dispersion of supernova luminosities and allowing for a simple model of systematics .",
    "as mentioned before , the return on dark energy surveys is quite sensitive to the availability of external constraints to remove parameter degeneracies , particularly @xmath48 in the case of the supernovae .",
    "figure  [ fig:3plots ] shows this effect for the snap supernova survey , with different constraints on @xmath48 to be compared with our standard assumption leading to the left panel of figure  [ fig : snap ] .",
    "one sees a significant worsening of the bayes factor contours in the case of weaker knowledge on @xmath48 .",
    "altering the constraint on @xmath48 can have a different effect on different experiments .",
    "for instance , if it were more stringent , then the difference between snls and snap or jedi would be greater  the requirement for a more sensitive experiment would be greater .",
    "similarly the relative comparison is dependent on the nature of dark energy itself ; if a parametrization more complex than @xmath19@xmath20 proved necessary , it would be more important to make precise high - redshift observations ( e.g.  snap or jedi versus alpaca ) .",
    "snap bayes factor contours for the quintessence prior on @xmath19 and @xmath20 .",
    "the lower left - hand region is cut off by the prior .",
    "the dashed contour shows the location of the @xmath72 contour for our full prior , as given in figure  [ fig : snap].,width=302 ]    figure  [ f : quint ] modifies our assumptions in a different way , this time altering the prior on the dark energy parameters .",
    "it assumes a prior appropriate to quintessence models , namely that @xmath73 at all redshifts .",
    "the evidence integral for the dark energy model is then carried out over a narrower region in the dark energy parameters , giving a boost to the evidence of the dark energy model relative to @xmath16cdm .",
    "however the effect is small ; the dashed line shows where the outer contour lay with our full dark energy prior and it has shrunk in only marginally .",
    "caldwell & linder ( 2005 ) classified quintessence models into freezing and thawing models and delineated areas of the @xmath19@xmath20 space where those models typically lie . according to figure  [ f :",
    "quint ] , freezing models can only be decisively distinguished from @xmath16cdm by the snap supernova survey if @xmath74 , and thawing models if @xmath75 .",
    "we have also investigated how changing the prior ranges on the dark energy parameters alters the areas given in table  [ tab : areas ] . in this case",
    "we narrowed the priors on @xmath19 and @xmath20 by a factor of two in each direction . in cases where the posterior still lies within the priors , this shifts the evidence by @xmath76 in favour of the dark energy model .",
    "unsurprisingly , we find this reduces the areas within which @xmath16cdm can not be excluded , typically by 10 to 20 per cent .",
    "importantly , however , this change preserves the rankings of the experiments .     the main contours match the left panel of figure  [ fig : snap ] , showing the snap supernova survey .",
    "additionally , the dashed contour shows how the outer contour shifts under a simple modelling of systematics , and the dot - dashed contour shows how the outer contour would move if the magnitude error were smaller.,width=302 ]    finally , in figure  [ f : snapsys ] we examine how the outer contour would shift if a smaller magnitude dispersion were achieved ( we take @xmath77 ) , and separately under a standard ( but crude ) modelling of possible systematics ( see for example kim et al .",
    "the systematics have been modelled as an increased redshift dependent uncertainty in magnitude of @xmath78 per redshift bin with @xmath79 mag , and added in quadrature to the ( intrinsic ) statistical uncertainty . for snap",
    ", this type of systematic has quite a small effect .",
    "there can be other types of systematics in the data , but we do not try to model them here as the ability of different experiments to detect and ( internally ) resolve systematics would be different and a proper study of systematics and the required marginalization over them can only be done once the data arrive .",
    "in this paper we have introduced the bayes factor plot as a tool for assessing the power of upcoming experiments .",
    "it offers a full implementation of bayesian model selection as a forecasting tool . as",
    "compared to the traditional parameter error forecasting technique , it offers a number of advantages enumerated in section  [ ss : list ] . amongst those ,",
    "perhaps the most important are that observational data is simulated at each point in the plane , rather than at a small number of fiducial models , and that the bayes factor plot properly captures the experimental motivation as being one of model selection rather than parameter estimation .    as a specific example",
    ", we have used the bayes factor plots to examine a number of proposed dark energy surveys , concentrating on their ability to distinguish between the @xmath16cdm model and a two - parameter dark energy model .",
    "figure  [ fig : all ] indicates the region of parameter space outside which the true model has to lie , in order for the experiment to have sufficient statistical power to exclude @xmath16cdm using model selection statistics .",
    "an important caveat is that our plots do not show the effects of systematics , which are likely to be the dominant uncertainty for many of the experiments .",
    "this drawback is shared by parameter error forecasts , and it is more or less the nature of systematic uncertainties that they can not be usefully modelled in advance of actual observational data being obtained . in judging the true merit of an experimental proposal ,",
    "it is therefore essential to judge how well structured it is for optimal removal of systematics , as well as looking at its raw statistical power .",
    "while we have focussed on dark energy as a specific application , the concept of the bayes factor plot has much broader applicability , and is suitable for deployment in a wide range of cosmological contexts .",
    "pm , dp and arl were supported by pparc ( uk ) , psc by columbia academic quality funds , and mk by the swiss nsf .",
    "pm acknowledges yun wang for helpful discussions regarding the application of the fisher matrix formalism to bao observations .",
    "we thank arlin crotts for information concerning jedi , and roberto trotta for helpful discussions and comments .    aldering g. et al .",
    "( snap collaboration ) , 2004 , astro - ph/0405232 astier p. et al .",
    "( snls collaboration ) , 2006 , a&a , 447 , 31 bassett b. a. , 2005 , phys .",
    "d , 71 , 083517 bassett b. a. , corasaniti p. s. , kunz m. , 2004 , apj , 617 , l1 bassett b. a. , parkinson d. , nichol r. c. , 2005 , apjl , 626 , l1 bond j. r. , 1995 , phys .",
    "lett . , 74 , 4369 bond j. r. , efstathiou g. , tegmark m. , 1997 , mnras , 291 , l33 caldwell r. r. , linder e. v. , 2005 , phys . rev .",
    "lett , 95 , 141301 chevallier m. , polarski d. , 2001 , int . j. mod .",
    ", d10 , 213 corasaniti p. s. , copeland e. j. , 2003 , phys .",
    "d , 67 , 063521 corasaniti p. s. , loverde m. , crotts a. , blake c. , 2005 , astro - ph/0511632 crotts a. et al .",
    "( jedi collaboration ) , 2005 , astro - ph/0507043 dickey j. m. , 1971 , ann .",
    "stat . , 42 , 204 efstathiou g. , bond j. r. , 1999 , mnras , 304 , 75 gregory p. , 2005",
    ", _ bayesian logical data analysis for the physical sciences _ ,",
    "cambridge university press jaffe a. , 1996 , apj , 471 , 24 jeffreys h. , 1961 , _ theory of probability _ , 3rd edition , oxford university press jungman j. , kamionkowski m. , kosowsky a. , spergel d. n. , 1996 , phys .",
    "d , 54 , 1332 kass r. e. , raftery a. e. , 1995 , j. amer .",
    "assoc . , 90 , 773 kim a. g. , linder e. v. , miquel r. , mostek n. , 2004 , mnras , 347 , 909 knox l. , 1995 , phys .",
    "d , 52 , 4307 kratochvil j. , linde a. , linder e. v. , shmakova m. , 2004 , jcap , 0407 , 1 linder e. v. , 2003 , phys .",
    "lett . , 90 , 091301 linder e.v . ,",
    "huterer d. , 2005 , phys .",
    "d , 72 , 043509 mackay d. j. c. , 2003 , _ information theory , inference and learning algorithms _ , cambridge university press marshall p. j. , hobson m. p. , slosar a. , 2003 , mnras , 346 , 489 mukherjee p. , parkinson d. , liddle a. r. , 2006 , apjl , 638 , l51 pogosian l. , corasaniti p. s. , stephan - otto c. , crittenden r. , nichol r. , 2005 , phys .",
    "d , 72 , 103519 pritchet c. j.  ( snls collaboration ) , 2004 , astro - ph/0406242 saini t. d. , weller j. , bridle , s. l. , 2004 , mnras , 348 , 603 seo h .-",
    "j . , eisenstein d. j. , 2003 , apj , 598 , 720 skilling j. , 2004 , in _",
    "bayesian inference and maximum entropy methods in science and engineering _ , ed . r. fischer et al . ,",
    "proc . , 735 , 395 ( available at http://www.inference.phy.cam.ac.uk/bayesys/ ) .",
    "tegmark m. , eisenstein d. j. , hu w. , de oliveira - costa a. , 2000 , apj , 530 , 133 tegmark m. , taylor a. , heavens a. , 1997 , mnras , 480 , 22 trotta r. , 2005 , astro - ph/0504022 .",
    "verdinelli i , wasserman l. , 1995 , j. amer .",
    "assoc . , 90 , 614 wang y. , tegmark m. , 2004 , phys .",
    "lett . , 92 , 241302 weller j. , albrecht a. , 2001 , phys . rev .",
    "lett . , 86 , 1939 zaldarriaga m. , spergel d. n. , seljak u. , 1997 , apj , 488 , 1",
    "in the main body of the paper , we have plotted the bayes factor as a function of the fiducial values of the dark energy parameters , assuming particular values for the other parameters in the fiducial model . in general , however , the bayes factor is a function of all the fiducial model parameters , not just the ones of principal interest , though a practical problem is that we can not easily plot the evidence ratio @xmath80 as a function of more than two variables @xmath17 .",
    "one solution is marginalization over the parameters that we are not interested in , as one does in parameter estimation , assuming those parameters to lie within the range motivated by present data . as the fiducial parameters @xmath17 belong to the definition of the data , we need to marginalize the evidences , @xmath81 , rather than the bayes factors .",
    "formally , the marginalization must take place in data space , so when we wish to integrate out a ` nuisance ' parameter @xmath38 which the data is a function of , we should take into account a transformation factor @xmath82 , evaluated at each @xmath17 along the integral",
    ". however , provided the evidence varies only weakly over the relevant range of the fiducial models , or if our model depends ( nearly ) linearly on its parameters , then this function is a constant which cancels when computing the bayes factor . in this case",
    "we can just average the evidences .",
    "this will also conserve the relation @xmath83 .    in practice ,",
    "the main determining factor in whether particular extra parameters are justified by the data is the true values of those parameters themselves , rather than values of the other parameters .",
    "often , then , one can choose fixed values of the uninteresting parameters , presenting results on a slice through the fiducial parameter space . indeed , this turns out to be the case for the dark energy surveys in this paper .",
    "in this paper we are advocating the use of bayes factors to quantify the power of upcoming experiments , in place of parameter error forecasts . for comparison",
    ", we provide a brief overview of parameter error forecasting here , and discuss some of its features and limitations .    the idea is to simulate a sample of experimental data and then infer the parameter uncertainties using standard likelihood analysis .",
    "more specifically , assuming a model @xmath3 specified by a set of parameters @xmath84 , a sample of data @xmath4 with the expected experimental errors is generated for a particular fiducial model with parameter values @xmath17 .",
    "then a likelihood @xmath1 is computed and the confidence intervals on the @xmath2 parameters are inferred by computing a posterior parameter probability distribution via bayes rule , @xmath85 as a result the parameter uncertainties depend both on the experimental characteristics and the choice of the fiducial model .    a simplified way of carrying out such an analysis is to use the fisher matrix approximation . by construction the fiducial model parameter values @xmath17 maximize the likelihood . hence expanding @xmath86 to quadratic order in @xmath87 one",
    "obtains ( bond 1995 ; tegmark , taylor & heavens 1997 ) @xmath88 which is a gaussian approximation to the likelihood with zero mean and with variance given by the inverse of the fisher matrix @xmath36 , where @xmath89 the sum is over all measurements and the partial derivatives are evaluated at the fiducial model parameter values @xmath38 .",
    "the matrix @xmath90 is the data covariance matrix ; for independent measurements ( e.g.  different supernovae ) it simplifies to @xmath91 .",
    "the parameter errors are then given by the square root of the diagonal components of the covariance matrix , @xmath92 .",
    "it is evident from equation ( [ fish ] ) that more accurate data , characterized by smaller uncertainty @xmath93 , provide larger fisher matrix components , hence smaller parameter errors .",
    "it can also be noticed that for a given experiment the parameters which are better constrained are those for which the partial derivatives are larger .",
    "since these derivatives are computed at the fiducial model , it is natural to expect that the size of the projected errors varies for different fiducial parameter values .",
    "these contours are usually plotted with the aim of drawing a conclusion based on the true model having different parameter values from those of the fiducial model .",
    "but the dependence on the choice of fiducial model means that there is no guarantee that the conclusions based on contours around e.g.  the @xmath16cdm model can be used to rule that model out .     and @xmath94 confidence contours in @xmath48@xmath95 plane .",
    "the fiducial models are a @xmath16cdm with @xmath23 and @xmath96 ( solid line ) , a dark energy model with @xmath97 and @xmath98 ( dash - dot line ) , and a phantom model with @xmath99 and @xmath100 ( dash line).,width=302 ]    as an explicit example we compute the fisher matrix errors of dark energy parameters from sn - ia luminosity  distance measurements .",
    "we assume experimental characteristics from the proposed snap mission as discussed in kim et al .",
    "we consider two different dark energy models , one parametrized by a constant equation of state parameter @xmath95 , and a second by the two - parameter equation of state family of equation ( [ lp ] ) .",
    "we assume an independent measurement of @xmath48 with uncertainty @xmath101 to reduce parameter degeneracies , and compute the marginalized confidence contours around different fiducial models in @xmath48@xmath95 and @xmath19@xmath20 planes respectively .    in figure  [ fig1 ]",
    "we plot the @xmath61 and @xmath94 ellipses around three models : a @xmath16cdm model with @xmath23 and @xmath102 , a dark energy model with @xmath103 and @xmath104 , and a phantom model with @xmath105 and @xmath106 .",
    "the alignment of the strongest degeneracy line differs amongst the models .",
    "this is because the degeneracy in the @xmath107 plane is not a straight line , but rather a curve ( see for instance weller & albrecht 2001 ) .",
    "notice also that the ellipses around the fiducial models have different sizes .",
    "as fig .  [ fig1 ] shows , if the true model lies on say the 95% confidence limit of the @xmath16cdm data , one can not necessarily presume that the @xmath16cdm model would lie on the 95% confidence limit of data simulated for the true model .",
    "it is possible to compute a contour indicating the locus of the fiducial models for which @xmath16cdm lies at their 95% confidence limit , and indeed such a locus is shown in figure 1 of kratochvil et al .",
    "( 2004 ) , but constructing it is a rather cumbersome procedure .",
    "this drawback turns out to be less severe for dark energy models parametrized by equation  ( [ lp ] ) . in figure  [ fig2 ]",
    "we plot the @xmath61 and @xmath94 ellipses in the @xmath19@xmath20 plane with @xmath96 around a @xmath16cdm model , a phantom model with @xmath108 and @xmath109 lying along the degeneracy line of the @xmath16cdm , and a constant phantom model with @xmath110 and @xmath111 .",
    "the dependence on the fiducial model is still present , since the ellipses become larger as the fiducial model shifts orthogonal to the principal degeneracy direction towards more negative equation of state values .",
    "fiducial models along the same degeneracy line whose @xmath94 contours include the @xmath16cdm model are within the @xmath94 ellipse of the @xmath16cdm as well .     and @xmath94 contours in @xmath19@xmath20 plane .",
    "the fiducial models are @xmath16cdm ( solid line ) , a dark energy model with @xmath108 and @xmath109 ( dash - dot line ) , and a phantom model with @xmath110 and @xmath111 ( dash line ) .",
    "for all three models @xmath96.,width=294 ]"
  ],
  "abstract_text": [
    "<S> a key science goal of upcoming dark energy surveys is to seek time evolution of the dark energy . </S>",
    "<S> this problem is one of _ model selection _ , where the aim is to differentiate between cosmological models with different numbers of parameters . </S>",
    "<S> however , the power of these surveys is traditionally assessed by estimating their ability to constrain parameters , which is a different statistical problem . in this paper </S>",
    "<S> we use bayesian model selection techniques , specifically forecasting of the bayes factors , to compare the abilities of different proposed surveys in discovering dark energy evolution . </S>",
    "<S> we consider six experiments  supernova luminosity measurements by the supernova legacy survey , snap , jedi , and alpaca , and baryon acoustic oscillation measurements by wfmos and jedi  and use bayes factor plots to compare their statistical constraining power . </S>",
    "<S> the concept of bayes factor forecasting has much broader applicability than dark energy surveys .    </S>",
    "<S> cosmology : theory , cosmological parameters , methods : statistical </S>"
  ]
}