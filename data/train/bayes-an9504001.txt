{
  "article_text": [
    "let @xmath0 be an observation from a @xmath1 population with unknown parameters .",
    "the following statement belongs to the folklore of statistical science : .",
    "this is not correct .",
    "for example @xmath2 will cover @xmath3 at least 90% of the time and @xmath4 will cover @xmath5 at least 95% of the time . if you do nt believe it check it with your pc !",
    "i first heard about this some years ago from herbert robbins . according to robbins",
    ", this phenomenon was discovered by an electrical engineer in the 60 s ( robert machol _",
    "ieee trans .",
    "theor . _ , 1964 ) but it is still relatively unknown to statisticians .",
    "i show machol s idea below .",
    "the intervals for @xmath3 in the parametric case are due to him .",
    "the nonparametric improvement is due to robbins and the intervals on @xmath5 are mine .",
    "consider the following problem . given a single observation from a r.v .",
    "@xmath6 with @xmath7 a _ known _ density symmetric about zero .",
    "find a finite length @xmath8 ci for @xmath3 .",
    "+ * machol s answer * : consider the event @xmath9\\ ] ] where @xmath10 is an arbitrary constant and @xmath11 is given .",
    "we have @xmath12\\ ] ] where @xmath13 the event @xmath14 corresponds to the shaded piece in fig .",
    "1 . thus ,    fig .  1 .",
    "illustration of event a    @xmath15 = \\left| { \\int_{{\\alpha t}\\over{t+1 } } ^{{\\alpha t}\\over{t-1 } } f(y ) dy } \\right| = \\beta(\\alpha , t)\\ ] ] and @xmath16 therefore @xmath17 = p(a^c ) \\ge 1 - \\beta^*(t)\\ ] ] hence , provided that @xmath18 as @xmath19 the interval @xmath20 can be made to have any pre - specified confidence . + * example * : take @xmath21 .",
    "from the symmetry of @xmath22 about zero we can write @xmath23 thus , @xmath24 for @xmath25 we have , @xmath26 so that @xmath27\\ = { { t+1}\\over{t-1}}\\ ] ] and taking logs we obtain @xmath28 } = { 2 \\log\\left ( { { t+1}\\over{t-1}}\\right)}\\ ] ] from where @xmath29 and @xmath30 with a calculator and a normal table we find that for @xmath31 then @xmath32 and the confidence is 90% for @xmath33 .",
    "other intervals could be computed in a similar way .",
    "in fact this shows that @xmath34\\ > \\ .90\\ ] ] for all @xmath35 .",
    "the best @xmath36 is the one that produces the shortest expected length .",
    "but , _ length _ @xmath37 and @xmath38 so that the best @xmath39 should minimize @xmath40 i.e. @xmath41 must be the * median * of @xmath42 and since @xmath42 is symmetric about @xmath3 we have @xmath43 . hence , the best @xmath36 is our best a priori guess for @xmath3 .",
    "this looks like _ bayesianism _ sneaking in classical confidence intervals!.    the arbitrariness of @xmath36 in the statement `` @xmath44 is a @xmath45 ci for @xmath3 '' reminds me of the stein shrinking phenomenon .",
    "perhaps this is part of the reason why robbins got interested in it .",
    "recall that robbins empirical bayesianism produces stein s estimators as a special case .",
    "let @xmath46 be the class of all unimodal , symmetric about zero densities .",
    "given a single observation of @xmath42 with @xmath47 where both @xmath48 are * unknown * , find a @xmath49 ci for @xmath3 of finite length .",
    "+ * robbins answer * : consider first the following simple lemma : + * lemma * : if @xmath50 in @xmath51 then @xmath52 * proof * : this is obvious from the picture ( see fig .",
    "2 . ) , since @xmath53 denotes the mean value of @xmath7 on @xmath54 .    fig .  2 .",
    "the mean value of @xmath55 decreases when x approaches b    of course the algebra gives the same answer .",
    "notice that @xmath56 thus , differentiating both sides of the equation @xmath57 we obtain @xmath58}\\ \\le\\ 0\\ ] ] i.e. @xmath53 decreases in @xmath59    consider as before the event @xmath60}\\ { \\rm for}\\ t > 1\\ { \\rm and}\\   a\\epsilon\\bbbr.\\ ] ] then , if @xmath61 , we have @xmath62}\\ { \\rm with}\\ \\alpha =   a - \\mu\\ \\epsilon\\bbbr.\\ ] ] @xmath63 but now applying the lemma for @xmath64 and @xmath65 we obtain @xmath66 hence , @xmath67 therefore @xmath68\\ \\ge\\ { 1 - { 1\\over{1+t}}}\\ ] ] holds for all @xmath69 , and @xmath70 + * example * : for @xmath71 , we have @xmath72 , and @xmath73 will cover @xmath3 at least @xmath74 of the time even if we are uncertain about @xmath75 . this suggests the following game : each time you pick up a function @xmath7 in @xmath46 in any way you want i.e. deterministically or stochastically with some distribution .",
    "then you choose @xmath76 also in an arbitrary way i.e. each @xmath77 every time or following a pre - specified sequence , or generate them with a distribution changing the distribution each time etc ... then use the computer to show me @xmath78 .",
    "i win $ 1 if @xmath79 covers your @xmath77 and you win $ 5 if it does nt .",
    "do you want to play a couple of hundred times ?",
    "we consider now the estimation of the scale parameter from a single observation .",
    "it should be noticed that the only interesting confidence intervals are those of finite length .",
    "thus , @xmath80 is a @xmath81 confidence interval but useless .",
    "the natural , invariant under re - parameterizations , measure of length for a confidence interval @xmath82 for a scale parameter is not just @xmath83 but proportional to the difference in the logarithmic scale , i.e. @xmath84 .",
    "this follows by recalling the fact that the square of the element of length , on the hypothesis space of the location - scale model , along a line of constant scale is given by :    @xmath85 where @xmath86 is the fisher information amount at @xmath5 given by :    @xmath87 with    @xmath88 and @xmath89 in the notation of the proposition below .",
    "hence , the geodesic distance from the probability distribution with scale `` @xmath36 '' to the probability distribution with scale `` @xmath90 '' is obtained by integrating the element of length and therefore proportional to the difference in the log scale as noted above .",
    "the reader unfamiliar with the geometry of hypothesis spaces may use the expression of the kullback number between the gaussian with mean zero and standard deviation `` @xmath36 '' and the gaussian with mean zero and standard deviation `` @xmath90 '' as an approximation to the geodesic distance , to convince him / herself of the logarithmic nature of this length .",
    "it is therefore necessary to consider confidence intervals with non - zero lower bounds , since @xmath91 is in fact a line at infinity .",
    "i show below that it is possible to have finite length confidence intervals for the scale parameter from a single observation , but only if we rule out a priori from the hypothesis space a bit more than the line @xmath91 .",
    "it is this interplay between geometry , classical inference and bayesianism that i find appealing in this problem .",
    "* proposition * : let @xmath7 be a pdf symmetric about 0 and differentiable everywhere",
    ". let @xmath92 be the associated cdf .",
    "let @xmath93 with @xmath94 and define @xmath95 let @xmath96 be given numbers .",
    "then if @xmath97 we have @xmath98\\ \\ge\\ 2 [ f(t_2 ) - f(t_1)]\\ i[m\\le m^*]\\ + \\ ] ] @xmath99\\ \\inf_{0 <",
    "\\alpha < m }   \\bigl\\{g(\\alpha , t_1,t_2)\\bigr\\}.\\ ] ] where @xmath100 if @xmath101 ( or any other pdf with similar tails ) and excellent approximation is @xmath102 * proof * : consider the event @xmath103 } .\\ ] ] let @xmath104 then by adding and subtracting @xmath3 inside the absolute values and dividing through by @xmath5 we obtain @xmath105 } \\ ] ] where @xmath106 is such that @xmath107 .",
    "notice that the y s satisfying the inequalities that define the event @xmath14 correspond to the shaded region in fig .",
    "3 .    fig .",
    "illustration of event @xmath14    hence , @xmath108 notice that for given values @xmath109 and @xmath110 the function @xmath111 , as a function of @xmath112 is twice differentiable and symmetric about zero with a local minimum at @xmath113 . since , using the fact that @xmath114 we have @xmath115}\\right|_{\\alpha = 0}\\ } = { \\ 0}\\ ] ] and also @xmath116 @xmath117 thus , @xmath118\\ ] ] provided that @xmath119 i.e. if @xmath120 .",
    "the picture ( see fig .",
    "illustrates the situation .",
    "illustration of the event @xmath14    in the gaussian case , to obtain reasonable confidences we must have @xmath121 and @xmath122 . hence , @xmath123 and @xmath124 . from where",
    "@xmath125 \\ \\approx\\ g(0,t_1,t_2)\\ ] ] and the approximation for @xmath126 is obtained by solving the central identity for @xmath127 + * remarks * :    \\1 ) notice that the lower bound of the confidence interval , i.e. @xmath128 , is positive only if @xmath129 i.e. if we know a priori that @xmath130 .",
    "\\2 ) when @xmath131 then @xmath132 and with no prior knowledge ( i.e. @xmath133 ) we still have @xmath134    \\3 ) the value of @xmath110 is related to the amount of prior information .",
    "the larger @xmath110 the weaker the prior information necessary to assume the desire confidence . on the other hand",
    "@xmath109 controls the confidence associated to the interval .",
    "these remarks are illustrated with examples .",
    "+ * examples * : let @xmath0 be a single observation from a gaussian with unknown mean @xmath3 and unknown variance @xmath135 . then @xmath74 cis for @xmath5 are :    @xmath136 valid always    @xmath137 valid if @xmath138    @xmath139 valid if @xmath140    @xmath141 cis are :    @xmath142 valid if @xmath143    @xmath144 valid if @xmath145    @xmath146 valid always .",
    "@xmath147 cis are :    @xmath148 valid if @xmath138    @xmath149valid if @xmath150    @xmath151 valid always .",
    "i ll try to show that the required prior knowledge necessary to have non - zero lower bounds for the cis is in fact often available .",
    "suppose that we want to measure the length of the desk in my office with a regular meter graduated in centimeters .",
    "let @xmath0 be the result of a single measurement and let @xmath3 be the _ true _ length of my desk . then @xmath152 is a reasonable and very popular assumption .",
    "now , even before i make the measurement i can write with _ all _ confidence that for my desk @xmath153 i.e. @xmath154 . with",
    "the meter graduated in centimeters i will be guessing the middle line between centimeters so i can be sure that @xmath155 at least @xmath156 of a centimeter .",
    "thus , @xmath157 therefore i can be absolutely sure that @xmath158 hence , @xmath159 will be a @xmath147 ci for @xmath5 ."
  ],
  "abstract_text": [
    "<S> robert machol s surprising result , that from a single observation it is possible to have finite length confidence intervals for the parameters of location - scale models , is re - produced and extended . </S>",
    "<S> two previously unpublished modifications are included . </S>",
    "<S> first , herbert robbins nonparametric confidence interval is obtained . </S>",
    "<S> second , i introduce a technique for obtaining confidence intervals for the scale parameter of finite length in the logarithmic metric . </S>"
  ]
}