{
  "article_text": [
    "strongly correlated quantum systems on low - dimensional lattices continue to pose some of the most interesting challenges of modern quantum many - body physics . in condensed matter physics , correlation effects dominate in quantum spin chains and ladders , in frustrated magnets in one and two spatial dimensions , and in high - temperature superconductors , to name but a few physical systems of interest .",
    "more recently , the advent of highly controlled and tunable strongly interacting ultracold atom gases in optical lattices has added an entirely new direction to this field@xcite .",
    "both analytically and numerically , these systems are hard to study : only in very few cases exact analytical solutions , for example by the bethe ansatz in one dimension , are available@xcite",
    ". perturbation theory fails in the presence of strong interactions .",
    "other approaches , such as field theoretical approaches , have given deep insights , for example regarding the haldane gap physics of integer - spin antiferromagnetic chains@xcite , but make potentially severe approximations that must ultimately be controlled by numerical methods .",
    "such algorithms include exact diagonalization , quantum monte carlo , series expansions or coupled cluster methods .    since its invention in 1992 by steve white@xcite ,",
    "the density - matrix renormalization group ( dmrg ) has firmly established itself as the currently most powerful numerical method in the study of one - dimensional quantum lattices@xcite .",
    "after initial studies of the static properties ( energy , order parameters , @xmath0-point correlation functions ) of low - lying eigenstates , in particular ground states , of strongly correlated hamiltonians such as the heisenberg , @xmath1-@xmath2 and hubbard models , the method was extended to the study of dynamic properties of eigenstates , such as dynamical structure functions or frequency - dependent conductivities@xcite . at the same time , its extension to the analysis of two - dimensional classical @xcite and one - dimensional quantum @xcite transfer matrices has given access to highly precise finite - temperature information on classical two - dimensional and quantum one - dimensional systems ; more recently the transfer matrix variant of dmrg has also been extended to dynamics at finite temperature@xcite .",
    "it has even been extended to the numerically much more demanding study of non - hermitian ( pseudo- ) hamiltonians emerging in the analysis of the relaxation towards classical steady states in one - dimensional systems far from equilibrium@xcite .    in many applications of dmrg ,",
    "the accuracy of results is essentially limited only by machine precision , even for modest numerical resources used , quite independent of the detailed nature of the hamiltonian .",
    "it is therefore not surprising that , beyond the extension of the algorithm to more and more problem classes , people wondered about the physical origins of the excellent performance of dmrg and also whether the success story could be extended to the study of real - time dynamics or of two - dimensional systems .",
    "in fact , both questions are intimately related : as was realized quite soon , dmrg is only moderately successful when applied to two - dimensional lattices : while relatively small systems can be studied with high accuracy@xcite , the amount of numerical resources needed essentially increases exponentially with system size , making large lattices inaccessible .",
    "the totally different behaviour of dmrg in one and two dimensions is , as it turned out , closely related@xcite to the different scaling of quantum entanglement in many - body states in one and two dimensions , dictated by the so - called area laws ( for a recent review , see @xcite ) .    in this paper",
    ", i will stay within the framework of one - dimensional physics ; while the generalizations of dmrg to higher dimensions reduce naturally to dmrg in one dimension , the emerging structures are so much richer than in one dimension that they are beyond the scope of this work .    in an originally unrelated development , so - called _ matrix product states _",
    "( mps ) were discovered as an interesting class of quantum states for analytical studies .",
    "in fact , the structure is so simple but powerful that it is no surprise that they have been introduced and used under a variety of names over the last fifty or more years ( most notably perhaps by baxter @xcite ) . in the present context",
    ", the most relevant prehistory is arguably given by the exact expression of the seminal one - dimensional aklt state in this form@xcite , which gave rise to extensive studies of the translationally invariant subclass of mps known as finitely correlated states@xcite .",
    "this form was then subsequently used in a variety of contexts for analytical variational calculations , e.g.  for spin-1 heisenberg antiferromagnets@xcite and ferrimagnets@xcite .",
    "the connection between mps and dmrg was made in two steps .",
    "in a first step , ostlund and rommer @xcite realized that the block - growth step of the so - called infinite - system dmrg could be expressed as a matrix in the form it takes in an mps .",
    "as in homogeneous systems this block - growth step leads to a fixed point in the thermodynamic limit , they took the fixed point matrix as building block for a translationally invariant mps . in a further step",
    ", it was recognized that the more important finite - system dmrg leads to quantum states in mps form , over which it variationally optimizes@xcite .",
    "it was also recognized that in traditional dmrg the state class over which is variationally optimized changes as the algorithm progresses , such that if one demands in some sense `` perfect '' variational character , a small change to the algorithm is needed , which however was found to increase ( solvable ) metastability problems@xcite .",
    "it remains a curious historical fact that only a few of the dmrg practicioners took this development very seriously up to about 2004 when cirac , verstraete , vidal and coworkers started to explore the power of mps very systematically .",
    "while it was considered useful for conceptual purposes , surprisingly little thought was given to rethinking and reexpressing real - life dmrg implementations purely in the mps language ; arguably , because the overwhelming majority of conventional dmrg applications ( i.e.  ground states for quantum chains with open boundary conditions ) hardly profits .",
    "what was overlooked is that it easily opens up the way to powerful extensions to dmrg hard to see and express in conventional dmrg language .",
    "a non - exhaustive list of extensions would list real - time evolutions@xcite , also at finite temperature@xcite , the efficient use of periodic boundary conditions@xcite , reliable single - site dmrg@xcite , numerical renormalization group ( nrg ) applications@xcite , infinite - system algorithms@xcite , continuous systems@xcite , not talking at all about progress made in higher dimensions starting with @xcite using a generalization of the mps state class@xcite .",
    "the goal of this paper can not be to provide a full review of dmrg since 1992 as seen from the perspective of 2010 , in particular given the review@xcite , which tries to provide a fairly extensive account of dmrg as of summer 2004 .",
    "i rather want to limit myself to more recent developments and phrase them entirely in the language of matrix product states , focussing rather on the nuts and bolts of the methods than showing a lot of applications .",
    "my hope would be that this review would allow newcomers to the field to be able to produce their own codes quickly and get a firm grasp of the key building blocks of mps algorithms .",
    "it has overlaps with the introductions @xcite in the key methods presented , but focuses on different extensions , some of which arose after these papers , and in many places tries to be more explicit .",
    "it takes a different point of view than @xcite , the first comprehensive exposition of dmrg in 1998 , because at that time the connection to mps ( though known ) and in particular to quantum information was still in many ways unexploited , which is the focus here .",
    "nevertheless , in a first `` historical '' step , i want to remind readers of the original way of introducing dmrg , which does not make use of the idea of matrix product states .",
    "this should make older literature easily accessible , but one can jump to section [ sec : matrixproductstates ] right away , if one is not interested in that .    in a second step",
    ", i will show that any quantum state can be written exactly in a very specific form which is given by the matrix product states already alluded to .",
    "in fact , the restriction to one dimension will come from the fact that only in this case mps are numerically manageable .",
    "i will highlight special canonical forms of mps and establish their connection to the singular value decomposition ( svd ) as a mathematical tool and the schmidt decomposition as a compact representation of quantum states .",
    "after this i will explain how mps are a natural framework for decimation schemes in one dimension as they occur in schemes such as dmrg and wilson s nrg . as a simple , but non - trivial example",
    ", i will discuss the aklt state in its mps form explicitly .",
    "we then move on to discuss explicitly operations with mps : overlaps , normalization , operator matrix elements , expectation values and mps addition .",
    "these are operations one would do with any quantum state ; more mps - specific are methods for bringing them into the computationally convenient canonical forms and for approximating an mps by another one of smaller dimension .",
    "i conclude this exposition of mps with discussing the relationship and the conversions between the mps notation i favour here , an alternative notation due to vidal , and the dmrg way of writing states ; this relatively technical section should serve to make the literature more accessible to the reader .",
    "the mps ideas generalize from states to the representation of operators , so i move on to discuss the use of matrix product operators ( mpo)@xcite . as far as i can see , all operators of interest to us ( ranging from local operators through bond evolution operators to full hamiltonians ) find a very compact and transparent formulation in terms of mpo .",
    "this leads to a much cleaner and sometimes even numerically more accurate formulation of dmrg - related algorithms , but their usage is not yet very widely spread .    admittedly , at this point the patience of the reader may have been stretched quite a bit , as no real - world algorithm e.g.  for ground state searches or time evolutions has been formulated in mps language yet ; but it will become obvious that a lot of cumbersome numerical details of dmrg algorithms have been hidden away neatly in the mps and mpo structures .",
    "i will discuss ground state algorithms , discussing the equivalences and differences between dmrg with one or two center sites and fully mps - based algorithms , including improvements to avoid trapping .",
    "i will focus on finite systems with open boundary conditions , where these methods excel .    after this",
    ", i move on to time - dependent methods for dynamics , for pure and mixed states . after a discussion of the basic algorithms and their subtle differences ,",
    "i will focus on the key problem of extending the time - range of such simulations : the possibility to calculate highly accurate real - time and imaginary - time evolutions of complex quantum many - body states has been particularly exciting for many people , also because it arrived just in time for studying highly tunable ultracold atom systems .",
    "while this development has already led to numerous interesting insights and applications , it was quickly realized that the time - range of time - dependent dmrg and related methods is limited by entanglement growth in quantum states out of equilibrium , such that long - time physics is out of reach . in this context ,",
    "interesting progress in trying to go beyond has been achieved recently .",
    "the review concludes with two further axes of development .",
    "i will start out by discussing the connection between dmrg and wilson s nrg , showing how nrg can be expressed in a very concise fashion as well as be improved in various directions .",
    "this closes an interesting historical loop , as the utter failure of nrg for homogeneous one - dimensional quantum lattices as opposed to quantum impurity models mapped to special non - homogeneous one - dimensional quantum lattices was at the starting point of white s invention of dmrg@xcite .",
    "i continue by looking at infinite - size algorithms using mps that work directly in the thermodynamic limit , one based on time evolution ( itebd)@xcite . the other ( idmrg)@xcite is an extension of infinite - system dmrg algorithm , which has had an interesting history : in many early discussions of dmrg it was presented as the key aspect of dmrg , with finite - system dmrg as a practitioners add - on to further improve numerical accuracy .",
    "later , it was recognized that applying finite - system dmrg is essential even for qualitative correctness in many cases , and infinite - system dmrg was seen as just a warm - up procedure . only recently , mcculloch@xcite pointed out a way how to turn infinite - system dmrg into a highly efficient tool for producing thermodynamic limit states for homogeneous systems .",
    "last but not least , i will give an outlook on further applications of mps that i could not cover here .",
    "as a toy model , let us consider an ( anisotropic ) @xmath3 heisenberg antiferromagnetic ( @xmath4 ) spin chain of length @xmath5 in one spatial dimension with external magnetic field @xmath6 , @xmath7 we consider _ open boundary conditions _",
    "[ fig : toymodel ] ) , which is well worth emphasizing : analytically , periodic boundary conditions are usually more convenient ; many numerical methods do not really depend strongly on boundary conditions , and some , like exact diagonalization , even become more efficient for periodic boundary conditions .",
    "dmrg , on the other hand , prefers open boundary conditions .     with open ends , where a spin-@xmath8 sits on each site and interacts with its nearest neighbours.,scaledwidth=80.0% ]",
    "it should also be emphasized that , dmrg being a variational method in a certain state class , it does not suffer from anything like the fermionic sign problem , and can be applied to bosonic and fermionic systems alike .",
    "the starting point of dmrg is to ask for the ground state and ground state energy of @xmath9 .",
    "we can ask this question for the thermodynamic limit @xmath10 or more modestly for finite @xmath5 . in the first case ,",
    "the answer is provided by _",
    "infinite - system _ dmrg albeit with quite limited precision ; in the second case , an answer can be read off from infinite - system dmrg , but it is more adequate to run a two - step procedure , starting with infinite - system dmrg and continuing with _ finite - system _ dmrg .    in any case , the numerical stumbling block is provided by the exponential growth of the hilbert space dimension , in our example as @xmath11 , where @xmath12 is the local state space dimension of a spin-@xmath8 .",
    "infinite - system dmrg deals with this problem by considering a chain of increasing length , usually @xmath13 , @xmath14 , @xmath15 , @xmath16 , and discarding a sufficient number of states to keep hilbert space size manageable .",
    "this _ decimation procedure _ is key to the success of the algorithm : we assume that there exists a reduced state space which can describe the relevant physics and that we can develop a procedure to identify it .",
    "the first assumption is typical for all variational methods , and we will see that indeed we are lucky in one dimension : for all short - ranged hamiltonians in 1d there is such a reduced state space that contains the relevant physics !    how is it found ?",
    "in infinite - system dmrg ( fig .",
    "[ fig : dmrgcombined ] ) , the buildup is carried out as follows : we introduce left and right _ blocks _ a and b , which in a first step may consist of one spin ( or site ) each , such that total chain length is 2 .",
    "longer chains are now built iteratively from the left and right end , by inserting pairs of spins between the blocks , such that the chain grows to length 4 , 6 , and so on ; at each step , previous spins are absorbed into the left and right blocks , such that block sizes grow as 1 , 2 , 3 , and so on , leading to exponential growth of the dimension of the full block state space as @xmath17 , where @xmath18 is the current block size .",
    "our chains then always have a block - site - site - block structure , a@xmath19b .",
    "let us assume that our numerical resources are sufficient to deal with a reduced block state space of dimension @xmath20 , where in practice @xmath20 will be of @xmath21 to @xmath22 , and that for a block a of length @xmath18 we have an effective description of block a in a @xmath20-dimensional reduced hilbert space with orthonormal basis @xmath23 .",
    "for very small blocks , the basis dimension may be less than @xmath20 , for larger blocks some truncation must have occurred , which we take for granted at the moment .",
    "let me mention right now that in the literature , @xmath20  which will turn out to be a key number  comes under a variety of names : in traditional dmrg literature , it is usually referred to as @xmath24 ( or @xmath25 ) ; more recent matrix product state literature knows both @xmath20 and @xmath26 .    within this framework , we may now ask , ( i ) what is the ground state of the current chain of length @xmath27 , also referred to as _ superblock _ , and ( ii ) how can we find the reduced hilbert space of dimension @xmath20 for the new blocks a@xmath28 and @xmath28b .",
    "any state of the superblock a@xmath19b can be described by @xmath29 where the states of the site next to a are in the set @xmath30 of local state space dimension @xmath31 , and analogously those of the site next to b. by numerical diagonalization we find the @xmath32 that minimizes the energy @xmath33 with respect to the hamiltonian of the superblock , answering ( i ) . to this purpose , we need some iterative sparse matrix eigensolver such as provided by the lanczos or jacobi - davidson methods . given that our hamiltonian [ eq .",
    "( [ eq : basicham ] ) ] is available in the full tensor product space , this minimization of course assumes that it can be expressed readily in the superblock basis .",
    "let us postpone this question , as it is intimately related to growing blocks and decimating their state space . as the matrix dimension is @xmath34 , for typical @xmath20 the eigenproblem is too large for direct solution , even assuming the use of quantum symmetries .",
    "as most matrix elements of short - ranged hamiltonians are zero , the matrix is sparse , such that the basic matrix - vector multiplication of iterative sparse matrix eigensolvers can be implemented very efficiently .",
    "we will discuss this question also further below .",
    "if we now take states @xmath35 as the basis of the next larger left block a@xmath28 , the basis dimension grows to @xmath36 .",
    "to avoid exponential growth , we truncate this basis back to @xmath20 states , using the following procedure for block a@xmath28 and similarly for @xmath28b : we consider the _ reduced density operator _ for a@xmath28 , namely @xmath37 the eigensystem of @xmath38 is determined by exact diagonalization ; the choice is to retain as reduced basis those @xmath20 orthonormal eigenstates that have the largest associated eigenvalues @xmath39 .",
    "if we call them @xmath40 , the vector entries are simply the expansion coefficients in the previous block - site basis , @xmath41 .",
    "after an ( approximate ) transformation of all desired operators on a@xmath28 into the new basis , the system size can be increased again , until the final desired size is reached .",
    "b is grown at the same time , for reflection - symmetric systems by simple mirroring .",
    "the motivation of the truncation procedure is twofold .",
    "the first one , which is on a weaker basis , is that we are interested in the states of a@xmath28 contributing most to the ground state for a@xmath28 embedded in the final , much larger , even infinitely large system .",
    "we approximate this final system ground state , which we do nt know yet , to the best of our knowledge by that of a@xmath19b , the largest superblock we can efficiently form . in that sense , we are bootstrapping , and the finite - system dmrg will , as we will see , take care of the large approximations this possibly incurs .",
    "let me remark right now that in the mps formulation of infinite - system dmrg a much clearer picture will emerge .",
    "the second motivation for the choice of states is on much firmer foundation : the above prescription follows both from statistical physics arguments or from demanding that the 2-norm distance @xmath42 between the current ground state @xmath32 and its projection onto truncated block bases of dimension @xmath20 , @xmath43 , is minimal .",
    "the most transparent proof follows from a singular value decomposition of the matrix @xmath44 with matrix elements @xmath45 formed from the wave function coefficients @xmath46 .",
    "the overall success of dmrg rests on the observation that even for moderate @xmath20 ( often only a few 100 ) the total weight of the truncated eigenvalues , given by the _ truncation error _",
    "@xmath47 if we assume descending order of the @xmath48 , is extremely close to 0 , say @xmath49 or less .",
    "algorithmically , we may of course also fix a ( small ) @xmath50 we are willing to accept and at each truncation choose @xmath20 sufficiently large as to meet this requirement .",
    "computational resources are used more efficiently ( typically , we will have a somewhat smaller @xmath20 towards the ends of chains because of reduced quantum fluctuations ) , the programming effort to obtain this flexibility is of course somewhat higher .",
    "an important aspect of improving the performance of any quantum algorithm is the exploitation of quantum symmetries , ranging from discrete symmetries like a @xmath51 mirror symmetry if the hamiltonian is invariant under mirroring from left to right through abelian symmetries like the @xmath52 symmetry of particle number ( `` charge '' ) or magnetization conservation to non - abelian symmetries like the _",
    "su_(2 ) symmetry of rotational invariance@xcite . a huge range of these symmetries have been used successfully in numerous applications , with the most common ones being the two @xmath52 symmetries of charge and magnetization conservation , but also _",
    "su_(2 ) symmetries@xcite .",
    "let us focus on magnetization and assume that the total magnetization , @xmath53 , commutes with the hamiltonian , @xmath54=0 $ ] , such that eigenstates of @xmath9 can be chosen to be eigenstates of @xmath55 .",
    "let us assume in particular that the good quantum number of the ground state is @xmath56 .",
    "if the block and site states are eigenstates of magnetization , then @xmath57 only if @xmath58 ; @xmath25 is a short - hand for the magnetization of the respective blocks and sites , assuming that the states have magnetization as a good quantum number .",
    "this constraint allows to exclude a large number of coefficients from the calculation , leading to a huge speedup of the calculation and ( less important ) savings in memory .",
    "the decisive point is that if the states @xmath59 and @xmath60 are eigenstates of magnetization , so will be the eigenstates of the reduced density operator @xmath38 , which in turn will be the states @xmath59 of the enlarged block .",
    "as the local site states can be chosen to be such eigenstates and as the first block in the growth process consists of one local site , the eigenstate property then propagates through the entire algorithm . to prove the claim , we consider @xmath61 .",
    "the states @xmath62 and @xmath63 are eigenstates of magnetization by construction , hence @xmath64 or @xmath65 .",
    "the density matrix therefore decomposes into blocks that are formed from states of equal magnetization and can be diagonalized block by block within these sets , such that its eigenstates are also eigenstates of magnetization .    in practical implementations ,",
    "the use of such good quantum numbers will be done by arranging matrix representations of operators into block structures labelled by good quantum numbers , which are then combined to satisfy local and global constraints .",
    "while this is conceptually easy , the coding becomes more complex and will not be laid out here explicitly ; hints will be given in the mps sections .",
    "so far , we have postponed the question of expressing operators acting on blocks in the current block bases , in order to construct the hamiltonian and observables of interest .",
    "let us consider an operator @xmath66 acting on site @xmath18 , with matrix elements @xmath67 . without loss of generality ,",
    "assume that site @xmath18 is on the left - hand side and added into block a. its construction is then initialized when block a grows from @xmath68 , as @xmath69 here , @xmath70 and @xmath71 are the effective basis states of blocks of length @xmath18 and @xmath72 respectively . of course , updates are necessary during the further growth steps of block a , e.g.@xmath73 it is important to realize that the sum in eq .",
    "( [ eq : update ] ) must be split as @xmath74 reducing the calculational load from @xmath75 to @xmath76 .    in hamiltonians , operator products @xmath77",
    "it is tempting , but due to the many truncation steps highly imprecise , to insert the quantum mechanical one in the current block basis and to write @xmath78 the correct way is to update the first operator ( counting from the left for a left block a ) until the site of the second operator is reached , and to incorporate it as @xmath79 the further updates are then as for single operators .",
    "obviously , we are looking at a straightforward sequence of ( reduced ) basis transformations , with a somewhat cumbersome notation , but it will be interesting to see how much simpler these formulae will look in the mps language , albeit identical in content .",
    "the ultimate evaluation of expectation values is given at the end of the growth procedure as @xmath80 where suitable bracketing turns this into an operation of order @xmath81 .",
    "an important special case is given if we are looking for the expectation value of a local operator that acts on one of the free sites @xmath28 in the final block - site configuration . then @xmath82 which is an expression of order @xmath83 ( for many operators , even @xmath84 ) .",
    "given that @xmath85 in all practical applications , such evaluations are computationally highly advantageous .",
    "let me conclude these more technical remarks by observing that for an efficient construction of @xmath9 from such operators , it is essential _ never _ to build it as a full matrix , but to make use of the specific block - site - site - block structure .",
    "assume , for example , a term which contains one operator acting on a and one on b ( this is in fact the most complicated case ) , @xmath86 .",
    "then @xmath87 which is a sequence of two @xmath81 multiplications ( instead of one naive @xmath88 calculation ) for all coefficients @xmath89 and similarly for all other terms .",
    "if we stop infinite - system dmrg at some superblock size @xmath5 , we can interpret the final wavefunction in two ways .",
    "we can take it as an approximation to the exact state for the superblock of size @xmath5 and evaluate expectation values .",
    "the accuracy is limited not only by the truncations , but also by the fact that the first truncations were carried out for extremely small superblocks : the choice of relevant short block states is likely to be a not too good approximation to those one would have chosen for these short blocks embedded in the final system of length @xmath5 .    alternatively , we may ignore these boundary effects and focus on the central sites as an approximation to the behaviour of an infinitely large system , provided @xmath5 is large enough and careful extrapolations of results to @xmath10 are done .",
    "this is not so simple to do in a very controlled fashion , but as we will see , infinite - system dmrg can be used to build highly controlled translationally invariant ( modulo , say , a unit cell of length 2 ) thermodynamic limit states .",
    "once the desired final system size is reached by infinite - system dmrg , it is important in all but the most trivial applications to follow up on it by the so - called finite - system dmrg procedure",
    ". this will not merely lead to some slight quantitative improvements of our results , but may change them completely : consider @xcite for an example where even the central physical statement changes : for a @xmath1-@xmath2-@xmath90-@xmath91 model on a ladder with moderate hole - doping @xmath92 , an infinite - system dmrg calculation indicates the existence of alternately circulating currents on plaquettes that are triggered by an infinitesimal current at the left end of the ladder , a signal of a so - called @xmath31-density wave state . only after applying the finite - system algorithm",
    "it becomes obvious that this current is in fact exponentially decaying into the bulk , excluding this type of order ( fig .",
    "[ fig : plaquettecurrent ] ) .",
    "the finite - system algorithm corrects the choices made for reduced bases in the context of a superblock that was not the system of interest ( of final length @xmath5 ) , but some sort of smaller proxy for it .",
    "-@xmath2-@xmath90-@xmath91-ladder , @xmath93 , @xmath94 , @xmath95 ( @xmath90 nearest , @xmath91 next - nearest neighbour interaction ) at hole doping @xmath92 , system size @xmath96 , as induced by a finite boundary current on rung @xmath97 .",
    "the absolute current strength is shown ; whereas infinite - system dmrg and the first sweep indicate the generation of a long - ranged pattern , a fully converged calculation ( here after 6 to 7 sweeps ) reveals an exponential decay into the bulk .",
    "taken from ref .",
    "@xcite . ]",
    "what the finite - system algorithm does is the following ( figure [ fig : dmrgcombined ] ) : it continues the growth process of ( say ) block b following the same prescription as before : finding the ground state of the superblock system , determining the reduced density operator , finding the eigensystem , retaining the @xmath20 highest weight eigenstates for the next larger block .",
    "but it does so at the expense of block a , which shrinks ( i.e.  old shorter blocks a are reused ) .",
    "this is continued until a is so small as to have a complete hilbert space , i.e.  of dimension not exceeding @xmath20 ( one may also continue until a is merely one site long ; results are not affected ) . then the growth direction is reversed : a grows at the expense of b , including new ground state determinations and basis choices for a , until b is small enough to have a complete hilbert space , which leads to yet another reversal of growth direction .",
    "this _ sweeping _ through the system is continued until energy ( or , more precisely , the wave function ) converges .",
    "the intuitive motivation for this ( in practice highly successful ) procedure is that after each sweep , blocks a or b are determined in the presence of an ever improved embedding .    in practice",
    ", this algorithm involves a lot of book - keeping , as all the operators we need have to be maintained in the current effective bases which will change from step to step .",
    "this means that the truncated basis transformations determined have to be carried out after each step ; operator representations in all bases have to be stored , as they will be needed again for the shrinking block .",
    "another important feature is that for finding the ground state @xmath32 for each a@xmath19b configuration one employs some iterative large sparse matrix eigensolver based on sequential applications of @xmath9 on some initial starting vector . to speed up this most time - consuming part of the algorithm ,",
    "it is highly desirable to have a good prediction for a starting vector , i.e.  as close as possible to the ultimate solution .",
    "this can be achieved by ( approximately ) transforming the result of the last step into the shifted a@xmath19b configuration @xcite by applying two basis transformations : e.g.  a@xmath98a and b@xmath99b for a sweep to the right .",
    "the explicit formulae ( see @xcite ) can be derived by writing @xmath100 where @xmath101 and @xmath102 are the block states for block a comprising sites 1 through @xmath18 and block b comprising sites @xmath103 through @xmath5 ( the label of the block states is taken from the label of the bond their ends cut ; see fig .  [",
    "fig : labelling ] ) , and inserting twice an approximate identity , namely @xmath104 and @xmath105 .",
    "one then obtains @xmath106 with @xmath107 the basis transformations required in the last equation are all available from previous steps in the dmrg procedure .",
    "a similar operation can be carried out for a sweep to the left . as we will see",
    ", this astute step , which led to drastic improvements in dmrg performance , is already implicit if one rewrites dmrg in the mps language , such that we will not discuss it here at length .",
    "an important observation is that both the infinite - system and finite - system algorithm can also be carried out by inserting only a single explicit site @xmath28 , hence one would study superblocks of the form a@xmath28b , with slightly adapted growth procedures .",
    "an advantage of this method would be a speedup by roughly a factor @xmath31 in the large sparse eigensolver ; for example , the application of @xmath108 to a state in eq .",
    "( [ eq : hamfragment ] ) would then lead to @xmath109 operations . in the infinite - system algorithm",
    "an obvious disadvantage would be that superblock lengths oscillate between odd and even ; in the finite - system algorithm the question of the relative merits is much more interesting and will be discussed at length in section [ subsec : conventionaldmrginmps ] .    obviously , for @xmath110 , no truncations occur and dmrg becomes exact ; increasing @xmath20 reduces truncation and therefore monotonically improves observables , which one extrapolates in @xmath110 ( even better , in the truncation error @xmath111 , for which local observables often show effectively linear error dependence on @xmath50 ) for optimal results .    for more details on dmrg and its applications ,",
    "i refer to @xcite .",
    "the dmrg algorithm quite naturally leads to the consideration of bipartite quantum systems , where the parts are a@xmath28 and @xmath28b . for an arbitrary bipartition , @xmath112 , where the states @xmath62 and @xmath63 form orthonormal bases of dimensions @xmath113 and @xmath114 respectively .",
    "thinking of the @xmath115 as entries of a rectangular matrix @xmath44 ( dimension @xmath116 ) , the reduced density matrices @xmath117 and @xmath118 take the form @xmath119 if we assume that we know @xmath32 exactly , but can approximate it in dmrg only with at most @xmath20 states per block , the optimal dmrg approximation is provided by retaining as block states the eigenstates belonging to the @xmath20 largest eigenvalues .",
    "if we happen to know the eigenspectra of reduced density operators of @xmath32 , we can easily assess the quality a dmrg approximation can have ; it simply depends on how quickly the eigenvalues @xmath48 decrease .",
    "in fact , such analyses have been carried out for some exactly solved systems in one and two dimensions @xcite .",
    "they reveal that in one dimension for gapped systems eigenvalues @xmath48 generically decay exponentially fast ( roughly as @xmath120 ) , which explains the success of dmrg , but in two - dimensional stripe geometries of size @xmath121 , @xmath122 , @xmath123 , such that with increasing width @xmath124 ( increasing two - dimensionality ) the eigenspectrum decay is so slow as to make dmrg inefficient .",
    "usually , we have no clear idea about the eigenvalue spectrum ; but it turns out that in such cases entanglement entropies can serve as `` proxy '' quantities , namely the von neumann entanglement or entanglement entropy .",
    "it is given by the non - vanishing part of the eigenvalue spectrum of @xmath117 ( identical to that of @xmath118 , as we will discuss below ) as @xmath125 it would seem as if we have gained nothing , as we do nt know the @xmath48 , but general laws about entanglement scaling are available .",
    "if we consider a bipartitioning a@xmath126b where ab is in the thermodynamic limit and a of size @xmath127 , with @xmath128 the spatial dimension , the so - called _ area laws _ @xcite predict that for ground states of short - ranged hamiltonians with a gap to excitations entanglement entropy is not extensive , but proportional to the surface , i.e. @xmath129 , as opposed to thermal entropy .",
    "this implies @xmath130 cst . in one dimension and @xmath131 in two dimensions .",
    "at criticality , a much richer structure emerges : in one dimension , @xmath132 , where @xmath133 and @xmath134 are the ( an)holonomic central charges from conformal field theory@xcite ; in two dimensions , bosonic systems seem to be insensitive to criticality ( i.e. @xmath135)@xcite , whereas fermionic systems get a logarithmic correction @xmath136 for a one - dimensional fermi surface ( with a prefactor proportional to its size ) , but seem to grow only sublogarithmically if the fermi surface consists of points @xcite .",
    "it should be emphasized that these properties of ground states are highly unusual : in the thermodynamic limit , a random state out of hilbert space will indeed show extensive entanglement entropy with probability 1 .    in a mathematically non - rigorous way one can now make contact between dmrg and the area laws of quantum entanglement : between two @xmath20-dimensional state spaces for a and b ,",
    "the maximal entanglement is @xmath137 in the case where all eigenvalues of @xmath117 are identical and @xmath138 ( such that @xmath117 is maximally mixed ) ; meaning that one needs a state of dimension @xmath139 and more to encode entanglement @xmath140 properly .",
    "this implies that for gapped systems in one dimension an increase in system size will not lead to a strong increase in @xmath20 ; in two dimensions , @xmath141 , such that dmrg will fail even for relatively small system sizes , as resources have to grow exponentially ( this however does not exclude very precise results for small two - dimensional clusters or quite large stripes ) .",
    "critical systems in one dimension are borderline cases : @xmath142 ; this means that the thermodynamic limit is not reachable , but the growth of @xmath20 is sufficiently slow ( usually the power is weak , say @xmath143 or @xmath144 , due to typical values for central charges ) such that large system sizes ( @xmath145 ) can be reached ; this allows for very precise finite - size extrapolations .",
    "obviously , this argument implicitly makes the cavalier assumption that the eigenvalue spectrum is close to flat , which leads to maximal entanglement , such that an approximate estimation of @xmath20 can be made . in practice ,",
    "the spectrum is dictated by the problem and indeed far from flat : as we have seen , it is in fact usually exponentially decaying .",
    "but numerically , it turns out that for standard problems the scaling of the resource @xmath20 is predicted correctly on the qualitative level .",
    "it even turns out that in a mathematically strict analysis , von neumann entanglement does _ not _ allow a general prediction of resource usage : this is because one can construct artificial eigenvalue spectra that allow or forbid efficient simulation , while their von neumann entanglement would suggest the opposite , following the above argument @xcite .",
    "typical many - body states of interest , however , do not have such `` pathological '' spectra .",
    "in fact , renyi entanglement entropies , a generalization of von neumann entanglement entropies , do allow mathematically rigourous connections @xcite , but usually are hard to calculate , with criticality in one dimension as an exception due to conformal field theory .",
    "if we consider our paradigmatic problem , the one - dimensional heisenberg antiferromagnet , the key problem is that hilbert space seems to be exponentially big ( @xmath146 ) .",
    "looking for the ground state may therefore seem like looking for a needle in the haystack .",
    "the claim is that at least for local hamiltonians with a gap between ground state and first excited state , the haystack is not very big , effectively infinitesimally small compared to the size of the full hilbert space , as we have already seen from the very peculiar entanglement scaling properties .",
    "what is even more important , this relevant corner of hilbert space can be parametrized efficiently , i.e.  with modest numerical resources , operated upon efficiently , and efficient algorithms of the dmrg type to solve important questions of quantum physics do exist .",
    "this parametrization is provided by the _ matrix product states ( mps)_.    maybe the two dmrg algorithms explained above seem to be very cumbersome to implement .",
    "but it turns out that if we do quantum mechanics in the restricted state class provided by matrix product states , dmrg and other methods almost force themselves on us .",
    "the manipulation of matrix product states seems to be very complicated at first , but in fact can be formalized beautifully , together with a graphical notation that allows to generate permitted operations almost automatically ; as any good formalism ( such as bra and ket ) , it essentially enforces correctness .        throughout the rest of this paper , we will make extensive use of one of the most versatile tools of linear algebra , the so - called _ singular value decomposition _",
    "( svd ) , which is at the basis of a very compact representation of quantum states living in a bipartite universe ab , the _ schmidt decomposition_. let us briefly recall what they are about .",
    "svd guarantees for an arbitrary ( rectangular ) matrix @xmath25 of dimensions @xmath147 the existence of a decomposition @xmath148 where    * @xmath149 is of dimension @xmath150 and has orthonormal columns ( the _ left singular vectors _ ) , i.e. @xmath151 ; if @xmath152 this implies that it is unitary , and also @xmath153 .",
    "* @xmath140 is of dimension @xmath154 , diagonal with non - negative entries @xmath155 .",
    "these are the so - called _ singular values_. the number @xmath156 of non - zero singular values is the _ ( schmidt ) rank _ of @xmath25 . in the following ,",
    "we assume descending order : @xmath157 * @xmath158 is of dimension @xmath159 and has orthonormal rows ( the _ right singular vectors _ ) , i.e.  @xmath160 .",
    "if @xmath161 this implies that it is unitary , and also @xmath162 .",
    "this is schematically shown in fig .",
    "[ fig : svd ] .",
    "singular values and vectors have many highly interesting properties .",
    "one which is of practical importance in the following is the optimal approximation of @xmath25 ( rank @xmath156 ) by a matrix @xmath163 ( with rank @xmath164 ) in the frobenius norm @xmath165 induced by the inner product @xmath166 .",
    "it is given by @xmath167 i.e.  one sets all but the first @xmath168 singular values to be zero ( and in numerical practice , will shrink the column dimension of @xmath149 and the row dimension of @xmath158 accordingly to @xmath168 ) .",
    "@xmath140 is purely non - negative diagonal . ]    as a first application of the svd , we use it to derive the _",
    "schmidt decomposition _ of a general quantum state .",
    "any pure state @xmath32 on ab can be written as @xmath169 where @xmath35 and @xmath170 are orthonormal bases of a and b with dimension @xmath113 and @xmath114 respectively ; we read the coefficients as entries of a matrix @xmath44 . from this representation",
    "we can derive the reduced density operators @xmath171 and @xmath172 , which expressed with respect to the block bases take the matrix form @xmath173    if we carry out an svd of matrix @xmath44 in eq .",
    "( [ eq : generalquantumstate ] ) , we obtain @xmath174 due to the orthonormality properties of @xmath149 and @xmath158 , the sets @xmath175 and @xmath176 are orthonormal and can be extended to be orthonormal bases of a and b. if we restrict the sum to run only over the @xmath177 positive nonzero singular values , we obtain the _ schmidt decomposition _ @xmath178 it is obvious that @xmath179 corresponds to ( classical ) product states and @xmath180 to entangled ( quantum ) states .",
    "the schmidt decomposition allows to read off the reduced density operators for a and b introduced above very conveniently : carrying out the partial traces , one finds @xmath181 showing that they share the non - vanishing part of the spectrum , but not the eigenstates .",
    "the eigenvalues are the squares of the singular values , @xmath182 , the respective eigenvectors are the left and right singular vectors .",
    "the von neumann entropy of entanglement can therefore be read off directly from the svd , @xmath183    in view of the large size of hilbert spaces , it is also natural to approximate @xmath32 by some @xmath184 spanned over state spaces of a and b that have dimension @xmath168 only .",
    "this problem can be related to svd , because the 2-norm of @xmath32 is identical to the frobenius norm of the matrix @xmath44 , @xmath185 if and only if the sets @xmath186 and @xmath187 are orthonormal ( which is the case here ) . the optimal approximation is therefore given in the 2-norm by the optimal approximation of @xmath44 by @xmath188 in the frobenius norm , where @xmath188 is a matrix of rank @xmath168 . as discussed above , @xmath189 , where @xmath190 , constructed from the largest singular values of @xmath44 .",
    "therefore , the schmidt decomposition of the approximate state reads @xmath191 where the @xmath192 must be rescaled if normalization is desired .",
    "while svd will be seen to cover all our needs , sometimes it is an overkill : in many cases of the expression @xmath193 , we are only interested in the property @xmath151 and the product @xmath194 , for example whenever the actual value of the singular values will not be used explicitly .",
    "then there is a numerically cheaper technique , _ qr decomposition _ , which for an arbitrary matrix @xmath25 of dimension @xmath147 gives a decomposition @xmath195 hence the name , where @xmath196 is of dimension @xmath197 and unitary , @xmath198 , and @xmath199 is of dimension @xmath147 and upper triangular , i.e. @xmath200 if @xmath201 .",
    "full _ qr decomposition can be reduced to a _",
    "qr decomposition : assume @xmath202 : then the bottom @xmath203 rows of r are zero , and we can write @xmath204 = \\left [ \\begin{array}{cc } q_1 & q_2 \\end{array } \\right ] \\left [ \\begin{array}{c } r_1 \\\\ 0 \\end{array } \\right ] = q_1 r_1 , \\label{eq : thinqrdecomposition}\\ ] ] where @xmath205 is now of dimension @xmath147 , @xmath206 of dimension @xmath207 , and while @xmath208 , in general @xmath209 .",
    "whenever i will refer to a qr decomposition in the following , i will imply the thin one .",
    "it should also be clear that the matrices @xmath196 ( or @xmath205 ) share properties with @xmath149 from svd , but are not the same in general ; but as we will see that the mps representation of states is not unique anyways , this does not matter .      consider a lattice of @xmath5 sites with @xmath31-dimensional local state spaces @xmath210 on sites @xmath211 .",
    "in fact , while we will be naturally thinking of a one - dimensional lattice , the following also holds for a lattice of arbitrary dimension on which sites have been numbered ; however , mps generated from states on higher - dimensional lattices will not be manageable in numerical practice .",
    "the most general pure quantum state on the lattice reads @xmath212 where we have exponentially many coefficients @xmath213 with quite oblique content in typical quantum many - body problems .",
    "let us assume that it is normalized .",
    "can we find a notation that gives a more local notion of the state ( while preserving the quantum non - locality of the state ) ? indeed",
    ", svd allows us to do just that .",
    "the result may look quite forbidding , but will be shown to relate profoundly to familiar concepts of quantum physics .",
    "there are three ways of doing this that are of relevance to us .    _",
    "( i ) left - canonical matrix product state .",
    "_ in a first step , we _ reshape _ the state vector with @xmath11 components into a matrix @xmath44 of dimension @xmath214 , where the coefficients are related as @xmath215 an svd of @xmath44 gives @xmath216 where in the last equality @xmath140 and @xmath158 have been multiplied and the resulting matrix has been reshaped back into a vector .",
    "the rank is @xmath217 .",
    "we now decompose the matrix @xmath149 into a collection of @xmath31 row vectors @xmath218 with entries @xmath219 . at the same time",
    ", we reshape @xmath220 into a matrix @xmath221 of dimension @xmath222 , to give @xmath223 @xmath44 is subjected to an svd , and we have @xmath224 where we have replaced @xmath149 by a set of @xmath31 matrices @xmath225 of dimension @xmath226 with entries @xmath227 and multiplied @xmath140 and @xmath158 , to be reshaped into a matrix @xmath44 of dimension @xmath228 , where @xmath229 . upon further svds , we obtain @xmath230 or more compactly @xmath231 where we have recognized the sums over @xmath232 , @xmath233 and so forth as matrix multiplications . the last set of matrices @xmath234 in fact",
    "consists of column vectors .",
    "if we wish , dummy indices 1 may be introduced in the first and last @xmath235 to turn them into matrices , too . in any case , the ( arbitrary ) quantum state is now represented exactly in the form of a _ matrix product state : _",
    "@xmath236    let us study the properties of the @xmath235-matrices .",
    "the maximal dimensions of the matrices are reached when for each svd done the number of non - zero singular values is equal to the upper bound ( the lesser of the dimensions of the matrix to be decomposed ) .",
    "counting reveals that the dimensions may maximally be @xmath237 , going from the first to the last site ( i have assumed @xmath5 even for simplicity here ) .",
    "this shows that in practical calculations it will usually be impossible to carry out this exact decomposition explicitly , as the matrix dimensions blow up exponentially .",
    "but there is more to it .",
    "because at each svd @xmath151 holds , the replacement of @xmath149 by a set of @xmath238 entails the following relationship : @xmath239 or , more succinctly , @xmath240 matrices that obey this condition we will refer to as _ left - normalized _ , matrix product states that consist only of left - normalized matrices we will call _ left - canonical_. in fact , a closer look reveals that on the last site the condition may be technically violated , but as we will see once we calculate norms of mps this corresponds to the original state not being normalized to 1 .",
    "let us ignore this subtlety for the moment .    in view of the dmrg decomposition of the universe into blocks",
    "a and b it is instructive to split the lattice into parts a and b , where a comprises sites @xmath97 through @xmath18 and b sites @xmath241 through @xmath5 .",
    "we may then introduce states @xmath242 such that the mps can be written as @xmath243 this pairing of states looks tantalizingly close to a schmidt decomposition of @xmath32 , but this is not the case .",
    "the reason for this is that while the @xmath23 form an orthonormal set , the @xmath244 in general do not .",
    "this is an immediate consequence of the left - normality of the @xmath235-matrices . for part",
    "a we find @xmath245 where we have iteratively carried out the sums over @xmath246 through @xmath247 and used left - normality . on the other hand , the same calculation for part b yields @xmath248 which can not be simplified further because in general @xmath249 .",
    "the change of representation of the state coefficients can also be represented graphically ( fig .",
    "[ fig : mpsbysvd ] ) .",
    "let us represent the coefficient @xmath213 as a black box ( with rounded edges ) , where the physical indices @xmath246 through @xmath250 stick out vertically .",
    "the result after the first decomposition we represent as in the second line , where we have on the left hand site an object representing @xmath251 , on the right @xmath252 .",
    "the auxiliary degrees of freedom ( @xmath232 ) are represented by horizontal lines , and the rule is that _ connected lines are summed over . _",
    "the second step is then obvious , we have @xmath251 , then @xmath253 and on the right @xmath254 , with all connected lines summed over . in the end , we have arrived at @xmath5 @xmath235-matrices multiplied together and labelled by physical indices ( last line of the figure ) .",
    "the graphical rules for the @xmath235-matrices , that on the first and last site are row and column vectors respectively , are summarized in fig .",
    "[ fig : abulkedge ] : a site @xmath18 is represented by a solid circle , the physical index @xmath247 by a vertical line and the two matrix indices by horizontal lines .",
    "-matrices at the ends and in the bulk of chains : the left diagram represents @xmath255 , the row vector at the left end , the right diagram represents @xmath256 , the column vector at the right end . in the center",
    "there is @xmath257 . ]",
    "let me conclude this exposition by showing the generation of a left - canonical matrix product state by a sequence of qr decompositions .",
    "we start as @xmath258 where we reshape @xmath259 and @xmath260 in analogy to the svd procedure .",
    "the next qr decomposition yields @xmath261 and so on ( on the right half of the chain , thin qr is needed , as an analysis of the dimensions shows ) .",
    "@xmath262 implies the desired left - normalization of the @xmath235-matrices .",
    "if numerically feasible , this is faster than svd .",
    "what we lose is that we do not see the spectrum of the singular values ; unless we use more advanced rank - revealing qr decompositions , we are also not able to determine the ranks @xmath263 , unlike in svd .",
    "this means that this decomposition fully exploits the maximal @xmath235-matrix dimensions .    _",
    "( ii ) right - canonical matrix product state .",
    "_ obviously , there was nothing specific in the decomposition starting from the left , i.e.  site 1 .",
    "similarly , we can start from the right in order to obtain @xmath264    here , we have reshaped @xmath265 into @xmath31 column vectors @xmath266 , @xmath267 into @xmath31 matrices @xmath268 , and so on , as well as multiplied @xmath149 and @xmath140 before reshaping into @xmath44 at each step .",
    "the obvious graphical representation is given in fig .",
    "[ fig : rightmpsbysvd ] .",
    "we do not distinguish in the graphical representation between the @xmath235- and @xmath269-matrices to keep notation simple .",
    "we obtain an mps of the form @xmath270 where the @xmath269-matrices can be shown to have the same matrix dimension bounds as the @xmath235 matrices and also , from @xmath271 , to obey @xmath272 such that we refer to them as _ right - normalized _ matrices .",
    "an mps entirely built from such matrices we call _ right - canonical_.    again , we can split the lattice into parts a and b , sites 1 through @xmath18 and @xmath241 through @xmath5 , and introduce states @xmath273 such that the mps can be written as @xmath243 this pairing of states looks again tantalizingly close to a schmidt decomposition of @xmath32 , but this is again not the case .",
    "the reason for this is that while this time the @xmath244 form an orthonormal set , the @xmath23 in general do not , as can be shown from the right - normality of the @xmath269-matrices .",
    "again , the right - normalized form can be obtained by a sequence of qr decompositions .",
    "the difference to the left - normalized form is that we do not qr - decompose @xmath274 , but @xmath275 , such that @xmath276 .",
    "this leads directly to the right - normalization properties of the @xmath269-matrices , if we form them from @xmath277 .",
    "let me make the first two steps explicit ; we start from @xmath278 reshaping @xmath279 into @xmath44 , @xmath277 into @xmath269 , and continue by a qr decomposition of @xmath280 as @xmath281    we have now obtained various different exact representations of @xmath32 in the mps form , which already indicates that the mps representation of a state is _ not unique _ , a fact that we are going to exploit later on .    _",
    "( iii ) mixed - canonical matrix product state .",
    "_ we can also mix the decomposition of the state from the left and from the right .",
    "let us assume we did a decomposition from the left up to site @xmath18 , such that @xmath282 we reshape @xmath158 as @xmath283 and carry out successive svds from the right as in the original decomposition from the right , up to and including site @xmath284 ; in the last svd @xmath285 remains , which we reshape to @xmath286 .",
    "then we obtain @xmath287 all @xmath269-matrices are right - normalized .",
    "this is simply due to the svd for sites @xmath288 through @xmath5 ; on site @xmath241 , it follows from the property @xmath160 : @xmath289 where we use in the last line the right - normalization property of all the @xmath269-matrices on sites @xmath290 to obtain the desired result .",
    "we therefore end up with a decomposition @xmath291 which contains the singular values on the bond @xmath292 and can be graphically represented as in fig .  [",
    "fig : bothmpsbysvd ] .",
    "what is more , the schmidt decomposition into a and b , where a runs from sites 1 to @xmath18 and b from sites @xmath241 to @xmath5 , can now be read off immediately .",
    "if we introduce vectors @xmath293 then the state takes the form ( @xmath294 ) @xmath295 which is the schmidt decomposition _ provided the states on _ a _ and _ b _ are orthonormal respectively .",
    "_ but this is indeed the case by construction .",
    "\\(iv ) _ gauge degrees of freedom .",
    "_ by now , we have three different ways of writing an arbitrary quantum state as an mps , all of which present advantages and disadvantages . while these three are arguably the most important ways of writing an mps , it is important to realise that the degree of non - uniqueness is much higher : mps are not unique in the sense that a gauge degree of freedom exists .",
    "consider two adjacent sets of matrices @xmath296 and @xmath297 of shared column / row dimension @xmath20 .",
    "then the mps is invariant for any invertible matrix @xmath298 of dimension @xmath299 under @xmath300 this gauge degree of freedom can be used to simplify manipulations drastically , our three constructions are just special cases of that .",
    "several questions arise .",
    "is there a connection between this notation and more familiar concepts from many - body physics ?",
    "indeed , there is a profound connection to iterative decimation procedures as they occur in renormalization group schemes , which we will discuss in section [ subsubsec : mpssinglesitedecimation ] .",
    "the matrices can potentially be exponentially large and we will have to bound their size on a computer to some @xmath20 .",
    "is this possible without becoming too inaccurate in the description of the state ?",
    "indeed this is possible in one dimension : if we consider the mixed - canonical representation , we see that for the exponentially decaying eigenvalue spectra of reduced density operators ( hence exponentially decaying singular values @xmath192 ) it is possible to cut the spectrum following eq .",
    "( [ eq : schmidtapproximation ] ) at the @xmath20 largest singular values ( in the sense of an optimal approximation in the 2-norm ) without appreciable loss of precision .",
    "this argument can be generalized from the approximation incurred by a single truncation to that incurred by @xmath301 truncations , one at each bond , to reveal that the error is at worst @xcite @xmath302 where @xmath303 is the truncation error ( sum of discarded squared singular values ) at bond @xmath304 incurred by truncating down to the leading @xmath20 singular values .",
    "so the problem of approximability is as in dmrg related to the eigenvalue spectra of reduced density operators , indicating failure in two dimensions , and ( a bit more tenuously ) to the existence of area laws .      in order to connect mps to more conventional concepts ,",
    "let us imagine that we set up an iterative growth procedure for our spin chain , @xmath305 , as illustrated in fig .",
    "[ fig : blockgrowth ] , such that associated state spaces grow by a factor of @xmath31 at each step . in order to avoid exponential growth",
    ", we now demand that state space dimensions have a ceiling of @xmath20 .",
    "once the state space dimension grows above @xmath20 , the state space has to be truncated down by some _ as of now undefined _ procedure .",
    "assume that somehow we have arrived at such a @xmath20-dimensional effective basis for our system ( or left block a , in dmrg language ) of length @xmath72 , @xmath306 .",
    "if the @xmath20 basis states of the ( left ) block a of length @xmath18 after truncation are @xmath307 and the local states of the added site @xmath308 , we must have @xmath309 for these states , with @xmath310 as of now unspecified .",
    "we now introduce at site @xmath18 @xmath31 matrices @xmath311\\sigma_\\ell}$ ] of dimension @xmath312 each , one for each possible local state @xmath313 .",
    "we can then rewrite eq .",
    "( [ eq : basistrafoblocksite ] ) as @xmath314\\sigma_\\ell}_{a_{\\ell-1 } , a_\\ell } { \\mbox{$| a_{\\ell-1 }   \\rangle$}}_a   { \\mbox{$| \\sigma_\\ell   \\rangle$ } }   \\label{eq : matrixbyrg}\\ ] ] where the elements of the matrices @xmath311\\sigma_\\ell}$ ] are given by ( see fig .  [",
    "fig : abulk ] ) @xmath315\\sigma_\\ell}_{a_{\\ell-1 } , a_\\ell } \\equiv \\phantom\\langle_a { \\mbox{$\\langle a_{\\ell-1}\\sigma_\\ell   | a_\\ell \\rangle$}}_a .",
    "\\label{eq : amatrixelements}\\ ] ] let us make a short remark on _ notations _ right here : in @xmath311\\sigma_\\ell}$ ] , @xmath316 $ ] indicates which set of @xmath235-matrices is considered , and @xmath247 which @xmath235-matrix in particular . in the present case",
    ", this is a notational overkill , because the local state @xmath313 is taken from the site where the matrices were introduced . in such cases",
    ", we drop one of the two @xmath18 , usually @xmath316 $ ] : @xmath315\\sigma_\\ell } \\rightarrow a^{\\sigma_\\ell } .\\ ] ] we will , however , encounter situations where matrices @xmath235 are selected by local states _ not _ on the site where they were introduced . in such cases ,",
    "the full notation obviously has to be restored !",
    "similarly , we will shorten @xmath317 , when the fact that the state lives on block a is irrelevant or totally obvious .",
    "is grown towards the right to a block of length @xmath18 by adding a site @xmath18 . ]",
    "-matrices : the left diagram represents @xmath257 , the right diagram the _ conjugate _ @xmath318 .",
    "the solid circle represents the lattice sites , the vertical line the physical index , the horizontal lines the matrix indices . ]",
    "the advantage of the matrix notation , which contains the decimation procedure yet unspecified , is that it allows for a simple _ recursion _ from a block of length @xmath18 to the smallest , i.e.  vanishing block .",
    "quantum states obtained in this way take a very special form : @xmath319 where @xmath304 runs through all sites of block a. the index a indicates that we are considering states on the left side of the chain we are building . on the first site , we have , in order to keep in line with the matrix notation , introduced a dummy row index 1 : the states of block length 1 are built from the local states on site 1 and the block states of the `` block '' of length 0 , for which we introduce a dummy state and index 1 .",
    "this means that @xmath218 is in fact a ( row ) vector ( cf .",
    "[ fig : abulkedge ] ) .",
    "we also see that the left or row index of @xmath235 correspond to states `` left '' of those labelled by the right or column index .",
    "quite generally , we can show this construction as in fig .",
    "[ fig : blockbymps ] , if  as before ",
    "we introduce the rule that all connected legs are summed over ( contracted ) .",
    "the advantage of the matrix notation is that we can hide summations in matrix multiplications .     by contraction ( multiplication ) of @xmath235-matrices .",
    "contractions run over all connected legs . ]",
    "similarly , we can build blocks to grow towards the left instead of to the right ( fig .",
    "[ fig : blockgrowth_right ] ) : we have @xmath320 or @xmath321\\sigma_{\\ell+1}}_{a_\\ell , a_{\\ell+1 } }   { \\mbox{$| a_{\\ell+1 }   \\rangle$}}_b { \\mbox{$| \\sigma_{\\ell+1 }   \\rangle$}}\\ ] ] with @xmath322\\sigma_{\\ell+1}}_{a_\\ell , a_{\\ell+1 } } = \\phantom\\langle_b { \\mbox{$\\langle a_{\\ell+1 } \\sigma_{\\ell+1 }   | a_\\ell \\rangle$}}_b .\\ ] ] we call matrices @xmath269 to indicate that they emerge from a growth process towards the left , in dmrg language this would mean block b. recursion gives @xmath323 where @xmath304 runs from @xmath241 to @xmath5 , the sites of block b. a similar dummy index as for position 1 is introduced for position @xmath5 , where the @xmath269-matrix is a ( column ) vector .",
    "note a slight asymmetry in the notation compared to the @xmath235-matrices : in order to be able to match blocks a and b later , we label block states according to the bond at which they terminate : bond @xmath18 connects sites @xmath18 and @xmath241 , hence a labeling as in fig .  [",
    "fig : labelling ] .     is grown towards the left to a block b of length @xmath324 by adding site @xmath241 . ]    ) and b ( sites @xmath241 through @xmath5 ) are joined at bond @xmath18 .",
    "states are labelled @xmath325 and @xmath326 . ]",
    "if we introduce @xmath235-matrices and @xmath269-matrices in this way , they can be seen to have very special properties .",
    "if we consider the growth from the left , i.e.  @xmath235-matrices , and demand reasonably that the chosen states should for each block length be orthonormal to each other , we have using eq .",
    "( [ eq : matrixbyrg ] ) @xmath327 summarizing we find that the @xmath235-matrices are _ left - normalized _ : @xmath328 a graphical representation is provided in fig .  [ fig : leftnormalization ] : the multiplication can also be interpreted as the contraction of @xmath235 and @xmath329 over both @xmath330 and their left index .    similarly , we can derive for @xmath269-matrices of blocks b built from the right that the _ right - normalization _",
    "identity @xmath331 holds ( usually , @xmath235 and @xmath269 will be used to distinguish the two cases ) .",
    "see fig .",
    "[ fig : rightnormalization ] .",
    "this means that orthonormal states can always be decomposed into left- or right - normalized matrices in the mps sense and that all states constructed from left- or right - normalized matrices form orthonormal sets , provided the type of normalization and the direction of the growth match .",
    "-matrices are contracted over their _ left _ index and the physical indices , a @xmath332 line results . ]",
    "-matrices are contracted over their _",
    "right _ index and the physical indices , a @xmath332 line results . ]",
    "let us take a closer look at the matrix dimensions .",
    "growing from the left , matrix dimensions go as @xmath333 , @xmath334 , @xmath335 , @xmath336 , where i have assumed that @xmath337",
    ". then they continue at dimensions @xmath312 . at the right end",
    ", they will have dimensions @xmath312 ,",
    "@xmath338 , @xmath339 , @xmath340 and @xmath341 .",
    "we can now again write down a matrix product state .",
    "putting together a chain of length @xmath5 from a ( left ) block a of length @xmath18 ( sites @xmath97 to @xmath18 ) and a ( right ) block b of length @xmath324 ( sites @xmath241 to @xmath5 ) , we can form a general superposition @xmath342 inserting the states explicitly , we find @xmath343 the bold - faced @xmath344 stands for all local state indices , @xmath345 .",
    "the notation suggests to interpret @xmath44 as a matrix ; then the notation simplifies to @xmath346    if we allow general matrices and do nt worry about left , right or no normalization , we can simply multiply the @xmath44-matrix into one of the adjacent @xmath235 or @xmath269 matrices , such that the general mps for open boundary conditions appears ( see fig .",
    "[ fig : mps_obc ] ) : @xmath347 where _ no _ assumption about the normalization is implied ( which is why i call matrices @xmath25 ) . due to the vectorial nature of the first and last matrices the product results in a scalar .",
    "this is exactly the form of an mps already discussed in the last section .        at this point",
    "it is easy to see how a matrix product state can exploit good quantum numbers .",
    "let us focus on magnetization and assume that the global state has magnetization @xmath25 .",
    "this abelian quantum number is additive , @xmath348 .",
    "we choose local bases @xmath210 whose states are eigenstates of local magnetization .",
    "consider now the growth process from the left .",
    "if we choose the states @xmath349 to be eigenstates of local magnetization ( e.g.  by taking just the @xmath350 ) , then eq .  ( [ eq : basistrafoblocksite ] ) allows us to construct by induction states @xmath351 that are eigenstates of magnetization , provided the matrices @xmath352 obtain a block structure such that for each non - zero matrix element @xmath353 holds .",
    "this can be represented graphically easily by giving directions to the lines of the graphical representation ( fig .",
    "[ fig : mps_obc_quantumnumbers ] ) , with ingoing and outgoing arrows .",
    "the rule is then simply that the sum of the magnetizations on the ingoing lines equals that on the outgoing lines . in order to enforce some global magnetization @xmath25",
    ", we may simply give magnetization values 0 and @xmath25 to the ingoing and outgoing dummy bonds before the first and after the last site .",
    "we may envisage that the indices of the mps matrices are multiindices for a given magnetization allowing degeneracy , leading to elegant coding representation .",
    "an inversion of the bond arrows would directly tie in with the structure of @xmath269-matrices from the growth from the right , but proper book - keeping gives us lots of freedom for the arrows : an inversion means that the sign has to be reversed .    in order to use good quantum numbers in practice",
    ", they have to survive under the typical operations we carry out on matrix product states .",
    "it turns out that all operations that are not obviously unproblematic and maintain good quantum numbers can be expressed by svds .",
    "an svd will be applied to matrices like @xmath354 .",
    "if we group states @xmath355 and @xmath356 according to their good quantum number , @xmath235 will consist of blocks ; if we rearrange labels appropriately , we can write @xmath357 or @xmath358 where @xmath359 and so forth . but",
    "this means that the new states generated from @xmath355 via @xmath149 will also have good quantum numbers . when the need for truncation arises , this property of course still holds for the retained states .",
    "if we replace svd by qr where possible and carry it out on the individual blocks , @xmath360 , the unitary matrices @xmath361 transform within sets of states of the same quantum numbers , hence they remain good quantum numbers .",
    "let us now assume that our lattice obeys periodic boundary conditions .",
    "at the level of the state coefficients @xmath362 there is no notion of the boundary conditions , hence our standard form of an mps is capable to describe a state that reflects periodic boundary conditions . in that sense",
    "it is in fact wrong to say that eq .",
    "( [ eq : mpsobc ] ) holds only for open boundary conditions .",
    "it is true in the sense that the anomalous structure of the matrices on the first and last sites is not convenient for periodic boundary conditions ; indeed , the entanglement across the bond @xmath363 must be encoded as stretching through the entire chain .",
    "this leads to numerically very inefficient mps representations .    for periodic boundary conditions",
    "the natural generalization of the mps form is to make all matrices of equal dimensions @xmath312 ; as site @xmath5 connects back to site @xmath97 , we make the mps consistent with matrix multiplications on all bonds by taking the trace ( see fig .  [",
    "fig : mps_pbc ] ) : @xmath364 while _ a priori _ not more accurate than the other , it is much better suited and computationally far more efficient .        in this section",
    ", our emphasis has been on approximate representations of quantum states rather than on usually unachievable exact representations .",
    "while we have no prescription yet how to construct these approximate representations , some remarks are in order .",
    "even an approximate mps is still a linear combination of all states of the hilbert space , no product basis state has been discarded .",
    "the limiting constraint is rather on the form of the linear combinations : instead of @xmath11 coefficients , @xmath365 matrices of dimension @xmath299 with a matrix - valued normalization constraint that gives @xmath366 scalar constraints have @xmath367 independent parameters only , generating interdependencies of the coefficients of the state .",
    "the quality of the optimal approximation of any quantum state for given matrix dimensions will improve monotonically with @xmath20 : take @xmath368 , then the best approximation possible for @xmath20 can be written as an mps with @xmath369 with @xmath312 submatrices in the @xmath370 matrices and all additional rows and columns zero .",
    "they give further parameters for improvement of the state approximation .",
    "product states ( with schmidt rank 1 for any schmidt decomposition ) can be written exactly using @xmath371 mps .",
    "real quantum physics with entangled states starts at @xmath372 .",
    "given the exponential number of coefficients in a quantum state , it may be a surprise that even in this simplest non - trivial case interesting quantum physics can be done exactly !",
    "but there are important quantum states that find a compact exact expression in this new format .      in order to make the mps framework less abstract ,",
    "let us construct the mps representation of a non - trivial quantum state .",
    "one of the most interesting quantum states in correlation physics is the _ affleck - kennedy - lieb - tasaki state _ introduced in 1987 , which is the ground state of the aklt hamiltonian@xcite @xmath373 where we deal , exceptionally in this paper , with @xmath374 spins .",
    "it can be shown that the ground state of this hamiltonian can be constructed as shown in fig .",
    "[ fig : akltstate ] .",
    "each individual spin-1 is replaced by a pair of spin-@xmath8 which are completely symmetrized , i.e. of the four possible states we consider only the three triplet states naturally identified as @xmath374 states : @xmath375 on neighbouring sites , adjacent pairs of spin-@xmath8 are linked in a singlet state @xmath376    as it turns out , this state can be encoded by a matrix product state of the lowest non - trivial dimension @xmath372 and contains already lots of exciting physics @xcite . in the language of the auxiliary @xmath377 spin-@xmath8 states on a chain of length",
    "any state is given as @xmath379 with @xmath380 and @xmath381 representing the first and second spin-@xmath8 on each site .",
    "we now encode the singlet bond @xmath382 on bond @xmath304 connecting sites @xmath304 and @xmath383 as @xmath384 }   \\rangle$ } } = \\sum_{b_i a_{i+1 } } \\sigma_{ba } { \\mbox{$| b_i   \\rangle$}}{\\mbox{$| a_{i+1 }   \\rangle$}}\\ ] ] introducing a @xmath385 matrix @xmath386 @xmath387 .\\ ] ] then the state with singlets on all bonds reads @xmath388 for periodic boundary conditions . if we consider open boundary conditions , @xmath389 is omitted and the first and last spin-@xmath8 remain single .",
    "particles which are linked across sites by singlet states .",
    "the picture shows the case of pbc , for obc the `` long '' bond is cut , and two single spins-@xmath8 appear at the ends . ]    note that this state is a product state factorizing upon splitting any site @xmath304 into its two constituents .",
    "we now encode the identification of the symmetrized states of the auxiliary spins with the physical spin by introducing a _ mapping _ from the states of the two auxiliary spins-@xmath8 , @xmath390 to the states of the physical spin-1 , @xmath391 . to represent eq .",
    "( [ eq : tripletmapping ] ) , we introduce @xmath392 , with @xmath393 and @xmath394 representing the auxiliary spins and the physical spin on site @xmath304 .",
    "writing @xmath395 as three @xmath396 matrices , one for each value of @xmath394 , with rows and column indices standing for the values of @xmath397 and @xmath398 , we find @xmath399 \\quad      m^0 = \\left [ \\begin{array}{cc } 0 & \\frac{1}{\\sqrt{2 } } \\\\",
    "\\frac{1}{\\sqrt{2 } } & 0 \\end{array } \\right ] \\quad      m^- = \\left [ \\begin{array}{cc } 0 & 0 \\\\ 0 & 1 \\end{array } \\right ] .\\ ] ] the mapping on the spin-1 chain hilbert space @xmath400 then reads @xmath401 @xmath402 therefore is mapped to @xmath403 or @xmath404 ) { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$ } } , \\ ] ] using the matrix notation . to simplify further ,",
    "we introduce @xmath405 , such that @xmath406 \\quad      \\tilde{a}^0 = \\left [ \\begin{array}{cc } -\\frac{1}{2 } & 0 \\\\       0 & + \\frac{1}{2 } \\end{array } \\right ] \\quad      \\tilde{a}^- = \\left [ \\begin{array}{cc } 0 & 0 \\\\ -\\frac{1}{\\sqrt{2 } } & 0 \\end{array } \\right ] .",
    "\\label{eq : unnormalizeda}\\ ] ] the aklt state now takes the form",
    "@xmath407 let us left - normalize the @xmath408 .",
    "@xmath409 , which implies that the matrices @xmath410 should be rescaled by @xmath411 , such that we obtain normalized matrices @xmath235 , @xmath412 \\quad      a^0 = \\left [ \\begin{array}{cc } -\\frac{1}{\\sqrt{3 } } & 0 \\\\       0 & \\frac{1}{\\sqrt{3 } } \\end{array } \\right ] \\quad      a^- = \\left [ \\begin{array}{cc } 0 & 0 \\\\ -\\sqrt{\\frac{2}{3 } } & 0 \\end{array } \\right ] .",
    "\\label{eq : normalizeda}\\ ] ] this normalizes the state in the thermodynamic limit : we have @xmath413 in this expression , the @xmath414 are the 4 eigenvalues of @xmath415 , \\ ] ] namely @xmath416 . but then @xmath417 for @xmath10",
    ".    the methods of the next section can now be used to work out analytically the correlators of the aklt state : antiferromagnetic correlators are decaying exponentially , @xmath418 , whereas the string correlator @xmath419 for @xmath420 , indicating hidden order .    to summarize , it has been possible to express the aklt state as a @xmath372 matrix product state , the simplest non - trivial mps ! in fact , the projection from the larger state space of the auxiliary spins which are linked by maximally entangled states ( here : singlets ) onto the smaller physical state space can also be made the starting point for the introduction of mps and their higher - dimensional generalizations@xcite .",
    "let us now turn to operations with mps , beginning with the calculation of expectation values .",
    "expectation values are obviously special cases of general matrix elements , where states @xmath32 and @xmath421 are identical . staying in the general case , let us consider an overlap between states @xmath32 and @xmath421 , described by matrices @xmath25 and @xmath422 , and focus on open boundary conditions .",
    "taking the adjoint of @xmath421 , and considering that the wave function coefficients are scalars , the overlap reads @xmath423 transposing the scalar formed from the @xmath424 ( which is the identity operation ) , we arrive at adjoints with reversed ordering : @xmath425 in a pictorial representation ( fig .  [ fig : overlap ] ) , this calculation becomes much simpler , if we follow the rule that all bond indices are summed over .     and",
    "all contractions ( sums ) over same indices are indicated by arrows . ]      evaluating expression ( [ eq : finaloverlap ] ) in detail shows the importance of finding the _ right ( optimal ) order of contractions _ in matrix or more generally tensor networks .",
    "we have contractions over the matrix indices implicit in the matrix multiplications , and over the physical indices .",
    "if we decided to contract first the matrix indices and then the physical indices , we would have to sum over @xmath11 strings of matrix multiplications , which is exponentially expensive .",
    "but we may regroup the sums as follows : @xmath426 this means , in the ( special ) first step we multiply the column and row vectors @xmath427 and @xmath428 to form a matrix and sum over the ( first ) physical index . in the next step ,",
    "we contract a three - matrix multiplication over the second physical index , and so forth ( fig .  [",
    "fig : overlaporder ] ) .",
    "the important observation is that from the second step onwards the complexity does not grow anymore . also , it is of course most efficient to decompose matrix multiplications @xmath429 as @xmath430 or @xmath431 .",
    "then we are carrying out @xmath432 multiplications , each of which is of complexity @xmath433 , ignoring for simplicity that matrices are non - square in general at the moment .",
    "the decisive point is that we go from exponential to weak polynomial complexity , with total operation count @xmath434 .     and @xmath32 with indication of the optimal sequence of contractions , running like a zipper through the chain . ]    what is also immediately obvious ,",
    "is that for a norm calculation @xmath435 and obc having a state in left- or right - normalized form immediately implies that it has norm 1 . in the calculation above it",
    "can be seen that for left - normalized matrices @xmath235 , the innermost sum is just the left - normalization condition , yielding @xmath436 , so it drops out , and the next left - normalization condition shows up , until we are through the chain ( fig .",
    "[ fig : overlaplnormalized ] ) : @xmath437     by subsequent applications of the contraction rule for left - normalized @xmath235-matrices . ]    to calculate general matrix elements , we consider @xmath438 } \\hat{o}^{[j ] } \\ldots { \\mbox{$| \\psi   \\rangle$}}$ ] , tensored operators acting on sites @xmath304 and @xmath439 . the matrix elements of such operators are taken from @xmath440 } = \\sum_{\\sigma_\\ell,\\sigma'_\\ell } o^{\\sigma_\\ell,\\sigma'_\\ell } { \\mbox{$| \\sigma_\\ell   \\rangle$ } } { \\mbox{$\\langle \\sigma'_\\ell   |$ } } .\\ ] ] let us extend this to an operator on every site , which in practice will be the identity on almost all sites , e.g. for local expectation values or two - site correlators .",
    "we are therefore considering operator matrix elements @xmath441 . in the analytical expression , we again transpose and distribute the ( now double ) sum over local states ( matrix multiplications for the @xmath25-matrices are as before ) : @xmath442 this amounts to the same calculation as for the overlap , with the exception that formally the single sum over the physical index turns into a double sum ( fig .",
    "[ fig : matrixelement ] ) . for typical correlators",
    "the double sum will trivially reduce to a single sum on most sites , as for most sites only the identity acts , @xmath443}=\\hat{i}$ ] ; on the few non - trivial sites , of the up to @xmath444 matrix elements , most will be zero for conventional operators , strongly restricting the number of terms , so essentially the operational count is @xmath434 again .     and @xmath32 are calculated like the overlap , with the operators inserted at the right places , generating a double sum of physical indices there , as indicated by the arrows . ]    } { \\mbox{$| \\psi   \\rangle$}}$ ] for a state @xmath32 with left- and right - normalized matrices to the left and right of site @xmath18 . ]",
    "important simplifications for expectation values @xmath445 } { \\mbox{$| \\psi   \\rangle$}}$ ] are feasible and should be exploited whenever possible : assume that we look at a local operator @xmath446}$ ] and that normalizations are such that to the left of site @xmath18 all matrices are left - normalized and to the right of site @xmath18 all matrices are right - normalized ; the status of site @xmath18 itself is arbitrary",
    ". then left- and right - normalization can be used to contract the network as in fig .",
    "[ fig : overlaplnormalized ] without explicit calculation , such that just two matrices remain ( fig .",
    "[ fig : localoverlap ] ) .",
    "the remaining calculation is just @xmath447 } { \\mbox{$| \\psi   \\rangle$ } } = \\sum_{\\sigma_\\ell \\sigma'_\\ell } o^{\\sigma_\\ell \\sigma'_\\ell } { { \\rm tr } } ( m^{\\sigma_\\ell \\dagger } m^{\\sigma'_\\ell}),\\ ] ] an operation of order @xmath84 , saving one order of @xmath20 in calculation time . as we will encounter algorithms where the state is in such mixed - canonical representation",
    ", it makes sense to calculate observables `` on the sweep '' .",
    "this is just identical to expectation values on the explicit sites of dmrg .",
    "a frequently used notation for the calculation of overlaps , expectation values and matrix elements is provided by reading the hierarchy of brackets as an iterative update of a matrix , which eventually gives the scalar result .",
    "we now introduce matrices @xmath448}$ ] , where @xmath449}$ ] is a dummy matrix , being the scalar 1 .",
    "then an overlap @xmath450 can be carried out iteratively by running @xmath18 from 1 through @xmath5 : @xmath451 } = \\sum_{\\sigma_\\ell } \\tilde{m}^{\\sigma_{\\ell}\\dagger } c^{[\\ell-1 ] } m^{\\sigma_{\\ell } } , \\ ] ] where @xmath452}$ ] will be a scalar again , containing the result . for operators taken between the two states , the natural extension of this approach",
    "is @xmath451 } = \\sum_{\\sigma_\\ell,\\sigma'_\\ell } o^{\\sigma_\\ell,\\sigma'_\\ell } \\tilde{m}^{\\sigma_{\\ell}\\dagger } c^{[\\ell-1 ] } m^{\\sigma'_{\\ell } } .\\ ] ] again , the right order of evaluating the matrix products makes a huge difference in efficiency : @xmath451}_{a_\\ell , a'_\\ell } = \\sum_{\\sigma_\\ell , a_{\\ell-1 } }   \\tilde{m}^{\\sigma_{\\ell}*}_{a_{\\ell-1},a_\\ell } \\left ( \\sum_{\\sigma'_\\ell } o^{\\sigma_\\ell,\\sigma'_\\ell }   \\left ( \\sum_{a'_{\\ell-1 } } c^{[\\ell-1]}_{a_{\\ell-1},a'_{\\ell-1 } }   m^{\\sigma'_{\\ell}}_{a'_{\\ell-1},a'_\\ell } \\right ) \\right)\\ ] ] reduces an operation @xmath453 to @xmath454 .    of course",
    ", we can also proceed from the right end , introducing matrices @xmath455}$ ] , starting with @xmath456}=1 $ ] , a scalar . to this purpose",
    ", we exchange the order of scalars in @xmath450 , @xmath457 and transpose again the @xmath422-matrices , leading to a hierarchy of bracketed sums , with the sum over @xmath250 innermost .",
    "the iteration running from @xmath458 to @xmath459 then reads : @xmath460 } = \\sum_{\\sigma_\\ell }   m^{\\sigma_{\\ell } } d^{[\\ell ] } \\tilde{m}^{\\sigma_{\\ell}\\dagger } , \\ ] ] which can be extended to the calculation of matrix elements as @xmath460 } = \\sum_{\\sigma_\\ell,\\sigma'_\\ell }   o^{\\sigma_\\ell,\\sigma'_\\ell } m^{\\sigma'_{\\ell } } d^{[\\ell ] } \\tilde{m}^{\\sigma_{\\ell}\\dagger } .\\ ] ] @xmath461}$ ] then contains the result .",
    "this approach is very useful for book - keeping , because in dmrg we need operator matrix elements for left and right blocks , which is just the content of the @xmath462- and @xmath20-matrices for blocks a and b. as blocks grow iteratively , the above sequence of matrices will be conveniently generated along with block growth .",
    "let us formalize the iterative construction of @xmath448}$]-matrices of the last section a bit more , because it is useful for the understanding of the nature of correlations in mps to introduce a transfer ( super)operator @xmath463}$ ] , which is a mapping from operators defined on block a with length @xmath72 to operators defined on block a with length @xmath18 , @xmath464 and defined as @xmath465 } = \\sum_{a_{\\ell-1},a'_{\\ell-1 } } \\sum_{a_\\ell , a'_\\ell } \\left ( \\sum_{\\sigma_\\ell } m^{[\\ell]\\sigma_\\ell * } \\otimes m^{[\\ell]\\sigma_\\ell } \\right)_{(a_{\\ell-1}a'_{\\ell-1}),(a_\\ell , a'_\\ell ) } ( { \\mbox{$| a_{\\ell-1 }   \\rangle$ } } { \\mbox{$\\langle a'_{\\ell-1 }   |$ } } ) ( { \\mbox{$| a_{\\ell }   \\rangle$ } } { \\mbox{$\\langle a'_{\\ell }   |$}}),\\ ] ] where we read off the expression in brackets as the matrix elements of @xmath466}$ ] of dimension @xmath467 , the @xmath25-matrix dimensions at the respective bonds .",
    "it generalizes to the contraction with an interposed operator at site @xmath18 as @xmath468}_o = \\sum_{\\sigma_\\ell,\\sigma'_\\ell } o^{\\sigma_\\ell,\\sigma'_\\ell } m^{[\\ell]\\sigma_\\ell * } \\otimes m^{[\\ell]\\sigma'_\\ell } .\\ ] ] how does @xmath463 } $ ] act ? from the explicit notation @xmath468}_{(a_{\\ell-1}a'_{\\ell-1}),(a_{\\ell}a'_{\\ell } ) } = \\sum_{\\sigma_\\ell } m^{[\\ell]\\sigma_\\ell * } _ { a_{\\ell-1},a_\\ell } \\cdot m^{[\\ell]\\sigma_\\ell}_{a'_{\\ell-1},a'_\\ell}\\ ] ] we can read @xmath463 } [ \\hat{o}^{[\\ell-1]}]$ ] as an operation on a matrix @xmath469}_{a , a'}$ ] as @xmath468 } [ o^{[\\ell-1 ] } ]   = \\sum_{\\sigma_\\ell } m^{\\sigma_\\ell\\dagger } o^{[\\ell-1 ] } m^{\\sigma_\\ell}\\ ] ] or on a row vector of length @xmath470 with coefficients @xmath471}_{a , a'}$ ] multiplied from the left , @xmath472 the @xmath462-matrices of the last section are then related as @xmath451 } = e^{[\\ell ] } [ c^{[\\ell-1 ] } ]   , \\ ] ] but we will now take this result beyond numerical convenience : if @xmath473 , we can also ask for eigenvalues , eigenmatrices and ( left or right ) eigenvectors interchangeably . in this context",
    "we obtain the most important property of @xmath474 , namely that if it is constructed from left - normalized matrices @xmath235 or right - normalized matrices @xmath269 , all eigenvalues @xmath475 .",
    "in fact , for @xmath476 and left - normalized @xmath235-matrices , the associated left eigenvector @xmath477 , as can be seen by direct calculation or trivially if we translate it to the identity matrix : @xmath478 = \\sum_\\sigma a^{\\sigma\\dagger } \\cdot i \\cdot a^{\\sigma } = 1 \\cdot i .\\ ] ] the right eigenvector for @xmath474 constructed from left - normalized @xmath235 matrices is non - trivial , but we will ignore it for the moment . for right - normalized @xmath269 matrices , the situation is reversed : explicit calculation shows that @xmath477 is now right eigenvector with @xmath476 , and the left eigenvector is non - trivial .    to show that 1 is the largest eigenvalue@xcite , we consider @xmath479 $ ] .",
    "the idea is that then one can show that @xmath480 for the largest singular values of @xmath481 and @xmath462 , if @xmath474 is constructed from either left- or right - normalized matrices .",
    "this immediately implies that all eigenvalues of @xmath474 , @xmath482 : @xmath483 implies @xmath484 , such that @xmath485 would contradict the previous statement .",
    "the existence of several @xmath486 can not be excluded .",
    "the proof runs as follows ( here for left - normalized matrices ) : consider the svd @xmath487 .",
    "@xmath462 is square , hence @xmath488 .",
    "we can then write @xmath489 \\left [ \\begin{array}{ccc } s & & \\\\ & s & \\\\ & & s \\end{array } \\right ] \\left [ \\begin{array}{c } va^1 \\\\ \\vdots \\\\ va^d \\end{array } \\right ] = p^\\dagger \\left [ \\begin{array}{ccc } s & & \\\\ & s & \\\\ & & s \\end{array } \\right ] q .\\ ] ] we have @xmath490 and @xmath491 ( however @xmath492 , @xmath493 ) , if the @xmath238 are left - normalized : @xmath494 and similarly for @xmath196 ; they therefore are reduced basis transformations to orthonormal subspaces , hence the largest singular value of @xmath481 must be less or equal to that of @xmath140 , which is @xmath495 .",
    "independent of normalization , the overlap calculation becomes @xmath496 } e^{[2 ] } e^{[3 ] } \\ldots e^{[l-2 ] } e^{[l-1 ] } e^{[l ] }   , \\ ] ] and expectation value calculations before proper normalization by @xmath435 would read @xmath497 } \\hat{o}^{[2 ] } \\ldots \\hat{o}^{[l-1 ] } \\hat{o}^{[l]}{\\mbox{$| \\psi   \\rangle$ } } = e^{[1]}_{o_1 } e^{[2]}_{o_2 } e^{[3]}_{o_3 } \\ldots e^{[l-2]}_{o_{l-2 } } e^{[l-1]}_{o_{l-1 } } e^{[l]}_{o_l }   .\\ ] ] numerically , this notation naively taken is not very useful , as it implies @xmath498 operations ; of course , if its internal product structure is accounted for , we return to @xmath433 operations as previously discussed .",
    "but analytically , it reveals very interesting insights .",
    "let us assume a translationally invariant state with left - normalized site - independent @xmath235-matrices ( hence also site - independent @xmath474 ) with periodic boundary conditions .",
    "then we obtain in the limit @xmath10 @xmath499}\\hat{o}^{[j ] } { \\mbox{$| \\psi   \\rangle$ } } & = & { { \\rm tr } } e^{[1 ] } \\ldots e^{[i-1 ] } e^{[i]}_o e^{[i+1 ] } \\ldots e^{[j-1 ] }   e^{[j]}_o e^{[j+1 ] } \\ldots e^{[l ] } \\\\ & = & { { \\rm tr } } e^{[i]}_o e^{j - i-1 } e^{[j]}_o e^{l - j+i-1 } \\\\ & = & \\sum_{l , k } { \\mbox{$\\langle l   |$ } } e^{[i]}_o { \\mbox{$| k   \\rangle$ } } \\lambda_k^{j - i-1 } { \\mbox{$\\langle k   |$ } } e^{[j]}_o { \\mbox{$| l   \\rangle$ } } \\lambda_l^{l - j+i-1}\\\\ & = & \\sum_k { \\mbox{$\\langle 1   |$ } } e^{[i]}_o { \\mbox{$| k   \\rangle$ } } \\lambda_k^{j - i-1 } { \\mbox{$\\langle k   |$ } } e^{[j]}_o { \\mbox{$| 1   \\rangle$ } } \\quad ( l\\rightarrow\\infty)\\end{aligned}\\ ] ] where @xmath500 are the eigenvalues of @xmath474 . we have used @xmath501 for @xmath474 from normalized matrices and that @xmath476 is the only eigenvalue of modulus 1 ; but relaxing the latter ( not necessarily true ) assumption would only introduce a minor modification . @xmath502 and @xmath503 are the right and left eigenvectors of ( non - hermitian ) @xmath474 for eigenvalues @xmath500 .",
    "@xmath504 corresponds to the eigenoperator @xmath436 for @xmath474 from left - normalized @xmath235 .",
    "the decisive observation is that correlators can be long - ranged ( if the matrix elements @xmath505}_o { \\mbox{$| 1   \\rangle$}}$ ] are finite ) or are a superposition of exponentials with decay length @xmath506 , such that mps two - point correlators take the generic form @xmath507 } \\hat{o}^{[j ] } { \\mbox{$| \\psi   \\rangle$}}}{{\\mbox{$\\langle \\psi   | \\psi \\rangle$ } } } = c_1 + \\sum_{k=2}^{d^2 } c_k { { \\rm e } } ^{-r/\\xi_k } , \\ ] ] where @xmath508 and @xmath509}_o { \\mbox{$| k   \\rangle$ } } { \\mbox{$\\langle k   |$ } } e^{[j]}_o { \\mbox{$| 1   \\rangle$}}$ ] for @xmath510 .",
    "a simple example can be extracted from the aklt state of the previous section .",
    "the eigenvalues of @xmath474 were already found to be @xmath511 .",
    "for the spin - operators , the matrix elements for long - range order vanish , such that the correlation @xmath512 for @xmath513 , a purely exponential decay with correlation length @xmath514 . on the other hand , for the string correlator , the long - range matrix elements are finite , and long - range order emerges in the string correlator .",
    "the form of correlators of mps has important consequences : the usual form correlators take in one dimensional quantum systems in the thermodynamic limit is either the ornstein - zernike form @xmath515 or the critical power - law form ( maybe with logarithmic corrections ) , @xmath516 the aklt state belongs to a very special state class whose correlation functions mimic a quantum system in a lower spatial dimension ( so - called dimensional reduction ) , which removes the @xmath517-term ; the aklt state sits on a so - called disorder line , where such phenomena occur @xcite .",
    "any finite - dimensional mps therefore will only approximate the true correlator by a superposition of exponentials .",
    "it turns out that this works very well on short distances , even for power laws .",
    "what one observes numerically is that the true correlation function will be represented accurately on increasingly long length scales as @xmath20 is increased .",
    "eventually , the slowest exponential decay will survive , turning the correlation into a pure exponential decay with @xmath518 , where @xmath519 is the largest eigenvalue of @xmath474 that contributes to the correlator .",
    "the comparison of curves for various @xmath20 is therefore an excellent tool to gauge the convergence of correlation functions and the length scale on which it has been achieved .      as we have already seen for dmrg ,",
    "the concept of reduced density operators is of importance in various ways .",
    "let us express them using the mps notation .",
    "we have @xmath520 we now bipartition into ab , where a contains sites 1 through @xmath18 and b sites @xmath241 through @xmath5 .",
    "tracing out the degrees of freedom of b in the last expression we obtain @xmath521 } = { { \\rm tr } } _ b { \\mbox{$| \\psi   \\rangle$}}{\\mbox{$\\langle \\psi   |$ } } = \\sum_{{\\mbox{\\boldmath$\\sigma$\\unboldmath}},{\\mbox{\\boldmath$\\sigma$\\unboldmath}}'\\in a }   a^{\\sigma_1 } \\ldots a^{\\sigma_\\ell } \\rho_a^{[\\ell ] } a^{\\sigma'_\\ell\\dagger } \\ldots a^{\\sigma'_1\\dagger } { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$ } } { \\mbox{$\\langle { \\mbox{\\boldmath$\\sigma$\\unboldmath } } '   |$ } } , \\ ] ] where @xmath522 } =   \\sum_{{\\mbox{\\boldmath$\\sigma$\\unboldmath}}\\in b } a^{\\sigma_{\\ell+1 } } \\ldots a^{\\sigma_l } a^{\\sigma_l\\dagger } \\ldots a^{\\sigma_{\\ell+1}\\dagger } .\\ ] ] this equation immediately implies a recursion relation between different reduced density matrices , namely @xmath523 } = \\sum_{\\sigma_\\ell } a^{\\sigma_\\ell } \\rho_a^{[\\ell ] } a^{\\sigma_\\ell\\dagger } .",
    "\\label{eq : rhoarecursion}\\ ] ] in the thermodynamic limit @xmath10 , @xmath524 of a translationally invariant system , we may therefore ask whether a fixed point relationship @xmath525 is fulfilled .",
    "all these equations hold even if the matrices of the mps are not left - normalized . in the case that they are , we can directly express the density operator in the orthonormal basis generated by the @xmath235-matrices , namely @xmath521 } = \\sum_{a_\\ell , a'_\\ell } ( \\rho_a^{[\\ell]})_{a_\\ell , a'_\\ell } { \\mbox{$| a_\\ell   \\rangle$}}_a \\phantom{{}}_a{\\mbox{$\\langle a'_\\ell   |$ } } .\\ ] ]    similar relationships hold for the reduced density operator of b , where ( using @xmath269-matrices now ) we obtain @xmath526 } = { { \\rm tr } } _ a { \\mbox{$| \\psi   \\rangle$}}{\\mbox{$\\langle \\psi   |$ } } = \\sum_{{\\mbox{\\boldmath$\\sigma$\\unboldmath}},{\\mbox{\\boldmath$\\sigma$\\unboldmath}}'\\in b }   b^{\\sigma'_l\\dagger } \\ldots b^{\\sigma'_{\\ell+1}\\dagger } \\rho_b^{[\\ell ] } b^{\\sigma_{\\ell+1 } } \\ldots b^{\\sigma_l } { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$ } } { \\mbox{$\\langle { \\mbox{\\boldmath$\\sigma$\\unboldmath } } '   |$ } } , \\ ] ] where @xmath527 } =   \\sum_{{\\mbox{\\boldmath$\\sigma$\\unboldmath}}\\in a } b^{\\sigma_{\\ell}\\dagger } \\ldots b^{\\sigma_1\\dagger } b^{\\sigma_1 } \\ldots b^{\\sigma_{\\ell } } \\ ] ] and the recursion relationship @xmath527 } = \\sum_{\\sigma_\\ell } b^{\\sigma_\\ell\\dagger } \\rho_b^{[\\ell-1 ] } b^{\\sigma_\\ell } .",
    "\\label{eq : rhobrecursion}\\ ] ] giving rise to a potential fixed point relationship @xmath528 again , all these relationships would hold for arbitrary mps matrices , but if they are right - normalized , we again get an expression in an orthonormal basis , now generated by the @xmath269-matrices , @xmath526 } = \\sum_{a_\\ell , a'_\\ell } ( \\rho_b^{[\\ell]})_{a_\\ell , a'_\\ell } { \\mbox{$| a_\\ell   \\rangle$}}_b \\phantom{{}}_b{\\mbox{$\\langle a'_\\ell   |$ } } .\\ ] ] in the case of a mixed - canonical state @xmath529 a rerun of the calculation shows that @xmath530}_a = \\psi \\psi^\\dagger\\ ] ] and @xmath530}_b = \\psi^\\dagger\\psi , \\ ] ] expressed in an orthonormal basis .",
    "an operation that one needs comparatively rarely in practice is the addition of two mps .",
    "let us first consider the pbc case , which is easier .",
    "taking two mps , with no normalization assumed , @xmath531 we can write down @xmath532 where @xmath533 this means that we simply take @xmath25 and @xmath422 as diagonal blocks of a matrix @xmath534 .",
    "the diagonal block structure implies that upon multiplying the @xmath534 matrices the result is again diagonal , with @xmath535 in the first and @xmath536 in the second block",
    ". then the trace can be split , and we are back at the original states : @xmath537    in the case of obc , we can proceed in exactly the same fashion . on the first and last sites , something special has to happen :",
    "naively , the first and last dimensions would go up to 2 , and the scalar nature be lost .",
    "physically , these indices are dummies anyways .",
    "so what we have to do ( and a simple calculation shows that this works ) is to form a row vector @xmath538 $ ] and a column vector @xmath539^t$ ] on the last sites , from the row and column vectors of the original states .",
    "addition of mps therefore leads to new matrices with dimension @xmath540 , such that mps of a certain dimension are not closed under addition .",
    "it is also obvious that in many cases this way of describing a new state is uneconomical : the extreme case would be adding @xmath541 , where the resulting state is the same , just with a prefactor 2 , so matrix dimensions should not increase .",
    "so after additions it is worthwhile to consider _ compressing _ the mps again to some lower dimension , which depending on the states added may or may not ( like in the example ) incur a loss of information .      for a general matrix product state ,",
    "no particular demands are placed on the matrices @xmath296 except that their dimensions must match appropriately .",
    "certain classes of matrices are to be preferred , namely left- and right - normalized matrices , leading to left- and right - canonical mps : certain contractions become trivial , orthonormal reduced bases are generated automatically .    in order to bring an arbitrary mps to canonical form we exploit that svd generates either unitary matrices or matrices with orthonormal rows and columns which can be shown to obey the left- or right normalization condition .",
    "setting out from a general mps , without normalization assumption , making the contractions explicit , @xmath542 we reshape @xmath543 by grouping physical and left ( row ) index to carry out an svd on the new @xmath25 , yielding @xmath544 : @xmath545 as @xmath546 due to svd , after reshaping to @xmath218 , left - normalization holds for @xmath218 .",
    "the remaining two matrices of the svd are multiplied into @xmath547 , such that a new mps with @xmath548 is generated .",
    "now the procedure can be iterated : @xmath549 is reshaped to @xmath550 ( fig .",
    "[ fig : mreshaping ] ) , singular value decomposed as @xmath551 , generating @xmath552 , reshaped to a left - normalized @xmath553 .",
    "the right two matrices of the svd are again multiplied into the next ansatz matrix , and so forth .",
    "after the last step , left - normalized matrices @xmath554 live on all sites .",
    "@xmath555 , a scalar as @xmath234 is a column vector , survive at the last site , but this scalar is nothing but the norm of @xmath32 .",
    "we may keep it separately if we want to work with non - normalized states .",
    "this procedure extends trivially to normalization : we identify the prefactor of the state , but instead of storing it , we simply set it to 1 .",
    "as we do not use the singular values explicitly , the above procedure can be easily reformulated using qr decompositions , along the lines of section [ subsubsec : mpsdecomposition ] .",
    "standard qr , however , does not show us whether the matrices used are bigger than necessary , i.e. have singular values that are zero , such that matrices can be trimmed to a smaller size without loss of accuracy ; this would only be possible using rank revealing qr ; for many mps it is however clear from the underlying physics that the spectrum of singular values has a long tail , such that this issue does not arise .",
    "the same argumentation holds also for the generation of a right - canonical mps , which we turn to in the following .",
    "the same procedure can be applied to arrive at a state of right - normalized matrices , by carrying out a sequence of svds starting from the right on reshaped matrices @xmath556 , splitting @xmath269 into matrices @xmath557 that are right - normalized ( due to @xmath558 ) , and multiplying @xmath149 and @xmath140 to the left , creating the matrix to be singular value decomposed next :    @xmath559    proceeding as before , with the sole differences that ( i ) the direction is reversed and ( ii ) reshaping now groups the physical index with the column instead of the row index : @xmath560 .      the ( rare ) addition of mps and various algorithms that can be formulated with mps lead to a substantial increase in matrix dimensions of the result .",
    "it is therefore a recurrent issue how to approximate a given mps with matrix dimensions @xmath561 by another mps with matrix dimensions @xmath562 , where @xmath563 , as closely as possible .",
    "fundamentally , two procedures are available , _ svd compression _ and _ variational compression_. both have advantages and disadvantages : for small degrees of compression , @xmath564 , svd is fast , but it is never optimal ; it becomes very slow if @xmath565 .",
    "variational compression is optimal , but slow if the starting point is chosen randomly , can however be greatly speeded up by providing a good trial state e.g.  from the svd approach .",
    "generally , issues of getting stuck in a non - optimal compression may arise in the variational ansatz .",
    "depending on the specific nature of the state to be compressed , procedures can be optimized , for example if the mps to be compressed is a sum of mps or if it is the result of the application of a matrix product operator ( mpo ; sec .",
    "[ sec : mpo ] ) to an mps .",
    "let us consider an mps in mixed canonical representation ,",
    "@xmath566 } b^{\\sigma_{\\ell+1 } } \\ldots b^{\\sigma_{l-1 } } b^{\\sigma_l }   { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$ } } , \\label{eq : compressionstart}\\ ] ] from which we read off the schmidt decomposition @xmath567 , where the states on a and b form orthonormal sets respectively ; this follows from the canonical construction .",
    "let us suppose there are @xmath369 states each for this decomposition .",
    "we now look for the state @xmath184 that approximates @xmath32 best in the 2-norm and can be spanned by @xmath20 states each in a and b. we have shown that svd provides the result by retaining the @xmath20 largest singular values , and the compressed state simply reads @xmath568 , providing a simple truncation prescription : retain the first @xmath20 columns of @xmath569 , the first @xmath20 rows of @xmath570 , and the first @xmath20 rows and columns of @xmath571}$ ] .",
    "if normalization is desired , the retained singular values must be rescaled .",
    "this procedure rests on the orthonormality of the states on a and b , therefore can only be carried out at one bond . in order to shrink all matrices , we have to work our way through all mixed canonical representations , say from right to left , truncate , and shift the boundary between left- and right - normalized matrices by one site to the left , using techniques from canonization .",
    "after the first step of right - canonization of a left - canonical state , it reads : @xmath572 where i have already reshaped @xmath269 , which is right - normalized and guarantees that states formed as @xmath573 are orthonormal .",
    "but so are the states @xmath574 as svd guarantees @xmath575 : we are just doing a basis transformation within the orthonormal basis set constructed from the left - normalized @xmath576 . hence , we have a correct schmidt decomposition as @xmath577 the difference to a right canonization is now the truncation : matrices @xmath149 , @xmath140 and @xmath578 are truncated ( and singular values possibly renormalized ) to @xmath579 , @xmath580 and @xmath581 just as explained before : retain the @xmath20 largest singular values .",
    "@xmath581 is still right - normalized .",
    "the next @xmath582 to the left , @xmath579 and @xmath580 are multiplied together to form @xmath583 . by reshaping , svd and reshaping as @xmath584",
    "we obtain right - normalized @xmath585 , truncate @xmath149 , @xmath140 and @xmath585 to @xmath579 , @xmath580 and @xmath586 , and the procedure continues : @xmath587 at the end , the compressed mps @xmath184 is right - normalized and given by @xmath588-matrices .",
    "as we will see , this compression procedure is just the truncation that is carried out by ( time - dependent ) dmrg or tebd as they sweep through the chain .",
    "both methods at each bond have correctly normalized matrices ( i.e.  orthonormal states ) to the left and right , carry out the cut and proceed .",
    "the disadvantage of the procedure is that a one - sided interdependence of truncations occurs : the matrix @xmath25 always contains a truncated @xmath579 from the previous step , hence is truncation - dependent .",
    "generally , truncations can not be independent of each other because for each decomposition ( [ eq : compressionstart ] ) truncations of the @xmath235- and @xmath269-matrices affect the orthonormal systems , but here the dependence is one - sided and `` unbalanced '' : truncations further to the left depend on those to the right , but not vice versa . if the truncation is small  which it usually is for small time steps in time - dependent dmrg  the introduced additional inaccuracy is minor ; however , for cases where large truncations may occur , the dependence might become too strong and the truncation far from optimal .",
    "a second concern regards efficiency : for matrix dimensions @xmath589 , @xmath590 , the cost of svd is @xmath591 .",
    "this means that the svd cost @xmath592 if @xmath593 and @xmath594 otherwise ; the matrix multiplications cost @xmath595 . in many applications , @xmath596 ; then this method becomes quite slow .",
    "the situation is even worse if the original state is not in canonical form and has to be brought to that form first by a sequence of svds , that are of order @xmath597 .",
    "let me conclude this section with the remark that of course we can of course also compress by imposing some @xmath50 which at each truncation we accept as maximal 2-norm distance between the original and the compressed state ( given by the sum of the squares of the discarded singular values ) , implicitly defining @xmath20 .",
    "the optimal approach is to start from an ansatz mps of the desired reduced dimension , and to minimize its distance to the mps to be approximated iteratively , i.e.  by changing its @xmath598 matrices iteratively .",
    "the matrices play the role of variational parameters .",
    "the mathematically precise form of optimal compression of @xmath32 from dimension @xmath369 to @xmath184 with dimension @xmath20 is to minimize @xmath599 , which means that we want to minimize @xmath600 with respect to @xmath184 .",
    "let us call the matrices @xmath25 and @xmath422 respectively , to emphasize that we make no assumption about the normalization",
    ". expressed in the underlying matrices @xmath422 , this is a highly nonlinear optimization problem .    but this can be done iteratively as follows .",
    "start with an initial guess for @xmath184 , which could be an svd - compression of @xmath32 , arguably not optimal , but a good starting point .",
    "then we sweep through the set of @xmath601 site by site , keeping all other matrices fixed and choosing the new @xmath601 , such that distance is minimized .",
    "the ( usually justified hope ) is that repeating this sweep through the matrices several times will lead to a converged optimal approximation .",
    "the new @xmath601 is found by extremizing with respect to @xmath602 , which only shows up in @xmath603 .",
    "we find @xmath604 the sum over @xmath605 runs over all physical sites except @xmath304 .",
    "this system looks complicated , but is in fact quite easy . keeping the matrix to be found , @xmath601 , explicit",
    ", we may rewrite this equation as @xmath606 if , for each @xmath607 , we interpret the matrix @xmath601 as a vector @xmath608 of length @xmath609 , @xmath610 as a matrix @xmath611 of dimension @xmath612 and @xmath613 as a vector @xmath614 of length @xmath609 , we have a linear equation system @xmath615 the result @xmath608 can then taken to be the matrix we are looking for . as this system is usually too big for a direct solution",
    ", an iterative solver has to be used , such as a conjugate gradient method .",
    "the system is hermitian , as can be seen from the construction of @xmath611 : unconjugated and conjugated @xmath422 simply reverse their role under transposition .",
    "once again , the graphical representation is simplest ( fig .",
    "[ fig : iterativecompression ] ) .        as in the later case of finding ground states variationally ,",
    "it is important to realize that the cost of the matrix - vector multiplications in the conjugate gradient method is not @xmath616 as dimensions would naively suggest .",
    "there is an obvious factorization , which becomes particularly obvious graphically , that then leads to a cost of @xmath433 : @xmath617 where @xmath618 and similarly @xmath619 . in the graphical representation ( fig .",
    "[ fig : normalizediterativecompressionlr ] ) , they are simply the contracted objects to the left and right of the circled @xmath422-matrix we are solving for",
    ".    then @xmath620 two operations of cost @xmath433 .",
    "a similar decomposition simplifies the calculation of the vector @xmath614 , which is formed from @xmath621 as @xmath622 with @xmath5 and @xmath199 as indicated in fig .",
    "[ fig : normalizediterativecompression ] .",
    "in fact , calculating @xmath5 and @xmath199 is nothing but carrying out the first steps of an overlap calculation , starting from left or right",
    ". the result would then be the @xmath462 matrix produced there at intermediate steps .",
    "if one sweeps through the system from left to right and back one can build @xmath5 and @xmath199 iteratively from previous steps , which is the most efficient way .",
    "we can however _ drastically _ simplify the compression procedure if we exploit the canonical form !",
    "assume that @xmath184 is in mixed canonical form @xmath623 and we want to update @xmath601 : to the left of the matrix to be updated , everything is left - normalized , to the right everything is right - normalized and the form of @xmath601 does not matter , as it will be recalculated anyways .",
    "then @xmath624 because of left normalization , and similarly @xmath625 because of right normalization , hence @xmath626 . in the linear equation system",
    "this means that @xmath627 and we have trivially @xmath628 so there is no need to solve a large equation system ( fig .",
    "[ fig : normalizediterativecompression ] ) .         and @xmath619 for compression . ]    to make this work for an entire chain , we have to shift the boundary between the left and right normalized matrices as we move through the chain .",
    "assume we begin with all left - normalized matrices .",
    "then we move through the chain from right to left , start by solving on the last site for @xmath629 , right - normalize it via svd ( or , as we do not need the singular values , more cheaply by qr ) as before , to obtain @xmath630 where @xmath631 is in general without normalization .",
    "it is now optimized as @xmath632 where @xmath633 and similarly @xmath199 , the result is right - normalized , and so on as we go through the chain . at the end ,",
    "all matrices are right - normalized , and we restart from the left .    in order to assess convergence , we can monitor at each step @xmath634 , and observe the convergence of this value ; if necessary , @xmath20 has to be increased .",
    "the calculation may seem costly , but is nt . if we keep @xmath184 in proper mixed normalization , and use eq .",
    "( [ eq : compressionrhs ] ) to simplify the overlap @xmath635 , we find @xmath636 which is easy to calculate .",
    "the subtracted sum is just @xmath637 ; at the end , this allows us to normalize the state @xmath184 by simple rescaling .",
    "as already hinted at for single - site dmrg  and we will discuss this issue at length in sec .",
    "[ sec : groundstates ]  there is a danger that this variational ansatz gets stuck in a non - global minimum for the distance between the compressed and the original state . often ( but not always ) it is helpful to consider two sites at the same time , by analogy to two - site dmrg , for optimization .",
    "an operation count shows that this is somewhat slower .",
    "assume the compressed @xmath184 is in a mixed - canonical representation @xmath638 running through the same arguments as before , optimizing with respect to @xmath639 , yields an equation as in fig .",
    "[ fig : twositecompression ] for @xmath640 .",
    "the major change occurs now : we reshape the new @xmath641 as @xmath642 , carry out an svd to obtain @xmath643 where the @xmath422 is formed from reshaping @xmath644 .",
    "in fact , it is discarded because we shift one site towards the left , looking for @xmath645 .",
    "we can also use a cheaper qr decomposition of @xmath646 instead , to obtain @xmath269 from @xmath277 .",
    "let me conclude this section on compression by discussing the relative merits of the methods .",
    "if the compression is only small , the interdependency of the svd approach will not matter too much .",
    "still , the variational ansatz is superior ; its only weakness is that because of its iterative nature one has to provide an initial guess for the compressed state . taken randomly",
    ", the method will waste a lot of time on just getting into the right vicinity .",
    "therefore , the smart proposal is to take the svd - compressed state as the first input into the iterative method .",
    "how can we avoid the potentially high costs due to @xmath369 at least partially ?",
    "in practice , compressions occur mainly in two situations : ( i ) mps have been added , hence the matrix dimensions have been added ; ( ii ) a matrix product operator ( mpo ) has been applied to an mps ; we will see that this leads to the multiplication of the matrix dimensions of mps and mpo .    in the first case",
    ", the variational compression can be speeded up by using the fact that @xmath647 .",
    "then we may rewrite the variational equation as @xmath648 if we work out the equation",
    "( assuming mixed canonical representation ) , the right - hand side consists now of a sum of @xmath0 overlaps involving @xmath20-dimensional matrices , instead of one overlap involving @xmath20- and @xmath649-dimensional matrices ( costing up to @xmath650 and @xmath651 in the two types of matrix multiplications occurring in the overlap ) we now have @xmath0 overlaps costing @xmath433 . for large @xmath0 , the `` decomposed '' approach should be up to @xmath0 times faster .    the second case we postpone for details until we have discussed mpos .",
    "the idea is to carry out an svd compression , but without the particularly costly step of previously ensuring correct normalization ; if for some reason the block states are almost orthonormal nevertheless , the outcome should be quite reasonable ( and can be brought into canonical form , which is cheap after compression ) or can at least serve as a reasonable input for the variational method @xcite .",
    "so far , we have explored an mps notation based on one set of matrices per site ; special normalization properties for these matrices were exploited to arrive at mps with attractive additional features ( like the generation of orthonormal sets of states or the encoding of a schmidt decomposition ) .",
    "if we consider our lattice with sites @xmath97 through @xmath5 , it would be useful in view of the dmrg construction to be able to access easily all @xmath301 possible bipartitionings of the system ab that can be obtained with a single cut .",
    "such a notation has been introduced by vidal@xcite and takes the following form : @xmath652 }   \\gamma^{\\sigma_2 } \\lambda^{[2 ] }   \\gamma^{\\sigma_3 } \\lambda^{[3 ] } \\ldots   \\gamma^{\\sigma_{l-1 } } \\lambda^{[l-1 ] }   \\gamma^{\\sigma_l } { \\mbox{$| \\sigma_1,\\ldots,\\sigma_l   \\rangle$ } } , \\label{eq : canonicalform}\\ ] ] where we introduce on each site @xmath18 a set of @xmath31 matrices @xmath653 and on each bond @xmath18 one diagonal matrix @xmath571}$ ] .",
    "the matrices are specified by the demand that for arbitrary @xmath654 we can read off the schmidt decomposition @xmath655 where the schmidt coefficients are the diagonal elements of @xmath571}$ ] , @xmath656}_{a_\\ell , a_\\ell}$ ] and the states on a and b are given as @xmath657}\\gamma^{\\sigma_2 } \\ldots \\lambda^{[\\ell-1 ] } \\gamma^{\\sigma_\\ell})_{a_{\\ell } } { \\mbox{$| \\sigma_1,\\ldots,\\sigma_\\ell   \\rangle$ } } , \\\\ { \\mbox{$| a_\\ell   \\rangle$}}_b & = & \\sum_{\\sigma_{\\ell+1},\\ldots,\\sigma_l }   ( \\gamma^{\\sigma_{\\ell+1}}\\lambda^{[\\ell+1]}\\gamma^{\\sigma_{\\ell+2 } } \\ldots \\lambda^{[l-1 ] } \\gamma^{\\sigma_l})_{a_\\ell } { \\mbox{$| \\sigma_{\\ell+1},\\ldots,\\sigma_l   \\rangle$}},\\end{aligned}\\ ] ] where the states on a and on b are orthonormal respectively , reminding of similar constructions from @xmath235- and @xmath269-matrices .",
    "graphically , the new notation can be represented as in fig .",
    "[ fig : vidalmps ] .",
    "it is obviously a more explicit version of the @xmath235-matrix notation with the advantage of keeping explicit reference to the singular values , reduced density matrix eigenvalues and entanglement : cutting bond @xmath18 , the reduced density operators @xmath658 and @xmath659 read in eigenbasis representation @xmath522 } = \\rho_b^{[\\ell ] } = ( \\lambda^{[\\ell]})^2 , \\ ] ] more precisely ( but irrelevant for real and diagonal @xmath571}$ ] ) @xmath660 } = \\lambda^{[\\ell]}\\lambda^{[\\ell]\\dagger}$ ] and @xmath661 } = \\lambda^{[\\ell]\\dagger}\\lambda^{[\\ell]}$ ] , where the eigenstates of @xmath660}$ ] and @xmath661}$ ] are given by @xmath23 and @xmath244 respectively .",
    "the von neumann entropy of entanglement can be read off directly from @xmath571}$ ] as @xmath662})^2 \\log_2 ( \\lambda^{[\\ell]})^2 $ ] .    before exploring the connections to other notations ,",
    "let us first show that any quantum state can indeed be brought into that form by a procedure in close analogy to the one that decomposed @xmath32 into a product of @xmath235-matrices ( or @xmath269-matrices , for that matter ) . starting from coefficients @xmath362 , we reshape to @xmath663 , which is svded iteratively .",
    "we label the singular value matrices @xmath664}$ ] .",
    "after the first svd , we rename @xmath218 to @xmath665 . in the subsequent svds , as before we form the next matrix to be svded by multiplying @xmath666 and @xmath158 into @xmath44 , reshaping such that there is always one @xmath667- and one @xmath330-index for the rows . using the reshaping of @xmath668 already used , we obtain @xmath669}_{a_1,a_1 } ( v^\\dagger)_{a_1 , ( \\sigma_2 \\ldots \\sigma_l ) } } \\\\ & = & \\sum_{a_1 } \\gamma^{\\sigma_1}_{a_1 } \\psi_{(a_1\\sigma_2 ) , ( \\sigma_3 \\ldots \\sigma_l ) } \\\\ & = & \\sum_{a_1,a_2 } \\gamma^{\\sigma_1}_{a_1 } a^{\\sigma_2}_{a_1,a_2 } \\underbrace{\\lambda^{[2]}_{a_2,a_2 } ( v^\\dagger)_{a_2 , ( \\sigma_3 \\ldots \\sigma_l ) } } \\\\ & = & \\sum_{a_1,a_2 } \\gamma^{\\sigma_1}_{a_1 } \\overbrace{\\lambda^{[1]}_{a_1,a_1 } \\gamma^{\\sigma_2}_{a_1,a_2 } } \\psi_{(a_2\\sigma_3 ) , ( \\sigma_4 \\ldots \\sigma_l ) } \\\\ & = & \\sum_{a_1,a_2,a_3 } \\gamma^{\\sigma_1}_{a_1 } \\lambda^{[1]}_{a_1,a_1 } \\gamma^{\\sigma_2}_{a_1,a_2 } a^{\\sigma_3}_{a_2,a_3 }   \\underbrace{\\lambda^{[3]}_{a_3,a_3 } ( v^\\dagger)_{a_3 , ( \\sigma_4 \\ldots \\sigma_l ) } } \\\\   & = & \\sum_{a_1,a_2,a_3 } \\gamma^{\\sigma_1}_{a_1 } \\lambda^{[1]}_{a_1,a_1 } \\gamma^{\\sigma_2}_{a_1,a_2 } \\overbrace{\\lambda^{[2]}_{a_2,a_2 } \\gamma^{\\sigma_3}_{a_2,a_3 } }   \\psi_{(a_3\\sigma_4 ) , ( \\sigma_5 \\ldots \\sigma_l ) } \\end{aligned}\\ ] ] and so on . the crucial difference to the decomposition into @xmath235-matrices is that each @xmath235 is decomposed , using the knowledge of @xmath670}$ ] obtained in the previous step , into @xmath671}_{a_{\\ell-1},a_{\\ell-1 } } \\gamma^{\\sigma_\\ell}_{a_{\\ell-1},a_\\ell } , \\label{eq : agammalambda}\\ ] ] which implies a division by the diagonal elements of @xmath670}$ ] .",
    "if in our svd we keep only the non - zero singular values , this is a mathematically valid operation , albeit potentially fraught with numerical difficulty . ignoring this issue in this conceptual demonstration",
    ", we do arrive at a decomposition of the desired form ; in order to prove that it is indeed correct , we have to show that at each iteration we indeed obtain a schmidt decomposition .",
    "but this is easy to see : the matrices to the left of any @xmath571}$ ] can all be grouped into ( or rather , have been generated from ) left - normalized @xmath235-matrices , which generate a set of orthonormal states on the part of the lattice ranging from site 1 to @xmath18 .",
    "on the right hand side of any @xmath571}$ ] , there is a matrix @xmath158 with orthonormal rows , which means that the states @xmath672 are also orthonormal .",
    "hence , the svd giving @xmath571}$ ] indeed leads to a valid schmidt decomposition .    an alternative way of obtaining this notation would be to carry out a standard left - normalized decomposition , and store all singular value matrices generated ( and previously discarded ) as @xmath664}$ ] , and to insert afterwards the identities @xmath664}(\\lambda^{[i]})^{-1}$ ] between all neighbouring @xmath235-matrices @xmath576 and @xmath673 .",
    "then using eq .",
    "( [ eq : agammalambda ] ) leads to the same result .     sit on bonds , @xmath674 on sites . by construction , adjacent @xmath666 and @xmath674",
    "can be contracted to @xmath235 or @xmath269 matrices , that are either left- or right - normalized .",
    "the state can be trivially grouped into a string of @xmath235 ( giving orthonormal block states ) , a singular value matrix , and a string of @xmath269 ( giving orthonormal block states ) . ]    similarly , starting the decomposition from the right using the right - normalization of @xmath269-matrices the same state is obtained with a grouping @xmath675}_{a_\\ell , a_\\ell } , \\label{eq : bgammalambda}\\ ] ] where for notational simplification for this and for the corresponding equation for the @xmath235-matrix , eq .",
    "( [ eq : agammalambda ] ) , it is useful to introduce dummies @xmath676}$ ] and @xmath677}$ ] that are both scalar 1 .    the groupings for @xmath235 and @xmath269-matrices allow to reexpress the left- and right - normalization conditions in the @xmath678-language : the left - normalization condition reads @xmath679\\dagger } \\lambda^{[i-1 ] } \\gamma^{\\sigma_i}\\ ] ] or , more compactly , @xmath680 } \\gamma^{\\sigma_i } = i .",
    "\\label{eq : leftnormalizevidal}\\ ] ] the right - normalization condition reads @xmath681 } \\gamma^{\\sigma_i\\dagger } = i .",
    "\\label{eq : rightnormalizevidal}\\ ] ] interestingly , eqns .",
    "( [ eq : leftnormalizevidal ] ) and ( [ eq : rightnormalizevidal ] ) also arise if we translate the density operator recursions eqns .",
    "( [ eq : rhoarecursion ] ) and ( [ eq : rhobrecursion ] ) using eqns .",
    "( [ eq : agammalambda ] ) and ( [ eq : bgammalambda ] ) . a matrix product state in the form of eq .",
    "( [ eq : canonicalform ] ) which meets the constraints eq .",
    "( [ eq : leftnormalizevidal ] ) and eq .",
    "( [ eq : rightnormalizevidal ] ) is called _",
    "canonical_.    conversions between the @xmath682-notation , the @xmath678-notation and also the block - site notation of dmrg are possible , albeit fraught with some numerical pitfalls .",
    "_ conversion _ @xmath683 : the conversion from @xmath683 is easy .",
    "if one introduces an additional dummy scalar @xmath676 } = 1 $ ] as a `` matrix '' to the very left of @xmath32 , we can use the above defining eq .",
    "( [ eq : agammalambda ] ) to group @xmath684 } \\gamma^{\\sigma_1 } ) ( \\lambda^{[1 ] } \\gamma^{\\sigma_2})(\\lambda^{[2 ] } \\gamma^{\\sigma_3 } )   \\ldots \\rightarrow a^{\\sigma_1}a^{\\sigma_2}a^{\\sigma_3}\\ldots\\ ] ] or using eq .",
    "( [ eq : bgammalambda ] ) @xmath685 } ) ( \\gamma^{\\sigma_2}\\lambda^{[2 ] } ) ( \\gamma^{\\sigma_3}\\lambda^{[3 ] } )   \\ldots \\rightarrow b^{\\sigma_1}b^{\\sigma_2}b^{\\sigma_3}\\ldots\\ ] ]    in view of what dmrg and other mps methods actually do , it is interesting to consider _ mixed _ conversions . consider bond @xmath18 between sites @xmath18 and @xmath241 .",
    "we could contract @xmath686 starting from the left , giving left - normalized matrices , and @xmath687 from the right , giving right normalized matrices , leaving out just @xmath571}$ ] in the center ( fig .",
    "[ fig : dmrg0mps ] ) :    , @xmath269-matrix mps notation , and dmrg block notation .",
    "the @xmath235-matrices generate the left block states , the @xmath269 matrices generate the right block states .",
    "the matrix @xmath571}$ ] connects them via singular values . ]",
    "-matrix mps notation into dmrg block notation .",
    "the @xmath235-matrices generate the left block states , the @xmath269 matrices generate the right block states .",
    "the matrix elements of @xmath688 are just the coefficients of the dmrg state . ]",
    "@xmath684}\\gamma)(\\lambda^{[1]}\\gamma)\\ldots(\\lambda^{[\\ell-2]}\\gamma)(\\lambda^{[\\ell-1]}\\gamma ) \\lambda^{[\\ell ] } ( \\gamma\\lambda^{[\\ell+1]})(\\gamma\\lambda^{[\\ell+2 ] } ) \\ldots ( \\gamma\\lambda^{[l ] } ) .\\ ] ]    as the bracketing to the left of bond @xmath18 generates left - normalized @xmath235-matrices and right - normalized matrices @xmath269 on the right , we can multiply them out as done in the recursions of the previous section to arrive at orthonormal block bases for a and b , hence at a schmidt decomposition @xmath689 what is more , we can also take one site ( @xmath18 ) or two sites ( @xmath690 ) and multiply all matrices into one there ( fig .",
    "[ fig : dmrg1mps ] and fig .",
    "[ fig : dmrg2mps ] ) :    -matrix mps notation into dmrg block notation .",
    "the @xmath235-matrices generate the left block states , the @xmath269 matrices generate the right block states .",
    "the elements of matrix @xmath691 are just the coefficients of the dmrg state . ]",
    "@xmath684}\\gamma)(\\lambda^{[1]}\\gamma)\\ldots(\\lambda^{[\\ell-2]}\\gamma)(\\lambda^{[\\ell-1]}\\gamma \\lambda^{[\\ell ] } ) ( \\gamma\\lambda^{[\\ell+1]})(\\gamma\\lambda^{[\\ell+2 ] } ) \\ldots ( \\gamma\\lambda^{[l ] } ) .\\ ] ]    calling the central matrix @xmath692}\\gamma^{\\sigma_\\ell } \\lambda^{[\\ell]}$ ] , we can write @xmath693 or , again building block bases , @xmath694 if we group even two sites , we have @xmath684}\\gamma)(\\lambda^{[1]}\\gamma)\\ldots(\\lambda^{[\\ell-2]}\\gamma)(\\lambda^{[\\ell-1]}\\gamma \\lambda^{[\\ell ] } \\gamma\\lambda^{[\\ell+1]})(\\gamma\\lambda^{[\\ell+2 ] } ) \\ldots ( \\gamma\\lambda^{[l]})\\ ] ] or , with central matrix @xmath695}\\gamma^{\\sigma_\\ell } \\lambda^{[\\ell ] } \\gamma^{\\sigma_{\\ell+1}}\\lambda^{[\\ell+1]}$ ] , @xmath696 or , using block bases , @xmath697 these are just the states considered by `` single - site '' and the original `` two - site '' dmrg , which keep one or two sites explicit between two blocks .    _",
    "conversion _ @xmath698 : conversion in the other direction @xmath698 is more involved .",
    "the idea is to obtain iteratively the schmidt decompositions ( hence singular values ) of a state , hence the diagonal matrices @xmath571}$ ] , from which the @xmath699-matrices can be calculated .",
    "the procedure is in fact very similar to that used to show the existence of a canonical @xmath678 representation for an arbitrary quantum state .",
    "let us assume that @xmath32 is right - normalized , then state coefficients take the form @xmath700 .",
    "then we can proceed by a sequence of svds as @xmath701 } v^\\dagger ) b^{\\sigma_2}b^{\\sigma_3}b^{\\sigma_4 } \\ldots \\\\ & = & \\gamma^{\\sigma_1 } m^{\\sigma_2 } b^{\\sigma_3}b^{\\sigma_4 } \\ldots \\\\ & = & \\gamma^{\\sigma_1 } ( a^{\\sigma_2 }   \\lambda^{[2 ] } v^\\dagger ) b^{\\sigma_3}b^{\\sigma_4 } \\ldots \\\\ & = & \\gamma^{\\sigma_1 } \\lambda^{[1 ] } \\gamma^{\\sigma_2 } m^{\\sigma_3 } b^{\\sigma_4 } \\ldots \\\\\\end{aligned}\\ ] ] and so forth . here , the to - be - svded matrices @xmath702 } v^\\dagger b^{\\sigma_\\ell}$ ] .",
    "the @xmath653-matrices are obtained from the @xmath703-matrices by remembering @xmath670}$ ] and using eq .",
    "( [ eq : agammalambda ] ) , which implies a division by singular values .",
    "the division by singular values is a numerical headache as they can and will often be very small , in particular if a high - precision calculation is attempted and even very small singular values will be carried along .",
    "it is numerically advisable to proceed as in the calculation of the ( pseudo)inverse of an almost singular matrix and set all @xmath704 , with , say , @xmath705 , to 0 and exclude them from all sums ( e.g.  in a schmidt decomposition ) .",
    "as we order @xmath192 by size , this implies shrinking matrices @xmath149 and @xmath158 accordingly .",
    "these small singular values carry little weight in the reduced density operators ( their square ) , hence the loss of accuracy in the state description is very small compared to the numerical pitfalls .",
    "in fact , the problem is that at various places in algorithms we implicitly rely on ( ortho)normality assumptions that may no longer hold after a `` wild '' division .",
    "let me conclude this long section by summarizing the various conversion and canonization procedures in a diagram ( fig .",
    "[ fig : conversions ] ) , where it should however be kept in mind that some conversions are only possible in theory , not in numerical practice .",
    "is the explicit representation by the exponentially large number of state coefficients ; @xmath235 , @xmath269 and @xmath678 stand for left - canonical , right - canonical and canonical mps ; @xmath25 stands for an arbitrary mps .",
    "solid lines indicate computationally feasible conversions , dashed lines more hypothetical ones . ]",
    "if we consider a single coefficient @xmath706 of an mps , @xmath707 it is a natural generalization to try to write coefficients @xmath708 of operators as @xcite @xmath709 where the @xmath710 are matrices just like the @xmath711 , with the only difference that as representations of operators they need both outgoing and ingoing physical states : @xmath712 with the same extension to periodic boundary conditions as for mps . the pictorial representation introduced for mps can be extended in a straightforward fashion : instead of one vertical line for the physical state in the representation of @xmath25 , we now have two vertical lines , one down , one up , for the ingoing and outgoing physical state in @xmath124 ( fig .  [",
    "fig : singlempo ] ) .",
    "the complete mpo itself then looks as in figure [ fig : mpo ] .",
    "if we want to use good quantum numbers , the methods for mps translate directly : we introduce an ingoing local state quantum number from the top , an outgoing one towards the bottom , and an ingoing quantum number from the left and an outgoing one to the right .",
    "the rule is , as for mps , that the total sum of ingoing and outgoing quantum numbers must be equal , or @xmath713 , where i have interpreted the bond labels as states for the notation . we may also think about dummy indices before the first and after the last site as in an mps , which reflect in which ( definite ! ) way the operator changes the total quantum number . for a hamiltonian , which commutes with the corresponding operator ,",
    "the change is zero , and we can ignore the dummies .",
    "the mpos we are going to build can all be shown to have good quantum numbers on the bonds , because they originate either from svds ( e.g. for time evolutions ) or from rules that involve operators with well - defined changes of quantum numbers ( e.g. for mpos for hamiltonians ) .",
    "in fact , _ any _ operator can be brought into the form of eq .",
    "( [ eq : mpoform ] ) , because it can be written as @xmath714 and we can decompose it like we did for an mps , with the double index @xmath715 taking the role of the index @xmath607 in an mps .",
    "\\sigma_1\\sigma'_1}_{1,b_1}$ ] at the left end of the chain ; ( ii ) a bulk matrix operator @xmath716\\sigma_\\ell\\sigma'_\\ell}_{b_{\\ell-1},b_{\\ell}}$ ] ; ( iii ) a corner operator @xmath717\\sigma_l\\sigma'_l}_{b_{l-1},1}$ ] at the right end : the physical indices points up and down , the matrix indices are represented by horizontal lines . ]        as for mps , we have to ask how we operate with them and how they can be constructed in practice , because the naive decomposition might be exponentially complex .",
    "as it turns out , most operations run in perfect analogy to the mps case .",
    "the application of a matrix product operator to a matrix product state runs as @xmath718    the beauty of an mpo is that it leaves the form of the mps invariant , at the prize of an increase in matrix size : the new mps dimension is the product of that of the original mps and that of the mpo ( fig .",
    "[ fig : mpotimesmps ] ) .",
    "the result can be summarized as @xmath719 with @xmath421 an mps built from matrices @xmath720 with @xmath721 if we use ( additive ) good quantum numbers , one can show from the sum rules at each tensor that they are additive on the in- and outgoing horizontal bonds .",
    "once again , a seemingly exponentially complex operation ( sum over exponentially many @xmath344 ) is reduced to a low - cost operation : the operational count is of order @xmath722 , @xmath723 being the dimension of the mpo .",
    "operations with mpos follow very much the lines of mps . if we consider the addition of two operators , @xmath66 and @xmath724 , that have mpo representations @xmath725 and @xmath726 , then the resulting mpo is formed exactly as in the case of mps , by the direct sum @xmath727 for all sites @xmath728 , with the same special rules for sites @xmath97 and @xmath5 .",
    "in essence ,",
    "we ( again ) just have to consider @xmath607 and @xmath729 as one `` big '' physical index .",
    "the multiplication of ( or rather , subsequent operation with ) two operators , @xmath730 , can also be understood easily : the application of @xmath66 to some state @xmath32 leads to a new mps with matrices @xmath731 .",
    "then the subsequent operation of @xmath724 gives a new mps with @xmath732 .",
    "but from this we can read off right away ( and this is also obvious from the graphical representation of a sequence of two mpos applied to a state ) that the new mpo ( with matrices @xmath733 ) is given by @xmath734 hence , mpo dimensions simply multiply as for tensors .",
    "if we consider an mps as an mpo with dummy indices in one physical direction , the rule for applying an mpo to an mps follow as a special case .      as for mps , the question of compressing an mpo may arise .",
    "this should be obvious from the last section , where mpo dimensions summed up or multiplied .",
    "if it is no option to shift the issue of compression to the application of an mpo to an mps ( then of dimension @xmath735 and a natural candidate for compression ) , we have to compress the mpo .",
    "a typical example would be given by the representation of a longer - ranged hamiltonian in mpo form , which quickly leads to large dimensions .",
    "but we can apply the same techniques as for compressing mps , both by svd and iteratively , in order to approximate the exact mpo by one with smaller @xmath723 .",
    "the only change is that instead of one physical index @xmath330 , we have now two physical indices @xmath736 , which we may take as one single index @xmath737 .",
    "the approximation is then done in the frobenius norm , which naturally extends the 2-norm of vectors we used for mps approximations .    at this point",
    "it is worthwhile mentioning that it has been proposed @xcite that in the special case of compressing an mpo - mps product , an important speedup over the standard methods may be achieved : svd may be very slow if normalization has to be carried out first at a cost @xmath738 , but a good starting point for the variational method would be essential to have .",
    "but the proposed solution from svd compression may not be bad if the block states are almost orthonormal and it seems that in the mpo - mps product case this is essentially true if both the mpo and the mps were in canonical form ( for the mpo again formed by looking at the double index as one big index ) , which can be achieved at much lower cost ( @xmath739 and @xmath740 , where @xmath741 usually , versus @xmath742 ) .",
    "even if the proposed compression is not too good , it will still present a much better starting point for the variational compression .",
    "so the procedure would be : ( i ) bring both mpo and mps in the same canonical form ; ( ii ) do svd compression , of course only multiplying out mpo and mps matrices on the fly ; ( iii ) use this as variational input if you do nt trust the result too much .",
    "assume we want to find the ground state of some hamiltonian @xmath9 . in order to find the optimal approximation to it , we have to find the mps @xmath32 of some dimension @xmath20 that minimizes @xmath743 the most efficient way of doing this ( in particular compared to an imaginary time evolution starting from some random state , which is also possible ) is a variational search in the mps space . in order to make this algorithm transparent ,",
    "let us first express @xmath9 as an mpo .",
    "due to the product structure inherent in the mpo representation , it might seem a hopeless task  despite its guaranteed existence  to explicitly construct a compact mpo representation for a hamiltonian such as @xmath744 this common notation is of course an abbreviation for sums of tensor products of operators : @xmath745 it is however surprisingly easy to express this sum of tensor products in mpo form @xcite  to this purpose it is convenient to reconsider the building block @xmath746 combined with its associated projector @xmath747 to become an operator - valued matrix @xmath748 such that the mpo takes the simple form @xmath749}\\hat{w}^{[2 ] } \\ldots \\hat{w}^{[l ] } .\\ ] ] each @xmath750}$ ] acts on a different local hilbert space at site @xmath304 , whose tensor product gives the global hilbert space .",
    "multiplying such operator - valued matrices yields sums of tensor products of operators such that expressing @xmath9 in a compact form seems feasible .    to understand the construction ,",
    "we move through an arbitrary operator string appearing in @xmath9 : starting from the right end , the string contains unit operators , until at one point we encounter one of ( in our example ) 4 non - trivial operators . for the field operator ,",
    "the string part further to the left may only contain unit operators ; for the interaction operators , the complementary operator must follow immediately to complete the interaction term , to be continued by unit operators further to the left . for book - keeping ,",
    "we introduce 5 corresponding states of the string at some given bond : state 1 : only units to the right , states 2,3,4 : one @xmath751 , @xmath752 , @xmath753 just to the right , state 5 : completed interaction or field term @xmath754 somewhere to the right . comparing the state of a string left and right of one site ,",
    "only a few transitions are allowed : @xmath755 by the unit operator @xmath756 , @xmath757 by @xmath751 , @xmath758 by @xmath752 , @xmath759 by @xmath753 , @xmath760 by @xmath754 .",
    "furthermore @xmath761 by @xmath762 , @xmath763 by @xmath764 and @xmath765 by @xmath766 , to complete the interaction term , and @xmath767 for a completed interaction by the unit operator @xmath756 .",
    "furthermore all string states must start at 1 to the right of the last site and end at 5 ( i.e. the dimension @xmath723 of the mpo to be ) to the left of the first site .",
    "this can now be encoded by the following operator - valued matrices :    @xmath768 } = \\left [ \\begin{array}{ccccc } \\hat{i } & 0 & 0 & 0 & 0 \\\\ \\hat{s}^+ & 0 & 0 & 0 & 0 \\\\ \\hat{s}^- & 0 & 0 & 0 & 0 \\\\ \\hat{s}^z & 0 & 0 & 0 & 0 \\\\ -h\\hat{s}^z & ( j/2)\\hat{s}^- & ( j/2)\\hat{s}^+ & j^z\\hat{s}^z & \\hat{i } \\end{array } \\right]\\ ] ]    and on the first and last sites @xmath769 } = \\left [ \\begin{array}{ccccc } -h\\hat{s}^z & ( j/2)\\hat{s}^- & ( j/2)\\hat{s}^+ & j^z\\hat{s}^z & \\hat{i }   \\end{array } \\right ] \\quad\\quad   \\hat{w}^{[l ] } = \\left [ \\begin{array}{c } \\hat{i } \\\\ \\hat{s}^+ \\\\ \\hat{s}^- \\\\ \\hat{s}^z \\\\ -h\\hat{s}^z   \\end{array } \\right ] .\\ ] ] indeed , a simple multiplication shows how the hamiltonian emerges .",
    "inserting the explicit operator representations gives the desired @xmath710-matrices for the mpo .",
    "it is therefore possible to express hamiltonians exactly in a very compact mpo form ; a similar set of rules leading to the same result has been given by @xcite .",
    "for longer - ranged hamiltonians , further `` intermediate states '' have to be introduced .",
    "let us consider a model with just @xmath770-interactions , but between nearest and next - nearest neighbours , @xmath771 then the bulk operator would read @xmath768 } = \\left [ \\begin{array}{cccc } \\hat{i } & 0 & 0 & 0 \\\\ \\hat{s}^z & 0 & 0 & 0 \\\\ 0 & \\hat{i } & 0 & 0 \\\\ 0 & j_1\\hat{s}^z & j_2\\hat{s}^z & \\hat{i } \\end{array } \\right ] .\\ ] ] while the @xmath772-interaction can be encoded as before ( moving as @xmath773 ) , for the next - nearest neighbour interaction , one has to insert an additional step between 2 and 4 , an intermediate state 3 , where exactly one identity is inserted ( moving as @xmath774 ) .",
    "it merely serves as a book - keeping device .",
    "similarly , one can construct longer - ranged interactions . except the top - left and botton - right corner ,",
    "the non - vanishing parts of @xmath750}$ ] are all below the diagonal by construction .",
    "it might seem that for longer - ranged interactions the dimension @xmath723 will grow rapidly as more and more intermediate states are needed ( one additional state per unit of interaction range and per interaction term ) . while this is true in general , important exceptions are known which can be formulated much more compactly @xcite ; consider for example the following exponentially decaying interaction strength @xmath775 , where @xmath776 and @xmath777 .",
    "an interaction term @xmath778 would be captured by a bulk operator @xmath768 } = \\left [ \\begin{array}{ccc } \\hat{i } & 0 & 0   \\\\ \\hat{s}^z & \\lambda\\hat{i } & 0   \\\\ 0 & j\\lambda \\hat{s}^z & \\hat{i } \\end{array } \\right ] .\\ ] ]    but even if such a simplification does not occur , it turns out that mpos with quite small dimensions and moderate loss of accuracy can be found , either by approximating an arbitrary interaction function @xmath779 by a sum of exponentials coded as above@xcite , minimizing the @xmath780 distance @xmath781 in @xmath782 , where @xmath0 is given by the @xmath723 and loss of accuracy one is willing to consider .",
    "alternatively @xcite , one can of course construct the exact mpo where feasible and compress it by adapting mps compression techniques to an acceptable @xmath723 ( and loss of accuracy ) .",
    "let us consider @xmath32 in the following mixed canonical representation , identical to the single - site dmrg representation , @xmath783 or @xmath784 let us now look at the matrix elements @xmath785 obtained using the mpo representation for @xmath9 . by inserting twice the identity @xmath786 ,",
    "we obtain ( the sums with a star exclude site @xmath18 ) @xmath787 all the beauty of the mpo formulation seems gone , but a graphical representation restores it ( fig .",
    "[ fig : mpodmrghamiltonian ] ) .",
    "it can be understood most easily from the second or third line of the explicit expressions above : the hamilton mpo ( expressed in the product basis ) is projected on the block states of a and b , which have an expansion in the @xmath344-basis .     in mpo / mps language .",
    "the hamiltonian mpo is contracted with four block state expansions in mps form ( two bras , two kets , two on block a , two on block b ) .",
    "the contracted network decouples into parts @xmath5 , @xmath124 and @xmath199 , corresponding to blocks a and b and the center site . ]    in fact , we can also encode the obvious tripartite structure of the expression as @xmath788 where @xmath5 and @xmath199 contain the contracted left and right parts of the graphical network : @xmath789 we can now write the action of @xmath9 on a state @xmath32 in the mixed canonical or single - site dmrg representation as @xmath790 as we will discuss in an instant , @xmath791 is the key operation in an iterative ground state search . evaluating",
    "this expression naively is inacceptably slow ; it can be drastically accelerated on two counts : first , @xmath5 and @xmath199 can be built iteratively in order to maximally reuse available information ; this involves an optimal arrangement of a network contraction .",
    "moreover , the final action of @xmath5 , @xmath199 and @xmath124 on @xmath32 can also be arranged highly efficiently .",
    "let us first consider building @xmath5 and @xmath199 .",
    "in actual applications , we will never carry out the full network contraction that stands behind them , because in the spirit of dmrg we are looking at blocks that are growing and shrinking in size site by site .",
    "the construction of @xmath5 and @xmath199 , however , is iterative in a way that directly matches block growth and shrinkage .",
    "i will illustrate it for @xmath5 , using @xmath235-matrices ; left - normalization will be exploited explicitly for further simplification at one point only such that the formulae are generic .",
    "we start by considering the block of size 1 : we contract @xmath792}$ ] and @xmath792\\dagger}$ ] with @xmath793}$ ] .",
    "the block basis representation is then given by @xmath794}_{a_1,b_1;a'_1 } = \\sum_{\\sigma_1,\\sigma_1',a_0,b_0,a'_0 } w^{[1]\\sigma_1\\sigma'_1}_{b_0,b_1 } ( a^{[1]\\sigma_1\\dagger})_{a_1,a_0 } f^{[0]}_{a_0,b_0,a'_0 } a^{[1]\\sigma'_1}_{a'_0,a'_1}\\ ] ] where we have introduced a dummy scalar @xmath795}_{a_0,b_0,a'_0}=1 $ ] , and where @xmath796 can just take the value 1 ; this is just to make the first step more consistent with all that follow .",
    "the resulting object is a tensor @xmath797}_{a_1,b_1,a'_1}$ ] , corresponding to the three legs sticking out .",
    "we can now simply continue to contract @xmath235 , @xmath798 and @xmath124 on the next site , and the contraction update reads @xmath799}_{a_i , b_{i},a'_i } =   \\sum_{\\sigma_i,\\sigma_i',a_{i-1},b_{i-1},a'_{i-1 } } w^{[i]\\sigma_i\\sigma'_i}_{b_{i-1},b_{i } }    ( a^{[i]\\sigma_i\\dagger})_{a_i , a_{i-1 } } f^{[i-1]}_{a_{i-1},b_{i-1},a'_{i-1 } } a^{[i]\\sigma'_i}_{a'_{i-1},a'_i}\\ ] ] and can be represented pictorially as in fig .",
    "[ fig : constructionematrices ] .    }",
    "$ ] to @xmath800}$ ] by contracting with @xmath801*}$ ] , @xmath802}$ ] and @xmath801}$ ] . while it makes sense mathematically to consider the three added tensors as one object , in numerical practice",
    ", they are contracted into the network sequentially for efficiency . ]",
    "this construction can be calculated most efficiently by optimal bracketing as @xmath799}_{a_i , b_{i},a'_i } = \\sum_{\\sigma_i , a_{i-1 } } ( a^{[i]\\sigma_i\\dagger})_{a_i , a_{i-1 } }   \\left ( \\sum_{\\sigma_i',b_{i-1 } } w^{[i]\\sigma_i\\sigma'_i}_{b_{i-1},b_{i } } \\left ( \\sum_{a'_{i-1 } } f^{[i-1]}_{a_{i-1},b_{i-1},a'_{i-1 } } a^{[i]\\sigma'_i}_{a'_{i-1},a'_i }   \\right ) \\right ) .\\ ] ] here , we have contracted the three new tensors into the network one by one , at operational counts @xmath803 in the innermost bracket , then @xmath804 and last @xmath805 .",
    "in fact , the second operation is faster in practice , as we know that most operators in @xmath806 are simply zero ; the remaining ones also often have a simple structure .",
    "another acceleration is possible in the case of building @xmath5 from left - normalized matrices for indices @xmath807 , if we build @xmath9 following the rules outlined in the previous section : we know that in this case only identities operate towards the left , implying that @xmath800}_{a_i , d_w , a'_i } = \\delta_{a_i , a'_i}$ ] , simplifying both the innermost bracket and the outermost operation .",
    "the same idea applies for indices @xmath808 on the right side for building @xmath199 from right - normalized matrices .",
    "note that this construction is a generalization of the representation update explained for dmrg : a typical situation is the representation of @xmath809 , where the two operators act locally on sites @xmath304 and @xmath439 respectively .",
    "then the mpos are of dimension @xmath810 everywhere and @xmath811 everywhere but on sites @xmath304 and @xmath439 , where they read @xmath812\\sigma_i,\\sigma'_i}$ ] and similarly for @xmath439 .",
    "pushing forward the contractions , @xmath813}$ ] is still a scalar 1 .",
    "then @xmath799 } =   \\sum_{\\sigma_i,\\sigma_i ' } o^{[i]\\sigma_i,\\sigma'_i } a^{[i]\\sigma_i\\dagger } a^{[i]\\sigma'_i}\\ ] ] where @xmath800}$ ] , @xmath801\\sigma_i\\dagger}$ ] and @xmath801\\sigma'_i}$ ] are matrices and a multiplication @xmath801\\sigma_i\\dagger } a^{[i]\\sigma'_i}$ ] is implied .",
    "the @xmath800}$]-matrix is just the operator representation in the block basis , comprising sites 1 through @xmath304 .",
    "the update up to site @xmath814 then simplifies to @xmath815 } =   \\sum_{\\sigma_k } a^{[k]\\sigma_k\\dagger } f^{[k-1 ] } a^{[k]\\sigma_k } , \\quad ( i < k < j)\\ ] ] matrix multiplications implied , and at site @xmath439 we get again a non - trivial step , @xmath816 } = \\sum_{\\sigma_j,\\sigma'_j } o^{[j]\\sigma_j,\\sigma'_j } a^{[j]\\sigma_j\\dagger } f^{[j-1 ] } a^{[j]\\sigma'_j},\\ ] ] after which updates continue as on the previous sites .",
    "making the matrix multiplications explicit , one sees that this is just the construction discussed for the dmrg algorithm .    in the end",
    ", @xmath791 can be bracketed advantageously as follows : @xmath817 which scales at worst as @xmath433 .",
    "more precisely , the innermost operation is @xmath818 ; the next one is @xmath819 , after this we have a sum of cost @xmath820 .",
    "it is advantageous to keep track of the structure of @xmath124 , namely exploiting for which @xmath821 configurations it is zero and nothing has to be calculated ( usually , for most of them ) , and to use the simplifications for @xmath5 and @xmath199 just discussed if the state is in mixed - canonical form .",
    "let us now turn to the algorithm .",
    "assume @xmath9 given in mpo form and consider a class of mps with predefined matrix dimensions ( simply think about a random mps with matrices @xmath822 of desired shape and size , but no normalization assumed for the moment ) .",
    "in order to find the optimal approximation to the ground state within this class , we have to find the mps @xmath32 that minimizes @xmath743 it turns out that this can be turned into a ground state algorithm much more efficient than imaginary time evolution from some random state . in order to solve this problem",
    ", we introduce a lagrangian multiplier @xmath519 , and extremize @xmath823 in the end , @xmath32 will be the desired ground state and @xmath519 the ground state energy .",
    "the mps network that represents eq .",
    "( [ eq : lagrange ] ) is shown in fig .",
    "[ fig : extremizationexpression ] .    , the right - hand side the squared norm @xmath435 . ]",
    "the problem with this approach is that the variables ( the matrix elements @xmath824 ) appear in the form of products , making this a highly non - linear optimization problem .",
    "but it can be done iteratively , too , and this is the idea that also drives dmrg : while keeping the matrices on all sites but one ( @xmath18 ) constant , consider only the matrix entries @xmath825 on site @xmath18 as variables .",
    "then the variables appear in eq .",
    "( [ eq : lagrange ] ) only in quadratic form , for which the determination of the extremum is a benign linear algebra problem .",
    "this will lower the energy , and find a variationally better state , but of course not the optimal one .",
    "now one continues to vary the matrix elements on another site for finding a state again lower in energy , moving through all sites multiple times , until the energy does not improve anymore .",
    "let us first consider the calculation of the overlap , while keeping the chosen @xmath826 explicit .",
    "we find @xmath827 where @xmath828 as is particularly clear in the graphical representation , for obtaining the last two expressions the same rules about smart contracting apply as for overlaps ; moreover , if we move through sites @xmath18 from neighbour to neighbour , they can be updated iteratively , minimizing computational cost . in the case where sites 1 through @xmath72 are left - normalized and sites @xmath241 through @xmath5",
    "right - normalized , normalization conditions lead to a further simplification , namely @xmath829    let us now consider @xmath830 , with @xmath9 in mpo language . taking into account the analysis of @xmath791 in the last section ,",
    "we can immediately write @xmath831 with @xmath5 and @xmath199 as defined before ; how such an expression can be evaluated efficiently has been discussed previously .    if we now take the extremum of eq .",
    "( [ eq : lagrange ] ) with respect to @xmath832 we find @xmath833 this is in fact a very simple eigenvalue equation ; if we introduce matrices @xmath834 and @xmath534 by reshaping @xmath835 and @xmath836 as well as a vector @xmath608 with @xmath837 , we arrive at a _ generalized eigenvalue problem _ of matrix dimension @xmath838 , @xmath839 represented in fig .",
    "[ fig : equationsystem ] . solving for the lowest eigenvalue @xmath840 gives us a @xmath841 , which is reshaped back to @xmath842 , @xmath840 being the current ground state energy estimate .    .",
    "the unknown matrix is circled on the left and right networks . ]",
    "a few remarks are in order .",
    "* the problem is hermitian ; both @xmath834 and @xmath534 are hermitian , as can be seen from the construction and the hermiticity of the mpo employed . * in general",
    ", @xmath843 is too large for an exact diagonalization , but as we are only interested in the lowest eigenvalue and eigenstate , an iterative eigensolver that aims for the ends of the spectrum will do .",
    "typical methods are the lanczos or jacobi - davidson large sparse matrix solvers .",
    "the speed of convergence of such methods ultimately rests on the quality of the initial starting or guess vector .",
    "as this eigenproblem is part of an iterative approach to the ground state , the current @xmath826 is a valid guess that will dramatically speed up calculations close to convergence .",
    "* generalised eigenvalue problems can be numerically very demanding , if the condition number of @xmath534 becomes bad .",
    "but this is no issue for open boundary conditions , if one ensures that the state is left - normalized up to site @xmath72 and right - normalized from site @xmath241 onwards .",
    "then the simplifications for @xmath844 and @xmath845 imply that @xmath534 is just the identity matrix @xmath436 .",
    "the eigenvalue problem then simplifies to a standard one , @xmath846 or @xmath847 , as represented in fig .",
    "[ fig : normalizedequationsystem ] . the evaluation of the sums will be done using the optimal bracketing for @xmath791 . to achieve this simplification",
    ", one will sweep the position @xmath18 from right to left and vice versa through the chain , such that the optimal normalization configuration can be maintained by a single step of the left or right canonization procedure after each minimization .    .",
    "the unknown matrix is circled on the left network . ]",
    "the optimal algorithm then runs as follows .",
    "* start from some initial guess for @xmath32 , which is right - normalized , i.e. consists of @xmath269-matrices only . *",
    "calculate the @xmath199-expressions iteratively for all site positions @xmath301 through 1 iteratively .",
    "* _ right sweep : _ starting from site @xmath459 through site @xmath301 , sweep through the lattice to the right as follows : solve the standard eigenproblem by an iterative eigensolver for @xmath826 , taking its current value as starting point . once the solution is obtained , left - normalize @xmath826 into @xmath703 by svd ( or qr ) to maintain the desired normalization structure .",
    "the remaining matrices of the svd are multiplied to the @xmath848 to the right , which will be the starting guess for the eigensolver for the next site .",
    "build iteratively the @xmath5 expression by adding one more site .",
    "move on by one site , @xmath849 , and repeat . *",
    "_ left sweep : _ starting from site @xmath458 through site @xmath850 , sweep through the lattice to the left as follows : solve the standard eigenproblem by an iterative eigensolver for @xmath826 , taking its current value as starting point .",
    "once the solution is obtained , right - normalize @xmath826 into @xmath851 by svd ( or qr ) to maintain the desired normalization structure .",
    "the remaining matrices of the svd are multiplied to the @xmath852 to the left , which will be the starting guess for the eigensolver for the next site .",
    "build iteratively the @xmath199 expression by adding one more site .",
    "move on by one site , @xmath853 , and repeat . * repeat right and left sweeps , until convergence is achieved .",
    "convergence is achieved if energy converges , but the best test is ( using mpo ) to consider @xmath854 to see whether an eigenstate has been reached ; this expression should approach 0 as closely as possible .",
    "if we call matrices @xmath235 , @xmath269 , @xmath25 depending on their normalization ( @xmath25 always being the one on the site currently attended to ) , and giving them an subscript index @xmath304 to label the number of updates by the eigensolver they have undergone , the algorithm would formalize as @xmath855 and again moving from left to right , starting with a diagonalization step .    in this iterative process",
    ", the energy can only go down , as we continuously improve by varying the parameters .",
    "two problems occur : starting from a random state , the guesses for the @xmath826 in the iterative eigensolvers will be very bad in the initial sweeps , leading to large iteration numbers and bad performance . moreover , we can not guarantee that the global minimum is actually reached by this procedure instead of being stuck in a non - global minimum .",
    "one way of addressing the first issue is to start out with infinite - system dmrg to produce an initial guess ; an optimal mps version of infinite - system dmrg is discussed in section  [ sec : infinite ] . while this initial guess may be far from the true solution",
    ", it will usually fare much better than a random starting state .",
    "moreover , one can try to balance the number of iterations ( high in the first sweeps ) by starting with small @xmath20 , converge in that ansatz class , enlarge @xmath20 and add zeros in the new matrix entries , converge again , and so on .",
    "when @xmath20 gets large , the guess states will hopefully be so close to the final state that only very few iterations will be needed .",
    "it turns out , however , that starting with too small @xmath20 may land us in a non - global minimum that we will not get out of upon increasing @xmath20 . quite generally , as in dmrg",
    ", one should never calculate results for just a single @xmath20 , but increase it in various runs until results converge ( they are guaranteed to be exact in the @xmath110 limit ) .",
    "if we are looking for low - lying excited states instead of a ground state , two typical situations occur : ( i ) the excited state is known to be the ground state of another sector of the hilbert space decomposed according to some good quantum number .",
    "then the calculation is just a ground state calculation in that different sector .",
    "( ii ) the excited state is the first , second , or higher excitation in the sector of the ground state .",
    "then we have to calculate these excitations iteratively , and orthonormalize the state with respect to the lower - lying states already identified ; this clearly limits the approach to a few low - lying excitations .",
    "the place where the algorithm is to be modified is in the iterative eigensolver ; e.g.  in the lanczos iterations , the next lanczos state generated is orthonormalized not only with respect to the previous lanczos states , but also already constructed eigenstates of the hamiltonian .",
    "this is a standard extension of the lanczos algorithm .",
    "the variational mps algorithm just introduced is quite prone to getting stuck .",
    "how this is going to happen , actually depends a bit on how initial states are chosen in the procedure : assume that , as is the case for the anisotropic heisenberg chain , there is a quantum symmetry with some commuting operator @xmath856=0 $ ] , in this case the total magnetization operator @xmath857 , giving rise to magnetization @xmath25 as a good quantum number .",
    "then initial states fall into two categories , whether they are eigenstates of @xmath55 or not",
    ". the latter will generally be the case if the state is chosen randomly ; the former is the case if it is generated by infinite - system dmrg or its mps variant .    decomposing the hilbert space into eigenstates of magnetisation , @xmath858 ,",
    "we can write initial states as @xmath859 the ground state we are looking for is @xmath860 ; the initial state will then have either arbitrary @xmath861 or @xmath862 if @xmath863 ( assuming that we do nt run into the desaster of offering an initial state in the wrong symmetry sector ) .",
    "let us assume that in the first case , sweeping will eliminate contributions from the wrong symmetry sectors ; if they do nt , the variationally optimal state can never be reached anyways because wrong admixtures survive . as an iterative ground state search by e.g.",
    "lanczos is an optimized version of the power method @xmath864 for finding the largest eigenvalue and associated eigenstate , one can show that in the full hilbert space wrong symmetry sectors will definitely be projected out . in our algorithm ,",
    "this iterative projection proceeds in a highly constrained state space and might not be as efficient , as it looks at various wave function components sequentially . as random starting states are very inefficient , i can not report on a lot of practical experience here . in any case , once we arrive in a well - defined symmetry sector , we will have , for any schmidt decomposition @xmath865 , that each of the states will have a good quantum number ( superpositions of different quantum numbers lead immediately to a contradiction to a global good quantum number ) , namely @xmath866 and @xmath867 such that @xmath868 , where i have simplified indices . taking the @xmath867 , for example",
    ", they will be distributed over some range , say 1 state with magnetization @xmath24 , 3 states with magnetization @xmath869 , 5 states with magnetization @xmath870 and so forth .",
    "as i will show next , this distribution stays _ fixed _ in further sweeps .",
    "this means that if it does not correspond to the distribution that the variationally optimal state would yield , it can never reach that state . in the random state approach",
    "one may hope that the slow elimination of other total magnetizations `` eases '' us into the right distributions but there is no guarantee ; in the infinite - system approach one has to hope that this warm - up scheme produces the right distribution right away , which is quite unlikely to happen .",
    "the reason why the distribution stays fixed can be seen from the svd of @xmath871 to carry out one ( for example ) left - normalization step : reshaping matrices @xmath872 into some @xmath44 and applying an svd gives at most @xmath20 non - vanishing singular values ; the right - singular vectors in @xmath158 are nothing but the eigenvectors of @xmath873 , which is block - diagonal because the states @xmath874 have good quantum numbers .",
    "the right singular vectors ( eigenvectors ) therefore encode a basis transformation within blocks of the same quantum number , hence the number of states with a given quantum number remains the same , and so does the number of states with a given quantum number in the other part of the system because of the matching of quantum numbers required in the schmidt decomposition .",
    "various ways of getting out of this potential trap have been proposed .",
    "the first one is to modify the algorithm to consider two sites at the same time , just as in conventional ( two - site ) dmrg ; we will discuss its mps implementation in the next section . while this approach is slower ( roughly by a factor of @xmath31 ) , it offers a slightly enlarged ansatz space with a subsequent truncation that allows the algorithm to be more robust against the danger of getting stuck in local energy minima in ground state searches . in particular",
    ", the enlarged ansatz space of the two - site algorithm allows a reshuffling of the quantum number distribution due to the truncation .",
    "once this is converged , one may switch to the single - site algorithm , as proposed by takasaki et al .",
    "@xcite , although it is not at all clear that this leads strictly to the optimal outcome@xcite .",
    "much better , there is a procedure by white @xcite that protects reasonably against trapping and ensures reshuffling .",
    "it is crucial for a reliable single - site dmrg ( or variational mps , which we will show to be identical ) algorithm and turns it into the state of the art form of the method .",
    "it starts from the observation that quantum numbers of a subsystem a are changed by quantum fluctuations due to those parts of the hamiltonian that connect a to the rest of the system .",
    "we therefore have to consider the structure of @xmath791 in more detail .",
    "consider @xmath875 _",
    "after energy optimization _ in the single - site algorithm .",
    "we can also write @xmath876 where @xmath877 such that there are @xmath723 terms in this sum .",
    "if we think in terms of block states , we would like to know which new states can be reached on a@xmath28 by the action of @xmath878 . projecting the result of this action onto the a@xmath28b basis it will read @xmath879 which is just @xmath880 using @xmath881 from eq .",
    "( [ eq : ldefineinmpo ] ) , as can be seen graphically in fig .",
    "[ fig : whiteimprovement ] .",
    "this indicates that the actual cost of computation is very low , because we have already done the most complicated part .",
    "represented graphically : with the exception of one @xmath124-tensor and one @xmath44-tensor , all the contractions have already been computed to obtain @xmath881 . ]    now we would like to include the states generated by @xmath878 into the search for a good basis for a@xmath28 .",
    "here , dmrg offers the possibility of multiple - state targetting",
    ". the conventional algorithm would now proceed by calculating @xmath882 or @xmath883 , finding the eigenvalues ( squares of the singular values ) , the eigenvectors ( left singular vectors ) , truncation and so on .",
    "but we can look at a modified density matrix , which takes also into account the new terms as @xmath884 where @xmath885 is a small number , say @xmath886 , giving a little weight to contributions that the conventional algorithm may miss .",
    "the price paid is that at the end of the spectrum a few very - small weight states from @xmath887 will drop out . upon multiple sweeping ,",
    "@xmath885 will be taken slowly to zero .",
    "the new density matrix is diagonalized , and truncation according to the @xmath20 largest eigenvalues is carried out , yielding a @xmath888 matrix of orthonormal columns , @xmath889 , and we continue on the next site ; as we are not using the eigenvalues of the modified density matrix beyond their relative ordering , it does not matter that they do not sum up to 1 . for predicting the next @xmath890 for the large sparse matrix solver , we use the dmrg prediction formula derived in the next section , @xmath891 otherwise",
    ", everything remains the same .",
    "the additional numerical cost and programming effort is minimal for an algorithm that often converges much faster and is much less prone to getting stuck at a non - optimal result .      how can the previous approach be related to conventional dmrg ?",
    "the essential answer is that the mps approach is identical to finite - size dmrg for obc , albeit only if we shift one site instead of two , i.e.  consider `` single - site '' instead of `` two - site '' dmrg , where we consider a block - site - block configuration a@xmath28b instead of a block - site - site - block configuration a@xmath19b .",
    "let us first remind ourselves of the key steps of the algorithms , assuming that we are sweeping to the right : ( i ) given some configuration a@xmath28b ( or corresponding configuration @xmath892 ) and a hamiltonian @xmath9 , the ground state is found by a large sparse matrix eigensolver looking for the optimal @xmath893 ( in dmrg ) or @xmath894 ( in mps ) respectively ; analogously for a@xmath19b .",
    "( ii ) given the ground state , mps derives a set of left - normalized @xmath235-matrices , whereas dmrg finds new block states whose structure can be encoded by left - normalized @xmath235-matrices .",
    "( iii ) all algorithms switch to a new a@xmath28b , a@xmath19b or @xmath895 configuration , where the active center is shifted by one site to the right and provide an initial guess for the calculation of the next ground state , taking us back to step ( i ) .",
    "step ( i ) : results must be identical if we use the same state configuration and the same hamiltonian .",
    "as dmrg grows the blocks a and b from left and right , and as each block growth step a@xmath896a can be encoded by @xmath235-matrices and similarly @xmath28b @xmath897 b , we conclude that all matrices on a are left - normalized and those on b right - normalized , hence the two - site dmrg state takes the form @xmath898 with the obvious change for a single - site dmrg state , @xmath899 .",
    "this is in perfect agreement with the mixed - canonical states of the variational mps approach and we are looking at the same state structure .    it remains to show that the hamiltonians are identical , too . strictly speaking ,",
    "this is not the case : the mpo representation of @xmath9 we just used is clearly exact . on the other hand ,",
    "the representation of @xmath9 in dmrg contains a series of reduced basis transformations , hence is inherently inexact .",
    "so , the two representations seem unrelated , with an advantage on the mpo side because it is exact . but a more careful analysis reveals that on the level of calculating expectation values @xmath830 as they appear in mps and dmrg ground state searches both representations give identical results ( they are not identical for higher moments , such as @xmath900 , where the mpo representation is demonstrably more accurate at a numerical cost , see below ) .",
    "both the dmrg and the mpo hamiltonian contain all terms of the exact hamiltonian . as we have already seen in the application of a hamiltonian mpo to a mixed canonical state ( sec .",
    "[ subsec : hamiltonianmixedcanonical ] ) , the evaluation of the @xmath5 and @xmath199-objects appearing in the large sparse eigenproblem eq .",
    "( [ eq : vmpseigenequation ] ) is nothing but the sequence of reduced basis transformations occuring in dmrg up to the current a@xmath28b configuration .",
    "hence , for @xmath830 ( but in general only for this ! ) , both approaches are identical .",
    "moreover , the calculation @xmath791 appearing in the eigenproblem does not have a worse operational count than in the corresponding dmrg procedure . to see this ,",
    "let us focus on our example mpo for an anisotropic nearest - neighbour heisenberg chain .",
    "there seems to be a difference in efficiency when we consider the double sum over @xmath901 . from the structure of the @xmath124-matrix",
    "it is clear that for most of the @xmath902 ( in the example 25 ) entries we find zeros , such that we can strongly restrict the sum . but",
    "this would still give the following count : setting the field 0 , for the heisenberg hamiltonian there are 8 contributions in the dmrg setup : one each for @xmath903 and @xmath904 , the parts of the hamiltonian that act strictly on a and b , and three per block for the three operator combinations linking a block and the site .",
    "all of them are diagonal in the other block , so there are altogether 8 operations of cost @xmath433 . in the mpo calculation ,",
    "the double matrix - matrix multiplication would naively suggest 16 operations of cost @xmath433 , for the 8 non - vanishing entries of @xmath905 .",
    "but then we can exploit the following rules : if @xmath906 , then there are no operations to the left , @xmath907 , and one operation drops out . similarly ,",
    "if @xmath908 , then there are no operations to the right and @xmath909 , and again one operation drops out . looking at the structure of @xmath124 , all non - vanishing entries meet one or the other condition , and the count halves down to 8 operations . only longer - ranged interactions do not fit this picture , but they would be of cost @xmath910 in dmrg as well .    step ( ii ) : after energy minimization , variational mps and dmrg produce ( identical ) @xmath826 and @xmath688 , or @xmath911 .",
    "both methods now seem to proceed differently with the result , but in fact do the same : in variational mps one just shifts one site to the right after an svd to ensure left - normalization , to continue minimizing on the next site . in dmrg one",
    "previously carries out a density matrix analysis to determine a new ( truncated ) block basis .",
    "but if one carries out the corresponding svd , the number of non - zero singular values ( hence non - zero density matrix eigenvalues ) is limited by @xmath20 , the matrix dimension : @xmath912 hence , no truncation happens , and we are just doing a unitary transformation to obtain orthonormal states for the new larger block a ( which is just the left - normalization in the mps because of the link between svd and density matrix diagonalization ) .",
    "both formalisms act identically ; as no truncation occurs , thin qr would do , too .",
    "on the other hand , in two - site dmrg the same step reads @xmath913 but we can only keep @xmath20 states in the new block , hence truncation has to occur ! here is the _ only _ difference between variational mps and single - site dmrg on the one and two - site dmrg on the other hand .",
    "step ( iii ) : in dmrg , after completion of one iteration , the free site(s ) are shifted by one , leading to block growth of a and shrinkage of b. here , all methods agree again : in variational mps , the shrinkage of b is simply reflected in the states being formed from a string of @xmath269-matrices where the leftmost one has dropped off .",
    "the growth of a is given by a similar string , where one @xmath235-matrix has been added .",
    "the matrix on the free sites is to be determined in all approaches , so nothing is to be said about its normalization .",
    "minimization of ground state energy is , as we have seen , a costly large sparse matrix problem .",
    "as the methods are iterative , a good initial guess is desirable .",
    "dmrg has provided some `` state prediction '' for that @xcite .",
    "in fact , it turns out that the result of the prediction is just what one gets naturally in variational mps language without the intellectual effort involved to find state prediction .",
    "let us assume that for single - site dmrg we just optimized @xmath688 , deriving a new @xmath914 . then in mps language the next @xmath915 , where @xmath140 and @xmath158 are from the svd . in dmrg language , we take @xmath916 and insert twice approximate identities @xmath917 and @xmath918 . expressing the matrix elements by @xmath235 and @xmath269 matrices",
    ", the state now reads @xmath919 so the prediction reads @xmath920 but this is exactly the mps ansatz for the next eigenproblem , as @xmath921 .",
    "but this is just @xmath922 because in the ansatz , @xmath923 is summed over and left - normalization holds .",
    "two - site dmrg proceeds by analogy and is left as an exercise for the reader .    while this clarifies the relationship between variational mps , single - site dmrg ( the same ) and two - site dmrg ( different ) , it is important to note that the different ways of storing information more implicitly or more explicitly implies differences even if the algorithms are strictly speaking identical  the fact that in one formulation prediction is trivial and in the other is not already gave us an example .",
    "but there is more .",
    "\\(i ) in dmrg , the effective bases for representing the states and the hamiltonian or other operators are tied up .",
    "this is why concepts such as targetting multiple states arise , if we consider several different states like the ground state and the first excited state at the same time .",
    "one then considers mixed reduced density operators @xmath924 with @xmath925 the target states and @xmath926 , @xmath927 , to give a joint set of bases for all states of interest .",
    "this can of course only be done at a certain loss of accuracy for given numerical resources and for a few states only . at the price of calculating the contractions anew for each state , in the mpo / mps formulation ,",
    "the state bases are only tied up at the level of the exact full basis .",
    "mpo / mps formulations therefore acquire their full potential versus conventional dmrg language once multiple states get involved .",
    "\\(ii ) another instance where the mpo / mps formulation is superior , albeit at elevated numerical cost , is the calculation of the expression @xmath900 , which is interesting e.g.  in the context of estimating how accurately a ground state has been obtained . in the mpo formalism",
    ", it can be done exactly up to the inherent approximations to @xmath32 by contracting the network shown in fig .",
    "[ fig : calculationh2 ] .",
    "it would of course be most economical for the programmer to calculate @xmath791 and take the norm , two operations which at this stage he has at hand",
    ". the operational cost of this would be @xmath928 for the action of the mpo and @xmath929 for the norm calculation .",
    "the latter is very costly , hence it is more efficient to do an iterative construction as done for @xmath830 . let me make the important remark that dimension @xmath902 is only the worst case for @xmath930@xcite : writing out the square and introducing rules for the expression leads to more efficient mpos , whose optimality can be checked numerically by doing an svd compression and looking for singular values that are zero .",
    "our anisotropic heisenberg hamiltonian takes @xmath931 instead of 25 for @xmath932 . for higher powers , the gains are even more impressive , and can be obtained numerically by compressing an explicit mpo for @xmath933 with discarding only zeros among the singular values .    :",
    "the hamiltonian mpo is repeated twice and sandwiched between @xmath32 at the bottom and @xmath934 at the top . ]    in a dmrg calculation , there would be a sequence @xmath935 , in the dmrg block - site basis as shown in fig .",
    "[ fig : dmrgcalculationh2 ] .",
    "the point is that before the second application of @xmath9 , a projection onto the reduced block bases happens , which is not the identity and loses information .    :",
    "the hamiltonian mpo is applied once to @xmath32 in step ( 1 ) in the dmrg basis , i.e. the result is projected onto the reduced bases , yielding some @xmath936 .",
    "this in turn replaces @xmath937 in the second application of @xmath9 in step ( 2 ) .",
    "ultimately , the result is projected on the block bases . ]",
    "what does the comparison mps and dmrg imply algorithmically ?",
    "first of all , the truncation error of conventional dmrg , which has emerged as a highly reliable tool for gauging the quality of results , is nothing but an artefact of the somewhat anomalous two - site setup . in variational mps or single - site dmrg",
    "it has to be replaced by some other criterion , like the variance of the energy .",
    "second , while all the approaches are variational in the sense that they are looking for the lowest energy that can be achieved in a given type of ansatz , it varies from site to site in two - site dmrg ( because of the @xmath938 anomaly in the ansatz ) , the ansatz stays the same all the time in single - site dmrg , which is conceptually nicer . that this comes at the expense of potential trapping serves as a reminder that the mathematically most beautiful does not have to be the most practical .",
    "the calculation of the action of operators like @xmath939 or @xmath940 on quantum states is of central interest in quantum mechanics , for real - time evolutions of quantum states and for quantum statistical mechanics ; @xmath941 can be interpreted as an imaginary time .",
    "it is one of the most attractive features of mps that such real or imaginary time evolutions can be encoded very neatly and efficiently .",
    "this holds both for pure and mixed states , important at finite temperature . in the following ,",
    "i will focus on time evolution based on a trotter decomposition of the evolution operators @xcite , explaining first the trotter decomposition and the structure of the algorithm for pure states , then the representation of the trotter decomposition by mpos .",
    "after this , i will discuss the changes necessary for the simulation of the dynamics of mixed states .",
    "let us assume that @xmath9 consists of nearest - neighbour interactions only , i.e.  @xmath942 , where @xmath943 contains the interaction between sites @xmath304 and @xmath383 .",
    "we can then discretize time as @xmath944 with @xmath945 , @xmath946 and ( in the most naive approach ) do a first - order trotter decomposition as @xmath947 which contains an error due to the noncommutativity of bond hamiltonians , @xmath948 \\neq 0 $ ] in general ; higher order decompositions will be discussed later in this section .",
    "all time evolutions on odd ( @xmath949 ) and even ( @xmath950 ) bonds respectively commute among each other , and can be carried out at the same time .",
    "so we are looking for an mpo doing an infinitesimal time step on the odd bonds and for another mpo doing the same on the even bonds .",
    "as any operator is guaranteed to be mpo - representable , let us assume for a moment that indeed we can construct these representation of infinitesimal time steps efficiently ( see next section for the explicit construction ) . as we will see , the maximum bond dimension of the infinitesimal time step mpos is @xmath444 because the dimension of @xmath951 is @xmath952 .",
    "the application of the infinitesimal time step mpos thus increases the bond dimensions from @xmath20 up to @xmath953 .",
    "repeated applications of the infinitesimal time evolution mpos leads to an exponential growth of the matrix dimensions , which therefore have to be truncated after time steps .",
    "the resulting time evolution algorithm takes a very simple form : starting from @xmath954 , repeat the following steps :    * apply the mpo of the odd bonds to @xmath955 . *",
    "apply the mpo of the even bonds to @xmath956 . *",
    "compress the mps @xmath957 from dimensions @xmath953 to @xmath20 , monitoring the error .",
    "obviously , one may also allow for some compression error ( state distance ) @xmath50 and choose a time - dependent @xmath20 : it will typically grow strongly with time , limiting the reachable timescale . by analogy to the ground state calculations , all results should be extrapolated in @xmath110 or @xmath111 .    after each time step , we may evaluate observables in the standard way , @xmath958 .",
    "but we can do more : we can calculate time - dependent correlators as @xmath959 where @xmath960 and @xmath961 .",
    "if we take e.g.  @xmath962 and @xmath963 , we can calculate @xmath964 and by a double fourier transformation the structure function @xmath965 where i have assumed translational invariance and infinite extent of the lattice for simplicity of the formula .",
    "a simple improvement on the algorithm given above is to do a second - order trotter decomposition @xmath966 where the error per timestep is reduced by another order of @xmath967 .",
    "if we do not do evaluations after each time step , we can group half steps , and work at no additional expense compared to a first - order trotter decomposition .",
    "a very popular implementation of a fourth order - trotter decomposition that originates in quantum monte carlo would be given by the following formula due to suzuki@xcite : @xmath968 where @xmath969 and @xmath970 even smaller errors can be achieved at similar cost using less symmetric formulae@xcite .",
    "this completes the exposition of the algorithm ( an error analysis will be given after the other methods for time evolution have been explained ) , and we now have to construct the mpos .",
    "let us consider the trotter step for all odd bonds of a chain : @xmath971 each bond - evolution operator like @xmath972 takes the form @xmath973 . both in the pictorial and the explicit mathematical representation it is obvious that this operator destroys the mps form ( fig .",
    "[ fig : trotterstep ] ) .        it would therefore be desirable to have @xmath974 in some form containing tensor products @xmath975 , to maintain the mps form . to this purpose",
    ", we carry out the procedure for decomposing an arbitrary state into an mps , adapted to an operator ( two indices per site ) .",
    "it works because there are so few indices .",
    "one reorders @xmath976 to group local indices and carries out a singular value decomposition : @xmath977 where @xmath978 and @xmath979 . in the very last step of the derivation , we have introduced a dummy index taking value 1 to arrive at the form of an mpo matrix .",
    "the index @xmath980 may run up to @xmath444 , giving the bond dimension @xmath723 of the mpo .",
    "the mpo representing the operator in eq .",
    "( [ eq : oddevolution ] ) , @xmath981 , factorizes on every second bond , as do the original unitaries .",
    "if one site does not participate in any bond evolution , we simply assign it the identity unitary as a @xmath810-matrix : @xmath982 .",
    "then the global mpo can be formed trivially from local mpos .",
    "the mpo for time evolution on all odd bonds would read @xmath983 , whereas the even - bond time step reads @xmath984 ( fig .",
    "[ fig : oddeventrotter ] ) .     on mpo bonds .",
    "the mpos in the top line on the first and last site are trivial scalar identities 1 . ]",
    "finite temperature calculations can be carried out based on the purification of an arbitrary mixed quantum state@xcite : if we consider a mixed state in physical space p formed from orthonormal states , we can interpret it as the result of a partial trace over a schmidt decomposition of a pure state on pq , where q is an auxiliary space : @xmath985 the auxiliary state space can simply be taken as a copy of the original one , so finite - temperature density operators on a chain can be expressed as pure states on a ladder ( see fig .",
    "[ fig : finitetemperaturesketch ] ) .    to calculate a thermal density operator @xmath986 , @xmath987 , we write @xmath988 the identity @xmath756 is nothing but @xmath989 , the infinite temperature density operator times the infinite temperature partition function .",
    "assume we know the purification of @xmath990 as an mps , @xmath991 .",
    "then @xmath992 the trace over q can be pulled out as the hamiltonian does not act on q. but the result means that we have to do an imaginary time evolution @xmath993 expectation values are given by @xmath994 @xmath995 may seem difficult to obtain , but follows trivially from the expectation value of the identity , @xmath996 hence @xmath997 , or , in complete agreement with standard quantum mechanics , @xmath998 but this takes us right back to expressions we know how to calculate .",
    "all we have to do is to find @xmath999 , carry out imaginary time evolution up to @xmath1000 , and calculate expectation values as for a pure state .",
    "we can even subject the purified state @xmath1001 to subsequent real time evolutions , to treat time dependence at finite @xmath1002 .",
    "we can also do thermodynamics quite simply , as @xmath1003 is given by the square of the norm of @xmath1001 and @xmath1004 .",
    "this means that we can obtain @xmath1005 by keeping the purified state normalized at all temperatures and by accumulating normalization factors as temperature goes down and @xmath941 increases . from @xmath1005",
    ", we have @xmath1006 . at the same time , @xmath1007 . but",
    "this in turn gives us @xmath1008 .",
    "further thermodynamic quantities follow similarly .",
    ", an imaginary time evolution is carried out up to `` time '' @xmath1000 . ]",
    "the purification of the infinite temperature mixed state is a simple mps of dimension 1 , because it factorizes ( if we take one ladder rung as a big site ) : @xmath1009 as @xmath990 factorizes , we can now purify the local mixed state on each physical site as a pure state on rung @xmath304 , to get @xmath1010 , then @xmath1011 , a product state or an mps of dimension 1 .",
    "if we consider some rung @xmath304 of the ladder , with states @xmath1012 and @xmath1013 on the physical site @xmath1014 and the auxiliary site @xmath1015 , we can purify as follows : @xmath1016 .\\ ] ] hence the purification is given by a maximally entangled state ( entanglement entropy is @xmath1017 ) , @xmath1018 it is easy to see that one can carry out local unitary transformations on both p and q separately that leave that structure invariant .",
    "for example , for the purification of a spin-1/2 chain it is advantageous to use the singlet state as local purification , @xmath1019,\\ ] ] in case the program knows how to exploit good quantum numbers : this state would allow to conserve total @xmath1020 and @xmath1021 at the same time . in this case , the four @xmath235-matrices would read @xmath1022 and the purified starting state @xmath999 for @xmath1023 is now given by a product of singlet bonds on a ladder .",
    "in fact , a svd of reshaped matrix @xmath1024 allows us to introduce truly site - local @xmath235-matrices , which have dimension @xmath1025 on odd and @xmath1026 on even sites : @xmath1027 \\quad a^{\\downarrow_{2i-1 } } = [ 0\\ \\ -1 ] \\quad a^{\\uparrow_{2i } } = [ 0\\ \\ 1/\\sqrt{2}]^t \\quad a^{\\downarrow_{2i } } = [ 1/\\sqrt{2 } \\ \\",
    "0]^t \\quad .\\ ] ] in order to apply the pure state time evolution algorithm , it remains to find the mpo .",
    "the ladder appearing in mixed state simulations can be mapped to a chain ( fig .  [",
    "fig : laddersetup ] ) , where the physical hamiltonian acts only on the odd sites , @xmath1028 , and the auxiliary sites are even , @xmath1029 . then the only non - trivial time - evolution connects @xmath1030 .",
    "there are several ways of dealing with such longer - ranged interactions , one explicitly constructing the longer - ranged interaction , the other using so - called swap gates , reducing it to a nearest - neighbour interaction .    the direct mpo description of the `` longer - ranged '' interaction @xmath1031 involves necessarily a non - trivial tensor on site @xmath850 , whereas the site @xmath14 is inert .",
    "similarly for @xmath1032 , there is a non - trivial tensor on @xmath14 , but site @xmath15 is inert .",
    "this suggests a trotter decomposition @xmath1033 in the `` odd '' and @xmath1034 in the `` even '' steps .",
    "the four - site evolution operator on sites 1 through 4 then reads @xmath1035 and we can build the three - site unitary with only a slight modification of the two - site unitary which contains the actual physical time evolution : @xmath1036 this three - site unitary is now subjected to two svds . for the notation , we first shift down the indices and reorder sitewise .",
    "reshaping with subsequent svds then iteratively isolates @xmath1037 , @xmath1038 , and @xmath1039 : @xmath1040}_{k_2,k_2 } ( v^\\dagger_{23})_{k_2,(\\sigma_3\\sigma'_3 ) } \\\\ & = &   \\sum_{k_2 } u_{(\\sigma_1 \\sigma'_1),(\\sigma_2\\sigma'_2 k_2 ) } s^{[2]}_{k_2,k_2 } ( v^\\dagger_{23})_{k_2,(\\sigma_3\\sigma'_3 ) } \\\\ & = & \\sum_{k_1,k_2 } u_{(\\sigma_1 \\sigma'_1),k_1 } s^{[1]}_{k_1,k_1 } ( v^\\dagger_{12})_{k_1 , ( \\sigma_2\\sigma'_2 k_2 ) } s^{[2]}_{k_2,k_2 } ( v^\\dagger_{23})_{k_2,(\\sigma_3\\sigma'_3 ) } \\\\ & = & \\sum_{k_1,k_2 } w^{\\sigma_1 \\sigma'_1}_{1,k_1 } w^{\\sigma_2 \\sigma'_2}_{k_1,k_2 } w^{\\sigma_3 \\sigma'_3}_{k_2,1 } \\end{aligned}\\ ] ] where , with the introduction of dummy indices and the inert tensor on site 4 : @xmath1041}_{k_1,k_1 } } \\\\",
    "w^{\\sigma_2 \\sigma'_2}_{k_1,k_2 } & = & \\sqrt{s^{[1]}_{k_1,k_1 } } ( v^\\dagger_{12})_{k_1 , ( \\sigma_2\\sigma'_2 k_2 ) } \\sqrt{s^{[2]}_{k_2,k_2 } } \\\\",
    "w^{\\sigma_3 \\sigma'_3}_{k_2,1 } & = & \\sqrt{s^{[2]}_{k_2,k_2 } } ( v^\\dagger_{23})_{k_2,(\\sigma_3\\sigma'_3 ) } \\\\",
    "w^{\\sigma_4 \\sigma'_4}_{1,1 } & = & \\delta_{\\sigma_4,\\sigma'_4}\\end{aligned}\\ ] ] from this , mpos for the entire chain can be formed as for the pure state time evolution .",
    "we have done nothing but the iterative decomposition of an mpo on 4 sites .",
    "again , this is still manageable , as only 4 sites are involved .",
    "obviously , it is a straightforward step to write an evolution operator acting on all four bonds @xmath1042 , @xmath1031 , @xmath1043 and @xmath1044 and subject it to a similar sequence of svds , which would allow to consider pure state time - evolution on a real ladder .",
    "an alternative approach to carry out interactions beyond immediate neighbours is provided by the use of _ swap gates_@xcite .",
    "let us take the example of a real ladder with interactions on four bonds , two of which [ @xmath1031 and @xmath1043 ] are next - nearest - neighbour interactions .",
    "but if we swapped states on sites @xmath1046 , they would be nearest - neighbour interaction .",
    "time - evolution on the ladder would then be done as follows : ( i ) evolve bonds @xmath1042 and @xmath1044 ; ( ii ) swap states on sites 2 and 3 , ( iii ) evolve `` new '' bonds @xmath1042 and @xmath1044 with the evolution operators for `` old '' bonds @xmath1031 and @xmath1043 and ( iv ) swap states on sites 2 and 3 once again . in other situations ,",
    "more astute schemes need to be found , preferrably generating a sequence of swaps between nearest neighbours .",
    "the swap operator for sites @xmath304 and @xmath439 is simply given by @xmath1047 is unitary and its own inverse .",
    "it swaps the physical indices of two sites in an mps ; for swaps between nearest neighbours it is easy to restore the original form of the mps : assume that the mps is left - normalized ; a unitary applied to sites @xmath304 and @xmath383 affects this only on these two sites . in particular , the orthonormality of block states @xmath1048 and @xmath1049 is not affected .",
    "if we introduce a matrix @xmath1050\\sigma_{i+1}}_{a_{i-1},a_i } a^{[i+1]\\sigma_i}_{a_i , a_{i+1}}$ ] , we can form @xmath1051 and carry out an svd , where @xmath1052 yields a new left - normalized @xmath1053 and @xmath1054 a new left - normalized @xmath1055 .",
    "that the latter is left - normalized follows from the left - normalization of @xmath1056 and the maintained orthonormality of the @xmath1049 .",
    "let me conclude this outlook on beyond - nearest - neighbour interactions with the remark that using mpo allows also other trotter decompositions , e.g. decomposing the heisenberg hamiltonian in its @xmath1057 , @xmath1058 and @xmath1059-dependent parts , useful for long - range interactions @xcite .",
    "a bit before time evolution with mps ( tmps ) was developed , two other algorithms were introduced to simulate the real - time dynamics of one - dimensional quantum chains , time - evolving block decimation ( tebd)@xcite and real - time or time - dependent dmrg ( tdmrg ) @xcite .",
    "both algorithms are also based on mps , but are different from tmps , when one looks more closely .",
    "before i get into that , let me stress however that all of them are based on the idea of time - evolving an mps which was first put forward in @xcite and therefore are minor variations on a theme .",
    "tdmrg and tebd are mathematically equivalent , i.e.  should for exact arithmetic give the same results , whereas numerically they are clearly distinct algorithms , both carrying out operations that have no counterpart in the other method , with their respective advantages and disadvantages .",
    "let us discuss first tdmrg , because its language is closer to that of tmps , and then tebd , to see how important ( or unimportant ) the little differences are .",
    "the decomposition of a global time - evolution on an entire lattice into a trotter sequence of infinitesimal time - evolutions on bonds is the same for all three algorithms discussed here .",
    "let us therefore focus on one infinitesimal time - evolution @xmath1060 on sites @xmath241 and @xmath288 . the evolution operator expressed in the local basis is given by @xmath1061 the current state @xmath1062 is given in the two - site dmrg notation with left- and right normalized matrices as @xmath1063 the time - evolution turns @xmath1064 into @xmath1065 this , together with the @xmath235 and @xmath269-matrices defines a valid dmrg state we call @xmath421 . in order to make progress , namely to apply @xmath1066 on the next pair of sites",
    ", we have to bring the state into the form @xmath1067 the changes can only concern sites @xmath241 through @xmath1068 : on the first two sites because of the action of the evolution operator , on the last two sites because they are brought into dmrg form .",
    "let us first generate the new @xmath235-matrices on sites @xmath241 and @xmath288 : we reshape @xmath1069 and subject it to an svd ( dmrg traditionally does this by a density matrix analysis and the dmrg prediction when shifting sites , leading to the same result ) : @xmath1070 @xmath149 can immediately be reshaped into a valid @xmath235-matrix , but has column dimension up to @xmath36 , which has to be truncated down to @xmath20 while maintaining the best approximation to the mps of dimension @xmath36 .",
    "the answer is provided as always by keeping just the @xmath20 largest singular values and shrinking the matrices @xmath149 , @xmath140 , @xmath158 accordingly .",
    "here lies the approximation of the method ( beyond the obvious trotter error ) .",
    "this done , we reshape as @xmath1071 and form @xmath1072 shifted by one site as @xmath1073 but we have to shift by another site , which we achieve by reshaping @xmath1074 as @xmath1075 , carry out an svd as done before , keep the states corresponding to the @xmath20 largest out of @xmath36 singular values , reshape , note down @xmath1076 and form @xmath1072 shifted by two sites as @xmath1077 the second svd and the associated truncation down to @xmath20 singular values does not lose further information , because there are at most @xmath20 non - zero singular values , although formally there could be @xmath36 of them .",
    "the reason is that before the time evolution on sites @xmath241 and @xmath288 , the schmidt rank across the bond @xmath288 was at most @xmath20 ( due to the mps construction ) .",
    "the schmidt rank of two states is however identical if they are related by a unitary transformation that acts on either part a or part b. but the infinitesimal time - evolution was a unitary on part a.    we can now continue with the next infinitesimal local time - evolution step , in the spirit of tmps .      here",
    ", we assume that we have @xmath32 in the @xmath678-notation , @xmath1078 } \\gamma^{\\sigma_2 } \\lambda^{[2 ] } \\ldots \\gamma^{\\sigma_{\\ell } } \\lambda^{[\\ell ] }   \\gamma^{\\sigma_{\\ell+1 } } \\lambda^{[\\ell+1 ] } \\gamma^{\\sigma_{\\ell+2 } } \\lambda^{[\\ell+2 ] }   \\gamma^{\\sigma_{\\ell+3 } } \\lambda^{[\\ell+3 ] } \\ldots \\gamma^{\\sigma_l }     { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$}}. \\label{eq : tebdstart}\\ ] ] this state can be immediately connected to the two - site dmrg notation . in particular ,",
    "@xmath1079 }   \\gamma^{\\sigma_{\\ell+1 } } \\lambda^{[\\ell+1 ] } \\gamma^{\\sigma_{\\ell+2 } } \\lambda^{[\\ell+2 ] }   .\\ ] ] this is identical to the dmrg @xmath44 , so is the evolution operator @xmath1080 , hence also @xmath1081 in order to proceed , the @xmath678-notation has to be restored on the two active sites . in perfect analogy to tdmrg ,",
    "one obtains by svd @xmath1082}_{a_{\\ell+1},a_{\\ell+1 } } ( v^\\dagger)_{a_{\\ell+1 } , ( \\sigma_{\\ell+2 } a_{\\ell+2 } ) } , \\ ] ] what is missing are @xmath571}$ ] and @xmath1083}$ ] .",
    "we therefore write ( reshaping @xmath149 and @xmath158 and omitting the @xmath667-indices ) @xmath1084 } ( \\lambda^{[\\ell]})^{-1 } u^{\\sigma_{\\ell+1 } }    \\lambda^{[\\ell+1 ] } v^{\\sigma_{\\ell+2}\\dagger } ( \\lambda^{[\\ell+2]})^{-1 }   \\lambda^{[\\ell+2 ] } .\\ ] ] now , as in tdmrg , there are up to @xmath36 singular values in @xmath1085}$ ] , which we truncate down to the @xmath20 largest ones , just as in tdmrg , also truncating the neighbouring matrices accordingly .",
    "we now introduce @xmath1086})^{-1}_{a_\\ell , a_\\ell } u^{\\sigma_{\\ell+1}}_{a_\\ell , a_{\\ell+1 } } \\quad   \\gamma^{\\sigma_{\\ell+2}}_{a_{\\ell+1},a_{\\ell+2 } } =   v^{\\sigma_{\\ell+2}\\dagger}_{a_{\\ell+1},a_{\\ell+2 } } ( \\lambda^{[\\ell+2]})^{-1}_{a_{\\ell+2},a_{\\ell+2}}\\ ] ] and obtain @xmath1084 }   \\gamma^{\\sigma_{\\ell+1 } }    \\lambda^{[\\ell+1 ] } \\gamma^{\\sigma_{\\ell+2 } }   \\lambda^{[\\ell+2 ] } , \\ ] ] back to the canonical form . in order to consider the time - evolution on the next bond",
    ", we have to carry out no svds , but just group @xmath1087 }   \\gamma^{\\sigma_{\\ell+3 } } \\lambda^{[\\ell+3 ] } \\gamma^{\\sigma_{\\ell+4 } } \\lambda^{[\\ell+4]}\\ ] ] and continue . as in tdmrg , no loss of information is associated with this step , but this is more explicit here .",
    "when @xmath20 becomes very large in high - precision calculations , singular values will tend to be very small , and dividing by them is , as mentioned previously , a source of numerical instability . in the context of the thermodynamic limit itebd method , which we will discuss later , hastings has proposed an elegant workaround that comes at very low numerical cost@xcite , but it can be easily adapted to finite - system tebd .",
    "let us assume that we start with a state in representation ( [ eq : tebdstart ] ) .",
    "we then group all pairs into right - normalized @xmath269-matrices , @xmath1088 } , \\ ] ] but remember the @xmath664}$ ] for later use .",
    "we then form @xmath1089 } \\gamma^{\\sigma_{\\ell+2 } } \\lambda^{[\\ell+2 ] } , \\ ] ] hence @xmath1090 } \\overline{\\psi}^{\\sigma_{\\ell+1 } \\sigma_{\\ell+2}}$ ] .",
    "we carry out the time - evolution on @xmath1091 to obtain @xmath1092 then @xmath1093 } \\overline{\\phi}^{\\sigma_{\\ell+1 } \\sigma_{\\ell+2}}$ ] . as before ,",
    "we carry out an svd on @xmath1094 , to obtain @xmath1082}_{a_{\\ell+1},a_{\\ell+1 } } ( v^\\dagger)_{a_{\\ell+1 } , ( \\sigma_{\\ell+2 } a_{\\ell+2 } ) } = a^{\\sigma_{\\ell+1 } } \\lambda^{[\\ell+1 ] } b^{\\sigma_{\\ell+2 } } .\\ ] ] truncating down to the @xmath20 largest singular values , we have found the new @xmath1095}$ ] , to be retained for further usage , and the new @xmath1096 .",
    "the new @xmath570 is given by @xmath1097 hence costs a simple matrix multiplication ; divisions have been avoided .",
    "for the last equation , we use right - normalization of @xmath1096 , hence @xmath1098}$ ] . at the same time , @xmath1099 } = ( \\lambda^{[\\ell]})^{-1 } a^{\\sigma_{\\ell+1 } }   \\lambda^{[\\ell+1]}$ ] . combining these two identities with @xmath1093 }",
    "\\overline{\\phi}^{\\sigma_{\\ell+1 } \\sigma_{\\ell+2}}$ ] gives the result .",
    "comparing tebd and tdmrg step by step , one sees immediately the complete mathematical equivalence of the methods .",
    "the second svd in tdmrg does nothing but shifting the boundary between left- and right - normalized matrices , which in tebd is simply achieved by a rebracketing of @xmath674 and @xmath666 . nevertheless , there are differences : tdmrg carries out two costly svd decompositions ( or density matrix analyses , which is equivalent ) per bond evolution , where tebd does only one . on the other hand , tebd encounters divisions by potentially very small singular values , which is a strong source of potential numerical inaccuracies ; but these can be eliminated @xcite at low numerical cost . from a numerical point of view , tdmrg is not just a translation of tebd , which came first , but an algorithm of its own , with strengths and weaknesses .",
    "both methods share the central feature that time evolution and truncation are intertwined : after each bond evolution , there is a truncation by svd .",
    "by contrast , tmps evolves all bonds first , and then truncates the entire state by compression of matrix dimensions @xmath1100 by svd or iteratively .",
    "tmps is the cleaner approach , but it can also be shown to be more precise .",
    "in fact , for real - time evolution it relates to tdmrg or tebd exactly as iterative variational compression to compression by svd , which implies that for small state changes ( e.g.  for very small time steps ) the difference goes down , as the interdependence of truncations becomes less severe , there being only very benign truncations . that the above relationship exists can be seen from compressing a tmps state not variationally , but by svd only :    take @xmath32 to be right - canonical , and do a tdmrg / tebd step on the first bond or tmps steps on all odd bonds .",
    "the truncation is now to be carried out by svd and my claim is that svd does not see a difference between the two very different time - evolved states . on the first bond itself ,",
    "all methods produce the same structure , but they differ on all other sites . whereas @xmath1101 is @xmath1102 where the @xmath1103-matrices come from the contraction with the time evolution bond operators .",
    "the svds on the first bonds are equivalent for both states provided both sets @xmath1104 and @xmath1105 generate sets of orthonormal states .",
    "this is indeed the case , because the @xmath269-matrices do this by definition , and the states generated by the @xmath1103-matrices are related to the first set of orthonormal states by a unitary transformation ( real - time evolution ! ) .",
    "this observation of the equivalence of methods also holds for bonds further down the chain .",
    "hence , the difference between the three algorithms becomes only visible at the level of variational compression .      in this section ,",
    "i have described basic algorithms for the time evolution of pure and mixed states .",
    "there were two sources of error .",
    "one of them is the trotter decomposition , which for an @xmath0th order decomposition generated an error @xmath1106 for each time step @xmath967 .",
    "as there are @xmath1107 time steps , the error will ultimately be @xmath1108 , i.e.  linear in time .",
    "this means it is only growing moderately in time and can be scaled down by smaller time steps and/or higher - order decompositions .",
    "this is common to all current methods @xcite .",
    "in fact , there are other methods of calculating matrix exponentials such as the krylov method@xcite or lookahead procedures such as in @xcite , which reduce this error even more . in any case",
    ", it is not very worrisome in the long run .    on the other hand",
    ", there is the error due to the truncation of the blown - up bond dimensions of the mps after each time step .",
    "this error is serious ; early on it could be shown to lead to errors exponentially blowing up in time @xcite . yet",
    "truncation errors are only the symptom , not the fundamental problem : the real reason is that  following the lieb - robertson theorem ",
    "entanglement @xmath140 can grow up to linearly in time for an out - of - equilibrium evolution of a quantum state : @xmath1109 , where @xmath133 is some constant related to the propagation speed of excitations in the lattice@xcite .",
    "this linear bound is actually reached for many quantum quenches , where a hamiltonian parameter is abruptly changed such that the global energy changes extensively . both from @xmath1110 and from a rigorous analysis",
    "@xcite it follows that in such cases the matrix dimensions will have to go up exponentially in time , @xmath1111 , or that for fixed matrix dimensions precision will deteriorate exponentially .",
    "nevertheless , in many circumstances matrix size growth is slow enough that numerical resources are sufficient to observe the time - dependent phenomenon of interest : time - dependent dmrg has been used extensively in the meantime and found to open completely new perspectives on the non - equilibrium behaviour of strongly correlated one - dimensional systems ( to name a few:@xcite ) .",
    "time evolution  whether it is done by tebd , tdmrg or tmps , to give the historical order  is fundamentally limited by the times that can be reached .",
    "the underlying reason is the ( at worst ) linear buildup of entanglement in time in an out - of - equilibrium quantum state , that translates itself into an ( at worst ) exponential growth of bond dimensions @xmath1112 if a given precision is desired .",
    "a `` time wall '' is hit exponentially fast .",
    "can one push it further into the future ?",
    "a similar issue arises for finite - temperature calculations . while they are not necessarily about dynamics , seen as imaginary time evolutions they raise their own problems , regarding the @xmath1113 limit for static or thermodynamic calculations , and regarding dynamics , there in particular at high temperatures .    a second issue that we have not covered so far concerns _ dissipative _ time evolution where we are not looking at a closed quantum system as in pure hamiltonian dynamics but at an open quantum system . if the dynamics is markovian ( i.e.  the bath has no memory , a highly non - trivial assumption in many cases ) , then the most general dynamics is given by the lindblad equation .",
    "while it is easy to show that formally this can be simulated using mps quite easily , in actual practice this is numerically involved and simpler schemes are highly desirable .    in this section",
    "we will first consider attempts to extend the time range of simulation by different schemes for evaluating the time evolution tensor networks . as we have already seen for simple examples like the evaluation of wave function overlaps , the order of contractions may hugely change the computational effort . in a second step",
    ", we will look at a prediction method that picks up on numerical raw data and extrapolates them very successfully over an order of magnitude , provided they meet a certain mathematical form , taking the case of finite temperature as an example . in a third step , we will look at an altogether different way of finite temperature simulations . in a last step ,",
    "i will take up the issue of dissipative dynamics and show neat progress made in that field .",
    "let us consider the calculation of the time - dependent expectation value @xmath1114 starting with @xmath32 , we evolve it up to time @xmath1 , obtaining @xmath955 .",
    "the expectation value then is calculated by sandwiching the two operators between @xmath1115 and @xmath955 , as discussed before .",
    "but we can represent this procedure also as the ( approximate ) contraction over a two - dimensional tensor network as shown in fig .",
    "[ fig:2dcontractiontime ] , which is then contracted line by line along the time direction , moving inwards .     and @xmath32 .",
    "the two arrays of mpos ( indicated by brackets ) represent @xmath1116 and @xmath939 in trotterized form ; i do not distinguish between different local mpos such as identity operators which show up on some sites of the left- and rightmost columns .",
    "in the central line , we put identity operators ( white squares ) and the operators to be evaluated .",
    "the dashed line indicates the buildup of contractions in time direction . ]    assuming @xmath1117 and @xmath0 mpos per trotter step ( e.g.  2 in first order ) , we have a lattice of @xmath1118 sites , i.e. of width @xmath5 and odd height @xmath1119 .",
    "if we call @xmath1120}$ ] the tensor located on the site in row @xmath304 and column @xmath439 ( like in a matrix ) , and if we label indices by up @xmath1121 , down @xmath31 , left @xmath1122 and right @xmath156 , and write @xmath1120}$ ] in analogy to mpos with indices @xmath1120u , d}_{l , r}$ ] , then we can identify , for example , for @xmath1123 ( location of the bra state ) : @xmath1124 1,d}_{1,r } = a^{[1]d*}_{1,r } \\quad t^{[1,j ] 1,d}_{l , r } = a^{[j]d*}_{l , r } \\quad t^{[1,l ] 1,d}_{l,1 } = a^{[l]d*}_{l,1}\\ ] ] where @xmath1125 .",
    "similarly for @xmath1126 ( location of the ket state ) : @xmath1127 u,1}_{1,r } = a^{[1]u}_{1,r } \\quad t^{[2nn+3,j ] u,1}_{l , r } = a^{[j]u}_{l , r } \\quad t^{[2nn+3,l ] u,1}_{l,1 } = a^{[l]u}_{l,1}\\ ] ] and on row @xmath1128 ( location of the operators ) : @xmath1129 u , d}_{1,1 } = \\left\\ { \\begin{array}{cl } \\hat{o}^{u , d } & { \\rm on\\ operator\\ location\\ } j \\\\ \\delta_{u , d } & { \\rm else } \\end{array } \\right\\ } .\\ ] ] in this row , horizontally the network is a product of scalars , hence the @xmath1130 . on all other rows , the tensors @xmath1120}$ ]",
    "are given by local mpos such that @xmath1120u , d}_{l , r}= w^{[\\alpha]u , d}_{l , r}$ ] on all rows @xmath1131 ( with the type @xmath885 depending on the chosen decomposition ) and @xmath1120u , d}_{l , r}= w^{[\\alpha]d , u*}_{l , r}$ ] on all rows @xmath1132 , which correspond to the time evolution of the bra .",
    "considering the time evolution of bra and ket together in fact allows important simplifications . in fig .",
    "[ fig : lightcone1 ] i have restored the alternating pattern of bond evolutions in a first order trotter decomposition and explicitly marked the position of unit operators by white squares .",
    "we would like to calculate @xmath1133 , where the operator sits on site 2 .",
    "let us look at the last trotter steps ( rows 5 and 7 ) . in row 5",
    "there are several evolution operators @xmath1134 with corresponding operators @xmath1135 in row 7 . but",
    "this means that they cancel each other and can be replaced by unit operators , except in columns 2 and 3 because they have @xmath66 interposed .",
    "if , in turn , we look now at rows 4 and 8 , there are now evolution operators cancelling each other in columns 5 through 8 ; the other ones do not cancel , as they sandwich non - identity operators . like this , we work our way towards the bra and ket states , until no cancellation is possible anymore .",
    "the resulting tensor network shows a large degree of replacements of complicated tensors of bond ( row ) dimensions larger than 1 by identity tensors with bond dimension 1 , which means that contractions become trivial and no compression is needed .",
    "there remains an algorithmic _ light cone _ of evolution operators that `` see '' the presence of a non - trivial operator @xmath66 to be evaluated .",
    "note that this algorithmic light cone is not to be confused with a physical light cone : if we send @xmath1136 , the algorithmic light cone becomes infinitely wide for any fixed time @xmath1 .",
    "physically , the lieb - robinson theorem states that beyond a `` light cone '' of width @xmath1137 , where @xmath133 is some problem - specific `` velocity '' , correlations decay exponentially fast , as opposed to the hard cut imposed by a relativistic light cone . the physical light cone and the special decay of correlations is at the basis of very interesting algorithmic extensions of the mps / tdmrg / tebd algorithms of the last section by hastings@xcite , which i will not pursue here .",
    "@xmath1138 @xmath1138 @xmath1138    while this structure becomes more complicated if we look , e.g.  at @xmath0-point correlators , we may look at a huge algorithmic saving , even though we have to pay the price that for different locations of operators , new networks have to be considered .",
    "what is the prize for calculating at different times , e.g.  @xmath1139 , @xmath1140 and so on ? this is a very natural question , as we might be interested in the time evolution of , say , some local density .",
    "if we do not use the light cone , then we simply calculate the contraction moving inwards , calculate some average , retrieve the stored result of the contraction up to the line with the operators , add more trotter steps , contract , calculate some average , and so on .",
    "this is exactly what we have been doing all along .",
    "of course , the light cone generated by the operator acting at time @xmath1141 is different from and larger than that generated by the operator acting at time @xmath1142 .",
    "but if the hamiltonian is time - independent , the larger light cone contains the smaller one at its tip .",
    "it therefore makes numerical sense to reverse the time evolution , and work from the future towards the past . but",
    "this corresponds to nothing else but a switch to the heisenberg picture .",
    "mathematically , the switch to the heisenberg picture is nothing but a rebracketing : @xmath1143 where we have introduced the time - dependent operator @xmath1144 if we trotterize the time evolutions present , we arrive exactly at the light cone structure of the last section , except that it has not been contracted yet with bra and ket ; fig .",
    "[ fig : heisenbergtime ]",
    ".     in the heisenberg picture , translated to the mps / mpo representation .",
    "each symmetric set of layers around the operator corresponds to one time step ( more precisely , part of a trotter time step ) .",
    "the light cone widens as a larger and larger section of the lattice is affected by @xmath66 .",
    "the identity operator ( white square ) is inserted for reasons of symmetry , but without explicit function . ]",
    "this allows to set up time evolution in the heisenberg picture @xcite.technically , one constructs a spatially growing mpo from mpo - mpo - multiplications as encountered e.g.  in the calculation of the action of @xmath930 .",
    "if the current mpo of the time - evolved operator consists of local mpos of the form @xmath1145 and bond dimension @xmath20 ( on sites @xmath304 where it actually has to be considered ) , and if the time evolution mpo ( for @xmath1146 ) reads @xmath1147 with bond dimensions @xmath723 , then the operator reads after ( part of ) the time step @xmath1148 with bond dimensions @xmath1149 .",
    "this operator is then compressed down to bond dimensions @xmath20 as explained earlier for mpos , essentially using the method for compressing mps .",
    "this sets up a `` conventional '' time evolution : instead of a state , an operator in mpo form is subjected to time evolution by mpos , and compressed to manageable matrix dimensions after each time step .",
    "we can basically recycle most of the algorithm .",
    "what are potential advantages and disadvantages of this formulation ?",
    "first of all , the savings due to the algorithmic light cone are immediately incorporated .",
    "second , we may hope that truncations are smaller : while the network contracted over is identical in the heisenberg and schrdinger picture , _ truncations _ in the schrdinger picture do not take into account the operator and hence are less specific - one may enviseage that for `` simple '' operators like local density a lot of the fine structure of the state evolution is not really needed , and evolving the operator itself tells us which information is needed specifically for this operator .",
    "a corresponding disadvantage is of course that calculations need to be redone for different operators , which in the schrdinger picture may be evaluated whenever one likes , provided the time - evolved wave function is stored .",
    "of course , here the corresponding advantage is that for different states one may evaluate whenever one likes , provided the time - evolved operator is stored .",
    "at the moment of writing it seems indeed that for simple operators the reachable time spans can be extended substantially , but i would find it hard to commit to some rule of thumb .      of course , the iterative build up of the state as it evolves in time appeals to our intuition about the world , but there is nothing that prevents us to contract the same network in the spatial direction , i.e.  column by column ; as the order of contraction may influence efficiency quite strongly , maybe it helps . in order to recycle existing programs ,",
    "one may simply rotate the current network by 90 degrees counterclockwise , and obtains a lattice of width @xmath1150 and height @xmath5 .",
    "if we continue to label tensors @xmath1120}$ ] by the vertical before the horizontal and in the row - column logic of a matrix , then tensors in the new lattice read @xmath1151 u , d}_{l , r } = t^{[l+1-j , i ] r , l}_{u , d } , \\ ] ] as can be seen from fig .",
    "[ fig : latticerotation ] .",
    "then we can contract again line by line .",
    "as it turns out , a simple rotation ( or transverse contraction ) does not extend the reachable timescale .",
    "it is by an additional _ folding _ step that a strong extension of the timescale is possible @xcite .",
    "the folding happens parallel to the new `` time '' ( i.e. real space ) axis , and halves the extent of the new `` space '' ( i.e. real time ) domain ( see fig .",
    "[ fig : latticefolding ] ) . instead of sites 1 through @xmath1119",
    "we then have double sites 1 through @xmath1152 , where double site 1 comprises old sites 1 and @xmath1153 , double site 2 comprises old sites 2 and @xmath1154 ; generally @xmath304 comprises old sites @xmath304 and @xmath1155 , up to the pair @xmath1156 .",
    "the site @xmath1152 is special : as we are folding an odd number of sites , one site remains single .",
    "this is site @xmath1152 , which corresponds to the line that contained the operators to be evaluated at time @xmath1 .",
    "on all the other sites , we fold tensors onto each other that correspond to `` identical '' timesteps , one forward and one backward in time .",
    "the expectation is that this folding of forward and backward timesteps leads to cancellations in entanglement buildup , such that larger times can be reached ( the growth in @xmath20 is not as fast ) .    to simplify notation ,",
    "we define @xmath1157 .",
    "if we read the bottom end of the folding as an mps , the folded state also starts with an mps whose matrices are formed as @xmath1158\\sigma_i}_{a^f_{i-1},a^f_i } = m^{f[i]\\sigma_i , \\sigma_{l'+1-i}}_{(a_{i-1},a_{l'+1-i}),(a_i , a_{l'-i } ) } = \\overline{t}^{[l , i]\\sigma_i}_{a_{i-1},a_i } \\overline{t}^{[l , l'+1-i]\\sigma_{l'+1-i}}_{a_{l'-i},a_{l'+1-i}}\\ ] ] for all @xmath1159 and @xmath1160\\sigma_{\\ell+1}}_{a^f_{\\ell},1 } = m^{f[\\ell+1]\\sigma_{\\ell+1}}_{(a_{\\ell},a_{\\ell+1}),1 }   = \\overline{t}^{[l,\\ell+1]\\sigma_{\\ell+1}}_{a_{\\ell},a_{\\ell+1}}.\\ ] ] we have defined @xmath444 `` fat '' local states @xmath1161 on each site , except site @xmath241 , where it remains of dimension @xmath31 ( for programming , one may of course introduce a dummy site ) .",
    "similarly , we construct the new tensors for the folded mpos .",
    "$ ] with time @xmath304 and space @xmath439 ( which after rotation refers to ficticious `` time '' and `` space '' ) tensor indices @xmath1121,@xmath31 and @xmath1122,@xmath156 exchange places as shown in the figure . ]     sites .",
    "sites corresponding to same times come to cover each other ( indicated by an ellipse ) ; the line on which operators are evaluated at final time remains single at the bend . ]",
    "if we assume that the original lattice and the hamiltonian acting on it were translationally invariant , at least for translations by an even number of lattice sites , we can write the contractions conveniently using a transfer operator .",
    "if we call the state on the first line ( first `` time '' slice ) of the folded lattice @xmath1162 ( corresponding to site @xmath5 of the original lattice ) and the one on the bottom line ( last `` time '' slice ) @xmath1163 , then ( @xmath304 odd for simplicity ) @xmath1164 here , we have introduced the transfer operators @xmath474 and @xmath1165 on stripes of length @xmath18 and width 2 , as represented in fig .",
    "[ fig : bigtransferoperator ] ( in unfolded , unrotated form for simplicity of representation ) .",
    "@xmath1165 is derived from @xmath474 by inserting @xmath66 instead of the identity at site @xmath241 .",
    "( dashed rectangle ; note direction of action ) in the unfolded , unrotated representation of the time evolution network .",
    "it repeats throughout the lattice by spatial translation by two sites , except on the sites with evaluation of an operator , where it is modified accordingly . ]",
    "this can be evaluated by iterative contractions and compressions for spatially finite lattices , but one can also take the thermodynamic limit .",
    "let us assume an eigenvector decomposition of @xmath474 as @xmath1166 note that @xmath474 is not hermitian , hence @xmath1167 and @xmath1168 are not adjoint , but distinct right and left eigenvectors . from the biorthonormality of those , @xmath1169 where i have assumed that the largest eigenvalue @xmath840 is non - degenerate ( which is usually the case ) and changed notation to @xmath1170 and @xmath1171 for the associated right and left eigenvectors .",
    "we then obtain in the thermodynamic limit as expectation value @xmath1172 where @xmath1173 .",
    "2-point correlators would then be given by @xmath1174 where @xmath156 is the number of transfer operators between the sites @xmath304 and @xmath439 .    in order to evaluate such expressions",
    ", we obviously need @xmath840 , @xmath1170 and @xmath1171 .",
    "as the components of @xmath474 are explicitly available , we can construct its transpose equally easily , hence reduce all to the determination of two right eigenvectors . as we are looking for the largest eigenvalue , the power method ( iterative application of @xmath474 to a guess vector ) will work .",
    "but one can equally read @xmath474 as the mpo representation of some non - hermitian operator , and reuse iterative ground state search techniques , with two modifications : the search for the lowest eigenvalue is replaced by the highest eigenvalue and the conventional lanczos algorithm has to be replaced by non - hermitian methods , either the biorthogonal lanczos algorithm or the arnoldi method .    while the coding is more involved than for standard time evolution , the timescales reachable are extended substantially , factors 3 to 5 seem easily possible .",
    "spectral functions @xmath1175 are among the most important theoretical and experimental quantities in many - body physics .",
    "while there are very accurate ways of calculating them directly at @xmath1176 @xcite , there is also an indirect approach , pioneered in @xcite , to calculate real - time real - space correlators like @xmath1177 , and to carry out a double fourier transform to momentum and frequency space .",
    "this approach has the advantage to extend to finite @xmath1002 seamlessly , but suffers from the limitations of reachable length and time scales .    of these , the limitations in time are much more serious , because of the rapid growth of entanglement in time .",
    "the time scales reachable are mostly so limited that a naive fourier transform gives strong aliasing or that one has to introduce a windowing of the raw data that smears out spectral information quite strongly .",
    "this limitation can be circumvented however at very low numerical cost by a linear prediction technique both at @xmath1176@xcite and @xmath1178@xcite that extends reachable @xmath1 and thereby greatly refines results in the frequency domain .    for a time series of complex data @xmath1179 at equidistant points in time @xmath1180 ( and maximal time @xmath1181 ) obtained by dmrg one",
    "makes a prediction of @xmath1182 . for the data",
    "points beyond @xmath1183 , linear prediction makes the ansatz @xmath1184 the ( predicted ) value @xmath1185 at time step @xmath0 is assumed to be a linear combination of @xmath1186 previous values @xmath1187 .",
    "once the @xmath1188 are determined from known data , they are used to calculate ( an approximation of ) all @xmath1189 with @xmath1190 .    the coefficients @xmath1188 are determined by minimizing the least square error in the predictions over a subinterval @xmath1191 $ ] of the known data ( corresponding to a set @xmath1192 ) , i.e.  we minimize in the simplest approach @xmath1193 .",
    "@xmath1194 is often a robust choice to have little short - time influence and enough data points .",
    "minimization of @xmath474 with respect to @xmath1188 yields the linear system @xmath1195 where @xmath199 and @xmath1196 are the autocorrelations @xmath1197 and @xmath1198 .",
    "( [ eq : linpred : stationaryerror ] ) is solved by @xmath1199 .",
    "one may wonder why extrapolation towards infinite time is possible in this fashion . as demonstrated below",
    ", linear prediction generates a superposition of oscillating and exponentially decaying ( or growing ) terms , a type of time - dependence that emerges naturally in many - body physics : green s functions of the typical form @xmath1200 are in time - momentum representation dominated by the poles ; e.g.  for a single simple pole at @xmath1201 with residue @xmath1202 , green s function will read @xmath1203 , and similarly it will be a superposition of such terms for more complicated pole structures .",
    "often only few poles matter , and the ansatz of the linear prediction is well suited for the typical properties of the response quantities we are interested in .",
    "where such an ansatz does not hold , the method is probably inadequate .    to see the special form of time - series generated by the prediction",
    ", we introduce vectors @xmath1204^t$ ] such that ( [ eq : predictionansatz ] ) takes the form @xmath1205 with @xmath1206 , \\ ] ] with the @xmath1188 as the elements of the vector @xmath1207 found above .",
    "prediction therefore corresponds to applying powers of @xmath235 to the initial vector @xmath1208 .",
    "a ( non - hermitian ) eigenvector decomposition of @xmath235 with eigenvalues @xmath1209 leads to @xmath1210_1=\\sum_{i=1}^p c_i \\alpha_i^m,\\ ] ] where coefficients @xmath1211 are determined from @xmath1208 and the eigenvectors of @xmath235 .",
    "the eigenvalues @xmath1209 encode the physical resonance frequencies and dampings .",
    "the connection is given as @xmath1212 .",
    "spurious @xmath1213 may appear , but can be dealt with@xcite .    at @xmath1176 ,",
    "critical one - dimensional systems exhibit power - law decays in their time - dependent correlators .",
    "the superposition of exponential decays is then taken to mimic these power - laws @xcite . at finite temperatures ,",
    "time - dependent correlators @xmath1214 decay typically exponentially for large times ( due to thermal broadening ) , making linear prediction especially well - suited for this situation .",
    "this is also close to typical experimental situations , like inelastic neutron scattering off one - dimensional magnetic chains .",
    "as example , let us consider a field - free heisenberg antiferromagnet with @xmath1215 ( @xmath1216-chain ) and @xmath1217 .",
    "the former case allows for an exact analytical solution .",
    "it turns out that prediction allows to extend time series @xmath1214 by over an order of magnitude without appreciable loss of precision . in frequency space",
    ", this corresponds to extremely high - precision spectral lineshapes ( figure [ fig : xychain ] ) .     of an @xmath1216-chain at temperatures @xmath1218 and @xmath1219 ( broad and narrow lineshapes ) for ( from the left ) @xmath1220 , @xmath1221 , @xmath1222 .",
    "the dashed lines are the shapes that would optimally be extracted from the @xmath1218 simulation without prediction using some windowing of the raw data before fourier transformation . adapted from @xcite . ]    as the dispersion relation of the @xmath1216-chain is just a simple magnon line , its self - energy structure is very simple , hence the prediction method easily applicable . as a more demanding example , we consider the spinon continuum of an isotropic @xmath1223 chain ; fig .",
    "[ fig : ushafm ] . in the zero - temperature limit , results agree extremely well with bethe - ansatz results ( where remaining differences are hard to attribute : the bethe ansatz here can only be evaluated approximately @xcite ) . at finite temperatures , simulations at different precision",
    "indicate that results are fully converged and essentially exact .",
    "this lets us expect that this method will be a powerful tool in e.g. simulating the results of neutron scattering experiments .    , bethe ansatz ( b.a . ) and numerics agree extremely well . adapted from @xcite .",
    "]      simulating thermal density operators for the calculation of static and dynamic properties works very well . theoretically , there are no limits to this method . in practice ,",
    "one encounters several limitations . on the one hand , simulations become difficult at very low temperatures @xmath1113 . in this limit ,",
    "the mixed state living on the physical system p will evolve towards the pure state projector on the ground state , @xmath1224 ( here",
    "i use @xmath1225 as the ground state of the physical hamiltonian @xmath9 , to refer to @xmath1226 as in the purification section ) .",
    "but in this limit p is not entangled with the auxiliary system q anymore , and we simulate a product of two pure states : assume for simplicity that the ground state energy is set to 0 .",
    "consider now the reduced density operator for the auxiliary system .",
    "up to an irrelevant norm , @xmath1227 because in the limit @xmath1228 the trace reduces to the ground state contribution , @xmath1229 . with the @xmath1023 purification of the density operator , @xmath1230 , the last expression reduces , again up to an irrelevant norm , to @xmath1231 where the @xmath1232 are the expansion coefficients of the ground state .",
    "hence , the zero temperature purification is a product state @xmath1233 where the latter state is just the physical ground state defined on the auxiliary state space . assuming that it can be described with sufficient precision using matrix dimension @xmath20",
    ", the product will be described by matrices of dimension @xmath609 .",
    "effectively this means that our algorithm scales with the sixth instead of the third power of the characteristic matrix dimension for the problem under study . on the other hand , and this is the issue prediction has tried to address , we encounter long - time simulation problems in particular at high temperatures @xmath1234 : many states contribute at similar , but not identical , weight and mps are not efficient at encoding this wealth of contributing states .    as white @xcite has pointed out",
    ", one can avoid the purification approach entirely by sampling over a cleverly chosen set of thermal states , the so - called _ minimally entangled typical thermal states _ ( metts ) .",
    "this approach has already been shown to alleviate strongly the first limitation , while not much is known yet about the second limitation .",
    "a thermal average is given by @xmath1235 where i have chosen , like all textbooks do , the energy representation of the thermal density operator .",
    "as already pointed out by schrdinger many decades ago , this is mathematically correct , but unphysical in the sense that real systems at finite temperature will usually not be in a statistical mixtures of eigenstates , as eigenstates are highly fragile under coupling to an environment .",
    "but the choice of the basis for taking the trace is arbitrary , and one may also write @xmath1236 where @xmath186 is an arbitrary orthonormal basis and @xmath1237 . with @xmath1238 ,",
    "we recognize @xmath1239 to be normalized .",
    "it is easy to see that @xmath1240 , hence the @xmath1241 are probabilities .",
    "one can therefore statistically estimate @xmath1242 by _ sampling _ @xmath1243 with probabilities @xmath1241 and average over @xmath1244 .",
    "several questions arise before this can be turned into a practical algorithm .",
    "how can we sample correctly given that we do not know the complicated probability distribution ?",
    "can we choose a set of states such that averages converge most rapidly ?",
    "given that an imaginary time evolution will be part of the algorithm , can we find a low - entanglement basis @xmath186 such that time evolution can be done with modest @xmath20 , i.e.  runs fast ?    to address these issues , white chooses as orthonormal basis the computational basis formed from product states , @xmath1245 classical ( unentangled ) product states ( cps ) that can be represented exactly with @xmath371 .",
    "the corresponding states @xmath1246 are so - called _ minimally entangled typical thermal states _ ( metts ) : the hope is that while the imaginary time evolution introduces entanglement due to the action of the hamiltonian , it is a reasonable expectation that the final entanglement will be lower than for similar evolutions of already entangled states . while this is not totally true in a strict mathematical sense , in a practical sense it seems to be ! compared to purification , this will be a much faster computation , in particular as the factorization issue of purification will not appear .    in order to sample the @xmath1243 with the correct probability distribution , which we can not calculate ,",
    "one uses the same trick as in monte carlo and generates a markov chain of states , @xmath1247 such that the correct probability distribution is reproduced . from this distribution",
    ", we can generate @xmath1248 , @xmath1249 , @xmath1250 , @xmath16 for calculating the average .",
    "the algorithm runs as follows : we start with a random cps @xmath1167 . from this",
    ", we repeat the following three steps until the statistics of the result is good enough :    * calculate @xmath1251 by imaginary time evolution and normalize the state ( the squared norm is @xmath1252 , but we wo nt need it in the algorithm ) . *",
    "evaluate desired quantities as @xmath1244 for averaging .",
    "* collapse the state @xmath1243 to a new cps @xmath1253 by quantum measurements with probability @xmath1254 , and restart with this new state .",
    "let us convince ourselves that this gives the correct sampling , following @xcite . as the @xmath1243 follow the same distribution as the @xmath1167 , one only has to show that the latter are sampled correctly .",
    "asking with which probability one collapes into some @xmath1255 provided the previous cps @xmath1167 was chosen with the right probability @xmath1241 , one finds @xmath1256 this shows that the desired distribution is a fixpoint of the update procedure .",
    "it is therefore valid , but it is of course sensible to discard , as in monte carlo , a number of early data points , to eliminate the bias due to the initial cps .",
    "it turns out that - after discarding the first few metts , to eliminate effects of the initial choice - averaging quantities over only a hundred or so allows to calculate local static quantities ( magnetizations , bond energies ) with high accuracy .",
    "while we already know how to do an imaginary time evolution , we still have to discuss the collapse procedure .",
    "as it turns out , the structure of mps can be exploited to make this part of the algorithm extremely fast compared to the imaginary time evolution .",
    "for each site @xmath304 , we choose an _ arbitrary _ @xmath31-dimensional orthonormal basis @xmath1257 , to be distinguished from the computational basis @xmath1258 . from this",
    "we can form projectors @xmath1259 with the standard quantum mechanical probability of a local collapse into state @xmath1260 given by @xmath1261 .",
    "if we collapse @xmath32 into the cps @xmath1262 , the probability is given by @xmath1263 , as demanded by the algorithm .",
    "after a single - site collapse , the wave function reads @xmath1264 where the prefactor ensures proper normalization of the collapsed state as in elementary quantum mechanics . to give an example , for @xmath3 spins measured along an arbitrary axis @xmath1265 , the projectors would read @xmath1266    such a sequence of local measurements and collapses on all sites can be done very efficiently , as pointed out by @xcite , if one exploits two features of mps and cps : ( i ) local expectation values can be evaluated very efficiently if they are on explicit sites ( in dmrg language ) or on sites between left- and right - normalized sites of a mixed - canonical state ( in mps language ) and ( ii ) after the collapse , the resulting state is a product state of local states on all collapsed sites and the uncollapsed remainder .",
    "assume that @xmath32 is right - canonical ( with the relaxation that the normalization on site 1 is irrelevant ) .",
    "then the evaluation of @xmath1267 trivializes because the contraction of the expectation value network over sites 2 through @xmath5 just yields @xmath1268 .",
    "hence @xmath1269 \\left [ \\sum_{\\sigma'_1 } b^{\\sigma'_1}_{a_1 } { \\mbox{$\\langle \\tilde{\\sigma}_1   | \\sigma'_1 \\rangle$ } } \\right ] .",
    "\\label{eq : probsinmetts}\\ ] ] this expression looks very specific to the first site ( because of the open boundary ) , but as we will see it is not !    once the probabilites for the collapse on site 1 are calculated , one particular collapse is chosen randomly according to the distribution just generated , @xmath1270 .",
    "the state after collapse will be of the form @xmath1271 , hence a product state .",
    "therefore , the new matrices ( which we call @xmath218 ) on site 1 must all be scalars , i.e.  @xmath371 matrices . from @xmath1272",
    "they are given by @xmath1273 it is easy to see that left - normalization is trivially ensured , hence the labelling by @xmath235 . but",
    "this change in the dimension of @xmath218 means that @xmath1274 has to be changed too , namely @xmath1275 as the label @xmath1276 takes a definite value , it is just a dummy index , and the row dimension of @xmath547 is just 1 , like for the matrices on the first site .",
    "hence , eq .  ( [ eq : probsinmetts ] ) generalizes to all sites , and the most costly step is the update of @xmath1274 , which scales as @xmath1277 , but not as @xmath1278 , as time evolution does",
    ".    to see the substitution , we express @xmath1279 as an mpo , @xmath1280 .",
    "hence , the collapsed @xmath32 reads @xmath1281 which yields the substitution .",
    "a few more comments are in order . at each site",
    ", the measurement basis can be chosen randomly , and in order to obtain short autocorrelation `` times '' of the markov chain , i.e.  high quality of the sampling , this is certainly excellent , but also much more costly than collapsing always into the same basis , which however generates ergodicity problems .",
    "the proposal is to switch alternatingly between two bases where for each basis projectors are maximally mixed in the other basis ( e.g.  if we measure spins alternatingly along the @xmath1057- and @xmath1059- ( or @xmath1058-)axis ) .",
    "autocorrelation times then may go down to 5 steps or so @xcite . for estimating the statistical error , in the simplest cases it is enough to calculate averages over bins larger than the autocorrelation time , and to look at the statistical distribution of these bin averages to get an error bar .",
    "intriguing questions remain , concerning both the potential and the foundation of the algorithm : how well will it perform for longer - ranged correlators , as needed for structure functions ?",
    "dynamical quantities can be accessed easily , as the time - evolution of the weakly entangled metts is not costly - but will the efficiency of averaging over only a few  typical \" states continue to hold ?",
    "dissipative ( i.e.  non - hamiltonian ) dynamics occurs when our physical system a is coupling to some environment b such that a is an _",
    "open _ quantum system .",
    "this is a very rich field of physics , so let me review a few core results useful here .",
    "the time evolution of the density operator of the system can always be written in the kraus representation as @xmath1282 where the kraus operators meet the condition @xmath1283 if the dynamics is without memory ( markovian ) , it depends only on the density operator at an infinitesimally earlier time , and a master equation , the lindblad equation , can be derived . in the limit @xmath1284 ,",
    "the environment remains unchanged with probability @xmath1285 and changes ( quantum jumps ) with a probability linear in @xmath1286 .",
    "if we associate kraus operator @xmath1287 with the absence of change , a meaningful ansatz scaling out time is @xmath1288 or more precisely @xmath1289 with two hermitian operators @xmath1290 and @xmath903 .",
    "the normalization condition of the kraus operators entails @xmath1291 these ansatzes allow to derive a differential equation from the kraus evolution formula , which is the lindblad equation @xmath1292 + \\sum_{j>0 } \\left ( \\hat{l}^j \\hat{\\rho } \\hat{l}^{j\\dagger } - \\frac{1}{2 } \\ { \\hat{l}^{j\\dagger } \\hat{l}^j , \\hat{\\rho } \\ }",
    "\\right ) , \\ ] ] where i have dropped the indices a. indeed , in the absence of quantum jumps ( @xmath1293 only ) , one recovers the von neumann equation . at the price of non - hermiticity , this equation can be simplified .",
    "if we introduce @xmath1294 , then the last term disappears and we have @xmath1295 + \\sum_{j>0 } \\hat{l}^j \\hat{\\rho } \\hat{l}^{j\\dagger } .",
    "\\label{eq : lindblad2}\\ ] ]    the simulation of lindblad equations is possible quite easily in the mps formalism , in particular using mpos @xcite , but also in the form of a superoperator formalism @xcite .",
    "the problem with this approach is that it is numerically more costly compared to the hamiltonian evolution of a state .",
    "a very attractive alternative , which allows maximal reusage of available pure state codes , has been proposed by @xcite , which combines pure state time evolution with the method of quantum trajectories .",
    "the method of quantum trajectories has been widely applied in quantum optics@xcite .",
    "instead of using the lindblad equation directly ( which takes into account both the probabilistic distribution of initial states through @xmath1296 and all possible sequences of quantum jumps ) , the quantum trajectory approach samples over the distribution of initial states , and for each of this sample states carries out a pure state time evolution where random quantum jumps occur at random times .",
    "they are chosen such that if one averages physical quantities over this distribution of time - evolving states , the result of the lindblad equation is recovered .",
    "let us ignore the sampling over initial states , assume that it is always the same , and instead focus on the conceptually more difficult averaging over quantum jumps .",
    "the algorithm then proceeds by generating @xmath1297 quantum trajectories in a time interval @xmath1298 $ ] ( where @xmath1002 is the final time of the simulation ) as follows :    * generate a starting state @xmath1299 ; it either samples the @xmath1300 density operator correctly or is simply always the same , depending on the physical problem . *",
    "choose a uniformly distributed random number @xmath1301 in @xmath1302 $ ] .",
    "* carry out , using one of our pure state time evolution methods , the time evolution of @xmath1299 under @xmath1303 .",
    "as the effective hamiltonian is non - hermitian , the norm of the state will decrease over time .",
    "stop the time evolution at time @xmath1142 , which is defined by @xmath1304 ; this is the time of the first quantum jump .",
    "note that if @xmath1305 , our simulation stops at @xmath1002 and we have a trajectory without jump , and we normalize the final state . * to carry out the quantum jump at @xmath1142 , we calculate @xmath1306 and choose a @xmath439 according to the normalized probability distribution @xmath1307 .",
    "* we carry out this jump and normalize the state , @xmath1308 * after this , we continue with finding a new @xmath1301 , from which time evolution of @xmath1309 with @xmath1303 generates @xmath1310 , the location of the second quantum jump , and so on , until @xmath1002 is exceeded .",
    "physical quantities up to time @xmath1002 are now averaged over the @xmath1297 quantum trajectories that have been generated .",
    "the correct probabilities are produced if all states are normalized at all times ; as this is not the case in the algorithm , norms at say time @xmath1 have to be taken into account .",
    "obviously , a careful analysis of convergence in @xmath1311 has to be carried out , but it seems that for a small number of jump operators , even a few 100 trajectories may give highly reliable results @xcite .    the observation that this sampling reproduces the dynamics of the lindblad equation is part of the standard literature on quantum trajactories . the proof can be done in two steps , which i just sketch here . in a first step ,",
    "one considers fixed time steps @xmath1286 , and calculates probabilities for no jump vs. jump @xmath439 in this time interval ( @xmath1312 , @xmath1313 ) .",
    "one then either time - evolves under @xmath1303 over @xmath1286 and normalizes , or does the jump and normalizes , according to the generated distribution .",
    "one can show that this reproduces the lindblad equation . in a second step ,",
    "one shows that the distributions of quantum jumps generated in this way and the one we use in the algorithm are identical .",
    "wilson s numerical renormalization group ( nrg ) @xcite originates in attempts to explain why metals with a small concentration of magnetic impurities exhibit a non - monotonic behaviour of resistivity .",
    "it was found that an adequate minimal model is provided by @xmath1314 this single - impurity anderson model contains an impurity site that can be occupied by up to two electrons ( operators @xmath1315 ) with on - site repulsion @xmath149 and which couples to a conduction band ( operators @xmath1316 ) with energy dispersion @xmath1317 through some hybridization function @xmath1318 .    in order to make it tractable , one changes from momentum to energy representation , assuming that only low - energy isotropic @xmath1319-wave scattering matters , and introduces logarithmic discretization : the band is represented by band segments of an energy width that decreases exponentially close to the fermi energy @xmath1320 .",
    "this accounts for the observation that the decisive feature of quantum impurity physics , namely the appearance of a very narrow resonance peak at the fermi energy in the local impurity spectral function , is linked exponentially strongly to the states close to the fermi energy .",
    "logarithmic discretization is however also required to make nrg work at all on a technical level !    after further manipulations , for which i refer to @xcite , the anderson hamiltonian is finally mapped to a semi - infinite chain of non - interacting sites with the exception of the first one : @xmath1321 where the @xmath1322 are fermionic operators .",
    "the crucial point is that the @xmath1323 decay exponentially , @xmath1324 , where @xmath666 is the shrinkage factor of the energy bands in the logarithmic discretization , usually a value of the order 1.5 to 2 .",
    "this is obviously a model that is amenable to our methods , e.g. a ground state search  as the hoppings decay exponentially , we will not have to consider a truly infinite chain .",
    "nrg builds on the observation that the exponential decay leads to a separation of energy scales : assuming we know the spectrum of the partial chain up to some length , all remaining sites will only make exponentially small corrections to it because of the exponentially small energy scales further down the chain . finding the ground state ( and more generally the low lying spectrum ) is now achieved by iterative exact diagonalization : assume that we have an effective @xmath20-dimensional eigenspace for some left - end part of the chain .",
    "then the next - larger chain has state space dimension @xmath1325 ; in order to avoid exponential growth , we have to truncate down to @xmath20 states .",
    "the nrg prescription is to diagonalize that system and to retain the @xmath20 lowest - lying eigenstates .",
    "starting out from very short chains that can still be done exactly , this procedure resolves the lowest - lying states exponentially well and is justified by the separation of energy scales : the decision which states to retain at some step would not be drastically changed with hindsight , as all further sites in the chain interact at much smaller energies .",
    "the obtained eigenspectra at different energy scales ( chain lengths ) can then be used to extract rg flow information or calculate thermodynamic or dynamic quantities for the impurity problem .",
    "given that the building block @xmath238 of an mps can be interpreted as encoding a decimation step upon growing a block by one site , irrespective of the decimation prescription , it is immediately obvious that nrg , like dmrg , can be seen as operating on mps@xcite .",
    "this closes a historical loop as in fact the analysis of failures of nrg naively applied to heisenberg and hubbard models gave rise to the development of dmrg .",
    "a nrg state would look like @xmath1326 at each length @xmath18 , we get a spectrum of @xmath20 states .",
    "given that dmrg is variational over the mps ansatz space , it is reasonable to expect that at least some improvement must be possible over the nrg method .",
    "in fact this is the case @xcite ; in the next section , i am going to discuss some improvements which are already firmly established and others which are more speculative , i.e.  where benchmarking on relevant complex problems is still lacking .",
    "in fact , considering an mps formulation of nrg helps even without resorting to the connection to variational methods like dmrg , as exemplified by the strict enforcement of certain sum rules @xcite , but this is outside the topic of this review paper .",
    "what we can do more , however , is to subject the final mps construction generated by nrg to dmrg - like sweeping .",
    "this will somewhat improve the quality of the ground state , but above all , the truncation procedure for high energies ( short chains ) will learn about truncation at low energies and vice versa . as opposed to nrg",
    ", there is now a feedback between energy scales . in that sense ,",
    "nrg for an impurity problem is a similar conceptual step as the warm - up procedure infinite - system dmrg provides for variational finite - system dmrg .    for logarithmic discretization ,",
    "energy scale separation is big enough that this effect is minor and for a simple single impurity problem with a focus on the abrikosov - kondo - suhl resonance the ultimate improvement is very limited , as nrg is geared to describe this feature optimally .",
    "the essential point is that energy scale separation can now be abandoned altogether due to feedback , hence also logarithmic discretization , and we may choose a more fine - grained resolution of the energy band wherever it is physically suitable . this could find a variety of applications .    in one application , variational calculus over mps was applied to an impurity problem in an external field .",
    "the external field leads to a splitting of the peak into two spin - dependent ones , shifted above and below the fermi energy . in figure",
    "[ fig : nrgdmrg ] we consider one of these peaks , using three techniques , nrg , an analytical approach@xcite , and variational mps ( dmrg ) calculus .",
    "nrg due to logarithmic discretization focuses on @xmath1320 and does not see the field - dependent peak at all",
    ". relaxing logarithmic discretization and providing sufficiently fine energy intervals around the expected peak positions away from @xmath1320 the shifted resonance can be resolved clearly and even in very good agreement with analytics .",
    "a second interesting application of this could be to replace nrg as an impurity solver in the context of the dynamical mean - field theory ( dmft ) @xcite .",
    "in that case , information beyond the metallic resonance at the fermi energy is required such that improving spectral resolution on other energy scales would be highly desirable .        as the semi - infinite chain is non - interacting but on the first site",
    ", one can think about unfolding it into an infinite chain of spin-@xmath1327 , with the impurity at the center and the presence or absence of spin - up or spin - down fermions corresponding to the 2 spin states , the left half of the chain corresponding to the spin - up fermions and the right half to the spin - down fermions @xcite .",
    "similar energies are now no longer grouped together , but in a dmrg - like approach this does not matter anymore !",
    "the intuition that spins that interact only through the central impurity might be essentially unentangled is corroborated by actual calculations .",
    "this is important as this means we will not pay a strong price by increased matrix dimensions . on the contrary : if in the nrg approach we are essentially looking at two uncoupled spin chains parallel to each other , this means that the corresponding mps has dimension @xmath1328 if the spin chain has dimension @xmath20 .",
    "we can therefore expect that a nrg calculation with state number @xmath20 can be replaced by a faster dmrg calculation with a state number @xmath1329 .    beyond this speedup",
    ", unfolding can of course also be applied if the impurity couples to multiple bands , where nrg becomes exponentially complex@xcite .",
    "the central site , of course , remains the same , and its numerical treatment can become extremely costly , such that new strategies have to be designed for that site .",
    "much work remains to be done here , but first interesting follow - ups on these ideas have been made@xcite .",
    "after the extensive discussion of finite - system algorithms , let us now reformulate infinite - system dmrg entirely in mps language .",
    "it is convenient to label local states a bit differently to account for the iterative insertion of sites ; we call the states @xmath1330",
    ". moreover , it will be very useful to give two labels to the matrices @xmath235 and @xmath269 , because the link between the matrices and the site on which they were generated will disappear .",
    "starting from blocks of size 0 ( i.e.  a chain of 2 sites ) , the ground state wavefunction is @xmath1331 .",
    "reading @xmath1332 as matrix @xmath1333 , it is singular - value decomposed as @xmath1334 } v^\\dagger_1 $ ] . from this",
    "we read off @xmath1335\\sigma_1^a}_{1,a_1 } = ( u_1)_{\\sigma_1^a , a_1 } \\quad\\quad b^{[1]\\sigma_1^b}_{a_1,1 } = ( v^\\dagger_1)_{a_1,\\sigma_1^b } .\\ ] ] @xmath235 and @xmath269 inherit left and right - normalization properties from @xmath149 and @xmath158 , and the state takes the form @xmath1336\\sigma_1^a } \\lambda^{[1 ] } b^{[1]\\sigma_1^b } { \\mbox{$| \\sigma_1^a \\sigma_1^b   \\rangle$ } } .\\ ] ] if we now insert two sites , and minimize the energy with respect to @xmath9 , we obtain @xmath1337\\sigma_1^a }   \\psi^{\\sigma_2^a \\sigma_2^b }   b^{[1]\\sigma_1^b } { \\mbox{$| \\sigma_1^a \\sigma_2^a \\sigma_2^b \\sigma_1^b   \\rangle$}},\\ ] ] where each @xmath1338 is a matrix with dimensions to match those of @xmath235 and @xmath269 , implicit matrix multiplications @xmath1339 assumed .",
    "reshaping this set of @xmath44-matrices into one , @xmath1340 svd gives @xmath1341 } v^\\dagger_2 $ ] , from which we can form @xmath1342\\sigma_2^a}_{a_1^a , a_2^a } = u_{(a_1^a \\sigma_2^a ) , a_2^a } \\quad\\quad    b^{[2]\\sigma_2^b}_{a_2^b , a_1^b } = v^\\dagger_{(a_1^b \\sigma_2^b ) , a_2^b}\\ ] ] such that @xmath1343\\sigma_1^a}a^{[2]\\sigma_2^a } \\lambda^{[2 ] } b^{[2]\\sigma_2^b}b^{[1]\\sigma_1^b }   { \\mbox{$| \\sigma_1^a \\sigma_2^a \\sigma_2^b \\sigma_1^b   \\rangle$}}.\\ ] ] at the @xmath18th step , the wavefunction will read @xmath1344\\sigma_1^a } \\ldots a^{[\\ell]\\sigma_\\ell^a } \\lambda^{[\\ell ] } b^{[\\ell]\\sigma_\\ell^b } \\ldots b^{[1]\\sigma_1^b }    { \\mbox{$| \\sigma_1^a \\ldots \\sigma_\\ell^a \\sigma_\\ell^b \\ldots \\sigma_1^b   \\rangle$}}\\ ] ] and look like in fig .  [",
    "fig : infinitedmrg_ab ] .    : a string of left - normalized @xmath235 , a string of right - normalized @xmath269 , joined by a diagonal singular value matrix @xmath571}$ ] .",
    "note that structurally the central unit does not repeat . ]",
    "of course , at each step we discard the smallest singular values and their associated singular vectors once matrix dimensions exceed @xmath20 , which is nothing but the density - matrix based truncation in the original formulation . at each step ( new chain length )",
    "we can write down @xmath9 for that length as an mpo and do the energy minimization .",
    "other operators find similar representations as in the finite - size case .",
    "let me briefly go through the reformulation of this algorithm in the @xmath678-notation . in the first step we simply rename @xmath235 and @xmath269 into @xmath674 , in line with the translation of boundary sites in the finite - system case : @xmath1345\\sigma_1^a } \\lambda^{[1 ] } \\gamma^{[1]\\sigma_1^b } { \\mbox{$| \\sigma_1^a \\sigma_1^b   \\rangle$ } } .\\ ] ] we then minimize @xmath1338 in @xmath1346\\sigma_1^a }   \\psi^{\\sigma_2^a \\sigma_2^b }   \\gamma^{[1]\\sigma_1^b } { \\mbox{$| \\sigma_1^a \\sigma_2^a \\sigma_2^b \\sigma_1^b   \\rangle$}},\\ ] ] and decompose it  as before  into @xmath1347\\sigma_2^a } \\lambda^{[2 ] } b^{[2]\\sigma_2^b}$ ] .",
    "now we define ( and due to the labelling , there is a slight change for the @xmath269-matrices compared to the finite - system setup ) @xmath1348}_a \\gamma^{\\sigma_2^a}_{ab } = a^{[2]\\sigma_2^a}_{ab } \\quad\\quad \\gamma^{\\sigma_2^b}_{ab } \\lambda^{[1]}_b = b^{[2]\\sigma_2^b}_{ab}\\ ] ] to arrive at @xmath1349\\sigma_1^a } \\lambda^{[1 ] } \\gamma^{[2]\\sigma_2^a } \\lambda^{[2 ] } \\gamma^{[2]\\sigma_2^b } \\lambda^{[1 ] } \\gamma^{[1]\\sigma_1^b }    { \\mbox{$| \\sigma_1^a \\sigma_2^a \\sigma_2^b \\sigma_1^b   \\rangle$ } } , \\ ] ] as represented in fig .",
    "[ fig : infinitedmrg_gl ] .",
    "we can now ask two questions : ( i ) in dmrg , finding the ground state by an iterative solver like lanczos is the most time - consuming part .",
    "can we find a speed - up by providing a good initial guess ?",
    "in finite - system dmrg the mps formulation automatically yielded white s prediction method , whereas attempts at speeding up infinite - system dmrg have been made in the past , meeting with mixed success@xcite .",
    "( ii ) can we use the information at the chain center to build a translationally invariant state ( up to period 2 ) in the thermodynamic limit , find its ground state or evolve it in time ?",
    "the answer is yes to both questions , and builds on the identification of a two - site repetititve structure in the states .",
    "as opposed to the @xmath1350-notation , where the central unit does not repeat itself even in the thermodynamic limit , it is very easy to read off a two - site repeat unit in the @xmath678-notation , given by @xmath1351 } \\gamma^{[\\ell]\\sigma_\\ell^a } \\lambda^{[\\ell ] } \\gamma^{[\\ell]\\sigma_\\ell^b } .\\ ] ] using the translation rules it can be translated into the @xmath235 , @xmath269-language : @xmath315\\sigma_\\ell^a } \\lambda^{[\\ell ] } b^{[\\ell]\\sigma_\\ell^b } ( \\lambda^{[\\ell-1]})^{-1 } .\\ ] ] this result can also be obtained directly from the @xmath235 , @xmath269 notation , but the argument is more complicated than in the @xmath678 notation .",
    "it is of course to be understood that repeating these state fragments does not generate the state they were taken from ; the claim is just that in the thermodynamic limit @xmath524 , when all sites are created equal , this repetition can come close . in any case , they are an educated guess about what the state will look like !     in the @xmath678-notation : @xmath674 and @xmath666 matrices alternate , and a possible identification of a ( repetitive ) two - site building block is given . ]",
    "we will now put this state fragment to multiple use , first on finite systems generated by infinite - system dmrg and then on thermodynamic limit states , both in the context of ground state searches and time evolutions . in the former case",
    ", it will provide a highly efficient guess for the next quantum state ; the evaluation of observables on this state proceed exactly as in the other finite systems . in the second case ,",
    "both ground state and time evolution algorithms can be formulated ( idmrg and itebd ) , which however necessitate both an ( identical ) analysis of the issue of orthonormality of states in the thermodynamic limit .",
    "the identification of the `` unit cell '' of the state allows us to define a good initial guess for infinite - system dmrg@xcite , which avoids all the problems encountered by previous authors and leads to a dramatic speed - up even for small chains , where the underlying assumption that the chain center is representative of the physics of the thermodynamic limit state is certainly wrong : in order to grow the chain , we simply insert one unit cell , even though for small chains the idea that the state is just a repetition of these unit cells is not well verified  but even then so much better than a random guess . starting from @xmath1352\\sigma_1^a } \\ldots a^{[\\ell-1]\\sigma_{\\ell-1}^a } ( a^{[\\ell]\\sigma_\\ell^a } \\lambda^{[\\ell ] } b^{[\\ell]\\sigma_\\ell^b } [ \\lambda^{[\\ell-1]}]^{-1 } ) \\lambda^{[\\ell-1 ] } b^{[\\ell-1]\\sigma_{\\ell-1}^b } \\ldots b^{[1]\\sigma_1^b } { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$}},\\ ] ] where the repeat unit has been bracketed out , the guess will then read @xmath1353\\sigma_1^a } \\ldots   a^{[\\ell-1]\\sigma_{\\ell-1}^a } \\times \\nonumber \\\\ & & ( a^{[\\ell]\\sigma_\\ell^a } \\lambda^{[\\ell ] } b^{[\\ell]\\sigma_{\\ell+1}^a } [ \\lambda^{[\\ell-1]}]^{-1 } ) ( a^{[\\ell]\\sigma_{\\ell+1}^b } \\lambda^{[\\ell ] } b^{[\\ell]\\sigma_\\ell^b }    [ \\lambda^{[\\ell-1]}]^{-1 } ) \\times \\nonumber \\\\ & &   \\lambda^{[\\ell-1 ] } b^{[\\ell-1]\\sigma_{\\ell-1}^b } \\ldots b^{[1]\\sigma_1^b } { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$ } } \\end{aligned}\\ ] ] or , multiplying out , @xmath1354\\sigma_1^a } \\ldots a^{[\\ell]\\sigma_\\ell^a } \\lambda^{[\\ell ] } b^{[\\ell]\\sigma_{\\ell+1}^a } [ \\lambda^{[\\ell-1]}]^{-1 } a^{[\\ell]\\sigma_{\\ell+1}^b } \\lambda^{[\\ell ] } b^{[\\ell]\\sigma_\\ell^b } b^{[\\ell-1]\\sigma_{\\ell-1}^b } \\ldots b^{[1]\\sigma_1^b } { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$ } } .\\ ] ] in this ansatz , we can now identify a guess for @xmath1355 as @xmath1356 } b^{[\\ell]\\sigma_{\\ell+1}^a } [ \\lambda^{[\\ell-1]}]^{-1 } a^{[\\ell]\\sigma_{\\ell+1}^b } \\lambda^{[\\ell ] } .",
    "\\label{eq : guess2sites}\\ ] ] from this ansatz , we can then iteratively find the @xmath1355 that minimizes the energy in the infinite - system dmrg framework , generating from it @xmath1357\\sigma_{\\ell+1}^a}$ ] , @xmath1095}$ ] , and @xmath1358\\sigma_{\\ell+1}^b}$ ] .    alternatively",
    ", the ansatz can be brought into in a more elegant form . at the moment , @xmath269-matrices show up on the a - side of the lattice and vice versa .",
    "but we can exploit our ability to canonize mps , and canonize @xmath571 } b^{[\\ell]\\sigma_{\\ell+1}^a}$ ] by svd to @xmath1357\\sigma_{\\ell+1}^a } \\lambda_r^{[\\ell]}$ ] , where @xmath235 is derived from @xmath149 and @xmath666 from @xmath1359 in the way described before ( @xmath1360 ) .",
    "similarly , we do a canonization from the right on @xmath311\\sigma_{\\ell+1}^b } \\lambda^{[\\ell]}$ ] to obtain @xmath1361 } b^{[\\ell+1]\\sigma_{\\ell+1}^b}$ ] , where @xmath269 is from @xmath158 .",
    "then we have an ansatz @xmath1354\\sigma_1 } \\ldots   a^{[\\ell+1]\\sigma_{\\ell+1 } } \\lambda^{[\\ell+1]}_{{\\rm guess } } b^{[\\ell+1]\\sigma_{\\ell+1 } }   \\ldots b^{[1]\\sigma_1 } { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$ } } , \\ ] ] where @xmath1362}_{{\\rm guess } } =   \\lambda_r^{[\\ell ] } [ \\lambda^{[\\ell-1]}]^{-1 } \\lambda^{[\\ell]}_l .\\ ] ] from this ansatz , we can then iteratively find the @xmath1095}$ ] that minimizes the energy , slightly modifying the minimization part of variational mps for a single site .",
    "in general , the result will not have the diagonal form resulting from an svd , because @xmath1363 and @xmath1364 are not diagonal to begin with .",
    "but an svd on it yields two unitaries that can be absorbed into the neighbouring @xmath235 and @xmath269 without affecting their normalization properties , such that the final @xmath1095}$ ] is diagonal . in this form",
    ", the algorithm can be represented as in fig .",
    "[ fig : infinitebuildup ] .",
    "as shown by mcculloch@xcite , this prediction leads to a dramatic speedup of infinite - system dmrg which complements nicely prediction algorithms of finite - system dmrg : the overlap between the predicted and calculated state often approaches unity up to @xmath49 or so !",
    "using the ideas of the preceding sections , it is very simple now to turn infinite - system dmrg into a performing and precise algorithm , called _ idmrg _ , referring to the thermodynamic limit version of dmrg :    * set up an infinite - system dmrg algorithm . *",
    "add the prediction procedure of the last section to the minimization algorithm .",
    "* run the modified algorithm until convergence is achieved .",
    "convergence of the wave function to the thermodynamic limit can be judged by considering the relationship eq .",
    "( [ eq : rhoarecursion ] ) @xmath1365\\sigma_\\ell } \\rho_a^{[\\ell ] } a^{[\\ell]\\sigma_\\ell\\dagger } = \\rho_a^{[\\ell-1 ] } , \\ ] ] where @xmath660 } = \\lambda^{[\\ell]}\\lambda^{[\\ell]\\dagger}$ ] and @xmath1366 } = \\lambda^{[\\ell-1]}\\lambda^{[\\ell-1]\\dagger}$ ] are the reduced density operators of the left half of the system .",
    "note that while this relationship holds always between reduced density operators in the same finite system , here they originate from systems of two different lengths @xmath1367 and @xmath1368 , such that this relationship is expected to hold only as a fixed point relationship for @xmath524 .",
    "following the same argument as for generating the ansatz for the larger system , we may transform @xmath311\\sigma_\\ell}\\lambda^{[\\ell]}$ ] to @xmath571}_l b^{[\\ell+1]\\sigma_\\ell}$ ] .",
    "then the left - hand side of the fixed point relationship simplifies , using right normalization , to @xmath571}_l\\lambda^{[\\ell]\\dagger}_l \\equiv \\hat{\\rho}^{[\\ell]}_l$ ] , and it becomes @xmath1369}_l = \\rho_a^{[\\ell-1]}$ ] .",
    "if this relationship holds to high accuracy , the thermodynamic fixed point has been reached .",
    "one way of measuring the closeness of the two density operators is given by the fidelity @xcite @xmath1370}_l , \\hat{\\rho}_a^{[\\ell-1 ] } ) = { { \\rm tr } } \\sqrt{\\sqrt{\\hat{\\rho}^{[\\ell]}_l}\\hat{\\rho}_a^{[\\ell-1 ] } \\sqrt{\\hat{\\rho}^{[\\ell]}_l } } .\\ ] ] inserting the definitions and using cyclicity properties of the trace , one can show that @xmath1371}_l , \\hat{\\rho}^{[\\ell-1]}_a ) = \\sum_i s_i$ ] , where @xmath1372 are the singular values of @xmath571}_l \\lambda^{[\\ell-1]\\dagger}$ ] .",
    "of course the algorithm can be stopped at any time , but then we have a finite system result which definitely can be improved by using finite - system dmrg . the convergence criterion given",
    "really gives us access to the thermodynamic limit state , which we might write down formally as @xmath1373\\sigma_i}\\lambda^{[\\ell ] } b^{[\\ell]\\sigma_{i+1 } } [ \\lambda^{[\\ell-1]}]^{-1}a^{[\\ell]\\sigma_{i+2}}\\lambda^{[\\ell ] } b^{[\\ell]\\sigma_{i+3 } } [ \\lambda^{[\\ell-1]}]^{-1}a^{[\\ell]\\sigma_{i+4}}\\lambda^{[\\ell ] } b^{[\\ell]\\sigma_{i+5 } } [ \\lambda^{[\\ell-1]}]^{-1 } \\ldots    { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$ } } , \\ ] ] where we take @xmath18 to be the iteration step when the convergence criterion is met .",
    "the question is now how to evaluate expectation values .",
    "obviously , we can not write down a finite network contraction as before ; it will be of infinite size and therefore can not be contracted naively .",
    "a contraction can only work if we can reduce the number to a finite number of contractions .",
    "for finite - system networks we saw that left- and right - orthonormality allow to eliminate most contractions : for observables on sites @xmath304 and @xmath439 , one only had to consider the contractions on and between these two sites .",
    "there is however no reason why the thermodynamic limit state should meet normalization criteria ; in fact , usually it does not .",
    "we therefore need an orthonormalization procedure .",
    "after that , expectation values can be evaluated as for a finite lattice with left- and right - orthonormalization . because this procedure is also important for the next algorithm and conceptually a bit more advanced ,",
    "i postpone it to an extra section .    at this point",
    "it should be mentioned that idmrg can be related to earlier algorithmic approaches under the name of pwfrg ( product wave function renormalization group ) @xcite which already contain part of the above ideas ; idmrg takes them to their natural completion @xcite .      in this section ,",
    "i switch to the @xmath678 notation , although the formulae can be easily translated into the @xmath1350-formulation . using our state fragment @xmath670 } \\gamma^{[\\ell]\\sigma_\\ell^a }",
    "\\lambda^{[\\ell ] } \\gamma^{[\\ell]\\sigma_\\ell^b}$ ] , we can set up an infinite chain @xmath1374 just like in the previous section , where @xmath1375\\sigma_\\ell^a}$ ] , @xmath1376\\sigma_\\ell^b}$ ] , @xmath1377}$ ] and @xmath1378}$ ]",
    ". the fragment may be the result of a converged ground state calculation or from some simple starting state that one can construct exactly .",
    "we can now write down a time evolution in the trotter form by applying an infinitesimal time step to all odd bonds ( which i will refer to as ab ) and then on all even bonds ( which i will refer to as ba ) .",
    "the bond evolution operators will be exactly as in the tmps / tdmrg / tebd cases , i will refer to them as @xmath1379 and similarly @xmath1380 .    as we have already seen [ cf .",
    "( [ eq : guess2sites ] ) ] , a full two - site fragment consists of a product of five matrices , @xmath1381",
    ". then time evolution on bond ab yields a set of matrices @xmath1382 upon the by now standard reshaping we obtain by svd @xmath1383 where the new @xmath1384 ( and correspondingly @xmath1385 and @xmath1386 ) are truncated as in tdmrg or tebd , to replace the old one . using @xmath1387 ( still from the last iteration ) , we can define new @xmath1388 and @xmath1389 ( via @xmath1390 and @xmath1391 ) .",
    "this defines a new `` unit cell '' .",
    "if we write it down and attach another one , we can read off the bond ba in the center of the two ab unit cells as @xmath1392 , for which time evolution gives @xmath1393 reshaping and svd gives us @xmath1394 where again @xmath1387 ( and correspondingly the other matrices ) are truncated and replace the old ones . using @xmath1384 ( still from the last iteration ) , we can define new @xmath1395 and @xmath1396 ( via @xmath1397 and @xmath1398 ) . the problematic division by small singular values can be avoided by the simple modification already discussed for tebd @xcite .    by applying sequences of infinitesimal bond evolution operators",
    "we can therefore set up a real or imaginary time evolution for the thermodynamic limit .",
    "this algorithm is referred to as _ itebd _ , because it provides the infinite - size generalization of tebd @xcite .",
    "again , the question of orthonormality arises @xcite .",
    "let us assume that the initial state was meeting orthonormality criteria .",
    "a pure real - time evolution generates a sequence of unitaries acting on the state , which preserves orthonormality properties .",
    "but the inevitable truncation after each time step spoils this property , even though truncation may only be small . to turn this method into a viable algorithm",
    ", we have to address the issue of orthogonalization in the thermodynamic limit , as for idmrg , after each step .",
    "let me mention here that mcculloch@xcite has shown that idmrg can be turned into itebd by replacing the minimization on the central bond by a time - evolution on the central bond , with some conceptual advantages over the original itebd algorithm .",
    "let me conclude this section by a few words on extrapolation . in finite - system dmrg ( or mps ) , the recipe was to extrapolate for each finite length @xmath5 results in @xmath20 to maximize accuracy , and then to extrapolate these results in @xmath5 to the thermodynamic limit . here",
    ", we are working directly in the thermodynamic limit ( assuming that idmrg has been taken to convergence ) , and the extrapolation in @xmath20 remains .",
    "interestingly , at criticality , this extrapolation in @xmath20 has profound and useful connections to entanglement entropy scaling and critical exponents @xcite .",
    "effectively , the finite matrix dimension introduces a finite correlation length into the critical system , not unlike the finite - system dmrg case , where the length scale on which the mps - typical superposition of exponentials mimicks a power - law properly also scales with some power of @xmath20 @xcite .      within idmrg on a finite system , @xmath235- and @xmath269-matrices",
    "retain left- and right - normalization ; this implies that the left and right block states are orthogonal among each other , as shown previously . we will call a state with this property _ orthogonal _ in a slight abuse of conventional usage . as we have seen in the previous section",
    ", we may use a fragment @xmath315\\sigma_\\ell^a}\\lambda^{[\\ell ] } b^{[\\ell]\\sigma_\\ell^b } ( \\lambda^{[\\ell-1]})^{-1}\\ ] ] that we can repeat to build up an infinitely long chain , @xmath1399 } b^{\\sigma_{i+1 } } ( \\lambda^{[\\ell-1]})^{-1}a^{\\sigma_{i+2}}\\lambda^{[\\ell ] } b^{\\sigma_{i+3 } } ( \\lambda^{[\\ell-1]})^{-1}a^{\\sigma_{i+4}}\\lambda^{[\\ell ] } b^{\\sigma_{i+5 } } ( \\lambda^{[\\ell-1]})^{-1 } \\ldots { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$ } } , \\ ] ] where i have simplified the notation of @xmath235 , @xmath269 .",
    "the problem with these states is that , for an arbitrary bipartition into two blocks , the states on the left and right blocks will in general _ not be orthogonal _ : if we transform @xmath571 } b$ ] into @xmath1400}$ ] as described above , the chain will read @xmath1401 where @xmath1402 } ( \\lambda^{[\\ell-1]})^{-1}$ ] . if we absorb @xmath611 into the @xmath410 to its left , @xmath1403 , the normalization condition becomes @xmath1404 in general , however , @xmath1405 .",
    "this is not only the case if @xmath18 is small and we are far from the infinite - system fixed point .",
    "it is also the case at the fixed point as long as the discarded state weight is finite , which is usually the case in dmrg calculations , even if it is very small .",
    "as pointed out by orus and vidal@xcite  in the presentation i follow @xcite  , a condition to detect orthonormality is to check whether the expectation value of the unit operator between two block states @xmath397 , @xmath1406 is @xmath1407 ( see fig .  [",
    "fig : infiniteorthogonalization ] ) .",
    "let us consider an expectation value contraction as for a finite system and assume we have carried it out up to site @xmath1408 , coming from the left , @xmath1409 .",
    "the result will be a matrix - like object @xmath1410 , corresponding to the open legs .",
    "let us now consider the operation @xmath1411 , which carries the contraction two steps further , i.e. over sites 1 and 2 .",
    "this _ transfer operator _ reads [ cf .",
    "[ subsubsec : transferoperator ] ] @xmath1412 for an orthonormal state , we want that @xmath1413 , which is just the expectation value matrix the unit operator produces for orthonormal block states",
    ". what we get , however , is , using the left - normalization condition , @xmath1414 .",
    "as the system extends to infinity , @xmath1413 must be associated with the largest eigenvalue ; normalizability of the entire state implies that the largest eigenvalue must be 1 .",
    "the `` quadratic '' form of @xmath1415 implies that the associated eigenmatrix @xmath1416 is hermitian and non - negative .",
    "an eigenvalue or singular value decomposition allows to decompose @xmath1417 , where @xmath298 is invertible .",
    "we can insert @xmath1418 after each @xmath611 , such that the unit cell becomes @xmath1419 and the new transfer operator reads @xmath1420 then @xmath1421 from the eigenmatrix properties of @xmath1416 with respect to @xmath1415 .",
    "( if the largest eigenvalue of @xmath1415 happens not to be 1 , @xmath298 must be suitably scaled . )",
    "inserting the definition of @xmath611 in @xmath1422 , undoing the transformation to @xmath410 , and transforming @xmath1423 } \\rightarrow \\lambda^{[\\ell]}_l \\tilde{b}^{\\sigma_1}$ ] , the unit cell becomes @xmath1424}_l \\tilde{b}^{\\sigma_1 } b^{\\sigma_2 } ( \\lambda^{[\\ell-1]})^{-1 } x^{-1}$ ] .",
    "shifting the starting point of the unit cell it becomes @xmath1425})^{-1 } x^{-1 } x \\lambda^{[\\ell]}_l \\tilde{b}^{\\sigma_1 } b^{\\sigma_2 } = q \\tilde{b}^{\\sigma_1 } b^{\\sigma_2}$ ] , where @xmath1426})^{-1 } x^{-1 } x \\lambda_l^{[\\ell ] } = ( \\lambda^{[\\ell-1]})^{-1 } \\lambda_l^{[\\ell]}$ ] , independent of @xmath298 . calculating a contraction from the right leads to a transfer operator @xmath1427 the same eigenvalue / eigenmatrix argument as before leads to the dominant eigenmatrix @xmath1428 , @xmath1429 invertible , and a unit cell @xmath1430 .",
    "this in turn leads to @xmath1431 with @xmath1432 .",
    "if we insert the definition of @xmath196 into the unit cell , return from @xmath1433 to @xmath218 and make @xmath196 explicit , the unit cell reads @xmath1434})^{-1 } x^{-1 } x a^{\\sigma_1 } \\lambda^{[\\ell ] } b^{\\sigma_2 } y$ ] , shifting its origin we obtain @xmath1435 } b^{\\sigma_2 } y y^{-1 }   ( \\lambda^{[\\ell-1]})^{-1 } x^{-1 } , \\ ] ] which can be brought back to the original form of the unit cell by setting @xmath1436 , @xmath1437 and @xmath670 } \\leftarrow x\\lambda^{[\\ell-1]}y$ ] , but now with _",
    "proper left- and right - normalization ensured .",
    "_    more precisely , the new unit cell leads to @xmath1438 and @xmath1439 . but",
    "note that @xmath1415 and @xmath1440 are constructed from slightly shifted unit cells , namely @xmath1423 } b^{\\sigma_2 } ( \\lambda^{[\\ell-1]})^{-1}$ ] for @xmath1415 and @xmath1425})^{-1 } a^{\\sigma_1 } \\lambda^{[\\ell ] } b^{\\sigma_2}$ ] for @xmath1440 , as shown in the pictorial representation .",
    "we can lump together the first and second unit cells into left- and right - normalized two - site matrices @xmath1441 and @xmath1442 .",
    "these can now be decomposed into left- and right - normalized matrices in the standard way , giving @xmath792\\sigma_1}a^{[2]\\sigma_2}$ ] and @xmath1443\\sigma_1}b^{[2]\\sigma_2}$ ] .",
    "note that these matrices are of course different from those we had originally .",
    "the thermodynamic limit state can now be written as @xmath1444\\sigma_1 } a^{[2]\\sigma_2 } a^{[1]\\sigma_3 } a^{[2]\\sigma_4 } \\ldots { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$}}\\ ] ] or analogously using @xmath1445}$ ] , for left- and right - canonical form .",
    "of particular interest for expectation values is the mixed - canonical form , with @xmath235-matrices on the left and @xmath269-matrices on the right . if we consider the two underlying unit cells , we see that at the boundary , both want to incorporate the same @xmath1425})^{-1}$ ] to generate @xmath235 and @xmath269-matrices .",
    "this problem can be solved by inserting the identity @xmath1446 } ( \\lambda^{[\\ell-1]})^{-1}$ ] after the problematic @xmath1425})^{-1}$ ] .",
    "then we can immediately write down a mixed - canonical form as @xmath1444\\sigma_1 } a^{[2]\\sigma_2 } a^{[1]\\sigma_3 } a^{[2]\\sigma_4 } \\lambda^{[\\ell-1 ] }   b^{[1]\\sigma_5 } b^{[2]\\sigma_6 } b^{[1]\\sigma_7 } b^{[2]\\sigma_8 } \\ldots { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$ } } .",
    "\\label{eq : infinitemixedcanonical}\\ ] ]      in finite systems , we have seen how an expectation value can be calculated by transferring an object @xmath1447}$ ] , starting as a dummy scalar @xmath449}=1 $ ] from @xmath1447}$ ] to @xmath1448}$ ] by means of a transfer operator @xmath1449}_o$ ] , where @xmath1450 is the locally acting operator in the expectation value structure ( mostly the identity , except , say , two sites if we are looking at a two - point correlator ) . in the case of the identity operator , for left - normalized matrices , the transfer operator mapping from left to right maps the identity to the identity ; similarly , the transfer operator mapping from right to left maps the identity to the identity if formed from right - normalized matrices .",
    "the same structure has been found in the last section for the thermodynamic limit state and its two two - site transfer operators @xmath1415 and @xmath1440 .",
    "this allows a direct transfer of the old results .",
    "assume we want to calculate @xmath1451 ; then we bring the state into the mixed - canonical form of eq .",
    "( [ eq : infinitemixedcanonical ] ) , with @xmath235-matrices up to site @xmath304 or @xmath383 ( depending on the odd - even structure ) , then @xmath670 } $ ] , followed by @xmath269-matrices up to infinity . contracting from the left over all @xmath235-matrices up to 0 and from the right all @xmath269-matrices , we obtain a remaining finite network as in fig .  [",
    "fig : finitecontractionremainder ] . this expectation value",
    "is then evaluated as in a finite network ; if we use the @xmath1447}$ ] and transfer operator notation , it starts from @xmath449}=i$ ] .",
    "the difference is that at the end , @xmath670}$ ] shows up in the contraction and the final reduction to a scalar is done by the closing @xmath1452 line ( which can be read as a trace ) : assuming the last site is @xmath304 , then the final expectation value is given in the last step as @xmath1453\\dagger } c^{[i ] } \\lambda^{[\\ell-1 ] } =   { { \\rm tr } } \\lambda^{[\\ell-1 ] } \\lambda^{[\\ell-1]\\dagger } c^{[i ] } = { { \\rm tr } } \\rho_a c^{[i ] } , \\ ] ] where we have used the relationship between @xmath666-matrices and reduced density operators in canonical representations .",
    "this calculation can be reduced easily to the case of the overlap of two states , which is just the matrix element of the unit operator between them .",
    "assume that both states are in translationally invariant form , e.g. by using left - normalized matrices @xmath792}$ ] and @xmath1347}$ ] ( and @xmath1454}$ ] , @xmath1455}$ ] respectively ) .",
    "we now carry forward an infinite overlap calculation by two sites ( say 1 and 2 ) towards the right using @xmath1415 : if the current overlap matrix is @xmath462 , it is carried forward as @xmath1456\\sigma_2\\dagger } \\tilde{a}^{[1]\\sigma_1\\dagger } c a^{[1[\\sigma_1 } a^{[2]\\sigma_2 } .\\ ] ] if we decompose @xmath462 in the eigenmatrices of @xmath1415 , in the thermodynamic limit only the largest eigenvalue contribution will survive . for an orthonormal state , for the overlap with itself ,",
    "@xmath1457 and @xmath1458 are the dominant eigenpair .",
    "a smaller @xmath519 in the overlap of two states can be interpreted as an overlap per site , while of course the two states are orthogonal with respect to each other in the thermodynamic limit ( overlap @xmath1459 ) . such thermodynamic overlaps ( or fidelities ) per site",
    "can be used very nicely to detect quantum phase transitions by overlapping ground states for two hamiltonians with slightly different parameters@xcite .",
    "after moving through this long list of topics , focussing on the fundamental algorithmic building blocks , ground state searches , thermodynamic limit algorithms and a wealth of real and imaginary time methods at zero and finite temperature , the possibilities of dmrg and mps - based algorithms are far from being exhausted .",
    "a few topics that i have not touched upon , but which i would like to mention briefly ( again in a non - exhaustive list ) , are : transfer matrix dmrg methods ( cf .  the introductory section for references ) , dmrg and mps with periodic boundary conditions , and as the most recent addition , mps for continuous space@xcite , which emerge as a beautiful generalization of coherent states and should allow for interesting applications in field theories . for _ periodic boundary conditions",
    "_ quite a lot of results already exist , so let me give just a brief overview .",
    "pbc have already been treated in the dmrg framework by introducing one long - ranged interaction between sites 1 and @xmath5 on an open - boundary chain ( see e.g.  @xcite ; however , the scaling of accuracy was consistently found to be much worse than for open boundary conditions .",
    "the underlying reason is ( roughly speaking ) that on a ring the surface between a and b doubles , hence the entanglement ; given the exponential relationship to the mps dimension , this means that resources have to go up from @xmath20 to up to @xmath609 , meaning that for similar accuracy , the algorithm needs the square of time ( sometimes referred to as @xmath1460-scaling , referring to the open boundary condition @xmath20 ) .",
    "the physically adequate ansatz for mps for periodic boundary conditions is given by eq .",
    "( [ eq : mpsforpbc ] ) ; one needs roughly the same @xmath20 as for obc , but rerunning the variational ground state search algorithm on it scales as @xmath1461 ( because the simplification of vectors instead of matrices on sites 1 and @xmath5 does not occur ) @xcite .",
    "at the same time , the simplification of the generalized to a standard eigenvalue problem does not occur , which may lead to bad conditioning .",
    "a nice feature of the mps representation for pbc is that one can generate eigenstates of momentum : for @xmath1462 and a ( non - translationally invariant ) mps @xmath1463\\sigma_1 } \\ldots a^{[l]\\sigma_l } ) { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$}}$ ] , the following state is a translationally invariant eigenstate of momentum @xmath980 : @xcite @xmath1464\\sigma_{1+n } } \\ldots a^{[l]\\sigma_{l+n } } ) { \\mbox{$| { \\mbox{\\boldmath$\\sigma$\\unboldmath } }   \\rangle$ } } .\\ ] ] recently ,",
    "interesting proposals to improve the @xmath1461 scaling have been made @xcite , and this is a field of ongoing interest .",
    "reference @xcite discusses this topic quite extensively .",
    "i think one may conclude by saying that while the fundamental framework of mps is by now very well established , and while dmrg has come of age as one of the most powerful numerical methods available for strongly correlated quantum systems , even in the well - established field of one - dimensional systems many of the algorithms presented will still allow further improvement , bringing new applications into our reach .",
    "it is in fact quite surprising that for quite a few of the methods presented ( and also the others ) very little is known about their detailed behaviour in real - world problems , analyzing which might give interesting further ideas . also , the ratio between applications done and applications doable seems very favourable for future exciting research .",
    "i would like to thank the aspen center for physics , the international center for theoretical physics in trieste , italy , and the wissenschaftskolleg ( institute for advanced study ) , berlin , where major parts of this work were carried out , for their hospitality .",
    "their combination of stimulating discussions and room for withdrawal to intensive work are a physicist s dream .",
    "thanks go of course to the many people i have discussed these subjects with and from whom i have learned a lot : mari - carmen banuls , thomas barthel , ignacio cirac , andrew daley , jan von delft , jens eisert , adrian feiguin , juanjo garcia - ripoll , fabian heidrich - meisner , corinna kollath , ian mcculloch , valentin murg , volker nebendahl , tomotoshi nishino , reinhard noack , tobias osborne , lode pollet , matthias troyer , frank verstraete , guifre vidal , andreas weichselbaum , steve white and tao xiang , to name but a few .",
    "special thanks go to matt hastings for pointing out an important paper of his and to stefan depenbrock for a very careful reading of an almost final version of this review ( all remaining errors were added afterwards ) ."
  ],
  "abstract_text": [
    "<S> the density - matrix renormalization group method ( dmrg ) has established itself over the last decade as the leading method for the simulation of the statics and dynamics of one - dimensional strongly correlated quantum lattice systems . in the further development of the method , </S>",
    "<S> the realization that dmrg operates on a highly interesting class of quantum states , so - called matrix product states ( mps ) , has allowed a much deeper understanding of the inner structure of the dmrg method , its further potential and its limitations . in this paper , </S>",
    "<S> i want to give a detailed exposition of current dmrg thinking in the mps language in order to make the advisable implementation of the family of dmrg algorithms in exclusively mps terms transparent . </S>",
    "<S> i then move on to discuss some directions of potentially fruitful further algorithmic development : while dmrg is a very mature method by now , i still see potential for further improvements , as exemplified by a number of recently introduced algorithms . </S>"
  ]
}