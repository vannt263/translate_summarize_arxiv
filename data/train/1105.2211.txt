{
  "article_text": [
    "in many real world problems , control decisions have to be made with limited information . obtaining extensive and accurate information about the controlled system",
    "can often be a costly and time consuming process . in some cases",
    ", acquiring detailed information on system characteristics may be simply infeasible due to high observation costs . in others",
    ", the observed system may be so nonstationary that by the time the information is obtained , it is already outdated due to system s fast - changing nature .",
    "therefore , the only option left to the controller is to develop a strategy for collecting information efficiently and choose a model to estimate the `` missing portions '' of the system in order to control it according to a given objective .",
    "a variant of this problem has been well - known in the control literature since 1960s as _ dual control_. the underlying concept in dual control is obtaining good process information through perturbation while controlling it .",
    "the controller has necessarily dual goals .",
    "first the controller must control the process as well as possible .",
    "second , the controller must inject a probing signal or perturbation to get more information about the process . by gaining more process information better control",
    "can be achieved in the future  @xcite .",
    "the problem considered here differs from the classical dual control problem in the very limited amount of information available to the controller .",
    "the controller here can not aim to identify the system first to obtain better performance in the future due to non - stationarity and/or prohibitive observation costs .",
    "furthermore , the perturbation idea is not fully applicable since each action - observation pair provides a single data point for identifying the nonlinear discrete - time system , unlike in the identification of ( linear ) continuous - time systems .",
    "this paper approaches the `` dual control '' problem from a bayesian perspective .",
    "gaussian processes ( gp ) are utilized as a state - of - the - art regression ( function estimation ) method for identifying the underlying state - space equations of the discrete - time nonlinear system from observed ( training ) data .",
    "more importantly , the adopted gp ( bayesian ) framework allows explicit quantification of information , which each observed data point provides within the a - priori chosen model .",
    "hence , the information collection goal can be explicitly combined with the control objectives and posed as a ( weighted - sum , multi - objective ) optimization problem based on one ( or multi- ) step lookahead .",
    "this results in a joint and iterative scheme of active learning and control .",
    "the proposed approach consists of three main parts : observation , update of gp for regression , and optimization to determine the next control action .",
    "these three steps , shown in figure  [ fig : model1 ] are taken iteratively to achieve the dual objectives of identification and control .",
    "observations , given that they are a scarce resource in the class of problems considered , play an important role in this approach .",
    "uncertainties in the observed quantities can be modeled as additive noise .",
    "likewise , properties ( variance or bias ) of additive noise can be used to model the reliability of ( and bias in ) the data points observed .",
    "gps provide a straightforward mathematical structure for incorporating these aspects to the model under some simplifying assumptions .",
    "the set of observations collected provide the ( supervised ) training data for gp regression in order to estimate the characteristics of the function or system at hand .",
    "this process relies on the gp methods , which will be described in subsection  [ sec : gp ] .",
    "thus , at each iteration an up - to - date description of the function or system is obtained based on the latest observations .",
    "the final step of the approach provides a basis for determining the next control action based on an optimization process that takes into account dual objectives .",
    "the information measurement aspect of these objectives will be discussed in subsection  [ sec : obsinfo ] .",
    "an important issue here is the fact that there are infinitely many candidate points in this optimization process , but in practice only a finite collection of them can be evaluated .",
    "the investigated approach incorporates many concepts that have been implicitly considered by heuristic schemes , and builds upon results from seemingly disjoint but relevant fields such as information theory , machine learning , optimization , and control theory .",
    "specifically , it combines concepts from these fields by    * explicitly quantifying the information acquired using the entropy measure from information theory , * modeling and estimating the ( nonlinear ) controlled system adopting a bayesian approach and using gaussian processes as a state - of - the - art regression method , * using an iterative scheme for observation , learning , and control , * capturing all of these aspects under the umbrella of a multi - objective `` meta '' optimization and control formulation .    despite methods and approaches from machine ( statistical ) learning are heavily utilized in this framework ,",
    "the problem at hand is very different from many classical machine learning ones , even in its learning aspect . in most classical application domains of",
    "machine learning such as data mining , computer vision , or image and voice recognition , the difficulty is often in handling significant amount of data in contrast to lack of it .",
    "many methods such as expectation - maximization ( em ) inherently make this assumption , except from `` active learning '' schemes @xcite .",
    "information theory plays plays an important role in evaluating scarce ( and expensive ) data and developing strategies for obtaining it .",
    "interestingly , data scarcity converts at the same time the disadvantages of some methods into advantages , e.g. the scalability problem of gaussian processes .",
    "it is worth noting that the class of problems described here are much more frequently encountered in practice than it may first seem .",
    "social systems and economics , where information is scarce and systems are very non - stationary by nature constitute an important application domain .",
    "the control framework proposed is further applicable to a wide variety of fields due to its fundamentally adaptive nature .",
    "one example is decentralized resource allocation decisions in networked and complex systems , e.g. wired and wireless networks , where parameters change quickly and global information on network characteristics is not available at the local decision - making nodes .",
    "another example is security and information technology risk management in large - scale organizations , where acquiring information on individual subsystems and processes can be very costly .",
    "yet another example application is in biological systems where individual organisms or subsystems operate autonomously ( even if they are part of a larger system ) under limited local information .",
    "this section summarizes the results in @xcite and presents the underlying methods that are utilized within the dual control framework .",
    "first , the regression model and gaussian processes ( gp ) are presented .",
    "subsequently , modeling and measurement of information is discussed using ( shannon ) information theory .",
    "the system identification problem here involves inferring the nonlinear function(s ) @xmath0 in the state - space equations describing the system using the set of observed data points .",
    "this is known as _ regression _ in machine learning literature , which is a _ supervised learning _",
    "method since the data observed here is at the same time the training data .",
    "this learning process involves selection of a `` model '' , where the learned function @xmath1 is , for example , expressed in terms of a set of parameters and specific basis functions .",
    "gaussian processes ( gp ) provide a nonparametric alternative to this but follow in spirit the same idea .",
    "the main goal of regression involves a trade - off . on the one hand",
    ", it tries to minimize the _ observed _ error between @xmath0 and @xmath1 . on the other , it tries to infer the `` real '' shape of @xmath0 and make good estimates using @xmath1 even at unobserved points ( generalization ) .",
    "if the former is overly emphasized , then one ends up with `` over fitting '' , which means @xmath1 follows @xmath0 closely at observed points but has weak predictive value at unobserved ones .",
    "this delicate balance is usually achieved by balancing the prior `` beliefs '' on the nature of the function , captured by the model ( basis functions ) , and fitting the model to the observed data .",
    "this paper focuses on gaussian process @xcite as the chosen regression method within the proposed dual control approach without loss of any generality .",
    "there are multiple reasons behind this preference .",
    "firstly , gp provides an elegant mathematical method for easily combining many aspects of the approach .",
    "secondly , being a nonparametric method gp eliminates any discussion on model degree .",
    "thirdly , it is easy to implement and understand as it is based on well - known gaussian probability concepts . fourthly , noise in observations is immediately taken into account if it is modeled as gaussian . finally , one of the main drawbacks of gp namely being computational heavy",
    ", does not really apply to the problem at hand since the amount of data available is already very limited .",
    "it is not possible to present here a comprehensive treatment of gp .",
    "therefore , a very rudimentary overview is provided next within the context of the control problem .",
    "consider a set of @xmath2 data points @xmath3 where each @xmath4 is a @xmath5dimensional vector , and the corresponding vector of scalar values is @xmath6 .",
    "assume that the observations are distorted by a zero - mean gaussian noise , @xmath7 with variance @xmath8 .",
    "then , the resulting observations is a vector of gaussian @xmath9 .",
    "a gp is formally defined as a collection of random variables , any finite number of which have a joint gaussian distribution @xcite .",
    "it is completely specified by its mean function @xmath10 and covariance function @xmath11 , where @xmath12\\ ] ] and @xmath13 ,   \\ ; \\forall x , \\tilde x \\in { \\mathcal}d.\\ ] ]    let us for simplicity choose @xmath14 .",
    "then , the gp is characterized entirely by its covariance function @xmath11 .",
    "since the noise in observation vector @xmath15 is also gaussian , the covariance function can be defined as the sum of a _ kernel function _ @xmath16 and the diagonal noise variance @xmath17 where @xmath18 is the identity matrix .",
    "while it is possible to choose here any ( positive definite ) kernel @xmath19 , one classical choice is @xmath20.\\ ] ] note that gp makes use of the well - known _ kernel trick _ here by representing an infinite dimensional continuous function using a ( finite ) set of continuous basis functions and associated vector of real parameters in accordance with the _ representer theorem _ @xcite .",
    "the ( noisy ) is positive definite . ]",
    "training set @xmath21 is used to define the corresponding gp , @xmath22 , through the @xmath23 covariance function @xmath24 , where the conditional gaussian distribution of any point outside the training set , @xmath25 , given the training data @xmath26 can be computed as follows .",
    "define the vector @xmath27\\ ] ] and scalar @xmath28 then , the conditional distribution @xmath29 that characterizes the @xmath30 is a gaussian @xmath31 with mean @xmath1 and variance @xmath32 , @xmath33    this is a key result that defines gp regression as the mean function @xmath34 of the gaussian distribution and provides a prediction of the function @xmath35 . at the same time , it belongs to the well - defined class @xmath36 , which is the set of all possible sample functions of the gp @xmath37 where @xmath38 is defined in ( [ e : gcov ] ) and @xmath39 through ( [ e : k ] ) , ( [ e : kappa ] ) , and ( [ e : gp1 ] ) , above .",
    "furthermore , the variance function @xmath40 can be used to measure the uncertainty level of the predictions provided by @xmath1 , which will be discussed in the next subsection .",
    "each observation provides a data point to the regression problem ( estimating @xmath0 by constructing @xmath1 ) as discussed in the previous subsection . _ active learning",
    "_ addresses the question of `` how to quantify information obtained and optimize the observation process ? '' .",
    "following the approach discussed in @xcite , the approach here provides a precise answer to this question .    making any decision on the next ( set of ) observations in a principled manner necessitates first _ measuring the information obtained from each observation within the adopted model_. it is important to note that the information measure here is dependent on the chosen model .",
    "for example , the same observation provides a different amount of information to a random search model than a gp one .",
    "shannon information theory readily provides the necessary mathematical framework for measuring the information content of a variable .",
    "let @xmath41 be a probability distribution over the set of possible values of a discrete random variable @xmath42 .",
    "the * entropy * of the random variable is given by @xmath43 , which quantifies the amount of uncertainty .",
    "then , the information obtained from an observation on the variable , i.e. reduction in uncertainty , can be quantified simply by taking the difference of its initial and final entropy , @xmath44    it is important here to avoid the common conceptual pitfall of equating entropy to information itself as it is sometimes done in communication theory literature . since",
    "this issue is not of great importance for the class of problems considered in communication theory , it is often ignored .",
    "however , the difference is of conceptual importance in this problem . in this case , ( shannon ) _ information is defined as a measure of the decrease of uncertainty after ( each ) observation ( within a given model)_. to apply this idea to gp , let the zero - mean multivariate gaussian ( normal ) probability distribution be denoted as @xmath45^t|c_p(x)|^{-1 } [ x - m]\\right),\\ ] ] where @xmath46 , @xmath47 is the determinant , @xmath48 is the mean ( vector ) as defined in ( [ e : gp1 ] ) , and @xmath49 is the covariance matrix as a function of the newly observed point @xmath46 given by @xmath50 .\\ ] ] here , the vector @xmath51 is defined in ( [ e : k ] ) and @xmath52 in ( [ e : kappa ] ) , respectively .",
    "the matrix @xmath53 is the covariance matrix based on the training data @xmath54 as defined in ( [ e : gcov ] ) .",
    "the entropy of the multivariate gaussian distribution ( [ e : multivargauss ] ) is @xcite @xmath55 where @xmath56 is the dimension .",
    "note that , this is the entropy of the gp estimate at the point @xmath57 based on the available data @xmath54 .",
    "the aggregate entropy of the function on the region @xmath58 is given by @xmath59    the problem of choosing a new data point @xmath60 such that the information obtained from it within the gp regression model is maximized can be formulated as : @xmath61 \\ , dx \\\\",
    "\\nonumber = \\arg \\min_{\\tilde x }   \\int_{x \\in { \\mathcal}x } \\dfrac{1}{2 } \\ln |c_q(x,\\tilde x)| dx,\\end{aligned}\\ ] ] where the integral is computed over all @xmath46 , and the covariance matrix @xmath62 is defined as @xmath63 , \\ ] ] and @xmath64 . here",
    ", @xmath53 is a @xmath23 matrix and @xmath65 is a @xmath66 one , whereas @xmath52 and @xmath67 are scalars and @xmath68 is a @xmath69 vector .",
    "this result from @xcite is summarized in the following proposition .",
    "[ thm : gpsearch ] as a maximum information data collection strategy for a gaussian process with a covariance matrix @xmath53 , the next observation @xmath60 should be chosen in such a way that @xmath70 where @xmath62 is defined in ( [ e : covxbar ] ) .",
    "when making a decision on the next action through multi - objective optimization , there are ( infinitely ) many candidate points .",
    "a pragmatic solution to the problem of finding solution candidates is to ( adaptively ) sample the problem domain @xmath58 to obtain the set @xmath71 that does not overlap with known points . in low ( one or two ) dimensions ,",
    "this can be easily achieved through grid sampling methods . in higher dimensions , ( quasi )",
    "monte carlo schemes can be utilized . for large problem domains ,",
    "the current domain of interest @xmath58 can be defined around the last or most promising observation in such a way that such a sampling is computationally feasible .",
    "likewise , multi - resolution schemes can also be deployed to increase computational efficiency .",
    "given a set of ( candidate ) points @xmath72 sampled from @xmath58 , the result in proposition  [ thm : gpsearch ] can be revisited .",
    "the problem in ( [ e : infocollect1 ] ) is then approximated @xcite by @xmath73 using monotonicity property of the natural logarithm and the fact that the determinant of a covariance matrix is non - negative .",
    "thus , the following counterpart of proposition  [ thm : gpsearch ] is obtained :    [ thm : gpsearch2 ] as an approximately maximum information data collection strategy for a gaussian process with a covariance matrix @xmath53 and given a collection of candidate points @xmath72 , the next observation @xmath74 should be chosen in such a way that @xmath75 where @xmath62 is given in ( [ e : covxbar ] ) .",
    "although it is an approximation , finding a solution to the optimization problem in proposition  [ thm : gpsearch2 ] can still be computationally costly .",
    "therefore , a greedy algorithm is proposed as a computationally simpler alternative . choosing the maximum variance @xmath60 as @xmath76 leads to a large ( possibly largest ) reduction in @xmath77 , and",
    "hence provides a rough approximate solution to ( [ e : infocollect2 ] ) and to the result in proposition  [ thm : gpsearch ] .",
    "this result from @xcite is consistent with widely - known heuristics such as `` maximum entropy '' or `` minimum variance '' methods @xcite and a variant has been discussed in @xcite .",
    "[ thm : gpsearch3 ] given a gaussian process with a covariance matrix @xmath53 and a collection of candidate points @xmath72 , an approximate solution to the maximum information data collection problem defined in proposition  [ thm : gpsearch ] is to choose the sample point(s ) @xmath78 in such a way that it has ( they have ) the maximum variance within the set @xmath72 .",
    "consider a nonlinear discrete - time representation of a dynamical system that evolves on a @xmath5dimensional state space @xmath79 steered by control actions chosen from an @xmath80dimensional space @xmath81 .",
    "usually , the dimension of the control space is smaller than the state one , @xmath82 .",
    "it is assumed here for simplicity that both control and state spaces are nonempty , convex , and compact .",
    "the system states evolve according to @xmath83 where @xmath84 , @xmath85 is a scalar , @xmath86 denotes discrete time instances , and each @xmath87 is a possibly nonlinear function .",
    "states of dynamical systems are , however , often not observable .",
    "therefore , define a mapping from the states to observable quantities @xmath15 as @xmath88 where each @xmath89 is possibly a nonlinear function , and @xmath90 .    if nothing is known about the dynamic system defined by ( [ e : dyn1])-([e : dyn1 ] ) in the beginning , and there is no observation or system noise , then the system can be simplified to its input - output relationship : @xmath91\\right ) \\\\",
    "\\rightarrow & y_j(t+1)=h_j \\left(y(t),u(t)\\right),\\ ; \\quad j=1,\\ldots,\\bar d \\ , ,   \\end{array}\\ ] ] where each @xmath92 is possibly a nonlinear function . as a simplification , system and observation noise",
    "can be modeled as zero - mean gaussian .",
    "thus , a noisy variant of system ( [ e : dyn3 ] ) is @xmath93 where @xmath94 and @xmath95 is the respective noise variance .",
    "the dual control problem is defined as follows .",
    "consider an unknown nonlinear discrete - time dynamic system , which has a control input and a ( partially ) observable output that is possibly distorted by noise .",
    "the control input may affect the system linearly , which leads to a simpler problem , or its effect may be nonlinear and unknown to the decision maker .",
    "the objective of the decision maker is to control the system in such a way that it follows a given reference signal .",
    "each action taken is assumed to be very costly and the decision maker may only have limited time to satisfy dual goals of identification and control .",
    "_ what is the best strategy to address this problem _ ?    based on the discussion above",
    ", the described problem can be formulated more concretely .",
    "let @xmath96 denote the @xmath97dimensional reference signal .",
    "the discrete - time nonlinear system can be modeled using ( [ e : dyn4 ] ) , where @xmath98 is the output , @xmath99 is the control action , and @xmath100 is the observation noise at time @xmath101 . then , the following dual control problem is formulated .",
    "[ prob : control1 ] [ _ dual control under limited information _ ] let a discrete - time system be described by the following input - output relationship @xmath102 where @xmath98 is the @xmath97dimensional output , @xmath99 is the @xmath80dimensional control action , and @xmath103 is a zero - mean gaussian observation noise with variance @xmath95 at time @xmath101 .",
    "the function @xmath92 is possibly nonlinear for all @xmath104 . given a @xmath97dimensional desired reference signal @xmath105 , what is the best control strategy ( series of control actions ) @xmath106 such that @xmath107 @xmath108 is a norm quantifying the mismatch between the observed and desired outputs ?",
    "if there was more information on the system available or more time for experimentation , one could have resorted to the rich literature on adaptive and robust control to find a solution .",
    "however , problem  [ prob : control1 ] differentiates from the ones in the classical adaptive and robust control literature by the fact that the decision maker starts with zero or very little prior information and a solution has to be found online while learning the system .",
    "this puts special emphasis on observations and quantifying information using the methods described in section  [ sec : obsinfo ] .    using gp regression for estimating the system dynamics in ( [ e : dyn4 ] ) and shannon information theory to measure and maximize the amount of information obtained with each observation",
    ", a model - based variant of problem  [ prob : control1 ] is defined .",
    "[ prob : control2 ] [ _ model - based control under limited information _ ] let a discrete time dynamic system be described by the following input - output relationship @xmath102 where @xmath98 is the @xmath97dimensional output , @xmath99 is the @xmath80dimensional control action , and @xmath103 is a zero - mean gaussian observation noise with variance @xmath95 at time @xmath101 .",
    "the function @xmath109 is possibly nonlinear for all @xmath104 .",
    "the goal is to control the system in such a way that the output @xmath98 follows a given @xmath97dimensional reference signal @xmath105 .",
    "let @xmath110 be an estimate of system dynamics @xmath111 based on an a priori model and a set of observations .",
    "what is the best control strategy ( series of control actions ) @xmath106 that solves the multi - objective problem with the following components ?    * _ objective 1 : _ @xmath112",
    "* _ objective 2 : _",
    "@xmath113    the main ( first ) objective of problem  [ prob : control2 ] is naturally the same as the one of problem  [ prob : control1 ] .",
    "the second objective states the `` exploration '' or information collection aspect .    as a side note ,",
    "unlike the static optimization problem in @xcite , how close the estimated system dynamic @xmath110 approximates the original one is not set as an objective .",
    "the reason behind this is the fact that the data points used for identifying @xmath110 can only be selected indirectly through control actions @xmath114 .",
    "therefore , a reasonably complete identification of the system dynamics may be too costly . a partial identification relevant to the main objective is sufficient for the purpose here .",
    "the solution approach to problem  [ prob : control2 ] utilizes the methodology in section  [ sec : methods ] .",
    "the gp variance maximization approximates here the information maximization objective .",
    "a ( random or grid - based ) sampling scheme is adopted again for evaluating candidate solutions , in this case , a combination of the observed current state and available control actions .",
    "a weighted - sum scheme is utilized to combine the two objectives in problem  [ prob : control2 ] .",
    "a visual depiction of the control framework is shown in figure  [ fig : model3 ] .",
    "since the problem is by its very nature iterative , the best control strategy has to be evaluated at the current state , taking into account newly received information and using the latest update of estimated system dynamics . as a starting point ,",
    "a gradient or greedy algorithm is proposed which aims to balance both exploration and exploitation objectives .",
    "[ prob : control3 ] let a discrete time dynamic system be described by the following input - output relationship @xmath115 @xmath116 , where @xmath103 is a zero - mean gaussian observation noise with variance @xmath95 .",
    "further let @xmath117 be a grid - based or randomly sampled set of available control actions @xmath114 from the control space @xmath118 . given a reference signal @xmath119 ,",
    "define the optimization problem @xmath120 where @xmath121 is the next estimated output using a gp based on control @xmath99 , and @xmath122 is the variance of the associated gaussian as defined in ( [ e : gp1 ] ) .",
    "the solution to this problem @xmath123 approximates the best control strategy under limited information , and hence approximately solves problem  [ prob : control2 ] .",
    "couple of remarks should be made at this point regarding the solution approach presented .",
    "firstly , the approach in proposition  [ prob : control3 ] constitutes a greedy one , which aims to solve the problem in shortest time based on available information and goes in the direction of the steepest gradient ( here of the weighted sum of objectives ) .",
    "the main concern here is whether such an algorithm gets stuck in a local minimum .",
    "this issue can be remedied at least partially by putting a higher weight to the information collection objective .",
    "secondly , it is implicitly assumed here that the system at hand is at least partially observable and controllable .",
    "it is naturally difficult , if not impossible , to check such properties of an unknown system .",
    "thus , the approach here can be interpreted also as a `` best effort '' one , which aims to achieve the best performance possible given controllability and observability limitations .",
    "a summary of the solution approach discussed above for a specific set of choices is provided by algorithm  [ alg : algctrl1 ] .",
    "problem domain , gp meta - parameters , objective weights @xmath124 $ ] , initial data set @xmath54 , reference signal @xmath125 , control actions @xmath117 .",
    "estimate the system dynamics ( i / o function ) @xmath110 using gp .",
    "compute the best control action @xmath126 solving ( [ e : contweigth1 ] ) . compute variance , @xmath127 , of @xmath110 as an estimate of @xmath128 . update the data set @xmath54 using newly observed data point @xmath15",
    "the logistic map @xmath129 parameterized by the scalar @xmath125 is a well - known one - dimensional discrete - time nonlinear system , where @xmath7 denotes the time step or iteration .",
    "it is chosen as an illustrative example due to its interesting properties and for visualization purposes . for @xmath130 ,",
    "logistic map converges to a limit cycle while it exhibits chaotic behavior for @xmath131 as shown in figure  [ fig : logisticmap ] .     and @xmath131 .",
    "]      first , the logistic map is controlled with additive actions while being identified using the gp method described in algorithm  [ alg : algctrl1 ] : @xmath132 the controller knows here that the control is linear ( additive ) , and utilizes this extra knowledge in identifying the system which simplifies the problem significantly . the system description ( input - output relationship ) from the perspective of the controller is : @xmath133 the control actions are taken from the finite set @xmath134 : u_{i+1}=u_i+0.02 , \\ ; i=1,\\ldots,101\\}.\\ ] ]    the kernel variance is @xmath135 and the weights in the objective function ( [ e : contweigth1 ] ) are chosen as @xmath136 .",
    "the goal is stabilize the system at @xmath137 , which constitutes the constant reference signal .",
    "the starting point is @xmath138 .",
    "the control actions and state estimation errors over time ( in each step based on arrived data points ) for @xmath130 and the corresponding trajectory of the logistic map are depicted in figures  [ fig : control2 ] and [ fig : trajectory2 ] .",
    "note that , in this case the logistic map acts only as a nonlinear system with a limit cycle rather than behaving chaotically .",
    "it is observed that approximately the first @xmath139 steps are used by the algorithm to explore or learn the system after which the trajectory approaches to the target .",
    "the figure  [ fig : mapping2 ] shows the estimated function versus the original mapping for @xmath140 as well as one standard deviation from estimated value .",
    "it can be seen that the variance is minimum , i.e. the estimate is best , around the target value .     and",
    "linear control . ]     and linear control . ]     and @xmath130 after @xmath141 iterations ( data points ) . ]",
    "the same numerical analysis is repeated for @xmath131 in which case the logistic map behaves chaotically and the task turns to from control of an unknown nonlinear system to control of an unknown chaotic system . in this case , the goal is to stabilize the system at @xmath137 .",
    "the control actions and state estimation errors over time ( in each step based on arrived data points ) for @xmath131 and the corresponding trajectory of the logistic map are depicted in figures  [ fig : control1 ] and [ fig : trajectory1 ] .",
    "note that the learning process takes longer in this case possibly due to the chaotic ( complex ) behavior of the system .",
    "the mapping shown in figure  [ fig : mapping1 ] shows the estimated function versus the original mapping for @xmath142 .     and linear control ]     and linear control . ]     and @xmath131 after @xmath141 iterations ( data points ) . ]",
    "next , the logistic map is controlled with actions that affect the system nonlinearly in a way that is unknown to the controller : @xmath143 the system description ( input - output relationship ) from the perspective of the controller is : @xmath144 compared to the linear and known control case , this problem is obviously much harder to address .",
    "the control actions are taken from the finite set @xmath145 : u_{i+1}=u_i+0.1 , \\ ; i=1,\\ldots,32\\}.\\ ] ] the weights in the objective function ( [ e : contweigth1 ] ) are chosen initially as @xmath146 and @xmath147 to emphasize exploration in the beginning but @xmath148 is increased gradually to @xmath149 to achieve as good control performance as possible .",
    "figures  [ fig : control3 ] , [ fig : trajectory3 ] , and  [ fig : mapping3 ] summarize the obtained results . since the objective of the algorithm  [ alg : algctrl1 ] is not only learning the entire system behavior but achieving the control target in a greedy manner , the system is estimated accurately only around the target value .",
    "it is observed that the learning process takes longer ( twice as much of the case in the linear control ) and the control actions are less accurate .",
    "it should be kept in mind , however , that concurrently identifying and adaptively controlling a chaotic system with limited information is not an easy task .     and",
    "nonlinear control . ]     and nonlinear control . ]     and @xmath131 after @xmath141 iterations ( data points ) . ]",
    "the inverted pendulum on a cart is a classic example system for control problems . in this case , the problem is formulated as the position control of the cart with the inverted pendulum , which is defined by the following set of discrete - time nonlinear state - space equations @xcite :    @xmath150    @xmath151 , \\end{aligned}\\ ] ]    @xmath152 ,   \\\\",
    "y(n)=x_1(n ) , \\quad \\label{e : cart5}\\end{aligned}\\ ] ]    where @xmath153 is the sampling period , @xmath154 is the position of the cart , @xmath155 is the cart velocity @xmath156 is the inverted pendulum angle , @xmath157 is the angular velocity .",
    "the parameter values are : @xmath158 , @xmath159 , @xmath160 , @xmath161 , and @xmath162 .",
    "further details on this standard model are available in @xcite .",
    "first , the cart is controlled using a one - step look - ahead strategy _ with full knowledge _ from the starting point @xmath163 $ ] with control actions chosen from the set @xmath164 : u_{i+1}=u_i+1 , \\ ; i=1,\\ldots,21\\}$ ] .",
    "the objective is to fix the position of the cart to @xmath165 .",
    "the weights in the objective function ( [ e : contweigth1 ] ) are @xmath146 and @xmath166 .",
    "the results of this case shown in figures  [ fig : invcontrol1 ] and [ fig : invtrajectory1 ] provide a benchmark to compare against .",
    "next , the cart is controlled using a one - step look - ahead strategy as a _ as black - box system _ ; @xmath167 . as side information",
    ", the controller knows ( [ e : cart1 ] ) , but has to estimate ( [ e : cart2 ] ) while ( [ e : cart3 ] ) and ( [ e : cart4 ] ) effectively act as external / unmodeled dynamics .",
    "the kernel and noise variance in gp are chosen as @xmath135 and @xmath168 , respectively .",
    "the results obtained using algorithm  [ alg : algctrl1 ] are shown in figures  [ fig : invcontrol2 ] and [ fig : invtrajectory2 ] .",
    "the performance is satisfactory considering that the trajectory is within @xmath169 distance of the target within @xmath170 steps .",
    "the book @xcite provides important and valuable insights into the relationship between information theory , inference , and learning , where measuring information content of data points using shannon information is discussed .",
    "however , focusing mainly on more traditional coding , communication , and machine learning topics , the book does not discuss the type of control problems presented in this paper .",
    "learning plays an important role in the presented framework , especially _ regression _ , which is a classical machine ( or statistical ) learning method .",
    "a very good introduction to the subject can be found in @xcite .",
    "a complementary and detailed discussion on kernel methods is in @xcite .",
    "another relevant topic is bayesian inference @xcite , which is in the foundation of the presented framework . in machine",
    "learning literature , gaussian processes ( gps ) are getting increasingly popular due to their various favorable characteristics .",
    "the book @xcite presents a comprehensive treatment of gps .",
    "additional relevant works on the subject include @xcite , which also discuss gp regression .",
    "gaussian processes have been recently applied to the area of optimization and regression @xcite as well as system identification @xcite . while the latter mentions active learning @xcite , neither work discusses explicit information quantification or builds a connection with shannon information theory . using gp for system identification is discussed again in @xcite , yet again without information collection aspects .",
    "the paper @xcite discusses in a static optimization setting objective functions which measure the expected informativeness of candidate measurements within a bayesian learning framework .",
    "the subsequent study @xcite investigates active learning for gp regression in machine learning applications using variance as a ( heuristic ) confidence measure for test point rejection .",
    "dual control is an old topic , which has attracted the interest of the research community in the second half of the last century @xcite .",
    "the article @xcite revisits this subject and incorporates information explicitly into the dual control problem , but focuses on estimation of parameters in a known , linear system . adopting a different perspective ,",
    "a dynamic programming approach is presented recently in @xcite , where an approximate value - function based reinforcement learning algorithm based on gps and its online variant are presented .",
    "an application of gp - based identification and control to an autonomous blimp is discussed in @xcite .",
    "the dual control approach presented in this paper addresses focuses on black - box control with very limited information .",
    "the information acquired at each control step is quantified using the entropy measure from information theory and serves as the training input to a state - of - the - art gaussian process regression ( bayesian learning ) method .",
    "the quantification of the information obtained from each data point allows for iterative and joint optimization of both identification and control objectives .",
    "the results obtained from two illustrative examples , control of logistic map as a chaotic system and position control of a cart with inverted pendulum , demonstrate the developed approach .",
    "the dynamic control problem in this paper differs from the static optimization analysis in @xcite in multiple ways .",
    "one of the main differences is the fact that the system states are now influenced indirectly through control actions .",
    "the data points used for identifying the underlying system mapping can only be selected indirectly ( unlike static optimization ) and under the constraints imposed by the nature of the `` control '' in the dynamic system at hand .",
    "the presented results should be considered mainly as an initial step .",
    "future research directions are abundant and include further investigation of the exploration - exploitation trade - off , more elaborate adaptive weighting parameters , and random sampling methods for problems in higher dimensional spaces .",
    "applications to multi - person decision - making and game theory constitute another interesting future research topic .",
    "this work is supported by deutsche telekom laboratories .",
    "p.  boyle , `` gaussian processes for regression and optimisation , '' ph.d .",
    "dissertation , victoria university of wellington , wellington , new zealand , 2007 .",
    "[ online ] .",
    "available : http://researcharchive.vuw.ac.nz/handle/10063/421      j.  ko , d.  klein , d.  fox , and d.  haehnel , `` gaussian processes and reinforcement learning for identification and control of an autonomous blimp , '' in _ ieee intl .",
    "conf . on robotics and automation _ ,",
    "april 2007 , pp . 742747 .",
    "d.  j.  c. mackay , `` introduction to gaussian processes , '' in _ neural networks and machine learning _ ,",
    "nato asi series , c.  m. bishop , ed .",
    "1em plus 0.5em minus 0.4emkluwer academic press , 1998 , pp .",
    "133166 .",
    " , `` information - based objective functions for active data selection , '' _ neural computation _ , vol .  4 , no .  4 , pp . 590604 , 1992 .",
    "[ online ] .",
    "available : http://www.mitpressjournals.org/doi/abs/10.1162/neco.1992.4.4.590          s.  seo , m.  wallat , t.  graepel , and k.  obermayer , `` gaussian process regression : active data selection and test point rejection , '' in _ proc .",
    "of ieee - inns - enns intl .",
    "joint conf . on neural networks",
    "ijcnn 2000 _ , vol .  3 , july 2000 , pp .",
    "241246 .",
    " , `` a neural network based method for solving discrete - time nonlinear output regulation problem in sampled - data systems , '' in _ advances in neural networks - isnn 2004 _ , ser .",
    "lecture notes in computer science , f.  yin , j.  wang , and c.  guo , eds.1em plus 0.5em minus 0.4em springer berlin / heidelberg , 2004 , vol . 3174 , pp .",
    "9797 , 10.1007/978 - 3 - 540 - 28648 - 6_9 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1007/978-3-540-28648-6_9    b.  wittenmark , `` adaptive dual control , '' in _ control systems , robotics and automation , encyclopedia of life support systems ( eolss ) , developed under the auspices of the unesco_.1em plus 0.5em minus 0.4emoxford , uk : eolss publishers , jan ."
  ],
  "abstract_text": [
    "<S> in many real world problems , control decisions have to be made with limited information . </S>",
    "<S> the controller may have no a priori ( or even posteriori ) data on the nonlinear system , except from a limited number of points that are obtained over time . </S>",
    "<S> this is either due to high cost of observation or the highly non - stationary nature of the system . </S>",
    "<S> the resulting conflict between information collection ( identification , exploration ) and control ( optimization , exploitation ) necessitates an active learning approach for iteratively selecting the control actions which concurrently provide the data points for system identification . </S>",
    "<S> this paper presents a dual control approach where the information acquired at each control step is quantified using the entropy measure from information theory and serves as the training input to a state - of - the - art gaussian process regression ( bayesian learning ) method . </S>",
    "<S> the explicit quantification of the information obtained from each data point allows for iterative optimization of both identification and control objectives . </S>",
    "<S> the approach developed is illustrated with two examples : control of logistic map as a chaotic system and position control of a cart with inverted pendulum . </S>"
  ]
}