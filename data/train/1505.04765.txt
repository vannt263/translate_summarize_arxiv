{
  "article_text": [
    "the underlying hopf algebraic strucuture of the process of renormalization was discovered first by kreimer in @xcite .",
    "further progress was made in formulating the renormalization procedure in the language of hopf algebra and doing explicit computations using this algebraic structure , in @xcite .",
    "the purpose of this article is to briefly review this algebraic structure . for simplicity , we avoid many of the technicalities of the quantum field theory by considering a simple toy model containing only nested divergences .",
    "issues related to overlapping divergences and more realistic field theoretic models have been discussed in literature ( see refs . @xcite and @xcite ) . for a more detailed review of this subject see @xcite .",
    "this article closely follows the conventions and notation used in @xcite . for a detailed treatment of renormalization procedure , see @xcite . for a mathematically rigorous introduction to hopf algebra ,",
    "see @xcite .",
    "the article is organized as follows . in section [ sec : pre ] , we describe necessary notation and conventions . in section [ sec : halgebra ]",
    "we explicitly construct the hopf algebra structure .",
    "for clarity of our arguments and construction , most of the proofs have been relegated to appendices .",
    "the article is concluded with a very simple example in appendix [ app : example ]",
    "a brief summary of the bphz renormalization procedure and the derivation of the forest formula is given in the appendix [ app : bphz ] .",
    "the key result of bphz renormalization is an iterative formula ( forest formula ) which gives a renormalized feynman graph in terms of the divergent graph , its subgraphs and the corresponding counter terms .",
    "forest formula can be written in a schematic form as follows : @xmath0 where @xmath1 and @xmath2 are bare and renormalized graphs respectivley .",
    "@xmath3 is the graph with all the subdivergences removed .",
    "the sum is over all non - empty proper forests of @xmath1 . @xmath4 and @xmath5 are counter terms .",
    "@xmath6 is a renormalization scheme dependent operator , which removes the overall divergence associated with graph @xmath1 . to make the notion of forest precise ,",
    "let @xmath7 be all 1pi , non overlapping divergent subgraphs of @xmath1 , then a proper forest of @xmath1 is any subset of the following set : @xmath8      we would like to represent feynman graphs in a more algebraic fashion such that their forest structure and subdivergences become manifest .",
    "this would be done by representing them as ` parenthesized words ' .",
    "parentheses encode information about the nestedness or the disjointness of the subdivergences and letters appearing in these words correspond to graphs without subdivergences .",
    "parenthesized words can be assigned to a graph by the following procedure :    * for every forest we write down a pair of brackets respecting the forest structure , i.e. , if a forest @xmath9 is inside a forest @xmath10 then the pair of brackets corresponding to the forest @xmath9 are contained inside the pair of brackets corresponding to @xmath10 . *",
    "consider a given pair of brackets , if we shrink all the brackets / forests inside it to a point the remainder is a graph @xmath11 without any subdivergences .",
    "we write the letter corresponding to @xmath11 next to the right closing bracket of the pair of brackets under consideration . *",
    "rest of what is contained in the pair under consideration is written to the left of this letter .",
    "for an example , consider the diagram in figure [ fig : twodiv ] .",
    "it has two disjoint subdivergences and is overall divergent when the subdivergences are shrunk to a point .",
    "the two subdivergences are contained in rectangular boxes .",
    "these subdivergences themselves are both 1pi and do not contain any subdivergences . in the figure",
    "we have also shown the letters corresponding to these subdivergences .",
    "it is easy to see that , using our rules above , this diagram corresponds to the parenthesized word @xmath12 .",
    "important features of this construction are following .",
    "* disjoint forests and configurations inside disjoint pair of brackets commute in this construction .",
    "i.e. , @xmath13 * only the forest structure of the graph is made manifest in this construction and we lose information about to which propagator or to which vertex of a graph @xmath14 another graph @xmath15 is attached . several different attachment can yield the same forest structure .",
    "hence any feynman diagram belongs to a class given by a parenthesized word .",
    "for example , the two diagrams in figure [ fig : samepw ] belong to the class represented by the parenthesized word @xmath16 . + ] * a letter @xmath17 has one and only one closing bracket on its right side while it can have more than one opening brackets .",
    "* we include the empty graph as @xmath18 which would act as a unit element ( not to be confused with the unit map ) in the construction of the hopf algebra .",
    "* an important characteristic of a parenthesized word is its length , which is simply the total number of letters @xmath17 appearing in it .",
    "for example , in collection ( [ coll ] ) , the parentheized words have lengths @xmath19 respectively . *",
    "in general we will have a class of feynman graphs represented by the notion of parenthesized words constructed out of letters @xmath17 .",
    "some examples are : @xmath20 * a parenthesized word , whose left most bracket is matched with its right most bracket is called an irreducible parenthesized word and corresponds to a 1pi feynman graph .",
    "examples are : @xmath21 an arbitrary irreducible parenthesized word can be represented as @xmath22 , where @xmath23 is an any parenthesized word . * a parenthesized word ,",
    "whose left most and the right most brackets do not match with each other is called a reducible parenthesized word and can be written as product of irreducible parenthesized words . for example @xmath24 is a reducible parenthesized word and is written as a product of two irreducible parenthesized words @xmath25 and @xmath26 .",
    "r0.4    hh & & & & hh & + m & + h & & k & & h & + m & + hh & & _ s & & hh & +    a detailed discussion of the mathematical properties of hopf algebra will lead us off topic . in this subsection",
    ", we will give the formal definition of a hopf algebra and different elements appearing in the definition .",
    "we will also give a rough sketch of how the procedure of renomalization can be described by an underlying hopf algebra structure .",
    "these notions will be made more precise in the next section .",
    "formally a hopf algebra is defined as following .",
    "[ defhopf ] a hopf algebra is an associative and co - associative bialbegra @xmath27 over a field @xmath28 with a k - linear map @xmath29 , called antipode such that the diagram [ fig : hopf ] commutes .",
    "@xmath30 are called unit , co - unit , product and co - product maps respectively .",
    "the condition for the commutativity of the diagram can be written algebraically as : @xmath31\\right]=m\\left[\\left({\\mathbf{1_d}}\\otimes s\\right)\\delta\\left[x\\right]\\right]=e\\circ \\overline{e}\\left[x\\right]\\label{hopfcom}\\end{aligned}\\ ] ] where @xmath23 is an element of hopf algebra and @xmath32 is the identity map .",
    "now we will give a brief overview of how renormalization would turn out to be related to the hopf algebra structure .",
    "* basic objects of the hopf algebra are feynman graphs @xmath1 which will be represented by the corresponding parenthesized word @xmath33 .",
    "representatives of the overall divergent graphs without subdivergences will be identified as the primitive elements of the hopf algebra .",
    "all other elements @xmath33 can be built out of these primitive elements . *",
    "the co - product resolves the graph into its forests .",
    "@xmath34=\\sum_{\\text{all forests } \\gamma}\\ x_{\\gamma}\\otimes x_{\\gamma/\\gamma}.\\end{aligned}\\ ] ] * we have a renormalization map @xmath35 , which extracts the divergent parts of a graph ( depending on the renormalization scheme ) . *",
    "the antipode @xmath36 gives the counter term @xmath5 through the renormalization map .",
    "@xmath37=-r\\left[x_{\\gamma}\\right]-\\ \\sum_{\\text{all non - empty proper forests } \\gamma}r\\left[s_r\\left[x_{\\gamma}\\right]x_{\\gamma/\\gamma}\\right].\\end{aligned}\\ ] ] * the renormalized feynman graph will related to the term @xmath38\\right]$ ] , appearing in the condition of the commutativity .",
    "we would indeed see that @xmath38\\right]=0 $ ] , expressing the fact that the we get a finite result .",
    "in this section we will construct the hopf algebra related to renormalization .",
    "this will be done by explicitly defining the all the maps and elements appearing in the definition ( [ defhopf ] ) .",
    "we will proceed in several steps , establishing algebra , co - algebra , bialgebra and finally hopf algebra structure .      as discussed in the previous section",
    ", we will represent feynman diagrams by parenthesized words .",
    "we will arrange these parenthesized words into an algebra structure here .",
    "let @xmath39 be the set of all parenthesized words .",
    "we regard this as a @xmath40 vector space .",
    "it is easy to see that @xmath39 is a vector space over @xmath40 .",
    "now , we introduce a bilinear product map as follows : @xmath41\\ \\equiv \\ \\ xy \\equiv yx,\\ \\ \\",
    "\\forall\\ x , y \\in \\mathcal{a}.\\label{defprod}\\end{aligned}\\ ] ] also we have an identity element @xmath42 which satisfies : @xmath43 to understand the product ( [ defprod ] ) consider the example with @xmath44 and @xmath45 then @xmath46 is a well defined product given by @xmath47 , i.e. , the product of two parenthesized words give a reducible parenthesized word . by introducing the product",
    "we have furnished @xmath39 with an algebra structure .",
    "now we define a homomorphism ( the unit map ) from @xmath40 to the set @xmath39 as follows : @xmath48&\\ \\equiv e,\\ \\ \\",
    "\\forall\\ \\text{rational numbers } q.\\label{defunit}\\end{aligned}\\ ] ] now , by definition , the bilinear product @xmath49 is associative , our algebra @xmath39 has an identitiy element @xmath50 and we have constructed a homomorphism from the field of rational numbers @xmath40 to algebra @xmath39 , this means that the set @xmath39 is a unital associative algebra .      in this subsection",
    ", we furnish @xmath39 with the structure of a coalgebra .",
    "let us first give the formal definition of a coalgebra .",
    "[ defcoalg ] a coalgebra , @xmath51 over a field @xmath28 is a vector space @xmath51 over @xmath28 together with linear maps @xmath52 ( counit ) and @xmath53 ( coproduct ) such that @xmath54 where @xmath32 is the identity map on @xmath51 , or quivalently , the two diagrams in figure [ fig : coalg ] commute . in the second diagram , we have identified the naturally isomorphic spaces @xmath51 , @xmath55,@xmath56 . the second equation above is also called the coassociativity condition for the coproduct @xmath57 .",
    "c & ^&cc & & & c&^ & & cc + & & & & + cc&_&ccc & & & cc & _ & & kccck    now , we will define the counit and the coproduct maps for the set @xmath39 under consideration .",
    "we define a counit by : @xmath58&\\equiv \\ 1,\\\\ & \\overline{e}\\left[x\\right]&\\equiv \\ 0,\\ \\",
    "\\forall\\ x\\neq e , \\in \\mathcal{a}.\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\label{defcounit}\\end{aligned}\\ ] ] this definition is motivated by the fact that there is no rational number which should be assigned naturally to an arbitrary parenthesized word and thus the counit annihilates feynman graphs . on the other hand",
    "we assign the rational number @xmath59 to the empty graph @xmath50 .",
    "the definition of the coproduct is more involved as compared to the elements defined so far .",
    "roughly speaking , coproduct yields a sum of terms @xmath60 , where the first terms , @xmath61 , are to be identified with divergent subgraphs and the second terms , @xmath62 , correspond to the remainder of the graph obtained by reducing @xmath63 to a point .    to give a rigorous definition of the coproduct , it will be useful to define a projection map @xmath64 as follows : @xmath65 it is easy to confirm the following properties of the map @xmath64 by explicit computation . @xmath66&=&0,\\ \\",
    "\\forall\\ x\\in \\mathcal{a},\\\\ p\\left[x\\otimes y\\right]&=&x\\otimes y,\\   \\ \\",
    "\\ \\forall\\",
    "x\\neq e,\\ y , \\in \\mathcal{a},\\\\ p^2&=&p.\\end{aligned}\\ ] ]    we also define a useful endomorphism @xmath67 , which is parametrized by a single letter @xmath17 , corresponding to a primitive graph .",
    "@xmath68&\\equiv \\left(xx_i\\right).\\end{aligned}\\ ] ] for example , @xmath69=\\left(\\left(x_2\\right)x_1\\right)$ ] . with the help of the maps @xmath64 and @xmath10",
    ", we are now in a position to define the coproduct as follows .",
    "@xmath70&\\ \\equiv\\ e\\otimes e,\\\\ & \\delta\\left[\\left(xx_i\\right)\\right]&\\ \\equiv\\ \\left(xx_i\\right)\\otimes e+e\\otimes\\left(xx_i\\right)+\\left({\\mathbf{1_d}}\\otimes b_{\\left(x_i\\right)}\\right)\\left[p\\left[\\delta\\left[x\\right]\\right]\\right].\\label{coprod}\\end{aligned}\\ ] ] this definition of the coproduct is complete .",
    "it is easy to use the above definition to show an important property of the coproduct . @xmath71&\\",
    "e + e\\otimes\\left(x_i\\right).\\label{coprodprim}\\end{aligned}\\ ] ] another important property of the coproduct is : @xmath72&\\   \\equiv \\",
    "\\delta\\left[x\\right]\\delta\\left[y\\right].\\label{compatcoprod}\\end{aligned}\\ ] ] this can also be shown by using the definition ( [ coprod ] ) , however the proof is a bit involved .",
    "the proof is based on the standard induction argument on the length of the words @xmath23 and @xmath73 .    another way to write the coproduct is by using the sweedler s notation , @xmath74=\\sum_x x_1\\otimes x_2 $ ] , where the sum is over the subwords @xmath75 of @xmath23 and @xmath76 .",
    "proof of this assertion is given in appendix [ app : sweed ] . using this notation and the properties of the map @xmath64 , we can write the equation ( [ coprod ] ) of the coproduct as : @xmath77=\\left(xx\\right)\\otimes e + \\left({\\mathbf{1_d}}\\otimes b_{\\left(x\\right)}\\right)\\left[\\sum_x x_1\\otimes x_2\\right]\\label{coprodsweed}.\\end{aligned}\\ ] ]    let us now consider a few example to explain how the coproduct acts on the elements of the set @xmath39",
    "@xmath78}&=&{\\left({\\left(x_i\\right)}x_j\\right)}\\otimes e + e\\otimes { \\left({\\left(x_i\\right)}x_j\\right)}+{\\left({\\mathbf{1_d}}\\otimes b_{{\\left(x_j\\right)}}\\right)}p{\\left(\\delta{\\left[{\\left(x_i\\right)}\\right]}\\right)},\\\\ & = & { \\left({\\left(x_i\\right)}x_j\\right)}\\otimes e + e\\otimes { \\left({\\left(x_i\\right)}x_j\\right)}+{\\left({\\mathbf{1_d}}\\otimes b_{{\\left(x_j\\right)}}\\right)}{\\left[{\\left(x_i\\right)}\\otimes e\\right]},\\\\ & = & { \\left({\\left(x_i\\right)}x_j\\right)}\\otimes e + e\\otimes { \\left({\\left(x_i\\right)}x_j\\right)}+{\\left(x_i\\right)}\\otimes { \\left(x_j\\right)}.\\label{eq : exampledel1}\\end{aligned}\\ ] ] 2",
    ".   using the similar method ( but after more tedious algebra ) we can also compute : @xmath79}=&&{\\left({\\left(x_i\\right)}{\\left(x_j\\right)}x_k\\right)}\\otimes e + e\\otimes { \\left({\\left(x_i\\right)}{\\left(x_j\\right)}x_k\\right)}+{\\left(x_i\\right)}\\otimes { \\left({\\left(x_j\\right)}x_k\\right)}\\nonumber \\\\ & & + { \\left(x_j\\right)}\\otimes { \\left({\\left(x_i\\right)}x_k\\right)}+{\\left(x_i\\right)}{\\left(x_j\\right)}\\otimes { \\left(x_k\\right)}.\\label{eq : exampledel2}\\end{aligned}\\ ] ]      we have defined the counit and the coproduct maps for @xmath39 , but in order to furnish the coalgebra structure on @xmath39 we need to show that these maps satisfy the equations ( [ coalg1 ] ) and ( [ coalg2 ] ) .",
    "the first of these relations is trivial to show due to the definition of the counit as : @xmath80}=x={\\left(\\overline{e}\\otimes{\\mathbf{1_d}}\\right)}\\delta{\\left[x\\right]}.\\end{aligned}\\ ] ]    next , we want to show the equation ( [ coalg2 ] ) holds .",
    "this can be proved using induction on the length of the words .",
    "a detailed proof is given in the appendix [ app : coalg ] .",
    "after successfully defining a counit and a coproduct on @xmath39 , we have completed the construction of the coalgebra structure on @xmath39 .",
    "we have already established the fact that @xmath39 is a unital coassociative algebra .",
    "the property ( [ compatcoprod ] ) ensures that the algebra and the coalgebra structures are compatible .",
    "this implies that @xmath39 is actually a bialgebra .      to complete the construction of the hopf algebra , what remains to find is an antipode .",
    "it turns out that antipode is actually the object which achieves the renormalization , it combines the terms generated by the coproduct and combines them in a way which is similar to the forest formula .",
    "we define the antipode as follows : @xmath81}&=&e,\\\\ s{\\left[{\\left(x_i\\right)}\\right]}&=&-{\\left(x_i\\right)},\\\\ s{\\left[xy\\right]}&=&s{\\left[y\\right]}s{\\left[x\\right]},\\\\ s{\\left[{\\left(xx_i\\right)}\\right]}&=&-{\\left(xx_i\\right)}-m{\\left[{\\left(s\\otimes{\\mathbf{1_d}}\\right)}p_2{\\left(\\delta{\\left[{\\left(xx_i\\right)}\\right]}\\right)}\\right]},\\label{eq : sdef1}\\\\ s{\\left[{\\left(xx_i\\right)}\\right]}&=&-{\\left(xx_i\\right)}-m{\\left[{\\left({\\mathbf{1_d}}\\otimes s\\right)}p_2{\\left(\\delta{\\left[{\\left(xx_i\\right)}\\right]}\\right)}\\right]},\\label{eq : sdef2}\\\\ p_2&\\equiv & { \\left({\\mathbf{1_d}}-e\\circ\\overline{e}\\right)}\\otimes { \\left({\\mathbf{1_d}}-e\\circ\\overline{e}\\right)}\\equiv p_1\\otimes p_1.\\end{aligned}\\ ] ] this completely defines the antipode",
    ". however , we need to show that this antipode is actually well defined and induces a hopf algebra structure . this amounts to showing that equations ( [ eq : sdef1 ] ) and ( [ eq : sdef2 ] ) are equivalent and also the condition ( [ hopfcom ] ) is satisfied .",
    "equivalence of the two definitions follow from the associativity of the product @xmath49 and the coassociativity of the coproduct @xmath57 . the detailed proof is given in appendix [ app : antipodedef ] .",
    "the proof that the condition ( [ hopfcom ] ) is satisfied , is given in appendix [ app : hopfcheck ] .",
    "we have now completely furnished the set of all feynman diagrams , @xmath39 with the structure of a hopf algebra .",
    "we have not yet discussed precisely how the renomalization is achieved by this structure",
    ". this will be the subject of the next section .      in this section ,",
    "we describe how the hopf algebra constructed above produces the forest formula , generates counter terms and the renormalized feynman graphs .",
    "we will see that an important ingredient in this regard is the renormalization map , @xmath35 , which is renormalization scheme dependent .",
    "given a feynman graph @xmath1 , we associate a parenthesized word @xmath33 to it . using the feynman rules we obtain an integral expression associated with the graph @xmath1 ,",
    "denote it by @xmath82 @xmath83 , where @xmath84 is a vector space , endowed with suitable structure which is not important for our considerations .",
    "for example , it could be the space of laurent polynomials in the regularization parameter .",
    "these feynman integrals are subject to some renormalization conditions which are described by renormalization map @xmath85 .",
    "the renormalization map depends on the renormalization scheme , for example , in the case of minimal subtraction , @xmath35 picks out the only the divergent part of @xmath82 .",
    "the map @xmath86 , the renormalization map @xmath35 and the antipode of the hopf algebra @xmath36 give rise to a map @xmath87 at the level of the feynman integrals , which is written as : @xmath88}=-r{\\left[\\phi{\\left({\\left(xx\\right)}\\right)}\\right]}-r{\\left[m{\\left[{\\left(s_{r}\\otimes\\phi\\right)}p_2{\\left(\\delta{\\left[{\\left(xx\\right)}\\right]}\\right)}\\right]}\\right]}.\\label{eq : antipode2}\\end{aligned}\\ ] ] with @xmath89}=e$ ] .",
    "this map @xmath87 gives the counter terms for a given graph depending on the particular renormalization scheme @xmath35 .",
    "consider the following examples where , for simplicity , we omit writing @xmath86 explicitly :    1",
    ".   @xmath90}=-r{\\left[{\\left({\\left(x_i\\right)}x_j\\right)}\\right]}-r{\\left[m{\\left[{\\left(s_r\\otimes { \\mathbf{1_d}}\\right)}p_2{\\left(\\delta{\\left[{\\left({\\left(x_i\\right)}x_j\\right)}\\right]}\\right)}\\right]}\\right]}.\\end{aligned}\\ ] ] + we can use @xmath91}$ ] as computed in equation ( [ eq : exampledel1 ] ) . since , @xmath92 annihilates @xmath50 , we finally find that : @xmath90}=-r{\\left[{\\left({\\left(x_i\\right)}x_j\\right)}\\right]}+r{\\left[r{\\left[{\\left(x_i\\right)}\\right]}{\\left(x_j\\right)}\\right]}.\\end{aligned}\\ ] ] 2 .",
    "similarly , after a straightforward but tedious computation one can find that : @xmath93}&=&-r{\\left[{\\left({\\left(x_i\\right)}{\\left(x_j\\right)}x_k\\right)}\\right]}+r{\\left[r{\\left[{\\left(x_i\\right)}\\right]}{\\left({\\left(x_j\\right)}x_k\\right)}\\right]}+r{\\left[r{\\left[{\\left(x_j\\right)}\\right]}{\\left({\\left(x_i\\right)}x_k\\right)}\\right]}\\nonumber \\\\&&-r{\\left[r{\\left[{\\left(x_i\\right)}\\right]}r{\\left[{\\left(x_j\\right)}\\right]}{\\left(x_k\\right)}\\right]}.\\label{eq : example}\\end{aligned}\\ ] ]    let us now proceed further to show that the forest structure in equations ( [ eq : for1],[eq : for2],[eq : for3 ] ) emerges from the hopf the algebra structure .",
    "let @xmath94 be a subword of @xmath23 , then by using the representation of the coproduct in sweedler s notation and the fact that @xmath92 annihilates @xmath50 , the antipode can be written as : @xmath95}=- x - \\sum_{u\\neq e , x } s{\\left[u\\right]}{\\left(x / u\\right)}.\\end{aligned}\\ ] ] if the parenthesized word @xmath23 is associated to a feynman graph @xmath1 then the subwords @xmath96 are associated to the proper forest @xmath97 of the graph @xmath1 .",
    "using this fact , we can now write the map @xmath87 in the following way : @xmath98}&=&-r{\\left[\\gamma\\right]}-\\sum_{\\text{proper forest } \\gamma\\subset \\gamma } r{\\left[s_{r}{\\left[\\gamma\\right]}\\gamma/\\gamma\\right]},\\\\ & = & -r{\\left[\\gamma+\\sum_{\\text{proper forest } \\gamma\\subset \\gamma } s_{r}{\\left[\\gamma\\right]}\\gamma/\\gamma\\right]}.\\end{aligned}\\ ] ] now , if we identify @xmath99}$ ] with counter term associated to the subgraph @xmath97 , then the argument of the map @xmath35 in the above equation is just @xmath3 , the graph @xmath1 with all its subdivergences renormalized as defined in equation ( [ eq : for2 ] ) .",
    "we can also identify the renormalization map @xmath35 with the operator @xmath6 , both are renormalizatio scheme dependent operators and picks out just the divergent part of a feynman integral in ms scheme . with this identification",
    ", we see that @xmath100}$ ] just gives the counter term @xmath5 and we recover the forest structure of equations ( [ eq : for1],[eq : for2],[eq : for3 ] ) . the renormalized feynman graph @xmath101 is obtained as follows .",
    "let @xmath23 be the parenthesized word associated with the graph @xmath1 ( we will use the parenthesized word @xmath23 , the corresponding graph @xmath1 and the corresponding feynman integral @xmath102 interchangeably ) then : @xmath103}\\delta{\\left[x\\right]}&=&m{\\left[s_{r}\\otimes \\phi\\right]}{\\left(e\\otimes",
    "x + x\\otimes e+ \\sum_{\\text{subwords } u\\neq e , x}u\\otimes { \\left(x / u\\right)}\\right)},\\\\ & = & \\phi{\\left[x\\right]}+s_r{\\left[x\\right]}+\\sum_{\\text{subwords } u\\neq e , x } s_{r}{\\left[u\\right]}\\phi{\\left[x / u\\right]},\\end{aligned}\\ ] ] in the last equation , the first term is just the feynman integral associated with graph @xmath1 , the second term is the counter term @xmath5 and the last term just removes the subdivergences as we have seen earlier .",
    "now , we omit writing @xmath86 and replace parenthesized words with the respecting graphs to find : @xmath103}\\delta{\\left[x\\right]}=\\gamma + z_{\\gamma}+\\sum_{\\text{proper forests } \\gamma\\subset \\gamma}z_{\\gamma}\\gamma/\\gamma=\\overline{\\gamma}+z_{\\gamma}=\\gamma_{ren}.\\end{aligned}\\ ] ] earlier , we showed that at the hopf algebra level , the operator @xmath104}$ ] annihilates any parenthesized word other than the unit @xmath50 .",
    "this expresses the fact that at the level of the feynman integrals we will get essentially a finite result .",
    "in this section we will briefly summarize the key results of this article . by representing the feynman diagrams as parenthesized words",
    ", we furnished them into a set @xmath39 .",
    "we also included the empty graph , represented by the unit element @xmath50 , in that set .",
    "then we introduced an algebra structure on @xmath39 by defining a bilinear product @xmath105 .",
    "we also defined a unit map @xmath106 , furnishing @xmath39 into a unital associative algebra .",
    "next , we introduced the coalgebra structure on @xmath39 by defining the counit map and the coproduct map .",
    "the coproduct was defined in such a way that it was compatible with the product @xmath49 and hence we obtained a bialgebra structure on @xmath39 . to complete the construction of the hopf algebra",
    ", we defined an antipode map @xmath107 .",
    "we also showed that the struture of the forest formula is recovered if we identify the antipode with the counter term of a specific graph . to make this notion precise , we defined a map @xmath108 , which assigns a parenthesized word an analytic expression ( feynman integral ) using the feynman rules .",
    "we defined the renormalization map @xmath35 which gives the divergent part of a feynman integral .",
    "it turned out antipode @xmath36 induced the counter term for a graph via @xmath35 .",
    "the most important result we obtained is the equivalence of the antipode and the forest formula .",
    "this equivalence followed by making a set of identifications between the elements of the hopf algebra and the objects of the standard renormalization theory .",
    "we list these identifications here .",
    "* 1pi feynman graph @xmath1 with subdivergences are identified with irreducible parenthesized word @xmath109 whose bracket structure matches the forest structure of @xmath1 , and the letters label the components of @xmath1 obtained after reducing the subdivergences to a point . * the counter term @xmath5 is identified with @xmath100}$ ] . *",
    "the feynman graph , with all its subdivergences renormalized , @xmath3 is identified with the object : @xmath110}\\right]},\\ \\ \\text{where}\\ \\ \\ p_r={\\mathbf{1_d}}\\otimes{\\left({\\mathbf{1_d}}-e\\circ\\overline{e}\\right)}.\\end{aligned}\\ ] ] * the renormalized feynman graph @xmath111 is identified with : @xmath112}\\right]}.\\end{aligned}\\ ] ]",
    "consider a feynman graph @xmath1 . by using feynman rules",
    "we can obtain the corresponding analytic expression @xmath113 . in general this expression",
    "can be written as a laurent series in the regularization parameter @xmath114 .",
    "if we consider @xmath86-cubed theory in @xmath115 spacetime dimensions and use dimensional regularization then @xmath116 where @xmath117 are some coefficients and the integer @xmath118 is bounded above by the number of loops in the graph @xmath1 , which can be shown explicitly .",
    "we stress here that in the general argument for the bphz renormalization nothing depends crucially on the particular toy model chosen here .",
    "let us now define a ` subtraction ' operator associated with the graph @xmath1 as follows @xmath119 i.e. , it picks out the divergent part of @xmath113 .",
    "in general , the subtraction operator is renormalization scheme dependent , here we have chosen the minimal subtraction scheme .",
    "the finite part of the graph can now be written as : @xmath120 so , we see that the term ` @xmath121 ' provides the counter term for the graph @xmath1 and @xmath122 removes the divergence associated with graph @xmath1 and makes it finite in the @xmath123 limit .    now , consider the graph @xmath1 to have proper 1pi subgraphs @xmath124 for simplicity , we assume that all these subgraphs are overall divergent , if they are not divergent , there is no need for renormalization .",
    "we order these graphs such that if @xmath125 then @xmath126 .",
    "now we define the following : @xmath127 where the product in the second equality needs to be ordered .",
    "since the operator ` @xmath128 ' removes the divergence associated with the subgraph @xmath129 , we see that equation ( [ subdivr ] ) is nothing but the graph @xmath1 with all its subdivergences renormalized .",
    "now we define the ` bogoliubov @xmath35 operator ' which removes the over all divergence associated with @xmath1 and renders it finite : @xmath130 let us now define a restricted graph @xmath131 as the graph obtained by reducing @xmath27 to a point inside @xmath1 , then it is easy to see that @xmath132 , i.e. , we can replace the subgraph @xmath27 in @xmath1 by @xmath133 and multiply by the counter term which makes @xmath27 finite .",
    "we can write equation ( [ rengam ] ) as : @xmath134 where the sum is taken over all subgraphs of @xmath1 ( i.e. , all non empty subsets ( denoted by @xmath86 ) of the set @xmath135 ) . we will also need the following theorem due to hepp @xcite , which we state here without proof .",
    "[ hepp ] let @xmath136 be overlapping 1pi subgraphs of @xmath1 . then consider a subgraph @xmath137 such that @xmath138 then @xmath139 i.e. , the finite part of the graph left after replacing the overlapping subdivergences is zero .",
    "courtesy this theorem we can restrict the @xmath86 in equation ( [ renf2 ] ) to be the subset of non overlapping 1pi divergences . since @xmath140 provides the counter term associated with the subgraph @xmath86 we can write : @xmath141 where @xmath142 is the counter term which makes the subgraph @xmath86 finite .",
    "the subgraph @xmath86 is formally defined as : @xmath143 and is called a ` forest ' of graph @xmath1 . in the above expression the term inside second set of parenthesis is the graph @xmath1 with all non - overlapping subdivergences renormalized .",
    "the remaining divergence is then removed by the operator @xmath144 .",
    "equation ( [ renf3 ] ) is called ` zimmermann s forest formula ' .",
    "we can write the forest formula in a schematic fashion as follows : @xmath145 where @xmath1 and @xmath2 are bare and renormalized graphs respectivley .",
    "@xmath3 is the graph with all the subdivergences removed .",
    "@xmath97 denotes all proper forests of @xmath1 . @xmath4 and @xmath5 are the counter terms .",
    "we now consider an example which explains some important aspects of the forest structure of a feynman graph and the application of the forest formula .",
    "let us look at the diagram in figure [ fig : twodiv ] .",
    "this graph ( say @xmath146 ) has only two non overlapping 1pi subgraphs , say @xmath147 and @xmath148 , as labeled and boxed in the diagram .",
    "the corresponding proper forests are : @xmath149 so we find that : @xmath150 we shoowed earlier that this diagram corresponds a parenthesized word @xmath151 .",
    "if we compare the structure of the counter term @xmath5 obtained here with equation ( [ eq : example ] ) ( which computes @xmath152}$ ] ) , we see that the two objects have exactly the same structure after the identifications described in the section [ sec : sum ] .",
    "let @xmath94 be any subword of a parenthesized word @xmath23 , then our coproduct is defined in such a way that : @xmath153=\\sum _ { u } u\\otimes { \\left(x / u\\right)}.\\end{aligned}\\ ] ] this assertion is easy to prove using the induction on length of the words .",
    "it is obviously true for words of length @xmath59 .",
    "assume that it is true for word @xmath23 of length @xmath154 and then induce .",
    "let us consider an irreducible parenthesized word @xmath155 of length @xmath156 .",
    "@xmath157}&=&{\\left(xx\\right)}\\otimes e + e\\otimes { \\left(xx\\right)}+{\\left({\\mathbf{1_d}}\\otimes b_{{\\left(x\\right)}}\\right)}p\\delta{\\left[x\\right]},\\\\ & = & { \\left(xx\\right)}\\otimes e + e\\otimes { \\left(xx\\right)}+{\\left({\\mathbf{1_d}}\\otimes b_{{\\left(x\\right)}}\\right)}{\\left(\\sum_{\\text{all subwords } u\\neq e \\text { of x}}u\\otimes { \\left(x / u\\right)}\\right)},\\\\ & = & { \\left(xx\\right)}\\otimes e + e\\otimes { \\left(xx\\right)}+{\\left(\\sum_{\\text{all subwords } u\\neq e \\text { of x}}u\\otimes { \\left(x / u x\\right)}\\right ) } , \\\\ & = & { \\left(xx\\right)}\\otimes e + { \\left(\\sum_{\\text{all subwords } u \\text { of x}}u\\otimes { \\left(x / u x\\right)}\\right ) } , \\\\ & = & \\sum_{\\text{all subwords } u \\text { of } { \\left(xx\\right)}}u\\otimes { \\left(xx\\right)}/u \\end{aligned}\\ ] ] which proves our assertion for irreducible word of length @xmath156",
    ". for an arbitrary word @xmath46 of length @xmath156 , the assertion follows by using the induction assumption and the fact that @xmath158}=\\delta{\\left[x\\right]}\\delta{\\left[y\\right]}$ ] .",
    "this completes our proof .",
    "here we prove that the coproduct defined in equation ( [ coprod ] ) is coassociative and satisfies the following condition : @xmath159}&=&{\\left({\\mathbf{1_d}}\\otimes\\delta\\right)}\\delta{\\left[x\\right]},\\ \\ \\",
    "x\\in\\mathcal{a}.\\label{coass}\\end{aligned}\\ ] ]    we will prove this using induction on the length of the parenthesized words .",
    "it is trivial to see that @xmath57 is coassociative when acting on the words of length @xmath59 . for the induction",
    "we assume that it is coassociative acting on words of length @xmath154 .",
    "first , we show that it is coassociative on irreducible parenthesized words of length @xmath156 and then we prove the assertion for arbitrary parenthesized words .",
    "we use the sweedler s notation and also drop the summation sign @xmath160 to simplify the notation further .",
    "let @xmath23 be a parenthesized word of length @xmath154 then : @xmath161}&=&x_1\\otimes x_2,\\label{eq : dx}\\\\ { \\left(\\delta\\otimes{\\mathbf{1_d}}\\right)}\\delta{\\left[x\\right]}&=&{\\left({\\mathbf{1_d}}\\otimes\\delta\\right)}\\delta{\\left[x\\right]}\\label{eq : indass},\\end{aligned}\\ ] ] where equation ( [ eq : dx ] ) is just the simplified sweedler s notation and equation ( [ eq : indass ] ) is the induction assumption .",
    "now , consider the parenthesized word @xmath162 of length @xmath156 .",
    "a straightforward computation gives : @xmath163}&=&{\\left(\\delta\\otimes{\\mathbf{1_d}}\\right)}{\\left({\\left(xx_j\\right)}\\otimes e+{\\left({\\mathbf{1_d}}\\otimes b_{{\\left(x_j\\right)}}\\right)}{\\left(x_1\\otimes x_2\\right)}\\right)},\\\\ & = & \\delta{\\left[xx_j\\right]}\\otimes e + \\delta{\\left[x_1\\right]}\\otimes { \\left(x_2x_j\\right)},\\\\ & = & { \\left(xx_j\\right)}\\otimes e\\otimes e + x_1\\otimes { \\left(x_2x_j\\right)}\\otimes e + \\delta{\\left[x_1\\right]}\\otimes { \\left(x_2x_j\\right)}.\\label{eq : pr1}\\end{aligned}\\ ] ] now , let us compute the rhs of equation ( [ coass ] ) . by using the definition ( [ coprodsweed ] )",
    "@xmath164}&=&{\\left(xx_j\\right)}\\otimes e\\otimes e + x_1\\otimes { \\left(x_2x_j\\right)}\\otimes e + x_1\\otimes{\\left[{\\left({\\mathbf{1_d}}\\otimes b_{{\\left(x_j\\right)}}\\right)}\\delta{\\left[x_2\\right]}\\right]}.\\ \\ \\ \\label{eq : pr2}\\end{aligned}\\ ] ] first two terms in the above equation are the same as in equaton ( [ eq : pr1 ] ) .",
    "let s focus on the third term .",
    "an important result in this regard is the following .",
    "@xmath165 } & = & { \\left({\\mathbf{1_d}}\\otimes{\\mathbf{1_d}}\\otimes b_{{\\left(x_j\\right)}}\\right)}{\\left({\\mathbf{1_d}}\\otimes\\delta\\right)}{\\left(x_1\\otimes x_2\\right)},\\\\ & = & { \\left({\\mathbf{1_d}}\\otimes{\\mathbf{1_d}}\\otimes b_{{\\left(x_j\\right)}}\\right)}{\\left(x_1\\otimes \\delta{\\left[x_2\\right]}\\right)},\\\\ & = & x_1\\otimes { \\left[{\\left({\\mathbf{1_d}}\\otimes b_{{\\left(x_j\\right)}}\\right)}\\delta{\\left[x_2\\right]}\\right]}.\\end{aligned}\\ ] ] using this we can write : @xmath166}\\right]}&=&{\\left({\\mathbf{1_d}}\\otimes{\\mathbf{1_d}}\\otimes b_{{\\left(x_j\\right)}}\\right)}{\\left({\\mathbf{1_d}}\\otimes\\delta\\right)}\\delta{\\left[x\\right]},\\\\ & = & { \\left({\\mathbf{1_d}}\\otimes{\\mathbf{1_d}}\\otimes b_{{\\left(x_j\\right)}}\\right)}{\\left(\\delta\\otimes{\\mathbf{1_d}}\\right)}\\delta{\\left[x\\right ] } , \\\\ & = & { \\left({\\mathbf{1_d}}\\otimes{\\mathbf{1_d}}\\otimes b_{{\\left(x_j\\right)}}\\right)}{\\left(\\delta\\otimes{\\mathbf{1_d}}\\right)}{\\left[x_1\\otimes x_2\\right]},\\\\ & = & \\delta{\\left[x_1\\right]}\\otimes { \\left(x_2x_j\\right)},\\end{aligned}\\ ] ] where , the second equality just follows from the induction assumption ( [ eq : indass ] ) .",
    "this is precisely the third term in equation ( [ eq : pr1 ] ) and this complete the proof of coassociativity for parenthesized words of length @xmath156 an of the form @xmath167 .",
    "now , for a general parenthesized word @xmath46 of length @xmath156 , we use the property of the coproduct ( [ compatcoprod ] ) to get : @xmath168}&=&{\\left({\\mathbf{1_d}}\\otimes\\delta\\right)}{\\left(\\delta{\\left[x\\right]}\\delta{\\left[y\\right]}\\right)},\\\\ & = & { \\left({\\left({\\mathbf{1_d}}\\otimes\\delta\\right)}\\delta{\\left[x\\right]}\\right)}{\\left({\\left({\\mathbf{1_d}}\\otimes\\delta\\right)}\\delta{\\left[y\\right]}\\right)},\\\\ & = & { \\left({\\left(\\delta\\otimes{\\mathbf{1_d}}\\right)}\\delta{\\left[x\\right]}\\right)}{\\left({\\left(\\delta\\otimes{\\mathbf{1_d}}\\right)}\\delta{\\left[y\\right]}\\right)},\\\\ & = & { \\left(\\delta\\otimes{\\mathbf{1_d}}\\right)}{\\left(\\delta{\\left[x\\right]}\\delta{\\left[y\\right]}\\right)},\\\\ & = & { \\left(\\delta\\otimes{\\mathbf{1_d}}\\right)}\\delta{\\left[xy\\right]},\\end{aligned}\\ ] ] where the first and second lines follow from property ( [ compatcoprod ] ) , third equality follows fromt the induction assumption .",
    "fourth and fifth lines again follow from ( [ compatcoprod ] ) .",
    "this complete the proof of coassociativity for the coproduct .",
    "in the definition of the antipode , two definitions , ( [ eq : sdef1 ] ) and ( [ eq : sdef2 ] ) , were given .",
    "for the antipode to be well defined , these two definitions should be equivalent .",
    "we prove this equivalence in the following .",
    "we can strip off the parenthesized word @xmath22 from the argument of the antipode in equations ( [ eq : sdef1 ] ) and ( [ eq : sdef2 ] ) and represent antipode as an operator acting on @xmath39 .",
    "then , we need to show that : @xmath169}\\ & = & -{\\mathbf{1_d}}-\\ m{\\left[{\\left({\\mathbf{1_d}}\\otimes s\\right)}p_2\\delta\\right]},\\\\ -{\\mathbf{1_d}}-m{\\left[{\\left(s p_1\\otimes p_1\\right ) } \\delta\\right]}\\ & = & -{\\mathbf{1_d}}-\\ m{\\left[{\\left(p_1\\otimes sp_1\\right)}\\delta\\right]}.\\label{eq : claim1}\\end{aligned}\\ ] ] both sides still involve the antipode @xmath36 , let us do one more iteration on the both sides . for the left hand side",
    "we get : @xmath170}\\right)}p_1\\otimes p_1\\right ) } \\delta\\right]},\\\\ & = & -{\\mathbf{1_d}}+m{\\left[{\\left(p_1\\otimes p_1\\right ) } \\delta\\right]}+m{\\left[{\\left({\\left(m{\\left[{\\left(s p_1\\otimes",
    "p_1\\right ) } \\delta\\right]}\\right)}p_1\\otimes p_1\\right ) } \\delta\\right]},\\\\ & = & -{\\mathbf{1_d}}+m{\\left[{\\left(p_1\\otimes p_1\\right ) } \\delta\\right]}\\nonumber \\\\ & & + m{\\left[{\\left(m\\otimes{\\mathbf{1_d}}\\right)}{\\left(s\\otimes{\\mathbf{1_d}}\\otimes{\\mathbf{1_d}}\\right)}{\\left(p_1\\otimes p_1\\otimes{\\mathbf{1_d}}\\right)}{\\left(\\delta\\otimes{\\mathbf{1_d}}\\right)}{\\left(p_1\\otimes p_1\\right)}\\delta\\right]},\\\\   & = & -{\\mathbf{1_d}}+m{\\left[{\\left(p_1\\otimes p_1\\right ) } \\delta\\right]}\\nonumber \\\\ & & + m{\\left[{\\left(m\\otimes{\\mathbf{1_d}}\\right)}{\\left(s\\otimes{\\mathbf{1_d}}\\otimes{\\mathbf{1_d}}\\right)}{\\left(p_1\\otimes p_1\\otimes p_1\\right)}{\\left(\\delta\\otimes{\\mathbf{1_d}}\\right)}\\delta\\right]},\\label{lhs1}\\end{aligned}\\ ] ] where the last equality follows because of the fact that @xmath171 , which is easy to confirm . for the right hand side , a similar computation yields : @xmath172}\\nonumber \\\\ & & + m{\\left[{\\left({\\mathbf{1_d}}\\otimes m\\right)}{\\left({\\mathbf{1_d}}\\otimes{\\mathbf{1_d}}\\otimes s\\right)}{\\left(p_1\\otimes p_1\\otimes p_1\\right)}{\\left({\\mathbf{1_d}}\\otimes \\delta\\right)}\\delta\\right]}.\\label{rhs1}\\end{aligned}\\ ] ] from equations ( [ lhs1 ] ) and ( [ rhs1 ] )",
    ", we deduce that , to show the equivalence of the two definitions we need to prove the following : @xmath173}\\nonumber \\\\ & = & m{\\left[{\\left(m\\otimes{\\mathbf{1_d}}\\right)}{\\left(s\\otimes{\\mathbf{1_d}}\\otimes{\\mathbf{1_d}}\\right)}{\\left(p_1\\otimes p_1\\otimes p_1\\right)}{\\left(\\delta\\otimes{\\mathbf{1_d}}\\right)}\\delta\\right]}\\end{aligned}\\ ] ] this is very easy to show using the previously established properties of the coproduct @xmath57 and the product @xmath49 . using the coassociativity @xmath174",
    ", we can freely make the following change in the left side of the above equation : @xmath175 similarly , now we make use of the associativity of the product , this implies that @xmath176 .",
    "using this , we can again move the last two operators in the direct product to the first two places , yielding : @xmath177 this completes the proof for the equivalence of the two definitions .      here , we show that the antipode defined earlier in this article actually satisfies the condition ( [ hopfcom ] ) .",
    "we will do this using induction . for a parenthesized word of length 1 , @xmath178 , it is easy to see that : @xmath179}=0,\\end{aligned}\\ ] ] and @xmath180}\\right]}&=&m{\\left[{\\left(s\\otimes{\\mathbf{1_d}}\\right)}{\\left({\\left(x\\right)}\\otimes e + e\\otimes { \\left(x\\right)}\\right)}\\right]},\\\\ & = & m{\\left[-{\\left(x\\right)}\\otimes e + e\\otimes { \\left(x\\right)}\\right]}=0.\\end{aligned}\\ ] ] a similar computation yields @xmath181}\\right]}=0.\\end{aligned}\\ ] ] let us now assume that the assertion holds for parenthesized words of length @xmath154 , consider an irreducible parenthesized word @xmath155 of length @xmath156 .",
    "since the map @xmath92 annihilates @xmath50 , using the sweedler s notation we can write the antipode of @xmath155 as follows : @xmath182}=-{\\left(xx\\right)}-\\sum_{x_{1}\\neq e}s{\\left[x_1\\right]}{\\left(x_{2}\\ x\\right)}.\\end{aligned}\\ ] ] now , @xmath157}&=&{\\left(xx\\right)}\\otimes e + \\sum_{x_1}x_{1}\\otimes { \\left(x_2\\ x\\right)},\\\\ { \\left(s\\otimes { \\mathbf{1_d}}\\right)}\\delta{\\left[{\\left(xx\\right)}\\right]}&= & s{\\left[{\\left(xx\\right)}\\right]}\\otimes e + \\sum_{x_1}s{\\left[x_{1}\\right]}\\otimes { \\left(x_2\\ x\\right)},\\\\ & = & -{\\left(xx\\right)}\\otimes e-\\sum_{x_{1}\\neq e}s{\\left[x_1\\right]}{\\left(x_{2}\\ x\\right)}\\otimes e+ \\sum_{x_1}s{\\left[x_{1}\\right]}\\otimes { \\left(x_2\\ x\\right)},\\\\ m{\\left(s\\otimes { \\mathbf{1_d}}\\right)}\\delta{\\left[{\\left(xx\\right)}\\right]}&=&-{\\left(xx\\right)}-\\sum_{x_{1}\\neq e}s{\\left[x_1\\right]}{\\left(x_{2}\\ x\\right)}+ \\sum_{x_1}s{\\left[x_{1}\\right ] } { \\left(x_2\\ x\\right)},\\\\ & = & -{\\left(xx\\right)}+s{\\left[e\\right]}{\\left(xx\\right)}=0,\\end{aligned}\\ ] ] where the last line follows from the fact that then when @xmath183 , @xmath184 . now , let us consider the case for @xmath185}\\right]}$ ] . due to the equivalence of two definitions ( [ eq : sdef1 ] ) and ( [ eq : sdef2 ] ) , and",
    "the properties of @xmath186 we have the following identity : @xmath187 using this , we find that : @xmath188}&=&{\\left(xx\\right)}\\otimes e + { \\left({\\mathbf{1_d}}\\otimes s\\right)}\\sum_{x_1}x_1\\otimes { \\left(x_2 x\\right ) } , \\\\ & = & { \\left(xx\\right)}\\otimes e + { \\left(s\\otimes { \\mathbf{1_d}}\\right)}\\sum_{x_1\\neq e}x_1\\otimes { \\left(x_2 x\\right)}+{\\left({\\mathbf{1_d}}\\otimes s\\right)}e\\otimes { \\left(xx\\right ) } , \\\\ & = & { \\left(xx\\right)}\\otimes e + \\sum_{x_1\\neq e}s{\\left[x_1\\right]}\\otimes { \\left(x_2 x\\right)}+{\\left({\\mathbf{1_d}}\\otimes s\\right)}{\\left[e\\otimes { \\left(xx\\right)}\\right]},\\\\ & = & { \\left(xx\\right)}\\otimes e + \\sum_{x_1\\neq e}s{\\left[x_1\\right]}\\otimes { \\left(x_2 x\\right)}-e\\otimes { \\left(xx\\right)}\\nonumber \\\\ & & -\\sum_{x_{1}\\neq e}e\\otimes s{\\left[x_1\\right]}{\\left(x_2x\\right)},\\end{aligned}\\ ] ] which implies @xmath189}\\right]}&= & 0.\\end{aligned}\\ ] ] since the counit annihilates any parenthesized word we finally conclude that : @xmath190}\\right]}=0=e\\circ\\overline{e}{\\left[{\\left(xx\\right)}\\right]}.\\end{aligned}\\ ] ] for an arbitrary parenthesized word @xmath46 , due to the induction assumption and the property ( [ compatcoprod ] ) of the coproduct , the assertion holds trivially .",
    "this completes our proof .",
    "here , we will work out an elementary example which elucidates how all the different elements of the hopf algebra fit together to give a finite result for a divergent integral .",
    "we will use a very simple toy model , defined below : @xmath191}&\\equiv & \\int_{c}^{\\infty}dy y^{-1-j\\epsilon}\\equiv i_j,\\\\ { \\left(xx_{j}\\right)}{\\left[c\\right]}&\\equiv & \\int_{c}^{\\infty}dy y^{-1-j\\epsilon}x{\\left[y\\right]},\\\\ { \\left(x_j\\right)}{\\left(x_k\\right)}{\\left[c\\right]}&= & i_ji_k,\\\\ r{\\left[x{\\left[c\\right]}\\right]}&\\equiv & x{\\left[1\\right]}.\\end{aligned}\\ ] ] it is easy to see that @xmath192 is divergent as @xmath193",
    ". we call the subscript @xmath194 in @xmath195 , the loop order of @xmath195 .",
    "this toy model is the simplest realization of our hopf algebra .",
    "let us consider the divergent graph @xmath196 .",
    "our claim is that the expression @xmath197}\\right]}\\right]}$ ] is a finite integral as expected from our hopf algebra construction . by making use of the",
    "already worked out examples for @xmath198}$ ] , @xmath199}$ ] , @xmath200}$ ] and the fact @xmath201}=s_r{\\left[x\\right]}s_r{\\left[y\\right]}$ ] we find that : @xmath202}-{\\left(x_1\\right)}{\\left[1\\right]}{\\left({\\left(x_2\\right)}x_1\\right)}{\\left[c\\right]}-{\\left(x_2\\right)}{\\left[1\\right]}{\\left({\\left(x_1\\right)}x_1\\right)}{\\left[c\\right]}+{\\left(x_1\\right)}{\\left[1\\right]}{\\left(x_2\\right)}{\\left[1\\right]}{\\left(x_1\\right)}{\\left[c\\right]}\\nonumber \\\\ & & -{\\left(\\text{first four terms with } c\\text { replaced by } 1\\right)}.\\label{eq : xr}\\end{aligned}\\ ] ] now , @xmath203}&=&\\int_{c}^{\\infty}dx x^{-1-\\epsilon}\\int_{x}^{\\infty}dy y^{-1 - 2\\epsilon}\\int_{x}^{\\infty}dz z^{-1-\\epsilon},\\\\",
    "t_2\\equiv - { \\left(x_1\\right)}{\\left[1\\right]}{\\left({\\left(x_2\\right)}x_1\\right)}{\\left[c\\right]}&=&- \\int_{c}^{\\infty}dx x^{-1-\\epsilon}\\int_{x}^{\\infty}dy y^{-1 - 2\\epsilon}\\int_{1}^{\\infty}dz z^{-1-\\epsilon},\\\\ t_3\\equiv - {",
    "\\left(x_2\\right)}{\\left[1\\right]}{\\left({\\left(x_1\\right)}x_1\\right)}{\\left[c\\right]}&=&-\\int_{c}^{\\infty}dx x^{-1-\\epsilon}\\int_{1}^{\\infty}dy y^{-1 - 2\\epsilon}\\int_{x}^{\\infty}dz z^{-1-\\epsilon},\\\\ t_4\\equiv { \\left(x_1\\right)}{\\left[1\\right]}{\\left(x_2\\right)}{\\left[1\\right]}{\\left(x_1\\right)}{\\left[c\\right]}&=&\\int_{c}^{\\infty}dx x^{-1-\\epsilon}\\int_{1}^{\\infty}dy y^{-1 - 2\\epsilon}\\int_{1}^{\\infty}dz z^{-1-\\epsilon}.\\end{aligned}\\ ] ] the first two terms can be combined to get : @xmath204 the third term can be written as @xmath205 so that the sum of the four terms is : @xmath206 plug this in equation ( [ eq : xr ] ) we finally obtain the expression : @xmath207 which is clearly well defined and finite in the @xmath208 limit .",
    "although this was a very simple example , there should be no hinderance in generalizing this to more realistic qft examples . if we consider some realistic feynman graph , our hopf algebra will renormalize it with the same ease by applying the operator @xmath104}$ ] .",
    "d. kreimer , _ on the hopf algebra structure of perturbative quantum field theories _ , http://arxiv.org/pdf/q-alg/9707029v4.pdf[arxiv:q-alg/9707029 ] .",
    "a. connes and d. kreimer , _ hopf algebra , renormalization and non commutative geometry _ , http://arxiv.org/pdf/hep-th/9808042.pdf[arxiv:hep-th/9808042 ] .",
    "d. j. broadhurst , d. kreimer , _ renormalization automated by hopf algebra _ , http://arxiv.org/pdf/hep-th/9810087.pdf[arxiv:hep-th/9810087 ] .",
    "d. kreimer , r. delbourgo , _ using the hopf algebra structure of qft in calculations _ , http://arxiv.org/pdf/hep-th/9903249.pdf[arxiv:hep-th/9903249 ] .",
    "a. connes , d. kreimer , _ lessons from quantum field theory _ , http://arxiv.org/pdf/hep-th/9904044.pdf[hep-th/9904044 ] .",
    "d. kreimer , _ on overlapping divergences _ , http://arxiv.org/abs/hep-th/9810022[arxiv:hep-th/9810022 ] .",
    "w. v. suijlekom , _ the hopf algebra of feynman graphs in qed _ , http://arxiv.org/abs/hep-th/0602126[hep-th/0602126 ] e. panzer , _ hopf algebraic renormalization of kreimer s toy model _ , http://arxiv.org/abs/1202.3552[arxiv:1202.3552[math-ph ] ] .",
    "d. kreimer , _ knots and feynman diagrams _ , 2000 , cambrige university press .",
    "j. c. collins , _ renormalization _ , 1986 , cambridge university press .",
    "s. majid , _ foundations of quantum group theory _ , 1996 , cambridge university press .",
    "k. hepp , _ proof of the bogoliubov - parasiuk theorem on renormalization _ ,",
    "phys . , 1966 , springer ."
  ],
  "abstract_text": [
    "<S> we briefly review the hopf algebra structure arising in the renormalization of quantum field theories . </S>",
    "<S> we construct the hopf algebra explicitly for a simple toy model and show how renormalization is achieved for this particular model . </S>"
  ]
}