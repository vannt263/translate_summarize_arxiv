{
  "article_text": [
    "digital textual representations of original historic documents are being made available thanks to the work of digital archiving projects @xcite .",
    "as the wealth of digitised textual data increases it becomes more important to provide the appropriate tools for analysing and interrogating the sources .",
    "humanities researchers are discovering how digital tools can become part of their methodology - even collating their source materials into a simple repository can help to speed up the access to resources which were otherwise stored in physical libraries .",
    "however , there are still barriers to adoption , including usability and the scope of the provided tools @xcite . in addition",
    ", there is a tendency to develop systems which are language specific and rely on part of speech taggers to identify all instances of a word , regardless of its morphology , in order to provide accurate recall .",
    "furthermore , such systems may be tied to a particular document collection , for example , the works of william shakespeare . as a result , when developing any tool for the humanities important aspects to consider are how to index , search , compare , and apply data mining tools to domain - specific corpora represented by a collection of documents grouped together for a specific research agenda .",
    "+   + samtla has been designed to provide a research environment that is agnostic to the document collection and can therefore be used by a wide range of research groups whose work involves analysing digital representations of original source texts .",
    "it currently supports search , browsing , and analysis of texts through approximate phrase searches , related query and document recommendations , a document comparison tool , and community features in the form of popular queries and documents .",
    "samtla s interface adopts the flat design principle , which reflects current trends @xcite in user interface design in terms of user interaction and the layout of components such as tool bars and informational side panels to promote familiarity with respect to applications the user may use regularly ( including browsers , music and video players , cloud storage ) , and legibility in terms of centralising the content by presenting it clearly to users . +     +",
    "samtla was developed in collaboration with historians and linguists to cater for their research needs in quantifying the content of textual corpora .",
    "we have adopted a statistical language model ( slm ) for information retrieval @xcite , and incorporated text mining tools into the system to allow researchers to go beyond a pure search and browse paradigm .",
    "such an extended `` search and research '' model supports the discovery of patterns ( known by historians as `` formulae '' or `` parallel passages '' ) that have significance in terms of their research goals .",
    "the `` formulae '' are reflected by textual fragments represented , for example , by set phrases or quotations .",
    "the main textual fragment is duplicated across several documents with slight variations resulting from differences in authorship , language change due to locality and time , which can manifest themselves through dialectal differences .",
    "the system has been designed to be applicable to any type of corpus in any language with little pre - processing , and to provide transparency in terms of its functionality , in order to help researchers adopt it as an integral part of their research strategy @xcite . for this purpose ,",
    "our _ n_-gram statistical language model is character - based rather than word - based , which makes the query processing and further analysis flexible .",
    "for instance , consider the difficulty involved in indexing words from a collection of english news articles and those in the chinese language ; the latter of which has no whitespace equivalent word boundary marker as that present in english .",
    "+   + figure  [ fig : typology ] illustrates the basic structure of a corpus and the documents contained within .",
    "some corpora maybe partitioned in to subcorpora , and documents may also come with metadata , either in terms of document features ( title , pages , and length ) or additional metadata items generated by the user group .",
    "+   + samtla currently operates with five case study textual corpora : a collection of aramaic texts from late antiquity , italian and english translations of the writings of giorgio vasari , the microsoft corpus of 68,000 scanned books , the king james bible in english , and a test corpus of scanned newspaper articles from the financial times as part of a pilot study in collaboration with the british library .",
    "samtla was developed to enable faster access to the document collection and to compliment existing methods adopted by our users for comparison and discovery of related documents and parallel text fragments .",
    "+   + in the following sections we discuss prominent tools that are currently available for researchers ( section  [ sec : relatedwork ] ) , outline each of the system components described briefly above in more detail including the samtla system architecture ( section  [ sec : architecture ] ) , the statistical models underlying document scoring and recommendation , and a discussion of the chosen implementation methods used to structure and organise the data used by the system ( section  [ sec : datamodel ] ) .",
    "we introduce the tools that have been implemented to help researchers browse , view documents and related metadata , and compare shared - sequences between document pairs ( section  [ sec : textmining ] ) .",
    "next , we introduce the recommendation component of the system , which leverages data collected from the user query submissions and document views to generate recommended queries and documents to help users locate interests aspects of the collection ( section  [ sec : community ] ) . section  [ sec : ui ] provides a description of the user interface ( _ ui _ ) and discusses how the various tools have been incorporated in to the interface and how we expect users to navigate through the system .",
    "we also present case studies describing how the system is currently being used by researchers ( section  [ sec : casestudy ] ) , before moving to the results of a formal evaluation using a crowdsourcing platform ( section  [ sec : evaluation ] ) .",
    "lastly , we conclude the paper with a summary of the work and future development plans ( section  [ sec : conclusion ] ) .",
    "there are a number of existing systems that provide state of the art tools in the humanities .",
    "we discuss some of the systems that share common functionality , source material , or user groups with reference to samtla .",
    "+   + the bar - ilan _ responsa _ project , established in 1963 , is one of the earliest examples of humanities researchers adopting the use of computer - based methods for search , comparison , and analysis of hebrew texts .",
    "the corpus spans approximately three thousand years , and includes the mishnah , talmud , torah , and the bible in aramaic @xcite .",
    "the responsa environment is packaged on a cd - rom and provides browsing and searching the corpus using keyword and phrase search , comparison of parallel passages , author biographies , and user comment and annotation tools @xcite .",
    "the bar - ilan _ responsa _ project has made a considerable contribution to computational linguistics and information retrieval for hebrew .",
    "+   + the 1641 depositions project at trinity college library ( dublin ) @xcite adopted ibm s _ languageware _",
    "@xcite for the analysis of 31 volumes of books containing 19,010 pages of witness accounts reporting theft , vandalism , murder , and land taking during the conflicts between catholics and protestants in 17th century ireland .",
    "_ languageware _ provides text analysis tools for mining facts from large repositories of unstructured text .",
    "its main features are dictionary and fuzzy look - up , lexical analysis , language identification , spelling correction , part - of - speech disambiguation , syntactic parsing , semantic analysis , and entity and relationship extraction .",
    "_ languageware _ was chosen due to the complexity of the language contained in the documents , which have many spelling mistakes making analysis a complex task . _ cultivating understanding through research and adaptivity _ ( _ cultura _ )",
    "is a project related to the 1641 depositions , launched in 2011 @xcite .",
    "_ cultura _ provides users with tools for normalising texts containing inconsistent spelling , entity and relationship extraction present within unstructured text , and social network analysis tools for displaying the entities and relationships from metadata through an interactive user environment .",
    "+   + aside from tools developed as part of funded projects , we also see new applications for mobile and touch devices , developed specifically for exploring well known texts such as the bible .",
    "one such tool is _ accordance _ for _ _ apple ios__@xcite , which is a bible study application featuring exact and flexible query search tools , a browsing , a timeline for viewing when people lived and important events that took place , and an atlas view for exploring journeys and battles .",
    "+   + the systems descibed above are successful at providing the appropriate tools for specific groups of researchers to explore a particular collection of texts .",
    "the main issue , however , is the generalisability of their systems to other text domains and natural languages .",
    "these systems use language specific tools that operate at the word or morphological level requiring affix removal , tokenisation , lemmatisation , and part - of - speech tagging for normalising the texts and capturing all instances of a word in order to generate an accurate retrieval model .",
    "the question is whether they could be extended to languages with no clear word - level boundary markers ( e.g. chinese languages such as mandarin ) , or without the complex rules necessary to identify affixes ( e.g. hebrew , aramaic , arabic , italian , and russian ) .",
    "regardless of the approach adopted for text normalisation , these systems are by their nature language dependent .",
    "if we are to keep up with the volume of output generated by digitisation projects , then a new approach is necessary .",
    "the samtla system was designed to address the need for tools for the digital humantities through the creation of a flexible language - independent framework for searching , browsing , and comparing documents in a text collection that could be generalised to any document collection due to its data - driven design .",
    "samtla shares many of the features and tools available in the systems outlined above , however it differs in many respects due to the language - independent framework that can be extended in many novel ways without changes to the underlying system each time a new corpus is introduced .",
    "this enables a samtla system to be deployed relatively quickly , allowing document collections and archives to be unlocked to the general public , or for research once the digitised materials are made available .",
    "the philosophy underlying the development of samtla has been to provide the basic tools first ( browse , search , and comparison ) , and then to develop further features through consultation with our users to discover what tools they actually need in order to be able to carry out their research .",
    "the samtla system is a web - based application built on a client - server architecture , providing a platform - independent solution for its deployment through a web browser .",
    "the samtla system operates with a single code - base , with the only corpus - dependent component being a wrapper function , which is responsible for parsing the documents or metadata to the system .",
    "this enables the system to be data - driven and allows upgrades or changes to the functionality of samtla to be rolled - out simultaneously to each user group .",
    "+   + the client is represented by a web - based user interface ( ui ) , which sends requests to the server and renders the results within the browser .",
    "a central server stores all the data associated with the system , processes requests sent from the client , and responds with the appropriate data , for instance , a list of search query results .",
    "+   + samtla can be viewed as _ a model - view - controller _ ( mvc ) design pattern @xcite , allowing the separation of the system by function .",
    "the advantage of adopting a mvc implementation is that changes to the ui are independent of the underlying logic of the system .",
    "therefore , due to the separation of components , introducing new features and changes to the look or functionality of the ui can be easily implemented without affecting other components .",
    "an overview of samtla is shown in figure  [ fig : architecture ] , where arrows in the diagram represent the flow of communication between the various components of the system .",
    "+     + the client - side of the system is represented by the _ view _ component ( i.e. the ui ) providing a web - based browser interface , which allows the user to interact with the system ; see section  [ sec : ui ] for more detail on the ui .",
    "such interactions cause events to be triggered and picked up by the _ controller _ , representing the program logic .",
    "technically , the client communicates with the server through the controller using url requests , which are mapped to an appropriate function call in the _",
    "model_. this instigates a change to the data or the retrieval of information such as search query results or metadata .",
    "the _ model _ returns data to the controller to process , which passes the results to the view for rendering to the ui .",
    "the controller is implemented in the django web framework @xcite , which processes client http requests and sends a response .",
    "the data is passed between components using the javascript object notation ( json ) @xcite format , which allows us to store data objects that can be further processed in the browser ( i.e. for dynamic rendering of html snippets for the search results ) , or static html fragments which are rendered directly ( i.e. the raw documents ) .",
    "the ui is developed in javascript with jquery @xcite , providing cross - browser support for the interactive elements of the interface .",
    "in addition , the system uses a number of html5 apis @xcite , including web storage for persisting the user s system preferences . +   +",
    "the samtla system libraries and data are encompassed by the _ model _ component .",
    "samtla is written in python and all system data is stored in sql databases , except for the suffix tree , which is stored in _",
    "json _ format and serialised to disk ; see section  [ sec : suffixtree ] for more detail on the suffix tree component . +   + the _ model _",
    "is composed of a library of software tools that interact with the system data .",
    "the _ search _",
    "component is responsible for answering user queries , and uses a _ statistical language model _ ( slm ) , which is a relatively recent framework for information retrieval @xcite ; see section  [ sec : lm ] for more detail on how we make use of slm in samtla .",
    "the slm communicates with a suffix tree data structure , which is used to index the corpora that are being investigated .",
    "the suffix tree is loaded into memory at runtime for fast access .",
    "the suffix tree also provides support for the text mining tools , which are detailed in section  [ sec : textmining ] and include a _ related query _ feature , which recommends queries to the user based on permutations of the original query resulting from morphological or orthographic variations present in the corpus ( discussed in subsection  [ sec : relatedqueries ] ) , a _ related document _",
    "tool , presents users with a list of similar documents to the one they are viewing ( discussed subsection  [ sec : relateddocuments ] ) , and a _ document comparison _",
    "tool facilitates the comparison of shared - sequences between documents ( discussed in subsection  [ sec : doccomp ] ) .",
    "lastly , the _ community _ component is responsible for logging user data , such as query submissions and document views , usage statistics reflecting the user s navigation histories through the system , and for returning to the user recommended queries and documents based on their popularity in the user community ; see section  [ sec : community ] for more detail . +   + in the following sections we discuss in detail the methods and algorithms adopted to support the current set of tools divided into search , text mining , and community support .",
    "statistical language modelling @xcite is central to samtla s data model .",
    "it provides the foundation for samtla s search tool allowing users to locate documents through full and partial matches to queries .",
    "samtla s _ statistical language model _",
    "( slm ) , whose details are given in subsection  [ sec : lm ] , is supported by a character - based _ suffix tree _",
    "@xcite , described in detail in subsection  [ sec : suffixtree ] .",
    "a suffix trees is a very powerful data structure supporting fast retrieval of sequences of characters , known as _ n - grams _",
    ", where @xmath0 is the length of a sequence ( for our purposes , measured in characters ) .",
    "samtla is unique in that it is language agnostic and can thus support a variety of languages within a single data model ; we will demonstrate this in subsection  [ sec : casestudy ] .",
    "+      a slm is a mathematical model representing the probabilistic distribution of words or sequences of characters found in the natural language represented by text corpora @xcite .",
    "samtla is designed as a language agnostic search tool and as such uses a character - based @xmath0-gram slm , rather than the more conventional word - based model .",
    "language modelling provide samtla with a consistent methodology for retrieving and ranking search results according to the underlying principles and structure of the language present in a corpus , which is often domain specific . beyond that",
    ", slms provide a unifying model for samtla s text mining tools described in section  [ sec : textmining ] .",
    "+   + statistical language modelling combined with character - level ( 1-gram ) suffix tree nodes enable the system to be applied to multilingual corpora with very little pre - processing of the documents , unlike word - based systems .",
    "for example , languages like hebrew , russian , and italian attach affixes to a root word to identify syntactic relationships .",
    "this complicates word - based retrieval models since it is necessary to capture all instances of the same word in order to produce an accurate probabilistic model .",
    "word - based models typically require a language - dependent stemming , part - of - speech tagging , or text segmentation algorithm , however , by adopting a character - based @xmath0-gram model these issues can be ignored to some extent and character - based models have been shown to outperform raw word - based models , especially when the language is morphologically complex @xcite .",
    "furthermore , a character - based model enables the system to be applied to different language corpora , but also corpora which contain documents written in several different languages .",
    "for example , some documents in the aramaic collection contain texts written in hebrew , judeo - arabic , syriac , mandaic , and aramaic , the vasari corpus contains english and italian documents , whereas the british library microsoft corpus covers a range of languages including english , french , spanish , hungarian , romanian , and russian .",
    "+   + operationally , when the user submits a query , a list of documents is returned and ranked according to how relevant the document is to the query .",
    "the notion of relevance refers to the users expectation of which documents should be present at the top of the ranked list , in other words , which documents the user may be looking for @xcite . in samtla",
    "we take the view that the more probable a document in the slm sense , the more relevant it is , thus avoiding the philosophical debate on the notion of `` relevance '' @xcite .",
    "this equates to the system retrieving the most probable documents based on the slm representing the distribution of the @xmath0-grams in the corpus being searched .",
    "+   + in samtla the data comes from corpora , which consist of a collection of text documents grouped according to a specific topic , genre , demographic , or origin ( e.g institution storing original versions of the digital texts ) . for instance , a bible corpus can be composed of several bibles from different periods or translations ( wycliffe bible , tyndale bible , or thomas young s translation ) .",
    "each bible therefore represents an individual corpus containing a collection of documents , which represent each chapter of the given bible .",
    "+   + we generate slms from the corpora over the whole collection , which we call the _ collection model _ , and over each individual document , which we call the _ document model_. a generic slm is denoted by @xmath1 , while the collection model is denoted by @xmath2 and a document model is denoted by @xmath3 .",
    "each slm is generated from the @xmath0-grams extracted from documents in the corpora , where @xmath0 will vary from one to some pre - determined maximum .",
    "the example below demonstrates how text is converted to @xmath0-grams of various sizes . here",
    "the @xmath0-grams are generated for the sequence `` beginning '' , which has a maximum @xmath0-gram size of nine , and can itself be reduced to lower - order @xmath0-grams by reducing the sequence a character at a time , as illustrated in the table below : +   +    [ cols=\"<,<\",options=\"header \" , ]     to summarise , on the basis of the performance measures presented above , we can say that users were highly correlated with the _ slm _ order of the queries than the _ display _ order when analysing the results of the _ random _ order queries independently of the 10 _ samtla _ queries .",
    "the users were more influenced by the presentation order of the 10 _ samtla _ queries , in the sense that they were slightly more generous with their relevance grades , where they tended to assign higher relevance to a few documents at the very top of the search results shown by the high @xmath1-measure and @xmath4 scores .",
    "out of the 50 queries completed by each user , 80% of them were presented in random order , yet we see that the users consistently assigned more relevance to the documents that received the highest document score according to the underlying @xmath5 , and we can see that these scores are not the result of users assigning relevance at random , or `` gaming '' the system , in part due to the role played by the quality assessment represented by the test queries .",
    "we also observed users revisiting their earlier relevance assignments , when they encountered highly relevant documents at the bottom of the result page , caused by the random shuffle process .",
    "therefore , there is significant evidence to suggest that users were attempting to do a good job and were not assigning relevance grades purely at random , but based on what they considered to be relevant given the provided query context .",
    "+   + we can conclude then , that the ranking quality of _ samtla _ and its underlying @xmath5 correlates well with the ranking generated by the user relevance judgements , both in terms of which documents were relevant and also of the top document , which were most likely to meet their information across query types , from single word queries to long more verbose queries .",
    "crowdsourcing has its challenges , in particular , the researcher has little control over the evaluation process once it is launched and available online . therefore , as we have demonstrated ,",
    "it is necessary to consider the use of test queries in order to filter out bad users upfront e.g. those who have not understood the task or do not have the correct attitude .",
    "this increases the quality of the submissions , and mitigates against issues that can arise , such as an unhappy user as a result of a rejected submission , or withholding payment due to a suspect submission .",
    "these issues can be difficult to resolve and may have an impact on your reputation , and consequently on whether you will be able to submit future evaluations with the same crowd sourcing platform . +   + the design of the evaluation should record data that permits the testing of a display bias , since some users may assign relevance to document in the top ranks without necessarily digesting the snippets fully .",
    "this is easily achievable by randomising the order of the queries .",
    "it is also worth recording a timestamp for each response .",
    "this enables the researcher to check for users who are speeding through the evaluation at a rate that exceeds the ability to comfortably digest the information related to the task .",
    "we found that users assigned relevance at an average rate of three seconds per rank position .",
    "the minimum time taken was one second , which we could argue is not enough time to digest the snippet and then navigate to the drop - down box to select a relevance grade .",
    "the maximum time to select a relevance grade was 13 minutes , but this is likely the result of users being interrupted or distracted from the task .",
    "+   + furthermore , the difference between the total query average and user averages can be explained by the fact that users tended to adopt their own strategy for assigning relevance . a large number of users did not make use of all relevance grades ( see figure  [ fig : evalrelevance ] ) , but instead adopted a binary relevance approach where they only assigned grades of `` very relevant '' or `` not relevant '' to the documents .",
    "the short queries tended to have more relevant documents in the top-10 meaning that the user tended to judge relevance based on the total number of highlighted terms in the snippet . on the other hand",
    ", the longer verbose queries contained an average of 3 to 4 `` very relevant '' documents , with the remaining results containing partial matches to the query , which received less relevance .",
    "for example , documents containing a full match for the query `` ... @xmath6as the lord commanded@xmath7 $ ] ... '' naturally received higher relevance scores than the partial match `` ... @xmath6as th@xmath7$]y @xmath6lord commanded@xmath7 $ ] ... '' .",
    "however , this is often user - dependent , and it could be argued that a researcher of the bible would find the latter example just as relevant to their information need , or at least , that it provides an interesting example for their research .",
    "+   +    in conclusion , we have shown that non - parametric correlation and @xmath4 measures provide a good basis for assessing the performance of an information retrieval system .",
    "the non - parametric correlation measures show the degree of agreement between what users considered relevant and the ranking generated by the @xmath5 ( see section  [ sec : datamodel ] ) .",
    "on the other hand , the @xmath4 described the ranking quality of the ranked lists , and we observe that the system consistently produces a ranking where the top ranks are occupied by the most relevant documents .",
    "we also described how we can measure the overall opinion or agreement between the users by comparing each user with the _ consensus _ ranking , which showed that each individual user agreed on average with the ranking generated by the crowd .",
    "lastly , the significance of the results was evaluated with the _ bootstrap _ method , which is non - parametric , relatively simple to implement , and as effective as other significance tests @xcite . +   + using crowdsourcing as a platform for system evaluation provides researchers with access to a large group of potential participants , but as we have demonstrated , it is necessary to design the evaluation in such a way so as to minimise technical challenges , minimise poor quality results , and record data on user interaction with the evaluation software in order to spot potential cheating .",
    "we have introduced the underlying framework of the samtla system ( section  [ sec : architecture ] ) , and the data structures and algorithms adopted .",
    "we showed how statistical language models can be used for ranking documents according to user queries ( section  [ sec : datamodel ] ) and demonstrated that our implementation is providing users with the most relevant documents in the top ranks of the search results ( section  [ sec : evaluation ] ) . +   + we also described how users interact with the system ( section  [ sec : ui ] ) , and the tools we have currently released to our user groups ( section  [ sec : textmining ] ) .",
    "the case studies provide an insight into how our users are currently using these tools to carry out their research ( section  [ sec : casestudy ] ) .",
    "+   + we are now focusing on the development of the underlying framework where we look at additional parameters that can be incorporated in to the data model ( see section  [ sec : datamodel ] ) in order to add a layer of semantics to the search component .",
    "for example , we currently assume a uniform prior for all document probabilities when ranking the documents in response to a query",
    ". we can use the _ jsd _ matrix generated for the related documents tool ( see section  [ sec : relateddocuments ] ) to compute a non - uniform prior , which will enable us to integrate document - specific knowledge as part of the samtla query model .",
    "further work is centered on simple methods for identifying important events in the collection documents , which could be presented to users as a timeline .",
    "this task is often referred to as event tracking and identification @xcite .",
    "+   + the main novelty of samtla is the underlying probabilistic model that has enabled us to develop a diverse range of tools that are language independent and applicable to many document collections , including flexible search and mining of text patterns , document comparison , query and document recommendation , and the way the system can incorporate external sources of information in the form of metadata provided by users or third - party sources such as wikipedia , to supplement the toolset .",
    "samtla aims to complement existing methods in the digital humanities by helping researchers with their research needs by providing a general purpose environment .",
    "+   + in summary , we have discussed how systems developed for the humanities can be made future - proof in the sense of providing a generalised framework that can be easily extended to new document collections without changes to the underlying system components in order to compensate for language - specific issues such as word stemming and tokenisation .",
    "although samtla is still in development we already have a number of samtla systems available for a range of document collections ( king james bible , aramaic magic bowls , vasari , the microsoft corpus , and the financial times ) , which cover a broad range of corpora composed of one or more languages including aramaic , syriac , mandaic , hebrew , english , german , french , hungarian , italian , and russian .",
    "in addition , samtla is not necessarily restricted to historic document collections , but can be extended straightforwardly to other application domains , which require search and mining of text patterns , such as medical and legal text collections .",
    "o.  alonso and r.  a. baeza - yates .",
    "design and implementation of relevance assessments using crowdsourcing . in _ advances in information",
    "retrieval - 33rd european conference on ir research , ecir 2011 , dublin , ireland , april 18 - 21 , 2011 . proceedings _ , pages 153164 , 2011 .",
    "v.  broughton .",
    "faceted classification as a basis for knowledge organization in a digital environment : the bliss bibliographic classification as a model for vocabulary management and the creation of multidimensional knowledge structures .",
    ", 7(1):67102 , july 2002 .",
    "s.  p. crain , k.  zhou , s .- h .",
    "yang , and h.  zha .",
    "dimensionality reduction and topic modeling : from latent semantic indexing to latent dirichlet allocation and beyond . in c.  c. aggarwal and c.  zhai , editors , _ mining text data _ ,",
    "pages 129161 .",
    "springer , 2012 .",
    "u.  m. fayyad , g.  piatetsky - shapiro , and p.  smyth .",
    "advances in knowledge discovery and data mining .",
    "chapter from data mining to knowledge discovery : an overview , pages 134 .",
    "american association for artificial intelligence , menlo park , ca , usa , 1996 .",
    "s.  huston and w.  b. croft .",
    "evaluating verbose query processing techniques . in _ proceedings of the 33rd international acm sigir conference on research and development in information retrieval _ , sigir 10 , pages 291298 , new york , ny , usa , 2010 .",
    "j.  kazama and k.  torisawa .",
    "exploiting wikipedia as external knowledge for named entity recognition . in _",
    "joint conference on empirical methods in natural language processing and computational natural language learning _ , pages 698707 , 2007 .",
    "a.  kittur , e.  h. chi , and b.  suh .",
    "crowdsourcing user studies with mechanical turk . in _ proceedings of the sigchi conference on human factors in computing systems _ , chi 08 , pages 453456 , new york , ny , usa , 2008 .",
    "acm .",
    "a.  leff and j.  rayfield .",
    "web - application development using the model / view / controller design pattern . in _ enterprise",
    "distributed object computing conference , 2001 .",
    "fifth ieee international _",
    ", pages 118127 , 2001 .",
    "d.  d. lewis .",
    "naive ( bayes ) at forty : the independence assumption in information retrieval . in _ proceedings of the 10th european conference on machine learning _ , ecml 98 , pages 415 , london , uk , uk , 1998 .",
    "springer - verlag .",
    "t.  sakai .",
    "evaluating evaluation metrics based on the bootstrap . in _ proceedings of the 29th annual international acm sigir conference on research and development in information retrieval _ , sigir 06 , pages 525532 , new york , ny , usa , 2006 .",
    "acm .",
    "m.  d. smucker , j.  allan , and b.  carterette .",
    "a comparison of statistical significance tests for information retrieval evaluation . in _ proceedings of the sixteenth acm conference on conference on information and knowledge management _ , cikm 07 , pages 623632 , new york , ny , usa , 2007 .",
    "m.  sweetnam , m.  agosti , n.  orio , c.  ponchia , c.  steiner , e.  hillemann , m.    siochr , and s.  lawless .",
    "user needs for enhanced engagement with cultural heritage collections . in",
    "_ proceedings of the international conference on theory and practice of digital libraries ( tpdl ) _ , pages 6475 , 2012 .",
    "o.  f. zaidan and c.  callison - burch .",
    "crowdsourcing translation : professional quality from non - professionals . in _ proceedings of the 49th annual meeting of the association for computational linguistics : human language technologies - volume 1 _ , hlt 11 , pages 12201229 , stroudsburg , pa , usa , 2011 .",
    "association for computational linguistics ."
  ],
  "abstract_text": [
    "<S> samtla ( search and mining tools with linguistic analysis ) is a digital humanities system designed in collaboration with historians and linguists to assist them with their research work in quantifying the content of any textual corpora through approximate phrase search and document comparison . </S>",
    "<S> the retrieval engine uses a character - based @xmath0-gram language model rather than the conventional word - based one so as to achieve great flexibility in language agnostic query processing . </S>",
    "<S> + the index is implemented as a space - optimised character - based suffix tree with an accompanying database of document content and metadata . </S>",
    "<S> a number of text mining tools are integrated into the system to allow researchers to discover textual patterns , perform comparative analysis , and find out what is currently popular in the research community . </S>",
    "<S> + herein we describe the system architecture , user interface , models and algorithms , and data storage of the samtla system . </S>",
    "<S> we also present several case studies of its usage in practice together with an evaluation of the systems ranking performance through crowdsourcing .    </S>",
    "<S> * keywords : * digital humanities , statistical language model , information retrieval , text analysis </S>"
  ]
}