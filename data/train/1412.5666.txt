{
  "article_text": [
    "a recent trend in data - mining is to find communities in a graph . generally speaking",
    ", a community in a graph is a vertex set such that the number of edges contained entirely inside the set is `` significantly more than expected . ''",
    "these communities are then used to describe cliques in social networks , families of proteins in protein - protein interaction networks , construct groups of similar products in recommendation systems , among other applications . for",
    "a survey on the state of community detection see @xcite .",
    "there are multiple measurements that assess how the number of edges contained in a vertex set exceeds what is expected , and each is considered legitimate for a subset of applications .",
    "finding an optimum set of vertices is * np*-hard for most of these measurements , with a few exceptions @xcite .",
    "the measurement that will be investigated in this paper is _",
    "conductance_.    let @xmath2 be a weighted undirected graph . for shorthand",
    ", @xmath3 will mean @xmath4 .",
    "also , @xmath5 will represent @xmath3 and @xmath6 .",
    "the adjacency matrix @xmath7 is the matrix @xmath8 , where @xmath9 is the weight on the edge @xmath10 and @xmath11 if @xmath12 .",
    "this paper will operate on the assumption that @xmath13 for all edges @xmath10 , although this assumption is not ubiquitous .",
    "the degree of a vertex @xmath14 is @xmath15 , and the degree matrix @xmath16 is a diagonal matrix with entries @xmath17 .",
    "we assume that our graphs have no isolated vertices ; equivalently , @xmath18 for all @xmath19 . for the rest of this paper",
    ", we will assume that our graphs have @xmath20 vertices and @xmath21 edges , unless otherwise specified .",
    "the conductance of a subset of vertices @xmath0 , denoted by @xmath22 , is the sum of the weights on the edges incident with exactly one vertex of @xmath0 divided by the sum of the degrees of the vertices in @xmath0 .",
    "typically it is assumed that the sum of the degrees of the vertices in @xmath0 is at most half the sum of the degrees of all vertices in @xmath23 , as one can alternatively consider the set @xmath24 .",
    "stub _ is a half edge - for each edge @xmath25 , there is a stub incident with @xmath26 and a stub incident with @xmath27 .",
    "each stub is given a weight equal to the weight on the edge containing said stub .",
    "let @xmath28 be the set of stubs incident with @xmath0 ( the assigned or `` colored '' stubs ) .",
    "let @xmath29 be the set of stubs @xmath30 from an edge @xmath21 such that @xmath30 is incident with @xmath0 , but the other stub from @xmath21 is not incident with @xmath0 ( the `` bad '' stubs ) .",
    "for a set of edges and stubs @xmath31 , let @xmath32 be the sum of the weights on the stubs plus twice the sum of the weights on the edges .",
    "using this notation , @xmath33 .",
    "the _ combinatorial laplacian _ is @xmath34 and the _ normalized laplacian _ is @xmath35 .",
    "if we define a vector @xmath36 such that @xmath37 if @xmath38 and @xmath39 otherwise , then the _ rayleigh quotient _ of @xmath40 is the same as the conductance of @xmath0 : @xmath41 hence , minimizing the value of @xmath42 over all vectors @xmath43 is considered a _ continuous relaxation _ of the problem of finding a good community .",
    "note that if @xmath44 , then @xmath45 .",
    "@xmath46 and @xmath47 are positive semidefinite , and @xmath46 has eigenvectors with eigenvalues @xmath48 .    the most famous method to `` round '' a solution of the continuous relaxation into a good solution to the original discrete problem is the cheeger inequality ( see @xcite ) .",
    "let @xmath21 be an eigenvector of @xmath46 corresponding to eigenvalue @xmath49 .",
    "let @xmath50 be the vertex set @xmath51 .",
    "cheeger s inequality states that under these conditions there exists @xmath52 such that @xmath53 .",
    "there have been multiple heuristic attempts to generalize cheeger s inequality by using several eigenvectors , see @xcite for a survey of such algorithms .",
    "an approach with theoretical rigor was found very recently by two groups independently : louis , raghavendra , tetali , and vempala @xcite and lee , gharan , and trevisan @xcite .",
    "they both showed that for any disjoint @xmath54 communities @xmath55 the @xmath56 .",
    "[ trevisan thm ] there exist disjoint vertex sets @xmath57 such that for each @xmath19 , we have that @xmath58 for some absolute constant @xmath59 .",
    "furthermore , there exist disjoint sets @xmath57 such that for each @xmath19 , we have that @xmath60    we consider a new goal in community detection : finding good _",
    "bipartite communities_. a bipartite community is a pair of disjoint vertex sets @xmath61 such that the number of edges with one endpoint in @xmath0 and the other endpoint in @xmath1 is `` significantly more than expected . ''",
    "to this end , we will define a measurement of bipartite conductance .",
    "let @xmath62 be the set of edges entirely contained in @xmath0 or entirely contained in @xmath1 , and let @xmath63 .",
    "the bipartite conductance of @xmath64 is @xmath65 . because @xmath66 , it clearly follows that @xmath67 , so if @xmath64 is a good bipartite community then @xmath68 is a good community .",
    "qualitatively , a good bipartite community is a good community with additional structure , and finding a good bipartite community is a refinement of finding a good community .",
    "we claim that this additional structure is natural to some applications of community detection .",
    "in fact , using other terminology , they have already been used to study protein interactions @xcite and group - versus - group antagonistic behavior @xcite in online social settings ( also known as a `` flame war '' ) .",
    "the study of correlation clustering ( see the introduction to @xcite for a survey ; also studied under the name `` community detection in signed graphs '' @xcite ) is the special case where an edge may represent similarity _ or dissimilarity _ , and a recent approach by atay and liu @xcite involved bipartite communities .",
    "there are many more possible applications : a network of spammers and their targets will display bipartite behavior",
    ". another application would be to isolate a regional network of airports inside a global graph of air traffic , where the two sets represent major hub airports and small local airports ( the assumptions being that small local airports almost exclusively have flights to geographically close hub airports and major hub airports send relatively few flights to other major hub airports that are geographically close ) .",
    "finally , we suggest that it is natural to look for a bipartite relationship when examining co - purchasing networks . in this case",
    ", each side of the community would be different brands of the same product - people are unlikely to purchase two versions of the same product in one shopping trip .",
    "the benefit of looking for the additional structure of a bipartite community in these scenarios is that false positives will be weeded out .",
    "for example , an algorithm for classical community detection algorithms is likely to return the set of international airports at the core of the air transportation network as a community instead of regional networks , because the core of international hubs form a stronger `` rich - club '' than even the internet backbone @xcite .",
    "another benefit is the two - sided labels a bipartite community gives to its members .",
    "kleinberg considered a related problem @xcite for directed graphs when he developed the famous _ hyperlink induced topic search _ ( hits ) algorithm to find results for a web search query .",
    "his algorithm looked to label a subset of webpages as `` hubs '' or `` authorities , '' with the only criteria for such labeling being that hub webpages have many links to authority webpages .",
    "the hits algorithm is then spectral clustering using the eigenvectors of @xmath69 .",
    "kleinberg s algorithm is famous for its strength , but it does have a known issue of reporting popular websites instead of websites that are popular _ in reference to the search query_. this is because the large eigenvectors of an adjacency matrix are dominated by vertices of high degree @xcite , and the normalized laplacian is known to present results that better match the topology of the graph .",
    "we take a moment here to use one final application as an example that will help distinguish a bipartite community from a _",
    "bicluster_. a bicluster is a classical community during the special case when the underlying graph @xmath23 is bipartite .",
    "for example , kluger , basri , chang , and gerstein @xcite find biclusters in a bipartite graph that matched genes to different environmental conditions that affect how those genes are expressed . on the other hand , bellay et .",
    "@xcite found bipartite communities in a graph where genes are matched _ to each other _ when they affect the expression of each other . to be specific : the rate of growth of yeast colonies is modified by a known rate when one of the genes in the set is deleted ; an edge is added between two genes when the observed modification to the rate of growth after both genes are deleted is statistically different from the product of the modifications from each independent gene deletion .",
    "this particular study of gene interaction is called _",
    "double mutant combinations _ , and bipartite communities are suggested to correspond to redundant pathways @xcite .",
    "we will investigate the existence of bipartite communities in several public source data sets , including the double mutant combination network for yeast cells .",
    "we will also look for bipartite communities in a network of political blogs ; our results will match kleinberg s model for the internet .",
    "we will show that bipartite communities can be found using the largest eigenpairs of @xmath46 .",
    "this is not the first time that the largest eigenpairs of @xmath46 and @xmath47 have been studied .",
    "they are frequently seen as duals to the small eigenpairs of @xmath46 and @xmath47 ( see @xcite and @xcite ) .",
    "they have also been the focus of independent interest because of the related problem of max - cut .",
    "the problem of max - cut is to find a vertex set @xmath0 such that @xmath70 is maximized ( and equivalently @xmath71 is minimized ) .",
    "let @xmath72 . if @xmath73 is the largest eigenvalue of @xmath47 , then @xmath74 @xcite .",
    "it follows that @xmath75 .",
    "certain strengthenings of this are possible , giving tight results for specific classes of graphs @xcite .",
    "there is a similar proof to show that @xmath76 .",
    "one of the most recent results in approximate solutions to max - cut is from trevisan , who recursively seeks out bipartite communities and returns a set of vertices that is the union of one of the two vertex sets from each bipartite community . if @xmath77 for some bipartite community @xmath64 where @xmath78 if @xmath38 , @xmath79 if @xmath80 , and @xmath81 otherwise , then @xmath82\\ ] ] while we had equality for classical communities .",
    "it follows that for any @xmath83 disjoint bipartite communities @xmath84 , we have the @xmath85 .",
    "[ one dim algorithm ] let @xmath21 be an eigenvector of @xmath46 corresponding to eigenvalue @xmath49",
    ". for @xmath86 , let @xmath50 be the vertex set @xmath87 and @xmath88 be the vertex set @xmath89 .",
    "under these conditions , there exists a @xmath52 such that @xmath90 .",
    "liu @xcite showed that there exists @xmath54 disjoint bipartite communities that satisfy @xmath91 .",
    "the main theoretical work of this paper is to strengthen this bound .",
    "[ main ] fix a value for @xmath54 .",
    "there exists disjoint sets @xmath92 such that for any graph @xmath23 and each @xmath93 , + ( a ) @xmath94 and @xmath95 .",
    "+ ( b ) @xmath96 and @xmath97 .    to summarize the result asymptotically :    [ main cor ] there exists a constant @xmath59 such that for any graph @xmath23 and value of @xmath54 there exist disjoint sets @xmath92 such that for each @xmath93 , + ( a ) @xmath94 and @xmath98 . + ( b ) @xmath99 and @xmath100 .",
    "liu @xcite proved that large unweighted cycles satisfy @xmath101 there exist several examples that show that the @xmath102 term is necessary for theorem [ trevisan thm ] ( see @xcite and @xcite ) .",
    "we modify one of those examples to demonstrate the sharpness of corollary [ main cor ] .",
    "we call this example the _ bipartite noisy hypercube_.    [ bipartite noisy hypercubes ] let @xmath54 and @xmath103 be fixed , with @xmath104 , and let @xmath105 .",
    "let @xmath106 be the weighted complete bipartite graph on @xmath107 vertices , where @xmath108 , an edge @xmath109 exists if and only if @xmath110 is odd , and the weight of edge @xmath109 is @xmath111 .",
    "in @xmath106 we have that @xmath112 and for any set @xmath113 with @xmath114 we have that @xmath115 .",
    "the outline for the rest of the paper is as follows : in section 2 we prove theorem [ main ] , followed by the details of example [ bipartite noisy hypercubes ] in section 3 , and concluding with section 4 where we present a heuristic algorithm and empirical results on its performance .",
    "louis , raghavendra , tetali , and vempala @xcite and lee , gharan , and trevisan @xcite used different approaches to prove theorem [ trevisan thm ] .",
    "both groups considered the @xmath54 eigenvectors as a mapping into @xmath116 .",
    "the former randomly projected the points in spectral space onto the axes , where each axis forms a candidate community to be calculated using the same procedure as cheeger s inequality .",
    "the latter grouped points together in @xmath116 using a random @xmath117-net followed by a test of magnitude for community membership .",
    "our approach is a hybrid of these arguments : we will partition the points in @xmath116 randomly , and each part of the partition will be deterministically projected onto an axis where a community will be calculated using the same procedure as theorem [ one dim algorithm ] .",
    "we will be examining the signless normalized laplacian @xmath118 and the smallest eigenpairs of @xmath119 . because @xmath120 , the eigenvalues of @xmath119 are @xmath121 , and the eigenvectors of @xmath46 are the eigenvectors of @xmath119 in reverse order .",
    "let @xmath122 be a map , and let @xmath123 be the standard euclidean distance between points @xmath124 .",
    "we define the _ signless rayleigh quotient of @xmath125 _ to be @xmath126 if @xmath127 and @xmath128 , then @xmath129 let @xmath130 be the eigenvectors of @xmath119 that correspond to the smallest eigenvalues , and for each @xmath19 , let @xmath131 . because @xmath119 is symmetric , we may choose our @xmath132 to be orthonormal .",
    "it follows that @xmath133 .",
    "it is also an easy calculation to see that @xmath134 for all @xmath19 .",
    "we choose @xmath135 .    for each vertex @xmath26 with @xmath136 ,",
    "let @xmath137 .",
    "for this type of operation we will modify the _ radial projection distance _",
    ", which is @xmath138 when well defined and @xmath139 when @xmath140 or @xmath141 is the origin .",
    "this is the distance function used by lee , gharan , and trevisan to cluster points in spectral space to find subsets of vertices with low conductance .",
    "the radial projection distance can be thought of as an angle - based distance because if @xmath142 is the angle between @xmath140 and @xmath141 , then @xmath143 when @xmath144 are not the origin .",
    "however , to find subsets of vertices that have low bipartite conductance , we wish to cluster a vertex @xmath26 with vertices that map to a point close to @xmath145 as well as close to @xmath146 . for points @xmath40 and",
    "@xmath147 , we define the _ mirror radial projection _ to be @xmath148 when @xmath149 and @xmath150 otherwise .",
    "this is equivalent to the distance function on the appropriate projective space .",
    "let @xmath151 and @xmath152 if @xmath153 , and @xmath154 and @xmath155 otherwise . as a slight abuse of notation , for vertices",
    "@xmath156 we use the shorthand notation @xmath157 , which equals @xmath158 when @xmath159 . if @xmath160 is the angle between @xmath146 and @xmath161 , then @xmath162 . for fixed vertex @xmath26",
    "we have that @xmath163 behaves like standard euclidean distance for all pairs of vertices @xmath164 such that @xmath165 .",
    "when not specified , all distance functions are assumed to be @xmath166 .",
    "we define a ball for @xmath167 to be @xmath168 such that @xmath169 .    for a set of points @xmath0 and distance function @xmath170",
    ", we write the _ diameter _ of @xmath0 as @xmath171 . for a set of vertices",
    "@xmath31 , we define the _ volume _ to be @xmath172 and the _ mass _ to be @xmath173 . we will use @xmath174 to denote a partition of the vertex set , and @xmath175 to denote the part of the partition that contains vertex @xmath26 .",
    "we say that @xmath125 is @xmath176-_spreading _ if for every subset of vertices @xmath0 with diameter less than @xmath177 has mass at most @xmath178 .",
    "the support of a map @xmath179 is the subset of the domain @xmath180 that is defined by @xmath181 if and only if @xmath182 .",
    "note that @xmath183      [ spreading ] if @xmath184 , then @xmath125 is @xmath185-spreading .",
    "let @xmath0 be a set of points with diameter at most @xmath177 and @xmath186 . if @xmath0 contains a point at the origin and has diameter less than @xmath187 , then @xmath188 .",
    "furthermore , points at the origin have no mass , and thus the lemma is true trivially .",
    "so we may restrict our attention to vertices that @xmath125 does not map to the origin .",
    "let @xmath189 be the angle between vectors @xmath190 and @xmath191 , and let @xmath192 be the angle between vectors @xmath190 and @xmath193 .",
    "observe , @xmath194    the statement of the lemma then follows by comparing this to    @xmath195    we will partition our space by greedily assigning new points to a part ; suppose that @xmath196 have been assigned to some part .",
    "pick a random point @xmath197 , and create a new part equal to @xmath198 . repeat until @xmath199 .",
    "charikar , chekuri , goel , guha , plotkin @xcite proved that this simple algorithm performs reasonably well .    [ partition happy ] there exists a randomized algorithm to generate a partition @xmath174 such that each part of the partition has diameter at most @xmath177 and @xmath200 \\leq \\frac{2 \\sqrt{k } d_m(u , v)}{\\delta}.\\ ] ]    each of our communities will be a subset of a union of parts .",
    "we will produce a lemma that shows that edges @xmath25 with @xmath201 contribute very little to the term @xmath202 .",
    "[ wooooo ] for any @xmath122 and @xmath203 such that @xmath159 , we have that @xmath204 .    for brevity ,",
    "let @xmath205 and @xmath206 . among all vectors",
    "@xmath207 with magnitude @xmath208 , the one that minimizes @xmath209 is @xmath210 . using this",
    ", we see that @xmath211    if @xmath212 , then @xmath213 , and the lemma follows . if @xmath214 , then @xmath215 , and the lemma follows .",
    "[ i think i solved it ] for any @xmath122 and @xmath203 such that @xmath159 , we have that @xmath216    apply the cauchy - schwartz formula to see that @xmath217      [ all the work ] if we have a randomized method to generate a partition @xmath174 with @xmath83 parts such that @xmath218 \\leq c_1 d_m(u , v)$ ] and each part has mass at least @xmath219 , then there exists vertex sets @xmath220 where @xmath221 .",
    "let @xmath222 denote an indicator variable .",
    "choose a partition @xmath174 that performs at least as well as the expectation in the sense that @xmath223    fix some @xmath19 ; we will find the communities @xmath84 independently .",
    "we will project @xmath125 onto one of its coordinates @xmath224 , and use @xmath225 instead of @xmath125 .",
    "when there is no chance for confusion , we will use @xmath226 as shorthand for @xmath224 . if we choose a @xmath226 at random then the terms @xmath227 and @xmath228 have expectation @xmath229 and @xmath230 . choose a @xmath226 such that there exists an @xmath231 where @xmath232 and @xmath233 @xmath234 each @xmath226 may be chosen independently for each fixed @xmath19 , but there is only one partition @xmath174 , which was chosen before we fixed the value for @xmath19",
    ". we will then use ( [ pick j ] ) by summing across all values for @xmath19 at once , where the right hand side becomes ( after using lemma [ i think i solved it ] and ( [ pick p ] ) ) @xmath235 the two terms in the left hand side of ( [ pick p ] ) ) are positive so they are independently bounded by the right hand side .",
    "the two independent bounds are @xmath236 @xmath237 and @xmath238    let @xmath239 .",
    "choose @xmath240 uniformly and randomly and define two sets @xmath241 , @xmath242 .",
    "let @xmath243 if @xmath244 , @xmath245 if @xmath246 , and @xmath247 otherwise .",
    "note that @xmath248 and @xmath249 , so our theorem is equivalent to proving @xmath250    the expected volume of @xmath251 is the mass of @xmath252 : @xmath253           & = &     \\sum_{u \\in p_i}d(u)\\mathbb{p}[f_{j}(u)^2 \\geq t\\alpha _ i ] \\\\                          & = &     \\sum _ { u \\in p_i }   d(u ) f_{j}(u)^2 \\alpha _",
    "i^{-1}\\hat{\\alpha}^{-1 } \\\\                          & = &     \\hat{\\alpha}^{-1 } \\sum _ { u \\in p_i } \\|f(u)\\|^2 d(u ) \\\\                          &",
    "\\geq & \\hat{\\alpha}^{-1 } c_2 \\sum _ { u \\in v } \\|f(u)\\|^2 d(u).\\end{aligned}\\ ] ]    we claim that if @xmath254 , then @xmath255 the proof of this splits into two cases : when @xmath256 and when @xmath257 .",
    "for the first case , assume that @xmath258 .",
    "we will only consider the case @xmath259 ; the other case follows similarly .",
    "in this situation , the case becomes @xmath260 for the second case , we have that @xmath257 . by symmetry , assume that @xmath261 .",
    "in this situation , the case becomes @xmath262 this concludes the proof to the claim .",
    "we make use of this to count the bad stubs in all of our communities .    using ( [ bound f_j ] ) , @xmath263   & \\leq &     \\sum_i \\sum_{u \\in p_i } \\sum_{v \\in n(u ) } w_{uv}\\mathbb{p}[v \\notin p_i , u \\in",
    "s_t \\cup s_t ' ] \\\\                      &    &    + \\sum_i \\sum_{u \\in p_i } \\sum_{v \\in n(u ) } w_{uv}\\mathbb{e}_t[|y_u + y_v| : u , v \\in p_i ] \\\\",
    "& \\leq & \\sum_i \\sum_{u \\in p_i } \\sum_{v \\in n(u ) } w_{uv}\\chi(p(u ) \\neq p(v ) ) f_j(u)^2 \\alpha _ i^{-1}\\hat{\\alpha}^{-1 } \\\\",
    "&    &     +   \\sum_i \\sum_{u \\in p_i } \\sum_{v \\in n(u ) } w_{uv}\\left(|f_{j}(u)| + |f_{j}(v)|\\right)\\left|f_{j}(u ) + f_{j}(v)\\right|\\alpha _ i^{-1}\\hat{\\alpha}^{-1 }   \\\\                      & \\leq & 2\\hat{\\alpha}^{-1}c_1(1 + \\sqrt{2 } ) \\tilde{\\mathcal{r}}(f)^{-1/2 } \\sum_{ij \\in e^ < }",
    "\\|f(u ) + f(v)\\|^2 \\\\                      &    & + \\hat{\\alpha}^{-1 } \\sum_i \\sum_{u \\in p_i } \\sum_{v \\in n(u ) } w_{uv}\\left(|f_{j}(u)| + |f_{j}(v)|\\right)\\left|f_{j}(u ) + f_{j}(v)\\right|\\alpha _ i^{-1}.\\end{aligned}\\ ] ] in order to bound the term @xmath264 apply the cauchy - schwartz formula and ( [ bound f_j + f_j ] ) as follows : @xmath265                       & \\leq & \\sqrt { \\sum_i \\sum_{u \\in p_i } \\sum_{v \\in n(u ) } w_{uv}\\alpha _ i^{-1 }   \\left|f_{j^{(i)}}(u ) + f_{j^{(i)}}(v)\\right|^2 } \\\\                      &      &    \\cdot   \\sqrt { \\sum_i \\sum_{u \\in p_i } \\sum_{v \\in n(u ) } w_{uv}\\alpha _ i^{-1 }   \\left ( |f_{j^{(i)}}(u)| + |f_{j^{(i)}}(v)|\\right)^2 } \\\\                      & \\leq & \\sqrt { \\sum_{uv \\in e^ < } 2(1 + \\sqrt{2 } ) w_{uv}\\|f(u ) + f(v)\\|^2 } \\sqrt{2\\sum_{u \\in v } d(u ) \\|f(u)\\|^2 } \\\\                      & = & 2\\sqrt{\\frac{(1 + \\sqrt{2})}{\\tilde{\\mathcal{r}}(f ) } }   \\sum_{ij \\in e^ < }",
    "\\|f(u ) + f(v)\\|^2 .\\end{aligned}\\ ] ] plugging the bound on @xmath266 into our previous bound yields @xmath267 \\leq 2\\hat{\\alpha}^{-1 } \\sqrt{\\frac{(1 + \\sqrt{2})}{\\tilde{\\mathcal{r}}(f ) } } \\left(c_1 \\sqrt{1 + \\sqrt{2 } } + 1\\right ) \\sum_{ij \\in e^ < }",
    "\\|f(u ) + f(v)\\|^2.\\ ] ]    after @xmath268 is chosen , there will be some order such that @xmath269 when @xmath270 .",
    "this ordering implies that @xmath271 using @xmath272 and @xmath273 we have that @xmath274 > 0.\\ ] ] if @xmath275 , then @xmath276 and the term inside [ final ineq ] is zero .",
    "so we may choose @xmath268 separately for each @xmath19 that performs at least as well as the expectation and satisfies @xmath277 .",
    "let @xmath278 .",
    "so each ball with diameter at most @xmath177 contains at most @xmath279 mass by lemma [ spreading ] .",
    "use lemma [ partition happy ] to partition @xmath280 into parts with with diameter at most @xmath177 , where for arbitrary edge @xmath156 we have that @xmath281 \\leq 4k d_m(u , v)$ ] .",
    "if two parts of the partition have mass less than @xmath282 each , then combine them ( this process will maintain the property that each part has mass at most @xmath279 ) .",
    "we claim that we now have at least @xmath54 parts with mass at least @xmath282",
    ". if we have at most @xmath283 such parts in @xmath174 , then the sum of the masses of those parts is at most @xmath284 .",
    "so either there are two parts left with mass at most @xmath282 that should have been combined , or there is one extra part with mass at least @xmath282 .",
    "this proves the claim .",
    "the final step of the proof is to apply theorem [ all the work ] with @xmath285 , @xmath94 , and @xmath286 .",
    "we follow the dimension reduction arguments of @xcite .",
    "let @xmath287 , and let @xmath288 be random independent @xmath54-dimensional gaussians , and define a projection @xmath289 as @xmath290 .",
    "this mapping enjoys the properties ( see @xcite ) for any @xmath197 @xmath291 = \\|x\\|^2\\ ] ] and @xmath292 \\right ] \\leq 2e^{-\\delta^2h/12}.\\ ] ]    let @xmath293 .",
    "recall markov s inequality : if @xmath294 is a non - negative random variable , then @xmath295 } \\geq a \\right ] \\leq 1/a$ ] .",
    "this implies that with probability @xmath296 we have that @xmath297 let @xmath298 $ ] .",
    "we see that @xmath299 \\leq |v|2e^{-(0.1)^2h/12 } = \\frac{|v|}{100k^2}.\\ ] ] this implies that with probability @xmath296 we have that @xmath300 .",
    "therefore with the same @xmath296 probability we have that @xmath301 the probability of the intersection of two ( possibly dependent ) events , each with probability at least @xmath296 , is at least @xmath302 .",
    "so with probability at least @xmath302 we have that @xmath303    we used @xmath304 to describe the set of vertices that `` behaved appropriately . ''",
    "we will now use @xmath305 to describe the set of pairs of vertices that `` behave appropriately . ''",
    "let @xmath306\\}.\\ ] ] by definition , if @xmath307 , then @xmath308 .",
    "observe , @xmath309          & = & \\sum_{uv \\in v^2 } d(u)\\|f(u)\\|^2 d(v ) \\|f(v)\\|^2 \\mathbb{p}[uv \\notin u_e ] \\\\",
    "& \\leq & \\sum_{uv \\in v^2 } d(u)\\|f(u)\\|^2 d(v ) \\|f(v)\\|^2 2e^{-(0.1)^2h/12 } \\\\          & = & \\left ( \\frac{\\mathcal{m}(v)}{10k } \\right)^2.\\end{aligned}\\ ] ] we can then say that with @xmath296 probability we have @xmath310 we claim that @xmath311 is spreading . by way of contradiction , let @xmath312 be a ball in @xmath313 with diameter at most @xmath314 and @xmath315 .",
    "let @xmath207 be an arbitrary vertex such that @xmath316 . by the triangle inequality we have that @xmath317 .",
    "let @xmath318 , so that if @xmath319 and @xmath320 , then @xmath321 . by lemma",
    "[ spreading ] , the mass of @xmath322 is at most @xmath323 . by our assumption",
    ", this implies that @xmath324 we then sum this over all possible values of @xmath207 to get @xmath325 this is a contradiction , and therefore our claim is true .",
    "the proof now easily follows from the proof to theorem [ main].a .",
    "project the points into @xmath313 , and then partition the points in the projected space using lemma [ partition happy ] and desired radius @xmath326 .",
    "we have probability @xmath302 that @xmath327 and probability @xmath296 that each ball of the projected space has mass at most @xmath328 , and so both of these things happen with probability at least @xmath329 .",
    "similar to before , we may combine the parts of the partitions until we have at least @xmath330 parts , each with mass at least @xmath331 .",
    "the final step of the proof is to apply theorem [ all the work ] with @xmath311 instead of @xmath125 , so that we may use @xmath332 , @xmath333 , and @xmath334 to satisfy the assumptions of the theorem .",
    "in this section we will give the details behind the noisy bipartite hypercube , example [ bipartite noisy hypercubes ] .",
    "let @xmath54 and @xmath103 be fixed , with @xmath104 , and let @xmath105 .",
    "let @xmath335 be the weighted complete graph on @xmath107 vertices , where each vertex corresponds to a finite binary sequence of length @xmath54 ( in other words @xmath108 ) , and the weight of edge @xmath109 is @xmath111 .",
    "@xmath335 is called the _",
    "noisy hypercube_. lee , gharan , and trevisan @xcite demonstrated a separation between the eigenvalues of @xmath335 and the conductance of small sets in the graph .",
    "we define @xmath106 to be a complete bipartite spanning subgraph of @xmath335 such that @xmath336 ( and keeps the same weight ) if and only if @xmath337 is odd .",
    "we will show that @xmath106 satisfies @xmath112 and for any set @xmath113 with @xmath114 we have that @xmath115 .",
    "this will show that corollary [ main cor ] is sharp .",
    "the norm between @xmath338 in the above example is defined to be the number of entries in which @xmath40 and @xmath147 are different ( denoted by @xmath110 ) .",
    "we will drop the subscripts @xmath54 and @xmath103 from @xmath335 when it is clear . for vertex subsets",
    "@xmath339 define @xmath340 to be the set of edges with one endpoint in @xmath7 and the other endpoint in @xmath312 ; edges contained inside @xmath341 are counted twice .",
    "let @xmath342 be the sum of the weights on the edges in @xmath340 .",
    "we can consider a vector @xmath343 as a map @xmath344 , where @xmath345 is the value in coordinate @xmath19 of the vector . in this notation",
    ", we can think of the matrices @xmath7 and @xmath46 as operators on real - valued functions whose domain is @xmath280 .",
    "this notation - of maps and operators - also holds when we think of @xmath280 in terms of @xmath346 instead of @xmath347 . for example , the _ adjacency matrix operator _ is @xmath348 .",
    "let @xmath349 denote the set of functions defined from @xmath346 into @xmath350 with the inner - product of two functions @xmath351 defined by @xmath352 the _ @xmath353-norm _ of a function @xmath343 is @xmath354 , therefore @xmath355 .",
    "our proofs will make use of the rich field of study on maps whose domain is @xmath346 .",
    "our notation follows that of @xcite .",
    "we also found the course notes @xcite that odonnel grew into a book @xcite to be enlightening .",
    "we will need a select few theorems from this field , which we present below .",
    "the _ walsh functions _ defined by @xmath356 for @xmath357 $ ] form an orthonormal basis for @xmath349 .",
    "thus , any @xmath358 can be written as @xmath359 } \\widehat{f}(s)w_s(x)$ ] for some set of coefficients @xmath360 .",
    "we call @xmath360 the _ fourier coefficients _ of @xmath343 where @xmath361 also recall parseval s identity which states that @xmath362}\\widehat{f}(s)^2 $ ] .",
    "we define a _ noise process _",
    "@xmath363 to be a randomized automorphism on @xmath346 , where @xmath364 = \\eta^{\\|x - y\\|_1}(1-\\eta)^{k - \\|x - y\\|_1}$ ] .",
    "this is the standard model for independent bit - flip errors in coding theory .",
    "the _ noise operator _ is defined to be @xmath365 $ ] .",
    "the noise operator is suggested to `` flatten out '' the values of @xmath343 , although the exact strength to which this is true remains open @xcite .",
    "this process is intimately linked to fourier coefficients and walsh functions by @xmath366 } \\widehat{f}(s)\\eta^{|s|}w_s(x)$ ] ( this is also known as the bonami - beckner operator ) . the final statement that we need",
    "is the bonami - beckner inequality : if @xmath367 and @xmath368 , then @xmath369 .",
    "we will not need the full generality of this statement , just that if @xmath370 , then @xmath371 } \\widehat{f}(s)^2 \\eta^{2|s| }   \\leq \\|f\\|_{1+\\eta^2}^2.\\ ] ]      we begin by calculating the degree of a vertex in @xmath335 .",
    "let @xmath40 be a fixed vertex , so that the degree of @xmath40 is @xmath372 using this generating function , we see that the degree @xmath373 of @xmath40 in @xmath106 is @xmath374    it will be convenient to define a graph @xmath375 to be the subgraph of @xmath335 where @xmath376 . using a symmetrical argument , we see that each vertex in @xmath375 has degree @xmath377 .",
    "we have chosen our @xmath117 , @xmath103 , and @xmath54 such that @xmath378 .",
    "we will use the eigenvalues of the adjacency matrix to calculate the eigenvalues of the laplacian of our graph . because our graph is regular , the eigenvectors of the laplacian are the same as the eigenvectors of the adjacency matrix .",
    "we can use this information to directly calculate the eigenvalues associated to @xmath379 . for this calculation we will need the eigenvalues of the normalized adjacency matrix .",
    "the _ normalized adjacency matrix _ is defined by @xmath380 .",
    "if @xmath208 is an eigenvalue of the adjacency matrix for a regular graph , @xmath381 will denote the associated eigenvalue of the normalized version .",
    "let @xmath382 .",
    "the first lemma states that @xmath383 is an eigenfunction of the operator @xmath7 with eigenvalue @xmath384 .",
    "[ eigenvalue ] let @xmath357 $ ] . then , @xmath385 .    using lemma [ eigenvalue ] we see that for each @xmath386 , with multiplicity @xmath387 , the normalized laplacian has eigenvalue @xmath388 by choosing the @xmath389 sets @xmath0 with @xmath390 , we have that our eigenvalues satisfy @xmath391 .",
    "we used mathematica to confirm that @xmath392 for the ranges of @xmath393 allowed .",
    "now we return to give the proof of lemma [ eigenvalue ] .",
    "_ proof of lemma [ eigenvalue ] .",
    "_ let @xmath357 $ ] .",
    "consider the following :    @xmath394    first we will concentrate on the first summand in the above expression , call it @xmath395 .",
    "in @xmath395 we are summing over all @xmath396 such that the following two conditions hold :    1 .",
    "@xmath397 + 2 .",
    "@xmath398 .",
    "notice that @xmath399 .",
    "thus , @xmath400 in a similar fashion , the second summand , call it @xmath401 , can be seen to be @xmath402    now , notice that @xmath403 and @xmath404 . pulling everything back together we observe    @xmath405    our proof about small sets having large conductance will make use of the fact that @xmath406      in this subsection we will prove that @xmath407 for any @xmath408 with @xmath409 . recall that @xmath410 and let @xmath411 . because @xmath412 , this will conclude the details of example [ bipartite noisy hypercubes ] .",
    "we will require the following two lemmas .",
    "let @xmath413 $ ] and define @xmath414 to be the characteristic function of @xmath31 .",
    "under these conditions , @xmath415 } \\left(\\frac{1-\\epsilon}{1+\\epsilon}\\right)^{|s|}\\left ( \\widehat{\\mathbbm{1}_t}(s)\\right)^2.\\ ] ]    _ proof .",
    "_ let @xmath413 $ ] . recall that @xmath416 , and so by ( [ adj eig ] ) we have that @xmath417 . using that the walsh functions form an orthonormal basis , we observe : @xmath418 } \\widehat{\\mathbbm{1}_t}(s)w_s(x)\\right ) \\left ( \\sum_{s'\\subseteq [ k ] } \\widehat{\\mathbbm{1}_t}(s')\\frac{1}{d_k^o}aw_{s'}(x)\\right)\\\\              & = & \\frac{1}{n}\\sum_{x\\in\\{0,1\\}^k } \\left ( \\sum_{s\\subseteq [ k ] } \\widehat{\\mathbbm{1}_t}(s)w_s(x)\\right ) \\left ( \\sum_{s'\\subseteq [ k ] } \\widehat{\\mathbbm{1}_t}(s')\\overline{\\rho_{|s'|}}w_{s'}(x)\\right)\\\\              & = & \\sum_{s\\subseteq [ k]}\\sum_{s'\\subseteq [ k]}\\widehat{\\mathbbm{1}_t}(s)\\overline{\\rho_{|s'| } } \\widehat{\\mathbbm{1}_t}(s')\\left(\\frac{1}{n } \\sum_{x\\in\\{0,1\\}^k}w_s(x)w_{s'}(x)\\right)\\\\              & = & \\sum_{s\\subseteq [ k ] } \\overline{\\rho_{|s| } } \\left ( \\widehat{\\mathbbm{1}_t}(s)\\right)^2 \\\\              & \\leq & \\sum_{s\\subseteq [ k ] } \\frac{11}{10}\\left ( \\frac{1-\\epsilon}{1+\\epsilon}\\right)^{|s| } \\left ( \\widehat{\\mathbbm{1}_t}(s)\\right)^2 . \\hfill\\qed\\end{aligned}\\ ] ]    let @xmath413 $ ] .",
    "then , @xmath419    _ proof .",
    "_ let @xmath413 $ ] .",
    "notice that what we really are proving is that @xmath420 .",
    "now consider    @xmath421    we are now ready to prove the main result from this section .",
    "the conductance @xmath407 for any @xmath408 with @xmath409 .",
    "_ let @xmath413 $ ] be such that @xmath422 .",
    "then , @xmath423    by ( [ bonami - beckner ] ) with @xmath424 , we have that @xmath425 } \\left(\\frac{1-\\epsilon}{1+\\epsilon}\\right)^{|s|}\\left ( \\widehat{\\mathbbm{1}_t}(s)\\right)^2 \\\\      & \\leq & \\frac{11n}{10|t| } \\left\\|\\mathbbm{1}_t\\right\\|^2_{1+\\eta^2}\\\\      & = & \\frac{11n}{10|t| } \\left(\\frac{|t|}{n}\\right)^{2/(1+\\eta^2 ) } \\\\      & = & \\frac{11}{10 } \\left ( \\frac{|t|}{n } \\right)^\\epsilon.\\end{aligned}\\ ] ]    by choice of @xmath117 , we have that @xmath426",
    "we do not recommend trying to implement the argument in section [ nbh ] for real - world use .",
    "the construction was optimized for rigorous bounds at the cost of efficiency and real - world performance .",
    "we now present a modified version of the construction in the proof .",
    "the outline of the construction is the same .",
    "this modified version does not have any rigorous bounds , but it has good performance and does not require significant computational power .",
    "we also take advantage of things observed by applied mathematicians . for example , the theoretical proof partitions the points in spectral space greedily , which gives poor but rigorous bounds on concentration .",
    "however , there is ample empirical evidence @xcite that the spectral space of real - world graphs are strongly clusterable . also ,",
    "when we project down to one dimension , we do not necessarily project down onto one axis .",
    "by examining the @xmath427 plot in figure @xmath428 of @xcite , we see that some communities are best detected using a combination of several eigenvectors .        1 .",
    "calculate @xmath125 , and throw out all points at the origin .",
    "2 .   let @xmath137 and let @xmath434 be the range of @xmath435 .",
    "3 .   calculate @xmath83 random centers @xmath436 such that @xmath437 .",
    "4 .   run @xmath83-means . for @xmath438",
    ": 1 .   initialize each cluster @xmath439 for @xmath93 .",
    "2 .   for each point @xmath440 , 1 .",
    "find the value of @xmath441 such that @xmath442 is minimum .",
    "2 .   if @xmath443 , then assign @xmath444 , otherwise set @xmath445 .",
    "3 .   calculate the centers : for @xmath93 , 1 .",
    "if @xmath446 is nonempty , calculate @xmath447 .",
    "2 .   if @xmath439 , set @xmath448 to equal a random point @xmath449 . leave @xmath450 empty .",
    "4 .   repeat ( b ) and ( c ) as necessary .",
    "5 .   for @xmath451 ,",
    "if @xmath450 is non - empty do : 1 .   for each vertex @xmath452 , calculate @xmath453 .",
    "2 .   find appropriate @xmath454 and @xmath455 as thresholds .",
    "3 .   set @xmath456 and @xmath457 .",
    "because finding the largest eigenvectors is an approximate algorithm , we will abuse notation by saying that a vector @xmath458 is `` at the origin '' if @xmath459 . since @xmath132 denotes an eigenvector , we will use the notation @xmath460 to denote the unit vector that is @xmath187 in the @xmath461 coordinate and @xmath462 in all other coordinates .",
    "when we say @xmath463 , we have represented the vector @xmath40 using an approximation by deleting any @xmath460 whose coefficient is less than @xmath464 . to find appropriate values for @xmath465 and @xmath466",
    ", we tested every pair of values under two conditions :        recall that the bipartite conductance from our @xmath470 strongest community must be at least @xmath471 .",
    "we will use this to compare our communities to the `` best possible '' based on the eigenvalues that we calculate .",
    "it has been commented that the `` best '' theoretical bounds @xcite for community detection use linear programming for a continuous relaxation instead of spectral methods .",
    "the best bounds from linear programming are @xmath472 . in the graphs we encountered , the spectral values are not very small , and therefore the bounds from the eigenvalues performed much better in practice .",
    "our algorithm was run on four data sets below : a biological network , the hyperlink structure between a set of websites , a traffic routing network for telecommunication companies , and relationships between fictional characters .",
    "our heuristic algorithm found bipartite communities where the @xmath470 best community has bipartite conductance less than @xmath473 .",
    "this is significantly better than the bound in theorem [ main ] , and borders on the best possible . despite that bipartite conductance is larger than conductance on the same vertex set , the second and third best bipartite communities found by our algorithm had lower bipartite conductance than the conductance of the second and third best classical communities found by a standard algorithm in the telecommunications network !",
    "our algorithm found communities with relevant structure in all but the biological network . on political blogs ,",
    "our algorithm found the authority / hub framework first described by kleinberg @xcite . on telecommunication networks , our algorithm found a community local to a regional network ( korea ) rather than the dense formation at the logical center .",
    "furthermore , the two sets of the community provided information about the peering relationship . this can be used to infer the _ level _ of a telecommunications company , which approximates how close it is to the logical center of the internet .",
    "information about levels can be used to efficiently route traffic @xcite by idealizing the network as a hyperbolic space .",
    "hence our results do not just score well ; they have qualitative significance too .",
    "costanzo et .",
    "@xcite prepared a data set of how a colony of yeast would react when a pair of genes were deleted , which is available at the supplementary online material website @xcite .",
    "this is the data set discussed in section 1 when the difference between a bicluster and a bipartite community is clarified .",
    "a yeast colony typically grows at a rate of @xmath268 , and when gene @xmath19 is mutated it grows at rate @xmath474 .",
    "the double mutant combinations is then an analysis of when genes @xmath19 and @xmath226 are deleted and the yeast colony grows at a rate of @xmath475 .",
    "we specifically worked with data set @xmath476 , where edge @xmath10 exists if the experimental value of @xmath477 is more than @xmath478 , and the @xmath353-value for the true value of @xmath479 equaling @xmath462 is less than @xmath480 .",
    "we chose this specific data set because it was recommended to us by one of the authors , chad myers .",
    "the experiment specifically only tested gene combinations with one gene from an array set @xmath7 and the other gene from a query set @xmath481 .",
    "both sets are large , with @xmath482 and @xmath483 .",
    "we used the graph induced by the intersection of the two lists , where @xmath484 .",
    "this induced subgraph has @xmath485 directed edges .",
    "there were @xmath486 edges that were close to the cut - off threshold and were only represented in one direction .",
    "we chose to include an undirected edge if either orientation of it exists in the directed graph ; this produced @xmath487 undirected edges without multiplicities .",
    "we originally ran our algorithm with @xmath488 eigenvectors .",
    "however , the expected distance between two random unit vectors in @xmath116 is @xmath489 . in the end",
    "this space was too sparse , and none of the parts of the partitions contained more than @xmath490 genes .",
    "we modified our algorithm to run on @xmath491 eigenvectors , and we only required the radius for each partition to be @xmath492 instead of @xmath493 .",
    "this change was unique to this data set .",
    "the basic facts about the eigenvalues can be seen in the table below .",
    "there was one vertex at the origin that was thrown out .",
    "as you can see , this graph has no good bipartite communities .",
    "we ran @xmath83-means to find three clusters . in every case , @xmath495 ( and so @xmath496 and @xmath497 ) .",
    "the behavior is clear : this graph has no bipartite communities and so the algorithm is spreading the communities out to try to cover the entire graph .",
    "recall that we originally established that communities are vaguely defined terms .",
    "conductance is only one measure of a `` good community . ''",
    "our algorithm has proven that this is not the correct method for this data set .",
    "conductance is a measure that wants the community to be exclusive , while the _ modular hypothesis _",
    "@xcite suggests that each module may be in many communities with other modules .",
    "hence their algorithm to find bipartite communities only counts good edges , while not significantly penalizing for bad edges . based on our discussion in section 1",
    ", it may be better for this application to use @xmath47 instead of @xmath46 .",
    "there is some silver lining to this result - it does fix one of the trade offs mentioned in the discussion section of @xcite .",
    "their methods had very strict conditions for when a set of vertices formed a bipartite community .",
    "those conditions led to very small communities : they reported a mode of @xmath499 genes per community , and it appears that none have more than @xmath500 genes ( see figure s5 in supplementary materials ) . these communities do not cover entire pathways , and an ad - hoc procedure is developed to reduce overlapping communities into one single subset of a pathway .",
    "our algorithm naturally looked for larger communities , and each likely contains entire pathway(s ) .",
    "we have a graph with @xmath501 blogs that focus on political matters .",
    "this data set was originally put together by adamic for a paper by adamic and glance @xcite ; we found it on a list of data sets maintained by mark newman @xcite .",
    "the name of each blog is given , and a value is given for whether the blog has a liberal or conservative bias .",
    "there were @xmath502 blogs with a liberal bias and @xmath503 with a conservative bias .",
    "the graph contains an unweighted directed multi - edge from blog @xmath504 to blog @xmath505 for each time blog @xmath504 contains a hyperlink to blog @xmath505 .",
    "we turn this into a weighted undirected simple graph , where the weight on edge @xmath506 is the number of directed edges in the original graph from @xmath504 to @xmath505 or from @xmath505 to @xmath504 .",
    "the normalized laplacian of our new graph has @xmath507 as an eigenvalue with multiplicity @xmath187 .",
    "the maximum eigenvector is nonzero in just two coordinates , at blogs `` digital-democrat.blogspot.com '' and `` thelonedem.com , ''",
    "each of which is in just one edge with weight @xmath507 to the other .",
    "we call this the _ trivial bipartite community_. the graph also has @xmath508 isolated vertices ( blogs that never linked or were linked by other blogs ) .",
    "we remove the isolated blogs and the blogs in the trivial community , and continue on the reduced graph .",
    "we call our reduced graph the _ blog graph_. we present the basic facts about the eigenvalues below .",
    "the communities found by our algorithm are somewhat strong , with @xmath511 .",
    "we will assess our algorithms ability to pass the `` eye - test '' by finding expected structures inside our reported communities .",
    "based on previous applications of bipartite communities mentioned in section 1 , we know of two possible structures that might be expected in our communities .",
    "one is that we might see group - versus - group antagonistic behavior ( called a _ flame war _ ) , which would be represented by many links between blogs from different political parties .",
    "the second structure is the authority - hub framework suggested by hits , which would be represented by a uniform orientation of the original links .",
    "another sign of the authority - hub framework is that one side should have a large in - degree and the other side should have a large out - degree .",
    "we will now define a few parameters that will help us assess whether or not these structures are present in our results .",
    "let @xmath512 denote the ratio of edges that involve a blog from each political party among all edges that cross from @xmath513 to @xmath514 .",
    "let @xmath515 denote the average out - degree and @xmath516 denote the average in - degree based on the hyperlink orientations in the original data set .",
    "finally , let @xmath517 denote ratio of edges , among all edges that cross from @xmath513 to @xmath514 , that are oriented from a blog with a positive projection score to a blog with a negative projection score . because this would be @xmath518 in a random graph",
    ", we set @xmath519 $ ] . by this construction , a large @xmath520 would indicate a strong authority / hub structure without bias from which of @xmath513 and @xmath514 is the set of hubs and which is the set of authorities .",
    "the first conclusion is that this algorithm did not pick up even a trace of a flame war .",
    "cluster 2 , and to a lesser extent cluster 1 , do demonstrate an authority - hub framework .",
    "now we see how these parameters adjust when we restrict @xmath450 to @xmath522 . @xmath523        our next data set is the caida relationships dataset for autonomous systems ( as ) from november 12 , 2007 , which was downloaded from the stanford snap project @xcite , who received it from leskovec , kleinberg , and faloutsos @xcite .",
    "we associated each autonomous system identifier with a name using a table found at geoff huston s personal website @xcite .",
    "an autonomous system is a communications company that routes internet traffic .",
    "the data represents a collection of inter - company connections used for routing traffic through several in - between carriers . from the information provided",
    ", we created an unweighted undirected graph .",
    "our dataset also includes information about the type of relationship ( customer , provider , or peer ) that two linked companies have , which we choose to ignore until we perform an autopsy on our results .",
    "the graph contains as s @xmath187 through @xmath525 .",
    "however , as one as buys another , or some as disappears for any other reason , only half of the as s in that range were active at the time our graph was made .",
    "specifically , @xmath526 of those addresses were not in any relationships , and so we removed them .",
    "we clustered using the top twenty eigenvalues , none of which had trivial eigenvectors .",
    "we describe the results below .",
    "the algorithm returned at least one weak community ( @xmath530 ) and several trivial communities ( @xmath531 and @xmath532 ) .",
    "however , the seven other communities are within @xmath533 times the best possible , and some of them are within @xmath534 times the best possible . as a comparison , we also ran classical community detection algorithms on the graph .",
    "we made only two changes to our heuristic algorithm to do this : we calculated the smallest eigenpairs of @xmath46 and used standard distance euclidean distance instead of @xmath535 . note that if we skip step 5 and just returned @xmath450 as the community , then this algorithm would be equivalent to the one developed by ng , jordan , and weiss @xcite . to avoid confusion ,",
    "the set of vertices forming the @xmath470 classical community will be denoted @xmath536 . as a fair comparison",
    ", we also tested for the @xmath488 smallest eigenvalues and clustered for the best @xmath537 clusters .",
    "we can immediately see that the continuous relaxation has stronger solutions for classical communities than for bipartite communities .",
    "specifically , there are six non - trivial eigenvalues less than @xmath541 , while only one eigenvalue is at least @xmath542 .",
    "the classical algorithm also had no issue with trivial communities , as the smallest community returned with @xmath543 members . however , the classical algorithm had more issues with weak communities than the bipartite algorithm ; as it had three communities with classical conductance over @xmath544 compared to one community with bipartite conductance over @xmath544 , and one community with classical conductance over @xmath545 compared to no communities with bipartite conductance that large .",
    "the strongest communities from the two algorithms are quite comparable : the best classical community has a stronger score than the best bipartite community , the second and third best bipartite communities have stronger scores than the second and third best classical communities respectively , and the fourth best classical community is better than the fourth best bipartite community .",
    "the communities discovered by the two algorithms are largely disjoint , with the notable exception of the best - scoring communities from each algorithm .",
    "the twelve as s in @xmath546 with the best @xmath547 score are in order : @xmath548 the top two best scorers in @xmath549 are @xmath550 and @xmath551 , while the top ten in @xmath552 are : @xmath553 all of the as s listed above are based in korea .",
    "a diagram of the connections between these as s is presented in figure [ asn figure ] .",
    "the diagram demonstrates that the difference between @xmath549 and @xmath552 contains information about peering relationships .",
    "we have a graph with @xmath554 characters and @xmath555 journals owned by publisher marvel .",
    "this data was put together by alberich , miro - julia , and rosell @xcite , and we found it on the amazon web services @xcite list of large data sets .",
    "the graph is bipartite ; a character is linked to a journal title if the character appears in that journal . from this",
    ", we create a different undirected unweighted graph .",
    "each vertex corresponds to a character , and the two characters are adjacent if there exists a journal that they both appear in .",
    "we call our new graph the _ marvel graph_.    among the largest eleven eigenvalues of the normalized laplacian of the marvel graph , there are eigenvalues @xmath507 and @xmath556 , with multiplicities @xmath187 and @xmath490 , respectively .",
    "it is well known that the multiplicity of @xmath507 as an eigenvalue corresponds to the number of bipartite components in the graph . in this case , the marvel graph has one bipartite component , and it is one edge between the characters `` master of vengeance '' and `` steel spider / ollie o. '' the space of eigenvectors with eigenvalue @xmath556 can be generated by vectors @xmath557 , where each @xmath558 is non - zero in exactly two coordinates .",
    "furthermore , each non - zero coordinate of @xmath558 corresponds to a vertex with degree two , and the vertices are adjacent . as an odd structural motif ,",
    "each of the @xmath490 pairs of vertices have a common neighbor .",
    "we call these ten bipartite communities the trivial communities of the marvel graph .",
    "we display information for the ten largest eigenvalues for the non - trivial communities below . @xmath559    using the above ten eigenvectors , we threw out @xmath560 vertices at the origin in addition to the deleted trivial communities .",
    "we found four clusters among the remaining vertices .",
    "the centers are dominated by just a few of the eigenvectors , and those eigenvectors are the ones with many non - zero coordinates .",
    "the basic stats of the clusters are listed below .      by examining the eigenvalues ,",
    "we conclude from this that the marvel graph simply does not have strong bipartite communities",
    ". however , our algorithm did find bipartite communities with bipartite conductance that is within @xmath562 of best possible .",
    "the point of using the marvel graph instead of the ubiquitous hollywood graph is that we can de - anonymize the nodes and use an `` eye - test '' to see if the bipartite communities have any significance .",
    "the descriptions of some of the characters in our bipartite communities are accessible by a quick internet search ; some of the characters are too obscure to find their background . based on the characters whose backgrounds we were able to track down , our communities",
    "do have a cohesive theme .",
    "most of the top scorers in @xmath563 have a scientific or pseudo - scientific background ( `` zabo , '' `` past master , '' `` dr .",
    "joanne tumolo , '' and `` dr . edwin hawkins '' ) ; characters in @xmath564 are villains and characters in @xmath565 are side characters .",
    "most of the top scorers in @xmath566 are from the `` spiderman '' comics .",
    "two of the top five scorers in @xmath567 are villains ( `` brainstorm '' and `` rocket racer ii '' ) , and two others are minor characters ( `` sarah chan '' and `` clarice bernhard '' ) . on the other side ,",
    "the second and fourth highest scorers in @xmath568 are spiderman s wife and boss ( `` mary watson - parker '' and `` j. jonah jameson '' ) .",
    "all of the top scorers in @xmath569 involve the comic series surrounding the protagonist `` dr .",
    "strange . ''",
    "furthermore , the top scorers in @xmath570 are different manifestations of dr .",
    "strange ( `` dr vincent stevens , '' `` strange , '' `` noble , '' and `` paradox '' ) .",
    "the characters in @xmath571 include a villain ( `` sister nil '' ) , a love interest ( `` clea '' ) , and a financial relationship ( `` azopardi '' ) .",
    "the classical community formed by @xmath572 is centered on a setting called `` earth-9910 , '' but we found no clear distinction between the characters in @xmath573 and the characters in @xmath574 .    * acknowledgments .",
    "* we would like to thank geoffrey sanders and noah streib for their helpful notes on this manuscript .",
    "we would also like to thank randall dahlberg for his support and assistance .",
    "we are grateful for shiping liu s kind emails that filled in the holes of the literature review from earlier drafts of this manuscript .",
    "finally , we would like to thank chad myers for his help in finding and understanding the gene interaction data set .",
    "j. bellay , g. atluri , t. sing , k. toufighi , m. costanzo , p ribeiro , g. pandey , j. baller , b. vandersluis , m. michaut , s. han , p. kim , g. brown , b. andrews , c. boone , v. kumar , and c. myers , `` putting genetic interactions in context through a global modular decomposition . '' _ genome research _ _ 21 _ ( 2011 ) , 1375  1387 .",
    "m. costanzo , a. baryshnikova , j. bellay , y. kim , e. spear , c. sevier , h. ding , j. koh , k. toufighi , s. mostafavi , j. prinz , r. st onge , b. vandersluis , t. makhnevych , f. vizeacoumar , s. alizadeh , s. bahr , r. brost , y. chen , m. cokol , r. deshpande , z. li , z. lin , w. liang , m. marback , j. paw , b. san luis , e. shuteriqi , a. tong , n. van dyk , i. wallace , j. whitney , m. weirauch , g. zhong , h. zhu , w. houry , m. brudno , s. ragibizadeh , b. papp , c. pal , f. roth , g. giaever , c. nislow , o. troyanskaya , h. bussey , g. bader , a. gingras , q. morris , p. kim , c. kaiser , c. myers , b. andrews , and c. boone , `` the genetic landscape of a cell . '' _ science _ * 327 * ( 2010 ) , 425431 .",
    "m. costanzo , a. baryshnikova , j. bellay , y. kim , e. spear , c. sevier , h. ding , j. koh , k. toufighi , s. mostafavi , j. prinz , r. st onge , b. vandersluis , t. makhnevych , f. vizeacoumar , s. alizadeh , s. bahr , r. brost , y. chen , m. cokol , r. deshpande , z. li , z. lin , w. liang , m. marback , j. paw , b. san luis , e. shuteriqi , a. tong , n. van dyk , i. wallace , j. whitney , m. weirauch , g. zhong , h. zhu , w. houry , m. brudno , s. ragibizadeh , b. papp , c. pal , f. roth , g. giaever , c. nislow , o. troyanskaya , h. bussey , g. bader , a. gingras , q. morris , p. kim , c. kaiser , c. myers , b. andrews , and c. boone , http://drygin.ccbr.utoronto.ca/~costanzo2009/        g. gallier , `` spectral graph theory of unsigned and signed graphs applications to graph clustering : a survey '' ( 2015 manuscript available at http://www.cis.upenn.edu/~jean/hot.html , which is an update from the 2013 manuscript _ arxiv _",
    "@xmath578 )      v. henson , g. sanders , and j. trask , `` extremal eigenpairs of adjacency matrices wear their sleeves near their hearts : maximum principles and decay rates for resolving community structure . '' _ lawrence livermore national laboratory technical report _ * llnl - tr-618872 * ( available at https://library-ext.llnl.gov ) .",
    "j. kunegis , s. schmidt , a. lommatzsch , j. lerner , e. de luca and s. albayrak , `` spectral analysis of signed graphs for clustering , prediction and visualization . '' _ proc .",
    "siam int . conf . on data mining _",
    "* 12 * ( 2010 ) 559570 .",
    "j. li , g. liu , h. li , and l. wong , `` maximal biclique subgraphs and closed pattern pairs of the adjacency matrix : a one - to - one correspondence and mining algorithms . ''",
    "_ ieee transactions on knowledge and data engineering _ * 19 * , 12 ( 2007 ) , 16251637 .",
    "b. prakash , m. seshadri , a. sridharan , s. machiraju , and c. falostsos , `` eigenspokes : surprising patterns and scalable community chipping in large graphs . ''",
    "_ 2009 ieee international conference on data mining workshops _ 290295 .      c. tsourakakis , f. bonchi , a. gionis , f. gullo , and m. tsiarli , `` denser than the densest subgraph : extracting optimal quasi - cliques with quality guarantees . ''",
    "_ proceedings of the 19th acm sigkdd _ ( 2013 ) , 104112 .",
    "l. wu , x. ying , x. wu , a. lu , and z - h .",
    "zhou , `` spectral analysis of k - balanced signed graphs . ''",
    "_ proceedings of the 15th pacific - asia conference on knowledge discovery and data mining ( pakdd11 ) _ ( 2011 ) 112 ."
  ],
  "abstract_text": [
    "<S> a recent trend in data - mining is to find communities in a graph . generally speaking </S>",
    "<S> , a community in a graph is a vertex set such that the number of edges contained entirely inside the set is `` significantly more than expected . '' </S>",
    "<S> these communities are then used to describe families of proteins in protein - protein interaction networks , among other applications . </S>",
    "<S> community detection is known to be np - hard ; there are several methods to find an approximate solution with rigorous bounds .    </S>",
    "<S> we present a new goal in community detection : to find good bipartite communities . </S>",
    "<S> a bipartite community is a pair of disjoint vertex sets @xmath0 , @xmath1 such that the number of edges with one endpoint in @xmath0 and the other endpoint in @xmath1 is `` significantly more than expected . '' </S>",
    "<S> we claim that this additional structure is natural to some applications of community detection . </S>",
    "<S> in fact , using other terminology , they have already been used to study correlation networks , social networks , and two distinct biological networks . </S>",
    "<S> we will show how the spectral methods for classical community detection can be generalized to finding bipartite communities , and we will prove sharp rigorous bounds for their performance . additionally , we will present how the algorithm performs on public - source data sets .    </S>",
    "<S> _ keywords _ : community detection , spectral graph theory , network analysis    _ 2010 mathematics subject classification_:05c90 , 90c35 </S>"
  ]
}