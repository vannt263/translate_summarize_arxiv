{
  "article_text": [
    "image understanding @xcite is becoming one of the most important problems in computer vision and many research efforts have been devoted to this topic . while object recognition @xcite and scene recognition @xcite have been extensively studied in the task of image classification , event recognition @xcite in still images received much less research attention , which also plays an important role in semantic image interpretation .",
    "as shown in figure [ fig : example ] , the characterization of event is extremely complicated as the event concept is highly related to many other high - level visual cues , such as objects , scene categories , human garments , human poses , and other context . therefore , event recognition in still images poses more challenges for the current state - of - the - art image classification methods , and needs to be further investigated in the computer vision research .",
    "convolutional neural networks ( cnns ) @xcite have recently enjoyed great successes in large - scale image classification , in particular for object recognition @xcite and scene recognition @xcite . for event recognition ,",
    "much fewer deep learning methods have been designed for this problem .",
    "our previous work @xcite proposed a new deep architecture , called _ object - scene convolutional neural network _",
    "( os - cnn ) , for cultural event recognition .",
    "os - cnns are designed to extract useful information for event understanding from the perspectives of containing objects and scene categories , respectively .",
    "os - cnns are composed of two - stream cnns , namely object nets and scene nets .",
    "object nets are pre - trained on the large - scale object recognition datasets ( e.g. imagenet @xcite ) , and scene nets are based on models learned from the large - scale scene recognition datasets ( e.g. places205 @xcite ) .",
    "decomposing into object nets and scene nets enables us to use the external large - scale annotated images to initialize os - cnns , which may be further fine tuned elaborately on the event recognition dataset .",
    "finally , event recognition is performed based on the late fusion of softmax outputs of object nets and scene nets .        following the research line of os - cnns , in this paper",
    ", we try to further explore different aspects of os - cnns and better exploit os - cnns for better event recognition .",
    "specifically , we design four types of investigation scenarios to study the performance of os - cnns . in the first scenario",
    ", we directly use the softmax outputs of cnns as recognition results . in the next three scenarios ,",
    "we treat cnns as feature extractors , and use them to extract both _ global _ and _ local _ features of an image region .",
    "global features are more compact and aim to capture the holistic structure , while local features focus on describing the image details and local patterns .",
    "our experimental results indicate these two kinds of features are complementary to each other and robust for event recognition . based on our empirical explorations with os - cnns ,",
    "we come up with our solution for the cultural event recognition track at the iccv chalearn looking at people ( lap ) challenge @xcite and we secure the third place .",
    "the rest of this paper is organized as follows . in section [ sec : os - cnn ] , we will give a brief introduction to os - cnns , including network architectures and implementation details .",
    "after that , we will introduce our extensive explorations with os - cnns for event recognition in section [ sec : feature ] .",
    "we then report our experimental results in section [ sec : exp ] .",
    "finally , we conclude our method and present the future work in section [ sec : con ] .",
    "in this section , we will first briefly introduce the architecture of _ object - scene convolutional neural networks _ ( os - cnns ) , which was proposed in our previous work @xcite .",
    "then , we will present the implementation details of os - cnns , including network structures , data augmentations , and learning policy .",
    "event is a relatively complicated concept in computer vision research and highly related with other two problems : object recognition and scene recognition .",
    "the basic idea behind os - cnn is to utilize two separate components to perform event recognition from the perspectives of occurring objects and scene context .",
    "specifically , os - cnns are composed of object nets and scene nets , as shown in figure [ fig : os - cnn ] .",
    "* object nets . *",
    "object net is designed to capture useful information of objects to help event recognition .",
    "intuitively the occurring objects are able to provide useful cues for event understanding .",
    "for instance , in the cultural event of australia day as shown in figure [ fig : example ] , australian flag will be a representative object . as the main goal of object net is to deal with object cues ,",
    "we build it based on recent advances on large - scale object recognition , and pre - train the network on the public imagenet models .",
    "then , we further fine tune the model parameters on the training dataset of cultural event recognition by setting the output number as @xmath0 ( cultural event recognition dataset containing 100 classes ) .    * scene nets .",
    "* scene net is expected to extract scene information of image to assist event understanding . in general",
    ", the scene context will be helpful for recognizing the event category in the image .",
    "for example , in the cultural event of sapporo snow festival as shown in figure [ fig : example ] , outdoor will be usually the scene category . specifically , we pre - train the scene nets by using the models learned on the dataset places205 , which contains 205 scene classes and 2.5 millions images .",
    "similar to object nets , we then fine tune the network weights of scene nets on the event recognition dataset , where we set network output number as @xmath0 .",
    "based on the above analysis , recognizing cultural event will benefit from the transferred representations learned for object recognition and scene recognition .",
    "thus , we will fuse the network outputs of both object nets and scene nets as the prediction of os - cnns .          in this subsection",
    ", we will describe the implementation details of training os - cnns , including network structures , data augmentations , and learning policy .",
    "* network structures .",
    "* network structures are of great importance for improving the performance of cnns . in the past several years",
    ", many successful network architectures have been proposed for object recognition , such as alexnet @xcite , clarifainet @xcite , overfeat @xcite , googlenet @xcite , vggnet @xcite , msranet @xcite , and inception2 @xcite .",
    "some good practices can be drawn from the evolution of network architectures : smaller convolutional kernel size , smaller convolutional stride , more convolutional channel , deeper network structure . in this paper , we choose the vggnet-19 as our main investigated structure due to its good performance in object recognition , which is composed of 16 convolutional layers and 3 fully connected layers .",
    "the detailed description about vggnet-19 is out of the scope of this paper and can be found in @xcite .",
    "* data augmentations .",
    "* by data augmentation , we mean perturbing an image by transformations that leave the underlying class unchanged .",
    "typical transformations include corner cropping , scale jittering , and horizontal flipping . specifically , during the training phase of os - cnns ,",
    "we randomly crop image regions ( @xmath1 ) from 4 corners and 1 center of the whole image .",
    "meanwhile these cropped regions undergo horizontal flipping randomly .",
    "furthermore , we use three different scales to resize training images , where the smallest size @xmath2 of an image is set to @xmath3 .",
    "it should be noted that data augmentation is a method applicable to both training images and testing images . during training phase ,",
    "data augmentation will generate additional training examples and reduce the influence of over - fitting .",
    "for testing phase , data augmentation will help to improve the classification accuracy .",
    "the augmented samples can be either regarded as independent images or combined into a single representation by pooling or stacking operations . in the current implementation , during the test phase , we use sum pooling to aggregate these representations of augmented samples into a single representation .",
    "* learning policy .",
    "* effective training methods are very crucial for learning cnn models .",
    "as the training dataset of cultural event recognition is relatively small compared with imagenet @xcite and places205 @xcite , we resort to pre - training os - cnns by using these public available models trained on imagenet and places205 .",
    "specifically , we pre - train object nets with public vggnet-19 model , which achieved the top performance at ilsvrc2014 .",
    "for scene net , we use the model released by @xcite to initialize the network weights , which has obtained the best performance on the places205 dataset so far .",
    "the network weights are learned using the mini - batch stochastic gradient descent with momentum ( set to 0.9 ) . at each iteration",
    ", a mini - batch of 256 images is constructed by random sampling .",
    "the dropout ratios for fully connected layers are set as @xmath4 .",
    "as we pre - train network weights with imagenet and places205 models , we set a smaller learning rate for fine tuning os - cnns : learning rate starts with @xmath5 , decreases to @xmath6 after 5k iterations , decreases to @xmath7 after 10k iterations and the training process ends at 12k iterations . to speed up the training process",
    ", we use a multi - gpu extension version @xcite of caffe toolbox @xcite , which is publicly available online .",
    "we have introduced the architectures and implementation details about os - cnns in the previous section . in this section ,",
    "as shown in figure [ fig : pipeline ] , we will focus on describing the explorations of os - cnn activations from different layers and try to improve the recognition performance .      the simplest way to utilize os - cnns for",
    "cultural event recognition is directly using the outputs ( softmax layer ) of cnn networks as final prediction results .",
    "specifically , given an image @xmath8 , its recognition score is calculated as follows : @xmath9 where @xmath10 and @xmath11 are the prediction scores of object nets and scene nets , @xmath12 and @xmath13 are the fusion weights of object nets and scene nets . in the current implementation ,",
    "fusion weights are set to be equal for object nets and scene nets .",
    "another way to deploy os - cnns for cultural event recognition is to treat them as generic feature extractors and use them to extract the global representation of an image region .",
    "we usually extract the activations of * fully connected layers * , which are very compact and discriminative . in this case",
    ", we only use the pre - trained models without fine - tuning .",
    "specifically , given an image region @xmath14 , we extract this global representation based on os - cnns as follows : @xmath15,\\ ] ] where @xmath16 and @xmath17 are the cnn activations from pre - trained object nets and scene nets , @xmath18 and @xmath19 are the fusion weights of object nets and scene nets . in current implementation ,",
    "the fusion weights are set to be equal for object nets and scene nets .      in previous scenario , os - cnns",
    "are only pre - trained on large scale dataset of object recognition and scene recognition , and directly applied to the smaller event recognition dataset .",
    "however , it was demonstrated that fine - tuning a pre - trained cnns on the target data can improve the performance a lot @xcite .",
    "we consider fine - tuning the os - cnns on the event recognition dataset and the resulted image representations become dataset - specific .",
    "after fine - tuning process , we obtain the following global representation with the fine - tuned os - cnns : @xmath20,\\ ] ] where @xmath21 and @xmath22 are the cnn activations from the fine - tuned object nets and scene nets , @xmath18 and @xmath19 are the fusion weights of object nets and scene nets . in current implementation ,",
    "the fusion weights are set to be equal for object nets and scene nets .",
    "in previous two scenarios , we extract a global representation of an image region with os - cnns .",
    "although this global representation is compact and discriminative , it may lack the ability of describing local patterns and detailed information .",
    "inspired by the recent success on video - based action recognition with deep convolutional descriptors @xcite , we investigate the effectiveness of * convolutional layer * activations .",
    "convolutional layer features have been also demonstrated to be effective in image - based tasks , such as object recognition @xcite , scene recognition @xcite and texture recognition @xcite . in this scenario ,",
    "os - cnns are first pre - trained on large - scale imagenet and places205 datasets , and then fine - tuned on the event recognition dataset , just as in scenario 3 .",
    "specifically , given an image region @xmath8 , we first extract the convolutional feature maps of os - cnns ( activations of convolutional layers ) @xmath23 , where @xmath24 is feature map size and @xmath25 is feature channel number .",
    "each activation value in the convolutional feature map corresponds to a local receptive field in the original image , and therefore we call these activations of convolutional layers as os - cnn local representations .    after extracting os - cnn local representations , we utilize two normalization methods , namely _ channel normalization _ and _ spatial normalization _ proposed in @xcite , to pre - process these convolutional feature maps into transformed convolutional feature maps @xmath26 .",
    "more details regarding these two normalization methods are out scope of this paper and can be found in @xcite .",
    "the normalized cnn activation @xmath27 at each postion @xmath28 is called as the _ transformed deep - convolutional descriptor _ (",
    "these two kinds of normalization methods have turned out to be effective for improving the performance of cnn local representations in @xcite . moreover , the combination of them can obtain higher performance .",
    "therefore , we will use both normalization methods in our experimental explorations .",
    "finally , we employ fisher vector @xcite to encode these tdds into a global representation due to its good performance in object recognition @xcite and action recognition @xcite . in particular , according to our previous comprehensive study on encoding methods @xcite , we first use pca to reduce the dimension of tdd to @xmath29",
    ". then each tdd is soft - quantized with a gaussian mixture model ( gmm ) with @xmath30 components ( @xmath30 set to 256 ) .",
    "the first and second order differences between each tdd @xmath31 and its gaussian center @xmath32 are aggregated in the block @xmath33 and @xmath34 , respectively . the final fisher vector representation is yielded by concatenating these blocks together : @xmath35.\\ ] ] for os - cnns , the fisher vector of local representation is defined as follows : @xmath36,\\ ] ] where @xmath37 is the fisher vector representation from object nets , @xmath38 is the fisher vector representation from scene nets , @xmath18 and @xmath19 are their fusion weights and set to be equal to each other in the current implementation .      all the representations @xmath39 in previous three scenarios",
    "are used to construct a linear classifier @xmath40 , where @xmath41 is the weight of linear classifier . in our implementation , we choose libsvm @xcite as the classifier to learn the weight @xmath41 , where the parameter @xmath42 , balancing regularizer and loss , is set as @xmath43 .",
    "it is worth noting that all these representations are first normalized before fed into svm for training . for os - cnn global representations , we use @xmath44-normalization , and for os - cnn local representations",
    ", we use intra normalization and power @xmath44-normalization .",
    ".event recognition performance of os - cnn global and local representations on the validation data . [ cols=\"^,^,^,^\",options=\"header \" , ]      * datasets . *",
    "the iccv chalearn lap challenge 2015 @xcite contains a track of cultural event recognition and provides an event recognition dataset .",
    "this dataset contains images collected from two image search engines ( google images and bing images ) .",
    "there are totally 100 event classes ( 99 event classes and 1 background class ) from different countries and some images are shown in figure [ fig : example ] . from these samples , we see that cultural event recognition is really complicated , where garments , human poses , objects and scene context all constitute the possible cues to be exploited for event understanding .",
    "this dataset is divided into three parts : development data ( 14,332 images ) , validation data ( 5,704 images ) , and evaluation data ( 8,669 images ) .",
    "as we can not access the label of evaluation data , we mainly train our models on the development data and report the results on the validation data",
    ".    * evaluation protocol . *",
    "the principal quantitative measure is based on precision recall curve .",
    "they use the area under this curve as the computation of the average precision ( ap ) , which is calculated by numerical integration . finally , they average these per - class ap values across all event classes and employ the mean average precision ( map ) as the final ranking criteria . hence , in our exploration experiments , we report our results evaluated as ap value for each class and map value for all classes .      * settings . * in this exploration experiment , we use the vggnet-19 as the os - cnn network structure .",
    "we extract activations from two fully connected layers ( ` fc6 ` , ` fc7 ` ) as os - cnn global representations , and activations from four convolutional layers ( ` conv5 - 1 ` , ` conv5 - 2 ` , ` conv5 - 3 ` , ` conv5 - 4 ` ) as os - cnn local representations .",
    "it should be noted that we choose the activations after rectified linear units ( relus ) .",
    "we use @xmath44-normalization to further process os - cnn global representations for better svm training . for fisher vector representation of os - cnn local representation ,",
    "we employ intra - normalization and power @xmath44-normalization , as suggested by @xcite",
    ".    * analysis .",
    "* we first report the numerical results in table [ tbl : result ] . from these results ,",
    "several conclusions can be drawn as follows :    * we see that the object nets outperform scene nets on the task of cultural event recognition , which may imply that object cues play more important roles than scene cues for cultural event understanding .",
    "* we observe that os - cnns are effective for event recognition as it extract both object and scene information from the image .",
    "they achieve superior performance to object nets and scene nets , no matter what scenario is adopted . *",
    "we can notice that combining fine tuned features with linear svm classifier ( scenario 3 ) is able to obtain better performance than direct using the softmax output of cnns ( scenario 1 ) .",
    "this result may be ascribed to the fact that cnns are easily over - fitted to the training samples when the number of training images is relatively small .",
    "* comparing fine - tuned features ( scenario 3 ) with pre - trained features ( scenario 2 ) , we may conclude that fine tuning on the target dataset is very useful for improving recognition performance , which agrees with the findings of @xcite . * comparing the local representations ( scenario 4 ) and global representations ( scenario 3 ) of cnns , we see that global representation achieve slightly higher recognition accuracy . *",
    "we further combine the global representation ( ` fc7 ` ) with local representation ( ` conv5 - 3 ` ) of cnns and find that this combination is capable of boosting final recognition performance .",
    "this performance improvement indicates that different layers of cnns capture different level abstraction of original image .",
    "these feature activations from different layers are complementary to each other .",
    "we also plot the ap values for all event classes in figure [ fig : ap ] . from these ap values",
    ", we see that the events of ` monkey buffet festival ` and ` battle of the oranges ` achieve the highest performance ( 100% ) .",
    "this result may be ascribed to the fact that there are specific objects in these two event categories . at the same time",
    ", we notice that some event classes obtain very low ap values , such as ` halloween festival of the dead ` , ` fiesta de la candelaria ` , ` apokries ` , and ` viking festival ` .",
    "the ap values of these cultural event classes are below 50% . in general , there are no specific objects and scene context in these difficult event classes , and besides these classes are easily confused with other classes from the perspective of visual appearance , as observed from figure [ fig : result_example ] .",
    "we visualize several recognition examples in figure [ fig : result_example ] . in the row 1",
    ", we give eight examples that are successfully predicted by our method , from classes like ` keene pummpking ` , ` boryeong mud ` , ` afrikaburn ` and so on .",
    "meanwhile , we also provide some failure cases with high confidence from our method in the rows 2,3,4 . from these",
    "wrong predicted examples , we see that these failure cases are rather reasonable and there exists great confusion between some cultural event classes .",
    "for example , the event classes of ` dia de los muertos ` and ` halloween festival of the dead ` share similar human make - up and garments .",
    "the event classes of ` up helly aa ` and ` viking festtival ` share similar human dresses and containing objects .",
    "the event classes of ` harbin icen and snow festival ` and ` sapporo snow festival ` share similar scene context and color appearance .",
    "the event classes of ` chinese new year ` and ` pingxi lattern festival ` share similar containing objects . in summary",
    ", these examples in figure [ fig : result_example ] indicate that the concept of event is really complicated and there only exist slight difference between some event classes .      for final evaluation",
    ", we merge the development data ( 14,332 images ) and validation data ( 5,704 images ) into a single training dataset ( 20,036 images ) and re - train our os - cnn models on this new dataset .",
    "our final submission results to the iccv chalearn lap challenge are based on our re - trained model .    according to the above experimental explorations , we conclude that the os - cnn global and local representations are complementary to each other .",
    "thus , we choose to combine activations from ` fc7 ` and ` conv5 - 3 ` layers , to keep a balance between performance and efficiency .",
    "meanwhile , our previous study demonstrated that googlenet is complementary to vggnet @xcite .",
    "hence , we also extract a global representation by using the os - cnns of googlenet in our challenge solution . in summary , our challenge solution is composed of three representations : ( i ) os - cnn vggnet-19 local representations , ( ii ) os - cnn vggnet-19 global representations , and ( iii ) os - cnn googlenet global representations .",
    "the challenge results are summarized in table [ tbl : challenge ] .",
    "we see that our method is among the top performers and our map is very close to the best performance of this challenge ( 84.7% vs. 85.4% ) .",
    "regarding computational cost , our implementation is based on cuda 7.0 and matlab 2013a , and it takes about 1s to process one image in our workstation equipped with 8 cores cpu , 48 g ram , and tesla k40 gpu .",
    "in this paper , we have comprehensively studied different aspects of os - cnns for better cultural event recognition .",
    "specifically , we investigate the effectiveness of cnn activations from different layers by designing four types scenarios of adapting os - cnns to the task of cultural event recognition . from our empirical study , we demonstrate that the cnn activations from convolutional layers and fully connected layers are complementary to each other , and the combination of them is able to boost recognition performance . finally , we come up with a solution by using os - cnns at the iccv chalearn lap challenge and secure the third place . in the future",
    ", we may consider how to incorporate more visual cues such as human poses , garments , object and scene relationship in a systematic manner for event recognition in still images .",
    "this work is supported by a donation of two tesla k40 gpus from nvidia corporation .",
    "meanwhile this work is partially supported by national natural science foundation of china ( 91320101 , 61472410 ) , shenzhen basic research program ( jcyj20120903092050890 , jcyj20120617114614438 , jcyj20130402113127496 ) , 100 talents program of cas , and guangdong innovative research team program ( no.201001d0104648280 ) ."
  ],
  "abstract_text": [
    "<S> event recognition from still images is one of the most important problems for image understanding . </S>",
    "<S> however , compared with object recognition and scene recognition , event recognition has received much less research attention in computer vision community . </S>",
    "<S> this paper addresses the problem of cultural event recognition in still images and focuses on applying deep learning methods on this problem . </S>",
    "<S> in particular , we utilize the successful architecture of _ object - scene convolutional neural networks _ </S>",
    "<S> ( os - cnns ) to perform event recognition . </S>",
    "<S> os - cnns are composed of object nets and scene nets , which transfer the learned representations from the pre - trained models on large - scale object and scene recognition datasets , respectively . </S>",
    "<S> we propose four types of scenarios to explore os - cnns for event recognition by treating them as either `` end - to - end event predictors '' or `` generic feature extractors '' . </S>",
    "<S> our experimental results demonstrate that the global and local representations of os - cnns are complementary to each other . finally , based on our investigation of os - cnns , </S>",
    "<S> we come up with a solution for the cultural event recognition track at the iccv chalearn looking at people ( lap ) challenge 2015 . </S>",
    "<S> our team secures the third place at this challenge and our result is very close to the best performance . </S>"
  ]
}