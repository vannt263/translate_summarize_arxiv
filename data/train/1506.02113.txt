{
  "article_text": [
    "greedy equivalence search ( ges ) is a score - based search algorithm that searches over equivalence classes of bayesian - network structures .",
    "the algorithm is appealing because ( 1 ) for finite data , it explicitly ( and greedily ) tries to maximize the score of interest , and ( 2 ) as the data grows large , it is guaranteed  under suitable distributional assumptions  to return the generative structure .",
    "although empirical results show that the algorithm is efficient in real - world domains , the number of search states that ges needs to evaluate in the worst case can be exponential in the number of domain variables .    in this paper , we show that if we assume the generative distribution is perfect with respect to some dag @xmath0 defined over the observable variables , and if @xmath0 is known to be constrained by various graph - theoretic measures of complexity , then we can disregard all but a polynomial number of the backward search operators considered by ges while retaining the large - sample guarantees of the algorithm ; we call this new variant of ges _ selective greedy equivalence search _ or _ sges_. our complexity results are a consequence of a new understanding of the backward phase of ges , in which edges ( either directed or undirected ) are greedily deleted from the current state until a local minimum is reached . we show that for any _ hereditary _ and _ equivalence - invariant _ property known to hold in generative model @xmath0 , we can remove from consideration any edge - deletion operator between @xmath2 and @xmath3 for which the property does not hold in the resulting induced subgraph over @xmath4 @xmath5 and their common descendants . as an example , if we know that each node has at most @xmath6 parents , we can remove from consideration any deletion operator that results in a common child with more than @xmath6 parents .",
    "we define a new notion of complexity that we call _ v - width_. for a given generative structure @xmath0 , v - width is necessarily smaller than the maximum clique size , which is necessarily smaller than or equal to the maximum number of parents per node . by casting limited v - width and other complexity constraints as graph properties ,",
    "we show how to enumerate directly over a polynomial number of edge - deletion operators at each step , and we show that we need only a polynomial number of calls to the scoring function to complete the algorithm .",
    "the main contributions of this paper are theoretical .",
    "our definition of the new sges algorithm deliberately leaves unspecified the details of how to implement its forward phase ; we prove our results for sges given _ any _ implementation of this phase that completes with a polynomial number of calls to the scoring function .",
    "a naive implementation is to immediately return a complete ( i.e. , no independence ) graph using _ no _ calls to the scoring function , but this choice is unlikely to be reasonable in practice , particularly in discrete domains where the sample complexity of this initial model will likely be a problem . whereas we believe it an important direction , our paper does not explore practical alternatives for the forward phase that have polynomial - time guarantees .",
    "this paper , which is an expanded version of chickering and meek ( 2015 ) and includes all proofs , is organized as follows . in section",
    "[ sec : related ] , we describe related work . in section [ sec : notation ] , we provide notation and background material . in section [ sec :",
    "main ] , we present our new sges algorithm , we show that it is optimal in the large - sample limit , and we provide complexity bounds when given an equivalence - invariant and hereditary property that holds on the generative structure . in section [ sec : experiments ] , we present a simple synthetic experiment that demonstrates the value of restricting the backward operators in sges .",
    "we conclude with a discussion of our results in section [ sec : conclude ] .",
    "it is useful to distinguish between approaches to learning the structure of graphical models as _ constraint based _ , _ score based _ or _",
    "hybrid_. constraint - based approaches typically use ( conditional ) independence tests to eliminate potential models , whereas score - based approaches typically use a penalized likelihood or a marginal likelihood to evaluate alternative model structures ; hybrid methods combine these two approaches . because score - based approaches are driven by a global likelihood , they are less susceptible than constraint - based approaches to incorrect categorical decisions about independences .    there are polynomial - time algorithms for learning the best model in which each node has at most one parent .",
    "in particular , the chow - liu algorithm ( chow and liu , 1968 ) used with any equivalence - invariant score will identify the highest - scoring tree - like model in polynomial time ; for scores that are not equivalence invariant , we can use the polynomial - time maximum - branching algorithm of edmonds ( 1967 ) instead .",
    "gaspers et al .",
    "( 2012 ) show how to learn _ k - branchings _ in polynomial time ; these models are polytrees that differ from a branching by a constant @xmath6 number of edge deletions .    without additional assumptions ,",
    "most results for learning non - tree - like models are negative .",
    "meek ( 2001 ) shows that finding the maximum - likelihood path is np - hard , despite this being a special case of a tree - like model .",
    "dasgupta ( 1999 ) shows that finding the maximum - likelihood polytree ( a graph in which each pair of nodes is connected by at most one path ) is np - hard , even with bounded in - degree for every node",
    ". for general directed acyclic graphs , chickering ( 1996 ) shows that finding the highest marginal - likelihood structure under a particular prior is np - hard , even when each node has at most two parents .",
    "chickering at al .",
    "( 2004 ) extend this same result to the large - sample case .",
    "researchers often assume that the training - data `` generative '' distribution is _ perfect _ with respect to some model class in order to reduce the complexity of learning algorithms .",
    "geiger et al . ( 1990 ) provide a polynomial - time constraint - based algorithm for recovering a polytree under the assumption that the generative distribution is perfect with respect to a polytree ; an analogous score - based result follows from this paper .",
    "the constraint - based pc algorithm of sprites et al .",
    "( 1993 ) can identify the equivalence class of bayesian networks in polynomial time if the generative structure is a dag model over the observable variables in which each node has a bounded degree ; this paper provides a similar result for a score - based algorithm .",
    "kalish and buhlmann ( 2007 ) show that for gaussian distributions , the pc algorithm can identify the right structure even when the number of nodes in the domain is larger than the sample size . chickering ( 2002 )",
    "uses the same dag - perfectness - over - observables assumption to show that the greedy ges algorithm is optimal in the large - sample limit , although the branching factor of ges is worst - case exponential ; the main result of this paper shows how to limit this branching factor without losing the large - sample guarantee .",
    "chickering and meek ( 2002 ) show that ges identifies a `` minimal '' model in the large - sample limit under a less restrictive set of assumptions .",
    "hybrid methods for learning dag models use a constraint - based algorithm to prune out a large portion of the search space , and then use a score - based algorithm to select among the remaining ( friedman et al . , 1999 ;",
    "tsamardinos et al . , 2006 ) .",
    "ordyniak and szeider ( 2013 ) give positive complexity results for the case when the remaining dags are characterized by a structure with constant treewidth .",
    "many researchers have turned to exhaustive enumeration to identify the highest - scoring model ( gillispie and perlman , 2001 ; koivisto and sood 2004 ; silander and myllymki , 2006 ; kojima et al , 2010 ) .",
    "there are many complexity results for other model classes .",
    "karger and srebro ( 2001 ) show that finding the optimal markov network is np - complete for treewidth @xmath7 .",
    "narasimhan and bilmes ( 2004 ) and shahaf , chechetka and guestrin ( 2009 ) show how to learn approximate limited - treewidth models in polynomial time .",
    "abeel , koller and ng ( 2005 ) show how to learn factor graphs in polynomial time .",
    "we use the following syntactical conventions in this paper .",
    "we denote a variable by an upper case letter ( e.g. , @xmath8 ) and a state or value of that variable by the same letter in lower case ( e.g. , @xmath9 ) .",
    "we denote a set of variables by a bold - face capitalized letter or letters ( e.g. , @xmath10 ) .",
    "we use a corresponding bold - face lower - case letter or letters ( e.g. , @xmath11 ) to denote an assignment of state or value to each variable in a given set .",
    "we use calligraphic letters ( e.g. , @xmath12 ) to denote statistical models and graphs .    a _ bayesian - network model _ for a set of variables @xmath13 is a pair @xmath14 .",
    "@xmath15 is a directed acyclic graph  or _",
    "dag _ for short  consisting of nodes in one - to - one correspondence with the variables and directed edges that connect those nodes .",
    "@xmath16 is a set of parameter values that specify all of the conditional probability distributions .",
    "the bayesian network represents a joint distribution over @xmath13 that factors according to the structure @xmath0 .",
    "the structure @xmath0 of a bayesian network represents the independence constraints that must hold in the distribution .",
    "the set of all independence constraints implied by the structure @xmath0 can be characterized by the _ markov conditions _ , which are the constraints that each variable is independent of its non - descendants given its parents .",
    "all other independence constraints follow from properties of independence . a distribution defined over the variables from @xmath0 is _ perfect with respect to @xmath0 _ if the set of independences in the distribution is equal to the set of independences implied by the structure @xmath0 .",
    "two dags @xmath0 and @xmath17 are _",
    "equivalent_denoted @xmath18if the independence constraints in the two dags are identical .",
    "because equivalence is reflexive , symmetric , and transitive , the relation defines a set of equivalence classes over network structures . we will use @xmath19_{\\approx}$}}$ ] to denote the equivalence class of dags to which @xmath0 belongs .    an equivalence class of dags @xmath20 is an _ independence map _ ( _ imap _ ) of another equivalence class of dags",
    "@xmath21 if all independence constraints implied by @xmath20 are also implied by @xmath21 . for two dags @xmath0 and @xmath22",
    ", we use @xmath23 to denote that @xmath24_{\\approx}$}}$ ] is an imap of @xmath19_{\\approx}$}}$ ] ; we use @xmath25 when @xmath23 and @xmath24_{\\approx}$ } } \\not = { \\mbox{$[{{\\cal g}}]_{\\approx}$}}$ ] .    as shown by verma and pearl ( 1991 ) ,",
    "two dags are equivalent if and only if they have the same _ skeleton _",
    "( i.e. , the graph resulting from ignoring the directionality of the edges ) and the same _ v - structures _",
    "( i.e. , pairs of edges @xmath26 and @xmath27 where @xmath2 and @xmath28 are not adjacent ) . as a result",
    ", we can use a _ partially directed acyclic graph_or _ pdag _ for short  to represent an equivalence class of dags : for a pdag @xmath29 , the equivalence class of dags is the set that share the skeleton and v - structures with @xmath29 .",
    "we extend our notation for dag equivalence and the dag imap relation to include the more general pdag structure .",
    "in particular , for a pdag @xmath29 , we use @xmath30_{\\approx}$}}$ ] to denote the corresponding equivalence class of dags . for any pair of pdags @xmath29 and @xmath31where one or both may be a dag  we use @xmath32 to denote @xmath33_{\\approx}$ } } = { \\mbox{$[{\\mbox{$\\cal p$}}]_{\\approx}$}}$ ] and we use @xmath34 to denote @xmath33_{\\approx}$}}$ ] is an imap of @xmath30_{\\approx}$}}$ ] . to avoid confusion , for the remainder of the paper we will reserve the symbols @xmath0 and @xmath22 for dags .    for any pdag @xmath29 and subset of nodes",
    "@xmath35 , we use @xmath36$}}$ ] to denote the subgraph of @xmath29 induced by @xmath35 ; that is , @xmath36$}}$ ] has as nodes the set @xmath35 and has as edges all those from @xmath29 that connect nodes in @xmath35 .",
    "we use @xmath37 to denote , within a pdag , the set of nodes that are _ neighbors _ of @xmath2 ( i.e. , connected with an undirected edge ) and also adjacent to @xmath3 ( i.e. , without regard to whether the connecting edge is directed or undirected ) .    an edge in @xmath0",
    "is _ compelled _ if it exists in every dag that is equivalent to @xmath0 .",
    "if an edge in @xmath0 is not compelled , we say that it is _",
    "reversible_. a _ completed _ pdag ( _ cpdag _",
    ") @xmath38 is a pdag with two additional properties : ( 1 ) for every directed edge in @xmath38 , the corresponding edge in @xmath0 is compelled and ( 2 ) for every undirected edge in @xmath38 the corresponding edge in @xmath0 is reversible . unlike non - completed pdags , the cpdag representation of an equivalence class is unique .",
    "we use @xmath39 to denote the _ parents _ of node @xmath3 in @xmath29 .",
    "an edge @xmath26 is _ covered _ in a dag if @xmath2 and @xmath3 have the same parents , with the exception that @xmath2 is not a parent of itself .      ' '' ''    algorithm @xmath40    ' '' ''    @xmath41 fes(@xmath42 ) + @xmath41 bes(@xmath42 , @xmath38 ) + @xmath38 +    ' '' ''    the ges algorithm , shown in figure [ fig : ges ] , performs a two - phase greedy search through the space of dag equivalence classes .",
    "ges represents each search state with a cpdag , and performs transformation operators to this representation to traverse between states .",
    "each operator corresponds to a dag edge modification , and is scored using a dag scoring function that we assume has three properties .",
    "first , we assume the scoring function is _ score equivalent _ , which means that it assigns the same score to equivalent dags .",
    "second , we assume the scoring function is _ locally consistent _ , which means that , given enough data , ( 1 ) if the current state _ is not _",
    "an imap of @xmath0 , the score prefers edge additions that remove incorrect independences , and ( 2 ) if the current state _ is _ an imap of @xmath0 , the score prefers edge deletions that remove incorrect dependences",
    ". finally , we assume the scoring function is _ decomposable _ , which means we can express it as : @xmath43 note that the data @xmath42 is implicit in the right - hand side equation [ eq : decompose ] .",
    "most commonly used scores in the literature have these properties . for the remainder of this paper , we assume they hold for the scoring function we use .    all of the cpdag operators from ges are scored using differences in the dag scoring function , and in the limit of large data , these scores are positive precisely for those operators that remove incorrect independences and incorrect dependences .    the first phase of the ges  called _ forward equivalence search _ or _ fes_starts with an empty ( i.e. , no - edge ) cpdag and greedily applies _ ges insert _ operators until no operator has a positive score ; these operators correspond precisely to the union of all single - edge additions to all dag members of the current ( equivalence - class ) state .",
    "after fes reaches a local maximum , ges switches to the second phase  called _ backward equivalence search _ or _",
    "bes_and greedily applies _ ges delete _ operators until no operator has a positive score ; these operators correspond precisely to the union of all single - edge deletions from all dag members of the current state .    *",
    "( chickering , 2002 ) * [ th : ges ] let @xmath38 be the cpdag that results from applying the ges algorithm to @xmath44 records sampled from a distribution that is perfect with respect to dag @xmath0 . then in the limit of large @xmath44 , @xmath45 .",
    "the role of fes in the large - sample limit is only to identify a state @xmath38 for which @xmath46 ; theorem [ th : ges ] holds for ges under any implementation of fes that results in an imap of @xmath0 .",
    "the implementation details can be important in practice because what constitutes a `` large '' amount of data depends on the number of parameters in the model . in theory ,",
    "however , we could simply replace fes with a ( constant - time ) algorithm that sets @xmath38 to be the no - independence equivalence class .",
    "the focus of our analysis in the next section is on a modified version of bes , and the details of the delete operator used in this phase are important .",
    "we detail the preconditions , scoring function , and transformation algorithm for a delete operator in figure  [ fig : op - delete ] .",
    "we note that we do not need to make any cpdag transformations when _ scoring _ the operators ; it is only once we have identified the highest - scoring ( non - negative ) delete that we need to make the transformation shown in the figure . after applying the edge modifications described in the * foreach * loop ,",
    "the resulting pdag @xmath29 is not necessarily completed and hence we may have to convert @xmath29 into the corresponding cpdag representation . as shown by chickering ( 2002 )",
    ", this conversion can be accomplished easily by using the structure of @xmath29 to extract a dag that we then convert into a cpdag by undirecting all reversible edges .",
    "the complexity of this procedure for a @xmath29 with @xmath47 nodes and @xmath48 edges is @xmath49 , and requires no calls to the scoring function .    ' '' ''    ' '' ''    * @xmath50 preconditions * + @xmath2 and @xmath3 are adjacent + @xmath51 + @xmath52 is a clique + * @xmath50 scoring * + @xmath53 + * @xmath50 transformation * + remove edge between @xmath2 and @xmath3 + convert to cpdag +    ' '' ''",
    "in this section , we define a variant of the ges algorithm called _ selective ges_or _ sges _ for short  that uses a subset of the ges operators . the subset is chosen based on a given property @xmath1 that is known to hold for the generative structure @xmath0 . just like ges , sges  shown in figure",
    "[ alg : limited - ges]has a forward phase and a backward phase .    for the forward phase of sges , it suffices for our theoretical analysis that we use a method that returns an imap of @xmath0 ( in the large - sample limit ) using only a polynomial number of insert - operator score calls .",
    "for this reason , we call this phase _ poly - fes_. a simple implementation of poly - fes is to return the no - independence cpdag ( with no score calls ) , but other implementations are likely more useful in practice",
    ".    the backward phase of sges  which we call _ selective backward equivalence search _ ( _ sbes_)uses only a subset of the bes delete operators .",
    "this subset must necessarily include all _ @xmath1-consistent _ delete operators  defined below  in order to maintain the large - sample consistency of ges , but the subset can ( and will ) include additional operators for the sake of efficient enumeration",
    ".    the dag properties used by sges must be _ equivalence invariant _ , meaning that for any pair of equivalent dags , either the property holds for both of them or it holds for neither of them .",
    "thus , for any equivalence - invariant dag property @xmath1 , it makes sense to say that @xmath1 either holds or does not hold for a pdag . as shown by chickering ( 1995 ) ,",
    "a dag property is equivalence invariant if and only if it is invariant to covered - edge reversals ; it follows that the property that each node has at most @xmath6 parents is equivalence invariant , whereas the property that the length of the longest directed path is at least @xmath6 is not .",
    "furthermore , the properties for sges must also be _ hereditary _ , which means that if @xmath1 holds for a pdag @xmath29 it must also hold for all induced subgraphs of @xmath29 . for example , the max - parent property is hereditary , whereas the property that each node has _ at least _",
    "@xmath6 parents is not .",
    "we use _ eih property _ to refer to a property that is equivalence invariant and hereditary .",
    "* @xmath1-consistent ges delete * + a ges delete operator @xmath54 is _",
    "@xmath1 consistent _ for cpdag @xmath38 if , for the set of common descendants @xmath55 of @xmath2 and @xmath3 in the resulting cpdag @xmath56 , the property holds for the induced subgraph @xmath57$}}$ ] .",
    "[ def : consistent ]    in other words , after the delete , the property holds for the subgraph defined by @xmath2 , @xmath3 , and their common descendants .    ' '' ''    algorithm @xmath58    ' '' ''    @xmath41 poly - fes + @xmath41 sbes(@xmath42 , @xmath38 , @xmath1 ) + @xmath38 +    ' '' ''    ' '' ''    algorithm @xmath59    ' '' ''     + @xmath60 generate @xmath1-consistent delete operators for + @xmath61 highest - scoring operator in @xmath62 + @xmath41 apply @xmath63 to @xmath38 +    ' '' ''      the following theorem establishes a graph - theoretic justification for considering only the @xmath1-consistent deletions at each step of sbes .",
    "[ th : main ] if @xmath64 for cpdag @xmath38 and dag @xmath0 , then for any eih property @xmath1 that holds on @xmath0 , there exists a @xmath1-consistent @xmath54 that when applied to @xmath38 results in the cpdag @xmath56 for which @xmath65 .",
    "we postpone the proof of theorem [ th : main ] to the appendix .",
    "the result is a consequence of an explicit characterization of , for a given pair of dags @xmath0 and @xmath22 such that @xmath25 , an edge in @xmath22 that we can either reverse or delete in @xmath22 such that for the resulting dag @xmath66 , we have @xmath67 , which provides an _ implicit _ characterization of reversals / deletions in @xmath22 . ] .",
    "[ th : ges - limited ] let @xmath38 be the cpdag that results from applying the sges algorithm to ( 1 ) @xmath44 records sampled from a distribution that is perfect with respect to dag @xmath0 and ( 2 ) eih property @xmath1 that holds on @xmath0 . then in the limit of large @xmath44 , @xmath45 .",
    "* proof : * because the scoring function is locally consistent , we know poly - fes must return an imap of @xmath0 . because sbes includes all the @xmath1-consistent delete operators , theorem [ th : main ] guarantees that , unless @xmath45 , there will be a positive - scoring operator .      in this section",
    ", we discuss a number of distributional assumptions that we can use with theorem [ th : ges - limited ] to limit the number of operators that sges needs to score . as discussed in section [ sec : related ] , when we assume the generative distribution is perfect with respect to a dag @xmath0 , then graph - theoretic assumptions about @xmath0 can lead to more efficient training algorithms .",
    "common assumptions used include ( 1 ) a maximum parent - set size for any node , ( 2 ) a maximum - clique size among any nodes and ( 3 ) a maximum treewidth .",
    "treewidth is important because the complexity of exact inference is exponential in this measure .",
    "we can associate a property with each of these assumptions that holds precisely when the dag @xmath0 satisfies that assumption .",
    "consider the constraint that the maximum number of parents for any node in @xmath0 is some constant @xmath6 . then , using `` ps '' to denote parent size , we can define the property @xmath68 to be true precisely for those dags in which each node has at most @xmath6 parents .",
    "similarly we can define @xmath69 and @xmath70 to correspond to maximum - clique size and maximum treewidth , respectively .    for two properties @xmath1 and @xmath71 , we write @xmath72 if for every dag @xmath0 for which @xmath1 holds , @xmath71 also holds .",
    "in other words , @xmath1 is a _ more constraining _",
    "property than is @xmath71 . because the lowest node in any clique has all other nodes in the clique as parents , it is easy to see that @xmath73 .",
    "because the treewidth for dag @xmath0 is defined to be the size of the largest clique minus one in a graph whose cliques are at least as large as those in @xmath0 , we also have @xmath74 . which property to use",
    "will typically be a trade - off between how reasonable the assumption is ( i.e , less constraining properties are more reasonable ) and the efficiency of the resulting algorithm ( i.e. , more constraining properties lead to faster algorithms ) .",
    "we now consider a new complexity measure called _ v - width _ , whose corresponding property is less constraining than the previous three , and somewhat remarkably leads to an efficient implementation in sges . for a dag @xmath0",
    ", the v - width is defined to be the maximum of , over all pairs of non - adjacent nodes @xmath2 and @xmath3 , the size of the largest clique among common children of @xmath2 and @xmath3 . in other words ,",
    "v - width is similar to the maximum - clique - size bound , except that the bound only applies to cliques of nodes that are shared children of some pair of non - adjacent nodes . with this understanding",
    "it is easy to see that , for the property @xmath75 corresponding to a bound on the v - width , we have @xmath76 .    to illustrate the difference between v - width and the other complexity measures , consider the two dags in figure [ fig : properties ] .",
    "the dag in figure [ fig : properties](a ) has a clique of size @xmath77 , and consequently a maximum - clique size of @xmath77 and a maximum parent - set size of @xmath78 .",
    "thus , if @xmath77 is @xmath79 for a large graph of @xmath47 nodes , any algorithm that is exponential in these measures will not be efficient . the v - width , however , is zero for this dag .",
    "the dag in figure [ fig : properties](b ) , on the other hand , has a v - width of @xmath77 .        in order to use a property with sges , we need to establish that it is eih . for @xmath68 , @xmath69 and @xmath75 , equivalence - invariance follows from the fact that all three properties are covered - edge invariant , and hereditary follows because the corresponding measures can not increase when we remove nodes and edges from a dag .",
    "although we can establish eih for the treewidth property @xmath70 with more work , we omit further consideration of treewidth for the sake of space .      in this section ,",
    "we show how to generate a set of deletion operators for sbes such that all @xmath1-consistent deletion operators are included , for any @xmath80 .",
    "furthermore , the total number of deletion operators we generate is polynomial in the number of nodes in the domain and exponential in @xmath6 .",
    "our approach is to restrict the @xmath54 operators based on the @xmath81 sets and the resulting cpdag @xmath56 .",
    "in particular , we _ rule out _",
    "candidate @xmath81 sets for which @xmath1 does not hold on the induced subgraph @xmath82$}}$ ] ; because all nodes in @xmath81 will be common children of @xmath2 and @xmath3 in @xmath56and thus a subset of the common descendants of @xmath2 and @xmath3we know from definition [ def : consistent ] ( and the fact that @xmath1 is hereditary ) that none of the dropped operators can be @xmath1-consistent .    before presenting our restricted - enumeration algorithm",
    ", we now discuss how to enumerate delete operators without restrictions . as shown by andersson et al .",
    "( 1997 ) , a cpdag is a chain graph whose undirected components are chordal .",
    "this means that the induced sub - graph defined over @xmath83which is a subset of the neighbors of @xmath3is an undirected chordal graph .",
    "a useful property of chordal graphs is that we can identify , in polynomial time , a set of _ maximal cliques _ over these nodes ; let @xmath84 denote the nodes contained within these @xmath44 maximal cliques , and let @xmath52 be the complement of the shared neighbors with respect to the candidate @xmath81",
    ". recall from figure [ fig : op - delete ] that the preconditions for any @xmath54 include the requirement that @xmath85 is a clique .",
    "this means that for any valid @xmath81 , there must be some maximal clique @xmath86 that contains the entirety of @xmath85 ; thus , we can generate all operators ( without regard to any property ) by stepping through each maximal clique @xmath86 in turn , initializing @xmath81 to be all nodes _ not _ in @xmath86 , and then generating a new operator corresponding to expanding @xmath81 by all subsets of nodes in @xmath86 .",
    "note that if @xmath83 is itself a clique , we are enumerating over all @xmath87 operators .    as we show below",
    ", all three of the properties of interest impose a bound on the maximum clique size among nodes in @xmath81 .",
    "if we are given such a bound @xmath88 , we know that any `` expansion '' subset for a clique that has size greater than @xmath88 will result in an operator that is not valid . thus , we can implement the above operator - enumeration approach more efficiently by only generating subsets within each clique that have size at most @xmath88 .",
    "this allows us to process each clique @xmath86 with only @xmath89 calls to the scoring function .",
    "in addition , we need not enumerate over _ any _ of the subsets of @xmath86 if , after removing this clique from the graph , there remains a clique of size greater than @xmath88 ; we define the function @xmath90 to be the subset of cliques that remain after imposing this constraint . with this function , we can define selective - generate - ops as shown in figure [ fig : generate ] to leverage the max - clique - size constraint when generating operators ; this algorithm will in turn be used to generate all of the cpdag operators during sbes .",
    "* example : * in figure  [ fig : generateexample ] , we show an example cpdag for which to run selective - generate - ops(@xmath38 , @xmath2 , @xmath3 , @xmath88 ) for various values of @xmath88 . in the example , there is a single clique @xmath91 in the set @xmath83 , and thus at the top of the outer * foreach * loop , the set @xmath92 is initialized to the empty set . if @xmath93 , the only subset of @xmath94 with size zero is the empty set , and so that is added to @xmath62 and the algorithm returns . if @xmath95 we add , in addition to the empty set , all singleton subsets of @xmath94 . for @xmath96 ,",
    "we add all subsets of @xmath94 .",
    "now we discuss how each of the three properties impose a constraint @xmath88 on the maximum clique among nodes in @xmath81 , and consequently the selective - generation algorithm in figure [ fig : generate ] can be used with each one , given an appropriate bound @xmath88 . for both @xmath75 and @xmath69",
    ", the @xmath6 given imposes an explicit bound on @xmath88 ( i.e. , @xmath97 for both ) . because any clique in @xmath81 of size @xmath98 will result in a dag member of the resulting equivalence class having a node in that clique with at least @xmath99 parents ( i.e. , @xmath100 from the other nodes in the clique , plus both @xmath2 and @xmath3 ) , we have for @xmath68 , @xmath101 .    ' '' ''    algorithm selective - generate - ops(@xmath102 )    ' '' ''    @xmath103 + generate maximal cliques @xmath104 from @xmath83 + @xmath105 +   +    ' '' ''    we summarize the discussion above in the following proposition .",
    "algorithm selective - generate - ops applied to all edges using clique - size bound @xmath88 generates all @xmath1-consistent delete operators for @xmath106 .",
    "we now argue that running sbes on a domain of @xmath47 variables when using algorithm selective - generate - ops with a bound @xmath88 requires only a polynomial number in @xmath47 of calls to the scoring function .",
    "each clique in the inner loop of the algorithm can contain at most @xmath47 nodes , and therefore we generate and score at most @xmath107 operators , requiring at most @xmath108 calls to the scoring function . because the cliques are maximal , there can be at most @xmath47 of them considered in the outer loop . because there are never more than @xmath109 edges in a cpdag , and we will delete at most all of them , we conclude that even if we decided to rescore every operator after every edge deletion , we will only make a polynomial number of calls to the scoring function .    from the above discussion and the fact that sbes completes using at most a polynomial number of calls to the scoring function , we get the following result for the full sges algorithm .    [",
    "prop : complex - complete ] the sges algorithm , when run over a domain of @xmath47 variables and given @xmath106 , runs to completion using a number of calls to the dag scoring function that is polynomial in @xmath47 and exponential in @xmath88 .     and the resulting operators generated by selective - generate - ops(@xmath38,@xmath2,@xmath3,@xmath88 ) for various values of @xmath88.,width=288 ]",
    "in this section , we present a simple synthetic experiment comparing sbes and bes that demonstrates the value of pruning operators . in our experiment",
    "we used an _ oracle _ scoring function .",
    "in particular , given a generative model @xmath0 , our scoring function computes the minimum - description - length score assuming a data size of five billion records , but without actually sampling any data : instead , we use exact inference in @xmath0 ( i.e. , instead of counting from data ) to compute the conditional probabilities needed to compute the expected log loss .",
    "this allows us to get near - asymptotic behavior without the need to sample data .",
    "to evaluate the cost of running each algorithm , we counted the number of times the scoring function was called on a unique node and parent - set combination ; we cached these scores away so that if they were needed multiple times during a run of the algorithm , they were only computed ( and counted ) once .    in figure",
    "[ fig : clique ] , we show the average number of scoring - function calls required to complete bes and sbes when starting from a complete graph over a domain of @xmath47 binary variables , for varying values of @xmath47 .",
    "each average is taken over ten trials , corresponding to ten random generative models .",
    "all variables in the domain were binary .",
    "we generated the structure of each generative model as follows .",
    "first , we enumerated all node pairs by randomly permuting the nodes and taking each node in turn with all of its predecessors in turn . for each node pair in turn , we chose to attempt an edge insertion with probability one half . for each attempt",
    ", we added an edge if doing so ( 1 ) did not create a cycle and ( 2 ) did not result in a node having more than two parents ; if an edge could be added in either direction , we chose the direction at random .",
    "we sampled the conditional distributions for each node and each parent configuration from a uniform dirichlet distribution with equivalent - sample size of one .",
    "we ran sbes with @xmath110 .",
    "our results show clearly the exponential dependence of bes on the number of nodes in the clique , and the increasing savings we get with sbes , leveraging the fact that @xmath110 holds in the generative structure .",
    "note that to realize large savings in practice , when ges runs fes instead of starting from a dense graph , a ( relatively sparse ) generative distribution must lead fes to an equivalence class containing a ( relatively dense ) undirected clique that is subsequently `` thinned '' during bes .",
    "we can synthesize challenging grid distributions to force fes into such states , but it is not clear how realistic such distributions are in practice .",
    "when we re - run the clique experiment above , but where we instead start both bes and sbes from the model that results from running fes ( i.e. , with no polynomial - time guarantee ) , the savings from sbes are small due to the fact that the subsequent equivalence classes do not contain large cliques .",
    "through our selective greedy equivalence search algorithm sges , we have demonstrated how to leverage graph - theoretic properties to reduce the need to score graphs during score - based search over equivalence classes of bayesian networks .",
    "furthermore , we have shown that for graph - theoretic complexity properties including maximum - clique size , maximum number of parents , and v - width , we can guarantee that the number of score evaluations is polynomial in the number of nodes and exponential in these complexity measures .",
    "the fact that we can use our approach to selectively choose operators for any hereditary and equivalence invariant graph - theoretic property provides the opportunity to explore alternative complexity measures .",
    "another candidate complexity measure is the maximum number of v - structures .",
    "although the corresponding property does not limit the maximum size of a _ clique _ in @xmath81 , it limits directly the size @xmath111 for every operator .",
    "thus it would be easy to enumerate these operators efficiently .",
    "another complexity measure of interest is _ treewidth _ , due to the fact that exact inference in a bayesian - network model is takes time exponential in this measure .",
    "the results we have presented are for the general bayesian - network learning problem .",
    "it is interesting to consider the implications of our results for the problem of learning particular subsets of bayesian networks .",
    "one natural class that we discussed in section  [ sec : related ] is that of polytrees . if we assume that the generative distribution is perfect with respect to a polytree then we know the v - width of the generative graph is one .",
    "this implies , in the limit of large data , that we can recover the structure of the generative graph with a polynomial number of score evaluations .",
    "this provides a score - based recovery algorithm analogous to the constraint - based approach of geiger et al .",
    "( 1990 ) .",
    "we presented a simple complexity analysis for the purpose of demonstrating that sges uses a only polynomial number of calls to the scoring function .",
    "we leave as future work a more careful analysis that establishes useful constants in this polynomial .",
    "in particular , we can derive tighter bounds on the total number of node - and - parent - configurations that are needed to score all the operators for each cpdag , and by caching these configuration scores we can further take advantage of the fact that most operators remain valid ( i.e. , the preconditions still hold ) and have the same score after each transformation .    finally , we plan to investigate practical implementations of poly - fes that have the polynomial - time guarantees needed for sges .",
    "in the following two appendices , we prove theorem [ th : main ] .",
    "in this section , we introduce additional background material needed for the proofs .",
    "to express sets of variables more compactly , we often use a comma to denote set union ( e.g. , we write @xmath112 as a more compact version of @xmath113 ) .",
    "we also will sometimes remove the comma ( e.g. , @xmath114 ) .",
    "when a set consists of a singleton variable , we often use the variable name as shorthand for the set containing that variable ( e.g. , we write @xmath115 as shorthand for @xmath116 ) .",
    "we say a node @xmath117 is a _ descendant _ of @xmath3 if @xmath118 or there is a directed path from @xmath3 to @xmath117 .",
    "we use @xmath22-descendant to refer to a descendant in a particular dag @xmath22 .",
    "we say a node @xmath117 is a _ proper descendant _ of @xmath3 if @xmath117 is a descendant of @xmath3 and @xmath119 .",
    "we use @xmath120 to denote the non - descendants of node @xmath3 in @xmath0 .",
    "we use @xmath121 as shorthand for @xmath122 .",
    "for example , to denote all the parents of @xmath28 in @xmath22 except for @xmath2 and @xmath3 , we use @xmath123 .",
    "the independence constraints implied by a dag structure are characterized by the _",
    "d - separation _ criterion .",
    "two nodes @xmath8 and @xmath124 are said to be d - separated in a dag @xmath0 given a set of nodes @xmath125 if and only if there is no _ active path _ in @xmath0 between @xmath8 and @xmath124 given @xmath125 .",
    "the standard definition of an active path is a _ simple _ path for which each node @xmath126 along the path either ( 1 ) has converging arrows ( i.e. , @xmath127 ) and @xmath126 or a descendant of @xmath126 is in @xmath125 or ( 2 ) does not have converging arrows and @xmath126 is not in @xmath125 . by simple ,",
    "we mean that the path never passes through the same node twice .    to simplify our proofs",
    ", we use an equivalent definition of an active path  that need not be simple  where each node @xmath126 along the path either ( 1 ) has converging arrows and @xmath126 is in @xmath125 or ( 2 ) does not have converging arrows and @xmath126 is not in @xmath125 . in other words , instead of allowing a segment @xmath127 to be included in a path by virtue of a descendant of @xmath126 belonging to @xmath125 , we require that the path include the sequence of edges from @xmath126 to that descendant and then back again . for those readers familiar with the celebrated `` bayes ball '' algorithm of shachter ( 1998 ) for testing d - separation ,",
    "our expanded definition of an active path is simply a valid path that the ball can take between @xmath8 and @xmath124 .",
    "we use @xmath128 to denote the assertion that dag @xmath0 imposes the constraint that variables @xmath129 are independent of variables @xmath130 given variables @xmath131.when a node @xmath126 along a path has converging arrows , we say that @xmath126 is a _ collider _ at that position in the path .    the direction of each _ terminal _ edge in an active path  that is , the first and last edge encountered in a traversal from one end of the path to the other  is important for determining whether we can append two active paths together to make a third active path . we say that a path @xmath132 is _ into _",
    "@xmath8 if the terminal edge incident to @xmath8 is oriented toward @xmath8 ( i.e. , @xmath133 ) .",
    "similarly , the path is into @xmath124 if the terminal edge incident to @xmath124 is oriented toward @xmath124 .",
    "if a path is not into an endpoint @xmath8 , we say that the path is _ out of _ @xmath8 . using the following result from chickering ( 2002 )",
    ", we can combine active paths together .    *",
    "( chickering , 2002 ) * [ lem : append ] let @xmath132 be an @xmath125-active path between @xmath8 and @xmath124 , and let @xmath134 be an @xmath125-active path between @xmath124 and @xmath135 .",
    "if either path is out of @xmath124 , then the concatenation of @xmath132 and @xmath134 is an @xmath125-active path between @xmath8 and @xmath135 .    given a dag @xmath22 that is an imap of dag @xmath0 , we use the d - separation criterion in two general ways in our proofs .",
    "first , we identify d - separation facts that hold in @xmath22 and conclude that they must also hold in @xmath0 .",
    "second , we identify active paths in @xmath0 and conclude that there must be corresponding active paths in @xmath22 .      in many of our proofs",
    ", we would like to reason about the independence facts that hold in dag @xmath0 without knowing what its structure is , which makes using the d - separation criterion problematic .",
    "as described in pearl ( 1988 ) , any set of independence facts characterized by the d - separation criterion also respect the independence axioms shown in figure [ fig : axioms ] .",
    "these axioms allow us to take a set of independence facts in some unknown @xmath0 ( e.g. , that are implied by d - separation in @xmath22 ) , and derive new independence facts that we know must also hold in @xmath0 .",
    "llrcl + & & @xmath136 & + & & @xmath137 & + & & @xmath137 & + & & @xmath137 & + & & @xmath137 & + & & @xmath138 & + & & @xmath137 & +    throughout the proofs , we will often use the symmetry axiom implicitly .",
    "for example , if we have @xmath139 we might claim that @xmath140 follows from weak union , as opposed to concluding @xmath141 from weak union and then applying symmetry .",
    "we will frequently identify independence constraints in @xmath22 and conclude that they hold in @xmath0 , without explicitly justifying this with _ because @xmath23_. for example , we will say : + _ because @xmath8 is a non - descendant of @xmath124 in @xmath22 , it follows from the markov conditions that @xmath142 . _",
    "+ in other words , to be explicit we would say that @xmath143 follows from the markov conditions , and the independence holds in @xmath0 because @xmath23 .",
    "the composition axiom states that if @xmath129 is independent of both @xmath130 and @xmath55 individually given @xmath131 , then @xmath129 is independent of them jointly .",
    "if we have more than two such sets that are independent of @xmath129 , we can apply the composition axiom repeatedly to combine them all together . to simplify",
    ", we will do this combination implicitly , and assume that the composition axiom is defined more generally .",
    "thus , for example , we might have :    _ because @xmath144 for every @xmath145 , we conclude by the composition axiom that @xmath146 . _",
    "in this section , we provide a number of intermediate results that lead to a proof of theorem [ th : main ] .      given dags @xmath0 and @xmath22 for which @xmath25",
    ", we say that an edge @xmath48 from @xmath22 is _ deletable in @xmath22 with respect to @xmath0 _ if , for the dag @xmath66 that results after removing @xmath48 from @xmath22 , we have @xmath23 .",
    "we will say that an edge is _ deletable in @xmath22 _ or simply _ deletable _ if @xmath0 or both dags , respectively , are clear from context .",
    "the following lemma establishes necessary and sufficient conditions for an edge to be deletable .",
    "* proof : * let @xmath66 be the dag resulting from removing the edge . the `` only if '' follows immediately because the given independence is implied by @xmath66 . for the ``",
    "if '' , we show that for every node @xmath8 and every node @xmath149 , the independence @xmath150 holds ( in @xmath0 ) . we need only consider @xmath151 pairs for which @xmath124 is a descendant in @xmath22 but not in @xmath66 ; if the `` descendant '' relationship has not changed , we know the independence holds by virtue of @xmath23 and the fact that deleting an edge results in strictly more independence constraints .",
    "the proof follows by induction on the length of the longest directed path in @xmath66 from @xmath3 to @xmath124 . for the base case",
    "( see figure [ fig : deletableproof]a and figure [ fig : deletableproof]b ) , we start with a longest path of length zero ; in other words , @xmath152 . because @xmath8 is an ancestor of @xmath3 in @xmath22 , both it and its parents must be non - descendants of @xmath3 in @xmath22 , and therefore the markov conditions in @xmath22 imply @xmath153 given the independence fact assumed in the lemma , we can apply the contraction axiom to remove @xmath2 from the conditioning set in ( [ eq : del1 ] ) , and then apply the weak union axiom to move @xmath154 into the conditioning set to conclude @xmath155 neither @xmath3 nor its new parents @xmath156 can be descendants of @xmath8 in @xmath66 , else @xmath124 would remain a descendant of @xmath8 after the deletion , and thus we conclude by the markov conditions in @xmath22 that @xmath157 applying the contraction axiom to ( [ eq : del2 ] ) and ( [ eq : del3 ] ) , we have @xmath158 and because @xmath159 the lemma follows .    for the induction step ( see figure [ fig : deletableproof]c and figure [ fig : deletableproof]d )",
    ", we assume the lemma holds for all nodes whose longest path from @xmath3 is @xmath160 , and we consider a @xmath124 for which the longest path from @xmath3 is @xmath161 .",
    "consider any parent @xmath162 of node @xmath124 .",
    "if @xmath162 is a descendant of @xmath3 , the longest path from @xmath3 to @xmath124 must be @xmath160 , else we have a path to @xmath124 that is longer than @xmath161 .",
    "if @xmath162 is not a descendant of @xmath3 , then @xmath162 is also not a descendant of @xmath8 in @xmath22 , else @xmath124 would be a descendant of @xmath8 in @xmath66 .",
    "thus , for every parent @xmath162 , we conclude @xmath163 either by the induction hypothesis or by the fact that @xmath162 is a non - descendant of @xmath8 in @xmath22 . from the composition axiom",
    "we can combine these individual parents together , yielding @xmath164 because @xmath124 is a descendant of @xmath8 in @xmath22 , we know that @xmath8 and all of its parents @xmath154 are non - descendants of @xmath124 in @xmath22 , and thus @xmath165 applying the weak union axiom to ( [ eq : del5 ] ) yields @xmath166 and finally applying the contraction axiom to ( [ eq : del4 ] ) and ( [ eq : del6 ] ) yields @xmath167 because the parents of @xmath8 are the same in both @xmath22 and @xmath66 , the lemma follows .",
    "we define the _ pruned variables for @xmath0 and @xmath22_denoted @xmath168 to be the subset of the variables that remain after we repeatedly remove from both graphs any common sink nodes ( i.e. , nodes with no children ) with the same parents in both graphs . for @xmath169 , let @xmath170 denote the complement of @xmath35 .",
    "note that every node in @xmath170 has the same parents and children in both @xmath0 and @xmath22 , and that @xmath171 $ } } = { \\mbox{${{\\cal h}}[\\overline{{\\mbox{${\\bf v}$}}}]$}}$ ] .",
    "we use @xmath172 to denote any node in @xmath0 that has no children . for any @xmath172 @xmath173",
    ", we say that @xmath173 is an _",
    "@xmath22-lowest @xmath172 _ if no proper descendant of @xmath173 in @xmath22 is a @xmath172 .",
    "note that we are discussing _ two _ dags in this case : @xmath173 is a leaf in @xmath0 , and out of all nodes that are leaves in @xmath0 , @xmath173 is the one that is lowest in the other dag @xmath22 . to avoid ambiguity",
    ", we often prefix other common graph concepts ( e.g. , _ @xmath0-child _ and _ @xmath22-parent _ ) to emphasize the specific dag to which we are referring .      *",
    "( chickering , 2002 ) * [ lem : induction ] let @xmath0 and @xmath22 be two dags containing a node @xmath3 that is a sink in both dags and for which @xmath174 .",
    "let @xmath17 and @xmath66 denote the subgraphs of @xmath0 and @xmath22 , respectively , that result by removing node @xmath3 and all its in - coming edges .",
    "then @xmath175 if and only if @xmath176 .            1 .   if @xmath173 does not have any @xmath179$}}$]-children , then for every @xmath181 that is an @xmath179$}}$]-parent of @xmath173 but not a @xmath180$}}$]-parent of @xmath173 , @xmath182 is deletable in @xmath22 .",
    "2 .   if @xmath173 has at least one @xmath179$}}$]-child , let @xmath8 be any @xmath179$}}$]-highest child ; one of the following three properties must hold in @xmath22 : 1 .",
    "@xmath183 is covered .",
    "2 .   there exists an edge @xmath184 , where @xmath173 and @xmath124 are not adjacent , and either @xmath185 or @xmath184 ( or both ) are deletable .",
    "3 .   there exists an edge @xmath182 , where @xmath186 and @xmath8 are not adjacent , and either @xmath187 or @xmath183 ( or both ) are deletable .",
    "* proof : * as a consequence of corollary [ cor : induction ] , the lemma holds if and only if it holds for any graphs @xmath0 and @xmath22 for which there are no nodes that are sinks in both graphs with the same parents ; in other words , @xmath188 and @xmath189 .",
    "thus , to vastly simplify the notation for the remainder of the proof , we will assume that this is the case , and therefore @xmath173 is a leaf node in @xmath0 , @xmath8 is a highest child of @xmath173 in @xmath22 , and the restriction of @xmath124 and @xmath186 to @xmath35 is vacuous .    for case ( 1 ) , we know that @xmath190 , else there would be some edge in @xmath191 in @xmath0 for which @xmath2 and @xmath173 are not adjacent in @xmath22 , contradicting @xmath23 .",
    "because @xmath173 is a leaf in @xmath0 , all non - parents must also be non - descendants , and hence @xmath192 for all @xmath2 .",
    "it follows that for every @xmath193 , @xmath194 is deletable in @xmath22 .",
    "there must exist such a @xmath186 , else @xmath173 would be in @xmath177 .    for case",
    "( 2 ) , we now show that at least one of the properties must hold .",
    "assume that the first property _ does not _",
    "hold , and demonstrate that one of the other two properties must hold .",
    "if the first property does not hold then we know that in @xmath22 either there exists an edge @xmath184 where @xmath124 is not a parent of @xmath173 , or there exists an edge @xmath182 where @xmath186 is not a parent of @xmath8 .",
    "thus the pre - conditions of at least one of the remaining two properties must hold .",
    "suppose @xmath22 contains the edge @xmath184 where @xmath124 is not a parent of @xmath173 .",
    "then we conclude immediately from corollary [ cor : yab ] that either @xmath183 or @xmath184 is deletable in @xmath22 .",
    "suppose @xmath22 contains the edge @xmath182 where @xmath186 is not a parent of @xmath8 .",
    "then the set @xmath42 containing _ all _ parents of @xmath173 that are not parents of @xmath8 is non - empty .",
    "let @xmath195 be the shared parents of @xmath173 and @xmath8 , and let @xmath196 be the remaining non-@xmath173 parents of @xmath8 in @xmath22 , so that we have @xmath197 and @xmath198 . because no node in @xmath42 is a child or a descendant of @xmath8 , lest @xmath22 contains a cycle ,",
    "we know that @xmath22 contains the following independence constraint that must hold in @xmath0 : @xmath199 because @xmath173 is a leaf node in @xmath0 , it is impossible to create a new active path by removing it from the conditioning set , and hence we also know @xmath200 applying the weak transitivity axiom to independence [ eq : dya - with - l ] and independence [ eq : dya - no - l ] , we conclude either @xmath201in which case @xmath202 is deletable  or @xmath203 we know that no node in @xmath204 can be a descendant of @xmath173 , or else @xmath8 would not be the highest child of @xmath173 .",
    "thus , because @xmath173 is independent of any non - descendants given its parents we have @xmath205 applying the intersection axiom to independence [ eq : ad ] and independence [ eq : lt ] , we have @xmath206 in other words , @xmath173 is independent of _ all _ of the nodes in @xmath42 given the other parents . by applying the weak union axiom , we can pull all but one of the nodes in @xmath42 into the conditioning set to obtain @xmath207 and hence @xmath182 is deletable for each such @xmath186 .",
    "[ [ intermediate - result - add - a - singleton - descendant - to - the - conditioning - set ] ] intermediate result : `` add a singleton descendant to the conditioning set '' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    the intuition behind the following lemma is that if @xmath173 is an @xmath22-lowest @xmath172 , no v - structure below @xmath173 in @xmath22 can be `` real '' in terms of the dependences in @xmath0 : for any @xmath3 below @xmath173 that is independent of some other node @xmath2 , they remain independent when we condition on any singleton descendant @xmath28 of @xmath3 , even if @xmath28 is also a descendant of @xmath2 .",
    "the lemma is stated in a somewhat complicated manner because we want to use it both when ( 1 ) @xmath2 and @xmath3 are adjacent but the edge is known to be deletable and ( 2 ) @xmath2 and @xmath3 are not adjacent .",
    "we also find it convenient to include , in addition to @xmath3 s non-@xmath2 parents , an arbitrary additional set of non - descendants @xmath125 .",
    "* proof : * to simplify notation , let @xmath211 . assume the lemma does not hold and thus @xmath212 .",
    "consider any @xmath213-active path @xmath214 between @xmath2 and @xmath3 in @xmath0 . because @xmath215 , this path can not be active without @xmath28 in the conditioning set , which means that @xmath28 must be on the path , and it must be a collider in every position it occurs . without loss of generality ,",
    "assume @xmath28 occurs exactly once as a collider along the path ( we can simply delete the sub - path between the first and last occurrence of @xmath28 , and the resulting path will remain active ) , and let @xmath216 be the sub - path from @xmath2 to @xmath28 along @xmath214 , and let @xmath217 be the sub - path from @xmath28 to @xmath3 along @xmath214 .",
    "because @xmath28 is a proper descendant of @xmath3 in @xmath22 , and @xmath3 is a descendant of an @xmath22-lowest @xmath172 , we know @xmath28 can not be a @xmath172 , else it would be lower than @xmath173 in @xmath22 .",
    "that means that in @xmath0 , there is a directed path @xmath218 consisting of at least one edge from @xmath28 to some @xmath172 .",
    "no node @xmath219 along this path can be in @xmath220 , else we could splice in the path @xmath221 between @xmath216 and @xmath217 , and the resulting path would remain active without @xmath28 in the conditioning set . note that this means that @xmath222 can not belong to @xmath223 .",
    "similarly , the path can not reach @xmath2 or @xmath3 , else we could combine this out - of-@xmath28 path with @xmath217 or @xmath216 , respectively , to again find an @xmath220-active path between @xmath2 and @xmath3 .",
    "we know that in @xmath22 , @xmath222 must be a non - descendant of @xmath3 , else @xmath222 would be a lower @xmath172 than @xmath173 in @xmath22 .",
    "because @xmath224 contains all of @xmath3 s parents and none of its descendants , and because ( as we noted ) @xmath222 can not be in @xmath224 , we know @xmath22 contains the independence @xmath225 .",
    "but we just argued that the ( directed ) path @xmath226 in @xmath0 does not pass through any of @xmath227 , which means that it constitutes an out - of @xmath28 @xmath228-active path that can be combined with @xmath217 to produce a @xmath228-active path between @xmath28 and @xmath222 , yielding a contradiction .",
    "the next lemma considers a collider @xmath229 in @xmath22 where either there is no edge between @xmath2 and @xmath3 ( i.e. , the collider is a v - structure ) or the edge is deletable . the lemma states that if @xmath2 and @xmath3 remain independent when conditioning on their common child  where all the non-@xmath230 parents of all three nodes are also in the conditioning set  then one of the two edges must be deletable .    [ lem : desc - del ] let @xmath231 and @xmath232 be two edges in @xmath22 .",
    "if @xmath233 and @xmath234 ( i.e. , @xmath28 added to the conditioning set ) , then at least one of the following must hold : @xmath235 or @xmath236 .",
    "* proof : * let @xmath237 be the ( non-@xmath2 and non-@xmath3 ) parents of @xmath2 and @xmath3 that are not parents of @xmath28 , and let @xmath238 be all of @xmath28 s parents other than @xmath2 and @xmath3 . using this notation , we can re - write the two conditions of the lemma as : @xmath239 and @xmath240 from the weak transitivity axiom we conclude from these two independences that either @xmath241 or @xmath242 .",
    "assume the first of these is true @xmath243 if we apply the composition axiom to the independences in equation [ eq : base - no - z ] and equation [ eq : wt1 ] we get latexmath:[$x { \\mbox{$\\perp\\!\\!\\perp$}}_{{{\\cal h } } } y , z    axiom we can then pull @xmath3 into the conditioning set to get : @xmath245 because @xmath246 is precisely the parent set of @xmath28 , and because @xmath125 ( i.e. , the parents of @xmath28 s parents ) can not contain any descendant of @xmath28 , we know by the markov conditions that @xmath247 applying the intersection axiom to the independences in equation [ eq : wu - aio ] and equation [ eq : nd - aio ] yields : @xmath248 because @xmath249 , this means the first independence implied by the lemma follows .    if the second of the two independence facts that follow from weak transitivity hold ( i.e. , if @xmath241 ) , then a completely parallel application of axioms leads to the second independence implied by the lemma .",
    "[ lem : delete - lower ] let @xmath3 be any @xmath22-descendant of an @xmath22-lowest @xmath172 . if there exists an @xmath250 that has a common @xmath22-descendant with @xmath3 and for which @xmath251 then there exists an edge @xmath252 that is deletable in @xmath22 , where @xmath28 is a proper @xmath22-descendant of @xmath3 .",
    "* proof : * let @xmath28 be the _",
    "highest _ common descendant of @xmath3 and @xmath2 , let @xmath253 be the _",
    "lowest _ descendant of @xmath3 that is a parent of @xmath28 , and let @xmath254 be any descendant of @xmath2 that is a parent of @xmath28 .",
    "we know that either ( 1 ) @xmath255 and @xmath256 or ( 2 ) @xmath253 and @xmath254 are not adjacent and have no directed path connecting them ; if this were not the case , and @xmath22 contained a path @xmath257 ( @xmath258 ) then @xmath254 ( @xmath253 ) would be a higher common descendant than @xmath28 .",
    "this means that in either case ( 1 ) or in case ( 2 ) , we have @xmath259 for case ( 1 ) , this is given to us explicitly in the statement of the lemma , and for case ( 2 ) , @xmath260 and thus the independence holds from the markov conditions in @xmath22 because @xmath254 is a non - descendant of @xmath253 . because in both cases we know there is no directed path from @xmath253 to @xmath254 , we know that all of @xmath261 are non - descendants of @xmath253 , and thus we can add them ( via composition and weak union ) to the conditioning set of equation [ eq : de ] : @xmath262 for any @xmath263 ( i.e. , any parent of @xmath28 excluding @xmath253 and @xmath254 ) , we know that @xmath264 can not be a descendant of @xmath253 , else @xmath264 would have been chosen instead of @xmath253 as the lowest descendant of @xmath3 that is a parent of @xmath28 .",
    "thus , we can yet again add to the conditioning set ( via composition and weak union ) to get : @xmath265 because no member of the conditioning set in equation [ eq : de - r ] is a descendant of @xmath253 , and because @xmath253 , by virtue of being a descendant of @xmath3 , must also be a descendant of the @xmath22-lowest @xmath172 , we conclude from lemma [ lem : desc - add ] that for ( proper @xmath22-descendant of @xmath3 ) @xmath28 we have : @xmath266 given equation [ eq : de - r ] and equation [ eq : de - r - z ] , we can apply lemma [ lem : desc - del ] and conclude either ( 1 ) @xmath267 and hence @xmath268 is deletable in @xmath22 or ( 2 ) @xmath269 and hence @xmath270 is deletable in @xmath22    [ cor : yab ] let @xmath173 be an @xmath22-lowest @xmath172 , and let @xmath8 be any @xmath22-highest child of @xmath173 . if there exists an edge @xmath184 in @xmath22",
    "for which @xmath173 and @xmath124 are not adjacent , then either @xmath183 or @xmath184 is deletable in @xmath22 .",
    "* proof : * because @xmath173 is equal to ( and thus a descendant of ) an @xmath22-lowest @xmath172 , it satisfies the requirement for `` @xmath3 '' in the statement of lemma [ lem : delete - lower ] . because @xmath8 is the highest child of @xmath173 , @xmath124 can not be a descendant of @xmath173 and thus satisfies the requirement of `` @xmath2 '' in the statement of lemma [ lem : delete - lower ] . from the proof of the lemma , if we choose @xmath8 to be the highest - common descendant ( i.e. , `` @xmath28 '' ) , the corollary follows by noting that because @xmath8 is the highest @xmath22-child of @xmath173 , @xmath173 must be a lowest parent of @xmath8 , and thus we can choose @xmath271 @xmath272 .",
    "[ cor : recurse ] let @xmath26 be any deletable edge within @xmath22 for which @xmath3 is a descendant of an @xmath22-lowest @xmath172 .",
    "then there exists an edge @xmath273 that is deletable in @xmath22 for which @xmath28 and @xmath126 have no common descendants .",
    "* proof : * if @xmath2 and @xmath3 have a common descendant , we know from lemma [ lem : delete - lower ] that there must be another deletable edge @xmath273 for which @xmath126 is a proper descendant of @xmath3 , and thus @xmath28 and @xmath126 satisfy the conditions for `` @xmath2 '' and `` @xmath3 '' , respectively , in the statement of lemma [ lem : delete - lower ] , but with a lower `` @xmath3 '' than we had before .",
    "because @xmath22 is acyclic , if we repeatedly apply this argument we must reach some edge for which the endpoints have no common descendants .",
    "* theorem  [ th : main ] * _ if @xmath64 for cpdag @xmath38 and dag @xmath0 , then for any eih property @xmath1 that holds on @xmath0 , there exists a @xmath1-consistent @xmath54 that when applied to @xmath38 results in the cpdag @xmath56 for which @xmath65 .",
    "_ * proof : * consider any dag @xmath274 in @xmath275_{\\approx}$}}$ ] . from theorem [ th :",
    "delete ] , we know that there exists either a covered edge or deletable edge in @xmath274 ; if we reverse any covered edge in dag @xmath276 , the resulting dag @xmath277 ( which is equivalent to @xmath276 ) will be closer to @xmath0 in terms of total edge differences , and therefore because @xmath278 we must eventually reach an @xmath279 for which theorem [ th : delete ] identifies a deletable edge @xmath48 .",
    "the edge @xmath48 in @xmath22 satisfies the preconditions of corollary [ cor : recurse ] , and thus we know that there must also exist a deletable edge @xmath26 in @xmath22 for which @xmath2 and @xmath3 have no common descendants in @xmath179$}}$ ] for @xmath177 .",
    "let @xmath66 be the dag that results from deleting the edge @xmath147 in @xmath22 .",
    "because there is a ges delete operator corresponding to every edge deletion in every dag in @xmath275_{\\approx}$}}$ ] , we know there must be a set @xmath81 for which the operator @xmath280when applied to @xmath38results in @xmath281_{\\approx}$}}$ ] . because @xmath26 is deletable in @xmath22 , the operator satisfies the imap requirement in the theorem .",
    "for the remainder of the proof , we demonstrate that it is @xmath1-consistent .",
    "because all directed edges in @xmath56 are compelled , these edges must exist with the same orientation in all dags in @xmath282_{\\approx}$}}$ ] ; it follows that any subset @xmath55 of the common descendants of @xmath2 and @xmath3 in @xmath56 must also be common descendants of @xmath2 and @xmath3 in @xmath66 .",
    "but because @xmath2 and @xmath3 have no common descendants in the `` pruned '' subgraph @xmath179$}}$ ] , we know that @xmath55 is contained entirely in the complement of @xmath35 , which means @xmath283 $ } } = { \\mbox{${{\\cal g}}[{\\mbox{${\\bf w}$}}]$}}$ ] ; because @xmath66 is the same as @xmath22 except for the edge @xmath26 , we conclude @xmath284 $ } } = { \\mbox{${{\\cal g}}[{\\mbox{${\\bf w}$}}]$}}$ ] .",
    "we now consider the induced subgraph @xmath285$}}$ ] that we get by `` expanding '' the graph @xmath284$}}$ ] to include @xmath2 and @xmath3 . because @xmath2 and @xmath3 are not adjacent in @xmath66 , and because @xmath66 is acyclic , any edge in @xmath285$}}$ ] that is not in @xmath284$}}$ ] must be directed from either @xmath2 or @xmath3 into a node in the descendant set @xmath55 . because all nodes in @xmath55 are in the complement of @xmath35",
    ", these new edges must also exist in @xmath0 , and we conclude @xmath285 $ } } = { \\mbox{${{\\cal g}}[{\\mbox{${\\bf w}$}}\\cup x \\cup y]$}}$ ] . to complete the proof , we note that because @xmath1 is hereditary , it must hold on @xmath286$}}$ ] . from proposition",
    "[ prop : subeq ] , we know @xmath285 $ } } \\approx { \\mbox{${\\mbox{${\\cal c}$}}'[{\\mbox{${\\bf w}$}}\\cup x \\cup y]$}})$ ] , and therefore because @xmath1 is equivalence invariant , it holds for @xmath287$}}$ ] .",
    "david  maxwell chickering .",
    "a transformational characterization of bayesian network structures . in s.  hanks and",
    "p.  besnard , editors , _ proceedings of the eleventh conference on uncertainty in artificial intelligence , montreal , qu _ , pages 8798 .",
    "morgan kaufmann , august 1995 .",
    "david  maxwell chickering .",
    "learning bayesian networks is np - complete . in d.",
    "fisher and h.j .",
    "lenz , editors , _ learning from data : artificial intelligence and statistics v _ , pages 121130 .",
    "springer - verlag , 1996 .",
    "david  maxwell chickering and christopher meek .",
    "finding optimal bayesian networks . in a.",
    "darwiche and n.  friedman , editors , _ proceedings of the eighteenth conference on uncertainty in artificial intelligence , edmonton , ab _ , pages 94102 .",
    "morgan kaufmann , august 2002 .    david  maxwell chickering and christopher meek .",
    "selective greedy equivalence search : finding optimal bayesian networks using a polynomial number of score evaluations . in _ proceedings of the thirty first conference on uncertainty in artificial intelligence , amsterdam , netherlands _ , 2015 .",
    "s.  dasgupta . learning polytrees . in k.",
    "laskey and h.  prade , editors , _ proceedings of the fifteenth conference on uncertainty in artificial intelligence , stockholm , sweden _ , pages 131141 .",
    "morgan kaufmann , 1999 .",
    "nir friedman , iftach nachman , and dana peer .",
    "learning bayesian network structure from massive datasets : the `` sparse candidate '' algorithm . in _ proceedings of the fifteenth conference on uncertainty in artificial intelligence , stockholm , sweden_. morgan kaufmann , 1999 .",
    "serge gaspers , mikko koivisto , mathieu liedloff , sebastian ordyniak , and stefan szeider . on finding optimal polytrees . in _ proceedings of the twenty - sixth aaai conference on artificial intelligence_. aaai press , 2012",
    "dan geiger , azaria paz , and judea pearl .",
    "learning causal trees from dependence information . in _ proceedings of the eighth national conference on artificial intelligence - volume 2 _ , aaai90 , pages 770776 .",
    "aaai press , 1990 .",
    "steven  b. gillispie and michael  d. perlman . enumerating markov equivalence classes of acyclic digraph models . in m.",
    "goldszmidt , j.  breese , and d.  koller , editors , _ proceedings of the seventeenth conference on uncertainty in artificial intelligence , seattle , wa _ , pages 171177 .",
    "morgan kaufmann , 2001 .",
    "mukund narasimhan and jeff bilmes .",
    "pac - learning bounded tree - width graphical models . in _ proceedings of the 20th conference on uncertainty in artificial intelligence _",
    ", uai 04 , pages 410417 , arlington , virginia , united states , 2004 .",
    "auai press .",
    "tomi silander and petri myllymki . a simple approach for finding the globally optimal bayesian network structure . in _ proceedings of the twenty second conference on uncertainty in artificial intelligence , cambridge , ma",
    "_ , pages 445452 , 2006 .",
    "thomas verma and judea pearl .",
    "equivalence and synthesis of causal models . in m.",
    "henrion , r.  shachter , l.  kanal , and j.  lemmer , editors , _ proceedings of the sixth conference on uncertainty in artificial intelligence _ , pages 220227 , 1991 ."
  ],
  "abstract_text": [
    "<S> we introduce selective greedy equivalence search ( sges ) , a restricted version of greedy equivalence search ( ges ) . </S>",
    "<S> sges retains the asymptotic correctness of ges but , unlike ges , has polynomial performance guarantees . </S>",
    "<S> in particular , we show that when data are sampled independently from a distribution that is perfect with respect to a dag @xmath0 defined over the observable variables then , in the limit of large data , sges will identify @xmath0 s equivalence class after a number of score evaluations that is ( 1 ) polynomial in the number of nodes and ( 2 ) exponential in various complexity measures including maximum - number - of - parents , maximum - clique - size , and a new measure called _ v - width _ that is at least as small as  and potentially much smaller than  the other two . </S>",
    "<S> more generally , we show that for any hereditary and equivalence - invariant property @xmath1 known to hold in @xmath0 , we retain the large - sample optimality guarantees of ges even if we ignore any ges deletion operator during the backward phase that results in a state for which @xmath1 does not hold in the common - descendants subgraph . </S>"
  ]
}