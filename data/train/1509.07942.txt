{
  "article_text": [
    "linear mixed models and model - based estimators including the empirical bayes estimator ( eb ) or empirical best linear unbiased predictor ( eblup ) have been studied quite extensively in the literature from both theoretical and applied points of view . of these",
    ", small area estimation is an important application , and methods for small area estimation have received much attention in recent years due to a growing demand for reliable small area estimates . for good reviews on this topic , see ghosh and rao @xcite , rao and molina @xcite , datta and ghosh @xcite and pfeffermann @xcite .",
    "the linear mixed models used for small area estimation are categorized into two major types , the fay - herriot model suggested by fay and herriot @xcite for area - level data , and the nested error regression ( ner ) models given in battese , harter and fuller @xcite for unit - level data .",
    "the resulting model - based estimators , such as eb or eblup , for small - cluster means or subject - specific values , provide reliable estimates with higher precision than direct estimates like sample means .",
    "these stable inferences are owing to random effects , but the misspecification of random effects may increase the risk of prediction .    concerning this issue ,",
    "datta , hall and mandal @xcite recently suggested inference by testing the presence of random effects in general mixed models .",
    "they pointed out that if the random effects can be dispensed , the model parameters and the small area means may be estimated with substantially higher accuracy .",
    "further , datta and mandal @xcite generalized the idea of preliminary testing to the uncertain random effects in the fay - herriot model , which is described as @xmath1 where @xmath2 for known @xmath3 , @xmath4 and @xmath5 . in datta and mandal @xcite , the term @xmath6",
    "is called the  uncertain random effect \" since the density of @xmath6 is expressed as a mixture of @xmath7 and the one - point distribution on @xmath0 .",
    "the mixture expression of the distribution of random effects can control the extent of random effects and flexible prediction can be achieved .",
    "actually , the resulting estimator ( predictor ) of @xmath8 is expressed as the linear combination of the direct estimator @xmath9 and the regression estimator @xmath10 .",
    "the weight depends on the squared residuals @xmath11 while the weight in the resulting estimator from the traditional fay - herriot model does not take the residuals into account . in datta and mandal @xcite ,",
    "the bayesian method was implemented for inferences of the small area parameters @xmath8 s as well as the model parameters by setting the proper prior distributions for @xmath12 and @xmath13 , namely @xmath14 and @xmath15 for known ( user specified ) @xmath16 , and the improper uniform prior for @xmath17 , where @xmath18 and @xmath19 denote the beta and inverse gamma distributions , respectively .",
    "it was shown that the resulting posterior distributions of all the parameters are proper under some conditions . however , datta and mandal @xcite focused on the fay - herriot model , and their method could be restrictive in real applications .",
    "moreover , they used the proper ( informative ) prior distribution for both @xmath12 and @xmath13 , and the result could be affected by the choice of hyperparameters .    in this paper , we treat not only the uncertain random effects in more general small area models like the ner model , but also non - informative prior distributions for model parameters .",
    "the ner model has been used in various applications including small area estimation , biological experiments and econometric analysis .",
    "the ner model is described as @xmath20 where @xmath21 is the sampling error associated with @xmath22 and @xmath23 is a random effect in the @xmath24th area .",
    "it is usually assumed that @xmath21 and @xmath23 are mutually independent and distributed as @xmath25 and @xmath26 , respectively .",
    "the main purpose of the ner model is to predict ( estimate ) the quantity of linear combinations of @xmath17 and @xmath23 , namely @xmath27 for some known vector @xmath28 . for a decade ,",
    "there has been criticism that the assumption of the ner model is not necessarily satisfied in real applications and several extensions of the ner model have been proposed in order to adapt to real data sets .",
    "for example , jiang and nguyen @xcite , kubokawa , sugasawa , ghosh and chaudhuri @xcite and sugasawa and kubokawa @xcite proposed heteroscedastic nested error regression models in which the variance components @xmath29 and @xmath30 are not constant over the areas .",
    "also , ghosh , sinha and kim @xcite , arima , datta and liseo @xcite and torabi @xcite introduced extended models with measurement errors in covariates .",
    "however , the problem of uncertainty of random effects , to our knowledge , has not been considered so far in the context .    in this article",
    ", we suggest the use of the uncertain random effect in the ner model and propose the uncertain nested error regression ( uner ) model by adopting the structure @xmath31 for the prior distribution of @xmath29 , the variance of random effects , we use the prior distribution depending on @xmath32 s , which is defined as @xmath33 for some @xmath34 , where @xmath35 and @xmath36 is some proper density , so that the prior distribution of @xmath29 is more non - informative than the proper prior such as an inverse gamma distribution as used in datta and mandal @xcite . for the other parameters @xmath37 and @xmath12 , we also assign the non - informative prior as @xmath38 . hence , our bayesian procedure is objective .",
    "we also apply the ner model in the framework of the finite population to predict the true finite population mean based on the partially observed data in each population .",
    "this article is organized as follows . in section [ sec : model ] , we describe the details of the uner model and provide the bayesian estimation method as well as the main theorem regarding the propriety of the posterior distribution and the finiteness of posterior variances .",
    "the prediction problem of finite population means using uner is also discussed . in section [ sec : num ] , we compare the uner model with the ner model through simulation and empirical studies . concluding remarks are given in section [ sec : conc ] and the technical proof is given in the appendix .",
    "we consider the following uncertain nested error regression ( uner ) model @xmath39 independently for @xmath24 with @xmath40 , where @xmath41 is a @xmath42-dimensional vector of covariates , @xmath17 is a @xmath42-dimensional vector of regression coefficients , @xmath43 denotes the dirac measure on @xmath0 , and @xmath21 s are independently and identically distributed as @xmath44 .",
    "the marginal density function of @xmath23 is given by @xmath45 which is a mixture of the normal distribution @xmath46 and the point mass on @xmath0 .",
    "thus the model parameters are regression coefficients @xmath17 , the variance components @xmath30 and @xmath29 , and the mixture ratio @xmath12 .",
    "let @xmath47 be the observed vector in the @xmath24th area .",
    "then the variance of @xmath48 is @xmath49 for @xmath50 .",
    "if the prior probability @xmath12 of @xmath51 is @xmath0 , it follows that @xmath52 , and the observations in the @xmath24th area are mutually independent .",
    "the parameter which we want to estimate ( predict ) is @xmath27 for a known vector @xmath28 .",
    "the typical choice of @xmath28 is @xmath53 in which @xmath54 corresponds to the mean of the @xmath24th area .",
    "the posterior distribution of @xmath54 given @xmath32 and @xmath48 is @xmath55 where @xmath56 , the sample mean of @xmath22 in the @xmath24th area .",
    "thus the posterior distribution of @xmath54 given @xmath48 is a mixture of the normal distribution and one point mass on @xmath57 .",
    "the resulting bayes estimator @xmath58 of @xmath54 is @xmath59&=\\pt_i\\big\\{\\c_i^{\\top}\\bbe+\\frac{n_i\\tau^2}{\\si^2+n_i\\tau^2}(\\bary_i-\\barx_i^{\\top}\\bbe)\\big\\}+(1-\\pt_i)\\c_i^{\\top}\\bbe\\\\ & = \\c_i^{\\top}\\bbe+\\frac{n_i\\tau^2\\pt_i}{\\si^2+n_i\\tau^2}(\\bary_i-\\barx_i^{\\top}\\bbe),\\end{aligned}\\ ] ] where @xmath60 is the posterior probability of @xmath51 given by @xmath61 we note that @xmath60 increases in @xmath12 and @xmath62 .",
    "thus , if @xmath41 is a good covariate to explain @xmath22 in the @xmath24th area , the squared residual @xmath62 is expected to be small , and the posterior probability @xmath60 is small as well .",
    "the posterior probability @xmath60 is @xmath63 when @xmath64 and @xmath60 converges to @xmath63 as @xmath62 goes to infinity .",
    "moreover , the posterior variance of @xmath54 is expressed as @xmath65 it is interesting to point out that the posterior variance of @xmath54 , in this case , depends on observation @xmath48 through the squared residual @xmath62 and the posterior probability @xmath60 , while the posterior variance of the random effect in the usual nested error regression model is given by @xmath66 , which does not depend on observation @xmath48 .",
    "this means that the uncertain random effect enables us to take the distance between sample mean @xmath67 and synthetic estimator @xmath68 into the posterior variability of the interesting parameter @xmath54 .      since the marginal likelihood function of the model parameters @xmath69 and",
    "@xmath12 is rather complex , we consider objective bayesian inference for the model parameters as well as the random effect @xmath23 . to this end , we rewrite the model ( [ model ] ) as @xmath70 independently for @xmath24 , where @xmath71 denotes the bernoulli distribution . for implementation of full bayesian inference ,",
    "we need to set prior distributions on the model parameters . to keep objectivity of inferences",
    ", we use the uniform prior distribution on @xmath17 and the jeffreys prior distributions on @xmath30 and @xmath12 . on the other hand ,",
    "the prior distribution of @xmath29 should depend on @xmath35 , since @xmath29 can not be identified for a small value of @xmath72 .",
    "thus , for the model parameters , we use the prior distributions @xmath73 where @xmath74 for known constants @xmath75 and @xmath76 . the value of @xmath77 is chosen by the user , and this point will be discussed later .",
    "it is noted that the prior distribution on @xmath12 is proper , but the priors on @xmath37 and @xmath29 are improper , so that the posterior propriety is not always guaranteed . in theorem",
    "[ thm : pos ] , we show that the posterior distribution for the model parameters is proper under mild conditions .",
    "we now describe the posterior distribution and investigate its properties .",
    "the set of all observed data is denoted by @xmath78 for @xmath79 . from the model ( [ unerm ] ) with prior setup ( [ prior ] ) , the posterior density of parameters @xmath80 for @xmath81 and @xmath82 is given by @xmath83 \\\\ & \\times \\exp\\big\\{-\\frac{b_{2}}{\\tau^{2}}i(z\\leq a)\\big\\}. \\end{split}\\ ] ]    now , we state our main result about the posterior propriety and the existence of posterior variances .    [",
    "thm : pos ] ( a )  the marginal posterior density @xmath84 is proper if @xmath85 and @xmath86 + ( b )  the model parameters @xmath69 and @xmath12 have finite posterior variances if @xmath87 and @xmath88 .",
    "remember that @xmath42 is the dimension of the vector of regression coefficients @xmath17 , and @xmath77 is the tuning parameter of the prior for @xmath29 .",
    "part ( a ) in theorem [ thm : pos ] says that the marginal posterior densities of the small area means are proper and part ( b ) provides a sufficient condition for obtaining finite measures of uncertainty for the model parameters .",
    "we note that the conditions in theorem [ thm : pos ] are similar to the conditions given in arima , et al .",
    "@xcite and datta and mandal @xcite .",
    "the proof of theorem [ thm : pos ] is presented in the appendix .",
    "since the posterior distribution in ( [ pos ] ) can not be obtained in a closed form , we rely on the markov chain monte carlo technique , in particular the gibbs sampler , in order to draw samples from the posterior distribution .",
    "this requires generating samples from the full conditional distributions for each of @xmath80 given the remaining parameters and the data @xmath89 .",
    "fortunately , the full conditional distributions are described as familiar distributions allowing us to easily implement the gibbs sampling .",
    "the full conditional distributions are given by @xmath90 where @xmath35 , @xmath91 with @xmath92 , @xmath93 , @xmath94 , and @xmath60 is given in ( [ prob ] ) .",
    "using these expressions of full conditional distributions , we can easily draw posterior samples of all the variances and parameters to make inferences , such as point estimation , prediction intervals and standard errors , for @xmath27 .    in the closing of this section",
    ", we discuss the choices of @xmath95 and @xmath96 in the posterior distribution of @xmath29 .",
    "we remember that the prior distribution of @xmath29 is non - informative and improper when @xmath97 and informative and proper when @xmath98 .",
    "taking it into account , we should select a value of @xmath77 as small as possible .",
    "hence , it follows from theorem [ thm : pos ] that @xmath99 is the most reasonable choice . on the other hand ,",
    "as discussed in datta and mandal @xcite , a reasonable choice is @xmath100 and @xmath101 such that @xmath102=v$ ] and @xmath103 , where @xmath104 is the estimated sampling variance given by @xmath105 here , @xmath106 is the ordinary least squared estimator of @xmath17 . it should be noted that @xmath104 satisfies @xmath107=\\si^2 $ ] .      here , we consider the problem of predicting the means in finite populations .",
    "assume that there exist @xmath108 finite populations and the @xmath24th population consists of @xmath109 pairs of data @xmath110 , @xmath111 .",
    "it is supposed that @xmath112 observations are sampled from the @xmath24th population .",
    "what we want to predict is the mean of the @xmath24th finite population @xmath113 .",
    "assume also that the mean vector of covariates @xmath114 is available , which is often encountered in real application ( battese , et al .",
    "let @xmath115 and @xmath116 be collections of indices of sampled and non - sampled observations in the @xmath24th area , respectively , so that @xmath115 and @xmath116 satisfy @xmath117 and @xmath118 . without loss of generality , we assume that @xmath119 and @xmath120 . the bayes estimator of @xmath121 under quadratic loss is given by @xmath122=\\frac{1}{n_i}\\big\\{n_i\\bary_{i(s)}+(n_i - n_i)\\e[\\bary_{i(r)}|\\y_i]\\big\\},\\ ] ] where @xmath123 for evaluating the conditional mean @xmath124 $ ] , we assume that @xmath125 is expressed as @xmath126 that is , the non - sampled observations have the same data generating structure as the sampled ones .",
    "then the unobserved mean @xmath127 is expressed as @xmath128 where @xmath129 .",
    "thus the conditional distribution of @xmath127 given @xmath48 and @xmath32 is @xmath130 which yields the predictive density of @xmath127 given by @xmath131 where @xmath60 is the posterior probability of @xmath51 given in ( [ prob ] ) .",
    "thus the conditional distribution of the non - sampled data is a mixture of the two normal distributions of the predictive density , with and without random effect .",
    "moreover , the conditional variance @xmath127 given @xmath48 is calculated as @xmath132 , where @xmath133 is the posterior variance of @xmath23 given in ( [ pos.var ] ) .",
    "it is noted that , when the true mean vector of the explanatory variables @xmath134 is available in each area , the value of @xmath135 is easily obtained by @xmath136 to implement the prediction in the finite population model , we regard @xmath127 as latent variables and add the sampling step from ( [ fp - cond ] ) to the gibbs sampling given in ( [ full ] ) .",
    "in this simulation study , we compared the uner model with the conventional ner model in terms of the quality of the estimates . in applying the ner model",
    ", we used the jeffreys prior on @xmath137 , namely @xmath138 , where it is well - known that the resulting posterior distribution is proper ( berger @xcite ) .",
    "the full conditional posterior distributions are given by @xmath139 where @xmath140 with @xmath141 .",
    "we considered the following data generating process : @xmath142 where @xmath143 , @xmath144 , @xmath145 , and @xmath146 s were generated from the uniform distribution on @xmath147 and fixed through simulation runs .",
    "the four combinations of @xmath148 were considered as @xmath149 , @xmath150 , @xmath151 , @xmath152 . for the true distributions of @xmath23 , we considered the following four scenarios for each choice of @xmath148 .",
    "@xmath153 where @xmath154 and @xmath155 denote the scaled @xmath156-distribution with @xmath157 degrees of freedom with mean @xmath77 and variance @xmath158 and the scaled laplace distribution with mean @xmath77 and variance @xmath158 , respectively .",
    "hence , uner is misspecified in scenarios s3 and s4 , and overspecified in scenario s1 .    based on @xmath159 simulation runs , we computed the mean squared errors ( mse ) , absolute bias of @xmath160 , and empirical coverage probability of the @xmath161 credible interval of @xmath54 , which are respectively defined as @xmath162 where @xmath163 , @xmath164 and @xmath165 are the posterior mean , the true value , and the @xmath161 credible intervals , respectively , of @xmath54 in the @xmath166th simulation runs . in each iteration of the simulation run",
    ", we used @xmath167 posterior samples after @xmath168 initial iterations for both uner and ner .",
    "the results are given in table [ tab : sim ] . in scenario s1 ,",
    "both the mse and absolute bias of uner are larger than those of ner since uner is overspecified . however , as the number of @xmath169 and @xmath108 get large , the difference of these values gets small . for the other scenarios , we can observe that uner clearly performs better than ner in terms of mse and absolute bias , and the differences get larger as @xmath169 and @xmath108 get larger . finally , it is observed that the coverage probability of credible intervals are similar in uner and ner .",
    "hence , we can conclude that uner is expected to be a useful tool when @xmath108 and @xmath169 are moderate or large .",
    "@xmath170    [ tab : sim ]      this example , primarily for illustration , used the uner model ( [ model ] ) and data from the posted land price data along the keikyu train line in 2001 .",
    "this train line connects the suburbs in kanagawa prefecture to the tokyo metropolitan area .",
    "those who live in the suburbs in kanagawa prefecture take this line to work in tokyo every weekday .",
    "thus , it is expected that the land price depends on the distance from tokyo .",
    "the posted land price data are available for 52 stations on the keikyu train line , and we consider each station as a small area , namely , @xmath171 . for the @xmath24th station ,",
    "data of @xmath172 land spots are available , where @xmath172 varies around @xmath173 and ranges from @xmath63 to @xmath174 .    for @xmath175 ,",
    "let @xmath22 denote the log - transformed value of the posted land price ( yen ) per for square meter of the @xmath176th spot , @xmath177 is the time it takes from the nearby station @xmath24 to tokyo station around 8:30 in the morning , @xmath178 is the geographical distance from spot @xmath176 to station @xmath24 and @xmath179 denotes the floor - area ratio , or ratio of the building volume to the area at spot @xmath176 .",
    "these values of @xmath180 and @xmath179 are also transformed by the logarithmic function .",
    "we applied the uner model ( [ model ] ) described as @xmath181 where @xmath21 s are independent and identically distributed as @xmath44 . for comparison",
    ", we also applied the conventional ner model to this data set .",
    "in applying the uner model , we used the prior distribution with @xmath99 and @xmath182 for @xmath183 as discussed in the end of section [ sec : post ] . in both models , we generated @xmath184 posterior samples after @xmath185 iterations of gibbs sampling given in ( [ full ] ) and ( [ posner ] ) , respectively , and obtained the posterior means as well as the @xmath161 credible intervals of the model parameters , which are given in table [ tab : plp ] .",
    "moreover , based on the posterior samples , we computed the deviance information criterion ( dic ) suggested in spiegelhalter , best , carlin and van der linde @xcite , which is defined as @xmath186 , where @xmath187 is a vector of the unknown model parameters , @xmath188 is @xmath189 times the log - marginal likelihood function , and @xmath190 and @xmath191 denote the posterior means of @xmath188 and @xmath187 , respectively .",
    "note that @xmath192 in the uner model , and @xmath193 in the ner model , which are given in table [ tab : plp ] as well .",
    "it is revealed from table [ tab : plp ] that the posterior estimates and credible intervals of regression coefficients @xmath194 are similar between uner and ner , and in both models , all the credible intervals of regression coefficients are bounded away from @xmath0 . on the other hand , the results of variance components @xmath29 and @xmath30 are different because of the effect of the parameter @xmath12 . in terms of dic values , the uner model seems more preferable than the conventional ner model . to see the effects of @xmath32 , we calculated the posterior probabilities @xmath60 s which are illustrated in the left panel in figure [ fig : plp ] .",
    "it is revealed that the @xmath60 s change dramatically from area to area , and the @xmath60 s in most areas are around @xmath195 which comes from the posterior mean of @xmath196 as shown in table [ tab : plp ] .",
    "we next considered estimating the land price of a spot with a floor - area ratio of 100@xmath197 and a distance of 1000 m from the station @xmath24 , namely @xmath198 for @xmath199 and @xmath200 . based on the posterior samples ,",
    "we calculated the point estimates @xmath160 and the posterior standard errors .",
    "the results are given in the right panel of figure [ fig : plp ] , noting that the mean of the posterior standard errors for all areas in uner and ner are @xmath201 and @xmath202 , respectively .",
    "we also computed the length of the prediction intervals of @xmath54 , and found that the results are similar to standard errors .",
    "it is revealed from figure [ fig : plp ] that uner provides better estimates than ner in terms of posterior standard errors in most areas . in some areas ,",
    "the posterior standard errors of uner are larger than those of ner when correspondingly the posterior probability @xmath60 is larger than @xmath203 as shown in the left panel of figure [ fig : plp ] .",
    "thus the uncertain random effects may increase the variability of predictors compared to the conventional random effects in the areas where the existence of random effect is strongly supported .",
    "this phenomenon was pointed out in datta and mandal @xcite in the fay - herriot model . however , taking the dic values into account as well , the uner model works well in this application .",
    "( left ) and standard errors of @xmath54 ( right ) in each area . [",
    "fig : plp ] , title=\"fig:\",width=226 ]   ( left ) and standard errors of @xmath54 ( right ) in each area .",
    "[ fig : plp ] , title=\"fig:\",width=226 ]    @xmath204    [ tab : plp ]      we next investigated the numerical performance of the small area prediction problem in the framework of a finite population .",
    "we again used the plp data in the kanto region in 2001 , which includes tokyo , kanagawa , chiba and saitama prefectures .",
    "thus the data set includes the plp data along the keikyu line used in the previous subsection .",
    "the full data set we used is the land price data with covariates ( @xmath205 , @xmath178 and @xmath179 as used in the previous study ) and each data point has its unique nearest railroad station , which we regard as a small area . for the @xmath24th small area ( @xmath206 )",
    ", there are @xmath109 land spots .",
    "to consider all the observed land price data in each small area in the framework of a finite population , we analyzed only the data which belong to the small areas that have a moderately large number of data points , namely we pick up the area @xmath24 s with @xmath207 .",
    "then the resulting number of finite populations is @xmath208 , and the population sizes @xmath109 s range from @xmath209 to @xmath210 , but most @xmath109 s vary around @xmath211 .",
    "we artificially made the sampled data set and predict each finite population mean of the land price by applying uner .",
    "the sampling scheme is simple random sampling without replacement in each finite population and @xmath172 data are sampled in the @xmath24th finite population .",
    "the sample sizes @xmath172 s are decided by some ratio @xmath212 and @xmath213 percent of the data in each population are sampled , that is @xmath172 is the nearest integer to @xmath214 .",
    "we considered four choices for @xmath215 , namely @xmath216 . in each case , we computed the squared root mean squared errors for estimators of finite population means as @xmath217 where @xmath163 is the estimator of the finite population using uner or ner , and @xmath159 in this study . for both uner and ner , we calculated @xmath163 by 5,000 posterior samples after 1,000 iterations",
    "using the method discussed in section [ sec : fp ] . in the uner estimation ,",
    "the same form of the prior distribution as in the previous section was used , namely @xmath218 and @xmath101 for estimated sampling error @xmath104 . to compare values of the smse for the two models",
    ", we then computed the ratio of smse given by @xmath219 , and provide their values in figure [ fig : fp ] .",
    "it is observed from figure [ fig : fp ] that uner provides better estimates than ner in some areas , but worse estimates than in several areas for the four cases of @xmath215 .",
    "moreover , it is also revealed that an improvement of uner over ner becomes greater as the sampling rate @xmath215 gets larger .     ,",
    "title=\"fig:\",width=226 ]   , title=\"fig:\",width=226 ] +   , title=\"fig:\",width=226 ]   , title=\"fig:\",width=226 ]",
    "in this article , we have proposed the use of uncertain random effects in the nested error regression model called the uner model for unit - level data .",
    "this can be regarded as an extension of datta and mandal @xcite .",
    "we have used the non - informative priors for all the parameters and proposed bayesian inferences for the linear combination of fixed effects and random effects as well as the model parameters .",
    "we have shown that the posterior distribution is proper and the posterior variances exist under some conditions . through the simulation study ,",
    "we have compared the uner model with the conventional nested error regression ( ner ) model .",
    "it has been revealed that uner can provide more accurate estimates than that of ner when the underlying distribution of random effects is a mixture of a point mass on the origin and a continuous distribution .",
    "moreover , we have applied uner together with ner to the plp data and have found that the uner model fits better than the ner model in terms of dic .",
    "+ * acknowledgement *    we would like to thank the associate editor and two reviewers for many valuable comments and helpful suggestions which led to an improved version of this paper .",
    "the first author was supported in part by grant - in - aid for scientific research ( 15j10076 ) from the japan society for the promotion of science ( jsps ) .",
    "research of the second author was supported in part by grant - in - aid for scientific research ( 15h01943 and 26330036 ) from the japan society for the promotion of science .",
    "let @xmath220 be the right side of ( [ pos ] ) . for part ( a )",
    ", we shall show that @xmath221 namely the integral for each @xmath222 is finite .",
    "we first prove for the case @xmath223 . in this case , the integral reduces to @xmath224 it is noted that @xmath225 , where @xmath226 is a beta function",
    ". then the integral is finite since the posterior distribution of the usual linear regression for the jeffreys prior is proper if the conditions given in theorem [ thm : pos ] are satisfied .",
    "for the integral in the case @xmath227 , using @xmath228 , it is sufficient to show that @xmath229 for @xmath230 where @xmath231,\\end{aligned}\\ ] ] and @xmath232.\\end{aligned}\\ ] ] to show the integrability of @xmath233 and @xmath234 , we consider the case of @xmath222 with @xmath235 . without loss of generality , we assume that @xmath51 for @xmath236 and @xmath237 for @xmath238 . then @xmath239 can be rewritten as @xmath240\\\\ & \\ \\ \\ \\ \\times \\big [ \\prod_{i = k+1}^m \\exp\\big ( -\\frac{\\sum_{j=1}^{n_i}(y_{ij}-\\x_{ij}^{\\top}\\bbe)^2}{2\\si^2}\\big   ) \\de_0(v_i)\\big   ] .\\end{aligned}\\ ] ] we define @xmath241-dimensional vector @xmath242 as @xmath243 and @xmath244 for @xmath245 .",
    "then , if @xmath246 , we have @xmath247 where @xmath248 .",
    "the right side is integrable with respect to @xmath30 and @xmath29 since @xmath249 and @xmath250 , whereby we obtain @xmath251 where @xmath252 in what follows , we show that @xmath253 is integrable . to this end",
    ", we note that @xmath254 and we evaluate the two integrals separately . for the first term , since @xmath255 is idempotent and @xmath256 , there exists @xmath257 such that @xmath258 for all @xmath259",
    ". then we have @xmath260 where @xmath261 is the volume of the unit sphere in @xmath262 . for the second term",
    ", it follows that @xmath263 since @xmath264 is a quadratic function of @xmath259 , the integral is finite as far as @xmath85 . for the integrability of @xmath265",
    ", we carry out integration with respect to @xmath266 and @xmath29 to get @xmath267 since for @xmath249 , @xmath268 it follows that @xmath269 is integrable as far as @xmath249 .",
    "thus the proof of part ( a ) is established .    for the proof of part ( b ) , it is sufficient to show that the posterior second moments are finite . since the statement for @xmath12 is clear , we establish the result for @xmath266 and @xmath29 . as in the proof of part (",
    "a ) , we consider the three cases where @xmath270 and @xmath271 . by replacing @xmath272 in expressions of @xmath273 and @xmath274 with @xmath275 , it follows that @xmath276<\\infty$ ] when @xmath87 .    for @xmath277",
    "$ ] , we first note that @xmath278 for @xmath279 then it follows that @xmath280 since @xmath281 , the second term is finite if @xmath282 for all @xmath283 , namely @xmath284 .",
    "the first term is also finite as far as @xmath285 .",
    "for the other cases @xmath286 and @xmath271 , we can similarly show that @xmath287 and @xmath288 are finite under the condition given in theorem [ thm : pos ] .",
    "finally , for @xmath289 $ ] , it follows that @xmath290 which is finite as far as @xmath282 for all @xmath283 , namely @xmath284 . in the cases of @xmath286 and @xmath271 , it is integrable if @xmath291 which can be established since @xmath75 .",
    "thus we complete the proof of part ( b ) .",
    "battese , g. e. , harter , r. m. and fuller , w. a. ( 1988 ) .",
    "an error component model for prediction of mean crop areas using survey and satellite data .",
    "_ journal of the american statistical association _ , * 95 * , 28 - 36 .",
    "datta , g. , s. , hall , p. and mandal , a. ( 2011 ) .",
    "model selection by testing for the presence of small - area effects , and application to area - level data .",
    "_ journal of the american statistical association _ , * 106 * , 362 - 374 .",
    "ghosh , m. , sinha , k. and kim , d. ( 2006 ) .",
    "empirical and hierarchical bayesian estimation in finite population sampling under structural measurement error models .",
    "_ scandinavian journal of statistics _ , * 33 * , 591 - 608 .",
    "spiegelhalter , d. j. , best , n. g. , carlin , b. p. and van der linde , a. ( 2002 ) . bayesian measures of model complexity and fit ( with discussion ) .",
    "_ journal of the royal statistical society , b. _ , * 64 * , 583 - 639 ."
  ],
  "abstract_text": [
    "<S> nested error regression models are useful tools for analysis of grouped data , especially in the case of small area estimation . </S>",
    "<S> this paper suggests a nested error regression model using uncertain random effects in which the random effect in each area is expressed as a mixture of a normal distribution and a positive mass at @xmath0 . for estimation of the model parameters and prediction of the random effects , </S>",
    "<S> an objective bayesian inference is proposed by setting non - informative prior distributions on the model parameters . under mild sufficient conditions , </S>",
    "<S> it is shown that the posterior distribution is proper and the posterior variances are finite , confirming the validity of posterior inference . to generate samples from the posterior distribution </S>",
    "<S> , we provide the gibbs sampling method with familiar forms for all the full conditional distributions . </S>",
    "<S> this paper also addresses the problem of predicting finite population means , and a sampling - based method is suggested to tackle this issue . </S>",
    "<S> finally , the proposed model is compared with the conventional nested error regression model through simulation and empirical studies .    </S>",
    "<S> bayesian estimator , nested error regression model , posterior propriety , small area estimation , uncertain random effect </S>"
  ]
}