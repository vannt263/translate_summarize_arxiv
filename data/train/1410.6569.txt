{
  "article_text": [
    "classical noiseless index coding problem consists of a sender with @xmath0 independent messages , and a noiseless broadcast channel , where each receiver demands a subset of the messages , while knowing the values of a different subset of messages as side information .",
    "the transmitter is required to broadcast a coded packet , with the least possible length , to meet the demands of all the receivers  ( see  @xcite and references therein ) . in the noisy version of this problem , the messages are to be transmitted across a broadcast channel with additive white gaussian noise ( awgn ) at the receivers  ( see @xcite and references therein ) .",
    "the exact capacity region ( the achievable rates of the @xmath0 messages ) with general message demands and side informations is known only for the two - receiver case  @xcite .",
    "we consider the special case of noisy index coding where every receiver demands all the messages at the source .",
    "instances of this communication problem are encountered in wireless relay networks  @xcite , retransmissions in broadcast channels  @xcite , and communications in sensor networks  @xcite .",
    "[ fig : cellular ] illustrates a wireless version of the ` butterfly ' network where noisy index coding is useful .",
    "two data packets @xmath1 and @xmath2 , which are available at the base stations @xmath3 and @xmath4 , respectively , are to be broadcast to all three users @xmath5 in the network through a decode - and - forward helper node @xmath6 .",
    "the nodes @xmath7 and @xmath6 are within the range of @xmath3 , @xmath8 and @xmath6 are within the range of @xmath4 , and all three users are in the range of @xmath6 . in the first phase of the protocol",
    ", both @xmath3 and @xmath4 simultaneously broadcast their corresponding data packets .",
    "while @xmath7 and @xmath8 decode @xmath1 and @xmath2 , respectively , the helper node @xmath6 experiences a multiple - access channel and decodes both the messages . in the second phase of the protocol , @xmath6 broadcasts @xmath1 and @xmath2 to all three users .",
    "while @xmath7 and @xmath8 are aided by the data packets received in the first phase of the protocol , no such side information is available at @xmath9 .",
    "the traditional approach of broadcasting the bit - wise xor of @xmath1 and @xmath2 in the second phase is not useful , since it does not satisfy the demands of @xmath9 . on the other hand ,",
    "performing index coding at the physical layer will allow us to convert the side informations at @xmath7 and @xmath8 into performance gains while meeting the demands of all three receivers .",
    "noisy index coding for broadcasting common messages is also useful in the retransmission phase of satellite broadcasting services , which was the original motivation for considering ( noiseless ) index codes  @xcite .",
    "consider a satellite downlink , as shown in fig .",
    "[ fig : satellite ] , where a common message consisting of @xmath0 data packets is broadcast to multiple terrestrial receivers . due to",
    "varying channel conditions , each receiver successfully decodes ( possibly different ) parts of the transmitted frame . in the retransmission phase of the protocol",
    ", the satellite can use a noisy index code to simultaneously broadcast the @xmath0 packets while exploiting the side informations at all the receivers .",
    "the capacity region of the common message gaussian broadcast channel with receiver side information follows from the results in  @xcite .",
    "denote a receiver by @xmath10 , where @xmath11 is the signal - to - noise ratio , and is the index set of the messages whose values are known at the receiver as side information .",
    "note that this terminology includes the case , i.e. , no side information .",
    "let be the rates of the individual messages in bits per dimension ( b / dim ) , i.e. , the number of bits to be transmitted per each use of the broadcast channel .",
    "the source entropy is , and the _ side information rate _ at is defined as .",
    "the rate tuple @xmath12 is achievable if and only if  @xcite @xmath13 for every receiver @xmath10 .",
    "consequently , at high message rates , the presence of the side information corresponding to @xmath14 at a receiver reduces the minimum required @xmath11 from approximately @xmath15 to @xmath16 , or equivalently , by a factor of . hence",
    ", a capacity - achieving index code allows a receiver to transform each bit per dimension of side information into an apparent @xmath11 gain of approximately .",
    "the notion of _ multiple interpretation _ was introduced in  @xcite as a property of error correcting codes that allows the receiver performance to improve with the availability of side information .",
    "binary multiple interpretation codes based on nested convolutional and cyclic codes were constructed in  @xcite and  @xcite , respectively .",
    "these codes can be viewed as index codes for the noisy binary broadcast channel . to the best of our knowledge , there has been no prior work in designing index codes for the awgn broadcast channel .      in this work ,",
    "we propose _ lattice index codes _ @xmath17 for the awgn broadcast channel , in which the @xmath0 messages are individually mapped to @xmath0 modulo lattice constellations , and the transmit symbol",
    "is generated as the sum of the individual symbols modulo a coarse lattice .",
    "given the value of @xmath18 as side information , the optimal decoder restricts its choice of symbols to a subset of @xmath17 , thereby increasing the minimum squared euclidean distance between the valid codewords .",
    "we use this squared distance gain , normalized by the side information rate @xmath19 , as the design metric , and call it the _ side information gain _ of the code @xmath17 .",
    "we first motivate our results using a simple one - dimensional lattice code over @xmath20 ( section  [ sec : motivating_example ] ) , and then show that is an upper bound on the side information gain of lattice index codes constructed from densest lattices  ( section  [ sec : linear_lattice_codes ] ) . note that this upper bound characterizes the maximum squared distance gain , and is independent of the information theoretic result of  @xcite which characterizes the @xmath11 gain asymptotically in both the code dimension and probability of error . based on the chinese remainder theorem",
    ", we construct index codes for the awgn channel using lattices over the following principal ideal domains  ( pids ) : rational integers @xmath20 , gaussian integers @xmath21 $ ] , eisenstein integers @xmath22 $ ] , and the hurwitz quaternion integers @xmath23  ( sections  [ sec : commutative ] and  [ sec : hurwitz ] ) .",
    "all the proposed lattice index codes provide a side information gain of . among all lattice index codes",
    "constructed using the densest lattices in any given dimension , our codes provide the optimal side information gain .",
    "finally , using the example of a three receiver gaussian broadcast channel with private message requests , we illustrate how the proposed lattice index codes can be utilized under more general message demands ( section  [ sec:3receiver ] ) .      since the submission of the initial version of this paper , further results on index codes for the common message gaussian broadcast channel have been reported .",
    "the lattice index codes presented in this paper are designed using tuples of distinct prime numbers , and hence , the resulting rates of the @xmath0 messages are not all equal to each other , and the alphabet sizes of the messages are not powers of @xmath24 . new lattice index codes are reported in  @xcite that generalize the @xmath21 $ ] and @xmath22 $ ] based constructions of section  [ sec : commutative ] to arbitrary algebraic number fields .",
    "further ,  @xcite constructs sequences of lattice index codes , that consist of one code for each value of @xmath0 , for encoding all the @xmath0 messages at the same rate .",
    "index codes based on multidimensional pulse amplitude modulation ( pam ) constellations have been obtained in  @xcite that encode all the messages at the same rate and allow alphabet sizes that are powers of @xmath24 . in  @xcite , the achievable rate region of a concatenated coding scheme that uses an inner index code for modulation and @xmath0 independent outer channel codes for noise resilience has been analyzed .",
    "this concatenated scheme has been shown to convert the noisy index coding channel into a multiple - access channel and perform close to the channel capacity .    _",
    "notation : _ we use and .",
    "the symbol @xmath25 denotes the complement of the set @xmath14 , and @xmath26 is the empty set . for a complex number @xmath27 ,",
    "the symbols @xmath28 , @xmath29 and @xmath30 denote the conjugate , the real part , and the imaginary part of @xmath27 , respectively .",
    "the operator @xmath31 is the transpose of a matrix or a vector , and @xmath32 is the euclidean norm of a vector .",
    "the lattice index codes proposed in sections  [ sec : commutative ] and  [ sec : hurwitz ] achieve a large side information gain by providing a squared distance gain that is exponential in the side information rate @xmath19 for . in this section",
    ", we illustrate the key idea behind our construction using a simple one - dimensional lattice index code  ( example  [ ex : toy_example ] ) .",
    "let be @xmath0 independent messages at the source with alphabets , respectively .",
    "the transmitter jointly encodes the information symbols , to a codeword , where is an @xmath33-dimensional constellation .",
    "the rate of the @xmath34 message is  b / dim ,",
    ". given the channel output , where @xmath35 is the additive white gaussian noise , and the side information @xmath36 , i.e. , @xmath37 for @xmath38 , the maximum - likelihood decoder at the receiver @xmath10 restricts its search to the subcode obtained by expurgating all the codewords in @xmath17 that correspond to . denote the minimum distance between any two points in @xmath17 by @xmath39 .",
    "let @xmath40 be the minimum distance of the subcode @xmath41 , and @xmath42 be the minimum of @xmath40 over all possible values of side information @xmath18 .",
    "then the minimum squared distance gain corresponding to the side information index set @xmath14 is @xmath43  db . the performance improvement at the receiver due to @xmath14 is observed as a shift in the probability of error curve ( versus @xmath11 ) to the left .",
    "the squared distance gain @xmath44  db is a first - order estimate of this apparent @xmath11 gain .",
    "normalizing with respect to the side information rate , and minimizing over all subsets @xmath14 , we see that each bit per dimension of side information provides a squared distance gain of at least @xmath45 we call @xmath46 the _ side information gain _ of the code @xmath17 , and its unit is @xmath47 .    for a given code @xmath17 ,",
    "the gain available from @xmath14 is at least @xmath48  db with respect to the baseline performance of @xmath17 in the classical point - to - point awgn channel , i.e. , with no side information . for @xmath17 to be a good index code for the awgn broadcast channel , we require that    @xmath17 be a good point - to - point awgn code , in order to minimize the @xmath11 requirement at the receiver with no side information ; and    @xmath46 be large , so as to maximize the minimum gain from the availability of side information at the other receivers .",
    "an additional desirable property is that the normalized gain @xmath49 provided by the lattice index code be constant for every @xmath14 , i.e. , @xmath50 we say that a lattice index code provides _ uniform gain _ if it satisfies  .",
    "a necessary and sufficient condition for a lattice index code to be a uniform gain code is that @xmath42 is exponential in @xmath19 .",
    "all the index codes constructed in sections  [ sec : commutative ] and  [ sec : hurwitz ] are uniform gain lattice index codes with @xmath51  db / b / dim .",
    "[ ex : toy_example ]        consider independent messages @xmath52 and @xmath53 assuming values from , and , respectively .",
    "the three messages are encoded to a code using the function @xmath54 where the operation @xmath55 gives the unique remainder in @xmath56 when the integer @xmath57 is divided by @xmath58 . using chinese remainder theorem  @xcite , it is easy to verify that @xmath17 is the set of all possible values that the transmit symbol @xmath59 can assume . since the dimension of @xmath17 is , the rate of the @xmath34 message is @xmath60  b / dim , i.e. , @xmath61    with no side information , a receiver decodes the channel output to the nearest point in @xmath17 , with the corresponding minimum inter - codeword distance . with , the receiver knows the value of the first message .",
    "the decoder of this receiver restricts the choice of transmit symbols to the subcode @xmath62 any two points in this subcode differ by , where @xmath63 and @xmath64 are integers , not both equal to zero .",
    "since the greatest common divisor ( @xmath65 ) of @xmath66 and @xmath67 is , the minimum non - zero magnitude of is @xmath24  @xcite .",
    "hence , the minimum distance corresponding to the side information index set is .",
    "the side information rate is  b / dim , which equals .",
    "when , the set of possible transmit symbols is @xmath68 where @xmath69 and @xmath70 are known .",
    "the minimum distance of this subcode is , and the side information rate is  b / dim .",
    "similarly , for every choice of @xmath71 , we have , i.e. , the minimum distance @xmath42 is exponential in the side information rate @xmath19 .",
    "as will be shown in sections  [ sec : commutative ] and  [ sec : hurwitz ] , this property is satisfied by all the proposed lattice index codes . using @xmath72 in  , we see that the side information gain is uniform , and . in section  [ sec : upper_bound ] we show that this is the maximum side information gain achievable by any index code in which the messages are linearly encoded .",
    "[ fig : toy_example ] shows the performance of the code with , and . at the probability of error of @xmath73 ,",
    "the side informations corresponding to and provide @xmath11 gains of @xmath67  db and @xmath74  db over .",
    "this is close to the corresponding squared distance gains of @xmath75  db and @xmath76  db , respectively .",
    "+    we now give an example of a non - uniform gain index code with  db / b / dim based on a non - lattice constellation .",
    "this example also highlights the notion that , given a constellation @xmath17 , the task of designing a good index code is equivalent to designing a good labelling scheme .",
    "[ ex:16psk ] we encode @xmath77 messages with alphabets @xmath78 to the @xmath79-psk constellation @xmath17 .",
    "the encoder @xmath80 is represented as a labelling scheme in fig .",
    "[ fig:16psk_1 ] where each of the @xmath79 constellation points @xmath59 is labelled with the corresponding message tuple @xmath81 .",
    "the dimension of the code is @xmath82 , and the message rates are @xmath83    a receiver with no side information , i.e. , with , decodes the received channel vector to the nearest @xmath79-psk constellation point . the error performance at this receiver is equal to that of the @xmath79-psk signal set . assuming that the constellation points have unit energy , the corresponding minimum euclidean distance at this receiver is @xmath84 .",
    "if , the receiver has the knowledge of the value of the first message @xmath1 .",
    "for example , if @xmath85 , this receiver knows that the transmitted vector is one of the four points in the set @xmath86 ; see fig .",
    "[ fig:16psk_2 ] .",
    "the minimum euclidean distance of this subcode is @xmath87 .",
    "the minimum euclidean distance corresponding to the other three values of @xmath1 is also @xmath88 .",
    "hence , for , we have and the normalized squared distance gain is @xmath89  db / b / dim .    a receiver with decodes its channel output to one of the four subcodes of @xmath17 determined by the value of @xmath2 obtained as side information .",
    "the subcode for is shown in fig .",
    "[ fig:16psk_3 ] .",
    "all four subcodes have minimum euclidean distance .",
    "the squared distance gain for @xmath90 normalized by @xmath19 is @xmath91  db / b / dim .",
    "to conclude , this @xmath79-psk index code does not have uniform gain , and has .",
    "[ ex : set_partition ] labelling a given constellation @xmath17 by _ set partitioning _",
    "@xcite is apparently a related problem , but it does not necessarily provide good index codes . in set partitioning with binary ` labels ' @xmath92 ,",
    "the constellation @xmath17 is recursively partitioned into two smaller signal sets with larger minimum distance . for any @xmath93 , , the set of points with a given label forms one of the @xmath94 @xmath34-level partitions of @xmath17 .",
    "the minimum distance of the partition improves with increasing @xmath95 .",
    "[ fig : set_part_constellation ] shows one such labelling of @xmath79-qam , with , where the knowledge of the values of the first @xmath95 bits @xmath96 increases the minimum distance from to .",
    "however , this does not guarantee squared distance gain for every side information index set .",
    "for instance , the side information , corresponding to , does not provide any improvement in minimum distance . the performance of the code of fig .  [ fig : set_part_constellation ] for , and is shown in fig .  [",
    "fig : set_part_simulation ] .",
    "when the error rate is , the knowledge of the first two bits provides an @xmath11 gain of @xmath97  db .",
    "however , the @xmath11 gain with is only @xmath98  db at and is smaller for diminishing @xmath99 .",
    "set partition labelling is designed to provide squared distance gain when @xmath14 is of the form for . when restricted to such side information index sets ,",
    "set partitioning provides side information gain @xmath100  db / b / dim .",
    "the codes in examples  [ ex : toy_example ] and  [ ex:16psk ] allow us to achieve side information gains when @xmath14 is any subset of @xmath101 .",
    "we first review the necessary background on lattices and lattice codes , based on  @xcite  ( section  [ sec : lattices ] ) , introduce lattice index codes  ( section  [ sec : linear_modulo_encoding ] ) , and then derive an upper bound on the side information gain of such codes constructed from the densest lattices  ( section  [ sec : upper_bound ] ) .          an @xmath33-dimensional _ lattice _ in @xmath102 is a discrete additive subgroup , where the full - ranked matrix is called the _ generator matrix _ of @xmath103 . since the difference between any two lattice points is also a lattice point , the _ minimum distance _",
    "@xmath104 between any two points in @xmath103 is the euclidean length of the shortest non - zero vector of @xmath103 .",
    "closest lattice point quantizer _ is @xmath105 where , , and ties ( if any ) between competing lattice points are broken systematically .",
    "the _ fundamental voronoi region _",
    "@xmath106 is the set of all points in @xmath102 that are mapped to @xmath107 under @xmath108 .",
    "the volume of the fundamental region is related to the generator matrix @xmath109 as .",
    "the _ packing radius _ is the radius of the largest @xmath33-dimensional sphere contained in the voronoi region @xmath106 .",
    "the _ center density _ of @xmath110 is @xmath111 the center density of a lattice is invariant to scaling , i.e. , for any non - zero .",
    "if @xmath110 is scaled by , then and is the average number of points in @xmath112 per unit volume in @xmath102 , i.e. , @xmath113 is the density of the lattice points in @xmath102 when scaled to unit packing radius . for the same average transmit power constraint and minimum distance ,",
    "a constellation carved from a lattice with a higher value of @xmath113 has a larger size , and hence , a higher coding gain .",
    "the densest lattices are known for dimensions and  @xcite . for",
    ", the densest lattices are @xmath114 and @xmath115 , respectively , while the leech lattice @xmath116 is densest in @xmath117 dimensions .",
    "the lattice @xmath118 is equivalent to its dual lattice @xmath119 up to scaling and orthogonal transformation .",
    "hence , @xmath119 too has the highest density in @xmath120 dimensions .",
    "the _ modulo_-@xmath103 operation , is the difference between a vector and its closest lattice point , and it satisfies the relation @xmath121 for all .",
    "let be a sub - lattice of @xmath110 , and @xmath122 be the quotient group of the cosets of @xmath123 in @xmath110 .",
    "each coset of @xmath124 can be identified by its representative contained in @xmath125 .",
    "we will identify the group @xmath124 with the group of coset leaders , where addition is performed modulo @xmath123 .",
    "further , @xmath126 the constellation @xmath124 is called a _ ( nested ) lattice code _ , and @xmath123 is called the _ coarse lattice _ or the _ shaping lattice _  @xcite .      consider @xmath0 lattices , with a common sub - lattice , .",
    "we will use the lattice constellations as the alphabets of the @xmath0 messages at the source .",
    "[ def : lattice_index_code ] a _ lattice index code _ for @xmath0 messages consists of @xmath0 lattice constellations @xmath127 , and the injective linear encoder map @xmath128 given by @xmath129 where @xmath130 and @xmath17 is the set of all possible values of the transmit symbol @xmath131 .",
    "we require that @xmath132 be injective so that no two message tuples are mapped to the same transmit symbol .",
    "we now relate some properties of a lattice index code to those of its component lattice constellations @xmath127 .    *",
    "_ the transmit codebook @xmath17 : _ let be the lattice generated by the union of the lattices @xmath133 .",
    "it follows from   that , and hence @xmath134 . on the other hand ,",
    "every point in @xmath110 is the sum of @xmath0 lattice points , one each from .",
    "it follows from   that every point in the lattice constellation @xmath124 is the @xmath135 sum of @xmath0 points , from , respectively .",
    "hence , the transmit codebook is . *",
    "_ message rates : _ if @xmath110 is an @xmath33-dimensional lattice , the rate of the @xmath34 message is @xmath136 * _ minimum distance : _ since is carved from the lattice @xmath110 , the minimum inter - codeword distance with no side information is @xmath137 now suppose that a receiver has side information of the messages with indices in @xmath14 , say @xmath138 ( i.e. , @xmath139 , @xmath38 ) .",
    "the subcode @xmath41 decoded by the receiver is @xmath140 where we have used  .",
    "thus , @xmath41 is a lattice code carved from a translate of the lattice @xmath141 , and hence its minimum distance is @xmath142    the code in example  [ ex : toy_example ] is a lattice index code with , , , , and .",
    "the transmit codebook of a lattice index code is a commutative group under addition modulo @xmath123 , and @xmath127 are subgroups of @xmath17 .",
    "it follows from definition  [ def : lattice_index_code ] that the encoding map @xmath132 is a group isomorphism between @xmath17 and the direct product @xmath143 of the subgroups @xmath127 , i.e. , @xmath17 is a direct sum of these @xmath0 subgroups .",
    "thus , the problem of designing a good lattice index code is to construct a pair of nested lattices , and to find a decomposition of @xmath124 into @xmath0 subgroups , such that is large for every choice of . while constructions of pairs of lattices  @xcite and chains of nested lattices  @xcite",
    "are well known in the literature , we require a lattice code @xmath124 and a set of its generating subcodes such that all non - trivial direct sums @xmath144 , , of the @xmath0 subcodes have large minimum euclidean distances .    in sections  [ sec : commutative ] and  [",
    "sec : hurwitz ] , we construct index codes using lattices that possess the multiplicative structure of a _ principal ideal domain _ ( pid ) or that of a _ module _ over a pid , besides the additive structure of a commutative group .",
    "the structure of a pid ( or a module over a pid ) enables us to control the minimum euclidean distance @xmath42 , and hence the side information gain @xmath145 , of the resulting codes .",
    "when the underlying pid is commutative ( section  [ sec : commutative ] ) , we use the chinese remainder theorem to construct pairs of nested lattices and decompose the resulting code @xmath124 into a direct sum of @xmath0 lattice subcodes .",
    "we then construct lattice index codes using the hurwitz integral quaternions as the base pid ( section  [ sec : hurwitz ] ) .",
    "the chinese remainder theorem does not apply to quaternions due to the technical reason that they are non - commutative and their ideals are not two - sided .",
    "nevertheless , we design a family of quaternionic lattice index codes by identifying the essential constituents of the techniques used in section  [ sec : commutative ] and extending them to the non - commutative case .",
    "consider the side information index set @xmath146 .",
    "the minimum distance is @xmath147 and the side information rate is @xmath148 representing the volume of the fundamental region in terms of the minimum distance @xmath149 and the center density @xmath113 ( see  ) , @xmath150 if @xmath110 is the densest lattice in @xmath33 dimensions , then , and hence .",
    "thus the side information gain of @xmath17 can be upper bounded as follows @xmath151    this upper bound on the side information gain holds only for the family of lattice index codes in which the underlying lattice @xmath110 has the highest density in its dimension , such as when @xmath103 is @xmath20 , @xmath152 or @xmath119 .",
    "this upper bound is independent of the information - theoretic result of  @xcite which guarantees the existence of codes that provide an @xmath11 gain of for each b / dim of side information at the receiver",
    ". the @xmath11 gain of of  @xcite holds for capacity - approaching noisy index codes at finite values of @xmath11 in the asymptotic regime where the code dimension goes to infinity and the probability of error is arbitrarily small . on the other hand ,",
    "@xmath145 measures the squared distance gain at a finite code dimension , and approximates the @xmath11 gain due to receiver side information in the high @xmath11 regime .",
    "when @xmath110 is not the densest lattice in @xmath102 , for example when @xmath153 , it is possible to have . in such cases , from  , , and @xmath145 may exceed @xmath100  db / b / dim . note that @xmath145 is a relative gain measured with respect to the performance of with no side information .",
    "any amount of side information gain available over and above is due to the lower packing efficiency of @xmath110 when compared to @xmath154 , and hence due to the inefficiency of @xmath17 as a code in the point - to - point awgn channel .",
    "we now give an example of such a lattice index code with side information gain more than .",
    "[ ex : lattice_more_than_6 ] consider lattices @xmath155 and @xmath156 with generator matrices @xmath157 respectively , and the coarse lattice .",
    "the above lattices have been carefully chosen so that the densities of @xmath155 and @xmath156 are greater than that of their sum lattice @xmath158 . in order to prove that this choice of @xmath159 and @xmath123 indeed defines a valid lattice index code ,",
    "we first show that @xmath123 is a sub - lattice of @xmath155 and @xmath156 , we then identify the transmit lattice @xmath110 and the codebook @xmath17 , and then show that the encoding map @xmath132 is injective . finally , we compute the minimum distances of @xmath159 and @xmath110 , and the side information gain @xmath145 .",
    "the following identities show that the basis vectors @xmath160 and @xmath161 of can be expressed as integer linear combinations of the columns of @xmath162 , and hence , @xmath163 : @xmath164 similarly , the proof for @xmath165 follows from the observation @xmath166    in order to identify the lattice , we first note that , and hence , .",
    "the following expressions show that the basis vectors @xmath167 and @xmath168 of @xmath169 are integer linear combinations of the columns of @xmath162 and @xmath170 : @xmath171 we conclude that @xmath172 , and therefore , @xmath173 .",
    "the transmit codebook @xmath174 is @xmath175 .",
    "thus , the encoding map @xmath132 has domain @xmath176 and range @xmath17 .",
    "the cardinality of the domain is latexmath:[\\ ] ] which consists of @xmath434 copies of the matrix @xmath457 , and where the function @xmath458 is given in  .",
    "the generator matrix of @xmath459 is the product of   and the generator matrix of @xmath460 . since @xmath457 is orthogonal with determinant @xmath461 , the matrix   is orthogonal with determinant @xmath462 .",
    "hence , the volume and the squared minimum distance of the lattice @xmath459 are @xmath463      the following lemma enables us to extend the construction of section  [ sec : d4 ] to all lattices @xmath217 that are two - sided @xmath23-modules .",
    "[ lem : quat_enabling_lemma ] if @xmath464 are such that @xmath465 , then @xmath466 .",
    "then for some , and hence , . since @xmath217 is a right-@xmath23 module , , and hence .",
    "let @xmath387 and @xmath446 be as defined in section  [ sec : d4 ] .",
    "we set @xmath467 we construct our quaternionic lattice index code by using @xmath468 since @xmath449 , using lemma  [ lem : quat_enabling_lemma ] , we have @xmath469 , and hence @xmath470 , for all @xmath471 .",
    "the cardinality @xmath472 of the @xmath34 message is @xmath473 and the rate is @xmath474 note that the rates are identical to those achieved using the construction on @xmath119 .",
    "we now show that this lattice index code provides uniform side information gain of .",
    "the proof is similar to the proofs of lemmas  [ lem : arbit_construction ] and  [ lem : ds_rs ] in section  [ sec : commutative ] .",
    "[ lem : quat_lattices_injective ] with @xmath133 and @xmath123 defined as above ,    1 .",
    "the transmit codebook @xmath174 , and the encoding map @xmath132 is injective ; and 2 .",
    "for every side information index set @xmath14 , @xmath475 .    see appendix  [ app : lem : quat_lattices_injective ] .    from lemma  [ lem : quat_lattices_injective ]",
    ", we conclude that the side information gain of the quaternionic lattice index code @xmath124 is .",
    "lattice index codes with large side information gains are suitable when all the messages are demanded by every receiver . for these codes , the encoding operation is oblivious to both the number of receivers and the side information configuration at each receiver ( see definition  [ def : lattice_index_code ] ) . when the message demands are more general ( such as private message requests ) , the number of receivers , and the @xmath11 and the side information available at each receiver may need to be considered during code design  @xcite .",
    "capacity - achieving random coding schemes have been proposed for a class of @xmath267-receiver private message gaussian broadcast channels in  @xcite and  @xcite .",
    "the coding schemes of  @xcite make use of channel codes that are efficient in converting receiver side information into additional coding gains , similar to lattice index codes , as component subcodes in superposition coding . in this section , we consider an instance of a broadcast channel where each message is demanded at a unique receiver . inspired by the ideas in  @xcite , we show that lattice index codes with large side information gains can be useful in constructing coding schemes that are matched to this broadcast channel",
    ".    we will now briefly review some lattice parameters from  @xcite that are relevant to the analysis of error performance .",
    "the _ kissing number _ @xmath476 of a lattice @xmath110 is the number of shortest non - zero vectors in @xmath110 , i.e. , the number of lattice points with euclidean length equal to @xmath477 .",
    "every point in @xmath110 has exactly @xmath476 nearest neighbours in the lattice .",
    "the _ covering radius _ of a lattice @xmath110 is given by @xmath478 where @xmath106 is the fundamental voronoi region of @xmath110 , and equals the radius of the smallest sphere centered around origin that contains the fundamental voronoi region as a subset .",
    "we consider a broadcast channel with three receivers @xmath479 , , each of which experiences additive noise with the corresponding variance @xmath480 , see fig .",
    "[ fig:3_receiver ] .",
    "we assume that , i.e. , the first receiver has the strongest channel .",
    "also assume that there are messages at the transmitter , , .",
    "let denote the index sets of the messages demanded by , and the side information available at @xmath479 .",
    "we consider the private message broadcast scenario @xmath481 , @xmath482 , @xmath483 , with side information index sets @xmath484 , @xmath485 , @xmath486 .",
    "the objective is to efficiently encode the messages such that the three receivers @xmath487 can tolerate increasingly more noise , i.e. , the messages @xmath488 experience increasing coding gains , in that order . using a lattice index code",
    ", we will exploit the side information @xmath489 to enhance the coding gain of @xmath490 over that of @xmath491 . since @xmath486",
    ", we will combine this lattice index code with superposition coding to enhance the coding gain at @xmath492 .",
    "the transmitter uses nested lattices and , to individually map the information symbols @xmath488 to the points @xmath493 in the @xmath33-dimensional lattice constellations @xmath494 , @xmath495 and @xmath496 , respectively .",
    "finally , the transmit vector is generated as @xmath497 where @xmath498 .",
    "we assume that the map @xmath499 generates a lattice index code @xmath500 , where denotes the sum lattice . denoting @xmath501 by @xmath502",
    ", we observe that the transmit codebook @xmath503 is a superposition code , where the codewords of @xmath504 form the ` cloud particles ' and those of @xmath502 are the ` cloud centers '  @xcite .      the weakest receiver @xmath492 observes @xmath505 , where @xmath506 is a random gaussian vector with variance @xmath507 per dimension .",
    "the optimal decoder chooses @xmath508 that maximizes the likelihood of observing @xmath509 . since this receiver is complex to analyze , we consider the sub - optimal decoder that treats the ` interference ' @xmath510 as noise , and decodes @xmath509 to the nearest point in @xmath501 .",
    "we now derive an upper bound on the pairwise error probability of this receiver considering two competing codewords @xmath511 . assuming that @xmath53 was encoded as , the decoder at @xmath492 chooses @xmath512 over @xmath513 if @xmath514 , i.e. , if @xmath515 where is the vector that jointly encodes @xmath52 .",
    "squaring both sides of the inequality and using usual simplifications , we arrive at @xmath516 to upper bound the error probability , we obtain a lower bound on the value of the right - hand - side term above . utilizing the cauchy - schwarz inequality , we obtain @xmath517 observe that , and hence , . from the definition of the covering radius",
    ", we have . since , we have .",
    "this yields the following lower bound @xmath518 hence , @xmath492 favours @xmath519 _ only if _ @xmath506 is such that @xmath520 normalizing both sides by @xmath521 , we immediately obtain the following upper bound on pairwise error probability , @xmath522 where @xmath523 is the gaussian tail function and @xmath507 is the variance of the vector @xmath506 along each dimension .",
    "an approximate bound on the average error probability can be obtained by considering all the competing codewords which are at the shortest euclidean distance from the transmitted codeword  @xcite , i.e. , all the nearest neighbours in the coding lattice .",
    "using union bound , we arrive at the following approximate bound  @xcite for error rate at @xmath492 @xmath524    to analyze the performance at @xmath491 and @xmath490 , we again consider sub - optimal decoders for which upper bounds on error probabilities can be easily obtained .",
    "the decoders at @xmath491 and @xmath490 experience a higher @xmath11 than @xmath492 .",
    "both these receivers first decode @xmath53 using the same procedure as @xmath492 , and subtract its contribution in the received vector . assuming that the estimated codeword @xmath525 is correct , the received vector at @xmath479 , @xmath526 , after cancelling the interference @xmath527 is @xmath528 where @xmath529 is a gaussian noise vector with variance @xmath480 per dimension . since @xmath491 has no side information , it jointly decodes @xmath1 and @xmath2 , i.e. , it chooses the codeword @xmath530 that is closest to @xmath531 . using conventional union bounding arguments , the overall error probability at this receiver , considering both the steps of the decoding procedure ,",
    "can be upper bounded as @xmath532 on the other hand , @xmath490 has prior knowledge of the exact value @xmath533 of @xmath189 and its decoder can exploit the fact that @xmath534 is a lattice index code .",
    "the effective codebook seen by this receiver after cancelling the interference @xmath527 and expurgating all codewords corresponding to @xmath535 is a lattice code carved from a translate of @xmath156 .",
    "hence , the error rate at this receiver satisfies @xmath536    at high values of @xmath11 , the arguments of the @xmath537-function in  ,   and   dictate the error performance at the three receivers .",
    "since @xmath492 experiences the most noise , we require @xmath538 to be larger than @xmath539 and @xmath540 . in this case , the high @xmath11 error rates at the three receivers @xmath487 are determined by @xmath540 , @xmath539 and @xmath541 , respectively .",
    "hence , we arrive at the following guidelines for designing a good channel code :    1 .",
    "@xmath534 must be a good lattice index code in order to achieve a good error performance at @xmath491 and @xmath490",
    ". a large value of @xmath542 will be efficient in converting the side information into additional coding gains , which will be useful in combating the higher noise power at @xmath490 .",
    "the covering radius of @xmath543 must be small , so as to reduce the interference from @xmath510 at @xmath492 .",
    "3 .   and finally , @xmath544 must be large in order to maximize the coding gain at @xmath492 .",
    "we will consider a coding scheme for the @xmath267-user private message broadcast channel that utilizes the @xmath299-qam constellation of example  [ ex:25qam ] as the lattice index code @xmath534 .",
    "this constellation has dimension and encodes two messages with @xmath263-ary alphabets . from example",
    "[ ex:25qam ] , we have and . to encode the third message , we will use , and the lattice generated by @xmath545 as @xmath546 .",
    "it is straightforward to show that , , and that all three messages are encoded at the same rate . at high @xmath11 , the error performance at @xmath490 is better than @xmath491 by @xmath547 and the performance at @xmath492 is better than @xmath491 by @xmath548 hence , this constellation allows @xmath490 and @xmath492 to tolerate @xmath549  db and @xmath550  db of additional noise compared to @xmath491 , respectively . while the additional gain at @xmath492 is due to superposition coding , the performance improvement at @xmath490 is due to the side information gain of the component lattice index code .",
    "we have proposed lattice index codes for the gaussian broadcast channel where every receiver demands all the messages from the transmitter .",
    "we have introduced the notion of side information gain as a code design metric , and constructed lattice index codes from lattices @xmath110 over the pids @xmath20 , @xmath21 $ ] , @xmath22 $ ] and @xmath23 .",
    "if @xmath110 has the highest lattice density in its dimension , the proposed codes achieve the maximum side information gain among all lattice index codes constructed from @xmath110 .",
    "an interesting property of these lattice index codes is that the side information gain is uniform .",
    "the key ingredients that we used in the construction of our lattice index codes are the chinese remainder theorem , the properties of principal ideals for the base pids , and the mapping of ideals of the pid modules to lattice constellations .",
    "in particular , the specific choices of the pids enable us to associate the norms of principal ideals with the minimum euclidean distance of the corresponding component lattices , while the chinese remainder theorem guarantees the unique decodability property for any amount of side information at the receivers .",
    "it is possible to construct lattice index codes using the @xmath551-dimensional non - commutative non - associative pid of octavian integers @xmath552 .",
    "since @xmath552 is geometrically equivalent to the gosset lattice @xmath115 , the resulting lattice index codes use the octonion version of @xmath115 as the base lattice @xmath217",
    ". however , the only ideals in @xmath552 are the trivial ones , viz . the ideals @xmath553 , where  @xcite .",
    "hence the extension of our construction from the hurwitz integers @xmath23 to the octavian integers @xmath552 coincides with the codes constructed in section  [ sec : commutative ] with @xmath554 and @xmath349 .",
    "the lattice index codes constructed here can be used as modulation schemes together with strong outer codes . consider @xmath0 information streams , encoded independently using @xmath0 outer codes over the alphabets @xmath555 , respectively .",
    "the coded information streams are multiplexed using the lattice index code @xmath17 and transmitted .",
    "if the minimum hamming distance of the outer codes is @xmath556 , then the minimum squared euclidean distance at a receiver corresponding to @xmath14 is at least .",
    "while the outer code improves error resilience , the inner lattice index code collects the gains from side information .",
    "this approach converts the index coding problem into coding for a multiple - access channel where the @xmath0 information streams are viewed as @xmath0 independent transmitters . since coding for multiple - access channels",
    "is well studied in the literature , this knowledge may be leveraged to construct good noisy index codes of manageable encoding and decoding complexity , such as by using iterative multiuser demodulators / decoders . in",
    "@xcite we have shown that this concatenated architecture can perform close to the capacity of the gaussian broadcast channel with receiver side information .",
    "in order to prove part  _ ( [ lem : part1:arbit_construction ] ) _ , we need to show that @xmath132 is injective and @xmath557 .    from lemma  [ lem : gcd_m_s ] , for every choice of @xmath14 .",
    "hence , there exists a tuple of elements in @xmath209 such that @xmath558 .",
    "it follows that , for every , we have @xmath559 hence . using this result along with the additive property of @xmath232",
    ", we obtain @xmath560 considering cosets modulo @xmath123 , the above relation implies @xmath561    let @xmath562 be the restriction of the encoding map   to the message symbols with indices in @xmath563 , i.e. , @xmath564 note that @xmath565 is the image of the map @xmath428 . from",
    ", we observe that @xmath566 is a subset of this image .",
    "the cardinality @xmath567 of this subset of the image of @xmath562 equals the cardinality @xmath568 of the domain of @xmath562 .",
    "hence , we conclude that @xmath562 is an injective map , and the subset @xmath566 equals the entire image @xmath144 .",
    "this implies that @xmath569 , proving part  _ ( [ lem : part3:arbit_construction ] ) _ of this lemma .",
    "choosing , we observe that is injective , and . hence , the transmit codebook is .",
    "this proves part  _ ( [ lem : part1:arbit_construction])_.      it is enough to show that , i.e. , , or equivalently , @xmath570 let and @xmath571 for .",
    "then , @xmath572 we will complete the proof by deriving @xmath573 , and then showing that @xmath373 is a unit in @xmath23 .    for each , we have @xmath574 where the last equality follows from the assumption that @xmath575 for some @xmath576 . since @xmath577",
    "we obtain @xmath578 .",
    "since @xmath579 is an odd prime , we have @xmath580 on the other hand , @xmath581 is a divisor of both @xmath326 and @xmath582 , and hence is a divisor of @xmath583 . hence , @xmath584 from   and  , . from  , @xmath585 in @xmath20 .",
    "since @xmath586 are pairwise relatively prime in @xmath20 , @xmath587 hence , and @xmath373 is a unit in @xmath23 .",
    "up to unit multiplication in @xmath23 , we have @xmath588        it is enough to show that , or equivalently , @xmath589 . since @xmath590 , for all @xmath95 , it is clear that @xmath591 from  , we have @xmath592 .",
    "hence , there exist @xmath593 such that @xmath594 . if @xmath595 , then @xmath596 since @xmath597 , we have @xmath598 . hence @xmath599 the injective nature of the map @xmath132 follows from observing that its domain @xmath143 and image @xmath600 have the same cardinality @xmath601 .",
    "let @xmath602 . we first show that @xmath603 , or equivalently @xmath604 .",
    "there exists a tuple @xmath605 of hurwitz integers such that @xmath606 .",
    "similar to the proof of part  _",
    "( i ) _ of this lemma , by considering the term @xmath607 for each @xmath595 , we conclude that @xmath608 the above relation implies that @xmath609 is a subset of the image of @xmath562 , which is the restriction of the function @xmath132 to messages with indices in @xmath563 . as in the proof of lemma  [ lem : arbit_construction ] , to prove @xmath610 , it is enough to show that @xmath611 using @xmath612 ( from  ) , and the above equation , we have @xmath613 hence , we conclude that @xmath610 .    using @xmath614",
    ", we obtain the minimum squared distance with @xmath14 as follows , @xmath615 this shows that @xmath616 .",
    "we show that every odd rational prime @xmath384 can be expressed as the sum of the squares of four rational integers @xmath617 , where the first integer @xmath618 .",
    "then , @xmath619 is a hurwitz integer with norm @xmath384 and real part a power of @xmath24 .",
    "the proof follows from the following result from number theory known as the three - square theorem .",
    "if @xmath384 is a positive odd rational integer , we have @xmath622 . for each of these four possible values of @xmath623",
    ", we show that at least one of @xmath624 or @xmath625 is not of the form @xmath626 .",
    "it then follows that , either @xmath624 or @xmath625 is a sum of three squares , and consequently , @xmath384 equals either the sum of @xmath627 and three squares , or the sum of @xmath628 and three squares .",
    "if , then @xmath629 assume @xmath630 for some @xmath621 . since , @xmath631 is odd , which implies @xmath632 , and hence , @xmath633 .",
    "this leads to a contradiction since @xmath634 and @xmath635 .",
    "the proofs for the cases @xmath636 are similar .    if @xmath637 , we have @xmath638 .",
    "suppose @xmath639 for some choice of @xmath640 .",
    "since @xmath641 , @xmath120 is not a divisor of @xmath624 , and hence , @xmath632 .",
    "contradiction follows from observing that @xmath642 .",
    "y.  birk and t.  kol , `` informed - source coding - on - demand ( iscod ) over broadcast channels , '' in _ proc .",
    "17th annu .",
    "joint conf .",
    "ieee computer and communications societies ( infocom ) _ , vol .",
    "1998 , pp .",
    "12571264 .",
    "s.  el  rouayheb , a.  sprintson , and c.  georghiades , `` on the index coding problem and its relation to network coding and matroid theory , '' _ ieee trans .",
    "inf . theory _ ,",
    "56 , no .  7 , pp . 31873195 , jul .",
    "2010 .",
    "j.  sima and w.  chen , `` joint network and gelfand - pinsker coding for 3-receiver gaussian broadcast channels with receiver message side information , '' in _ proc .",
    "information theory ( isit ) _",
    ", jun . 2014 , pp . 8185 .",
    "b.  asadi , l.  ong , and s.  johnson , `` the capacity of three - receiver awgn broadcast channels with receiver message side information , '' in _ proc .",
    "information theory ( isit ) _ , jun .",
    "2014 , pp . 28992903 .",
    "y.  ma , z.  lin , h.  chen , and b.  vucetic , `` multiple interpretations for multi - source multi - destination wireless relay network coded systems , '' in _ proc .",
    "ieee 23rd int .",
    "personal indoor and mobile radio communications ( pimrc ) _ , sep .",
    "2012 , pp . 22532258 .",
    "huang , k.  r. narayanan , and n.  e. tunali , `` multistage compute - and - forward with multilevel lattice codes based on product constructions , '' _ arxiv preprint _",
    "[ online ] .",
    "available : http://arxiv.org/abs/1401.2228"
  ],
  "abstract_text": [
    "<S> the index coding problem involves a sender with @xmath0 messages to be transmitted across a broadcast channel , and a set of receivers each of which demands a subset of the @xmath0 messages while having prior knowledge of a different subset as side information . </S>",
    "<S> we consider the specific case of noisy index coding where the broadcast channel is gaussian and every receiver demands all the messages from the source . instances of this communication problem arise in wireless relay networks , sensor networks , and retransmissions in broadcast channels . </S>",
    "<S> we construct _ lattice index codes _ for this channel by encoding the @xmath0 messages individually using @xmath0 modulo lattice constellations and transmitting their sum modulo a coarse lattice . </S>",
    "<S> we introduce a design metric called _ side information gain _ that measures the advantage of a code in utilizing the side information at the receivers , and hence , its goodness as an index code . </S>",
    "<S> based on the chinese remainder theorem , we then construct lattice index codes with large side information gains using lattices over the following principal ideal domains : rational integers , gaussian integers , eisenstein integers , and the hurwitz quaternions . among all lattice index codes </S>",
    "<S> constructed using any densest lattice of a given dimension , our codes achieve the maximum side information gain . finally , </S>",
    "<S> using an example , we illustrate how the proposed lattice index codes can benefit gaussian broadcast channels with more general message demands .    </S>",
    "<S> chinese remainder theorem , gaussian broadcast channel , index coding , lattice codes , principal ideal domain , side information . </S>"
  ]
}