{
  "article_text": [
    "fake ( dummy ) information can protect privacy and security in many different systems such as web search @xcite , anonymous communications @xcite , authentication systems @xcite , and statistical analysis @xcite . in all these scenarios , the main challenge and",
    "the open problem is to generate context - dependent fake information that resembles genuine user - produced data and also provides an acceptable level of utility while enhancing privacy of users .    in this paper , we propose a systematic approach for preserving privacy of _ location _ data using fake traces .",
    "we focus on two practical scenarios : sharing location with location - based services , and publishing location datasets e.g. , for research . in location - based systems",
    ", users hide their true location among fake location traces while connecting to a server to obtain contextual information about their whereabouts .",
    "this protects them against the location inference attacks .",
    "the benefit of the fake injection approach with respect to other obfuscation techniques , such as location perturbation @xcite , is that it does not reduce the users experienced service quality .",
    "users only incur the overhead of filtering out the received information about fake locations . in publishing privacy - preserving location datasets , the purpose is to preserve the general statistics about human mobility .",
    "there is a utility loss associated with fake traces as they might not fully preserve all the characteristics of real traces .",
    "the challenge is to generate synthetic traces that semantically resemble the real traces yet do not leak information about the exact geographic locations visited by any particular individual .",
    "this gives rise to a tradeoff between utility and privacy that is inherent to privacy - preserving systems .",
    "there has been some preliminary work on using fake location queries to protect users location privacy @xcite . however , they are based on very simple heuristics such as i.i.d . location sampling , sampling locations from a random walk on a grid with uniform probability , and using road trip algorithms to generate driving traces between two random locations . in this paper",
    ", we quantitatively show that these methods fail to protect location privacy against inference attacks .",
    "besides , what these methods are missing are ( i ) a _ metric _ that captures how realistic a synthetic location trace is with respect to human mobility , so it can not be easily detected by attacker , ( ii ) a _ generative model _ that produces samples of synthetic yet realistic traces according to such a metric , while preserving utility and ensuring that the synthetic traces do not themselves leak information about any individual . in this paper , we present the first formal methodology to solve these problems and to generate fake yet semantically real location traces for protecting location privacy .",
    "we also enforce , and quantitatively measure , privacy against location privacy attacks .",
    "our scheme is based on the fact that mobility patterns of different individuals share some semantic features , regardless of which geographic locations they visit .",
    "these common features of human mobility stem from their similar lifestyles .",
    "the mobility patterns share a similar structure that reflects the general behavior of a population ( even at a high level @xcite ) .",
    "we model the mobility of each individual in two dimensions : _ geographic _ and _ semantic_. the geographic features are mostly specific to each individual ( hence are sensitive ) , whereas the semantic features are mostly generic and representative of human mobility behavior ( hence are useful ) .",
    "we extract the common semantic features of mobility patterns and use them to generate realistic synthetic traces , without leaking the geographic features of any individual s locations .",
    "consequently , we define two metrics to quantify the similarity between human mobility models : the geographic similarity metric between two individuals captures how correctly we can predict locations of one knowing the mobility model of the other one .",
    "this metric helps us to capture the spatiotemporal information leakage of a fake trace about a real trace .",
    "the semantic similarity metric reflects how well two traces match in terms of their semantic features .",
    "we assume that we have a dataset of real traces .",
    "we develop an algorithm that automatically learns the semantic correlation between locations and transitions between locations . to generate semantically realistic fake traces ,",
    "we transform a ( real ) seed trace into the semantic domain and probabilistically sample ( fake ) location traces that are consistent with it .",
    "thus , a generated sample resembles a typical sequence of locations that could have been visited by some real individual .",
    "we then design a _ rejection sampling _ assertion to ensure that a fake trace does not leak information about the locations in its seed trace , i.e. , we reject those who do not meet the privacy requirements .",
    "thereby , we protect privacy of seed traces against the following threats : _ inference _ attacks ( to learn which locations the seed contributors have visited ) , and _",
    "membership inclusion _ attack ( to learn if a particular individual with certain semantic habits has been in the seed dataset ) .",
    "if a fake trace s geographic similarity or its intersection with its real seed trace exceeds a given threshold , we reject it and sample a new trace . we also ensure that the semantic similarity between fake and seed traces can not be used against anonymity of seed traces . to this end , we reject the fake trace if there is no @xmath0 alternative real traces that could have been the seed for generating the fake ( i.e. , the differential semantic similarity with the fake trace is below a threshold ) .",
    "this additionally guarantees a _",
    "plausible deniability _ for each seed trace .",
    "the resulting pool of fake traces can later be drawn upon for use by e.g. , users smart - phones .",
    "the fake traces generated from the seed database can be used to protect location privacy of any user ( not the contributed of the seed database ) .",
    "the privacy tests guarantee that we preserve privacy of seed traces . additionally , we show that the generated fakes can significantly protect privacy of lbs users against inference attacks .    _ our contributions _ : in summary , the novelty of this work is twofold .",
    "( 1 ) we introduce the notion of semantic similarity for mobility patterns , we propose both a metric for it , and an algorithm to quantify the semantic similarity between location traces .",
    "we also automatically learn the semantic relation between locations .",
    "( 2 ) we propose a generative model for fake location traces that are semantically similar to real traces .",
    "we also guarantee plausible deniability to individuals whose real traces are used as seed in our algorithm .",
    "our software tool , given a set of real location traces , generates fake traces based on our theoretical framework .",
    "we run our algorithms on a real - world dataset collected by nokia @xcite .",
    "we show the effectiveness of our fake traces in protecting privacy of users in two main scenarios : location - based services and published location datasets , while preserving utility .",
    "in this section , we present a sketch of , and describe the main intuition behind , our scheme for generating fake traces .",
    "we assume that time and space are discrete , so a location trace is represented as a sequence of visited locations over time . in our scheme , we generate a fake trace through a multiple step process .",
    "figure  [ fig : sketch ] illustrates the details .",
    "the first step is to compute the semantic similarity between the set of locations in an area .",
    "we learn these similarity values automatically from a _ dataset _ of real location traces . for each trace",
    "( i.e. , the sequence of locations visited by a single individual ) in the dataset , we first compute a probabilistic _ mobility model _ that represents the visiting probability to each location and transition probability among the locations ( see section  [ sec : similarity : mobility ] ) . the mobility model encompasses the spatiotemporal behavior of each individual with respect to different locations .",
    "time , duration , and probability ( frequency ) of visiting a location , as well as the probable comings from and goings to locations are all computable from the mobility model .",
    "so , it implicitly reflects the types of activities that an individual might carry out in each location ( and over a sequence of locations ) .",
    "we analyze and discover the semantic relation between different locations in a consistent manner by considering all locations together . to this end",
    ", we propose a _",
    "semantic similarity metric _",
    "( see section  [ sec : similarity : semantic ] ) .",
    "intuitively , we assign a higher similarity value to the pair of locations at which different individuals have similar spatiotemporal activities .",
    "thus , our metric tries to find the optimal way to map the visited locations in a pair of traces such that the mapping maximizes the statistical similarity between their mobility models .",
    "the semantic similarity metric is therefore the statistical similarity between mobility models under the optimal mapping between locations .",
    "this means that if we were to translate the locations of this pair according to the discovered best mapping , they would follow the same mobility model when their semantic similarity is high .",
    "for example , consider alice and bob spending all day at their respective work locations @xmath1 and @xmath2 , and all night at their respective home locations @xmath3 and @xmath4 .",
    "obviously , their mobility models are semantically very similar , although it might be the case that @xmath5 and @xmath6 . in this example",
    ", the best semantic mapping between locations will be @xmath7 and @xmath8 .    for each pair of mobility models for traces in our dataset ,",
    "we compute their semantic similarity as well as the best semantic mapping between their locations .",
    "we then aggregate all the location matchings across all trace pairs , with weights based on the semantic similarity between mobility models , and construct a _ location semantic graph _",
    ", where the nodes are locations and the weight of the edges is the average semantic similarity between the locations over the dataset .",
    "the location semantic graph enables us to find what locations have similar meanings for different people , so they have similar activities in those places .",
    "the locations that have higher semantic similarity can be grouped together to represent one _ location semantic class_. to this end , we run a clustering algorithm on the location semantic graph to partition locations into distinct classes .",
    "locations that fall into the same class are visited in the same way by different people regardless of their geographic positions .",
    "thus , we can consider them as being semantically equivalent .",
    "so , using the notations of our previous example , @xmath1 and @xmath2 should belong to the same cluster that can represent `` workplace '' locations , and @xmath3 and @xmath4 should be grouped into another cluster representing residential or `` home '' locations .",
    "we use the location semantic classes as the basis to generate fake traces .",
    "in addition to being semantically realistic , the fake traces must be geographically consistent with the general mobility of individuals in the considered area .",
    "for example , the speed of moving in some locations differs depending on the time , or the probabilities of taking different paths is different . to capture these patterns",
    ", we compute an _ aggregate mobility _ model from the traces in our dataset . we can , for example , compute this by averaging the mobility models that we constructed on the traces .",
    "the goal is to generate fake traces that are semantically similar to real traces . in order to construct a fake trace ,",
    "our algorithm starts with a _ seed _ trace and converts it to a probabilistically generated semantically similar synthetic trace which is consistent with the aggregate mobility model .",
    "we pick the seed trace at random from the trace dataset .",
    "the seed trace , similar to other location traces in the database , is composed of a sequence of geographic locations . in our algorithm , we first _",
    "transform _ the geographic seed trace into the semantic domain , then we use the transformed semantic trace to _",
    "sample _ from the state space of all geographic traces that could have been transformed to the same semantic trace .",
    "the transformation and sampling procedures , which are at the heart of this step , are done as follows .    for the seed trace _ transformation _ , we replace the geographic locations in the seed with the locations that are in the same semantic class .",
    "this seed _ semantic trace _ is a sequence of location sets . for the fake trace _ sampling _ ,",
    "we address the following problem .",
    "we want to construct a trace that follows the aggregate mobility model under the constraint that its locations over time are subset of locations of the seed semantic trace .",
    "hence , both the fake trace and the seed trace can be transformed to the same semantic trace .",
    "we add some randomness to the locations in the semantic trace to allow higher number of possible fake traces .",
    "many algorithms can be used to sample the fake trace that satisfies our constraints .",
    "we make use of dynamic programming algorithms that construct the traces efficiently ( section  [ sec : sampling ] ) .",
    "we can repeatedly generate fake traces from each seed trace in the dataset , each of which having a probability according to the aggregate mobility model . after generating each fake trace , however , we need to make sure that it is not geographically similar to the seed trace .",
    "this is because we do not want to leak information about the real seed trace .",
    "to this end , we add a test to compute the _ geographic similarity _",
    "( see section  [ sec : similarity : geographic ] ) between the seed trace and the fake trace to _ reject _ the sample traces that are more similar than a threshold to the seed trace .",
    "thus , we make sure that the semantically similar synthetic traces are indeed geographically dissimilar to the traces in our dataset , hence not leaking information about visited locations in the real traces .",
    ".table of notations [ cols=\"^ , < \" , ]",
    "in this section , we present a probabilistic model for mobility , and propose two metrics to analyze the geographic and semantic similarity between two mobility models . table  [ tab : notation ] presents the list of notations that we use in this paper .",
    "we model the user mobility as a time - dependent first - order markov chain on the set of regions ( locations ) . as users have different behavior and mobility patterns during different periods of time , we assume that time is partitioned into time periods , e.g. , morning - afternoon - evening - night .",
    "so , the mobility profile @xmath9 of a given user @xmath10 is a _ transition _ probability matrix of the markov chain associated with the user s mobility ( from a region to another ) , and the user s _ visiting _ probability distribution over the regions , respectively .",
    "note that these probabilities are dependent on each other , and together they constitute the joint probability of two regions that are subsequently visited by the user .",
    "the entry @xmath11 of @xmath12 is the probability that user @xmath10 will move to region  @xmath13 in the next time instant ( which will be in time period  @xmath14 ) , given that she is now ( in time period  @xmath15 ) in region  @xmath16 .",
    "the entry @xmath17 is the probability that user @xmath10 is in region @xmath16 in time period @xmath15 .",
    "let the random variable @xmath18 represent the actual location of user @xmath10 at time @xmath19 , and @xmath20 be the time period associated with @xmath18 .",
    "so , the mobility profile of a given user @xmath10 consists of the following probabilities : @xmath21    this markovian model can predict the location of an individual to a great extent , as it takes both location and time aspect into account .",
    "it can become even more precise , by increasing its order , or by enriching its state .",
    "we can , for example , include multiple granularities of locations , and model the mobility of a user on the set of e.g. , pair of ( location , neighborhood ) in addition to the time dimension .",
    "our framework can incorporate all these new dimensions similar to the way we model the time periods .",
    "to learn the probabilities of the mobility profile , from location traces , we can use maximum likelihood estimation ( if the traces are complete ) or make use of algorithms such as gibbs sampling ( if the traces have missing locations or are noisy ) @xcite .",
    "we propose two metrics to compare the mobility of two users and compute their similarities : _ geographic _ and _ semantic _ similarity . in this subsection",
    ", we describe the intuition behind these metrics , and in the following subsections , we formally define and provide the algorithms to compute them .",
    "the _ geographic similarity _",
    "metric captures the correlation between location traces that are generated by two mobility profiles .",
    "it reflects if two users visit similar locations over time with similar probabilities and if they move between those locations also with similar probabilities . using this metric , for example , two individuals who live in the same region a and",
    "their workplace is in the same region b potentially have very similar mobilities , as they spend their work hours in b and most of their free time in a.    there are very few people whose mobility patterns have a high geographic similarity with each other .",
    "however , if we ignore the exact locations that are visited by different people , we observe that they share similar patterns for visiting locations with similar semantics ( locations therein they have similar activities ) .",
    "for example , most people visit and stay at a single location from each evening until its subsequent morning .",
    "these locations differ from one individual to another , but have the same semantic for them : home .",
    "one can imagine the semantic dimension of locations as a coloring on the locations in a map . instead of computing the correlation between location traces at the geographic level",
    ", we can also compute such correlation at the semantic level ( by reducing the set of locations to the set of colors and computing the similarity of color traces ) .",
    "this is the intuition behind our _ semantic similarity _ metric . in this case , if the pair of locations that two individuals visit over time have the same semantic , their mobility models are also semantically similar ( even if they are in two different cities , i.e. , have no geographic similarity ) . hence , in this example , if we transform trace a by replacing its locations with their corresponding semantically similar locations in trace b , the transformed trace becomes geographically similar to b. so , two traces are semantically similar if their locations can be mapped to each other that accordingly one trace can be transformed to a geographically similar trace to the other .",
    "we define this similarity metric based on the earth mover s distance ( emd ) for probability distributions . the emd is widely used in a range of applications including image processing  @xcite .",
    "the emd can be understood by thinking of the two distributions as piles of dirt . in this interpretation",
    ", the emd represents the minimum amount of work needed to turn one pile of dirt ( i.e. , one distribution ) into the other ; the cost of moving dirt being proportional to both the amount of dirt and the distance to the destination .",
    "the special case of emd for probability distributions has been shown to be equivalent to the mallows distance  @xcite .",
    "let @xmath22 and @xmath23 be discrete random variables with probability distributions @xmath24 and @xmath25 , such that @xmath26 and @xmath27 , respectively , for @xmath28 .",
    "we also have @xmath29 and @xmath30 .",
    "( from  @xcite ) let @xmath31 be an arbitrary distance function between @xmath22 and @xmath23 .",
    "the _ mallows distance _",
    "@xmath32 is defined as the minimum expected distance between @xmath22 and @xmath23 with respect to @xmath31 and to any joint distribution function @xmath33 for @xmath34 such that @xmath24 and @xmath25 are the marginal distributions of @xmath22 and @xmath23 , respectively . @xmath35 where the expectation , minimized under @xmath33 , is @xmath36    in addition to the constraints @xmath37 and @xmath38 , for all @xmath39 , @xmath40 , the joint probability distribution function @xmath33 must also satisfy @xmath41 and @xmath42 .",
    "note that , for given @xmath24 and @xmath25 , the minimum @xmath33 is easily computed by expressing the optimization problem as a linear program .    using the previous definition , we define the geographic similarity metric based on the mallows distance .",
    "let @xmath31 be an arbitrary distance function .",
    "the _ dissimilarity _ between two mobility profiles @xmath9 and @xmath43 ( belonging to individuals @xmath10 and @xmath44 ) , is defined as the expected mallows distance of the next random locations @xmath45 and @xmath46 according to the mobility profiles of @xmath10 and @xmath44 , respectively .",
    "more formally , it is @xmath47 where @xmath48 and @xmath49 denote the conditional probability distributions of the next location , given the current location and the current and next time periods .",
    "the mallows function is computed over random variables @xmath45 and @xmath46 , and the expectation is computed over random variable @xmath50 and time periods @xmath15 and @xmath14 .",
    "we define the _ geographic similarity _ between mobility patterns of @xmath10 and @xmath44 as @xmath51 [ def : ds1 ]    we compute the geographic _ dissimilarity _ using the law of total expectation .",
    "this also clarifies its meaning by showing more directly the role of the random variables .",
    "@xmath52    this is simply the average , for each time and location , of the emd between the distributions of the next location of @xmath10 and @xmath44 .",
    "so , for each current location ( and time ) , we use the emd to compute the dissimilarity between the distributions representing the next locations of users @xmath10 and @xmath44 , respectively .",
    "the current location is taken according to user @xmath10 s mobility profile , making this definition asymmetric .    for a particular distance function @xmath31 , the mallows distance definition can be expanded and previous expressions can be further simplified .",
    "this is the case for @xmath53 , for which @xmath32 , for arbitrary probability distributions @xmath24 and @xmath25 , has closed form @xmath54 .    using the dissimilarity metric",
    ", we can compute the _ geographic similarity _ between the mobility profiles @xmath9 and @xmath43 , for any distance function ( e.g. , hamming distance , euclidean distance ) .",
    "for example , considering hamming distance @xmath55 , the geographic similarity is : @xmath56    we emphasize that this definition leads to an asymmetrical similarity measure , i.e. the similarity of @xmath10 to @xmath44 need not be the same as the similarity of @xmath44 to @xmath10 . in principle , this metric can also be computed using measures other than emd .",
    "for example , one can use kullback - leibler divergence measure @xcite to compute the difference between two probability distributions , ignoring the distance between the locations .",
    "we emphasize that we use emd , in our geographic similarity metric , as we also want to include the distance function @xmath31 between locations while computing the difference between two distributions ( i.e. , mobility models ) .",
    "consider now the computation of the geographic similarity .",
    "for the case , @xmath55 , the computation according to closed - form of takes @xmath57 operations , where @xmath58 is the number of time periods and @xmath59 is the number of locations ( regions ) . for arbitrary @xmath31 with no closed - form expressions ,",
    "the geographic similarity is obtained through @xmath60 emd computations .",
    "each of these emd computations involves minimizing the mallows distance , that is equivalent to solving the linear program given by .",
    "the semantic similarity metric builds upon the basic assumption that for two individuals @xmath10 and @xmath44 there exists an ( unknown ) semantics mapping @xmath61 of locations @xmath62 onto itself ( i.e. a permutation ) such that @xmath62 , for @xmath10 and @xmath63 , for @xmath44 semantically match .",
    "it is important to note that assuming such a mapping does not commit us to trying to learn it based on modeling location semantics directly .",
    "instead , we define the ( hidden ) semantic similarity between @xmath10 and @xmath44 as the maximum geographic similarity taken over all possible mappings @xmath61 . we define semantic similarity metric as follows .",
    "let @xmath61 be the mapping of locations of @xmath10 to locations of @xmath44 .",
    "let @xmath50 , @xmath45 , and @xmath46 be random variables for locations , and @xmath15 and @xmath14 be two time periods .",
    "we define the semantic _ dissimilarity _ between @xmath10 and @xmath44 for moving in the sequence of time periods @xmath64 as @xmath65 ,          \\label{eq : hdkp }      \\end{aligned}\\ ] ] where the mallows distance @xmath66 is computed over the random variable @xmath45 and the expectation is computed over the random variable @xmath50 given time periods @xmath15 and @xmath14 .",
    "now , we define the _ semantic similarity _ between @xmath10 and @xmath44 over any sequences of time periods as @xmath67 .",
    "\\label{eq : hdk}\\ ] ]    what we compute in is the minimum geographic mobility dissimilarity between @xmath10 and @xmath44 where the locations of @xmath44 are relabeled and mapped to locations of @xmath10 according to the permutation function @xmath68 ( which is the @xmath61 that minimizes [ eq : hdkp ] ) .",
    "the intuition is the following .",
    "consider two individuals @xmath10 and @xmath44 are at @xmath50 and @xmath69 , respectively , at time period @xmath15 .",
    "the mallows distance @xmath70 computes how dissimilar their movement will be to the next location which are represented with random variables @xmath45 for @xmath10 and @xmath71 for @xmath44 . if , according to a mapping , the way that they move between these locations is similar , they behave similarly with respect to those locations .",
    "if this is true across different time periods and location pairs , their mobilities are similar .",
    "so , the semantic similarity between two individuals is determined by @xmath68 .",
    "we compute this metric at two different levels of accuracy of the mobility model .",
    "if we only consider the visiting probability @xmath72 part of each individual s mobility profile , we compute @xmath73 as follows .",
    "let us consider the hamming distance function @xmath74 . in this case",
    ", we can compute the semantic similarity metric as @xmath75    note that the computation of requires finding the mapping @xmath61 which maximizes the inner term for each time period @xmath15 .",
    "since there are @xmath76 possible candidates for the maximum mapping @xmath61 , a brute - force approach is inefficient . however , the problem s structure resembles that of a linear assignment . focusing on the inner sum",
    ", we see that each term ( each @xmath16 ) can be associated with @xmath59 values of @xmath77 independently of the other components of @xmath61 . to recast the problem as a linear assignment",
    ", we construct a bipartite graph where the nodes represent @xmath62 and @xmath78 , and each edge represents the association ( through @xmath61 ) of @xmath16 with @xmath77 .",
    "the maximum weight assignment of the constructed bipartite graph gives the permutation @xmath61 .",
    "the running time of this procedure is @xmath79 using the hungarian algorithm  @xcite .",
    "we compute the semantic similarity for the case where we consider the more accurate mobility profile @xmath80 as follows .",
    "@xmath81    it is not known whether there is an efficient algorithm to compute the semantic similarity according to .",
    "the difficulty comes from having to consider assignments of pairs : @xmath82 to @xmath83 , which makes this computation resemble the quadratic assignment problem ( qap ) @xcite , known to be np - hard and apx - hard .",
    "the semantic similarity can nevertheless be computed through approximation techniques such as simulated annealing  @xcite , or the metropolis - hastings algorithm  @xcite . nevertheless , can be approximated using techniques such as simulated annealing  @xcite , or the metropolis - hastings algorithm .",
    "we use this algorithm to compute the semantic similarity metric , in the case of considering both visiting and transition probabilities of the individuals mobility models ( see  @xcite for details ) .",
    "the idea is to find good approximations to the quantity of interest ( for us @xmath61 ) through probabilistic local exploration of the solution space . at each step , we replace our current permutation with a new solution randomly selected from its neighbors ( e.g. a permutation which differs in two positions ) .",
    "the output of the algorithm is the best permutation found so far when the algorithm terminates ( after some fixed number of iterations ) .",
    "it is known that the starting permutation can have an impact on the quality of the output . in our case",
    ", we expect the permutation found during the computation of to be a good starting point .",
    "in this section , we present the details of our algorithms for sampling fake traces .",
    "figure  [ fig : alg ] presents a high - level view .",
    "the process of generating and using fake traces are completely separate .",
    "when a set of fake traces are generated , they can be used in any protection mechanism accordingly .",
    "we assume that we have a dataset @xmath84 of real traces that we use as seed to generate fake traces .",
    "each seed trace in the dataset comes from a different individual . generating a fake trace starts by transforming a real trace ( taken as seed ) to a semantic trace . to this end",
    ", we require to know the semantic coordinates of the seed trace .",
    "we compute the semantic similarity between all locations in @xmath62 , and create a location semantic graph @xmath85 such that the vertices are in @xmath62 and the weight @xmath86 on the edge between locations @xmath16 and @xmath13 is the weighted sum of the number pairs of users @xmath10 and @xmath44 for whom @xmath16 and @xmath13 is semantically mapped ( i.e. , @xmath87 ) , weighted according to their similarity .",
    "then , we create the equivalent semantic classes @xmath88 by running a clustering algorithm on this graph . for this purpose , we make use of k - means clustering algorithm , and we choose the number of clusters such that it optimizes the clustering objective .",
    "we present the sketch of this algorithm in figure  [ fig : alg]-@xmath89 .",
    "we then convert the seed location trace @xmath90 into its corresponding semantic trace @xmath91 by simply replacing each location in the trace with all its semantically equivalent locations ( according to the semantic classes @xmath88 ) .",
    "figure  [ fig : procedure ] depicts an example of such a semantic seed .",
    "intuitively , this composite trace encompasses all possible geographic traces that have a high semantic similarity to the original seed trace . to be more flexible with respect to the traces that we can generate ,",
    "we add some randomness to the semantic seed trace . in the transformation process of the seed trace into the semantic trace , we sub - sample locations from the semantic classes as opposed to using them all . for privacy reasons , we remove each location in a cluster with probability @xmath92 . the result is a new cluster @xmath93 .",
    "we also allow locations of different classes to merge into each other closer to the time instants where the user moves from one class to the other .",
    "we implement this by merging a location between two cluster visited @xmath94 time instants away with a geometric probability @xmath95 .      any random walk on the semantic seed trace that crosses the available locations at each time",
    "instant is a valid location trace that is semantically similar to the seed trace .",
    "however , the synthetic traces we want to generate also need to be geographically consistent with the general mobility of people in the considered area .",
    "we cast the problem of sampling such traces as a decoding problem in hidden markov models ( hmms ) @xcite . the symbols are locations , the observables are the semantic classes ( or the set of semantically equivalent locations in the same class ) , and the transition probability matrix is our aggregate mobility model .",
    "we construct the aggregate mobility model by averaging over the mobility models of all traces in dataset @xmath84 , as well as giving a small probability to the possible movements between locations according to their distance and connectivity .",
    "more precisely , we compute the aggregate transition probability @xmath96 as @xmath97 , where @xmath98 is a small constant , and @xmath99 is the normalizing factor .",
    "we compute the aggregate visiting probability @xmath100 as the average of @xmath101 , for all @xmath102 .",
    "the probability distribution @xmath103 is also the steady state probability distribution of @xmath104 .    by decoding the semantic trace into geographic traces using hmms",
    ", we generate traces that are probable according to aggregate mobility models , i.e. , there could be one individual who prefers to take that trajectory .",
    "there are different hmm decoding algorithms .",
    "we make use of the viterbi algorithm which is a dynamic programming algorithm to generate the most probable trace given the observation ( i.e. , the sematic seed trace ) @xcite .",
    "more precisely , viterbi finds @xmath105 assuming that @xmath106 can only choose from locations in @xmath107 .",
    "finding the most likely fake trace is equivalent to finding the shortest path in an edge - weighted directed graph where each location at time instant @xmath19 is linked to all locations at the subsequent time in the semantic seed trace .    by using this encoding technique ,",
    "we make sure that the sampled trace is consistent with the generic mobility and has a significant probability of ( geographically ) being a real trace .",
    "however , viterbi produces ( only ) one trace , hence we can not directly generate multiple fake traces . to address this issue , we add randomness to the trace reconstruction of viterbi .",
    "we modify the viterbi algorithm , which originally , at each step ( time instant ) selects the most probable location in the path ; we add some randomness to the probabilities such that the algorithm does not deterministically select the most probable location .",
    "more precisely , we slightly perturb the probabilities in such a way that viterbi selects randomly among a set of locations that are close in probability to the most probable location .",
    "we implement this idea by choosing a parameter @xmath108 and multiplying all the probabilities of moving from one location to the next with a random number between @xmath109 and @xmath108 .    .",
    "to generate a fake trace , we first probabilistically remove the seed location and probabilistically merge subsequent classes . in our example , @xmath110 are removed , and @xmath111 are merged into their neighboring visited clusters .",
    "we then run a decoder to generate a probable trace given the possibility of choosing from all available locations at each time instant .",
    "the fake trace is shown with dashed boxes .",
    "a rejection test will run on this trace to guarantee its privacy compliance . ]",
    "the threat against fake trace generating algorithms is twofold .",
    "( 1 ) one threat is directly related to the adversary who wants to filter out traces that are fake and to find out the true location of mobile users ( _ localization _ attack ) , e.g. , when it is used in location based services to hide the true location of the user .",
    "for this attack , we assume the adversary has a background knowledge on general mobility models of users in the considered area . in section  [ sec :",
    "evaluation_lbs ] , we quantify the success rate of an adversary in localizing users while fake traces are used as a defense mechanism .",
    "( 2 ) the other threat is secondary as it is related to the algorithm that generates the fakes , and comes from the adversary whose goal is to identify the real individuals whose trace are used as seed ( _ membership inclusion _ attack ) . in the next subsection",
    ", we enforce a privacy property that protects against the second threat .",
    "we guarantee plausible deniability for seed contributors independently from the adversary s knowledge .      in the end , we want to make sure that the generated fake traces do not leak information about the seed trace .",
    "we design tests to protect against the following threat model .",
    "we assume the adversary has access to traces ( or mobility patterns ) of some individuals that might overlap with the set of individuals who contribute to the seed dataset .",
    "the attacks depend on the scenario in which a fake trace is used",
    ". the adversary might be interested in separating fake from real ( in lbs scenario ) or finding the seed from which a fake trace is generated ( in trace publishing scenario ) . to protect against such threats , as the last step of our process",
    ", we run a @xmath89 on each of the generated fake traces .    *  * we compute the geographic similarity of each fake trace to the seed trace and reject the fake trace if its similarity is higher than a threshold @xmath112 .",
    "this makes sure that the fake trace does not _ statistically _ leak information about the mobility of the individual behind the seed trace .",
    "we also reject a fake trace if its intersection with the seed trace is larger than @xmath113 .",
    "this makes sure that the exact locations visited by the individual are not present in the fake trace .",
    "these tests provide the privacy guarantee with respect to information leakage of visited locations .    *",
    " * we also use another notion of privacy , which is more of relevance in the case of publishing a location dataset . specifically ,",
    "we want to defend against _ membership inclusion _ attacks , in which an adversary wants to infer whether a particular individual s data was included in the seed dataset .",
    "therefore , we design another privacy test that guarantees _ plausible deniability _ for those whose trace was used as seed .",
    "the main idea is that a fake trace should be as semantically similar to its own seed as to some other real traces which are not included in the seed dataset , so that an adversary can not certainly infer that a particular individual was in the seed dataset and de - anonymize the seed contributor .",
    "intuitively , if the semantic similarity of a fake trace to its own seed is comparable to its semantic similarity with some non - seed real trace , then the fake trace could have been generated from either of them . to enforce this property , we test if for a generated fake trace @xmath114 ( that was generated from a seed trace @xmath115 ) , there are some other real trace @xmath116 such that their differential semantic similarity is bounded .",
    "@xmath117    we can enforce this to hold for a minimum @xmath0 number of alternative @xmath116 traces ( from which we are not going to publish fake traces ) . thus",
    ", there is at least one real trace outside the set of seeds associated with fake traces that could have produced each releasable fake trace .",
    "more generally , we enforce the size of anonymity set to be @xmath118 .",
    "this property , which provides _ plausible deniability _",
    ", is conceptually related to , but weaker than , differential privacy ( dp )  @xcite .",
    "indeed , this is one kind of guarantee that differential privacy is meant to provide .",
    "that said , we enforce this property for _ actual _ seeds in the datasets .",
    "thus , by looking at a fake trace the adversary can not surely conclude that a particular trace was in the seed dataset , because there exist at least @xmath0 other traces that could have seeded the same fake trace .",
    "each time we generate a new fake trace that passes the privacy tests , we compute its likelihood based on the aggregate mobility model .",
    "one can then randomly sample from the bag of fake traces based on this likelihood .",
    "the traces that are generated according to this process do not leak information about the seed traces , yet they share their average geographic features and semantic features .      the fake generation process , which results in a pool of fake traces having passed the privacy test , is run offline on powerful machines , before the users device retrieve and use such fakes .",
    "therefore , this computational burden is not placed on the users device . nevertheless , the generation process is reasonably efficient : the computation of both the aggregate mobility and the semantic clustering needs to be done only once for each input set of real traces .",
    "the former takes time @xmath119 where @xmath120 is the number of seed traces , @xmath121 is the length ( i.e. , number of events ) of each seed trace . the latter is dominated by @xmath122 semantic similarity computations ( e.g. , each taking @xmath123 in the zeroth - order case ) and one clustering operation . excluding the final clustering , this step is embarrassingly parallel : the semantic similarity for any two users @xmath10 , @xmath44 can be computed independently .",
    "also , if a few input traces are added , both the aggregate statistics and the semantic clustering can be updated and do not need to be recomputed from scratch . once the semantic clustering has been computed , an arbitrarily large number of fakes for each seed can be generated .",
    "this process is also embarrassingly parallel , since each fake can be generated independently of other fakes for that seed , and other seeds .",
    "the algorithm of figure  [ fig : alg ] works if the input dataset contains at least two seed traces .",
    "however , its quality will be high if , among the seed traces : the coverage of the location set @xmath62 is high ( not necessarily complete ) ; the semantic similarity is high ; and the geographic similarity is low .",
    "in this section , we run our algorithms on a set of real location traces and evaluate their utility and privacy in two scenarios : publishing a location dataset , and sharing locations with a location - based service .      the dataset we use for the evaluation is collected through the nokia lausanne data collection campaign ( see  @xcite ) .",
    "we prepare the dataset for our needs in two phases , filling gaps in the traces and discretizing the time and location .",
    "the raw dataset contains events of three types : gps ( the gps position of the user is known ) , wlan ( the ssid and signal strength of a set wireless networks which surround the user are known ) , and gsm ( the identifier of the gsm base station to which the user s phone is associated is known ) . in the first phase , we compute valid traces ( out of possibly partial traces ) by aggregating events and filling gaps .",
    "we do this by interpolating along the path of consecutive gps points and using the wlan and gsm information . in the second phase ,",
    "we extract two days of traces for 30 users , such that each trace contains a sequence of 72 locations ( i.e. , one location is reported every 20 minutes ) .",
    "some locations are visited very rarely only by very few users .",
    "thus , we reduce the number of locations from 1491 to 400 by clustering close - by locations together .",
    "we use a hierarchical clustering algorithm for this purpose , in which the distance between two locations is taken to be proportional to both the euclidean distance between the locations and the product of their weights ( defined as the number of total visits to each location , for all users ) .",
    "this means that locations clustered together will tend be both geographical close and have few visits .",
    "the geographical distribution of visits of all users over the locations in the considered area is shown in figure  [ fig : dataset](a ) .",
    "we computed the mobility profiles of all 30 users , and then the semantic location graph by calculating a similarity score for each pair of locations , averaged across all users .",
    "after clustering this semantic location graph , we obtained 20 location clusters .",
    "we choose this number of clusters as it provides optimal clustering i.e. , it maximizes the ratio of inter - cluster similarity over intra - cluster similarity .",
    "this clustering is illustrated in figure  [ fig : dataset](b ) , where each location is drawn with the color of the cluster it belongs to .",
    "the figure allows us to distinguish some patterns , for example locations at the center of cities are mostly in blue , while many locations representing roads and highways are colored in red .",
    "also notice that the semantic clustering does not seem to depend on the geographical distance of locations .    to illustrate the difference between geographic and semantic similarities",
    ", we can compute those metrics pairwise over all 30 users .",
    "the result is shown in figures  [ fig : real - gs - similarity](a ) , and  [ fig : real - gs - similarity](b ) .",
    "the first histogram shows that the 30 users are not strongly geographically similar to each other , except for a few pairs of users .",
    "this is expected given the range of locations they explore overall , as seen in figure  [ fig : dataset](a ) .",
    "on the other hand , the distribution of the semantic similarity across all distinct pairs of users has a larger variance ; while some pairs of users are not similar at all ( e.g. , those with semantic similarity score of 0.2 ) , a large number of users are highly similar .",
    "we build our tool to generate fake traces on top of the open - source location privacy meter ( lpm )  @xcite . to exploit lpm s modularity we split our algorithm into modules . to implement the time - dependent sub - sampling of clusters and merging around transitions , and the transformation of users actual traces into semantic traces",
    ", we use the location obfuscation mechanism feature of the tool .",
    "the reconstruction of geographically valid synthetic traces from the semantic traces is done using the viterbi algorithm ( implemented in lpm as a tracking attack ) . to cluster the semantic location graph",
    ", we employ the cluto toolkit @xcite .      as for the parameters of the @xmath89 algorithm",
    ", we set the location - removal probability @xmath92 to @xmath124 , and we set the location merging probability @xmath125 to @xmath126 .",
    "we set the probability @xmath127 of removing the true location visited in the seed to @xmath128 .",
    "we set the randomization multiplication factor for viterbi randomization to 4 .",
    "so , for each probability assigned to each location at each time instant , we multiply it with a randomly chosen number between 1 to 4 .",
    "we set very tight values for the privacy parameters .",
    "we set @xmath113 , the maximum intersection between fake and seed , to @xmath129 .",
    "so , we do not tolerate any intersection between fake and seed .",
    "we set the geographic similarity threshold @xmath112 to @xmath130 , and the differential semantic similarity threshold also to @xmath130 .",
    "for each of the 30 users , we generated about 500 fake traces .",
    "out of those we randomly pick 50 traces ( for each user ) to be used for the datasets publishing scenario . for the lbs scenario",
    ", we sampled traces ( for each user ) according to the traces likelihoods , out of the pool of traces ( for that user ) which passed the privacy test .    out of the two days of traces ( each 72 timestamps , for each of the 30 users ) , we use the first day as the training dataset , and the second day as the testing dataset .",
    "we calculate the aggregate statistics and mobility profile of users on the training dataset , while we use the testing dataset to evaluate both the data publishing scenario and the attack for the lbs scenario .",
    "unless otherwise stated , for all experiments , we consider a single time - period , and compute the zeroth order versions of the geographic and semantic similarities .      in the following two subsections we evaluate the use of fake traces in two popular scenarios : publishing a dataset of fake traces , and using fake locations along with real locations when accessing location - based services . in both scenarios ,",
    "we evaluate our fake traces with respect to two metrics : _ privacy _ and _ utility_. the privacy guarantee that we provide using our privacy rejection test applies to both scenarios",
    ". however , there are some differences in terms of the adversary model between different scenarios .",
    "there are therefore some additional considerations regarding the privacy of users in location - based services , e.g. , their privacy against inference attacks , that we discuss in its corresponding subsection .",
    "the utility metric is very dependent on the application ( scenario ) , hence is measured differently in each case .                    in this scenario",
    ", we assume that we generate a fake trace for some seed traces and publish them all in a dataset .",
    "we use some real traces in our dataset that we use as alternative seeds in the differential semantic similarity test .",
    "we assume an adversary wants to infer information about the true traces that have been used to generate the fakes .",
    "due to the privacy test , location privacy of individuals who contributed to the seed dataset is guaranteed as fake traces do not intersect with the locations that are visited and does not even leak statistically about what could have been visited by those individuals . moreover , due to the differential semantic similarity test , the seed traces are not the only traces that could have generated the released fake traces .",
    "out of all fake traces that we generated from our 30 seed traces , on average @xmath131 of them could pass the geographic and intersection privacy tests with tight constraints ( @xmath132 , i.e. , no intersection allowed , and @xmath133 ) , so it is not difficult to generate fake traces that satisfy such privacy guarantees . regarding the differential semantic similarity test , we should be able to find enough number of real traces as alternative traces that could have been the seed for releasing fake traces . in figure",
    "[ fig : deltas - fakeset2 ] , we show the difference between semantic similarity of a fake trace and its seed with the semantic similarity of the same fake trace and any other real trace in our dataset .",
    "the histogram shows that the majority of fake traces have very low similarity to real traces other than their seeds .",
    "this is due to the high semantic similarity between real traces ( figure  [ fig : real - semantic - similarity ] ) so it is not difficult to find potential alternative seeds for a fake trace .",
    "we set @xmath134 to @xmath130 to obtain a high level of differential semantic privacy .      to preserve the utility of the original traces , fake traces should share similar statistical properties with the real trace dataset .",
    "note , however , that we would not expect all useful statistics to be preserved since some may be counter to our goal of preserving privacy .",
    "that is , certain geographic features are expected not to be preserved , due to the nature of the generation and the privacy test .",
    "for example , if a location is primarily visited by a single user in the real dataset , it is unlikely that the location would be visited with similar frequency by a ( fake ) user in the fake trace dataset .",
    "this is because if such a fake trace were generated from that seed , the privacy test would reject it .",
    "nevertheless , we can evaluate to what extent certain useful statistics are preserved .",
    "to start , we compare the basic mobility statistics obtained from the real and fake datasets .",
    "we compute the aggregate mobility model for each fake dataset ( we generate 10 of size 30 ) , and compare its geographic similarity with the real dataset .",
    "more precisely , for a fake dataset @xmath135 , we compute @xmath136 and compute its similarity to @xmath137 .",
    "the statistical similarity of @xmath138 with @xmath104 over all fake datasets is @xmath139\\ ] ] on ( average , median , standard deviation ) , and the results for the statistical similarity of @xmath140 with @xmath103 is @xmath141.\\ ] ] both these results show a strong correlation between average / aggregate mobility information of real and fake datasets .",
    "we then compare the location visiting probabilities of the real dataset and fake datasets .",
    "namely , for each dataset we compute the spatial allocation , i.e. , for each location ( from least to most popular , for that dataset ) , we calculate the number of visits spent in that location across all traces in the dataset .",
    "we then normalize this quantity to obtain a probability distribution over locations ( sorted by popularity ) , i.e. , for each location we have the probability of a random visit to that location . from these distributions",
    ", we compute the kl - divergence of the real ( training ) dataset to each of our fake datasets , and to a variety of baselines .",
    ", before normalizing .",
    "this is required because there may be locations which are visited in the fake dataset but not in the real dataset , or vice - versa . ]",
    "the results are shown in table  [ tbl : vistprob - kl ] . since the kl - divergence is not upper bounded , we use as baselines the kl - divergences of the real ( training ) dataset to the following distributions : real testing dataset ; uniform visiting probabilities ; and single location visiting .",
    "we see that while the kl - divergence of the real ( training ) dataset to the real testing dataset is smaller than that to the fake datasets , the latter is also significantly smaller than both the the kl - divergences to the uniform visiting baseline and the single location visiting baseline .",
    "this indicate that a lot of information is preserved in the fake datasets .",
    "next , we repeat the previous calculation of kl - divergence , but considering only visits to the @xmath142 most popular locations ( of each dataset ) .",
    "table  [ tbl : vistprob - kl-50mp ] shows the results : the information is almost as well preserved in the fake datasets than compared to the real testing dataset .",
    "we also compare the users time allocation of the real and fake datasets .",
    "namely , for each dataset and each user , we calculate the time spent at each location , among the locations visited .",
    "that is , we calculate , for the three most popular locations of that user , what proportion of the time is spent in each .",
    "we perform this calculation across all 30 users and normalize the result .",
    "we compare this distribution for the real and fake datasets .",
    "table  [ tbl : timealloc - kl ] shows the kl - divergence of the real ( training ) dataset to the fake datasets and baselines : real testing dataset ; uniform time allocation ( each user spends @xmath143 proportion of time at each of the @xmath118 locations ) ; random time allocation ( each user spends a uniformly random proportion of time at the location ) .",
    "this statistic is highly preserved in the fakes ; sometimes the fake datasets distribution is closer to that of the real ( training ) dataset , than the distribution of the real testing dataset is .",
    "the previous results provide confidence that useful information is indeed preserved in the fake traces dataset .",
    "that said , our original goal was to preserve utility in the sense of semantic similarity , so it sensible to wonder how close we are to that goal . to determine this , we first compute the semantic similarity of each fake trace with its own seed trace to check if the semantic features of the original traces are indeed preserved",
    ". figure  [ fig : real - fake - semantic - similarity ] illustrates the distribution of this value over all fake traces .",
    "clearly , the distribution is biased towards higher similarity values .",
    "so , the fake traces considerably preserve the semantic features of the real traces .",
    "another type of statistics that we would expect the set of fake traces to preserve is the inner similarity between the set of traces . in figure",
    "[ fig : fake - fake - semantic - similarity - qq ] , we present the correlation between two distributions : semantic similarity among real traces , and semantic similarity among fake traces .",
    "the q - q plot shows a significant correlation between these two distributions ; they are strongly linearly related .",
    "this reflect that in addition to maintaining the information about each seed , we also preserve the statistical relation among the traces .",
    "results show that fake traces can not be distinguished from the real ones if it appears among some real traces .",
    "this is because the relation between a fake trace and the distribution of real traces is largely indifferent from that of a real trace with respect to both semantic and geographic features .",
    "& mean & std & & + & 0.3841 & 0.0432 & & +     & mean & std & & + & 0.0289 & 0.0086 & & +    c |*6c| & testing & & uniform & random + & & mean & std & & + & & 0.0125 & 0.0022 & & + & & mean & std & & + & & 0.0092 & 0.0031 & & + & & mean & std & & + & & 0.0089 & 0.0036 & & +      the utility and privacy evaluation for the publishing dataset scenario applies to the case where traces are shared with a service provider . however",
    ", we can perform a more specific analysis on the fake locations when they are shared in a new setting .",
    "we present the details of how fake locations are used to protect location privacy , and how they perform against inference attacks despite the fact that they have passed privacy guarantee tests .",
    "we assume a user shares her current location with a location - based service with a probability @xmath144 ( set to @xmath145 in our case ) .",
    "the service provider , in return , provides the user with contextual information about the shared locations ( e.g. , list of nearby restaurants , current traffic information on the road ) . the service provider would receive a sequence of locations that are visited by the user at different time instants . to protect her location privacy ,",
    "i.e. , hiding her location at the time of access to the lbs and also preventing the inference of the full trajectory , the user sends a number of fake locations along with her true location .",
    "we assume the user has access to some full fake traces , and at any time instant @xmath19 , when she is accessing the server , she consistently adds the locations visited at @xmath19 on each fake trace to her actual location at @xmath19 and sends them to the server .",
    "the service provider responds to each of these location queries , and the user needs to filter out the results associated with fake locations to obtain the information about her true location .",
    "we evaluate a few other methods to generate fake locations along with our method for comparison .",
    "* uniform iid : we sample each fake location independently and identically distributed from the uniform probability distribution .",
    "* aggregate mobility iid : we sample each fake location independently and identically distributed from the aggregate mobility probability distribution @xmath103 .",
    "* random walk on aggregate mobility : we sample a fake trace by doing a random walk on the set of locations following the probability distribution @xmath104 . * random walk on user s mobility : we do a random walk on the set of locations following the probability distribution @xmath12 to generate a fake trace .",
    "we assume the adversary wants to filter out the fake locations and to find the true sequence of locations that are visited by the user .",
    "the privacy metric that we use is based on the error of adversary in his inference attack @xcite .",
    "put simply , the fraction of true locations that are missed by the adversary is our privacy metric .",
    "more precisely , the metric is the probability of error of inference attack on guessing the correct location .",
    "we assume the adversary makes use of the aggregate mobility model @xmath137 to single out the true locations and reconstruct the true location of the user .",
    "there is an overhead to these privacy - preserving mechanisms , as a user has to send more than one query to the server to get the results for one query .",
    "this can be interpreted as utility loss , and so we define two metrics for ( the lack of ) utility .",
    "the first is the number of distinct locations sent by the user at each time ( diversity overhead ) .",
    "note that this number can be less than the number of fake traces as they might intersect at the times of connection to the server . additionally , some service providers ( e.g. , google now ) might profile the user over time based on the type of locations she visits , in order to provide recommendations or reminders . in these cases ,",
    "the queries that are sent to the server can pollute the profile of the user hence reduce the predictability power of the service provider .",
    "for this , we use the number of ( distinct ) semantic clusters among the locations sent by the user at each time ( semantic overhead ) .      figure  [ fig : locationprivacy ] shows the tradeoff between location privacy and utility for various methods of generating fake traces .",
    "we evaluate the utility loss in terms of two metrics : diversity overhead ( figure  [ fig : locationprivacy1 ] ) , and semantic overhead ( figure  [ fig : locationprivacy2 ] ) .",
    "we evaluate the privacy for exposure probability @xmath146 , and three different number of fake traces : @xmath147 .",
    "although the number of fake traces are the same , across different algorithms , but the average number of distinct locations sent to the lbs is not the same .",
    "this is because of the high randomness in the _ uniform iid _ , _ agg mobility iid _ , and _ rw agg mobility _ that select fake traces from all possible locations .",
    "our method and the _ rw user profile _ method have both lower diversity overhead and lower semantic overhead in the set of fake locations .",
    "our method , clearly outperforms all the tested methods , especially the random strategies . for the case of",
    "_ rw user profile _",
    "method , the privacy level against tracking attack gets closer to what we achieve ( which is very close to the maximum ) , due to the fact that the fake traces generated by _",
    "rw user profile _ are geographically very similar to the true location of the user , and hence creates high confusion , hence error , for the adversary .",
    "note that the _ rw user profile _ is never a privacy - preserving fake injection method as the adversary can easily de - anonymize and profile the user , no matter if he makes mistakes on exactly tracking the user at each access time ( as shown here ) .",
    "whereas , our method is ensured to have minimal geographic mutual information with the true trace , thus it is robust against profiling attack .",
    "we also ensure that the fake traces have small differential semantic similarity , thus they are robust against de - anonymization .",
    "additionally , the plot shows that our method is the strongest fake generating algorithm against an attacker who is interested in filtering out the fake locations and localize the user over time .",
    "location obfuscation is a prevalent non - cryptographic technique to protect location privacy .",
    "it does not require changing the infrastructure , as it can also be done all on the user s side either by altering ( perturbing ) the location coordinates to be reported or by sending fake location reports interleaved or along with the true location of the user .",
    "many location perturbation techniques have been proposed in the literature , usually based on adding some noise to the user s location coordinates or reducing its granularity , e.g. , @xcite .",
    "the downside of these techniques is that they reduce the service quality of the user in interaction with the location - based service ( lbs ) provider .",
    "this is because the server provides contextual information related to the shared location and not the true location of the user .",
    "so , users have to trade service quality to obtain their required level of privacy . optimal solutions for location perturbation techniques are proposed @xcite which show the high cost of location privacy on service quality using perturbation .    hiding the user s true location among fake locations is a promising yet very little - explored approach to protecting location privacy .",
    "there are few simple techniques proposed so far : adding independently selected fake locations drawn from the population s location distribution @xcite , generating dummy locations at random as a random walk on a grid @xcite , constructing fake driving trips by building the path between two random locations on the map given the more probable paths traveled by drivers @xcite , or adding noise to the paths generated by road trip planner algorithms @xcite .",
    "these solutions lack a formal model for human mobility and do not consider the semantics associated with sequence of locations visited by people over time .",
    "thus , the generated traces can be distinguished from real location traces .",
    "this paper , to the best of our knowledge , is the first that proposes a systematic methodology for generating fake location traces based on statistical features of both geographical and semantic dimensions of real traces , and based on a metric to measure how realistic a synthetic trace is .",
    "moreover , we introduce multiple privacy tests to ensure that the published / shared fake traces themselves do not leak information about real seed traces .",
    "our evaluation on real data also shows the clear advantage of our algorithm with respect to other existing approaches against known inference attacks .",
    "this is the first paper to address the problem of generating realistic synthetic location traces based on a quantitative metrics .",
    "generating such traces is very useful to protect privacy of users when they share location with location - based services , or when we want to publish a dataset of locations to be used for various research reasons .",
    "based on well - established statistical methods , we propose two metrics to quantify geographic and semantic features of human mobility . using these metrics , we propose efficient algorithms to generate fake traces that do not leak geographic information about real individuals ( guaranteed using a privacy rejection test ) , yet highly resemble the mobility of a population semantically . we show that inference attacks can not identify the true location of mobile users if our fake traces are used as protection .",
    "we also quantitatively show that our method is superior to all existing methods of generating fake traces .",
    "m.  e. andrs , n.  e. bordenabe , k.  chatzikokolakis , and c.  palamidessi .",
    "geo - indistinguishability : differential privacy for location - based systems . in _ proceedings of the 2013 acm sigsac conference on computer & communications security _ , pages 901914 .",
    "acm , 2013 .",
    "r.  chow and p.  golle .",
    "faking contextual data for fun , profit , and privacy . in _",
    "wpes 09 : proceedings of the 8th acm workshop on privacy in the electronic society _ , pages 105108 , new york , ny , usa , 2009 .",
    "acm .        c.  dwork .",
    "differential privacy . in m.",
    "bugliesi , b.  preneel , v.  sassone , and i.  wegener , editors , _ 33rd international colloquium on automata , languages and programming , icalp 2006 _ , volume 4052 of _ lecture notes in computer science _ ,",
    "pages 112 .",
    "springer , 2006 .",
    "b.  hoh , m.  gruteser , h.  xiong , and a.  alrabady .",
    "preserving privacy in gps traces via uncertainty - aware path cloaking . in _",
    "ccs 07 : proceedings of the 14th acm conference on computer and communications security _ , pages 161171 , new york , ny , usa , 2007 .",
    "acm .",
    "h.  kido , y.  yanagisawa , and t.  satoh .",
    "an anonymous communication technique using dummies for location - based services . in _ pervasive services , 2005 .",
    "icps 05 . proceedings .",
    "international conference on _ , pages 8897 , july 2005 .",
    "j.  krumm .",
    "realistic driving trips for location privacy . in _ pervasive 09 : proceedings of the 7th international conference on pervasive computing _ , pages 2541 , berlin , heidelberg , 2009 .",
    "springer - verlag .",
    "e.  levina and p.  bickel .",
    "he earth mover s distance is the mallows distance : some insights from statistics . in _",
    "computer vision , 2001 .",
    "iccv 2001 .",
    "eighth ieee international conference on _ , volume  2 , pages 251 256 vol.2 , 2001 .",
    "a.  machanavajjhala , d.  kifer , j.  abowd , j.  gehrke , and l.  vilhuber .",
    "privacy : theory meets practice on the map . in _ data engineering , 2008 .",
    "icde 2008 .",
    "ieee 24th international conference on _ , pages 277286 .",
    "ieee , 2008 .",
    "r.  shokri , g.  theodorakopoulos , g.  danezis , j .-",
    "hubaux , and j .- y .",
    "le  boudec .",
    "quantifying location privacy : the case of sporadic location exposure . in _ proceedings of the 11th international conference on privacy enhancing technologies _",
    ", pets11 , pages 5776 , berlin , heidelberg , 2011 .",
    "springer - verlag .",
    "r.  shokri , g.  theodorakopoulos , j .- y .",
    "le  boudec , and j .-",
    "quantifying location privacy . in _ proceedings of the 2011 ieee symposium on security and privacy _",
    ", sp 11 , pages 247262 , washington , dc , usa , 2011 .",
    "ieee computer society .",
    "r.  shokri , g.  theodorakopoulos , c.  troncoso , j .-",
    "hubaux , and j .- y .",
    "le  boudec .",
    "protecting location privacy : optimal strategy against localization attacks .",
    "in t.  yu , g.  danezis , and v.  d. gligor , editors , _ acm conference on computer and communications security ( ccs12 ) _ , pages 617627 .",
    "acm , 2012 ."
  ],
  "abstract_text": [
    "<S> camouflaging data by generating fake information is a well - known obfuscation technique for protecting data privacy . </S>",
    "<S> the effectiveness of this technique in protecting users privacy highly depends on the resemblance of fake information to reality , such that an adversary can not easily filter such fake information out . in this paper , we focus on a very sensitive and increasingly exposed type of data : location data . </S>",
    "<S> there are two main scenarios in which fake traces are of extreme value to preserve location privacy : publishing datasets of location trajectories , and using location - based services . despite advances in protecting ( location ) data privacy , </S>",
    "<S> there is no quantitative method to _ evaluate _ how realistic a synthetic trace is , and how much utility and privacy it provides in each scenario . also , the lack of a methodology to _ generate _ privacy - preserving fake traces is evident . in this paper , we fill this gap and propose the first statistical metric and model to generate fake location traces such that both the utility of data and the privacy of users are preserved .    </S>",
    "<S> we build upon the fact that , although geographically they visit distinct locations , people have strongly semantically similar mobility patterns , for example , their transition pattern across activities ( e.g. , working , driving , staying at home ) is similar . we define a statistical metric and propose an algorithm that automatically discovers the hidden semantic similarities between locations from a bag of real location traces as seeds , without requiring any initial semantic annotations . </S>",
    "<S> we guarantee that fake traces are geographically dissimilar to their seeds , so they do not leak sensitive location information . </S>",
    "<S> we also protect contributors to seed traces against membership attacks . </S>",
    "<S> interleaving fake traces with mobile users traces is a prominent location privacy defense mechanism . </S>",
    "<S> we quantitatively show the effectiveness of our methodology in protecting against localization inference attacks while preserving utility of sharing / publishing traces . </S>"
  ]
}