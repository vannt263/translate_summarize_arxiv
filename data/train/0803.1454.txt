{
  "article_text": [
    "code division multiple access ( cdma ) has been a successful scheme for reliable communication between multiple users and a common receiver .",
    "the scheme consists of @xmath0 users modulating their information sequence by a signature sequence , also known as spreading sequence , of length @xmath1 and transmitting .",
    "the number @xmath1 is sometimes referred to as the spreading gain or the number of chips per sequence .",
    "the receiver obtains the sum of all transmitted signals and the noise which is assumed to be white and gaussian ( awgn ) .",
    "the achievable rate region ( for real valued inputs ) with power constraints and optimal decoding has been given in @xcite .",
    "there it is shown that the achievable rates depend only on the correlation matrix of the spreading coefficients .",
    "it is well known that these detectors have exponential ( in @xmath0 ) complexity .",
    "therefore , it is important to analyze the performance under sub - optimal but low - complexity detectors like the linear detectors . for a good overview of these detectors",
    "we refer to @xcite . in @xcite ,",
    "the authors considered random spreading ( spreading sequences are chosen randomly ) and analyzed the spectral efficiency , defined as the bits per chip that can be reliably transmitted , for these detectors . in the _ large - system limit _",
    "@xmath2 they obtained nice analytical formulas for the spectral efficiency and showed that it concentrates .",
    "these formulas follow from the known spectrum of large covariance matrices . in @xcite,@xcite",
    "the authors analyzed the signal to interference ratio for the decorrelator and the mmse receiver and showed that it is asymptotically gaussian with variance going to zero .",
    "now consider the case where the user input is restricted to take only binary values .",
    "not much is known in this case except for the spectral efficiency in the case of high snr which is analyzed in @xcite .",
    "the random matrix techniques used for gaussian inputs do not apply here because the spectral efficiency can not be written in terms of just the covariance matrix of the spreading sequences .",
    "tanaka @xcite applied the formal replica method , developed in statistical mechanics , to this problem and conjectured the formula for spectral efficiency and bit error rate ( ber ) for uncoded transmission .",
    "these results were later extended in @xcite to include the case of unequal powers and channel with fading .",
    "the replica method is non - rigorous but believed to yield exact results for some models in statistical mechanics @xcite .",
    "more recently montanari and tse @xcite have made progress towards a rigorous derivation of tanaka s capacity formula in a restricted range of parameters .",
    "our main contributions in this paper are twofold .",
    "first we prove that tanaka s formula is an upper bound to the capacity for all values of the parameters and second we prove various useful concentration theorems in the large - system limit .      there is a natural connection between various communication systems and statistical mechanics of random spin systems , stemming from the fact that often in both systems there is a large number of degrees of freedom ( bits or spins ) , interacting locally , in a random environment .",
    "so far , there have been applications of two important but somewhat complementary approaches of statistical mechanics of random systems .",
    "the first one is the very important but mathematically uncontrolled replica method .",
    "the merit of this approach is to obtain conjectural but rather explicit formulas for quantities of interest such as , free energy , conditional entropy or error probability . in some cases",
    "the natural fixed point structure embodied in the mean field formulas allows to guess good iterative algorithms .",
    "this program has been carried out for linear error correcting codes , source coding , multiuser settings like broadcast channel ( see for example @xcite , @xcite , @xcite ) and the case of interest here @xcite : randomly spread cdma with binary inputs .",
    "the second type of approach aims at a rigorous understanding of the replica formulas and has its origins in methods stemming from mathematical physics ( see @xcite , @xcite ) . for systems",
    "whose underlying degrees of freedom have gaussian distribution ( gaussian input symbols or gaussian spins in continuous spin systems ) random matrix methods can successfully be employed .",
    "however when the degrees of freedom are binary ( binary information symbols or ising spins ) these seem to fail , but the recently developed interpolation method @xcite,@xcite has had some success .",
    "the basic idea of the interpolation method is to study a measure which interpolates between the posterior measure of the ideal decoder and a mean field measure .",
    "the later can be guessed from the replica formulas and from this perspective the replica method is a valuable tool .",
    "so far this program has been developed only for linear error correcting codes on sparse graphs and binary input symmetric channels @xcite , @xcite .    in this paper",
    "we develop the interpolation method for the random cdma system with binary inputs ( in the large - system limit ) .",
    "the situation is qualitatively different than the ones mentioned above in that the `` underlying graph '' is complete .",
    "superficially one might think that it is similar to the sherrington - kirkpatrick model which was the first one treated by the interpolation method .",
    "however as we will see the analysis of the randomly spread cdma system is substantially different due to the structure of the interaction between degrees of freedom .",
    "we consider a scenario where @xmath0 users send binary information symbols @xmath3 , @xmath4 to a common receiver , through a single awgn channel .",
    "each user @xmath5 has a random signature sequence @xmath6 where the components are independently identically distributed . for each time division ( or chip ) interval @xmath7 the received signal @xmath8 is @xmath9 where @xmath10 are independent identically distributed gaussian variables @xmath11 so that the noise power is @xmath12 . the variance of @xmath13 is set to @xmath14 and the scaling factor @xmath15 is introduced so that the power ( per symbol ) of each user is normalized to 1 .",
    "our results hold for the rather wide class of distributions satisfying : 0.25 cm    _ * assumption a. * the distribution @xmath16 is symmetric @xmath17 and has a rapidly decaying tail .",
    "more precisely , there exists positive constants @xmath18 and @xmath19 such that @xmath20 @xmath21 _    in particular , our favorite gaussian and binary cases are included in this class , and also any compactly supported distribution .",
    "an inspection of our proofs suggests that the results could be extended to a larger class satisfying : 0.25 cm _ * assumption b. * the distribution @xmath16 is symmetric with finite second and fourth moments .",
    "_ 0.25 cm however to keep the proofs as simple as possible only one of the theorems is proven with such generality .    in the sequel we use the notations @xmath22 for the @xmath23 matrix @xmath24 , @xmath25 for the corresponding random matrix , and @xmath26 , @xmath27 for the input and output random vectors .",
    "our main interest is in proving a  tight \" upper bound on @xmath28\\ ] ] in the large - system limit @xmath29 with @xmath30 fixed . in the next few paragraphs",
    "we discuss various settings for which it is justified to consider this formula as a capacity . in principle for multiaccess channels",
    "one maximizes over product distributions @xmath31 .",
    "but in fact this restriction makes no difference when one maximizes the expected mutual information because the maximum is attained for a uniform distribution .",
    "indeed for any given @xmath22 the mutual information @xmath32 is a concave functional of @xmath33 and thus so is its average .",
    "moreover the later is invariant under the transformations @xmath34 where @xmath35 . combining these two facts",
    "we deduce that the maximum in is attained for the convex combination @xmath36 which is nothing else than the product of uniform distributions for each user . before discussing the meaning of for the cdma setting let us note that it can also be interpreted as the capacity of a mimo system with binary constellations , @xmath0 transmit , @xmath1 receive antennas , and ergodic channel coefficients @xmath13 that are known to the receiver only @xcite , @xcite .    in the traditional cdma setting ( see for example @xcite )",
    "the spreading sequences are assigned to each user and do not change from symbol to symbol .",
    "moreover it is assumed that the users and the receiver know @xmath22 .",
    "the general analysis of multiaccess channels implies that the total capacity per user ( or maximal achievable sum rate ) is @xmath37 where the maximum is over @xmath38 and @xmath39 $ ] , @xmath40 . in the large - system limit",
    "we are able to prove a concentration theorem for the mutual information @xmath32 which implies that if @xmath41 belongs to a finite discrete set @xmath42 with cardinality increasing at most polynomially in @xmath0 , then concentrates on @xmath43 $ ] .",
    "of course by the same argument as before this maximum is attained for @xmath44 as long as @xmath45 .",
    "unfortunately , in order to extend these arguments to the more realistic case of exponential cardinality of @xmath42 , or even all possible continuous values of the input distribution ( and thus to fully justify ) we would have to prove stronger forms of concentration .    at this point",
    "it is interesting to discuss the situation for the continuous input case .",
    "there it is known that the maximum of is attained for a gaussian input distribution independent of the spreading sequence realization @xcite . then the concentration theorems for @xmath32 suffice to prove that in the large- system limit asymptotically equals .",
    "it is an open problem to decide if an analogous result holds in the binary input case , namely that the maximum of is attained for the uniform distribution .",
    "we conjecture that this is the case .",
    "alternatively , following @xcite one may consider the case of  long spreading sequences \" , that is sequences that extend over many symbol durations .",
    "then by  ergodicity \" one can compute the capacity as an expectation of over @xmath25 . in the continuous input case it turns out that one can switch the expectation and the maximum because it can be shown ( by the standard argument adapted above for the binary case ) that the maximum of the expectation is attained for the same gaussian input distribution .",
    "thus , remarkably , in the continuous case one exchanges the expectation over @xmath25 with the maximum over product distributions even for finite @xmath0 .",
    "finally let us return to the binary case and consider the situation of long spreading sequences as in @xcite that are assumed to be unknown ( or rather not used ) to the encoder and known to the receiver .",
    "then , by the analysis in @xcite , formula gives the capacity .",
    "if users do not cooperate @xmath33 is really a product distribution .",
    "but in any case the maximum is attained for the uniform distribution .",
    "let us now collect a few formulas that will be useful in the sequel .",
    "the conditional entropy @xmath46 $ ] is the average over @xmath27 given @xmath22 of the shannon entropy for the posterior distribution @xmath47 with the normalization factor @xmath48 note that this is the distribution used by the ideal or optimal detector .",
    "the average over @xmath27 is carried out with the distribution induced by the channel transition probability @xmath49 where in the sum @xmath50 is interpreted as the input signal .",
    "the normalization factor can be interpreted as the partition function of interacting ising spins @xmath51 with free measure @xmath33 . in view of this",
    "it is not surprising that the free energy @xmath52 plays a crucial role . in appendix [ apen : capfree ]",
    "we show that it is related to the mutual information by @xmath53\\ ] ] therefore @xmath54\\ ] ] of course by the previous discussion the @xmath55 is attained for @xmath56 .      by using the formal replica trick of statistical mechanics",
    "tanaka reduced the calculation of the conditional entropy to a variational problem .",
    "his conjectural formula is @xmath57 } c_{rs}(m)\\end{aligned}\\ ] ] where the  replica symmetric capacity functional \" @xmath58 with @xmath59 and @xmath60 the standard gaussian measure @xmath61 , has to be maximized over a parameter @xmath62 .",
    "it is easy to see that the maximizer must satisfy the fixed point condition @xmath63 the formal calculations involved in the replica method make clear that the formula should not depend on the distribution of the spreading sequence ( see @xcite ) .    in the present problem one",
    "expects a priori that replica symmetry is not broken because of a gauge symmetry induced by channel symmetry .",
    "for this reason tanaka s formula is conjectured to be exact .",
    "our upper bound ( theorem  [ thm : upperbound ] ) on the capacity precisely coincides with the above formulas and strongly supports this conjecture .",
    "recent work announced by montanari and tse @xcite also provides strong support to the conjecture at least in a regime of @xmath64 without phase transitions ( more precisely , for @xmath65 where @xmath66 is the maximal value of @xmath64 such that the solution of ( [ eqn : fixedpt ] ) remains unique ) .",
    "the authors first solve the case of sparse signature sequence ( using the area theorem and the data processing inequality ) in the limit @xmath67 .",
    "then the dense signature sequence ( which is of interest here ) is recovered by exchanging the @xmath67 and @xmath68 limits .      in the case of continuous inputs @xmath69 , in formulas ,",
    "@xmath70 are replaced by @xmath71 .",
    "the capacity is maximized by a gaussian prior , @xmath72 and one can express it in terms of a determinant involving the correlation matrix of the spreading sequences . using the exact spectral measure given by random matrix theory shamai and verdu @xcite obtained the rigorous result @xmath73 where @xmath74 on the other hand tanaka applied the formal replica method to this case and found with @xmath75 where @xmath76 .",
    "the maximizer satisfies @xmath77 solving we obtain @xmath78 and substituting this in ( [ eqn : gaussianreplica ] ) gives the equality between ( [ eqn : gaussianverdu ] ) and ( [ eqn : gaussianreplica ] ) .",
    "so at least for the case of gaussian inputs we are already assured that the replica method finds the correct solution .",
    "as we will show in section [ sec : gaussianinter ] our methods also work in the case of gaussian inputs , and yield the upper bound .",
    "the main focus and challenge of this work is on the case of binary inputs for the communication set up described above , although the methods also work for many other constellations including gaussian inputs .",
    "the main results are explained in section [ mainresults ] while the remaining sections are devoted to the proofs .",
    "we prove concentration of the mutual information in the limit of @xmath79 and @xmath80 fixed ( theorems  [ thm : capconc ] , [ thm : capconcbin ] in section [ sec : concentration ] ) . as we will see",
    "the mathematical underpinning of this is the concentration of a more fundamental object , namely , the  free energy \" of the associated spin system ( theorem  [ thm : freeconc ] ) . in fact",
    "this turns out to be important in the proof of the bound on capacity .",
    "when the spreading coefficients are gaussian the main tool used is a powerful theorem @xcite of the concentration of lipschitz functions of many independent gaussian variables , and this leads to subexponential concentration bounds . for more general spreading coefficient distributions such tools do not suffice and we have to combine them with martingale arguments which lead to weaker algebraic bounds . since the concentration proofs are mainly technical they are presented in appendices [ apen : probtools ] , [ apen : concproofs ] .",
    "sections [ sec : upperboundproof ] and [ sec : concmag ] form the core of the paper .",
    "they detail the proof of the main theorem  [ thm : upperbound ] announced in section [ sec : upperbound ] , namely the tight upper bound on capacity .",
    "we use ideas from the interpolation method combined with a non - trivial concentration theorem for the empirical average of soft bit estimates .",
    "section  [ sec : indspreadingproof ] shows that the average capacity is independent of the spreading sequence distribution at least for the case where it is symmetric and decays fast enough ( theorem  [ thm : indspreading ] in section [ sec : indspreading ] ) .",
    "this enables us to restrict ourselves to the case of gaussian spreading sequences which is more amenable to analysis .",
    "the existence of the limit @xmath67 for the capacity is shown in section [ sec : limitexistproof ] .",
    "section  [ sec : extensions ] discusses various extensions of this work .",
    "we sketch the treatment for unequal powers for each user as well as colored noise . as alluded to before the bound on capacity for the case of gaussian inputs",
    "can also be obtained by the present method and we give some indications to this effect .",
    "the appendices contain the proofs of various technical calculations .",
    "preliminary versions of the results obtained in this paper have been summarized in references @xcite and @xcite .",
    "in the case of a gaussian input signal , the concentration can be deduced from general theorems on the concentration of the spectral density for random matrices , but this approach breaks down for binary inputs . here we prove ,    [ thm : capconc ] assume the distribution @xmath16 are standard gaussians .",
    "given @xmath81 , there exists an integer @xmath82 independent of @xmath33 , such that for all @xmath83 , @xmath84\\vert\\geq \\epsilon k ] \\leq 3 e^{-\\alpha_1 \\epsilon^2 k}\\ ] ] where @xmath85 .",
    "0.25 cm    the mathematical underpinning of this result is in fact a more general concentration result for the free energy , that will be of some use latter on .",
    "[ thm : freeconc ] assume the distribution @xmath16 are standard gaussians .",
    "given @xmath81 , there exists an integer @xmath86 independent of @xmath33 , such that for all @xmath87 , @xmath88\\vert\\geq \\epsilon ] \\leq 3 e^{-\\alpha_2 \\epsilon^2 \\sqrt k}\\ ] ] where @xmath89 .    0.25 cm we prove these theorems thanks to powerful probabilistic tools developed by ledoux and talagrand for lipschitz functions of many gaussian random variables .",
    "these tools are briefly reviewed in appendix [ apen : probtools ] for the convenience of the reader and the proofs of the theorems are presented in appendix [ apen : concproofs ] .",
    "unfortunately the same tools do not apply directly to the case of other spreading sequences . however in this case the following weaker result can at least be obtained .",
    "[ thm : capconcbin ] assume the spreading sequence satisfies assumption b. there exists an integer @xmath90 independent of @xmath33 , such that for all @xmath91 @xmath92|\\geq \\epsilon k ] \\leq \\frac{\\alpha}{k \\epsilon^2}\\end{aligned}\\ ] ] @xmath93|\\geq \\epsilon ]",
    "\\leq \\frac{\\alpha}{k \\epsilon^2}\\end{aligned}\\ ] ] for some constant @xmath94 and independent of @xmath0 .    to prove such estimates it is enough ( by chebycheff ) to control second moments . for the mutual information we simply have to adapt martingale arguments of pastur , scherbina and tirrozzi , @xcite",
    "whereas the case of free energy is more complicated because of the additional gaussian noise fluctuations .",
    "we deal with these by combining martingale arguments and lipschitz function techniques .",
    "the concentration of capacity , namely @xmath95\\vert\\geq \\epsilon k]\\leq \\frac{\\alpha}{k\\epsilon^2}\\ ] ] would follow from a stronger ( uniform concentration with respect to @xmath33 ) @xmath96|\\geq \\epsilon k ] \\leq \\frac{\\alpha}{k\\epsilon^2}\\end{aligned}\\ ] ] to see this it suffices to note that for two positive functions @xmath97 and @xmath98 we have @xmath99 .",
    "but unfortunately it is not clear how to extend our proofs to obtain .",
    "however as announced in the introduction we can deduce from our theorems , by using the union bound , as long as the maximum is carried out over a finite set ( sufficiently small with respect to @xmath0 ) of distributions .",
    "we wish to argue here that theorem [ thm : freeconc ] suggests a method for proving the concentration of the bit error rate ( ber ) for uncoded communication @xmath100 where the map bit estimate for uncoded communication is defined through the marginal of ( [ eqn : postdist ] ) , namely @xmath101 .",
    "we remark that @xmath102 where we find it convenient to adopt the statistical mechanics notation @xmath103 for the average with respect to the posterior measure ( [ eqn : postdist ] ) .",
    "for example the average @xmath104 ( a soft bit estimate or  magnetization \" ) can be obtained from the free energy by adding first an infinitesimal perturbation (  small external magnetic field \" ) to the exponent in ( [ eqn : postdist ] ) , namely @xmath105 , and then differentiating the perturbed free energy dependence in the perturbed free energy ] , @xmath106 however one really needs to relate @xmath107 to the derivative of the free energy and this does not appear to be obvious .",
    "one way out is to introduce product measures of @xmath108 copies ( also called  real replicas \" ) of the posterior measure @xmath109 and then relate @xmath110 to a suitable derivative of the replicated free energy . then from the set of all moments one can in principle reconstruct @xmath107 . thus one could try to deduce the concentration of the ber from the one for the free energy .",
    "however the completion of this program requires a uniform , with respect the system size , control of the derivative of the free energy precisely at @xmath111 , which at the moment is still lacking ] .",
    "the replica method leads to the same tanaka formula for general class of symmetric distributions @xmath112 .",
    "we are able to prove this : in particular binary and gaussian spreading sequences lead to the same capacity .",
    "[ thm : indspreading ] consider cdma with binary inputs and assume a for the spreading sequence .",
    "let @xmath113 be the capacity for gaussian spreading sequences ( symmetric i.i.d with unit variance ) .",
    "then @xmath114    this theorem turns out to be very useful in order to obtain the bound on capacity because it allows us to make use of convenient integration by parts identities that have no clear counterpart in the non - gaussian case .",
    "the proof of the theorem is given in section  [ sec : indspreadingproof ] .      the interpolation method can be used to show the existence of the limit @xmath29 for @xmath115 .",
    "[ thm : limitexist ] consider cdma with binary inputs and assume a for the spreading sequences with uniform input distribution .",
    "then @xmath116    the proof of this theorem is given in section [ sec : limitexistproof ] for gaussian spreading sequences .",
    "the general case then follows because of theorem [ thm : indspreading ] .",
    "the main result of this paper is that tanaka s formula ( [ eqn : hrs ] ) is an upper bound to the capacity for all values of @xmath64",
    ". 0.25 cm    [ thm : upperbound ] consider cdma with binary inputs and assume a for the spreading sequence .",
    "we have @xmath117 } c_{rs}(m)\\end{aligned}\\ ] ] where @xmath118 is given by ( [ eqn : hrs ] )",
    ".    0.25 cm if we combine this result with an inequality in montanari and tse @xcite , and exchanging as they do the limits of @xmath29 and @xmath68 , one can deduce that the equality holds for some regime of noise smaller than a critical value .",
    "this value corresponds to the threshold for belief propagation decoding . note that this equality is valid even if @xmath64 is such that there is a phase transition ( the fixed point equation has many solutions ) , whereas in @xcite the equality holds for values of @xmath64 for which the phase transition does not occur",
    "since the proof is rather complicated we find it useful to give the main ideas in an informal way .",
    "the integral term in ( [ eqn : hrs ] ) suggests that we can replace the original system with a simpler system where the user bits are sent through @xmath0 independent gaussian channels given by @xmath119 where @xmath120 and @xmath121 is an effective snr .",
    "of course this argument is a bit naive because this effective system does not account for the extra terms in ( [ eqn : hrs ] ) , but it has the merit of identifying the correct interpolation .",
    "we introduce an interpolating parameter @xmath122 $ ] such that the independent gaussian channels correspond to @xmath123 and the original cdma system corresponds to @xmath124 ( see figure [ interpolationcomsystem ] )    [ interpolationcomsystem ]    ( 450,550 ) ( 0,0 ) are transmitted through the normal cdma channel with variance @xmath125 and through individual gaussian channels with noise @xmath126,title=\"fig : \" ] ( 200,555)(0,0)[t ] ( 150,505)(0,0)[t ] ( 200,255)(0,0)[t ] ( 150,205)(0,0)[t ] ( 200,155)(0,0)[t ] ( 150,105)(0,0)[t ] ( 420,260)(0,0)[t ] ( 460,310)(0,0)[t ] ( 72,45)(0,0)[t ] ( 72,145)(0,0)[t ] ( 72,445)(0,0)[t ] ( 10,110)(0,0)[t ] ( 10,210)(0,0)[t ] ( 10,510)(0,0)[t ]    it is convenient to denote the snr of the original gaussian channel as @xmath127 ( that is @xmath128 ) . then becomes @xmath129",
    "we introduce two interpolating snr functions @xmath130 and @xmath131 such that @xmath132 and @xmath133 the meaning of is the following . in the interpolating @xmath134-system",
    "the effective snr seen by each user has an effective @xmath134-cdma part and an independent channel part @xmath130 chosen such that the total snr is fixed to the effective snr of the cdma system .",
    "there is a whole class of interpolating functions satisfying the above conditions but it turns out that we do not need to specify them more precisely except for the fact that @xmath131 is increasing , @xmath130 is decreasing and with continuous first derivatives .",
    "subsequent calculations are independent of the particular choices of functions .",
    "the parameter @xmath62 is to be considered as fixed to any arbitrary value in @xmath135 $ ] .",
    "all the subsequent calculations are independent of its value , which is to be optimized to tighten the final bound .",
    "we now have two sets of channel outputs @xmath136 ( from the cdma with noise variance @xmath137 ) and @xmath138 ( from the independent channels with noise variance @xmath139 ) and the interpolating communication system has a posterior distribution @xmath140 note that here we take without loss of generality @xmath141 . by analyzing the mutual information",
    "@xmath142 $ ] of the interpolating system we can relate @xmath143 $ ] ( the @xmath124 value ) to the easily computed entropy @xmath144 $ ] of the independent channel limit .",
    "the average over @xmath145 is now performed with respect to @xmath146 these equations completely define the interpolating communication system .    in order to carry out this program",
    "successfully it turns out that we need a concentration result on empirical average of the `` magnetization '' , @xmath147 which , as explained in section [ sec : concentration ] , is closely related to the ber . informally speaking we need to prove that the fluctuations of @xmath148 are small .",
    "this involves the control of two types of fluctuations , @xmath149 and @xmath150 ( by the triangle inequality ) . in some spin glass problems both type of fluctuations need",
    "not be small at the same time .",
    "indeed it is a quite general fact that the first one is small for thermodynamic ( or convexity ) reasons while the smallness of the second is not assured if replica symmetry breaking occurs ( see @xcite ) .",
    "here we use a crucial ingredient that is specific to the communication set up , namely the channel symmetry , which induces a gauge symmetry and prevents replica breaking .",
    "this , it turns out , allows to prove that both fluctuations are small .",
    "the control of these fluctuations is the object of theorem  [ thm : concmag ] in section  [ sec : conclemmas ] .",
    "there are technical complications that we have to deal with because such control of fluctuations is only possible away from phase transitions .",
    "for this reason we have to add small appropriate perturbations to the measure and give almost sure statements with respect to the strength of the perturbation . by being sufficiently careful with the order of limits the extra perturbation terms",
    "can be removed at the end of the calculations .",
    "the interpolating communication system defined by the measure allows us to compare the original cdma system with the independent channel system .",
    "the distribution of @xmath151 is given by .",
    "this distribution consists of a summation of @xmath152 terms , each corresponding to different possible input sequence .",
    "each of these terms contribute equally to the capacity ( free energy ) .",
    "the reader can explicitly check this by making the change of variables @xmath153 and @xmath154 , @xmath155 , @xmath156 which leave all standard gaussians invariant .",
    "hence we can assume that a particular input sequence say @xmath50 is transmitted .",
    "the distribution of the received vectors with this assumption is @xmath157 for technical reasons that will become clear only in the next section we consider a slightly more general interpolation system where the perturbation term @xmath158 is added in the exponent of the measure . here",
    "@xmath159 are i.i.d .",
    "@xmath160 . for the moment",
    "@xmath161 is arbitrary but in the sequel we will take @xmath162 .",
    "this time it is convenient to perform a new change of variables @xmath163 and @xmath164 , where @xmath165 and we set @xmath166 for the average corresponding to the posterior measure @xmath167 with the obvious normalization factor @xmath168 . we define a free energy @xmath169 for @xmath124 we recover the original free energy , @xmath170=\\frac{1}{2}+\\lim_{u\\to 0}{\\mathbb{e}}[f_{1,u}({\\underline{n}},{\\underline{w}},{\\underline{h}},{\\textbf{s}})]\\ ] ] while for @xmath123 the statistical sums decouple and we have the explicit result dependence and see that it is @xmath171 , uniformly in @xmath0 ] @xmath173= -\\frac{1}{2\\beta}-   \\lambda     + \\int dz \\ln ( 2\\cosh(\\sqrt{\\lambda } z+ \\lambda ) ) \\end{aligned}\\ ] ] where @xmath174 denotes the appropriate collective expectation over random objects . in view of formula in order to obtain the average capacity it is sufficient to compute @xmath175 + \\frac{1}{2}\\ ] ] there is no loss in generality in setting @xmath176 for the input symbols . from now on in sections [ sec : upperboundproof],[sec : concmag ] , and [ sec : limitexistproof ] we stick to .",
    "we also use the shorthand notations @xmath177 using @xmath178 it easily follows that ( @xmath179 small ) @xmath180 - { \\mathbb{e}}[f_{t,0 } ] \\vert \\leq 2\\sqrt u{\\mathbb{e}}[\\vert h_k\\vert ] + u\\end{aligned}\\ ] ] therefore we can permute the two limits in and compute @xmath181 + \\frac{1}{2}\\ ] ] from now on we keep the limits in that order . by the fundamental theorem of calculus , @xmath182 = { \\mathbb{e}}[f_{0,u } ] + \\int_0 ^ 1dt \\frac{d}{dt}{\\mathbb{e}}[f_{t , u}]\\ ] ] our task",
    "is now reduced to estimating @xmath183\\ ] ] this is done in sections [ sec : derivative ] , [ sec : endofproof ] .",
    "this requires a few preliminary results that are the object of sections [ sec : nish ] , [ sec : conclemmas ] .",
    "as already alluded to in the introduction the  magnetization \" plays an important role @xmath184 a closely related quantity is the  overlap parameter \" @xmath185 where @xmath186 and @xmath187 are independent copies (  replicas \" ) of the @xmath188 .",
    "this means that the joint distribution of @xmath189 is the product measure @xmath190 the average with respect to this joint distribution is denoted ( by a slight abuse of notation ) with the same bracket @xmath191 .",
    "the important thing to notice is that the replicas are  coupled \" through the common randomness @xmath192 .    [ lem : nishimorimq ] the distributions of @xmath193 and @xmath194 defined as @xmath195 are equal , namely @xmath196    in particular the following identity holds @xmath197={\\mathbb{e}}[\\langle q_{12}\\rangle_{t , u}]\\ ] ] such identities are known as nishimori identities in the statistical physics literature and are a consequence of a gauge symmetry satisfied by the measure @xmath198 .",
    "they have also been used in the context of communications ( see @xcite,@xcite ) . for completeness a sketch of the proof is given in appendix [ apen : nishimori ] .",
    "the next two identities also follow from similar considerations .",
    "[ lem : nishimori2 ] let @xmath199 consider two replicas @xmath200 , @xmath201 corresponding to @xmath202 .",
    "we have then @xmath203 = 1\\ ] ] and @xmath204   = \\sum_{k}{\\mathbb{e}}[\\langle ( { \\underline{n}}\\cdot{{\\underline{{\\cal z}}}})z_k\\rangle_{t , u } ] \\end{aligned}\\ ] ]      a crucial feature of the calculation in the next paragraph is that @xmath193 ( and @xmath194 ) concentrate , namely 0.25 cm    [ thm : concmag ] fix any @xmath81 . for lebesgue almost every @xmath205 , @xmath206    0.25 cm the proof of this theorem , which is the point where the careful tuning of the perturbation is needed , has an interest of its own and is presented section [ sec : concmag ] .",
    "similar statements in the spin glass literature have been obtained by talagrand @xcite .",
    "the usual signature of replica symmetry breaking is the absence of concentration for the overlap parameter @xmath194 .",
    "this theorem combined with the nishimori identity  explains \" why the replica symmetry is not broken .",
    "we will also need the following corollary    [ cor : concmag ] the following holds @xmath207 with @xmath208 for almost every @xmath209 .    by the cauchy - schwartz inequality @xmath210 because of the concentration of the magnetization @xmath193 ( theorem [ thm : concmag ] ) it suffices to prove that @xmath211 for some constant @xmath212 independent of @xmath1 .",
    "the proof follows from the central limit theorem and is given in appendix [ apen : centrallimbound ] .",
    "we have @xmath214 = t_1 + t_2\\ ] ] where @xmath215 and @xmath216      integration by parts with respect to @xmath218 leads to @xmath219 to obtain the second equality we remark that the @xmath220 terms cancel and for the third one follows from . from the relation between @xmath130 and @xmath131 given in equation ( [ eqn : snrrelation ] ) , @xmath217 can be rewritten in the form @xmath221      the term @xmath222 can be rewritten as @xmath223 because of the first two terms cancel , @xmath224 now we use integration by parts with respect to @xmath13 , @xmath225 and the nishimori identity @xmath226 \\\\ & - \\frac { b^\\prime(t)\\sqrt{b(t)}}{2k n^{3/2}}\\sum_k{\\mathbb{e}}\\langle ( { \\underline{n}}\\cdot { \\textbf{s}}{\\underline{z}})(1-x_k)\\rangle_{t , u}\\end{aligned}\\ ] ] since @xmath227 concentrates on @xmath14 , we get @xmath228 applying corollary [ cor : concmag ] to the last expression for @xmath222 together with we obtain a closed affine equation for the later , whose solution is @xmath229      we add and subtract the term @xmath230 from and use the integral representation @xmath231 to obtain @xmath232 = { \\mathbb{e}}[f_{0,u}]-\\frac{1}{2\\beta}\\ln(1+\\beta b(1-m ) ) + \\int_0 ^ 1 dt\\biggl(\\frac{d}{dt}{\\mathbb{e}}[f_{t , u}]+\\frac { b'(t)(1-m)}{2(1+\\beta b(t ) ( 1-m))}\\biggr)\\ ] ] if one uses and expressions ( [ eqn : t1 ] ) , ( [ eqn : t2 ] ) some remarkable algebra occurs in the last integral .",
    "the integrand becomes @xmath233 with @xmath234 so the integral has a positive contribution @xmath235 plus a computable contribution equal to @xmath236 .",
    "finally thanks to we find @xmath237 & = \\int dz \\ln ( 2\\cosh(\\sqrt{\\lambda } z+ \\lambda ) )   - \\frac{1}{2\\beta } - \\frac{1}{2\\beta}\\ln ( 1+\\beta b(1-m ) ) \\nonumber \\\\ &    -\\frac{\\lambda}{2}(1+m ) + \\int_0 ^ 1 r(t ) dt + o_n(1)+ o(\\sqrt u ) \\label{eqn : free1}\\end{aligned}\\ ] ] where for a.e @xmath205 , @xmath238 .",
    "we take first the limit @xmath239 , then @xmath240 ( along some appropriate sequence ) and then @xmath241 to obtain a formula for the free energy where the only non - explicit contribution is @xmath242 . since this is positive for all @xmath62",
    ", we obtain a lower bound on the free energy which is equivalent to the announced upper bound on the capacity .",
    "the goal of this section is to prove theorem [ thm : concmag ] . the proof is organized in a succession of lemmas . by the same methods used for theorem [ thm : freeconc ]",
    "we can prove 0.25 cm    [ lem : freetuconc ] there exists a strictly positive constant @xmath243 ( which remains positive for all @xmath134 and @xmath179 ) such that @xmath244\\vert\\geq \\epsilon ] = o(e^{-\\alpha \\epsilon^2 \\sqrt k})\\ ] ]    0.25 cm    the perturbation term ( [ eqn : perturb ] ) has been chosen carefully so that the following holds , 0.25 cm    [ lem : ftuconvex ] when considered as a function of @xmath179 , @xmath245 is convex in @xmath179 .",
    "0.25 cm    we simply evaluate the second derivative and show it is positive .",
    "@xmath246 where we have defined @xmath247 differentiating again , @xmath248    0.25 cm the quantity @xmath249 turns out to be very useful and satisfies two concentration properties .",
    "0.25 cm    for any @xmath250 fixed , @xmath251    0.25 cm    from equation ( [ 2derivative ] ) , we have @xmath252 \\\\ & \\leq \\frac1k \\big(\\frac{d}{du}{\\mathbb{e}}[f_{t , a } ]   - \\frac{d}{du}{\\mathbb{e}}[f_{t,\\epsilon}]\\vert\\big ) = o\\big(\\frac1k \\big)\\end{aligned}\\ ] ] in the very last equality we use that the first derivative of @xmath253 $ ] is bounded for @xmath254 . using cauchy - schwartz inequality for @xmath255 we obtain the lemma .    0.25 cm    for any @xmath256 fixed , @xmath257    0.25 cm    from convexity of @xmath245 with respect to @xmath179 ( lemma [ lem : ftuconvex ] ) we have for any @xmath258 , @xmath259 \\leq \\frac{f_{t , u+\\delta } - f_{t , u}}{\\delta } - \\frac{d}{du } { \\mathbb{e}}[f_{t , u } ] \\\\ & \\leq \\frac{f_{t , u+\\delta } - { \\mathbb{e}}[f_{t , u+\\delta}]}{\\delta } - \\frac{f_{t , u}-{\\mathbb{e}}[f_{t , u}]}{\\delta }   \\\\&\\;\\;\\;\\;\\;+ \\frac{d}{du}{\\mathbb{e}}[f_{t , u+\\delta } ] - \\frac{d}{du}{\\mathbb{e}}[f_{t , u}]\\end{aligned}\\ ] ] a similar lower bound holds with @xmath260 replaced by @xmath261",
    ". now from lemma [ lem : freetuconc ] we know that the first two terms are @xmath262 .",
    "thus from the formula for the first derivative in the proof of lemma [ lem : ftuconvex ] and the fact that the fluctuations of @xmath263 are @xmath264 we get @xmath265 - \\frac{d}{du}{\\mathbb{e}}[f_{t , u}]\\end{aligned}\\ ] ] we will choose @xmath266 . note that we can not assume that the difference of the two derivatives is small because the first derivative of the free energy is not uniformly continuous in @xmath0 ( as @xmath67 it may develop jumps at the phase transition points ) .",
    "the free energy itself is uniformly continuous .",
    "for this reason if we integrate with respect to u , using we get @xmath267    using the two last lemmas we can prove theorem [ thm : concmag ] .",
    "0.25 cm _ proof of theorem [ thm : concmag ] : _ combining the concentration lemmas we get @xmath268 for any function",
    "@xmath269 such that @xmath270 , we have @xmath271 more generally the same thing holds if one takes a function depending on many replicas such as @xmath272 .",
    "using integration by parts formula with respect to @xmath159 , @xmath273 where in the last two equalities we used the nishimori identity ( [ eqn : mq ] ) . by a similar calculation , @xmath274 from equations ( [ eqn : lhslq ] ) and ( [ eqn : rhslq ] )",
    ", we get @xmath275 now integrating with respect to @xmath134 and exchanging the integrals ( by fubini s theorem ) , we get @xmath276 the limit of the left hand side as @xmath67 therefore vanishes . by lebesgue s theorem",
    "this limit can be exchanged with the @xmath179 integral and we get the desired result .",
    "( note that one can further exchange the limit with the @xmath134-integral and obtain that the fluctuations of @xmath193 vanish for almost every @xmath277 ) .",
    "we consider a communication system with spreading values @xmath278 generated from a symmetric distribution with unit variance and satisfying assumption a. we compare the capacity of this system to the gaussian @xmath279 case whose spreading sequence values are denoted by @xmath13 .",
    "the comparison is done through an interpolating system with respect to the two spreading sequences @xmath280 let @xmath281 denote the matrix with entries @xmath282 and let @xmath283 denote the @xmath284th row of the matrix . by the fundamental theorem of calculus",
    "the capacities are related by @xmath285-{\\mathbb{e}}_{{\\textbf{s}}}[c({\\textbf{s}})]=\\int_0 ^ 1dt \\frac{d}{dt}{\\mathbb{e}}_{{\\textbf{v}}(t)}[c({\\textbf{v}}(t))]\\ ] ] from the derivative is equal to @xmath286 = - { \\mathbb{e}}_{{\\textbf{s}}}{\\mathbb{e}}_{{\\textbf{r}}}\\frac{d}{dt } { \\mathbb{e}}_{{\\underline{y}}\\vert { \\textbf{v}}(t)}[f({\\underline{y } } , { \\textbf{v}}(t)]\\ ] ] as before we can assume that the transmitted sequence is @xmath287 .",
    "it is convenient to first perform the change of variables @xmath288 and then perform the @xmath134 derivative .",
    "one finds @xmath289   = \\frac{1}{\\sigma^2 k\\sqrt n } { \\mathbb{e}}_{{\\textbf{s}},{\\textbf{r}},{\\underline{n}}}\\big\\langle \\biggl({\\underline{n}}+ \\frac{1}{\\sqrt n}{\\textbf{v}}(t ) ( { \\underline{x}}^0-{\\underline{x}})\\biggr)\\cdot { \\textbf{v}}^\\prime(t)({\\underline{x}}^0-{\\underline{x } } )   \\big\\rangle_t\\end{aligned}\\ ] ] where @xmath290 is the average with respect to the normalized measure @xmath291 we split in two contributions @xmath292 corresponding to @xmath293 for @xmath217 we have @xmath294\\end{aligned}\\ ] ] with @xmath295 for @xmath222 we have @xmath296\\end{aligned}\\ ] ] with the same expression for @xmath297 . for each contribution in the sums , we use integration by parts formulas . for",
    "we use the formula ( it is an exercise to check that it is valid for any symmetric random variable ) @xmath298 &   = { \\mathbb{e}}[r_{ik}^2 \\frac{\\partial g(r_{ik})}{\\partial r_{ik } } ] - \\frac{1}{4}{\\mathbb{e}}\\biggl[\\vert r_{ik}\\vert\\int_{-\\vert r_{ik}\\vert}^{\\vert r_{ik}\\vert}(r_{ik}^2-u^2 ) \\frac{\\partial^3 g(u)}{\\partial u^3 } du\\biggr ] \\nonumber \\\\ = { \\mathbb{e}}[\\frac{\\partial g(r_{ik})}{\\partial r_{ik } } ] & + { \\mathbb{e}}\\biggl[(r_{ik}^2 - 1)\\int_0^{r_{ik } } \\frac{\\partial ^2 g(u)}{\\partial u^2 } du\\biggr ]   -\\frac{1}{4}{\\mathbb{e}}\\biggl[\\vert r_{ik}\\vert\\int_{-\\vert r_{ik}\\vert}^{\\vert r_{ik}\\vert}(r_{ik}^2-u^2 ) \\frac{\\partial^3 g(u)}{\\partial u^3 } du\\biggr]\\end{aligned}\\ ] ] and for we use the standard gaussian ( unit variance ) integration by parts formula @xmath299 & = { \\mathbb{e } } [ \\frac{\\partial g(s_{ik})}{\\partial s_{ik}}]\\end{aligned}\\ ] ] when we consider @xmath292 the term corresponding to the expectation in cancels with that of the first expectation in and we get @xmath300   -\\frac{1}{8\\sqrt{t}}\\sum_{i , k}{\\mathbb{e}}\\biggl[\\vert r_{ik}\\vert\\int_{-\\vert r_{ik}\\vert}^{\\vert r_{ik}\\vert}(r_{ik}^2-u^2 ) \\frac{\\partial^3 g_{ik}(u)}{\\partial u^3 } du\\biggr]\\end{aligned}\\ ] ] it remains to prove that both terms with the partial derivatives tend to zero as @xmath301 .",
    "this computation is rather lengthy and is deferred to appendix [ appen : independence ] , but for the convenience of the reader we point out the mechanism that is at work . on the expression for @xmath297 one sees that when the @xmath302 and @xmath303 derivatives are performed extra powers @xmath304 and @xmath305 are generated .",
    "therefore we get @xmath306=o(n^{-5/2})\\ ] ] and @xmath307 = o(n^{-3})\\ ] ] since one sums over @xmath308 terms one finds that the final contributions are @xmath309 and @xmath310 .",
    "let us recall the following relation between the free energy and the capacity . @xmath311\\end{aligned}\\ ] ] where @xmath312 is defined in with @xmath313 .",
    "this implies that it is sufficient to show the existence of limit for the average free energy @xmath314 $ ] .",
    "the theorem is proved by showing that the sequence @xmath315 is super additive , @xmath316 for @xmath317 . from standard theorems",
    "it then follows that the limit @xmath318 exists . as in the previous sections , working directly with this system",
    "is difficult and hence we perturb the hamiltonian with @xmath319 as defined in .",
    "@xmath320 let us define the corresponding partition function as @xmath321 and the free energy as @xmath322 $ ] .",
    "the original free energy is obtained by substituting @xmath323 , i.e. , @xmath324 . from the uniform continuity of @xmath325 , it is sufficient to show the convergence of @xmath325 for some @xmath179 close to zero .",
    "even this turns out to be difficult and what we can show is the existence of the limit @xmath326 for any @xmath327 .",
    "however this is sufficient for us due to the following : from the continuity of the free energy with @xmath179 we have @xmath328 since the limit of the integral exists , we have @xmath329 can be made as small as desired and hence the theorem follows .",
    "let @xmath317 and let @xmath330 .",
    "this assumption can be removed by considering their integer parts .",
    "but we will stick to this assumption to simplify the proof .",
    "split the @xmath23 dimensional spreading matrix @xmath22 in to two parts of dimension @xmath331 and @xmath332 and denote these matrices by @xmath333 respectively .",
    "let @xmath334 be two spreading matrices with dimensions @xmath335 and @xmath336 .",
    "all the entries of these matrices are distributed as @xmath337 and the noise is gaussian with variance @xmath12 . similarly split the noise vector @xmath338 where @xmath339 is of length @xmath340 and @xmath341 where @xmath342 is of length @xmath343 .",
    "let us consider the following hamiltonian :    @xmath344    note that the all - one vectors @xmath345 appearing above are of different dimensions ( the dimension is clear from the context ) .",
    "for a moment neglect the @xmath319 part of the hamiltonian and consider the remaining part . at @xmath346",
    ", we get the hamiltonian corresponding to an @xmath23 cdma system with spreading matrix @xmath347 $ ] . at @xmath123",
    "we get the hamiltonian corresponding to two independent cdma systems with spreading matrices @xmath348 of dimensions @xmath349 . as before we perturb the hamiltonian with @xmath319 so that we can use the concentration results for the magnetization .",
    "let @xmath168 be the partition function with this hamiltonian and the corresponding average free energy is given by @xmath350 $ ] .",
    "note that @xmath351 and @xmath352 .",
    "from the fundamental theorem of calculus , @xmath353 let @xmath354 , @xmath355 . using integration by parts formula with respect to the spreading sequences ,",
    "the derivative can be simplified as follows @xmath356 the system with hamiltonian @xmath357 has nishimori symmetry and hence we can derive results similar to theorem  [ thm : concmag ] and lemma [ lem : nishimori1 ] .",
    "in addition to these we need one more nishimori identity which we did not use before .",
    "@xmath358 let @xmath359 let @xmath360 be fixed . using @xmath361 and theorem  [ thm : concmag ] , for a.e . ,",
    "@xmath205 and a.e . ,",
    "@xmath362 , we get @xmath363 now using integration by parts formula with respect to the spreading sequences , and doing transformations similar to section [ sec : transformingt2 ] , we get for a.e .",
    ", @xmath205 and a.e . ,",
    "@xmath362 , @xmath364 let us define a function @xmath365 as follows , @xmath366 note that for @xmath367 , @xmath368 we get the summation in .",
    "when @xmath369 satisfy @xmath370 the function @xmath365 has the following useful properties : @xmath371 and the derivative with @xmath134 of this function given by @xmath372 therefore for any @xmath369 satisfying , @xmath373 and hence we can claim the summation in is also non - positive .    bringing the @xmath374 in to the left",
    ", we get for a.e . ,",
    "@xmath375 , @xmath376 therefore for a.e .",
    ", @xmath377 , we get @xmath378 let @xmath379 be a constant .",
    "then @xmath380 which implies @xmath381 which in turn implies that @xmath382 exists .",
    "in this section we briefly describe three variations for which our methods extend in a straightforward manner .",
    "suppose that the users transmit with unequal powers @xmath383 , @xmath384 with normalized average power @xmath385 .",
    "we assume that the empirical distribution of the @xmath383 tends to a distribution and denote the corresponding expectation by @xmath386 $ ] .",
    "the interpolation method can be applied as before .",
    "we interpolate between the true communication system and a decoupled one where @xmath387 let @xmath388 denote the diagonal matrix @xmath389 .",
    "the relevant posterior measure replacing is now @xmath390 where @xmath130 and @xmath131 are related as in .",
    "the whole analysis can again be performed in exactly the same manner with the proviso that the correct  order parameters \" are now @xmath391 and @xmath392 .",
    "one finds in place of @xmath237 = & -\\frac{1}{2\\beta } + { \\mathbb{e}}_{p}\\biggl[\\int dz \\ln(2\\cosh(\\sqrt { p\\lambda } z+ p\\lambda))\\biggr]\\\\ & -\\frac{\\lambda}{2}(1+m)-\\frac{1}{2\\beta}\\ln(1+\\beta b(1-m ) ) + \\int_0 ^ 1 r(t ) dt\\end{aligned}\\ ] ] where @xmath393 has the same form as before but the with new definition of @xmath193 . from the positivity of @xmath393 we deduce the upper bound on the capacity with @xmath118 replaced by @xmath394+\\frac{\\lambda}{2}(1+m ) -\\frac{1}{2\\beta}\\ln\\lambda\\sigma^2\\ ] ]      now consider the scenario where @xmath395 with colored noise of finite memory .",
    "more precisely we assume that the the covariance matrix @xmath396=c(i , j)$ ] ( depends on @xmath397 ) is circulant as @xmath398 and has well defined ( real ) fourier transform ( the noise spectrum ) @xmath399 .",
    "the covariance matrix is real symmetric and thus can be diagonalized by an orthogonal matrix : @xmath400 with @xmath401 . as @xmath301 the eigenvalues",
    "are well approximated by @xmath402 .",
    "multiplying the received signal by @xmath403 the input - output relation becomes @xmath404 where @xmath405 the new noise vector @xmath406 is white with unit variance , but the spreading matrix is now correlated with @xmath407=\\delta_{ij}\\delta_{kl}\\gamma_i^{-1}\\ ] ] one may guess that this time the interpolation is done between the true system and the decoupled channels @xmath408 where this time @xmath409 note that @xmath410 when the noise is white and we get back the @xmath121 defined in .",
    "the interpolating system has the same posterior as in but with @xmath411 and @xmath131 related by @xmath412 the only difference in the subsequent analysis is in the algebraic manipulations for the term @xmath222 in section [ sec : transformingt2 ] .",
    "indeed these require integrations by parts with respect to the spreading sequence which involve .",
    "the analog of now becomes @xmath413 this finally leads to the bound on capacity with @xmath118 replaced by , @xmath414      the interpolation method also works for non binary inputs .",
    "here we consider the simplest case of gaussian inputs with distribution ( which achieves the maximum of the mutual information for any symmetric @xmath13 ) . here",
    "we outline the necessary changes in the analysis .",
    "the interpolation is done as explained in section [ sec : upperbound ] except that is multiplied by the gaussian distribution . in we also have to include this gaussian factor and the sum over @xmath415 is replaced by an integral .",
    "then as in section [ sec : preliminaries ] we do the change of variables @xmath416 and @xmath417 .",
    "the posterior measure used for the interpolation becomes @xmath418 and we have to compute @xmath419 $ ] .",
    "the main difference is that now the expectation @xmath174 is also with respect to the gaussian vector @xmath415 .",
    "the algebra is done as in section [ sec : upperboundproof ] except that @xmath420 is not set to one , @xmath421 is replaced by @xmath422 and the correct order parameters are @xmath423 and @xmath424 .",
    "the interpolation method then yields in place of @xmath237 & = -\\frac{1}{2\\beta } -\\frac12 \\ln(1+\\lambda ) - \\frac{1}{2\\beta}\\ln(1+\\beta b(1-m ) ) \\\\&+ \\frac{\\lambda}{2}(1-m ) + \\int_0 ^ 1 r(t ) dt + o(\\sqrt u)\\end{aligned}\\ ] ] where @xmath393 is the same function as before but with new definition of @xmath193 . again",
    "the positivity of @xmath393 implies that the replica solution is an upper bound to the capacity .",
    "in this contribution we have shown that the capacity of binary input cdma system with random spreading is upper bounded by the formula conjectured by tanaka using replica method .",
    "the approach we follow is by developing an interpolation method for this system .",
    "this idea has its origins in statistical mechanics and has been applied to gaussian energy models .",
    "the current system is very much different from those models and the proof we develop is also significantly different .",
    "in fact this model is closer to the hopfield model for neural networks , for which the interpolation method is still an open problem .",
    "we also show that the capacity and the free energy functions concentrate around their average in the large - system limit .",
    "in addition we prove a weak concentration for the magnetization for a system which is slightly perturbed using a gaussian field .",
    "it might be interesting to show a similar result for the cdma system itself which has some implications towards proving the concentration of the ber .",
    "we also show the independence of the capacity from the spreading sequence distributions in the large - system limit .",
    "we expect that the powerful probabilistic tools used here have applications for other similar situations in communication systems .",
    "we have shown some of the extensions here but there are many other cases like constellations other than binary , cdma with ldpc coded communication to name a few , to which this method can be applied . in all these cases",
    "we can prove an upper bound on the capacity .",
    "the most interesting and also important open problem is to prove the lower bound .",
    "this seems to be a difficult problem and again the standard techniques fail .",
    "other important problems are proving the conjectures related to the ber of various decoders .",
    "[ appendix ]",
    "replacing ( [ eqn : postdist ] ) in the conditional entropy @xmath425\\nonumber \\\\ & = { \\mathbb{e}}_{{\\underline{y}}}\\biggl[\\sum_{{\\underline{x } } } p({\\underline{x}}\\vert { \\underline{y}},{\\textbf{s}})\\ln z({\\underline{y}},{\\textbf{s}})\\biggr ] + { \\mathbb{e}}_{{\\underline{y}}}\\biggl[\\sum_{{\\underline{x } } } p({\\underline{x}}\\vert { \\underline{y}},{\\textbf{s}})\\frac{1}{2\\sigma^2 } \\vert n^{-\\frac{1}{2}}{\\textbf{s}}{\\underline{x}}-{\\underline{y}}\\vert^2\\biggr]\\\\ \\nonumber & -{\\mathbb{e}}_{{\\underline{y}}}[\\sum_{{\\underline{x}}}p({\\underline{x}}\\mid{\\underline{y}},{\\textbf{s}})\\ln p_{{\\underline{x}}}({\\underline{x}})]\\end{aligned}\\ ] ] the first term on the r.h.s is equal to @xmath426 $ ] because @xmath427 .",
    "the second term on the r.h.s can be computed exactly .",
    "indeed , @xmath428\\nonumber \\\\ & = \\int d{\\underline{y}}\\frac{z({\\underline{y } } , { \\textbf{s}})}{(\\sqrt{2\\pi\\sigma^2})^n}\\sum_{{\\underline{x } } } p({\\underline{x}}\\vert { \\underline{y}},{\\textbf{s}})\\frac{1}{2\\sigma^2}\\vert n^{-\\frac{1}{2}}{\\textbf{s}}{\\underline{x}}-{\\underline{y}}\\vert^2 \\nonumber \\\\ & = \\sum_{{\\underline{x}}}p_{{\\underline{x}}}({\\underline{x}})\\int d{\\underline{y}}\\frac{1}{(\\sqrt{2\\pi\\sigma^2})^n}e^{-\\frac{1}{2\\sigma^2}\\vert n^{-\\frac{1}{2}}{\\textbf{s}}{\\underline{x}}-{\\underline{y}}\\vert^2 } \\nonumber\\\\ & \\times \\frac{1}{2\\sigma^2}\\vert n^{-\\frac{1}{2}}{\\textbf{s}}{\\underline{x}}-{\\underline{y}}\\vert^2 \\nonumber \\\\ & = \\frac{n}{2 } =   \\frac{k}{2\\beta}\\nonumber\\end{aligned}\\ ] ] a similar calculation shows that the third term is equal to @xmath429 .",
    "therefore the relation between shannon s conditional entropy and the free energy is @xmath430 + \\frac{k}{2\\beta } + h({\\underline{x}})\\ ] ] this is equivalent to the announced relation .",
    "our proofs rely on a general concentration theorem for suitable lipschitz functions of many gaussian random variables @xcite , @xcite and",
    "this is why we need gaussian signature sequences . in the version that we use here",
    "we need functions that are lipschitz with respect to the euclidean distance .",
    "more precisely we say that a function @xmath431 is a lipschitz function with constant @xmath432 if for all @xmath433 @xmath434 when another distance is used the function will still be lipschitz but one has to carefully keep track of the possibly qualitatively different @xmath435 dependence .",
    "0.25 cm    @xcite[gauss_conc ] let @xmath436 be @xmath435 independent identically distributed gaussian random variables with distribution @xmath437 and let @xmath438 be lipschitz with respect to the euclidean distance , with constant @xmath432",
    ". then @xmath97 satisfies @xmath439\\vert \\geq t ] \\leq 2e^{-\\frac{t^2}{2v^2 l_m^2}}\\ ] ]    0.25 cm    in our application it will not be possible to apply directly this theorem because the relevant function is lipschitz only on a subset @xmath440 .",
    "it turns out that the measure of the complement @xmath441 is negligible as @xmath442 . for the `` good part '' of the function supported on @xmath443 we will use the following result of mcshane and whitney    0.25 cm    @xcite[shane - whitney ] let @xmath444 , be lipschitz over @xmath445 with constant @xmath432 .",
    "then there exists an extension @xmath446 such that @xmath447 which is lipschitz with the same constant over the whole of @xmath448 .    from these two theorems",
    "we can prove the following .",
    "0.25 cm    [ littlelemma ]    let @xmath97 and @xmath98 be as in theorem [ shane - whitney ] .",
    "assume @xmath449 and @xmath450\\leq c^2 $ ] , @xmath451 for some positive number @xmath452 .",
    "then for @xmath453 we have @xmath454 \\vert \\geq t]\\leq 2e^{-\\frac{t^2}{8v^2 l_m^2 } } + p[g^c]\\ ] ]    0.25 cm    we drop the @xmath455 dependence to lighten the notation . notice that @xmath449 implies @xmath456 .",
    "thus @xmath457 .",
    "also , since @xmath98 is lipschitz on the whole of @xmath448 @xmath458&\\leq 2(g(0)^2 + { \\mathbb{e}}[(g - g(0))^2])\\nonumber \\\\ & \\leq 2(c^2+l_m{\\mathbb{e}}[\\vert { \\underline{u}}^2\\vert)\\nonumber \\\\&=2(c^2+m v^2l_m)\\nonumber\\end{aligned}\\ ] ] furthermore on @xmath443 we have @xmath459 , so by the cauchy - schwartz inequality @xmath460\\vert&= \\vert{\\mathbb{e}}[(g - f)1_{g^c}]\\vert\\nonumber \\\\ & \\leq ( { \\mathbb{e}}[g^2]^{1/2}+{\\mathbb{e}}[f^2]^{1/2})\\sqrt{{\\mathbb{p}}[g^c ] } \\nonumber \\\\ & \\leq ( c + \\sqrt{2}(c^2+m v^2l_m)^{1/2 } ) \\sqrt{\\mathbb{p}[g^c ] } \\nonumber   \\\\ & \\leq 3(c+ v\\sqrt{m}l_m)\\sqrt{\\mathbb{p}[g^c ] } \\leq \\frac{t}{2}\\nonumber\\end{aligned}\\ ] ] moreover @xmath461   & = \\mathbb{p}[\\vert g - { \\mathbb{e}}f\\vert \\geq t\\mid { \\underline{u}}\\in g]\\mathbb{p}[g ] \\nonumber \\\\&\\,\\,\\,\\,\\,\\ , + { \\mathbb{p}}[\\vert f - { \\mathbb{e}}f\\vert \\geq t\\mid { \\underline{u}}\\in g^c]\\mathbb{p}[g^c]\\nonumber \\\\ & \\leq \\mathbb{p}[\\vert g - { \\mathbb{e}}g\\vert \\geq t - \\vert { \\mathbb{e}}g - { \\mathbb{e}}f \\vert ] + \\mathbb{p}[g^c]\\nonumber\\end{aligned}\\ ] ] the result of the lemma then follows from @xmath462\\leq \\mathbb{p}[\\vert g - { \\mathbb{e}}g\\vert \\geq \\frac{t}{2}]\\ ] ] and the application of theorem [ gauss_conc ] .    0.25 cm in order to prove theorems [ thm : capconc ] and [ thm : freeconc ] it will be sufficient to find suitable sets @xmath443 with measure nearly equal to one ( as @xmath463 ) , on which the capacity and free energy have a lipschitz constant @xmath464 .",
    "for the proofs , it is convenient to reformulate the statements of the theorems as follows . let @xmath465 be the @xmath0 dimensional vector @xmath466 , @xmath467 be the @xmath468 matrix with elements @xmath469 .",
    "we set @xmath470 and consider the partition function @xmath471 where we recall that @xmath472 are independent gaussian variables @xmath337 . notice that due to the invariance of the distribution of @xmath13 under the transformation @xmath473 , @xmath474={\\mathbb{e}}_{{\\underline{n}},{\\textbf{s}}}[\\ln z^\\prime({\\underline{n}},{\\textbf{s}})]\\ ] ] the statements of theorems [ thm : capconc ] and [ thm : freeconc ] are equivalent to @xmath475 - & { \\mathbb{e}}_{{\\underline{n}},{\\textbf{s}}}[\\ln z^\\prime({\\underline{n}},{\\textbf{s}})]\\vert\\geq tk ] \\leq 3 e^{-\\alpha_1 t^2{n}}\\end{aligned}\\ ] ] and @xmath476\\vert\\geq tk]\\leq 3 e^{-\\alpha_2 t^2\\sqrt{n}}\\ ] ] to see this use the change of variable @xmath477 followed by @xmath478 in the partition function summation .",
    "let @xmath127 be a positive constant to be chosen later and define @xmath479 0.25 cm    [ measbadset ]    we have the following estimate for the measure of @xmath441 , @xmath480    0.25 cm    first notice that for any given @xmath481 , @xmath482 are independent gaussian random variables with zero mean and variance @xmath483 smaller than @xmath484 .",
    "thus the identity @xmath485 implies ( because @xmath486 ) @xmath487\\leq 2^{\\frac{n}{2}}\\ ] ] then from the markov inequality , for any @xmath481 @xmath488 the result of the lemma then follows from the union bound over @xmath489 possible @xmath490 vectors .    0.25 cm    we will apply lemma [ measbadset ] to @xmath491\\end{aligned}\\ ] ] for a suitable choice of @xmath127 . in the application",
    "the matrix @xmath22 is to be thought as a vector with @xmath308 components and norm @xmath492    clearly @xmath449 and @xmath493)^2 = 1/4\\beta^2 $ ] .",
    "also it is evident that @xmath494 . on the other hand",
    "restricting the sum in the partition function to @xmath495 we have @xmath496\\geq -\\frac{1}{2\\sigma^2k}{\\mathbb{e}}_{{\\underline{n}}}[\\sigma^2\\vert { \\underline{n}}\\vert^2]-\\frac{1}{k } h({\\underline{x}})\\geq -\\frac{n}{2k}-\\ln 2\\ ] ] therefore we have @xmath497\\leq ( \\frac{1}{2\\beta}+\\ln 2)^2\\ ] ]    let us now compute the lipschitz constant . 0.25 cm    [ lipconst1 ] @xmath498 $ ] is lipschitz on @xmath443 , with constant @xmath499    0.25 cm    the exponent of the partition function is @xmath500 in the section [ appen : lipschitzh1 ] we show that for @xmath501    @xmath502    using this inequality together with @xmath503 we have for @xmath501 @xmath504 therefore taking the expectation over the noise , we get @xmath505- \\sum_{{\\underline{x}}^0}p_{{\\underline{x}}}({\\underline{x}}^0){\\mathbb{e}}_{{\\underline{n}}}[\\ln z^\\prime({\\underline{n}},{\\textbf{t}}^0)]\\vert\\nonumber \\\\ & \\leq \\sigma^{-2}2\\sqrt\\beta(\\sqrt b+\\sigma{\\mathbb{e}}[\\vert { \\underline{n}}\\vert])\\vert { \\textbf{s}}-{\\textbf{t}}\\vert \\nonumber \\\\ & \\leq \\sigma^{-2}2\\sqrt\\beta(\\sqrt b+\\sigma{\\mathbb{e}}[\\vert { \\underline{n}}\\vert^2]^{1/2})\\vert { \\textbf{s}}-{\\textbf{t}}\\vert \\nonumber\\end{aligned}\\ ] ] which yields the lipschitz constant of the lemma .",
    "0.25 cm    finally ( [ reform1 ] ) follows from lemmas [ littlelemma ] , [ measbadset ] and [ lipconst1 ] with the choice @xmath506 .",
    "we obtain @xmath507 .",
    "this case is more cumbersome but the ideas are the same .",
    "we choose the set @xmath443 as @xmath508 where , as before @xmath19 and @xmath127 will be chosen appropriately later on . for gaussian noise @xmath509\\leq 4 e^{-\\frac{a}{4}}$",
    "] therefore from the union bound @xmath510 .",
    "using lemma [ measbadset ] we obtain an estimate for the measure of @xmath441 , @xmath511\\leq 4n e^{-\\frac{a}{4}}+2^{k+\\frac{n}{2}}e^{-\\frac{b}{16\\beta}}\\ ] ]    the goal is to apply lemma [ littlelemma ] to @xmath512 defined on @xmath513 .    clearly @xmath514 , @xmath515 and by the same argument as before we have @xmath516\\leq ( \\frac{1}{2\\beta}+ \\ln 2)^2=c^2 $ ] .",
    "it remains to compute the lipschitz constant .",
    "0.25 cm    [ lipconst2 ] the free energy @xmath517 is lipschitz on @xmath443 with constant @xmath518    0.25 cm    for the same hamiltonian ( [ ham ] ) we show in section [ appen : lipschitzh2 ] @xmath519 then proceeding in the same way as in the proof of lemma [ lipconst1 ] we get @xmath520    we can now conclude the proof of ( [ reform2 ] ) by collecting the previous results and choosing @xmath521 and @xmath522 .",
    "this gives @xmath523 .",
    "let @xmath524 , @xmath525 be two noise realizations and @xmath22 , @xmath526 two spreading sequences all belonging to the appropriate set @xmath443 .",
    "let @xmath527 .",
    "first we expand the euclidean norms @xmath528 we estimate each of the four terms on the right hand side of the last equality . by cauchy - schwartz the first term is bounded by @xmath529 using cauchy - schwartz and @xmath530 where @xmath531 is the ( hilbert - schmidt ) norm , @xmath532 we obtain for the second term the estimate @xmath533 similarly the third term is bounded by , @xmath534 and the fourth one by @xmath535 collecting all four estimates we obtain @xmath536 where the last norm is the euclidean norm in @xmath537 .",
    "let @xmath22 and @xmath526 be two spreading sequences both belonging to the appropriate @xmath443 .",
    "let @xmath527 .",
    "following similar steps as in the previous paragraph with @xmath538 the result can be read off @xmath539",
    "the idea of this proof is based on @xcite,@xcite .    here , for simplicity of notation and without loss of generality , we assume the noise variance to be @xmath14 and the second and fourth moments of spreading sequences to be less than @xmath14 . for @xmath540 , let @xmath541 be the sigma algebra generated by @xmath542 . and set @xmath543,\\quad \\psi_l = f_l - f_{l-1}\\end{aligned}\\ ] ] then @xmath544)^2 & = \\sum_{l=1}^{k}{\\mathbb{e}}[\\psi_l^2]\\end{aligned}\\ ] ] the goal is to bound each term in this sum by @xmath545 .",
    "here we use the following form of the mutual information @xmath546\\end{aligned}\\ ] ] where , @xmath547 in the above expanded form , the first two terms do not involve @xmath481 and hence the concentration of these terms follows very easily .",
    "therefore , in the rest of the proof we consider the hamiltonian with only the remaining two terms . from now on in the notation , we do not explicitly show the dependency of @xmath548 on @xmath50 and @xmath481 . to this end",
    "we define the following three hamiltonians .",
    "@xmath549 where @xmath122 $ ] will play the role of an interpolating parameter .",
    "we also introduce the difference of free energies associated to the hamiltonian @xmath550 and @xmath551 , @xmath552 in the last definition the partition function is defined by the usual summation over all configurations @xmath481 .    with these definitions we have the representation @xmath553 where @xmath554 means expectation with respect to @xmath555 .",
    "using convexity in the form of @xmath556 ^ 2 \\leq { \\mathbb{e}}_{\\geq l+1}[\\tilde{f}_l(1)^2]$ ] , it follows that @xmath557   & \\leq \\frac{1}{k^2}{\\mathbb{e}}{\\mathbb{e}}_{\\geq l+1}\\tilde{f}_l(1)^2 + \\frac{1}{k^2}{\\mathbb{e}}{\\mathbb{e}}_{\\geq l}\\tilde{f}_l(1)^2   \\\\&- \\frac{2}{k^2 } { \\mathbb{e}}[({\\mathbb{e}}_{\\geq l+1}\\tilde{f}_l(1)|\\phi_{l-1})({\\mathbb{e}}_{\\geq l}\\tilde{f}_l(1 ) ) ] \\\\ & = \\frac{2}{k^2 } { \\mathbb{e}}\\tilde{f}_l(1)^2 - \\frac{2}{k^2 } { \\mathbb{e}}[({\\mathbb{e}}_{\\geq l}\\tilde{f}_l(1))^2]\\\\ & \\leq \\frac{2}{k^2 } { \\mathbb{e}}\\tilde{f}_l(1)^2\\end{aligned}\\ ] ] notice that @xmath558 and @xmath559 .",
    "therefore , @xmath560 and @xmath561   \\leq { \\mathbb{e}}[\\tilde{f}_l'(0)^2 ] + { \\mathbb{e}}[\\tilde{f}_l'(1)^2]\\ ] ] this shows that our task is reduced to a proof of @xmath562 = o(1)$ ] , @xmath563 = o(1)$ ] .",
    "this is a technical calculation and is given in the next lemma .",
    "[ lem : bounddf0df1 ] @xmath564 = o(1),\\quad { \\mathbb{e}}[(\\tilde{f}_l'(1))^2 ] = o(1)$ ]    0.25 cm    from convexity , @xmath565 we will find a uniform bound for each term in the above sum over @xmath50 .",
    "let us consider a particular term in the above sum and set @xmath566 .",
    "we use the simple bound of @xmath567 in the following and hence we remove the average over @xmath50 .",
    "@xmath568 \\leq   12 \\\\&+ 3{\\mathbb{e}}\\big\\langle\\sum_{k_1,k_2\\neq l}\\frac{1}{n^2}\\sum_{i_1,i_2}s_{i_1k_1}s_{i_1l}s_{i_2k_2}s_{i_2l}z_{0k_1}z_{0k_2}z_{0l}^2\\big\\rangle_{\\tilde h_l(0)}\\\\&+3{\\mathbb{e}}\\big\\langle\\frac{1}{n}\\sum_{i_1,i_2}n_{i_1}n_{i_2}s_{i_1l}s_{i_2l}\\big\\rangle_{\\tilde{h}_l(0)}\\end{aligned}\\ ] ] since @xmath569 does not depend on @xmath570 and since they are symmetric random variables , in the above sums only those terms remain where @xmath570 are repeated even number of times .",
    "let @xmath571 and @xmath572 denote its largest singular value .",
    "therefore , @xmath573 & \\leq 12 + 3{\\mathbb{e}}\\big\\langle\\sum_{k_1k_2}\\frac{1}{n}j_{k_1,k_2}z_{0k_1}z_{0k_2}z_{0l}^2\\big\\rangle_{\\tilde h_l(0 ) }   + 3\\\\ & \\leq 15 + 3\\times2 ^ 4{\\mathbb{e}}\\vert j\\vert + 3 = o(1)\\end{aligned}\\ ] ] where we use that @xmath574 . for bounding @xmath575",
    "$ ] we use symmetry of the indices and take the sum over @xmath576 and divide by @xmath0 .",
    "let @xmath577 .",
    "@xmath578 & \\leq 12 + 3 { \\mathbb{e}}\\big\\langle\\frac1k\\sum_l\\sum_{k_1,k_2}j_{lk_1}j_{lk_2}z_{0k_1}z_{0k_2}z_{0l}^2\\big\\rangle\\\\ & + 3{\\mathbb{e}}\\big\\langle\\frac1k\\frac{1}{n}\\sum_{i_1,i_2}n_{i_1}n_{i_2}\\sum_{l}s_{i_1l}s_{i_2l}\\big\\rangle\\\\ & \\leq 12 + 6\\times2 ^ 4 { \\mathbb{e}}\\vert j\\vert^2 + 3{\\mathbb{e}}[\\vert a\\vert\\frac{1}{n}\\sum_{i}(n_{i})^2]\\\\ & = 12 + 96{\\mathbb{e}}\\vert j\\vert^2 + 3 { \\mathbb{e}}\\vert a\\vert = o(1)\\end{aligned}\\ ] ] in order to estimate @xmath579 and @xmath580 one can use standard methods ( see for example @xcite )",
    "let @xmath581 and @xmath582 denote the vector @xmath583 .",
    "let us split the contribution from @xmath584 in to @xmath585 corresponding to the two terms appearing in . for @xmath586 , we get @xmath587\\end{aligned}\\ ] ] where @xmath588 denotes the function in with @xmath589 .",
    "let @xmath590 denote the gibbs measure with @xmath589 .",
    "let @xmath591 denote the vector @xmath283 with @xmath278 replaced by @xmath179 .",
    "we now show that the term inside the integral decays with @xmath1 .",
    "@xmath592    @xmath593    the hamiltonians corresponding to @xmath594 and @xmath590 are @xmath595 where @xmath596 differs from @xmath281 only in the @xmath597th entry with @xmath179 replacing @xmath278 .",
    "expanding @xmath598 , @xmath599 let the sum of the first two terms be denoted as @xmath600 and the terms involving @xmath179 be @xmath601 .",
    "consider the following set @xmath602 for sufficiently large @xmath452 we have @xmath603 for some constant @xmath94 .",
    "if @xmath604 , then for all @xmath605 @xmath606 therefore for the first term in the equation @xmath607 the expectation over @xmath441 can be bounded as @xmath608 .",
    "therefore the last two terms contribute @xmath609 .",
    "for the first term after we have removed the terms with @xmath179 dependence , the hamiltonian @xmath610 satisfies nishimori symmetry .",
    "therefore we get the first term to be equal to , @xmath611 note that the above integral is a gaussian integral and can be evaluated easily . using similar method",
    ", we can show that @xmath612 \\leq o(1)e^{\\frac{3c'(u)}{\\sigma^2 } } + o(n^{-\\frac12})|u|^3\\end{aligned}\\ ] ] the exponent @xmath613 is due the occurrence of @xmath613 replicas in the equation .",
    "therefore , @xmath614 du\\big]\\nonumber\\\\ \\leq & { \\mathbb{e}}_{r_{ik}}\\big[r_{ik}^2\\int_{0}^{r_{ik } } n^{-\\frac52}(o(1)e^{3\\frac{c'(u)}{\\sigma^2 } } + o(n^{-\\frac12}|u|^3))du\\big]\\nonumber\\\\ \\leq &   o(n^{-\\frac52 } )   \\end{aligned}\\ ] ] where we have used the assumption a for the distribution of @xmath278 . now summing this over all @xmath615 we get @xmath616 . for this",
    "we have to evaluate the following term .",
    "@xmath617 we can prove along similar lines that @xmath618 .",
    "_ proof of lemma [ lem : nishimorimq ] . _",
    "we only give a brief sketch because the method is standard ( see for example @xcite ) .",
    "one writes fully explicitly the expression for @xmath619 and performs the gauge transformation @xmath620 , @xmath621 where @xmath50 is an arbitrary binary sequence .",
    "since @xmath619 does not depend on @xmath50 we sum over all such @xmath152 sequences and obtain a lengthy expression .",
    "exactly the same procedure is applied to @xmath622 and one gets another lengthy expression .",
    "then one can recognize that these two expressions are the same .",
    "+   + _ proof of lemma [ lem : nishimori2 ] .",
    "_    _ proof of .",
    "_ we will prove it for @xmath124 and for general @xmath134 it is similar .",
    "let the transmitted sequence be the all one sequence , and the received vector be @xmath623 where @xmath624 .",
    "the proof follows by using gauge symmetry .",
    "let @xmath455 denote the @xmath0 dimensional vector @xmath625 .",
    "@xmath626 & = { \\mathbb{e}}_{{\\textbf{s}}}\\big[\\int\\frac{1}{(2\\pi u)^{\\frac{k}{2}}(2\\pi\\sigma^2)^{\\frac{n}{2 } } } e^{-\\frac{\\vert{\\underline{h}}-{\\underline{u}}\\vert^2}{2u}}e^{-\\frac1{2\\sigma^2 } \\vert{\\underline{r}}- n^{-\\frac12}{\\textbf{s}}\\vert^2 } \\langle\\vert{{\\underline{{\\cal z}}}}\\vert^2\\rangle_{1,u } d{\\underline{r}}\\ ; d{\\underline{h}}\\big]\\nonumber\\\\   & = { \\mathbb{e}}_{{\\textbf{s}}}\\big[\\int \\frac{1}{(2\\pi u)^{\\frac{k}{2}}(2\\pi \\sigma^2)^{\\frac{n}{2}}}e^{-\\frac{\\vert{\\underline{h}}\\vert^2}{2u } + { \\underline{h}}\\cdot{\\underline{1}}-\\frac{ku}{2}}e^{-\\frac1{2\\sigma^2 } \\vert{\\underline{r}}- n^{-\\frac12}{\\textbf{s}}\\vert^2 } \\frac{\\sum_{{\\underline{x}}}e^{-\\frac1{2\\sigma^2 } \\vert{\\underline{r}}- n^{-\\frac12}{\\textbf{s}}{\\underline{x}}\\vert^2+{\\underline{h}}\\cdot{\\underline{x}}}\\vert{{\\underline{{\\cal z}}}}\\vert^2}{\\sum_{{\\underline{x}}}e^{-\\frac1{2\\sigma^2 } \\vert{\\underline{r}}- n^{-\\frac12}{\\textbf{s}}{\\underline{x}}\\vert^2+{\\underline{h}}\\cdot{\\underline{x } } } } d{\\underline{r}}\\;d{\\underline{h}}\\big]\\nonumber\\\\   & = \\frac{1}{2^{k}}{\\mathbb{e}}_{{\\textbf{s}}}\\big[\\int \\frac{1}{(2\\pi u)^{\\frac{k}{2}}(2\\pi \\sigma^2)^{\\frac{n}{2}}}e^{-\\frac{\\vert{\\underline{h}}\\vert^2}{2u } -\\frac{ku}{2}}\\sum_{{\\underline{x}}^0}e^{-\\frac1{2\\sigma^2 }",
    "\\vert{\\underline{r}}- n^{-\\frac12}{\\textbf{s}}{\\underline{x}}^0\\vert^2 + { \\underline{h}}\\cdot{\\underline{x}}^0 } \\nonumber\\\\ & \\quad\\quad\\quad\\quad\\quad\\quad \\frac{\\sum_{{\\underline{x}}}e^{-\\frac1{2\\sigma^2 } \\vert{\\underline{r}}- n^{-\\frac12}{\\textbf{s}}{\\underline{x}}\\vert^2+{\\underline{h}}\\cdot{\\underline{x}}}\\vert{{\\underline{{\\cal z}}}}\\vert^2}{\\sum_{{\\underline{x}}}e^{-\\frac1{2\\sigma^2 } \\vert{\\underline{r}}- n^{-\\frac12}{\\textbf{s}}{\\underline{x}}\\vert^2+{\\underline{h}}\\cdot{\\underline{x } } } } \\ ; d{\\underline{r}}\\ ; \\ ; d{\\underline{h}}\\big]\\label{eqn : gauge1}\\\\   & = n\\nonumber\\end{aligned}\\ ] ] is obtained by performing the gauge transformation @xmath627 , @xmath628 and @xmath629 and summing over all the @xmath152 possibilities of @xmath50 . now canceling the summation over @xmath50 with the denominator and then integrating we get it to be equal to @xmath1 .    _ proof of . _",
    "the proof is complete if we show @xmath630 = 0 $ ] .",
    "we will prove this for @xmath124 and it is similar for other @xmath134 .",
    "@xmath631 \\\\ & = \\sum_{i , k}{\\mathbb{e}}[\\langle(r_i -   n^{-\\frac12 } \\sum_l s_{il})(r_i - n^{-\\frac12 } \\sum_l s_{il}x_l^{(2)})(x_k^{(1)}-x_k^{(1)}x_k^{(2)})\\rangle_{t , u}]\\end{aligned}\\ ] ] now performing the gauge transformation @xmath632 , @xmath633 , @xmath154 and @xmath634 we get @xmath635\\end{aligned}\\ ] ] this quantity can be shown to be equal to @xmath636 by noticing that the @xmath50 and @xmath637 play symmetric roles .",
    "for a given configuration of @xmath638 , @xmath639 is a gaussian random variable with mean @xmath636 and variance smaller than @xmath484 .",
    "thus for @xmath640 and independent of @xmath641 , @xmath642 = { \\mathbb{e}}[e^{\\frac{-n_iz_i}{\\alpha } } ] \\leq \\sqrt\\frac{\\alpha^2}{\\alpha^2 - 4}\\end{aligned}\\ ] ] if @xmath643 , we have both the expectations to be less than some constant @xmath644 . therefore for any @xmath638 @xmath645 = { \\mathbb{e } } [ e^{\\frac{1}{\\alpha}n^{-\\frac12}\\sum_{i , l } n_i s_{il } z_l } ] \\leq c^n\\end{aligned}\\ ] ] using the markov inequality , @xmath646 using the union bound over @xmath638 , for @xmath647 large enough there exists a constant @xmath648 such that @xmath649 let @xmath443 be the event that @xmath650 holds for all @xmath638 . splitting the expectation into two parts corresponding to @xmath443 and @xmath441 and using cauchy - schwartz inequality , we have @xmath651 0.25 cm",
    "we would like to thank shrinivas kudekar , olivier lvque , andrea montanari , and rdiger urbanke for useful discussions .",
    "the work presented in this paper is partially supported by the national competence center in research on mobile information and communication systems ( nccr - mics ) , a center supported by the swiss national science foundation under grant number 5005 - 67322 .",
    "a.  montanari and d.  tse , `` analysis of belief propagation for non - linear problems : the example of cdma ( or : how to prove tanaka s formula ) , '' in _ proc . of the ieee inform .",
    "theory workshop _ , punta del este , uruguay , mar 13mar 17 2006 .",
    "y.  kabashima and t.  hosaka , `` statistical mechanics of source coding with a fidelity criterion , '' _ progress of theoretical physics .",
    "157 , pp . 197204 , 2005 . k.  nakamura , y.  kabashima , r.  morelos - zaragoza , and d.saad , `` statistical mechanics of broadcast channels using low - density parity - check codes , '' _ phys .",
    "67 , no . 036703",
    "( 1 - 9 ) , 2003 .",
    "s.  b. korada and n.  macris , `` on the concentration of the capacity for a code division multiple access system , '' in _ proc . of the ieee int .",
    "symposium on inform .",
    "theory _ , nice , france , june 24june 29 2007 , pp .",
    "28012805 .",
    "a.  bovier and v.  gayrard , `` hopfield models as generalized random mean field models , '' in _ mathematical aspects of spin glasses and neural networks _ , a.  bovier and p.  picco , eds .",
    "41.1em plus 0.5em minus 0.4em boston : birkhauser , 1998 , pp"
  ],
  "abstract_text": [
    "<S> we consider multiple access communication on a binary input additive white gaussian noise channel using randomly spread code division . for a general class of symmetric distributions for spreading coefficients , in the limit of a large number of users , we prove an upper bound on the capacity , which matches a formula that tanaka obtained by using the replica method . we also show concentration of various relevant quantities including mutual information , capacity and free energy . </S>",
    "<S> the mathematical methods are quite general and allow us to discuss extensions to other multiuser scenarios . </S>"
  ]
}