{
  "article_text": [
    "consider the linear discrete ill - posed problem @xmath8 where the norm @xmath9 is the 2-norm of a vector or matrix , and @xmath5 is extremely ill conditioned with its singular values decaying to zero without a noticeable gap",
    ". mainly arises from the discretization of the first kind fredholm integral equation @xmath10 where the kernel @xmath11 and @xmath12 are known functions , while @xmath13 is the unknown function to be sought .",
    "if @xmath14 is non - degenerate and @xmath12 satisfies the picard condition , there exists the unique squares integrable solution @xmath13 ; see @xcite . here for brevity we assume that @xmath15 and @xmath16 belong to the same set @xmath17 with @xmath18 .",
    "applications include image deblurring , signal processing , geophysics , computerized tomography , heat propagation , biomedical and optical imaging , groundwater modeling , and many others ; see , e.g. , @xcite .",
    "the theory and numerical treatments of integral equations can be found in @xcite .",
    "the right - hand side @xmath19 is noisy and assumed to be contaminated by a white noise @xmath20 , caused by measurement , modeling or discretization errors , where @xmath21 is noise - free and @xmath22 . because of the presence of noise @xmath20 and the extreme ill - conditioning of @xmath5 , the naive solution @xmath23 of bears no relation to the true solution @xmath24 , where @xmath25 denotes the moore - penrose inverse of a matrix",
    "therefore , one has to use regularization to extract a best possible approximation to @xmath26 .    in principle , regularizing an ill - posed problem is to replace it by a well - posed one , such that the error is compensated by the gain in stability . in other words",
    ", regularization is to compromise the error and stability as best as possible .",
    "for a white noise @xmath20 , throughout the paper , we always assume that @xmath21 satisfies the discrete picard condition @xmath27 with some constant @xmath28 for @xmath29 arbitrarily large @xcite .",
    "it is an analog of the picard condition in the finite dimensional case ; see , e.g. , @xcite , @xcite , @xcite and @xcite .",
    "the two dominating regularization approaches are to solve the following two essentially equivalent problems @xmath30 and general - form tikhonov regularization ( cf .",
    "@xcite ) @xmath31 with @xmath32 the regularization parameter for regularized solutions @xcite",
    ". a suitable choice of the matrix @xmath33 is based on a - prior information on @xmath26 , and typically @xmath33 is either the identity matrix , a diagonal weighting matrix , or a @xmath34 discrete approximation of a first or second order derivative operator . particularly , if @xmath35 , the identity matrix , is standard - form tikhonov regularization .",
    "the case @xmath35 is of most common interests and our concern in this paper . from now on ,",
    "we always assume @xmath35 , for which the solutions to , and can be fully analyzed by the singular value decomposition ( svd ) of @xmath5 .",
    "let @xmath36 be the svd of @xmath5 , where @xmath37 and @xmath38 are orthogonal , @xmath39 with the singular values @xmath40 assumed to be simple throughout the paper , and the superscript @xmath41 denotes the transpose of a matrix or vector .",
    "then @xmath42 with @xmath43 .",
    "the discrete picard condition means that , on average , the fourier coefficients @xmath44 decay faster than @xmath45 and enables regularization to compute useful approximations to @xmath26 , which results in the following popular model that is used throughout hansen s books @xcite and the current paper : @xmath46 where @xmath47 is a model parameter that controls the decay rates of @xmath48 .",
    "hansen @xcite points out ,  while this is a crude model , it reflects the overall behavior often found in real problems .",
    "\" one precise definition of the discrete picard condition is @xmath49 with certain constants @xmath50 .",
    "we remark that once the @xmath51 and @xmath52 do not differ greatly , such discrete picard condition does not affect our claims , rather it complicates derivations and forms of the results .    the white noise @xmath20 has a number of attractive properties which play a critical role in the regularization analysis : its covariance matrix is @xmath53 , the expected values @xmath54 and @xmath55 , and @xmath56 and @xmath57 ; see , e.g. , @xcite and @xcite .",
    "the noise @xmath20 thus affects @xmath58 _ more or less equally_. with , relation shows that for large singular values @xmath59 is dominant relative to @xmath60 .",
    "once @xmath61 from some @xmath62 onwards , the small singular values magnify @xmath60 , and the noise @xmath20 dominates @xmath63 and must be suppressed .",
    "the transition point @xmath6 is such that @xmath64 see @xcite and a similar description @xcite .",
    "the @xmath65 are then divided into the @xmath6 large ones and the @xmath66 small ones .",
    "the truncated svd ( tsvd ) method @xcite deals with by solving @xmath67 where @xmath68 is the best rank approximation @xmath4 to @xmath5 with respect to the 2-norm with @xmath69 , @xmath70 and @xmath71 ; it holds that @xmath72 ( cf .",
    "and @xmath73 called the tsvd solution , solves .",
    "an crucial observation is that @xmath74 is the minimum - norm least squares solution to @xmath75 that perturbs @xmath5 to @xmath76 in , and we will frequently exploit this interpretation later .    based on the above properties of the white noise @xmath20 , it is known from @xcite and @xcite that the tsvd solutions @xmath77 and @xmath78 is the best tsvd regularized solution to , which balances the regularization and perturbation errors optimally and stabilizes the residual norms @xmath79 for @xmath4 not close to @xmath29 after @xmath80 . the index @xmath4 plays the role of the regularization parameter that determines how many large svd components of @xmath5 are used to compute a regularized solution @xmath74 to .",
    "the solution @xmath81 of the tikhonov regularization has a filtered svd expansion @xmath82 where the @xmath83 are called filters .",
    "the tsvd method is a special parameter filtered method , where , in @xmath74 , we take @xmath84 and @xmath85 . the error @xmath86 can be written as the sum of the regularization and perturbation errors , and an optimal @xmath87 aims to balance these two errors and make the sum of their norms minimized @xcite .",
    "the best possible regularized solution @xmath88 retains the @xmath6 dominant svd components and dampens the other @xmath66 small svd components as much as possible @xcite .",
    "apparently , the ability to acquire _ only _ the largest svd components of @xmath5 is fundamental in solving .",
    "a number of parameter - choice methods have been developed for finding @xmath87 or @xmath6 , such as the discrepancy principle @xcite , the l - curve criterion , whose use goes back to miller @xcite and lawson and hanson @xcite and is termed much later and studied in detail in @xcite , and the generalized cross validation ( gcv ) @xcite ; see , e.g. , @xcite for numerous comparisons .",
    "all parameter - choice methods aim to make @xmath89 not small for @xmath90 and @xmath91 for @xmath92 .",
    "each of these methods has its own merits and disadvantages , and no one is absolutely reliable for all ill - posed problems .",
    "for example , some of the mentioned parameter - choice methods may fail to find accurate approximations to @xmath87 ; see @xcite for an analysis on the l - curve method and @xcite for some other parameter - choice methods .",
    "a further investigation on paramater - choice methods is not our concern in this paper .",
    "the tsvd method and the standard - form tikhonov regularization produce very similar solutions with essentially the minimum 2-norm error , i.e. , the worst - case error @xcite ; see @xcite , @xcite , @xcite and ( * ? ? ?",
    "* sections 4.2 and 4.4 ) . indeed , for an underlying linear compact equation @xmath93 , e.g. , , with the noisy @xmath94 and true solution @xmath95 , under the source condition that its solution @xmath96 or @xmath97 , the range of the adjoint @xmath98 of @xmath99 or that of @xmath100 , which amounts to assuming that @xmath95 or its derivative is squares integrable , the errors of the best regularized solutions by the tsvd method and the tikhonov regularization are _ order optimal , i.e. , the same order as the worst - case error _",
    "@xcite , @xcite and @xcite .",
    "these conclusions carries over to @xcite .",
    "therefore , both @xmath88 and @xmath78 are best possible solutions to under the above assumptions , and any of them can be taken as the reference standard when assessing the regularizing effects of an iterative solver . for the sake of clarity and analysis",
    ", we will take @xmath78 as the standard reference .    for large , the tsvd method and the tikhonov regularization method",
    "are generally too demanding , and only iterative regularization methods are computationally viable .",
    "a major class of methods has been krylov iterative solvers that project onto a sequence of low dimensional krylov subspaces and computes iterates to approximate @xmath26 @xcite . of krylov",
    "iterative solvers , the cgls ( or cgnr ) method , which implicitly applies the cg method @xcite to @xmath3 , and its mathematically equivalent lsqr algorithm @xcite have been most commonly used .",
    "the krylov solvers cgme ( or cgne ) @xcite and lsmr @xcite are also choices , which amount to the cg method applied to @xmath101 or @xmath102 with @xmath103 and minres @xcite applied to @xmath3 , respectively .",
    "these krylov solvers have been intensively studied and known to have general regularizing effects @xcite and exhibit semi - convergence @xcite ; see also @xcite , @xcite , @xcite and @xcite : the iterates converge to @xmath26 and their norms increase steadily , and the residual norms decrease in an initial stage ; afterwards the noise @xmath20 starts to deteriorate the iterates so that they start to diverge from @xmath26 and instead converge to @xmath104 , while their norms increase considerably and the residual norms stabilize .",
    "if we stop at the right time , then , in principle , we have a regularization method , where the iteration number plays the role of the regularization parameter .",
    "semi - convergence is due to the fact that the projected problem starts to inherit the ill - conditioning of from some iteration onwards , and a small singular value of the projected problem amplifies the noise considerably .",
    "the regularizing effects of cg type methods were noticed by lanczos @xcite and were rediscovered in @xcite . based on these works and motivated by a heuristic explanation on good numerical results with very few iterations using cgls in @xcite , and realizing that such an excellent performance can only be expected",
    "if convergence to the regular part of the solution , i.e. , @xmath78 , takes place before the effects of ill - posedness show up , on page 13 of @xcite , bjrck and eldn in 1979 foresightedly expressed a fundamental concern on cgls ( and lsqr ) : _ more research is needed to tell for which problems this approach will work , and what stopping criterion to choose .",
    "_ see also @xcite . as remarked by hanke and hansen @xcite ,",
    "the paper @xcite was the only extensive survey on algorithmic details until that time , and a strict proof of the regularizing properties of conjugate gradients is extremely difficult .",
    "an enormous effort has long been made to the study of regularizing effects of lsqr and cgls ( cf .",
    "@xcite ) , but hitherto there has been no definitive answer to the above long - standing fundamental question , and the same is for cgme and lsmr .    for @xmath5 symmetric , minres and mr - ii applied to @xmath1 directly are alternatives and have been shown to have regularizing effects @xcite , but mr - ii seems preferable since the noisy @xmath2 is excluded in the underlying subspace @xcite . for @xmath5 nonsymmetric or multiplication with @xmath105 difficult to compute , gmres and rrgmres are candidate methods @xcite , and the latter may be better @xcite .",
    "the hybrid approaches based on the arnoldi process have been first proposed in @xcite and studied in @xcite .",
    "gazzola and her coauthors @xcite have described a general framework of the hybrid methods and presented various krylov - tikhonov methods with different parameter - choice strategies .",
    "the regularizing effects of these methods are highly problem dependent , and it appears that they require that the mixing of the left and right singular vectors of @xmath5 be weak , that is , @xmath106 is close to a diagonal matrix ; for more details , see , e.g. , @xcite and @xcite .",
    "the behavior of ill - posed problems critically depends on the decay rate of @xmath107 .",
    "the following characterization of the degree of ill - posedness of was introduced in @xcite and has been widely used @xcite : if @xmath108 , then is mildly or moderately ill - posed for @xmath109 or @xmath110 . if @xmath111 with @xmath112 , @xmath113 , then is severely ill - posed . here for mildly ill - posed problems we add the requirement @xmath114 , which does not appear in @xcite but must be met for @xmath11 in @xcite . in the one - dimensional case ,",
    "i.e. , @xmath115 , is severely ill - posed with @xmath14 sufficiently smooth , and it is moderately ill - posed with @xmath116 , where @xmath117 is the highest order of continuous derivatives of @xmath14 ; see , e.g. , @xcite and @xcite .",
    "clearly , the singular values @xmath107 for a severely ill - posed problem decay at the same rate @xmath118 , while those of a moderately or mildly ill - posed problem decay at the decreasing rate @xmath119 that approaches one more quickly with @xmath120 for the mildly ill - posed problem than for the moderately ill - posed problem .    if a regularized solution to is at least as accurate as @xmath78 , then it is called a best possible regularized solution . given , if the regularized solution of an iterative regularization solver at semi - convergence is such a best possible one , then , by the words of bjrck and eldn , the solver _ works _ for the problem and is said to have the _ full _ regularization .",
    "otherwise , the solver is said to have only the _ partial _ regularization .",
    "because it has long been unknown whether or not lsqr , cgls , lsmr and cgme have the full regularization for a given , one commonly combines them with some explicit regularization , hoping that the resulting hybrid variants find best possible regularized solutions @xcite .",
    "a hybrid cgls is to run cgls for several trial regularization parameters @xmath121 and picks up the best one among the candidates @xcite .",
    "its disadvantages are that regularized solutions can not be updated with different @xmath121 and there is no guarantee that the selected regularized solution is a best possible one .",
    "the hybrid lsqr variants have been advocated by bjrck and eldn @xcite and oleary and simmons @xcite , and improved and developed by bjrck @xcite and bjrck , grimme and van dooren @xcite . a hybrid lsqr",
    "first projects onto krylov subspaces and then regularizes the projected problems explicitly .",
    "it aims to remove the effects of small ritz values and expands krylov subspaces until they captures the @xmath6 dominant svd components of @xmath5 @xcite .",
    "the explicit regularization for projected problems should be introduced and play into effects only after semi - convergence rather than from the very first iteration .",
    "if it works , the error norms of regularized solutions and the residual norms further decrease until they ultimately stabilize .",
    "the hybrid lsqr and cgme have been intensively studied in , e.g. , @xcite and @xcite . within the framework of such hybrid solvers , however , it is hard to find a near - optimal regularization parameter @xcite .",
    "in contrast , if an iterative solver is theoretically proved and practically identified to have the full regularization , one simply stops it after semi - convergence , and no complicated hybrid variant and further iterations are needed .",
    "obviously , we can not emphasize too much the importance of proving the full or partial regularization of lsqr , cgls , lsmr and cgme . by the definition of the full or partial regularization",
    ", we now modify the concern of bjrck and eldn as : _ do lsqr , cgls , lsmr and cgme have the full or partial regularization for severely , moderately and mildly ill - posed problems ? how to identify their full or partial regularization in practice ?",
    "_    in this paper , we focus on lsqr and analyze its regularization for severely , moderately and mildly ill - posed problems . due to the mathematical equivalence of cgls and lsqr , the assertions on the full or partial regularization of lsqr",
    "apply to cgls as well .",
    "we prove that lsqr has the full regularization for severely and moderately ill - posed problems once @xmath112 and @xmath110 suitably , and it generally has only the partial regularization for mildly ill - posed problems . in section [ lsqr ] , we describe the lanczos bidiagonalization process and lsqr , and make an introductory analysis . in section [ sine ] ,",
    "we establish @xmath122 theorems for the 2-norm distance between the underlying @xmath4-dimensional krylov subspace and the @xmath4-dimensional dominant right singular subspace of @xmath5 .",
    "we then derive some follow - up results that play a central role in analyzing the regularization of lsqr . in section [ rankapp ] , for the first two kinds of problems we prove that a @xmath4-step lanczos bidiagonalization always generates a near best rank @xmath4 approximation to @xmath5 , and the @xmath4 ritz values always approximate the first @xmath4 large singular values in natural order , and no small ritz value appears for @xmath7 .",
    "this will show that lsqr has the full regularization .",
    "for mildly ill - posed problems , we prove that , for some @xmath123 , the @xmath4 ritz values generally do not approximate the first @xmath4 large singular values in natural order and lsqr generally has only the partial regularization . in section [ alphabeta ] , we derive bounds for the entries of bidiagonal matrices generated by lanczos bidiagonalization , showing how fast they decay and how to use them to identify if lsqr has the full regularization when the degree of ill - posedness of is unknown in advance . in section [ numer ] ,",
    "we report numerical experiments to confirm our theory on lsqr . finally , we summarize the paper with further remarks in section [ concl ] .    throughout the paper ,",
    "we denote by @xmath124 the @xmath4-dimensional krylov subspace generated by the matrix @xmath125 and the vector @xmath126 , and by @xmath127 and the bold letter @xmath128 the identity matrix and the zero matrix with orders clear from the context , respectively . for the matrix @xmath129 ,",
    "we define @xmath130 , and for @xmath131 , @xmath132 means @xmath133 componentwise .",
    "the lsqr algorithm is based on the lanczos bidiagonalization process , algorithm  [ alg : lb ] , that computes two orthonormal bases @xmath134 and @xmath135 of @xmath136 and @xmath137 for @xmath138 , respectively",
    ".    1 . : :    take @xmath139 , and define    @xmath140 .",
    "2 . : :    for @xmath141    +    ( i ) ; ;      @xmath142    ( ii ) ; ;      @xmath143    ( iii ) ; ;      @xmath144    ( iv ) ; ;      @xmath145    algorithm  [ alg : lb ] can be written in the matrix form @xmath146 where @xmath147 is the @xmath148-th canonical basis vector of @xmath149 , @xmath150 , @xmath151 and @xmath152 it is known from that @xmath153 we remind that the singular values of @xmath154 , called the ritz values of @xmath5 with respect to the left and right subspaces @xmath155 and @xmath156 , are all simple .    at iteration @xmath4 , lsqr solves the problem @xmath157 and computes the iterates @xmath158 with @xmath159 where @xmath160 is the first canonical basis vector of @xmath149 , and the residual norm @xmath161 decreases monotonically with respect to @xmath4 .",
    "we have @xmath162 and @xmath163 , both of which can be cheaply computed .",
    "note that @xmath164 .",
    "we have @xmath165 that is , the iterate @xmath166 by lsqr is the minimum - norm least squares solution to the perturbed problem that replaces @xmath5 in by its rank @xmath4 approximation @xmath167 . recall that the best rank @xmath4 approximation @xmath76 to @xmath5 satisfies @xmath72 . furthermore , analogous to",
    ", lsqr now solves @xmath168 for the regularized solutions @xmath166 to .",
    "if @xmath167 is a near best rank @xmath4 approximation to @xmath5 with an approximate accuracy @xmath169 and the @xmath4 singular values of @xmath154 approximate the first @xmath4 large ones of @xmath5 in natural order for @xmath7 , these two facts relate lsqr and the tsvd method naturally and closely in two ways : ( i ) @xmath74 and @xmath166 are the regularized solutions to the two perturbed problems of that replace @xmath5 by its two rank @xmath4 approximations with the same quality , respectively ; ( ii ) @xmath74 and @xmath166 solve almost the same two regularization problems and , respectively . as a consequence ,",
    "the lsqr iterate @xmath170 is as accurate as @xmath78 , and lsqr has the full regularization .",
    "otherwise , as will be clear later , under the discrete picard condition , @xmath170 can not be as accurate as @xmath78 if either @xmath167 is not a near best rank @xmath4 approximation to @xmath5 , @xmath7 , or @xmath154 has at least one singular value smaller than @xmath171 for some @xmath123 .",
    "precisely , if either of them is violated for some @xmath123 and @xmath172 , @xmath166 has been deteriorated by the noise @xmath20 , and lsqr has only the partial regularization",
    ". we will give a precise definition of a near best rank @xmath4 approximation to @xmath5 soon .",
    "van der sluis and van der vorst @xcite prove the following result , which has been used in hansen @xcite and the references therein to illustrate the regularizing effects of lsqr and cgls .",
    "we will also investigate it further in our paper .",
    "[ help ] lsqr with the starting vector @xmath175 and cgls applied to @xmath3 with the starting vector @xmath176 generate the same iterates @xmath177 where @xmath178 and the @xmath179 are the singular values of @xmath154 labeled as @xmath180 .",
    "shows that @xmath166 has a filtered svd expansion of form .",
    "if all the ritz values @xmath179 approximate the first @xmath4 singular values @xmath107 of @xmath5 in natural order , the filters @xmath181 and the other @xmath182 monotonically approach zero for @xmath183 .",
    "this indicates that if the @xmath179 approximate the first @xmath4 singular values @xmath107 of @xmath5 in natural order for @xmath7 then the @xmath6-step lsqr has the full regularization .",
    "however , if a small ritz value appears before some @xmath123 , i.e. , @xmath184 and @xmath185 with the smallest integer @xmath186 , then @xmath187 tends to zero monotonically for @xmath188 ; on the other hand , we have @xmath189 since the first factor is non - positive and the second factor is positive",
    ". then we get @xmath190 , indicating that @xmath166 is already deteriorated and lsqr has only the partial regularization .",
    "the standard @xmath4-step lanczos bidiagonalization method computes the @xmath4 ritz values @xmath179 , which are used to approximate some singular values of @xmath5 .",
    "it is mathematically equivalent to the symmetric lanczos method for the eigenvalue problem of @xmath191 starting with @xmath192 ; see @xcite or @xcite for several variations that are based on standard , harmonic , and refined projection @xcite or a combination of them @xcite .",
    "it is known that , for general singular value distribution and @xmath2 , some ritz values become good approximations to the extreme singular values of @xmath5 as @xmath4 increases .",
    "if large singular values are well separated but small singular values are clustered , large ritz values converge fast but small ritz values converge slowly .    for",
    ", @xmath193 contains more information on dominant right singular vectors than on the ones corresponding to small singular values .",
    "therefore , @xmath173 hopefully contains richer information on the first @xmath4 right singular vectors @xmath194 than on the other @xmath195 ones , at least for @xmath4 small .",
    "furthermore , note that @xmath5 has many small singular values clustered at zero . due to these two basic facts ,",
    "all the ritz values are expected to approximate the large singular values of @xmath5 in natural order until some iteration @xmath4 , at which a small ritz value shows up . in this case , the iterates @xmath166 by lsqr capture only the largest @xmath4 dominant svd components of @xmath5 , and they are deteriorated by the noise @xmath20 dramatically after that iteration .",
    "this is why lsqr and cgls have general regularizing effects ; see , e.g. , @xcite and the references therein .",
    "unfortunately , these arguments can not help us draw any definitive conclusion on the full or partial regularization of lsqr because there has been no quantitative result on the size of such @xmath4 for any kind of ill - posed problem and the noise @xmath20 .",
    "for a severely ill - posed example from seismic tomography , it is reported in @xcite that the desired convergence of the ritz values actually holds as long as the discrete picard condition is satisfied and there is a good separation among the large singular values of @xmath5 . yet",
    ", there has been no mathematical justification on these observations .",
    "a complete understanding of the regularization of lsqr includes accurate solutions of the following problems : how accurately does @xmath196 approximate the @xmath4-dimensional dominant right singular subspace of @xmath5 ?",
    "how accurate is the rank @xmath4 approximation @xmath197 to @xmath5 ? can it be a near best rank @xmath4 approximation to @xmath5 ? how does the noise level @xmath198 affects the approximation accuracy of @xmath196 and @xmath197 for @xmath123 and @xmath80 , respectively ?",
    "what sufficient conditions on @xmath199 and @xmath200 are needed to guarantee that @xmath197 is a near best rank @xmath4 approximation to @xmath5 ?",
    "when do the @xmath201 approximate @xmath202 in natural order ?",
    "when does at least a small ritz value appear , i.e. , @xmath172 before some @xmath123",
    "? we will make a rigorous and detailed analysis on these problems , present our results , and draw definitive assertions on the regularization of lsqr for the three kinds of ill - posed problems .    in terms of the canonical angles @xmath203 between two subspaces @xmath204 and @xmath205 of equal dimension @xcite , we first present the following @xmath122 theorem , showing how @xmath196 approximates the @xmath4-dimensional dominant right singular subspace @xmath206 of @xmath5 for severely ill - posed problems .",
    "[ thm2 ] let the svd of @xmath5 be as .",
    "assume that is severely ill - posed with @xmath111 and @xmath112 , @xmath113 , and the discrete picard condition is satisfied .",
    "let @xmath207 be the @xmath4-dimensional dominant right singular subspace of @xmath5 spanned by the columns of @xmath208 and @xmath209 .",
    "then for @xmath210 we have @xmath211    with @xmath212 to be defined by and @xmath213 @xmath214 where @xmath215 in particular , we have @xmath216 whose columns are the first @xmath29 left singular vectors of @xmath5 defined by .",
    "then the krylov subspace @xmath217 with @xmath218 partition the diagonal matrix @xmath219 and the matrix @xmath220 as follows : @xmath221 where @xmath222 .",
    "since @xmath223 is a vandermonde matrix with @xmath107 distinct for @xmath141 , it is nonsingular .",
    "therefore , from @xmath224 we have @xmath225 where @xmath226 write @xmath227 , and define @xmath228 then @xmath229 , and the columns of @xmath230 form an orthonormal basis of @xmath231 .",
    "so we get an orthogonal direct sum decomposition of @xmath232 : @xmath233 by definition and , we obtain @xmath234 which is . from it",
    ", we get directly .",
    "next we estimate @xmath235 . for @xmath236",
    ", it is easily justified that the @xmath120-th column of @xmath237 consists of the coefficients of the @xmath120-th lagrange polynomial @xmath238 that interpolates the elements of the @xmath120-th canonical basis vector @xmath239 at the abscissas @xmath240 .",
    "consequently , the @xmath120-th column of @xmath241 is @xmath242 from which we obtain @xmath243 since @xmath244 is monotonically decreasing for @xmath245 , it is bounded by @xmath246 . with this property and the definition of @xmath247",
    ", we get @xmath248 where @xmath249 is a rank one matrix . therefore , by @xmath250 ( cf .",
    "@xcite ) , we get @xmath251    by the discrete picard condition , and the description between them , for the white noise @xmath20 , it is known from @xcite and @xcite that @xmath252 decrease as @xmath120 increases up to @xmath6 and then become stabilized as @xmath252 a small constant for @xmath253 . in order to simplify the derivation and",
    "present our results compactly , in terms of these assumptions and properties , in later proofs we will use the following strict equalities and inequalities : @xmath254 , for @xmath210 we obtain @xmath255 with @xmath256 for @xmath257 . for @xmath236 ,",
    "from we get @xmath258 from the above and , we finally obtain by noting @xmath259    note that the lagrange polynomials @xmath260 require @xmath261 .",
    "so , we need to treat the case @xmath262 independently . observe from and that @xmath263 therefore , we have @xmath264 from which and for @xmath262 it is direct to get .    in terms of the discrete picard condition , , and , we have @xmath265 @xmath266 applying them to and establishes , and , respectively .",
    "we next estimate the factor @xmath267 and all @xmath246 , @xmath141 accurately .",
    "[ estlk ] for the severely ill - posed problem , we have @xmath268    _ proof_. exploiting the taylor series expansion and @xmath269 for @xmath270 , by definition , for @xmath271 we have @xmath272 by absorbing those higher order terms into @xmath273 in the numerator . for @xmath274 , we get @xmath275 which is .    note that for the numerator of we have @xmath276 and @xmath277 whose product for any @xmath4 is @xmath278 on the other hand , note that the denominator of is defined by @xmath279 which , together with the above estimate for the numerator of , proves .",
    "notice that the above quantity is always _",
    "bigger than one _ for @xmath271 .",
    "therefore , for any @xmath4 , combining and gives .",
    "[ severerem ] from , the results in theorem  [ thm2 ] are simplified as @xmath280    it is seen from the proof that @xmath281 must be close to @xmath4 or equals @xmath4 . illustrates that @xmath246 increases fast , up to @xmath282 , with @xmath120 increasing , and the smaller @xmath120 , the smaller @xmath246 . and",
    "indicate that @xmath231 captures @xmath283 better for @xmath123 than for @xmath80 .",
    "that is , after iteration @xmath6 , the noise @xmath20 starts to impair the ability of @xmath231 to capture @xmath283 .",
    "next we estimate @xmath284 for moderately and mildly ill - posed problems .",
    "[ moderate ] assume that is moderately or mildly ill - posed with @xmath285 , where @xmath114 and @xmath286 is some constant .",
    "then and hold with @xmath287    _ proof_. following the proof of theorem  [ thm2 ] , we know that @xmath288 defined by .",
    "so we only need to bound the right - hand side of . for @xmath289 ,",
    "from we get @xmath290 since the function @xmath291 with any @xmath292 is convex over the interval @xmath293 $ ] , for @xmath294 , from we obtain @xmath295 substituting the above and into and exploiting and , we obtain and . for @xmath262",
    ", it follows from and that holds .    for the sake of precise presentation",
    ", we have used the simplified singular value model @xmath296 to replace the general form @xmath108 , where the constant in each @xmath273 is implicit .",
    "this model , though simple , reflects the essence of moderately and mildly ill - posed problems and avoids some non - transparent formulations .",
    "unlike the severely ill - posed problem case , for moderately and mildly ill - posed problems it appears impossible to estimate @xmath267 both elegantly and accurately .",
    "we present the following results on @xmath297 and @xmath267 .",
    "[ estlk2 ] for the moderately and mildly ill - posed problems with @xmath298 and @xmath114 , we have @xmath299 for @xmath110 , we have @xmath300 with the lower bound requiring @xmath4 satisfying @xmath301 ; for @xmath302 and @xmath4 satisfying @xmath301 , we have @xmath303    _ proof_. exploiting the first order taylor expansion , we obtain estimate @xmath304 which proves .    for @xmath271 , by the definition of @xmath45 , since @xmath305 , we have @xmath306 note that @xmath307 are always smaller than one for @xmath271 , and the smaller @xmath120 is , the smaller this factor is .",
    "furthermore , exploiting @xmath308 and by some elementary manipulation , for @xmath110 we can justify the estimates @xmath309 as a result , for @xmath110 we have @xmath310 which establishes . a combination of it and gives the right - hand part of .",
    "on the other hand , once @xmath4 is such that @xmath301 , we always have @xmath311 which yields the lower bound of and .    the inaccuracy source of and consists in using @xmath312 to replace @xmath313 approximately in the proof .",
    "they are considerable underestimates for @xmath302 but are accurate , provided that @xmath110 suitably ; the bigger @xmath200 is , the more accurate the estimates and are .",
    "the derivation of indicates that @xmath267 can be bigger than @xmath314 substantially for @xmath302 , particularly when @xmath200 is close to @xmath315 ; in this case , we can not bound @xmath267 from above since is a considerable underestimate and the denominator @xmath316 in can be very small .",
    "it is easily seen from that @xmath284 increases monotonically with respect to @xmath235 . for @xmath235",
    "reasonably small and @xmath235 large we have @xmath317 respectively . from and , we obtain @xmath318 , where @xmath319 is the gaussian function . as a result , for @xmath110 , @xmath6 is typically small and at most modest for a practical noise @xmath20 with @xmath320 since @xmath321 typically ranges from @xmath322 to @xmath323 .",
    "this means that for a moderately ill - posed problem @xmath235 is at most modest and can not be large , so that @xmath324 fairly .    for severely ill - posed problems , since all the @xmath325 , and",
    "indicate that @xmath284 is essentially unchanged for @xmath7 and @xmath326 , respectively , meaning that @xmath231 captures @xmath283 with almost the same accuracy for @xmath123 and @xmath80 , respectively .",
    "however , the situation is different for moderately ill - posed problems . for them",
    ", @xmath327 increases slowly as @xmath4 increases , and latexmath:[$\\sqrt{\\frac{k^2}{4\\alpha^2 - 1}+\\frac{k}{2\\alpha-1 } }    illustrate that @xmath284 increases slowly with @xmath123 and @xmath329 , respectively .",
    "this means that @xmath231 may not capture @xmath283 so well as it does for severely ill - posed problems as @xmath4 increases . in particular , starting with some @xmath80 , @xmath284 starts to approach one , which indicates that , for @xmath4 big , @xmath231 will contain substantial information on the right singular vectors corresponding to the @xmath195 small singular values of @xmath5 .",
    "[ mildrem ] for mildly ill - posed problems with @xmath330 , there are some distinctive features .",
    "note from and that @xmath6 is now considerably bigger than that for a severely or moderately ill - posed problem with the same noise level @xmath198 and @xmath47 . as a result ,",
    "firstly , for @xmath331 and the same @xmath4 , the factor @xmath332 is bigger than that for the moderately ill - posed problem ; secondly , @xmath333 if @xmath334 and is much bigger than @xmath4 and can be arbitrarily large if @xmath335 ; thirdly , and the comment on it indicate that @xmath267 is bigger than one considerably for @xmath302 as @xmath4 increases up to @xmath6 .",
    "the bound thus becomes increasingly large as @xmath4 increases up to @xmath6 for mildly ill - posed problems , causing that @xmath235 is large and @xmath336 starting with some @xmath123 .",
    "consequently , @xmath337 can not effectively capture @xmath338 and contains substantial information on the right singular vectors corresponding to the @xmath66 small singular values .    before proceeding ,",
    "we tentatively investigate how @xmath284 affects the smallest ritz value @xmath339 .",
    "this problem is of central importance for understanding the regularizing effects of lsqr .",
    "we aim to lead the reader to a first manifestation that ( i ) we may have @xmath340 , that is , no small ritz value may appear when @xmath324 suitably , and ( ii ) we must have @xmath341 , that is , @xmath339 can not approximate @xmath65 in natural order , meaning that @xmath342 no later than iteration @xmath6 , once @xmath284 is sufficiently close to one .",
    "[ initial ] let @xmath343 with @xmath344 , @xmath210 , and let the unit - length @xmath345 be a vector that has the smallest acute angle with @xmath346 , i.e. , the closest to @xmath346 , where @xmath347 is the matrix consisting of the last @xmath195 columns of @xmath348 defined by .",
    "then it holds that @xmath349 if @xmath350 , then @xmath351 if @xmath352 for a given arbitrarily small @xmath353 , then @xmath354    _ proof_. since the columns of @xmath355 generated by lanczos bidiagonalization form an orthonormal basis of @xmath231 , by definition and the assumption on @xmath356 we have @xmath357 with @xmath358 and @xmath359 . since @xmath283 is the orthogonal complement of @xmath346 , by definition we know that @xmath360 has the largest acute angle with @xmath283 , that is , it is the vector in @xmath231 that contains the least information on @xmath283 .",
    "expand @xmath356 as the following orthogonal direct sum decomposition : @xmath361 then from @xmath362 and we obtain @xmath363 from , we next bound the rayleigh quotient of @xmath356 with respect to @xmath191 from below . by the svd of @xmath5 and @xmath364 , we partition @xmath365 where @xmath366 and @xmath367 . making use of @xmath368 and @xmath369 as well as @xmath370",
    ", we obtain @xmath371 observe that it is impossible for @xmath372 and @xmath373 to be the eigenvectors of @xmath374 and @xmath375 associated with their respective smallest eigenvalues @xmath376 and @xmath377 simultaneously , which are the @xmath378-th canonical vector @xmath379 of @xmath380 and the @xmath4-th canonical vector @xmath381 of @xmath382 , respectively ; otherwise , we have @xmath383 and @xmath384 simultaneously , which are impossible as @xmath385 .",
    "therefore , from , and , we obtain the strict inequality @xmath386 from which it follows that the lower bound of holds .",
    "similarly , from and , we obtain the upper bound of : @xmath387    from the lower bound of , we see that if @xmath388 satisfies @xmath389 , i.e. , @xmath350 , then @xmath390 , i.e. , holds .    from ,",
    "we obtain @xmath391 . note that @xmath392 is the smallest eigenvalue of the symmetric positive definite matrix @xmath393 .",
    "therefore , we have @xmath394 where @xmath395 is , in fact , the ritz vector of @xmath191 from @xmath231 corresponding to the smallest ritz value @xmath392 .",
    "therefore , for @xmath356 defined in theorem  [ initial ] we have @xmath396 from which it follows from that @xmath397 . as a result , for any @xmath353 , we can choose @xmath398 such that @xmath399 i.e. , holds , solving which for @xmath400 gives @xmath352 .",
    "we analyze @xmath339 when @xmath350 . in the sense of @xmath401 in , @xmath402 is the optimal vector that extracts the least information from @xmath283 and the richest information from @xmath346 . from theorem  [ initial ] , since @xmath283 is the orthogonal complement of @xmath346 , we know that @xmath360 has the largest acute angle with @xmath283 , that is , it contains the least information from @xmath283 and the richest information from @xmath346 . therefore , @xmath395 and",
    "@xmath356 have a similar optimality , so that we have @xmath403 combining this estimate with , we may have @xmath340 when @xmath350 .",
    "we inspect the condition @xmath404 for and get insight into whether or not the true @xmath388 resulting from the three kinds of ill - posed problems satisfies it . for severely ill - posed problems , the lower bound @xmath405 is basically @xmath118 ; for moderately ill - posed problems with @xmath110 , the bound increases with increasing @xmath123 , and it can not be close to one provided that @xmath110 suitably or @xmath6 not big ; for mildly ill - posed problems with @xmath406 , the bound increases faster than it does for moderately ill - posed problems , and it may well approach one for @xmath123 . therefore , the condition for requires that @xmath284 be not close to one for severely and moderately ill - posed problems , but @xmath284 must be close to zero for mildly ill - posed problems . in view of and @xmath343",
    ", we have @xmath407 .",
    "thus , the condition @xmath404 for amounts to requiring that @xmath235 be at most modest and can not be large for severely and moderately ill - posed problems but it must be fairly small for mildly ill - posed problems .",
    "unfortunately , theorems  [ thm2][moderate ] and the remarks followed indicate that @xmath235 increases with @xmath4 increasing and is generally large for a mildly ill - posed problem , while it increases slowly with @xmath123 for a moderately ill - posed problem with @xmath110 suitably , and by it is approximately @xmath408 , considerably smaller than one for a severely ill - posed problem with @xmath112 not close to one .",
    "consequently , for mildly ill - posed problems , because the actual @xmath235 can hardly be small and is generally large , the true @xmath388 is small and may well be close to zero , so that the condition @xmath409 generally fails to meet as @xmath4 increases , while it is satisfied for severely or moderately ill - posed problems with @xmath112 or @xmath110 suitably .",
    "[ appear ] shows that there is at least one @xmath341 if @xmath284 is sufficiently close to one since we can choose @xmath410 small enough such that @xmath411 is close to @xmath169 arbitrarily .",
    "as we have shown , @xmath284 can not be close to one for severely or moderately ill - posed problems with @xmath112 or @xmath110 suitably , but it is generally so for mildly ill - posed problems .",
    "this means that for some @xmath123 it is very likely that @xmath341 for mildly ill - posed problems .",
    "we must be aware that our above analysis on @xmath340 is not rigorous because we can not quantify _ how small _ @xmath412 is . from @xmath413 , it is apparent that the condition @xmath409 may not be sufficient for @xmath340 .",
    "we delay our detailed and rigorous analysis to section [ rankapp ] .",
    "theorems  [ thm2][moderate ] establish necessary background for answering the fundamental concern by bjrck and eldn , and their proof approaches also provide key ingredients for some of the later results .",
    "we now present the following results , which will play a central role in our later analysis .",
    "[ thm3 ] assume that the discrete picard condition is satisfied , let @xmath414 be defined as and @xmath415 and @xmath247 defined as , and write @xmath416 .",
    "then for severely ill - posed problems and @xmath210 we have @xmath417 and @xmath418 for moderately or mild ill - posed problems with the singular values @xmath296 and @xmath419 a positive constant we have @xmath420 and @xmath421    _ proof_. from and , for @xmath141 and @xmath422 we have @xmath423 and from , for @xmath262 we have @xmath424 for severely ill - posed problems , @xmath210 and @xmath141 , from we obtain @xmath425 for moderately or mildly ill - posed problems , @xmath210 and @xmath141 , from we obtain @xmath426 combining the above with , and @xmath427 we obtain , while follows from the above and directly . for @xmath262 , from and the above we get and , respectively .",
    "by , for @xmath422 we have @xmath428 therefore , we get @xmath429 by , for @xmath262 we have @xmath430 we have derived the bounds and for @xmath431 for severely and moderately or mildly ill - posed problems , respectively , from which we obtain and for @xmath262 . in order to bound @xmath432 for @xmath422 , we need to estimate @xmath433 .",
    "we next carry out this task for severely and moderately or mildly ill - posed problems , respectively , for each kind of which we consider the cases of @xmath123 and @xmath80 separately .",
    "case of @xmath123 for severely ill - posed problems : from the discrete picard condition and , we obtain @xmath434    case of @xmath329 for severely ill - posed problems : from and , we obtain @xmath435 substituting the above two relations for the two cases into and combining them with and , we get .    case of @xmath123 for moderately or mildly ill - posed problems : from we have @xmath436    case of @xmath329 for moderately or mildly ill - posed problems : from and we have @xmath437 substituting the above two bounds for the two cases into and combining them with , we get .    and indicate that @xmath432 decays swiftly as @xmath4 increases . as has been seen",
    ", we must take some cares to accurately bound @xmath432 .",
    "indeed , for @xmath438 , if we had simply estimated it by @xmath439 we would have obtained a bound , which not only does not decay but also increases for moderately and mildly ill - posed problems as @xmath4 increases .",
    "such bound is useless to precisely analyze the regularization of lsqr for ill - posed problems and makes us impossible to get those predictively accurate results to be presented in sections [ rankapp][alphabeta ] .",
    "making use of theorems  [ thm2][thm3 ] , we are able to solve those key problems stated before theorem  [ thm2 ] and give definitive answers to the fundamental concern by bjrck and eldn , proving that lsqr has the full regularization for severely or moderately ill - posed problems with @xmath112 or @xmath110 suitably and it , in general , has only the partial regularization for mildly ill - posed problems .    define @xmath440 which measures the accuracy of the rank @xmath4 approximation @xmath197 to @xmath5 generated by lanczos bidiagonalization .",
    "recall and the comments followed .",
    "it is known that the full or partial regularization of lsqr uniquely depends on whether or not @xmath441 holds , where we will make the precise meaning ` @xmath442 ' clear by introducing the definition of near best rank @xmath4 approximation to @xmath5 , and on whether or not the @xmath4 ritz values @xmath201 approximate the @xmath4 large singular values @xmath45 of @xmath5 in natural order for @xmath443 .",
    "if both of them hold , lsqr has the full regularization ; if either of them is not satisfied , lsqr has only the partial regularization .",
    "we first present one of the main results in this paper .",
    "[ main1 ] assume that the discrete picard condition is satisfied .",
    "then for @xmath210 we have @xmath444 with @xmath445 for severely ill - posed problems and @xmath446 for moderately or mildly ill - posed problems with @xmath447 , where @xmath448 for @xmath449 and @xmath450 for @xmath451 .    _",
    "proof_. since @xmath76 is the best rank @xmath4 approximation to @xmath5 with respect to the 2-norm and @xmath72 , the lower bound in holds .",
    "next we prove the upper bound .    from",
    ", we obtain @xmath452 from algorithm  [ alg : lb ] , , and , we obtain @xmath453 with @xmath355 and @xmath232 being orthonormal , and the orthogonal projector onto @xmath231 is thus @xmath454 keep in mind that @xmath68 . it is direct to justify that @xmath455 for @xmath210 .",
    "therefore , exploiting this and noting that @xmath456 and @xmath370 for @xmath210 , we get from , and that @xmath457 where the last inequality follows by using @xmath458 and the definition of the induced matrix 2-norm to amplify the second term in .",
    "we estimate @xmath459 accurately below . to this end",
    ", we need to use two key identities and some results related . by the svd of @xmath460 ,",
    "it is direct to justify that @xmath461 and @xmath462 define the function @xmath463 with @xmath464 . since the derivative @xmath465",
    ", @xmath466 is monotonically increasing for @xmath467 $ ] and decreasing for @xmath468 , and the maximum of @xmath466 over @xmath464 is @xmath315 , which attains at @xmath469 .",
    "based on these properties and exploiting the svd of @xmath460 , for the matrix 2-norm we get @xmath470 for @xmath449 and @xmath471 for @xmath451 ( note : in this case , since @xmath460 may have at least one singular value smaller than one , we do not have an expression like ) .",
    "it then follows from , , and @xmath472 that @xmath473 for @xmath449 and @xmath474 for @xmath451 .",
    "replace @xmath432 by its bounds and in the above , insert the resulting bounds for @xmath459 into , and let @xmath475 .",
    "then we obtain the upper bound in with @xmath476 satisfying and for severely and moderately or mildly ill - posed problems , respectively .",
    "note from that @xmath477 therefore , for the right - hand side of and @xmath123 we have @xmath478    [ decayrate ] for severely ill - posed problems , from , and the definition of @xmath479 we know that @xmath480 for both @xmath123 and @xmath80 .",
    "therefore , from and , for @xmath123 we have @xmath481 by ignoring the smaller term @xmath482 , and for @xmath80 we have @xmath483 by ignoring the smaller term @xmath484 , which increases slowly with @xmath4 .    for the moderately or mildly ill - posed problems with @xmath296 , from the derivation on @xmath476 and its estimate , for @xmath123 we approximately have @xmath485 and for @xmath80 , from and we approximately have @xmath486 which increases faster than the right - hand side of with respect to @xmath4 .    [ decayrate2 ] from , and , for severely ill - posed problems we have @xmath487 and @xmath488 is an accurate approximation to @xmath169 for @xmath123 and marginally less accurate for @xmath80 .",
    "thus , the rank @xmath4 approximation @xmath197 is as accurate as the best rank @xmath4 approximation @xmath76 within the factor @xmath489 for @xmath123 and @xmath112 suitably . for",
    "moderately ill - posed problems , @xmath488 is still an excellent approximation to @xmath169 , and the rank @xmath4 approximation @xmath197 is almost as accurate as the best rank @xmath4 approximation @xmath76 for @xmath123 .",
    "therefore , @xmath197 plays the same role as @xmath76 for these two kinds of ill - posed problems and @xmath123 , it is known from the clarification in section [ lsqr ] that lsqr may have the full regularization",
    ". we will , afterwards , deepen this theorem and derive more results , proving that lsqr must have the full regularization for these two kinds of problems provided that @xmath112 and @xmath110 suitably .    for both severely and moderately ill - posed problems",
    ", we note that the situation is not so satisfying for increasing @xmath80 .",
    "but at that time , a possibly big @xmath476 does not do harm to our regularization purpose since we will prove that , provided that @xmath112 and @xmath110 suitably , lsqr has the full regularization and has already found a best possible regularized solution at semi - convergence occurring at iteration @xmath6 .",
    "if it is the case , we will simply stop performing it after semi - convergence .",
    "[ mildre ] for mildly ill - posed problems , the situation is fundamentally different .",
    "as clarified in remark  [ mildrem ] , we have @xmath490 and @xmath491 considerably as @xmath4 increases up to @xmath6 because of @xmath302 , leading to @xmath492 substantially .",
    "this means that @xmath493 is substantially bigger than @xmath171 and can well lie between @xmath494 and @xmath495 , so that the rank @xmath6 approximation @xmath496 is much less accurate than the best rank @xmath6 approximation @xmath497 and lsqr has only the partial regularization .",
    "there are several subtle treatments in the proof of theorem  [ main1 ] , each of which turns out to be absolutely necessary .",
    "ignoring or missing any one of them would be fatal and make us fail to obtain accurate estimates for @xmath459 defined by .",
    "the first is the treatment of @xmath498 . by the definition of @xmath284 ,",
    "if we had amplified it by @xmath499 we would have obtained a too large overestimate , which is almost a fixed constant for severely ill - posed problems and @xmath7 and increases with @xmath7 for moderately and mildly ill - posed problems .",
    "such rough estimates are useless to get a meaningful bound for @xmath488 .",
    "the second is the use of and .",
    "the third is the extraction of @xmath432 from as a whole other than amplify it to @xmath500 .",
    "the fourth is accurate estimates for it ; see and in theorem  [ thm3 ] .",
    "for example , without using and , by we would have no way but to obtain @xmath501 from and the previous estimates for @xmath235 , such bound is too pessimistic and completely useless in our context , and it even does not decrease and could not be small as @xmath4 increases , while our estimates for @xmath475 in theorem  [ main1 ] are much more accurate and decay swiftly as @xmath4 increases , as indicated by and .    in order to prove the full or partial regularization of lsqr for completely and rigorously , besides theorem  [ main1 ] , we need to introduce a precise definition of the near best rank @xmath4 approximation @xmath197 to @xmath5 . by definition , the rank @xmath4",
    "matrix @xmath197 is called a near best rank @xmath4 approximation to @xmath5 if it satisfies @xmath502 that is , @xmath488 lies between @xmath65 and @xmath169 and is closer to @xmath169 .",
    "this definition is natural .",
    "we mention in passing that a near best rank @xmath4 approximation to @xmath5 from an ill - posed problem is much more stringent than it is for a matrix from a numerically rank - deficient problem where the large singular values are well separated from the small ones and there is a substantial gap between two groups of singular values .    based on theorem  [ main1 ] , for the severely and moderately or mildly ill - posed problems with the singular value models @xmath503 and @xmath504",
    ", we next derive the sufficient conditions on @xmath199 and @xmath200 that guarantee that @xmath197 is a near best rank @xmath4 approximation to @xmath5 for @xmath7 .",
    "we analyze if and how the sufficient conditions are satisfied for three kinds of ill - posed problems .",
    "[ nearapprox ] for a given , assume that the discrete picard condition is satisfied .",
    "then , in the sense of , @xmath197 is a near best rank @xmath4 approximation to @xmath5 for @xmath7 if @xmath505 for the severely ill - posed problems with @xmath503 and the moderately or mildly ill - posed problems with @xmath504 , @xmath197 is a near best rank @xmath4 approximation to @xmath5 for @xmath7 if @xmath506 and @xmath200 satisfies @xmath507 respectively .    _",
    "proof_. by , we see that @xmath508 .",
    "therefore , @xmath197 is a near best rank @xmath4 approximation to @xmath5 in the sense of provided that @xmath509 and @xmath510 from which follows .    from , for the severely ill - posed problems with @xmath503 and @xmath112 we have @xmath511 from which it follows that @xmath512 since @xmath513 , holds provided that @xmath514 i.e. , @xmath515 , solving which for @xmath199 we get @xmath506 . for the moderately or mildly ill - posed problems with @xmath504 ,",
    "it is direct from to get @xmath516 since @xmath517 decreases monotonically as @xmath4 increases , its minimum over @xmath7 is @xmath518 .",
    "therefore , we obtain .",
    "given the noise level @xmath198 , the discrete picard condition and , from the bound for @xmath519 , we see that the bigger @xmath110 is , the smaller @xmath6 and @xmath476 are .",
    "therefore , there must be @xmath110 such that holds .",
    "here we should remind that it is more suitable to regard the conditions on @xmath199 and @xmath200 as an indication that @xmath199 and @xmath200 must not be close to one other than precise requirements since we have used the bigger and simplified models @xmath520 and @xmath504 .    for the mildly ill - posed problems with @xmath504 ,",
    "theorem  [ moderate ] has shown that @xmath235 is generally not small and can be arbitrarily large for @xmath7 . from , we see that the size of @xmath476 is comparable to @xmath235 .",
    "note that the right - hand side @xmath521 for @xmath302 and any @xmath522 .",
    "consequently , can not be met generally for mildly ill - posed problems .",
    "the rare possible exceptions are that @xmath6 is only very few and @xmath200 is close to one since , in such case , @xmath476 is not large for @xmath7 .",
    "so , @xmath197 is generally not a near best rank @xmath4 approximation to @xmath5 for @xmath443 for this kind of problem .      starting with theorem  [ main1 ] , we prove that , under certain sufficient conditions on @xmath199 and @xmath200 for the severely and moderately ill - posed problems with the models @xmath523 and @xmath524 , respectively , the @xmath4 ritz values @xmath201 approximate the first @xmath4 large singular values @xmath45 in natural order for @xmath7 , which means that no ritz value smaller than @xmath171 appears . combining this result with theorem  [ nearapprox ] , we can draw the definitive conclusion that lsqr must have the full regularization for these two kinds of problems provided that @xmath112 and @xmath110 suitably . on the other hand , we will show why lsqr generally has only the partial regularization for mildly ill - posed problems .",
    "[ ritzvalue ] assume that is severely ill - posed with @xmath523 and @xmath112 or moderately ill - posed with @xmath524 and @xmath110 , and the discrete picard condition is satisfied .",
    "let the ritz values @xmath201 be labeled as @xmath525 .",
    "then @xmath526 if @xmath527 or @xmath110 satisfies @xmath528 then the @xmath4 ritz values @xmath201 strictly interlace the first large @xmath529 singular values of @xmath5 and approximate the first @xmath4 large ones in natural order for @xmath7 : @xmath530 meaning that there is no ritz value @xmath201 smaller than @xmath171 for @xmath443 .",
    "_ proof_. note that for @xmath7 the @xmath531 are just the nonzero singular values of @xmath197 , whose other @xmath195 singular values are zeros .",
    "we write @xmath532 with @xmath533 by definition .",
    "then by the mirsky s theorem of singular values ( * ? ? ?",
    "* , thm 4.11 ) , we have @xmath534 since the singular values of @xmath5 are simple and @xmath2 has components in all the left singular vectors @xmath535 of @xmath5 , lanczos bidiagonalization , i.e. , algorithm  [ alg : lb ] , can be run to completion , producing @xmath536 and the lower bidiagonal @xmath537 such that @xmath538 with the @xmath539 matrix @xmath540 and @xmath541 matrix @xmath542 orthogonal and all the @xmath543 and @xmath544 , @xmath270 , of @xmath545 being positive .",
    "note that the singular values of @xmath546 are all simple and that @xmath154 consists of the first @xmath4 columns of @xmath545 with the last @xmath195 _ zero _ rows deleted .",
    "applying the cauchy s _ strict _ interlacing theorem ( * ? ? ?",
    "* , corollary 4.4 ) to the singular values of @xmath154 and @xmath545 , we have @xmath547 therefore , becomes @xmath548 which proves .",
    "that is , the @xmath201 approximate @xmath45 from below for @xmath549 with the errors no more than @xmath508 . for @xmath549 ,",
    "notice that @xmath550 .",
    "then from , and @xmath523 we obtain @xmath551 provided that @xmath552 , solving which we get @xmath527 . together with the upper bound of , we have proved .    for the moderately ill - posed problems with @xmath553 and @xmath7 ,",
    "we get @xmath554 i.e. , holds , provided that @xmath555 and @xmath110 are such that @xmath556 which means that @xmath557 it is easily justified that the above right - hand side monotonically decreases with respect to @xmath549 , whose minimum attains at @xmath558 and equals @xmath559 . furthermore , since @xmath559 decreases monotonically as @xmath4 increases , its minimum over @xmath7 is @xmath560 , which is just the condition .",
    "similar to , there must be @xmath110 such that holds . comparing theorem  [ nearapprox ] with theorem  [ ritzvalue ]",
    ", we find out that , as far as the severely or moderately ill - posed problems are concerned , for @xmath7 the near best rank approximation @xmath197 essentially means that the singular values @xmath201 of @xmath154 approximate the first @xmath4 large singular values @xmath45 of @xmath5 in natural order , provided that @xmath112 or @xmath110 suitably .",
    "[ extract ] in terms of the above remarks , theorems  [ main1][ritzvalue ] show that lsqr has the full regularization for these two kinds of ill - posed problems with @xmath112 and @xmath110 suitably and can obtain best possible regularized solutions @xmath170 at semi - convergence .    for mildly ill - posed problems .",
    "we observe that the sufficient condition for is never met for this kind of problem because @xmath561 for any @xmath6 and @xmath562 .",
    "this indicates that , for @xmath7 , the @xmath4 ritz values @xmath201 may not approximate the first @xmath4 large singular values @xmath45 in natural order and particularly there is at least one ritz value @xmath563 , causing that @xmath170 is already deteriorated and can not be as accurate as the best tsvd solution @xmath78 , so that lsqr has only the partial regularization .",
    "we can also make use of theorem  [ initial ] to explain the partial regularization of lsqr : theorem  [ moderate ] has shown that @xmath235 is generally not small and may become arbitrarily large as @xmath4 increases up to @xmath6 for mildly ill - posed problems , meaning that @xmath336 , as the sharp bound indicates , from which it follows that a small ritz value @xmath563 generally appears .",
    "in this section , we will present a number of results on the decay rates of @xmath564 and @xmath565 .",
    "the decay rates of @xmath564 and @xmath565 are particularly useful for practically detecting the degree of ill - posedness of and identifying the full or partial regularization of lsqr .",
    "we prove how @xmath564 and @xmath565 decay by relating them to @xmath488 and the estimates established for it .",
    "then we show how to exploit the decay rate of @xmath566 to identify the degree of ill - posedness of and the regularization of lsqr .",
    "[ main2 ] with the notation defined previously , the following results hold : @xmath567    _ proof_. from , since @xmath568 and @xmath542 are orthogonal matrices , we have @xmath569 with @xmath570 resulting from deleting the @xmath571 leading principal matrix of @xmath545 and the first @xmath4 zero rows and columns of the resulting matrix . from the above , for @xmath210 we have @xmath572 which shows that @xmath573 and @xmath574 since @xmath575 and @xmath576 .",
    "so from , we get and . on the other hand , noting that @xmath577 we get .    note that @xmath578 and @xmath579 . by @xmath580 and , note that @xmath581 equals the 2-norm of the submatrix deleting the first column of @xmath582 . applying the cauchy s strict interlacing theorem to the singular values of this submatrix and @xmath582 , we obtain .    for severely and moderately ill - posed problems , based on the results in the last section , and show that @xmath583 and @xmath584 decay as fast as @xmath169 for @xmath123 and their decays may become slow for @xmath80 . for mildly ill - posed problems , since @xmath476",
    "are generally bigger than one considerably for @xmath123 , @xmath583 and @xmath584 can not generally decay as fast as @xmath169 , and their decays become slower for @xmath80 .",
    "we now shed light on and . for a given",
    ", its degree of ill - posedness is either known or unknown .",
    "if it is unknown , is of practical importance and can be exploited to identify whether or not lsqr has the full regularization without extra cost in an automatic and reliable way , so is . from the proofs of and",
    ", we find that @xmath583 and @xmath584 are as small as @xmath488 .",
    "since our theory and analysis in section [ rankapp ] have proved that @xmath488 decays as fast as @xmath169 for severely or moderately ill - posed problems with @xmath112 or @xmath110 suitably and it decays more slowly than @xmath169 for mildly il - posed problems , the decay rate of @xmath65 can be judged by that of @xmath564 or @xmath565 or better judged by that of @xmath566 reliably , as shown below",
    ".    given , run lsqr until semi - convergence occurs at iteration @xmath585 .",
    "check how @xmath566 decays as @xmath4 increases during the process .",
    "if , on average , it decays in an obviously exponential way , then is a severely ill - posed problem . in this case",
    ", lsqr has the full regularization , and semi - convergence means that we have found a best possible regularized solution .",
    "if , on average , @xmath564 decays as fast as @xmath586 with @xmath110 considerably , then is surely a moderately ill - posed problem , and lsqr also has found a best possible regularized solution at semi - convergence .",
    "if , on average , it decays at most as fast as or more slowly than @xmath586 with @xmath200 no more than one , is a mildly ill - posed problem .",
    "notice that the noise @xmath20 does not deteriorate regularized solutions until semi - convergence .",
    "therefore , if a hybrid lsqr is used , then it is more reasonable and also cheaper to apply regularization to projected problems only from iteration @xmath587 onwards other than from the first iteration , as done in the hybrid lanczos bidiagonalization / tikhonov regularization scheme @xcite , until a best possible regularized solution is found .",
    "huang and jia @xcite have numerically justified the full regularization of lsqr for severely and moderately ill - posed problems and its partial regularization for mildly ill - posed problems @xcite , where each @xmath5 is @xmath588 . in this section , we report numerical experiments to confirm our theory and illustrate the full or partial regularization of lsqr in much more detail .",
    "for the first two kinds of problems , we demonstrate that @xmath589 and @xmath584 decay as fast as @xmath169 .",
    "we compare lsqr and the hybrid lsqr with the tsvd method applied to projected problems after semi - convergence . for each of",
    "severely and moderately ill - posed problems , we show that the regularized solution obtained by lsqr at semi - convergence is at least as accurate as the best tsvd regularized solution , indicating that lsqr has the full regularization . in the meantime , for mildly ill - posed problems ,",
    "we show that the regularized solution obtained by lsqr at semi - convergence is considerably less accurate than @xmath78 , demonstrating that lsqr has only the partial regularization .",
    "we choose several ill - posed problems from hansen s regularization toolbox @xcite , which include the severely ill - posed problems @xmath590 , the moderately ill - posed problems @xmath591 , and the mildly ill - posed problem @xmath592 with the parameter `` example=3 '' .",
    "all the codes are from @xcite , and the problems arise from discretizations of .",
    "we remind that , as far as solving is concerned , our primary goal consists in justifying the regularizing effects of iterative solvers for , which are _ unaffected by the size _ of and only depends on the degree of ill - posedness , the noise level @xmath198 and the actual discrete picard condition , provided that the condition number of , measured by the ratio between the largest and smallest singular values of each @xmath5 , is large enough .",
    "therefore , for this purpose , as extensively done in the literature ( see , e.g. , @xcite and the references therein as well as many other papers ) , it is enough to report the results on small and/or medium sized discrete ill - posed problems since the condition numbers of these @xmath5 are already huge or large , which , in finite precision arithmetic , are roughly @xmath593 and @xmath594 for severely , moderately and mildly ill - posed problems with @xmath595 , respectively .",
    "indeed , for @xmath29 large , say , 10,000 or more , we have observed that lsqr has the same behavior as for small @xmath29 , e.g. , @xmath595 , which is used in this paper .",
    "the only exception is @xmath592 , and we will test a larger one of @xmath596 whose condition number is one order larger than that of @xmath595 , so as to better confirm the partial regularization of lsqr . also , an important reason is that such choice enables us to fully justify the regularization effects of lsqr by comparing it with the tsvd method , which suits only for small and/or medium sized problems because of its computational complexity . for each example",
    ", we generate @xmath5 , @xmath26 and @xmath21 . in order to simulate the noisy data , we generate white noise vectors @xmath20 such that the relative noise levels @xmath597 , respectively .",
    "to simulate exact arithmetic , lsqr uses full reorthogonalization in lanczos bidiagonalization .",
    "all the computations are carried out in matlab 7.8 with the machine precision @xmath598 under the miscrosoft windows 7 64-bit system .      in figure",
    "[ fig1 ] , we display the decay curves of the @xmath488 for @xmath599 with @xmath600 and for @xmath601 with @xmath602 , respectively .",
    "we observe that the three curves with different @xmath603 are almost unchanged .",
    "this is in accordance with our remark  [ decayrate ] , where it is stated that the decay rate of @xmath488 is little affected by noise levels for severely ill - posed problems , since @xmath488 primarily depends on the decay rate of @xmath169 and different noise levels only affect the value of @xmath6 other than the decay rate of @xmath488 .",
    "in addition , we have observed that @xmath488 and @xmath169 decay until they level off at @xmath604 due to round - off errors .",
    "most importantly , the results have clearly confirmed the theory that @xmath488 decreases as fast as @xmath169 , and we have @xmath605 , whose decay curves are almost indistinguishable .    in figure  [ fig2 ] , we plot the relative errors @xmath606 with different @xmath603 for these two problems . as we have seen , lsqr exhibits clear semi - convergence .",
    "moreover , for a smaller @xmath603 , we get a more accurate regularized solution at cost of more iterations , as @xmath6 is bigger from and .     and",
    "@xmath169 for @xmath599 with @xmath607 ( left ) and @xmath608 ( right ) ; ( c)-(d ) : decay curves of the sequences @xmath488 and @xmath169 for @xmath601 with @xmath608 ( left ) and @xmath609 ( right).,width=226,height=170 ]    ( a )     and @xmath169 for @xmath599 with @xmath607 ( left ) and @xmath608 ( right ) ; ( c)-(d ) : decay curves of the sequences @xmath488 and @xmath169 for @xmath601 with @xmath608 ( left ) and @xmath609 ( right).,width=226,height=170 ]    ( b )     and @xmath169 for @xmath599 with @xmath607 ( left ) and @xmath608 ( right ) ; ( c)-(d ) : decay curves of the sequences @xmath488 and @xmath169 for @xmath601 with @xmath608 ( left ) and @xmath609 ( right).,width=226,height=170 ]    ( c )     and @xmath169 for @xmath599 with @xmath607 ( left ) and @xmath608 ( right ) ; ( c)-(d ) : decay curves of the sequences @xmath488 and @xmath169 for @xmath601 with @xmath608 ( left ) and @xmath609 ( right).,width=226,height=170 ]    ( d )     with @xmath610 for @xmath599 ( left ) and @xmath601 ( right).,width=226,height=170 ]    ( a )     with @xmath610 for @xmath599 ( left ) and @xmath601 ( right).,width=226,height=170 ]    ( b )     and @xmath169 for @xmath611 with ( left ) and ( b ) : decay curves of the sequences @xmath488 and @xmath169 for @xmath612 with @xmath608 ( right).,width=226,height=170 ]    ( a )     and @xmath169 for @xmath611 with ( left ) and ( b ) : decay curves of the sequences @xmath488 and @xmath169 for @xmath612 with @xmath608 ( right).,width=226,height=170 ]    ( b )    from figure  [ fig3 ] , we see that @xmath488 decreases almost as fast as @xmath169 for the moderately ill - posed problems @xmath611 and @xmath612",
    ". however , slightly different from severely ill - posed problems , @xmath488 , though excellent approximations to @xmath169 , may not be so very accurate .",
    "this is expected , as the constants @xmath476 in are generally bigger than those in for severely ill - posed problems .",
    "also , different from figure  [ fig1 ] , we observe from figure  [ fig3 ] that @xmath488 deviates more from @xmath169 with @xmath4 increasing , especially for the problem @xmath612 .",
    "this confirms remarks  [ decayrate][decayrate2 ] on moderately ill - posed problems .    in figure  [ fig4 ]",
    ", we depict the relative errors of @xmath166 , and from them we observe analogous phenomena to those for severely ill - posed problems .",
    "the only distinction is that lsqr now needs more iterations , i.e. , a bigger @xmath6 is needed for moderately ill - posed problems with the same @xmath603 , as is seen from and .",
    "with @xmath610 for @xmath611 ( left ) and @xmath612 ( right).,width=226,height=170 ]    ( a )     with @xmath610 for @xmath611 ( left ) and @xmath612 ( right).,width=226,height=170 ]    ( b )     and @xmath169 for @xmath592 with @xmath608,width=226,height=170 ]    ( a )     and @xmath169 for @xmath592 with @xmath608,width=226,height=170 ]    ( b )    figure  [ figmild ] ( a)-(b ) display the decay curves of the partial and complete sequences @xmath488 and @xmath169 for the mildly ill - posed problem deriv2 , respectively .",
    "we see that , different from severely and moderately ill - posed problems , @xmath488 does not decay so fast as @xmath169 and deviates from @xmath169 significantly .",
    "these observations justify our theory and confirm that the rank @xmath4 approximations to @xmath5 generated by lanczos bidiagonalization are not as accurate as those for severely and moderately problems .      for the severely ill - posed @xmath613 and the moderately ill - posed @xmath614 , we now illustrate that @xmath564 and @xmath565 decay as fast as the singular values @xmath65 of @xmath5 .",
    "we take the noise level @xmath608 .",
    "the results are similar for @xmath607 and @xmath322 .",
    "figure  [ fig7 ] illustrates that both @xmath564 and @xmath565 decay as fast as @xmath65 , and for @xmath599 and @xmath601 all of them decay swiftly and level off at @xmath604 due to round - off errors in finite precision arithmetic .",
    "precisely , they reach the level of @xmath604 at @xmath615 and @xmath616 for @xmath599 and @xmath601 , respectively . such decay behavior has also been observed in @xcite , but no theoretical support was given .",
    "these experiments confirm theorem  [ main1 ] and theorem  [ main2 ] , which have proved that @xmath488 decreases as fast as @xmath169 and that @xmath564 , @xmath565 and @xmath566 decay as fast as @xmath65 .    ,",
    "@xmath565 and @xmath65 for @xmath617 and @xmath611 ( from top left to bottom right).,width=226,height=170 ]    ( a )    , @xmath565 and @xmath65 for @xmath617 and @xmath611 ( from top left to bottom right).,width=226,height=170 ]    ( b )    , @xmath565 and @xmath65 for @xmath617 and @xmath611 ( from top left to bottom right).,width=226,height=170 ]    ( c )    , @xmath565 and @xmath65 for @xmath617 and @xmath611 ( from top left to bottom right).,width=226,height=170 ]    ( d )      we compare the performance of lsqr and the tsvd method for the severely ill - posed @xmath590 , the moderately ill - posed @xmath591 and the mildly ill - posed problem @xmath592 of @xmath596 .",
    "we take @xmath608 . for each problem , we compute the relative errors of regularized solutions and the residual norms obtained by the two methods .",
    "we will demonstrate that lsqr has the full regularization for the severely and moderately ill - posed problems , but it has only the partial regularization for the mildly ill - posed problem .",
    "the results on @xmath618 are very similar , and we thus omit them",
    ". figures  [ lsqrtsvd1][lsqrtsvd2 ] indicate lsqr and the tsvd method behave very similarly for @xmath599 and @xmath601 .",
    "they illustrate that , for @xmath601 , the norms of approximate solutions and the relative errors by the two methods are almost indistinguishable for the same @xmath4 , and , for @xmath599 , the residual norms by lsqr decreases more quickly than the ones by the tsvd method for @xmath619 and then they become almost identical starting from @xmath620 .",
    "these results demonstrate that lsqr has the full regularization .    for each of @xmath611 and @xmath612 , figures  [ lsqrtsvd3][lsqrtsvd4 ] demonstrate that the best regularized solution obtained by lsqr is at least as accurate as , in fact , a little bit more accurate than that by the tsvd method , and the corresponding residual norms decreases and drop below at least the same level as those by the tsvd method .",
    "the residual norms by the two methods then stagnate after the best regularized solutions are found .",
    "all these confirm that lsqr has the full regularization .",
    "to better illustrate the regularizing effects of lsqr , we test a larger @xmath592 of @xmath621 whose condition number is @xmath622 .",
    "figure  [ lsqrtsvd5 ] demonstrates that the best regularized solution by lsqr at semi - convergence is considerably less accurate than @xmath78 . actually , the relative error of the former is @xmath623 , while that of the latter is only @xmath624 , almost one order more accurate .",
    "as we have observed , the semi - convergence of lsqr occurs at the very first iteration , while the best regularized solution @xmath78 consists of three dominant svd components of @xmath5 .",
    "the results clearly shows that lsqr has only the partial regularization for mildly ill - posed problems .    from the figures we observe some obvious differences between moderately and severely ill - posed problems . for @xmath611",
    ", it is seen that the relative errors and residual norms converge considerably more quickly for the lsqr solutions than for the tsvd solutions . figure  [ lsqrtsvd3 ] ( a ) tells us that lsqr only uses 12 iterations to find the best regularized solution , but the tsvd method finds the best regularized solution for @xmath625 .",
    "similar differences are observed for @xmath612 , where figure  [ lsqrtsvd4 ] ( a ) indicates that both lsqr and the tsvd method find the best regularized solutions at @xmath626 .",
    "we can observe more .",
    "figure  [ lsqrtsvd3 ] shows that the tsvd solutions improve little and their residual norms decrease very slowly for the indices @xmath627 .",
    "this implies that the @xmath194 corresponding to these indices @xmath62 make very little contribution to the tsvd solutions .",
    "this is due to the fact that the fourier coefficients @xmath628 are very small relative to @xmath45 for these indices @xmath62 .",
    "note that @xmath173 adapts itself in an optimal way to the specific right - hand side @xmath2 , while the tsvd method uses all @xmath629 to construct a regularized solution , independent of @xmath2 .",
    "therefore , @xmath173 picks up only those svd components making major contributions to @xmath26 , such that lsqr uses possibly fewer @xmath4 iterations than @xmath6 needed by the tsvd method to capture those truly needed dominant svd components .",
    "the fact that lsqr ( cgls ) includes fewer svd components than the tsvd solution with almost the same accuracy was first noticed by hanke @xcite .",
    "generally , for severely and moderately ill - posed problems , we may deduce that lsqr uses possibly fewer than @xmath6 iterations to compute a best possible regularized solution if , in practice , some of @xmath630 , @xmath90 are considerably bigger than the corresponding @xmath45 and some of them are reverse . for @xmath612 ,",
    "as noted by hansen @xcite , half of the svd components satisfy @xmath631 for @xmath62 even , only the odd indexed @xmath632 make contributions to @xmath26 .",
    "this is why the relative errors and residual norms of tsvd solutions do not decrease at even indices before @xmath78 is found .",
    ".,width=226,height=170 ]    ( a )    .,width=226,height=170 ]    ( b )    .,width=226,height=170 ]    ( a )    .,width=226,height=170 ]    ( b )    .,width=226,height=170 ]    ( a )    .,width=226,height=170 ]    ( b )    .,width=226,height=170 ]    ( a )    .,width=226,height=170 ]    ( b )    .,width=226,height=170 ]    ( a )    .,width=226,height=170 ]    ( b )",
    "for the large - scale , iterative solvers are the only viable approaches . of them , lsqr and cgls are most popularly used for general purposes , and cgme and lsmr are also choices .",
    "they have general regularizing effects and exhibit semi - convergence .",
    "however , if semi - convergence occurs before it captures all the needed dominant svd components , then best possible regularized solutions are not yet found and the solvers have only the partial regularization . in this case ,",
    "their hybrid variants have often been used to compute best possible regularized solutions .",
    "if semi - convergence means that they have already found best possible regularized solutions , they have the full regularization , and we simply stop them after semi - convergence .    for the case that the singular values of @xmath5 are all simple , we have considered the fundamental open question in depth : do lsqr and cgls have the full or partial regularization for severely , moderately and mildly ill - posed problems ?",
    "we have first considered the case that all the singular values of @xmath5 are simple . as a key and indispensable step ,",
    "we have established accurate bounds for the 2-norm distances between the underlying @xmath4 dimensional krylov subspace and the @xmath4 dimensional dominant right singular subspace for the three kinds of ill - posed problems under consideration .",
    "then we have provided other absolutely necessary background and ingredients . based on them ,",
    "we have proved that , for severely or moderately ill - posed problems with @xmath112 or @xmath110 suitably , lsqr has the full regularization .",
    "precisely , for @xmath123 we have proved that a @xmath4-step lanczos bidiagonalization produces a near best rank @xmath4 approximation of @xmath5 and the @xmath4 ritz values approximate the first @xmath4 large singular values of @xmath5 in natural order , and no small ritz value smaller than @xmath171 appears before a best possible regularized solution has been found . for mildly ill - posed problems",
    ", we have proved that lsqr generally has only the partial regularization since a small ritz value generally appears before all the needed dominant svd components are captured .",
    "since cgls is mathematically equivalent to lsqr , our assertions on the full or partial regularization of lsqr apply to cgls as well .",
    "we have derived bounds for the diagonals and subdiagonals of bidiagonal matrices generated by lanczos bidiagonalization .",
    "particularly , we have proved that they decay as fast as the singular values of @xmath5 for severely ill - posed problems or moderately ill - posed problems with @xmath112 or @xmath110 suitably and decay more slowly than the singular values of @xmath5 for mildly ill - posed problems .",
    "these bounds are of theoretical and practical importance , and they can be used to identify the degree of ill - posedness without extra cost and decide the full or partial regularization of lsqr . we have made detailed and illuminating numerical experiments , confirming our theory .",
    "our analysis approach can be adapted to mr - ii for symmetric ill - posed problems , and certain definitive assertions are expected for three kinds of symmetric ill - posed problems .",
    "our approach are applicable to the preconditioned cgls ( pcgls ) and lsqr ( plsqr ) @xcite by exploiting the transformation technique originally proposed in @xcite and advocated in @xcite or the preconditioned mr - ii @xcite , all of which correspond to a general - form tikhonov regularization involving the matrix pair @xmath633 , in which the regularization term @xmath634 is replaced by @xmath635 with some @xmath34 matrix @xmath636 .",
    "it should also be applicable to the mathematically equivalent lsqr variant @xcite that is based on a joint bidiagonalization of the matrix pair @xmath633 that corresponds to the above general - form tikhonov regularization . in this setting , the generalized svd ( gsvd ) of @xmath633 or the mathematically equivalent svd of @xmath637 will replace the svd of @xmath5 to play a central role in analysis , where @xmath638 is call the _ @xmath5-weighted generalized inverse of @xmath33 _ and @xmath639 if @xmath33 is square and invertible ; see @xcite and @xcite .",
    "i thank dr .",
    "yi huang and mrs .",
    "yanfei yang for running the numerical experiments .",
    "i am grateful to professors  .",
    "bjrck , p. c. hansen , l. reichel and d.  p. oleary for their comments and suggestions that helped improve the presentation of this paper .",
    "bjrck ,  . ,",
    "eldn , l. : methods in numerical algebra for ill - posed problems .",
    "report lith - r-33 - 1979 , dept . of mathematics , linkping univeristy , sweden , ( 1979 ) .",
    "proceedings of the international symposium on ill - posed problems : theory and practice , university of delaware , newark , delaware , oct .",
    "26 , ( 1979 )                                                                                                    jia , z. , niu , d. : a refined harmonic lanczos bidiagonalization method and an implicitly restarted algorithm for computing the smallest singular triplets of large matrices .",
    "siam j. sci .",
    "comput . * 32 * , 714744 ( 2010 )                                                                squire , w. : the solution of ill - conditioned linear systems arising from fredholm equations of the first kind by steepest descents and conjugate gradients .",
    "* 10 * , 607617 ( 1976 )                    van der vorst , h.a . :",
    "computational methods for large eigenvalue problems . in : ciarlet ,",
    "p.g . , cucker , f. , ( eds . ) , handbook of numerical analysis , vol . *",
    "viii * , 3179 .",
    "north holland elsevier , amsterdam ( 2002 )"
  ],
  "abstract_text": [
    "<S> for the large - scale linear discrete ill - posed problem @xmath0 or @xmath1 with @xmath2 contaminated by a white noise , the lanczos bidiagonalization based lsqr method and its mathematically equivalent conjugate gradient ( cg ) method for @xmath3 are most commonly used . </S>",
    "<S> they have intrinsic regularizing effects , where the number @xmath4 of iterations plays the role of regularization parameter . </S>",
    "<S> however , there has been no answer to the long - standing fundamental concern by bjrck and eldn in 1979 : _ for which kinds of problems lsqr and cgls can find best possible regularized solutions _ ? here </S>",
    "<S> a best possible regularized solution means that it is at least as accurate as the best regularized solution obtained by the truncated singular value decomposition ( tsvd ) method or standard - form tikhonov regularization . in this paper , assuming that the singular values of @xmath5 are simple , we analyze the regularization of lsqr for severely , moderately and mildly ill - posed problems . </S>",
    "<S> we establish accurate estimates for the 2-norm distance between the underlying @xmath4-dimensional krylov subspace and the @xmath4-dimensional dominant right singular subspace of @xmath5 . for the first two kinds of problems </S>",
    "<S> , we then prove that lsqr finds a best possible regularized solution at semi - convergence occurring at iteration @xmath6 and that , for @xmath7 , ( i ) the @xmath4-step lanczos bidiagonalization always generates a near best rank @xmath4 approximation to @xmath5 ; ( ii ) the @xmath4 ritz values always approximate the first @xmath4 large singular values in natural order ; ( iii ) the @xmath4-step lsqr always captures the @xmath4 dominant svd components of @xmath5 . for the third kind of problem , we prove that lsqr generally can not find a best possible regularized solution . </S>",
    "<S> we derive estimates for the entries of the bidiagonal matrices generated by lanczos bidiagonalization , which can be practically exploited to identify if lsqr finds a best possible regularized solution at semi - convergence . </S>",
    "<S> numerical experiments confirm our theory . </S>"
  ]
}