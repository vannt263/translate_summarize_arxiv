{
  "article_text": [
    "financial time series are hard to model , since they are heavily influenced by unpredictable events .",
    "natural disasters , uncertainty about public behaviour , statements from governments and central banks , etc .",
    ", are all events that can drastically affect the market . as a consequence financial data",
    "do not behave the same at all times , hence we can not assume any stationarity property for them .",
    "the latter implies that classic techniques used to analyse time series are widely inadequate to model such data , therefore alternative methods have to be developed .",
    "the family of _ markov switching models _ ( msm ) constitutes a possible solution , since these models allow us to effectively address the non - stationarity of financial data .",
    "the main idea behind the msm is that , in order to take into account the changes in the behaviour of the data , we allow the distribution of the observations to change over time . a general msm model can be written in the following form @xmath1 where @xmath2 indicates the state of the model at time @xmath3 , @xmath4 is the vector of the parameters characterizing the model , @xmath5 is the set of all observations up to time @xmath3 , @xmath6 is the set of all observed states up to time @xmath3 , @xmath7 is the set of all possible states , and @xmath8 is the function that governs the transitions between the states .",
    "the function @xmath9 defines how the observation at time @xmath3 depends on @xmath10 and finally , @xmath11 , where @xmath12 , @xmath13 , is the so called _ terminal time_. system clearly shows the intrinsic richness of the msm approach .",
    "particular realizations of allow the treatment of specific problems . before getting into the details of our study ,",
    "it is worth mentioning that in most of the dedicated literature , we can distinguish between two classes of models .",
    "the first class consists of models that have complicated distributions for the data or a large number of states , but very simple transition laws , e.g. , a first order markov chain , see , e.g. , @xcite .",
    "the second class is made up of models with simple assumptions and very few states , usually two , but with more complicated transition laws , see , e.g. , @xcite .",
    "the present paper is structured as follows : in sections 1 through 4 we cover the mathematical and computational theory needed to establish the techniques that we then develop in subsequent sections ; in section 5 we introduce the jump - diffusion model , while in section 6 we present a model that uses @xmath14stable distributions ; in section 7 we explain how the models can be concretely implemented and , in section 8 , we present the related results obtained applying them to a relevant case study which concerns the s&p500 index ; conclusions and further developments are outlined in section 9 .",
    "bayesian inference is a branch of statistical inference that assumes the parameters of a probability distribution to be randomly distributed according to a _",
    "prior _ distribution . in particular",
    "the idea is to exploit the observed data , along with the bayes rule , to generate the _ posterior _ distribution of the aforementioned parameters .",
    "therefore , the posterior distribution can be interpreted as the distribution of the parameters once we have taken into account both our subjective belief about them , namely the prior , and the data .",
    "such an approach can be rigorously represented as follows @xmath15 where @xmath16 is the prior distribution , @xmath17 is the distribution of the data depending on the parameter @xmath4 , and @xmath18 is the posterior of @xmath4 .",
    "finally , @xmath19 is the marginal distribution of @xmath20 , namely @xmath21 clearly the choice of the prior can have a large impact on the posterior .",
    "a particularly convenient form of prior is what is known as a _",
    "conjugate prior_. we say that a prior distribution is conjugate if the posterior distribution derived from it belongs to the same family , as it happens , e.g. , for the beta - bernoulli pair , namely @xmath22    it follows that if we start with a @xmath23 prior and assume that the data are binomially distributed , we end up with a @xmath24 posterior .",
    "hence , we do not have to update the distribution for each new observation , just its parameters .",
    "we would like to note that the latter is a particularly relevant aspect from the algorithmic point of view since it translates into less computationally expensive code .",
    "for the sake of completeness , in the following subsections we list other particularly convenient choices for distribution pairs and , in order to give clear examples , we first start by explaining how the posterior of a set of independent identically distributed ( i.i.d ) random variables is obtained .",
    "let @xmath25 be a set of i.i.d .",
    "random variables with density function @xmath17 .",
    "moreover , let @xmath26 .",
    "then @xmath27 where @xmath28 is the likelihood function of the data , and @xmath29 is the set of all possible values of @xmath4 . for the rest of this paper we will denote the vector of observations by @xmath30 .",
    "assume that we have @xmath31 independent observations @xmath32 where @xmath33 , and the value of @xmath34 is known . in order to perform bayesian inference on the given data , we also need to place a distribution on @xmath35 .",
    "therefore , we set @xmath36 the corresponding likelihood function is @xmath37 while for the posterior we have @xmath38 hence @xmath39      assume again that we have @xmath31 independent observations @xmath40 but , this time , @xmath33 is known , while @xmath34 is unknown .",
    "taking @xmath41 to be inverse - gamma distributed with parameters @xmath42 and @xmath43 , and denoting the distribution by @xmath44 , we can write the density function of @xmath45 as follows @xmath46 where @xmath47 is the extension of the factorial to the set of positive real numbers , known as the _ gamma function _ , and defined by @xmath48 therefore , the associated likelihood function is @xmath49 hence , the posterior is @xmath50    unfortunately , not all distribution pairs are as convenient as the previously mentioned ones , especially from the point of view of the parameter simulation needed by concrete computational studies . when the posterior is a well known distribution , as in the _ normal - normal _ and _ inverse gamma - normal _ cases , we can simulate the parameters using , e.g. , existing r libraries .",
    "otherwise , _ ad hoc _ sampling algorithms have to be developed .",
    "the next section addresses these problems .",
    "in this section , we describe two methods that will be used to sample the parameters , namely , the _ gibbs sampling method _ and the _ metropolis - hastings algorithm_. the latter will be used in situations where the posterior distribution is non - standard , while the former will be used when the distribution can be simulated using an existing software .      assume that we have a model with a finite number @xmath51 of parameters , @xmath52 , and that we want to find the full posterior distribution @xmath53 .",
    "this goal can be quite difficult to reach , since the multivariate simulation of distributions is much more tangled and computationally heavy than its univariate counterpart .",
    "the gibbs sampling approach allows the sampling of @xmath53 , knowing only the conditional distributions @xmath54 .",
    "let @xmath55 be the number of simulations we want to perform .",
    "we assign arbitrary starting values @xmath56 to each of the parameters .",
    "then , for every @xmath57 , we perform the following steps @xmath58 hence we can simulate each of the model parameters .",
    "the first @xmath59 simulations are discarded , being part of what is called the _ burn in period _ , in order to get rid of the dependence on the arbitrary choice of the starting point @xmath56 , while the remaining @xmath60 values are assumed to be a suitable approximation of the real distribution .",
    "it is worth mentioning that the number of iterations , as well as the length of the _ burn in period _",
    ", should be chosen carefully , since for larger values of @xmath55 the simulations become too time consuming , while small values might not provide enough iterations for the sampler to converge .",
    "the gibbs sampler is rather easy to implement , but its major drawback is that it requires each @xmath61 to be readily samplable , where @xmath62 is the vector @xmath63 .",
    "the metropolis - hastings algorithm allows for a solution to such an inconvenience .",
    "in particular , it only requires a function @xmath64 proportional to the density function @xmath65 , and a _ proposal distribution _",
    "@xmath66 which denotes a proper probability density function defined on the space @xmath29 of all possible values of @xmath67 . in what follows",
    "we provide the description of the general metropolis - hastings algorithm , which uses the full parameter vector @xmath67 , as it is reported in @xcite .",
    "we underline that the algorithm remains unchanged when @xmath67 is a scalar .",
    "let @xmath55 be the number of simulations we want to perform .",
    "we assign an arbitrary starting value @xmath68 to the parameter vector .",
    "then , for every @xmath57 , we perform the following steps @xmath69 having defined a method to sample the parameters , we now have the task of simulating the states of the models we will be using .",
    "this problem is the subject of the next section .",
    "in this section our goal is to simulate the state vector @xmath70 . in order to accomplish this ,",
    "we first need to obtain the values @xmath71 .",
    "we start by setting arbitrary values for the parameters , and then we use the following expression @xmath72    notice that , @xmath73 , we can sample from @xmath70 if we have @xmath74 , which is nothing more than the transition probability from one state to another , and @xmath75 .",
    "the latter can be obtained , @xmath76 , exploiting the hamilton filter , see below .",
    "the basic hamilton filter , see @xcite , can be described as input - output - byproduct .",
    "* input : * @xmath77    * output : * @xmath78    * byproduct : * @xmath79    running the hamilton filter for @xmath80 , we get the desired values @xmath81 , which can be used to generate @xmath70 , as described in what follows @xmath82 such a probability is used to draw a sample of @xmath83 , i.e. @xmath84 then , the above probability together with the previously simulated @xmath83 , are both used to simulate @xmath85 , and , proceeding iteratively , we have @xmath86 therefore , we can simulate @xmath87 obtaining the last component of @xmath70 .",
    "the latter implies that , for every @xmath80 , we know what the distribution of @xmath88 is , because we know what the state we are in is . in the next two sections we present the models that will be used later",
    "in the paper _ the variation of certain speculative prices _ , see @xcite , benoit mandelbrot draws attention to the fact that the normal distribution is inadequate when it comes to describing economic and financial data .",
    "he argues that although the histograms of price changes seem to behave according to a gaussian distribution , a more careful analysis reveals that the large number of outliers makes the normal distribution fitted to the data much flatter than the actual data are , and with not enough density at the tails to include all the extreme values .",
    "if one tries to manipulate the variance of the gaussian distribution to accommodate the values around the mean , then the result is a distribution that is even worse than the previous one where the extreme values are concerned .    in what follows",
    "we will show how to solve the aforementioned issue by using a gaussian distribution , to model the values around the mean , plus jumps of stochastic intensity , to include outlying values . specifically , our model is the following @xmath89 \\end{cases}\\ ] ]",
    "we divide the analysis of the model defined in into two components , the _ gaussian component _ and the _ jump component_.      we will use the gaussian distribution to model most of the data by means of the random variable @xmath90 , where both the mean and the variance of @xmath91 are state dependent . in particular , we define the state dependence of the mean as follows @xmath92 hence each state has its own , constant mean , without further restrictions . concerning the variance , we assume that it increases depending on the state , namely @xmath93 where , @xmath94 , @xmath95 , which gives us @xmath96 hence , by , as we go up in states we also go up in volatility .      jump diffusion models , first introduced into finance by robert c. merton in @xcite ,",
    "are currently widely accepted as an effective way to model the behaviour of financial data , see , e.g. , @xcite . in order to incorporate the jump feature in our model",
    ", we have to deal with two major difficulties .",
    "first , we have to find a distribution under which the sum of independent random variables behaves well , at least from the point of view of real statistical applications .",
    "this task is not as straightforward as it may seem , since even the sum of i.i.d .",
    "uniform random variables has a distribution that rapidly grows in complexity with the number of addends . to overcome this particular problem ,",
    "we have chosen to exploit the exponential distribution to model the i.i.d .",
    "jump amplitudes , as the sum of i.i.d .",
    "exponential random variables follows a _ gamma distribution _ , namely @xmath97 where @xmath98 is the gamma distribution in the @xmath99 parameterization , while @xmath100 and @xmath55 are given natural numbers .",
    "the aforementioned choice leads us to the second problem , which concerns the sign of the jumps . obviously , financial shocks can have both positive and negative values , while the gamma distribution allows only for the positive ones .",
    "the issue can be solved by multiplying the sum in by a random variable @xmath101 taking values in @xmath102 , with equal probability .",
    "we refer to the resulting distribution as the _ symmetric gamma distribution _ and we denote it by @xmath103 .",
    "assuming now that @xmath104 , the probability density function of @xmath105 is given by @xmath106 hence @xmath105 has mean equal to zero , and variance @xmath107    looking at eq .",
    "one can see that @xmath108 can be used to control how much @xmath0 influences the variance of the distribution .",
    "for example , if we take two random variables @xmath109 , we have @xmath110 and @xmath111 which is a drastic increase in variance .",
    "taking @xmath112 on the other hand gives us the variances @xmath113 and @xmath114 , which is a much smaller increase , for the same change in @xmath0 .",
    "the previous , rather straightforward observation , will be useful later since in our model @xmath0 will represent the number of jumps at a certain point in time . taking",
    "a large @xmath108 means that every extra jump only slightly increases the variance of the model , hence allowing for a finer analysis of the data .",
    "the next step consists in determining the length @xmath55 of the sum in eq . .",
    "in particular we assume that such a sum has a state dependent length represented by a state - dependent poisson random variable @xmath115 , hence we have to determine the values of @xmath116 . in keeping with the interpretation of the states , see eq . , we want the number of jumps to increase as the state the data are in increases .",
    "this can be done by ordering the parameters @xmath116 . moreover , in order to also allow the parameters to be sufficiently flexible for our purposes , we assume them to be distributed as follows @xmath117 which clearly guarantees that @xmath118 .",
    "summing up the definitions stated in subsections [ gaussianelement ] and [ jumpelement ] , we can write the full model as follows @xmath119 there is no analytic expression for the distribution of @xmath88 , but we can obtain an integral form of it using the following well known fact .",
    "let @xmath105 and @xmath120 be two independent random variables with density functions @xmath121 and @xmath122 , defined for @xmath123 . then the sum @xmath124 is a random variable with density function @xmath125 given by @xmath126 therefore , by the convolution formula in , we have @xmath127 although not very useful in general , the expression in eq",
    ". can be computationally handled with little difficulty , a crucial fact for the concrete case study we will consider in section [ casestudy ] . in the next section we consider the @xmath0-stable distribution model .",
    "in section [ jumpdiffusionmodel ] , we pointed out that the gaussian distribution is not adequate to model financial data , mainly because of its slim tails , which we offset by adding jumps . in",
    "what follows , we will consider a different approach , namely we will model the data using a distribution that has fatter tails than the gaussian one , but still preserves its most important characteristics .",
    "there are multiple equivalent ways to define a stable distribution .",
    "we will consider the two most common ones , the interested reader can refer to , e.g. , @xcite , for the others .",
    "a random variable @xmath105 is said to have a stable distribution if , for every @xmath129 and @xmath130 positive , there exists a positive number @xmath131 and a real number @xmath132 such that    @xmath133    where @xmath134 and @xmath135 are independent copies of @xmath105 and @xmath136 stands for _ equal in distribution_. this implies that the sum of two stable independent identically distributed random variables is still a stable random variable , with the same distribution , up to a _ scale factor _ @xmath131 , and a shift component @xmath132 . as an example",
    ", we can consider two gaussian random variables @xmath134 and @xmath135 , assumed to be independent copies of @xmath137 .",
    "then , @xmath138 , which means that @xmath139 .",
    "alternatively , we can define the stable distribution using characteristic functions , namely    a random variable @xmath105 is said to have a stable distribution if there exist parameters @xmath140 , such that its characteristic function has the form @xmath141 } , & \\alpha \\neq 1 \\\\",
    "e^{\\left [ - \\sigma | \\theta | ( 1 + i \\beta \\frac{2}{\\pi } { \\text{sgn}}(\\theta ) \\ln |\\theta| ) + i \\mu \\theta \\right ] } , & \\alpha = 1      \\end{cases }      \\:.\\ ] ]    we call @xmath0 the _ stability _ parameter , @xmath108 the _ skewness _ parameter , @xmath142 the _ scale _ parameter and @xmath35 the _ location _ parameter . for @xmath143 we obtain the normal distribution , which is the only member of the stable distribution family that has finite variance .",
    "for @xmath144 we have infinite variance and mean @xmath35 , while , for @xmath145 $ ] , both the mean and the variance are undefined .",
    "we note that in general there is not a solution in closed form for the probability density function of a stable distribution .",
    "the stable distribution will be denoted by @xmath146 for the remainder of the paper .      in the model",
    "we propose , the data are assumed to follow a symmetric @xmath0-stable distribution , more precisely @xmath147 .",
    "the full model is presented in the following @xmath148 \\end{cases } \\:.\\ ] ] the motivation behind the choice of the model represented by , mainly relies on empirical observations of financial data which exhibit fat tails that can not be well described using the gaussian approach . in particular",
    "we believe that such phenomenon can be suitably addressed by exploiting @xmath0-stable distributions with @xmath144 .",
    "moreover , financial data often exhibit structural breaks because of abrupt changes in the market , e.g. as during the sub - prime mortgage credit crisis of 2008 , which is the reason why we consider both the scale and the location parameters , to be state - dependent .",
    "as we previously mentioned , in general there is no closed form for the density of an @xmath0-stable distribution .",
    "nevertheless , this problem can be circumvented using the fact that @xmath88 can be conditionally represented as a gaussian random variable , see , e.g. , @xcite , by introducing a random variable @xmath149 and using the property @xmath150 which allows us to have an analytic likelihood function which significantly speeds up the sampling process .",
    "analogously to what we considered in section [ jumpdiffusionmodel ] , we have one mean for each state , without further restrictions , namely @xmath151 we also want the scale parameter to be increasing with respect to the state , namely @xmath152 where @xmath153 , which leads to the property @xmath154 so that an increase in the state number indicates an increase in volatility .",
    "in this section we get into the specifics of our two models .",
    "in particular we provide the details regarding the likelihood functions , the priors and the posteriors , for both the _ jump diffusion model _",
    ", described in section [ jumpdiffusionmodel ] , and for the _ @xmath14stable model _ , defined in section [ alfastablemodel ] .",
    "the concept of duration analysis is also explained , along with its importance .",
    "both of the models will be characterized by four states , with the states being interpreted as _ low , medium , high _ and _ very high _ volatility _",
    "regime_. let us start by defining the following quantities @xmath155 for the rest of this section we will suppress unneeded parameters .",
    "therefore , e.g. , the conditional posterior @xmath156 , will be denoted by @xmath157 , the general rule being that the parameters that are not being inferred on are considered known .",
    "the description of the implementation is divided into three parts , namely : the first part deals with the form of the likelihood function , the second with the priors while the third part provides a detailed analysis of the different types of obtained posteriors .",
    "we have to take into account whether there are jumps in the model or not , as well as the state of each observation . hence ,",
    "if @xmath158 , we define @xmath159 while , if @xmath160 , we define @xmath161 as @xmath162 then , the full likelihood function is @xmath163 which has a standard form only if @xmath164 , for every @xmath165 .",
    "as this very rarely happens , we will use the metropolis - hastings algorithm in this model .",
    "* mean : *    we take the mean to be normally distributed .",
    "moreover , we give the same prior to the means of all the states , namely @xmath166    * variance : *    the variance @xmath167 will have an inverse - gamma prior .",
    "@xmath168    * h parameters : *    we previously saw that in order for to hold , we need @xmath169 , hence we define @xmath170 , for all @xmath171 , and make these parameters frchet distributed , namely @xmath172 then the density function of @xmath173 reads as follows @xmath174 where @xmath175 , and @xmath9 is defined for @xmath176 .    * poisson parameters : *    for the priors of the poisson parameters we refer to .",
    "* transition probabilities : *    for the transition probabilities we will use a dirichlet prior , namely @xmath177 for every @xmath165 .",
    "the density function of this particular dirichlet distribution is given by @xmath178 and it is defined on the simplex @xmath179 while , everywhere else , its value is zero . finally , the parameter @xmath180 is a constant .",
    "* mean : *    because the likelihood function depends on whether or not jumps have occurred , we have two different posteriors for the mean .",
    "in particular , if @xmath164 , by , we have @xmath181 for all @xmath165 , while , if @xmath160 , we obtain @xmath182    * variance : *    similarly to the previous point , we have to differentiate between the jump and no - jump cases . therefore ,",
    "if @xmath164 , by , we have @xmath183 otherwise , we obtain @xmath184    * h parameters : *    in order to obtain @xmath185 , we need to transform the data , also taking into account the different states .",
    "in particular we have the following cases    @xmath186    @xmath187    where we have used the transformed data set @xmath188 to obtain a posterior for @xmath189 when @xmath190 , namely @xmath191    @xmath192    @xmath193    which gives us the posterior @xmath194 hence , when @xmath195 , the posterior is analogous to the one for @xmath189 , with the only difference being that we use @xmath196 instead of @xmath188 .",
    "@xmath197    @xmath198    which yields the posterior @xmath199    in the case where we have jumps , i.e. @xmath200 , there is no analytic expression , therefore @xmath201    * poisson parameters : *    concerning the posterior of the theta parameters , for @xmath165 , we have @xmath202    * transition probabilities : *    the transition probabilities differ from the other parameters in that they do not depend directly on the observations @xmath203 . instead , they depend on the vector of states @xmath70 . assuming that the vector @xmath70 is known , the posterior distribution of the transition probability vector @xmath204 , @xmath165 , has the dirichlet distribution @xmath205 where @xmath206 is the number of transitions from state @xmath171 to state @xmath207 .      in what follows , we proceed analogously to subsection [ subsec : jump_diffusion_model ] .      using the fact that , in the present setting , our data are conditionally normal , see , the likelihood function reads as follows @xmath208 and , unlike in the previous model , we do not have to worry about multiple cases .",
    "* mean : *    the prior of the means is the same as in eq .  .",
    "* scale : *    the distribution of the scale is analogous to that of the variance in the previous model , namely @xmath209    * h parameters : *    these parameters are exactly the same as they were in the previous model , in fact their role remains unchanged , since they allow for the volatility to increase as the states increase .    *",
    "lambda : *    the lambda parameter follows a stable distribution , hence @xmath210      * mean : *    the posterior of the mean is analogous to that of the one in eq .",
    ", with the only difference being the form of the variance .",
    "in particular , we have @xmath211    * scale : *    the posterior of the scale is @xmath212    * h parameters : *    in what follows we limit ourselves to listing the needed transformations , therefore we have    @xmath186    @xmath213    @xmath192    @xmath214    @xmath197    @xmath215    the posteriors are obtained as in the previous case .",
    "* lambda : *    since there is no closed form for the posterior distribution of the lambda parameter , we only write @xmath216    the prior and posterior of the transition probabilities are the same in both proposed models . in fact , the transition probabilities do not depend by any of the parameters , but only by the state vector @xmath83 .",
    "the expected duration of each state for a msm is a quantity of significant interest . having an estimate of",
    "how long a certain data set remains in a particular state can give us useful insights into how the model will behave for a certain period of time . in this section",
    "we are going to explain how the expected duration can be calculated exploiting the transition probabilities .",
    "the expected duration , denoted by @xmath217 , is defined as follows @xmath218\\;,\\ ] ] where @xmath219 is the random variable that models the length of the time interval for which the time series is in state @xmath171 .",
    "the first thing we have to consider is @xmath220 , the probability of the data being in state @xmath171 , meaning @xmath221 where @xmath222 .",
    "it just so happens that @xmath217 has a very simple closed form , in particular @xmath223    we will use the previous expression later on , when we compare the state durations obtained in the present paper , with those provided in @xcite .",
    "we will see that there is a significant difference in the state durations , showing that the models developed in this paper perform better than the one proposed in @xcite to model the time series of the chicago board options exchange volatility index , better known as vix .",
    "our case study is concerned with the application of the above theory to developing an indicator that has a role similar to the one played by the vix .",
    "in particular we use the set of s&p500 weekly prices , considering a time interval that runs from the 3rd of january , 2007 to 29th of december , 2014 .",
    "we picked this interval to include the sub - prime mortgage crash of 2008 as well as the subsequent period of relative calm .",
    "this choice allows us to analyse how our approach performs in both situations .",
    "we will show that our techniques improve the results stated in @xcite , where the model was very effective in periods of high volatility , but also too smooth in case of low volatility .",
    "our results are summarised below with respect to both the _ jump diffusion model _ , defined in section [ jumpdiffusionmodel ] , and the _ @xmath14stable model _ , provided in section [ alfastablemodel ] .      for the jump diffusion model we model the data as a zero mean process in order to make the framework more parsimonious .",
    "we take the exponential distribution parameter @xmath180 to be equal to 40 , in order to make the contribution of each extra jump to the variance relatively small .",
    "this choice of b allows for a finer analysis .",
    "we first present the histograms of the sampled variances , see fig .",
    "[ fig : variance_comparison ] .",
    "as we can see , the algorithm is rather accurate in sampling the variances . in particular , we recall that the theoretical posterior of the variances is an inverse - gamma distribution , which is exactly what we can observe in the histograms .",
    "moreover , in table [ tbl : variance1 ] , we report the point estimates of each variance value .    .gaussian variance point estimates [ cols=\"^,^\",options=\"header \" , ]     one thing that stands out in the mean point estimates , is the sign of the mean of the fourth state , which is negative . the latter should not come as a surprise since it refers to highest volatility value in the time series , namely the one related to the mortgage crisis of 2008 .",
    "we recall that , during a severe financial crisis , most price movements are downward , resulting in a negative drift .",
    "in what follows , we present the transition probability matrix , see eq . , and the transition matrix , see eq .",
    ", namely    @xmath224    @xmath225    as in the previous case , we note the expected values of the state durations obtained using eq . , namely @xmath226 we can note how the difference between the results in and those in , is significant . in order to better explain the latter datum , let us define the volatility indicator within the present framework , and make a comparison with the vix index .",
    "in particular we define a second volatility indicator , denoted by @xmath227 , which , analogously to the previous case , will stand for the expected standard deviation of the data at time @xmath3 , i.e. @xmath228 in fig .",
    "[ fig : stable_comparison ] , we can see a visual comparison between the two values .    using eq . , we obtain @xmath229 , which is a significant increase over @xmath230 .",
    "this leads us to conclude that the estimate obtained from the jump diffusion model is closer to the vix than the one obtained from the @xmath0-stable distribution model .",
    "we now briefly explain the difference between the results in and .",
    "the expected duration of state 1 falls while at the same time there is a drastic increase in the expected durations of states 3 and 4 .",
    "looking at the way the estimators behave in fig .",
    "[ fig : jump_comparison ] and in fig .",
    "[ fig : stable_comparison ] , it is to note that the estimator obtained from the jump diffusion model is much more _ jagged _ , because of the regular transition from one state to another ; while the one obtained from the stable distribution model is much smoother , seeing as the time series tends to stay in the high volatility states much longer .",
    "furthermore , when the stable distribution model has to place observations , that should be in the low volatility states , in the high volatility ones , so that to solve the variance underestimation problem mentioned in @xcite , the jump diffusion model can simply add a few jumps to make up for the missing variance .",
    "this is why , despite its attempts to increase the variance by staying in the higher states , we see the indicator of the stable model _",
    "drooping _ and underestimating the low volatility , while , in this situation , the jump model stays much closer to the vix .",
    "in the present paper we have presented two novel techniques to implement a markov switching model ( msm ) type approach to non - stationary data , namely a jump diffusion - msm and an @xmath14stable - msm . in sec .",
    "[ jump_diffusion_case ] , we have shown that the first one is very effective in mimic the vix index , moreover its implementation can be smoothly done without sacrificing its theoretical peculiarities , see sec .",
    "[ jumpdiffusionmodel ] . a slightly different situation concerns the implementation of the second approach ,",
    "[ alpha_stable_case ] , since eeven if the @xmath0-stable - msm approach turns to be quite effective , we have to consider sampling problems of one of its parameters , implying that computational results do not behave exactly the way the are meant to .",
    "we would like to underline that the achieved tractability of the jump diffusion model is a crucial point , and it witnesses how such technique can be fruitfully used to model any kind of time series presenting pronounced tails , not just financial ones .",
    "as far as the issues of over - smoothing and excessive state duration , which have been stated in @xcite as the main deficiencies of the msm approach to financial data , we have shown that , using the models here presented , the state durations can been significantly reduced , see subsection [ jump_diffusion_case ] , and the problem of over - smoothing can be solved , see subesctions [ jump_diffusion_case ] and [ alpha_stable_case ] .",
    "concerning future developments , we aim at improving our jump diffusion - msm model by considering , instead of a simple first - order markov transition law , a @xmath51-th order markov transition law .",
    "other possibilities consist in dealing with a transition law that is state duration dependent , or allowing the law to depend on other observable quantities used as indicators of the economy behaviour , e.g. , real personal income , industrial production index , rate of private credit growth , etc . +",
    "* acknowledgements : * we would like to sincerely thank matteo frigo for his insightful comments and his fundamental suggestions , which have helped us a lot in preparing the present work , especially with respect to the duration analysis ."
  ],
  "abstract_text": [
    "<S> we perform a detailed comparison between a _ markov switching jump diffusion model _ and a _ markov switching @xmath0-stable distribution model _ with respect to the analysis of non - stationary data . </S>",
    "<S> we show that the jump - diffusion model is extremely robust , flexible and accurate in fitting of financial time series . </S>",
    "<S> a thorough computational study involving the two models being applied to real data , namely , the s&p500 index , is provided . </S>",
    "<S> the study shows that the jump - diffusion model solves the over - smoothing issue stated in  @xcite , while the @xmath0-stable distribution approach is a good compromise between computational effort and performance in the estimate of implied volatility , which is a major problem widely underlined in the dedicated literature , see , e.g. ,  @xcite .    </S>",
    "<S> markov switching , @xmath0-stable distribution , jump - diffusion model , symmetric gamma distribution , regime switching , markov chain monte carlo , metropolis - hastings algorithm . </S>"
  ]
}