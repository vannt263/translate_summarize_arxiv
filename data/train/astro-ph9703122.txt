{
  "article_text": [
    "the availability of fast computers is allowing a huge development of simulations of large @xmath0body systems in astrophysics , as well as in other fields of physics where the behaviour of large systems of particles have to be investigated .",
    "the heaviest computational part of a dynamical simulation of such systems ( composed by point masses and/or smoothed particles representing a gas ) is the evaluation of the _ long  range _ force , such as the gravitational one , acting on every particle and due to all the other particles of the system .",
    "astrophysically realistic simulations require very large @xmath0 ( greater than @xmath3 ) , making the direct @xmath4 pair gravitational interaction evaluations too slow to perform . to overcome this problem various approximated techniques to compute gravitational interactions have been proposed .",
    "+ among them , the tree ",
    "code algorithm proposed by barnes & hut ( hereafter b.h . , see [ @xcite ] ) is now widely used in astrophysics because it does not require any spatial fixed grid ( like , for example , methods based on the solution of poisson s equation ) .",
    "this makes it apt to follow very inhomogeneous and variable in time situations , typical of self  gravitating systems out of equilibrium .",
    "in fact its intrinsic capability to give a rapid evaluation of forces allows to dedicate more cpu  time to follow fast dynamical evolution , contrarily to other higher accuracy methods that are more suitable in other physical situations , e.g. molecular dynamics for polar fluids , where coulomb term is present .",
    "while for the tree  code the cpu  time requirement scales as @xmath5 , in the recently proposed fast multipole algorithm ( hereafter fma , see [ @xcite ] ) this time is claimed to scale as @xmath0 , at least in quasi  homogeneous 2d particle distributions . were this linear behaviour confirmed in 3-d highly non  uniform cases , fma would really be appealing for use in astrophysical simulations .",
    "+ in this paper , we compare cpu times of our own implementations of adaptive 3-d fma and tree ",
    "code to evaluate gravitational forces among @xmath0 particles in two rather different ( uniform and clumped ) spatial configurations .",
    "detailed descriptions of tree  code and fma can be found in [ @xcite ] , [ @xcite ] and [ @xcite ] respectively .",
    "for the purpose of this paper ( the performance comparison of the two above mentioned methods in astrophysically realistic situations ) we built our own computer versions of tree  code and fma . our tree ",
    "code was written following at most the [ @xcite ] prescription but for the short  range component of the interaction force ( see [ @xcite ] ) , while our fma is slightly different from the original proposed by greengard [ @xcite ] , to make it more efficient in non  uniform situations where adaptivity is important , and to include the _ smoothing _ of interactions which is quite useful in astrophysical simulations , as we will describe in sect .",
    "[ descrfma ] .    in sect . 2 and 3 we briefly review the algorithms and give some details of our implementations , in particular for the fma , while in sect",
    "4 the comparison of fma and tree  code cpu ",
    "time performances is presented and discussed .",
    "we have implementated our own version of the `` classic '' bh _ tree  code _ ( see [ @xcite ] or [ @xcite ] ) which is well described in [ @xcite ] ( see also [ @xcite ] ) ; we will give here only a brief discussion of the improvements we have introduced .",
    "in the tree ",
    "code the cubic volume of side @xmath6 that encloses all the particles is subdivided in 8 cubic _ boxes _ ( in 3-d ) and each of them is further subdivided in 8 _ children boxes _ and so on .",
    "the subdivision goes on recursively until the smallest boxes ( the so called _ terminal boxes _ ) have only one particle inside .",
    "moreover the subdivision is local and _ adaptive _ in the sense that it is locally as more refined as the density is higher .",
    "the logical internal representation of this picture is a `` tree data structure '' , from that the denomination _ tree ",
    "code_.    the gravitational force on a given particle in @xmath7",
    "is then computed considering the contribution of the `` clusters '' of particles contained in boxes that are sufficiently distant from the particle , that is in those boxes which satisfy the _",
    "open  angle _ criterion : @xmath8 with @xmath9 the distance between the particle and the center of mass of the cluster , @xmath10 the box size at level @xmath11 of refinement and @xmath12 a parameter a priori fixed .",
    "this contribution is evaluated by means of a truncated multipole expansion that permits to represent the set of @xmath13 particles contained in the box with a unique `` entity '' identified by a relatively low number of attributes ( the total mass , the center of mass , the quadrupole moment ... , that is the set of multipole coefficients ) , that are stored , in a previous step , in the tree data structure . in this way",
    "the evaluation of interactions is speeded  up compared to a direct pair - to - pair evaluation .",
    "usually in tree  codes",
    "second order expansions are used , that is up to the quadrupole term , this approximation being sufficient in typical astrophysical simulations .",
    "those boxes that do not satisfy the condition ( [ opa ] ) , will be `` opened '' and their _ children _ boxes will be considered .",
    "this `` tree descending '' continues until one reaches a terminal box whose contribution to the field will be calculated _",
    "directly_.    the parameter @xmath14 and the order of truncation of the expansion , permit to have some control of the error made in the evaluation of the field in the generic particle position . with the second order of approximation we used and with @xmath14 in the interval @xmath15",
    "$ ] one obtaines a relative error less then about 1% , as we will see in the following .    in our version of the tree ",
    "code we considered a _ gravitational smoothing_.",
    "this means that each particle is represented by a @xmath16-spline ( a polinomial function , with a compact support , differentiable up to the second order ) that gives a newtonian potential outside the sphere centered at the position of the particle and of radius @xmath17 , while inside that sphere the field is _ smoothed _ ; see for example [ @xcite ] and [ @xcite ] . this smoothing avoids divergence in the accelerations during too close approaches between particles whose trajectories would be not well integrated in time by the usual numerical procedures ( like , for example , the _ leap  frog _ scheme ) . in the particular case of our _ static _ test ,",
    "i.e. without considering any time evolution , the smoothing would only be an unnecessary complication ; consequently in these tests we fix @xmath18 for every particle ( exactly newtonian potential ) .",
    "however because of the presence , in general , of a smoothing of the field we have modified the open  angle criteria in the following way : the box of size @xmath6 with center of mass at @xmath19 is `` sufficiently distant '' from the particle in @xmath7 , i.e. its potential can be expandend in a multipole series , if @xmath20 where @xmath17 is the gravitational smoothing `` radius '' of the particle in @xmath7 .",
    "in a way similar to the tree ",
    "code , the fma is based on an approximation of the gravitational field produced by a set of sufficiently distant particles over a generic particle .",
    "it uses the same logical `` octal tree  structure '' of the hierarchical subdivision of the space as the tree ",
    "code , with the only difference that instead of stopping subdivision when boxes contain single particles , in this case the recursive subdivision ends up at boxes containing no more than a fixed number @xmath21 of particles .",
    "this to reduce the cpu ",
    "time required for the calculation .",
    "we still call _ terminal boxes _ the boxes located at the `` leaves '' of the logical tree  structure",
    ". also the fma uses the truncated _ multipole expansion _ , but in a different and more complicated form .",
    "the advantage is that of a more rigorouse control of the truncation error .    in general",
    "the spherical harmonics expansion works for particles interacting via a potential @xmath22 , so , even if we will always speak in terms of gravitational field the treatment is the same in the case of electrostatic field .",
    "the only differences are the coupling constant and the attribute of each particle ( the mass in the gravitational case , the charge with its sign in the electrostatic case ) .",
    "the fma takes advantage of that if we know the coefficients of the _ multipole expansion _ that gives the potential in a point @xmath23 , we are able to build a taylor expansion the so called _ local expansion_ of the potential in a neighbourhood of @xmath23 ( see appendix [ fmatheo ] ) .",
    "this expansion is used to evaluate the acceleration of a particle near @xmath23 , instead of re - evaluating the multipole expansions of the field due to all collections of distant particles as it happens with the tree  code .",
    "furthermore , besides the interaction particle  particle and particle  box , fma considers also an interaction box  box which is estimated by a truncated multipolar expansion , if and only if the boxes are sufficiently distant one each other , that is if they satisfy the so called _ well  separation _ criterion ( which substitutes the open  angle criterion of the tree  code ) .",
    "boxes which are not well  separated , will be `` opened '' and their children boxes considered . in this way one can control the error introduced by the truncation of the multipolar expansion , having this error , as we will see , a well defined upper bound .",
    "in fact we know that , if we have a set of @xmath24 particles at @xmath25 ( we will use spherical coordinates ) having masses @xmath26 , which is enclosed in a sphere @xmath27 with center in the origin and radius @xmath28 , and another set of @xmath29 particles at @xmath30 enclosed in a sphere @xmath31 centered in @xmath32 with radius @xmath33 , then the approximated potential generated by the set of particles in @xmath27 at the position of the @xmath34-th particle in @xmath31 , is given by a multipole expansion truncated at the order @xmath35 : @xmath36 the functions @xmath37 are the spherical harmonics and @xmath38 now one can show ( see [ @xcite ] ) that , for any @xmath39 , @xmath40 where @xmath41 is the exact potential and @xmath42 .",
    "this result gives the possibility to limit the error introduced by approximating @xmath41 with the expression ( [ mul1 ] ) , if the two sets of particles are sufficiently distant .",
    "let @xmath9 be the distance between the centers of the two spheres and let us define @xmath43 the _ separation _ between them .",
    "obviously the set of particles in @xmath31 is such that @xmath44 for any @xmath45 .",
    "then from ( [ err1 ] ) we find : @xmath46 the maximum error of the truncated multipole expansion depends on two quantities : the order of the expansion @xmath35 and the separation @xmath47 .    in his original algorithm ,",
    "greengard introduced the concept of _ well  separation _ between two boxes of the _ same level _ of refinement , i.e. with the same size @xmath6 , to control the truncation error .",
    "suppose to have two sets of particles in two boxes circumscribed by two spheres @xmath27 and @xmath31 , with equal radii @xmath48 : these two boxes are _ well  separated _ if , and only if , their separation is such that @xmath49 , i.e. @xmath50 . in this way",
    "the upper bound on the error will be , from eq .",
    "( [ err2 ] ) , @xmath51 to implement this criterion , greengard imposed simply that : two boxes of the same level are _",
    "well  separated _ if , and only if , there are at least _ two layers of boxes _ of that level between them , in such a way to satisfy the inequality @xmath50 and finally the ( [ errgre ] ) .",
    "note that greengard s well  separation criterion refers exclusively to boxes at the same level of refinement , limiting the efficiency of the algorithm especially in the case of non  uniform distributions of particles .",
    "we have modified this criterion to make it more efficient ( in the _ adaptive _ form of the algorithm ) to face astrophysical typical distributions very far from uniformity .",
    "+ let us briefly explain our modification .",
    "+ first of all , every box is associated to a sphere that is not merely the sphere circumscribing the box but the _ smallest _ one containing all its particle .",
    "so , for terminal boxes , is the smallest sphere concentric to the box and that contains all its particles and for a non  terminal box of size @xmath6 , the sphere is also concentric to the box but the radius @xmath52 is calculated recursively , knowing the radii @xmath53 @xmath54 of the spheres associated to each of its _ children unempty boxes _ , via the formula @xmath55 this sphere contains all the spheres associated to the children boxes ) , for the truncated expansions obtained translating and composing the local and the multipole expansions as discussed in appendix [ fmatheo ] ] .",
    "the value of the radius of these spheres is stored in the `` tree '' data structure together with the other data pertinent to the box and it is much more representative of the `` size '' of the set of particles in the box , than the mere box size @xmath6 , for controlling the truncation error .",
    "now consider the box @xmath56 centered in the origin @xmath57 and containing the collection of @xmath24 particles belonging to the sphere @xmath27 seen before .",
    "let this sphere @xmath27 be its associated sphere with radius @xmath28 ( see fig .",
    "[ fig2 ] ) .",
    "let the other set of particles at @xmath58 , be enclosed in the box @xmath59 whose associated sphere be the sphere @xmath31 centered in @xmath32 and with radius @xmath33 .",
    "the radii @xmath60 have been evaluated by the ( [ radius ] ) .",
    "let us suppose that the separation of the two spheres is such that @xmath61 , with @xmath62 a fixed parameter ( see again fig.[fig2 ] ) .",
    "obviously the set of particles in @xmath31 is such that , from eq .",
    "( [ err2 ] ) , @xmath63 and we can note that the parameter @xmath64 works in a way similar to @xmath14 in the tree  code .    hence , our criterion of _ well  separation _ is the following : once we fixed the parameter @xmath64 , we define two boxes as _ well  separated _ , if the distance between their centers @xmath9 is such that @xmath65 that is if the separation between their associated spheres is @xmath61 . in this way",
    "the evaluation of the interaction between the sets of particles contained into such boxes will be affected by a truncation error which is bounded by the ( [ err3 ] ) .",
    "the implementation of this criterion is very easy because it consists just in verifying the ( [ welsep ] ) where the radii of the spheres associated to the boxes have been already calculated and stored , together with all the other data of each box , in the phase of the algorithm in which the tree ",
    "structure is built .",
    "our criterion of _ well  separation _ is more efficient than the greengard s original one , having the following features :    * it depends upon the internal distribution of particles in the box ( via the radius of the associated sphere ) ; * it can involve boxes of different level of refinement , having different sizes , so to improve efficiency in non  uniform situations and to make unnecessary those complicated tricks conceived to shorten the list of the well  separated boxes like , for example , the mechanism of `` parental conversion '' , ( see [ @xcite ] ) ; * it can be tuned in such a way to obtain the desired accuracy , via the parameter @xmath64 ; * it can be easily modified in order to allow a _ gravitational smoothing _ to be applied to the particles , as we will see below .",
    "note also , see the ( [ errgre ] ) , that to control the truncation error , greengard varied @xmath35 according to the desired accuracy . in our version",
    "we have , instead , fixed @xmath66 and achieved varied the parameter @xmath64 in order to obtain the same accuracy that is usually obtained with the tree  code in astrophysical simulations .",
    "one has to care with keeping reasonably low the execution cpu ",
    "time ( be small compared with human time scale ! ) and this is obtained at a price of a certain loss in accuracy in the evaluation of interactions .",
    "in fact the main characteristics of astrophysical simulations of gravitating systems are :    1 .   they require a great number of particles ( usually more than @xmath67 ) for a rather large duration of the simulation and , in particular , 2 .   due to the intrinsic instability",
    "they offer a very wide distribution of time scales .",
    "so while simulating polar fluids in molecular dynamics , one has to face `` microscopic '' time scales more narrowly distributed ( just because molecules tend to repulse each other due to the presence of short  range interactions , like the lennard ",
    "jones potential ) and one can work with expansions truncated up to eighth order or more ( although the cpu  time grows as @xmath68 , see [ @xcite ] ) , in astrophysical simulations one prefers to limit the precision at a lower but reasonable level and , on the other hand , to be able to process systems which are highly dynamical .",
    "therefore one usually works with expansions truncated up to the second order ( in some cases even the first order ) that , in the tree  code , corresponds to consider up to the quadrupole moment .    for the mass density of the single particle we used the same _ @xmath16spline _ profile as we did in our tree  code . in this way",
    "the potential is exactly newtonian outside the sphere of radius @xmath69 centered in @xmath70 , so it can be expanded in multipole series _ only in this region_. hence the interaction with a particle inside the sphere of radius @xmath69 must be necessarily evaluated by means of a _ direct _ summation .",
    "this requirement , which would be very difficult to incorporate in greengard s criterium , has been considered via a little arrangement of our _ well  separation _ criterium ( [ welsep ] ) , that is : + two boxes ( @xmath56 and @xmath59 ) are _ well  separated _ if , and only if , their spheres ( @xmath27 , with radius @xmath28 and @xmath31 with radius @xmath33 respectively ) are such that : @xmath71 where @xmath9 is the distance between the centers of the two spheres .",
    "the smoothing length @xmath72 used for the box @xmath56 is another quantity stored in the tree data structure and it is given by this simple recursive scheme : if @xmath56 is terminal , then @xmath73 , where @xmath74 is the smoothing lenght of the particle @xmath34 contained in @xmath56 , otherwise @xmath75 , with the maximum taken over all the unempty children boxes @xmath76 of @xmath56 . anyway in the following comparison tests , we let @xmath18 ( as for the tree  code ) because we are not interested in the dynamical evolution of the system .    for a more detailed description of our own implementaton of fma see appendixes [ fmatheo ] and [ formal ]",
    "to compare the cpu  time spent by the two algorithms described in the previous sections , we ran the codes on a ibm r6000 workstation with two different distributions of particles . in the first case",
    "@xmath0 particles have been distributed a _",
    "uniformly _ at random in a sphere of unitary radius . in the second case a set of @xmath0 particles has been distributed , with a monte ",
    "carlo method , in a unitary sphere in such a way to discretize the density profile : @xmath77^{5/2}},\\ ] ] with @xmath78 ( obviously @xmath79 for @xmath80 ) .",
    "this latter is known as schuster s ( [ @xcite ] ) profile ; it corresponds to a polytropic sphere ( of index 5 ) at equilibrium ( see [ @xcite ] ) and represents a good approximation to the density distribution of various stellar systems . in both the uniform and clumped case all the particles",
    "are assumed to have the same mass .",
    "the order of accuracy chosen was the same for both the tree ",
    "code and the fma . for accuracy",
    "we mean how close , in modulus , the evaluated forces are to those calculated `` exactly '' by a direct , _ particle  particle _ ( pp ) method , which is affected only by the numerical error of the computer ( due to the finite number of digits ) .",
    "consequently we define as _ relative error _ of the calculation @xmath81 : @xmath82 where @xmath83 is the modulus of the acceleration of the @xmath34-th particle estimated by each of the two algorithms and @xmath84 that computed by the pp method .",
    "the error on the _ direction _ of the forces is much lower then the error on the modulus we have defined above , and , as it is usual in n  body numerical method , it is not considered at all in performance tests being negligible .",
    "5 truein    5 truein    figure [ fig.err ] gives the relative error of the tree ",
    "code and of the fma in the uniform and `` clumped '' case .",
    "the error is almost the same for both the algorithms .",
    "an averaged ( on all the particles ) relative error less than 1% ( this is the order of magnitude of the error generally admitted in astrophysical simulations ) , is obtained fixing @xmath85 and considering , as we have said , up to the quadrupole term in the tree ",
    "code and to the same order term in the multipole expansion ( @xmath66 ) of the fma .",
    "moreover we chose @xmath86 in the fma as the best compromise between accuracy and computational speed , as we checked .",
    "time spent to calculate the accelerations vs. the number @xmath0 of particles is shown in fig.[fig.time ] . the cpu ",
    "time for the _ particle  particle _ method is also shown as reference . both the algorithms are slower to compute forces in the non  uniform model than in the uniform one , and for the tree ",
    "code this is more evident .",
    "this is clearly due to the more complicated and non - uniform spatial subdivision in boxes that affects mostly the tree ",
    "code due to the _ finer _ and _ deeper _ subdivision of the space it uses .",
    "anyway the tree ",
    "code shows to be faster than the fma for both the distributions and for @xmath0 varying in the range we tested .",
    "as expected , the behaviour of the cpu  time vs. @xmath0 for the tree  code is well fitted by the logaritmic law @xmath87 where @xmath88 and @xmath16 are given in table [ tavola ] . in our opinion , this law must be followed by the fma too , as we will explain in section [ scaling ] .",
    "however , let us observe the cpu ",
    "time for the uniform case : it is not easy to distinguish at a first sight a logarithmic behaviour from a linear one , furthermore we can presume , as we can observe in figure [ fig.time ] , that the fma must show a more complicated behaviour due to the presence of the parameter @xmath89 ( the maximum number of particles leaved in terminal boxes ) and to that @xmath89 was kept _ fixed_. hence for a certain range of @xmath0 this @xmath89 could have been chosen as optimum , but could have not been so for other values of @xmath0 ( in those ranges in which the cpu ",
    "time shows to grow excessively with a slope larger than that of the tree ",
    "code and comparable to that of the pp method ) .",
    "blelloch and narlikar [ @xcite ] have obtained similar `` undulations '' in the behaviour of the cpu  time of their version of fma , while the behaviour of tree ",
    "code was much `` cleaner '' , as in our tests .",
    "coming back to the accuracy , note that for @xmath90 , the rel .",
    "error of the fma exceeds that of the tree ",
    "code ( see fig.[fig.err ] ) . in the same range of @xmath0 the cpu  time of the fma grows less rapidly than that of the tree  code .",
    "this follows the obvious gross rule by which the faster the calculation the lower the precision in the results .",
    "so for @xmath90 the value @xmath86 fixed is likely too small and consequently the percentage of _ direct _ ( pp ) calculation is decreased , so that fma loses precision . on the contrary , for @xmath91 we observe , especially in the schuster case , that @xmath92 ; in the same region the cpu ",
    "time for fma grows more rapidly than for the tree ",
    "code , so in this case @xmath89 seems to be too high .",
    "cc uniform & schuster +    .values obtained for the parameter , fitting the behaviour of the cpu ",
    "time for both algorithms with the law : @xmath93.[tavola ] [ cols=\"^,^,^ \" , ]      +    it is interesting to note that the relative error of the tree  code shows a decrease at increasing the number of particles .",
    "this is probably due to the large fraction of _ direct , particle  particle _ calculations , because of the growing density of particles ( the volume occupied by the system remains the same ) .",
    "this explains also the lower error in the clumped case than in the uniform one at a given @xmath0 , because in the schuster s profile the central density of particles is clearly higher than in the uniform case .",
    "finally we can see that our fma becomes faster than the pp method for @xmath94 in the schuster s model , and for @xmath95 in the uniform case .",
    "+ to make a comparison with codes of other authors , let us consider the fma implemented in 3-d by schmidt and lee [ @xcite ] ( although this code _ is not adaptive _ ) following the original greengard s algorithm and , in particular , his well  separation criterion .",
    "their fma is _ vectorized _ and it runs on a cray y - mp ,",
    "but anyway we do not make a direct comparison , but rather compare our `` cpu  time ratio '' ( that is the ratio between the cpu ",
    "time consumed by fma and that consumed by the direct pp method ) , with the same ratio as obtained by the codes of schmidt and lee , _ at the same order of magnitude of the error on the forces_.    so we can note ( see [ @xcite ] ) that for @xmath96 uniformly distributed particles , a truncation of eighth order ( @xmath97 ) and five levels of refinement ( _ a priori _ chosen ) , they obtain a cpu  time of 418 sec . for their fma , against 11 sec . spent by the _",
    "direct _ pp method , with a relative error on the forces of about @xmath98 .",
    "thus they obtain a ratio @xmath99 , while with our codes we see that for the uniform distribution with @xmath96 , we have an error on the forces that is @xmath100 ( see fig.[fig.err ] ) with a cpu  time ratio @xmath101 , i.e. about the same cpu ",
    "time spent by the pp method ( see fig.[fig.time ] ) .",
    "this seems a very good result .",
    "greengard and other authors ( [ @xcite ] , [ @xcite],[@xcite ] ) assert that fma would exhibit a _ linear _ scaling of cpu ",
    "time vs. @xmath0 .",
    "we tried to fit @xmath102 as function of @xmath0 , with various laws , the linear included .",
    "the result is that a _ logarithmic _ behaviour like that of eq .",
    "( [ tlog ] ) , gives the best fit , as for the tree  code .",
    "the values obtained for @xmath88 and @xmath16 in table [ tavola ] show that @xmath103 : the tree  code is roughly _ three times faster _ than the fma .",
    "note how this difference of performances reduces slightly passing to the schuster clumped profile ; this because , as we have said , our fma adaptive code is less sensitive to the degree of uniformity of the distribution of the particles than the tree ",
    "code which uses a finer subdivision of the space in boxes ( as it corresponds to @xmath104 ) .    the higher speed of the tree  code respect to the fma is easily understood , at least in 3-d , since while in theory the fma is more efficient and less `` redundant '' in managing informations ( remember the use of taylor expansion of the potential on near bodies ) , in practice this `` potential '' greater efficiency pays the price of a certain quantity of computational `` complications ''",
    "this carries the method to a negative total balance in terms of speed respect to the competing tree  code .",
    "how can we interpret the cpu ",
    "time scaling ? + the logarithmic behaviour of the tree ",
    "code is explained by a simple estimate of the number of operations needed by the various steps of the algorithm ( see e.g. [ @xcite],[@xcite ] and [ @xcite ] ) .",
    "it is roughly given by the product between the number of particles @xmath0 by the number of `` bodies '' ( boxes or particles ) , about @xmath105 , which contribute to the force on each particle .",
    "hence @xmath106 .",
    "the logarithmic behaviour of the fma can be similarly understood when one reconsiders carefully the cost of each step of the algorithm .",
    "+ it can be estimated ( see [ @xcite ] ) that @xmath107 that is the cpu ",
    "time is a _ linear function _ of @xmath0 , @xmath108 ( the number of all _ terminal _ boxes ) and @xmath109 ( the number of all non  empty boxes ) .",
    "greengard [ @xcite ] in his final considerations on the scaling of the fma in the adaptive 2-d version ( the 3-d case is similar ) , estimates the number of this types of boxes ( see lemmas 2.6.4 and 2.6.5 in [ @xcite ] ) to be @xmath110 where @xmath111 is the total _ number of subdivisions _ needed to reach terminal boxes .",
    "this @xmath111 is identified by greengard with @xmath112 , where @xmath113 , _ a priori _ fixed , is the _ spatial resolution _ that one wants to reach in the simulation .",
    "being @xmath113 fixed , @xmath111 would be _ independent _ of @xmath0 , thus @xmath108 and @xmath109 , in eq .",
    "( [ tcpufma ] ) , are quantities linear in @xmath0 .",
    "then the fma cpu ",
    "time estimated by the eq .",
    "( [ tcpufma ] ) results linear in @xmath0 too .",
    "the crucial point is that a constant @xmath113 ( and @xmath111 ) allows to manipulate only those distribution of particles such that @xmath114 , with @xmath115 the minimum distance between a pair of particles ( see observation 2.5.1 in [ @xcite ] ) .",
    "obviously , in 3-d , @xmath116 , so that @xmath117 implies @xmath118 substituting this inequality in the expressions ( [ nter ] ) and ( [ nne ] ) for @xmath109 and @xmath108 , one obtains from eq .",
    "( [ tcpufma ] ) that @xmath119 , that is the same `` natural '' scaling of the tree  code .",
    "realistic astrophysical simulations are characterized by the large amount of computations required by the evaluation of gravitational forces . many codes which give performant approximation of the force field",
    "have been proposed in the literature . in this paper",
    "we compare two of these codes : one ( the bh tree ",
    "code ) has been largely used in astrophysics for ten years , the other ( the greengard s fma [ @xcite ] ) has given promising results in the field of molecular dynamics .",
    "+ we have so implemented our own optimized _ serial _ versions of both the tree ",
    "code and _ adaptive _ , 3-d , fma .",
    "the results of our comparison tests indicate the tree ",
    "code as faster than fma over all the interval of total number of particles ( @xmath1 ) allowed by the central memory capacity of a `` typical '' workstation .",
    "this maximum value of @xmath0 , which could appear low respect to modern parallel simulations ( up to @xmath120 ) , is anyway meaningful because even fully parallel codes are limited by an _ individual _",
    "processor charge of that order of magnitude .",
    "the problems in the parallelization of the two codes are comparable due to their similar structure , thus the higher speed of the tree ",
    "code , here verified in a serial context , should be confirmed in the parallel implementation and it seems a valid reason to concentrate efforts for the most efficient parallelization of the tree  code .    at the end of this paper",
    "we have discussed the dependence of the fma cpu ",
    "time on @xmath0 and given explanation of why its behaviour is similar to that of the classic tree  code .",
    "here we briefly describe the three theorems , due to greengard [ @xcite ] , that permits the manipulation , in 3-d , of the various series expansions used in the algorithm , and that are useful for the deeper and formal description of our own implementation that follows in the next appendix [ formal ] .",
    "we have said that one can `` transform '' the multipole expansion ( [ mul1 ] ) into a _ local expansion _",
    "useful to evaluate the field about a given point @xmath23 .",
    "more precisely , given the set of @xmath24 particles at @xmath121 in the sphere @xmath27 ( associated to the box @xmath56 , see the fig .",
    "[ fig2 ] ) which produce the gravitational potential @xmath122 over the set of particles in the sphere @xmath31 ( box @xmath59 ) with center @xmath32 , then one can show that in the vicinity of @xmath32 the approximated potential @xmath123 where @xmath124 , differs from the exact @xmath122 of an amount bounded by the same expression that appears in the r.h.s . of the eq .",
    "( [ err3 ] ) . in this truncated",
    "_ local expansion _",
    "the coefficients are given by : @xmath125 @xmath126 being the _ same _ that appears in the expression ( [ mul1 ] ) and @xmath127 a matrix of coefficients ( see appendix [ coeff ] ) .",
    "another theorem allows us to calculate @xmath126 in a _ recursive _ manner .",
    "let us consider the _ partition _ of the set of @xmath24 particles in the box @xmath56 , in the @xmath128 sub  sets each of them enclosed in the spheres associated to the children boxes of @xmath56 and with centers in @xmath129 .",
    "let @xmath130 be the multipole coefficients calculated for each of the sub  sets of particles .",
    "if all these spheres are enclosed in the sphere @xmath27 ( this is automatically satisfied because of the eq .",
    "( [ radius ] ) ) , the coefficients @xmath131 given by : @xmath132 ( see the appendix [ coeff ] for the matrix @xmath133 ) give a potential @xmath134 ( where @xmath135 is a generic point _ outside _ the sphere @xmath27 ) , which _",
    "well approximates _ the exact potential @xmath136 generated by _ all _ the @xmath24 particles in the sphere @xmath27 .",
    "in fact if @xmath23 is the position of a particle in the _ well  separated _ box @xmath59 , then one can show that : @xmath137 the truncation error has the same upper bound given by ( [ err3 ] ) .",
    "so we can compute @xmath131 associated to the box @xmath56 containing the total set of particles knowing only those pertinent to the @xmath138 sub  sets in each children box . in the tree ",
    "code the same happens , but there the analogous theorem  the `` quadrupole composition theorem''has been developed _ specifically _ for the quadrupole moment by goldstein [ @xcite ] ( those for the monopole and the dipole are obvious ) . in the fma this theorem works for coefficients of any order and it has an upper error bound .",
    "thus , once @xmath126 have been calculated for all _ terminal _ boxes using the definition ( [ mul0 ] ) , by means of ( [ mulcom ] ) we can compute recursively the coefficients of _ parent _ boxes ascending the tree  structure .",
    "this coefficients will be transformed , when needed , in the local expansion coefficients ( as we will see in more details in appendix [ formal ] ) necessary to calculate forces by ( [ tay1 ] ) . in this way",
    ", we will be sure that the error made in approximating the `` true '' potential with the various expansions , will always be bounded by the ( [ err4 ] ) .",
    "the last theorem concerns with the translation and composition of the _ local expansion _ coefficients ( briefly _ taylor coefficients _ ) . in this case",
    "the rules of composition works , in a certain sense , inversely .",
    "that is , given the coefficients @xmath139 relative to the set of @xmath24 particles in the sphere @xmath27 , such that the potential @xmath140 ( @xmath135 is a point _ inside _ @xmath27 ) given by the truncated local expansion about the origin @xmath57 : @xmath141 is such that @xmath142 then at the same point but with another origin @xmath143 , we have the equality @xmath144 where @xmath145 and where the new translated coefficients are : @xmath146 being @xmath147 ( for the matrix @xmath148 see appendix [ coeff ] ) .",
    "thus given the @xmath139 for a box , we can compute the taylor coefficients for all the unempty _ children boxes _ using the above formula , with the new origin @xmath149 at the center of each children boxes .",
    "the process has to be recursively iterated until we reach terminal boxes . but",
    "how can we obtain the coefficients @xmath139 of a box @xmath31 `` the first time '' ( not knowing those of its parent box )",
    "? obviously they will be calculated by means of the ( [ multay ] ) , transforming the multipole coefficients of _ sufficiently distant _ boxes .",
    "that is of boxes that are _ well  separated _ from @xmath31 .",
    "here we describe in deeper detail our version of the fma algorithm that is sligthly different from the original greengard s algorithm in the adaptive implementation .",
    "the differences regard mainly the way interactions between distant boxes and the set of particles in a terminal box are calculated . moreover , as we have said , we have modified the greengard s _ well  separation _ criterion to take into account the presence of a _ smoothing _ of the interaction that in astrophysical simulations , contrarily to molecular dynamics , is unavoidable to include .",
    "let us first introduce some useful definitions : in the following @xmath89 indicates the maximum number of particles in the _ terminal boxes _ and the `` calligraphic '' letters refer to collections of boxes while simple capitals letters refer to single box .",
    "* @xmath150 is the maximum level of refinement reached in the space subdivision ; * @xmath151 indicates the level of box @xmath27 , whereas the level of the _ root box _",
    "@xmath152 , that is the box containing all the particles , is @xmath153 ; * @xmath154 is the set of all boxes at level @xmath29 of refinement ; * @xmath155 is the _ parent _ box of box @xmath27 ; * @xmath156 is the set of all _ children boxes _ of box @xmath27 ; * @xmath157 is the set of all children boxes of each box in the set @xmath158 ; * @xmath159 indicates the set of boxes , of level @xmath151 or @xmath160 , that are _ not well separated _ from box @xmath27 .",
    "the set contains all the _ brothers _ of box @xmath27 , but not @xmath27 itself ; * @xmath161 is the set of _ terminal boxes _ , that is such boxes that have no children because they contain less than @xmath162 particles , so they have not been subdivided ; * @xmath163 , with @xmath164 , is the number of particles inside the terminal boxes @xmath27 ( obviously @xmath165 ) ; * @xmath166 represents the distance between the geometrical centers of boxes @xmath27 and @xmath31 ; * @xmath167 is the length of the _ gravitational smoothing _ relative to the box @xmath27 ; * @xmath168 is the radius of the sphere that contains all the particles in the box @xmath27 and that is concentric to it ( see text ) .    the notation ` do @xmath169 ' ( with @xmath170 integers ) means that all passages included between this statement and the correspondent ` end do ' , are repeated @xmath171 times and every time the integer variable @xmath13 takes the values : @xmath172 , like in the fortran , while the notation ` do @xmath173 ' means , in this case , that every time the loop is executed the _ box _",
    "@xmath27 represents one of the various boxes in the set @xmath158 .",
    "so the statements between ` do ' and the related ` end do ' are repeated card@xmath174 times and each time with a different box @xmath173 .",
    "for example , if @xmath175 , the box @xmath27 is @xmath176 the first time the loop is executed , @xmath177 , the second time and so on .",
    "however , the order the boxes have in the set @xmath158 has no importance in the algorithm . on the contrary in the first case of ` do ... end do ' , the order in the values that @xmath13 takes everytime is important .",
    "another notation is ` do while _ condition _ ' , meaning that it will be executed the statements between this ` do while ... ' and the correspondent ` end do ' , _ while _ the logical condition keeps _",
    "true_.    note that we have simplified the way forces on the particles in terminal boxes are evaluated . in greengard s adaptive algorithm",
    "this is made by means of complicated passages and classifications of boxes into many several collections that are computationally expensive to build up .    in our opinion",
    "this complication is unnecessary , because when one has to consider a terminal box for wich one has the long  range component of the potential in terms of taylor coefficients ( translated from those of its parent box ) , one has only to calculate the short  range forces on the @xmath13 particles ( with @xmath178 ) inside the terminal box , due to a certain set of near boxes and this can be done in the most efficient way by means of the same kind of passages that in the _ tree  code _ are used to evaluate the force on a single particle .",
    "suppose we have to evaluate forces on @xmath179 particles in the terminal box @xmath180 .",
    "when we deal with a non  terminal box @xmath31 and this box is _ not _ well  separated from @xmath180 , then it will be subdivided considering its children boxes and the subdivision is recursively repeated until we reach either terminal or well - separated boxes . the contribution due to terminal boxes will be calculated _ directly _ , that is summing particle  particle interactions .",
    "the contibution due to well  separated boxes will be evaluated converting their multipole expansion coefficients into taylor ones , summing them to the pre ",
    "existent cofficients of the box @xmath180 and then , in a following passage , using these coefficients and the taylor expansion to evaluate gravitational forces at the points occupied by the particle in @xmath180 .",
    "this is done in the last statements of the above description ( from the ` do while ... ' forward ) .",
    "defining @xmath181^{-1/2}$ ] , we have : @xmath182 where @xmath183    \\1 .",
    "barnes , j. & hut , p. 1986,_nature _ , * 324 * , 446 .",
    "2 . binney , j. & tremaine , s. 1987 , _ galactic dynamics _ , ed .",
    "princeton univ . press ( princeton , usa ) .",
    "blelloch , g. & narlikar , g. _ a practical comparison of n  body algorithms _",
    "board jr . , j.a . &",
    "leathrum , j.f .",
    "1992 _ the parallel fma in three dimension _ , technical report , duke university ( usa ) , dept . of electrical engineering .",
    "5 . eastwood , j.w .",
    "& hockney , r.w .",
    "1988 , _ computer simulation using particles _ ed .",
    "adam hilger ( bristol , uk ) .",
    "goldstein , h. 1980 , _ classical mechanics _ ( ed .",
    "wesley ) . 7 .",
    "greengard , l. 1987 , _ the rapid evaluation of potential fields in particle systems _ , phd thesis , mit press ( cambridge , ma , london , uk ) 8 .",
    "hernquist , l. 1987 , _",
    "suppl.s . _ * 64 * , 715 . 9 .",
    "hernquist , l. , katz , n. 1989 , _",
    "s. _ * 70 * , 419 . 10 .",
    "miocchi p. 1994",
    ", graduation thesis , university of laquila ( italy ) , dept . of physics .",
    "salmon , j.k . &",
    "warren , m.s .",
    "astrophysical n - body simulations using hierarchical tree data structures _ , in _ supercomputing 92 _ ( ieee comp . soc . , los alamitos ) 12 .",
    "schmidt , k. & lee , m.a .",
    "1991 _ journ .",
    "* 63 * ( 5/6 ) , 1223 13 .",
    "schuster , a. , 1883 _ british assoc .",
    "report _ , 427 ."
  ],
  "abstract_text": [
    "<S> we present tests of comparison between our versions of the fast multipole algorithm ( fma ) and `` classic '' tree  </S>",
    "<S> code to evaluate gravitational forces in particle systems . </S>",
    "<S> we have optimized the greengard s original version of fma allowing for a more efficient criterion of _ well  separation _ between boxes , to improve the _ </S>",
    "<S> adaptivity _ of the method ( which is very important in highly inhomogeneous situations ) and to permit the _ smoothing _ of gravitational interactions .    </S>",
    "<S> the results of our tests indicate that the tree  code is almost three times faster than fma for both a homogeneous and a clumped distribution , at least in the interval of @xmath0 ( @xmath1 ) here investigated and at the same level of accuracy ( error @xmath2 ) . </S>",
    "<S> this order of accuracy is generally considered as the best compromise between cpu  time consumption and precision for astrophysical simulation . moreover , </S>",
    "<S> the claimed linear dependence on @xmath0 of the cpu  time of fma is not confirmed and we give a `` theoretical '' explanation for that .    </S>",
    "<S> 15.5 true cm # 1    running head : fma and tree  </S>",
    "<S> code comparison    send proofs to :    r. capuzzo  </S>",
    "<S> dolcetta    istituto astronomico , universit la sapienza    via g.m . </S>",
    "<S> lancisi 29 , i-00161 , roma , italy    e  mail : dolcetta@astrmb.rm.astro.it </S>"
  ]
}