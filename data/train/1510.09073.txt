{
  "article_text": [
    "game theory provides a powerful framework to study interactions between individuals (  players \" ) . among the most interesting types of interactions are social dilemmas , which result from conflicts of interest between individuals and groups @xcite .",
    "perhaps the most well - studied model of a social dilemma is the prisoner s dilemma @xcite . a two - player game with actions , @xmath0 (  cooperate \" ) and @xmath1 (  defect \" ) , and payoff matrix , @xmath2 is said to be a prisoner s dilemma if @xmath3 @xcite .",
    "in a prisoner s dilemma , defection is the dominant action , yet the players can realize higher payoffs from mutual cooperation ( @xmath4 ) than they can from mutual defection ( @xmath5 ) , resulting in a conflict of interest between the individual and the pair , which characterizes social dilemmas .",
    "thus , in a one - shot game ( i.e. a single encounter ) , two opponents have an incentive to defect against one another , but the outcome of mutual defection ( the unique nash equilibrium ) is suboptimal for both players .    one proposed mechanism for the emergence of cooperation in games such as the prisoner s dilemma is direct reciprocity @xcite , which entails repeated encounters between players and allows for reciprocation of cooperative behaviors . in an iterated game , a player might forgo the temptation to defect in the present due to the threat of future retaliationthe shadow of the future \" or the possibility of future rewards for cooperating @xcite , phenomena for which there is both theoretical and empirical support @xcite .",
    "one example of a strategy for the iterated game is to copy the action of the opponent in the previous round (  tit - for - tat \" ) @xcite . alternatively",
    ", a player might choose to retain his or her action from the previous round if and only if the most recent payoff was @xmath4 or @xmath6 (  win - stay , lose - shift \" ) @xcite .",
    "these examples are among the simplest and most successful strategies for the iterated prisoner s dilemma @xcite .    in a landmark paper , @xcite",
    "deduce the existence of zero - determinant strategies , which allow a single player to exert much more control over this game than previously thought possible . since their introduction",
    ", these strategies have been extended to cover multiplayer social dilemmas @xcite and temporally - discounted games @xcite .",
    "moreover , zero - determinant strategies have been studied in the context of evolutionary game theory @xcite , adaptive dynamics @xcite , and human behavioral experiments @xcite . in each of these studies ,",
    "the game is assumed to have only two actions : cooperate and defect .",
    "in fact , the qualifier  zero - determinant \" actually reflects this assumption because these strategies force a matrix determinant to vanish for action spaces with only two options .",
    "we show here that this assumption is unnecessary .",
    "more specifically , suppose that players @xmath7 and @xmath8 interact repeatedly with no limit on the number of interactions . for games with two actions , @xmath0 and @xmath1 ,",
    "a memory - one strategy for player @xmath7 is a vector , @xmath9 , where @xmath10 is the probability that @xmath7 cooperates following an outcome in which @xmath7 plays @xmath11 and @xmath8 plays @xmath12 .",
    "let @xmath13 and @xmath14 be the payoff vectors for players @xmath7 and @xmath8 , respectively , and let @xmath15 , @xmath16 , and @xmath17 be fixed constants .",
    "@xcite show that if there is a constant , @xmath18 , for which @xmath19 then @xmath7 can unilaterally enforce the linear relationship @xmath20 on the average payoffs , @xmath21 and @xmath22 , by playing @xmath23 .",
    "a strategy , @xmath23 , that satisfies eq .",
    "( [ eq : pressdysonvector ] ) is known as a  zero - determinant \" strategy due to the fact that @xmath24 causes a particular matrix determinant to vanish @xcite . however , what is important about these strategies is not that they cause some matrix determinant to vanish , but rather that they unilaterally enforce a linear relationship on expected payoffs . therefore , we refer to these strategies and their generalization to arbitrary action spaces as autocratic strategies . of particular interest",
    "are extortionate strategies , which ensure that a player receives an unfair share of the payoffs exceeding the payoff at the nash equilibrium @xcite .",
    "hence , if @xmath5 is the payoff for mutual defection in the prisoner s dilemma , then @xmath23 is a an extortionate strategy for player @xmath7 if @xmath23 enforces the equation @xmath25 for some extortion factor , @xmath26 .",
    "the most common extensions of finite action sets are continuous action spaces .",
    "an element @xmath27 $ ] represents a player s investment or cooperation level ( up to some maximum , @xmath28 ) , such as the amount a player invests in a public good @xcite ; the volume of blood one vampire bat donates to another @xcite ; the amount of resources used by microbes to produce siderophores @xcite ; or the effort expended in intraspecies grooming @xcite .",
    "it is important to note that games with continuous action spaces can yield qualitatively different results than their discrete counterparts .",
    "for example , the strategy  raise - the - stakes \" initially offers a small investment in prisoner s dilemma interactions and subsequently raises the contribution in discrete increments if the opponent matches or betters the investment @xcite .",
    "however , in a continuous action space , raise - the - stakes evolves into defection due to the fact that another strategy can be arbitrarily close  in terms of the initial investment and subsequent increases in contribution  yet exhibit qualitatively different behavior @xcite .",
    "in particular , raise - the - stakes succeeds in a discrete action space but fails in a continuous one .",
    "@xcite calls the vector , @xmath24 , of eq .",
    "( [ eq : pressdysonvector ] ) a press - dyson vector . for continuous action spaces ,",
    "the payoff vectors , @xmath29 and @xmath30 , must be replaced by payoff functions , @xmath31 and @xmath32 .",
    "that is , @xmath33 denotes the payoff to player @xmath34 when @xmath7 plays @xmath11 and @xmath8 plays @xmath12 .",
    "the analogue of the linear combination @xmath35 is the function @xmath36 .",
    "here , we formally define a press - dyson function that extends the press - dyson vector to iterated games with arbitrary action spaces .",
    "this extension allows one to deduce the existence of strategies that unilaterally enforce linear relationships on the payoffs in more general iterated games .",
    "in particular , autocratic ( or zero - determinant strategies ) are not peculiar to games with two ( or even finitely many ) actions .",
    "moreover , under mild conditions , player @xmath7 can enforce a linear relationship on expected payoffs by choosing a memory - one strategy that plays just two actions , despite the fact that the opponent may have an infinite number of actions from which to choose .",
    "we give examples of such autocratic strategies in the continuous donation game , which represents an instance of the prisoner s dilemma but with an extended , continuous action space .",
    "consider a two - player iterated game with actions spaces , @xmath37 and @xmath38 , and payoff functions , @xmath31 and @xmath32 , for players @xmath7 and @xmath8 , respectively .",
    "players @xmath7 and @xmath8 interact repeatedly ( infinitely many times ) , deriving a payoff at each round based on @xmath39 and @xmath40 .",
    "we treat games with temporally - discounted payoffs , which means that for some discounting factor @xmath41 with @xmath42 , a payoff of @xmath43 at time @xmath44 is treated the same as a payoff of @xmath45 at time @xmath46 ( see * ? ? ?",
    "alternatively , one may interpret this game as having a finite number of rounds , where in any given round @xmath41 denotes the probability of another round @xcite , which results in an expected game length of @xmath47 rounds .",
    "suppose that , for each @xmath48 , @xmath49 and @xmath50 are the actions used by players @xmath7 and @xmath8 at time @xmath46 .",
    "then , irrespective of the interpretation of @xmath41 , the average payoff to player @xmath7 is @xmath51 the payoff to player @xmath8 , @xmath22 , is obtained by replacing @xmath39 with @xmath40 in eq .",
    "( [ eq : totaldiscountedpayoff ] ) .",
    "if the strategies of @xmath7 and @xmath8 are stochastic , then the payoffs are random variables with expectations , @xmath21 and @xmath22 ( see * supporting information * ) . of particular interest are memory - one strategies , which are probabilistic strategies that depend on only the most recent outcome of the game . if @xmath52 is a memory - one strategy for @xmath7 , then we denote by @xmath53\\left(s\\right)$ ] the probability that @xmath7 uses @xmath54 after @xmath7 plays @xmath11 and @xmath8 plays @xmath12 ( see fig . [",
    "fig : density ] ) .",
    "the proofs of the existence of zero - determinant strategies ( both in games with and without discounting ) rely heavily on the fact that the action space is finite @xcite . in particular , it remains unclear whether zero - determinant strategies are consequences of the finiteness of the action space or instances of a more general concept .",
    "here , we introduce autocratic strategies as an extension of zero - determinant strategies to discounted games with arbitrary action spaces . the traditional ,",
    "undiscounted case is recovered in the limit @xmath55 .",
    "[ thm : maintheorem ] suppose that @xmath53 $ ] is a memory - one strategy for player @xmath7 and let @xmath56 be player @xmath7 s initial action . if , for some bounded function , @xmath57 , the equation @xmath58\\left(s\\right )   - \\left(1-\\lambda\\right)\\int_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right)\\end{aligned}\\ ] ] holds for each @xmath59 and @xmath60 , then @xmath56 and @xmath53 $ ] together enforce the linear payoff relationship @xmath61 for _ any _ strategy of player @xmath8 .",
    "in other words , the pair @xmath62\\right)$ ] is an autocratic strategy for player @xmath7 .",
    "note that the initial action , @xmath56 , in eq .",
    "( [ eq : mainequation ] ) becomes irrelevant without discounting ( @xmath63 ) .",
    "the function @xmath57 may be interpreted as a  scaling function \" that is used to ensure @xmath53 $ ] is a feasible memory - one strategy ; that is , @xmath57 plays the same role as the scalar @xmath18 in eq .",
    "( [ eq : pressdysonvector ] ) , which is chosen so that the entries of @xmath23 are all between @xmath64 and @xmath43 .",
    "we call the right - hand side of eq .",
    "( [ eq : mainequation ] ) a press - dyson function , which extends the press - dyson vector of eq .",
    "( [ eq : pressdysonvector ] ) to arbitrary action spaces ( see * supporting information * ) .",
    "in contrast to action spaces with two options (  cooperate \" and  defect \" , for instance ) , autocratic strategies are defined only implicitly via eq .",
    "( [ eq : mainequation ] ) for general action spaces ( and actually already for games with just three actions ) .    for each @xmath11 and @xmath12 , the integral , @xmath65\\left(s\\right)$ ] , may be thought of as the weighted average ( expectation ) of @xmath57 with respect to @xmath53 $ ] .",
    "since the integral is taken against @xmath53 $ ] , in general one can not solve eq .",
    "( [ eq : mainequation ] ) explicitly for @xmath53 $ ] , so it is typically not possible to directly specify all pairs @xmath62\\right)$ ] that unilaterally enforce eq .",
    "( [ eq : linearrelationship ] ) .",
    "interestingly , under mild conditions , @xmath52 can be chosen to be a remarkably simple  two - point \" strategy , concentrated on just two actions , @xmath66 and @xmath67 ( see corollary [ cor : maincorollary ] in * supporting information * ) .",
    "player @xmath7 can enforce eq .",
    "( [ eq : linearrelationship ] ) by playing either @xmath66 or @xmath67 in each round , with probabilities determined by the outcome of the previous round ( see fig .  [",
    "fig : density](a ) ) .",
    "thus , a strategy of this form uses the ( memory - one ) history of previous play only to adjust the relative weights placed on @xmath66 and @xmath67 , while @xmath66 and @xmath67 themselves remain unchanged .",
    "unlike in the case of arbitrary @xmath52 , for fixed @xmath57 , @xmath66 , and @xmath67 , it is possible to explicitly solve for all autocratic , two - point strategies on @xmath66 and @xmath67 satisfying eq .",
    "( [ eq : mainequation ] ) ( see remark [ rem : twopointexplicit ] in * supporting information * ) . in a two - action game ,",
    "every memory - one strategy is concentrated on two points , which explains why games like the classical prisoner s dilemma fail to capture the implicit nature of autocratic strategies .",
    "in the classical donation game , cooperators pay a cost , @xmath68 , to provide a benefit , @xmath69 , to the opponent @xcite .",
    "defectors make no donations and pay no costs .",
    "the payoff matrix for this game is given by eq .",
    "( [ eq : classicalpd ] ) with @xmath70 , @xmath71 , @xmath72 , and @xmath73 . for @xmath74",
    "a social dilemma arises because the payoff for mutual defection ( the nash equilibrium ) is strictly less than the payoff for mutual cooperation , yet both players are tempted to shirk donations , which represents an instance of the prisoner s dilemma . in the iterated ( and undiscounted ) version of the donation game",
    ", the main result of @xcite implies that a memory - one strategy for player @xmath7 , @xmath9 , enforces @xmath75 for some @xmath76 and @xmath26 whenever there exists a scalar , @xmath18 , for which    [ eq : pdiscrete ] @xmath77    the term @xmath78 denotes the extortion factor and @xmath76 the baseline payoff , i.e. the payoff of @xmath23 against itself @xcite .",
    "for example , if @xmath79 and @xmath26 , then eq .  ( [ eq : pdiscrete ] ) defines an extortionate strategy , which unilaterally enforces @xmath80 as long as @xmath18 is sufficiently small . in this sense , @xmath18 acts as a scaling factor to ensure",
    "each coordinate of @xmath23 falls between @xmath64 and @xmath43 .    instead of discrete  levels \" of cooperation ,",
    "the continuous donation game admits a range of cooperation levels , @xmath81 $ ] , with @xmath82 indicating maximal cooperation .",
    "the costs and benefits associated with @xmath54 , denoted by @xmath83 and @xmath84 , respectively , are nondecreasing functions of @xmath54 and , in analogy to the discrete case , satisfy @xmath85 for @xmath86 and @xmath87 @xcite . the payoff matrix , eq .",
    "( [ eq : classicalpd ] ) is replaced by payoff functions , with the payoffs to players @xmath7 and @xmath8 for playing @xmath11 against @xmath12 being @xmath88 and @xmath89 , respectively ( i.e. the game is symmetric ) . for this natural extension of the classical donation game ,",
    "we first show the existence of autocratic and , in particular , extortionate strategies , that play only @xmath90 and @xmath91 and ignore all other cooperation levels .      for the continuous donation game , we show , using theorem [ thm : maintheorem ] , that player @xmath7 can unilaterally enforce @xmath75 for fixed @xmath78 and @xmath76 by playing only two actions : @xmath90 ( defect ) and @xmath91 ( fully cooperate ) . conditioned on the fact that @xmath7 plays only @xmath64 and @xmath28 , a memory - one strategy for player @xmath7 is defined by a reaction function , @xmath92 , which denotes the probability that @xmath7 plays @xmath28 following an outcome in which @xmath7 plays @xmath93 and @xmath8 plays @xmath94 $ ] ; @xmath95 is the probability that @xmath7 plays @xmath64 ( i.e. defects ) .",
    "player @xmath7 s initial action is determined by the probability , @xmath96 , that @xmath7 plays @xmath91 in the first round .",
    "consider the function @xmath97 and suppose that @xmath98 . if player @xmath7 s initial action is @xmath91 with probability @xmath96 and @xmath90 with probability @xmath99 then , for sufficiently weak discounting or , equivalently , sufficiently many rounds of interaction , @xmath100 and for @xmath96 falling within a feasible range ( see eq .",
    "( [ sieq : twopointinitialboundextortion ] ) in * supporting information * ) , the reaction function @xmath101 defines a memory - one strategy ,    @xmath102 & = \\left ( 1-p\\left(x , y\\right ) \\right ) \\delta_{0 } + p\\left(x , y\\right ) \\delta_{k } , \\end{aligned}\\ ] ]    where @xmath103 denotes the dirac measure centered at @xmath27 $ ] , that enforces the equation @xmath104 .",
    "if there is no discounting ( i.e. @xmath105 ) , then the initial move is irrelevant and @xmath96 can be anything in the interval @xmath106 $ ] .",
    "note that eq .",
    "( [ eq : twopointdonationexample ] ) represents a reactive strategy @xcite because @xmath7 conditions her play on only the previous move of the opponent ( see fig .",
    "[ fig : donationgame](b ) ) .    for @xmath79 and @xmath26 , eq .",
    "( [ eq : twopointdonationexample ] ) defines an extortionate strategy , @xmath52 , which guarantees player @xmath7 a fixed share of the payoffs over the payoff for mutual defection . if @xmath107 ( and @xmath76 is arbitrary ) , then this strategy is fair since player @xmath7 ensures the opponent has a payoff equal to her own @xcite . on the other hand , if @xmath108 and @xmath26 , then eq .  ( [ eq : twopointdonationexample ] ) defines a generous ( or  compliant \" ) strategy @xcite . by playing a generous strategy , player",
    "@xmath7 ensures that her payoff is at most that of her opponent s . for each of these types of strategies ,",
    "the probability that @xmath7 reacts to @xmath12 by cooperating is increasing as a function of @xmath12 .",
    "in particular , @xmath7 is most likely to cooperate after @xmath8 fully cooperates ( @xmath109 ) and is most likely to defect after @xmath8 defects ( @xmath110 ) .",
    "moreover , this single choice of @xmath111 demonstrates the existence of each of these three classes of autocratic strategies for the continuous donation game provided @xmath41 is sufficiently weak .",
    "similarly , if @xmath112 and @xmath113 , then @xmath114 defines a reaction probability that allows @xmath7 to set @xmath115 for any @xmath17 satisfying @xmath116 , provided @xmath96 falls within a suitable range ( see eq .",
    "( [ sieq : twopointinitialboundequalizer ] ) in * supporting information * ) . a strategy that allows a player to single - handedly set the score of the opponent",
    "is termed an equalizer strategy @xcite . however , no autocratic strategy allows player @xmath7 to set her own score via eq .",
    "( [ eq : mainequation ] ) ( see * supporting information * ) .",
    "these results are consistent with the observations of @xcite that , in the classical prisoner s dilemma without discounting , player @xmath7 can not set her own score but can set player @xmath8 s score to anything between the payoffs for mutual defection and mutual cooperation .",
    "one feature of two - point autocratic strategies is that they allow a player to exert control over the payoffs of a repeated game while ignoring most of the action space .",
    "one drawback is that they restrict the region of feasible game payoffs ( see fig .",
    "[ fig : twopointsimulation ] ) .",
    "this shortcoming of two - point strategies leads to a new class of strategies called deterministic strategies , which are perhaps the simplest alternatives to two - point strategies .",
    "a deterministic strategy requires a player to respond to a history of previous play by playing an action with certainty rather than probabilistically .",
    "for example , a memory - one deterministic strategy for player @xmath7 is defined by ( i ) an initial action , @xmath117 , and ( ii ) a reaction function , @xmath118 , such that @xmath7 plays @xmath119 following an outcome in which @xmath7 plays @xmath11 and @xmath8 plays @xmath12 .",
    "one well - known example of a deterministic strategy is tit - for - tat in the classical prisoner s dilemma , which is defined by @xmath120 ( initially cooperate ) and @xmath121 ( do what the opponent did in the previous round ) .",
    "tit - for - tat is also an autocratic strategy since it enforces the fair relationship @xmath122 @xcite .    for general memory - one deterministic strategies , the condition for the existence of autocratic strategies , eq .",
    "( [ eq : mainequation ] ) , becomes @xmath123 if eq .",
    "( [ eq : mainequationdeterministic ] ) holds for each @xmath59 and @xmath60 , then the deterministic strategy defined by @xmath124 and @xmath125 enforces @xmath20 .",
    "thus , in order to enforce @xmath75 for @xmath98 , one may choose @xmath97 and use the reaction function @xmath126 where @xmath127 denotes the inverse of the function @xmath57 , provided @xmath41 satisfies eq .",
    "( [ eq : deltaconditiondonation ] ) and @xmath124 falls within a feasible range ( see eq .",
    "( [ sieq : deterministicinitialboundextortion ] ) in * supporting information * ) .    similarly , to enforce @xmath115 for @xmath116 , one may choose @xmath128 and use the reaction function @xmath129 provided @xmath113 and , again , @xmath124 falls within a feasible range ( see eq .",
    "( [ sieq : deterministicinitialboundequalizer ] ) in * supporting information * ) .    examples of deterministic extortionate , generous , and equalizer strategies are given in fig .",
    "[ fig : deterministicsimulation ] .",
    "it is evident that deterministic strategies increase the feasible region in which linear payoff relationships can be enforced as compared to their two - point counterparts ( c.f .",
    "[ fig : twopointsimulation ] ) .",
    "in games with two actions , zero - determinant strategies are typically defined via a technical condition such as eq .",
    "( [ eq : pressdysonvector ] ) @xcite .",
    "this definition makes generalizations to games with larger action spaces difficult because eq .",
    "( [ eq : pressdysonvector ] ) makes sense only for two - action games .",
    "therefore , we introduce the more general term autocratic strategy for any strategy that unilaterally enforces a linear relationship on expected payoffs .",
    "of course , this linear relationship is precisely what makes strategies satisfying eq .",
    "( [ eq : pressdysonvector ] ) interesting .",
    "theorem  [ thm : maintheorem ] provides a condition for the existence of autocratic strategies for games with general action spaces .",
    "we illustrate this phenomenon with a continuous - action - space extension of the classical donation game , which represents an instance of the prisoner s dilemma .",
    "the existing literature on zero - determinant strategies for the classical prisoner s dilemma provides no way of treating this continuous extension of the donation game .",
    "however , theorem  [ thm : maintheorem ] makes no assumptions on the action space of the game and thus applies to the continuous donation game as well as its classical counterpart .",
    "surprisingly , in many cases a player can enforce a linear relationship on expected payoffs by playing only two actions , despite the fact that the opponent may have infinitely many actions available to use ( corollary [ cor : maincorollary ] in * supporting information * ) .",
    "we demonstrate that the conditions guaranteeing the existence of extortionate , generous , fair , and equalizer strategies in the continuous donation game are in fact similar to those of the two - action case .",
    "however , despite the simplicity of these two - point strategies , a player needs to know how to respond to every possible move of the opponent ; knowledge of how to respond to just defection ( @xmath110 ) and full cooperation ( @xmath109 ) does not suffice .",
    "therefore , although a player using a two - point strategy plays only @xmath90 and @xmath91 , these strategies represent a departure from the classical donation game .",
    "another important difference is that , whereas in the classical prisoner s dilemma mutual generosity represents a symmetric nash equilibrium @xcite , this need not be the case in the continuous donation game . instead , mutual generosity results in a payoff of @xmath130 for each player , where @xmath28 is the maximal investment , but intermediate levels of cooperation may yield @xmath131 for @xmath132 , i.e. both players fare better if they each invest @xmath133 instead of @xmath28 ( see figs .",
    "[ fig : twopointsimulation ] and [ fig : deterministicsimulation ] ) .",
    "however , no player can enforce a generous relationship with baseline payoff @xmath134 because it is outside of the feasible range for @xmath76 ( see * supporting information * ) .",
    "thus , the performance of a generous strategy as a response to itself depends critically on whether the game has two actions or a continuous range of actions .",
    "extortionate strategies for the iterated prisoner s dilemma are not evolutionarily stable @xcite .",
    "since mutual generosity in the continuous donation game need not be a nash equilibrium , it follows that generous strategies also need not be evolutionarily stable .",
    "moreover , against human opponents , extortioners are punished by a refusal to fully cooperate , while generous players provide their opponents with an incentive to cooperate and fare better in experiments @xcite .",
    "such behavior supports what one would expect from a player using a fair autocratic strategy enforcing @xmath122 ( such as tit - for - tat ) : if the opponent ensures @xmath75 for some @xmath135 , then both players get @xmath76 .",
    "in particular , fair strategies punish extortion and reward generosity . based on our results on generous strategies for the continuous donation game",
    ", it would be interesting to see whether ( human ) experiments support the same conclusion and whether the participants succeed in securing payoffs that exceed those of mutual generosity .",
    "the performance of autocratic strategies in populations , however , is but one perspective on this recently - discovered class of strategies for repeated games .    in games with two discrete actions ,",
    "our definition of a press - dyson function specializes to a multiple of the press - dyson vector , @xmath136 with @xmath0 a constant ( see eq .",
    "( [ eq : pressdysonvector ] ) and * supporting information * for details ) .",
    "the press - dyson vector is recovered by normalizing the press - dyson function and thus eliminating the constant , @xmath0 . however , in games with @xmath137 actions , this function involves at least @xmath138 constants , which , for @xmath139 , can not be eliminated by normalization ( see * supporting information * for an example with three actions ) .",
    "therefore , based on theorem  [ thm : maintheorem ] , in two - action games it is perhaps more appropriate to define a press - dyson vector to be any vector of the form @xmath136 .",
    "this distinction for games with two actions is minor , however , and does not change the fact that theorem @xmath140 covers all of the known results on the existence of zero - determinant strategies for repeated games .",
    "more importantly , however , the analysis of iterated games with only two actions completely misses the fact that autocratic strategies are most naturally presented implicitly via eq .",
    "( [ eq : mainequation ] ) . even in the case of two actions ,",
    "infinitely many autocratic strategies may exist @xcite , but their simplistic nature admits explicit solutions .",
    "our extension shows that , in general , ( i ) autocratic strategies need not be unique and ( ii ) one can not explicitly list all autocratic strategies that produce a fixed press - dyson function .",
    "thus , for arbitrary action spaces ( but already for games with @xmath139 actions ) , the space of autocratic strategies is more sophisticated than two - action games suggest . notwithstanding the intrinsic difficulty in explicitly specifying all autocratic strategies ,",
    "our results demonstrate that these strategies exist in a broad class of games and are not simply consequences of the finiteness of the action space in games such as the prisoner s dilemma .",
    "the authors are grateful to christian hilbe for reading an earlier draft of this manuscript and for suggesting that we look into deterministic strategies .",
    "the authors acknowledge financial support from the natural sciences and engineering research council of canada ( nserc ) , grant rgpin-2015 - 05795 .",
    "41 [ 1]#1 [ 1]`#1 ` urlstyle [ 1]doi : # 1    c.  adami and a.  hintze .",
    "evolutionary instability of zero - determinant strategies demonstrates that winning is not everything .",
    "_ nature communications _ , 4 , aug 2013 .",
    "doi : 10.1038/ncomms3193 .",
    "e.  akin . .",
    "_ games _ , 60 ( 3):0 175190 , jun 2015 .",
    "doi : 10.3390/g6030175 .",
    "m.  y. akinyi , j.  tung , m.  jeneby , n.  b. patel , j.  altmann , and s.  c. alberts . .",
    "_ animal behaviour _ , 850 ( 3):0 559568 , mar 2013 .",
    "doi : 10.1016/j.anbehav.2012.12.012 .",
    "r.  axelrod .",
    "_ the evolution of cooperation_. basic books , 1984 .",
    "r.  axelrod and w.  hamilton . .",
    "_ science _ ,",
    "2110 ( 4489):0 13901396 , mar 1981 .",
    "doi : 10.1126/science.7466396 .",
    "m.  c. boerlijst , m.  a. nowak , and k.  sigmund .",
    "equal pay for all prisoners . _ the american mathematical monthly _ , 1040 ( 4):0 303 , apr 1997 .",
    "doi : 10.2307/2974578 .",
    "p.  dal  b . .",
    "_ american economic review _ , 950 ( 5):0 15911604 , dec 2005 .",
    "doi : 10.1257/000282805775014434 .",
    "r.  m. dawes .",
    "social dilemmas .",
    "_ annual review of psychology _ , 310 ( 1):0 169193 , jan 1980 .",
    "doi : 10.1146/annurev.ps.31.020180.001125 .",
    "a.  w. delton , m.  m. krasnow , l.  cosmides , and j.  tooby .",
    "evolution of direct reciprocity under uncertainty can explain human generosity in one - shot encounters .",
    "_ proceedings of the national academy of sciences _ , 1080 ( 32):0 1333513340 , jul 2011 .",
    "doi : 10.1073/pnas.1102131108 .",
    "m.  doebeli and c.  hauert .",
    "models of cooperation based on the prisoner s dilemma and the snowdrift game . _ ecology letters _ , 80 ( 7):0 748766 , jul 2005 .",
    "doi : 10.1111/j.1461 - 0248.2005.00773.x .",
    "m.  doebeli , c.  hauert , and t.  killingback . .",
    "_ science _ , 3060 ( 5697):0 859862 , oct 2004 .",
    "doi : 10.1126/science.1101456 .",
    "d.  fudenberg and j.  tirole . _ game theory_. the mit press , 1991 .    j.  b. heide and a.  s. miner . the shadow of the future : effects of anticipated interaction and frequency of contact on buy - seller cooperation .",
    "_ academy of management journal _ , 350 ( 2):0 265291 , jun 1992 .",
    "doi : 10.2307/256374 .    c.  k. hemelrijk . .",
    "_ animal behaviour _ , 480 ( 2):0 479481 , aug 1994 .",
    "doi : 10.1006/anbe.1994.1264 .    c.  hilbe , m.  a. nowak , and k.  sigmund . .",
    "_ proceedings of the national academy of sciences _ , 110:0 69136918 , apr 2013 .",
    "doi : 10.1073/pnas.1214834110 .    c.  hilbe , m.  a. nowak , and a.  traulsen . .",
    "_ plos one _ , 80 ( 11):0 e77886 , nov 2013 .",
    "doi : 10.1371/journal.pone.0077886 .    c.  hilbe , t.  rhl , and m.  milinski . .",
    "_ nature communications _ , 5 , may 2014 .",
    "doi : 10.1038/ncomms4976 .    c.  hilbe , b.  wu , a.  traulsen , and m.  a. nowak . .",
    "_ proceedings of the national academy of sciences _ , 1110 ( 46):0 1642516430 , oct 2014 .",
    "doi : 10.1073/pnas.1407887111 .    c.  hilbe , a.  traulsen , and k.  sigmund . .",
    "_ games and economic behavior _ , 92:0 4152 , jul 2015 .",
    "doi : 10.1016/j.geb.2015.05.005 .    c.  hilbe , b.  wu , a.  traulsen , and m.  a. nowak . .",
    "_ journal of theoretical biology _ , 374:0 115124 , jun 2015 .",
    "doi : 10.1016/j.jtbi.2015.03.032 .",
    "t.  killingback and m.  doebeli . .",
    "_ nature _ , 4000 ( 6744):0 518518 , aug 1999 .",
    "doi : 10.1038/22913 .",
    "t.  killingback and m.  doebeli . .",
    "_ the american naturalist _ , 1600 ( 4):0 421438 , oct 2002 .",
    "doi : 10.1086/342070 .",
    "t.  killingback , m.  doebeli , and n.  knowlton . .",
    "_ proceedings of the royal society b : biological sciences _",
    ", 2660 ( 1430):0 17231728 , sep 1999 .",
    "doi : 10.1098/rspb.1999.0838 .",
    "j.  korevaar .",
    "_ tauberian theory_. springer berlin heidelberg , 2004 .",
    "doi : 10.1007/978 - 3 - 662 - 10225 - 1 .",
    "m.  nowak and k.  sigmund .",
    "the evolution of stochastic strategies in the prisoner s dilemma .",
    "_ acta applicandae mathematicae _ , 200 ( 3):0 247265 , sep 1990 .",
    "doi : 10.1007/bf00049570 .",
    "m.  nowak and k.  sigmund . .",
    "_ nature _ , 3640 ( 6432):0 5658 , jul 1993 .",
    "doi : 10.1038/364056a0 .",
    "m.  a. nowak .",
    "_ evolutionary dynamics : exploring the equations of life_. belknap press , 2006 .",
    "m.  a. nowak .",
    "five rules for the evolution of cooperation . _ science _ , 3140 ( 5805):0 15601563 , dec 2006 .",
    "doi : 10.1126/science.1133755 .",
    "l.  pan , d.  hao , z.  rong , and t.  zhou . .",
    "_ scientific reports _ , 5:0 13096 , aug 2015 .",
    "doi : 10.1038/srep13096 .",
    "w.  h. press and f.  j. dyson .",
    "iterated prisoner s dilemma contains strategies that dominate any evolutionary opponent .",
    "_ proceedings of the national academy of sciences _ , 1090 ( 26):0 1040910413 , may 2012 .",
    "doi : 10.1073/pnas.1206569109 .",
    "g.  roberts and t.  n. sherratt .",
    "development of cooperative relationships through increasing investment .",
    "_ nature _ , 3940 ( 6689):0 175179 , jul 1998 .",
    "doi : 10.1038/28160 .",
    "k.  sigmund . _",
    "the calculus of selfishness_. princeton university press , 2010 .",
    "a.  j. stewart and j.  b. plotkin . .",
    "_ proceedings of the national academy of sciences _ , 1090 ( 26):0 1013410135 , jun 2012 .",
    "doi : 10.1073/pnas.1208087109 .",
    "a.  j. stewart and j.  b. plotkin . .",
    "_ proceedings of the national academy of sciences _ , 1100 ( 38):0 1534815353 , sep 2013 .",
    "doi : 10.1073/pnas.1306246110 .",
    "a.  szolnoki and m.  perc . .",
    "_ physical review e _ , 890 ( 2 ) , feb 2014 .",
    "doi : 10.1103/physreve.89.022804 .",
    "r.  l. trivers . .",
    "_ the quarterly review of biology _ , 460 ( 1):0 3557 , mar 1971 .",
    "doi : 10.1086/406755 .",
    "p.  a.  m. van  lange , j.  joireman , c.  d. parks , and e.  van  dijk .",
    "the psychology of social dilemmas : a review . _ organizational behavior and human decision processes _ , 1200 ( 2):0 125141 , mar 2013 .",
    "doi : 10.1016/j.obhdp.2012.11.003 .",
    "l.  m. wahl and m.  a. nowak . .",
    "_ journal of theoretical biology _",
    ", 2000 ( 3):0 307321 , oct 1999 .",
    "doi : 10.1006/jtbi.1999.0996 .",
    "l.  m. wahl and m.  a. nowak . .",
    "_ journal of theoretical biology _",
    ", 2000 ( 3):0 323338 , oct 1999 .",
    "doi : 10.1006/jtbi.1999.0997 .",
    "s.  a. west and a.  buckling .",
    "cooperation , virulence and siderophore production in bacterial parasites .",
    "_ proceedings of the royal society b : biological sciences _ , 2700 ( 1510):0 3744 , jan 2003 .",
    "doi : 10.1098/rspb.2002.2209 .",
    "g.  s. wilkinson .",
    "reciprocal food sharing in the vampire bat .",
    "_ nature _ , 3080 ( 5955):0 181184 , mar 1984 .",
    "doi : 10.1038/308181a0 .",
    "by  action space , \" we mean a measurable space , @xmath141 , equipped with a @xmath142-algebra , @xmath143 ( although we suppress @xmath143 and refer to the space simply as @xmath141 ) .",
    "informally , @xmath141 is the space of actions , decisions , investments , or options available to a player at each round of the iterated interaction and could be a finite set , a continuous interval , or something more complicated . since the players need not have the same action space , we denote by @xmath37 the space of actions available to player @xmath7 and by @xmath38 the space of actions available to player @xmath8 . in what follows",
    ", all functions are assumed to be measurable and bounded .    in each encounter",
    "( i.e.  one - shot game \" ) , the players receive payoffs based on a payoff function ,    @xmath144    the first and second coordinate functions , @xmath39 and @xmath40 , give the payoffs to players @xmath7 and @xmath8 , respectively . an iterated game between players",
    "@xmath7 and @xmath8 consists of a sequence of these one - shot interactions .",
    "if , at time @xmath46 , player @xmath7 uses @xmath145 and player @xmath8 uses @xmath146 , then the ( normalized ) payoff to player @xmath7 for a sequence of @xmath147 interactions ( from time @xmath148 to @xmath149 ) is    @xmath150    where @xmath41 is the discounting factor , @xmath42 . the payoff to player @xmath8 is obtained by replacing @xmath39 by @xmath40 in eq .",
    "( [ eq : totalpayoff ] ) .",
    "thus , the discounted payoffs , @xmath151 , are simply added up and then normalized by a factor of @xmath152 to ensure that the payoff for the repeated game is measured in the same units as the payoffs for individual encounters @xcite . moreover ,",
    "provided the series @xmath153 is cesro summable , meaning @xmath154 exists , we have    @xmath155    ( see * ? ? ?",
    "therefore , payoffs in the undiscounted case may be obtained from the payoffs for discounted games in the limit @xmath156 , provided this limit exists ( see * ? ? ?",
    "* ) .    here",
    ", we consider stochastic strategies that condition on the history of play : both players observe the sequence of play up to the current period and use it to devise an action for the present encounter . in order to formally define such strategies ,",
    "we first recall the notion of  history \" in a repeated game : a history at time @xmath6 is a sequence of action pairs ,    @xmath157    indicating the sequence of play leading up to the interaction at time @xmath6 @xcite . in other words , a history at time",
    "@xmath6 is an element of @xmath158 .",
    "let @xmath159 , where @xmath160 denotes the  empty \" history ( which serves just to indicate that there has been no history of past play , i.e. that the game has not yet begun ) .",
    "the set of all possible histories is the disjoint union , @xmath161 . for",
    "@xmath162 and @xmath163 , let    @xmath164    that is , @xmath165 is the action pair played at time @xmath46 , and @xmath166 is the  sub - history \" of @xmath167 until time @xmath168 .",
    "a pure strategy for player @xmath7 in the repeated game is a map , @xmath169 , indicating an action in @xmath37 ( deterministically ) for each history leading up to the current encounter .",
    "more generally , @xmath7 could look at the history of past play and use this information to choose an action from @xmath37 probabilistically ( rather than deterministically ) .",
    "a strategy of this form is known as a behavioral strategy @xcite . in terms of @xmath170 , a behavioral strategy for player",
    "@xmath7 is a map    @xmath171    where @xmath172 is the space of probability measures on @xmath37 .",
    "an important type of behavioral strategy is a markov strategy , which is a behavioral strategy , @xmath52 , that satisfies @xmath173 = \\sigma_{x}\\left[h^{t}_{t-1}\\right]$ ] .",
    "that is , a markov strategy depends on only the last pair of actions and not on the entire history of play .",
    "note , however , that a markov strategy may still depend on @xmath46 .",
    "if @xmath52 is a markov strategy that does not depend on @xmath46 , then we say that @xmath52 is a stationary ( or memory - one ) strategy .",
    "suppose that @xmath52 and @xmath174 are behavioral strategies for players @xmath7 and @xmath8 , respectively .",
    "consider the map , @xmath142 , defined by the product measure ,    @xmath175\\times\\sigma_{y}\\left[h^{t}\\right ] .\\end{aligned}\\ ] ]    by the hahn - kolmogorov theorem , for each @xmath48 there exists a unique measure , @xmath176 , on @xmath177 such that for each @xmath178 and @xmath179 ,    @xmath180    where , for @xmath181 and @xmath182 , @xmath183 denotes the differential of the measure @xmath184 on @xmath185 . in the case",
    "@xmath148 , this measure is simply the product of the two initial actions , i.e. @xmath186\\times\\sigma_{y}\\left[\\varnothing\\right]$ ] . from these measures ,",
    "we obtain a sequence of measures , @xmath187 , defined by    @xmath188    informally , @xmath189 is the probability that the action pair at time @xmath46 is in @xmath190 , averaged over all histories that lead to @xmath191 .",
    "the sequences , @xmath192 and @xmath193 , admit a convenient format for the expected payoffs , @xmath194 and @xmath195 , to players @xmath7 and @xmath8 , respectively . before stating this result ,",
    "we first formally define expected payoffs for the @xmath196-period game ( where @xmath197 ) :    if @xmath52 and @xmath174 are behavioral strategies for players @xmath7 and @xmath8 , respectively , and if @xmath198 ( see eq .",
    "( [ eq : kappadefinition ] ) ) , then the objective function ( or expected payoff ) for player @xmath7 in the @xmath196-period game is    @xmath199 \\,d\\sigma\\left(h_{\\leqslant t-1}^{t+1},h_{t}^{t+1}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{t+1},h_{1}^{t+1}\\right)\\,d\\sigma\\left(\\varnothing , h_{0}^{t+1}\\right ) .\\end{aligned}\\ ] ]    using @xmath193 , we can write @xmath194 differently :    [ lem : expectedpayoff ] for fixed @xmath52 and @xmath174 generating @xmath193 , we have    @xmath200    as a consequence of lemma [ lem : expectedpayoff ] , we see that @xmath201 exists since @xmath202 is a probability measure and    @xmath203    by the fact that @xmath39 is bounded .",
    "thus , we define the objective function for an infinite game as follows :    if @xmath52 and @xmath174 are behavioral strategies for players @xmath7 and @xmath8 , respectively , and if @xmath198 , then the objective function for player @xmath7 in the infinite game is    @xmath204    classically , the objective function of a repeated game with infinitely many rounds is defined using a distribution over  infinite histories , \" which is generated by the players strategies for the repeated game @xcite . that is , for @xmath205 and some measure , @xmath206 , the objective function of player @xmath7 is defined by    @xmath207    using eq .",
    "( [ eq : expectedpayoff ] ) as an objective function for player @xmath7 , we do not need to worry about what @xmath208 is ( or if it even exists for a general action space ) since eq .",
    "( [ eq : classicalpayoff ] ) , whenever it is defined , must coincide with eq .",
    "( [ eq : expectedpayoff ] ) . to see why ,",
    "suppose that there is a distribution , @xmath208 , on @xmath209 that satisfies    @xmath210    for each @xmath211 .",
    "then , by the dominated convergence theorem , eq .",
    "( [ eq : reductiononcylinders ] ) , and eq .",
    "( [ eq : nudefinition ] ) ,    @xmath212    therefore , assuming lemma [ lem : expectedpayoff ] , the objective function for player @xmath7 defined by @xmath213 is the same as the classical objective function for repeated games when the players strategies produce a probability distribution over infinite histories .",
    "typically , the existence of such a distribution depends on @xmath141 being finite or the measures in @xmath192 being inner regular ( which allows one to deduce the existence of @xmath208 from @xmath192 using the kolmogorov extension theorem ) . in practice , these assumptions are often not unreasonable , but with lemma  [ lem : expectedpayoff ] , we do not need to worry about the existence of such a distribution .    in order to prove lemma [ lem : expectedpayoff ]",
    ", we first need a simple technical result :    [ lem : technicallemma ] suppose that @xmath214 and @xmath215 are measure spaces and @xmath142 is a markov kernel from @xmath214 to @xmath215 .",
    "let @xmath208 be a probability measure on @xmath214 and consider the measure on @xmath215 defined , for @xmath216 , by    @xmath217    for any bounded , measurable function , @xmath218 , we have    @xmath219    where , for each @xmath220 , @xmath221 denotes the differential of the measure @xmath222 on @xmath215 .",
    "since @xmath223 is bounded , there exists a sequence of simple functions , @xmath224 , such that @xmath225 uniformly on @xmath215 . for each @xmath226 , let @xmath227 for some @xmath228 and @xmath229 , where @xmath230 is the characteristic function of @xmath231 ( meaning @xmath232 if @xmath233 and @xmath234 if @xmath235 ) .",
    "by uniform convergence ,    @xmath236    which completes the proof .    by lemma [ lem : technicallemma ] and the definitions of @xmath176 and @xmath202 ,    @xmath237 \\,d\\sigma\\left(h_{\\leqslant t-1}^{t+1},h_{t}^{t+1}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{t+1},h_{1}^{t+1}\\right)\\,d\\sigma\\left(\\varnothing , h_{0}^{t+1}\\right )",
    "\\nonumber \\\\ & = \\frac{1-\\lambda}{1-\\lambda^{t+1}}\\sum_{t=0}^{t}\\lambda^{t}\\int_{h^{t+1}\\in\\mathcal{h}^{t+1 } } u_{x}\\left(h_{t}^{t+1}\\right ) \\,d\\sigma\\left(h_{\\leqslant t-1}^{t+1},h_{t}^{t+1}\\right)\\cdots\\,d\\sigma\\left(h_{\\leqslant 0}^{t+1},h_{1}^{t+1}\\right)\\,d\\sigma\\left(\\varnothing , h_{0}^{t+1}\\right ) \\nonumber \\\\ & = \\frac{1-\\lambda}{1-\\lambda^{t+1}}\\sum_{t=0}^{t}\\lambda^{t}\\int_{h^{t+1}\\in\\mathcal{h}^{t+1 } } u_{x}\\left(h_{t}^{t+1}\\right ) \\,d\\mu_{t}\\left(h^{t+1}\\right ) \\nonumber \\\\ & = \\frac{1-\\lambda}{1-\\lambda^{t+1}}\\sum_{t=0}^{t}\\lambda^{t}\\int_{h^{t+1}\\in\\mathcal{h}^{t+1 } } u_{x}\\left(h_{t}^{t+1}\\right ) \\,d\\mu_{t}\\left(h^{t+1}\\right ) \\nonumber \\\\ & = \\frac{1-\\lambda}{1-\\lambda^{t+1}}\\sum_{t=0}^{t}\\lambda^{t}\\int_{h_{t}^{t+1}\\in s_{x}\\times s_{y } } u_{x}\\left(h_{t}^{t+1}\\right ) \\,d\\nu_{t}\\left(h_{t}^{t+1}\\right ) \\nonumber \\\\ & = \\frac{1-\\lambda}{1-\\lambda^{t+1}}\\sum_{t=0}^{t}\\lambda^{t}\\int_{\\left(x , y\\right)\\in s_{x}\\times s_{y } } u_{x}\\left(x , y\\right ) \\,d\\nu_{t}\\left(x , y\\right ) , \\end{aligned}\\ ] ]    which completes the proof .    the objective function of eq .",
    "( [ eq : expectedpayoff ] ) , which is obtained using lemma  [ lem : expectedpayoff ] , eliminates the need to deal with histories when proving our main results for iterated games .",
    "with the background on expected payoffs now established , we turn our attention to the proofs of the results claimed in the main text :",
    "before proving our main results , we state a technical lemma that generalizes lemma 3.1 of @xcite  which @xcite refer to as akin s lemma  and lemma 1 of @xcite .",
    "this lemma relates the strategies of the two players , @xmath52 and @xmath174 , and the ( discounted ) sequence of play to the initial action of player @xmath7 when @xmath52 is memory - one .",
    "our proof of this lemma is essentially the same as theirs but in the broader setting of a measurable action space :    [ lem : akinslemma ] for any memory - one strategy , @xmath52 , and @xmath238 ,    @xmath239\\left(e\\right ) \\big ] \\,d\\nu_{t}\\left(x , y\\right ) & = \\sigma_{x}^{0}\\left(e\\right ) , \\end{aligned}\\ ] ]    where @xmath56 is the initial action of player @xmath7 .    by the definition of @xmath202",
    ", we have    @xmath240\\left(e\\right ) \\,d\\nu_{t}\\left(x , y\\right ) & = \\nu_{t+1}\\left(e\\times s\\right ) .\\end{aligned}\\ ] ]    therefore , since @xmath202 is a probability measure ( in particular , at most @xmath43 on any measurable set ) for each @xmath46 ,    @xmath241\\left(e\\right ) \\big ] \\,d\\nu_{t}\\left(x , y\\right ) \\nonumber \\\\ & = \\sum_{t=0}^{\\infty}\\lambda^{t}\\big ( \\nu_{t}\\left(e\\times s\\right ) - \\lambda\\nu_{t+1}\\left(e\\times s\\right ) \\big ) \\nonumber \\\\ & = \\nu_{0}\\left(e\\times s\\right ) - \\lim_{t\\rightarrow\\infty}\\lambda^{t+1}\\nu_{t+1}\\left(e\\times s\\right ) \\nonumber \\\\ & = \\nu_{0}\\left(e\\times s\\right ) \\nonumber \\\\ & = \\sigma_{x}^{0}\\left(e\\right ) , \\end{aligned}\\ ] ]    which completes the proof .    by the definitions of @xmath21 and @xmath22",
    ", we have    @xmath242 \\ , d\\nu_{t}\\left(x , y\\right ) .\\end{aligned}\\ ] ]    since our goal is to establish theorem [ thm : maintheorem ] , which states that player @xmath7 can enforce the relation @xmath243 using some @xmath53 $ ] and @xmath56 , as a first step we show that @xmath244 for a particular choice of @xmath245 .",
    "we then deduce theorem [ thm : maintheorem ] by setting    @xmath246    for this known function , @xmath247 .",
    "[ prop : mainproposition ] if @xmath248 is a bounded , measurable function , then    @xmath249\\left(s\\right ) \\right ] \\ , d\\nu_{t}\\left(x , y\\right ) & = \\int_{s\\in s_{x}}\\psi\\left(s\\right ) \\",
    ", d\\sigma_{x}^{0}\\left(s\\right ) , \\end{aligned}\\ ] ]    for any memory - one strategy , @xmath52 , where @xmath56 is the initial action of player @xmath7 .",
    "since @xmath57 is bounded , there exists a sequence of simple functions , @xmath250 , such that @xmath251 uniformly on @xmath141 . for each @xmath226 , let @xmath252 .",
    "using the uniform convergence of this sequence , together with the dominated convergence theorem and lemma [ lem : akinslemma ] , we obtain    @xmath253\\left(s\\right ) \\right ] \\ , d\\nu_{t}\\left(x ,",
    "y\\right ) \\nonumber \\\\ & = \\sum_{t=0}^{\\infty}\\lambda^{t } \\lim_{n\\rightarrow\\infty } \\int_{\\left(x , y\\right)\\in s_{x}\\times s_{y } } \\left [ \\psi_{n}\\left(x\\right ) -",
    "\\lambda\\int_{s\\in s_{x}}\\psi_{n}\\left(s\\right)\\,d\\sigma_{x}\\left[x , y\\right]\\left(s\\right ) \\right ] \\ , d\\nu_{t}\\left(x ,",
    "y\\right ) \\nonumber \\\\ & = \\lim_{n\\rightarrow\\infty } \\sum_{t=0}^{\\infty}\\lambda^{t } \\int_{\\left(x , y\\right)\\in s_{x}\\times s_{y } } \\left [ \\psi_{n}\\left(x\\right ) -",
    "\\lambda\\int_{s\\in s_{x}}\\psi_{n}\\left(s\\right)\\,d\\sigma_{x}\\left[x , y\\right]\\left(s\\right ) \\right ] \\ ,",
    "d\\nu_{t}\\left(x , y\\right ) \\nonumber \\\\ & = \\lim_{n\\rightarrow\\infty } \\sum_{t=0}^{\\infty}\\lambda^{t}\\sum_{i=1}^{n_{n}}c_{i}^{n}\\int_{\\left(x , y\\right)\\in s_{x}\\times s_{y } } \\left [ \\chi_{e_{i}^{n}}\\left(x\\right ) -",
    "\\lambda\\int_{s\\in s_{x}}\\chi_{e_{i}^{n}}\\left(s\\right)\\,d\\sigma_{x}\\left[x , y\\right]\\left(s\\right ) \\right ] \\ , d\\nu_{t}\\left(x ,",
    "y\\right ) \\nonumber \\\\ & = \\lim_{n\\rightarrow\\infty } \\sum_{t=0}^{\\infty}\\lambda^{t}\\sum_{i=1}^{n_{n}}c_{i}^{n}\\int_{\\left(x , y\\right)\\in s_{x}\\times s_{y } } \\big [ \\chi_{e_{i}^{n}}\\left(x\\right ) - \\lambda\\sigma_{x}\\left[x , y\\right]\\left(e_{i}^{n}\\right ) \\big ] \\ , d\\nu_{t}\\left(x , y\\right ) \\nonumber \\\\ & = \\lim_{n\\rightarrow\\infty } \\sum_{i=1}^{n_{n}}c_{i}^{n}\\sum_{t=0}^{\\infty}\\lambda^{t}\\int_{\\left(x , y\\right)\\in s_{x}\\times s_{y } } \\big [ \\chi_{e_{i}^{n}}\\left(x\\right ) - \\lambda\\sigma_{x}\\left[x , y\\right]\\left(e_{i}^{n}\\right ) \\big ] \\ , d\\nu_{t}\\left(x , y\\right ) \\nonumber \\\\ & = \\lim_{n\\rightarrow\\infty } \\sum_{i=1}^{n_{n}}c_{i}^{n}\\sigma_{x}^{0}\\left(e_{i}^{n}\\right ) \\nonumber \\\\ & = \\lim_{n\\rightarrow\\infty } \\int_{s\\in s_{x}}\\psi_{n}\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) \\nonumber \\\\ & = \\int_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) , \\end{aligned}\\ ] ]    which completes the proof .    while proposition [ prop : mainproposition ] applies to discounted games with @xmath254 , we can get an analogous statement for undiscounted games by multiplying both sides of eq .",
    "( [ eq : mainpropequation ] ) by @xmath255 and taking the limit @xmath156 :    if @xmath256 is a bounded , measurable function , then , when the limit exists ,    @xmath257\\left(s\\right ) \\right ] \\ , d\\nu_{t}\\left(x , y\\right ) & = 0\\end{aligned}\\ ] ]    for any memory - one strategy , @xmath52 , where @xmath56 is the initial action of player @xmath7 .",
    "suppose that @xmath53 $ ] is a memory - one strategy for player @xmath7 and let @xmath56 be player @xmath7 s initial action . if , for some bounded function , @xmath57 , the equation    @xmath258\\left(s\\right ) - \\left(1-\\lambda\\right)\\int_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right)\\end{aligned}\\ ] ]    holds for each @xmath59 and @xmath60 , then @xmath56 and @xmath53 $ ] together enforce the linear payoff relationship    @xmath259    for _ any _ strategy of player @xmath8 .",
    "in other words , the pair @xmath260\\big)$ ] is an autocratic strategy .    if eq .",
    "( [ eq : mainsiequation ] ) holds , then by eq .",
    "( [ eq : mainpropequation ] ) in proposition [ prop : mainproposition ] ,    @xmath261\\left(s\\right ) \\right ] \\ , d\\nu_{t}\\left(x ,",
    "y\\right ) \\nonumber \\\\ & = \\left(1-\\lambda\\right)\\int_{s\\in s_{x}}\\psi\\left(s\\right ) \\ , d\\sigma_{x}^{0}\\left(s\\right ) , \\end{aligned}\\ ] ]    and it follows at once that @xmath20 .",
    "[ cor : maincorollary ] let @xmath262 and suppose that there exist @xmath263 ( i.e. two discrete actions ) and @xmath264 such that    [ eq : corollaryequation ] @xmath265    for each @xmath60 , where @xmath96 is the probability that @xmath7 initially uses @xmath66 and @xmath99 is the probability that @xmath7 initially uses @xmath67",
    ". let @xmath103 be the dirac measure on @xmath141 centered at @xmath54 , and , for @xmath266 and @xmath60 , consider the memory - one strategy ,    @xmath267 & : = p\\left(x , y\\right)\\delta_{s_{1 } } + \\big(1-p\\left(x , y\\right)\\big)\\delta_{s_{2 } } , \\end{aligned}\\ ] ]    where    @xmath268    then , irrespective of player @xmath8 s strategy , this choice of @xmath96 and @xmath53 $ ] enforces @xmath20 .",
    "by theorem [ thm : maintheorem ] , we need only show that there exists @xmath269 such that    @xmath270\\left(s\\right ) -\\left(1-\\lambda\\right)\\int_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right)\\end{aligned}\\ ] ]    for each @xmath59 and @xmath60 in order to establish the equation @xmath20 . indeed , since we are restricting @xmath7 s actions to two points , we may assume that @xmath271 .",
    "fix @xmath272 and let @xmath273 .",
    "since    @xmath274\\left(s\\right ) - \\left(1-\\lambda\\right)\\int_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) \\nonumber \\\\ & = \\psi_{1 } - \\lambda\\left(\\psi_{1}+\\left(1-p\\left(s_{1},y\\right)\\right)\\frac{1}{\\phi}\\right ) - \\left(1-\\lambda\\right)\\left(\\psi_{1}+\\left(1-p_{0}\\right)\\frac{1}{\\phi}\\right ) \\nonumber \\\\ & = \\alpha u_{x}\\left(s_{1},y\\right ) + \\beta u_{y}\\left(s_{1},y\\right ) + \\gamma\\end{aligned}\\ ] ]    and    @xmath275\\left(s\\right ) - \\left(1-\\lambda\\right)\\int_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) \\nonumber \\\\ & = \\frac{1}{\\phi } + \\psi_{1 } - \\lambda\\left(\\psi_{1}+\\left(1-p\\left(s_{2},y\\right)\\right)\\frac{1}{\\phi}\\right ) - \\left(1-\\lambda\\right)\\left(\\psi_{1}+\\left(1-p_{0}\\right)\\frac{1}{\\phi}\\right ) \\nonumber \\\\ & = \\alpha u_{x}\\left(s_{2},y\\right ) + \\beta u_{y}\\left(s_{2},y\\right ) + \\gamma , \\end{aligned}\\ ] ]    and since @xmath276 for each @xmath266 and @xmath60 by eq .",
    "( [ eq : corollaryequation ] ) , the proof is complete .    in the undiscounted case ( @xmath105 ) , eq .",
    "( [ eq : corollaryequation ] ) is satisfied for some @xmath264 if and only if there exist @xmath263 such that    @xmath277    for every @xmath60 .",
    "moreover , if eq .",
    "( [ eq : corollaryequation ] ) holds for some @xmath41 , @xmath96 , @xmath18 , and @xmath263 , then it must be true that eq .",
    "( [ eq : underoverzero ] ) also holds for every @xmath60 .",
    "( [ eq : underoverzero ] ) does not hold for a particular choice of @xmath263 , then @xmath66 and @xmath67 can not form a two - point autocratic strategy for any discounting factor , @xmath41 . therefore , eq .",
    "( [ eq : underoverzero ] ) , which is easy to check , offers a straightforward way to show that two actions can not form a two - point autocratic strategy for a particular game .    [ rem : twopointexplicit ] for @xmath57 , @xmath66 , and @xmath67 , fixed , one can ask which strategies of the form    @xmath278 & = p\\left(x , y\\right)\\delta_{s_{1}}+\\big(1-p\\left(x , y\\right)\\big)\\delta_{s_{2 } } , \\end{aligned}\\ ] ]    for some @xmath96 and @xmath92 , satisfy the equation    @xmath270\\left(s\\right ) - \\left(1-\\lambda\\right)\\int_{s\\in s_{x}}\\psi\\left(s\\right)\\,d\\sigma_{x}^{0}\\left(s\\right ) .\\end{aligned}\\ ] ]    indeed , we see from the proof of corollary [ cor : maincorollary ] that , for a strategy of this form , we must have    @xmath279    for each @xmath266 and @xmath60 . therefore , this simple case does not capture the generally - implicit nature of autocratic strategies because one can explicitly write down two - point strategies via eq .",
    "( [ eq : omegaexpression ] ) , which is typically not possible for strategies concentrated on more than just two actions .",
    "here we present some simple examples of theorem [ thm : maintheorem ] and its implications . in  [ si : sizefinite ] , we demonstrate how theorem [ thm : maintheorem ] reduces to the main result of @xcite when the action space has only two options .",
    "moreover , we use an action space consisting of three choices to illustrate the implicit nature of autocratic strategies defined via press - dyson functions for more than two actions . in  [ si : continuousdonationgame ] , we show that there is no way for a player to unilaterally set her own score using theorem [ thm : maintheorem ] . in particular , despite the implicit nature of autocratic strategies , one can use theorem [ thm : maintheorem ] to deduce the non - existence of certain classes of strategies .",
    "@xmath281\\left(s\\right ) \\nonumber \\\\ & = \\psi\\left(x\\right ) - \\sum_{r=1}^{n}\\psi\\left(a_{r}\\right)\\sigma_{x}\\left[x , y\\right]\\left(a_{r}\\right ) \\nonumber \\\\ & = \\psi\\left(x\\right ) - \\sum_{r=1}^{n-1}\\psi\\left(a_{r}\\right)\\sigma_{x}\\left[x , y\\right]\\left(a_{r}\\right ) - \\psi\\left(a_{n}\\right)\\left(1-\\sum_{r=1}^{n-1}\\sigma_{x}\\left[x , y\\right]\\left(a_{r}\\right)\\right ) \\nonumber \\\\ & = \\psi\\left(x\\right ) - \\psi\\left(a_{n}\\right ) - \\sum_{r=1}^{n-1}\\big ( \\psi\\left(a_{r}\\right ) -\\psi\\left(a_{n}\\right ) \\big)\\sigma_{x}\\left[x , y\\right]\\left(a_{r}\\right ) \\nonumber \\\\ & = \\begin{cases}\\displaystyle\\sum_{r=1}^{n-1}\\big ( \\psi\\left(a_{n}\\right ) -\\psi\\left(a_{r}\\right ) \\big)\\big(\\sigma_{x}\\left[x , y\\right]\\left(a_{r}\\right ) -\\delta_{r , r'}\\big ) & x = a_{r'}\\neq a_{n } , \\\\",
    "\\displaystyle\\sum_{r=1}^{n-1}\\big ( \\psi\\left(a_{n}\\right ) -\\psi\\left(a_{r}\\right ) \\big)\\sigma_{x}\\left[x , y\\right]\\left(a_{r}\\right ) & x = a_{n}.\\end{cases}\\end{aligned}\\ ] ]            @xmath284\\left(s\\right ) & = \\begin{cases}c_{1}\\sigma_{x}\\left[x , y\\right]\\left(a_{1}\\right ) + c_{2}\\sigma_{x}\\left[x , y\\right]\\left(a_{2}\\right ) - c_{1 } & x = a_{1 } , \\\\",
    "c_{1}\\sigma_{x}\\left[x , y\\right]\\left(a_{1}\\right ) + c_{2}\\sigma_{x}\\left[x , y\\right]\\left(a_{2}\\right ) - c_{2 } & x = a_{2 } , \\\\",
    "c_{1}\\sigma_{x}\\left[x , y\\right]\\left(a_{1}\\right ) + c_{2}\\sigma_{x}\\left[x , y\\right]\\left(a_{2}\\right ) & x = a_{3},\\end{cases}\\end{aligned}\\ ] ]    where @xmath287 and @xmath288 . for each @xmath59 and @xmath60 ,",
    "the measure @xmath53 $ ] is uniquely determined by @xmath53\\left(a_{1}\\right)$ ] and @xmath53\\left(a_{2}\\right)$ ] .",
    "therefore , unlike for @xmath282 , one can not necessarily eliminate both of @xmath289 and @xmath290 by normalizing the press - dyson function .",
    "for this reason , as well as due to the fact that a press - dyson function reduces to a multiple of the press - dyson vector for @xmath282 , it is perhaps more natural to refer to any multiple of @xmath24 ( as opposed to just @xmath24 itself ) as a press - dyson vector",
    ".          for a two - point strategy , @xmath7 s action space may be restricted to @xmath291 .",
    "therefore , the scaling function @xmath248 of theorem [ thm : maintheorem ] is defined by two numbers , @xmath292 and @xmath293 .",
    "letting @xmath294 , we see by corollary [ cor : maincorollary ] in  [ subsec : detailedproofs ] that the function              note eq .",
    "( [ eq : twopointdonation ] ) simply states formally that player @xmath7 fully cooperates with probability @xmath92 and defects with probability @xmath95 following an outcome in which @xmath7 plays @xmath11 and @xmath8 plays @xmath12 .",
    "thus , setting @xmath300 , and @xmath301 , the general form , eq .",
    "( [ eq : pgeneral ] ) , recovers the discrete - action - space case , eq .",
    "( [ eq : pdiscrete ] ) .",
    "in particular , the autocratic memory - one strategy in eq .",
    "( [ eq : twopointdonation ] ) is a direct generalization of zero - determinant strategies to the continuous donation game .",
    "however , this strategy contains much more information than the corresponding strategy for the classical donation game because it encodes @xmath7 s play in response to @xmath8 s for every @xmath94 $ ] .",
    "despite the fact that player @xmath8 has an uncountably infinite number of actions to choose from , player @xmath7 can still ensure that eq .",
    "( [ eq : extortionequation ] ) holds by playing only two actions .      in the main text",
    ", we saw that @xmath7 can unilaterally enforce @xmath75 for @xmath26 provided @xmath98 and @xmath41 is sufficiently close to @xmath43 . if @xmath107 , then @xmath76 is irrelevant and the linear relationship is simply @xmath122 . here , we show that , if @xmath135 , then @xmath98 is necessary for such a payoff relationship to be enforced via theorem [ thm : maintheorem ] . indeed ,",
    "if                      although a player can not set her own score in the continuous donation game , she can set the score of her opponent .",
    "we saw in the main text that @xmath7 can set @xmath8 s score to anything between @xmath64 and @xmath130 provided @xmath41 is sufficiently large , and here we show that this interval is the only range of payoffs for player @xmath8 that @xmath7 can unilaterally set via theorem [ thm : maintheorem ] .",
    "indeed , if @xmath17 satisfies                  we saw in the main text that extortionate strategies exist in the continuous donation game , as demonstrated by the two - point strategy defined by eq .",
    "( [ eq : twopointdonationexample ] ) .",
    "however , it certainly need not be the case that for any @xmath311 , there exists @xmath256 such that                  which is impossible since @xmath320 and @xmath321 .",
    "thus , there is no feasible press - dyson function that allows player @xmath7 to unilaterally enforce the equation @xmath322 .",
    "in other words , a player can not unilaterally set her own payoff ."
  ],
  "abstract_text": [
    "<S> the recent discovery of zero - determinant strategies for the iterated prisoner s dilemma sparked a surge of interest in the surprising fact that a player can exert unilateral control over iterated interactions . </S>",
    "<S> these remarkable strategies , however , are known to exist only in games in which players choose between two alternative actions such as  cooperate \" and  defect . </S>",
    "<S> \" here we introduce a broader class of autocratic strategies by extending zero - determinant strategies to iterated games with more general action spaces . </S>",
    "<S> we use the continuous donation game as an example , which represents an instance of the prisoner s dilemma that intuitively extends to a continuous range of cooperation levels . </S>",
    "<S> surprisingly , despite the fact that the opponent has infinitely many donation levels from which to choose , a player can devise an autocratic strategy to enforce a linear relationship between his or her payoff and that of the opponent even when restricting his or her actions to merely two discrete levels of cooperation . </S>",
    "<S> in particular , a player can use such a strategy to extort an unfair share of the payoffs from the opponent . therefore , although the action space of the continuous donation game dwarfs that of the classical prisoner s dilemma , players can still devise relatively simple autocratic and , in particular , extortionate strategies . </S>"
  ]
}