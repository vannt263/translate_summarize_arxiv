{
  "article_text": [
    "consider an ill - posed linear operator equation au = f with @xmath0 mapping between nontrivial banach spaces @xmath1 and @xmath2 . in practice",
    "only noisy data @xmath3 will be given .",
    "we assume here that the noise level @xmath4 satisfying is known and consider convergence of regularized solutions to an exact solution @xmath5 of as @xmath4 goes to zero .",
    "regularization by projection onto finite dimensional subspaces of @xmath1 and/or @xmath2 has been studied in detail e.g. , in @xcite in the hilbert space setting . here",
    "the dimension of the projection spaces plays the role of a regularization parameter .",
    "the error estimates of @xcite allow for an a priori choice of this dimension , in @xcite also an a posteriori choice of the dimension is considered .",
    "our aim is to extend these results ( or at least part of them ) to the general banach space setting .",
    "this is motivated , e.g. , by the use of @xmath6 spaces with @xmath7 to recover sparse solutions or to model uniform or impulsive noise .",
    "also the space @xmath8 of continuous functions on some domain @xmath9 and its dual @xmath10 are of particular interest since our setting allows then to analyze , e.g. collocation of integral equations as a regularization method .",
    "note that some results regarding regularization by discretization in banach spaces are known in a general setting ( see @xcite and @xcite ) and about the quadrature formulae method ( see @xcite ) , the collocation method ( see , e.g. , @xcite ) and the galerkin method ( see @xcite ) .",
    "let @xmath11 , @xmath12 , @xmath13 , be finite dimensional nontrivial subspaces which have the role of approximating the spaces @xmath1 and @xmath14 , respectively .",
    "for instance , the subspaces can be chosen in the following manner , as it will be emphasized later , n , :  e_ne_n+1 = e , n , :  z_nz_n+1 = f^*. the general projection method defines a finite dimensional approximation @xmath15 to @xmath5 by u_ne_n z_nz_n :  = .",
    "as in the hilbert space case , the least squares method u_n\\ { : _ ne_n } and the least error method u_n\\ { : z_nz_n :  = } can be recovered to some extent as special cases of , see lemmas [ characterization_leastsquares ] , [ characterization_leasterror ] below .",
    "a justification of the name  least error  method will be provided later ( see theorem [ rem_leasterror ] in section [ sec_leasterror ] ) .    in the following",
    ", @xmath16 denotes some projection . for drawing certain conclusions ,",
    "this will sometimes be assumed to have the following properties : ( i - p_n)^2=i - p_n ux ,   : ( i - p_n)(x)=||(i - p_n)(x ) . as opposed to the hilbert space setting ,",
    "@xmath17 is not necessarily linear any more .",
    "\\i ) one can use the metric projection operator @xmath18 in case it is single valued ( as happens in strictly convex banach spaces ) , but it can also be some differently defined projection operator , for an example see section [ sec_applic ] below . note that the metric projection @xmath17 is obviously homogeneous , idempotent and does fulfill @xmath19 , as one can see in what follows : @xmath20 if and only if @xmath21 which is equivalent to @xmath22 .",
    "indeed , @xmath23 for all @xmath24 , as @xmath25 .",
    "ii ) in general , single valued metric projections onto finite dimensional subspaces of a banach space @xmath26 are nonlinear , otherwise @xmath26 would be linearly isometric to an inner product space , cf . , e.g. , @xcite .",
    "let @xmath27 be the linear operator defined by @xmath28 which allows to write as u_ne_n q_na u_n = q_n .",
    "the norm of @xmath27 equals one since @xmath29 moreover , @xmath30 will stand for the metric projection onto the subspace @xmath31 ( or a single valued choice of the metric projection in case it is multivalued ) , whenever @xmath32 is a linear subspace of @xmath1 , so that can be rewritten as @xmath33 in the hilbert space setting , the least squares and the least error method can be shown to be special cases of the general projection method upon appropriate choice of the spaces @xmath32 and @xmath34 , respectively .",
    "this can be extended to the banach spaces under certain conditions . for this purpose",
    "we will make use of duality mappings    & j_q^ff^*=(^q)=_f , + & j_q^*^f^*f^**=(^q^ * ) ,   q^*= , + & j_q^ee^*=(^q)=_e ,    cf .",
    ", e.g. , ( * ? ? ?",
    "* chapters i - ii ) .",
    "moreover , we will make use of the bregman distance induced by the functional @xmath35 , which in case of single valued duality mapping @xmath36 is defined by d_q(,u)=^q-^q + .",
    "we will also use the symmetric bregman distance d_q^sym(,u)=d_q(,u)+d_q(u,)= and the identity d_q^*(j_q^ee^*(u),j_q^ee^ * ( ) ) = d_q(,u ) provided that @xmath37 holds cf .",
    "* lemma 2.63 ) .",
    "note that in smooth and uniformly convex spaces ( such as @xmath6 with @xmath38 ) , convergence with respect to the bregman distance implies convergence with respect to the norm and vice versa , cf .",
    ", e.g. ( * ? ? ?",
    "* theorem 2.60 ) d_q(,u^k)0  d_q(u^k,)0  0 .",
    "while tools like the bregman distance have only relatively recently been applied in the context of regularization , some of the fundamental concepts we use are still those from the seminal papers @xcite . in @xcite , which partly also works with general banach spaces , error estimates for",
    "the general projection method rely on the norms of the linear operator @xmath39 mapping @xmath40 to a solution of , as well as the special projection @xmath41 , @xmath42 .",
    "note that well - definedness of these operators can be shown under certain conditions , see , e.g. , , below . as a matter of fact",
    ", it is readily checked that for @xmath15 defined by , the error estimate @xmath43 holds , which splits the total error into an approximation error term and a term bounding the noise propagation .",
    "error estimates of this type will enable the construction of convergent parameter choice rules also here and the concepts of quasi - optimality ( uniform boundedness of @xmath44 ) and robustness ( uniform boundedness of @xmath45 with @xmath46 ) can be recovered in the boundedness conditions , , , , .",
    "note that computing general projection , least squares and least error approximations in general banach spaces might not be trivial .",
    "the reader is referred e.g. , to ( * ? ? ? * section 3 ) , @xcite for some iterative methods ( landweber type , sequential subspace optimization ) in uniformly convex and smooth banach spaces .",
    "this work is organized as follows .",
    "well - definedness , stability and convergence with a priori and a posteriori choices of the dimension parameter are shown for the general projection method , the least squares method and the least error method in section [ sec_genproj ] , [ sec_leastsquares ] and [ sec_leasterror ] , respectively .",
    "this theory has , of course , its limitations and can approach problems in various couples of smaller or larger function spaces @xmath1 and @xmath2 , as shortly outlined in section [ sec_space ] .",
    "some applications are discussed in section [ sec_applic ] .",
    "namely , analytical considerations and numerical tests are provided for a collocation method applied to a volterra integral equation in one dimension space .",
    "throughout this section , @xmath11 and @xmath12 , @xmath13 , are finite dimensional subspaces .",
    "the following lemma gives conditions for well - definedness of @xmath15 according to .",
    "[ welldef_projmeth ] let ( e_n)=(z_n ) and ( q_na)e_n=\\{0 } hold . then is uniquely solvable for any @xmath47 .",
    "since is a finite dimensional linear system , with , unique solvability for any right hand side is equivalent to uniqueness , i.e. , to the condition @xmath48 this is the same as .      for stating stability we will make use of the following quantity :    _ n:= & _ w_ne_n , w_n0 + = & + = & _ w_ne_n , = 1 ,    that is finite under conditions , . in case @xmath49 defined as _ n : = _ w_ne_n ,",
    "w_n0 is finite , which , e.g. , is ensured by , one can bound @xmath50 by means of the simpler quantity _",
    "n:=_w_ne_n = _ w_ne_n , = 1 .",
    "[ kappa - inequality ] suppose that and hold .",
    "then the operator @xmath51 has an inverse and _",
    "n a_n^-1=_n _",
    "n _ n.    for any @xmath52 we have @xmath53 .",
    "let @xmath24 be an element for which in the maximum is attained .",
    "then by we have @xmath54 .",
    "[ kappafinite ] under conditions and of lemma [ welldef_projmeth ] one has @xmath55 , since one takes the supremum over the unit sphere , which is compact in the finite dimensional spaces under consideration .",
    "the definition of the reciprocal of the stability factor @xmath50 in the general projection method reveals the relation to ladyshenskaja - babuska - brezzi ( or inf - sup ) conditions used for showing well - posedness of petrov - galerkin discretizations of partial differential equations .    for the general projection method we get :    [ stability_projmeth ]",
    "let the assumptions of lemma [ welldef_projmeth ] be satisfied and consider , for @xmath56 the solutions of @xmath57 then the estimate @xmath58 holds .    according to lemma [ welldef_projmeth ] , the solutions @xmath59",
    "are well defined .",
    "then , the difference @xmath60 satisfies @xmath61 therefore , by definition of @xmath50 and @xmath62 ( due to linearity of the space @xmath32 ) we have @xmath63      [ conv_projmeth_apriori ] let for all @xmath13 , the assumptions of lemma [ welldef_projmeth ] be satisfied and let @xmath15 be defined by the projection method .",
    "additionally , we assume that there exists a sequence of approximations @xmath65 , @xmath66 , satisfying the convergence conditions 0nand _ n _ z_nz_n , = 1 0n .",
    "then for exact data @xmath67 we have convergence @xmath68 for noisy data and with the dimension @xmath69 chosen such that n()_n ( ) 0 0 we have convergence @xmath70    for any @xmath52 we have , by definition of @xmath50 and @xmath71 ( here linearity of the space @xmath32 is used ) , that    & + + & + _ n _ z_nz_n , = 1 + & + _ n _ z_nz_n , = 1(+ ) + & = + _",
    "n _ z_nz_n , = 1 ( + ) + & + _ n ( + _ z_nz_n , = 1 )    where we have also used linearity of @xmath72 . inserting @xmath73 and using , , together with our assumptions on the choice of @xmath74 we therefore immediately get the assertions in both cases @xmath67 and @xmath75 .",
    "[ approx ] i ) the approximation property holds , e.g. , when the subspaces @xmath32 are chosen according to .",
    "\\ii ) under conditions and 0n , on some sequence of operators @xmath76 , the uniform boundedness condition c < n : _ n _ we,=1 _ z_nz_n , = 1 c is sufficient for and by with @xmath77 yields the estimate ( 1+c ) + _ n .    in the context of petrov galerkin discretizations of pdes ,",
    "estimate is known as strang s first lemma .",
    "[ conv_projmeth_dp ] let the assumptions of lemma [ welldef_projmeth ] be satisfied for all @xmath13 and let @xmath15 be defined by the projection method .",
    "we also assume that there exists a sequence of approximations @xmath65 , @xmath66 , satisfying and the conditions _",
    "z_nz_n , = 10n _ n+1 0n .",
    "additionally , we assume that there exists @xmath78 such that _ z_nz_n , = 1 ,  w_ne_n , i.e. , @xmath79 for all @xmath13 , where @xmath49 is defined by .",
    "denote @xmath80 .",
    "let @xmath81 be fixed and for @xmath75 , let @xmath82 be the first index such that d_dp(n)b .",
    "then @xmath83 is finite .",
    "+ moreoever , @xmath84 as @xmath85 subsequentially in the following sense : there exists a convergent subsequence and the limit of every convergent subsequence solves ; if @xmath5 is unique , then @xmath86 as @xmath85",
    ".    by lemma [ kappa - inequality ] and assumption we can use @xmath87 as in instead of @xmath50 as in here .",
    "+ for any @xmath64 let @xmath52 be such that @xmath88",
    ". from it follows that    & + + & _",
    "z_nz_n , = 1 + + & = _ z_nz_n , = 1 + + & ( + 1 ) ( , ae_n ) .    in particular",
    ", since @xmath89 by , this implies that @xmath83 is finite .",
    "if for some @xmath90 the discrepancy principle gives @xmath91 , with @xmath92 , then the sequence @xmath93 lies in a finite - dimensional subspace  the linear hull of @xmath32 , @xmath94 .",
    "boundedness and therefore relative compactness of @xmath95 follows from ( e.g. , with @xmath96 ) . since @xmath97 , then @xmath98 as @xmath99 .",
    "hence @xmath100 has a convergent subsequence and the limit of every convergent subsequence solves .    otherwise , @xmath83 will be larger than zero . in this case , let @xmath101 . for @xmath102 the inequality does not hold and gives @xmath103",
    "since @xmath81 we have @xmath104    inserting this into with @xmath73 , @xmath82 and using , , , , we get convergence if @xmath105 as @xmath85 .",
    "if some sequence of operators @xmath76 satisfies and , then and follow from for @xmath106 and from the uniform boundedness conditions c < n : _",
    "n _ we,=1 _ z_nz_n , = 1 c ,    c_1 < n : & _ n+1 _ we,=1 c_1 .    if additionally @xmath107 is homogeneous , one has by and by homogeneity of @xmath108    & _ m+1 _ we,=1 + & c_1 .    hence , by and lemma [ kappa - inequality ] , we obtain the error estimate    & + & ( 1+c)+ ,    in case @xmath109 .",
    "note that conditions and correspond to @xmath110 in condition ( 1.27 ) of @xcite .",
    "throughout this section , @xmath11 is a finite dimensional subspace . we show below that the least squares method is well - defined and converges to a solution under a priori and a posteriori choices for the discretization dimension .",
    "[ welldef_leastsquares ] let ( a)e_n=\\{0}. then the set of minimizers @xmath111 is nonempty . if , for some @xmath112 , the functional _ f : g^q is strictly convex , then the minimizer is unique .",
    "the finite dimensional linear subspace @xmath32 is reflexive , closed , convex and nonempty .",
    "the cost functional @xmath113 is convex , weakly lower semicontinuous , bounded from below .",
    "it is also coercive , since the minimum @xmath114 exists on the finite dimensional hence compact unit sphere and is positive by condition , hence boundedness of some sequence @xmath115 implies boundedness of @xmath116 as follows : @xmath117 thus we can conclude existence of a minimizer .",
    "+ minimizing @xmath118 over @xmath32 is obviously equivalent to minimizing @xmath119 over @xmath32 . moreover , strict convexity of the functional @xmath120 by transfers to the functional @xmath121 on @xmath32 .",
    "this implies uniqueness .    in the hilbert space setting",
    ", the least squares method can be shown to be a special case of the general projection method upon appropriate choice of the spaces @xmath32 .",
    "[ characterization_leastsquares ] let hold and let @xmath15 be defined by the least squares method .",
    "assume that , for some @xmath112 , the functional is strictly convex , the duality mappings satisfy @xmath122 and @xmath123 is gateaux differentiable at @xmath124 with gateaux derivative + @xmath125 , @xmath126 .",
    "then we have equivalence of and by considering the linear space @xmath127 .    using the identity @xmath128 , and the functional @xmath129 we have that is equivalent to @xmath130 the necessary and , by convexity",
    ", also sufficient condition for this optimality problem reads as @xmath131\\\\ & = \\dupf { \\tfrac{d}{d u_n } \\left(j_q^{f\\to f^*}(au_n-\\fdel)\\right ) [ w_n ] ,   \\partial \\phi_{f^*}(j_q^{f\\to f^*}(a u_n-\\fdel)}\\\\ & = \\dupf{(j_q^{f\\to f^*})'(au_n-\\fdel)a w_n , j_{q^*}^{f^*\\to f^{**}}(j_q^{f\\to f^*}(a u_n-\\fdel)}\\\\ & = \\dupf{(j_q^{f\\to f^*})'(au_n-\\fdel)a w_n , a u_n-\\fdel}\\ , , \\end{aligned}\\ ] ] which is with @xmath132 .    since @xmath15 from the definition of the operator",
    "@xmath133 is unknown , lemma [ characterization_leastsquares ] is only of theoretical use .",
    "later on , it will enable us to conclude convergence from the respective result for general projection methods - see corollary [ conv_leastsquares_apriori ] below . for practical computation of @xmath15 , the finite dimensional minimization problem should be solved .",
    "note that the equality @xmath134 required by the previous lemma holds , e.g. , in reflexive spaces , cf .",
    "@xcite .      for the least squares method ,",
    "the crucial quantity in the stability estimate is @xmath87 defined as in . as in remark",
    "[ kappafinite ] , under the conditions of lemma [ welldef_leastsquares ] , we have @xmath135 . therewith we obtain the following stability result .",
    "[ stability_leastsquares ] let all the assumptions of lemma [ characterization_leastsquares ] be satisfied and consider , for @xmath56 the solutions of @xmath136 then the estimate @xmath137 holds , where @xmath30 is some single valued selection of the metric projection onto the subspace @xmath31 . if @xmath30 is continuous , then @xmath138 depends continuously on @xmath139 .",
    "the proof follows by the definition of @xmath87 and the fact that @xmath140 .",
    "[ qpcontinuous ] the metric projection operator @xmath30 onto closed convex sets is single valued and continuous in uniformly convex banach spaces ( see , e.g. , @xcite ) .",
    "thus , the above result is applicable to the setting @xmath141 with @xmath142 , but not to the space @xmath143 in general .",
    "however , since the subspaces @xmath31 are finite dimensional according to the rank - nullity theorem for linear mappings , one might work with continuous selections of the metric operators in this nonreflexive banach space setting if those subspaces have certain properties - see , e.g. , theorem 6.34 in @xcite .",
    "more precisely , the metric projection @xmath144 onto an @xmath64-dimensional subspace @xmath145 of @xmath146 $ ] admits a unique continuous selection if and only if every function @xmath147 , @xmath148 has at most @xmath64 zeros and if every @xmath147 has at most @xmath149 changes of sign .      together with lemma",
    "[ characterization_leastsquares ] , theorem [ conv_projmeth_apriori ] immediately implies convergence of the least squares method .",
    "[ conv_leastsquares_apriori ] let all the assumptions of lemma [ characterization_leastsquares ] be satisfied .",
    "additionally , we assume that there exists a sequence of approximations @xmath65 , @xmath66 , satisfying , , where @xmath50 is defined as in with @xmath132 .    then for exact data @xmath67 we have convergence as @xmath150 @xmath68 for noisy data and with the dimension @xmath69 chosen according to",
    ", we have convergence as @xmath85 @xmath70    alternatively , we can also prove convergence directly :    [ conv_leastsquares_apriori_gen ] let condition be satisfied for all @xmath13 . then an approximation @xmath15 according to the least squares method exists and the error estimate _",
    "e_n \\ { + 2 _ n } + 2_n holds .",
    "if there exists a sequence of approximations @xmath65 , @xmath66 , satisfying and _ n0 n , then we have in case of exact data ( @xmath67 ) convergence @xmath151 and in case of noisy data with the choice of @xmath69 according to n()_n ( ) 0 0 convergence as @xmath85 : @xmath70    let @xmath52 be arbitrary .",
    "we have @xmath152 due to the least squares property , therefore @xmath153 and @xmath154 in this error estimate @xmath155 is arbitrary , hence holds .",
    "if some sequence of approximations @xmath65 satisfies conditions and , then insertion of @xmath73 into gives the convergence assertions .",
    "[ lsconvcond ] note that convergence condition is satisfied , if some sequence of operators @xmath76 satisfies conditions , and c < n : _",
    "wh,=1 c ( compare , ) .",
    "namely , the equality @xmath156 allows to estimate @xmath157      [ conv_leastsquares_dp ] let for all @xmath13 condition be satisfied so that @xmath15 according to the least squares method exists .",
    "additionally , we assume that there exists a sequence of approximations @xmath65 , @xmath66 , satisfying and the condition _ n ( + )  0 nlet @xmath158 be fixed and for @xmath75 , let @xmath82 be the first index such that holds .",
    "then for @xmath75 we have that @xmath83 is finite .",
    "moreover , @xmath84 as @xmath85 subsequentially .",
    "the proof is the same as for the theorem [ conv_projmeth_dp ] , but with @xmath159 is now trivial , using optimality of @xmath15 for the minimization problem , and hence @xmath160 can be omitted in formula ( with @xmath161 ) .",
    "note also that we do not need now relations and that estimate with @xmath73 is used instead of .",
    "if some sequence of operators @xmath76 satisfies and , then the uniform boundedness condition c < n : ( _ n + _ n+1 ) _",
    "wh,=1 c. is sufficient for .",
    "throughout this section , @xmath12 is a finite dimensional subspace .",
    "we establish well - definedness and convergence of the least error method to a solution under a priori and a posteriori choices for the discretization dimension .",
    "[ welldef_leasterror ]    1 .",
    "let @xmath1 be a banach space in which the unit ball is weakly compact and assume that ( a^*)z_n = \\{0}. + then the set of minimizers @xmath162 is nonempty .",
    "2 .   if additionally for some @xmath112 , the functional _",
    "e:^q is strictly convex , then the minimizer @xmath15 of is unique , and so is the minimum - norm - solution @xmath163 of .",
    "condition implies that the admissible set @xmath164 is nonempty . to see this , we apply the closed range theorem to the linear operator @xmath165 , whose finite dimensional range is obviously closed .",
    "hence we have the identity @xmath166 under condition , since by definition of @xmath27 we have @xmath167 for all @xmath168 : @xmath169 thus , the equation @xmath170 with @xmath171 defining @xmath172 is always solvable under condition .    due to our assumption on @xmath1 , level sets of the cost function @xmath173 are weakly compact .",
    "moreover , @xmath118 is weakly lower semicontinuous and bounded from below .",
    "this implies existence of a minimizer , which in case of strict convexity of the cost function @xmath174 is obviously unique .",
    "also the least error method is to some extent a special case of .",
    "however , different from the hilbert space situation , the ansatz space might be nonlinear in general banach spaces .",
    "[ characterization_leasterror ] let the conditions of lemma [ welldef_leasterror ] ( i ) be satisfied and let additionally , for some @xmath175 , the norm functional @xmath176 be frechet differentiable , and the single valued duality mapping @xmath36 be invertible .    then and are equivalent , when @xmath177 .    by convexity and frechet differentiability of the cost function as well as linearity of the constraints ,",
    "optimality in is equivalent to existence of a lagrange multiplier @xmath178 with @xmath179 such that stationarity for the lagrange function @xmath180 holds , where @xmath181 .",
    "that is , there exists @xmath182 such that @xmath183 where @xmath184 .",
    "the first of these two equations with invertibility of @xmath36 yields that is equivalent to with @xmath185 .",
    "+ the implication @xmath186 can be shown also in a variational manner , by exploiting duality mapping properties .",
    "we include the alternative proof here , for the sake of completeness .",
    "thus , assume that @xmath15 satisfies with @xmath185 and let @xmath187 be an arbitrary element of the feasible set @xmath164",
    ". then we can write @xmath188 for some @xmath189 and insert @xmath190 to obtain the identity @xmath191 , which together with feasibility of @xmath187 yields @xmath192 on the other hand , we have @xmath193 thus altogether @xmath194    note that @xmath177 is not necessarily a linear space , though .",
    "so in the proof of stability and convergence we can not resort to the respective results on the general projection method , but have to carry out separate proofs for the least error method , see lemma [ stability_leasterror ] and theorem [ conv_leasterror_apriori ] below .    in the sequel",
    "one can see that the  least error  method deserves its name in the banach space setting , too .",
    "[ rem_leasterror ] let @xmath5 be some solution of .",
    "then , for any @xmath13 , the minimizer @xmath15 defined by in case @xmath195 attains the least error in @xmath185 measured with respect to the bregman distance , that is , @xmath196    in the case of exact data , equation can be written as = 0 , z_nz_n .",
    "let @xmath197 with @xmath198 be an arbitrary element of @xmath185 .",
    "then one has @xmath199 as @xmath200 satisfy .",
    "since @xmath201 is nonnegative , this implies the desired inequality , showing that @xmath15 is the bregman projection of @xmath5 onto @xmath32 .",
    "a stability result for the least error method can be formulated by using    _",
    "n:=&_z_n,1,z_n,2z_n   + = & _ z_n,1,z_n,2z_n , = 1 , 1 + _",
    "n^*:=&_z_nz_n =    again , as in remark [ kappafinite ] , one sees that @xmath202 and @xmath203 are finite under the conditions of lemma [ welldef_leasterror ] , in particular , condition .",
    "[ stability_leasterror ] let the assumptions of lemma [ characterization_leasterror ] be satisfied and consider , for @xmath56 the solutions of @xmath204 then the estimate @xmath205 holds ; in particular , if @xmath1 is a @xmath206-convex space , then one has @xmath207 if additionally @xmath1 is @xmath208-smooth , then one has @xmath209 for some constants @xmath210 independent of @xmath64 .    according to lemma [ welldef_leasterror ] ,",
    "the solutions @xmath211 , are well defined .",
    "lemma [ characterization_leasterror ] implies existence of @xmath212 such that @xmath213 , @xmath214 .",
    "therefore , we get the identity @xmath215 similarly , in the @xmath206-convex and @xmath208-smooth case , which implies d_q^sym(,u)d_q(,u)c_q^q @xmath216 for some constants @xmath217 and all @xmath218 ( see , e.g. , ( * ? ? ?",
    "* lemma 2.7 ) , ( * ? ? ?",
    "* theorem 2.42 ) ) , we get @xmath219    note that for @xmath38 , @xmath220 is @xmath221-convex and @xmath222-smooth , see , e.g , ( * ? ? ?",
    "* example 2.47 ) .      for the least error method , due to possible",
    "nonlinearity of the space @xmath32 according to lemma [ characterization_leasterror ] , convergence can not be directly concluded from theorem [ conv_projmeth_apriori ] .",
    "we obtain the following result with a priori discretization level choice .",
    "[ conv_leasterror_apriori ] let @xmath1 be a banach space in which the unit ball is weakly compact and assume that , for some @xmath112 , the functional is strictly convex and frechet differentiable , and the single valued duality mapping @xmath36 is invertible .",
    "let @xmath15 be defined by the least error method , where the operator @xmath72 is assumed to satisfy and zf^ * :  _ z_nz_n 0n .",
    "then the minimum - norm - solution @xmath163 of is unique and for exact data ( @xmath67 ) we have convergence @xmath223 if , additionally , the space @xmath1 is smooth and uniformly convex , one has @xmath224 for exact data , while for noisy data and with the dimension @xmath69 chosen such that n()_n()0 0 , we have convergence @xmath225 .",
    "let @xmath226 be the well defined elements ( due to lemma [ welldef_leasterror ] ) _ n\\ { : z_nz_n :  = } , i.e. , @xmath15 with exact data .",
    "then the following holds for any solution @xmath5 to , . by the assumed weak compactness of the unit ball in @xmath1 ,",
    "the sequence @xmath227 has a weakly convergent subsequence @xmath228 whose limit @xmath187 solves , since @xmath72 is weakly continuous and by @xmath229 for all @xmath230 and we have @xmath231 moreover , by and weak lower semicontinuity of the norm , this limit @xmath187 satisfies @xmath232 for any solution @xmath5 of , thus it has to coincide with the unique minimum - norm - solution @xmath163 .",
    "a subsequence - subsequence argument yields weak convergence of the whole sequence @xmath227 to @xmath163 as @xmath150 .",
    "hence , for the bregman distance we get , again using with @xmath233 , that @xmath234 by the already shown weak convergence .",
    "this proves the assertion in case of exact data , since then we have @xmath235 .",
    "+ in case of noisy data we can estimate the bregman distance between @xmath15 and @xmath226 by means of lemma [ stability_leasterror ] : @xmath236 so by choosing @xmath69 such that @xmath237 and @xmath238 as @xmath85 , we have @xmath239 however , the bregman distance does not satisfy a triangle inequality , thus we need @xmath206-convexity of @xmath1 at this point to conclude from lemma [ stability_leasterror ] and @xmath240 thus the assertion .",
    "the approximation property is ensured , e.g. , by choosing @xmath34 according to .      under the conditions of lemma [ characterization_leasterror ] we can carry over some results for the least error method from the hilbert space setting by closely following @xcite .",
    "in particular we will show monotonicity of the error measured in the bregman distance defined by , as well as convergence if the stopping index determined by the monotone error rule goes to infinity as @xmath85 , see ( * ? ? ? * theorem 2 ) .",
    "[ conv_leastserror_me ] let the assumptions of lemmas [ welldef_leasterror ] ( i ) , ( ii ) and [ characterization_leasterror ] be satisfied .",
    "then for @xmath15 defined by the least error method we have    1 .",
    "there exists @xmath241 such that @xmath188 .",
    "2 .   with @xmath189 as in ( a ) , the identity @xmath242 holds .",
    "if @xmath243 for all @xmath244 , then @xmath245 3 .   with @xmath246 defined by @xmath247 the identities @xmath248 and the estimate @xmath249 hold . in particular , if @xmath250 then by minimality of @xmath15 , we have @xmath251 and the error measured in the bregman distance is monotonically decreasing as long as d_me(n ) .",
    "4 .   let @xmath252 be the first index such that is violated .",
    "+ if @xmath253 as @xmath85 and holds , then @xmath254 as @xmath85 provided that @xmath1 is smooth and @xmath206-convex .    item ( a ) has already been proven in lemma [ characterization_leasterror ] .",
    "+ since the duality mapping satisfies = ^q , we get the first part of item ( b ) : @xmath255 note that @xmath189 as in ( a ) satisfies @xmath191 and @xmath256 , due to the assumption @xmath243",
    ". then yields the second part of ( b ) .",
    "the first identity in ( c ) is an immediate consequence of ( b ) , while the second one follows from @xmath257 which can be rewritten as @xmath258 .",
    "considering the differences between the bregman distances and using that the term @xmath259 cancels out we get @xmath260 where we have used again in the second equality .",
    "let @xmath261 be an a priori stopping rule satisfying , let @xmath262 be a sequence of noise levels tending to zero and denote by @xmath263 , @xmath264 the stopping indices chosen by the a priori and the monotone error rule , respectively .",
    "+ if there exists @xmath265 such that @xmath266 for all @xmath267 , then by monotone decay of the error up to @xmath268 we have @xmath269 as @xmath270 .",
    "+ otherwise there exists a subsequence @xmath271 such that for all @xmath272 we have @xmath273 and therefore @xmath274 , so the right hand limit in together with lemma [ stability_leasterror ] implies @xmath275 . on the other hand , by assumption we have @xmath276 , thus by theorem [ conv_leasterror_apriori ] , @xmath277 as @xmath278 .",
    "thus a subsequence - subsequence argument yields the assertion",
    ".    convergence in the degenerate case when @xmath279 has finite accumulation points remains an open problem even in hilbert spaces .    as regards a relation of the type @xmath280 shown in hilbert spaces ( see , e.g. , ( * ? ? ?",
    "* th.2 , 5 ) ) , it is not clear whether such a connection could be established in the banach space framework .",
    "the three projection methods investigated in this work require different theoretical settings as concerns stability and convergence .",
    "note that reflexivity of the space @xmath1 is essential in convergence results for the least error method , thus ruling out the case @xmath281 or @xmath282 , while allowing @xmath283 ( thus , e.g. , collocation ) or @xmath284 ( for modelling impulsive noise ) .    the additional restrictions on uniform boundedness ( e.g. , ) will be discussed in the following section ; they are more severe in case of a posteriori choice of @xmath64 , a fact which is already known from the hilbert space setting .",
    "the preimage and image space combinations we are interested in are e = l^p ( ) , f = l^r ( ) , p , r(1 , ) , e = l^p ( ) , f = c ( ) , p(1 , ) , e = c()^*= ( ) , f = l^r ( ) , p(1 , ) , e= ( ) , f = c ( ) , for some smooth open domain @xmath285 .",
    "@xmath6 spaces with @xmath38 are reflexive , smooth and @xmath286-convex with @xmath287 , the duality mappings , which are given by @xmath288 are invertible with @xmath289 ( see , e.g. , ( * ? ? ? * section ii.2 ) ) , and if @xmath290 , i.e. , @xmath291 , then @xmath292 is additionally gateaux differentiable with gateaux derivative @xmath293(x)=(r-1)|g(x)|^{r-2}h(x)\\,.\\ ] ] therefore in case all well - definedness , characterization , stability and convergence results lemmas [ welldef_projmeth ] , [ welldef_leastsquares ] , [ welldef_leasterror ] , [ characterization_leastsquares ] , [ characterization_leasterror ] , [ stability_projmeth ] , [ stability_leastsquares ] , [ stability_leasterror ] , corollary [ conv_leastsquares_apriori ] , and theorems [ conv_projmeth_apriori ] , [ conv_leasterror_apriori ] , [ conv_projmeth_dp ] , [ conv_leastsquares_dp ] , [ conv_leastserror_me ] , are applicable . in case , we still have all these results except for those on stability of the least squares method , lemma [ stability_leastsquares ] unless the projection spaces are chosen appropriately ( cf . remark [ qpcontinuous ] ) .",
    "likewise , in case all results except for those concerning the least error method apply .",
    "finally , in the situation , only the results for the general projection method , lemmas [ welldef_projmeth ] , [ stability_projmeth ] , and theorems [ conv_projmeth_apriori ] , [ conv_projmeth_dp ] , remain valid .",
    "we will now consider applicability of the results derived in the previous sections for concrete discretizations , so that the crucial conditions for convergence and stability , , , , , , , will become conditions on the smoothing properties of the forward operator .",
    "these will be interpreted for the case of integral equations . for certain test examples we will also provide numerical experiments .      for applying the results from sections [ sec_genproj ] , [ sec_leastsquares ] , [ sec_leasterror ] , in the respective cases",
    ", it still remains to verify the crucial convergence conditions .",
    "however , the convergence conditions , , , , ( recall the corrsponding sufficient boundedness conditions , , , , ) require an appropriate trade - off between stability and approximation . note that these conditions are only needed for the general projection and the least squares method , but not for the least error method",
    ".    we will now illustrate these conditions for integral equations with discretization in spline spaces .",
    "let @xmath294 , @xmath295 , @xmath296 , @xmath297 .",
    "we denote by @xmath298 the spline space defined as the set of functions @xmath299 $ ] , which in each subinterval @xmath300 , i=1,\\dots , n$ ] are polynomials of order @xmath301 : @xmath302 .",
    "the case of potentially discontinuous piecewise polynomial functions @xmath303 will be denoted by @xmath304 .",
    "+ we recall below several well - known properties of splines .    1 .",
    "approximation property : @xmath305 , \\,\\,\\ ,",
    "\\exists v_h \\in s^{(-1)}_{k-1}(i_h ) : \\,\\,\\ ,    \\|v - v_h\\|_{c[0,1 ] } \\leq c_{\\text{app } } h^{\\min(k , l ) } \\|d^lv\\|_{c[0,1 ] } , \\end{aligned}\\ ] ] where @xmath306 is the differential operator of order @xmath307 .",
    "stability property : @xmath308}.\\ ] ]    on each subinterval @xmath309 we define the local projection @xmath17 , using an @xmath310-orthogonal basis @xmath311 of @xmath312 : @xmath313 we consider @xmath17 as a mapping @xmath314 , with range @xmath315 , @xmath316 by the @xmath310 orthogonality of the basis functions , it is easily checked that @xmath317 is defined in exactly the same manner , but considered as a mapping @xmath318 , again with range @xmath319 .",
    "obviously @xmath320 annihilates polynomials of degree lower or equal to @xmath321 on each @xmath309 .    for checking conditions , , ,",
    ", we can use the following lemma which follows from the approximation property of splines .",
    "[ appr - error ] let @xmath0 , @xmath322 , @xmath323 .",
    "if @xmath324 , @xmath325 or @xmath326 $ ] , @xmath327 $ ] , then @xmath328    due to this lemma , for conditions , , , , , we need the inequality @xmath329 and the estimate @xmath330 .",
    "we are able to guarantee the latter estimate only for specific operators .",
    "[ kappa - estimate ] let @xmath0 with @xmath322 , @xmath323 and @xmath324 or @xmath326 $ ] .",
    "if for all @xmath331 we have @xmath332 and @xmath333 , then _",
    "n=_w_ns^(-1)_k-1(i_h ) c n^l , c = c_1 c_.    let @xmath331 satisfy the above assumptions . since @xmath334 is a spline of order @xmath335 with increased global smoothness , one can apply the stability property of splines to @xmath189 : @xmath336    the conditions of lemmas [ appr - error ] and [ kappa - estimate ] are satisfied for integral equations of the first kind ( a u)(t):= _ 0 ^ 1 k(t , s ) u(s)ds = f(t ) ,  t , whose kernels are green s functions for the differential operator @xmath337 under different homogeneous boundary conditions , such that the equation @xmath338 has only the trivial solution @xmath339 . here",
    "@xmath340 has different forms @xmath341 and @xmath342 for regions @xmath343 and @xmath344 respectively .",
    "note that a green s function of @xmath306 with boundary conditions @xmath345 is given by the volterra kernel @xmath346 , @xmath347 . for @xmath348 and boundary conditions @xmath349 we have @xmath350 , for @xmath351 and boundary conditions",
    "@xmath352 we have @xmath353 .",
    "let us formulate the convergence theorem .",
    "[ convgp - ls ] consider @xmath354 defined by ( [ int - eq ] ) with @xmath322 , @xmath296 , where @xmath355\\mbox { and } f \\in c^l[0,1 ] \\end{aligned}\\ ] ] is assumed .",
    "let @xmath340 be a green s function of @xmath306 with homogeneous boundary conditions such that @xmath338 has only the trivial solution @xmath339 , let @xmath356 satisfy these boundary conditions .",
    "+ then the following statements hold :    \\(i ) equation ( [ int - eq ] ) has a unique solution @xmath5 .",
    "\\(ii ) let @xmath323 with @xmath329 .",
    "then the least squares method determines a unique approximation @xmath357 for all @xmath358 .",
    "\\(iii ) if hold the general projection method ( [ projmeth ] ) determines a unique approximation @xmath357 for all @xmath358 . under these assumptions we have for both methods convergence",
    "@xmath359 as @xmath360 in case of exact data @xmath67 . in case of noisy data",
    "one has convergence @xmath361 as @xmath362 , if @xmath69 is chosen a priori such that @xmath363 , @xmath364 or a posteriori according to the discrepancy principle , where in the least squares method @xmath158 , while in the general projection method assumptions and @xmath365 are assumed .    the assumptions of lemmas [ appr - error ] and [ kappa - estimate ] are satisfied , since for any @xmath366 we have @xmath367 and for any @xmath155 we have @xmath368 with increased power and global smoothness of the spline .",
    "the assertions follow with lemmas [ appr - error ] , [ kappa - estimate ] from theorems [ conv_leastsquares_apriori_gen ] , [ conv_leastsquares_dp ] for the least squares method , and from theorems [ conv_projmeth_apriori ] , [ conv_projmeth_dp ] , and inequalities for the general projection method , respectively .",
    "one can compare the above results to their counterparts in hilbert spaces ( see @xcite ) .",
    "for the general projection method ( [ projmeth ] ) , the hilbert space analog of theorems [ conv_projmeth_apriori ] , [ conv_projmeth_dp ] is the following .",
    "[ hilbert - gp ] let @xmath0 , where @xmath1 and @xmath2 are hilbert spaces .",
    "let @xmath369 and @xmath370 , @xmath371 , @xmath372 be orthoprojectors , where @xmath373 are finite dimensional subspaces of @xmath2 . let the following conditions ( i)-(iii ) hold :    1 .",
    "@xmath374 , 2 .",
    "@xmath375 , 3 .",
    "@xmath376 .",
    "then equations @xmath377 and ( [ projmethqn ] ) have unique solutions @xmath378 and @xmath379 respectively . if @xmath67 , then @xmath380 as @xmath381 ( ( i)-(iii ) are necessary and sufficient conditions of this convergence for arbitrary @xmath369 ) . if @xmath75 , then for an a priori choice of @xmath69 such that @xmath382 one has @xmath383 as @xmath85 . if @xmath75 and the following additional conditions ( iv)-(vi ) hold    1 .",
    "@xmath384 , 2 .",
    "@xmath385 , 3 .",
    "@xmath386 ,    then convergence @xmath383 as @xmath85 also holds for a choice of @xmath69 by the discrepancy principle with @xmath387 .",
    "note that in hilbert spaces , conditions ( iii ) , ( v ) are automatically fulfilled by the least error method @xmath388 and by the least squares method @xmath389 respectively , and that for condition ( vi ) the inequality @xmath390 is useful . conditions ( iii ) , ( v ) here seem to be weaker than the corresponding conditions ( [ bd ] ) , ( [ bd1 ] ) , ( [ bddp ] ) in the banach space theorems .    for the least squares method ( [ leastsquares ] ) , the hilbert space analog of theorems [ conv_leastsquares_apriori_gen ] , [ conv_leastsquares_dp ] is theorem [ hilbert - ls - gen ] and the analog of theorem [ convgp - ls ] is theorem [ hilbert - ls - green ] .    [ hilbert - ls - gen ]",
    "let @xmath0 , where @xmath1 , @xmath2 - hilbert spaces , @xmath391 , @xmath369 , @xmath370 orthoprojector , let @xmath392 as @xmath150 for all @xmath393 , and let l c < : ( _ n + _",
    "n+1)^l cn .",
    "then equations @xmath377 and ( [ leastsquares ] ) have unique solutions @xmath378 and @xmath379 respectively . if @xmath67 , then @xmath394 as @xmath381",
    ". if @xmath75 , then @xmath395 as @xmath85 for an a priori choice of @xmath69 such that @xmath396 as @xmath397 and also for a choice of @xmath69 according to the discrepancy principle with @xmath158 .    [ hilbert - ls - green ] let @xmath398 , @xmath399 in ( [ int - eq ] ) be a green s function of the differential operator @xmath400,\\quad b_m(t ) \\not=0 \\quad\\forall t \\in(0,1)\\ ] ] with boundary conditions @xmath401 , @xmath402 such that @xmath403 only has the trivial solution @xmath339 , and let @xmath356 satisfy these boundary conditions . then equation ( [ int - eq ] ) has a unique solution @xmath5 and the least squares method with @xmath323 determines a unique approximation @xmath404 .",
    "convergence @xmath383 as @xmath85 holds with an a priori choice of @xmath69 such that @xmath405 and also with a choice of @xmath69 by the discrepancy principle with @xmath158 .    in theorems [ conv_leastsquares_apriori_gen ] , [ conv_leastsquares_dp ] we needed instead of condition ( [ bdls - h ] ) the conditions ( [ kappa*appr0 ] ) , ( [ kappa2*appr0 ] ) corresponding to the special case @xmath406 in ( [ bdls - h ] ) .",
    "if @xmath407 , then @xmath408 and in case @xmath409 , @xmath410 condition ( [ bdls - h ] ) is satisfied for all @xmath411 , but ( [ kappa*appr0 ] ) , ( [ kappa2*appr0 ] ) require @xmath412 in theorem [ convgp - ls ] .",
    "+ we list below several open problems :    1 .",
    "is it possible to weaken the assumption @xmath412 ?",
    "is it possible to extend the results of theorem [ convgp - ls ] using a more general operator @xmath413 instead of the operator @xmath306 , as in theorem [ hilbert - ls - green ] ?    concerning ( 1 ) ,",
    "computational results for the collocation method indicate that @xmath414 is really needed there .",
    "note that ( 2 ) can be reduced to the ( also open ) question , whether the following lemma , proved in @xcite for the case @xmath415 , remains valid for general @xmath416 $ ] .",
    "let @xmath417 , where @xmath418 , @xmath419 , @xmath420 , @xmath297 .",
    "then @xmath421 , @xmath422 , @xmath423 , @xmath424 , where @xmath425 , @xmath426 is the inverse to the differential operator @xmath427 for the boundary conditions @xmath428 .    in the next section we consider the collocation method as a special case of the general projection method , applying theorem [ convgp - ls ] to a volterra integral equation of the first kind and estimating @xmath160 .",
    "note that in @xcite a collocation method for integral equations of the first kind is considered using kernel functions for basis functions , the number of which was determined by the monotone error rule .",
    "we consider a volterra integral equation of the first kind ( a u)(t):= _ 0^t k(t , s ) u(s)ds = f(t ) ,  t with the operator @xmath429),\\   1\\leq p\\leq \\infty$ ] .",
    "a special case of equation ( [ volterra ] ) is the model problem ( a u)(t):= _ 0^t(t - s)^l-1 u(s)ds = f(t ) ,  t. in the collocation method we find @xmath430 such that @xmath431 where @xmath432 $ ] , @xmath433 , @xmath434 are collocation nodes and @xmath435 are collocation parameters whose choice is essential .    in @xcite , spline collocation",
    "is considered in case @xmath67 , @xmath436 , @xmath437 , @xmath438 ( case @xmath406 in ) .",
    "2.4.2 in @xcite ( page 123 ) proves that convergence holds if and only if @xmath439 in @xcite the case @xmath440 is considered , where @xmath441 ( case @xmath348 in ( [ volt - conv ] ) ) and convergence if @xmath442 and @xmath443 is proven .",
    "convergence of the collocation method for equation in case @xmath444 seems to be an open problem .    in our numerical experiments below",
    "we will use the discrepancy principle for the choice of a proper number @xmath69 of the subintervals , thus we use the first @xmath64 such that @xmath445 . according to theorem [ conv_projmeth_dp ] we need that @xmath446 , so the value of @xmath160 in is needed . for the use of inequality @xmath79 for all @xmath13 we need to estimate @xmath447 } |aw_n(t)|}{\\sup_{i , j } |aw_n(t_{i , j})|}.\\ ] ] in the numerical experiments of the next section we solve equation with @xmath348 .",
    "we use linear splines @xmath448 and collocation nodes @xmath449 with @xmath450 and @xmath451 .",
    "it can be shown that @xmath452 depends on @xmath453 in the form ( c ) = 1+,y = c(-2c^3+c^2 + 1 ) . actually , it is sufficient to consider cubic functions @xmath454 on the interval @xmath455 $ ] which satisfy @xmath456 , @xmath457 .",
    "the last equality is the bound on the derivative of the cubic spline @xmath458 at the points @xmath459 under conditions @xmath460 if @xmath360 .",
    "the value of @xmath461 in ( [ tau(c ) ] ) is the maximum of @xmath454 .",
    "we consider equation ( [ volt - conv ] ) with the exact solutions @xmath462 , where the exact right hand side is computed as @xmath463 .",
    "the noisy data were generated by the formula @xmath464 , where @xmath465 and @xmath466 are random numbers with normal distribution , normed after being generated : @xmath467 in the space setting we used @xmath468 , i.e. , we consider @xmath72 as an operator from @xmath469 to @xmath470 $ ] .    in our numerical experiment we took @xmath448 ( linear splines ) and used collocation nodes @xmath449 with @xmath450 and @xmath451 .",
    "table [ tab : numerics_apost ] contains the results for @xmath471 ; according to formula , the corresponding values of @xmath461 are 5.67 , 4.10 , 4.22 and 6.51 respectively . for fulfilling the theoretical requirement in theorem [ conv_projmeth_dp ] we actually used @xmath472 in the discrepancy principle .",
    "the discrepancy principle gave a number @xmath473 of subintervals with corresponding error @xmath474 .",
    "we also found the optimal number @xmath475 of subintervals and the corresponding error @xmath476 , as well as the best coefficient @xmath477 for the choice of @xmath69 in the discrepancy principle according to @xmath478 .",
    "table [ tab : numerics_apost ] contains our results for the exact solutions @xmath479 with @xmath480 ( left ) and @xmath481 ( right ) .",
    "columns @xmath482 and @xmath483 contain the ratios of the @xmath484-values @xmath485 and the corresponding errors @xmath486 .",
    "the performance of the discrepancy principle is determined by the constant @xmath484 . according to column @xmath482 , the lowest values of constants @xmath487 , needed by the assumptions of theorem [ conv_projmeth_dp ] , are typically 1.5 to 3 times larger than the optimal values @xmath488 .",
    "nevertheless , column @xmath483 shows that the errors @xmath489 of the approximate solutions with choice of the dimension by the discrepancy principle were typically not larger than 1 to 1.4 times the optimal errors @xmath490 .",
    "comparison of the errors @xmath489 for different @xmath453-values suggests to use medium @xmath453-values 0.7 or 0.8 .",
    ".results for optimal @xmath64 and for @xmath64 according to the discrepancy principle [ cols=\"^,^,^,^,^,^,^,^,^,^,^,^,^ \" , ]",
    "in this paper we have extended some results on regularization by projection in hilbert spaces to a more general banach space setting . besides being applicable in case of `` nice '' reflexive banach spaces like @xmath6 with @xmath38 ,",
    "some of our results also give new insights concerning certain cases of nonreflexive banach spaces like @xmath491 which are currently of high interest for several applications .",
    "analytical considerations and numerical results are provided for a volterra integral equation in one dimension space , using a spline discretization .",
    "future work in this context will be devoted to proving convergence rates , particularly also in nonreflexive spaces , and to more general applications in higher dimension spaces .",
    "the first and third author are supported by the estonian science foundation grant 9120 and by institutional research funding iut20 - 57 of the estonian ministry of education and research . the second and fourth author",
    "are supported by the karl popper kolleg `` modeling - simulation - optimization '' funded by the alpen - adria - universitt klagenfurt and by the carinthian economic promotion fund ( kwf ) ."
  ],
  "abstract_text": [
    "<S> we consider ill - posed linear operator equations with operators acting between banach spaces . for solution approximation , the methods of choice here are projection methods onto finite dimensional subspaces , thus extending existing results from hilbert space settings . </S>",
    "<S> more precisely , general projection methods , the least squares method and the least error method are analyzed . in order to appropriately choose the dimension of the subspace , we consider a priori and a posteriori choices by the discrepancy principle and by the monotone error rule . </S>",
    "<S> analytical considerations and numerical tests are provided for a collocation method applied to a volterra integral equation in one dimension space . </S>"
  ]
}