{
  "article_text": [
    "the kaczmarz method is an iterative projection algorithm for solving linear systems of equations  @xcite . due to its simplicity",
    ", the kaczmarz method has found numerous applications including image reconstruction , distributed computation and signal processing to name a few  @xcite , see  @xcite for more applications .",
    "the kaczmarz method has also been rediscovered in the field of image reconstruction and called art ( algebraic reconstruction technique )  @xcite , see also  @xcite for additional references .",
    "it has been also applied to more general settings , see  ( * ? ? ?",
    "* table  1 ) and @xcite for non - linear versions of the kaczmarz method .",
    "let @xmath0 and @xmath1 . throughout the paper all vectors",
    "are assumed to be column vectors .",
    "the kaczmarz method operates as follows : initially , it starts with an arbitrary vector @xmath2 . in each iteration",
    ", the kaczmarz method goes through the rows of @xmath3 in a cyclic manner . ] and for each selected row , say @xmath4-th row @xmath5 , it orthogonally projects the current estimate vector onto the affine hyperplane defined by the @xmath4-th constraint of @xmath6 , i.e. , @xmath7 where @xmath8 is the euclidean inner product . more precisely , assuming that the @xmath9-th row has been selected at @xmath10-th iteration , then the @xmath11-th estimate vector @xmath12 is inductively defined by @xmath13 where @xmath14 are the so - called relaxation parameters and",
    "@xmath15 denotes the euclidean norm .",
    "the original kaczmarz method corresponds to @xmath16 for all @xmath17 and all other setting of @xmath18 s are usually referred as the _ relaxed kaczmarz method _ in the literature  @xcite .",
    "kaczmarz proved that this process converges to the unique solution for square non - singular matrices  @xcite , but without any attempt to bound the rate of convergence .",
    "bounds on the rate of convergence of the kaczmarz method are given in  @xcite , @xcite and ( * ? ? ?",
    "* theorem  4.4 , p.120 ) .",
    "in addition , an error analysis of the kaczmarz method under the finite precision model of computation is given in  @xcite .",
    "nevertheless , the kaczmarz method converges even if the linear system @xmath6 is overdetermined ( @xmath19 ) and has no solution . in this case and provided that @xmath3 has full column rank , the kaczmarz method converges to the least squares estimate .",
    "this was first observed by whitney and meany  @xcite who proved that the relaxed kaczmarz method converges provided that the relaxation parameters are within @xmath20 $ ] and @xmath21 , see also  ( * ? ? ?",
    "* theorem  1 ) , @xcite and  @xcite for additional references . in the literature",
    "there was empirical evidence that selecting the rows non - uniformly at random may be more effective than selecting the rows via kaczmarz s cyclic manner  @xcite .",
    "towards explaining such an empirical evidence , strohmer and vershynin proposed a simple randomized variant of the kaczmarz method that has exponential convergence _ in expectation _  @xcite assuming that the linear system is solvable ; see also  @xcite for extensions to linear constraints . a randomized iterative algorithm that computes a sequence of random vectors @xmath22",
    "is said to _ converge in expectation _ to a vector @xmath23 if and only if @xmath24 as @xmath25 , where the expectation is taken over the random choices of the algorithm .",
    "soon after  @xcite , needell analyzed the behavior of the randomized kaczmarz method for the case of full column rank linear systems that do not have any solution  @xcite .",
    "namely , needell proved that the randomized kaczmarz estimate vector is ( in the limit ) within a fixed distance from the least squares solution and also that this distance is proportional to the distance of @xmath26 from the column space of @xmath3 .",
    "in other words , needell proved that the randomized kaczmarz method is effective for least squares problems whose least squares error is negligible .",
    "in this paper we present a randomized iterative least squares solver ( algorithm  [ alg : rek ] ) that converges in expectation to the minimum euclidean norm solution of @xmath27 the proposed algorithm is based on  @xcite and inspired by  @xcite .",
    "more precisely the proposed algorithm can be thought of as a randomized variant of popa s extended kaczmarz method  @xcite , therefore we named it as _ randomized extended kaczmarz_.    [ [ organization - of - the - paper ] ] organization of the paper + + + + + + + + + + + + + + + + + + + + + + + + +    in section  [ sec : related ] , we briefly discuss related work on the design of deterministic and randomized algorithms for solving least squares problems . in section  [ sec : back ] , we present a randomized iterative algorithm for projecting a vector onto a subspace ( represented as the column space of a given matrix ) which may be of independent interest .",
    "in addition , we discuss the convergence properties of the randomized kaczmarz algorithm for solvable systems ( section  [ sec : rk ] ) and recall its analysis for non - solvable systems ( section  [ sec : noisyrk ] ) . in section  [ sec : result ] , we present and analyze the randomized extended kaczmarz algorithm . finally , in section  [ sec : impl ] we provide a numerical evaluation of the proposed algorithm .",
    "in this section we give a brief discussion on least squares solvers including deterministic direct and iterative algorithms together with recently proposed randomized algorithms . for a detailed discussion on deterministic methods ,",
    "the reader is referred to  @xcite .",
    "in addition , we place our contribution in context with prior work .    [ [ deterministic - algorithms ] ] deterministic algorithms + + + + + + + + + + + + + + + + + + + + + + + +    in the literature , several methods have been proposed for solving least squares problems of the form  . here",
    "we briefly describe a representative sample of such methods including the use of qr factorization with pivoting , the use of the singular value decomposition ( svd ) and iterative methods such as krylov subspace methods applied on the normal equations  @xcite .",
    "lapack provides robust implementations of the first two methods ; dgelsy uses qr factorization with pivoting and dgelsd uses the singular value decomposition  @xcite . for the iterative methods ,",
    "lsqr is equivalent to applying the conjugate gradient method on the normal equations  @xcite and it is a robust and numerically stable method .    [ [ randomized - algorithms ] ] randomized algorithms + + + + + + + + + + + + + + + + + + + + +    to the best of our knowledge , most randomized algorithms proposed in the theoretical computer science literature for approximately solving least squares are mainly based on the following generic two step procedure : first randomly ( and efficiently ) project the linear system into sufficiently many dimensions , and second return the solution of the down - sampled linear system as an approximation to the original optimal solution  @xcite , see also  @xcite .",
    "concentration of measure arguments imply that the optimal solution of the down - sampled system is close to the optimal solution of the original system .",
    "the accuracy of the approximate solution using this approach depends on the sample size and to achieve relative accuracy @xmath28 , the sample size should depend inverse polynomially on @xmath28 .",
    "this makes these approaches unsuitable for the high - precision regime of error that is considered here .",
    "a different approach is the so called randomized preconditioning method , see  @xcite .",
    "the authors of  @xcite implemented blendenpik , a high - precision least squares solver .",
    "blendenpik consists of two steps . in the first step ,",
    "the input matrix is randomly projected and an effective preconditioning matrix is extracted from the projected matrix . in the second step ,",
    "an iterative least squares solver such as the lsqr algorithm of paige and saunders  @xcite is applied on the preconditioned system .",
    "blendenpik is effective for overdetermined and underdetermined problems .",
    "a parallel iterative least squares solver based on normal random projections called lsrn was recently implemented by meng , saunders and mahoney  @xcite .",
    "lsrn consists of two phases . in the first preconditioning phase",
    ", the original system is projected using random normal projection from which a preconditioner is extracted . in the second step ,",
    "an iterative method such as lsqr or the chebyshev semi - iterative method  @xcite is applied on the preconditioned system .",
    "this approach is also effective for over - determined and under - determined least squares problems assuming the existence of a parallel computational environment .      in section  [ sec : impl ]",
    ", we compare the randomized extended kaczmarz algorithm against dgelsy , dgelsd , blendenpik .",
    "lsrn  @xcite did not perform well under a setup in which no parallelization is allowed , so we do not include lsrn s performance .",
    "the numerical evaluation of section  [ sec : impl ] indicates that the randomized extended kaczmarz is effective on the case of sparse , well - conditioned and strongly rectangular ( both overdetermined and underdetermined ) least squares problems , see  figure  [ fig : sparse ] .",
    "moreover , the randomized extended kaczmarz algorithm has also comparable performance with lapack s routine for the dense random input matrices , see  figure  [ fig : dense ] ( notice that the proposed algorithm almost matches blendenpik s performance for the underdetermined case , see figure  [ fig : denseunder ] ) . on the other hand , a preconditioned version of the proposed algorithm",
    "does not perform well under the case of ill - conditioned matrices , see figure  [ fig : cond ] .",
    "[ [ preliminaries - and - notation ] ] preliminaries and notation + + + + + + + + + + + + + + + + + + + + + + + + + +    for an integer @xmath29 , let @xmath30:=\\{1,\\ldots , m\\}$ ] . throughout the paper all vectors",
    "are assumed to be column vectors .",
    "we denote the rows and columns of @xmath3 by @xmath31 and @xmath32 , respectively ( both viewed as column vectors ) .",
    "@xmath33 denotes the column space of @xmath3 , i.e. , @xmath34 and @xmath35 denotes the orthogonal complement of @xmath33 . given any @xmath1 , we can uniquely write it as @xmath36 , where @xmath37 is the projection of @xmath26 onto @xmath33 . @xmath38 and @xmath39 denotes the frobenius norm and spectral norm , respectively . let @xmath40 be the non - zero singular values of @xmath3 .",
    "we will usually refer to @xmath41 and @xmath42 as @xmath43 and @xmath44 , respectively .",
    "the moore - pensore pseudo - inverse of @xmath3 is denoted by @xmath45  @xcite .",
    "recall that @xmath46 . for any non - zero real matrix @xmath3",
    ", we define @xmath47 related to this is the scaled square condition number introduced by demmel in  @xcite , see also  @xcite .",
    "it is easy to check that the above parameter @xmath48 is related with the condition number of @xmath3 , @xmath49 , via the inequalities : @xmath50 .",
    "we denote by @xmath51 the number of non - zero entries of its argument matrix .",
    "we define the _ average row sparsity _ and _ average column sparsity _ of @xmath3 by @xmath52 and @xmath53 , respectively , as follows : @xmath54 where @xmath55 for every @xmath56}$ ] and @xmath57 for every @xmath58}$ ]",
    ". the following fact will be used extensively in the paper .",
    "[ fact : xls ] let @xmath3 be any non - zero real @xmath59 matrix and @xmath1",
    ". denote by @xmath60 . then @xmath61 .",
    "we frequently use the inequality @xmath62 for every @xmath63 .",
    "we conclude this section by collecting a few basic facts from probability theory that will be frequently used . for any random variable @xmath64 ,",
    "we denote its expectation by @xmath65 $ ] or @xmath66 .",
    "if @xmath64 is a non - negative random variable , markov s inequality states that @xmath67 $ ] .",
    "let @xmath64 and @xmath68 be two random variables , then @xmath69=\\operatorname{\\mathbb{e}}[x ] + \\operatorname{\\mathbb{e}}[y]$ ] .",
    "we will refer to this fact as _ linearity of expectation_. let @xmath70 be a set of events defined over some probability space holding with probabilities @xmath71 respectively , then @xmath72 .",
    "we refer to this fact as _",
    "union bound_.      initialize @xmath73 pick @xmath74 $ ] with probability @xmath75 $ ] set @xmath76 output @xmath77    in this section we present a randomized iterative algorithm ( algorithm  [ alg : randop ] ) that , given any vector @xmath1 and a linear subspace of @xmath78 represented as the column space of a given matrix @xmath3 , approximately computes the orthogonal projection of @xmath26 onto the column space of @xmath3 ( denoted by @xmath37 , @xmath79 ) , see  @xcite for a different approach .",
    "algorithm  [ alg : randop ] is iterative .",
    "initially , it starts with @xmath80 . at the @xmath10-th iteration ,",
    "the algorithm randomly selects a column @xmath81 of @xmath3 for some @xmath82 , and updates @xmath83 by projecting it onto the orthogonal complement of the space of @xmath81 .",
    "the claim is that randomly selecting the columns of @xmath3 with probability proportional to their square norms implies that the algorithm converges to @xmath84 in expectation .",
    "after @xmath85 iterations , the algorithm outputs @xmath77 and by orthogonality @xmath86 serves as an approximation for @xmath37 .",
    "the next theorem bounds the expected rate of convergence for algorithm  [ alg : randop ] .",
    "[ thm : randop ] let @xmath0 , @xmath1 and @xmath87 be the input to algorithm  [ alg : randop ] .",
    "fix any integer @xmath88 . in exact arithmetic , after @xmath10 iterations of algorithm  [ alg : randop ] it holds that @xmath89 moreover , each iteration of algorithm  [ alg : randop ] requires in expectation ( over the random choices of the algorithm ) at most @xmath90 arithmetic operations .",
    "a suggestion for a stopping criterion for algorithm  [ alg : randop ] is to regularly check : @xmath91 for some given accuracy @xmath92 .",
    "it is easy to see that whenever this criterion is satisfied , it holds that @xmath93 , i.e. , @xmath94 .",
    "we devote the rest of this subsection to prove theorem  [ thm : randop ] .",
    "define @xmath95 for every @xmath96 $ ] .",
    "observe that @xmath97 , i.e. , @xmath98 is a projector matrix .",
    "let @xmath64 be a random variable over @xmath99 that picks index @xmath82 with probability @xmath100 .",
    "it is clear that @xmath101 = { \\mathbf{i}}_m - { { { \\ensuremath{\\mathsf{a } } } } } { { { \\ensuremath{\\mathsf{a } } } } } ^\\top /{\\ensuremath{\\left\\| { { { \\ensuremath{\\mathsf{a } } } } } \\right\\|_{\\text{\\rm f}}}}^2 $ ] .",
    "later we will make use of the following fact .",
    "[ lem : technical ] for every vector @xmath102 in the column space of @xmath3 , it holds @xmath103 .",
    "define @xmath104 for every @xmath17 .",
    "a direct calculation implies that @xmath105 indeed , @xmath106 using the definitions of @xmath107 , @xmath83 , @xmath108 and the fact that @xmath109 for any @xmath110}$ ] .",
    "moreover , it is easy to see that for every @xmath111 @xmath107 is in the column space of @xmath3 , since @xmath112 , @xmath113 and in addition @xmath114 is a projector matrix for every @xmath115 $ ] .",
    "let @xmath116 be a sequence of independent and identically distributed random variables distributed as @xmath64 .",
    "for ease of notation , we denote by @xmath117 = \\operatorname{\\mathbb{e}}_{x_k } [ \\cdot\\ |\\ x_1 , x_2 , \\ldots , x_{k-1}]$ ] , i.e. , the conditional expectation conditioned on the first @xmath118 iteration of the algorithm .",
    "it follows that @xmath119 { \\ensuremath{{\\mathbf e}}}^{(k-1 ) } } \\right\\rangle } \\\\                               & \\leq   { \\ensuremath{\\left\\|{\\ensuremath{{\\mathbf e}}}^{(k-1)}\\right\\|_2 } } { \\ensuremath{\\left\\| \\left({\\mathbf{i}}_m - \\frac { { { { \\ensuremath{\\mathsf{a } } } } } { { { \\ensuremath{\\mathsf{a } } } } } ^\\top } { { \\ensuremath{\\left\\| { { { \\ensuremath{\\mathsf{a } } } } } \\right\\|_{\\text{\\rm f}}}}^2}\\right ) { \\ensuremath{{\\mathbf e}}}^{(k-1 ) } \\right\\|_2 } }                                \\ \\leq \\ \\left(1 - \\frac{\\sigma^2_{\\min}}{{\\ensuremath{\\left\\| { { { \\ensuremath{\\mathsf{a } } } } } \\right\\|_{\\text{\\rm f}}}}^2}\\right ) { \\ensuremath{\\left\\|{\\ensuremath{{\\mathbf e}}}^{(k-1)}\\right\\|_2}}^2\\end{aligned}\\ ] ] where we used linearity of expectation , the fact that @xmath120 is a projector matrix , cauchy - schwarz inequality and fact  [ lem : technical ] . repeating the same argument @xmath121 times",
    "we get that @xmath122 note that @xmath123 to conclude .",
    "step @xmath124 can be rewritten as @xmath125 . at every iteration ,",
    "the inner product and the update from @xmath83 to @xmath126 require at most @xmath127 operations for some @xmath110}$ ] ; hence in expectation each iteration requires at most @xmath128 operations .",
    "set @xmath129 to be any vector in the row space of @xmath3 pick @xmath130 $ ] with probability @xmath131 $ ] set @xmath132 output @xmath133    strohmer and vershynin proposed the following randomized variant of kaczmarz algorithm  ( algorithm  [ alg : randomized ] ) , see  @xcite for more details .",
    "the following theorem is a restatement of the main result of  @xcite without imposing the full column rank assumption .",
    "[ thm : rk : consistent ] let @xmath0 , @xmath1 and @xmath87 be the input to algorithm  [ alg : randomized ] .",
    "assume that @xmath6 has a solution and denote @xmath134 .",
    "in exact arithmetic , algorithm  [ alg : randomized ] converges to @xmath135 in expectation : @xmath136    the above theorem has been proved in  @xcite for the case of full column rank .",
    "also , the rate of expected convergence in  @xcite is @xmath137 where @xmath138 .",
    "notice that if @xmath139 , then @xmath140 is infinite whereas @xmath48 is bounded .",
    "we devote the rest of this subsection to prove theorem  [ thm : rk : consistent ] following  @xcite . the proof is based on the following two elementary lemmas which both appeared in  @xcite . however , in our setting , the second lemma is not identical to that in  @xcite .",
    "we deferred their proofs to the appendix .",
    "[ lem : ortho ] assume that @xmath6 has a solution and use the notation of algorithm  [ alg : randomized ] , then @xmath141 is perpendicular to @xmath142 for any @xmath17 .",
    "in particular , in exact arithmetic it holds that @xmath143 .",
    "the above lemma provides a formula for the error at each iteration . ideally , we seek to minimize the error at each iteration which is equivalent to maximizing @xmath144 over the choice of the row projections of the algorithm .",
    "the next lemma suggests that by randomly picking the rows of @xmath3 reduces the error in expectation .",
    "[ lem : avg ] assume that @xmath145 has a solution .",
    "let @xmath146 be a random variable over @xmath30 $ ] with distribution @xmath147 and assume that @xmath148 is a vector in the row space of @xmath3 .",
    "if @xmath149 ( in exact arithmetic ) , then @xmath150    theorem  [ thm : rk : consistent ] follows by iterating lemma [ lem : avg ] , we get that @xmath151      the analysis of strohmer and vershynin is based on the restrictive assumption that the linear system has a solution .",
    "needell made a step further and analyzed the more general setting in which the linear system does not have any solution and @xmath3 has full column rank  @xcite . in this",
    "setting , it turns out that the randomized kaczmarz algorithm computes an estimate vector that is within a fixed distance from the solution ; the distance is proportional to the norm of the `` noise vector '' multiplied by @xmath48  @xcite .",
    "the following theorem is a restatement of the main result in  @xcite with two modifications : the full column rank assumption on the input matrix is dropped and the additive term @xmath152 of theorem  @xmath153 in  @xcite is improved to @xmath154 .",
    "the only technical difference here from  @xcite is that the full column rank assumption is not necessary , so we defer the proof to the appendix for completeness .",
    "[ thm : rk : inconsistent ] assume that the system @xmath155 has a solution for some @xmath156 .",
    "denote by @xmath157 .",
    "let @xmath158 denote the @xmath10-th iterate of the randomized kaczmarz algorithm applied to the linear system @xmath6 with @xmath159 for any fixed @xmath160 , i.e. , run algorithm  [ alg : randomized ] with input @xmath161 .",
    "in exact arithmetic , it follows that @xmath162 in particular , @xmath163",
    "given any least squares problem , theorem  [ thm : rk : inconsistent ] with @xmath164 tells us that the randomized kaczmarz algorithm works well for least square problems whose least squares error is very close to zero , i.e. , @xmath165 .",
    "roughly speaking , in this case the randomized kaczmarz algorithm approaches the minimum @xmath166-norm least squares solution up to an additive error that depends on the distance between @xmath26 and the column space of @xmath3 .    in the present paper ,",
    "the main observation is that it is possible to efficiently reduce the norm of the `` noisy '' part of @xmath26 , @xmath84 ( using algorithm  [ alg : randop ] ) and then apply the randomized kaczmarz algorithm on a new linear system whose right hand side vector is now arbitrarily close to the column space of @xmath3 , i.e. , @xmath167 .",
    "this idea together with the observation that the least squares solution of the latter linear system is equal ( in the limit ) to the least squares solution of the original system ( see fact  [ fact : xls ] ) implies a randomized algorithm for solving least squares .",
    "next we present the randomized extended kaczmarz algorithm which is a specific combination of the randomized orthogonal projection algorithm together with the randomized kaczmarz algorithm .",
    "initialize @xmath168 and @xmath73 pick @xmath130 $ ] with probability @xmath131 $ ] pick @xmath74 $ ] with probability @xmath75 $ ] set @xmath169 set @xmath170 [ alg : stopping ] check every @xmath171 iterations and terminate if it holds : @xmath172    output @xmath148    we describe a randomized algorithm that converges in expectation to the minimum @xmath166-norm solution vector @xmath135 ( algorithm  [ alg : rek ] ) .",
    "the proposed algorithm consists of two components . the first component consisting of steps @xmath124 and @xmath173 is responsible to implicitly maintain an approximation to @xmath37 formed by @xmath174 .",
    "the second component , consisting of steps 4 and 7 , applies the randomized kaczmarz algorithm with input @xmath3 and the current approximation @xmath175 of @xmath37 , i.e. , applies the randomized kaczmarz on the system @xmath176 .",
    "since @xmath177 converges to @xmath37 , @xmath148 will eventually converge to the minimum euclidean norm solution of @xmath178 which equals to @xmath179 ( see fact  [ fact : xls ] ) .",
    "the stopping criterion of step  [ alg : stopping ] was decided based on the following analysis .",
    "assume that the termination criteria are met for some @xmath88 .",
    "let @xmath180 for some @xmath181 ( which holds by the definition of @xmath83 ) .",
    "then , @xmath182 by re - arranging terms and using the second part of the termination criterion , it follows that @xmath183 .",
    "now , @xmath184 where we used the triangle inequality , the first part of the termination rule together with @xmath185 and the above discussion .",
    "now , since @xmath186 , it follows that @xmath187 equation   demonstrates that the forward error of rek after termination is bounded .      the following theorem bounds the expected rate of convergence of algorithm  [ alg : rek ] .",
    "[ thm : rek ] after @xmath87 iterations , in exact arithmetic , algorithm  [ alg : rek ] with input @xmath3 ( possibly rank - deficient ) and @xmath26 computes a vector @xmath133 such that @xmath188    for the sake of notation , set @xmath189 and denote by @xmath190 : = \\operatorname{\\mathbb{e}}[\\cdot \\ |\\ i_0,j_0 , i_1,j_1,\\ldots , i_k , j_k]$ ] , i.e. , the conditional expectation with respect to the first @xmath10 iterations of algorithm  [ alg : rek ] .",
    "observe that steps @xmath124 and @xmath173 are independent from steps @xmath191 and @xmath192 of algorithm  [ alg : rek ] , so theorem  [ thm : randop ] implies that for every @xmath193 @xmath194 fix a parameter @xmath195 .",
    "after the @xmath196-th iteration of algorithm  [ alg : rek ] , it follows from theorem  [ thm : rk : inconsistent ] ( inequality  ) that @xmath197 indeed , the randomized kaczmarz algorithm is executed with input @xmath198 and current estimate vector @xmath199 .",
    "set @xmath200 and @xmath201 in theorem  [ thm : rk : inconsistent ] and recall that @xmath202 .",
    "now , averaging the above inequality over the random variables @xmath203 and using linearity of expectation , it holds that @xmath204 simplifying the right hand side using the fact that @xmath205 , it follows @xmath206 moreover , observe that for every @xmath193 @xmath207 now for any @xmath88 , similar considerations as ineq .",
    "implies that @xmath208 to derive the last inequality , consider two cases .",
    "if @xmath85 is even , set @xmath209 , otherwise set @xmath210 . in both cases , @xmath211 .",
    "in this section , we discuss the running time complexity of the randomized extended kaczmarz ( algorithm  [ alg : rek ] ) .",
    "recall that rek is a las - vegas randomized algorithm , i.e. , the algorithm always outputs an `` approximately correct '' least squares estimate ( satisfying  ) but its runnning time is a random variable . given any fixed accuracy parameter @xmath92 and any fixed failure probability @xmath212 we bound the number of iterations required by the algorithm to terminate with probability at least @xmath213 .",
    "[ lem : runtime ] fix an accuracy parameter @xmath214 and failure probability @xmath212 . in exact arithmetic , algorithm  [ alg : rek ] terminates after at most @xmath215 iterations with probability at least @xmath213 .",
    "denote @xmath216 for notational convenience .",
    "it suffices to prove that with probability at least @xmath213 the conditions of step  [ alg : stopping ] of algorithm  [ alg : rek ] are met . instead of proving this",
    ", we will show that :    1 .   with probability at least @xmath217 : @xmath218 .",
    "2 .   with probability at least @xmath217 : @xmath219 .",
    "later we prove that items ( 1 ) and ( 2 ) imply the lemma .",
    "first we prove item ( 1 ) . by the definition of the algorithm , @xmath220 the first equality follows since @xmath221 ,",
    "the second inequality is markov s inequality , the third inequality follows by theorem  [ thm : randop ] , and the last inequality since @xmath222 .",
    "now , we prove item ( 2 ) : @xmath223 the first inequality is markov s inequality , the second inequality follows by theorem  [ thm : rek ] , and the last inequality follows provided that @xmath224 a union bound on the complement of the above two events ( item ( 1 ) and ( 2 ) ) implies that both events happen with probability at least @xmath213 .",
    "now we show that conditioning on items ( 1 ) and ( 2 ) , it follows that rek terminates after @xmath225 iterations , i.e. , @xmath226 we start with the first condition .",
    "first , using triangle inequality and item 2 , it follows that @xmath227 now , @xmath228 where the first inequality is triangle inequality , the second inequality follows by item @xmath229 and @xmath230 , the third and forth inequality follows by item @xmath231 and the fifth inequality holds by inequality   and the last inequality follows since @xmath232 .",
    "the second condition follows since @xmath233 the first equation follows by orthogonality , the second inequality assuming item ( 2 ) , the third inequality follows since @xmath230 , the forth inequality follows by   and the final inequality since @xmath234 .",
    "lemma  [ lem : runtime ] bounds the number of iterations with probability at least @xmath213 , next we bound the total number of arithmetic operations in worst case  ( eqn .  ) and in expectation  ( eqn .  ) .",
    "let s calculate the computational cost of rek in terms of floating - point operations ( flops ) per iteration .",
    "for the sake of simplicity , we ignore the additional ( negligible ) computational overhead required to perform the sampling operations ( see section  [ sec : impl ] for more details ) and checking for convergence .",
    "each iteration of algorithm  [ alg : rek ] requires four level-1 blas operations ( two _ ddot _ operations of size @xmath29 and @xmath235 , respectively , and two _ daxpy _ operations of size @xmath235 and @xmath29 , respectively ) and additional four flops . in total ,",
    "@xmath236 flops per iteration",
    ". therefore by lemma  [ lem : runtime ] , with probability at least @xmath213 , rek requires at most @xmath237 arithmetic operations ( using that @xmath238 ) .",
    "next , we bound the _ expected running time _ of rek for achieving the above guarantees for any fixed @xmath28 and @xmath239 .",
    "obviously , the expected running time is at most the quantity in  .",
    "however , as we will see shortly the expected running time is proportional to @xmath240 instead of @xmath241 .    exploiting the ( possible ) sparsity of @xmath3",
    ", we first show that each iteration of algorithm  [ alg : rek ] requires at most @xmath242 operations in expectation . for simplicity of presentation",
    ", we assume that we have stored @xmath3 in compressed column sparse format _ and _ compressed row sparse format  @xcite .",
    "indeed , fix any @xmath243}$ ] and @xmath110}$ ] at some iteration @xmath10 of algorithm  [ alg : rek ] . since @xmath3 is both stored in compressed column and compressed sparse format , steps @xmath192 and step @xmath244 can be implemented in @xmath245 and 5@xmath246 , respectively .    by the linearity of expectation and the definitions of @xmath53 and @xmath52 ,",
    "the expected running time after @xmath225 iterations is at most @xmath247 .",
    "it holds that ( recall that @xmath248 ) @xmath249 } } { \\ensuremath{\\left\\| { { { { \\ensuremath{\\mathsf{a } } } } } _ { ( j)}}\\right\\|_2}}^2}{\\sigma_{\\min}^2 } \\ln \\left(\\frac{32(1 + 2{\\ensuremath{\\kappa^2\\left ( { { { \\ensuremath{\\mathsf{a } } } } } \\right)}})}{\\delta{\\varepsilon}^2}\\right)\\\\              & \\leq 2{\\ensuremath{\\mathrm{\\textbf{\\footnotesize nnz}}\\left ( { { { \\ensuremath{\\mathsf{a } } } } } \\right)}}{\\ensuremath{\\kappa^2\\left ( { { { \\ensuremath{\\mathsf{a } } } } } \\right ) } } \\ln \\left(\\frac{32(1 + 2{\\ensuremath{\\kappa^2\\left ( { { { \\ensuremath{\\mathsf{a } } } } } \\right)}})}{\\delta{\\varepsilon}^2}\\right)\\end{aligned}\\ ] ] using the definition of @xmath53 and @xmath225 in the first equality and the fact that @xmath250 } } { \\ensuremath{\\left\\| { { { { \\ensuremath{\\mathsf{a } } } } } _ { ( j)}}\\right\\|_2}}^2 \\leq \\sigma_{\\max}^2 $ ] and @xmath251 in the first and second inequality . a similar argument shows that @xmath252 using the inequality @xmath253 } } { \\ensuremath{\\left\\| { { { { \\ensuremath{\\mathsf{a } } } } } ^{(i)}}\\right\\|_2}}^2 \\leq \\sigma_{\\max}^2 $ ] . hence by lemma  [ lem : runtime ] , with probability at least @xmath213 , the expected number of arithmetic operations of rek is at most @xmath254 in other words , the expected running time analysis is much tighter than the worst case displayed in equation   and is proportional to @xmath240 times the square condition number of @xmath3 as advertised in the abstract .",
    "the proposed algorithm has been entirely implemented in c. we provide three implementation of algorithm  [ alg : rek ] : rek - c , rek - blas and rek - blas - precond .",
    "rek - c corresponds to a direct translation of algorithm  [ alg : rek ] to c code .",
    "rek - blas is an implementation of rek with two additional technical features .",
    "first , rek - blas uses level-1 blas routines for all operations of algorithm  [ alg : rek ] and secondly rek - blas additionally stores explicitly the transpose of @xmath3 for more efficiently memory access of both the rows and columns of @xmath3 using blas .",
    "rek - blas - precond is an implementation of rek - blas that additionally supports upper triangular preconditioning ; we used blendenpik s preconditioning code to ensure a fair comparison with blendenpik ( see section  [ sec : exp ] ) . in the implementations of rek - c and rek - blas we check for convergence",
    "every @xmath255 iterations .",
    "moreover , all implementations include efficient code that handles sparse input matrices using the compressed column ( and row ) sparse matrix format  @xcite .",
    "[ [ sampling - from - non - uniform - distributions ] ] sampling from non - uniform distributions + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the sampling operations of algorithm  [ alg : rek ] ( steps 4 and 5 ) are implemented using the so - called `` alias method '' for generating samples from any given discrete distribution  @xcite .",
    "the alias method , assuming access to a uniform random variable on @xmath256 $ ] in constant time and linear time preprocessing , generates one sample of the given distribution in constant time  @xcite .",
    "we use an implementation of w. d. smith that is described in  @xcite and c s _ drand48 _ ( ) to get uniform samples from @xmath256 $ ] .",
    "we report our experimental results in this section .",
    "we compared the randomized extended kaczmarz ( rek - c , rek - blas , rek - blas - precond ) algorithm to lapack s dgelsy and dgelsd least squares solvers , blendenpick ( version 1.3 ,  @xcite ) and matlab s backslash operator .",
    "lsrn  @xcite did not perform well under a setup in which no parallelization is allowed as the one used here , so we do not include lsrn s performance .",
    "dgelsy uses qr factorization with pivoting and dgelsd uses the singular value decomposition .",
    "we use matlab with version 7.9.0.529 ( r2009b ) .",
    "in addition , we use matlab s included blas and lapack packages and we call lapack s functions from matlab using matlab s cmex technology which allows us to measure only lapack s elapsed time .",
    "we should highlight that matlab is used as a scripting language and no matlab - related overheads have been taken under consideration .",
    "blendenpik requires the fftw library ; we used fftw-3.3.3 . to match the accuracy of lapack s direct solvers , we fixed @xmath28 in algorithm  [ alg : rek ] to be 10e-14 .",
    "moreover , during our experiments we ensured that the residual error of all the competing algorithms were about of the same order of magnitude .",
    "we used a pentium(r ) dual - core e5300 ( 2.60ghz ) equipped with 5 gb of ram and compiled our source code using gcc-4.7.2 under linux operating system .",
    "all running times displayed below are measured using the _ ftime _ linux system call by taking the average of the running time of 10 independent executions .",
    "we experimented our algorithm under three different distributions of random input matrices ( sparse , dense and ill - conditioned ) under the setting of strongly rectangular settings of least squares instances .",
    "in all cases we normalized the column norms of the input matrices to unity and generate the right hand side vector @xmath26 having gaussian entries of variance one .",
    "[ [ sparse - least - squares ] ] sparse least squares + + + + + + + + + + + + + + + + + + + +    we tested our algorithm in the overdetermined setting of random sparse @xmath59 matrices with @xmath257 and @xmath258 and density @xmath259 .",
    "we also tested rek - blas on the underdetermined case where @xmath260 and @xmath261 . in both cases ,",
    "the density of the sparse matrices was set to @xmath259 ( for even sparser matrices rek - blas performed even better compared to all other mentioned methods ) .",
    "to generate these sparse matrix ensembles , we used matlab s _ sprandn _ function with variance one .",
    "the results are depicted in figure  [ fig : sparse ] .",
    "both plots demonstrate that rek - blas is superior on both the underdetermined ( figure  [ fig : sparseunder ] ) and overdetermined case ( figure  [ fig : sparseover ] ) .",
    "it is interesting that rek - blas performs well in the underdetermined case .",
    "[ [ dense - and - well - conditioned - least - squares ] ] dense and well - conditioned least squares + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in this scenario , we used random overdetermined dense @xmath59 matrices with much more rows than columns , i.e. , we set @xmath262 and @xmath263 .",
    "we also tested rek - blas on the underdetermined case where @xmath264 and @xmath265 .",
    "we generated this set of matrices using matlab s _ randn _ function with variance ten .",
    "we depicted the results in figure  [ fig : denseover ] . in the overdetermined case ( figure  [ fig : denseover ] ) ,",
    "rek - blas is marginally superior compared to lapack s routines whereas rek - c ( as a naive implementation of algorithm  [ alg : rek ] ) is inferior .",
    "blendepik is the winner in this case .",
    "interestingly , rek - blas almost matches the performance of blendenpik in the underdetermined case , see figure  [ fig : denseunder ] .",
    "[ [ dense - and - ill - conditioned - least - squares ] ] dense and ill - conditioned least squares + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    finally , we tested all algorithms under a particular case of random ill - conditioned dense matrices with @xmath262 and @xmath266 .",
    "namely , we used higham s _ randsvd _ function for generating these matrices  @xcite .",
    "more precisely , we set the condition number of these matrices to be @xmath267 ; set the top singular value to one and the rest to 10e-6 .",
    "the results are displayed in figure  [ fig : cond ] .",
    "unfortunately , in the ill - conditioned setting rek - blas - precond is inferior compared to lapack s routines and blendepik .",
    "we also verified the results of  @xcite that blendepik is superior compared to lapack s least squares solvers in this setting .",
    "we would like to thank the anonymous reviewers for their invaluable comments on an earlier draft of the present manuscript .",
    "the first author would like to thank haim avron for his technical support on several issues regarding blendenpik and philip a. knight for sharing his unpublished manuscript  @xcite .",
    "dmms11    e.  anderson , z.  bai , j.  dongarra , a.  greenbaum , a.  mckenney , j.  du  croz , s.  hammerling , j.  demmel , c.  bischof , and d.  sorensen . .",
    "in _ proceedings of the 1990 acm / ieee conference on supercomputing _ , supercomputing 90 , pages 211 .",
    "ieee computer society press , 1990 .",
    "h.  avron , p.  maymounkov , and s.  toledo . .",
    ", 32(3):12171236 , 2010 .",
    "r.  ansorge . .",
    "33(34):367375 , september 1984 .",
    "r.  barrett , m.  berry , t.  f. chan , j.  demmel , j.  donato , j.  dongarra , v.  eijkhout , r.  pozo , c.  romine , and h.  van  der vorst . .",
    "software , environments , tools . society for industrial and applied mathematics , 1987 .",
    "a.  bjrck . .",
    "society for industrial and applied mathematics , 1996 .",
    "y.  censor , p.  eggermont , and d.  gordon . .",
    ", 41:8392 , 1983 .    y.  censor .",
    ", 23(4):444466 , 1981 .",
    "e.  s. coakley , v.  rokhlin , and m.  tygert . .",
    ", 33(2):849868 , 2011 .    k.  l. clarkson and d.  p. woodruff . .",
    "in _ proceedings of the symposium on theory of computing ( stoc ) _ , pages 205214 , 2009 .",
    "k.  l. clarkson and d.  p. woodruff . .",
    "available at  arxiv:1207.6365 , july 2012 .",
    "y.  censor and s.  a. zenios . .",
    "numerical mathematics and scientific computation series .",
    "oxford university press , 1997 .    j.  w. demmel . .",
    ", 50(182):pp . 449480 , 1988 .",
    "p.  drineas , m.  w. mahoney , and s.  muthukrishnan . .",
    "in _ proceedings of the acm - siam symposium on discrete algorithms ( soda ) _ , pages 11271136 , 2006 .",
    "p.  drineas , m.  w. mahoney , s.  muthukrishnan , and t.  sarls . . , 117(2):219249 ,",
    "feb 2011 .",
    "h.  g. feichtinger , c.  cenker , m.  mayer , h.  steier , and t.  strohmer . .",
    "pages 299310 , 1992 .    n.  m. freris and a.  zouzias . . ,",
    "a.  galntai . .",
    "advances in mathematics .",
    "springer , 2003 .",
    "r.  gordon , r.  bender , and g.  t. herman . .",
    ", 29(3):471  481 , 1970 .    g.  h. golub and c.  f.  van loan . . ,",
    "third edition , 1996 .",
    "g.  h. golub and r.  s. varga . .",
    ", 3:157168 , 1961 .",
    "g.  t. herman . .",
    "omputer science and applied mathematics .",
    "new york etc .",
    ": academic press ( a subsidiary of harcourt brace jovanovich , publishers ) .",
    "xiv , 1980 .",
    "n.  j. higham . .",
    "technical report , ithaca , ny , usa , 1989 .    nicholas  j. higham . .",
    "society for industrial and applied mathematics , philadelphia , pa , usa , first edition , 1996 .",
    "g.  t. herman and l.  b. meyer . .",
    ", 12(3):600609 , 1993 .    m.  hanke and wilhelm n. .",
    ", 130(0):83  98 , 1990 .    s.  kaczmarz . . , 35:355357 , 1937 .",
    "p.  a. knight . .",
    ", manchester university , 1993 .",
    "p.  a. knight . .",
    "unpublished manuscript , may 1996 .",
    "d.  leventhal and a.  s. lewis . .",
    ", 35(3):641654 , 2010 .    s.  f. mccormick . .",
    ", 23:371385 , 1975 .",
    "x.  meng , m.  a. saunders , and m.  w. mahoney . .",
    "available at  http://arxiv.org/abs/1109.5981 , sept 2011 .",
    "a.  magen and a.  zouzias . .",
    "in _ proceedings of the acm - siam symposium on discrete algorithms ( soda ) _ , pages 14221436 , 2011 .    f.  natterer . .",
    "society for industrial and applied mathematics , 2001 .",
    "n.  h. nguyen , t.  t. do , and t.  d. tran . .",
    "in _ proceedings of the symposium on theory of computing ( stoc ) _ , pages 215224 , 2009 .    d.  needell . .",
    ", 50(2):395403 , 2010 .",
    "c.  popa . .",
    ", 6:5164 , 1999 .",
    "c.c . paige and m.a .",
    "saunders . .",
    ", 8(1):4371 , 1982 .",
    "v.  rokhlin and m.  tygert . .",
    ", 105(36):1321213218 , 2008 .",
    "y.  saad . .",
    "society for industrial and applied mathematics , 2nd edition , 2003 .",
    "t.  sarls . .",
    "in _ proceedings of the symposium on foundations of computer science ( focs ) _ , pages 143152 , 2006 .",
    "w.  d. smith . .",
    "technical report , princeton , nj , usa , 2002 .",
    "t.  strohmer and r.  vershynin . .",
    ", 15(1):262278 , 2009 .",
    "k.  tanabe . .",
    ", 17:203214 , 1971 .    c.  tompkins . .",
    "in _ proc .",
    "2nd symposium of linear programming _ , pages 425448 , washington , dc , 1955 .",
    "m.  d. vose . .",
    ", 17(9):972975 , september 1991 .",
    "a.  j. walker . . ,",
    "3(3):253256 , september 1977 .",
    "t.  whitney and r.  meany . .",
    ", 4(1):109118 , 1967 .",
    "we present the proof of known facts from previous works for completeness .",
    "( of lemma  [ lem : ortho ] ) it suffices to show that @xmath268 . for notational convenience ,",
    "let @xmath269 for every @xmath58}$ ] .",
    "assume that @xmath270 for some arbitrary @xmath271 $ ] .",
    "then , @xmath272 using the definition of @xmath12 , and the fact that @xmath273 since @xmath135 is a solution to @xmath145 .",
    "now , by the definition of @xmath274 , @xmath275 .",
    "( of lemma  [ lem : avg ] ) in light of lemma  [ lem : ortho ] , it suffices to show that @xmath276 . by the definition of @xmath12",
    ", it follows @xmath277 \\ = \\",
    "\\operatorname{\\mathbb{e}}_{z } \\frac{{\\left\\langle { \\xls - { \\mathbf{x}}^{(k ) } } , \\ { { { { { \\ensuremath{\\mathsf{a } } } } } ^{(z ) } } } \\right\\rangle}^2}{{\\ensuremath{\\left\\| { { { { \\ensuremath{\\mathsf{a } } } } } ^{(z)}}\\right\\|_2}}^2 } \\\\   & =    \\sum_{i=1}^{m } \\frac{{\\left\\langle { \\xls - { \\mathbf{x}}^{(k)}},\\ { { { { { \\ensuremath{\\mathsf{a } } } } } ^{(i ) } } } \\right\\rangle}^2}{{\\ensuremath{\\left\\| { { { \\ensuremath{\\mathsf{a } } } } } \\right\\|_{\\text{\\rm f}}}}^2 } = \\frac{{\\ensuremath{\\left\\| { { { \\ensuremath{\\mathsf{a } } } } } ( \\xls - { \\mathbf{x}}^{(k)})\\right\\|_2}}^2}{{\\ensuremath{\\left\\| { { { \\ensuremath{\\mathsf{a } } } } } \\right\\|_{\\text{\\rm f}}}}^2}.\\end{aligned}\\ ] ] by hypothesis , @xmath148 is in the row space of @xmath3 for any @xmath10 when @xmath129 is ; in addition , the same is true for @xmath135 by the definition of pseudo - inverse  @xcite .",
    "therefore , @xmath278 .",
    "( of theorem  [ thm : rk : inconsistent ] ) as in  @xcite , for any @xmath58}$ ] define the affine hyper - planes : @xmath279 assume for now that at the @xmath10-th iteration of the randomized kaczmarz algorithm applied on @xmath280 , the @xmath4-th row is selected .",
    "note that @xmath158 is the projection of @xmath281 on @xmath282 by the definition of the randomized kaczmarz algorithm on input @xmath161 .",
    "let us denote the projection of @xmath281 on @xmath283 by @xmath148 .",
    "the two affine hyper - planes @xmath284 are _ parallel _ with common normal @xmath5 , so @xmath148 is the projection of @xmath158 on @xmath283 and the minimum distance between @xmath283 and @xmath282 equals @xmath285 .",
    "in addition , @xmath286 since @xmath287 , therefore by orthogonality we get that @xmath288 since @xmath148 is the projection of @xmath281 onto @xmath283 ( that is to say , @xmath148 is a randomized kaczmarz step applied on input @xmath289 where the @xmath4-th row is selected on the @xmath10-th iteration ) and @xmath281 is in the row space of @xmath3 , lemma  [ lem : avg ] tells us that @xmath290 note that for given selected row @xmath4 we have @xmath291 ; by the distribution of selecting the rows of @xmath3 we have that @xmath292 inequality   follows by taking expectation on both sides of equation   and bounding its resulting right hand side using equations   and  . applying inequality   inductively , it follows that @xmath293 where we used that @xmath129 is in the row space of @xmath3 .",
    "the latter sum is bounded above by @xmath294 ."
  ],
  "abstract_text": [
    "<S> we present a randomized iterative algorithm that exponentially converges in expectation to the minimum euclidean norm least squares solution of a given linear system of equations . </S>",
    "<S> the expected number of arithmetic operations required to obtain an estimate of given accuracy is proportional to the square condition number of the system multiplied by the number of non - zeros entries of the input matrix . </S>",
    "<S> the proposed algorithm is an extension of the randomized kaczmarz method that was analyzed by strohmer and vershynin . </S>"
  ]
}