{
  "article_text": [
    "the large hadron collider ( lhc ) is running successfully .",
    "after the next long shutdown the center of mass energy will be raised from 8 to 13 or 14 tev .",
    "this higher center of mass energy will increase the reach for finding new physics .",
    "here we are concerned with supersymmetric extensions of the standard model ( sm ) of particle physics . within the simplest potentially realistic supersymmetric model , the minimal supersymmetric extension of the sm ( mssm ) @xcite",
    ", the 14 tev lhc will increase the mass reach for first generation squarks and gluinos from the current lower bounds , which reach nearly 1.5 tev for equal squark and gluino masses @xcite , to values between 2 and 3 tev @xcite .",
    "this leaves plenty of room for new discoveries .",
    "in particular , the `` natural '' range of parameters of supersymmetric theories will then be probed decisively .    discovering a signal for physics beyond the sm , important as it would be , would certainly not be the end of the lhc physics program .",
    "one would then not only have to ascertain what kind of new physics has been discovered , but also determine the values of the free parameters as accurately as possible . in the context of the mssm , this should help to unravel the mechanism responsible for the breaking of supersymmetry .",
    "there is a large literature on ways to determine the parameters of supersymmetric theories .",
    "most methods start from kinematic features , in particular endpoints or `` edges '' of invariant mass distributions @xcite or kinks in slightly more complicated kinematic distributions @xcite .",
    "these kinematic features directly allow to determine ( differences of ) superparticle masses ; at least at the tree  level , in most cases there is a direct relation between the mass of a superpartner and a weak  scale parameter of the underlying theory . in many cases",
    "the experimental resolution that can be achieved is such that at least one  loop corrections should be included ; e.g.  the difference between pole ( on  shell ) masses , which determine the kinematics , and @xmath12 masses , which are `` fundamental '' free parameters in the supersymmetric les houches accord @xcite , can easily reach several percent for strongly interacting superparticles @xcite .",
    "the derived @xmath13 masses will then depend on many ( pole ) masses .",
    "moreover , in the chargino and neutralino sector , as well as for third generation sfermions , the relation between pole masses and fundamental parameters is complicated by mixing @xcite .",
    "nevertheless the basic kinematic quantities that are used for parameter determination can be determined from a single ( simulated ) experiment . while the step from there to the determination of the basic parameters and their errors may entail many calls of spectrum calculators ,",
    "there is no need to simulate event generation for different sets of parameters , which is usually far more time consuming than the calculation of the spectrum of superparticles .    on the other hand , even in constrained scenarios",
    "purely kinematical determinations of the underlying parameters work well only if sufficiently many events contain two ( or more ) charged leptons ( meaning electrons or muons ) .",
    "kinematic reconstructions based on jets suffer not only from the much poorer energy resolution of jets , but also from larger combinatorial backgrounds ( since the production and decay of strongly interacting superparticles typically leads to events with many jets ) .    in any case",
    ", it is clear that the number of signal events in certain categories contains a lot of information about the underlying physics .",
    "even if kinematic reconstruction works well , it would be wasteful to ignore this information . to mention a well  known example",
    ", the cross section for the pair production of a new color triplet complex scalar boson ( like the stop ) is much smaller than that for spin@xmath14 quarks of the same mass @xcite .",
    "moreover , in constrained supersymmetric scenarios strongly interacting superparticles tend to be heavier than those without strong interactions .",
    "the production of strongly interacting superparticles therefore frequently leads to long `` cascade '' decays @xcite , which can populate many `` topologically different '' final states , i.e.  final states characterized by different numbers ( and charges ) of leptons as well as different numbers ( and flavors ) of jets .",
    "it has been recognized quite early that the relative abundance of these final states contains a great deal of information about the sparticle spectrum @xcite .    however , these early studies mostly focused on distinguishing qualitatively different spectra of superparticles .",
    "information on the total signal rate has only quite recently been included in fits attempting to determine the underlying parameters from ( simulated ) events @xcite .",
    "we are not aware of any study that attempts to determine the values of the underlying parameters using ( mostly ) counting observables , although a recent analysis showed that these observables can be very useful for discriminating between discrete sets of model parameters @xcite .",
    "one major difficulty with this approach is that it requires to generate event samples for many different assumed sets of input parameters .",
    "for example , even in the cmssm , which has only four free parameters , a simple grid scan over all parameters with a step size comparable to or smaller than the anticipated statistical accuracy of the method is prohibitively cpu expensive in most circumstances .",
    "the purpose of this paper is to demonstrate the usefulness of artificial neural networks for the parameter determination of such a new physics theory . largely due to the limitation of our computational resources",
    ", we do this in the framework of the cmssm ; the method should also be useful for other theories , supersymmetric or otherwise .",
    "again for computational simplicity we ignore detector effects , but we work at full hadron level , including initial and final state radiation , hadronization , and the underlying event . similarly , we ignore standard model backgrounds , but we include cuts that should keep them at a manageable level . we consider four benchmark scenarios , all of which lie ( slightly ) beyond current lower bounds on superparticle masses , but have qualitatively different spectra .",
    "we find that @xmath15 of data at @xmath16 are sufficient to determine the common scalar mass parameter @xmath5 and the common gaugino mass parameter @xmath6 to few percent accuracy _ without _ any direct kinematic mass reconstruction . with @xmath17 of data",
    "the neural networks can also determine the trilinear soft breaking parameter @xmath10 and the ratio of vacuum expectation values @xmath9 quite accurately for these benchmark scenarios .",
    "in contrast , in many cases a simple @xmath0 minimization failed to converge , i.e.  it could not reliably determine the parameters and their errors .",
    "the likely reason is that the minimization of @xmath0 is very sensitive to fluctuations in the predictions due to finite monte carlo statistics .    in this paper",
    "we are only interested in the production and decay of superparticles at the lhc , as an example for an extension of the sm containing many new parameters that can hopefully be determined from future lhc data . in our numerical analysis",
    "we will therefore respect the experimental bounds on the masses of superparticles , but we will not try to reproduce the recently discovered ( increasingly ) higgs  like boson @xcite in our cmssm spectra , nor will we try to describe dark matter through thermally produced superparticles .",
    "instead we are using the cmssm as toy model whose parameter space is manageable even without requiring the correct higgs mass and dark matter relic density . obviously imposing these constraints , or other constraints",
    "not directly related to lhc data , would simplify the task of fixing the free parameters . here",
    "we wish to show that data on the production and decay of superparticles at the lhc by themselves can be used for this task , even if mostly counting observables are used .",
    "the remainder of this article is organized as follows . in sec .",
    "[ sec : simulation ] we first introduce the general setting of the simulation .",
    "one important issue is the choice of observables .",
    "an automated reconstruction of the underlying parameters can only succeed if one has sufficiently many observables to be sensitive to all parameters everywhere in parameter space . on the other hand , including too many observables can dilute the statistical power .",
    "we present a set of observables which we showed to be useful for discriminating between different parameter sets for a more general supersymmetric model with 15 parameters @xcite . in the second part of sec .",
    "[ sec : simulation ] we introduce four different benchmark points in the cmssm framework . in sec .",
    "[ sec : strategies ] we discuss both our attempts at parameter reconstruction , first using artificial neural networks and second a @xmath0 minimization .",
    "we explain the general set  up as well as each step of the creation of the neural networks for this specific application .",
    "we also estimate the errors on the cmssm parameters , including their correlations , using different methods that yield consistent results . in the second part of sec .",
    "[ sec : strategies ] the attempted @xmath0 minimization is discussed ; as already mentioned , it does not perform very well .",
    "the results obtained by the artificial neural networks for all four benchmark points are discussed in sec .",
    "[ sec : results ] .",
    "we also compare them to the results from the @xmath0 minimization .",
    "finally , the last section contains a summary and some conclusions .",
    "we simulate future lhc data at a center of mass energy of @xmath1{tev}$ ] .",
    "as mentioned in the introduction , we work in the framework of the cmssm , where the entire spectrum of superparticles and higgs bosons is defined by four continuous parameters and a sign .",
    "the continuous parameters are the common scalar mass parameter @xmath5 , the common gaugino mass @xmath6 , the common trilinear soft breaking parameter @xmath10 and the ratio @xmath9 of vacuum expectation values of the two higgs doublets . as usual ,",
    "@xmath18 and @xmath10 are specified at the scale of grand unification , @xmath19 gev , whereas @xmath9 is given at the electroweak scale .",
    "we fix the sign of the supersymmetric higgsino mass parameter @xmath20 to be positive .",
    "we use softsusy @xcite to compute the cmssm superparticle and higgs boson spectra from the values of the four input parameters . the weak  scale spectrum",
    "is then passed on to susy",
    " hit @xcite , which calculates the branching ratios of all kinematically allowed decays .",
    "knowledge of the superparticle masses and branching ratios is needed for the simulation of the production and decay of pairs of superparticles at the lhc , which is handled by the event generator herwig++ @xcite . in a first step @xmath21",
    "events are simulated in order to determine the total cross section for the production of all superparticles for the given set of input parameters .",
    "next , the appropriate number of events is simulated which corresponds to the assumed integrated luminosity ; we will show results for @xmath22 and @xmath17 .    each simulated event",
    "is assigned to one of twelve mutually exclusive event classes , based on the number , charges and flavors of charged leptons .",
    "in addition , for each event a small number of mostly counting observables is kept , from which we construct our @xmath4 observables .",
    "this is described in more detail in the following subsection .",
    "we do this , first of all , for four benchmark scenarios , which lie in qualitatively different regions of cmssm parameter space , as described in the second subsection . of course , in the attempt to determine the values of the cmssm parameters from the four simulated measurements , the procedure from spectrum calculation to event generation has to be performed for many additional parameter sets , as described in sec .",
    "[ sec : strategies ] .      in this subsection",
    "we summarize our observables , which we introduced in detail in sec .  3 of @xcite .",
    "in particular , the precise definitions of the objects ( isolated charged leptons , hadronically decaying @xmath23 leptons , hadronic jets with or without @xmath24tag ) we use to characterize the events , and the applied cuts , can be found in the appendices of @xcite .",
    "as already noted , we group all accepted events into twelve mutually exclusive classes , which differ by the number , charges and flavors of charged leptons . here only isolated electrons or muons with transverse momentum @xmath25 gev and pseudorapidity @xmath26 are counted .",
    "these classes are :    * @xmath27 : events with no charged leptons * @xmath28 : events with exactly one charged lepton , with negative charge ( in units of the proton charge ) * @xmath29 : events with exactly one charged lepton , with positive charge * @xmath30 : events with exactly two charged leptons , with total charge @xmath31 * @xmath32 : events with exactly two charged leptons , with total charge @xmath33 * @xmath34 : events with exactly two charged leptons , with opposite charge but the same flavor ; i.e.  @xmath35 or @xmath36 * @xmath37 : events with exactly two charged leptons , with opposite charge and different flavor ; i.e.  @xmath38 or @xmath39 * @xmath40 : events with exactly three charged leptons with total charge @xmath41 .",
    "there is an opposite  charged lepton pair with same flavor . for example @xmath42 or",
    "@xmath43 * @xmath44 : events with exactly three charged leptons with total charge @xmath45 .",
    "there is an opposite  charged lepton pair with same flavor . for example @xmath46 or @xmath47 * @xmath48 : events with exactly three charged leptons with total negative charge , i.e.  there are at least two negatively charged leptons .",
    "there is opposite  charged lepton pair with same flavor . for example @xmath49 or @xmath50 * @xmath51 : events with exactly three charged leptons with total positive charge , i.e.  there are at least two positively charged leptons .",
    "there is opposite  charged lepton pair with same flavor . for example @xmath52 or @xmath53 * @xmath54 : events with four or more charged leptons    we distinguish between different charges of leptons since the initial state at the lhc carries charge @xmath33 . in general",
    "the number of events with positively charged leptons can therefore differ from those with negatively charged leptons .",
    "moreover , we distinguish between lepton pairs with opposite charge but the same flavor , which can originate from leptonic neutralino decays , @xmath55 , and all other lepton pairs , which have to come from the decays of two different particles .",
    "this explains why we have two different classes of events with exactly one charged lepton , and four different classes each for events with exactly two and exactly three charged leptons , respectively . in principle",
    "we could also define several different classes of four lepton events .",
    "however , the number of such events is in any case rather small ; further separating these few events into several classes is therefore not very useful .",
    "our first observable is the total number of events after cuts , @xmath56 .",
    "note that the cuts differ for the different event classes , as described in ref.@xcite .",
    "in addition , for each of these twelve classes @xmath57 , the values of seven observables @xmath58 are computed :    * @xmath59 : the number of events @xmath60 contained in the given class @xmath61 divided by the total number of events @xmath56 , i.e.  the fraction of all events contained in a given class * @xmath62 : average number of tagged hadronically decaying @xmath63 of all events within a given class @xmath61 * @xmath64 : average number of tagged hadronically decaying @xmath65 of all events within a given class @xmath61 * @xmath66 : average number of tagged @xmath24jets of all events within a given class @xmath61 * @xmath67 : average number of non@xmath68jets of all events within a given class @xmath61 * @xmath69 : average of the square of the number of non@xmath68jets in the given class contains @xmath70 non@xmath24jets , then @xmath71 .",
    "] of all events within a given class @xmath61 * @xmath72 : average value of @xmath73 of all events within a given class @xmath61 , where @xmath73 is the scalar sum of the transverse momenta of all hard objects , including the missing @xmath74    both @xmath75 and @xmath24jets have to have transverse momentum @xmath76 gev and pseudorapidity @xmath26 .",
    "in addition , a @xmath75jet needs to be isolated , and a @xmath24jet has to contain a @xmath24flavored hadron .",
    "jets satisfying these criteria are tagged with an assumed tagging efficiency of @xmath77{\\%}$ ] . finally , @xmath73 is the scalar sum of the transverse momenta of all hard objects ( jets and charged leptons ) and the absolute value of the missing @xmath74 .",
    "we again refer to ref.@xcite for further details .",
    "three of those observables are different to the ones used in ref.@xcite . the number of events in a given class @xmath61 that contain at least one tagged hadronically decaying @xmath63 divided by the total number of events in this class , @xmath78 , has been replaced by the average number of tagged hadronically decaying @xmath63 of all events within a given class @xmath61 , @xmath79 , and similarly for positively charged @xmath75jets . in the parameter sets considered in @xcite the number of events containing a tagged @xmath23 was rather small and the number of events containing two of those even smaller .",
    "therefore it was sufficient to just count the number of events containing at least one tagged @xmath23 .",
    "now in the case of the cmssm there can be more events with a higher number of @xmath75leptons .",
    "therefore here we switched the observable to preserve more information about the measurement .",
    "the same applies to the observable @xmath80 , which is used instead of @xmath81 .    out of the @xmath82 observables",
    "listed above , one should be discarded .",
    "obviously the fractions of events @xmath83 which belong to a certain class @xmath61 add up to one , because @xmath84 .",
    "we therefore do not include the fraction of events without charged leptons , @xmath85 , among our observables ; note that this does not lead to any loss of information .",
    "we thus end up with @xmath4 observables .    for the calculation of @xmath0 , and also in order to improve the performance of our artificial neural networks",
    ", we need the covariance matrix of all @xmath4 observables .",
    "the variance of the total number of events after cuts , @xmath56 , is @xmath86 the next twelve observables are the fractions of events @xmath83 that belong to each class @xmath61 . as mentioned before they are not independent .",
    "the covariance between the fraction of events in two different classes @xmath61 and @xmath87 is then : @xmath88 the covariance for identical classes ( @xmath89 ) equals the variance .",
    "note that this matrix would be singular if we included all twelve @xmath90 among our observables .",
    "in contrast , @xmath83 and the total number of events @xmath56 are not correlated , i.e. @xmath91 the remaining observables can be written as averages over all events in a given class , @xmath92 with @xmath93 or @xmath94 .",
    "their variances can be calculated directly from the simulated data using the formula @xmath95 of these observables , only @xmath96 and @xmath97 are correlated within a given class : @xmath98 here @xmath99 is also determined directly from the ( simulated ) events .",
    "observables from different classes are not statistically correlated .",
    "we also ignore the possible correlation between @xmath100 and @xmath101 .",
    "the validity of this approximation was checked for the closely related observables @xmath78 and @xmath102 in @xcite and should also be fine here .",
    "we look at four different reference points in the cmssm parameter space each yielding @xmath103 events after cuts for @xmath3{fb^{-1}}$ ] of data :    * @xmath104{gev } $ ] , @xmath105{gev } $ ] , @xmath106 and @xmath107{gev } $ ] * @xmath108{gev } $ ] , @xmath109{gev }    $ ] , @xmath106 and @xmath107{gev } $ ] * @xmath110{gev } $ ] , @xmath111{gev }    $ ] , @xmath106 and @xmath112{gev } $ ] * @xmath113{gev } $ ] , @xmath105{gev } $ ] , @xmath114 and @xmath107{gev } $ ]    all points have a positive higgs(ino ) mass parameter @xmath20 .",
    "the resulting spectra of superparticles and higgs bosons are given in table  [ tab : spec ] .",
    ".cmssm input parameters and selected superparticle and higgs boson masses for our four benchmark points .",
    "all mass parameters are in gev .",
    "note that first and second generation sfermions with the same gauge quantum numbers have identical masses .",
    "moreover , @xmath115 in these scenarios , while @xmath116 , and @xmath117 .",
    "similarly , @xmath118 in all cases , while @xmath119 are about @xmath22 to @xmath120 gev above @xmath121 . finally , in all cases @xmath122 .",
    "[ cols=\"^,^,^,^,^\",options=\"header \" , ]     [ tab : errors ]    this is confirmed by table  [ tab : errors ] , where we list the values of the cmssm parameters reconstructed from our anns fed with the @xmath3{fb^{-1}}$ ] and @xmath8{fb^{-1}}$ ] simulated measurements at the four benchmark points .",
    "the standard deviations and correlation coefficients are calculated with the propagation of uncertainty method as described at the end of sec .",
    "[ sec : error ] . if we divide the final estimate of the standard deviation by the product of the normalized control error of table  [ tab : performance ] and the size of the parameter region spanned by the training sets , we obtain values that cluster around @xmath123 ( @xmath124 ) for the simulated measurements with @xmath3{fb^{-1}}$ ] ( @xmath8{fb^{-1}}$ ] ) of data .",
    "in other words , the final estimate of the statistical uncertainty is approximately proportional to this product .",
    "the main exceptions to this rule occur for benchmark point 2 , where the estimated uncertainties for @xmath5 ( @xmath10 ) are nearly two times bigger than ( less than half as big as ) the value obtained from this simple scaling . a strict scaling",
    "is not expected , since the normalized control error measures the _ average _ performance of the ann against 300 cmssm scenarios in the control set , whereas we are now considering specific benchmark points .",
    "moreover , the control error determines the deviation from the true value , not the estimated size of the uncertainty of the extracted cmssm parameters .",
    "however , table  [ tab : errors ] also shows that the estimated standard deviations reflect the differences to the true values quite well .",
    "this is true in particular for the simulated measurement based on @xmath3{fb^{-1}}$ ] of data , where @xmath125 of the @xmath126 estimated parameter values are less than one estimated standard deviation away from the true value , and the remaining @xmath127 estimates differ from the true values by less than two estimated standard deviations .",
    "another indication for the reliability of the estimated standard deviations is that they decrease approximately by the expected factor @xmath128 when going to the simulated measurement based on @xmath8{fb^{-1}}$ ] of data .",
    "recall that we only include statistical uncertainties , which should of course decrease proportional to the inverse square root of the accumulated luminosity .",
    "however , upon closer expectation some systematic deviation from the expected reduction of the estimated uncertainties by a factor of @xmath129 become apparent .",
    "first , when averaging over all four benchmark points the estimated errors on @xmath130 and @xmath9 actually decrease by factors of @xmath131 and @xmath132 .",
    "this indicates that the uncertainties for the @xmath8{fb^{-1}}$ ] `` measurements '' might be somewhat underestimated .",
    "in fact , table  [ tab : errors ] shows that in this case @xmath22 out of @xmath126 reconstructed parameter values are more than one estimated standard deviation away from their true values ; @xmath127 of the reconstructed values are more than two standard deviations off , and one ann output ( @xmath5 for benchmark point 3 ) differs from its true value by more than three estimated standard deviations .",
    "the likely explanation for this is that the predictions in the training and control sets were also `` only '' based on @xmath8{fb^{-1}}$ ] of simulated data , i.e.  they had the same uncertainty due to finite monte carlo statistics as our simulated measurements .",
    "this `` theoretical uncertainty '' is not included in our estimates of the uncertainty of the ann outputs .",
    "statistical fluctuations in the training and/or control sets might also lead to systematic off  sets of the ann outputs relative to the true values .",
    "this might explain the relatively poor performance of the anns for benchmark point 3 when fed the simulated @xmath8{fb^{-1}}$ ] measurement , where all four output values are more than one estimated standard deviation off , and three of the four values are more than two estimated standard deviations off . in order to check this , we simulated the @xmath8{fb^{-1}}$ ] measurement of benchmark point 3 two more times with different seeds in herwig++ . for both additional versions",
    "the estimated value of @xmath5 was less than one standard deviation away from the true value .",
    "therefore , the more than three standard deviations in table [ tab : errors ] seems to be a rather extreme statistical fluctuation . on the other hand",
    ", for all three version of the measurement , @xmath10 differed between two and three standard deviations from the true value .",
    "the estimated value was always smaller than the true value @xmath133{gev}$ ] .",
    "this slight tendency to lower values might originate from the fact that the true value lies near the upper bound @xmath134 enforced in the selection of the training sets .",
    "in contrast , the error estimates for the four values of @xmath10 only decrease by a factor of @xmath135 . for the reasons listed above",
    ", the errors for the @xmath8{fb^{-1}}$ ] `` measurements '' might still be slightly under  estimated . however , in the case at hand the errors for the @xmath3{fb^{-1}}$ ] `` measurements '' are also somewhat suspect .",
    "the reason is that in three cases the estimated `` @xmath136 '' interval for @xmath10 extends beyond the range covered in the training and control sets , which satisfy @xmath137 .",
    "this means that the anns are forced to at least partially extrapolate , rather than interpolate , when estimating these errors .",
    "recall also that values of @xmath138 significantly larger than @xmath139 often lead to problems with the calculation of the spectrum .    in spite of these caveats ,",
    "we consider the overall performance of our anns to be quite satisfactory . already with @xmath3{fb^{-1}}$ ] of simulated data",
    "the gaugino mass parameter @xmath6 can be determined with a relative accuracy of @xmath140 to @xmath141 .",
    "if @xmath5 is large enough to significantly affect the squark masses ( benchmark points 2 and 3 ) , it can be determined with a relative accuracy of about @xmath142 ; if @xmath5 is very small , as in point 1 , this relative accuracy deteriorates .",
    "meaningful determinations of @xmath10 and @xmath9 will need more data . for the simulated measurements with @xmath8{fb^{-1}}$ ] , the estimated uncertainty on @xmath9 varies between @xmath143 for point 4 , which had a large input value of @xmath9 , and @xmath144 for point 3 , which , as we had seen before , has the largest normalized control error for this quantity .",
    "the estimated error on @xmath10 is roughly @xmath145 to @xmath146 of the input value of @xmath5 .",
    "finally , table  [ tab : errors ] also lists the correlation coefficients .",
    "we see that most correlations are quite weak .",
    "the true correlation coefficients should be independent of the luminosity , but our estimates of these coefficients should , and do , fluctuate when the ( simulated ) data set is increased .",
    "we nevertheless observe consistently negative correlations between the extracted values of @xmath5 and @xmath6 for benchmarks points 2 , 3 and 4 .",
    "this can be explained from the observation that increasing either @xmath6 or @xmath5 will increase the masses of strongly interacting superparticles , which will lead to a reduction of the total event rate , and to an increase of the average @xmath73 values . to some extent",
    "an increase in @xmath5 can therefore be compensated by a reduction of @xmath6 , and vice versa .",
    "this correlation is essentially absent for benchmark point 1 , which has @xmath147 so that even the squark masses are essentially independent of @xmath5 .",
    "similarly , the mild positive correlation between @xmath10 and @xmath6 can be explained from the observation that the coefficients @xmath148 in eq.([equ : mi ] ) are negative , while the @xmath149 are positive .",
    "the rg effect on the scalar masses of increasing @xmath10 can therefore be compensated by increasing @xmath6 .    as already noted ,",
    "the standard deviations and correlation coefficients listed in table  [ tab : errors ] have been computed using error propagation .",
    "we conclude this section by comparing these with the results obtained by feeding gaussian distributed variants of the original `` measurements '' into our anns , as described in the first part of sec .",
    "[ sec : error ] .",
    "we do this for benchmark point 4 ; results for the other benchmark points are similar .. ]    fig .",
    "[ fig:1d_10 ] shows the distribution of the output of the four anns for the simulated measurement with @xmath3{fb^{-1}}$ ] of data .",
    "we note first of all that the binned distributions of ann outputs do indeed look rather gaussian already for this smaller data sample  much more so than the corresponding distributions obtained via @xmath0 minimization , see fig .",
    "[ fig : fehler4 ] .",
    "moreover , in case of @xmath150 and @xmath9 both the mean values of the gaussians ( the @xmath151 values given in the inserts in the figure ) , which are the final parameters estimates of the ann derived in this manner , and their widths ( the @xmath152 values ) , which are the final estimates for the uncertainty of these parameters , agree quite well with the results listed in table  [ tab : errors ] . in case of the mean values , the two methods yield estimates that agree to about @xmath153 estimated standard deviations .",
    "the two estimates for the standard deviations differ slightly more .",
    "this is not unexpected , since the standard deviation estimated via error propagation itself has an error , which is not negligible for this small ( simulated ) data set .",
    "recall also that we set all observables to zero that have been obtained from fewer than @xmath22 events .",
    "benchmark point 4 has @xmath154 events in class 9 and @xmath155 events in class 4 . using the method of error propagation ,",
    "the observables @xmath156 are thus ignored , while @xmath157 are included . however , quite a few of the gaussian distributed variants of this measurement will have @xmath158 events in class 9 and/or @xmath159 events in class 4 .",
    "these variants will thus feed _ qualitatively _ different input in the anns than the original simulated measurement .",
    "both the statistical error of the estimated standard deviation , and the systematic difference between the ann inputs from different variants of the same simulated measurement , are expected to decrease with increasing luminosity .",
    "for example , for an integrated luminosity of @xmath8{fb^{-1}}$ ] , benchmark point 4 has @xmath160 events in class 9 , which is about @xmath161 standard deviations away from the lower bound of @xmath162 events now required for the inclusion of observables @xmath156 ; we can therefore be quite certain that none of the up to @xmath163 variants of the simulated measurements has sufficiently many events of class 9 for the @xmath156 to be included .",
    "we therefore expect the differences between the two methods for determining the final ann output , and its estimated uncertainty , to agree better for higher luminosity .",
    "this is confirmed by fig .",
    "[ fig:1d_500 ] .",
    "in particular , the two estimates of the uncertainties now agree to better than @xmath164 in all cases .",
    "recall that we used @xmath165 gaussian distributed variants of ann inputs for each cmssm training parameter set . without this trick ,",
    "the distributions of the ann outputs for @xmath9 and @xmath10 would look much less gaussian , in particular for the smaller luminosity of @xmath3{fb^{-1}}$ ] .",
    "moreover , the estimated uncertainties on the extracted cmssm parameters would be @xmath166 larger .",
    "the anns therefore clearly profit from the information on the relative errors of our observables .",
    "recall that these additional training sets were obtained without additional event generation . on the other hand , the time needed for training the anns scales linearly with the size of the training sets .    finally , fig .",
    "[ fig:2d_500 ] shows that gaussian fits to two  dimensional distributions of ann outputs yield almost the same estimates of the standard deviations as the one  dimensional fits or the method of error propagation .",
    "these two  dimensional fits also allow to determine the correlation coefficients ( the @xmath167 values given in the inserts in the figures ) .",
    "again we observe quite close agreement with the results derived from gaussian error propagation .",
    "above we found some evidence that the errors from the @xmath8{fb^{-1}}$ ] `` measurements '' are underestimated , since they do not agree the `` theory '' error from the finite mc statistics used in the training and control sets . since figs .",
    "[ fig:1d_500 ] and [ fig:2d_500 ] have been obtained with fixed anns , only varying the input ( i.e. , the results of the `` measurements '' ) , they do not reflect this `` theory error '' , either .",
    "it is nevertheless reassuring that two methods which are computationally independent yield very similar results .",
    "in this paper we investigated methods to determine the values of underlying parameters from ( simulated ) measurements at the lhc , with heavy emphasis on counting observables . mostly for reasons of computational simplicity , we did this for the cmssm where only four free parameters need to be determined ; the sign of @xmath20 was fixed to be positive .    evidently the choice of observables is crucial .",
    "here we used the same observables as in ref.@xcite , where we had shown that they perform well when trying to distinguish different ( generalized ) mssm parameter sets using a @xmath0 criterion .",
    "we also used the same cuts as in ref.@xcite , even though the sparticle mass scale of the benchmark points we used for the present analysis , which lie just outside the currently excluded region , is significantly higher than in our previous study .",
    "moreover , in this proof  of  concept analysis we ignored standard model backgrounds as well as statistical uncertainties .",
    "our main result is that artificial neural networks ( anns ) can be used for the determination of model parameters , including statistically reliable estimates of their errors .",
    "in contrast , an in principle straightforward @xmath0 minimization did not yield reliable results , probably because we do not have the computational resources required for the calculation of theoretical predictions for sufficiently many different sets of model parameters with sufficiently small monte carlo uncertainty .",
    "moreover , the estimated errors on @xmath5 and @xmath6 from the @xmath0 minimization were about two to three times larger than those obtained from the anns .",
    "we thus conclude that anns can yield better and more reliable results with less computational effort than a @xmath0 minimization .",
    "of course , the training of the anns was also affected by the finite mc statistics used for deriving our theoretical predictions .",
    "however , here the main requirement is that the error due to finite mc statistics should be ( much ) smaller than the statistical error of the ( actual or simulated ) measurement .",
    "in contrast , any `` smart '' algorithm attempting to minimize a @xmath0 will need reliable information on systematic changes of @xmath0 when the cmssm parameters are changed by relatively small amounts .",
    "the uncertainty on @xmath0 due to mc statistics therefore needs to be ( much ) smaller than the ( typically quite small ) change of @xmath0 induced by this small variation of the parameters .    mathematically , an ann is a function mapping ( typically a rather large number of ) input values into one or more output value(s ) . in the case at hand , the inputs are the 84 observables described in sec .  [",
    "sec : observables ] .",
    "these observables have quite different statistical uncertainties .",
    "this should affect the weights given to these inputs .",
    "we took this into account in two ways .",
    "first , we simply set all observables to zero that have been obtained from fewer than @xmath140 event per fb@xmath168 of ( simulated ) data .",
    "since we assume an integrated luminosity of at least @xmath3{fb^{-1}}$ ] , this effectively removes very `` noisy '' observables .",
    "second , for each training set of cmssm parameters , we generated @xmath165 variants where the observables were drawn from multi  dimensional gaussians , whose central values and covariances were taken from the original simulation . for each set of cmssm parameters that we simulated for the training sets , the anns were therefore confronted with @xmath165 slightly different sets of inputs ( observables ) yielding the same outputs ( cmssm parameters ) .",
    "the anns could thus learn the relative accuracy between the various observables , which , at least for gaussian statistics , should be independent of the integrated luminosity .",
    "the trained anns could thus be used on ( simulated ) data sets of any luminosity , as long as the statistical uncertainty of this `` measurement '' is ( much ) larger than the monte carlo uncertainty of the predictions in the training and control sets .",
    "since the training of the anns is independent of actual data , it can be done before the measurement .",
    "once actual measurements exist , the ann results for the cmssm parameters could then be obtained with negligible computational effort . in contrast",
    ", a @xmath0 minimization has to be ( re)done for each measurement .",
    "as expected the cmssm parameters @xmath5 ( scalar mass parameter ) and @xmath6 ( gaugino mass parameter ) could be determined relativeley well for all four benchmark points already with an integrated luminosity of @xmath3{fb^{-1}}$ ] . in the best cases these",
    "could be determined to @xmath169{\\%}$ ] for @xmath5 and @xmath170{\\%}$ ] for @xmath6 . with this luminosity ,",
    "leading to around @xmath171 events after cuts , @xmath9 and @xmath10 could at best be determined very roughly .",
    "on the other hand , with a luminosity of @xmath8{fb^{-1}}$ ] , @xmath6 can be determined with statistical uncertainty well below @xmath7 .",
    "the statistical error on @xmath5 then amounts to @xmath172 to @xmath3{gev}$ ] for our four benchmark points . for three of the points",
    ", @xmath9 could be determined with an error of @xmath173 or better . finally , the error on @xmath10 was about @xmath145 to @xmath146 of the input value of @xmath5 .",
    "we also computed the full covariance matrix , and found that most correlations are quite weak .",
    "these results were obtained with two different methods . in one method ,",
    "the central values were obtained by simply feeding the simulated measurements into the trained anns , and the uncertainties and correlation coefficients were computed using gaussian error propagation .",
    "alternatively we generated numerous gaussian distributed variants of the original simulated measurements , and fitted gaussian distributions to the outputs of the anns .",
    "the results of these two methods agreed quite well .",
    "one disadvantage of using anns is that they do not automatically give a measure for the goodness of the fit ( at most only an indication by the shapes of the gaussian output distributions ) : even if nature is described by a completely different theory , the anns will output some values of the free parameters of the ( wrong ) theory on which they have been trained when confronted with actual data .",
    "one will have to simulate the assumed theory with the values of the free parameters determined by the anns in order to determine the quality of the fit , e.g.  by computing the @xmath0 .",
    "however , the numerical effort required for this is trivial compared to the effort required for the determination of the values of the free parameters .",
    "our results can be improved in a number of ways .",
    "first of all , we ignored all information on the higgs sector . in the context of the mssm , knowledge of the mass of one of the cp  even neutral higgs bosons will greatly reduce the allowed parameter space .",
    "one can also try to tag top quarks @xcite or higgs bosons @xcite in the final state using subjet techniques , or to devise dedicated sets of cuts that attempt to isolate specific decay chains . moreover , kinematic features ( edges or kinks ) could be included .",
    "all this would increase the number of inputs fed into the anns , and could thus increase their ability to determine the underlying parameters .",
    "conversely it might be possible to remove some of the observables from the list of input parameters without significant loss of information .",
    "since our algorithm should automatically assign low weights to observables with little discriminating power , this would presumably not improve the performance of the anns very much , but it could reduce the computational effort . similarly , the number of gaussian distributed variants generated for each training set of cmssm parameters could perhaps be reduced without degrading the performance ; the time needed to train the anns is essentially proportional to this number .",
    "finally , we did not consider anns with two ( or more ) layers of hidden neurons ; this more complicated architecture might allow to reduce the total number of hidden neurons , and perhaps also the total number of weights that need to be determined , which would speed up the training process .",
    "however , before trying to further optimize the performance of the anns one should make the set  up more realistic , by including standard model backgrounds as well as systematic uncertainties .",
    "the cuts could then be optimized for each benchmark point separately , as e.g.  done in @xcite .",
    "this would not increase the computational effort , since we already use different anns for the different benchmark points ( or regions ) .",
    "systematic uncertainties could be introduced as in @xcite . moreover ,",
    "if the method is applied to supersymmetric scenarios , one should consider benchmark points that have a higgs boson of the correct mass and coupling , in agreement with recent data @xcite . in the framework of the cmssm",
    "this is known to push the squark mass scale to quite large values @xcite ; this will presumably greatly reduce the possibility to extract @xmath5 .",
    "if scalar masses are not required to unify , first and second generation scalars could still have masses similar to those in our benchmark scenarios .",
    "alternatively , one could introduce additional higgs superfields to increase the mass of the lightest cp  even higgs boson , as e.g.  in the nmssm @xcite .",
    "the purpose of this paper was to show that artificial neural networks do have the potential to determine quantitatively the values of the parameters of the underlying theory , and the corresponding ( statistical ) uncertainties .",
    "further , more realistic studies are thus well worth the effort .",
    "nb wishes to thank the `` bonn - cologne graduate school of physics and astronomy '' for financial support .",
    "this work was partially supported by the bmbf  theorieverbund and by the helmholtz alliance `` physics at the terascale '' .",
    "[ sec : calculationofweights ]    in this appendix we discuss the calculation of the weights of a neural network with @xmath174 input neurons , @xmath175 hidden neurons and one output neuron ; this describes the anns we constructed in sec .",
    "[ sec : neuralnetwork ] .",
    "since there is only one output neuron , we suppress the index @xmath176 on the corresponding weights in eq.([equ : outputneuroninput ] ) .",
    "we begin by combining all weights in one vector @xmath177 .",
    "the first @xmath178 entries are weights in the first weight layer , and the remaining @xmath175 entries are from the second weight layer : @xmath179 in total the weight vector thus has @xmath180 entries .",
    "the @xmath181 are related to the @xmath182 via @xmath183 with @xmath184 means the smallest integer that is larger than or equal to the real number @xmath185 ; e.g.  @xmath186 . ] and @xmath187 $ ] .",
    "similarly , for @xmath188 we have @xmath189 with @xmath190 .        as mentioned in sec .",
    "[ sec : initialization ] the first weight vector @xmath193 is chosen randomly from a gaussian distribution . in the first improvement",
    ", @xmath177 is changed in direction @xmath194 equal to the negative gradient @xmath195 .",
    "the first gradient vector @xmath196 is calculated using the function @xmath197 describing the error the ann makes in reproducing the training set .",
    "we wish to minimize this function of the weights .",
    "since the location of the minimum is independent of the normalization , we use the simple definition @xmath198 as in sec .",
    "[ sec : neuralnetwork ] @xmath56 is the number of training sets ; in our applications , @xmath199 .",
    "again as in sec .",
    "[ sec : neuralnetwork ] , @xmath200 is the output that the ann computes from the normalized input @xmath201 of training set @xmath202 , while the correct ( inversely ) normalized cmssm output of the training set is labeled @xmath203 ; the normalization of the input and output has been described in sec .",
    "[ sec : normalization ] .",
    "the first @xmath178 entries of the gradient vector can be computed from eqs.([equ : errorfunction ] ) , ( [ equ : hiddenneuroninput ] ) and ( [ equ : outputneuroninput ] ) : @xmath204 the remaining @xmath175 entries are : @xmath205 here , @xmath206 is the hidden neuron processing function , @xmath207 , and @xmath208 as in eq.(3.1 ) .",
    "moreover , @xmath209 in eq.([ea1 ] ) , with @xmath210 , and @xmath211 in eq.([ea2 ] ) are abbreviations for : @xmath212 where @xmath213 stands for the derivative of @xmath206 , i.e.  @xmath214 , and @xmath215      the following steps of the calculation steps are repeated until one is satisfied that the ( global ) minimum of the normalized control error ( [ equ : normalizederror ] ) has been reached . the new weight vector is calculated in step @xmath216 from the expression @xmath217 the calculation of @xmath218 has already been described in eqs.([ea1 ] ) to ( [ equ : delta2 ] ) .",
    "the coefficient @xmath219 can be computed from the hessian matrix @xmath220 : @xmath221 the explicit calculation of the hessian matrix is shown at the end of this appendix . with the new weights the normalized control error of eq.([equ : normalizederror ] ) can be calculated and depending on the stopping criterion the learning process might be terminated .",
    "if the stopping criterion is not fulfilled the new gradient vector @xmath222 would be calculated , just as in eqs.([ea1 ] ) to ( [ equ : delta2 ] ) .",
    "next , the new search direction is computed from @xmath223 where the coefficient @xmath224 is also calculated from the hessian matrix : @xmath225 now the next step @xmath226 can be taken , starting with the calculation of the new weights from eq.([equ : newweights ] ) .",
    "the main numerical effort in the training process is the repeated calculation of the hessian matrix .",
    "this is a symmetric @xmath227 matrix , i.e.  its dimension is determined by the number of hidden neurons .",
    "it is given by the matrix of second derivatives of the error function @xmath197 with respect to the weights : @xmath228 its numerical value will in general be different for each step during the training process . for our architecture , with one layer of hidden neurons , we can distinguish three different cases : both weights are from the first layer ; both weights are from the second layer ; or one weight is from the first and the other from the second weight layer :    * both weights are from the first weight layer , i.e.  @xmath229 : @xmath230 \\ , x^\\ell_j \\\\         & = & \\sum\\limits_{\\ell = 1}^{n } \\left [ w_a^{(2 ) } \\ , w_b^{(2 ) } \\ ,               h^\\prime(z^\\ell_a ) \\ , h^\\prime(z^\\ell_b ) + \\delta_{ba } \\ ,               \\delta^{(2)\\ell } \\ , w_b^{(2 ) } \\ , h^{\\prime\\prime}(z^\\ell_b ) \\right ]             \\ , x^\\ell_i \\ , x^\\ell_j \\,.\\end{aligned}\\ ] ] here we have used eqs.([equ : errorfunction ] ) , ( [ equ : delta1 ] ) , ( [ equ : delta2 ] ) , ( [ equ : hiddenneuroninput ] ) and ( [ equ : outputneuroninput ] ) .",
    "the index pairs @xmath231 and @xmath232 are computed from the indices @xmath233 and @xmath234 as described following eq.([ea0 ] ) above .",
    "the second derivative of the hidden neuron processing function is @xmath235 * both weights are from the second weight layer , i.e.  @xmath236 : @xmath237 where @xmath238 . * one weight each from the first and the second weight layer , i.e.  @xmath239 and @xmath240 or vice versa : @xmath241 \\ , x^\\ell_i \\\\         & = & \\sum\\limits_{\\ell = 1}^{n } \\left ( h(z^\\ell_a ) \\ ,",
    "w_b^{(2 ) } +          \\delta_{ba } \\ , \\delta^{(2)\\ell } \\right ) \\ , h^\\prime(z^\\ell_b ) \\ ,        x^\\ell_i \\end{aligned}\\ ] ]      for introductions to supersymmetry , see m. drees , r.m .",
    "godbole and p. roy , `` theory and phenomenology of sparticles '' , world scientific , singapore ( 2004 ) ; h.a .",
    "baer and x.r .",
    "tata , `` weak scale supersymmetry : from superfields to scattering events '' , cambridge university press ( 2006 ) .",
    "atlas collab .",
    ", g. aad et al . , _ phys .",
    "* d85 * ( 2012 ) 112006 [ arxiv:1203.6193 [ hep - ex ] ] ; cms collab .",
    ", s. chatrchyan et al .",
    ", _ jhep _ * 1210 * ( 2012 ) 018 [ arxiv:1207.1798 [ hep - ex ] ; atlas collab . , g. aad et al . , _ phys .",
    "_ * d86 * ( 2012 ) 092002 [ arxiv:1208.4688 [ hep - ex ] ] ; atlas collab . ,",
    "g. aad et al .",
    "phys . j. _",
    "* c72 * ( 2012 ) 2215 , [ arxiv:1210.1314 [ hep - ex ] ] ; cms collab .",
    ", s. chatrchyan et al .",
    "_ * d87 * ( 2013 ) 052006 [ arxiv:1211.3143 [ hep - ex ] ] ; cms collab . , s. chatrchyan et al .",
    ", arxiv:1212.6961 [ hep - ex ] ; cms collab . , s. chatrchyan et al . , _ eur .",
    "phys . j. _ * c73 * ( 2013 ) 2404 [ arxiv:1212.6428 [ hep - ex ] ] .",
    "i. hinchliffe , f.e .",
    "paige , m.d .",
    "shapiro , j. soderqvist and w. yao , _ phys .",
    "_ * d55 * , 5520 ( 1997 ) [ hep - ph/9610544 ] ; h. bachacou , i. hinchliffe and f.e .",
    "paige , _ phys .",
    "rev . _ * d62 * , 015009 ( 2000 ) [ hep - ph/9907518 ] ; i. hinchliffe and f.e .",
    "paige , _ phys .",
    "rev . _ * d61 * , 095011 ( 2000 ) [ hep - ph/9907519 ] ; b.c .",
    "allanach , c.g .",
    "lester , m.a .",
    "parker and b.r .",
    "webber , _ jhep _ * 0009 * , 004 ( 2000 ) [ hep - ph/0007009 ] ; m. drees et al .",
    ", _ phys . rev .",
    "_ * d63 * , 035008 ( 2001 ) [ hep - ph/0007202 ] ; j. hisano , k. kawagoe and m.m .",
    "nojiri , _ phys .",
    "rev . _ * d68 * , 035007 ( 2003 ) [ hep - ph/0304214 ] ; k. kawagoe , m.m .",
    "nojiri and g. polesello , _ phys .",
    "rev . _ * d71 * , 035008 ( 2005 ) [ hep - ph/0410160 ] ; g.g .",
    "ross and m. serna , _ phys .",
    "lett . _ * b665 * , 212 ( 2008 ) [ arxiv:0712.0943 [ hep - ph ] ] ; m.m .",
    "nojiri , g. polesello and d. tovey , _ jhep _ * 0805 * , 014 ( 2008 ) [ arxiv:0712.2718 [ hep - ph ] ] ; n.  kersting , phys . rev .",
    "* d79 * ( 2009 ) 095018 [ arxiv:0901.2765 [ hep - ph ] ] ; d.  costanzo and d.r .",
    "tovey , _ jhep _ * 0904 * ( 2009 ) 084 [ arxiv:0902.2331 [ hep - ph ] ] ; m.  burns , k.t .",
    "matchev and m.  park , _ jhep _ * 0905 * ( 2009 ) 094 [ arxiv:0903.4371 [ hep - ph ] ] ; h .- c .",
    "cheng , j.f .",
    "gunion , z.  han and b.  mcelrath , phys . rev .",
    "* d80 * ( 2009 ) 035020 [ arxiv:0905.1344 [ hep - ph ] ] ; k.t .",
    "matchev , f.  moortgat , l.  pape and m.  park , _ jhep _ * 0908 * ( 2009 ) 104 [ arxiv:0906.2417 [ hep - ph ] ] ; b.  webber , _ jhep _ * 0909 * ( 2009 ) 124 [ arxiv:0907.5307 [ hep - ph ] ] ; k.t .",
    "matchev , f.  moortgat , l.  pape and m.  park , phys .",
    "* d82 * ( 2010 ) 077701 [ arxiv:0909.4300 [ hep - ph ] ] ; v.  barger , y.  gao , a.  lessa and x.  tata , _ phys .",
    "* d83 * ( 2011 ) 095013 [ arxiv:1103.0018 [ hep - ph ] ] ; h .- c .  cheng and j.  gu ,",
    "_ jhep _ * 1110 * ( 2011 ) 094 [ arxiv:1109.3471 [ hep - ph ] ] ; b.  dutta , t.  kamon , a.  krislock , k.  sinha and k.  wang , _ phys .",
    "_ * d85 * ( 2012 ) 115007 [ arxiv:1112.3966 [ hep - ph ] ] ; w.s .",
    "cho , d. kim , k.t .",
    "matchev and m. park , arxiv:1206.1546 [ hep - ph ] ; n. pietsch , j. reuter , k. sakurai and d. wiesler , _ jhep _ * 1207 * ( 2012 ) 148 [ arxiv:1206.2146 [ hep - ph ] ] .",
    "lester and d.j .",
    "summers , _ phys .",
    "lett . _ * b463 * , 99 ( 1999 ) [ hep - ph/9906349 ] ; c. lester and a. barr , _ jhep _ * 0712 * , 102 ( 2007 ) [ arxiv:0708.1028 [ hep - ph ] ] ; b. gripaios , _ jhep _ * 0802 * , 053 ( 2008 ) [ arxiv:0709.2740 [ hep - ph ] ] ; a.j .",
    "barr , b. gripaios and c.g .",
    "lester , _ jhep _ * 0802 * , 014 ( 2008 ) [ arxiv:0711.4008 [ hep - ph ] ] ; w.s .",
    "cho , k. choi , y.g .",
    "kim and c.b .",
    "park , _ phys .",
    "lett . _ * 100 * , 171801 ( 2008 ) [ arxiv:0709.0288 [ hep - ph ] ] , and _ jhep _ * 0802 * , 035 ( 2008 ) [ arxiv:0711.4526 [ hep - ph ] ] ; m.m .",
    "nojiri , y. shimizu , s. okada and k. kawagoe , _ jhep _ * 0806 * , 035 ( 2008 ) [ arxiv:0802.2412 [ hep - ph ] ] ; d.r .",
    "tovey , _ jhep _ * 0804 * , 034 ( 2008 ) [ arxiv:0802.2879 [ hep - ph ] ] ; a.j .",
    "barr , g.g .",
    "ross and m. serna , _ phys .",
    "_ * d78 * 056006 ( 2008 ) [ arxiv:0806.3224 [ hep - ph ] ] ; m.m .",
    "nojiri , k. sakurai , y. shimizu and m. takeuchi , _ jhep _ * 0810 * , 100 ( 2008 ) [ arxiv:0808.1094 [ hep - ph ] ] ; h.  -c .",
    "cheng and z.  han , jhep * 0812 * ( 2008 ) 063 [ arxiv:0810.5178 [ hep - ph ] ] ; m. burns , k. kong , k.t . matchev and m. park ,",
    "_ jhep _ * 0810 * , 081 ( 2008 ) [ arxiv:0808.2472 [ hep - ph ] ] , and [ arxiv:0810.5576 [ hep - ph ] ] ; a.  j.  barr , a.  pinder and m.  serna , phys",
    "* d79 * ( 2009 ) 074005 [ arxiv:0811.2138 [ hep - ph ] ] ; t.  han , i .-",
    "kim and j.  song , phys .",
    "* b693 * ( 2010 ) 575 [ arxiv:0906.5009 [ hep - ph ] ] ; a.j .",
    "barr , b.  gripaios and c.g .",
    "lester , _ jhep _ * 0911 * ( 2009 ) 096 [ arxiv:0908.3779 [ hep - ph ] ] ; g.  polesello and d.r .",
    "tovey , _ jhep _ * 1003 * ( 2010 ) 030 [ arxiv:0910.0174 [ hep - ph ] ] ; i.  -w .",
    "kim , phys .",
    "rev . lett .",
    "* 104 * ( 2010 ) 081601 [ arxiv:0910.1149 [ hep - ph ] ] ; k.t .  matchev and m.  park , phys . rev",
    "* 107 * ( 2011 ) 061801 [ arxiv:0910.1584 [ hep - ph ] ] ; p.  konar , k.  kong , k.t .",
    "matchev and m.  park , _ jhep _ * 1004 * ( 2010 ) 086 [ arxiv:0911.4126 [ hep - ph ] ] ; t.  cohen , e.  kuflik and k.m .",
    "zurek , _ jhep _ * 1011 * ( 2010 ) 008 [ arxiv:1003.2204 [ hep - ph ] ] ; c.g .",
    "lester , _ jhep _ * 1105 * ( 2011 ) 076 [ arxiv:1103.5682 [ hep - ph ] ] ; a.j .",
    "barr et al . , _ phys .",
    "* d84 * ( 2011 ) 095031 [ arxiv:1105.2977 [ hep - ph ] ] ; k.  choi , d.  guadagnoli and c.  b.  park , _ jhep _ * 1111 * ( 2011 ) 117 [ arxiv:1109.2201 [ hep - ph ] ] ; p.  baringer , k.  kong , m.  mccaskey and d.  noonan , _ jhep _ * 1110 * ( 2011 ) 101 [ arxiv:1109.1563 [ hep - ph ] ] ; d.  curtin , _ phys .",
    "rev . _ * d85 * ( 2012 ) 075004 [ arxiv:1112.1095 [ hep - ph ] ] ; t. han , i .-",
    "kim and j. song , _ phys .",
    "* d87 * ( 2013 ) 035003 [ arxiv:1206.5633 [ hep - ph ] ] and _ phys .",
    "* d87 * ( 2013 ) 035004 [ arxiv:1206.5641 [ hep - ph ] ] ; m.  e. cabrera and j.  a. casas , arxiv:1207.0435 [ hep - ph ] .      s.p .",
    "martin and m.t .",
    "vaughn , _ phys .",
    "lett . _ * b318 * ( 1993 ) 331 [ hep - ph/9308222 ] ; d.  m. pierce , j.  a. bagger , k.  t. matchev and r .- j .",
    "zhang , _ nucl .",
    "* b491 * ( 1997 ) 3 [ hep - ph/9606211 ] ; s.  p. martin , _ phys .",
    "* d74 * ( 2006 ) 075009 [ hep - ph/0608026 ] .",
    "m. drees , w. hollik and q. xu , _ jhep _ * 0702 * ( 2007 ) 032 [ hep - ph/0610267 ] ; r. horsky , m. krmer , a. mck and p.  m. zerwas , _ phys .",
    "* d78 * ( 2008 ) 035004 [ e - print : arxiv:0803.2603 [ hep - ph ] ] ; w. hollik , j.  m. lindert and d. pagani , arxiv:1207.1071 [ hep - ph ] and arxiv:1303.0186 [ hep - ph ] .",
    "h.  baer , x.  tata and j.  woodside , _ phys .",
    "_  * d45 * , 142 ( 1992 ) ; h.  baer , m.  drees , c.  kao , m.  m.  nojiri and x.  tata , _ phys .  rev . _   * d50 * , 2148 ( 1994 ) [ hep - ph/9403307 ] ; d.  feldman , z.  liu and p.  nath , _ phys .  rev .  lett . _  * 99 * , 251802 ( 2007 ) , erratum - ibid . *",
    "100 * , 069902 ( 2008 ) [ arxiv:0707.1873 [ hep - ph ] ] , and _ jhep _ * 0804 * , 054 ( 2008 ) [ arxiv:0802.4085 [ hep - ph ] ] ; m.  drees , j.m .",
    "kim and e .- k .",
    "park , phys .",
    "* d82 * ( 2010 ) 095005 [ arxiv:1006.2100 [ hep - ph ] ] .",
    "lester , m.a .",
    "parker and m.j .",
    "white , 2 , _ jhep _ * 0601 * ( 2006 ) 080 [ hep - ph/0508143 ] ; h.k .",
    "dreiner , m.  krmer , j.m .",
    "lindert and b.  oleary , _ jhep _ * 1004 * ( 2010 ) 109 [ arxiv:1003.2648 [ hep - ph ] ] ; j.a .",
    "conley , h.k .",
    "dreiner l.  glaser , m.  krmer and j.  tattersall , _ jhep _ * 1203 * ( 2012 ) 042 [ arxiv:1110.1287 [ hep - ph ] ] .",
    "kaplan , k. rehermann , m.d .",
    "schwartz and b. tweedie , _ phys .",
    "_ * 101 * ( 2008 ) 142001 [ arxiv:0806.0848 [ hep - ph ] ] ; l.g .",
    "almeida , s.j .",
    "lee , g. perez , i. sung and j. virzi , _ phys .",
    "* d79 * ( 2009 ) 074012 [ arxiv:0810.0934 [ hep - ph ] ] ; t. plehn , m. spannowsky , m. takeuchi and d. zerwas , _ jhep _ * 1010 * ( 2010 ) 078 [ arxiv:1006.2833 ] ; p. bandyopadhyay and b. bhattacherjee , _ phys .",
    "* d84 * ( 2011 ) 035020 [ arxiv:1012.5289 [ hep - ph ] ] ; a. hook , m. jankowiak and j.g .",
    "wacker , _ jhep _ * 1204 * ( 2012 ) 007 [ arxiv:1102.1012 [ hep - ph ] ] ; v. barger and p. huang , _ phys .",
    "* b708 * ( 2012 ) 296 [ arxiv:1102.3183 [ hep - ph ] ] ; j. thaler and k. van tilburg , _ jhep _ * 1202 * ( 2012 ) 093 [ arxiv:1108.2701 [ hep - ph ] ] ; t. plehn , m. spannowsky and m. takeuchi , _ phys .",
    "* d85 * ( 2012 ) 034029 [ arxiv:1111.5034 [ hep - ph ] ] ; b. bhattacherjee , s.k .",
    "mandal and m.m .",
    "nojiri , _ jhep _ * 1303 * ( 2013 ) 105 [ arxiv:1211.7261 [ hep - ph ] ] ; m.r .",
    "buckley , t. plehn and m. takeuchi , arxiv:1302.6238 [ hep - ph ] ; c. chen , _ phys .",
    "* d87 * ( 2013 ) 074007 [ arxiv:1303.3521 [ hep - ph ] ] .",
    "butterworth , a.r .",
    "davison , m. rubin and g.p .",
    "salam , _ phys .",
    "* 100 * ( 2008 ) 242001",
    "[ arxiv:0802.2470 [ hep - ph ] ] ; t. plehn , g.p . salam and m. spannowsky , _ phys .",
    "_ * 104 * ( 2010 ) 111801 [ arxiv:0910.5472 [ hep - ph ] ] ; d.e . soper and m. spannowsky , _ jhep _ * 1008 * ( 2010 ) 029 [ arxiv:1005.0417 [ hep - ph ] ] ; g.d .",
    "kribs , a. martin , t.s .",
    "roy and m. spannowsky , _ phys .",
    "* d81 * ( 2010 ) 111501 [ arxiv:0912.4731 [ hep - ph ] ] , and _ phys .",
    "rev . _ * d82 * ( 2010 ) 095012 [ arxiv:1006.1656 [ hep - ph ] ] .",
    "a. arbey , m. battaglia , a. djouadi , f. mahmoudi and j. quevillon , _ phys .",
    "* b708 * ( 2012 ) 162 [ arxiv:1112.3028 [ hep - ph ] ] ; a. arbey , m. battaglia , a. djouadi and f. mahmoudi , _ jhep _ * 1209 * ( 2012 ) 107 [ arxiv:1207.1348 [ hep - ph ] ] ; o. buchmller et al .",
    "phys . j. _",
    "* c72 * ( 2012 ) 2020 [ arxiv:1112.3564 [ hep - ph ] ] ; j.l .",
    "feng , p. kant , s. profumo and d. sanford , arxiv:1306.2318 [ hep - ph ] ."
  ],
  "abstract_text": [
    "<S> in most ( weakly interacting ) extensions of the standard model the relation mapping the parameter values onto experimentally measurable quantities can be computed ( with some uncertainties ) , but the inverse relation is usually not known . in this paper </S>",
    "<S> we demonstrate the ability of artificial neural networks to find this unknown relation , by determining the unknown parameters of the constrained minimal supersymmetric extension of the standard model ( cmssm ) from quantities that can be measured at the lhc . </S>",
    "<S> we expect that the method works also for many other new physics models . </S>",
    "<S> we compare its performance with the results of a straightforward @xmath0 minimization . </S>",
    "<S> we simulate lhc signals at a center of mass energy of @xmath1{tev}$ ] at the hadron level . in this proof  of  </S>",
    "<S> concept study we do not explicitly simulate standard model backgrounds , but apply cuts that have been shown to enhance the signal  to  background ratio . </S>",
    "<S> we analyze four different benchmark points that lie just beyond current lower limits on superparticle masses , each of which leads to around @xmath2 events after cuts for an integrated luminosity of @xmath3{fb^{-1}}$ ] . </S>",
    "<S> we use up to @xmath4 observables , most of which are counting observables ; we do not attempt to directly reconstruct ( differences of ) masses from kinematic edges or kinks of distributions . </S>",
    "<S> we nevertheless find that @xmath5 and @xmath6 can be determined reliably , with errors as small as @xmath7 in some cases . with @xmath8{fb^{-1}}$ ] of data @xmath9 as well as @xmath10 can also be determined quite accurately . for comparable computational effort the @xmath0 minimization yielded much worse results .    </S>",
    "<S> july 2013    @xmath11_physikalisches institut and bethe center for theoretical physics , universitt bonn , + nuallee 12 , d53115 bonn , germany _ </S>"
  ]
}