{
  "article_text": [
    "in quantum field theory ( qft ) , the analytic structure of a correlation or green function is tied to the physical interpretation of the propagating degree of freedom .",
    "hereby , the analytic structure in the complex plane spanned by analytic continuation of the square of the external momentum is considered .",
    "( nb : we work throughout in euclidean momentum space , _ i.e. _ , we consider all integrals after a wick rotation has been performed . ) for example , a two - point function of a massive scalar particle features a single pole in the complex plane . in momentum space",
    "this pole occurs in the timelike momentum region at @xmath1 , with @xmath2 being the external momentum and @xmath3 the mass of the particle .",
    "furthermore , if there are more than just one particle making up the correlator , a branch cut appears starting at a threshold @xmath4 .",
    "also the occurrence of bound states among the particles forming the correlator is evident within the correlator s analytic structure , since then additional poles exists below the two - particle threshold in this case .",
    "also the property of positivity of a green function is encoded in its analytic structure .",
    "( more precisely , in the euclidean case , the analytic structure determines whether the property of reflection positivity of the correlator s schwinger function is fulfilled . )",
    "positivity violating green functions do not possess a klln - lehmann representation @xcite .",
    "their negative norm contributions do not allow for a probabilistic interpretation as demanded by a quantum theory .",
    "positivity is a necessary condition for a certain state to be part of the physical spectrum of asymptotic states . correspondingly , the investigation of the analytic structure has been subject of many preceding studies , see _",
    "e.g. _ , refs .",
    "@xcite and references therein .",
    "the main reason for the development of this code is an investigation of exactly this kind @xcite .",
    "there , the field - strength tensor of pure yang - mills ( ym ) theory is used to construct the correlator @xmath5 where @xmath6 is the corresponding ( euclidean ) momentum space operator whose analytic structure is to be investigated , and @xmath7 is the number of space - time dimensions .",
    "here we have already exploited the fact that due to poincar invariance of ym theory @xmath6 depends only on the length of the four - vector @xmath2 , _ i.e. _ , on @xmath8 .",
    "the ym field - strength tensor is given by @xmath9 and the square entering the correlator reads ( using einstein s sum convention ) @xmath10 ym theory accounts for gauge field dynamics only , thus only gluonic degrees of freedom are considered .",
    "the gauge fields entering the correlator ( [ 1 ] ) might form a bound state , since the non - abelian character of ym - theory induces self - interactions among the gluons .",
    "such bound states are called glueballs ( see , _ e.g. _ , ref .",
    "@xcite ) . in a ( hypothetical ) exact calculation",
    "they will lead to poles in the expression ( [ 1 ] ) . since gluon propagators of different kinds are used as an input in ref .",
    "@xcite , we developed this code which performs the investigation of the analytic structure numerically .",
    "note that such integral expressions can not be solved in general with conventional methods .",
    "this article is intended to provide a step  by  step tutorial for performing such an investigation numerically , using the power of parallelism provided by graphics processing units .",
    "the code has been developed following the ` fortran90 ` standard and has been extended to gpus by using cuda fortran , provided by the portland group @xcite . since each evaluation point in the complex plane can be treated on its own , the problem is perfectly suitable for a gpu treatment .",
    "this article is organized as follows : sect .",
    "[ formulation ] provides the guideline how to extract the analytic structure of a correlator numerically , while sect .",
    "[ cuda ] presents a short introduction to gpu computing using cuda @xcite to establish the terminology .",
    "the numerical implementation of the procedure is described in sect .",
    "[ numerics ] .",
    "a worked example which can be solved analytically serves as a test case in sect .",
    "[ test ] , where we follow and detail the procedure given in sect .  [ formulation ] to reproduce the exact results numerically .",
    "we conclude in section [ conclusions ] .",
    "let us assume we have the momentum space operator @xmath6 corresponding to a certain two - point function in four - dimensional euclidean space as a starting point .",
    "note that the procedure can be applied to arbitrary dimensions by trivial modifications , but let us restrict to the physical four dimensions for simplicity .",
    "the generic structure of such an operator expressed through an integral over the internal momentum is @xmath11 where @xmath12 is the corresponding integrand which is a function of the squares of the external and internal momenta ( @xmath8 and @xmath13 , respectively ) , as well as of the scalar product between the external and the internal momentum .",
    "the aim is to find the analytic structure of @xmath6 in the complex @xmath8-plane numerically . in the following",
    "we provide the steps that one has to carry out to achieve this goal .",
    "all one has to provide to follow this procedure is an operator expressed in the form as denoted in eq .",
    "( [ 4 ] ) .",
    "the steps presented below are then used in the worked example in sect .",
    "steps which are labeled with the attribute ( a ) are to be performed analytical , while steps carrying the attribute ( n ) are numerical steps .",
    "one step carries the attribute",
    "( a , n ) because one can choose to work it out either analytical or numerically . in the worked example we show both possibilities .    *",
    "* step 1 , ( a ) : express ( [ 4 ] ) in hyperspherical coordinates * + for a subsequent numerical treatment it is convenient to transform the integral in eq .",
    "( [ 4 ] ) into hyperspherical coordinates : @xmath14 applying another change of variables by introducing @xmath15 as well as relabeling @xmath16 after the transformation , we arrive at @xmath17 rewriting the integrand of ( [ 4 ] ) in the new variables we see that the integrand depends on @xmath18 and @xmath19 only , @xmath20 thus we can integrate @xmath21 and @xmath22 trivially : @xmath23 * * step 2 , ( a ) : regularization ( if applicable ) * + in four dimension an integral like expression ( [ 4 ] ) typically diverges logarithmically .",
    "if this is the case one has to regularize the integral .",
    "this step can be skipped if the integral is already finite .",
    "here we use the bphz - procedure @xcite to obtain a finite expression .",
    "the so - called superficial degree of divergence ( sdd ) can be determined by counting the powers of the inner momenta that appear in @xmath24 , as well as the powers of the inner momenta present due to the integral measure .",
    "let the sdd @xmath25 .",
    "then we can render the integral finite by replacing the integrand @xmath26 with @xmath27 , which is obtained by applying a taylor - subtraction operator @xmath28 up to the order of @xmath29 to the initial integrand , @xmath30 where @xmath28 is given by @xmath31_{x=0}.\\ ] ] performing this step , we arrive at @xmath32 where upper integration limit @xmath33 , introduced purely for numerical reasons , assumes some large finite value .",
    "note that the bphz procedure ensures cut - off independence , _",
    "i.e. , _ the limit @xmath34 does not alter the value of the integral . * * step 3 , ( a , n ) : analytic continuation * + as it has been pointed out in ref .",
    "@xcite , the @xmath19-integral induces a branch cut in the complex @xmath35-plane .",
    "this happens when one integrates over the ( integrable ) singularities of the @xmath19-integrand . for certain values of @xmath36",
    ", the branch cut in the @xmath35-plane might obstruct the contour of the @xmath35-integration along the positive real axis , as it is used in equation ( [ 14 ] ) . if the integrand of the angular ( @xmath19 ) integral is a well behaved function , and if there are no poles of the remaining integrand for the @xmath35-integral on the positive real @xmath35-axis , then there is nothing to do and this step can be skipped . usually , the region in the complex @xmath36-plane for which the induced branch cut does not interfere with the @xmath35-contour along the positive real axis is rather small . to avoid troubles , one has to perform the angular integration",
    "( either analytical or numerically ) and look at the results in the complex @xmath35-plane .",
    "this can also be achieved by finding the complex @xmath35-values for which the @xmath19-integrand for a given complex @xmath36 becomes singular . in the usual case of the integrand being a fraction ,",
    "this simply reduces to putting the denominator polynomial to zero and solve this equation with respect to ( complex ) @xmath35 for a certain ( complex ) value of @xmath36 . +",
    "as soon as this troublesome regions in the complex @xmath36-plane have been identified , one has to deform the @xmath35-contour in the complex @xmath35-plane accordingly , avoiding the branch - cut present due to the angular integration , as well as poles which might be present due to the @xmath35-integrand itself .",
    "the most accurate form of the integral corresponding to @xmath37 is @xmath38 with @xmath39 being the deformed contour connecting @xmath40 with @xmath33 , while avoiding the cut and the poles . *",
    "* step 4 , ( n ) : preparation * + now we have done all the analytical work involved in this investigation .",
    "the first ( numerical ) step is to determine a @xmath41 matrix @xmath42 which holds the @xmath36 values at which we want to evaluate @xmath37 as given by equation ( [ 15 ] ) , with the contour adjusted as necessary ( see * step 3 * ) .",
    "@xmath43 denotes the number of points along the real axis of @xmath36 , and @xmath44 is the number of points along the imaginary axis of @xmath36 .",
    "the limits for the complex @xmath36-values have to be chosen as desired .",
    "the region of interest in the complex @xmath36-plane is then discretized and mapped to a matrix @xmath42 .",
    "this step is already performed on the gpu ( see section [ numerics ] for the implementation of the numerics ) . * * step 5 , ( n ) : evaluation of the integrals * + this is the final step in this procedure .",
    "it is also performed on the gpu , using its parallelism capabilities . for each entry of the matrix @xmath42",
    "we have to evaluate equation ( [ 15 ] ) , which we do by using non - adaptive quadrature rules for approximating the values of the integrals . on the gpu",
    "we perform these integrations in parallel for a @xmath45 sub - matrix of @xmath42 , where the maximal size of the sub - matrix depends on the architecture of the gpu .",
    "the result is stored to a file , the subsequent graphics processing of the data is then performed by using ` mathematica ` @xcite .",
    "this concludes our generic discussion of the procedure .",
    "the numerical steps ( * step 3 , step 4 * and * step 5 * ) are discussed in detail in sect.[numerics ] . the whole procedure ( * step 1 * - * step 5 * )",
    "is demonstrated in great detail by the worked example in sect .",
    "in this section we briefly review some features of cuda in order to make this article self - contained .",
    "we only describe such features we will need in the following section , for a more detailed description the reader is referred to ref .",
    "@xcite .",
    "compute unified device architecture ( cuda ) is a general purpose parallel computing architecture provided by nvidia @xcite .",
    "cuda - enabled devices can be addressed using c ( with some extensions ) as a programming language , but there are also other high - level languages available . this study has been performed by implementing the code using cuda fortran , provided by pgi @xcite .",
    "cuda fortran is a small set of extensions to fortran that allows one to use the computing resources of cuda - enabled devices .",
    "a brief review of the realm of cuda is in order before we discuss the actual implementation of the steps described in the previous section .",
    "in contrast to cpus , gpus are devices specialized in heavy - duty parallel calculations , as they are demanded by their primary purpose , i.e. , 3d rendering .",
    "a gpu features several simd multiprocessors .",
    "the cuda programming model is organized as follows .",
    "the code controlling the calculation runs as a sequential code on a cpu called the _",
    "host_. the task of the host part is to control the flow of data to and from the gpu , which is called the _ device_.",
    "each cuda program consist thus of a host part and a device part . a function that is executed on the gpu",
    "is called a _",
    "kernel_. cuda possesses a 3-level thread hierarchy .",
    "the lowest level of the model is a _ thread_.",
    "the threads are executed on a scalable array of multithreaded _ streaming processors _ ( sms ) .",
    "a multiprocessor uses the _ single - instruction multiple - thread _ ( simt ) architecture to perform the concurrent execution of the threads .",
    "the multiprocessor partitions the threads in groups of 32 threads , called _ warps _ , which are then scheduled and executed .",
    "one common instruction is executed within a warp at a given time.the next element in the hierarchy is called a _",
    "block_. each block contains a certain number of threads , which should be a multiple of the warp - size for an efficient usage of the hardware .",
    "the maximum number of threads per block is limited and determined by the hardware in use .",
    "the highest level in the hierarchy is called the _",
    "grid_. the grid consists of blocks and is assigned to a device . on the device ,",
    "the blocks within the grid are distributed among the sms , where subsets of the blocks , the warps , are scheduled .",
    "the threads of the warp are then executed on the cores of the sm .",
    "blocks and grids can be either 1 , 2 or 3-dimensional , which also depends on the hardware .",
    "each thread within the hierarchy possesses a unique identification number , the thread - id , which can be calculated from the position of the block in the grid and the position of the thread in the block . besides the thread hierarchy",
    ", there exists a memory hierarchy on the device .",
    "the _ global device memory _ can be accessed by each thread , where each thread can read and write on this memory .",
    "however , it is not a small latency memory . in the so - called fermi architecture ,",
    "each sm possesses a on - chip memory of 64 kb .",
    "one can either configure the on - chip memory to use 48 kb for shared memory with 16 kb l1 cache or to use 16 kb for shared memory with 48 kb l1 cache .",
    "fermi furthermore features a 768 kb l2 cache which connects all sms .",
    "a cuda program is usually of the following form .",
    "parts running on the host are labeled with the attribute ( h ) , while device parts are labeled with ( d ) .    *",
    "* initialization ( h ) * the program starts with a host part , where data is allocated in the host memory , as well as in the device memory .",
    "the grid- and blocksize and dimensions are determined , variables are initialized and prepared for the parallel execution on the device .",
    "data is transferred from the host to the device . * * kernel execution ( d ) * one or more kernels are executed on the device by a kernel call of the host .",
    "each kernel has to be called together with its grid- and blocksize , which also includes the information about their dimensionality .",
    "the blocks of the grid of the kernel are executed on the sms of the device . * * finalization ( h ) * once the device executions have finished , the result , which still resides on the device , has to be transferred back to the host where it can be stored to file .",
    "finalizing steps such as memory deallocation are performed and the program closes .",
    "this rather brief discussion covers only the very basics of the programing model , but should provide enough understanding to follow the discussion in the next section .",
    "on the basis of the short introduction to cuda outlined in the previous section , we can now introduce the actual implementation of the numerical steps of section [ formulation ] .",
    "the centerpiece of course is the integration , which we perform by numerical quadrature .",
    "in particular we use gauss - legendre quadrature @xcite for the radial ( @xmath35 ) integral , and tanh - sinh quadrature ( also known as double exponential quadrature ) @xcite for the angular ( @xmath19 ) integral .",
    "we also implemented gauss - chebyshev quadratures @xcite ( by using both , polynomials of the first and second kind , which we use as convenient depending on the dimension the problem is located in ) to have a check on the angular integration results .",
    "the code is organized as follows , where again we make use of the labels ( h ) for code running on the host and ( d ) for device code respectively .    * * initialization ( h ) * + several preparation steps are necessary . *",
    "* * allocation * + allocation on both , the host and the device is performed for the weights and nodes needed for the quadratures .",
    "since it is necessary to integrate along contours which are running close to singular structures in the complex plane , we have to use a huge number of nodes to get a smooth picture in the end .",
    "another option would have been to use adaptive strategies , but they tend to get stuck near singularities and are more complicated to implement .",
    "we achieved good results with this procedure . * * * preparation * + the calculation of the weights and nodes that are to be stored in the arrays of size @xmath46 for gauss - legendre and @xmath47 for tanh - sinh quadrature respectively , are calculated on the host . in well - behaved areas it is by far sufficient to use @xmath48 and @xmath49 .",
    "however , in regions where the contour comes close to the singular structures living in the complex @xmath35-plane , one only obtains good results with much more nodes . note furthermore , that while we only need one array for the angular nodes , we need @xmath29 arrays for the radial nodes , where @xmath29 is the number of the sub - contours needed to form the contour @xmath39 that connects @xmath40 with @xmath33 in the complex @xmath35-plane . depending on the parametrization , we have @xmath50 up to @xmath51 in our worked example .",
    "besides the arrays for the weights and nodes , we need two @xmath52 matrices of the data - type complex . the matrix @xmath42 will contain the complex @xmath36 values at which we intend to perform the calculation , the matrix @xmath43 is used to store the result in the end .",
    "furthermore , the grid and block dimension is set . * * * transfer * + the data that has been calculated on the host is transferred to the device global memory . * * kernel 1 ( d ) : discretize the region of evaluation * + this kernel corresponds to * step 4 * of section [ formulation ] .",
    "this kernel is used to fill the matrix @xmath42 with the complex values of the region in the complex @xmath36-plane where @xmath37 is to be evaluated .",
    "we used square matrices with @xmath53 points .",
    "usually , @xmath53 points are absolutely sufficient to produce a reasonable picture of the area , for some purposes we also used @xmath54 and @xmath55 points .",
    "we usually restrict the real and imaginary part of @xmath36 to range between @xmath56 .",
    "the kernel is called with blocks of @xmath57 in size , the grid in case of the @xmath53 matrix is then formed by @xmath58 blocks .",
    "each thread , which is described by a unique tuple @xmath59 writes the complex number of @xmath36 to the matrix element @xmath60 , where it determines the complex number by calculating a homogeneous distribution of the @xmath52 points within the given range .",
    "the result is a matrix which holds a discretized version of the region of interest in the complex @xmath36-plane . * * kernel 2 ( d ) : evaluation * + this kernel corresponds to * step 5 * of section [ formulation ] .",
    "it is the center part of the calculation .",
    "the block and grid sizes are the same as for kernel  1 .",
    "each thread within a block is assigned to exactly one value of the @xmath42-matrix and calculates the double integral of equation ( [ 15 ] ) , where it has to choose the contour that has been assigned to the area the point of evaluation @xmath61 belongs to . in our worked example we had to distinguish 4 areas in the complex @xmath36-plane , so we had to use 4 different contours .",
    "the decision which contour is the right one can be made by a simple if - then - else statement .",
    "the result produced by each thread corresponding to a certain value of @xmath36 is then stored in the result matrix @xmath43 .",
    "once this kernel has finished its execution , the host takes over again . * * finalization * + the host transfers the result stored in the matrix @xmath43 from the device back to the host and produces a stream that stores the result , together with the complex @xmath36 value in a file .",
    "the file - name is generated dynamically and consists of several parameters to identify the run .",
    "the whole procedure will be detailed in the worked example in the following section .",
    "the procedure as proposed in the step  by  step recipe of sect.[formulation ] is here detailed using as example the correlator given in eq .",
    "( 32 ) of ref .",
    "there exists an exact solution for this correlator which makes this example a perfect test - case for the numerics .",
    "the correlator is given by @xmath62 in ref .",
    "@xcite it has been shown that in four dimensions for @xmath63 the integral in ( [ 16 ] ) can be done analytically for the regularized expression yielding @xmath64 our numerical result will be compared to it , however , it is useful to rescale ( [ 17 ] ) to get rid of the prefactor : @xmath65 the numerical task starts with eq .",
    "( [ 16 ] ) and continues with the steps outlined in sect .",
    "[ formulation ] .",
    "we investigate @xmath66 eq .  ( [ 16 ] ) @xmath67 $ ] in four dimensions with @xmath68 .",
    "step 1 demands to switch to hyperspherical coordinates , which gives according to eq .",
    "( [ 11 ] ) @xmath69      we determine the superficial degree of divergence of the integral by investigating eq .",
    "( [ 16 ] ) . in four dimensions we have four powers of the inner momentum @xmath70 in the numerator due to the integral measure .",
    "the denominator also produces a highest power of 4 in the momentum @xmath70 .",
    "thus the superficial degree of divergence is 0 , which means that the integral diverges logarithmically . following the procedure , we use eq .",
    "( [ 12 ] ) with the definition ( [ 13 ] ) to get the regularized integrand , which is in our case @xmath71 performing the cancellations in the prefactor of ( [ 19 ] ) , as well as plugging eq .",
    "( [ 20 ] ) into ( [ 14 ] ) , the following equation remains , @xmath72      in this step we have to investigate the analytic structure arising in the complex @xmath35-plane due to the analytic continuation of @xmath73 appearing in the integrand of the angular integral .",
    "the integral is @xmath74 clearly , term @xmath75 induces two poles in the complex @xmath35-plane , appearing at @xmath76 .",
    "the angular integral @xmath77 produces a branch cut in the complex @xmath35 plane once the outer momentum @xmath73 has been continued to a complex value .",
    "the branch cut at a given value of @xmath36 in the complex @xmath35-plane can be found analytically by finding the poles of the integrand of @xmath77 . in order to obtain a parametrization",
    ", we take the denominator polynomial prior to the change of variables , _",
    "i.e. , _ we solve @xmath78 with respect to k. the two ( redundant ) solutions can be written as @xmath79 where we named the complex function @xmath80 instead of @xmath70 to stress that we use it as a parametrization for the branch cut . since we solved eq .",
    "( [ 23 ] ) with respect to @xmath70 for convenience , the branch cut in the complex @xmath81 plane is then given by @xmath82 with the help of eq .",
    "( [ 25 ] ) , we can plot the branch cut in the complex @xmath35-plane for a given value of @xmath83 .",
    "we also performed this investigation numerically by simply solving integral @xmath77 for a given value of @xmath83 and for complex @xmath35 with ` mathematica ` @xcite , as well as by using cuda - fortran and a separate kernel to obtain and verify the information .",
    "fig.[fig1 ] shows the complex @xmath35-plane for some values of @xmath83 .",
    "-plane after the angular integration for four different values of @xmath73 .",
    "the blue curves given by eq .",
    "( [ 25 ] ) coincide with the rough numerical estimate for the angular integration which is expressed by the density - plot in the background . at each point in complex @xmath35-space",
    "the branch cut looks different .",
    "the original integration contour is shown by the arrow . only in the case shown in the upper left corner we can keep the original contour . in all other cases",
    "we are blocked by the branch cut .",
    "the green dots represent the poles present due to term @xmath75 in eq .",
    "( [ 22]).,width=491 ]    in fact , there are not many points in the complex @xmath36-plane where the branch cut does not interfere with the original integration contour along the positive real @xmath35-axis .",
    "we calculated the region where no obstruction occurs numerically by using a kernel designed for this purpose .",
    "[ fig2 ] shows the regions in the complex @xmath36-plane where the original contour remains unharmed .",
    "-points within the region of evaluation where the branch cut does not obstruct the integration contour along the positive real @xmath35-axis . in all other regions we have to deform the contour in an adequate way.,width=377 ]    since the branch cut changes its orientation , size and shape we have to divide the complex @xmath36-plane into regions within we can apply the same contour .",
    "fig.[fig3 ] shows the regions we have chosen .",
    "-plane into 5 regions where we will apply different deformations of the integration contour . in region 1",
    "we can keep the original contour along the positive real @xmath35-axis .",
    "furthermore , in the regions 2 and 5 we can apply the same contour , such that we are left with 3 different parametrizations covering the regions 2 , 3 , 4 and 5 , and the original contour which we can keep in region 1.,width=377 ]    there is nothing to do in region 1 , thus we proceed by investigating the other regions . in the following",
    "we show the parametrizations of the deformed contours for the regions 2 , 3 , 4 and 5 .",
    "the figs .",
    "[ fig4 ] , [ fig5 ] and [ fig6 ] show the contours obtained by these parametrizations .    * * region 2 and 5 * * * @xmath84 + @xmath85 * * @xmath86 + @xmath87 * * region 3 * * * @xmath88 + @xmath89 * * @xmath90 + @xmath91 * * @xmath92 + @xmath93 * * @xmath94 + @xmath95 * * @xmath96 + @xmath97 * * region 4 * * * @xmath98 + @xmath99 * * @xmath100 + @xmath101 * * @xmath102 + @xmath103 * * @xmath104 + @xmath105 * * @xmath106 + @xmath107                  in this step we have to choose the size of the matrix to which the complex @xmath36-plane is mapped to .",
    "in this example we used @xmath108 for the size of the matrix @xmath42 , and we are interested in the area @xmath109 , @xmath110 .",
    "the matrix is filled with @xmath53 points which are homogeneously distributed over the region we restricted this consideration to . the cuda kernel achieving this",
    "is called with a block size of @xmath57 threads and with @xmath58 blocks forming the grid .",
    "each thread in the grid , which can be uniquely addressed by a tuple of numbers @xmath59 , operates only on the matrix element @xmath60 .",
    "the indices @xmath111 are running from 1 to 128 .",
    "thus , for example the thread identified by the tuple @xmath112 operates only on the matrix entry @xmath113 .",
    "this is the last step of our program .",
    "the kernel corresponding to this step is launched with the same parameters as the one in the step before , that is we still use @xmath57 blocks organized in a @xmath58 grid .",
    "each thread operates only on the matrix entry it is assigned to and performs the integrations according to its position in complex @xmath36-space .",
    "the decision which contour a certain thread has to choose is made by a simple if - then - else construction .",
    "finally we can compare the results obtained by numerical integration compared to the exact solution given by eq .",
    "( [ 18 ] ) .",
    "the plots are shown in the figs .",
    "[ fig7 ] and [ fig8 ] .",
    "this concludes our worked example .    ) after regularization and rescaling .",
    "the numerical data ( blue dots ) perfectly agrees with the exact solution provided by the surface - plot.,width=453 ]    ) after regularization and rescaling .",
    "the numerical data ( blue dots ) perfectly agrees with the exact solution provided by the surface - plot.,width=453 ]      we compared the total execution time of a cheap consumer graphics card and two high performance graphics cards to the time needed by the code to run on one core of a modern cpu .",
    "the speedup results are presented in table [ tab1 ] .",
    ".comparison of running time and speed for a certain set of parameters .",
    "we used a modern cpu and compared against three different gpus . [ cols=\"^,^,^,^,^\",options=\"header \" , ]",
    "to summarize , we presented the numerical determination of the analytic structure of correlation functions given by momentum space integrals exploiting the parallel computing capability of a gpu .",
    "this rather complicated numerical analysis can then be performed within minutes .",
    "we provided a step  by  step description for the procedure required to obtain a numerical solution , and we presented a worked example and compared to its exact solution .",
    "the independence of the points in the complex plane makes such an investigation a perfect candidate for gpu treatment , which pays off even more with increasing matrix - size and/or increasing number of nodes .",
    "note that there may be still potential in speeding up both , the procedure and the code , which we have not done so far .",
    "the development of this procedure has been the first step in an ongoing investigation @xcite of the analytic structure of correlators with different expressions as input .",
    "hereby several different integrals of the form as given in eq .",
    "( [ 15 ] ) have been evaluated .",
    "the here presented example served as decisive test for the achieved accuracy .",
    "given the general features of the problem we are confident that the algorithm presented here will be valuable also for other investigations .",
    "we thank m.q . huber for helpful discussions . + furthermore , we acknowledge support by the _ research core area `` modeling and simulation '' _ of the university of graz .",
    "p.  maris , phys .",
    "d * 52 * ( 1995 ) 6087 [ hep - ph/9508323 ] .",
    "r.  alkofer , w.  detmold , c.  s.  fischer , p.  maris , phys .",
    "* d70 * ( 2004 ) 014014 [ hep - ph/0309077 ] ; nucl .  phys",
    ".  proc .",
    "* 141 * ( 2005 ) 122 [ arxiv : hep - ph/0309078 ] .",
    "v.  mathieu , n.  kochelev and v.  vento , int .",
    "j.  mod .",
    "e * 18 * ( 2009 ) 1 [ arxiv:0810.4453 [ hep - ph ] ] . the portland group inc .",
    ", `` cuda - fortran , programming guide and reference , release 2011 '' , ` http://www.pgroup.com/resources/cudafortran.htm `"
  ],
  "abstract_text": [
    "<S> graphics processing units ( gpus ) are employed for a numerical determination of the analytic structure of two - point correlation functions of quantum field theories . </S>",
    "<S> these functions are represented through integrals in @xmath0-dimensional euclidean momentum space . </S>",
    "<S> such integrals can in general not be solved analytically , and therefore one has to rely on numerical procedures to extract their analytic structures if needed . after describing the general outline of the corresponding algorithm </S>",
    "<S> we demonstrate the procedure by providing a completely worked - out example in four dimensions for which an exact solution exists . </S>",
    "<S> we resolve the analytic structure by highly parallel evaluation of the correlation functions momentum space integral in the complex plane . </S>",
    "<S> the ( logarithmically ) divergent integral is regularized by applying a bphz - like taylor subtraction to the integrand . </S>",
    "<S> we find perfect agreement with the exact solution . </S>",
    "<S> the fact that each point in the complex plane does not need any information from other points makes this a perfect candidate for gpu treatment . a significant gain in speed as compared to sequential execution </S>",
    "<S> is obtained . </S>",
    "<S> we also provide typical running times on several gpus .    analytic structure , green s function , complex integration , branch cut , gpu , cuda fortran </S>"
  ]
}