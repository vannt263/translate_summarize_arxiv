{
  "article_text": [
    "this paper provides an econometric analysis for the factor models when the factors depend on several observed explanatory variables .",
    "consider the following factor model : @xmath0 where the latent factors @xmath1 can be partially explained by a vector of observables @xmath2 : @xmath3 for some function @xmath4 , a nonparametric function . here",
    "@xmath5 is the outcome ; @xmath6 is an @xmath7 matrix of unknown loadings ; @xmath8 denotes the idiosyncratic vector . in ( [ e1.2 ] ) , @xmath9 is interpreted as the factors components that can not be explained by the observables , whose covariance @xmath10 may or may not be close to zero .",
    "when @xmath10 is close to zero , the true factors are mostly explained by the observables @xmath2 ; the latter is then interpreted as the good proxy of the true factors .",
    "factor models are found to be extremely useful for summarizing the information of a large number of economic variables . in economic applications , it is often the case that common factors are associated with some time - dependent observables . in financial factor models for instance ,",
    "the factors are explained by a few observable proxies , such as the fama - french factors @xcite . in diffusion index forecasts , @xcite and @xcite identified seven factors that represent production outcomes , the housing variables , stock markets , etc .",
    "the identified factors are strongly associated with several directly measurable economic variables such as consumption - wealth variable , financial ratios ( ratios of price to dividends or earnings ) , and term spread .    to incorporate the explanatory power of @xmath2",
    ", we propose a _",
    "robust proxy - regressed _",
    "method to estimate the factors and loadings .",
    "the method consists of two major steps :    \\(i ) ( robustly ) regress @xmath11 on the observables @xmath12 and obtain fitted value @xmath13 ;    \\(ii ) take the principal components of @xmath14 to estimate the loadings and factors .",
    "+ since @xmath2 is uncorrelated with @xmath15 , the regression step effectively removes the effects of idiosyncratic components . as a result ,",
    "the loadings and @xmath16 function can be identified ( up to a rotation ) under any given @xmath17 , as apposed to being identified asymptotically in traditional studies ( as @xmath18 , e.g. , @xcite ) .",
    "in addition , when @xmath9 is near zero ( @xmath2 nearly fully explains @xmath1 , which is a testable statement ) , the estimated @xmath19 can be directly used as factor estimators , whose rate of convergence is nearly @xmath20 , and is faster than the usual estimates when @xmath21 .",
    "this shows it is possible to estimate the factors well when the dimension is not very large relative to the sample size .",
    "the proposed estimation procedure is robust to possibly heavy - tailed errors .",
    "it is well known that returns of many macroeconomic and financial time series are heavy - tailed and skewed . indeed , by examining the kurtosis of the macroeconomic dataset",
    "commonly used for diffusion index forecast @xcite , we find that most of these variables have heavier tails than the @xmath22-distribution with degrees of freedom five .",
    "most of the existing methods ( pca , mle , etc . ) , however , are known to be sensitive to the tail distribution . in particular , when the number of cross - sectional units is large , these estimation methods require the tail distribution of the errors to exponentially decay in order to achieve good statistical properties @xcite .",
    "the sensitivity to the tail distributions , therefore , limits the application scopes of these estimators .",
    "we employ @xcite s robust m - estimation with a diverging regularity parameters in step ( i ) of our estimation .",
    "this demonstrates another advantage of our estimation procedure : the regression step projects the original data to the space of @xmath2 , whose distribution is no longer heavy - tailed , and is suitable for the pca step ( ii ) .",
    "we consider two specific applications of the model with explanatory variables @xmath2 for the common factors .",
    "* testing proxy factors for financial returns *    in model ( [ e1.2 ] ) , we test @xmath23 where @xmath2 represents a set of observable proxies to the true factors , ( e.g. , fama - french factors ) .",
    "the null hypothesis is equivalent to @xmath24 almost surely in the entire sampling period , under which the observed proxies fully explain the true factors . while it is well known that the commonly used fama - french factors have explanatory power for most of the variations of stock returns , it is questionable whether they fully explain the true ( yet unknown ) factors .",
    "these observed proxies are nevertheless used as the factors empirically , and the remaining components ( @xmath9 and @xmath15 ) have all been mistakenly regarded as the idiosyncratic components .    the proposed test provides a diagnostic tool for the specification of common factors in empirical studies , and complements the  efficiency test \" in the financial econometric literature ( e.g. , @xcite ) . while the efficiency test aims to test whether the alphas of excess returns are simultaneously zero for the specified factors , here we directly test whether the factor proxies are correctly specified .",
    "we test the specification of fama french factors for the returns of s&p 500 constituents using rolling windows .",
    "the null hypothesis is more often to be rejected using the daily data compared to the monthly data , due to a larger volatility of the unexplained factor components . the estimated volatility of unexplained components varies over time and drops significantly during the acceptance period .",
    "* multi - index regression *    with more accurately estimated latent factors , we also consider a multi - index regression model using both latent factors and observed attributes : @xmath25 where @xmath26 represents an observed scalar outcome and @xmath27 denote a set of regression indices . here @xmath1 and @xmath2 are allowed to have overlapped components .",
    "for instance , in treatment effect studies , @xmath26 represents the outcome , and @xmath2 denotes the treatments and a set of observed demographic variables for the individual @xmath22 . in macroeconomic forecasts , @xmath28 represents a scalar macroeconomic variable to forecast ; and @xmath2 denotes the observed characteristics at time @xmath22 .",
    "the regression depends on a nonparametric link function @xmath29 .",
    "in particular , it admits a factor - augmented linear model as a special case .",
    "we estimate the common factors using the proposed _ robust proxy - regressed _ method from a large panel of variables .",
    "for prediction and forecast purposes , the multi - index model considered here does not require the identification of the index coefficients or complicated semi - parametric methods to individually estimate them .",
    "using the  dimension reduction \" techniques in the statistical literature @xcite , our method only requires estimating the space spanned by the index coefficients .    in the empirical study",
    ", we apply the multi - index regression to forecast the risk premia of u.s .",
    "government bonds .",
    "we find that the observed macroeconomic characteristics contain strong explanatory powers of the factors .",
    "incorporating these characteristics in the estimation of factors leads to a substantially improved out - of - sample forecast compared to the usual procedures that directly use them for forecasts .",
    "various methods have been developed in the literature to estimate the common factors , including principal components analysis ( pca , e.g. , @xcite ) , maximum likelihood estimate ( mle , @xcite ) , kalman filtering @xcite , among others .",
    "we study the _",
    "static factor model _ , which is different from the _ dynamic factor model_. the dynamic model allows more general infinite dimensional representations using the frequency domain pca @xcite .",
    "we refer to @xcite for the literature , among others .    in the financial econometric literature , observed characteristics",
    "are often imposed to explain the loading matrix .",
    "for instance , @xcite considered a model where the loadings depend on a set of firm - specific characteristics ( market capitalization , price - earning ratio , etc ) .",
    "they proposed a kernel - based method to iteratively estimate the loading matrix and factors .",
    "their characteristics are observed cross - sectionally ( firm - specific ) .",
    "improved estimation of factors , on the other hand , is particularly important for predictions and forecasts .",
    "as is recently demonstrated by @xcite , more accurate estimations of the factors can substantially improve the out - of - sample forecasts .",
    "there is also an extensive literature on prediction / forecast based factor models .",
    "in addition to those discussed above , the literature includes , @xcite , among many others .    finally , the robust estimation is not rare in the econometric literature .",
    "for instance , it has been extensively studied in the time series literature ( e.g. , @xcite ) .",
    "the quantile regression is another type of robust estimation .",
    "however , quantile regression does not estimate conditional mean functions when the data are asymmetrically distributed .    the rest of the paper is organized as follows .",
    "section 2 overviews the method and defines the estimators .",
    "section 3 presents the general asymptotic theory of the estimators .",
    "section [ testff ] proposes a new test on the specification of fama - french factors , which tests whether the factor proxies fully explain the true factors .",
    "section [ multir ] applies the proposed method to multi - index nonlinear regression .",
    "section [ sec : sim ] provides simulations and section [ sec : emp1 ] applies the methods to an empirical application on bond risk premia .",
    "finally section [ sec : con ] concludes .",
    "the appendix contains an empirical study of testing fama - french factors , as well as all the technical proofs .    throughout the paper ,",
    "we use @xmath30 and @xmath31 to denote the minimum and maximum eigenvalues of a matrix @xmath32 .",
    "we also denote by @xmath33 , @xmath34 , @xmath35 and @xmath36 the frobenius norm , spectral norm ( also called operator norm ) , @xmath37-norm , and elementwise norm of a matrix @xmath32 , defined respectively by @xmath38 , @xmath39 , @xmath40 and @xmath41 .",
    "note that when @xmath32 is a vector , both @xmath33 and @xmath34 are equal to the euclidean norm . finally , for two sequences",
    ", we write @xmath42 if @xmath43 and @xmath44 if @xmath45 and @xmath46",
    "suppose that there is a @xmath47-dimensional observable vector @xmath2 that is : ( i ) associated with the latent factors @xmath1 , and ( ii ) mean - independent of the idiosyncratic term .",
    "we focus on the effect of observing @xmath2 on the identification and estimation of the factors and loadings . taking the conditional mean on both sides of ( [ e2.1 ] )",
    ", we have @xmath48 and @xmath49 suppose the following normalization conditions hold : @xmath50 and that @xmath51 is a diagonal matrix , with distinct diagonal entries .",
    "then taking expectation on both sides of ( [ e2.3 ] ) , and right multiplying by @xmath52 , by the normalization condition , we reach : @xmath53    since @xmath54 is identified by the data generating process with observables @xmath55 , we see that the columns of @xmath56 ( up to a sign change ) are identified as the eigenvectors corresponding to the first @xmath57 eigenvalues of @xmath58 , which is assumed to have rank @xmath59 .",
    "let @xmath60 from ( [ e2.3 ] ) , we have @xmath61 note that @xmath62 is a @xmath63 matrix , hence @xmath64 has at most @xmath59 nonzero eigenvalues . as a result , from ( [ e2.4 ] ) , @xmath65 corresponds to these @xmath59 nonzero eigenvalues .",
    "left multiplying @xmath66 on both sides of ( [ e2.2 ] ) , one can see that @xmath67 is also identified as : @xmath68    we impose the normalization conditions above to facilitate our heuristic arguments . in this paper , these normalization conditions are not imposed .",
    "then the same argument shows that @xmath65 and @xmath19 can be identified up to a matrix transformation .",
    "it is important to note that here the identification of @xmath65 ( or its transformation ) is  exact \" in the sense that it can be written as leading eigenvectors of identified covariance matrices for any given @xmath17 .",
    "this is in contrast to the  asymptotic identification \" ( as @xmath18 ) as in @xcite where the loading matrix ( or its transformation ) is identified only when there are sufficiently large number of cross - sectional units . here",
    "the exact identification is achieved due to the fact that the conditional expectation operation @xmath69 removes the effects of idiosyncratic components in the equality ( [ e2.2 ] ) .",
    "the key assumption to be made about the role of @xmath2 is as follows :    [ a1 ] there are @xmath70 so that all the eigenvalues of @xmath62 are confined in @xmath71 $ ] .",
    "this assumption requires that the observed characteristics @xmath2 should have an explanatory power for @xmath1 , which is essential whenever @xmath2 is incorporated in the estimation procedure .",
    "for instance , when @xmath2 represents the fama - french factors @xcite , they are believed to be strongly associated with the  true \" factors . in the ideal case that @xmath2 fully explains @xmath1 , we have @xmath72 almost surely .",
    "then this assumption is naturally satisfied so long as @xmath73 is well conditioned .",
    "the identification strategy motivates us to estimate @xmath65 and @xmath67 respectively by @xmath74 and @xmath75 as follows : let @xmath76 be some covariance estimator of @xmath64 , whose definition will be clear below , and @xmath77 be an estimator of @xmath78",
    ". then the columns of @xmath79 are defined as the eigenvectors corresponding to the first @xmath59 eigenvalues of @xmath76 , and @xmath80    recall that @xmath81 .",
    "we assume that @xmath82 is independent of @xmath2 .",
    "when @xmath10 is small , @xmath83 also serves as an estimator for the unknown factor @xmath1 .",
    "above all , @xmath83 is consistent for @xmath1 so long as @xmath84 .",
    "in general , @xmath85 might not vanish and we estimate @xmath1 directly using ols : @xmath86 finally , we estimate @xmath9 by : @xmath87      several covariance estimators @xmath76 for @xmath64 are available .",
    "note that @xmath64 is a high - dimensional matrix when @xmath17 is large , hence it is difficult to estimate it consistently under usual matrix norms ( e.g. , fronenius norm or spectral norm ) . fortunately , as we show in theorem [ th1 ] below , consistency for @xmath64 is not a requirement for the consistency of @xmath74 , @xmath83 or @xmath88 .",
    "the proposed estimators work so long as a  not - too - bad \" estimator @xmath76 is used .",
    "the required condition is mild .    throughout the paper ,",
    "we assume both @xmath17 and @xmath89 grow to infinity , while @xmath57 and @xmath90 are constant .",
    "write @xmath91 .",
    "[ a2 ] ( i ) all the eigenvalues of the @xmath63 matrix @xmath92 are bounded away from both zero and infinity ; + ( ii ) the eigenvalues of @xmath93 are distinct .",
    "we focus on strong factors throughout the paper , and condition ( i ) is the usual  pervasive condition \" for approximate factor models .",
    "it requires that the common factors should impact on a non - negligible portion of the components of @xmath94 .",
    "as we take the principal components of @xmath76 in the second step , we still require the first @xmath59 eigenvalues of @xmath64 to be large in order to signal the corresponding eigenvectors .",
    "this gives rise to the pervasive condition in the current context .",
    "[ th1 ] suppose assumptions [ a1 ] and [ a2 ] hold .",
    "let @xmath76 be such that @xmath95 then there exists an invertible @xmath63 matrix @xmath96 ( whose dependence on @xmath17 and @xmath89 is suppressed for notational simplicity ) such that , as @xmath97 , @xmath98 in addition , if the normalization conditions hold : @xmath99 and @xmath51 is a diagonal matrix , then @xmath100    recall that ( [ e2.5 ] ) uses the spectral norm for matrices .",
    "a useful sufficient condition for ( [ e2.5 ] ) is the element - wise convergence : @xmath101 which is a very weak convergence requirement .",
    "recall that @xmath102 .",
    "hence we construct an estimator @xmath77 first as follows .",
    "let @xmath103 be a @xmath104 dimensional vector of sieve basis .",
    "suppose @xmath78 can be approximated by a sieve representation : @xmath105 where @xmath106 is an @xmath107 matrix of sieve coefficients .",
    "this setup includes structured nonparametric models such as the additive model and the parametric model ( e.g. , linear models ) . to adapt for different heaviness of the tails of idiosyncratic components to robustify the estimation , we use the huber loss function ( @xcite ) to estimate the sieve coefficients .",
    "define @xmath108 for some deterministic sequence @xmath109 , we estimate the sieve coefficients @xmath110 by the following convex optimization : @xmath111 we then estimate @xmath64 by @xmath112    we regard @xmath113 as a tuning parameter , which diverges in order to reduce the biases of estimating the conditional mean @xmath78 when the distribution of @xmath114 is asymmetric . throughout the paper , we shall set @xmath115 for some constant @xmath116 .",
    "we recommend choose the constant @xmath117 through a multifold cross - validation .",
    "we explain this choice in section [ sec : choose ] .",
    "our method is particularly suitable for applications of financial and macroeconomic time series that often exhibit heavy tails @xcite . to our best knowledge , factor models with this type of distributions have not been studied previously .",
    "we discuss some alternative estimation strategies .",
    "recall that @xmath103 is a @xmath104 dimensional vector of sieve basis .",
    "let @xmath118 then , the fitted values of the least - squares estimate for @xmath119 is simply @xmath120 and the sieve - ls covariance estimator for @xmath64 is @xmath121 . while the sieve - ls is attractive due to its closed form , it is not suitable when the idiosyncratic distribution has heavier tails .",
    "nevertheless , in complicated real data analysis , applied researchers might like to use simple but possibly not robust estimators , for sake of simplicity . in that case",
    ", @xmath122 can still serve as an alternative estimator for @xmath64 .",
    "our major estimation procedure for incorporating the information from @xmath2 still carries over .",
    "as expected , our numerical studies in section [ sec : sim ] demonstrate that sieve - ls performs well in light - tailed scenarios , but is less robust to heavy - tailed distributions .",
    "plugging @xmath81 into ( [ e2.1 ] ) , we obtain @xmath123 alternatively , one may also consider the following model : @xmath124 for a nonparametric function @xmath125 , or simply a linear form @xmath126 . models ( [ e2.5add ] ) and ( [ e2.6 ] ) are known as the panel data models with interactive effects in the literature @xcite , where parameters are often estimated using least squares .",
    "for instance , we can estimate model ( [ e2.5add ] ) by @xmath127    but this approach is not appropriate in the current context when @xmath2 almost fully explains @xmath1 for all @xmath128 . in this case , @xmath129 , and least squares ( [ e2.7 ] ) would be inconsistent . for _ any _ scalar @xmath130 , since the true @xmath131 .",
    "] in addition , @xmath65 in ( [ e2.6 ] ) would be very close to zero because the effects of @xmath1 would be fully explained by @xmath132 . as a result",
    ", the factors in ( [ e2.6 ] ) can not be consistently estimated @xcite either .",
    "we conduct numerical comparisons with this method in the simulation section . in all simulated scenarios ,",
    "the interactive effect approach gives the worst estimation performance .",
    "let @xmath133 suppose the conditional distribution of @xmath134 given @xmath135 is absolutely continuous for almost all @xmath136 , with a conditional density @xmath137 .",
    "[ a31 ] ( i ) there are @xmath138 , @xmath116 and @xmath139 , so that for all @xmath140 , @xmath141 ( ii ) @xmath142 is a sub - gaussian vector , that is , there is @xmath143 , for any @xmath144 so that @xmath145 , @xmath146 ( iii ) for @xmath147 , there is @xmath148 , so that @xmath149^v<\\infty$ ] .",
    "we allow @xmath134 to have a tail distribution that is heavier than the exponential - type tails .",
    "note that @xmath150 .",
    "therefore if the distribution of factors has a light tail ( e.g. , decays either exponentially or polynomially faster than that of @xmath151 ) , then the required tail conditions on @xmath134 directly carry over to @xmath151 .",
    "the following condition is regarding the sieve approximation .",
    "[ a3.3 ] for @xmath152 , let @xmath153 .",
    "then there is @xmath154 , as @xmath155 , @xmath156    suppose @xmath157 belongs to a hlder class : for some @xmath158 , @xmath159 then this condition is satisfied by common basis such as the polynomials and b - splines with @xmath160 .",
    "if @xmath157 admits an additive structure and each component is in the hlder class , then we can take @xmath161 .",
    "furthermore , as co - movements of the cross - sectional units are driven by the common factors , this assumption ensures that @xmath162 can be approximated by the sieve representation uniformly well across @xmath163 .",
    "[ a34 ] there are @xmath164 so that @xmath165    [ a32 ]    \\(i ) @xmath166 , and @xmath167 .",
    "\\(ii ) ( serial independence ) @xmath168 is independent and identically distributed",
    ";    \\(iii ) ( weak cross - sectional dependence ) @xmath169    note that we allow for conditional heteroskedasticity and cross - sectional correlations in @xmath15 .",
    "a limitation of our theory is that serial independence is required , as required in assumption [ a32 ] ( ii ) .",
    "the serial independence is solely a technical condition for robust estimations . unlike the usual principal components methods , the robust estimation based on huber s loss",
    "does not have a closed form solution . in order to achieve sharp rates of convergence and limiting distributions ,",
    "the asymptotic analysis relies on the uniform bahadur representation ( @xcite ) of the robust m - estimator : @xmath170 where @xmath171 denotes the derivative of the huber s loss function : @xmath172 here @xmath173 denotes the sign function ; @xmath32 denotes the hessian matrix of the expected huber s loss function ; @xmath174 is the sieve approximation error of @xmath175 ; @xmath176 is the remainder of the representation .",
    "the key technical argument is to bound the remainder uniformly over the cross - sectional units : @xmath177 .",
    "we appeal to the empirical process theories of @xcite for this task , which requires the data be independently distributed .",
    "when the data are not heavy - tailed , the sieve - ls estimator @xmath122 can be employed instead . in that case , the serial independence assumption can be replaced with strong mixing conditions to allow for serial correlations .      as mentioned earlier , throughout this paper , we take @xmath178 for a constant @xmath117 chosen by the cross - validation .",
    "the huber - estimator is biased for estimating the mean coefficient , whose population counterpart is @xmath179 as @xmath113 increases , the huber loss behaves like a quadratic loss .",
    "in fact , we show in the appendix ( proposition [ pb1 ] ) that for @xmath180 ^ 2 $ ] , @xmath181 for an arbitrarily smal @xmath182 , where @xmath183 is defined in assumption [ a31 ] .",
    "hence the bias decreases as @xmath113 grows as expected . on the other hand",
    ", we shall investigate the uniform convergence ( in @xmath184 ) of @xmath185 which is the leading term in the bahadur expansion of the huber - estimator .",
    "it turns out that @xmath113 can not grow faster than @xmath186 in order to guard for robustness and to have a sharp uniform convergence , where @xmath187 is the number of sieve basis .",
    "hence the choice ( [ e3.2 ] ) leads to the asymptotically least - biased robust estimation .",
    "we have the following result .",
    "recall that @xmath188 , and @xmath189    [ t31 ] suppose @xmath190 and @xmath191 . under assumptions",
    "[ a1][a32 ] , there is an invertible matrix @xmath96 , as @xmath192 , we have @xmath193    the optimal rate for @xmath187 in ( [ e3.3 ] ) is @xmath194 , which results in @xmath195 here @xmath196 represents the smoothness of @xmath162 . when @xmath196 is sufficiently large , the rate is close to @xmath197 , which is faster than the rate of the usual principal components ( pc ) estimator when @xmath17 is relatively small compared to @xmath89 .",
    "in fact , the pc estimator @xmath198 ( e.g. , @xcite ) satisfies , for some @xmath199 , @xmath200 the estimation improvement is essentially due to a better estimation of the factors when @xmath17 is relatively small . in the contrary , the usual pc estimator can not estimate the factors well when @xmath17 is small .",
    "define @xmath201    [ t32 ] let @xmath202 .",
    "suppose @xmath203 , @xmath204 , and assumptions [ a1][a32 ] hold .",
    "for @xmath96 in theorem [ t31 ] , as @xmath205 , we have @xmath206 @xmath207 where @xmath10 denotes the covariance matrix of @xmath208    the term @xmath209 reflects the impact of the components in the factors that can not be explained by @xmath2 . in the special case when @xmath210 , we have @xmath211 , and ( [ e3.6 ] ) implies @xmath212 when @xmath196 is large , this rate is faster than the usual pc estimator @xmath213 , since the latter has the following rate of convergence ( e.g. , @xcite ) : @xmath214 on the other hand , when @xmath10 is bounded away from zero and @xmath196 is large , the rate of convergence for @xmath215 is approximately @xmath216 which is the same as that of the pc estimator for @xmath1 .    for a general @xmath187 ,",
    "the rates of convergence of the two factor components are : @xmath217 in fact @xmath218 is the optimal choice in ( [ e3.8 ] ) ignoring the term involving @xmath209 .",
    "we now present the asymptotic distribution for @xmath219 , which can be used to derive the confidence interval for ( rotated ) @xmath9 for each fixed @xmath22 .",
    "we introduce an additional assumption and some notation .",
    "let @xmath220 denote the covariance matrix of @xmath15 .",
    "assumption [ a3.5 ] below is the cross - sectional central limit theorem , and is commonly imposed for the limiting distribution of estimated factors ( e.g. , @xcite ) .    [ a3.5 ] suppose @xmath221 , and for each fixed @xmath22 , @xmath222    define @xmath223 , @xmath224 .",
    "let @xmath225 be a @xmath63 diagonal matrix , whose diagonal elements are the eigenvalues of @xmath226 , and @xmath227 be the @xmath63 matrix whose columns are the corresponding eigenvectors .",
    "let @xmath228 , @xmath229 , and @xmath230 . finally , let @xmath231 where @xmath232 , @xmath233 .",
    "it can be shown that @xmath234 is positive definite .",
    "[ t3.3 ] suppose @xmath235 , @xmath236",
    ". then under assumptions [ a1][a3.5 ] , for each fixed @xmath128 , @xmath237    all terms in the asymptotic variance can be estimated using their sample counterparts : respectively define @xmath238 , @xmath239 , @xmath240 , @xmath241 , @xmath242 , and @xmath243 , where the covariance matrix estimator @xmath244 for @xmath220 can be easily constructed based on the residuals in the absence of cross - sectional correlations ( see section [ testff ] below , where we also present a covariance estimator allowing for cross - sectional correlations ) .",
    "finally , @xmath245 , @xmath246 and @xmath234 can be estimated similarly : @xmath247 where @xmath248 , and @xmath249 .",
    "the following result provides the limiting distribution of @xmath219 with consistent covariance estimators .",
    "[ c3.1 ] assume the assumptions of theorem [ t3.3 ] and cross - sectional independence .",
    "as @xmath250 , @xmath251",
    "the fama - french three - factor model @xcite is one of the most celebrated ones in the empirical asset pricing .",
    "it takes into account the size and value effects , in addition to the market risk .",
    "ever since its proposal , there is much evidence that the three - factor model can leave the cross - section of expected stock returns unexplained . to isolate exposures to the different dimensions of returns ,",
    "different factor definitions have been explored , e.g. , @xcite and @xcite . @xcite added profitability and investment factors to the three - factor model .",
    "they modeled the excess return @xmath252 on security or portfolio @xmath253 for period @xmath22 as @xmath254 where @xmath255 and @xmath256 are the three factors of @xcite , respectively representing the the excess returns of the market , the difference of returns between stocks with small and big market capitalizations (  small minus big \" ) , and the difference of returns between stocks with high book to equity ratios and those with low book to equity ratios (  high minus low \" ) .",
    "two additional factors were included : @xmath257 ( profitability ) is the difference between the returns on diversified portfolios of stocks with robust and weak profitability , and @xmath258 ( investment ) is the difference between the returns on diversified portfolios of low and high investment stocks .",
    "in addition , @xcite conducted grs tests @xcite on the five - factor models and its different variations .",
    "their tests  reject all models as a complete description of expected returns \" .",
    "on the other hand , the fama - french factors , though imperfect , are good proxies for the true unknown factors .",
    "consequently , they form a natural choice for @xmath2 . these observables are actually diversified portfolios , which have explanatory power on the latent factors @xmath1 , as supported by financial economic theories as well as empirical studies .",
    "our general results in section 3 immediately apply to the estimation of the loadings and true factors , incorporating the extra information from observing @xmath2 .",
    "we shall use @xmath2 as the  observed proxy \" of the true factors , such as the fama - french factors .",
    "we are interested in testing : ( recall that @xmath259 . )",
    "@xmath260 under @xmath261 , @xmath262 over the entire sampling period @xmath263 , implying that observed fama - french factors @xmath2 fully explain the true factors @xmath1 . the grs test and related tests , in contrast , are designed to test the  zero - alpha \" hypothesis ( @xmath264 for all @xmath163 ) using @xmath2 as the factors in the empirical asset pricing model",
    "the  zero - alpha \" test is used to assess the proxy of the true factors only when the market is mean - variance efficient @xcite .",
    "in contrast , our proposed test aims directly at the question whether the observed proxy @xmath2 is adequate or not , without assuming the efficient market hypothesis .    our method can also be used to test whether there are any missing factors in financial studies . to illustrate this , consider a simple example where there are four true factors , which are characterized by four variables : @xmath265 as follows : @xmath266 where @xmath267 are unknown functions ( e.g. , @xmath268 , @xmath269 ) .",
    "suppose however , only @xmath270 are identified and measured ( e.g. , fama - french three factors ) , but @xmath271 is missing . then in our notation , @xmath272 , and we write the factors as @xmath273 if at least one of the true factors depends on @xmath271 , then at least one of the @xmath274 s must be nonzero .",
    "this can be detected by testing ( [ e4.1add ] ) as the test is equivalent to testing @xmath24 for @xmath263 almost surely .",
    "our test statistic is based on a weighted quadratic statistic @xmath275 the weight matrix normalizes the test statistic , taken as @xmath276 avar@xmath277 , where avar@xmath278 represents the asymptotic variance - covariance matrix of @xmath219 under the null , and is given by @xmath279 as @xmath220 is a high - dimensional covariance matrix , to facilitate the technical arguments , in this section we assume @xmath280 to be cross - sectionally uncorrelated , and estimate @xmath220 by : @xmath281 the feasible test statistic is defined as @xmath282 we reject the null hypothesis for large values of @xmath283 .",
    "it is reasonable to allow cross - sectional dependence by assuming @xmath220 to be a sparse covariance , in the sense that most off - diagonal entries of @xmath220 are either zero or nearly so .",
    "the sparsity condition is a natural extension of the standard setup of approximate factor models @xcite , and has been recently used in the financial econometrics literature by , e.g. , @xcite . following the construction of @xcite",
    ", we can estimate @xmath220 by , for some estimator @xmath284 for @xmath285 , @xmath286 here @xmath287 is taken as a the soft - thresholding function , commonly used in the statistical literature , where @xmath288 .",
    "the threshold value @xmath289 is chosen to guarantee that @xmath290 the resulting estimator is a sparse covariance matrix , which thresholds off most off - diagonal entries ( @xmath291 is zero so long as @xmath292 ) . when @xmath151 is possibly heavy - tailed , the uniform convergence ( [ e4.1 ] ) requires a robust variance estimator @xmath284 , which can be defined as @xmath293 while these extensions are straightforward , we expect that the asymptotic analysis might be quite involved , and do not pursue it in this paper .",
    "we will show that the test statistic has the following asymptotic expansion : @xmath294 thus the limiting distribution is determined by that of @xmath295 .",
    "note that the cross - sectional central limit theorem ( assumption [ a3.5 ] ) implies as @xmath18 , @xmath296 hence each component of @xmath297 can be roughly understood as @xmath298-distributed with degrees of freedom @xmath59 being the number of common factors , whose variance is @xmath299 .",
    "this motivates the following assumption .",
    "[ a4.1 ] suppose as @xmath250 , @xmath300    we now state the null distribution in the following theorem .",
    "suppose @xmath301 is cross - sectionally independent , and assumption [ a4.1 ] and assumptions of theorem [ t32 ] hold .",
    "then , when @xmath302 , @xmath303 , @xmath304 , as @xmath250 , @xmath305    there are three technical conditions in this theorem that characterize the relationship among @xmath306 : the first condition ( i ) @xmath302 requires that @xmath89 should be large relative to @xmath17 .",
    "high - dimensional estimation errors accumulate in the test statistic as @xmath17 increases .",
    "hence this condition controls the error accumulations under a large panel . condition ( ii ) @xmath303 , on the other hand , is commonly required to guarantee the asymptotic accuracy of estimating the unknown factors .",
    "importantly , we allow either @xmath307 or @xmath308 .",
    "finally , condition ( iii ) @xmath304 requires the function @xmath309 be sufficiently smooth so that the sieve approximation error is negligible , and does not play a role in the limiting distribution .",
    "consider a multi - index regression model : @xmath310 where @xmath26 represents an observed scalar outcome ; @xmath1 is a set of latent factors that have a predicting power about @xmath26 ; @xmath2 is a set of observed conditioning variables that might be associated with @xmath1 and @xmath311 . for instance , in treatment effect studies , @xmath26 represents the outcome , and @xmath2 denotes the treatments and a set of observed demographic variables for the individual @xmath22 . in macroeconomic forecasts , @xmath28 represents a scalar macroeconomic variable to be forecast .",
    "the common factors are often inferred by using a large panel data : @xmath312 our goal is to predict / forecast @xmath313 using the data @xmath314 and @xmath315 .",
    "forecasts based on the estimated factors of large datasets have been extensively studied , where @xmath316 represents industrial production outputs , excess returns of stocks or u.s .",
    "government bonds @xcite , among many others .    here",
    "the non - parametric link function @xmath29 depends on @xmath317 indices @xmath318 with unknown coefficients @xmath319 s , and @xmath320 is imposed for the dimension reduction .",
    "while numerous regression models focus on linear models , some empirical evidence also suggests the possibility of nonlinear dynamics .",
    "for instance , nonlinearity is an important part of the theories that attempt to explain the great recession with a financial accelerator mechanism @xcite .",
    "omitted nonlinearity can lead to biases in predictions . on the other hand",
    ", a full nonparametric model may suffer from the curse of dimensionality of @xmath321 .",
    "our goal is to enhance the prediction using improved estimated factors , incorporating the explanatory power of the observed conditioning variables .",
    "since the function @xmath29 is unknown , neither the index parameters nor the unknown factors are separately identifiable .",
    "however , we can find a proper transformation @xmath322 such that @xmath323 and @xmath324 is identified , where @xmath324 denotes the space spanned by the index coefficients .",
    "as a result , we consider the following observationally equivalent model : @xmath325 for the ease of reading and to avoid complicated notations in this section , we give the definition of @xmath326 in the appendix .",
    "the method we introduce below does not require the identification of the individual coefficients .",
    "the estimation procedure is summarized as follows .",
    "step 1 : :    estimate @xmath327 by    @xmath328 , where    @xmath329    here @xmath88 is the proposed _",
    "robust    proxy - regressed _",
    "factor estimator , with @xmath2    incorporated in the estimation procedure .",
    "step 2 : :    find @xmath330 so that    @xmath331    consistently estimates    @xmath332 .",
    "then our estimated indices are written as    @xmath333 ,    @xmath334 .",
    "step 3 : :    finally , obtain a nonparametric estimator @xmath335    using any smoothing technique by regressing @xmath26 onto the    estimated indices    @xmath333 , for    @xmath336 .",
    "we then predict @xmath337 by    @xmath338    in particular , when @xmath339 in the forecast context ,    we forecast @xmath340 by @xmath341    a standard procedure of estimating the common factors is to apply the principal components ( pc ) estimator on ( [ e4.2 ] ) .",
    "in contrast , we employ the proposed factor estimators .",
    "our estimator potentially have two advantages compared to the pc estimator : ( i ) macroeconomic variables and financial excess returns are heavy - tailed .",
    "we shall also demonstrate it in our empirical study .",
    "( ii ) the conditioning variables @xmath2 can have strong explanatory powers on the factors .",
    "indeed , numerous empirical studies of the macroeconomic dataset used in @xcite and @xcite have identified several factors related to housing variables and stock markets .",
    "these factors are believed to be strongly associated with , e.g. , the consumption - wealth variable , financial ratios ( ratios of price to dividends or earnings ) , and term spread ( e.g. , @xcite ) . by incorporating these variables as @xmath2 , the estimation of @xmath1",
    "can be improved , which can potentially lead to significantly better predictions .    in step 2 we shall directly estimate @xmath332 . in the statistical literature on dimension reductions",
    "@xcite , this space is also called _ dimension - reduction subspace_. we now explain the rationale of using this space for the multi - index regression .",
    "we assume that the indices are sufficient for @xmath26 in the sense that the conditional distribution of @xmath342 satisfies : @xmath343 for all values of @xmath327 in its marginal sample space .",
    "as is shown by @xcite , ( [ eq5.3add ] ) still holds when @xmath344 is replaced with any @xmath345 such that @xmath346 in other words , all the information of @xmath342 is preserved by using @xmath347 .",
    "this then implies , @xmath348    we shall propose @xmath349 so that @xmath350 for a particular set of @xmath351 .",
    "hence @xmath352      we now describe the identification and estimation of span@xmath353 , which is based on the _ sliced inverse regression _ method of @xcite .",
    "fix @xmath354 , and divide the range of data @xmath355 into @xmath356 disjoint  slices \" @xmath357 such that @xmath358 .",
    "specifically , let @xmath359 denote the cumulative distribution function ( cdf ) of @xmath26 , and let @xmath360.\\ ] ] in practice , we replace @xmath359 with the sample cdf to construct @xmath361 .",
    "now define a  sliced covariance matrix \" @xmath362 it follows from @xcite that @xmath324 can be identified as the space spanned by the eigenvectors @xmath363 of @xmath364 , corresponding to the first @xmath317 eigenvalues : . ]",
    "@xmath346 we shall present this proposition and its proof in appendix [ sec : fo ] .",
    "importantly , @xmath365 is easy to estimate using its sample counterpart , whose leading eigenvectors span a subspace that consistently estimates @xmath324 .",
    "let @xmath366 be the sample analogue of @xmath367 , which is the sample average of @xmath368 for all @xmath369 , for @xmath336 : @xmath370 where @xmath368 is as defined in ( [ eq5.3 ] ) .",
    "we then let @xmath330 be the eigenvectors of the first @xmath317 eigenvalues of @xmath371    it is shown by @xcite and many authors in the statistical literature that the eigenvectors of @xmath372 is non - sensitive to @xmath356 .",
    "indeed , the choice of @xmath356 has very little impact on the estimated eigenvector space .",
    "this was elucidated by @xcite .",
    "the following result presents the estimation consistency of the index space .",
    "similar results of this type was recently obtained by @xcite .",
    "theorem [ th5.1 ] in contrast , provides a robust estimator for the factors that takes advantages of the information contained in the observables @xmath2 .",
    "in addition , our procedure is suitable for possibly heavy - tailed economic data .",
    "as recently noted by @xcite , more accurate estimation of the common factors can lead to better out - of - sample forecast performances .",
    "define @xmath373    [ th5.1 ] for any given @xmath374 , if the largest @xmath375 eigenvalues of @xmath376 are distinct , then @xmath377 in addition , for each fixed @xmath22 , @xmath378 , and @xmath379    theorem [ th5.1 ] immediately implies @xmath380 consistently estimates @xmath381 for each fixed @xmath22 .",
    "then by regressing @xmath26 onto @xmath382 , the function @xmath383 consistently estimates @xmath384 , whenever @xmath385 is consistent .",
    "the latter is a conditional mean predictor for @xmath337 .",
    "in this section , we use simulated examples to demonstrate the finite sample performance of the proposed _ robust proxy - regressed _ method and compare it with existing ones . throughout this section , we respectively specify five factors ( @xmath386 ) and five characteristics , and the sample size is @xmath387 . more results based on different sample sizes ( @xmath388 and @xmath389 ) are presented in appendix [ app_b ] , and the results are very similar .",
    "the sieve basis is chosen as the additive fourier basis with @xmath390 . as discussed in section [ sec : choose ] , the tuning parameter @xmath113 in the huber loss is of form @xmath391 .",
    "we selected the constant @xmath117 by the 5 fold cross validation .",
    "consider the following model , @xmath392 where @xmath9 are drawn from i.i.d . @xmath393 and @xmath394 is set to be @xmath395 and @xmath396 .",
    "the smaller the @xmath394 is , the more @xmath1 and @xmath19 are correlated . in this study , @xmath65 and @xmath2 are drawn from i.i.d .",
    "standard normal distribution .",
    "the unknown function @xmath397 is set to be one of the following 3 models :    1 .",
    "@xmath398 , where @xmath399 is a @xmath400 matrix with each entry drawn from @xmath401 $ ] ; 2 .",
    "@xmath402 ; 3 .",
    "@xmath403 , which implies that @xmath2 is irrelevant to @xmath1 .",
    "in addition , @xmath15 is drawn from one of the following four distributions :    1 .",
    "normal distribution ( @xmath404 ) ; 2 .",
    "mixture normal distribution ( mixn ) @xmath405 , which is asymmetric and light tailed ; 3 .   two times",
    "the @xmath406distribution with degrees of freedom 3 ( @xmath407 ) , which is symmetric and heavy - tailed ; 4 .   log - normal distribution ( logn ) @xmath408 , where @xmath409 is standard normal , which is asymmetric and heavy - tailed .",
    "the generated @xmath15 has been centralized to have zero mean . for model ( iii ) , we only consider @xmath410 , as the observables @xmath2 are independent of latent factors and other choices would have yield similar results .    in the presentation",
    "below , we shall abbreviate the proposed _ robust proxy - regressed _ method as rpr . for comparisons , we estimate the factors and loadings in ( [ sim_model ] ) by the proposed rpr , sieve - ls ( section 2.3.1 ) , the regular pca and int under different scenarios . in particular , the int method estimates the factors and loadings from the panel data with interactive effects ( int ) model @xcite as follows @xmath411 by solving the least squares problem ( [ e2.5add ] ) .",
    "first , we compare the in - sample model fitting performance among rpr , sieve - ls , pca and int under different scenarios .",
    "let @xmath412 be the @xmath413 matrix of factors .",
    "we use pca as a benchmark and define the relative estimation error as @xmath414 where @xmath415 and @xmath416 are the estimators of @xmath417 and @xmath418 obtained by pca , @xmath419 and @xmath420 are the estimators of @xmath417 and @xmath418 obtained by one of the methods to be compared . for each scenario",
    ", we conduct 200 simulations and calculate the average of relative estimation error .",
    "results are presented in table [ ntab1_1_s ] . besides",
    ", one may be also interested in the estimation accuracy of factors or loadings alone rather than their products .",
    "as the factors and loading may be estimated up to a rotation matrix , the canonical correlations between the parameter and its estimator can be used to measure the estimation accuracy @xcite . for model ( i ) and",
    "( ii ) we report the sample mean of the median of 5 canonical correlations between the true loading matrix and the estimated one and true factors and estimated ones(@xcite ) .",
    "the results are presented in table [ ntab1_2_s ] and [ ntab1_3_s ] .    according to tables [ ntab1_1_s] [ ntab1_3_s ] , sieve - ls and rpr are comparable for light - tail distributions .",
    "this implies that we do not pay much the price for robustness .",
    "however , when the error distributions have heavy tails , rpr yields much better estimation than other methods as expected .",
    "sieve - ls out - performs pca when @xmath2 and @xmath1 are well correlated . in general",
    ", pca gives the worst estimation performance as it does not exploit the information in @xmath2 .",
    "when @xmath421 , the observabed @xmath2 is not as informative and hence the performance of rpr and sieve - ls deteriorates .",
    "the interactive - effect based method ( int ) has worse estimation performance then sieve - ls under light tailed scenarios and performs similarly to pca under heavy - tailed cases .    .mean relative estimation error of @xmath422 ( % ) when @xmath423 : the smaller the better ( with pca as the benchmark ) [ cols=\"^,^,^,^,^,^,^,^,^,^,^ \" , ]     for the factor - augmented multi - index model , @xmath2 itself gives an out - of - sample @xmath424 of @xmath425 in predicting the bond risk premia with two year maturity and its forecast power decreases as the maturity increases .",
    "the factors and @xmath2 together ( @xmath426 ) have slightly worse forecast performance than the factors alone .    adding each covariate in @xmath2 to augmenting the prediction leads to some interesting findings . the forecast performance based on pca method",
    "gets sizable improvement when adding @xmath427 ( linear combination of five forward rates ) , @xmath428 ( non - agriculture employment ) or @xmath429 ( cpi ) .",
    "this coincides with the findings in existing literature that forward rates , employment and inflation have predictive power in bond risk premia @xcite .",
    "however , the forecast performance based on either rpr or sieve - ls can not be improved by adding any covariate in @xmath2 .",
    "we argue that , in this application , the information of @xmath2 should be mainly used as the explanatory power for the factors .",
    "also our proposed methods ( rpr and sieve - ls ) have efficiently exploited this information .",
    "therefore , we conclude :    1 .",
    "the observed macroeconomic characteristics @xmath2 ( e.g. forward rates , employment and inflation ) contain strong explanatory powers of the latent factors .",
    "the gain of forecasting bond risk premia is more substantial when these characteristics are incorporated to estimate the common factors ( using the proposed procedure ) than directly used for forecasts . 2 .",
    "the multi - index models yield significantly larger out - of - sample @xmath424 s than those of the linear forecast models .",
    "the factors estimated by rpr lead to significantly improved out - of - sample forecast on the us bond risk premia compared to the ones estimated by pca .",
    "as many series in the panel data are heavy - tailed , the proposed method can robustly estimate the factors and result in improved out - of - sample forecasts .",
    "we provide an econometric analysis for the factor models when the factors depend on several observed explanatory characteristics . in financial factor pricing models for instance ,",
    "the factors are approximated by a few observable proxies , such as the fama - french factors . in diffusion index forecasts ,",
    "identified factors are strongly related to several directly measurable economic variables such as consumption - wealth variable , financial ratios , and term spread . to incorporate the explanatory power of these observed characteristics , we propose a new two - step estimation procedure : ( i ) regress the data onto the observables , and ( ii ) take the principal components of the fitted data to estimate the loadings and factors .",
    "the proposed estimator is robust to possibly heavy - tailed distributions , which is found to be the case for many macroeconomic time series .",
    "the factors can be estimated accurately even if the cross - sectional dimension is mild .",
    "empirically , we apply the model to forecast us bond risk premia , and find that the observed macroeconomic characteristics contain strong explanatory powers of the factors .",
    "the gain of forecast is more substantial when these characteristics are incorporated to estimate the common factors than directly used for forecasts .",
    "fan , j. , liao , y. and mincheva , m. ( 2013 ) . large covariance estimation by thresholding principal orthogonal complements ( with discussion ) . _ journal of the royal statistical society : series b _ * 75 * 603680 ."
  ],
  "abstract_text": [
    "<S> we provide an econometric analysis for the factor models when the latent factors can be explained partially by several observed explanatory proxies . in financial factor models for instance , the unknown factors can be reasonably well predicted by a few observable proxies , such as the fama - french factors . in diffusion index forecasts , </S>",
    "<S> identified factors are strongly related to several directly measurable economic variables such as consumption - wealth variable , financial ratios , and term spread . to incorporate the explanatory power of these observed characteristics , we propose a new two - step estimation procedure : ( i ) </S>",
    "<S> regress the data onto the observables , and ( ii ) take the principal components of the fitted data to estimate the loadings and factors . </S>",
    "<S> the proposed estimator is robust to possibly heavy - tailed distributions , which are encountered by many macroeconomic and financial time series . with those proxies , </S>",
    "<S> the factors can be estimated accurately even if the cross - sectional dimension is mild . </S>",
    "<S> empirically , we apply the model to forecast us bond risk premia , and find that the observed macroeconomic characteristics contain strong explanatory powers of the factors . </S>",
    "<S> the gain of forecast is more substantial when these characteristics are incorporated to estimate the common factors than directly used for forecasts .    * jel classification * : c38 , c53 , c58    * key words * : huber loss , heavy tails , forecasts , fama - french factors , large dimensions </S>"
  ]
}