{
  "article_text": [
    "consider a gaussian random field @xmath9 living on a @xmath10-dimensional domain @xmath11 with zero mean and unit variance , that is , for every finite subset @xmath12 , @xmath13 is a mean zero multivariate gaussian random vector .",
    "let @xmath14 be a ( deterministic ) function and @xmath15 be a scale factor .",
    "define @xmath16 in this paper , we develop a precise asymptotic description of the conditional distribution of @xmath3 given that @xmath17 exceeds a large value @xmath18 , that is , @xmath19 .",
    "in particular , we provide a tractable total variation approximation ( in the sample path space ) for such conditional random fields based on a change of measure technique .",
    "in addition to the asymptotic descriptions , we design efficient monte carlo estimators that run in polynomial time of @xmath7 for computing the tail probabilities @xmath20 with a prescribed relative accuracy .      in the probability literature , the extreme behaviors of gaussian random fields have been studied extensively .",
    "the results range from general bounds to sharp asymptotic approximations . an incomplete list of works includes @xcite",
    ". a few lines of investigations on the supremum norm are given as follows .",
    "assuming locally stationary structure , the double - sum method @xcite provides the exact asymptotic approximation of @xmath21 over a compact set @xmath1 , which is allowed to grow as the threshold tends to infinity . for almost surely at least twice differentiable fields , the authors of @xcite",
    "derive the analytic form of the expected euler  poincar characteristics of the excursion set [ @xmath22 which serves as a good approximation of the tail probability of the supremum .",
    "the tube method @xcite takes advantage of the karhune ",
    "love expansion and weyl s formula .",
    "a recent related work along this line is given by @xcite .",
    "the rice method @xcite provides an implicit description of @xmath21 .",
    "change of measure based rare - event simulations are studied in @xcite .",
    "the discussions also go beyond the gaussian fields .",
    "for instance , @xcite discusses the situations of gaussian process with random variances .",
    "see also @xcite for discussions on non - gaussian cases .",
    "the distribution of @xmath17 is studied in the literature when @xmath0 is a brownian motion @xcite .",
    "recently , @xcite derive the asymptotic approximations of @xmath23 as @xmath24 for three times differentiable and homogeneous gaussian random fields .",
    "besides the tail probability approximations , rigorous analysis of the conditional distributions of stochastic processes given the occurrence of rare events is also an important topic . in the classic large deviations analysis for light - tailed stochastic systems , the sample path(s ) that admits the highest probability ( the most likely sample path ) under the conditional distribution given the occurrence of a rare event is central to the entire analysis in terms of determining the appropriate exponential change of measure , developing approximations of the tail probabilities and designing efficient simulation algorithms ; see , for instance , standard textbook @xcite . for heavy - tailed systems , the conditional distributions and the most likely paths , which typically admit the so - called `` one - big - jump '' principle",
    ", are also intensively studied @xcite .",
    "these results not only provide intuitive and qualitative descriptions of the conditional distribution , but also shed light on the design of rare - event simulation algorithms @xcite  the best importance sampling estimator of the rare - event probability uses a change of measure corresponding to the interesting conditional distribution .",
    "in addition , the conditional distribution ( or the conditional expectations ) is also of practical interest .",
    "for instance , in risk management , the conditional expected loss given some rare / disastrous event is an important risk measure and stress test .    in the literature of gaussian random fields ,",
    "the exact slepian models [ conditional field given a local maximum or level crossing of @xmath0 ] are studied intensively for twice differentiable fields .",
    "for instance , leadbetter , lindgren and rootzn @xcite give the slepian model conditioning on an upcrossing of level @xmath26 at time zero .",
    "lindgren @xcite treats conditioning on a local maximum of height @xmath26 at time zero .",
    "the first rigorous treatment of slepian models for nonstationary processes is given by lindgren @xcite .",
    "grigoriu @xcite extends the results of leadbetter , lindgren and rootzn  @xcite for level crossings to the general nonstationary case .",
    "this work is followed up by gadrich and adler @xcite . in the later analysis",
    ", we will set an asymptotic equivalence between the conditional distribution given @xmath27 and that given the high excursion of the supremem of @xmath3 .",
    "the latter can be characterized by the slepain model .      in this paper , we pursue along this line for the extreme behaviors of gaussian processes and begin to describe the conditional distribution of @xmath3 given the occurrence of the event @xmath28 . in particular , we provide both quantitative and qualitative descriptions of this conditional distribution .",
    "furthermore , from a computational point of view , we construct a monte carlo estimator that takes a polynomial computational cost ( in @xmath7 ) to estimate @xmath29 for a prescribed relative accuracy .",
    "central to the analysis is the construction of a change of measure on the space @xmath30 ( continuous functions living on @xmath1 ) .",
    "the application of the change of measure ideas is common in the study of large deviations analysis for the light - tailed stochastic systems .",
    "however , it is not at all standard in the study of gaussian random fields .",
    "the proposed change of measure is not of a classical exponential - tilting form .",
    "this measure has several features that are appealing both theoretically and computationally .",
    "first , we show that the change of measure denoted by @xmath31 approximates the conditional measure @xmath32 in total variation as @xmath24 .",
    "second , the measure @xmath31 is analytically tractable in the sense that the distribution of @xmath3 under @xmath31 has a closed form representation and the radon  nikodym derivative @xmath33 takes the form of a @xmath10-dimensional integral .",
    "this tractability property has useful consequences . from a methodological point of view ,",
    "the measure @xmath31 provides a very precise description of the mechanism that drives the rare event @xmath34 .",
    "this result allows us to directly use the intuitive mechanism to provide functional probabilistic descriptions that emphasize the most important elements that are present in the interesting rare events . more technically , the analytical computations associated with the measure @xmath31 are easy ( compared to the conditional measure ) , and the expectation @xmath35 $ ] is theoretically much more tractable than @xmath36 $ ] . based on this result",
    ", we show that the tail event @xmath37 is asymptotically equivalent to the tail event of @xmath5 where @xmath6 is an affine function of @xmath0 and its derivative field @xmath38 and @xmath6 implicitly depends on @xmath18 .",
    "thus , one can further characterize the conditional measure by means of the results on the slepian model mentioned earlier .",
    "another contribution of this paper lies in the numerical evaluation of @xmath29 . the importance sampling algorithm associated with the proposed change of measure yields an efficient estimator for computing @xmath29 .",
    "an important issue concerns the implementation of the monte carlo method .",
    "the processes considered in this paper are continuous while computers can only represent discrete objects .",
    "inevitably , we will introduce a suitable discretization scheme and use discrete ( random ) objects to approximate the continuous processes .",
    "a naturally raised issue lies in the control of the approximation error relative to the probability @xmath29 .",
    "we will perform careful analysis and report the overall computational complexity of the proposed monte carlo estimators .",
    "a key requirement of the current analysis is the twice differentiability of  @xmath3 .",
    "our change of measure is written explicitly in the form of @xmath3 , @xmath39 and @xmath40 .",
    "a  very interesting future study would be developing parallel results for nondifferentiable fields .",
    "the technical challenges are two - fold .",
    "first , there is lack of asymptotic analysis for the exponential integral of general nondifferentiable fields . to the author s best knowledge ,",
    "the behavior of @xmath41 for nondifferentiable processes is investigated only when @xmath3 is a brownian motion whose techniques can not be extend to general cases @xcite .",
    "in addition , there is a lack of descriptive tools ( such as derivatives and the palm model ) for nondifferentiable processes .",
    "this also leads to difficulties in describing the slepian model for level crossing . to the author s best knowledge , analytic description of slepian models for excursion of @xmath21",
    "are available only for twice differentiable fields . despite of the smoothness limitation ,",
    "the current analysis has important applications the details of which will be presented in the following section .",
    "the rest of this paper is organized as follows .",
    "two applications of this work are given in section  [ secapp ] . in section  [ secmain ] , we present the main results including the change of measure , the approximation of @xmath32 and the efficient monte carlo estimator of @xmath29 .",
    "proofs of the theorems are given in sections  [ secproof][proofth5 ] .",
    "a supplemental material @xcite is provided including all the supporting lemmas .",
    "the integral of exponential functions of gaussian random fields plays an important role in many probability models .",
    "we present two such models for which the conditional distribution is of interest and the underlying random fields are differentiable .",
    "in spatial point process modeling , let @xmath42 be the intensity of a poisson point process on @xmath1 , denoted by @xmath43 .",
    "in order to build in spatial dependence structure and to account for overdispersion , the log - intensity is typically modeled as a gaussian random field , that is , @xmath44 and then @xmath45 = \\int_{a}e^{f(t)+\\mu(t)}\\,dt$ ] , where @xmath14 is the mean function , and @xmath0 is a zero - mean gaussian process . for instance , chan and ledolter @xcite consider the time series setting in which @xmath1 is a one - dimensional interval , @xmath14 is modeled as the observed covariate process and @xmath0 is an autoregressive process ; see @xcite for more examples in high - dimensional domains .    for the purpose of illustration",
    ", we consider a very concrete case that the point process @xmath46 represents the spatial distribution of asthma cases over a geographical domain @xmath1 .",
    "the latent intensity @xmath42 [ or equivalently @xmath0 ] represents the unobserved ( and appropriately transformed ) metric of the pollution severity at location  @xmath47 . the mean function",
    "can be written as a linear combination of the observed covariates that may affect the pollution level , that is , @xmath48 is treated as a deterministic function .",
    "it is well understood that @xmath42 is a smooth function of the spatial parameter @xmath47 at the macro level as the atmosphere mixes well ; see , for example , @xcite .",
    "one natural question in epidemiology is the following : upon observing an unusually high number of asthma cases , what is their geographical distribution , that is , the conditional distribution of the point process @xmath46 given that @xmath49 for some large @xmath18 ?",
    "first of all , liu and xu @xcite show that @xmath50 as @xmath24 .",
    "following the same derivations , it is not difficult to establish the following convergence : @xmath51 the total count @xmath52 is a poisson random variable with mean @xmath53 . intuitively speaking ,",
    "the tail of the integral is similar to a lognormal random variable and thus is heavy - tailed .",
    "its overshoot over level @xmath18 is @xmath54 .",
    "however , a poisson random variable with mean @xmath55 has standard deviation @xmath56 .",
    "thus , a  large number of @xmath52 is mainly caused by a large value of @xmath41 .",
    "the symmetric difference of the two sets @xmath57 and @xmath58 vanishes , and the probability law of the entire system conditional upon observing that @xmath49 is asymptotically the same as that given @xmath59 .",
    "therefore , the conditional distribution of @xmath46 given @xmath49 is asymptotically another doubly - stochastic poisson process whose intensity is @xmath60 where @xmath0 follows the conditional distribution of @xmath61 .",
    "based on the main results presented momentarily , a qualitative description of the conditional distribution of @xmath46 is as follows .",
    "given @xmath62 , the overshoot is of order @xmath54 , that is , @xmath63 .",
    "the locations of the points are i.i.d .",
    "samples approximately following a @xmath10-dimensional multivariate gaussian distribution with mean @xmath64 and variance @xmath65 where @xmath66 depends on the spectral moments of @xmath3 .",
    "the distribution of @xmath67 is uniform over @xmath1 if @xmath14 is a constant ; if @xmath14 is not constant , @xmath67 has a density @xmath68 presented in ( [ lt ] ) .",
    "the exponential integral can be considered as a generalization of the sum of dependent lognormal random variables that has been studied intensively from different aspects in the applied probability literature ( see @xcite ) . in portfolio risk analysis , consider a portfolio of @xmath69 assets @xmath70 .",
    "the asset prices are usually modeled as log - normal random variables .",
    "that is , let @xmath71 and @xmath72 follows a multivariate normal distribution .",
    "the total portfolio value @xmath73 is the weighted sum of dependent log - normal random variables .",
    "an important question is the behavior of this sum when the portfolio size becomes large and the assets are highly correlated .",
    "one may employ a latent space approach used in the literature of social networks . more specifically",
    ", we construct a gaussian process @xmath9 and map each asset @xmath74 to a latent variable @xmath75 , that is , @xmath76 .",
    "then the log - asset prices fall into a subset of the continuous gaussian process .",
    "furthermore , we construct a ( deterministic ) function @xmath77 so that @xmath78",
    ". then , the unit share value of the portfolio is @xmath79 .",
    "see @xcite for detailed discussions on the random field representations of large portfolios .    in the asymptotic regime",
    "that @xmath80 and the correlations among the asset prices become close to one , the subset @xmath81 becomes dense in @xmath1 .",
    "ultimately , we obtain the limit @xmath82 where @xmath83 is the limiting spatial distribution of @xmath84 in @xmath1 .",
    "let @xmath85 .",
    "then the ( limiting ) unit share price is @xmath86 .",
    "the current study provides an asymptotic description of the performance of each asset given the occurrence of the tail event @xmath87 .",
    "this is of great importance in the study of the so - called _ stress test _ that evaluates the impact of shocks on and the vulnerability of a system .",
    "for instance , consider that another investor holds a different portfolio that has a substantial overlap with the current one , or it has exactly the same collection of assets but with different weights .",
    "thus , this second portfolio corresponds to a different mean function @xmath88 .",
    "the stress test investigates the performance of this second portfolio on the condition that a rare event has occurred to the first , that is , @xmath89 to characterize the above distribution , we need a precise description of the conditional measure @xmath90 .",
    "throughout this discussion , we consider a homogeneous gaussian random field @xmath9 living on a domain @xmath11 .",
    "let the covariance function be @xmath91 we impose the following assumptions :    @xmath3 is stationary with @xmath92 and @xmath93 .",
    "@xmath3 is almost surely at least two times differentiable with respect to  @xmath47 .",
    "@xmath1 is a @xmath10-dimensional compact set of @xmath94 with piecewise smooth boundary .",
    "the hessian matrix of @xmath95 at the origin is standardized to be @xmath96 , where  @xmath97 is the @xmath98 identity matrix .",
    "in addition , @xmath95 has the following expansion when @xmath47 is close to @xmath99 @xmath100 where @xmath101 and @xmath102 for some .    for each @xmath103 ,",
    "the function @xmath104 is a nonincreasing function of @xmath105 .",
    "the mean function @xmath14 falls into either of the two cases :    @xmath106 ;    the maximum of @xmath14 is unique and is attained in the interior of @xmath1 and @xmath107 as @xmath108 .",
    "we define a set of notation constantly used in the later development and provide some basic calculations .",
    "let @xmath109 be the conditional measure given @xmath110 , that is , @xmath111 let `` @xmath112 '' denote the gradient and `` @xmath113 '' denote the hessian matrix with respect to @xmath47 .",
    "the notation `` @xmath114 '' is used to denote the vector of second derivatives .",
    "the difference between @xmath38 and @xmath115 is that @xmath115 is a @xmath116 symmetric matrix whose diagonal and upper triangle consist of elements of @xmath38 .",
    "furthermore , let @xmath117 be the partial derivative with respect to the @xmath118th element of @xmath47 . finally , we define the following vectors : @xmath119 \\\\[-8pt ] \\nonumber & & \\hspace*{6pt}{}i=1,\\ldots , d-1,j = i+1,\\ldots , d \\bigr ) , \\nonumber \\\\",
    "\\mu_{02}^\\top&=&\\mu_{20}=\\mu_{2}(0 ) . \\nonumber\\end{aligned}\\ ] ]    suppose @xmath120 .",
    "it is well known that @xmath121 is a multivariate gaussian random vector with mean zero and covariance matrix ( cf .",
    "chapter  5.5 of @xcite ) @xmath122 where the matrix @xmath123 is a @xmath124-dimensional positive definite matrix and contains the 4th order spectral moments arranged in an appropriate order according to the order of elements in @xmath125 .",
    "let @xmath126 be the density function of @xmath127 evaluated at @xmath128 .",
    "then , simple calculation yields that @xmath129 \\\\[-8pt ] \\nonumber & & \\qquad=\\frac{\\det(\\gamma)^{-{1}/{2}}}{(2\\pi)^ { { ( d+1)(d+2)}/{4}}}e^{-({1}/{2 } ) [ { y}^{\\top}{y}+{(x-\\mu_{20}\\mu _ { 22}^{-1}{z})^{2}}/{(1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02})}+{z}^{\\top}\\mu_{22}^{-1}{z } ] } , \\end{aligned}\\ ] ] where @xmath130 is the determinant of a matrix and @xmath131    we define @xmath26 as a function of @xmath18 such that @xmath132 note that the above equation generally has two solutions : one is approximately @xmath133 , and the other is close to zero as @xmath24 .",
    "we choose @xmath26 to be the one close to @xmath134 .",
    "for @xmath14 and @xmath135 appearing in ( [ inti ] ) , we define @xmath136 approximately , @xmath137 is the level that @xmath0 needs to reach so that @xmath87 .",
    "furthermore , we need the following spatially varying set : @xmath138 where @xmath139 is a tuning parameter that will be eventually sent to zero as @xmath24 and @xmath140 is a function of @xmath0 and its derivative fields taking the form of @xmath141 in the above equation ( [ s ] ) , @xmath142 is defined as [ with the notation in ( [ moment ] ) ] @xmath143 the term @xmath144 is a deterministic function depending only on @xmath95 , @xmath14 and  @xmath135 , @xmath145 where @xmath10 is the dimension of @xmath1 , and @xmath146 .",
    "note that @xmath147 .",
    "thus on the set @xmath148 , @xmath149 .",
    "together with the fact that @xmath150 = u_t\\mu _ { 02}$ ] , @xmath142 is the standardized second derivative of @xmath3 given that @xmath151 . in section  [ secchange ] , we will show that the event @xmath28 is approximately @xmath152 .    for notational convenience , we write @xmath153 if there exists a constant @xmath154 independent of everything such that @xmath155 for all @xmath156 , and @xmath157 if @xmath158 as @xmath159 , and the convergence is uniform in other quantities .",
    "we write @xmath160 if @xmath161 and @xmath162 .",
    "in addition , we write @xmath163 if @xmath164 as @xmath159 .",
    "condition c1 assumes unit variance .",
    "we treat the standard deviation @xmath135 as an additional parameter and consider @xmath165 .",
    "condition c2 implies that @xmath95 is at least 4 times differentiable and the first and third derivatives at the origin are all zero .",
    "differentiability is a crucial assumption in this analysis .",
    "condition c3 restricts the results to finite horizon .",
    "condition c4 assumes the hessian matrix is standardized to be @xmath96 , which is to simplify notation . for any gaussian process",
    "@xmath166 with covariance function @xmath167 and @xmath168 and @xmath169 , identity hessian matrix can be obtained by an affine transformation by letting @xmath170 and @xmath171 condition c5 is imposed for technical reasons so that we are able to localize the integration . for condition",
    "c6 , we assume that @xmath14 either is a constant or attains its global maximum at one place .",
    "if @xmath172 has multiple ( finitely many ) maxima , the techniques developed in this paper still apply , but the derivations will be more tedious .",
    "therefore , we stick to the uni - mode case .",
    "the setting in ( [ tails ] ) incorporates the case in which the integral is with respect to other measures with smooth densities .",
    "then , if @xmath173 , we will have that @xmath174 which shows that the density can be absorbed by the mean function .      in this subsection",
    ", we propose a change of measure @xmath31 on the sample path space @xmath30 that approximates @xmath175 in total variation .",
    "let @xmath176 be the original measure .",
    "the measure @xmath31 is defined such that @xmath176 and @xmath31 are mutually absolutely continuous .",
    "we define the measure @xmath31 under two different scenarios : @xmath14 is not a constant and @xmath106 .",
    "note that the measure @xmath31 obviously will depend on @xmath18 . to simplify the notation",
    ", we omit the index @xmath18 in @xmath31 whenever there is no ambiguity .",
    "the measure @xmath31 takes a mixture form of three measures , which are weighted by @xmath177 , @xmath178 and @xmath179 , respectively ( a natural constraint is that @xmath180 , @xmath181 and @xmath182 $ ] ) .",
    "we define @xmath31 through the radon  nikodym derivative @xmath183 \\\\[-8pt ] \\nonumber & & { } + { \\rho_{2 } } \\int_{t}\\frac { \\operatorname{lr}_{2}(t)}{\\operatorname{mes}(t)}\\,dt,\\end{aligned}\\ ] ] where @xmath184 will be eventually sent to 0 as @xmath18 goes to infinity at the rate @xmath185 , @xmath186 is the lebesgue measure of @xmath1 and @xmath187 the density @xmath188 is defined in ( [ denhxyz ] ) , @xmath68 is a density function on @xmath1 , @xmath189 and @xmath190 are two density functions . before presenting the specific forms of @xmath68 , @xmath189 and @xmath190 , we would like to provide an intuitive explanation of @xmath33 from a simulation point of view",
    ". one can generate @xmath0 under the measure @xmath31 via the following steps :    1 .",
    "generate @xmath191 .",
    "if @xmath192 , then : a.   generate @xmath67 uniformly from the index set @xmath1 , that is , @xmath193 ; b.   given the realized @xmath67 , generate @xmath194 ; c.   given @xmath195 , simulate @xmath196 from the original conditional distribution under @xmath176 .",
    "3 .   if @xmath197 : a.   simulate a random variable @xmath67 following the density function @xmath68 ; b.   given the realized @xmath67 , simulate @xmath198 from density function @xmath199 c.   given @xmath200 , simulate @xmath196 from the original conditional distribution under @xmath176 .",
    "thus , @xmath67 is a random index at which we twist the distribution of @xmath3 and its derivatives .",
    "the likelihood ratio at a specific location @xmath67 is given by @xmath201 , @xmath202 or @xmath203 depending on the mixture component .",
    "the distribution of the rest of the field @xmath196 given @xmath204 is the same as that under @xmath176 .",
    "it is not hard to verify that the above simulation procedure is consistent with the radon  nikodym derivative in ( [ lrv ] ) .",
    "we now provide the specific forms of the functions defining @xmath31 .",
    "we first consider the situation when @xmath205 . by condition c6",
    ", @xmath14 admits its unique maximum at @xmath206 in the interior of @xmath1 .",
    "furthermore , the hessian matrix @xmath207 is negative definite .",
    "the function @xmath68 is a density on @xmath1 such that for @xmath208 @xmath209 which is approximately a gaussian density centered around @xmath210 .",
    "as @xmath68 is defined on a compact set @xmath47 , the @xmath211 term goes to zero as @xmath18 tends to infinity .",
    "it is introduced to correct for the integral of @xmath68 outside the region @xmath1 that is exponentially small and does not affect the current analysis .",
    "the functions @xmath189 and @xmath190 are density functions on the vector space where @xmath212 lives , and they are defined as follows ( we will explain the following complicated functions momentarily ) : @xmath213 \\biggr\\ } , \\\\ & & h_{1,t}\\bigl(f(t),{\\partial f(t)},\\partial^2 f(t)\\bigr ) \\\\ & & \\qquad=\\mathbb{i}_{a_{t}^{c}}\\times h_{\\lambda_{1}}\\times u_{t } \\times e^{\\lambda_{1}u_{t } ( f(t)+({\\mathbf1^\\top\\bar f''_t}/{(2\\sigma u_t)})+{b_{t}}/{u_t}-u_{t } ) } \\times e^{- { |{\\partial f(t)}|^{2}}/{2 } } \\\\ & & \\qquad\\quad{}\\times\\exp \\biggl\\ { -\\frac{1}{2 } \\biggl [ \\frac{|\\mu_{20}\\mu_{22}^{-1}\\bar f''_{t}|^{2}}{1-\\mu_{20}\\mu_{22}^{-1}\\mu _ { 02}}+ \\biggl\\vert \\mu_{22}^{-1/2}\\bar f''_{t}- \\frac{\\mu _ { 22}^{1/2}\\mathbf{1}}{2\\sigma } \\biggr\\vert^{2 } \\biggr ] \\biggr\\},\\end{aligned}\\ ] ] where @xmath214 is the indicator function , @xmath215 is defined as in ( [ at ] ) , @xmath142 is defined as in ( [ tra ] ) , @xmath216 is positive and it will be sent to 1 as @xmath18 goes to infinity , @xmath217 is a fixed positive constant ( e.g. , @xmath218 ) and the normalizing constants are defined as @xmath219 } \\,dz \\biggr ] ^{-1 } , \\nonumber\\hspace*{-35pt } \\\\[-6pt ] \\\\[-6pt ] \\nonumber\\hspace*{-35pt } \\quad h_{\\lambda_{1}}&=&\\frac{e^{\\lambda_{1}\\eta}(1+\\lambda _ { 1})^{d/2}\\lambda _ { 1}}{(2\\pi)^{{d}/{2}}}\\\\ & & { } \\times \\biggl [ \\int_{r^{{d(d+1)}/{2}}}e^{-({1}/{2 } ) [ { |\\mu_{20}\\mu_{22}^{-1}z|^{2}}/{(1-\\mu_{20}\\mu _ { 22}^{-1}\\mu_{02})}+ \\vert\\mu_{22}^{-1/2}z-{\\mu_{22}^{1/2 } \\mathbf{1}}/{(2\\sigma ) } \\vert^{2 } ] } \\,dz \\biggr ] ^{-1}. \\nonumber\\hspace*{-35pt } \\ ] ] the constants @xmath220 and @xmath221 ensure that @xmath189 and @xmath190 are properly normalized densities .    _ understanding the measure @xmath31_. the measure @xmath31 is designed such that the distribution of @xmath3 under the measure @xmath31 is approximately the conditional distribution of @xmath3 given @xmath222 .",
    "the two terms corresponding to the probabilities @xmath178 and @xmath223 are included to ensure the absolute continuity and to control the tail of the likelihood ratio .",
    "thus , @xmath178 and @xmath179 will be sent to zero eventually .",
    "we now provide an explanation of the leading term corresponding to the probability @xmath224 .",
    "to understand @xmath189 , we use the notation @xmath140 in ( [ s ] ) and rewrite the density function as @xmath225 \\biggr\\},\\end{aligned}\\ ] ] which factorizes into three pieces consisting of @xmath140 , @xmath226 and @xmath142 , respectively .",
    "we consider the change of variables from @xmath227 to @xmath228 .",
    "then , under the distribution @xmath189 , the random vectors @xmath229 , @xmath230 and @xmath142 are independent .",
    "note that @xmath189 is defined on the set @xmath231 where @xmath232 will be send to zero eventually .",
    "then , @xmath233 is approximately an exponential random variable with rate @xmath234 ; @xmath230 , and @xmath142 are two independent gaussian random vectors .",
    "the density @xmath190 has a similar interpretation .",
    "the only difference is that @xmath190 is defined on the set @xmath235 and @xmath236 follows approximately an exponential distribution . for the last piece corresponding to @xmath179 ,",
    "the density is simply an exponential tilting of @xmath0 .    under the dominating mixture component , to generate an @xmath0 from @xmath31 , a random index @xmath67",
    "is first sampled from @xmath1 following density @xmath68 , then @xmath237 is sampled according to @xmath238 .",
    "this implies that the large value of the integral @xmath239 is mostly caused by the fact that the field reaches a high level at @xmath67 ; more precisely , @xmath240 reaches a high level of  @xmath241 ( with an exponential overshoot of rate @xmath242 ) .",
    "therefore , the random index @xmath67 localizes the position where the field @xmath140 goes very high .",
    "the distribution of @xmath67 given as in ( [ lt ] ) is very concentrated around @xmath243 .",
    "this suggests that the maximum of @xmath140 [ or @xmath0 ] is attained within @xmath244 distance from  @xmath243 .",
    "we now consider the case where @xmath245 .",
    "we choose @xmath68 to be the uniform distribution over set @xmath1 and have that @xmath246 \\\\[-8pt ] \\nonumber & & { } + { \\rho_{2}}\\int _ { t}\\frac { \\operatorname{lr}_{2}(t)}{\\operatorname{mes}(t ) } \\,dt,\\end{aligned}\\ ] ] where @xmath247 is the lebesgue measure .",
    "the following theorem states that @xmath31 is a good approximation of @xmath175 with appropriate choice of the tuning parameters .",
    "[ main ] consider a gaussian random field @xmath9 living on a domain @xmath1 satisfying conditions .",
    "if we choose the parameters defining the change of measure @xmath248 , then we have the following approximation : @xmath249 where @xmath250 is the @xmath135-field where the measures are defined .",
    "theorem [ main ] is the central result of this paper .",
    "we present its detailed proof .",
    "the technical developments of other theorems are all based on that of theorem [ main ] .",
    "therefore , we only layout their key steps and the major differences from that of theorem [ main ] .",
    "the measure @xmath31 in the limit of the above theorem obviously depends on the tuning parameters ( @xmath232 , @xmath180 , @xmath181 , and @xmath251 ) and the level @xmath18 . to simplify the notation",
    ", we omit the indices of those parameters when there is no ambiguity .",
    "the measure corresponding to the last mixture component in  ( [ lrv ] ) , @xmath252 , has been employed by @xcite to develop approximations for @xmath29 .",
    "we emphasize that the measure constructed in this paper is substantially different .",
    "in fact , the measure corresponding to @xmath253 does not appear in the main proof .",
    "we included it to control the tail of the likelihood ratio in one lemma .    to illustrate the application of the measure @xmath31",
    ", we provide a further characterization of the conditional distribution @xmath175 by presenting another approximation result which is easier to understand at an intuitive level .",
    "let @xmath254 \\\\[-8pt ] \\nonumber \\qquad{\\tilde p}_{b}\\bigl(f(\\cdot ) \\in a\\bigr ) & = & p \\bigl(f(\\cdot)\\in",
    "a| \\beta_u(t ) > u \\bigr).\\end{aligned}\\ ] ] the process @xmath255 is slightly different than @xmath140 .",
    "the following theorem states that the measure @xmath31 also approximates the distribution @xmath256 in total variation for @xmath18 large .",
    "[ sup ] consider a gaussian random field @xmath9 living on a domain @xmath1 satisfying conditions .",
    "with the same choice of tuning parameters as in theorem [ main ] , that is , @xmath257 , @xmath31 approximates @xmath256 in total variation , that is , @xmath258      the results of theorems [ main ] and [ sup ] provide both qualitative and quantitative descriptions of @xmath175 . from a qualitative point of view",
    ", theorems [ main ] and [ sup ] suggest that @xmath259 as @xmath24 .",
    "note that @xmath255 itself is a gaussian process .",
    "thus , the above convergence result connects the tail events of exponential integrals to those of the supremum of another gaussian random field that is a linear combination of @xmath3 and its derivative field .",
    "we set up this connection mainly because the distribution of gaussian random fields conditional on level crossing ( also known as the slepian model ) is very well studied for smooth processes @xcite . for the purpose of illustration , we cite one result in chapter  6.2 of @xcite when @xmath255 is stationary and twice differentiable .",
    "let covariance function of @xmath255 be @xmath260 .",
    "conditional on @xmath255 achieving a local maximum at location @xmath261 at level @xmath262 , we have the following closed form representation of the conditional field : @xmath263 where @xmath264 @xmath265 s are the spectral moments of @xmath260 , @xmath266 is a @xmath124 dimensional random vector whose density can be explicitly written down and @xmath166 is a mean zero gaussian process whose covariance function is also in a closed form ; see @xcite for the specific forms .",
    "if we set @xmath267 , the local maximum is asymptotically the global maximum .",
    "furthermore , thanks to stationarity , the distribution of @xmath261 is asymptotically uniform over @xmath1 .",
    "the overshoot @xmath268 is asymptotically an exponential random variable .",
    "thus , the conditional field @xmath255 can be written down explicitly through representation ( [ ssl ] ) , the overshoot distribution and the distribution of @xmath261 .",
    "furthermore , the conditional distribution of @xmath0 can be implied by  ( [ gammau ] ) and conditional normal calculations .",
    "from a quantitative point of view , theorem [ main ] implies that for any bounded function @xmath269 the conditional expectation @xmath270 $ ] can be approximated by @xmath271 $ ] , more precisely , @xmath272 - e^q\\bigl[\\xi(f ) \\bigr]\\rightarrow0\\ ] ] as @xmath24 .",
    "the expectation @xmath273 $ ] is much easier to compute ( both analytically and numerically ) via the following identity : @xmath274 = e^q \\bigl [ e\\bigl [ \\xi(f ) | \\imath , \\tau , f(\\tau ) , \\partial f(\\tau ) , \\partial^2 f(\\tau ) \\bigr ] \\bigr].\\ ] ] note that the inner expectation is under the measure @xmath176 in that the conditional distribution of @xmath3 given @xmath275 under @xmath31 is the same as that under  @xmath176 .",
    "furthermore , conditional on @xmath276 , the process @xmath0 is also a gaussian process and has the expansion @xmath277 these results provide sufficient tools to evaluate the conditional expectation @xmath278.\\ ] ] once the above expectation has been evaluated , we may proceed to the outer expectation in ( [ exp ] ) .",
    "note that the inner expectation is a function of @xmath279 , the joint distribution of which is in a closed form .",
    "thus , evaluating the outer expectation is usually an easier task .",
    "in fact , the proof of theorem [ main ] is an exercise of the above strategy by considering that @xmath280 .    according to the detailed proof of theorem [ main ] ,",
    "the approximation  ( [ appexp ] ) is applicable to all the functions such that @xmath281 < \\infty$ ] . to see",
    "that , we need to change the statement and the proof of lemma [ lemtv1 ] presented in section  [ secproof ] .      in the preceding subsection we constructed a change of measure that asymptotically approximates the conditional distribution of @xmath3 given @xmath282 . in this section",
    ", we construct an efficient importance sampling estimator based on this change of measure to compute @xmath29 as @xmath24 .",
    "we evaluate the overall computation efficiency using a concept that has its root in the general theory of computation in both continuous and discrete settings  @xcite .",
    "in particular , completely analogous notions in the setting of complexity theory of continuous problems lead to the notion of tractability of a computational problem @xcite .",
    "a monte carlo estimator is said to be a fully polynomial randomized approximation scheme ( fpras ) for estimating @xmath29 if , for some @xmath283 and @xmath284 , it outputs an averaged estimator that is guaranteed to have at most @xmath285 relative error with confidence at least @xmath286 in @xmath287 function evaluations .",
    "equivalently , one needs to compute an estimator @xmath288 with complexity @xmath289 @xmath290 such that @xmath291 in the literature of rare - event simulations , an estimator @xmath292 is said to be _ strongly efficient _ in estimating @xmath29 if @xmath293 and @xmath294 .",
    "suppose that a strongly efficient estimator @xmath292 has been obtained .",
    "let @xmath295 be i.i.d .",
    "copies of @xmath292 .",
    "the averaged estimator @xmath296 has a _ relative _ mean squared error equal to @xmath297 .",
    "a simple consequence of chebyshev s inequlity yields @xmath298 thus , it suffices to simulate @xmath299 i.i.d .",
    "replicates of @xmath292 to achieve the accuracy in ( [ mse ] ) .",
    "the so - called importance sampling is based on the identity @xmath300 $ ] .",
    "the random variable @xmath301 is an unbiased estimator of @xmath302 .",
    "it is well known that if one chooses @xmath303 , then @xmath301 has zero variance .",
    "the measure @xmath31 created in the previous subsection is a good approximation of @xmath175 , and thus it naturally leads an estimator for @xmath29 with small variance .",
    "in addition to the variance control , another issue is that the random fields considered in this paper are continuous objects .",
    "a computer can only perform discrete simulations .",
    "thus we must use a discrete object approximating the continuous field to implement the algorithms .",
    "the bias caused by the discretization must be well controlled relative to @xmath29 .",
    "in addition , the complexity of generating one such discrete object should also be considered in order to control the overall computational complexity to achieve an fpras .",
    "we create a regular lattice covering @xmath1 .",
    "define @xmath304 for each @xmath305 , define @xmath306 \\hbox { for } j=1,\\ldots , d \\bigr\\}\\vadjust{\\goodbreak}\\ ] ] that is , the @xmath307-cube intersected with @xmath1 and cornered at @xmath47 .",
    "furthermore , let @xmath308 since @xmath1 is compact , @xmath309 is a finite set .",
    "we enumerate the elements in @xmath310 , where @xmath311 .",
    "we further define @xmath312 and use @xmath313 as an approximation of @xmath29 where @xmath314 we have the following theorem to control the bias .    [ bias ] consider a gaussian random field @xmath3 satisfying conditions in theorem [ main ] . for any @xmath315 , there exists @xmath316 such that for any @xmath317 , if @xmath318 , then for @xmath319 @xmath320    we estimate @xmath321 using a discrete version of the change of measure proposed in the previous section . the specific algorithm is given as follows :    1 .",
    "generate a random indicator @xmath322 . if @xmath192 , then : a.   generate @xmath323 uniformly from @xmath324 ; b.   generate @xmath325 ; c.   given @xmath326 , simulate the joint field @xmath327 on the lattice @xmath328 from the original conditional distribution under @xmath176 .",
    "2 .   if @xmath197 : a.   if @xmath14 is not constant , simulate a random index @xmath323 proportional to @xmath329 , that is , @xmath330 and @xmath331 ; if @xmath106 , then @xmath323 is simulated uniformly over @xmath324 ; b.   given the realized @xmath323 , simulate @xmath332 from density function @xmath333 c.   given @xmath334 , simulate the joint field @xmath335 on the lattice @xmath336 from the original conditional distribution under @xmath176 .",
    "output @xmath337 \\\\[-8pt ] \\nonumber & & \\hspace*{200pt}{}+ { \\rho_2 } \\sum_{i=1}^m \\frac { \\operatorname{lr}_2(t_i)}{m}\\biggr).\\end{aligned}\\ ] ]    let @xmath338 be the measure induced by the above simulation scheme .",
    "then it is not hard to verify that @xmath339 , and thus @xmath340 is an unbiased estimator of @xmath321 .",
    "the next theorem states the strong efficiency of the above algorithm .",
    "[ variance ] suppose @xmath3 is a gaussian random field satisfying conditions in theorem [ main ] .",
    "if @xmath341 is chosen as in theorem [ bias ] and all the other parameters are chosen as in theorem [ main ] , then there exists some constant @xmath342 such that @xmath343    let @xmath344 be the average of @xmath69 i.i.d .",
    "copies of @xmath340 . according to the results in theorem [ bias ]",
    ", we have that @xmath345 the results of theorem [ variance ] indicate that @xmath346 if we choose @xmath347 , then @xmath348 thus , the accuracy level as in ( [ mse ] ) has been achieved .",
    "note that simulating one @xmath349 consists of generating a multivariate gaussian random vector of dimension @xmath350 .",
    "the complexity of generating such a vector is at the most @xmath351 .",
    "thus the overall complexity is @xmath352 .",
    "the proposed estimator in ( [ est1 ] ) is a fpras .",
    "the proposed algorithm can also be used to compute conditional expectations via the representation @xmath353 = e[\\xi ( f);\\break \\mathcal i(t)>b]/v(b)$ ] , where @xmath354 $ ] can be estimated by @xmath355 and @xmath29 can be estimated by @xmath356 .",
    "we use the following simple yet powerful lemma to prove theorem [ main ] .",
    "[ lemtv1]let @xmath357 and @xmath358 be probability measures defined on the same @xmath135-field @xmath359 such that @xmath360 for a positive random variable @xmath361 .",
    "suppose that for some @xmath285 , @xmath362=e^{q_{0}}[r]\\leq1+\\varepsilon$ ] .",
    "then @xmath363    @xmath364 \\bigr{\\vert}\\\\ & \\leq & e^{q_{1 } } { \\vert}r-1{\\vert}\\leq\\bigl[e^{q_{1}}(r-1)^{2 } \\bigr]^{1/2 } \\\\ & = & \\bigl ( e^{q_{1}}\\bigl[r^{2}\\bigr]-1 \\bigr ) ^{1/2}\\leq\\varepsilon^{1/2}.\\end{aligned}\\ ] ]    we also need the following approximations for the tail probability @xmath29 .",
    "this proposition is an extension of theorem 3.4 and corollary 3.5 in @xcite .",
    "we layout the key steps of its proof in the supplemental material @xcite .",
    "[ corgrf ] consider a gaussian random field @xmath9 living on a domain @xmath1 satisfying conditions .",
    "if @xmath14 has one unique maximum in @xmath1 denoted by @xmath243 , then @xmath365 where @xmath26 is as defined in ( [ u ] ) , and @xmath366 is defined as @xmath367 \\biggr\\}\\,dz.\\end{aligned}\\ ] ] if @xmath106 , @xmath366 is a constant denoted by @xmath368 . then @xmath369      to make the proof smooth , we arrange the statement of the rest supporting lemmas in the .",
    "we start the proof of theorem [ main ] when @xmath14 is not a constant .",
    "note that @xmath370 = v(b)^{-2 } e^{q } \\biggl [ \\biggl(\\frac{dp}{dq } \\biggr)^{2 } ; \\mathcal{i}(t)>b \\biggr].\\ ] ] thanks to lemma [ lemtv1 ] , we only need to show that for any @xmath371 there exists @xmath372 such that for all @xmath373 @xmath374 & = & e^q \\biggl[e_{\\imath,\\tau}^{q } \\biggl [ \\biggl(\\frac{dp}{dq } \\biggr)^{2 } ; \\mathcal{i}(t)>b \\biggr ] \\biggr]\\leq(1 + { \\varepsilon})v(b)^{2},\\end{aligned}\\ ] ] where we use the notation @xmath375=e^{q } [ \\cdot    @xmath376 and @xmath67 .",
    "@xmath377 is the random index described as in the simulation scheme admitting a density function @xmath68 if @xmath197 and @xmath378 if @xmath192 .",
    "note that @xmath379 \\\\ & & \\qquad= e_{\\imath,\\tau}^q \\biggl[e_{\\imath,\\tau}^{q } \\biggl [ \\biggl(\\frac{dp}{dq } \\biggr)^{2 } ; \\mathcal{i}(t)>b \\big| f(\\tau),\\partial f(\\tau),\\partial ^{2}f(\\tau ) \\biggr ] \\biggr].\\end{aligned}\\ ] ] for the rest of the proof , we mostly focus on the conditional expectation @xmath380.\\ ] ]    the rest of the discussion is conditional on @xmath376 and @xmath67 . to simplify notation , for a given @xmath67 ,",
    "we define @xmath381 on the set @xmath28 , @xmath382 reaches a level @xmath241 , and @xmath383=u_\\tau c(t-\\tau)$ ] .",
    "thus , @xmath384 is the field with the conditional expectation removed . from now on",
    ", we work with this shifted field @xmath384 .",
    "correspondingly , we have @xmath385 we further define the following notation : @xmath386 under the measure @xmath31 and a given @xmath67 , if @xmath197 , @xmath387 has density function @xmath388 if @xmath389",
    ", then @xmath387 follows density @xmath390 .",
    "the forms of the densities can be derived from @xmath189 , @xmath190 and @xmath391 . in particular , their expressions are given as follows : @xmath392 \\biggr\\ } , \\\\",
    "h^*_{1,\\tau}(w , y , z)&\\propto&\\mathbb{i}_{a_{\\tau}^c}\\times\\exp \\biggl\\ { \\lambda_1 u_\\tau \\biggl(w+\\frac{\\mathbf1^\\top z}{2\\sigma u_\\tau } + \\frac { b_{\\tau}}{u_\\tau } \\biggr)-\\frac{1}{2}|y|^{2 } \\biggr\\ } \\\\ & & { } \\times\\exp \\biggl\\{- \\frac{1}{2 } \\biggl[\\frac{|\\mu_{20}\\mu_{22}^{-1 } z|^2}{1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02 } } + \\biggl| \\mu_{22}^{-1/2 } z-\\frac{\\mu_{22}^{1/2}\\mathbf{1}}{2\\sigma } \\biggr|^2 \\biggr ] \\biggr\\ } , \\\\",
    "h^*_\\tau(w , y , z)&= & h(w , y , z)= \\frac{\\det(\\gamma)^{-({1}/{2})}}{(2\\pi ) ^{{(d+1)(d+2)}/{4}}}\\\\ & & \\hspace*{56pt}{}\\times \\exp \\biggl\\{- \\frac{1}{2 } \\biggl[{y}^{\\top}{y } + \\frac{{\\vert}w-\\mu_{20}\\mu_{22}^{-1}{z}{\\vert}^2}{1-\\mu_{20}\\mu _ { 22}^{-1}\\mu_{02}}+{z}^{\\top } \\mu_{22}^{-1}{z } \\biggr ] \\biggr\\},\\end{aligned}\\ ] ] and @xmath393 is defined as in ( [ at ] ) .    in the next step",
    ", we will compute @xmath394 in the form of @xmath395 .",
    "basically , we replace @xmath0 by @xmath396 , @xmath397 by @xmath398 , @xmath399 by @xmath400 and @xmath401 by @xmath402 . for the likelihood ratio terms @xmath403 and @xmath404 in ( [ lr ] ) , note that the @xmath405 terms in @xmath189 and @xmath190 cancel with those in @xmath406 ,",
    "that is , @xmath407\\biggr\\}\\\\ & & { } \\big/\\biggl(\\frac{\\det(\\gamma)^{-{1}/{2}}}{(2\\pi)^ { { ( d+1)(d+2)}/{4}}}\\\\ & & \\hspace*{13pt}{}\\times e^ { -({1}/{2 } ) [ { ( f(t)-\\mu_{20}\\mu_{22}^{-1}{\\partial^2 f(t)})^2}/{(1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02 } ) } + { \\partial^2 f(t)}^{\\top}\\mu_{22}^{-1}{\\partial^2f(t ) } ] } \\biggr).\\end{aligned}\\ ] ] we insert the notation in ( [ not ] ) and obtain that @xmath408\\biggr\\ } \\nonumber \\\\ & & { } \\times h^{-1}_{x , z } \\bigl(w_{t } + u_{\\tau } c(t-\\tau ) , z_t+u_\\tau \\partial^{2 } c(t-\\tau ) \\bigr),\\nonumber\\end{aligned}\\ ] ] where @xmath409 } , \\hspace*{-35pt}\\ ] ] which is the function @xmath126 with the @xmath410 term removed .",
    "similarly , we have that @xmath411\\biggr\\ } \\nonumber \\\\ & & { } \\times h^{-1}_{x , z } \\bigl(w_{t } + u_{\\tau } c(t-\\tau ) , z_t+u_\\tau \\partial^{2 } c(t-\\tau ) \\bigr).\\nonumber\\end{aligned}\\ ] ] with the analytic forms ( [ lr ] ) and ( [ lr1 ] ) , we proceed to the likelihood ratio in ( [ lrv ] ) @xmath412 where @xmath413 the set @xmath414 [ depending on the sample path @xmath384 ] is defined as @xmath416 we may equivalently define @xmath417 . note that @xmath418 if @xmath419 .",
    "thus , the integral @xmath420 is on the set @xmath421 , and @xmath422 is on the complement of @xmath421 .    based on the above results , we have that @xmath423\\nonumber \\\\ & & \\qquad\\leq e^{q } \\biggl \\{e^{q}_{\\imath,\\tau } \\biggl [ \\frac{1 } { [ ( 1-\\rho _ 1-\\rho _ 2)k+\\rho_1 k_1 ] ^2};\\mathcal{i}(t)>b \\biggr ] \\biggr\\ } \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\qquad\\leq e^{q } \\biggl\\{e^{q}_{\\imath,\\tau } \\biggl [ \\frac{1 } { [ ( 1-\\rho _ 1-\\rho _ 2)k ] ^2};\\mathcal{i}(t)>b , { { \\cal a}}_\\tau\\geq0 \\biggr ] \\biggr\\ } \\nonumber \\\\ & & \\qquad\\quad { } + e^{q } \\biggl\\{e^{q}_{\\imath,\\tau } \\biggl [ \\frac{1 } { [ ( 1-\\rho _ 1-\\rho _ 2)k+\\rho_1 k_1 ] ^2};\\mathcal{i}(t)>b , { { \\cal a}}_\\tau<0 \\biggr ] \\biggr\\ } , \\nonumber\\end{aligned}\\ ] ] where @xmath424 note that the term @xmath425 is not used in the main analysis .",
    "in fact , @xmath425 is only used in lemma [ lx1 ] for the purpose of localization that will be presented later .",
    "the rest of the analysis consists of three main parts .    _",
    "conditional on @xmath426 , we study the event@xmath427 and write the occurrence of this event almost as a deterministic function of @xmath428 , @xmath429 and @xmath430 , equivalently , @xmath387 .",
    "_ part _ 2 .",
    "conditional on @xmath431 , we express @xmath420 and @xmath422 as functions of @xmath432 , @xmath433 , @xmath434 with small correction terms .",
    "_ part _ 3 .",
    "we combine the results from the first two parts and obtain an approximation of ( [ part2 ] ) .",
    "all the subsequent derivations are conditional on @xmath376 and @xmath67 .",
    "to proceed , we provide the taylor expansions for @xmath395 , @xmath95 and @xmath14 :    * expansion of @xmath395 given @xmath435 .",
    "let @xmath436 .",
    "conditional on @xmath435 , we first expand the random function@xmath437+g(t-\\tau ) \\nonumber \\\\ & = & f_{*}(\\tau)+\\partial f_{*}(\\tau)^{\\top}(t- \\tau)+\\tfrac { 1}{2}(t-\\tau)^{\\top } \\delta f_{*}(\\tau ) ( t- \\tau ) \\\\ & & { } + r_{f}(t-\\tau)+g(t-\\tau ) , \\nonumber\\end{aligned}\\ ] ] where @xmath438 is the remainder term of the taylor expansion of @xmath439 $ ] .",
    "@xmath166 is a mean zero gaussian random field such that @xmath440 as @xmath441 . in addition , the distribution of @xmath166 is independent of @xmath376 , @xmath442 and @xmath443 . *",
    "expansion of @xmath95 : @xmath444 where @xmath445 and @xmath446 .",
    "* expansion of @xmath14 : @xmath447 where @xmath448 .",
    "we write @xmath449 to denote all the remainder terms .",
    "choose small constants @xmath450 and @xmath451 such that @xmath452 . by writing @xmath453 we mean that @xmath454 is chosen sufficiently small , but @xmath454 does not change with @xmath18 .",
    "let @xmath455 \\\\[-8pt ] \\nonumber & & \\hspace*{7pt}\\sup_{|t-\\tau|<u^{-1+\\delta}}|z_t - z|<u^{-\\epsilon } , \\sup _",
    "{ |t-\\tau|<u^{-1+\\delta } } \\bigl|g(t)\\bigr| < u^{-1-\\delta } \\bigr\\}.\\end{aligned}\\ ] ] by lemma [ lx1 ] whose proof uses the last component @xmath253 , we have that @xmath456&= & o(1)v^2(b).\\end{aligned}\\ ] ] therefore we only need to consider the second moment on the set @xmath457 , that is , @xmath458\\nonumber \\\\ & & \\qquad\\leq e^{q } \\biggl[e_{\\imath,\\tau}^{q } \\biggl [ \\frac{1 } { [ ( 1-\\rho _ 1-\\rho _ 2)k ] ^2};\\mathcal{e}_{b},\\mathcal{l } , { { \\cal a}}_\\tau>0 \\biggr ] \\biggr ] \\\\ & & \\qquad\\quad{}+e^{q } \\biggl[e_{\\imath,\\tau}^{q } \\biggl [ \\frac{1 } { [ ( 1-\\rho _ 1-\\rho _ 2)k+\\rho_1 k_1 ] ^2};\\mathcal{e}_{b},\\mathcal{l } , { { \\cal a}}_\\tau < 0 \\biggr ] \\biggr ] , \\nonumber\\end{aligned}\\ ] ] where @xmath420 and @xmath422 are given as in ( [ integral ] ) .",
    "we will focus on the terms on the right - hand side of ( [ der ] ) in the subsequent derivations .",
    "now , we start to carry out each part of the program .",
    "all the derivations in this part are conditional on specific values of @xmath376 , @xmath67 , @xmath428 , @xmath429 and @xmath459 , equivalently , @xmath376 , @xmath67 , @xmath460 , @xmath461 and @xmath462 . by definition ,",
    "@xmath463 we insert the expansions in ( [ expf ] ) , ( [ expc ] ) and ( [ expmu ] ) into the expression of @xmath17 and obtain that @xmath464 \\biggr\\ } \\\\ & & \\hspace*{18pt}{}\\times\\exp \\biggl\\ { \\bigl(\\sigma u-\\mu(\\tau ) \\bigr ) \\nonumber \\\\ & & \\hspace*{51pt}{}\\times \\biggl(1- \\frac { 1}{2}(t-\\tau ) ^{\\top}(t-\\tau)+c_{4}(t- \\tau)+r_{c}(t-\\tau ) \\biggr ) \\biggr\\ } \\nonumber\\\\ & & \\hspace*{17pt}{}\\times\\exp \\biggl\\{\\mu(\\tau)+\\partial\\mu(\\tau)^{\\top}(t-\\tau)+ \\frac{1}{2}(t-\\tau)^{\\top}\\delta\\mu(\\tau ) ( t-\\tau)\\nonumber\\\\ & & \\hspace*{215pt}{}+r_{\\mu } ( t- \\tau ) \\biggr\\}\\,dt,\\nonumber\\end{aligned}\\ ] ] where the first row corresponds to the expansion of @xmath465 , and the second and third rows correspond to those of @xmath95 and @xmath14 , respectively .",
    "we write the exponent inside the integral in a quadratic form of @xmath466 and obtain that@xmath467 \\\\[-8pt ] \\nonumber & & \\hspace*{102pt}{}\\times \\bigl ( t-\\tau -(ui-{\\tilde { \\mathbf{z}}})^{-1}{\\tilde y } \\bigr ) \\biggr\\ } \\nonumber \\\\ & & \\hspace*{30pt } { } \\times\\exp\\bigl\\ { \\sigma u_\\tau c_{4 } ( t-\\tau ) + \\sigma r ( t-\\tau ) \\bigr\\ } \\times \\exp\\bigl\\ { \\sigma g ( t-\\tau ) \\bigr\\ } \\,dt , \\nonumber\\end{aligned}\\ ] ] where @xmath468 and @xmath469 are defined as in ( [ not ] ) .",
    "let @xmath470 and @xmath471 be two generic positive functions .",
    "then we have the representation of the following integral : @xmath472\\int _ { t } a(s)\\,ds,\\ ] ] where @xmath473 is a random variable taking values in @xmath1 with density @xmath474 . using this representation and the change of variable that @xmath475 , we write the big integral in ( [ l4 ] ) as a product of expectations and a normalizing constant , and obtain that @xmath476 \\times e   \\bigl [ e^ { \\sigma g ( ( ui-{\\tilde{\\mathbf{z}}})^{-{1}/{2}}\\tilde { s } ) } \\bigr].\\end{aligned}\\ ] ] the two expectations in the above display",
    "are taken with respect to @xmath473 and @xmath477 given the process @xmath166 .",
    "@xmath473 is a random variable taking values in the set @xmath478 with density proportional to @xmath479 and @xmath477 is a random variable taking values in the set @xmath480 with density proportional to @xmath481 together with the definition of @xmath26 that @xmath482 , we obtain that @xmath483 if and only if @xmath484 \\\\[-8pt ] \\nonumber & & \\times e \\bigl[e^{\\sigma u_\\tau c_{4 } ( ( ui-{\\tilde{\\mathbf{z}}})^{-{1}/{2}}s ) + \\sigma r ( ( ui-{\\tilde{\\mathbf{z}}})^{-{1}/{2}}s ) } \\bigr ] \\cdot e^ { -u^{-1}\\xi_{u } } \\\\ & > & \\biggl ( \\frac{2\\pi}{\\sigma } \\biggr ) ^{d/2}u^{-d/2}e^{\\sigma u},\\nonumber\\end{aligned}\\ ] ] where @xmath485 \\bigr\\}.\\ ] ] we take log on both sides , and plug in the result of lemma [ lemexp ] that handles the big expectation term in ( [ ineq ] )",
    ". then inequality ( [ ineq ] ) is equivalent to @xmath486 \\\\[-8pt ] \\nonumber & & \\qquad > \\frac{\\xi_{u}}{u\\sigma } + \\frac{o(|w|+|y|+|z|+1)}{u^{1+\\delta_0/4}}.\\end{aligned}\\ ] ] on the set @xmath487 , we further simplify ( [ a ] ) using the following facts ( see lemma  [ lemdet ] ) : @xmath488 where @xmath489 is the trace of a matrix .",
    "therefore , on the set @xmath457 , ( [ a ] ) is equivalent to @xmath490 and further , equivalently ( by replacing @xmath26 with @xmath241 ) , @xmath491 using the notation defined as in ( [ b ] ) and ( [ ma ] ) , @xmath492 is equivalent to @xmath493 where @xmath494 is defined as in ( [ ma ] ) . furthermore , with @xmath495 and on the set @xmath487 , @xmath496 . for the above inequality , we absorb @xmath497 into @xmath498 and rewrite it as @xmath499.\\ ] ]      in part 2 , we first consider @xmath500 in the first expectation of ( [ part2 ] ) ( which is on the set @xmath501 ) and then @xmath502 in the second expectation of ( [ part2 ] ) .",
    "similarly to part 1 , all the derivations are conditional on @xmath503 .",
    "we now proceed to the second part of the proof .",
    "more precisely , we simplify the term @xmath420 defined as in ( [ integral ] ) , and write it as a deterministic function of @xmath387 with a small correction term . recall that @xmath504 \\biggr\\ } \\\\ & & \\hspace*{13pt}{}\\times h^{-1}_{x , z } \\bigl(w_{t } + u_{\\tau } c(t-\\tau ) , z_t+u_\\tau \\partial^{2 } c(t-\\tau ) \\bigr)\\,dt.\\end{aligned}\\ ] ] we plug in the forms of @xmath505 and @xmath68 that are defined in ( [ denh ] ) and ( [ lt ] ) and obtain that @xmath506 \\biggr\\ } \\\\ & & \\hspace*{26pt}{}\\times\\exp \\biggl\\ { \\frac{1}{2 } \\biggl[\\frac { ( w_{t}+u_\\tau c(t-\\tau)-\\mu_{20}\\mu _ { 22}^{-1}({z_t+\\mu_2(t-\\tau)u_\\tau } ) ) ^2}{1-\\mu_{20}\\mu _ { 22}^{-1}\\mu_{02 } } \\\\ & & \\hspace*{90pt } { } + \\bigl({z_t+\\mu_2(t-\\tau)u_\\tau } \\bigr)^{\\top } \\mu_{22}^{-1}{\\bigl(z_t+ \\mu_2(t-\\tau)u_\\tau\\bigr ) } \\biggr ] \\biggr\\ } \\,dt.\\end{aligned}\\ ] ] for some @xmath507 such that @xmath508 , where @xmath509 are the parameters we used to define  @xmath457 , we further restrict the integration region by defining @xmath510 \\biggr\\ } \\nonumber \\\\ & & \\hspace*{6pt}{}\\times\\exp \\biggl\\ { \\frac{1}{2 } \\biggl[\\frac { ( w_{t}+u_\\tau c(t-\\tau)-\\mu_{20}\\mu _ { 22}^{-1}({z_t+\\mu_2(t-\\tau)u_\\tau } ) ) ^2}{1-\\mu_{20}\\mu _ { 22}^{-1}\\mu_{02 } } \\nonumber \\\\ & & \\hspace*{71pt } { } + \\bigl({z_t+\\mu_2(t-\\tau)u_\\tau } \\bigr)^{\\top } \\mu_{22}^{-1}{\\bigl(z_t+ \\mu_2(t-\\tau)u_\\tau\\bigr ) } \\biggr ] \\biggr\\ } \\,dt .",
    "\\nonumber\\end{aligned}\\ ] ] thus @xmath511 for the rest of part 2.1 , we focus on @xmath512 . with some tedious algebra ,",
    "lemma [ lemi2 ] writes @xmath512 in a more manageable form ; that is , @xmath512 equals @xmath513\\nonumber\\\\ & & \\hspace*{41pt}{}+ \\frac{(1-\\lambda)}{2\\sigma } \\mathbf1^\\top \\bigl(z_t-\\mu_{02}u_t+ \\mu_2(t-\\tau)u_\\tau \\bigr ) -\\lambda b_{t}- \\frac{\\mathbf1^\\top\\mu_{22}\\mathbf1}{8\\sigma ^2 } \\biggr\\ } \\nonumber \\\\[-6pt ] \\\\[-6pt ] \\nonumber & & \\hspace*{6pt } { } \\times\\exp \\bigl\\{\\bigl(\\bigl ( w_{t}+u_\\tau c(t-\\tau)-u_t \\bigr)^2 \\\\ & & \\hspace*{43pt}{}-2 \\bigl(w_{t}+u_\\tau c(t-\\tau)-u_t \\bigr)\\mu_{20}\\mu_{22}^{-1 } { \\bigl(z_t-\\mu _ { 02}u_t+\\mu_2(t-\\tau)u_\\tau \\bigr)}\\bigr)\\nonumber\\\\ & & \\hspace*{232pt}{}/{\\bigl(2 \\bigl(1-\\mu_{20}\\mu _ { 22}^{-1}\\mu _ { 02 } \\bigr)\\bigr ) } \\bigr\\}\\,dt . \\nonumber\\end{aligned}\\ ] ] lemma [ lema ] implies that @xmath514 .",
    "thus , on the set @xmath515 , we have latexmath:[$a^*\\cap\\{|t-\\tau    @xmath421 from the integration region of @xmath517 .",
    "in addition , on the set @xmath457 and @xmath518 , we have that @xmath519 we insert the above estimates to ( [ i2 ] ) . together with the fact that @xmath520 we have that @xmath521 \\\\ & & \\hspace*{99pt } { } + ( 1-\\lambda)\\frac{\\mathbf1^\\top z}{2\\sigma } + \\frac { w_{t}^{2}-2w_{t}\\mu_{20}\\mu_{22}^{-1}z_t+o(1)w_{t}}{2 ( 1-\\mu _ { 20}\\mu_{22}^{-1}\\mu_{02 } ) } \\biggr\\}\\,dt.\\end{aligned}\\ ] ] further , we have that @xmath522 let @xmath523 , and we simplify @xmath517 to @xmath524 + ( 1- \\lambda)\\frac { \\mathbf 1^\\top z}{2\\sigma } \\biggr\\}\\,dt.\\end{aligned}\\ ] ] in what follows",
    ", we insert the expansions in ( [ expf ] ) , ( [ expc ] ) and ( [ expmu ] ) into the expression of @xmath512 and write the exponent as a quadratic function of @xmath525 , and we obtain that on the set @xmath526 @xmath527 \\\\[-8pt ] \\nonumber & & { } \\times\\int_{|t-\\tau|<u^{-1+\\delta ' } } e^{-({1}/{2})(1-\\lambda)(u_\\tau+\\zeta_{u } ) ( t-\\tau -({u}i-{\\tilde{\\mathbf{z}}})^{-1}{{\\tilde y } } ) ^{\\top } ( { u}i-{\\tilde { \\mathbf{z } } } ) ( t-\\tau-({u}i-{\\tilde{\\mathbf{z}}})^{-1}{{\\tilde y } } ) } \\\\ & & \\hspace*{67pt}{}\\times e^{(1-\\lambda)(u_\\tau+\\zeta_{u } ) [ { u_\\tau}c_{4}(t-\\tau ) + r(t-\\tau)+g(t-\\tau )   ] } \\,dt,\\nonumber\\end{aligned}\\ ] ] where we recall that @xmath528 and @xmath529 .",
    "this derivation is very similar to that from ( [ i1 ] ) to ( [ l4 ] ) . in the last row of the above display , on the set @xmath530 and @xmath531",
    ", @xmath532 therefore , they can be ignored .",
    "we consider the change of variable that @xmath533 and obtain that @xmath512 equals ( with the terms @xmath534 and @xmath535 removed ) @xmath536 \\\\[-8pt ] \\nonumber & & \\times \\int_{s\\in\\mathcal s_{u } } e^{-({1}/{2}){\\vert}s-(1-\\lambda)^{1/2}(u_\\tau+\\zeta_u)^{1/2}({u}i- { \\tilde{\\mathbf{z}}})^{-1/2}{\\tilde y}{\\vert}^{2 } } \\,ds \\nonumber \\\\ & & \\times e \\bigl[e^{(1-\\lambda)({u_\\tau}+\\zeta_u)g ( ( 1-\\lambda ) ^{-1/2}(u_\\tau+\\zeta_u)^{-1/2 } ( { u}i-{\\tilde{\\mathbf{z}}})^{-1/2}s^{\\prime } ) } \\bigr ] , \\nonumber\\end{aligned}\\ ] ] where @xmath537 , and @xmath538 is a random variable taking values on the set @xmath539 with density proportional to @xmath540 we use @xmath541 to denote the last two terms of ( [ inter0 ] ) , that is , @xmath542 \\\\[-8pt ] \\nonumber & & \\hspace*{14pt}{}\\times e \\bigl[e^{(1-\\lambda)({u_\\tau}+\\zeta_u)g ( ( 1-\\lambda ) ^{-1/2}(u_\\tau+\\zeta_u)^{-1/2 } ( { u}i-{\\tilde{\\mathbf{z}}})^{-1/2}s^{\\prime } ) } \\bigr].\\end{aligned}\\ ] ] it is helpful to keep in mind that @xmath541 is approximately @xmath543 .",
    "we insert @xmath541 back to the expression of @xmath512 . together with the fact that @xmath544 , we have @xmath545 \\\\[-8pt ] \\nonumber & & { } \\times\\exp \\biggl\\{(1-\\lambda ) ( u_\\tau+\\zeta_{u } ) \\biggl((1+\\zeta _ { u})w+\\frac{|\\tilde y|^{2}}{2u_\\tau } + \\frac{\\mathbf1^\\top z}{2\\sigma u_\\tau } \\biggr ) \\biggr\\}. \\nonumber\\end{aligned}\\ ] ] thus , we have that on the set @xmath546 , @xmath547 we further insert the @xmath494 defined in ( [ ma ] ) into ( [ kk ] ) and obtain that @xmath548 \\\\[-8pt ] \\nonumber & & \\times \\exp \\biggl\\{\\frac{1}{2}u_{t_*}^2- b_{t_{*}}- \\frac{\\mathbf1^\\top \\mu _ { 22}\\mathbf1}{8\\sigma^2}+(1-\\lambda)u_\\tau\\bigl(1+o(1 ) \\bigr){{\\cal a}}_\\tau\\\\ & & \\hspace*{132pt}{}+ ( 1-\\lambda ) \\zeta_{u}\\cdot \\bigl(|\\tilde y|^{2}+|z| \\bigr ) \\biggr\\}. \\nonumber\\end{aligned}\\ ] ]      in this part , we focus mostly on the @xmath422 term , whose handling is very similar to that of @xmath420 . therefore , we only list out the key steps . for some large constant @xmath551 ,",
    "let @xmath552 that is , the dominating region of the integral .",
    "we split the set @xmath553 .",
    "there are two situations : @xmath554 and @xmath555 .",
    "for the first situation , the term @xmath422 is dominating ; for the second situation , the term @xmath420 ( more precisely @xmath517 ) is dominating .",
    "to simplify @xmath422 , we write it as @xmath556 \\\\ & \\triangleq&(2\\pi)^{{(d+1)(d+2)}/{4}-{d}/{2}}\\det(\\gamma ) ^{{1}/{2 } } \\cdot{\\det \\bigl(-\\delta\\mu_\\sigma(t_*)\\bigr)^{1/2}u_{t_*}^{d/2}}h_{\\lambda_1}\\\\ & & { } \\times [ \\mathcal{i}_{1,2}+\\mathcal{i}_{1,3 } ] .\\end{aligned}\\ ] ] note that the difference between @xmath557 and @xmath420 is that the term `` @xmath558 '' has been replaced by `` @xmath559 . '' with exactly the same derivation for ( [ i2 ] ) , we obtain that @xmath560 equals [ by replacing `` @xmath558 '' in ( [ i2 ] ) by `` @xmath561 '' ] @xmath562\\nonumber\\\\ & & \\hspace*{56pt}{}+ \\frac{(1+\\lambda_1)}{2\\sigma}\\mathbf1^\\top \\bigl(z_t-\\mu _ { 02}u_t+\\mu _ 2(t-\\tau)u_\\tau \\bigr )   + \\lambda_1 b_t- \\frac{\\mathbf1^\\top\\mu _ { 22}\\mathbf1}{8\\sigma^2 } \\biggr\\ } \\nonumber \\\\ & & \\qquad{}\\times\\exp \\bigl\\{\\bigl ( \\bigl(w_t+u_\\tau c(t-\\tau)-u_t \\bigr)^2 \\\\ & & \\hspace*{57pt}{}-2 \\bigl(w_t+\\bigl(u_\\tau c(t-\\tau)-u_t\\bigr ) \\bigr)\\nonumber\\\\ & & \\hspace*{57pt}{}\\times \\mu_{20}\\mu_{22}^{-1 } { \\bigl(z_t-\\mu _ { 02}u_t+\\mu_2(t-\\tau)u_\\tau \\bigr)}\\bigr)\\nonumber\\\\ & & \\hspace*{135pt}{}/ \\bigl ( 2 \\bigl(1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02 } \\bigr)\\bigr ) \\bigr\\}\\,dt . \\nonumber\\end{aligned}\\ ] ] with a very similar derivation as in part 2.1 , in particular , the result in ( [ lrd ] ) , we have that @xmath563 \\biggr\\ } \\nonumber\\hspace*{-25pt } \\\\ & & \\times\\exp \\bigl\\{(1+\\lambda_1 ) ( u_\\tau+ \\zeta_{u } ) \\bigl[{u_\\tau}c_{4}(t-\\tau)+r(t- \\tau)+g(t-\\tau ) \\bigr ] \\bigr\\ } \\,dt .",
    "\\nonumber\\hspace*{-25pt}\\end{aligned}\\ ] ] furthermore , similarly to the results in ( [ ii2 ] ) , we have that @xmath564 \\\\[-8pt ] \\nonumber & & { } \\times e^{(1+\\lambda_1)(u_\\tau+\\zeta_{u } ) ( ( 1+\\zeta _ { u})w+ ( { 1}/{2}){\\tilde y}^{\\top}({u}i-{\\tilde{\\mathbf{z}}})^{-1}{\\tilde y } + { \\mathbf1^\\top z}/{(2\\sigma u_\\tau ) } ) } , \\end{aligned}\\ ] ] where @xmath565 is defined as @xmath566,\\end{aligned}\\ ] ] the change of variable @xmath567 and @xmath568 is a random variable taking values in the set @xmath569 with an appropriately chosen density function similarly as in ( [ inter0 ] ) . in summary ,",
    "the only difference between @xmath560 and @xmath512 lies in that the multiplier @xmath558 is replaced by @xmath559 .",
    "we now proceed to providing a lower bound of @xmath570 .",
    "note that @xmath571 therefore at least one of @xmath572 and @xmath573 is nonempty .",
    "if @xmath574 , we have the bound @xmath575 similarly , if @xmath576 , we have that @xmath577 we further split @xmath512 in part 2.1 into two parts : @xmath578 similarly to the derivation of @xmath579 , we have that @xmath580 where @xmath581 \\\\[-8pt ] \\nonumber & & \\times e \\bigl[e^{(1-\\lambda)({u_\\tau}+\\zeta_u)g ( ( 1-\\lambda ) ^{-1/2}(u_\\tau+\\zeta_u)^{-1/2 } ( { u}i-{\\tilde{\\mathbf{z}}})^{-1/2}s_{2,1 } ) } \\bigr ] . \\ ] ] @xmath582 is a random variable taking values on the set @xmath583 with an appropriate density function similarly as in ( [ inter0 ] ) and @xmath584 .    then combining the above results of @xmath560 and @xmath585",
    ", we have that for the case in which @xmath586 @xmath587 \\\\ & & \\qquad\\geq \\theta(1 ) u^{-d/2 + 1 } e^{({1}/{2})u_{t_*}^2 } \\\\ & & \\qquad\\quad{}\\times \\bigl [ \\mathbb{i}_{c_{1}}\\cdot\\rho_1\\kappa_{1,2 } e^{(1+\\lambda _ 1)(u_\\tau+\\zeta_{u } ) ( ( 1+\\zeta_{u})w+{|\\tilde y|^{2}}/{(2u_\\tau)}+ { \\mathbf1^\\top z}/{(2\\sigma u_\\tau ) } ) } \\\\ & & \\hspace*{16pt}\\qquad\\quad { } + \\mathbb{i}_{c_{2}}\\cdot(1-\\rho_1-\\rho_2 ) ( 1-\\lambda)^{-d/2}\\kappa _ { 2,1}\\\\ & & \\hspace*{90pt}{}\\times e^{(1-\\lambda)(u_\\tau+\\zeta_{u } )   ( ( 1+\\zeta_{u})w+ { |\\tilde y|^2}/{(2u_\\tau)}+ { \\mathbf1^\\top z}/{(2\\sigma u_\\tau ) } ) } \\bigr],\\end{aligned}\\ ] ] where @xmath588 and @xmath589 .",
    "we further insert @xmath494 defined in ( [ ma ] ) .",
    "note that on the set @xmath590 , @xmath591 and @xmath144 is bounded away from zero and infinity",
    ". then @xmath592.\\nonumber\\end{aligned}\\ ] ]      we now put together the results in parts 1 and 2 and obtain an approximation for ( [ part2 ] ) .",
    "recall that @xmath593\\nonumber\\\\[-2pt ] & & \\qquad \\leq e^{q } \\biggl [ \\frac{1 } { [ ( 1-\\rho_{1}-\\rho_{2})k ] ^{2}};\\mathcal{e}_{b } , \\mathcal{l},{{\\cal a}}_{\\tau}\\geq0 \\biggr ] \\\\[-2pt ] & & \\qquad\\quad{}+e^{q } \\biggl [ \\frac{1 } { [ ( 1-\\rho_{1}-\\rho_{2})k+\\rho_{1}k_{1 } ] ^{2}};\\mathcal{e}_{b},\\mathcal{l},{{\\cal a}}_{\\tau}<0 \\biggr].\\nonumber\\end{aligned}\\ ] ] we consider the two terms on the right - hand side of the above display one by one .",
    "we start with the first term @xmath594 ^{2 } } ; \\mathcal{e}_{b},\\mathcal{l},{{\\cal a}}_{\\tau}\\geq0 \\biggr ] \\nonumber\\\\[-2pt ] & & \\qquad= e^{q } \\biggl [ \\frac{1 } { [ ( 1-\\rho_{1}-\\rho_{2})k ] ^{2 } } ; \\mathcal{e}_{b } , \\mathcal{l},{{\\cal a}}_{\\tau}\\geq0 , \\imath=0 \\biggr ] \\\\[-2pt ] & & \\qquad\\quad{}+ e^{q } \\biggl [ \\frac{1 } { [ ( 1-\\rho_{1}-\\rho_{2})k ] ^{2}};\\mathcal{e}_{b } , \\mathcal{l } , { { \\cal a}}_{\\tau}\\geq0 , \\imath=1 \\biggr ] . \\nonumber\\end{aligned}\\ ] ] the index @xmath67 admits density @xmath68 when @xmath197 and @xmath67 is uniformly distributed over @xmath1 if @xmath192 .",
    "consider the first expectation in ( [ 1st ] ) .",
    "note that conditionally on @xmath67 and @xmath197 , on the set @xmath595 , @xmath387 follows density @xmath596 defined as in ( [ hall * ] ) .",
    "thus , according to ( [ kkk ] ) , we have that the conditional expectation @xmath597 \\nonumber\\\\[-2pt ] & & \\qquad\\leq\\bigl(1+o(1)\\bigr ) \\biggl [ \\frac{h_{\\lambda}^{-1}\\det(\\gamma ) ^{-{1}/{2}}\\det ( -\\delta\\mu_{\\sigma}(t_{\\ast}))^{-1/2}}{(2\\pi)^ { { ( d+1)(d+2)}/{4}-{d}/{2}}}\\nonumber\\\\[-2pt ] & & \\hspace*{82pt}{}\\times{(1-\\lambda)^{d/2}u^{d/2 - 1}}e^{-({1}/{2})u_{t_*}^{2}+b_{t_{\\ast } } + { \\mathbf{1}^{\\top}\\mu _ { 22}\\mathbf { 1}}/{(8\\sigma^{2 } ) } } \\biggr ] ^{2 } \\\\[-2pt ] & & \\qquad\\quad{}\\times\\int_{{\\cal a}_{\\tau}>0,\\mathcal{l}}e^{-2(1-\\lambda ) u ( ( 1+o(1)){{\\cal a}}_{\\tau}+o({|y|^{2}}/{(2u)}+{\\mathbf { 1}^{\\top } z}/{(2\\sigma u ) } ) ) } \\cdot \\gamma_{u}(u\\sigma{{\\cal a}}_\\tau ) \\nonumber\\\\[-2pt ] & & \\hspace*{81pt}{}\\times \\frac{1-\\rho_1-\\rho_2}{1-\\rho_2}h_{0,\\tau}^{\\ast } ( w , y , z)\\,dw\\,dy\\,dz , \\nonumber\\end{aligned}\\ ] ] where @xmath598 & & \\hspace*{53pt } x > \\bigl(1+o\\bigl(u^{-1-\\delta_0/4}\\bigr)\\bigr)\\bigl[\\xi_u + o \\bigl(u^{-\\delta_0/8}\\bigr)\\bigr]\\big{\\vert}\\imath , \\tau , w,{y},{z } \\biggr],\\end{aligned}\\ ] ] with the expectation taken with respect to the process @xmath166 .",
    "we insert the analytic form of @xmath599 into ( [ hall * ] ) and obtain that @xmath600\\nonumber \\\\ & & \\hspace*{205pt}{}-\\frac{1-\\lambda}{2}{y}^{\\top}y \\biggr\\ } \\,d{{\\cal a}}_{\\tau } \\,dy\\,dz.\\nonumber\\end{aligned}\\ ] ] thanks to the borel  tis inequality ( lemma [ lemborel ] ) , lemma lemremainder and the definition of  @xmath541 in ( [ kappa ] ) , for @xmath601 , @xmath602 is bounded and as @xmath24 , @xmath603 \\biggr ] \\rightarrow ( 2\\pi)^{-d}.\\ ] ] thus , by the dominated convergence theorem and with @xmath220 defined as in ( [ hl ] ) , as @xmath159 , we have that @xmath604 we insert it back to ( [ 111 ] ) and obtain that@xmath605 \\nonumber \\\\ & & \\qquad\\leq\\bigl(1+o(1)\\bigr)\\frac{(2\\pi)^{-d}}{(1-\\rho_{1}-\\rho_{2})(1-\\rho _ 2)}\\frac{e^{-\\lambda\\eta}\\lambda}{2-\\lambda } \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\qquad\\quad{}\\times \\biggl [ \\frac{h_{\\lambda}^{-1}\\det(\\gamma)^{- { 1}/{2}}\\det ( \\delta \\mu_{\\sigma}(t_{\\ast}))^{-1/2}}{(2\\pi)^{{(d+1)(d+2)}/{4}-{d}/{2}}}\\\\ & & \\hspace*{49pt}{}\\times { ( 1-\\lambda)^{d/2}u^{d/2 - 1}}e^{-({1}/{2})u_{t_*}^{2}+b_{t_{\\ast } } + { \\mathbf{1}^{\\top}\\mu_{22}\\mathbf{1}}/{(8\\sigma ^{2 } ) } } \\biggr ] ^{2}. \\nonumber\\end{aligned}\\ ] ] using the asymptotic approximation of @xmath29 given by proposition [ corgrf ] , we obtain that @xmath606 ^{2}};\\mathcal{e}_{b},\\mathcal{l},{{\\cal a}}_{\\tau}\\geq0,\\imath=0 \\biggr ] \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\qquad\\leq \\frac { 1+o(1)}{1-\\rho_{1}-\\rho_{2}}\\frac{e^{\\lambda\\eta } } { \\lambda(2-\\lambda)}v^{2}(b).\\end{aligned}\\ ] ] we choose @xmath607 then , the right - hand side of the above inequality is bounded by @xmath608 for @xmath18 sufficiently large .",
    "the handling of the second term of ( [ 1st ] ) is similar except that @xmath609 follows density @xmath610 .",
    "thus , we only mention the key steps .",
    "note that @xmath611 \\nonumber \\\\ & & \\hspace*{-2pt}\\qquad=\\bigl(1+o(1)\\bigr ) \\biggl [ \\frac{h_{\\lambda}^{-1}\\det(\\gamma ) ^{-{1}/{2}}\\det ( -\\delta\\mu_{\\sigma}(t_{\\ast}))^{-1/2}}{(2\\pi)^ { { ( d+1)(d+2)}/{4}-{d}/{2}}}\\nonumber\\\\ & & \\qquad\\hspace*{59pt}{}\\times{(1-\\lambda)^{d/2}u^{d/2 - 1}}e^{- ( { 1}/{2})u_{t_*}^{2}+b_{t_{\\ast}}+{\\mathbf{1}^{\\top}\\mu _ { 22}\\mathbf { 1}}/{(8\\sigma^{2 } ) } } \\biggr ] ^{2 } \\\\ & & \\hspace*{-2pt}\\qquad\\quad{}\\times\\frac{\\det(\\gamma)^{-{1}/{2}}}{(2\\pi)^ { { ( d+1)(d+2)}/{4 } } } \\nonumber \\\\ & & \\hspace*{-2pt}\\qquad\\quad{}\\times \\int_{{{\\cal a}}_{\\tau}\\geq0,\\mathcal{l } } \\gamma_{u}(u \\sigma{{\\cal a}}_{\\tau})\\nonumber \\\\ & & \\hspace*{78pt}{}\\times\\exp\\biggl\\{-2(1-\\lambda)u\\mathcal a_{\\tau}\\nonumber\\\\ & & \\hspace*{111pt}{}-\\frac{1+o(1)}{2 } \\nonumber\\\\ & & \\hspace*{122pt}{}\\times\\biggl [ { y}^{\\top}y+\\frac{|w-\\mu_{20}\\mu_{22}^{-1}z|^{2}}{1-\\mu_{20}\\mu _ { 22}^{-1}\\mu_{02}}+z^{\\top}\\mu_{22}^{-1}z \\biggr ] \\biggr\\}\\,d{{\\cal a}}_{\\tau}\\,dy\\,dz \\nonumber \\\\ & & \\hspace*{-2pt}\\qquad = o(1 ) ( 1-\\lambda)^{-1}u^{-1}\\cdot{u^{d-2}}e^{-u_{t_*}^{2}}.\\nonumber\\end{aligned}\\ ] ] according to the asymptotic form of @xmath29 and with @xmath612 , we have that @xmath613 ^{2}};\\mathcal{e}_{b},\\mathcal{l},{{\\cal a}}_{\\tau}\\geq0,\\imath=1 \\biggr ] \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\qquad = o(1 ) \\rho_2(1-\\lambda)^{-1}u^{-1}\\cdot { u^{d-2}}e^{-u_{t_*}^{2 } } = o(1)v^{2}(b).\\end{aligned}\\ ] ] therefore , combining the results in ( [ 11st ] ) and ( [ 22nd ] ) , we have the first term in  ( [ part3cal ] ) is bounded by @xmath614 .",
    "the last step is to show that the second term of ( [ part3cal ] ) is of a smaller order of @xmath615 .",
    "first , we split the expectation@xmath616 ^{2 } } ; \\mathcal{e}_{b},\\mathcal{l},{{\\cal a}}_{\\tau}<0 \\biggr ] \\nonumber\\\\ & & \\qquad = e^{q } \\biggl [ \\frac{1 } { [ ( 1-\\rho_{1}-\\rho_{2})k+\\rho _ { 1}k_{1 } ] ^{2}};\\mathcal{e}_{b } , \\mathcal{l},{{\\cal a}}_{\\tau}<0,\\imath=1 \\biggr ] \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\qquad\\quad{}+e^{q } \\biggl [ \\frac{1 } { [ ( 1-\\rho_{1}-\\rho_{2})k+\\rho _ { 1}k_{1 } ] ^{2}};\\mathcal{e}_{b } , \\mathcal{l},-\\eta / u_{\\tau}<{{\\cal a}}_{\\tau } < 0,\\imath = 0 \\biggr ] \\nonumber \\\\ & & \\qquad\\quad{}+e^{q } \\biggl [ \\frac{1 } { [ ( 1-\\rho_{1}-\\rho_{2})k+\\rho _ { 1}k_{1 } ] ^{2}};\\mathcal{e}_{b } , \\mathcal{l},{{\\cal a}}_{\\tau}\\leq-\\eta / u_{\\tau } , \\imath=0 \\biggr ] .",
    "\\nonumber\\end{aligned}\\ ] ] we study these three terms one by one . let@xmath617 ^{2 } } ; \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\hspace*{22pt } x>\\bigl(1+o\\bigl(u^{-1-\\delta_0/4}\\bigr)\\bigr)\\bigl[\\xi_u + o \\bigl(u^{-\\delta_0/8}\\bigr)\\bigr ] \\big\\vert \\imath,\\tau , w,{y},{z } \\biggr ] \\nonumber .\\end{aligned}\\ ] ] we start with the first expectation in ( [ e2 ] ) . plugging in the lower bound for @xmath618 derived in ( [ 3star ] ) , we have @xmath619 ^{2 } } ; \\mathcal{e}_{b},\\mathcal{l},{{\\cal a}}_{\\tau}<0 \\big| \\imath = 1,\\tau \\biggr ] \\nonumber\\\\ & & \\qquad = o(1){u^{d-2}}e^{-u_{t_*}^{2}}\\nonumber\\\\ & & \\qquad\\quad{}\\times \\int_{{{\\cal a}}_{\\tau}<0}\\gamma _ { 1,u}(u\\sigma{{\\cal a}}_{\\tau } ) \\\\ & & \\hspace*{73pt}{}\\times\\exp\\biggl\\{-2(1+\\lambda_{1})u{{\\cal a}}_{\\tau}\\nonumber\\\\ & & \\hspace*{106pt}{}-\\frac{1}{2 } \\biggl [ { y}^{\\top } y+\\frac { |w-\\mu_{20}\\mu_{22}^{-1}z|^{2}}{1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02}}+z^{\\top}\\mu_{22}^{-1}z \\biggr ] \\biggr\\}\\,d { { \\cal a}}_{\\tau}\\,dy\\,dz . \\nonumber\\end{aligned}\\ ] ] we deal with the @xmath620 term in the above integration . on the set @xmath457 , @xmath621 . by lemma [ lemgamma ] , for @xmath622",
    ", there exists a constant @xmath623 such that @xmath624\\big \\vert\\imath , \\tau , w,{y},{z},c_1 \\biggr]\\\\ & & \\qquad = o(1)\\rho _ { 1}^{-2}e^{u^{\\delta^{\\ast}}x}\\end{aligned}\\ ] ] and @xmath625 \\big\\vert \\imath , \\tau , w,{y},{z},c_2 \\biggr ] \\\\ & & \\qquad = o(1 ) ( 1-\\rho_{1}-\\rho_{2})^{-2}(1- \\lambda)^{-d}e^{u^{\\delta ^{\\ast}}x}.\\end{aligned}\\ ] ] therefore , the above approximations and the dominated convergence theorem imply that conditionally on @xmath457 , @xmath626 thus , ( [ add1 ] ) equals @xmath627 taking expectation of the above equation with respect to @xmath376 and @xmath67 and choosing @xmath184 and @xmath628 be @xmath629 , we have @xmath630 ^{2}};\\mathcal{e}_{b } , \\mathcal{l},{{\\cal a}}_{\\tau}<0,\\imath=1 \\biggr ] = o(1)v^2(b).\\ ] ] for the second term in ( [ 222 ] ) , with the same bound of @xmath631 , we have @xmath632 ^{2}};\\mathcal{e}_{b } , \\mathcal{l},-\\eta / u_{\\tau}<{{\\cal a}}_{\\tau}<0 \\big| \\imath=0,\\tau \\biggr ] \\\\ & & \\qquad = o(1){u^{d-2}}e^{-u_{t_*}^{2}}\\\\ & & \\qquad\\quad{}\\times{u_{\\tau } } \\int_{-{\\eta}/{u_{\\tau}}<{{\\cal a}}_{\\tau}<0}\\gamma _ { 1,u}(u\\sigma { { \\cal a}}_{\\tau})e^{-2(1+\\lambda_{1})u{{\\cal a}}_{\\tau}}e^{-\\lambda u_{\\tau } { { \\cal a}}_{\\tau } } \\\\ & & \\qquad\\quad\\times\\exp \\biggl\\ { -\\frac{1}{2 } \\biggl [ \\frac{|\\mu_{20}\\mu_{22}^{-1}z|^{2}}{1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02}}+ \\biggl\\vert\\mu_{22}^{-1/2}z-\\frac{\\mu_{22}^{1/2}\\mathbf { 1}}{2\\sigma}\\biggr\\vert^{2 } \\biggr ] \\\\ & & \\hspace*{201pt}{}-\\frac{1-\\lambda}{2}{y}^{\\top}y \\biggr\\ } \\,d{{\\cal a}}_{\\tau}\\,dy\\,dz \\\\ & & \\qquad = o(1)\\cdot\\max\\bigl\\{\\rho_1^{-2 } , ( 1- \\lambda)^{-2d}\\bigr\\}\\cdot u^{-\\delta ^*}\\cdot{u^{d-2}}e^{-u_{t_*}^{2 } } \\\\ & & \\qquad= o(1)v^2(b),\\end{aligned}\\ ] ] and similarly for the third term in ( [ 222 ] ) , @xmath633 ^{2 } } ; \\mathcal{e}_{b},\\mathcal{l},{{\\cal a}}_{\\tau}\\leq-\\eta /u_{\\tau } \\big| \\imath=0,\\tau \\biggr ] \\nonumber \\\\ & & \\qquad = o(1)\\rho_1\\cdot{u^{d-2}}e^{-u_{t_*}^{2}}u_\\tau \\nonumber\\\\ & & \\qquad\\quad{}\\times\\int_{{{\\cal a}}_{\\tau } < -{\\eta}/{u_{\\tau}}}\\gamma_{1,u}(u\\sigma{{\\cal a}}_{\\tau } ) \\nonumber \\\\ & & \\qquad\\quad{}\\times e^{-2(1+\\lambda_{1})u{{\\cal a}}_{\\tau}}\\nonumber\\\\ & & \\qquad\\quad{}\\times\\exp\\biggl\\{\\lambda_{1}u_{\\tau}{{\\cal a}}_{\\tau}\\\\ & & \\hspace*{32pt}\\qquad\\quad{}-\\frac{1}{2 } \\biggl [ \\frac{|\\mu_{20}\\mu_{22}^{-1}z|^{2}}{1-\\mu _ { 20}\\mu _ { 22}^{-1}\\mu_{02}}+ \\biggl\\vert\\mu_{22}^{-1/2}z-\\frac{\\mu_{22}^{1/2 } \\mathbf{1}}{2\\sigma } \\biggr\\vert^{2 } \\biggr ] \\nonumber\\\\ & & \\hspace*{200pt}{}-\\frac{1+\\lambda _ { 1}}{2}{y}^{\\top}y\\biggr\\}\\,d{{\\cal a}}_{\\tau}\\,dy\\,dz \\nonumber \\\\ & & \\qquad = o(1)\\rho_1\\cdot\\max\\bigl\\{\\rho_1^{-2 } , ( 1- \\lambda)^{-2d}\\bigr\\}\\cdot u^{-\\delta^*}\\cdot { u^{d-2}}e^{-u_{t_*}^{2 } } \\nonumber \\\\ & & \\qquad= o(1)v^2(b).\\nonumber\\end{aligned}\\ ] ]    we put all the estimates in ( [ 11st ] ) , ( [ 22nd ] ) , ( [ 33rd ] ) and ( [ 44th ] ) back to ( [ part3cal ] ) . for any @xmath285",
    ", if we choose @xmath634 , then for @xmath18 sufficiently large we have that @xmath635 \\leq(1 + 3\\varepsilon)v^{2}(b).\\ ] ] we complete the proof of theorem [ main ] for the case that @xmath636 .",
    "the proof when @xmath106 is very similar , except that we need to consider two situations : first , @xmath637 is not close to the boundary of @xmath1 and otherwise .",
    "more precisely , for a given @xmath638 small enough , we consider the case when @xmath639 and otherwise .",
    "for the first situation , @xmath67 is `` far away '' from the boundary of @xmath1 , which is the important case , the derivation is same as that of the case where @xmath14 is not a constant . for the case in which @xmath67 is within @xmath640 distance from the boundary of  @xmath1 , the contribution of the boundary case is @xmath641 .",
    "an intuitive interpretation is that the important region of the integral @xmath17 might be cut off by the boundary of  @xmath1 .",
    "therefore , in cases that @xmath67 is too close to the boundary , the tail @xmath17 is not heavier than that of the interior case .",
    "the rigorous analysis is basically repeating the parts  1 , 2 and 3 on a truncated region .",
    "therefore , we omit the details .",
    "the proof of theorem [ sup ] is analogous to that of theorem [ main ] . according to lemma [ lxsup ] ,",
    "we focus on the set ( for some small @xmath642 ) @xmath643 a similar three - part procedure is applied here .    in part 1 , using the transformation from @xmath3 to the process @xmath644 , we have @xmath645 we insert the expansions in ( [ expf ] ) , ( [ expc ] ) and ( [ expmu ] ) into the expression of @xmath646 and obtain that @xmath647 equals @xmath648 note that the above display is approximately a quadratic function of @xmath525 and is maximized approximately at @xmath649 .",
    "in addition , on the set @xmath650 , we have that @xmath651 and thus @xmath652 .",
    "therefore , on the set  @xmath650 , we have the following approximation of @xmath646 : @xmath653 .",
    "since we use the same change of measure , the analysis of the likelihood ratio is exactly the same as part 2 of theorem [ main ] . for part 3 ,",
    "we compute the second moment of @xmath549 on the set @xmath654 .",
    "this is also identical to the proof of theorem [ main ] .",
    "thus , with the same choice of tuning parameters , we have that @xmath655\\leq(1 + { \\varepsilon})v^2(b).\\ ] ] additionally , lemma [ lxsup ] provides an approximation that @xmath656 .",
    "thus , we use lemma [ lemtv1 ] ( presented at the beginning of section  [ secproof ] ) and complete the proof .",
    "for the bias control , we need the following result  @xcite .    [ theorem 4 ]",
    "suppose that conditions are satisfied .",
    "let @xmath657 be the probability density function of @xmath658 .",
    "then the following approximation holds as @xmath659 : @xmath660    thus , for any small @xmath661 , @xmath662 similar to the log - normal distribution , the overshoot of @xmath53 is @xmath663 .",
    "note that @xmath664 let @xmath665 note that @xmath397 is a @xmath10-dimensional gaussian process . using borel ",
    "tis lemma , we obtain that @xmath666 therefore , it is sufficient to control @xmath667 and @xmath668 .    by the definition of @xmath669 in ( [ defim ] ) , there exists a constant @xmath670 such that @xmath671 then we have , on the set @xmath672 , @xmath673 , which implies that @xmath674 the last step is due to the result of proposition [ theorem 4 ] and further ( [ den ] ) .",
    "thus , it is sufficient to choose @xmath675 so that the above probability is bounded by @xmath676 .",
    "the bound of @xmath668 is completely analogous .",
    "the proof of theorem [ variance ] is similar to that of theorem [ main ] .",
    "therefore , we only lay out the key steps .",
    "the only difference is that we replace the integral by a finite sum over @xmath309 .",
    "recall that the proof of theorem  [ main ] consists of three parts : first , we write the event @xmath677 as a function of @xmath387 ( with an ignorable correction term ) ; second , we write the likelihood ratio as a function of @xmath387 ( with an ignorable correction term ) ; third , we integrate the likelihood ratio with respect to @xmath678 .",
    "for the current proof , we also have three similar parts .    _ part _ 1 .",
    "for the first step in the proof of theorem [ main ] , we write @xmath679 if and only if @xmath680 . with the current discretization size , as proved in theorem [ bias ] , @xmath681 thus , we reach the same result that @xmath682 if @xmath683 .    _",
    "part _ 2 . consider the likelihood ratio @xmath684 \\,dt.\\ ] ] under the discretization setup , we have @xmath685 which is a discrete approximation of @xmath33 . in the proof of theorem",
    "[ main ] , after taking all the terms not consisting of @xmath47 out of the integral [ such as that in ( [ lrd ] ) ] , the discrete sum is essentially approximating the following integral : @xmath686 the above integral concentrates on a region of size @xmath687 .",
    "given that we choose @xmath688 , the discretized likelihood ratio in @xmath689 approximate @xmath33 up to a constant in the sense that @xmath690    _ part _ 3 .",
    "with the results of parts  1 and 2 , the analysis of part 3 is completely analogous to part 3 in the proof of theorem [ main ] .",
    "thus , we conclude that @xmath691 where the constant @xmath692 depends on the @xmath693 in ( [ discretize ] ) .",
    "in this section , we state all the lemmas used in the previous sections . to facilitate reading , we move several lengthy proofs ( lemmas [ lx1 ] , [ lxsup ] , [ lemexp ] , [ lemi2 ] , [ lema ] and [ lemgamma ] ) to the supplemental materials @xcite , as those proofs are not particularly related to the proof of the theorems and mostly involve tedious elementary algebra .",
    "[ lemborel ] let @xmath0 , @xmath694 , @xmath695 is a parameter set , be a mean zero gaussian random field .",
    "@xmath3 is almost surely bounded on @xmath695 .",
    "then @xmath696 , and @xmath697\\geq b \\bigr)\\leq e^ { -{b^{2}}/{(2\\sigma_{{\\cal u}}^{2})}},\\ ] ] where @xmath698 $ ]",
    ".          for @xmath708 , we split the expectation into two parts @xmath709 .",
    "note that @xmath710 and @xmath166 is a mean zero gaussian random field with @xmath711 .",
    "a direct application of the borel  tis inequality ( lemma [ lemborel ] ) yields the result of this lemma .",
    "[ lemexp ] let @xmath473 be a random variable taking values in @xmath712 with density proportional to @xmath713 if @xmath714 and @xmath715 and @xmath495 , then @xmath716 where the expectation is taken with respect to @xmath473 .",
    "[ lemi2 ] on the set @xmath487 , @xmath512 defined as in ( [ i22 ] ) can be written as @xmath723\\\\ & & \\hspace*{56pt}{}+ \\frac { ( 1-\\lambda)}{2\\sigma } \\mathbf1^\\top \\bigl(z_t-\\mu_{02}u_t+\\mu_2(t-\\tau)u_\\tau \\bigr ) -\\lambda b_{t}- \\frac{\\mathbf1^\\top\\mu_{22}\\mathbf1}{8\\sigma^2}\\biggr\\ } \\\\ & & \\qquad { } \\times \\exp\\bigl\\{\\bigl(\\bigl ( w_{t}+u_\\tau c(t-\\tau)-u_t \\bigr)^2 -2\\bigl ( w_{t}+u_\\tau c(t-\\tau)-u_t \\bigr)\\\\ & & \\hspace*{122pt}{}\\times\\mu_{20}\\mu_{22}^{-1 } { \\bigl(z_t-\\mu _ { 02}u_t+\\mu_2(t-\\tau)u_\\tau \\bigr)}\\bigr)\\\\ & & \\hspace*{200pt}{}/\\bigl(2 ( 1-\\mu_{20}\\mu _ { 22}^{-1}\\mu _ { 02 } ) \\bigr)\\bigr\\}\\,dt.\\end{aligned}\\ ] ]      [ lemgamma ] on the set @xmath530 , there exists some @xmath623 such that for all @xmath727 , @xmath728 \\big\\vert \\imath , \\tau , w,{y},{z } , { c_1 } \\biggr ] \\\\ & & \\qquad= o(1)\\rho_1^{-2}e^{u^{\\delta^{\\ast}}x } , \\\\ & & e \\biggl[\\frac{1}{(1-\\rho_1-\\rho_2)^2\\kappa _ { 2,1}^2};x>\\bigl(1+o\\bigl(u^{-1-\\delta_0/4}\\bigr)\\bigr ) \\bigl[\\xi_u + o\\bigl(u^{-\\delta_0/8}\\bigr)\\bigr ] \\big\\vert \\imath , \\tau , w,{y},{z},{c_2 } \\biggr ] \\\\ & & \\qquad= o(1 ) ( 1-\\rho_1-\\rho_2)^{-2}(1- \\lambda)^{-d}e^{u^{\\delta^{\\ast}}x},\\end{aligned}\\ ] ] where @xmath729 and @xmath730 ."
  ],
  "abstract_text": [
    "<S> in this paper , we consider the extreme behavior of a gaussian random field @xmath0 living on a compact set @xmath1 . in particular , we are interested in tail events associated with the integral @xmath2 . </S>",
    "<S> we construct a ( non - gaussian ) random field whose distribution can be explicitly stated . </S>",
    "<S> this field approximates the conditional gaussian random field @xmath3 ( given that @xmath4 exceeds a large value ) in total variation . </S>",
    "<S> based on this approximation , we show that the tail event of @xmath4 is asymptotically equivalent to the tail event of @xmath5 where @xmath6 is a gaussian process and it is an affine function of @xmath0 and its derivative field . </S>",
    "<S> in addition to the asymptotic description of the conditional field , we construct an efficient monte carlo estimator that runs in polynomial time of @xmath7 to compute the probability @xmath8 with a prescribed relative accuracy . </S>"
  ]
}