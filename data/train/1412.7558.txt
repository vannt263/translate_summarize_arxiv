{
  "article_text": [
    "graph modification problems form an important subclass of discrete computational problems , where the task is to modify a given graph using a constrained number of modifications in order to make it satisfy some property  @xmath4 , or equivalently belong to the class  @xmath5 of graphs satisfying  @xmath4 .",
    "well - known examples of graph modification problems include vertex cover , cluster editing , feedback vertex set , odd cycle transversal , and minimum fill - in .",
    "the systematic study of graph modification problems dates back to early 80s and the work of yannakakis  @xcite , who showed that there is a dichotomy for the vertex deletion problems : unless a graph class  @xmath5 is trivial ( finite or co - finite ) , the problem of deleting the least number of vertices to obtain a graph from  @xmath5 is -hard .",
    "however , when , in order to obtain a graph from  @xmath5 , we are to modify the edge set of the graph instead of the vertex set , there are three natural classes of problems : deletion problems ( deleting the least number of edges ) , completion problems ( adding the least number of edges ) and editing problems ( performing the least number of edge additions or deletions ) . for neither of these ,",
    "any complexity dichotomy in the spirit of yannakakis result is known . indeed , in  @xcite yannakakis states",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ it [  ] would be nice if the same kind of techniques could be applied to the edge - deletion problems .",
    "unfortunately we suspect that this is not the case  the reductions we found for the properties considered [  ] do not seem to fall into a pattern . _ +  mihalis yannakakis _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    even though for edge modification problems there is no general  vs.   classification known , much can be said about their parameterized complexity .",
    "recall that a parameterized problem is called _ fixed - parameter tractable _ if it can be solved in time @xmath6 for some computable function  @xmath7 , where  @xmath8 is the size of the input and  @xmath1 is its parameter . in our case , the natural parameter  @xmath1 is the allowed number of modifications .",
    "cai  @xcite made a simple observation that for all the aforementioned graph modification problems there is a simple branching algorithm running in time @xmath9 for some constant  @xmath10 , as long as @xmath5 is _ characterized by a finite set of forbidden induced subgraphs _",
    ": there is a finite list of graphs @xmath11 such that any graph  @xmath12 belongs to  @xmath5 if and only if  @xmath12 does not contain any  @xmath13 as an induced subgraph .",
    "although many studied graph classes satisfy this property , there are important examples , like chordal or interval graphs , that are outside this regime .",
    "for this reason , the parameterized analysis of modification problems for graph classes characterized by a finite set of forbidden induced subgraphs focused on studying the design of _ polynomial kernelization algorithms _ ( _ polynomial kernels _ ) ; recall that such an algorithm is required , given an input instance  @xmath14 of the problem , to preprocess it in polynomial time and obtain an equivalent output instance  @xmath15 , where @xmath16 for some polynomial  @xmath17 .",
    "that is , the question is the following : can you , using polynomial - time preprocessing only , bound the size of the tackled instance by a polynomial function depending only on  @xmath1 ?    for vertex deletion problems",
    "the answer is again quite simple : as long as  @xmath5 is characterized by a finite set of forbidden induced subgraphs , the task is to hit all the copies of these subgraphs ( so - called _ obstacles _ ) that are originally contained in the graph .",
    "hence , one can construct a simple reduction to the @xmath18-hitting set problem for a constant  @xmath18 depending on  @xmath5 , and use the classic  @xmath19 kernel for the latter that is based on the sunflower lemma ( see e.g.  @xcite ) . for edge modifications problems",
    ", however , this approach fails utterly : every edge addition / deletion can create new obstacles , and thus it is not sufficient to hit only the original ones .",
    "for this reason , edge modification problems behave counterintuitively w.r.t .",
    "polynomial kernelization , and up to recently very little was known about their complexity .    on the positive side , kernelization of edge modification problems for well - studied graph classes",
    "was explored by guo  @xcite , who showed that four problems : threshold completion , split completion , chain completion , and trivially perfect completion , all admit polynomial kernels .",
    "however , the study took a turn for the interesting when kratch and wahlstrm  @xcite showed that there is a graph  @xmath20 on @xmath21 vertices , such that the deletion problem to @xmath20-free graphs ( the class of graphs not admitting  @xmath20 as an induced subgraph ) does not admit a polynomial kernel , unless the polynomial hierarchy collapses .",
    "this shows that the subtle differences between edge modification and vertex deletion problems have tremendous impact on the kernelization complexity .",
    "kratch and wahlstrm conclude by asking whether there is a `` simple '' graph , like a path or a cycle , for which an edge modification problem does not admit a polynomial kernel under similar assumptions .",
    "the question was answered by guillemot et al .",
    "@xcite who showed that both for the class of @xmath22-free graphs ( for  @xmath23 ) and for the class of  @xmath24-free graphs ( for  @xmath25 ) , the edge deletion problems probably do not have polynomial kernelization algorithms .",
    "they simultaneously gave a cubic kernel for the cograph editing problem , the problem of editing to a graph without induced paths on four vertices .",
    "these results were later improved by cai and cai  @xcite , who tried to obtain a complete dichotomy of the kernelization complexity of edge modification problems for classes of  @xmath20-free graphs , for every graph  @xmath20 .",
    "the project has been almost fully successful  the question remains unresolved only for a finite number of graphs  @xmath20 .",
    "in particular , it turns out that the existence of a polynomial kernel for any of @xmath20-free editing , @xmath20-free edge deletion , or @xmath20-free completion problems is in fact a very rare phenomenon , and basically happens only for specific , constant - size graphs  @xmath20 . in particular , for  @xmath20 being a path or a cycle , the aforementioned three problems admit polynomial kernels if and only if  @xmath20 has at most three edges .",
    "at the same time , there is a growing interest in identifying parameterized problems that are solvable in _ subexponential parameterized time _ ,",
    "i.e. , in time @xmath26 .",
    "although for many classic parameterized problems already known -hardness reductions show that the existence of such an algorithm would contradict the _ exponential time hypothesis _ of impagliazzo et al .",
    "@xcite , subexponential parameterized algorithms were known to exist for problems in restricted settings , like planar , or more generally @xmath20-minor free graphs  @xcite , or tournaments  @xcite .",
    "see the book of flum and grohe  @xcite for a wider discussion .",
    "therefore , it was an immense surprise when fomin and villanger  @xcite showed that chordal completion ( also called minimum fill - in ) can be solved in time @xmath27 . following this discovery , a new line of research was initiated .",
    "ghosh et al .",
    "@xcite showed that split completion is solvable in the same running time .",
    "although komusiewicz and uhlmann  @xcite showed that we can not expect cluster editing to be solvable in subexponential parameterized time , as shown by fomin et al .",
    "@xcite , when the number of clusters in the target graph is sublinear in the number of allowed edits , this is possible nonetheless .    following these three positive examples , drange et al .",
    "@xcite showed that completion problems for trivially perfect graphs , threshold graphs and pseudosplit graphs all admit subexponential parameterized algorithms .",
    "later , bliznets et al",
    ". showed that both proper interval completion and interval completion also admit subexponential parameterized algorithms  @xcite .",
    "let us remark that in almost all these results , the known existence of a polynomial kernelization procedure for the problem played a vital role in designing the subexponential parameterized algorithm .",
    "kernelization is namely used as an opening step that enables us to assume that the size of the considered graph is polynomial in the parameter @xmath1 , something that turns out to be extremely useful in further reasonings .",
    "the only exception is the algorithm for the interval completion problem  @xcite , for which the existence of a polynomial kernel remains a notorious open problem .",
    "the need of circumventing this issue created severe difficulties in  @xcite .    in this paper",
    "we study the trivially perfect editing problem .",
    "recall that trivially perfect graphs are exactly graphs that do not contain a  @xmath28 or a  @xmath29 as an induced subgraph ; see section  [ ssec : prelim - tp ] for a structural characterization of this graph class .",
    "interest in trivially perfect graphs started with the attempts to prove the strong perfect graph theorem . in recent times ,",
    "new source of motivation has grown , with the realization that trivially perfect graphs are related to the width parameter _ treedepth _ ( called also vertex ranking number , ordered chromatic number , and minimum elimination tree height ) .",
    "although it had been known that both the completion and the deletion problem for trivially perfect graphs are -hard , it was open for a long time whether the editing version is -hard as well  @xcite .",
    "this question was answered very recently by nastos and gao  @xcite , who showed that the problem is indeed -hard .",
    "actually , the work of nastos and gao focuses on exhibiting applications of trivially perfect graphs in social network theory , since this graph class may serve as a model for _ familial groups _ , communities in social networks showing a hierarchical nature .",
    "specifically , the _ editing number _ to a trivially perfect graph can be used as a measure of how much a social network resembles a collection of hierarchies .",
    "nastos and gao also ask whether it is possibly to obtain a polynomial kernelization algorithm for this problem .",
    "the question about the existence of a polynomial kernel for trivially perfect editing was then restated in a recent survey by liu , wang , and guo  @xcite , which _ nota bene _ contains a comprehensive overview of the current status of the research on the kernelization complexity of graph modification problems .",
    "[ [ our - contribution . ] ] our contribution .",
    "+ + + + + + + + + + + + + + + + +    we answer the question of nastos and gao  @xcite and of liu , wang , and guo  @xcite in affirmative by proving the following theorem .",
    "[ thm : tpe - polykernel - intro ] the problem trivially perfect editing admits a proper kernel with  @xmath0 vertices .    here , we say that a kernel ( kernelization algorithm ) is _ proper _ if it can only decrease the parameter , i.e. , the output parameter  @xmath30 satisfies  @xmath31 .",
    "to prove theorem  [ thm : tpe - polykernel - intro ] , we employ an extensive analysis of the tackled instance , based on the equivalent structural definition of trivially perfect graphs .",
    "the main approach is to construct a small _ vertex modulator _",
    ", a set of vertices whose removal results in obtaining a trivially perfect graph .",
    "however , since we are allowed only edge deletions and additions , this modulator just serves as a tool for exposing the structure of the instance .",
    "more specifically , we greedily pack disjoint obstructions into a set  @xmath32 , whose size can be guaranteed to be at most  @xmath33 , with the condition that to get rid of each of these obstructions , at least one edge must be edited inside the modulator per obstruction .",
    "having obtained such a modulator , the rest of the graph ,  @xmath34 , is trivially perfect , and we may apply the structural view on trivially perfect graphs to find irrelevant parts that can be reduced .    while the modulator technique is commonly used in kernelization ,",
    "the new insight in this work is as follows .",
    "since we work with an edge modification problem , we can be less restrictive about when an obstacle can be greedily packed into the modulator .",
    "for example , the obstacle does not need to be completely vertex - disjoint with the so far constructed  @xmath32 ; sharing just one vertex is still allowed .",
    "this observation allows us to reason about the adjacency structure between  @xmath32 and  @xmath35 , which is of great help when identifying irrelevant parts .",
    "we hope that this generic technique finds applications in other edge modification problems as well .    by slight modifications of our kernelization algorithm",
    ", we also obtain polynomial kernels for trivially perfect deletion and trivially perfect completion .",
    "[ thm : tpd - polykernel - intro ] the problem trivially perfect deletion admits a proper kernel with  @xmath0 vertices .",
    "[ thm : tpc - polykernel - intro ] the problem trivially perfect completion admits a proper kernel with  @xmath0 vertices .    to the best of our knowledge , no polynomial kernel for trivially perfect deletion was known so far . for trivially perfect completion",
    ", a cubic kernel was shown earlier by guo  @xcite .",
    "unfortunately , the work of guo  @xcite is published only as a conference extended abstract , where it is only sketched how the approach yielding a quartic kernel for split deletion could be used to obtain a cubic kernel for trivially perfect completion .",
    "the details of this kernelization algorithm are deferred to the full version , which , alas , has not appeared .",
    "for this reason , we believe that our proof of theorem  [ thm : tpc - polykernel - intro ] fills an important gap in the literature  the polynomial kernel for trivially perfect completion is an important ingredient of the subexponential parameterized algorithm for this problem  @xcite .    finally , we show that trivially perfect editing , in addition to being -complete , can not admit a subexponential parameterized algorithm , provided that the exponential time hypothesis holds .",
    "[ thm : eth - hardness - intro ] under eth , the trivially perfect editing problem is -hard and can not be solved in time @xmath26 or @xmath36 even on graphs with maximum degree  @xmath37 .    in other words ; the familial group measure can not be computed in time subexponential in terms of the value of the measure .",
    "this stands in contrast with trivially perfect completion that admits a subexponential parameterized algorithm , and shows that trivially perfect editing is more similar to trivially perfect deletion , for which a similar lower bound has been proved earlier by drange et al .",
    "in fact , our reduction can be used as an alternative proof of hardness of trivially perfect deletion as well .",
    "let us note that the -hardness reduction for trivially perfect editing presented by nastos and gao  @xcite can not be used to prove nonexistence of a subexponential parameterized algorithm , since it involves a cubic blow - up of the parameter ( see section  [ sec : hardness ] for details ) . to prove theorem  [ thm : eth - hardness - intro ] , we resort to the technique used for similar hardness results by komusiewicz and uhlmann  @xcite and by drange et al .  @xcite .",
    "[ [ graphs . ] ] graphs . + + + + + + +    in this work we consider only undirected simple finite graphs . for a graph @xmath12 , by @xmath38 and @xmath39",
    "we denote the vertex and edge set of @xmath12 , respectively .",
    "the _ size _ of a graph @xmath12 is defined as @xmath40 .    for a vertex @xmath41 , by @xmath42",
    "we denote the open neighborhood of  @xmath43 , i.e. @xmath44 . the closed neighborhood of @xmath43 , denoted by @xmath45 $ ] , is defined as @xmath46 .",
    "these notions are extended to subsets of vertices as follows : @xmath47=\\bigcup_{v\\in x } n_g[v]$ ] and @xmath48\\setminus x$ ] .",
    "we omit the subscript whenever  @xmath12 is clear from context .    when @xmath49 is a subset of vertices of  @xmath12 , we write  @xmath50 $ ] to denote the _ induced subgraph _ of  @xmath12 , i.e. , the graph @xmath51 where  @xmath52 is  @xmath39 restricted to  @xmath53 .",
    "the degree of a vertex @xmath41 , denoted @xmath54 , is the number of vertices it is adjacent to , i.e. , @xmath55 .",
    "we denote by @xmath56 the maximum degree in the graph , i.e. , @xmath57 . for a set @xmath58",
    ", we write @xmath59 to denote the set of unordered pairs of elements of @xmath58 ; thus @xmath60 . by @xmath61",
    "we denote the _ complement _ of a graph  @xmath12 , i.e. , @xmath62 and @xmath63 .",
    "if  @xmath43 and  @xmath64 are such that @xmath65 = n[u]$ ] , then we call  @xmath43 and  @xmath64 _ true twins_. observe that  @xmath43 and  @xmath64 are adjacent if they are true twins . on the other hand ,",
    "if  @xmath43 and  @xmath64 have  @xmath66 , then we call  @xmath43 and  @xmath64 _ false twins _ , and in this case we may observe that  @xmath43 and  @xmath64 are non - adjacent . if  @xmath32 is an inclusion - wise maximal set of vertices such that for every pair of vertices  @xmath43 and  @xmath64 in  @xmath32 they are true ( resp",
    ".  false ) twins , then we call  @xmath32 a true ( resp",
    ".  false ) twin class .    for a graph @xmath12 and a set of vertices @xmath67 , we denote by @xmath34 the ( induced subgraph ) @xmath68 $ ] . when @xmath69 , we write  @xmath70 to denote the graph  @xmath71 on vertex set  @xmath38 and edge set @xmath72 . finally , we let @xmath73 be the graph on vertex set  @xmath38 and edge set @xmath74 , where @xmath75 denotes the _ symmetric difference _ ; for two sets  @xmath58 and  @xmath76 , @xmath77 .",
    "we will also say that two sets @xmath58 and @xmath76 are _ nested _ if @xmath78 or @xmath79 .",
    "a vertex @xmath80 is _ universal _ if it is adjacent to all the other vertices of the graph .",
    "note that the set of universal vertices of a graph forms a clique , which is also a true twin class .",
    "this clique will be denoted by @xmath81 and called the _ universal clique _ of @xmath12 .",
    "[ [ modules - and - the - modular - decomposition . ] ] modules and the modular decomposition .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in our kernelization algorithm we will use the notion of a _ module _ in a graph .",
    "[ def : module ] given a graph  @xmath12 , a set of vertices  @xmath82 is called a _ module _ if for any two vertices  @xmath43 and  @xmath64 in  @xmath83 , we have that @xmath84 , i.e. , all the vertices of @xmath83 have exactly the same neighborhood outside @xmath83 .",
    "observe that for any graph @xmath12 , any singleton  @xmath85 is a module , and also  @xmath38 itself is a module .",
    "however , @xmath12 can contain a whole hierarchy of modules .",
    "this hierarchy can be captured using the following notion of a _ modular decomposition _ , introduced by gallai  @xcite .",
    "the following description of a modular decomposition is taken verbatim from the work of bliznets et al .",
    "@xcite .",
    "a module decomposition of a graph @xmath12 is a rooted tree @xmath86 , where each node @xmath87 is labeled by a module @xmath88 , and is one of four types :    leaf : : :    @xmath87 is a leaf of @xmath86 , and @xmath89 is    a singleton ; union : : :    @xmath90 $ ] is disconnected , and the children of    @xmath87 are labeled with different connected components of    @xmath90 $ ] ; join : : :    the complement of @xmath90 $ ] is disconnected , and the    children of @xmath87 are labeled with different connected    components of the complement of @xmath90 $ ] ; prime : : :    neither of the above holds , and the children of @xmath87 are    labeled with different modules of @xmath12 that are proper    subsets of @xmath89 , and are inclusion - wise maximal with this    property .    moreover , we require that the root of @xmath86 is labeled with the module @xmath38 .",
    "we need the following properties of the module decomposition .",
    "[ thm : module - decomp ] for a graph @xmath12 , the following holds .    1 .",
    "a module decomposition @xmath91 of @xmath12 exists , is unique , and computable in linear time . 2 .",
    "at any prime node @xmath87 of @xmath86 , the labels of the children form a partition of @xmath89 .",
    "in particular , for each vertex @xmath43 of @xmath12 there exists exactly one leaf node with label @xmath92 .",
    "each module @xmath83 of @xmath12 is either a label of some node of @xmath86 , or there exists a * union * or * join * node @xmath87 such that @xmath83 is a union of labels of some children of @xmath87 .",
    "let us remark that since in this work we do not optimize the running time of the kernelization algorithm , we do not need to compute the modular decomposition in linear time . any simpler polynomial time algorithm would suffice ( see the work of mcconnell and spinrad  @xcite for a literature overview ) .    [",
    "[ parameterized - complexity . ] ] parameterized complexity .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + +    the running time of an algorithm is usually described as a function of the length of the input . to refine the complexity analysis of computationally hard problems ,",
    "parameterized complexity introduced the notion of an extra `` parameter '' that is an additional part of a problem instance responsible for measuring its complexity . to simplify the notation",
    ", we will consider inputs to problems of the form @xmath14 , which is a pair consisting of a graph  @xmath12 and a nonnegative integer  @xmath1 .",
    "a problem is then said to be _ fixed parameter tractable _ if there is an algorithm which solves the problem in time @xmath93 , where @xmath7 is any function , and @xmath94 any polynomial function . in the case",
    "when @xmath95 we say that the algorithm is a subexponential parameterized algorithm . when a problem @xmath96 is fixed - parameter tractable , where  @xmath5 is the class of all graphs , we say that  @xmath4 belongs to the complexity class . for a more rigorous introduction to parameterized complexity",
    "we refer to the books of downey and fellows  @xcite and of flum and grohe  @xcite .    a _ kernelization algorithm _ ( or _",
    "kernel _ ) is a polynomial - time algorithm for a parameterized problem  @xmath4 that takes as input a problem instance @xmath14 and returns an equivalent instance @xmath15 , i.e. @xmath97 , where both  @xmath98 and  @xmath30 are bounded by  @xmath99 for some function  @xmath7 .",
    "we then say that  @xmath7 is the _ size of the kernel_. when @xmath100 , we say that the kernel is a _",
    "proper kernel_. specifically , a proper polynomial kernelization algorithm for  @xmath4 is a polynomial time algorithm which takes as input an instance @xmath14 and returns an equivalent instance @xmath15 with @xmath100 and @xmath101 for some polynomial function @xmath17 .    [",
    "[ tools - for - lower - bounds . ] ] tools for lower bounds .",
    "+ + + + + + + + + + + + + + + + + + + + + + +    as evidence that trivially perfect editing can not be solved in subexponential parameterized time @xmath102 , we will use the exponential time hypothesis , formulated by impagliazzo , paturi , and zane  @xcite .",
    "there exists a positive real number @xmath103 such that 3sat with @xmath8 variables and @xmath104 clauses can not be solved in time @xmath105 .",
    "impagliazzo , paturi , and zane  @xcite proved a fundamental result called _ sparsification lemma _",
    ", which can serve as a turing reduction from an arbitrary instance of 3sat to an instance where the number of clauses is linear in the number of variables . thus , the following statement is an immediate corollary of the sparsification lemma .",
    "[ prop : eth ] unless eth fails , there exists a positive real number @xmath103 such that 3sat with @xmath8 variables and @xmath104 clauses can not be solved in time @xmath106 . in particular",
    ", 3sat does not admit an algorithm with time complexity @xmath107 .",
    "0.45    \\(1 ) at ( 0,0 ) ; ( 2 ) at ( 1,0 ) ; ( 3 ) at ( 0,1 ) ; ( 4 ) at ( 1,1 ) ;    \\(1 )  ( 2 ) ; ( 2 )  ( 4 ) ; ( 3 )  ( 4 ) ;    0.45    \\(1 ) at ( 0,0 ) ; ( 2 ) at ( 1,0 ) ; ( 3 ) at ( 0,1 ) ; ( 4 ) at ( 1,1 ) ;    \\(1 )  ( 2 ) ; ( 2 )  ( 4 ) ; ( 3 )  ( 4 ) ; ( 1 )  ( 3 ) ;    [ [ combinatorial - properties . ] ] combinatorial properties .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + +    a graph  @xmath12 is trivially perfect if and only if it does not contain a  @xmath29 or a  @xmath28 as an induced subgraph .",
    "that is , trivially perfect graphs are defined by the forbidden induced subgraph family @xmath108 ( see figure  [ fig : forbidden - graphs ] ) .",
    "however , we mostly rely on the following recursive characterization of the trivially perfect graphs :    [ def : tp - recursive ] the class of trivially perfect graphs can be defined recursively as follows :    * @xmath109 is a trivially perfect graph . * adding a universal vertex to a trivially perfect graph results in a trivially perfect graph . *",
    "the disjoint union of two trivially perfect graphs results in a trivially perfect graph .",
    "based on proposition  [ def : tp - recursive ] , a superset of the current authors  @xcite proposed the following notion of a decomposition for trivially perfect graphs . in the following , for a rooted tree @xmath86 and vertex @xmath110 , by @xmath111 we denote the subtree of @xmath86 rooted at @xmath87 .",
    "[ def : univeral - clique - decomposition ] a _ universal clique decomposition _",
    "( _ ucd _ ) of a connected graph @xmath12 is a pair @xmath112 , where  @xmath86 is a rooted tree and  @xmath113 is a partition of the vertex set  @xmath38 into disjoint nonempty subsets , such that    * if  @xmath114 and  @xmath115 , then either  @xmath116 ,  @xmath87 is an ancestor of  @xmath103 in  @xmath86 , or  @xmath103 is an ancestor of  @xmath87 in  @xmath86 , and * for every node  @xmath117 , the set of vertices  @xmath118 is the universal clique of the induced subgraph @xmath119 $ ]",
    ".    we call the vertices of  @xmath86 _ nodes _ and the sets in  @xmath113 _ bags _ of the universal clique decomposition  @xmath120 . by slightly abusing notation",
    ", we often identify nodes with corresponding bags .",
    "note that by the definition , in a universal clique decomposition every non - leaf node  @xmath87 has at least two children , since otherwise the bag  @xmath118 would not comprise _ all _ the universal vertices of the graph  @xmath121 $ ] .",
    "the following lemma explains the connection between trivially perfect graphs and universal clique decompositions .",
    "[ lem : tp - iff - ucd ] a connected graph  @xmath12 admits a universal clique decomposition if and only if it is trivially perfect .",
    "moreover , such a decomposition is unique up to isomorphisms .",
    "note that a universal clique decomposition can trivially be found in polynomial time by repeatedly locating universal vertices and connected components .",
    "moreover , we can extend the notion of a universal clique decomposition also to a disconnected trivially perfect graph @xmath12 . in this case , the universal clique decomposition of @xmath12 becomes a rooted forest consisting of universal clique decompositions of the connected components of @xmath12 . since",
    "a graph is trivially perfect if and only if each of its connected component is , lemma  [ lem : tp - iff - ucd ] can be easily generalized to the following statement : every ( possibly disconnected ) graph @xmath12 is trivially perfect if and only if it admits a universal clique decomposition , where the decomposition has the shape of a rooted forest .",
    "moreover , this decomposition is unique up to isomorphism .    the following definition of a quasi - ordering of vertices respecting the ucd will be helpful when arguing the correctness of the kernelization procedure .",
    "let @xmath122 be the universal clique decomposition of a trivially perfect graph @xmath12 .",
    "we impose a quasi - ordering  @xmath123 on vertices of @xmath12 defined as follows .",
    "suppose vertex @xmath64 belongs to bag @xmath118 and vertex @xmath43 belongs to bag @xmath124 .",
    "then @xmath125 if and only if @xmath126 or @xmath87 is an ancestor of @xmath103 in the rooted forest @xmath86 .",
    "thus , classes of vertices pairwise equivalent with respect to  @xmath123 are exactly formed by the bags of @xmath113 , and otherwise the ordering respects the rooted structure of @xmath86 .",
    "note that since the ucd of a trivially perfect graph is unique up to isomorphism , the quasi - ordering @xmath123 is uniquely defined and can be computed in polynomial time .    [",
    "[ computational - problems . ] ] computational problems .",
    "+ + + + + + + + + + + + + + + + + + + + + + +    in this work we are mainly interested in the trivially perfect editing problem , defined formally as follows :    a graph @xmath12 and a non - negative integer @xmath1 .",
    "@xmath1 is there a set @xmath127 of size at most @xmath1 such that @xmath128 is trivially perfect ?    for a graph @xmath12 , any set @xmath129 for which @xmath130 is trivially perfect",
    "will henceforth be referred to as an _ editing set_. an editing set is _ minimal _ if no proper subset  @xmath131 is also an editing set .    in the trivially perfect deletion and trivially perfect completion problems",
    "we allow only edge deletions and edge additions , respectively .",
    "more formally , we require that the editing set @xmath132 is contained in , or disjoint from @xmath39 , respectively . in section  [ sec : kernel - editing ] we prove theorem  [ thm : tpe - polykernel - intro ] , that is , we show that trivially perfect editing admits a kernel with @xmath0",
    ". actually , the character of our data reduction rules will be very simple ; the kernelization algorithm will start with instance @xmath14 , and perform only the following operations :    * edit some @xmath133 , decrement the budget @xmath1 by @xmath134 , and terminate the algorithm if @xmath1 becomes negative ; or * remove some vertex @xmath64 of @xmath12 and proceed with instance @xmath135 .",
    "thus , the kernel will essentially be an induced subgraph of @xmath12 , modulo performing some edits whose safeness and necessity can be deduced . in the proofs of correctness , we will never use any minimality argument that exchanges edge deletions for completions , or vice versa .",
    "therefore , the whole approach can be applied almost verbatim to trivially perfect deletion and trivially perfect completion , yielding proofs for theorems  [ thm : tpd - polykernel - intro ] and  [ thm : tpc - polykernel - intro ] after very minor modifications .",
    "we hope that the reader will be convinced about this after understanding all the arguments of section  [ sec : kernel - editing ] . however , for the sake of completeness we , in section  [ sec : kernel - comp - del ] , review the modifications of the argumentation of section  [ sec : kernel - editing ] that are necessary to prove theorems  [ thm : tpd - polykernel - intro ] and  [ thm : tpc - polykernel - intro ] .",
    "[ [ tp - set - systems . ] ] tp - set systems .",
    "+ + + + + + + + + + + + + + +    in the kernelization algorithm we will need the following auxiliary definition and result .",
    "[ def : tpss ] a set system @xmath136 over a ground set @xmath53 is called a _ tp - set system _ if for every @xmath137 and @xmath138 in @xmath139 with @xmath140 and @xmath141 , there is no @xmath142 with @xmath143 .",
    "the following property bounds the size of a tp - set system , which we need later :    [ lem : tpss - bounded ] let  @xmath139 be a tp - set system over a finite ground set  @xmath53 .",
    "then the cardinality of  @xmath139 is at most  @xmath144 .",
    "we proceed by induction on @xmath145 , with the claim being trivial when @xmath146 .",
    "suppose @xmath139 is a tp - set system over a ground set @xmath53 , and let @xmath32 be a member of @xmath139 that has the minimum cardinality among the nonempty ones ( if there is no such set , then @xmath147 and we are done ) .",
    "the first observation is that if @xmath148 and @xmath149 are two nonempty members of @xmath139 that satisfy @xmath150 ( possibly @xmath151 or @xmath152 ) , then in fact @xmath153 .",
    "suppose otherwise that there exist two such nonempty sets @xmath154 with @xmath155 ; w.l.o.g .",
    ", suppose that there exists an element @xmath156 , and hence @xmath157 .",
    "since @xmath32 is of minimum cardinality , we have that @xmath158 . as @xmath159",
    ", we infer that there exists an element @xmath160 .",
    "consider the pair @xmath161 and observe that ( a )  @xmath162 , ( b )  @xmath163 , and ( c )  @xmath164 .",
    "this contradicts the definition of a tp - set system .",
    "define a set system @xmath165 over the ground set @xmath166 as follows : @xmath167 clearly , @xmath165 is a tp - set system over a strictly smaller ground set , so from the induction hypothesis we infer that @xmath168 .",
    "moreover , from the observation of the previous paragraph we infer that sets @xmath169 are pairwise different for @xmath170 , and hence @xmath171 ( the additive @xmath172 comes from possibly having the empty set in @xmath139 ) . concluding , @xmath173",
    "this section is devoted to the proof of theorem  [ thm : tpe - polykernel - intro ] , stating that trivially perfect editing admits a proper kernel with @xmath0 vertices . as usual",
    ", the kernelization algorithm will be given as a sequence of _ data reduction rules _",
    ": simple preprocessing procedures that , if applicable , simplify the instance at hand . for each rule",
    "we shall prove two results : ( a ) that applicability of the rule can be recognized in polynomial time , and ( b ) that the rule is _ safe _ , i.e. , the resulting instance is equivalent to the input one . at the end of the proof",
    "we will argue that if no rule is applicable , then the size of the instance must be bounded by  @xmath0 .",
    "some rules will decrement the budget  @xmath1 for edge edits ; if this budget drops below zero , we may conclude that we are dealing with a no - instance , so we immediately terminate the algorithm and provide a constant - size trivial no - instance as the obtained kernel , for example the instance @xmath174 .    before starting the formal description ,",
    "let us give a brief overview of the structure of the proof .",
    "in section  [ sec : basic - rules ] we give some preliminary basic rules , which mostly deal with situations where we can find a large number of induced  @xmath29s and  @xmath28s in the graph ( henceforth called _ obstacles _ ) , which share only one edge or non - edge .",
    "we then infer that this edge or non - edge has to be included in any editing set of size at most  @xmath1 , and hence we can perform the necessary edit and decrement the budget .    in section  [ sec : modulator ] we perform a greedy algorithm that iteratively packs disjoint induced  @xmath29s and  @xmath28s in the graph .",
    "note that if we are able to pack more than  @xmath1 of them , then this certifies that the considered instance does not have a solution , and we can terminate the algorithm .",
    "hence , if  @xmath32 is the union of vertex sets of the packed obstacles , then  @xmath175 and  @xmath34 is a trivially perfect graph .",
    "uncovering such a set  @xmath32 , which we call a tp - modulator , imposes a lot of structure on the considered instance , and is the key for further analysis of irrelevant parts of the input .",
    "although the applied modulator technique is standard in the area of kernelization for graph modification problems , in this paper we introduce a new twist to it that may have possible further applications .",
    "namely , we observe that since we consider edge editing problems , the packed obstacles do not have to be entirely vertex - disjoint , but the next obstacle can be packed even if it shares one vertex with the union of vertex sets of the previous obstacles ; in some limited cases even having two vertices in common is permitted .",
    "thus , the obtained modulator  @xmath32 has the property that not only is there no obstacle in the graph  @xmath12 that is vertex - disjoint with  @xmath32 , but even the existence of obstacles sharing one vertex with  @xmath32 is forbidden .",
    "this simple observation enables us to reason about the adjacency structure between  @xmath32 and @xmath35 . in section  [ sec : modulator - nei ] we analyze this structure in order to prove the most important technical result of the proof : the number of subsets of  @xmath32 that are neighborhoods within  @xmath32 of vertices from @xmath35 is bounded polynomially in  @xmath1 ; see lemma  [ lem : bounded - x - neighborhoods ] .    in section  [ sec : impbags ]",
    "we proceed to analyze the trivially perfect graph @xmath34 . having the polynomial bound on the number of neighborhoods within @xmath32",
    ", we can locate in the ucd of @xmath34 a polynomial ( in  @xmath1 ) number of _ important bags _",
    ", where something interesting from the point of view of @xmath32-neighborhoods happens .",
    "the parts between the important bags have very simple structure .",
    "they are either _ tassels _ : sets of trees hanging below some important bag , where each such tree is a module in the whole graph @xmath12 ; or _ combs _ : long paths stretched between two important bags where all the vertices of subtrees attached to the path have exactly the same neighborhood in @xmath32 .",
    "tassels and combs are treated differently : large tassels contain large trivially perfect modules in @xmath12 that can be reduced quite easily , however for combs we need to devise a quite complicated irrelevant vertex rule that locates a vertex that can be safely discarded in a long comb .",
    "the module reduction rules are described in section  [ sec : module - rules ] , while in section  [ sec : kernel - final ] we reduce the sizes of tassels and combs and conclude the proof .      in this section",
    "we introduce the first two basic reduction rules . in the argumentation of the next sections",
    ", we will assume that none of these rules is applicable .",
    "an instance satisfying this property will be called _",
    "reduced_.    0.45    \\(u ) at ( 2,0 ) @xmath64 ; ( v ) at ( 5,0 ) @xmath43 ;    ( a1 ) at ( 0,1 ) ; ( a2 ) at ( 1,1 ) ;    ( b1 ) at ( 2,1 ) ; ( b2 ) at ( 3,1 ) ;    ( c1 ) at ( 4,1 ) ; ( c2 ) at ( 5,1 ) ;    ( d1 ) at ( 6,1 ) ; ( d2 ) at ( 7,1 ) ;    \\(u )  ( v ) ;    \\(u ) ",
    "( a1 )  ( v )  ( a2 )  ( u ) ; ( a1 )  ( a2 ) ;    \\(u )  ( b1 )  ( v )  ( b2 )  ( u ) ; ( b1 )  ( b2 ) ;    \\(u ) ",
    "( c1 )  ( v )  ( c2 ) ",
    "( u ) ; ( c1 )  ( c2 ) ;    \\(u )  ( d1 )  ( v )  ( d2 )  ( u ) ; ( d1 )  ( d2 ) ;    0.45    \\(u ) at ( 2,0 ) @xmath64 ; ( v ) at ( 5,0 ) @xmath43 ;    ( a1 ) at ( 0,1 ) ; ( a2 ) at ( 1,1 ) ;    ( b1 ) at ( 2,1 ) ; ( b2 ) at ( 3,1 ) ;    ( c1 ) at ( 4,1 ) ; ( c2 ) at ( 5,1 ) ;    ( d1 ) at ( 6,1 ) ; ( d2 ) at ( 7,1 ) ;    \\(u )  ( v ) ;    \\(u )  ( a1 ) ; ( u )  ( b1 ) ; ( u )  ( c1 ) ; ( u )  ( d1 ) ;    \\(v )  ( a2 ) ; ( v )  ( b2 ) ; ( v ) ",
    "( c2 ) ; ( v )  ( d2 ) ;    ( a1 )  ( a2 ) ; ( b1 )  ( b2 ) ; ( c1 )  ( c2 ) ; ( d1 )  ( d2 ) ;    [ rule : c4 ] for an instance @xmath14 with @xmath176 , if there is a matching of size at least @xmath177 in @xmath178}$ ] , then add edge @xmath179 to  @xmath12 and decrease  @xmath1 by one , i.e. , return the new instance @xmath180 .",
    "[ rule : p4 ] for an instance @xmath14 with @xmath181 and @xmath182 $ ] and @xmath183 $ ] , if there is a matching in @xmath61 between @xmath184 and @xmath185 of size at least @xmath177 , then delete edge @xmath179 from @xmath12 and decrease  @xmath1 by one , i.e. , return the new instance @xmath186 .",
    "[ lem : basic - rules - sound ] applicability of rules  [ rule : c4 ] and  [ rule : p4 ] can be recognized in polynomial time . moreover , both these rules are safe , i.e. , the input instance @xmath14 is a yes - instance if and only if the output instance @xmath187 is a yes - instance .",
    "observe that verifying applicability of rule  [ rule : c4 ] or [ rule : p4 ] to a fixed ( non-)edge  @xmath179 boils down to computing the cardinality of the maximum matching in an auxiliary graph .",
    "this problem is well - known to be solvable in polynomial time  @xcite .",
    "thus , by iterating over all edges and non - edges of  @xmath12 we obtain polynomial time algorithms for recognizing applicability of rules  [ rule : c4 ] and  [ rule : p4 ] .",
    "we proceed to the proof of the safeness for both rules .",
    "_ rule  [ rule : c4 ] _ : let @xmath188 be edges of the found matching in @xmath178}$ ] .",
    "observe that for each @xmath189 , @xmath190 , vertices @xmath191 induce a  @xmath29 in  @xmath12 .",
    "these induced  @xmath29s share only the non - edge  @xmath179 , hence any editing set that does not contain  @xmath179 must contain at least one element of @xmath192 , and consequently be of size at least  @xmath177 .",
    "we infer that every editing set for  @xmath12 that has size at most  @xmath1 has to include the edge  @xmath179 , and the safeness of the rule follows .",
    "_ rule  [ rule : p4 ] _ :",
    "we proceed similarly as for rule  [ rule : c4 ] .",
    "suppose @xmath188 is the found matching in  @xmath61 , where @xmath193 and @xmath194 for @xmath190 .",
    "then vertices @xmath195 induce a  @xmath28 , and all these  @xmath28s for @xmath190 pairwise share only the edge  @xmath179 .",
    "similarly as for rule  [ rule : c4 ] , we conclude that every editing set for  @xmath12 of size at most  @xmath1 has to contain  @xmath179 , and the safeness of the rule follows .",
    "we can now use lemma  [ lem : basic - rules - sound ] to apply rules  [ rule : c4 ] and  [ rule : p4 ] exhaustively ; note that each application reduces the budget @xmath1 , hence at most @xmath1 applications can be performed before discarding the instance as a no - instance . from now on , we assume that the considered instance @xmath14 is reduced .",
    "we now move to the construction of a small modulator whose _",
    "raison dtre _ is to expose structure in the considered graph  @xmath12 .",
    "we say that a subset @xmath196 with @xmath197 is an _ obstruction _ if @xmath198 $ ] is isomorphic to a @xmath29 or a @xmath28 .",
    "formally , our modulator will be compliant to the following definition .",
    "[ def : modulator ]",
    "let  @xmath14 be an instance of trivially perfect editing .",
    "a subset  @xmath199 is a _ tp - modulator _ if for every obstruction @xmath200 the following holds ( see figure  [ fig : forbidden - modulator ] ) :    * @xmath201 , and * if @xmath202 , then it can not happen that @xmath198 $ ] is a @xmath29 of the form @xmath203 or a @xmath28 of the form @xmath204 , where @xmath205 .",
    "we call a tp - modulator @xmath32 _ small _ if @xmath175 .    in particular , observe that for a tp - modulator @xmath32 there is no obstacle disjoint with @xmath32 , so @xmath34 is trivially perfect .",
    "the following result shows that from now we can assume that a small tp - modulator is given to us .",
    "[ lem : polytime - modulator ] given an instance @xmath14 for trivially perfect editing , we can in polynomial time construct a small tp - modulator @xmath199 , or correctly conclude that @xmath14 is a no - instance .",
    "the algorithm starts with @xmath206 , and iteratively constructs an increasing family of sets @xmath207 . in the  @xmath189th iteration",
    "we look for an obstacle  @xmath200 that contradicts the fact that  @xmath208 is a tp - modulator according to definition  [ def : modulator ] , by verifying all the quadruples of vertices in  @xmath209 time . if this check verifies that  @xmath208 is a tp - modulator",
    ", then we terminate the algorithm and output @xmath210 .",
    "otherwise , we set @xmath211 and proceed to the next iteration . moreover , if we performed  @xmath177 iterations , i.e. , successfully constructed set  @xmath212 , then we terminate the algorithm concluding that  @xmath14 is a no - instance .",
    "since in each iteration the next  @xmath213 grows by at most  @xmath37 vertices , we infer that if we succeed in outputting a tp - modulator  @xmath32 , then it has size at most  @xmath33 .",
    "we are left with proving that if the algorithm successfully constructed @xmath212 , then @xmath14 is a no - instance . to this end",
    ", we prove by induction on @xmath189 that for every @xmath214 and every editing set @xmath215 for @xmath12 , it holds that @xmath216 . indeed , from this statement for @xmath217 we can infer that every editing set for @xmath12 has size at least @xmath177 , so @xmath14 is a no - instance .",
    "the base of the induction is trivial , so for the induction step suppose that @xmath218 , where @xmath200 is an obstacle with @xmath219 or having the form described in the second point of definition  [ def : modulator ] .    first , if @xmath219 , then @xmath220 is disjoint with @xmath221 . since @xmath215 is an editing set for @xmath12 , we have that @xmath222 , and hence @xmath223 by the induction hypothesis .",
    "second , if @xmath224 and @xmath200 has one of the two forms described in the second point of definition  [ def : modulator ] , then it is easy to see that @xmath215 in fact has to have a nonempty intersection with @xmath225 : editing only the ( non)edge @xmath226 would turn a @xmath29 into a @xmath28 or vice versa . since @xmath225 is disjoint with @xmath221",
    ", we analogously obtain that @xmath227    by applying lemma  [ lem : polytime - modulator ] , from now on we assume that we are given a small tp - modulator @xmath32 in @xmath12 .",
    "recall that we exposed a small tp - modulator  @xmath32 in the input graph  @xmath12 . in polynomial time",
    "we compute the universal clique decomposition @xmath228 of the trivially perfect graph  @xmath34 .",
    "the goal of this section is to analyze the structure of neighborhoods within  @xmath32 of vertices residing outside  @xmath32 .",
    "let @xmath12 be a graph and @xmath67 . for a vertex @xmath229 , the _",
    "@xmath32-neighborhood _ of @xmath43 , denoted @xmath230 , is the set @xmath231 .",
    "the family of @xmath32-neighborhoods of @xmath12 is the set @xmath232 .",
    "( a1 ) at ( 0,0 ) ; ( a2 ) at ( 1,0 ) ; ( a3 ) at ( 0,1 ) ; ( a4 ) at ( 1,1 ) ; ( a1 )  ( a2 ) ; ( a2 )  ( a4 ) ; ( a3 )  ( a4 ) ; ( a1 )  ( a3 ) ;    ( b1 ) at ( 2,0 ) ; ( b2 ) at ( 3,0 ) ; ( b3 ) at ( 2,1 ) ; ( b4 ) at ( 3,1 ) ; ( b1 )  ( b3 ) ; ( b4 )  ( b3 ) ; ( b2 )  ( b4 ) ;    ( c1 ) at ( 4.5,+ ) ; ( c2 ) at ( 4.5- , ) ; ( c3 ) at ( 4.5,0 ) ; ( c4 ) at ( 4.5 + , ) ; ( c1 )  ( c2 ) ; ( c2 )  ( c3 ) ; ( c3 )  ( c4 ) ; ( c4 )  ( c1 ) ;    ( d1 ) at ( 6+,0 ) ; ( d2 ) at ( 6 , ) ; ( d3 ) at ( 6+,+ ) ; ( d4 ) at ( 6++ , ) ; ( d1 )  ( d2 ) ; ( d2 )  ( d3 ) ; ( d3 )  ( d4 ) ; ( e1 ) at ( 8+,0 ) ; ( e2 ) at ( 8 , ) ; ( e3 ) at ( 8+,+ ) ; ( e4 ) at ( 8++ , ) ; ( e1 )  ( e2 ) ; ( e2 )  ( e3 ) ; ( e1 )  ( e4 ) ; ( -.2 , -.2 ) rectangle ( 9 , .2 ) ; ( x ) at ( 9+,0 ) @xmath32 ;    again , we shall omit the subscript  @xmath12 whenever this does not lead to any confusion .",
    "recall that the ucd  @xmath233 gives us a quasi - ordering  @xmath123 on the vertices of  @xmath34 .",
    "we have  @xmath234 if the bag to which  @xmath43 belong is a descendant of the bag which  @xmath64 belongs to , where every bag is considered its own descendant .",
    "we shall use the notation  @xmath235 to denote that  @xmath125 and  @xmath236 .",
    "the following two lemmas show that the quasi - ordering  @xmath123 is compatible with the inclusion ordering of @xmath32-neighborhoods .",
    "[ lem : x - nei - inclusion - diff ] if @xmath235 then @xmath237 .",
    "suppose @xmath238 and @xmath239 , where @xmath240 and @xmath87 is an ancestor of @xmath103 in the forest @xmath86 .",
    "recall that in a ucd , every non - leaf node has at least two children , which means that there exists some node @xmath241 that is a descendant of @xmath87 , but which is incomparable with @xmath103 .",
    "let @xmath242 be any vertex of @xmath243 . from the definition of a ucd it follows that @xmath244 but @xmath245 .",
    "for the sake of contradiction suppose that @xmath246 , which means there exists a vertex  @xmath247 with  @xmath248 and  @xmath249 .",
    "it follows that  @xmath250 is an obstacle regardless of whether  @xmath251 is an edge or a non - edge : it is an induced  @xmath29 if  @xmath252 and an induced  @xmath28 if  @xmath253 .",
    "thus we have uncovered an obstacle sharing only one vertex with  @xmath32 , contradicting the fact that  @xmath32 is a tp - modulator .",
    "[ lem : x - nei - inclusion - same ] if @xmath254 for some @xmath255 , then @xmath256 or @xmath257 .    since @xmath254 , we have that @xmath258 . for the sake of contradiction ,",
    "suppose that there exist some @xmath259 and @xmath260 .",
    "it can be now easily seen that regardless whether @xmath261 belongs to @xmath39 or not , the quadruple @xmath262 forms one of the obstacles forbidden in the second point of the definition  [ def : modulator ] .",
    "this is a contradiction with the fact that @xmath32 is a tp - modulator .",
    "lemmas  [ lem : x - nei - inclusion - diff ] and  [ lem : x - nei - inclusion - same ] motivate the following refinement of the quasi - ordering @xmath123 : if @xmath263 belong to different bags of @xmath233 , then we put @xmath264 if and only if @xmath125 , and if they are in the same bag , then @xmath264 if and only if @xmath265 .",
    "thus , by lemma  [ lem : x - nei - inclusion - same ] @xmath266 refines @xmath123 by possibly splitting every bag of @xmath233 into a family of linearly ordered equivalence classes . moreover , by lemmas  [ lem : x - nei - inclusion - diff ] and  [ lem : x - nei - inclusion - same ] we have the following corollary .",
    "[ cor : preceqn ] if @xmath264 then @xmath265 .",
    "observe that for a pair of vertices @xmath267 , the following conditions are equivalent : ( a )  @xmath64 and @xmath43 are comparable w.r.t  @xmath123 , ( b )  @xmath64 and @xmath43 are comparable w.r.t .",
    "@xmath266 , and ( c )  @xmath258 .",
    "we have now prepared all the tools needed to prove the main lemma from this section .",
    "[ lem : bounded - x - neighborhoods ] if @xmath14 is a reduced instance for trivially perfect editing and  @xmath32 is a small tp - modulator , then the number of different  @xmath32-neighborhoods is at most  @xmath268 .",
    "let @xmath139 be the family of @xmath32-neighborhoods in @xmath12 .",
    "for every @xmath269 , let us choose an arbitrary vertex @xmath270 with @xmath271 .",
    "we split @xmath139 into two subfamilies : the first family  @xmath272 contains all the sets of  @xmath139 that contain the endpoints of some non - edge in  @xmath273 $ ] , whereas the second family  @xmath274 contains all the sets of  @xmath139 that induce complete graphs in  @xmath273 $ ] .",
    "we bound the sizes of  @xmath272 and  @xmath274 separately .    _",
    "bounding @xmath275 _ : let @xmath276 be a non - edge of  @xmath273 $ ] , and for @xmath277 let @xmath278 be the family of those sets of  @xmath272 that contain  @xmath279 and have cardinality exactly @xmath280 .",
    "take any distinct @xmath281 , and observe that they are not nested since both have size  @xmath280 . by corollary  [ cor :",
    "preceqn ] , this means that vertices  @xmath282 and  @xmath283 are incomparable w.r.t .",
    "@xmath266 , so @xmath284 .",
    "hence , set @xmath285 is independent in  @xmath12 .",
    "observe now that if we had that @xmath286 , then rule  [ rule : c4 ] would be applicable to the non - edge  @xmath276 . since we assume that the instance is reduced ,",
    "we conclude that @xmath287 , and hence also @xmath288 . by summing through all the  @xmath280 between  @xmath289 and  @xmath290 and through all the non - edges of",
    "@xmath273 $ ] , we infer that @xmath291    _ bounding @xmath292 _ : consider any pair of @xmath32-neighborhoods @xmath293 such that they are not nested , and moreover there exist vertices @xmath294 and @xmath295 such that @xmath296 .",
    "since  @xmath297 and  @xmath298 are not nested , by corollary  [ cor : preceqn ] we infer that  @xmath282 and  @xmath283 are incomparable w.r.t .",
    "@xmath266 , and hence @xmath284 .",
    "observe that then @xmath299 $ ] is an induced  @xmath28 ; however , the existence of such an obstacle is not forbidden by the definition of a tp - modulator .",
    "create an auxiliary graph  @xmath20 with  @xmath300 , and put @xmath301 if and only if  @xmath297 and  @xmath298 satisfy the condition from the previous paragraph , i.e. ,  @xmath297 and  @xmath298 are not nested and there exist @xmath302 and @xmath303 with @xmath296 .",
    "run the classic greedy @xmath289-approximation algorithm for vertex cover in  @xmath20 .",
    "this algorithm either finds a matching  @xmath83 in  @xmath20 of size more than @xmath304 , or a vertex cover  @xmath305 of  @xmath20 of size at most @xmath306 . in the first case , assign each edge  @xmath307 of  @xmath83 to the corresponding edge  @xmath226 of  @xmath273 $ ] as in the definition of the edges of  @xmath20 .",
    "observe that since  @xmath308 , then some edge  @xmath309 $ ] is assigned at least  @xmath177 times .",
    "then it is easy to see that the sets @xmath310 for @xmath307 being edges of  @xmath83 assigned to  @xmath226 induce  @xmath28s that share only the edge  @xmath226 , and hence rule  [ rule : p4 ] would be applicable to  @xmath226 .",
    "this is a contradiction with the assumption that  @xmath14 is reduced .",
    "hence , we can assume that we have successfully constructed a vertex cover  @xmath305 of  @xmath20 of size at most @xmath311 .",
    "let now @xmath312 .",
    "since  @xmath313 is independent in  @xmath20 , it follows that for any non - nested @xmath314 and any @xmath315 , @xmath316 , we have that @xmath317 .",
    "since the sets of  @xmath313 induce complete graphs in  @xmath273 $ ] , this means that in particular there is no set @xmath318 that contains both  @xmath319 and  @xmath320 .",
    "this proves that the family  @xmath313 is a tp - set system with  @xmath32 as ground set , so by lemma  [ lem : tpss - bounded ] we infer that @xmath321 .",
    "concluding , @xmath322 and @xmath323 .      .25 .,title=\"fig : \" ]    .25 .,title=\"fig : \" ]    .25 .,title=\"fig : \" ]    in the previous section we analyzed the structure of neighborhoods that nodes from  @xmath35 have in  @xmath32 .",
    "our goal in this section is to perform the symmetric analysis : to understand , how the neighborhood of a fixed  @xmath247 in  @xmath35 looks like .",
    "eventually , we aim to locate a family  @xmath324 of  @xmath325 _ important bags _ , where some non - trivial behavior w.r.t .",
    "the neighborhoods of vertices of  @xmath32 happens .",
    "then , we will perform a lowest common ancestor - closure on the set  @xmath324 , thus increasing its size to at most twice . after performing this step ,",
    "all the connected components of  @xmath326 have very simple structure from the point of view of their neighborhoods in  @xmath32 .",
    "as there are only  @xmath325 such components , we will be able to kernelize them separately .",
    "the following definition and lemma explains what are the types of neighborhoods that vertices of  @xmath32 can have in  @xmath35 . to simplify the notation , in the following we treat  @xmath123 also as a partial order on the vertices of the forest  @xmath86 denoting the ancestor - descendant relation , i.e. ,  @xmath327 if and only if  @xmath103 is an ancestor of  @xmath87 ( possibly  @xmath328 ) .",
    "let @xmath329 be any vertex and consider @xmath330 .",
    "we say that @xmath331 is ( see figure  [ fig : nx ] ) :    * a _ neighborhood of type  0 _ if @xmath331 is the union of the vertex sets of a collection of connected components of @xmath34 .",
    "* a _ neighborhood of type  1 _ if there exists a node @xmath332 such that @xmath333 .",
    "in other words , @xmath331 consists of all the vertices contained in bags on the path from @xmath334 to the root of its subtree in @xmath86 , where some vertices of @xmath335 itself may be excluded . * a _ neighborhood of type  2 _ if there exists a node @xmath332 and a collection @xmath336 of subtrees of @xmath86 rooted at children of @xmath334 such that @xmath337 .",
    "in other words , @xmath331 is formed by all the vertices contained in bags on the path from @xmath334 to the root of its subtree in @xmath86 , plus a selection of subtrees rooted in the children of @xmath334 , where the vertices appearing in the bags of each such subtree are either all included in @xmath331 or all excluded from @xmath331 .",
    "[ lem : nx - two - types ] let @xmath329 be any vertex and consider @xmath330 .",
    "then @xmath331 is of type  0 ,  1 or  2 .    from corollary  [ cor : preceqn ]",
    "we infer that @xmath331 is closed downwards w.r.t .",
    "the quasi - ordering @xmath266 , i.e. , if @xmath338 and @xmath264 , then also @xmath339 .",
    "let @xmath340 be the set of nodes of @xmath86 whose bags contain at least one vertex of @xmath331 .",
    "it follows that @xmath340 is closed under taking ancestors in forest @xmath86 .",
    "moreover if @xmath341 , then the bags of all the ancestors of @xmath87 other than @xmath87 are fully contained in @xmath331 .    [ cl : types ] suppose @xmath342 are two nodes that are incomparable w.r.t .",
    "then @xmath343 and @xmath344 , i.e. , @xmath331 contains all the vertices of all the bags contained in the subtrees of @xmath86 rooted at @xmath87 and @xmath345 .",
    "we prove the statement for the subtree rooted at  @xmath345 ; the proof for the subtree rooted at  @xmath87 is symmetric .",
    "let  @xmath346 and  @xmath347 be arbitrary vertices of  @xmath348 and  @xmath349 , respectively . for the sake of contradiction suppose there exists some  @xmath350 such that  @xmath351 . since  @xmath350 and  @xmath352 are incomparable w.r.t .",
    "@xmath123 , by the properties of the universal clique decomposition we have that  @xmath353 , @xmath354 and @xmath355 .",
    "since @xmath356 by the definition of  @xmath331 , we conclude that  @xmath357 would induce a  @xmath28 in  @xmath12 that has only one vertex in common with  @xmath32 ( see figure  [ fig : broken - type ] ) , a contradiction to the definition of a tp - modulator .",
    "we now use claim  [ cl : types ] to perform a case study that recognizes @xmath331 as a neighborhood of type  0 ,  1 , or  2 .",
    "suppose first that  @xmath331 contains vertices of at least two distinct connected components of  @xmath34 .",
    "let  @xmath358 be any two such components , and let  @xmath359 and  @xmath360 be the trees of the forest  @xmath86 that are ucds of  @xmath361 and  @xmath362 , respectively .",
    "since  @xmath340 is closed under taking ancestors in  @xmath86 , it follows that the roots of  @xmath359 and  @xmath360 belong to  @xmath340 .",
    "claim  [ cl : types ] implies then that the entire vertex sets of  @xmath361 and  @xmath362 are contained in  @xmath331 . since  @xmath358 was an arbitrary pair of components containing a vertex of  @xmath331",
    ", it follows that  @xmath331 must be the union of vertex sets of a selection of connected components of  @xmath34 , i.e. , a neighborhood of type  0 .",
    "since  @xmath363 is also a neighborhood of type  0 , we are left with analyzing the case when @xmath364 for  @xmath365 being a connected component of  @xmath34 ; let  @xmath366 be the ucd of  @xmath365 .",
    "observe that if  @xmath331 does not contain any pair of vertices incomparable w.r.t .",
    "@xmath123 , then  @xmath340 must form a path from some node of  @xmath366 to the root of  @xmath366 , and hence  @xmath331 is a neighborhood of type  1 . otherwise , there exists some node of  @xmath340 such that at least two subtrees rooted at its children contain nodes from  @xmath340 .",
    "let  @xmath334 be such a node that is highest in  @xmath366 , and let  @xmath336 be the family of subtrees rooted at children of  @xmath334 that contain nodes of  @xmath340 . again applying claim  [ cl : types ] , we infer that  @xmath331 contains all the vertices of all the bags of every subtree of  @xmath336 : for any two distinct subtrees  @xmath367 ,  @xmath340 contains the roots of  @xmath359 and  @xmath360 , and hence by claim  [ cl : types ]  @xmath331 contains all the vertices of all the bags of  @xmath359 and  @xmath360 . since  @xmath334 was chosen to be the highest , it follows that  @xmath331 is a neighborhood of type  2 for node  @xmath334 and selection of subtrees  @xmath336 .",
    "clearly , for every @xmath247 we can in polynomial time analyze @xmath331 and recognize it as a neighborhood of type  0 ,  1 , or  2 .",
    "let @xmath368 be the set of nodes @xmath334 for vertices @xmath247 for which @xmath331 is of type  @xmath134 or  @xmath289 . to simplify the structure of @xmath369",
    ", we perform the lowest common ancestor - closure operation on @xmath368 .",
    "the following variant of this operation is taken verbatim from the work of fomin et al .",
    "@xcite .    for a rooted tree @xmath86 and vertex set @xmath370 the lowest common ancestor - closure ( lca - closure )",
    "is obtained by the following process .",
    "initially , set @xmath371 .",
    "then , as long as there are vertices @xmath372 and @xmath346 in @xmath373 whose least common ancestor @xmath242 is not in @xmath373 , add @xmath242 to @xmath373 . when the process terminates , output @xmath373 as the lca - closure of @xmath83 .",
    "the following folklore lemma summarizes two basic properties of lca - closures .",
    "[ lem : lca ] let @xmath86 be a tree , @xmath374 and @xmath375",
    ". then @xmath376 and for every connected component @xmath305 of @xmath377 , @xmath378 .",
    "construct now the set @xmath324 by taking @xmath379 and adding the root of every connected component of  @xmath86 that contains a bag of  @xmath368 ( provided it is not already included ) .",
    "the nodes from  @xmath324 will be called _ important nodes _ , or _ important bags_. from lemma  [ lem : lca ]",
    "it follows that  @xmath380 , and by the construction we infer that every connected component  @xmath305 of  @xmath326 is of one of the following three forms :    * @xmath305 is not adjacent to any node of  @xmath324 , and is thus simply a connected component of  @xmath86 that does not contain any important bag . *",
    "@xmath305 is adjacent to one node  @xmath381 of  @xmath324 , and it is a subtree rooted at a child of  @xmath381 .",
    "* @xmath305 is adjacent to two nodes  @xmath381 and  @xmath382 of  @xmath324 such that  @xmath381 is an ancestor of  @xmath382 .",
    "then  @xmath305 is formed by the internal nodes of the  @xmath383 path in  @xmath86 , plus all the subtrees rooted at the other children of these internal nodes .      in this section",
    "we give two new reduction rules : a twin reduction and a module reduction rule .",
    "these rules are executed exhaustively by the algorithm as rules  [ rule : twin ] and  [ rule : module ] .",
    "the reason why we introduce them now is that only after understanding the structural results of sections  [ sec : modulator - nei ] and  [ sec : impbags ] , the motivation of these rules becomes apparent .",
    "namely , these rules will be our main tools in reducing the sizes of parts of @xmath34 located between the important bags .",
    "[ rule : twin ] if  @xmath384 is a true twin class of size  @xmath385 , and  @xmath386 is an arbitrarily picked vertex , then remove  @xmath43 from the graph , i.e. , proceed with the instance  @xmath387 .",
    "[ lem : rule : twin : sound ] applicability of rule  [ rule : twin ] can be recognized in polynomial time . moreover , rule  [ rule : twin ] is safe , i.e. ,  @xmath14 is a yes - instance if and only if  @xmath387 is a yes - instance .    in order to recognize the applicability of rule  [ rule : twin ] we only need to inspect every true twin classes in the graph , which clearly can be done in polynomial time .",
    "we proceed to the proof of the safeness of the rule .",
    "let  @xmath86 be a true twin class of size at least  @xmath388 and let  @xmath43 be the vertex the rule deleted .",
    "since the class of trivially perfect graphs is hereditary , if  @xmath14 is a yes - instance , it follows that @xmath387 is a yes - instance .",
    "suppose now that @xmath387 is a yes - instance .",
    "let  @xmath215 be a set of edges with  @xmath389 such that @xmath390 is trivially perfect .",
    "we now show that @xmath391 is also trivially perfect , which means that  @xmath215 is also a solution to  @xmath14 . for the sake of contradiction , suppose  @xmath200 is an obstruction in  @xmath392 .",
    "since @xmath390 is trivially perfect ,  @xmath200 must contain the deleted vertex  @xmath43 .",
    "since  @xmath215 has size at most  @xmath1 , at most  @xmath393 vertices of  @xmath86 can be incident to an edge of  @xmath215 .",
    "let  @xmath394 , @xmath395 , @xmath396 , and  @xmath397 be four vertices of  @xmath86 that are different from  @xmath43 and are not incident to  @xmath215 .",
    "then one of them , say  @xmath394 , is not contained in  @xmath200 .",
    "since  @xmath43 and  @xmath394 are true twins both in @xmath12 and in @xmath398 , we can replace  @xmath43 with  @xmath394 in  @xmath200 yielding a new set  @xmath399 which is an obstruction in @xmath392 .",
    "however , since  @xmath43 is not a member of  @xmath399 , we have that  @xmath399 is an obstruction in @xmath390 , contradicting the assumption that @xmath390 was trivially perfect .",
    "recall that a module is a set of vertices @xmath83 such that for every vertex @xmath43 in @xmath400 , either @xmath401 or @xmath402 ; see definition  [ def : module ] .",
    "the following rule enables us to reduce large trivially perfect modules .",
    "[ rule : module ] suppose @xmath82 is a module such that @xmath403 $ ] is trivially perfect and it contains an independent set of size at least @xmath404 . then let us take any independent set @xmath405 of size @xmath406 , and we delete every vertex of @xmath83 apart from @xmath324 , i.e. , proceed with the instance @xmath407 .",
    "observe that rule  [ rule : module ] always deletes at least one vertex , since @xmath408 and @xmath409 .",
    "actually , we could define a stronger rule where we only assume that @xmath408 ; however , the current statement will be helpful in recognizing the applicability of rule  [ rule : module ] .",
    "we first prove that the rule is indeed safe .",
    "[ lem : rule - mod - correct ] provided that @xmath14 is a reduced instance ( w.r.t .",
    "rules  [ rule : c4 ] and  [ rule : p4 ] ) , then rule  [ rule : module ] is safe , i.e. , @xmath14 is a yes - instance if and only if @xmath407 is a yes - instance .",
    "let @xmath410 , and @xmath411 .",
    "since  @xmath71 is an induced subgraph of  @xmath12 , by heredity , if @xmath14 is a yes - instance , then @xmath412 is a yes - instance .",
    "we proceed to the proof of the other direction .",
    "suppose then that @xmath413 is a yes - instance , and let  @xmath215 , @xmath414 , be a minimum - size editing set for  @xmath71 .",
    "[ claim : i - notin - f ] no vertex of  @xmath324 is incident to any edit of  @xmath215 .",
    "since  @xmath215 has minimum possible size , it is inclusion - wise minimal .",
    "we show that if @xmath415 is the set of edges of  @xmath215 incident to a vertex of  @xmath324 and @xmath416 , then @xmath417 being trivially perfect implies @xmath418 being trivially perfect . since  @xmath409",
    ", we can find at least four vertices @xmath419 that are not incident to any edit of  @xmath215 .",
    "suppose that @xmath418 is not trivially perfect .",
    "then there is an obstruction  @xmath200 in @xmath418 containing at least one of the vertices of  @xmath324 incident to an edge of  @xmath215 .",
    "create  @xmath399 by replacing every vertex of @xmath420 by a different vertex of @xmath421 that is not contained in  @xmath200 .",
    "since vertices of  @xmath324 are not incident to the edits of  @xmath422 , they are false twins in @xmath418 , and hence  @xmath399 created in this manner induces a graph isomorphic to the one induced by  @xmath200 . thus ,  @xmath399 is an obstacle in @xmath418 .",
    "however , the vertices @xmath423 are not incident to the edits of  @xmath215 and hence  @xmath399 induces the same graph in @xmath418 as in @xmath417 .",
    "therefore  @xmath399 would be an obstacle in @xmath424 , a contradiction to @xmath425 being trivially perfect .    since we argued that @xmath426 is also a solution , by the optimality of @xmath215 we infer that @xmath427 and @xmath428 .",
    "we now argue that @xmath398 is trivially perfect , which will imply that @xmath14 is a yes - instance . for the sake of contradiction ,",
    "suppose that there exists an obstacle  @xmath200 in  @xmath398 ; it follows that  @xmath200 shares at least one vertex with  @xmath429 . from claim  [ claim : i - notin - f ]",
    "it follows that no edit of  @xmath215 is incident to any vertex of  @xmath83 , so in  @xmath391 we still have that  @xmath83 is a module .",
    "if the obstruction  @xmath200 induces a  @xmath28 , then it is known that  @xmath200 is fully contained in the module  @xmath83 , or has at most one vertex in  @xmath83  ( * ? ? ?",
    "* observation  1 ) . since  @xmath403=(g\\triangle f)[m]$ ] is trivially perfect , the latter is the case .",
    "but since  @xmath83 is a module in @xmath398 , then replacing the single vertex of @xmath430 with any vertex of  @xmath324 would yield an obstacle in @xmath425 , a contradiction .    consider then the case when  @xmath200 induces a  @xmath29 in @xmath398 .",
    "since  @xmath403=(g\\triangle f)[m]$ ] is  @xmath29-free , we have that  @xmath200 is not entirely contained in  @xmath83 .",
    "also , if  @xmath200 had three vertices in  @xmath83 , then the remaining vertex would need to be contained in  @xmath431 , and hence would be adjacent in @xmath398 to all the other three vertices of  @xmath200 , a contradiction to  @xmath432 $ ] being a  @xmath29 .",
    "therefore , at most two vertices of  @xmath200 can be in  @xmath83 .",
    "suppose exactly two vertices  @xmath433 and  @xmath434 of  @xmath200 are in  @xmath83 , and  @xmath435 and  @xmath436 are outside  @xmath83 .",
    "as @xmath83 is a module both in @xmath12 and in @xmath398 , we must have that @xmath437 and hence the @xmath37-cycle induced by @xmath200 in @xmath398 must be @xmath438 .",
    "take any two vertices @xmath439 and obtain @xmath399 by replacing @xmath433 and @xmath434 with them .",
    "it follows that @xmath399 induces a @xmath29 in @xmath425 , a contradiction .",
    "finally , consider the case when exactly one vertex of  @xmath200 , say  @xmath433 , is in  @xmath83 .",
    "again , replacing @xmath433 with any vertex of @xmath324 would yield an induced @xmath29 contained in @xmath425 , a contradiction .",
    "thus , we conclude that @xmath398 is trivially perfect .",
    "observe that in order to apply rule  [ rule : module ] , one needs to be given the module  @xmath83 .",
    "given  @xmath83 , finding any independent set  @xmath405 of size  @xmath406 can then be done easily as follows : we can find an independent set of maximum cardinality in  @xmath83 in polynomial time , since  @xmath403 $ ] is trivially perfect and the problem is polynomial - time solvable on trivially perfect graphs ( it boils down to picking one vertex from every leaf bag of the universal clique decomposition of the considered graph ) .",
    "then we take any of its subsets of size  @xmath406 to be  @xmath324 . hence , to apply rule  [ rule : module ] exhaustively , we need the following statement .    [",
    "lem : recognizing - module ] there exists a polynomial - time algorithm that , given an instance @xmath14 , either finds a module @xmath440 where rule  [ rule : module ] can be applied , or correctly concludes that rule  [ rule : module ] is inapplicable .    using theorem  [ thm : module - decomp ] we compute the module decomposition  @xmath91 of  @xmath12 .",
    "then we verify applicability of rule  [ rule : module ] to each module  @xmath89 for  @xmath110 , by checking whether  @xmath403 $ ] is trivially perfect and contains an independent set of size  @xmath388 ( the latter check can be done in polynomial time since  @xmath403 $ ] is trivially perfect ) .",
    "moreover , we perform the same check on all the modules  @xmath441 formed as follows : take a union node  @xmath110 , and construct a module  @xmath441 by taking the union of labels of those children of  @xmath87 that induce trivially perfect graphs .    we now argue that if rule  [ rule : module ] is applicable to some module  @xmath83 in  @xmath12 , then this algorithm will encounter some ( possibly different ) module  @xmath373 to which rule  [ rule : module ] is applicable as well . by the third point of theorem  [ thm : module - decomp ] , either  @xmath442 for some  @xmath110 , or  @xmath83 is the union of a collection of labels of children of some union or join node . in the first case the algorithm verifies  @xmath83 explicitly . in the following ,",
    "let  @xmath443 denote the size of a maximum independent set in a graph  @xmath20 .",
    "if now  @xmath83 is a union of labels of some children of a union node  @xmath87 , then by heredity  @xmath444 .",
    "moreover ,  @xmath445 induces a trivially perfect graph ( since trivially perfect graphs are closed under taking disjoint union ) and clearly @xmath446 .",
    "hence , rule  [ rule : module ] is applicable to @xmath447 , and this will be discovered by the algorithm .",
    "finally , suppose  @xmath83 is a union of labels of some children @xmath448 of a join node  @xmath87 .",
    "observe that since for every  @xmath449 , every vertex of  @xmath450 is adjacent to every vertex of  @xmath451 , it follows that @xmath452)=\\max_{i=1,2,\\ldots , p}\\alpha(g[m^{t_i}])$ ] . without loss of generality",
    "suppose that the maximum on the right hand side is attained for the module  @xmath453 .",
    "then by heredity  @xmath454 $ ] is trivially perfect , and @xmath455)=\\alpha(g[m])\\geq    2k+5 $ ] .",
    "therefore rule  [ rule : module ] is applicable to @xmath456 , and this will be discovered by the algorithm .",
    "we remark here that for the kernelization algorithm it is not necessary to be sure that rule  [ rule : module ] is inapplicable at all .",
    "instead , we could perform it on demand .",
    "more precisely , during further analysis of the structure of @xmath34 we argue that some modules have to be small , since otherwise rule  [ rule : module ] would be applicable .",
    "this analysis can be performed by a polynomial - time algorithm that would just apply rule  [ rule : module ] on any encountered module that needs shrinking .",
    "however , we feel that the fact that rule  [ rule : module ] can be indeed applied exhaustively provides a better insight into the algorithm , and streamlines the presentation .    having introduced and verified rules  [ rule : twin ] and  [ rule : module ] , we can now prove that after applying them exhaustively , all the trivially perfect modules in the graph are small .    [",
    "lem : small - ind - twin - small ] a ( possibly disconnected ) trivially perfect graph with maximum true twin class size @xmath87 and maximum independent set size @xmath457 has at most @xmath458 vertices in total .    let @xmath233 be the ucd of @xmath12 , a trivially perfect graph with independent set number @xmath457 and every true twin class of size at most @xmath87 .",
    "since any collection comprising one vertex from each leaf bag of @xmath233 forms an independent set , there are at most @xmath457 leaf bags in @xmath233 .",
    "thus the number of nodes of @xmath233 in total is at most @xmath459 .",
    "since every bag of the decomposition @xmath384 is a true twin class , we conclude that there are at most @xmath458 vertices in @xmath12 .",
    "[ cor : small - modules ] suppose an instance @xmath14 is reduced , and moreover rules  [ rule : twin ] and  [ rule : module ] are not applicable to @xmath14 .",
    "then for every module @xmath82 such that @xmath403 $ ] is trivially perfect , we have that @xmath460 .",
    "suppose @xmath83 is such a module .",
    "observe that members of every true twin class in @xmath403 $ ] are also true twins in @xmath12 ( since @xmath83 is a module ) .",
    "hence twin classes in @xmath403 $ ] have size at most @xmath406 , as otherwise rule  [ rule : twin ] would be applicable .",
    "moreover , if @xmath403 $ ] contained an independent set of size @xmath388 , then rule  [ rule : module ] would be applicable . by lemma  [ lem : small - ind - twin - small ] , we infer that @xmath461 .    from now on we assume that in the considered instance @xmath14 we have exhaustively applied rules  [ rule : c4][rule : module ] , using the algorithms of lemmas  [ lem : basic - rules - sound ] ,  [ lem : rule : twin : sound ] , and  [ lem : recognizing - module ] .",
    "hence corollary  [ cor : small - modules ] can be used . observe that to perform this step , we do not need to construct the small modulator @xmath32 at all .",
    "however , we hope that the reader already sees that rules  [ rule : c4][rule : module ] will be useful for shrinking too large parts of @xmath34 between the important bags .",
    "recall that we have fixed a small tp - modulator  @xmath32 with  @xmath175 such that  @xmath34 is a trivially perfect graph with universal clique decomposition  @xmath233 .",
    "moreover , rules  [ rule : c4][rule : module ] are inapplicable to @xmath14 . by lemma  [ lem : bounded - x - neighborhoods ]",
    "we have that the number of @xmath32-neighborhoods is @xmath268 .",
    "by the marking procedure , we have marked a set  @xmath324 of  @xmath325 bags of  @xmath233 as important , in such a manner that every connected component of  @xmath462 is adjacent to at most two vertices of  @xmath324 , and is in fact of one of the three forms described at the end of section  [ sec : impbags ] .",
    "thus , the whole vertex set of @xmath34 can be partitioned into four sets :    @xmath463 : : :    vertices contained in bags from  @xmath324 ; @xmath464 : : :    vertices contained in bags of those components    of  @xmath462 that are not adjacent to any bag    from  @xmath324 ; @xmath465 : : :    vertices contained in bags of those components    of  @xmath462 that are adjacent to exactly one bag    from  @xmath324 ; @xmath466 : : :    vertices contained in bags of those components    of  @xmath462 that are adjacent to exactly two bags    from @xmath324 .",
    "we are going to establish an upper bound on the cardinality of each of these sets separately .",
    "upper bounds for  @xmath463 ,  @xmath464 , and  @xmath465 follow already from the introduced reduction rules , but for  @xmath466 we shall need a new reduction rule .",
    "the upper bounds on the cardinalities of  @xmath463 and  @xmath464 are quite straightforward .",
    "[ lem : vi ] @xmath467 .",
    "consider for some @xmath468 the bag @xmath469 .",
    "note that @xmath469 is a module in @xmath34 . by lemma  [ lem : bounded - x - neighborhoods ]",
    "there are only @xmath268 possible @xmath32-neighborhoods among vertices of @xmath34 .",
    "hence , vertices of  @xmath469 can be partitioned into  @xmath268 classes w.r.t .  the neighborhoods in  @xmath32 .",
    "each such class is a module in  @xmath12 that is also a clique , and hence it is a true twin class .",
    "since the twin reduction rule ( rule  [ rule : twin ] ) is not applicable , each true twin class has size at most  @xmath388 , which implies that @xmath470 . as @xmath471 , we conclude that @xmath467 .",
    "we remark that using a more precise analysis of the situation in one bag @xmath469 for @xmath472 , one can see that the @xmath32-neighborhoods of elements of @xmath469 are nested , so there is only at most @xmath473 of them . by plugging in this argument in the proof of lemma  [ lem : vi ] ,",
    "we obtain a sharper upper bound of @xmath2 instead of @xmath474 .",
    "however , the upper bounds on @xmath475 and @xmath476 are @xmath474 and @xmath0 , respectively , so establishing a better bound here would have no influence on the overall asymptotic kernel size .",
    "hence , we resorted to a simpler proof of a weaker upper bound .",
    "[ lem : v0 ] @xmath477 .",
    "observe that @xmath464 is the union of bags of these connected components of @xmath34 , whose universal clique decompositions ( being components of @xmath233 ) do not contain any important bag . by the definition of important bags ,",
    "each such connected component  @xmath305 is a module in  @xmath12 , and clearly its neighborhood is entirely contained in  @xmath32 .",
    "recall that by lemma  [ lem : bounded - x - neighborhoods ] there are only  @xmath268 possible different  @xmath32-neighborhoods among vertices of  @xmath34 .",
    "thus , we can group the connected components of  @xmath478 $ ] according to their @xmath32-neighborhoods into  @xmath268 groups , and the union of vertex sets in each such group forms a module in  @xmath12 .",
    "since rule  [ rule : module ] is not applicable , by corollary  [ cor : small - modules ] we have that each of these modules has size  @xmath479 .",
    "thus we infer that  @xmath477 .    to bound the size of @xmath465",
    "we need a few more definitions .",
    "suppose that  @xmath305 is a component of @xmath462 that is adjacent to exactly one important bag @xmath472 . by the construction of  @xmath324 , we have that  @xmath305 is a tree rooted in a child of  @xmath381 .",
    "we shall say that  @xmath305 is _ attached below  @xmath381_. the union of bags of all the components of @xmath462 attached below  @xmath381 will be called the _ tassel rooted at  @xmath381_. thus ,  @xmath465 can be partitioned into  @xmath325 tassels .",
    "[ lem : one - tassel ] for every @xmath472 , the tassel rooted at @xmath381 has size at most @xmath474 .",
    "let @xmath480 be the components of @xmath462 rooted at the children of @xmath381 , whose union of bags forms the tassel rooted at @xmath381 . recall that none of the @xmath481s contains any important bag .",
    "therefore , from lemma  [ lem : nx - two - types ] we infer that for any @xmath481 and any @xmath247 , either all the vertices from the bags of @xmath481 are adjacent to @xmath372 , or none of them .",
    "thus , the union of bags of each @xmath481 forms a module in @xmath12 : the vertices in this union have the same @xmath32-neighborhood , and moreover their neighborhoods in @xmath34 are formed by the vertices from the bags on the path from @xmath381 to the root of @xmath381 s connected component in @xmath233 .",
    "similarly as in the proof of lemma  [ lem : v0 ] , by lemma  [ lem : bounded - x - neighborhoods ] there are only @xmath268 possible @xmath32-neighborhoods , so we can partition the components @xmath481 into @xmath268 classes with respect to their neighborhoods in @xmath32 .",
    "the union of bags in each such class forms a module in @xmath12 ; since rule  [ rule : module ] is not applicable , by corollary  [ cor : small - modules ] we infer that its size is bounded by @xmath479 .",
    "thus , the total number of vertices in all the components @xmath481 is at most @xmath474 .    as @xmath471",
    ", lemma  [ lem : one - tassel ] immediately implies the following .",
    "[ lem : v1 ] @xmath482 .",
    "we are left with bounding the cardinality of @xmath466 .",
    "let us fix any component  @xmath305 of  @xmath462 which is adjacent in  @xmath233 to two nodes of  @xmath324 . from the construction of @xmath324 , it follows that @xmath305 has the following form :    * @xmath305 contains a path @xmath483 such that in @xmath233 , node @xmath484 is a child of an important node @xmath485 , and @xmath486 has exactly one important child @xmath487 . * for every @xmath488 , @xmath305 contains also all the subtrees of @xmath233 rooted in children of @xmath489 that are different from @xmath490 ( where @xmath491 ) .",
    "such a component  @xmath305 will be called a _ comb _ ( see figure  [ fig : comb ] ) .",
    "the path  @xmath492 is called the _ shaft _ of a comb ; the union of the bags of the shaft will be denoted by  @xmath493 .",
    "the union of the bags of the subtrees rooted in children of  @xmath489 , apart from  @xmath490 , will be called the _ tooth at  @xmath189 _ , and denoted by  @xmath494 .",
    "note that the subgraph induced by a tooth is not necessarily connected ; it is , however , always non - empty by the definition of the universal clique decomposition",
    ". we also denote @xmath495 . by somehow abusing the notation",
    ", we will also denote @xmath496 for @xmath488 .",
    "the number of teeth  @xmath18 is called the _ length _ of a comb .",
    "since the comb @xmath305 does not contain any important vertices , from lemma  [ lem : nx - two - types ] and the construction of  @xmath324 we immediately infer the following observation about the @xmath32-neighborhoods of vertices of the shaft and the teeth .",
    "[ lem : comb - neighborhoods ] there exists two sets @xmath497 with @xmath498 such that @xmath499 for every @xmath500 and @xmath501 for every @xmath502 .",
    "in particular , lemma  [ lem : comb - neighborhoods ] implies that every tooth of a comb is a module .",
    "hence , since rule  [ rule : module ] is not applicable , we infer that @xmath503 for @xmath488 .",
    "also , observe that each @xmath504 is a twin class , so by inapplicability of rule  [ rule : twin ] we conclude that @xmath505 for each @xmath488 .    since @xmath233 is a forest and @xmath471",
    ", it follows that in @xmath462 there are @xmath325 combs .",
    "as we already observed , for each comb the sizes of individual teeth and bags on the shaft are bounded polynomially in @xmath1 .",
    "hence , the only thing that remains is to show how to reduce combs that are long . in order to do this ,",
    "we need one more definition : a tooth @xmath494 is called _ simple _ if @xmath506 $ ] is edgeless , and it is called _ complicated _ otherwise .",
    "we can now state the final reduction rule .",
    "[ rule : comb ] suppose @xmath305 is a comb of length at least @xmath507 , and adopt the introduced notation for the shaft and the teeth of @xmath305 .",
    "define an index @xmath508 as follows :    a.   [ c1 ] if at least @xmath509 teeth @xmath494 are complicated , then we let @xmath510 .",
    "b.   [ c2 ] otherwise , there is a sequence of @xmath509 consecutive teeth @xmath511 that are simple .",
    "let @xmath508 be the index of the last tooth of this sequence , i.e. , @xmath512 .",
    "having defined @xmath508 , remove the tooth @xmath513 from the graph and do not modify the budget .",
    "that is , proceed with the instance @xmath514 .",
    "[ lem : rule - comb - correct ] rule  [ rule : comb ] is safe .",
    "since @xmath515 is an induced subgraph of @xmath12 , then we trivially have that the existence of a solution for @xmath14 implies the existence of a solution for @xmath514 .",
    "hence , we now prove the converse .",
    "suppose that @xmath215 is a solution to @xmath514 , that is , a set of edits in @xmath515 such that @xmath516 is trivially perfect and @xmath414 .",
    "we will say that a tooth @xmath494 is _ spoiled _ if any vertex of @xmath517 is incident to an edit from @xmath215 , and _",
    "clean _ otherwise .",
    "the first goal is to find an index @xmath518 such that    a.   [ q1 ] @xmath519 , b.   [ q2 ] the teeth @xmath520 and @xmath521 are clean , and c.   [ q3 ] if any of the teeth @xmath522 is complicated , then @xmath521 is also complicated .",
    "suppose first that @xmath508 was constructed according to case ( [ c1 ] ) , i.e. , there are at least @xmath509 complicated teeth in the comb , and hence @xmath510",
    ". out of these teeth @xmath494 , at most one can have index @xmath134 , at most one can have index @xmath18 , at most @xmath393 can be spoiled ( since @xmath414 ) and at most @xmath393 can have the preceding tooth @xmath523 spoiled .",
    "this leaves at least one complicated tooth @xmath494 such that @xmath524 and both @xmath494 and @xmath523 are clean",
    ". then we can take @xmath525 ; thus , property ( [ q3 ] ) of @xmath518 is satisfied since @xmath521 is complicated .",
    "suppose then that @xmath508 was constructed according to case ( [ c2 ] ) , i.e. , the following teeth are all simple : @xmath526 .",
    "similarly as before , out of these @xmath509 teeth , one has index @xmath508 , one has index @xmath527 , at most @xmath393 can be spoiled , and at most @xmath393 can have the preceding tooth spoiled .",
    "hence , among them there is a tooth @xmath494 such that @xmath528 and both @xmath494 and @xmath523 are clean .",
    "again , we take @xmath525 ; thus , property ( [ q3 ] ) is satisfied since all the teeth @xmath529 are simple .    with",
    "@xmath518 defined , we are ready to complete the proof of lemma  [ lem : rule - comb - correct ] . to that aim ,",
    "define @xmath530 .",
    "construct @xmath422 from @xmath215 by removing all the edits that are incident to any vertex of  @xmath531 ; clearly  @xmath532 .",
    "we claim that  @xmath422 is a solution to the instance  @xmath14 , that is , that @xmath533 is trivially perfect . for the sake of a contradiction , suppose that  @xmath534 is a vertex set of size  @xmath37 such that  @xmath535 $ ] is a  @xmath28 or a  @xmath29 .",
    "let @xmath536 and @xmath537 .",
    "[ cl : smalla0 ] @xmath538 or @xmath539 .",
    "suppose first that @xmath540 , so @xmath541 . since @xmath542 and @xmath543 , we have that the induced subgraph @xmath535 $ ] is equal to the induced subgraph @xmath544 $ ] . however , the graph @xmath545 is trivially perfect , so it can not have an induced @xmath28 or @xmath29 ; a contradiction .",
    "suppose now that @xmath546 .",
    "since @xmath547 and no edit of @xmath422 is incident to any vertex of @xmath531 , we infer that there is no edit of @xmath422 between vertices of @xmath58 : only at most one vertex of @xmath58 does not belong to @xmath548",
    ". therefore @xmath549=g\\triangle f'[a]$ ] and @xmath549 $ ] is an induced @xmath29 or @xmath28 in the graph @xmath12 .",
    "however , @xmath550 , so @xmath551 .",
    "thus , @xmath549 $ ] would be an obstacle in @xmath12 that has at most one common vertex with tp - modulator @xmath32 , a contradiction with the definition of a tp - modulator ( definition  [ def : modulator ] ) .    to obtain a contradiction",
    ", we shall construct a set @xmath552 satisfying the following properties :    a.   [ p1 ] @xmath553 ; b.   [ p2 ] @xmath554 and @xmath555 $ ] is edgeless if and only if @xmath556 $ ] is edgeless ; c.   [ p3 ] @xmath557 and hence @xmath558 .",
    "let us define @xmath559 .",
    "for now we postpone the exact construction    [ cl : iso ] if @xmath552 satisfies properties ( [ p1 ] ) , ( [ p2 ] ) , and ( [ p3 ] ) , then @xmath535 $ ] is isomorphic to @xmath560 $ ] .    by property ( [ p3 ] ) there exists a bijection  @xmath561 between  @xmath548 and  @xmath552 that preserves belonging to  @xmath493 or  @xmath562 between the argument and the image .",
    "extend  @xmath561 to  @xmath58 by defining @xmath563 for @xmath564 ; we claim that  @xmath561 is an isomorphism between @xmath535 $ ] and @xmath560 $ ] . to see this , observe that since @xmath565 , then we have that no vertex of  @xmath548 or  @xmath552 is incident to any edit of  @xmath422 .",
    "moreover , in  @xmath12 , all the vertices of @xmath566 have the same neighborhood in @xmath567 , and the same holds also for the vertices of  @xmath568 . as the neighborhoods of these vertices in  @xmath12 and in  @xmath533 are exactly the same , we infer that each vertex  @xmath569 is adjacent in @xmath533 to the same vertices of  @xmath570 as the vertex  @xmath571 is .    to conclude the proof , we need to prove that @xmath561 restricted to @xmath552 is also an isomorphism between @xmath572 $ ] and @xmath573 $ ] .",
    "again , @xmath548 and @xmath552 are not incident to any edit of @xmath422 , so @xmath572=g[a_0]$ ] and @xmath573=g[a_0']$ ] . by claim  [ cl : smalla0 ]",
    "we have that @xmath538 or @xmath539 , and we conclude by observing that a pair of simple graphs with at most two vertices are isomorphic if and only if both of them are edgeless or both of them contain an edge , and in both cases any bijection between the vertex sets is an isomorphism .",
    "we now argue that the existence of a set @xmath552 satisfying properties ( [ p1 ] ) , ( [ p2 ] ) , and ( [ p3 ] ) leads to a contradiction .",
    "recall that the teeth  @xmath520 and  @xmath521 are clean , which means that no vertex of @xmath574 is incident to any edit from  @xmath215 .",
    "moreover , as  @xmath575 , we have that @xmath576 . by the construction of  @xmath422 and  @xmath577",
    "we infer that @xmath560=(g-{r_{{\\beta}}})\\triangle f[a']$ ] . by claim  [ cl : iso ]",
    "we have that  @xmath560 $ ] is a  @xmath28 or a  @xmath29 , since @xmath535 $ ] was .",
    "this would , however , mean that @xmath516 would contain an induced  @xmath28 or an induced  @xmath29 , a contradiction to the assumption that @xmath516 is trivially perfect",
    ".    therefore , we are left with constructing a set  @xmath552 satisfying properties ( [ p1 ] ) , ( [ p2 ] ) , and ( [ p3 ] ) .",
    "we give different constructions depending on the alignment of the vertices of  @xmath548 .",
    "in each case we just define @xmath552 ; verifying properties ( [ p1 ] ) , ( [ p2 ] ) , and ( [ p3 ] ) in each case is trivial .",
    ": :    @xmath538 .",
    "+    case 1a . ; ;      @xmath578 and @xmath500 .",
    "then      @xmath579 for any      @xmath580 .",
    "case 1b . ; ;      @xmath578 and @xmath581 .",
    "then      @xmath579 for any      @xmath582 .",
    ": :    @xmath539 .",
    "+    case 2a . ; ;      @xmath583 , @xmath584 .",
    "as      @xmath585 $ ] is a clique , it follows that      @xmath258 .",
    "then @xmath586 for any      @xmath580 and      @xmath587 .",
    "case 2b . ; ;      @xmath583 , @xmath500 ,      @xmath588 , and @xmath589 .",
    "then @xmath586 for any      @xmath580 and      @xmath590 .",
    "case 2c . ; ;      @xmath583 , @xmath500 ,      @xmath588 , and @xmath258 .",
    "then      @xmath586 for any      @xmath591 and @xmath592 .",
    "case 2d . ; ;      @xmath583 , @xmath593 , and      @xmath594 .",
    "then @xmath586 for      any @xmath595 and @xmath592 .",
    "case 2e . ; ;      @xmath583 , @xmath593 , and      @xmath258 . as there are no edges in  @xmath12      between different teeth",
    ", we observe that @xmath596      for some  @xmath189 such that  @xmath597 ,      i.e. , @xmath598 .",
    "in particular , the      tooth  @xmath494 must be complicated .",
    "if  @xmath599 or  @xmath600 , then we      can take @xmath601 .",
    "otherwise we have that      @xmath602 and  @xmath494 is      complicated , so by property ( [ q3 ] ) of  @xmath508 we infer      that  @xmath521 is also complicated .",
    "then we take      @xmath586 for any      @xmath603 such that @xmath604 .",
    "this case study is exhaustive due to claim  [ cl : smalla0 ] .",
    "we can finally gather all the pieces and prove our main theorem .",
    "[ thm : tpe - polykernel ] the problem trivially perfect editing admits a proper kernel with @xmath0 vertices .",
    "the algorithm first applies reduction rules [ rule : c4][rule : module ] exhaustively . as each application of a reduction rule either decreases  @xmath8 and does not change  @xmath1 , or decreases  @xmath1 while not changing  @xmath8 ,",
    "the number of applications of these rules will be bounded by @xmath605 until  @xmath1 becomes negative and we can conclude that we are working with a no - instance . by lemmas  [ lem : basic - rules - sound ] , [ lem :",
    "rule : twin : sound ] ,  [ lem : rule - mod - correct ] , and  [ lem : recognizing - module ] , these rules are safe , applicability of each rule can be recognized in polynomial time , and applying the rules also takes polynomial time .    after rules  [ rule : c4][rule : module ] have been applied exhaustively , we construct a small tp - modulator  @xmath32 using the algorithm of lemma  [ lem : polytime - modulator ] . in case",
    "the construction fails , we conclude that we are working with a no - instance .",
    "otherwise , in polynomial time we construct the universal clique decomposition @xmath233 of @xmath34 , and then we mark the set  @xmath324 of important bags . both locating the important bags and performing the lowest common ancestor closure can be done in polynomial time .",
    "after this , we examine all the combs of @xmath462 . in case",
    "there is a comb of length greater than @xmath507 , we apply rule  [ rule : comb ] on it and restart the whole algorithm . observe that each application of this rule reduces the vertex count by one while keeping  @xmath1 , so the total number of times the algorithm is restarted is bounded by the vertex count of the original instance .",
    "we are left with analyzing the situation when reduction rule  [ rule : comb ] is not applicable , i.e. , all the combs have length less than @xmath507 . as we have argued , the inapplicability of rules  [ rule : twin ] and  [ rule : module ] ensures that bags of shafts of combs have sizes  @xmath325 and teeth of combs have sizes  @xmath479 .",
    "hence , every comb has  @xmath268 vertices .",
    "since the number of combs is  @xmath325 , we infer that @xmath606 . together with the upper bounds on the sizes of  @xmath463 , @xmath464 , and  @xmath465 given by lemmas  [ lem : vi ] ,  [ lem : v0 ] , and  [ lem : v1 ] , we conclude that @xmath607 hence , we can output the current instance as the obtained kernel .",
    "we now present how the technique applied to trivially perfect editing also yields polynomial kernels for trivially perfect completion and trivially perfect deletion after minor modifications .",
    "that is , we prove theorems  [ thm : tpd - polykernel - intro ] and  [ thm : tpc - polykernel - intro ] .    we show that all the rules given above , with only two minor modifications are correct for both problems .",
    "clearly , the running times of the algorithms recognizing applicability of the rule do not depend on the problem we are solving , so we only need to argue for their safeness .    in the first two rules , rules  [ rule : c4 ] and  [ rule : p4 ] , we add and delete an edge , respectively , and the argument is that any editing set of size at most  @xmath1 must necessarily include this edit .",
    "however , in the completion and deletion version , we are not allowed both operations . hence , for the first rule , in the deletion variant we can immediately infer that we are working with a no - instance , and respectively for the second rule in the completion variant .",
    "thus , the two following rules replace rule  [ rule : c4 ] for deletion and rule  [ rule : p4 ] for completion , and their safeness is guaranteed by a trivial modification of the proof of lemma  [ lem : basic - rules - sound ] :    [ rule : c4]d [ rule : c4d ] for an instance @xmath14 with @xmath176 , if there is a matching of size at least @xmath177 in @xmath178}$ ] , then return a trivial no - instance as the computed kernel .",
    "[ rule : p4]c [ rule : p4c ] for an instance @xmath14 with @xmath181 and @xmath182 $ ] and @xmath183 $ ] , if there is a matching in @xmath61 between @xmath184 and @xmath185 of size at least @xmath177 , then return a trivial no - instance as the computed kernel .",
    "observe that rules  [ rule : c4d ] and  [ rule : p4c ] are applicable in exactly the same instances as their unmodified variants .",
    "hence , exhaustive application of the basic rules with any of these modifications results in exactly the same notion of a reduced instance as the one introduced in section  [ sec : basic - rules ] .",
    "we now argue that rules  [ rule : twin ] and  [ rule : module ] are safe for both the deletion and the completion variant , without any modifications .",
    "[ lem : module - rules - safe ] rules  [ rule : twin ] and [ rule : module ] are safe both for trivially perfect deletion and for trivially perfect completion .",
    "the proof of the safeness of rule  [ rule : twin ] ( lemma  [ lem : rule : twin : sound ] ) in fact argues that every editing set @xmath215 for @xmath387 with @xmath414 is also an editing set for @xmath14 .",
    "this holds also for editing sets that consist only of edge additions / deletions , so the reasoning remains the same for trivially perfect deletion and trivially perfect completion .",
    "the proof of the safeness of rule  [ rule : module ] ( lemma  [ lem : rule - mod - correct ] ) first argues that any minimum - size editing set @xmath215 for the reduced instance @xmath413 is not incident to any vertex of @xmath324 .",
    "this is done by showing that otherwise @xmath215 would not be an inclusion - wise minimal editing set ( proof of claim  [ claim : i - notin - f ] ) , and the argumentation can be in the same manner applied to minimum - size completion / deletion sets .",
    "then it is argued that @xmath215 is in fact an editing set for the original instance @xmath14 , and the argumentation is oblivious to whether @xmath215 is allowed to contain edge additions or deletions .",
    "we now proceed to the analysis of rule  [ rule : comb ] in the completion and deletion variants .",
    "first , let us consider the construction of the modulator . in the completion /",
    "deletion variants we can construct the modulator in exactly the same manner as for editing",
    ". indeed , the main argument for the bound @xmath175 states that if the construction was performed for more than @xmath1 rounds , then we are dealing with a no - instance , since then any editing set for @xmath12 has size at least @xmath177 .",
    "completion and deletion sets are editing sets in particular , so the same argument holds also for trivially perfect deletion and trivially perfect completion .",
    "results of sections  [ sec : modulator - nei ] and  [ sec : impbags ] , i.e. , the analysis of the @xmath32-neighborhoods and marking of the important bags , work in exactly the same manner , since they are based on the same notions of a reduced instance and of a tp - modulator .",
    "thus , lemma  [ lem : bounded - x - neighborhoods ] holds as well , and we have marked the same set @xmath324 of @xmath325 important bags , with the same properties .",
    "rules  [ rule : twin ] and  [ rule : module ] are not modified , so the bounds on @xmath608 , @xmath475 and @xmath476 from lemmas  [ lem : vi ] ,  [ lem : v0 ] , and  [ lem : v1 ] also hold .",
    "we are left with analyzing rule  [ rule : comb ] , and we claim that this rule is also safe for trivially perfect deletion and trivially perfect completion without any modifications . indeed , in the proof of the safeness of the rule ( lemma  [ lem : rule - comb - correct ] ) , we have argued that for every editing set  @xmath215 ( @xmath414 ) for the new instance  @xmath413 , there exists some  @xmath426 which is a solution to the original instance  @xmath14 . in case",
    "@xmath215 consists of edge deletions or edge additions only , so does  @xmath422 .",
    "hence ,  @xmath413 being a yes - instance of trivially perfect deletion , resp .",
    "trivially perfect completion , implies that  @xmath14 is also a yes - instance of the same problem .",
    "thus rule  [ rule : comb ] is safe without any modifications , and the kernel size analysis contained in the proof of theorem  [ thm : tpe - polykernel ] ( end of section  [ sec : kernel - final ] ) can be performed in exactly the same manner .",
    "this concludes the proof of theorems  [ thm : tpd - polykernel - intro ] and  [ thm : tpc - polykernel - intro ] .",
    "in this section we show that trivially perfect editing is -hard , and furthermore not solvable in subexponential parameterized time unless the exponential time hypothesis fails . recall that the -hardness of the problem was already established by nastos and gao  @xcite .",
    "their reduction ( see the proof of theorem 3.3 in  @xcite ) starts with an instance of exact 3-cover with universe of size  @xmath8 and set family of size  @xmath104 , and constructs an instance  @xmath14 of trivially perfect editing with @xmath609 .",
    "thus , the parameter blow - up is at least cubic , and the reduction can not be used to establish the non - existence of a subexponential parameterized algorithm under eth .    here , we give a direct , linear reduction from 3sat to trivially perfect editing .",
    "furthermore , the resulting graph in our reduction has maximum degree equal to  @xmath37 .",
    "thus , we in fact prove that even on input graphs of maximum degree  @xmath37 , trivially perfect editing remains -hard and does not admit a subexponential parameterized algorithm , unless eth fails .",
    "formally , the following theorem will be proved , where for an input formula  @xmath610 of 3sat , by @xmath611 and @xmath612 we denote the variable and clause sets of  @xmath610 , respectively :    [ thm : np - hardness ] there exists a polynomial - time reduction that , given an instance @xmath610 of 3sat , returns an equivalent instance @xmath613 of trivially perfect editing , where @xmath614 , @xmath615 , @xmath616 , and @xmath617 .",
    "consequently , even on instances with maximum degree @xmath37 , trivially perfect editing remains -hard and can not be solved in time @xmath26 or @xmath36 , unless eth fails .",
    "theorem  [ thm : np - hardness ] clearly refines theorem  [ thm : eth - hardness - intro ] , and its conclusion follows from the reduction by an application of proposition  [ prop : eth ] .",
    "hence , we are left with constructing the reduction , to which the rest of this section is devoted .",
    "our approach is similar to the technique used by komusiewicz and uhlmann to show the hardness of a similar problem , cluster editing  @xcite ; however , the gadgets are heavily modified to work for the trivially perfect editing problem .",
    "let @xmath610 be the input instance of 3sat .",
    "by standard modifications of the formula we may assume that every clause contains exactly three literals , all containing different variables , and that every variable appears in at least two clauses . for a variable @xmath618 , let  @xmath619 be the number of occurrences of  @xmath372 in the clauses of  @xmath610 ; moreover , we order these occurrences arbitrarily . observe that @xmath620 .",
    "now , for every @xmath621 we create a _ variable gadget _ , and for every @xmath622 we create a _ clause gadget_.    ( tx1 ) at ( cos(60),sin(60 ) )",
    "[ label = left:@xmath623 ; ( bx1 ) at ( cos(80),sin(80 ) ) [ label = below left:@xmath624 ; ( sx1 ) at ( cos(100),sin(100 ) ) [ label = left:@xmath625 ; ( px1 ) at ( 0.75*cos(70),0.75*sin(70 ) ) [ label = below left:@xmath626 ;    ( tx2 ) at ( cos(0),sin(0 ) ) [ label = left:@xmath627 ; ( bx2 ) at ( cos(20),sin(20 ) ) [ label = left:@xmath628 ; ( sx2 ) at ( cos(40),sin(40 ) ) [ label = left:@xmath629 ; ( px2 ) at ( 0.75*cos(10),0.75*sin(10 ) ) [ label = left:@xmath630 ;    ( tx3 ) at ( cos(-60),sin(-60 ) [ label = above left:@xmath631 ; ( bx3 ) at ( cos(-40),sin(-40 ) [ label = above left:@xmath632 ; ( sx3 ) at ( cos(-20),sin(-20 ) [ label = left:@xmath633 ; ( px3 ) at ( 0.75*cos(-50),0.75*sin(-50 ) ) [ label = above left:@xmath634 ;    ( tx4 ) at ( cos(-120),sin(-120 ) ) [ label = above:@xmath635 ; ( bx4 ) at ( cos(-100),sin(-100 ) ) [ label = above right:@xmath636 ; ( sx4 ) at ( cos(-80),sin(-80 ) ) [ label = above:@xmath637 ; ( px4 ) at ( 0.75*cos(-110),0.75*sin(-110 ) ) [ label = above:@xmath638 ;    ( gx ) at ( 0,0 ) @xmath639 ;    ( sx1 )  ( bx1 )  ( tx1 )  ( sx2 )  ( bx2 )  ( tx2 )  ( sx3 )  ( bx3 )  ( tx3 )  ( sx4 )  ( bx4 )  ( tx4 ) ;    ( tx1 )  ( px1 )  ( bx1 ) ; ( tx2 )  ( px2 )  ( bx2 ) ; ( tx3 )  ( px3 )  ( bx3 ) ; ( tx4 )  ( px4 )  ( bx4 ) ;    ( ty1 ) at ( 2+cos(-40),2+sin(-40 ) ) [ label = left:@xmath640 ; ( by1 ) at ( 2+cos(-20),2+sin(-20 ) ) [ label = above left:@xmath641 ; ( sy1 ) at ( 2+cos(0),2+sin(0 ) ) [ label = above left:@xmath642 ; ( py1 ) at ( 2 + 0.75*cos(-30),2 + 0.75*sin(-30 ) ) [ label = left:@xmath643 ;    ( ty2 ) at ( 2+cos(-100),2+sin(-100 ) ) [ label = above:@xmath644 ; ( by2 ) at ( 2+cos(-80),2+sin(-80 ) ) [ label = above:@xmath645 ; ( sy2 ) at ( 2+cos(-60),2+sin(-60 ) ) [ label = above left:@xmath646 ; ( py2 ) at ( 2 + 0.75*cos(-90),2 + 0.75*sin(-90 ) ) [ label = above:@xmath647 ;    ( ty3 ) at ( 2+cos(-160),2+sin(-160 ) [ label = above right:@xmath648 ; ( by3 ) at ( 2+cos(-140),2+sin(-140 ) [ label = right:@xmath649 ; ( sy3 ) at ( 2+cos(-120),2+sin(-120 ) [ label = above right:@xmath650 ; ( py3 ) at ( 2 + 0.75*cos(-150),2 + 0.75*sin(-150 ) ) [ label = above right:@xmath651 ;    ( ty4 ) at ( 2+cos(-220),2+sin(-220 ) ) [ label = above right:@xmath652 ; ( by4 ) at ( 2+cos(-200),2+sin(-200 ) ) [ label = below right:@xmath653 ; ( sy4 ) at ( 2+cos(-180),2+sin(-180 ) ) [ label = right:@xmath654 ; ( py4 ) at ( 2 + 0.75*cos(-210),2 + 0.75*sin(-210 ) ) [ label = right:@xmath655 ;    ( gy ) at ( 2,2 ) @xmath656 ;    ( sy1 )  ( by1 )  ( ty1 )  ( sy2 )  ( by2 ) ",
    "( ty2 )  ( sy3 )  ( by3 ) ",
    "( ty3 )  ( sy4 )  ( by4 )  ( ty4 ) ;    ( ty1 )  ( py1 )  ( by1 ) ; ( ty2 )  ( py2 ) ",
    "( by2 ) ; ( ty3 )  ( py3 )  ( by3 ) ; ( ty4 )  ( py4 ) ",
    "( by4 ) ;    ( tz1 ) at ( 4+cos(240),sin(240 ) ) [ label = above:@xmath657 ; ( bz1 ) at ( 4+cos(260),sin(260 ) ) [ label = above right:@xmath658 ; ( sz1 ) at ( 4+cos(280),sin(280 ) ) [ label = above:@xmath659 ; ( pz1 ) at ( 4 + 0.75*cos(250),0.75*sin(250 ) ) [ label = above right:@xmath660 ;    ( tz2 ) at ( 4+cos(180),sin(180 ) ) [ label = above right:@xmath661 ; ( bz2 ) at ( 4+cos(200),sin(200 ) ) [ label = right:@xmath662 ; ( sz2 ) at ( 4+cos(220),sin(220 ) ) [ label = above right:@xmath663 ; ( pz2 ) at ( 4 + 0.75*cos(190),0.75*sin(190 ) ) [ label = right:@xmath664 ;    ( tz3 ) at ( 4+cos(120),sin(120 ) [ label = below right:@xmath665 ; ( bz3 ) at ( 4+cos(140),sin(140 ) [ label = below right:@xmath666 ; ( sz3 ) at ( 4+cos(160),sin(160 ) [ label = right:@xmath667 ; ( pz3 ) at ( 4 + 0.75*cos(130),0.75*sin(130 ) ) [ label = below right:@xmath668 ;    ( tz4 ) at ( 4+cos(60),sin(60 ) ) [ label = below right:@xmath669 ; ( bz4 ) at ( 4+cos(80),sin(80 ) ) [ label = below left:@xmath670 ; ( sz4 ) at ( 4+cos(100),sin(100 ) ) [ label = below:@xmath671 ; ( pz4 ) at ( 4 + 0.75*cos(70),0.75*sin(70 ) ) [ label = below left:@xmath672 ;    ( gz ) at ( 4,0 ) @xmath673 ;    ( sz1 )  ( bz1 )  ( tz1 )  ( sz2 )  ( bz2 )  ( tz2 )  ( sz3 )  ( bz3 )  ( tz3 )  ( sz4 )  ( bz4 ) ",
    "( tz4 ) ;    ( tz1 )  ( pz1 ) ",
    "( bz1 ) ; ( tz2 ) ",
    "( pz2 )  ( bz2 ) ; ( tz3 )  ( pz3 )  ( bz3 ) ; ( tz4 )  ( pz4 )  ( bz4 ) ;    ( gc ) at ( 2,-.1 ) @xmath674 ; ( c ) at ( 2,.2 ) ;    \\(c ) to[looseness=1 , out=180 , in=0 ] ( tx2 ) ; ( c ) to[looseness=1 , out=90 , in=-90 ] ( by2 ) ; ( c ) to[looseness=1 , out=0 , in=180 ] ( tz2 ) ;    ( tx1 ) at ( cos(60),sin(60 ) ) [ label = left:@xmath623 ; ( bx1 ) at ( cos(80),sin(80 ) ) [ label = below left:@xmath624 ; ( sx1 ) at ( cos(100),sin(100 ) ) [ label = left:@xmath625 ; ( px1 ) at ( 0.75*cos(70),0.75*sin(70 ) ) [ label = below left:@xmath626 ;    ( tx2 ) at ( cos(0),sin(0 ) ) [ label = left:@xmath627 ; ( bx2 ) at ( cos(20),sin(20 ) ) [ label = left:@xmath628 ; ( sx2 ) at ( cos(40),sin(40 ) ) [ label = left:@xmath629 ; ( px2 ) at ( 0.75*cos(10),0.75*sin(10 ) ) [ label = left:@xmath630 ;    ( tx3 ) at ( cos(-60),sin(-60 ) [ label = above left:@xmath631 ; ( bx3 ) at ( cos(-40),sin(-40 ) [ label = above left:@xmath632 ; ( sx3 ) at ( cos(-20),sin(-20 ) [ label = left:@xmath633 ; ( px3 ) at ( 0.75*cos(-50),0.75*sin(-50 ) ) [ label = above left:@xmath634 ;    ( tx4 ) at ( cos(-120),sin(-120 ) ) [ label = above:@xmath635 ; ( bx4 ) at ( cos(-100),sin(-100 ) ) [ label = above right:@xmath636 ; ( sx4 ) at ( cos(-80),sin(-80 ) ) [ label = above:@xmath637 ; ( px4 ) at ( 0.75*cos(-110),0.75*sin(-110 ) ) [ label = above:@xmath638 ;    ( gx ) at ( 0,0 ) @xmath639 ;    ( bx1 )  ( tx1 ) ",
    "( sx2 ) ; ( bx2 )  ( tx2 )  ( sx3 ) ; ( bx3 )  ( tx3 )  ( sx4 ) ; ( bx4 )  ( tx4 ) ;    ( tx1 )  ( px1 ) ",
    "( bx1 ) ; ( tx2 ) ",
    "( px2 )  ( bx2 ) ; ( tx3 )  ( px3 )  ( bx3 ) ; ( tx4 )  ( px4 )  ( bx4 ) ;    ( ty1 ) at ( 2+cos(-40),2+sin(-40 ) ) [ label = left:@xmath640 ; ( by1 ) at ( 2+cos(-20),2+sin(-20 ) ) [ label = above left:@xmath641 ; ( sy1 ) at ( 2+cos(0),2+sin(0 ) ) [ label = above left:@xmath642 ; ( py1 ) at ( 2 + 0.75*cos(-30),2 + 0.75*sin(-30 ) ) [ label = left:@xmath643 ;    ( ty2 ) at ( 2+cos(-100),2+sin(-100 ) ) [ label = above:@xmath644 ; ( by2 ) at ( 2+cos(-80),2+sin(-80 ) ) [ label = above:@xmath645 ; ( sy2 ) at ( 2+cos(-60),2+sin(-60 ) ) [ label = above left:@xmath646 ; ( py2 ) at ( 2 + 0.75*cos(-90),2 + 0.75*sin(-90 ) ) [ label = above:@xmath647 ;    ( ty3 ) at ( 2+cos(-160),2+sin(-160 ) [ label = above right:@xmath648 ; ( by3 ) at ( 2+cos(-140),2+sin(-140 ) [ label = right:@xmath649 ; ( sy3 ) at ( 2+cos(-120),2+sin(-120 ) [ label = above right:@xmath650 ; ( py3 ) at ( 2 + 0.75*cos(-150),2 + 0.75*sin(-150 ) ) [ label = above right:@xmath651 ;    ( ty4 ) at ( 2+cos(-220),2+sin(-220 ) ) [ label = above right:@xmath652 ; ( by4 ) at ( 2+cos(-200),2+sin(-200 ) ) [ label = below right:@xmath653 ; ( sy4 ) at ( 2+cos(-180),2+sin(-180 ) ) [ label = right:@xmath654 ; ( py4 ) at ( 2 + 0.75*cos(-210),2 + 0.75*sin(-210 ) ) [ label = right:@xmath655 ;    ( gy ) at ( 2,2 ) @xmath656 ;    ( by1 )  ( ty1 )  ( sy2 ) ; ( by2 )  ( ty2 )  ( sy3 ) ; ( by3 )  ( ty3 )  ( sy4 ) ; ( by4 )  ( ty4 ) ;    ( ty1 )  ( py1 )  ( by1 ) ; ( ty2 )  ( py2 )  ( by2 ) ; ( ty3 )  ( py3 ) ",
    "( by3 ) ; ( ty4 )  ( py4 )  ( by4 ) ;    ( tz1 ) at ( 4+cos(240),sin(240 ) ) [ label = above:@xmath657 ; ( bz1 ) at ( 4+cos(260),sin(260 ) ) [ label = above right:@xmath658 ; ( sz1 ) at ( 4+cos(280),sin(280 ) ) [ label = above:@xmath659 ; ( pz1 ) at ( 4 + 0.75*cos(250),0.75*sin(250 ) ) [ label = above right:@xmath660 ;    ( tz2 ) at ( 4+cos(180),sin(180 ) ) [ label = above right:@xmath661 ; ( bz2 ) at ( 4+cos(200),sin(200 ) ) [ label = right:@xmath662 ; ( sz2 ) at ( 4+cos(220),sin(220 ) ) [ label = above right:@xmath663 ; ( pz2 ) at ( 4 + 0.75*cos(190),0.75*sin(190 ) ) [ label = right:@xmath664 ;    ( tz3 ) at ( 4+cos(120),sin(120 ) [ label = below right:@xmath665 ; ( bz3 ) at ( 4+cos(140),sin(140 ) [ label = below right:@xmath666 ; ( sz3 ) at ( 4+cos(160),sin(160 ) [ label = right:@xmath667 ; ( pz3 ) at ( 4 + 0.75*cos(130),0.75*sin(130 ) ) [ label = below right:@xmath668 ;    ( tz4 ) at ( 4+cos(60),sin(60 ) ) [ label = below right:@xmath669 ; ( bz4 ) at ( 4+cos(80),sin(80 ) ) [ label = below left:@xmath670 ; ( sz4 ) at ( 4+cos(100),sin(100 ) ) [ label = below:@xmath671 ; ( pz4 ) at ( 4 + 0.75*cos(70),0.75*sin(70 ) ) [ label = below left:@xmath672 ;    ( gz ) at ( 4,0 ) @xmath673 ;    ( sz1 )  ( bz1 )  ( tz1 ) ; ( sz2 )  ( bz2 )  ( tz2 ) ; ( sz3 )  ( bz3 )  ( tz3 ) ; ( sz4 )  ( bz4 )  ( tz4 ) ;    ( tz1 )  ( pz1 )  ( bz1 ) ; ( tz2 )  ( pz2 )  ( bz2 ) ; ( tz3 )  ( pz3 )  ( bz3 ) ; ( tz4 )  ( pz4 )  ( bz4 ) ;    ( gc ) at ( 2,-.1 ) @xmath674 ; ( c ) at ( 2,.2 ) ;    \\(c ) to[looseness=1 , out=180 , in=0 ] ( tx2 ) ;    [ [ variable - gadgets . ] ] variable gadgets .",
    "+ + + + + + + + + + + + + + + + +    for @xmath675 , construct a graph @xmath639 isomorphic to @xmath676 , a cycle on @xmath677 vertices .",
    "the vertices of @xmath639 are labeled @xmath678 for @xmath679 $ ] , in the order of their appearance on the cycle .",
    "we then add a vertex @xmath680 adjacent to @xmath681 and @xmath682 , for each @xmath683 $ ] , see figure  [ fig : clause - gadget ] .",
    "formally , the vertices @xmath680 do not belong to @xmath639 , but they will be used to wire variable gadgets with clause gadgets .",
    "this concludes the construction of the variable gadget , and it should be clear that the number of created vertices and edges is bounded linearly in @xmath684 ; more precisely , we created @xmath685 vertices and @xmath686 edges .    for the sake of later argumentation",
    ", we now define the deletion set @xmath687 for @xmath639 .",
    "if , in an assignment of variables @xmath688 , we have @xmath689 , then we let @xmath687 be the set consisting of every edge of the form @xmath690 for",
    "@xmath691 $ ] .",
    "if , on the other hand , @xmath692 , we define the deletion set @xmath687 to be the set comprising the edges @xmath693 for @xmath691 $ ] , see figure  [ fig : clause - gadget - edited ] .",
    "we will later show that these are the only relevant editing sets of size at most @xmath684 for @xmath639 .",
    "[ [ clause - gadget . ] ] clause gadget .",
    "+ + + + + + + + + + + + + +    the clause gadgets are very simple . a clause gadget consists simply of one vertex , i.e. , for a clause @xmath694 construct the vertex  @xmath695 .",
    "this vertex will be connected to  @xmath639 ,  @xmath656 and  @xmath673 , for  @xmath372 ,  @xmath346 , and  @xmath696 being the variables appearing in  @xmath10 , in appropriate places , depending on whether the variable occurs positively or negatively in  @xmath10 .",
    "more precisely , if  @xmath10 is the  @xmath189th clause  @xmath372 appears in , then we make  @xmath695 adjacent to  @xmath681 provided that  @xmath372 appears positively in  @xmath10 , and to  @xmath682 provided that  @xmath372 appears negatively in  @xmath10 .",
    "this concludes the construction of a clause gadget .",
    "as every clause gadget contains one vertex and three edges , the construction of all the clause gadgets creates @xmath697 vertices and @xmath698 edges .    the deletion set for a clause gadget will be as follows .",
    "let @xmath688 , be an assignment of the variables that satisfies all the clauses .",
    "suppose @xmath699 , where the literals  @xmath700 ,  @xmath701 , and  @xmath702 contain variables  @xmath372 ,  @xmath346 , and  @xmath696 , respectively .",
    "pick any literal satisfying  @xmath10 , say  @xmath700 , and delete the two other edges in the connection , i.e. , the two edges connecting  @xmath695 with vertices of  @xmath656 and  @xmath673 .",
    "thus  @xmath695 remains a vertex of degree  @xmath134 , adjacent to a vertex of  @xmath639 .",
    "let @xmath703 be the constructed graph .",
    "we set the budget for edits to @xmath704 observe also that latexmath:[\\[\\begin{aligned }     and that @xmath617 .",
    "thus , all the technical properties stated in theorem  [ thm : np - hardness ] are satisfied , and we are left with proving that @xmath613 is a yes - instance of trivially perfect editing if and only if @xmath610 is satisfiable .    before we state the main lemma , we give two auxiliary observations that settle the tightness of the budget :    [ claim : var - gadget - tight ] suppose that a graph @xmath20 is a cycle on @xmath706 vertices for some @xmath707 , and suppose  @xmath215 is an editing set for  @xmath20 . then @xmath708 . moreover , if  @xmath709 then  @xmath215 consists of deletions of every third edge of the cycle .",
    "[ claim : clause - gadget - tight ] suppose a graph @xmath20 is a _ subdivided claw _ , i.e. , the star @xmath710 with every leg subdivided once ( see figure  [ fig : subdivided - claw ] ) . furthermore , suppose that  @xmath215 is an editing set for  @xmath20 . then  @xmath711 . moreover , if  @xmath712 then  @xmath215 consists of deletions of two edges incident to the center of the subdivided claw ( see figure  [ fig : subdivided - claw - edited ] )",
    ".    we will prove the two claims in order now .",
    "the astute reader should already see that this implies the tightness of the budget : every editing set needs to include exactly  @xmath684 edges of every variable gadget  @xmath639 ( by claim  [ claim : var - gadget - tight ] ) , and exactly two edges incident to every vertex  @xmath695 ( by claim  [ claim : clause - gadget - tight ] ) .",
    "the additional vertices  @xmath680 will form the degree-1 vertices of subdivided claws created by clause gadgets , and all the subgraphs in question pairwise share at most single vertices , which means that any edit can influence at most one of them .",
    "this statement is made formal in the proof of lemma  [ lem:3sat - tpe ] .",
    "let @xmath713 be the vertices of  @xmath20 , in their order of appearance on the cycle .",
    "for @xmath714 , let @xmath715 ; here and in the sequel , the indices behave cyclically in a natural manner .",
    "observe that each @xmath716 induces a @xmath28 in @xmath20 , hence @xmath717 .",
    "however , the sets @xmath718 are pairwise disjoint for @xmath714 , from which it follows that @xmath719 .",
    "suppose now that @xmath709 .",
    "hence @xmath720 for each @xmath721 $ ] , and there are no edits outside the sets @xmath718 .",
    "there are five possible ways for an @xmath716 of how @xmath722 can look like : it is either a deletion of the edge @xmath723 , @xmath724 , or @xmath725 ( henceforth referred to as types  @xmath726 ,  @xmath727 , and  @xmath728 , respectively ) , or an addition of the edge @xmath729 or @xmath730 ( henceforth called types  @xmath731 and  @xmath732 , respectively)the sixth possibility , which has been left out , creates an induced  @xmath29 .",
    "observe now that if some  @xmath716 has type  @xmath726 , then  @xmath733 also has type  @xmath726 , or otherwise a  @xmath28 @xmath734 would remain in the graph . similarly ,",
    "if  @xmath716 has type  @xmath728 then  @xmath735 also has type  @xmath728 .",
    "hence , if type  @xmath728 or  @xmath726 appears for any  @xmath716 , then all the  @xmath716s have the same type .",
    "observe now that if some  @xmath716 had type  @xmath731 and  @xmath732 , then  @xmath735 would have to have type  @xmath728 and  @xmath733 would have to have type  @xmath726 or otherwise an unresolved  @xmath28 would appear ; this is a contradiction with the previous observations , since types  @xmath726 and  @xmath728 can not appear simultaneously .",
    "hence , we are left with only three possibilities : all the  @xmath716s have type  @xmath726 , or all have type  @xmath727 , or all have type  @xmath728 .",
    "denote the vertices of @xmath20 as in figure  [ fig : subdivided - claw ] .",
    "consider the following three @xmath28s in @xmath20 :    * @xmath736 , * @xmath737 , and * @xmath738 .",
    "0.45    \\(v ) at ( 0,0 ) @xmath43 ; ( a1 ) at ( 0,1 ) @xmath486 ; ( a2 ) at ( 0,2 ) @xmath739 ; ( b1 ) at ( -,- ) @xmath740 ; ( b2 ) at ( -,- ) @xmath741 ; ( c1 ) at ( , - ) @xmath742 ; ( c2 ) at ( , - ) @xmath743 ;    ( a2 )  ( a1 )  ( v )  ( b1 )  ( b2 ) ; ( v ) ",
    "( c1 )  ( c2 ) ;    0.45    \\(v ) at ( 0,0 ) @xmath43 ; ( a1 ) at ( 0,1 ) @xmath486 ; ( a2 ) at ( 0,2 ) @xmath739 ; ( b1 ) at ( -,- ) @xmath740 ; ( b2 ) at ( -,- ) @xmath741 ; ( c1 ) at ( , - ) @xmath742 ; ( c2 ) at ( , - ) @xmath743 ;    ( a2 )  ( a1 )  ( v ) ; ( b1 )  ( b2 ) ; ( c1 )  ( c2 ) ;    observe that any edge addition in @xmath20 can destroy at most one of these  @xmath28s , and a deletion of any of edges @xmath744 , @xmath745 , or @xmath746 also can destroy at most one of these  @xmath28s .",
    "moreover , a deletion of any of the edges incident to the center  @xmath43 destroys only two of them .",
    "we infer that  @xmath711 since no single edit can destroy all three considered  @xmath28s , and moreover if  @xmath712 , then  @xmath215 contains at least one deletion of an edge incident to  @xmath43 , say  @xmath747 . after deleting this edge",
    "we are left with a  @xmath748 @xmath749 , and it can be readily checked that the only way to edit it to a trivially perfect graph using only one edit is to delete  @xmath750 or  @xmath751 .",
    "thus , any editing set  @xmath215 with  @xmath712 in fact consists of deletions of two edges incident to  @xmath43 .",
    "[ lem:3sat - tpe ] the input 3sat instance @xmath610 is satisfiable if and only if @xmath613 is a yes - instance of trivially perfect editing .",
    "suppose @xmath610 is satisfiable and let @xmath752 be a satisfying assignment .",
    "define editing set @xmath753 ; note that  @xmath215 consists of deletions only .",
    "then we have that  @xmath754 and it can be easily seen that  @xmath398 is a disjoint union of components of constant size , each being a paw or a cricket ( see figure  [ fig : three - graphs ] ) . both these graphs are trivially perfect , so a disjoint union of any number of their copies is also a trivially perfect graph .",
    "thus  @xmath755 is a solution to the instance  @xmath613 .",
    "0.3    \\(1 ) at ( 0,0 ) ; ( 2 ) at ( 1,0 ) ; ( 3 ) at ( 0,1 ) ; ( 4 ) at ( 1,1 ) ;    \\(1 )  ( 2 ) ; ( 1 )  ( 3 ) ; ( 4 )  ( 3 ) ; ( 1 )  ( 4 ) ;    0.3    \\(1 ) at ( .5,0 ) ; ( 2 ) at ( 0,1 ) ; ( 3 ) at ( 1,1 ) ; ( 4 ) at ( 1,0 ) ; ( 5 ) at ( 0,0 ) ;    \\(1 )  ( 2 )  ( 3 )  ( 1 ) ; ( 1 )  ( 4 ) ; ( 1 )  ( 5 ) ;    for the other direction , let @xmath756 be an editing set such that @xmath757 is trivially perfect , and @xmath758 .",
    "for every @xmath621 consider the subgraph @xmath639 .",
    "for every @xmath622 consider the subgraph @xmath674 induced in @xmath12 by    * vertex @xmath695 ; * the three neighbors of @xmath695 , say @xmath759 , @xmath760 , and @xmath761 , where @xmath762 are variables appearing in @xmath10 and each symbol @xmath763 is replaced by @xmath764 or @xmath765 depending whether the variable s occurrence is positive or negative ; and * vertices @xmath766 , @xmath767 , and @xmath768 .",
    "observe that each @xmath639 is isomorphic to a cycle on @xmath677 vertices and each @xmath674 is isomorphic to a subdivided claw .",
    "moreover , all these subgraphs pairwise share at most one vertex , which means that sets @xmath769 for @xmath621 and @xmath770 for @xmath622 are pairwise disjoint . by claim  [ claim : var - gadget - tight ]",
    "we infer that @xmath771 for each @xmath772 , and by claim  [ claim : clause - gadget - tight ] we infer that @xmath773 for each @xmath774 .",
    "thus @xmath775 hence , in fact @xmath776 and all the used inequalities are in fact equalities : @xmath777 for each @xmath772 and @xmath778 for each @xmath774 . using claims  [ claim : var - gadget - tight ] and  [",
    "claim : clause - gadget - tight ] again , we infer that @xmath215 has the following form : it consists of deletions only , from every cycle @xmath639 it deletes every third edge , and for every vertex @xmath695 it deletes two out of three edges incident to it . in particular , no edit is incident to any of the vertices @xmath680 for @xmath772 and @xmath683 $ ] .",
    "consider now the cycle @xmath639 ; we already know that the solution deletes either all the edges @xmath779 for @xmath780 $ ] , or all the edges @xmath781 for @xmath780 $ ] , or all the edges @xmath782 for @xmath683 $ ] .",
    "observe that the first case can not happen , since then we would have an induced @xmath28 @xmath783 remaining in the graph  no other edit can destroy it . hence , one of the latter two cases happen .",
    "construct an assignment @xmath784 by , for each @xmath621 , putting @xmath785 if all the edges @xmath781 are included in @xmath215 , and @xmath786 if all the edges @xmath782 are included in @xmath215 .",
    "we now claim that @xmath457 satisfies @xmath610 .    for the sake of contradiction ,",
    "suppose that a clause @xmath787 is not satisfied by @xmath457 .",
    "let @xmath788 be the edge incident to @xmath695 which has not been removed and suppose without loss of generality that this edge connects @xmath695 with @xmath639 .",
    "suppose further that @xmath789 , i.e. , @xmath372 appears positively in @xmath10 , so @xmath790 for some @xmath683 $ ] .",
    "since @xmath372 does not satisfy @xmath10 , @xmath692 and both edges @xmath791 and @xmath792 are not deleted in @xmath215  the deleted edge is @xmath693 .",
    "but then we have the following induced @xmath28 : @xmath793 , which contradicts the assumption that @xmath757 is trivially perfect . the case",
    "when @xmath794 , i.e. , @xmath372 appears negatively in @xmath10 , is symmetric .",
    "hence @xmath457 is indeed a satisfying assignment for @xmath610 and we are done .",
    "lemma  [ lem:3sat - tpe ] guarantees that the reduction is correct , and hence theorem  [ thm : np - hardness ] follows by a straightforward application of proposition  [ prop : eth ] .",
    "we can also observe that this reduction works immediately for trivially perfect deletion as well since every optimal edit set consisted purely of deletions ( see claims  [ claim : var - gadget - tight ] and  [ claim : clause - gadget - tight ] ) , however this result is known  @xcite .",
    "in this paper we gave the first polynomial kernels for trivially perfect editing and trivially perfect deletion , which answers an open problem by nastos and gao  @xcite , and liu , wang , and guo  @xcite .",
    "we also proved that assuming eth , trivially perfect editing does not have a subexponential parameterized algorithm . together with the earlier results  @xcite",
    ", we thus obtain a complete picture of the existence of polynomial kernels and subexponential parameterized algorithms for edge modification problems related to trivially perfect graphs ; see figure  [ fig : tab : tp - complexity ] for an overview . in particular",
    ", the fact that all three problems trivially perfect editing , trivially perfect completion , and trivially perfect deletion admit polynomial kernels , stands in an interesting contrast with the results of cai and cai  @xcite , who showed that this is not the case for any of @xmath29-free editing , @xmath29-free completion and @xmath29-free deletion .",
    "the main contribution of the paper is the proof that trivially perfect editing admits a polynomial kernel with @xmath0 vertices .",
    "we apply the existing technique of constructing a _ vertex modulator _ , but with a new twist : the fact that we are solving an edge modification problem enables us also to argue about the adjacency structure between the modulator and the rest of the graph , which is helpful in understanding the structure of the instance .",
    "we believe that this new insight can be applied to other edge modification problems as well .",
    "finally , we showed that trivially perfect editing , in addition to being -complete , is not solvable in subexponential parameterized time unless the exponential time hypothesis fails .",
    "the same result was known for trivially perfect deletion , but contrasts the previous result that the completion variant _ does admit _ a subexponential parameterized algorithm  @xcite .",
    "l l l problem & polynomial kernel & subexp .  par .",
    "algorithm +   + trivially perfect completion & yes  @xcite & yes  @xcite + trivially perfect deletion & yes & no  @xcite + trivially perfect editing & yes & no +    let us conclude by stating some open questions . in this paper",
    ", we focused purely on constructing a polynomial kernel for trivially perfect editing and related problems , and in multiple places we traded possible savings in the overall kernel size for simpler arguments in the analysis .",
    "we expect that a tighter analysis of our approach might yield kernels with @xmath474 or even @xmath795 vertices , but we think that the really challenging question is to match the size of the cubic kernel for trivially perfect completion of guo  @xcite .    generally , we find the vertex modulator technique very well - suited for tackling kernelization of edge modification problems , since it is at the same time versatile , and exposes well the structure of a large graph that is close in the edit distance to some graph class .",
    "we have high hopes that this generic approach will find applications in other edge modification problems as well , both in improving the sizes of existing kernels and in finding new positive results about the existence of polynomial kernels . for concrete questions where the technique might be applicable , we propose the following :    * is it possible to improve the @xmath2 vertex kernels for cograph editing and cograph completion of guillemot et al .",
    "@xcite ? * is it possible to improve the @xmath268 vertex kernel for the split deletion problem of guo  @xcite ?",
    "* do the claw - free edge deletion or line graph edge deletion problems admit polynomial kernels ? here , the task is to remove at most  @xmath1 edges to obtain a graph that is _ claw - free _ , i.e. , does not contain @xmath710 as an induced subgraph , respectively is a line graph .",
    "n.  alon , d.  lokshtanov , and s.  saurabh .",
    "fast fast . in _ proceedings of the 36th colloquium of automata , languages and programming ( icalp 2009 ) _ , volume 5555 of _ lecture notes in computer science _ , pages 4958 .",
    "springer , 2009 .",
    "i.  bliznets , f.  v. fomin , m.  pilipczuk , and m.  pilipczuk . a subexponential parameterized algorithm for proper interval completion . in _ proceedings of the 22nd annual european symposium on algorithms ( esa 2014 ) _ , volume 8737 of _ lecture notes in computer science _ , pages 173184 .",
    "springer , 2014 .",
    "l.  cai and y.  cai .",
    "incompressibility of @xmath20-free edge modification . in _ proceedings of the 8th international symposium on parameterized and exact computation ( ipec 2013 ) _ , volume 8246 of _ lecture notes in computer science _ , pages 8496 .",
    "springer , 2013 .",
    "g. drange , f.  v. fomin , m.  pilipczuk , and y.  villanger . exploring subexponential parameterized complexity of completion problems . in _ proceedings of the 31st international symposium on theoretical aspects of computer science ( stacs 2014 ) _ , volume  25 of _ lipics _ , pages 288299 .",
    "schloss dagstuhl - leibniz - zentrum fr informatik , 2014 .",
    "f.  v. fomin , d.  lokshtanov , n.  misra , and s.  saurabh .",
    "planar @xmath215-deletion : approximation , kernelization and optimal fpt  algorithms . in _ proceedings of the 53rd ieee annual symposium on foundations of computer science ( focs 2012 ) _ , pages 470479 .",
    "ieee , 2012 .",
    "problem kernels for np - complete edge deletion problems : split and related graphs . in _ proceedings of the 18th international symposium on algorithms and computation ( isaac 2007 ) _ , volume 4835 of _ lecture notes in computer science _ , pages 915926 .",
    "springer , 2007 .",
    "s.  kratsch and m.  wahlstrm .",
    "two edge modification problems without polynomial kernels . in _ proceedings of the 4th international workshop on parameterized and exact computation ( iwpec 2009 ) _ , volume 5917 of _ lecture notes in computer science _ , pages 264275 .",
    "springer , 2009 ."
  ],
  "abstract_text": [
    "<S> we give a kernel with @xmath0 vertices for trivially perfect editing , the problem of adding or removing at most @xmath1 edges in order to make a given graph trivially perfect . </S>",
    "<S> this answers in affirmative an open question posed by nastos and gao  @xcite , and by liu et al .  </S>",
    "<S> @xcite . </S>",
    "<S> our general technique implies also the existence of kernels of the same size for related trivially perfect completion and trivially perfect deletion problems . </S>",
    "<S> whereas for the former an @xmath2 kernel was given by guo  @xcite , for the latter no polynomial kernel was known .    </S>",
    "<S> we complement our study of trivially perfect editing by proving that , contrary to trivially perfect completion , it can not be solved in time @xmath3 unless the exponential time hypothesis fails . in this manner </S>",
    "<S> we complete the picture of the parameterized and kernelization complexity of the classic edge modification problems for the class of trivially perfect graphs . </S>"
  ]
}