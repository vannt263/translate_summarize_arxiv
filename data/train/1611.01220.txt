{
  "article_text": [
    "on megaparsec scales , matter and galaxies have aggregated into a complex network of interconnected filaments and walls .",
    "this network , which has become known as the _ cosmic web _",
    "@xcite , contains structures from a few megaparsecs up to tens and even hundreds of megaparsecs of size .",
    "it has organized galaxies and mass into a wispy web - like spatial arrangement , marked by highly elongated filamentary , flattened planar structures and dense compact clusters surrounding large near - empty void regions .",
    "its appearance has been most dramatically illustrated by the maps of the nearby cosmos produced by large galaxy redshift surveys such as the 2dfgrs , the sdss , and the 2mass redshift surveys @xcite , as well as by recently produced maps of the galaxy distribution at larger cosmic depths such as vipers @xcite .",
    "the cosmic web is one of the most striking examples of complex geometric patterns found in nature , and certainly the largest in terms of size .",
    "computer simulations suggest that the observed cellular patterns are a prominent and natural aspect of cosmic structure formation through gravitational instability @xcite . according to the _ gravitational instability scenario _",
    ", cosmic structure grows from tiny primordial density and velocity perturbations .",
    "once the gravitational clustering process has progressed beyond the initial linear growth phase , we see the emergence of complex patterns and structures in the density field . within this context ,",
    "the cosmic web is the most prominent manifestation of the megaparsec scale tidal force field .    the recognition of the _ cosmic web _ as a key aspect in the emergence of structure in the universe came with early analytical studies and approximations concerning the emergence of structure out of a nearly featureless primordial universe .",
    "in this respect the zeldovich formalism  @xcite played a seminal role .",
    "it led to view of structure formation in which planar pancakes form first , draining into filaments which in turn drain into clusters , with the entirety forming a cellular network of sheets .",
    "as borne out by a large sequence of n - body computer experiments of cosmic structure formation , web - like patterns in the overall cosmic matter distribution do represent a universal but possibly transient phase in the gravitationally driven emergence and evolution of cosmic structure .",
    "n - body calculations have shown that web - like patterns defined by prominent anisotropic filamentary and planar features  and with characteristic large underdense void regions  are a natural manifestation of the gravitational cosmic structure formation process . within the context of gravitationally driven structure formation",
    ", the formation and evolution of anisotropic structures is a direct manifestation of the gravitational tidal forces induced by the inhomogeneous mass distribution .",
    "it is the anisotropy of the force field and the resulting deformation of the matter distribution which which are at the heart of the emergence of the web - like structure of the mildly nonlinear mass distribution .",
    "interestingly , for a considerable amount of time the emphasis on anisotropic collapse as agent for forming and shaping structure was mainly confined the soviet view of structure formation , zeldovich s pancake picture , and was seen as the rival view to the hierarchical clustering picture which dominated the western view .",
    "the successful synthesis of both elements culminated in the cosmic web theory @xcite , which stresses the dominance of filamentary shaped features instead of the dominance of planar pancakes in the pure zeldovich theory .",
    "perhaps even more important is the identification of the intimate dynamical relationship between the filamentary patterns and the compact dense clusters that stand out as the nodes within the cosmic matter distribution : filaments as cluster - cluster bridges ( also see * ? ? ?",
    "? * ; * ? ?",
    "? * ; * ? ? ?",
    "* ) . in the overall cosmic mass distribution , clusters",
    " and the density peaks in the primordial density field that are their precursors  stand out as the dominant features for determining and outlining the anisotropic force field that generates the cosmic web .    in this study",
    ", we pursue this observation and investigate in how far we should be able to outline in a given volume of the observed universe the web - like dark matter distribution on the basis of the observed cluster distribution .",
    "the challenge of this question is that of translating a highly biased population of compact massive clusters , the result of a highly nonlinear evolution , into the corresponding implied mildly nonlinear cosmic web .",
    "this inversion problem calls in several state - of - the - art statistical inversion techniques , in combination with advanced analytical prescriptions for the mildly nonlinear gravitational evolution of the cosmic density field . before describing the barcode  bayesian reconstruction formalism",
    ", we will first provide the context of the gravitationally induced formation of filaments and walls .      within the context of gravitational instability , it are the gravitational tidal forces that establish the relationship between some of the most prominent manifestations of the structure formation process . when describing the dynamical evolution of a region in the density field it is useful to distinguish between large scale `` background '' fluctuations @xmath1 and small - scale fluctuations @xmath2 . here , we are primarily interested in the influence of the smooth large - scale field .",
    "to a good approximation the smoother background gravitational force @xmath3 in and around the mass element includes three components . the _ bulk force _",
    "@xmath4 is responsible for the acceleration of the mass element as a whole .",
    "its divergence ( @xmath5 ) encapsulates the collapse of the overdensity while the tidal tensor @xmath6 quantifies its deformation , @xmath7 the tidal shear force acting over the mass element is represented by the ( traceless ) tidal tensor @xmath6 , @xmath8 in which the trace of the collapsing mass element , proportional to its overdensity @xmath9 , dictates its contraction ( or expansion ) . for a cosmological matter distribution the close connection between the local force field and global matter distribution follows from the expression of the tidal tensor in terms of the generating cosmic matter density fluctuation distribution @xmath10 @xcite : @xmath11 the megaparsec scale tidal shear forces are the main agent for the contraction of matter into the sheets and filaments which trace out the cosmic web .",
    "the anisotropic contraction of patches of matter depends sensitively on the signature of the tidal shear tensor eigenvalues . with two positive eigenvalues and one negative , @xmath12",
    ", we will see strong collapse along two directions .",
    "dependent on the overall overdensity , along the third axis collapse will be slow or not take place at all . likewise , a sheetlike membrane will be the product of a @xmath13 signature , while a @xmath14 signature inescapably leads to the full collapse of a density peak into a dense cluster .",
    "given our understanding of the tidal force configuration that will induce collapse into a filamentary configuration , we may deduce what a typical mass distribution configuration generating such a force field .",
    "figure  [ fig : tidalshear_peaks ] shows that in the primordial gaussian density field a generic configuration generating such a quadrupolar force field is that of two prominent density peaks @xcite . in the subsequent nonlinear evolution , these evolve into two massive clusters .",
    "meanwhile , the mass in the intermediate region is gravitationally contracted towards an elongated filamentary configuration .",
    "0.25truecm -0.5truecm    this demonstrates the intimate relationship of compact highly dense massive cluster peaks as the main source of the megaparsec tidal force field : filaments should be seen as tidal bridges between cluster peaks .",
    "this may be directly understood by realizing that a @xmath12 tidal shear configuration implies a quadrupolar density distribution ( eqn .",
    "[ eq : quadtide ] ) .",
    "in other words , the cluster peaks induce a compressional tidal shear along two axes and a dilational shear along the third axis .",
    "this means that , typically , an evolving filament tends to be accompanied by two massive cluster patches at its tip .",
    "these overdense protoclusters are the source of the specified shear .",
    "the latter explains the canonical _ cluster - filament - cluster _ configuration so prominently recognizable in the observed cosmic web : the nonlinear gravitational evolution results in the typical configuration of filamentary bridges suspended between two or more clusters .",
    "figure  [ fig : cosmicwebtide ] illustrates this close connection between cluster nodes and filamentary bridges .",
    "it also illustrates the correspondence with the anisotropic force field , as may be inferred from the bars that depict the compressional component of the tidal force field . the typical compressional force directed towards the heartline of the filaments",
    "is lined up in a spatially coherent field of tidal bars along the spine of the filaments , suspended in between the typical tidal configuration around cluster peaks .",
    "filaments between two clusters that are mutually aligned show this effect even more strongly . indeed , these filaments turn out to be the strongest and most prominent ones .",
    "studies have also quantitatively confirmed this expectation in @xmath0-body simulations ( see * ? ? ? * ) .    for a full understanding of the dynamical emergence of the cosmic web along the lines sketched above , we need to invoke two important observations stemming from intrinsic correlations in the primordial stochastic cosmic density field .",
    "when restricting ourselves to overdense regions in a gaussian density field we find that mildly overdense regions do mostly correspond to filamentary @xmath12 tidal signatures @xcite .",
    "this explains the prominence of filamentary structures in the cosmic megaparsec matter distribution , as opposed to a more sheetlike appearance predicted by the zeldovich theory .",
    "the same considerations lead to the finding that the highest density regions are mainly confined to density peaks and their immediate surroundings . following the observation that filaments and cluster peaks",
    "are intrinsically linked , the cosmic web theory of @xcite formulates the theoretical framework that describes the development of the cosmic web in the context of a hierarchically evolving cosmic mass distribution .",
    "a prime consideration is that cluster peaks play a dominant dynamical role in the megaparsec force field .",
    "this is clearly borne out in the map of the tidal force amplitude in fig .",
    "[ fig : cosmicwebtide ] .",
    "this concerns a typical lcdm mass distribution , in this case that of the millennium simulation @xcite .",
    "@xcite argued how clusters , or rather peaks in the primordial density field , can be used to define the bulk of the filamentary structure of the corresponding cosmic web .",
    "they demonstrated how on the basis of a mass ordering of cluster peaks in a particular cosmic volume , one may predict in increasing detail the outline of the filamentary spine of the cosmic web in that same volume . for the accuracy of the predicted web - like structure , it is not sufficient to only take along the location and density excess of the primordial peak , but also its shape and orientation .",
    "anisotropic peaks substantially enhance filament formation through the quadrupolar gravitational field configuration that they induce . when two such anisotropic peaks are mutually aligned , this effect becomes even stronger . in summary ,",
    "the prominence  i.e.  mass surface density and mass  of the implied filamentary bridges is sensitively dependent on a range of aspects of the cluster peaks .",
    "the filaments are more prominent and dense when the generating cluster peaks are    1 .   more massive 2 .   at a closer distance to each other 3 .",
    "are strongly anisotropic , i.e.  elongated , flattened or triaxial 4 .",
    "have a favorable mutual orientation , in particular when their long axis is aligned .",
    "based on the above we arrive at the core question of our program .",
    "it involves the question whether on the basis of a complete or well - selected sample of clusters we may predict , or reconstruct , the filamentary cosmic web .",
    "this question involves a few aspects .",
    "one direct one is the concentration on the filamentary spine of the cosmic web .",
    "another integral anisotropic component of the cosmic web are also the walls  or membranes  in the cosmic web . after all , they occupy  besides void regions  the major share of the volume in the universe . however , in the observational situation walls are far less outstanding than the filaments .",
    "first , filaments represent the major share of the mass content in the universe @xcite .",
    "secondly , as their matter content is distributed over a two - dimensional planar structure , their surface mass density is considerably lower than that of the one - dimensional filamentary arteries . in an observational setting",
    "this is augmented by an additional third effect .",
    "@xcite showed that the halo mass spectrum is a sensitive function of the cosmic web environment and has shifted to considerably lower masses in wall - like environments .",
    "this explains why it is so hard to trace walls in magnitude - limited galaxy surveys : because walls are populated but relatively minor galaxies , they tend to be missed in surveys with a magnitude limit that is too high . for practical observational applications , we may therefore be forced to concentrate on the filamentary aspect of the cosmic mass distribution .    following the considerations outlined above , we arrive at the definition of our program .",
    "given cluster locations and properties , we wish to reconstruct their surroundings and study the cosmic web as defined by the clusters .",
    "the program entails the following principal target list ( see fig.[fig : aim ] ) .    1 .",
    "use cosmic web theory to predict the location of filaments given cluster observations including shape , size and mutual alignment .",
    "2 .   predict the prominence and other intrinsic characteristics of filaments .",
    "investigate the application to the observational reality , taking into account systematic biases and effects , and observational errors .",
    "the observational significance of our program is based on the realization that , beyond a rather limited depth , it will be far more challenging to map the filamentary features in a cosmic volume than it is to map its cluster population . while filaments are well - known features in galaxy surveys of the nearby universe , such as 2dfgrs and sdss , it is hard to trace them at larger depths . moreover , mapping the outline of the dark matter cosmic web will be almost beyond any practical consideration , although @xcite recently managed to trace a strong intercluster filament . on the other hand , the cluster distribution is or will be accessible throughout large parts of the observable universe .",
    "armed with the ability to reconstruct the cosmic web given the observed cluster constraints , we would be enabled to explore the possibility to study its characteristics or observe filaments and investigate their properties in targeted campaigns . to this end , it is possible to probe the cluster distribution in different wavelength regimes .",
    "most promising are the cluster samples that will be obtained from upcoming x - ray regime surveys , of which in particular 50k-100k cluster sample of the erosita all - sky survey will be an outstanding example @xcite . given the implicit relation to the tidal force field , major gravitational weak lensing surveys  such at present",
    "the kids survey an the future euclid survey  will certainly open the possibility to explore the dark matter cosmic web in considerably more detail , and relate its characteristics to the observed galaxy distribution .",
    "perhaps even most promising will be upcoming observations of the sunyaev - zeldovich effect , which will potentially allow a volume - complete sample of clusters throughout the observable universe .",
    "there are several methods that allow the reconstruction of a full density field based on incomplete sampled information . the first systematic technique for allowing the inference on the basis of a restricted set of observational constraints is that of the constrained random field formalism @xcite , and its implementation in observational settings involving measurement errors in which the wiener filter is used to compute the mean field implied by the observational data @xcite .",
    "however , strictly speaking it is only suited for gaussian random fields , so that in a cosmological context it is merely applicable to configurations that are still  nearly  in the linear regime of structure formation @xcite .",
    "for the project at hand we seek to translate constraints based on a set of cluster observations into a density field .",
    "clusters , however , are highly nonlinear objects .",
    "it is extremely challenging to relate an evolved cluster to the primordial density peak out of which it evolved .",
    "this is a consequence of the complex hierarchical buildup of a cluster .",
    "a cluster emerges as the result of the assembly of a few major subclumps , augmented by the infall of numerous small clumps and the influx of a continuous stream of mass , along with the gravitational and tidal influence of surrounding matter concentrations ( see * ? ? ?",
    "* for an insightful study ) .",
    "any attempt to relate a present - day cluster directly to a unique primordial density peak is doomed .",
    "we therefore follow a `` from the ground up '' approach , in the context of a bayesian reconstruction formalism .",
    "besides allowing us to find statistically representative primordial configurations that would relate to the observed cluster configurations that emerged as a result of fully nonlinear evolution , it has the advantage of enabling the self - consistent incorporation of any number of additional physical and data models . in recent years , several groups have worked on the development and elaboration of sophisticated and elaborate bayesian inference techniques .",
    "original work along these lines by @xcite culminated in the development of kigen @xcite , on which the present barcode  formalism is based .",
    "kigen allows the translation of the observed distribution of galaxies , such as e.g.  those in the 2mrs survey , into a realization of the implied primordial density and velocity field in the sample volume @xcite .",
    "subsequent gravitational evolution reveals the implied nonlinear structure in the dark matter distribution . along the same lines ,",
    "elaborate bayesian reconstruction formalisms have been developed by jasche , wandelt , leclercq and collaborators @xcite .",
    "the latter allowed even the study of the void population in the dark matter distribution implied by the sdss survey @xcite .    while the bayesian formalism is basically oriented towards obtaining constrained samples of the primordial gaussian density and velocity field underlying the measured observational reality that was imposed as constraint , the intention of our barcode  program concerns the cosmic web that is emerging as a result of the gravitational evolution of structure . to this end , the primordial field sampled from the posterior probability distribution form the initial conditions for the subsequent gravitational evolution .",
    "the latter is followed by means of an @xmath0-body code or of an analytical structure formation model . in our case",
    ", we may analyze the structure of the various structural components of the emerging cosmic web .",
    "the basic philosophy of bayesian reconstructions is to find a set of realizations that form a statistically representative sample of the posterior distribution of allowed models or configurations given the ( observed ) data sample .",
    "in essence , bayesian inference is about finding the model that best fits the data , while taking into account all prior knowledge .",
    "philosophically , it is based on the interpretation of the concept of probability in terms of the degree of belief in a certain model or hypothesis @xcite .",
    "central to bayesian inference is bayes theorem , which formalizes the way to update our a priori belief @xmath15 in a model @xmath16 into an a posteriori belief @xmath17 , by accounting for new evidence from data @xmath18 , @xmath19 in which we recognize the following terms and probabilities ,    1 .",
    "the _ prior _ @xmath15 : the probability distribution that describes our a priori belief in the models @xmath16 , without regard for the observed data ; 2 .   the _ likelihood _ @xmath20 : the probability function that describes the odds of observing the data @xmath18 given our models ; 3 .",
    "the _ posterior _ @xmath17 : the updated belief in our models , given the data ; 4 .   and the _ evidence _ @xmath21 : the chance of observing the data without regard for the model . in bayesian inference",
    "this term can be ignored , as we are only interested in the relative probabilities of different models , meaning that the evidence always factors out .    in the context of our bayesian reconstruction formalism ,",
    "the data @xmath18 are the constraints inferred or processed from the raw cluster observations . as we will argue below , in sect .",
    "[ sec : constraints ] , there are several means in which galaxy or cluster observations can be imposed as constraints . in order to facilitate the imposition of heterogeneous cluster data , the barcode  algorithm has chosen for a representation in terms of values on a regular grid in eulerian space .",
    "the data are specified at eulerian positions @xmath22 .",
    "lagrangian coordinates @xmath23 and eulerian coordinates are related via the displacement field @xmath24 , @xmath25 the displacement field entails the dynamics of the evolving system .",
    "the formalism that we develop with the specific intention of imposing a set of sparse and arbitrarily located cluster constraints is called barcode .",
    "it is an acronym for bayesian reconstruction of cosmic density fields .    in barcode",
    "we have translated the observational ( cluster ) data at a heterogeneous sample of eulerian locations @xmath26 into a regular image grid @xmath27 , represented on a regular eulerian grid . a crucial ingredient to facilitate",
    "this transformation is the use of a mask .",
    "given the sparseness and heterogeneous nature of the imposed cluster constraints , the formalism includes a mask to indicate the regions that have not , incompletely or selectively covered .",
    "it is in particular on the aspect of using an regular grid @xmath27 to transmit the observational constraints that barcode  follows a fundamentally different approach from the one followed in the related kigen formalism @xcite .",
    "kigen is able to process the galaxy locations in the dataset directly for imposing the data constraints .",
    "it involves two stochastic steps instead of one .",
    "it first samples a density field given the galaxy distribution . in a second step",
    "it then samples a new particle distribution , given the sampled density field and a model of structure formation .",
    "it renders kigen highly flexible",
    ". it does require the posterior probability function to be differentiable , and is able to implicitly take into account the bias description for the galaxy sample .",
    "a grid - based formalism like barcode , on the other hand , requires an explicit bias description .",
    "also , it requires the posterior to be differentiable , because of the use of the hamiltonian monte carlo hmc sampling procedure ( see sect .",
    "[ sec : hmc ] ) .      in the context of the bayesian formalism , the signals that barcode  is sampling are the models constrained by the data . in our application they are realizations of the primordial density field @xmath28 .",
    "the core task of the reconstruction formalism is therefore the proper sampling of a realization of the primordial density field @xmath28 , given the posterior distribution function for @xmath28 .",
    "the posterior distribution function is determined on the basis of the input data and the assumed cosmological model .",
    "the key product of the procedure is therefore a sample @xmath29 of the _ primordial density fluctuation field_. for practical computational reasons , the primordial field is specified at the lagrangian locations @xmath23 on a regular grid . in our test runs , we used a grid with @xmath30 cells on a side for this discrete representation of an intrinsically fully continuous field on a finite regular grid .",
    "the presently running implementations have @xmath31 or @xmath32 cells .",
    "each of the density values @xmath33 is one of the stochastic variables to be sampled .",
    "the total signal @xmath34 , @xmath35 defines a @xmath36 dimensional probabilistic space .",
    "in other words , for @xmath37 we are dealing with the sampling of a full bayesian signal in a 262144-dimensional probabilistic space .",
    "the only thing we know about the primordial density field  without regard for the data  is that it must be a gaussian random field ; this should fully characterize our prior belief in such a field .",
    "the prior in our model is therefore a multivariate gaussian distribution characterized by a zero mean and a correlation matrix determined by the correlation function as measured from the cosmic microwave background : @xmath38 where @xmath39 is the inverse of the correlation matrix @xmath40 , the real - space dual of the fourier - space power spectrum @xmath41 with elements @xmath42    the cosmological model underlying our reconstruction enters via the cosmological power spectrum @xmath41 .",
    "it contains implicit information on global cosmological parameters , on the nature of the primordial density fluctuations , and via these the nature of dark matter .",
    "in addition to the primordial fluctuations , we also need to specify the structure formation model , which transforms the lagrangian to eulerian space density fields via the transformation @xmath43 from a lagrangian space overdensity field @xmath44 to eulerian space density field @xmath45 . in the context of gravitationally driven structure formation",
    ", one could employ an @xmath0-body simulation to optimally follow the structure formation process , including the complex nonlinear aspects .",
    "however , in practice it would be unfeasible to include this in the formalism , as it would take an overpowering computational effort to numerically compute derivatives with respect to the signal @xmath34 .    for the computation of the displacement ,",
    "barcode  therefore prefers to use analytical prescriptions .",
    "the most straightforward option is the zeldovich formalism .",
    "other options are higher - order lagrangian perturbation schemes such as 2lpt or alpt ( alpt , or augmented lagrangian perturbation theory , is a structure formation model that combines 2lpt on large scales with spherical collapse on small scales ) .",
    "closely related to the latter is a model @xmath46 that subsequently transforms eulerian coordinates to redshift space coordinates , and hence transforms the modeled density field from eulerian space to redshift space for the situations in which the observational data are in fact redshift data .",
    "this is implicitly included in the structure formation model via its prescription for the corresponding velocity perturbations .",
    "in addition to these cosmological and structure formation models , we also need to take along model descriptions relating the observed galaxy or cluster distribution to the underlying distribution .",
    "this includes factors such as a noise model for statistical sources of error , like measurement uncertainties in the observations , and a bias model connecting the galaxy / cluster distribution to the density field .      on the basis of the set of data constraints , and the model assumptions discussed in the previous section",
    ", we obtain the posterior distribution function @xmath47 to obtain meaningful constrained realizations for our problem , we sample the posterior distribution . given the complex nature of the posterior distribution function in an @xmath36 dimensional probability space , an efficient sampling procedure is crucial in order to guarantee a statistically proper set of samples @xmath34 .",
    "markov chain monte carlo ( mcmc ) methods try to alleviate the computational costs of sampling a high - dimensional probability distribution .",
    "they do this by constructing a so called markov chain of samples @xmath48 . in our case , this becomes a chain of density fields , each sampled on a regular grid .",
    "such a chain may be seen as a random walk through the parameter space of the pdf @xmath49 .",
    "each visited location in the high dimensional space corresponds to one particular sample realization of the density field @xmath29 .",
    "to do so , mcmc chains automatically visit high probability regions in direct proportion to their relative probability , and do not waste computational tie on low probability areas .",
    "the performance gain can be orders of magnitude for high - dimensional problems .",
    "the resulting sampling ensemble is equivalent to an ensemble from the full posterior @xmath49 .",
    "arguably the best known mcmc method is the metropolis - hastings sampler .",
    "another well - known algorithm is the closely related concept of gibbs sampling , basically a multi - dimensional extension of metropolis - hastings algorithm . in barcode",
    "we follow a far more efficient methodology , that of the hamiltonian monte carlo sampling .",
    "hamiltonian sampling is based on a physical analogy , and uses concepts from classical mechanics  specifically hamiltonian dynamics  to solve the statistical sampling problem @xcite ( also see @xcite for an excellent summary of the ideas involved ) .",
    "following the concept of hamiltonian mechanics , a markov chain is produced in the form of an _ orbit _ through parameter space , which is found by solving the hamiltonian equations of motion : @xmath50 where @xmath51 is an artificial `` time '' analogue that we merely use to evolve our markov chain .",
    "important in this respect is also the time reversibility of hamiltonian dynamics .",
    "the positions @xmath52 , the momenta @xmath53 and the hamiltonian @xmath54 , the sum of a potential term @xmath55 and a kinetic term @xmath56 , @xmath57 are not real physical quantities , but equivalent stochastic variables .",
    "it is straightforward to interpret the meaning of the position vectors @xmath52 .",
    "they represent the primordial density field realization @xmath29 , and the dynamical orbit the chain of density field samplings , @xmath58 in order to avoid confusion , notice that the stochastic coordinate analogues @xmath52 are something completely and fundamentally different than the lagrangian coordinates @xmath59 .",
    "the potential term @xmath55 is identified with the probability distribution function @xmath60 , and is equal to its negative logarithm , @xmath61 .",
    "the @xmath62-dimensional auxiliary momentum vector @xmath53 is related to the steepness of the change in density field sample between sampling steps .",
    "the kinetic energy term @xmath56 is the quadratic sum of these auxiliary momenta , @xmath63 in which the symmetric positive definite mass matrix term @xmath64 , called mass in analogy to the situation in the context of classical mechanics , characterizes the inertia of the sampling orbit moving through parameter space .",
    "it is of crucial importance for the performance of the formalism : if the mass term is too large it will result in slow exploration efficiency , while masses which are too light will result in large rejection rates .    as in the case of other mcmc algorithms , for the startup of the procedure",
    "there is an additional important aspect , the _ burn - in _ phase .",
    "an mcmc chain starts up from an initial guess for the signal @xmath34 to be sampled , and subsequently evolves a chain from there . as we may not necessarily start from a region of high probability , it may take the mcmc chain a series of iterations before reaching this region .",
    "the period up to this point is called the burn - in phase of the chain .",
    "the samples obtained in the burn - in phase are discarded from the ensemble , since they are not part of a representative sample .",
    "in barcode  we have implemented an hmc sampler of primordial density fields @xmath44 given density data from observations .",
    "the algorithm can deal both with real - space density fields , as well as density fields sampled in redshift space . to incorporate a structure formation model ,",
    "we can use either the zeldovich approximation or an alpt structure formation model , which combines the higher - order 2lpt lagrangian model on large scales with spherical collapse on small scales  @xcite . the implementation may invoke a gaussian or poisson error model for the observed densities .          here",
    "we first present the result of some numerical experiments , demonstrating the potential to reconstruct successfully the web - like outline of the cosmic matter distribution , given an observed sample of the large scale density distribution .",
    "as a test , we have evaluated the performance of our code on a lcdm dark matter simulation , in which the matter distribution in a box with a side of @xmath65 is represented on a grid of @xmath30 cells .",
    "it means the stochastic sampling process takes place in a @xmath66-dimensional space .",
    "we find that the algorithm starts constraining the large scales ( low modes ) and then increasingly gains power towards small scales ( high modes ) .    following the burn - in phase , the chain remains in the high probability region around the `` true '' density .",
    "the sampling chain is expected to vary around this true density due to the random kicks from the ( statistical , auxiliary ) momentum .",
    "figure  [ fig : density_fields ] shows the comparison between the eulerian space mean density field of 60 samples  obtained from 3000 iterations  and the true underlying density field .",
    "the match between the two is very good .",
    "we notice this on account of a visual comparison between the matter distribution in the top frames .",
    "this is strongly supported by the quantitative comparison in terms of the standard deviation of the 60 samples ( bottom left ) and the difference field between the true and mean fields ( bottom right - hand plot ) .",
    "the differences between mean and sampled field turn out to be rather subtle . in eulerian space",
    "they tend to be most prominent in the high - density regions . in part , this can be understood from the realization that there is more variation in those regions in combination with the fact that there are not enough samples to completely average out these variations .",
    "to appreciate the variation between field variations , in figure  [ fig : density_fields_zoom ] we zoom in on a couple of post - burn - in iterations .",
    "it shows that differences are hard to discern , in particularly at this low resolution . at a careful inspection",
    "we may notice some minor differences .",
    "for instance , the height of the two large peaks vary significantly .",
    "also , the shape of the `` cloud '' in the void , just on the lower right from the center , varies from almost spherical with a hole in the middle to an elongated and even somewhat curved configuration .    yet ,",
    "overall the reconstructions appear to be remarkably good .",
    "this is true over the entire range of scales represented in the density field .",
    "the power spectra of the chain samples properly converge to the true power spectrum , as may be inferred from figure  [ fig : powerpk ] .",
    "one important caveat in the basic barcode  algorithm is that in the observational practice we tend to use redshifts as measures for distance . because redshifts also include the contribution from peculiar motions , the measured distribution does not concern comoving space @xmath67 , but the distribution in redshift space @xmath68 .",
    "the direct implication is that our data will be deformed by so - called redshift space distortions .",
    "clusters will seem radically stretched along the line of sight due to the internal virialized velocities of their galaxies . on the other hand ,",
    "large scale overdense structures appear squashed along the line of sight , while underdense structures are observed to be larger in the radial direction than in reality .",
    "it is one of the principal reasons for the appearance of _ great walls _",
    "perpendicular to the line of sight .",
    "all these effects must be taken into account in order to accurately measure volumes , densities , shapes and orientations of the components of the cosmic web .",
    "there are several options to accommodate redshift space distortions when processing measurements .",
    "most of these involve a form of a posteriori or a priori `` correction '' of the redshift space effects .",
    "a priori corrections include , for instance , the detection of `` fingers of god '' , followed by an automatic reshaping into spheres .",
    "possible a posteriori corrections include the reshaping of the power spectrum to account for the `` kaiser effect '' of squashing along the line of sight . however , all these methods are approximations and most of them focus on one aspect of the redshift space transformation only .",
    "we opt for a self - consistent redshift space correction in the barcode  formalism .",
    "this concerns a one - step transformation of _ data model _ itself into redshift space .",
    "to the best of our knowledge , this is the first self - consistent redshift space data based reconstruction of the primordial density fluctuations . to this end",
    ", we adjust our barcode   data model to not only transform from lagrangian coordinates @xmath59 to eulerian coordinates @xmath67 using a structure formation model , but subsequently also from @xmath67 to the corresponding redshift space .",
    "since our structure formation formalisms are particle based ( using lagrangian perturbation theory ) , this can easily be achieved by means of one more coordinate mapping from eulerian space to redshift space . in this way , we incorporate automatically and directly all possible redshift space effects in our reconstructions , insofar as the structure formation model includes them .",
    "the one additional complication for such a strategy in the context of the hamiltonian monte carlo formalism , is that for the redshift space transformation to work it must facilitate analytical derivatives of the posterior distribution with respect to the sampled fields . to this end , we have derived and implemented the required equations in the barcode  code .",
    "redshift space coordinates @xmath68 can be defined as @xmath69 where @xmath68 is a particle s location in redshift space , @xmath67 is the eulerian comoving coordinate , @xmath70 is the particle s ( peculiar ) velocity and @xmath71 is the velocity of the observer .",
    "@xmath72 is the cosmological expansion factor , which converts from physical to comoving coordinates , and @xmath73 is the hubble parameter at that expansion factor , which converts the velocity terms to distances with units @xmath74 .",
    "we call @xmath75 the _ redshift space displacement field _ , analogously to the displacement field @xmath76 that transforms coordinates from lagrangian to eulerian space in lagrangian perturbation theory",
    ".    an important point to keep in mind is that in equation  [ eqn : redshift_space ] , the comoving coordinates are defined such that the observer is at the origin .",
    "the unit vector @xmath77 , and thus the entire redshift space , changes completely when the origin shifts .",
    "overall , in our @xmath78 test - runs based on redshift space renderings of the simulations described in the previous section we found that an excellent performance .",
    "it manages to deal with all redshift space artifacts , and differences between the sampled density field and the true density field remains limited to small local variations .",
    "this is confirmed by the power spectrum , which seems to match the expected true power spectrum in all necessary detail .",
    "our barcode  formalism has fully and self - consistently accounted for the kaiser redshift space effect and even additional mildly nonlinear effects such as in the triple value region corresponding to the infall region around clusters .",
    "perhaps the most convincing demonstration of this success is that of the 2d correlation function @xmath79 .",
    "it measures the correlation function by segregating the contributions along two direction one along the line of sight , the other perpendicular . in the case of an intrinsic anisotropies in the data ,",
    "we will obtain a deviation from a perfectly circular @xmath79 .",
    "as for the barcode  reconstructions , the two - dimensional correlation functions of the reconstructions match the true  almost isotropic and perfectly circular  one when using the redshift space model .",
    "in other words , it shows that it manages to eliminate large scale redshift space anisotropies .",
    "figure  [ fig : zspace ] shows the differences of the eulerian 2d correlation functions @xmath79 of five barcode  samples compared to that for the true field .",
    "the differences are very small , in the order of @xmath80 .",
    "nonetheless , we may note some variation in the differences .",
    "this is a result of a minor effect , a result of the mcmc sampling process itself introducing additional anisotropies in the samples                                                                          van de weygaert r. & bond j.r . 2008 , _ clusters and the theory of the cosmic web _ , in m. plionis , o. lpez - cruz & d. hughes eds . , _ a pan - chromatic view of clusters of galaxies and the large - scale structure _ , lnp 740 ( springer ) , p. 335"
  ],
  "abstract_text": [
    "<S> we describe the bayesian barcode  formalism that has been designed towards the reconstruction of the cosmic web in a given volume on the basis of the sampled galaxy cluster distribution . </S>",
    "<S> based on the realization that the massive compact clusters are responsible for the major share of the large scale tidal force field shaping the anisotropic and in particular filamentary features in the cosmic web . </S>",
    "<S> given the nonlinearity of the constraints imposed by the cluster configurations , we resort to a state - of - the - art constrained reconstruction technique to find a proper statistically sampled realization of the original initial density and velocity field in the same cosmic region . ultimately , the subsequent gravitational evolution of these initial conditions towards the implied cosmic web configuration can be followed on the basis of a proper analytical model or an @xmath0-body computer simulation . </S>",
    "<S> the barcode  formalism includes an implicit treatment for redshift space distortions . </S>",
    "<S> this enables a direct reconstruction on the basis of observational data , without the need for a correction of redshift space artifacts . in this contribution </S>",
    "<S> we provide a general overview of the the cosmic web connection with clusters and a description of the bayesian barcode  formalism . </S>",
    "<S> we conclude with a presentation of its successful workings with respect to test runs based on a simulated large scale matter distribution , in physical space as well as in redshift space . </S>"
  ]
}