{
  "article_text": [
    "the design of experimental schemes to reach thermonuclear ignition and burn in laser driven targets involves complex models that incorporate many physical effects @xcite .",
    "the radiation - hydrodynamic simulations used to predict the evolution of fusion capsules @xcite therefore contain a huge number of physical parameters which play an important role .",
    "the resulting laser targets are correspondingly complex , with a large number of design parameters . in a typical inertial confinement fusion ( icf )",
    "experiment performed at large laser facilities such as the national ignition facility ( nif ) @xcite , there are many tens of variables that play an important role in determining target evolution @xcite .",
    "this poses a difficult problem for data analysis since these parameters should not be neglected but are too numerous to treat directly using the standard methods of , for example , particle physics where monte carlo sampling of noise sources is often used @xcite . in this paper",
    "we develop a method that allows all important variables to be included , along with prior work on microphysics models , in a consistent and efficient analysis .",
    "the approach has been designed to couple with existing radiation - hydrodynamics simulation codes without modification ; in fact simulations are treated as a ",
    "black box making the method applicable to a large class of difficult data analysis problems .",
    "this approach also allows us to avoid the complex fitting functions used in other approaches @xcite , which are unlikely to capture the complex behavior of icf experiments close to ignition ( and are unsuitable for such large problems in any case ) .",
    "the data analysis approach that we describe is particularly important when considering the results of the recent national ignition campaign ( nic ) . throughout the campaign",
    ", post - shot simulations failed to match the observed data ; the implication is that simulations , or their underlying microphysics models , are inaccurate . determining which of the models should be investigated , and producing a consistent picture of the implied error , is a difficult task and forms a major motivation for this work .",
    "in fact , modifications to various physical parameters , even unrealistically large modifications , often can not produce a match to nic data .",
    "in this situation the neglect of important variables and prior knowledge has a dramatic effect on the results of inference ( even if they are purely sources of noise ) .",
    "our method allows these effects to be included with almost no computational overhead .",
    "we demonstrate this by presenting an analysis of a single nic convergent ablator ( cona ) shot @xcite , n110625 .",
    "we find that variations in the dimensions of the target can have a dramatic effect on the inferred drive and carbon opacity , although this is mitigated by thorough metrology of the target .",
    "our method also allows prior knowledge to be included and in the case of icf we find that this is an extremely important factor .",
    "we use it to investigate the implied error in microphysics models associated with neglecting this prior work .",
    "the inclusion of this prior knowledge is an important strength of the bayesian method , as it provides context for observed data and therefore allows meaningful information to be inferred even from a single experimental result .",
    "the total information from a set of experiments can be viewed as a series of such single - shot inferences , allowing the analysis performed here to be generalised to full experimental campaigns very easily .",
    "the approach is to treat the output of the simulation code as probabilistic , and to apply standard methods of bayesian analysis @xcite .",
    "the probabilistic nature of simulations is due to variations in the myriad important variables ( or  nuisance parameters ) .",
    "we derive a semi - analytic expression in which the dependence on interesting physics is retained but all other variables are represented by an analytic information loss .",
    "the result is framed as a modified @xmath0 analysis which is easy to implement , portable , and allows all available data to be included in a single analysis .",
    "we begin by elaborating on the challenges we have already introduced .",
    "we then develop our inference approach in section [ sec : probabilistic_output ] , and discuss methods for its application in section [ sec : implementation ] .",
    "finally , the importance of including all important variables and prior knowledge is demonstrated with an example application to a single nic shot , n110625 .",
    "in current analyses , particular data ( chosen largely through experience ) are preferentially matched by varying inputs that are considered to be unreliable , such as x ray drive @xcite .",
    "this approach has been very useful in testing the consistency between simulations and experiment , however it is potentially sensitive to noise and gives little information about the physical origin of inconsistencies . increasing the number of inferred parameters is essential to gaining more information about underlying physics models .",
    "radiation - hydrodynamic simulations represent a nonlinear map from the space of physical models that we wish to investigate to the data that are collected in an experiment .",
    "the nature of the simulations often means that they are not amenable to adjoint differentiation @xcite , are discontinuous , and may be noisy ; these complex features can make standard methods of searching the space of physical parameters quite unreliable .",
    "this limits the number of parameters that can be reliably inferred .",
    "the nuisance parameters included by our method result in a smoothing of the code output , allowing the use of advanced methods and an increase in the number of physical parameters that can be investigated .",
    "we have already described the difficulties associated with the large numbers of target parameters involved in icf experiments .",
    "although many of these are constrained by manufacturing precision and target metrology , it has already been seen that their large number can have an important impact on the output of simulation codes @xcite .",
    "there will be a corresponding effect on inference results , and we aim to investigate this .",
    "the physical parameters we aim to infer often refer to microscopic physics ( for example opacities or equations of state ) that are understood using other , separate , computer simulations .",
    "these simulations are highly complex and have been investigated both theoretically and experimentally for many decades ; the expected systematic error bars on their outputs are therefore quite small .",
    "this error bar plays an important role in data analysis by ensuring that the results are physically reasonable , and this motivates our bayesian approach .",
    "the fundamental problem is to develop a method of exploring the huge space of parameters that can affect the outcome of a simulation .",
    "as discussed , in the case of icf data there is no point in this space for which all data are correctly simulated . in general",
    "there may be a set of points that give comparable agreement .",
    "the best fit is found by defining a figure of merit that takes into account the difference between observed and simulated values of all data points , as well as the difference between simulation parameters and the expected physical reality . in this section",
    "we outline a figure of merit that is based on the bayesian posterior probability of a point in phase space ( the _ maximum a posteriori _ , or map , solution @xcite ) , and use an analytic prior - predictive approach to reduce the phase space to manageable size .",
    "we begin by splitting the set of all parameters into two ;    * ` interesting parameters ' @xmath1 - physically significant parameters that we aim to infer from experiment data . for example",
    "material equation of state , opacities , conductivities , ... , * ` nuisance parameters ' @xmath2  other parameters that have an effect on simulations but are not of direct physical significance .",
    "these are usually known with good precision , for example target dimensions , laser powers , ... ,    in our model , inference is performed on the interesting parameters only .",
    "bayes theorem allows us to write down the probability distribution of the interesting parameters once the experiment has been performed ( the _ posterior _ ) , in terms of the probability distribution before the experiment ( the _ prior _ ) and the probability of the experimental data ( the _ likelihood _ ) .",
    "bayes theorem is @xmath3 where @xmath4 is the vector of experimental data and",
    "we have introduced the code output @xmath5 and the nuisance parameters as marginalised variables .",
    "this allows us to introduce the known measurement error and prior distributions of the nuisance parameters later .",
    "such an approach is equivalent to assuming that experimental data are the simulation results plus a randomly distributed error , as is done in other approaches @xcite .",
    "writing @xmath6 and introducing the deterministic nature of the simulation code , @xmath7 the integration over @xmath5 can be performed trivially .",
    "the result is @xmath8 the likelihood @xmath9 implicitly contains the experimental error distribution and the code output as a function of all parameters @xmath10 .",
    "the two components of the prior distribution @xmath11 describe the expected distributions of nuisance and interesting parameters before the experiment has been performed ; these are determined by the experimental design , target manufacturing tolerances , previous experimental results and expert opinion .",
    "equation describes the relationship between the probability distributions of the interesting parameters before and after an experiment .",
    "the details of the relationship are approximated by the simulation code , and contained in the likelihood function .",
    "data analysis , then , is based on the evaluation of the integral in the definition of the likelihood . in its general form",
    "this involves the integration of simulation output over the entire nuisance parameter space ; it is common to evaluate this using a monte - carlo sampling of the integrand ( see , for example , @xcite ) . for our application , where even a conservative set of nuisance parameters results in a @xmath12 dimensional integral , this is prohibitively expensive .",
    "even if the radiation - hydrodynamics can be modelled by some fast surrogate model ( as a gaussian process or through other techniques @xcite ) , which itself is very difficult given the size of the space we must consider , the integral is still too expensive .",
    "we instead evaluate the integral by assuming a linear response to nuisance parameters , @xmath13 in the above @xmath14 is the nominal value of the nuisance parameters , typically zero .",
    "the linear response matrix @xmath15 can be populated using a small number of simulations ; once this has been done , the matrix @xmath15 is entirely portable and may be used in all subsequent analyses of this type without further calculation .",
    "the case of linear response , equation , is very useful as it allows an analytic treatment of the nuisance parameters .",
    "assuming that the experimental measurement errors and nuisance parameter variations are described by uncorrelated normal distributions with correlation matrices @xmath16 and @xmath17 , @xmath18 the result is @xmath19 ( d_{exp}-d_{m}(\\theta))}}{\\sqrt{(2\\pi)^{n_{exp}}|\\lambda_{exp}||\\lambda_{\\eta}||\\alpha^{t}\\alpha| } }       ~{\\rm . }",
    "\\label{eq : likelihood_marginal}\\ ] ] in the above , @xmath20 is the simulation result for nominal nuisance parameters and the matrices @xmath21 and @xmath22 satisfy the equations @xmath23 these expressions are the multivariate generalisation of the usual quadrature error propagation formula ; it should be noted that even if nuisance parameters and experimental errors are independent to begin with ( i.e. , if @xmath16 and @xmath17 are diagonal ) , the response of the simulations means that the likelihood can become strongly correlated .",
    "these potentially strong correlations arise due to the deterministic nature of the simulation code and play a very important role in the inference procedure described in the next section .",
    "the results of the previous section allow the efficient calculation of the likelihood as a function of interesting parameters , without neglecting other important variables or prior knowledge . as discussed in section [ sec : challenges ] , this can be expected to give a significant improvement in data analysis results .",
    "the marginalisation of nuisance parameters represents an averaging that smooths the response of simulations , making them more well - behaved .",
    "this allows us to use standard numerical techniques .",
    "the best fit to data , taking into account nuisance parameters and prior knowledge , is given by the parameters that maximise the posterior probability @xmath24 ( see equation ) .",
    "it is convenient to minimise the information , @xmath25 , which using equations and is @xmath26 the above equation has the form of a modified @xmath0 function , and is derived by assuming that @xmath16 is diagonal .",
    "note that the dependence of the first term on @xmath1 through the simulation @xmath27 means that even in the absence of nuisance parameters and prior knowledge the likelihood is non - normal .",
    "equation can be interpreted as an information processing rule @xcite ; the first 3 terms on the right hand side are the information gained from the experiment , and the final term is the information about the interesting parameters before the experiment was performed . in that sense",
    "it is clear that the positive definite matrix @xmath28 represents a loss of information due to nuisance parameters .",
    "as mentioned , once @xmath28 has been computed the evaluation of the modified @xmath0 only requires a single simulation .    in an actual inference problem",
    "we are interested in the values of @xmath1 that give the best fit to the experimental data .",
    "this requires the numerical minimisation of equation .",
    "the well behaved nature of the marginalised likelihood allows us to use standard methods ; two common approaches are    * markov chain monte carlo ( mcmc )  this approach gives an approximation to the entire posterior information @xcite .",
    "this is extremely useful to the evaluation of error bars on inferred parameters .",
    "the trade - off is that these methods require extensive ` burn in ' periods and are difficult to run in parallel . in our applications where a single simulation represents a significant computational overhead ,",
    "this is a major disadvantage ; * genetic algorithm ( ga )  this method uses ideas taken from genetics to efficiently find the minimum of a function .",
    "it is very easy to run in parallel and so is well suited to our application .",
    "the final result is the position of the minimum only and so some approximation is required to calculate error bars @xcite ,    in the following section we present an example application of the method . for simplicity",
    "the parameter space is small allowing the likelihood and posterior to be explored directly .",
    "the advanced techniques discussed above are therefore not needed . in a forthcoming paper",
    "we consider more complex cases for which we develop a genetic algorithm that is optimised for the sparse datasets encountered in icf research .",
    "in order to demonstrate the application to an actual inference problem , we now consider experimental data taken on a nic convergent ablator ( cona ) experiment @xcite . in this design",
    ", an icf capsule is imploded and backlit by emission from a nearby high @xmath29 plasma .",
    "this allows time- and space- resolved measurement of the plasma density during the implosion .",
    "this is analysed to give time resolved measurement of fuel shell position , velocity , and line density .",
    "simple models show that these quantities are sensitive to the details of the x ray drive from the hohlraum , and to radiation transport in the capsule ablator @xcite .    in these experiments",
    "the measured implosion velocities are consistently lower than simulated predictions , possibly suggesting a reduced x ray drive .",
    "absorption of the drive x rays by carbon in the ablator plastic also plays an important role , and simulations show that an increased carbon opacity can improve agreement @xcite .",
    "these parameters can be used to tune simulations to agree with experiment , however such an approach runs the risk of destroying the predictive capabilities of codes when run far from existing experimental data ( a common occurrence in all areas of hedp , and a possible problem when designing improved icf targets ) .",
    "we aim to analyse the significance of these experimental results with respect to the drive and carbon opacity by inferring the values of modifiers to those quantities in the presence of many nuisance parameters and of prior knowledge .",
    "the prior distributions that we place on these multipliers are interpreted as the uncertainties in the off - line calculations of opacity and drive .",
    "the inference is based on the hydra radiation - hydrodynamics code @xcite .",
    "the parameters of interest are the values of two dimensionless multipliers ; one is applied to the x ray drive spectrum ( at all times and photon energies ) and the other is applied to the carbon opacity ( all temperatures , densities and photon energies ) .",
    "we take into account 29 nuisance parameters , allowing all capsule dimensions , material densities and material compositions @xcite to vary .",
    "these parameters are allowed to vary according to two distributions with standard deviations of @xmath30 and @xmath31 respectively .",
    "these represent well constrained target parameters ( many nic capsule dimensions are known to better than @xmath30 ) , and ones with more uncertainty ( demonstrating the potential effect of nuisance parameters on inferred physics ) . for this relatively small inference it is feasible to generate a set of simulations that span the 2d parameter space . for each point , defined by the multipliers @xmath32 , we run hydra and extract the implosion velocity , ablator mass fraction , and time at which the implosion reaches a radius of @xmath33 m .",
    "these quantities are compared to experimental values taken from radiography @xcite .",
    "+    in figure [ fig : likelyhoods ] we plot the information in the likelihood as a function of @xmath34 and @xmath35 , calculated using equation with different values of the modification matrix @xmath28 .",
    "these plots represent our modified @xmath0 when the prior distribution @xmath36 is neglected . in (",
    "a ) nuisance parameters are neglected ( @xmath37 ) , and in ( b ) the modification is calculated as described for all 29 nuisance parameters varying at the @xmath31 level . in the case with @xmath30 variations ,",
    "nuisance parameters have a small effect and the likelihood is very similar to figure [ fig : likelyhoods](a ) .",
    "the positions of the minima are marked with red points , making the effect of nuisance parameters clear .",
    "this shift in minimum is very important in the subsequent analysis .    to further quantify the differences we perform a set of inferences based on the calculated likelihoods .",
    "the specific choice of prior distribution is often a difficult issue since it can be a subjective choice that has a direct influence on inference results .",
    "for this reason we perform a range of inferences with prior distributions for @xmath32 of varying width .",
    "this allows us to take into account the dependence of the inference results on the prior , and place limits on the actual prior for various results .",
    "we begin with a reasonable estimate of the uncertainties in opacity and drive models of 10% and 20% respectively .",
    "this defines our nominal prior as a normal distribution centered on @xmath38 , with covariance matrix @xmath39 a set of inference results are found by scaling this covariance , thereby changing the assumed prior error in microphysics models ( and the relative importance of prior and experimental information ) . for a very large scaling of",
    ", the prior is flat and our analysis reproduces the maximum likelihood ( ml ) result ; for a small scaling factor the prior tends to a @xmath40-function and the minimum of equation is at @xmath41 ( their prior values ) .",
    "the two red points at the right hand end represent the maxima of the likelihood for these two cases .",
    "the green line shows the case when nuisance parameters are included at the @xmath31 level .",
    "as the prior is scaled from a @xmath40-function , through our best estimated defined by , to flat , the inferred results tracks from the prior results @xmath38 to the minimum of the likelihood functions plotted in figure [ fig : likelyhoods ] .",
    "the figure also shows contours that define a change in multiplier of 5% from each end point . ]    in figure [ fig : posterior_tracks ] we plot the trajectories of the best fit as the prior covariance is scaled from small to large .",
    "the trajectory for calculations that neglect nuisance parameters , and that include them at the @xmath30 level , overlay each other and are shown in purple ; note the slight shift in the ml result at the right hand end .",
    "the @xmath31 case is plotted in green .",
    "the shapes of the trajectories are determined by all the factors we have discussed so far , not least the shape of the likelihood ( i.e. , the effect of nuisance parameters ) .",
    "the left hand end of the trajectories corresponds to small prior error and reproduces the prior result .",
    "the right hand end of each line is the flat prior result ; as we have already seen in figure [ fig : likelyhoods ] the inclusion of nuisance parameters at the @xmath31 level has a very significant effect on the inferred values of our interesting parameters .",
    "the wide difference between the start and end points of all trajectories in figure [ fig : posterior_tracks ] clearly shows that the prior distribution has an extremely important role to play in our analysis . for our nominal prior ,",
    "defined by the covariance , we find that the prior is in fact more important than the details of the nuisance parameters regardless of their distribution widths , giving inference results that are almost the same ; @xmath42 . the ml analysis , that neglects the prior , will then result in a significantly different result .",
    "this is true even for extremely broad priors ; for our map analysis ( which includes both prior and nuisance parameters ) to reproduce the @xmath30 nuisance parameter ml result to within 5% ( shown by the dashed contours in figure [ fig : posterior_tracks ] ) , the prior covariance must be scaled so that the prior errors in opacity and drive are more than 400% and 800% respectively .",
    "the simulations on which the opacity and drive are based can be expected to be much more accurate that this , giving further support to the importance of the prior .",
    "we have developed a bayesian model for investigation of underlying physics using complex he d experiments .",
    "the model allows for the inclusion of complications arising in experiments by using an approximate description of so - called nuisance parameters , and of previous investigations through a bayesian prior .",
    "the result is a modified @xmath0 function that can be easily incorporated into any analysis using standard methods .",
    "this approach allows complex simulations to be treated as black box transformations from physical models to experimental data and so is suitable for application in a wide range of physical applications .",
    "the linear response model described is the basis of the usual ` normal linear ' model @xcite .",
    "however , unlike that model , the use of complex simulations to describe interesting parameters and the resultant correlations between nuisance parameters results in a non - normal posterior .    in the case of icf experiments , the linear response approximation may not be sufficient .",
    "the difficult task of achieving thermonuclear ignition requires that target designs are highly optimised ; a change in nuisance parameters in either direction is likely to produce a reduction in target performance .",
    "such nonlinear behavior can be important , and is not captured by the current approach .",
    "test calculations for a reduced problem , including quadratic response to nuisance parameters , suggests that these effects are significant in the analysis of icf data . a major piece of further work is to develop an efficient way of including nonlinearity .    in the final sections of this paper",
    "we have applied our analysis to a single nic experiment .",
    "we attempt to describe deficiencies in radiation transport physics through multipliers on two physical quantities , and infer the posterior values of these multipliers .",
    "this process is a common one in the analysis of nif data , and is usually viewed as the tuning of simulations to allow more reliable target design . in this work",
    "we interpret the results of this process as a measure of the uncertainty in the underlying physical models , which are often applied in regimes where they are untested . only by improvement of these models , motivated by the kind of data analysis described here ,",
    "can a truly predictive simulation be developed .",
    "the particular example given here is sufficient to demonstrate the importance of an integrated approach to data analysis , and provides compelling evidence that a straightforward fit to experimental data , ignoring prior knowledge , can give misleading results . for the very well characterised targets used at the nif ,",
    "certain dimensions are known to better than the @xmath30 accuracy we allow in this work , however other nuisance parameters ( for example material densities ) could vary over a larger range .",
    "we have demonstrated that these nuisance parameters may have an important effect ; our method allows a complete description of the problem . alongside the nuisance parameters that we have included in this demonstration",
    ", there are also many other simulation inputs which can be treated as nuisance parameters in the same way .",
    "we demonstrated a novel method of analysing the importance of prior knowledge by referencing the possible conclusions from data to limits on prior distribution widths .",
    "the multipliers used here do not , however , provide an insight into specific problems in underlying physics ; it is also true that these multipliers only describe the average modification to theory that is required .",
    "any inferred physical modifier will lose its meaning when the simulations used in the inference have other unknown inaccuracies , and this is certainly the case in our first application .",
    "we begin addressing these problems in a forthcoming paper .",
    "the work presented here represents the first steps to providing a clearer view of problems with physics models from experimental data , in cases where the experiments are very complex .",
    "although we concentrate on icf experiments here , nuisance parameters can be expected to be important in all he d experiments , in particular those where target plasmas are less well constrained .",
    "the portability of our method makes its application to other experiments very easy .",
    "the computational framework described also provides the opportunity for bayesian experimental design @xcite , allowing future experiments to provide a significant measurement of difficult aspects of underlying physics @xcite .",
    "the integrated approach that we propose may also facilitate discovery of new rules and phenomenology that govern the evolution of these complex systems .",
    "fischer , r. , dreier , h. , dinklage , a. , kurzan , b. , and pasch , e. , integrated bayesian experimental design , in knuth , k. , abbas , a. , morris , r. , and castle , j. , editors , _ bayesian infererence and maximum entropy methods in science and engineering _ , 2005 ."
  ],
  "abstract_text": [
    "<S> the complex nature of inertial confinement fusion ( icf ) experiments results in a very large number of experimental parameters that are only known with limited reliability . </S>",
    "<S> these parameters , combined with the myriad physical models that govern target evolution , make the reliable extraction of physics from experimental campaigns very difficult . </S>",
    "<S> we develop an inference method that allows all important experimental parameters , and previous knowledge , to be taken into account when investigating underlying microphysics models . </S>",
    "<S> the result is framed as a modified @xmath0 analysis which is easy to implement in existing analyses , and quite portable . </S>",
    "<S> we present a first application to a recent convergent ablator experiment performed at the nif , and investigate the effect of variations in all physical dimensions of the target ( very difficult to do using other methods ) . </S>",
    "<S> we show that for well characterised targets in which dimensions vary at the 0.5% level there is little effect , but 3% variations change the results of inferences dramatically . </S>",
    "<S> our bayesian method allows particular inference results to be associated with prior errors in microphysics models ; in our example , tuning the carbon opacity to match experimental data ( i.e. , ignoring prior knowledge ) is equivalent to an assumed prior error of 400% in the tabop opacity tables . this large error is unreasonable , underlining the importance of including prior knowledge in the analysis of these experiments .    inertial confinement fusion , radiation hydrodynamic simulation , bayesian inference , plasma opacity , uncertainty analysis , convergent ablator , national ignition facility </S>"
  ]
}