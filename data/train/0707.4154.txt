{
  "article_text": [
    "the statistical model is succesfull in describing mean hadron multiplicities in both elementary and heavy ion collisions at high energy . in heavy ion collisions , many groups have carried out analysis of the available measurements for almost 10 years by now , reporting success in reproducing the data with few parameters .",
    "the usual employed technique is a @xmath0 fit , where the data is compared to the model prediction to determine the best values of those parameters ( temperature , baryon - chemical potentials , volume and , possibly , non - equilibrium parameters @xmath1 and @xmath2 ) .",
    "this analysis technique was first applied to heavy ion collision data in ref .",
    "@xcite .",
    "the calculations performed by different groups agree to a very good degree of accuracy with the _ same _ data input , showing that the implementations of the statistical model are essentially consistent , modulo the small uncertainty due to the poorly known branching ratios of high mass resonances .",
    "however , the parameter values quoted by different groups show significant differences , especially @xmath1 , which are ultimately owing to _ different _ data input . the main difference is related to the fact that some authors used hadron yields at midrapidity and others used full phase space yields , in the nn centre - of - mass energy range from few gev to 17.2 gev .",
    "this is due to different assumptions regarding the physical scheme , which can be settled after a careful study of the data .",
    "the point of view of the author of this note is expounded in ref .",
    "@xcite , but we will not deal with this issue here .",
    "in fact , the main point of this note is to show that there is another source of discrepancy : an incorrect fitting method which has led to biased results .",
    "the error resides in the use , in the fits , of ratios of midrapidity or full phase space yields formed _ a posteriori _ out of quoted measurements .",
    "it should be stressed , from the very beginning , that this in incorrect procedure only if the yields quoted by the experiments are used to form ratios _ a posteriori _ in a subsequent fit analysis .",
    "experiments ( especially at rhic ) often quote ratios of yields ( e.g. @xmath3 or @xmath4 ) because they can thereby achieve some nice cancellation of systematic errors . in this case",
    ", ratios are measured by experiments and using them in a fit is perfectly legitimate and sound ; what is wrong is getting measured yields and replace them with ratios made  at home \" .",
    "when trying to determine the best fit parameters of the statistical model in relativistic heavy ion collisions , one is given particle multiplicities or ratios of multiplicities , either at midrapity ( i.e. @xmath5 for @xmath6 in the centre - of - mass frame ) or in full phase space .",
    "as has been mentioned , the experiments sometimes quote ratios because of some cancellation of systematic errors , so that the effective error on the ratio is consistently smaller than that one would get if the yields had uncorrelated errors . in most cases , though , instead of ratios , experiments quote yields , which were obtained by means of extrapolating fits to both @xmath7 and rapidity spectra . unless some definite information is provided by the experimentalists , one is supposed to assume the errors on the yields to be fully uncorrelated , so that the no further information can be obtained by just manipulating the yields _ a posteriori_. however , some authors have formed ratios out of quoted experimental multiplicities and replaced yields with an _ equal amount _ ( or diminished by one ) of ratios in the statistical model fits to determine temperature and baryon - chemical potential , even without taking into account relevant correlations between different ratios . this procedure is meant to get rid of the volume parameter in the fit , which is an overall normalization factor cancelling out in ratios , leaving only the intensive parameters @xmath8 , @xmath9 and @xmath1 . however , this method would be incorrect even if correlations were taken into account and , most likely , involves a bias in the determination of the parameters themselves .",
    "we will illustrate how this problem comes about by first giving three simple examples and presenting a realistic one in next section 2 .",
    "the simplest example is the weighted average .",
    "consider four independent measurements of the same quantity @xmath10 with different normal errors , say @xmath11 , @xmath12 , @xmath13 , @xmath14 .",
    "minimizations and tests involving normally distributed random variables requires the errors to be the _ true _",
    "variances @xcite .",
    "we will assume throughout the paper that this is the case , i.e. we assume that our errors are the actual value of the gaussian parameter @xmath15 it is well known that the problem of determining the best estimate of @xmath10 through maximum likelihood method leads to the minimization of the @xmath0 : @xmath16 and has the weighted average as solution , which is in this case @xmath17 with a @xmath18 , that is a very good fit .",
    "if , on the other hand , we want to assess the consistency of the four measurements by taking ratios of pairs , we soon face an ambiguity : how many ratios should one take ?",
    "the naive ( wrong ) answer is taking as many as degrees of freedom in the @xmath0 minimization , that is 3 in our example . yet",
    ", there are 6 different triplets ( @xmath19 in general ) which can be formed out of 4 objects , considering as equivalent a ratio @xmath20 and its inverse @xmath21 .",
    "therefore , a choice has to be made ; for instance , if we took @xmath22 , @xmath23 and @xmath24 , we would get three times 1.5 , whereas if we took @xmath25 , @xmath26 and @xmath27 , we would get 1.0 twice and 0.66 .",
    "the two triplets of ratios ( 1.5,1.5,1.5 ) and ( 1.0,1.0,0.66 ) submitted to a consistency test yield different answers in terms of statistical significance , even taking into account the correlations between them .",
    "the deep reason of this is an information loss in using a subsample of ratios of measurements instead of measurements themselves ; by retaining only three ratios out of six to naively avoid redundancy , one is forced to give up some information and the statistical significance does depend on the particular chosen subset of ratios .      in this example we provide a concrete numerical example demonstrating the involved error in fitting a subsample of ratios instead of measurement .",
    "consider a simple linear model @xmath28 to be fitted to the measurements @xmath29 .",
    "the correct fit procedure to determine the best value of @xmath30 is the minization of : @xmath31 if , on the other hand , we adopted the ratio method , we should have chosen two ratios formed out of the three measurements , e.g. @xmath32 and @xmath33 and minimize the @xmath0 : @xmath34 where @xmath35 , @xmath36 are the indices of the measurements used to form the @xmath37th ratio and @xmath38 is the covariance matrix with non - vanishing off - diagonal elements estimated by means of the error propagation rules . for this example , the @xmath0 profiles as a function of @xmath30 are compared in fig",
    "one can clearly see that both the minimum and the curvature of the @xmath0 around the minimum are different for the two functions ( [ correct ] ) and ( [ wrong ] ) .",
    "this is reflected in different estimates of the best fit value and its error .",
    "it is especially worth remarking that the error estimate related to ( [ wrong ] ) is much larger than the correct error .",
    "= 4.0 in      we are now going to consider an example which is quite close to the actual problem of fitting multiplicities to the statistical model , which will make it clear that replacing @xmath39 multiplicities with @xmath40 ratios is incorrect also for an exponential fit like the statistical - thermal model one .",
    "consider a model @xmath41 and three measurements @xmath42 . here",
    ", the parameter @xmath43 corresponds to a volume and @xmath44 to an inverse temperature .",
    "the idea is to get rid of the parameter @xmath43 and fitting just @xmath44 by taking ratios of measurements .",
    "the correct @xmath0 now reads : @xmath45 whereas the @xmath0 for the ratios @xmath46 , @xmath47 reads : @xmath48 \\right )    c^{-1}_{ij } \\left(r_j - \\exp[b(x_{k(j)}-x_{h(j)})]\\right)\\ ] ] the parameter @xmath43 has disappeared in eq .",
    "( [ wrong3 ] ) .",
    "if we have a look at @xmath0 profiles of ( [ correct3 ] ) and ( [ wrong3 ] ) as a function of @xmath44 , we can see that also in this case both minima and curvature around the minima differ .",
    "the difference between the correct estimate of @xmath44 and the one obtained by minimizing ( 2.5 ) is 2% which is little but can not be neglected aiming at reaching the best accuracy .",
    "+    = 4.0 in    from the previous three examples we have learned how the replacement of measurements with ratios of them , always involves a discrepancy with the results of the maximum likelihood method . since a fundamental theorem of statistical inference states that if an efficient unbiased estimator exists , the maximum likelihood method will find it , we can fairly conclude that the estimate obtained with the minimization of the pseudo-@xmath0 s with ratios of normally distributed random variables is not efficient and biased .",
    "although we do not provide a general analytical proof of this statement , example 2 clearly shows that the estimator is not efficient as the curvature of the @xmath0 in the minimum ( which , for a linear fit , is related to the inverse variance of the estimator ) is larger for the correct method than for the  ratios \" method .",
    "thus , most likely , bias and inefficiency occur on a more general ground .",
    "we will now provide a realistic example of how the use of ratios instead of yields alters the estimation of thermodynamical parameters .",
    "we will use data collected by star experiment at rhic , at @xmath49 gev , shown in table 1 .",
    "we stress that experimental numbers here serve just as an instrument to compare different fit procedures ; most probably , some ratio measured by star experiment has a smaller systematic error than yields and should be better used ( for a more exhaustive discussion on how they have been collected and other comments , see ref .",
    "@xcite ) . nevertheless , this is not the point here : the aim of this exercise is to show how the choice of a particular set of ratios can affect the fit outcome . in this particular case",
    ", we have to pick 11 ratios out of 66 and we then have much freedom .",
    "let us first perform a correct fit to the midrapidity yields , as quoted in table 1 , and construct an array of residuals , i.e. a set of differences between actual measurements and fitted values , divided by the experimental error .",
    "indeed , it is fairly easy to realize that if we systematically choose ratios of light particles with negative residual to heavy particles with positive residual , the ensuing value of @xmath8 from a new fit to the ratios will tend to be larger , implying that we have introduced a bias in the fit . to show this",
    ", we have first performed a fit to midrapidity densities in table 1 by fixing the strangeness suppression factor @xmath1 to 1 .",
    "we then had a look at residuals of all particles and took the heaviest particle with positive residual , i.e. @xmath50 .",
    "we then chose a set of 11 ratios @xmath51 , @xmath52 being any particle lighter than @xmath53 in table 1 , and added as last ratio in the data sample @xmath54 , also showing a fluctuation in the same direction .",
    "as has been mentioned , the expectation for this kind of analysis is to artificially enhance the temperature in this fit , because all lighter particles have a residual larger than @xmath50 s .",
    "this is indeed what is found , as shown in table 2 .",
    "if we do not include correlations , the difference between fit to ratios and correct fit to the yields is 8.2 mev , i.e. about 2.61@xmath55 .",
    "the situation is much worse for @xmath9 , with a difference of 13 mev and @xmath56 , which is owing to the same problem : choosing an upward fluctuating antibaryon as reference implies the decrease of fitted @xmath9 . on the other hand",
    "the situation improves a lot including correlations ( what is not anyway done in many analyses ) .",
    "anyhow , the method is still conceptually wrong .",
    ".list of midrapidity yields of different hadrons measured by star in au - au collisins at @xmath49 gev compared with their fitted values . [ cols=\"^,^,^\",options=\"header \" , ]",
    "we have shown that replacing , _ a posteriori _ , measured yields with an equally sized sample of particle ratios in statistical model ( as well as in any other model ) fits to determine the chemical freeze - out parameters in relativistic heavy ion collisions is a statistically incorrect method .",
    "the error resides in the fact that selecting a subsample of all possible ratios entails a loss of information and produces biased and inefficient estimators . only for vanishing measurement errors",
    "the two methods would be equivalent .",
    "we have shown , in a realistic example , that the difference between correct and wrong fit may be as large as @xmath57 mev for temperature and baryon - chemical potential if , as it is usually done , correlations are not taken into account .",
    "this difference has been found with a purposely chosen set of ratios , designed to enhance the effect and it is then unlikely that all analyses performed so far suffer from such a large bias",
    ". it would be anyway appropriate to avoid introducing this bias in analyses aimed at getting the best accuracy .",
    "i would like to express my gratitude for clarifying discussions about statistical methods of data analysis to my colleagues in the department of physics of the university of florence .",
    "f. becattini , m. gazdzicki and j. sollfrank , eur .",
    "j. c 5 ( 1998 ) 143 .",
    "f.  becattini , m.  gazdzicki , a.  keranen , j.  manninen and r.  stock , phys .",
    "c 69 ( 2004 ) 024905 .",
    "see e.g. b. roe , _ probability and statistics in experimental physics _ , springer 1992 j. manninen , talk given at _",
    "critical point and onset of deconfinement _ , florence , july 3 - 6 2006 , proceeding published in http://pos.sissa.it ."
  ],
  "abstract_text": [
    "<S> in order to determine the chemical freeze - out parameters of the hadron - emitting source in relativistic heavy ion collisions some studies in literature perform fits by using as data input a subsample of ratios calculated out of experimentally measured hadron yields instead of yields themselves . </S>",
    "<S> we show that this is a statistically incorrect method fit , implying a bias in the extracted parameters . </S>"
  ]
}