{
  "article_text": [
    "there is a standard barrier in applied science : the computational complexity of hard ( non - polynomial ) problems .",
    "the modelling of competing interactions among the components of a large system often lead to consider the solution of a problem as the minimum of a functional with a complex landscape .",
    "the extensive search for the optimal configurations has a cost that grows too quickly ( usually exponentially ) and become practically intractable when the number of composing units is of the order of a few hundreds as in the interesting cases .",
    "the study of optimizing algorithms is then a basic step toward the solution of specific practical problems emerging in different fields of applied science . in this paper",
    "we build a strategy to efficiently explore the landscape of complex functionals in combinatorial optimization in order to find its minima both local and global . to allow the reader to better focus on our method , let us describe the functional to be minimized as the mathematical representation of a quickly changing mountain profile ( in large dimensions ) , with a high multiplicity of local minima separated by high barriers .",
    "the a priori knowledge of the landscape geometry is very poor and our strategy to explore the territory in order to find good quality minima ( close to the global one ) is to send signals in random directions ( initial configurations ) , follow their evolution according to a specified dynamics ( algorithm ) and collect the observed results .",
    "our investigation procedure is not dissimilar from an optical instrument in which we may tune a few parameters to better observe the landscape and find the sites which we are interested in .",
    "the algorithm is preliminary set by choosing the elementary dynamical moves : this choice reflects the topology that we are associating to our landscape and comes with a notion of vicinity and nearest neighboring sites .",
    "the successive step is to decide the criteria after which to select among a large multiplicity of moves .",
    "this is done by keeping into account what we search for and what we most fear : we want to reach the best possible minima as quickly as possible and the worse happening is to get stuck in a local minimum which is still far from the optimal or near optimal ones .",
    "it appears rather intuitive that an algorithm with a too steepy descent ( greedy ) has a very high risk to get stuck in poor local minima , but at the same time a too slow descent ( reluctant ) would cost a very high price in terms of computer time .",
    "it is natural to expect , and indeed it is what we find , an optimal speed of descent that compromise at best among having a wide exploration basin in a reasonable amount of time .",
    "yet the danger of remaining caught in wrong local minima remains . to avoid it",
    "we also allow moves which locally and momentarily deviates from the descending directions .",
    "in other terms : to reach a good minimum it is often necessary to overcome a high barrier .",
    "physically , the introduction of a similar possibility works like the availability of thermal energy where the probability of its happening is related to the temperature of the system : the higher the temperature the more likely are moves upwards and viceversa . to introduce such a useful strategy",
    "we initially allow upward and downward moves ; with the time passing the probability to go up is progressively decreased at a rate which we may optimize ( this simulates the annealing of a physical system ) and the algorithm will continue evolving according to its downward moves .",
    "our work and the implementation of the algorithm is built and tested toward a standard model in combinatorial optimization with origins in condensed matter physics : the sherrington - kirkpatrick ( sk ) model for the mean field spin glass phase @xcite . among the advantages of our approach",
    ", there is the flexibility of our algorithms and their wide applicability to practical problems like protein folding in biology @xcite , portfolio optimization in financial mathematics @xcite , error correcting codes for digital signal transmissions @xcite .",
    "in the following sections we will present details of the model and algorithms we used in our simulations . here",
    "we summarize the main ideas and results of our analysis .",
    ".2cmin the sherrington - kirkpatrick model the cost function is identified with the energy of the system , the domain of the cost function is the discrete spin configuration space and the optimization problem amounts to find the spin configuration with the lowest energy ( ground state ) . given a proper definition of distance in the configuration space ( we can think two spin configurations to be close if they differ only for a single spin - flip ) , the energy of the system is a real - valued function forming a complex and corrugated energy landscape , with valleys ( local minima ) and peaks ( local maxima ) .",
    "our optimization algorithms are described as dynamical evolution rules in this energy landscape which , starting from a random initial condition , drive the system towards local minima of the energy . the random transition from a point of the trajectory to the successive , which is a nearest neighboring one ,",
    "is ruled by a probability with exponential density .",
    "we consider four different algorithms : starting from the simplest one ( algorithm 0 ) which allows only energy - decreasing trajectories , we implement a sequence of refinements ( algorithms 1,2,3 ) leading to more efficient strategies , which exploit also increases in the cost function .",
    ".2cmwith algorithm 0 the cost - decreasing trajectory ends up as soon as it reaches a configuration which , according to our notion of vicinity ( see sec .  3 ) is a local minimum .",
    "the parameter controlling the transition probability function tunes the steepness of descents , generating a continuum of behaviors ranging from a reluctant - type dynamics ( very small jumps and slow convergence ) to a greedy - type one ( very large jumps deep into a valley ) .",
    ".2cma first improvement of this strategy , implemented in algorithms 1 and 2 , is obtained by introducing a `` temperature '' in the system , which enables random positive fluctuations of the cost function .",
    "this is obtained through the choice of a transition probability which gives a non zero weight to upwards moves . with these choices we have the following scenario for algorithms 1 and 2 :",
    "the dynamics starts with a given initial temperature and equal probability of positive and negative moves . as the time goes on , the system is gradually cooled until it reaches a state in which positive fluctuations are forbidden and the dynamics continues as either greedy or reluctant , depending on the initial temperature . with a high initial temperature",
    "the long term behavior of the dynamics will be greedy - like , while a low initial temperature will lead to reluctant - type motion .",
    "the difference between algorithm 1 and 2 lies in the convergence criterium : while the former stops when the first local minimum is attained ( likewise algorithm 0 ) , the latter allows the trajectory to escape from it in view of the possibility to reach deeper minima ( supplementary stopping conditions are required in this case ) .",
    ".2cma further improvement of the algorithm efficiency is obtained with algorithm 3 . in this case , the transition probability is designed to model an initially hot system with high probability of positive moves , which is gradually quenched ; when the system is cool , positive fluctuations are absent and the decreasing trajectories are forced to follow greedy - like paths . in fig .",
    "[ fi : trai ] typical trajectories for the four different algorithms are reported .",
    ".2cmthe efficiency of the algorithms are quantified on one hand by measuring the average time needed to reach a local minimum , on the other hand by the quality of the found minima ( i.e. how deep they are ) .",
    "the optimization is done by tuning the parameters which control the transition probabilities ; in particular , for algorithms 1 and 2 this parameter is mainly the initial temperature , while for algorithm 3 it is the rate of the quench , i.e. the speed of convergence to zero of the temperature of the system .",
    "as one would expect , for low initial temperatures ( very low possibility of energy increase ) , algorithm 1 and 2 behaves very much as algorithm 0 .",
    "however their differences become effective for sufficiently high initial temperatures . obviously , allowing positive jumps and escapes from local minima , the relaxation times increase passing from algorithm 0 to algorithm 2 ; less trivially , numerical results show that the scaling of the execution times with respect to the system size is greatly enhanced .",
    "this is an important fact , because it suggests that a crossover between computation times is to be expected for systems with larger sizes . as regards the lowest values found ,",
    "similar conclusions can be drawn : going from algorithm 0 to algorithm 2 deeper minima are attained .",
    ".2cmalgorithm 3 can be consistently compared with algorithm 2 , which is the best performing among the first three .",
    "the computation times and their scaling with the size are similar for the two algorithms when the initial temperature ( for algorithm 2 ) is high , but a clear enhancement is obtained by algorithm 3 when it is low . also the minimal values of the cost functional are similar for high temperatures , while they are lower for algorithm 2 with low initial temperatures .",
    "the previous remarks refer to an experimental protocol in which the search for low cost configurations is performed testing a fixed number of trajectories .",
    "the minimization of cost at fixed elapsed computer time is another relevant criterium for the comparison of the algorithms . in this case",
    "the best result is obtained with algorithm 3 , even though algorithm 2 gives comparable results .",
    ".1 cm      .5 cm the system we study is the sherrington - kirkpatrick model of spin - glasses @xcite .",
    "it is defined by the hamiltonian @xmath0 where @xmath1 for @xmath2 are ising spin variables which interact through couplings @xmath3 .",
    "these are gaussian random variables , independent and identically distributed with zero mean and variance @xmath4 .",
    "the random sign ( and strength ) of the interaction generates frustration in the system , i.e. the fact that in low energy configurations some of the couples will have unsatisfied interaction . in particular , the ground state of the system is far from the standard ground state of ferromagnetic models , where all spins point in the same direction .",
    "the model has been solved through the replica symmetry breaking ansatz by g. parisi @xcite , while the rigorous solution is still a debated issue in the mathematical physics community . from the numerical point of view",
    ", the model poses amazing difficulties and indeed it is often presented as the standard example of np - problems .",
    "several numerical studies have tried different algorithms in the search of ground - state energies , for example gradient descendent @xcite , simulated annealing @xcite , genetic algorithms @xcite , extremal optimization @xcite . in a previous paper we developed a new numerical scheme , which is based on a smooth interpolation between greedy and reluctant dynamics @xcite . here",
    "we make a further step by proposing a new class of algorithms which we describe in detail in the following .",
    ".5 cm      .5 cm we focus our attention on stochastic dynamics that generates a sequence of spin configurations ending up on a local energy minimum .",
    "the smooth interpolation between greedy and reluctant dynamics studied in a previous work @xcite follows an energy - decreasing trajectory and terminates in the first local minimum it encounters : only transitions corresponding to a decrease in the cost ( energy ) function are allowed by the algorithm . in the same spirit of simulated annealing strategies @xcite , where a slow decrease of the temperature leads the system through successive metastable states with lower and lower energy , we think of a class of algorithms which also accept , in some limited way , transitions corresponding to an increase in the cost function",
    "in fact , these algorithms are based on the statistical properties of metastable states : they are organized with some structure so that the evolution dynamics can be considered as the overlapping of a `` fast '' motion in the basin of attraction of a local minimum and of a `` slow '' motion with jumps between minima ( the time of the dynamics is determined by the energy barriers between these metastable states ) . .2cmin",
    "the algorithms that we are going to introduce , the transition between the spin configuration at time @xmath5 , @xmath6 , and the successive configurations at time @xmath7 , @xmath8 depends on the spectrum of energy changes of @xmath9 , obtained by flipping the spin in position @xmath10 , for @xmath11 : @xmath12 let also define @xmath13 that will be used in what follows",
    ". as a first step , let us briefly recall the algorithm studied in @xcite , where only energy decreasing trajectory are considered .",
    "it is described by the following procedure :    .3 cm * algorithm 0 * .2 cm    1 .",
    "initialization : choose an initial spin configuration @xmath14 and a parameter value for @xmath15 .",
    "2 .   generate a random number @xmath16 with probability density @xmath17 3 .",
    "select the site @xmath18 associated with the closest energy change to the value @xmath16 , i.e. : @xmath19 4 .",
    "flip the spin on site @xmath18 : @xmath20 5 .   if @xmath21 , @xmath22 , then the algorithm stops ( @xmath9 is a local minimum ) ; otherwise repeat from step 2 .",
    "the dynamics generated by this algorithm follows a @xmath4-spin flip decreasing energy trajectory and arrives at a configuration whose energy can not be decreased by a single spin - flip .",
    "the control parameter @xmath23 in the probability distribution function for the move acceptance , tunes the speed of convergence to local energy minima : the larger is @xmath23 , the bigger is the probability of doing small energy - decreasing steps , so that the trajectory will follow an evolution path close to level curves ( reluctant ) while , small values of @xmath23 enrich the probability of large negative energy steps ( greedy ) , which will quickly drive the dynamics to the end - point .",
    ".5 cm as a modification of algorithm @xmath24 we consider two new algorithms ( algorithm 1 and algorithm 2 ) .",
    "they generate a dynamics that follows a @xmath4-spin flip trajectory that , in addition to energy - decreasing transitions , accepts also energy - increasing transitions with probability exponentially decreasing in time .",
    "the difference between the two is that while the trajectory of algorithm 1 ends up in the first local minimum it encounters , in algorithm 2 it may continue to explore the space of configurations through the visit of subsequent local minima .",
    ".3 cm * algorithm 1 * .2 cm    1 .",
    "initialization : choose an initial spin configuration @xmath14 and parameter values @xmath25 , @xmath26 , with the obvious constraint @xmath27 in our simulation we chose @xmath28 as the only free parameter , by taking @xmath29 , @xmath30 , @xmath31 .",
    "this amounts to start with an equal probability of energy decreasing and energy increasing transitions ( @xmath32 ) .",
    "2 .   generate a random number @xmath16 with probability function @xmath33 3 .",
    "select the site @xmath18 associated with the closest energy change to the value @xmath16 and with the same sign , i.e. : @xmath34 4 .",
    "flip the spin on site @xmath18 : @xmath20 5 .",
    "if @xmath21 , @xmath22 , then the algorithm stops ( @xmath9 is a local minimum ) . otherwise , change the parameter @xmath35 of the probability distribution in step 2 with a suitable scheduling , for example @xmath36 and return to step 2 .",
    "the trajectory generated by algorithm 1 wonder in the energy landscape ( by a succession of moves which decrease and increase energy ) till it arrives to a local minimum . starting from a symmetric probability distribution for the spin - flip selection , as time goes on the probability of energy - increasing moves",
    "is decreased by the update rule ( [ eq : sch1 ] ) .",
    ".5 cm next , we want to consider an algorithm as the previous one but with the possibility of exploring subsequent minima .",
    "the problem one has to solve is to give an efficient criterium to stop the dynamics .",
    "we considered the following implementation :    .3 cm * algorithm 2 * .2 cm    1 .",
    "initialization : as in algorithm 1 .",
    "set also @xmath37 and @xmath38 .",
    "2 .   generate a random number @xmath16 as follows : + with probability function @xmath39 and with probability function @xmath40 3 .",
    "select the site @xmath18 associated with the closest energy change to the value @xmath16 and with the same sign , i.e. : @xmath34 4 .   flip the spin on site",
    "@xmath18 : @xmath20 5 .   if @xmath21 , @xmath22 , and @xmath41 then stop . +",
    "@xmath16 is a random number , @xmath42 is the cumulative function of the probability described in step 2 and @xmath43 is a small parameter . in other words ,",
    "if we arrive in a minimum and the probability of a significant energy increasing transition from this local minimum is too small ( or even zero when the energy increases are forbidden , see step 2 ) , then the algorithm stops .",
    "change the probability distribution ( [ eq : ftalg2 ] ) with the scheduling ( [ eq : sch1 ] ) for @xmath35 ( the same scheduling used in algorithm 1 ) and return to step 2 .    as in algorithm 1",
    ", the dynamics generated by this algorithm follows a @xmath4-spin flip trajectory making a combination of upwards and downwards moves .",
    "however , in this case , the trajectory does not end up in the first @xmath4-spin flip stable configuration it encounters , at least as long as the probability of positive moves ( @xmath44 ) remains greater than a certain threshold ( @xmath45 times the probability of negative moves @xmath46 - in our experiments @xmath37 ) . with this strategy it is possible to escape from the local minima to explore the neighboring space in view of ( possible ) lower energy minima . when the probability of energy increases exceed this fixed threshold , from this point on ,",
    "only decreases in energy are accepted and so the process terminates when the subsequent local minimum is reached .",
    "in fact , when the process starts at time @xmath47 we choose equal probabilities @xmath48 and @xmath49 of cost - decreasing or cost - increasing moves , respectively , by settling @xmath50 . as the algorithm continues its execution ,",
    "we decrease @xmath44 towards zero , varying the control parameter @xmath35 in accordance with the above mentioned law ( [ eq : sch1 ] ) : @xmath51 ( and keeping fixed @xmath28 ) until @xmath52 ; as a consequence , the probability of energy - decreasing move acceptance @xmath46 tends to one ( @xmath53 ) .",
    "therefore , while the speed of convergence to the local energy minima is mainly tuned by @xmath28 , the vanishing velocity of the probability of energy - increasing steps is governed by the parameter @xmath54 .",
    "of course , large @xmath28 ( and @xmath35 ) lead to evolution paths generated by small ( in absolute value ) energy changes ( _ annealed reluctant dynamics _ ) and the closer @xmath54 is to @xmath4 , the slower @xmath35 grows and then the more energy increases are enabled .",
    "when @xmath55 the dynamics continues governed only by the parameter @xmath28 , not depending on @xmath5 .",
    ".2cmwe see that for algorithm @xmath56 the possibility to escape from the minima is effective only when @xmath28 is sufficiently small ( say @xmath57 , and then @xmath58 , see ( [ eq : sch1 ] ) ) . for greater values of @xmath28",
    "the possibility to explore successive minima is not exploited and both the dynamics @xmath4 and @xmath56 can be expected to give similar results in terms of achieved minimum energy level . in these cases , the dynamics generated by algorithm @xmath56",
    "ends up naturally , after @xmath59 steps , in the first minimum it encounters , because the ( step dependent ) probability @xmath60 to escape from this configuration is too small ; therefore , we expect that for large values of @xmath28 algorithms @xmath4 and @xmath56 should be equivalent .",
    ".5cmsince for these algorithms the speed of convergence to the finale state is governed by the probability function @xmath61 , we can consider a third algorithm in which the time dependence is present only in the control parameters @xmath62 , @xmath63 ; in this case , starting from a ( in general ) non symmetric probability function , the dynamics evolves gradually towards a final scenario in which the system is cooled by tuning the control parameter @xmath64 .",
    ".3 cm * algorithm 3 * .2 cm    1 .",
    "initialization : choose an initial spin configuration @xmath14 and parameter values @xmath65",
    ", @xmath66 such that @xmath67 .",
    "set also @xmath37 and @xmath38 .",
    "2 .   generate a random number @xmath16 as follows : + with probability function @xmath68 and with probability function @xmath69 3 .",
    "select the site @xmath18 associated with the closest energy change to the value @xmath16 and with the same sign , i.e. : @xmath34 4 .",
    "flip the spin on site @xmath18 : @xmath20 5 .",
    "if @xmath21 , @xmath22 , and @xmath70 then stop ( as in algorithm 2 ) . 6 .   change the probability distribution defined in ( [ eq : ftalg3 ] ) with the same scheduling for @xmath35 used in algorithm 2 and return to step 2 .",
    "the main difference between algorithm 2 and algorithm 3 is that in the latter , when the process starts at time @xmath47 we have ( if @xmath71 ) different probabilities of energy - decreasing moves ( @xmath72 ) and of energy - increasing moves ( @xmath73 ) .",
    "as algorithm 3 continues its execution , we decrease @xmath74 towards zero , varying the control parameter @xmath35 in accordance with the scheduling : @xmath75 until @xmath76 ; as a consequence , the probability of energy - decreasing move acceptance @xmath77 tends to one ( @xmath78 ) .",
    "therefore , while the speed of convergence to the final state is mainly tuned by the initial value @xmath65 of the time dependent parameter @xmath64 ( which tends to @xmath4 , as time @xmath5 increases ) , the vanishing velocity of the probability of energy - increasing steps is governed by the parameter @xmath54 .",
    "when @xmath79 the dynamics continues , for @xmath80 , governed only by the parameter @xmath81 ( close to 1 ) not depending on @xmath5 .",
    "the dynamic evolution of the probability density functions for algorithm 1 and 2 compared with algorithm 3 is reported in fig .",
    "[ fi : pdfdy ] .    .",
    "the continuous lines refer to @xmath47 ; the time goes on passing from broken lines to dotted ones.,title=\"fig:\",width=491,height=377 ] ( -10.3,10)(a ) ( -3,10)(b )    .5cmsummarizing : the control parameters are @xmath23 for algorithm 0 , @xmath28 and @xmath54 for algorithms @xmath4 and @xmath56 , and @xmath65 and @xmath54 for algorithm @xmath82 . varying them we study the efficiency of the algorithms by measuring the average time to reach a metastable configuration and the lowest energy value found for different system sizes .",
    "to compare these annealed algorithms with those carried out in previous works @xcite and in particular with algorithm 0 , we performed a set of trials for different values of @xmath83 , starting from @xmath83 initial conditions ( for a system of size @xmath83 ) and averaging the data on @xmath84 disorder realizations .",
    "we measured two quantities to test the performance of the algorithms :    * the average time ( i.e. the number of spin flips ) to reach a minimum energy level @xmath85 with @xmath86 and @xmath87 , @xmath88 the time for each initial condition ; * the lowest energy found ( averaged over disorder ) @xmath89 where @xmath90 is the minimum value of the energy of the metastable states attained starting from the set of the @xmath83 initial conditions .",
    "our numerical experiments follows two different protocols :    1 .   with a fixed number of initial conditions ; 2 .   with a fixed elapsed computer time .",
    "the results are described in the following subsections .     to reach a metastable configuration as a function of @xmath83 for different values of @xmath28 and @xmath54 for algorithm 2 and for a fixed number of initial spin configurations.,title=\"fig:\",width=491,height=377 ]",
    "( -1.5,0)@xmath83 ( -12.5,9)@xmath91 ( -2.6,9.36 ) ( -2.6,9.1 ) ( -2.76,8.81 ) ( -2.76,8.53 ) ( -2.75,8.24 ) ( -2.9,7.97 ) ( -2.9,7.70 ) ( -2.9,7.42 ) ( -3,7.14 ) ( -1.18,9.44)(1,0).4 ( -1.18,9.17)(1,0).4 ( -1.18,8.89)(1,0).4 ( -1.18,8.54 ) ( -1.18,8.28 ) ( -1.19,7.98 ) ( -1.19,7.7 ) ( -1.19,7.44 ) ( -1.19,7.17 )      the dynamics of algorithm 0 has been shown @xcite to behave as a smooth interpolation between greedy and reluctant dynamics @xcite depending on the parameter @xmath23 : small @xmath23 ( say @xmath92 ) plays the role of the greedy algorithm , while large @xmath23 ( say @xmath93 ) that of reluctant .",
    "in fact , the relaxation time @xmath94 grows linearly with the system size when @xmath92 and quadratically when @xmath93 ( see tab .  [ tabfitcrnew ] ) , as it was previously observed in @xcite for deterministic greedy and reluctant regimes .    in fig .",
    "[ fi : cr1new ] , which refers to algorithm 2 , we represent @xmath91 as a function of @xmath83 ( @xmath95 $ ] ) .",
    "we performed the analysis for different values of the control parameters .",
    "for the sake of space , we show only the values @xmath96 and three values of @xmath54 ( @xmath97 ) for each @xmath28 , together with the best numerical fits .",
    "[ fi : cr1new ] shows the progressive increase of the slope in log - log scale from a sub - linear law in @xmath83 for @xmath98 and @xmath99 ( @xmath100 -.51 cm  ) to a super - linear one for @xmath101 and @xmath99 ( @xmath102 -.65 cm @xmath103 ) .",
    "more in detail , the numerical fits of @xmath104 in fig .",
    "[ fi : cr1new ] are reported in tab.[tabfitcrnew ] .",
    ".numerical fits of @xmath105 for algorithm 0 ( with the symbols of fig .",
    "[ fi : sr_cr1 ] ) and of @xmath106 for algorithm 1 and algorithm 2 ( with the symbols of fig .",
    "[ fi : cr1new ] ) [ cols=\"^,^,^,^,^,^,^,^,^,^ \" , ]      to reach a metastable configuration as a function of @xmath83 for different values of @xmath65 and @xmath54 for algorithm 3 , together with the best numerical fits for a fixed number of initial conditions .",
    "we represent @xmath107 ( @xmath99 ( @xmath100 -.4 cm  ) , @xmath108 ( @xmath109 -.49 cm  ) and @xmath110 ( @xmath111 -.49 cm  ) ) , @xmath112 ( @xmath99 ( @xmath100 -.45 cm @xmath103 ) , @xmath108 ( @xmath109 -.49 cm @xmath103 ) and @xmath110 ( @xmath111 -.49 cm @xmath103 ) ) and @xmath113 ( @xmath99 ( @xmath102 -.49 cm @xmath103 ) , @xmath108 ( @xmath114 -.58 cm @xmath103 ) and @xmath110 ( @xmath115 -.49 cm @xmath103 ) ) , title=\"fig:\",width=491,height=377 ] ( -1.5,0)@xmath83 ( -12.5,9)@xmath91     as a function of @xmath83 for different values of @xmath65 and @xmath54 for algorithm 3 and for a fixed number of initial conditions.,title=\"fig:\",width=491,height=377 ] ( -1.,0)@xmath83 ( -12.5,9)@xmath116 ( -3,9.36 ) ( -3,9.1 ) ( -3.16,8.81 ) ( -3.16,8.53 ) ( -3.16,8.24 ) ( -3.15,7.97 ) ( -3.3,7.70 ) ( -3.3,7.42 ) ( -3.3,7.14 ) ( -3.4,6.86 )     as a function of @xmath83 for @xmath117 ( @xmath100 ) for algorithm 0 , for @xmath101 and @xmath99 ( @xmath114 ) for algorithm 1 and ( @xmath102 ) for algorithm 2 and for @xmath107 and @xmath118 ( @xmath115 ) for algorithm 3.,title=\"fig:\",width=491,height=377 ] ( -2,0)@xmath83 ( -12.5,9)@xmath116 ( -2.1,9.36 ) ( -4,9.36 ) ( -3,9.1 ) ( -4,9.1 ) ( -3,8.79 ) ( -4,8.79 ) ( -3.1,8.49 ) ( -4,8.49 )     as a function of @xmath83 for different values of control parameters for algorithms 0 , 1 , 2 and 3 , for a fixed cpu time of @xmath119 h on a ibm sp4 . the symbol ( + ) refers to @xmath120 for algorithm 0 , @xmath121 to @xmath122 and @xmath99 for algorithm 1 , ( @xmath111 ) to @xmath98 and @xmath110 for algorithm 2 and ( @xmath102 ) for @xmath107 and @xmath118 for algorithm 3.,title=\"fig:\",width=491,height=377 ] ( -1.5,0)@xmath83 ( -12.5,9)@xmath116 ( -4,9.36 ) ( -2,9.36 ) ( -4,9.1 ) ( -2.76,9.1 ) ( -4,8.81 ) ( -2.76,8.81 ) ( -4,8.53 ) ( -3,8.53 )",
    "we thank prof . s. graffi and prof .",
    "i. galligani for their encouragement . the cineca staff and in particular dr .",
    "g. erbacci and dr . c. calonaci",
    "are acknowledged for the technical support .",
    "the computation resources were provided by cineca ( high performance computing grant ) and by cicaia ( universit di modena e reggio emilia ) .",
    "l. bussolari , p.contucci , c. giardin , c. giberti , f. unguendoli , c. vernia , `` optimization strategies in complex systems '' , _ science and supercomputing at cineca - 2003 report _ , 386 - 390 , http://arxiv.org/abs/math.na/0309058 .",
    "p.contucci , c. giardin , c. giberti , f. unguendoli , c. vernia , `` interpolating greedy and reluctant algorithms '' , to appear on _ optimization methods and software _ ( 2004 ) , http://arxiv.org/abs/math-ph/0309063 ."
  ],
  "abstract_text": [
    "<S> we consider optimization problems for complex systems in which the cost function has a multivalleyed landscape . </S>",
    "<S> we introduce a new class of dynamical algorithms which , using a suitable annealing procedure coupled with a balanced greedy - reluctant strategy drive the systems towards the deepest minimum of the cost function . </S>",
    "<S> results are presented for the sherrington - kirkpatrick model of spin - glasses . </S>"
  ]
}