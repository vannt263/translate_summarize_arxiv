{
  "article_text": [
    "suppose we have a numerical model , @xmath0 , for a dynamical process : @xmath1 where @xmath2 is the state at time indexed by @xmath3 .",
    "then it is almost certain that such a numerical model @xmath0 will contain errors .",
    "a large amount of uncertainty quantification has revolved around providing bounds of the accuracy of the numerical scheme used to approximate the underlying mathematical or statistical problem @xcite .",
    "this ignores one large issue : the underlying mathematical problem does not represent all of the features of the real world system in which one is interested . for example , when modelling wind around a wind farm , drag induced by individual trees / plants will likely not be included . instead , some approximate homogenised quantity will be used . as another example , when modelling carbon fibre composites , specific manufacturing defects will not be included in the model until measurements of the materials response under various loading conditions are incorporated .",
    "the ubiquitous quote on this issue is from @xcite : `` all models are wrong but some are useful '' . the problem we address is how to estimate the distribution of the errors that are made by the mathematical model in simulating a physical system .    to get a measure of",
    "how far a mathematical model is deviating from the real world , it is necessary to use observations from the system as an independent source of information .",
    "typically we shall never be able to fully observe a system ( in time and/or space ) and so one has to be careful how to compare a small set of observations with the larger model of the system . the theoretical framework to do this",
    "rigorously is well established : using data assimilation to numerically implement bayes theorem ( * ? ? ? * for example ) .",
    "a physical system that occurs in nature has only one realisation .",
    "we refer to that realisation as the _ truth _ and denote it @xmath4 .",
    "if we use such a truth with the numerical model of the system we have the following evolution equation , @xmath5 here @xmath6 is the model error term which is a realisation of a stochastic process which occurs at time @xmath3 .",
    "we wish to estimate , through the use of data assimilation , the properties of the distribution that @xmath6 follows .",
    "the first two moments of this unknown distribution , its mean and covariance , are denoted @xmath7 and @xmath8 respectively .",
    "knowledge of @xmath6 can be fed back into the dynamical model @xmath0 as a way to systematically improve the model .",
    "for example , directly subtracting @xmath7 from the model would be an example of a bias correction method ( e.g. * ? ? ? * ) , whereas the sources of these errors can be attributed to components of the model equations @xcite and thus can be corrected to improve the mathematical model .",
    "we use any or all prior information we have , along with observations of the system to obtain a _",
    "`` best estimate '' _ of the truth .",
    "this is the data assimilation stage and results in what is referred to as the _",
    "`` analysis '' _ , @xmath9 .",
    "there are many different techniques for data assimilation , each which make various assumptions or simplifications to bayes theorem .",
    "see @xcite or @xcite for an overview of the field .",
    "once we have @xmath9 we define our approximation to the model error at timestep @xmath3 , @xmath10 , with the equation @xmath11 this makes no assumptions on how @xmath9 is calculated .",
    "however , we can immediately see that one traditional method of data assimilation is inappropriate to estimate the @xmath6 term .    to estimate @xmath6 , @xmath9",
    "should not be obtained from strong constraint 4dvar ( sc-4dvar ) .    in sc-4dvar the analysis at time @xmath12 , @xmath13 is given as @xmath14 here , @xmath15 is a background estimate for the state at time @xmath12 , assumed to be gaussian with background error covariance matrix @xmath16 .",
    "observations of the system @xmath17 are taken at @xmath18 separate times @xmath19 .",
    "the observation is related to the system through the observation equation @xmath20 where the observation errors @xmath21 are assumed to be gaussian with an observation error covariance matrix @xmath22",
    ". then at subsequent times in the assimilation window , @xmath23 and thus @xmath24 .",
    "having an estimate for @xmath8 is important as it plays a vital role in many modern data assimilation methods . in the variational method of data assimilation known as weak constraint 4dvar ( wc-4dvar ) , in addition to the background and observation terms of sc-4dvar",
    ", a third term is introduced to penalise the addition of model error @xcite , which is implicitly assumed to follow a gaussian distribution .",
    "@xmath25 in this formulation , @xmath26 is the initial state which the method seeks to find , along with model error terms @xmath27 .",
    "the first term penalises the difference in the initial state @xmath28 and an initial guess known as the background term @xmath15 , weighted by the inverse of the background error covariance matrix @xmath16 .",
    "the second term penalises discrepancies between observations of the system @xmath29 and the model equivalent of the observations at the corresponding time , @xmath30 , all weighted by the appropriate observation error covariance matrix @xmath22 .",
    "this notation hides the fact that @xmath31 etc .",
    "the final term penalises the introduction of model error at each model timestep @xmath32 , weighted by the model error covariance matrix @xmath8 .    in particle filters , such as the equivalent weights particle filter @xcite , @xmath8",
    "is used as part of the proposal density to bring the ensemble closer to the observations .",
    "it also appears in the computation of weights associated with each particle .",
    "@xcite showed that the lack of information regarding @xmath8 is the limiting factor to applying particle filters in large - scale geophysical systems .",
    "much of the work to estimate @xmath8 has been undertaken at the european centre for medium - range weather forecasting ( ecmwf ) in the context of implementing a form of wc-4dvar for operational numerical weather forecasting .",
    "the lack of knowledge of @xmath8 is one of the main reasons that such weak - constraint methods are not operational .",
    "@xcite notes `` weak - constraint 4d - var has never been implemented fully with a realistic forecast model because of the computational cost and because of the lack of information to define the model - error covariance matrix required to solve the problem '' .",
    "it has been shown @xcite that for the atmospheric case , the background error covariance matrix ( @xmath16 ) is not successful as an approximation to the model - error covariance matrix ( @xmath8 ) . as an _ ad hoc _ approximation to @xmath8 , @xcite suggests the following . at time @xmath3 , get an ensemble of analysis states @xmath33 . as each ensemble member should be indistinguishable from the truth , each forecast @xmath34",
    "could be considered a `` possible evolution of the atmosphere from the true state '' . from this , trmolet concluded that the differences in these forecast increments could be interpreted as `` an ensemble of possible realisations of model error '' . the real world , however , has only one realisation .",
    "hence one needs to compare these forecasts not with themselves , but with the observations instead . in this way",
    ", one discovers not just where the model diverges based on its initial conditions , but where it has failed to capture the realisation of the underlying stochastic dynamics .    a smoother is a sequential method of data assimilation that gives an estimate of @xmath9 for all @xmath3 , not simply at timesteps where observations are present .",
    "recently , the concept of using a forecast from a lag-1 smoother estimate to approximate the model error covariances has been investigated @xcite .",
    "this work only considers estimating the @xmath8 the problem in observation space , and do not look at the full information available to them in state space .",
    "this is physically motivated as in the case where only the observed variables of the dynamical system are well constrained , only the projection of @xmath8 into the observation space will be accurate .",
    "such derivations from a smoother trajectory have been investigated by @xcite in the context of parameter and parameterization estimation .",
    "when the model error can be attributed to incorrect coefficients in the formulation of the model equations then it has been shown that the first moment of the derived model error can be used to determine the necessary corrections to the parameters used in the numerical model .",
    "this can be extended to estimation of parameterizations when the first moment of the model error is regressed onto different functions of the model state vector .",
    "however higher order moments have not been investigated .",
    "we now set out on the main path of this paper : to find a bound on the error in the approximation of @xmath7 and @xmath8 in terms of the accuracy of @xmath9 in approximating @xmath4 .",
    "the main assumption we shall make is that the dynamical model @xmath0 is ( lipschitz ) continuous .",
    "if the model were not continuous at @xmath35 then regardless of how close we approximate this argument , the resulting model trajectory could be wildly different .",
    "this would lead to a poor approximation of the model error .",
    "[ thm : beta]suppose @xmath0 is lipschitz with constant @xmath36 and @xmath37",
    ". then @xmath38 .",
    "@xmath0 lipschitz @xmath39 s.t . @xmath40 .",
    "@xmath41    hence @xmath42 as @xmath43 then latexmath:[\\ ] ]    it is now possible to obtain a bound on the error in the covariance of the model error distribution in terms of the analysis error . for clarity",
    ", the notation @xmath73 also refers to the @xmath57 component of a vector that already has a subscript .",
    "[ thm : q ] suppose @xmath0 is lipschitz with constant @xmath36 .",
    "suppose further that , for all @xmath3 , the analysis satisfies @xmath74 and @xmath75 then the corresponding estimated sample error covariance satisfies @xmath65 .    by theorem [ thm : beta ] , if @xmath74 then @xmath76 similarly if @xmath77 then @xmath78    by corollary [ cor : mu ] if @xmath79 then @xmath80 and if @xmath81 then @xmath82 hence we can use lemma [ lemma : q ] . thus @xmath65 .",
    "corollary [ cor : mu ] shows that if one desires to know the mean of the model error to an accuracy of @xmath83 , then the analysis of that variable must be within @xmath84 of the truth at every timestep .",
    "contrast this with the result from theorem [ thm : q ] : to estimate the variance of a variable to within @xmath83 , the analysis of that variable must be within @xmath85 of the truth at each timestep",
    ". with the factor of @xmath86 in the denominator , this can be seen as approximately an order of magnitude more accuracy needed in the analysis to achieve the same accuracy in the approximation . moreover , the accuracy in the variance depends on the mean value of that variable .",
    "the larger the mean value , the more accuracy required in the analysis to give the same error in the variance .",
    "this may be more easily understood conversely : the larger the mean value in a variable , the larger the error in the estimation of its variance .",
    "in this section we apply the model error moment estimation method as detailed in the previous sections to the lorenz 96 system @xcite .",
    "this is a very simple example to show numerically that the errors in the approximations of @xmath7 and @xmath8 are dependent on the quality of the analysis @xmath9 .",
    "the lorenz 96 system is given by the following ode :    @xmath87    where @xmath88 with cyclic boundary conditions .",
    "we choose @xmath89 .",
    "we prescribe the truth to evolve as with @xmath90 where @xmath91 and @xmath92 where @xmath93 @xmath94 and @xmath95 have been chosen to be _ interesting _ and @xmath95 in particular , for implementation purposes , has a rather simple symmetric square root .",
    "we take observations of the true state at every timestep .",
    "the observations are related to the state via the equation @xmath96 here we consider @xmath97 and will show two different experiments with observations of varying accuracy .",
    "the first experiment will have @xmath98 , and represents very informative observations .",
    "the second experiment will have @xmath99 , and represents observations containing less information .    to get an analysis @xmath9",
    ", we perform a simple 3dvar at each timestep .",
    "that is , @xmath100 we use @xmath101 as a particularly uninformative prior .",
    "the model is evolved for 3000 timesteps , giving us 2999 samples of @xmath10 .",
    "figure [ fig : hov ] shows hovmller diagrams of the analysis error as a result of the data assimilation process .",
    "the higher precision observations lead to significantly lower estimation errors .    using these analyses , estimates for @xmath102 and @xmath103 are calculated .",
    "results for @xmath104 are shown in figures [ fig : mu_8 ] to [ fig : qe_8 ] and for @xmath105 are shown in figures [ fig : mu_3 ] to [ fig : qe_3 ] .",
    "these results show that the second order moment of model error , @xmath8 , is much more sensitive to the quality of the analysis than the first order moment , @xmath7 .",
    "this is consistent with the theory set out in the previous section .",
    "0.48     for the two different precision observations .",
    "observe that the 3dvar algorithm can reduce the error in the state by @xmath106 orders of magnitude when the observations are more precise . ]",
    "0.48     for the two different precision observations .",
    "observe that the 3dvar algorithm can reduce the error in the state by @xmath106 orders of magnitude when the observations are more precise . ]    0.48 , title=\"fig : \" ]    0.48 , title=\"fig : \" ]    0.33    , scaledwidth=113.0% ]    0.33    , scaledwidth=113.0% ]    0.33    , scaledwidth=113.0% ]    0.33    , scaledwidth=113.0% ]    0.33    , scaledwidth=113.0% ]    0.33    , scaledwidth=113.0% ]    0.48 , title=\"fig : \" ]    0.48 , title=\"fig : \" ]    0.33    , scaledwidth=113.0% ]    0.33    , scaledwidth=113.0% ]    0.33    , scaledwidth=113.0% ]    0.33    , scaledwidth=113.0% ]    0.33    , scaledwidth=113.0% ]    0.33    , scaledwidth=113.0% ]",
    "this paper has considered using the problem of estimating the moments of model error of a dynamic model .",
    "the model error is approximated by the difference of the analysis and the model forecast of the analysis at the previous timestep .",
    "bounds for the errors in both the first and second moment of the approximated model error compared to the sample model error are derived , in terms of the error in the analysis from the truth .",
    "it is shown that to achieve the same error estimation in the second moment compared with the first , the analysis must be an order of magnitude closer to the truth .",
    "numerical experiments were conducted to elucidate how the quality of the analysis affects the estimation of both the mean and the covariance of the model error .",
    "it is shown numerically with the lorenz 96 system that the estimation of the covariance of the model error is much more sensitive to the quality of the data assimilation than the estimation of the mean of the model error ."
  ],
  "abstract_text": [
    "<S> using a dynamical model to make predictions about a system has many sources of error . </S>",
    "<S> these can include errors in how the model was initialised but also errors in the dynamics of the model itself . </S>",
    "<S> for many applications in data assimilation , probabilistic forecasting , or model improvement , these model errors need to be known over the timestep of the model , not over a time - averaged period . using a forecast from a state that combines observational information as well as prior information we can gain an approximation to the statistics of the model errors on the timescale of the model that is required . here </S>",
    "<S> we give bounds on the errors in the estimation of the mean and covariance of the errors in the model equations in terms of the errors made in the state estimation . </S>",
    "<S> this is the first time that such a result has been derived . </S>",
    "<S> the result shows to what extent the state estimation must constrain the analysis in order to obtain a specified error on the mean or covariance of the model errors . </S>",
    "<S> this is particularly useful for experimental design as it indicates the necessary information content required in observations of the dynamical system .    </S>",
    "<S> * keywords : * model error estimation , data assimilation , analysis forecast , model error covariance estimation </S>"
  ]
}