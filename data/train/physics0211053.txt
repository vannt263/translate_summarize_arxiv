{
  "article_text": [
    "the problem of long - range correlations is one of the topics of current research in the statistical mechanics .",
    "the stochastic processes with strong correlations have been observed in numerous systems .",
    "examples include the natural languages , the dna sequences , etc .",
    "@xcite .",
    "one of the efficient methods to investigate the correlated systems is based on a decomposition of the space of states into a finite number of parts labelled by definite symbols .",
    "this procedure referred to as coarse graining is accompanied by the loss of short - range memory between symbols but does not affect and does not damage the robust invariant statistical properties of the long - range correlated sequences . in terms of the power spectrum , one loses only the short - wave part of the spectrum .",
    "the most frequently used method of the decomposition is based on the introduction of two parts of the phase space . in other words , it consists in mapping the two parts of states onto two symbols , say 0 and 1 .",
    "thus , the problem is reduced to the investigation into the statistical properties of the binary sequences .",
    "this method is applicable for the examination of the both discrete and continuous systems .",
    "one of the ways to get a correct insight into the nature of correlations in a system consists in an ability of constructing a mathematical object ( for example , a correlated sequence of symbols ) possessing the same statistical properties as the initial system .",
    "there are many algorithms to generate long - range correlated sequences : the inverse fourier transform  @xcite , the expansion - modification li method  @xcite , the voss procedure of consequent random addition  @xcite , the correlated levy walks  @xcite , etc .",
    "we believe that from among the above - mentioned methods , using the markov chains is one of the most important .",
    "we would like to demonstrate this statement in the present paper .    in the next sections , the statistical properties of the _ binary many - steps markov chain _ is examined . in spite of the long - time history of studying the markov sequences ( see , for example ,  @xcite ) ,",
    "the concrete expressions for the variance of sums of random variables in such strings have not been obtained yet .",
    "our model operates with two parameters governing the conditional probability of the discrete markov process , specifically with the memory length @xmath1 and the correlation parameter @xmath3 .",
    "the correlation and distribution functions as well as the variance @xmath4 being nonlinearly dependent on the length @xmath2 of a word are derived analytically and calculated numerically .",
    "the nonlinearity of the @xmath5 function reflects the strong correlations in the system .",
    "the evolved theory is applied to the coarse - grained written texts and dictionaries , and to dna strings as well .",
    "let us consider a stationary binary sequence of symbols , @xmath6 . to determine the @xmath1-_step markov chain _ we have to introduce the conditional probability @xmath7 of following the definite symbol ( for example , zero ) after symbols @xmath8 .",
    "thus , it is necessary to define @xmath9 values of the @xmath10-function corresponding to each possible configuration of the symbols @xmath11 .",
    "we suppose that the @xmath10-function has the form , @xmath12 it is reasonable to assume the function @xmath13 to be decreasing with an increase of the distance @xmath14 between the symbols @xmath15 and @xmath16 in the markov chain .",
    "however , for the sake of simplicity we consider here a step - like memory function @xmath17 independent of the second argument @xmath14 . as a result ,",
    "our model is characterized by three parameters only , specifically by @xmath18 , @xmath19 , and @xmath1 : @xmath20 note that the probability @xmath10 in eq .",
    "( [ 2 ] ) depends on the numbers of symbols 0 and 1 in the @xmath1-word but is independent of the arrangement of the elements @xmath15 .",
    "we also suppose that @xmath21 this relation provides the statistical equality of the numbers of symbols zero and unity in the markov chain under consideration .",
    "in other words , the chain is non - biased . indeed , taking into account eqs .",
    "( [ 2 ] ) and ( [ 2a ] ) and the sequence of equations , @xmath22 one can see the symmetry with respect to interchange @xmath23 in the markov chain . here",
    "@xmath24 is the symbol opposite to @xmath16 , @xmath25 .",
    "therefore , the probabilities of occurring the words @xmath26 and @xmath27 are equal to each other for any word length @xmath2 . at @xmath28",
    "this yields equal average probabilities of occurring @xmath29 and @xmath30 in the chain .    taking into account the symmetry of a conditional probability @xmath10 with respect to a permutation of symbols @xmath16 ( see eq .",
    "( [ 2 ] ) ) , we can simplify the notations and introduce the conditional probability @xmath31 of occurring the symbol zero after the @xmath1-word containing @xmath14 unities , e.g. , after the word @xmath32 , @xmath33 with the correlation parameter @xmath34 being defined by the relation @xmath35    we focus our attention on the region of @xmath34 determined by the persistence inequality @xmath36 .",
    "nevertheless , the major part of our results is valid for the anti - persistent region @xmath37 as well .",
    "a similar rule for the production of an @xmath1-word @xmath38 following after a word @xmath39 was suggested in ref .",
    "however , the conditional probability @xmath40 of occurring the symbols @xmath41 does not depend on the previous ones in the model  @xcite .      in order to investigate the statistical properties of the markov chain , we consider the distribution @xmath42 of the words of definite length @xmath2 by the number @xmath14 of unities in them , @xmath43 and the variance of @xmath14 , @xmath44 where @xmath45 if @xmath46 one arrives at the known result for the non - correlated brownian diffusion , @xmath47 we will show that the distribution function @xmath42 for the sequence determined by eq .  ( [ 14 ] ) ( with nonzero but not extremely close to 1/2 parameter @xmath34 ) is the gaussian with the variance @xmath5 nonlinearly dependent on @xmath2 .      for the stationary markov chain , the probability @xmath48 of occurring a certain word",
    "@xmath49 satisfies the equation , @xmath50 thus , we have @xmath9 homogeneous algebraic equations for @xmath9 words and the normalization equation @xmath51 .",
    "the set of equations can be essentially simplified owing to the following statement .",
    "* proposition * @xmath52 : _ the probability @xmath48 depends on the number @xmath14 of unities in the @xmath1-word only but is independent of the arrangement of symbols in the word @xmath49_.    this statement illustrated by fig .",
    "1 is valid owing to the chosen simple model ( [ 2 ] ) , ( [ 14 ] ) of the markov chain .",
    "it can be easily verified directly by the substitution of the obtained below solution eq .",
    "( [ 15 ] ) into set ( [ 10 ] ) .",
    "proposition @xmath52 leads to the very important property of isotropy : any word @xmath53 appears with the same probability as the inverted one , @xmath54 .",
    "vs its number @xmath55 in the binary code , @xmath56 for @xmath57 , @xmath58.,title=\"fig : \" ]    let us apply set of eqs .",
    "( [ 10 ] ) to the word @xmath59 : @xmath60 this yields the recursion relation for @xmath61 , @xmath62",
    "in this section we investigate the statistical properties of the markov chain , specifically , the distribution of the words of definite length @xmath2 by the number @xmath14 of unities in them .",
    "the length @xmath2 can also be interpreted as the number of jumps of some particle over an integer - valued 1-d lattice or as the time of the diffusion imposed by the markov chain under consideration .",
    "the form of the distribution function @xmath42 depends essentially on the relation between the word length @xmath2 and the memory length @xmath1 .",
    "therefore , we start our study with the simplest case , @xmath63 .",
    "the value @xmath64 is the probability that an @xmath1-word contains @xmath14 unities with a _",
    "definite _ order of symbols @xmath65 .",
    "therefore , the probability @xmath66 that an @xmath1-word contains @xmath14 unities with _",
    "arbitrary _ order of symbols @xmath65 is @xmath64 multiplied by the number @xmath67 of different permutations of @xmath14 unities in the @xmath1-word , @xmath68 combining eqs .",
    "( [ 15 ] ) and ( [ 19 ] ) , we get @xmath69 with the parameter @xmath70 defined by @xmath71 the normalization constant @xmath72 can be obtained from the equality , @xmath73 note that the distribution @xmath66 is an even function of the variable @xmath74 , @xmath75 this fact is a direct consequence of the above - mentioned statistical equivalency of zeros and unities in the markov chain under consideration .",
    "let us analyze the distribution function @xmath66 for different relations between the parameters @xmath1 and @xmath3 .      in the absence of correlations , @xmath77 , eq .",
    "( [ 18 ] ) and the stirling formula yield the gaussian distribution at @xmath78 . in the most interesting case of not too strong persistence , @xmath76 , one can also obtain the gaussian form for the distribution function , @xmath79 with the @xmath3-dependent variance , @xmath80 equation ( [ 27 ] ) says that the @xmath1-words with equal numbers of zeros and unities , @xmath81 , are mostly probable .",
    "note that the persistence results in an increase of the variance @xmath82 with respect to its value @xmath83 at @xmath84 .",
    "in other words , the persistence is conductive to the intensification of the diffusion .",
    "inequality @xmath76 provides @xmath85 . therefore , despite the increase of @xmath82 , the fluctuations of @xmath86 of the order of @xmath1 are exponentially small .",
    "if the parameter @xmath70 is an integer of the order of unity , the distribution function @xmath66 is a polynomial of degree @xmath88 . in particular , at @xmath89 , the function @xmath66 is constant , @xmath90 at @xmath91 @xmath66 has a maximum at the middle of the interval @xmath92 $ ] .      in this situation",
    ", @xmath66 assumes the maximal values at @xmath94 and @xmath95 , @xmath96 formula ( [ 20 ] ) describes the sharply decreasing @xmath66 as @xmath14 changes from @xmath29 to @xmath30 ( and from @xmath1 to @xmath97 ) .",
    "then , at @xmath98 , the function @xmath66 decreases more slowly with an increase in @xmath14 , @xmath99 at @xmath100 the probability @xmath66 achieves its minimal value , @xmath101    the values @xmath102 are nearly @xmath103 to a logarithmic accuracy .    the evolution of the distribution function @xmath104 from the gaussian form to the inverse one with a decrease of the parameter @xmath70 is shown in fig .  2 .",
    "below we restrict ourselves to the case of weak persistence , @xmath76 .    formulas ( [ 27 ] ) and ( [ 28 ] ) describe the statistical properties of @xmath2-words for the fixed  diffusion time",
    " @xmath63 .",
    "it is necessary to look into the distribution function @xmath42 for the general situation , @xmath105 .",
    "we start the analysis with @xmath106 .     for @xmath1=20 and different values of the parameter @xmath70 shown near the curves.,title=\"fig : \" ]        the distribution function @xmath42 at @xmath106 can be given as @xmath107 this equation follows from the consideration of @xmath1-words consisting of two parts , @xmath108 the total number of unities in this word is @xmath0 .",
    "the right - hand part of the word ( @xmath2-sub - word ) contains @xmath14 unities .",
    "the remaining @xmath109 unities are situated within the left - hand part of the word ( @xmath110-sub - word ) .",
    "the multiplier @xmath111 in eq .",
    "( [ 29 ] ) takes into account all possible permutations of the symbols  1  within the @xmath1-word on condition that the @xmath2-sub - word always contains @xmath14 unities .",
    "then we perform the summation over all possible values of the number @xmath0 .",
    "note that eq .",
    "( [ 29 ] ) is valid due to the main proposition @xmath52 formulated in subsec .",
    "c of the previous section .    in this subsection ,",
    "we focus our attention on the most important limiting case @xmath112 . the straightforward calculations with using the stirling formula give the result , @xmath113 with @xmath114    the last equation allows one to analyze the behavior of the variance @xmath5 with an increase in the `` diffusion time '' @xmath2 .",
    "at small @xmath115 the dependence @xmath5 follows the classical law of the brownian diffusion , @xmath116 .",
    "then , at @xmath117 , the function @xmath5 becomes super - linear and meets the value ( [ 28 ] ) at @xmath63 .",
    "such an unusual behavior of the variance @xmath5 raises an issue as to what particular type of the diffusion equation corresponds to the nonlinear dependence @xmath5 in eq .",
    "( [ 32 ] ) . in the following subsection , when solving this problem",
    ", we will obtain the conditional probability @xmath118 of occurring the symbol zero after a given @xmath2-word with @xmath106 . the ability to find @xmath118 , with some reduced information about preceding symbols being available ,",
    "is very important for the study of the self - similarity of the markov chain ( see subsubsec .  3 of this subsection ) .",
    "it is quite obvious that the distribution @xmath42 satisfies the equation @xmath119 here @xmath118 is the probability of occurring  0  after an average - statistical @xmath2-word containing @xmath14 unities and @xmath120 is the probability of occurring  1  after an @xmath2-word containing @xmath121 unities . at @xmath106 ,",
    "the probability @xmath118 can be written as @xmath122 the product @xmath123 in this formula represents the conditional probability of occurring the @xmath1-word containing @xmath0 unities , the right - hand part of which , the @xmath2-sub - word , contains @xmath14 unities ( compare with eqs .",
    "( [ 29 ] ) , ( [ 29b ] ) ) .",
    "the product @xmath124 in eq .",
    "( [ 34 ] ) is a sharp function of @xmath0 with a maximum at some point @xmath125 whereas @xmath126 obeys linear law ( [ 14 ] ) .",
    "this implies that @xmath126 can be factored out of the summation sign being taken at point @xmath125 .",
    "the asymptotical calculation shows that point @xmath127 is described by the equation , @xmath128 expression ( [ 14 ] ) taken at point @xmath129 gives the desired formula for @xmath118 because @xmath130 is obviously equal to @xmath131 .",
    "thus , we have @xmath132    let us consider a very important fact following from eq .",
    "( [ 35 ] ) .",
    "if the concentration of unities in the right - hand part of the word ( [ 29b ] ) is higher than @xmath103 , @xmath133 , then the most probable concentration @xmath134 of unities in the left - hand part of this word is likewise increased , @xmath135 . at the same time , the concentration @xmath134 is less than @xmath136 , @xmath137 this means that the increased concentration of unities in the @xmath2-words is necessarily accompanied by the existence of a certain tail with an increased concentration of unities as well .",
    "we name such a phenomenon as the _ macro - persistence_. an analysis performed in the next section will indicate that the correlation length @xmath138 of this tail is @xmath139 with @xmath140 dependent on the parameter @xmath3 only .",
    "it is evident from the above - mentioned property of the isotropy of the markov chain that there are two correlation tails from the both sides of the @xmath2-word .    by going over to the continuous limit in eq .",
    "( [ 33 ] ) and using eq .",
    "( [ 36 ] ) and the relation @xmath141 , we obtain the diffusion equation generalized to the case of the correlated markov process , @xmath142 with @xmath143 and @xmath144 equation ( [ 39 ] ) has a solution of the gaussian form eq .",
    "( [ 31 ] ) with the variance @xmath5 satisfying the ordinary differential equation , @xmath145 its solution with the boundary condition @xmath146 coincides with ( [ 32 ] ) .      in this subsection",
    "we point out one of the most important properties of the markov chain being considered , namely , its self - similarity .",
    "let us reduce the @xmath1-step markov sequence by regularly ( or randomly ) removing some symbols and introduce the decimation parameter @xmath147 , @xmath148 here @xmath149 is a renormalized memory length for the reduced @xmath149-step markov chain . according to eq .",
    "( [ 36 ] ) , the conditional probability @xmath150 of occurring the symbol zero after @xmath14 unities among the preceding @xmath149 symbols is described by the formula , @xmath151 with @xmath152 the comparison of eqs .",
    "( [ 14 ] ) and ( [ 42 ] ) shows that the reduced chain possesses the same statistical properties as the initial one but is characterized by the renormalized parameters ( @xmath149 , @xmath153 ) instead of ( @xmath1 , @xmath34 ) .",
    "thus , eqs .",
    "( [ 41 ] ) and ( [ 43 ] ) determine the one - parametrical renormalization of the parameters of the stochastic process defined by eq .",
    "( [ 14 ] ) .",
    "the astonishing property of the reduced sequence consists in that _ the variance @xmath154 is invariant with respect to the one - parametric decimation transformation ( [ 41 ] ) , ( [ 43])_. therefore , it coincides with the function @xmath5 for the initial markov chain : @xmath155 the invariance of the function @xmath5 at @xmath106 was referred by us to as the phenomenon of self - similarity .",
    "it is demonstrated in fig .  3 and is also discussed in sec .",
    "iv a.     on the tuple length @xmath2 for the generated sequence with @xmath156 and @xmath58 ( solid line ) and for the decimated sequences ( the parameter of decimation @xmath157 ) .",
    "squares and circles correspond to the stochastic and deterministic reduction , respectively .",
    "the thin solid line describes the non - correlated brownian diffusion , @xmath158.,title=\"fig : \" ]      unfortunately , the very useful proposition @xmath52 is valid for the words of the length @xmath160 only and can not be applied to the analysis of the long words with @xmath159 .",
    "therefore , investigating the statistical properties of the long words represents a rather challenging combinatorial problem and requires new physical approaches for its simplification .",
    "thus , we start this subsection by analyzing the correlation properties of the long words .",
    "let us rewrite eq .",
    "( [ 14 ] ) in the form , @xmath161 the angle brackets denote the averaging of the density of unities in some region of the markov chain for its definite realization .",
    "the averaging is performed over distances much greater than unity but far less than the memory length @xmath1 .",
    "note that this averaging differs from the statistical averaging over the ensemble of realizations of the markov chain denoted by the bar in eqs .",
    "( [ 7 ] ) and ( [ 8 ] ) . equation ( [ 46 ] ) is a relationship between the average densities of unities in two different macroscopic regions of the markov chain , namely , in the vicinity of @xmath162-th element and in the region @xmath163 .",
    "such an approach is similar to the mean field approximation in the theory of the phase transitions and is asymptotically exact under the condition @xmath164 . in the continuous limit , eq .",
    "( [ 46 ] ) can be rewritten in the integral form , @xmath165 it has the obvious solution , @xmath166 where @xmath167 is determined by the relation , @xmath168 the last equation has a unique solution @xmath169 for any value of @xmath170 .    formula ( [ 49 ] ) shows that any fluctuation ( the difference between @xmath171 and the equilibrium value of @xmath172 ) is exponentially damped at distances of the order of the _ correlation length _",
    "@xmath138 , @xmath173 law ( [ 49 ] ) describes the phenomenon of the _ persistent macroscopic correlations _ discussed in the previous subsection .",
    "this phenomenon is governed by both of the parameters , the memory length @xmath1 and the persistence parameter @xmath3 .",
    "according to eqs .",
    "( [ 50 ] ) , ( [ 50b ] ) , the correlation length @xmath138 goes logarithmically to infinity with an increase in @xmath3 , at @xmath174 . at @xmath77 ,",
    "the macro - persistence is broken and the correlation length tends to zero .      using the already studied correlation properties of the the markov sequence and some heuristic reasons ,",
    "one can obtain the correlation function @xmath175 , @xmath176 and then the variance @xmath5 , @xmath177 comparing eqs .",
    "( [ 51 ] ) and ( [ 51b ] ) and taking into account the unbiased property of the sequence , @xmath178 , it is easy to derive the general relationship between the functions @xmath175 and @xmath5 , @xmath179 considering ( [ 51c ] ) as an equation with respect to @xmath180 , one can find its solution given as @xmath181 @xmath182 , \\quad r\\geq 3.\\ ] ] this solution has a very simple form in the continuous limit , @xmath183    equations  ( [ 51e ] ) and ( [ 32 ] ) give the correlation function at @xmath184 , @xmath185 or @xmath186 in the continuous approximation .",
    "the independence of the correlation function of @xmath187 at @xmath184 results from our choice of the conditional probability in the simplest form ( [ 14 ] ) . at @xmath188 , the function @xmath175 should decrease because of loss of the memory .",
    "therefore , based on eqs .",
    "( [ 49 ] ) and ( [ 50b ] ) , let us prolongate the correlator @xmath175 as the exponentially decreasing function at @xmath188 , @xmath189 correspondingly , the variance @xmath5 becomes @xmath190 with @xmath191 , \\",
    ", \\qquad l > n.}\\ ] ]    the plot of eq .",
    "( [ 56 ] ) for @xmath156 and @xmath58 is shown by the solid line in fig .",
    "4 . for comparison",
    ", the straight line in the figure corresponds to the dependence @xmath158 for the usual brownian diffusion without correlations ( for @xmath192 ) .",
    "it is clearly seen that the plot of variance ( [ 56 ] ) contains two qualitatively different portions .",
    "one of them , at @xmath193 , is the super - linear curve that moves away from the line @xmath194 with an increase of @xmath2 as a result of the persistence . for @xmath195 ,",
    "the plot @xmath5 achieves the linear asymptotics , @xmath196 this phenomenon can be explained as a result of the diffusion where each practically _ independent _ step @xmath197 of wandering represents a path traversed during the characteristic `` fluctuating time '' @xmath198 . since these steps of wandering are quasi - independent , the distribution function @xmath131 is the gaussian not only at @xmath106 ( see eq .",
    "( [ 31 ] ) ) but also in the case @xmath199 .     for the generated sequence with @xmath156 and @xmath58 ( circles ) .",
    "the solid line is the plot of function eq .",
    "( 55 ) with the same values of @xmath1 and @xmath3.,title=\"fig : \" ]    note that the above - mentioned phenomenon of the self - similarity relates only to the portion @xmath106 of the curve @xmath5 .",
    "since the decimation procedure leads to the decrease of the parameter @xmath3 ( see eq .",
    "( [ 43 ] ) ) , the plot of asymptotics ( [ 58 ] ) for the reduced sequence at @xmath200 goes below the plot for the initial chain .",
    "in this section , we support the obtained above analytical results by numerical simulations of the markov chain with the conditional probability eq .",
    "( [ 14 ] ) . besides",
    ", the properties of the studied binary @xmath1-step markov chain are compared with ones for the natural objects , specifically for the coarse - grained written and dna texts .",
    "the first stage of the construction of the @xmath1-step markov chain was a generation of the initial non - correlated @xmath1 symbols , zeros and unities , identically distributed with equal probabilities 1/2 .",
    "each consequent symbol was then added to the chain with the conditional probability determined by the previous @xmath1 symbols in accordance with eq .",
    "( [ 14 ] ) . than we numerically calculated the variance @xmath5 by means of eq .",
    "( [ 7 ] ) .",
    "the circles in fig .  4 represent the calculated variance @xmath5 for the 100-step markov chain generated at @xmath201 . a very good agreement between the analytical result in eq .",
    "( [ 56 ] ) and the numerical simulation can be observed .",
    "the numerical simulation was also used for the demonstration of the proposition @xmath52 ( fig .  1 ) and the self - similarity property of the markov sequence ( fig .  3 ) .",
    "the squares in fig .  3 represent the variance @xmath5 for the sequence obtained by the stochastic decimation of the initial markov chain ( solid line ) where each symbol was omitted with the probability 1/2 .",
    "the circles in this figure correspond to the regular reduction of the sequence by removing each second symbol .    and",
    "finally , the numerical simulations have allowed us to make sure that we are able to determine the parameters @xmath1 and @xmath3 of a given binary sequence .",
    "we generated markov sequences with different parameters @xmath1 and @xmath3 and defined numerically the corresponding curves @xmath5 .",
    "then we solved the inverse problem of the reconstruction of the parameters @xmath1 and @xmath3 by analyzing the curves @xmath5 .",
    "the reconstructed parameters were always in a good agreement with their prescribed values . in the next subsections",
    "we apply this ability to the treatment of the statistical properties of literary and dna texts .",
    "it is well - known that the statistical properties of the coarse - grained texts written in any language show a remarkable deviation from random sequences  @xcite . in order to check the applicability of the theory of the binary @xmath1-step markov chains to literary texts we resorted to the procedure of coarse graining by the random mapping of all characters of the text onto binary set of symbols , zeros and unities .",
    "the statistical properties of the coarse - grained texts depend , but not significantly , on the kind of mapping .",
    "this is illustrated by the curves in fig .",
    "5 where the variance @xmath5 for five different kinds of the mapping of bible is presented .",
    "usually , the random mapping leads to nonequal numbers of unities and zeros , @xmath202 and @xmath203 , in the coarse - grained sequence .",
    "the particular analysis shows that the variance @xmath5 ( [ 32 ] ) gets the additional multiplier , @xmath204 in this biased case . in order to derive the function @xmath5 for the non - biased sequence , we divided the numerically calculated value of the variance by this multiplier .     for the coarse - grained text of the bible obtained by means of five different kinds of random mapping.,title=\"fig : \" ]",
    "the study of different written texts has shown that all of them are featured by the pronounced persistent correlations .",
    "it is demonstrated by fig .",
    "6 where five variance curves go significantly higher than the straight line @xmath194 .",
    "however , it should be emphasized that regardless of the kind of mapping the initial portions , @xmath205 , of the curves correspond to a slight anti - persistent behavior ( see insert to fig .",
    "moreover , for some inappropriate kinds of mapping ( e.g. , when all vowels are mapped onto the same symbol ) the anti - persistent portions can reach the values of @xmath206 . in order to avoid this problem , all the curves in fig .",
    "6 are obtained for the definite representative mapping : ( a - m ) @xmath207 0 ; ( n - z ) @xmath207 1 .",
    "for the coarse - grained texts of collection of works on the computer science ( @xmath208 , solid line ) , bible in russian ( @xmath209 , dashed line ) , bible in english ( @xmath210 , dotted line ) , `` history of russians in the 20-th century '' by oleg platonov ( @xmath211 , dash - dotted line ) , and `` alice s adventures in wonderland '' by lewis carroll ( @xmath212 , dash - dot - dotted line).,title=\"fig : \" ]    thus , the persistence is the common property of the binary @xmath1-step markov chains and the coarse - grained written texts at large scales .",
    "moreover , the written texts as well as the markov sequences possess the property of the self - similarity . indeed",
    ", the curves in fig .  7 obtained from the text of bible with different levels of the deterministic decimation demonstrate the self - similarity . presumably , this property is the mathematical reflection of the well - known hierarchy in the linguistics : _",
    "letters @xmath207 syllables @xmath207 words @xmath207 sentences @xmath207 paragraphs @xmath207 chapters @xmath207 books @xmath213 collected works_.     on the tuple length @xmath2 for the coarse - grained text of bible ( solid line ) and for the decimated sequences with different parameters @xmath147 :",
    "@xmath214 ( squares ) , @xmath215 ( stars ) , and @xmath216 ( triangles ) .",
    "the insert demonstrate the anti - persistent portion of the @xmath5 plot for bible.,title=\"fig : \" ]    all the above - mentioned circumstances allow us to suppose that our theory of the binary @xmath1-step markov chains can be applied to the description of the statistical properties of the texts of natural languages . however , in contrast to the generated markov sequence ( see fig .",
    "4 ) where the full length @xmath217 of the chain is far greater than the memory length @xmath1 , the coarse - grained texts described by fig .  6 are of relatively short length @xmath218 . in other words ,",
    "the coarse - grained texts are similar not to the markov chains but rather to some non - stationary short fragments .",
    "this implies that each of the written texts is correlated throughout the whole of its length .",
    "therefore , for the written texts , it is impossible to observe the second portion of the curve @xmath5 parallel ( in the log - log scale ) to the line @xmath158 , similar to that shown in fig .  4 . as a result",
    ", one can not define the values of the both parameters @xmath1 and @xmath3 for the coarse - grained texts .",
    "the analysis of the curves in fig .",
    "6 can give the combination @xmath219 only ( see eq .",
    "( [ 32 ] ) ) . perhaps , this particular combination is the real parameter governing the persistent properties of the literary texts .",
    "we would like to note that the origin of the long - range correlations in the literary texts is hardly related to the grammatical rules as is claimed in ref .",
    "@xcite . at short scales",
    "@xmath220 where the grammatical rules are in fact applicable the character of correlations is anti - persistent whereas semantic correlations lead to the global persistent behavior of the variance @xmath5 throughout the whole of literary text .",
    "the numerical estimations of the persistent parameter @xmath221 and the characterization of the languages and different authors using this parameter can be regarded as a new intriguing problem of the linguistics .",
    "for instance , the unprecedented low value of @xmath221 for the very inventive work by lewis carroll as well as the closeness of @xmath221 for the texts of english and russian versions of bible are of certain interest .",
    "it should be noted that there exist special kinds of short - range correlated texts which can be specified by both of the parameters , @xmath1 and @xmath3 .",
    "for example , all dictionaries consist of the families of words where some preferable letters are repeated more frequently than in their other parts . yet another example of the shortly correlated texts is any lexicographically ordered list of words .",
    "the analysis of written texts of this kind is given below .",
    "as an example , we have investigated the statistical properties of the coarse - grained alphabetical list of the most frequently used 15462 english words . in contrast to other texts , the statistical properties of the coarse - grained dictionaries are very sensitive to the kind of mapping .",
    "if one uses the above - mentioned mapping , ( a - m ) @xmath207 0 ; ( n - z ) @xmath207 1 , the behavior of the variance @xmath5 similar to that shown in fig .",
    "6 would be obtained .",
    "the particular construction of the dictionary manifests itself if the preferable letters in the neighboring families of words are mapped onto the different symbols .",
    "the variance @xmath5 for the dictionary coarse - grained by means of such mapping is shown by circles in fig .",
    "it is clearly seen that the graph of the function @xmath5 consists of two portions similarly to the curve in fig .  4 obtained for the generated @xmath1-step markov sequence .",
    "the fitting of the curve in fig .  8 by the function ( [ 56 ] ) ( solid line in fig .",
    "8) yielded the values of the parameters @xmath222 and @xmath223 .",
    "the parameter @xmath224 given by eq .",
    "( [ 50 ] ) is around 3.9 .",
    "note that the characteristic fluctuation length @xmath225 for these @xmath1 and @xmath224 is nearly 900 .",
    "this value corresponds qualitatively to the length of the family of words in the dictionary .     for the coarse - grained alphabetical list of 15462 english words ( circles ) .",
    "the solid line is the plot of function eq .  (",
    "55 ) with the fitting parameters @xmath222 and @xmath226.,title=\"fig : \" ]      it is known that any dna text is written by four `` characters '' , specifically by adenine ( a ) , cytosine ( c ) , guanine ( g ) , and thymine ( t )",
    ". therefore , there are three nonequivalent types of the dna text mapping onto one - dimensional binary sequences of zeros and unities .",
    "the first of them is the so - called purine - pyrimidine rule , \\{a , g } @xmath207 0 , \\{c , t } @xmath207 1 .",
    "the second one is the hydrogen - bond rule , \\{a , t } @xmath207 0 , \\{c , g } @xmath207 1 . and ,",
    "finally , the third is \\{a , c } @xmath207 0 , \\{g , t } @xmath207 1 .     for the coarse - grained dna text of _ bacillus subtilis , complete genome _ , for three nonequivalent kinds of the mapping .",
    "solid , dashed , and dash - dotted lines correspond to the mappings \\{a , g } @xmath207 0 , \\{c , t } @xmath207 1 ( the parameter @xmath227 ) , \\{a , t } @xmath207 0 , \\{c , g } @xmath207 1 ( @xmath228 ) , and \\{a , c } @xmath207 0 , \\{g , t } @xmath207 1 ( @xmath229 ) , respectively.,title=\"fig : \" ]    by way of example , the variance @xmath5 for the coarse - grained text of _ bacillus subtilis , complete genome _ ( ftp:@xmath230ftp.ncbi.nih.gov@xmath231genomes@xmath231bacteria@xmath231bacillus_subtilis@xmath231nc_000964.gbk )",
    "is displayed in fig .",
    "9 for all possible types of mapping .",
    "one can see that the persistent properties of dna are more pronounced than for the written texts and , contrary to the written texts , the @xmath5 dependence for dna does not exhibit the anti - persistent behavior at small values of @xmath2 .",
    "however , as well as for the written texts , the @xmath5 curve for dna does not contain the linear portion given by eq .",
    "( [ 58 ] ) .",
    "this suggests that the dna chain is not a stationary sequence . in this connection",
    ", we would like to point out that the dna texts represent the collection of extended non - coding regions interrupted by small coding regions ( see , for example ,  @xcite ) . according to fig .",
    "9 , the coding regions do not interrupt the correlation between the non - coding areas , and the dna system is fully correlated throughout its whole length .    the noticeable deviation of different curves in fig .",
    "9 from each other demonstrate , in our opinion , that the dna texts are much more complex objects in comparison with the written ones .",
    "indeed , the different kinds of mapping reveal and emphasize various types of physical attractive correlations between the nucleotides in dna , such as the strong purine - purine and pyrimidine - pyrimidine persistent correlations ( the upper curve ) , and the correlations caused by a weaker attraction a@xmath232 t and c@xmath232 g ( the middle curve ) .",
    "thus , we have developed a new approach for the description of the strongly correlated one - dimensional systems .",
    "the simple exactly solvable model of the uniform binary @xmath1-step markov chain is presented .",
    "the memory length @xmath1 and the parameter @xmath3 of the persistent correlations are two parameters in our theory .",
    "usually , the correlation function @xmath175 is employed as the input characteristics for the description of the correlated random systems . yet",
    ", the function @xmath175 describes not only the direct interconnection of the elements @xmath65 and @xmath233 , but also takes into account their indirect interaction via other elements .",
    "since our approach operates with the `` origin '' parameters @xmath1 and @xmath3 , we believe that it allows us to disclose the intrinsic properties of the system which provide the correlations between the elements .",
    "we have demonstrated the applicability of the suggested theory to the different kinds of correlated stochastic systems .",
    "however , there exist some aspects which can not be interpreted in terms of our two - parameter model .",
    "obviously , more complex models should be developed for the adequate description of real correlated systems .",
    "we acknowledge to dr .",
    "s.v . denisov who drew our attention to the exposed problem , yu.l .",
    "rybalko for consultations and kind assistance in the numerical simulations , s.s . melnik and m.e .",
    "serbin for the helpful discussions ."
  ],
  "abstract_text": [
    "<S> a theory of systems with long - range correlations based on the consideration of _ binary n - step markov chains _ is developed . in our model , </S>",
    "<S> the conditional probability that the @xmath0-th symbol in the chain equals zero ( or unity ) is a linear function of the number of unities among the preceding @xmath1 symbols . </S>",
    "<S> the model allows exact analytical treatment . </S>",
    "<S> the correlation and distribution functions as well as the variance of number of symbols in the words of arbitrary length @xmath2 are obtained analytically and numerically . </S>",
    "<S> a self - similarity of the studied stochastic process is revealed and the similarity transformation of the chain parameters is presented . the diffusion equation governing the distribution function of the @xmath2-words is explored . </S>",
    "<S> if the persistent correlations are not extremely strong , the distribution function is shown to be the gaussian with the variance being nonlinearly dependent on @xmath2 . </S>",
    "<S> the applicability of the developed theory to the coarse - grained written and dna texts is discussed . </S>"
  ]
}