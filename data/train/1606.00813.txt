{
  "article_text": [
    "most standard graphical models are restricted to pairwise dependencies between variables .",
    "for example , the ising model for binary data and the multivariate gaussian for real - valued data are popular pairwise graphical models .",
    "however , real - world data often exhibits triple - wise , or more generally @xmath0-wise dependencies .",
    "for example , the words _ deep _ , _ neural _ and _ network _ often occur together in recent research papers  note that this _",
    "triple _ of words refers to something more specific than any of the two words without the third word , i.e. if a document only contains _ neural _ and _ network _ but not _ deep _ , then this may be a more classical paper about shallow neural networks . in the biological domain ,",
    "genetic , metabolic and protein pathways play an important role in studying the development of diseases and possible interventions .",
    "these pathways are known to be complex and involve many genes or proteins rather than just simple pairwise interactions .",
    "thus , we seek to begin bridging this gap between pairwise models and complex real - world data that contain complex @xmath0-wise interactions by defining a class of @xmath0-wise graphical models called generalized root models ( grm ) , which can be instantiated for any @xmath4 and any univariate exponential family with positive sufficient statistics including the gaussian ( using the @xmath5 sufficient statistic ) , poisson and exponential distributions .",
    "we estimate the graphical model structure and parameters using @xmath3-regularized node - wise regressions similar to previous work @xcite .",
    "however , unlike previous work , because the log partition function of the grm node conditionals is not known in closed - form  even for the previous work considering the pairwise case@xcite  we develop a novel numerical approximation method for the grm log partition function and related derivatives .",
    "in addition , we present a newton - like optimization algorithm similar to @xcite to solve the node - regressions  which significantly reduces the number of numerical log partition function approximations needed compared to gradient descent .",
    "finally , we demonstrate the grm model and parameter estimation algorithm on real - world text data .",
    "this paper generalizes the square root graphical model ( sqr ) from @xcite , which only considers pairwise dependencies .",
    "@xcite followed the idea of constructing a joint distribution by defining the form of the node - conditional distributions as in @xcite but introduced the idea of taking the square root of the sufficient statistics @xmath6 to form a pairwise term @xmath7 which is linear @xmath8 rather than the pairwise term @xmath9 in @xcite which is quadratic @xmath10 .",
    "this elegant modification allowed for arbitrary _ positive _ and _ negative _ dependencies in the poisson sqr graphical model whereas the poisson graphical model in @xcite only permitted negative dependencies  a crucial limitation of the poisson models from @xcite .",
    "while @xcite proposed three modifications to the original poisson models as defined in @xcite , the modifications lead to distributions with either gaussian - esque thin tails or truncated distributions which required unintuitive cutoff points where the probability mas may concentrate near the corners of the distribution @xcite .",
    "though sqr models have great promise , sqr models are limited to pairwise dependencies , and @xcite did not provide an estimation algorithm for the poisson sqr model because the node conditional log partition function is not known in closed form .",
    "thus , this paper extends the sqr model class to include @xmath0-wise interactions where @xmath11 and , in addition , instantiates a concrete approximation algorithm for the node conditional log partition function and associated derivatives .    in a somewhat different direction , latent variable models",
    "provide an implicit and indirect way of modeling complex dependencies . generally ,",
    "though the explicit dependencies in latent variable models are only pairwise , many variables can be related implicitly through a latent variable .",
    "for example , mixture models associate a discrete latent variable with every instance which implicitly introduces dependencies .",
    "other more complex latent variable models such as topic models @xcite can introduce even more implicit dependencies in interesting ways . while latent variable models have proven to be practically effective in helping to model complex dependencies , the development of grm models in this paper is distinctive and somewhat orthogonal to latent variable models .",
    "as opposed to implicitly modeling dependencies through latent variables , the grm model explicitly models dependencies between observed variables .",
    "thus , the discovered dependencies have an intuitive and obvious explanation in terms of the observed data variables . in addition",
    ", grm models can be seen as complementary to latent variable models because grm models can be used as base distributions for these latent variable models .",
    "for example , @xcite explore using count - valued graphical models in mixtures and topic models .",
    "thus , grms can provide new components from which to build more interesting models for real - world situations .",
    "finally , node - conditional models such as grm can be estimated using convex optimization problems , which often have theoretical guarantees @xcite whereas latent variable models often require optimizing a non - convex function and struggle with theoretical guarantees .",
    "[ [ notation ] ] notation + + + + + + + +    let @xmath12 and @xmath13 be the number of dimensions and data instances respectively .",
    "let @xmath14 denote the set of nonnegative real numbers and @xmath15 denote the set of nonnegative integers . unless indicated otherwise",
    ", we denote vectors with boldface lower case letters ( e.g. @xmath16 , @xmath17 ) and their corresponding scalar values as normal lower case letters ( e.g. @xmath18 , @xmath19 ) .",
    "we denote the standard basis vectors as @xmath20^t$ ] and the ones vector as @xmath21^t$ ] .",
    "let @xmath22 and @xmath23{\\bm{x}}$ ] to be the entry - wise power and @xmath24-th root of the vector @xmath25 .",
    "we denote tensors ( or multidimensional arrays ) with parenthesized superscripts as @xmath26 where @xmath0 is the order of the tensor .",
    "for example , @xmath27 is a matrix , @xmath28 is a three dimensional tensor , and @xmath29 is a @xmath0-th order tensor .",
    "we index tensors using brackets and subscripts , e.g. @xmath30_{1,2,3}$ ] is a scalar value in the multidimensional array at index @xmath31 .",
    "we define @xmath32_{\\vi } \\in \\r^{\\vmax \\times^{\\ell-1}}$ ] to be a sub tensor created by fixing the last index to @xmath33 and letting the others vary  in matlab colon indexing notation , this would be @xmath34 .",
    "for example , if @xmath35 , then @xmath30_{\\vi } \\in \\r^{\\vmax \\times \\vmax}$ ] is a matrix corresponding to the @xmath33-th slice of the tensor @xmath36 .",
    "we define @xmath37 to be the outer product operation . for example , @xmath38 and @xmath39 , where @xmath40_{\\vi_1\\vi_2\\vi_3 } = \\x_{\\vi_1}\\x_{\\vi_2}\\x_{\\vi_3}$ ] . for more general sizes ,",
    "we denote a @xmath0-th outer product to be @xmath41 such that there are @xmath0 copies of @xmath16 and the result is a @xmath0-th order tensor . we define @xmath42^t$ ] .",
    "we also denote the inner product operation of two tensors as @xmath43 .",
    "with the notation given in the previous section , we will define the grm model .",
    "first , let the sufficient statistic and log base measure of a univariate exponential family be denoted as @xmath6 and @xmath44 respectively .",
    "we will also define the domain ( or support ) of the random variable to be @xmath45 and it s corresponding measure to be @xmath46 , which is either the counting measure or lebesgue measure depending on whether @xmath47 is discrete or continuous .",
    "let us denote a new @xmath24-th root sufficient statistic @xmath48{\\t(\\x)}$ ] except in the case when @xmath49 where @xmath50 is an even positive integer .",
    "if @xmath49 , then we simplify @xmath51 ( rather than the usual @xmath52 ) .",
    "for example , if @xmath53 , then @xmath54 ( rather than @xmath55 ) . as in @xcite ,",
    "this nuanced definition is necessary to recover the multivariate gaussian distribution .",
    "however , for notational simplicity , we will merely write @xmath23{\\x}$ ] for @xmath56 throughout the paper .",
    "note that @xmath57{\\x}$ ] for the poisson and exponential grm models . using this simplified notation",
    ", we can define the generalized root model for @xmath58 as : @xmath59{\\xvec } \\ , \\circ^{\\ell } \\right\\rangle + \\textstyle{\\sum_{\\vi } } \\b(\\x_\\vi ) - \\a(\\multipall ) \\right ) \\label{eqn : full - model } \\\\ \\a(\\multipall ) & = \\log \\int_\\domain \\exp\\left ( \\sum_{\\j=1}^\\k \\sum_{\\ell=1}^\\j \\left\\langle \\multip^{(\\ell)}_{(\\j ) } , \\sqrt[\\j]{\\xvec } \\ , \\circ^{\\ell } \\right\\rangle + \\textstyle{\\sum_{\\vi } } \\b(\\x_\\vi ) \\right ) \\mathrm{d}\\mu(\\xvec ) \\ , , \\label{eqn : full - model - a}\\end{aligned}\\ ] ] where @xmath60 is the joint log partition function , @xmath61 , @xmath62 are super symmetric tensors of order @xmath63 which are zero whenever two indices are the same . more formally , letting @xmath64 be an index permutation : @xmath65_{\\vi_1,\\cdots,\\vi_\\ell } & = [ a^{(\\ell)}]_{\\pi(\\vi_1,\\cdots,\\vi_\\ell ) } & \\forall \\pi(\\cdot ) ,",
    "\\\\ \\left[a^{(\\ell)}\\right]_{\\pi(\\vi_u,\\vi_v,\\cdots,\\vi_\\ell ) } & = 0 & \\forall \\{(u , v , \\pi(\\cdot ) ) : u \\neq v , \\vi_u = \\vi_v \\ } \\end{array } \\right\\ } \\ , .",
    "\\label{eqn : parameter - constraints}\\end{aligned}\\ ] ] note that the non - zeros of @xmath62 define @xmath63-sized variable sets ( or cliques ) of the underlying graphical model .",
    "we now consider several special cases of this model to build some understanding of the grms connection to previous models .",
    "the independent model is trivially recovered if @xmath66 : @xmath67 .    [",
    "[ square - root - graphical - model ] ] square root graphical model @xcite + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    another special case is the previous sqr models ( i.e. @xmath2 ) from @xcite by taking ( using the notation from @xcite ) @xmath68 , @xmath69 and @xmath70 , where @xmath71 is a column vector of the diagonal entries and @xmath72 has the same off - diagonal entries as @xmath73 but is zero along the diagonal .",
    "thus , the sqr model can be written as : @xmath74{\\xvec } \\rangle + \\langle \\multip^{(2)}_{(2 ) } , \\sqrt[2]{\\xvec } \\circ \\sqrt[2]{\\xvec } \\rangle + \\textstyle{\\sum_{\\vi } } \\b(\\x_\\vi ) - \\a ( \\multipall ) \\right ) \\ , .\\end{aligned}\\ ] ]    [ [ simplified - model - with - only - strongest - interaction - terms ] ] simplified model with only strongest interaction terms + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we consider another special case such that only the strongest interaction ( i.e. when @xmath75 ) terms are non - zero : @xmath76{\\xvec } \\,\\circ^\\j \\rangle   \\,+ \\ , \\textstyle{\\sum_{\\vi } } \\b(\\x_\\vi ) - \\a ( \\multipall ) \\right ) \\ , .",
    "\\label{eqn : simplified - model}\\end{aligned}\\ ] ] this restricted parameter space forces @xmath24-wise dependencies to only be through the @xmath24-th root term .",
    "for example , pairwise interactions are only available through the sufficient statistic @xmath77{\\x_\\vi\\x_\\vit}$ ] and ternary interactions are only available through the sufficient statistic @xmath78{\\x_\\vi\\x_\\vit\\x_\\vir}$ ] . without this restriction interactions would be allowed through multiple terms , e.g. pairwise interactions would be allowed through multiple sufficient statistics @xmath77{\\x_\\vi\\x_\\vit } , \\sqrt[3]{\\x_\\vi\\x_\\vit},\\cdots,\\sqrt[\\k]{\\x_\\vi\\x_\\vit}$ ] .",
    "thus , this simplified model is more interpretable and easier to learn while still retaining the strongest @xmath24-wise interaction terms . for our experiments ,",
    "we assume this simplified model unless specified otherwise .      as in @xcite",
    ", we derive both the _ node _ conditionals and the _ radial _ conditional distributions .",
    "an illustration of these two types of univariate conditional distributions can be seen in fig .",
    "[ fig : conditional - illustration ] . this _",
    "conditional distribution is critical for the parameter estimation that will be described in later sections ; whereas the _ radial _ conditional distributions are critical for showing the normalization of grm models .",
    "the node conditionals are as follows ( see appendix for full derivation ) : @xmath79 where @xmath80 is all other variables except @xmath18 , @xmath81_{\\vi } , \\ell \\sqrt[\\j]{\\xvec } \\,\\circ^{\\ell-1 } \\right\\rangle$ ] .",
    "this is a univariate exponential family with sufficient statistics @xmath82 , natural parameters @xmath83 and base measure @xmath84 .",
    "note that this reduces to the original exponential family if the interaction terms @xmath85 .      as in @xcite , we define the _ radial _ conditional distribution by fixing the unit direction @xmath86 of the sufficient statistics but allowing the scaling @xmath87 to be unknown . thus , we get the following _ radial _ conditional distribution ( see appendix for derivation ) : @xmath88 where @xmath89 is the set of possible ratios , @xmath90{\\uvec } \\ , \\circ^{\\ell } \\rangle$ ] are the exponential family parameters , @xmath91 are the corresponding sufficient statistics and @xmath92 is the base measure . thus , the radial conditional distribution is a univariate exponential family ( as in @xcite )",
    ".      the previous exponential and poisson graphical models @xcite could only model negative dependencies . however , we generalize the results from the pairwise sqr model in @xcite and show that grm normalization for any @xmath0 puts little to no restriction on the value of the parameters  thus allowing both positive and negative dependencies . for our derivations",
    ", let @xmath93 be the set of unit vectors in the positive orthant .",
    "the grm log partition function @xmath60 can be decomposed into nested integrals over the unit direction and over the scaling @xmath94 : @xmath95{\\radx\\uvec } \\ , \\circ^{\\ell } \\right\\rangle + \\textstyle{\\sum_{\\vi } } \\b(\\radx\\usca_\\vi ) \\right ) \\mathrm{d}\\measure(\\radx ) \\ , \\mathrm{d}\\uvec \\notag \\\\ & = \\log \\!\\ ! \\int\\limits_\\uset \\!\\ !",
    "\\int\\limits_{\\radset(\\uvec ) } \\!\\!\\!\\ ! \\exp\\left ( \\sum_{r\\in\\mathcal{r } } \\natp_r(\\uvec ) \\radx^r + \\tilde{\\b}_{\\uvec}(\\radx ) \\right ) \\mathrm{d}\\measure(\\radx ) \\ , \\mathrm{d}\\uvec\\end{aligned}\\ ] ] where @xmath96 , and @xmath97 and @xmath45 are the measure and domain ( or support ) of the random variable .",
    "because @xmath98 is bounded , the joint distribution will be normalizable if the radial conditional distribution is normalizable  generalizing the results from @xcite for @xmath11 .",
    "informally , the radial conditional distribution converges if the asymptotically largest term of @xmath99 is monotonically decreasing at least linearly .",
    "we give several examples in the following paragraphs .",
    "[ [ gaussian - grm ] ] gaussian grm + + + + + + + + + + + +    for the gaussian grm , we take the gaussian univariate distribution with sufficient statistic @xmath53 and @xmath100 . when @xmath101 ( i.e. the standard multivariate gaussian ) , the largest radial conditional term is @xmath102 where @xmath103 .",
    "note that the radial conditional ( i.e. a univariate gaussian ) is normalizable only if @xmath104 for all @xmath105 , which is equivalent to the positive definite condition on the gaussian inverse covariance matrix . we can also consider a gaussian - like model with @xmath106 . in this case",
    ", we have that @xmath107 and we need @xmath108 .",
    "note that the gaussian grm models for @xmath11 are novel models to the authors best knowledge .",
    "[ [ exponential - grm ] ] exponential grm + + + + + + + + + + + + + + +    because the exponential distribution also has a constant base measure like the gaussian , the asymptotically largest term is @xmath109 and thus we must have that @xmath108 . however , unlike the gaussian , in the case of the exponential distribution @xmath98 is only positive @xmath3-normalized vectors .",
    "this is a significantly weaker condition on the parameters than for a gaussian and allows strong positive and negative dependencies .",
    "[ [ poisson - grm ] ] poisson grm + + + + + + + + + + +    for the poisson distribution , the base measure is the asymptotically largest term @xmath110 .",
    "thus , as in @xcite , the parameters can be arbitrarily positive or negative because eventually the base measure will ensure normalizability .",
    "note that this is true for arbitrarily large @xmath0 .",
    "as in @xcite , we solve a set of independent @xmath3-regularized node - wise regressions for each node  based on the node conditional distributions in sec .  [",
    "sec : node - conditionals]using a newton - like method for convex optimization with an non - smooth @xmath3 penalty as in @xcite .",
    "more specifically we take the log likelihood of the node conditionals and add an @xmath3 penalty on all interaction terms : @xmath111 where @xmath112_{\\vi } , \\ell \\sqrt[\\j]{\\xvec_\\ii } \\,\\circ^{\\ell-1 } \\right\\rangle$ ] and @xmath113 is an entry - wise sum of absolute values .",
    "note that this is trivially decomposable into @xmath12 subproblems and can thus be trivially parallelized to improve computation speed .",
    "we use the newton - like method as in @xcite to greatly reduce computation .",
    "the initial innovation from @xcite was that the hessian only needed to be computed over a _",
    "free _ set of variables each newton iteration because of the @xmath3 regularization which suggested sparsity of the parameters .",
    "yet , the number of newton iterations was very small compared to gradient descent . in the case of grm models , whose bottleneck is the computation of the gradient of @xmath114 ( at least under our current implementation though it might be possible to significantly reduce this bottleneck ) , this newton - like method provides even more benefit because the gradient only has to be computed a small number of times ( roughly 30 ) in our case rather than the several thousand times that would be needed for running thousands of proximal gradient descent steps for the same level of convergence .    in the next section",
    ", we derive the gradient and hessian for the smooth part of the optimization as a function of the gradient and hessian of the node conditional log partition function @xmath115 .",
    "then , we develop a general method for bounding the log partition function @xmath115 and associated derivatives even though usually no closed - form exists .",
    "[ [ notation - for - gradient - and - hessian ] ] notation for gradient and hessian + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath116 be the vectorized form of a tensor .",
    "for example , the vectorized form of a @xmath117 matrix is formed by stacking the matrix columns on top of each other to form one long @xmath118 vector .",
    "also , let @xmath119 $ ] be analogous to the normal set notation @xmath120 except that the bracket and vertical line notation creates a vector from all the elements concatenated to together .",
    "this is similar to a list comprehension in python . for our gradient and hessian calculations ,",
    "we define the following variable transformations and give them as examples of this notation :    @xmath121_{\\vi } \\right ) \\midgiven \\ell \\leq \\j \\right ] : \\j \\in \\{1,2,\\cdots,\\k\\}\\big\\ } \\\\ & = \\bigg\\ { \\underbrace{\\left[\\vectorize\\left ( \\left[\\multip^{(1)}_{(1)}\\right]_{\\vi } \\right)\\right]}_{\\regpvec_{1\\vi } } , \\underbrace{\\left[\\vectorize\\left ( \\left[\\multip^{(1)}_{(2)}\\right]_{\\vi } \\right ) , \\vectorize\\left ( \\left[\\multip^{(2)}_{(2)}\\right]_{\\vi } \\right)\\right]}_{\\regpvec_{2\\vi } } , \\underbrace{\\left[\\vectorize\\left ( \\left[\\multip^{(1)}_{(3)}\\right]_{\\vi } \\right ) , \\cdots\\right]}_{\\regpvec_{3\\vi } } , \\cdots , \\underbrace{\\left [ \\cdots , \\vectorize\\left ( \\left[\\multip^{(\\k)}_{(\\k)}\\right]_{\\vi } \\right)\\right]}_{\\regpvec_{\\k\\vi } } \\bigg\\ } , \\\\ { \\mathcal{z}}_{\\vi\\ii } & = \\big\\ { \\left [ \\vectorize\\left ( \\ell \\sqrt[\\j]{\\xvec_{\\vi\\ii } } \\ , \\circ^{\\ell-1 } \\right ) \\midgiven \\ell \\leq \\j \\right ] : \\j \\in \\{1,2,\\cdots,\\k\\}\\big\\ } \\\\ & = \\bigg\\ { \\underbrace{\\left[\\vectorize\\left ( \\sqrt[1]{\\xvec_{\\ii } } \\ , \\circ^{0 } \\right)\\right]}_{\\zvec_{1\\vi } } , \\underbrace{\\left[\\vectorize\\left ( \\sqrt[2]{\\xvec_{\\ii } } \\ , \\circ^{0 } \\right ) , \\vectorize\\left ( 2\\sqrt[2]{\\xvec_{\\ii } } \\ , \\circ^{1 } \\right)\\right]}_{\\zvec_{2\\vi } } , \\underbrace{\\left[\\vectorize\\left ( \\sqrt[3]{\\xvec_{\\ii } } \\ , \\circ^{0 } \\right ) , \\cdots\\right]}_{\\zvec_{3\\vi } } , \\cdots , \\underbrace{\\left [ \\cdots , \\vectorize\\left ( \\k \\sqrt[\\k]{\\xvec_{\\ii } } \\ , \\circ^{\\k-1 } \\right)\\right]}_{\\zvec_{\\k\\vi } } \\bigg\\ } \\ , .\\end{aligned}\\ ] ]    with this notation , we have that @xmath122 . because each node regression is independent ,",
    "we focus on solving one of the @xmath12 subproblems for a particular @xmath33 using the notation from above : @xmath123 where @xmath124{\\x_{\\vi\\ii } } + \\a([\\regp_{\\j\\vi}^t \\zvec_{\\j\\vi\\ii } \\given \\j \\in \\{1,\\cdots,\\k\\})$ ] . for notational simplicity ,",
    "we suppress the dependence on @xmath33 and @xmath125 in the derivations of the gradient and hessian of @xmath126 ( the gradient and hessian are merely the sum over all instances ) . with this simplified notation ,",
    "the gradient and hessian are as follows ( as functions of @xmath114 , @xmath127 and @xmath128 ) : @xmath129{\\x } + \\frac{\\partial \\a}{\\partial \\natp_{\\j } } \\right)\\zvec_\\j \\midgiven \\j \\in \\{1,2,\\cdots,\\k \\ } \\right ] \\",
    "\\nabla^2 f({\\mathcal{b}}\\given \\x , { \\mathcal{z } } ) & = \\left [ \\begin{array}{l } \\left[\\frac{\\partial^2 \\a}{\\partial \\natp_1 \\partial\\natp_\\j } \\zvec_\\j \\circ \\zvec_1 \\midgiven \\j \\in \\{1,2,\\cdots,\\k\\ } \\right ] , \\vspace{0.5em } \\\\",
    "\\left[\\frac{\\partial^2 \\a}{\\partial \\natp_2 \\partial\\natp_\\j } \\zvec_\\j \\circ \\zvec_2 \\midgiven \\j \\in \\{1,2,\\cdots,\\k\\}\\right ] , \\\\",
    "\\hspace{5em } \\vdots \\\\",
    "\\left[\\frac{\\partial^2 \\a}{\\partial \\natp_\\k \\partial\\natp_\\j } \\zvec_\\j \\circ \\zvec_\\k \\midgiven \\j \\in \\{1,2,\\cdots,\\k\\}\\right ] \\end{array } \\right ] \\ , .\\end{aligned}\\ ] ] note how the gradient and hessian are simple functions of @xmath130 and the derivatives of @xmath115 .",
    "thus , we develop bounded approximations for @xmath115 , @xmath131 and @xmath132 next .",
    "because the node conditional distributions are not standard distributions , we must either derive the closed - form log partition function as done with the specific case of the exponential sqr model in @xcite , or we must numerically approximate the log partition function and its first and second derivatives . to the authors best knowledge , even for the simplified sqr model with @xmath2 , no closed - form solution to log partition function exists for sqr node conditionals except for the discrete , gaussian and exponential sqr models .",
    "thus , we seek a general way to estimate the log partition function and associated derivatives for any univariate exponential family ; we also provide a concrete realization of this approximation method for the poisson grm case .",
    "[ [ derivatives - of - anatpvec - reformulated - as - expectations ] ] derivatives of @xmath115 reformulated as expectations + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we first note that the gradient and hessian of @xmath115 are merely functions of particular expectations  a well - known result of exponential families : @xmath133 \\\\",
    "\\nabla^2 \\a(\\natpvec ) & = \\left [   \\begin{array}{c } \\left [ \\e(\\x^{\\frac{1}{\\j}+\\frac{1}{2 } } ) - \\e(\\x^{\\frac{1}{\\j}})\\e(\\x ) \\given \\j \\in \\{1,\\cdots,\\k\\ } \\right ] \\\\",
    "\\left [ \\e(\\x^{\\frac{1}{\\j}+\\frac{1}{2 } } ) - \\e(\\x^{\\frac{1}{\\j}})\\e(\\x^{\\frac{1}{2 } } ) \\given \\j \\in \\{1,\\cdots,\\k\\ } \\right ] \\\\",
    "\\hspace{3em } \\vdots \\\\ \\left [ \\e(\\x^{\\frac{1}{\\j}+\\frac{1}{\\k } } ) - \\e(\\x^{\\frac{1}{\\j}})\\e(\\x^{\\frac{1}{\\k } } ) \\given \\j \\in \\{1,\\cdots,\\k\\ } \\right ] \\\\",
    "\\end{array } \\right ] \\ , .\\end{aligned}\\ ] ] thus , we need to compute expectations for at most @xmath134 functions of the form @xmath135 .    [",
    "[ definition - of - ma - to - unify - approximations ] ] definition of @xmath136 to unify approximations + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    to develop our approximations under a unified framework , let us define the following function @xmath136 and its subfunctions denoted @xmath137 and @xmath138 : @xmath139 by simple inspection , we see that @xmath140 and @xmath141 . thus , by approximating @xmath136",
    ", we can approximate all the necessary derivatives . if @xmath142 , then this is simply the log partition function of the base exponential family , which is usually known in closed form . if @xmath143 ( as we will develop in the next sections )",
    ", then we can create a modified @xmath144 and @xmath145 such that @xmath146 and @xmath147thus also allowing us to use the machinery of the base exponential family to compute the needed integrals .",
    "[ [ overall - approach - to - bounding - ma ] ] overall approach to bounding @xmath136 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    our approach splits the integral into @xmath148 integrals which bound the integral over different subdomains of the domain .",
    "we will choose the subdomains in appropriate way to minimize error , which will be described in a future section .",
    "for each subdomain , we will form linear upper and lower bounds for @xmath138 so that we can then use the cdf function of the base exponential family to approximate the integrals over these subdomains .",
    "first , we will describe how to compute linear upper and lower bounds to @xmath138 so that the integrals reduce to the original exponential family . because we can determine the concavity of each region of @xmath138",
    ", we can form linear upper and lower bounds using the theory of convexity . the secant line and the first - order taylor series approximation form upper and lower bounds or vice versa depending on concavity .",
    "we can bound the tails of @xmath138 with a constant function or taylor series approximation as appropriate .",
    "see appendix for details on linear approximations for @xmath138 .",
    "if @xmath138 is upper and lower bounded by a linear functions , i.e. @xmath149 , then we can form a modified functions of @xmath137 that will be upper and lower bounds of @xmath150 : @xmath151 assuming @xmath152 and @xmath153 are valid parameters , we can then use the original exponential family cdf  which is usually known in closed form  to compute the needed integrals .    now that we have linear upper and lower bounds for @xmath138",
    ", we can upper and lower bound @xmath136 using the cdf of the original exponential family to compute the needed integrals ( see appendix for more derivation ) : @xmath154 where the domain is split into disjoint subdomains , i.e. @xmath155 , @xmath156 are either @xmath157 or @xmath158 depending on whether the upper or lower bound is needed , @xmath159 and @xmath160 are the log partition function and cdf of the original exponential family .",
    "note that assuming @xmath159 and @xmath160 are available in closed form  as is the case for the poisson distribution  this approximation can be computed in @xmath161 time .",
    "[ [ algorithm - to - find - appropriate - subdomains - domain_i ] ] algorithm to find appropriate subdomains @xmath162 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we need that every subdomain has a constant concavity ( i.e. either concave or convex over the subdomain ) in order to use taylor series and secant line bounds ( and a constant bound for the tails ) .",
    "thus , we use the following algorithm to find subdomains to help minimize the difference between the upper and lower bounds ( an illustration of the method can be seen in fig .",
    "[ fig : approx - illustration ] . ) :    1 .",
    "find all real roots of @xmath163 , denoted @xmath164 so we know the inflection points ( which will define the regions of constant concavity ) .",
    "2 .   use inflection points and endpoints of domain ( e.g. @xmath165 and @xmath166 for poisson ) to define the initial subdomains .",
    "3 .   compute initial bounds for these subdomains using eqn .",
    "[ eqn : m - approx ] .",
    "4 .   split the subdomain with the largest difference between upper and lower bounds ( i.e. the subdomain with the largest error ) .",
    "recompute bounds for the two new subdomains formed by splitting the largest error subdomain .",
    "repeat previous two steps until @xmath167 domains have been obtained .",
    "note that the roots of @xmath163 can be solved by expanding to a polynomial and then computing the eigenvalues of the companion matrix .",
    "for example if @xmath168 , then @xmath169 . note that the zeros of this function are equal to the zeros of @xmath170 .",
    "thus , we can let @xmath171 and form the polynomial function @xmath172 .",
    "we can then solve the zeros of this polynomial by forming the companion matrix and solving for the eigenvalues .",
    "however , we only need the real zeros and we do not care about multiplicity so it may be faster to use a direct root finding algorithm instead  though we have not explored this option .",
    "we computed the poisson grm model on two datasets : classic3 and grolier encyclopedia articles .",
    "the classic3 dataset contains 3893 research abstracts from library and information sciences , medical science and aeronautical engineering .",
    "the grolier encyclopedia dataset contains 5000 random articles from the grolier encyclopedia .",
    "we set @xmath106 , @xmath173 and @xmath174 for our experiments .",
    "we chose 10 interval endpoints ( i.e. 9 subdomains ) for our approximations .",
    "note that this means there are at least @xmath175 possible parameters .",
    "we give the top 10 positive parameters for individual , edge - wise and triple - wise combinations .",
    "the top 50 ( unless there are less than 50 non - zeros ) of both negative and positive dependencies for single , pairwise and triple - wise dependencies can be found in the appendix .",
    "these results illustrate that our model and algorithm can find interesting pairwise and triple - wise words .",
    "the timing for these experiments using prototype code in matlab on tacc maverick cluster ( https://portal.tacc.utexas.edu/user-guides/maverick ) was 2653 seconds for the classic3 dataset and 5975 seconds for the grolier dataset . given the extremely large number of parameters to be optimized , this gives evidence that grm models are computationally tractable while still wanting for some improvement .",
    "while it may seem at first that this model is impractical for even @xmath176 , we suggest some practical ideas for reducing the parameter space . first , if some parameters are known or expected a priori to be non - zero , we could only allow those parameters to be non - zero .",
    "for example , known genetic pathways could be encoded as @xmath0-wise cliques .",
    "thousands of known pathways could be added which would only incur thousands of parameters , which is very small relative to all possible parameters .",
    "second , the optimization could proceed in a stage - wise fashion such that the first a model is fit for @xmath66 , then this model is used to choose which parameters to allow in the next model of @xmath101 , etc .",
    "for example , we could first train a model with only pairwise parameters ( @xmath177 ) . then",
    ", we could find all triangles in the discovered graph and only add these parameters for training a model with @xmath106 .",
    "this heuristic would significantly reduce the number of possible parameters if the parameters are assumed to be sparse ( as is usually the case with @xmath3-regularized objectives ) .",
    "third , the tensors could be constrained to be low - rank and thus only @xmath178 values for each tensor would be needed . for example , we could assume that the pairwise tensors are low - rank matrices .",
    "for higher order tensors , a similar idea could hold , e.g. @xmath179 , where @xmath180 is @xmath181 .",
    "we generalize the previous sqr @xcite model to include factors of size @xmath11 .",
    "we study this general distribution by giving the node and radial conditional distributions , which provides simple conditions for normalization of the grm class of models .",
    "we then develop an approximation technique for estimating the node - wise log partition function and associated derivatives for the poisson case ",
    "note that @xcite only provided an algorithm for approximating the exponential sqr model .",
    "finally , we qualitatively demonstrated our model on two real world datasets .",
    "this work was supported by nsf ( dge-1110007 , iis-1149803 , iis-1447574 , iis-1546459 , dms-1264033 , ccf-1320746 ) and aro ( w911nf-12 - 1 - 0390 ) .",
    "@xmath182{\\xvec_{\\vi0 } + \\x_\\vi\\evec_\\vi } \\ , \\circ^{\\ell } \\rangle + \\b(\\x_\\vi ) \\right ) \\\\ & \\propto \\exp\\left ( \\sum_{\\j=1}^\\k \\sum_{\\ell=1}^\\j \\langle \\multip^{(\\ell)}_{(\\j ) } , ( \\sqrt[\\j]{\\xvec_{\\vi0 } } + \\sqrt[\\j]{\\x_\\vi\\evec_\\vi } ) \\ , \\circ^{\\ell } \\rangle + \\b(\\x_\\vi ) \\right ) \\\\ & \\propto \\exp\\left ( \\sum_{\\j=1}^\\k \\sum_{\\ell=1}^\\j \\left\\langle \\multip^{(\\ell)}_{(\\j ) } , \\sum_{m=0}^\\ell \\binom{\\ell}{m } \\left(\\sqrt[\\j]{\\xvec_{\\vi0 } } \\,\\circ^{\\ell - m}\\right ) \\circ \\left(\\sqrt[\\j]{\\x_\\vi\\evec_\\vi } \\ , \\circ^{m}\\right ) \\right\\rangle + \\b(\\x_\\vi ) \\right ) \\\\ & \\propto \\exp\\left ( \\sum_{\\j=1}^\\k \\sum_{\\ell=1}^\\j   \\sum_{m=0}^\\ell \\binom{\\ell}{m }   \\left\\langle \\multip^{(\\ell)}_{(\\j)},\\left(\\sqrt[\\j]{\\xvec_{\\vi0 } } \\,\\circ^{\\ell - m}\\right ) \\circ \\left(\\sqrt[\\j]{\\x_\\vi\\evec_\\vi } \\ , \\circ^{m}\\right ) \\right\\rangle + \\b(\\x_\\vi ) \\right ) \\\\ & \\propto \\exp\\left ( \\sum_{\\j=1}^\\k \\sum_{\\ell=1}^\\j   \\sum_{m=0}^\\ell \\binom{\\ell}{m } \\left\\langle \\left[\\multip^{(\\ell)}_{(\\j)}\\right]_{\\mathbf{i}(\\vi , m)},\\sqrt[\\j]{\\xvec_{\\vi0 } } \\,\\circ^{\\ell - m } \\right\\rangle \\x_\\vi^{m/\\j } + \\b(\\x_\\vi ) \\right ) \\\\ & \\propto \\exp\\left ( \\sum_{\\j=1}^\\k \\sum_{\\ell=1}^\\j   \\sum_{m=1}^\\ell \\binom{\\ell}{m } \\left\\langle \\left[\\multip^{(\\ell)}_{(\\j)}\\right]_{\\mathbf{i}(\\vi , m)},\\sqrt[\\j]{\\xvec_{\\vi0 } } \\,\\circ^{\\ell - m } \\right\\rangle \\x_\\vi^{m/\\j } + \\b(\\x_\\vi ) \\right ) \\tag{$m=0 $ is constant}\\\\ & \\propto \\exp\\left ( \\sum_{\\j=1}^\\k \\sum_{\\ell=1}^\\j   \\binom{\\ell}{1 } \\left\\langle \\left[\\multip^{(\\ell)}_{(\\j)}\\right]_{\\mathbf{i}(\\vi,1)},\\sqrt[\\j]{\\xvec_{\\vi0 } } \\,\\circ^{\\ell-1 } \\right\\rangle \\x_\\vi^{1/\\j } + \\b(\\x_\\vi ) \\right ) \\tag{$m\\geq 2 $ are all zero since subtensors are zero by construction}\\\\ & \\propto \\exp\\left ( \\sum_{\\j=1}^\\k \\left ( \\sum_{\\ell=1}^\\j   \\ell \\left\\langle \\left[\\multip^{(\\ell)}_{(\\j)}\\right]_{\\mathbf{i}(\\vi,1)},\\sqrt[\\j]{\\xvec_{\\vi0 } } \\,\\circ^{\\ell-1 } \\right\\rangle \\right ) \\x_\\vi^{1/\\j } + \\b(\\x_\\vi ) \\right ) \\\\ & \\propto \\exp\\left ( \\sum_{\\j=1}^\\k \\natp_{\\j\\vi } \\x_\\vi^{1/\\j } + \\b(\\x_\\vi ) \\right ) \\ , , \\end{aligned}\\ ] ]    where @xmath183_{\\vi},\\sqrt[\\j]{\\xvec_{\\vi0 } } \\,\\circ^{\\ell-1 } \\right\\rangle \\right)$ ] .",
    "see notation section for definition of @xmath184_{\\vi}$ ] .",
    "this is a univariate exponential family with sufficient statistics @xmath82 , natural parameters @xmath83 , and base measure @xmath84 .",
    "this recovers the sqr node conditional from @xcite with @xmath101 .",
    "as in @xcite , we define the _ radial _ conditional distribution by fixing the unit direction @xmath86 of the sufficient statistics but allowing the scaling @xmath87 to be unkown .",
    "thus , we get the following _ radial _ conditional distribution : @xmath185{\\radx\\uvec } \\ , \\circ^{\\ell } \\rangle + \\textstyle{\\sum_{\\vi } } \\b(\\radx\\usca_\\vi ) \\right ) \\\\ & \\propto \\exp\\left ( \\sum_{\\j=1}^\\k \\sum_{\\ell=1}^\\j \\langle \\multip^{(\\ell)}_{(\\j ) } , \\sqrt[\\j]{\\uvec } \\ , \\circ^{\\ell } \\rangle \\radx^{\\frac{\\ell}{\\j } } + \\textstyle{\\sum_{\\vi } } \\b(\\radx\\usca_\\vi ) \\right ) \\\\ & \\propto \\exp\\left ( \\sum_{r\\in\\mathcal{r } } \\natp_r(\\uvec ) \\radx^r + \\tilde{\\b}_{\\uvec}(\\radx ) \\right ) \\ , , \\end{aligned}\\ ] ] where @xmath186 is the set of possible ratios , @xmath90{\\uvec } \\ , \\circ^{\\ell } \\rangle$ ] are the exponential family parameters , @xmath91 are the corresponding sufficient statistics , and @xmath92 is the base measure .",
    "thus , the radial conditional distribution is a univariate exponential family .",
    "[ [ taylor - series - linear - bound ] ] taylor series linear bound + + + + + + + + + + + + + + + + + + + + + + + + + +    upper bound if concavity = -1 and lower bound if concavity = 1 : @xmath188    [ [ secant - linear - bound ] ] secant linear bound + + + + + + + + + + + + + + + + + + +    upper bound if concavity = 1 and lower bound if concavity = -1 : @xmath189    [ [ tail - bounds ] ] tail bounds + + + + + + + + + + +    we know there are only a finite number of inflection points so let us take the @xmath47 value for the last inflection point , denoted @xmath190 . by simple asymptotic analysis , we know that the largest non - zero term will dominate eventually .",
    "let s assume w.l.o.g . that @xmath191 dominates , @xmath192 , then we can take @xmath193 , @xmath194 . ] and @xmath195 . then , we know that after the last inflection point , the concavity will be negative .",
    "in addition , we know that the @xmath196 as @xmath197 . the function must be monotonically increasing after the last inflection point .",
    "proof by contradiction : suppose the monotonicity is negative after the last inflection point . then , because the @xmath138 is a continuous function and @xmath196 as @xmath197 , the function must eventually have a positive monotonicity . yet",
    "this would switch from negative monotonicity to positive monotonicity after the last inflection point .",
    "however , this would be an inflection point that is greater than the assumed last inflection point which leads to a contradiction .",
    "the case where @xmath198 can be proved similarly .",
    "thus , we can use a constant function for an upper bound if concavity = 1 . and we can use a constant function as a lower bound if concavity = -1 . a taylor series approximation forms an upper or lower bound depending on concavity .",
    "< < < largest 1-tuples , j = 1 , ell = 1 > > > -0.6256   information -0.6906   flow -0.8097   library -1.1693   pressure -1.4066   system -1.4090   theory -1.4209   results -1.4248   data -1.4597   patients -1.5737   found -1.5791   method -1.6292   cells -1.6566   analysis -1.7161   given -1.7198   use -1.7389   number -1.7525   used -1.7550   study -1.7860   made -1.7884   effect -1.8054   time -1.8089   body -1.8371   research -1.8563   cases -1.8958   normal -1.9246   effects -1.9436   present -1.9690   discussed -1.9803   shock -1.9899   presented -2.0112   wing -2.0135   surface -2.0275   large -2.0295   case -2.0447   obtained -2.0603   new -2.0695   paper -2.0776   libraries -2.0834   high -2.0884   problems -2.1160   methods -2.1162   well -2.1311   development -2.1414",
    "general -2.1417   growth -2.1659   problem -2.2109   jet -2.2112   terms -2.2313   systems -2.2416   form    < < < positive 2-tuples , j = 2 , ell = 2 > > >   4.9827   boundary + layer   4.2583   heat + transfer   3.9493   tunnel + wind   3.3190   edge + leading   3.1510   bone + marrow   3.0395   angle + attack   2.8711   skin + friction   2.5638   growth + hormone   2.3182   plate + flat   2.2675   shock + wave   2.2548   mach + numbers   2.1277   number + mach   2.1047   number + reynolds   2.0561   agreement + good   2.0306   attack + angles",
    "2.0102   document + documents   1.9377   cells + cell   1.7727   journals + journal   1.5436   library + libraries   1.5291   lift + drag   1.5090   wing + wings   1.4283   shells + cylindrical   1.4192   buckling + shells   1.4126   temperature + thermal   1.4080   free + stream   1.3980   ratio + aspect   1.3892   equations + differential   1.3721   boundary + layers   1.3675   point + stagnation   1.2517   shock + waves   1.2495   heat + temperature   1.2285   reynolds + transition   1.2000   wings + aspect   1.1793   temperature + temperatures   1.1554   thin + shells   1.1335   science + scientific   1.1279   cells + marrow   1.1188   numbers + reynolds   1.1004   cylinder + circular   1.0910   renal + kidney   1.0907   pressure + pressures   1.0384   high + speed   1.0294   layer + laminar   1.0266   information + retrieval   1.0232   patients + therapy   1.0159   patients + cancer   1.0127   jet + nozzle   0.9848   group + groups   0.9660   experimental + theoretical   0.9528   buckling + stress    < < < negative 2-tuples , j = 2 , ell = 2 > > >",
    "-0.8428   flow - library -0.6400   information - pressure -0.5896   flow - cells -0.5885",
    "pressure - library -0.5737   library - patients -0.5570   flow - system -0.5559   information - cells -0.5533   information - heat -0.5185   information - patients -0.5184   flow - patients -0.4941   theory - patients -0.4902   information - normal -0.4695   information - found -0.4600   information - effect -0.4587   library - theory -0.4489   library - normal -0.4479   library - cells -0.4213   library - effects -0.4097   flow - retrieval -0.4071   flow - growth -0.3925   library - found -0.3857   library - cases -0.3667   information - wing -0.3653   information - case -0.3580   pressure - cells -0.3548   flow - information -0.3383   flow - subject -0.3364   results - library -0.3316   information - effects -0.3242   information - temperature -0.3170   information - surface -0.3143   flow - children -0.3131   library - obtained -0.2957   flow - book -0.2904   flow - research -0.2903   information - mach -0.2863   theory - cells -0.2858   library - effect -0.2824   information - equations -0.2817   flow - literature -0.2780   flow - index -0.2754   flow - buckling -0.2745   analysis - patients -0.2692   information - cases -0.2650   information - shock -0.2626   information - boundary -0.2583   information - method -0.2566   information - high -0.2524   library - body -0.2522   information - ratio    < < < positive 3-tuples , j = 3 , ell = 3 > > >   0.5067   layer + skin + friction   0.3171   information + retrieval + storage   0.3149   pressure + number + mach   0.3118   layer + plate + flat   0.2672   flow + given + case   0.2411   flow + plate + flat   0.1759   number + mach + investigation   0.1390   number + mach + conducted   0.1340   wing + ratio + aspect   0.1317   number + based + reynolds   0.1100   pressure + ratio + jet   0.1072   heat + transfer + coefficients   0.0973   system + retrieval + user   0.0972   boundary + layer + experiments   0.0926   mach + free + stream   0.0862   pressure + layer + gradient   0.0825   heat + temperature + coefficient   0.0716   pressure + supersonic + base   0.0711   boundary + shock + interaction   0.0709   boundary + layer + distance   0.0709   layer + shock + interaction   0.0678   theory + experimental + experiment   0.0594   flow + fluid + steady   0.0578   flow + boundary + present   0.0554   flow + body + revolution   0.0537   flow + case + form   0.0524   flow + body + shape   0.0511   information + data + base   0.0479   boundary + layer + found   0.0478   cells + bone + marrow   0.0462   flow + theory + approximation   0.0457   data + retrieval + base   0.0430   results + number + higher   0.0420   layer + temperature + compressible   0.0417   number + mach + static   0.0403   boundary + injection + mass   0.0397   number + mach + approximately   0.0393   flow + hypersonic + region   0.0365   theory + wing + wings   0.0360   growth + human + hormone",
    "0.0359   number + mach + lower   0.0357   heat + transfer + blunt   0.0337   number + mach + increasing   0.0337   number + boundary + increasing   0.0328   boundary + layer + measurements   0.0306   number + boundary + reynolds   0.0305   flow + body + conditions   0.0300   information + field + science   0.0293   flow + number + based",
    "0.0290   flow + data + experimental    < < < negative 3-tuples , j = 3 , ell = 3 > > > -0.3490   boundary - layer - conditions -0.2025   number - mach - numbers -0.0907   boundary - layer - wing -0.0566   flow - number - numbers -0.0548   boundary - layer - time -0.0450   layer - shock - laminar -0.0433   number - mach - solution -0.0353   boundary - layer - jet -0.0274   heat - transfer - jet -0.0265   boundary - solutions - turbulent -0.0236   flow - mach - reynolds -0.0208   pressure - number - numbers -0.0101   boundary - layer - flutter -0.0019   flow - mach - velocity -0.0014   number - mach - problems ....",
    "< < < largest 1-tuples , j = 1 , ell = 1 > > >",
    "-1.6202   american -1.7936   century -1.8188   john -1.8830   called -1.8866   city -1.9162   world -1.9543   life -2.0359   united -2.1299   system -2.1328   university -2.1390   family -2.1473   time -2.1591   war -2.1858   include -2.1870   english -2.2457   water -2.2485   history -2.2559   de -2.2694   form -2.3326   major -2.3442   national -2.3523   french -2.3537   william -2.3708   art -2.3808   found -2.4045   name -2.4049   modern -2.4255   music -2.4315   power -2.4433   king -2.4445   social -2.4455   british -2.4596   usually -2.4718   charles -2.4784   south -2.4923   law -2.4995   north -2.5030   repr -2.5165   species -2.5247   theory -2.5383   human -2.5520   ft -2.5530   black -2.5566   government -2.5660   west -2.5773   york -2.5777   church -2.5841   school -2.5890   development -2.5899   common    < < < positive 2-tuples , j = 2 , ell = 2 > > >   8.7140   km + mi   3.9800   language + languages   2.9617   china + chinese   2.6237   plants + plant   2.5229   deg + temperatures   2.5152   music + musical   2.4147   spanish + spain   2.1495   novel + novels   2.1059   art + painting   2.0869   poetry + poet   2.0738   agricultural + agriculture   2.0492   war + civil   2.0024   literature + literary   1.8595   french + france   1.8405   german + germany   1.7779   culture + cultural   1.7453   china + asia   1.7368   india + asia   1.7088   system + systems   1.6836   city + york   1.6818   west + east   1.5932   africa + african   1.5932   deg + mm   1.5137   southern + northern   1.4987   architecture + building   1.4788   style + architecture   1.4431   body + blood   1.4359   role + played   1.4313   sea + ocean   1.4304   cells + blood   1.4118   science + scientific   1.4074   century + centuries   1.3808   population + sq   1.3723   social + society   1.3611   italian + renaissance   1.3611   music + opera   1.3600   ocean + pacific   1.3569   cause + disease   1.3548   cities + urban   1.3419   war + army   1.3308   united + countries   1.3065   animals + animal   1.2998   church + christian   1.2991   art + museum   1.2907   education + schools   1.2809   programs + program   1.2715   deg + temperature   1.2550   world + war   1.2515   party + leader   1.2477   government + federal    < < < negative 2-tuples , j = 2 , ell = 2 > > > -0.2449   life - languages -0.2179   century - species -0.2041   city - species -0.1575   war - species -0.1156   city - sq -0.0941   century - june -0.0911   war - languages -0.0771   war - example -0.0725   city - theory -0.0718   city - common -0.0707   city - system -0.0684   city - called -0.0666   century - cells -0.0623   war - cells -0.0501   american - eng -0.0436   city - english -0.0420   century - president -0.0415   american - ft -0.0379   art - america -0.0367   city - found -0.0359   city - form -0.0340   city - development -0.0338   war - form -0.0333   war - usually -0.0301   called - deg -0.0279   war - forms -0.0247   city - time -0.0241   city - united -0.0237   war - human -0.0199   century - july -0.0199   century - party -0.0152   war - theory -0.0151   american - king -0.0128   city - family -0.0119   century - south -0.0112   called - eng -0.0109   city - life -0.0103   american - deg -0.0102   american - east -0.0080   american - city -0.0071   war - water -0.0058   city - usually -0.0053   american - cells -0.0051   form - university -0.0046   city - body -0.0039   city - process -0.0029   century - american -0.0027   ft - english -0.0008   city - cells    < <",
    "< positive 3-tuples , j = 3 , ell = 3 > > >   0.3126   american + city + york   0.2773   city + population + center   0.2549   population + deg + mm   0.1971   major + population + persons   0.1641   ft + sea + level   0.1523   american + south + america   0.1515   deg + sq + consists   0.1351   city + deg + july   0.1330   war + civil + union   0.1173   population + deg + elected   0.1170   american + united + english   0.1140   war + congress + program   0.1054   population + sq + persons   0.0986   american + french + british   0.0972   language + includes + languages   0.0965   world + war + japanese   0.0923   major + time + changes   0.0899   century + world + laws   0.0879   life + human + stage   0.0875   north + south + president   0.0870   city + population + university   0.0845   century + world + war   0.0830   km + mi + discovered   0.0813   war + united + received   0.0770   city + river + historical   0.0760   century + history + short   0.0744   century + english + story   0.0738   war + south + union   0.0721   american + war + congress",
    "0.0698   world + united + david   0.0676   century + history + active   0.0674   century + history + wide   0.0669   war + united + america   0.0668   war + army + june   0.0664   city + km + population   0.0664   government + national + rise   0.0663   century + form + appeared   0.0649   war + united + caused   0.0644   century + world + separate   0.0642   united + people + continued   0.0638   city + united + urban   0.0638   century + time + applied   0.0633   world + united + building   0.0629   world + south + iron   0.0621   world + population + rate   0.0614   city + university + center   0.0605   century + time + studied   0.0599   american + war + people   0.0586   north + km + fish   0.0582   world + william + series    < < < negative 3-tuples , j = 3 , ell = 3 > > >",
    "-0.2560   city - population - york -0.1206   km - mi - america -0.1076   american - km - mi -0.0586   km - mi - york -0.0518   war - north - example -0.0429   km - mi - social -0.0413   km - mi - family -0.0294   km - mi - own -0.0293   km - mi - style -0.0263   city - population - style -0.0262   km - mi - theory -0.0253   city - center - sq -0.0208   km - mi - law -0.0207   km - mi - human -0.0182   km - mi - example -0.0157   city - population - greek -0.0145   km - mi - water -0.0125   called - km - mi -0.0114   england - language - languages -0.0099   km - mi - greek -0.0093   time - km - mi -0.0042   km - mi - english -0.0025   mi - population - america -0.0021   population - america - sq -0.0012   war - km - mi -0.0003   american - city - center ...."
  ],
  "abstract_text": [
    "<S> we present a novel @xmath0-way high - dimensional graphical model called the generalized root model ( grm ) that explicitly models dependencies between variable sets of size @xmath1where @xmath2 is the standard pairwise graphical model . </S>",
    "<S> this model is based on taking the @xmath0-th root of the original sufficient statistics of any univariate exponential family with positive sufficient statistics , including the poisson and exponential distributions . as in the recent work with square root graphical ( sqr ) models @xcite  which was restricted to pairwise dependencies  </S>",
    "<S> we give the conditions of the parameters that are needed for normalization using the radial conditionals similar to the pairwise case @xcite . </S>",
    "<S> in particular , we show that the poisson grm has no restrictions on the parameters and the exponential grm only has a restriction akin to negative definiteness . </S>",
    "<S> we develop a simple but general learning algorithm based on @xmath3-regularized node - wise regressions . </S>",
    "<S> we also present a general way of numerically approximating the log partition function and associated derivatives of the grm univariate node conditionals  in contrast to @xcite which only provided algorithm for estimating the exponential sqr . to illustrate grm , we model word counts with a poisson grm and show the associated @xmath0-sized variable sets . </S>",
    "<S> we finish by discussing methods for reducing the parameter space in various situations . </S>"
  ]
}