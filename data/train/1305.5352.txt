{
  "article_text": [
    "multiplicative phase noise is a major source of impairment in radio and optical channels .",
    "the presence of phase noise in radio channels is well known and studied from a long time , being phase noise introduced by the local oscillators used in up conversion and down conversion , while multiplicative phase noise is recently becoming a hot topic in the context of coherent optical transmission .",
    "recent studies about the phase noise that arises in optical channels and about its effects in coherent optics can be found in @xcite .",
    "several methods have been proposed in the literature to combat the detrimental effects of phase noise . among these methods",
    "we cite iterative demodulation and decoding techniques of @xcite and the insertion of pilot symbols @xcite , and staged demodulation and decoding @xcite .",
    "the capacity of the additive white gaussian noise ( awgn ) channel affected by multiplicative phase noise with white power spectral density is studied in @xcite,@xcite , while wiener s phase noise is considered in @xcite .",
    "analytical bounds on capacity of phase noise channels at high signal - to - noise ratio are given in @xcite . despite the quantity and quality of the literature available , we find room for new results by considering the channel impaired by autoregressive moving - average ( arma ) multiplicative phase noise , a phase noise model that is much more realistic than wiener s phase noise and/or white phase noise in many cases of practical interest .",
    "the arma model makes it possible to shape the power spectral density of phase noise by acting on the order and on the parameters of the model .",
    "working out the capacity of a channel affected by a general multiplicative arma phase noise process is a challenging problem , because    * the state space is not finite and it is multidimensional , therefore it can not be approached by techniques like those used for white and wiener phase noise , * the observation is a nonlinear function of the state .",
    "the only paper studying the capacity of the channel affected by arma phase noise we are aware of is @xcite , where the method of particle filtering ( see @xcite for a tutorial on particle filtering ) is adopted to work out an approximation to the constrained channel capacity , the constrained capacity being the information rate transferred through the channel with a fixed source .",
    "the new results presented in this paper are tight numerical upper and lower bounds to the constrained capacity of the awgn arma phase noise channel .",
    "let @xmath0 indicate the column vector @xmath1 , @xmath2 , where @xmath3 is empty for @xmath4 , the superscript @xmath5 denotes transposition , and @xmath6 .",
    "also , let @xmath7 indicate a possibly non - stationary process , @xmath8 , whose generic realization is the sequence @xmath9 when @xmath10 is a continuous set , @xmath11 is used to indicate the multivariate probability density function , while when @xmath10 is a discrete set @xmath11 indicates the multivariate mass probability and @xmath12 denotes the number of elements in @xmath13 .",
    "consider a first - order markov channel .",
    "the markovian state process @xmath14 is characterized by the joint probability @xmath15 a channel without feedback that is memoryless given the state is characterized by the state transition probability @xmath16 and by the conditional distribution @xmath17 where @xmath18 is the channel output process and @xmath19 is the channel input process , that we assume to be discrete .",
    "equation ( [ markovchannel ] ) says that the channel output process is memoryless given the source and the state .",
    "drawing from the parlance of carrier recovery , the channel transition probability @xmath20 , which is conditioned on channel s input , is hereafter called _ data - aided _ channel transition probability .",
    "we assume that the source is memoryless and independent of the state , that is @xmath21 putting together ( [ markovchannel ] ) and ( [ markovsource ] ) one finds that the joint source and channel model is memoryless given the state : @xmath22 using ( [ markovjoint ] ) one finds that channel s output is memoryless given the state : @xmath23 drawing again from the parlance of carrier recovery , the channel transition probability @xmath24 , which is not aware of channel s input , is hereafter called _ blind _ channel transition probability . from eq .",
    "( [ markovstate ] ) and ( [ memorylesschannel ] ) , after straightforward passages one gets @xmath25 also , by ( [ markovjoint ] ) and ( [ memorylesschannel ] ) one finds that the source is memoryless given the state and channel s output : @xmath26",
    "any measurement process @xmath18 that is memoryless given the state can be cast in the general framework of state - space approach for modelling dynamic systems , which is defined by the state transition equation @xmath27 and by the measurement equation @xmath28 where @xmath29 and @xmath30 are possibly non - linear and time - varying known functions of their arguments , @xmath31 is the process noise vector , and @xmath32 is the measurement noise vector , which is assumed to be independent of @xmath31 .",
    "the state - space approach fits the markov channel , taking the output channel process @xmath18 as the measurement process both in the blind and in the data aided case . in the blind case , the measurement equation is a time - invariant function of the state , and the measurement noise is the joint effect of channel noise and input process .",
    "the blind case is described by the memoryless probability @xmath24 appearing in the product ( [ memorylesschannel ] ) . in the data - aided case",
    "the measurement noise is only the channel noise and the input process is embedded in the known non - linear and time - varying @xmath30 . in this case",
    "the measurement probability is @xmath20 .",
    "a powerful tool in the analysis of dynamical system is the so - called _",
    "bayesian tracking_. let the markovian state be continuous .",
    "one can track the hidden state by a two - step recursion that , for @xmath33 reads @xmath34 @xmath35 where @xmath36 is the _ predictive _ distribution , @xmath37 is the _ posterior _ distribution , and the denominator of ( [ update ] ) is a normalization factor such that the left - hand side is a probability .",
    "the normalization factor can be computed by the chapman - kolmogoroff equation @xmath38 the state transition probability @xmath16 appears in ( [ predict ] ) in place of @xmath39 thanks to ( [ markov ] ) .",
    "thanks to ( [ memorylesschannel ] ) , @xmath24 can be used in place of @xmath40 in ( [ update ] ) .",
    "when the dynamic system is a linear system with gaussian noises , bayesian tracking is performed by the kalman filter .",
    "when the model is not tractable , one can resort to particle filtering techniques to work out an approximation to the wanted distribution .",
    "the probabilities worked out by bayesian tracking can be used to evaluate entropy rates by monte carlo integration as , for instance , in @xcite .",
    "when the result of bayesian tracking is an approximation @xmath41 to the wanted probability @xmath42 , then , by the kullback - leibler inequality , the approximation can be used to get an upper bound on the wanted entropy rate @xmath43 where operator @xmath44 denotes expectation with respect to probability @xmath45 .",
    "the @xmath46-th output of the channel is @xmath47 where @xmath48 is the imaginary unit , @xmath18 is the complex channel output process , @xmath19 is the channel complex input modulation process made by i.i.d .",
    "random variables with zero mean and unit variance , @xmath49 is the complex awgn process with zero mean and variance @xmath50 , and @xmath51 is the phase noise process which is assumed to be independent of @xmath19 and @xmath49 .",
    "specifically , process @xmath51 is modelled as the 1-causal accumulation modulo @xmath52 of frequency noise , that is @xmath53_{\\bmod{2\\pi } } , \\label{nco}\\ ] ] where the frequency noise process @xmath54 is given by the @xmath55-transform @xmath56 where @xmath57 is a white gaussian noise process with zero mean and variance @xmath58 , and @xmath59 where @xmath60 , and it is understood that @xmath61 for @xmath62 , leading to the special case of random phase walk , where @xmath63 .",
    "@xmath64 is the transfer function of a filter made by a shift register with feedback taps @xmath65 and forward taps @xmath66 .",
    "let @xmath67 be the content of the shift register at the @xmath46-th channel use , that is @xmath68 the state at time @xmath46 is the @xmath69 column vector @xmath70 let us introduce the state transition matrix @xmath71 \\nonumber,\\end{aligned}\\ ] ] where @xmath72 is the identity matrix of size @xmath73 and @xmath74 is a column vector of @xmath75 zeros .",
    "the state transition equation is @xmath76 where @xmath77 is such that @xmath78 lies in the interval @xmath79 , thus making the state transition equation non - linear .",
    "given @xmath80 , for @xmath62 the state transition to @xmath81 is ambiguous of @xmath82 , while for @xmath83 , due to the presence of @xmath84 in @xmath81 , the state transition is not ambiguous .",
    "although not necessary , in the following we will assume @xmath85 , referring the reader to @xcite for the state transition probability with @xmath62 . for @xmath85",
    "the state transition probability is a @xmath69-dimensional gaussian distribution .",
    "note that , given @xmath86 , @xmath75 of the @xmath69 entries of @xmath81 are known , the only free random variable being @xmath31 , hence the covariance matrix of the state transition probability has unit rank .",
    "specifically , @xmath87 where @xmath88 is a @xmath75-dimensional gaussian distribution over the space spanned by @xmath89 with mean vector @xmath90 and covariance matrix @xmath91 , @xmath92 \\label{qmatrix},\\end{aligned}\\ ] ] where @xmath93 is an all - zero @xmath94 matrix , and @xmath95    the measurement at time @xmath46 is the @xmath96 given by ( [ envelope ] ) .",
    "the data - aided channel transition probability is @xmath97 where @xmath98 indicates a circular symmetric gaussian probability density function over the complex plane spanned by @xmath99 with mean @xmath90 and two - dimensional variance @xmath100 .",
    "the joint source and channel probability is @xmath101 from the above probability one can compute the blind channel transition probability by ( [ memorylesschannel ] ) .",
    "let @xmath102 denote the entropy rate of process @xmath7 .",
    "extract @xmath103 from @xmath104 to write @xmath105 where , by independence between @xmath19 and the state process @xmath14 , @xmath106 has been substituted in place of @xmath107 .",
    "the upper bound that we propose is @xmath108 where @xmath109 indicates an upper bound on @xmath110 .",
    "the two relative entropy rates @xmath111 and @xmath106 are those of the white gaussian processes @xmath49 and @xmath57 , respectively . the upper bound @xmath112 can be obtained by approximating the conditional probability @xmath113 to the normalization factor of blind bayesian tracking performed by a particle filter as in @xcite .",
    "the new contribution of the present paper is the upper bound @xmath114 , which is worked out as follows . invoking the chain rule , the markovian property ( [ markov ] ) , and the shannon - mcmillan - breiman theorem",
    ", one can evaluate the entropy rate by computer simulation as @xmath115 where @xmath116 is a realization of the joint process @xmath117 .",
    "unfortunately , the actual @xmath118 of ( [ smb2 ] ) is not tractable .",
    "we propose to approximate it as @xmath119 with @xmath120 thus , thanks to ( [ klbound ] ) , getting the upper bound @xmath121 the denominator of ( [ app ] ) can be treated by moving the sum ( [ postkalman ] ) outside the integral , and observing that the integral is the convolution between two gaussian distributions , leading to closed form computation as in the predictive step of the kalman filter ( * ? ? ?",
    "3.3 ) : @xmath122 the parameters @xmath123 and @xmath124 appearing in equations ( [ postkalman ] ) and ( [ predictcovkalman ] ) can be worked out by a linearized kalman filter ( * ? ? ?",
    "13.2 ) . as it will be shown by simulation results , a tighter bound can be obtained by taking for @xmath123 and @xmath124 a sample estimate where the sample is the set of posterior particles of a particle filter .",
    "note that the integral in the denominator of ( [ app ] ) is a normalization factor such that the left side of ( [ app ] ) is a probability . as a consequence",
    ", it can not be evaluated by the predictive particles of the particle filter , because the predictive particles would provide only an approximation to the wanted integral , and using an approximation to the denominator is not sufficient to guarantee that the ratio in ( [ app ] ) is a probability . also , it is worth pointing out that , while in @xcite the phase in the state model is unwrapped , here it is the evaluation of @xmath114 , that is not made in @xcite , that forces us to define the state by the wrapped phase ( [ nco ] ) . as a matter of fact ,",
    "phase ambiguities of @xmath125 are inherently present in the measurement , therefore cycle slips of the bayesian tracking algorithm would lead to catastrophic errors of @xmath82 between the actual unwrapped phase and the distribution of the unwrapped phase recovered by the tracking algorithm .",
    "assume a discrete input alphabet .",
    "the lower bound that we propose is @xmath126 , where , by the same arguments leading to ( [ smb2 ] ) and by the kullback - leibler inequality ( [ klbound ] ) , one evaluates the upper bound on the conditional entropy rate as @xmath127 the upper bound can be based on demodulation , that is on the probability @xmath128 where the probability inside the integral can be written as @xmath129 where the second equality comes from ( [ memorylesssource ] ) . in",
    "what follows the first factor in ( [ twoterms ] ) is approximated to @xmath130 .",
    "we point out that the proposed approximation is likely to be tight , because the condition @xmath131 gives only a weak contribution of non - data - aided type to the wanted probability .",
    "the proposed approximation leads to @xmath132 which , after normalization , can be used in ( [ lb ] ) to get the desired bound .",
    "the first factor inside the integral ( [ saturation2 ] ) is the predictive probability of bayesian tracking , while the second factor is a memoryless term that comes from the channel model ( [ sourcechanneltransition ] ) .",
    "the frequency noise used in the simulations is obtained by filtering white gaussian noise through the transfer function @xmath133 special cases of ( [ smmodel ] ) are obtained with @xmath134 and @xmath135 , leading to white phase noise , and @xmath136 , that leads to wiener s phase noise .",
    "model ( [ smmodel ] ) is proposed in @xcite as an approximation to the phase noise spectrum of real - world microwave local oscillators and it has been used with @xmath137 , @xmath138 , @xmath139 to get the simulation results that are hereafter presented . the lower bound is computed by adopting as a bayesian tracking method the linearized predictive kalman filter , as in @xcite and @xcite , while for the upper bound we use both the kalman filter and the particle filter .",
    "figure [ 4 ] reports the results for 4-ary quadrature - amplitude modulation ( qam ) while fig . [ 16 ] reports the results for 16-qam , in both cases with two values of @xmath140 .",
    "the two figures show that the particle filter greatly improves the upper bound over the kalman filter , especially for large @xmath140 . in contrast , the lower bound based on the predictive kalman filter is so tight that there is no need of using a particle filter for demodulation , also for large values of @xmath140 .",
    "we have observed that the kalman filter often produces a covariance @xmath124 with a determinant that is much lower than the one that is obtained by the particle filter .",
    "what happens is that the folded gaussian distribution ( [ postkalman ] ) is sampled in the state visited by the simulation , and , when this state is far from the mean vector , the gaussian is sampled on the tails . in this event , the poor estimation of the covariance leads to dramatically large errors in the evaluation of the differential entropy rate @xmath141 .",
    "conversely , the entropy rate @xmath142 that appears in the lower bound is based on the integral of the mentioned gaussian distribution , hence it is less sensitive to errors in the estimated covariance .",
    "we have presented upper and lower bounds to the constrained information rate transferred through the multiplicative phase noise channel with arma phase noise . from the results it appears that the upper and lower bounds are so close to each other that we can claim of having computed the actual information rate , at least for the second - order arma phase noise studied in the simulation .",
    "an important experimental result presented in the paper is that demodulation based on a predictive linearized kalman filter aided by past data is virtually capacity achieving , at least in the examples studied in the paper .",
    "this is not surprising in view of the result obtained in @xcite for the intersymbol interference ( isi ) channel , that says that predictive filtering aided by past data ( in the case of the isi channel , the predictive decision - feedback equalizer ) virtually leads to channel capacity .",
    "a practical mean to replace past data with the decisions coming from a capacity achieving code is the interleaving scheme originally proposed by eyuboglu in @xcite for the isi channel .",
    "extension of this principle to other channels can be found , for instance , in @xcite .",
    "computational complexity of demodulation via kalman filter can be lowered by using a time invariant filter as described in @xcite .",
    "m. magarini , a. spalvieri , f. vacondio , m. bertolini , m. pepe , and g. gavioli , `` empirical modeling and simulation of phase noise in long - haul coherent optical systems , '' _ optics express _ , vol .",
    "23 , pp . 22455 - 22461 ,",
    "nov . 7 , 2011 .",
    "g. colavolpe , a. barbieri , and g. caire , `` algorithms for iterative decoding in the presence of strong phase noise , '' _ ieee journal on selected areas in commun . , _ vol .",
    "9 , pp . 1748 - 1757 , sept .",
    "2005 .",
    "b. goebel , r .- j .",
    "essiambre , g. kramer , p. j. winzer , and n. hanik , `` calculation of mutual information for partially coherent gaussian channels with application to fiber optics , '' _ ieee trans .",
    "inf . theory _ ,",
    "9 , pp . 5720 - 5736 , sept .",
    "2011 .",
    "l. barletta , m. magarini , and a. spalvieri , `` estimate of information rates of discrete - time first - order markov phase noise channels , '' _ ieee photon .",
    "21 , pp 15821584 , nov . 1 , 2011 .      l. barletta , m. magarini , and a. spalvieri , `` the information rate transferred through the discrete - time wiener s phase noise channel , '' _ ieee j. lightw . technol .",
    "_ , vol . 30 , no . 10 , pp",
    ". 1480 - 1486 , may 15 , 2012 .",
    "arulampalam , s. maskell , n. gordon , and t. clapp , `` a tutorial on particle filters for online nonlinear / non - gaussian bayesian tracking , '' _ ieee trans . on signal proc . , _ vol .",
    "174 - 188 , feb . 2002 .",
    "a.  spalvieri and m.  magarini , `` wiener s analysis of the discrete - time phase - locked loop with loop delay , '' _ ieee trans",
    ". circuits and systems ii : express briefs , _ vol .",
    "55 , no . 6 , pp.596 - 600 , june 2008 .",
    "l. barletta , m. magarini , and a. spalvieri , `` a new lower bound below the information rate of wiener phase noise channel based on kalman carrier recovery , '' _ optics express _ , vol .",
    "25471 - 25477 , nov . 5 , 2012 .",
    "l. barletta , m. magarini , and a. spalvieri , `` new lower bound below the information rate of phase noise channel based on kalman carrier recovery , '' _ international journal on electrical engineering and informatics _ ,",
    "597 - 607 , dec . 2012 .",
    "j. m. cioffi , g. p. dudevoir , m. v. eyuboglu , and g. d. forney , `` mmse decision - feedback equalizers and coding  part i : equalization results , '' _ ieee trans .",
    "commun . , _ vol .",
    "10 , pp 2582 - 2594 , oct . 1995 .",
    "m. v. eyuboglu , `` detection of coded modulation signals on linear severely distorted channels using decision - feedback noise prediction and interleaving , '' _ ieee trans .",
    "commun . , _ vol .",
    "401 - 409 , apr . 1988 .",
    "l. barletta , m. magarini , and a. spalvieri , `` bridging the gap between kalman filter and wiener filter in carrier phase tracking , '' _ ieee photon .",
    "_ , vol . 25 , no . 11 , pp 10351038 , jun . 1 , 2013"
  ],
  "abstract_text": [
    "<S> numerical upper and lower bounds to the information rate transferred through the additive white gaussian noise channel affected by discrete - time multiplicative autoregressive moving - average ( arma ) phase noise are proposed in the paper . </S>",
    "<S> the state space of the arma model being multidimensional , the problem can not be approached by the conventional trellis - based methods that assume a first - order model for phase noise and quantization of the phase space , because the number of state of the trellis would be enormous . </S>",
    "<S> the proposed lower and upper bounds are based on particle filtering and kalman filtering . </S>",
    "<S> simulation results show that the upper and lower bounds are so close to each other that we can claim of having numerically computed the actual information rate of the multiplicative arma phase noise channel , at least in the cases studied in the paper . moreover , the lower bound , which is virtually capacity - achieving , is obtained by demodulation of the incoming signal based on a kalman filter aided by past data . </S>",
    "<S> thus we can claim of having found the virtually optimal demodulator for the multiplicative phase noise channel , at least for the cases considered in the paper . </S>"
  ]
}