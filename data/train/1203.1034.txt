{
  "article_text": [
    "numerical methods designed for finding zeros of a function were discovered hundreds of years ago .",
    "the first such processes were found by @xcite and @xcite . these algorithms were improved and made more universal by 18th and 19th century mathematicians , notably @xcite",
    "whose work we repeatedly use in this paper .",
    "the binary lens equation gives rise to a fifth - order complex polynomial @xcite , which must be solved by numerical methods @xcite . solving this equation is central to nearly all methods of modeling",
    "observed light curves due to binary lenses , including those with a low - mass , i.e. , planetary companion .    because of the elementary nature and long history of the problem of solving polynomials , it is generally believed that further optimization of root solvers is not possible .",
    "for example @xcite , when discussing his algorithm for calculating binary - lens magnifications , writes : `` we find that roughly 80 per cent of the machine time is spent in the root finding routine , for which there is basically no hope of further optimization . ''",
    "the value of 80% , cited above , refers to the calculation by contour integration @xcite , one of the most versatile and commonly used methods in microlensing . increasing",
    "the speed of a root finding algorithm by a factor of 2 would decrease the time of execution by a factor 1.6 and thus , effectively , decrease the need of new computers , saving money , electricity and other resources .",
    "this is a task worth pursuing .",
    "section  [ sec : roots ] of the paper presents a new algorithm for solving general complex polynomial equations . like other such algorithms",
    ", it locates roots one by one numerically , and then divides the original polynomial by the found root before searching for the next one .",
    "however , in contrast to previous algorithms , this new one can , at each step , efficiently decide whether to use laguerre s method , or whether to choose a faster root finding method , either newton s method @xcite or a new intermediate method , which is presented in section  [ sec : lag2newt ] .",
    "section  [ sec : lensing ] is focused on binary microlensing .",
    "we find that some significant improvements are possible by making use of specific features of the binary lens equation that do not apply to the full range of complex polynomials for which this more general algorithm was developed .",
    "we discuss these further optimizations and describe the codes there .",
    "moreover , in the course of implementing these improvements , we discovered several important results on the limits of precision of the lens solver .",
    "it is possible that these are already `` known '' by numerical mathematicians , but do not appear to be known by astronomers .",
    "we were unable to determine whether these results are known because we find the numerical literature to be virtually impenetrable .",
    "we expect that other astronomers may suffer similar difficulties .",
    "we discuss these results in section  [ sec : errors ] .    in appendix",
    "[ sec : newton ] we review the study that led us to identify thomas simpson as the discoverer of the so - called `` newton s method '' . appendix  [ sec : nr ] contains discussion of _ numerical recipes _",
    "* nr ) code copyright protection and suggestion to waive it for non - profit and academic uses .",
    "all codes described in this paper are open - source , are provided on the author s web page[multiblock footnote omitted ] and are attached to the version of the paper .",
    "please cite this paper if you are using these codes for a scientific work .",
    "a list of subroutines can be found in appendix  [ sec : routines ] .",
    "laguerre s method @xcite is an iterative method similar to newton s method @xcite but is more stable because it uses first and second derivative . in addition",
    ", it converges faster , although each step takes more time to calculate .",
    "non - convergent cycles are very rare and can be broken by introducing a simple modification to the method that does not hamper the overall speed of the algorithm .    to robustly find all @xmath0 roots of the @xmath0th order polynomial , making use of a single - root finding numerical method , such as laguerre s method",
    ", the algorithm should search for roots successively one by one .",
    "after every single root is found , it should be eliminated from the polynomial by division , so the next searches yield a different root .",
    "when the degree of the resulting polynomial reaches zero , all roots are found .",
    "we call this step `` robust '' .",
    "each search can be started from point ( 0,0 ) or from other initial guess on the positions of the root .",
    "the division process introduces numerical noise .",
    "hence , once the roots are all located in this fashion , each one can be `` polished '' by applying the same method used in `` robust '' to the full polynomial in the neighborhood of initially - located root .    the subroutine cmplxrootsgen that we introduce in this section ,",
    "contains a general polynomial solver that has the above overall structure , but employs a new algorithm for single root searches (   [ sec : lag2newt ] ) .",
    "we also discuss optimized implementation of laguerre s method (   [ sec : lag ] ) , a stopping criterion for polynomials (   [ sec : stop ] ) , and the detailed structure of the whole algorithm (   [ sec : cmplx_roots_gen ] ) .",
    "our algorithm is implemented in double precision , with all constants being in sync with this level of precision .",
    "laguerre s method is implemented in subroutine cmplxlaguerre using the formula @xmath1 where @xmath2 and @xmath3 is an @xmath0th order polynomial . to avoid division by small numbers , we choose the value of the square root with positive real component .",
    "most compilers return this automatically , but we leave a simple check of the sign in the code to make it suitable for every compiler .",
    "we encourage users to test what convention is used within their compilers and to remove this check if appropriate .    in each loop of the algorithm",
    "we calculate the value of the polynomial , as well as its first two derivatives .",
    "we check the stopping criterion ( * ? ? ?",
    "* see section  [ sec : stop ] ) immediately after the value of the polynomial is evaluated .",
    "if the value of the polynomial is one order of magnitude lower than the stopping criterion for a given point , we return immediately .",
    "if the value meets the stopping criterion but there is still room for improvement ( see section  [ sec : stop ] ) , we set a flag that makes the subroutine return right after the next iteration is completed , without need for recalculating the value of the polynomial at that point .",
    "this implementation of laguerre s method is faster than the one in zroots from nr .",
    "the biggest improvement ( by @xmath4 ) comes from the fact that to decide which sign of the square root should be taken we do not evaluate both denominators and do not calculate their absolute values , whereas zroots uses a different representation of @xmath5 @xmath6 where @xmath7 and does undertake these steps .",
    "we note , however , that even in this form one could substitute calculation of absolute values by a simpler check , which would recover most of the execution - time difference .",
    "that is , one could choose the `` + '' root if @xmath8 .    to avoid cycles in the laguerre s algorithm , every 10th step we modify @xmath5 by multiplying it by a number between 0.0 and 1.0",
    "our implementation of laguerre s method ( cmplxlaguerre ) calculates the stopping criterion in every loop , since it is used to locate a root on a broad plane , over which the value of the stopping criterion can change considerably .",
    "this is in contrast to our implementation of newton s method ( cmplxnewtonspec ) , which we use mainly for `` root polishing '' .",
    "thus we calculate the stopping criterion on the first iteration of newton s method , and then only every @xmath9th step ( as a failsafe procedure ) .",
    "this saves significant time , since evaluating the stopping criterion takes about 1/3 of the time of a single newton s step .",
    "the suffix _ spec in the name of the subroutine is meant to suggest that this routine is not a generic implementations of the newton s method , but rather is specifically tailored for certain tasks in the broader algorithm .",
    "users should not reuse provided routines without broader understanding of the choices made and implemented within them .      in traditional root solvers ,",
    "laguerre iterations consume the great majority of the computation time . for the binary - lens problem ( @xmath10th order polynomial ) , four laguerre searches are required to find the roots and five more to polish them .",
    "a close study of this algorithm is therefore worthwhile to determine under what conditions it can be simplified or replaced by newton s method .    for an @xmath0th order polynomial @xmath3 ,",
    "the laguerre iteration , @xmath5 , can be written in the form of equation  ( [ eqn : lag ] ) .",
    "this form has several interesting features .",
    "most notably , it shows immediately that laguerre iterations require about twice as much time as newton iterations .",
    "first , once @xmath11 is calculated , it requires only slightly fewer additional operations ( so slightly less additional time ) to calculate @xmath12 .",
    "second , substantial calculations are required after @xmath12 is found .",
    "finally , equation  ( [ eqn : lag ] ) actually has two roots , and a check may be required to see which leads to the larger modulus of the denominator , in order to avoid dividing by small numbers .",
    "when @xmath12 is small , we can taylor expand @xmath5 to obtain : @xmath13 in particular , at the limit of vanishing @xmath14 this is exactly equal to newton s method . in the neighborhood of an isolated root , @xmath12 is of the same order as @xmath11 .",
    "this immediately implies that for polishing isolated roots , one can dispense with laguerre s method altogether and just use newton s method .",
    "this simplification is actually of central importance from a practical standpoint in microlensing because the lens - solver is the rate - limiting step for the contour method ( not ray - shooting ) , and the overwhelming majority of contour - method calls to the lens - solver should use only polishing .",
    "now , there is some cost to this because laguerre s method does converge in fewer steps than newton s method , but we find by experimentation that the number of steps is @xmath15 fewer , while the computation time of each step is about 2 times longer .",
    "moreover , equation  ( [ eqn : lagapprox ] ) suggests a new algorithm .",
    "that is , the value of @xmath12 can be used as a discriminant to decide which method to use .",
    "if @xmath16 is very small , newton s method can be used successfully ; while for large values of @xmath16 , the full laguerre method will be more suitable . in between these two regimes , an intermediate method can be used , i.e. , the second order taylor expansion : @xmath17    computation of @xmath18 is fast because @xmath14 has already been evaluated , and it has the advantages of skipping the square - root evaluation , skipping one division , and determining the sign of the square root .",
    "laguerre s method is a second order method suitable for polynomials .",
    "we now show that the intermediate method presented in the equation  ( [ eqn : sg ] ) is in fact a second - order general method for all differentiable functions .      by taylor expanding the general function @xmath19 in the neighborhood of its root ( @xmath20 ) we have : @xmath21 the first 3 terms of the expansion constitute a quadratic equation in the variable @xmath22 .",
    "one of the roots of this equation is approximated by : @xmath23 where @xmath24 provided that @xmath14 can be regarded as small .",
    "this new second - order general method is similar to halley s method @xcite developed for solving polynomials ",
    "however , its origin is clearer .",
    "since @xmath14 needs to be calculated in each step to get new approximation of the root , one could leave in place the next term in @xmath14 in the expansion of the root of the quadratic : @xmath25 we will see immediately below , that this is equivalent to the 3rd order method , in the case that the third derivative of the function is negligible ( @xmath26 , see eq .",
    "( [ eqn : e ] ) for definition ) .",
    "we now derive a third order method that uses third derivative of the function ( @xmath27 ) .",
    "inspired by the form of the discriminative function @xmath14 and by a variation of householder s 3rd order method , we construct the function : @xmath28 we note that the use of the function @xmath29 instead of @xmath30 and the use of @xmath31 as a variable , allow us to write equation  ( [ eqn : taylor ] ) , up to the 3rd order , in the simple form : @xmath32 one of the solutions to this equation is approximated by : @xmath33 which gives us a new method of finding roots complete to third order in @xmath11 , @xmath12 and @xmath34 .",
    "we note that @xmath12 must be calculated as an intermediate step in laguerre s method .",
    "however , before actually implementing laguerre , we first evaluate , since this is substantially faster .",
    "the inequalities discussed in the text are then evaluated according to their squares . ] @xmath35 . if @xmath36 , we use the intermediate method , wherein we approximate @xmath37 .",
    "if @xmath38 , we simply use newton s method . in both cases , the fractional difference in step size is @xmath39 . in the later case , we convert to newton s method for all future iterations without bothering to calculate @xmath12 nor @xmath40 .    to speed up the calculations even more , we stop calculating the stopping criterion once the newton s method regime is reached .",
    "usually this happens when we are already very close to the root , thus the value of stopping criterion will not change much . for the rare cases when this is not true ,",
    "there is however a failsafe that returns the algorithm to the full laguerre s stage if the number of iterations in newton s stage exceeds 10 .    using this dynamic algorithm , instead of the full laguerre method , leads to an increase in speed by about factor of @xmath41 .",
    "this algorithm is implemented in the cmplxlaguerre2newton routine .",
    "there are many root - solver applications for which the distinction between real and complex roots is of fundamental importance .",
    "in particular , complex roots are often `` unphysical '' .",
    "thus , generic root solvers may have a criterion that if the imaginary component of the root is within ( a conservative version of ) the numerical precision of zero , then it is simply set to zero . for example the _ numerical recipes _ zroots sets this limit at about 10 times the naive numerical precision . because the lens equation makes no fundamental distinction between real and complex roots , we do not include any such preference for real roots in the codes .",
    "the problem of when to stop the laguerre / newton iterations is , in general , a subtle one .",
    "if the threshold is set conservatively above what is achievable given the numerical precision , then the result will not be as precise as possible .",
    "if set conservatively below , then the maximum precision will be achieved but at the cost that the condition is never met , so that iterations continue until some maximum allowed number is reached , which can burn a lot of computation time .",
    "this problem would seem to be solved by choosing the threshold at exactly what can be achieved .",
    "unfortunately , this is not possible at the factor few level .",
    "@xcite derived a stopping criterion for polynomial root finding .",
    "it is based on a limit ( @xmath29 ) on the value of polynomial that is indistinguishable from zero given the numerical error in polynomial evaluation . whenever the value of the polynomial at a given point is below @xmath29 ( @xmath42 )",
    ", one could stop looking for a better approximation of the root . a conservative formula for @xmath29",
    "gives this precision under the assumption that numerical errors add linearly in intermediate computation steps ( * ? ? ?",
    "however , from a statistical standpoint , these errors will tend grow in quadrature rather than linearly .",
    "nr uses a simplified version of the adams criterion , to enable faster calculations , by taking only the first component of the sum in equation  ( 10 ) in @xcite .",
    "we call this @xmath43 . we have found that this simplified criterion is a good approximation of the full criterion , and that both will overestimate round - off errors in some fraction of cases .",
    "for the simplified criterion , the true underlying limit of precision will not be achieved in @xmath39 of cases .",
    "typically , this limit lies a factor 8100 below the criterion .",
    "figure  [ fig : crit ] ( upper panel ) shows the value of the @xmath44 at the step when the stopping criterion was satisfied . the gaussian - like profile on the values of the @xmath44 contains values corresponding to the real limit of accuracy .",
    "the tail going to higher values , up to the line @xmath45 , contains cases for which additional iterations would be warranted , since the true limit of precision was not achieved .",
    "the other panels in the figure  [ fig : crit ] show that one additional iteration is enough to get down to full numerical precision .",
    "therefore , in most algorithms in this paper , we employ the simplified adams criterion with one additional step done after the criterion is satisfied .",
    "we skip this additional step in cases for which full precision is not essential to the result .",
    "we make all our calculations in double precision .",
    "we understand `` double precision '' as being a 64 bit ( 8 byte ) number described by ieee 754 floating - point standard .",
    "this means 1 bit for sign , 11-bit exponent and 52-bit mantissa .",
    "hence the fractional round - off error we should use in equation  ( 10 ) of @xcite is @xmath46 .      in cmplxrootsgen",
    "we use the dynamic algorithm described in section  [ sec : sgalgorithm ] for the `` robust '' part of calculations . because this algorithm incorporates newton s method , in a small number of cases ( e.g. , @xmath47 in our experimentation on @xmath10th order polynomial )",
    "it will fail to converge in the prescribed number of iterations .",
    "our algorithm therefore checks for these failures , and then employs a full laguerre search starting from point ( 0,0 ) , which finds correct root more robustly ( at the cost of greater computation time ) .    we note that in the last iteration , there is no need to divide the @xmath48st order polynomial by the last root that was found . additionally , the last root can be easily found by using vite s formula @xcite for quadratic equation .",
    "these two optimization , skipping one root solver and two divisions , leads to @xmath49 gain in the performance when the algorithm is used to solve a @xmath10th order polynomial .    during `` polish '' , when we try to find a more accurate position of the root based on the full ( not divided ) polynomial , we can use laguerre s method or newton s method .",
    "since usually polishing takes only one step , this choice does not have a large impact on the overall speed of the algorithm .",
    "there is a flag in the argument list of the cmplxrootsgen routine called `` userootsasstartingpoints '' .",
    "if the routine is started without any knowledge of the root positions , this flag can be set to `` .false . '' , so all components of the `` roots '' array will be reset to @xmath50 inside the routine .",
    "on the other hand , if one knows the approximate position of at least one root , the value(s ) should be put at the end of the `` roots '' array and the flag should be set to `` .true . '' .",
    "( unknown values should be reset to ( 0,0 ) . )",
    "this will help the routine to find all roots faster .",
    "it is important to initialize the whole ",
    "roots  array prior calling the routine unless the `` userootsasstartingpoints '' flag is set to `` .false . '' .",
    "this routine , with the use of the mentioned flag , can be used to robustly find all roots of a polynomial that was created from an already solved polynomial by making small changes in its coefficients .",
    "this is faster than starting all searches from zero .",
    "robustness comes of course with a price of speed , when compared to pure root polishing . in section",
    "[ sec : lensing ] we present a method that takes advantage of pure root polishing speeds , but employs a series of checks to ensure robustness in the particular problem of the binary lensing .",
    "subroutine cmplxrootsgen , provided in the source code , implements the robust , general complex polynomial solver with the use of all optimizations mentioned above .",
    "it is consistently faster than the nr implementation , zroots . for @xmath10th order polynomials",
    "we see a speed increase by a factor of 1.61.7 .",
    "there are three broad regimes in which the binary - lens solver must be applied .",
    "the first is the point - source regime , for which the magnification can be approximated as constant over the source .",
    "this requires only a single call to the lens solver . in the second regime ,",
    "the source suffers moderate differential magnification due to the proximity of a caustic .",
    "this is generally handled by the hexadecapole approximation @xcite , which requires 13 calls to the lens solver .",
    "finally , if the source actually straddles a caustic , or if is sufficiently close that differential magnification is severe , then much more computationally intense methods are required .",
    "these generally fall into two classes : inverse ray - shooting @xcite and contour integration ( * ? ? ?",
    "all methods require calls to the lens - solver , but in the ray - shooting approach the majority of the computation , as well as the precision of the result , depends primarily on another numerical operation , namely evaluating the lens equation .",
    "therefore , it is for contour integration , which uses stokes theorem , and the hexadecapole method , that calls to the lens solver are the rate - limiting step . and it is for these approaches that numerical errors in the lens solver propagate into the final result . since these are widely used , and since such computations are often quite lengthy and usually time - critical , it is worth an effort to optimize the lens solver .",
    "an efficient algorithm tailored specifically for root polishing is crucial for contour integration as well as for the hexadecapole method , where one needs to locate roots multiple times at close - by positions of the source .",
    "the binary lens equation has two simplifying features relative to general complex polynomials .",
    "first , it is fifth - order , and therefore just `` one step '' away from being susceptible to analytic solution @xcite .",
    "second , two of the five roots are always isolated",
    ". that is , when the source approaches a caustic ( or cusp ) , then two ( or three ) of the roots can be very close together , but the remaining roots are always well separated from these and from one another .",
    "together , these two features enable a very different approach .",
    "our original idea was to improve the root polishing algorithm by identifying the two isolated roots and solving these by laguerre s method .",
    "then we would divide these out and solve for the remaining three roots using the cubic equation .",
    "because the first two roots are isolated , they are very precisely determined .",
    "therefore the normal concerns about introducing numerical noise by dividing out roots , which do very much apply to closely - spaced roots , are greatly mitigated .",
    "however , first we found that newton s method is faster than laguerre s , and is also quite robust for these two isolated roots when they are already approximately known .",
    "second , somewhat surprisingly , we found that the third most isolated root was more precisely located by newton s method than by the cubic equation ( though not by much ) . finally , we found that the remaining two ( closest ) roots could be found roughly 3 times faster than newton s method by dividing out the first three roots and solving the resulting quadratic equation , thus , effectively increasing the speed of polishing by 25% .",
    "the quadratic equation is also slightly more stable than either newton s method or laguerre s method for these two roots in cases when a third root is nearby .    of course",
    ", to apply this approach , it is necessary to know in advance which are the isolated roots . in some cases these",
    "are indeed known because one has just finished solving the lens equation at a very nearby source position .",
    "but for cases in which it is not known , we simply apply the iterative root searching algorithm cmplxlaguerre2newton ( see section  [ sec : sgalgorithm ] ) to find two ( now arbitrary ) roots , and use the cubic equation to find the rest .",
    "the two closest roots can then be easily identified .",
    "the algorithm works in 2 modes : `` robust '' , which can be started without any knowledge of the roots , and `` polish '' , which is meant to be used with approximately known roots , e.g. , with roots that come straight from `` robust '' , or come from the previous solution to a similar polynomial .",
    "the flag `` polishonly '' controls the behavior of the subroutine .",
    "we describe both modes in turn , and discuss the failsafe measures that are incorporated in `` polish '' .",
    "we still must start with laguerre s method in `` robust '' mode ( section  [ sec : robust ] ) because it is guaranteed to find a root whereas newton s method is not .",
    "but because of the simplifications of the laguerre calculation , as described in sections  [ sec : lag ] and  [ sec : stop ] , as well as use of the new intermediate method described in section  [ sec : lag2newt ] , equation  ( [ eqn : sg2 ] ) , we are able to cut the time spent in `` robust '' by a factor of @xmath51-@xmath52 in most cases .",
    "this mode assumes that absolutely nothing is known of the location of the roots .",
    "we begin by searching for the first root by applying the previously described general method seeded at ( 0,0 ) .",
    "we then divide the original polynomial by the root and repeat the process to find a second root .",
    "( note that although this process is called root `` division '' , it is actually composed of only multiplications and additions , and is therefore very fast compared to laguerre . ) if one or both of these roots is close to other roots , then root division may introduce substantial errors because these root positions can be determined only to a precision equal to the square - root or cube - root of the underlying numerical precision .",
    "see section  [ sec : errors ] .",
    "so for example , for `` complex*16 '' precision ( with 52 mantissa bits ) , the location of three close roots can have errors up to @xmath53 .",
    "nevertheless , such errors are quite unimportant at this stage because the isolated roots will still be approximately located at the following step when the remaining cubic equation is solved analytically .",
    "this method is guaranteed to find five different roots , unless the source happens to land `` exactly '' ( to numerical precision ) on a caustic .",
    "note that the only real information that will be extracted from this aspect of the subroutine is the approximate position of the three most isolated roots .",
    "the five roots are then fed to the `` polishing '' routine .",
    "as will become clear , it is essential that the fourth and fifth root in this list be the two closest roots .",
    "so we must , at a minimum , locate this pair .",
    "an efficient algorithm for doing so is located in subroutine `` find2closestfrom5 '' .",
    "however , in fact we strictly order _ all _ roots according to which is most isolated .",
    "the distances between all pairs of roots are calculated .",
    "the one whose minimum distance to other roots is the largest is declared most isolated . if two roots are tied ( as will often be the case ) , the honor goes to the root whose second - closest neighbor is more distant .",
    "then other roots are ranked in a similar fashion .",
    "( see subroutine `` sort5pointsbyseparation '' ) .",
    "this is useful for some applications , but increases the run - time of this sub - algorithm by about 5% .",
    "users may therefore decide to substitute the simpler algorithm for finding the closest root pair .",
    "if `` polishonly '' is set to true , then the algorithm described below will be acted upon immediately , starting from the root positions provided in the input array . in the opposite case ,",
    "first the subroutine will carry out the steps from `` robust '' ( section  [ sec : robust ] ) and subsequently send the resulting list of roots to be polished .",
    "the polish algorithm initially assumes that the first three roots in the input list are the most isolated ( but see immediately below ) . then it polishes these using newton s method .",
    "it then successively divides the polynomial by these three polished roots , and solves the remaining quadratic equation to find the last two .",
    "then it checks to make sure that these are in fact the closest pair out of all roots .",
    "of course , if the trial roots come from the `` robust '' algorithm , then this will almost certainly be the case . and",
    "if the trial roots came from a neighboring position on the contour , then it will still almost always be the case . nevertheless , as the source position is moved around a contour , the pairs of roots that had been closest move apart , while others move close together .",
    "therefore , depending on exactly how the contour is sampled , such switches in closest pair may occur a few percent of the time .    when this does occur , the roots are completely reordered according to degree of isolation ( as at the end of section  [ sec : robust ] ) and are re - polished .",
    "a flag `` first3rootsorderchanged '' is set to notify the calling routine that there has been a reordering .",
    "this is because , for contour integration , the calling routine must match roots from one step to the next .",
    "if there has been no reordering , then the first three roots can be assumed to be automatically matched , and it is only necessary to check the final two .",
    "but if the roots have been reordered , then full matching of all roots is required .      as described above ,",
    "if the algorithm is started in `` robust '' mode , the roots will be found with maximum precision , beginning with no information . if the flag is set to do only `` polish '' , then it will achieve the same result with less computation , but only on the condition that the input roots are roughly correct .",
    "if incorrect roots are fed into the `` polish '' routine , it can in principle fail catastrophically in one of two following senses .",
    "first , it may fail to find a root after the prescribed maximum number of iterations ( 50 ) because it is using newton s method rather than laguerre s , which is more robust .",
    "second , two of the first three ( `` isolated '' ) root searches may yield the same root . therefore",
    ", if `` polish '' finds that the last two roots are not the closest , it simply restarts algorithm in the `` robust '' mode .    only when the two last ( `` closest '' ) roots after polishing stay the closest , does the algorithm return without any additional action .",
    "if it was called with the `` polishonly '' flag , it also informs the calling routine that there was no reordering of the first 3 roots .",
    "sending back to `` robust '' may seam very expensive , but this is the only way we can ensure that 5 distinct roots will be returned by the algorithm .",
    "polishing always implies some level of risk of collapsing two roots to the same point , in which case the resulting pair of roots will be the closest pair and the failsafe will be triggered . in the rare case that subsequent polishing , after `` robust '' , is not successful , the algorithm decides to return unpolished roots , since clearly there are some numerical problems , and better accuracy might be hard to achieve .",
    "we note that after the failsafe procedure is triggered , we can still use some of the information gathered during the previous stage to facilitate calculation in robust .",
    "we simply copy two roots found in the polishing stage that did not end up in the closest pair , and use those as a staring points of the two searches in `` robust '' .",
    "this makes the failsafe algorithm much less time demanding than starting the whole routine all over again .",
    "this failsafe feature , which has zero cost for normal polishing , means that the `` polish '' mode can be used for example for point - lens portions of the light curve .",
    "typically , these contain a series of points that are close enough together that only polishing is required .",
    "but for the cases that this proves not to be",
    "so ( for example , the source has passed over a caustic between one night and the next ) , the algorithm itself can figure this out and correct it .",
    "the cost is an extended failed polishing , which can take longer than a simple call to `` robust '' .",
    "however , if it is known that this involves only a few percent of points , this cost would be substantially smaller than the savings .",
    "as we show in section  [ sec : errors ] , for very specific applications , it is warranted to do all polishing numerically rather than using the quadratic equation .",
    "comments in the code can point the reader to specific changes for a `` polish only with newton '' scenario .",
    "notably , there is one more check in the failsafe procedure required in this case . after polishing",
    ", one should check whether the distance between closest pair of roots is smaller than some threshold ( e.g. @xmath54 ) .",
    "if so , this could suggest that two of the roots collapsed during polishing , and polynomial should sent to `` robust '' .      as mentioned in section  [ sec : lensing ] , the hexadecapole approximation is used when the source is too close to a caustic to apply the point - source approximation , but not so close as to require a full finite - source calculation .",
    "it requires 13 calls to the lens solver with a specified geometric distribution @xcite .",
    "all but the first of these can safely use `` polish '' , seeding it with the first set of roots found for the source center .",
    "the combination of substituting `` polish '' for `` robust '' , combined with the improved speed of `` polish '' described in section  [ sec : polish ] , implies an overall factor of 2 - 3 in the root finding speed for hexadecapole calculations . of course , these calculations still require calculation of the magnifications for each of the 13 calls ; these are however much cheaper than locating the roots .",
    "here we derive analytic estimates of the precision achievable when two or three roots are close together and test these numerically .",
    "of course , since the complex plane has no intrinsic scale , one must define `` close '' relative to something . in this case , we mean close relative to some additional ( third or fourth ) root .",
    "suppose that a cubic has roots @xmath55 and @xmath56 , where @xmath57 and @xmath58 .",
    "the polynomial will then have the form @xmath59 we then evaluate the isolated root @xmath56 using newton s ( or laguerre s ) method , but inevitably make an error @xmath60 which is of order of the numerical precision .",
    "next we divide @xmath61 $ ] into @xmath19 so as to obtain the quadratic equation @xmath62 and a possible remainder , which we would be forced to ignore .",
    "this can be solved using the quadratic equation @xmath63 where we have already made use of the fact that @xmath64 to drop a term of order @xmath65 .",
    "considering the two relevant regimes , @xmath66 and @xmath67 and now explicitly evaluating @xmath68 , we see that the error in @xmath69 is of order @xmath70 note , however , that while the errors in the values of these roots scale @xmath71 , the error in the midpoint between the two roots scales @xmath72 , i.e. , it is much smaller .",
    "suppose that a quartic has roots @xmath73 and @xmath56 , where again @xmath57 and @xmath58 and where @xmath74 .",
    "the polynomial will then have the form @xmath75 we again divide by the isolated root , which again is in error by @xmath60 , and obtain the cubic @xmath76 this yields roots @xmath77 which has analogous error properties to equation  ( [ eqn : quaderror1 ] ) , @xmath78    thus , for `` complex*16 '' precision , which contains 52 bits of mantissa , the limiting precision for very close roots is @xmath79 for two close roots ( near a caustic ) when calculated using the quadratic equation , and @xmath80 for three very close roots ( near a cusp ) , when obtained by solving the cubic equation .",
    "we test the accuracy in calculation of close - by roots numerically .",
    "figure  [ fig : errors ] shows typical errors in position estimation of the two close roots when solving the quadratic equation , as well as errors in positions of three close - by roots when solving the cubic equation , as a function of distance between the roots ( @xmath69 ) .",
    "these behave as described by equations  ( [ eqn : quaderror1 ] ) and  ( [ eqn : cuberror1 ] ) , with two regimes clearly visible . for a characteristic scale of the problem @xmath81 , the transition occurs at @xmath82 and @xmath83 , respectively .",
    "we also find ( not shown ) that pushing away one of the three close - by roots results in monotonically increasing accuracy , which bridges the relations for three and two close - by roots .",
    "the choice of origin of the coordinate system has a very low impact on the accuracy achievable by the quadratic and cubic solvers .",
    "this is because the biggest error comes from the division of the polynomial by imperfectly known roots .",
    "however , we noticed that in the case of iterative numerical methods , like newton s method , used on the undivided polynomial , the accuracy depends on the distance of the close - by roots from the origin of coordinates ( @xmath84 ) , scaling as @xmath85 in equation  ( [ eqn : quaderror1 ] ) , for the case of 2 nearby roots , and as @xmath86 in equation  ( [ eqn : cuberror1 ] ) , for the case of 3 nearby roots .",
    "figure  [ fig : origin ] shows how the accuracy improves when we bring the two close roots nearer to the origin of the system and solve them with newton s method ( with undivided @xmath10th order polynomial ) rather than the quadratic equation , obtained by dividing the polynomial by 3 known roots .",
    "similarly , figure  [ fig : origin3 ] shows the case of 3 close - by roots .",
    "note that to take advantage of this feature , one should think in advance about where the close - by roots are expected , and then shift the coordinate system to this point .",
    "however this may not always be possible .",
    "also , this level of accuracy is not usually required for the close - by roots in microlensing .",
    "this impacts only a small number of source positions that are very close to the caustic .",
    "the gain in speed achieved by the use of the cubic and quadratic solvers for all calculated positions , in most cases , is more important that the slight loss of the accuracy for this small subset of points .",
    "however , for certain applications , taking advantage of this behavior can be fruitful .",
    "we checked that we can recover the accuracy of numerical estimation of the roots on the undivided polynomial , when we use quadruple precision for polynomial division . before division , we perform one additional newton step in quadruple precision on each root that will be used in the division .",
    "the resulting quadratic equation can be still solved with double precision without loss of accuracy .",
    "we thank google books for digitizing the world s knowledge and making it public for free , making possible scientific works , such as this one .",
    "we thank wikipedia for providing quick references to historical literature and concise explanations of many mathematical methods . in particular , equation  ( [ eqn : lag ] ) , which played a major role in the genesis of this work ,",
    "was derived from a closely related equation found in wikipedia .",
    "this work was supported by nsf grant ast 1103471 .",
    "we began our investigation of the historical root - solving literature simply to identify proper references to newton , halley , and laguerre .",
    "this proved to be a non - trivial task despite the considerable help provided by several wikipedia entries and by google books .",
    "in the course of reading the various sources , simply to verify that we had found the right ones , we discovered that the method laid out in a work newton claims to have written in 1667 - 1671 @xcite , does not contain `` newton s method '' , nor anything approximating it .",
    "moreover , in this work , newton exhibits the deepest confusion over the relationship between the method he presents and the mathematics that are actually required for `` newton s method '' .",
    "since this method is sometimes referred to as `` newton - raphson '' , we initially thought that these shortcomings would be corrected by @xcite .",
    "however , we found that while raphson s work ( which appears to be completely independent of newton ) is indeed superior to newton s , it still does not approximate `` newton s method '' anywhere closely enough to designate raphson as its discoverer .    eventually , we came upon a biography of thomas simpson , which stated that it was simpson who discovered `` newton s method '' , while newton and raphson had found only algebraic prescriptions for polynomial root solving that did not involve calculus .",
    "this point is indeed central , although the gulf between newton ( and/or raphson ) and `` newton s method '' actually runs much deeper .",
    "the biography gave `` 1740 '' as the date of simpson s discovery , but did not cite a work .",
    "in fact , simpson wrote two works in that year , each several hundred pages , and it proved fairly difficult to locate his description of `` newton s method '' because it is given without benefit of equations ( displayed or otherwise ) .",
    "nevertheless , simpson s description is quite clear ( and quite short ) .",
    "moreover , simpson clearly and correctly states that this is a `` new method '' @xcite .",
    "armed with `` keywords '' from simpson s work , we were able to locate an article by @xcite in the british journal for history of science , which makes the case for simpson s discovery quite clearly :    _ what is today known as `` newton s method of approximation '' has two vital characteristics : it is iterative , and it employs a differential expression .",
    "the latter is simply the derivative @xmath87 of the function , resembling a newtonian fluxion in being based upon a theory of limits but not conceptually identical with it .",
    "the method uses the fundamental equation [ @xmath88 repetitively , inserting at each stage the ( hopefully ) more accurate solution .",
    "this paper will argue that neither of these characteristics applies to the method of approximate solution developed by newton in _ de analysi _ , which also appeared in his _ de methodis fluxionum et serierum inftnitorum _ , and that the method of approximation published by joseph raphson in his _ analysis aequationum universalis _ of 1690 was iterative  indeed was the first such method to be iterative  but was not expressed in derivative or fluxional terms . _    we fully agree with this assessment , and we strongly urge the interested reader to study the entire article , which also contains an excellent discussion of how the myth of newton s discovery of this method was born and how it `` blossomed '' over several hundred years .",
    "however , we would also like to make two points that go beyond kollerstrom s analysis .",
    "first , in addition to the two distinguishing characteristics of `` newton s method '' identified by kollerstrom ( `` iterative '' , and `` differential calculus '' ) , there is a third characteristic that we also regard as essential : the method is applicable to an extremely broad class of functions , essentially all differentiable functions .",
    "now , it is well - known that newton ( and raphson ) only applied their methods to polynomials .",
    "moreover , it can hardly be regarded as a shortcoming that they did so , since the general theory of functions was so weakly developed at this point .",
    "but what does not seem to have been previously appreciated is that their _ methods _ are so specifically designed to solve polynomials that they make use of features of polynomials that do not hold for almost any other function .",
    "therefore , these methods can not be generalized to all functions in anything like their present forms .",
    "that is , they can not be generalized without specifically reformulating them on the basis of differential calculus .",
    "this brings us to the second point .",
    "newton s exposition of his method makes explicit ( in so far as lacun can be explicit ) that he does not understand the relationship between the method he presents and differential calculus .",
    "this is particularly striking to the modern reader , who is aware that newton invented calculus , that `` newton s method '' is about the simplest application of differential calculus imaginable , and that newton was one of the most brilliant mathematicians and physicists of all time , and so naturally assumes that newton _ must _ have been cognizant of this relation , whether explicitly or implicitly .",
    "but this is clearly not the case . in his _ method of fluxions _ , newton presents his extremely clunky , algebraic method for solving polynomials , and then immediately after finishing this section , begins a new section on derivatives , which is quite elegant , including a diagram of a function , with its derivative represented as a tangent , just as appears in countless modern textbooks . indeed , this figure could have just as easily been used to illustrate `` newton s method '' as it is presently understood .",
    "the fact that it was not , virtually proves that newton did not understand this method in anything like its modern form .",
    "our original motivation to write our own root - solving algorithm was not to improve upon zroots , which like @xcite we believed to be essentially impossible .",
    "instead , we merely sought to create a root solver that was sufficiently different from zroots that we could make publicly available some binary - lens code without fear of lawsuit by the authors of _ numerical recipes _ ( nr ) on charges of copyright violation .",
    "the actual outcome of this effort , i.e. , new algorithm with dramatically better performance , confirms ( if such confirmation were needed ) the value of copyright and patent laws in stimulating intellectual innovation .",
    "nevertheless , as important as this stimulus is , we believe that copyright protection of nr algorithms is at this point , on balance , a substantial obstacle to scientific progress .",
    "@xcite have recently argued that `` code discoverability '' is becoming increasingly important to the fundamental criterion for acceptance of scientific conclusions : `` reproducibility of results '' .",
    "this concern can be interpreted narrowly in terms of allowing independent groups to run the same , or slightly modified code , but also more broadly , as making available the entire intellectual basis of a numerical discovery in order to enable and stimulate further advances on the topic .",
    "we urge the interested reader to review this article , which concisely addresses many of the arguments ( aka excuses ) given by numerical researchers for not publishing their codes .",
    "however , at least in astronomy , many codes contain commercial subroutines , and the majority of these are probably from nr .",
    "these can not at present be made public without violating copyright laws .",
    "the general problem here is quite complex since it arises from a conflict of cultures between commercial and non - profit activities in our society .",
    "code development , particularly of the high quality represented by nr , is not free .",
    "it must be supported either by universities and public research organizations , or by private ventures that anticipate revenues to cover the labor invested in writing and distributing the code , as well as normal profit on invested capital .",
    "the former route may be regarded as a `` natural outcome '' of research activity , but in fact is heavily influenced by the whims of faculty - search and p&t committees .",
    "nr is an example of the latter route .",
    "one may argue about whether the degree of remuneration has been appropriate to the effort , but certainly the results of these efforts have had far more positive impact than many activities that are more highly rewarded @xcite    a general solution to this problem is beyond the scope of the present work .",
    "one solution might be to include algorithm purchases on grant proposals ( similar to how computer purchases are presently handled ) , with the stipulation that both the purchased algorithms and the new algorithms covered under the award be made public for applications restricted to those directly traceable to the funded work .",
    "the mere statement of this proposal conveys how difficult it would be to properly formulate in practice .",
    "this is why we do not attempt a general solution here .",
    "however , most immediately , the problem could be solved if the nr authors agreed to make their algorithms available at no cost to non - profit users , with the stipulation that this did not extend to the commercial sector .",
    "it might be possible to do this through specifically worded licensing agreements .",
    "we urge the nr authors to consider such an approach .",
    "we provide two versions of the codes , written in fortran 90 and fortran 77 , for convenience of the users .",
    "both versions have the same set of subroutines , and their output is the same .",
    "sources are located in files : cmplx_roots_sg.f90 and cmplx_roots_sg_77.f . in the package we also provide files called license and notice containing open - source licensing details .",
    "table  [ tab : routines ] list all subroutines provided in the codes with short explanations of their use .",
    "we also list all arguments required to call the routines , as well as their role , type and if they are meant for input only ( `` in '' ) , output only ( `` out '' ) or both ( `` in / out '' ) .",
    "+ 1 & cmplxrootsgen  general complex polynomial solver + & = roots  array of roots , length = degree  ( complex*16 , in / out ) + & = poly  input",
    "polynomial , array length = degree+1 , poly(1 ) is a constant term  ( complex*16 , in ) + & = degree  degree of input polynomial and size of roots array  ( integer , in ) + & = polishrootsafter  turns on polishing , uses undivided polynomial after all roots are found  ( logical , in ) + & = userootsasstartingpoints  if set to .false",
    ". then roots array will be reset to ( 0,0 ) .",
    "otherwise the values in roots will be used as starting points for each root  ( logical , in ) + 2 & cmplxroots5  @xmath10th order polynomial solver for binary lens equation + & = roots  array of roots , length 5  ( complex*16 , in / out ) + & = first3rootsorderchanged ",
    "output flag showing if reordering of roots occurred  ( logical , out ) + & = poly ",
    "input @xmath10th order polynomial , array length 6  ( complex*16 , in ) + & = polishonly  if .true .",
    "then `` robust '' is skipped and algorithm goes to `` polish '' staring from values given in roots array  ( logical , in ) + 3 & sort5pointsbyseparation  this sorts array of 5 points to have the 1st point most isolated , and 4th and 5th being closest + & = points  array to sort , in place  ( complex*16 , in / out ) + 4 & sort5pointsbyseparationi  this sorts array of 5 points by separation , but returns only indices of a sorted array + & = sortedpoints  array of 5 indices that would sort array , 1st index shows the position of most isolated point from array points ",
    "( integer , out ) + & = points  array of points to be sorted , length=5  ( complex*16 , in ) + 5 & find2closestfrom5  routine to find closest pair from set of 5 points .",
    "+ & = i1  index of the one component of the closest pair from array points ",
    "( integer , out ) + & = i2  index of the second component of the closest pair from array points ",
    "( integer , out ) + & = d2min  square of the distance between closest pair of points ",
    "( real*8 , out ) + & = points  array of points , length=5  ( complex*16 , in ) + 6 & cmplxlaguerre  single root finding routine which uses laguerre s method .",
    "+ & = poly  input polynomial , array of length @xmath89 degree+1 ",
    "( complex*16 , in ) + & = degree  degree of polynomial ",
    "( integer , in ) + & = root  on input : a starting point for the algorithm , on output : a found root ",
    "( complex*16 , in / out ) + & = iter  number of laguerre iterations done before returning ",
    "( integer , out ) + & = success  success flag , if number of iteration is higher than specified number .false .",
    "is returned ",
    "( logical , out ) + 7 & cmplxnewtonspec  single root finding routine which uses newton s method .",
    "with modification that stopping criterion is calculated only every 10th step .",
    "+ & = poly  input polynomial , array of length @xmath89 degree+1 ",
    "( complex*16 , in ) + & = degree  degree of polynomial ",
    "( integer , in ) + & = root  on input : a starting point for the algorithm , on output : a found root ",
    "( complex*16 , in / out ) + & = iter  number of newtons iterations done before returning ",
    "( integer , out ) + & = success  success flag , if number of iteration is higher than specified number .false . is returned ",
    "( logical , out ) + 8 & cmplxlaguerre2newton  single root finding routine which uses new dynamic method with three regimes : laguerre , sg and newton .",
    "+ & = poly  input polynomial , array of length @xmath89 degree+1 ",
    "( complex*16 , in ) + & = degree  degree of polynomial ",
    "( integer , in ) + & = root  on input : a starting point for the algorithm , on output : a found root ",
    "( complex*16 , in / out ) + & = iter  number of total iterations done before returning  ( integer , out ) + & = success  success flag , if number of iteration is higher than specified number .false . is returned  ( logical , out ) + & = startingmode  if 2  starts with laguerre s method , if 1  starts with sg , if 0  starts with newton s method  ( integer , in ) .",
    "+ 9 & solvequadraticeq  the analytic solver of quadratic equation . + & = x0  first root ",
    "( complex*16 , out ) + & = x1  second root ",
    "( complex*16 , out ) + & = poly  input polynomial of degree=2 , length @xmath89 3 , poly(1 ) + poly(2 ) @xmath90 + poly(3 ) @xmath91  ( complex*16 , in ) + 10 & solvecubiceq  the analytic solver of cubic equation using lagrange s method .",
    "+ & = x0  first root  ( complex*16 , out ) + & = x1  second root  ( complex*16 , out ) + & = x2  third root ",
    "( complex*16 , out ) + & = poly  input polynomial of degree=3 , length @xmath89 4 ",
    "( complex*16 , in ) + 11 & dividepoly1  division of the polynomial by monomial ( x - p ) . + & = polyout  resulting polynomial after division with degree = degree-1 , array of length @xmath89 degree-1 ",
    "( complex*16 , out ) + & = remainder  remainder from the division ",
    "( complex*16 , out ) + & = p  coefficient in ( x - p ) , i.e. , in monomial by which polyin is divided ",
    "( complex*16 , in ) + & = polyin  input polynomial of a degree = degree , array of length @xmath89 degree ",
    "( complex*16 , in ) + & = degree  degree of the input polynomial ",
    "( integer , in )        abel , n. h.  1826 , `` beweis der unmglichkeit , algebraische gleichungen von hheren graden als dem vierten allgemein aufzulsen . ''",
    "j. reine angew .",
    "math . 1 , 65 . reprinted in abel , n. h. , 1881",
    ", oeuvres completes de niels henrik abel , ed .",
    "l. sylow and s. lie , christiania imprimerie de grndahl & son , oslo .",
    "laguerre , e. , n. , 1880 , nouvelles annales de mathmatiques , 2e srie , t.xix , 87 - 103 , reprinted in laguerre , e. , n. , 1898 , oeuvres de laguerre , eds .",
    "hemrite , h. poincar and e. rouch , acadmie des sciences ( france ) , pp .",
    "87 - 103      newton , i. , 1671 , methodus fluxionum et serierum infinitarum cum ejusdem applicatione ad curvarum geometriam , published in english in newton , i. , 1736 , the methods of fluxions and infiniete series with its application to the geometry of curve - lines , ed . and transl . by john colson , london , henry woodfall , and in latin : newton , i. , 1744 , methodus fluxionum et serierum infinitarum , opuscula mathematica philosophica et philologica , ed .",
    "johann von castillon , apud marcum - michaelem bousquet & socios . ,",
    "volume 1 , op ."
  ],
  "abstract_text": [
    "<S> we present a new algorithm to solve polynomial equations , and publish its code , which is 1.63 times faster than the zroots subroutine that is commercially available from _ numerical recipes _ , depending on application . </S>",
    "<S> the largest improvement , when compared to naive solvers , comes from a fail - safe procedure that permits us to skip the majority of the calculations in the great majority of cases , without risking catastrophic failure in the few cases that these are actually required . </S>",
    "<S> second , we identify a discriminant that enables a rational choice between laguerre s method and newton s method ( or a new intermediate method ) on a case - by - case basis . </S>",
    "<S> we briefly review the history of root solving and demonstrate that `` newton s method '' was discovered neither by newton ( 1671 ) nor by raphson ( 1690 ) , but only by simpson ( 1740 ) . </S>",
    "<S> some of the arguments leading to this conclusion were first given by the british historian of science nick kollerstrom in 1992 , but these do not appear to have penetrated the astronomical community . finally , we argue that _ numerical recipes _ should voluntarily surrender its copyright protection for non - profit applications , despite the fact that , in this particular case , such protection was the major stimulant for developing our improved algorithm . </S>"
  ]
}