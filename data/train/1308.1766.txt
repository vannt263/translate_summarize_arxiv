{
  "article_text": [
    "in this paper , we obtain the limiting spectral distribution ( lsd ) and a system of equations describing the corresponding stieltjes transforms of renormalized sample covariance matrices of the form @xmath23 when @xmath1 and @xmath24 , where @xmath3 has i.i.d .",
    "real or complex entries with zero mean , unit variance and uniformly bounded fourth moment . throughout this paper , for any matrix @xmath25 , we use @xmath26 to denote the complex conjugate transpose of @xmath25 if @xmath25 is complex - valued and transpose of @xmath25 if @xmath25 is real - valued . when @xmath27 as @xmath28 , the spectral properties of the separable sample covariance matrices , @xmath29 have been widely investigated under different assumptions on entries ( e.g. , zhang @xcite , paul and silverstein @xcite , el karoui @xcite ) .",
    "the name `` separable '' refers to the fact that the covariance matrix of the vectorized data matrix @xmath30 has the separable covariance @xmath21 , where @xmath22 denotes the kronecker product between matrices . under those circumstances",
    ", it is known that the spectral norm of @xmath31 does not converge to zero . however , if @xmath2 , @xmath32 .",
    "when @xmath33 and @xmath1 such that @xmath34 , the behavior of empirical spectral distribution ( esd ) of @xmath35 is similar to that of a @xmath36 wigner matrix @xmath37 , which has been verified by bai and yin @xcite . moreover , when @xmath38 , for i.i.d .",
    "real entries and under a finite fourth moment condition , pan and gao @xcite and bao @xcite derived the lsd of @xmath39 , which coincides with that of a generalized wigner matrix @xmath40 studied by bai and zhang @xcite .",
    "our work here extends the former result to a more general setting , namely , when @xmath10 is an arbitrary @xmath11 positive semi - definite matrix whose first two spectral moments converge to finite positive values as @xmath28 , and the entries of @xmath3 are either real or complex .",
    "the strategy of the proof of this result is divided into three parts .",
    "we first assume that the entries of @xmath41 are i.i.d .",
    "gaussian and use a construction analogous to that in pan and gao @xcite to obtain the form of the approximate deterministic equations describing the expected stieltjes transforms , then use a result on concentration of smooth functions of independent random elements to show that the stieltjes transform concentrates around its mean in the general setting ( without the restriction of gaussianity ) , and finally utilize the lindeberg principle to show that the expected stieltjes transforms in the gaussian and in the general case are asymptotically the same . in the process",
    ", we also prove the existence and uniqueness of the system of equations describing the stieltjes transform for an arbitrary @xmath13 , non - degenerate at zero .",
    "further , we state a result characterizing the lsd , including the existence and shape of its density function , by following the approach in bai and zhang @xcite .",
    "we also study the question of fluctuation of the eigenvalues of the sample covariance matrix @xmath42 itself when the esd of @xmath43 say @xmath44 and its limit @xmath13 are finite mixtures of point masses .",
    "specifically , we show that the empirical distribution of @xmath45 , where @xmath19 denotes the @xmath20-th largest eigenvalue , converges a.s . to a mixture of rescaled semi - circle laws with mixture weights being the same as the weights corresponding to the point masses of @xmath13 and the scaling factor depending on the limiting value of @xmath16 and the atoms of @xmath46 .",
    "it should be noted that the data model of the form @xmath47 , where @xmath3 has i.i.d .",
    "entries with zero mean and unit variance , relates very closely to the _ separable covariance model _ widely used in spatio - temporal data modeling , especially for modeling environmental data ( e.g. , kyriakidis and journel @xcite , mitchell and gumpertz @xcite , fuentes @xcite , li et al .",
    "the separable covariance model refers to the fact that for any @xmath48 sampling locations in space , and any @xmath49 observation times , the covariance of the corresponding data matrix can be expressed in the form @xmath50 . in that context",
    ", the rows of @xmath51 correspond to spatial locations while the columns represent the observation times . if furthermore , the process is gaussian , which is often assumed in the literature , then the data matrix @xmath52 is exactly of the form @xmath53 where @xmath5 s are i.i.d .",
    "@xmath54 . assuming a separable covariance structure , that the process is stationary in space , the sampling locations cover the entire spatial region under consideration fairly evenly , and the temporal variation has only short term dependence ( not necessarily stationary ) , the covariance of the observed data can be expressed in the form @xmath55 where @xmath9 and @xmath10 satisfy conditions 3 , 4 and 5 of our main result in this paper ( theorem [ thm : main_lsd ] ) . moreover , if the sampling locations are on a spatial grid , then the matrix of eigenvectors of @xmath56 is approximately the fourier rotation matrix on @xmath57 and the eigenvalues are approximately the fourier transform of the spatial autocovariance kernel evaluated at certain discrete frequencies related to the grid spacings .",
    "there is a body of literature on the statistical inference for a separable covariance model , in particular about the tests for separability of the joint covariance of the data .",
    "notable examples include dutilleul @xcite , lu and zimmerman @xcite , mitchell et al .",
    "( @xcite , @xcite ) , fuentes @xcite , roy and khatree @xcite , simpson @xcite and li et al .",
    "these tests typically assume joint gaussianity of the data and often the derivation of the test statistic requires additional structural assumptions , e.g. , stationarity of the spatial and temporal processes ( fuentes @xcite ) .",
    "in addition , the estimation techniques often involve matrix inversions ( dutilleul @xcite , mitchell et al .",
    "@xcite ) which become challenging if the dimensionality ( either @xmath48 or @xmath49 ) is large .",
    "we study the problem of tests involving the separable covariance structure under the framework @xmath58 and @xmath2 . under this",
    "setting , @xmath59 and hence we can infer about the spectral properties of @xmath9 from that of the sample covariance matrix @xmath60 .",
    "in particular , we propose to use the results derived here to construct test statistic for testing whether the space - time data follows a specific separable covariance model , where the null hypothesis is in terms of specification of @xmath9 and the first two spectral moments of @xmath14 .",
    "let @xmath61 , @xmath62 and @xmath63 be the specified values of @xmath9 , @xmath64 and @xmath65 under the null hypothesis , then this statistic measures the difference of the esd of the matrix @xmath66 , from the lsd of @xmath12 described in ( [ eq : c_n ] ) , where the matrix @xmath41 is assumed to have i.i.d .",
    "entries with zero mean and unit variance , @xmath67 , @xmath68 and @xmath69",
    ". we also propose a monte - carlo method for determination of the cut - off values of the test for any given level of significance and analyze the behavior of the test through simulation .",
    "we also carry out a simulation study with different combinations of @xmath70 to empirically assess the rate of convergence of the esd under to the lsd as measured by the @xmath71 distance between these distributions .",
    "under the framework presented in section [ sec : intro ] , our main result in this paper is about the existence and uniqueness of the lsd of @xmath12 defined through ( [ eq : c_n ] ) .",
    "the result will be described in terms of the stieltjes transform of the matrices .",
    "the stieltjes transform of the empirical spectral distribution @xmath72 is defined as @xmath73 for any @xmath74 .",
    "it will be shown that the esd of @xmath15 will converge almost surely to a distribution @xmath75 whose stieltjes transform is determined by a system of equations .",
    "[ thm : main_lsd ] suppose that    1 .   for every @xmath48 and @xmath49 , @xmath76 is an array of i.i.d real or complex valued random variables with @xmath77 , @xmath78 and @xmath79 ; 2 .",
    "@xmath80 with @xmath81 as @xmath28 ; 3 .",
    "@xmath9 is a @xmath36 nonnegative definite hermitian matrix and @xmath10 is a @xmath11 nonnegative hermitian matrix ; 4 .",
    "the esd @xmath82 as @xmath83 where @xmath46 is a nonrandom distribution function on @xmath84 that is not degenerate at zero ; 5 .",
    "@xmath85 is bounded above , and @xmath86 for @xmath87 converge to finite positive constants as @xmath88 .",
    "then @xmath72 almost surely converges weakly to a nonrandom distribution @xmath75 as @xmath28 , whose stieltjes transform @xmath89 is determined by the following system of equations : @xmath90 for any @xmath91 , where @xmath92 .",
    "[ rem : b_2 ] in ( [ equation_system ] ) , the constant @xmath93 determines the scale of the support of the lsd @xmath75 .",
    "specifically , the lsd @xmath75 is related to the lsd @xmath94 corresponding to the case @xmath95 ( studied by pan and gao @xcite and bao @xcite ) , by @xmath96 for all @xmath97 .",
    "note also that , @xmath94 coincides with the lsd of the generalized wigner matrix @xmath98 analyzed by bai and zhang @xcite .",
    "[ rem : semicircle ] if @xmath99 , the two equations ( [ equation_system ] ) reduce to only one , namely , @xmath100 , which is the equation for a rescaled semi - circle law @xmath101 with scaling factor @xmath102 , where , for any @xmath103 , @xmath104 where @xmath105 denotes the semi - circle law .",
    "notice that , in this case due to the rotational invariance , the statement of the theorem [ thm : main_lsd ] reduces to the statement that the empirical distribution of @xmath106 , converges a.s . to the rescaled semi - circle law with scaling factor @xmath93 .",
    "we present an interesting generalization of this result in section [ subsec : fluctuation_eigenvalues ] .",
    "[ rem : non_hermitian_root ] in the statement of theorem [ thm : main_lsd ] , the matrix @xmath8 needs not be the hermitian square root of @xmath9 . as long as @xmath107 ,",
    "the result will continue to hold .",
    "in particular , @xmath8 can be of the form @xmath108 , where @xmath109 is the spectral decomposition of @xmath9 , so that @xmath110 is a diagonal matrix and @xmath111 .",
    "moreover , from this it also follows that if @xmath112 is a @xmath113 matrix with @xmath114 such that @xmath115 where @xmath116 such that @xmath117 $ ] and @xmath118 then the esd of @xmath119 converges a.s . to the distribution @xmath101 introduced in remark [ rem : semicircle ] .",
    "[ rem : proof_thm ] proof of theorem [ thm : main_lsd ] can be divided into the following parts :    1 .",
    "the spectrum of @xmath9 is truncated at a sufficiently large @xmath120 .",
    "this is done in section [ subsec : truncation_f_a ] , following an approach in bai and yin @xcite .",
    "it is shown that the esd of the @xmath15 and the matrix corresponding to the truncated @xmath9 are almost surely equivalent .",
    "2 .   for each @xmath121 , and for @xmath12 corresponding to matrices with i.i.d . standard gaussian entries , @xmath122 satisfying ( [ equation_system ] ) , which is shown in section [ subsec : deterministic_part ] .",
    "3 .   for each @xmath91",
    ", @xmath123 converges almost surely to zero .",
    "this is derived in section [ subsec : random part ] through the use of mcdiarmid s inequality ( mcdiarmid @xcite ) .",
    "existence and uniqueness of the solution of the system of equations ( [ equation_system ] ) defining the limiting stieltjes transform @xmath89 is established in [ subsec : uniqueness ] .",
    "the entries of @xmath3 are truncated at @xmath124 and centered , where @xmath125 , @xmath126 which does not alter the lsd .",
    "the result is established in the general setting by establishing the asymptotic negligibility of the difference of @xmath127 corresponding to independent copies of @xmath3 with such truncated entries in section [ subsec : nongaussian ] .",
    "the following result characterizes the behavior of the lsd @xmath75 in theorem [ thm : main_lsd ] .",
    "[ prop : lsd_density ] suppose that @xmath128 and let @xmath75 be the lsd of @xmath129 as in theorem [ thm : main_lsd ] .",
    "then , @xmath130 , and for any real @xmath131 , @xmath132 exist such that @xmath133 where @xmath134 uniquely solves @xmath135 while satisfying @xmath136 , @xmath137 and @xmath138 , where @xmath139 moreover , we have    1 .",
    "@xmath140 and @xmath134 are continuous on the real line except only at the origin .",
    "@xmath141 is symmetric and continuously differentiable on the real line except at the origin and its derivative is given by @xmath142 3 .",
    "the support of @xmath75 , say @xmath143 is determined as follows : for any @xmath144 , @xmath145 ( complement of @xmath143 ) if and only if there exists some @xmath146 such that for all @xmath147 , @xmath148 .",
    "the proof of this proposition follows along the line of the proof theorem 1.2 of bai and zhang @xcite with an additional scale factor @xmath149 .",
    "the following lemma , which is a consequence of property ( 3 ) of proposition [ prop : lsd_density ] , provides a way of determining the support of the density function .",
    "[ lemma : density_support ] the support of @xmath150 is the set of @xmath97 satisfying @xmath151 and @xmath152 ( equivalently , @xmath153 ) .    a more direct verification of lemma [ lemma : density_support ] is given in section [ subsec : uniqueness ] .",
    "in certain applications , not only the eigenvalues of @xmath12 but difference of the eigenvalues of @xmath155 from those of @xmath156 may be of interest . since @xmath157 , a.s .",
    ", under the framework @xmath24 , it is expected that the eigenvalues of @xmath155 will fluctuate around the `` corresponding '' eigenvalues of @xmath158 . to make this notion more precise , we consider the setting where there are finitely many distinct eigenvalues of @xmath9 . then for large enough @xmath49",
    ", the eigenvalues of @xmath154 will tend to cluster around these distinct eigenvalues of @xmath159 .",
    "moreover , if both @xmath160 and @xmath85 are bounded , the proportion of eigenvalues falling in each cluster will coincide with the proportion of the corresponding eigenvalue of @xmath9 in the esd of @xmath9 .",
    "this can be seen as an instance of the spectrum separation phenomenon studied by bai and silverstein @xcite for sample covariance matrices in the setting @xmath161 .",
    "our goal in this subsection is to establish that , if @xmath162 is bounded , and if the probability distribution of the entries of @xmath41 has sufficiently fast decay in the tails ( specifically , `` sub - gaussian tails '' ) , then the fluctuations of the eigenvalues of @xmath155 around the eigenvalues of @xmath159 can be fully characterized , provided @xmath9 has finitely many distinct eigenvalues , the proportion of each of which converges to a nonzero fraction .    to state the result",
    ", we first define a sub - gaussian random vector ( cf .",
    "vershynin @xcite ) .",
    "a real - valued random vector @xmath163 is said to be sub - gaussian with scale parameter @xmath164 , if for all @xmath165 , @xmath166 \\leq \\exp(\\parallel",
    "\\gamma \\parallel^2 \\sigma^2/2).\\ ] ] clearly , if @xmath167 has independent coordinates each of which is sub - gaussian with scale parameter @xmath168 , then @xmath167 is sub - gaussian .",
    "moreover , it is easy to see that if @xmath167 is sub - gaussian with scale parameter @xmath168 , then for any @xmath169 matrix @xmath170 , the vector @xmath171 is also sub - gaussian , with scale parameter @xmath172 . a complex - valued random vector is sub - gaussian if and only if both real and imaginary parts of the vector are sub - gaussian .    [ thm : eigenvalue_fluctuations ]",
    "let @xmath10 be a @xmath11 positive semi - definite matrix such that @xmath85 is bounded above , @xmath173 and @xmath174 as @xmath28 .",
    "let @xmath9 be a @xmath36 positive semidefinite matrix with @xmath175 distinct eigenvalues @xmath176 such that @xmath177 is bounded above and @xmath175 is fixed , and if @xmath178 denotes the multiplicity of @xmath19 , then @xmath179 for all @xmath20 , as @xmath83 .",
    "let @xmath180 where @xmath3 is a @xmath4 matrix with i.i.d . real or complex sub - gaussian entries @xmath5 satisfying @xmath181 and @xmath182 . in the complex case , we also suppose that the real and imaginary parts of @xmath5 are independent with variance @xmath183 each .",
    "let @xmath184 , and let @xmath185 denote the @xmath20-th largest eigenvalue of a hermitian matrix @xmath170 . then , as @xmath186 such that @xmath187 , the empirical distribution of @xmath188 converges a.s . to a nonrandom probability distribution @xmath75 on @xmath189 which can be expressed as @xmath190 where @xmath191 , for any @xmath103",
    ", is defined in ( [ eq : scaled_semi_circle_law ] ) .",
    "[ rem : eigenvalue_fluctuations ] the assumption of sub - gaussianity of the entries in theorem [ thm : eigenvalue_fluctuations ] is not necessary if @xmath192 . in that case , if we only assume the finiteness of @xmath193 , it can be shown that the empirical distribution of @xmath188 converges in probability to the same limit law .",
    "this is because , as is seen from the proof given in section [ sec : proof_eigenvalue_fluctuations ] , without loss of generality assuming @xmath194 , the conclusion follows upon showing that @xmath195 , which can be majorized by @xmath196 , where @xmath197 denotes the frobenius norm .",
    "the latter is @xmath198 under the stated conditions . a stronger conclusion ( in the form of a.s .",
    "convergence ) can be made with appropriately higher moment conditions .",
    "the results in the previous subsections allow us to develop a test for the hypothesis that data matrix @xmath52 has a specific separable covariance structure .",
    "suppose that the vectorized @xmath52 has joint covariance @xmath199 .",
    "then our null hypothesis is that @xmath200 where @xmath201 , @xmath202 and @xmath203 are specified .",
    "note that @xmath204 and @xmath205 can be seen as the ( limiting ) values of @xmath206 and @xmath207 , respectively , where @xmath208 is the covariance of the data @xmath52 under @xmath209 .",
    "thus , @xmath209 is a composite hypothesis about @xmath199 .",
    "also note that , testing for @xmath209 is not the same as testing for separability of the data model since in our setting @xmath9 needs to be specified . later in this subsection , we discuss potential extensions of the proposed test procedure for dealing with the null hypothesis of separability , under certain weaker restrictions on @xmath9 .",
    "we propose a test statistic that measures the closeness of the empirical spectrum to the theoretical spectral density under the null hypothesis .",
    "if the data matrix is endowed with the assumed covariance structure in @xmath209 , theorem [ thm : main_lsd ] guarantees the convergence of esd of @xmath12 to an lsd .",
    "in fact , proposition [ prop : lsd_density ] gives an explicit expression for the aforementioned lsd @xmath75 .",
    "equipped with this result , in this paper , we propose and study the following test statistics based on the @xmath71 metric : @xmath210 is the esd of @xmath12 defined by ( [ eq : c_n ] ) when @xmath211 .",
    "another possible test statistic is a crmer - von mises - type statistic @xmath212 or @xmath213 , we need to obtain the distribution of the test statistics under @xmath209 . at this point",
    ", we do not have any result on the asymptotic distribution of these test statistics .",
    "however , it can be seen that under @xmath214 , both test statistics converge to zero as @xmath215 . in this paper",
    ", we propose a monte - carlo approximation of the null distribution of @xmath216 .",
    "a similar strategy applies to @xmath213 . implementing these tests",
    "require computing the esd @xmath217 of the matrix @xmath218 , which is obtained by setting @xmath219 and @xmath220 in the definition of @xmath12 in ( [ eq : c_n ] ) , and where @xmath41 is chosen to have i.i.d . @xmath54",
    "notice that , @xmath209 does not specify @xmath221 completely , but only specifies its first two spectral moments .",
    "thus , while carrying out this simulation , we need to construct an appropriate @xmath221 whose first two spectral moments are @xmath204 and @xmath205 respectively .",
    "we construct @xmath221 of the form ( assuming , for simplicity , @xmath49 to be even ) @xmath222 and solve the equations @xmath223 and @xmath224 to obtain @xmath225 and @xmath226 .",
    "in section [ sec : simulation ] we conduct a simulation study which shows that the the histogram of the lsd of @xmath227 is very close to the theoretical density function [ eq : density ] of the lsd @xmath228 under @xmath214 .",
    "in addition , the distribution of @xmath216 under @xmath209 and @xmath229 are well - separated as @xmath230 and @xmath24 .",
    "we do not present simulation results involving the statistic @xmath231 due to space constraints , even though the qualitative behavior is similar .    even though the proposed procedure does not test the separability of the covariance matrix of the data , we comment on the possibility of extending this test procedure to deal with some special cases of the latter scenario .",
    "the implementation of these is beyond the scope of this paper . the corresponding null hypothesis for the test of separability would be : @xmath232 where @xmath9 and @xmath10 are unknown positive semi - definite matrices satisfying that the esd @xmath233 converges to a distribution non - degenerate at zero , and @xmath234 and @xmath235 for some @xmath236 .",
    "the requirement @xmath237 is to ensure identifiability . in this case , under certain special structural assumptions on @xmath9 , it may still be possible to obtain fairly accurate estimates of @xmath9 and @xmath93 , which can then be used in the expression for @xmath238 or @xmath213 in place of @xmath61 and @xmath239 to construct a test for separability .",
    "one typical assumption in spatio - temporal statistics is that the process is stationary either in space or time . in the current",
    "setting , if we assume that the process is row - stationary , then the eigenvectors of @xmath9 can be well - approximated in a discrete fourier basis .",
    "if in addition , the corresponding spectrum of @xmath9 is piecewise constant , then we can estimate the spectrum of @xmath9 from the data as follows .",
    "first we can perform an orthogonal or unitary transformation of the data in the ( approximate ) eigen - basis of @xmath9 .",
    "then , we can apply a clustering procedure , and estimate the distinct eigenvalues as the means of the individual clusters , and assign the eigenvectors to these clusters according to the cluster membership of the coordinates of the rotated data matrix . another way to broaden",
    "the class of models under the null hypothesis is to remove the specification of @xmath93 .",
    "if either the eigenvalues of @xmath9 are known or they can be estimated accurately from the data , subject to some knowledge about the fourth moment of the entries of the data matrix , @xmath93 can be estimated by making use of the expression for @xmath240 in terms of the first two spectral moments of @xmath9 and @xmath10 .    if @xmath9 is unknown but has a relatively small number of distinct eigenvalues , those eigenvalues can be estimated as mean or median of the clusters of eigenvalues of @xmath154 , without requiring any knowledge of the eigenvectors of @xmath9 , by making use of theorem [ thm : eigenvalue_fluctuations ] .",
    "if @xmath46 is a finite mixture of point masses , then the density function of the lsd @xmath75 in theorem [ thm : main_lsd ] can be computed numerically by making use of proposition [ prop : lsd_density ] and lemma [ lemma : density_support ] .",
    "this computation is used to simulate the distribution of the test statistic @xmath238 in section [ sec : simulation ] . according to [ prop : lsd_density ] , the main ingredient of the computation of @xmath241 , the p.d.f . of @xmath75 , is the determination of the function @xmath242 which solves the equation ( [ eq : beta_x_equation ] ) .",
    "when @xmath46 is a finite mixture of point masses , the latter reduces to a polynomial in @xmath134 . in order to determine @xmath150",
    ", we need to isolate the roots that satisfy the constraints @xmath243 , @xmath137 and @xmath244 , where @xmath245 is given by ( [ eq : omega_x_equation ] ) , as stated in proposition [ prop : lsd_density ] .",
    "indeed , the support of @xmath134 can be determined by the condition @xmath246 , as stated in lemma [ lemma : density_support ] . in practice",
    ", we numerically solve for the appropriate root of @xmath134 for a grid of points @xmath247 by searching through all possible solutions of the polynomial satisfied by @xmath134 and checking the conditions , as well as making use of the continuity of @xmath134 on each side of the origin .",
    "then we can derive the density function @xmath150 by utilizing ( [ eq : density ] ) .",
    "our approach for proving theorem [ thm : main_lsd ] is to first restrict to gaussian observations and utilize the rank - one perturbation method used in bai and yin @xcite and pan and gao @xcite .",
    "however , the decompositions under the separable case require a slightly different treatment from the aforementioned references . the extension of the result to non - gausssian settings is handled in section [ subsec : nongaussian ] through through a use of the lindeberg principle ( see chatterjee @xcite ) .",
    "another potential route to prove this result is through the generalized stein s equations used in pastur and shcherbina @xcite and bao @xcite .",
    "we begin with a truncation of the spectrum of @xmath9 .",
    "let @xmath248 be a positive number such that @xmath249 .",
    "define @xmath250 and suppose that @xmath251 as @xmath88 .",
    "let @xmath252 be such that @xmath120 is a continuity point of @xmath46 , the lsd of @xmath9 .",
    "let @xmath253 since @xmath254 with @xmath255 , then defining @xmath256 , @xmath257 , and @xmath258 , we have @xmath259 further , defining @xmath260 , we have @xmath261 by choosing @xmath262 to be large enough , @xmath263 can be made arbitrarily small .",
    "thus , combining the above two inequalities , we can show that , for any given @xmath264 , there exists a large enough @xmath262 such that @xmath265 also , in section [ subsec : uniqueness ] , we show that the solution of ( [ equation_system ] ) is unique and has a continuous dependence on @xmath46 .",
    "thus , since @xmath266 converges to @xmath46 in distribution as @xmath267 , in order to prove theorem [ thm : main_lsd ] , it is enough to show that @xmath268 converges almost surely to @xmath75 , and @xmath75 has the stieltjes transform @xmath89 determined by ( [ equation_system ] ) with @xmath269 , for any fixed positive @xmath262 so that @xmath266 is not degenerate at zero . for notational convenience ,",
    "henceforth , we still use @xmath9 and @xmath15 instead of @xmath270 and @xmath271 , respectively , and simply assume that of @xmath272 for an arbitrary positive constant @xmath262 .      in this subsection",
    ", we derive asymptotic expansion for @xmath127 when @xmath41 is assumed to have i.i.d .",
    "standard normal entries .",
    "let @xmath273 with @xmath274 denoting the spectral decomposition of @xmath9 .",
    "then we have @xmath275 where @xmath276 and @xmath277 .",
    "let @xmath278 denote the @xmath279-th column of @xmath280 , where @xmath281 is the @xmath279-th column of @xmath282 note that @xmath283 has i.i.d gaussian entries with mean zero and variance one .",
    "moreover , denote by @xmath284 the matrix obtained from @xmath283 with the @xmath279-th row replaced by zero .",
    "then @xmath285 we introduce the following quantities : @xmath286 where @xmath287 is supposed to be a canonical unit @xmath288 vector with the @xmath279-th element being @xmath289 and all others @xmath290 .",
    "then , notice that @xmath291 , for all @xmath279 .",
    "thus , @xmath292 .",
    "since , @xmath293 , we have @xmath294 from the structure of @xmath295 and @xmath296 , we observe that @xmath297 for any non - negative definite @xmath36 hermitian matrix @xmath170 , define @xmath298 .",
    "then it follows that @xmath299 + \\omega_{k}^{*}y_{(k)}^{-1}(z)\\underline{d}e_{k}\\nonumber\\\\ & : = & { \\expandafter\\@slowromancap\\romannumeral 1@}+{\\expandafter\\@slowromancap\\romannumeral 2@}.\\end{aligned}\\ ] ] when @xmath300 , the term @xmath301 in ( [ plug in formula ] ) equals zero since by ( [ eq : y_identity ] ) , @xmath302 . plugging this into ( [ expression for st ] ) , and using @xmath303 , we get @xmath304 moreover , with the expression given by ( [ expression for st ] ) and ( [ plug in formula ] ) , we similarly have @xmath305 define @xmath306 when @xmath307 , so that @xmath308 , from ( [ eq : trace_resolvent_d ] ) , we get @xmath309 in order to derive explicit expressions for @xmath310 and @xmath311 , we still need a further approximation of @xmath312 .",
    "indeed , @xmath313 where @xmath314 and @xmath315 . note that @xmath316 which shows that the term @xmath317 in ( [ eq : beta_n_repr ] ) can be approximated by @xmath318 .",
    "hence we can derive convenient representations for @xmath319 and @xmath320 though this approximation and show that the remainder terms are negligible .",
    "let @xmath321 then , from ( [ eq : beta_n_repr ] ) we can write @xmath322 taking expectation on both sides , @xmath323 where @xmath324 by ( [ expectation equation of beta ] ) , to show the convergence of the expected stieltjes transform to @xmath325 satisfying ( [ equation_system ] ) , it suffices to show that @xmath326 . rewrite @xmath327 as @xmath328 first , by ( [ eq : quadratic term ] ) ,",
    "the fact that @xmath329 , and ( [ eq : y_identity ] ) , @xmath330\\right)\\right| \\nonumber\\\\ & = & \\frac{\\bar{b}_{2}(n)\\lambda_{k}}{p}\\left|{\\mathbb{e}}\\left ( \\tr\\left[y^{-1}(z)\\lambda\\right ] -\\tr\\left[y^{-1}_{(k)}(z)(\\lambda-\\lambda_{k}e_{k}e_{k}^{t})\\right]\\right ) \\right| \\nonumber\\\\ & = & \\frac{\\bar{b}_{2}(n)\\lambda_{k}}{p}\\left|{\\mathbb{e}}\\tr\\left[\\left((y^{-1}(z)-y_{(k)}^{-1}(z)\\right)\\lambda\\right ] + \\lambda_{k } { \\mathbb{e}}\\left(e_{k}^{t } y_{(k)}^{-1}(z)e_{k}\\right)\\right| \\nonumber\\\\ & \\leq & \\frac{\\bar{b}_{2}(n)\\lambda_{k}}{p}{\\mathbb{e}}\\left|\\tr\\left[\\left((y^{-1}(z)-y_{(k)}^{-1}(z)\\right)\\lambda\\right ] \\right| + \\frac{\\bar{b}_{2}(n)\\lambda_k^2}{p|z| } \\nonumber\\\\ & \\leq & \\frac{m}{p}~,\\end{aligned}\\ ] ] which follows from the fact that @xmath331\\right|\\leq \\frac{m}{p},\\ ] ] ( see appendix [ attach_estimation ] ) and that @xmath332 since @xmath333 and @xmath334 . note that @xmath335 thus , combining with ( [ eq : e_epsilon_k_bound ] ) , we conclude that @xmath336 as @xmath88 .    on the other hand , @xmath337 hence , to derive @xmath338 we only need to prove @xmath339 .",
    "let @xmath340\\right|^2\\\\ & + & { \\mathbb{e}}\\left|\\bar{b}_{2}(n)\\frac{\\lambda_{k}}{p}tr\\left[y^{-1}_{(k)}(z)\\lambda_{(k)}\\right]-\\bar{b}_{2}(n)\\frac{\\lambda_{k}}{p}{\\mathbb{e}}tr\\left[y^{-1}_{(k)}(z)\\lambda_{(k)}\\right]\\right|^2\\\\ & : = & d_{31}+d_{32}\\end{aligned}\\ ] ] where @xmath341 and @xmath342 ( see appendix [ d_31 ] and [ d_32 ] for details ) . then , we can conclude that @xmath343 based on the fact that @xmath344 .    repeating the same arguments , we can derive the following equation for @xmath319 given by @xmath345 where @xmath346 as @xmath88 .",
    "we proceed to the almost sure convergence of the random parts , i.e. , for any @xmath348 @xmath349 when the entries of @xmath3 are i.i.d .",
    "standardized random variables with arbitrary distributions . to derive above",
    "almost sure convergence , we first get a concentration inequality by using the following lemma ( known as mcdiarmid s inequality ) and then finish the proof through borel - cantelli lemma .",
    "[ lem : mcdiarmid ] ( mcdiarmid inequality @xcite :) let @xmath350 be independent random vectors taking values in @xmath351 .",
    "suppose that @xmath352 is a function of @xmath350 satisfying @xmath353 @xmath354 then for all @xmath355 @xmath356        in this subsection , we prove the existence and uniqueness of a solution to ( [ equation_system ] ) and its continuous dependence on @xmath46 . assuming first that this is established , we show that @xmath400 and @xmath401 for all @xmath402 . since @xmath403 is bounded for @xmath402 , by considering any subsequence such that @xmath320 converges , from ( [ expectation equation of beta ] ) , using the dominated convergence theorem , we obtain that @xmath404 converges to @xmath325 satisfying ( [ equation_system ] ) .",
    "then by the fact that @xmath405 , we establish the first assertion .",
    "again , since @xmath406 is bounded and @xmath407 , by the dominated convergence theorem and using ( [ eg : expectation_s_n_z ] ) , @xmath408 , which results in the second assertion by invoking the fact that @xmath409 . note that this completes the proof of theorem [ thm : main_lsd ] when the entries of @xmath3 are i.i.d .",
    "standard gaussian .",
    "in order to establish the existence and uniqueness of a solution of ( [ equation_system ] ) , first use the equation for @xmath325 to write @xmath410 the two sides of the last equality gives the following equivalent representation of ( [ equation_system ] ) : @xmath411 we will show that if @xmath46 is not the degenerate distribution at zero , we have @xmath412 so that there is a solution , and that there is a unique @xmath325 satisfying ( [ equation_system_combined ] ) .",
    "let @xmath413 .",
    "in view of establishing the continuous dependence of @xmath325 , and hence @xmath89 , on @xmath46 , suppose that there is another distribution @xmath414 , also non - degenerate at zero . and",
    "let , @xmath415 satisfies @xmath416 then we have @xmath417 where @xmath418",
    "let @xmath419 @xmath420 we have @xmath421 and @xmath422 by cauchy - schwarz inequality , @xmath423^{1/2 } \\left [ \\int \\frac{\\bar{b}_{2}a^{2}df^{a}(a)}{|z+\\bar{b}_{2}a\\beta^{0}(z)|^{2}}\\right]^{1/2}\\\\ & = & \\left(\\frac{\\beta_{2}\\omega(z)}{\\beta_{2}\\omega(z)+v\\tau(z)}\\right)^{1/2 } \\left(\\frac{\\beta^{0}_{2}\\omega^{0}(z)}{\\beta^{0}_{2}\\omega_{0}(z)+v\\tau^{0}(z)}\\right)^{1/2}\\\\ & < & 1.\\end{aligned}\\ ] ] the last inequality holds is due to the fact that for @xmath424 , @xmath425 which implies @xmath426 and it also holds that @xmath427 from ( [ eq : uniqueness_on_beta_n ] ) we have @xmath428 from which the uniqueness of the solution @xmath325 follows .",
    "if @xmath414 is not degenerate at zero , then the integrand ( [ eq : difference_beta_beta_zero ] ) is a bounded ( and continuous ) function of @xmath429 , which establishes the continuous dependence of @xmath325 on @xmath46 through the characterization of distributional convergence . to see this , note that @xmath430 implies that for all @xmath431 , @xmath432 where @xmath25 is large enough that the denominator in the last expression is positive . on the other hand , for @xmath433 , @xmath434 since @xmath435 by ( [ eg : expresssion_tau_0 ] ) and ( [ eq : omega_0 ] ) .",
    "now , to prove ( [ uniq ] ) , we write @xmath436 where @xmath437 \\left[\\bar{b}_{2}t\\int\\frac{a(u+\\bar{b}_{2}a\\beta_{1})df^{a}(a)}{|z+\\bar{b}_{2}a\\beta(z)|^{2 } } - u + i\\left(\\bar{b}_{2}t\\int\\frac{a(v+\\bar{b}_{2}a\\beta_{2})df^{a}(a)}{|z+\\bar{b}_{2}a\\beta(z)|^{2}}+v\\right)\\right]\\\\ & = & \\left [ ( u+\\bar{b}_{2}t\\beta_{1})\\left(\\bar{b}_{2}t\\int\\frac{a(u+\\bar{b}_{2}a\\beta_{1})df^{a}(a)}{|z+\\bar{b}_{2}a\\beta(z)|^{2}}-u\\right ) + ( v+\\bar{b}_{2}t\\beta_{2})\\left(\\bar{b}_{2}t\\int\\frac{a(v+\\bar{b}_{2}a\\beta_{2})df^{a}(a)}{|z+\\bar{b}_{2}a\\beta(z)|^{2}}+v\\right)\\right]\\\\ & & - i\\left[(u+\\bar{b}_{2}t\\beta_{1})\\left(\\bar{b}_{2}t\\int\\frac{a(v+\\bar{b}_{2}a\\beta_{2})df^{a}(a)}{|z+\\bar{b}_{2}a\\beta(z)|^{2}}+v\\right ) -(v+\\bar{b}_{2}t\\beta_{2})\\left(\\bar{b}_{2}t\\int\\frac{a(u+\\bar{b}_{2}a\\beta_{1})df^{a}(a)}{|z+\\bar{b}_{2}a\\beta(z)|^{2}}-u\\right)\\right]\\end{aligned}\\ ] ] from the fact that @xmath438 , we have @xmath439 . then , if @xmath440 and @xmath441 are either both nonpositive or both nonnegative , then @xmath442 is positive . else ,",
    "if these two terms have opposite signs , the imaginary part of @xmath443 is non - zero . therefore ( [ uniq ] ) is established .    .15 in finally , we give the proof of lemma [ lemma : density_support ] based on the facts given in this subsection .",
    "[ support_proof ] by ( [ imaginary part of beta ] ) , taking @xmath444 ( since @xmath445 ) , we have @xmath446 , which shows that , @xmath447 if and only if @xmath448 .",
    "this , together with ( [ eq : density ] ) , shows that @xmath449 if and only if @xmath450 and @xmath448 , i.e. , if @xmath447 .      in this section",
    ", we will prove the theorem [ thm : main_lsd ] for non - gaussian observations through the lindeberg s replacement strategy ( see chatterjee @xcite ) .",
    "as a first step , we perform a truncation , centering and rescaling of the entries of @xmath3 .",
    "let @xmath451 and @xmath452 , where @xmath453 is chosen to satisfy @xmath454 and @xmath455 .",
    "define @xmath456 then according to bai and yin @xcite , by applying a rank inequality and the bernstein s inequality , we get @xmath457 for notational simplicity , the truncated , centered and rescaled variables are henceforth still denoted by @xmath5 and we henceforth assume that @xmath5 s are i.i.d . with @xmath458 , @xmath459 , @xmath460 and @xmath461 for some @xmath462 .",
    "define @xmath463 where the entries of @xmath464 are i.i.d gaussian random variables with @xmath465 and @xmath466 .",
    "suppose @xmath467 are independent of @xmath5 defined in theorem [ thm : main_lsd ] .",
    "the key step is to estimate the difference of @xmath468 and to show that it converges to 0 as @xmath469 .",
    "in fact , the gaussianity of @xmath467 is not used in the proof , only moment conditions on @xmath467 are required . to apply the lindeberg principle",
    ", we denote @xmath470 and @xmath471 let @xmath472 , for each @xmath473 define @xmath474 and @xmath475 suppose that @xmath476 is defined as @xmath477 where @xmath478 , where the @xmath364 matrix @xmath479 is obtained by converting the @xmath480 vector @xmath167",
    ". then @xmath481 and @xmath482 .",
    "so we rewrite the difference as @xmath483-{\\mathbb{e}}\\left[\\frac{1}{p}\\tr(\\widetilde{c}_{n}-zi)^{-1}\\right ] = \\sum_{i=1}^{m}{\\mathbb{e}}\\left[f(z_{i})-f(z_{i-1})\\right].\\ ] ] since @xmath241 is thrice continuously differentiable , a third order taylor expansion yields : @xmath484 and @xmath485 where @xmath486 denotes the @xmath487-fold partial derivative ( @xmath488 ) with respect to the @xmath365-th coordinate and @xmath489 and @xmath490 since both @xmath491 and @xmath492 have zero mean and unit variance and are independent of @xmath493 , the expectation of first order and second order terms in ( [ taylor1 ] ) and ( [ taylor2 ] ) are zero .",
    "thus ( [ difference on resolvent ] ) becomes @xmath494 = \\frac{1}{2}\\sum_{i=1}^{m}{\\mathbb{e}}\\left[y_{i}^{3}\\int_{0}^{1}(1-t)^{2}{\\partial}_{i}^{3}f\\left(z_{i}^{(1)}(t)\\right)dt - { \\widetilde{y}}_{i}^{3}\\int_{0}^{1}(1-t)^{2}{\\partial}_{i}^{3}f\\left(z_{i-1}^{(2)}(t)\\right)dt\\right].\\ ] ]    in the following , to avoid complicated notations , unless otherwise specified , we will use the notation @xmath5 to mean either @xmath5 or @xmath467 since their role will be only in terms of providing bounds for the expected values of the remainder terms in the expansion above .",
    "@xmath3 will be used to denote a matrix containing the corresponding mixed terms .",
    "the properties of these random variables that we will use are that they are independent , have zero mean and unit variance , and are sub - gaussian ( bounded in case of @xmath5 s ) . accordingly , let @xmath495 . to derive a bound for the terms involving @xmath496 , @xmath87 ,",
    "we need a bound on @xmath497 $ ] . since @xmath498",
    ", we get @xmath499 = \\frac{6}{p}\\tr\\left[\\frac{{\\partial}c_{n}}{{\\partial}x_{ij}}g_{n}\\frac{{\\partial}^2 c_{n}}{{\\partial}x_{ij}^{2}}g_{n}^{2}\\right ] - \\frac{6}{p}\\tr\\left[\\frac{{\\partial}c_{n}}{{\\partial}x_{ij}}g_{n}\\frac{{\\partial}c_{n}}{{\\partial}x_{ij}}g_{n}\\frac{{\\partial}c_{n}}{{\\partial}x_{ij}}g_{n}^2\\right].\\ ] ] where @xmath500 and @xmath501 in which @xmath502 is a @xmath288 unit vector and @xmath503 is a @xmath504 unit vector .",
    "let @xmath505 and @xmath506 .",
    "the first term in ( [ third_derivative ] ) becomes @xmath507 & = & \\frac{12b_{jj}}{np^2}\\left[\\xi_{i}^{*}g_{n}^{2}\\xi_{i}\\xi_{i}^{*}g_{n}r_{j}\\right ] + \\frac{12b_{jj}}{np^2}\\left[r_{j}^{*}g_{n}\\xi_{i}\\xi_{i}^{*}g_{n}^{2}\\xi_{i}\\right]\\nonumber\\\\ & : = & \\eta_{1}(n)+\\eta_{2}(n)\\end{aligned}\\ ] ] and the second term in ( [ third_derivative ] ) becomes @xmath508 & = & \\frac{1}{n^{3/2}p^{5/2 } } \\tr\\left[(r_{j}\\xi_{i}^ { * } + \\xi_{i}r_{j}^{*})g_{n}(r_{j}\\xi_{i}^ { * } + \\xi_{i}r_{j}^{*})g_{n}(r_{j}\\xi_{i}^ { * } + \\xi_{i}r_{j}^{*})g_{n}^{2}\\right]\\\\ & : = & 2\\eta_{3}(n)+2\\eta_{4}(n)+2\\eta_{5}(n)+2\\eta_{6}(n)\\end{aligned}\\ ] ] where @xmath509\\\\ \\eta_{4}(n ) & = & \\frac{1}{n^{3/2}p^{5/2}}\\left[r_{j}^{*}g_{n}\\xi_{i}r_{j}^{*}g_{n}r_{j}\\xi_{i}^{*}g_{n}^{2}\\xi_{i}\\right]\\\\ \\eta_{5}(n ) & = &   \\frac{1}{n^{3/2}p^{5/2}}\\left[r_{j}^{*}g_{n}r_{j}\\xi_{i}^{*}g_{n}\\xi_{i}r_{j}^{*}g^{2}_{n}\\xi_{i}\\right]\\\\ \\eta_{6}(n)&= & \\frac{1}{n^{3/2}p^{5/2}}\\left[\\xi_{i}^{*}g_{n}\\xi_{i}r_{j}^{*}g_{n}\\xi_{i}r_{j}^{*}g^{2}_{n}r_{j}\\right].\\end{aligned}\\ ] ] to complete the proof , we need the following lemma whose proof is given in the appendix .",
    "[ lem : estimation_r ] for any positive number @xmath510 , @xmath511 for some positive constant @xmath512 .    to estimate ( [ difference on resolvent ] ) , we need to find appropriate bounds for @xmath513 and @xmath514 .",
    "note that for @xmath515 , @xmath516 ) lemma [ lem : estimation_r ] gives , for @xmath87 , @xmath517\\leq \\frac{m}{np^2}\\left[{\\mathbb{e}}|x_{ij}|^{4}\\right]^{3/4 } \\left[{\\mathbb{e}}\\|r_{j}\\|^{4}\\right]^{1/4}\\leq \\frac{m}{np^{3/2}}.\\ ] ] for @xmath518 we have @xmath519 since @xmath520 and ( [ eta_3 ] ) , by using cauchy - schwarz inequality and lemma [ lem : estimation_r ] we have @xmath521 & \\leq & \\frac{m}{n^{3/2}p^{5/2}}{\\mathbb{e}}\\left[|x_{ij}|^{3}\\|r_{j}\\|^{3}\\right]\\\\ & \\leq&\\frac{m}{n^{3/2}p^{5/2}}\\left[\\left({\\mathbb{e}}|x_{ij}|^{6}\\right)^{1/2}\\left({\\mathbb{e}}\\|r_{j}\\|^{6}\\right)^{1/2}\\right]\\\\ & \\leq&\\frac{m}{n^{3/2}p}\\left[{\\mathbb{e}}|x_{ij}|^{4}\\right]^{1/2}n^{1/4}\\epsilon_{p}\\\\ & \\leq & \\frac{m\\epsilon_{p}}{n^{5/4}p}.\\end{aligned}\\ ] ] therefore , by applying ( [ eta_3 ] ) and lemma [ lem : estimation_r ] , it also holds for @xmath522 that @xmath523=o(\\epsilon_{p}n^{-5/4}p^{-1})$ ] .",
    "if instead of @xmath5 the terms involved were @xmath467 , we could simply use the fact that all moments of @xmath467 are finite to reach the same conclusion .",
    "thus , combining the bounds , ( [ difference on resolvent ] ) can be bounded by @xmath524dt\\leq m \\max\\{n^{-1/4}\\epsilon_{p},p^{-1/2 } \\}\\to 0.\\ ] ] this completes the proof of theorem [ thm : main_lsd ] .      without loss of generality",
    ", we can take @xmath525 for @xmath526 , where @xmath527 $ ] is a @xmath36 unitary matrix where @xmath528 is a @xmath529 matrix , so that @xmath530 for @xmath531 and @xmath532 for @xmath533 .",
    "thus , the data matrix @xmath52 can be expressed as @xmath534 assume that @xmath10 is a @xmath11 matrix such that @xmath535 .",
    "then the sample covariance matrix @xmath536 with mean @xmath537 can be expressed as @xmath538 as a first step , we define the following renormalized matrix @xmath539 and @xmath540 where @xmath541 denotes the @xmath20-th largest eigenvalue of the hermitian matrix @xmath542 .",
    "the esd of @xmath543 converges weakly almost surely to a nonrandom distribution @xmath75 , where @xmath544 , where @xmath545 .",
    "this is established by observing that the stieltjes transform of @xmath543 can be expressed as @xmath546 and then applying the result in remark [ rem : non_hermitian_root ] to the terms on the rhs .",
    "thus , in order to complete the proof , we only need to show that the esd of @xmath543 and @xmath547 are almost surely equivalent . to this end , we need the following proposition .",
    "[ proposition_levy_f_d_and_f_e ] suppose that the data matrix @xmath548 , where @xmath9 is defined in ( [ eq : definition_a_p ] ) , @xmath14 is a @xmath11 matrix satisfying @xmath549 .",
    "let @xmath550 and @xmath551 .",
    "then , @xmath552 where @xmath553 denotes the lvy distance between the esds of @xmath543 and @xmath547 .",
    "the first step towards proving proposition [ proposition_levy_f_d_and_f_e ] is to obtain a bound on @xmath554 in terms of the differences between eigenvalues of @xmath543 and @xmath547 .",
    "observe first that the eigenvalues of @xmath547 ( not necessarily ordered ) are given by @xmath555 , where @xmath556 denotes the @xmath365-th largest eigenvalue of @xmath557 .",
    "this means in particular that @xmath558 next , since @xmath543 is a block diagonal matrix with diagonal blocks @xmath559 , whose eigenvalues are given by @xmath560 , and since @xmath24 implies that @xmath561 a.s . , it follows that for large enough @xmath49 , almost surely , the eigenvalues of @xmath543 are given by @xmath562 , where @xmath556 s are as defined above .",
    "thus , applying lemma [ lem : levy_distance_inequality ] , we obtain that , for large enough @xmath49 , almost surely , @xmath563 from ( [ eq : levy_distance_diagonal ] ) , it is clear that in order to establish ( [ eq : levy_d_n_e_n ] ) it suffices to show that @xmath564    we prove ( [ eq : max_eigenvalue_difference ] ) for @xmath194 . the result for general",
    "@xmath175 follows by a slight modification of the argument and using a finite induction . in the following , we use the notation @xmath565 to mean that @xmath566 is almost surely bounded for large enough @xmath49",
    "we need the following well - known result .",
    "( wielandt s inequality in eaton and tyler @xcite)[lem : wielandt_inequality ] consider a hermitian matrix @xmath567 where @xmath568 is @xmath36 and @xmath569 is @xmath570 and @xmath170 is @xmath571 .",
    "let @xmath572 denote the largest eigenvalue of @xmath573 and let @xmath574 ; @xmath575 and @xmath576 denote the ordered eigenvalues of @xmath568 , @xmath569 and @xmath170 respectively . if @xmath577 , then @xmath578 and @xmath579    when @xmath580 , we have @xmath581 note that since @xmath582 and @xmath583 a.s . , for @xmath584 , for large enough @xmath49 we have , @xmath585 , almost surely . thus ,",
    "applying lemma [ lem : wielandt_inequality ] to @xmath586 for @xmath587 , we have @xmath588 on the other hand , for @xmath589 , we have @xmath590    since @xmath591 and @xmath592 , we have for @xmath593 @xmath594 we will show that @xmath595 which implies ( [ eq : max_eigenvalue_difference ] ) .    showing ( [ eq : s_12_square ] ) is equivalent to showing that @xmath596 .",
    "observe that , we can write @xmath597 $ ] where @xmath598 is @xmath599 .",
    "also @xmath600 $ ] , for @xmath584 , where @xmath601 is @xmath602 , @xmath603 is @xmath604 , @xmath605 is @xmath606 and @xmath607 is @xmath608 matrix .",
    "then , @xmath609 where the last step follows from the fact that @xmath610 .",
    "we first show that @xmath611 .",
    "note that by lemma 5.3 in vershynin @xcite , @xmath612 where @xmath613 is an @xmath614-net covering the sphere @xmath615 with the cardinality @xmath616 . we need to show that , for any @xmath617 such that @xmath618 to this end , we need the following lemma on the concentration of quadratic forms of sub - gaussian random variables .    [",
    "lem : hanson_wright_inequality](hanson - wright inequality theorem 1.1 in rudelson and vershynin@xcite ) let @xmath619 be a random vector with independent components @xmath620 which satisfy @xmath621 and @xmath622 , where @xmath623 denotes the sub - gaussian norm defined by @xmath624 .",
    "let @xmath568 be an @xmath11 matrix , then for every @xmath625 @xmath626    this lemma applies to both real and complex - valued entries . in order to apply this result to our setting , we need the vector @xmath392 to be @xmath627 for any @xmath628 and ensure that there is a uniform finite bound on @xmath629 that does not depend on either @xmath630 or @xmath365 .",
    "for simplicity , we only provide the details for the case when @xmath3 is real .",
    "thus , let @xmath631 where @xmath628 .",
    "then @xmath632 has has i.i.d .",
    "sub - gaussian entries with zero mean , unit variance and scale parameter @xmath168 . by lemma 5.5 of vershynin",
    "@xcite , a random variable is sub - gaussian if and only if its sub - gaussian norm is finite and the sub - gaussian norm is a constant multiple of the scale parameter @xmath168 .",
    "the sub - gaussian norm for each entry @xmath633 , where @xmath634 is @xmath365-th column of @xmath635 , is given by @xmath636 by definition of sub - gaussian random vector and lemma 5.24 in vershynin @xcite , we have for an absolute constant @xmath542 , @xmath637 thus , @xmath638 and the latter bound does not depend on @xmath630 or @xmath365 .",
    "thus , applying lemma [ lem : hanson_wright_inequality ] , we can derive that for any @xmath639 , there exists @xmath640 and @xmath641 such that for @xmath642 @xmath643 this proves ( [ eq : quadratic_form_tail_bound ] ) .",
    "thus , by borel - cantelli lemma and ( [ eq : bound_term_iii ] ) , we have @xmath611 .",
    "similarly , @xmath644 .",
    "next , we show that @xmath645 .",
    "note that , since @xmath530 for @xmath584 , we have @xmath646 for @xmath647 , and hence @xmath648 let @xmath649 .",
    "we will prove that @xmath650 .",
    "accordingly , define @xmath651 , and note that @xmath652 has the same @xmath653 non - zero eigenvalues as @xmath654 as well as @xmath655 zero eigenvalues .",
    "let @xmath656 denote the spectral decomposition of @xmath652 where @xmath657 is @xmath658 and @xmath659 is a @xmath660 diagonal matrix .",
    "define @xmath661 and observe that the rows of @xmath662 are i.i.d . and sub - gaussian conditionally on @xmath663 .",
    "also note that if @xmath664 and @xmath665 denote the @xmath20-th row of @xmath666 and @xmath667 , respectively , then @xmath668 , so that @xmath669 , which shows that rows of @xmath662 are isotropic random vectors conditionally on @xmath663 .",
    "in addition , @xmath670 then by lemma 5.9 and theorem 5.39 in vershynin @xcite , applied to the matrix @xmath671 , and the fact that the entries of the diagonal matrix @xmath659 are bounded by @xmath672 which is a.s .",
    "finite ( again , by theorem 5.39 in vershynin @xcite ) , from the above display we conclude that @xmath673 .",
    "hence , @xmath674 and similarly , @xmath675 .",
    "so we finish the proof of proposition [ proposition_levy_f_d_and_f_e ] for @xmath194 case .",
    "we now give a brief outline of the induction argument .",
    "suppose that @xmath676 and ( [ eq : max_eigenvalue_difference ] ) holds for @xmath677 .",
    "we want to establish that the same holds when @xmath678 .",
    "accordingly , we write @xmath154 as @xmath679 where @xmath680 is the @xmath681 principal submatrix of @xmath154 , @xmath682 is @xmath683 and @xmath684 is @xmath685 .",
    "the proof follows by first showing that @xmath686 through proving that @xmath687 , which requires a minor modification of the argument for showing ( [ eq : s_12_square ] ) , and then applying the induction hypothesis .",
    "the details are omitted .",
    "in this section we carry out a simulation study to :    * demonstrate the convergence of the esd of @xmath12 to the limiting distribution by considering different combinations of @xmath70 ; * to illustrate the performance of the test based on the statistic @xmath238 proposed in section [ subsec : application ] by considering a specific null @xmath688 versus a specific simple alternative @xmath689 .",
    "we numerically investigate the convergence of the esd of @xmath690 to the lsd under @xmath214 , viz .",
    "note that , under @xmath214 , @xmath692 , while under @xmath693 , @xmath694 .",
    "we specifically assume that @xmath695 and @xmath696 since @xmath10 only influences the scale of the spectrum through the factor @xmath16 , for ease of comparison we take @xmath697 .",
    "first , to empirically investigate the rate of convergence of the esd to the lsd , we simulate data under @xmath214 and plot the relative frequency histogram of eigenvalues of @xmath12 together with the density of the lsd @xmath691 , denoted by @xmath698 .",
    "as indicated in section [ subsec : computation_density ] , this involves solving the following equation for @xmath134 : @xmath699 the histograms for five different combinations of @xmath70 are shown in figure [ fig : multi_compare ] . as we can see , with increasing values of @xmath48 and @xmath49 such that @xmath700 becomes smaller , the histograms closely match the smooth curve representing the density @xmath698 of the lsd .",
    "in addition to the graphical comparison , we also compute the value of the statistic @xmath238 defined in ( [ eq : cvm_statistic ] ) , which measures the discrepancy between the esd of @xmath12 ( when the data follow @xmath214 ) and the lsd @xmath691 .",
    "we make a three - way comparison , namely , ( i ) fixing @xmath48 and letting @xmath49 increase ; ( ii ) fixing @xmath48 and letting @xmath49 increase ; and ( iii ) allowing both @xmath48 and @xmath49 increase such that @xmath24 .",
    "the third scenario connects directly to the theory developed in this paper .",
    "the values of the means and standard deviations of the statistic @xmath238 based on 100 replicates for each of the @xmath70 combinations are reported in table [ table : convergence_rate ] .    * _ fix @xmath48 , increase @xmath49 : _ along the rows of table [ table : convergence_rate ] , i.e. , for a fixed @xmath48 , as @xmath28 , the matrix @xmath15 converges in distribution to a matrix of the form @xmath701 where @xmath702 is a @xmath36 ( real or complex ) wigner matrix , and so the esd of @xmath12 converges to that of @xmath703 which is different from @xmath691 . as can be seen from table [ table : convergence_rate ] , that along the rows , with increasing @xmath49 , the mean value of @xmath216 stabilizes to a nonzero value due to the fact that the lsd of @xmath129 is a limit distribution that is different from @xmath691 . *",
    "fix @xmath49 , increase @xmath48 : _ this comparison relates to the columns of table [ table : convergence_rate ] .",
    "the limiting behavior of @xmath129 under this setting is unclear and is beyond the scope of this paper .",
    "however , for any given @xmath49 , for large enough @xmath48 , the esd of @xmath12 will be quite different from @xmath691 . * _",
    "@xmath48 , @xmath49 both increase such that @xmath2 : _ this is the setting studied in this paper . for this comparison ,",
    "we focus on the main diagonal of table [ table : convergence_rate ] under this setting , @xmath129 converges to @xmath691 almost surely .",
    "the mean and @xmath704 standard deviation bars are depicted in figure [ figure : ratio_mean_std_l ] , with @xmath700 taking values @xmath705 , @xmath706 , @xmath707 , @xmath708 and @xmath709 , respectively .",
    "we observe that both the mean and standard deviation of @xmath238 decrease to zero as @xmath700 decreases to zero .",
    "this observation is consistent with the comparison of the histograms of eigenvalues of @xmath12 for the same combinations of @xmath70 as depicted in figure [ fig : multi_compare ] .",
    "@xmath48 & & & & & + 33 & 0.0050 & 0.0044 & 0.0042 & 0.0037 & 0.0041 + & ( 0.0021 ) & ( 0.0020 ) & ( 0.0018 ) & ( 0.0015 ) & ( 0.0017 ) + 66 & 0.0033&0.0018&0.0013&0.0011&0.0011 + & ( 8.9903e-4)&(6.1469e-4)&(4.5269e-4)&(3.4770e-4)&(3.7956e-4 ) + 99 & 0.0037 & 0.0015&8.3441e-4&6.5708e-4&5.6750e-4 + & ( 8.0365e-4)&(4.2526e-4)&(2.2154e-4)&(2.6689e-4)&(2.0820e-4 ) + 201 & 0.0065&0.0020&8.1588e-4&3.0589e-4&1.7812e-4 + & ( 5.0315e-4)&(2.7464e-4)&(1.7132e-4)&(8.0617e-5)&(6.2289e-5 ) + 600 & 0.0193&0.0058&0.0019&4.9400e-4&1.0062e-4 + & ( 2.7617e-4)&(1.4565e-4)&(8.4915e-5)&(3.9138e-5)&(1.7237e-5 ) +    [ table : convergence_rate ]     2 @xmath710 standard deviation of @xmath238 under different @xmath700 ratios.,scaledwidth=75.0% ]    .,scaledwidth=75.0% ]    next , we show the performance of the test for @xmath688 versus @xmath689 based on the test statistic of @xmath238 , where @xmath711 and @xmath712 , @xmath713 are defined in ( [ eq : a_0_b_0 ] ) and ( [ eq : a_1_b_1 ] ) .",
    "rather than performing the test at a specific level of significance , we compute the quantiles of the distribution of @xmath238 under @xmath214 and @xmath693 corresponding to a given set of probabilities . in order to evaluate the quantiles empirically ,",
    "we simulate 500 replicates for each setting .",
    "the quantiles of the test statistics @xmath238 under @xmath693 are plotted against those under @xmath214 in figure [ l2_qq_plot ] . since the points lie well above the @xmath714 line , it shows that the test is able to reject the null hypothesis at any reasonable level of significance when the data are generated under the alternative .     under @xmath209 versus under @xmath229 .",
    "left panel : @xmath715 ; right panel : @xmath716.,scaledwidth=75.0% ]    the numerical values of the quantiles of the distribution of @xmath238 under @xmath214 and @xmath693 are given in table [ table : quantiles ] .",
    "it shows that especially for @xmath717 ; @xmath718 setting , the effective supports of the distributions of the test statistic are essentially separated under @xmath214 and @xmath693 , indicating that the test is able to clearly discriminate between the two hypotheses .",
    ".quantiles of @xmath238 under @xmath214 and @xmath693 for @xmath719 and @xmath720 . [ cols=\"^,^,^,^,^ \" , ]     [ table : quantiles ]",
    "the authors thank the anonymous referees for their valuable suggestions regarding improving the quality of the manuscript .",
    "this work was done during a visit of the first author to the department of statistics , university of california , davis .",
    "wang was partially supported by nsfc grant 11071213 , nsfc 11371317 , nsfc grant 11101362 , zjnsf grant r6090034 and srfdp grant 20100101110001 .",
    "paul was partially supported by the nsf grants dmr-1035468 and dms-1106690 .",
    "60 bai , z. d. and silverstein , j. w. ( 2009 ) .",
    "_ spectral analysis of large dimensional random matrices_. springer .",
    "bai , z. d. and silverstein , j. w. ( 1999 ) . exact separation of eigenvalues of large dimensional sample covariance matrices . _",
    "annals of probability _ , * 27 * , 15361555 .",
    "bai , z. d. and yin , y. q. ( 1988 ) .",
    "convergence to the semicircle law .",
    "_ annals of probility _ , * 16 * , 863875 .",
    "bai , z. d. and zhang , l. x. ( 2010 ) .",
    "the limiting spectral distribution of the product of the wigner matrix and a nonnegative definite matrix .",
    "_ journal of multivariate analysis _ , * 101 * , 19271949 .",
    "bao , z. g. ( 2012 ) .",
    "strong convergence of esd for the generalized sample covariance matrices when @xmath2 . _ statistical and probability letters _ , * 82 * , 894901 .",
    "chatterjee , s. ( 2006 ) .",
    "a generalization of lindeberg principle . _",
    "annals of probability _ , * 6 * , 20612076 .",
    "dutilleul , p. ( 1999 ) .",
    "the mle algorithm for the matrix normal distribution .",
    "_ journal of statistical computation and simulation _ , * 64 * , 105123 .",
    "eaton , m. l. and tyler , d. e. ( 1991 ) . on weilandt s inequality and its application to the asymptotic distribution of the eigenvalues of a random symmetric matrix .",
    "_ annals of statistics _ , * 19 * , 260271 .",
    "el karoui , n. ( 2009 ) .",
    "concentration of measure and spectra of random matrices : applications to correlation matrices , elliptical distributions and beyond .",
    "_ annals of applied probability _ , * 19 * , 23622405 .",
    "fuentes , m. ( 2006 ) . testing separability of spatio - temporal covariance functions . _ journal of statistical planning and inference _ , * 136 * , 447466 .",
    "kyriakidis , p. and journel , a. g. ( 1999 ) .",
    "geostatistical space - time models : a review .",
    "_ mathematical geology _ , * 31 * , 651684 .",
    "mcdiarmid , c. ( 1989 ) . on the method of bounded differeces .",
    "_ surveys in combinatorics _ * 141 * , 148188 .",
    "mitchell , m. w. and gumpertz , m. l. ( 2003 ) .",
    "spatial variability inside a free - air co@xmath721 enrichment system .",
    "_ journal of agricultural , biological , and environmental statistics _",
    ",    mitchell , m. w. , genton , m. g. and gumpertz , m. l. ( 2005 ) .",
    "testing for separability of space - time covariances .",
    "_ environmetrics _ , * 16 * , 819831 .",
    "mitchell , m. w. , genton , m. g. and gumpertz , m. l. ( 2006 ) . a likelihood ratio test for separability of covariances .",
    "_ journal of multivariate analysis _ * 97 * , 10251043 .",
    "ledoux , m. ( 2003 ) . _ the concentration of measure phenomenon_. american mathematical society .",
    "li , b. , genton , m. g. and sherman , m. ( 2008 ) . testing the covariance structure of multivariate random fields .",
    "_ biometrika _ , * 95 * , 813829 .",
    "lu , n. and zimmerman , d. l. ( 2005 ) . the likelihood ratio test for a separable covariance matrix . _ statistics and probability letters _ , * 73 * , 449457 .",
    "pastur , l. and shcherbina , m. ( 2011 ) .",
    "_ eigenvalue distribution of large random matrices_. american mathematical society .",
    "pan , g. m. and gao , j. t. ( 2009 ) .",
    "asymptotic theory for sample covariance matrix under cross - sectional dependence .",
    "_ manuscript_. paul , d. ( 2007 ) .",
    "asymptotics for sample eigenstructure for a large dimensional spiked covariance model .",
    "_ statistica sinica _ , * 17 * , 16171642 .",
    "paul , d. and aue , a. ( 2013 ) .",
    "random matrix theory in statistics : a review .",
    "_ manuscript_. paul , d. and silverstein , j. w. ( 2009 ) .",
    "no eigenvalues outside the support of a separable covariance matrix .",
    "_ journal of multivariate analysis _ , * 100 * , 3757 .",
    "roy , a. and khatree , r. ( 2005 ) on implementation of a test for kronecker product covariance structure for multivariate repeated measures data .",
    "_ statistical methodology _ , * 2 * , 297306 .",
    "rudelson , m. and vershynin , r. ( 2013 ) .",
    "hanson - wright inequality and sub - gaussian concentration .",
    "_ arxiv:1306.2872_. silverstein , j. w. and bai , z. d. ( 1995 ) , on the empirical distribution of eigenvalues of a class of large dimensional random matrices .",
    "_ journal of multivariate analysis _ , * 54 * , 175192 .",
    "silverstein , j. w. and choi , s. i. ( 1995 ) .",
    "analysis of the limiting spectral distribution of large dimensional random matrices . _ journal of multivariate analysis _ ,",
    "* 54 * , 175192 .",
    "simpson , s. l. ( 2010 ) .",
    "an adjusted likelihood ratio test for separability in unbalanced multivariate repeated measures data .",
    "_ statistical methodology _ , * 7 * , 511519 .",
    "stewart , g. w. ( 1980 ) . the efficient generation of random orthogonal matrices with an application to condition estimators .",
    "_ siam journal of numerical analysis _",
    ", * 71 * , 403409 .",
    "vershynin , r. ( 2010 ) .",
    "introduction to the non - asymptotic analysis of random matrices .",
    "arxiv preprint:1011.3027 zhang , l. x. ( 2006 )",
    ". _ spectral analysis of large dimensional random matrices_. ph.d . thesis",
    ". national university of singapore .",
    "[ lemma : quad_bound ] ( lemma 2.6 of silverstein and bai @xcite ) : let @xmath402 with @xmath722 .",
    "let @xmath170 and @xmath75 be @xmath723 matrices with @xmath170 hermitian , and let @xmath724 .",
    "then , @xmath725      [ lemma : moments_of_quadratic_forms ] ( lemma 8.10 of silverstein and bai @xcite ) :",
    "let @xmath730 be an @xmath11 non - random matrix and @xmath731 be random vector of independent entries .",
    "assume that @xmath732 @xmath733 and @xmath734 .",
    "then for any @xmath735 , @xmath736 where @xmath737 is a constant depending on @xmath48 only .      [",
    "lem : levy_distance_inequality ] let @xmath738 and @xmath739 be two sets of real and let their empirical distributions be denoted by @xmath75 and @xmath740 , respectively .",
    "then , for any @xmath741 , @xmath742 where the minimum is taken over all permutation @xmath743 of the indices @xmath744 , and @xmath745 denotes the lvy distance between the distributions @xmath75 and @xmath740 .    [ lem : vershynin_berstein_tail ] ( bernstein s inequality ) : let @xmath746 be independent centered sub - exponential random variables , and @xmath747 where @xmath748 then for every @xmath749 and every @xmath750 we have @xmath751    [ lem : vershynin_subexponential_tail ] ( corollary 5.17 in vershynin @xcite ) : let @xmath746 be independent centered sub - exponential random variables , and let @xmath752 where @xmath753 then for every @xmath754 we have @xmath755 where @xmath756 is an absolute constant .",
    "[ lem : hoeffding_type_inequality ] ( hoeffding s inequality : proposition 5.10 in vershynin @xcite ) : let @xmath746 be independent centered sub - gaussian random variables , and let @xmath757 where @xmath758 then for every @xmath759 and every @xmath750 we have @xmath760 where @xmath756 is an absolute constant .      this is a direct application of the strategy shown in section [ subsec : random part ] .",
    "we will show that @xmath762\\right|\\leq m / p$ ] . to this end",
    ", we repeat the computation in ( [ eg : difference_resolvent_deleting_kth_row ] ) . since @xmath763 let @xmath764 , where @xmath765 and @xmath766 . also , define @xmath767 and @xmath768 so that @xmath769",
    ". then from ( [ eg : y_z_decomposition ] ) we have @xmath770 .",
    "therefore , @xmath771\\\\ & = & \\tr\\left[\\left(y^{-1}(z)-(d_{2k}-zi)^{-1}\\right)\\lambda\\right]+ \\tr\\left[\\left((d_{2k}-zi)^{-1}-(d_{1k}-zi)^{-1}\\right)\\lambda\\right]\\\\ & & ~~~~+ \\tr\\left[\\left((d_{1k}-zi)^{-1}-y_{(k)}^{-1}(z)\\right)\\lambda\\right]\\\\ & = & \\frac{\\tau_{kk}e_{k}^{*}(d_{2k}-zi)^{-1}\\lambda(d_{2k}-zi)^{-1}e_{k}}{1+\\tau_{kk}e_{k}^{*}(d_{2k}-zi)^{-1}e_{k } } + \\frac{\\mbf{v}_{k}^{*}(d_{1k}-zi)^{-1}\\lambda(d_{2k}-zi)^{-1}\\mbf{v}_{k}}{1+\\mbf{v}_{k}^{*}(d_{1k}-zi)^{-1}\\mbf{v}_{k } } + \\frac{\\mbf{u}_{k}^{*}y_{(k)}^{-1}\\lambda y_{(k)}^{-1}\\mbf{u}_{k}}{1+\\mbf{v}_{k}^{*}y_{(k)}^{-1}(z)\\mbf{u}_{k}}.\\end{aligned}\\ ] ] according to ( [ eq : c_diff ] ) and lemma [ lemma : quad_bound ] , each term above is bounded by @xmath772 .",
    "thus @xmath773\\right|\\leq \\frac{3a_{0}}{pv}\\leq \\frac{m}{p}.\\ ] ]",
    "so we have @xmath774 .      since @xmath776\\right|^2,\\end{aligned}\\ ] ] and we already have @xmath777 to prove the claim that @xmath341 , we need a bound on the expected value of the term @xmath778:=d_{k}^{(2)}\\ ] ] defined in ( [ eq : quadratic term ] ) .",
    "note that @xmath779\\\\ & = & \\frac{\\lambda_{k}}{p}tr\\left[v_{(k)}b_{n}v_{(k)}^{*}y_{(k)}^{-1}(z)\\right ] - \\bar{b}_{2}(n)\\frac{\\lambda_{k}}{p}\\tr\\left[y_{(k)}^{-1}(z)\\lambda_{(k)}\\right ] + d_{k}^{(1)}\\\\ & = & \\frac{\\lambda_{k}}{pn}\\sum_{i , j \\ne k}(\\sqrt{\\lambda_{i}\\lambda_{j}}\\widetilde{x}_{i}^{*}b_{n}^{2}\\widetilde{x}_{j } ) ( y_{(k)}^{-1}(z))_{ji}-\\bar{b}_{2}(n)\\frac{\\lambda_{k}}{p}\\tr\\left[y_{(k)}^{-1}(z)\\lambda_{(k)}\\right]+d_{k}^{(1)}\\\\ & = & \\frac{\\lambda_{k}}{p}\\sum_{i\\ne k } \\lambda_{i}\\left(\\frac{1}{n}\\widetilde{x}_{i}^{*}b_{n}^{2}\\widetilde{x}_{i } -\\bar{b}_{2}(n)\\right)(y_{(k)}^{-1}(z))_{ii}+\\frac{\\lambda_{k}}{p}\\sum_{i\\ne j\\ne k}\\sqrt{\\lambda_{i}\\lambda_{j } } \\frac{1}{n}\\widetilde{x}_{i}^{*}b_{n}^{2}\\widetilde{x}_{j}(y_{(k)}^{-1}(z))_{ji}+d_{k}^{(1)}\\\\ & : = & d_{k}^{(3)}+d_{k}^{(4)}+d_{k}^{(1)}.\\end{aligned}\\ ] ] in order to show @xmath780 , we need to derive corresponding bounds on @xmath781 and @xmath782 . using lemma [ lemma : moments_of_quadratic_forms ] , we have that for any @xmath783 @xmath784 thus , taking @xmath785 in ( [ eg : bound_expectation_quadra ] ) and using cauchy - schwarz inequality , we have @xmath786\\right|^2\\nonumber\\\\ & = & \\frac{\\lambda_{k}^2}{p^2}{\\mathbb{e}}\\left|\\tr\\left[\\left(\\frac{1}{n}\\widetilde{x}_{(k)}b_{n}^{2}\\widetilde{x}_{(k)}^ { * } -\\bar{b}_2(n)i_{(k)}\\right)\\left(\\lambda_{(k)}^{1/2}y_{(k)}^{-1}(z)\\lambda_{(k)}^{1/2}\\right)\\right]\\right|^2\\nonumber\\\\ & \\leq & \\frac{a_{0}^2}{p^2 } { \\mathbb{e}}\\left[\\tr\\left(\\frac{1}{n}\\widetilde{x}_{(k)}b_{n}^{2}\\widetilde{x}_{(k)}^ { * } -\\bar{b}_2(n)i_{(k)}\\right)^2\\tr\\left(\\lambda_{(k)}^{1/2}y_{(k)}^{-1}\\lambda_{(k)}y_{(k)}^{-1}(\\bar{z})\\lambda_{(k)}^{1/2}\\right)\\right]\\nonumber\\\\ & \\leq & \\frac{a_{0}^4}{pv^2}{\\mathbb{e}}\\tr\\left(\\frac{1}{n}\\widetilde{x}_{(k)}b_{n}^{2}\\widetilde{x}_{(k)}^{*}-\\bar{b}_2(n)\\lambda_{(k)}\\right)^2,\\end{aligned}\\ ] ] where @xmath787 .",
    "indeed , @xmath788 then we have @xmath789 which goes to zero as @xmath28 .",
    "next , we show that @xmath790 . since @xmath791\\nonumber\\\\ & = & \\frac{\\lambda_{k}}{n}\\widetilde{x}_{k}^{*}q_n(z)\\widetilde{x}_{k}-\\tr(q_n(z))\\end{aligned}\\ ] ] where @xmath792 , we get @xmath793\\nonumber\\\\ & \\leq & c\\frac{a_0^{2}}{p^2 } { \\mathbb{e}}\\tr\\left(q_{n}(z)q_{n}(z)^{*}\\right)\\nonumber\\\\ & \\leq & \\frac{c^{'}}{p}{\\mathbb{e}}\\|q_n(z)\\|^2\\nonumber\\\\ & \\leq & \\frac{m}{p}.\\end{aligned}\\ ] ] the last inequality holds due to the fact that under gaussianity , we have @xmath794 so that @xmath795 therefore , combining ( [ eg : bound_on_d_3_plus_d_4 ] ) and ( [ eg : bound_on_d_1 ] ) we derive that @xmath796 .",
    "this , together with ( [ eq : e_tau_kk_bound ] ) , implies that @xmath341 .",
    "denote by @xmath798 the conditional expectation with respect to the @xmath168-field generated by the first @xmath20 rows of @xmath799 except for @xmath800 , say , @xmath801 .",
    "let @xmath802 , where @xmath803 denotes the vector in @xmath57 with 1 in @xmath20-th coordinate and zero elsewhere .",
    "then , @xmath804-{\\mathbb{e}}\\tr\\left[y^{-1}_{(k)}(z)\\lambda_{(k)}\\right]=\\sum_{j\\ne k}^{p}\\left[{\\mathbb{e}}_{j}\\tr\\left(y_{(k)}^{-1}(z)\\lambda_{(k)}\\right)-{\\mathbb{e}}_{j-1}\\tr\\left(y_{(k)}^{-1}(z)\\lambda_{(k)}\\right)\\right]:=\\sum _ { j\\ne k}^{p}\\gamma_{j}\\ ] ] where @xmath805 forms a martingale difference sequence and can be written as @xmath806.\\end{aligned}\\ ] ] the second equality above holds because of the fact that @xmath807 thus , by lemma [ lemma : quad_bound ] we get @xmath808 and hence @xmath809 by ( [ eq : martingale_gamma_j_expression ] ) . applying burkhlder inequality ( lemma [ eg : burkholder_inequality ] ) , we have @xmath810 - \\bar{b}_{2}(n)\\frac{\\lambda_{k}}{p}{\\mathbb{e}}\\tr\\left[y^{-1}_{(k)}(z)\\lambda_{(k)}\\right]\\right|^2\\\\ & = & \\frac{(\\bar{b}_{2}(n)\\lambda_{k})^2}{p^2}{\\mathbb{e}}\\left|\\sum_{j\\ne k}\\gamma_{j}\\right|^2\\\\ & \\leq & \\frac{k}{p^2}{\\mathbb{e}}\\left(\\sum_{j\\ne k } |\\gamma_{j}|^2\\right)^{1/2}\\\\ & \\leq & \\frac{k}{p^2v^2}\\left[\\frac{36(p-1)a_{p}^2}{v^2}\\right]^{1/2}\\leq \\frac{m}{p^{3/2}}.\\end{aligned}\\ ] ]      since @xmath811 in which @xmath502 is a @xmath288 unit vector with 1 in @xmath365-th coordinate and @xmath503 is a @xmath504 unit vector with 1 in @xmath365-th coordinate .",
    "let @xmath812 and @xmath813 . then @xmath814 @xmath815 @xmath816 @xmath817 so we get @xmath818= \\frac{6}{p}\\tr\\left[\\frac{{\\partial}c_{n}}{{\\partial}x_{ij}}g_{n}\\frac{{\\partial}^2 c_{n}}{{\\partial}x_{ij}^{2}}g_{n}^{2}\\right]-\\frac{6}{p}\\tr\\left[\\frac{{\\partial}c_{n}}{{\\partial}x_{ij}}g_{n}\\frac{{\\partial}c_{n}}{{\\partial}x_{ij}}g_{n}\\frac{{\\partial}c_{n}}{{\\partial}x_{ij}}g_{n}^2\\right]\\ ] ] where @xmath819 = \\frac{12b_{jj}}{np^2}\\tr\\left[\\xi_{i}^{*}g^{2}_n(z)(r_{j}\\xi_{i}^{*}+\\xi_{i}r_{j}^{*})g_{n}\\xi_{i}\\right]\\ ] ] and @xmath820 & = & \\frac{1}{n^{3/2}p^{5/2 } } \\tr\\left[(r_{j}\\xi_{i}^ { * } + \\xi_{i}r_{j}^{*})g_{n}(r_{j}\\xi_{i}^ { * } + \\xi_{i}r_{j}^{*})g_{n}(r_{j}\\xi_{i}^{*}+\\xi_{i}r_{j}^{*})g_{n}^{2}\\right]\\\\ & : = & 2\\eta_{3}(n)+2\\eta_{4}(n)+2\\eta_{5}(n)+2\\eta_{6}(n)\\end{aligned}\\ ] ] where @xmath509\\\\ \\eta_{4}(n ) & = & \\frac{1}{n^{3/2}p^{5/2}}\\left[r_{j}^{*}g_{n}\\xi_{i}r_{j}^{*}g_{n}r_{j}\\xi_{i}^{*}g_{n}^{2}\\xi_{i}\\right]\\\\ \\eta_{5}(n ) & = &   \\frac{1}{n^{3/2}p^{5/2}}\\left[r_{j}^{*}g_{n}r_{j}\\xi_{i}^{*}g_{n}\\xi_{i}r_{j}^{*}g^{2}_{n}\\xi_{i}\\right]\\\\ \\eta_{6}(n)&= & \\frac{1}{n^{3/2}p^{5/2}}\\left[\\xi_{i}^{*}g_{n}\\xi_{i}r_{j}^{*}g_{n}\\xi_{i}r_{j}^{*}g^{2}_{n}r_{j}\\right].\\end{aligned}\\ ] ]      let @xmath821 ( for brevity , dropping index @xmath20 on the right ) and @xmath822 . since @xmath823 , where @xmath824 and @xmath825 , we have @xmath826 ^ 2\\right)^{k } = { \\mathbb{e}}\\left(\\sum_{i=1}^{p}n_{i}^{2}\\right)^{k},\\ ] ] where @xmath827 , @xmath828 , are independent , sub - gaussian random variables with @xmath829 and @xmath830",
    ". then we have @xmath831 where @xmath832 is a mean zero sub - exponential random variable .",
    "thus , @xmath833 the term @xmath834 . on the other hand",
    ", @xmath835 is the average independent sub - exponential random variables with mean zero and uniformly bounded sub - exponential norm ( can be verified ) .",
    "so by bernstein s inequality ( lemma [ lem : vershynin_berstein_tail ] ) , the tail probability can be controlled adequately so that @xmath836 for any @xmath837 .",
    "hence ( [ r ] ) holds ."
  ],
  "abstract_text": [
    "<S> we are concerned with the behavior of the eigenvalues of renormalized sample covariance matrices of the form @xmath0 as @xmath1 and @xmath2 , where @xmath3 is a @xmath4 matrix with i.i.d . </S>",
    "<S> real or complex valued entries @xmath5 satisfying @xmath6 , @xmath7 and having finite fourth moment . </S>",
    "<S> @xmath8 is a square - root of the nonnegative definite hermitian matrix @xmath9 , and @xmath10 is an @xmath11 nonnegative definite hermitian matrix . </S>",
    "<S> we show that the empirical spectral distribution ( esd ) of @xmath12 converges a.s . to a nonrandom limiting distribution under the assumption that the esd of @xmath9 converges to a distribution @xmath13 that is not degenerate at zero , and that the first and second spectral moments of @xmath14 converge . the probability density function of the lsd of @xmath15 is derived and it is shown that it depends on the lsd of @xmath9 and the limiting value of @xmath16 . </S>",
    "<S> we propose a computational algorithm for evaluating this limiting density when the lsd of @xmath9 is a mixture of point masses . </S>",
    "<S> in addition , when the entries of @xmath3 are sub - gaussian , we derive the limiting empirical distribution of @xmath17 where @xmath18 is the sample covariance matrix and @xmath19 denotes the @xmath20-th largest eigenvalue , when @xmath13 is a finite mixture of point masses . </S>",
    "<S> these results are utilized to propose a test for the covariance structure of the data where the null hypothesis is that the joint covariance matrix is of the form @xmath21 for @xmath22 denoting the kronecker product , as well as @xmath9 and the first two spectral moments of @xmath14 are specified . </S>",
    "<S> the performance of this test is illustrated through a simulation study .    </S>",
    "<S> separable covariance ; limiting spectral distribution ; stieltjes transform ; mcdiarmid s inequality ; lindeberg principle , wielandt s inequality .    60b20 , 62e20 , 60f05 , 60f15 , 62h99 </S>"
  ]
}