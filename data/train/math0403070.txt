{
  "article_text": [
    "the complexity and unpredictability of a chaotic system has been measured using many different indicators . among all one of the most important",
    "is the kolmogorov - sinai ( k - s ) entropy .",
    "being based on the shannon s notion of information , it is an average measure of the quantity of information that is necessary to describe each step of the behaviour of the system ( with an arbitrary accuracy given by the choice of a partition ) .",
    "more recently other notions of information content , such as the kolmogorov - chaitin _ algorithmic information content _ , have been applied to dynamical systems .",
    "these notions are pointwise and allow to consider the complexity of the behaviour of a single orbit .",
    "hence it is possible to define the information @xmath3 contained in @xmath0 steps of the orbit of a point @xmath4 with respect to a partition @xmath5 of the phase space .",
    "this can be done by associating to the orbit of @xmath4 the symbolic orbit with respect to @xmath5 and considering the information content of this string ( see section [ sec : info ] ) .",
    "the average of this pointwise information over an invariant measure @xmath6 is strictly related to the k - s entropy @xmath7 of the measure @xmath6 relative to the partition @xmath5 .",
    "indeed for a `` typical '' point @xmath4 it holds @xmath8 ( see theorem [ teo : ks - aic ] ) .",
    "when the entropy is null the previous relation becomes @xmath9 .",
    "the many possible different sublinear asymptotic behaviours of @xmath3 correspond to different kinds of `` weakly '' chaotic dynamics .",
    "the importance of this indicator of weak chaos is also confirmed by the relations that have been proved , even in the null entropy case , between the behaviour of the information and many important features of the dynamics , such as sensitivity to initial conditions , dimensions , recurrence ( @xcite,@xcite,@xcite,@xcite,@xcite ) and global topological complexity indicators ( @xcite , see also @xcite for relations between the topological complexity and other physically important features of dynamics ) .",
    "a class of systems which have a sublinear increase of the information are the systems with an infinite invariant measure ( see theorem [ teo : aic - mi ] ) .",
    "an important subclass of these consists of maps with an indifferent fixed point , being an important example the map on the interval @xmath10 $ ] given by @xmath11 in the above family of maps the origin is a neutrally unstable fixed point , hence an orbit that is sent near the origin can be trapped near the origin for long times .",
    "the resulting behaviour is an alternation of chaotic ( when the orbit stays far from the origin the map is similar to the baker s map ) and regular ( when the orbit is trapped near the origin ) phases .",
    "the expected trapping times can be modulated by varying @xmath12 . for these reasons",
    "this map was introduced in the physical literature in @xcite as a model of intermittent turbulent behaviour in fluid dynamics , and the particular statistical properties of the orbits of these maps were used in different fields to model intermittent phenomena ( see for example @xcite ) .    from the information point of view",
    "these maps exhibit a behaviour that is between the fully chaotic ( positive entropy ) and the regular one ( the dynamics is predictable , the information needed to describe it increases with time @xmath0 at most as @xmath13 ) .",
    "this was first discovered in @xcite in a piecewise linear example ( see section [ sec : plm ] ) .",
    "their seminal , short paper however does not present a complete mathematical proof of this fact ( a lower bound , like theorem [ teo : finale2 ] is not proved ) .",
    "some further study was made in @xcite ( where the lower bound was proved under some assumption on @xmath12 ) and in @xcite .",
    "this paper considers both @xmath14 and piecewise linear ( pl ) classes of interval maps with an indifferent fixed point .",
    "the @xmath14 case is studied using techniques that are different from the techniques used in the previous literature .    the main result of this paper implies that , in mean with respect to any absolutely continuous probability measure the information of the `` manneville - pomeau like''(see definition [ def : mp ] ) class of maps , for which equation ( [ manne001 ] ) is an example , behaves for @xmath15 like @xmath16 \\sim n^\\frac{1}{z-1}\\ ] ] that is as a power law with exponent less than 1 ( see theorem [ risultato ] ) .",
    "this shows in particular that the behaviour of the information content for these maps depends only on the local behaviour of the map near the neutrally unstable fixed point at the origin .",
    "some results about the pointwise behaviour of @xmath3 are also given ( see proposition [ prop : pw ] ) .",
    "moreover we study a class of piecewise linear maps , extending the results of @xcite , finding in particular different behaviours for the mean of the information content ( see section [ sec : plm ] ) .",
    "all our results are based on the definitions of section [ sec : info ] , where we introduce in an informal way the _ algorithmic information content _ of a string and the few related facts about algorithmic information theory that we need in the following . then using these concepts we define the _ local _ and _ global chaos indexes _ , which measure the local and average power law behaviour of the information @xmath3 ( roughly speaking when @xmath17 then the index is @xmath18 ) .",
    "the invariance properties of these indexes and the results on the manneville - pomeau maps imply , as a simple corollary , that two manneville - pomeau maps with different parameter @xmath12 can not be absolutely continuously conjugate ( corollary [ coniugio ] ) .",
    "the method we use to study a chaotic dynamical system is based on the idea of a measure of the information contained in the orbits of the system .",
    "let @xmath19 be a finite alphabet and let @xmath20 be the set of all strings of length @xmath0 written with letters from @xmath19 .",
    "then by @xmath21 we denote the set of finite strings of any length , that is @xmath22 given a string @xmath23 , the intuitive idea of information contained in @xmath24 is the length of the smallest binary message from which it is possible to reconstruct @xmath24 .",
    "thus , formally , the information @xmath25 is a function @xmath26    one of the most important measures for the information content is the _ algorithmic information content ( aic)_. in order to define it , it is necessary to define the notion of partial recursive function .",
    "we limit ourselves to give an intuitive idea which is very close to the formal definition .",
    "we can consider a partial recursive function as a computer @xmath27 which takes a program @xmath28 ( namely a binary string ) as an input , performs some computations , and gives a string @xmath29 , written on the given alphabet @xmath30 , as an output .",
    "the @xmath31 of a string @xmath24 is defined as the shortest binary program @xmath28 which gives @xmath24 as its output , namely @xmath32 where @xmath33 denotes the binary length of the program @xmath28 .",
    "up to now the algorithmic information content depends on @xmath27 , but there is a class of computing machines that allows a definition of information content independent on the particular computer up to a constant .",
    "we require that our computer is a universal computing machine . roughly speaking ,",
    "a computing machine is called _ universal _ if it can simulate any other machine if appropriately programmed .",
    "that is , @xmath27 is universal if for each other computer @xmath34 there is a program @xmath35 such that for each program @xmath28 it holds @xmath36 . in particular the computers we use",
    "every day are universal computing machines , provided that we assume that they have virtually infinite memory . for a precise definition see for example @xcite or @xcite .",
    "we have the following theorem    [ teo : aic - kolm ] if @xmath27 and @xmath37 are universal computing machines then @xmath38 where @xmath39 is a constant which depends only on @xmath27 and @xmath37 .",
    "this theorem implies that the information content @xmath40 of @xmath24 with respect to @xmath27 depends only on @xmath24 up to a fixed constant , then its asymptotic behaviour does not depend on the choice of @xmath27 .",
    "for this reason from now on we will write @xmath41 instead of @xmath42 .    the shortest program which gives a string as its output is a sort of encoding of the string , and the information which is necessary to reconstruct the string is contained in the program . from this point of view",
    "the computer can also be seen as a decoder .",
    "unfortunately the coding procedure associated to the algorithmic information content can not be performed by any algorithm .",
    "this is a very deep statement and , in some sense , it is equivalent to the turing halting problem or to the gdel incompleteness theorem",
    ". then the algorithmic information content is a function not computable by any algorithm .",
    "hence in computations one tries to approximate from above the @xmath31 of a string by means of some algorithm .",
    "this leads to consider the theory of _ compression algorithms _ , algorithms that encode an original string @xmath43 into a compressed version of it @xmath44 in a reversible way ( i.e. , there is an other algorithm that is able to recover the original string from the coded string ) . using a compression algorithm @xmath45",
    "one defines the information content of the string @xmath24 with respect to the encoding procedure @xmath45 as @xmath46 , where @xmath33 denotes the binary length of @xmath47 .",
    "we remark that the algorithmic information content of a string is up to a constant less than or equal to the information content as it is computed by some compression algorithm .",
    "that is , for each compression algorithm @xmath45 there is a constant @xmath48 such that for each @xmath24 it holds @xmath49 .",
    "this is because each universal computing machine can be programmed also to perform any coding - decoding technique , and the length of this program represents @xmath48 .    to study a chaotic dynamical system we have to consider the asymptotic behaviour of its orbits ,",
    "hence if we want to consider in some sense the information contained in the orbits of the system , we have to deal with infinite strings",
    ". then let @xmath50 denote the set of infinite strings @xmath51 with letters from @xmath52 . to study the information contained in a infinite string @xmath51 , we study what is the asymptotic behaviour of the information contained in the first @xmath0 symbols of @xmath51 as @xmath0 increases .",
    "hence we study the asymptotic behaviour of the function @xmath53 as @xmath0 increases , where @xmath54 is the string given by the first @xmath0 symbols of @xmath51 . by the methods of symbolic dynamics we will associate an infinite string to an orbit and then the above idea will be applied to dynamical systems .",
    "let @xmath55 be a dynamical system .",
    "@xmath56 is assumed to be a compact metric space , @xmath57 is the borel @xmath58-algebra , and @xmath59 is a @xmath57-measurable map from @xmath56 to itself .",
    "let @xmath6 be a @xmath59-invariant measure on @xmath60 .",
    "we do not suppose that @xmath61 , but we always assume @xmath6 to be @xmath58-finite and conservative .",
    "let @xmath62 be a finite measurable partition of @xmath56 , and let @xmath63 be the associated finite alphabet .",
    "then the symbolic representation of the system @xmath64 is given by the function @xmath65 associating to each point a symbolic orbit with respect to @xmath5 , defined by @xmath66    the image @xmath67 is a subset of @xmath68 which is invariant under the usual shift map @xmath69 on @xmath68 .",
    "the function @xmath70 induces on @xmath67 a measure corresponding to @xmath6 . of course similar symbolic representations",
    "can also be defined for countable partitions ( with a countable symbolic alphabet ) .    at this point",
    "it is possible to apply the notion of information to the orbits of the system .",
    "we obtain quantities dependent on a given partition @xmath5 of @xmath56 . the following definition and the following theorem , given in @xcite , shows the relation between aic and entropy .    [ def : complpts ] the _ information content @xmath71 _ of @xmath0 steps of the orbit of @xmath4 with respect to @xmath5 is defined as @xmath72 .",
    "analogously , the _ complexity _ @xmath73 of a point @xmath74 with respect to @xmath5 is given by @xmath75    the complexity of a sequence is related to the shannon entropy of the information source that has produced the sequence .",
    "hence in the theory of dynamical systems it is possible to relate the complexity to the kolmogorov - sinai entropy of the system .",
    "the following theorem holds    [ teo : ks - aic ] let @xmath76 be a dynamical system and @xmath6 a @xmath59-invariant probability measure on @xmath56 .",
    "given a finite measurable partition @xmath5 of @xmath56 , it holds @xmath77 where @xmath78 denotes the kolmogorov - sinai entropy of the system relative to the partition @xmath5 .",
    "if the dynamical system @xmath64 is ergodic then for @xmath6-almost all @xmath74 @xmath79    in systems with an infinite measure we have a behaviour of the information that is similar to zero entropy systems , indeed the following holds .",
    "[ teo : aic - mi ] let @xmath76 be a dynamical system and @xmath6 a @xmath59-invariant infinite ergodic measure . given a finite measurable partition @xmath5 of @xmath56 , for @xmath6-almost all @xmath74 it holds @xmath80 .",
    "these theorems tell us what we can expect for the asymptotic behaviour of the information content of a typical orbit of an ergodic dynamical system .",
    "if the system has an invariant probability measure @xmath6 with positive kolmogorov - sinai entropy relative to a partition @xmath5 , then for @xmath6-almost all @xmath74 it holds and @xmath81 we shall write @xmath82 if the quotient @xmath83 tends to unity as @xmath84 .",
    "moreover , the notation @xmath85 means that @xmath86 as well as @xmath87 for @xmath84 .",
    "moreover we shall write @xmath88 if @xmath89 . ]",
    "@xmath90 if instead the ergodic measure @xmath6 has null kolmogorov - sinai entropy or it is an infinite measure , then for @xmath6-almost all @xmath74 @xmath91 for any finite partition @xmath5 . in this second situation",
    "we introduce the notions of _ local _ and _ global chaos indexes _ to classify dynamical systems according to the asymptotic behaviour of @xmath71 .",
    "let @xmath76 be a dynamical system and @xmath6 a @xmath59-invariant measure .",
    "let @xmath92 be a probability measure on @xmath56 equivalent to @xmath6 ( each one is absolutely continuous with respect to the other ) .",
    "we refer to @xmath92 as a `` reference measure '' .",
    "of course when @xmath6 is a probability measure , we can set @xmath93 .",
    "let @xmath5 be a finite partition of @xmath56 .",
    "[ def : global - ind ] the _ upper chaos index @xmath94 with respect to @xmath5 _ is given by @xmath95 @xmath96 in the same way the _ lower chaos index @xmath97 with respect to @xmath5 _ is defined using the inferior limit instead of the superior limit .",
    "we remark that in principle the chaos index may depend on the choice of @xmath92 . in principle , even if we consider equivalent measures , the index may change . however",
    "we will see that in the class of map we are interested to study this does not happen .",
    "moreover we remark that in the examples we study there is a natural choice of the reference measure , the lebesgue measure .",
    "we also define the _ upper _ and _ lower local chaos indexes_.    [ def : local - ind ] the _ upper local chaos index @xmath98 _ is defined as @xmath99 @xmath100 in the same way the _ lower local chaos index @xmath101 _ is defined using the inferior limit instead of the superior limit .",
    "[ teo : indici ] let @xmath6 be ergodic and invariant for the dynamical system @xmath76 and let @xmath92 be a reference measure . for any finite partition @xmath5 of @xmath56 ,",
    "the local indexes are a.e .- constant , that is for @xmath6-almost all @xmath74 it holds @xmath102 and @xmath103 .",
    "moreover @xmath104    now we want to get rid of the dependence on the partition @xmath5 and define an indicator that is independent on the partition .",
    "we will state a definition for maps over the interval .",
    "further generalizations are possible ( see @xcite ) but for the sake of simplicity here we will restrict to interval maps .    to avoid pathologies coming from very complicated partitions ( see the `` negative results '' in @xcite ) we will consider a class of admissible partitions and take the supremum over this class .    [ xxx ] a partition @xmath105 of @xmath10 $ ]",
    "is called _ admissible _ if it is made of a finite set of intervals , i.e. each @xmath106 is an interval . the _",
    "upper _ and _ lower global weak chaos indexes _ of @xmath107,t,\\nu)$ ] are defined by @xmath108 @xmath109    what we obtained is a weak chaos index for maps of the interval that is in general invariant for a bi - lipschitz conjugacy .",
    "let us consider the lebesgue measure @xmath110 on the unit interval .",
    "if @xmath107,t)$ ] and @xmath107,t')$ ] are conjugated by a bi - lipschitz homeomorphism @xmath111 , then @xmath112 .    * proof . *",
    "it is clear that a homeomorphism sends an admissible partition @xmath5 to an admissible partition @xmath113 .",
    "we have that @xmath114 } \\",
    "\\frac{aic(\\pi(x),n,\\pi(z ) ) } { n^q } \\ dx=\\int_{[0,1 ] } \\",
    "\\frac{aic(x , n , z)}{n^q } \\ f(x)\\ dx\\ ] ] where @xmath115 $ ] and then we can estimate one index in function of the other .",
    "we apply our techniques , based on the asymptotic behaviour of the information content of symbolic orbits , to a family of interval differentiable maps @xmath116\\to [ 0,1]$ ] with an indifferent fixed point .",
    "[ def : mp ] we say that a map @xmath116\\to [ 0,1]$ ] is a _ manneville - pomeau map ( mp map ) _ with exponent @xmath12 if it satisfies the following conditions :    1 .   there is @xmath117 such that , if @xmath118 $ ] and @xmath119 $ ] , then @xmath120 and @xmath121 extend to @xmath14 diffeomorphisms , @xmath122 $ ] , @xmath123 $ ] and @xmath124 ; 2 .",
    "there is @xmath125 such that @xmath126 on @xmath127 , whereas @xmath128 on @xmath129 $ ] and @xmath130 ; 3 .",
    "the map @xmath59 has the following behaviour when @xmath131 @xmath132 for some constant @xmath133 and @xmath134 ( see left part of figure [ figmann ] ) .",
    "this family of maps is well known and many statistical ( the decay of correlations , the central limit theorem and the phenomenon of phase transitions ) and ergodic ( exactness , rational ergodicity , mixing and the return time sequences ) properties have been deeply analyzed .",
    "most of these studies are made for @xmath135 , on the contrary we are mostly interested in the case @xmath136 .",
    "for @xmath137 there is a unique absolutely continuous ( with respect to lebesgue measure ) probability measure @xmath6 that is @xmath59-invariant , moreover @xmath6 is a sinai - ruelle - bowen measure , it is exact and its kolmogorov - sinai entropy satisfies @xmath138 from the statistical point of view , it is known that some changes happen when @xmath12 crosses the value @xmath139 .",
    "however from our point of view these changes are not relevant .",
    "applying theorem [ teo : ks - aic ] and the consequent equation ( [ eq : aic - asint ] ) we obtain that if @xmath59 is a manneville - pomeau map with @xmath137 , and @xmath5 is the generating partition @xmath140 , then for the absolutely continuous @xmath59-invariant probability measure @xmath6 it holds @xmath141 for @xmath6-almost all @xmath142 $ ] .",
    "much more delicate is to study the case @xmath143 . indeed for these values of the parameter",
    "the only absolutely continuous @xmath59-invariant measure @xmath6 is infinite .",
    "hence in this case we obtain from theorem [ teo : aic - mi ] and equation ( [ eq : aic - asint2 ] ) that @xmath144 for @xmath6-almost all @xmath142 $ ] , for any finite partition @xmath5 . to classify these maps we study the behaviour of the chaos indexes introduced in section [ sec : info ] .",
    "the ergodic properties of the infinite measure @xmath6 for mp maps with @xmath143 have been studied in @xcite and @xcite , applying the theory of infinite ergodic measures ( see @xcite ) .",
    "in particular the measure @xmath6 is shown to be exact and rationally ergodic , with estimates for the return time sequences .",
    "putting together the results of @xcite and the darling - kac theorem ( @xcite ) we obtain    [ teo : adkt ] let @xmath59 be a manneville - pomeau map with @xmath143 and @xmath6 the infinite absolutely continuous @xmath59-invariant measure .",
    "then for all borel measurable @xmath145 $ ] with @xmath146 it holds @xmath147 where the convergence is in distribution with respect to all absolutely continuous borel probability measures on @xmath10 $ ] , @xmath148 is a positive random variable distributed according to the normalized mittag - leffler law of order @xmath18 and @xmath149 .",
    "moreover it holds    * @xmath150 if @xmath151 ; * @xmath152 if @xmath15 .",
    "the statistical distribution of the frequencies of visits to subsets of @xmath10 $ ] is the fundamental tool to obtain the behaviour of the @xmath31 of orbits of the system .",
    "our plan is the following :    * to consider a symbolic representation of the system induced by the choice of a partition ; * to estimate the information content of the orbits using a particular encoding as a compression algorithm ; * to show that this information content has the same average asymptotic behaviour as the algorithmic information content .    to obtain a symbolic representation of the system we will consider a finite admissible partition ( see definition [ xxx ] ) .",
    "first we will consider the case of a partition made of two intervals @xmath118 $ ] and @xmath119 $ ] , then we will show that the general case is similar . in this first particular case ,",
    "the alphabet associated to the partition @xmath5 is @xmath153 .",
    "let us consider a mp map .",
    "as said before the presence of the indifferent fixed point at the origin implies that a typical orbit will spend much time near the origin , since it moves away from it very slowly , and will spend the rest of time around in the interval .",
    "then at some time it will come again close to the origin and again stay near the origin a lot of time .",
    "this repeats over and over again .",
    "this fact implies that a typical symbolic orbit will have a lot of symbols equal to `` 0 '' and some equal to `` 1 '' . moreover being the derivative of the map bounded from 1 in @xmath127 ,",
    "the dynamics in this interval is `` fully '' chaotic , and this implies a sort of renewal process when the orbit of the point is in @xmath127 ( see section [ sec : plm ] ) .",
    "the results we will see are in some sense reminiscent of the theory of renewal processes , but this theory fails for mp maps , since they are not isomorphic to a markov chain .",
    "we now introduce the encoding we use to estimate the information .",
    "a typical sequence @xmath154 will look like - a.e .",
    "point @xmath142 $ ] ( analogously to the case of the dyadic numbers for the bernoulli shift ) . ]",
    "@xmath155 so it is possible to compress its first 30 symbols in the following string @xmath156 where we have just written how many `` 0 ' 's there are between two consecutive `` 1 ' 's .",
    "since the number of consecutive zeros can be as high as we want , the string @xmath24 is a string with digits coming from an infinite alphabet ( each digit is a natural number ) .",
    "since we want to deal with strings coming from a finite alphabet we codify @xmath24 into a binary string @xmath157 , simply using the standard binary representation of natural numbers and writing it with the usual prefix - code ( see below for an example ) . in this way",
    "a number @xmath158 is encoded by a binary string @xmath159 such that @xmath160 where @xmath161 ( denoting @xmath162 the inferior integral part of a number ) , and this binary string is written using the prefix - code given by @xmath163 where @xmath164 denotes the symbol `` 1 '' repeated @xmath165 times . in this way , leaving unchanged the symbols `` 0 '' , we obtain for our example @xmath166 hence @xmath167 is an encoding of the string @xmath168 ( see section [ sec : info ] ) .",
    "the information function @xmath25 associated to this compression is given by @xmath169 where @xmath33 denotes the length of the string .",
    "let @xmath170 be the sequence of functions defined by @xmath171 that is the number of passages of the orbit outside the interval @xmath172 in the first @xmath0 steps .",
    "then it is easy to realize that in the case of a partition made by two intervals @xmath173 . in this case",
    "we now prove a stronger relation between @xmath174 and @xmath175 .",
    "[ teo : stima - inf ] for any sequence @xmath176 it holds @xmath177 up to an additive constant given by the possibilities @xmath178 and @xmath179 , and by the presence of the inferior integral part in the definition of @xmath174 .    * proof .",
    "* it is enough to prove the lemma for @xmath180 and @xmath181 .",
    "otherwise simply add a constant .    in general @xmath182 , for some @xmath183 .",
    "the compression of such strings is then @xmath184-symbols long .",
    "moreover the compression is such that @xmath185 .",
    "we now want to find the maximum and the minimum of the function @xmath186 with the condition @xmath185 .",
    "the maximum is attained for equal @xmath187 , and the minimum for all the @xmath188 but one which is equal to @xmath189 .",
    "then the maximum is given by @xmath190 for all @xmath191 , and the information content is given by @xmath192 = n_n + 2\\ n_n \\log_2 \\left ( \\frac{n}{n_n } \\right)$ ] , and the minimum is given by @xmath193 .",
    "hence the lemma is proved .",
    "0.5 cm let us see what can be done when we have some general admissible partition made of a finite number of intervals .",
    "let @xmath194 be such a partition and let @xmath195 be the associated finite alphabet .",
    "in this case we assume @xmath196 to be made of the symbol `` 0 '' for the interval @xmath172 , and of letters ( or any other kind of symbols different from natural numbers ) for the other intervals .",
    "we slightly modify the previous coding procedure as follows .",
    "we have strings @xmath197 , and define @xmath198 , where @xmath199 . in the sense that we codify as numbers the occurrences of the symbol `` 0 '' as before , in a way that if at place @xmath200 there are @xmath201 consecutive `` 0 ' 's we write the number @xmath201 .",
    "the other symbols are left unchanged .",
    "for example , if @xmath202 and @xmath203 then @xmath204 .",
    "then we define @xmath157 as before , by the standard binary encoding of the natural numbers , obtaining a string @xmath157 written in the alphabet @xmath205 . in the previous example",
    ", we obtain @xmath206 .",
    "then we can easily estimate the information function @xmath207 in this case , by noting that the only difference with the previous case of a partition with only two intervals is that now when the symbol in @xmath168 is different from `` 0 '' we have to explicitly specify it , so that in @xmath167 the symbols `` 0 '' are replaced by the explicit strings , that is `` @xmath208 '' and `` @xmath209 '' in our example .",
    "since there are @xmath175 such symbols different from `` 0 '' or `` 1 '' in @xmath167 , we need at most @xmath210 bits more than in the previous case with a partition with only two intervals .",
    "note that in the previous case @xmath211 , hence this new term vanishes .",
    "we can now state the result    [ 3.5 ] let @xmath212 and @xmath157 be the encoding as above , then it holds @xmath213 where @xmath214 is the cardinality of @xmath195 .",
    "this lemma implies that the behaviour of the information content is given by the asymptotic behaviour of the functions @xmath184 .",
    "to estimate the behaviour of @xmath184 first of all notice that if @xmath4 is a point in @xmath10 $ ] such that @xmath215 , then @xmath216\\setminus i_0 } } ( t^j(x))\\ ] ] then we can apply theorem [ teo : adkt ] to the sequence @xmath184 with respect to any measure @xmath92 on @xmath68 induced by an absolutely continuous probability measure on @xmath10 $ ] .",
    "this gives the estimates @xmath217 \\sim \\left\\ { \\begin{array}{ll }      \\frac{n}{\\log",
    "n } , & \\hbox{z=2 ; } \\\\[0.2 cm ]      n^{\\frac{1}{z-1 } } , & \\hbox{z $ > $ 2 . } \\\\",
    "\\end{array } \\right.\\ ] ] obtained by the asymptotic behaviour of the sequence @xmath218 in theorem [ teo : adkt ] , where @xmath219 $ ] denotes the mean with respect to the measure @xmath92 . by the above estimates we have    [ teo : finale1 ]",
    "let @xmath59 be a manneville - pomeau map with parameter @xmath143 .",
    "let @xmath5 be an admissible finite partition .",
    "then for any probability measure @xmath92 on @xmath68 induced by an absolutely continuous probability measure on @xmath10 $ ] through the symbolic representation @xmath70 , it holds @xmath220\\preceq    { \\mathbb e}_\\nu [ i(\\omega^n ) ] \\preceq \\ n , & \\hbox{z=2 } \\\\[0.3 cm ]   { \\mathbb e}_\\nu [ aic(\\omega^n)]\\preceq     { \\mathbb e}_\\nu [ i(\\omega^n ) ] \\preceq \\ n^\\frac{1}{z-1 } \\log ( n ) , & \\hbox{z $ > $ 2}. \\\\ \\end{array}\\ ] ]    proposition [ teo : finale1 ] gives an estimate from above for the asymptotic behaviour of @xmath221 $ ] .",
    "now we want to calculate a lower estimate . for this",
    "we consider a map that is derived by the mp map ( it is an induced map ) and which gives a symbolic dynamics that is similar to the compressed string @xmath222 .",
    "proving that such a map has positive entropy we prove ( using theorem [ teo : ks - aic ] ) that no further drastic compression is possible .",
    "let us consider again the partition @xmath223,(c,1]\\}$ ] , we will give a lower estimate to @xmath224 .",
    "the induced version of a mp map is obtained studying the passages through @xmath127 . for any @xmath142 $ ] let @xmath225 be the _ time of the first passage through @xmath127 _",
    ", that is @xmath226 the level sets of the function @xmath225 are a partition of @xmath227 $ ] into intervals @xmath228 defined as @xmath229 \\",
    "|\\ \\tau(x)=n \\right\\}\\ ] ] using @xmath225 we define the _ induced map _",
    "\\to [ 0,1]$ ] by @xmath231 hence @xmath232 and @xmath233 $ ] , finally we define @xmath234 ( see right part of figure [ figmann ] ) .    [ cols= \" < , < \" , ]",
    "in this paper we considered two classes of weakly chaotic maps of the interval with a neutrally unstable fixed point .",
    "we calculated the information with respect to a partition and showed that this gives an invariant to characterize different weakly chaotic dynamics .",
    "this kind of behaviour for dynamical systems has been largely studied in the last years , from many different points of view .",
    "the importance of our approach lies in the fact that whereas the results given here are theoretical , the idea to use compression algorithms to study and measure experimentally the kind of chaos in intermittent dynamical systems can be practically exploited . in @xcite , using a particular compression algorithm that is suitable for null entropy strings , we performed experiments on some examples of intermittent and weakly chaotic dynamical systems and obtained results that are close to the theoretical predictions .",
    "moreover , the study of weak chaos by compression algorithms gives rise to new questions in data compression ( the search for algorithms that are optimal compressing zero entropy strings ) .",
    "we end remarking that we focused our interest onto maps of the interval . a more general approach to define a weak chaos index that is suitable for maps on a general metric space @xmath56 is to use open covers instead of partitions ( @xcite,@xcite , see also the remarks at the end of section 4 in @xcite ) . in this paper we chose to simplify the question by using admissible partitions , however all the results given here for the partitions hold also for the open covers . in @xcite",
    "there is some example of results of this kind for pl maps ."
  ],
  "abstract_text": [
    "<S> measuring the average information that is necessary to describe the behaviour of a dynamical system leads to a generalization of the kolmogorov - sinai entropy . </S>",
    "<S> this is particularly interesting when the system has null entropy and the information increases less than linearly with respect to time . </S>",
    "<S> we consider two classes of maps of the interval with an indifferent fixed point at the origin and an infinite natural invariant measure . </S>",
    "<S> we calculate that the average information that is necessary to describe the behaviour of its orbits increases with time @xmath0 approximately as @xmath1 , where @xmath2 depends only on the asymptotic behaviour of the map near the origin . </S>"
  ]
}