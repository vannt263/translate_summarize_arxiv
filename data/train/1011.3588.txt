{
  "article_text": [
    "in modern wireless communication systems , interference has become the major barrier for efficient utilization of available spectrum . in many scenarios ,",
    "interferences are originated from sources close to transmitters and hence can be inferred by intelligent transmitters , while receivers can not due to physical limitations . with the knowledge of interferences as side information",
    ", transmitters are able to encode their information against interferences and mitigate them , even though receivers can not distinguish interferences from desired signals .",
    "the simplest information theoretic model for studying such interference mitigation is the single - user point - to - point dirty - paper channel @xcite , which is a special case of state - dependent memoryless channels with the state known non - causaully to the transmitter @xcite .",
    "it is shown that the effect of interference can be completely removed in the additive white gaussian noise ( awgn ) channel when the interference is also additive white gaussian @xcite .",
    "as for multi - user scenarios , it has been found that when perfect state information ( the additive interference ) is available non - causally at all transmitters , the capacity region of the awgn multiple access channel ( mac ) is not affected by the additive white gaussian interference @xcite @xcite .",
    "when the sate information is known _ partially _ to different transmitters in the mac , however , the capacity loss caused by the interference is unbounded as the signal - to - noise ratios increase @xcite @xcite .",
    "since each transmitter only has partial knowledge about the interference , interference cancellation has to be realized in a _ distributed _ manner .    in this paper",
    ", we consider a @xmath0-user gaussian mac with @xmath0 independent additive white gaussian interferences . each interference is known to exactly one transmitter non - causally . transmitter @xmath1",
    ", for all @xmath2 , aims to deliver a message @xmath3 to the receiver reliably through the channel depicted in fig .",
    "[ fig_model ] , where @xmath4 and @xmath5 is the awgn noise .",
    "interference @xmath6 , @xmath2 , independent of everything else , is known non - causally to transmitter @xmath1",
    "_ only_. power constraint at transmitter @xmath1 is @xmath7 , @xmath2 .",
    "define channel parameters @xmath8 , @xmath9 , for @xmath10 .",
    "user @xmath1 s rate is denoted by @xmath11 , @xmath2 . throughout this paper , without loss of generality we assume that @xmath12 .          state - dependent networks with partial state knowledge available at different nodes have been studied in various scenarios .",
    "kotagiri _ et al._@xcite study the state - dependent two - user mac with state non - causally known to a transmitter , and for the gaussian case they characterize the capacity asymptotically at infinite interference ( @xmath13 ) as the informed transmitter s power grows to infinity .",
    "somekh - baruch _",
    "et al._@xcite study the problem with the same set - up as @xcite while the informed transmitter knows the other s message , and they characterize the capacity region completely .",
    "et al._@xcite study another case of degraded message set .",
    "the achievability part of @xcite , @xcite , and @xcite are based on random binning .",
    "et al._@xcite , on the other hand , characterize the capacity region of the doubly - dirty mac to within a constant gap at infinite interference ( i.e. , @xmath14 , @xmath15 ) , by lattice strategies @xcite .",
    "they also show that strategies based on gaussian random binning is unboundedly worse than lattice - based strategies .",
    "zaidi _ et al._@xcite @xcite and akhbari _",
    "et al._@xcite study a state - dependent relay channel where the state is only known either at the source or the relay .",
    "we characterize the capacity region of the channel in fig .",
    "[ fig_model ] to within @xmath16 bits , regardless of channel parameters @xmath7 s , @xmath17 s , and @xmath18 .",
    "the constant gap only depends on the number of users in the channel and is independent of channel parameters , providing a strong guarantee on the performance for any fixed @xmath0 .",
    "our approach to this problem is first investigating a _ binary expansion model _ of the original channel .",
    "the binary expansion model is a natural extension of the linear deterministic model proposed in @xcite to the case with additive interferences known to transmitters . after characterizing the capacity region of the binary expansion model ,",
    "we then make use of the intuitions and techniques developed there to derive outer bounds and build up achievability results for the original gaussian problem .",
    "such approach has been successfully applied to various problems in network information theory , including @xcite , @xcite , @xcite , @xcite , @xcite , etc . for the achievability",
    "part we propose a layered modulo - lattice scheme consisting of @xmath0 layers , based on the intuition drawn from the study of the binary expansion model .",
    "layer @xmath1 is shared among user @xmath19 , and the hierarchy of the layers is @xmath20 , from the top to the bottom .",
    "each layer treats the signals sent at higher layers as _ interference _ , each of which is known non - causally to exactly one transmitter . in each layer @xmath21",
    ", we use a modulo - lattice scheme to realize distributed interference cancellation , which is a simpler version of the single layer scheme in @xcite . for the converse part , we first extend the ideas in @xcite to derive matching outer bounds for the binary expansion model and then use the same technique to prove bounds in the gaussian scenario .",
    "notations used in this paper are summarized below :    * throughout the paper , the block coding length is denoted by @xmath22 . a sequence of random variables @xmath23,\\ldots , x[n]$ ] is denoted by @xmath24 and boldface @xmath25 interchangeably . *",
    "logarithms are of base @xmath26 if not specified .",
    "we use short - hand notations @xmath27 to denote @xmath28 and @xmath29 to denote @xmath30 .",
    "* we use the short - hand notation @xmath31 $ ] to denote a set / tuple @xmath32 and @xmath33}$ ] to denote @xmath34 if @xmath35 , respectively . if @xmath36 , @xmath31 $ ] and @xmath33}$ ] denote the empty set @xmath37 . *",
    "similarly , for a set of indices @xmath38 , we use @xmath39 to denote the collection @xmath40 .",
    "the rest of this paper is organized as follows . in section  [ sec_ldc ] ,",
    "we first introduce and formalize the binary expansion model , which serves as an auxiliary channel for the original one .",
    "then we characterize the capacity region of the auxiliary channel and draw important intuitions for solving the original problem . in section  [ sec_lattice ] ,",
    "we propose the layered modulo - lattice scheme and derive its achievable rates .",
    "then we show that the achievable rate region is within a constant gap to the proposed outer bounds in section  [ sec_constgap ] .",
    "finally , we conclude the paper in section  [ sec_conclude ] .",
    "to approach the distributed interference cancellation problem in gaussian multiple access channels ( mac ) , we first study a binary expansion model of the original problem .",
    "solutions to the original problem can be inferred by solving the auxiliary problem in this model .",
    "the model is a natural generalization of the linear deterministic model proposed in @xcite , with random states acting as additive interferences .",
    "we formally define the model as follows .",
    "[ def_ldc ] the binary expansion mac with additive interferences known to transmitters , corresponding to the original gaussian problem , is defined by nonnegative integers @xmath41 transmitted signals @xmath42 , interferences @xmath43 for @xmath44 $ ] , and received signal @xmath45 where additions are modulo - two component - wise , @xmath46\\rbp$ ] , and @xmath47 is the shift matrix @xmath48}.\\end{aligned}\\ ] ] each interference @xmath49 consists of @xmath50 i.i.d .",
    "@xmath51 bits and is known to transmitter @xmath1 , for @xmath44 $ ] .",
    "here we use subscript @xmath52 to draw distinction from the original channel model . note",
    "that the condition @xmath12 implies @xmath53 .",
    "an example is depicted in fig .",
    "[ fig_ldc ] , where @xmath54 .",
    "the main result in this section is the characterization of capacity region of the auxiliary channel , summarized in the following theorem and two lemmas . to distinguish notations from the original gaussian problem ,",
    "lower - cases letters are used to represent rates in the binary expansion model .",
    "[ lem_ldcconverse ] if @xmath55}\\ge 0 $ ] is achievable , it satisfies the following : for all @xmath56 $ ] , @xmath57 } , m_{[k+1:k]};k{\\right)},\\end{aligned}\\ ] ] where @xmath58 } , m_{[k+1:k]};k{\\right)}:= \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[k+1:k]},n_k\\rbp - \\sum_{i = k+1}^{k}{\\left(}m_i - \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[i+1:k ] } , n_i\\rbp{\\right)}^+.\\end{aligned}\\ ] ]    the proof is detailed in section  [ subsec_ldcconverse ] .",
    "[ lem_ldcachieve ] if @xmath55}\\ge 0 $ ] satisfies the following : for all @xmath56 $ ] , @xmath59 } , m_{[k+1:k]};k{\\right)}\\end{aligned}\\ ] ] it is achievable .",
    "here @xmath60 } , m_{[k+1:k]};k{\\right)}:= \\sum_{i = k}^k { \\left(}n_i - \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[i+1:k ] } , n_{i+1}\\rbp{\\right)}^+.\\end{aligned}\\ ] ]    the proof is detailed in section  [ subsec_ldcachieve ] .",
    "[ thm_ldc ] @xmath55}\\ge 0 $ ] is achievable , if and only if it satisfies the following : for all @xmath56 $ ] , @xmath61 } , m_{[k+1:k]};k{\\right)},\\end{aligned}\\ ] ] where @xmath62 } , m_{[k+1:k]};k{\\right)}= { \\overline}{{\\mathsf}{r}}_k{\\left(}n_{[k : k ] } , m_{[k+1:k]};k{\\right)}= { \\underline}{{\\mathsf}{r}}_k{\\left(}n_{[k : k ] } , m_{[k+1:k]};k{\\right)}$ ] .    to show @xmath63 } , m_{[k+1:k]};k{\\right)}= { \\underline}{{\\mathsf}{r}}_k{\\left(}n_{[k : k ] } , m_{[k+1:k]};k{\\right)}$ ] for all @xmath64 $ ] , we shall use induction backwards .",
    "\\1 ) @xmath65 : @xmath66 .",
    "2 ) suppose the claim is correct for @xmath67 .",
    "for @xmath68 , @xmath69 } , m_{[l : k]};k{\\right)}- { \\overline}{{\\mathsf}{r}}_l{\\left(}n_{[l : k ] } , m_{[l+1:k]};k{\\right)}\\\\ & = \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[l : k]},n_{l-1}\\rbp - \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[l+1:k]},n_{l}\\rbp - { \\left(}m_l - \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[l+1:k ] } , n_l\\rbp{\\right)}^+\\\\ & = \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[l : k]},n_{l-1}\\rbp - \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[l+1:k]},n_{l},m_l\\rbp\\\\ & = \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[l : k]},n_l , n_{l-1}\\rbp - \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[l :",
    "k]},n_{l}\\rbp\\\\ & = \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}\\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[l : k]},n_l\\rbp , n_{l-1}\\rbp - \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[l : k]},n_{l}\\rbp\\\\ & = { \\left(}n_{l-1 } - \\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[l : k ] } , n_{l}\\rbp{\\right)}^+ = { \\underline}{{\\mathsf}{r}}_{l-1}{\\left(}n_{[l-1:k ] } , m_{[l : k]};k{\\right)}- { \\underline}{{\\mathsf}{r}}_l{\\left(}n_{[l : k ] } , m_{[l+1:k]};k{\\right)}.\\end{aligned}\\ ] ] hence , @xmath70 } , m_{[l : k]};k{\\right)}= { \\underline}{{\\mathsf}{r}}_{l-1}{\\left(}n_{[l-1:k ] } , m_{[l : k]};k{\\right)}$ ] . by induction principle",
    ", the proof is complete .",
    "before we formally prove the converse and the achievability , we first give a couple of examples to illustrate the high - level intuition behind the result .",
    "such intuitions not only work for the binary expansion model , but also carry over to the original gaussian setting . for simplicity , all examples are two - user ( @xmath14 ) , with fixed @xmath71 and various @xmath72 .",
    "they are depicted in fig .",
    "[ fig_examples ] . although the total number of bit levels of @xmath73 is @xmath74 , referring to fig .",
    "[ fig_ldc ] only the first @xmath75 least significant bit ( lsb ) levels are those can be potentially used for communicating information , since none of the transmitters can access the upper bit levels owing to power constraints .",
    "therefore , with the side information of interferences at transmitters , they try to cancel interferences in these @xmath76 levels as much as possible .    the first example ( fig .",
    "[ fig_examples](a ) ) illustrates the situation where @xmath77 and @xmath78 .",
    "transmitter 1 can completely cancel interference @xmath79 since it only occupies @xmath80 lsb levels of @xmath73 .",
    "transmitter 2 can also cancel interference @xmath81 completely since it only occupies @xmath82 lsb level of @xmath73 .",
    "therefore , all bit levels are free from interference , and the capacity region is @xmath83 which is the same as the clean mac .",
    "the second example ( fig .  [ fig_examples](b ) ) illustrates the situation where @xmath84 and @xmath78 .",
    "transmitter 1 can not completely cancel interference @xmath79 since it occupies @xmath85 lsb levels of @xmath73 , while transmitter 1 has access to only @xmath86 lsb levels .",
    "however , it can cancel those in the first @xmath76 lsb levels .",
    "transmitter 2 can again cancel interference @xmath81 completely .",
    "therefore , all @xmath76 lsb levels are free from interference , and the capacity region is @xmath83 which is again the same as the clean mac .    from the above examples , we see that the strength of interference @xmath79 does not effect the capacity region , since the only bit levels that matter are the @xmath87 lsb levels , and transmitter 1 can always  clean up \" the interference caused by @xmath79 in these bit levels . on the other hand",
    ", the strength of interference @xmath81 _ does _ affect the capacity region , as discussed below .",
    "the third example ( fig .  [ fig_examples](c ) ) illustrates the situation where @xmath88 .",
    "since transmitter 2 only has access to @xmath89 lsb levels , it can not cancel the interference caused by @xmath81 at the third lsb level .",
    "therefore , the level is no longer useful and can not be used by transmitter 1 .",
    "the fourth lsb level , however , is clean after transmitter 1 s interference cancellation .",
    "the capacity region becomes @xmath90 .",
    "the last example ( fig .  [ fig_examples](d ) ) illustrates the situation where @xmath91 .",
    "again transmitter 2 can not do anything about @xmath81 except at the @xmath26 lsb levels .",
    "therefore , the third and the fourth bit levels are both corrupted and can not be used .",
    "the capacity region becomes @xmath92 .",
    "[ fig_examples](e ) depicts the degradation of the capacity regions due to various strengths of @xmath81 . from the above discussions , we make the following observations .",
    "* the strength of the interference that is known to the strongest transmitter , that is , @xmath79 , does not affect the capacity region , as in the single - user point - to - point case . *",
    "based on the interference cancellation capability of each transmitter ( its transmit power ) , the bit levels of @xmath73 can be partitioned into @xmath0 layers ( here @xmath14 ) : layer 1 , consisting of the third and the fourth lsb levels , and layer 2 , consisting of the first and second levels . in the bottom layer @xmath26 , both interferences caused by @xmath79 and @xmath81 can be completely cancelled . in this layer",
    "both users share @xmath93 bit levels . on the other hand , in the top layer @xmath94",
    ", only the interference caused by @xmath79 can be cancelled , while that caused by @xmath81 can not",
    ". hence in this layer user 1 can only use @xmath95 levels .",
    "these observations lead to a natural way for establishing achievability , which is detailed in section  [ subsec_ldcachieve ] . for the converse",
    ", the above discussion gives the intuitive explanation why the lack of knowledge about @xmath81 at transmitter 1 degrades the capacity region . in section  [ subsec_ldcconverse ]",
    "we give a formal converse proof .",
    "each transmitter , say @xmath1 , cancels the interference it knows , @xmath49 , as much as it can .",
    "if @xmath96 , then @xmath49 can be completely canceled . if @xmath97 , then the top most @xmath98 levels of @xmath49 can not be removed , and the bit levels of @xmath99 occupied by this chunk can never be used to convey data by any user .",
    "since the channel is linear and the interferences are additive , the effect of interference cancelation remains for other users .    superimposed upon interference cancellation ,",
    "the scheme consists of @xmath0 layers .",
    "layer @xmath1 is from the @xmath100-th level of lsb to the @xmath101-th level at the receiver , @xmath44 $ ] . in layer",
    "@xmath1 , user @xmath102 $ ] can transmit .",
    "therefore , we have the following achievable rates in layer @xmath1 , @xmath44 $ ] : @xmath103 } \\ge 0 $ ] satisfying @xmath104 } , n_{i+1}\\rbp{\\right)}^+.\\end{aligned}\\ ] ]    user @xmath1 s rate is the aggregate of its rates from layer @xmath1 to layer @xmath0 : @xmath105 .",
    "apply fourier - motzkin elimination we establish lemma [ lem_ldcachieve ] .",
    "next we prove the outer bounds in lemma [ lem_ldcconverse ] .",
    "let @xmath106 here we use @xmath107 to denote @xmath108 and @xmath109 to denote @xmath110 for notational convenience .",
    "it is easy to distinguish these notations from those in the original gaussian model based on the context .",
    "if @xmath55}$ ] is achievable , for any @xmath56 $ ] by fano s inequality and data processing inequality , we have @xmath111 } ; y_b^n | w_{[1 : k-1]}{\\right)}\\\\ & \\overset{{\\mathrm{(a)}}}{\\le } i{\\left(}w_{[k : k ] } ; y_b^n | w_{[1 : k-1 ] } , s^n_{[1:k-1]}{\\right)}\\\\ & = h{\\left(}y_b^n | w_{[1 : k-1 ] } , s^n_{[1:k-1]}{\\right)}- h{\\left(}y_b^n | w_{[1 : k ] } , s^n_{[1:k-1]}{\\right)}\\\\ & = h{\\left(}y_{b , k}^n | w_{[1 : k-1 ] } , s^n_{[1:k-1]}{\\right)}- h{\\left(}y_{b , k}^n | w_{[1 : k ] } , s^n_{[1:k-1]}{\\right)}\\\\ & \\overset{{\\mathrm{(b)}}}{= } i{\\left(}w_{[k : k ] } ; y_{b , k}^n{\\right)}= i{\\left(}w_{[k : k ] } , s_{[k : k]}^n ; y_{b , k}^n{\\right)}- i{\\left(}s_{[k : k]}^n ; y_{b , k}^n| w_{[k : k]}{\\right)}\\\\ & \\overset{{\\mathrm{(c)}}}{= } h{\\left(}y_{b , k}^n{\\right)}- \\sum_{i = k}^k h{\\left(}s_{i}^n{\\right)}+ h{\\left(}s_{[k : k]}^n | y_{b , k}^n , w_{[k : k]}{\\right)}\\\\ & = h{\\left(}y_{b , k}^n{\\right)}- \\sum_{i = k}^k h{\\left(}s_i^n{\\right)}+ \\sum_{i = k}^k h{\\left(}s_i^n | y_{b , k}^n , w_{[k : k ] } , s_{[k : i-1]}^n{\\right)}\\\\ & \\overset{{\\mathrm{(d)}}}{\\le } h{\\left(}y_{b , k}^n{\\right)}- h{\\left(}s_k^n{\\right)}+ h{\\left(}s_k^n|y_{b , k}^n{\\right)}- \\sum_{i = k+1}^{k } h{\\left(}s_i^n{\\right)}+ \\sum_{i = k+1}^{k } h{\\left(}s_i^n | y_{b , i}^n , w_{[i : k]}{\\right)}\\\\ & \\overset{{\\mathrm{(e)}}}{\\le } h{\\left(}y_{b , k}^n| s_k^n{\\right)}- \\sum_{i = k+1}^{k } h{\\left(}s_i^n{\\right)}+ \\sum_{i = k+1}^{k } \\min{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}h{\\left(}s_i^n { \\right ) } , h{\\left(}x_i^n + \\sum_{l = i+1}^{k } { \\left(}x_l^n+s_l^n{\\right)}{\\right)}\\rbp\\\\ & \\le n{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}\\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[k+1:k]},n_k\\rbp -   \\sum_{i = k+1}^{k } m_i +   \\sum_{i = k+1}^{k } \\min{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_i,\\max{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}m_{[i+1:k ] } , n_i\\rbp \\rbp \\rbp \\label{eq_upterm } , \\ ] ] where @xmath112 as @xmath113 . ( a ) is due to the facts that conditioning reduces entropy and that @xmath114}$ ] is independent of @xmath115}$ ] .",
    "( b ) is due to the fact that @xmath116 } , s_{[k : k]}^n , y_{b , k}^n{\\right)}$ ] and @xmath117 } , s_{[1:k-1]}^n{\\right)}$ ] are independent .",
    "( c ) is due to the fact that @xmath118},s_{[k : k]}^n \\rbp$ ] are mutually independent and @xmath119 is a function of @xmath118},s_{[k : k]}^n \\rbp$ ] .",
    "( d ) is due to conditioning reduces entropy and the fact that @xmath120 } , s_{[i : k]}^n , y_{b , i}^n{\\right)}$ ] and @xmath121 } , s_{[k : i-1]}^n{\\right)}$ ] are independent .",
    "( e ) is due to the fact that @xmath122 .",
    "it is straightforward to see that @xmath123 } , m_{[k+1:k]};k{\\right)}$ ] .",
    "proof complete .      by investigating the binary expansion model",
    ", we gain intuitions about how to solve the original gaussian problem . for the outer bounds",
    ", we will mimic the proof in section [ subsec_ldcconverse ] . for the achievability in the binary expansion model , interference cancellation",
    "is realized by simply subtracting interferences from the transmit signals . due to linearity of the channel and the fact that there is no interaction among different bit levels , if an interference , say , a component of @xmath79 , is cancelled by transmitter 1 , it will remain cancelled for other users as well . to realize such",
    "distributed interference cancellation in the gaussian scenario , however , philosof _",
    "et al._@xcite show that gelfand - pinsker scheme based on gaussian random binning is not sufficient .",
    "instead , they propose a modulo - lattice scheme which can carry out this task .",
    "motivated by the layered nature in the achievability of the binary expansion model , we propose a _ layered _",
    "modulo - lattice scheme , generalized from the single - layer scheme in @xcite , to realize distributed interference cancellation in all layers , and show that it achieves the capacity region to within a constant number of bits .",
    "in this section we first give a brief review on lattices and propose the modulo - lattice scheme used in each layer of our layered architecture .",
    "then we connect all layers , describe the overall architecture , and derive the achievable rates in all layers .      before introducing the modulo - lattice scheme ,",
    "first we give some basic definitions and facts about lattices . for more detailed introduction",
    ", please refer to @xcite and the references therein . for completeness",
    ", the following basic and useful facts adapted from @xcite are introduced .    an @xmath22-dimensional lattice @xmath124 is defined as @xmath125 where @xmath126 is non - singular . by definition , the origin @xmath127 .    a natural procedure associated to lattice @xmath124 is to quantize points in @xmath128 to the nearest lattice point .",
    "the nearest neighbor quantizer associated with lattice @xmath124 is defined as @xmath129 here @xmath130 denote the euclidean norm .",
    "another natural procedure is to take the modulo on a lattice . for any @xmath131",
    ", its modulo on lattice @xmath124 is the  quantization error \" @xmath132 note that the modulo - lattice operation satisfies the distributive property : for any @xmath133 ,",
    "@xmath134}\\bmod \\lambda = { \\left[}{\\mathbf}{x } + { \\mathbf}{y}{\\right]}\\bmod \\lambda.\\end{aligned}\\ ] ]    the basic voronoi region of lattice @xmath124 is defined as @xmath135 we denote the volume of @xmath136 by @xmath137 , @xmath138 .",
    "the second moment of the a lattice @xmath124 is defined by the second moment per dimension of a uniform distribution over the basic voronoi region @xmath136 : @xmath139 the normalized second moment is defined by @xmath140 note that the normalized second moment of a lattice is always lower bounded by @xmath141 @xcite .",
    "the following lemmas @xcite turn out to be useful for computing achievable rates .",
    "[ lem_entropy ] for a given @xmath22-dimensional lattice @xmath124 with basic voronoi region @xmath136 , if random vector @xmath142 , then @xmath143    [ lem_white ] consider an @xmath22-dimensional lattice @xmath124 has the minimal normalized second moment . if random vector @xmath142 , then its covariance matrix is white : @xmath144 .",
    "moreover , there exists a sequence of such lattices @xmath145 , that is _",
    "good for quantization _ , in the sense that they attain the lower bound @xmath141 as @xmath146 : @xmath147      in each layer , we shall use the following canonical modulo - lattice scheme , which is a simplified version of that in @xcite .    consider a generic layer @xmath148 where the subset of participating users is @xmath149 $ ] .",
    "the received signal can be written as @xmath150 where @xmath151 denotes user @xmath1 s transmit signal in this layer , @xmath152 denotes the _ interference _ in this layer that is known to user @xmath1 , and @xmath153 denotes the effective aggregate _ noise _ in this layer .",
    "all the transmit signals , interferences , and the noise are mutually independent .",
    "the difference between interference and noise is that , interference is mitigated using side information precoding , while noise can not and hence persists in the received signal . as we shall see in the overall architecture of our layered strategy",
    ", interferences @xmath152 and effective noise @xmath153 will contain the signals sent in other layers , and hence is not necessary gaussian .",
    "the canonical modulo - lattice scheme is configured by three parameters : ( 1 ) an @xmath22-dimensional lattice @xmath154 , ( 2 ) its second moment @xmath155 , and ( 3 ) @xmath149 $ ] , the subset of users participating in the transmission . for each user @xmath156 , its corresponding sub - encoder in this",
    "layer uses lattice @xmath154 with second moment @xmath155 and basic voronoi region @xmath157 to modulate its sub - message @xmath158 in this layer .",
    "its codeword , @xmath159 , is generated according to @xmath160 with rate @xmath161 .",
    "the transmit signal @xmath162 is generated according to the following modulo - lattice operation : @xmath163}\\bmod \\lambda^{(k ) } , \\label{eq_modtx}\\end{aligned}\\ ] ] where @xmath164 independent of everything else , is the dither known at the receiver ( common randomness ) .",
    "the corresponding decoder in this layer , upon receiving @xmath165 , first multiplies @xmath165 by @xmath166 , adds the dithers back , and then takes the modulo @xmath154 operation .",
    "the output becomes @xmath167}\\bmod \\lambda^{(k ) } \\label{eq_decode1}\\\\ & = { \\left[}{\\mathbf}{y } - { \\left(}1-\\alpha^{(k)}{\\right)}{\\mathbf}{y } + \\sum_{i\\in s^{(k ) } } { \\mathbf}{d}_i^{(k)}{\\right]}\\bmod \\lambda^{(k)}\\\\ & = { \\left[}\\begin{array}{l } \\sum_{i\\in s^{(k ) } } { \\left[}{\\mathbf}{v}_i^{(k ) } - \\alpha^{(k)}{\\mathbf}{s}_i^{(k ) } - { \\mathbf}{d}_i^{(k ) } { \\right]}\\bmod \\lambda^{(k ) } + \\sum_{i\\in s^{(k ) } } { \\mathbf}{s}^{(k)}_i",
    "+ { \\mathbf}{z}^{(k)}\\\\ - { \\left(}1-\\alpha^{(k)}{\\right)}{\\left(}\\sum_{i\\in s^{(k ) } } { \\mathbf}{x}^{(k)}_i + \\sum_{i\\in s^{(k ) } } { \\mathbf}{s}^{(k)}_i + { \\mathbf}{z}^{(k)}{\\right)}+ \\sum_{i\\in s^{(k ) } } { \\mathbf}{d}_i^{(k)}\\end{array}{\\right]}\\bmod \\lambda^{(k)}\\\\ & = { \\left[}\\sum_{i\\in s^{(k ) } } { \\mathbf}{v}_i^{(k ) } + \\alpha^{(k)}{\\mathbf}{z}^{(k ) } - { \\left(}1-\\alpha^{(k)}{\\right)}\\sum_{i\\in s^{(k ) } } { \\mathbf}{x}^{(k)}_i { \\right]}\\bmod \\lambda^{(k)}\\\\ & = { \\left[}\\sum_{i\\in s^{(k ) } } { \\mathbf}{v}_i^{(k ) } + { \\mathbf}{z}_{\\rm{eq}}^{(k ) } { \\right]}\\bmod \\lambda^{(k ) } , \\label{eq_decode2}\\end{aligned}\\ ] ] where @xmath168 denotes the _ effective noise _ in the _ effective modulo - lattice channel _ in layer @xmath148 . from the first line , due to dithers the output signal @xmath169 .",
    "moreover , @xmath170 is independent of @xmath171 due to dithering @xcite .",
    "now we are ready to describe the overall architecture of our layered modulo - lattice scheme .    _",
    "encoding _    for encoding , we shall use an inductive way to describe from the top layer @xmath94 to the bottom layer @xmath0 , which corresponds to the order of encoding .",
    "\\1 ) layer @xmath94 : in this layer , the set of participating users is @xmath172 .",
    "we choose the modulation lattice @xmath173 to be the one that attaining the minimal normalized second moment with second moment @xmath174 . the interference @xmath175",
    "the sub - encoder @xmath176 generates @xmath177 based on for @xmath178 , and feeds @xmath179 to the next - layer sub - encoder @xmath180 .",
    "2 ) layer @xmath181 : the set of participating users is @xmath182 $ ] .",
    "the modulation lattice @xmath154 is the one that attaining the minimal normalized second moment with second moment @xmath183 . the known interference @xmath184 , for all @xmath185 $ ] , and @xmath186 .",
    "the sub - encoder @xmath187 generates @xmath188 based on , and feeds @xmath189 to the next - layer sub - encoder @xmath190 , for all @xmath191 $ ] .",
    "3 ) layer @xmath0 : the set of participating users is @xmath192 $ ] .",
    "the modulation lattice @xmath193 is the one that attaining the minimal normalized second moment with second moment @xmath194 . the known interference @xmath195 , for all @xmath196 $ ] , and @xmath197 .",
    "the sub - encoder @xmath198 generates @xmath199 based on for @xmath65 .",
    "_ decoding _",
    "the receiver decodes layer @xmath64 $ ] with sub - decoder @xmath200 . unlike the sequential operation at the sub - encoders , these sub - decoders work _ in parallel_.",
    "@xmath200 takes the received signal @xmath165 as input , which can be written as , and takes the operation in @xmath201 to generate @xmath202 . with the above - mentioned encoding operations , the effective noise @xmath203}&= { \\left\\ { } \\newcommand{\\rbp}{\\right\\}}\\begin{array}{ll } { \\left(}n_o + \\sum_{l = k+1}^k { \\left(}q_l + l\\theta^{(l)}{\\right)}{\\right)}i_n , & 1\\le k \\le k-1\\\\ n_oi_n , & k = k \\end{array}\\right",
    ": = n^{(k)}i_n , \\label{eq_cov}\\end{aligned}\\ ] ] due to our choice of lattices and lemma [ lem_white ] .",
    "@xmath204 denotes the effective per - symbol noise variance in layer @xmath148 . due to dithering , indeed @xmath205}$ ] , @xmath206}$ ] , and @xmath153",
    "are mutually independent .",
    "based on @xmath202 , it performs joint typicality decoding as in standard mac to find @xmath207 , where @xmath182 $ ] .    the overall architecture of transmitters and receiver is depicted in fig .  [ fig_enck ] .",
    "the achievable rates of the scheme in this layer can be derived following the same line of analysis as in @xcite : non - negative rate tuples @xmath208}$ ] is achievable , if @xmath209 } ; { \\mathbf}{y}^{(k)}{\\right)}= h{\\left(}{\\mathbf}{y}^{(k)}{\\right)}- h{\\left(}{\\left[}\\sum_{i=1}^k { \\mathbf}{v}_i^{(k ) } + { \\mathbf}{z}_{\\rm{eq}}^{(k ) } { \\right]}\\bmod \\lambda^{(k)}\\bigg| { \\mathbf}{v}^{(k)}_{[1:k]}{\\right)}. \\label{eq_achieve}\\end{aligned}\\ ] ]    since @xmath169 , due to lemma [ lem_entropy ] , the first term @xmath210 . moreover , since the modulo operation only reduces the entropy , the second term can be upper bounded as follows : @xmath211}\\bmod \\lambda^{(k)}\\bigg| { \\mathbf}{v}^{(k)}_{[1:k]}{\\right)}\\\\ & \\le h{\\left(}\\sum_{i=1}^k { \\mathbf}{v}_i^{(k ) } + { \\mathbf}{z}_{\\rm{eq}}^{(k ) } \\bigg| { \\mathbf}{v}^{(k)}_{[1:k]}{\\right)}\\\\ & \\overset{{\\mathrm{(a)}}}{= } h{\\left(}{\\mathbf}{z}_{\\rm{eq}}^{(k ) } { \\right)}\\\\ & \\overset{{\\mathrm{(b)}}}{\\le } \\frac{n}{2}\\log{\\left(}2\\pi e{\\left(}{\\left(}\\alpha^{(k)}{\\right)}^2n^{(k ) } + { \\left(}1-\\alpha^{(k)}{\\right)}^2k\\theta^{(k ) } { \\right)}{\\right)}.\\end{aligned}\\ ] ] ( a ) is due to the fact that @xmath170 and @xmath212}$ ] are independent .",
    "( b ) is due to the fact that gaussian distribution is the entropy maximizer for a given covariance matrix , and that the covariance matrix of @xmath213 is @xmath214}= { \\left(}\\alpha^{(k)}{\\right)}^2n^{(k ) } i_n +   { \\left(}1-\\alpha^{(k)}{\\right)}^2 k\\theta^{(k ) } i_n , \\end{aligned}\\ ] ] based on and lemma  [ lem_white ] .",
    "hence , combining the above two , we obtain a lower bound on the right - hand side of : @xmath215    based on lemma [ lem_white ] , there exists a sequence of lattices satisfying , and therefore all non - negative rates satisfying @xmath216 are achievable in layer @xmath148 , @xmath64 $ ] .",
    "note that the optimal choice of @xmath166 is the mmse coefficient @xmath217 , and the resulting rate constraint is @xmath218 for notational convenience , we denote @xmath219 .    in the next section ,",
    "we derive outer bounds based on similar proof techniques as in the binary expansion model ( section  [ subsec_ldcconverse ] ) , derive inner bounds based on the discussion above , and show that they are within a constant number of bits to one another .",
    "the main result is summarized in the following lemmas and theorem .",
    "[ lem_gcconverse ] if @xmath220}\\ge 0 $ ] is achievable , it satisfies the following : for all @xmath56 $ ] , @xmath221 } , { \\mathsf{inr}}_{[k+1:k]};k{\\right)},\\end{aligned}\\ ] ] where @xmath222 } , { \\mathsf{inr}}_{[k+1:k]};k{\\right)}:= { \\left\\ { } \\newcommand{\\rbp}{\\right\\}}\\begin{array}{l}\\frac{1}{2}\\log{\\left(}1+\\sum_{i = k+1}^{k}2{\\left(}{\\mathsf{snr}}_i+{\\mathsf{inr}}_i{\\right)}+{\\mathsf{snr}}_k{\\right)}\\\\ - \\sum_{i = k+1}^{k}\\frac{1}{2}\\log^+{\\left(}\\frac{{\\mathsf{inr}}_i}{1+\\sum_{l = i+1}^{k}2{\\left(}{\\mathsf{snr}}_l+{\\mathsf{inr}}_i{\\right)}+{\\mathsf{snr}}_i}{\\right)}\\end{array}\\rbp \\ ] ]    the technique is similar to the converse proof for the binary expansion model . see appendix  [ app_pf_lem_gcconverse ] for detail .",
    "[ lem_gcachieve ] if @xmath220}\\ge 0 $ ] satisfies the following : for all @xmath56 $ ] , @xmath223 } , { \\mathsf{inr}}_{[k+1:k]};k{\\right)}\\end{aligned}\\ ] ] it is achievable .",
    "here @xmath224 } , { \\mathsf{inr}}_{[k+1:k]};k{\\right)}:= \\begin{array}{l}\\sum_{i = k}^k \\frac{1}{2}\\log^+{\\left(}\\frac{1 + i{\\mathsf{snr}}_{i } + \\sum_{j = i+1}^k { \\left(}{\\mathsf{snr}}_j+{\\mathsf{inr}}_j{\\right)}}{i{\\left(}1 + i{\\mathsf{snr}}_{i+1 } + \\sum_{j = i+1}^k { \\left(}{\\mathsf{snr}}_j+{\\mathsf{inr}}_j{\\right)}{\\right)}}{\\right)}\\end{array}\\end{aligned}\\ ] ]    based on section  [ subsec_latticerate ] , user @xmath1 s aggregate rate @xmath11 is the sum of rates in all layers in which it participates , that is , layer @xmath1 to layer @xmath0 : @xmath225 . applying fourier - motzkin elimination , we complete the proof .",
    "[ thm_gc ] @xmath226 + the above inner and outer bounds are within @xmath227 bits for user @xmath148 , for all @xmath64 $ ] .",
    "see appendix  [ app_pf_thm_gc ] .    an alternative way to show the inner and outer bounds are within a constant is using the binary expansion model as an interface . under the conversion in definition  [ def_ldc ]",
    ", it turns out that the outer bounds in lemma  [ lem_ldcconverse ] and lemma  [ lem_gcconverse ] are within a constant number of bits , as well as the inner bounds in lemma  [ lem_ldcachieve ] and lemma  [ lem_gcachieve ] . then by theorem  [ thm_ldc ] , which shows that the inner and outer bounds match in the binary expansion model , it is immediate to establish the constant - gap - to - optimality result in the gaussian scenario .",
    "moreover , it justifies the usage of the binary expansion model in solving this problem , in the sense that its capacity region uniformly approximate that of the original gaussian model .",
    "costa s landmark paper @xcite demonstrates that with proper precoding , in the point - to - point awgn channel the effect of additive interference can be mitigated as if there were no interference , as long as the interference is known to the transmitter non - causally . in the multi - user scenario , however , when the interference is known partially to each node in the network , such conclusion no longer holds .",
    "moreover , in the two - user doubly - dirty mac , philosof _",
    "et al._@xcite shows that a natural extension of costa s gaussian random binning scheme performs unboundedly worse than a lattice - based strategy .    in this paper",
    ", we make a step further from @xcite .",
    "we study the @xmath0-user gaussian mac with @xmath0 independent additive gaussian interferences each of which known to exactly one transmitter non - causally , which is an extension of the two - user doubly - dirty mac . with the help of a binary expansion model of the original problem",
    ", we propose a layered modulo - lattice scheme that realizes distributed interference cancellation , and characterize the capacity region to within a constant gap , for arbitrary channel parameters .",
    "the binary expansion model uncovers the underlying layered structure of the original gaussian problem , which leads naturally to the layered architecture and the converse proof",
    ".    10    m.  h.  m. costa , `` writing on dirty paper , '' _ ieee transactions on information theory _ ,",
    "29 , pp .  439441 , may 1983 .",
    "s.  i. gelfand and m.  s. pinsker , `` coding for channel with random parameters , '' _ problems of control and information theory _ ,",
    "vol .  9 , no .  1 , pp .",
    "1931 , 1980 .",
    "s.  i. gelfand and m.  s. pinsker , `` on gaussian channels with random parameters , '' _ proceedings of ieee international symposium on information theory _ , pp .",
    "247250 , 1984 .",
    "kim , a.  sutivong , and s.  sigurjnsson , `` multiple user writing on dirty paper , '' _ proceedings of ieee international symposium on information theory _ , p.  534 , june 2004 .",
    "t.  philosof , r.  zamir , u.  erez , and a.  khisti , `` lattice strategies for the dirty multiple access channel , '' _ proceedings of ieee international symposium on information theory _ , pp .",
    "386390 , july 2007 .",
    "extended version available at http://arxiv.org/abs/0904.1892 .",
    "a.  somekh - baruch , s.  shamai , and s.  verd , `` cooperative multiple - access encoding with states available at one transmitter , '' _ ieee transactions on information theory _ ,",
    "54 , pp .  44484469 , october 2008 .",
    "s.  p. kotagiri and j.  n. laneman , `` multiaccess channels with state known to some encoders and independent messages , '' _ eurasip journal on wireless communications and networking _ , vol .  2008 , february 2008",
    ", article i d 450680 .",
    "a.  zaidi , s.  p. kotagiri , j.  n. laneman , and l.  vandendorpe , `` multiaccess channels with state known to one encoder : another case of degraded message sets , '' _ proceedings of ieee international symposium on information theory _ , pp .  23762380 , june 2009 .",
    "u.  erez , s.  shamai , and r.  zamir , `` capacity and lattice strategies for canceling known interference , '' _ ieee transactions on information theory _ , vol .",
    "51 , pp .",
    "38203833 , november 2005 .",
    "a.  zaidi , s.  p. kotagiri , j.  n. laneman , and l.  vandendorpe , `` cooperative relaying with state available noncausally at the relay , '' _ ieee transactions on information theory _ , vol .",
    "56 , pp .  22722298 , may 2010 .",
    "a.  zaidi , s.  shamai , p.  piantanida , and l.  vandendorpe , `` bounds on the capacity of the relay channel with noncausal state information at source , '' _ proceedings of ieee international symposium on information theory _ , pp .  639643 , june 2010 .",
    "b.  akhbari , m.  mirmohseni , and m.  r. aref , `` compress - and - forward strategy for the relay channel with non - causal state information , '' _ proceedings of ieee international symposium on information theory _ , pp .  11681173 , june 2009 .",
    "a.  s. avestimehr , s.  n. diggavi , and d.  n.  c. tse , `` wireless network information flow , '' _ proceedings of allerton conference on communication , control , and computing _ ,",
    "september 2007 .",
    "g.  bresler , a.  parekh , and d.  n.  c. tse , `` the approximate capacity of the many - to - one and one - to - many gaussian interference channels , '' _ submitted to ieee transactions on information theory _ ,",
    "september 2008 , http://arxiv.org/abs/0809.3554 .",
    "a.  s. avestimehr , s.  n. diggavi , and d.  n.  c. tse , `` wireless network information flow : a deterministic approach , '' _ submitted to ieee transactions on information theory _ ,",
    "http://arxiv.org/abs/0906.5394 2009 .",
    "s.  rini , d.  tuninetti , and n.  devroye , `` state of the cognitive interference channel : a new unified inner bound , and capacity to within 1.87 bits , '' _ proceedings of international zurich seminar on communications _ , 2010 , http://arxiv.org/abs/0910.3028 .",
    "i .- h . wang and d.  n.  c. tse , `` interference mitigation through limited receiver cooperation , '' _ submitted to ieee transactions on information theory _ ,",
    "november 2009 , http://arxiv.org/abs/0911.2053 .",
    "wang and d.  n.  c. tse , `` interference mitigation through limited transmitter cooperation , '' _ submitted to ieee transactions on information theory _ , april 2010 , http://arxiv.org/abs/1004.5421 .",
    "t.  philosof and r.  zamir , `` on the loss of single - letter characterization : the dirty multiple access channel , '' _ ieee transactions on information theory _ ,",
    "55 , pp .  24422454 , june 2009 .",
    "r.  zamir and m.  feder , `` on lattice quantization noise , '' _ ieee transactions on information theory _ ,",
    "42 , pp .",
    "11521159 , july 1996 .",
    "let @xmath228    if @xmath220}$ ] is achievable , for any @xmath56 $ ] by fano s inequality and data processing inequality , we have @xmath229 } ; y^n | w_{[1 : k-1]}{\\right)}\\\\ & \\overset{{\\mathrm{(a)}}}{\\le } i{\\left(}w_{[k : k ] } ; y^n | w_{[1 : k-1 ] } , s^n_{[1:k-1]}{\\right)}\\\\ & = h{\\left(}y^n | w_{[1 : k-1 ] } , s^n_{[1:k-1]}{\\right)}- h{\\left(}y^n | w_{[1 : k ] } , s^n_{[1:k-1]}{\\right)}\\\\ & = h{\\left(}y_k^n | w_{[1 : k-1 ] } , s^n_{[1:k-1]}{\\right)}- h{\\left(}y_k^n | w_{[1 : k ] } , s^n_{[1:k-1]}{\\right)}\\\\ & \\overset{{\\mathrm{(b)}}}{= } i{\\left(}w_{[k : k ] } ; y_k^n{\\right)}= i{\\left(}w_{[k : k ] } , s_{[k : k]}^n ; y_k^n{\\right)}- i{\\left(}s_{[k : k]}^n ; y_k^n| w_{[k : k]}{\\right)}\\\\ & \\overset{{\\mathrm{(c)}}}{= } h{\\left(}y_k^n{\\right)}- h{\\left(}z^n{\\right)}- \\sum_{i = k}^k h{\\left(}s_i^n{\\right)}+ h{\\left(}s_{[k : k]}^n | y_k^n , w_{[k : k]}{\\right)}\\\\ & = h{\\left(}y_k^n{\\right)}- h{\\left(}z^n{\\right)}- \\sum_{i = k}^k h{\\left(}s_i^n{\\right)}+ \\sum_{i = k}^k h{\\left(}s_i^n | y_k^n , w_{[k : k ] } , s_{[k : i-1]}^n{\\right)}\\\\ & \\overset{{\\mathrm{(d)}}}{\\le } - h{\\left(}z^n{\\right)}+ h{\\left(}y_k^n{\\right)}- h{\\left(}s_k^n{\\right)}+ h{\\left(}s_k^n|y_k^n{\\right)}- \\sum_{i = k+1}^{k } h{\\left(}s_i^n{\\right)}+ \\sum_{i = k+1}^{k } h{\\left(}s_i^n | y_i^n , w_{[i : k]}{\\right)}\\\\ & \\overset{{\\mathrm{(e)}}}{\\le } - h{\\left(}z^n{\\right)}+ h{\\left(}y_k^n| s_k^n{\\right)}- \\sum_{i = k+1}^{k } h{\\left(}s_i^n{\\right)}\\\\ & \\quad + \\sum_{i = k+1}^{k } \\min{\\left\\ { } \\newcommand{\\rbp}{\\right\\}}h{\\left(}s_i^n { \\right ) } , h{\\left(}x_i^n + \\sum_{l = i+1}^{k } { \\left(}x_l^n+s_l^n{\\right)}+ z^n { \\right)}\\rbp\\\\ & \\overset{{\\mathrm{(f)}}}{\\le } n { \\overline}{{\\mathsf}{r}}_k{\\left(}{\\mathsf{snr}}_{[k : k ] } , { \\mathsf{inr}}_{[k+1:k]};k{\\right)},\\end{aligned}\\ ] ] where @xmath112 as @xmath113 .",
    "( a ) is due to the facts that conditioning reduces entropy and that @xmath114}$ ] is independent of @xmath115}$ ] .",
    "( b ) is due to the fact that @xmath116 } , s_{[k : k]}^n , y_k^n{\\right)}$ ] and @xmath117 } , s_{[1:k-1]}^n{\\right)}$ ] are independent .",
    "( c ) is due to the fact that @xmath118},s_{[k : k]}^n \\rbp$ ] are mutually independent and @xmath230 is a function of @xmath118},s_{[k : k]}^n \\rbp$ ] .",
    "( d ) is due to conditioning reduces entropy and the fact that @xmath120 } , s_{[i : k]}^n , y_i^n{\\right)}$ ] and @xmath121 } , s_{[k : i-1]}^n{\\right)}$ ] are independent .",
    "( e ) is due to the fact that @xmath231 .",
    "finally , ( f ) is due to the fact that @xmath232 gaussian distribution maximizes the unconditional entropy , and @xmath233}\\le 2{\\mathrm{var}}{\\left[}x_i^n{\\right]}+ 2{\\mathrm{var}}{\\left[}s_i^n{\\right]}$ ] for any @xmath1 .",
    "proof complete .",
    "we shall evaluate and upper bound the gap @xmath234 } , { \\mathsf{inr}}_{[k+1:k]};k{\\right)}- { \\underline}{{\\mathsf}{r}}_k{\\left(}{\\mathsf{snr}}_{[k : k ] } , { \\mathsf{inr}}_{[k+1:k ] } ; k{\\right)}.\\end{aligned}\\ ] ]      first note that @xmath236 } , { \\mathsf{inr}}_{[k+1:k ] } ; k{\\right)}$ ] can be lower bounded by @xmath224 } , { \\mathsf{inr}}_{[k+1:k ] } ; k{\\right)}\\\\ & \\ge \\frac{1}{2}\\log{\\left(}1 + k{\\mathsf{snr}}_k + \\upsilon_{k+1 } { \\right)}- \\sum_{i = k}^k\\frac{1}{2}\\log i - \\sum_{i = k+1}^{k}\\frac{1}{2}\\log{\\left(}\\frac{1 + i{\\mathsf{snr}}_i + { \\mathsf{inr}}_i + \\upsilon_{i+1}}{1 + i{\\mathsf{snr}}_i + \\upsilon_{i+1 } } { \\right)}\\\\ & \\ge \\frac{1}{2}\\log{\\left(}1 + { \\mathsf{snr}}_k + \\upsilon_{k+1 } { \\right)}- \\sum_{i = k}^k\\frac{1}{2}\\log i - \\sum_{i = k+1}^{k}\\frac{1}{2}\\log{\\left(}\\frac{1 + i{\\mathsf{snr}}_i + { \\mathsf{inr}}_i + \\upsilon_{i+1}}{1 + i{\\mathsf{snr}}_i + \\upsilon_{i+1 } } { \\right)}.\\end{aligned}\\ ] ] also , @xmath222 } , { \\mathsf{inr}}_{[k+1:k]};k{\\right)}\\\\ & = \\frac{1}{2}\\log{\\left(}1 + 2\\upsilon_{k+1}+{\\mathsf{snr}}_k{\\right)}- \\sum_{i = k+1}^{k}\\frac{1}{2}\\log^+{\\left(}\\frac{{\\mathsf{inr}}_i}{1 + 2\\upsilon_{i+1}+{\\mathsf{snr}}_i}{\\right)}\\\\ & \\le \\frac{1}{2}\\log{\\left(}1+\\upsilon_{k+1}+{\\mathsf{snr}}_k{\\right)}- \\sum_{i = k+1}^{k}\\frac{1}{2}\\log^+{\\left(}\\frac{{\\mathsf{inr}}_i}{1+\\upsilon_{i+1}+{\\mathsf{snr}}_i}{\\right)}+\\frac{1}{2}(k - k+1).\\end{aligned}\\ ] ] hence , @xmath237 where @xmath238 and @xmath239 ."
  ],
  "abstract_text": [
    "<S> in this paper , we consider a gaussian multiple access channel with multiple independent additive white gaussian interferences . each interference is known to exactly one transmitter non - causally . </S>",
    "<S> the capacity region is characterized to within a constant gap regardless of channel parameters . </S>",
    "<S> these results are based on a layered modulo - lattice scheme which realizes distributed interference cancellation .    dirty paper coding , dirty multiple access channels , distributed interference cancellation , modulo - lattice scheme , binary expansion model . </S>"
  ]
}