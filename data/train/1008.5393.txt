{
  "article_text": [
    "we study the capacity of the continuous - time , bandlimited , additive white gaussian noise ( awgn ) channel with one - bit output quantization .",
    "our focus is on the capacity at low transmit powers , i.e. , on the capacity per unit - cost , which is defined as the slope of the capacity - vs - input - power curve at zero .",
    "we show that increasing the sampling rate reduces the loss in capacity per unit - cost caused by the quantization .",
    "the capacity of the continuous - time awgn channel without output quantization was studied by shannon @xcite .",
    "he showed that if the channel input is bandlimited to @xmath0 hz and satisfies the average - power constraint @xmath1 , and if the additive gaussian noise is of double - sided power spectral density @xmath2 , then the capacity ( in nats per second ) is given by ( see also @xcite ) @xmath3 where @xmath4 denotes the natural logarithm function .",
    "this capacity can be achieved by transmitting @xmath5 ( where @xmath6 denotes the set of real numbers ) , and by sampling the output @xmath7 at nyquist rate @xmath8 . here",
    "@xmath9 ( where @xmath10 denotes the set of integers ) is a sequence of independent and identically distributed ( iid ) gaussian random variables of zero mean and variance @xmath1 , and @xmath11 denotes the sinc - function , i.e. , @xmath12    the above ( capacity - achieving ) transmission scheme reduces the continuous - time channel to a discrete - time awgn channel with inputs @xmath9 and outputs @xmath13 . yet",
    ", it is often required that the channel inputs and outputs be not only discrete in time , but also take on a discrete value , i.e. , take value in a finite set rather than in @xmath6 .",
    "this is , for example , the case if the transmitter and receiver use digital signal processing techniques . to ensure that the channel inputs are discrete - valued",
    ", we can simply restrict ourselves to finite input alphabets .",
    "this restriction is not critical for small input powers @xmath1 .",
    "indeed , it is well - known that binary inputs achieve the capacity per unit - cost of the awgn channel @xcite . to ensure that the channel outputs are discrete - valued , we have to employ a quantizer ( analog - to - digital converter ) , which approximates the continuous - valued output by a finite number of bits .    the capacity ( in nats per channel use ) of the discrete - time awgn channel with binary symmetric output quantization  where the quantizer produces @xmath14 for a nonnegative output and @xmath15 for a negative output  is given by @xmath16 where @xmath17 denotes the variance of the additive noise , @xmath18 the binary entropy function , and @xmath19 the @xmath20-function ; see ( * ? ? ?",
    "* ( 3.4.18 ) ) , @xcite , ( * ? ? ?",
    "* thm .  2 ) .",
    "to the best of our knowledge , there exists no closed - form expression for the capacity of the discrete - time awgn channel with nonbinary output quantization . however , numerical results are , for example , given in @xcite .",
    "furthermore , there exist analytical results concerning the capacity per - unit cost .",
    "for example , it was demonstrated that if a binary symmetric quantizer is employed , then the capacity per unit - cost equals @xmath21 ( * ? ? ? * ( 3.4.20 ) ) .",
    "it was further demonstrated that for an octal quantizer with uniform quantization the capacity per unit - cost is not less than @xmath22 ( * ? ? ? * ( 3.4.21 ) ) .",
    "thus , at low transmit power , employing a binary quantizer causes a loss of a factor of @xmath23 relative to the capacity per unit - cost @xmath24 for unquantized decoding @xcite .",
    "in contrast , by quantizing the output with 3 bits , a capacity per unit - cost can be achieved that is close to the capacity per unit - cost for unquantized decoding .",
    "( note that the capacity of discrete - time channels is measured in nats per channel use , whereas the capacity of continuous - time channels is measured in nats per second . since with a continuous - time signal of bandwidth @xmath0 hz we can approximately transmit @xmath8 samples per second",
    ", we have that one nat per channel use corresponds to @xmath8 nats per second . by further noting that lowpass filtering and sampling gaussian noise of double - sided power spectral density @xmath2 yields gaussian noise - samples of variance @xmath25",
    ", it follows that the capacity per unit - cost of the continuous - time channel corresponds to @xmath8 times the capacity per unit - cost of the discrete - time channel with @xmath17 replaced by @xmath25 . )",
    "the above results suggest that , in order to reduce the loss in capacity per unit - cost caused by the quantization , one needs to increase the quantizer s resolution .",
    "however , while this clearly holds for the discrete - time channel , this does not necessarily hold for the underlying continuous - time channel . indeed , in contrast to the unquantized channel output , the quantized output is not bandlimited , and it is therefore _ prima facie _ not clear , whether sampling the quantized output at nyquist rate is optimal .",
    "one might thus increase the capacity of the continuous - time channel by oversampling the quantized output , i.e. , by sampling the quantized output at rates higher than the nyquist rate .",
    "when there is no additive noise , it was shown by gilbert @xcite and by shamai @xcite that oversampling indeed increases the capacity . in this paper , we demonstrate that oversampling also increases the capacity when the noise power is large relative to the transmit power . in particular ,",
    "we show that , for binary symmetric output quantization , sampling the quantized output at twice the nyquist rate yields a capacity per unit - cost that is not less than @xmath26 , which is strictly larger than the capacity per unit - cost @xmath27 that can be achieved by sampling the quantized output at nyquist rate .",
    "the rest of this paper is organized as follows .",
    "section  [ sec : channel ] describes the channel model .",
    "section  [ sec : capacity ] defines channel capacity and capacity per unit - cost and presents the main result .",
    "section  [ sec : proof ] provides the proofs of the main result .",
    "section  [ sec : summary ] concludes the paper with a discussion of our results .",
    "[ r][r]@xmath28 [ cc][cc]@xmath29 [ cc][cc]@xmath30 [ tc][tc]@xmath31 [ cc][cc]lowpass filter [ cc][cc]hard - limiter [ l][l]@xmath32    we consider the communication channel depicted in figure  [ fig1 ] whose input @xmath33 is bandlimited to @xmath0 hz and satisfies the average - power constraint @xmath1 . the channel output @xmath32 at integer multiples of the sampling interval @xmath34 is @xmath35 where @xmath36 denotes the sign function ; @xmath37 the convolution between @xmath38 and @xmath39 at time @xmath40 ; and @xmath41 is the impulse response of the ideal unit - gain lowpass filter of cutoff frequency @xmath0 . the hard - limiter is a binary symmetric quantizer that produces @xmath14 for a nonnegative input and @xmath15 for a negative input .",
    "we assume that @xmath42 is white gaussian noise of double - sided power spectral density @xmath2 .    without loss of optimality ,",
    "we restrict ourselves to signals @xmath33 of the form @xmath43 where @xmath44 is some unit - energy waveform that is bandlimited to @xmath0 hz . indeed , by the sampling theorem ( * ? ? ?",
    "8.4.5 ) , any signal @xmath33 that is bandlimited to @xmath0 hz can be written as with @xmath45",
    "we define the capacity ( in nats per second ) as @xmath46 where the supremum is over all unit - energy waveforms @xmath44 that are bandlimited to @xmath0 hz and over all joint distributions on @xmath47 satisfying @xmath48 . here",
    "@xmath49 denotes the _ limit inferior _ ; @xmath50 is used to denote the sequence @xmath51 ; and @xmath52 ( with @xmath53 and @xmath54 denoting the ceiling and the floor function ) .",
    "a more general definition of channel capacity for continuous - time channels can be found in ( * ? ? ?",
    "8.1 ) . for the above channel",
    ", the capacity @xmath55 defined by is a lower bound on the capacity defined in ( * ? ? ?",
    "the two capacities coincide , for example , for the continuous - time awgn channel ( without output quantization ) .",
    "that oversampling can increase the capacity of the above channel has been demonstrated in the noiseless case , i.e. , when @xmath56 . in particular , gilbert @xcite showed that , for a gaussian input @xmath57 , sampling the output at twice the nyquist rate yields an information rate of @xmath58 bits per second , which is strictly larger than the @xmath8 bits per second that can be achieved by sampling the output at nyquist rate .",
    "shamai @xcite further showed , _",
    "inter alia _ , that by sampling the output at @xmath59-times the nyquist rate , rates of @xmath60 nats per second are achievable by transmitting a bandlimited process that possesses a single real zero within each nyquist interval .",
    "in the absence of noise it is thus possible to trade amplitude resolution versus time resolution .    in this paper , we focus on the case where the variance of the additive noise is large relative to the transmit power . in particular",
    ", we study the capacity per unit - cost , defined as @xmath61 ( where @xmath62 denotes the _ limit superior _ ) . by the data processing inequality (",
    "2.8.1 ) it follows that quantizing the output does not increase the capacity .",
    "this implies that the capacity per unit - cost is upper bounded by the capacity per unit cost of the continuous - time awgn channel ( without output quantization ) @xmath63 for the case where the output is sampled at nyquist rate @xmath64 , it was shown that the capacity per unit - cost is given by ( * ? ? ?",
    "* ( 3.4.20 ) ) @xmath65 thus , when we sample the output at nyquist rate , hard - limiting causes a loss of a factor of @xmath23 .",
    "this loss can be reduced by sampling the output at twice the nyquist rate :    [ thm : main ] sampling the output at rate @xmath66 yields    lcl _ ( 0 ) & & + & & 0.747    where @xmath67    see section  [ sub : mainproof ] .",
    "the main ingredients in the proof of theorem  [ thm : main ] are expansions of the complementary cumulative distribution function ( ccdf ) of bivariate and trivariate gaussian vectors around the orthant probability .",
    "we present these expansions in the following two propositions .",
    "[ prop : binary ] let @xmath68 denote the probability density function ( pdf ) of the bivariate , zero - mean , gaussian vector of covariance matrix @xmath69 for @xmath70 . then , for every @xmath71 , @xmath72 and @xmath73 , @xmath74 where @xmath75 and where @xmath76 is monotonically increasing in @xmath77 and is bounded for every finite @xmath78 , @xmath79 , and @xmath80 .",
    "see section  [ subsub : binary ] .",
    "[ prop : ternary ] let @xmath81 denote the pdf of the trivariate , zero - mean , gaussian vector of covariance matrix @xmath82 for @xmath83 , @xmath84 , @xmath85 satisfying @xmath86 ( where @xmath87 denotes the determinant of the matrix @xmath88 ) .",
    "then , for every @xmath71 , @xmath72 , @xmath73 , and @xmath89 ,    lcl + & = & + ( ( _ 12)+(_13)+(_23 ) ) + & & + [ + ( ) + & & + ( ) + ( ) ] + & & + ( , , , )    where @xmath90 and where @xmath91 is monotonically increasing in @xmath92 and is bounded for every finite @xmath78 , @xmath79 , @xmath80 , and @xmath93 .",
    "see section  [ subsub : ternary ] .",
    "the proof of theorem  [ thm : main ] is based on the expansions of the ccdf that were presented in propositions  [ prop : binary ] and [ prop : ternary ] .",
    "we derive these expansions in section  [ sub : compl ] .",
    "the proof of theorem  [ thm : main ] is given in section  [ sub : mainproof ] .",
    "we shall first evaluate the ccdf for the bivariate case .",
    "the result will then be used to solve the trivariate case .      in order to prove proposition  [ prop : binary ] , we express the ccdf as    lcl + & = & _ 0^_0^ _ , ( x , y)yx + _ -^0_-^ _ , ( x , y)yx + _ 0^_-^0 _ , ( x , y)yx + & = & + ( ) + _ -^0_-^ _ , ( x , y)yx + _ 0^_-^0 _ , ( x , y)yx[eq : binary_1 ]    where the last step follows from the expression for the orthant probability of a bivariate , zero - mean gaussian vector with correlation coefficient @xmath94 @xcite , see also @xcite .",
    "we proceed by evaluating the integrals on the right - hand side ( rhs ) of .",
    "to evaluate the first integral , we express the joint pdf @xmath68 as the product of a marginal pdf @xmath95 and a conditional pdf @xmath96 , i.e. , @xmath97 where @xmath98 denotes the pdf of a gaussian random variable of mean @xmath99 and variance @xmath17 .",
    "we thus obtain for the first integral on the rhs of    lcl _ -^0_-^ _ , ( x , y)yx & = & _ -^0 _ 0,1(x ) _ -^ _ x , 1-^2(y ) y x + & = & _ -^0 _ 0,1(x)x    where @xmath19 denotes the @xmath20-function @xmath100 expressing @xmath101 as a taylor series around zero yields ( * ? ? ?",
    "* ( 3.54 ) )    lcl _ -^0_-^ _ , ( x , y)yx & = & _ -^0 _ 0,1(x ) x + & = & _ -^0 _ 0,1(x )",
    "x + ( ) + _ 1(,,)[eq : binary_2 ]    where    lcl _ 1 ( , , ) & & _ -^0 _ 0,1(x)x + _ -^0 _ 0,1(x)xx + & & - _ -^0 _ 0,1(x)()x - ( ) [ eq : binary_delta1 ]    and where @xmath102 denotes the remainder term of the taylor series expansion of @xmath19 , which satisfies ( * ? ? ?",
    "0.317 ) latexmath:[\\[\\label{eq : delta_binary }    expressing again @xmath101 as a taylor series around zero , the first two terms on the rhs of are evaluated as    lcl _ -^0 _ 0,1(x ) x + ( ) & = & ( -q())+ + & = & .",
    "[ eq : binary_q ]    it is shown in appendix  [ app : bivariate ] that @xmath104 satisfies @xmath105 where @xmath106 is monotonically increasing in @xmath107 and is bounded for every finite @xmath78 , @xmath79 , and @xmath80 .",
    "along the same lines , we evaluate the second integral on the rhs of as    lcl _ 0^_-^0 _ , ( x , y)yx & = & _ -^0 _ 0,1(y ) _ 0^ _ y , 1-^2(x)x y + & = & _ -^0 _ 0,1(y ) y + & = & _ -^0 _ 0,1(y)y + & = & _ -^0 _ 0,1(y ) y + ( ) + _ 2 ( , , ) + & = & + _ 2 ( , , ) [ eq : binary_3 ]    where    lcl _ 2 ( , , ) _ -^0 _ 0,1(y ) y y - _ -^0 _ 0,1(y ) ( ) y - ( ) . [ eq : binary_delta2 ]    it is shown in appendix  [ app : bivariate ] that @xmath108 satisfies @xmath109 where @xmath110 is monotonically increasing in @xmath107 and is bounded for every finite @xmath78 , @xmath79 , and @xmath80 .    combining , , , and yields @xmath111 where @xmath112 by the triangle inequality ( * ? ? ?",
    "2.4 ) , we have    lcl |(,,)| & & |_1(,,)| + |_2(,,)| + & & ^2(_1(,,)+_2 ( , , ) ) .",
    "[ eq : binary_5 ]    proposition  [ prop : binary ] follows now from and by noting that if @xmath113 and @xmath114 are both monotonically increasing in @xmath107 , then so is @xmath115 and if @xmath113 and @xmath114 are bounded , then so is @xmath116 .      in order to prove proposition  [ prop : ternary ] , we express the ccdf as    lcl + & = & _ 0^ _ 0^ _ 0^ _ , ( x , y , z)zy x + _ -^0_-^_-^ _ , ( x , y , z)zyx + & & + _ 0^_-^0_-^ _ , ( x , y , z)zyx + _ 0^_0^_-^0 _ , ( x , y , z)zyx + & = & + ( ( _ 12)+(_13)+(_23 ) ) + _ -^0_-^_-^ _ , ( x , y , z)zyx + & & + _ 0^_-^0_-^ _ , ( x , y , z)zyx + _ 0^_0^_-^0 _ , ( x , y , z)zyx[eq : ternary_1 ]    where the last step follows from the expression for the orthant probability of a trivariate , zero - mean gaussian vector of covariance matrix @xcite ( see also @xcite ) @xmath117 if @xmath118 , then the integrals on the rhs of are zero and proposition  [ prop : ternary ] follows directly from .",
    "to prove proposition  [ prop : ternary ] for @xmath119 , we continue by evaluating the integrals on the rhs of separately .",
    "to evaluate the first integral , we express the joint pdf @xmath120 as the product of a marginal pdf @xmath95 and a conditional pdf @xmath121 @xmath122 where @xmath123 denotes the pdf of a bivariate gaussian vector of mean @xmath124 and covariance matrix @xmath88 , and where @xmath125 we thus have    lcl + & = & _ -^0_0,1(x)_-^_-^ _ ( x),(x)(y , z)zyx + & = & _ -^0_0,1(x)_-^_-^ _ , (x)(y,z)zyx + & = & _ -^0_0,1(x)x + & & + _ -^0_0,1(x ) ( + ) x + & & + _ -^0_0,1(x ) ( , , ) x + & = & ( _ -^0_0,1(x)x+())+ _ 1(,,,)[eq : ternary_2 ]    where @xmath126 and @xmath102 are as in the previous section , and where @xmath127 and    lcl _ 1 ( , , , ) & & - ( ) + & & + _ -^0_0,1(x ) ( + ) x + & & + _ -^0_0,1(x ) ( , , ) x.[eq : ternary_delta1 ]    here the second step follows by substituting @xmath128 and the third step follows from proposition  [ prop : binary ] .    by applying ,",
    "we obtain for the first term on the rhs of    lcl + & = & .",
    "[ eq : ternary_3 ]    it is shown in appendix  [ app : trivariate ] that @xmath129 satisfies @xmath130 where @xmath131 is monotonically increasing in @xmath92 and is bounded for every finite @xmath78 , @xmath79 , @xmath80 , and @xmath93 .    to evaluate the second integral on the rhs of",
    ", we express the joint pdf @xmath132 as @xmath133 where @xmath134 we thus have    lcl + & = & _ -^0_0,1(y ) _ 0^_-^ _ ( y),(y)(x , z)zx y + & = & _ -^0_0,1(y ) _ -^_-^ _ , (y)(x,z)zx y + & = & _ -^0_0,1(y ) y + & & + _ -^0_0,1(y ) ( + ) y + & & + _ -^0_0,1(y ) ( , , ) y + & = & ( _ -^0_0,1(y)y + ( ) ) + _ 2 ( , , , ) + & = & + _ 2 ( , , , ) [ eq : ternary_4 ]    where @xmath135 and    lcl _ 2 ( , , , ) & & - ( ) + & & + _ -^0_0,1(y ) ( + ) y + & & + _ -^0_0,1(y ) ( , , ) y.[eq : ternary_delta2 ]    here the second step follows by substituting @xmath136 the third step follows from proposition  [ prop : binary ] ; and the last step follows from . it is shown in appendix  [ app : trivariate ] that @xmath137 satisfies @xmath138 where @xmath139 is monotonically increasing in @xmath92 and is bounded for every finite @xmath78 , @xmath79 , @xmath80 , and @xmath93 .",
    "to evaluate the third integral on the rhs of , we express the joint pdf @xmath132 as @xmath140 where @xmath141 we have    lcl + & = & _ -^0 _ 0,1(z ) _ 0^ _ 0^ _ ( z),(z)(x , y ) yx z + & = & _ -^0 _ 0,1(z ) _ -^ _ -^ _ , (z)(x,y ) yxz + & = & _ -^0 _ 0,1(z)z + & & + _ -^0 _ 0,1(z ) ( + ) z + & & + _ -^0 _ 0,1(z)(,,)z + & = & ( _ -^0 _ 0,1(z)z + ( ) ) + _ 3 ( , , , ) + & = & + _ 3 ( , , , ) [ eq : ternary_5 ]    where @xmath142 and    lcl _ 3 ( , , , ) & & - ( ) + & & + _ -^0 _ 0,1(z ) ( + ) z + & & + _ -^0 _ 0,1(z)(,,)z.[eq : ternary_delta3 ]    here the second step follows by substituting @xmath143 the third step follows from proposition  [ prop : binary ] ; and the last step follows from .",
    "it is shown in appendix  [ app : trivariate ] that @xmath144 satisfies @xmath145 where @xmath146 is monotonically increasing in @xmath92 and is bounded for every finite @xmath78 , @xmath79 , @xmath80 , and @xmath93 .    combining ",
    "yields    lcl + & = & + ( ( _ 12)+(_13)+(_23 ) ) + & & + + & & + ( , , , ) [ eq : ternary_6 ]    where @xmath147 by the triangle inequality , we have    lcl |(,,,)| & & |_1(,,,)| + |_2(,,,)| + |_3(,,,)| + & & ^2 ( _ 1 ( , , , ) + _ 2 ( , , , ) + _ 3 ( , , , ) ) .",
    "[ eq : ternary_7 ]    proposition  [ prop : ternary ] follows now from and by noting that if @xmath148 , @xmath149 , and @xmath150 are monotonically increasing in @xmath92 , then so is @xmath151 and if @xmath148 , @xmath149 , and @xmath150 are bounded , then so is @xmath152 .      to prove theorem  [ thm : main ] , we derive a lower bound on @xmath153 and",
    "compute its ratio to @xmath1 in the limit as @xmath1 tends to zero . to this end",
    ", we evaluate @xmath154 for @xmath155 being a sequence of iid , binary random variables with @xmath156 -\\sqrt{p } , \\qquad & \\textnormal{with probability $ \\frac{1}{2}$. } \\end{array}\\right.\\ ] ] we shall restrict ourselves to waveforms @xmath44 that satisfy    rcl _ 0 |g()| & < & [ eq : g1 ] + _ 0 |g()| & < & [ eq : g2 ] + _ 0 |g()| & < & .",
    "[ eq : g3 ]    by the chain rule for mutual information ( * ? ? ?",
    "2.5.2 )    lcl i(x_1^n;_1^n ) & = & _",
    "k=1^n i(x_k;_1^n| x_1^k-1 ) + & & i(x_k;_k ) + & = & _ k=1^n i(x_k;y_k-,y_k , y_k+ ) + & = & 2 i(x_1;y_,y_1,y _ ) [ eq : main_firststep ]    where we define @xmath157 here the second step follows because reducing observations can not increase mutual information and because @xmath155 is iid ; the third step follows from the definition of @xmath158 ; and the last step follows because the joint law of @xmath159 does not depend on @xmath160 .      in order to evaluate @xmath162",
    ", we shall compute the conditional probability of @xmath163 , conditioned on @xmath164 . to this end",
    ", we first compute the conditional probability of @xmath163 , conditioned on @xmath165 , and then average over @xmath166 .    to compute @xmath167",
    ", we first note that by @xmath168 where we define @xmath169 let    lcl ( x_-^ ) & & _",
    "= -^ x _ g ( ) + ( x_-^ ) & & _ = -^ x _ g ( )    and    lcl ( x_-^ ) & & _",
    "= -^ x _ g ( ) .",
    "it follows from that    lcl + & = & ( z_-(x_-^ ) , z_1-(x_-^ ) , z _",
    "-(x_-^ ) ) + & = & ( z _ -(x_-^ ) , z_1-(x_-^ ) , z _",
    "-(x_-^ ) ) + & = & _ -(x_-^)^ _ -(x_-^)^ _ -(x_-^)^ _ , ( x , y , z ) zyx + & = & + ( ) + + & & + ( , ( x_-^),(x_-^),(x_-^ ) ) [ eq : main_2 ]    where @xmath170 here the third step follows by noting that @xmath171 is a zero - mean gaussian process of autocovariance function @xmath172 ; and the last step follows from proposition  [ prop : ternary ] .",
    "since @xmath155 is iid and of zero mean , we have    lcl _ 0 & & + & = & g(-)+_1 g ( ) + & = & g(- ) [ eq : main_alpha0 ]    and    lclcl _ 0 & & & = & g(0)[eq : main_beta0 ] + _ 0 & & & = & g().[eq : main_gamma0 ]    by setting @xmath173 and averaging over @xmath174 , we thus obtain    lcl + & = & + ( ) + + & & + + & = & + ( ) + + & & + .[eq : main_3 ]    we next show that @xmath175 where @xmath176 satisfies @xmath177 . to this end",
    ", we use the triangle inequality to upper bound    lcl |(x_-^)| & & _",
    "= -^ |x_| |g()| + & = & _ = -^ |g()| + & & _ max    which , by , is finite . here",
    "the second step follows because , for our choice of @xmath178 , we have with probability one @xmath179 .",
    "similarly , we have    lcl |(x_-^)| & & _ = -^ |g()| + & & _ max + & < &    and    lcl |(x_-^)| & & _ = -^ |g()| + & & _ max + & < & .",
    "we thus obtain    lcl + & & + & & + & & ( , _ max,_max,_max ) + & = & o ( ) [ eq : main_step2delta ]    where the first step follows from the triangle inequality ; the second step follows because @xmath180 ; the third step follows because @xmath91 is monotonically increasing in @xmath92 ; and the last step follows because @xmath152 is bounded for finite @xmath78 , @xmath79 , @xmath80 , and @xmath93 .",
    "this proves .    combining and yields    lcl + & = & + ( ) + & & + + o().[eq : main_111|a ]    by averaging over @xmath165 , and by noting that @xmath181 and @xmath182 we obtain for the unconditional probability    lcl ( y_=1,y_1=1,y_=1 ) & = & + ( ) + o ( ) .",
    "[ eq : main_111 ]    it thus follows from bayes law that    lcl + & = & + + & = & + + o()[eq : main_a|111 ]    where the last step follows because @xmath183 for any @xmath184 and @xmath185 .",
    "note that the first two terms on the rhs of depend on @xmath186 only via their means .",
    "thus , if @xmath155 is of zero mean , then intersymbol interference affects only the @xmath187-term , which does not influence our lower bound on the capacity per unit - cost .    the probability @xmath188 can be computed in a similar way .",
    "we have    lcl + & = & _ -(x_-^)^ _ -(x_-^)^ _ -^-(x_-^ ) _ , ( x , y , z ) zyx + & = & _ -(x_-^)^ _ -(x_-^)^ _ , ( x , y ) yx + & & - _ -(x_-^)^ _ -(x_-^)^ _ -(x_-^)^ _ , ( x , y , z ) zyx + & = & + ( ) + + ( , ( x_-^),(x_-^ ) ) + & & - - ( ) - + & & - ( , ( x_-^),(x_-^),(x_-^ ) ) + & = & + + & & + ( , ( x_-^),(x_-^ ) ) - ( , ( x_-^),(x_-^),(x_-^ ) )    where @xmath88 is the same as in , and where @xmath189 here the second step follows because @xmath190 and the third step follows from propositions  [ prop : binary ] and [ prop : ternary ] . by setting @xmath173 and averaging over @xmath191",
    ", we obtain    lcl + & = & + + & & + + & & - [ eq : main_4 ]    where @xmath192 , @xmath193 , and @xmath194 are defined in .",
    "it was shown above that the last term on the rhs of decays faster than @xmath195 . repeating the steps in",
    ", it can also be shown that @xmath196 by noting that @xmath197 , we thus obtain    lcl ( y_=1,y_1=1,y_=-1| x_1= ) & = & +    it follows from that the unconditional probability is given by    lcl ( y_=1,y_1=1,y_=-1 ) & = & + o()[eq : main_11 - 1 ] .    by bayes law , we thus have    lcl ( x_1= | y_=1,y_1=1,y_=-1 ) & = & + [ eq : main_a|11 - 1 ] .",
    "the other conditional probabilities can be computed along the same lines .",
    "the probabilities corresponding to @xmath198 and @xmath199 are given by    lcl + & = & + + o()[eq : main_a|1 - 11 ]    and    lcl ( x_1= | y_=-1,y_1=1,y_=1 ) & = & + [ eq : main_a|-111 ]    the remaining probabilities can be computed from , , , and by noting that , due to the symmetry of @xmath200 , @xmath201      let @xmath202 we express the mutual information @xmath162 as    lcl i(x_1;y_,y_1,y _ ) & = & h(x_1 ) - h(x_1| y_,y_1,y _ ) + & = & 2 -    where @xmath203 , @xmath204 ( with @xmath205 ) denotes the binary entropy function .",
    "to evaluate the binary entropy function , we express @xmath18 as a taylor series expansion around @xmath206 , i.e. , @xmath207 substituting @xmath208 and averaging over @xmath163 yields thus    lcl i(x_1;y_,y_1,y _ ) & = & 2 - + & = & 2 + + & = & 2 + o()[eq : main_beforeavg ]    where the last step follows because , by , , , and , we have for every @xmath209 @xmath210 where @xmath211 satisfies @xmath212 , so @xmath213 which implies that @xmath214 since the expectation is given by the sum of eight terms that all decay faster than @xmath1 .    by applying , , , and to , we obtain    lcl + & = & + o()[eq : main_lbmi ]    where @xmath192 , @xmath193 , and @xmath194 are defined in .    combining with and , and computing the ratio to @xmath1 in the limit as @xmath1 tends to zero , yields the lower bound on the capacity per unit - cost    lcl _",
    "( 0 ) & & + & & ( 0).[eq : main_lbgeneral ]    note that this lower bound holds for all unit - energy waveforms @xmath44 that are bandlimited to @xmath0 hz and that satisfy . in the following section we evaluate the rhs of for a specific choice of @xmath44 .",
    "any choice of @xmath44 satisfying the above conditions yields a lower bound on @xmath215 .",
    "here we shall find the waveform that gives rise to the largest lower bound .",
    "thus , we wish to maximize the rhs of over all unit - energy waveforms @xmath44 that are bandlimited to @xmath0 hz and that satisfy  , namely ,    lcl _ 0 |g()| & < & + _ 0 |g()| & < & + _ 0 |g()| & < & .    to further facilitate the optimization problem , we choose @xmath44 to be a symmetric function , which implies that @xmath216 .",
    "( numerical computation suggests that this choice is indeed optimal . ) in this case , the rate per unit - cost @xmath217 is of the form @xmath218 ( where @xmath219 , @xmath220 and @xmath221 ) , so @xmath217 is a convex function of @xmath222 , and all pairs @xmath222 that give rise to the same rate per unit - cost lie on an ellipse .",
    "let @xmath223 denote the set of all waveforms satisfying the above conditions , and let @xmath224 denote the set of all pairs @xmath222 that arise from these waveforms .",
    "since @xmath217 is convex in @xmath222 , it follows that the supremum of @xmath217 over @xmath224 lies on the boundary of @xmath224 , which we shall determine next .    while the set of all bandlimited functions that satisfy  is convex , the set of all unit - energy functions is not ( see ( * ? ? ?",
    "2 ) for a definition of a convex set ) . indeed ,",
    "if for example the functions @xmath225 and @xmath226 are of unit energy and satisfy @xmath227 , @xmath228 , then @xmath229\\ ] ] is of energy @xmath230 , which is not equal to @xmath14 unless @xmath231 or @xmath232 .",
    "nevertheless , the set of all functions whose energy is less than or equal to @xmath14 is convex , since @xmath233\\bigr)\\ ] ] where @xmath234 , and where the inequality follows from the triangle inequality .",
    "let @xmath235 denote the set of all waveforms that are bandlimited to @xmath0 hz , that satisfy  , and whose energy is less than or equal to @xmath14 .",
    "furthermore , let @xmath236 denote the set of all pairs @xmath222 that arise from these waveforms . since convexity is preserved under intersection ( * ? ? ?",
    "2.1 ) , it follows that the set @xmath237 ( and hence also @xmath238 ) is convex .",
    "we further have that @xmath239 where the first step follows because every rate per unit - cost @xmath217 that corresponds to a waveform satisfying @xmath240 can be increased by normalizing the waveform ; and where the second step follows because @xmath217 depends on @xmath44 only via @xmath222 and because @xmath237 determines @xmath238 .",
    "the above optimization problem can thus be expressed as the maximization of a convex function over a convex set .",
    "let @xmath241 denote the closure of @xmath238 ( i.e. , let @xmath241 be the smallest closed set containing @xmath238 ) and let @xmath242 be defined as @xmath243 since @xmath241 is a closed convex set , it follows that the boundary of @xmath238 is given by the points @xmath244 that achieve the supremum in ( * ? ? ?",
    "note that the boundary of @xmath238 is symmetric with respect to the origin , since @xmath222 and @xmath245 yield the same value for @xmath246 , @xmath247 .    for every @xmath247",
    ", the supremum in is achieved by the pair @xmath222 that corresponds to @xmath44 being of fourier transform @xmath248 where @xmath249 denotes the indicator function , i.e. , @xmath250 is @xmath14 if the statement is true and @xmath251 otherwise .",
    "this yields @xmath252 and @xmath253 note that the waveform given by is of unit energy and is bandlimited to @xmath0 hz , but it does not satisfy . nevertheless , it is shown in appendix  [ app : mainproof ] that there exist pairs @xmath254 that are arbitrarily close to and .",
    "the pairs @xmath222 given by and are thus in the closure of @xmath238 and the boundary of @xmath238 is hence parameterized by and .",
    "( notice that and describe only one half of the boundary of @xmath238 .",
    "the other half is given by @xmath245 . )",
    "[ lt][lt]boundary of @xmath238 [ cb][cb]@xmath255 [ cb][cb]@xmath256 [ cc][cc]@xmath192 [ cc][cc]@xmath193    the above problem is illustrated in figure  [ fig2 ] for @xmath257 .",
    "the outer curve ( solid line ) is the contour line corresponding to @xmath255 .",
    "the inner curve ( dot - dashed line ) depicts the boundary of @xmath238 as parameterized by and .",
    "the two curves touch at two points : one corresponds to @xmath256 and the other is the same point reflected through the origin . since @xmath217 is convex in @xmath222 , it follows that any point that lies inside the depicted contour line ( solid line ) yields a rate per unit - cost that is smaller than @xmath258 .",
    "thus , the two points on the boundary of @xmath238 that touch the contour line yield @xmath259 , whereas the other points @xmath254 yield a rate per unit - cost that is smaller .",
    "therefore , we conclude that choosing @xmath222 according to and with @xmath256 maximizes @xmath217 .    in the following , we summarize the above arguments to compute the supremum of @xmath217 over the set @xmath238 for general @xmath0 and @xmath260 . to this end , we first recall that @xmath217 is convex in @xmath222 and it therefore suffices to maximize @xmath217 over all boundary points of @xmath238 .",
    "we next use that every boundary point of @xmath238 is given by the parametric equations and .",
    "therefore , by applying and to , the maximization of @xmath217 over the set @xmath238 can be expressed as the maximization over the real scalar @xmath261    lcl _ ( 0 ) & & _ [ eq : main_beforeend ]    where @xmath262 and @xmath263 numerical computation shows that the supremum on the rhs of is achieved for @xmath256 , which is consistent with our interpretation of figure  [ fig2 ] .",
    "the capacity per unit - cost @xmath215 is thus lower bounded    lcl ( 0 ) & & + & & 0.747    where @xmath264",
    "this proves theorem  [ thm : main ] .",
    "we demonstrated that doubling the sampling rate recovers some of the loss in capacity per unit - cost incurred on the bandlimited gaussian channel with a one - bit output quantizer .",
    "indeed , when the channel output is sampled at nyquist rate @xmath8 , it is well - known that the capacity per unit - cost is given by @xmath265 @xcite , which is a factor of @xmath266 smaller than the capacity per unit - cost of the same channel but without output quantizer .",
    "we showed that , by sampling the output at twice the nyquist rate , a capacity per unit - cost not less than @xmath26 can be achieved .",
    "this can be viewed as a very - noisy counterpart of the work by gilbert @xcite and by shamai @xcite , which demonstrated that oversampling increases the capacity of the above channel when there is no additive noise .",
    "the conclusions that can be drawn from this result are twofold .",
    "firstly , we demonstrated that in order to reduce the loss in capacity per unit - cost caused by the quantization , one can either increase the quantization resolution or the sampling rate .",
    "thus , it is possible to trade amplitude resolution ( quantization ) versus time resolution ( sampling rate ) .",
    "secondly , we observe that while sampling the output at nyquist rate is optimal for the awgn channel ( without output quantization ) , this does not hold when the output is quantized .",
    "thus , a communication scheme that is optimal in the sense that it achieves the capacity need not be optimal anymore if the channel output is processed by a noninvertible operation ( such as quantization ) .",
    "fruitful discussions with michle wigger are gratefully acknowledged .",
    "we show that , for @xmath71 , @xmath72 , and @xmath73 , we have latexmath:[\\[|\\delta_1(\\const{a},\\alpha,\\beta)| \\leq \\const{a}^2\\eta_1(\\const{a},\\alpha,\\beta ) \\qquad \\textnormal{and } \\qquad    where @xmath104 and @xmath108 are defined in and , and where @xmath106 and @xmath110 are monotonically increasing in @xmath107 and are bounded for every finite @xmath78 , @xmath79 , and @xmath80 .",
    "we have    lcl + & & |_-^0 _ 0,1(x)x| + |_-^0 _ 0,1(x)|x|x| + & & + |_-^0 _ 0,1(x)|()|x| + |()| + & & ^2+^||_0 xx + |^-_0 x| + + & & ^2+^2 + ^4 + ^3 + & = & ^2 _ 1 ( , , )    where @xmath268 here the first step follows from the triangle inequality ; the second step follows by upper bounding @xmath269 , @xmath270 and from ; and the third step follows because , over the range of integration , @xmath271 and @xmath272 .    along the same lines , we obtain",
    "lcl + & & |_-^0 _ 0,1(y ) |y| y| + |_-^0 _ 0,1(y ) |()|y| + |()| + & & ^||_0 y y + ^||_0 y + ^3 + & = & ^2 _ 2 ( , , )    where @xmath273",
    "this proves the claim .",
    "we show that , for @xmath119 , @xmath72 , @xmath73 , and @xmath89 , we have    lcl |_1(,,,)| & & ^2_1 ( , , , ) +     and    lcl |_3(,,,)| ^2_3 ( , , , )    where @xmath129 , @xmath137 , and @xmath144 are defined in , , and , and where @xmath131 , @xmath139 , and @xmath146 are monotonically increasing in @xmath92 and are bounded for every finite @xmath78 , @xmath79 , @xmath80 , and @xmath93 .",
    "we have    lcl |_1(,,,)| & & |()||+()| + & & + |_-^0_0,1(x ) |+|x| + & & + |_-^0_0,1(x ) |(,,)|x| + & & |()| + |_-^0 |+|x| + & & + |_-^0 |(,,)|x| + & & ^3 + _ 0^|| ( + ) x + & & + ^2 _ 0^|| ( , , ) x + & & ^3 + ( + ) ^2 + & & + || ( , , ) ^3 + & = & ^2 _ 1 ( , , , )    where @xmath116 is as in proposition  [ prop : binary ] , and where    lcl _ 1 ( , , , ) & & + ( + ) + & & + || ( , , ) .    here",
    "the first step follows from the triangle inequality ; the second step follows by upper bounding @xmath274 , @xmath270 and @xmath275 , @xmath276 ; the third step follows again from the triangle inequality , from the upper bound @xmath75 and from the monotonicity of @xmath116 in @xmath107 ; and the fourth step follows because , over the range of integration , @xmath271 .",
    "along the same lines , we obtain for @xmath137    lcl |_2(,,,)| & & |()|| + ( ) | + & & + |_-^0_0,1(y ) |+|y| + & & + |_-^0_0,1(y ) |(,,)|y| + & & ^3 + ( + ) ^2 + & & + || ( , , ) ^3 + & = & ^2 _ 2 ( , , , )    where    lcl _ 2 ( , , , ) & & + ( + ) + & & + || ( , , ) .    finally , we obtain for @xmath144    lcl |_3(,,,)| & & |()||+()| + & & + |_-^0 _ 0,1(z ) |+| z| + & & + |_-^0 _ 0,1(z)|(,,)|z| + & & ^3 + ( + ) ^2 + & & + || ( , , ) ^3 + & = & ^2 _ 3 ( , , , )    where    lcl _ 3 ( , , , ) & & + ( + ) + & & + || ( , , ) .",
    "this proves the claim .",
    "we show that there exist bandlimited , unit - energy waveforms @xmath44 that satisfy  and that give rise to pairs @xmath222 that are arbitrarily close to @xmath277 and @xmath278 to this end , we first note that a sufficient condition for the waveform @xmath44 to satisfy ",
    "is @xmath279 for some nonnegative @xmath280 , @xmath281 , and some positive @xmath282 . indeed ,",
    "if holds , then we have for every @xmath283      where the first step follows because @xmath284 is nonnegative ; the third step follows from and because there are not more than @xmath285 terms satisfying @xmath286 ; and the fourth step follows by upper bounding the sum by an integral .",
    "the waveform @xmath44 corresponding to the fourier transform is given by @xmath287 we note that the sum of the last two terms on the rhs of equals @xmath288 \\displaystyle -\\frac{\\lambda}{2}\\frac{\\cos(2\\pi\\ww\\,t)}{\\pi\\bigl((2\\ww\\,t)^2-\\frac{1}{4}\\bigr ) } , \\quad & t\\neq \\pm\\frac{1}{4\\ww}\\end{array } \\right.\\ ] ] which satisfies and hence also . however , @xmath289 decays like @xmath290 and does neither satisfy nor .",
    "we therefore replace @xmath289 in by a raised - cosine pulse of bandwidth @xmath0 hz and of roll - off factor @xmath291 to obtain the desired waveform          for every @xmath292 , the raised - cosine pulse on the rhs of satisfies and hence also . it therefore follows from the triangle inequality that also the pulse @xmath293 satisfies  , since for every @xmath228                  to prove , we note that @xmath295which we shall denote by @xmath296satisfies @xmath297 where @xmath44 is the inverse fourier transform of . furthermore , since the fourier transform of @xmath298 satisfies @xmath299 , @xmath300 ( with @xmath301 given by ) , and since @xmath302 , it follows from the dominated convergence theorem ( * ? ? ?",
    "* thm .  1.34 )",
    "that @xmath303 where the second step follows from parseval s theorem ( * ? ? ?",
    "6.2.9 ) , and where the last step follows from and because @xmath44 is of unit energy .",
    "it thus follows that for every @xmath228 @xmath304 where the last step follows from and .",
    "this proves and hence also the claim .",
    "j.  singh , o.  dabeer , and u.  madhow , `` transceiver design with low - precision analog - to - digital conversion : an information theoretic perspective , '' 2009 , to appear in _ ieee transactions on communications . [ online ] .",
    "available : http://arxiv.org/abs/0804.1172v1_"
  ],
  "abstract_text": [
    "<S> it is demonstrated that doubling the sampling rate recovers some of the loss in capacity incurred on the bandlimited gaussian channel with a one - bit output quantizer . </S>"
  ]
}