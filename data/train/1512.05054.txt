{
  "article_text": [
    "multifractional brownian motion ( mbm ) is considered as one of the most natural extensions of fractional brownian motion ( fbm ) . nowadays applications of mbm are numerous and growing .",
    "similar to fbm , mbm has been used in such diverse areas as geology , image analysis , signal processing , traffic networks and mathematical finance .",
    "for instance , we refer to lvy - vhel ( 1995 ) , bertrand et al .",
    "( 2012 ) and bianchi et al .",
    "( 2013 ) . in this brief introduction",
    ", we focus on applications to mathematical finance , which we know best . since generally neither fbm nor mbm are semi - martingales , rogers ( 1997 ) pointed out that there would be arbitrage in a market where stocks are modelled by fbm . however , cheridito ( 2003 ) showed that , if one relaxes the definition of arbitrage , fbm is an excellent candidate to model long - term memory in stock markets .",
    "bayraktar et al .",
    "( 2006 ) obtained fbm as the limit of the stock price in an agent - based model where investors display inertia .",
    "moreover , unlike stock prices , several processes , like stochastic volatility , exchange rates , or short interest rates do not need to be semi - martingales for a mathematical model to be arbitrage - free in a strict sense .",
    "for each of these processes , there is empirical evidence of long - term memory .",
    "we refer to corlay et al .",
    "( 2014 ) for stochastic volatility , xiao et al .",
    "( 2010 ) for exchange rates , and ohashi ( 2009 ) for interest rates . making the hurst parameter time - dependent",
    "allows to model different regimes of the stochastic process of interest .",
    "for example , in times of financial crisis , asset volatility rises significantly .",
    "likewise , empirical evidence shows that there has been periods of different volatility in either exchange rates or interest rates .",
    "this phenomena motivates one to introduce mbm into finance , since unlike fbm , the local regularity of volatilities driven by mbm allows to change via different periods .",
    "let @xmath0 denote an mbm with hurst function @xmath1 .",
    "we consider a general model @xmath2 with @xmath3 , @xmath4)$ ] . in this paper",
    "we are interested in estimating @xmath1 , starting from the observations of @xmath5 .",
    "an advantage of our model and methodology is that the functions @xmath6 and @xmath7 do not need to be known a priori .",
    "this is for instance the case of stochastic volatility , where the volatility @xmath8 is an unknown @xmath9 class function of @xmath10 .",
    "we define the mbm @xmath11}$ ] through its harmonizable representation ( see benassi et al .",
    "1997 ) : for @xmath12 $ ] , @xmath13 where :    @xmath14 : :    the hurst functional parameter @xmath15 is a    @xmath16-hlderian function with some    @xmath17 ; @xmath14 : :    the complex - valued stochastic measure    @xmath18 is defined as the fourier    transform of the real - valued brownian measure    @xmath19 . more precisely , for all    @xmath20 ,    @xmath21    where @xmath22 denotes the fourier transform of    @xmath23 :    @xmath24    statistically , the most significant feature of mbm , its local hlder regularity , can be measured by its pointwise hlder exponent . recall that for a continuous nowhere differentiable process @xmath25 , its pointwise hlder exponent @xmath26 is a stochastic process defined by : for each @xmath27 , @xmath28:~\\limsup\\limits_{\\epsilon\\rightarrow0}\\frac{|y(t_0+\\epsilon)-y(t_0)|}{|\\epsilon|^{\\alpha}}=0\\big\\}.\\ ] ] ayache and lvy - vhel ( 2004 ) show that for each @xmath29 , the pointwise hlder exponent of @xmath30 at each point @xmath27 , @xmath31 , is with probability @xmath32 equal to its hurst functional parameter @xmath33 : @xmath34    since generating the scenarios of fbm and mbm relies only on their hurst parameters ( see ayache and lvy - vhel 2004 ) , the problem of estimation of the hurst parameter has significant interests .",
    "several results have already been obtained recently on the estimation of the mbm s hurst functional parameter .",
    "we refer to rosenbaum ( 2008 ) , coeurjolly ( 2005 , 2006 ) , bardet ( 2002 ) , bardet and surgailis ( 2013 ) and bertrand et al .",
    "( 2013 ) .",
    "rosenbaum ( 2008 ) and bardet ( 2002 ) used wavelet - based methods to study inference problem on fbm , i.e. , the hurst parameter is constant ; coeurjolly ( 2005 , 2006 ) and bertrand et al .",
    "( 2013 ) studied the estimation of @xmath35 by using respectively generalized variations ( see also chan et al .",
    "1995 ) and increment ratio statistic method , where a discretized sample path of the mbm is assumed to be observed .",
    "bardet and surgailis ( 2013 ) developed a nonparametric estimation method ( based on the increment ratio ) for evaluating the local hurst function of a multifractional gaussian process ( whose increments are asymptotically a multiple of an fbm ) which extends mbm , starting from a discrete sample path of this process . in this work",
    "we consider a model more general than mbm but slightly less general than the one considered in bardet and surgailis ( 2013 ) .",
    "we study a different statistical setting ( either the wavelet coefficients of @xmath5 or a discrete path of @xmath36 points is observed ) , by applying a wavelet - based approach .",
    "note that the main advantage of this statistical setting is that , it could be applied to inferential problems when only a set of wavelet coefficients are available ( we refer to delbeke and van ( 1995 ) , abry et al .",
    "( 2002 ) , abry and conalvs ( 1997 ) and the references therein ) . by a study on the fine regularity property",
    ", our central limit theorem provides an explicit form for the limit covariance matrix .",
    "it is worth noting that , the construction of our estimator relies on a sharp estimation of the covariance structure of the mbm s wavelet coefficients .",
    "the main technical difficulty arises due to the fact that the covariance structure of mbm is much more complicated than that of fbm .",
    "the techniques used to identify such covariance structure is not obvious and thus has its specific interests in statistical inferences on multifractional processes as well as on stochastic analysis .",
    "consider the following system : for @xmath12 $ ] , @xmath37 where    @xmath14 : :    @xmath38 is an mbm defined in ( [ mbm ] ) .",
    "assume that its hurst functional parameter @xmath1 belongs to    @xmath39)$ ] and    @xmath40}h(t),\\sup\\limits_{t\\in[0,1]}h(t)\\big]\\subset(0,1);\\ ] ] @xmath14 : :    the closed forms of the deterministic functions @xmath6 and    @xmath7 are unknown .",
    "however we assume that    +    @xmath41 ; ;      @xmath3 , @xmath42      almost everywhere and there exist two constants      @xmath43 such that      @xmath44 for all      @xmath45 .",
    "@xmath46 ; ;      @xmath47)$ ] and @xmath48      almost everywhere .",
    "@xmath14 : :    suppose that a discrete trajectory of @xmath5 :    @xmath49 is observed for some    @xmath50 large enough .    our major goal is to evaluate the functional parameter @xmath15 . as in coeurjolly ( 2005 , 2006 ) , we introduce a pointwise estimation method , namely , the function @xmath15 is estimated pointwisely for any @xmath29 .",
    "once the time @xmath27 is fixed , the problem becomes a parametric estimation problem .",
    "peng ( 2011a ) studied this problem when @xmath8 is some stationary increment process ( with @xmath51 ) , where the optimal convergence rate @xmath52 is obtained by using the observations @xmath53 .",
    "however , when @xmath1 varies via time , the estimation of @xmath33 only relies on the sample size of the observed data in the neighborhood of @xmath54 and this neighborhood s radius convergence speed .",
    "hence the convergence speed of the corresponding estimator would be reasonably slower than @xmath52 ( see e.g. coeurjolly ( 2005 , 2006 ) for a particular case when @xmath5 is mbm ) . in this work , heuristically speaking , since the sample size of the neighborhood data of @xmath54 for estimating each @xmath33 is about @xmath55 , it is then believed that a good estimator should have its convergence rate near @xmath56 .",
    "subject to this statistical setting , we try to get the `` optimal '' rate of convergence estimator of @xmath33 by using wavelet basis .",
    "let the integer @xmath57 and let us pick any mother wavelet @xmath58)$ ] whose first @xmath59 moments are vanishing : @xmath60 and @xmath61 @xmath62 is called the cancellation order of @xmath63 .",
    "fix an integer @xmath64 , with @xmath65 being a subsequence of @xmath66 .",
    "the wavelet coefficients of @xmath8 are given by : for @xmath67 , @xmath68 we introduce a set of indices corresponding to a neighborhood of each @xmath29 : @xmath69 where the radius of this neighborhood @xmath70 satisfies @xmath71 and @xmath72 as @xmath73 .",
    "then the quadratic form estimator of @xmath74 is given as : @xmath75 for showing the consistency of our estimator and existence of central limit results , we need to impose the following technical assumptions to @xmath76 , @xmath62 and @xmath15 :    * ( a0 ) : * : :    @xmath77 .",
    "this condition leads to    @xmath78}h(t)>1 $ ] .",
    "we remark that the latter    inequality still holds when @xmath79 and    @xmath80}h(t)<3/4 $ ] , as a consequence our results    are still valid .",
    "however , we wo nt consider the latter assumptions ,    because practitioners in data analysis would nt expect the unknown    functional parameter @xmath15 should be valued less than    @xmath81 . * ( a1 ) : * : :    a lower bound of the convergence rate of @xmath70    toward 0 is given as :    @xmath82 * ( a2 ) : * : :    an upper bound of the convergence rate of @xmath70    toward 0 is described as : for any @xmath83 arbitrarily    small ,    @xmath84 * ( a3 ) : * : :    there exists a constant @xmath85 such that    @xmath86 . * ( a4 ) : * : :    this condition is stronger than * ( a1 ) * :    @xmath87    through this paper we assume that * ( a0 ) * is always satisfied .",
    "we will successively show that our estimator of @xmath33 is weakly consistent under assumption * ( a1 ) * ; it is strongly consistent under assumptions * ( a1)-(a2 ) * ; and it has an asymptotic gaussian behavior subject to assumptions * ( a2)-(a4)*. before stating these main results , we make some notation conventions :    ( a ) : :    a sequence @xmath88 of real - valued random    variables is said to be bounded almost surely if and only if    @xmath89    it is said to be bounded in probability if and only if    @xmath90    let @xmath91 be a sequence of strictly    positive real numbers and let @xmath88 be a    sequence of positive random variables .",
    "the notations    @xmath92 mean respectively that the    sequence @xmath93 is bounded almost    surely and in probability .",
    "( b ) : :    we say two sequences of strict positive values    @xmath91 and    @xmath94 are equivalent as @xmath95    tends to infinity if and only if there exist two constants    @xmath96 such that    @xmath97    we denote the relation of equivalence by @xmath98 .",
    "( c ) : :    we use the notations `` @xmath99{a.s.}$ ] '' ,    `` @xmath99{\\mathbb p}$ ] '' and    `` @xmath99{dist}$ ] '' to respectively denote    convergence @xmath100-almost surely , convergence in    probability and convergence in law .",
    "it is also useful to briefly introduce the steps which lead to the construction of the estimators :    * step 1 : * : :    identification of @xmath101 starting from the    observations @xmath49 . in    order to estimate @xmath101 , it suffices to make an    identification of @xmath102 given in ( [ d ] ) .",
    "such an    identification can be naturally obtained by discretization of    integrals to the sum as @xmath103    by lvy s modulus of continuity theorem for mbm ( see e.g. theorem 1.7    in benassi et al .",
    "1997 ) , @xmath4)$ ] , ( [ supx ] )    and the fact that    @xmath104}h(u)}=\\mathcal o\\big(|s - t|^{\\max\\{h(s),h(t)\\}}\\big)~\\mbox{as}~|s - t|\\rightarrow0,\\ ] ]    there exists a positive - valued random variable @xmath105 all of    whose moments are finite , such that for all @xmath106 $ ]    with @xmath107 , @xmath108 then , the following important relations hold ( the    proofs are given in the appendix ) : @xmath109 which show that    @xmath110 is a good estimator of    @xmath102 .",
    "next we set @xmath111    and show that @xmath112 satisfies    @xmath113    please see the appendix for the proof of ( [ widev ] ) .",
    "* step 2 : * : :    identification of @xmath33 starting from    @xmath114 .",
    "we use similar computations appeared in    peng ( 2011a ) .",
    "the main result is the following ( see proposition    [ varvx ] for a more explicit formula ) :",
    "@xmath115    where @xmath116 is a constant which does not depend on    @xmath117 ; @xmath118 denotes the    cardinal of @xmath119 .",
    "it is observed that    @xmath120    therefore subject to feasible choices of the sequence    @xmath121 , the following convergence can    accordingly take place in probability or almost surely :    @xmath122    where @xmath116 is some constant not depending on    @xmath117 .",
    "* step 3 : * : :    identification of @xmath33 starting from    @xmath123 .    +    under assumption * ( a1 ) * ( resp . * ( a1)-(a2 ) * ) , one has the following    relation of equivalence ( see ( [ as1 ] ) , ( [ taylor2 ] ) , ( [ diffv_p ] ) and    ( [ diffv_as ] ) ) : for @xmath124 ,    @xmath125    in probability ( resp . almost surely ) . as a consequence ,",
    "@xmath126    is a consistent estimator of @xmath33 .",
    "we remark that the    speed of convergence relies on the choice of @xmath127 .",
    "more    details on the choice of @xmath127 will be discussed in    theorem [ vydn ] .",
    "in this part we provide a sharp estimation of the covariance structure of wavelet coefficients of @xmath10 . for @xmath129 , define the wavelet coefficient @xmath130 of @xmath128 by @xmath131 for all @xmath132 - 1 \\right\\},$ ] with @xmath133 $ ] being the integer part function .",
    "+ the following proposition provides a fine identification of @xmath134 s covariance structure .",
    "[ prop1 ] let @xmath135 satisfy that , there exist two constants @xmath136 such that @xmath137 . ] .",
    "let @xmath138 - 1\\}$ ] , @xmath139 - 1\\}$ ] .",
    "+ @xmath41 if @xmath140 and @xmath141}|\\frac{at - bs}{ak - bk'}|\\leq1 $ ] , then we have @xmath142where the closed form of @xmath143 is given in @xmath144 and the remaining terms @xmath145 verify @xmath146 - 1,0\\leq k'\\leq [ b^{-1}]-1,ak\\neq bk'}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\big(t(k , k',q , a , b)\\big)^2=\\mathcal o((ab)^{1/2}\\log a\\log b),~\\mbox{as $ a , b\\rightarrow0$}.\\ ] ] @xmath46 if @xmath147 , we have @xmath148 where the explicit form of @xmath149 is given in @xmath150 .    the proof of proposition [ prop1 ]",
    "is given in the appendix .",
    "the following lemma is a straightforward consequence of proposition [ prop1 ] ( it suffices to take @xmath151 in proposition [ prop1 ] . )",
    "that we will rely on heavily through the remaining context .",
    "[ lemma1 ] for @xmath152 and @xmath153 , we have @xmath154 where @xmath155)$ ] is defined as @xmath156 and @xmath157 where @xmath158)$ ] is defined as @xmath159 in ( [ c2 ] ) .      in this section",
    "we first construct a consistent estimator of @xmath33 , when the wavelet coefficients of @xmath128 : @xmath161 can be straightforwardly observed ( i.e. @xmath162 ) .",
    "to this end we let @xmath163 the following proposition provides sharp identifications of @xmath114 s first order and second order moments .",
    "[ varvx ] for any @xmath29 , @xmath164 and @xmath165 where the constants @xmath166 and @xmath167 are given in ( [ computei00 ] ) and ( [ c2 ] ) respectively , and @xmath168    the proof of proposition [ varvx ] is given in the appendix .",
    "we remark that , since a sequence of random variables bounded almost surely is also bounded in probability , therefore the following identification of @xmath114 holds , thanks to proposition [ varvx ] , chebyshev s inequality and borel - cantelli s lemma .",
    "[ iv ] if @xmath169 , we have @xmath170 as a consequence ,    ( a ) : :    if @xmath171 , then    @xmath172 ( b ) : :    if @xmath171 and    @xmath173    for arbitrarily small @xmath83 , then    @xmath174    for arbitrarily small @xmath83 .    * proof .",
    "* by using chebyshev s inequality , ( [ varv ] ) and the condition that @xmath169 , we get for any @xmath175 , @xmath176 where @xmath116 is some constant which does not depend on @xmath117 .",
    "this implies @xmath177 then it follows from ( [ varv ] ) , ( [ iv5 ] ) and the fact that @xmath178 that @xmath179 ( [ iv1 ] ) has been proven .",
    "note that ( [ iv2 ] ) follows straightforwardly from ( [ iv1 ] ) .",
    "now we only need to show ( [ iv3 ] ) holds . from ( [ iv5 ] ) and chebyshev s inequality",
    ", we observe that there exists a constant @xmath116 which does not depend on @xmath180 nor on @xmath117 such that for any @xmath175 , @xmath181 since @xmath173 , then applying borel - cantelli s lemma leads to @xmath182 further observe that @xmath183 therefore ( [ iv3 ] ) follows .",
    "lemma [ iv ] has been proven .",
    "@xmath184    now we are ready to state the main results of this section .",
    "the following theorem constructs a consistent estimator of @xmath33 starting from the wavelet coefficients @xmath160 .",
    "[ vxd ] for @xmath29 , denote by @xmath185    ( a ) : :    if @xmath171 , then    @xmath186 ( b ) : :    if @xmath171 and    @xmath173    for any @xmath83 arbitrarily small , then    @xmath187    * proof . * this theorem is a straightforward consequence of lemma [ iv ] , as we observe that , by construction , @xmath188 verifies @xmath189 then , by lemma [ iv ] , the fact that the logarithm function belongs to @xmath190 , continuous mapping theorem and the mean value theorem , we get theorem [ vxd ] .",
    "@xmath184    in theorem [ vxd ] , if we assume @xmath191 with some @xmath192 and @xmath193 , then by elementary computation we obtain the following corollary , which leads to choose @xmath194 to obtain the best rate of convergence of the estimator @xmath188 .",
    "this result is similar to the choice of @xmath195 in bardet ( 2002 ) in the setting of fbm .",
    "[ cor ] under assumption @xmath191 with @xmath192 and @xmath193 ,    ( a ) : :    taking @xmath196 and @xmath197 , we have    @xmath198 ( b ) : :    for small @xmath83 , taking    @xmath199 and    @xmath200 , we obtain    @xmath201    the second main result of this part describes an asymptotic gaussian behavior of the estimator of @xmath33 , where the limit covariance matrix is precisely given , which depends on @xmath33 .",
    "[ cltx ] for @xmath29 , if @xmath171 and assumptions @xmath202 are verified , then @xmath203{dist}\\mathcal n\\big(0,\\tilde{c}(t_0)\\big),\\ ] ] where the constant @xmath204 with @xmath205 given in @xmath206 and @xmath207 given in ( [ c3t0 ] ) .",
    "in order to prove theorem [ cltx ] , we rely heavily on the following proposition .",
    "[ prop : clt1 ] for any @xmath29 and any integer @xmath208 , denote by @xmath209 then @xmath210{dist}\\mathcal n(0,\\sigma),\\ ] ] where @xmath211 with @xmath212 and @xmath213    * proof . * following the similar method as in bardet ( 2000 )",
    ", we show that for the empirical average of @xmath214 , a multivariate central limit theorem holds thanks to a lindeberg s condition .",
    "more precisely , for @xmath117 big enough and for @xmath215 , @xmath216 , denote by @xmath217 a lindeberg s condition thus can be deduced from the following relations :    * for @xmath218 , @xmath219 * for @xmath220 , @xmath221 * for @xmath222 , @xmath223      next we present the following classical result ( see e.g. oehlert 1992 ) .",
    "[ deltamethod ] let the estimators @xmath242 ( valued in @xmath243 ) of @xmath244 satisfy the following central limit theorem : @xmath245{dist}\\mathcal n(0,\\sigma),\\ ] ] where @xmath246 denotes the covariance matrix of the limit distribution and @xmath247 is a sequence of positive numbers tending to infinity .",
    "let @xmath248 ( @xmath249 or @xmath250 ) belong to @xmath251 , then the following convergence in law holds : @xmath252{dist}\\mathcal n\\big(0,\\nabla g(\\theta_1,\\theta_2)^t\\sigma\\nabla g(\\theta_1,\\theta_2)\\big),\\ ] ] where @xmath253 denotes the transpose of the gradient of @xmath254 on @xmath244 .",
    "note that if @xmath255 in proposition [ deltamethod ] , the gradient of @xmath254 becomes a jacobian matrix . + * proof of theorem [ cltx ] . * for simplifying notation",
    "we denote by @xmath256therefore the following decomposition holds : @xmath257 since the fact that @xmath258 implies @xmath259 and also by taking @xmath260 in ( [ vnv2 ] ) , we have @xmath261 by ( [ lemme12 ] ) ( [ dec1 ] ) , ( [ jensen ] ) , ( [ cardident ] ) and ( [ das ] ) , we then obtain @xmath262 it follows from markov s inequality that there exists @xmath116 such that @xmath263 the assumption * ( a2 ) * then allows us to apply borel - cantelli s lemma to obtain @xmath264{a.s.}0.\\ ] ] therefore , it follows from proposition [ prop : clt1 ] and continuous mapping theorem that @xmath265{dist}\\mathcal n(0,\\sigma).\\ ] ] since @xmath266 , using slutsky s theorem , we get @xmath267{dist}\\mathcal n(0,\\sigma).\\ ] ] this is in fact equivalent to @xmath268{dist}\\mathcal n(0,\\widetilde{\\sigma}),\\ ] ] with @xmath269 . then by applying proposition [ deltamethod ] to ( [ dec2 ] ) with @xmath270 , @xmath271 , @xmath272 and @xmath273 , we get @xmath274{dist}\\mathcal n(0,\\widetilde{\\sigma}),\\end{aligned}\\ ] ] because the jacobian matrix @xmath275 .",
    "now we apply again proposition [ deltamethod ] to ( [ dec3 ] ) with @xmath276 , to get @xmath277{dist}\\mathcal n\\big(0,\\tilde{c}(t_0)\\big),\\ ] ] where @xmath278 because @xmath279 .",
    "since in practice , it is more realistic to assume that a discretized trajectory of @xmath281 is observed , therefore in this section , we obtain a consistent estimator of @xmath33 starting from the high frequency @xmath280 is still available .",
    "recall that the assumptions on @xmath6 are given in section 1.1 .",
    ", then the key point leading to these results is to take a second order taylor expansion with integral remainder , to obtain for @xmath29 , @xmath282 this together with ( [ ah ] ) and the fact that @xmath283 for all @xmath45 yields @xmath284 note that ( [ ah ] ) can lead to @xmath285 it follows from ( [ taylor2 ] ) , the definition of @xmath101 and ( [ bound - dx ] ) that @xmath286 hence similar to lemma [ iv ] , we have    [ ivy ] if @xmath169 , then @xmath287 as a consequence ,    ( a ) : :    under assumption @xmath288 ,    @xmath289 ( b ) : :    under assumptions @xmath290 ,    @xmath291    for @xmath83 arbitrarily small .    here",
    "we note that , to show ( [ ivy2 ] ) and ( [ ivy3 ] ) hold , we must observe that under assumption @xmath288 , @xmath292 lemma [ ivy ] further implies the following :    [ vyd ] for @xmath29 , denote by @xmath293    ( a ) : :    under assumption @xmath288 ,    @xmath294 ( b ) : :    under assumptions @xmath290 ,    @xmath295    for @xmath83 arbitrarily small .",
    "( c ) : :    under assumptions @xmath296 ,    @xmath297{dist}\\mathcal n\\big(0,\\tilde{c}(t_0)\\big),\\ ] ]    where the covariance matrix @xmath298 is given in    ( [ tildec ] ) .",
    "* proof . *",
    "( [ vyd2 ] ) and ( [ vyd3 ] ) are obvious by using lemma [ ivy ] and the fact that convergences in probability and almost surely are preserved under continuous transformations . in order to show ( [ clty1 ] )",
    ", we only need to verify @xmath299{a.s.}0.\\ ] ] equivalently , it suffices to show @xmath300{a.s.}0.\\ ] ] we have , by using the mean value theorem on @xmath301 , @xmath302 where @xmath303 is some random variable valued in the open interval with ending points @xmath304 and @xmath32 . since @xmath305 tends to @xmath32 a.s . as @xmath73 , then according to ( [ vxy ] ) and * ( a1 ) * , the right - hand side of the above equation can be bounded by @xmath306 which converges to @xmath307 as @xmath73 , thanks to assumption * ( a4)*. @xmath184    the following results are of the most interests in this section .",
    "we construct consistent estimators of @xmath33 starting from the observations @xmath308 .",
    "[ vydn ] for @xmath29 , denote by @xmath309    ( a ) : :    set @xmath310 $ ] , with @xmath311 .",
    "we let    @xmath312 satisfy assumption * ( a1 ) * , then    @xmath313 ( b ) : :    let @xmath312 satisfy assumptions * ( a1)-(a2 ) * , then    @xmath314    for any @xmath315 arbitrarily small .",
    "( c ) : :    under assumptions * ( a2)-(a4 ) * and    @xmath316 ,    @xmath317{dist}\\mathcal n\\big(0,\\tilde{c}(t_0)\\big).\\ ] ]    * proof . * in order to prove ( [ vydn2 ] ) and ( [ vydn3 ] ) , we rely on the following relation : under assumptions * ( a1)-(a2 ) * , @xmath318 this is because , by using markov s inequality , cauchy - schwarz inequality , ( [ widev ] ) , ( [ ivy3 ] ) and the dominated convergence theorem , @xmath319 similarly to ( [ ediffv ] ) , we also obtain for any @xmath320 arbitrarily small , @xmath321 the fact that @xmath322 implies @xmath323 , then by borel - cantelli s lemma , @xmath324 therefore , ( [ vydn2 ] ) ( resp . ( [ vydn3 ] ) ) follows from the following 2 decompositions : @xmath325 @xmath326 and equations ( [ vyd2 ] ) , ( [ diffv_p ] ) ( resp . ( [ vyd3 ] ) , ( [ diffv_as ] ) ) .    for showing ( [ cltyn1 ] ) , we only need to show @xmath327{\\mathbb p}0.\\ ] ] by using the same idea we took to prove ( [ diffh1 ] ) , we just need to verify @xmath328{\\mathbb p}0.\\ ] ] this is true since , according to ( [ ediffv ] ) and the fact that ( by assumption * ( a4 ) * ) @xmath329 , the left - hand side of the above term can be bounded in probability by @xmath330 the fact that @xmath316 entails @xmath331 .",
    "consequently , @xmath328{\\mathbb p}0,\\ ] ] hence ( [ cltyn1 ] ) holds .",
    "@xmath184      in theorem [ vydn ] ,",
    "the choices of @xmath70 and @xmath16 depend on the target parameter @xmath33 .",
    "this is unacceptable from practical point of view . to overcome this inconvenience",
    ", we make assumptions * ( a1 ) , ( a4 ) * stronger so that the values of @xmath70 and @xmath16 do nt rely on @xmath33 : suppose the lower bound @xmath332}h(t)$ ] and the upper bound @xmath333}h(t)$ ] are known .    * ( a1 ) * : :    @xmath334 with    @xmath335 ; * ( a4 ) * : :    @xmath334 with    @xmath336 and    @xmath337",
    ".    without great effort we could see * ( a1 ) * implies * ( a1 ) * and * ( a4 ) * implies * ( a4 ) * for all @xmath29 .",
    "then from theorem [ vyd ] and theorem [ vydn ] , we easily derive the following results :    [ cor2 ]    ( a ) : :    let @xmath338 satisfy assumption * ( a1 ) * , then    @xmath339 ( b ) : :    if @xmath338 satisfies assumption * ( a1 ) * , then it    also satisfies * ( a2)*. as a result ,    @xmath340    for @xmath83 arbitrarily small . ( c ) : :    under assumptions * ( a2 ) , ( a3 ) , ( a4 ) * ,    @xmath341{dist}\\mathcal n\\big(0,\\tilde{c}(t_0)\\big).\\ ] ]    [ cor1 ]    ( a ) : :    set @xmath310 $ ] , with @xmath311 . if    @xmath312 satisfies assumption * ( a1 ) * , then    @xmath342 ( b ) : :    if @xmath312 satisfies assumption * ( a1 ) * , then    @xmath343    for any @xmath315 arbitrarily small . ( c ) : :    under assumptions * ( a2 ) , ( a3 ) , ( a4 ) * ,    @xmath344{dist}\\mathcal n\\big(0,\\tilde{c}(t_0)\\big).\\ ] ]    we conclude that the selection of @xmath345 can be made for each setting as follows :    * in corollary [ cor2 ] ( a ) , for any @xmath346 , taking @xmath347 , we obtain the best rate of convergence in this setting : @xmath348 * in corollary [ cor2 ] ( b ) , similarly , taking @xmath349 obtains @xmath350 * in corollary [ cor1 ] ( a ) , the best choices of @xmath16 , @xmath351 are the ones such that @xmath352 and @xmath347 .",
    "consequently , @xmath353 * in corollary [ cor1 ] ( b ) we select @xmath354 and @xmath349 to obtain @xmath355    from the above discussion we conclude that our estimator has its best convergence rate approximately @xmath356 when the wavelet coefficients of @xmath5 are observed , and @xmath357 when a discrete sample path of @xmath5 is observed . this convergence rate is poorer than the case when @xmath128 is straightforwardly available .",
    "the estimation of the hidden pointwise hlder exponent also allows to solve stochastic volatility model s nonparametric estimation problem . for example , suppose some underlying mbm @xmath30 satisfies the following nonlinear model : for @xmath12 $ ] , @xmath359 where    * @xmath360}$ ] is an mbm with unknown @xmath361)$ ] ; * @xmath4)$ ] , @xmath362 almost everywhere is an unknown real - valued deterministic function ; * only a discrete trajectory @xmath308 is available .    from the statistical setting , the information of the hidden mbm remains unknown .",
    "however , the following result shows it is still possible to evaluate the parameter @xmath7 .",
    "the strategy is : first estimate the pointwise hlder exponent @xmath15 by @xmath363 given in theorem [ vydn ] , then the following result holds :    [ prop : application ] fix @xmath29 and @xmath310 $ ] with @xmath17 .",
    "let @xmath364 then ,    ( a ) : :    under assumption @xmath365 ,    @xmath366{\\mathbb p}\\theta(t_0)^2.\\ ] ] ( b ) : :    under assumptions @xmath365 and * ( a2 ) * ,    @xmath367{a.s.}\\theta(t_0)^2.\\ ] ]    * proof of proposition [ prop : application ] .",
    "* we only show ( [ theta1 ] ) holds , since the way to obtain ( [ theta1 ] ) is similar . under assumptions * ( a1 ) * and * ( a2 ) * , on one hand , it follows from ( [ diffv_as ] ) and ( [ ivy3 ] ) that @xmath368{a.s.}2c_2(t_0).\\ ] ] on the other hand , by using ( [ c2 ] ) and the fact that @xmath369 , we see @xmath370 since the functions @xmath371 and @xmath372 are both continuous over @xmath373 , therefore by combining ( [ ptheta1 ] ) , ( [ diffhath ] ) and ( [ vydn3 ] ) , we obtain proposition [ prop : application ] . @xmath184",
    "bardet and surgailis ( 2013 ) established a pseudo - generalized least squares version of the localized increment ratio estimator and quadratic estimator of @xmath15 , denoted by @xmath374 and @xmath375 respectively .",
    "this work is so far the most achieved one on estimation of the mbm s pointwise hlder exponent . in this section",
    "we compare our model and approach to bardet and surgailis ( 2013 ) s and illustrate some simulation results .",
    "the main differences between our statistical setting and bardet and surgailis ( 2013 ) s are :    1 .",
    "bardet and surgailis ( 2013 ) considers observation of a multifractional gaussian process which has asymptotic self - similarity and `` tangent to '' an fbm with hurst parameter @xmath376 and scaled by @xmath377 at each time @xmath378 .",
    "this setting covers ours when @xmath379 .",
    "however , our model is different when @xmath6 is some other function . 2 .",
    "the estimators @xmath374 and @xmath375 are obtained in terms of observations of discrete sample path of the process .",
    "we have established estimators based on observations of discrete sample path of @xmath5 and wavelet coefficients of the process ( see @xmath380 in theorem [ vyd ] ) , respectively .",
    "the latter result is the main contribution of this paper . for more details on wavelet - based statistics",
    "we refer to delbeke and van ( 1995 ) , abry et al .",
    "( 2002 ) , abry and conalvs ( 1997 ) .",
    "3 .   the estimators @xmath374 and @xmath375 apply to all @xmath381)$ ] with @xmath175",
    ", however our estimators only work for @xmath382 .",
    "4 .   in both @xmath374 and @xmath375 , the length of the local window @xmath383 plays the role as @xmath384 in our setting , which partially explains the estimator s asymptotic behavior . for building up the convergence ,",
    "both bardet and surgailis ( 2013 ) s and our model are subject to some technical assumptions . here",
    "we consider a particular case to compare the estimators rate of convergence .",
    "let @xmath385 , where @xmath128 has pointwise hlder exponent @xmath15 . from proposition 3 ( iii ) and",
    "( iv ) in bardet and surgailis ( 2013 ) we see for @xmath386 and arbitrarily small @xmath387 , the estimators @xmath388 and @xmath389 have the best rate of convergence in probability and a.s . respectively : @xmath390 and @xmath391 where * * @xmath392**@xmath393 ir2 or qv2 .",
    "we set @xmath394 in corollary [ cor ] .",
    "then according to corollary [ cor ] , @xmath388 has a better rate of convergence in probability than @xmath395 , while @xmath395 outperforms @xmath389 by having a better rate of a.s . convergence .",
    "now we deliver algorithms to generate our estimators @xmath396 and @xmath397 . from theorem [ vyd ] ,",
    "an algorithm to generate @xmath396 can be given as follows : + * algorithm i : estimation of @xmath398 starting from wavelet coefficients * + @xmath32 : * input : * a sample @xmath399 , @xmath332}h(t)$ ] and @xmath29 + @xmath250 : _ * initialize all the parameters : * _ + @xmath400 : @xmath401 ; @xmath402 ; + @xmath403 : _ * establish a set of indices corresponding to the neighbors of @xmath54 : * _ + @xmath404 : @xmath405 $ ] ; + @xmath406 : _ * compute `` partial '' sum of squares of the wavelet coefficients : * _ + @xmath407 : @xmath408 ; + @xmath409 : _ * compute estimate of @xmath33 : * _ + @xmath410 : @xmath411 ; + @xmath412 : * output : * @xmath396 + in algorithm i , line 3 proposes a data - driven procedure to set the parameters @xmath351 and @xmath413 . from line 7",
    "we see that this algorithm requires at least @xmath414 operations . by this result and corollary [ cor2 ]",
    "it appears a trade - off between computational cost and precision of estimation : less value of @xmath415 reduces computational cost but leads to less precision of estimation .",
    "next we numerically study the estimator @xmath416 and compare the results with bardet and surgailis ( 2013 ) s . in view of corollary",
    "[ cor1 ] , we choose the parameters @xmath310 $ ] , @xmath417 with @xmath352 and @xmath418 .",
    "we also choose @xmath63 to be haar wavelet s mother wavelet function : @xmath419}(x)$ ] .",
    "below is an algorithm to simulate @xmath416 , according to theorem [ vydn ] . + * algorithm ii : estimation of @xmath33 starting from discretized trajectory * + @xmath32 : * input : * a sample @xmath420 , @xmath332}h(t)$ ] and @xmath29 + @xmath250 : _ * initialize all the parameters : * _ + @xmath400 : @xmath421 ; @xmath422 ; @xmath423 $ ] ; @xmath424 ; + @xmath403 : _ * establish a set of indices corresponding to the neighbors of @xmath54 : * _ + @xmath404 : @xmath425 $ ] ; + @xmath406 : _ * estimate the wavelet coefficients : * _ + @xmath407 : * for @xmath426 in @xmath427 , do : * + @xmath409 :  @xmath428 ; + @xmath410 : * end for * + @xmath412 : _ * estimate `` partial '' sum of squares of the wavelet coefficients : * _ + @xmath429 : @xmath430 ; + @xmath431 : _ * compute estimate of @xmath33 : * _ + @xmath432 : @xmath433 ; + @xmath434 : * output : * @xmath416 + line 3 shows the procedure to set the parameters @xmath16 , @xmath351 , @xmath127 and @xmath312 . in line 8 , each item",
    "@xmath435 can be approximated by @xmath436 , when @xmath95 is large .",
    "hence from lines 7 - 9 of the algorithm we see that the algorithm requires at least @xmath437 operations .",
    "this fact together with the discussion on corollary [ cor1 ] reveals that the choice of @xmath415 has no impact on the computational cost , but only on the precision of the estimation .",
    "next we provide the empirical mean , the standard deviation and the quantile - quantile plots ( qq plots ) through a simulation study , where all the codes in matlab are available from authors upon request .",
    "we let @xmath438 , then choose 4 different types of @xmath6 and @xmath400 different hurst functional parameters @xmath376 , @xmath439 as follows : @xmath440 since @xmath441 for the above three @xmath15 , we then choose @xmath442 , @xmath443 , @xmath444 .",
    "we assume a single discrete trajectory : @xmath445 is available , and denote @xmath446 to be the estimate of @xmath447 : @xmath448 ( @xmath449 ) for short . by generating each estimator @xmath450 times , we present the corresponding empirical mean ( @xmath451 ) and standard deviation ( @xmath452 ) in the following table .",
    ".mean and std of the estimates @xmath416 with @xmath453 and @xmath454 . [ cols= \" < , < , < , < , < , < , < \" , ]     note that in the function _",
    "variair@xmath455mbm(eta , n , tot ) _ , the mbm was previously generated using the choleski decomposition of the covariance matrix , so that the sample size @xmath95 is limited to @xmath456 . however here we have generated the mbm using wood @xmath457 chan circulant matrix , some krigging and a prequantification ( see chan and wood 1998 ; barrire 2007 ) , the sample size @xmath95 can be thus taken as @xmath458 .",
    "the empirical comparison shows no significant difference between the performances of @xmath416 and @xmath459 , except that @xmath460 estimator has less variance .",
    "below we compare the probability distributions of @xmath416 versus @xmath459 , by displaying qq plots ( see fig .",
    "1 ) . the first @xmath400 qq plots show whether @xmath416 and @xmath459 come from the same distribution for @xmath461 , @xmath462 , @xmath463 and @xmath464 ; the last one illustrates the asymptotically normal behavior of our estimator @xmath416 for @xmath463 and @xmath465 .     versus @xmath459 for @xmath464 and @xmath416 versus standard normal for @xmath465 .",
    "]    the qq plots show that the probability distribution of our estimator for each @xmath33 are close to that of ir2 estimator when the observed signal process is mbm and it is asymptotically normally distributed .    through the above simulation study we conclude that there is no significant difference among ir2 estimator provided in bardet and surgailis ( 2013 ) and our wavelet - based estimator . and",
    "no significant difference is observed among wavelet - based estimators corresponding to different @xmath3 .",
    "we also state that the bias and variance of @xmath466 are generally greater than ir2 estimator when the sample size is relatively small .",
    "this is because , the wavelet - based method generally provides estimators of slower convergence rate than ir2 estimator .",
    "first by using triangle inequality , we get @xmath467 recall that @xmath281 for @xmath12 $ ] . define the random variable @xmath468 to be @xmath469}|x(t)|.\\ ] ] since @xmath7 is continuous and not equal to @xmath307 almost everywhere ,",
    "then @xmath470}$ ] is a gaussian process with continuous trajectories , by applying dudley s theorem and borell s inequality ( more precisely , with the same arguments for the proof of @xmath471 on page 1445 - 1446 in rosenbaum ( 2008 ) .",
    "see also ledoux and talagrand ( 2010 ) ) , we can show that @xmath472 this means all of @xmath468 s moments are finite .",
    "hence , using the mean value theorem , we get @xmath473}|\\phi'(s)|$ ] is a random variable .",
    "it follows from ( [ dnd1 ] ) and ( [ dnd2 ] ) that @xmath474 in order to get ( [ dnds ] ) , we need ( [ ah ] ) , from which we see there exists a positive random variable @xmath475 with all finite moments such that @xmath476 observe that for @xmath477 $ ] , @xmath478 and @xmath479 this together with the fact that @xmath480 for @xmath477 $ ] yields there exists a positive random variable @xmath481 with all finite moments such that , @xmath482 then ( [ dnds ] ) results from ( [ dnd3 ] ) and ( [ dnds1 ] ) .",
    "@xmath184    now we are going to prove ( [ dnd ] ) . for @xmath483 ,",
    "we consider the @xmath484-order moment of @xmath485 in ( [ dnd3 ] ) . by applying the following two versions of jensen s inequalities :",
    "@xmath486 and cauchy - schwarz inequality , we obtain @xmath487}|\\psi(s)|^r\\big)2^{-j(r/2 - 1)}\\nonumber\\\\      & & ~~\\times\\sum_{l=0}^{2^{n - j}-1}\\int_{\\frac{l}{2^n}}^{\\frac{l+1}{2^n}}\\big(\\mathbb e(c_1^{2r})\\big)^{1/2}\\big(\\mathbb e|x(l2^{-n}+k2^{-j})-x(t+k2^{-j})|^{2r}\\big)^{1/2}{\\,\\mathrm{d } } t.      \\end{aligned}\\ ] ] note that by lemma 2.12 ( i ) in ayache et al .",
    "( 2011 ) , there exists a constant @xmath488 which does not depend on @xmath489 and @xmath1 such that @xmath490 therefore by using again ( [ neighbor ] ) and the fact that @xmath480 , there exists some constant @xmath116 such that @xmath491 using ( [ dnd5 ] ) and similar computations as in ( [ computex ] ) , we obtain there exists @xmath492 such that @xmath493 by using the fact that all the moments of gaussian variable are equivalent , we get there exists some constant @xmath494 ( only depending on @xmath484 ) such that @xmath495 finally it results from ( [ dnd4 ] ) and ( [ dnd6 ] ) that @xmath496 where @xmath497}|\\psi(s)|^r\\big)\\big(c_3\\mathbb e(c_1^{2r})\\big)^{1/2}$ ] . therefore ( [ dnd ] ) has been proven .",
    "@xmath184        it follows from ( [ jensen ] ) , cauchy - schwarz inequality , ( [ card ] ) and the fact that @xmath500 that @xmath501 roughly speaking ( and it can be proven without efforts ) , since the trajectory @xmath502 is at least as smooth as @xmath503 , then for @xmath483 , there exists a constant @xmath504 ( only depending on @xmath484 ) such that , @xmath505 then it results from ( [ vnv1 ] ) , ( [ vnv2 ] ) , ( [ dnd ] ) and ( [ card ] ) that @xmath506 in view of the equivalence relation between @xmath507 and @xmath33 as @xmath215 and @xmath73 , ( [ widev ] ) finally results from ( [ vnv3 ] ) .",
    "@xmath184        by using the fact that @xmath508 , @xmath509 are zero - mean gaussian random variables , fubini s theorem , the isometry property of mbm s harmonizable presentation and a change of variables , we get @xmath510 since the pointwise hlder exponent of @xmath30 in the neighborhood of @xmath511 behave locally asymptotically like those of fractional brownian motions with hurst parameters @xmath512 : @xmath513 on @xmath514 and @xmath515 on @xmath516 , we can thus consider a taylor expansion of @xmath1 respectively on @xmath514 and @xmath517 . to be more explicit ,",
    "let s fix @xmath518 and define @xmath519 , since @xmath23 belongs to @xmath520)$ ] , we take the second order taylor expansion for @xmath23 respectively on @xmath514 and @xmath521 there exist @xmath522 and @xmath523 such that @xmath524where we denote , for @xmath525 , @xmath526 , @xmath527 and @xmath528 thus we rewrite ( [ cov1 ] ) as @xmath529 where @xmath530we note here @xmath531 s and @xmath532 s are notations in short for ( [ a ] ) and ( [ a ] ) . by using ( [ cov1 ] ) , it suffices to make an identification of all the terms @xmath533 in order to estimate the covariance structure of the wavelet coefficients .",
    "we consider different cases according to the values of @xmath534 .",
    "the key to these identifications is to observe the following :    * first , observe that for @xmath535 , @xmath536 , we have @xmath537 where for @xmath538 , @xmath539 , with @xmath540 being the binomial coefficient . *",
    "secondly , for @xmath541 , @xmath57 , @xmath542 , @xmath536 and @xmath543 , a @xmath544 order taylor expansion of @xmath545 on @xmath546 yields : @xmath547 where the integral remainder @xmath548 of @xmath549 s @xmath550-th order taylor expansion ( see e.g. apostol 1967 ) is given as : for @xmath551 , @xmath552 for @xmath553 , @xmath554 and the function @xmath555 here we note that for @xmath556 and @xmath557 , @xmath558    case ( i ) : :    @xmath559 .",
    "+    in this case we have @xmath560    let @xmath561 , @xmath562 and    @xmath563 in ( [ general ] ) .",
    "it follows    @xmath564then    by the assumption    @xmath565}\\vert \\frac{at - bs}{ak - bk^{\\prime } } \\vert \\leq 1 $ ] ,    we can thus take @xmath566 in ( [ computei ] ) and obtain    @xmath567    we finally obtain @xmath568where    the function    @xmath569 case ( ii ) : :    @xmath570    +    by definition , @xmath571    equals @xmath572    since @xmath573)$ ] , then by the triangle    inequality the above item can be expressed as    @xmath574    let @xmath561 and @xmath249 ( respectively    corresponding to @xmath575 and @xmath32 of the above    expression ) , @xmath576 and    @xmath577 in ( [ general ] ) , @xmath578 in ( [ computei ] ) ,    we obtain @xmath579    since    @xmath580 ,    thus we get at the meanwhile ,    @xmath581    using the fact that @xmath582 , we conclude    @xmath583 case ( iii ) : :    @xmath584    +    observe that    @xmath585 can be    expressed as @xmath586    +    let @xmath587 respectively ,    @xmath562 and    @xmath588 in ( [ general ] ) and    @xmath589 in ( [ computei ] ) , we get    @xmath590 case ( iv ) : :    @xmath591 +    by using the fact that @xmath592)$ ] ,    @xmath593 can be    expressed as    @xmath594    let @xmath587 respectively ,    @xmath562 and    @xmath595 in ( [ general ] ) and notice that    @xmath596 depends on @xmath378 , we get    @xmath597    +    then similarly to ( [ computei ] ) , using a @xmath62 order taylor    expansion of @xmath598 respectively on    @xmath599 and on @xmath600 , and also use    the fact that for @xmath601 ,    @xmath602 ( since    @xmath603 ) , we obtain    +    @xmath604    +    by using symmetric property , @xmath605 case ( v ) : :    @xmath606 . +    since the computations are quite similar as in the previous cases , we    present the results without proof .",
    "@xmath607    @xmath608    @xmath609    now denote by @xmath610 it remains to show that for @xmath77 and @xmath582 , @xmath611 - 1}\\sum_{k'=0}^{[b^{-1}]-1}\\big(t(k , k',q , a , b)\\big)^2=\\mathcal o((ab)^{1/2}\\log a\\log b),~\\mbox{as $ a , b\\rightarrow0$}.\\ ] ] according to ( [ tkk ] ) , it suffices to prove for any @xmath612 , @xmath613 - 1}\\sum_{k'=0}^{[b^{-1}]-1}(ab)^{-h(ak)-h(bk')-1}\\big(\\mathcal{i}_{l , l'}(k , k',a , b)\\big)^2=\\mathcal o((ab)^{1/2}\\log a\\log b).\\ ] ] to prove ( [ boundi ] ) holds we only take @xmath614 as an example , since the computations of the other items are similar . recall that @xmath615 remember that , the fact that @xmath77 yields @xmath616 , and @xmath617 $ ] . these facts together with @xmath582 imply @xmath618 - 1}\\sum_{k'=0}^{[b^{-1}]-1}(ab)^{-h(ak)-h(bk')-1}\\big(\\mathcal i_{1,0}(k , k',a , b)\\big)^2\\\\ & & = \\mathcal o\\big(ab|\\log(ab)|^2\\sum_{k=0}^{[a^{-1}]-1}\\sum_{|l|=1}^{+\\infty}\\frac{(\\log|l|)^2}{|l|^{4q-4\\sup_{t\\in[0,1]}h(t)-2}}\\big)\\\\ & & = \\mathcal o\\big(a^{-1}ab|\\log(ab)|^2\\big)=\\mathcal o\\big(b|\\log(ab)|^2\\big)=\\mathcal o\\big((ab)^{1/2}\\log a\\log b\\big).~~\\square\\\\\\end{aligned}\\ ] ]      when @xmath619 , we still make a taylor expansion as in the proof of ( [ prop11 ] ) . for the first term @xmath620 , since @xmath621 ( some constant ) , then using the same formula in ( [ computei00 ] ) , we get@xmath622 where @xmath623    the remaining items of @xmath624 s are of higher order so we only give a bound of them . by means of a taylor expansion of @xmath625 on @xmath626",
    ", then similar discussion shows that , for @xmath627 , @xmath628      fix @xmath29 .",
    "it follows from the definition of @xmath114 , ( [ vxv ] ) , ( [ lemme12 ] ) and the fact that @xmath629 that @xmath630 it remains to show , for @xmath215 , @xmath631 for this purpose , for fixed @xmath632 we define @xmath633)$ ] as for @xmath634 $ ] , @xmath635 then by using the taylor expansion of @xmath636 around @xmath637 and the facts that @xmath638 , @xmath639)$ ] , @xmath361)$ ] , we obtain @xmath640 where @xmath641 is some value in @xmath642 .    therefore , by using ( [ varv1 ] ) , ( [ varv2 ] ) and the fact that @xmath643 we get @xmath644 thus ( [ varv ] ) follows .",
    "now we are going to show ( [ varv ] ) .",
    "first observe @xmath645 then we recall the fact that if @xmath646 is a centered gaussian random vector , then ( see e.g. lemma 5.3.4 in peng 2011b ) @xmath647 it yields @xmath648 ( [ varv1 ] ) together with lemma [ lemma1 ] implies @xmath649 now we study the second line of ( [ varv2 ] ) . by the facts that @xmath629 , @xmath650 , @xmath651",
    ", we obtain @xmath652 for the fourth line of ( [ varv2 ] ) , by using cauchy - schwarz inequality and proposition [ prop1 ] , we get @xmath653 therefore ( [ varv2 ] ) is equivalent to @xmath654    in order to make an identification of the dominating part of ( [ varv5 ] ) , for fixed @xmath655 we define @xmath656),~k_3\\in c^1([0,1]^2)$ ] as , for @xmath657 $ ] , @xmath658 then it follows from the taylor expansion and the fact that @xmath638 that @xmath659 where @xmath180 is some value in @xmath642 and @xmath660 where @xmath661 are some values satisfying @xmath662 and @xmath663 .",
    "observe that , by a change of variable , @xmath664 then ( [ varv21 ] ) together with ( [ varv5 ] ) , ( [ varv6 ] ) , ( [ varv7 ] ) entails that @xmath665 observe that , since @xmath77 , @xmath666}^{+\\infty}l^{4h(t_0)-4q}+\\frac{1}{card(\\nu_{t_0,2^j})}\\sum_{|l|\\in\\nu_{t_0,2^j},l\\neq0}|l|^{4h(t_0)-4q+1}\\big).\\nonumber\\\\\\end{aligned}\\ ] ] on one hand , we recall that if @xmath23 is a monotonic decreasing function and the series @xmath667 is convergent , then for @xmath668 , @xmath669 it yields @xmath670}^{+\\infty}l^{4h(t_0)-4q}&=&\\mathcal o\\big(\\int_{[2^j\\epsilon_j]}^{+\\infty}x^{4h(t_0)-4q}{\\,\\mathrm{d } } x+ ( 2^j\\epsilon_j)^{4h(t_0)-4q}\\big)\\nonumber\\\\ & = & \\mathcal o\\big((2^j\\epsilon_j)^{4h(t_0)-4q+1}\\big).\\end{aligned}\\ ] ] on the other hand , since @xmath671 , then it is easy to see @xmath672 finally , @xmath673 it follows by ( [ varv8 ] ) and ( [ varv10 ] ) that @xmath674 we thus can conclude @xmath675 where @xmath676 is a constant only depending on @xmath27 .",
    "proposition [ varvx ] has been proven .",
    "@xmath184              ayache a , shieh n r , xiao y ( 2011 ) multiparameter multifractional brownian motion : local nondeterminism and joint continuity of the local times .",
    "h. poincar probab .",
    "47 ( 4 ) : 1029 - 1054          barrire o ( 2007 ) synthse et estimation de mouvements browniens multifractionnaires et autres processus  rgularit prescrite : dfinition du processus autorgul multifractionnaire et applications .",
    "dissertation , ecole centrale de nantes                          delbeke l , van a w ( 1995 ) a wavelet based estimator for the parameter of self - similarity of fractional brownian motion .",
    "proceedings of the 3rd international conference on approximation and optimization in the caribbean , 14 pp .",
    "( electronic ) , benemrita univ . autn ."
  ],
  "abstract_text": [
    "<S> we propose a wavelet - based approach to construct consistent estimators of the pointwise hlder exponent of a multifractional brownian motion , in the case where this underlying process is not directly observed . </S>",
    "<S> the relative merits of our estimator are discussed , and we introduce an application to the problem of estimating the functional parameter of a nonlinear model . + * * keywords : * * pointwise hlder exponent ; multifractional process ; wavelet coefficients ; parametric estimation </S>"
  ]
}