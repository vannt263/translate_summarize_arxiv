{
  "article_text": [
    "assessing string similarity ( or , as commonly referred in the literature , `` field similarity '' ) , is a recurrent problem in computer science , particularly when dealing with natural language and genetic data .",
    "a review of relevant literature on the topic is presented by yang _",
    "@xcite , which stresses the importance of these methods in applications such as data searching and cleansing , web searching , computational biology , and data compression .",
    "these areas of research were considered by the authors before introducing their method for field comparison , the moving contracting window pattern algorithm ( mcwpa ) .",
    "mcwpa is fundamentally different from the general methods for field comparison based in measures of `` edit distance '' ( such as the one proposed by wagner _ et _",
    "fischer , @xcite ) , which expand initial work by vladimir levenshtein @xcite .",
    "these methods , commonly referred to under the single label of `` levenshtein distance '' , are generally defined as counts of the minimum number of single character `` edits '' required to mutate a field @xmath0 into a field @xmath1 , where `` edit '' is defined as either an insertion , a deletion , or a substitution of a single character ; in general , no difference in weight for the various types of `` edit '' is specified .",
    "the method for this computation of field similarity is closely related to pairwise field alignment and usually implemented after the aforementioned wagner - fischer algorithm or through dynamic programming approaches such as the one proposed by guseld @xcite .",
    "the algorithm proposed by yang",
    "_ et al . _",
    "extends and generalizes an alternative `` token  based '' approach by lee _",
    "@xcite , developed in the context of data cleansing . in their paper , the authors present a pseudo - code for the algorithm , claiming that their solution `` not only achieve[s ] higher accuracy but also gain[s ] the time complexity o(knm ) ( k @xmath2 0.75 ) for worst case '' , comparing the accuracy of their proposal with the one of the method by lee _",
    "et al . _ and concluding that `` [ t]heoretical analysis , concrete examples and experimental result show that [ the proposed ] algorithms can significantly improve the accuracy and time complexity of the calculation of field similarity '' .",
    "in the course of a research conducted around 2005 with extensive usage of the natural language toolkit ( nltk ) , a python library and framework for natural language processing by bird _ et al . _",
    "@xcite , the author of the current paper needed to perform hundreds of field comparisons for sorting lists of fields according to their similarity to a number of reference field , usually short strings containing natural language data .",
    "levenshtein distance , the most recommended method , proved slow when computed without dynamic methods and , more importantly , was found to be unsuitable for a considerable number of cases , as its scores of similarity , adjusted to ratios between @xmath3 and @xmath4 , failed to match the magnitude of similarity that most speakers of the natural languages in study would expect or report .",
    "a theoretical investigation suggested that the obstacle was an intrinsic limitation of the algorithm itself given by its focus in general field comparison ( i.e. , with no _ a priori _ assumptions on the entropy of both fields ) , and was triggered by idiosyncrasies of the morphology and the orthography of the languages in analysis . while the difficulties could in part be circumvented with a combination of orthographic , phonological and , exceptionally , morphological mappings , the decision rested in adopting new methods .",
    "a bibliographic research suggested the paper by yang _",
    "et al . _ , and , while for our purposes the new algorithm performed better than the edit distance method , its results were occasionally unexpected and , eventually , worse than levenshtein distance for some corner cases .",
    "the author wrote a revised version that partially solved the deviations , and the python module which implemented them was eventually included among the `` contributions '' to nltk .",
    "when needing to perform a similar task almost a decade after that first revision , the author decided to write a new version which fully and correctly implemented the revised method , presenting the algorithm and its implementation in this paper .",
    "a brief but throughly description of the `` token - based '' approach for the computation of field similarity proposed by lee _",
    "is given in the second section of yang _",
    "et al . _ ,",
    "from which the outline of the current section is developed .",
    "let a field @xmath5 of length @xmath6 be composed of tokens ( such as `` words '' ) @xmath7 , @xmath8 , @xmath9 , @xmath10 and the corresponding field @xmath11 of length @xmath12 be composed of tokens @xmath13 , @xmath14 , @xmath9 , @xmath15 .",
    "each token @xmath16 , where @xmath17 , is compared with each token @xmath18 , where @xmath19 .",
    "let @xmath20 , @xmath21 , @xmath22 , @xmath23 , @xmath24 , @xmath25 , @xmath22 , @xmath26 be the maximum degree of similarity for tokens @xmath27 , @xmath28 , @xmath9 , @xmath29 , @xmath30 , @xmath31 , @xmath9 , @xmath32 , respectively . the field similarity between @xmath0 and @xmath1",
    "is computed as follows :    @xmath33    the algorithm proposed by yang _",
    "_ generalizes the `` tokens '' employed by lee _",
    "et al . _ ,",
    "essentially words in natural languages , into `` window patterns '' , which are defined as subfields of minimal length equal to @xmath34 . as in the first example given in their paper , for the string ` abcde ` , considering a window of size @xmath35 sliding from left to right , the series of patterns obtained is composed of ` abc ` , ` bcd ` , and ` cde ` . the field similarity in mcwpa",
    "is given by the sum of the squares of the number of the same characters , or minimal units , between fields @xmath0 and @xmath1 , which is defined as the cumulative sum of the square of combined length of minimal units matched in both fields , i.e. twice the length of the pattern ; the sum is accumulated while marking already matched subfields as inaccessible for further comparisons .    thus , in mcwpa , let a field @xmath0 of @xmath6 characters and a field @xmath1 of @xmath12 characters ; the field similarity between the two fields , which `` approximately reflects the ratio of the total number of the common characters in two fields to the total number of characters in two fields '' , where ssnc represents the sum of the square of the number of same characters between @xmath0 and @xmath1 , is computed as follows :    @xmath36    the algorithm is described in depth by yang _",
    "et al . _ , with a number of examples and graphical representations of the inner workings of the sliding window approach .",
    "the author of the current paper first implemented the mcwpa algorithm in python following the pseudo - code given in figure 1 in yang _",
    "et al._. while the authors did not offer actual code or reference values to test implementations of theirs algorithms , all the examples could be matched , suggesting that the implementation was correct .",
    "when testing the implementation in production code , however , it was verified that for some corner cases the results returned were unsuitable , with scores generally higher than what was expected by human reviewers .",
    "the author also experimented with some random strings used in imitation of genetic data , generated by an _",
    "ad hoc _ weighted random function according to a table of dna codon frequencies for the human genome ; for a restricted number of test samples the results were considered equally unsatisfactory .",
    "an investigation of the algorithm did not prove sufficient for identifying any theoretical limit as a source for the unsatisfactory scores .",
    "after implementing the algorithm in multiple and different ways , by a trial and error methodology an hypothesis was developed that the problem resided in a simplification of the original implementation , which can be found in the pseudo - code itself and might have been intentional , as mcwpa is less computationally expansive than the revised method here proposed and the limitation affected a small number of cases .    in detail , while the theoretical description of the paper and the pseudo - code correctly call for marking characters in @xmath0 and @xmath1 as `` inaccessible '' after a given pattern matching , the implementation was apparently not marking inaccessible characters as a boundary for future pattern matchings , thus allowing new windows to `` jump over them '' .",
    "the limitation might have been introduced when adapting the method from a token based to a character based approach , as the implementation in lee _",
    "et al . _ does nt seem to allow non contiguous tokens to be matched .",
    "this hypothesis can not be verified without access to the original source code .    to illustrate the difference of the algorithm here proposed , the implementation yielding results considered wrong would , when matching the strings ` a123b ` and ` 123ab ` , first match the pattern of characters ` 123 ` , but after the deletion of this pattern in both fields it would not treat the residual characters as groups of non - overlapping and non - contiguous subfields ( ` a ` and ` b ` for the first field , `` and ` ab ` for the second ) , but as two identical ` ab ` strings .",
    "when reducing the length of the window from @xmath35 to @xmath37 , the implementation would incorrectly find a match of a substring of length @xmath37 , when , from the theoretical stand point of the algorithm , it would be supposed to identify two different matches of length @xmath34 , with a lower final score .",
    "the python implementation presented in the following section solves this problem by replacing the operation of string concatenation of the first version by operations on lists , introducing the concept of `` sub - fields '' , i.e. , non - overlapping and non - contiguous factors resulting after the removal of a specific factor ( the pattern being matched ) from a starting field or subfields . when the algorithm matches a pattern , it returns two subfields , i.e. , the characters that precede and the characters that follow the matched pattern , if any .",
    "as the subfields might be empty , when the match includes the first or the last character in the string , a check is performed to filter out such empty subfields from the list of subfields .",
    "as stated , the distortion was only found in corner cases , and actual scores were higher than the expect only to a reduced limit .",
    "however , as bibliographical research did not find any mention or correction to yang _",
    "_ , even though their paper has a considerable number of citations , the author found it useful to publish this corrected implementation under the name of mmcwpa ( modified moving contracting window pattern algorithm ) .",
    "the author wishes to publicity note that his implementation distributed with old versions of nltk at the time of writing is still affected by the problem describe above , and should be replaced whenever possible by the one presented here .",
    "a stand - alone python implementation for the algorithm is presented in this section . as per the terms of the `` mit license '' ,",
    "permission is hereby granted , free of charge , to any person obtaining a copy of this software and associated documentation files ( the `` software '' ) , to deal in the software without restriction , including without limitation the rights to use , copy , modify , merge , publish , distribute , sublicense , and/or sell copies of the software , and to permit persons to whom the software is furnished to do so , subject to the following conditions :    * the above copyright notice and this permission notice shall be included in all copies or substantial portions of the software . *",
    "the software is provided `` as is '' , without warranty of any kind , express or implied , including but not limited to the warranties of merchantability , fitness for a particular purpose and noninfringement . in no event",
    "shall the author be liable for any claim , damages or other liability , whether in an action of contract , tort or otherwise , arising from , out of or in connection with the software or the use or other dealings in the software .",
    "table 1 provides some reference scores as returned by the python implementation given in the previous section . besides some new examples , we reproduce all the string comparison employed by yang _",
    "_ when presenting the mcwpa .",
    ".evaluation for mmcwpa [ cols=\"<,<,<\",options=\"header \" , ]",
    "this paper presented a new algorithm , modified moving contracting window pattern algorithm ( mmcwpa ) for the calculation of field similarity , strongly relying on previous work by yang _",
    "( which are in no way associated with this work ) . as for mcwpa ,",
    "theoretical analysis , concrete examples , and experimental results indicate that mmcwpa improves the accuracy and efficiency of the calculation of field similarity and should be considered alongside with other field metrics , particularly when dealing with short strings representing natural language .",
    "m.  l.  lee , h.  lu , t.  w.  ling , and y.  t.  ko , `` cleansing data for mining and warehousing '' , in proceedings of the 10^th^ international conference on database and expert systems applications ( dexa99 ) , pages 751760 , august 1999 ."
  ],
  "abstract_text": [
    "<S> this paper presents a new algorithm , the modified moving contracting window pattern algorithm ( cmcwpm ) , for the calculation of field similarity . </S>",
    "<S> it strongly relies on previous work by yang _ </S>",
    "<S> et al . _ </S>",
    "<S> ( 2001 ) , correcting previous work in which characters marked as inaccessible for further pattern matching were not treated as boundaries between subfields , occasionally leading to higher than expected scores of field similarity . </S>",
    "<S> a reference python implementation is provided . + </S>",
    "<S> * keywords * : field similarity , string similarity , string comparison . </S>"
  ]
}