{
  "article_text": [
    "the rate of scientific discovery in astronomy has traditionally been tied to the amount of data available .",
    "the advent of digital astronomy with modern detectors and computational resources , e.g. , databases , has changed this . although more data in the past two decades has allowed us to discover the cosmic web , dark energy , and exoplanets , the vast majority of such low - hanging fruit have now been found .",
    "the new challenge is growing data complexity .",
    "the era of data - intensive astronomy promises a vastly more thorough exploration of parameter space but the discovery of new scientifically significant relationships is equally more complicated and daunting when faced with overwhelming data dimensions and volumes .",
    "given a highly complex data set , such as sdss , with hundreds of parameters for each object , and sufficient numbers of objects - hundreds of millions or more - to provide a fair and representative covering of parameter space , one will uncover many significant relationships - linear , nonlinear , functional , structural - between pairs , triplets and groups of parameters .",
    "however , only a small fraction of these will be truly causative , the result of some valid underlying astrophysical process or processes , and identifying these is non - trivial .",
    "in fact , @xcite have shown that identifying the underlying dynamical equations from any amount of experimental data , however precise , is a provably computationally hard ( np - hard ) problem .",
    "the framework of astroinformatics , combining astronomy , applied computer science and information technology , has arisen to contend with this computational intractability . at its core",
    "are sophisticated data mining and multivariate statistical techniques which seek to extract and refine information from highly complex data sets ( see @xcite for an overall review of different techniques in astronomy , @xcite for those specific to the time domain and the ivoa kddig web pages for general material related to this ) .",
    "this includes identifying unique or unusual classes of objects , estimating correlations , and computing the statistical significance of a fit to a model in the presence of missing or bounded data , i.e. , with lower or upper limits , as well as visualizing this information in a useful and meaningful manner .",
    "however , the nature of these methodologies is , at best , semi - automated with focused application in particular regions of discovery space rather than allowing an unbounded exploration of what might be there .    in recent years",
    "a number of approaches have been presented in the general scientific literature that seek to redress this , e.g. , @xcite , @xcite , @xcite , @xcite .",
    "discovery - based science employs cutting edge data mining techniques for automated hypothesis forming and automated theorem proving .",
    "many of these tend to have originated within the context of systems biology ( out of association analysis ) where researchers are attempting to identify and derive universal relationships in biological systems akin to those which seem to exist in physical ones , although there is prior art in computer science , particularly within the area of genetic programming ( @xcite ) .",
    "these methods are also similar in scope to various feature selection and extraction and dimensional reduction techniques , such as principal component analysis ( e.g. , @xcite ) and self - organizing maps ( @xcite ) , which attempt to counter the `` curse of dimensionality '' by reducing high dimensional data to lower more manageable dimensions whilst preserving meaningful structures within them .",
    "nonetheless these so - called automated discovery methods are applicable to any general data set and especially to those with many variables , such as arise in economics , climate science , sensor networks or any field advocating an informatics - based approach .    in this work",
    ", we describe the application of automated discovery systems of relationships to astronomical data .",
    "we have focused in particular on two types of approach - those that seek to identify general connections ( correlations ) between particular parameters in a data set and those that try to formulate a specific functional relationship between parameters .",
    "these may be considered representative of the type of mapping of discovery space that has so far been attempted .",
    "a common complaint of data mining techniques is that they usually follow a `` black box '' approach - the data goes in and the answer comes out but there is no real understanding of how one led to the other .",
    "we hope to show that automated discovery systems are also more translucent if not actually transparent and allow some deconstruction of the methodology to understand what is going on inside .",
    "this is particularly important if their discoveries are to be scientifically validated , i.e. , a particular relationship is not only statistically significant but also stems from a ( new ) non - trivial underlying cause .",
    "it should be noted that although these discovery tools are labelled as automated , they are actually employed as part of a collaborative human - machine discovery process . in data - intensive problems , not only is data processing and analysis automated but also necessarily , given the data volumes and dimensions , the first levels of data interpretation .",
    "the human expert now validates machine - generated hypotheses rather than attempting to formulate them themselves .",
    "we still make discoveries , but as the complexity of data increases , we need machine intelligence to help us guide towards an insight .",
    "this paper is structured as follows : in section 2 , we will describe the two specific techniques we are applying whilst in section 3 , we will present a number of different astronomical contexts in which these have been applied - these both attempt to mimic or recreate past discoveries as well as find new ones .",
    "we will analyze and discuss our results in sections 4 and 5 and present our conclusions in section 6 .",
    "the methods we are applying in this paper will probably be unfamiliar to many astronomers and so , in this section , we will introduce some of the pertinent terminology and formalism related to them .",
    "the maximal information coefficient ( mic ; @xcite ) aims to be the 21st - century equivalent of the pearson correlation coefficient ( @xcite ) but it goes beyond just expressing linear associations and can quantify general associations between variables .",
    "it is based on the mutual information between two random variables , @xmath1 and @xmath2 :    @xmath3    where @xmath4 and @xmath5 are the marginal probability mass functions of @xmath1 and @xmath2 and @xmath6 is the joint probability mass function respectively .",
    "now consider a partitioning of a data set , @xmath7 , of ordered pairs , @xmath8 , into an @xmath9-by-@xmath10 grid , @xmath11 , such that there are @xmath9 bins ( of variable size ) covering @xmath12 and @xmath10 bins ( also of variable size ) spanning @xmath13 respectively .",
    "the probability mass function of a particular grid cell is clearly proportional to the number of data points falling inside that cell and so , for a given @xmath14 , there will be a maximal mutual information .",
    "we can then construct a characteristic matrix @xmath15 whose elements :    @xmath16    are the highest normalized mutual informations achieved by any of the corresponding @xmath9-by-@xmath10 grids .",
    "the maximal information coefficient is then defined to be the maximum value in @xmath17 , such that @xmath18 where @xmath19 is a function of the sample size and represents the maximal grid size considered . too high a value for @xmath19 can lead to non - zero scores even for random data because each data point gets its own cell , while setting it too low means that only simple patterns are considered .",
    "@xcite found empirically that @xmath20 provides a satisfactory limit :    @xmath21    the behaviour of mic is that it tends to 1 for all never - constant noiseless functional relationships and to 0 for statistically independent variables .",
    "moreover , mic - @xmath22 , where @xmath23 is the pearson correlation coefficient , is an indicator of a nonlinear relationship between two variables : as @xmath23 is a measure of linear dependence , the statistic mic - @xmath22 , is near to 0 for linear relationships and large for nonlinear relationships with high values of mic .",
    "other measures involving mic and m ( the characteristic matrix ) can also indicate deviations from monotonicity , the degree to which the data set appears to be sampled from a continuous function and the complexity of the association , as different relationship types give rise to characteristic matrices with different properties .",
    "the statistical significance of a mic value can be determined from comparison of a real value against a set of values from @xmath24 surrogate data sets where @xmath25 is the probability of false rejection .",
    "because mic is a rank - order statistic , the uncorrected p - value ( essentially the one - tailed p - value for this statistic ; when multiple hypotheses ( many parameters ) are being tested , a corrected value must be used to mitigate false positives ) of a given mic score under a null hypothesis of statistical independence depends only on the score and on the sample size of the relationship in question and not on the specific relationship being tested .",
    "precomputed uncorrected p - values are available for different sample sizes .",
    "to illustrate this statistic , consider a data set of 100 points randomly selected from a cubic relationship ( @xmath26 , @xmath27 $ ] ) plus a unitary gaussian noise term , i.e. , a gaussian about the @xmath10-value with @xmath28 .",
    "we can partition this data set into a set of @xmath29 grids ( the maximum grid size is set to @xmath30 for this data ) of variable size ( see fig .",
    "[ micexample ] ) .",
    "each grid has a mutual information associated with it and for a given partition configuration , e.g. , @xmath29 , there will be a maximal mutual information .",
    "the maximal ( normalized ) mutual information across all configurations ( 44 in this case ) is the maximal information coefficient .",
    "this data set has a statistically significant mic of 0.836 compared to a linear regression coefficient of just 0.068 .",
    "it also has high values for the measures indicating nonlinearity ( 0.831 ) and functionality ( 0.836 ) and moderate non - monotonicity ( 0.427 ) .",
    "grid partitions of a data set of 100 points randomly selected from a cubic relationship .",
    "the mutual information for each grid is : solid line : 0.059 , dashed line : 0.044 and dotted line : 0.023 respectively .",
    ", width=336 ]      symbolic regression is the task of finding a function , in symbolic form , that fits a finite sample of data .",
    "the most efficient approach employs a genetic algorithm - based search ( @xcite ) of the space of mathematical expressions to determine the best - fitting functional form .",
    "successive generations of formulae are specified in terms of a ( user - defined ) mathematical alphabet of atomic building blocks , such as algebraic and boolean operators , analytical function types - trigonometric , exponential / logarithmic , power laws , etc . , and state variables , which keeps the search tenable .",
    "its advantage over more standard regression methods is that the search process works simultaneously on both the model specification problem ( the form of the fitting equation ) and the problem of fitting coefficients .",
    "eureqa ( now also called formulize ) ( @xcite ) is a software tool which employs symbolic regression to describe a data set by identifying the simplest mathematical formulae which could describe the underlying mechanisms that produced the data .",
    "the tool works from the numerical partial derivatives of each pair of variables in the input data set and uses an evolutionary algorithm to explore this partial differential metric space for non - trivial invariant quantities , looking for predicted partial derivatives that best match the numerical ones :    @xmath31    where @xmath32 is one of the candidate functions .",
    "the search continues until some stopping criterion ",
    "time elapsed , goodness - of - fit , confidence of fit ( maturity and stability ) , etc .",
    "the output is then an ordered list of final candidate analytical expressions on the accuracy - parsimony pareto front , i.e. , the tradeoff between the most optimal ( best - fitting according to some criteria ) and complexity .",
    "each mathematical operation in an expression has a numerical value ( cost ) associated with it , e.g. , addition = 1 , exponentiation = 4 , and the complexity of a formula is defined here as the sum of these values .",
    "a high - order polynomial could therefore be more complex than a straightforward exponential or trigonometric function",
    ".    when comparing and optimizing solutions , eureqa employs a user - defined error metric .",
    "a number of different measures are available and the nature of the data can help determine which is the most appropriate , for example , minimizing the mean of the squared residual errors is suitable for normally distributed noise whereas the logarithmic error is better for many outliers .",
    "data can also be weighted according to some prescription , although the importance of particular variables can always be explicitly stressed in the definition of the equation form being searched for .",
    "there are , too , various types of data preprocessing operations available , familiar to data mining , such as normalization , outlier rejection and missing value handling .",
    "the results of symbolic regression , i.e. , the expressions identified by eureqa , are the best ( non - trivial ) mathematical descriptions of the data .",
    "their interpretation and physical validity , however , remain an exercise for the human expert , who may take them at face value or decide to cross check them ( `` prove them '' ) using other techniques .",
    "in this section , we report on a number of automated discovery experiments we have carried out with different representative astronomical data sets .",
    "a number of different options are available , depending exactly on how you want to measure the whole process .",
    "it should be noted that in applying our techniques , we are not simply fitting a set of formulae to data but that the respective discovery methods decide which variables to use and in what functional relationship and then find the optimal coefficients and measures of fit .",
    "the two methods are also sufficiently different that it is interesting to compare their findings relative to each other .",
    "the hertzsprung - russell ( hr ) diagram is the quintessential representation of physical relationships associated with different stages of stellar evolution .",
    "the original plot of magnitude vs. temperature can be considered as the two - dimensional pdf , @xmath33 ; more modern versions also incorporate metallicty and surface gravity giving a four - dimensional pdf , @xmath34 , \\log g)$ ] - which constrains all of its arguments .",
    "the parameterization of these relationships in terms of observable and non - observable stellar quantities expressed as a function of the observable color is an open problem in astronomy , e.g. , @xcite , @xcite .",
    "this is particularly relevant for the next generation of large photometric surveys , e.g. , lsst , where spectroscopy of every source is not feasible .",
    "note that @xcite describe a related problem of inferring the astrophysical parameters of stars from gaia spectrophotometry .",
    "unfortunately , prior to the availability of the gaia data , there is no single large stellar data set which offers both accurate distances and physical parameters for a representative sampling of the hr space .",
    "hipparcos has reliable distances but no intrinsic parameters , such as @xmath35 or @xmath36 $ ] .",
    "( @xcite ) and segue ( @xcite ) both offer spectroscopically - determined parameters ( @xmath37 $ ] ) but lack distance information ",
    "rave dr3 shares only 685 objects with hipparcos and segue none .",
    "a photometric parallax relationship has been defined for segue based on stellar metallicity and color ( @xcite ) but the corresponding hr diagram shows only a main sequence ( see fig .",
    "[ seguehr ] ) . for a relatively complete coverage of the parameter space",
    ", we have therefore constructed a data set consisting of all stars in simbad with a quoted parallax , effective temperature ( @xmath35 ) , surface gravity ( @xmath38 ) , and metallicity @xmath36 $ ] ) .",
    "[ fig1 ] shows the hr diagram for this data set of 3865 stars .    as a comparison",
    ", we have also considered the distribution of parameters for stars from a single globular cluster .",
    "47 tuc is one of the most studied globular clusters : it is comparatively near , one of the more massive ( and hence populous ) clusters , and it is relatively metal rich . @xcite give stellar parameters for 1992 stars in 47 tuc but only @xmath39 and @xmath40 magnitudes .",
    "however , @xcite have measured @xmath2 , @xmath39 , and @xmath40 for @xmath41 stars in 47 tuc , giving us a final data set of 1739 stars with stellar parameters : @xmath42 $ ] ( uncalibrated metallicity ) , @xmath43 , \\xi$ ] ( microturbulence ) and @xmath44 ( rotational velocity ) and @xmath2 and @xmath39 magnitudes ( see fig .",
    "[ 47tuchr ] for its hr diagram ) .                        in the second ( 47 tuc ) .",
    "although these formulations are based on prior knowledge of what the dependent variables are and also what data is available , symbolic regression incorporates feature selection and so will only use a subset of the most relevant variables , in this case those which persist in successive generations of calculations in the evolutionary algorithm , rather than all available variables ( see section  3.3 for an explicit demonstration of this ) .",
    "we also consider the choice of variables more in section  4 .",
    "we use a set of mathematical building blocks restricted to : constants , basic operators ( + , - , * , / ) , exp ( ) , log ( ) , x@xmath47 .",
    "we employed an r@xmath48 goodness - of - fit error metric - eureqa attempts to maximize this quantity in its fits - and selected an 80:20 split of the data in terms of test set and validation set .",
    "data with any missing values were ignored ( other options are available ) and no weighting was used for any parameter in terms of its error as the heterogeneity of the data means that not every value has an error associated with it .",
    "27 cpu - hour runs ( taking 1.5 hours on 18 cores ) produced a number of formulae of varying complexity and correlation coefficients of around 0.85 red for both data sets ( see table  [ table1 ] ) .",
    "we also ran it for the simbad data set restricting the formulae to just power law expressions ( no exp ( ) or log ( ) operators ) .",
    "we shall consider the results obtained for the simbad data set first .",
    "to validate the results and test against overfitting , i.e. , the formulae are actually describing random errors or noise in the data instead of any underlying relationship , we determined the median absolute error for each formula when applied to the rave dr3 and segue data sets mentioned above .",
    "johnson b and v magnitudes were derived from the segue data using the transformation equations of @xcite and an absolute v magnitude determined using the inferred parallax relating apparent r magnitude and absolute r magnitude calculated using the photometric parallax method of @xcite .",
    "any systematic errors that these transformations may introduce can be estimated from a plot of @xmath49 vs. @xmath35 for the segue data compared to the simbad data .",
    "since @xmath35 is calculated spectroscopically , any photometric offset will show in the relative positions of the main sequences of the two data sets .    the left plot in fig .",
    "[ mvteff ] shows good agreement between the simbad and rave dr3 data sets with an offset of the segue data relative to the other two .",
    "this offset can be estimated from the difference between linear fits to the main sequences of both simbad and segue data sets defined between the regions of @xmath50 and @xmath51 and we find a value of @xmath52 for segue .",
    "a similar procedure can be performed with plots of @xmath53 vs. @xmath35 to estimate any systematic errors in the color and we find a value of @xmath54 for segue . the right plot in fig .",
    "[ mvteff ] shows the agreement between the three data sets when the offsets have been applied .",
    "table  [ table1 ] gives the median absolute difference ( mad ) between the `` measured '' absolute magnitude and the estimated value for each formula when applied to the simbad , segue and rave data sets .",
    "for comparison , we also computed the mad between the observed data and the values derived from the semi - analytical formulae of @xcite relating @xmath49 and @xmath53 for each data set ( note that zaninetti s other formulae relating mass , radius and luminosity to @xmath53 all derive from these ) , although those are only defined over the range @xmath55 and are stellar luminosity class dependent , with separate relationships for main sequence , giant , supergiant and white dwarf stars .",
    "it is worth bearing in mind when looking at these results that the various functional relationships that this approach finds are , in some statistical sense , the optimal descriptors of the data - they are phenomenological . their physical interpretation , however , remains the purview of the human scientist .",
    "this method aims to identify all potentially interesting , significant relationships without any preconceived bias , e.g. , due to some established notion of what should actually be there .",
    "the results for the simbad and segue data sets are broadly consistent suggesting that the found formulae provide a good description of the variable relationships in the data but do not overfit it",
    ". it should be not surprising that the zaninetti formulae give better results for the segue data set since it essentially just consists of a main sequence and uses that class specific result .",
    "the eureqa results are derived for a range of luminosity types and so give a better broader fit but not necessarily for specific luminosity classes .",
    "the poor performance on the rave dr3 data set can be largely attributed to the errors on the parallax value ( the mean value is 7.63 mas with a mean error of 1.91 mas ) and thus the absolute magnitude ( 54% of the objects have @xmath56 ) .",
    "if we restrict the analysis to those stars with @xmath57 , we find that the mad values drop to @xmath58 for the eureqa formulae and @xmath59 for the zaninetti formula ."
  ],
  "abstract_text": [
    "<S> high - volume feature - rich data sets are becoming the bread - and - butter of @xmath0 century astronomy but present significant challenges to scientific discovery . </S>",
    "<S> in particular , identifying scientifically significant relationships between sets of parameters is non - trivial . </S>",
    "<S> similar problems in biological and geosciences have led to the development of systems which can explore large parameter spaces and identify potentially interesting sets of associations . in this paper </S>",
    "<S> , we describe the application of automated discovery systems of relationships to astronomical data sets , focussing on an evolutionary programming technique and an information - theory technique . </S>",
    "<S> we demonstrate their use with classical astronomical relationships - the hertzsprung - russell diagram and the fundamental plane of elliptical galaxies . </S>",
    "<S> we also show how they work with the issue of binary classification which is relevant to the next generation of large synoptic sky surveys , such as lsst . </S>",
    "<S> we find that comparable results to more familiar techniques , such as decision trees , are achievable . finally , we consider the reality of the relationships discovered and how this can be used for feature selection and extraction .    [ firstpage ]    </S>",
    "<S> methods : data analysis  </S>",
    "<S> astronomical data bases : miscellaneous  virtual observatory tools </S>"
  ]
}