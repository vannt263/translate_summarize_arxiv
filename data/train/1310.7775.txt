{
  "article_text": [
    "in a recent article @xcite , the authors studied complex gaussian multiplicative chaos , a complex extension of classical gaussian multiplicative chaos ( see @xcite for a review on gaussian multiplicative chaos ) .",
    "more precisely , consider two independent and logarithmically correlated gaussian fields @xmath0 on a subdomain @xmath1 @xmath2 = { \\mathds{e}}[y(x)y(y ) ] \\underset{|y - x| \\to 0}{\\sim }   \\ln \\frac{1}{|y - x|}.\\ ] ] we denote @xmath3 the space of smooth functions with compact support in @xmath4 and @xmath3 the space of distributions ( in the sense of schwartz ) .",
    "they adressed the problem of finding a proper renormalization as well as the limit of the family of complex random distributions @xmath5 where @xmath6 are appropriate regularizations ( say of variance of order @xmath7 ) which converge to @xmath0 and @xmath8 are real constants . in this",
    "setting , they recovered the phase diagram of figure [ diagram ] which was first discovered in the pioneering work @xcite in the simpler context of discrete multiplicative cascades , i.e. when @xmath9 are independent branching random walks on a tree - like structure .",
    "more precisely , the authors of @xcite computed the free energy of the total mass ( or partition function ) @xmath10 for a subset @xmath4 and found phase transitions according to a diagram similar to our figure [ diagram ] . in particular , they distinguished three phases i , ii and iii which we have indicated on the figure . the work @xcite is a step further in understanding the limit of .",
    "indeed , the framework of @xcite is that of finding a deterministic sequence @xmath11 such that @xmath12 converges to a non trivial limit in the space of distributions ( see also the interesting and related works @xcite ) . in a series of works",
    "@xcite , this question was essentially solved for the phases i and iii ( and their frontiers ) but left unanswered in phase ii .",
    "however , it was conjectured that in phase ii , the behaviour of @xmath13 is mainly ruled by two phenomena : the local intensity of this complex measure is dominated by the local maxima of the field @xmath14 whereas the overall phase resulting from the ( strong ) windings of the field @xmath15 asymptotically behaves like a white noise .",
    "this led to the following freezing conjecture corresponding to the so - called glassy phase ( the freezing and glassy phase terminology comes from physics , see @xcite for example ) :    [ conjii ] let @xmath16 and @xmath17 be such that @xmath18 .",
    "set @xmath19 .",
    "there exists some constant @xmath20 such that we get the following convergence in law : @xmath21 where , conditionally on @xmath22 , @xmath23 is a complex gaussian random measure with intensity @xmath24 and @xmath22 is a @xmath25-stable random measure with intensity @xmath26 , namely a random distribution whose law is characterized by @xmath27={\\mathds{e}}[e^{-q^{2\\alpha } m'(a)}]$ ] for every @xmath28 and every bounded borelian set @xmath29 .",
    "let us finally mention that a result similar to is proved in the paper @xcite in the real case , i.e. on the frontier of phase ii hence for @xmath30 and @xmath31 ( see also @xcite for related results ) .",
    "analogous results in the real case were also derived recently for the branching random walk in @xcite . recall that in the context of the real branching random walk , these problems have received much attention since the works @xcite .",
    "the purpose of this work is to prove the analogue of conjecture in the context of the simpler but related model , the so - called branching brownian motion ( bbm ) where the approximations @xmath9 are defined by particles which split along a poisson process and then perform independent brownian motions : see the next section for precise definitions .",
    "let us mention that , up to some technical adaptations , it should be possible to prove in the bbm context results analogue to @xcite and in particular to recover a phase diagram similar to figure [ diagram ] .",
    "over the past years , there has been impressive progress on the the study of bbm since the seminal works @xcite : this progess has culminated in the works @xcite . thanks to these achievements , it is possible to know with high precision the behaviour of the extreme particles of the bbm which dominate phase ii .",
    "though our work in the context of bbm relies on the fine results of @xcite , we believe that it gives insights on the mechanism involved behind the conjectured convergence : this will be discussed in more detail in the next section .",
    "the paper is organized as follows . in the next section , we define the setup and cite the main result of the paper namely theorem [ maintheorem ] .",
    "we also include a discussion on related models , like the branching random walk or the logarithmically correlated gaussian fields considered in @xcite .",
    "special emphasis will be given to the case of the maximum of the discrete gaussian free field which has received a lot of attention recently @xcite .",
    "in the following section , we prove theorem [ maintheorem ] .",
    "( 3,0 )  ( 12,0 ) ",
    "( 3,6 ) ; ( 3.5,3.5 ) ",
    "( 12,3.5 ) ",
    "( 12,10 ) ",
    "( 0,7 ) ; ( 5,0 ) arc ( 0:45:5 ) ",
    "( 5,0 ) ; ( 3.53,3.5 )  ( 12,3.5 ) ; ( 3.6,3.5 ) ",
    "( 0,7 ) ; ( 5,0 ) arc ( 0:45:5 ) ; ( 0,0 ) ",
    "( 0,8.2 ) node[left]@xmath32 ; ( 0,0 ) ",
    "( 12.2,0)node[below]@xmath33 ; ( 7,3.5 ) node[above]@xmath34 ; ( 2,5.2 ) node[above , rotate=-45,line width=2pt]@xmath35 ; ( 4.8,1.5 ) node[above , rotate=-70,line width=2pt]@xmath36 ; ( 1,2 ) node[right]phase i ; ( 5,7 ) node[right]phase ii ; ( 7,2 ) node[right]phase iii ;",
    "in this paper , we will study the branching brownian motion ( bbm for short ) . start with a single particle which performs standard brownian motion starting from @xmath37 up to an exponential holding time @xmath38 with parameter @xmath39 . at time @xmath38 , the particle splits into two new particles , both of them following a new independent copy of the same process starting from its place of birth .",
    "both new particles thus move according to a standard brownian motion and split into two after an exponential holding time and so on .",
    "we introduce @xmath40 the associated poisson point process which counts the number of particles at time @xmath41 and @xmath42 the ( increasingly ordered ) positions of the particles .",
    "we then introduce the properly normalized and shifted quantity @xmath43 in order to have : @xmath44 = 1,\\qquad { \\mathds{e}}\\left[\\sum_{i=1}^{n(t ) } x_i(t ) e^{-x_i(t ) } \\right ] = 0,\\qquad \\forall t>0.\\ ] ]    on the same probability space , we consider particles which split according to the * same * poisson point process @xmath40 but follow brownian motions that are independent of those involved in the definition of @xmath45 .",
    "we consider @xmath46 the positions of these new particles .",
    "we introduce the random measure @xmath47 we will also consider the measure @xmath48 which corresponds to the measure @xmath49 conditioned to the event that all particles @xmath50 are above @xmath51 . if @xmath52 is some continuous function , we denote @xmath53 and similarly for @xmath48 .    in order to state our results ,",
    "we introduce the limit of the derivative martingale @xmath26 given by the following limit ( first derived in @xcite ) @xmath54 recall the following classical convergence in law of the minimum obtained in @xcite @xmath55 where @xmath56 is some random variable satisfying @xmath57 and @xmath58 some constant .",
    "we are interested in studying the variable @xmath59 in the so - called phase ii , i.e. @xmath60 and @xmath61 where for a real @xmath62 we set @xmath63 .",
    "to state our main result , we recall that a random variable @xmath64 is a standard complex gaussian random variable if @xmath65 where @xmath66 are two independent standard real gaussian variables .",
    "the following theorem is the main result of the paper :    [ maintheorem ] for @xmath67 in phase ii , there is some constant @xmath68 such that we have the following convergence in law @xmath69 where @xmath64 is a standard complex gaussian random variable independent from @xmath70 which is a @xmath25-stable random variable with intensity @xmath26 and @xmath71 . more precisely , the law of @xmath70 is characterized by @xmath72={\\mathds{e}}[e^{-q^\\alpha m'}].\\ ] ] for all @xmath28 .    in a recent work @xcite",
    ", the authors showed a result similar to in the context of the complex rem , i.e. when the variables @xmath73 form an iid sequence of centered gaussian vectors . in the rem context",
    ", one must replace the renormalization @xmath74 in by @xmath75 and the limiting law is of the same form as the right hand side of with the variable @xmath70 distributed as a standard stable distribution ( whereas , in the bbm context of theorem [ maintheorem ] , the variable @xmath70 is stable conditionally to @xmath26 ) .",
    "note that in our case the result is different because of the strong correlations in the bbm ; in particular , the methods of @xcite which rely on the summation theory of triangular arrays of independent random vectors can not be adapted here .      in this subsection , we start by giving an insight on the proof of theorem [ maintheorem ] which will enable us to discuss other related models : the branching random walk and the discrete gff .",
    "first , introduce the set @xmath76 of local minima of @xmath77 that are close to @xmath78 , i.e. those particles which are at distance of order 1 from @xmath78 and that are smaller than all the particles sharing with them a common ancestor at distance of order 1 . in phase ii ,",
    "the variable [ defvariable ] concentrates on the local minima along with the close neighbours that do not have atypical high values , which constitute the so - called decoration .",
    "therefore , the variable is roughly equal for large @xmath41 to @xmath79 where @xmath80 means that @xmath81 is of order 1 .",
    "now , one can rewrite the above quantity in the following way @xmath82    from the results of @xcite , the sum @xmath83 converges to @xmath84 where @xmath85 is a poisson point process ( ppp ) with intensity @xmath86 where @xmath87 is some constant .",
    "since the local minima are far apart , each sum @xmath88 is asymptotically independent for different values of @xmath89 . from the results of @xcite",
    ", one can also deduce that each term @xmath90 converges in law to some non trivial variable @xmath91 ( which is painful to describe ) .    finally , if @xmath92 is a standard gaussian the variable @xmath93 converges in law as @xmath94 to a random variable uniformly distributed on the unit circle",
    ". hence @xmath95 converges in law to a variable @xmath96 uniformly distributed on the unit circle and independent from @xmath97 . gathering the above considerations , we see that the variable converges to @xmath98 where @xmath99 is an i.i.d",
    ". sequence of * isotropic * random variables . though we do not have a friendly description of the variable @xmath100 , the scaling property of the poisson sequence and the isotropy of @xmath100 yield representation .",
    "in fact , a similar mechanism is behind the freezing phenomenon in the real case @xmath101 ; indeed , in this case , the i.i.d property of the decoration combined to the scaling property of the ppp yield a stable distribution .      in the case of the branching random",
    "walk , it should be possible to prove analogues of @xcite though it certainly requires non trivial technical difficulties to adapt the proofs of @xcite .",
    "therefore , proving a result similar to theorem [ maintheorem ] is clearly within reach ( in the lognormal and even the non lattice case ) .    in the case of the discrete gff ,",
    "the situation is a bit more involved and does not just require technical adaptations : this is due to the fact that the correlations do not involve a hierarchical structure .",
    "consider a discrete gff @xmath14 on a square grid of size @xmath102 in a fixed bounded domain @xmath103 with the normalization @xmath104= 2 \\ln \\frac{1}{\\varepsilon}+2 \\ln c(x , d ) + o(1 ) $ ] where @xmath105 denotes the conformal radius of a point @xmath106 .",
    "fix @xmath107 .",
    "we introduce the set @xmath108 of coordinates of the local maxima of @xmath14 that are in the interval @xmath109\\ ] ] in view of the results of @xcite , it is natural to conjecture that the following convergence in law holds for all @xmath110 @xmath111 } \\label{convconj}\\end{aligned}\\ ] ] where @xmath112 is a poisson point process ( ppp ) with intensity @xmath113 where @xmath26 is the derivative martingale constructed in @xcite , @xmath114 some constant and @xmath115 is an i.i.d .",
    "sequence of couples of point processes that are independent from the @xmath85 .",
    "the law of @xmath116 should be isotropic .",
    "recall the remarkable result of @xcite where the authors prove that @xmath117 converges to a ppp with intensity @xmath118\\}}e^{-y } dy$ ] where @xmath119 should coincide with @xmath120 .",
    "nonetheless , in order to adapt our result to this context , one still has to reinforce the conjectured convergence by adding information on the `` decorrelation time '' @xmath102 of two points in the point process @xmath121 .",
    "this is certainly a non trivial issue that requires a fine analysis of the discrete gff .",
    "we first recall the following useful lemma , the so - called many - to - one lemma , which states that for all nonnegative function @xmath122 @xmath123 & = e^t { \\mathds{e } } [ f   ( ( \\sqrt{2}b_s+ 2s)_{0 { \\;\\leqslant\\;}s { \\;\\leqslant\\;}t } ) ] \\\\ & = { \\mathds{e } } [ e^{\\sqrt{2}b_t } f   ( ( \\sqrt{2}b_s)_{0 { \\;\\leqslant\\;}s { \\;\\leqslant\\;}t } ) ] \\label{manytoone}\\end{aligned}\\ ] ] where @xmath124 is a standard brownian motion .      given the technical lemmas of the next subsection , it is not very difficult to conduct the proof . let @xmath122 be some bounded and lipschitz function from @xmath125 to @xmath126 .",
    "we will additionally suppose that @xmath122 is bounded by @xmath127 and @xmath127-lipschitz .",
    "by lemma [ complextension ] , there exists @xmath128 such that @xmath129 and @xmath130 { \\;\\leqslant\\;}c_k\\ ] ]    following @xcite , for @xmath131 , we introduce @xmath132 the set of particles which are the first in their line of descent up to time @xmath41 to hit @xmath133 .",
    "since @xmath134 converges almost surely to infinity as @xmath41 goes to infinity , @xmath132 is constant for @xmath41 ( random ) large enough and equal to a set that we will denote @xmath135 .",
    "observe that @xmath135 is finite almost surely .",
    "for each @xmath136 , we consider the ordered descendants @xmath137 up to time @xmath41 .",
    "then , we have @xmath138 where @xmath139 corresponds to the sum on the @xmath140 which are not descendants of @xmath136 .",
    "since @xmath134 converges almost surely to infinity as @xmath41 goes to infinity , the variable @xmath141 converges almost surely to @xmath37 as @xmath41 goes to infinity .",
    "hence , we just have to study the convergence of @xmath142 $ ] where @xmath143 is defined in equality [ truc ] .",
    "we introduce @xmath144 the splitting times of particles @xmath145 and @xmath146 .",
    "now , we have @xmath147   \\\\ \\nonumber & = { \\mathds{e}}\\left [ f \\left ( \\sum_{u \\in \\mathcal{h}_l(t ) }   t^{\\frac{3 \\gamma}{2 } } e^{-\\gamma x_1^u(t)+i \\sqrt{2 } \\beta \\bar{y}_1^u(t )    }   \\sum_{j=1 , \\ : t-\\tau^u_{j,1}(t)<b}^{n^u(t)}\\1_{\\{x_j^u(t ) { \\;\\leqslant\\;}\\frac{3}{2}\\ln t + k \\ } }   e^{-\\gamma ( x_{j}^u(t)-x_{1}^u(t))+i \\sqrt{2 } \\beta ( \\bar{y}_{j}^u(t)-\\bar{y}_{1}^u(t )   ) } \\right ) \\right ] \\\\",
    "\\label{aborne}&+ b_{t , l , k , b}\\end{aligned}\\ ] ] where the remainder term @xmath148 is such that @xmath149 where @xmath150 is defined by @xmath151 ; \\ :",
    "\\tau^u_{j,1}(t ) { \\;\\leqslant\\;}t - b \\ : \\text{and } \\ :",
    "x_j^u(t ) { \\;\\leqslant\\;}\\frac{3}{2}\\ln t + k     \\rbrace.\\ ] ]    now for all @xmath152 , we have by lemma [ complextensionfinale ] that @xmath153 =   \\\\ \\nonumber &   { \\mathds{e}}\\left [ f \\left ( \\sum_{u \\in \\mathcal{h}_l(t ) }   t^{\\frac{3 \\gamma}{2 } } e^{-\\gamma x_1^u(t)+i \\sqrt{2 } \\beta \\bar{y}_1^u(t )    } \\1_{\\{x_1^u(t ) { \\;\\leqslant\\;}\\frac{3}{2}\\ln t + k \\ } } \\sum_{j=1 , \\ : t-\\tau^u_{j,1}(t)<b}^{n^u(t ) } \\1_{\\{x_j^u(t ) { \\;\\leqslant\\;}\\frac{3}{2}\\ln t + k ' \\ } }   e^{-\\gamma ( x_{j}^u(t)-x_{1}^u(t))+i \\sqrt{2 } \\beta ( \\bar{y}_{j}^u(t)-\\bar{y}_{1}^u(t )   ) } \\right ) \\right ] \\\\",
    "\\label{deuxsansdelta}&+ c_{t , l , k , k',b}\\end{aligned}\\ ] ] where @xmath154 is such that @xmath155 where @xmath156 goes to @xmath37 when @xmath110 goes to infinity .",
    "now , in order to describe the limit , we need to introduce some notations .",
    "we consider @xmath135 as a subset of @xmath157 .",
    "we introduce an i.i.d .",
    "sequence @xmath158 of random variables uniformly distributed on the unit circle and an i.i.d .",
    "sequence @xmath159 of standard brownian motions .",
    "we also consider an i.i.d .",
    "sequence @xmath160 distributed like the backward path @xmath161 of @xcite and the associated poisson jumps @xmath162 .",
    "finally , given @xmath89 and conditionally to @xmath163 , we consider an independent sequence of point processes @xmath164 of distribution that of @xmath165 where @xmath166 and @xmath167 .        where @xmath170 is an i.i.d .",
    "sequence distributed like the asymptotic minimum of the ( shifted ) bbm , i.e. of distribution @xmath56 in , and @xmath171 is an i.i.d . sequence given by @xmath172 the point that does not come out of the results of @xcite is the appearance of the sequence @xmath173 and the sequence @xmath174 .",
    "observe that if @xmath64 is a standard gaussian variable then @xmath175 converges in law as @xmath94 to a random variable uniformly distributed on the unit circle .",
    "we extend this elementary result to the following lemma :    assume that @xmath176 is a sequence of centered @xmath177-valued gaussian random vectors such that @xmath178 \\to \\infty \\text { as } n\\to\\infty.\\ ] ] then the following convergence holds in law as @xmath179 @xmath180 where @xmath181 are independent random variables uniformly distributed on the unit circle .    _ proof .",
    "_ let us consider @xmath182 smooth functions",
    "@xmath183 on the unit circle .",
    "we can write the fourier expansion of the product @xmath184 @xmath185 the sum is absolutely converging .",
    "we deduce @xmath186=\\sum_{p\\in{\\mathbb{z}}^d}c_p { \\mathds{e}}[e^{i < p , x^n>}]\\end{aligned}\\ ] ] the relation @xmath187=e^{-\\frac{1}{2}{\\mathds{e}}[|<p , x^n>|^2]}$ ] and assumption imply that each term in the above sum , except for @xmath188 , converges towards @xmath37 .",
    "the dominated convergence theorem then entails that @xmath189\\to c_0.\\ ] ] the result follows .",
    "since @xmath133 is fixed here , conditionally on the poisson process @xmath190 and the particles @xmath191 , the sequence @xmath192 satisfies the assumptions of the above lemma as they are brownian motions , the increments of which become independent after some time @xmath193 .",
    "hence , since @xmath16 , the sequence @xmath194 converges in law as @xmath195 to an i.i.d .",
    "sequence of random variables uniformly distributed on the unit circle and independent from all the other variables .",
    "[ lemmejusti ] let @xmath196 be a standard brownian motion . for all fixed @xmath197 and @xmath198",
    ", we have the following convergence in law @xmath199 where @xmath200 is uniformly distributed on the circle and @xmath201 is a standard brownian motion independent from @xmath200 .    when @xmath89 is fixed , each term @xmath202 is the sum of @xmath203 and an independent branching part .",
    "hence , conditionally on the poisson process @xmath190 and the particles @xmath191 , we can apply a straightforward variant of lemma [ lemmejusti ] in the limit since @xmath204 is fixed before taking the limit @xmath195 .",
    "now , we wish to take the limit in @xmath205 in . by lemma [ exislimitbis ] and because the set @xmath135 is finite , we have @xmath206= { \\mathds{e}}\\left [   f \\left ( \\sum_{u \\in \\mathcal{h}_l } \\1_{\\{w_{u}+l { \\;\\leqslant\\;}k\\ } } \\ : e^{- \\gamma ( w_{u}+l ) }   u_{u } z^{(u ) }    \\right )   \\right ] \\ ] ] where @xmath91 is an i.i.d . sequence given by ( see lemma [ exislimit ] ) @xmath207    now , we wish to take the limit as @xmath133 goes to infinity . by the results of @xcite",
    ", we get that @xmath208   = { \\mathds{e}}\\left [   f \\left ( \\sum_{u   { \\;\\geqslant\\;}1 } \\1_{\\{\\delta_u { \\;\\leqslant\\;}k\\ } } \\ : e^{- \\gamma \\delta_{u } } u_{u } z^{(u ) }    \\right )   \\right ] , \\end{aligned}\\ ] ] where @xmath85 is a poisson point process of intensity @xmath209 where @xmath26 is the limit of the derivative martingale .    to sum things up",
    ", we have proven that @xmath210-{\\mathds{e}}\\left [   f \\left ( \\sum_{u   { \\;\\geqslant\\;}1 } \\1_{\\{\\delta_u { \\;\\leqslant\\;}k\\ } } \\ : e^{- \\gamma \\delta_{u } } u_{u } z^{(u ) }    \\right )   \\right ]   \\right |   \\nonumber \\\\ & { \\;\\leqslant\\;}\\underset{l \\to \\infty}{\\overline{\\lim } } \\underset{k ' \\to \\infty}{\\overline{\\lim } } \\underset{b \\to \\infty}{\\overline{\\lim}}\\underset{t \\to \\infty}{\\overline{\\lim } } \\left ( c_k+{\\mathds{e}}[|a_{t , l , k}| \\wedge 1]+ |b_{t , l , k , b } | + |c_{t , l , k , k',b}|   \\right ) \\nonumber \\\\ & { \\;\\leqslant\\;}c_k + d_k\\label{yeah}.\\end{aligned}\\ ] ] in fact , the bounds that we have obtained along the proof hold uniformly with respect to the functions @xmath122 that are bounded by @xmath127 and @xmath127-lipschitz .",
    "let @xmath211 denote the space of such functions .",
    "we have thus proved @xmath212-{\\mathds{e}}\\left [   f \\left ( \\sum_{u   { \\;\\geqslant\\;}1 } \\1_{\\{\\delta_u { \\;\\leqslant\\;}k\\ } } \\ : e^{- \\gamma \\delta_{u } } u_{u } z^{(u ) }    \\right )   \\right ]   \\right |   \\nonumber \\\\ & { \\;\\leqslant\\;}c_k + d_k\\label{yeahbis}.\\end{aligned}\\ ] ] now , we conclude by using the following trick . recall that the sequence @xmath213 is tight . indeed , by lemma [ complextension ]",
    ", it suffices to show that for all fixed @xmath110 the sequence @xmath214 is tight .",
    "but this results from the real case @xcite and the bound @xmath215    since the sequence @xmath213 is tight , we can find a sequence @xmath216 going to infinity and such that it converges in law towards a random variable . from this subsequence",
    ", we can extract an increasing subsequence @xmath217 such that for all @xmath110 , we have    @xmath218-{\\mathds{e}}\\left [   f \\left ( \\sum_{u   { \\;\\geqslant\\;}1 } \\1_{\\{\\delta_u { \\;\\leqslant\\;}k\\ } } \\ : e^{- \\gamma \\delta_{u } } u_{u } z^{(u ) }    \\right )   \\right ]   \\right |   \\nonumber \\\\ & { \\;\\leqslant\\;}c_k + d_k + \\frac{1}{k^2}\\label{yeahbis}.\\end{aligned}\\ ] ]    hence , we conclude that @xmath219 converges in law as @xmath110 goes to infinity .",
    "we would like to identify this law .",
    "let @xmath220 .",
    "we denote the scalar product by @xmath221 and @xmath222 expectation with respect to a variable @xmath45 . by isotropy of the uniform law on the unit circle ,",
    "the random variables @xmath223 have the same laws as @xmath224 where @xmath225 is the first component of @xmath96 and @xmath226 is an independent family of i.i.d random variables with law @xmath227 . recalling that @xmath228 is a poisson point process with intensity @xmath229 , we have @xmath230   & =   { \\mathds{e}}_{m ' }   \\left [    e^{c m '    { \\mathds{e}}_{u , z}\\big [    \\int _ { \\{v { \\;\\leqslant\\;}k\\ } } ( e^{i e^{-\\gamma v }    < x , uz > } -1 ) e^{v } dv\\big ] }   \\right ]    \\\\ & = { \\mathds{e}}_{m ' }   \\left [    e^{c m '    { \\mathds{e}}_{u , z,{\\varepsilon}}\\big [    \\int _ { \\{v { \\;\\leqslant\\;}k\\ } } ( e^{i e^{-\\gamma v } |x|   |u^1| |z|{\\varepsilon } } -1 ) e^{v } dv\\big ] }   \\right ]    \\\\ & = { \\mathds{e}}_{m ' } \\left [    e^{c\\frac{m ' } {   2    }    { \\mathds{e}}_{u , z}\\big [    \\int _ { \\{v { \\;\\leqslant\\;}k\\ } } ( e^{i e^{-\\gamma v } |x|",
    "|u^1| |z| } + e^{-i e^{-\\gamma v } |x|",
    "|u^1| |z|}-2 ) e^{v } dv\\big ] }   \\right ]    \\\\ & = { \\mathds{e}}_{m ' } \\left [    e^{- c\\frac{m ' } {    \\gamma } |x|^{1/\\gamma } { \\mathds{e}}_{uz }   \\big [ |u^1z |^{1/\\gamma }   \\int_{\\{w { \\;\\geqslant\\;}e^{-\\gamma k}|x|   |u^1| |z| \\}}(1-\\cos(w ) ) \\frac{du}{w^{1 + \\frac{1}{\\gamma } } } \\big ] }    \\right ]   .\\end{aligned}\\ ] ] then , by the monotone convergence theorem , we have the following convergence @xmath231=c_\\gamma \\ : { \\mathds{e}}_{u , z }   [ |u^1z|^{1/\\gamma } ] .\\ ] ] it is important to observe that the expectation @xmath232 $ ] is necessarily finite , otherwise the family @xmath219 could not converge in law as @xmath233 . in conclusion",
    ", there exists some constant @xmath234 such that for all @xmath62 @xmath235 = { \\mathds{e}}_{m ' } \\left [    e^{- c(\\gamma,\\beta ) m '   |x|^{1/\\gamma } }   \\right ]    .\\ ] ] now , inequality yields that @xmath236 also converges in law as @xmath41 goes to infinity to the variable whose fourier transform is defined by the right hand side of .        in this technical subsection , we do not suppose that the particles are ordered and we will identify the interval @xmath237 $ ] with a random tree . in particular , given two particles @xmath238 , we will denote @xmath239 their splitting time and set @xmath240 to be the node of the random tree where the splitting occurs .",
    "we start with the following lemma which we will need in the next subsection      for simplicity , we suppose @xmath41 is an integer .",
    "we have @xmath246 ^ { 1/ ( 2 \\gamma ) }   \\right )    \\\\ & { \\;\\leqslant\\;}{\\mathds{e}}\\left (   \\left [ \\sum_{l=1}^{t }    e^{-2 \\beta^2 ( t - l ) }      \\sum_{\\tau \\in [ l , l+1]}\\ee^ { -2\\gamma x_{n_\\tau}(\\tau ) } \\sum_{i , j ; \\ : \\tau_{i , j}=\\tau }   e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_\\tau}(\\tau ) ) } \\right   ] ^{1/ ( 2\\gamma ) }   \\right )    \\\\ & { \\;\\leqslant\\;}{\\mathds{e}}\\left [ \\sum_{l=1}^{t }    e^{- \\frac{\\beta^2}{\\gamma } ( t - l ) }      \\sum_{\\tau \\in [ l , l+1 ] } e^ {   { \\green - }   x_{n_\\tau}(\\tau ) } \\left(\\sum_{i , j ; \\ : \\tau_{i , j}=\\tau }   e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_\\tau}(\\tau ) ) } \\right)^{1/ ( 2\\gamma ) }   \\right ]     \\\\\\end{aligned}\\ ] ] we introduce for any @xmath107 , @xmath247 the times of successive branching after @xmath133 .",
    "we have @xmath248 }    e^{-   x_{n_\\tau}(\\tau ) } \\left(\\sum_{i , j ; \\ : \\tau_{i , j}=\\tau }   e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_\\tau}(\\tau ) ) } \\right)^{1/ ( 2\\gamma ) } \\right]\\\\ & = \\sum_{p{\\;\\geqslant\\;}0}{\\mathds{e}}\\left [ e^{- x_{n_{\\sigma_p^{(l)}}}(\\sigma_p^{(l ) } ) }   \\1_{\\ { \\sigma_p^{(l)}{\\;\\leqslant\\;}l+1\\ } }   \\left(\\sum_{i , j ; \\ : \\tau_{i , j}=\\sigma_p^{(l ) } }   e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_{\\sigma_p^{(l)}}}(\\sigma_p^{(l ) } ) ) } \\right)^{1/ ( 2\\gamma ) } \\right ]      \\\\ & { \\;\\leqslant\\;}\\sum_{p{\\;\\geqslant\\;}0}{\\mathds{e}}\\left [ e^ { - x_{n_{\\sigma_p^{(l)}}}(\\sigma_p^{(l ) } ) }   \\1_{\\ { \\sigma_p^{(l)}{\\;\\leqslant\\;}l+1\\ } }   \\left ( { \\mathds{e } } [ \\sum_{i , j ; \\ : \\tau_{i , j}=\\sigma_p^{(l ) } }   e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_{\\sigma_p^{(l)}}}(\\sigma_p^{(l ) } ) ) }    | \\sigma_p^{(l ) } ] \\right)^{1/ ( 2\\gamma ) } \\right ]      \\\\ & =   \\sum_{p{\\;\\geqslant\\;}0}{\\mathds{e}}\\left [ e^ { -x_{n_{\\sigma_p^{(l)}}}(\\sigma_p^{(l ) } ) }   \\1_{\\ { \\sigma_p^{(l)}{\\;\\leqslant\\;}l+1\\ } } e^{\\frac{(1-\\gamma)^2(t-\\sigma_p^{(l)})}{\\gamma } } \\right ]      \\\\\\end{aligned}\\ ] ] hence by using ( [ critical ] ) , we get @xmath249 } e^ { { \\green - }   x_{n_\\tau}(\\tau ) } \\left(\\sum_{i , j ; \\ : \\tau_{i , j}=\\tau }   e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_\\tau}(\\tau ) ) } \\right)^{1/ ( 2\\gamma ) }   \\right ]     \\\\ & { \\;\\leqslant\\;}{\\mathds{e}}\\left [ \\sum_{l=1}^{t }    e^ { \\frac{(1-\\gamma)^2-\\beta^2}{\\gamma } ( t - l ) }      \\sum_{\\tau \\in [ l , l+1 ] } e^ { { \\green - }   x_{n_\\tau}(\\tau ) }   \\right ]    \\\\   & { \\;\\leqslant\\;}c   \\sum_{l=1}^{t }    e^ { \\frac{(1-\\gamma)^2-\\beta^2}{\\gamma } ( t - l ) }   \\\\ & { \\;\\leqslant\\;}c   \\\\\\end{aligned}\\ ] ] since @xmath250 .",
    "now , we state an intermediate lemma which we will need to prove the important lemma [ complextension ] .",
    "first , we introduce a few notations we will use in the sequel . for @xmath251 , set @xmath252 $ ] . for any @xmath253",
    "$ ] and @xmath254 , we denote by @xmath255 $ ] the real which realizes the infimum of the trajectory on @xmath256 $ ] @xmath257 } x_i(u).\\ ] ] then for any @xmath258 we define @xmath259 the subset defined by @xmath260,\\ ,   x_i(s(i , t ) ) \\in i_t(l )   \\\\\\end{aligned}\\ ] ]    [ intermediaire ] let @xmath241 and @xmath242\\frac{1}{2},1]$ ] be such that @xmath261 .",
    "let @xmath262 be such that @xmath263 .",
    "there exist @xmath264 and @xmath2650,1[$ ] such that , if @xmath266 , then for any @xmath267 , @xmath268 , @xmath269 @xmath270    in the proof , for simplicity , we will suppose that @xmath271 and @xmath272 are integers .",
    "we denote @xmath273 the time where two particles @xmath274 and @xmath275 have split .",
    "let @xmath262 such that @xmath276 . according to the markov property , then the sub - additivity , the probability in ( [ ? 3 ?",
    "] ) is smaller than @xmath277 let us study for any @xmath278 $ ] the expectations in the right hand side of ( [ retoujensen ] ) .",
    "we take the conditional expectation according to the real part of the bbm , then via the jensen inequality we deduce that @xmath279 ^ { \\kappa }   \\right )     \\\\ \\label{popopop } & { \\;\\leqslant\\;}{\\mathds{e}}\\left (   \\left [ \\sum_{l=1}^{t }    e^{-2 \\beta^2 ( t - l ) }     \\sum_{v = t/2}^{t - a_l } \\sum_{\\tau \\in [ l , l+1 ] } e^ { -2\\gamma ( x_{n_\\tau}(\\tau)-\\frac{3}{2}\\ln t ) } \\sum_{i , j ; \\ :",
    "\\tau_{i , j}=\\tau } \\1_{\\{i \\in   \\underset{k \\in \\mathbb{z}}{\\bigcup}\\mathcal{z}^{k_1,k}(v , l)\\ } } e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_\\tau}(\\tau ) ) } \\right   ] ^{\\kappa }   \\right),\\end{aligned}\\ ] ] where in the first inequality we have applied jensen s inequality with @xmath280 and @xmath281 $ ] , the conditional measure with @xmath282 fixed . by sub - additivity of @xmath283 , this is smaller than @xmath284}\\ee^ { -2\\kappa \\gamma ( x_{n_\\tau}(\\tau)-\\frac{3}{2}\\ln t ) } \\1_{\\{n_\\tau \\in a(v , l)\\ } } \\left [ \\sum_{i , j ; \\ : \\tau_{i , j}=\\tau }   e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_\\tau}(\\tau ) ) } \\right   ] ^{\\kappa }   \\right)\\end{aligned}\\ ] ] where @xmath285 means : @xmath286}{x_{n_\\tau}}(s ) { \\;\\geqslant\\;}\\frac{3}{2 } \\ln t - l   &   \\quad      \\text{if    } \\quad t/2<l+1{\\;\\leqslant\\;}v+2                   \\\\    &   \\inf_{s{\\;\\leqslant\\;}\\tau}{x_{n_\\tau}}(s ) { \\;\\geqslant\\;}-k_1,\\ ,   s({n_\\tau},\\tau)\\in [ v , v+1],\\ , \\inf_{s\\in [ t/2,\\tau]}{x_{n_\\tau}}(s )",
    "\\in i_t(l )   &        \\quad",
    "\\text{if    } \\quad   v+1 < l,\\end{aligned}\\ ] ] where @xmath287 satisfies @xmath288 } x_{n_\\tau}(u)$ ] . by introducing , as in the proof of lemma [ lemmamoment ] , for any @xmath107 , the times @xmath247 of successive branching after @xmath133 , one can use the branching property at these times and jensen s inequality ( with @xmath283 ) to get @xmath289}\\ee^ { -2\\kappa \\gamma ( x_{n_\\tau}(\\tau)-\\frac{3}{2}\\ln t)}\\1_{\\{n_\\tau \\in a(l , v)\\ } }   { \\mathds{e}}\\left ( \\sum_{i , j ; \\ : \\tau_{i , j}=\\tau } e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_\\tau}(\\tau ) ) }   \\right)^{\\kappa }   \\right ) \\\\ \\nonumber & & =   \\sum_{l=1}^{t }    e^{-2 \\kappa \\beta^2 ( t - l ) }     \\sum_{v = t/2}^{t - a_l } { \\mathds{e}}\\left ( \\sum_{\\tau \\in [ l , l+1 ] } e^ { -2\\kappa \\gamma ( x_{n_\\tau}(\\tau)-\\frac{3}{2}\\ln t)}\\1_{\\{n_\\tau \\in a(v , l)\\ } }     { \\mathds{e}}\\left ( \\sum_{i=1}^{n(t-\\tau ) } e^{-\\gamma x_i(t-\\tau ) }    |   \\tau \\right)^{2\\kappa } \\right ) \\\\ \\nonumber & & { \\;\\leqslant\\;}c   \\sum_{l=1}^{t }    e^{- \\kappa \\theta(\\gamma,\\beta ) (",
    "t - l ) }     \\sum_{v = t/2}^{t - a_l } { \\mathds{e}}\\left ( \\sum_{\\tau \\in [ l , l+1 ] } e^ { -2\\kappa \\gamma ( x_{n_\\tau}(\\tau)-\\frac{3}{2}\\ln t)}\\1_{\\{n_\\tau \\in a(v , l)\\ } }     \\right)\\end{aligned}\\ ] ] where , in the last inequality , we have used the many - to - one lemma to evaluate @xmath290 and with @xmath291 .",
    "let us estimate @xmath292 } e^ { -2\\kappa \\gamma ( x_{n_\\tau}(\\tau)-\\frac{3}{2}\\ln t)}\\1_{\\{n_\\tau \\in a(v , l)\\ } }     \\right)$ ] according to the value of @xmath293 and @xmath133 . for any @xmath294",
    "we denote by @xmath295 the set of all the branching times occurring along the bbm starting from @xmath296 .",
    "@xmath297 } e^ { -2\\kappa \\gamma ( x_{n_\\tau}(\\tau)-\\frac{3}{2}\\ln t)}\\1_{\\{n_\\tau \\in a(v , l)\\ } }     \\right ) \\\\   \\nonumber & = { \\mathds{e}}\\left(\\sum_{i=1}^{n(l ) } e^ { -2\\kappa \\gamma ( x_{i}(l)-\\frac{3}{2}\\ln t ) } \\sum_{\\tau\\in \\upsilon^{(i)},\\tau{\\;\\leqslant\\;}l+1 } e^ { -2\\kappa \\gamma ( x_{n_{\\tau}}(\\tau)-x_i(l ) ) }   \\1_{\\{n_\\tau \\in a(v , l)\\}}\\right ) \\\\ \\label{goodamount } & { \\;\\leqslant\\;}{\\mathds{e}}\\left(\\sum_{i=1}^{n(l ) } e^ { -2\\kappa \\gamma ( x_{i}(l)-\\frac{3}{2}\\ln t ) } \\1_{\\ { i \\in b(v , l)\\}}\\right ) { \\mathds{e}}\\left(\\sum_{\\tau{\\;\\leqslant\\;}1 } e^ { -2\\kappa \\gamma ( x_{n_{\\tau}}(\\tau ) ) } \\right )   , \\end{aligned}\\ ] ] where @xmath298 means @xmath299}{x_i}(s ) { \\;\\geqslant\\;}\\frac{3}{2 } \\ln t - l   &   \\quad      \\text{if    } \\quad t/2<l+1{\\;\\leqslant\\;}v+2                   \\\\    &   \\inf_{s{\\;\\leqslant\\;}l}{x_i}(s ) { \\;\\geqslant\\;}-k_1,\\ ,   s(i , l)\\in [ v , v+1],\\ , \\inf_{s\\in [ t/2,l]}{x_i}(s ) \\in i_t(l ) &        \\quad",
    "\\text{if    } \\quad   v+1 < l.\\end{aligned}\\ ] ] where @xmath300 satisfies @xmath301 } x_{i}(u)$ ] .",
    "we bound @xmath302 by @xmath303 and we deduce by the many - to - one lemma and the girsanov lemma that @xmath304 where , in a slight abuse of notation , the condition @xmath305 means that the trajectory satisfies the same conditions as @xmath274 when @xmath306 .",
    "finally , we have established the bound @xmath307 recall that @xmath308 .",
    "according to the definition of @xmath309 , we divide the estimation of @xmath310 in the following cases :      -second case , @xmath313 .",
    "@xmath314 } \\sqrt{2}b_s { \\;\\geqslant\\;}\\frac{3}{2 } \\ln t - l,\\,\\sqrt{2 } b_l\\in i_t(l - j ) \\right )   \\nonumber   \\\\   & { \\;\\leqslant\\;}c e^{- ( 1 - 2\\kappa\\gamma)l }   \\sum_{j{\\;\\geqslant\\;}0 } \\ee^ { ( 1 - 2\\kappa\\gamma)j } t^{\\frac{3}{2 } } \\frac{(1+k_1)(1+j ) } { t^{\\frac{3}{2 } } } \\nonumber   \\\\ & { \\;\\leqslant\\;}c ( 1+k_1 ) e^{- ( 1 - 2\\kappa\\gamma)l } ,   \\label{casou2}\\end{aligned}\\ ] ] where we have used standard estimates for brownian motion ( see for example lemmas 2.2 and 2.4 in @xcite ) .",
    "-third case , @xmath315 . by introducing @xmath316 , via the markov property at time @xmath317 , we have for any @xmath318 @xmath319,\\ , \\inf_{s\\in [ t/2,l]}\\sqrt{2 } b_s\\in i_t(l),\\ , \\sqrt{2}b_l\\in i_t(l - j ) \\right ) \\\\ & { \\;\\leqslant\\;}{\\mathds{e}}\\left ( 1_{\\ {   \\inf_{s{\\;\\leqslant\\;}v}\\sqrt{2 } b_s { \\;\\geqslant\\;}-k_1,\\ ,   \\sigma \\in [ v , v+1]\\ } } \\p_{b_\\sigma-\\frac{3}{2 } \\ln t+l}\\left ( \\inf_{s\\in[t/2-\\sigma , l-\\sigma ] } \\sqrt{2}b_s{\\;\\geqslant\\;}-1,\\ , \\sqrt{2}b_{l-\\sigma}\\in [ j , j+1 ] \\right)\\right ) \\\\ & { \\;\\leqslant\\;}c \\frac{1+j}{(l - v)^\\frac{3}{2}}\\p\\left ( \\inf_{s{\\;\\leqslant\\;}v}\\sqrt{2 } b_s { \\;\\geqslant\\;}-k_1,\\ ,   \\sigma \\in [ v , v+1]\\right ) \\\\ & { \\;\\leqslant\\;}c \\frac{(1+j)(1+k_1)}{(l - v)^\\frac{3}{2 } t^\\frac{3}{2}},\\end{aligned}\\ ] ] where we have used standard estimates for brownian motion ( see for example lemmas 2.2 and 2.4 in @xcite ) .",
    "thus we deduce that @xmath320 going back to ( [ bpose ] ) , and by combining ( [ casou1 ] ) , ( [ casou2 ] ) and ( [ casou3 ] ) we get @xmath321 where @xmath322 and @xmath323 where we have used the inequality @xmath324 for any @xmath325 , @xmath326 @xmath327 where we have used the inequality @xmath328 for any @xmath329 .",
    "recall here that the condition on @xmath330 ensures that @xmath331 and @xmath332 .",
    "hence we can find @xmath2650,1[$ ] and @xmath333 such that @xmath334 leading to @xmath335 .",
    "we also suppose that @xmath336 . then combining ( [ goback ] ) with ( [ * * 1 ] ) , ( [ * * 2 ] ) , ( [ * * 3 ] ) , ( [ * * 4 ] ) , it is plain to deduce that for any @xmath337 @xmath338 going back to ( [ retoujensen ] ) , by using ( [ retouback22 ] ) for any @xmath278 $ ] we get : @xmath339 which is the desired result .",
    "_ proof of lemma [ complextension ] . _ if @xmath344,we have the following obvious bound @xmath345 and therefore it suffices to adapt ( from the branching random walk to the bbm ) the proof of proposition 4.6 in @xcite to obtain the result .",
    "hence , in the sequel , we suppose that @xmath242\\frac{1}{2},1]$ ] . for simplicity ,",
    "we suppose @xmath271 is an integer .",
    "recall from a minor adaptation of @xcite that for any @xmath346 , we have @xmath347 for any @xmath346 , @xmath348 , the probability in is less or equal than @xmath349 clearly , we have @xmath350,\\ ,   \\inf_{s { \\;\\leqslant\\;}t }   x_i(s ) { \\;\\geqslant\\;}-k_1 , x_i(t)-\\frac{3}{2}\\ln t \\in [ k , k+1 ]   \\}= \\underset{v\\in",
    "\\{t/2, ... ,t\\}}{\\bigcup}\\underset{l\\in \\{-k, ...",
    ",2\\ln t\\}}{\\bigcup}\\mathcal{z}^{k_1,k}(v , l)\\ ] ]    we consider @xmath333 and @xmath2650,1[$ ] according to lemma [ intermediaire ] ( recall that @xmath266 that we will also suppose to be an integer for simplicity ) .",
    "according to the proof of lemma 3.3 in @xcite ( or more precisely its analogue to bbm ) , we know that for any @xmath351 , @xmath352,\\ , i \\in   \\underset{k \\in \\mathbb{z}}{\\bigcup } \\ : \\underset{v\\in \\ { t - a_l, ... ,t\\}}{\\bigcup}\\mathcal{z}^{k_1,k}(v , l)\\big){\\;\\leqslant\\;}c ( 1+k_1 ) a_l e^{-l}.\\ ] ] this inequality is useful for @xmath353 large .",
    "now , according to lemma [ intermediaire ] , we have for any @xmath354 , @xmath269 and @xmath355 , @xmath356}x_i(s){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t - l,\\ , x_i(t){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t+k \\ } } e^ { -\\gamma ( x_i(t)-\\frac{3}{2}\\ln t ) + i\\beta\\sqrt{2}\\ : \\bar{y}_i(t)}\\right| { \\;\\geqslant\\;}{\\varepsilon}\\right )   \\nonumber \\\\ & + \\sum_{l'=l+1}^{2\\ln t}\\p\\left ( \\exists i \\in [ |1,n(t)|],\\ , i \\in",
    "\\underset{k \\in \\mathbb{z}}{\\bigcup } \\ : \\underset{v\\in \\ { t - a_l, ... ,t\\}}{\\bigcup}\\mathcal{z}^{k_1,k}(v , l')\\right )   \\nonumber \\\\ & + \\p\\left(\\sum_{l'=l+1}^{2\\ln t}\\left| \\sum_{i=1}^{n(t ) }   \\1_{\\{i \\in   \\underset{k \\in \\red{\\mathbb{z}}}{\\bigcup } \\ : \\underset{v\\in \\ { t/2, ... ,t - a_l\\}}{\\bigcup}\\mathcal{z}^{k_1,k}(v , l')\\ } } e^ { -\\gamma ( x_i(t)-\\frac{3}{2}\\ln t ) + i\\beta\\sqrt{2}\\ : \\bar{y}_i(t)}\\right| { \\;\\geqslant\\;}{\\varepsilon}\\right ) \\nonumber \\\\ & { \\;\\leqslant\\;}e^{-k_1 } + c(1+k_1 ) e^{-\\delta l }   + c e^{k_1 } \\ln t   e^{-\\delta t } \\nonumber \\\\ & +   \\p\\left(\\left| \\sum_{i=1}^{n(t ) }   \\1_{\\ {    \\inf_{s{\\;\\leqslant\\;}t } x_i(s){\\;\\geqslant\\;}-k_1,\\ , \\inf_{s\\in [ t/2,t]}x_i(s){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t - l,\\ , x_i(t){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t+k \\ } } e^ { -\\gamma ( x_i(t)-\\frac{3}{2}\\ln t ) + i\\beta\\sqrt{2}\\ : \\bar{y}_i(t)}\\right| { \\;\\geqslant\\;}{\\varepsilon}\\right ) ,   \\label{tttt}\\end{aligned}\\ ] ] where , in the last inequality , we have used the bound @xmath357 .    thus in order to prove ( [ limlim ] ) , it remains to study for @xmath337 , @xmath358}x_i(s){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t - l,\\ , x_i(t){\\;\\geqslant\\;}\\frac{3}{2}\\ln t+k \\ } } e^ { -\\gamma ( x_i(t)-\\frac{3}{2}\\ln t ) + i\\beta\\sqrt{2}\\ : \\bar{y}_i(t)}\\right| { \\;\\geqslant\\;}{\\varepsilon}\\right )    .\\ ] ] according to the markov inequality and jensen s inequality , the probability in ( [ stud ] ) is smaller than @xmath359 } e^ { -2\\gamma ( x_{n_\\tau}(\\tau)-\\frac{3}{2}\\ln t ) } \\sum_{i , j ; \\ : \\tau_{i , j}=\\tau }",
    "\\1_{\\ {    \\inf_{s{\\;\\leqslant\\;}t } x_i(s){\\;\\geqslant\\;}-k_1,\\ , \\inf_{s\\in [ t/2,t]}x_i(s){\\;\\geqslant\\;}\\frac{3}{2}\\ln t - l,\\ , x_i(t){\\;\\geqslant\\;}\\frac{3}{2}\\ln t+k \\ } }    \\\\ & \\label{proproprop } \\times e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_\\tau}(\\tau ) ) }   ) \\\\ & \\nonumber   = { \\varepsilon}^{-2}{\\mathds{e}}\\left (   \\sum_{l=1}^{t - e^{l } } ...",
    "\\right ) + { \\varepsilon}^{-2}{\\mathds{e}}\\left (   \\sum_{l = t - e^l+1}^{t } ...",
    "\\right ) \\end{aligned}\\ ] ] again by introducing for any @xmath107 , @xmath247 the times of successive branching after @xmath133 , by the branching property at these time we can write : @xmath360(t - l ) }      \\sum_{\\tau \\in [ l , l+1 ] }   \\sum_{i > \\tau ; } \\1_{\\ {    \\inf_{s{\\;\\leqslant\\;}t } x_i(s){\\;\\geqslant\\;}-k_1,\\ , \\inf_{s\\in [ t/2,t]}x_i(s){\\;\\geqslant\\;}\\frac{3}{2}\\ln t - l,\\ , x_i(t){\\;\\geqslant\\;}\\frac{3}{2}\\ln t+k \\ } }    \\nonumber   \\\\ & \\times   e^ { -\\gamma ( x_i(t ) + x_{n_\\tau}(\\tau ) ) } ) ,   \\label{pourlasuite}\\end{aligned}\\ ] ] where @xmath361 means that @xmath362 is a spliting time of particle @xmath140 . in the above equality ,",
    "we have averaged out the trajectory of particle @xmath363 on the interval @xmath364 $ ] .",
    "we also have @xmath365 } e^ { -2\\gamma ( x_{n_\\tau}(\\tau)-\\frac{3}{2}\\ln t)}\\1_{\\{n_\\tau \\in a(l ) \\ } } \\right)\\ ] ] where we have averaged out the particles @xmath238 on @xmath364 $ ] and @xmath366 means : @xmath367}{x_{n_\\tau}}(s ) { \\;\\geqslant\\;}\\frac{3}{2}\\ln t -l   &   \\quad      \\text{if    } \\quad 3t/4<l+1{\\;\\leqslant\\;}t- e^l\\end{aligned}\\ ] ] first let us bound the term in ( [ secood2 ] ) . by reasoning as in ( [ goodamount ] ) and ( [ moodforl ] ) we have @xmath368 where @xmath369 means @xmath370}b_s { \\;\\geqslant\\;}\\frac{3}{2}\\ln",
    "t - l   &   \\quad      \\text{if    } \\quad 3t/4<l+1{\\;\\leqslant\\;}t-\\ee^l.\\end{aligned}\\ ] ]    then it follows that @xmath371 } \\sqrt{2}b_s { \\;\\geqslant\\;}\\frac{3}{2 } \\ln t - l,\\,\\sqrt{2 } b_l\\in i_t(l - j ) \\right )   \\\\    { \\;\\leqslant\\ ; } & ct^{3\\gamma } e^{(1 - 2\\gamma ) k_1 } e^{-\\theta(\\beta,\\gamma)t/4 } + c   e^{-(1 - 2\\gamma)l-\\theta(\\beta,\\gamma)e^l } ( 1+k_1).\\end{aligned}\\ ] ]    now we need to bound the term .",
    "we can bound the term in by @xmath372(t - l ) } t^{3\\gamma } { \\mathds{e}}\\left ( \\sum_{i=1}^{n(t ) }    \\1_{\\ {    \\inf_{s{\\;\\leqslant\\;}t } x_i(s){\\;\\geqslant\\;}-k_1,\\ , \\inf_{s\\in [ t/2,t]}x_i(s){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t - l,\\ , x_i(t){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t+k \\ } }      e^ { -\\gamma ( x_i(t ) + \\inf_{s\\in [ l , l+1 ] } x_{i}(s ) ) }   \\right ) \\\\ & = { \\varepsilon}^{-2}\\sum_{l = t - e^l+1}^{t }   t^{3\\gamma }   e^ { ( ( 1-\\gamma)^2- 2\\beta^2 ) ( t - l ) }   \\\\ & \\times   { \\mathds{e}}\\left ( e^{\\sqrt{2 } b_t-\\gamma(\\sqrt{2 } b_t + \\inf_{s\\in [ l , l+1 ] } \\sqrt{2 } b_s ) }    \\1_{\\ {    \\inf_{s{\\;\\leqslant\\;}t } \\sqrt{2 } b_s{\\;\\geqslant\\;}-k_1,\\ , \\inf_{s\\in [ t/2,t]}\\sqrt{2 } b_s{\\;\\geqslant\\;}\\frac{3}{2 } \\ln t -l,\\ , \\sqrt{2 } b_t{\\;\\geqslant\\;}\\frac{3}{2 } \\ln t+k \\ } }     \\right )   \\\\ & { \\;\\leqslant\\;}{\\varepsilon}^{-2 } t^{3/2 } e^{(1 - 2\\gamma)k }   \\sum_{l = t - e^l+1}^{t }    e^ { [ ( 1-\\gamma)^2- 2\\beta^2 ] ( t - l ) }   \\\\ & \\times\\sum_{j=1}^\\infty e^{(1 - 2 \\gamma)j } { \\mathds{e}}\\left ( e^{-\\gamma(\\inf_{s\\in [ l , l+1 ] } \\sqrt{2 } b_s-\\sqrt{2}b_t ) }    \\1_{\\ {    \\inf_{s{\\;\\leqslant\\;}t } \\sqrt{2 } b_s{\\;\\geqslant\\;}-k_1,\\ , \\inf_{s\\in [ t/2,t]}\\sqrt{2 } b_s{\\;\\geqslant\\;}\\frac{3}{2 } \\ln t -l,\\ , \\sqrt{2 } b_t \\in i_t(-j - k ) \\ } }     \\right )   \\\\ &   { \\;\\leqslant\\;}c(l ) { \\varepsilon}^{-2 } t^{3/2 } e^{(1 - 2\\gamma)k }   \\sum_{l = t - e^l+1}^{t }    e^{((1-\\gamma)^2- 2\\beta^2 ) (",
    "t - l ) }   \\\\ & \\times   \\sum_{j=1}^\\infty e^{(1 - 2 \\gamma)j }   \\frac{(1+k_1)(l+j+k)}{t^{3/2 } }   \\\\   & { \\;\\leqslant\\;}c(l ) { \\varepsilon}^{-2 } ( 1+k_1)(l+k ) e^{(1 - 2\\gamma)k } \\end{aligned}\\ ] ] where @xmath373 is a constant depending on @xmath353 and we have used standard estimates on brownian motion ( see for example lemmas 2.2 and 2.4 in @xcite ) . in conclusion , we have the following bound @xmath374}x_i(s){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t - l,\\ , x_i(t){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t+k \\ } } e^ { -\\gamma ( x_i(t)-\\frac{3}{2}\\ln t ) + i\\beta\\sqrt{2}\\ : \\bar{y}_i(t)}\\right| { \\;\\geqslant\\;}{\\varepsilon}\\right )   \\nonumber \\\\ & { \\;\\leqslant\\;}ct^{3\\gamma } e^{(1 - 2\\gamma ) k_1 } e^{-\\theta(\\beta,\\gamma)t/4 } + c   e^{-(1 - 2\\gamma)l-\\theta(\\beta,\\gamma)e^l } ( 1+k_1)+ c(l ) { \\varepsilon}^{-2 } ( 1+k_1)(l+k ) e^{(1 - 2\\gamma)k}. \\label{ttttt}\\end{aligned}\\ ] ] gathering and , we finally obtain @xmath375 now , one concludes by letting @xmath195 and then choosing successively @xmath376 .",
    "notice that we can write : @xmath378 where @xmath379 is the branching brownian motion rooted at @xmath89 , @xmath380 is the splitting time of @xmath381 and @xmath382 and @xmath383 means : @xmath384 an important observation is that : @xmath385 is a set which belong to the sigma field generated by the real branching brownian motion , and therefore which is indenpendent of the @xmath386}$ ] .",
    "we want to bound @xmath387 reasoning as in ( [ stud ] ) , we have : @xmath388}x_i(s){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t - l,\\ , x_i(t){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t+k',\\ , i \\in a(l , t , b , k ) \\ } } e^ { -\\gamma ( x_i(t)-\\frac{3}{2}\\ln t ) + i\\beta\\sqrt{2}\\ : \\bar{y}_i(t)}\\right| { \\;\\geqslant\\;}{\\varepsilon}\\right )   \\nonumber \\\\ & + \\sum_{l'=l+1}^{2\\ln t}\\p\\left ( \\exists i \\in [ |1,n(t)|],\\ , i \\in",
    "\\underset{k \\in \\mathbb{z}}{\\bigcup } \\ : \\underset{v\\in \\ { t - a_l, ... ,t\\}}{\\bigcup}\\mathcal{z}^{k_1,k}(v , l')\\right )   \\nonumber \\\\ & + \\p\\left(\\sum_{l'=l+1}^{2\\ln t}\\left| \\sum_{i=1}^{n(t ) }   \\1_{\\{i \\in   \\underset{k \\in \\mathbb{z}}{\\bigcup } \\ : \\underset{v\\in \\ { t/2, ... ,t - a_l\\}}{\\bigcup}\\mathcal{z}^{k_1,k}(v , l'),\\ , i \\in a(l , t , b , k)\\ } } e^ { -\\gamma ( x_i(t)-\\frac{3}{2}\\ln t ) + i\\beta\\sqrt{2}\\ : \\bar{y}_i(t)}\\right| { \\;\\geqslant\\;}{\\varepsilon}\\right )   \\\\ & { \\;\\leqslant\\;}e^{-k_1}+ c(1+k_1 ) e^{-\\delta l}+ c e^{k_1}\\ln t \\ : e^{-\\delta t } + \\\\ & + \\frac{1}{{\\varepsilon}^2 } { \\mathds{e}}\\left ( \\left|\\sum_{i=1}^{n(t ) }   \\1_{\\ {    \\inf_{s{\\;\\leqslant\\;}t } x_i(s){\\;\\geqslant\\;}-k_1,\\ , \\inf_{s\\in [ t/2,t]}x_i(s){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t - l,\\ , x_i(t){\\;\\geqslant\\;}\\frac{3}{2 } \\ln t+k',\\ , i \\in a(l , t , b , k ) \\ } } e^ { -\\gamma ( x_i(t)-\\frac{3}{2}\\ln t ) + i\\beta\\sqrt{2}\\ : \\bar{y}_i(t)}\\right|^2 \\right )   \\\\ & +   \\frac{1}{{\\varepsilon}^{{\\red \\kappa } } } \\sum_{l'=l+1}^{2\\ln t}{\\mathds{e}}\\left ( \\left| \\sum_{i=1}^{n(t ) }   \\1_{\\{i \\in   \\underset{k \\in \\mathbb{z}}{\\bigcup } \\ : \\underset{v\\in \\ { t/2, ...",
    ",t - a_l\\}}{\\bigcup}\\mathcal{z}^{k_1,k}(v , l'),\\ , i \\in a(l , t , b , k)\\ } } e^ { -\\gamma ( x_i(t)-\\frac{3}{2}\\ln t ) + i\\beta\\sqrt{2}\\ : \\bar{y}_i(t)}\\right|^{{\\red\\kappa } } \\right).\\end{aligned}\\ ] ] by jensen s inequality , we therefore get @xmath389 } e^ { -2\\gamma ( x_{n_\\tau}(\\tau)-\\frac{3}{2}\\ln t ) } \\sum_{i , j ; \\ : \\tau_{i , j}=\\tau }    \\\\ &   \\times \\1_{\\ {    \\inf_{s{\\;\\leqslant\\;}t } x_i(s){\\;\\geqslant\\;}-k_1,\\ , \\inf_{s\\in [ t/2,t]}x_i(s){\\;\\geqslant\\;}\\frac{3}{2}\\ln t - l,\\ , x_i(t){\\;\\geqslant\\;}\\frac{3}{2}\\ln t+k',\\ ,   i \\in a(l , t , b , k ) \\ } } e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_\\tau}(\\tau ) ) }   ) \\\\ & +    { \\varepsilon}^{-{\\kappa}}\\sum_{l = l_0 + 1}^{2\\ln t } { \\mathds{e}}\\left (   \\left [ \\sum_{l=1}^{t }    e^{-2 \\beta^2 ( t - l ) }     \\sum_{v = t/2}^{t - a_l } \\sum_{\\tau \\in [ l , l+1 ] } e^ { -2\\gamma ( x_{n_\\tau}(\\tau)-\\frac{3}{2}\\ln t ) } \\sum_{i , j ; \\ : \\tau_{i , j}=\\tau } \\1_{\\{i \\in   \\underset{k \\in \\mathbb{z}}{\\bigcup}\\mathcal{z}^{k_1,k}(v , l),\\ , i \\in a(l , t , b , k)\\}}\\right .",
    "\\\\ & \\left.\\left",
    ". e^ { -\\gamma ( x_i(t)+x_j(t)-2 x_{n_\\tau}(\\tau ) ) } \\right   ] ^{\\kappa }   \\right)^ { \\frac{1}{2 } } \\\\ & { \\;\\leqslant\\;}e^{-k_1}+ c(1+k_1 ) e^{-\\delta l}+ c e^{k_1}\\ln t \\ : e^{-\\delta t}+ a +   { \\varepsilon}^{-{\\kappa}}\\sum_{l = l_0 + 1}^{2\\ln t}(b_l)^\\frac{1}{2 } , \\end{aligned}\\ ] ] where @xmath29 and @xmath390 are the expectations defined respectively in ( [ proproprop ] ) ( with @xmath205 in place of @xmath110 ) and ( [ popopop ] ) ( to get the last inequality , it suffices to remove the indicator @xmath391 ) .",
    "we then conclude along the same lines as the proofs of lemmas [ intermediaire ] and [ complextension ] .",
    "we consider the less obvious case , i.e. @xmath241 and @xmath242\\frac{1}{2},1]$ ] such that @xmath243 .",
    "since the law of @xmath91 does not depend on @xmath89 , we consider the case @xmath397 and remove the superscript @xmath398 for clarity .",
    "we denote @xmath399 $ ] the conditional expectation with respect to @xmath400 and @xmath401 .",
    "we introduce an i.i.d .",
    "sequence @xmath402 of bbms of law given by the @xmath50 of the section setup and main result .",
    "now , we have ( below @xmath403 denotes a finite constant depending on @xmath400 and @xmath401 ) @xmath404   \\\\ & =   \\sum_{j=1}^\\infty e^{-\\gamma \\gamma(\\tau_j ) } { \\mathds{e } } [   | < e^{-\\gamma x+i   \\sqrt{2 } \\beta y } ,   \\bar{\\mathcal{n}}^{j}_{\\gamma(\\tau_j),\\tau_j}(dx , dy ) >",
    "|    | \\gamma , \\tau ] \\\\ &   { \\;\\leqslant\\;}\\sum_{j=1}^\\infty   \\frac{e^{-\\gamma \\gamma(\\tau_j ) }    } { \\p ( x_1^j(\\tau_j ) > - \\gamma(\\tau_j ) )   } { \\mathds{e } } [ ( \\sum_{k , k ' }   e^{- \\gamma x_k^j(\\tau_j ) - \\gamma x_{k'}^j(\\tau_{j } ) -2 \\beta^2 \\tau_{k , k'}^{j , j } }     ) ^{1/ 2 }   |   \\gamma , \\tau   ] \\\\ &   { \\;\\leqslant\\;}c(\\gamma,(\\tau_j)_{j { \\;\\geqslant\\;}1 } ) \\sum_{j=1}^\\infty e^{-\\gamma \\gamma(\\tau_j ) }   { \\mathds{e } } [ ( \\sum_{k , k ' }   e^{- \\gamma x_k^j(\\tau_j ) - \\gamma x_{k'}^j(\\tau_{j } ) -2 \\beta^2 \\tau_{k , k'}^{j , j } }     ) ^{1/ 2 }   |   \\gamma , \\tau   ] \\\\ &   { \\;\\leqslant\\;}c(\\gamma,(\\tau_j)_{j { \\;\\geqslant\\;}1 } ) \\sum_{j=1}^\\infty e^{-\\gamma \\gamma(\\tau_j ) }   { \\mathds{e } } [ ( \\sum_{k , k ' }   e^{- \\gamma x_k^j(\\tau_j ) - \\gamma x_{k'}^j(\\tau_{j } ) -2 \\beta^2 \\tau_{k , k'}^{j , j } }     ) ^{1/ ( 2\\gamma ) }   |   \\gamma , \\tau   ] ^{\\gamma } \\\\ &   { \\;\\leqslant\\;}c(\\gamma,(\\tau_j)_{j { \\;\\geqslant\\;}1 } ) \\sum_{j=1}^\\infty e^{-\\gamma \\gamma(\\tau_j ) }   \\\\ & < \\infty   \\end{aligned}\\ ] ] since @xmath2421/2,1]$ ] and where we have used lemma [ lemmamoment ] .",
    "finally , it is not hard to see that the limit variable @xmath405 is non trivial .",
    "observe that , conditionally to @xmath400 and @xmath401 , the variables @xmath406 are independent and non constant hence @xmath407 is non trivial .",
    "we consider the less obvious case , i.e. @xmath241 and @xmath242\\frac{1}{2},1]$ ] such that @xmath243 . once again , since the law of @xmath91 does not depend on @xmath89 , we consider the case @xmath397 and remove the superscript @xmath398 for clarity .",
    "we introduce an i.i.d .",
    "sequence @xmath402 of bbms of law given by the @xmath50 of the section setup and main result .",
    "now , we have ( below @xmath403 denotes a finite constant depending on @xmath400 and @xmath401 ) @xmath411   \\\\ & { \\;\\leqslant\\;}{\\mathds{e } } [   \\sum_{j=1}^\\infty e^{-\\gamma \\gamma ( \\tau_j ) }   | < \\1_{\\{x > \\theta\\}}e^{-\\gamma x+i   \\sqrt{2 } \\beta y } ,   \\bar{\\mathcal{n}}^{j}_{\\gamma(\\tau_j),\\tau_j}(dx , dy ) >",
    "|    | \\gamma , \\tau ]   \\\\ & =   \\sum_{j=1}^\\infty e^{-\\gamma \\gamma(\\tau_j ) } { \\mathds{e } } [   | <   \\1_{\\{x > \\theta\\ } } e^{-\\gamma x+i   \\sqrt{2 } \\beta y } ,   \\bar{\\mathcal{n}}^{j}_{\\gamma(\\tau_j),\\tau_j}(dx , dy ) > |",
    "| \\gamma , \\tau ] \\\\ &   { \\;\\leqslant\\;}c(\\gamma,(\\tau_j)_{j { \\;\\geqslant\\;}1 } ) \\sum_{j=1}^\\infty e^{-\\gamma \\gamma(\\tau_j ) }   { \\mathds{e } } [ ( \\sum_{k , k ' }   \\1_{\\{x_k^j(\\tau_j ) > \\theta\\ } }   \\1_{\\{x_{k'}^j(\\tau_{j } )   > \\theta\\ } } e^{- \\gamma x_k^j(\\tau_j ) - \\gamma x_{k'}^j(\\tau_{j } ) -2 \\beta^2 \\tau_{k , k'}^{j , j } }     ) ^{1/ 2 }   |   \\gamma , \\tau   ] .\\end{aligned}\\ ] ] each term @xmath412 $ ] is bounded by the same quantity without the indicator function and converges to @xmath37 as @xmath410 goes to infinity .",
    "hence , by the dominated convergence theorem , we have @xmath413   \\underset{\\theta \\to \\infty}{\\rightarrow } 0.\\ ] ] therefore , the variable @xmath414 $ ] converges almost surely to @xmath37 as @xmath410 goes to infinity .",
    "now , one concludes by using the following inequality for all @xmath415 @xmath416 } { \\varepsilon }    \\wedge 1 \\right ] .\\ ] ]                                    carpentier d. , le doussal p. : glass transition of a particle in a random potential , front selection in nonlinear rg and entropic phenomena in liouville and sinh - gordon models , _ phys .",
    "e _ * 63*:026110 ( 2001 ) .",
    "duplantier b. , rhodes r. , sheffield s. , vargas v. : critical gaussian multiplicative chaos : convergence of the derivative martingale , to appear in _ annals of probability _ , arxiv:1206.1671 .",
    "duplantier b. , rhodes r. , sheffield s. , vargas v. : renormalization of critical gaussian multiplicative chaos and kpz formula , to appear in _ communications in mathematical physics _ , arxiv:1212.0529 .",
    "fyodorov y. and bouchaud j.p . :",
    "freezing and extreme - value statistics in a random energy model with logarithmically correlated potential , _ j. phys .",
    "a _ * 41 * ( 2008 ) 372001 .",
    "fyodorov y , le doussal p. , rosso a. : statistical mechanics of logarithmic rem : duality , freezing and extreme value statistics of @xmath418 noises generated by gaussian free fields , _ j. stat",
    ". mech . _ ( 2009 ) p10005 .",
    "neveu , j. : multiplicative martingales for spatial branching processes . in seminar on stochastic processes , 1987 , ( eds : e. cinlar , k.l .",
    "chung , r.k .",
    "progress in probability and statistics , 15 , 223 - 241 .",
    "birkhauser , boston ( 1988 ) ."
  ],
  "abstract_text": [
    "<S> in this paper , we study complex valued branching brownian motion in the so - called glassy phase , or also called phase ii . in this context , we prove a limit theorem for the complex partition function hence confirming a conjecture formulated by lacoin and the last two authors in a previous paper on complex gaussian multiplicative chaos </S>",
    "<S> . we will show that the limiting partition function can be expressed as a product of a gaussian random variable , mainly due to the windings of the phase , and a stable transform of the so called derivative martingale , mainly due to the clustering of the modulus . </S>",
    "<S> the proof relies on the fine description of the extremal process available in the branching brownian motion context .     </S>",
    "<S> thomas madaule ,  rmi rhodes ,   vincent vargas    * key words or phrases : * branching brownian motion , freezing , glassy phase .    </S>",
    "<S> * msc 2000 subject classifications : 60g57 , 60g15 * </S>"
  ]
}