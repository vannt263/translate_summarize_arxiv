{
  "article_text": [
    "in ciuperca  ( 2012 ) , the author considered a linear regression model with multiple change - points occurring at unknown times .",
    "in particular , the author studied the asymptotic properties of the lasso - type and that of the adaptive lasso estimators .",
    "while the established results seem interesting , we point out a major error in proof of one of the important result . in particular , the proof of part  ( ii ) of lemma  3 in ciuperca  ( 2011 ) is based on the inequality @xmath0 , which is wrong .",
    "indeed , take @xmath1 and @xmath2 , we get @xmath3 which contradicts the inequality used in the quoted paper .    for the sake of clarity",
    ", we use the same notation and we suppose that the main assumptions in ciuperca  ( 2012 ) hold .",
    "below , we recall these assumptions for the convenience of the reader .",
    "namely , we consider the following model : @xmath4 , where @xmath5 @xmath6 denotes the indicator function of the event @xmath7 , @xmath8 denotes the response variable , @xmath9 is a @xmath10-vector of regressors , @xmath11 are the errors which are assumed to be independent and identically distributed ( i.i.d . ) random variables , @xmath12 , @xmath13 is compact , @xmath14 .",
    "the model parameters are given by @xmath15 , with the regression parameters @xmath16 and the change - points @xmath17 .",
    "in addition , we set @xmath18 and @xmath19 to be the true values of @xmath20 and @xmath21 , respectively . as in ciuperca  ( 2012 )",
    ", we impose the following conditions .",
    "@xmath22 : :    there exists two positive constants @xmath23 such    that @xmath24 $ ] , for every    @xmath25 , with @xmath26 and    @xmath27 . without loss of generality , we consider    @xmath28 , and @xmath29 .",
    "@xmath30 : :    @xmath31 { } \\bm{0}$ ] and for any @xmath32 , the    matrix +    @xmath33 { }   c_r$ ] , where @xmath34    is a non - negative definite matrix . @xmath35 : :    @xmath36 is a random variable absolutely continuous    with @xmath37 ,    @xmath38 ,    @xmath39 .",
    "we assume that @xmath40 , @xmath41 , and consider the following penalized sum : @xmath42,\\ ] ] where @xmath43 is the tuning parameter and @xmath44 .",
    "we define the lasso - type estimator of @xmath45 , say @xmath46 , where @xmath47 and @xmath48 , by @xmath49 and @xmath50 note that , for @xmath51 and @xmath52 , we obtain the lasso estimator and ridge estimator respectively .",
    "the rest of this paper is organized as follows .",
    "section  [ sec : mainres ] gives the main result of this paper , and in section  [ sec : conclusion ] .",
    "the proof of the main result is given in the appendix .",
    "[ lema3 ] under assumptions @xmath30 , @xmath35 , for all @xmath53 , @xmath54 , such that @xmath55 , with @xmath56 , @xmath57 , @xmath58 , let be the model : @xmath59 with @xmath60 .",
    "we set @xmath61 and + @xmath62 .",
    "let @xmath63 .",
    "then ,    1",
    ".   @xmath64 .",
    "2 .   if @xmath65 for some @xmath66 , then @xmath67    it should be noted that , although part ( i ) of the above lemma is the same as that of lemma  3 of ciuperca  ( 2012 ) , part  ( ii ) is slightly different . the established result holds if @xmath65 , while the result stated in ciuperca  ( 2012 ) is supposed to hold for all @xmath68 , but with incorrect proof .",
    "so far , we are neither able to correct the proof for all @xmath68 nor to prove that the statement itself is wrong . similarly ,",
    "part  ( ii ) of lemmas  4  and  8 hold under the condition that @xmath65 .",
    "in this paper , we proposed a modification of part ( ii ) of lemma  3 given in ciuperca  ( 2012 ) for which the proof is wrong .",
    "further , we provided the correct proof .",
    "it should be noted that there are several important results in the quoted paper which were established by using lemma  3 . in particular , the quoted author used this lemma in establishing lemmas  4 and 8 , as well as theorems 1 , 2 and 4 .",
    "the proof of part ( i ) is similar to that in ciuperca  ( 2012 ) .",
    "2 .   let @xmath69 , @xmath70 $ ] .",
    "then , @xmath71 since @xmath72 , by cauchy - schwarz inequality , we have @xmath73 further , let @xmath74 be the largest eigenvalue of @xmath75 . then , using the fact that @xmath76 and cauchy - schwarz inequality , we have @xmath77 and then , @xmath78 also , we have @xmath79 therefore , @xmath80 .",
    "further , since + @xmath81 , @xmath82 , we have @xmath83 hence @xmath84 which implies that @xmath85 let @xmath86 and @xmath74 be the largest eigenvalue of @xmath87 . then , by cauchy - schwarz inequality , @xmath88 and then , @xmath89 now , let@xmath90\\\\ t_n^s(\\phi)&=&\\sum_{i = n_1 + 1}^{n_1+n_2}[(\\epsilon_i - x_i'(\\phi-\\phi_2 ^ 0))^2 -(\\epsilon_i - x_i'(\\phi_1-\\phi_2 ^ 0))^2]\\\\ & & \\quad { } + \\lambda_{n;(n_1,n_1+n_2 ) } [ \\sum_{k=1}^p(|\\phi_{,k}|^\\gamma-|\\phi_{1,k}^0|^\\gamma)].\\end{aligned}\\ ] ] then , @xmath91.\\ ] ] then @xmath92 .",
    "in addition , using the similar approach as previous , with the fact that @xmath93 and @xmath76 , we have @xmath94\\\\ & = & o_p(1)+o(n^{v/2})o_p(||\\hat{\\phi}_{n_1+n_2}^s-\\phi_1 ^ 0||)=o_p(n^{-(u-2v-\\delta)/2 } ) = o_p(1).\\end{aligned}\\ ] ] besides , @xmath95 , thus @xmath96 hence @xmath97 on the other hand , since @xmath98,\\ ] ] @xmath99|.\\ ] ] further , @xmath100 \\leqslant \\sum_{k=1}^p(|\\hat{\\phi}_{n_1,k}|^\\gamma-|\\phi_{1,k}^0|^\\gamma ) = o_p(||\\hat{\\phi}_{n_1}-\\phi_1 ^ 0||)=o_p(n_1^{-1/2}),\\ ] ] and @xmath101 .",
    "it follows that @xmath102 .",
    "hence , @xmath103"
  ],
  "abstract_text": [
    "<S> in ciuperca  ( 2012 )  ( ciuperca . model selection by lasso methods in a change - point model , _ stat </S>",
    "<S> . papers _ , 2012;(in press ) ) , the author considered a linear regression model with multiple change - points occurring at unknown times . </S>",
    "<S> in particular , the author studied the asymptotic properties of the lasso - type and of the adaptive lasso estimators . </S>",
    "<S> while the established results seem interesting , we point out some major errors in proof of the most important result of the quoted paper . </S>",
    "<S> further , we present a corrected result and proof .    </S>",
    "<S> _ keywords : _ asymptotic properties ; change - points ; model selection ; lasso ; regression . </S>"
  ]
}