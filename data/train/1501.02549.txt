{
  "article_text": [
    "in recent times , there has been an increase in demand for online video streaming leading to high data traffic .",
    "also , it is observed that the demands are variable across time , with periods of high and low traffic demand .",
    "the load on the server is high during peak hours when a majority of users access video and relatively low at other times .",
    "thus , there exists the possibility of storing content at the end users during the off peak hours such that the load on the server is reduced during peak hours .",
    "this method is called _",
    "caching_. there are two main phases involved in this process , placement phase and delivery phase . in the placement phase , data is stored at the end user when the network is relatively uncongested ; here the constraint is the cache memory size at the user . also , at this stage the actual request the user might make is not usually known . in the delivery phase , when the actual requests of the users are made , the constraint is the rate required to serve all the requested content .",
    "a straightforward approach is to cache a copy of a fraction of all the files at all the users .",
    "then in the delivery phase , the central server needs to send only the remaining parts of the requested files .",
    "this is effective only when the cache size is comparable to the database size at the server .",
    "a more sophisticated approach is to allow the central server to satisfy the request of several users with different demands with a single multicast stream as was shown in  @xcite using the idea of network coding  @xcite .",
    "streams are generated by coding across the different files requested .",
    "this reduces the rate as compared to a conventional caching scheme .",
    "the requested files are decoded from the data stream using the contents stored in the local cache memory .",
    "the gain from this approach is not only proportional to the cache size but also increases with the increasing number of users .",
    "another approach suggested in  @xcite is to store contents that are coded across files to reduce the rate .    in  @xcite , inner and outer bounds on the optimal tradeoff between cache size @xmath0 at each user and the data rate @xmath1 required to service any set of single file requests from all the users",
    "were obtained .",
    "considering a popularity distribution on the files , inner and outer bounds on the tradeoff between cache size and expected load of the shared link was obtained in  @xcite .",
    "an online version of this problem was considered in  @xcite . in  @xcite ,",
    "a scheme was proposed where the placement phase is distributed and not centrally controlled by the central server . in  @xcite ,",
    "a hierarchical system is considered , where caching happens at two or more levels .    in this paper , we are interested in the case when the database size is large compared to the number of users . for a fixed cache size , when the number of files is considerably large compared to the number of users , no significant gain in the rate can be achieved by any scheme compared to having no cache .",
    "specifically , we are interested in finding the minimum number of files beyond which the benefits of caching disappear in the setting of  @xcite . to this end",
    ", we first prove a general outer bound on the optimal @xmath2 tradeoff which generalizes an example in  @xcite .",
    "we show that the gains from caching are small when the number of files is comparable to the square of the number of users .",
    "we then define the pre - constant to the @xmath3 term ( where @xmath4 denotes the number of users ) . using the improved outer bound",
    "we obtain a better upper bound to this pre - constant .",
    "the rest of the paper is organized as follows . in section",
    "slowromancap2@ we recapitulate the system model proposed in  @xcite , and in section  slowromancap3@ we summarize the different caching strategies proposed there .",
    "we derive a new outer bound on the tradeoff of cache size and rate in section  slowromancap4@ by generalizing an example in  @xcite . in section  slowromancap5@ , we calculate the minimum number of files beyond which benefits of caching become small .",
    "we finish with a short discussion in section  slowromancap6@.",
    "consider a system ( see fig .",
    "1 ) with @xmath4 users connected to the central server through a shared , error free link . the server has access to the database containing @xmath5 files @xmath6 , of @xmath7 bits each , all independent and uniformly distributed .",
    "each user has access to a cache @xmath8 of size @xmath9 bits for some real number @xmath0 @xmath10 @xmath11 $ ] .",
    "( nodea ) ; ( spreadout ) ; ( framematrix ) ( frame1 ) ; & ( frame2 ) ; & ( frame3 ) ; + ; ( fram1 ) ; ( fram2 ) ; ( fram3 ) ; ( nodea ) - > ( spreadout ) ; ( name)server ; ( name1)shared link ; ( name2)@xmath4 users ; ( name3)caches ; ( spreadout.north )  ( frame1.north ) ; ( spreadout.north )  ( frame2.north ) ; ( spreadout.north )  ( frame3.north ) ; ( fram3.north east ) + + ( 0.2,0.03 ) edge + + ( 0,-0.55)(fram3.south east ) node[right = 0.2 cm of nodea]@xmath5 files ; ( nodea.north east ) + + ( 0.2,0.075 ) edge + + ( 0,-1.35)(nodea.south east ) node[right = 0.2 cm of fram3]size @xmath0 ;    in the placement phase , the user fills the content of its cache by accessing the database . in the delivery phase ,",
    "user @xmath12 requests one of the files @xmath13 from the database .",
    "the server knows all the requests and transmits a signal @xmath14 of size at most @xmath15 bits , where we call @xmath1 the rate and @xmath16 the file request vector . using the content @xmath8 of its cache and the signal received @xmath14",
    ", each user @xmath12 must decode its requested file @xmath13 .",
    "for the rest of the paper we will be expressing @xmath1 and @xmath0 as well as entropies and mutual informations in units of @xmath7 bits .    *",
    "definition 1*. the memory - rate pair @xmath17 is _ achievable _ if for every @xmath18 and every large enough file size @xmath7 there exists an @xmath17 caching scheme such that the probability of error in decoding the required file is less than @xmath19 for each request vector .",
    "we define the optimal _ memory - rate tradeoff _ as @xmath20",
    "we summarize the three strategies given in  @xcite . here",
    ", coding refers to taking linear combinations of the requested files .",
    "there is no coding involved in this strategy .",
    "each user caches @xmath21 fraction of each file in the placement phase and in the delivery phase the @xmath22 fraction of the file that is not available to the user is transmitted by the server . since there are @xmath5 files , and the size of each file is @xmath7 bits , the cache size of each user is @xmath9 bits . in the worst case , when no two users request the same file , for each of the @xmath4 users , the server needs to transmit the remaining @xmath22 part of each file .",
    "this gives an achievable rate @xmath23 which is , @xmath24 there are two factors , @xmath4 which is the rate without caching and @xmath22 , which is the gain because of the availability of caches at the end user referred to as _ local caching gain_. when the number of users is more than the number of files then an additional gain of @xmath25 is obtained .      in this strategy , as mentioned before , the aim is to multicast  ( combine various files meant for different users ) in the delivery phase . in the placement phase , each file is divided into @xmath26 equal - sized parts , and each user caches @xmath27 bits of each file such that every @xmath28 set of users have one part of each file in common . for the delivery phase ,",
    "consider any set of @xmath29 users .",
    "each user in the set will require a part of the requested file that is present at the remaining @xmath28 users in the set .",
    "the central server sends a linear combination of all the @xmath29 requested parts .",
    "similar linear combinations are sent by considering all possible sets of @xmath29 users .",
    "this gives an achievable rate @xmath30 of  @xcite , @xmath31 in addition to the _ local caching gain _ as explained in section [ subsection : uncoded ] , coded caching achieves an additional gain of @xmath32 which is the _ global caching gain_.      the achievable rate of section  [ subsection : coded ] can be further improved by coded content placement . for @xmath33 ,",
    "coded content placement strategy has a lower rate compared to coded caching strategy which improves the rate in the region @xmath34 .",
    "we illustrate this with an example .",
    "consider the case of @xmath35 and @xmath36 . in this strategy , we split the three files @xmath37 into three sub files i.e. , @xmath38 , @xmath39 and @xmath40 .",
    "the caches are stored with @xmath41 and @xmath42 .",
    "consider that user one requests file a , user two requests file b and user three request file c. the server satisfies the requests by transmitting ( @xmath43 ) at rate @xmath44 which does better than the achievable rate @xmath45 given by   as shown in fig .  2 .",
    "in this section , we first summarize the cut - set bound of  @xcite and then give an improved bound .",
    "let @xmath47 . consider @xmath48 , which is transmitted during the delivery phase , on the shared link when the first @xmath49 users request files @xmath50 , respectively .",
    "then , @xmath48 along with the caches @xmath51 of the first @xmath49 users must determine the files @xmath52 . in a similar manner",
    "consider @xmath53 . now",
    "@xmath54 and @xmath55 must determine @xmath56 . since @xmath57 transmissions of size @xmath1 and @xmath49 caches of size @xmath0 determines @xmath58 files we have , @xmath59 solving for @xmath46 and optimizing over all @xmath49",
    ", we obtain @xmath60",
    "in this section , we give an example to illustrate how the lower bound on @xmath61 can be tightened compared to the cut - set bound   by generalizing the approach used in  ( * ? ? ? * appendix ) .",
    "* example 1 . * consider the case of @xmath62 files and @xmath63 users .",
    "we consider @xmath64 and @xmath65 , the signals transmitted by the server for the request vectors @xmath66 and @xmath67 , respectively .",
    "@xmath68 can be decoded by user @xmath69 using its cache @xmath70 and @xmath71 .",
    "similarly , user @xmath72 can decode file @xmath68 using @xmath73 and @xmath74 . in the same way ,",
    "users @xmath75 and @xmath76 can decode file @xmath68 from their caches along with @xmath77 and @xmath65 , respectively .",
    "now , notice that @xmath78 and @xmath79 can be decoded by combining @xmath71 , @xmath74 and the caches @xmath70 of user @xmath69 and @xmath73 of user @xmath72 .",
    "specifically , user @xmath69 with its cache @xmath70 and @xmath74 can decode file @xmath79 and user @xmath72 with its cache @xmath73 and @xmath71 can decode file @xmath78 . in the same way",
    ", files @xmath78 and @xmath79 can also be decoded by combining @xmath77 , @xmath65 and the caches @xmath80 of user @xmath75 and @xmath81 of user @xmath76 .",
    "this combining refers to step ( b ) in the chain of inequalities below and is key to obtaining our lower bound .",
    "the remaining files @xmath82 can be decoded by taking all the @xmath76 request vectors together and using the corresponding cache of the user that requests that file .",
    "the steps given below demonstrates this procedure . recall that @xmath1 , @xmath0 , entropies , and mutual informations are all in units of @xmath7  bits . for any achievable memory - rate pair @xmath2 , ( below we suppress the small terms resulting from fano s inequality )",
    "@xmath83 where ( a ) follows from fano s inequality since @xmath68 can be decoded from each of @xmath84 and @xmath85 , and ( b ) holds because @xmath86 similarly ( c ) follows from fano s inequality because @xmath87 can be decoded from each of @xmath88 and @xmath89 .",
    "similarly , ( d ) holds because @xmath82 can be decoded from + @xmath90 . combining the above results we get , @xmath91",
    "this is an improvement over the cut - set bound which gives @xmath92 .",
    "the coded caching achievable strategy gives @xmath93 at @xmath94      our main result is the following lower bound on the optimal @xmath17 tradeoff .",
    "recall that @xmath95 are in units of @xmath7  bits .",
    "+   + * theorem 1 . *",
    "+ for @xmath96 and @xmath97 users , if @xmath17 is achievable ,    a.   then for @xmath98 , @xmath99 where , @xmath100 b.   then for @xmath101 , @xmath102    for @xmath103 and @xmath104 users , if @xmath17 is achievable ,    a.   then for @xmath105 , @xmath106 where , @xmath107 b.   then for @xmath108 , @xmath109    a proof is given in the appendix .",
    "the next example also shows that , in general , theorem 1 is tighter than the cut - set bound  .",
    "* example 2 . *",
    "consider the case of @xmath110 files and @xmath111 users .",
    "the cut - set lower bound  , the lower bound of   for @xmath112 , and the achievable tradeoffs of   and   are shown in figure  2 .    ; ; ; ; ; ; ; ;",
    "for any caching system , if the number of files grows we expect the reduction in @xmath1 to be small , for a fixed number of users @xmath4 and cache size @xmath0 . in general ,",
    "each user may find only a small fraction of the file requested in its cache .",
    "this results in the server having to send a significant part of the requested file in most cases .",
    "so the decrease in rate @xmath1 for a fixed @xmath0 is negligible .",
    "hence , having a large database decreases the benefits of caching .    to find the minimum database size for a fixed number of users for which caching becomes ineffective",
    ", we consider the quantity @xmath113 , which arguably measures the cost of operating a caching system , where @xmath96 is the relative cost of cache memory ( per user ) versus server bandwidth .",
    "clearly , @xmath114 since @xmath115 for @xmath116 , as the central server must serve the whole file when there is no cache .",
    "we are interested in finding the smallest size of the database , such that @xmath117 .",
    "* definition 2 . * for any @xmath4 users and @xmath96 , @xmath118 is the minimum number of files such that @xmath119    the following three lemmas give upper and lower bounds on @xmath120 .",
    "lemma 1 uses the cut set bound to derive an upper bound on @xmath118 .",
    "an improved upper bound using theorem 1 is given in lemma 2 .",
    "a lower bound on @xmath118 using the coded caching achievable strategy of  @xcite is given in lemma 3 .",
    "+ * lemma 1 . * for @xmath4 users and @xmath121 , + @xmath122 using the lower bound we derived in theorem 1 , we can improve upon this bound .",
    "we illustrate this with an example .",
    "+   + * example 3 . *",
    "consider the case when there are @xmath63 users and instead of @xmath123 files considered in section  [ subsection : bound_example ] , suppose we increase the number of files to @xmath124 .",
    "following the same procedure as in example 1 , we get @xmath125 thus upper bound on @xmath126 this is an improvement compared to @xmath127 files given by lemma 1",
    ". +   + * lemma 2 . * for @xmath97 users and @xmath121 , + @xmath128 for @xmath104 users and @xmath129 , + @xmath130 * lemma 3 . * for @xmath4 users and @xmath121 , + @xmath131 the proofs of the lemmas are given in the appendix . from the lemmas it is clear that @xmath132 .",
    "thus , it is important to characterize the smallest pre - constant to the @xmath3 term which is concretely defined as , @xmath133 the following theorem directly follows from the lemmas .",
    "* theorem 2 . * for any @xmath4 users , @xmath96 and @xmath118 , @xmath134 is bounded by + @xmath135    since the minimum number of files @xmath118 such that @xmath136 is of @xmath3 , we can conclude that the effectiveness of caching becomes small when the number of files becomes comparable to the square of the number of users .",
    "in this paper , we consider the case when the number of files is large compared to the number of users in a caching system .",
    "first , we studied inner and outer bounds on the memory - rate tradeoff and present an improved outer bound by generalizing the approach used in  @xcite .",
    "we showed that when the number of files is comparable to the square of the number of users , the benefits of caching become negligible .",
    "we defined the @xmath137 to be the pre - constant to the @xmath3 term . using the improved bound ,",
    "we obtain a better upper bound to this pre - constant .",
    "we studied the worst - case shared link load ( as in  @xcite ) .",
    "we expect similar results to hold for the expected load of the shared link under popularity distributions on files with a large number of popular files .",
    "this work was supported in part by information technology research academy ( itra ) , government of india under itra - mobile grant itra/15(64)/mobile / useaadwn/01",
    ".    1 m. a. maddah - ali and u. niesen , `` fundamental limits of caching , '' _ ieee trans .",
    "theory , _ vol .",
    "5 , pp . 28562867 , may 2014 .",
    "r. ahlswede , n. cai , s .- y",
    ". r. li , and r. w. yeung , `` network information flow , '' _ ieee trans .",
    "inf . theory _ , vol .",
    "46 , pp . 12041216 , apr . 2000 .",
    "u. niesen and m. a. maddah - ali , `` coded caching with nonuniform demands , '' in _ proc . of ieee infocom workshops _ ,",
    "221 - 226 , may 2014 .",
    "r. pedarsani , m. a. maddah - ali , and u. niesen , `` online coded caching , '' in _ proc . of ieee icc _ , pp .",
    "1878 - 1883 , june 2014 .",
    "m. a. maddah - ali and u. niesen , `` decentralized coded caching attains order - optimal memory - rate tradeoff , '' in _ proc . of 51st annual allerton conference on communication , control , and computing _ , pp .",
    "421 - 427 , oct . 2013 .",
    "n. karamchandani , u. niesen , m. a. maddah - ali , and s. diggavi , `` hierarchical coded caching , '' in _ proc . of ieee isit _ , pp .",
    "2142 - 2146 , july 2014 .",
    "we will first obtain a lower bound on @xmath138 , for any achievable @xmath17 , i.e. , the case of @xmath112 .",
    "for this , we first consider the case of @xmath139 , where @xmath140 is as defined in  .",
    "note that @xmath141 of   is @xmath142 in this case .",
    "recall example 1 where @xmath76 request vectors were considered .",
    "similarly , we consider the following @xmath143 request vectors    @xmath144    [ eq : request - vectors ]    of these , we require that @xmath145 @xmath146 @xmath147 @xmath148 be distinct .",
    "hence , we will require that @xmath149 .",
    "furthermore , we want these along with the @xmath150 s , i.e. , @xmath145 @xmath146 @xmath147 @xmath151 @xmath152 @xmath147 @xmath153 to include all of @xmath154 . hence , we need @xmath140 to be such that @xmath155 we can verify that the choice of @xmath140 in  , which is reproduced below , satisfies this .",
    "@xmath156    consider the first request vector and the first @xmath140 users .",
    "user @xmath69 requests file @xmath68 , and the rest @xmath157 users request files @xmath158 . similarly , in the second request vector , user @xmath72 requests file @xmath68 and the rest @xmath157 users request files @xmath159 . in the same manner for the @xmath140-th request vector ,",
    "user @xmath140 requests file @xmath68 and the first @xmath157 users request files @xmath160",
    ". these @xmath161 are @xmath162 distinct files in the database . for the second set of @xmath140 request vectors , users @xmath163 to @xmath143 request the same files as users @xmath69 to @xmath140 in the first @xmath140 request vectors .",
    "for the first @xmath140 request vectors , users @xmath163 to @xmath143 requests @xmath164 files @xmath165 . for the second @xmath140 request vectors , users @xmath69 to @xmath140 requests @xmath164 files @xmath166 . by our choices",
    "we have ensured that these @xmath167 files contain the remaining @xmath168 distinct files .",
    "we now follow the same procedure as in example 1 .",
    "first file @xmath68 can be decoded from all the @xmath143 request vectors .",
    "this is done by considering the first request vector and cache @xmath70 , the second request vector and cache @xmath73 and so on for the remaining request vectors .",
    "then , the first set of @xmath140 vectors and the second set of @xmath140 vectors are separately combined to decode files @xmath169 . from the first @xmath140 request vectors and caches",
    "@xmath170 the files @xmath169 can be decoded .",
    "similarly , from the second set of @xmath140 vectors and @xmath171 the same set of files can be decoded .",
    "the rest @xmath168 files which are included in @xmath165 can be decoded by considering all the @xmath143 request vectors together using all the caches @xmath172 .",
    "all @xmath1 , @xmath0 , entropies and mutual informations are in units of @xmath7 bits and , as before , we suppress small terms from fano s inequality .",
    "so for any achievable memory - rate pair @xmath17 and @xmath173 , @xmath174 where ( i ) is similar to steps  ( a ) and  ( b ) together in example  1 . in step",
    "( ii ) , which is similar to step ( c ) in example  1 .",
    "we define @xmath175 step  ( iii ) is similar to step",
    "( d ) of example  1 . therefore , for @xmath139 , @xmath176 notice that @xmath177 for @xmath139 , and the definition of @xmath140 is such that @xmath178 .",
    "thus we have proved the theorem for @xmath112 , @xmath139 .    when @xmath179 , we defined @xmath180 as the smallest integer such that @xmath181 .",
    "notice that since @xmath182 , @xmath183 . recall that we had considered @xmath143 vectors .",
    "now we consider @xmath184 request vectors .",
    "we follow the same steps as above with @xmath140 replaced by @xmath185 . for this",
    ", we will now need @xmath5 to satisfy ( cf .  )",
    "@xmath186 it is easy to verify that the left inequality follows from the definitions of @xmath140 and @xmath141 .",
    "hence , for @xmath187 , @xmath188 for @xmath179 and @xmath189 , we proceed as before , but now the number of files @xmath5 is larger than the number of indices @xmath190 s , @xmath150 s , and 1 .",
    "we may set them all to be distinct files and hence , in step ( iii ) , instead of decoding @xmath191 files , we now have @xmath192 files .",
    "thus , @xmath193 this completes the proof for @xmath112 . for generalizing this to any @xmath121 , we first consider the case of @xmath98 . for the case of @xmath139 ( i.e. , @xmath177 )",
    ", we consider @xmath194 sets of @xmath143 request vectors similar to  . the condition analogous to",
    "is now @xmath195 which can be verified to hold for @xmath140 as defined in with @xmath177 .",
    "now , in step  ( i ) , @xmath194 files can be decoded by decoding one file from each of @xmath194 sets of @xmath143 request vectors . then , in step  ( ii ) , we may now consider @xmath196 sets of @xmath140 vectors each such that @xmath197 files can be decoded from each set .",
    "the remaining @xmath198 can be decoded by combining all the @xmath199 vectors .",
    "hence for @xmath139 , @xmath200 since @xmath201 , we have , for @xmath139 , @xmath202 the proof for @xmath203 is along the same lines as for @xmath112 ; as above , we now work with @xmath204 request vectors instead of @xmath199 .",
    "when @xmath101 we consider @xmath194 request vectors such that one of the users , say the first user , requests all @xmath5 files between these @xmath194 request vectors . from this",
    "we get , @xmath205 which gives @xmath206 .",
    "this completes the proof for @xmath207 .",
    "now we prove the second part of the theorem  1 when @xmath103 .",
    "we first consider the case of @xmath208 , where @xmath140 is as defined in  .",
    "note that @xmath141 of   is @xmath142 in this case . now consider the following @xmath143 request vectors .",
    "@xmath209    [ eq : request - vectors2 ]    of these , we require that @xmath210 @xmath147 @xmath211 be distinct .",
    "hence , we will require that @xmath212 .",
    "furthermore , we want these along with the @xmath150 s , i.e. , @xmath210 @xmath147 @xmath211 @xmath213 @xmath147 @xmath214 to include all of @xmath154 . hence , we need @xmath140 to be such that @xmath215 we can verify that the choice of @xmath140 in  , which is reproduced below , satisfies this .",
    "@xmath216 consider the first request vector and the first @xmath217 users .",
    "users @xmath69 to @xmath218 request files @xmath68 to @xmath219 and the rest @xmath220 users request files @xmath221 . similarly in the second request vector , users @xmath222 to @xmath223 request files @xmath68 to @xmath219 and the rest @xmath220 users request files @xmath224 .",
    "this proceeds in the same manner until the @xmath140-th request vector .",
    "these @xmath225 are @xmath226 distinct files in the database . for the second set of @xmath140 request vectors , users @xmath227 to @xmath228 request the same files as users @xmath69 to @xmath217 in the first @xmath140 request vectors .",
    "for the first @xmath140 request vectors , users @xmath227 to @xmath228 requests @xmath229 files @xmath230 . for the second @xmath140 request vectors , users @xmath69 to @xmath140 requests @xmath229 files @xmath231 . by our choices",
    "we have ensured that these @xmath232 files contain the remaining @xmath233 distinct files .",
    "we now follow the similar procedure as in the case when @xmath234 .",
    "first files @xmath68 to @xmath219 can be decoded from all the @xmath143 request vectors .",
    "this is done by considering the first request vector and caches @xmath70 to @xmath235 , the second request vector and caches @xmath236 to @xmath237 and so on for the remaining request vectors .",
    "then , the first set of @xmath140 vectors and the second set of @xmath140 vectors are separately combined to decode files @xmath238 . from the first @xmath140 request vectors and caches",
    "@xmath239 the files @xmath238 can be decoded .",
    "similarly , from the second set of @xmath140 vectors and @xmath240 the same set of files can be decoded .",
    "the rest @xmath233 files which are included in @xmath241 can be decoded by considering all the @xmath143 request vectors together using all the caches @xmath242 .",
    "all @xmath1 , @xmath0 , entropies and mutual informations are in units of @xmath7 bits .",
    "so for any achievable memory - rate pair @xmath17 and @xmath243 , @xmath244 since @xmath245 , for @xmath246 , @xmath247 the proof for @xmath248 is similar to the case of @xmath249 .",
    "here we find the least integer @xmath141 such that @xmath250 .",
    "notice that since @xmath251 , @xmath183 .",
    "now we consider @xmath184 request vectors instead of @xmath143 . for this , we will now need @xmath5 to satisfy @xmath252 it is easy to verify that the left inequality follows from the definitions of @xmath140 and @xmath141 .",
    "hence , for + @xmath253 , @xmath254 for @xmath255 and @xmath256 , we proceed as before , but now the number of files @xmath5 is larger than the number of indices @xmath190 s , @xmath150 s , and @xmath257 .",
    "we may set them all to be distinct files and hence , in step ( iii ) , instead of decoding @xmath258 files , we now have @xmath259 files .",
    "thus , @xmath260 this completes the proof for @xmath248 .",
    "when @xmath108 we consider @xmath218 caches such that among them all @xmath4 users are included .",
    "we consider one request vector where among the users all the @xmath5 files are requested . since @xmath261 from the @xmath218 caches",
    "all the files can be decoded , we get @xmath262 this completes the proof of theorem 1 when @xmath103 .",
    "_ proof of lemma 1 . _ +   + using equation  , by substituting @xmath263 and @xmath264 , @xmath265 which gives , @xmath266 + _ proof of lemma 2 . _ +   + this proof follows from theorem 1 .",
    "consider the case when @xmath4 is even and @xmath121 .",
    "we want to show that for @xmath267 the lower bound of theorem  1 gives @xmath268 to see this , substitute @xmath5 from   in  - to see that @xmath269 and @xmath177 .",
    "then , the lower bound of   indeed gives @xmath270 .",
    "hence we have for even @xmath4 , @xmath271 to handle odd @xmath4 as well , we note that @xmath118 is a non - decreasing function of @xmath4 for fixed @xmath272 .",
    "hence for @xmath121 and @xmath182 , @xmath128 following the same procedure for @xmath129 we first consider @xmath4 to be such that @xmath273 .",
    "we choose @xmath5 to be , @xmath274 then , the lower bound of   gives @xmath275 .",
    "to find for any @xmath4 , we note that @xmath118 is a non - decreasing function of @xmath4 for fixed @xmath272 . hence for @xmath129 and @xmath251 , @xmath276 summarizing for @xmath97 users and @xmath121 , + @xmath128 for @xmath104 users and @xmath129 , + @xmath130     + _ proof of lemma 3 .",
    "_ +   + to find the minimum number of files such that @xmath277 is @xmath4 for the coded caching strategy explained in section  [ subsection : coded ] notice that , @xmath278 since @xmath0 takes only those values for which @xmath279 as defined by the coded caching strategy we substitute @xmath280 .",
    "solving this we obtain , @xmath281 to show that for all @xmath5 less than  , the scheme satisfies @xmath282 , consider @xmath283 , @xmath284 and substitute in @xmath285 .",
    "we get , @xmath286 hence , + @xmath287"
  ],
  "abstract_text": [
    "<S> replicating or caching popular content in memories distributed across the network is a technique to reduce peak network loads . </S>",
    "<S> conventionally , the performance gain of caching was thought to result from making part of the requested data available closer to end users . </S>",
    "<S> recently , it has been shown that by using a carefully designed technique to store the contents in the cache and coding across data streams a much more significant gain can be achieved in reducing the network load . </S>",
    "<S> inner and outer bounds on the network load v / s cache memory tradeoff were obtained in  @xcite . </S>",
    "<S> we give an improved outer bound on the network load v / s cache memory tradeoff . </S>",
    "<S> we address the question of to what extent caching is effective in reducing the server load when the number of files becomes large as compared to the number of users . </S>",
    "<S> we show that the effectiveness of caching become small when the number of files becomes comparable to the square of the number of users . </S>"
  ]
}