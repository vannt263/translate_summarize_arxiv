{
  "article_text": [
    "in this paper , we consider sums and differences of dependent log - normal random variables and obtain sharp asymptotic formulas , characterizing the tail behavior of distributions of such variables .",
    "we also give applications of the asymptotic formulas established in the present paper to some problems of risk management .",
    "log - normal distributions are rather universal . they are used in business , industry , finance , risk management , economics , biology , ecology , geology , and atmospheric sciences .",
    "a strictly positive random vector @xmath0 such that the vector @xmath1 with @xmath2 , @xmath3 , has an @xmath4-dimensional normal distribution with mean vector @xmath5 and covariance matrix @xmath6 , is called an @xmath4-dimensional log - normal vector with parameters @xmath7 and @xmath6 .",
    "the elements of the matrix @xmath6 will be denoted by @xmath8 .",
    "the distribution of the random vector @xmath9 is called the @xmath4-dimensional log - normal distribution and denoted by @xmath10 . in the present paper",
    ", we make the standing assumption that @xmath11 .",
    "the inverse matrix of the covariance matrix will be denoted by @xmath12 , its elements will be denoted by @xmath13 , and we put @xmath14 , @xmath15 .",
    "the log - normal distribution @xmath10 admits a density defined by @xmath16 where @xmath17 for @xmath3 .",
    "in particular , the one - dimensional log - normal density with mean @xmath18 and variance @xmath19 is given by @xmath20 the interested reader may find information about the history and the applications of log - normal distributions in the following publications : @xcite .    in the present paper , we study sums and differences of lognormal variables .",
    "the general setting is as follows .",
    "let @xmath1 be an @xmath4-dimensional gaussian random variable such as above .",
    "for every integer @xmath21 with @xmath22 , we consider the random variable @xmath23 the support of @xmath24 is equal to @xmath25 for @xmath26 , and to @xmath27 for @xmath28 . for @xmath28 , the variable @xmath29",
    "is denoted simply by @xmath30 .",
    "the symbols @xmath31 and @xmath32 will stand for the density of @xmath24 and @xmath30 , respectively .",
    "our main goal in this paper is to characterize the tail behavior of the distribution of the random variable @xmath24 .",
    "we are mainly interested in the asymptotic behavior of the right tail of the variables @xmath24 , @xmath33 , that is , the behavior of @xmath34 $ ] and @xmath35 as @xmath36 , as well as the behavior of the left tail of @xmath30 ( as @xmath37 ) .",
    "the right tail behavior of the distribution function of @xmath30 was completely characterized in the paper @xcite of asmussen and rojas - nandayapa , while in the paper @xcite of gao , xu , and ye , a similar characterization was obtained for the density .",
    "the left tail behavior of @xmath24 , @xmath33 , can be deduced from that of the right tail by exchanging the variables . since",
    "positive coefficients can be incorporated into the mean vector of @xmath38 , our results provide a complete characterization of the tail behavior of a linear combination @xmath39 , @xmath40 , of components of a log - normal random vector @xmath41 .",
    "next , we will provide a short description of various publications related to the main topics of the present paper .",
    "we refer the interested reader to those publications and the references therein for more details . in asmussen",
    "@xcite , estimations of tail probabilities of sums of correlated lognormal variables via simulation are provided .",
    "the paper @xcite of senarante and tellambura deals with numerical techniques for the computation of the distribution function of a log - normal sum . in tellambura - senarante @xcite",
    ", the distribution of a log - normal sum is derived as an alternating series , while tellambura @xcite provides bounds for the distribution function of a sum of 2 or 3 correlated log - normal variables , and also for a sum of any number of equally - correlated log - normal variables . in baruch - kaufman and",
    "baruch - kaufman - glasser @xcite , the authors find approximations to the density of a sum of log - normal random variables , while in szyszkowicz - yanikomeroglu @xcite , the best log - normal fit to a tail of a log - normal sum is introduced and studied .",
    "for the right tail , the best log - normal fit is given in the paper @xcite of asmussen and rojas - nandayapa .",
    "the authors of @xcite also discuss the best log - normal fit to the left tail , conjecture how it may look , and check their conjecture by simulation .",
    "note that the asymptotic behavor of the left tail for the sum of two log - normals was completely characterized in gao - xu - ye @xcite , while for any number of correlated lognormals a sharp asymptotic formula for the left tail is provided in the present paper .",
    "the paper @xcite of vanduffel et al .",
    "is devoted to approximations of the distribution function of a sum of log - normal random variables by the distribution function of the conditional expectation of such a sum with respect to an auxiliary conditioning random variable .",
    "the authors of @xcite also show how to optimally choose a conditioning random variable .",
    "stochastic models with heavy tails , including the log - normal models , are sudied in the dissertation @xcite of rojas - nandayapa .    in financial mathematics ,",
    "estimates for the tails of sums of correlated log - normal variables are used in the theory of basket options and asian options ( see an explanation in @xcite ) , and spread options ( see carmona - durrleman @xcite ) .",
    "the paper @xcite of lo develops a unified approach to estimations of distributions of sums and differences of two log - normal variables .",
    "lo uses the lie - trotter splitting formula from semigroup theory , which yields a first order asymptotic approximation @xmath42 to the semigroup @xmath43 for small values of @xmath44 .",
    "lo s approach works in the dynamic case and only for two correlated log - normal variables and small values of the parameter .",
    "gao , xu , and ye @xcite provide asymptotic formulas ( without error estimates ) for the left tail of the distirbution of the sum of two dependent lognormal variables in the regular cases .",
    "the log - normal distribution is a special example of a subexponential distribution ( see @xcite for the definition of subexponentiality ) .",
    "numerous publications were devoted to tail estimates for distributions of sums or more general functions of dependent sub - exponential random variables ( see @xcite and the references therein ) .",
    "various bounds for tails of functions of general random vectors with fixed marginals were obtained in the papers @xcite-@xcite of embrechts and puccetti .",
    "we hope that the techniques developed in the present paper may be useful in the study of the tail behavior of distributions of functions of more general random variables than the log - normal ones",
    ".    we will next briefly overview the contents of the present paper .",
    "section [ s : nachalo ] deals with the left tail asymptotics of sums of lognormal variables .",
    "this section is split into two subsections : subsection [ ss : fmr1 ] , where we formulate and discuss our results concerning the left tail asymptotics of sums of log - normals , and subsection [ ss : proofs1 ] , containing the proofs of those results .",
    "in subsection [ ss : fmr1 ] , we first provide sharp asymptotic formulas with error estimates for the distribution function and the distribution density in the special case ( see lemma [ easy.prop ] ) when the row sums of the inverse matrix of the covariance matrix are all strictly positive . here",
    "we can apply laplace s method to the integral , characterizing the distribution density of the log - normal sum .",
    "next , we formulate asymptotic formulas for the distribution function and the distribution density in the general case , under rather mild nondegeneracy conditions ( theorem [ gen.thm ] and corollary [ c : corr ] )",
    ". this is done by relating the tail asymptotics of the sum of log - normals to the quadratic optimization problem @xmath45 where @xmath46 is the set of vectors in @xmath47 whose components are all non - negative and sum up to one . in particular , the leading term in the asymptotics for both the distribution function and the density is given by @xmath48 this is in sharp contrast with the findings of @xcite for the asymptotics of the _ right tail _ of the sum of log - normals , where the leading term is @xmath49 as an application of theorem [ gen.thm ] and corollary [ c : corr ] , we characterize the asymptotic behavior of conditional laplace transforms of multivariate log - normal random variables ( see corollaries [ laplace.cor ] and [ laplacedens.cor ] ) .",
    "the estimates for the conditional laplace transform are used in section [ rm.sec ] , which deals with stress testing of log - normal portfolios .",
    "section [ s : tail1 ] is concerned with extensions of the results obtained in section [ s : nachalo ] for log - normal sums to the case of the difference of two such sums ( see the random variable in ( [ e : bass ] ) ) .",
    "these extensions are not trivial , and they are new even in simple cases . we find sharp asymptotic formulas for right - tails of distriubtions of such differences .",
    "the structure of the proofs of the assertions established in section [ s : tail1 ] is similar to that in section [ s : nachalo ] .",
    "however , the details are more complicated .",
    "we start with a special case where laplace s method can be applied directly ( see lemma [ t : standard ] ) , and reduce the general case to the special one using quadratic programming methods ( see theorem [ t : present ] ) .",
    "the asymptotic behavior of the conditional laplace transform is characterized in corollary [ laplace2.cor ] .    in section [ num.sec ]",
    "we analyze the performance of our asymptotic forumals via numerical examples , by comparing the theoretical results with monte carlo computations .",
    "the convergence turns out to be quite slow , which is consistent with logarithmic error bounds in our main results .",
    "however , the asymptotic formulas provide a good order of magnitude approximation for a wide range of values of @xmath50 , which makes it possible to use them to design variance reduction methods for precise evaluation of the tail event probabilities by monte carlo .",
    "the last part of the paper ( section [ rm.sec ] ) considers applications of our asymptotic formulas to risk management in the context of the multidimensional black - scholes model .",
    "this model , which represents stock prices as exponentials of correlated brownian motions , remains widely used for the analysis of large portfolios .",
    "a good introduction to risk management techniques is the book @xcite by macneil , frei , and embrechts .",
    "our asymptotic theory provides two types of insights .",
    "first , it allows to quantify the tail behavior of portfolios of log - normal stocks .",
    "for example , for portfolios with positive weights , the leading term of the probability of a large downside move in the value of the portfolio is given by .",
    "this means that measures the risk of the portfolio in a downturn .",
    "second , it provides an understanding of the behavior of individual assets under various adverse scenarios .",
    "for instance , we consider a typical stress scenario when the normalized value of a benchmark portfolio ( or index ) drops to @xmath50 with @xmath50 small .",
    "theorem 4 characterizes the asymptotic behavior of conditional expectations of the individual assets in the original portfolio under such an adverse scenario , when the benchmark portfolio has only positive weights .",
    "this theorem shows that the assets in a market can be categorized into two classes : those for which conditional expectations decay proportionally to @xmath50 as @xmath51 ( safe assets ) , and those assets , for which conditional expectations decay much faster than @xmath50 ( dangerous assets ) .",
    "the safe assets are exactly those which have strictly positive weights in the solution to the quadratic programming problem .",
    "results such as theorem 4 may be employed for systematic construction of stress tests , which banks and investment firms are required to conduct by the regulatory bodies .",
    "the present section studies the left tail asymptotics of the random variable @xmath52 .",
    "the section is subdivided into two subsections . in the first of them , we formulate and discuss our results , while the second subsection includes the proofs of those statements .",
    "denote by @xmath46 the n - dimensional simplex defined by @xmath53 and let @xmath54 be the unique vector such that @xmath55 the existence and uniqueness of @xmath56 follows from the non - degeneracy of the matrix @xmath6 . in the case where @xmath57 for @xmath58 , @xmath59 which means that @xmath60 for @xmath58 . in the general case , we let @xmath61 @xmath62 @xmath63 with @xmath64 , and @xmath65 with @xmath66 .",
    "the inverse matrix of @xmath67 is denoted by @xmath68 and its elements and row sums by @xmath69 and @xmath70 .    in the present subsection",
    ", we are only dealing with the sum of the exponentials of the random variables @xmath71 .",
    "since these variables are exchangeable , we can assume with no loss of generality that for the covariance matrix @xmath6 , @xmath72 with @xmath73 . by the strict convexity of the objective function , the minimizer of @xmath74 coincides with the first @xmath75 components of @xmath56 and therefore belongs to the interior of the set @xmath76 .",
    "the minimizer over @xmath77 then coincides with the minimizer over the set @xmath78 , which means that @xmath79 or , equivalently , @xmath80 since @xmath81 ( the matrix @xmath82 is positive definite ) , this implies that @xmath83 for @xmath84 .",
    "equation also leads to the following useful formula : @xmath85    the following preliminary result characterizes the asymptotic behavior of the distribution function and the density of the random variable @xmath30 in the tail regime in the special case where @xmath86 for all @xmath58 , or , equivalently , @xmath87    [ easy.prop ] assume that @xmath88 .",
    "then , as @xmath51 , @xmath89 and @xmath90=\\frac{c}{a_1+\\dots+a_n}\\left(\\log\\frac{1}{x}\\right)^{-\\frac{1+n}{2}}x^{\\sum_{k=1}^na_k\\left(\\log\\frac{a_1+\\cdots+a_n}{a_k}+\\mu_k\\right ) } \\nonumber \\\\ & \\quad\\exp\\left\\{-\\frac{1}{2}(a_1+\\cdots+a_n)\\log^2\\frac{1}{x}\\right\\ }   \\left(1+o\\left(\\left(\\log\\frac{1}{x}\\right)^{-1}\\right)\\right ) , \\label{e : prof}\\end{aligned}\\ ] ] where @xmath91    next , we focus on the general case , where some of the numbers @xmath92 are possibly negative",
    ". we shall need the following assumption .",
    "* for every @xmath93 , @xmath94 where @xmath95 satisfies @xmath96 if @xmath97 and @xmath98 otherwise .",
    "assumption @xmath99 is equivalent to the following : @xmath100 for every @xmath93 .",
    "indeed , the gradient of the minimization functional @xmath101 at the point @xmath56 is given by @xmath102 , and for @xmath103 small enough , @xmath104 clearly belongs to @xmath46 .",
    "therefore @xmath105 would contradict the fact that @xmath56 is the minimizer .",
    "assumption @xmath99 is a natural nondegeneracy condition for our problem .",
    "the following straightforward equality gives a relation between the optimization problem in and a similar problem without the normalization constraint : @xmath106 a minimizer @xmath107 of the right - hand side can therefore be constructed from the minimizer @xmath56 of as follows : @xmath108 now , introducing the vector @xmath109 of lagrange multipliers for the positivity constraints on the right - hand side of , we get the lagrangian @xmath110 at the extremum therefore , @xmath111 , or in other words , @xmath112 therefore , assumption @xmath99 simply states that for the constraints , which are saturated , the lagrange multipliers are not equal to zero ( since the constraints are inequalities , this is equivalent to the strict positivity for the multipliers ) . this is generally true , except when the solution of the unconstrained problem belongs to the boundary of the domain defined by the constraints .",
    "the next assertion provides a sharp asymptotic formula with error estimate for the distribution function of the random variable @xmath30 , under assumption @xmath99",
    ". a similar formula for the distribution density of @xmath30 will be formulated below ( see corollary [ c : corr ] ) .    [",
    "gen.thm ] suppose assumption @xmath99 holds . then , as @xmath37 , @xmath90=\\frac{c}{\\bar a_1+\\dots+\\bar a_{\\bar      n}}\\left(\\log\\frac{1}{x}\\right)^{-\\frac {      1+\\bar n}{2}}x^{\\sum_{k=1}^{\\bar n}\\bar a_k\\left(\\log\\frac{\\bar        a_1+\\cdots+\\bar a_n}{\\bar a_k}+\\bar \\mu_k\\right ) } \\nonumber \\\\ & \\quad\\exp\\left\\{-\\frac{1}{2}(\\bar a_1+\\cdots+\\bar a_{\\bar n})\\log^2\\frac{1}{x}\\right\\ }   \\left(1+o\\left(\\left(\\log\\frac{1}{x}\\right)^{-1}\\right)\\right),\\label{e : generass}\\end{aligned}\\ ] ] where @xmath113    formula can be rewritten in terms of the solution @xmath56 to the quadratic programming problem in as follows : @xmath90=\\widetilde c \\left(\\log\\frac{1}{x}\\right)^{-\\frac {      1+\\bar n}{2}}\\exp\\left\\{-\\frac{(\\log x-\\bar w^\\perp \\mu -\\mathcal e(\\bar w))^2}{2 \\bar w^\\perp { { \\eufrak b}}\\bar w}\\right\\ }       \\nonumber \\\\ & \\quad\\times\\left(1+o\\left(|\\log x|^{-1}\\right)\\right),\\label{genw.eq}\\end{aligned}\\ ] ] where @xmath114 and @xmath115 is a certain constant",
    ". the asymptotic behavior of the left tail of the sum of log - normal random variables with positive coefficients is thus intimately related to the quadratic programming problem formulated in . in particular , this problem determines which components of the random vector influence the tail behavior .",
    "theorem [ gen.thm ] and corollary [ c : corr ] below allow us to estimate various conditional expectations .",
    "the next assertion provides a characterization of the limiting conditional law of the laplace transform of @xmath71 , given that @xmath116 .",
    "[ laplace.cor ] suppose assumption @xmath99 holds . then , as @xmath37 , for any @xmath117 , @xmath118=x^{\\sum_{i=1}^n u_i \\sum_{j=1}^{\\bar n }    \\bar a_j b_{ij } } \\\\ & \\exp\\left\\ { \\sum_{i=1}^n u_i \\left(\\mu_i - \\sum_{p , q=1}^{\\bar n } b_{pi } \\bar a_{pq }   \\left(\\log\\frac{\\bar a_1+\\dots",
    "+ \\bar a_{\\bar          n}}{\\bar a_q } + \\bar \\mu_q\\right)\\right ) \\right\\ } \\\\ & \\exp\\left\\{\\frac{1}{2}\\sum_{i , j\\notin\\bar i } u_i u_j \\left(b_{ij } - \\sum_{p , q=1}^{\\bar n } \\bar    a_{pq } b_{pi}b_{qj }   \\right)\\right\\ }   \\left(1+o\\left(\\left(\\log        \\frac{1}{x } \\right)^{-1}\\right)\\right).\\end{aligned}\\ ] ]    [ remgt1 ] note that @xmath119_i } { \\bar w^\\perp { { \\eufrak b}}\\bar w } \\left\\{\\begin{aligned}=1,\\quad i",
    "\\in \\bar i \\\\",
    "> 1 , \\quad i\\notin \\bar i\\end{aligned}\\right.\\ ] ] by assumption @xmath99 .",
    "let @xmath120_i } { \\bar w^\\perp { { \\eufrak b}}\\bar w } - 1.\\ ] ] then , corollary [ laplace.cor ] implies that the conditional distribution of the vector @xmath121 given @xmath122 , converges weakly to the ( degenerate ) gaussian law with mean @xmath123 and covariance matrix @xmath124 where @xmath125 note that for @xmath126 , the expression for @xmath127 simplifies to @xmath128    the next statement concerns the asymptotics of the distribution density @xmath32 of the random variable @xmath30 .",
    "[ c : corr ] suppose assumption @xmath99 holds .",
    "then , as @xmath37 , @xmath129 where the constant @xmath130 is given by ( [ e : for1 ] )",
    ".    corollary [ c : corr ] implies that the conditional expectation in corollary [ laplace.cor ] can be taken with respect to the event @xmath131 .",
    "[ laplacedens.cor ] suppose assumption @xmath99 holds . then , as @xmath37 , for any @xmath117 , @xmath132=x^{\\sum_{i=1}^nu_i\\sum_{j=1}^{\\bar n } \\bar a_jb_{ij } }    \\nonumber \\\\   & \\exp\\left ( \\sum_{i=1}^n u_i \\left\\{\\mu_i - \\sum_{p , q=1}^{\\bar n } b_{pi } \\bar a_{pq } \\left(\\log\\frac{\\bar a_1+\\dots + \\bar a_{\\bar          n}}{\\bar a_q } + \\bar \\mu_q\\right)\\right\\ } \\right ) \\nonumber \\\\   & \\times \\exp\\left(\\frac{1}{2}\\sum_{i , j\\notin \\bar i } u_i u_j \\left\\{b_{ij } - \\sum_{p , q=1}^{\\bar n } \\bar    a_{pq } b_{pi } b_{qj }   \\right\\}\\right )   \\left(1+o\\left(\\left(\\log        \\frac{1}{x } \\right)^{-1}\\right)\\right ) .",
    "\\label{e : lt}\\end{aligned}\\ ] ]    [ [ example - the - sum - of - two - lognormal - variables . ] ] example : the sum of two lognormal variables .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath133 , and denote the elements of the matrix @xmath6 by @xmath134 , @xmath135 and @xmath136 .",
    "to fix the ideas we assume @xmath137 . then",
    ", @xmath138 and @xmath139 therefore , the solution to problem is given by @xmath140    and we have the following three cases :    * if @xmath141 , then both weights are strictly positive , assumption @xmath99 holds , and the asymptotic behavior of the density @xmath32 is as follows : @xmath142 with @xmath143 * if @xmath144 , then @xmath145 , assumption @xmath99 holds , and the asymptotic behavior of the density is characterized by @xmath146 note that in this case the asymptotic behavior of @xmath32 is determined by the second component only . * the case , where @xmath147 , is exceptional . here",
    "we have @xmath145 , but assumption",
    "@xmath99 does not hold .",
    "thus , theorem [ gen.thm ] can not be applied .    in @xcite , gao , xu , and ye characterize the left tail behavior of the sum of two log - normal variables in all the three cases described above .",
    "it follows from the results established in @xcite that the asymptotic behavior of the density @xmath32 in the exceptional case is qualitatively different from the behavior of @xmath32 in the cases where @xmath148 or @xmath149 .",
    "this shows that one can not relax assumtion @xmath99 without changing the form of the asymptotics , which means that , in a sense , assumption @xmath99 is optimal .",
    "_ proof of lemma [ easy.prop ] .",
    "+   + we will first prove the formula in ( [ e : pro3 ] ) .",
    "the distribution function of @xmath30 is given by @xmath150 differentiating the previous formula with respect to @xmath151 and making a change of variable , we see that the density @xmath32 of the random variable @xmath30 can be represented as follows : @xmath152 set @xmath153 now , taking into account ( [ e : mult1 ] ) and ( [ e : vis1 ] ) , we see that for every @xmath154 , @xmath155 _    in the tail regime ( @xmath37 ) , we can isolate the effect of @xmath50 in the formula : @xmath156 where @xmath157 and @xmath158    it is clear from formula ( [ e : vis2 ] ) that it suffices to characterize the asymptotic behavior as @xmath159 of the integral @xmath160 we will use the higher - dimensional extension of laplace s method in the proof .",
    "recall that @xmath161 for all @xmath15 .",
    "we have @xmath162 for all @xmath163 .",
    "it follows that the function @xmath164 has a unique critical point @xmath165 where @xmath166 for @xmath163 .",
    "note that the critical point @xmath167 belongs to the interior of the integration set in ( [ e : vis5 ] ) , and moreover , this point is the global minimum point of the function @xmath164 .",
    "next , using formula ( 8.3.50 ) in @xcite , we obtain @xmath168 as @xmath51 , where @xmath169 is the hessian matrix of the function @xmath164 evaluated at the critical point @xmath167 .",
    "note that @xmath170 and @xmath171 moreover , since @xmath172 and @xmath173 we have @xmath174 next , using ( [ e : vis9 ] ) and making long and tedious computations , we get the following equality : @xmath175    finally , taking into account ( [ e : vis2 ] ) , ( [ e : vis6 ] ) , and ( [ e : vis7 ] ) , ( [ e : vis8 ] ) , and ( [ e : vis10 ] ) , we complete the proof of formula ( [ e : pro3 ] ) in lemma [ easy.prop ] .",
    "formula ( [ e : prof ] ) can be derived by integrating formula ( [ e : pro3 ] ) , or we can prove ( [ e : prof ] ) directly by employing the same methods as those used in the proof of ( [ e : pro3 ] ) .",
    "+   + _ proof of theorem [ gen.thm ] .",
    "+   + let @xmath176 , @xmath177 , and @xmath178 be such that @xmath179 . then , @xmath180 \\geq \\mathbb p[e^{y_1}+\\dots + e^{y_{k } } \\leq e^a , y_{k+1 } \\leq b ] \\\\ & = \\mathbb p[e^{y_1}+\\dots + e^{y_{k } } \\leq e^a ] - \\mathbb p[e^{y_1}+\\dots + e^{y_{k } } \\leq e^a , y_{k+1 } > b ] .",
    "\\end{aligned}\\ ] ] note that @xmath181 implies that @xmath182 .",
    "the second term in the above formula can be estimated as follows : @xmath183 & \\leq \\mathbb p[\\bar w_1 y_1 + \\dots + \\bar w_{k } y_{k } \\leq a , y_{k+1 } > b ] \\\\ & \\leq \\mathbb p[\\bar w_1 y_1 + \\dots + \\bar w_{k } y_{k } - a \\leq \\alpha ( y_{k+1 } - b ) ] \\\\ & = n\\left(\\frac{a-\\alpha b - \\mathbb e[\\bar w^{\\perp } y - \\alpha",
    "y_{k+1}]}{\\sqrt{\\text{var}\\ , [ \\bar w^{\\perp } y - \\alpha      y_{k+1}]}}\\right)\\end{aligned}\\ ] ] for every @xmath184 .",
    "now , let @xmath185 ( the inequality follows from assumption @xmath99 ) and choose @xmath186 noting that @xmath187 = \\bar w^{\\perp } { { \\eufrak b}}\\bar w(1 - 2 \\alpha x_{k+1 } ) + \\alpha^2 { { \\eufrak b}}_{k+1,k+1},\\ ] ] and making the above substitutions , we obtain , for @xmath188 small enough , @xmath189}{\\sqrt{\\text{var}\\ , [ \\bar w^{\\perp } y - \\alpha      y_{k+1 } ] } } \\\\      & = \\frac { ( 1-\\alpha    \\frac{x_{k+1}+1}{2 } ) \\log z+ \\log(1-z^{\\frac{x_{k+1}-1}{2 } } ) + \\bar    w^\\perp \\mu - \\alpha \\mu_{k+1}}{\\sqrt{\\bar w^{\\perp }     { { \\eufrak b}}\\bar w}\\sqrt{1 - 2\\alpha x_{k+1 } + \\frac{\\alpha^2        { { \\eufrak b}}_{k+1,k+1}}{\\bar w^{\\perp } { { \\eufrak b}}\\bar w } } } \\\\ & \\leq   \\frac{\\log z}{\\sqrt{\\bar w^{\\perp } { { \\eufrak b}}\\bar w } } \\frac{1-\\alpha    \\frac{x_{k+1}+1}{2}}{\\sqrt{1 - 2\\alpha x_{k+1 } + \\frac{\\alpha^2        { { \\eufrak b}}_{k+1,k+1}}{\\bar w^{\\perp } { { \\eufrak b}}\\bar w}}}+ c_{k+1},\\end{aligned}\\ ] ] where @xmath190 is a constant which does not depend on @xmath191 .",
    "next , for @xmath188 small enough , @xmath192 now it is easy to see that by choosing @xmath188 small enough , one can always find @xmath193 such that @xmath194}{\\sqrt{\\text{var}\\ , [ \\bar w^{\\perp } y - \\alpha      y_{k+1 } ] } } \\leq \\frac{\\log z}{\\sqrt{\\bar w^{\\perp } { { \\eufrak b}}\\bar w } } ( 1 + \\varepsilon_{k+1 } ) + c_{k+1}.\\ ] ] we conclude that @xmath195 & \\geq \\mathbb p[e^{y_1}+\\dots+e^{y_{k}}\\leq z(1-z^{\\frac{x_{k+1 } - 1}{2 } } ) ] \\\\ & \\quad + n\\left(\\frac{\\log z}{\\sqrt{\\bar w^\\perp { { \\eufrak b}}\\bar        w}}(1+\\varepsilon_{k+1 } ) + c_{k+1}\\right)\\end{aligned}\\ ] ] _    let us first apply this formula for @xmath196 and @xmath197 . since @xmath198 as @xmath199 , and @xmath200 using lemma [ easy.prop ] to compute the asymptotics of @xmath201\\ ] ] we have that @xmath202 } = o\\left(\\left(\\log \\frac{1}{x}\\right)^{-1}\\right).\\ ] ] as @xmath37 . on the other hand , by lemma [ easy.prop ] , for @xmath203 @xmath204 \\\\ & = \\frac{c}{\\bar    a_1+\\dots+\\bar a_{\\bar n } } \\left(\\log \\frac{1}{x }    -\\log(1-x^\\delta)\\right)^{-\\frac{\\bar n}{2 } } ( x(1-x^\\delta))^{\\sum_{k=1}^{\\bar n } \\bar a_k \\left(\\log\\frac{\\bar        a_1+\\dots+\\bar a_{\\bar n}}{\\bar a_k}+\\bar      \\mu_k\\right)}\\\\&\\exp\\left(-\\frac{1}{2}(\\bar a_1+\\dots+\\bar a_{\\bar n }    ) \\left(\\log\\frac{1}{x }      -\\log(1-x^\\delta)\\right)^2\\right)\\left(1+o\\left(\\left(\\log        \\frac{1}{x } \\right)^{-1}\\right)\\right)\\\\ & = \\frac{c}{\\bar    a_1+\\dots+\\bar a_{\\bar n } } \\left(\\log \\frac{1}{x }   \\right)^{-\\frac{\\bar n}{2 } } x^{\\sum_{k=1}^{\\bar n } \\bar a_k \\left(\\log\\frac{\\bar        a_1+\\dots+\\bar a_{\\bar n}}{\\bar a_k}+\\bar      \\mu_k\\right)}\\\\&\\exp\\left(-\\frac{1}{2}(\\bar a_1+\\dots+\\bar a_{\\bar n }    ) \\log^2\\frac{1}{x }     \\right)\\left(1+o\\left(\\left(\\log        \\frac{1}{x } \\right)^{-1}\\right)\\right).\\end{aligned}\\ ] ] therefore , we have shown that @xmath205 \\geq \\mathbb p[e^{y_1 } + \\dots + e^{y_{\\bar",
    "n } } \\leq z ] \\left(1+o\\left(\\left(\\log        \\frac{1}{x } \\right)^{-1}\\right)\\right).\\ ] ] and since clearly , @xmath205",
    "\\leq \\mathbb p[e^{y_1 } + \\dots + e^{y_{\\bar n } } \\leq z],\\ ] ] we also get @xmath205 = \\mathbb p[e^{y_1 } + \\dots + e^{y_{\\bar n } } \\leq z ] \\left(1+o\\left(\\left(\\log        \\frac{1}{x } \\right)^{-1}\\right)\\right)\\ ] ] iterating this procedure @xmath206 times using the induction argument , we finally get that @xmath207 = \\mathbb p[e^{y_1 } + \\dots + e^{y_{\\bar n } } \\leq z ] \\left(1+o\\left(\\left(\\log        \\frac{1}{x } \\right)^{-1}\\right)\\right),\\ ] ] which completes the proof of the theorem , since the asymptotics for @xmath208\\ ] ] can be computed using lemma [ easy.prop ] . +   + _",
    "proof of corollary [ laplace.cor ] .",
    "+   + for any @xmath209 , we have @xmath210 = \\frac{\\mathbb    e[e^{\\sum_{i=1}^n u_i y_i}\\mathbf 1_{x\\leq x}]}{\\mathbb p[x\\leq x ] } = \\mathbb e[e^{\\sum_{i=1}^n u_i y_i } ] \\frac{\\tilde{\\mathbb p}[x\\leq x]}{\\mathbb p[x\\leq x]},\\label{probchange}\\end{aligned}\\ ] ] where the symbol @xmath211 stands for a new probability determined from @xmath212}.\\ ] ] under this probability , @xmath213 . applying theorem [ gen.thm ] to the numerator and the denominator of the fraction in , and making cancellations , we get the following : @xmath214   \\\\ & =   x^{\\sum_{i=1}^n u_i \\sum_{j=1}^{\\bar n }    \\bar a_j b_{ij } } \\ , e^{\\mu^\\perp u +    \\frac{1}{2 } u^\\perp { { \\eufrak b}}u}\\ , \\frac{\\bar c_{\\mu+{{\\eufrak b}}u ,      { { \\eufrak b}}}}{\\bar c_{\\mu,{{\\eufrak b}}}}\\left(1+o\\left(\\left(\\log        \\frac{1}{x } \\right)^{-1}\\right)\\right)\\\\ & = x^{\\sum_{i=1}^n u_i \\sum_{j=1}^{\\bar n }    \\bar a_j b_{ij } } \\exp\\left\\{\\frac{1}{2}\\sum_{i , j=1}^n u_i u_j \\left(b_{ij}-\\sum _ { p , q=1}^{\\bar n } \\bar    a_{pq } b_{pi}b_{qj}\\right)\\right\\ } \\\\&\\exp\\left\\{\\sum_{i=1}^n u_i \\left(\\mu_i - \\sum _ { p , q=1}^{\\bar n } \\bar    a_{pq}b_{pi } \\left(\\log\\frac{\\bar a_1+\\cdots+\\bar a_{\\bar n}}{\\bar a_q}+\\bar    \\mu_q \\right)\\right)\\right\\ } \\\\ &   \\left(1+o\\left(\\left(\\log        \\frac{1}{x } \\right)^{-1}\\right)\\right).\\end{aligned}\\ ] ] it is easy to check that when @xmath126 or @xmath215 , necessarily @xmath216 _",
    "this completes the proof of corollary [ laplace.cor ] .",
    "+   + _ proof of corollary [ c : corr ] .",
    "+   + recall the formula for the distribution function of @xmath30 : @xmath217 =   \\int_{e^{y_1}+\\dots + e^{y_n}\\leq x}\\frac{1}{(2\\pi)^{\\frac{n}{2}}\\sqrt{|{{\\eufrak b}}| } } \\exp\\left\\{-\\frac{1}{2 }    ( y-\\mu)^\\perp { { \\eufrak b}}^{-1 } ( y-\\mu)\\right\\ } dy_1\\dots dy_n\\\\ & = \\int_{e^{z_1}+\\dots + e^{z_n}\\leq 1 } \\frac{1}{(2\\pi)^{\\frac{n}{2}}\\sqrt{|{{\\eufrak b}}| } } \\exp\\left\\{-\\frac{1}{2 }    ( z + \\mathbf 1 \\log x-\\mu)^\\perp { { \\eufrak b}}^{-1 } ( z + \\mathbf 1 \\log x-\\mu)\\right\\ } dz_1\\dots dz_n.\\end{aligned}\\ ] ] differentiating with respect to @xmath50 , we obtain an alternative representation for the density : @xmath218 = -\\frac{1}{x}\\mathbb e\\left[\\sum_{i=1}^n a_i ( y_i - \\mu_i)\\mathbf 1_{x\\leq    x}\\right].\\end{aligned}\\ ] ] next , we make a transformation inspired by corollary [ laplace.cor ] : @xmath219 \\\\ & -\\frac{\\log x}{x}\\mathbb e\\left[\\sum_{i=1}^n",
    "a_i    \\sum_{j=1}^{\\bar n } \\bar a_j b_{ij } \\mathbf 1_{x\\leq    x}\\right]\\\\ & = \\frac{\\mathbb p[x\\leq x]}{x } \\sum_{i=1}^n a_i \\mu_i - \\frac{1}{x}\\sum_{i=1}^n a_i\\mathbb e[(y_i - ( 1+\\bar \\lambda_i ) \\log x ) \\mathbf 1_{x\\leq x } ] \\\\ & -\\frac{\\log x}{x}\\ , \\sum_{j=1}^{\\bar n } \\bar a_j   \\,\\mathbb    p[x\\leq x]\\\\ & = -\\frac{\\log x}{x}\\ , \\sum_{j=1}^{\\bar n } \\bar a_j   \\,\\mathbb    p[x\\leq x ] + o\\left(\\frac{\\mathbb p[x\\leq x]}{x}\\right).\\end{aligned}\\ ] ] in the reasoning above , we used the following estimate , which can be derived from corollary [ laplace.cor ] . for every @xmath220 , @xmath221 \\right| \\\\ & \\leq \\mathbb p[x\\leq x ] ( \\mathbb e[e^{(y_i - ( 1+\\bar \\lambda_i ) \\log x } | x\\leq x ] + \\mathbb e[e^{-(y_i - ( 1+\\bar \\lambda_i ) \\log x } | x\\leq x ] ) \\\\ & =   c\\mathbb p[x\\leq x ]   \\left(1+o\\left(\\left(\\log        \\frac{1}{x } \\right)^{-1}\\right)\\right)\\end{aligned}\\ ] ] for some constant @xmath130 . _",
    "this completes the proof of corollary [ c : corr ] .",
    "in this section , we analyze the asymptotic behavior of the distribution function and the density of the random variable @xmath24 as @xmath222 , assuming with no loss of generality that @xmath223 .",
    "if @xmath224 , then the support of the distribution of @xmath24 is @xmath225 , and the tail behavior at @xmath226 follows from the results obtained in section [ s : nachalo ] .",
    "let us first consider the case when @xmath227 .",
    "define @xmath228 and introduce the vector @xmath229 as the unique point such that @xmath230 the existence and uniqueness of @xmath56 follows from the non - degeneracy of @xmath6 .",
    "when @xmath231 and @xmath232 for @xmath233 , @xmath56 is given by . in the general case , we define @xmath75 , @xmath234 , @xmath235 , @xmath236 , @xmath69 and @xmath237 as in equation and below .    since by the definition of @xmath238 , @xmath239 , and moreover the variables @xmath240 are exchangeable in the definition of @xmath241",
    ", we shall assume with no loss of generality that @xmath72 .",
    "this has already been done in subsection [ ss : fmr1 ] .",
    "observe that the minimum in @xmath242 is attained in the interior of @xmath76 .",
    "this implies that @xmath243 and @xmath244 for @xmath245 ( see a similar reasoning in subsection [ ss : fmr1 ] ) .",
    "the following preliminary lemma concerns the case where @xmath246 .",
    "[ t : standard ] let @xmath247 , @xmath248 .",
    "then the following formulas hold : @xmath249 & = \\frac{c}{a_1+\\dots+a_n}(\\log x)^{-\\frac{1+n}{2 } } x^{\\sum_{i=1}^n a_i\\left ( \\log \\frac{\\sum_{j=1}^n a_j}{|a_i| } +      \\mu_i\\right)}\\notag\\\\ & \\times \\exp\\{-\\frac{1}{2}(\\log^2x)\\sum_{j=1}^na_j\\}\\left(1+o\\left(\\left(\\log x\\right)^{-1}\\right)\\right)\\end{aligned}\\ ] ] as @xmath250 .",
    "the constant @xmath130 in ( [ e : finf ] ) is given by @xmath251    we will next focus on the case where @xmath21 is still equal to one , but the equality @xmath246 may not hold .",
    "our next result requires the following assumption :    * for every @xmath93 , @xmath252    [ rema1 ] assumption @xmath253 , although it has the same form as assumption @xmath254 above , is a different assumption on the covariance matrix @xmath6 , because the weight vector @xmath56 is computed differently now ( with @xmath238 instead of @xmath255 ) .",
    "assumption @xmath253 is equivalent to the following : for every @xmath93 , @xmath256 indeed , since @xmath257 , for every @xmath258 and for @xmath103 small enough , @xmath259 belongs to @xmath238 .",
    "therefore , the inequality opposite to that in ( [ e : opp ] ) would lead to a contradiction to the fact that @xmath56 is a minimizer .",
    "[ t : character ] let assumption @xmath253 hold true . then",
    ", as @xmath222 , @xmath260 & = \\frac{c}{\\bar a_1+\\dots+\\bar a_{\\bar n}}(\\log x)^{-\\frac{1+{\\bar n}}{2 } } x^{\\sum_{i=1}^{\\bar n } \\bar a_i\\left ( \\log \\frac{\\sum_{j=1}^{\\bar n } \\bar a_j}{|\\bar a_i| } +      \\bar\\mu_i\\right)}\\notag\\\\ & \\times \\exp\\{-\\frac{1}{2}(\\log^2x)\\sum_{j=1}^{\\bar n}\\bar a_j\\}\\left(1+o\\left(\\left(\\log x\\right)^{-1}\\right)\\right),\\end{aligned}\\ ] ] where @xmath261    theorem [ t : character ] shows that the exponential rate of decay in the leading term of the asymptotics of @xmath262 $ ] is determined by the quantity @xmath263 depending on the covariance matrix @xmath6 , this rate may either be equal to @xmath264 , the inverse of the variance of @xmath265 , in which case the asymptotic behavior of @xmath241 is determined by @xmath265 only , or be greater than @xmath264 , in which case the asymptotic behavior of @xmath241 is determined by more than one component of the vector @xmath266 .",
    "one may call the number @xmath267 the relative asymptotic variance of @xmath265 with respect to @xmath240 .",
    "let us next consider the random varable @xmath24 given by ( [ e : bass ] ) . for every @xmath32 with @xmath268 ,",
    "put @xmath269    the tail behavior of the random variables like those in ( [ e : split1 ] ) was characterized in theorem [ t : character ] .",
    "more precisely , let @xmath270 be the set of weights @xmath271 with @xmath272 for @xmath273 , @xmath274 ; @xmath275 ; @xmath276 for @xmath277 ; and @xmath278 .",
    "let @xmath279 be the unique point such that @xmath280 and define @xmath281 , @xmath282 , @xmath283 , @xmath284 , @xmath285 , @xmath286 , @xmath287 as in equation and below .",
    "we will say that assumption @xmath288 holds if for every @xmath289 , @xmath290    according to theorem [ t : character ] , if assumption @xmath288 is satisfied , then @xmath291=\\delta_{1,p}(\\log x)^{\\delta_{2,p}}x^{\\delta_{3,p } } \\exp\\left\\{-\\frac{\\log^2x}{2 \\delta_{4,p}}\\right\\}(1+o\\left((\\log x)^{-1}\\right ) \\label{e : splitasymp}\\ ] ] where @xmath292 @xmath293 it will be shown below that the asymptotic behavior of the distribution function of the random variable @xmath24 is dominated by one ( or several similar ) of the random variables @xmath294 .",
    "we will need the following parameters to describe the above - mentioned domination : @xmath295 @xmath296 @xmath297 and finally @xmath298    now , we are ready to formulate the main result of the present subsection .",
    "[ t : present ] let assumption @xmath288 hold for every @xmath299",
    ". then the distribution function of the random variable @xmath24 defined by ( [ e : bass ] ) satisfies @xmath300=\\delta_1(\\log x)^{\\delta_2}x^{\\delta_3 } \\exp\\left\\{-\\frac{\\log^2x}{2 \\delta_4}\\right\\}(1+o\\left((\\log x)^{-\\frac{1}{2}}\\right)\\ ] ] as @xmath250 .    when @xmath28 , the variables @xmath294 are one - dimensional and log - normal , and the result in theorem [ t : present ] reduces to theorem 1 of @xcite which shows that the asymptotic behavior of the right tail of @xmath301 is determined by the components of @xmath266 which have the largest variance . for other values of @xmath21 ,",
    "theorem [ t : present ] extends theorem 1 of @xcite by showing that the asymptotic behavior of the right tail of @xmath24 is determined by the components of @xmath302 , which have the largest relative asymptotic variance with respect to @xmath303 .    as in the case of theorem [ gen.thm ] ,",
    "several useful corollaries can be derived from theorem [ t : present ] .",
    "we omit the proofs of those corollaries , since they are very similar to those given in subsection [ ss : fmr1 ] .",
    "[ laplace2.cor ] suppose that assumption @xmath288 holds for every @xmath299 , and that the set @xmath304 is a singleton , @xmath305 .",
    "then , as @xmath36 , for any @xmath117 ,",
    "@xmath118= \\mathbb e\\left[e^{\\sum_{i=1}^n u_i y_i}| x= x\\right ] = x^{\\sum_{j=1}^n u_j \\sum_{i=1}^{\\bar n^{(p)}}\\bar a_i^{(p)}b_{\\bar k^{(p)}(i),j } } \\notag\\\\ & \\times \\exp\\left\\ {    \\sum_{j=1}^n u_j\\left(\\mu_j-\\sum_{i , k=1}^{\\bar n^{(p ) } } \\bar a^{(p)}_{ik } b_{\\bar k^{(p)}(i),j }   \\left(\\log \\frac{\\sum_{j=1}^{\\bar n^{(p ) } } \\bar a^{(p)}_j}{|\\bar a^{(p)}_k|}+     \\mu_{\\bar k^{(p)}(k)}\\right)\\right ) \\right\\ } \\notag\\\\ & \\times \\exp\\left\\{+\\frac{1}{2 } \\sum_{j , l\\notin \\bar i^{(p)}}^n u_j u_l \\left(b_{jl}-\\sum_{i , k=1}^{\\bar n^{(p ) } } \\bar a^{(p)}_{ik } b_{\\bar k^{(p)}(i),j } b_{\\bar k^{(p)}(k),l}\\right)\\right\\ } \\notag\\\\ & \\left(1+o\\left(\\left(\\log        \\frac{1}{x } \\right)^{-1}\\right)\\right).\\label{lt2.eq}\\end{aligned}\\ ] ]    in the next statement , we use the notation introduced before the formulation of theorem [ t : present ] .",
    "[ c : corrr ] suppose assumption @xmath288 holds for every @xmath299 .",
    "then , as @xmath36 , the density @xmath31 of the random variable @xmath24 satisfies @xmath306      _ proof of lemma [ t : standard ] .",
    "+   + differentiating the distribution function , we obtain the following representation of the density @xmath307 of @xmath241 : @xmath308 with @xmath309 we have for all @xmath310 , @xmath311 where @xmath312 and @xmath313 for @xmath314 .",
    "now , it is easy to see that the solution @xmath315 to the system of equations @xmath316 , @xmath310 , is given by @xmath317 _    under the assumptions in the formulation of the lemma , it is clear that @xmath315 belongs to the interior of the set @xmath318 .",
    "we will next apply laplace s method to the integral in ( [ e : f4 ] ) .",
    "however , first we need to check that the hessian matrix of the function @xmath319 at the point @xmath320 , that is , the matrix @xmath321_{i , m=1,\\cdots n-1}$ ] , is positive - definite .",
    "it is not hard to see that @xmath322 and @xmath323 therefore , @xmath324 where @xmath325 is the @xmath326-matrix with the entries @xmath327 along the main diagonal , and all the entries outside the main diagonal equal to 1 .",
    "it is an easy exercise in linear algebra to show that that the leading principal minor of order @xmath32 of the matrix @xmath325 is equal to @xmath328 under the assumption in the lemma , these numbers are positive for @xmath329 .",
    "therefore , the matrix @xmath325 is positive definite , and hence the matrix @xmath330 is also positive definite .",
    "moreover , the determinant of @xmath330 is given by @xmath331 next , taking in the account what was said above , we see that laplace s method can be applied to the integral in ( [ e : f4 ] ) .",
    "similarly to , we get the following formula : @xmath332 the asymptotic behavior of the distribution function can be characterized by integrating the asymptotic formula for the density .",
    "this completes the proof of lemma [ t : standard ] .",
    "+   + _ proof of theorem [ t : character ] .",
    "+   + we will only sketch the proof , which is very similar to that of theorem [ gen.thm ] . if @xmath333 , the result follows from lemma [ t : standard ] .",
    "next , assume that @xmath334 , @xmath335 , and let @xmath178 be such that @xmath336 . on the one hand , clearly , @xmath337",
    "\\leq \\mathbb p[e^{y_1}\\geq e^{y_2 } + \\dots + e^{y_{n-1}}+x].\\ ] ] on the other hand , @xmath338   \\geq \\mathbb p[e^{y_2 } + \\dots + e^{y_{k}}\\leq e^{y_1 } - e^a , y_{k+1 } \\leq b ] \\\\ & = \\mathbb p[e^{y_2 } + \\dots + e^{y_{k}}\\leq e^{y_1 } - e^a ] - \\mathbb p[e^{y_2 } + \\dots + e^{y_{k}}\\leq e^{y_1 } - e^a , y_{k+1 } > b].\\end{aligned}\\ ] ] since @xmath181 , @xmath339 .",
    "moreover , since @xmath239 , we may define @xmath340 and @xmath341 for @xmath342 ; these weights are positive and satisfy @xmath343 . _    we have @xmath344 & \\leq \\mathbb p[\\tilde w_1 e^a + \\tilde w_2 e^{y_2 } + \\dots + \\tilde w_k e^{y_{k}}\\leq e^{y_1 } , y_{k+1 } > b]\\\\ & \\leq \\mathbb p[\\tilde w_1 a + \\tilde w_2 { y_2 } + \\dots + \\tilde w_k { y_{k}}\\leq { y_1 } , y_{k+1 } > b ] \\\\ & = \\mathbb p[a \\leq   \\bar w_1 y_1 + \\bar w_2 { y_2 } + \\dots + \\bar w_k { y_{k } } , y_{k+1 } > b]\\\\ & \\leq \\mathbb p[a -\\sum_{i=1}^k   \\bar w_i y_i \\leq \\alpha ( y_{k+1 } - b)]\\\\ & = \\mathbb p[\\sum_{i=1}^k   \\bar w_i y_i + \\alpha   y_{k+1 } \\geq a + \\alpha b   ] \\\\ & = n\\left(\\frac{-a-\\alpha b + \\mathbb e[\\bar w^\\perp y + \\alpha y_{k+1}]}{\\sqrt{\\text{var}\\,[\\bar w^\\perp y",
    "+ \\alpha y_{k+1}]}}\\right ) \\end{aligned}\\ ] ] for all @xmath184 .",
    "next , reasoning as in the proof of theorem [ gen.thm ] , let @xmath345 then , @xmath346}{\\sqrt{\\text{var}\\,[\\bar w^\\perp y + \\alpha        y_{k+1}]}}\\right ) = n\\left(\\frac{-a-\\alpha b + \\bar      w^\\perp \\mu + \\alpha \\mu_{k+1}}{\\sqrt{\\bar w^\\perp { { \\eufrak b}}\\bar w \\left(1 + 2        \\alpha x_{k+1 } + \\frac{\\alpha^2 { { \\eufrak b}}_{k+1,k+1}}{\\bar w^\\perp { { \\eufrak b}}\\bar w}\\right)}}\\right)\\ ] ] now , we take @xmath347 using these substitutions , we obtain @xmath348 where @xmath190 is a constant independent of @xmath50 .",
    "next , reasoning as in the proof of theorem [ gen.thm ] , we see that there exist @xmath188 small enough and @xmath349 such that for all @xmath335 , @xmath350}{\\sqrt{\\text{var}\\,[\\bar w^\\perp y + \\alpha        y_{k+1 } ] } } \\leq -\\frac{\\log x}{\\sqrt{\\bar w^\\perp { { \\eufrak b}}\\bar w}}(1+\\varepsilon_{k+1})+c_{k+1}.\\ ] ] the rest of the proof is similar to that of theorem [ gen.thm ] modulo some trivial changes .    the proof of theorem [ t : character ] is thus completed .",
    "+   + _ proof of theorem [ t : present ] .",
    "+   + it is clear that the sets @xmath351 , @xmath352 , and @xmath353 defined by ( [ p4 ] ) , ( [ p3 ] ) , and ( [ p2 ] ) , respectively , are not empty .",
    "_    _ upper estimate .",
    "fix a positive function @xmath354 such that @xmath355 as @xmath36 .",
    "then we have @xmath356 \\leq \\sum_{1\\leq p\\leq m } \\mathbb p[x_{p } \\geq",
    "( 1-\\varphi(x))(x_{m+1}+\\dots+x_n + x)]\\notag\\\\ & + \\sum_{1\\leq p , q \\leq m , p\\neq q } \\mathbb",
    "p\\left[x_p \\geq \\frac{\\varphi(x)}{m-1}(x_{m+1}+\\dots+x_n+x),x_q \\geq \\frac{\\varphi(x)}{m-1}(x_{m+1}+\\dots+x_n+x)\\right ] .",
    "\\label{upperxm}\\end{aligned}\\ ] ] formula ( [ upperxm ] ) can be established as follows .",
    "let @xmath357 , @xmath358 , and @xmath359 with @xmath360 , be random variables .",
    "then it is not hard to prove that the following set theoretical inclusion holds : @xmath361 .",
    "\\label{e : kr1}\\end{aligned}\\ ] ] next , using ( [ e : kr1 ] ) with @xmath362 and @xmath363 and taking into account the countable subadditivity of @xmath364 , we obtain ( [ upperxm ] ) . _",
    "to estimate the terms in the first sum in formula ( [ upperxm ] ) , we introduce the following probability measure : @xmath365},\\ ] ] where @xmath366 is the vector with @xmath32-th component equal to @xmath367 and all the other components equal to zero .",
    "note that the measure @xmath368 depends on @xmath32 .",
    "however , we omit the parameter @xmath32 in the symbol @xmath368 for the sake of simplicity .    under the probability @xmath369 , the following formula holds : @xmath370    therefore , by the hlder inequality , @xmath371 = \\widetilde{\\mathbb    e}\\left[\\frac{d{\\mathbb p}}{d\\widetilde{\\mathbb p } } \\mathbf 1_{\\{x_{p } \\geq ( 1-\\varphi(x))(x_{m+1}+\\dots+x_n + x)\\}}\\right]\\\\ & = \\mathbb e[e^{\\log(1-\\varphi(x ) ) e^{p }      { { \\eufrak b}}^{-1}y } ] \\widetilde{\\mathbb    e}\\left [ e^{-\\log(1-\\varphi(x ) ) e^{p }     { { \\eufrak b}}^{-1}y}\\mathbf 1_{\\{x_{p } \\geq ( 1-\\varphi(x))(x_{m+1}+\\dots+x_n + x)\\}}\\right]\\\\ & \\leq \\mathbb e[e^{\\log(1-\\varphi(x ) ) e^{p }      { { \\eufrak b}}^{-1}y } ] \\widetilde{\\mathbb    e}\\left [ e^{-r\\log(1-\\varphi(x ) ) e^{p }      { { \\eufrak b}}^{-1}y}\\right]^{1/r } \\\\      & \\quad\\times\\widetilde{\\mathbb p}[x_{p } \\geq ( 1-\\varphi(x))(x_{m+1}+\\dots+x_n + x)]^{1/q}\\\\ & = \\mathbb e[e^{\\log(1-\\varphi(x ) ) e^{p }      { { \\eufrak b}}^{-1}y}]^{1-\\frac{1}{r } } { \\mathbb    e}\\left [ e^{-(r-1)\\log(1-\\varphi(x ) ) e^{p }      { { \\eufrak b}}^{-1}y}\\right]^{1/r } \\\\ & \\quad\\times{\\mathbb p}[x_{p } \\geq x_{m+1}+\\dots+x_n + x]^{1/q}\\\\ & = e^{\\frac{r-1}{2 } \\log^2(1-\\varphi(x))a_{pp}}{\\mathbb p}[x_{p } \\geq ( x_{m+1}+\\dots+x_n + x)]^{1/q},\\end{aligned}\\ ] ] where @xmath372 and @xmath373 are positive numbers satisfying @xmath374 .",
    "set @xmath375 , @xmath376 , and @xmath377 .",
    "then , @xmath378 and hence , by theorem [ t : character ] , @xmath379   \\\\&\\leq \\delta_{1,p}(\\log x)^{\\delta_{2,p}}x^{\\delta_{3,p } } \\exp\\left\\{-\\frac{\\log^2x}{2 \\delta_{4,p}}\\right\\}(1+o\\left((\\log x)^{-1}\\right).\\end{aligned}\\ ] ]    it remains to estimate the terms in the second sum in .",
    "for any two integers @xmath32 and @xmath373 with @xmath380 and @xmath381 , let @xmath382 be the set of weights @xmath271 with @xmath383 for @xmath384 , @xmath385 ; @xmath386 , @xmath387 ; @xmath388 for @xmath277 ; and @xmath389 .",
    "recall that @xmath390 . by jensen s inequality , for any @xmath391 , @xmath392 \\notag\\\\ & \\leq \\mathbb p\\left[\\sum_{i=1}^n w_i\\log x_i \\geq ( w_p+w_q)\\log \\frac{\\phi(x)}{m-1 } + \\log x\\right]\\notag\\\\ & \\leq n\\left(-\\frac{(w_p+w_q)\\log \\frac{\\phi(x)}{m-1 } + \\log x -      \\sum_{i=1}^n w_i \\mu_i}{\\sqrt{w^\\perp { { \\eufrak b}}w}}\\right)\\notag\\\\ & = \\exp\\left\\{-\\frac{\\log^2 x } { 2w^\\perp { { \\eufrak b}}w } + o(\\log x \\cdot \\log \\log    x)\\right\\}.\\label{estim2prob}\\end{aligned}\\ ] ]    since the matrix @xmath6 is invertible and positive definite , the mapping @xmath393 is strictly convex .",
    "this implies that @xmath394 since @xmath395 we conclude from the estimate in that the terms in the second sum in formula provide a negligible contribution to the asymptotics , so that @xmath396 & \\leq \\sum_{p=1}^m\\delta_{1,p}(\\log x)^{\\delta_{2,p}}x^{\\delta_{3,p } } \\exp\\left\\{-\\frac{\\log^2x}{2 \\delta_{4,p}}\\right\\}(1+o\\left((\\log    x)^{-1}\\right)\\\\ & = \\delta_{1}(\\log x)^{\\delta_{2}}x^{\\delta_{3 } } \\exp\\left\\{-\\frac{\\log^2 x}{\\delta_4}\\right\\}(1+o\\left((\\log    x)^{-\\frac{1}{2}}\\right)\\end{aligned}\\ ] ]    _ lower estimate .",
    "let @xmath397 , @xmath398 , be random variables .",
    "then for every such @xmath32 , the following inclusion is valid : @xmath399 in addition , the sets @xmath400 , @xmath268 , are disjoint .",
    "now , setting @xmath401 , @xmath268 , and @xmath402 in ( [ e : kr2 ] ) , we can easily derive the following lower bound for the probability of our interest : @xmath356 \\geq \\sum_{p=1}^m \\mathbb p[x_p   \\geq x_{m+1 } + \\dots + x_n + x ] \\\\ & - \\sum_{1\\leq p , q,\\leq m , p\\neq q}\\mathbb p[x_p   \\geq x_{m+1 } + \\dots + x_n + x , x_q   \\geq x_{m+1 } + \\dots + x_n + x ] .\\end{aligned}\\ ] ] similarly to the first part of the proof we can now show that the terms in the second line make a negligible contribution to the limit .",
    "it follows that @xmath403\\geq \\delta_{1}(\\log x)^{\\delta_{2}}x^{\\delta_{3 } } \\exp\\left\\{-\\frac{\\log^2 x}{2\\delta_4}\\right\\}(1+o\\left((\\log    x)^{-\\frac{1}{2}}\\right),\\ ] ] and the proof of theorem [ t : present ] is thus completed . _",
    "to illustrate the performance of the asymptotic formulas of theorems [ gen.thm ] and [ t : present ] numerically , we have taken a @xmath404 covariance matrix with the following entries : @xmath405 ( constant correlation ) where @xmath406 .",
    "the distribution functions @xmath407 = \\mathbb p[e^{y_1 } + e^{y_2 } + e^{y_3 } + e^{y_4 } \\leq x]\\ ] ] and @xmath408 = \\mathbb p[e^{y_1 } + e^{y_2 } - e^{y_3 } - e^{y_4}\\geq x]\\ ] ] have been computed first , using the asymptotic formulas given in theorems [ gen.thm ] and [ t : present ] .",
    "the corresponding asymptotic approximations will be denoted below by @xmath409 and @xmath410 , respectively .",
    "then we evaluated monte carlo estimates @xmath411 and @xmath412 of these quantities ( the monte carlo algorithm is described in detail later in this section ) .",
    "to evaluate the quality of the asymtotic approximation , we plot the ratios @xmath413 and @xmath414 for a wide range of values of @xmath50 .",
    "these ratios , plotted as functions of @xmath415 , are shown in figure [ 2cor.fig ] for two values of the correlation coefficient @xmath416 .    in the evaluation of the asymptotic formula for @xmath417 $ ] , one needs to solve the quadratic programming problem formulated in . for the first value , @xmath418 ,",
    "the solution to this problem is @xmath419 .",
    "thus , here we are in the setting of the `` special case '' , where the asymptotics is obtained directly by laplace s method ( see lemma [ easy.prop ] ) . for the second value , @xmath420 , the solution is @xmath421 , so only the first two components make a contribution to the asymptotics .    in the evaluation of the asymptotic formula for @xmath422 $ ]",
    ", one needs to solve the problem in twice , for @xmath423 and @xmath424 , and compare the resulting minimum values . here , for @xmath418 , the solutions are @xmath425 , and @xmath424 gives a larger minimum value , so that the asymptotic behavior of the distribution function is determined by the second component of the vector @xmath426 only . for @xmath427 , the solutions",
    "are @xmath428 and @xmath429 , and once again , the minimum value is greater for @xmath424 . therefore , in this case the asymptotic behavior is determined by the second , third and fourth components of @xmath426 .",
    "right : @xmath422 $ ] .",
    "the fluctuations in the curves are due to the monte carlo error.,title=\"fig:\",scaledwidth=60.0%]$ ] .",
    "right : @xmath422 $ ] .",
    "the fluctuations in the curves are due to the monte carlo error.,title=\"fig:\",scaledwidth=60.0% ]    analyzing figure [ 2cor.fig ] , one can make the following observations , which turn out to be rather generic :    * as expected , the ratio of the distribution functions converges to one , but this convergence is very slow .",
    "this observation is consistent with the logarithmic error bounds in theorems [ gen.thm ] and [ t : present ] . *",
    "although the ratio of the estimates converges to one very slowly , this ratio is never very far from one ( compared to the value of the probability itself ) , which means that the asymptotic formula gives the right order of magnitude for a wide range of probabilities .",
    "for instance , for @xmath420 , the values of @xmath50 , shown in the left graph , correspond to the range of probabilities from @xmath430 for @xmath431 to @xmath432 for @xmath433 .",
    "as we have already seen , due to the slow convergence , the asymptotic formulas in theorems [ gen.thm ] and [ t : present ] typically provide only order - of - magnitude approximations of the distribution function of the sum / difference of log - normal random variables .",
    "when a more precise estimate is needed , and the dimension @xmath4 is large , one can use a monte carlo estimator .",
    "in such a case , as we will next explain , the asymptotic formulas can be utilized to construct very efficient variance reduction procedures . to save space ,",
    "we will only discuss the case of distribution functions .",
    "similar ideas can be used to reduce the variance of monte carlo estimates of densities , conditional expectations , or other quantities of interest .",
    "[ [ left - tail - of - x . ] ] left tail of @xmath30 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + +    for the distribution function @xmath434 $ ] , the standard estimate is the following : @xmath435 where @xmath436 are i.i.d .",
    "vectors with the law @xmath437 .",
    "however , this estimate is not a suitable approximation of the tail of the distribution function .",
    "indeed , the variance of @xmath438 is given by @xmath439 and the relative error , that is , @xmath440 explodes very quickly as @xmath37 ( it behaves like @xmath441 for some constant @xmath442 ) . the usual way to reduce variance in the gaussian context",
    "is via importance sampling .",
    "the idea is to rewrite the formula for @xmath443 as follows : @xmath444,\\ ] ] where @xmath445 is a vector that will be chosen later .",
    "note that if @xmath446 , then the standard estimate is recovered .",
    "the goal is to find a nonzero @xmath447 such that the corresponding estimate @xmath448 has variance smaller than that of the standard estimate .",
    "simple computations show that the variance of @xmath449 is given by @xmath450 \\\\ & = \\frac{1}{n } \\left\\{\\mathbb e[\\exp\\{-2\\lambda^\\perp { { \\eufrak b}}^{-1}(y-\\mu ) -   \\lambda^\\perp { { \\eufrak b}}^{-1}\\lambda \\ }   \\mathbf 1_{\\{\\sum_{i=1}^n \\exp\\{y_i + \\lambda_i\\}\\leq x\\ } } ] - f^2(x)\\right\\}\\\\ & = \\frac{1}{n } \\left\\{\\exp\\{\\frac{1}{2 } \\lambda^\\perp { { \\eufrak b}}^{-1}\\lambda\\ } \\mathbb e[\\exp\\{-\\lambda^\\perp { { \\eufrak b}}^{-1}(y-\\mu)\\ } \\mathbf 1_{\\{\\sum_{i=1}^n \\exp\\{y_i\\}\\leq x\\ } } ] - f^2(x)\\right\\}\\\\ & = \\frac{1}{n } \\left\\{\\exp\\{\\lambda^\\perp { { \\eufrak b}}^{-1}\\lambda\\ } \\mathbb p\\left[\\sum_{i=1}^n\\exp\\{y_i-\\lambda_i\\}\\leq x\\right ] - f^2(x)\\right\\}.\\end{aligned}\\ ] ] let @xmath451.\\ ] ] since @xmath452 does not depend on @xmath447 , the optimal variance reduction is obtained by minimizing @xmath453 as a function of @xmath447 .",
    "our idea is to obtain an explicit estimate by replacing the probability in the previous expression by an asymptotically equivalent expression given in theorem [ gen.thm ] . in other words , we compute an approximation to the optimal @xmath447 by minimizing @xmath454 to obtain the expression above , we have omitted all the factors in the formula in theorem [ gen.thm ] , which do not depend on @xmath447 , and have also taken the logarithm of the resulting expression . to solve for the optimal value of @xmath447",
    "( we will denote it by @xmath455 ) , we first formulate the first order condition , and then multiply the resulting expression by the matrix @xmath6 .",
    "this gives @xmath456 for all @xmath58 .",
    "when @xmath457 , the formula in ( [ e : add ] ) simplifies to @xmath458 substituting this into ( [ e : add ] ) , we see that for all @xmath459 , the optimal value @xmath460 is given by @xmath461 note that since the optimal vector @xmath455 depends on @xmath50 , we can not apply theorem [ gen.thm ] directly to characterize the asymptotic behavior of the function @xmath462 as @xmath37 .",
    "nevertheless , this function can be estimated from above by using jensen s inequality as follows : @xmath463\\\\ & = e^{\\lambda^\\perp { { \\eufrak b}}^{-1}\\lambda } n\\left(\\frac{\\bar w^\\perp \\lambda^ * + \\log x + \\sum_{i=1}^n \\bar w_i(\\log \\bar w_i - \\mu_i)}{\\sqrt{\\bar w^\\perp { { \\eufrak b}}\\bar w}}\\right),\\end{aligned}\\ ] ] where @xmath56 is the solution of and @xmath464 is the standard normal distribution function . substituting the expression in for @xmath455 and using , we obtain @xmath465 and @xmath466 therefore , as @xmath37 , @xmath467 where the constant @xmath130 is independent of @xmath50 . comparing the previous estimate with the asymptotics of @xmath452 ( see formula ) , we see that , for a different constant @xmath130 , @xmath468 as @xmath37 .",
    "this means that the relative error of the monte carlo estimate in with @xmath447 given by grows only logarithmically in @xmath50 as @xmath37 .    to test the performance of the proposed variance reduction algorithm , we have computed the monte carlo estimates with and without variance reduction for different levels @xmath50 , using the same numerical values of the parameters as above .",
    "table [ ratio.tab ] shows the ratio of the standard deviation of the estimate to that of the estimate , where the value of @xmath455 is given by .",
    "the reduction factors are greater than one for all values of @xmath50 and in general quite spectacular , ranging from @xmath469 for not so small probabilities of order of @xmath470 to hundreds for probabilities of order of @xmath471 .",
    ".standard deviation reduction factors obtained with the variance reduction estimate with the value of @xmath455 given by . [ cols=\"^,^,^,^,^,^ \" , ]",
    "the tail estimates obtained in this paper can be applied to risk management problems in the context of the @xmath4-dimensional black - scholes model .",
    "suppose that the dynamics of the asset price vector @xmath472 is described by the following @xmath4-dimensional stochastic process : @xmath473 where @xmath474 is an n - dimensional standard brownian motion , @xmath6 is the covariance matrix , @xmath475 is the drift vector , and @xmath476 stands for the main diagonal of @xmath6 .",
    "consider a portfolio containing the assets @xmath477 , @xmath3 with weights @xmath478 , and price process denoted by @xmath30 : @xmath479 the process @xmath30 can be alternatively expressed as @xmath480 , where @xmath481 in ( [ e : pr1 ] ) , the symbols @xmath482 stand for the elements of the matrix @xmath483 .",
    "we also set @xmath484 in the sequel , @xmath44 will be fixed , and the asymptotic formulas obtained in sections [ s : nachalo ] and [ s : tail1 ] will be applied to the random variable @xmath485 defined in ( [ e : bss ] ) .",
    "the gaussian data associated with the case described above are given by the following : the mean vector is @xmath486 and the covariance matrix is @xmath487 .      * evaluate various risk measures for the portfolio @xmath30 , such as the probability of loss of a given magnitude or the value at risk ( the quantile function ) .",
    "the probability of loss may be approximated using the asymptotic formulas of section [ s : nachalo ] ( for portfolios with only positive weights ) or section [ s : tail1 ] ( for portfolios with both positive and negative weights ) . *",
    "quantify the behavior of one portfolio in specific adverse scenarios of market evolution , which are typically defined in terms of another portfolio ( the benchmark ) .",
    "this can be done using our characterization of the asymptotic behavior of a gaussian vector conditionnally on the sum or difference of exponentials of its components ( corollaries [ laplacedens.cor ] and [ laplace2.cor ] ) .",
    "we address this issue in detail in the following paragraph .",
    "suppose that an investor holds a portfolio containing assets @xmath488 with weights @xmath489 .",
    "the value of such a portfolio is given by @xmath490 the 1996 market risk ammendment to basel i @xcite as well as basel ii and basel iii capital accords require banks and investment firms to conduct stress tests to determine their ability to respond to adverse market events .",
    "these adverse scenarios are typically defined in terms of the performance of a certain benchmark and correspond to a stylized version of certain crisis events observed in the past .",
    "we will next describe some examples of plausible stress scenarios and explain how the corresponding benchmark process @xmath30 can be defined .",
    "* _ equity market fall of a certain magnitude .",
    "this is the most common stress scenario .",
    "the benchmark process @xmath491 under such a scenario is the normalized market index , having the initial value @xmath367 , and the adverse event is @xmath492 for some @xmath493 and @xmath50 which is supposed small .",
    "the weights @xmath494 are then positive and equal to the normalized market capitalizations of the stocks . _ * _ a certain difference in performance between the equity markets of two geographical areas or two sectors .",
    "for instance , one may assume that the american markets outperform the european ones , or that small capitalization shares outperform large capitalization ones .",
    "let @xmath495 be the market index of the first area , where @xmath496 are the positive market capitalization weights of the stocks @xmath497 , and @xmath498 be the market index of the second area .",
    "the stress scenario is the event @xmath499 this can be dealt with in our framework by taking @xmath500 with the stress scenario @xmath492 . here",
    "the value of @xmath50 is large . _ * _ a certain difference in performance between two benchmarks .",
    "the investor may be interested , for example , in the event when her portfolio severely underperforms the market .",
    "this is similar to the case considered above , except that the two benchmarks may contain the same stocks .",
    "let the two benchmarks be given by @xmath501 and @xmath502 .",
    "we are once again interested in the stress scenario @xmath503 .",
    "this is equivalent to taking @xmath504 and using the stress scenario @xmath492 with @xmath50 large . _",
    "our results allow to approximate the conditional expected value under the stress scenarios of individual stocks @xmath505 , \\label{e : conex2}\\ ] ] and of the entire portfolio @xmath506 = \\sum_{i=1}^n v_i e_i(t , x ) .",
    "\\label{e : conex1}\\ ] ] the quantities @xmath507 can be estimated using formulas and for the conditional laplace transform , since @xmath508",
    "\\label{e : lap1}\\ ] ] for all @xmath3 .",
    "the following results are thus direct consequences of corollaries [ laplace.cor ] and [ laplace2.cor ] .        since @xmath513 for @xmath514 ( see remark [ remgt1 ] )",
    ", it follows from theorem [ stress.prop ] that the assets in the market index can be classified into two categories , depending on the behavior of their conditional expectation under the conditional law .",
    "* `` safe assets '' , whose conditional expectations decay proportionally to the value @xmath50 of the market index . those are exactly the assets , which enter the markowitz minimal variance portfolio ( solution of problem ) with strictly positive weights .",
    "* `` dangerous assets '' , whose conditional expectations decay faster than the index .",
    "suppose that for @xmath515 the weights @xmath496 are positive and @xmath516 are negative , that assumption @xmath517 holds for matrix @xmath6 with every @xmath518 , and that the set @xmath304 defined in is a singleton , @xmath305 .",
    "then the following are true .        * those assets , whose conditional expectations , given the stress scenario , grow proportionally to @xmath50 .",
    "this category includes exactly one asset among @xmath525 , that one with the highest relative asymptotic variance with respect to @xmath526 .",
    "it may or may not include some assets among @xmath526 .",
    "* those assets , whose conditional expectations , given the stress scenario , grow slower than @xmath50 .",
    "in other words , the fact that the portfolio @xmath527 strongly outperforms the portfolio @xmath528 can be attributed asymptotically to a very strong performance of a single stock among @xmath497 , which may be partially offset by the performance of some stocks from the second group .",
    "j. aitchison , j. a. c. brown , the lognormal distribution , cambridge university press , cambridge , 1957 .",
    "h. albrecher , s. asmussen , d. kortschak , tail asymptotics for the sum of two heavy - tailed dependent risks , extremes 9 ( 2006 ) ,",
    "107130 . s. asmussen , j. blanchet , s. juneja , l. rojas - nandayapa , efficient simulation of tail probabilities of sums of correlated lognormals , ann .",
    ". res 189 , ( 2011 ) 523 .",
    "s. asmussen , l. rojas - nandayapa , asymptotics of sums of lognormal random variables with gaussian copula , statistics and probability letters 78 ( 2008 ) , 27092714 . , amendment to the capital accord to incorporate market risks .",
    "n. bleistein , r. a. handelsman , asymptotic expansions of integrals , holt , rinehartand winston , new york , 1995 .",
    "e. barouch , g. m. kaufman , on sums of lognormal random variables , m.i.t .",
    "alfred p. sloan school of management , working paper  no.831 - 76 , 1976 .",
    "e. barouch , g. m. kaufman , m. l. glasser , on sums of lognormal random variables , studies in applied mathematics , 75 ( 1986 ) , 3755 .",
    "r. carmona , v. durrleman , pricing and hedging spread options , siam review , 45 ( 2003 ) , 627685 .",
    "e. l. crow , k. shimizu ( eds . ) , lognormal distributions : theory and applications , marcel dekker , inc . , new york , new york , 1988 .",
    "d. dufresne , the log - normal approximation in financial and other computations , adv .",
    "appl . prob .",
    "36 ( 2004 ) , 747773 .",
    "p. embrechts , g. puccetti , aggregating risk capital , with an application to operational risk , geneva risk insur .",
    "31 ( 2006 ) , 7190 .",
    "p. embrechts , g. puccetti , bounds for functions of multivariate risks , journal of multivariate analysis 97 ( 2006 ) , 526547 .",
    "p. embrechts , g. puccetti , bounds for functions of dependent risks , finance and stochastics 10 ( 2006 ) , 341352 .",
    "p. embrechts , g. puccetti , bounds for the sum of dependent risks having overlapping marginals , journal of multivariate analysis 101 ( 2009 ) , 177190 .",
    "s. foss , d. korshunov , s. zachary , an introduction to heavy - tailed and subexponential distributions , springer new york dordrecht heidelberg london , 2011 .",
    "s. foss , a. richards , on sums of conditionally independent subexponential random variables , mathematics of operations research 35 ( 2010),102119 .",
    "x. gao , h. xu , d. ye , asymptotic behavior of tail density for sum of correlated lognormal variables , international journal of mathematics and mathematical sciences volume 2009 .",
    "j. geluk , q. tang , asymptotic tail probabilities of sums of dependent subexponential random variables , j. theor .",
    "probab . , 22 ( 2009 ) , 871882 . n. l. johnson , s. kotz , distributions in statistics : continuous univariate distributions - 1 , houghton miffin company , boston , 1970 .",
    "b. ko , q. tang , sums of dependent nonnegative random variables with subexponential tails , j. appl .",
    ", 45 ( 2008 ) , 8594 .",
    "d. kortschak , h. albrecher , asymptotic results for the sum of dependent non - identically distributed random variables , methodology and computing in applied probability , 11 ( 2009 ) , 279306 .",
    "a. ligeti , outage probability in the presence of correlated lognormal useful and interfering components , ieee commun .",
    ", 4 , ( 2000 ) , 1517 .",
    "e. limpert , w. a. stahel , m. abbt , log - normal distributions across the sciences : keys and clues , bioscience 51 ( 2001 ) , 341352 . c. f. lo , the sum and difference of two lognormal random variables , journal of applied mathematics volume 2012 .",
    "a. j. mcneil , r. frey , p. embrechts , quantitative risk management : concepts , techniques , tools , princeton university press , princeton , nj , 2005 .",
    "l. rojas - nandayapa , risk probabilities : asymptotics and simulation , ph.d .",
    "dissertation , department of mathematical sciences , faculty of sciences , university of aarhus , 2008 .",
    "d. senaratne , c. tellambura , numerical computation of the lognormal sum distribution , globecom 2009 : 16 . s. s. szyszkowicz , h. yanikomeroglu , on the tails of the distribution of the sum of lognormals , in proceeding of ieee international conference on communications , 2007 . icc 07 . c. tellambura , bounds on the distribution of a sum of correlated lognormal random variables and their application , ieee transactions on communications , 56 ( 2008 ) , 12411248 . c. tellambura , d. senaratne , accurate computation of the mgf of the lognormal distribution and its application to sum of lognormals , ieee transactions on communications 58 ( 2010 ) , 15681577 . s. vanduffel , x. chen , j. dhaene , m. goovaerts , l. henrard , r. kaas , optimal approximations for risk measures of sums of lognormals based on conditional expectations , journal of computational and applied mathematics 221 ( 2008 ) , 202218 .",
    "yuen , c. yin , asymptotic results for tail probabilities of sums of dependent heavy - tailed random variables , chin .",
    "ann . math .",
    "33b ( 2012 ) , 557568 ."
  ],
  "abstract_text": [
    "<S> we present sharp tail asymptotics for the density and the distribution function of linear combinations of correlated log - normal random variables , that is , exponentials of components of a correlated gaussian vector . </S>",
    "<S> the asymptotic behavior turns out to be determined by a subset of components of the gaussian vector , and we identify the relevant components by relating the asymptotics to a tractable quadratic optimization problem . as a corollary , we characterize the limiting behavior of the conditional law of the gaussian vector , given a linear combination of the exponentials of its components . </S>",
    "<S> our results can be used either to estimate the probability of tail events directly or to construct efficient variance reduction procedures for precise estimation of these probabilities by monte carlo methods . </S>",
    "<S> they lead to important qualitative and quantitative insights concerning the behavior of individual stocks and portfolios during market downturns in the multidimensional black - scholes model .    </S>",
    "<S> key words : log - normal random variables , tail - behavior , laplace s method , monte carlo method , importance sampling , multidimensional black - scholes model , risk management , stress testing .    </S>",
    "<S> msc2010 : 62e20 , 91b30 , 91g10 </S>"
  ]
}