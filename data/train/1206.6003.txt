{
  "article_text": [
    "measurement quantization is a critical step in the design and in the dissemination of new technologies implementing the compressed sensing ( cs ) paradigm .",
    "quantization is indeed mandatory for transmitting , storing and even processing any data sensed by a cs device .    in its most popular version ,",
    "cs provides uniform theoretical guarantees for stably recovering any sparse ( or compressible ) signal at a sensing rate proportional to the signal intrinsic dimension ( _ i.e. _ , its _ sparsity _ level ) @xcite .",
    "however , the distortion introduced by any quantization step is often still crudely modeled as a noise with bounded @xmath0-norm .",
    "such an approach results in reconstruction methods aiming at finding a sparse signal estimate for which the sensing is close , in a @xmath0-sense , to the available quantized signal observations .",
    "however , earlier works have pointed out that this method is not optimal .",
    "for instance , @xcite analyses the error achieved when a signal is reconstructed from its quantized coefficients in some overcomplete expansion",
    ". translated to our context , this amounts to the ideal cs scenario where some _ oracle _ provides us the true signal support knowledge . in this context , a linear _ least square _",
    "( ls ) reconstruction minimizing the @xmath0-distance in the coefficient domain is inconsistent and has a _ mean square error _ ( mse ) decaying , at best , as the inverse of the frame redundancy factor .",
    "interestingly , any _ consistent _ reconstruction method , _",
    "i.e. _ , for which the quantized coefficients of the reconstructed signal match those of the original signal , shows a much better behavior since its mse is in general lower - bounded by the inverse of the _ squared _ frame redundancy ; this lower bound being attained for specific overcomplete fourier frames .",
    "a few other works in the compressed sensing literature have also considered the quantization distortion differently . in @xcite , an adaptation of both basis pursuit denoise ( bpdn ) program and the subspace pursuit algorithm",
    "integrates an explicit constraint enforcing consistency . in @xcite , nonuniform quantization noise and gaussian noise in the measurements before quantization",
    "are properly dealt with using an @xmath1-penalized maximum likelihood decoder .    finally , in @xcite , the extreme case of 1-bit cs is studied , _",
    "i.e. _ , when only the signs of the measurements are sent to the decoder .",
    "these works have shown that consistency with the 1-bit quantized measurements is of paramount importance for reconstructing the signal where straightforward methods relying on @xmath0 fidelity constraints reach poor estimate quality .",
    "the present work addresses the problem of recovering sparse or compressive signals in a _ given _ non - uniform quantized compressed sensing ( qcs ) scenario .",
    "in particular , we assume that the signal measurements have undergone an optimal non - uniform scalar quantization process , _ i.e. _ , optimized a priori according to a common minimal distortion standpoint with respect to a source with known probability density function ( pdf ) .",
    "this _ post - quantization _ reconstruction strategy , where only increasing the number of measurements can improve the signal reconstruction , is inspired by other works targeting consistent reconstruction approaches in comparison with methods advocating solutions of minimal @xmath0-distortion @xcite .",
    "our work is therefore distinct from approaches where other quantization schemes ( _ e.g. _ , @xmath12-quantization @xcite ) are tuned to the global cs formalism or to specific cs decoding schemes ( _ e.g. _ , message passing reconstruction @xcite ) .",
    "these techniques often lead to signal reconstruction mse rapidly decaying with the measurement number @xmath13    for instance , a @xmath14-order @xmath12-quantization of cs measurements combined with a particular reconstruction procedure has a mse decaying nearly as @xmath15 @xcite    but their application involves generally more involved quantization strategies at the cs encoding stage .",
    "this paper also generalizes the results provided in @xcite to cover the case of non - uniform scalar quantization of cs measurements .",
    "we show that the theory of `` companders '' @xcite provides an elegant framework for stabilizing the reconstruction of a sparse ( or compressible ) signal from non - uniformly quantized cs measurements . under the _ high resolution assumption _ ( hra ) , _ i.e. _ , when the bit budget of the quantizer is high and the quantization bins are narrow , the compander theory provides an equivalent description of the action of a quantizer through sequential application of a _",
    "_ comp__ressor , a uniform quantization , then an ex__pander _ _ ( see section  [ sec : quant - fram ] for details ) . as will be clearer later",
    ", this equivalence allows us to define new distortion constraints for the signal reconstruction which are more faithful to the non - uniform quantization process given a certain qcs measurement regime .",
    "algorithms for reconstructing from quantized measurements commonly rely on mathematically describing the noise induced by quantization as bounded in some particular norm . a data fidelity constraint reflecting this fact",
    "is then incorporated in the reconstruction method .",
    "two natural examples of such constraints are that the @xmath0-norm be bounded , or that the quantization error be such that the unquantized values lie in specified , known quantization bins . in this paper , guided by the compander theory , we show that these two constraints can be viewed as special ( extreme ) cases of a particular _ weighted _",
    "@xmath2-norm , which forms the basis for our reconstruction method .",
    "the weights are determined from a set of @xmath11-optimal quantizer levels , that are computed from the observed quantized values .",
    "we draw the reader attention to the fact these weights do not depend on the original signal which is of course unknown .",
    "they are used only for signal reconstruction purposes , and are optimized with respect to the weighted norm . in the qcs framework , and owing to the particular weighting of the norm , each quantization bin contributes equally to the related global distortion .",
    "thanks to a new estimator of the weighted @xmath2-norm of the quantization distortion associated to these particular levels ( see lemma  [ lemma : bound - lpw - gaussian - vector ] ) , and with the proviso that the sensing matrix obeys a generalized restricted isometry property ( rip ) expressed in the same norm ( see ) , we show that solving a general basis pursuit denoising program ( gbpdn )  an @xmath1-minimization problem constrained by a weighted @xmath2-norm whose radius is appropriately estimated ",
    "stably recovers strictly sparse or compressible signals ( see theorem  [ prop : l2-l1-instance - optimality - gbpdn ] ) .",
    "we also quantify precisely the reconstruction error of gbpdn as a function of the quantizer bit rate ( under the hra ) for any value of @xmath11 in the weighted @xmath2 constraint .",
    "these results reveal a set of conflicting considerations for setting the optimal @xmath11 . on the one hand , given a budget of @xmath9 bits per measurement and for a high number of measurements @xmath13 , the error decays as @xmath8 when @xmath11 increases ( see proposition  [ prop : towards - quant - cons ] ) , _ i.e. _ , a favorable situation since then gbpdn tends also to a consistent reconstruction method . on the other hand , the larger @xmath11 , the greater the number of measurements required to ensure that the generalized rip is fulfilled .",
    "in particular , one needs @xmath16 measurements compared to a @xmath0-based cs bound of @xmath17 measurements ( see proposition  [ prop : grip - gauss ] ) . put differently , given a certain number of measurements , the range of theoretically admissible @xmath11 is upper bounded ,",
    "an effect which is expected since the error due to quantization can not be eliminated in the reconstruction .",
    "in fact , the stability of gbpdn in the context of qcs is a consequence of a an even more general stability result that holds for a broader class additive heteroscedastic measurement noise having a bounded weighted @xmath2 norm .",
    "this for instance covers the case of heteroscedastic generalized gaussian noise where the constraint of gbpdn can be interpreted as a ( variance ) stabilization of the measurement distortion , see section  [ sec : case - heter - nois ] ) .",
    "our work is novel in several respects .",
    "for instance , as stated above , the quantization distortion in the literature is often modeled as a mere gaussian noise with bounded variance @xcite . in @xcite ,",
    "only uniform quantization is handled and theoretically investigated . in @xcite , nonuniform quantization noise and gaussian noise are handled but theoretical guarantees are lacking . to the best of our knowledge , this is the first work thoroughly investigating the theoretical guarantees of @xmath1 sparse recovery from non - uniformly quantized cs measurements , by introducing a new class of convex @xmath1 decoders . the way we bring the compander theory in the picture to compute the optimal weights from the quantized measurements is also an additional originality of this work .",
    "the paper is organized as follows . in section  [ sec : non - uniform - scalar ] , we recall the theory of optimal scalar quantization seen through the compander formalism . we then explain how this point of view can help us in understanding the intrinsic constraints that quantized cs measurements must satisfy , and we introduce a new distortion measure , the @xmath11-distortion consistency , expressed in terms of a weighted @xmath2-norm .",
    "section  [ sec : weight - fidel - guar ] introduces the gbpdn cs class of decoders integrating weighted @xmath2-constraints , and describes sufficient conditions for guaranteeing reconstruction stability .",
    "this section shows also the generality of this procedure for stabilizing additive heteroscedastic ggd measurement noise during the signal reconstruction . in section  [ sec : dequ - with - gener ] , we explain how gbpdn can be used for reconstructing a signal in qcs when its fidelity constraint is adjusted to the parameters defined in section  [ sec : p - optimal - levels ] .",
    "we show that this specific choice leads to a ( variance ) stabilization of the quantization distortion forcing each quantization bin to contribute equally to the overall distortion error . in section  [ sec : numer - exper ] , we describe a provably convergent primal - dual proximal splitting algorithm to solve the gbpdn program , and demonstrate the power of the proposed approach with several numerical experiments on sparse signals .",
    "all finite space dimensions are denoted by capital letters ( _ e.g. _ , @xmath18 ) , vectors ( resp .",
    "matrices ) are written in small ( resp .",
    "capital ) bold symbols . for any vector @xmath19 ,",
    "the @xmath2-norm for @xmath20 is @xmath21 , as usual @xmath22 and we write @xmath23 .",
    "we write @xmath24 , which counts the number of non - zero components .",
    "we denote the set of @xmath4-sparse vectors in the canonical basis by @xmath25 .",
    "when necessary , we write @xmath26 as the normed vector space @xmath27 .",
    "the identity matrix in @xmath28 is written @xmath29 ( or simply @xmath30 if the @xmath31 is clear from the context ) .",
    "@xmath32 is the diagonal matrix with diagonal entries from @xmath19 , _",
    "i.e. _ , @xmath33 . given the @xmath34-dimensional signal space @xmath5 , the index set is @xmath35=\\{1,\\,\\cdots , n\\}$ ] , and @xmath36 is the restriction of the columns of @xmath37 to those indexed in the subset @xmath38 $ ] , whose cardinality is @xmath39 .",
    "given @xmath40 , @xmath41 stands for the best @xmath4-term @xmath0-approximation of @xmath42 in the orthonormal basis @xmath43 , that is , @xmath44 . when @xmath45 , we write @xmath46 with @xmath47 . a random matrix @xmath48 is a @xmath49 matrix with entries @xmath50 .",
    "the 1-d gaussian pdf of mean @xmath51 and variance @xmath52 is denoted @xmath53 .    for a function @xmath54 ,",
    "we write @xmath55 , with @xmath56 .    in order",
    "to state many results which hold asymptotically as a dimension @xmath57 increases , we will use the common landau family of notations , _",
    "i.e. _ , the symbols @xmath58 , @xmath59 , @xmath60 , @xmath61 , and @xmath62 ( their exact definition can be found in @xcite ) .",
    "additionally , for @xmath63 , we write @xmath64 when @xmath65 .",
    "we also introduce two new asymmetric notations dealing with asymptotic quantity ordering ,  _ i.e. _ , @xmath66 if any of the asymptotic relations above hold with respect to several large dimensions @xmath67 , we write @xmath68 and correspondingly for @xmath69 and @xmath70 .",
    "let us consider a signal @xmath71 to be measured .",
    "we assume that it is either strictly sparse or compressible , in a prescribed orthonormal basis @xmath72 .",
    "this means that the signal @xmath73 is such that the @xmath74-approximation error @xmath75 quickly decreases ( or vanishes ) as @xmath4 increases . for the sake of simplicity , and without loss of generality , the sparsity basis is taken in the sequel as the standard basis , _",
    "i.e. _ , @xmath76 , and @xmath77 is identified with @xmath42 .",
    "all the results can be readily extended to other orthonormal bases @xmath78 .    in this paper , we are interested in compressively sensing @xmath40 with a given measurement matrix @xmath79 .",
    "each cs measurement , _",
    "i.e. _ , each entry of @xmath80 , undergoes a general scalar _",
    "quantization_. we will assume this quantization to be optimal relative to a known distribution of each entry @xmath81 .",
    "for simplicity , we only consider matrices @xmath37 that yield @xmath81 to be i.i.d .",
    "@xmath82 gaussian , with pdf @xmath83 .",
    "this is satisfied , for instance , if @xmath48 , with @xmath84 . when @xmath85^t$ ] is a ( fixed ) realization of @xmath86 , the entries @xmath87 of the vector @xmath88 are @xmath13 ( fixed ) realizations of the same gaussian distribution @xmath89 .",
    "it is therefore legitimate to quantize these values optimally using the normality of the source .",
    "is adversarially forged knowing @xmath37 for breaking this assumption . ] .",
    "our quantization scenario uses a @xmath9-bit quantizer @xmath90 which has been optimized with respect to the measurement pdf @xmath91 for @xmath92 levels @xmath93 and thresholds @xmath94 with @xmath95 . unlike the framework developed in @xcite , our sensing scenario considers that any noise corrupting the measurements before quantization is negligible compared to the quantization distortion .",
    "consequently , given a measurement matrix @xmath96 , our quantized sensing model is @xmath97\\ = \\",
    "{ \\mathcal}q[{\\boldsymbol}z]\\ \\in \\omega^m.\\ ] ]    following recent studies @xcite in the cs literature , this work is interested in optimizing the signal reconstruction stability from @xmath98 under different sensing conditions , for instance , when the _ oversampling ratio _ @xmath99 is allowed to be large . before going further into this signal sensing model , let us describe first the selected quantization framework .",
    "the latter is based on a scalar quantization of each component of the signal measurement vector .",
    "a scalar quantizer @xmath90 is defined from @xmath100 _ levels _ @xmath101 ( coded by @xmath102 bits ) and @xmath103 _ thresholds _",
    "@xmath104 , with @xmath105 and @xmath106 for all @xmath107 .",
    "the @xmath108 quantizer _ bin _ ( or _ region _ ) is @xmath109 , with bin width @xmath110 .",
    "the quantizer @xmath90 is a map : @xmath111 , @xmath112 = \\omega_k \\iff t\\in { \\mathcal}r_k$ ] .",
    "an optimal scalar quantizer @xmath90 with respect to a random source @xmath113 with pdf @xmath114 is such that the distortion @xmath115|^2 $ ] is minimized .",
    "optimal levels and thresholds can be calculated for a fixed number of quantization bins by the lloyd - max algorithm @xcite , or by an asymptotic ( with respect to  @xmath9 ) _ companding _ approach @xcite .    throughout this paper",
    ", we work under the hra .",
    "this means that , given the source pdf @xmath114 , the number of bits @xmath9 is sufficient to validate the approximation @xmath116    a common argument in quantization theory @xcite states that under the hra , every optimal regular quantizer can be described by a compander ( a portemanteau for `` * * comp**ressor '' and `` exp*ander * '' ) .",
    "more precisely , we have @xmath117 with @xmath118 $ ] a bijective function called the _ compressor _ , @xmath119 a uniform quantizer of the interval @xmath120 $ ] of bin width @xmath121 , and the inverse mapping @xmath122\\to{\\mathbb{r}}$ ] called the _ expander_.    for optimal quantizers the compressor @xmath123 maps the thresholds @xmath124 and the levels @xmath125 into the values @xmath126 and under the hra the optimal @xmath123 satisfies @xmath127^{-1}\\,{\\varphi}_{{\\mathcal}z}^{1/3}(\\lambda).\\ ] ] intuitively , the function @xmath128 , also called _ quantizer point density function _ ( qpdf ) @xcite , relates the quantizer bin widths before and after domain compression by @xmath123 . indeed , under hra , we can show that @xmath129 if @xmath130 .",
    "we will see later that this function is the key to conveniently weight some new quantizer distortion measures .",
    "we note that , for @xmath131 with cumulative distribution function @xmath132 so that @xmath133 , we have @xmath134 and @xmath135 .    the application of @xmath123 modifies the source @xmath113 such that @xmath136)$ ] behaves more like a uniformly distributed random variable over @xmath137 $ ] .",
    "the compander formalism predicts the distortion of optimal scalar quantizer under hra . for high bit rate @xmath9 ,",
    "the panter and dite formula @xcite states that @xmath138|^2\\ \\mathop{\\simeq}_b\\ \\tfrac{2^{-2b}}{12}\\,\\int_{{\\mathbb{r } } } { \\mathcal}g'(t)^{-2}\\,{\\varphi}_{{\\mathcal}z}(t)\\,{\\mathrm{d}}t\\ = \\ \\tfrac{2^{-2b}}{12}\\,\\bigg(\\int_{{\\mathbb{r } } } \\,{\\varphi}_{{\\mathcal}z}^{1/3}(t)\\,{\\mathrm{d}}t\\bigg)^3\\ = \\ \\tfrac{2^{-2b}}{12}\\,{|\\!|\\!|{\\varphi}_{{\\mathcal}z}|\\!|\\!|}_{1/3}.\\ ] ]    finally , we note that by the construction defined in , the quantized values @xmath139 $ ] satisfy latexmath:[\\[\\label{eq : compressor - consistent - rel }    we describe in the next sections how and may be viewed as two extreme cases of a general class of constraints satisfied by a quantized source @xmath113 .",
    "let us consider the sensing model , for which the scalar quantizer @xmath90 and associated compressor @xmath123 are optimal relative to the measurements @xmath88 whose entries @xmath81 are @xmath141 realizations of @xmath82 . in the compressor domain we may write @xmath142 ) - { \\mathcal}g({\\boldsymbol}z ) ) = { \\mathcal}g({\\boldsymbol}z ) + { \\boldsymbol}\\varepsilon,\\ ] ] where @xmath143 represents the quantization distortion .",
    "then shows that @xmath144 ) - { \\mathcal}g({\\boldsymbol}z)\\|_{\\infty } { \\leqslant}{\\upalpha}/2.\\ ] ]    naively , one may expect any reasonable estimate @xmath145 of @xmath42 ( obtained by some reconstruction method ) to reproduce the same quantized measurements as originally observed .",
    "inspired by the terminology introduced in @xcite , we say that @xmath145 satisfies the _ quantization consistency _",
    "( qc ) if @xmath146 = { \\boldsymbol}y$ ] . from the previous reasoning",
    "this is equivalent to @xmath147    at first glance , it is tempting to try to impose directly qc in the data fidelity constraint . however , as will be revealed by our analysis , directly imposing qc does _ not _ lead to an effective qcs reconstruction algorithm .",
    "this counterintuitive effect , already observed in the case of signal recovery from uniformly quantized cs @xcite , is due to the specific requirements that the sensing matrix should respect to make such a consistent reconstruction method stable .",
    "in contrast the basis pursuit denoise ( bpdn ) program @xcite enforces a constraint on the @xmath0 norm of the reconstruction quantization error , which we will call distortion consistency . for bpdn , the estimate @xmath145 is provided by @xmath148 where the bound @xmath149 is dictated by the panter - dite formula . according to the strong law of large numbers ( slln ) obeyed by the hra , and",
    "since @xmath81 are @xmath141 realizations of @xmath150 , the following holds almost surely @xmath151\\|^2\\ \\mathop{\\simeq}_{m}\\ { { \\mathbb{e}}}|{\\mathcal}z - { \\mathcal}q[{\\mathcal}z]|^2\\ \\mathop{\\simeq}_{b}\\ \\tfrac{2^{-2b}}{12 } { |\\!|\\!|{\\varphi}_0|\\!|\\!|}_{1/3 } = \\   \\tfrac{\\sqrt{3}\\,\\pi}{2}\\,\\sigma_0 ^ 2\\ , 2^{-2b } .\\ ] ] accordingly , we say that any estimate @xmath145 satisfies _ distortion consistency _ ( dc ) if @xmath152    however , as stated for the uniform quantization case in @xcite , dc and qc do not imply each other .",
    "in particular , the output @xmath145 of bpdn needs not satisfy quantization consistency .",
    "a major motivation for the present work is the desire to develop provably stable qcs recovery methods based on measures of quantization distortion that are as close as possible to qc .",
    "this section shows that the qc and dc constraints may be seen as limit cases of a weighted @xmath2-norm description of the quantization distortion .",
    "the expression of the appropriate weights in the weighted @xmath2 norm will depend both on the @xmath11-optimal quantizer levels , described below , and of the quantizer point density function @xmath128 introduced in section  [ sec : quant - fram ] .",
    "for the gaussian pdf @xmath153 , given a set of thresholds @xmath124 , we define the @xmath11-_optimal quantizer levels _ @xmath154 as @xmath155 for @xmath156 , and @xmath157 .",
    "these generalized levels were for instance already defined by max in his minimal distortion study @xcite , and their definition is also related to the concept of minimal @xmath158-power distortion @xcite . for @xmath159 , we find the definition of the initial quantizer levels , _",
    "i.e. _ , @xmath160 . in this paper",
    ", we always assume that @xmath11 is a positive integer but all our analysis can be extended to the positive real case . as proved in appendix  [ sec : p - optimal - level - definiteness ] , the @xmath11-optimal levels are well - defined .",
    "[ lemma : p - optimal - levels ] the @xmath11-optimal levels @xmath161 are uniquely defined .",
    "moreover , for @xmath162 , @xmath163 , with @xmath164 for @xmath165 .    using these new levels , we define the ( suboptimal ) quantizers @xmath166 ( with @xmath167 ) such that @xmath168 = \\omega_{k , p}\\ \\leftrightarrow\\ t\\in{\\mathcal}r_k = { \\mathcal}q_p^{-1}[\\omega_{k , p } ] = { \\mathcal}q^{-1}[\\omega_k].\\ ] ]    two important points must be explained regarding the definition of @xmath166 . first , the _",
    "( re)quantization _ of any source @xmath113 with @xmath166 is possible from the knowledge of the quantized value @xmath169 $ ] , as @xmath170={\\mathcal}q_p[{\\mathcal}q[{\\mathcal}z]]$ ] since both quantizers share the same decision thresholds .",
    "second , despite the sub - optimality of @xmath166 relative to the untouched thresholds @xmath124 , we will see later that introducing this quantizer provides improvement in the modeling of @xmath170 - { \\mathcal}z$ ] by a generalized gaussian distribution ( ggd ) in each quantization bin .",
    "unfortunately , there is no closed form formula for computing @xmath161 .",
    "however , as detailed in appendix  [ sec : comp - omeg - p ] , they can be computed up to numerical precision using newton s method combined with simple numerical quadrature for the integral in .",
    "given @xmath3 and for high @xmath9 , the asymptotic behavior of a quantizer @xmath166 and of its @xmath158 _ power distortion _",
    "@xmath171 in each bin @xmath172 follows two very different regimes in @xmath173 governed by a particular transition value @xmath174 .",
    "this is described in the following lemma ( proved in appendix  [ proof - toolbox - lemma ] ) , which , to the best of our knowledge , provides new results and may be of independent interest for characterizing gaussian source quantization ( even for the standard case @xmath159 ) .",
    "[ lemma : useful - ineq ] given the gaussian pdf @xmath175 and its associated compressor @xmath123 function , choose @xmath176 and @xmath177 , and define the transition value @xmath178 @xmath179 defines two specific asymptotic regimes for the quantizer @xmath166 :    1 .",
    "the _ vanishing bin regime _",
    "$ ] : for all @xmath181 and any @xmath182 , the bin widths decay as @xmath183 , and the the related @xmath184-power distortion and _ qpdf _ asymptotically obey @xmath185 2 .",
    "the _ vanishing distortion regime _",
    "@xmath186 : we have @xmath187 for all @xmath188 . moreover , the number of bins in @xmath186 and their @xmath184-power distortion decay , respectively , as @xmath189    we now state an important result , proved in appendix [ proof - lemma - bound - lpw - gaussian - vector ] from the statements of lemma  [ lemma : useful - ineq ] , which , together with the slln , estimates the quantization distortion of @xmath166 on a random gaussian vector . given @xmath190 and some positive weights",
    "@xmath191 , this distortion is measured by a weighted @xmath2-norm defined as - norm definition reads @xmath192 . our definition choice , which is strictly equivalent , offers useful writing simplifications , _",
    "e.g. _ , when observing that @xmath193 with @xmath194 . ]",
    "@xmath195 for any @xmath196 .",
    "[ lemma : bound - lpw - gaussian - vector ] let @xmath197 be a random vector where each component @xmath198 .",
    "given the optimal compressor function @xmath123 associated to @xmath175 and the weights @xmath199 such that @xmath200\\big)^{(p-2)/p}$ ] for @xmath3 , the following holds almost surely @xmath201 - { \\boldsymbol}z\\|^p_{p,{\\boldsymbol}w}\\ \\mathop{\\simeq}_{b , m}\\       m\\ , \\tfrac{2^{-bp}}{(p+1)\\,2^{p}}\\,{|\\!|\\!|{\\varphi}_0|\\!|\\!|}_{1/3}\\ { = : } \\ \\epsilon_p^p,\\ ] ] with @xmath202 .",
    "this lemma provides a tight estimation for @xmath159 and @xmath203 .",
    "indeed , in the first case @xmath204 and the bound matches the panter - dite estimation . for @xmath205 , we observe that @xmath206 .     comparing the theoretical bound @xmath207 to the empirical mean estimate of @xmath208 - { \\boldsymbol}z\\|_{p,{\\boldsymbol}w}$ ] using 1000 trials of monte - carlo simulations , for each @xmath209).,width=283 ]    fig .  [",
    "fig : testing_eps_p_bound ] shows how well the @xmath207 estimates the distortion @xmath210 - { \\boldsymbol}z\\|_{p,{\\boldsymbol}w}$ ] for the weights and the @xmath11-optimal levels given in lemma 2 .",
    "this has been measured by averaging this quantization distortion for 1000 realizations of a gaussian random vector @xmath211 with @xmath212 , @xmath213 and @xmath214 and 5 .",
    "we observe that the bias of @xmath207 , as reflected here by the ratio @xmath215 - { \\boldsymbol}z\\|_{p,{\\boldsymbol}w}$ ] , is rather limited and decreases when @xmath11 and @xmath9 increase with a maximum relative error of about @xmath216 between the true and estimated distortion at @xmath217 and @xmath159 .",
    "inspired by relation , we say that an estimate @xmath218 of @xmath42 sensed by the model satisfies the _ @xmath11-distortion consistency _",
    "( or d@xmath219c ) if @xmath220\\|_{p,{\\boldsymbol}w}\\ { \\leqslant}\\    \\epsilon_p,\\tag{\\bf d$_p$c}\\end{aligned}\\ ] ] with the weights @xmath221)^{(p-2)/p}$ ] .",
    "the class of d@xmath219c constraints has qc and dc as its limit cases .",
    "[ lemma : equiv - d2c - dinfc ] given @xmath222 $ ] , we have asymptotically in @xmath9 @xmath223    let @xmath224 be a vector to be tested with the dc , qc or d@xmath219c constraints .",
    "the first equivalence for @xmath159 is straightforward since @xmath225 , @xmath226\\|_{p,{\\boldsymbol}w } = \\|{\\boldsymbol}\\phi { \\boldsymbol}x^ * - { \\mathcal}q[{\\boldsymbol}y]\\|_{2}$ ] and @xmath227 from .    for the second , we use the fact that @xmath222 $ ] is fixed by the sensing model . let us denote by @xmath228 the index of the bin to which @xmath229 $ ] belongs for @xmath230 . since @xmath231 is fixed , and because relation in lemma  [ lemma : useful - ineq ] implies that the amplitude of the first or of the last @xmath232 thresholds grow faster than @xmath233 for @xmath176 , there exists necessarily a @xmath234 such that @xmath235 for all @xmath236 and all @xmath237 .",
    "writing @xmath238 , we can use the equivalence @xmath239 and the squeeze theorem on the following limit : @xmath240\\|_{p,{\\boldsymbol}w(p ) }   = \\",
    "\\lim_{p\\to\\infty}\\|{\\boldsymbol}w_{\\!\\!p}\\big(\\phi { \\boldsymbol}x^ * - { \\mathcal}q_p[{\\boldsymbol}y]\\big)\\|_{p}\\\\   = \\",
    "\\lim_{p\\to\\infty}\\,\\|{\\boldsymbol}w_{\\!\\!p}\\big(\\phi { \\boldsymbol}x^ * - { \\mathcal}q_p[{\\boldsymbol}y]\\big)\\|_{\\infty}.\\ ] ]    moreover , since for @xmath236 and for all @xmath237 the bin @xmath241 is finite , the limit @xmath242)^{(p-2)/p}\\,\\big|({\\boldsymbol}\\phi { \\boldsymbol}x^*)_i - { \\mathcal}q_p[y_i]\\big|\\ ] ] exists and is finite .",
    "therefore , from the continuity of the @xmath243 function applied on the @xmath13 components of vectors in @xmath244 , we find @xmath245\\|_{p,{\\boldsymbol}w(p)}&=\\ \\lim_{p\\to\\infty}\\,\\max_{i}\\,{\\mathcal}g'({\\mathcal}q_p[y_i])^{(p-2)/p}\\,\\big|({\\boldsymbol}\\phi { \\boldsymbol}x^*)_i - { \\mathcal}q_p[y_i]\\big|\\\\ & = \\ \\max_{i}\\,\\lim_{p\\to\\infty}\\ { \\mathcal}g'({\\mathcal}q_p[y_i])^{(p-2)/p}\\,\\big|({\\boldsymbol}\\phi { \\boldsymbol}x^*)_i - { \\mathcal}q_p[y_i]\\big|\\\\ & = \\",
    "\\max_{i}\\,{\\mathcal}g'({\\mathcal}q_\\infty(y_i))\\,\\big|({\\boldsymbol}\\phi { \\boldsymbol}x^*)_i - { \\mathcal}q_\\infty(y_i)\\big|.\\end{aligned}\\ ] ]    for @xmath236 , provides @xmath246 , so that , if we impose @xmath247\\|_{p,{\\boldsymbol}w(p ) } { \\leqslant}\\epsilon_{\\rm qc } = { \\upalpha}/2 $ ] , we get asymptotically in @xmath9 @xmath248 which is equivalent to imposing @xmath249 , _",
    "i.e. _ , the quantization constraint .",
    "the last section has provided us some weighted @xmath250 constraints , with appropriate weights @xmath251 , that can be used for stabilizing the reconstruction of a signal observed through the quantized sensing model .",
    "we now turn to studying the stability of @xmath1-based decoders integrating these weighted @xmath250-constraints as data fidelity .",
    "we will highlight also the requirements that the sensing matrix must fulfill to ensure this stability .",
    "we then then apply this general stability result to additive heteroscedastic ggd noise , where weighing can be view as a variance stabilization transform .",
    "section  [ sec : dequ - with - gener ] will later instantiate the outcome of this section to the particular case of qcs .      given some positive weights @xmath252 and @xmath3 , we study the following general minimization program , coined general basis pursuit denoise ( gbpdn ) , @xmath253 where @xmath254 is the weighted @xmath2-norm defined in the previous section . note that bpdn is special case of gbpdn corresponding to @xmath159 and @xmath204 .",
    "the basis pursuit dequantizers ( bpdq ) introduced in @xcite are associated to @xmath190 and @xmath204 , while the case @xmath255 and @xmath204 has also been covered in @xcite .",
    "we are going to see that the stability of gbpdn@xmath256 is guaranteed if @xmath37 satisfies a particular instance of the following general isometry property .",
    "given two normed spaces @xmath257 and @xmath258 ( with @xmath259 ) , a matrix @xmath96 satisfies the restricted isometry property from @xmath260 to @xmath261 at order @xmath262 , radius @xmath263 and for a normalization @xmath264 , if for all @xmath265 , @xmath266 @xmath267 being an exponent function of the geometries of @xmath268 .",
    "to lighten notation , we will write that @xmath37 is rip@xmath269 .",
    "we may notice that the common rip is equivalent to are normalized to unit - norm . ]",
    "rip@xmath270 with @xmath271 , while the rip@xmath272 introduced earlier in @xcite is equivalent to rip@xmath273 with @xmath274 and @xmath275 depending only on @xmath13 , @xmath11 and @xmath276 . moreover , the rip@xmath277 defined in @xcite is equivalent to the rip@xmath278 with @xmath271 , @xmath279 and @xmath280 .",
    "finally , the restricted @xmath11-isometry property proposed in @xcite is also equivalent to the rip@xmath281 with @xmath282 .    in order to study the behavior of the gbpdn program , we are interested in the embedding induced by @xmath37 in of @xmath283 into the normed space @xmath284 , _",
    "i.e. _ , we consider the rip@xmath285 property that we write in the following as rip@xmath286 .",
    "the following theorem establishes that gbpdn provides stable recovery from distorted measurements , if the rip@xmath286 holds .",
    "[ prop : l2-l1-instance - optimality - gbpdn ] let @xmath287 , @xmath288 and @xmath96 be a rip@xmath289 matrix for @xmath290 such that @xmath291 then , for any signal @xmath40 observed according to the noisy sensing model @xmath292 with @xmath293 , the unique solution @xmath294 obeys @xmath295 where @xmath296 is the @xmath4-term @xmath1-approximation error .    if @xmath37 is rip@xmath289 for @xmath290 , then , by definition of the weighted @xmath250-norm , @xmath297 is rip@xmath298 .",
    "since @xmath299 , the stability results proved in ( * ? ? ?",
    "* theorem 2 ) for gbpdn@xmath300 shows that @xmath301 with @xmath302 , @xmath303 and @xmath304 @xcite .",
    "it is easy to see that if holds , then @xmath305 and @xmath306 .",
    "as we shall see shortly , this theorem may be used to characterize the impact of measurement corruption due to both additive heteroscedastic ggd noise ( section  [ sec : case - heter - nois ] ) as well as those induced by a non - uniform scalar quantization ( section  [ sec : dequ - with - gener ] ) . before detailing these two sensing scenarios , we first address the question of designing matrices satisfying the rip@xmath286 for @xmath307 .",
    "we will describe a random matrix construction that will satisfy the rip@xmath286 for @xmath20 . to quantify when this is possible ,",
    "we introduce some properties on the positive weights @xmath251 .",
    "[ def : bound - weight - moment ] a weight generator @xmath308 is a process ( random or deterministic ) that associates to @xmath309 a weight vector @xmath310 .",
    "this process is said to be of converging moments ( cm ) if for @xmath190 and all @xmath311 for a certain @xmath312 , @xmath313 where @xmath314 and @xmath315 are , respectively , the largest and the smallest values such that holds . in other words , a cm generator @xmath308 is such that @xmath316 . by extension",
    ", we say that the weighting vector @xmath251 has the cm property , if it is generated by some cm weight generator @xmath308 .",
    "the cm property can be ensured if @xmath317 exists , bounded and nonzero .",
    "it is also ensured if the weights @xmath318 are taken ( with repetition ) from a finite set of positive values . more generally , if @xmath319 are @xmath141 random variables , we have @xmath320 almost surely by the slln .",
    "notice finally that @xmath321 since @xmath322 , and @xmath323 .    for a weighting vector @xmath251 having the cm property ,",
    "we define also its _ weighting dynamic _ at moment @xmath11 as the ratio @xmath324 we will see later that @xmath325 directly influences the number of measurements required to guarantee the existence of rip@xmath286 random gaussian matrices",
    ".    given a weight vector @xmath251 , the following lemma ( proved in appendix  [ sec : proof - lemma - strict - bound ] ) characterizes the expectation of the @xmath250-norm of a random gaussian vector .",
    "[ lem : strict - bounds - mu_p ] if @xmath326 and if the weights @xmath251 have the cm property , then , for @xmath327 and @xmath328 , @xmath329 in particular , @xmath330 , with @xmath331 .    with an appropriate modification of ( * ? ? ?",
    "* proposition  1 ) , we can now prove the existence of random gaussian rip@xmath286 matrices ( see appendix [ sec : proof - prop - grip - gauss ] ) .",
    "[ prop : grip - gauss ] let @xmath332 and some cm weights @xmath333 . given @xmath190 and @xmath334 ,",
    "then there exists a constant @xmath335 such that @xmath37 is rip@xmath336 with probability higher than @xmath337 when we have jointly @xmath338 , and @xmath339\\ + \\",
    "\\log\\tfrac{2}{\\eta}\\big).\\end{aligned}\\ ] ] moreover , the value @xmath340 in is given by @xmath341 for a random vector @xmath326 .",
    "the rip normalizing constant @xmath275 can be bounded owing to lemma [ lem : strict - bounds - mu_p ] .",
    "in the light of proposition  [ prop : grip - gauss ] , assumption becomes reasonable since following the simple argument presented in ( * ? ? ?",
    "* appendix  b ) the saturation of requirement implies that @xmath342 decays as @xmath343 for rip@xmath286 gaussian matrices .",
    "therefore , for any value @xmath11 , it is always possible to find a @xmath13 such that holds .",
    "however , this is only possible for high oversampling situation , _",
    "i.e. _ , for @xmath344 measurements .      consider the following general signal sensing model @xmath345 where @xmath346 is the noise vector .",
    "for heteroscedastic ggd noise , each @xmath347 follows a zero - mean @xmath348 distribution with pdf @xmath349 , where @xmath350 is the shape parameter ( the same for all @xmath347 s ) , and @xmath351 the scale parameter @xcite .",
    "it is obvious that @xmath352    if one sets the weights to @xmath353 in gbpdn@xmath256 , it can be seen that the associated constraint corresponds precisely to the negative log - likelihood of the joint pdf of @xmath143 . as detailed below , introducing these non - uniform weights @xmath354 leads to a reduction in the error of the reconstructed signal , relative to using constant weights . without loss of generality",
    ", we here restrict our analysis to strictly @xmath4-sparse @xmath355 , and assume knowledge of bounds ( estimators ) for the @xmath2 and the @xmath250 norms used for characterizing @xmath143 , _ i.e. _ , we know that @xmath356 and @xmath357 for some @xmath358 to be detailed later",
    ".    in this case , if the random matrix @xmath359 is rip@xmath336 for @xmath360 , with @xmath361 for @xmath362 , theorem  [ prop : l2-l1-instance - optimality - gbpdn ] asserts that @xmath363 for @xmath364 and @xmath365 .",
    "conversely , for the weights to @xmath353 , and assuming @xmath37 being rip@xmath366 with @xmath367 , we get @xmath368 for @xmath369 and @xmath370 .",
    "when the number of measurements @xmath13 is large , using classical ggd absolute moments formula , the two bounds @xmath371 and @xmath372 can be set close to @xmath373 and @xmath374 .",
    "moreover , using lemma  [ lem : strict - bounds - mu_p ] , @xmath375 and @xmath376 , where @xmath328 .",
    "[ prop : whitening - heter - ggd - nois ] for an additive heteroscedastic noise @xmath377 such that @xmath378 , setting @xmath379 provides @xmath380 .",
    "therefore , asymptotically in @xmath13 , gbpdn@xmath256 has a smaller reconstruction error compared to gbpdn@xmath300 when estimating @xmath42 from the sensing model .",
    "let us observe that @xmath381 . by the jensen inequality , @xmath382",
    ", so that @xmath383 .",
    "the price to pay for this stabilization is an increase of the weighting dynamic @xmath384 defined in proposition  [ prop : grip - gauss ] , which implies an increase in the number of measurements @xmath13 needed to ensure that the rip@xmath336 is satisfied .",
    "let us consider a simple situation where the @xmath385 s take only two values , _",
    "i.e. _ , @xmath386 for some @xmath387 .",
    "let us assume also that the proportion of @xmath385 s equal to @xmath388 converges to @xmath389 $ ] with @xmath13 as @xmath390 .",
    "in this case , the stabilizing weights are @xmath391 .",
    "an easy computation provides @xmath392 so that , the `` stabilization gain '' with respect to an unstabilized setting can be quantified by the ratio @xmath393 we see that the stabilization provides a clear gain which increases as the measurements get very unevenly corrupted , _",
    "i.e. _ , when @xmath388 is large .",
    "interestingly , the higher @xmath11 is , the less sensitive is this gain to @xmath14 .",
    "we also observe that the overhead in the number of measurements between the stabilized and the unstabilized situations is related to @xmath394    the limit case where @xmath395 can be interpreted as ignoring @xmath14 percent of the measurements in the data fidelity constraint , keeping only those for which the noise is not dominating . in that case , the sufficient condition in proposition  [ prop : grip - gauss ] for @xmath37 to be rip@xmath286 tends to @xmath396 which is consistent with the fact that on average only fraction @xmath397 of the @xmath13 measurements significantly participate to the cs scheme , _",
    "i.e. _ , @xmath398 must satisfy the common rip requirement . for @xmath159 , this",
    "is somehow related to the democratic property of rip matrices @xcite , _",
    "i.e. _ , the fact that a reasonable number of rows can be discarded from a matrix while preserving the rip .",
    "this property was successfully used for discarding saturated cs measurements in the case of a limited dynamic quantizer @xcite .",
    "let us now instantiate the use of gbpdn to the reconstruction of signals in the qcs scenario defined in section[sec : non - uniform - scalar ] . under the quantization formalism defined in lemma  [ lemma : bound - lpw - gaussian - vector ] and for gaussian matrices",
    "@xmath37 , the factor @xmath399 in can be shown to decrease as @xmath400 asymptotically in @xmath13 and @xmath9 .",
    "this asymptotic and _ almost sure _ result which relies on the slln ( see appendix [ proof : towards - quant - cons ] ) suggests increasing @xmath11 to the highest value allowed by in order to decrease the gbpdn reconstruction error .",
    "[ prop : towards - quant - cons ] given @xmath71 and @xmath48 , assume that the entries of @xmath80 are @xmath141 realizations from @xmath401 .",
    "we take the corresponding optimal compressor function @xmath123 defined in and the @xmath11-optimal @xmath9-bits scalar quantizer @xmath166 as defined in .",
    "then , the ratio @xmath402 given in is asymptotically and almost surely bounded by @xmath403 with @xmath404",
    ".    notice that , under hra and for large @xmath13 , it is possible to provide a rough estimation of the weighting dynamic @xmath325 when the weights are those provided by the d@xmath219c constraints .",
    "indeed , since @xmath405)^{(p-2)/p}$ ] and @xmath406 , we find @xmath407)^{p-2}\\ \\simeq_m\\ m\\,\\sum_k { \\mathcal}g'^{p-2}(\\omega_{k , p})\\,p_k\\\\ & \\simeq_{b , m}\\ , m\\ , ( 2\\pi 3\\sigma_0 ^ 2)^{(2-p)/2}(2\\pi \\sigma_0 ^ 2)^{-1/2 } \\sum_k { \\uptau}_k\\,\\exp(-{{\\textstyle\\frac{1}{2}}}\\omega_{k , p}^2\\tfrac{p+1}{3\\sigma^2_0})\\\\ & \\simeq_{b , m}\\ , m\\ , ( 2\\pi 3\\sigma_0 ^ 2)^{(2-p)/2}(2\\pi \\sigma_0 ^ 2)^{-1/2 } ( 2\\pi \\tfrac{3\\sigma_0 ^ 2}{p+1})^{1/2}\\\\ & = \\ m\\,(2\\pi\\sigma_0 ^ 2)^{(2-p)/2 } 3^{(3-p)/2 } ( p+1)^{-1/2},\\end{aligned}\\ ] ] where we recall that @xmath408 , for any @xmath409 ( see the proof of lemma  [ lemma : bounding - a - tail - after - t ] ) .",
    "moreover , using and since one of the two smallest quantization bins is @xmath410 , @xmath411 therefore , estimating @xmath412 with @xmath413 , we find @xmath414    therefore ,",
    "at a given @xmath3 , since ( [ eq : sgr - rip - measur - bound ] ) involves that @xmath13 evolves like @xmath415 , using the weighting induced by gbpdn(@xmath250 ) requires collecting @xmath416 times more measurements than gbpdn(@xmath417 ) in order to ensure the appropriate rip@xmath418 property .",
    "this represents part of the price to pay for guaranteeing bounded reconstruction error by adapting to non - uniform quantization .",
    "* dequantizing is stabilizing quantization distortion : *    in connection with the procedure developed in section  [ sec : case - heter - nois ] , the weights and the @xmath11-optimal levels introduced in lemma  [ lemma : bound - lpw - gaussian - vector ] can be interpreted as a `` stabilization '' of the quantization distortion seen as a heteroscedastic noise .",
    "this means that , asymptotically in @xmath13 , selecting these weights and levels , _ all quantization regions @xmath172 contribute equally to the @xmath419 distortion measure_.    to understand this fact , we start by studying the following relation shown in the proof of lemma  [ lemma : bound - lpw - gaussian - vector ] ( see appendix  [ proof - lemma - bound - lpw - gaussian - vector ] ) : @xmath420 - { \\boldsymbol}z\\|^p_{p,{\\boldsymbol}w}\\ & \\mathop{\\simeq}_{m}\\ m\\ , \\sum_{k}\\ [ { \\mathcal}g'(\\omega_{k , p})]^{p-2 } \\int_{{\\mathcal}r_k}|t - \\omega_{k , p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t.\\end{aligned}\\ ] ] using the threshold @xmath421 and @xmath422 $ ] as defined in lemma [ lemma : useful - ineq ] , the proof of lemma  [ lemma : bounding - a - tail - after - t ] in appendix  [ proof - lemma - bound - lpw - gaussian - vector ] shows that @xmath420 - { \\boldsymbol}z\\|^p_{p,{\\boldsymbol}w}\\ & \\mathop{\\simeq}_{m , b}\\ m\\ , \\sum_{k : { \\mathcal}r_k \\subset { \\mathcal}t}\\ [ { \\mathcal}g'(\\omega_{k , p})]^{p-2 } \\int_{{\\mathcal}r_k}|t - \\omega_{k , p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t,\\\\ & \\mathop{\\simeq}_{b}\\ m\\ , \\sum_{k : { \\mathcal}r_k \\subset { \\mathcal}t}\\ [ { \\mathcal}g'(\\omega_{k , p})]^{p-2 } \\tfrac{{\\uptau}_k^{p+1}}{(p+1)\\,2^p }   \\,{\\varphi}_0(\\omega_{k , p}),\\end{aligned}\\ ] ] using . however , using and the relation @xmath423 , we find @xmath424 .",
    "therefore , each term of the sum in   provides a contribution @xmath425^{p-2 } \\tfrac{{\\uptau}_k^{p+1}}{(p+1)\\,2^p }   \\,{\\varphi}_0(\\omega_{k , p})\\ \\mathop{\\simeq}_{b , m}\\ { |\\!|\\!|{\\varphi}_0|\\!|\\!|}_{1/3}\\,\\tfrac{{\\upalpha}^{p+1}}{(p+1)2^p},\\ ] ] which is independent of @xmath426 !",
    "this phenomenon is well known for @xmath159 and may actually serve for defining @xmath128 itself @xcite .",
    "the fact that this effect is preserved for @xmath3 is a surprise for us .",
    "we first describe how to numerically solve the gbpdn optimization problem using a primal - dual convex optimization scheme , then illustrate the use of gbpdn for stabilizing heteroscedastic gaussian noise on the cs measurements .",
    "finally , we apply gbpdn for reconstructing signals in the quantized cs scenario described in section  [ sec : non - uniform - scalar ] .",
    "the optimization problem gbpdn@xmath256 is a special instance of the general form @xmath427 where @xmath428 and @xmath429 are closed convex functions that are not infinite everywhere ( _",
    "i.e. _ , proper functions ) , and @xmath430 is a bounded linear operator , with @xmath431 , and @xmath432 where @xmath433 is the indicator function of the @xmath2-ball @xmath434 centered at zero and of radius @xmath371 , _ i.e. _ , @xmath435 if @xmath436 and @xmath437 otherwise . for the case of gbpdn@xmath256 ,",
    "both @xmath428 and @xmath429 are non - smooth but the associated proximity operators ( to be defined shortly ) can be computed easily .",
    "this will allow to minimize the gbpdn@xmath256 objective by calling on proximal splitting algorithms .    before delving into the details of the minimization splitting algorithm",
    ", we recall some results from convex analysis . the _ proximity operator _",
    "@xcite of a proper closed convex @xmath428 is defined as the unique solution @xmath438 if @xmath439 for some closed convex set @xmath440 , @xmath441 is equivalent to the orthogonal projector onto @xmath440 , @xmath442 .",
    "@xmath443 is the _ legendre - fenchel conjugate _ of @xmath428 . for @xmath444 ,",
    "the proximity operator of @xmath445 can be deduced from that of @xmath446 through moreau s identity @xmath447    solving with an arbitrary bounded linear operator @xmath448 can be achieved using primal - dual methods motivated by the classical kuhn - tucker theory .",
    "starting from methods to solve saddle function problems such as the arrow - hurwicz method @xcite , this problem has received a lot of attention recently , _",
    "e.g. _ , @xcite . in this paper",
    ", we use the relaxed arrow - hurwicz algorithm as revitalized recently in @xcite . adapted to our problem",
    ", its steps are summarized in algorithm  [ algo : gbpdn ] .",
    "* inputs : * measurements @xmath98 , sensing matrix @xmath37 , weights @xmath251 . + * parameters : * iteration number @xmath449 , @xmath450 $ ] , step - sizes @xmath451 and @xmath452 with @xmath453 . + * main iteration : * + * output : * signal @xmath454 .",
    "a sufficient condition for the sequences of algorithm  [ algo : gbpdn ] to converge is to choose @xmath455 and @xmath456 such that @xmath453 .",
    "it has been shown in ( * ? ? ?",
    "* theorem 1 ) that under this condition and for @xmath457 , the primal sequence @xmath458 converges to a ( possibly strict ) global minimizer of gbpdn@xmath256 , with the rate @xmath459 in ergodic sense on the partial duality gap .    [ [ proximity - operator - of - f ] ] proximity operator of @xmath428 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    for @xmath460 , @xmath461 is the popular component - wise soft - thresholding of @xmath19 with threshold @xmath456 .    [ [ proximity - operator - of - g ] ] proximity operator of @xmath429 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    recall that @xmath462 . using moreau s identity above , and proximal calculus rules for translation and scaling ,",
    "we have @xmath463 it remains to compute the orthogonal projection @xmath464 to get @xmath465 . for @xmath159 and @xmath466",
    ", this projector has an easy closed form . for @xmath467",
    ", we used the newton method we proposed in @xcite for solving the related karush - kuhn - tucker system which is reminiscent of the strategy underlying sequential quadratic programming .",
    "we explore numerically the impact of using non - uniform weights ( _ e.g. _ , stabilizing the measurement noise ) for signal reconstruction when the cs measurements are corrupted by heteroscedastic gaussian noise , as discussed in section  [ sec : case - heter - nois ] .",
    "this illustrates for @xmath159 both the gain induced by stabilizing the sensing noise and the increase of measurements necessary for observing this gain .    in this illustration , we set the problem dimensions to @xmath468 , @xmath469 , and let the oversampling factor be in @xmath470 .",
    "the @xmath4-sparse unit norm signals were generated independently according to a bernoulli - gaussian mixture model with @xmath4-length support picked uniformly at random in @xmath35 $ ] , and the non - zero signal entries drawn from @xmath471 with @xmath472 .",
    "noisy measurements were simulated by setting @xmath473 , with @xmath474 and @xmath332 .",
    "the heteroscedastic behavior of @xmath143 has been designed so that @xmath475)$ ] with @xmath476 and @xmath477 .",
    "two reconstruction methods were tested : one _ with _ and the other _ without _ stabilizing the noise variance . in the first case",
    ", the weights have been set to @xmath478 , while in the second @xmath204 .",
    "since the purpose of this analysis is not focused on the design of efficient noise power estimators , @xmath371 and @xmath372 have been simply set by an oracle to @xmath479 and @xmath480 .",
    "given the parameters above , we compute the weighting dynamic @xmath481 , and the average stabilization gain should be ( see proposition  [ prop : whitening - heter - ggd - nois ] ) @xmath482    numerically , gbpdn@xmath483 and gbpdn@xmath484bpdn have been solved with the method described in section  [ sec : whitening - example ] until the relative @xmath0-change in the iterates was smaller than @xmath485 ( with a maximum of 2000 iterations ) .",
    "reconstruction results were averaged over 50 experiments . in fig .",
    "[ fig : rec - gbpdn - whiten - snr ] , the reconstruction signal - to - noise ratio ( snr ) of the stabilized reconstruction is clearly superior to the unstabilized one and this gain increases with increasing oversampling ratio @xmath99 .",
    "this snr gain is displayed in fig .",
    "[ fig : rec - gbpdn - whiten - snrgain ] .",
    "the dashed horizontal line represents the theoretical prediction of @xmath486 db which turns to be an upper - bound on the numerically observed gain .",
    "we describe several simulations challenging the power of gbpdn for reconstructing sparse signals from non - uniformly quantized measurements when the weights and the @xmath11-optimal levels of lemma  [ lemma : bound - lpw - gaussian - vector ] are combined .",
    "several configurations have been tested for different @xmath3 , oversampling ratio @xmath99 , number of bits @xmath9 and for non - uniform and uniform quantization .    for this experiment",
    ", we set the key dimensions to @xmath487 , and the @xmath4-sparse unit norm signals have been generated as in the previous section .",
    "the oversampling ratio was taken as @xmath488 , @xmath489 and the matrix @xmath37 has been drawn randomly as @xmath48 .",
    "the non - uniform quantization of the measurements @xmath490 was defined with a compressor @xmath123 associated to @xmath491 according to .",
    "the weights @xmath251 were computed as in lemma  [ lemma : bound - lpw - gaussian - vector ] , and the @xmath11-optimal levels using the numerical method described in appendix  [ sec : comp - omeg - p ] .    for the sake of completeness",
    ", we also compared some results to those obtained for a uniformly quantized cs scenario . in this case , the measurements @xmath88 are quantized as @xmath492 , the quantization bin width @xmath493 has been set by dividing regularly the interval @xmath494 $ ] into the same number of bins as those used for the non - uniform quantization .",
    "again , gbpdn was solved with the primal - dual scheme described in section  [ sec : whitening - example ] until either the relative @xmath0-change in iterates was smaller than @xmath485 or a maximum number of iterations of 2000 was reached .",
    "finally , all the reconstruction results were averaged over 50 replications of sparse signals for each combination of parameters .",
    "[ fig : rec - gbpdn - nu - quant - snr ] displays the evolution of the signal reconstruction quality , as measured by the snr , as a function of the oversampling factor @xmath99 .",
    "we clearly see a reconstruction quality improvement with respect to both the uniformly quantized cs scheme ( dashed curve ) and to increasing values of @xmath11 and @xmath99 .",
    "this last effect is better analyzed in fig .",
    "[ fig : rec - gbpdn - nu - quant - snrgain ] where the snr gain with respect to @xmath159 for various values of @xmath11 is shown . as predicted by proposition  [ prop : towards - quant - cons ] , we clearly see that , as soon as the ratio @xmath99 is large , taking higher @xmath11 value leads to a higher reconstruction quality than the one obtained for @xmath159 ( bpdn )",
    ". moreover , fig .",
    "[ fig : rec - gbpdn - nu - quant - snrgain ] confirms that when @xmath11 increases , the minimal measurement number inducing a positive snr gain increases .",
    "for instance , to achieve a positive gain at @xmath495 , we must have @xmath496 , while at @xmath497 , @xmath99 must be higher than 20 . at @xmath11",
    "fixed , the reconstruction quality increased also monotonically with  @xmath99 .",
    "we observe that , given the oversampling ratio , these experimental results allow to increase @xmath11 to a greater extent than would be allowed by our theory deployed in section  [ sec : dequ - with - gener ] . in particular , the sufficient condition dictated by proposition  [ prop : grip - gauss ] requires the number of measurements @xmath13 to scale as @xmath498 ( ignoring times the usual logarithmic terms ) in order to ensure the rip@xmath286 .",
    "this would imply an exponential increase in the number of measurements needed as @xmath11 increases .",
    "however , from fig .  [",
    "fig : rec - gbpdn - nu - quant - snrgain ] , one can see that for @xmath499 , @xmath495 was the largest value before performance starts degrading . with @xmath500 , @xmath11 could be increased to 6 before degradation , and to 8 before degradation with @xmath501 .",
    "at least for this example , we do not observe such a severe exponential dependence in the needed oversampling in order to benefit from error decrease when increasing @xmath11 .    in fig .",
    "[ fig : gbpdn - qc ] , the quantization consistency of the reconstructed signals is tested by looking at the histogram of @xmath502 .",
    "we do observe that this histogram is closer to a uniform distribution for @xmath497 than for @xmath159 , in good agreement with the `` companded '' quantizer definition @xmath503 showing that in the domain compressed by @xmath123 , this quantizer is similar to a uniform one .    as a last test ,",
    "we have more thoroughly compared a uniform quantization scenario described in the experimental setup above with the bpdq@xmath219 decoder developed in  @xcite to the non - uniform case studied in this paper .",
    "more precisely , fig .",
    "[ fig : rec - gbpdn - nu - quant - exp - vs - th ] shows the reconstruction snr gain between non - uniform and uniform quantization at various @xmath11 , _",
    "i.e. _ , snr@xmath504gbpdn@xmath505 @xmath506 snr@xmath504bpdq@xmath507 .",
    "we see that , at a given @xmath11 , this gain improves with @xmath99 , and the highest snr improvement values are obtained for @xmath159 .",
    "this points the fact that for @xmath508 , the quantization scheme is not optimized for reducing the @xmath250-norm distortion .",
    "this would require us to change the quantization scenario by not only optimizing the @xmath11-optimal levels but also the thresholds .",
    "this will be be left to a future research .",
    "in this paper , we have shown that , when the compressive measurements of a sparse or compressible signal are non - uniformly quantized , there is a clear interest in modifying the reconstruction procedure by adapting the way it imposes the reconstructed signal to `` match '' the observed data . in particular , we have proved that in an oversampled scenario , replacing the common bpdn @xmath0-norm constraint by a weighted @xmath2-norm adjusted to the non - uniform nature of the quantizer reduces the reconstruction error by a factor of @xmath10 .",
    "moreover , we showed that this improvement stems from a stabilization of the quantization distortion seen as an additive heteroscedastic ggd noise on the measurements .    in future work",
    ", we will investigate if the quantization scheme can also be optimized with respect to the proposed reconstruction procedure , _",
    "i.e. _ , by adjusting the thresholds for minimizing the weighted @xmath2-distortion at a fixed bit budget .",
    "this appendix contains several key lemmata that are useful for the subsequent proofs developed in the other appendices .",
    "the first lemma will serve later to evaluate asymptotically the contribution of each quantization bin to the global quantizer distortion measured with @xmath250-norm when a gaussian source ( with pdf @xmath175 ) is quantized .",
    "[ lemma : optimal - p - moment - bound ] given @xmath509 with @xmath510 , @xmath511 and a gaussian pdf @xmath153 .",
    "let @xmath512 be the ( unique ) minimizer of @xmath513}\\ \\int_a^b |t-\\lambda|^n\\ { \\varphi}_0(t)\\,{\\mathrm{d}}t$ ] .",
    "then , @xmath514 @xmath515 with @xmath516}{\\varphi}_0(t)$ ] , @xmath517}{\\varphi}_0(t)$ ] and @xmath518 .",
    "let us first show the upper bound . in lemma  [ lemma : p - optimal - levels ] and its proof , it was show that @xmath512 exists and is unique , _",
    "i.e. _ , the minimization problem is well - posed .",
    "furthermore , @xmath512 satisfies @xmath519 since @xmath520 $ ] for @xmath521 $ ] , we have @xmath522 and @xmath523 .",
    "this implies @xmath524 and @xmath525 , from which we easily deduce  .    since @xmath526 , we find @xmath527\\,{\\mathsf}d$ ] . from @xmath528",
    "$ ] , we find that @xmath529\\ , { \\mathsf}d.\\ ] ] this provides since @xmath530 . the bound is obtained similarly .",
    "the following lemma presents a generalization of `` @xmath531-function like '' bounds for lower partial moments of a gaussian pdf .",
    "[ lemma : bounding - lpm ] let @xmath444 , @xmath532 and @xmath533 .",
    "let us define @xmath534 .",
    "then , @xmath535 . more precisely , @xmath536    this lemma generalizes the well known bound on @xmath537 , namely @xmath538 .",
    "the proof involves integration by parts , the identities @xmath539 and @xmath540 .",
    "therefore , the upper bound is a simple consequence of @xmath541    to get the lower bound , observe first that , defining @xmath542 , we find @xmath543 therefore , @xmath544 .",
    "but @xmath545 , so that @xmath546 , which concludes the proof .",
    "for @xmath307 , @xmath547 is a continuous , coercive and strictly convex function of @xmath548 over @xmath173 , and therefore so is @xmath549 since @xmath550 .",
    "it follows that the function @xmath551 has a unique minimizer on @xmath173 .",
    "moreover , this minimizer is necessarily located in @xmath172 since @xmath549 is monotonically decreasing ( resp .",
    "increasing ) on @xmath552 ( resp .",
    "@xmath553 ) . consequently",
    ", @xmath554 exists and is unique",
    ".    for proving the limit case @xmath205 , for finite bins @xmath172 ( @xmath555 ) and without loss of generality for @xmath556 , relation in lemma  [ lemma : optimal - p - moment - bound ] with @xmath557 and @xmath558 , together with the squeeze theorem shows that @xmath559 where @xmath560 .    for infinite bins ( _ i.e. _ , @xmath165 ) and assuming again @xmath556",
    ", it follows from the beginning of the proof that @xmath161 is the unique root on @xmath561 of @xmath562 .",
    "let @xmath563 $ ] be the root of @xmath564 for some @xmath565 .",
    "we then have @xmath566 , which implies @xmath567 since @xmath568 is non - decreasing for @xmath190 .",
    "however , since @xmath569 is optimal on @xmath570 $ ] , taking @xmath571 , for @xmath335 , we have by lemma  [ lemma : optimal - p - moment - bound ] with @xmath557 and @xmath572 , @xmath573 since @xmath574 .",
    "this proves @xmath575 and @xmath164 for @xmath165 .",
    "the content of lemma [ lemma : useful - ineq ] is derived from this larger set of results which constitutes a _ toolbox _",
    "lemma for other developments given in these appendices .",
    "[ lemma : useful - ineq - ext ] given the gaussian pdf @xmath175 and its associated compressor @xmath123 function , choose @xmath176 and @xmath177 , and define @xmath576 , @xmath577 $ ] and @xmath578 .",
    "we have the following asymptotic properties ( relative to @xmath9 ) : @xmath579 moreover , for all @xmath426 such that @xmath181 and any @xmath182 @xmath580 finally , if @xmath426 is such that @xmath581 , then , writing the interval length / measure @xmath582 for @xmath583 , @xmath584    in this proof we use the quantizer symmetry to restrict the analysis to the half ( positive ) real line @xmath585 , on which @xmath175 is decreasing .",
    "relation comes from the definition of @xmath586 and that of @xmath587 . for proving",
    ", we can observe that @xmath588 where @xmath589 .",
    "since @xmath590 , we obtain @xmath591 taking @xmath592 in the last inequalities and using , we deduce from the quantizer definition @xmath593 relation is proved by noting that , if @xmath594 , @xmath595 where the first inequality follows from the @xmath11-optimality of @xmath596 . however , from lemma  [ lemma : bounding - lpm ] , we know that , for @xmath597 @xmath598 with @xmath599 and @xmath600 .",
    "therefore , since @xmath601 , @xmath602    relation is obtained by observing that @xmath123 is concave on @xmath585 .",
    "this implies @xmath603 and if @xmath426 is such that @xmath604 , @xmath605 . for",
    ", keeping the same @xmath426 , we note that @xmath606 which is then arbitrarily close to  1 .    for proving , we assume first @xmath190 . let us consider and with @xmath557 , @xmath558 , @xmath607 and @xmath608 with @xmath609 . from we",
    "see that @xmath610 .",
    "we show easily that this involves the equivalent relations @xmath611 , @xmath612 and @xmath613",
    ". therefore , @xmath614 and @xmath615 .",
    "moreover , @xmath616 and @xmath617 for any @xmath618 , so that and ) show finally @xmath619 and @xmath619 , which proves the relation . the case @xmath620 is demonstrated similarly by observing that @xmath621 .",
    "let s now turn to showing . from and since @xmath622 , @xmath623 so that @xmath624 .",
    "by concavity of @xmath123 on @xmath585 , we know that @xmath625 . therefore , @xmath626 which yields @xmath627",
    ". by the concavity argument again , we have @xmath628 for any @xmath629 , and thus @xmath630 .",
    "this implies @xmath631 .",
    "if @xmath426 is such that @xmath632 , using again the concavity of @xmath123 on @xmath585 , we find @xmath633 , which proves .    for showing , we note that @xmath634 . since @xmath635 which is arbitrarily close to 1 ( _ i.e. _ , it is @xmath636 ) , we find @xmath637 , _",
    "i.e. _ , it inherits the behavior of @xmath638 .",
    "the last relation is proved similarly to by appealing again to lemma  [ lemma : bounding - lpm ] , @xmath639 where the asymptotic relation is obtained by seeing that , as soon as @xmath640 ( which is always possible to meet thanks to ) , @xmath641 and @xmath642 since @xmath601 .",
    "before proving lemma [ lemma : bound - lpw - gaussian - vector ] , let us show the following asymptotic equivalence .",
    "[ lemma : bounding - a - tail - after - t ] let @xmath643 and @xmath644 .",
    "@xmath645^{\\gamma } \\int_{{\\mathcal}r_k}|t -    \\omega_{k ,",
    "p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t\\ \\simeq_b\\    \\tfrac{2^{-pb}}{(p+1)\\,2^p}\\,\\int_{{\\mathbb{r } } } [ { \\mathcal}g'(t)]^{\\gamma - p } { \\varphi}_0(t)\\,{\\mathrm{d}}t,\\ ] ]    let us use the threshold @xmath586 defined in lemma [ lemma : useful - ineq - ext ] for splitting the sum in two parts , _",
    "i.e. _ , using the quantizer symmetry , @xmath646^{\\gamma } \\int_{{\\mathcal}r_k}|t -    \\omega_{k , p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t = \\ 2\\!\\!\\!\\!\\!\\!\\sum_{k:\\ 0 { \\leqslant}t_{k+1 } < t(b ) } \\ [ { \\mathcal}g'(\\omega_{k , p})]^{\\gamma } \\int_{{\\mathcal}r_k}|t - \\omega_{k , p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t\\quad + \\quad { \\mathsf}r,\\ ] ] where the residual @xmath647 reads @xmath648^{\\gamma } \\int_{{\\mathcal}r_k}|t - \\omega_{k , p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t,\\\\ & \\,=\\ 2\\,[{\\mathcal}g'(\\omega_{k',p})]^{\\gamma } \\int_{{\\mathcal}r_{k'}}|t - \\omega_{k',p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t\\ + \\ 2\\!\\!\\!\\!\\sum_{k:\\ t_{k } { \\geqslant}\\ , t(b)}\\ [ { \\mathcal}g'(\\omega_{k , p})]^{\\gamma } \\int_{{\\mathcal}r_k}|t - \\omega_{k , p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t,\\end{aligned}\\ ] ] where @xmath649 is such that @xmath650 .    from lemma [ lemma : useful - ineq - ext ]",
    ", we can easily bound this residual .",
    "we know from , , and that , for all @xmath651 , @xmath652^{\\gamma } \\int_{{\\mathcal}r_k}|t - \\omega_{k , p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t = o(2^{-\\beta(\\gamma+3)b } b^{-(p+1)/2}).\\ ] ] however , tells us that the sum in @xmath647 is made of no more than @xmath653 terms , so that @xmath654    let us now study the terms for which @xmath604 . using and provides @xmath655^{\\gamma } \\int_{{\\mathcal}r_k}|t -    \\omega_{k , p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t\\\\ & \\mathop{\\simeq}_{b}\\ 2\\ , \\sum_{k:\\,0{\\leqslant}t_{k+1}{\\leqslant}t(b)}\\ [ { \\mathcal}g'(\\omega_{k , p})]^{\\gamma } \\tfrac{{\\uptau}_k^{p+1}}{(p+1)\\,2^p }   \\,{\\varphi}_0(\\omega_{k , p})\\ + \\ { \\mathsf}r\\\\ & \\mathop{\\simeq}_{b}\\ 2 \\tfrac{{\\upalpha}^{p}}{(p+1)\\,2^p}\\,\\sum_{k:\\,0{\\leqslant}t_{k+1}{\\leqslant}t(b)}\\ [ { \\mathcal}g'(\\omega_{k , p})]^{\\gamma - p }    \\,{\\varphi}_0(\\omega_{k , p})\\,{\\uptau}_k\\ + \\ { \\mathsf}r\\\\ & \\mathop{\\simeq}_{b}\\   2\\tfrac{2^{-pb}}{(p+1)\\,2^p}\\,\\int_{0}^{t(b ) } [ { \\mathcal}g'(t)]^{\\gamma - p } { \\varphi}_0(t)\\,{\\mathrm{d}}t\\ + \\ { \\mathsf}r,\\end{aligned}\\ ] ] where ,",
    "knowing that @xmath656 , we have also used with @xmath620 to see that @xmath657 for any @xmath658 .",
    "therefore , provided that @xmath659 , which means that @xmath644 since @xmath660 , the residual @xmath647 decreases faster than the first term in the right - hand side of last of the last equivalence relation , so that @xmath646^{\\gamma } \\int_{{\\mathcal}r_k}|t -    \\omega_{k , p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t\\ \\mathop{\\simeq}_{b}\\   \\tfrac{2^{-pb}}{(p+1)\\,2^p}\\,\\int_{{\\mathbb{r } } } [ { \\mathcal}g'(t)]^{\\gamma - p } { \\varphi}_0(t)\\,{\\mathrm{d}}t,\\ ] ] since @xmath661 by definition .    with the three previous lemmata under our belts",
    ", we are now ready to prove lemma  [ lemma : bound - lpw - gaussian - vector ] .    for @xmath662 with pdf @xmath175 , using the slln applied to @xmath81 conditionally on each quantization bin",
    ", we have @xmath663 - { \\boldsymbol}z\\|^p_{p,{\\boldsymbol}w}&{:=}\\ \\sum_{i=1}^m\\ [ { \\mathcal}g'({\\mathcal}q_p[z_i])]^{p-2}\\,|z_i - { \\mathcal}q_p[z_i]|^p,\\\\ & \\mathop{\\simeq}_{m}\\ m\\ , \\sum_{k=1}^{{\\mathcal}b}\\ [ { \\mathcal}g'(\\omega_{k , p})]^{p-2 } \\int_{{\\mathcal}r_k}|t - \\omega_{k , p}|^p\\,{\\varphi}_0(t)\\,{\\mathrm{d}}t,\\end{aligned}\\ ] ] where we used implicitly the quantizer symmetry in the last relation . this last relation is characterized by lemma  [ lemma : bounding - a - tail - after - t ] by taking @xmath664 and @xmath665 , so that @xmath663 - { \\boldsymbol}z\\|^p_{p,{\\boldsymbol}w } & \\mathop{\\simeq}_{m , b}\\ m\\,\\tfrac{2^{-pb}}{(p+1)\\,2^p}\\,\\int_{{\\mathbb{r } } } [ { \\mathcal}g'(t)]^{-2 } { \\varphi}_0(t)\\,{\\mathrm{d}}t,\\\\ & \\mathop{\\simeq}_{m , b}\\ m\\ , \\tfrac{2^{-pb}}{(p+1)2^p}\\,{|\\!|\\!|{\\varphi}_0|\\!|\\!|}_{1/3}.\\end{aligned}\\ ] ]",
    "first , the inequality @xmath667 follows from the jensen inequality applied on the convex function @xmath668 on @xmath585 .",
    "second , from our result in ( * ? ? ?",
    "* appendix c ) it is easy to show that @xmath669 moreover , @xmath670 , while @xmath671 therefore , assuming cm weights , @xmath672 since @xmath673 , and @xmath674 @xcite .",
    "the proof proceeds simply by considering the lipschitz function @xmath676 and the expected value @xmath677 for a random vector @xmath326 in ( * ? ? ?",
    "* appendix a ) .",
    "the lipschitz constant of @xmath678 is @xmath679 with @xmath680 for @xmath190 .",
    "the value @xmath341 can be estimated thanks to lemma [ lem : strict - bounds - mu_p ] .",
    "indeed , it tells us that if @xmath681 , @xmath682 with @xmath683 .    inserting these results in ( * ? ? ?",
    "* appendix a ) , it is easy to show that a matrix @xmath332 is rip@xmath336 with a probability higher than @xmath337 if @xmath684\\ + \\ \\log\\tfrac{2}{\\eta}\\big),\\ ] ] for some constant @xmath335 .",
    "we have to bound @xmath685 , with @xmath362 , when @xmath13 is large and under the hra .",
    "first , according to lemma  [ lem : strict - bounds - mu_p ] , using the slln and using the same decomposition than in the proof of lemma  [ lemma : bound - lpw - gaussian - vector ] with the threshold @xmath586 ( with @xmath686 ) and the bounds provided by lemma  [ lemma : useful - ineq - ext ] , we find almost surely @xmath687)]^{p-2 } { { \\mathbb{e}}}|{\\mathcal}z|^p\\\\ & \\mathop{\\simeq}_{m}\\ m\\,{{\\mathbb{e}}}|{\\mathcal}z|^p\\,\\sum_{k:\\,t_k{\\geqslant}0 }    p_k\\,[{\\mathcal}g'(\\omega_{k , p})]^{p-2}.\\end{aligned}\\ ] ] the sum in the last expression is characterized by lemma  [ lemma : bounding - a - tail - after - t ] by setting inside @xmath688 and @xmath689 .",
    "this provides @xmath690^{p-2}{\\varphi}_0(t)\\,{\\mathrm{d}}t\\\\ & \\mathop{\\simeq}_{m , b}\\ m\\ , { { \\mathbb{e}}}|{\\mathcal}z|^p\\,\\big[\\int_{{\\mathbb{r } } } { \\varphi}_0^{1/3}(t)\\big]^{2-p}\\,\\big[\\int_{{\\mathbb{r } } } { \\varphi}_0^{(p+1)/3}(t)\\,{\\mathrm{d}}t\\big ] .",
    "\\end{aligned}\\ ] ]    therefore , using the value @xmath207 defined in lemma  [ lemma : bound - lpw - gaussian - vector ] , @xmath691 however , for @xmath692 , @xmath693 consequently , @xmath694 and @xmath695 , so that @xmath696 knowing that @xmath697 with @xmath698 @xcite , we get @xmath403 with @xmath404 .",
    "this section describes a numerical procedure for efficiently computing the @xmath11-optimal levels @xmath161 of a gaussian source @xmath699 for integer @xmath3 , defined by @xmath700 , where @xmath701 as @xmath702 is strictly convex and differentiable , the desired @xmath161 are the unique stationary points satisfying @xmath703 .",
    "we compute the @xmath161 by newton method , using standard numerical quadrature for @xmath704 and @xmath705 .",
    "we handle the semi - infinite bins by replacing @xmath706 and @xmath707 by -39 and + 39 , respectively ( chosen as the smallest integer @xmath708 so that @xmath709 when evaluated in double precision floating point arithmetic ) .",
    "given quadrature weights @xmath710 , we approximate @xmath711 by @xmath712 .",
    "we then have @xmath713 and @xmath714 .",
    "we initialize with the midpoint for each of the finite bins , _",
    "i.e. _ , set @xmath715 for @xmath716 , and @xmath717 , @xmath718 for the semi - infinite bins . for each @xmath426",
    "we then iterate the newton step @xmath719 until the convergence criterion @xmath720 is met .",
    "we used @xmath710 given by the fourth - order accurate simpson s rule , _",
    "e.g. _ , @xmath721 , which yielded empirically observed @xmath722 convergence of the calculated @xmath723 .",
    "results in this paper employed @xmath724 quadrature points , sufficient to yield @xmath723 accurate to machine precision .",
    "r.  berinde , a.  c. gilbert , p.  indyk , h.  karloff , and m.  j. strauss , `` combining geometry and combinatorics : a unified approach to sparse signal recovery , '' in _ allerton conf .",
    "comm . , control & comp._. ieee , 2008 , pp ."
  ],
  "abstract_text": [
    "<S> this paper addresses the problem of stably recovering sparse or compressible signals from compressed sensing measurements that have undergone optimal non - uniform scalar quantization , _ </S>",
    "<S> i.e. _ , minimizing the common @xmath0-norm distortion . generally , this quantized compressed sensing ( qcs ) problem is solved by minimizing the @xmath1-norm constrained by the @xmath0-norm distortion . in such cases , re - measurement and quantization of the reconstructed signal do not necessarily match the initial observations , showing that the whole qcs model is not _ </S>",
    "<S> consistent_. our approach considers instead that quantization distortion more closely resembles heteroscedastic uniform noise , with variance depending on the observed quantization bin . </S>",
    "<S> generalizing our previous work on uniform quantization , we show that for non - uniform quantizers described by the `` compander '' formalism , quantization distortion may be better characterized as having bounded weighted @xmath2-norm ( @xmath3 ) , for a particular weighting . </S>",
    "<S> we develop a new reconstruction approach , termed generalized basis pursuit denoise ( gbpdn ) , which minimizes the @xmath1-norm of the signal to reconstruct constrained by this weighted @xmath2-norm fidelity . </S>",
    "<S> we prove that , for standard gaussian sensing matrices and @xmath4 sparse or compressible signals in @xmath5 with at least @xmath6 measurements , _ </S>",
    "<S> i.e. _ , under strongly oversampled qcs scenario , gbpdn is @xmath7 instance optimal and stable recovers all such sparse or compressible signals . </S>",
    "<S> the reconstruction error decreases as @xmath8 given a budget of @xmath9 bits per measurement . </S>",
    "<S> this yields a reduction by a factor @xmath10 of the reconstruction error compared to the one produced by @xmath0-norm constrained decoders . </S>",
    "<S> we also propose an primal - dual proximal splitting scheme to solve the gbpdn program which is efficient for large - scale problems . </S>",
    "<S> interestingly , extensive simulations testing the gbpdn effectiveness confirm the trend predicted by the theory , that the reconstruction error can indeed be reduced by increasing @xmath11 , but this is achieved at a much less stringent oversampling regime than the one expected by the theoretical bounds . besides the qcs scenario , we also show that gbpdn applies straightforwardly to the related case of cs measurements corrupted by heteroscedastic generalized gaussian noise with provable reconstruction error reduction . </S>"
  ]
}