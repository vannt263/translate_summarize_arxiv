{
  "article_text": [
    "numerically computing the shannon information rate for source / channel models with memory can be difficult . in many cases of practical interest ,",
    "analytical results are not available or hard to evaluate numerically . for a large class of channels , however , monte carlo methods as proposed in @xcite have been shown to yield reliable numerical results .    in this paper",
    ", we consider the extension of such monte carlo methods to source / channel models with a two - dimensional ( ) structure .",
    "the focus of the paper is on 2-d binary - input channels with constraints on the allowed input configurations ; for example , we consider the channel where adjacent channel input symbols must not both have the value  1 .",
    "variations of such channels are of interest in magnetic and optical storage , where the constraints are imposed , e.g. , in order to reduce the intersymbol interference or to help in timing control @xcite .",
    "we will consider both noiseless and noisy versions of such channels .",
    "with suitable modifications ( simplifications ) , the methods of this paper can also be applied to other source / channel models such as channels with intersymbol interference .    in the one - dimensional ( ) case , computing the capacity of noiseless constrained channels was addressed and solved by shannon @xcite , see also @xcite .",
    "for the noisy case , the monte carlo methods of @xcite can be used to compute the information rate .",
    "the 2-d case is harder .",
    "even the noiseless capacity is hard to compute numerically : while very tight analytical results are available for a number of special cases ( e.g. , @xcite ) , other cases have remained open problems .",
    "the noisy case has remained largely unsolved .",
    "the capacity of a noiseless constrained channel is essentially the logarithm of the partition function of the corresponding indicator function ( see section  [ sec : partitionfunction ] ) .",
    "moreover , computing the information rate of noisy source / channel models can also be reduced to the computation of a partition function ( see section  [ sec : estinfo ] ) .",
    "the heart of the paper , therefore , are monte carlo algorithms for the computation of partition functions .",
    "several such algorithms are well known @xcite , see also  @xcite , but some modifications will be necessary for the problems of interest in this paper . in particular , we will find tree - based gibbs sampling ( due to hamze and de freitas @xcite ) extremely useful .",
    "we will observe that monte carlo estimates of a partition function may actually be obtained as a by - product of tree - based gibbs sampling , which does not seem to have been noticed before .    in related prior work ,",
    "monte carlo algorithms have been used to compute bounds on , or approximations of , the information rate of 2-d source / channels with memory @xcite .",
    "some of this work uses generalized belief propagation @xcite , which appears to yield very good approximations to the information rate @xcite , @xcite .",
    "in contrast to all this prior work , the monte carlo methods of this paper are asymptotically unbiased , i.e. , in the limit of infinitely many samples , the estimates are guaranteed to converge to the desired quantity ( the information rate ) .",
    "moreover , the focus of this paper is on constrained channels , for which these computational problems are harder than for intersymbol interference channels ( cf .",
    "section  [ sec : estinfomethod ] ) .",
    "the empirical success of the proposed algorithms is epitomized by fig .",
    "[ fig : snr2 ] , which shows the uniform - input information rate of a binary - input channel with input constraints and additive white gaussian noise ( awgn ) .",
    "as far as known to the authors , no such figure ( for such a channel ) has been presented before .    if the reader is not familiar with gibbs sampling , the following comments on the general nature of this work may be in order .",
    "first , gibbs sampling is easily proved ( under very mild conditions ) to yield samples that are _ eventually _ distributed according to the desired distribution and _ asymptotically _ independent  @xcite ( i.e. , deleting the first @xmath0 samples and decimating the remaining sample sequence by a factor @xmath1 results in an i.i.d .",
    "sequence in the limit @xmath2 ) .",
    "however , the dependencies among the samples may decay extremely slowly , which is the pivotal issue with gibbs sampling and makes naive gibbs sampling perfectly useless for the problems of this paper ( and for many other problems ) .",
    "the challenge , therefore , is to speed up gibbs sampling ( i.e. , to decrease the dependencies of the samples ) by various additional tricks and insights so that it becomes useful .",
    "second , the class of problems for which the methods proposed in this paper will work is not easily expressed in exact terms .",
    "again , the issue is not formal applicability ( which is quite sweeping ) , but the speed of convergence , which strongly depends on the particulars of the case and is not easily predicted . the paper is organized as follows . in section  [ sec : partitionfunction ] , we review partition functions and noiseless 2-d constrained channels , and we introduce the corresponding notation . in section  [ sec : basicmontecarlo ] , we review several monte carlo algorithms that will be used in this paper .",
    "however , additional ideas are necessary to make these algorithms work for our applications .",
    "in particular , we will need tree - based gibbs sampling as described in section  [ sec : tbgz ] .",
    "the application to noiseless constrained channels is demonstrated in section  [ sec : noiselesscapnumex ] .",
    "the application to noisy channels is described and demonstrated in section  [ sec : estinfo ] . the appendix reviews sampling from markov chains , which is needed in section  [ sec : tbgz ] .",
    "let @xmath3 be finite sets , let @xmath4 be the cartesian product @xmath5 , and let @xmath6 be a nonnegative function @xmath7 .",
    "we are interested in computing ( exactly or approximately ) the _ partition function _",
    "@xmath8    for cases where    * @xmath9 is large and * @xmath6 has a suitable factorization ( as will be detailed below ) .",
    "we will usually assume @xmath10 .",
    "then @xmath11 is a probability mass function on @xmath4 .",
    "we also define the support of @xmath6 ( and of @xmath12 ) as @xmath13    if @xmath14 has a cycle - free factor graph representation ( and if @xmath15 are not too large ) , then @xmath16 can be computed efficiently by sum - product message passing @xcite . in this paper , however , we consider factor graphs with cycles . in particular , we are interested in examples of the following type .",
    "* example : simple 2-d constrained channel * + consider a grid of @xmath17 binary ( i.e. , @xmath18-valued ) variables @xmath19 with the constraint that no two ( horizontally or vertically ) adjacent variables have both the value  @xmath20 .",
    "let @xmath21 be the indicator function of this constraint , which can be factored into @xmath22 where the product runs over all adjacent pairs @xmath23 and with factors @xmath24 the corresponding forney factor graph of @xmath6 is shown in fig .",
    "[ fig:2dgrid ] , where the boxes labeled `` @xmath25 '' are equality constraints @xcite .",
    "( note that , in forney factor graphs , variables are represented by edges .",
    "[ fig:2dgrid ] may also be viewed as a factor graph as in @xcite where the boxes labeled `` @xmath25 '' are the variable nodes . )",
    "note that , in this example , @xmath26 .",
    "this example is known as the 2-d @xmath27 run - length limited constrained channel  @xcite .",
    "the quantity @xmath28 is known as the ( finite - size ) noiseless capacity of the channel . for this particular example ,",
    "upper and lower bounds on the infinite - size noiseless capacity @xmath29 were first proposed in  @xcite and improved in  @xcite and  @xcite .",
    "the bounds in  @xcite agree on nine decimal digits , which far exceeds the accuracy that can be achieved with the monte carlo methods of the present paper .",
    "however , the methods proposed in this paper work also for various generalizations of this example for which no tight bounds are known",
    ". @xmath30    ( 76,64)(0,0 ) ( 0,60)(4,4)@xmath25 ( 4,62)(1,0)8 ( 8,63)(0,0)[bc]@xmath31 ( 12,60)(4,4 ) ( 16,62)(1,0)8 ( 24,60)(4,4)@xmath25 ( 28,62)(1,0)8 ( 32,63)(0,0)[bc]@xmath32 ( 36,60)(4,4 ) ( 40,62)(1,0)8 ( 48,60)(4,4)@xmath25 ( 52,62)(1,0)8 ( 56,63)(0,0)[bc]@xmath33 ( 60,60)(4,4 ) ( 64,62)(1,0)8 ( 72,60)(4,4)@xmath25 ( 2,54)(0,1)6 ( 0,50)(4,4 ) ( 2,50)(0,-1)6 ( 26,54)(0,1)6 ( 24,50)(4,4 ) ( 26,50)(0,-1)6 ( 50,54)(0,1)6 ( 48,50)(4,4 ) ( 50,50)(0,-1)6 ( 74,54)(0,1)6 ( 72,50)(4,4 ) ( 74,50)(0,-1)6 ( 0,40)(4,4)@xmath25 ( 4,42)(1,0)8 ( 12,40)(4,4 ) ( 16,42)(1,0)8 ( 24,40)(4,4)@xmath25 ( 28,42)(1,0)8 ( 36,40)(4,4 ) ( 40,42)(1,0)8 ( 48,40)(4,4)@xmath25 ( 52,42)(1,0)8 ( 60,40)(4,4 ) ( 64,42)(1,0)8 ( 72,40)(4,4)@xmath25 ( 2,34)(0,1)6 ( 0,30)(4,4 ) ( 2,30)(0,-1)6 ( 26,34)(0,1)6 ( 24,30)(4,4 ) ( 26,30)(0,-1)6 ( 50,34)(0,1)6 ( 48,30)(4,4 ) ( 50,30)(0,-1)6 ( 74,34)(0,1)6 ( 72,30)(4,4 ) ( 74,30)(0,-1)6 ( 0,20)(4,4)@xmath25 ( 4,22)(1,0)8 ( 12,20)(4,4 ) ( 16,22)(1,0)8 ( 24,20)(4,4)@xmath25 ( 28,22)(1,0)8 ( 36,20)(4,4 ) ( 40,22)(1,0)8 ( 48,20)(4,4)@xmath25 ( 52,22)(1,0)8 ( 60,20)(4,4 ) ( 64,22)(1,0)8 ( 72,20)(4,4)@xmath25 ( 2,14)(0,1)6 ( 0,10)(4,4 ) ( 2,10)(0,-1)6 ( 26,14)(0,1)6 ( 24,10)(4,4 ) ( 26,10)(0,-1)6 ( 50,14)(0,1)6 ( 48,10)(4,4 ) ( 50,10)(0,-1)6 ( 74,14)(0,1)6 ( 72,10)(4,4 ) ( 74,10)(0,-1)6 ( 0,0)(4,4)@xmath25 ( 4,2)(1,0)8 ( 12,0)(4,4 ) ( 16,2)(1,0)8 ( 24,0)(4,4)@xmath25 ( 28,2)(1,0)8 ( 36,0)(4,4 ) ( 40,2)(1,0)8 ( 48,0)(4,4)@xmath25 ( 52,2)(1,0)8 ( 60,0)(4,4 ) ( 64,2)(1,0)8 ( 72,0)(4,4)@xmath25    later on , in section  [ sec : estinfo ] , we will consider noisy versions of such channels . as it turns out",
    ", the computation of the information rates of such channels also requires the computation of partition functions as in  ( [ eqn : partitionfunction ] ) .",
    "one well - known method to estimate @xmath34 ( and thus @xmath16 itself ) goes as follows .    *",
    "ogata - tanemura method * @xcite :    1 .",
    "draw samples @xmath35 from @xmath36 according to @xmath37 as in ( [ eqn : pdef ] ) .",
    "2 .   compute @xmath38    @xmath30    it is easy to verify that @xmath39 .    however , there are two major issues with this method .",
    "first , there is the problem of generating the samples @xmath35 according to @xmath37 . ideally , we would like these samples to be independent , but ( for the purposes of this paper ) this is asking too much .",
    "in particular , we will use gibbs sampling  @xcite , which produces dependent samples .",
    "however , with naive gibbs sampling , the dependencies among the samples decay far too slowly for the estimate  ( [ eqn : ogatatanemura ] ) to be useful for us ( cf .  the remarks in the introduction ) .",
    "we will see in section  [ sec : tbgz ] , how this issue is eased by tree - based gibbs sampling as proposed by hamze and de  freitas  @xcite .",
    "second , it is usually assumed that @xmath6 is strictly positive . in this case",
    ", @xmath40 and @xmath41 is known .",
    "however , this assumption excludes applications to constrained channels as in the example in section  [ sec : partitionfunction ] . indeed ,",
    "in that example , we would have @xmath42 for all samples @xmath43 , and @xmath44 is the desired unknown quantity .",
    "we will address this issue in section  [ subsec : applicationpfunction ] .",
    "with suitable modifications , which will address the mentioned issues , the ogata - tanemura method will turn out to work well for the capacity of noiseless constrained 2-d channels .",
    "however , for our second application  the information rate of noisy 2-d constrained source / channel models ",
    "the ogata - tanemura method turns out to be inadequate .",
    "we will therefore resort to multilayer importance sampling as described below .",
    "we first describe the use of standard ( single - layer ) importance sampling to estimate @xmath16 .    * importance sampling * @xcite :    1 .",
    "draw samples @xmath35 from @xmath4 according to some auxiliary probability distribution @xmath45 , where @xmath46 is a nonnegative function defined on @xmath4 satisfying @xmath47 whenever @xmath48 .",
    "2 .   compute @xmath49    @xmath30    it is easy to verify that @xmath50 .",
    "the key issue with importance sampling is to find a useful function @xmath46 such that    * @xmath51 is a good approximation of @xmath52 ( so that @xmath53 does not wildly fluctuate ) , * sampling from @xmath51 is feasible , and * computing @xmath54 is feasible .",
    "an obvious choice for @xmath46 ( and thus @xmath51 ) is @xmath55 for @xmath56 . with this choice , any factorization of @xmath14 results in a factorization of @xmath46 that preserves the topology of the corresponding factor graph .",
    "( note , however , that this choice of @xmath46 is not helpful if @xmath14 is @xmath18-valued . )    in order to sample from @xmath51 , we will again use tree - based gibbs sampling ( see section  [ subsec : treebasedgibbssampling ] ) . in a variation of the algorithm ,",
    "the estimator ( [ eq : estimport ] ) of the ratio @xmath57 could be replaced by bennett s acceptance ratio method  @xcite , which is also known as bridge sampling @xcite .",
    "a function @xmath46 with all the required properties may be hard to find , or it may not exist .",
    "this problem is addressed by multilayer importance sampling , which uses several auxiliary distributions .",
    "( 82,84)(0,0 ) ( 0,10 )    ( 76,64)(0,0 ) ( 0,60)(4,4)@xmath25 ( 4,62)(1,0)8 ( 12,60)(4,4 ) ( 16,62)(1,0)8 ( 24,60)(4,4)@xmath25 ( 28,62)(1,0)8 ( 36,60)(4,4 ) ( 40,62)(1,0)8 ( 48,60)(4,4)@xmath25 ( 52,62)(1,0)8 ( 60,60)(4,4 ) ( 64,62)(1,0)8 ( 72,60)(4,4)@xmath25 ( 2,54)(0,1)6 ( 0,50)(4,4 ) ( 2,50)(0,-1)6 ( 26,54)(0,1)6 ( 24,50)(4,4 ) ( 26,50)(0,-1)6 ( 50,54)(0,1)6 ( 48,50)(4,4 ) ( 50,50)(0,-1)6 ( 74,54)(0,1)6 ( 72,50)(4,4 ) ( 74,50)(0,-1)6 ( 0,40)(4,4)@xmath25 ( 4,42)(1,0)8 ( 12,40)(4,4 ) ( 16,42)(1,0)8 ( 24,40)(4,4)@xmath25 ( 28,42)(1,0)8 ( 36,40)(4,4 ) ( 40,42)(1,0)8 ( 48,40)(4,4)@xmath25 ( 52,42)(1,0)8 ( 60,40)(4,4 ) ( 64,42)(1,0)8 ( 72,40)(4,4)@xmath25 ( 2,34)(0,1)6 ( 0,30)(4,4 ) ( 2,30)(0,-1)6 ( 26,34)(0,1)6 ( 24,30)(4,4 ) ( 26,30)(0,-1)6 ( 50,34)(0,1)6 ( 48,30)(4,4 ) ( 50,30)(0,-1)6 ( 74,34)(0,1)6 ( 72,30)(4,4 ) ( 74,30)(0,-1)6 ( 0,20)(4,4)@xmath25 ( 4,22)(1,0)8 ( 12,20)(4,4 ) ( 16,22)(1,0)8 ( 24,20)(4,4)@xmath25 ( 28,22)(1,0)8 ( 36,20)(4,4 ) ( 40,22)(1,0)8 ( 48,20)(4,4)@xmath25 ( 52,22)(1,0)8 ( 60,20)(4,4 ) ( 64,22)(1,0)8 ( 72,20)(4,4)@xmath25 ( 2,14)(0,1)6 ( 0,10)(4,4 ) ( 2,10)(0,-1)6 ( 26,14)(0,1)6 ( 24,10)(4,4 ) ( 26,10)(0,-1)6 ( 50,14)(0,1)6 ( 48,10)(4,4 ) ( 50,10)(0,-1)6 ( 74,14)(0,1)6 ( 72,10)(4,4 ) ( 74,10)(0,-1)6 ( 0,0)(4,4)@xmath25 ( 4,2)(1,0)8 ( 12,0)(4,4 ) ( 16,2)(1,0)8 ( 24,0)(4,4)@xmath25 ( 28,2)(1,0)8 ( 36,0)(4,4 ) ( 40,2)(1,0)8 ( 48,0)(4,4)@xmath25 ( 52,2)(1,0)8 ( 60,0)(4,4 ) ( 64,2)(1,0)8 ( 72,0)(4,4)@xmath25    ( 26,42)(24,84 ) ( 72,42)(20,84 ) ( 2,79)(0,0)[c]@xmath58 ( 26,79)(0,0)[c]@xmath59 ( 50,79)(0,0)[c]@xmath58 ( 74,79)(0,0)[c]@xmath59    * multilayer ( multi - temperature ) importance sampling : *    multilayer importance sampling , as described here , is a variation of annealed importance sampling as proposed by neal  @xcite , @xcite ; see also  @xcite .",
    "we use @xmath60 parallel versions of importance sampling as follows .",
    "for @xmath61 , let @xmath62 with @xmath63 .",
    "note that @xmath64 and @xmath65 for @xmath66 , compute the ratio @xmath67 by importance sampling as described before :    1 .",
    "draw samples @xmath35 from @xmath68 .",
    "2 .   compute + rcl r_j & = & _ k=1^k + & = & _ k=1^k f(*x*^(k))^_j-1-_j .",
    "[ eqn : hatrj ]    @xmath30    noting that @xmath69 , we use @xmath70 as an estimate of @xmath71 .",
    "if the number of layers @xmath60 is large , @xmath72 is a good approximation of @xmath73 at each layer @xmath74 .",
    "it remains to find an estimate of @xmath75 , which tends to be easier than the original problem of estimating @xmath16 .",
    "in particular , for @xmath76 , we have @xmath77 , the cardinality of the support of @xmath6 . in our application",
    "( section  [ sec : estinfo ] ) , it turns out that @xmath75 can be computed efficiently by the tree - based ogata - tanemura method of section  [ subsec : applicationpfunction ] .",
    "tree - based gibbs sampling was proposed by hamze and de freitas  @xcite .",
    "it works as follows .",
    "let @xmath78 be a partition of the index set @xmath79 such that ,    * for fixed @xmath80 , the factor graph of @xmath81 is cycle - free , and * for fixed @xmath82 , the factor graph of @xmath81 is also cycle - free .",
    "an example of such a partition is shown in fig .",
    "[ fig:2dgridpartition ] . starting from some initial configuration @xmath83 ,",
    "the samples @xmath84 , @xmath85 , are created as follows : first , @xmath86 is drawn from @xmath87 second , @xmath88 is drawn from @xmath89    the point is that drawing these samples is easy ( by means of backward - filtering forward - sampling , see the appendix ) since the corresponding factor graphs are cycle - free .    as in standard gibbs sampling ,",
    "the samples @xmath90 are eventually ( i.e. , for @xmath91 ) drawn from @xmath12 ( provided that the corresponding markov chain is irreducible and aperiodic @xcite ) . however , tree - based gibbs sampling mixes faster than naive gibbs sampling .      with @xmath58 and @xmath59 as above , let @xmath92 and @xmath93 we then note that    rcl z_f_a & = & _ * x*_a f_a(*x*_a ) + & = & z_f ,    i.e. , @xmath94 ( and analogously @xmath95 ) has the same partition function as @xmath6 itself .",
    "we also note that samples @xmath96 , @xmath97 ,  , from @xmath98 can be obtained by tree - based gibbs sampling as in section  [ subsec : treebasedgibbssampling ] simply by dropping the second component ( the @xmath59-part ) of the samples @xmath99 , @xmath100 ,     we can now use the ogata - tanemura method ( section  [ sec : basicmontecarlo ] ) to estimate @xmath101 in two different ways .",
    "one way is to directly use the estimator ( [ eqn : ogatatanemura ] ) with samples @xmath102 as in section  [ subsec : treebasedgibbssampling ] . another way is to apply the estimator ( [ eqn : ogatatanemura ] ) to @xmath94 , i.e. , to compute @xmath103 which is also an estimate of @xmath104 .",
    "the computation of @xmath105 which is required in ( [ eqn : gammaa ] ) , is easy since the corresponding factor graph is a tree ; in fact , the result of this computation is obtained for free as a by - product of tree - based gibbs sampling as is explained in the appendix . by symmetry",
    ", we also have an analogous estimate @xmath106 defined as @xmath107    with the same samples @xmath99 , @xmath100 ,  , estimating @xmath104 from ( [ eqn : gammaa ] ) and ( [ eqn : gammab ] ) tends to converge faster than ( [ eqn : ogatatanemura ] ) .",
    "more importantly for this paper , the direct ogata - tanemura method ( [ eqn : ogatatanemura ] ) can not be used for constrained channels ( cf .",
    "the example in section  [ sec : partitionfunction ] ) where @xmath44 is the desired quantity .",
    "in contrast , the computation of @xmath108 in ( [ eqn : gammaa ] ) and @xmath109 in ( [ eqn : gammab ] ) may be easy in such cases as will be exemplified below .",
    "estimated noiseless capacity ( in bits / symbol ) vs.  the number of samples  @xmath110 for a @xmath111 grid with a @xmath27 constraint .",
    "the plot shows 10 different sample paths , each with two estimates , one from @xmath112 and another from @xmath113 .",
    "the horizontal dotted line shows the infinite - size capacity for this constraint . ]",
    "we demonstrate the estimators ( [ eqn : gammaa ] ) and ( [ eqn : gammab ] ) by their application to the example in section  [ sec : partitionfunction ] , the 2-d @xmath27 runlength - limited constrained channel .",
    "we will use factor graphs as in fig .",
    "[ fig:2dgrid ] with a partitioning as in fig .",
    "[ fig:2dgridpartition ] . in this example , the quantities @xmath108 and @xmath109 , which are needed in ( [ eqn : gammaa ] ) and ( [ eqn : gammab ] ) , respectively , are given by @xmath114 and likewise for @xmath115 .",
    "it follows that @xmath108 and @xmath109 are easy to compute by sum - product message passing in the cycle - free factor graphs of @xmath116 and @xmath115 , respectively .",
    "estimated noiseless capacity ( in bits / symbol ) vs.  the number of samples  @xmath110 for a @xmath117 grid with a @xmath27 constraint .",
    "the plot shows 10 different sample paths , each with two estimates , one from @xmath112 and another from @xmath113 .",
    "the horizontal dotted line shows the infinite - size capacity for this constraint . ]",
    "some experimental results are shown in figs .",
    "[ fig : p10 ] through  [ fig : p60 - 3 ] .",
    "all figures refer to @xmath6 as in ( [ eqn : noadjacentonesfunction ] ) and ( [ eqn : noadjacentonesfactor ] ) and show the estimates of the finite - size capacity @xmath118 ( [ eqn : cm ] ) obtained from ( [ eqn : gammaa ] ) and ( [ eqn : gammab ] ) vs.  @xmath110 for several different experiments . in fig .",
    "[ fig : p10 ] , we have @xmath119 and we obtain @xmath120 bits / symbol . in fig .  [",
    "fig : p60 - 1 ] , we have @xmath121 , and there are issues with slow convergence . in order to speed up the mixing and thus improving the convergence",
    ", we now partition the factor graph into vertical strips each containing @xmath122 or @xmath123 variables ( rather than @xmath124 variables as in fig .",
    "[ fig:2dgridpartition ] ) .",
    "exact sum - product message passing is still possible on such strips , e.g. , by converting the strip into an equivalent cycle - free factor graph .",
    "the computation time is exponential in the width of the strip , but the faster mixing results in a substantial reduction of total computation time for strips of moderate width .",
    "simulation results for strips of width 2 and 3 are shown in figs .",
    "[ fig : p60 - 2 ] and  [ fig : p60 - 3 ] , respectively , both for a grid of size @xmath121 .",
    "note that the convergence is much better than in fig .",
    "[ fig : p60 - 1 ] , and we obtain @xmath125 bits / symbol .    also shown in these figures , as a horizontal dotted line , is the infinite - size capacity @xmath126 bits / symbol from @xcite , which ( in this example ) is a lower bound on the finite - size capacity .",
    "same conditions as in fig .",
    "[ fig : p60 - 1 ] , but with strips of width three . ]    same conditions as in fig .",
    "[ fig : p60 - 1 ] , but with strips of width three . ]",
    "we now consider the problem of computing the information rate of noisy 2-d source / channel models . although the focus of this paper is on constrained channels , the proposed approach can also be applied to other 2-d source / channel models such as 2-d channels with intersymbol interference . for a 2-d grid of size @xmath17 ( as before ) ,",
    "let @xmath127 be the source process ( i.e. , the input process of the channel ) and let @xmath128 be the output process of the channel ; @xmath129 takes values in @xmath4 ( as defined in section  [ sec : partitionfunction ] ) and @xmath130 takes values in @xmath131 .",
    "we wish to compute the mutual information rate @xmath132 for cases where @xmath133 has a suitable factor graph .",
    "in particular , we will focus on the case where the channel is memoryless , i.e. , @xmath134 and where the channel input distribution @xmath52 has a factorization with a factor graph as in fig .",
    "[ fig:2dgrid ] .",
    "it then follows that @xmath133 has a factor graph as in fig .",
    "[ fig : sourcechannelgraph ] . in many cases of practical interest",
    ", @xmath135 is analytically available , see our numerical experiments in section  [ sec : numinfo ] .",
    "in such cases , the problem of computing the mutual information rate ( [ eqn : ir ] ) reduces to computing @xmath136.\\ ] ]    if @xmath135 is not analytically available , it can be computed by the same method as @xmath137 , see  ( * ? ? ? * section  iii ) .",
    "( 87,73)(0,-9 ) ( 0,60)(4,4)@xmath25 ( 4,60)(4,-3)4 ( 8,54)(3,3 ) ( 11,54)(4,-3)4 ( 14,53)@xmath138 ( 4,62)(1,0)8 ( 8,63)(0,0)[bc]@xmath31 ( 12,60)(4,4 ) ( 16,62)(1,0)8 ( 24,60)(4,4)@xmath25 ( 28,60)(4,-3)4 ( 32,54)(3,3 ) ( 35,54)(4,-3)4 ( 38,53)@xmath139 ( 28,62)(1,0)8 ( 32,63)(0,0)[bc]@xmath32 ( 36,60)(4,4 ) ( 40,62)(1,0)8 ( 48,60)(4,4)@xmath25 ( 52,60)(4,-3)4 ( 56,54)(3,3 ) ( 59,54)(4,-3)4 ( 62,53)@xmath140 ( 52,62)(1,0)8 ( 56,63)(0,0)[bc]@xmath33 ( 60,60)(4,4 ) ( 64,62)(1,0)8 ( 72,60)(4,4)@xmath25 ( 76,60)(4,-3)4 ( 80,54)(3,3 ) ( 83,54)(4,-3)4 ( 2,54)(0,1)6 ( 0,50)(4,4 ) ( 2,50)(0,-1)6 ( 26,54)(0,1)6 ( 24,50)(4,4 ) ( 26,50)(0,-1)6 ( 50,54)(0,1)6 ( 48,50)(4,4 ) ( 50,50)(0,-1)6 ( 74,54)(0,1)6 ( 72,50)(4,4 ) ( 74,50)(0,-1)6 ( 0,40)(4,4)@xmath25 ( 4,40)(4,-3)4 ( 8,34)(3,3 ) ( 11,34)(4,-3)4 ( 4,42)(1,0)8 ( 12,40)(4,4 ) ( 16,42)(1,0)8 ( 24,40)(4,4)@xmath25 ( 28,40)(4,-3)4 ( 32,34)(3,3 ) ( 35,34)(4,-3)4 ( 28,42)(1,0)8 ( 36,40)(4,4 ) ( 40,42)(1,0)8 ( 48,40)(4,4)@xmath25 ( 52,40)(4,-3)4 ( 56,34)(3,3 ) ( 59,34)(4,-3)4 ( 52,42)(1,0)8 ( 60,40)(4,4 ) ( 64,42)(1,0)8 ( 72,40)(4,4)@xmath25 ( 76,40)(4,-3)4 ( 80,34)(3,3 ) ( 83,34)(4,-3)4 ( 2,34)(0,1)6 ( 0,30)(4,4 ) ( 2,30)(0,-1)6 ( 26,34)(0,1)6 ( 24,30)(4,4 ) ( 26,30)(0,-1)6 ( 50,34)(0,1)6 ( 48,30)(4,4 ) ( 50,30)(0,-1)6 ( 74,34)(0,1)6 ( 72,30)(4,4 ) ( 74,30)(0,-1)6 ( 0,20)(4,4)@xmath25 ( 4,20)(4,-3)4 ( 8,14)(3,3 ) ( 11,14)(4,-3)4 ( 4,22)(1,0)8 ( 12,20)(4,4 ) ( 16,22)(1,0)8 ( 24,20)(4,4)@xmath25 ( 28,20)(4,-3)4 ( 32,14)(3,3 ) ( 35,14)(4,-3)4 ( 28,22)(1,0)8 ( 36,20)(4,4 ) ( 40,22)(1,0)8 ( 48,20)(4,4)@xmath25 ( 52,20)(4,-3)4 ( 56,14)(3,3 ) ( 59,14)(4,-3)4 ( 52,22)(1,0)8 ( 60,20)(4,4 ) ( 64,22)(1,0)8 ( 72,20)(4,4)@xmath25 ( 76,20)(4,-3)4 ( 80,14)(3,3 ) ( 83,14)(4,-3)4 ( 2,14)(0,1)6 ( 0,10)(4,4 ) ( 2,10)(0,-1)6 ( 26,14)(0,1)6 ( 24,10)(4,4 ) ( 26,10)(0,-1)6 ( 50,14)(0,1)6 ( 48,10)(4,4 ) ( 50,10)(0,-1)6 ( 74,14)(0,1)6 ( 72,10)(4,4 ) ( 74,10)(0,-1)6 ( 0,0)(4,4)@xmath25 ( 4,0)(4,-3)4 ( 8,-6)(3,3 ) ( 11,-6)(4,-3)4 ( 4,2)(1,0)8 ( 12,0)(4,4 ) ( 16,2)(1,0)8 ( 24,0)(4,4)@xmath25 ( 28,0)(4,-3)4 ( 32,-6)(3,3 ) ( 35,-6)(4,-3)4 ( 28,2)(1,0)8 ( 36,0)(4,4 ) ( 40,2)(1,0)8 ( 48,0)(4,4)@xmath25 ( 52,0)(4,-3)4 ( 56,-6)(3,3 ) ( 59,-6)(4,-3)4 ( 52,2)(1,0)8 ( 60,0)(4,4 ) ( 64,2)(1,0)8 ( 72,0)(4,4)@xmath25 ( 76,0)(4,-3)4 ( 80,-6)(3,3 ) ( 83,-6)(4,-3)4      as in  @xcite , we approximate the expectation in ( [ eqn : hy ] ) by the empirical average @xmath141 where samples @xmath142 are drawn according to @xmath143 . the problem of estimating the mutual information rate is thus reduced to    * creating samples @xmath144 and * computing @xmath145 for each sample .    if @xmath133 has a cycle - free factor graph ( and if @xmath15 are not too large ) , then both tasks can be carried out in a single - loop algorithm as in @xcite . in this paper ,",
    "however , we assume that no such factor graph exists and we propose a double - loop algorithm ( with an outer loop and an inner loop ) to carry out these tasks . in the outer loop , we create samples @xmath146 as follows",
    ".    1 .   draw samples @xmath147 according to @xmath52 .",
    "in simple cases ( such as unconstrained channels with i.i.d .  input ) , this may be trivial ; in general , however , we do this by tree - based gibbs sampling ( as in section  [ subsec : treebasedgibbssampling ] ) using the factor graph of @xmath52 .",
    "2 .   for @xmath148 , draw @xmath149 from @xmath150 , i.e. , by simulating the channel with input @xmath151 .    in the inner loop ,",
    "we compute an estimate of @xmath152 as follows .",
    "note that , for fixed @xmath153 , the right - hand side of ( [ eqn : py ] ) is the partition function @xmath154 of @xmath155 which has a suitable factor graph ( as , e.g. , in fig .",
    "[ fig : sourcechannelgraph ] ) . in principle",
    ", we can thus estimate ( [ eqn : py ] ) by any of the methods of section  [ sec : basicmontecarlo ] .",
    "it turns out , however , that only multilayer importance sampling is able to handle the more demanding cases ( as will be explained in our numerical experiments in section  [ sec : numinfo ] ) while the other methods of section  [ sec : basicmontecarlo ] suffer from slow and erratic convergence .      in our numerical experiments ,",
    "we consider a noisy version of the example in section  [ sec : partitionfunction ] , i.e. , a noisy version of the @xmath27 runlength - limited constrained channel .",
    "we assume that the channel input distribution @xmath52 is uniform over the allowed configurations , i.e. , @xmath156 with @xmath6 as in ( [ eqn : noadjacentonesfunction ] ) , and we assume that the noise is additive white gaussian ( and independent of @xmath129 ) , i.e. , @xmath157 is a product as in ( [ eqn : memorylesschannel ] ) with factors @xmath158 and thus @xmath159 we will use the signal - to - noise ratio ( snr ) defined as @xmath160 which we will specify in db , i.e. , @xmath161 .",
    "the grid size in all the plots is @xmath162 and the parameters @xmath163 in ( [ eqn : multilayerg ] ) are set to @xmath164 , for @xmath165 .",
    "[ fig : snr2 ] shows the computed information rate vs.  the snr over the interval @xmath166 $ ]  db . the horizontal dotted line in  fig .",
    "[ fig : snr2 ] shows the capacity of the noiseless version of this channel , which is about @xmath167 bits per symbol .    figs .",
    "[ fig : ir_zero ] and  [ fig : ir_six ] illustrate the convergence of the outer loop of the proposed double - loop algorithm at 0  db and at 6  db , respectively .",
    "both figures show the estimated information rate vs.  the number of samples @xmath168 in ( [ eqn : hye ] ) for 12 different sample paths . as for the inner loop ,",
    "the required number of layers @xmath60 in ( [ eqn : ratioz ] ) depends on the snr .",
    "as the snr increases ( or equivalently as @xmath169 decreases ) , the function @xmath170 in ( [ eqn : fell ] ) tends to have more isolated modes .",
    "therefore , in order to obtain a good approximation at each level of multilayer importance sampling , larger values of @xmath60 are required for higher snr . in our numerical experiments at 0  db and 6  db , @xmath60 is set to 3 and 6 , respectively .",
    "[ fig : lev1 ] shows the convergence of @xmath171 as in ( [ eqn : hatrj ] ) for @xmath172 , for a fixed output sample at 6  db .",
    "the value of @xmath75 is estimated by the tree - based ogata - tanemura method of section  [ subsec : applicationpfunction ] .",
    "[ fig : lev2 ] shows the convergence of the estimate of @xmath173 according to ( [ eqn : gammaa ] ) for four different sample paths .      in statistical physics , the partition function typically has the form @xmath174 where @xmath175 is the temperature and @xmath176 is the energy of the configuration @xmath177 .",
    "we therefore point out that the noise variance @xmath169 in ( [ eqn : noisychanmodnumex ] ) may be viewed as the temperature parameter of the partition function @xmath154 of ( [ eqn : fell ] ) .",
    "it is well known in statistical physics that computing the partition function is harder at low temperatures than at high temperatures .",
    "similarly , we observe that computing the partition function @xmath154 of ( [ eqn : fell ] ) is harder at high snr than at low snr ; in particular , at high snr , more layers ( higher values of @xmath60 ) are required for multilayer ( multi - temperature ) importance sampling .",
    "we also note that , in the examples of section  [ sec : numinfo ] , the choice of the parameters @xmath164 in ( [ eqn : multilayerg ] ) is somewhat arbitrary .",
    "it is possible that other choices of these parameters result in faster convergence .",
    "monte carlo methods have been highly succesful in computing the information rate of source / channel models with memory .",
    "the extension of such methods to source / channel models with 2-d memory has been an open research problem . in this paper",
    ", we develop such methods with a focus on the ( difficult ) case of channels with input constraints , with or without noise .",
    "in contrast to previous techniques , which either use generalized belief propagation or compute only bounds on the information rate , the monte carlo algorithms of this paper are guaranteed to converge ( asymptotically ) to the desired information rate . a key role in the proposed algorithms is played by tree - based gibbs sampling by hamze and de freitas , which we have shown to yield an estimate of the partition function as a by - product .",
    "the success of the proposed methods is exemplified by fig .",
    "[ fig : snr2 ] , which ( to the best of our knowledge ) is the first such plot for a noisy 2-d channel . we also note that the extension of the proposed methods to computing upper and lower bounds on the information rate as in  ( * ? ? ?",
    "* section  vi ) is straightforward .",
    "the authors wish to thank radford neal for helpful discussions and advice on annealed importance sampling .",
    "the authors also wish to thank david mackay and iain murray for pointing out to us @xcite , and the reviewers and the associate editor for helpful comments .",
    "we recall some pertinent facts about the simulation of markov chains and cycle - free factor graphs .",
    "let @xmath178 be the probability mass function of a markov chain .",
    "if @xmath52 is given in the form @xmath179 then it is obvious how to draw i.i.d .",
    "samples according to @xmath52 .",
    "now consider the case where @xmath52 is not given in the form ( [ eqn : pxchainrule ] ) , but in the more general form @xmath180 with general factors @xmath181 .",
    "it is then still easy to draw i.i.d .",
    "samples according to @xmath52 , which may be seen as follows .",
    "first , a probability mass function of the form ( [ eqn : pxcostchain ] ) can be rewritten in the form ( [ eqn : pxchainrule ] ) ( which allows efficient simulation ) .",
    "second , this reparameterization of @xmath52 may be efficiently carried out by backward sum - product message passing , as will be detailed below .",
    "the resulting algorithm is known as `` backward - filtering forward - sampling '' ( or , in a time - reversed version , as `` forward - filtering backward - sampling '' ) @xcite .",
    "specifically , let @xmath182 be the backward sum - product message along the edge @xmath183 in the factor graph of  ( [ eqn : pxcostchain ] ) , as is illustrated in fig .",
    "[ fig : ffgpxcostchainmsgb ] ( cf .",
    "we then have @xmath184 and          and @xmath186 for @xmath187 .",
    "the proof of ( [ eqn : transprobforw ] ) follows from noting that @xmath188 and @xmath189 where @xmath190 is the forward sum - product message along the edge @xmath191 and where @xmath192 is the missing scale factor in ( [ eqn : pxcostchain ] ) .",
    "( 75,15)(0,0 ) ( 0,5)(1,0)15 ( 7.5,8)(0,0)@xmath193 ( 15,2.5)(5,5 ) ( 17.5,11)(0,0)@xmath194 ( 20,5)(1,0)15 ( 27.5,8)(0,0)@xmath191 ( 35,2.5)(5,5 ) ( 37.5,11)(0,0)@xmath195 ( 40,5)(1,0)15 ( 47.5,8)(0,0)@xmath196 ( 50,3)(-1,0)5.5 ( 55,2.5)(5,5 ) ( 57.5,11)(0,0)@xmath197 ( 60,5)(1,0)15 ( 67.5,8)(0,0)@xmath198 ( 70,3)(-1,0)5.5    we also note that @xmath199 where @xmath46 is defined as the right - hand side of  ( [ eqn : pxcostchain ] ) . in this paper , this fact is used to compute the marginals ( [ eqn : samplemarginal ] ) as a by - product of the sampling .",
    "d.  arnold , h .- a .",
    "loeliger , p.  o.  vontobel , a.  kavi , and w.  zeng , `` simulation - based computation of information rates for channels with memory , '' _ ieee trans .",
    "theory _ , vol .",
    "52 , no .",
    "8 , august 2006 , pp .  34983508 .",
    "loeliger and m.  molkaraie , `` simulation - based estimation of the partition function and the information rate of two - dimensional models , '' _ proc .",
    "2008 ieee int .",
    "symp .  on information theory , _",
    "toronto , canada , july 611 , 2008 , pp .",
    "11131117 .",
    "loeliger and m.  molkaraie , `` estimating the partition function of fields and the capacity of constrained noiseless channels using tree - based gibbs sampling , '' _ proc .",
    "2009 ieee information theory workshop , _ taormina , italy , october 1116 , 2009 , pp .",
    "228232 .",
    "m.  molkaraie and h .- a .",
    "loeliger , `` estimating the information rate of noisy constrained 2-d channels , '' _ proc .",
    "2010 ieee int .",
    "symp .  on information theory , _",
    "austin , usa , june 1318 , 2010 , pp .  16781682 .",
    "o.  shental , n.  shental , s.  shamai ( shitz ) , i.  kanter , a.  j.  weiss , and y.  weiss , `` discrete - input two - dimensional gaussian channels with memory : estimation and information rates via graphical models and statistical mechanics , '' _ ieee trans .",
    "theory , _ vol .",
    "54 , april 2008 , pp .  15001513 .",
    "g.  sabato and m.  molkaraie , `` generalized belief propagation algorithm to estimate the capacity of multi - dimensional run - length limited constraints , '' _ proc .",
    "2010 ieee int .",
    "symp .  on information theory , _",
    "austin , usa , june 1318 , 2010 , pp .  12131217 .",
    "g.  sabato and m.  molkaraie , `` generalized belief propagation for the noiseless capacity and information rates of run - length limited constraints , '' _ ieee trans .",
    "comm . , _ vol .  60 , march 2012 , pp .  669675 ."
  ],
  "abstract_text": [
    "<S> the paper proposes monte carlo algorithms for the computation of the information rate of two - dimensional source / channel models . </S>",
    "<S> the focus of the paper is on binary - input channels with constraints on the allowed input configurations . </S>",
    "<S> the problem of numerically computing the information rate , and even the noiseless capacity , of such channels has so far remained largely unsolved . </S>",
    "<S> both problems can be reduced to computing a monte carlo estimate of a partition function . </S>",
    "<S> the proposed algorithms use tree - based gibbs sampling and multilayer ( multitemperature ) importance sampling . </S>",
    "<S> the viability of the proposed algorithms is demonstrated by simulation results .    </S>",
    "<S> two - dimensional channels , constrained channels , partition function , gibbs sampling , importance sampling , factor graphs , sum - product message passing , capacity , information rate . </S>"
  ]
}