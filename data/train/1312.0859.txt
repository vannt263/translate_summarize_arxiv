{
  "article_text": [
    "survival techniques are useful in situations where regular regression procedures are inadequate . for instance , where the probability of survival past a certain time is of more interest than the expected time of survival , survival techniques are more appropriate .",
    "the same holds true when there are censored data .",
    "censored data may arise due to partial follow - up ( until a specific time ) , loss to follow - up , or a subject dropping out of a study .",
    "attrition is quite common in medical studies where a subject is followed to a particular event of interest . in such cases ,",
    "the status of these subjects with respect to the event of interest is only known up to a particular time point .",
    "competing risks data often arise in survival and reliability analyses .",
    "these multiple cause data represent time to failure ( occurrence of event of interest ) and can be due to a host of causes . in a cancer study , for example ,",
    "a significant number of deaths due to causes other than cancer may be expected post - treatment because the average age of cancer patients is high @xcite .",
    "some existing methods for dealing with failure time data include parametric mixture models based on failure time densities @xcite , proportional hazards models @xcite , cause - specific hazard functions @xcite , accelerated failure time models @xcite , first hitting time models @xcite , frailty models @xcite , and so on .",
    "a classical mixture model for competing risks adopted a proportional hazards model with piecewise constant baseline hazards @xcite . a traditional approach to competing risks is the latent failure time approach @xcite which makes untestable assumptions about the independence of the competing risks ; this is unlike the mixture approach @xcite .",
    "we present a novel method to account for censored competing risks data using a mixture of accelerated failure time models in a cluster - weighted modelling ( cwm ) framework .",
    "this approach can be called the cluster - weighted accelerated failure time ( cwaft ) model",
    ". section [ cwm ] gives an introduction to cluster - weighted modelling .",
    "section [ methods ] briefly goes over accelerated failure time models and the mathematical details involved for cwaft models . in section [ results ] , we present our results on some simulated and real censored data , where the time to failure and cause of failure were only recorded for some of the observations .",
    "finally , we conclude with a discussion and some ideas for further research .",
    "@xcite give a good introduction to mixture models for the analysis of failure time data . in survival analysis , mixture models can be defined in terms of the density function @xmath0 or in terms of the survival function @xmath1 of @xmath2 where @xmath2 , is the ( non - negative , continuous ) random variable representing the time to the event of interest .",
    "hence , @xmath3 or @xmath4 , where @xmath5 and @xmath6 are the @xmath7th component density and the @xmath7th component survival function , respectively .",
    "@xcite introduced cwm in a more general statistical context .",
    "this methodology allowed for the decomposition and modelling of the joint probability of a response variable and a set of explanatory variables .",
    "let @xmath8 be the pair of random vector @xmath9 and random variable @xmath10 defined on @xmath11 with joint probability distribution @xmath12 . here",
    ", the response variable @xmath10 has values in @xmath13 and the explanatory variable @xmath9 is a @xmath14-dimensional vector with values in @xmath15 . if @xmath11 can be partitioned into @xmath16 disjoint groups , such that @xmath17 , the joint probability @xmath12 can be decomposed as @xmath18 where @xmath19 is the conditional density of @xmath10 given @xmath20 and @xmath21 , @xmath22 is the probability density of @xmath9 given @xmath21 , , and @xmath23 is the mixing weight , where @xmath24 ( @xmath25 ) and @xmath26 .",
    "@xmath27 denotes the set of all parameters . here",
    ", @xmath23 is the mixing weight of @xmath21 , where @xmath24 ( @xmath25 ) and @xmath26 . the mixing proportions @xmath28 in survival mixture models are often assumed to follow a logistic model of the covariates @xcite .",
    "using a cwm framework , the model presented in this paper is not necessarily bound by this restriction . here , @xmath19 can be viewed as weighted by both the marginal @xmath22 and unrestricted mixing weights @xmath28 .",
    "accelerated failure time ( aft ) models are a popular parametric regression alternative to proportional hazards regression .",
    "some common aft models employ the log - normal , log - logistic , and weibull distributions @xcite .",
    "@xmath29 is modeled analogous to classical regression . for a log - normal distribution , @xmath30 where @xmath31 is the mean and",
    "@xmath32 is the standard deviation of @xmath33 .",
    "this is @xmath34 where @xmath35 is the survival function of the standard gaussian distribution .",
    "a regression model can be constructed for @xmath10 given @xmath20 with @xmath36    with covariates , the linear model representation is @xmath37 , where @xmath38 is the error distribution ( log - scale form ) and @xmath20 provides the covariates . if a standard gaussian distribution is used for the error distribution , this results in a log - normal aft model .",
    "the underlying density and survival function for @xmath10 are @xmath39 and @xmath40    here , @xmath41 and because @xmath42 , where @xmath43 , @xmath44 .",
    "we propose that @xmath45 in the cwm joint likelihood decomposition can be modeled as a gaussian distribution where the random variable @xmath10 is @xmath33 , where @xmath2 , the time to event , follows a log - normal distribution .",
    "recall that cwm decomposes the joint probability @xmath12 as follows : @xmath46 the observed data likelihood is then @xmath47^{l_{ig } } \\times    \\\\ & \\qquad \\prod_{i=1}^{c } \\sum_{g=1}^g s_{y}(y_{ig}|{\\mathbf{x}}_i , { \\mbox{\\boldmath $ \\chi$}}_g)\\phi_d({\\mathbf{x}}_i| { \\mbox{\\boldmath $ \\psi$}}_g ) \\pi_g,\\end{aligned}\\ ] ] where @xmath48 is 1 if observation @xmath49 is known to have failed from cause @xmath7 and 0 otherwise , @xmath50 , and @xmath51 .",
    "@xmath52 and @xmath53 are the number of censored and total observations , respectively .",
    "the expectation - maximization framework is a popular technique for parameter estimation @xcite .",
    "this involves maximizing the expected complete - data log - likelihood .",
    "we use the alternating expectation conditional maximization ( aecm ) algorithm @xcite , which is a variation of the em algorithm that allows for different complete data at different stages .",
    "the em algorithm was coded in r @xcite .",
    "let @xmath54 be a sample of @xmath53 independent observations .",
    "then , the corresponding complete - data likelihood function can be written in the form @xmath55^{z_{ig}}.\\ ] ]    here , two latent variables are introduced .",
    "if @xmath57 comes from the @xmath7th population and @xmath58 otherwise . this corresponds to the conditional probability that individual @xmath49 will eventually fail from risk @xmath7 , conditional on no failure having occured by time @xmath59 .",
    "also , @xmath60 represents the uncensored failure time conditional on the @xmath61th individual failing from the @xmath7th cause ( @xmath7th component ) . for uncensored individuals , @xmath62",
    "is observed ; that is , it is merely @xmath63 . as an illustration ,",
    "consider @xmath64 and assume that @xmath65 corresponds to the competing risk and @xmath64 corresponds to the cause of interest .",
    "then , @xmath66 represents the failure time associated with the censored time @xmath63 conditional on the @xmath49th individual failing from the competing cause .",
    "using the accelerated failure time framework , the complete - data log - likelihood can be decomposed as @xmath67 \\\\ & = { \\mathcal{l}}_{1c } ( { \\mbox{\\boldmath $ \\chi$ } } ) + { \\mathcal{l}}_{2c } ( { \\mbox{\\boldmath $ \\psi$ } } ) + { \\mathcal{l}}_{3c } ( { \\mbox{\\boldmath $ \\pi$ } } ) , \\end{aligned}\\ ] ] where @xmath68 ^ 2}{\\sigma_{g}^{2}}\\right ] \\\\   { \\mathcal{l}}_{2c } ( { \\mbox{\\boldmath $ \\psi$ } } ) & = \\frac{1}{2 } \\sum_{i=1}^n \\sum_{g=1}^g   z_{ig } \\left[- p \\log 2\\pi - \\log |{\\mbox{\\boldmath $ \\sigma$}}_g| - ( { \\mathbf{x}}_i-{\\mbox{\\boldmath $ \\mu$}}_g ) ' { \\mbox{\\boldmath $ \\sigma$}}_g^{-1 } ( { \\mathbf{x}}_i-{\\mbox{\\boldmath $ \\mu$}}_g)\\right ] \\label{l2c } \\\\   { \\mathcal{l}}_{3c } ( { \\mbox{\\boldmath $ \\pi$ } } ) & = \\sum_{i=1}^n \\sum_{g=1}^g   z_{ig } [ \\log \\pi_g ] .\\end{aligned}\\ ] ]    given the parameters @xmath69 , @xmath70 , @xmath71 , @xmath72 , @xmath73 at the @xmath74th iteration , the expected complete - data log - likelihood is @xmath75",
    "\\notag \\\\    & = \\sum_{i=1}^n \\sum_{g=1}^g   \\tau_{ig}^{(k ) } [ q_{1}({\\mbox{\\boldmath $ \\chi$}}_g|{\\mbox{\\boldmath $ \\theta$}}^{(k ) } ) + q_{2}({\\mbox{\\boldmath $ \\psi$}}_g|{\\mbox{\\boldmath $ \\theta$}}^{(k ) } ) + \\log \\pi_g^{(k ) } ] ,   \\end{aligned}\\ ] ] where @xmath76 provides the current value on the @xmath74-iteration for the censored observations and @xmath77 ^ 2}{\\sigma_{g}^{2}}\\right ) \\right ] , \\\\",
    "q_{2}({\\mbox{\\boldmath $ \\psi$}}_g|{\\mbox{\\boldmath $ \\theta$}}^{(k ) } ) & =   \\frac{1}{2 } \\left[- p \\log 2\\pi - \\log |{\\mbox{\\boldmath $ \\sigma$}}_g| - ( { \\mathbf{x}}_i-{\\mbox{\\boldmath $ \\mu$}}_g ) ' { \\mbox{\\boldmath $ \\sigma$}}_g^{-1 } ( { \\mathbf{x}}_i-{\\mbox{\\boldmath $ \\mu$}}_g)\\right].\\end{aligned}\\ ] ]    here , for an observed failure time , @xmath78 . for right censored times @xmath79 ( associated response variables are @xmath80 ) , following",
    "@xcite we observe that the conditional probability density function of an observation censored to the right is that of the random variable @xmath59 truncated to the left at @xmath81 .",
    "hence , @xmath82 where @xmath83 in which @xmath84 is the lifetime that would have been observed if @xmath85 has not been censored ; that is , if it had been observed .",
    "then , the conditional expected value @xmath86 for a right censored time is @xmath87 where @xmath88 .",
    "note that this is also the mean of the truncated normal distribution ( see appendix [ appeyderive ] ) .",
    "similarly , @xmath89 is ( see appendix [ appey2derive ] ) @xmath90 + \\\\ & \\qquad   2 \\mu^{(k)}_{g(y ) } { \\mathbb{e}}(y_{ig } ) - \\mu^{2(k)}_{g(y)}.    \\end{aligned}\\ ] ]    the m - step requires the maximization of the conditional expectation of the complete - data log - likelihood with respect to @xmath27 . the updates for the parameters @xmath91 , @xmath92 , and @xmath93 can be found by taking the derivative with respect to the appropriate parameter @xmath94 these closed form updates can be found in @xcite .",
    "the updates @xmath95 , and @xmath96 can similarly be derived ( appendix [ mstepapp ] ) :    @xmath97 } { \\sum_{i=1}^n \\tau_{ig}^{(k ) } } .\\end{aligned}\\ ] ]    aitken s stopping criterion was used to determine convergence of the algorithm .",
    "aitken s acceleration at iteration @xmath74 can be calculated as @xmath98 where @xmath99 , @xmath100 , and @xmath101 are the log - likelihood values from iterations @xmath102 , @xmath74 , and @xmath103 , respectively .",
    "this can be used to compute the asymptotic estimate of the log - likelihood at iteration @xmath103 @xcite : @xmath104 the em algorithm is stopped when @xmath105 @xcite .",
    "we use overall survival functions and cumulative incidence function for judging model fits .",
    "the overall survival function is estimated in the fashion of @xcite by averaging individual estimates of subjects , and compared to a nonparametric estimate by way of a kaplan meier curve @xcite .",
    "this statistic does not utilize information on cause of death or covariates .",
    "the overall survival function is @xmath106 .",
    "since kaplan - meier ( km ) curves are not appropriate for the event of interest or the competing event directly , cumulative incidence curves are used .",
    "the cumulative incidence function can be defined as the cause - specific failure probability up to a certain time point @xmath59 .",
    "the cumulative incidence curves are also presented with fits to the nelson - aalen cumulative incidence estimator @xcite .",
    "following @xcite , the cumulative incidence function for the @xmath7th type of failure is @xmath107 .",
    "this was estimated by @xmath108 .",
    "the standard errors were calculated using a non - parametric bootstrap @xcite that was adjusted to account for the competing risks structure as in @xcite .",
    "as before , let @xmath52 be the number of censored observations .",
    "then , let @xmath109 @xmath110 be the number of observed failures due to the @xmath7th cause .",
    "each bootstrap sample was obtained by sampling with replacement separately from each of the @xmath111 sets with the size of each bootstrap subsample equal to @xmath109 and @xmath52 , respectively .",
    "the data @xmath57 were re - sampled 100 times independently .",
    "the standard deviation of the resulting bootstrap maximum likelihood estimates yield an approximation of the standard error of the estimates .",
    "note that we present results for a simulation with two covariates here for simplicity ; however , the model is not bound by this restriction and seems to perform quite well in simulations with more than two covariates .",
    "the specifications for the gaussian covariate vectors for group 1 were mean@xmath112 and covariance @xmath113 .",
    "the specifications for the gaussian covariate vectors for group 2 were mean@xmath114 and covariance @xmath115 .",
    "the regression intercepts used for the groups were @xmath116 and @xmath117 , respectively .",
    "the regression coefficients were @xmath118 and @xmath119 , respectively , and the error @xmath120 .",
    "fifty observations were censored ( type ii right , noninformative ) in total by subtracting normally distributed values from randomly selected observations from both groups .",
    "+    .parameter estimates and standard errors ( rounded off to 2 decimals ) for simulated data . [ cols=\"<,<,<,<,<\",options=\"header \" , ]     parameter estimates with standard errors in parenthesis , where @xmath7=1 and 2 refer to the cause of interest and the competing cause , respectively .",
    "+     table [ parest4d ] contains the parameter estimates and standard errors .",
    "apart from the high percentage of censoring , this dataset is also unique in that censoring begins relatively late ( figure [ real2osf ] ) .",
    "the estimated cumulative incidence functions are still able to capture the trend of the non - parameteric estimators quite closely ( figure [ real2cuminc ] ) .",
    "a novel approach to classifying censored data from different groups while utilizing the distribution of the covariates was presented . in simulated and real data sets ,",
    "the algorithm showed good performance and was able to extract marginal probabilistic behaviour quite well .",
    "the algorithm is quite stable as shown in regards to initialization for the em .",
    "sometimes , a reasonable number was substituted where nan or infinity errors were encountered while calculating @xmath86 or @xmath89 .",
    "commonly , in the literature , the distribution of the covariates is taken into account to alleviate the impact of any mis - recorded covariates , unobserved heterogeneity , or in the presence of evidence that the data are from particular subsamples of the population .",
    "these usually correspond to data misspecification ( or missing data ) models , or random effect models . in survival literature ,",
    "frailty models attempt to account for unobserved heterogeneity by including a random effect . here , the marginal distribution of the covariates @xmath121 is directly taken into account in the maximization of the likelihood function in the em algorithm .",
    "this is also novel in the field of survival analysis to the authors knowledge .",
    "note that for both real data sets , the competing risk was death from other events .",
    "also note that it is not always easy to distinguish between a cured individual and a susceptible individual with a large failure time .",
    "@xcite gives a good discussion on how care must be exercised in assuming that a fraction of patients is cured .",
    "having said that , a cure rate can estimated by following @xcite .",
    "assuming that a patient is cured if the patient dies from a competing cause at a time @xmath122 ( for example , @xmath123 years has been used in breast cancer studies ) without any symptoms of the disease , then from our model , the cure rate can be calculated as @xmath124 . here",
    ", @xmath125 is the proportion of individuals who fail from one of the competing causes , that is , will not fail from the cause of interest .",
    "@xmath126 refers to the conditional survival function for failure from a competing cause .",
    "note that here @xmath125 is being adjusted by excluding those patients with death times smaller than @xmath122 as being cured to account for early deaths that may have been due to postoperative complications and not because they did not have any symptoms of the cause of interest .",
    "because we are fitting a gaussian distribution to the marginal distribution of the covariates , currently only continuous covariates can be used . a convenient way to include discrete covariates might be to use them as concomitant variables in a logistic model of the covariates for the probability of failure from a particular risk .",
    "however , more work is required to eliminate this aspect from the methodology . incorporating something akin to a latent trait model for the covariates might be fruitful , for instance if we have data on a few levels of dosage .",
    "we used the log - normal distribution here , but other commonly used distributions like log - logistic , weibull , generalized gamma , etc .",
    "could also be used depending on the data .",
    "furthermore , semi - parametric extensions of the model might lead to more flexible alternatives . due to the nature of the likelihood formulation , dealing with missing data in the covariates",
    "might also be worthwhile .",
    "this work is supported by a alexander graham bell canada graduate scholarship ( cgs - d ) and discovery grant from the natural sciences and engineering research council ( nserc ) of canada .",
    "@xmath128    let @xmath129 . then , @xmath130 and @xmath131 , \\\\ & = \\mu + \\sigma \\frac{\\phi\\left(\\frac{y^*-\\mu}{\\sigma}\\right)}{1-\\phi\\left(\\frac{y^*-\\mu}{\\sigma}\\right)}. \\\\\\end{aligned}\\ ] ]",
    "@xmath133    where @xmath134 . again , let @xmath129 . hence , @xmath135 where @xmath136 .",
    "now , using integration by parts ,    @xmath137 +    \\\\ & \\qquad 2 b^ * \\mu{\\mathbb{e}}^{(k)}(y)\\left(1-\\phi\\left(\\frac{y^*-\\mu}{\\sigma}\\right)\\right ) -b^*\\mu^2\\left(1-\\phi\\left(\\frac{y^*-\\mu}{\\sigma}\\right)\\right ) , \\\\   & = \\sigma_g^2\\left[\\frac{\\left(\\frac{y^*-\\mu_g}{\\sigma_g}\\right)\\phi{\\left(\\frac{y^*-\\mu_g}{\\sigma_g}\\right ) } + 1 - \\phi\\left(\\frac{y^*-\\mu_g}{\\sigma_g}\\right)}{1-\\phi\\left(\\frac{y^*-\\mu_g}{\\sigma_g}\\right)}\\right ] + 2\\mu{\\mathbb{e}}^{(k)}(y_{ig } ) -\\mu^{2}_{g } .",
    "\\\\\\end{aligned}\\ ] ]",
    "for @xmath138 @xmath139 , @xmath140 yields @xmath141 & = 0 \\\\ \\sum_{i=1}^n \\tau_{ig}^{(k ) } \\left({\\mathbb{e}}^{(k)}(y_{ig})-{\\mathbf{b}}_g^{'(k)}{\\mathbf{x}}_i\\right ) & =   b_{0g}^{(k ) } \\sum_{i=1}^n \\tau_{ig}^{(k)},\\end{aligned}\\ ] ] and then we get @xmath142 similarly , for @xmath143 @xmath139 , @xmath144 implies @xmath145{\\mathbf{x}}'_n   = \\boldsymbol{0 } ' , \\ ] ] yielding @xmath146 for @xmath147 @xmath148 ) , @xmath149 yields @xmath150 this implies @xmath151            bhning d , dietz e , schaub r , schlattmann p , lindsay bg ( 1994 ) the distribution of the likelihood ratio for mixtures of densities from the one - parameter exponential family .",
    "annals of the institute of statistical mathematics 46(2):373388                                                  yamaguchi k ( 1992 ) accelerated failure - time regression models with a regression model of surviving fraction : an application to the analysis of permanent employment in japan .",
    "journal of the american statistical association 87(418):284292"
  ],
  "abstract_text": [
    "<S> a novel approach for dealing with censored competing risks regression data is proposed . </S>",
    "<S> this is implemented by a mixture of accelerated failure time ( aft ) models for a competing risks scenario within a cluster - weighted modelling ( cwm ) framework . </S>",
    "<S> specifically , we make use of the log - normal aft model here but any commonly used aft model can be utilized . the alternating expectation conditional maximization algorithm ( aecm ) </S>",
    "<S> is used for parameter estimation and bootstrapping for standard error estimation . </S>",
    "<S> finally , we present our results on some simulated and real competing risks data . </S>"
  ]
}