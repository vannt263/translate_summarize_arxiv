{
  "article_text": [
    "[ secintro ] the aim of this paper is to prove the edge universality of correlation matrices .",
    "the data matrix @xmath11 is an @xmath12 matrix with independent centered real - valued entries .",
    "the entries in each column @xmath13 all are assumed to be identically distributed : @xmath14 furthermore , the entries @xmath15 have a subexponential decay , that is , there exists a constant @xmath16 such that for @xmath17 , @xmath18 we will be working the regime @xmath19 thus , without loss of generality , henceforth we will assume that for some small constant @xmath20 , for all @xmath21 , latexmath:[\\[\\theta < d_n<\\theta^{-1 } \\quad\\mbox{and}\\quad\\theta <    @xmath20 and @xmath23 , but we will subsume this dependence in the notation .    for a euclidean vector @xmath24 , define the @xmath25 norm @xmath26 the matrix @xmath27 is the usual covariance matrix .",
    "the @xmath13th column of @xmath28 is denoted by @xmath29 .",
    "define the matrix @xmath30 matrix @xmath31 @xmath32 the @xmath33 matrix @xmath6 is called the correlation matrix . using the identity @xmath34 , we have @xmath35 since we are mainly interested in correlation matrices , without loss of generality ,",
    "henceforth we will assume that @xmath36 covariance matrices are ubiquitous in modern multivariate statistics where the advance of technology has led to a profusion of high - dimensional data sets .",
    "see  @xcite and the references therein for motivation and applications in a wide variety of fields .",
    "correlation matrices are sometimes preferred in certain statistical applications .",
    "for instance , the classic exploratory method principal component analysis ( pca ) is not invariant to change of scale in the matrix entries .",
    "therefore , it is often recommended first to standardize the matrix entries and then perform pca on the resulting correlation matrix  @xcite .",
    "recent progress in random matrix theory has led to a wealth of techniques for proving universality of various matrix ensembles ( see @xcite and the references therein ) . here",
    "the word universality refers to the phenomenon that the asymptotic distributions of various functionals of covariance / correlation matrices ( such as eigenvalues , eigenvector , etc . )",
    "are identical to those gaussian covariance / correlation matrices .",
    "thus , harnessing these methods to obtain universality results in statistical problems is an important step , since these results let us calculate the exact asymptotic distributions of various test statistics without having restrictive distributional assumptions of the matrix entries .",
    "for instance , an important consequence of universality is that in some cases one can perform various hypothesis tests under the assumption that the matrix entries are _ not _ normally distributed but use the same test statistic as in the gaussian case .    in this context , in a recent paper  @xcite we studied the asymptotic distribution of the eigenvalues of the covariance matrix @xmath27 under the assumptions of ( [ eqnxmat ] ) and  ( [ eqnxmatexpbd ] ) . in  @xcite",
    ", we proved that the stieltjes transform of the empirical eigenvalue distribution of the sample covariance matrix is given by the marcenko ",
    "pastur law @xcite uniformly up to the edges of the spectrum with an error of order @xmath37 , where @xmath38 is the imaginary part of the spectral parameter in the stieltjes transform .",
    "from this strong local marcenko  pastur law , we derived the following results : ( 1 )  rigidity of eigenvalues ( 2 ) delocalization of eigenvectors ( 3 ) universality of eigenvalues in the bulk and ( 4 ) universality of eigenvalues at the edges .",
    "furthermore , in our proof of edge universality of eigenvalues for covariance matrices ( see theorem  7.5 of  @xcite ) , we gave a sufficient criterion for checking whether two matrices of form @xmath39 ( @xmath40 is a data matrix ) have the same asymptotic eigenvalue distribution at the edge ( see section  [ secproofsketch ] for details ) . here",
    "@xmath41 could be quite general , including covariance and correlation matrices .",
    "verifying the above criteria for correlation matrices is much more complicated , owing to the fact that even if it has the same form @xmath6 as above , the matrix entries of @xmath42 are not independent .",
    "fortunately in  @xcite , as a byproduct , we also proved the strong marcenko ",
    "pastur law , the rigidity of eigenvalues and delocalization of eigenvectors of correlation matrices ( see lemma  [ lemstrmplawri ] in section  [ sec2 ] below or theorem 1.5 of  @xcite ) . in this paper , we complete the research program initiated in  @xcite by proving the edge universality of correlation matrices .",
    "there are not many papers which study the asymptotics of the correlation matrices as compared to the relatively large literature on covariance matrices .",
    "the asymptotic distribution of the largest ( appropriately rescaled ) eigenvalue of the gaussian correlation matrix was only very recently established by @xcite . as will be explained below",
    ", we also obtain this result as a special case of our main result and , more importantly , _",
    "we do not need this result in our proof _ ( see remark  [ remglaw ] ) .",
    "the almost sure convergence of the largest and smallest eigenvalues of the correlation matrix was established in  @xcite .",
    "the very recent paper @xcite , relying on our results in  @xcite , shows that the asymptotic distribution of the largest or smallest eigenvalue of the correlation matrix is given by the tracy  widom law , under the assumption that the data matrix @xmath7 satisfies  ( [ eqnxmat ] ) and its entries have _ symmetric _ distributions .",
    "in particular , the authors in  @xcite use the above mentioned sufficiency criteria for edge universality developed in  @xcite .",
    "furthermore , the assumption that the matrix entries are symmetric is very restrictive and not natural in statistical applications . in this paper",
    "we will build on our previous work  @xcite and prove edge universality of correlation matrices just under the assumptions  ( [ eqnxmat ] ) and ( [ eqnxmatexpbd ] ) .",
    "furthermore , we believe that all of our main results should hold if one replaces the subexponential tail decay of the matrix entries by a uniform bound on the @xmath43th moment @xmath44 of the matrix entries ( e.g. , @xmath45 will suffice ) , as proved in  @xcite for wigner matrices .",
    "the central ideas in this paper are based on the general machinery for proving universality established in a series of recent papers @xcite , where the authors yau , erds et al .",
    "study the distribution of eigenvalues and eigenvectors by studying the green s functions ( resolvent ) of the random matrices .",
    "the proof of this paper is based on the comparison of green s functions first initiated in  @xcite , but , as mentioned earlier , the key obstacle to be surmounted is the strong dependence of the entries of the correlation matrix .",
    "we achieve this via a novel argument which involves comparing the moments of the product of the entries of the standardized data matrix to those of the raw data matrix ( see section  [ secproofsketch ] for a summary of the key ideas ) .",
    "our proof strategy may be extended for proving the edge universality of other random matrix ensembles with dependent entries and hence is of independent interest .",
    "furthermore , it will be interesting to see if bulk universality of correlation matrices can be established using the methods developed in this paper .",
    "let us state the main result now .",
    "we denote @xmath46 , @xmath47 , as the eigenvalues of @xmath48 and @xmath49 for @xmath50 .",
    "we order them as @xmath51 analogously , let @xmath52 denote the eigenvalues values of the matrix @xmath53 .",
    "the following is the main result of this paper .",
    "it shows that the largest and smallest @xmath9 eigenvalues of the correlation matrix , after appropriate centering and rescaling , converge in distribution to those of the corresponding covariance matrix .",
    "[ thmmain ] let @xmath7 and @xmath28 , respectively , denote the correlation and covariance matrix as defined in  ( [ eqnxmat])([defxnc ] ) .",
    "for any fixed @xmath54 , there exists @xmath55 and @xmath56 such that for any @xmath57 ( which may depend on  @xmath58 ) , there exists @xmath59 independent of @xmath60 such that for all @xmath61 , we have @xmath62\\\\[-8pt ] & & \\qquad \\leq{\\mathbb{p}}\\bigl ( n^{2/3 } ( \\widetilde\\lambda_1 - \\lambda_+ ) \\leq s_1 + n^{-{\\varepsilon } } , \\ldots , n^{2/3 } ( \\widetilde\\lambda_k - \\lambda_+ ) \\leq s_{k } + n^{-{\\varepsilon } } \\bigr)\\nonumber\\hspace*{-30pt}\\\\ & & \\qquad\\quad{}+ n^{-\\delta}. \\nonumber\\hspace*{-30pt}\\end{aligned}\\ ] ] an analogous result holds for the @xmath9 smallest eigenvalues .    in  @xcite and  @xcite , peche , soshnikov and sodin proved that for some covariance matrices ( including the wishart matrix ) , the largest and smallest @xmath9 eigenvalues after appropriate centering and rescaling converge in distribution to the tracy  widom law whose density is a smooth function . combining with our recent result on the universality of covariance matrices in @xcite",
    ", we have the following immediate corollary for theorem [ thmmain ] :    let @xmath7 denote the correlation matrix as defined in  ( [ eqnxmat])([defxnc ] ) .",
    "for any fixed @xmath63 , we have @xmath64 where @xmath65 denotes the tracy  widom distribution .",
    "an analogous statement holds for the @xmath9-smallest ( nontrivial ) eigenvalues .",
    "[ remglaw ] thus , as a special case , we also obtain the tw law for the gaussian correlation matrices .",
    "although the current paper builds on our recent work  @xcite , it is mostly self - contained and for the reader s convenience , we will recall all of the needed results from  @xcite .",
    "the rest of the paper is organized as follows . in section  [ secprelim ] , after establishing some notation , we give the key results establishing the strong marcenko  pastur law and rigidity of eigenvalues for correlation matrices , as obtained from  @xcite . in section  [ secproofsketch ]",
    "we give a brief proof sketch illustrating the key ideas . in section  [ secpromainre ]",
    "we give the proof of the main results and in section  [ secmomcomp ] we prove some technical lemmas which constitute the key ingredients in the proof of the main result .",
    "for the rest of the paper the letter @xmath66 will denote a generic constant whose value might change from one line to the next , but will be independent of everything else . the notation @xmath67 will be used to denote @xmath68 .",
    "[ secprelim ] we will adopt the notation used in this paper from  @xcite . define the green function of @xmath6 by @xmath69 the stieltjes transform of the empirical eigenvalue distribution of @xmath70 is given by @xmath71 recall that @xmath72 from  ( [ eqnd ] ) and define @xmath73 the marcenko  pastur ( henceforth abbreviated by mp ) law is given by @xmath74_+}{x^2}}.\\ ] ] we define @xmath75 , @xmath76 , as the stieltjes transform of @xmath77 , that is , @xmath78 the function @xmath79 depends on @xmath80 and has the closed form solution @xmath81 where @xmath82 denotes the square root on a complex plane whose branch cut is the negative real line .",
    "we also define the classical location of the eigenvalues with @xmath83 as follows : @xmath84 define the parameter @xmath85    [ defhp ] let @xmath86 .",
    "we say that an event @xmath87 holds with _ @xmath88-high probability _ if there exists a constant @xmath89 such that @xmath90 for large enough @xmath58 .",
    "let us first give the following large deviation lemma for independent random variables ( see  @xcite , appendix b for a proof ) .",
    "[ lemlargdev ] suppose , for @xmath91 , @xmath92 are independent , mean @xmath93 complex variables , with @xmath94 and have a subexponential decay as in ( [ eqnxmatexpbd ] ) .",
    "then there exists a constant @xmath95 such that , for any @xmath86 and for any @xmath96 and @xmath97 , the bounds latexmath:[\\ ] ] obtaining  ( [ x11 ] ) , and the proof is finished .",
    "the authors would like to thank jiefeng jiang , two anonymous referees , the associate editor and the editor for very useful comments ."
  ],
  "abstract_text": [
    "<S> let @xmath0 be a rectangular data matrix with independent real - valued entries @xmath1 $ ] satisfying @xmath2 and @xmath3 , @xmath4 . </S>",
    "<S> these entries have a subexponential decay at the tails . </S>",
    "<S> we will be working in the regime @xmath5 . in this paper </S>",
    "<S> we prove the edge universality of correlation matrices @xmath6 , where the rectangular matrix @xmath7 ( called the standardized matrix ) is obtained by normalizing each column of the data matrix @xmath8 by its euclidean norm . </S>",
    "<S> our main result states that asymptotically the @xmath9-point ( @xmath10 ) correlation functions of the extreme eigenvalues ( at both edges of the spectrum ) of the correlation matrix @xmath6 converge to those of the gaussian correlation matrix , that is , tracy  widom law , and , thus , in particular , the largest and the smallest eigenvalues of @xmath6 after appropriate centering and rescaling converge to the tracy  widom distribution . the asymptotic distribution of extreme eigenvalues of the gaussian correlation matrix has been worked out only recently . as a corollary of the main result in this paper </S>",
    "<S> , we also obtain that the extreme eigenvalues of gaussian correlation matrices are asymptotically distributed according to the tracy  widom law . the proof is based on the comparison of green functions , but the key obstacle to be surmounted is the strong dependence of the entries of the correlation matrix . </S>",
    "<S> we achieve this via a  novel argument which involves comparing the moments of product of the entries of the standardized data matrix to those of the raw data matrix . </S>",
    "<S> our proof strategy may be extended for proving the edge universality of other random matrix ensembles with dependent entries and hence is of independent interest . </S>"
  ]
}