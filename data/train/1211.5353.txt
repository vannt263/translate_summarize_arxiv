{
  "article_text": [
    "finding the @xmath0 most documents relevant to a query is at the heart of search engines and information retrieval @xcite .",
    "a simple relevance measure is the number of occurrences of the query in the documents ( _ term frequency _ ) .",
    "typically the data structure employed to solve those `` top-@xmath0 '' queries is the _",
    "inverted index_. inverted indexes work well , but they are limited to scenarios where the queryable terms are predefined and not too many ( typically `` words '' in western languages ) , while they can not search for arbitrary patterns ( i.e. , substrings in the sequences of symbols ) .",
    "this complicates the use of inverted indexes for oriental languages such as chinese , japanese and korean , for agglutinating languages such as finnish and german , and in other types of collections containing dna and protein sequences , source code , midi streams , and other symbolic sequences .",
    "top-@xmath0 document retrieval is of interest on those more general sequence collections @xcite , yet the problem of finding top-@xmath0 documents containing the pattern as a substring , even with a simple measure like term frequency , is much more challenging .    the general problem can be defined as follows : preprocess a collection of @xmath8 documents containing sequences of total length @xmath4 over an alphabet of size @xmath9 , so that later , given a query string @xmath10 of length @xmath2 , one retrieves @xmath0 documents with highest relevance to @xmath10 , for some definition of relevance .",
    "hon et al .",
    "@xcite presented the first efficient solution for this problem , achieving @xmath11 time , yet with super - linear space usage , @xmath12 bits .",
    "then hon et al .",
    "@xcite improved the solution to @xmath13 time and linear space , @xmath14 bits . recently ,",
    "navarro and nekrich @xcite achieved optimal @xmath1 time , using @xmath15 bits .",
    "although the latter solution essentially closes the problem in theoretical terms , the constants involved are not small , especially in space : their index can use up to @xmath3 bytes , making it unfeasible for real scenarios .",
    "there has been some work aiming to reduce the space of top-@xmath0 indexes @xcite , yet they come at the cost of search times of at least @xmath16 for any constant @xmath17 , while reaching as low as @xmath18 bits of space ( all our logarithms are in base 2 ) . in practice ,",
    "the best ones @xcite require @xmath19 to @xmath20 bytes and answer top-10 queries in about a millisecond .",
    "their main idea is _ suffix tree sampling _ , that is , store the top-@xmath0 answers for large enough suffix tree nodes .",
    "hon et al .",
    "@xcite have proposed an intermediate alternative , which is basically an engineered implementation of their classical scheme @xcite .",
    "they use @xmath21 bits and @xmath22 time , or @xmath23 bits and @xmath24 time .",
    "this solution has not been yet implemented , however .",
    "we estimate their space would be at least @xmath20 to @xmath25 in practice .    in this work we design and implement a fast and compact solution for top-@xmath0 document retrieval , building on the ideas of navarro and nekrich @xcite . apart from replacing classical by compact data structures",
    ", we use a novel idea of _ frequency thresholding _ instead of sampling suffix tree nodes : we store all the solutions for all the suffix tree nodes , but discard those with frequency 1 .",
    "we obtain time @xmath26 and space @xmath27 bits for typical texts . by `` typical '' we mean that our results hold almost surely ( a.s",
    ". tends to a value @xmath28 almost surely if , for every @xmath17 , the probability that @xmath29 for some @xmath30 tends to zero as @xmath4 tends to infinity , @xmath31 . ] , a very strong kind of convergence ) for texts sampled from a stationary mixing ergodic source ( more precisely , type a2 in szpankowski s sense @xcite ) .",
    "this is also a quite general assumption including bernoulli and markovian models .",
    "in addition , we have implemented our index , showing its practicality .",
    "it turns out to require about @xmath5@xmath6 bytes , that is , 2550 times less than a naive implementation of the basic idea @xcite and at most 5% more space than the most compressed practical solutions @xcite ( while in some cases our index uses half the space ) .",
    "its time per query is @xmath0@xmath32 microseconds , outperforming the more compressed solutions by up to 25 times .",
    "this is the first top-@xmath0 index for general texts that achieves little space and microseconds - time .",
    "moreover , it shows that our idea of thresholding frequencies generally gives better results than the previous trend of sampling suffix tree nodes .",
    "consider a collection of string documents @xmath33 as the concatenation @xmath34 = d_1,d_2 \\dots$ ] @xmath35 , @xmath36 , where at the end of each @xmath33 a special symbol $ is used to mark the end of that document .",
    "a _ suffix array _",
    "@xcite @xmath37 $ ] contains pointers to every suffix of @xmath38 , lexicographically sorted . for a position @xmath39 $ ] ,",
    "@xmath40 $ ] points to the suffix @xmath41,n ] = t_{sa[i]}t_{sa[i]+1}\\dots t_n$ ] , where it holds @xmath41,n ] < t[sa[i+1],n]$ ] .",
    "the @xmath42 occurrences of a pattern @xmath43 $ ] in @xmath38 are pointed from a range @xmath44 $ ] , that can be found and listed in time @xmath45 .    the _ suffix tree _",
    "@xcite of @xmath38 is a path - compressed trie ( i.e. , unary paths are collapsed ) in which all the suffixes of @xmath38 are inserted .",
    "internal nodes correspond to repeated strings of @xmath38 and the leaves correspond to suffixes . for internal nodes",
    "@xmath46 , @xmath47 is the concatenation of the edge labels from the root to @xmath46 .",
    "the suffix tree finds the occurrences of @xmath10 in @xmath38 in time @xmath48 , by traversing it from the root to the _ locus _ of @xmath10 , i.e. , the highest node @xmath46 such that @xmath10 is a prefix of @xmath47 .",
    "then all the occurrences of @xmath10 correspond to the leaves of the subtree rooted at @xmath46 .",
    "these leaves correspond to the range @xmath44 $ ] , indeed , @xmath46 is the lowest common ancestor of the @xmath49th and the @xmath50th leaves .",
    "the suffix tree has @xmath51 nodes .",
    "_ compressed suffix arrays ( csas ) _",
    "@xcite can represent the text _ and _ its suffix array within essentially @xmath52 bits .",
    "here @xmath53 is the empirical @xmath0th order entropy of @xmath38 @xcite , a lower bound to the bits per symbol emitted by a statistical compressor of order @xmath0 .",
    "this representation allows us to _ count _ ( determine the interval @xmath54 $ ] corresponding to a pattern @xmath10 ) , _ access _ ( compute @xmath40 $ ] for any @xmath55 ) , and _ extract _ ( rebuild any @xmath56 $ ] ) .",
    "we use one @xcite that can count in time @xmath57 , access in time @xmath58 and extract in time @xmath59 while using @xmath60 bits for any @xmath61 and any constant @xmath62 .",
    "the @xmath63 bits correspond to storing one @xmath40 $ ] value every @xmath64 text positions .",
    "_ general trees _ of @xmath4 nodes can be represented using @xmath65 bits . in this paper",
    "we use a representation @xcite that supports in @xmath66 time a number of operations , including @xmath67 ( the preorder of node @xmath46 ) , @xmath68 ( the @xmath55th node in preorder ) , @xmath69 ( depth of node @xmath46 ) , @xmath70 ( number of nodes in subtree rooted at @xmath46 ) , @xmath71 ( lowest common ancestor of nodes @xmath72 and @xmath46 ) , and many others .",
    "this structure is practical and implemented @xcite , using @xmath73 bits .",
    "_ bitmaps _ @xmath74 $ ] can be represented using @xmath75 bits , so that we can solve in constant time operations @xmath76 ( number of occurrences of bit @xmath77 in @xmath78 $ ] ) and @xmath79 ( position in @xmath80 of the @xmath81th occurrence of bit @xmath77 ) @xcite .",
    "we use an implementation @xcite that requires @xmath82 bits , yet for very sparse bitmaps ( with @xmath83 bits set ) we prefer a compressed one using @xmath84 bits @xcite .    _",
    "range maximum queries ( rmqs ) _",
    "ask for the position of the maximum element in a range of an array , @xmath85 $ ] .",
    "they can be solved in constant time after preprocessing @xmath86 and storing a structure using @xmath65 bits .",
    "no accesses to @xmath86 are needed at query time @xcite .",
    "the solution requires @xmath87 queries on a tree called a `` 2d - min - heap '' , and we implement it over our compact trees @xcite .    _ direct access codes _ @xcite",
    "represent a sequence of variable - length numbers by packing them into chunks of length @xmath77 .",
    "then the chunks are rearranged to allow one accessing any @xmath88-bit number in the sequence in time @xmath89 .",
    "the space overhead for a number of @xmath88 bits is @xmath90 .",
    "we use their implementation , which chooses optimally the @xmath77 values .    _ wavelet trees _",
    "@xcite can be used to represent an @xmath91 grid that contains @xmath4 points , one per column @xcite .",
    "the root represents the sequence of coordinates @xmath92 of the points in @xmath93-coordinate order .",
    "it only stores a bitmap @xmath74 $ ] telling at @xmath94 $ ] whether @xmath95 or not .",
    "then the points with @xmath95 are represented , recursively , on the left child of the root , and the others on the right .",
    "adding @xmath96 capabilities to the bitmaps , the wavelet tree requires overall @xmath97 bits and can track any point towards its leaf ( where the @xmath92 value is revealed ) in time @xmath98 .",
    "it can also count , in @xmath98 time , the number of points lying inside a rectangle @xmath99 \\times [ y_1,y_2]$ ] : start at the root with the interval @xmath99 $ ] and project those values towards the left and right child ( on the left child the interval is @xmath100 $ ] , and similarly with @xmath101 on the right ) .",
    "this is continued until reaching the @xmath98 wavelet tree nodes that cover @xmath102 $ ] .",
    "then the answer is the sum of the lengths of the mapped intervals @xmath103 $ ] .",
    "one can also track those points toward the leaves and report them , each in time @xmath98 .",
    "we use a simple balanced wavelet tree without pointers @xcite .    _",
    "muthukrishnan s algorithm _",
    "@xcite for listing the distinct elements in a given interval @xmath104 $ ] of an array @xmath105 $ ] uses another array @xmath106 $ ] where @xmath107 = \\max \\ { j < i,~ a[j]=a[i]\\ } \\cup \\{-1\\}$ ] , which is preprocessed for range minimum queries .",
    "each value @xmath108<i$ ] for @xmath109 is a distinct value @xmath110 $ ] in @xmath104 $ ] .",
    "a range minimum query in @xmath111 $ ] gives one such value @xmath2 , and then we continue recursively on @xmath112 $ ] and @xmath113 $ ] until the minimum is @xmath114 .",
    "one retrieves any @xmath0 unique elements in time @xmath115 .",
    "our implementation is based on the framework proposed by hon , shah and vitter @xcite and then followed by navarro and nekrich @xcite : let @xmath116 be the suffix tree for the concatenation @xmath38 of a collection of documents @xmath117 .",
    "this tree contains the nodes corresponding to all the suffix trees @xmath118 of the documents @xmath33 : for each node @xmath119 , there is a node @xmath120 such that @xmath121 .",
    "we will say that @xmath122 . also , let @xmath123 be the parent of a node @xmath72 and @xmath124 be its depth .",
    "they store @xmath116 plus additional information on the trees @xmath118 . if @xmath122 , then they store @xmath55 in a list called _ f - list _ associated to @xmath46 .",
    "further , for each @xmath122 they store a pointer @xmath125 , noting where the parent of @xmath72 maps in @xmath116 .",
    "we add a dummy root @xmath126 to @xmath116 so that @xmath127 if @xmath72 is the root of @xmath118 .",
    "together with the pointers @xmath128 they also store a weight @xmath129 , which is the relevance of @xmath130 in @xmath33",
    ". this relevance can be any function that depends on the set of starting positions of @xmath130 in @xmath33 .",
    "in this paper we focus on a simple one : the number of leaves of @xmath72 in @xmath118 , that is , the _ term frequency_.    let @xmath46 be the locus of @xmath10 .",
    "hon et al .",
    "@xcite prove that , for each distinct document @xmath33 where @xmath10 appears , there is exactly one pointer @xmath131 going from a descendant @xmath132 of @xmath46 ( @xmath46 itself included ) to a ( strict ) ancestor @xmath133 of @xmath46 , and @xmath134 is the relevance of @xmath10 in @xmath33 .",
    "therefore , they find the @xmath0 largest @xmath135 values in this set .",
    "navarro and nekrich @xcite represent this structure as a grid of size @xmath136 with labeled weighted points , as follows .",
    "they traverse @xmath116 in preorder .",
    "for each node @xmath137 , and for each pointer @xmath138 , they add a new rightmost @xmath93-coordinate with only one point , with @xmath139-coordinate equal to @xmath140 , weight equal to @xmath129 , and label equal to @xmath55 . at query time , they find the locus @xmath46 of @xmath10 , determine the range @xmath99 $ ] of all the @xmath93-coordinates filled by @xmath46 or its descendants , find the @xmath0 highest - weighted points in @xmath99 \\times [ 0,depth(v)-1]$ ] , and report their labels . a linear - space representation ( yet with a large constant ) allows them to carry out this task in time @xmath1 .",
    "we describe our compressed data structures we use and how we carry out the search .    [ [ suffix - tree . ] ] suffix tree .",
    "+ + + + + + + + + + + +    we use a csa @xcite requiring @xmath141 bits , which computes @xmath54 $ ] corresponding to @xmath10 in time @xmath57 .",
    "it also computes any @xmath40 $ ] in time @xmath142 .",
    "for this sake we use a sampling every @xmath143 positions . in the samples we store not the exact position in @xmath38 but just the document where it lies .",
    "hence we need @xmath144 bits for the sampling .    in practice",
    ", we use an off - the - shelf csa ( ssa from _ pizzachili _ site , http:// pizzachili.dcc.uchile.cl ) , and add a sparse bitmap @xmath145 $ ] marking where documents start in @xmath38 : the document corresponding to @xmath40 $ ] is @xmath146)$ ] , computed in time @xmath142 .",
    "while this is worse than having the csa directly return documents , it retains our csa other pattern matching functionalities .",
    "we also add @xmath65 bits to describe the topology of the suffix tree , using a tree representation that carries out most of the operations in constant time @xcite .",
    "note this is just the topology , not a full suffix tree , so we need to search using the csa .",
    "we also add @xmath65 bits for an rmq structure on top of muthukrishnan s array @xmath147 @xcite , which can list @xmath0 distinct documents in any interval @xmath44 $ ] in time @xmath115 .",
    "[ [ mapping - to - the - grid . ] ] mapping to the grid .",
    "+ + + + + + + + + + + + + + + + + + + +    the grid is of width @xmath148 , as we add one coordinate per node in the suffix tree of each document . to save space",
    ", we will consider a _",
    "virtual _ grid just as defined , but will store a narrower _ physical _ grid . in the physical grid , the entries corresponding to leaves of @xmath116 ( which contain exactly one pointer @xmath128 ) will not be represented .",
    "thus the physical grid is of width at most @xmath4 .",
    "this _ frequency thresholding _ is a key idea , as it halves the space of most structures in our index .",
    "two bitmaps will be used to map between the suffix array , the suffix tree , and the virtual and physical grids : @xmath149 $ ] and @xmath150 $ ] .",
    "bitmap @xmath80 will mark starting positions of nodes of @xmath116 in the physical grid : each time we arrive at an internal node @xmath46 we add a 1 to @xmath80 , and each time we add a new @xmath93-coordinate to the grid ( due to a pointer @xmath128 ) we add a 0 to @xmath80 .",
    "bitmap @xmath151 will mark leaves in the preorder traversal of @xmath116 , using a 1 for leaves and a 0 for internal nodes .",
    "[ [ representing - the - grid . ] ] representing the grid .",
    "+ + + + + + + + + + + + + + + + + + + + + +    in the grid there is exactly one point per @xmath93-coordinate .",
    "we represent with a wavelet tree @xcite the sequence of corresponding @xmath139-coordinates .",
    "note that the height of this grid is @xmath152 for some constant @xmath153 a.s .",
    "1(ii ) and remark 2(iv ) ) .",
    "thus , the height of the wavelet tree is @xmath154 and the wavelet tree requires @xmath155 bits in total , a.s .",
    "( from now on we will omit , except in the theorems , that our results hold almost surely and not in the worst case ) .",
    "each node @xmath46 of the wavelet tree represents a subsequence of the original sequence of @xmath139-coordinates .",
    "we consider the ( virtual ) sequence of the weights associated to the points represented by @xmath46 , @xmath156 , and build an rmq data structure @xcite for @xmath156 .",
    "this structure requires @xmath157 .",
    "this adds up to @xmath158 for the whole wavelet tree .",
    "[ [ representing - labels - and - weights . ] ] representing labels and weights .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the labels of the points , that is , the document identifiers , are represented directly as a sequence of at most @xmath159 bits , aligned to the bottom of the wavelet tree .",
    "given any point to report , we descend to the leaf in @xmath142 time and retrieve the document identifier .",
    "the weights are stored similarly , but using direct access codes @xcite to take advantage of the fact that most weights ( term frequencies ) are small .",
    "note that the subtree size of each @xmath118 internal node will be stored exactly once as the weight of some @xmath128 .",
    "we analyze now that the number of bits required to store those numbers .",
    "let @xmath160 .",
    "since the height of any @xmath118 is @xmath161 , so is the depth of any node .",
    "the sum of the depths of all the nodes is then @xmath162 , and this is also the sum of all the subtree sizes . distributing those sizes over the @xmath163 nodes uniformly ( which gives a pretty pessimistic worst case for the sum of the logarithms ) gives @xmath161 for each .",
    "thus the number of bits required to represent the sizes is at most @xmath164 . using direct access codes with block size @xmath165 poses an extra overhead of @xmath166 bits .",
    "hence all the weights can be stored in @xmath155 bits and accessed in time @xmath167 . , which we can prove only for uniformly distributed texts . ]",
    "[ [ answering - queries . ] ] answering queries .",
    "+ + + + + + + + + + + + + + + + + +    the first step to answer a query is to use the csa to determine the range @xmath54 $ ] in time @xmath57 . to find the locus @xmath46 of @xmath10 in the topology of the suffix tree , we compute @xmath168 and @xmath169 , the @xmath49th and @xmath50th leaves of the tree , respectively , using @xmath170 and @xmath171 , and then we have @xmath172 .",
    "all those operations take @xmath66 time .    to determine the horizontal extent @xmath99 $ ] of the grid that corresponds to the locus node @xmath46 , we first compute @xmath173 and @xmath174 .",
    "this gives the preorder range @xmath175 including leaves .",
    "now @xmath176 and @xmath177 gives the number of leaves up to those preorders .",
    "then , since we have omitted the leaves in the physical grid , we have @xmath178 and @xmath179 .",
    "the limits in the @xmath139 axis are just @xmath180 $ ] .",
    "thus the grid area to query is determined in constant time .",
    "once the range @xmath99 \\times [ y_1,y_2]$ ] to query is determined , we proceed to the grid .",
    "we determine the wavelet tree nodes that cover the interval @xmath102 $ ] , and map the interval @xmath99 $ ] to all of them .",
    "as there are at most two such nodes per level , there are @xmath142 nodes covering the interval , and they are found in @xmath142 time .",
    "we now use a top-@xmath0 algorithm for wavelet trees @xcite .",
    "let @xmath181 the wavelet tree nodes that cover @xmath102 $ ] and let @xmath103 $ ] be the interval @xmath99 $ ] mapped to @xmath182 .",
    "for each of them we compute @xmath183 to find the position @xmath184 with the largest weight among the points in @xmath182 , and find out that weight and the corresponding document , @xmath185 and @xmath186 .",
    "we set up a max - priority queue that will hold at most @xmath0 elements ( elements smaller than the @xmath0th are discarded by the queue ) .",
    "we initially insert the @xmath142 tuples @xmath187 , being @xmath185 the sort key .",
    "now we iteratively extract the tuple with the largest weight , say @xmath188 .",
    "we report the document @xmath189 with weight @xmath190 , and create two new ranges in @xmath191 : @xmath192 $ ] and @xmath193 $ ] .",
    "we compute their rmq , find the corresponding documents and weights , and reinsert them in the queue .",
    "after @xmath0 steps , we have reported the top-@xmath0 documents .    using a y - fast trie @xcite for the priority queue , the total time is @xmath142 to find the cover nodes , @xmath194 to determine their tuples and insert them in the queue , and @xmath195 to extract the minima , compute and reinsert new tuples .",
    "we remind that we have not stored the leaves in the grid . therefore , if the procedure above yields less than @xmath0 results , we must complete it with documents where the pattern appears only once .",
    "we use muthukrishnan s algorithm @xcite with the rmq structure on the @xmath147 array .",
    "we extract distinct documents until we obtain @xmath0 distinct documents in total , counting those already reported with the grid .",
    "this requires at most @xmath196 steps , as we can revisit the documents reported with the grid .",
    "each step requires @xmath142 time to compute the document identifier .",
    "given @xmath8 documents concatenated into a text @xmath34 $ ] , we can build an index requiring almost surely @xmath197 bits , which can report the top-@xmath0 documents most relevant to a search pattern @xmath43 $ ] in time @xmath198 almost surely .",
    "our structure can be built in time @xmath199 ( details omitted ) .",
    "we compared our solution to the implementation of navarro and valenzuela @xcite , which is the current state of the art .",
    "we use various compact data structures implementations from _ libcds _ ( http://libcds.recoded.cl ) .",
    "we used the following collections in our experiments .",
    "their grid heights are between 5 and 9 .    * * _ dna . _ * a sequence of 10,000 highly repetitive ( @xmath200 difference between documents ) synthetic dna sequences with 100,030,004 bases in total . * * _ kgs . _ * a collection of 18,383 sgf - formatted go game records from year 2009 ( http://www.u-go.net/gamerecords ) , containing 26,351,161 chars . * * _ proteins . _ * a collection of 143,244 sequences of human and mouse proteins ( http://www.ebi.ac.uk/swissprot ) , containing 59,103,058 symbols .",
    "* * _ ft91 - 94 .",
    "_ * a sample of 40,000 documents from trec corpus ft91 to 94 ( http://trec.nist.gov ) containing 93,498,090 characters .",
    "* * _ wikipedia .",
    "_ * a sample of 40,000 documents from the english wikipedia containing 83,647,329 characters .",
    "the experiments were performed in an intel(r ) xeon(r ) model e5620 running at 2.40 ghz with 96 gb of ram and 12,288 kb cache .",
    "the operating system is linux with kernel 2.6.31 - 41 64 bits and we used the gnu c compiler version 4.4.3 with -o3 optimization parameter . for queries , we selected 4,000 random substrings of length 3 and 8 , and obtained the top-@xmath0 documents for each , for @xmath201 every 10 values .",
    "table  [ tab : comp ] compares our solution with previous work @xcite on the three collections shared , taking their best compressed ( from their variant _ wt - alpha+ssgst _ plus more recent improvements ) and uncompressed ( from their variant _ wt - plain+ssgst _ ) results .",
    "our structure is at most only 5% larger . when both use about the same space , our structure is 4 to 25 times faster . in other cases",
    "our structure can use up to half the space , and it is still faster , up to 3 times ( for large @xmath0 and @xmath2 we must resort to much document listing , where their wavelet tree on documents is faster ) .",
    "needless to say , this is a remarkable result for a structure that , in theory @xcite , used about 80 times the collection size .",
    "we have sharply compressed it while retaining the best ideas that led to its optimal time .",
    "we believe this establishes a new direction in which research on space - efficient top-@xmath0 retrieval could be focused : rather than sampling the suffix tree nodes @xcite , threshold the document _ frequencies _ we store ( curiously , this is closer in spirit to the first , superlinear - size , proposed top-@xmath0 solution @xcite ) .",
    "for example , can we discard all the frequencies below a threshold @xmath202 and efficiently list them if needed ?",
    "our work shows this is possible at least for @xmath203 .",
    "our approach easily extends to relevance functions other than term frequency . in most cases it is sufficient to store the appropriate weights in our data structure .",
    "even if these are not compressible , the space should not grow up too much .",
    "our structure also trivially solves other document listing problems , like @xmath0-mining ( list the documents where @xmath10 appears at least @xmath0 times ) .",
    "muthukrishnan @xcite solves it in optimal time @xmath48 and @xmath14 bits for @xmath0 fixed at indexing time . for variable @xmath0",
    "the space is @xmath204 .",
    "our compressed structure , without modifications , solves both variants in time @xmath205 ."
  ],
  "abstract_text": [
    "<S> _ * abstract : * _ an optimal index solving top-@xmath0 document retrieval [ navarro and nekrich , _ soda12 _ ] takes @xmath1 time for a pattern of length @xmath2 , but its space is at least @xmath3 bytes for a collection of @xmath4 symbols . </S>",
    "<S> we reduce it to @xmath5@xmath6 bytes , with @xmath7 time , on typical texts . </S>",
    "<S> the index is up to 25 times faster than the best previous compressed solutions , and requires at most 5% more space in practice ( and in some cases as little as one half ) . </S>",
    "<S> apart from replacing classical by compressed data structures , our main idea is to replace _ suffix tree sampling _ by _ frequency thresholding _ to achieve compression .     </S>",
    "<S> +   + _ department of computer science , university of chile + _ </S>"
  ]
}