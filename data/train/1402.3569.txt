{
  "article_text": [
    "there has been renewed interest in directional bayesian analysis in view of its fundamental applications to molecular biology @xcite . due to chemical constraints on the bonds of biomolecules , the geometry of these molecules can be described by a set of angles .",
    "other applications include locating and tracking an electric signal @xcite and the analysis of forensic fingerprint evidence @xcite .",
    "all these applications involve circular data which is naturally modelled by the von mises distribution .",
    "the probability density function of the von mises distribution with mean @xmath0 on the unit circle and concentration parameter @xmath1 is given by @xcite @xmath2 where @xmath3 is the modified bessel function of the first kind and order @xmath4 .",
    "the circular variance can be described by @xmath5 where @xmath6 .",
    "let @xmath7 be a vector of observations from a von mises distribution .",
    "when a conjugate prior is used , the posterior distribution of the mean @xmath8 is itself von mises , and can be easily sampled via @xcite .",
    "let @xmath9 be the conjugate prior for the concentration .",
    "the posterior is @xmath10 where @xmath11 and @xmath12 are observed constants ; in this case @xmath13 and @xmath14 . for the case @xmath15 and @xmath16 the normalization constant is @xmath17 , however in general the normalization constant is intractable @xcite . in this paper we shall call the _ bessel exponential distribution_.    existing algorithms to sample tend to generate from approximate distributions @xcite or have a large overhead of sampled auxiliary variables @xcite .",
    "we present a new , extremely fast algorithm to sample from the bessel exponential distribution .    for large @xmath18 ,",
    "@xmath19 is approximately @xmath20 ( * ? ? ?",
    "9.7.1 ) . plugging this approximation into yields a gamma density with shape @xmath21 and rate @xmath22 .",
    "this insight motivates us to use a gamma - based acceptance - rejection sampler for @xmath18 .",
    "however , the above approximation for @xmath19 breaks down for small @xmath18 , and thus great care is needed to ensure our rejection sampler is efficient for all values of @xmath18 .",
    "we derive the optimal gamma - based proposal distribution and show that the resulting sampler has an acceptance probability of at least 0.7 for all @xmath23 and @xmath24 .",
    "the minimum acceptance probability of @xmath25 occurs when the distribution is concentrated around @xmath26 .",
    "the algorithm is described in section  [ sect : alg ] and derived in section  [ sect : derivation ] .",
    "enhancements are considered in section  [ sect : speedup ] and the algorithm s efficiency is explored in section  [ sect : efficiency ] .",
    "as discussed above , we can approximate the bessel exponential distribution with a gamma distribution .",
    "however , because the ratio of these densities diverges as @xmath27 , we can not directly use a gamma proposal for our rejection sampler .",
    "instead we propose values @xmath28 where @xmath29 and @xmath30 has a gamma distribution .",
    "this is an application of marsaglia s exact approximation procedure , see @xcite for more details .    using a shifted gamma proposal with shape @xmath31 and",
    "scale @xmath32 leads to the envelope function @xmath33 for @xmath34 , where the amplitude @xmath35 is chosen to ensure the ratio @xmath36 is bounded below one .",
    "we can generate a sample from the bessel exponential distribution by generating a sample @xmath18 from @xmath37 and accepting it with probability @xmath38 where @xmath39 and @xmath40 .",
    "the samples generated via this procedure have the correct bessel exponential distribution for any choice of the proposal parameters @xmath41 , though the values of these parameters will affect the algorithm s efficiency .",
    "in section  [ sect : derivation ] we show that the approximate optimal choices for the proposal parameters are @xmath42 where the terms @xmath43 and @xmath44 are @xmath45 and @xmath46 is the principal branch of the lambert w function defined as @xmath47 for @xmath48 .    the acceptance - rejection algorithm to generate a sample from the bessel exponential distribution proceeds as follows :    1 .",
    "find efficient proposal parameters @xmath41 , which will depend on @xmath49 .",
    "2 .   draw @xmath30 from a gamma distribution with shape @xmath50 and rate @xmath51 .",
    "3 .   draw @xmath52 from a uniform distribution on @xmath53 $ ] .",
    "4 .   accept @xmath28 if @xmath54 , else go to 2 .",
    "the detailed procedure is described in algorithm  [ alg : kappa ] . when implementing the algorithm , both the bessel functions and the lambert w function",
    "can be computed using software such as the general scientific library @xcite or its r wrapper , the cran package * gsl*. in practice it is often possible to avoid computing these functions , as we show in section  [ sect : speedup ] .",
    "@xmath55 [ algline : startsetup ] @xmath56 @xmath57 @xmath58[algline : kappastar ]",
    "@xmath59 @xmath60 @xmath61 @xmath62 @xmath63 [ algline : betadefn ] @xmath64 @xmath65[algline : lambert ] @xmath66 @xmath67 [ algline : endsetup ] [ algline : startloop ] @xmath68 sample from a @xmath69 left - truncated at @xmath70 [ algline : xsampling ] @xmath71 @xmath72 sample from a @xmath73 [ algline : acceptreject ] + [ algline : returnline ]",
    "we will now derive the optimal parameters @xmath41 for the proposal distribution of @xmath74 which follows a gamma distribution with shape @xmath50 and rate @xmath51 .",
    "we do so by maximizing the expected probability of acceptance @xmath75\\nonumber \\\\&=\\frac{(\\eta \\beta)^{\\eta \\alpha+1}}{\\gamma(\\eta \\alpha+1)}\\exp\\{-\\eta \\beta\\varepsilon-\\eta g(\\kappa_0;\\alpha,\\beta,\\varepsilon)\\}\\int_{0}^\\infty",
    "\\frac{\\exp(-\\eta \\beta_0\\kappa)}{i_0(\\kappa)^\\eta } { \\mathrm{d}}\\kappa \\label{eq : acceptprob}\\end{aligned}\\ ] ] over @xmath76 subject to the constraint @xmath40 . in order for the maximum to be finite as @xmath77",
    "we require @xmath78 .    by taking logs we see that maximizing with respect to @xmath18 is equivalent to maximizing @xmath79    the constraint @xmath40 implies either @xmath80 or @xmath81 .",
    "the lagrangians for constrained optimization corresponding to these conditions are @xmath82 and @xmath83 , neither of which have interior critical points over @xmath84 because the @xmath85 and @xmath70 derivatives have no common root .",
    "thus the optimal parameters must lie on the boundary of the parameter space .",
    "an examination of the boundaries show that the maximum satisfies @xmath81 and @xmath86 .",
    "intuitively , this says that for any @xmath43 we should pick @xmath70 as small as possible while still having @xmath43 be the maximizer of @xmath87 .",
    "thus our lagrangian is @xmath88    our optimal parameters are either a critical point of @xmath89 or lie on one or more of the boundaries @xmath90 or @xmath91 .",
    "if either @xmath92 or @xmath93 then direct differentiation shows the maximum occurs when @xmath94 and @xmath43 is the unique positive root of @xmath95 .",
    "we shall see this is a limiting case of the critical point solution .",
    "the only other boundary is @xmath91 ; we shall see this is the solution when @xmath24 is close to @xmath96 .    to find the critical points of @xmath89 ,",
    "we start by setting the derivatives with respect to @xmath97 and @xmath98 to zero and rearranging yields the optimal parameters as functions of @xmath43 and @xmath99 . this yields @xmath100 where @xmath101 is the digamma function .",
    "we must have @xmath102 so that @xmath85 and @xmath70 are positive .",
    "notice that the limit @xmath103 corresponds to the boundary case @xmath104 discussed above .",
    "the above equations give all optimal parameters in terms of @xmath99 and @xmath43 .",
    "note that since constraint @xmath105 at @xmath106 is satisfied whenever @xmath107 , we are free to choose alternative , sub - optimal values for the other parameters if the true optimal values are too difficult to compute",
    ". we shall explore this in section  [ sect : speedup ] when we use an approximation for the lambert w function .    finally , we find the optimal @xmath99 as follows",
    ". this value must either lie on the boundary @xmath91 or else satisfy @xmath108 unfortunately plugging into and solving for @xmath99 as a function of @xmath43 alone is analytically intractable .",
    "however , one can check that @xmath109 decreases from positive infinity at @xmath110 to negative infinity as @xmath111 . since all admissible @xmath99 lie in the finite interval @xmath112 we can easily find the optimal @xmath99 through any standard one - dimensional root - finding algorithm . if the root lies to the right of @xmath113 , the optimal value is @xmath91 .",
    "we plug the optimal @xmath99 into to find all of our optimal parameters in terms of @xmath43 .",
    "doing this for each @xmath43 and plugging the resulting parameters @xmath114 into @xmath115 yields a function which we numerically maximize over @xmath43 .",
    "let @xmath116 be the optimal value of @xmath43 and let @xmath117 be the optimal parameters corresponding to @xmath116 .",
    "these are the desired parameters that maximize the expected acceptance probability .",
    "the above numeric maximizations for @xmath99 and @xmath43 may be acceptable when @xmath23 and @xmath24 are known a priori .",
    "however , they are computationally prohibitive in the standard monte carlo case where we wish to generate many samples from the bessel exponential distribution with different values of @xmath23 and @xmath24 for each sample .",
    "thus our next task is to approximate the optimal parameters with easily computable functions of @xmath23 and @xmath24 .    for all @xmath23 and @xmath24 , @xmath116",
    "is well approximated by @xmath118 , the positive root of @xmath119 ; indeed @xmath118 is the exact optimum in the boundary case @xmath104 . to approximate @xmath118 we use the bounds (",
    "11 ) , @xmath120 rearranging these bounds shows that @xmath121 where @xmath122 these bounds are relatively tight , we found that the convex combination @xmath123 with @xmath124 provides a good approximation to @xmath118 and hence to @xmath116 .",
    "the parameter @xmath125 is exactly equal to @xmath113 when @xmath24 is close to its lower bound of negative one . for @xmath24 sufficiently large , @xmath125 drops from its upper limit @xmath113 towards its lower limit @xmath126 .",
    "the transition between the two limits is very rapid for @xmath127 .",
    "we achieve good accuracy with the approximation @xmath128 where @xmath129 .",
    "this approximation is very good when @xmath130 is large or when @xmath131 .",
    "a slower , more precise approximation for @xmath125 may lead to parameters which provide better efficiency for small @xmath23 and @xmath132 ; we address this in section  [ sect : efficiency ] .    given these approximations of @xmath116 and @xmath125 , the parameters @xmath133 and @xmath134",
    "are given by .",
    "the truncated gamma on line  [ algline : xsampling ] can be sampled using dagpunar s algorithm @xcite . alternatively , one can use a standard gamma sampling algorithm such as marsaglia ",
    "tsang @xcite and reject when @xmath135 .",
    "indeed , the marsaglia  tsang algorithm is itself a rejection sampler with a gaussian proposal , and its rejection step can be combined with the rejection step on line  [ algline : acceptreject ] for an additional speed - up .",
    "the function @xmath136 on line  [ algline : lambert ] can be approximated by ( winitzki , @xcite ) @xmath137 with no noticeable drop in the expected probability of acceptance .",
    "finally , we can implement the simple squeezes @xmath138 to avoid computing the bessel function within the rejection loop on line  [ algline : acceptreject ] .",
    "specifically , the loop on lines [ algline : startloop ] to [ algline : returnline ] can be replaced with algorithm  [ alg : squeezed ] .",
    "@xmath139 @xmath68 sample from a @xmath140 left - truncated at @xmath70 @xmath71 @xmath141 @xmath72 sample from a @xmath73 @xmath142 * if * @xmath143 * or * @xmath144 * then * + * if * @xmath145 * or * @xmath146 * then * +",
    "we now analyze the efficiency of algorithm  [ alg : kappa ] . when using the winitzki approximation , the initial setup ( lines [ algline : startsetup][algline : endsetup ] ) involve arithmetic operations , four square roots , two bessel function evaluations , one logarithm and one exponentiation . in total",
    "this setup requires approximately 70 microseconds on a 2.4ghz intel i5 computer when using the r package * gsl*. implementation in a lower - level language would increase the speed significantly .",
    "each iteration of the rejection loop requires a gamma sample , a uniform sample , between three and five logarithms , and in the worst case a bessel function evaluation .",
    "the squeeze in algorithm  [ alg : squeezed ] does a good job of avoiding the bessel computation most of the time , and each iteration of the loop requires approximately @xmath147 microseconds .",
    "most of these iterations are accepted , and the algorithm , implemented in r , yields approximately 80,000 von mises samples per second when @xmath148 and @xmath24 is drawn uniformly over @xmath149 .",
    "when using a compiled language such as c++ , the algorithm yields over one million samples per second .    in figure",
    "[ fig : efficiency ] we plot the expected probabilities of acceptance as functions of @xmath23 and @xmath24 .",
    "the figures were generated by numerically integrating the expected probability of acceptance for each @xmath150 and for each of 2000 equally spaced values of @xmath151 .",
    "there is a noticeable dip in efficiency near @xmath152 . recalling that @xmath153",
    ", we see that this region corresponds to diffused @xmath154 , i.e. the true @xmath18 is near zero .",
    "this is precisely the region where our bessel function approximation fails , so this drop is to be expected .",
    "fortunately the drop in efficiency is not severe and our efficiency remains above @xmath155 for all @xmath23 and @xmath24 .    from figure",
    "[ fig : efficiency ] we see that our algorithm with the approximate optimal parameters does noticeably worse than the numerically computed true optimal parameters when @xmath132 .",
    "this corresponds to the transition region where the optimal @xmath99 rapidly drops from its upper limit of @xmath113 to its lower limit of @xmath156 .",
    "our approximation of the optimal @xmath99 is inaccurate in this transition region .",
    "a more sophisticated approximation of the optimal @xmath99 would increase the algorithm s efficiency , however , the region @xmath157 is not usually an area of primary interest and we prefer to use the faster approximation .",
    "table[x index=0,y index=1 ] eff1.csv ; table[x index=0,y index=2 ] eff1.csv ;    table[x index=0,y index=1 ] eff10.csv ; table[x index=0,y index=2 ] eff10.csv ;    table[x index=0,y index=1 ] eff100.csv ; table[x index=0,y index=2 ] eff100.csv ;",
    "we have described a highly efficient algorithm to sample from the bessel exponential distribution .",
    "it is suitable for any application where one wishes generate samples from the posterior distribution for the concentration parameter of the von mises distribution ."
  ],
  "abstract_text": [
    "<S> motivated by molecular biology , there has been an upsurge of research activities in directional statistics in general and its bayesian aspect in particular . </S>",
    "<S> the central distribution for the circular case is von mises distribution which has two parameters ( mean and concentration ) akin to the univariate normal distribution . </S>",
    "<S> however , there has been a challenge to sample efficiently from the posterior distribution of the concentration parameter . </S>",
    "<S> we describe a novel , highly efficient algorithm to sample from the posterior distribution and fill this long - standing gap . </S>"
  ]
}