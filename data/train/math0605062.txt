{
  "article_text": [
    "to    to    to    to    to    to    to    to    to    to",
    "* 1 . overview . *",
    "one of the basic problems of finance is : _ how to measure risk in a proper way ? _    two most well - known and widely used in practice approaches to this problem are variance and v@r .",
    "however , both of them have serious drawbacks .",
    "variance penalizes high profits in the same way as high losses .",
    "furthermore , the corresponding gain to loss ratio @xmath2 known as the sharpe ratio does not have the monotonicity property : @xmath3 does not imply that @xmath4 .",
    "in particular , an arbitrage possibility might have a very low sharpe ratio .",
    "concerning v@r , it takes into account only the quantile of the distribution without caring about what is happening to the left and to the right of the quantile . to put it another way ,",
    "v@r is concerned only with the probability of the loss and does not care about the size of the loss .",
    "however , it is obvious that the size of the loss should be taken into account .",
    "let us remark in this connection that in the study of the default risk the main two characteristics of a default are its probability and its severity .",
    "further criticism of variance and v@r can be found in  @xcite as well as in numerous discussions in financial journals .",
    "recently , a new very promising approach to measure risk was proposed in the landmark papers by artzner , delbaen , eber , and heath  @xcite , @xcite ( these are the financial and the mathematical versions of the same paper ) . these authors introduced the notion of a _ coherent risk measure_. since then , the theory of coherent risk measures has rapidly been evolving ; it already occupies a considerable part of the modern financial mathematics .",
    "let us cite the papers  @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , to mention only a few .",
    "nice reviews on the theory of coherent risk measures are given in  @xcite , ( * ? ? ?",
    "* ch .  4 ) , @xcite .",
    "much of the current research in this area deals with defining properly a dynamic risk measure ( let us mention in this connection the papers  @xcite , @xcite , @xcite , @xcite , @xcite ) .",
    "currently , more and more research in the theory of coherent risk measures is related to applications to problems of finance rather than to the study of `` pure '' risk measures . in particular ,",
    "the problem of capital allocation was considered in  @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite ; the problem of pricing and hedging was investigated in  @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite ; the problem of the optimal portfolio choice was studied in  @xcite , @xcite , @xcite ; the equilibrium problem was considered in  @xcite , @xcite , @xcite , @xcite , @xcite , @xcite .",
    "this list is very far from being complete ; for example , on the gloria mundi web page over two hundred papers are related to coherent risk measures .",
    "the investigations mentioned above show that the whole finance can be built based on coherent risk measures .",
    "this is not surprising because risk ( @xmath5  uncertainty ) is at the very basis of finance , and a new way of measuring risk yields new approaches to all the basic problems of finance . in some sources , the theory of coherent risk measures and their applications",
    "is already called the `` third revolution in finance '' ( see  @xcite ) .    *",
    "2 . coherent risk . *",
    "a coherent risk measure is a functional defined on the space of random variables that has the following form @xmath6{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathcal{d}}}{\\mathsf{e}}_{\\mathsf{q}}x.\\ ] ] here @xmath7 means the p&l produced by some portfolio over the unit time period ( for example , one day ) and @xmath8 is a set of probability measures ( all the measures from  @xmath8 are assumed to be absolutely continuous with respect to the original measure  @xmath9 ) . from the financial point of view , @xmath10 is the risk of the portfolio .",
    "formula   has a straightforward economic interpretation : we have a family  @xmath8 of probabilistic scenarios ; under each scenario we calculate the average p&l ; then we take the worst case .",
    "let us remark that typically a coherent risk measure is defined as a functional on random variables satisfying certain properties , and the representation theorem states that it should have the form  .",
    "the notion of a coherent risk measure is very convenient theoretically , but when applying it to practice the following problem arises immediately : _ how to estimate @xmath10 empirically ? _ of course , representation   can not be used for the practical calculation ; furthermore , the class of coherent risk measures ( @xmath11 the class of different sets  @xmath8 ) is very wide .",
    "thus , for the practical purposes one needs to select a subclass of coherent risk measures that admits an easy estimation procedure .",
    "one of the best subclasses known so far is _",
    "tail v@r_. tail v@r of order @xmath12 $ ] is the coherent risk measure  @xmath13 corresponding to @xmath14 .",
    "it is easy to check that @xmath15 , where @xmath16 is the @xmath17-quantile of  @xmath7 .",
    "thus , @xmath13 is a very simple functional .",
    "however , the sceptics can propose the following argument : it is already hard to estimate @xmath16 due to rare tail data and it is much harder to estimate the tail mean , so the empirical estimation of  @xmath13 is problematic .    in this paper",
    ", we propose a one - parameter family of coherent risk measures , which are extremely easy to estimate .",
    "this is the class of risk measures of the form @xmath18 where @xmath19 is a fixed natural number and @xmath20 are independent copies of  @xmath7 .",
    "the parameter  @xmath19 controls the risk aversion of  @xmath21 : the higher is  @xmath19 , the more risk averse is  @xmath21 .",
    "we call @xmath21 _ alpha v@r_. this family of risk measures is a very good substitute for tail v@r .",
    "it has the following advantages :    @xmath21 is very intuitive ;    @xmath21 depends on the whole distribution of  @xmath7 and not just on the tail as @xmath13 ;    it is very easy to estimate @xmath22 from the time series for  @xmath7 .",
    "let us remark that for large data sets the empirical estimation of @xmath21 from time series is faster than the empirical estimation of @xmath23 ( ! ) because it does not require the ordering of the time series .",
    "we believe that @xmath21 is the best one - parameter family of coherent risk measures .",
    "alpha v@r is a subclass of the two - parameter family of coherent risk measures , which we call _ beta v@r_. this is the class of risk measures of the form @xmath24,\\ ] ] where @xmath25 are fixed natural numbers and @xmath26 are the order statistics obtained from the sequence @xmath20 of independent copies of  @xmath7 .",
    "in particular , @xmath27 .",
    "we believe that @xmath28 is the best two - parameter family of coherent risk measures .    *",
    "3 . factor risk .",
    "* the theory of coherent risk measures is already rather rich .",
    "however , so far , an important issue has been absent : _ how to measure the separate risks of a portfolio induced by factors like the price of oil , s&p 500 index , or the credit spread ? _",
    "measuring these risks separately is very important .",
    "suppose , for example , that a significant change in the price of oil is expected in the near future . then having a big exposure to the price of oil is dangerous .",
    "of course , one might argue at this point that @xmath10 depends on @xmath29 , and this distribution already takes into account high risk induced by possible oil price moves ( as well as all the other risks ) , so that there is no need to consider separate risks .",
    "our reply to this possible criticism is as follows .",
    "suppose that we are trying to assess empirically the risk of a large portfolio .",
    "as different assets in a large portfolio have different durations ( like options or bonds ) , a joint time series for all of them does not exist .",
    "so , for the empirical estimation we should consider the main factors driving the risk , express the values of all the assets through these factors , and use time series for the factors .",
    "another advantage of factor risks is as follows .",
    "when choosing data for the empirical risk estimation , there is always a conflict between accuracy and flexibility to the recent changes ( the more data we take , the more accurate are estimates , but less is the flexibility to recent changes ) .",
    "however , if we are looking for the separate risks driven by separate factors , then this conflict can be resolved .",
    "namely , for a factor one can take time series whose time step is stretched according to the current volatility of the factor ( for details , see section  [ fr ] ) .",
    "this time change procedure enables one to use arbitrarily large data sets and at the same time immediately react to the volatility changes .",
    "we propose a way for the coherent measurement of factor risks .",
    "let @xmath7 be the p&l of a portfolio produced over a unit time period and @xmath30 be the increment of some factor / factors over this period ( @xmath30 might be multidimensional ) .",
    "the _ factor risk _ of @xmath7 induced by @xmath30 is defined as @xmath31{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathsf{e}}({\\mathcal{d}}{\\hspace{0.3mm}|\\hspace{0.3mm}}y)}{\\mathsf{e}}_{\\mathsf{q}}x,\\ ] ] where @xmath8 is the set standing in   and @xmath32 here we identify measures from @xmath8 with their densities with respect to  @xmath9 .",
    "thus , @xmath33 is again a coherent risk measure .",
    "it is easy to check that @xmath34 this expression clarifies the essence of factor risk : @xmath35 takes into account the risk of  @xmath7 driven only by  @xmath30 and cuts off all the other risks .",
    "the value @xmath35 might be looked at as the coherent counterpart of the sensitivity of  @xmath7 to  @xmath30 .",
    "however , an important difference from the sensitivity analysis is the non - linearity of @xmath35 .",
    "the notion of factor risk can be employed in two forms :    we take one factor ( i.e. @xmath30 is one - dimensional ) , and then @xmath36 measures the risk induced by this factor .",
    "we take all the main factors driving the risk ( i.e. @xmath30 is multidimensional ) , and then @xmath36 measures the `` non - diversifiable '' risk and serves as a good approximation to  @xmath37 . in other words",
    ", we are taking the main factors , express the values of all the assets in the portfolio through these factors , and look at the coherent risk .",
    "this is a standard procedure of the risk measurement , the only difference is that coherent risk measures are employed .",
    "a very pleasant feature of @xmath36 is that it is easily calculated for large portfolios .",
    "suppose , for example , that our portfolio consists of @xmath38 assets , so that @xmath39",
    ". then @xmath40 where @xmath41 .",
    "in order to calculate this value , we need not know the joint distribution of  @xmath42 ( if the portfolio consists of several thousands assets , finding this distribution is not a very pleasant problem ) . instead , we only need the joint distributions of @xmath43 , @xmath44 .",
    "in essence , there is no difference whether our portfolio consists of 1000 or 1000000 assets because different @xmath45s are joined simply by the summation procedure .    for coherent factor risks based on alpha v@r and beta v@r",
    ", we consider an empirical estimation procedure similar to the historic v@r estimation ( for the description of these methods , see  ( * ? ? ?",
    "* sect .  6 ) ) .",
    "this procedure has the following advantages :    arbitrarily large data sets for factors are available ;    for one - factor risks we can use the time change procedure , which enables one to use arbitrarily large data sets and immediately react to the volatility changes ;    the procedure is simple and works at the same speed as the historic v@r estimation ;    the use of coherent risk measures is much wiser than the use of v@r ;    the procedure is completely non - linear ;    the procedure employs no model assumptions ( except , of course , for those used in the calculation of @xmath46 ) .    *",
    "portfolio optimization .",
    "* the main message of the first part of the paper is : it is reasonable to assess the risk of a position not just as a number , but as a vector of factor risks @xmath47 .",
    "we also consider the problem of portfolio optimization when the constraints on the portfolio are given as @xmath48 , @xmath49 .",
    "it turns out that this problem admits a simple geometric solution that is similar to the one given in  ( * ? ? ?",
    "* subsect .",
    "2.2 ) for the case of a single constraint @xmath50 .",
    "we do not insist that this solution is the one that should be implemented in practice , but it gives a nice theoretic insight into the form of the optimal portfolio .",
    "a possible practical approach to this problem is also discussed .",
    "* 5 . risk contribution .",
    "* the functional @xmath37 measures the outstanding risk of a portfolio .",
    "however , if a big firm assesses the risk of a trade , it should take into account not the outstanding risk of the trade , but rather its impact on the risk of the whole firm .",
    "thus , if the p&l of the trade is  @xmath7 and the p&l produced over the same period by the whole firm is  @xmath51 , the quantity of interest is @xmath52 .",
    "if @xmath7 is small as compared to  @xmath51 , then a good approximation to this difference is the _ risk contribution _ of  @xmath7 to  @xmath51 .",
    "the notion of risk contribution based on coherent risk measures was considered in  @xcite , @xcite , @xcite , @xcite , @xcite . in this paper",
    ", we are taking the definition proposed in  ( * ? ? ?",
    "* subsect .",
    "one of equivalent definitions of the coherent risk contribution @xmath53 of  @xmath7 to  @xmath51 is @xmath54 note that if @xmath7 is small as compared to  @xmath51 , then @xmath55 in most typical situations @xmath56 admits the representation @xmath57 where @xmath58 is the _ extreme measure _ defined as @xmath59 ( @xmath8 is the set standing in  ) .",
    "note that in this case @xmath36 is linear in  @xmath7 .    for the most important classes of coherent risk measures ,",
    "risk contribution admits a simple empirical estimation procedure . as shown in the paper , for alpha v@r , @xmath56 has the following form : @xmath60 where @xmath61 are independent copies of @xmath62 .",
    "in particular , it is not hard to compute this quantity for the typical case , where the firm s portfolio consists of many assets , i.e. @xmath63 with a large number  @xmath38 .",
    "a similar simple representation is provided for the beta v@r risk contribution .",
    "we also provide formulas for the empirical estimation of risk contributions for the class of risk measures , which we call _ weighted v@r _ ( the term _ spectral risk measures _ is also used in the literature ) ; this is a wide class containing , in particular , beta v@r .",
    "we also study the properties of the coefficient @xmath64 which measures the tail correlation between @xmath7 and @xmath51 .    *",
    "factor risk contribution . * in this paper , we introduce the notion of _ factor risk contribution_. it is simply the risk contribution applied to the risk measure @xmath36 , i.e @xmath65 the quantity @xmath66 may be viewed as a coherent alternative to the sensitivity coefficient .",
    "there are , however , two important differences :    the sensitivity coefficient is a nice estimate of risk provided that the change in the corresponding factor is small ( i.e. @xmath30 is small ) . on the other hand , the factor risk contribution is a nice estimate of risk provided that @xmath7 is small as compared to  @xmath51 and there are no requirements on the size of  @xmath30 .",
    "the sensitivity coefficient measures the sensitivity of a portfolio to a market factor . on the other hand ,",
    "the factor risk contribution measures the sensitivity of a portfolio  @xmath7 both to the market factor  @xmath30 and to the firm s portfolio  @xmath51 .",
    "so , @xmath67 is a `` firm - specific '' coherent sensitivity to the factor  @xmath30 .    as shown in the paper , @xmath68 this formula reduces the computation of @xmath69 to two steps : calculating the functions @xmath70 , @xmath71 and computing  @xmath56 .    *",
    "7 . risk sharing . *",
    "the relevance of factor risk contributions becomes clear from our considerations of the risk sharing problem .",
    "one of the basic problems of the central management of a firm consisting of several desks is : how to impose the limits on the risk of each desk ?",
    "typically , this problem is approached as follows . by looking at the performance of each desk ,",
    "the central management decides which desks should grow and which ones should shrink and chooses the risk limits accordingly .",
    "nowadays , the procedure of choosing the risk limits is to a large extent a political one . at the same time",
    ", the central managers would like to have a quantitative rather than political procedure of choosing these limits .",
    "an idea proposed by practitioners is : instead of giving each desk a fixed risk limit , it might be reasonable to allow the desks to trade the risk limits between themselves . for example",
    ", if one desk is not using its risk limit completely , it might sell the excess risk limit to another desk , which needs it .    in this paper",
    "we address the following problem : _ is it possible to arrange a market of risk within a firm in such a way that the resulting competitive optimum would coincide with the global one ? _",
    "( by the global optimum we mean the one attained if the central management had possessed all the information available to all the desks and had been able to solve the corresponding global optimization problem . )",
    "the hope of the positive answer is justified by a well - known equivalence established in the expected utility framework between the global optimum ( known also as the pareto - type or the soviet - type optimum ) and the competitive optimum ( known also as the arrow  debreu - type or the western - type optimum ) ; see  @xcite .",
    "a coherent risk counterpart of this result was established in  ( * ? ? ?",
    "* sect .  4 ) .",
    "the difference between these results and our setting is that here the objects traded are risk limits rather than financial contracts .",
    "the results of this paper ( they are established within the coherent risk framework ) are as follows :    if the desks are measuring their outstanding risks and are keeping them within the risk limits , then the competitive optimum is _ not _ the global one .",
    "if the desks are keeping track of their risk contributions to the whole firm , then the competitive optimum coincides with the global one .    moreover , it turns out that the global optimum is achieved regardless of what the initial allocation of risk limits between the desks is .",
    "( by the initial allocation we mean the risk limits given to the desks by the central management before the desks start to trade their risk limits . ) our result applies not only to the case of one risk constraint on the firm s portfolio , but also to the case of several risk constraints ( a typical example is the constraints on each factor risk ) .    *",
    "structure of the paper .",
    "* in essence , the paper consists of two parts .",
    "the first part ( sections  [ crm][po ] ) deals with factor risk . in section  [ crm ] , we recall basic facts and examples related to coherent risk measures .",
    "section  [ fr ] deals with factor risk . in section  [ po ]",
    ", we study the problem of portfolio optimization under limits imposed on factor risks . the second part ( sections  [ rc][ors ] ) deals with ( factor ) risk contribution . in section  [ rc ] , we recall basic facts related to risk contribution . section  [ frc ] deals with factor risk contribution . in section",
    "[ ors ] , we study the problem of risk sharing between the desks of a firm .",
    "the appendix contains the @xmath72-version of the kusuoka theorem , which is needed for some statements of the paper and is of interest by itself .",
    "the recipes for the practical risk measurement are gathered in section  [ sc ] , where we also compare various empirical risk estimation techniques considered in this paper with the classical ones like parametric v@r , monte carlo v@r , and historic v@r .",
    "the reader interested in practical applications only might proceed directly to section  [ sc ] .",
    "a.  cherny expresses his thanks to d.  heath and s.  hilden for the fruitful discussions related to the risk sharing problem .",
    "* 1 . basic definitions and facts . *",
    "let @xmath73 be a probability space .",
    "it is convenient to consider instead of coherent risk measures their opposites called coherent utility functions .",
    "this enables one to get rid of numerous minus signs .",
    "recall that @xmath74 is the space of bounded random variables on @xmath73 .",
    "the following definition was introduced in  @xcite , @xcite , @xcite .",
    "[ crm1 ] a _ coherent utility function on @xmath74 _ is a map @xmath75 satisfying the properties :    ( superadditivity ) @xmath76 ;    ( monotonicity ) if @xmath3 , then @xmath77 ;    ( positive homogeneity ) @xmath78 for @xmath79 ;    ( translation invariance ) @xmath80 for @xmath81 ;    ( fatou property ) if @xmath82 , @xmath83 , then @xmath84 .",
    "the corresponding _ coherent risk measure _ is @xmath85 .",
    "` remarks ` .",
    "( i ) from the financial point of view , @xmath7 means the p&l produced by some portfolio over the unit time period ( taken as the basis for risk measurement ) and discounted to the initial time",
    ". actually , all the financial quantities in this paper are the discounted ones . however , the unit time period is typically small ( for example , one day ) , and for such time horizons the discounted values are very close to the actual ones . for this reason , below",
    "we skip the word `` discounted '' .",
    "\\(ii ) the superadditivity property of  @xmath86 ( @xmath11  the subadditivity of  @xmath37 ) has the following financial meaning : if we have a portfolio consisting of several subportfolios and the risk of each subportfolio is small , then the risk of the whole portfolio is small .",
    "v@r satisfies all the conditions of the above definition except for the subadditivity , and this leads to serious drawbacks of v@r .",
    "this can be illustrated by a simple example proposed in  @xcite .",
    "suppose that a portfolio consists of 25 subportfolios ( corresponding to several agents ) , i.e. its p&l @xmath7 equals @xmath87 .",
    "suppose that @xmath88 , where @xmath89 and @xmath90 are disjoint sets ( @xmath91 denotes the complement of  @xmath92 ) .",
    "this means that each agent employs a spiking strategy .",
    "if risk is measured by @xmath93 , then the risk of each subportfolio is negative ( meaning that each subportfolio is extremely good from the viewpoint of this risk measure ) , while the p&l produced by the whole portfolio is identically equal to @xmath94 !    a natural example , in which v@r is subadditive , is the gaussian case : if @xmath95 have a jointly gaussian distribution , then @xmath96 .",
    "but actually on the set of ( centered ) gaussian variables all the reasonable risk measures like v@r , variance , any law invariant coherent risk measure ( see example  [ crm7 ] ) coincide up to multiplication by a positive constant .",
    "however , for general random variables this is not the case , v@r and variance exhibit serious drawbacks ( see  @xcite ) , and coherent risk measures are really needed .",
    "@xmath97    the theorem below is the basic representation theorem .",
    "it was established in  @xcite for the case of a finite @xmath98 ( in this case the axiom  ( e ) is not needed ) and in  @xcite for the general case ( the proof can also be found in  ( * ? ? ?",
    "* cor .  4.35 ) or  ( * ? ? ?",
    "* cor .  1.17 ) ) .",
    "we denote by @xmath99 the set of probability measures on  @xmath100 that are absolutely continuous with respect to  @xmath9 . throughout the paper , we identify measures from  @xmath99 ( these are typically denoted by  @xmath58 ) with their densities with respect to  @xmath9 ( these are typically denoted by  @xmath101 ) .",
    "[ crm2 ] a function  @xmath86 satisfies conditions ( a)(e ) if and only if there exists a non - empty set @xmath102 such that @xmath103{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathcal{d}}}{\\mathsf{e}}_{\\mathsf{q}}x,\\quad x\\in l^\\infty.\\ ] ]    ` remarks ` .",
    "( i ) let us emphasize that a coherent risk measure is defined on random variables and not on their distributions .",
    "using representation  , it is easy to construct an example of a risk measure @xmath37 and two random variables @xmath7 and @xmath30 with @xmath104 , but with @xmath105 .",
    "a particularly important subclass of coherent risk measures is the class of _ law invariant _ ones , i.e. the risk measures @xmath37 that depend only on the distribution of  @xmath7 .",
    "however , it would not be a nice idea to include law invariance as the sixth axiom in definition  [ crm1 ] .",
    "indeed , the basic risk measure used by an agent is typically law invariant .",
    "but there are many `` derivative '' risk measures like @xmath33 ( many examples of naturally arising `` derivative '' risk measures can be found in  @xcite , @xcite , @xcite ) , and these ones need not be law invariant even if the basic risk measure  @xmath37 is law invariant .",
    "\\(ii ) coherent risk measures are primarily aimed at measuring risk .",
    "but they can be used to measure the risk - adjusted performance as well .",
    "the risk - adjusted performance based on coherent risk is a functional of the form @xmath106 , where @xmath37 is a coherent risk measure and @xmath79 .",
    "( by @xmath107 we will always denote the expectation with respect to the original measure  @xmath9 . ) note that the functional @xmath108 is a coherent utility ( it is sufficient to take @xmath109 in  ) .",
    "furthermore , if @xmath110{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathcal{d}}_n}{\\mathsf{e}}_{\\mathsf{q}}x,\\quad n=1,2\\ ] ] are two coherent utilities and @xmath111 $ ] , then @xmath112{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\lambda}{\\mathcal{d}}_1+(1-{\\lambda}){\\mathcal{d}}_2}{\\mathsf{e}}_{\\mathsf{q}}x\\ ] ] is also a coherent utility ( we use the notation @xmath113 ) .",
    "thus , @xmath114 is again a coherent utility , which is a very convenient `` stability '' feature . as a result",
    ", coherent utility / risk can be used    to measure risk ;    to measure the risk - adjusted performance , i.e. utility .",
    "\\(iii ) coherent utility may serve as a substitute for the classical expected utility .",
    "the techniques like utility - indifference pricing , utility - based optimization , utility - based equilibrium , etc . can be transferred from the expected utility framework to the coherent utility framework .",
    "note that the intersection of these two classes of utility is trivial : it consists only of the functional @xmath108 ( note that all the other expected utilities do not satisfy the translation invariance property ) .",
    "\\(iv ) a generalization of coherent utility is the notion of _ concave utility _ introduced by fllmer and schied  @xcite , @xcite .",
    "a functional @xmath75 is a _ concave utility function _ if it satisfies the axioms ( b ) , ( d ) , ( e ) of definition  [ crm1 ] as well as the condition    ( concavity ) @xmath115 for @xmath111 $ ] .",
    "the corresponding _ convex risk measure _ is @xmath85 .",
    "the representation theorem states that  @xmath86 is a concave utility function if and only there exists a non - empty set @xmath102 and a function @xmath116 such that @xmath117{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathcal{d}}}({\\mathsf{e}}_{\\mathsf{q}}x+{\\alpha}({\\mathsf{q}})),\\quad x\\in l^\\infty\\ ] ] ( the proof can be found in  @xcite , ( * ? ? ?",
    "* th .  4.31 ) , or  ( * ? ?",
    "* th .  1.13 ) ) .",
    "a natural example of a concave utility function is @xmath118{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathcal{d } } } { \\mathsf{e}}_{\\mathsf{q}}u(x - m)\\ge x_0\\bigr\\},\\quad x\\in l^\\infty,\\ ] ] where @xmath119 is a concave increasing function , @xmath102 , and @xmath120 is a fixed threshold .",
    "this object is closely connected with the robust version of the savage theory developed by gilboa and schmeidler  @xcite . for a detailed study of these concave utilities ,",
    "see  @xcite , ( * ? ? ?",
    "4.9 ) , or  ( * ? ? ?",
    "the theory of convex risk measures is now a rather large field .",
    "however , in applications to problems of finance like pricing and optimization , coherent risk measures turn out to be much more convenient than the convex ones . for this reason , we will consider only coherent risk measures .",
    "@xmath97    so far , a coherent risk measure has been defined on bounded random variables .",
    "let us ask ourselves the following question : are `` financial '' random variables like the increment of a price of some asset indeed bounded ?",
    "the right way to address this question is to split it into two parts :    are `` financial '' random variables bounded in practice ?",
    "are `` financial '' random variables bounded in theory ?",
    "the answer to the first question is positive ( clearly , everything is bounded by the number of the atoms in the universe ) .",
    "the answer to the second question is negative because most distributions used in theory ( like the lognormal one ) are unbounded .",
    "so , as we are dealing with theory , we need to extend coherent risk measures to the space @xmath72 of all random variables .",
    "it is hopeless to axiomatize the notion of a risk measure on @xmath72 and then to obtain the corresponding representation theorem . instead ,",
    "following  @xcite , we take representation   as the basis and extend it to  @xmath72 .",
    "[ crm3 ] a _ coherent utility function on @xmath72 _ is a map @xmath121 $ ] defined as @xmath122{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathcal{d}}}{\\mathsf{e}}_{\\mathsf{q}}x,\\quad x\\in l^0,\\ ] ] where @xmath8 is a non - empty subset of @xmath99 and @xmath123 is understood as @xmath124 ( @xmath125 , @xmath126 ) with the convention @xmath127 .",
    "( throughout the paper , all the expectations are understood in this way . )    ` remark ` .",
    "this way of defining coherent utility has parallels to what is done with the classical expected utility .",
    "namely , the von neumann ",
    "morgenstern representation shows that ( appropriately axiomatized ) investor s preferences are described by @xmath128 with a bounded function  @xmath129 .",
    "then one typically takes a concave increasing unbounded function @xmath130 and _ defines _ the preferences by @xmath128 .",
    "@xmath97    clearly , different sets @xmath8 might define the same coherent utility ( for example , @xmath8 and its convex hull define the same function  @xmath86 ) . however , among all the sets @xmath8 defining the same  @xmath86 there exists the largest one .",
    "it is given by @xmath131 .",
    "[ crm4 ] we will call the largest set , for which  resp . , is true , the _ determining set _ of  @xmath86 .",
    "` remarks ` .",
    "( i ) let @xmath132 be another coherent utility with the determining set  @xmath133 . clearly , @xmath134 in other words , the size of @xmath8 controls the risk aversion of  @xmath37 .",
    "\\(ii ) the determining set is convex . for coherent utilities on  @xmath74",
    ", it is also @xmath135-closed ( for the corresponding example , see  ( * ? ? ?",
    "* subsect .",
    "2.1 ) ) . in particular , the determining set of a coherent utility on @xmath72 and the determining set of its restriction to @xmath74 might be different .",
    "\\(iii ) let @xmath8 be an @xmath135-closed convex subset of  @xmath99 .",
    "( let us note that a particularly important case is where @xmath8 is @xmath135-closed , convex , and uniformly integrable ; this condition will be needed in a number of places below . )",
    "define a coherent utility  @xmath86 by  .",
    "then @xmath8 is the determining set of  @xmath86 .",
    "indeed , assume that the determining set @xmath136 is larger than  @xmath8 , i.e. there exists @xmath137 .",
    "then , by the hahn",
    " banach theorem , we can find @xmath138 such that @xmath139{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathcal{d}}}{\\mathsf{e}}_{\\mathsf{q}}x$ ] , which is a contradiction .",
    "the same argument shows that @xmath8 is also the determining set of the restriction of  @xmath86 to @xmath74 .",
    "@xmath97    in what follows , we will always consider coherent utility functions on  @xmath72 .",
    "* 2 . examples .",
    "* let us now provide several natural examples of coherent risk measures .",
    "[ crm5 ] let @xmath12 $ ] and consider @xmath140 the corresponding coherent risk measure is called _",
    "tail v@r _ ( the terms _ average v@r _ , _ conditional v@r _ , _ expected shortfall _ , and _ expected tail loss _ are also used ) .",
    "let us denote it by  @xmath13 and the corresponding coherent utility by  @xmath141 .",
    "clearly , @xmath142 so that @xmath17 serves as the risk aversion parameter .",
    "we have @xmath143{}-{\\mathop{\\rm essinf}}_\\omega x(\\omega)\\ ] ] ( recall that @xmath144 ) .",
    "the right - hand side of this relation is the most severe risk measure ( it is easy to see that any coherent risk measure  @xmath37 satisfies the inequality @xmath145 ) .",
    "furthermore , @xmath146 , which is the most liberal risk measure ( it is seen from theorem  a.1 that any law invariant risk measure  @xmath37 satisfies the inequality @xmath147 ) .",
    "let us provide a more explicit representation of  @xmath141 .",
    "set @xmath148 throughout the paper , @xmath149 will denote the right @xmath17-quantile , i.e. @xmath150{0mm}{1mm}}}\\{x : f(x)\\ge{\\lambda}\\}$ ] , where @xmath151 is the distribution function of  @xmath7 . then @xmath152 , @xmath153 and ,",
    "for any @xmath154 , we have @xmath155\\ge0.\\end{aligned}\\ ] ] hence , @xmath156 where @xmath157 .",
    "in particular , it follows that @xmath141 is law invariant , i.e. it depends only on the distribution of  @xmath7 .",
    "if @xmath7 has a continuous distribution , then this formula is simplified to : @xmath158    using  , one easily gets an equivalent representation of @xmath141 : @xmath159 it is seen from this representation that @xmath160 .",
    "the advantage of tail v@r over v@r is that it takes into account the heaviness of the @xmath17-tail ( see figure  1 ) .",
    "kusuoka  @xcite proved that on @xmath74 , @xmath13 is the smallest law invariant coherent risk measure that dominates @xmath23 ( the proof can also be found in  ( * ? ? ?",
    "4.61 ) or  ( * ? ?",
    "* th .  1.48 ) ) .",
    "this suggests an opinion that tail v@r might be the most important subclass of coherent risk measures .",
    "however , there exists a risk measure , which is in our opinion much better than tail v@r .",
    "this is the risk measure of the next example .",
    "@xmath97    ( 150,60)(-35,-27.5 ) ( -10,-0.2 ) ( -15,0)(1,0)60 ( 15,0)(0,1)30 ( 55,0)(1,0)50 ( 75,0)(0,1)30 ( 10.2,0)(0,1)2 ( 70.2,0)(0,1)5 ( 8,-4)@xmath149 ( 68,-4)@xmath149 ( -12,-20 )    [ crm6 ] let @xmath161 be a probability measure on @xmath162 $ ] . _ weighted v@r with the weighting measure  @xmath161 _ ( the term _ spectral risk measure _ is also used ) is the coherent risk measure corresponding to the coherent utility function @xmath163}u_{\\lambda}(x)\\mu(d{\\lambda}),\\ ] ] where @xmath164 is understood as @xmath165 with the convention @xmath127 .",
    "( throughout the paper , all the integrals are understood in this way . )",
    "one can check that @xmath166 is indeed a coherent utility ( see  ( * ? ? ?",
    "3 ) for details ) .",
    "the measure @xmath161 reflects the risk aversion of  @xmath167 : the more is the mass of @xmath161 attributed to the left part of @xmath162 $ ] , the more risk averse is  @xmath167 .",
    "let us give two arguments in favor of weighted v@r over tail v@r :    ( financial argument ) tail v@r of order @xmath17 takes into consideration only the of the distribution of @xmath7 ; thus , two distributions with the same @xmath17-tail will be assessed by this measure in the same way , although one of them might be clearly better than the other ( see figure  2 ) . on the other hand , if the right endpoint of the support of  @xmath161 is  @xmath168 , then @xmath167 depends on the whole distribution of  @xmath7 .",
    "the paper  @xcite provides some further financial arguments in favor of weighted v@r .",
    "( mathematical argument ) if the support of  @xmath161 is the whole @xmath169 $ ] , then @xmath167 possesses some nice properties that are not shared by @xmath13 .",
    "in particular , if @xmath7 and @xmath30 are not comonotone ( for the definition , see section  [ rc ] ) , then @xmath170 ( the proof can be found in  ( * ? ? ?",
    "* sect .  5 ) , where this was called the _ strict diversification property _ ) .",
    "this property is important because it leads to the uniqueness of a solution of several optimization problems based on weighted v@r ( see  ( * ? ? ?",
    "* sect .  5 ) ) .    to put it briefly , weighted",
    "v@r is `` smoother '' than tail v@r .",
    "( 150,60)(-26,-27.5 ) ( 0,-0.2 ) ( -5,0)(1,0)50 ( 15,0)(0,1)30 ( 55,0)(1,0)60 ( 75,0)(0,1)30 ( 10.2,0)(0,1)4 ( 70.2,0)(0,1)4 ( 8,-4)@xmath149 ( 68,-4)@xmath149 ( -2,-20 )    weighted v@r is law invariant because tail v@r possesses this property .",
    "kusuoka  @xcite proved that on @xmath74 the class of weighted v@rs is exactly the class of law invariant coherent risk measures satisfying the additional property of _ comonotonicity _ , which means that @xmath171 for any comonotone ( the definition is recalled in section  [ rc ] ) random variables @xmath7 and  @xmath30 ( the proof can also be found in  ( * ? ? ?",
    "* th .  4.87 ) or  ( * ? ?",
    "* th .  1.58 ) ) .",
    "let us now provide several equivalent representations of weighted v@r .",
    "it follows from   that @xmath172}{\\lambda}^{-1}\\int_0^{\\lambda}q_x(x)dx\\mu(d{\\lambda})\\\\ = \\int_0 ^ 1 q_x(x)\\psi_\\mu(x)dx,\\ ] ] where @xmath173}{\\lambda}^{-1}\\mu(d{\\lambda } ) , \\quad x\\in[0,1].\\ ] ] the last formula establishes a one - to - one correspondence between the left - continuous decreasing functions @xmath174\\to[0,1]$ ] with @xmath175}\\psi(x)dx=1 $ ] and the probability measures on @xmath162 $ ] .    in particular ,",
    "let @xmath176 and @xmath177 .",
    "let @xmath178 be the values @xmath179 in the increasing order .",
    "define @xmath180 through the equality @xmath181 .",
    "then @xmath182 where @xmath183 .",
    "this formula yields a simple procedure of the empirical estimation of  @xmath184 .    in order to provide another representation of @xmath166 , consider the function @xmath185}{\\lambda}^{-1}\\mu(d{\\lambda})dy , \\quad x\\in(0,1].\\ ] ] it is easy to see that @xmath186\\to[0,1]$ ] is increasing , concave , continuous , @xmath187 , and @xmath188 .",
    "in fact , establishes a one - to - one correspondence between the functions with these properties and the probability measures  @xmath161 on @xmath162 $ ] ( for details , see  ( * ? ? ? * lem .",
    "4.63 ) or  ( * ? ? ?",
    "the inverse map @xmath189 is given by @xmath190 , where @xmath191 is the second derivative of @xmath192 taken in the sense of distributions , i.e. it is the measure on @xmath162 $ ] defined by @xmath193):=\\psi'_+(b)-\\psi'_+(a)$ ] , where @xmath194 is the right - hand derivative .",
    "let @xmath151 be the distribution function of  @xmath7 .",
    "as the function @xmath195 is constant on the intervals of the form @xmath196 , we can derive from   the following representation : @xmath197 where @xmath30 is a random variable with the distribution function @xmath198 .",
    "this representation provides a convenient tool for designing particular risk measures .",
    "let us remark that the functionals of the form   were considered by actuaries under the name _ distorted measures _ already in the early 90s , i.e. before the papers of artzner , delbaen , eber , and heath ; see , for example ,  @xcite , @xcite ( see also the paper  @xcite , which appeared at the same time as  @xcite ) .",
    "if @xmath7 has a continuous distribution , we get from   one more representation : @xmath199 where @xmath200 .",
    "note that @xmath201}\\int_0^{\\lambda}{\\lambda}^{-1}dx\\mu(d{\\lambda } ) = 1,\\ ] ] so that @xmath202 is a probability measure . as @xmath203 is decreasing , this measure attributes more mass to the outcomes corresponding to low values of  @xmath7 .",
    "thus , @xmath202 reflects the risk aversion of an agent who possesses the position that yields the p&l  @xmath7 .",
    "the determining set @xmath204 of @xmath166 admits the following representation : @xmath205 where @xmath206}(\\psi_\\mu(y)-xy),\\quad x\\in{\\mathbb{r}}_+\\ ] ] ( see  ( * ? ? ?",
    "note that @xmath207 is continuous , decreasing , convex , @xmath208 , @xmath209 for @xmath210}{\\lambda}^{-1}d\\mu$ ] , and @xmath211 for @xmath212}{\\lambda}^{-1}d\\mu$ ] .",
    "( 150,65)(-18,-17.5 ) ( -0.4,-0.3 ) ( 0,0)(1,0)25 ( 0,0)(0,1)45 ( -0.5,40)(1,0)1 ( 20,-0.5)(0,1)1 ( -15,39 ) ( 19,-4)@xmath168 ( -1,-4)@xmath213 ( 24,-3)@xmath214 ( 4,17)@xmath215 ( 35,0)(1,0)25 ( 35,0)(0,1)25 ( 55,0.5)(0,2)10(0,1)1 ( 35.5,20)(2,0)10(1,0)1 ( 32,19)@xmath168 ( 34,-4)@xmath213 ( 54,-4)@xmath168 ( 59,-3)@xmath214 ( 37.5,3.5 ) ( 36,15)@xmath216 ( 70,0)(1,0)55 ( 70,0)(0,1)25 ( 69.5,20)(1,0)1 ( 110,-0.5)(0,1)1 ( 67,19)@xmath168 ( 69,-4)@xmath213 ( 124,-3)@xmath214 ( 103,-4 ) ( 84,10)@xmath217 ( 28,-15)*figure  3 . *",
    "the form of @xmath215 , @xmath216 , and @xmath217    one more representation of @xmath204 is : @xmath218\\bigr\\}.\\end{aligned}\\ ] ] it was obtained in  @xcite ( the proof can also be found in  ( * ? ? ?",
    "* th .  4.73 ) or  ( * ? ?",
    "* th .  1.53 ) ) .",
    "it is seen from this representation that @xmath219    moreover , it is easy to see that @xmath220 where the notation @xmath221 means that @xmath161 stochastically dominates @xmath222 , i.e. their distribution functions satisfy @xmath223 . in order to prove  , it is sufficient to notice that @xmath141 is increasing in  @xmath17 and @xmath224 , where @xmath225 is a random variable on some space @xmath226 with @xmath227 .",
    "one should also use the following well - known fact ( see  ( * ? ? ? *",
    "a ) ) : @xmath221 if and only on some space there exist @xmath228 with @xmath227 , @xmath229 .    for more information on weighted v@r ,",
    "see  @xcite , @xcite , @xcite , @xcite .",
    "@xmath97    weighted v@r is a particular case of the more general class of risk measures that is described in the next example .",
    "[ crm7 ] a risk measure @xmath37 is _ law invariant _ if @xmath230 whenever @xmath104 .",
    "kusuoka  @xcite proved that a coherent risk measure @xmath37 on @xmath74 is law invariant if and only if it has the form @xmath231 with some set @xmath232 of probability measures on @xmath162 $ ] ( the proof can also be found in  ( * ? ? ?",
    "* cor .  4.58 ) or  ( * ? ? ?",
    "* cor .  1.45 ) ) .",
    "theorem  a.1 extends this result to risk measures on  @xmath72 .",
    "@xmath97    an interesting two - parameter family of coherent risk measures is provided by the example below .",
    "[ crm8 ] let @xmath233 $ ] and @xmath234 $ ] .",
    "consider the set @xmath235 where @xmath236 and @xmath237 .",
    "then the corresponding coherent risk measure has the form @xmath238 ( see  ( * ? ? ?",
    "* sect .  4 ) ) .",
    "in particular , if @xmath239 , @xmath240 , and @xmath241 , then @xmath10 is the semivariance of  @xmath7 .",
    "semivariance was proposed by markowitz  @xcite as a substitute for variance .",
    "its advantage is that it measures really risk ( i.e. the downfall ) ; its disadvantage is that it is less convenient analytically than variance .",
    "@xmath97    the moment - based risk measures are law invariant , but they do not belong to the class of weighted v@rs , which is a very convenient class .",
    "weighted v@rs are parametrized by the probability measures  @xmath161 on @xmath162 $ ] , which is a huge class . for the practical purposes",
    ", one needs to select a convenient finite - parameter subclass of weighted v@rs .",
    "the most natural parametric family of probability measures on @xmath169 $ ] is the family of beta distributions .",
    "it turns out that the family of corresponding weighted v@rs admits a very natural interpretation and a very simple estimation procedure .",
    "we call these measures beta v@rs in accordance with beta distributions .",
    "[ crm9 ] let @xmath242 , @xmath243 .",
    "_ beta v@r with parameters @xmath244 _ is the weighted v@r with the weighting measure @xmath245.\\ ] ] this risk measure will be denoted as @xmath28 and the corresponding coherent utility will be denoted as @xmath246 .",
    "it follows from   that @xmath247 furthermore , @xmath248{}{\\delta}_0 & \\;\\longrightarrow\\ ; \\rho_{{\\alpha},{\\beta}}(x){\\xrightarrow}[{\\alpha}\\to\\infty ] { } -{\\mathop{\\rm essinf}}_\\omega x(\\omega),\\\\ \\mu_{{\\alpha},{\\beta}}{\\xrightarrow}[{\\beta}{\\uparrow}{\\alpha}]{}{\\delta}_1 & \\;\\longrightarrow\\ ; \\rho_{{\\alpha},{\\beta}}(x){\\xrightarrow}[{\\beta}{\\uparrow}{\\alpha}]{}-{\\mathsf{e}}x,\\end{aligned}\\ ] ] where @xmath249 denotes the delta - mass concentrated at  @xmath250 .",
    "in particular , these relations show that we can redefine @xmath251 as @xmath252 .",
    "suppose now that @xmath253 .",
    "let @xmath20 be independent copies of  @xmath7 , @xmath26 be the corresponding order statistics , and @xmath225 be an independent uniformly distributed on @xmath254 random variable .",
    "let us prove that @xmath255.\\ ] ] the second equality is obvious , so we should prove only the first one .",
    "the random variables @xmath256 can be realized as @xmath257 , where @xmath151 is the distribution function of  @xmath7 and @xmath258 are independent uniformly distributed on @xmath169 $ ] random variables .",
    "let @xmath259 denote their order statistics .",
    "we have ( see  ( * ? ? ?",
    "* ch .  1 ,",
    "  7 ) ) @xmath260 so that @xmath261 and @xmath262 for the function @xmath263 , we have @xmath264 moreover , the functions @xmath265 and @xmath266 coincide at  0 and at  1 .",
    "consequently , these functions are equal , and therefore , @xmath267 recalling  , we obtain  .",
    "it is seen from the calculations given above that for beta v@r the function @xmath268 has the form @xmath269    let us remark that , according to  , tail v@r admits the following representation : @xmath270 , where @xmath225 is a random variable on some space @xmath226 with the uniform distribution on @xmath271 $ ] .",
    "formula   can be rewritten as follows : @xmath272 , where @xmath273 is a random variable distributed according to the empirical distribution constructed by @xmath20 , @xmath225 is an independent random variable with the uniform distribution on @xmath274 $ ] , and @xmath275 means the averaging over empirical distributions .",
    "@xmath97    an important one - parameter family of coherent risk measures is obtained from beta v@r by fixing the value @xmath276 .",
    "[ crm10 ] let @xmath277 .",
    "_ alpha v@r of order @xmath19 _ is beta v@r of order @xmath278 .",
    "it is seen from   that @xmath19 measures the risk aversion of  @xmath21 .",
    "furthermore , it follows from   that , for @xmath279 , @xmath280 where @xmath20 are independent copies of  @xmath7 .",
    "@xmath97    the classes of risk measures described by examples  [ crm5][crm10 ] are related by the following diagram :    [ cols=\"^,^,^,^,^,^,^ \" , ]     in our opinion , the best classes are : weighted v@r , beta v@r , and alpha v@r .",
    "all the empirical estimation procedures considered in the paper will be provided for these three classes .    *",
    "3 . further examples . *",
    "coherent risk measures are primarily intended to assess the risk of non - gaussian p&ls . however , as an example , it is interesting to look at their values in the gaussian case .",
    "[ crm11 ] * ( i ) * let @xmath86 be a law invariant coherent utility that is finite on gaussian random variables .",
    "it is easy to see that then there exists @xmath281 such that , for any gaussian random variable  @xmath7 with mean  @xmath282 and variance  @xmath283 , we have @xmath284 . in particular , if @xmath7 is a @xmath285-dimensional gaussian random vector with mean  0 and covariance matrix  @xmath286 , then @xmath287 , @xmath288 .    * ( ii ) * for tail v@r , we get an explicit form of the constant  @xmath289 : @xmath290 where @xmath149 is the @xmath17-quantile of the standard normal distribution ( in order to check the second equality , one should consider separately the cases @xmath291 and @xmath292 ) .",
    "( 150,67.5)(-34,-15 ) ( -7.5,-4.4 ) ( 0,0)(1,0)80 ( 0,0)(0,1)50 ( 79,-3)@xmath17 ( 25,20)@xmath293 ( 15,-12)*figure  4 .",
    "* the form of @xmath293    * ( iii ) * for beta v@r , we have from  ( ii ) : @xmath294    ( 150,67.5)(-34,-15 ) ( -7.7,-104.5 ) ( 0,0)(1,0)80 ( 0,0)(0,1)50 ( 79,-3)@xmath19 ( 72,27 ) ( 72,30.5 ) ( 72,34 ) ( 72,38 ) ( 72,43.5 ) ( 14,-12)*figure  5 . *",
    "the form of @xmath295    let us also give a nice credit risk example , which illustrates the effect of coherent risk diversification achieved in large portfolios .",
    "the example is borrowed from  @xcite .",
    "[ crm12 ] let @xmath161 be a measure on @xmath162 $ ] such that @xmath175}{\\lambda}^{-1}\\mu(d{\\lambda})<\\infty$ ] ( for example , the weighting measures of tail v@r , beta v@r with @xmath296 , and alpha v@r satisfy this condition ) .",
    "let @xmath297 be independent identically distributed integrable random variables .",
    "set @xmath298 . by the law of large numbers , @xmath299 .",
    "consequently , @xmath300 for any @xmath12 $ ] . using the estimate @xmath301 and the lebesgue dominated convergence theorem",
    ", we get @xmath302}u_{\\lambda}\\bigl(\\frac{s_n}{n}\\bigr)\\mu(d{\\lambda } ) { \\xrightarrow}[n\\to\\infty]{}\\int_{(0,1]}u_{\\lambda}({\\mathsf{e}}x)\\mu(d{\\lambda } ) = { \\mathsf{e}}x.\\ ] ] this result admits the following interpretation . if a firm gives many loans of size  @xmath303 to independent identical customers ( so that the @xmath304-th customer returns back the random amount  @xmath305 ) , then the firm is on the safe side provided that @xmath306 .",
    "@xmath97    * 4 . empirical estimation .",
    "* here we will describe procedures for the empirical estimation of alpha v@r , beta v@r , and weighted v@r , which serve as coherent counterparts of the historic v@r estimation ( see  ( * ? ? ?",
    "* sect .  6 ) ) .",
    "let @xmath7 be the increment of the value of some portfolio over the unit time period  @xmath307 .",
    "in order to estimate alpha v@r with @xmath279 , one should first choose the number of trials @xmath308 and generate independent draws @xmath309 of  @xmath7 .",
    "this can be done by one of the following techniques :    each @xmath310 is drawn uniformly from the recent @xmath311 realizations @xmath179 of  @xmath7 .",
    "for example , if @xmath307 is one day ( which is a typical choice ) , these are @xmath311 recent daily increments of the value of the portfolio under consideration .",
    "each @xmath310 is drawn from recent @xmath311 realizations @xmath179 of  @xmath7 , according to a probability measure  @xmath312 on @xmath313 .",
    "a natural example is : @xmath314 , so that @xmath315 is the increment of the portfolio s value over the interval @xmath316 $ ] , where 0 is the current time instant ; @xmath312 is the geometric distribution with a parameter  @xmath17 .",
    "this method enables one to put more mass on recent realizations of  @xmath7 .",
    "it is at the basis of the _ weighted historical simulation _ ( see  ( * ? ? ?",
    "typically , @xmath17 is chosen between 0.95 and 0.99 .",
    "each @xmath310 might be generated using the bootstrap method , i.e. we split the time axis into small intervals of length @xmath317 and create each @xmath310 as a sum of the increments of the portfolio s value over @xmath304 randomly chosen small intervals .",
    "the bootstrap method might be combined with the weighting described above , i.e. we take recent small intervals with a higher probability than old ones .",
    "having generated @xmath310 , one should calculate the array @xmath318 according to  , an empirical estimate of @xmath22 is provided by @xmath319    in order to estimate beta v@r with @xmath253 , one should generate @xmath310 similarly .",
    "let @xmath320 be the numbers @xmath321 such that the corresponding @xmath310 stand at the first @xmath322 places ( in the increasing order ) among @xmath323 . according to  ,",
    "an empirical estimate of @xmath324 is provided by @xmath325    in order to estimate weighted v@r , one should fix a data set @xmath179 and a measure  @xmath312 on @xmath313 .",
    "this can be done by one of the following techniques :    the values @xmath179 are recent @xmath311 realizations of  @xmath7 .",
    "the values @xmath179 are obtained through the bootstrap technique , i.e. each @xmath315 is a sum of the increments of the portfolio s value over randomly chosen small intervals ; @xmath312 is uniform .",
    "let @xmath178 be the values @xmath179 in the increasing order .",
    "define @xmath180 through the equality @xmath181 . according to  ,",
    "an empirical estimate of @xmath326 is provided by @xmath327 where @xmath328 and @xmath215 is given by  .",
    "an advantage of weighted v@r over alpha v@r and beta v@r is that it is a wider class . however , beta v@r is already rather a flexible family .",
    "a big advantage of alpha v@r and beta v@r is that their empirical estimation procedure does not require the data ordering ( the number of operations required to order the data set @xmath179 is @xmath329 ; this is a particularly unpleasant number for @xmath314 , which is one of typical possible choices in estimating alpha v@r and beta v@r ) .",
    "note that , for estimating v@r from a data set of size  @xmath311 , one needs to order the time series , and the number of operations required grows quadratically in  @xmath311 .",
    "thus , alpha v@r and beta v@r are not only much wiser than v@r ; they are also estimated faster !",
    "* 1 . @xmath135-spaces . *",
    "let @xmath73 be a probability space and @xmath86 be a coherent utility with the determining set  @xmath8 .    for the theorems below , we need to define the @xmath135-spaces associated with a coherent risk measure ( they were introduced in  @xcite ) .",
    "the _ weak _ and _ strong @xmath135-spaces _ are @xmath330 clearly , @xmath331 . in general , this inclusion might be strict .",
    "indeed , let @xmath332 be a positive unbounded random variable with @xmath333 and let @xmath334 .",
    "then @xmath335 , but @xmath336 . however , as shown by the examples below , in most natural situations these two spaces coincide and have a very simple form .",
    "[ fr1 ] * ( i ) * if @xmath337 is a singleton , then @xmath338 , which motivates the notation .    *",
    "( ii ) * for weighted v@r , we have @xmath339 ( see  ( * ? ? ?",
    "* subsect .  2.2 ) ) , so we can denote this space simply by @xmath340 .",
    "it is clear from   that @xmath341 , so that @xmath342 ( throughout the paper , @xmath135 stands for @xmath343 ) . in general",
    ", this inclusion can be strict .",
    "however , if @xmath175}{\\lambda}^{-1}\\mu(d{\\lambda})<\\infty$ ] ( for example , the weighting measures of tail v@r , beta v@r with @xmath296 , and alpha v@r satisfy this condition ) , then it is seen from   that all the densities from  @xmath204 are bounded by @xmath175}{\\lambda}^{-1}\\mu(d{\\lambda})$ ] , so that @xmath344 .    * ( iii ) * if @xmath37 is the moment - based risk measure of example  [ crm8 ] with @xmath345 , then clearly @xmath346 and @xmath347 , so that @xmath348 .  @xmath97",
    "* 2 . factor risk .",
    "* let @xmath30 be a random variable ( resp .",
    ", random vector ) meaning the increment over the unit time period of some market factor ( resp . ,",
    "several market factors ) .",
    "[ fr2 ] the _ factor utility _",
    "is @xmath349{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathsf{e}}({\\mathcal{d}}{\\hspace{0.3mm}|\\hspace{0.3mm}}y)}{\\mathsf{e}}_{\\mathsf{q}}x,\\ ] ] where @xmath350 .",
    "the _ factor risk _ is @xmath351 .",
    "` remarks ` .",
    "( i ) as @xmath8 is convex , @xmath352 is also convex .",
    "\\(ii ) if @xmath8 is convex and @xmath135-closed , then @xmath352 is not necessarily @xmath135-closed . as an example , consider @xmath353 ^ 2 $ ] endowed with the lebesgue measure and let @xmath354 where @xmath355 let @xmath356 .",
    "then @xmath357{l^1}2i(x_1>1/2 ) \\notin{\\mathsf{e}}({\\mathcal{d}}{\\hspace{0.3mm}|\\hspace{0.3mm}}y).\\ ] ]    \\(iii ) if @xmath8 is convex , @xmath135-closed , and uniformly integrable , then @xmath352 is also convex , @xmath135-closed , and uniformly integrable .",
    "indeed , let @xmath358 be such that @xmath359 . by komlos principle of subsequences ( see  @xcite ) , we can select a sequence @xmath360 such that @xmath361 .",
    "as @xmath8 is convex and uniformly integrable , the convergence holds in @xmath135 and @xmath362 .",
    "then @xmath363 , so that @xmath352 is @xmath135-closed .",
    "its uniform integrability is a well - known fact .",
    "@xmath97    [ fr3 ] for @xmath364 , we have @xmath365    this theorem follows from    [ fr4 ] for @xmath364 and @xmath366 , we have @xmath367 .    `",
    "we can write @xmath368 , where @xmath369 , @xmath370 , @xmath371 . by the definition of @xmath135-spaces , @xmath372 and @xmath373 . the equality @xmath374 and the estimates @xmath375 yield the desired statement",
    ".  @xmath97    recall that a probability space @xmath73 is called _ atomless _ if for any @xmath376 with @xmath377 , there exist @xmath378 such that @xmath379 and @xmath380 .",
    "[ fr5 ] suppose that @xmath73 is atomless and @xmath86 is law invariant .",
    "then , for @xmath381 , we have @xmath365    ` proof ` . by corollary",
    "a.2 , @xmath382 .",
    "furthermore , it is clear from   that @xmath341 for any  @xmath161 , so that , by theorem  a.1 , @xmath383 and @xmath384 .",
    "now , the result follows from theorem  [ fr3 ] .",
    "@xmath97    [ fr6 ] let @xmath86 be a law invariant coherent utility that is finite on gaussian random variables .",
    "let @xmath385 have a jointly gaussian distribution .",
    "denote @xmath386 , @xmath387 .",
    "we can represent  @xmath7 as @xmath388 where @xmath389 and @xmath225 is independent of  @xmath30 .",
    "then @xmath390 where @xmath391 denotes the linear space spanned by @xmath392 , @xmath393 denotes the projection , and @xmath289 is provided by example  [ crm11 ]  ( i ) .",
    "let us give an expression for @xmath394 in the matrix form .",
    "denote @xmath395 and let @xmath286 be the covariance matrix of  @xmath30 .",
    "let @xmath303 be the image of  @xmath396 under the map @xmath397 .",
    "note that @xmath398 .",
    "the inverse @xmath399 is correctly defined .",
    "the vector @xmath400 is found from the condition @xmath401 which shows that @xmath402 .",
    "we have @xmath403 as a result , @xmath404 in particular , if @xmath30 is one - dimensional , then @xmath405    @xmath406    from the financial point of view , @xmath35 means the risk of  @xmath7 in view of the uncertainty contained in  @xmath30 .",
    "so , we could expect that passing from @xmath30 to a compound random vector @xmath407 would increase  @xmath36 . the theorem below states that this is indeed true for law invariant risk measures .    [ fr7 ]",
    "suppose that @xmath73 is atomless and @xmath86 is law invariant .",
    "then , for any random variable  @xmath7 and any random vectors @xmath408 , we have @xmath409    ` proof ` . by theorem",
    "a.1 , @xmath410 with some set @xmath232 of probability measures on @xmath162 $ ] .",
    "it is seen from   and the jensen inequality that @xmath411 and the similar representation is true for @xmath412 .",
    "now , it is clear from the jensen inequality that @xmath413 , so that @xmath414 , and the result follows .",
    "@xmath97    ` remark ` .",
    "coherent risk measures @xmath37 with the property @xmath415 for any  @xmath7 and any sub-@xmath416-field @xmath417 of  @xmath100 are called _ dilatation monotonous _ ( this property was introduced by j.  leitner  @xcite ) .",
    "thus , theorems  [ fr3 ] and  [ fr7 ] show that on an atomless space any law invariant risk measure is dilatation monotonous .",
    "@xmath97    the example below shows that the condition of law invariance is important in theorem  [ fr7 ] .",
    "[ fr8 ] let @xmath8 consist of a unique measure  @xmath58 .",
    "take @xmath418 and let @xmath419 be such that @xmath420 .",
    "then @xmath421 , while @xmath422 .",
    "clearly , the inequality @xmath423 might be violated .",
    "@xmath97    * 3 . factor model .",
    "* the question that immediately arises in connection with the factor risks is : how close is @xmath394 to @xmath424 ?",
    "below we provide a sufficient condition for the closeness between @xmath394 and @xmath424",
    ". this will be done within the framework of the factor model , which is very popular in statistics .",
    "let @xmath86 be a law invariant coherent utility that is finite on gaussian random variables and @xmath425 be a random vector whose components belong to @xmath426 .",
    "we will assume that @xmath427 for any @xmath428 .",
    "let @xmath429 where @xmath430 is @xmath431-matrix and @xmath432 , where @xmath433 are independent and @xmath434 is gaussian with mean  0 and variance @xmath435 .",
    "we will assume that there exists a sequence @xmath436 such that @xmath437 and @xmath438{}b^m , \\quad m=1,\\dots , m,\\\\ & a_n^{-2}\\sum_{k=1}^n({\\sigma}_n^k)^2{\\xrightarrow}[n\\to\\infty]{}0\\end{aligned}\\ ] ] with @xmath439 .",
    "[ fr9 ] we have @xmath440{}1.\\ ] ]    ` proof ` .",
    "we have @xmath441 where @xmath442 , @xmath49 , and @xmath443 is gaussian with mean  0 and variance @xmath444 .",
    "moreover , @xmath443 is independent of  @xmath151 .",
    "let @xmath445 be a gaussian random variable with mean  0 and variance  1 that is independent of  @xmath151 .",
    "in view of the law invariance of  @xmath86 , @xmath446 consider the set @xmath447 , where `` @xmath448 '' denotes the closure and @xmath8 is the determining set of  @xmath86 . in view of the inclusions @xmath449 , @xmath450 ,",
    "the set @xmath451 is a convex compact in @xmath452 ( in the terminology of  @xcite , @xmath451 is the _ generator _ of @xmath453 and  @xmath86 )",
    ". then @xmath454{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathcal{d}}}{\\mathsf{e}}_{\\mathsf{q}}({\\langle}b_n , f{\\rangle}+{\\sigma}_n\\eta ) = { \\mathop{\\rm inf\\rule[-0.8mm]{0mm}{1mm}}}_{x\\in g}{\\langle}(b_n,{\\sigma}_n),x{\\rangle}\\\\ & { \\xrightarrow}[n\\to\\infty]{}{\\mathop{\\rm inf\\rule[-0.8mm]{0mm}{1mm}}}_{x\\in g}{\\langle}(b,0),x{\\rangle}={\\mathop{\\rm inf\\rule[-0.8mm]{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathcal{d}}}{\\mathsf{e}}_{\\mathsf{q}}{\\langle}b , f{\\rangle}=u({\\langle}b , f{\\rangle}).\\end{aligned}\\ ] ] in a similar way we prove that @xmath455{}u({\\langle}b , f{\\rangle}).\\ ] ] to complete the proof , it is sufficient to note that @xmath427 .  @xmath97    * 4 . multifactor risk . * the previous theorem shows that in order to assess the risk @xmath10 , one can take the main factors @xmath456 driving risk , and then @xmath457 . the question arises : what is the relationship between @xmath458 and @xmath459 ?",
    "first , we provide a positive statement .",
    "[ fr10 ] assume that @xmath456 are independent and @xmath460 , where @xmath461 is @xmath462-measurable , @xmath463 , and @xmath464 .",
    "then @xmath465    ` proof ` .",
    "we have @xmath466 and the result follows from the subadditivity property of  @xmath37 .",
    "@xmath97    the conditions of the proposition are unrealistic because different factors are correlated .",
    "this might lead to violation of   as shown by the example below .",
    "let @xmath467 be a gaussian random vector with mean  0 and covariance matrix @xmath468 take @xmath469 .",
    "let @xmath37 be a law invariant coherent risk measure that is finite on gaussian random variables .",
    "then @xmath470 where @xmath289 is provided by example  [ crm11 ]  ( i ) .",
    "on the other hand , by example  [ fr6 ] , @xmath471 if @xmath472 is small enough , then the inequality @xmath473 is violated .",
    "@xmath97    ( 150,56)(-70,-32.5 ) ( -15,-10 ) ( 31,9)@xmath474 ( 31,-11)@xmath475 ( -1.5,21)@xmath7 ( -30,-25 )    the effect described in this example has the following financial background .",
    "suppose that we have several correlated factors @xmath456 and a portfolio consisting of  @xmath476 parts , i.e. @xmath477 , where the risk of the @xmath282-th part is driven mainly by the @xmath282-th factor",
    ". then @xmath461 is correlated with @xmath478 for @xmath479 simply because @xmath462 and @xmath478 are correlated .",
    "thus , when summing up @xmath480 over  @xmath282 , we are calculating the factor loading of @xmath462 in @xmath461 once through the @xmath282-th factor risk and then several times more through the other correlated factor risks . this might lead to a significant increment as well as a significant reduction of the estimated risk ( which was described by example  [ fr11 ] ) .",
    "in this situation , the right way to estimate @xmath10 is to take @xmath481 . indeed ,",
    "if each @xmath461 corresponds to a big portfolio , then above results tell us that @xmath482 , and then @xmath483 another pleasant feature of this technique is that we estimate the @xmath282-th factor risk only for a part of the portfolio rather than the whole portfolio , which accelerates the computation speed .",
    "however , it might happen that we can not split a portfolio in several groups such that the risk of each group is affected by one factor only ( for example , the risk of credit derivatives is affected by the whole yield curve ) .",
    "but then we might combine the one - factor and the multifactor techniques as follows .",
    "suppose that we can split the factors into several groups ( thus we again have @xmath456 , but now these random variables are multidimensional ) and split the portfolio into  @xmath476 parts , i.e. @xmath477 , so that the risk of the @xmath282-th part is driven mainly by the @xmath282-th group of factors",
    ". then we can assess the risk of the portfolio as @xmath481 .",
    "* 5 . empirical estimation .",
    "* in view of theorem  [ fr3 ] , the empirical estimation of @xmath35 reduces to finding the function @xmath70 and then applying the procedures described at the end of section  [ crm ] to @xmath484 .",
    "however , for factor risks we can use one more convenient method of the choice of data .",
    "suppose that @xmath30 is one - dimensional and let @xmath416 be the current volatility of  @xmath30 .",
    "it might be estimated through one of numerous well - known methods ; in particular , @xmath416 might be the implied volatility .",
    "it is a widely accepted idea that volatility serves as the speed of growth of the inner time ( known also as the business or operational time ) for  @xmath30 . in other words ,",
    "if the current volatility is  @xmath416 , then @xmath30 is currently oscillating at the speed  @xmath283 .",
    "following this idea , we can take as the data for  @xmath30 the values @xmath485 , where @xmath486 is the increment of  @xmath30 over the time interval @xmath487 $ ] and @xmath307 is the unit time period . here",
    "it is reasonable to take standardized time series for  @xmath30 rather than the ordinary one : we calculate empirically the integrated volatility and take its inverse as the time change to obtain standardized time series from the ordinary one .",
    "this approach enables one    to use large data sets ;    to capture volatility predictions immediately .",
    "if @xmath307 is one day ( which is a typical choice ) , then @xmath488 would be a non - integer number of days , which is not very convenient .",
    "this can be overcome as follows .",
    "we choose a large number  @xmath371 and split the time axis into small intervals of length @xmath317 .",
    "then we approximate @xmath283 by a rational number @xmath489 and generate each @xmath486 as a sum of increments of  @xmath30 over @xmath282 randomly chosen small intervals . in other words , this is a combination of the time change procedure with the bootstrap technique .    instead of the time change procedure described above , one can also use the classical scaling procedure , which is at the basis of the _ filtered historical simulation _ ( see  ( * ? ? ?",
    "namely , instead of altering the time step for  @xmath486 , we keep the same time step  @xmath307 , but multiply each  @xmath486 by the current volatility  @xmath416 .",
    "as above , it is reasonable to take standardized time series for  @xmath30 rather than the ordinary one : we divide each observed increment of  @xmath30 by its volatility estimated through one of standard techniques ( for example , garch ) .",
    "let us remark that both the time change and the scaling work only for one - dimensional @xmath30s because if @xmath30 is multidimensional , its different components have different volatilities .",
    "this is a big advantage of one - factor risks .",
    "* 1 . problem . *",
    "let @xmath73 be a probability space and @xmath490 be coherent utilities with the determining sets @xmath491 .",
    "a particular example we have in mind is @xmath492 , where @xmath456 are the main factors driving the risk of a portfolio .",
    "let @xmath493 be the p&ls produced by traded assets over the unit time period , so that the space of possible p&ls attained by various investment strategies is @xmath494 , where @xmath495 .",
    "we will assume that @xmath496 for any @xmath497 .",
    "this condition means that the risk of any trade is strictly positive and is known as the _ no good deals _ condition ( see  @xcite ) .",
    "let @xmath498 be the vector of rewards for @xmath499 .",
    "one might think of  @xmath500 as the vector of expectations @xmath501 . however , this is not the only interpretation of  @xmath500 . in general , we mean by  @xmath500 the vector of subjective assessments by some agent of the profitability of the assets @xmath499 . in this case",
    "@xmath500 need not be related to @xmath502 , and @xmath502 can be equal to zero .",
    "we will consider the markowitz - type optimization problem , risk being measured not as variance , but rather as the vector of risks : @xmath503 where @xmath504 are fixed risk limits .",
    "* 2 . geometric solution .",
    "* the paper  ( * ? ? ?",
    "* subsect .",
    "2.2 ) contains a geometric solution of this problem with @xmath505 . here",
    "we will present a similar geometric solution for an arbitrary  @xmath476 .",
    "let us introduce the notation @xmath506 note that @xmath507 are convex compacts in @xmath508 . according to the terminology of  @xcite",
    ", @xmath509 is the _ generator _ of @xmath7 and @xmath510 .",
    "the role of this set is seen from the equality @xmath511{0mm}{1mm}}}_{x\\in g^m}{\\langle}h , x{\\rangle},\\quad m=1,\\dots , m.\\ ] ] the right - hand side is the classical object of convex analysis termed the _ support function _ of the set  @xmath509 . the notion of the generator was found to be very convenient for the geometric solutions of various problems like capital allocation , portfolio optimization , pricing , and equilibrium ( see  @xcite , @xcite ) . as @xmath496 for any @xmath497 , the point  0 belongs to the interior of  @xmath451 .",
    "let @xmath311 be the intersection of the ray @xmath512 with the border of  @xmath451 .",
    "denote by @xmath38 the set of inner normals to  @xmath451 at the point  @xmath311 ( typically , @xmath38 is a ray ) .",
    "( 150,92.5)(-39,-30 ) ( 0,0 ) ( 22,26.5)@xmath451 ( 56,32.8)@xmath513 ( 48,4.5)@xmath514 ( 66.5,38.5)@xmath515 ( 53.7,-6)@xmath516 ( 27.5,16.5)@xmath517 ( 25.5,2)@xmath311 ( 41.2,21)@xmath213 ( 43.5,25)@xmath500 ( 5,-25 )    [ po1 ] the set of solutions of problem   is @xmath518 and the maximal @xmath519 is @xmath520 .",
    "` remark ` .",
    "note that @xmath38 is a non - empty cone , so that @xmath521 .",
    "furthermore , @xmath522 .",
    "@xmath97    ` proof of theorem  [ po1 ] . ` using  , we can write @xmath523{0mm}{1mm}}}\\limits_{x\\in g^m}{\\langle}h , x{\\rangle}\\ge - c^m \\end{cases } \\hspace{-3mm}{\\longleftrightarrow}\\ ; \\begin{cases } { \\langle}h , e{\\rangle}\\longrightarrow\\max,\\\\ h\\in{\\mathbb{r}}^d,\\\\ { \\mathop{\\rm inf\\rule[-0.8mm]{0mm}{1mm}}}\\limits_{x\\in g}{\\langle}h , x{\\rangle}\\ge-1 .",
    "\\end{cases}\\ ] ]    denote @xmath518 by @xmath524 . for any @xmath525 , we have @xmath526{0mm}{1mm}}}_{x\\in g}{\\langle}h , x{\\rangle}={\\langle}h , t{\\rangle}=-1\\ ] ] and @xmath527    if @xmath528 and @xmath529{0mm}{1mm}}}_{x\\in g}{\\langle}h , x{\\rangle}\\ge-1 $ ] , then @xmath529{0mm}{1mm}}}_{x\\in g}{\\langle}h , x{\\rangle}<{\\langle}h , t{\\rangle}$ ] , so that @xmath530 , and , due to  , @xmath531 .",
    "@xmath97    ` remark ` . we can also provide a geometric solution of   under portfolio constraints of the type @xmath532 , where @xmath533 is a convex cone , and the ambiguity of the reward vector  @xmath500 .",
    "this is done by transforming   into the problem with one constraint as described above and then applying the result of  ( * ? ? ?",
    "* subsect .",
    "2.2 ) , where the cone constraints and the ambiguity were taken into account .  @xmath97    [ po2 ] let @xmath534 and @xmath30 be an @xmath476-dimensional random vector .",
    "then the generator of @xmath535 and  @xmath7 has the form @xmath536 where @xmath70 , @xmath537 , and @xmath217 is given by  . in order to prove this equality ,",
    "denote its left - hand side by  @xmath451 and its right - hand side by  @xmath538 .",
    "due to  , @xmath526{0mm}{1mm}}}_{x\\in g'}{\\langle}h , x{\\rangle}=u'_\\mu({\\langle}h , f{\\rangle } ) , \\quad h\\in{\\mathbb{r}}^d,\\ ] ] where @xmath539 is minus the weighted v@r with the weighting measure  @xmath161 on the probability space @xmath540 . as @xmath166 and @xmath539",
    "depend only on the distribution of a random variable ( this is seen from  , ) and @xmath541 , we get @xmath542 & = { \\mathop{\\rm inf\\rule[-0.8mm]{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathsf{e}}({\\mathcal{d}}_\\mu{\\hspace{0.3mm}|\\hspace{0.3mm}}y)}{\\mathsf{e}}_{\\mathsf{q}}{\\langle}h , x{\\rangle}={\\mathop{\\rm inf\\rule[-0.8mm]{0mm}{1mm}}}_{x\\in g}{\\langle}h , x{\\rangle},\\quad h\\in{\\mathbb{r}}^d.\\end{aligned}\\ ] ] thus , the support functions of @xmath451 and @xmath538 coincide .",
    "furthermore , both @xmath451 and @xmath538 are convex and closed . as a result , @xmath543 .",
    "* 3 . practical aspects . *",
    "the geometric solution presented above provides a nice theoretical insight into the form of the optimal portfolio .",
    "it can be used if we have a model for the joint distribution of @xmath499 . however ,",
    "if we do not have such a model , but rather want to approach   empirically , then , instead of the geometric solution , the following straightforward procedure can be employed .",
    "first of all , @xmath544 due to the scaling property , the solution to this problem coincides up to multiplication by a positive ( easily computable ) constant with the solution of the problem @xmath545 this is a problem of maximizing a convex functional over an affine space .",
    "a typical example we have in mind is @xmath492 , where @xmath86 is one of @xmath166 , @xmath246 , or @xmath546 . in this case the values @xmath547 can easily be estimated empirically through the procedures described at the end of section  [ crm ] .",
    "if @xmath500 is the vector of expected profits @xmath501 , then its empirical estimation is known to be an extremely unpleasant problem ( see the discussion in  @xcite and the 20 s example in  @xcite ) , unlike the estimation of the volatility - type quantities @xmath510 .",
    "the reason is that this vector is very close to zero , and therefore , its direction ( which is in fact the input that we need ) depends on the data in a very unstable way .",
    "one of possible ways to overcome this problem is to use theoretical estimates of  @xmath500 rather than empirical ones .",
    "for example , sharpe s sml relation ( @xcite ) implies that @xmath548 ( recall that @xmath549 is the _ discounted _",
    "p&l produced by the @xmath550-th asset ) .",
    "thus , the direction of  @xmath500 ( and this is what we need ) coincides with that of @xmath551 .",
    "* 1 . extreme measures . *",
    "let @xmath73 be a probability space and @xmath86 be a coherent utility with the determining set  @xmath8 .",
    "let @xmath51 be a random variable meaning the p&l produced by some portfolio over the unit time period .",
    "the following definition was introduced in  @xcite .",
    "[ rc1 ] a measure @xmath552 is an _",
    "extreme measure _ for  @xmath51 if @xmath553 .",
    "the set of extreme measures will be denoted by @xmath554 .",
    "[ rc2 ] if the determining set @xmath8 is @xmath135-closed and uniformly integrable , while @xmath555 , then @xmath556 .    `",
    "it is clear that @xmath557 .",
    "find a sequence @xmath358 such that @xmath558 . by the dunford ",
    "pettis criterion , @xmath8 is compact with respect to the weak topology @xmath559 .",
    "therefore , the sequence @xmath560 has a weak limit point @xmath561 . clearly , the map @xmath562 is weakly continuous .",
    "hence , @xmath563 , which means that @xmath564 .",
    "@xmath97    ` remark ` .",
    "it is seen from   that the determining set of weighted v@r is @xmath135-closed and uniformly integrable ( note that @xmath565 as @xmath566 ) .  @xmath97    [ rc3 ] * ( i ) * if @xmath12 $ ] and @xmath567 , then @xmath568 where @xmath569 is given by  .",
    "indeed , if @xmath101 belongs to the right - hand side of  , then , for any @xmath570 , we have @xmath571.\\end{aligned}\\ ] ] it is seen that this quantity is positive and equals zero if and only if @xmath572 belongs to the right - hand side of  .    * ( ii ) * let @xmath176 and @xmath573 .",
    "assume that @xmath574 .",
    "set @xmath575 .",
    "it is seen from  ( i ) that , for any @xmath12 $ ] , @xmath576 consists of the unique measure @xmath577 having the form @xmath578 where @xmath304 is such that @xmath579 .",
    "this can be rewritten as @xmath580 it follows from  ( * ? ? ?",
    "6.2 ) that @xmath581 consists of the unique measure @xmath582}{\\mathsf{q}}_{\\lambda}(w)\\mu(d{\\lambda})$ ] .",
    "we have @xmath583}\\int_0^{\\lambda}{\\lambda}^{-1}i(z_{i-1}<x\\le z_i ) dx\\mu(d{\\lambda})\\\\[1 mm ] & = \\int_0 ^ 1\\int_{[x,1]}{\\lambda}^{-1}i(z_{i-1}<x\\le z_i ) \\mu(d{\\lambda})dx\\\\[1 mm ] & = \\int_0 ^ 1 i(z_{i-1}<x\\le z_n)\\psi_\\mu(x)dx\\\\[1 mm ] & = \\int_{z_{n-1}}^{z_n}\\psi_\\mu(x)dx , \\quad i=1,\\dots , t,\\end{aligned}\\ ] ] where @xmath215 is given by  .    *",
    "( iii ) * if @xmath584 has a continuous distribution , then @xmath581 consists of the unique measure @xmath585 , where @xmath151 is the distribution function of  @xmath51 ( for the proof , see  ( * ? ? ?",
    "* sect .  6 ) ) .",
    "the measure @xmath586 has already appeared in  .",
    "* ( iv ) * suppose that @xmath253 and @xmath584 has a continuous distribution . for beta v@r , the measure @xmath587 of the previous example gets a more concrete form @xmath588 , where @xmath589 is provided by  .",
    "let us clarify the meaning of @xmath590 .",
    "let @xmath591 be independent copies of  @xmath51 , @xmath592 be the corresponding order statistics , and @xmath225 be an independent uniformly distributed on @xmath254 random variable . according to the reasoning of example  [ crm9 ] , the distribution function of @xmath593 is @xmath594 , where @xmath595.\\ ] ] consequently , @xmath596    * ( v ) * for alpha v@r with @xmath279 , we have @xmath597 and @xmath598    @xmath406    if an agent is using the classical expected utility @xmath128 to assess the quality of his / her position , then there exists his / her `` personal '' measure with which he / she assesses the quality of any possible trade .",
    "this measure is given by @xmath599 , where @xmath600 is the agent s wealth at the terminal date and @xmath601 is the normalizing constant .",
    "the role of this measure is seen from the equality @xmath602 if @xmath7 is the p&l produced by some trade and @xmath7 is small as compared to  @xmath51 , then @xmath7 is profitable for the agent if and only if @xmath603 . the extreme measure is the coherent substitute for this agent - specific measure as seen from theorem  [ rc5 ] stated below .",
    "* 2 . risk contribution .",
    "* the following definition was introduced in  @xcite .",
    "[ rc4 ] the _ utility contribution _ is defined as @xmath604{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathcal{x}}_{\\mathcal{d}}(w)}{\\mathsf{e}}_{\\mathsf{q}}x,\\quad x\\in l^0.\\ ] ] the _ risk contribution _ is defined as @xmath605 .",
    "if @xmath554 is non - empty , then @xmath606 is a coherent utility .",
    "[ rc5 ] if @xmath8 is @xmath135-closed and uniformly integrable and @xmath607 , then @xmath608    for the proof , see  ( * ? ? ?",
    "* subsect .",
    "for theoretical purposes , it is sometimes convenient to use a geometric representation of  @xmath609 .",
    "suppose that @xmath8 is @xmath135-closed and uniformly integrable , while @xmath607 .",
    "denote by  @xmath451 the generator @xmath610 and set @xmath611 , @xmath612 .",
    "then @xmath613 and therefore , @xmath614    ( 150,59)(-55,-16.5 ) ( 4.7,5 ) ( 0,0)(1,0)50 ( 0,0)(0,1)40 ( 0,5)(2,0)10(1,0)1 ( 5,0)(0,2)10(0,1)1 ( 20,0)(0,2)3(0,1)1 ( 48,-4)@xmath214 ( -3.5,38)@xmath615 ( -9,4 ) ( 1,-4 ) ( 14,-4 ) ( 23,19)@xmath451 ( -17,-14)*figure  8 . * geometric representation of  @xmath609    [ rc6 ] * ( i ) * if @xmath51 is a constant , then @xmath616 , so that @xmath617 .",
    "* ( ii ) * if @xmath618 with @xmath79 , then @xmath619 provided that @xmath556 .    * ( iii ) * let @xmath86 be law invariant and @xmath62 be jointly gaussian .",
    "we assume that @xmath607 and that the covariance matrix  @xmath286 of @xmath62 is non - degenerate .",
    "set @xmath386 , @xmath620 . as @xmath621 can be represented as @xmath622 , where @xmath623 is a standard two - dimensional gaussian random vector , the generator  @xmath624 of @xmath621 has the form @xmath625 , where @xmath626 is the generator of  @xmath623 .",
    "clearly , @xmath626 is the ball of radius  @xmath289 , where @xmath289 is provided by example  [ crm11 ]  ( i ) .",
    "thus , @xmath627 set @xmath611 , @xmath612 . by  ,",
    "@xmath628 , where @xmath629 . the point  @xmath630 is found from the condition @xmath631 which shows that @xmath632 with some @xmath633 , i.e. @xmath634 . the constant  @xmath19 is found from the condition @xmath635 , which shows that @xmath636 . as a result ,",
    "@xmath637 = { \\mathsf{e}}x-{\\gamma}\\,\\frac{{\\langle}e_1,ce_2{\\rangle}}{{\\langle}e_2,ce_2{\\rangle}^{1/2}}\\\\[1 mm ] = { \\mathsf{e}}x-{\\gamma}\\,\\frac{{\\mathop{\\sf cov}}(x , w)}{({\\mathop{\\sf var}}w)^{1/2}}.\\ ] ] note that @xmath638 .",
    "in particular ,",
    "if @xmath639 , then @xmath640 where @xmath641 denotes the v@r contribution ( for the definition , see  ( * ? ? ?",
    "* sect .  7 ) ) .    *",
    "( iv ) * let @xmath176 , @xmath177 , @xmath573 .",
    "assume that all the values @xmath642 are different .",
    "let @xmath643 be the values @xmath644 in the increasing order .",
    "define @xmath180 through the equality @xmath645 . according to example  [ rc3 ]",
    "( ii ) , @xmath646 where @xmath183 ( cf .  ) .    * ( v ) * if @xmath584 has a continuous distribution , then , according to example  [ rc3 ]  ( iii ) , @xmath647 ( cf .  ) .",
    "note that this value is linear in  @xmath7 .",
    "* ( vi ) * suppose that @xmath253 , @xmath648 , and @xmath51 has a continuous distribution .",
    "let @xmath61 be independent copies of @xmath62 and @xmath225 be an independent uniformly distributed on @xmath254 random variable .",
    "let @xmath592 be the corresponding order statistics .",
    "define random variables @xmath649 through the equality @xmath650 ( as @xmath51 has a continuous distribution , all the values @xmath591 are a.s .",
    "different , so that @xmath649 is a.s . determined uniquely ) .",
    "we have ( cf .  ) @xmath651\\\\ & = \\frac{1}{{\\beta}}\\sum_{i=1}^{\\beta}\\sum_{j=1}^{\\alpha}{\\mathsf{e}}x_j i(n(i)=j)\\\\ & = \\frac{1}{{\\beta}}\\sum_{i=1}^{\\beta}\\sum_{j=1}^{\\alpha}{\\mathsf{e}}x_j i\\{i-1\\text { members of } w_1,\\dots , w_{\\alpha}\\text { are smaller than } w_j\\\\[-2 mm ] & \\hspace{25mm}\\text { and } { \\alpha}-i\\text { members of } w_1,\\dots , w_{\\alpha}\\text { are greater than } w_j\\}\\\\ & = \\frac{1}{{\\beta}}\\sum_{i=1}^{\\beta}\\sum_{j=1}^{\\alpha}{\\mathsf{e}}[x_jf(w_j)^{i-1}(1-f(w_j))^{{\\alpha}-i}]\\\\ & = \\frac{{\\alpha}}{{\\beta}}\\sum_{i=1}^{\\beta}c_{{\\alpha}-1}^{i-1 } { \\mathsf{e}}[x f(w)^{i-1}(1-f(w))^{{\\alpha}-i}]\\\\ & = { \\mathsf{e}}x\\psi_{{\\alpha},{\\beta}}(f(w))\\\\ & = u_{{\\alpha},{\\beta}}^c(x;w).\\end{aligned}\\ ] ]    * ( vii ) * suppose that @xmath279 , @xmath648 , and @xmath51 has a continuous distribution .",
    "it follows from  ( vi ) that @xmath652 where @xmath61 are independent copies of @xmath62 .",
    "* 3 . capital allocation .",
    "* the notion of risk contribution is closely connected with the _ capital allocation _ problem .",
    "suppose that a firm consists of several desks , i.e. @xmath63 , where @xmath653 is the p&l produced by the @xmath304-th desk . the following definition was introduced in  @xcite .",
    "[ rc7 ] a collection @xmath654 is a _ capital allocation _ between  @xmath655  if @xmath656    from the financial point of view , @xmath657 means the contribution of the @xmath550-th component to the total risk of the firm , or , equivalently , the capital that should be allocated to this component . in order to illustrate the meaning of  ,",
    "consider the example @xmath658 , where @xmath659 is a subset of @xmath660 . then   means that the capital allocated to a part of the firm does not exceed the risk carried by that part .",
    "the following theorem was established in  ( * ? ? ?",
    "* subsect .",
    "[ rc8 ] suppose that @xmath8 is @xmath135-closed and uniformly integrable , while @xmath661 .",
    "then the set of solutions of the capital allocation problem has the form @xmath662 .",
    "if @xmath554 consists of a unique measure  @xmath58 , then the solution of the capital allocation problem is unique and has the form @xmath663 .",
    "in particular , in this case @xmath664    * 4 .",
    "tail correlation .",
    "* it follows from the inclusion @xmath665 that @xmath666 .",
    "typically , for a random variable  @xmath7 meaning the p&l of some transaction , we have @xmath667 ( i.e. its risk is strictly positive ) , so that @xmath668 the coefficient @xmath669 is a good measure for the tail correlation between  @xmath7 and  @xmath51 ( see  ) .",
    "let us recall that the standard _ tail correlation _ coefficient between @xmath7 and @xmath51 ( see  ( * ? ? ?",
    "5.2.3 ) ) is defined as @xmath670 , where @xmath671 at the same time , @xmath672 corresponding to @xmath673 has the form @xmath674 this is the same as the expression for @xmath675 with @xmath676 being replaced by  @xmath7 . however , an essential difference between  @xmath669 and the standard tail correlation coefficient is that @xmath669 is not symmetric in  @xmath677 .",
    "let us also remark that , for the weighted v@r , @xmath672 remains unchanged under monotonic transformations of  @xmath51 , i.e. @xmath678 , where @xmath679 is a strictly increasing function ( this is seen from example  [ rc6 ]  ( v ) ) .",
    "let us study some basic properties of  @xmath669 .",
    "two propositions below correspond to two extremes : no correlation and complete correlation .",
    "[ rc9 ] let @xmath648 and suppose that @xmath51 has a continuous distribution .",
    "then @xmath680 for any @xmath12 $ ] if and only if @xmath681 .",
    "` proof ` .",
    "set @xmath682 .",
    "according to example  [ rc6 ]  ( v ) , @xmath683}g(w){\\mathsf{q}}(d w ) , \\quad { \\lambda}\\in(0,1],\\ ] ] where @xmath684 and @xmath685 .",
    "now , the result is obvious",
    ".  @xmath97    recall that random variables @xmath7 and @xmath51 are called _ comonotone _ if @xmath686 for @xmath687-a.e .",
    "@xmath688 .",
    "[ rc10 ] suppose that the support of  @xmath161 is @xmath169 $ ] .",
    ". then @xmath690 if and only if @xmath7 and @xmath51 are comonotone .    `",
    "let us prove the `` only if '' part .",
    "the map @xmath691 is continuous with respect to the weak topology @xmath559 .",
    "hence , the set @xmath581 is weakly closed .",
    "an application of the hahn ",
    "banach theorem shows that @xmath581 is @xmath135-closed . by proposition  [ rc2 ]",
    ", there exists @xmath692 such that @xmath693 . according to  ( * ? ? ?",
    "4.4 ) , there exists a jointly measurable function @xmath694,\\omega\\in\\omega)$ ] such that @xmath695}z_{\\lambda}\\mu(d{\\lambda})$ ] with @xmath696 for any  @xmath17 .",
    "then @xmath697}{\\mathsf{e}}wz_{\\lambda}\\mu(d{\\lambda } ) = { \\mathsf{e}}wz = u_\\mu(w ) = \\int_{(0,1]}u_{\\lambda}(w)\\mu(d{\\lambda}),\\ ] ] and it follows that @xmath698 for @xmath161-a.e .",
    "furthermore , @xmath697}{\\mathsf{e}}xz_{\\lambda}\\mu(d{\\lambda } ) = { \\mathsf{e}}xz = u_\\mu^c(x;w ) = u_\\mu(x ) = \\int_{(0,1]}u_{\\lambda}(x)\\mu(d{\\lambda}),\\ ] ] and it follows that @xmath699 for @xmath161-a.e",
    ".  @xmath17 .",
    "thus , @xmath700 for @xmath161-a.e .",
    "@xmath17 . using",
    ", we get @xmath701 for @xmath161-a.e .  @xmath17 .",
    "as the functions @xmath16 and @xmath702 are right - continuous in  @xmath17 and the support of  @xmath161 is @xmath169 $ ] , we deduce that   is satisfied for every  @xmath12 $ ] . from this",
    "it is easy to deduce that @xmath703))=1 $ ] , where @xmath704 .",
    "thus , @xmath7 and @xmath51 are comonotone .",
    "let us prove the `` if '' part . by  ( * ?",
    "* lem .  4.83 ) , there exists a random variable  @xmath225 and increasing functions @xmath705 such that @xmath706 , @xmath707 .",
    "set @xmath708 where @xmath601 is the constant such that @xmath709 . according to  (",
    "4.4 ) , @xmath710}z_{\\lambda}\\mu(d{\\lambda})\\in{\\mathcal{d}}_\\mu$ ] .",
    "it is clear that @xmath711 .",
    "hence , @xmath712}{\\mathsf{e}}wz_{\\lambda}\\mu(d{\\lambda } ) = \\int_{(0,1]}u_{\\lambda}(w)\\mu(d{\\lambda } ) = u_\\mu(w),\\\\[1 mm ] & { \\mathsf{e}}xz = \\int_{(0,1]}{\\mathsf{e}}xz_{\\lambda}\\mu(d{\\lambda } ) = \\int_{(0,1]}u_{\\lambda}(x)\\mu(d{\\lambda } ) = u_\\mu(x).\\end{aligned}\\ ] ] as a result , @xmath692 and @xmath713 .",
    "since the reverse inequality is obvious , we get @xmath690 .  @xmath97    * 5 . empirical estimation . * in order to estimate empirically alpha v@r contribution of  @xmath7 to  @xmath51 with @xmath279 , one should first choose the number of trials @xmath308 and generate independent draws @xmath714 of  @xmath62 using one of procedures described at the end of section  [ crm ] .",
    "having generated @xmath715 , one should calculate the array @xmath716 according to example  [ rc6 ]  ( vii ) , an empirical estimate of @xmath717 is provided by @xmath718    in order to estimate beta v@r contribution with @xmath253 , one should generate @xmath715 similarly .",
    "let @xmath320 be the numbers @xmath321 such that the corresponding @xmath719 stand at the first @xmath322 places ( in the increasing order ) among @xmath720 . according to example  [ rc6 ]  ( vi ) , an empirical estimate of @xmath721",
    "is provided by @xmath722    in order to estimate weighted v@r contribution , one should fix a data set @xmath723 and a measure  @xmath312 on @xmath313 using one of the procedures described at the end of section  [ crm ] .",
    "let @xmath643 be the values @xmath644 in the increasing order ( we assume that all the @xmath642 are different ) . define @xmath180 through the equality @xmath645 .",
    "according to example  [ rc6 ]  ( iv ) , an empirical estimate of @xmath724 is provided by @xmath725 where @xmath328 and @xmath215 is given by  .",
    "* 1 . factor risk contribution . *",
    "let @xmath73 be a probability space and @xmath86 be a coherent utility with the determining set  @xmath8 .",
    "let @xmath30 be a random variable ( resp .",
    ", random vector ) meaning the increment of some market factor ( resp . , factors ) over the unit time period and @xmath51 be a random variable meaning the p&l produced by some portfolio over the unit time period .",
    "[ frc1 ] the _ factor utility contribution _ is @xmath726{0mm}{1mm}}}_{{\\mathsf{q}}\\in{\\mathcal{x}}_{{\\mathsf{e}}({\\mathcal{d}}{\\hspace{0.3mm}|\\hspace{0.3mm}}y)}(w)}{\\mathsf{e}}_{\\mathsf{q}}x , \\quad x\\in l^0.\\ ] ] the _ factor risk contribution _ is @xmath727 .    the function @xmath728 is a coherent utility provided that @xmath729 .",
    "[ frc2 ] if @xmath8 is @xmath135-closed and uniformly integrable , while @xmath730 , then @xmath729 .",
    "` proof ` . by remark  ( iii ) following definition  [ fr2 ] , @xmath352 is @xmath135-closed and uniformly integrable .",
    "now , the result follows from proposition  [ rc2 ] .  @xmath97    [ frc3 ] if @xmath731 , then @xmath732    ` proof ` .",
    "by lemma  [ fr4 ] , @xmath733 thus , @xmath734 which means that @xmath735 one more application of lemma  [ fr4 ] yields @xmath736 as a result , @xmath737{0mm}{1mm}}}_{z\\in{\\mathcal{x}}_{\\mathcal{d}}({\\mathsf{e}}(w{\\hspace{0.3mm}|\\hspace{0.3mm}}y))}{\\mathsf{e}}x{\\mathsf{e}}(z{\\hspace{0.3mm}|\\hspace{0.3mm}}y)\\\\ & = { \\mathop{\\rm inf\\rule[-0.8mm]{0mm}{1mm}}}_{z\\in{\\mathcal{x}}_{\\mathcal{d}}({\\mathsf{e}}(w{\\hspace{0.3mm}|\\hspace{0.3mm}}y))}{\\mathsf{e}}{\\mathsf{e}}(x{\\hspace{0.3mm}|\\hspace{0.3mm}}y)z\\\\ & = u^c({\\mathsf{e}}(x{\\hspace{0.3mm}|\\hspace{0.3mm}}y);{\\mathsf{e}}(w{\\hspace{0.3mm}|\\hspace{0.3mm}}y)).\\end{aligned}\\ ] ]    @xmath406    [ frc4 ] if @xmath8 is @xmath135-closed and uniformly integrable , while @xmath731 , then @xmath738    ` proof ` .",
    "applying successively theorems  [ frc3 ] , [ rc5 ] , and  [ fr3 ] , we get @xmath739 ( in order to apply theorem  [ rc5 ] in the second equality , we need to check that @xmath740 and @xmath741 ; this is done by the same argument as in the proof of lemma  [ fr4 ] ) .",
    "@xmath97    ` remark ` . if @xmath73 is atomless and @xmath86 is law invariant , then , by corollary  a.2 , the integrability condition on @xmath677 in the above statements can be replaced by a weaker one : @xmath607 .  @xmath97    [ frc5 ] if @xmath51 is a constant , then @xmath742 , so that @xmath743 .    *",
    "( ii ) * if @xmath618 with @xmath79 , then @xmath744 provided that @xmath729 .    * ( iii ) * let @xmath86 be law invariant and @xmath745 be a non - degenerate gaussian random vector such that each of its components belongs to @xmath746 .",
    "let @xmath286 denote the covariance matrix of  @xmath30 and set @xmath395 , @xmath747 , @xmath386 , @xmath387 , @xmath620 .",
    "we have ( cf . example  [ fr6 ] ) @xmath748 , @xmath749 , so that , by theorem  [ frc3 ] and example  [ rc6 ]  ( iii ) , @xmath750 & = { \\mathsf{e}}x-{\\gamma}\\,\\frac{{\\mathop{\\sf cov}}({\\langle}c^{-1}a,{\\overline}y{\\rangle } , { \\langle}c^{-1}b,{\\overline}y{\\rangle})}{({\\mathop{\\sf var}}{\\langle}c^{-1}b,{\\overline}y{\\rangle})^{1/2}}\\\\[1 mm ] & = { \\mathsf{e}}x-{\\gamma}\\,\\frac{{\\langle}c^{-1}a , b{\\rangle}}{{\\langle}c^{-1}b , b{\\rangle}^{1/2}}.\\end{aligned}\\ ] ] in particular , if @xmath30 is one - dimensional , then @xmath751 if moreover , @xmath752 and @xmath753 , then , recalling example  [ fr6 ] and example  [ rc6 ]  ( iii ) , we get @xmath754    @xmath406    * 2 . empirical estimation . * in view of theorem  [ frc3 ] , the empirical estimation of @xmath755 reduces to finding the functions @xmath70 , @xmath71 and then applying the procedures described at the end of section  [ rc ] to @xmath484 , @xmath756 .",
    "if @xmath30 is one - dimensional , one can create the data for  @xmath30 using the time change or the scaling procedures described at the end of section  [ fr ] .",
    "* 1 . problem . *",
    "let @xmath73 be a probability space and @xmath490 be coherent utilities with the determining sets @xmath491 .",
    "we assume that each @xmath757 is @xmath135-closed and uniformly integrable .",
    "suppose there is a firm consisting of  @xmath38 desks , and the @xmath304-th desk can invest into the assets that produce p&ls @xmath758 .",
    "we assume that @xmath759 for any @xmath760 .",
    "the set of p&ls that the @xmath304-th desk can produce over a unit time period is @xmath761 , where @xmath762 and @xmath763 is a convex subset of  @xmath764 with a non - empty interior meaning the constraint on the portfolio of the @xmath304-th desk .",
    "we assume that @xmath765 for any @xmath766 , which means that any possible trade has a strictly positive risk .",
    "let @xmath767 be the vector of rewards for the assets available to the @xmath304-th desk .",
    "this is the vector of subjective assessments by the @xmath304-th desk of the profitability of the assets @xmath768 .",
    "we will consider the following optimization problem for the whole firm : @xmath769 \\rho^m\\bigl(\\sum_n{\\langle}h^n , x^n{\\rangle}\\bigr)\\le c^m,\\;m=1,\\dots , m , \\end{cases}\\ ] ] where @xmath504 are fixed risk limits .",
    "this problem is a generalization of  , which might be considered as the optimization problem for a separate desk . we will not try to solve   for the following reason : if this problem admitted a solution that can be implemented in practice , this would mean that the central management is able to optimize the firm s portfolio and there would be no need for the existence of separate desks . instead of trying to solve  , we will study the following question : _ is it possible to decentralize  , i.e. to create for the desks conditions such that the global optimum is achieved when each desk acts optimally ? _",
    "* hypothesis  1 .",
    "* there exist @xmath770 such that if @xmath771 satisfy the conditions    we have @xmath772 and the equality is attained at least for one  @xmath282 ;    for each  @xmath304 , the vector @xmath771 solves the problem @xmath773    then @xmath774 solves  .",
    "this hypothesis is wrong as shown by the example below .",
    "[ ors1 ] let @xmath505 , @xmath775 , @xmath86 be a law invariant coherent utility that is finite on gaussian random variables , @xmath776 , @xmath777 , and @xmath778 have a jointly gaussian distribution with a non - degenerate covariance matrix  @xmath286 .",
    "it was shown in  ( * ? ? ?",
    "* subsect .",
    "2.2 ) that the solution of   has the form @xmath779 furthermore , the solution of   with @xmath780 has the form @xmath781 where @xmath782 is the covariance matrix of @xmath783 ( the constant here depends on @xmath770 ) .",
    "it is clear that there need not exist @xmath770 such that @xmath784 .",
    "@xmath97    * 2 .",
    "limits on risk contribution .",
    "* the reason why hypothesis  1 is wrong is that in general @xmath785 on the other hand , we typically have @xmath786 ( see  ) .",
    "this gives rise to    * hypothesis  2 .",
    "* let @xmath787 be such that @xmath788 for each  @xmath282 .",
    "if @xmath771 satisfy the conditions    we have @xmath772 and the equality is attained at least for one  @xmath282 ;    for each  @xmath304 , the vector @xmath771 solves the problem @xmath789    then @xmath774 solves  .",
    "this hypothesis is also wrong as shown by the example below .",
    "[ ors2 ] let @xmath505 , @xmath775 , @xmath86 be a law invariant coherent utility , @xmath790 , @xmath791 be jointly gaussian with a non - degenerate covariance matrix , and @xmath792 . take arbitrary @xmath793 such that @xmath794 and @xmath795 where @xmath289 is provided by example  [ crm11 ]  ( i ) .",
    "set @xmath796 ( we used example  [ rc6 ]  ( iii ) ) .",
    "obviously , each @xmath771 solves  . on the other hand , @xmath797 need not be optimal for  .",
    "@xmath97    * 3 .",
    "risk trading .",
    "* the reason why hypothesis  2 is wrong is that if one unit is more profitable than another , but it obtains a lower risk limit , then the global optimum can not be achieved .",
    "in fact , if we replace fixed  @xmath770 in hypothesis  2 by the assumption `` there exists @xmath770 ... '' , then ( as follows from theorem  [ ors3 ] ) the hypothesis becomes true .",
    "but this leaves open the problem of finding  @xmath770 . instead of trying to solve this problem",
    ", we will take another path .",
    "let us assume that the desks are allowed to trade their risk limits , i.e. they establish themselves ( through the supply  demand equilibrium ) the price  @xmath798 for the @xmath282-th risk limit , so that if the @xmath304-th desk buys from the @xmath799-th desk @xmath250 units of the @xmath282-th risk limit , then the @xmath304-th desk pays the @xmath799-th desk the amount @xmath800 , the @xmath304-th desk raises its @xmath282-th risk limit by the amount  @xmath250 , and the @xmath799-th desk lowers its @xmath282-th risk limit by the amount  @xmath250 .    * hypothesis  3 . *",
    "let @xmath787 be such that @xmath788 for each  @xmath282 .",
    "if @xmath801 , @xmath802 , and @xmath803 satisfy the conditions    we have @xmath804    we have @xmath805 and the equality is attained at least for one  @xmath282 ;    @xmath806 for all  @xmath282 such that inequality   is strict ;    for each  @xmath304 , the vectors @xmath771 and @xmath807 solve the problem @xmath808    then @xmath774 solves  .",
    "this hypothesis is true ( under minor technical assumptions ) as shown by the theorem below .",
    "[ ors3 ] let @xmath787 be such that @xmath788 for each  @xmath282 .",
    "let @xmath771 belong to the interior of  @xmath763 and assume that , for each  @xmath282 , the set @xmath809 consists of a unique measure  @xmath810 .",
    "then the following conditions are equivalent :    @xmath811 solve     there exist @xmath802 and @xmath803 that satisfy the conditions of hypothesis  3 ;    there exist @xmath803 satisfying conditions 2 , 3 of hypothesis  3 and such that @xmath812    moreover , the sets of possible @xmath813 in ( ii ) and ( iii ) are the same .    ` remark ` .",
    "the theorem shows that the system finds the optimum regardless of the allocation @xmath770 of risk limits .",
    "( the resulting rewards @xmath814 depend on  @xmath770 , but their sum does not depend on  @xmath770 . ) it is also clear from  ( iii ) that the equilibrium prices @xmath815 of risk limits do not depend on @xmath770 .  @xmath97    ` proof of theorem  [ ors3 ] . `",
    "( i)@xmath816(iii ) set @xmath817 so that @xmath818 is a convex closed cone in  @xmath508 , where @xmath819 .",
    "suppose that @xmath820 . by the hahn ",
    "banach theorem , there exists @xmath821 such that @xmath822 .",
    "consider @xmath823 .",
    "there exists @xmath824 such that , for @xmath825 , we have : @xmath826 for any  @xmath304 and @xmath827 for any @xmath828 . set @xmath829 then @xmath830 and , by theorem  [ rc5 ] , @xmath831 due to our assumptions , @xmath832 .",
    "then we can find @xmath825 and @xmath833 such that @xmath834 for each  @xmath304 , @xmath835 , and @xmath836 for any @xmath837 .",
    "this means that @xmath838 and @xmath839 which is a contradiction . as a result , @xmath840 , which is the desired statement .",
    "( iii)@xmath816(ii ) it follows from the inequality @xmath841 that we can choose @xmath842 in such a way that @xmath843 for any  @xmath282 and @xmath844 for any @xmath845 .",
    "then @xmath846 clearly , for @xmath837 , this inequality is the equality .",
    "assume that there exist  @xmath304 and @xmath847 , @xmath848 such that @xmath849 this means that , for @xmath850 and @xmath851 , we have @xmath852 this leads to the inequality @xmath853 which is a contradiction .",
    "( ii)@xmath816(i ) suppose that there exist @xmath847 such that @xmath854 then @xmath855 for any @xmath856 . for @xmath857 , we have @xmath858 , and , due to the convexity of the function @xmath859 , @xmath860 this means that there exists  @xmath304 such that @xmath861 for this  @xmath304 , set @xmath862",
    ". then @xmath863 furthermore , @xmath864 & = ( \\rho^m)^c\\bigl({\\langle}h_*^n , x^n{\\rangle};\\sum_{n=1}^n { \\langle}h_*^n , x^n{\\rangle}\\bigr)+a^{nm}-a_*^{nm}\\\\ & \\le c^{nm}+a^{nm},\\quad m=1,\\dots , m,\\end{aligned}\\ ] ] which is a contradiction .",
    "in order to complete the proof , it is sufficient to show that any @xmath813 satisfying  ( ii ) also satisfies  ( iii ) .",
    "this is obvious .",
    "* 1 . risk measurement . * consider a firm whose portfolio has the form @xmath63 . here",
    "@xmath51 is the p&l produced by the portfolio over the unit time period  @xmath865 , which is used as the basis for risk measurement ( typically it is one day ) ; @xmath653 is the p&l of the @xmath304-th asset .",
    "let @xmath7 be the p&l produced by some additional asset or portfolio over the same period .",
    "the empirical procedure to assess alpha v@r risk of  @xmath51 and the risk contribution of  @xmath7 to  @xmath51 is :    fix @xmath279 .",
    "choose a probability measure  @xmath312 on the set of natural numbers , choose the number of trials @xmath308 , and generate independent draws @xmath866 from the distribution  @xmath312 .",
    "a natural choice for  @xmath312 is a geometric distribution .",
    "calculate the array @xmath867 here @xmath868 is the increment of the value of the @xmath304-th asset in the portfolio over the time period @xmath869 $ ] ( the current time instant is  0)-th asset is positive by its nature ( for example , the @xmath304-th asset is a share ) , then one can use a finer procedure to determine @xmath868 , i.e. @xmath868 is the current value of the asset times its relative increment over the period @xmath869 $ ] . ] .",
    "calculate the empirical estimates of @xmath870 and @xmath717 by the formulas : @xmath871 here @xmath310 is the realization of  @xmath7 ( i.e. the increment of the value of the corresponding portfolio ) over the time period @xmath869 $ ] .",
    "note that the same arrays @xmath872 and @xmath873 are used for different  @xmath7 .",
    "if we measure risk on the daily basis , steps  13 can be performed only once a day ( for example , in the night ) .",
    "thus , in the morning the central desk announces the arrays @xmath872 and @xmath873 , and when assessing the risk contribution of any trade  @xmath7 , any desk should simply take the realizations of  @xmath7 over the corresponding intervals and insert them into the formula for  @xmath874 .",
    "the number of operations required to generate @xmath872 and @xmath873 is of order @xmath875 ; the number of operations required to calculate @xmath874 is of order  @xmath818 . in particular , we need not order the data set ( which is needed for estimating v@r ) .",
    "the above estimation procedure is completely non - linear .",
    "moreover , it is completely empirical as it uses no model assumptions on the structure of  @xmath7 and  @xmath51 .    if @xmath876 is itself a big portfolio ( for example ,",
    "the p&l produced by a desk of the firm ) , then both the theoretical risk contribution and its empirical estimate satisfy the linearity property : @xmath877    the above procedure can be combined with the bootstrap technique , with obvious changes .",
    "a similar procedure can be performed for beta v@r .",
    "the difference is that one should additionally choose @xmath878 and find the numbers @xmath320 such that the corresponding @xmath879 stand at the first @xmath322 places ( in the increasing order ) among @xmath880",
    ". then the empirical estimates of @xmath881 and @xmath721 are provided by @xmath882    * 2 .",
    "factor risk measurement . *",
    "the procedure to assess alpha v@r factor risks of  @xmath51 and the factor risk contributions of  @xmath7 to  @xmath51 is :    fix @xmath279 .",
    "choose the main market factors @xmath456 affecting the risk of the portfolio . here",
    "@xmath462 means the increment of the @xmath282-th factor over the unit time period .",
    "create procedures for calculating the functions @xmath883 and @xmath884 .",
    "choose a probability measure  @xmath312 on the set of natural numbers , choose the number of trials  @xmath818 , and generate independent draws @xmath866 from the distribution  @xmath312 .",
    "calculate the array @xmath885 here @xmath886 is the increment of the @xmath282-th factor over the time period @xmath887 $ ] , where @xmath888 is the current volatility of the @xmath282-th factor ( for example , the implied volatility ) . instead of this time change procedure , one can use the scaling procedure .    calculate the empirical estimates of @xmath889 and @xmath890 by the formulas : @xmath891    all the pleasant features of risk estimates described above remain true for factor risks .",
    "moreover , an important advantage of factor risks is that we can take an arbitrarily large data set @xmath485 , while the joint data set @xmath892 required for ordinary risk does not exist for large portfolios .",
    "a similar procedure can be performed for beta v@r .",
    "the difference is that one should additionally choose @xmath878 and find the numbers @xmath893 such that the corresponding @xmath894 stand at the first @xmath322 places ( in the increasing order ) among @xmath895 .",
    "then the empirical estimates of @xmath896 and @xmath897 are provided by @xmath898    the functions @xmath899 should not be recalculated every day ( if we measure risk on a daily basis ) ; once computed , these functions might be used for rather a long period .",
    "of course , the collection of assets in the portfolio changes each day , but the main part of this collection remains the same , so that when the @xmath900-th asset appears in the portfolio , we should calculate @xmath901 , @xmath49 , but we should not recalculate @xmath899 , @xmath44 , @xmath49 .    the factor risk estimation admits a multi - factor version : instead of considering @xmath476 different factor risks , we consider one risk driven by the multidimensional factor @xmath902 .",
    "alternatively , we could split the factors into @xmath476 groups so that the increment of the @xmath282-th group is a random vector , which we still denote by  @xmath462 , and split the portfolio into @xmath476 groups so that the risk of the @xmath282-th group is driven mainly by the @xmath282-th group of factors .",
    "then when dealing with the @xmath282-th factor risk we are considering only the @xmath282-th part of the portfolio .",
    "all the formulas remain the same with obvious changes .    *",
    "3 . comparison of various techniques . * in table  1 , we compare different risk measurement techniques proposed in this paper and several classical risk measurement techniques ( see  ( * ? ? ?",
    "* sect .  6 ) for their description ) .",
    "let us briefly describe this table .",
    "all the techniques , except for one - factor risk measurement , assess the overall risk .",
    "as shown by example  [ fr11 ] , the sum of one - factor risks need not exceed the multi - factor risk , so that the measurement of one - factor risks might be insufficient .    for the empirical risk estimation procedure described above",
    ", one requires the joint time series @xmath892 for all the assets in the portfolio . however , different assets have different durations , so that a joint time series might exist only for small portfolios or portfolios consisting of long - living assets only .",
    "in contrast , all the other methods express the values of the assets through the main factors , and for the factors one can get arbitrarily large time series .    for one - factor risks we can use the time change technique described above , which enables one to react immediately to the volatility changes . for parametric v@r and monte carlo v@r",
    ", this can partially be done , but these methods require the covariance matrix for different assets , for which we should use historic data .    the speed of computations for one - factor coherent risks , multi - factor coherent risks , and historic v@r is approximately the same because in all these methods the main part of computations consists in finding the values @xmath903 .",
    "the methods proposed in this paper deal with coherent risk .",
    "the arguments of section  [ crm ] show that in many respects this is much wiser than the use of v@r .",
    "all the methods of this paper admit simple calculation of risk contributions . for parametric v@r ,",
    "this is also possible because there exist explicit formulas for gaussian v@r contributions . for monte carlo v@r ,",
    "the possibility to calculate risk contributions depends on the choice of the probabilistic model .",
    "all the methods , except for parametric v@r , are completely non - linear .",
    "monte carlo v@r might be performed both for gaussian and non - gaussian models , but for the latter ones this leads to a further decrease in the speed of computations .",
    "the empirical risk estimation technique uses absolutely no model assumptions . as for the factor risks and historic v@r , there are no assumptions on the probabilistic structure of  @xmath462 , but model assumptions are used when calculating the functions @xmath904 , @xmath899 .    as the conclusion ,",
    "the best methods are : one - factor and multi - factor coherent risk measurement .",
    "it might be reasonable to use both of them simultaneously .        ' '' ''    ordinary risk & & & & & & & & & +    ' '' ''    multi - factor risk & & & & & & & & & +    ' '' ''    one - factor risk & & & & & & & & & +    ' '' ''    parametric v@r & & & & & & & & & +    ' '' ''    monte carlo v@r & & & & & & & & & +    ' '' ''    historic v@r & & & & & & & & & +    ( 1,1)(79,-57 ) ( 0,0 ) ( 2,3)*technique * ( 32,8 )    * 4 .",
    "risk management .",
    "* two practical recommendations of this paper concerning risk management are as follows :    the central management of a firm should impose the limits not on the outstanding risks ( resp .",
    ", factor risks ) of the desks portfolios , but rather on their risk contributions ( resp .",
    ", factor risk contributions ) to the capital of the whole firm .",
    "in view of the formulas given above , this can be done simply by announcing the arrays @xmath872 and @xmath873 ( resp . ,",
    "@xmath872 and @xmath905 ) .",
    "if the desks are allowed to trade these risk limits within the firm , then the corresponding competitive optimum is in fact the global optimum for the whole firm , regardless of the initial allocation of the risk limits .",
    "* theorem  a.1 . *",
    "( i)@xmath816(ii ) as @xmath73 is atomless , it supports a random variable  @xmath7 with any given distribution  @xmath58 on the real line .",
    "then the equality @xmath906 correctly defines a function on the set of distributions . by the definition , @xmath907 where the intersection is taken over all the probability measures on  @xmath908 . by the hardy  littlewood inequality ( see  ( * ? ? ?",
    "a.24 ) ) , @xmath909 where @xmath151 is the distribution function of  @xmath7 . consequently ,",
    "@xmath910 fix @xmath101 and a probability measure  @xmath58 on  @xmath908 .",
    "as @xmath73 is atomless , @xmath101 can be represented as @xmath911 with a uniformly distributed on @xmath169 $ ] random variable  @xmath129 .",
    "then @xmath912 has the distribution  @xmath58 ( @xmath913 is the @xmath17-quantile of  @xmath58 ) . obviously , @xmath914 combining this with  ( a.1 ) , we get @xmath526{0mm}{1mm}}}_{x:{\\mathop{\\rm law}\\nolimits}x={\\mathsf{q}}}{\\mathsf{e}}zx=\\int_0 ^ 1 q_s({\\mathsf{q}})q_{1-s}(z)ds.\\ ] ] thus , the set @xmath915 is law invariant .",
    "hence , @xmath8 is law invariant .",
    "( ii)@xmath816(iii ) the law invariance of @xmath8 means that there exists a set @xmath916 of probability measures on  @xmath917 such that @xmath918 .",
    "fix @xmath919 .",
    "there exists a unique measure  @xmath920 on @xmath162 $ ] such that @xmath921 , @xmath922 $ ] ( @xmath215 is given by  ) .",
    "clearly , @xmath161 is positive and @xmath923 ) & = \\int_{(0,1]}\\int_{(0,y]}y^{-1}dx\\mu(dy ) = \\int_0 ^ 1\\int_{[x,1]}y^{-1}\\mu(dy)dx\\\\ & = \\int_0 ^ 1 q_{1-x}({\\mathsf{q}})dx = \\int_{{\\mathbb{r}}_+}x{\\mathsf{q}}(dx ) = 1.\\end{aligned}\\ ] ] applying the same argument as above and recalling  , we get @xmath526{0mm}{1mm}}}_{z:{\\mathop{\\rm law}\\nolimits}z={\\mathsf{q}}}{\\mathsf{e}}xz = \\int_0 ^ 1 q_s(x)q_{1-s}({\\mathsf{q}})ds = \\int_0 ^ 1 q_s(x)\\psi_\\mu(x)ds = u_\\mu(x),\\quad x\\in l^0.\\eqno\\text{(a.2)}\\ ] ] as a result , @xmath924{0mm}{1mm}}}_{z\\in{\\mathcal{d}}}{\\mathsf{e}}xz = { \\mathop{\\rm inf\\rule[-0.8mm]{0mm}{1mm}}}_{{\\mathsf{q}}\\in\\mathfrak q}{\\mathop{\\rm inf\\rule[-0.8mm]{0mm}{1mm}}}_{z:{\\mathop{\\rm law}\\nolimits}z={\\mathsf{q}}}{\\mathsf{e}}xz = { \\mathop{\\rm inf\\rule[-0.8mm]{0mm}{1mm}}}_{{\\mathsf{q}}\\in\\mathfrak q}u_{\\mu({\\mathsf{q}})}(x),\\quad x\\in l^0 . \\eqno\\text{(a.3)}\\ ] ]      ( ii)@xmath816(iv ) it follows from  ( a.2 ) that @xmath925 .",
    "hence , @xmath926 . on the other hand ,",
    "if @xmath927 with some @xmath919 , then , by  ( a.3 ) , @xmath928 so that , by definition , @xmath366 . hence , @xmath929 .        ` proof ` . by theorem",
    "a.1 , @xmath410 with some set @xmath232 of probability measures on @xmath162 $ ] . using representation  , the convexity of the function  @xmath217 given by  , and the jensen inequality , we get @xmath931 , which yields the desired statement .  @xmath97                                              _ f.  delbaen . _ coherent risk measures on general probability spaces . in : k.  sandmann , p.  schnbucher ( eds . )",
    ". advances in finance and stochastics . essays in honor of dieter sondermann .",
    "springer , 2002 , p.  137 .                    _",
    "h.  fllmer , a.  schied .",
    "_ robust preferences and convex measures of risk . in : k.  sandmann , p.  schnbucher ( eds . ) .",
    "advances in finance and stochastics . essays in honor of dieter sondermann .",
    "springer , 2002 , ."
  ],
  "abstract_text": [
    "<S> * abstract . * we propose a new procedure for the risk measurement of large portfolios . </S>",
    "<S> it employs the following objects as the building blocks :    _ coherent risk measures _ introduced by artzner , delbaen , eber , and heath ;    _ factor risk measures _ introduced in this paper , which assess the risks driven by particular factors like the price of oil , s&p500 index , or the credit spread ;    _ risk contributions _ and _ factor risk contributions _ , which provide a coherent alternative to the sensitivity coefficients .    </S>",
    "<S> we also propose two particular classes of coherent risk measures called _ </S>",
    "<S> alpha v@r _ and _ beta v@r _ </S>",
    "<S> , for which all the objects described above admit an extremely simple empirical estimation procedure . </S>",
    "<S> this procedure uses no model assumptions on the structure of the price evolution .    </S>",
    "<S> moreover , we consider the problem of the risk management on a firm s level . </S>",
    "<S> it is shown that if the risk limits are imposed on the risk contributions of the desks to the overall risk of the firm ( rather than on their outstanding risks ) and the desks are allowed to trade these limits within a firm , then the desks automatically find the globally optimal portfolio .    * key words and phrases . * </S>",
    "<S> alpha v@r , beta v@r , capital allocation , coherent risk measure , extreme measure , factor risk , factor risk contribution , law invariant risk measure , portfolio optimization , risk contribution , risk management , risk measurement , risk sharing , risk trading , tail correlation , tail v@r , weighted v@r .    </S>",
    "<S> * coherent measurement of factor risks *    _ * alexander s.  cherny@xmath0,dilip b.  madan@xmath1 * _    _ @xmath0moscow state university _ + _ faculty of mechanics and mathematics _ </S>",
    "<S> + _ department of probability theory _ + _ 119992 moscow , russia _ </S>",
    "<S> + ` e - mail : cherny@mech.math.msu.su ` + ` webpage : http://mech.math.msu.su/~cherny `    _ </S>",
    "<S> @xmath1robert h.  smith school of business _ </S>",
    "<S> + _ van munching hall _ </S>",
    "<S> + _ university of maryland _ + _ college park , md 20742 _ + ` e - mail : dmadan@rhsmith.umd.edu ` + ` webpage : http://www.rhsmith.umd.edu/faculty/dmadan ` </S>"
  ]
}