{
  "article_text": [
    "our purpose here is to investigate mathematically a numerical approach recently introduced in  @xcite to solve high dimensional partial differential equations .",
    "the approach is a nonlinear approximation type approach that consists in expanding the solution of the equation in tensor products of functions sequentially determined as the iterations of the algorithm proceed .",
    "the original motivation of the approach is the wish of its authors to solve high - dimensional fokker - planck type equations arising in the modelling of complex fluids .",
    "reportedly , the approach performs well in this case , and , in addition , extends to a large variety of partial differential equations , static or time - dependent , linear or nonlinear , elliptic or parabolic , involving self - adjoint or non self- adjoint operators provided the data enjoy some appropriate separation property with respect to the different coordinates ( this property is made precise in remark  [ rem : rhs ] below ) .",
    "we refer the reader to  @xcite for more details .    in the present contribution focused on mathematical analysis , we restrict ourselves to the simplest possible case , namely the solution of the poisson equation set with dirichlet homogeneous boundary conditions on a two dimensional parallelepipedic domain @xmath0 with @xmath1 and @xmath2 bounded . in short",
    ", the approach under consideration then determines the solution @xmath3 to @xmath4 as a sum @xmath5 by iteratively determining functions @xmath6 , @xmath7 , @xmath8 such that for all @xmath9 , @xmath10 is the best approximation ( in a sense to be made precise below ) of the solution @xmath11 to @xmath12 in terms of one single tensor product @xmath13 .",
    "we show that it is possible to give a sound mathematical ground to the approach _ provided _ we consider a variational form of the approach that manipulates minimizers of energies instead of solutions to equations . in order to reformulate the approach in such a variational setting , our arguments",
    "thus crucially exploit the fact that the laplace operator is self - adjoint .",
    "it is to be already emphasized that , because of the nonlinearity of the tensor product expansion ( [ eq:22 ] ) , the variational form of the approach is _ not _ equivalent to the form ( [ eq:11])-([eq:22 ] ) ( which is exactly the euler - lagrange equations associated to the energy considered in the variational approach ) .",
    "our analysis therefore does not apply to the actual implementation of the method as described in  @xcite . at present time",
    ", we do not know how to extend our arguments to cover the practical situation , even in the simple case of the poisson problem .",
    "the consideration of some particular pathological cases , theoretically and numerically , shows that the appropriate mathematical setting is unclear .",
    "likewise , it is unclear to us how to provide a mathematical foundation of the approach for non variational situations , such as an equation involving a differential operator that is not self - adjoint .    on the other hand , the analysis provided here straightforwardly extends to the case of a @xmath14-dimensional poisson problem with @xmath15 ( unless explicitly mentioned ) .",
    "likewise , our analysis extends to the case of elliptic linear partial differential equations set on a cylinder in @xmath16 , with appropriate boundary conditions .",
    "the only , although substantial , difficulty that may appear when the dimension @xmath14 grows is the algorithmic complexity of the approach , since a set of @xmath14 coupled non - linear equations has to be solved ( see remark  [ rem : hd ] ) .",
    "at least , the number of unknowns involved in the systems to be solved does not grow exponentially , as it would be the case for a naive approach ( like for a finite differences method on a tensorized grid ) .",
    "this is not the purpose of the present article to further elaborate on this .",
    "our article is organized as follows .",
    "section  [ sec : presentation ] introduces the approach .",
    "the variational version of the approach ( along with a relaxed variant of it ) is described in section  [ sec : algo ] .",
    "elementary properties follow in sections  [ sec : well ] and [ sec : el ] .",
    "the non variational version is presented in section  [ sec : nonvar ] . in section  [ sec : convergence ] we show the convergence of the variational approach and give an estimate of the rate of convergence .",
    "our arguments immediately follow from standard arguments of the literature of _ nonlinear approximation theory _ , and especially from those of  @xcite .",
    "the particular approach under consideration is indeed closely related to the so - called _ greedy algorithms _ introduced in approximation theory .",
    "we refer to  @xcite for some relevant contributions , among many .",
    "the purpose of section  [ sec : discussion ] is to return to the original non variational formulation of the approach . for illustration",
    ", we first consider the case when the laplace operator @xmath17 in ( [ eq:11 ] ) is replaced by the identity operator .",
    "the approach then reduces to the determination of the _ singular value decomposition _",
    "( also called _",
    "rank - one decomposition _ ) of the right - hand side @xmath18 .",
    "this simple situation allows one to understand various difficulties inherent to the non variational formulation of the approach .",
    "we then discuss the actual case of the laplace operator , and present some intriguing numerical experiments , in particular when a non - symmetric term ( namely there an advection term ) is added .    as will be clear from the sequel , our current mathematical understanding of the numerical approach is rather incomplete . our results do not cover real practice .",
    "some ingredients from the literature of nonlinear approximation theory nevertheless already allow for understanding some basics of the approach .",
    "it is the hope of the authors that , laying some groundwork , the present contribution will sparkle some interest among the experts , and allows in a not too far future for a complete understanding of the mathematical nature of the approach .",
    "should the need arise , it will also indicate possible improvements of the approach so that it is rigorously founded mathematically and , eventually , performs even better that the currently existing reports seemingly show .",
    "* acknowledgments * : the authors wish to thank a.  ammar and f.  chinesta for introducing them to their series of works initiated in  @xcite , a.  cohen for stimulating discussions , and a.  lozinski for pointing out reference  @xcite .",
    "this work was completed while the first author ( clb ) was a long - term visitor at the institute for mathematics and its applications , minneapolis .",
    "the hospitality of this institution is gratefully acknowledged .",
    "consider a function @xmath19 where @xmath0 with @xmath1 and @xmath2 two bounded domains . to fix ideas ,",
    "one may take @xmath20 .",
    "consider on @xmath21 the following homogeneous dirichlet problem : @xmath22 it is well known that solving   is equivalent to solving the variational problem : @xmath23 in the following , for any function @xmath24 , we denote @xmath25 notice that @xmath26 where @xmath27 is defined by  , so that minimizing @xmath28 is equivalent to minimizing @xmath29 with respect to @xmath3 .",
    "we endow the functional space @xmath30 with the scalar product : @xmath31 and the associated norm @xmath32      we now introduce two algorithms to solve  .",
    "the first algorithm is the _ pure greedy algorithm _ :    set @xmath33 , and at iteration @xmath34 ,    1 .",
    "find @xmath35 and @xmath36 such that @xmath37 2 .",
    "set @xmath38 .",
    "3 .   if @xmath39 , proceed to iteration @xmath40 .",
    "otherwise , stop .    throughout this article ,",
    "we denote by @xmath41 the tensor product : @xmath42 . notice that @xmath43 the fonction @xmath44 belongs to @xmath45 and the tensor product @xmath46 is in @xmath30 if @xmath47 and @xmath48 ( see lemma  [ lem : h10 ] below ) , so that the integral @xmath49 in   is well defined .",
    "a variant of this algorithm is the _ orthogonal greedy algorithm _ :    set @xmath50 , and at iteration @xmath34 ,    1 .",
    "find @xmath51 and @xmath52 such that @xmath53 2 .   solve the following galerkin problem on the basis @xmath54 :",
    "find @xmath55 such that @xmath56 3 .",
    "set @xmath57 .",
    "4 .   if @xmath58 , proceed to iteration @xmath40 .",
    "otherwise , stop .",
    "let us also introduce @xmath59 satisfying the dirichlet problem : @xmath60 notice that @xmath61 so that @xmath62 .",
    "likewise , we introduce @xmath63 , which satisfies @xmath64 in @xmath21 and @xmath65 on @xmath66 . proving the convergence of the algorithms amounts to proving that @xmath59 and @xmath67 converge to @xmath68 .",
    "the terminology _ pure greedy algorithm _ and _ orthogonal greedy algorithm _ is borrowed from approximation theory ( see  @xcite ) .",
    "such algorithms have been introduced in a more general framework , namely for an arbitrary hilbert space and an arbitrary set of functions ( not only tensor products ) .",
    "recall for consistency that , in short , the purpose of such nonlinear approximations techniques is to find the best possible approximation of a given function as a sum of elements of a prescribed _",
    "dictionary_. the latter does not need to have a vectorial structure . in the present case ,",
    "the dictionary is the set of simple products @xmath13 for @xmath69 varying in @xmath70 and @xmath71 varying in @xmath72 ( all this will be formalized with the introduction of the space @xmath73 in section  [ sec : convergence ] below ) .",
    "the metric chosen to define the approximation is the natural metric induced by the differential operator , here the @xmath74 norm .",
    "the algorithm proposed by ammar _",
    "et al_.  @xcite is actually related to the orthogonal greedy algorithm : it consists in replacing the optimization procedure   by the associated euler - lagrange equations .",
    "we shall give details on this in section  [ sec : el ] below .",
    "for the moment , we concentrate ourselves on the variational algorithms above",
    ".      we will need the following three lemmas .",
    "[ lem : h10 ] for any measurable functions @xmath75 and @xmath76 such that @xmath77 @xmath78    [ lem : distrib ] let @xmath79 be a distribution such that , for any functions @xmath80 , @xmath81 then @xmath82 in @xmath83 .",
    "moreover , for any two sequences of distributions @xmath84 and @xmath85 such that @xmath86 in @xmath87 and @xmath88 in @xmath89 , @xmath90 in @xmath83 .",
    "[ lem : e_neg ] let us consider a function @xmath19 . if @xmath91 , then @xmath92 such that @xmath93 where @xmath94 is defined by  .",
    "lemma  [ lem : distrib ] is well - known in distribution theory .",
    "we now provide for consistency a short proof of lemmas  [ lem : h10 ] and [ lem : e_neg ] , respectively .    *",
    "proof of lemma  [ lem : h10 ] * notice that @xmath95 and @xmath96 , then @xmath97 .",
    "now , when @xmath97 , we have @xmath98 and @xmath96 , since @xmath99 and @xmath100 .",
    "@xmath101    * proof of lemma  [ lem : e_neg ] * fix @xmath19 and assume that for all @xmath102 , @xmath103 .",
    "then , for a fixed @xmath104 , we have , for all @xmath105 , @xmath106 by letting @xmath107 , this shows that @xmath108 which implies @xmath109 ( by lemma  [ lem : distrib ] ) and concludes the proof . @xmath101",
    "the above lemmas allow us to prove .",
    "[ prop : lra_var_well_posed ] for each @xmath9 , there exists a solution to problems   and  .    without loss of generality",
    ", we may only argue on problem   and assume that @xmath110 and @xmath111 .",
    "first , using  , it is clear that @xmath112 thus , we can introduce @xmath113 and a minimizing sequence @xmath114 such that @xmath115 .",
    "notice that we may suppose , again without loss of generality ( up to a multiplication of @xmath116 by a constant ) , that @xmath117    since @xmath118 , the sequence @xmath119 is bounded in @xmath30 : there exists some @xmath120 such that , for all @xmath121 , @xmath122 , @xmath123 and @xmath96 such that ( up to the extraction of a subsequence ) :    * @xmath124 converges to @xmath125 weakly in @xmath30 , and strongly in @xmath126 , * @xmath127 converges to @xmath69 weakly in @xmath128 , * @xmath116 converges to @xmath71 weakly in @xmath72 , and strongly in @xmath129 .",
    "since @xmath124 converges to @xmath125 weakly in @xmath30 and @xmath94 is convex and continuous , we have @xmath130 .",
    "this yields @xmath131 .",
    "moreover , by lemma  [ lem : e_neg ] , we know @xmath132 .",
    "therefore , @xmath133    the convergences @xmath134 and @xmath135 in the distributional sense imply the convergence @xmath136 in the distributional sense ( see lemma  [ lem : distrib ] ) , and therefore @xmath137 .",
    "thus , if @xmath138 , lemma  [ lem : h10 ] concludes the proof , showing that indeed @xmath47 .",
    "now , we can not have @xmath139 , since this would imply @xmath140 , which would contradict  .",
    "this concludes the proof .",
    "the optimization step   admits also a solution by standard arguments and we therefore have proven :    [ lem : algo_well_defined ] at each iteration of the pure greedy algorithm , problem ( [ eq : lra_var ] ) admits ( at least ) a minimizer @xmath141 .",
    "likewise , at each iteration of the orthogonal greedy algorithm , problem ( [ eq : lra_varo ] ) admits ( at least ) a minimizer @xmath142 .",
    "it is important to note that , in either case , uniqueness of the iterate is unclear . throughout the text",
    ", we will thus be refering to _ the _ functions @xmath141 ( resp .",
    "@xmath142 ) although we do not know whether they are unique . however , our arguments and results are valid for _ any such _ functions .",
    "our purpose is now to derive the euler - lagrange equations of the problems considered , along with other important properties of the sequences @xmath141 and @xmath142 .",
    "we only state the results for @xmath141 .",
    "similar properties hold for @xmath142 , replacing @xmath44 and @xmath59 by @xmath143 and @xmath67 .",
    "the first order optimality conditions write :    the functions @xmath144 satisfying   are such that : for any functions @xmath145 @xmath146 this can be written equivalently as @xmath147 or , in terms of @xmath59 , as : @xmath148    equation   is obtained differentiating  .",
    "namely , for any @xmath145 and any @xmath105 , we have @xmath149 it holds : @xmath150 using  , we get , for any @xmath105 , @xmath151 which implies that @xmath152 is zero , that is , .",
    "equation   is the strong formulation of  . on the other hand ,",
    "is an immediate consequence of the following simple computations : @xmath153 since @xmath154 in @xmath21 and @xmath155 on @xmath66 .",
    "note that , taking @xmath156 and @xmath157 in the euler - lagrange equations   yields @xmath158 since @xmath159 .",
    "this will be useful below .",
    "let us now state two other properties of @xmath141 .",
    "the second order optimality conditions write :    [ lem : el2 ] the functions @xmath144 satisfying   are such that : for any functions @xmath145 @xmath160 which is equivalent to : for any functions @xmath145",
    "@xmath161    returning to equation  , we see that @xmath162 and @xmath163 , which is exactly  . for any @xmath164 ,",
    "taking @xmath165 as a test function in   shows @xmath166 this equivalently reads @xmath167 hence @xmath168 this yields  .",
    "we will also need the following optimality property of @xmath141 :    [ lem : prodscal ] the functions @xmath141 satisfying   are such that : @xmath169 @xmath170    we may assume without loss of generality that @xmath110 .",
    "the first equality is  . to prove the inequality ,",
    "let us introduce the supremum : @xmath171 using  , we have @xmath172 by definition of @xmath173 . on the other hand , consider @xmath174 a maximizing sequence associated to the supremum  @xmath173 : @xmath175 and @xmath176 .",
    "we have , using  , for all @xmath177 , @xmath178 and , letting @xmath179 , @xmath180 combining   and  , we get @xmath181 so that all the inequalities are actually equalities . by using the fact that , by  , @xmath182 , we thus have @xmath183 this concludes the proof .      before we get to the proof of the convergence of the approach in the next section ,",
    "let us conclude section  [ sec : presentation ] by some comments that relates the theoretical framework developed here to the practice .",
    "it is important to already note , although we will return to this in section  [ sec : discussion ] below , that the euler - lagrange equation is indeed the form of the algorithm manipulated in practice by the authors of  @xcite .",
    "the above variational setting is somewhat difficult to implement in practice .",
    "it requires to solve for the minimizers of ( and respectively ) , which can be extremely demanding computationally . in their implementation of the approach ( developed independently from the above nonlinear approximation theoretic framework ) ,",
    "ammar _ et al .",
    "_ therefore propose to search for the iterate @xmath141 ( and respectively @xmath142 ) not as a minimizer to optimization problems   and  , but as a solution to the associated euler - lagrange equations ( first order optimality conditions ) .",
    "the pure greedy algorithm is thus replaced by : set @xmath33 , and at iteration @xmath34 ,    1 .",
    "find @xmath35 and @xmath36 such that , for all functions @xmath184 ,   ( or its equivalent form ) holds .",
    "2 .   set @xmath185 .",
    "3 .   if @xmath39 , proceed to iteration @xmath40 .",
    "otherwise , stop .",
    "the orthogonal greedy algorithm is modified likewise .",
    "as already explained in the introduction , and in sharp contrast to the situation encountered for linear problems , being a solution to the euler - lagrange equation does not guarantee being a minimizer in this nonlinear framework .",
    "we will point out difficulties originating from this in section  [ sec : discussion ] .",
    "in addition to the above theoretical difficulty , and in fact somehow entangled to it , we have to mention that of course , the euler - lagrange equations  , as a nonlinear system , need to be solved iteratively . in  @xcite ,",
    "a simple fixed point procedure is employed : choose @xmath186 and , at iteration @xmath177 , compute @xmath187 solution to : @xmath188 until convergence is reached .",
    "we will also discuss below the convergence properties of this procedure on simple examples .",
    "[ rem : rhs ] in practice ( bearing in mind that the approach has been designed to solve high - dimensional problems ) , in order for the right - hand side terms in   to be computable , the function @xmath18 needs to be expressed as a sum of tensor products .",
    "otherwise , computing high dimensional integrals would be necessary , and this is a task of the same computational complexity as the original poisson problem .",
    "the function @xmath18 thus needs to enjoy some appropriate separation property with respect to the different coordinates .",
    "if @xmath18 is not given in such a form , it may be possible to first apply the singular value decomposition algorithm to get a good estimate of @xmath18 as a sum of tensor products ( see section  [ sec : svd ] ) .",
    "[ rem : hd ] in dimension @xmath189 ( on a parallelepipedic domain @xmath190 ) , the euler - lagrange equations   become : find functions @xmath191 such that : for any functions @xmath192 , @xmath193 this is a nonlinear system of @xmath14 equations , which only involves one - dimensional integrals by fubini theorem , provided that the data @xmath18 is expressed as a sum of tensor products ( see remark  [ rem : rhs ] ) .",
    "[ rem : disc ] we presented the algorithms without space discretization , which is required for the practical implementation . in practice , finite element spaces @xmath194 ( resp .",
    "@xmath195 ) are used to discretized @xmath70 ( resp .",
    "@xmath72 ) , where @xmath196 denotes a space discretization parameter .",
    "the space discretized version of   thus writes : find @xmath197 such that , for any functions @xmath198",
    "to start with , we prove that the approach converges",
    ". then we will turn to the rate of convergence .",
    "[ theo : cv_pga ] * [ pure greedy algorithm ] *    consider the pure greedy algorithm , and assume first that @xmath141 satisfies the euler - lagrange equations  .",
    "denote by @xmath200 the energy at iteration @xmath9 .",
    "we have @xmath201 assume in addition that @xmath141 is a minimizer of . then",
    ", @xmath202    immediate consequences of   and   are @xmath203 and @xmath204    let us first suppose that @xmath141 only satisfies the euler - lagrange equations  .",
    "we notice that , using   @xmath205 thus , @xmath206 is a nonnegative non increasing sequence .",
    "hence it converges .",
    "this implies that @xmath207 .",
    "next , notice that @xmath208 since by  , @xmath209 .",
    "this proves the first part of the theorem . at this stage , we have only used that @xmath141 satisfies the euler - lagrange equations  .    to conclude that @xmath210",
    ", we now need to assume that @xmath141 indeed satisfies the minimization problem  . we know that @xmath206 is a bounded sequence , and therefore , we may assume ( up to the extraction of a subsequence ) that @xmath59 converges weakly in @xmath30 to some @xmath211 .",
    "for any @xmath34 and for any functions @xmath184 , @xmath212 by passing to the limit this inequality , we have @xmath213 this implies that for any functions @xmath104 , @xmath214 thus , by lemma  [ lem : distrib ] , @xmath215 in the distributional sense , which , since @xmath211 , implies @xmath216 .",
    "this shows that there is only one possible limit for the subsequence @xmath59 and thus that the whole sequence itself weakly converges to @xmath68 .",
    "the convergence of @xmath59 to @xmath68 is actually strong in @xmath30 .",
    "the argument we use here is taken from  @xcite .",
    "using lemma  [ lem : prodscal ] , we have : for any @xmath217 @xmath218 define @xmath219 , @xmath220 , and , by induction , @xmath221 notice that @xmath222 since @xmath223 .",
    "for example , if @xmath224 is a decreasing sequence , then @xmath225 .",
    "now , we have : for any @xmath226 @xmath227 since @xmath228 and @xmath229 is converging , the previous inequality shows that the subsequence @xmath230 is a cauchy sequence , and therefore strongly converges to @xmath68 ( recall it is already known that @xmath59 weakly converges to @xmath68 ) .",
    "since @xmath231 is itself a converging sequence , this shows that @xmath232    a similar result holds for the orthogonal greedy algorithm .",
    "[ theo : cv_oga ] * [ orthogonal greedy algorithm ] *    consider the orthogonal greedy algorithm , and assume first that @xmath142 only satisfies the euler - lagrange equations   associated with   ( thus with @xmath233 in  ) .",
    "denote by @xmath234 the energy at iteration @xmath9 .",
    "we have @xmath235 assume in addition that @xmath142 is indeed a minimizer to the optimization problem  .",
    "then , @xmath236    immediate consequences of   and   are @xmath237 and @xmath238    let us first assume that @xmath142 only satisfies the euler - lagrange equations   ( with @xmath233 in  ) .",
    "notice that by   and  : @xmath239 thus , @xmath240 is a nonnegative non increasing sequence .",
    "hence it converges .",
    "this implies that @xmath241 , and proves the first part of the theorem , using the same arguments as in the proof of theorem  [ theo : cv_pga ] .",
    "let us now assume in addition that @xmath142 is a minimizer to .",
    "for fixed @xmath69 and @xmath71 , we derive from  : @xmath242 letting @xmath9 go to infinity , and using the same arguments as in the proof of theorem  [ theo : cv_pga ] , this implies that @xmath67 weakly converges to @xmath68 in @xmath30 .",
    "the proof of the strong convergence of @xmath67 to zero is then easy since , using the euler lagrange equations associated to  : @xmath243 and the right - hand side converges to @xmath68 .",
    "we now present an estimate of the rate of convergence for both the pure and the orthogonal greedy algorithms .",
    "these results are borrowed from  @xcite .",
    "we begin by only citing the result for pure greedy algorithm . on the other hand , with a view to showing the typical mathematical ingredients at play",
    ", we outline the proof of convergence of the orthogonal greedy algorithm , contained in the original article  @xcite .",
    "we first need to introduce a functional space adapted to the convergence analysis ( see  @xcite ) .",
    "we define the @xmath73 space as @xmath244 and we define the @xmath73-norm as @xmath245 for @xmath246 .    the following properties may readily be established :    * the space @xmath73 is a banach space .",
    "* the space @xmath73 is continuously embedded in @xmath30 .",
    "notice that , in the definition of @xmath73 , the function @xmath247 is indeed well defined in @xmath30 as a normally convergent series .",
    "this also shows that @xmath248 , and this imbedding is continuous by the triangle inequality @xmath249 .",
    "we do not know if there exists a simple characterization of functions in @xmath73 .",
    "let us however give simple examples of such functions .",
    "for any @xmath250 , @xmath251 .    without loss of generality",
    ", consider the case @xmath20 .",
    "using the fact that @xmath252 , where @xmath253 , is an orthonormal basis of @xmath126 , we can write any function @xmath254 as the series @xmath255 , where @xmath256 . it is well known that @xmath257 and , more generally , for any @xmath258 , @xmath259 on the other hand , @xmath260 since @xmath261 .",
    "thus , by the hlder inequality , we have , for any @xmath262 , if @xmath263 , @xmath264 since @xmath265 as soon as @xmath250 .",
    "[ rem : l1 ] more generally , in dimension @xmath189 , the same proof shows that : for any @xmath266 , @xmath251 .",
    "let us now give the rate of convergence of the pure greedy algorithm .",
    "for the details of the proof , we again refer to  @xcite .",
    "the proof is based on the fundamental lemma :    [ lem : dvt ] let us assume that @xmath246 .",
    "then , for any @xmath267 , @xmath268 and we have : @xmath269    the following technical result ( easily obtained by induction ) is also needed .",
    "[ lem : suite ] let @xmath270 be a sequence of non - negative real numbers and @xmath271 a positive real number such that @xmath272 and @xmath273 .",
    "then , @xmath274 , @xmath275    using lemma  [ lem : dvt ] and lemma  [ lem : suite ] , it is possible to show :    for @xmath246 , we have @xmath276    a better rate of convergence can be proven for the orthogonal greedy algorithm . for the orthogonal greedy algorithm ,",
    "the following lemma plays the role of lemma  [ lem : dvt ] .",
    "[ lem : dvto ] assume that @xmath246 .",
    "then , for any @xmath267 , @xmath277 and we have : @xmath278    since @xmath279 , it is clear that @xmath268 . the equality @xmath280 is obtained as a consequence of the euler - lagrange equations associated to the optimization problem on @xmath281 ( see  ) .",
    "since @xmath246 , for any @xmath282 , we can write @xmath283 with @xmath284 , and @xmath285 . by",
    ", we have @xmath286 , and therefore , using lemma  [ lem : prodscal ] : @xmath287 from which we conclude letting @xmath288 vanish .    for @xmath246 , we have @xmath289    we have , using   and lemma  [ lem : dvto ] : @xmath290 the conclusion is reached applying lemma  [ lem : suite ] with @xmath291 and @xmath292 .",
    "the rate of convergence of the pure greedy algorithm in   may be improved to @xmath293  @xcite .",
    "for both algorithms , it is known that there exists dictionaries and right - hand sides @xmath18 ( even simple ones , like a sum of only two elements of the dictionary ) such that the rate of convergence @xmath294 is attained ( see  @xcite ) . in that sense",
    ", the orthogonal greedy algorithm realizes the optimal rate of convergence .",
    "notice that this rate of convergence does not depend on the dimension of the problem .",
    "however , the assumption @xmath295 seems to be more and more demanding , in terms of regularity , as the dimension increases ( see remark  [ rem : l1 ] ) .",
    "we begin this section by considering the case when the laplace operator is replaced by the identity operator .",
    "we examine on this simplified case the discrepancy between the variational approach consisting in minimizing the energy and the non variational approach solving the euler - lagrange equation .",
    "the algorithms we have presented above are closely related to the singular value decomposition ( svd , also called _",
    "rank one decomposition _ ) .",
    "more precisely , omitting the gradient in the optimization problem   yields : find @xmath296 and @xmath297 such that @xmath298 with the recursion relation @xmath299 and @xmath300 .    in view of the exact same arguments as in the previous sections , the series @xmath301 can be shown to converge to @xmath27 in @xmath126 .",
    "this problem has a well - known companion discrete problem , namely the svd decomposition of a matrix ( see for example  @xcite ) .",
    "this corresponds to the case @xmath302 , @xmath303 , the integral @xmath304 is replaced by the discrete sum @xmath305 , @xmath306 is a matrix in @xmath307 and @xmath308 are two ( column ) vectors in @xmath309 . in this case",
    "the tensor product @xmath310 is simply the matrix @xmath311 .",
    "the matrices @xmath312 are then defined by recursion : @xmath313 and @xmath314 .",
    "an important property of the sequence @xmath141 generated by the algorithm in the svd case is the orthogonality relation : if @xmath315 @xmath316 in order to check this , let us first write the euler - lagrange equations in the svd case ( compare with  ): for any functions @xmath317 , @xmath318 this also reads ( compare with ): @xmath319 it is immediate to see that for @xmath110 and @xmath320 implies , @xmath321 likewise , it can be shown , for any @xmath322 and any @xmath323 @xmath324 the orthogonality property   is then easy to check using the fubini theorem and arguing by induction .",
    "a simple consequence of the orthogonality of the functions obtained by the algorithm is that , in the discrete version ( svd of a matrix @xmath325 ) the algorithm converges in a finite number of iterations ( namely @xmath326 ) . as usual in this situation ,",
    "practice may significantly deviate from the above theory if round - off errors due to floating - point computations are taken into account .",
    "this is especially true if the matrix is ill conditioned .        *",
    "\\(i ) the pure greedy algorithm and the orthogonal greedy algorithm are equivalent to one another in the svd case . *",
    "\\(ii ) the svd decomposition @xmath330 is unique . *",
    "\\(iii ) at iteration @xmath9 , @xmath331 is the minimizer of @xmath332 over all possible @xmath333 .      *",
    "\\(iv ) the only solutions to the euler lagrange equations   are the null solution @xmath334 and the tensor products @xmath335 ( for all @xmath34 ) in the svd decomposition of @xmath27 . *",
    "\\(v ) the solutions to the euler - lagrange equations which maximize the @xmath336-norm @xmath337 are exactly the solutions to the variational problem  .",
    "* \\(vi ) in dimension @xmath338 , the solutions to the euler - lagrange equation that satisfy the second order optimality conditions are exactly the solutions of the original variational problem  .",
    "notice that there is no loss of generality in assuming @xmath339 , and @xmath340 decreasing in   ( [ eq : nondeg ] ) ( up to a change of the @xmath341 ) .",
    "the fundamental assumption in nondegeneracy is thus that @xmath342 if @xmath315 . when the decomposition has some degeneracy ( _ i.e. _ several @xmath9 correspond to the same @xmath343 in ( [ eq : nondeg ] ) ) then properties ( i)-(iii)-(v)-(vi ) still hold true . on the other hand , in ( ii )",
    "the svd is only unique up to rotations within eigenspaces and property ( iv ) must be modified accordingly . in short ,",
    "the only other solutions beyond those mentioned above consist of tensor products of linear combinations of functions within a given eigenspace .",
    "we skip such technicalities .",
    "the degenerate case indeed does not differ much from the non degenerate case above in the sense that a complete understanding of the algorithm , both in its variational and in its non variational forms , is at hand .",
    "we first prove assertion ( iv ) .",
    "it is sufficient to consider the first iteration of the algorithm . using the svd decomposition of @xmath27 ,",
    "the euler - lagrange equations write : for any functions @xmath317 , @xmath344 using the orthogonality property , and successively @xmath345 and @xmath346 as test functions , we get @xmath347 which yields : @xmath274 @xmath348 since for @xmath315 , @xmath342 , this shows that either @xmath349 , or there exists a unique @xmath350 such that @xmath351 and @xmath352 , @xmath353 ( because the product @xmath354 cancels and thus each of the term cancels because of the euler lagrange equations ) . since by the euler - lagrange equations , @xmath355 ( resp .",
    "@xmath356 ) can be decomposed on the set of orthogonal functions @xmath357 ( resp .",
    "@xmath358 ) , we get @xmath359 , which concludes the proof of assertion ( iv ) .",
    "assertion ( v ) is readily obtained using ( iv ) and the orthogonality property .",
    "notice that assertion ( ii ) is a consequence of assertions ( iv)-(v ) . to prove assertion ( vi ) , we recall that the second order optimality condition writes ( see lemma  [ lem : el2 ] , adapted to the svd case ) : @xmath360 , @xmath361 it is again enough to consider the case @xmath110 .",
    "let us consider a solution of the euler - lagrange equation : @xmath359 , and let us take as test functions in   @xmath362 , for all @xmath34 .",
    "we obtain that for all @xmath34 , @xmath363 which concludes the proof of assertion ( vi ) .",
    "notice that in dimension @xmath364 , assertion ( vi ) seemingly does not hold : the solutions to the euler - lagrange equation that satisfy the second order optimality conditions may not necessarily be global minimizers .",
    "[ [ link - between - the - euler - lagrange - equations - and - the - variational - problem ] ] link between the euler - lagrange equations and the variational problem ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    properties ( iv)-(v)-(vi ) above tend to indicate that , at least in the svd case , the consideration of the solutions to the euler - lagrange equations is somehow close to the consideration of the minimization problems .",
    "indeed , if we assume that at each iteration , non zero solutions of the euler - lagrange equations are obtained ( of course under the assumption  @xmath365 in  ) , then the non variational form of the algorithm , if it converges , will eventually provide the correct decomposition .",
    "we however would like to mention two practical difficulties .",
    "first , it is not clear in practice how to compute the norm @xmath231 to check the convergence , since this is in general a high dimensional integral .",
    "a more realistic convergence criterion would read : @xmath366 _ is small compared to _ @xmath367 .",
    "however , using this criterion , it is possible to erroneously conclude that the algorithm has converged , while a term with an arbitrarily large contribution has been missed .",
    "indeed , consider again , to convey the idea , the case ( [ eq : nondeg])-([eq : nondeg2 ] ) .",
    "assume that the tensor product @xmath368 is picked at first iteration ( _ instead of _ the tensor product @xmath369 which would be selected by the _",
    "variational _ version of the algorithm ) .",
    "assume similarly that @xmath370 is picked at second iteration , and so on and so forth .",
    "in such a situation , one would then decide the series @xmath371 solves the problem , while obsviously it does not .",
    "we will show below ( see section  [ sec : resol - el ] ) that in the simple fixed - point procedure we have described above to solve the nonlinear euler - lagrange equations , the fact that @xmath372 is missed , and never obtained as a solution , may indeed happen as soon as the initial condition of the iterative procedure has a zero component on the eigenspace associated to @xmath373 .",
    "second , without an additional assumption reminiscent of the minimizing character of the solution , iteratively solving the euler - lagrange equations may result in picking the tensor products @xmath335 in an order not appropriate for computational efficiency .",
    "such an assumption is present in assertions ( v ) and ( vi ) . for the illustration ,",
    "let us indeed consider a svd decomposition @xmath374 for some functions @xmath375 and @xmath376 that become highly oscillatory when @xmath9 grows .",
    "it is clear that we may obtain an error in @xmath74 norm that is arbitrarily large at each iteration of the algorithm .",
    "in particular , it may happen ( in particular if smooth functions are chosen as initial guesses for the nonlinear iteration loop solving the euler - lagrange equation ) that the highly oscillatory products are only selected in the latest iterations , although they contribute to the error in a major way .",
    "a poor efficiency of the algorithm follows .",
    "inevitably , reaching computational efficiency therefore requires to account for some additional assumptions to select the appropriate solutions among the many solutions of the euler - lagrange equations .",
    "indeed , consider a svd @xmath377 , such that @xmath375 and @xmath376 are non - zero functions for all @xmath378 ( and @xmath339 ) .",
    "then , any @xmath379 is a solution of the euler lagrange equation at the first iteration , and the norm of the @xmath379 which is selected may be arbitrarily small since the series @xmath380 converges , and therefore @xmath381 goes to zero .",
    "a similar argument applies to all iterations of the algorithm .",
    "therefore , a criterion of convergence of the type @xmath366 _ is small compared to _ @xmath382 may again yield an erroneous conclusion and lead to a prematurate termination of the iterations .",
    "a last comment we would like to make on the svd case again concerns the practical implementation of the solution procedure for the euler - lagrange equations .",
    "consider the discrete case for clarity .",
    "the fixed point procedure then simply writes ( for a fixed @xmath9 ) : at iteration @xmath177 , compute two vectors @xmath383 such that : @xmath384 ( r_n^{k+1})^t r_n^{k+1 } s_n^{k+1 } = ( g_{n-1})^t r_n^{k+1}. \\end{array } \\right.\\ ] ] one can check that this procedure is similar to the power method to compute the largest eigenvalues ( and associated eigenvectors ) of the matrix @xmath385 . let us explain this .",
    "the recursion writes : @xmath386 where @xmath387 here denotes the euclidean norm and where we have omitted the subscripts @xmath9 and @xmath388 for clarity . to study the convergence of this algorithm one can assume that @xmath306 is actually a diagonal matrix up to a change of coordinate .",
    "indeed , let us introduce the svd decomposition of @xmath306 : @xmath389 where @xmath390 and @xmath391 are two orthogonal matrices , and @xmath392 is a diagonal matrix with non - negative coefficients .",
    "without loss of generality , we may assume that @xmath393 , @xmath394 , @xmath395 , @xmath396 and @xmath397 .",
    "for simplicity , assume that @xmath398 .",
    "then , setting @xmath399 , the recursion reads @xmath400 and the convergence is easy to study .",
    "one can check that if the initial condition @xmath401 has a non - zero component along the vector associated to the largest value @xmath402 , then @xmath403 converges to this vector .",
    "the convergence is geometric , with a rate related to @xmath404 ( at least if the initial condition @xmath401 has a non - zero component along the vector associated to @xmath405 , otherwise @xmath405 should be replaced by the appropriate largest @xmath406 , with @xmath407 ) .",
    "of course , if the initial condition is not well chosen ( namely , if @xmath401 has a zero component along the vector associated to @xmath402 ) , then this algorithm can not converge to the solution of the variational version of the algorithm .",
    "we would like to mention that this method to compute the svd of a matrix is actually known to poorly perform in practice .",
    "more precisely , the approach is very sensitive to numerical perturbations , see  ( * ? ? ?",
    "* lecture 31 ) ) since the condition number of @xmath408 is typically large .",
    "alternative methods exist that compute the svd decomposition , and it would be interesting to use these techniques as guidelines to build more efficient procedures to solve the nonlinear euler - lagrange equations  .",
    "we first observe , on a general note , that a property similar to   holds in the poisson case , namely : @xmath409 this , however , does not seem to imply any simple orthogonality property as  . in particular , in the poisson case , it is generally wrong that , for @xmath315 , @xmath410 .",
    "next , we remark that none of the properties ( i)-(ii)-(iii ) holds in the poisson case . likewise , we are not able to characterize the list of solutions to the euler - lagrange equations as we did in ( iv)-(v)-(vi ) .",
    "this is for the generic situation , but in order to better demonstrate the connections between the svd case above and the poisson case , let us show that , in fact , the poisson case necessarily embeds all the difficulties of the svd case . for this purpose , we consider the original algorithm ( for the poisson problem ) performed for a particular right - hand - side @xmath411 , namely @xmath412 \\text{$\\phi_k$ ( resp .",
    "$ \\psi_k$ ) are eigenfunctions of}\\\\[4pt ] \\text{the homogeneous dirichlet operator    $ -\\partial_{xx}$ ( resp .",
    "$ -\\partial_{yy}$)}\\\\[4pt ] \\text{and satisfy $ \\forall k , l , \\ , \\int \\phi_k \\phi_l = \\int    \\psi_k \\psi_l = \\delta_{k , l}$ , } \\end{array } \\right.\\ ] ] where @xmath413 is again the kronecker symbol .",
    "then , it can be shown that , as in the svd case , @xmath414 are indeed solution to the euler - lagrange equations  .",
    "this suffices to show the non uniqueness of the solution .",
    "furthermore , and in sharp contrast to  ( iv ) , there even exist solutions to the euler lagrange equations that are not of the above form .    here is an example of the latter claim . consider the case @xmath415 , associated with an eigenvalue @xmath373 and @xmath416 , associated with an eigenvalue @xmath417 .",
    "we suppose @xmath418 for @xmath419 .",
    "we are looking for @xmath69 and @xmath71 solution to the euler - lagrange equations @xmath420 then , it can be checked that @xmath421 and @xmath422 are solution to the euler - lagrange equations , with the following set of parameters : @xmath423 , @xmath424 , @xmath425 , @xmath426 , @xmath427 and @xmath428 .",
    "likewise , it is immediate to see that ( vii ) still holds . in view of the above remarks",
    ", it seems difficult to devise ( and , even more difficult , to prove the convergence of ) efficient iterative procedures to correctly solve the euler - lagrange equation .",
    "we now show some numerical tests .",
    "even though the algorithms presented above have been designed for solving problems in high dimension , we restrict ourselves to the two - dimensional case . for numerical results in higher dimension , we refer to  @xcite .",
    "moreover , we consider the discrete case mentioned in section  [ sec : svd ] , which writes ( compare with  ): for a given symmetric positive definite matrix @xmath429 ( which plays the role of the one - dimensional operator @xmath430 ) , and a given matrix @xmath431 ( which plays the role of the right - hand side @xmath18 ) : @xmath432 here , the dimension @xmath433 typically corresponds to the number of points used to discretize the one - dimensional functions @xmath434 or @xmath435 . to this problem is associated the variational problem ( compare with  ) @xmath436 where , for two matrices @xmath437 , @xmath438 .",
    "the matrix @xmath306 is built as a sum of rank one matrices @xmath439 with @xmath440 , using the following pure greedy algorithm ( compare with the algorithm presented in section  [ sec : algo ] ) :        as explained in section  [ sec : el ] , step 1 of the above algorithm is replaced in practice by the resolution of the associated euler - lagrange equations .",
    "this consists in finding two vectors @xmath442 and @xmath443 in @xmath444 solution to the nonlinear equations : @xmath449 \\|r_n\\|^2 \\ , d s_n + \\|r_n\\|_d^2 \\ , s_n   = f_{n-1}^t r_n , \\end{array } \\right.\\ ] ] where , for any vectors @xmath450 , we set @xmath451",
    ". this nonlinear problem is solved by a simple fixed point procedure ( as  ) .",
    "we have observed in practice that choosing a random vector as an initial condition for the fixed point procedure is more efficient than taking a given deterministic vector ( like @xmath452 ) .",
    "this is of course related to the convergence properties of the fixed point procedure we discussed in section  [ sec : resol - el ] .      in this section ,",
    "we take @xmath453 diagonal , with @xmath454 on the diagonal , and a random matrix @xmath455 .",
    "the parameter @xmath288 is @xmath456 .",
    "we observe that the algorithm always converges .",
    "this means that , in practice , the solutions of the euler - lagrange equations   selected by the fixed point procedure are appropriate .    on figure  [ fig : nrj ] , we plot the energy @xmath457 , where @xmath446 .",
    "we observe that the energy rapidly decreases and next reaches a plateau .",
    "this is a general feature that we observe on all the tests we perfomed .",
    "consider , for the prototypical case of an advection diffusion equation : @xmath460 where @xmath461 is a given smooth velocity field .",
    "when @xmath462 for some real - valued function @xmath391 , problem ( [ eq : adv_diff ] ) is equivalent to minimizing the energy @xmath463 when this is not the case , it is not in general possible to recast   in terms of a minimization problem .",
    "however , a variational formulation can be written as : find @xmath464 such that , for all @xmath465 , @xmath466 it is proposed in  @xcite to use this variational formulation in step 1 and 2 of the orthogonal greedy algorithm .",
    "the iterations then write :      1 .",
    "find @xmath35 and @xmath36 such that , for all functions @xmath184 , @xmath467 2 .",
    "find @xmath468 such that for all @xmath469 @xmath470 3 .",
    "set @xmath471 .",
    "4 .   if @xmath472 , proceed to iteration @xmath40 .",
    "otherwise , stop .        1 .",
    "find @xmath442 and @xmath443 two vectors in @xmath444 such that : @xmath476 \\|r_n\\|^2 \\ , b s_n + \\|r_n\\|_b^2 \\ , s_n = f_{n-1}^t r_n . \\end{array } \\right.\\ ] ] 2 .",
    "set @xmath477 .",
    "3 .   if @xmath448 , proceed to iteration @xmath40 . otherwise stop .",
    "we consider the case when @xmath478 with @xmath453 symmetric positive definite , and @xmath271 antisymmetric , so that we know there exists a unique solution to  . on the numerical tests we have performed",
    ", the algorithm seems to converge . in the absence of any energy minimization principle , it is however unclear to us how to prove convergence of this algorithm .",
    "a.  ammar , b.  mokdad , f.  chinesta , and r.  keunings . a new family of solvers for some classes of multidimensional partial differential equations encountered in kinetic theory modeling of complex fluids .",
    ", 139:153176 , 2006 ."
  ],
  "abstract_text": [
    "<S> we investigate mathematically a nonlinear approximation type approach recently introduced in  @xcite to solve high dimensional partial differential equations . </S>",
    "<S> we show the link between the approach and the _ greedy algorithms _ of approximation theory studied _ </S>",
    "<S> e.g. _ in  @xcite . on the prototypical case of the poisson equation , </S>",
    "<S> we show that a variational version of the approach , based on minimization of energies , converges . on the other hand , we show various theoretical and numerical difficulties arising with the non variational version of the approach , consisting of simply solving the first order optimality equations of the problem . several unsolved issues are indicated in order to motivate further research . </S>"
  ]
}