{
  "article_text": [
    "many image recovery problems can be formulated in hilbert spaces @xmath0 and @xmath1 as structured optimization problems of the form @xmath2 where , for every @xmath3 , @xmath4 is a proper lower semicontinuous convex function from @xmath5 to @xmath6-\\infty,+\\infty\\right]}}$ ] and @xmath7 is a bounded linear operator from @xmath0 to @xmath5 .",
    "for example , the functions @xmath8 may model data fidelity terms , smooth or nonsmooth measures of regularity , or hard constraints on the solution . in recent years",
    ", many algorithms have been developed to solve such a problem by taking advantage of recent advances in convex optimization , especially in the development of proximal tools ( see @xcite and the references therein ) . in image processing , however , solving such a problem still poses a number of conceptual and numerical challenges .",
    "first of all , one often looks for methods which have the ability to split the problem by activating each of the functions through elementary processing steps which can be computed in parallel .",
    "this makes it possible to reduce the complexity of the original problem and to benefit from existing parallel computing architectures .",
    "secondly , it is often useful to design algorithms which can exploit , in a flexible manner , the structure of the problem .",
    "in particular , some of the functions may be lipschitz differentiable in which case they should be exploited through their gradient rather than through their proximity operator , which is usually harder to implement ( examples of proximity operators with closed - form expression can be found in @xcite ) . in some problems , the functions @xmath9 can be expressed as the infimal convolution of simpler functions ( see @xcite and the references therein ) .",
    "last but not least , in image recovery , the operators @xmath10 may be of very large size so that their inversions are costly ( e.g. , in reconstruction problems ) .",
    "finding algorithms which do not require to perform inversions of these operators is thus of paramount importance .",
    "note that all the existing convex optimization algorithms do not have these desirable properties .",
    "for example , the alternating direction method of multipliers ( admm ) @xcite requires a stringent assumption of invertibility of the involved linear operator .",
    "parallel versions of admm @xcite and related parallel proximal algorithm ( ppxa ) @xcite usually necessitate a linear inversion to be performed at each iteration .",
    "also , early primal - dual algorithms @xcite did not make it possible to handle smooth functions through their gradients .",
    "only recently , have primal - dual methods been proposed with this feature .",
    "such work was initiated in @xcite in the line of @xcite and subsequent developments can be found in @xcite . as will be seen in the present paper ,",
    "another advantage of these approaches is that they can be coupled with variable metric strategies which can potentially accelerate their convergence .    in section  [ sec:2 ] ,",
    "we provide some background on convex analysis and monotone operator theory . in section  [ sec:3 ]",
    ", we introduce a general form of the forward - backward algorithm which uses a variable metric .",
    "this algorithm is employed in section  [ sec:4 ] to develop a versatile family of primal - dual proximal methods .",
    "several particular instances of this framework are discussed .",
    "finally , we provide illustrating numerical results in section  [ sec:5 ] .",
    "monotone operator theory @xcite provides a both insightful and elegant framework for dealing with convex optimization problems and developing new solution algorithms that could not be devised using purely variational tools .",
    "we summarize a number of related concepts that will be needed .    throughout , @xmath0 , @xmath11 , and @xmath12 are real hilbert spaces .",
    "we denote the scalar product of a hilbert space by @xmath13 and the associated norm by @xmath14 .",
    "the symbol @xmath15 denotes weak convergence , and @xmath16 denotes the identity operator .",
    "we denote by @xmath17 the space of bounded linear operators from @xmath0 to @xmath11 , we set @xmath18 , where @xmath19 denotes the adjoint of @xmath20 .",
    "the loewner partial ordering on @xmath21 is denoted by @xmath22 . for every @xmath23",
    ", we set @xmath24 and we denote by @xmath25 the square root of @xmath26 .",
    "moreover , for every @xmath27 and @xmath28 , we define the norm @xmath29 .",
    "we denote by @xmath30 the hilbert direct sum of the hilbert spaces @xmath12 , i.e. , their product space equipped with the scalar product @xmath31 where @xmath32 and @xmath33 denote generic elements in @xmath34 .",
    "let @xmath35 be a set - valued operator .",
    "we denote by @xmath36 the graph of @xmath37 , by @xmath38 the set of zeros of @xmath37 , and by @xmath39 its range .",
    "the inverse of @xmath37 is @xmath40 , and the resolvent of @xmath37 is @xmath41 .",
    "moreover , @xmath37 is monotone if @xmath42 and maximally monotone if it is monotone and there exists no monotone operator @xmath43 such that @xmath44 and @xmath45 .",
    "an operator @xmath46 is @xmath47-cocoercive for some @xmath480,+\\infty\\right[}}$ ] if @xmath49 the conjugate of a function @xmath50-\\infty,+\\infty\\right]}}$ ] is @xmath51}}\\colon u\\mapsto \\sup_{x\\in{\\ensuremath{\\mathcal h}}}\\big({\\left\\langle{x}\\mid { u } \\right\\rangle}-f(x)\\big),\\ ] ] and the infimal convolution of @xmath52 with @xmath53-\\infty,+\\infty\\right]}}$ ] is @xmath54}}\\colon x\\mapsto \\inf_{y\\in{\\ensuremath{\\mathcal h}}}\\big(f(y)+g(x - y)\\big).\\ ] ] the class of lower semicontinuous convex functions @xmath50-\\infty,+\\infty\\right]}}$ ] such that @xmath55 is denoted by @xmath56 . if @xmath57 , then @xmath58 and the subdifferential of @xmath52 is the maximally monotone operator @xmath59 let @xmath26 for some @xmath600,+\\infty\\right[}}$ ] .",
    "the proximity operator of @xmath57 relative to the metric induced by @xmath61 is ( * ? ? ?",
    "* section  xv.4 ) @xmath62 when @xmath63 , we retrieve the standard definition of the proximity operator @xcite .",
    "let @xmath64 be a nonempty subset of @xmath0 .",
    "the indicator function of @xmath64 is defined on @xmath0 as @xmath65 finally , @xmath66 denotes the set of summable sequences in @xmath67 .",
    "optimization problems can often be reduced to finding a zero of a sum of two maximally monotone operators @xmath37 and @xmath68 acting on @xmath0 . when @xmath68 is cocoercive ( see ) , a useful algorithm to solve this problem is the forward - backward algorithm , which can be formulated in a general form involving a variable metric as shown in the next result .",
    "[ t:1 ] let @xmath600,+\\infty\\right[}}$ ] , let @xmath480,+\\infty\\right[}}$ ] , let @xmath35 be maximally monotone , and let @xmath46 be cocoercive .",
    "let @xmath69 , and let @xmath70 be a sequence in @xmath71 such that @xmath72 and @xmath73 is @xmath47-cocoercive .",
    "let @xmath74 be a sequence in @xmath750,1\\right]$ ] such that @xmath76 and let @xmath77 be a sequence in @xmath780,2\\beta[$ ] such that @xmath79 and @xmath80 .",
    "let @xmath81 , and let @xmath82 and @xmath83 be absolutely summable sequences in @xmath0 .",
    "suppose that @xmath84 , and set @xmath85 x_{n+1}=x_n+\\lambda_n\\big(j_{\\gamma_n v_n a}\\ , ( y_n)+a_n - x_n\\big ) .",
    "\\end{array } \\right.\\\\[2 mm ] \\end{array}\\ ] ] then @xmath86 for some @xmath87 .    at iteration @xmath88 , variables @xmath89 and @xmath90 model numerical errors possibly arising when applying @xmath91 or @xmath68",
    "note also that , if @xmath68 is @xmath92-cocoercive with @xmath930,+\\infty\\right[}}$ ] , one can choose @xmath94 , which allows us to retrieve ( * ? ? ?",
    "* theorem  4.1 ) . in the next section",
    ", we shall see how a judicious use of this result allows us to derive a variety of flexible convex optimization algorithms .",
    "a wide array of optimization problems encountered in image processing are instances of the following one , which was first investigated in @xcite and can be viewed as a more structured version of the minimization problem in :    [ prob:2 ] let @xmath95 , let @xmath96 be a strictly positive integer , let @xmath57 , and let @xmath97 be convex and differentiable with a lipschitzian gradient . for every @xmath98 , let @xmath99 , let @xmath100 , let @xmath101 be strongly convex , , @xmath102 is @xmath103-strongly convex with @xmath1040,+\\infty\\right[}}$ ] if and only if @xmath105 is @xmath106-lipschitz differentiable ( * ? ? ?",
    "* theorem  18.15 ) . ] and suppose that @xmath107 .",
    "suppose that @xmath108 consider the problem @xmath109 and the dual problem @xmath110    note that in the special case when @xmath111 , @xmath112 reduces to @xmath4 in .",
    "let us now examine how problem [ prob:2 ] can be reformulated from the standpoint of monotone operators . to this end , let us define @xmath113 , @xmath114 and @xmath115 by @xmath116 let us now introduce the product space @xmath117 and the operators @xmath118 and @xmath119 the operator @xmath120 can be shown to be maximally monotone , whereas @xmath121 is cocoercive .",
    "a key observation in this context is that , if there exists @xmath122 such that @xmath123 , then @xmath124 is a pair of primal - dual solutions to problem [ prob:2 ] @xcite .",
    "this connection with the construction for a zero of @xmath125 makes it possible to apply a forward - backward algorithm as discussed in section [ sec:3 ] , by using a linear operator @xmath126 to change the metric at each iteration @xmath88 .",
    "depending on the form of this operator various algorithms can be obtained .",
    "let @xmath600,+\\infty\\right[}}$ ] , let @xmath127 be a sequence in @xmath71 such that @xmath128 @xmath129 . for every @xmath98 , let @xmath130 be a sequence in @xmath131 such that @xmath128 @xmath132 . a first possible choice for @xmath133 is given by @xmath134 where @xmath135 the following result constitutes a direct extension of ( * ?",
    "* example  6.4 ) :    [ ex:2012 - 30 - 04 ] let @xmath136 , and let @xmath82 and @xmath137 be absolutely summable sequences in @xmath0 . for every @xmath98 , let @xmath138 , let @xmath139 and @xmath140 be absolutely summable sequences in @xmath5 . for every @xmath141 , let @xmath1420,+\\infty\\right[}}$ ] be a lipschitz constant of @xmath143 and , for every @xmath3 , let @xmath1440,+\\infty\\right[}}$ ] be a lipschitz constant of @xmath145 .",
    "let @xmath74 be a sequence in @xmath780,1]$ ] such that @xmath146 .",
    "for every @xmath147 , set @xmath148 and suppose that @xmath149 set @xmath150 \\end{array } \\right.\\\\[2 mm ] \\end{array}\\end{aligned}\\ ] ] then @xmath151 converges weakly to a solution to , for every @xmath98 @xmath152 converges weakly to some @xmath153 , and @xmath154 is a solution to .",
    "in the special case when @xmath155 with @xmath1560,+\\infty\\right[}}$ ] and , for every @xmath3 , @xmath157 with @xmath1580,+\\infty\\right[}}$ ] , we recover the parallel algorithm proposed in @xcite .",
    "variants of this algorithm where , for every @xmath3 , @xmath111 are also investigated in @xcite . in this case , less restrictive assumptions on the choice of @xmath159 can be made .",
    "note that this algorithm itself can be viewed as a generalization of the algorithm which constitutes the main topic of @xcite ( designated by some authors as pdhg ) .",
    "a preconditioned version of this algorithm was proposed in @xcite corresponding to the case when @xmath160 , @xmath128 @xmath161 and @xmath162 are constant matrices , and no error term is taken into account .",
    "algorithm when , for every @xmath141 , @xmath163 , @xmath161 and @xmath164 are diagonal matrices , @xmath165 , and @xmath166 @xmath111 appears also to be closely related to the adaptive method in @xcite .",
    "let @xmath600,+\\infty\\right[}}$ ] , let @xmath127 be a sequence in @xmath71 such that @xmath128 @xmath129",
    ". for every @xmath98 , let @xmath130 be a sequence in @xmath131 such that @xmath128 @xmath132 .",
    "a second possible choice for @xmath133 is given by the following diagonal form : @xmath167 where @xmath168 is given by .",
    "the following result can then be deduced from theorem  [ t:1 ] .",
    "its proof is skipped due to the lack of space .",
    "[ ex:2014 - 25 - 01 ] let @xmath136 , and let @xmath137 be an absolutely summable sequence in @xmath0",
    ". for every @xmath98 , let @xmath169 , let @xmath139 and @xmath140 be absolutely summable sequences in @xmath5 .",
    "for every @xmath141 , let @xmath1420,+\\infty\\right[}}$ ] be a lipschitz constant of @xmath143 and , for every @xmath3 , let @xmath1440,+\\infty\\right[}}$ ] be a lipschitz constant of @xmath145 .",
    "let @xmath74 be a sequence in @xmath780,1]$ ] such that @xmath146 .",
    "for every @xmath147 , set @xmath170 and suppose that @xmath171 set @xmath172 p_n = s_n - u_n \\sum_{i=1}^m l_i^ * q_{i , n}\\\\ x_{n+1}=x_n+\\lambda_n(p_n - x_n).\\\\ \\end{array } \\right.\\\\[2 mm ] \\end{array}\\end{aligned}\\ ] ] assume that @xmath173 .",
    "then @xmath151 converges weakly to a solution to , for every @xmath98 @xmath152 converges weakly to some @xmath153 , and @xmath154 is a solution to .",
    "the algorithm proposed in @xcite is a special case of the previous one , in the absence of errors , when @xmath174 , @xmath0 and @xmath175 are finite dimensional spaces , @xmath176 , @xmath155 with @xmath1560,+\\infty\\right[}}$ ] , @xmath177 with @xmath1780,+\\infty\\right[}}$ ] , and no relaxation ( @xmath179 or a constant one ( @xmath180 ) is performed .",
    "[ cols=\"^,^ \" , ]",
    "we illustrate the flexibility of the proposed primal - dual algorithms on an image recovery example .",
    "two observed images @xmath181 and @xmath182 of the same scene @xmath183 ( @xmath184 ) are available ( see fig .",
    "[ fig : rest](a)-(c ) ) . the first one is corrupted with a noise with a variance @xmath185 , while the second one has been degraded by a linear operator @xmath186 ( @xmath187 uniform blur ) and a noise with variance @xmath188 .",
    "the noise components are mutually statistically independent , additive , zero - mean , white , and gaussian distributed .",
    "note that this kind of multivariate restoration problem is encountered in some push - broom satellite imaging systems .",
    "an estimate @xmath189 of @xmath190 is computed as a solution to where @xmath191 , @xmath192 , @xmath193 , @xmath194 , @xmath195^n},\\quad   g_2 = \\kappa \\|\\cdot\\|_{1,2 } , \\label{e : g2}\\\\ f & = 0,\\quad \\ell_1 = \\ell_2 = \\iota_{\\{0\\}}\\end{aligned}\\ ] ] where the second function in denotes the @xmath196-norm and @xmath1970,+\\infty\\right[}}$ ] .",
    "in addition , @xmath198 and @xmath199^\\top$ ] where @xmath200 and @xmath201 are horizontal and vertical discrete gradient operators .",
    "function @xmath202 introduces some a priori constraint on the range values in the target image , while function @xmath203 corresponds to a classical total variation regularization .",
    "the minimization problem is solved numerically by using algorithm with @xmath163 . in a first experiment ,",
    "standard choices of the algorithm parameters are made by setting @xmath155 , @xmath204 , and @xmath205 with @xmath2060,+\\infty\\right[}}^3 $ ] . in a second experiment ,",
    "a more sophisticated choice of the metric is made .",
    "the operators @xmath207 , @xmath208 and @xmath209 are still chosen diagonal and constant in order to facilitate the implementation of the algorithm , but the diagonal values are optimized in an empirical manner .",
    "a similar strategy was applied in @xcite in the case of algorithm .",
    "the regularization parameter @xmath210 has been set so as to get the highest value of the resulting signal - to - noise ratio ( snr ) .",
    "the restored image is displayed in fig .",
    "[ fig : rest](d ) . fig .",
    "[ fig : conv ] shows the convergence profile of the algorithm .",
    "we plot the evolution of the normalized euclidean distance ( in log scale ) between the iterates and @xmath189 in terms of computational time ( ` matlab r2011b ` codes running on a single - core intel i7 - 2620 m cpu@2.7 ghz with 8 gb of ram ) .",
    "an approximation of @xmath189 obtained after 5000 iterations is used .",
    "this result illustrates the fact that an appropriate choice of the metric may be beneficial in terms of speed of convergence .",
    "s.  r. becker and p.  l. combettes , `` an algorithm for splitting parallel sums of linearly composed monotone operators , with applications to signal recovery , '' _ nonlinear convex anal .",
    "_ , vol .  15 , no .  1 ,",
    "137159 , jan .",
    "r.  i. bo and c.  hendrich , `` convergence analysis for a primal - dual monotone + skew splitting algorithm with applications to total variation minimization , '' _ j. math .",
    "imaging vision _ , 2013 , accepted http://www.mat.univie.ac.at/@xmath211rabot/publications/jour.pdf .",
    "p.  chen , j.  huang , and x.  zhang , `` a primal - dual fixed point algorithm for convex separable minimization with applications to image restoration , '' _ inverse problems _ , vol .",
    "29 , no .  2 , 2013 , doi:10.1088/0266 - 5611/29/2/025011 .",
    " , `` proximal splitting methods in signal processing , '' in _ fixed - point algorithms for inverse problems in science and engineering _ , h.  h. bauschke , r.  s. burachik , p.  l. combettes , v.  elser , d.  r. luke , and h.  wolkowicz , eds.1em plus 0.5em minus 0.4emnew york : springer - verlag , 2011 , pp .",
    "185212 .",
    " , `` primal - dual splitting algorithm for solving inclusions with mixtures of composite , lipschitzian , and parallel - sum type monotone operators , '' _ set - valued var .",
    "_ , vol .",
    "20 , no .  2 ,",
    "pp . 307330 , june 2012 .",
    "p.  l. combettes and b.  c. v , `` variable metric forward - backward splitting with applications to monotone inclusions in duality , '' _ optimization _ , 2012 , published online doi:10.1080/02331934.2012.733883 .",
    "e.  esser , x.  zhang , and t.  chan , `` a general framework for a class of first order primal - dual algorithms for convex optimization in imaging science , '' _ siam j. imaging sci .",
    "_ , vol .  3 , no .  4 ,",
    "pp . 10151046 , 2010 .",
    "m.  a.  t. figueiredo and r.  d. nowak , `` deconvolution of poissonian images using variable splitting and augmented lagrangian optimization , '' in _ ieee work .",
    "_ , cardiff , united kingdom , aug . 31 - sept . 3 2009 , pp .",
    "x - x+4 .",
    "m.  fortin and r.  glowinski , eds . , _ augmented lagrangian methods : applications to the numerical solution of boundary - value problems_.1em plus 0.5em minus 0.4emamsterdam : north - holland : elsevier science ltd , 1983 .",
    "t.  pock and a.  chambolle , `` diagonal preconditioning for first order primal - dual algorithms in convex optimization , '' in _ proc .",
    "vis . _ , barcelona , spain , nov . 6 - 13 2011 , pp . 17621769 .",
    "a.  repetti , e.  chouzenoux , and j .- c .",
    "pesquet , `` a penalized weighted least squares approach for restoring data corrupted with signal - dependent noise , '' in _ proc .",
    "sig . and image proc . conference _ ,",
    "bucharest , romania , 27 - 31 aug .",
    "2012 , pp ."
  ],
  "abstract_text": [
    "<S> a wide array of image recovery problems can be abstracted into the problem of minimizing a sum of composite convex functions in a hilbert space . to solve such problems , </S>",
    "<S> primal - dual proximal approaches have been developed which provide efficient solutions to large - scale optimization problems . </S>",
    "<S> the objective of this paper is to show that a number of existing algorithms can be derived from a general form of the forward - backward algorithm applied in a suitable product space . </S>",
    "<S> our approach also allows us to develop useful extensions of existing algorithms by introducing a variable metric . </S>",
    "<S> an illustration to image restoration is provided .    </S>",
    "<S> * keywords . * </S>",
    "<S> convex optimization , duality , parallel computing , proximal algorithm , variational methods , image recovery . </S>"
  ]
}