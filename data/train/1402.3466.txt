{
  "article_text": [
    "the particle filter enables its user to efficiently compute integral characteristics ( moments ) of distributions of interest . in the filtering problem , these distributions are traditionally referred to as the _ filtering distributions_. in the particle filter , the filtering distribution is approximated by an empirical measure .",
    "this measure is implemented in the form of a weighted sum of dirac measures located at randomly ( empirically ) generated points called _",
    "particles_. particles are generated sequentially by the algorithm which is an instance of the _ sequential monte carlo methods _",
    "@xcite .",
    "the theoretical result that justifies the application of the particle filter is that the generated empirical measures converge to the theoretical filtering distribution as the number of particles goes to infinity @xcite . approximating",
    "the filtering distribution by an empirical measure is extremely useful for estimating moments of the distribution because they correspond to weighted sums of values of moment functions over generated particles .",
    "the filtering distribution has typically a density with respect to the corresponding lebesgue measure .",
    "this density is called the _ filtering density_. the knowledge of a suitable analytical approximation of the filtering density has several advantages .",
    "let us mention , for example , the possibility of computing densities of related conditional distributions and conditional expected values in an analytical form .",
    "the other benefit is that one can get a  deeper insight into the character of the filtering distribution through the analysis of its density approximation .    from these practical , and of course also theoretical , reasons the issue of the analytical approximation of the filtering densities",
    "is the subject of ongoing research .",
    "the problem has been addressed in @xcite , chapter 12 , @xcite and recently in @xcite .    in this paper",
    ", we deal with the estimation / approximation of filtering densities using the nonparametric kernel density estimation methodology .",
    "we use an approach based on fourier analysis inspired by the book of tsybakov @xcite .",
    "we will show that the convergence of kernel density estimates is assured even if the particles generated by the particle filter are not  i.i.d .",
    ", which is the common assumption in the application of kernel methods .",
    "the paper presents two main results .",
    "the first result is the convergence of the kernel density estimates to the theoretical filtering density at a fixed time of operation of the filter , provided that the number of generated particles goes to infinity .",
    "the result is based on the notion of the sobolev character of the filtering density .",
    "the second result gives a condition under which this sobolev character is retained over time .",
    "thus , the first result applies at any time of operation of the filter .",
    "both results are extended to partial derivatives of the estimates and filtering densities .",
    "the rest of the paper is organized as follows . in the next section",
    "we review the basics of the particle filter s theory together with the related convergence results .",
    "section  [ seciii ] deals with a review of nonparametric kernel density estimation methods with the focus on the fourier analysis approach . sections [ seciv ]  and  [ secv ] present the announced main results of the paper .",
    "section  [ secvi ] shows an application of the developed theory in an example related to the kalman filter .",
    "the paper is concluded by section  [ secvii ] .",
    "the basics of the particle filter and general filtering theory can be found in @xcite and @xcite .",
    "however , there is a plenty of other literature specialized in these subjects .",
    "nevertheless , we present here the essential framework of the related methodology in order that the paper be self - contained .",
    "the filtering problem is the task of determining the optimal estimate of an inaccessible value of the actual state of a stochastic process on the basis of knowledge of accessible observations .",
    "the observations establish a stochastic process called the _",
    "observation process_. the observation process is interconnected with a principal stochastic process which is called the _ signal process_. let us be more specific .",
    "let @xmath0 be a probabilistic space with two stochastic processes @xmath1 , @xmath2 specified on it . the first process @xmath1 , @xmath3 , @xmath4 , @xmath5 is the signal process .",
    "the signal process is considered to represent generally an inhomogeneous markov chain with a continuous state space .",
    "the probabilistic behavior of the chain is determined by the initial distribution @xmath6 of @xmath7 and by the set of transition kernels @xmath8 $ ] , @xmath9 .",
    "we denote by @xmath10 the measure represented by the transition kernel @xmath11 for @xmath12 being fixed .",
    "let @xmath2 , @xmath13 , @xmath9 , @xmath14 be the observation process specified on the basis of the signal process by formula @xmath15 where @xmath16 , @xmath9 are borel functions and @xmath17 are ( all)-other - variables independent random variables specified on @xmath0 .",
    "that is , @xmath18 , @xmath9 , @xmath14 and @xmath19 for all @xmath9 .",
    "the ( all)-other - variables independence of @xmath17 transfers on observations in the following way : @xmath20 indeed , we have @xmath21 due to ( [ ytdef ] ) .",
    "@xmath22 is independent of @xmath23 , therefore @xmath24 .",
    "the assertion is finally obtained by the markov property of the signal process .",
    "remark that for @xmath25 , the left - hand side of ( [ ytcondind ] ) reads as @xmath26 .",
    "as stated , the purpose of filtering is to present the optimal estimate of the actual state @xmath27 of the signal process using the actual and past observations @xmath28 .",
    "this is done at each time instant @xmath9 .",
    "it is the classical result that under the assumption of @xmath29 integrability of @xmath30 , the @xmath29-optimal estimate corresponds to the conditional expectation @xmath31 $ ] . in what follows",
    "we will assume that @xmath32 for each @xmath33 .    for fixed observations @xmath34 , the conditional expectation",
    "@xmath35 $ ] can be determined on the basis of the related conditional distribution @xmath36 .",
    "this distribution then represents the filtering distribution at time and will be approximated by an empirical measure generated by the particle filter .    in the standard setting of the filtering problem ,",
    "all the involved finite - dimensional distributions have bounded and continuous densities with respect to the corresponding lebesgue measures . especially , we assume that @xmath37 , @xmath38 and @xmath39 .",
    "this enables us to identify the respective filtering density , which is the density of @xmath36 .",
    "the conditional density of is determined by formula ( [ ytdef ] ) .",
    "the density is denoted @xmath40 and writes as @xmath41 the joint density of @xmath42 has then form @xmath43 these specifications are induced by the conditional independence of observations ( [ ytcondind ] ) and by the standard theory of markov chains with a continuous state space .",
    "the filtering density is @xmath44 for employing the joint distribution ( [ xtytjoint ] ) , we have @xmath45    the above integrals are generally inexpressible in a  closed form",
    ". however , certain recursive analytical relations can be stated .",
    "these relations are called the _ filtering equations _ and are addressed in the next section .",
    "the filtering equations describe recursively the evolution of the filtering density @xmath44 over time .",
    "they consists of the _ prediction formula _ ( [ l1 ] ) and the _ update formula _  ( [ l2 ] ) .",
    "let the joint density be given by formula ( [ xtytjoint ] ) , then @xmath46 for @xmath47 , and @xmath48 for @xmath49 .",
    "* we get the result from ( [ xtytjoint ] ) by series of integrations .",
    "let us start with @xmath49",
    ". in this case , formula  ( [ xtytjoint ] ) reads as @xmath50 . by integrating out @xmath51 we get @xmath52 and the result is obtained by integration with respect to @xmath53 .    in the general case of @xmath47",
    ", we get the following expressions by the transcription of ( [ xtytjoint ] ) and integrating out @xmath54 , @xmath55 subsequently , the integration w.r.t . @xmath56 and @xmath57 gives @xmath58 finally , dividing both sides of the last formula by the marginal density @xmath59 gives the result.@xmath60",
    "let the joint density be given by formula ( [ xtytjoint ] ) , then @xmath61 with @xmath62 understood as @xmath63 for @xmath49 .",
    "* we start with the bayes rule and rearrange @xmath64 we again use the bayes rule on @xmath65 , which gives @xmath66 considering the conditional independence of @xmath67 , which is expressed by @xmath68 , and cancelling out the @xmath69 terms we get the final formula @xmath70 in the denominator , the normalizing constant is obtained by integration @xmath71 as we have @xmath72 , this finishes the proof.@xmath60    the development of the filtering density over time is split into two sub - steps by the filtering equations .",
    "the prediction density @xmath73 is obtained in the first sub - step and , in the second one , it is updated to the filtering density @xmath44 on the basis of the actual observation @xmath54 .",
    "speaking in the language of distributions , the filtering distribution is usually denoted by @xmath74 , i.e. , @xmath75 .",
    "@xmath74  is also alternatively referred to as the _ update distribution ( measure)_. the prediction density then corresponds to the density of the so - called _ prediction distribution ( measure ) _ denoted by  @xmath76 , i.e. , @xmath77 .",
    "the time evolution of the filtering distribution can be seen as a recursive alternation between the prediction and update distributions @xmath76 and @xmath74 .",
    "this characterization fits to the particle filter operation because the filter alternately generates empirical prediction and update measures .    in the particle filter ,",
    "empirical measures are constructed as weighted sums of dirac measures localized at particles generated by the filter .",
    "the justification of this representation stems from the strong law of large numbers ( slln ) . assuming that @xmath78 , @xmath79 is an i.i.d .",
    "sample from a given distribution @xmath80 and constructing the empirical measure @xmath81  as @xmath82 the slln states that for any integrable function @xmath83 , the integral over this empirical measure converges a.s . to the integral over the distribution  @xmath80 .",
    "note that in ( [ pdxdef ] ) , the second expression points out the random character of @xmath81 , in fact , @xmath81 is a random measure .",
    "dealing with the filtering problem practically , we are not able to directly generate i.i.d",
    ". samples from @xmath74 because we do not have any closed - form representation of the filtering density at our disposal .",
    "however , due to the product character of the joint density @xmath84 , one can state an  algorithm which recursively generates samples ( particles ) that are used for constructing empirical counterparts of @xmath76 and @xmath74 distributions .",
    "the construction of empirical measures proceeds sequentially .",
    "the particles generated in the previous cycle of operation are employed in the actual cycle .",
    "a stochastic update of particles and their weights is taken in each cycle .",
    "the weights are updated on the basis of the actual observation .",
    "the procedure is in fact an instance of the sequential monte carlo methods applied in the context of the filtering problem @xcite and the algorithm follows the recursion described by the filtering equations .",
    "however , there is one extension .    in the raw mode of operation",
    ", the update measure is constructed as a non - uniformly weighted sum of dirac measures . as explained in @xcite , as @xmath9 increases",
    "the distribution of weights becomes more and more skewed and practically , after a few time steps , only one particle has a non - zero weight .",
    "to avoid this degeneracy , the _ resampling step _ is introduced .    during the resampling step",
    ", a non - uniformly weighted empirical measure is resampled into its uniformly weighted counterpart .",
    "the basic type of resampling is based on the idea of discarding particles with low weights ( with respect to @xmath85 ) and promote those with high weights .",
    "practically , it is done by sampling from the multinomial distribution @xmath86 over original particles with the probabilities of selection given by particles weights .",
    "this type of resampling corresponds to the sampling with replacement from the set of original particles with the probabilities of individual selections corresponding to the individual weights .",
    "let us stress here that the resampled particles _ does not constitute an i.i.d .",
    "_    we are now ready to present the operation of the particle filter in the algorithmic way :    * * 0 .",
    "declarations * + @xmath79 - the number of particles , + @xmath87 - the computational horizon , + @xmath88 - the initial density of @xmath7 , + @xmath89 - the transition densities . *",
    "initialization * + @xmath90 , + sample @xmath91 , + constitute @xmath92 , + set @xmath93 , i.e. , @xmath94 . *",
    "* 2 . sampling * + @xmath95 , + sample @xmath96 , + for @xmath97 compute @xmath98 + constitute @xmath99 . * * 3 .",
    "resampling * + using @xmath100 , resample @xmath101 from @xmath102 and constitute + @xmath103 . *",
    "if @xmath104 end , else go to step 2 .",
    "+    algorithm 1 .",
    "operation of the particle filter .",
    "[ tabsmcpf ]    the particle filter sequentially generates three empirical measures in each single cycle of its operation .",
    "these are the empirical prediction measure @xmath105 , the empirical update measure before resampling @xmath106 and the empirical update measure after resampling @xmath107 .",
    "the third measure then forms the empirical counterpart of the filtering distribution @xmath74 .",
    "a comparison of the evolution of the empirical measures with the evolution of the theoretical distributions can be done by means of the following schema :    @xmath108      the particle filter algorithm is known that the empirical measures @xmath105 and @xmath107 converge weakly a.s .",
    "( they are random measures ) to their theoretical counterparts as the number of generated particles goes to infinity .",
    "we will not go into details of the proof of the assertion , we only mention the result and its @xmath29 variant related to our research .    to present the convergence theorems , we denote the class of all real bounded and continuous functions over @xmath109 by @xmath110 , the supremum norm of a function @xmath111 by @xmath112 , i.e. , @xmath113 , and the integral of @xmath83 over the measure @xmath80 by @xmath114 .",
    "further , it is assumed that the transition kernels of the signal process possess the feller property .",
    "that is , @xmath115 for any @xmath116 and @xmath9 , where @xmath117 .",
    "the other assumption is that the densities @xmath118 of ( [ gtdef ] ) , are bounded , continuous and strictly positive functions .",
    "[ ascttheorem ] let @xmath119 and @xmath120 be the sequences of empirical measures generated by the particle filter for some fixed observation history @xmath121 , @xmath87 .",
    "then for all @xmath122 and , @xmath123    see @xcite , chapter 2 for a discussion of the convergence theorems .",
    "other source is @xcite , section iv .",
    "paper @xcite has a proof even for unbounded functions in proposition 1(b ) .",
    "in our research we employ the @xmath29 version of the theorem for @xmath124 .",
    "it reads as follows :    [ cttheorem ] let @xmath120 be the sequence of empirical measures generated by the particle filter for some fixed observation history @xmath121 , @xmath87 .",
    "then for all @xmath125 and , @xmath126\\leq \\frac{c^2_t||f||^2_{\\infty}}{n}\\ ] ] with @xmath127 being a constant for fixed @xmath125 .    in this formulation ,",
    "the theorem is presented in  @xcite , section  v ( authors use @xmath128 instead ours @xmath129 ) .",
    "remark that the @xmath130 version , i.e. , @xmath131 $ ] , is treated in  @xcite , theorem 2.4.1 .",
    "the theorem is mentioned for general @xmath132 norm , @xmath133 in @xcite , proposition 1(a ) .",
    "the theorem holds also for the class @xmath134 of bounded and continuous complex functions of real variables over @xmath109 .",
    "that is , it holds also for functions @xmath135 , @xmath136 , @xmath137 , where @xmath138 denotes the imaginary unit . clearly , the extension on complex functions is due to the triangle inequality for the absolute value ( the modulus ) of a complex number .",
    "kernel methods are widely used for nonparametric estimation of densities of probability distributions with the vast literature available on the topic . here",
    "we review the very basics of the related methodology .",
    "we focus in more details on the application of fourier analysis in this field .",
    "our review is mainly based on the standard works of @xcite and @xcite , and the recent book by tsybakov @xcite .",
    "let @xmath139 , @xmath79 be a set of independent random variables identically distributed as the real random variable  @xmath140 .",
    "let the distribution of @xmath141 have the density with respect to the @xmath142-dimensional lebesgue measure .",
    "a nonparametric kernel density estimate of @xmath83 is constructed on the basis of an i.i.d .",
    "sample from the distribution of @xmath141 .",
    "the estimate is constructed as a generalization of the classical histogram by replacing the indicator function , which specifies individual bins of the histogram , by a more general function which is commonly referred to as the _ kernel function _ or simply as the  _",
    "kernel_.    the definition formula of the standard @xmath142-variate nonparametric kernel density estimate writes as @xmath143 in the formula , the second expression points out the random character of the estimate .",
    "that is , for each @xmath144 , the estimate @xmath145 constitutes a random variable whose distribution is determined by the distribution of @xmath141 and by the value of the parameter @xmath146 which is called the  _",
    "bandwidth_.    due to the random character of @xmath145 , there is the relevant question of the consistency and unbiasedness of the estimate . in the univariate case , the classical result of parzen @xcite ( see also @xcite , p.  71 ) states the conditions under which the estimate is consistent .",
    "the result extends on the multivariate case , see e.g. @xcite .",
    "the conditions are imposed on the properties of the kernel function and on the evolution of the bandwidth @xmath147 in dependence on the sample size @xmath79 .",
    "we mention only that @xmath147 is required to evolve in such a way that 1 )  @xmath148 and 2 ) @xmath149 .",
    "the investigation on the bias of @xmath145 is closely related to the investigation on the quality of the estimate in terms of the _ mean squared error _ - @xmath150 .",
    "for a fixed point @xmath144 , the error is specified as @xmath151 $ ] . employing properties of mean and variance",
    ", it writes as @xmath152-f({\\boldsymbol{x}}))^2+var[\\hat{f}_n({\\boldsymbol{x } } ) ] = ( b[\\hat{f}_n]({\\boldsymbol{x}}))^2+\\sigma^2[\\hat{f}_n]({\\boldsymbol{x}}),\\ ] ] where the term @xmath153({\\boldsymbol{x}})={\\mathbb{e}}[\\hat{f}_n({\\boldsymbol{x}})]-f({\\boldsymbol{x}})$ ] is the _ bias _ and @xmath154({\\boldsymbol{x}})=var[\\hat{f}_n({\\boldsymbol{x}})]$ ] the _ variance _ of the kernel density estimate @xmath145 at the point @xmath144 .",
    "the @xmath150 is the local measure of the quality of the estimate .",
    "it is desirable to have also a corresponding global measure .",
    "expectedly , such the measure deals with local errors accumulated over the whole domain of the estimated density .",
    "mathematically , the accumulation is performed by integration .",
    "this leads to the notion of the _ mean integrated squared error _ ( mise ) of a kernel density estimate .",
    "the mise of the kernel density estimate @xmath155 is defined and expressed on the basis of ( [ msedef ] ) using the fubini s theorem as @xmath156\\,d{\\boldsymbol{x } } = \\int { \\mathrm{mse}}_{{\\boldsymbol{x}}}(\\hat{f}_n)\\,{\\boldsymbol{x}}\\nonumber\\\\ & \\!\\!=\\!\\!&\\int({\\mathbb{e}}[\\hat{f}_n({\\boldsymbol{x}})]-f({\\boldsymbol{x}}))^2\\,d{\\boldsymbol{x}}+ \\int var [ \\hat{f}_n({\\boldsymbol{x}})]\\,d{\\boldsymbol{x}}\\nonumber\\\\ & \\!\\!=\\!\\!&\\int(b[\\hat{f}_n]({\\boldsymbol{x}}))^2\\,d{\\boldsymbol{x}}+ \\int \\sigma^2[\\hat{f}_n]({\\boldsymbol{x}})\\,d{\\boldsymbol{x}}.\\nonumber \\label{misehexact}\\end{aligned}\\ ] ] the formula consists of two summands which are the integrated versions of the squared bias and variance terms of the @xmath150 .",
    "the value of the mise(@xmath155 ) depends on the value of the bandwidth @xmath147 .",
    "it is a standard observation that the bias and variance terms behave in the opposite way with respect to the magnitude of the bandwidth .",
    "that is , for @xmath79 fixed , if @xmath147 decreases , i.e. , if @xmath157 , then the bias goes to zero , and we have the asymptotic unbiasedness of the @xmath145 estimate .",
    "however , the variance increases .",
    "if @xmath147 increases , i.e. , if @xmath158 , the bias increases too , but the variance term diminishes .",
    "thus , we encounter here the situation of the _ bias - variance trade - off _ when minimizing the @xmath159 by adjusting the bandwidth @xmath147 .",
    "the specification of the optimal value @xmath160 minimizing ( [ 1dmise ] ) can be made analytically only if ( [ 1dmise ] ) has a closed - form expression .",
    "this is known only in some specific cases , for example , when the estimated density @xmath83 is a convex sum of normal densities , see @xcite , p.  37 or",
    "@xcite , p.  102",
    "for the related explicit formulas for @xmath159 . to deal with the minimization problem generally , the widely used approach is to investigate the asymptotic behavior of the mise with respect to the sample size @xmath79 going to infinity ( amise analysis ) .",
    "the result based on the taylor s expansion of the estimated density @xmath83 states ( @xcite , p. 85 , @xcite , p.  99 ) that @xmath161 for @xmath162 , @xmath163 , @xmath164 . using standard calculus ,",
    "the minimizer of the above formula reads as @xmath165^{1/(d+4 ) } \\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!.\\ ] ]    in ( [ amise ] ) , the terms @xmath166 and @xmath167 can be further minimized over a set of appropriate kernels .",
    "the minimizer is known as the _ epanechnikov kernel _ which is specified as @xmath168 where @xmath169 is the volume of the @xmath142-dimensional unit sphere , @xmath170 is the euclidean norm and @xmath171 is the positive part",
    ".    amise analysis represents the standard approach to the analytic specification of a suitable value of the bandwidth when constructing a kernel density estimate , even though the specification of @xmath172 requires the knowledge of partial derivatives of the density @xmath83 under estimation .",
    "typically , to overcome the deadlock , the respective entities are somehow estimated from data @xcite .",
    "however , in section 1.2.4 of his book @xcite , tsybakov provides a deeper criticism of the asymptotic approach .",
    "it stems from the fact that the optimality of @xmath172 is related to a  _ fixed density  @xmath83 _ and not to a well defined class of densities . in proposition 1.7",
    ", tsybakov shows that for a given fixed density @xmath83 it is possible to construct such a non - negative kernel estimate that the mise(@xmath155 ) diminishes , but this can not be done uniformly over a sufficiently broad class of densities .",
    "examples of such classes , e.g. hlder , sobolev or nikolski classes , are presented in @xcite .",
    "the sobolev class is treated in definition  [ defsob ] below .",
    "based on this criticism , tsybakov presents a different approach to the mise analysis in section  1.3 of @xcite .",
    "the approach relies on fourier analysis .      in this section",
    ", we deal with the application of fourier analysis in the area of nonparametric kernel density estimation .",
    "we mainly follow the presentation of tsybakov given in chapter  1 of @xcite . in @xcite , results are provided for the univariate case . in order to the results could be applied in our research presented in section  [ seciv ] , we have extended them into multiple dimensions .    in the probability theory , fourier analysis is intimately interconnected with the notion of the characteristic function .",
    "let @xmath140 be a @xmath142-variate real random vector with the joint distribution @xmath173 .",
    "the characteristic function @xmath174 of @xmath141 is defined as the integral transform @xmath175= \\int e^{\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{x}}{\\rangle}}\\ , \\mu(d{\\boldsymbol{x}}),\\;\\;{\\boldsymbol{\\omega}}\\in{\\mathbb{r}}^d,\\ ] ] where @xmath176 denotes the dot product .",
    "it is well known that the transform provides the complete characterization of the distribution of @xmath141 ; and we often speak about the fourier transform of the random vector @xmath141 .",
    "the other quite common view of the fourier transform comes from the area of applied mathematics .",
    "let @xmath177 be an integrable function ( a signal in electrical engineering ) , i.e. , let @xmath178 , then its fourier transform is specified as @xmath179({\\boldsymbol{\\omega}})=\\int e^{\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{x}}{\\rangle } } f({\\boldsymbol{x}})\\,d{\\boldsymbol{x } } , \\;\\;{\\boldsymbol{\\omega}}\\in{\\mathbb{r}}^d.\\ ] ] formula ( [ ftransform ] ) can be treated as the special case of formula ( [ charfce ] ) when the distribution of @xmath141 is absolutely continuous with respect to the @xmath142-dimensional lebesgue measure and has the density  @xmath83 , i.e. , @xmath180 . on the other hand , in ( [ ftransform ] ) , @xmath83 need not be necessarily a density , only the integrability is assumed .",
    "let @xmath181 , i.e. , we consider functions both @xmath130 and @xmath29 integrable over @xmath182 , then the following properties of the multivariate fourier transform are relevant to our research :    * continuity : @xmath183 $ ] is uniformly continuous on @xmath182 , * linearity : @xmath184({\\boldsymbol{\\omega}})=a{\\mathcal{f}}[f]({\\boldsymbol{\\omega}})+b{\\mathcal{f}}[g]({\\boldsymbol{\\omega}}),\\;\\;\\;a , b\\in{\\mathbb{r}}$ ] , * shifting : @xmath185({\\boldsymbol{\\omega}})= e^{\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{s}}{\\rangle}}{\\mathcal{f}}[f]({\\boldsymbol{\\omega}}),\\;\\;{\\boldsymbol{s}}\\in{\\mathbb{r}}^d$ ] , * scaling : @xmath186({\\boldsymbol{\\omega}})={\\mathcal{f}}[f](h{\\boldsymbol{\\omega}}),\\;\\;h>0 $ ] , * shifting & scaling : @xmath187= e^{\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{s}}{\\rangle}}{\\mathcal{f}}[f](h{\\boldsymbol{\\omega}}),\\;\\;{\\boldsymbol{s}}\\in{\\mathbb{r}}^d$ ] , * complex conjugate : @xmath188({\\boldsymbol{\\omega}})}}={\\mathcal{f}}[f](-{\\boldsymbol{\\omega}})$ ] , * convolution : @xmath189({\\boldsymbol{\\omega}})={\\mathcal{f}}[f]({\\boldsymbol{\\omega}}){\\mathcal{f}}[g]({\\boldsymbol{\\omega}})$ ] , * derivative : @xmath190({\\boldsymbol{\\omega}})\\!=\\ ! ( \\mathrm{-i})^m ( \\omega^{i_1}_1\\cdot\\dots\\cdot\\omega^{i_d}_d){\\mathcal{f}}[f]({\\boldsymbol{\\omega}})$ ] , * symmetry : if @xmath191 , then @xmath183(-{\\boldsymbol{\\omega}})\\!=\\!{\\mathcal{f}}[f]({\\boldsymbol{\\omega}})$ ] , * isometry , due to the plancheler s formula for @xmath192 : @xmath193({\\boldsymbol{\\omega}})|^2\\,d{\\boldsymbol{\\omega}}.\\ ] ]    now , the uniformly weighted sum of dirac measures @xmath81 introduced in formula ( [ pdxdef ] ) represents the probability distribution which does not have any density with respect to the corresponding lebesgue measure .",
    "its characteristic function @xmath194 is specified as @xmath195 note that @xmath194 constitutes a random variable for @xmath196 being fixed .    under the assumption of @xmath197 integrability of the employed kernel @xmath198",
    ", we can consider the fourier transform of the multivariate density kernel estimate  ( [ fnddim ] ) .",
    "using the linearity and the shifting  &  scaling property of the fourier transform , @xmath199({\\boldsymbol{\\omega}})$ ] is specified by formula @xmath200({\\boldsymbol{\\omega}})= \\frac{1}{n}\\sum_{j=1}^n { \\mathcal{f}}\\left[\\frac{1}{h^d}k\\!\\!\\left(\\frac{{\\boldsymbol{x}}-{\\boldsymbol{x}}_j}{h}\\right)\\right ] = \\frac{1}{n}\\sum_{j=1}^n   e^{\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{x}}_j{\\rangle}}{\\mathcal{f}}[k](h{\\boldsymbol{\\omega}}).\\ ] ]    writing @xmath201 for @xmath202({\\boldsymbol{\\omega}})$ ] we obtain the compact expression of @xmath155 in the form @xmath203({\\boldsymbol{\\omega}})=\\phi_n({\\boldsymbol{\\omega}})k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}}).\\ ] ] this shows that the standard kernel estimator which is based on an i.i.d .",
    "sample is obtained by the convolution of the employed kernel with the uniformly weighted sum of dirac measures corresponding to the sample .    to proceed with the investigation of the mise of density kernel estimates in the frequency domain",
    ", we present a multivariate version of lemma 1.2 from  @xcite .",
    "[ lmtheorem ] let @xmath204 be an i.i.d .",
    "sample from a distribution with the density  @xmath83 .",
    "let the characteristic function of @xmath205 be @xmath206 .",
    "then for @xmath207 of @xmath208 we have    ll & [ _ n()]= ( ) , + & [ |_n()|^2]=(1-)|()|^2 + , + & [ |_n()-()|^2]= ( 1-|()|^2 ) .",
    "& &    * proof . * to show ( i ) , consider the i.i.d .",
    "character of @xmath204 , @xmath209=\\frac{1}{n}\\sum_{j=1}^n \\int e^{\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{x}}{\\rangle}}f({\\boldsymbol{x}})\\,d{\\boldsymbol{x } } = \\frac{1}{n}\\sum_{j=1}^n\\phi({\\boldsymbol{\\omega } } ) = \\phi({\\boldsymbol{\\omega}}).\\ ] ] to show ( ii ) , note that @xmath210&= & { \\mathbb{e}}[\\phi_n({\\boldsymbol{\\omega}}){\\overline{\\phi_n({\\boldsymbol{\\omega}})}}]= { \\mathbb{e}}[\\phi_n({\\boldsymbol{\\omega}})\\phi_n(-{\\boldsymbol{\\omega}})]\\nonumber\\\\ & = & { \\mathbb{e}}\\left[\\frac{1}{n^2}\\sum_{j , k : j\\not= k } e^{\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{x}}_j{\\rangle}}e^{-\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{x}}_k{\\rangle}}\\right ] + \\frac{n}{n^2}\\nonumber\\\\ & = & \\frac{1}{n^2}\\sum_{j , k : j\\not= k } { \\mathbb{e}}\\left[e^{\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{x}}_j{\\rangle}}\\right ] { \\mathbb{e}}\\left[e^{-\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{x}}_k{\\rangle}}\\right ] + \\frac{1}{n}\\nonumber\\\\ & = & \\frac{n^2-n}{n^2}\\phi({\\boldsymbol{\\omega}})\\phi(-{\\boldsymbol{\\omega}})+\\frac{1}{n}\\nonumber\\\\ & = & \\left(1-\\frac{1}{n}\\right)|\\phi({\\boldsymbol{\\omega}})|^2+\\frac{1}{n}.\\end{aligned}\\ ] ] case ( iii ) folows from ( ii ) a ( i ) . indeed , @xmath211=$ ]",
    "@xmath212\\nonumber\\\\ & = & { \\mathbb{e } } [ ( \\phi_n({\\boldsymbol{\\omega}})-\\phi({\\boldsymbol{\\omega}}))(\\phi_n(-{\\boldsymbol{\\omega}})-\\phi(-{\\boldsymbol{\\omega}}))]\\nonumber\\\\ & = & { \\mathbb{e } } [    -\\phi({\\boldsymbol{\\omega}})\\phi_n(-{\\boldsymbol{\\omega}})+|\\phi({\\boldsymbol{\\omega}})|^2]\\nonumber\\\\ & = & { \\mathbb{e } } [    -\\phi({\\boldsymbol{\\omega}})\\phi(-{\\boldsymbol{\\omega}})+|\\phi({\\boldsymbol{\\omega}})|^2\\nonumber\\\\ & = & { \\mathbb{e } } [    & = & \\left(1-\\frac{1}{n}\\right)|\\phi({\\boldsymbol{\\omega}})|^2+\\frac{1}{n}-|\\phi({\\boldsymbol{\\omega}})|^2\\nonumber\\\\ & = & \\frac{1}{n}(1-|\\phi({\\boldsymbol{\\omega}})|^2)\\nonumber.\\end{aligned}\\ ] ] this concludes the proof.@xmath60 + let us assume that both density @xmath83 and kernel @xmath198 belong also to @xmath213 .",
    "then employing the plancherel s theorem and  ( [ fconv ] ) , we get for the mise of ( [ 1dmise ] ) the expression @xmath214    the next theorem provides the exact computation of the mise(@xmath155 ) for any fixed @xmath79 .",
    "_ let @xmath192 be a density and @xmath215 a kernel .",
    "then for all @xmath216 and @xmath146 the mise of the i.i.d .",
    "based kernel estimator @xmath155 of @xmath217 has the form _",
    "@xmath218 \\nonumber\\\\ & & -\\frac{1}{(2\\pi)^d}\\frac{1}{n } \\int |\\phi({\\boldsymbol{\\omega}})|^2 |k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}})|^2\\,d{\\boldsymbol{\\omega}}.\\end{aligned}\\ ] ]    * proof .",
    "* as @xmath219 and @xmath220 for all @xmath196 , all the integrals are finite . to obtain the fourier mise formula it suffices to develop ( [ llp ] ) , @xmath221|k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}})|^2 +    & & \\hspace{0.4cm}+\\;({\\mathbb{e}}[(\\phi_n({\\boldsymbol{\\omega}})]-\\phi({\\boldsymbol{\\omega}}))k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega } } ) \\,{\\overline{(1-k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}}))\\phi({\\boldsymbol{\\omega}}))}}\\\\[0.2 cm ] & & \\hspace{0.4cm}+\\;(1-k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}}))\\phi({\\boldsymbol{\\omega}}))\\ , ( { \\mathbb{e}}[{\\overline{\\phi_n({\\boldsymbol{\\omega}})}}]-{\\overline{\\phi({\\boldsymbol{\\omega}}}})){\\overline{k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega } } ) } } \\,d{\\boldsymbol{\\omega}}\\\\[0.2 cm ] & = & \\int{\\mathbb{e}}[|\\phi_n({\\boldsymbol{\\omega}})-\\phi({\\boldsymbol{\\omega}})|^2]|k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}})|^2 +    & = & \\frac{1}{n}\\int(1-|\\phi({\\boldsymbol{\\omega}})|^2)|k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}})|^2\\,d{\\boldsymbol{\\omega } } + \\int |1-k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}})|^2|\\phi({\\boldsymbol{\\omega}})|^2\\,d{\\boldsymbol{\\omega}}\\end{aligned}\\ ] ] after rearranging we",
    "obtain the assertion of the theorem.@xmath60    we are now going to discuss the individual terms in the fourier mise formula ( [ misefourier ] ) .",
    "we start with the notion of the _ order of a kernel_.    [ defell ] let @xmath222 be an integer .",
    "we say that the kernel @xmath223 is of order @xmath224 , if @xmath198 is @xmath225 integrable , its fourier transform @xmath226 is real , satisfies and has all partial derivatives @xmath227 , @xmath228 , @xmath229 up to the @xmath224-th order and it holds that @xmath230 for all @xmath231 .",
    "remark that the above definition imposes the following conditions on a multivariate kernel to be of order @xmath222 , @xmath232 :    * @xmath233 , * @xmath234 for @xmath231 .",
    "indeed , at the origin we have @xmath235 . for the partial derivative ,",
    "we get @xmath236 hence @xmath237 .    from the remark",
    ", it follows that kernels of order @xmath238 must take negative values .",
    "if such kernels are allowed in kernel estimates , then @xmath155 of ( [ fnddim ] ) may also take negative values .",
    "however , this is not a serious drawback because we can always take as the final estimate the positive part of @xmath155 , i.e. , @xmath239 . at each point @xmath144 ,",
    "the @xmath240 of @xmath241 is always smaller than that of negative @xmath145 .",
    "therefore we have also @xmath242 .",
    "+      for the first term in the fourier mise formula ( [ misefourier ] ) , we are able to say something more specific if we consider the order of the kernel involved in the estimate .",
    "[ bdtheorem ] let @xmath223 be a kernel of order @xmath222 , @xmath232 .",
    "then there exists a constant @xmath243 such that @xmath244 and @xmath245 for any function @xmath83 with the fourier transform @xmath206 and @xmath146 .    * proof .",
    "* we employ the multidimensional taylor s theorem . because the kernel @xmath198 is of order @xmath222",
    ", its fourier transform @xmath226 is real and by the taylor s theorem @xmath246 with @xmath247 for the reminder , where @xmath170 is the euclidean norm .    because the involved partial derivatives equal to zero , the remainder writes @xmath248 and @xmath249 by the taylor s theorem .",
    "let us define @xmath250 for @xmath251 , and @xmath252 .",
    "the function is continuous on @xmath182 and attains its maximum on the unit ball .",
    "we denote this maximum by @xmath253 , @xmath254 . because @xmath255 , we have @xmath256 .",
    "indeed , @xmath257 for @xmath258 . composing both cases one",
    "gets @xmath259 for @xmath196 .",
    "the inequality ( [ 1stterm ] ) is implied by ( [ acondition ] ) as follows : @xmath260 this concludes the proof.@xmath60 + the other terms in formula ( [ misefourier ] ) refer to individual properties of the kernel and density under considerations .",
    "we mention only two straightforward observations .",
    "+      the second term can be directly translated from the frequency to the  time \" domain by the plancherel s theorem and the scaling property of the fourier transform : @xmath261      the third term is actually the correction term . for this term",
    "we have the following inequality : @xmath262 where @xmath263 .",
    "concerning an upper bound on the fourier mise formula ( [ misefourier ] ) , we actually sum up the results obtained in the preceding sections .",
    "first of all , to obtain the upper bound we can omit the correction ( the third ) term in ( [ misefourier ] ) .",
    "the second term is solely determined by the properties of the kernel , which is expressed by formula ( [ 2ndmiseterm ] ) . finally , to obtain a bound on the first term , the properties of the density",
    "the data are sampled from and the properties of the kernel have to be matched somehow .",
    "to do this we introduce the so - called sobolev class of densities .",
    "[ defsob ] let @xmath264 be an integer and @xmath265 .",
    "the sobolev class of densities @xmath266 consists of all probability density functions @xmath177 satisfying @xmath267 where @xmath268({\\boldsymbol{\\omega}})$ ] and @xmath170 is the euclidean norm .",
    "the condition ( [ sobolevprop ] ) is related to the boundedness of partial derivatives of densities in the sobolev class ; e.g. , it can be shown that if @xmath269 for all @xmath270 , then ( [ sobolevprop ] ) holds for @xmath271 and @xmath272 .",
    "furthermore , if @xmath273 , for some @xmath274 and @xmath265 , then @xmath192 .",
    "now , the announced matching is provided by the fitting the order of the kernel to the sobolev character of the estimated density .",
    "the next theorem , which is the variant of theorem  1.5 in @xcite , provides the final result .",
    "let @xmath79 be the number of i.i.d .",
    "samples from a  distribution with the density @xmath275 which is @xmath276-sobolev for some @xmath274 and @xmath265 , i.e. , @xmath273 . let @xmath198 be a kernel of order @xmath276 .",
    "assume that inequality @xmath277 holds for some constant @xmath243 .",
    "fix @xmath278 and set @xmath279 .",
    "then for any @xmath216 the kernel density estimate @xmath155 satisfies @xmath280 where @xmath281 is a constant depending only on @xmath282 and on the kernel @xmath198 .    * proof .",
    "* by theorem  [ bdtheorem ] and from the definition of the sobolev class of densities , we have @xmath283 plugging this into the fourier mise formula ( [ misefourier ] ) and employing @xmath284 we get for @xmath279 the following : @xmath285 and @xmath286\\\\ & \\leq&\\!\\!\\ !",
    "+ \\frac{1}{nh^d}\\int k^2({\\boldsymbol{u}})\\,d{\\boldsymbol{u}},\\\\ & \\leq&\\!\\!\\ ! ( al)^2\\alpha^{2\\beta } n^{-\\frac{2\\beta}{2\\beta+d } } + \\alpha^{-d}n^{-\\frac{2\\beta}{2\\beta+d}}\\!\\!\\int\\!\\ !",
    "k^2({\\boldsymbol{u}})\\,d{\\boldsymbol{u}},\\\\ & \\leq&\\!\\!\\ ! \\left[(al)^2\\alpha^{2\\beta}+\\alpha^{-d}\\int k^2({\\boldsymbol{u}})\\,d{\\boldsymbol{u}}\\right ] \\cdot n^{-\\frac{2\\beta}{2\\beta+d}},\\\\ & \\leq&\\!\\!\\ !",
    "c(\\alpha,\\beta , d , a , l , k)\\cdot n^{-\\frac{2\\beta}{2\\beta+d}}.\\end{aligned}\\ ] ] this concludes the proof.@xmath60 + the theorem provides the upper bound on the mise of the multivariate kernel density estimate ( [ fnddim ] ) , if the order of the employed kernel fits to the sobolev character of the density the employed data are sampled from .",
    "this section presents our own research in the area of the combination of the particle filter and kernel methods .",
    "the main question here is if the kernel density estimates constructed on the basis of empirical measures approximate the related filtering densities reasonably well .",
    "the main obstacle to a direct application of the presented kernel estimation methodology is the fact that the generated empirical measures are not based on i.i.d",
    ". samples due to the resampling step of the filter .",
    "our results are twofold .",
    "first , we show that , despite the mentioned obstacle , the standard kernel density estimates still converge to the related filtering densities .",
    "the proof of the assertion is based on fourier analysis of the convergence result for the particle filter .",
    "the second result concerns a deeper analysis of the obtained convergence formula .",
    "the convergence result is based on the assumption on the sobolev character of the filtering densities .",
    "we present a sufficient condition for the persistency of this sobolev character over time .",
    "we extend both results to the partial derivatives of the kernel density estimates and to the partial derivatives of the filtering densities , respectively .      to start ,",
    "let us remind that the particle filter generates at each time step , @xmath87 the empirical measure @xmath287 .",
    "this measure approximates the related filtering distribution @xmath74 that is assumed to have the density @xmath288 with respect to the @xmath142-dimensional lebesgue measure , i.e. , @xmath289 .",
    "a carrier of the empirical measure @xmath107 is the set of particles @xmath290 , .",
    "this set does not constitute an i.i.d .",
    "sample from @xmath74 .",
    "if one constructs the standard kernel density estimate on the basis of @xmath290 and the selected kernel  @xmath198 , i.e. , the estimate @xmath291 then we ask if @xmath292 converges in the mise to the filtering density @xmath293 , provided that the number of particles goes to infinity .",
    "[ mainth ] in the filtering problem , let @xmath294 , @xmath295 , @xmath87 be the sequences of filtering distributions and corresponding filtering densities .",
    "let @xmath293 , @xmath296 be for some @xmath274 and @xmath297 , i.e. , @xmath298 .",
    "let @xmath299 , @xmath300 , @xmath79 be the sequences of the empirical measures generated by the particle filter and related kernel density estimates ( [ ptn ] ) with the bandwidth varying as @xmath301 for some @xmath278 .",
    "let the kernel  @xmath198 employed in the estimates be of order  @xmath276 .",
    "then we have the following evolution of the mise of @xmath302 over time @xmath303 @xmath304 \\leq c^2_t\\cdot n^{-\\frac{2\\beta}{2\\beta+d}},\\ ] ] where @xmath305 + in ( [ mtheq2 ] ) , @xmath306 is the constant of theorem  [ bdtheorem ] , @xmath128 , @xmath125 are the constants of theorem  [ cttheorem ] and @xmath307 is the @xmath29 norm of the kernel  @xmath198 .    *",
    "the proof is based on the employment of the fourier transform .",
    "we start by the assertion of theorem  [ cttheorem ] : @xmath308\\leq\\frac{c^2_t||f||^2_{\\infty}}{n},\\\\\\ ] ] where we replace a general function @xmath309 by the complex exponential specified on  @xmath182 .",
    "note that @xmath310 .",
    "let @xmath311 , then @xmath312 .",
    "denoting @xmath313 $ ] and @xmath314 $ ] we have from the above @xmath315 & \\leq & \\frac{c^2_t}{n},\\nonumber\\\\    & \\leq &    { \\mathbb{e}}\\;[|\\psi_t^n({\\boldsymbol{\\omega}})k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega } } ) -\\psi_t({\\boldsymbol{\\omega}})k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}})|^2 ] & \\leq &    { \\mathbb{e}}\\left[\\int |\\psi_t^n({\\boldsymbol{\\omega}})k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega } } ) -\\psi_t({\\boldsymbol{\\omega}})k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}})|^2\\,d{\\boldsymbol{{\\boldsymbol{\\omega}}}}\\right ] & \\leq & \\frac{c^2_t}{n}\\!\\!\\int |k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}})|^2\\,d{\\boldsymbol{\\omega}},\\nonumber\\\\ { \\mathbb{e}}\\left[\\int ( \\hat{p}_t^{n}({\\boldsymbol{x}}_t)-p^*_t({\\boldsymbol{x}}_t))^2\\,d{\\boldsymbol{x}}_t\\right ] & \\leq & \\frac{c^2_t}{nh^{d}}\\!\\!\\int\\!\\!k^2({\\boldsymbol{u}})\\,d{\\boldsymbol{u}}. \\label{e1fce}\\end{aligned}\\ ] ] for any density @xmath293 and its convolution , @xmath316 we assume that the employed kernel has order @xmath276 and @xmath317",
    ". therefore the right - hand side of ( [ e2fce ] ) is bounded according to theorem  [ bdtheorem ] .",
    "further , there is nothing random here and we can apply the expectation with no effect to obtain @xmath318",
    "\\leq a^2 h^{2\\beta}l_t^2.\\ ] ]    to proceed , let us consider the product measure @xmath319 with the corresponding norm @xmath320^{1/2}$ ] .",
    "we have @xmath321 by ( [ e1fce ] ) , ( [ e3fce ] ) and the triangle inequality for @xmath322 .",
    "let the bandwidth @xmath147 develop with @xmath323 as @xmath301 for some @xmath278 .",
    "we  have @xmath324 .",
    "further , @xmath325 and therefore @xmath326 inequality ( [ etriangle ] ) then reads as @xmath327 squaring to obtain the mise we get @xmath328 or in the more compact form @xmath329 for @xmath330 .",
    "@xmath60 + let us discuss the theorem .",
    "+ 1 ) first of all , the theorem is proved without any assumption on the i.i.d .",
    "character of samples ( particles ) constituting the empirical measures @xmath331 .",
    "this is the crucial observation , as we know that due to the resampling step the generated particles are not i.i.d .",
    "\\2 ) convergence . for @xmath9 fixed , we immediately see from ( [ mtheq1 ] ) that the  mise of kernel estimates goes to zero as the number of particles increases and the bandwidth decreases accordingly , i.e. , @xmath332 .",
    "\\3 ) consistency .",
    "the theorem proposes that the bandwidth develops with the number of particles @xmath323 as @xmath301 for some @xmath333 .",
    "obviously , @xmath148 , and @xmath334 .",
    "\\4 ) the dimension matters .",
    "we have @xmath335 for @xmath336 , and therefore we must increase the number of particles in order to assure a given accuracy as the dimension increases .",
    "\\5 ) the order helps .",
    "contrary to the previous result , we have @xmath337 for @xmath338 . hence the greater is the order of the employed kernel , the tighter is the bound on the related mise , in fact , it tends towards @xmath339 .",
    "there are techniques available for constructing kernels of arbitrary orders @xcite , however , the order of the employed kernel is primarily driven by the sobolev character of the filtering densities .",
    "\\6 ) the theorem assumes that the filtering densities @xmath293 are @xmath276-sobolev for some  @xmath297 , @xmath340 , @xmath87 and @xmath274 being constant over time .",
    "it is the question when this assumption holds . in section  [ secv ] , we show that the sobolev character of the filtering densities is retained over time , if a certain condition holds on the transition kernels of the signal process .",
    "\\7 ) for @xmath341 , the specification of @xmath342 simplifies to @xmath343 and @xmath342 consists of four terms .",
    "two of them , @xmath306 and @xmath344^{1/2}$ ] are the constants determined by the employed kernel . the other two , @xmath345 and @xmath128 ,",
    "develop with time .",
    "the @xmath345 term is discussed in section  [ secv ] .",
    "\\8 ) the @xmath128 constant ( with respect to the number of particles ) comes from theorem  [ cttheorem ] .",
    "it can be shown that its values can be computed recursively as @xmath346 .",
    "the integral @xmath347 depends on the values of the observation process and @xmath128 generally develops exponentially with time , see the remark in concluding section  [ secvii ] .",
    "the result of theorem  [ mainth ] can be straightforwardly extended to the convergence of partial derivatives of kernel density estimates to partial derivatives of the filtering densities .",
    "the proof of the assertion substantially overlaps with the proof of theorem  [ mainth ] , however , we present it here in full detail for the convenience of the reader .    in what follows",
    "we denote by @xmath348 the @xmath349-th partial derivative of the filtering density @xmath293 , @xmath340 , @xmath87 for , such that @xmath228 , and @xmath350 .",
    "similarly , we will use @xmath351 for the partial derivative of kernel estimate ( [ ptn ] ) , @xmath352 for the partial derivative of the convolution @xmath353 and @xmath354 for the partial derivative of the kernel employed in the estimates .",
    "clearly , the zero value of @xmath355 , @xmath356 , corresponds to the situation when no differentiation is applied in the respective dimension .",
    "[ pdmainth ] in the filtering problem , let @xmath294 , @xmath357 , @xmath87 , be the sequences of filtering distributions and @xmath349-th partial derivatives of corresponding filtering densities for some @xmath358 , @xmath228 .",
    "let @xmath359 , @xmath340 satisfy ( [ sobolevprop ] ) for some @xmath274 and @xmath360 .",
    "let @xmath299 , @xmath361 , @xmath79 be the sequences of the empirical measures generated by the particle filter and @xmath349-th partial derivatives of the related kernel density estimates ( [ ptn ] ) with the bandwidth varying as @xmath362 for some @xmath278 .",
    "let the kernel  @xmath198 employed in the estimates be of order  @xmath276 .",
    "then we have the following evolution of the mise of the @xmath349-th partial derivatives of kernel estimates @xmath363 over time @xmath303 @xmath364 \\leq c^2_{t,(m)}\\cdot n^{-\\frac{2\\beta}{2\\beta+d+2m}},\\ ] ] where @xmath365 + in ( [ pdmtheq2 ] ) , @xmath306 is the constant of theorem  [ bdtheorem ] , @xmath128 , @xmath125 are the constants of theorem  [ cttheorem ] and @xmath366 is the @xmath29 norm of the corresponding @xmath349-th partial derivative of kernel  @xmath198 .    *",
    "* to start remind that for any function @xmath177 and its @xmath349-th partial derivative @xmath367 , both assumed in @xmath197 , one has for their fourier transforms @xmath368({\\boldsymbol{\\omega}})$ ] and @xmath369({\\boldsymbol{\\omega}})$ ] , respectively , the equality @xmath370({\\boldsymbol{\\omega}})= ( \\mathrm{-i})^m ( \\omega^{i_1}_{i_1}\\cdot\\dots\\cdot\\omega^{i_d}_{i_d } ) { \\mathcal{f}}[f]({\\boldsymbol{\\omega } } ) .",
    "\\label{fder}\\ ] ]    now , in order to prove the theorem , we just mimic the proof of theorem  [ mainth ] . employing the complex exponential in ( [ ctform ] ) and the equality ( [ fder ] )",
    "we have @xmath371\\;\\leq\\;\\frac{c^2_t}{n},\\nonumber\\\\ \\hspace{-1cm}&&|(\\mathrm{-i})^m(\\omega^{i_1}_{1}\\dots\\cdot\\omega^{i_d}_{d } ) k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}})|^2\\cdot{\\mathbb{e}}[|\\psi_t^n({\\boldsymbol{\\omega}})-\\psi_t({\\boldsymbol{\\omega}})|^2]\\nonumber\\\\ & & \\hspace{4.55 cm } \\;\\leq\\;|(\\mathrm{-i})^m(\\omega^{i_1}_{1}\\dots\\cdot\\omega^{i_d}_d ) k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}})|^2\\cdot\\frac{c^2_t}{n},\\nonumber\\\\ \\hspace{-1cm}&&{\\mathbb{e}}\\;[|(\\mathrm{-i})^m(\\omega^{i_1}_{1}\\dots\\cdot\\omega^{i_d}_{d } ) ( \\psi_t^n({\\boldsymbol{\\omega}})k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega } } ) ) -(\\mathrm{-i})^m(\\omega^{i_1}_{1}\\dots\\cdot\\omega^{i_d}_{d } ) ( \\psi_t({\\boldsymbol{\\omega}})k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}}))|^2]\\nonumber\\\\ \\hspace{-1cm}&&\\hspace{4.55 cm } \\;\\leq\\;|(\\mathrm{-i})^m(\\omega^{i_1}_{1}\\dots\\cdot\\omega^{i_d}_{d } ) k_{{\\mathcal{f}}}(h{\\boldsymbol{\\omega}})|^2\\cdot\\frac{c^2_t}{n},\\nonumber\\\\ \\hspace{-1 cm } & & { \\mathbb{e}}\\left[\\int |{\\mathcal{f}}[\\,\\partial^m \\hat{p}^n_t/\\partial x^{i_1}_1\\dots\\partial x^{i_d}_d]({\\boldsymbol{\\omega } } ) -{\\mathcal{f}}[\\,\\partial^m p^*_t/\\partial x^{i_1}_1\\dots\\partial x^{i_d}_d]({\\boldsymbol{\\omega}})|^2\\ , d{\\boldsymbol{{\\boldsymbol{\\omega}}}}\\right]\\nonumber\\\\ \\hspace{-1cm}&&\\hspace{4.55 cm } \\;\\leq\\;\\frac{c^2_t}{n}\\!\\ ! \\int |{\\mathcal{f}}[\\partial^m",
    "\\partial x^{i_1}_1\\dots\\partial x^{i_d}_d]|^2\\,d{\\boldsymbol{\\omega}},\\nonumber\\\\ \\hspace{-1 cm } & & { \\mathbb{e}}\\left[\\int |{\\mathcal{f}}[\\,\\hat{p}_{t , i_1,\\dots , i_d}^{n,(m)}({\\boldsymbol{x}}_t)]({\\boldsymbol{\\omega } } ) -{\\mathcal{f}}[\\,p_{t , i_1,\\dots , i_d}^{*,(m)}({\\boldsymbol{x}}_t)]({\\boldsymbol{\\omega}})|^2\\ , d{\\boldsymbol{{\\boldsymbol{\\omega}}}}\\right]\\nonumber\\\\ \\hspace{-1cm}&&\\hspace{4.55 cm } \\;\\leq\\;\\frac{c^2_t}{n}\\!\\ !",
    "\\partial x^{i_1}_1\\dots\\partial x^{i_d}_d]|^2\\,d{\\boldsymbol{\\omega}},\\nonumber\\\\ \\hspace{-1 cm } & & { \\mathbb{e}}\\left[\\int ( \\hat{p}_{t , i_1,\\dots , i_d}^{n,(m)}({\\boldsymbol{x}}_t ) -p_{t , i_1,\\dots , i_d}^{*,(m)}({\\boldsymbol{x}}_t))^2\\ , d{\\boldsymbol{x}}_t\\right]\\nonumber\\\\ \\hspace{-1cm}&&\\hspace{4.55 cm } \\;\\leq\\;\\frac{c^2_t}{nh^{2d}}\\!\\ ! \\int ( \\partial^m k({\\boldsymbol{x}}/h)/ \\partial x^{i_1}_1\\dots\\partial x^{i_d}_d)^2\\,d{\\boldsymbol{x}},\\nonumber\\\\ \\hspace{-1 cm } & & { \\mathbb{e}}\\left[\\int ( \\hat{p}_{t , i_1,\\dots , i_d}^{n,(m)}({\\boldsymbol{x}}_t ) -p_{t , i_1,\\dots , i_d}^{*,(m)}({\\boldsymbol{x}}_t))^2\\ , d{\\boldsymbol{x}}_t\\right]\\nonumber\\\\ \\hspace{-1cm}&&\\hspace{4.55 cm } \\;\\leq\\;\\frac{c^2_t}{nh^{d+2m}}\\!\\ ! \\int ( \\partial^m k({\\boldsymbol{u}})/ \\partial u^{i_1}_1\\dots\\partial u^{i_d}_d)^2\\,d{\\boldsymbol{u}},\\nonumber\\\\ \\hspace{-1cm}&&{\\mathbb{e}}\\left[\\int ( \\hat{p}_{t , i_1,\\dots , i_d}^{n,(m)}({\\boldsymbol{x}}_t)- p_{t , i_1,\\dots , i_d}^{*,(m)}({\\boldsymbol{x}}_t))^2\\,d{\\boldsymbol{x}}_t\\right]\\nonumber\\\\ \\hspace{-1cm}&&\\hspace{4.55 cm } \\;\\leq\\;\\frac{c^2_t}{nh^{d+2 m } } \\int ( k^{(m)}_{i_1,\\dots , i_d}({\\boldsymbol{u}}))^2\\,d{\\boldsymbol{u}}.\\nonumber\\end{aligned}\\ ] ]    using the @xmath29 norm of @xmath372 , i.e. , @xmath373 , the above reads as @xmath374    for given @xmath375 , we assume that @xmath359 , @xmath340 exist and are sobolev in the sense of validity of ( [ sobolevprop ] ) .",
    "that is , for the fourier transforms @xmath376({\\boldsymbol{\\omega}})$ ] there exist positive constants @xmath377 such that @xmath378({\\boldsymbol{\\omega}})|^2 \\,d{\\boldsymbol{\\omega}}\\,\\leq\\ , ( 2\\pi)^d l^{2}_{t,(m)}.\\ ] ] using ( [ pdsobolev ] ) we have under the assumptions of theorem  [ bdtheorem ] the formula @xmath379    by ( [ conv1kd ] ) we get the counterpart of ( [ e2fce ] ) that writes as @xmath380({\\boldsymbol{\\omega}})|^2\\,d{\\boldsymbol{\\omega}}\\\\[0.2 cm ] & & \\hspace{2.5cm}\\leq a^2 h^{2\\beta}l_{t,{(m)}}^2.\\end{aligned}\\ ] ]    we proceed in the same way as in the proof of theorem  [ mainth ] .",
    "we consider the @xmath322 norm and employ the triangle inequality to get @xmath381    the bandwidth @xmath147 develop with @xmath323 as @xmath362 for some @xmath278 .",
    "so we have @xmath382 .",
    "further , @xmath383 and therefore @xmath384 this gives us after squaring ( [ pdtriangle ] ) the statement of the theorem : @xmath385 for @xmath386 .",
    "@xmath60 + the structure of formula ( [ ctpder ] ) is the same as that of formula ( [ mtheq1 ] ) of theorem  [ mainth ] .",
    "only two constants are replaced .",
    "therefore , the discussion of its corollaries remains valid , especially , it implies the convergence of partial derivatives of the kernel density estimates to the respective derivatives of the related filtering densities .    on the other hand , we see that the order of the partial derivative @xmath349 slows down the convergence .",
    "in fact , it has the same effect on the convergence as the dimension @xmath142 , see the discussion concerning the influence of the dimension below theorem  [ mainth ] .",
    "in theorem [ mainth ] , we have assumed that the filtering densities @xmath293 , @xmath340 , @xmath87 are @xmath276-sobolev over time . this assumption can be verified for @xmath387 , but for other time instants @xmath388 a  direct verification is typically impossible .",
    "that is why we are interested in a practical tool for performing the verification indirectly so that the assumptions for the convergence result of theorem  [ mainth ] were fulfilled . as a result",
    ", we present a sufficient condition on the densities of transition kernels of the signal process such that the sobolev character of the filtering densities is retained over time .    in the statement",
    "below , we work with the prediction and update formulas , ( [ l1 ] ) and ( [ l2 ] ) , respectively , of section [ fesec ] .",
    "we rewrite these formulas in the more compact form using the following shortcuts : @xmath389 , @xmath288 ( in fact , this shortcut was already used in theorem  [ mainth ] ) and @xmath390 for the respective densities ; and @xmath391 for the normalizing integral . using the introduced shortcuts we have ( [ l1 ] ) and ( [ l2 ] ) written as @xmath392",
    "let @xmath11 be the transition kernel in the filtering problem for time @xmath393 , @xmath394 .",
    "as the conditional characteristic function @xmath395({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})$ ] of the transition kernel @xmath11 we denote the characteristic function of the conditional distribution determined by this kernel ,  i.e. , @xmath396({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})= \\int e^{\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{x}}_t{\\rangle } } k_{t-1}(d{\\boldsymbol{x}}_t|{\\boldsymbol{x}}_{t-1}).\\ ] ]    [ th2 ] in the filtering problem , let @xmath397 .",
    "let @xmath11 , @xmath9 be the set of the transition kernels and @xmath395 $ ] , @xmath9 be the set of the corresponding conditional characteristic functions . for all @xmath9 , let @xmath395 $ ]",
    "be bounded by a  function @xmath398 in such a way that for any @xmath399 and @xmath196 @xmath400 satisfy ( [ sobolevprop ] ) for some @xmath274 and @xmath401",
    ". then the filtering densities @xmath293 are @xmath276-sobolev for all , i.e. , @xmath298 , with the recurrence for @xmath345 written as @xmath402 where @xmath403 .",
    "* proof . *",
    "the theorem holds for @xmath387 by the assumption .",
    "let @xmath9 , then by multiplying both sides of ( [ predft ] ) by the complex exponential we get from the prediction formula @xmath404 by integration , the left - hand side gives the characteristic function @xmath405 of  @xmath406 , i.e. , @xmath407 the right - hand side has then form @xmath408({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})\\,d{\\boldsymbol{x}}_{t-1}.\\end{aligned}\\ ] ] the equality of two complex numbers is equivalent to the equality of their complex conjugates .",
    "hence we can multiply both sides by their complex conjugates with the equality retained .",
    "this gives us the expression @xmath409({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})\\,d{\\boldsymbol{x}}_{t-1}\\right|^2.\\ ] ]    by the jensen s inequality and assumed boundedness of @xmath395 $ ] , we have @xmath410({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})|\\ , p_{t-1}({\\boldsymbol{x}}_{t-1})\\,d{\\boldsymbol{x}}_{t-1}\\right)^{\\!\\!2}\\\\ & \\leq & \\left(|k_b({\\boldsymbol{\\omega}})| \\int\\ ! p_{t-1}({\\boldsymbol{x}}_{t-1})\\,d{\\boldsymbol{x}}_{t-1}\\!\\right)^{\\!\\!2 } \\!=|k_b({\\boldsymbol{\\omega}})|^2.\\end{aligned}\\ ] ] thus , @xmath411    the above formula shows that @xmath412 for any @xmath9 .",
    "we proceed with the specification of the sobolev constant @xmath345 of the update ( filtering ) density @xmath293 .    in section  [ ftds ] , in formula ( [ gtdef ] ) , there was shown that the function @xmath413 of the update formula ( [ updateft ] ) has form @xmath414 .",
    "function @xmath415 is the density of the noise term in the observation process and is assumed to be bounded .",
    "thus , we have @xmath416 .",
    "again , multiplying the update formula ( [ updateft ] ) by the complex exponential , integrating and multiplying by the respective conjugates gives us @xmath417 this concludes the proof.@xmath60 + the theorem tells us that , in the particle filter , the character of the filtering densities is retained over time if the set of the conditional characteristic functions of transition kernels @xmath395({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})$ ] , @xmath9 is uniformly bounded .",
    "considering preservation of the sobolev character of partial derivatives ( in the sense of validity of ( [ sobolevprop ] ) ) of the filtering densities @xmath418 , the theorem holds as well .",
    "the difference is that we assume that @xmath419 is is @xmath276-sobolev or write @xmath420 as the partial derivative is not a density anymore .",
    "but , if we still do it for a  general function , then we mean that the fourier transform of this function exists and satisfies the inequality ( [ sobolevprop ] ) for some @xmath274 and @xmath265 . ] and , in ( [ ikf ] ) , instead of considering boundedness of @xmath395({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})$ ] , we consider the boundedness of @xmath421({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})$ ] for any @xmath399 , @xmath9 .",
    "[ derth2 ] in the filtering problem , let @xmath419 be @xmath276-sobolev for some @xmath274 , @xmath422 and @xmath358 such that @xmath228 , @xmath350 .",
    "let @xmath11 , @xmath9 be the set of the transition kernels , and @xmath423 , @xmath9 the set of corresponding partial derivatives .",
    "let @xmath421({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})$ ] , @xmath9 be the set of the corresponding conditional fourier transforms , i.e. , @xmath424({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})= \\int e^{\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{\\boldsymbol{x}}_t{\\rangle } } k_{t-1,i_1,\\dots , i_m}^{(m)}({\\boldsymbol{x}}_t|{\\boldsymbol{x}}_{t-1})\\,d{\\boldsymbol{x}}_t.\\ ] ] for all @xmath9 , let @xmath421 $ ] be bounded by some function @xmath425 in such a way that for any @xmath399 and @xmath196 , @xmath426 satisfy ( [ sobolevprop ] ) for the above @xmath274 and some @xmath427 .",
    "then the partial derivatives of filtering densities @xmath418 , are @xmath276-sobolev with the recurrence for @xmath345 written as @xmath428 where @xmath429",
    ".    * proof . *",
    "the theorem holds for @xmath419 by the assumption . from the prediction formula ,",
    "multiplying both sides of ( [ predft ] ) by the complex exponential , we get @xmath430 by integration , the left - hand side just gives the characteristic function @xmath405 of  @xmath406 , i.e. , @xmath407 the right - hand side has then form @xmath431({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})\\,d{\\boldsymbol{x}}_{t-1}.\\end{aligned}\\ ] ] multiplying both sides by @xmath432 , we move both sides to the fourier transforms of the corresponding partial derivatives",
    ". that is , @xmath433\\ ] ] and @xmath434({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})\\,d{\\boldsymbol{x}}_{t-1}=\\ ] ] @xmath435 ( { \\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})\\,d{\\boldsymbol{x}}_{t-1}.\\ ] ] further multiplying both sides by the complex conjugates gives the expression @xmath436|^2=",
    "\\left|\\int p_{t-1}({\\boldsymbol{x}}_{t-1 } ) { \\mathcal{f}}[k_{t-1,i_1,\\dots , i_m}^{(m ) } ] ( { \\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})\\,d{\\boldsymbol{x}}_{t-1}\\right|^2.\\ ] ]    now , by the assumed boundedness of @xmath421 $ ] and the jensen s inequality , we have @xmath437({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})|\\ , p_{t-1}({\\boldsymbol{x}}_{t-1})\\,d{\\boldsymbol{x}}_{t-1}\\right)^{\\!\\!2}\\\\ & \\leq & \\left(|k_{b,(m)}({\\boldsymbol{\\omega}})| \\int\\ ! p_{t-1}({\\boldsymbol{x}}_{t-1})\\,d{\\boldsymbol{x}}_{t-1}\\!\\right)^{\\!\\!2 } \\!=|k_{b,(m)}({\\boldsymbol{\\omega}})|^2.\\end{aligned}\\ ] ] thus , @xmath438    the above formula shows that @xmath439 for any @xmath9 .",
    "we proceed with the specification of the sobolev constant @xmath377 of the partial derivative @xmath418 .    similarly as in the proof of theorem  [ th2 ] , we have @xmath440 .",
    "further , multiplying the update formula ( [ updateft ] ) by the complex exponential , integrating , multiplying by @xmath432 and the respective conjugates we shift to the fourier transforms of partial derivatives and get @xmath441|^2 & \\leq & ||g_t||_{\\infty}^2\\,|{\\mathcal{f}}[\\,{\\overline{p}}_{t , i_1,\\dots , i_m}^{(m)}]|^2,\\\\    & \\leq & \\frac{||g_t||_{\\infty}^2}{({\\overline{\\pi}}_tg_t)^2}\\,||{\\boldsymbol{\\omega}}||^{2\\beta }    ( 2\\pi)^{-d}\\!\\int\\ ! ||{\\boldsymbol{\\omega}}||^{2\\beta }    & \\leq & \\frac{||g_t||_{\\infty}^2l^2_{k_{b,(m)}}}{({\\overline{\\pi}}_tg_t)^2}=l^2_{t,(m)}. \\label{derltdef}\\end{aligned}\\ ] ] this concludes the proof.@xmath60",
    "in this section , we demonstrate an application of the presented theory . because our research has not been driven by any concrete application",
    ", we apply the particle filtering and kernel density estimation methodologies on the filtering problem for a  multivariate gaussian process .",
    "this problem has the analytical solution - the well - known kalman filter @xcite .",
    "the purpose of this choice is to check if empirical results from computer simulations follow the analytic counterpart . by replacing the gaussian transition kernel and gaussian observation density by general entities we can build up the appropriate particle filter for a general markov process , but without the possibility of checking against the analytical solution .",
    "let the signal and observation processes introduced in section  [ sigsec ] be specified as multivariate gaussian .",
    "that is , we assume that the formulas driving evolution of states and observations are specified , for a general dimension @xmath442 ,  as @xmath443 where @xmath444 , @xmath445 are @xmath446 regular matrices and @xmath447 , @xmath448 are multivariate normal noise terms with @xmath446 covariance matrices @xmath449 and @xmath450 .",
    "the signal process @xmath451 forms a multivariate markov chain with gaussian transition kernels .",
    "the initial distribution is considered also multivariate normal , i.e. , @xmath452 , @xmath453 and @xmath454 is a @xmath446 covariance matrix .",
    "mathematically , the filtering task is to find the conditional expected values @xmath455 $ ] for @xmath456 . at the given time instant  @xmath9 ,",
    "the conditional expected value is the integral characteristic of the related conditional distribution which represents the filtering distribution we are interested  in .",
    "the vector @xmath457 is multivariate normal because it is determined by a linear transformation of the vector @xmath458 which is multivariate normal .",
    "therefore , the filtering distribution is also multivariate normal , and is determined by its mean vector @xmath459 and its covariance matrix  @xmath460 at time @xmath9 .",
    "the preservation of the normal character of the filtering distribution over time allows us to obtain an analytic expression for its parameters .",
    "the result is known as the _ multivariate kalman filter_.      the theoretical analysis presented in @xcite gives the following recursive kalman s equations for @xmath459 and @xmath460 .",
    "the parameters are computed in several steps using some auxiliary variables for @xmath456 : @xmath461^{-1 } , \\nonumber\\\\ { \\boldsymbol{\\mu}}_t&=&{\\boldsymbol{\\mu}}_{t|t-1}+{{\\boldsymbol{\\mathrm{k}}}}_t[{\\boldsymbol{y}}_t-{{\\boldsymbol{\\mathrm{h}}}}{\\boldsymbol{\\mu}}_{t|t-1}],\\\\ \\label{mvk1 } { \\boldsymbol{\\sigma}}_{t}&=&[{{\\boldsymbol{\\mathrm{i}}}}_d-{{\\boldsymbol{\\mathrm{k}}}}_t{{\\boldsymbol{\\mathrm{h}}}}]{\\boldsymbol{\\sigma}}_{t|t-1}. \\label{mvk2}\\end{aligned}\\ ] ]    using the above formulas , one can recursively compute the determining parameters of the filtering distribution over time . due to the normal character of the distribution , we have apparently @xmath455={\\boldsymbol{\\mu}}_t$ ] . further",
    ", the formula for the evolution of the covariance matrix @xmath462 is deterministic .",
    "that is , it is not affected by observations .",
    "the incorporation of schema ( [ mvgprocess ] ) into the particle filter s computation , presented in section  [ smcalgsec ] , stems from the specification of the initial density @xmath88 and the set of transition kernels @xmath11 , @xmath9 .",
    "as already mentioned , the initial density is multivariate normal with some mean @xmath453 and a @xmath446 covariance matrix @xmath463 , i.e. , @xmath464\\!.\\ ] ] the densities of gaussian transition kernels @xmath465 , @xmath9 are specified  as @xmath466\\ ] ] with @xmath467 .",
    "the above formula reflects the multivariate normal character of the noise term @xmath468 in ( [ mvgprocess ] ) and , in fact , corresponds to the specification of the density of the multivariate normal distribution @xmath469 .",
    "the sobolev character of the filtering densities is given by the sobolev character of the gaussian transition kernels .",
    "we show that the conditional characteristic functions of the gaussian kernels ( [ mgkeq ] ) are uniformly bounded , which implies the sobolev character according to theorem  [ th2 ] .",
    "we have @xmath395({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})={\\mathcal{f}}[\\mathcal{n}({{\\boldsymbol{\\mathrm{f}}}}{\\boldsymbol{x}}_{t-1},{{\\boldsymbol{\\mathrm{q}}}})]$ ] , and therefore @xmath396({\\boldsymbol{\\omega}}|{\\boldsymbol{x}}_{t-1})= e^{\\mathrm{i}{\\langle}{\\boldsymbol{\\omega}},{{\\boldsymbol{\\mathrm{f}}}}{\\boldsymbol{x}}_{t-1}{\\rangle } } \\exp\\left[-\\frac{1}{2}{\\boldsymbol{\\omega}}^{t}{{\\boldsymbol{\\mathrm{q}}}}\\,{\\boldsymbol{\\omega}}\\right].\\ ] ] further , @xmath470\\\\ & \\leq & \\exp\\left[-\\frac{1}{2}\\lambda_{\\min}||{\\boldsymbol{\\omega}}||^2\\right ] = k_b({\\boldsymbol{\\omega}}),\\end{aligned}\\ ] ] where @xmath471 is the minimal eigenvalue of the covariance matrix  @xmath472 .    for the sobolev constant @xmath473 of @xmath474 and @xmath271",
    ", we have the integral @xmath475 = \\frac{\\pi^{-\\frac{d}{2}}}{4^d(\\sqrt{\\lambda_{\\min}})^{d+2}}.\\ ] ]    from this result we also see that any multivariate normal initial distribution with the covariance matrix @xmath454 is @xmath476-sobolev with the constant @xmath477 $ ] , where @xmath478 is the minimal eigenvalue of @xmath454 .    the obtained result on the sobolev character of the filtering densities is consistent with the fact that all densities in the multivariate gaussian process ( [ mvgprocess ] ) are normal , i.e. , the character of the involved densities does not change during operation of the filter .      in the multivariate gaussian particle filter ,",
    "kernel density estimates are made using the multivariate standard normal ( convolution ) kernel @xmath479.\\ ] ]    the specification of the @xmath29 norm of the kernel is straightforward .",
    "we have @xmath480 hence @xmath481 .",
    "concerning the @xmath306 constant of theorem [ bdtheorem ] , we start with the fourier transform of the multivariate standard normal kernel which corresponds to the characteristic function of the @xmath482 distribution . that is , @xmath483 . in order to specify some constant @xmath306 , we need to determine a bound on the spectral matrix norm of the hessian of @xmath484 .",
    "the entries of the hessian matrix @xmath485 reads as @xmath486 in the matrix notation , the hessian writes as @xmath487 . using the spectral matrix norm we get @xmath488    note that for a vector @xmath196 , @xmath489 ( the standard euclidean norm ) .",
    "let @xmath490 such that @xmath491 .",
    "then we clearly have @xmath492 as @xmath493 .",
    "the multidimensional taylor s theorem for @xmath484 writes as @xmath494{\\boldsymbol{\\omega}}\\ ] ] for a suitable @xmath495 , @xmath496 . for the gradient",
    ", we have @xmath497 and @xmath498 , therefore the above taylor s theorem gives for any @xmath499 , @xmath500{\\boldsymbol{\\omega}},\\\\    \\frac{1}{2 }        \\frac{|k_{{\\mathcal{f}}}({\\boldsymbol{\\omega}})-1|}{||{\\boldsymbol{\\omega}}|| } & \\leq&||{\\boldsymbol{\\omega}}^t||=||{\\boldsymbol{\\omega}}||.\\end{aligned}\\ ] ]    further @xmath501 for all @xmath196 and therefore @xmath502 for @xmath258 .",
    "thus , joining the two inequalities we finally get @xmath503 and the @xmath306 constant equals to 1 , i.e. , @xmath504",
    ".    the above considerations immediately lead to the specification of the order of the multivariate standard normal kernel . as mentioned ,",
    "the fourier transform of the kernel is @xmath505 and @xmath506 .",
    "the related gradient writes as @xmath507 , thus @xmath497 .",
    "for the hessian of @xmath201 , we have @xmath508 .",
    "hence the order of the kernel is @xmath509 .      in this section",
    "we introduce our implementation of the multivariate kalman filter and its particle filter counterpart to show results of several experiments .",
    "we have implemented both filters in the form of a matlab function .",
    "the inputs into the function are @xmath510 matrices of formula ( [ mvgprocess ] ) , the computational horizon @xmath87 and the selected number of particles @xmath79 .",
    "the outputs are the means and covariance matrices from the particle and kalman filters , respectively .",
    "if the dimension of the signal process is @xmath511 or @xmath512 , then the script provides a graphical output illustrating the estimated density and its theoretical counterpart from the kalman filter .",
    "the source code of the function is presented in appendix  [ mvsmc.m ] .",
    "we have performed several experiments in order to check if the computational behavior of the multivariate gaussian particle filter coincides with the analytical results .",
    "the experiments were performed for the following setting of parameters : @xmath513 , @xmath514 , @xmath515 , @xmath516 . in the script ,",
    "the density of the multivariate standard normal distribution is used as the initial density .",
    "computational horizon was set to @xmath517 .",
    "the results of three @xmath512 experiments for different numbers of particles @xmath518 and @xmath519 are presented in table  [ resmkf ] .",
    "graphically , the obtained kernel density estimate and theoretical filtering density are presented in fig .",
    "[ mv100 ] for @xmath520 .",
    ".comparison of bivariate particle and kalman filters . [ cols=\"<,^,^,^,^,^,^\",options=\"header \" , ]         on the basis of the inspection of the numerical results presented in table  [ resmkf ] , we can state a good agreement of numerical characteristics delivered by the gaussian particle filter with the theoretical characteristics of the filtering distributions .",
    "in the paper , we have demonstrated that the standard methodology of kernel density estimates can be applied in the area of particle filtering .",
    "we have proved that the kernel density estimates constructed on the basis of particles generated by the particle filter converge in the mise to the theoretical filtering density at each time instant of operation of the filter .",
    "the result holds even though the generated particles do not constitute an i.i.d .",
    "sample from the filtering distribution .",
    "moreover , we have stated the sufficient condition for the preservation of the sobolev character of the filtering densities over time .",
    "the extension of both results to the partial derivatives of the kernel estimates and filtering densities has been provided as well .    in theorem 2 , the constant @xmath521 is known that it typically grows exponentially with time , see e.g. , @xcite p.  87",
    ", therefore @xmath342 of ( [ mtheq2 ] ) does so ; and , if one wants to assure the given precision of the density approximation , then one must increase the number of generated particles exponentially , too .",
    "this is an unpleasant property of the particle filter . on the other hand ,",
    "there are results available , e.g. , @xcite or @xcite , that under additional conditions , uniformly convergent particle filters can be constructed .",
    "that is , that @xmath128 of ( [ ctformula ] ) is constant over time .",
    "the constant @xmath342 depends on @xmath345 . under the conditions of theorem  [ th2 ] , we know the evolution of @xmath345 over time . in fact",
    ", the evolution is somehow similar to the evolution of @xmath128 constant and there is again the risk of an exponential growth of @xmath345 .",
    "the study of the conditions when @xmath345 evolves uniformly over time is the issue of the future research in this field .",
    "the author is grateful to v. bene ( charles university in prague ) for stimulating interest in the field of particle filtering .",
    "the research was supported by cost grant ld13002 provided by the ministry of education , youth and sports of the czech republic .",
    "a.  doucet and a.  m. johansen , `` a tutorial on particle filtering and smoothing : fifteen years later , '' in _ the oxford handbook of nonlinear filtering _ ,",
    "d.  crisan and b.  rozovskii , eds.1em plus 0.5em minus 0.4emoxford university press , 2011 .",
    "f.  legland and n.  oudjane , `` stability and uniform approximation of nonlinear filters using the hilbert metric and application to particle filters , '' _ the annals of applied probability _ , vol .",
    "14 , no .  1 ,",
    "pp . 144187 , 2004 .",
    "p.  d. morral and a.  guionnet ,",
    "`` on the stability of interacting processes with applications to filtering and genetic algorithms , '' _ annales de linstitut henri poincar ( b ) probabilits et statistiques _ , vol .",
    "37 , no .  2 ,",
    "pp . 155194 , 2001 ."
  ],
  "abstract_text": [
    "<S> the paper deals with kernel density estimates of  filtering densities in the particle filter . </S>",
    "<S> the convergence of the estimates is investigated by means of fourier analysis . </S>",
    "<S> it is shown that the estimates converge to the theoretical filtering densities in the mean integrated squared error under a certain assumption on the sobolev character of the filtering densities . </S>",
    "<S> a  sufficient condition is presented for the persistence of this sobolev character over time . </S>",
    "<S> both results are extended to partial derivatives of the estimates and filtering densities .    </S>",
    "<S> shell : bare demo of ieeetran.cls for journals </S>"
  ]
}