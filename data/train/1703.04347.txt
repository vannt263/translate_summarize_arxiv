{
  "article_text": [
    "the identification , segmentation , and quantification of structures visible in medical images is a crucial component in the processing of medical image data . in the context of spinal images , segmentation of spine",
    "has an immediate diagnostic importance in clinical decisions around fracture detection and inter - vertebral disc pathology .",
    "segmented spines are also used in the bio - mechanical modelling of the spine for load analysis and fracture prediction .",
    "therefore , an automated approach attempting to segment the spine should posses two key features : ( 1 ) highly generalisable in terms of the fields - of - view ( fov ) and scanner calibrations , in addition to variability in the spine s curvature , bmd ( bone mineral density ) distribution , and micro - architecture and ( 2 ) capable of segmenting images from a clinical population that consists of abnormalities such as vertebral fractures , scoliotic , and kyphotic spines .    a typical analysis pipeline for spinal images consists of three stages : spine localisation , vertebrae detection , and spine segmentation .",
    "the first two steps of localisation and detection are accomplished by basic routines such as shape matching ( using generalised hough transform @xcite ) and spine - curve detection ( using circle detection in axial slices @xcite ) .",
    "this is followed by a segmentation stage which may tackled using statistical mean shape models or atlases , followed by an optimisation routine that adapts the fitted model to account for local variations @xcite .",
    "such a pipeline has proven to be highly effective in most of the cases . however , there is a limit to the amount of generalisability such model / shape - based approach can offer in clinical cases .",
    "its limit is determined by the robustness of the chosen model and the amount of relaxation it can withstand during the optimisation routine post fit .",
    "it is obvious that such models can not generalise to a fractured vertebra or a deformed spine . in such cases ,",
    "learning - based approaches offer respite , provided that the data that the approach can learn from is rich and diverse enough .",
    "for example , @xcite and @xcite solve the problem of vertebra detection in arbitrary fovs using random forests and multi - layer regressors respectively .",
    "chen et al .",
    "@xcite make use of the omni - present convolutional neural networks to detect vertebrae using an altered cost formulation that takes into account the sequence of the vertebrae",
    ". however , there is no _ end - to - end _ approach that handles every problem in the analysis pipeline ( localisation , detection , and segmentation ) in one go , that is , takes a 3d spine scan as input and generates an annotated and segmented spine volume .    in this work ,",
    "we propose an approach that segments and simultaneously labels the the lumbar vertebrae using deep neural networks . given a ct scan volume of an arbitrary fov , our approach performs a multi - class segmentation over five classes corresponding to the five lumbar vertebrae ( l1 to l5 ) and a background class .",
    "this is done in a two - staged approach : ( 1 ) localise the lumbar region , and ( 2 ) segment the localised lumbar vertebrae in to their respective classes .",
    "both the stages are elaborated in detail in section [ sec : methodology ] .",
    "figure [ figure:1 ] gives a schematic overview of our approach .",
    "we use the dataset released as part of the xvertseg challenge in miccai 2016 to test the performance of our approach .",
    "we are the first to attempt this challenge , and achieve a mean dice coefficient upwards of 90% on both the training and the test set .",
    "section [ sec : exp ] contains the implementation and experimental details .",
    "when compared to typical binary segmentation , multi - class segmentation is inherently difficult due to a more complex representation that is to be learnt .",
    "moreover , the appearance of adjacent vertebrae are highly correlated .",
    "thus , instead of directly attempting the segmentation problem on the entire scan , we choose to restrict our attention to a restricted region of interest - the lumbar region .",
    "we pose the localisation of the lumbar region as a regression problem , and employ a five - layered perceptron with relu ( rectified linear unit ) activation as a regressor .",
    "it is trained on contextual , intensity - dependant features that encode long - range spatial information , as in @xcite , and regresses on the location of the six planes that define a bounding box .",
    "an @xmath0 lenght feature , @xmath1 can be constructed at the voxel location of @xmath2 as below : @xmath3    where @xmath4 , @xmath5 is the mean intensity of the 3d image region lying inside a cuboid that is centered at a certain offset from the voxel at @xmath2 .",
    "the cuboid s offset and the dimension are generated randomly for construction of a feature .",
    "given these features , each of them corresponding to a voxel location , the regressor should predict the region - of - interest , or a bounding box around the lumbar region .    in a simple set - up , a bounding box can be defined by six planes : @xmath6 , the smallest @xmath7-coordinate , @xmath8 , the largest @xmath7-coordinate , and their @xmath9 and @xmath10 equivalents .",
    "these are refereed to as the _ bounding planes_. given the contextual information through the feature @xmath1 , a six - length vector encoding the voxel s location _ relative _ the bounding planes is learnt , as below : @xmath11      each pass through the regressor using a feature corresponding to a certain voxel predicts the locations of the bounding planes with respect to that voxel . in order to speed - up the feature generation procedure without loss of useful information , only the _ significant",
    "_ voxels are considered for feature extraction . for this purpose ,",
    "the voxels from the response of a canny s edge detector are used for feature extraction .",
    "thus , every significant voxel votes for a prospective bounding box of which the most representative bounding box is chosen .",
    "figure [ figure:2 ] shows a few examples of the localised lumbar regions .",
    "once the lumbar region is successfully identified , the fov is restricted , enabling a human to effectively identify the vertebrae , based on certain key points such as the sacrum , number of vertebrae in the fov etc .",
    "we make use of a deep convolutional network to learn such key points on its own in order to segment and annotate the lumbar vertebrae .",
    "this is the segmentation of the vertebrae is carried out by a fully convolutional network ( fcn ) .",
    "we rely on the 2d u - net @xcite , but implement an architecture that one level deeper , i.e. , six more convolutional layers , three each in the contracting and expanding path , joined by one additional downsampling and up - convolutional layers , and works on sagittal slices from the localised lumbar region .",
    "the motivation for a deeper network is to adapt it towards multi - label classification of vertebrae by increasing the receptive field of the coarsest level .",
    "the receptive field of our fcn ( @xmath12 270@xmath13270 pixel@xmath14 or 27@xmath1327@xmath15 ) covers at least two vertebrae when working at isotropic @xmath16 resolution .",
    "such a receptive field will force the network to learn the sequence of vertebrae in pairs , l1-l2 , l2-l3 etc .",
    ", so that the sequence of the annotations is always in order .",
    "it is a common practice to pre - train a network for one purpose and use it as an initialisation for another network attempting a related yet more - complex task .",
    "for example , long et al .",
    "@xcite use the state - of - art recognition networks ( vgg-16 etc . ) as initialisation for the task of segmentation . on a similar footing , a network trained for binary segmentation of lumbar spine ( spine vs. background )",
    "is employed as an initialisation for the multi - class segmentation .",
    "this alleviates the shortcoming of the limited data at our disposal to train a very deep network for the relatively complex task of multi - class segmentation .",
    "another key concept in our segmentation routine is the roi augmentation step .",
    "however , the localisations are not _ uniform _ as shown in figure [ figure:2 ] .",
    "there could either be non - lumbar vertebrae showing up in the sagittal slices ( usually t11 and t12 in our experiments ) , or part of the lumbar region could be missing ( usually l1 in our experiments ) .",
    "the high correlation in the appearance of the vertebrae makes this problem detrimental .",
    "therefore , in addition to augmenting the sagittal slices using elastic and rigid transformations , we also augment based on varying bounding boxes sizes .",
    "let @xmath17 be the dimension of the lumbar bounding box obtained from the localisation stage .",
    "we augment the sagittal slices from bounding box by randomly choosing a @xmath18 so that the sagittal slice dimensions vary between @xmath19 and @xmath20 .",
    "this makes the segmentation network robust to improper lumbar localisations .",
    "once all the sagittal slices are segmented , the final segmented volume is coronally corrected by closing the holes in every label of a coronal slice using morphological closing operation .",
    "finally , a 3d connected - component analysis is performed on each label to discard the smaller connected components .",
    "this cleans - up a few stray segmentations in the final volume .",
    "we make use of a publicly available dataset for evaluating the performance of the lumbar localisation and the multi - class segmentation stages of our approach .",
    "the xvertseg dataset , released as part of the xvertseg challenge @xcite in miccai 2016 , consists of fifteen train ct volumes with ground truth segmentations of the lumbar vertebrae ( into five classes , l1-l5 ) and ten test ct volumes .",
    "the participants do not have access to the ground truth segmentations of the test set .",
    "the data is very rich in terms of varying fovs , spine curvatures , and vertebral deformities .",
    "+ _ ground truth for localisation : _ the first and the last slices in the three directions ( sagittal , coronal , and axial ) consisting of a label were considered to be the bounding planes .",
    "a tolerance of 15 slices was added on all sides of the bounding box to prevent a tight cropping of the lumbar region .",
    "this expanded bounding box was used as the ground truth for training the localisation network .",
    "+ _ ground truth segmentations for test cases : _ as the challenge organisers did not make the performance metrics of our approach available yet , we opted for an in - house ground truth generation .",
    "the near - perfect segmentation from our approach was given to two clinical experts ( rater-1 and rater-2 ) for correction .",
    "rater-1 was tasked to correct the entire volume , while rater-2 was tasked to pick a random subset of sagittal , coronal , and axial slices from a volume and segment them entirely .",
    "inspired from @xcite , a five - layered neural network is cast as a regressor to map the features ( @xmath1 ) to the offsets of the bounding planes ( @xmath21 ) .",
    "the input layer has @xmath0 ( = 500 ) neurons , followed by four hidden layers with 350 , 250 , 150 , and 50 neurons respectively .",
    "the output layer has six neurons corresponding to the offsets of the six bounding planes .",
    "all the neurons are relus .",
    "the network was implemented in the caffe @xcite framework .",
    "a squared - error loss was optimised using stochastic gradient descent .",
    "the available data was augmented with rigid and elastic transformations .",
    "the network was trained for 1000 epochs over a few hours with a learning rate of 1e-3 and a momentum of 0.9 .",
    "the most representative bounding box is chosen using kernel density estimation , aided by botev bandwidth @xcite selection .    to measure the performance of localisation , a measure of _ sensitivity _ ( or true positive rate ) was used , as defined : @xmath22 where @xmath23 is the of set voxels in the ground truth segmentation , and @xmath24 is the set of voxels within the bounding box .",
    "we use the ground truth segmentation for rater-1 for this purpose .",
    "the sensitivity measures on the test set are shown in table [ table:1 ] , with a few cases shown visually in figure [ figure:2 ] .",
    "we obtain a near perfect localisation of 1.0 in all cases except one ( case025 ) . in order to completely cover the lumbar region , a tolerance of 15 voxels",
    "is added to the bounding boxes on all sides before considering the localisation for for the next stage .",
    "+ _ the curious case of case025 : _ case025 of the test set is peculiar due to the presence of the entire sacrum ( s1 , s2 , and s3 ) within the fov .",
    "it is the only such case in the train and the test data .",
    "the network thus furnishes an imperfect localisation from l2 to s1 .",
    "such a behaviour can be easily rectified with additional representative training data .",
    ".sensitivities of the localisation algorithms on the ten test cases .",
    "the localisation is near perfect ( @xmath251.0 ) for all the case except case25 .",
    "[ cols=\"^,^,^,^,^,^,^,^,^,^,^ \" , ]      the segmentation network is implemented in the caffe framework .",
    "a cross - entropy loss is optimised using an adam solver with an initial learning rate of 1e-4 .",
    "the binary segmentation network is run for 3000 epochs and the multi - class segmentation ( with pre - training ) net was run for 2000 epochs .",
    "the segmented bounding boxes are reinstated into the actual volumes to obtain the full - resolution segmentations .",
    "we report the dice coefficient for each of the five vertebrae and for the entire lumbar region in table [ table:2 ] .",
    "the evaluation is carried out based on the available ground truth segmentations of the train set and those from both rater-1 and rater-2 in case of the test set .",
    "we also observe a mean dice score of @xmath2592% .",
    "since our segmentation is the starting point for rater-1 , a bias in the corresponding performance scores can be observed , with a mean dice score of 94% .",
    "figure [ figure:3 ] shows the spread of the dice coefficients across vertebrae and among the datasets .",
    "observe that the vertebrae in the middle ( l3 and l4 ) are segmented well compared to the peripheral vertebrae ( l1 and l5 ) .",
    "this is expected since the uncertainty that the net has to overcome for deciding between l1 & t12 or l5 & s1 is higher compared to deciding between l2 & l3 or l3 & l4 owing to the large receptive field etc .          in general , both the stages in our pipeline work remarkably well as per the quantitative results in tables [ table:1 ] and [ table:2 ] .",
    "we obtain a near perfect localisation of 1.0 for almost every case , and a mean dice score of 92% .",
    "in addition to this , the prime motivation of our approach is to successfully segment the deformed spines where the model - based approaches fail .",
    "this can be observed visually in figure [ figure:4 ] .",
    "four test cases as shown highlighting the highly deformed spine and vertebrae .",
    "observe that our algorithm successfully segments these cases in spite of the severe deformations .",
    "deep - learning based algorithms are a way forward if generalisability is to be achieved . however , usage of such algorithms for dense segmentation is still in its incipient stage .",
    "the task of segmentation becomes more challenging when it involves multiple - classes over similar - looking vertebrae .",
    "we propose a two - staged approach with deep networks for localisation of the lumbar region and segmenting it into multiple classes .",
    "we are the first to present results on the xvertseg dataset , with an incredible performance achieving a mean dice coefficient of above 90% .",
    "we also highlight the ability of our approach to handle severe deformities in the spine , which prior approaches would struggle with .",
    "we believe that our approach can form a basis for handling more complicated tasks of multi - class segmentation of the entire spine",
    ".    4    klinder , t. , et al . : automated model - based vertebra detection , identification , and segmentation in ct images . in : medical image analysis , 13(3):471482 ( 2009 )",
    "forsberg , d. : atlas - based segmentation of the thoracic and lumbar vertebrae . in : proc miccai - csi 2014 , boston , usa : springer ( 2014 )    kadoury , s. , labelle , h. , and paragios , n. : spine segmentation in medical images using manifold embeddings and higher - order mrfs . in : ieee tmi , pages 12271238 ( 2013 )",
    "korez , r. , et al .",
    ": interpolation - based shape constrained deformable model approach for segmentation of vertebrae from ct spine images . in : proc miccai - csi 2014 , boston , usa : springer ( 2014 )    glocker , b. , et al . : automatic localization and identification of vertebrae in arbitrary field - of - view ct scans . in : miccai ( 2012 )",
    "suzani , a. , et al . : deep learning for automatic localization , identification , and segmentation of vertebral bodies in volumetric mr images . in : spie medical imaging , international society for optics and photonics , 2015 , pp .",
    "941 514941 514 ( 2015 )    chen , h. , et al .",
    ": automatic localization and identification of vertebrae in spine ct via a joint learning model with deep neural networks . in : miccai 2015 .",
    "lncs , vol . 9349 , pp .",
    "springer , heidelberg ( 2015 )    jia , y. , et al .",
    ": caffe : convolutional architecture for fast feature embedding ( 2014 ) , arxiv:1408.5093 [ cs.cv ]    botev , z.i . , grotowski , j.f . ,",
    "kroese , d.p . : kernel density estimation via diffusion . in : annals of statistics .",
    "38 ( 5 ) : 29162957 ( 2010 )    ronneberger , o. , fischer , p. , and brox , t. : u - net : convolutional networks for biomedical image segmentation . in : miccai , pp .",
    "234241 , springer ( 2015 )    long , j. , shelhamer , e. , darrell , t. : fully convolutional networks for semantic segmentation ( 2014 ) , arxiv:1411.4038 [ cs.cv ]    the xvertseg challenge , http://lit.fe.uni-lj.si/xvertseg/",
    "0.75         we present more results of multi - class segmentation on the test set of xvertseg ( figure 5 ) in addition to the results in figure 4 , thereby emphasising the robustness of our approach .",
    "we also present a few aberrant segmentations analysing which could further improve our approach .      as mentioned in section 3 ( lumbar localisation ) of the main article ,",
    "the localisation in case 25 occurs with a sensitivity of 0.94 ( figure 6(c ) , red outline ) as it is the only example in the train and test data that consists of three sacral bones ( s1 , s2 , and s3 ) within the field - of - view ( figure 6(a ) ) . when the scan , with s3 manually cropped off , is used as input ( figure 6(b ) ) , the lumbar localisation is perfect ( sensitivity of 1.0 ) , as shown by the green outline in figure 6(c ) .",
    "it is clear that the improper localisation is a consequence of working with limited data , and can easily be averted by increasing the variability in the training dataset ."
  ],
  "abstract_text": [
    "<S> multi - class segmentation of vertebrae is a non - trivial task mainly due to the high correlation in the appearance of adjacent vertebrae . </S>",
    "<S> hence , such a task calls for the consideration of both global and local context . based on this motivation , </S>",
    "<S> we propose a two - staged approach that , given a computed tomography dataset of the spine , segments the five lumbar vertebrae and simultaneously labels them . </S>",
    "<S> the first stage employs a multi - layered perceptron performing non - linear regression for locating the lumbar region using the global context . the second stage , comprised of a fully - convolutional deep network , exploits the local context in the localised lumbar region to segment and label the lumbar vertebrae in one go . aided with practical data augmentation for training , </S>",
    "<S> our approach is highly generalisable , capable of successfully segmenting both healthy and abnormal vertebrae ( fractured and scoliotic spines ) . </S>",
    "<S> we consistently achieve an average dice coefficient of over 90% on a publicly available dataset of the xvertseg segmentation challenge of miccai16 . </S>",
    "<S> this is particularly noteworthy because the xvertseg dataset is beset with severe deformities in the form of vertebral fractures and scoliosis . </S>"
  ]
}