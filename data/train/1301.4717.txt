{
  "article_text": [
    "consider the autonomous ordinary differential equation ( ode ) @xmath3 where @xmath4 for some @xmath5 , @xmath6 is the initial condition and @xmath7 is locally lipschitz continuous . then given a bounded set @xmath8 , there exists a @xmath9 such that for any @xmath10 the solution exists and remains bounded for @xmath11 $ ] ( see e.g. ( * ? ? ?",
    "i.7.3 on p. 37 ) ) .",
    "we assume that this ode has a conserved first integral ( also called a constant of motion ) @xmath12 such that @xmath13$}.\\ ] ] to simplify notation define @xmath14 for all @xmath15 , and assume that @xmath16 is locally lipschitz continuous .",
    "define @xmath17 .",
    "according to @xcite , on @xmath18 we may write as @xmath19 where @xmath20 is skew - symmetric ( @xmath21 ) and may be given by the so - called _ default _ formula @xmath22 in general , the choice of @xmath23 satisfying @xmath24 is not unique .",
    "moreover , proposition 2.1 in @xcite states that if @xmath25 for @xmath26 and @xmath27 is a morse function ( i.e. smooth with non - degenerate critical points ) then @xmath28 in is @xmath29 and locally bounded on @xmath18 , and in the proof of proposition 2.1 we also have that @xmath30 is locally bounded on @xmath18 .",
    "in fact , the requirement that @xmath25 for @xmath26 may be relaxed to @xmath31 locally lipschitz continuous so that @xmath28 is also only locally lipschitz continuous on @xmath18 .",
    "let us also make the assumption that @xmath27 is a morse function so that for a bounded set @xmath8 there exists a constant @xmath32 such that @xmath33 note that from continuity it follows that if @xmath34 for @xmath35 , then @xmath36 .",
    "a useful constant throughout this paper will be @xmath37 .",
    "methods for approximating the solution to this type of ode that simultaneously preserve the integral are of interest in many applications .",
    "for example , hamiltonian systems , poisson systems , celestial mechanics , the lotka - volterra system and the undamped duffing oscillator ( see @xcite and references therein ) . here we consider _ discrete gradient methods _ for approximating the solution to whilst exactly preserving @xmath27 ( see e.g. @xcite ) .",
    "let us first define a special type of discretization of the gradient of @xmath27 , a _ discrete gradient of @xmath27_.    ( gonzalez @xcite ) .",
    "a discrete gradient of @xmath27 , denoted @xmath38 , is continuous and satisfies @xmath39    there are several ways of constructing a discrete gradient .",
    "two notable examples are the one used in the averaged vector field method ( called the mean value discrete gradient in @xcite , see also @xcite ) and the coordinate increment method @xcite .    given a time step",
    "@xmath40 we define a discrete gradient method by the map @xmath41 ( the approximate solution at step @xmath42 ) and @xmath43 . ] @xmath44 where @xmath45 is a discrete gradient of @xmath27 and @xmath46 is any skew - symmetric consistent approximation of @xmath28 . by consistent we mean that @xmath47 is continuous and @xmath48 on @xmath49 .",
    "all discrete gradient methods preserve @xmath27 because @xmath50 the final equality in is because @xmath46 is skew - symmetric .    by discretizing the default formula for @xmath23 given",
    "in we obtain an example of a discrete gradient method ( there are many different possible discrete gradient methods for ) .",
    "let @xmath51 , @xmath52 and @xmath53 be consistent approximations to @xmath16 , so that they are all continuous and @xmath54 let @xmath55 be a consistent approximation of @xmath56 , and let @xmath57 be a discrete gradient of @xmath27 . then a discrete gradient method applied to",
    "is defined by with @xmath47 given by @xmath58    a useful way of describing the accuracy of a numerical method for solving is to determine its _ order of accuracy_. for one - step methods this is defined by the truncation error around the point @xmath59 for a time step @xmath40 .    a one - step method @xmath41 with time step @xmath40 for solving has order of accuracy @xmath2 , if there exist positive constants @xmath60 and @xmath61 such that @xmath62 $ and all $ x \\in b$,}\\ ] ] where @xmath63 denotes the solution to with @xmath64 for some @xmath65 and @xmath66 is a compact set in @xmath67 .",
    "the constants @xmath60 and @xmath61 may depend on @xmath66 but should be independent of @xmath59 and @xmath40 .",
    "this definition ( taken from ( * ? ? ?",
    "v.1.3 ) ) is more precise about the dependencies for the constants @xmath60 and @xmath61 than the definitions for order @xmath1 given in other texts ( e.g. ( * ? ? ?",
    "ii.1.2 ) and ( * ? ? ?",
    "ii.1.2 ) ) where it is defined by @xmath68 as @xmath69 .",
    "these other definitions are ambiguous regarding how the hidden constant in @xmath70 may depend on other parameters , and how small @xmath40 should be . by using the definition from @xcite in our results",
    "we can be sure that the constants in the definition of order @xmath1 do not depend on @xmath71 , which may be small .    throughout this paper",
    "we will also make use of banach s fixed point theorem ( also called the contraction principle ) , see e.g. ( * ? ? ?",
    "3.1.2 on p. 74 ) .",
    "[ thm banach ] let @xmath72 be a non - empty complete metric space .",
    "let @xmath73 be a contraction on @xmath74 , i.e. there exists a @xmath75 such that @xmath76 then there exists a unique fixed point @xmath77 such that @xmath78 .",
    "furthermore , the fixed point can be found by iteration , @xmath79 for @xmath80 with @xmath81 arbitrary .    in section",
    "[ sec exist ] we prove that discrete gradient methods where @xmath46 has the form are well - defined in the sense that provided @xmath40 is sufficiently small and @xmath82 , @xmath83 , @xmath84 , @xmath85 and @xmath45 satisfy certain consistency and local lipschitz continuity conditions , then there exists a locally unique solution to . in section [ sec error ]",
    "we prove that for arbitrarily chosen @xmath2 , if @xmath82 , @xmath83 , @xmath84 , @xmath85 and @xmath45 satisfy two additional conditions ( @xmath82 defines a method of order @xmath1 and @xmath86 is bounded in a special way ) then we get a discrete gradient method of order @xmath1 .    in section",
    "[ sec modified ] we consider discrete gradient methods from the perspective of doing computations .",
    "generally , each step of a discrete gradient method requires solving a nonlinear system of equations for @xmath87 and this may add a significant amount to the computational cost of the method because an iterative scheme , such as newton s method , must be employed at each step . in the case when @xmath27 is quadratic we present a new method that is linearly implicit in @xmath87 at each time step , so only a linear system of equations must be solved at each step .",
    "we also show that runge - kutta methods , under very mild conditions on the coefficients , give an @xmath82 that satisfies the conditions required in sections [ sec exist ] and [ sec error ] , and therefore we may use runge - kutta methods of order @xmath1 ( for some @xmath2 ) to construct discrete gradient methods of order @xmath1 .",
    "following the theory in these sections we present a numerical example in section [ sec examples ] to illustrate our theory , and finally , in section [ sec conclusion ] we discuss the implications of this work and possible avenues for future research .",
    "at each time step of the discrete gradient method we must ( in general ) solve a nonlinear system of equations ( see ) for @xmath87 , but does the solution to this system of equations exist ?",
    "in this section we present a theorem that ensures for sufficiently small time step @xmath40 , the map from @xmath41 is well - defined in the sense that there exists a locally unique solution @xmath87 to the system of equations for the case when @xmath46 is given by .",
    "usual techniques for achieving this type of result include applying the implicit function theorem ( see @xcite ) or the newton - kantorovich theorem ( see @xcite ) . for example , the newton - kantorovich theorem is used in @xcite to obtain existence of a numerical solution for a symmetric projection method , which requires solving a nonlinear system of equations at each time step . in our experience these approaches for discrete gradient methods lead to a condition on the time step such as @xmath88 for some positive constants @xmath60 and @xmath89 .",
    "if we are close to a critical point of @xmath27 ( i.e. when @xmath71 is small ) then the theory implies that we must also take @xmath40 small .",
    "our result and its proof below avoid this issue and we show that a solution to the nonlinear system of equations for a discrete gradient method ( with @xmath46 defined by ) exists and is locally unique for a sufficiently small time step independent of @xmath71 ( and hence independent of the distance to critical points of @xmath27 ) .    the local nature of our result ( everything will depend on an initially chosen bounded set @xmath66 ) is only due to the local lipschitz continuity of @xmath31 and @xmath90 , and , rather than also depending on the distance to critical points of @xmath27",
    ".    we will require the following definition of a ball around a point @xmath91 .",
    "given a constant @xmath92 and @xmath91 define @xmath93 note that if @xmath94 , then @xmath95 .",
    "the following theorem ensures that , for sufficiently small @xmath40 and under certain local lipschitz conditions , the map @xmath41 defined by and is locally well - defined , in the sense that there exists a locally unique solution to the nonlinear system of equations defined by and .",
    "[ thm exist ] let @xmath66 be a bounded set in @xmath67 and suppose there exist positive constants @xmath96 , @xmath97 and @xmath61 such that for each @xmath35 and all @xmath98 and @xmath99 , @xmath100 satisfies @xmath101 @xmath38 is a discrete gradient of @xmath27 satisfying @xmath102 @xmath103 satisfies @xmath104 and similarly for @xmath105 and @xmath106 .",
    "let @xmath107 be the constant defined after and define @xmath108 then for each @xmath35 and @xmath109 there exists a unique @xmath110 satisfying where @xmath46 is given by the formula .",
    "note that if @xmath35 and @xmath34 then @xmath111 is the unique solution to in @xmath112 .",
    "for the case when @xmath113 we will apply banach s fixed point theorem ( theorem [ thm banach ] ) to prove our result .",
    "let @xmath114 and @xmath115 be defined as in the theorem and for fixed @xmath35 , such that @xmath113 , define @xmath116 .",
    "@xmath74 is a closed subset of @xmath67 , so together with the metric @xmath117 , it is a complete metric space .",
    "also fix @xmath118 , and define @xmath119 by @xmath120 where @xmath46 is given by . to satisfy the assumptions of theorem [ thm banach ] we must show that @xmath121 for all @xmath122 and that @xmath123 is a contraction on @xmath124 .    let @xmath122 . using , @xmath125 ( since @xmath126 ) , @xmath127 and @xmath128 we have @xmath129 we can derive similar inequalities for @xmath84 and @xmath85 , and for @xmath45 we can derive @xmath130 using , , @xmath131 , @xmath127 and @xmath128 we also get @xmath132 using and for @xmath84 and @xmath85 , @xmath133 , @xmath127 , @xmath128 and writing @xmath90 instead of @xmath16 we get @xmath134   \\cdot { \\breve{i}}(x , z , h ) \\\\      & + i \\cdot [ ( { \\breve{i}}(x , z , h ) - { \\breve{i}}(x , x , h ) ) + ( { \\breve{i}}(x , x , h ) - { \\breve{i}}(x , x,0 ) ) ] \\\\",
    "\\geq & |i|^2 -   ( { { \\textstyle \\frac{{l}|i|}{r ' } } } + { l}h |i| ) { { \\textstyle \\frac{6}{5 } } } |i|      - |i| ( { { \\textstyle \\frac{{l}|i|}{r ' } } } + { l}h |i|)\\\\      \\geq & |i|^2 -   { { \\textstyle \\frac{2}{10 } } } \\cdot { { \\textstyle \\frac{6}{5 } } } |i|^2 - { { \\textstyle \\frac{2}{10 } } } |i|^2",
    "= { { \\textstyle \\frac{28}{50 } } } |i|^2       > { { \\textstyle \\frac{1}{2 } } } |i|^2 .",
    "\\end{split}\\ ] ] we get @xmath121 from the following inequality , where we have used , , , and @xmath135 to get @xmath136    to show @xmath123 is a contraction , let @xmath137 . using , and for @xmath84 and @xmath85 , and writing @xmath138 as @xmath139 etc .",
    "we get @xmath140 using , , , , , , and we get @xmath141 \\cdot { \\bar{i}}(z ) { \\tilde{f}}(z)}{{\\hat{i}}(z)\\cdot{\\breve{i}}(z ) } } } \\right|        + \\left| { { \\textstyle \\frac{{\\tilde{i}}(z ' ) \\cdot [ { \\bar{i}}(z ) - { \\bar{i}}(z ' ) ] { \\tilde{f}}(z)}{{\\hat{i}}(z)\\cdot{\\breve{i}}(z ) } } } \\right| \\\\       & + \\left| { { \\textstyle \\frac{{\\tilde{i}}(z')\\cdot{\\bar{i}}(z ' ) [ { \\tilde{f}}(z ) - { \\tilde{f}}(z ' ) ] } { { \\hat{i}}(z)\\cdot{\\breve{i}}(z ) } } } \\right| \\\\      & + \\left| \\left ( { { \\textstyle \\frac{1}{{\\hat{i}}(z)\\cdot { \\breve{i}}(z ) } } } - { { \\textstyle \\frac{1}{{\\hat{i}}(z')\\cdot{\\breve{i}}(z ' ) } } } \\right ) { \\scriptstyle { \\tilde{i}}(z')\\cdot{\\bar{i}}(z ' ) { \\tilde{f}}(z ' ) } \\right| \\\\",
    "\\leq & { \\scriptstyle \\frac{2}{|i(x)|^2 } } \\bigl ( { \\scriptstyle { l}|z - z'| \\frac{11}{10 } |i(x)| c_2 |i(x)|   + \\frac{6}{5 } |i(x)| { l}|z - z'| c_2 |i(x)| } \\\\      & { \\scriptstyle+ \\frac{6}{5}|i(x)| \\frac{11}{10 } |i(x)| { l}|z - z'| } \\bigr )       { \\scriptstyle + \\frac{10 { l}}{|i(x)|^3 } |z - z'| \\frac{6}{5 } |i(x)| \\frac{11}{10 } |i(x)| c_2|i(x)| } \\\\      = & \\left ( { { \\textstyle \\frac{89}{5 } } } c_2 + { { \\textstyle \\frac{66}{25 } } } \\right ) { l}|z - z'|   \\\\      \\leq & \\left ( 18c_2 + 3 \\right){l}|z - z'| .",
    "\\end{split}\\ ] ] using a similar argument we can also derive @xmath142 now using , and @xmath143 we get @xmath144 where @xmath145 . therefore , @xmath123 is a contraction on @xmath124 and by theorem [ thm banach ] there exists a unique @xmath146 such that @xmath147 . by the definition of @xmath123 it follows that @xmath87 satisfies where @xmath46 is given by",
    "in this section we give sufficient conditions for a discrete gradient method defined by and to be of order @xmath1 for arbitrarily chosen @xmath2 .",
    "in addition to requiring the same conditions as in theorem [ thm exist ] , we also require two further conditions .    the following two lemmas will be used to prove our main result , theorem [ thm error2 ] .    [ lem exist f ] for a bounded set @xmath8 , let @xmath148 and @xmath115 be defined as in theorem [ thm exist ] .",
    "then , for each fixed @xmath35 and @xmath109 there exists a unique @xmath149 such that @xmath150    fix @xmath35 and @xmath109 , and define @xmath151 and @xmath152 for each @xmath122 . for @xmath122 use and @xmath153 to get @xmath154 so @xmath121 . for @xmath155 , use and @xmath128 to get @xmath156",
    "hence @xmath157 is a contraction and the result follows by applying theorem [ thm banach ] . for the case when @xmath94 note that @xmath158 for @xmath159 ( use and @xmath160 ) .",
    "[ lem 1 ] in addition to the hypotheses of theorem [ thm exist ] suppose that for each @xmath35 and all @xmath161 , @xmath31 satisfies @xmath162 let @xmath63 denote the exact solution to with @xmath64 for some @xmath65 and @xmath109 , then @xmath163 exists and satisfies @xmath164 for all @xmath165 $ ] .    if @xmath34 then ( by ) we are at a stationary point and the result is trivial .",
    "suppose @xmath113 .",
    "existence theory for odes ( see e.g. ( * ? ? ?",
    "i.7.3 on p. 37 ) ) implies there exists a @xmath166 such that @xmath164 for all @xmath167 $ ] .",
    "if @xmath168 then we are done , so suppose @xmath169 .",
    "existence theory also implies that the solution @xmath163 exists for @xmath170 $ ] for some @xmath171 , even though it may not be in @xmath172 .",
    "for each @xmath167 $ ] we have @xmath173 so by the gronwall inequality ( see e.g. ( * ? ? ?",
    "1.1 on p. 24 ) ) , , @xmath143 and @xmath113 we have @xmath174 therefore , for each @xmath167 $ ] , @xmath175 since this inequality is strict and @xmath63 exists up to @xmath176 and is continuous , there exists an @xmath177 such that @xmath178 for all @xmath179 $ ] .    to complete the proof",
    "let us argue by contradiction .",
    "suppose there exists a @xmath180 $ ] such that @xmath181 ( this includes the case when @xmath182 does not exist ) . then by continuity of @xmath63 , @xmath64 and",
    "since @xmath172 is closed , there exists a @xmath183 and a @xmath184 such that @xmath178 for all @xmath185 $ ] and @xmath186 for all @xmath187 .",
    "however , by the above argument there exists an @xmath177 such that @xmath178 for all @xmath188 . a contradiction .",
    "therefore , @xmath164 for all @xmath165 $ ] .    the extra lipschitz continuity condition on @xmath31 in lemma [ lem 1 ] follows from our earlier assumption that @xmath31 is locally lipschitz .",
    "now let us present the main theorem of this section , where we show that under certain conditions the discrete gradient method defined by and is of order @xmath1 , for some @xmath2 .",
    "[ thm error2 ] for a compact set @xmath8 , let @xmath96 , @xmath189 , @xmath61 , @xmath82 , @xmath45 , @xmath83 , @xmath84 @xmath85 , @xmath107 , @xmath114 and @xmath115 be defined as in theorem [ thm exist ] and let @xmath31 satisfy the lipschitz condition in lemma [ lem 1 ] .    for each @xmath35 and @xmath109    1 .",
    "let @xmath110 be the unique solution to with @xmath46 defined by ( which exists by theorem [ thm exist ] ) , 2 .",
    "let @xmath149 be the unique solution to ( which exists by lemma [ lem exist f ] ) , and 3 .",
    "let @xmath63 denote the exact solution to satisfying @xmath64 for some @xmath65 ( which exists on @xmath190 $ ] by lemma [ lem 1 ] )",
    ".    also suppose that    1 .",
    "@xmath82 is such that the method defined by is of order @xmath1 for some @xmath2 , i.e. there exist positive constants @xmath191 and @xmath192 such that @xmath193 $ and all $ x \\in b$,}\\ ] ] and 2 .",
    "there exists a positive constant @xmath194 such that for each @xmath35 and all @xmath195 $ ] , @xmath196    then the discrete gradient method defined by with @xmath46 given by is also of order @xmath1 , so that there exist positive constants @xmath197 and @xmath198 such that @xmath199 $ and all $ x \\in b$.}\\ ] ]    define @xmath200 and @xmath201 .",
    "fix @xmath35 and @xmath202 $ ] .",
    "the first step in the proof is to bound @xmath203 .",
    "we get @xmath204|   \\\\      & + | h [ { \\tilde{f}}(x , x',h ) - { \\tilde{f}}(x , y , h ) ] \\cdot { \\bar{i}}(x , x ' ) | \\\\",
    "= : & t_1 + t_2 + t_3 . \\end{split}\\ ] ] now bound each @xmath205 separately . using @xmath206 , and ( with @xmath207 )",
    "we get @xmath208 using ( with @xmath209 ) , and @xmath210 we get @xmath211| \\\\",
    "\\leq & h c_2 |i(x)| l |x ' - x(t+h)| \\\\",
    "\\leq & { { \\textstyle \\frac{1}{36 } } } |i(x)| |x ' - x(t+h)| .",
    "\\end{split}\\ ] ] and using , ( with @xmath212 ) and @xmath213 we get @xmath214 \\cdot { \\bar{i}}(x , x ' ) | \\\\      & \\leq h l |x'-y| { { \\textstyle \\frac{11}{10 } } } |i(x)| \\\\      & \\leq { { \\textstyle \\frac{11}{100 } } } |i(x)| |x'-y| .",
    "\\end{split}\\ ] ] putting together with , and we get @xmath215 .",
    "we get @xmath216 now bound @xmath217 and @xmath218 separately .",
    "using , , , , ( with @xmath212 and @xmath219 ) , and @xmath220 we get @xmath221 and using ( with @xmath222 ) , and we get @xmath223 putting together with and we get @xmath224 and hence @xmath225 our result now follows easily from and since @xmath226 : @xmath227 therefore , @xmath228",
    "in this section we consider discrete gradient methods that may be used in computations , and how we might choose @xmath82 , @xmath83 , @xmath45 , @xmath84 and @xmath85 so that they satisfy the hypotheses of theorems [ thm exist ] and [ thm error2 ] . we also consider how to make the nonlinear system of equations defined by and as easy as possible to solve at each time step . in the case when @xmath27 is quadratic we achieve this by constructing a discrete gradient method so that it is linearly implicit in @xmath87 . in general",
    "this is not possible , except in the case when @xmath27 is quadratic .",
    "since @xmath56 and @xmath16 are locally lipschitz continuous , for a given bounded set @xmath8 and constant @xmath229 there exists a constant @xmath230 such that for all @xmath35 and for all @xmath231 @xmath232    a possible choice for @xmath82 is so that the method defined by is a runge - kutta method . the following definition of a runge - kutta method has been modified from @xcite for the case of autonomous odes .",
    "let @xmath233 , @xmath234 @xmath235 be real numbers and let @xmath236 be the time step .",
    "one step of an _",
    "@xmath237-stage runge - kutta method _ defining a map @xmath41 for approximating the solution to is defined by @xmath238    for @xmath82 in to correspond to an @xmath237-stage runge - kutta method then we must define @xmath239 where the @xmath240 are ( implicitly ) defined by . even though the @xmath240 may be implicitly defined by , as for implicit runge - kutta methods",
    ", we may use the map @xmath241 ( defined below in lemma [ lem rk exist ] ) to explicitly represent each @xmath240 in terms of @xmath59 and @xmath40 as the @xmath242 column of @xmath243 .",
    "since the @xmath240 do not depend on @xmath87 we get a @xmath82 that does not depend on @xmath87 and we may write @xmath244 instead of @xmath245 .    for a given @xmath237-stage runge - kutta method two constants that will be useful are @xmath246    for completeness , the following lemma gives conditions on @xmath40 so that an @xmath237-stage runge - kutta method is well - defined in the sense that the map @xmath247 is locally well - defined ( so that the map @xmath41 is also locally well - defined ) . although it is a bespoke result for this paper , the proof is very similar to that given for ( * ? ? ?",
    "ii.7.2 ) .",
    "[ lem rk exist ] let @xmath8 be a bounded set and let @xmath248 be a constant .",
    "let @xmath249 be the constant from , and let @xmath250 be the constant from .",
    "define @xmath251 then for each @xmath35 , @xmath99 and @xmath252 there exists a unique @xmath253 \\in \\lbrace [ m_1 m_2 \\dotsi m_s ] \\in { \\mathbb{r}}^{d\\times s } : |m_i - f(x ) | \\leq { { \\textstyle \\frac{l_0|i(x)|}{r_0 } } } \\rbrace$ ] satisfying @xmath254 let us define a map @xmath241 such that @xmath255 .",
    "we again apply banach s fixed point theorem ( theorem [ thm banach ] ) .",
    "fix @xmath256 , @xmath99 and @xmath252 . for",
    "@xmath253 \\in { \\mathbb{r}}^{d \\times s}$ ] let @xmath257 and define @xmath258 \\in { \\mathbb{r}}^{d\\times s } : | m_i - f(x ) | \\leq { { \\textstyle \\frac{l_0|i(x)|}{r_0 } } } \\rbrace$ ] and @xmath259 by @xmath260 \\qquad \\mbox{where } \\qquad l_i : = f\\left ( u + h \\sum_{j=1}^s a_{ij } k_j \\right)\\ ] ] for each @xmath253 \\in x$ ] . to apply theorem [ thm banach ]",
    "we must show that @xmath261 for all @xmath262 , and that @xmath73 is a contraction .",
    "let @xmath253 , k ' = [ k_1 ' k_2 ' \\dotsi k_s ' ] \\in x$ ] , @xmath263 $ ] and @xmath264 $ ] .",
    "first note that by the definition of @xmath74 and using we have @xmath265 using this , and since @xmath266 and @xmath252 , we have @xmath267 hence @xmath268 . using and",
    "we then get @xmath269 hence @xmath261 . by",
    "we also have @xmath270 so @xmath271 .",
    "since @xmath272 , @xmath157 is a contraction and the result then follows by applying theorem [ thm banach ] .",
    "the following lemma is a technical result for the subsequent corollary .",
    "[ lem tff ] let @xmath273 be defined by , where the @xmath240 are defined by an @xmath237-stage runge - kutta method with @xmath274 .",
    "let @xmath8 be a bounded set and @xmath275 a constant .",
    "let @xmath249 be the constant from and @xmath250 be the constant from .",
    "then @xmath276 for every @xmath35 , and there exist positive constants @xmath96 , @xmath189 and @xmath61 such that for each @xmath35 , and for all @xmath277 and @xmath278 @xmath279    define @xmath280 , @xmath281 and @xmath282 and fix @xmath35 . if @xmath283 , then @xmath284 for all @xmath90 , and using @xmath274 we get @xmath285 .    for @xmath286 and @xmath277",
    ", we have from lemma [ lem rk exist ] that there exist unique @xmath287 and @xmath288 in @xmath289 \\in { \\mathbb{r}}^{d\\times s } : | m_i - f(x ) | \\leq { { \\textstyle \\frac{l_0|i(x)|}{r_0 } } } \\rbrace$ ] satisfying . using , and @xmath290 , we have @xmath291 hence , @xmath292 . using this , and",
    "@xmath293 we get @xmath294 finally , using , @xmath274 , , and writing @xmath295 for the @xmath242 column of @xmath243 , @xmath296    all consistent runge - kutta methods ( so that @xmath274 ) define a @xmath82 ( see ) that satisfies condition in theorem [ thm exist ] .",
    "if we define @xmath82 corresponding to an explicit @xmath237-stage runge - kutta method ( where @xmath297 for @xmath298 ) , then the @xmath240 in are defined explicitly in terms of @xmath59 and @xmath40 and @xmath273 may be calculated explicitly ( instead of using the map @xmath299 which may not be computed explicitly ) . to obtain a runge - kutta method that is of order @xmath1",
    "there are additional constraints on the @xmath234 and @xmath233 ( e.g. see @xcite ) .    to check whether or not @xmath300 satisfies we only need to ensure that it is locally lipschitz continuous since @xmath301 is already satisfied by the definition of a discrete gradient .",
    "moreover , since @xmath16 is locally lipschitz , it easily follows that both the coordinate increment discrete gradient ( see @xcite ) and the one used in the average vector field method ( see e.g. @xcite ) are also locally lipschitz . for general @xmath27",
    "there are no known explicitly defined discrete gradients . however",
    ", if @xmath27 is quadratic then @xmath16 is linear and we may define @xmath57 so that it is linear in @xmath87 by taking @xmath302    there is considerable freedom over how we choose @xmath83 , @xmath84 and @xmath85 in , and to apply theorems [ thm exist ] and [ thm error2 ] they only need to satisfy and . for example , we may define @xmath83 to be any of the following ( and similarly for @xmath84 and @xmath85 ) : @xmath303 except for the final case when @xmath304 , it is obvious that all of these choices for @xmath83 satisfy since @xmath16 is locally lipschitz . to confirm that @xmath304 satisfies we prove the following two lemmas .",
    "[ lem exist f2 ] let @xmath8 be a bounded set and suppose there exist positive constants @xmath96 , @xmath189 and @xmath61 such that for each @xmath35 , and for all @xmath305 and @xmath99 , @xmath306 satisfies . let @xmath250 be the constant from .",
    "then for each @xmath35 , @xmath307 and @xmath308 there exists a unique @xmath309 satisfying @xmath310 moreover , if @xmath311 then @xmath312 .",
    "fix @xmath35 , @xmath307 and @xmath308 .",
    "define @xmath313 and @xmath314 by @xmath315 for each @xmath122 .",
    "let @xmath316 .",
    "using , , @xmath307 , @xmath317 and @xmath318 we get @xmath319 so @xmath121 . from",
    "we also get @xmath320 .",
    "since @xmath321 , @xmath322 is a contraction and the first part of the result then follows by applying theorem [ thm banach ] .    if @xmath323 then repeating this argument with @xmath324 yields @xmath312 .",
    "[ lem tii ] let @xmath8 be a bounded set and let @xmath325 be a positive constant .",
    "let @xmath249 be the constant from , and let @xmath250 be the constant from .",
    "suppose there exist positive constants @xmath96 , @xmath189 and @xmath61 such that for each @xmath35 , and all @xmath305 and @xmath99 that @xmath306 satisfies . define @xmath326 , @xmath327 , @xmath328 and @xmath329 such that @xmath330 for all @xmath35 , @xmath331 and @xmath332",
    ".    then for each @xmath35 , and for all @xmath333 and @xmath332 , @xmath83 satisfies @xmath334    fix @xmath35 , @xmath333 and @xmath332 .",
    "let @xmath335 denote the solution to @xmath336 , and similarly for @xmath337 and @xmath338 . from lemma",
    "[ lem exist f2 ] we know these solutions exist and that @xmath339 and @xmath340 .    if @xmath283 then @xmath341 and @xmath342 .",
    "if @xmath343 , since @xmath344 , we may use and @xmath345 to get @xmath346 and so @xmath347 . using this and we get @xmath348 using , , , @xmath339 and @xmath349 we also get @xmath350    in theorem [ thm error2 ]",
    "we also require that @xmath83 , @xmath45 , @xmath84 and @xmath85 satisfy condition . by taking @xmath351 and @xmath352",
    "then this is achieved trivially , and the resulting method is equivalent to a projection method ( see @xcite ) .",
    "unfortunately , in this case the system of equations to solve at each time step is nonlinear in general .",
    "a method that is almost a projection method is the following .",
    "for general @xmath83 , @xmath45 and @xmath82 satisfying the conditions in theorem [ thm exist ] and theorem [ thm error2 ] , define @xmath351 and @xmath353 where @xmath354 satisfies @xmath336 .",
    "the following two lemmas ensure that @xmath85 satisfies and @xmath83 , @xmath45 , @xmath84 and @xmath85 satisfy .",
    "[ lem brii ] let @xmath8 be a bounded set and let @xmath250 be the constant from .",
    "suppose there exist positive constants @xmath96 , @xmath189 and @xmath61 such that for each @xmath35 , and all @xmath305 and @xmath99 that @xmath306 satisfies , and @xmath38 is a discrete gradient of @xmath27 satisfying . define @xmath326 , @xmath355 and @xmath356 , and also define @xmath357 such that @xmath358 for all @xmath35 , @xmath331 and @xmath332",
    ".    then for each @xmath35 , and for all @xmath333 and @xmath332 , @xmath85 satisfies @xmath359    the proof of this result is very similar to the proof of lemma [ lem tii ] so we omit it .",
    "[ lem brii2 ]",
    "let @xmath8 be a compact set and suppose that @xmath360 and @xmath45 all satisfy the conditions of theorem [ thm exist ] .",
    "define @xmath361 .",
    "define @xmath362 , @xmath363 , @xmath364 and @xmath85 as in lemma [ lem brii ] , and define @xmath365    then @xmath82 , @xmath83 , @xmath45 , @xmath84 , @xmath85 @xmath366 and @xmath367 satisfy the conditions in theorem [ thm exist ] with @xmath96 , @xmath189 , @xmath61 , @xmath114 and @xmath115 replaced by @xmath362 , @xmath363 , @xmath364 , @xmath366 and @xmath367 respectively .    moreover , for each @xmath35 and @xmath368    1 .",
    "let @xmath369 be the unique solution to ( that exists by lemma [ lem exist f ] ) , 2 .",
    "let @xmath370 be the unique solution to with @xmath46 defined by ( that exists by theorem [ thm exist ] ) , and 3 .",
    "let @xmath63 denote the exact solution to satisfying @xmath371 for some @xmath65",
    ".    also suppose that    1 .",
    "@xmath82 is such that the method defined by is of order @xmath1 for some @xmath2 , i.e. there exist constants @xmath191 and @xmath372 such that @xmath373 $ and all $ x \\in b$}.\\ ] ]    if we define @xmath374 , then @xmath83 , @xmath45 , @xmath84 and @xmath85 satisfy .",
    "the fact that @xmath82 , @xmath83 , @xmath45 , @xmath84 , @xmath85 @xmath366 and @xmath367 satisfy the conditions in theorem [ thm exist ] with @xmath96 , @xmath189 , @xmath61 , @xmath114 and @xmath115 replaced by @xmath362 , @xmath363 , @xmath364 , @xmath366 and @xmath367 respectively , follows from @xmath375 , @xmath376 and @xmath377 .    using and ( with @xmath189 replaced by @xmath363 ) we get @xmath378| \\\\      & \\leq { { \\textstyle \\frac{6}{5 } } } |i(x)| l_1 |x'-y| \\\\      & \\leq { { \\textstyle \\frac{6l_1}{5 } } } |i(x)| ( |x ' \\!-\\ ! x(t+h)| + |y \\!-\\ !",
    "x(t+h)| ) \\\\      & \\leq { { \\textstyle \\frac{6l_1}{5 } } } \\left (   |x'-x(t+h)| + c_3 h^{p+1 } \\right ) |i(x)| \\\\      & \\leq c_4 \\left (   |x'-x(t+h)| + h^{p+1 } \\right ) |i(x)|.\\end{aligned}\\ ] ]    this lemma leads to the following obvious corollary of theorem [ thm error2 ] .    with the same hypotheses as lemma [ lem brii2 ] , then the discrete gradient method defined by and is of order @xmath1 .",
    "if @xmath27 is quadratic then using to define @xmath45 and an explicit @xmath237-stage runge - kutta method to define @xmath82 we can construct a linearly implicit discrete gradient method . the following corollary is a direct consequence of , lemmas [ lem tff ] , [ lem exist f2 ] , [ lem brii ] and [ lem brii2 ] and theorems [ thm exist ] and [ thm error2 ] .",
    "[ cor 1 ] suppose @xmath27 is quadratic and let @xmath82 correspond to an explicit @xmath237-stage runge - kutta method of order @xmath1 , for some @xmath2 .",
    "then the discrete gradient method defined by @xmath379 where @xmath380 is linearly implicit in @xmath87 , locally well - defined ( in the sense that for sufficiently small @xmath40 there exists a locally unique @xmath87 at each time step ) and of order @xmath1 .",
    "in this section we experiment with using the new linearly implicit ( when @xmath27 is quadratic ) discrete gradient method constructed in corollary [ cor 1 ] .",
    "to demonstrate the efficiency gain due to only needing to solve a linear system at each time step we will compare it with the standard projection method from @xcite on a problem with quadratic @xmath27 .",
    "the new discrete gradient method we suggested in corollary [ cor 1 ] for the case when @xmath27 is quadratic corresponds to defining @xmath381 , @xmath382 and @xmath383 where @xmath384 satisfies @xmath385 and @xmath82 is defined by an explicit @xmath237-stage runge - kutta method . with these choices for @xmath82 ,",
    "@xmath83 , @xmath45 , @xmath84 and @xmath85 then the discrete gradient method defined by and becomes the one defined in corollary [ cor 1 ] .",
    "in our experiments below we use the classical explicit @xmath386 order runge - kutta ( rk4 ) method to define @xmath82 .",
    "it is defined by the butcher tableau ( see e.g. @xcite ) : @xmath387 the entries denoted by @xmath388 are not required because we are only considering autonomous odes .",
    "since @xmath27 is quadratic , @xmath16 is linear and there exists a matrix @xmath389 and a vector @xmath390 such that @xmath391 for all @xmath91 . in the case when @xmath113 , to obtain @xmath87 at each time step of the method in corollary [ cor 1 ] , we must solve the linear system @xmath392 where @xmath393 is the identity matrix .",
    "note that the cost of computing @xmath273 at each time step is essentially the same as the cost for computing the rk4 method , so we already know that computing this new discrete gradient method will cost more than the rk4 method .    to compare this new linearly implicit discrete gradient method with another integral preserving method we also consider the standard projection method ( see algorithm iv.4.2 in @xcite ) with rk4 as the underlying method .",
    "the algorithm is : @xmath394 actually , step @xmath395 above is what is suggested in equation ( 4.5 ) of @xcite , after algorithm iv.4.2 , as a more convenient nonlinear system to solve ( by reducing the number of evaluations of @xmath396 required ) . to solve the nonlinear system in step @xmath395 hairer , lubich and wanner use the following simplified newton iteration ( see @xcite for details )",
    "@xmath397 once this iterative scheme has converged to @xmath398 then @xmath87 is computed using @xmath399 .      in the following example",
    "we will compare the performance of our new discrete gradient method with the rk4 method and another integral preserving method , the standard projection method ( all described above ) .",
    "we first demonstrate the benefits of preserving the integral by inspecting phase space plots for the rk4 method and our new discrete gradient method .",
    "we will see that the integral preserving method does a much better job of following the trajectory of the exact solution .",
    "to compare the errors we include all three methods .",
    "we will see that the errors for all three methods are of similar size , that all three methods are of the same order , and that our new discrete gradient method is more efficient than the standard projection method .",
    "the example we use for our computations is a modification to the equations for rigid body motion in three dimensions ( see e.g. example 1.7 in @xcite ) . for a parameter @xmath400 ,",
    "the augmented equations of motion for a body with centre of mass at the origin are @xmath401 = \\left [ { \\begin{array}{ccc } 0 & -x_3 & x_2 - \\alpha x_1 ^ 2 \\\\ x_3 & 0 & -x_1 \\\\ -x_2 + \\alpha x_1 ^ 2 & x_1 & 0 \\end{array } } \\right ]   \\left [ { \\begin{array}{c } x_1/i_1 \\\\ x_2/i_2 \\\\ x_3/i_3 \\end{array } } \\right],\\ ] ] where @xmath402 , @xmath403 and @xmath404 are also parameters . in the case when @xmath405 this system reduces to the equations for rigid body motion where the vector @xmath406 is the angular momentum in the body frame and the @xmath407 parameters are the principal moments of inertia . moreover , when @xmath405 there are two quadratic first integrals , but in the general case when @xmath408 then the only first integral is , @xmath409 notice that has the form of .    in our computations",
    "we have taken @xmath410 , @xmath411 , @xmath412 , @xmath413 and we have used the initial condition @xmath414 at @xmath415 . except for @xmath416 ,",
    "these are the same values used in @xcite .    in figure [ fig1 ]",
    "we see that phase space , projected onto the @xmath417-plane , is more accurately represented when we compute the solution using our new discrete gradient method instead of the rk4 method . here",
    "we have used two different time steps ( @xmath418 and @xmath419 ) and computed up to a final time of @xmath420 . in the plots ,",
    "the solid grey line is the exact solution and the black dots are the approximate solution at each time step using either rk4 or our new discrete gradient method . for the larger step size of @xmath419",
    "the rk4 method appears to converge to equilibrium which is the wrong type of asymptotic behaviour . for our new discrete gradient method , while the errors are clearly quite large for this larger step size , the solution appears to be circulating around a periodic orbit which is the correct asymptotic behaviour for this example .",
    "another possibility with the rk4 method ( not observed in this example ) is that the solution will blow up at some critical time ( for example with @xmath421 , @xmath422 at @xmath423 ) .",
    "this can not happen for integral preserving methods such as our new discrete gradient method .    in figures [ fig2 ] and [ fig3 ]",
    "we compare the errors for the three different methods : rk4 , the standard projection method , and our new discrete gradient method . in figure [ fig2 ]",
    "we have plotted the solution error and integral error versus time for the three different methods .",
    "we see that the solution error is initially similar for all three methods , it grows as time increases , and then remains bounded .",
    "the integral error plot clearly shows that the integral preserving methods preserve the integral up to double machine precision and are vastly superior in terms of preserving the integral than the non - integral preserving rk4 method .",
    "these computations used a fixed time step of @xmath418 for all three methods and computations were performed up to a final time of @xmath420 .    in figure [ fig3 ]",
    "we compare the performance of the same three methods for different step sizes .",
    "we are interested to see whether or not our new discrete gradient method is of the same order as rk4 ( order 4 ) , and to compare the efficiency of our new discrete gradient method with another integral preserving method , the standard projection method , where a nonlinear system of equations must be solved at each time step . by plotting the solution error at time @xmath424 for different step sizes ( @xmath425 $ ] ) in the left plot of figure [ fig3 ] ,",
    "we confirm that our new discrete gradient method is of order @xmath426 , the same as rk4 which is the underlying method defining @xmath82 . in the right plot of figure [ fig3 ] for the same range of step sizes",
    "we have plotted the solution error at @xmath424 against the cpu time required to compute the solution up to @xmath424 . in this way",
    "we can compare the efficiency of these methods .",
    "the plot clearly shows that our new discrete gradient method is more efficient than the standard projection method for this problem because it yields smaller errors using less computational effort .",
    "the plot also shows that the rk4 method is more efficient again .",
    "since both integral preserving methods effectively compute the rk4 approximation within their methods the computational cost required by these methods is more than rk4 .",
    "moreover , in the left plot of figure [ fig3 ] we saw that the size of the error for all three methods is similar .",
    "for these reasons rk4 is the most efficient method , however , rk4 does not preserve the integral and over longer time intervals it often has the wrong asymptotic behaviour .    also notice in figure [ fig3 ] ( right ) that the difference in efficiency between our new discrete gradient method and the standard projection method is more pronounced for larger time steps .",
    "this is probably due to the fact that the initial guess ( the rk4 solution ) in the newton iteration for calculating the projection step in the standard projection method is more accurate for smaller time steps , resulting in fewer iterations until the convergence test is satisfied .",
    "a key feature of the existence and order of accuracy results in this paper is the fact that we may take @xmath59 as close as we like to a critical point of @xmath27 without any additional constraints on the time step . by considering different @xmath59 values , and computing a single time step to get @xmath87 for different time steps we can show that this feature of our results is illustrated in the modified rigid body motion example . as criteria for a valid time step we consider the denominator of @xmath46 ( which should be positive ) and the condition number ( ratio between the largest and smallest eigenvalues ) of the matrix @xmath427 ( see ) .",
    "the initial points we consider are @xmath428 for @xmath429",
    "( this is the initial condition used in our earlier simulations and is far away from a critical point of @xmath27 ) , respectively @xmath430 and @xmath431 ( which is near to the critical point @xmath432 of @xmath27 ) .    in figure [ fig4 ] we have plotted condition number of @xmath427 , the denominator of @xmath46 and the error after a single time step vs. time step , for different starting @xmath59 ( @xmath433 , @xmath430 and @xmath431 ) .",
    "we see that as the time step is increased there seem to be critical values where the condition number blows up , the denominator veers down to zero , and the error no longer behaves with the same asymptotic behaviour with respect to the time step .",
    "we see that for @xmath59 close to the critical point the largest allowable time step actually increases .",
    "this is consistent with our theory .",
    "in this paper we have analysed discrete gradient methods from first principles .",
    "we have established the bare essentials in terms of local lipschitz continuity conditions and other criteria to ensure that these types of methods are locally well - defined and are of order @xmath1 .",
    "a key feature of our analysis is that we have removed any dependence of the time step on the distance to critical points of the preserved integral and all of the constants in our results are independent of @xmath71 .",
    "although we have been careful to trace the value of constants through our proofs we do not make the claim that our constants are optimal .",
    "the reasons for this are that we have assumed that the same constants @xmath96 and @xmath189 can be used in all of the inequalities in , and , and to simplify the presentation we sometimes used inequalities that were not completely sharp .",
    "if we had more precise knowledge of the optimal constants for which , , , , and hold , then we could repeat the arguments in the proofs of theorems [ thm exist ] and [ thm error2 ] to obtain better constants @xmath114 and @xmath115 in theorem [ thm exist ] , and @xmath197 and @xmath198 in theorem [ thm error2 ] .    as well as considering theoretical conditions for these methods",
    "we also developed results that will be useful for users of these methods for solving odes .",
    "we have shown how runge - kutta methods can easily be used inside the framework of discrete gradient methods and we have also developed a new method that is linearly implicit when the integral to be preserved is quadratic , and of order @xmath1 for arbitrarily chosen @xmath2 .",
    "our numerical experiments confirmed that , in this case , solving a linear system at each step instead of a nonlinear system led to significantly reduced computational cost .",
    "the results in this paper can be easily applied to projection methods , see @xcite , and further avenues for research include developing similar theory for discrete gradient methods applied to odes with lyapunov functions , and discrete gradient methods applied to stiff odes , an issue not addressed here .",
    "this research was supported by the australian research council . using the property of the discrete gradient in the bound of @xmath434 in",
    "is a generalisation of an unpublished proof for projection methods by ari stern .",
    "99 ( mr1454125 ) w. gautschi , `` numerical analysis .",
    "an introduction '' , birkhuser , boston , 1997 .",
    "( mr1411343)o .",
    "gonzalez , _ time integration and discrete hamiltonian systems _ , j. nonlinear science , * 6 * ( 1996 ) , 449467 .",
    "( mr1799312 ) e. hairer , _ symmetric projection methods for differential equations on manifolds _ , bit , * 40 * ( 2000 ) , 726734 .",
    "( mr2221614 ) e. hairer , c. lubich and g. wanner , `` geometric numerical integration .",
    "structure preserving algorithms for ordinary differential equations '' , springer series in computational mathematics , vol .",
    "31 , 2@xmath435 edition , springer - verlag , berlin , 2006 .",
    "( mr1227985 ) e. hairer , s. p. nrsett and g. wanner , `` solving ordinary differential equations .",
    "i. nonstiff problems '' , springer series in computational mathematics , vol . 8 ,",
    "2@xmath435 edition , springer - verlag , berlin , 1993 .",
    "( mr0171038 ) p. hartman , `` ordinary differential equations '' , john wiley & sons inc . , new york , 1964 .",
    "( mr0620639 ) v. i. istrescu , `` fixed point theory , an introduction '' , mathematics and its applications , vol . 7 , d. reidel publishing co. , dordrecht , holland , 1981 .",
    "( mr0943488 ) toahiaki itoh and kanji abe , _ hamiltonian - conserving discrete canonical equations based on variational difference quotients _ , j. comput .",
    "phys . , * 76 * ( 1988 ) , 85102 .",
    "( mr1694701 ) robert i. mclachlan , g. r. w. quispel and nicolas robidoux , _ geometric integration using discrete gradients _",
    "ser . a math .",
    ", * 357 * ( 1999 ) , 10211045 . r. a. norton , d. i. mclaren , g. r. w. quispel , a. stern and a. zanna , _ projection methods and discrete gradient methods for preserving first integrals of odes _ , in preparation , 2012 .",
    "( mr0231218 ) j. m. ortega , _ the newton - kantorovich theorem _ ,",
    "monthly , * 75 * ( 1968 ) , 658660 .",
    "( mr2206097 ) marco papi , _ on the domain of the implicit function and applications _ ,",
    "j. inequal .",
    "* 2005 * ( 2005 ) , 221234 .",
    "( mr1400626 ) g. r. w. quispel and h. w. capel , _ solving odes numerically while preserving a first integral _ , physics letters . a , * 218 * ( 1996 ) , 223228 .",
    "( mr2451073 ) g. r. w. quispel and d. i. mclaren , _ a new class of energy - preserving numerical integration methods _ , j. phys .",
    "a , * 41 * ( 2008 ) , 045207(7 ) .",
    "( mr1400157 ) g. r. w. quispel and g. s. turner , _ discrete gradient methods for solving odes numerically while preserving a first integral _ , j. phys .",
    "a , * 29 * ( 1996 ) , l341l349 ."
  ],
  "abstract_text": [
    "<S> in this paper we consider discrete gradient methods for approximating the solution and preserving a first integral ( also called a constant of motion ) of autonomous ordinary differential equations . </S>",
    "<S> we prove under mild conditions for a large class of discrete gradient methods that the numerical solution exists and is locally unique , and that for arbitrary @xmath0 we may construct a method that is of order @xmath1 . in the proofs of these results </S>",
    "<S> we also show that the constants in the time step constraint and the error bounds may be chosen independently from the distance to critical points of the first integral .    </S>",
    "<S> in the case when the first integral is quadratic , for arbitrary @xmath2 , we have devised a new method that is linearly implicit at each time step and of order @xmath1 . </S>",
    "<S> this new method has significant advantages in terms of efficiency . </S>",
    "<S> we illustrate our theory with a numerical example .    </S>",
    "<S> richard a. norton and g. r. w. quispel    _ this paper is dedicated to arieh iserles , a dear friend and a wonderful colleague . _ </S>"
  ]
}