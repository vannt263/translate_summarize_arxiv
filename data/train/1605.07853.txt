{
  "article_text": [
    "the entropy power inequality ( epi ) for statistically independent real _ continuous_-valued random variables @xmath0 and @xmath3 , @xmath6 was first stated by shannon  @xcite , where @xmath7 is the _ entropy power _ of @xmath0 , with @xmath8 being the differential entropy of @xmath0 .",
    "equality in   holds if and only if @xmath0 and @xmath3 are gaussian . using @xmath9 the entropy of a gaussian random variable with variance @xmath10 , we get @xmath11 . in other words ,",
    "the entropy power of @xmath0 is the variance of a gaussian random variable that has the same differential entropy as that of @xmath0 .",
    "the epi was subsequently proved by stam  @xcite and blachman  @xcite .",
    "the epi   has proven to be a powerful tool in information theory .",
    "it has found use in converse proofs of various gaussian channel coding theorems involving continuous - valued sources and channels , especially in the respective converse proofs .",
    "some prominent examples are : the capacity region of the scalar gaussian broadcast channel  @xcite , its generalization to the mimo case  @xcite , the private capacity of the gaussian wiretap channel  @xcite , capacity region of the gaussian interference channel  @xcite , gaussian source multiple - description problem  @xcite , and rate distortion region for multi - terminal gaussian source coding  @xcite .    due to this success of shannon s epi ,",
    "it is natural to speculate if there is an epi for statistically - independent discrete - valued random variables @xmath0 and @xmath3 defined on the set of natural numbers @xmath12 , which has analogous implications as above in discrete - valued information and coding theorems .",
    "there have been several attempts to provide an epi for discrete random variables .",
    "it is simple to see that   does not hold as is when @xmath0 and @xmath3 are arbitrary discrete random variables and the differential entropy @xmath13 is replaced by the discrete shannon entropy @xmath1 ; a simple counterexample occurring for when @xmath0 and @xmath3 are deterministic .",
    "epis with bernoulli sources were proven where the  @xmath14 \" operation in   was taken modulo @xmath15",
    "harremo \" es and vignat retained the use of  @xmath14 \" as integer addition , and proved that   holds when @xmath0 and @xmath3 are independent binomial @xmath16 and @xmath17 variables , upon redefining @xmath18 in   as @xmath19 , with @xmath1 being the discrete entropy  @xcite .",
    "a discrete epi was proven for arbitrary i.i.d .",
    "integer - valued random variables , albeit of a non - standard asymmetric form  @xcite .",
    "yu and johnson developed a natural form of the discrete epi but one that holds only for ultra - log concave ( ulc ) distributed random variables  @xcite .",
    "recently , woo and madiman showed that an inequality very similar to   holds for uniform distributions over finite subsets of the integers  @xcite .    in this paper , we present an axiomatic framework to develop a natural generalization of the epi for arbitrary discrete random variables and an associated central limit theorem ( clt ) .",
    "we begin with an overview of shannon s epi in section  [ sec : review ] .",
    "section  [ sec : discreteepi ] provides an intuitive development of our discrete epi . in section",
    "[ sec : quantum ] , we provide proofs leveraging the algebra of quantum optics , and a close connection of our discrete epi to a quantum epi that naturally emerges in capacity proofs for transmitting classical information over bosonic channels  @xcite .",
    "using the following scaling identity for entropy power : @xmath20 it is straightforward to see that ineq .   can be restated as : @xmath21 @xmath22 is a scaled addition operation .",
    "the ` linear ' form of the epi , @xmath23 i.e. , the fact that differential entropy is concave with respect to normalized linear combinations , was first stated by lieb  @xcite , a rigorous proof of which , and the proof of the fact that   is equivalent to  , was later provided by dembo , cover and thomas  @xcite . that  , hence   implies   follows simply from the application of @xmath24 to both sides of  , and using the concavity of the logarithm function .",
    "the converse implication requires the entropy of a scaled random variable , @xmath25  @xcite .",
    "consider random variables @xmath26 and @xmath27 , with @xmath28 .",
    "using the expression for @xmath29 stated above , it readily follows that @xmath30 . we then have , using  , @xmath31 applying @xmath32 to both sides , and using  , yields the epi  .",
    "scaling plays an important role in many proofs of the epi .",
    "the fact that the epi can be stated in terms of scaled random variables as in inequality   was implicit in verd ' u and guo s proof of the epi  @xcite , but johnson and yu later realized the significance of this form to construct an epi for ulc discrete random variables , as we will describe in section  [ sec : discreteepi ]  @xcite .",
    "artstein , ball , barthe and naor proved a stronger form of the epi   for sums of independent continuous random variables  @xcite , a special case of which was the first rigorous proof of _ monotonicity _ of the convergence of differential entropy in the clt , i.e. , for i.i.d .",
    "@xmath33 , the entropy of the normalized sum @xmath34 , with @xmath35 , is monotone increasing in @xmath36 , and converges to the entropy of the gaussian ( which has the maximum entropy for a given variance ) as @xmath37 .",
    "note that @xmath38 for i.i.d . @xmath39 and @xmath40 follows from  , repeated application of which shows that @xmath41 is nondecreasing in @xmath42 .",
    "this cruder version of monotonicity is already sufficient to prove the clt  @xcite .",
    "alternative proofs of monotonicity of @xmath43 were later given by tulino and verd ' u  @xcite , and by madiman and barron  @xcite .",
    "the main ingredient needed for a natural discrete - variable generalization of shannon s epi , i.e. ,   and is a :    * * scaled addition * : an appropriate definition of @xmath2 for @xmath0 and @xmath3 both defined on @xmath44 , and @xmath4 .",
    "further , the definition of @xmath45 should be extendable to a random vector @xmath46 , i.e. , @xmath47 , where @xmath48 with @xmath49 and @xmath50 , such that : ( 1 ) it reduces to the bivariate case for @xmath51 , viz .",
    ", @xmath52 ; ( 2 ) it is commutative in the sense that @xmath47 is invariant under an arbitrary ( yet identical ) permutation of the entries of @xmath53 and @xmath54 ; and ( 3 ) it is well behaved under a clt :    * * _ limiting _ distribution * : a distribution @xmath55 $ ] , @xmath56 should exist that can be defined solely as a function of its mean @xmath57 , and is the limiting distribution in a clt under @xmath58 addition . in other words ,",
    "@xmath55 $ ] is the distribution of @xmath59 , as @xmath37 , for i.i.d .",
    "arbitrarily - distributed @xmath57-mean random variables @xmath60 .    for a complete analogy with shannon s epi",
    ", one would want @xmath61 , the entropy of @xmath62 , to be monotonically increasing in @xmath63 .",
    "thus , @xmath64 should be the distribution with the maximum entropy for a given mean @xmath57 .",
    "we already know that the geometric distribution @xmath65 = \\left(1+\\lambda\\right)^{-1}\\left(\\lambda/(1+\\lambda)\\right)^k$ ] , @xmath56 , has this property .",
    "so , we would like the @xmath58 operation for which the above clt holds with the geometric distribution being the limiting distribution .",
    "one would then define :    * * entropy power * : @xmath66 of @xmath0 as the mean of a random variable with distribution @xmath67 that has entropy @xmath1 .",
    "note that in order for the above to make sense , the entropy of the limiting distribution @xmath67 should be monotonic ( increasing ) in its mean @xmath57 . with the above",
    ", the following should hold :    * * entropy power inequality * : the epi for discrete random variables , i.e. ,   and should hold with the shannon entropy power @xmath18 replaced by the discrete entropy power @xmath66 and the differential entropy @xmath13 replaced by the discrete shannon entropy @xmath1 .",
    "further , equality in both aforesaid forms of the discrete epi should hold when @xmath0 and @xmath3 both are distributed according to the limiting distribution @xmath67 ( possibly with different means ) .",
    "the above discussion suggests that once we have the ` correct ' definition of the @xmath58 operation for discrete random variables ( i.e. , one that is well behaved under the clt with the limiting distribution being geometric ) , one would immediately obtain the natural discrete generalization of shannon s epi .    in the above framework for discrete - valued random variables , we chose to peg the definitions to the mean as opposed to the variance ( as in the case of continuous random variables ) . in the discrete case , the law of small numbers ( see footnote  [ footnote : losn ] ) and the corresponding maximum entropy property both require ` thinning ' the mean , whereas in the continuous case",
    ", the central limit theorem requires the thinning of the variance , which is achieved by multiplication by @xmath68 .",
    "many have realized that the r ' enyi thinning operation @xmath69 is the natural discrete - variable equivalent of multiplication by @xmath68 , and has the desirable effect of thinning the mean by a factor @xmath70  @xcite .    given @xmath4 , and @xmath71 , the random variable @xmath72 , obtained by @xmath70-thinning of @xmath0 ( denoted , @xmath73 ) , has the distribution of the sum @xmath74 , where @xmath75 are binary @xmath76 valued i.i.d .",
    "bernoulli(@xmath77 ) random variables that are independent of @xmath0 . the p.m.f .",
    "of @xmath3 is : @xmath78 = \\sum_{k = n}^\\infty p_x[k ] \\binom{k}{n}\\eta^n(1-\\eta)^{k - n}$ ] .",
    "yu and johnson developed a promising line of approach to the discrete epi for ultra - log concave ( ulc ) random variables ( i.e. , those with p.m.f.s @xmath79 , n \\in { \\mathbb n}_0 $ ] , for which @xmath80/p_x[n-1]$ ] is decreasing as @xmath36 increases ) .",
    "they defined the scaled addition @xmath81 which extends naturally to multiple variables and is well behaved under the clt with the associated limiting distribution being poisson . for i.i.d .",
    "mean-@xmath57 @xmath82 with p.m.f .",
    "@xmath79 $ ] , @xmath83 converges to the poisson distribution of mean @xmath57 as @xmath37  the distribution of @xmath84 is the @xmath36-fold convolution of @xmath79 $ ] .",
    "when @xmath85 bernoulli(@xmath86 ) , @xmath87 binomial(@xmath88 ) and @xmath89 binomial(@xmath90 ) @xmath91 poisson(@xmath86 ) as @xmath37 .",
    "this special case is the classical binomial - to - poisson convergence , known as the  law of small numbers \"  @xcite . ] .",
    "since the limiting distribution is not geometric , the @xmath45 operation in   does not satisfy the criteria in section  [ sec : axioms ] .",
    "however , within the class of all ulc random variables of mean @xmath57 , the poisson(@xmath57 ) random variable maximizes the entropy  @xcite .",
    "furthermore , @xmath61 increases monotonically in @xmath36 if @xmath79 $ ] is ulc  @xcite . motivated by this , yu and johnson defined entropy power @xmath92 in terms of the entropy @xmath93 of a poisson(@xmath57 ) random variable , with the hope that the straightforward equivalents  ,   and   would hold , with @xmath0 and @xmath3 restricted to ulc random variables .",
    "they proved that the linear form ( concavity of entropy )   holds  @xcite , i.e. , @xmath94 for all ulc independent @xmath0 and @xmath3 .",
    "this was the first major step towards a discrete epi .",
    "the equivalents of and , @xmath95 were naturally conjectured  @xcite , but were shown later _ not _ to hold in general , even for ulc @xmath0 and @xmath3  @xcite .",
    "the key step in going from the epi   to the linear form   was the scaling identity for the entropy power  .",
    "if such an identity were to hold for any ulc variable @xmath0 , i.e. , @xmath96 , then   would imply the conjectured discrete epi  .",
    "but since the conjecture was found to be false , the scaling identity above can not be true .",
    "however , the following one - sided version of it was proved for ulc @xmath0 : @xmath97 which was termed the restricted discrete epi  @xcite .",
    "even though   does not hold in general , the restated form   does hold for discrete ulc variables  @xcite : given ulc independent @xmath0 and @xmath3 , if @xmath98 @xmath99 and @xmath100 s.t .",
    "@xmath101 and @xmath102 for some @xmath4 , s.t .",
    "@xmath103 , then @xmath104 with equality iff @xmath0 and @xmath3 are poisson .",
    "the reason why   holds but not  , is that finding @xmath70 , @xmath99 and @xmath100 that satisfy the aforesaid conditions is not always possible .",
    "this is unlike the continuous version  , for which @xmath70 , @xmath99 and @xmath100 can always be constructed that satisfy the conditions , as shown in section  [ sec : review ] .       and @xmath105 combined on a beamsplitter with transmissivity @xmath70 results in a number - diagonal state @xmath106 at the output .",
    "the distribution of the photon number at the output is a particular scaled addition of the two input distributions , explained in section  [ sec : discreteepi_gsg ] , which is at the core of our discrete epi . ]",
    "our goal is to develop a @xmath45 operation that : ( i ) is well behaved under a clt with the geometric distribution as the limiting distribution ; and ( ii ) satisfies ineqs .   and   for @xmath0 and @xmath3 with _",
    "arbitrary _ discrete distributions , and with the entropy power @xmath107 defined in terms of @xmath108 , the entropy of the geometric distribution with mean @xmath57 .",
    "let us consider the following @xmath109-to-@xmath109 transform between a discrete distribution @xmath79 $ ] , @xmath110 and a circularly - symmetric continuous distribution @xmath111 , @xmath112 ( proof in section  [ sec : quantum ] ) : @xmath113 \\frac{e^{-\\left| { \\boldsymbol r } \\right|^2 } \\left| { \\boldsymbol r } \\right|^{2n}}{n ! } , { \\text{and}}\\label{eq : t}\\\\ p_x[n ] & = & \\frac{1}{\\pi}\\int p_{{\\boldsymbol x}_c}(\\boldsymbol r ) { \\cal l}_n\\left(\\left| { \\boldsymbol s } \\right|^2\\right ) e^{{\\boldsymbol r}{\\boldsymbol s}^ * - { \\boldsymbol r}^*{\\boldsymbol s}}d^2{\\boldsymbol r}d^2{\\boldsymbol s } , \\label{eq : inverset}\\end{aligned}\\ ] ] where @xmath114 is the @xmath36-th laguerre polynomial .",
    "let us denote @xmath115 and @xmath116   is not a function that maps the random variable @xmath0 to the random variable @xmath117 .",
    "it is a transform that takes a _ function _ , a discrete p.m.f .",
    "@xmath79 $ ] , to another function , a continuous p.d.f . @xmath111 . ] .",
    "we define scaled addition @xmath45 for discrete random variables @xmath0 and @xmath3 as follows , but in section  [ sec : discreteepi_gsg ] onwards , the definition in eq .   will be implied for @xmath45 . ] : @xmath118 where the @xmath45 on the rhs of   is the usual continuous - variable definition as in  .",
    "the following is simple to verify :    if @xmath78 = \\delta[n]$ ] is a delta function at @xmath119 , @xmath120 .",
    "similarly , if @xmath79 = \\delta[n]$ ] , @xmath121 .",
    "[ thm : thinning_pureloss ]    our definition of @xmath45 coincides with the yu - johnson definition when one of the two variables is @xmath122 with probability @xmath109 , but instead of directly adding the integer - valued scaled random variables @xmath123 and @xmath124 , we add the real - valued scaled random variables @xmath125 and @xmath126 ( and transform back to the integer domain using  ) , where @xmath115 and @xmath127 .",
    "generalizing our @xmath45 operation for multiple variables is straightforward . following the steps outlined in section  [ sec : axioms ]",
    ", we consider a clt under this scaled addition .    for i.i.d .",
    "arbitrarily - distributed @xmath57-mean random variables @xmath60 , the p.m.f . of @xmath59 converges to the geometric distribution of mean @xmath57 as @xmath37 .",
    "[ thm : clt_gsg ]    we have the following conjecture on monotonicity of entropy :    @xmath61 increases monotonically with @xmath63 and converges to @xmath128 , as @xmath37 .",
    "[ conj : monotonicity ]    this is analogous to harremo \" es _ et al .",
    "_ s law of small numbers  @xcite and johnson - yu s discrete entropic - monotonicity result  @xcite , but no longer restricted to ulc random variables .",
    "[ thm : epi_gsg_linear ] the linear form of the discrete epi holds for arbitrary independent discrete - valued random variables @xmath0 , @xmath3 : @xmath129    we will show in section  [ sec : quantum ] that   follows as a special case of a recent result on a quantum version of the epi  @xcite .",
    "inequality   with @xmath130 implies @xmath131 , which is sufficient to prove theorem  [ thm : clt_gsg ] but only proves conjecture  [ conj : monotonicity ] for @xmath36 increasing in power - of-@xmath15 steps .",
    "[ conj : epi_gsg_scaled ] the following is the natural discrete generalization of shannon s epi , which holds true for arbitrary independent discrete - valued random variables @xmath0 and @xmath3 : @xmath132    even though we do not provide a proof of  , we will show in section  [ sec : quantum ] that   is a simple special case of the yet - unproven entropy photon number inequality ( epni )  @xcite .",
    "de palma _ et al .",
    "_ recently proved the following restricted one - sided version of  , analogous to yu and johnson s ineq .",
    ": @xmath133 see theorem @xmath134 of ref .",
    "@xcite for a proof .",
    "there has been a suite of recent progress in quantum versions of the epi  @xcite , and an eventual proof of the epni will imply the validity of the discrete epi   in conjecture  [ conj : epi_gsg_scaled ] .",
    "finally , we have :    using a ( somewhat unnatural ) definition of entropy power , @xmath135in analogy with the continuous entropy power @xmath18the epi statement in   holds true for arbitrary independent discrete random variables @xmath0 , @xmath3 : @xmath136    we show in section  [ sec : quantum ] that this result follows as a special case of a quantum epi result recently proved in  @xcite .",
    "in this section , we will provide proofs of the various statements in section  [ sec : discreteepi_gsg ] . even though it is possible to prove them directly ,",
    "it is much easier to leverage the mathematics of quantum optics .",
    "let us consider a beamsplitter of transmissivity @xmath4 that mixes two modes whose annihilation operators are @xmath137 and @xmath138 , to produce an output mode @xmath139 .",
    "assume that the quantum states of the two input modes , @xmath140 are statistically independent .",
    "the density operators @xmath141 and @xmath105 are infinite - dimensional , unit - trace , positive , hermitian matrices , whose matrix elements we will express in the complete orthonormal _ fock _ ( or photon - number ) basis @xmath142 , @xmath143 .",
    "the von neumann entropy of @xmath141 , @xmath144 , where @xmath145 are the eigenvalues of @xmath141 . for a number diagonal state",
    "@xmath146|n\\rangle \\langle n|$ ] , @xmath147 , shannon entropy of the discrete random variable @xmath0 .",
    "consider independent @xmath0 and @xmath3 with p.m.f.s @xmath79 $ ] and @xmath78 $ ] , @xmath110 .",
    "consider mixing independent number - diagonal states @xmath146|n\\rangle \\langle n|$ ] and @xmath148|n\\rangle \\langle n|$ ] on a beamsplitter of transmissivity @xmath70 .",
    "then the output state is also number - diagonal , i.e. , @xmath149|n\\rangle \\langle n|$ ] , and the output number distribution @xmath150 $ ] is that of the random variable @xmath151 , with our definition of @xmath45 given in  . in other words , the scaled addition in eq .",
    "has a physical interpretation ",
    "it is how a beamsplitter of transmissivity @xmath70 ` adds ' photon number distributions of two independent number - diagonal input states .",
    "the husimi function of a quantum state @xmath141 , @xmath152 , @xmath112 , can be interpreted as the p.d.f . of a continuous - valued random variable @xmath153 . here , @xmath154 is the _ coherent state _ of complex amplitude @xmath155 , an eigenstate of the annihilation operator @xmath156 .",
    "when @xmath146|n\\rangle \\langle n|$ ] is number - diagonal , its husimi function @xmath111 is given by eq .",
    ", which is a circularly - symmetric function in the phase space .",
    "the anti - normally - ordered characteristic function of @xmath157 is then @xmath158 . using the operator fourier inverse to express the state @xmath159 , writing down the number - basis diagonal elements @xmath160 $ ] , and using the identity @xmath161",
    ", we obtain eq .  .",
    "so , we have the @xmath109-to-@xmath109 transform , @xmath115 and @xmath116 . physically , @xmath0 and @xmath162 are random variables corresponding to the outcomes of ( ideal ) photon number measurement and ( ideal ) optical heterodyne detection measurement respectively , on the state @xmath141 .",
    "because the husimi function of a quantum state is unique , the above transform relation implies that the husimi function of a state is circularly symmetric if and only if it is diagonal in the number basis .",
    "next , we observe that the husimi function of the output state @xmath106 is given by the scaled convolution @xmath163 , which implies that the respective transformed variables are related by the scaled addition , @xmath164  @xcite .",
    "given @xmath141 and @xmath105 are both number diagonal ( and hence have circularly - symmetric husimi functions ) , @xmath106 must also have a circularly - symmetric husimi function , and hence be number diagonal .",
    "therefore , the number distribution of @xmath106 is that of a random variable @xmath165 .",
    "it is simple to verify that , for number - diagonal @xmath141 , if @xmath78 = \\delta[0]$ ] , the output state s number distribution @xmath150 $ ] is the @xmath70-thinned version of @xmath79 $ ] , @xmath166 .",
    "similarly , with @xmath79 = \\delta[0]$ ] and number - diagonal @xmath105 , @xmath167 .",
    "interestingly however , if neither @xmath141 nor @xmath105 is the vacuum state , the output number distribution is _ not _ a simple addition of the thinned input distributions , i.e. , @xmath168 ( the rhs is yu and johnson s @xmath45 ) ; rather it is given by  .",
    "proof of the discrete clt in theorem  [ thm : clt_gsg ] follows from theorem 5.10 of  @xcite when restricted to number - diagonal inputs and using the definition of @xmath45 in eq .  .",
    "let us consider the following two definitions of entropy power for a quantum state , and associated entropy power inequalities for each definition :    \\(a ) _ entropy photon number _",
    ", @xmath169 , where @xmath170 is the von neumann entropy of a thermal state @xmath171|n\\rangle \\langle n|$ ] of mean photon number @xmath57 , with @xmath172 = \\left(1+\\lambda\\right)^{-1}\\left(\\lambda/(1+\\lambda)\\right)^n$ ] . since @xmath173 is diagonal in the number basis , @xmath128 is also the shannon entropy of the geometric distribution of mean @xmath57 , as used in section  [ sec : discreteepi_gsg ] .",
    "\\(b ) _ quantum entropy power _ , @xmath174 , where @xmath175 , defined in analogy with the gaussian entropy function @xmath176 used to define the classical entropy power @xmath18 that appears in the original epi  .",
    "_ entropy photon number inequality _",
    "( epni )  @xcite  for a pair of independent states @xmath141 and",
    "@xmath105 input to a beamsplitter of transmissivity @xmath70 , producing the state @xmath106 at the output , guha , shapiro and erkmen conjectured the following  @xcite : @xmath177 proving that equality occurs if @xmath141 and @xmath105 are thermal states .",
    "the epni plays a role analogous to the epi in converse proofs of capacities of gaussian bosonic channels .",
    "a general proof of epni remains open , but it was proved for gaussian - state inputs  @xcite .",
    "it was shown that a special case of the epni , @xmath178 a statement analogous to  , would complete the converse proofs of the capacity region of the multi - user bosonic broadcast channel  @xcite , and the triple tradeoff region of the pure - loss bosonic channel  @xcite .",
    "inequality   was proved recently by de palma _",
    "et al . _",
    "@xcite , which when applied to number - diagonal inputs , implies   as a special case .    _ quantum entropy power inequality _ ( q - epi )",
    "@xcite  koenig and smith conjectured ( and provided a partial proof for ) the following , by replacing the @xmath179 in the epni by @xmath180  @xcite : @xmath181 a complete proof of the q - epi  , and a multi - input generalization thereof , were provided by de palma _ et al . _",
    "however , unlike the epni , which emerges naturally in the bosonic gaussian channel capacity converses , the q - epi only implies upper bounds ( or outer bounds , in case of broadcast channels ) to the respective capacities  @xcite ( or capacity regions , for broadcast channels  @xcite ) .",
    "the q - epi implies the following linear form , analogous to  , by applying @xmath182 on both sides of   and using the concavity of the log function : @xmath183 if the epni were proven true , the concavity of @xmath184 would also imply  .",
    "the linear form   when applied to number - diagonal inputs implies   in theorem  [ thm : epi_gsg_linear ] .",
    "similarly , the q - epi   implies the discrete epi  . by employing   for @xmath130 recursively on pairs of identical input states ,",
    "we get : @xmath185 which provides a partial proof of a conjecture by guha and shapiro on entropic monotonicity in a quantum clt ( theorem 5.10 of  @xcite ) , with @xmath36 increasing in power - of-@xmath15 increments",
    ". a complete proof of the aforesaid conjecture , when applied to identical independent number - diagonal states , will imply conjecture  [ conj : monotonicity ] as a special case . finally ,",
    "a proof of the epni would imply the natural discrete - variable generalization of shannon s epi  , which would satisfy all the desirable properties stated in section  [ sec : axioms ] and would hold for all discrete random variables and not be restricted to ulc distributed random variables as in the yu - johnson discrete epi .",
    "shannon s entropy power inequality ( epi ) found many applications in proving coding theorem converses for many gaussian channel and source coding problems .",
    "the entropy photon - number inequality ( epni ) was shown to assume a role analogous to shannon s epi in capacity converse proofs for transmitting classical information over gaussian bosonic ( quantum ) channels . even though the general form of the epni remains unproven , several special cases of it have been proven in the recent years .",
    "many attempts have been made to find the most natural discrete - variable version of shannon s entropy power inequality ( epi ) . in this paper , we developed an axiomatic framework from which we deduced the natural form of a discrete - variable epi and an associated entropic monotonicity in a discrete - variable central limit theorem . in this discrete epi , the geometric distribution , which has the maximum entropy among all discrete distributions with a given mean , assumes a role analogous to the gaussian distribution in shannon s epi , and the thermal state in the epni .",
    "we defined the entropy power of a discrete random variable @xmath0 as the mean of a geometric random variable with entropy @xmath1 .",
    "the crux of our construction is a discrete - variable version of lieb s scaled addition @xmath2 of two discrete random variables @xmath0 and @xmath3 with @xmath4 .",
    "we discussed the relationship of our discrete epi with recent work of yu and johnson who developed an epi for a restricted class of random variables that have ultra - log - concave ( ulc ) distributions , and pegged their definition of the entropy power to the entropy function of the poisson distribution , which attains the maximum entropy for a given mean , among the class of ulc random variables .",
    "even though we left open the proof of the aforesaid natural form of the discrete epi that we conjectured in this paper , we showed that this discrete epi holds true for discrete random variables with arbitrary discrete distributions when the entropy power is redefined as @xmath5 in analogy with the continuous version .",
    "finally , we showed that our conjectured discrete epi is a special case of the epni , corresponding to the case when two input quantum states to the epni are independent number - diagonal states .",
    "acknowledge the organizers of the third beyond i.i.d .",
    "workshop held at birs , banff in july 2015 , where this work took seed , and thank rupert l. frank and elliott lieb for inspiring discussions on the epi at that workshop .",
    "the authors thank vittorio giovannetti and seth lloyd for useful discussions .",
    "sg would like to acknowledge the darpa quiness program funded under us army research office award number w31p4q-12 - 1 - 0019 .",
    "j.h.s . acknowledges support from the air force office of scientific research ( afosr ) grant number fa9550 - 14 - 1 - 0052 .",
    "is research associate of the f.r.s .- fnrs .        c. e. shannon ,  a mathematical theory of communication , \" bell syst .",
    "j. , * 27 * , pp . 379423 and 623656 ( 1948 ) .",
    "a. j. stam ,  some inequalities satisfied by the quantities of information of fisher and shannon , \" inform .",
    "contr . , * 2 * , 101112 ( 1959 )",
    ". n. m. blachman ,  the convolution inequality for entropy powers , \" ieee trans .",
    "inform . theory ,",
    "it-*11 * , 267271 ( 1965 ) .",
    "p. bergmans ,  a simple converse for broadcast channels with additive white gaussian noise , \" ieee transactions on information theory , vol .",
    "2 , 279280 ( 1974 ) .",
    "h. weingarten , y. steinberg , and s. shamai ( shitz ) ,  the capacity region of the gaussian multiple - input multiple - output broadcast channel , \" ieee transactions on information theory , vol .",
    "52 , no . 9 , 39363964 ( 2006 ) .",
    "m. mohseni and j. m. cioffi ,  a proof of the converse for the capacity of gaussian mimo broadcast channels , \" in proceedings of the ieee international symposium on information theory , seattle , 881885 ( 2006 ) .",
    "s. leung - yan - cheong and m. hellman ,  the gaussian wire - tap channel , \" ieee transactions on information theory , vol .",
    "4 , 451456 ( 1978 ) .",
    "m. h. m. costa ,  on the gaussian interference channel , \" ieee transactions on information theory , vol .",
    "31 , no . 5 , 607615 ( 1985 ) .",
    "r. zamir , ",
    "gaussian codes and shannon bounds for multiple descriptions , \" ieee transactions on information theory , vol .",
    "45 , no . 7 , 26292636 ( 1999 ) .",
    "l. ozarow ,  on a source - coding problem with two channels and three receivers , \" bell system technical journal , vol .",
    "10 , 19091921 ( 1980 ) .",
    "y. oohama , ",
    "gaussian multiterminal source coding , \" ieee transactions on information theory , vol .",
    "43 , no . 6 , 19121923 ( 1997 )",
    "a. wyner and j. ziv ,  a theorem on the entropy of certain binary sequences and applications : part i , and part ii \" ieee trans .",
    "theory , it-*19 * , 769772 ; 772777 ( 1973 ) .",
    "witsenhausen ,  entropy inequalities for discrete channels , \" ieee trans .",
    "theory , it-*20 * , 610616 ( 1974 ) .",
    "r. ahlswede and j. k \" oruer ,  on the connection between the entropies of input and output distributions of discrete memoryless channels , \" proc . of the fifth conference on probability theory , brasov ( 1974 ) .",
    "s. shamai and a. wyner ,  a binary analog to the entropy - power inequality , \" ieee trans .",
    "theory , it-*36 * , 14281430 ( 1990 ) .",
    "p. harremoe \" es and c. vignat ,  an entropy power inequality for the binomial family , \" jour . of inequalities in pure and applied math .",
    ", vol . * 4 * , issue 5 , article 93 ( 2003 ) .",
    "s. haghighatshoar , e. abbe , and e. telatar ,  a new entropy power inequality for integer - valued random variables \" , proc .",
    "isit , 589593 ( 2013 ) .",
    "o. t. johnson ,  log - concavity and the maximum entropy property of the poisson distribution , \" stoch .",
    "* 117 * , 6 791802 ( 2007 ) .",
    "y. yu and o. t. johnson ,  concavity of entropy under thinning , \" proc .",
    "isit , 144148 ( 2009 ) .",
    "y. yu ,  monotonic convergence in an information - theoretic law of small numbers , \" ieee trans .",
    "theory , * 55 * , 12 54125422 ( 2009 ) .",
    "o. johnson and y. yu ,  monotonicity , thinning and discrete versions of the entropy power inequality , \" ieee trans . on inform .",
    "theory , vol . * 56 * , no .",
    "11 , 53875395 ( 2010 ) .",
    "j. o. woo and m. madiman ,  a discrete entropy power inequality for uniform distributions \" , proc .",
    "isit , 16251629 ( 2015 ) .",
    "s. guha , j. h. shapiro , and b. i. erkmen ,  capacity of the bosonic wiretap channel and the entropy photon - number inequality , \" proc .",
    "isit , 9195 ( 2008 ) .",
    "e. lieb ,  proof of an entropy conjecture of wehrl , \" comm .",
    "phys . , vol .",
    "* 62 * , pp . 3541 ( 1978 ) .",
    "a. dembo , t. m. cover , and j. a. thomas ,  information theoretic inequalities , \" ieee trans .",
    "* 37 * , 6 , 15011518 ( 1991 ) .",
    "s. verd ' u and d. guo ,  a simple proof of the entropy - power inequality , \" ieee trans .",
    "theory , vol . * 52 * , no .",
    "5 , pp . 21652166 ( 2006 ) .",
    "s. artstein , k. m. ball , f. barthe , and a. naor ,  solution of shannon s problem on the monotonicity of entropy , \" j. amer .",
    "* 17 * , no .",
    "4 , 975982 ( 2004 ) .",
    "r. shimizu ,  on fisher s amount of information for location family \" , statistical distributions in scientific work , g. p. patil _",
    "et al . _ ,",
    "dordrecht , the netherlands : reidel , vol . * 3 * , 305312 ( 1975 ) .",
    "a. tulino and s. verd ' u ,  monotonic decrease of the non - gaussianness of the sum of independent random variables : a simple proof , \" ieee trans .",
    "theory , vol .",
    "* 52 * , no .",
    "9 , pp . 42954297 ( 2006 ) .",
    "m. madiman and a. barron ,  generalized entropy power inequalities and monotonicity properties of information , \" ieee trans .",
    "theory , vol . * 53 * , no . 7 ,",
    "23172329 ( 2007 ) .",
    "p. harremo \" es , o. johnson , and i. kontoyiannis ,  thinning and the law of small numbers , \" proc .",
    "isit , 14911495 ( 2007 ) .",
    "r. koenig and g. smith ,  the entropy power inequality for quantum systems , \" ieee trans . inf .",
    ", * 60 * , 3 , 15361548 ( 2014 ) .",
    "s. guha , j. h. shapiro , and b. i. erkmen ,  classical capacity of bosonic broadcast communication and a new minimum output entropy conjecture , \" phys .",
    "a * 76 * , 032303 ( 2007 ) .",
    "g. de palma , d. trevisan , and v. giovannetti , ",
    "gaussian states minimize the output entropy of the one - mode quantum attenuator \" , arxiv:1605.00441 [ quant - ph ] ( 2016 ) .",
    "s. guha ,  multiple - user quantum information theory for optical communication channels \" , mit ph.d .",
    "thesis ( 2008 ) .",
    "v. giovannetti , s. guha , s. lloyd , l. maccone , and j. h. shapiro ,  minimum output entropy of bosonic channels : a conjecture , \" phys .",
    "a * 70 * , 032315 ( 2004 ) .",
    "v. giovannetti , a. s. holevo and r. garc ' ia - patr ' on s ' anchez ,  a solution of gaussian optimizer conjecture for quantum channels , \" commun .",
    "august 2014 .",
    "g. de palma , a. mari , s. lloyd , and v. giovannetti ,  the multi - mode quantum entropy power inequality , \" phys .",
    "rev . a * 91 * , 032320 ( 2015 ) .",
    "g. de palma , a. mari , and v. giovannetti ,  a generalization of the entropy power inequality to bosonic quantum systems , \" nat .",
    "photonics * 8 * , 958964 ( 2014 ) .",
    "g. de palma , d. trevisan , and v. giovannetti ,  passive states optimize the output of bosonic gaussian quantum channels , \" arxiv:1511.00293 [ quant - ph ] ( 2015 ) . m. m. wilde , p. hayden and s. guha ,  information trade - offs for optical quantum communication \" , phys .",
    "lett . * 108 * , 140501 ( 2012 ) .",
    "r. koenig and g. smith ,  limits on classical communication from quantum entropy power inequalities , \" nat .",
    "photonics * 7 * , 142146 ( 2013 ) ."
  ],
  "abstract_text": [
    "<S> many partially - successful attempts have been made to find the most natural discrete - variable version of shannon s entropy power inequality ( epi ) . </S>",
    "<S> we develop an axiomatic framework from which we deduce the natural form of a discrete - variable epi and an associated entropic monotonicity in a discrete - variable central limit theorem . in this discrete epi , the geometric distribution , which has the maximum entropy among all discrete distributions with a given mean , assumes a role analogous to the gaussian distribution in shannon s epi . </S>",
    "<S> the entropy power of @xmath0 is defined as the mean of a geometric random variable with entropy @xmath1 . </S>",
    "<S> the crux of our construction is a discrete - variable version of lieb s scaled addition @xmath2 of two discrete random variables @xmath0 and @xmath3 with @xmath4 . </S>",
    "<S> we discuss the relationship of our discrete epi with recent work of yu and johnson who developed an epi for a restricted class of random variables that have ultra - log - concave ( ulc ) distributions . </S>",
    "<S> even though we leave open the proof of the aforesaid natural form of the discrete epi , we show that this discrete epi holds true for variables with arbitrary discrete distributions when the entropy power is redefined as @xmath5 in analogy with the continuous version . </S>",
    "<S> finally , we show that our conjectured discrete epi is a special case of the yet - unproven entropy photon - number inequality ( epni ) , which assumes a role analogous to shannon s epi in capacity proofs for gaussian bosonic ( quantum ) channels . </S>"
  ]
}