{
  "article_text": [
    "one of the main purposes of information theory is to compress data so that data can be recovered exactly or approximately .",
    "one of the most important quantities was called entropy because it is calculated according to a formula that mimics the calculation of entropy in statistical mechanics .",
    "another key concept in information theory is information divergence ( kl - divergence ) that was introduced by kullback and leibler in 1951 in a paper entitled information and sufficiency @xcite .",
    "the link from information theory back to statistical physics was developed by e.t .",
    "jaynes via the maximum entropy principle .",
    "the link back to statistics is now well established @xcite .",
    "related quantities appear in information theory , statistics , statistical mechanics , and finance , and we are interested in a theory that describes when these relations are exact and when they just work by analogy . first we introduce some general results about optimization on convex sets .",
    "this part applies exactly to all the topics under consideration and lead to bregman divergences .",
    "secondly , we introduce a notion of sufficiency and show that this leads to information divergence .",
    "this second step is not always applicable which explains when the different topics are really different .",
    "our knowledge about a system will be represented by a state space .",
    "i many cases the state space is given by a set of probability distributions on the sample space .",
    "in such cases the state space is a simplex , but it is well - known that the state space is not a simplex in quantum physics . for applications in quantum physics the state space",
    "is often represented by a density matrix , i.e. a positive semidefinite complex matrix with trace 1 . in some cases",
    "the states are represented as elements of a finite @xmath0-algebra which is direct just a sum of matrix algebras .",
    "a @xmath0-algebra that is a sum of @xmath1 matrices leads to a state space that is a simplex , so the finite @xmath0-algebras contain the classical probability distributions as a special case .",
    "the extreme points in the set of states are the pure states .",
    "the pure states of a @xmath0-algebra can be identified with projections of rank 1 .",
    "two density matrices @xmath2 and @xmath3 are said to be orthogonal if @xmath4 any state @xmath5 has a decomposition @xmath6 where @xmath7 are orthogonal pure states .",
    "such a decomposition is not unique , but for a @xmath0-algebra the coefficients @xmath8 are unique and are called the spectrum of the state .    sometimes more general states spaces are of interest . in general a state space",
    "is a convex set where mixtures are defined by randomly chosing certain states with certain probabilities @xcite .",
    "a convex set where all orthogonal decompositions of a state has the same spectrum is called a spectral state space .",
    "much of the theory in this paper can be generalized to spectral sets .",
    "the most important spectral sets are sets of positive trace 1 elements of jordan algebras . for questions related to the foundation of quantum theory",
    "the jordan algebras and other spectral sets give new insight @xcite , but in this paper we will restrict our attention to states on finite @xmath0-algebras .",
    "nevertheless some of the theorems and proofs are stated in such a way that they hold for quite general state spaces .",
    "let @xmath9 denote a subset of the feasible measurements such that @xmath10 maps the state space @xmath11 into a distribution on the real numbers i.e. the distribution of a random variable .",
    "the elements of @xmath9 may represent feasible _ actions _ ( decisions ) that lead to a payoff like the score of a statistical decision , the energy extracted by a certain interaction with the system , ( minus ) the length of a codeword of the next encoded input letter using a specific code book , or the revenue of using a certain portfolio . for each @xmath12",
    "we define @xmath13.\\ ] ] and @xmath14 without loss of generality we may assume that the set of actions @xmath9 is closed so that we may assume that there exists @xmath10 such that @xmath15 and in this case we say that @xmath16 is optimal for @xmath17 we note that @xmath18 is convex but @xmath18 need not be strictly convex .    in the definition of regret",
    "we follow servage @xcite but with different notation .",
    "if @xmath19 is finite then we define _ the regret _ of the action @xmath16 by @xmath20    if @xmath21 are actions and @xmath22 is a probability vector then we we may define the mixed action @xmath23 as the action where we do the action @xmath21 with probability @xmath24 we note that @xmath25 we will assume that all such mixtures of feasible actions are also feasible . if @xmath26 almost surely for all states we say that @xmath27 dominates @xmath28 and if @xmath29 almost surely for all states @xmath5 we say that @xmath27 strichtly dominates @xmath30 all actions that are dominated may be removed from @xmath9 without changing the function @xmath31 let @xmath32 denote the set of measurements @xmath33 such that @xmath34 then @xmath35 therefore we may replace @xmath9 by @xmath36 without changing the optimization problem .    if @xmath19 is finite _ the regret _ of the action @xmath16 is defined by @xmath37    the regret @xmath38 has the following properties :    * @xmath39 with equality if @xmath16 is optimal for @xmath5 .",
    "* @xmath40 is a convex function . *",
    "if @xmath41 is optimal for the state @xmath42 where @xmath43 is a probability vector then @xmath44 * @xmath45 is minimal if @xmath16 is optimal for @xmath42 .    if the exact state is not know but we know that @xmath5 is one of the states @xmath46 then the _ minimax regret _ is defined as @xmath47 we have the following result .    for any set of actions @xmath48 where the supremum is taken over all probability vectors @xmath49 supported on @xmath11",
    ".    this result can improved .",
    "if @xmath50 is a probability vector on the states @xmath46 with @xmath42 and @xmath51 is the optimal action for minimax regret then @xmath52 if @xmath16 is an action and @xmath53 is optimal then @xmath54    if @xmath51 is optimal then @xmath55 where @xmath16 is optimal for @xmath56    if @xmath50 is a probability vector then @xmath57 this inequality holds for any probability vector @xmath49 so we may take a sequence of asymptotically optimal probability vectors and take the limit .",
    "then @xmath41 converges to @xmath51 and the result follows by lower semi - continuity .",
    "( -0.06431,-0.5008779149519884 ) rectangle ( 1.1419478737997253,0.15580246913580265 ) ; plot(,()*ln(()+1.0e-4 ) ) ; ( 0.,0 . )  ( 1.1419478737997253,0 . ) ; ( 0.,-0.5 )  ( 0.,0.15580246913580265 ) ; ( 0.3868 , -0.4994 ) ",
    "( 1.1362 , 0.0827 ) ; ( 0.8,0.) ( 0.8,-0.178414847300847 ) ; ( 0.45,-0.450314607074793) ( 0.45,-0.35922847440746253 ) ; ( 0.45,0.) ( 0.45,-0.35922847440746253 ) ; ( 0.4343468211923174,0.07152263374485619 ) node[anchor = north west , color = brown ] @xmath58 ; ( 0.790781098312178,0.0680109739369001 ) node[anchor = north west , color = brown ] @xmath59 ; ( 0.23,-0.38 ) node[anchor = north west , color = brown ] @xmath60 ; ( 1.0330861733985859,0.1540466392318246 ) node[anchor = north west , color = blue ] @xmath18 ; ( 0.8,-0.178414847300847 ) circle ( 2pt ) ; ( 0.45,-0.35922847440746253 ) circle ( 2pt ) ; ( 0.45,-0.450314607074793 ) circle ( 2pt ) ; ( 0.45,0 . )",
    "circle ( 2pt ) ; ( 0.8,0 . ) circle ( 2pt ) ;    if the state is @xmath2 but one acts as if the state were @xmath3 one suffers a regret that equals the difference between what one achieves and what could have been achieved .",
    "[ def : regret ] if @xmath61 is finite then we define _ the regret of the state _ @xmath3 as @xmath62 where the infimum is taken over actions @xmath16 that are optimal for @xmath63    if the state @xmath3 has the unique optimal action @xmath28 then @xmath64 so the function @xmath18 can be reconstructed from @xmath38 except for an affine function of @xmath65 the closure of the convex hull of the set of functions @xmath66 is uniquely determined by the convex function @xmath31    the regret is called a _ bregman divergence _ if it can be written in the following form @xmath67 where @xmath68 denotes some inner product ( see figure 1 ) . in the context of forecasting and statistical scoring rules",
    "the use of bregman divergences dates back to @xcite .",
    "a similar but less general definition of regret was given by rao and nayak @xcite where the name _ cross entropy _ was proposed .",
    "we note that if @xmath38 is a bregman divergence and @xmath3 minimizes @xmath18 then @xmath69 so that the formula for the bregman divergence reduces to @xmath70 bregman divergences satisfy the _ bregman identity _ @xmath71 but if @xmath18 is not differentiable this identity can be violated .",
    "let the state space be the interval @xmath72 $ ] with two actions @xmath73 and @xmath74 let @xmath75 and @xmath76 let further @xmath77 and @xmath78 then @xmath79 if @xmath80 then @xmath81 but @xmath82 we also have @xmath83 clearly the bregman identity ( [ eq : bregmanid ] ) is violated .",
    "the following proposition is easily proved .",
    "the following conditions are equivalent .",
    "* for each state @xmath5 and all actions @xmath27 and @xmath28 such that @xmath84 we have @xmath85 where @xmath86 denote expectation .    *",
    "the function @xmath18 is differentiable .    *",
    "the regret @xmath38 is a bregman divergence . *",
    "the bregman identity is always satisfied .",
    "in this section we shall see how regret functions are defined in various cases of interest .",
    "we recall that a code is uniquely decodable if any finite sequence of input symbols give a unique sequence of output symbols .",
    "it is well - known that a uniquely decodable code satisfies kraft s inequality @xmath87 where @xmath88 denotes the length of the codeword corresponding to the input symbol @xmath89 and @xmath90 denotes the size of the output alphabet @xmath91 .",
    "the length of a codeword is here an integer .",
    "if @xmath92 is a probability vector over the input alphabet , then the mean code - length is @xmath93 our goal is to minimize the expected code - length . here the state space consist of probability distributions over the input alphabet and the actions are code - length functions .",
    "shannon established the inequality @xmath94 it is a combinatoric problem to find the optimal code length function . in the simplest case with a binary output alphabet the optimal code - length function",
    "is determined by the huffmann algorithm .",
    "if a code - length function is not dominated by another code - length function then for all @xmath89 the lenght is bounded by@xmath95 therefore for fixed alphabets @xmath96 and @xmath91 there exists only a finite number of code - length functions @xmath97 that satisfy kraft s inequality and are not dominated by other code - length functions that satisfies kraft s inequality .",
    "the use of scoring rules has a long history in statistics .",
    "an early contribution was the idea of minimizing the sum of square deviations that dates back to gauss and works perfectly for gaussian distributions .",
    "in the 1920s ramsay and de finetti proved versions of the dutch book theorem where determination of probability distributions were considered as dual problems of maximizing a payoff function .",
    "later it was proved that any consistent inference procedure corresponds to optimizing with respect to some payoff function .",
    "a more systematic study of scoring rules was given by mccarthy @xcite .",
    "consider an experiment with @xmath98 as sample space .",
    "a _ scoring rule _",
    "@xmath99 is defined as a function with domain @xmath100 such that the score is @xmath101 when a prediction has been given by @xmath102 and @xmath103 has been observed .",
    "a scoring rule is _ proper _ if for any probability measure @xmath104 the score @xmath105 is minimal if and only if @xmath106 here the state space consist of probablity distributions over @xmath107 and the actions are predictions over @xmath107 , which are also probability distributions over @xmath107 .",
    "there is a correspondence between proper scoring rules and regret functions as explained in @xcite .",
    "assume that @xmath99 is proper .",
    "then we may define a divergence by @xmath108 since @xmath99 is assumed to be proper @xmath109 with equality if and only if @xmath110 the equality @xmath111 follows by straight forward calculations . with these two results",
    "we see that @xmath112 equals a bregman divergence @xmath38 and that @xmath113 hence @xmath114    if @xmath99 is given by @xmath115 where @xmath38 is some regret function then @xmath116 because @xmath117 .",
    "if @xmath18 is strictly convex then @xmath118 if and only if @xmath106    the brier score is given by @xmath119 the brier score is generated by the convex function @xmath120      thermodynamics is the study of concepts like heat , temperature and energy .",
    "a major objective is to extract as much energy from a system as possible .",
    "concepts like entropy and free energy play a significant role .",
    "the idea in statistical mechanics is to view the macroscopic behavior of a thermodynamic system as a statistical consequence of the interaction between a lot of microscopic components where the interacting between the components are governed by very simple laws . here",
    "the central limit theorem and large deviation theory play a major role .",
    "one of the main achievements is the formula for entropy as a logarithm of a probability .",
    "here we shall restrict the discussion to the most simple kind of thermodynamic system where we want to extract energy from a system .",
    "we may think of a system of non - interacting spin particles in a magnetic field .",
    "for such a system the hamiltonian is given by @xmath121 where @xmath122 is the spin configuration , @xmath123 is the magnetic moment , @xmath124 is the strength of an external field , and @xmath125 is the spin of the the @xmath126th particle . if the the system is in thermodynamical equilibrium the configuration probability is @xmath127 where @xmath128 is the partition function @xmath129 here @xmath90 is the inverse temperature @xmath130 of the spin system and @xmath131 is boltzmann s constant .    the mean energy is given by @xmath132 which can be identified with @xmath133 and the shannon entropy can be calculated as @xmath134    the amount of energy that can be extracted from the system if a heat bath is availabe , is called the _ exergy _ @xcite .",
    "we assume that the heat bath has temperature @xmath135 and the internal energy and entropy of the system are @xmath136 and @xmath137 if the system has been brought in iequilibrium with the heat bath .",
    "the exergy can be calculated by @xmath138 the information divergence between the actual state and the corresponding state that is in equilibrium with the environment is @xmath139 hence @xmath140 this equation appeared already in @xcite .",
    "the relation between information theory and gambling was established by kelly @xcite .",
    "logarithmic terms appear because we are interested in the exponent in the exponential growth rate of our wealth .",
    "later kelly s approach has been generalized to trading of stocks although the relation to information theory is weaker @xcite .",
    "let @xmath141 denote _ price relatives _ for a list of @xmath142 assets .",
    "for instance @xmath143 means that asset no .",
    "5 increases its value by 4 % .",
    "such price relatives are mapped into a price relative vector @xmath144    a special asset is the _ safe asset _ where the price relative is 1 for any possible price relative vector . investing in this asset corresponds to placing the money at a safe place with interest rate equal to 0 % .    a _ portfolio _ is a probability vector @xmath145 where for instance @xmath146 means that 30 % of the money is invested in asset no .",
    "we note that a portfolio may be traded just like the original assets .",
    "the price relative for the portfolio @xmath147 is @xmath148 the original assets may be considered as extreme points in the set of portfolios . if an asset has the property that the price relative is only positive for one of the possible price relative vectors , then we may call it a _ gambling asset_.    assume that there are only finitely many possible price relative vectors @xmath149 we define a price relative matrix @xmath150 where @xmath151 equals the price relative if the @xmath152th price relative vector is used to calculate the price relative for the @xmath126th asset .",
    "let @xmath153 denote some constant that is greater than @xmath154 for all @xmath126 and define @xmath155 and @xmath156 then the @xmath126th asset has the same price relatives as a portfolio over @xmath157 gambling assets where the @xmath158th gambling asset always has price relative 0 and the @xmath152th gambling asset has price relative @xmath153 is the @xmath152th price relative vector applies and zero else .",
    "in this way we may consider that price relative vectors an identifier of the winning gambling asset and the feasible assets as portfolios of gambling assets .",
    "in particular the set of feasible portfolios is a convex set of portfolios that we will denote @xmath159    let @xmath160 and @xmath161 denote two portfolios .",
    "we say that @xmath160 _ dominates _",
    "@xmath161 if @xmath162 for any possible price relative vector @xmath163 @xmath164 we say that @xmath160 _ strictly dominates _",
    "@xmath161 if @xmath165 for any possible price relative vector @xmath163 @xmath164    we now consider a situation where the assets are traded once every day . for a sequence of price relative vectors",
    "@xmath166 and _ a constant re - balancing portfolio _ @xmath147 the wealth after @xmath167 days is @xmath168\\right)\\end{aligned}\\ ] ] where the expectation is taken with respect to the empirical distribution of the price relative vectors . here",
    "$ ] is proportional to the _ doubling rate _ and is denoted @xmath170 where @xmath171 indicates the probability distribution of @xmath172 .",
    "our goal is to maximize @xmath170 by choosing an appropriate portfolio @xmath173 in @xcite and @xcite it was tacitly assumed that a unique optimal portfolio exists , but this is not always the case . in this paper",
    "we will not assume uniqueness .",
    "we do not change the maximal doubling rate by removing assets that are dominated .",
    "sometimes assets that are dominated but not strictly dominated may lead to non - uniqueness of the optimal portfolio .    for a vector @xmath174",
    "the support @xmath175 is the set of indices @xmath152 such that @xmath176 we note that if @xmath160 strictly dominates @xmath161 if and only if there exists an @xmath177 such that @xmath160 strictly dominates @xmath178 where @xmath178 denotes the @xmath152th basis vector .",
    "the consequence is that we may remove asset number @xmath152 if @xmath178 is strictly dominated because one will never put any money on that particular asset .",
    "similarly , @xmath160 dominates @xmath161 if and only if there exists an @xmath177 such that @xmath160 dominates @xmath178 .",
    "a set @xmath179 of assets is said to dominate the set of assets @xmath180 if any asset in @xmath180 is dominated by a portfolio of assets in @xmath181    if @xmath182 is an optimal portfolio for the distribution @xmath183 concentrated on @xmath184 then the support of @xmath182 is a subset of the support of @xmath185    if @xmath186 then @xmath187=\\log\\left\\langle \\vec{x_{0}},\\vec{b}\\right\\rangle .$ ] the portfolio @xmath147 is a probability distribution over assets so if we let @xmath188 denote the conditional distribution of @xmath147 on the support of @xmath189 then @xmath190 with equality if and only if the support of @xmath147 is a subset of the support of @xmath189 therefore @xmath191 implies that the support of @xmath188 is a subset of the support of @xmath189    let @xmath192 denote a portfolio that is optimal for @xmath171 .",
    "the regret of choosing a portfolio that is optimal for @xmath102 when the distribution is @xmath171 is given by the bregman divergence @xmath193 if @xmath194 is not uniquely determined we take a minimum over all @xmath147 that are optimal for @xmath195    if the assets are orthogonal gambling assets we get the type of gambling described by kelly @xcite .",
    "there is a one - to - one correspondence between price relative vectors and portfolios . for a probability distribution @xmath171 over price relative vectors the optimal portfolio",
    "@xmath192 is a vector with the same coordinates as the probability vector @xmath196 we have @xmath197 if a set of feasible portfolios it embedded as a subset @xmath198 in a set of ideal gambling assets then @xmath198 may be identified with a convex set of incomplete probability distributions .",
    "now maximizing @xmath170 over possible portfolios @xmath147 is the same as minimizing the regret given by ( [ eq : perfekt ] ) over @xmath199 in the set of portfolios over ideal gambling assets .",
    "therefore @xmath194 may be identified with a reversed information projection of @xmath102 on @xmath159    maximizing @xmath170 over @xmath147 in the set of feasible portfolios corresponds to minimizing the regret @xmath200 over @xmath102 which again corresponds to minimizing @xmath201 under the condition that @xmath202 in a set of portfolios on orthogonal gambling assets .",
    "as proved in @xcite the regret satisfies @xmath203 the inequality ( [ eq : cover ] ) therefore states that information divergence decreases when probability measures are projected ( reverse information projection ) into a convex set . here",
    "we should note that information divergence is convex but not strictly convex in the second argument .",
    "therefore the reverse information projection may be non - unique .    in the case where there are only two price relative vectors the optimal portfolio can be calculated exactly .",
    "let @xmath204 denote the two price relative vectors .",
    "without loss of generality we may assume that the indices @xmath152 have been chosen in such a way that @xmath205 if @xmath206 then @xmath207 so that if @xmath208 then @xmath209 and the asset @xmath152 is dominated by the asset @xmath210 since we have assumed that no asset is dominated we may assume that @xmath211 if @xmath212 then according to @xcite the portfolio @xmath213 is log - optimal if and only if @xmath214 for all @xmath215 with equality if @xmath216 assume that the portfolio @xmath217 is log - optimal . then @xmath218 similarly @xmath219 now we have to check that @xmath220 the right hand side equals the determinant @xmath221 which is positive because asset @xmath126 is not dominated by a portfolio based on asset @xmath222 and asset @xmath223 thus the interval @xmath72 $ ] is subdivided into intervals such that all points in an interval are either mapped into a single asset or a portfolio over two consecutive assets .",
    "we see that the portfolio concentrated in asset @xmath126 is optimal for @xmath224 in the interval @xmath225\\ ] ] in the interval between two consecutive intervals of this form the optimal portfolio will be supported on asset @xmath126 and asset @xmath223    since we have assumed that none of the assets are dominated by other portfolios only two of these inequalities can hold with equality .",
    "therefore we may assume that only @xmath226 and @xmath227 are positive .",
    "hence we may assume that there are only two assets .",
    "let @xmath228 denote the measure concentrated on @xmath172 and let @xmath229 denote the measure concentrated on @xmath230 since the measures @xmath228 and @xmath229 are orthogonal we have that @xmath231 now @xmath232\\\\   & = & \\log\\left\\langle \\vec{x}_{i},\\vec{b}_{\\delta_{j}}\\right\\rangle \\end{aligned}\\ ] ] so that @xmath233 .",
    "since the support of @xmath234 is a subset of the support of @xmath235 we have that @xmath236 therefore @xmath237 and @xmath238 must be proportional to the basis vectors . since @xmath237 and @xmath238 are vectors in a @xmath239-dimensional space and their coordinates are non - negative we have that @xmath234 must proportional to a basis vector . since @xmath233 for @xmath240 we have that @xmath235 is parallel with @xmath241",
    "in this section we will introduce various conditions on a bregman divergence . under some mild conditions they turn out to be equivalent .",
    "let @xmath38 denote a regret function defined on the state space of a finite @xmath0-algebra .",
    "if the state space has at least three orthogonal states then the following conditions are equivalent .",
    "* the function @xmath18 equals entropy times a constant plus an affine function .    *",
    "the regret @xmath38 is proportional to information divergence .    *",
    "the regret is monotone , i.e. it satisfies the data processing inequality .    *",
    "the regret is sufficiency stable .    *",
    "the regret is local .    in the rest of this section",
    "we will describe each of these equivalent conditions and prove that they are actually equivalent .",
    "the theorems and proofs will be stated so that they can hold even for more general state spaces than the ones considered in this paper .",
    "let @xmath5 denote an element in a positive cone .",
    "the _ entropy _ of @xmath5 is be defined as @xmath242 where the infimum is taken over all decompositions @xmath243 of @xmath5 into pure states @xmath244 ( extreme points that are 1-dimensional projections ) .",
    "this definition extends a similar definition of the entropy of a state as defined by uhlmann @xcite . using that entropy is decreasing under majorization the entropy of @xmath5",
    "is attained at an orthogonal decomposition @xcite and we obtain the familiar equation @xmath245    in general this definition of entropy does not provide a concave function on a convex set . for instance the entropy of points in the square has local maximum in the four different points .",
    "a characterization of the convex sets with concave entropy functions is lacking .",
    "if the entropy is a concave function then the bregman divergence @xmath246 is called _",
    "information divergence_.    the information divergence is also called _ kullback - leibler divergence _ , _ relative entropy _ or _ quantum relative entropy_. in a jordan algebra",
    "we get @xmath247\\\\   & = \\mathrm{tr}\\left[f\\left(q\\right)-f\\left(p\\right)+\\left(p - q\\right ) f'\\left(q\\right)\\right]\\end{aligned}\\ ] ] where @xmath248 now @xmath249 so that @xmath250 hence @xmath251\\ ] ] and for states @xmath252 it reduces to @xmath253.\\ ] ]      we consider a set @xmath254 of _ feasible transformations _ of the state space . by a feasible transformation we mean a transformation that we are able to perform on the state space before we choose a feasible action .",
    "let @xmath255 denote a feasible transformation and let @xmath16 denote a feasible action .",
    "then @xmath256 is the action @xmath257 thus the set of feasible transformations acts on the set of actions .",
    "if @xmath258 and @xmath259 are feasible transformations then we will assume that @xmath260 is also feasible .",
    "further we will assume that the identity is feasible",
    ". led @xmath261 denote the monoid of feasible transformations .",
    "finally we will assume that @xmath262 is feasible for @xmath263 $ ] so that @xmath261 becomes a convex monoid .",
    "if @xmath259 is a feasible transformation then @xmath264    if @xmath16 is a feasible action then @xmath265 because @xmath256 is a feasible action",
    ". inequality [ eq : aftagende ] follows because @xmath266    since the feasible transformations decrease the value of @xmath18 the set of states with minimal value of @xmath18 is invariant under feasible transformations .",
    "let @xmath267 be a state space .",
    "then the set @xmath268 of transformations @xmath255 such that @xmath269 for all @xmath12 is a convex monoid and for any action @xmath270 we have that @xmath271    it is straight forward to check that @xmath272 is a monoid that is closed under mixing . assume that @xmath270 so that @xmath273 for all states @xmath17 then @xmath274 for all states @xmath5 so that @xmath271    let @xmath259 denote a feasible transformation and let @xmath3 denote a state that minimizes the function @xmath18 . if @xmath38 is a bregman divergence then @xmath275    since @xmath3 maximizes @xmath18 and @xmath18 is differentiable we have @xmath69 . since @xmath3 minimizes @xmath18 and @xmath276 we also have that @xmath277 minimizes @xmath18 and that @xmath278 .",
    "therefore @xmath279 which proves the inequality .",
    "next we introduce the stronger notion of monotonicity .",
    "let @xmath38 denote a regret function on the convex set @xmath159 then @xmath38 is said to be _ monotone _",
    "if @xmath280 for any affine transformation @xmath281    in general a regret function need not be monotone .",
    "consider the convex set @xmath72 $ ] with two actions .",
    "@xmath282 consider the transformation @xmath283 then @xmath259 together with the identity and mixing generate a monoid that is consistent with the actions @xmath27 and @xmath30 let @xmath284 and @xmath285 then @xmath28 is the optimal action for both @xmath2 and @xmath3 so that @xmath286 the optimal action for @xmath287 is @xmath27 and the optimal action for @xmath277 is @xmath30 therefore @xmath288 and we see that a data processing inequality not is fulfilled .",
    "recently it was proved that information divergence on a complex hilbert space decreases under positive trace preserving maps @xcite .",
    "previously this was only known to hold if some extra condition like complete positivity or 2-positivity was assumed @xcite .",
    "information divergence is monotone under any positive trace preserving map on the states of a finite @xmath0-algebra .",
    "any finite @xmath0-algebra @xmath9 can be embedded in @xmath289 and there exist a conditional expectation @xmath290 if @xmath259 is a positive trace preserving map of the density matrices of @xmath9 into it self then @xmath291 is positive and trace preserving on @xmath292 according to mller - hermes and reep @xcite we have @xmath293 for density matrices in @xmath292 in particular this inequality holds for density matrices in @xmath179 and for such matrices we have @xmath294 .",
    "the present definition of sufficiency is based on @xcite , but there are a number of other equivalent ways of defining this concept .",
    "we refer to @xcite where the notion of sufficiency is discussed in great detail .",
    "let @xmath295 denote a family of states and let @xmath259 denote an affine transformation @xmath296 where @xmath11 and @xmath254 denote state spaces .",
    "then @xmath259 is said to be _ sufficient _ for @xmath295 if there exists an affine transformation @xmath297 such that @xmath298 we say that @xmath259 is _ reversible _ if @xmath259 is feasible and there exist a feasible @xmath258 such that @xmath298    if @xmath38 is a regret function and @xmath259 is reversible for @xmath2 and @xmath3 then @xmath299    let @xmath258 denote a reverse of @xmath259 .",
    "then @xmath300 therefore @xmath301 let @xmath16 denote an action that is optimal for @xmath63 then @xmath302 and we see that @xmath303 is optimal for @xmath304 now @xmath305 where the infimum",
    "is taken over actions @xmath16 that are optimal for @xmath63 then @xmath306 so we have @xmath307 the reverse inequality is proved in the same way .    the notion of sufficiency as a property of divergences was introduced in @xcite . the crucial idea of restricting the attention to transformations of the state space into itself was introduced in @xcite .",
    "it was shown in @xcite that a bregman divergence on the simplex of distributions on an alphabet that is not binary determines the divergence except for a multiplicative factor . here",
    "we generalize the notion of sufficiency from bregman divergences to regret functions .",
    "we say that the regret @xmath38 on the state space @xmath267 is _ sufficiency stable _ if @xmath308 for any affine transformation @xmath309 that is sufficient for @xmath310    [ prop : sufficiency]a monotone regret function @xmath38 is sufficiency stable .",
    "assume that the regret function @xmath38 is monotone .",
    "let @xmath2 and @xmath3 denote two states and let @xmath259 and @xmath258 denote transformations on the state space such that @xmath311  .",
    "then @xmath312 hence @xmath313    combining the previous results we get that information divergence is sufficiency stable . under some conditions there",
    "exists an inverse version of proposition [ prop : sufficiency ] stating that if monotonicity holds with equality then the transformation is sufficient . in statistics where the state space is a simplex",
    "this result is well established .",
    "for density matrices over the complex numbers it has been proved for completely positive maps in @xcite .",
    "some new results on this topic can be found in @xcite .",
    "often it is relevant to use the following weak version of the sufficiency property .",
    "the regret function @xmath38 is said to be local if @xmath314 when @xmath2 and @xmath3 are states that are orthogonal to @xmath315 and @xmath3160,1\\right[.$ ]    on a 1-dimensional simplex ( an interval ) or on the block sphere any regret function @xmath38 is local .",
    "the reason is that if @xmath2 and @xmath3 are states that are orthogonal to @xmath315 then @xmath317    any sufficiency stable regret function @xmath38 is local .",
    "let @xmath2 and @xmath3 be states that are orthogonal to @xmath318 let @xmath319 denote tests such that @xmath320 and @xmath321 let the transformations @xmath259 and @xmath258be defined by @xmath322 then @xmath323 and @xmath324 and @xmath325 therefore @xmath326 and @xmath327    the following lemma follows from alexandrov s theorem",
    ". see ( * ? ? ?",
    "* theorem 25.5 ) for details .",
    "a convex function on a finite dimensional convex set is differentiable almost everywhere with respect to the lebesgue measure .",
    "let @xmath11 be a state space on a @xmath328-algebra with at least three orthogonal states .",
    "if a regret function @xmath38 defined on @xmath11 is local then it is a bregman divergence generated by the entropy times some constant .    in the following proof",
    "we will assume that the regret function is based on the convex function @xmath329    let @xmath330 denote the convex hull of a set @xmath331 of orthogonal states .",
    "let @xmath332 denote the function @xmath333 .",
    "note that @xmath332 is decreasing and continuous from the left .",
    "let @xmath334 and @xmath335",
    "if @xmath18 is differentiable in @xmath171 then locality implies that @xmath336 note that @xmath337 is a convex function and thereby it is continuous .",
    "assume that @xmath338 is an arbitrary element in @xmath330 and let @xmath339 denote a sequence such that @xmath340 for @xmath341 the sequence @xmath339",
    "can be choosen so that regret is differentiable in @xmath342 for all @xmath343 further the sequence @xmath342 can be chosen such that @xmath344 is increasing for all @xmath345 then @xmath346 similarly , if the sequence @xmath342 can be chosen such that @xmath344 is increasing for all @xmath347 then @xmath348 which implies that @xmath349 and that @xmath350 for all @xmath126 so that @xmath351 even if the regret is not differentiable in @xmath352    as a function of @xmath102 the regret has minimum when @xmath106 we have @xmath353 where @xmath354",
    "we also have @xmath355 implying that @xmath356 where @xmath357    assume that @xmath358 . then @xmath359 so that @xmath360 is mid - point convex , which for a measurable function implies convexity",
    ". therefore @xmath360 is differentiable from left and right .",
    "we have @xmath361 with equality when @xmath362 we differentiate with respect to @xmath363 from right .",
    "@xmath364 which is positive for @xmath362 @xmath365 since @xmath360 is convex we have @xmath366 which in combination with the previous inequality implies that @xmath367 so that @xmath360 is differentiable . since @xmath368 the function @xmath332 is also differentiable .",
    "we have @xmath369 and @xmath370 we have the condition @xmath371 so using lagrange multipliers we get that there exist a constant @xmath372 such that @xmath373 hence @xmath374 so that @xmath375 for some constant @xmath376    now we get @xmath377 therefore there exists an affine function defined on @xmath330 such that @xmath378 .",
    "if @xmath330 and @xmath379 simplices such that @xmath380 then @xmath381 so that @xmath382 if @xmath383 has dimension greater than zero then the right hand side is affine so the left hand side is affine which is only possible when @xmath384 therefore we also have @xmath385 for all @xmath386 therefore the functions @xmath387 can be extended to a single affine function on the whole of @xmath388    a careful inspection of the previous proof reveals that a convex set with a local bregman divergence must be spectral .",
    "if only integer values of a code - length function @xmath97 are allowed then there are only finitely many actions that are not dominated .",
    "therefore the function @xmath18 given by @xmath389 is piece - wise linear . in particular",
    "it is not proportional to the entropy function and the corresponding regret function does not satisfy monotonicity . in information theory monotonicity of a divergence function is normally called a _ data processing inequality _ and since the data processing inequality is one of the most important tools for deriving inequalities in information theory we need to modify our notion of code - length function in order to achieve a data processing inequality .    we now formulate a version of kraft s inequality that allow the code length function to be non - integer valued .    [",
    "theorem : kraft]let @xmath390 be a function",
    ". then the function @xmath97 satisfies kraft s inequality ( [ eq : kraft ] ) if and only if for all @xmath391 there exists an integer @xmath167 and a uniquely decodable fixed - to - variable length block code @xmath392 such that @xmath393 where @xmath394 denotes the length @xmath395 divided by @xmath396 the uniquely decodable block code can be chosen to be prefix free .",
    "assume that @xmath97 satisfies kraft s inequality .",
    "then @xmath397 therefore the function @xmath398 given by @xmath399 is integer valued and satisfies kraft s inequality and there exists a prefix - free code @xmath400 such that @xmath401 therefore @xmath402 for any @xmath391 choose @xmath167 such that @xmath403    assume that for all @xmath391 there exists a uniquely decodable fixed - to - variable length code @xmath400 such that @xmath404 for all strings @xmath405 then @xmath406 satisfies kraft s inequality and @xmath407 therefore @xmath408 for all @xmath391 and the result is obtained .    like in bayesian statistics we focus on finite sequences .",
    "contrary to bayesian statistics we should always consider a finite sequence as a prefix of _ longer finite _ sequences .",
    "contrary to frequential statistics we do not have to consider a finite sequence as a prefix of an _ infinite _ sequence .",
    "if we minimize the mean code - length over functions that satisfy kraft s inequality but without an integer constraint the code - length should be @xmath409 and the function @xmath18 is given by @xmath410 which is proportional to the shannon entropy and where the proportionality factor is determined by the size of the output alphabet .      in statistics",
    "one is often interested in scoring rules that are local , which means a scoring rule where the payoff only depends on the probability of the observed value and not on the predicted distribution over unobserved values .",
    "the notion of locality has recently been extended by dawid , lauritzen and parry @xcite , but here we shall focus on the original definition .",
    "the basic result is that the only strictly local proper scoring rule is logarithmic score .",
    "a _ strictly local proper scoring rule _ is a scoring rule of the form @xmath411    on a finite space a strictly local scoring rule is given by a local regret function .",
    "the regret function of a strictly local proper scoring rule is given by @xmath412 if @xmath413 and @xmath171 and @xmath102 are mutually singular then @xmath414 and we see that the regret does not depend on @xmath415",
    "because @xmath415 vanish on the support of @xmath196 therefore the regret function is local .    on a finite space with at least three elements a strictly local scoring rule is given by a function @xmath416 of the form @xmath417 for some constants @xmath16 and @xmath418    also the notion of sufficiency plays an important role in statistics . here",
    "we will restrict the discussion to 1-dimensional exponential families .",
    "a natural exponential family is a family of probability distributions of the form @xmath419 where @xmath102 is a reference measure on the real numbers and @xmath420 is the moment generating function given by @xmath421 . then @xmath422 is a sufficient statistic for the family @xmath423    in a bernoulli model a sequence @xmath424 is predicted with probability @xmath425 the function @xmath422 induces a sufficient transformation @xmath259 from probability distributions on @xmath426 to probability distributions on @xmath427 the reverse transformation maps a measure concentrated in @xmath428 into a uniform distributions over sequences @xmath424 that satisfy @xmath429    the mean value of @xmath430 is @xmath431 the set of possible mean values is called the mean value range and is an interval .",
    "let @xmath432 denote the element in the exponential family with mean value @xmath433 then a bregman divergence on the mean value range is defined by @xmath434 note that the mapping @xmath435 is not affine so the bregman divergence @xmath436 will in general not be given by the formula for information divergence with the family of binomial distributions as the only exception .",
    "nevertheless the bregman divergence @xmath436 encode important information about the exponential family .",
    "in statistics it is common to use squared euclidean distance as distortion measure , but often it is better to use the bregman divergence @xmath436 as distortion measure .",
    "note that @xmath436 is only proportional to squared eucledian distance for the gaussian location family .",
    "an exponential distribution has density @xmath437 this leads to a bregman divergence on the interval @xmath438 given by @xmath439 this bregman divergence is called the _ isakura - saito distance_. the isakura - saito distance is defined on an unbounded set so our previous results can not be applied .",
    "affine bijections on @xmath438 have the form @xmath440 for some constant @xmath441 .",
    "the isakura - saito distance is obviouly sufficiency stable for such transformations and it is a simple exercise to check that the isakura - saito distance is the only bregman divergence on @xmath442 $ ] that is sufficiency stable .",
    "any affine transformation @xmath443 is composed of a transformation @xmath444 where @xmath445 and a right translation @xmath446 where @xmath447 the itakura - saito distance decreases under right translations because @xmath448 thus the isakura - saito distance is monotone .",
    "statistical mechanics can be stated based on classical mechanics or quantum mechanics . for our purpose",
    "this makes no difference because our theorems can be applied for both classical systems and quantum systems .",
    "as we have seen before @xmath449 our general results for bregman divergences imply that the bregman divergence based on this exergy satisfies @xmath450 therefore @xmath451 for any transformation that is sufficient for @xmath452 the equality holds for any regret function that is reversible and conserves the state that is in equilibrium with the environment . since a different temperature of the environment leads to a different state that is in equilibrium the equality holds for any reversible transformation that leave some equilibrium state invariant .",
    "we see that @xmath453 is uniquely determined as long as there exists a sufficiently large set of transformations that are reversible .",
    "in this exposition we have made some short - cuts .",
    "first of all we did not derive equation xxx .",
    "in particular the notion of temperature was used without discussion .",
    "secondly we identified the internal energy with the mean value of the hamiltonian and identified the thermodynamic entropy with @xmath142 times the shannon entropy .",
    "finally , in the argument above we need to verify in all details that the set of reversible transformations is sufficiently large to determine the regret function . for classical thermodynamics",
    "the most comprehensive exposition was done by lieb and yngvason @xcite . in their exposition randomness",
    "was not taken into account .",
    "our present framework is able to do so , and it can make a bridge between thermodynamics and statistical mechanics .",
    "a detailed exposition will be given in a future paper .",
    "according to equation ( [ eq : kelvin ] ) any bit of information can be converted into an amount of energy !",
    "one may ask how this is related to the mixing paradox ( a special case of gibbs paradox ) . consider a container divided by a wall with a blue and a yellow gas on each side of the wall .",
    "the question is how much energy can be extracted by mixing the gasses ?",
    "we loose one bit of information about each molecule by mixing the gasses , but if the color is the _ only difference _ no energy can be extracted .",
    "this seems to be in conflict with equation ( [ eq : kelvin ] ) , but in this case different states can not be converted into each other by reversible processes . for instance one can not convert the blue gas into the yellow gas . to get around this problem",
    "one can restrict the set of preparations and one can restrict the set of measurements . for instance one may simply ignore measurements of the color of the gas .",
    "what should be taken into account and what should be ignored , can only be answered by an experienced physicist .",
    "formally this solves the mixing paradox , but from a practical point of view nothing has been solved .",
    "if for instance the molecules in one of the gases are much larger than the molecules in the other gas then a semi - permeable membrane can be used to create an osmotic pressure that can be used to extract some energy .",
    "it is still an open question which differences in properties of the two gases that can be used to extract energy .      according to equation ( [ eq : perfekt ] )",
    "the sufficiency condition is fulfilled in gambling .",
    "[ lem : todim]assume that there are only two possible price relative vectors and that the set of assets is minimal dominating . if the bregman divergence @xmath454 is proportional to information divergence @xmath455 then the set of feasible assets consists of two orthogonal gambling assets .",
    "assume that @xmath456 for all @xmath457 assume that @xmath458 and @xmath459 belong to the same face of the set of feasible portfolios .",
    "let @xmath330 denote the affine span of @xmath458 and @xmath459 in the set of all ideal portfolios .",
    "then @xmath460 for distributions @xmath171 and @xmath102 between @xmath338 and @xmath461 therefore @xmath462 for distributions @xmath171 and @xmath102 between @xmath338 and @xmath463 implying that @xmath464 for a fixed @xmath171 between @xmath338 and @xmath463 we get that @xmath465 this is only possible if the set of feasible portfolios contain all portfolios in @xmath466 hence the set of feasible assets consists of two orthogonal gambling assets .    [ theorem : proper]assume that none of the feasible assets are dominated by a portfolio of other feasible assets . if the bregman divergence @xmath454 is proportional to information divergence @xmath455 the measures @xmath171 and @xmath102 are supported by @xmath142 price relative vectors of the form @xmath467 , @xmath468 until @xmath469    assume that there exists a constant @xmath470 such that @xmath471 if @xmath472 then @xmath473 and @xmath474 and @xmath110 therefore the mapping @xmath475 is injective",
    ". the vectors @xmath192 form a simplex with @xmath142 extreme points .",
    "therefore the simplex of probability measures @xmath171 has at most @xmath142 extreme points , so @xmath171 is supported on at most @xmath142 distinct vectors that we will denote @xmath476 .",
    "assume that @xmath172 and @xmath477 are two vectors of price relatives .",
    "then equation [ eq : propertional ] holds for probability vectors restricted to the set @xmath478 from lemma [ lem : todim ] it follows that @xmath172 and @xmath477 are orthogonal .",
    "therefore all the price relative vectors are orthogonal , and have disjoint supports . since the price relative vectors have disjoint support , an asset can only have a positive price relative for one of the price relative vectors .",
    "therefore each price relative vector has one asset that dominates any other asset in the support of the price relative vector .",
    "since we have assumed none of the assets are dominated each price relative vector is supported on a single asset .",
    "if the price relative vectors are as in theorem [ theorem : proper ] we are in the situation of gambling introduced by kelly @xcite .",
    "assume that the bregman divergence @xmath479 is local for probability measures @xmath171 and @xmath102 supported on @xmath142 price relative vectors where @xmath480 .",
    "then the set of feasible assets contain @xmath142 gambling assets and any other asset is dominated by a portfolio over these gambling assets .",
    "if the bregman divergence is local and one of the assets is the safe asset then there exists a portfolio @xmath147 such that @xmath481 for all @xmath482 equivalently @xmath483 which is possible if and only if @xmath484 one say that the gamble is _ fair _ if @xmath485 . if the gamble is _ super - fair _ , i.e. @xmath486 , then the portfolio @xmath487 gives a price relative equal to @xmath488 independently of what happens , which is a _",
    "dutch book_.    assume that there are at least three distinct price relative vectors .",
    "the bregman divergence ( [ eq : bregman ] ) is local if and only if @xmath489 implies @xmath110    if equation [ eq : perfekt ] does not hold then we do not have locality so the set of possible portfolios can be identified with a convex and proper subset of the set of all portfolios on a set of gambling assets .",
    "then we just have to find to distributions @xmath171 and @xmath102 that have the same reversed information projection into the set of possible portfolios .",
    "the original paper of kullback and leibler @xcite was called `` on information and sufficiency '' . in the present paper",
    "we have made the relation between information divergence and the notion of sufficiency more explicit .",
    "the idea of sufficiency has different consequences in different applications but in all cases information divergence prove to be the quantity that convert the general notion of sufficiency into a number .    in information theory information divergence",
    "appear as a consequence of kraft s inequality . for code length functions of integer length",
    "we get functions that are piecewise linear .",
    "only if we are interested in extendable sequences we get a regret function that satisfies a data processing inequality . in this sense information theory",
    "is a theory of extendable sequences . for scoring functions in statistics",
    "the notion of locality is important .",
    "these applications do not refer to sequences.similarly the notion of sufficiency that plays a major role in statistics does not refer to sequences . both sufficiency and locality imply that regret is proportional to information divergence , but these reasons are different from the reasons why information divergence is used in information theory .",
    "our description of statistical mechanics does not go into all technical details , but the main point is that the many symmetries in terms of reversible transformations form a set of transformations so large that our result on invariance of regret under sufficient transformations applies .",
    "this sense statistical mechanics and statistics both apply information divergence for reasons related to sufficiency . for portfolio theory",
    "the story is different . in most cases one has to apply the general theory of bregman divergences because we deal with an optimization problem .",
    "the general bregman divergences only reduce to information divergence when the assets are gambling assets .",
    "often one talk about applications of information theory in statistics , statistical mechanics and portfolio theory . in this paper",
    "we have argued that information theory is mainly a theory of sequences , while some problems in statistics and statistical mechanics are also relevant without reference to sequences .",
    "for the topics of this paper it would be more correct to say that convex optimization can be applied in both information theory , statistics , statistical mechanics and portfolio theory and that certain conditions related to sufficiency lead to the same type of quantities in different applications .",
    "the author want to thank prasad santhanam for inviting me to the electical engineering department , university of hawaii at mnoa , where many of the ideas presented in this paper were developed .",
    "i also want to thank jan naudts and alexander mller - hermes for stimulating discussions .",
    "gneiting , t. ; raftery , a.e .",
    "strictly proper scoring rules , prediction , and estimation . , _ 102 _ ,  359378 , http://xxx.lanl.gov/abs/http://dx.doi.org/10.1198/016214506000001437 [ [ http://dx.doi.org/10.1198/016214506000001437 ] ] .",
    "gundersen , t. an introduction to the concept of exergy and energy quality .",
    "technical report , department of energy and process engineering , norwegian university of science and technology , trondheim , norway , 2011 .",
    "harremos , p. ; vol .",
    "255 , _ imfufa - tekst _ , imfufa roskilde university , 1993 .",
    "original in danish entitled tid og betinget uafhngighed .",
    "english translation partially available .",
    "harremos , p. proper scoring and sufficiency .",
    "proceeding of the the eighth workshop on information theoretic methods in science and engineering ; rissanen , j. ; harremos , p. ; forchhammer , s. ; roos , t. ; myllymke , p. , eds . ; , 2015 ; number report b-2015 - 1 in series of publications b , pp . 1922 .",
    "an appendix with proofs only exists in the arxiv version of the paper .",
    "lieb , e. ; yngvason , j. , the mathematics of the second law of thermodynamics . in _ visions in mathematics _ ; alon , n. ; bourgain , j. ; connes , a. ; gromov , m. ; milman , v. , eds .",
    "; birkhuser basel , 2010 ; pp . 334358 ."
  ],
  "abstract_text": [
    "<S> logarithmic score and information divergence appear in both information theory , statistics , statistical mechanics , and portfolio theory . </S>",
    "<S> we demonstrate that all these topics involve some kind of optimization that leads directly to the use of bregman divergences . </S>",
    "<S> if the bregman divergence also fulfills a sufficiency condition it must be proportional to information divergence . </S>",
    "<S> we will demonstrate that sufficiency is equivalent to the apparently weaker notion of locality and it is also equivalent to the apparently stronger notion of monotonicity . </S>",
    "<S> these sufficiency conditions have quite different relevance in the different areas of application , and often they are not fulfilled . therefore sufficiency conditions can be used to explain when results from one area can be transferred directly to another and when one will experience differences . </S>"
  ]
}