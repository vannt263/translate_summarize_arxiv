{
  "article_text": [
    "paper considers a general multimessage network which may consist of multiple nodes .",
    "each node may send a message to any other node in the network . under the discrete memoryless model where all the input and output alphabets",
    "are assumed to be finite , the network is referred to as _ discrete memoryless network ( dmn ) _",
    "18 ) . a well - known outer bound on the capacity region of the dmn is the _ cut - set bound _ , developed by el gamal in 1981  @xcite .",
    "this bound states that for any cut - set  @xmath2 of the network with nodes indexed by a set @xmath3 , the sum of the rates of transmission of messages on one side of the cut is bounded above by the conditional mutual information between the input variables in  @xmath2 and the output variables in  @xmath4 given the input variables in  @xmath5 .",
    "the dmn is a generalization of the well - studied discrete memoryless relay channel ( dm - rc ) @xcite .",
    "it is known that the cut - set bound is not tight ( achievable ) in general @xcite , but it is tight ( achievable ) for several classes of dmns , including the degraded dm - rc  @xcite , the degraded dmn @xcite , the semi - deterministic dm - rc  @xcite , the dm - rc with orthogonal sender components @xcite and the linear deterministic multicast network @xcite among others .",
    "one potential drawback of the cut - set bound is the fact that it is only a _ weak converse _ for networks with tight cut - set bound .",
    "this weak converse only guarantees that for any network with tight cut - set bound and any fixed rate vector residing outside the capacity region , the average probabilities of decoding error of any sequence of length-@xmath0 codes operated at the rate vector is bounded away from  @xmath6 as  @xmath0 tends to infinity . in information theory , it is also important to establish a _ strong converse _",
    "statement indicating that there is a sharp phase transition of the minimum achievable asymptotic error probability between rate vectors inside and outside the capacity region in the following sense : any rate vector inside the capacity region can be supported by some sequence of length-@xmath0 codes with asymptotic error probability being  @xmath6 , and the asymptotic error probability of any sequence of length-@xmath0 codes operated at a rate vector outside the capacity region equals  @xmath1 .",
    "a strong converse statement indicates that for any fixed rate vector residing outside the capacity region , the average error probabilities of any sequence of codes operated at the rate vector must necessarily tend to  @xmath1 .",
    "the contrapositive of this statement can roughly be stated as follows : all codes that result in an error probability not exceeding a tolerable error @xmath7 as the block length grows , i.e. , @xmath8-reliable codes , must have rate vectors belonging to the capacity region . as a result , the strong converse statement _ fully characterizes the fundamental limit of all @xmath8-reliable codes_. since @xmath8-reliable codes are of fundamental importance to modern short - packet communications for low - latency applications ( e.g. , online streaming , live data updates , video conferencing and virtual - reality applications ) ,",
    "we are motivated to identify the networks to which the strong converse statement can be applied for characterizing the fundamental limit of @xmath8-reliable codes .",
    "behboodi and piantanida first conjectured the strong converses for dm - rcs  @xcite and dmns  @xcite with tight cut - set bound ( also see the thesis by behboodi  ( * ? ? ?",
    "c ) ) . unfortunately it appears to the present authors that some steps of the proofs , which are based on the information spectrum method @xcite , are incomplete , as will be elaborated upon in remark  [ remark0 ] after the first theorem is stated .    in our prior work @xcite , inspired by the work of polyanskiy and verd  @xcite",
    ", we leveraged properties of the conditional rnyi divergence to prove the strong converse for certain classes of dmns with tight cut - set bound .",
    "these include the linear deterministic multicast network @xcite , the multimessage multicast networks consisting of independent dmcs @xcite and the wireless erasure network @xcite , but excluding the following networks with tight cut - set bound : the degraded dm - rc  @xcite , the degraded dmn @xcite , the semi - deterministic dm - rc  @xcite , and the dm - rc with orthogonal sender components @xcite .",
    "this work significantly strengthens our prior work by proving the strong converse for all dmns with tight cut - set bound including the four aforementioned networks left out by our prior work .",
    "see remark [ remark_compare ] for a more detailed discussion .",
    "our generalization of the strong converse proof for dmns to gaussian networks is not obvious , mainly due to the fact that the strong converse proof for dmns is based on the method of types  ( * ? ? ?",
    "* ch .  2 ) .",
    "indeed , the strong converse property does not hold for gaussian networks with tight cut - set bound in general if long - term power constraints are used instead of peak power constraints , proved by fong and tan for the gaussian degraded rc  @xcite and truong et al .  for the gaussian mac with feedback  @xcite .",
    "being aware that the existing literature lacks a conclusive statement concerning strong converses for gaussian networks , we are motivated to provide a strong converse proof for gaussian networks with tight cut - set bound subject to peak power constraints .",
    "the first contribution of this work is a self - contained proof of the strong converse for dmns with tight cut - set bound .",
    "more precisely , our main result shows that for any given dmn , any rate vector that can be supported by a sequence of codes with asymptotic error probability equal to  @xmath8 must belong to the region prescribed by the cut - set bound as long as @xmath9 .",
    "thus , this result establishes the strong converse for dmns whose cut - set bounds are known to be tight .",
    "so for example , for the degraded dm - rc whose cut - set bound is tight ( i.e. , all rates below the cut - set bound are achievable in the sense that there exist codes with those rates and vanishing error probabilities ) , our strong converse result implies that the error probabilities of any sequence of length-@xmath0 codes operated at a rate above the capacity must necessarily tend to  @xmath1 as  @xmath0 grows . the proof is based on the method of types .",
    "the proof techniques are inspired by the work of csiszr and krner @xcite which fully characterized the reliability function of any discrete memoryless channel ( dmc ) with feedback for rates above capacity ( same as that of the corresponding dmc without feedback ) .",
    "important consequences of this result are new strong converses for the degraded dm - rc  @xcite , the general rc with feedback  @xcite , the degraded dmn @xcite , the semi - deterministic dm - rc  @xcite , and the dm - rc with orthogonal sender components  @xcite .",
    "the second contribution of this work is the generalization of our strong converse proof to gaussian networks where the random noises are modeled to be additive white gaussian and each node is subject to a peak power constraint .",
    "this proof for gaussian networks involves a careful generalization of the method of types for discrete distributions to general distributions .",
    "more specifically , the method of types defined for dmns is based on counting arguments since the input and output alphabets of dmns are finite . on the contrary , the method of types defined for gaussian networks is based on careful approximation and quantization arguments due to the continuous input and output alphabets .",
    "see section  [ awgn : subsecquantize ] for the details regarding the quantization arguments .",
    "there is one key difference between the proof for dmns in section  [ secconverse ] and the proof for gaussian networks in section  [ awgn : secconverse ] : in the proof for gaussian networks , we avoid using conditional types , which can not be easily defined when the correlation between the input symbols and the noises is not negligible .",
    "instead , we modify our definition of joint type classes in definition  [ awgn : definitionjointtypeclass ] so that we can omit the use of conditional types in our proof .",
    "in contrast , the proof for dmns in section  [ secconverse ] relies heavily on the definition of conditional types .",
    "important consequences of this result are new strong converses for the gaussian degraded rc  @xcite , the general gaussian rc with feedback  @xcite , the sender frequency - division gaussian rc  @xcite , and the gaussian multiple access channel ( mac ) with feedback under peak power constraints  @xcite .",
    "this paper is organized as follows .",
    "the notations used in this paper are described in the next subsection .",
    "section  [ sectiondefinition ] presents the problem formulation of the dmn and its  @xmath8-capacity region for @xmath10 , followed by the first main result in this paper  the strong converse for dmns with tight cut - set bound .",
    "section  [ awgn : sectiondefinition ] presents the problem formulation of the gaussian network and its  @xmath8-capacity region for @xmath10 , followed by the second main result of this paper  the strong converse for gaussian networks with tight cut - set bound .",
    "the preliminaries for the proof of the first result are contained in section  [ sectionprelim ] , which includes well - known results based on the method of types .",
    "section  [ secconverse ] presents the proof of the first main result .",
    "the preliminaries for the proof of the second result are contained in section  [ awgn : sectionprelim ] , which explains the construction and quantization of gaussian types .",
    "section  [ awgn : secconverse ] presents the proof of the second main result .",
    "the sets of real and non - negative real numbers are denoted by @xmath11 and @xmath12 respectively .",
    "the @xmath13-dimensional identity matrix is denoted by @xmath14 , the length-@xmath13 all - zero column vector is denoted by @xmath15 , the @xmath16 all - zero matrix is denoted by @xmath17 , and the @xmath16 all - one matrix is denoted by @xmath18 . for any real - valued matrix @xmath19 , we let @xmath20 denote its transpose .",
    "if @xmath19 is a square matrix , we let @xmath21 , @xmath22 and @xmath23 denote the diagonal vector , determinant and trace of @xmath19 respectively .",
    "if @xmath19 is symmetric , we use @xmath24 and @xmath25 to represent that @xmath19 is positive definite and @xmath19 is positive semi - definite respectively .",
    "we let @xmath26 denote the inverse of any invertible matrix  @xmath19 . for any two real - valued matrices @xmath27 and @xmath28 of the same dimension , we use @xmath29 , @xmath30 and @xmath31 to represent the corresponding relations between @xmath27 and @xmath28 entrywise .",
    "we will take all logarithms to base  @xmath32 throughout this paper .",
    "we use @xmath33 to represent the probability of an event  @xmath34 , and we let @xmath35 be the characteristic function of @xmath34 .",
    "every random variable is denoted by a capital letter ( e.g. , @xmath36 ) , and the realization and the alphabet of the random variable are denoted by the corresponding small letter ( e.g. , @xmath37 ) and calligraphic letter ( e.g. , @xmath38 ) respectively .",
    "we use @xmath39 to denote a random tuple @xmath40 , where the components @xmath41 have the same alphabet  @xmath38 .",
    "we let @xmath42 and @xmath43 denote the probability distribution of @xmath36 and the conditional probability distribution of @xmath44 given @xmath36 respectively for any random variables  @xmath36 and  @xmath44 ( can be both discrete , both continuous or one discrete and one continuous ) .",
    "we let @xmath45 denote the joint distribution of @xmath46 , i.e. , @xmath47 for all @xmath37 and @xmath48 . for any function @xmath49",
    "whose domain contains @xmath38 , we use @xmath50 $ ] to denote the expectation of  @xmath51 where @xmath36 is distributed according to @xmath42 . for simplicity",
    ", we drop the subscript of a notation if there is no ambiguity . for any discrete random variable @xmath52 distributed according to @xmath53 , we let @xmath54 or more simply @xmath55 denote the entropy of @xmath36 given @xmath56 , and let @xmath57 or more simply @xmath58 denote the mutual information between @xmath36 and @xmath44 given @xmath56 .",
    "the relative entropy between @xmath43 and @xmath59 given @xmath60 is denoted by @xmath61 .",
    "the @xmath62-distance between two distributions @xmath42 and @xmath63 on the same discrete alphabet @xmath38 , denoted by @xmath64 , is defined as @xmath65 . for any @xmath13-dimensional real - valued gaussian vector @xmath66^t$ ]",
    "whose mean and covariance are @xmath67 and  @xmath68 respectively , we let @xmath69 be the corresponding probability density function .",
    "we consider a general network that consists of  @xmath13 nodes .",
    "let @xmath70 be the index set of the nodes .",
    "the @xmath13 terminals exchange information in @xmath0 time slots as follows .",
    "node  @xmath71 chooses message @xmath72 according to the uniform distribution from the alphabet @xmath73 and sends @xmath72 to node  @xmath74 for each @xmath75 , where @xmath76 characterizes the rate of message  @xmath72 and all the messages are mutually independent . for each @xmath77 and each @xmath78",
    ", node  @xmath71 transmits @xmath79 , a function of @xmath80 and @xmath81 , and receives @xmath82 in the @xmath83 time slot where @xmath84 and @xmath85 are some alphabets that possibly depend on  @xmath71 .",
    "after  @xmath0 time slots , node  @xmath74 declares  @xmath86 to be the transmitted  @xmath72 based on @xmath87 and @xmath88 for each @xmath89 .",
    "to simplify notation , we use the following conventions for each @xmath90 : for any random vector @xmath91^t \\in \\mathcal{x}_1\\times \\mathcal{x}_2 \\times \\ldots \\times \\mathcal{x}_n,\\ ] ] we let @xmath92^t\\ ] ] be the subvector of @xmath93^t$ ] and @xmath94 be the alphabet of @xmath95 .",
    "similarly , for any @xmath77 and any random vector @xmath96^t \\in \\mathcal{x}_1\\times \\mathcal{x}_2 \\times \\ldots \\times \\mathcal{x}_n,\\ ] ] we let @xmath97^t\\ ] ] be the subvector of @xmath98^t$ ] .",
    "for any @xmath99 and any @xmath100-dimensional random vector @xmath101^t \\in \\mathcal{w}_{1,1}\\times \\mathcal{w}_{1,2}\\times \\ldots \\times \\mathcal{w}_{n , n},\\ ] ] we let @xmath102\\ ] ] be the subtuple of @xmath103^t$ ] .",
    "the following six definitions formally define a dmn and its capacity region .",
    "[ discretememoryless ] a discrete network consists of @xmath13 finite input sets @xmath104 , @xmath13 finite output sets @xmath105 and a transition matrix @xmath106 . the discrete network is denoted by @xmath107 . for every @xmath108 , the marginal distribution @xmath109 is defined as @xmath110 for all @xmath111 and all @xmath112 .",
    "[ defcode ] let @xmath107 be a discrete network .",
    "an @xmath113-code , where @xmath114^t \\ge \\mathbf{0}_{n^2}$ ] denotes the @xmath100-dimensional rate vector , for @xmath0 uses of the network consists of the following :    1 .",
    "a message set @xmath115 at node  @xmath71 for each @xmath89 as defined in  .",
    "message @xmath72 is uniform on @xmath115 .",
    "an encoding function @xmath116 for each @xmath78 and each @xmath117 , where @xmath118 is the encoding function at node  @xmath71 in the @xmath83 time slot such that is @xmath119 . ] @xmath120 3 .   a decoding function @xmath121 for each @xmath122 , where @xmath123 is the decoding function for @xmath124 at node  @xmath71 such that @xmath125    [ defdiscretememoryless ] a discrete network @xmath107 , when used multiple times , is called a _ discrete memoryless network ( dmn ) _",
    "if the following holds for any @xmath113-code :    let @xmath126 be the collection of random variables that are generated before the @xmath83 time slot .",
    "then , for each @xmath117 and each @xmath108 , @xmath127 holds for all @xmath128 , @xmath129 and @xmath130 .",
    "[ cutseterrorprobability ] for an @xmath113-code , we can calculate the average probability of decoding error defined as @xmath131 we call an @xmath113-code with average probability of decoding error no larger than @xmath132 an @xmath133-code .",
    "[ cutsetachievable rate ] a rate vector @xmath134 is _",
    "@xmath8-achievable _ if there exists a sequence of @xmath133-codes such that @xmath135 .",
    "without loss of generality , we assume that @xmath136 for all @xmath78 in the rest of this paper .",
    "[ cutsetcapacity region ] the _ @xmath8-capacity region _ , denoted by @xmath137 , of the dmn is the closure of the set consisting of every @xmath8-achievable rate vector @xmath138 with @xmath136 for all @xmath78 .",
    "the _ capacity region _ is defined to be 0-capacity region @xmath139 .",
    "the following theorem is the first main result in this paper .",
    "[ thmmainresult ] let @xmath107 be a dmn .",
    "define @xmath140{2.75 in}{$ \\sum\\limits _ { ( i , j)\\in t\\times t^c } r_{i , j }   \\le   i_{p_{x_{\\mathcal{i}}}q_{y_{t^c}|x_\\mathcal{i}}}(x_t ; y_{t^c}|x_{t^c}),\\\\   r_{i , i}=0 \\text { for all } i\\in\\mathcal{i}$ } \\right.\\right\\}. \\label{rcutset}\\ ] ] then for each @xmath141 , @xmath142    [ remark0 ] the authors in  @xcite conjectured that the strong converse holds for general dmns with tight cut - set bound and they employed information spectrum techniques",
    ". however , the fourth equality of the chain of equalities after equation ( c.8 ) in @xcite need not hold , which implies that the first step of their proof in ( * ? ? ?",
    "* section iv.b ) is incomplete .",
    "consequently , their proof has a gap .",
    "our proof of theorem  [ thmmainresult ] does not use information spectrum methods .",
    "rather , we use the method of types to establish a strong converse for dmns with tight cut - set bound .",
    "[ remark1 ] we observe from theorem  [ thmmainresult ] that the cut - set bound characterized by is a universal outer bound on @xmath137 for all @xmath143 , which implies the strong converse for the class of dmns whose cut - set bounds are achievable . as mentioned in section  [ subsubsec1stcontribution ] , the class includes the degraded dm - rc  @xcite , the general rc with feedback  @xcite , the degraded dmn  @xcite , the semi - deterministic dm - rc  @xcite , and the dm - rc with orthogonal sender components  @xcite .",
    "[ remark_compare ] theorem  [ thmmainresult ] establishes the strong converse for any dmn with tight cut - set bound under the _ multiple unicast demand _ where each node has a unique message to send to each other node . by slightly changing the definition of _ multiple unicast _ codes to _ multimessage multicast _ codes and modifying the definition of @xmath8-achievable rates , we can follow almost the same steps as in the proof of theorem  [ thmmainresult ] and derive the strong converse for dmns with tight cut - set bound under the _ multimessage multicast demand _ where each source node sends a single message and each destination node wants to recover all the source messages .",
    "this strong converse result under the multimessage multicast demand strengthens our prior strong converse result  @xcite established for some classes of multicast networks with tight cut - set bound . to be more explicit",
    ", our prior strong converse result specialized to the multiple unicast demand scenario states that @xmath144 for all @xmath9 , where @xmath145{2.75 in}{$ \\sum\\limits _ { ( i , j)\\in t\\times t^c } r_{i , j }   \\le   i_{p_{x_{\\mathcal{i}}}q_{y_{t^c}|x_\\mathcal{i}}}(x_t ; y_{t^c}|x_{t^c}),\\\\   r_{i , i}=0 \\text { for all } i\\in\\mathcal{i}$ } \\right.\\right\\}. \\label{rcutset2}\\ ] ] comparing to , we observe that the union and intersection are swapped and consequently , @xmath146 with strict inequality for many classes of networks .",
    "thus , theorem [ thmmainresult ] is considerably stronger than the main theorem in @xcite .",
    "in particular , theorem [ thmmainresult ] establishes the strong converse for the following four networks : the physically degraded dm - rc , the physically degraded dmn , the semi - deterministic dm - rc , and the dm - rc with orthogonal sender components .",
    "strong converses for these important networks were not proved in our previous paper @xcite .",
    "the proof of theorem  [ thmmainresult ] is based on the method of types  @xcite , which is completely different compared to the rnyi divergence approach in our prior work  @xcite .",
    "it seems challenging ( to the authors ) to use other standard strong converse proof techniques to prove theorem  [ thmmainresult ] such as the rnyi divergence approach  @xcite , the information spectrum method @xcite and the blowing - up lemma ( * ? ? ?",
    "* ch .  5 )",
    "@xcite .",
    "[ remark3 ] the proof of theorem  [ thmmainresult ] implies that for any fixed rate vector @xmath138 lying outside the cut - set bound @xmath147 , the average probabilities of correct decoding of any sequence of @xmath113-codes tend to  0 exponentially fast .",
    "see   in the proof for the derived upper bound on the non - asymptotic probability of correct decoding .",
    "in other words , we have proved an _ exponential strong converse _ for networks with tight cut - set bound ( cf .",
    "oohama s works in  @xcite and  @xcite that established exponential strong converse for broadcast channels ) .",
    "we leave the exact characterization of the strong converse exponent to future work .",
    "the proof of theorem  [ thmmainresult ] is inspired by two works which are based on the method of types  @xcite .",
    "first , tan showed in  @xcite that the proof techniques used for analyzing the reliability functions of dmcs with feedback can be applied to dm - rcs .",
    "second , csiszr and krner  @xcite fully characterized the reliability functions of any dmc with feedback for rates above capacity .",
    "we use those ideas in the proof of theorem [ thmmainresult ] .",
    "[ example1 dm ] consider a @xmath148-node dm - rc where the source is indexed by  1 , the relay is indexed by  2 and the destination is indexed by  3 .",
    "the capacity of the dm - rc is unknown in general .",
    "however , if there exists a noiseless feedback link which carries @xmath149 to node  2 in each time slot  @xmath150 , then the capacity of the resultant dm - rc with feedback coincides with the cut - set bound ( * ? ? ?",
    "17.4 ) , which is intuitively true because the feedback link transforms the dm - rc into a physically degraded dm - rc .",
    "consequently , theorem  [ thmmainresult ] implies that the dm - rc with feedback to the relay satisfies the strong converse property .",
    "in addition , inserting two noiseless feedback links which carry @xmath151 and @xmath149 to node  1 in each time slot  @xmath150 does not further increase the capacity of the dm - rc with feedback , and hence the strong converse property also holds under this setting .",
    "in this section , we consider the gaussian network whose channel law is described below . for each @xmath77 and each @xmath78",
    ", node  @xmath71 transmits @xmath152 , a function of @xmath153 and @xmath81 , and receives @xmath154 in the @xmath83 time slot , where @xmath155 characterizes the constant channel gain associated with the signal path starting from node  @xmath74 and ending at node  @xmath71 and @xmath156 denotes the additive gaussian noise experienced by node  @xmath71 . each node @xmath78 is subject to the peak power constraint @xmath157 where @xmath158 is some constant specifying the admissible power for node  @xmath71 . to facilitate discussion , we define @xmath159^t$ ] and @xmath160^t$ ] , and let @xmath161_{(i , j)\\in\\mathcal{i}\\times \\mathcal{i } } $ ] be the @xmath162 channel gain matrix that does not depend on  @xmath150 .",
    "in addition , let @xmath163^t$ ] be a zero - mean gaussian vector with some covariance matrix  @xmath164 where  @xmath165 characterizes the correlation among the  @xmath13 gaussian noises .",
    "the relation between @xmath166 and @xmath167 can be written as follows for each @xmath117 : @xmath168 after  @xmath0 time slots , node  @xmath74 declares  @xmath86 to be the transmitted  @xmath72 based on @xmath87 and @xmath88 for each @xmath89 .",
    "to simplify notation , we use the following convention for any @xmath99 : for any @xmath162 matrix @xmath169_{(i , j)\\in \\mathcal{i}\\times \\mathcal{i}},\\ ] ] we let @xmath170_{(i , j)\\in t_1\\times t_2}\\ ] ] denote the submatrix of @xmath171 .",
    "[ awgn : defcode ] an @xmath172-code , where @xmath173^t > \\mathbf{0}_n$ ] denotes the @xmath13-dimensional vector that specifies the admissible power , for the gaussian network is an @xmath113-code defined in definition  [ defcode ] with the following extra assumptions : @xmath174 and the power constraint   is satisfied for each @xmath122 .",
    "[ awgn : defdiscretememoryless ] a gaussian network , denoted by @xmath175 , is characterized by a channel gain matrix @xmath176 , an @xmath162 real - valued covariance matrix @xmath164 , and a transition matrix @xmath106 where @xmath177 such that the following holds for any @xmath172-code : let @xmath126 be the collection of random variables that are generated before the @xmath83 time slot .",
    "then , for each @xmath117 and each @xmath108 , @xmath178 holds for all @xmath179 , @xmath180 and @xmath181 , where @xmath109 is the marginal distribution of @xmath106 defined as @xmath182 for all @xmath183 and all @xmath184 .",
    "the average probability of decoding error for an @xmath172-code is defined in a similar way to definition  [ cutseterrorprobability ] , and @xmath185 is said to be _",
    "@xmath8-achievable _ if there exists a sequence of @xmath186-codes such that @xmath135 .",
    "the _ @xmath8-capacity region _ , denoted by @xmath137 , of the gaussian network is the closure of the set consisting of every @xmath8-achievable rate vector .",
    "the _ capacity region _ is defined to be the @xmath6-capacity region @xmath139 .",
    "the following theorem is the second main result of this paper .",
    "[ awgn : thmmainresult ] let @xmath175 be a gaussian network",
    ". for each covariance matrix  @xmath187 and each @xmath90 , let @xmath188 denote the conditional covariance of @xmath95 given @xmath189 when @xmath190 , i.e. , @xmath191 ) ( x_t-\\e[x_t|x_{t^c}])^t\\left| x_{t^c } \\right.\\right]\\right ] .",
    "\\label{awgn : conditionalvar } \\ ] ] define @xmath192 to be the set of covariance matrices that characterize the correlation among the transmitted symbols .",
    "define @xmath193{3.9 in}{$ \\sum\\limits _ { ( i ,",
    "j)\\in t\\times t^c } r_{i , j }   \\le   \\frac{1}{2}\\log\\left|i_{|t^c| } + g_{t^c\\times t}k_{t|t^c}g_{t^c\\times t}^t \\left(\\sigma_{t^c\\times t^c}\\right)^{-1}\\right|,\\\\   r_{i , i}=0 \\text { for all } i\\in\\mathcal{i}$ } \\right.\\right\\}. \\label{awgn : rcutset}\\ ] ] then for each @xmath141 , @xmath194    [ awgn : remark1 ] we observe from theorem  [ awgn : thmmainresult ] that the cut - set bound characterized by is a universal outer bound on @xmath137 for all @xmath143 , which implies the strong converse for the class of gaussian networks whose cut - set bounds are achievable .",
    "gaussian degraded rc  @xcite , the general gaussian rc with feedback  @xcite , the sender frequency - division gaussian rc  @xcite , and the gaussian mac with feedback under peak power constraints  @xcite    [ awgn : remark3 ] the proof of theorem  [ awgn : thmmainresult ] implies that for any fixed rate vector @xmath138 lying outside the cut - set bound @xmath147 , the average probabilities of correct decoding of any sequence of @xmath172-codes tend to  0 exponentially fast .",
    "see   in the proof for the derived upper bound on the non - asymptotic probability of correct decoding .",
    "in other words , we have proved an _ exponential strong converse _ for gaussian networks with tight cut - set bound ( cf .",
    "oohama s works in  @xcite and  @xcite that established exponential strong converse for broadcast channels ) .",
    "we leave the exact characterization of the strong converse exponent to future work .",
    "[ awgn : remarkrelaychannel ] consider a @xmath148-node gaussian rc where the source is indexed by  1 , the relay is indexed by  2 and the destination is indexed by  3 .",
    "suppose nodes  1 and  2 are subject to the peak power constraints  .",
    "the capacity of this gaussian rc is unknown in general .",
    "however , if there exists a noiseless feedback link which carries @xmath149 to node  2 in each time slot  @xmath150 , then the capacity of the resultant gaussian rc with feedback coincides with the cut - set bound ( * ? ? ?",
    "17.4 ) , which is intuitively true because the feedback link transforms the gaussian rc into a gaussian degraded rc .",
    "consequently , theorem  [ awgn : thmmainresult ] implies that the gaussian rc with feedback to the relay satisfies the strong converse property .",
    "in addition , inserting two noiseless feedback links which carry @xmath151 and @xmath149 to node  1 in each time slot  @xmath150 does not further increase the capacity of the dm - rc with feedback , and hence the strong converse property also holds under this setting .",
    "however , if the peak power constraints   are replaced with the long - term power constraints @xmath195 \\le p_i ,   \\label{awgn : ltpconstraints }   \\end{aligned}\\ ] ] the gaussian rc no longer satisfies the strong converse property  @xcite .",
    "[ awgn : remarkmacfeedback ] consider a @xmath196-source gaussian mac with feedback where the two sources are indexed by  1 and  2 respectively .",
    "suppose nodes  1 and  2 are subject to the peak power constraints  .",
    "in addition , there exists a noiseless feedback link which carries @xmath197 to both nodes  1 and  2 in each time slot  @xmath150 . although the achievability scheme that achieves the cut - set bound proposed by ozarow  @xcite satisfies only the long - term power constraint in  , it can be easily modified so that the peak power constraints   are satisfied .",
    "therefore , the capacity of this gaussian mac with feedback coincides with the cut - set bound .",
    "consequently , theorem  [ awgn : thmmainresult ] implies that the gaussian mac with feedback satisfies the strong converse property .",
    "however , if the peak power constraints   are replaced with the long - term power constraints  , the gaussian rc no longer satisfies the strong converse property  @xcite .",
    "the following definitions and results are standard ( * ? ? ? * ch .  2 ) .",
    "the _ type _ of a sequence @xmath198 , denoted by @xmath199}$ ] , is the empirical distribution of @xmath200 , i.e. , @xmath201}(a ) \\stackrel{\\text{def}}{= } \\frac{n(a| x^n)}{n}\\ ] ] for all @xmath202 where @xmath203 denotes the number of occurrences of the symbol @xmath204 in @xmath200 .",
    "the set of all possible types of sequences in @xmath205 is denoted by @xmath206 } \\ , \\right| x^n \\in \\mathcal{x}^n   \\right\\}.\\ ] ] similarly , the set of all possible types of sequences in @xmath207 conditioned on a type @xmath208 is denoted by @xmath209}=r_x$ and $ \\phi_{x , y}^{[(x^n , y^n)]}=r_x s_{y|x}$ }   \\right\\}.\\ ] ] for a given type @xmath210 , the _ type class _ of @xmath60 is defined as @xmath211 }   = r_x \\right.\\right\\}.\\ ] ] a well - known upper bound on the number of types is @xmath212 we will frequently use the following fact without explicit explanation : for each @xmath210 , each @xmath213 and each transition matrix @xmath59 , the following equality holds for any @xmath214 : @xmath215",
    "in this section , we will show that for all @xmath10 @xmath216 where @xmath147 is as defined in  .",
    "it suffices to show that for any @xmath217 and any sequence of @xmath133-codes , @xmath218 to this end , we fix a rate vector  @xmath217 and a sequence of @xmath219-codes .",
    "since @xmath217 and @xmath147 is closed , we can always find a positive number denoted by @xmath220 such that for any distribution @xmath221 defined on @xmath222 , there exists a @xmath223 that satisfies @xmath224 where the shorthand notation @xmath225 is used to denote @xmath226 .",
    "[ [ simplifying - the - correct - decoding - probability - by - using - the - discrete - memoryless - property ] ] simplifying the correct decoding probability by using the discrete memoryless property ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    fix a natural number  @xmath0 and let @xmath227 be the probability distribution induced by the @xmath133-code .",
    "unless specified otherwise , the probabilities are evaluated according to  @xmath227 in the rest of the proof .",
    "consider the probability of correct decoding @xmath228 in order to simplify the rhs of  , we write for each @xmath229 @xmath230 where ( a ) follows from definitions  [ defcode ] and  [ defdiscretememoryless ] .    [",
    "[ further - simplifying - the - correct - decoding - probability - by - using - the - method - of - types ] ] further simplifying the correct decoding probability by using the method of types ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    with a slight abuse of notation , we let @xmath231 for each @xmath122 .",
    "for each @xmath232 , each type @xmath233 and each conditional type @xmath234 , we define @xmath235 and define for each @xmath108 and each @xmath236 @xmath237{2.65 in}{$((f_i(w_{\\{i\\}\\times \\mathcal{i } } , y_i^n):i\\in t^c ) , y_{t^c}^n)\\in \\mathcal{t}_{u_{x_{t^c } , y_{t^c}}}^{(n)}$ where $ u_{x_{t^c } , y_{t^c}}$ is the marginal type\\\\ of $ r_{x_\\mathcal{i}}s_{y_{t^c}|x_\\mathcal{i}}$ restricted to $ ( x_{t^c } , y_{t^c})$ } \\right.\\right\\}. \\label{defsetf}\\ ] ] note that the set @xmath238 in   also plays a crucial role in the proof of the upper bound on the reliability functions for dm - rcs in  @xcite . following   and adopting the shorthand notation @xmath239 to denote the set in  ,",
    "since the collection of sets @xmath240 forms a partition on @xmath241 for each @xmath242 , the probability of correct decoding conditioned on @xmath243 can be expressed as @xmath244    [ [ bounding - the - correct - decoding - probability - in - terms - of - mathcalf_tw_tctimes - mathcalirs ] ] bounding the correct decoding probability in terms of @xmath245 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    fix any arbitrary @xmath108 .",
    "define @xmath246 to simplify notation . in order to simplify the rhs of",
    ", we consider the innermost product .",
    "in particular , we consider the following chain of equalities for each @xmath247 , each @xmath248 , each @xmath242 , and each @xmath249 : @xmath250 where ( b ) follows from definition  [ defdiscretememoryless ] and the fact that @xmath249 ( recall the definition of @xmath251 in ) . following   and letting @xmath245 denote the set in  , we consider the following chain of inequalities for each @xmath247 and each @xmath248 : @xmath252 where    1",
    ".   follows from the definitions of @xmath239 and @xmath245 in   and   respectively .",
    "2 .   follows from the fact that for each @xmath253 and each @xmath254 , @xmath255 ( the last equality is a consequence of the simple fact that @xmath256 is a function that outputs values in @xmath257 for each @xmath122 ) .      for each @xmath247 and each @xmath248 , we let @xmath258 denote the marginal type induced by @xmath259 in order to obtain an upper bound on @xmath260 as follows . for each @xmath247 , each @xmath248 and each @xmath236 , since @xmath261 it follows that @xmath262 ( recall the definition of  @xmath245 in  ) , which implies that @xmath263 which then implies that @xmath264 we have for each @xmath247 and each @xmath248 @xmath265 note that   resembles ( * ? ? ?",
    "* eq .  ( 5 ) ) in the proof of the reliability functions for dmcs with feedback .",
    "[ [ bounding - the - correct - decoding - probability - in - terms - of - mathcalaw_mathcalitimes - mathcali - r - s ] ] bounding the correct decoding probability in terms of @xmath239 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~        for each @xmath247 , each @xmath248 and each @xmath242 , since @xmath268 it follows that @xmath269 ( recall the definition of  @xmath267 in  ) , which implies that @xmath270 which then implies that latexmath:[\\ ] ] consequently , and   follow from   and   respectively .",
    "a.  behboodi , `` cooperative networks with channel uncertainty , '' ph.d .",
    "dissertation , department of telecommunications , suplec ( cole suprieure dlectricit ) , 2012 .",
    "[ online ] .",
    "available : http://tel.archives-ouvertes.fr/tel-00765429"
  ],
  "abstract_text": [
    "<S> this paper considers a multimessage network where each node may send a message to any other node in the network . under the discrete memoryless model , </S>",
    "<S> we prove the strong converse theorem for any network with tight cut - set bound , i.e. , whose cut - set bound is achievable . </S>",
    "<S> our result implies that for any network with tight cut - set bound and any fixed rate vector that resides outside the capacity region , the average error probabilities of any sequence of length-@xmath0 codes operated at the rate vector must tend to  @xmath1 as  @xmath0 grows . the proof is based on the method of types . </S>",
    "<S> the proof techniques are inspired by the work of csiszr and krner in 1982 which fully characterized the reliability function of any discrete memoryless channel ( dmc ) with feedback for rates above capacity . </S>",
    "<S> in addition , we generalize the strong converse theorem to the gaussian model where each node is subject to a peak power constraint . important consequences of our results are new strong converses for the gaussian multiple access channel ( mac ) with feedback and the following relay channels under both models : the degraded relay channel ( rc ) , the rc with orthogonal sender components , and the general rc with feedback .    </S>",
    "<S> capacity region , cut - set outer bound , method of types , multimessage network , strong converse . </S>"
  ]
}