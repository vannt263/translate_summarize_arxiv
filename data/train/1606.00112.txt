{
  "article_text": [
    "nearest - neighbor search is a fundamental problem in data management .",
    "it has applications in such diverse areas as spatial databases , information retrieval , data mining , pattern recognition , etc . in its simplest form",
    ", it asks for preprocessing a set @xmath0 of @xmath1 points in @xmath2 into @xmath3 so that given any query point @xmath4 , the nearest neighbor ( @xmath5 ) of  @xmath4 in  @xmath0 can be reported efficiently .",
    "this problem has been studied extensively in database , machine learning , and computational geometry communities , and is now relatively well understood . however , in some of the applications mentioned above , data are imprecise and are often modeled as probabilistic distributions .",
    "this has led to a flurry of research activities on query processing over probabilistic data , including the problem ; see  @xcite for surveys on uncertain data , and see , e.g. ,  @xcite for application scenarios of search under uncertainty .    despite many efforts devoted to the probabilistic problem",
    ", it still lacks a theoretical foundation . specifically , not only are we yet to understand its complexity ( is the problem inherently more difficult than on precise data ? ) , but we also lack efficient algorithms to solve it . furthermore ,",
    "existing solutions all use heuristics without nontrivial performance guarantees .",
    "this paper addresses some of these issues .",
    "an uncertain point @xmath6 in @xmath7 is represented as a continuous probability distribution defined by a probability density function ( ) @xmath8 ; @xmath9 may be a parametric such as a uniform distribution or a gaussian distribution , or may be a non - parametric such as a histogram .",
    "the uncertainty region of  @xmath6 ( or the support of  @xmath9 ) is the set of points for which @xmath9 is positive , i.e. , @xmath10 @xmath11 .",
    "we assume @xmath6 has a bounded uncertainty region : if @xmath9 is gaussian , we work with the truncated gaussian , as in  @xcite",
    ". we also consider the case where @xmath6 is represented as a discrete distribution defined by a finite set @xmath12 along with a set of _ location probabilities _ @xmath13 $ ] , where @xmath14 $ ] and @xmath15 ; and we say that @xmath6 has a discrete distribution of _ description complexity _ @xmath16 .",
    "let @xmath17 be a set of @xmath1 uncertain points in  @xmath7 , and let @xmath18 be the euclidean distance .",
    "fix a point @xmath19 and an integer @xmath20 .",
    "we define @xmath21 to be the probability of @xmath22 being the nearest neighbor of @xmath4 , referred to as the quantification probability of @xmath4 ( for @xmath23 ) .",
    "next , let @xmath24 be the of the distance between @xmath4 and @xmath23 .",
    "that is , @xmath25   / { { \\ifmmode{\\rm d}\\else{\\mbox{\\(\\rm d\\)}}\\fi}{r}}.\\end{aligned}\\ ] ] see for an example of @xmath24 .",
    "let @xmath26 denote the cumulative distribution function ( ) of the distance between @xmath4 and @xmath23 .",
    "note that if @xmath23 is the nn of @xmath4 and @xmath27 then @xmath28 for all @xmath29 .",
    "therefore @xmath30 can be expressed as follows : @xmath31    if @xmath23 s are represented by discrete distributions , then can be rewritten as follows : @xmath32 where @xmath33    given a set @xmath34 of @xmath1 uncertain points , the probabilistic nearest neighbor ( @xmath35 ) problem is to preprocess @xmath34 into @xmath3 so that , for any given query point @xmath4 , we can efficiently return all pairs @xmath36 with @xmath37 .    [ cols=\"^,^,^ \" , ]     [ fig : bounded_ratio ]",
    "they are interior - disjoint ,    their radii lie in the interval @xmath38 $ ] ,    they are contained in the aforementioned ring , and    the area of each such disk is at least @xmath39 .",
    "hence , the number of removed disks is @xmath40 .",
    "consider the circle @xmath41 of radius @xmath42 centered at  @xmath43 .",
    "consider any disk @xmath44 and its witness disk @xmath45 touching both @xmath46 and @xmath47 from the outside .",
    "if @xmath48 has not been removed from  @xmath49 , then @xmath50 ; in particular it is larger than @xmath51 and the center of @xmath52 lies outside @xmath41 .",
    "let @xmath53 be the disk concentric with @xmath45 with radius @xmath54 , where @xmath55 .",
    "the interior of @xmath53 is disjoint from all disks in @xmath49 , as @xmath48 touches @xmath45 from inside and @xmath45 does not fully contain any other disks from @xmath49 .",
    "the witness disk @xmath45 covers an arc of length at least @xmath51 on  @xmath41 .",
    "indeed , neither of these two disks contains the center of the other , and the inner distance between the two intersection arcs is @xmath51 , see figure on the right .",
    "similarly , let @xmath56 be the arc @xmath57 .",
    "by the same argument , we have that @xmath56 is of length at least @xmath58 .",
    "the circumference of @xmath41 is @xmath59 , so if the arcs @xmath56 , for @xmath44 , are pairwise disjoint , we are done , as this implies that there could be at most @xmath60 such arcs and thus the size of the original @xmath49 , including the disks that were deleted from @xmath49 is @xmath61 .",
    "see ( b ) .",
    "we now prove the claim that for any two disks @xmath62 realizing a top tangency event , @xmath56 and @xmath63 are disjoint .",
    "let @xmath45 ( resp .",
    "@xmath64 ) be the witness disk that is tangent to @xmath65 and @xmath48 ( resp .",
    "@xmath66 ) .",
    "assume that the tangency of @xmath45 with @xmath47 is clockwise to the tangency of @xmath64 with @xmath47 ( i.e. , @xmath48 is `` above '' @xmath66 ) .",
    "if @xmath53 and @xmath67 are disjoint then the corresponding arcs @xmath56 and @xmath63 are obviously disjoint , so assume that @xmath53 and @xmath67 intersect ; see ( c ) .",
    "let @xmath68 be the center of @xmath67 .",
    "we define three circular arcs on @xmath69 .",
    "let @xmath70 , let @xmath71 be the portion of @xmath69 lying in the disk bounded by @xmath72 , and let @xmath73 be the portion of @xmath74 lying in the wedge formed by the rays @xmath75 and @xmath76 ; see ( d ) .",
    "it can be verified that @xmath77 and the right endpoint of @xmath73 lies inside @xmath72 and thus on @xmath71 .",
    "next , let @xmath78 be the intersection point of @xmath69 with the segment connecting @xmath68 and the center of @xmath66 ; since @xmath66 lies in the exterior of @xmath67 , @xmath79 exists . since @xmath66 realizes a top tangency event , @xmath80 .",
    "furthermore , @xmath66 lies in the exterior of @xmath53 and @xmath81 , which implies that @xmath82 and it lies to the right of @xmath83 .",
    "similarly , @xmath66 lies in the exterior of @xmath72 and the right endpoint of @xmath73 lies on @xmath71 , therefore @xmath79 lies to the left of the arc @xmath71 . in other words",
    ", @xmath79 separates @xmath83 and @xmath71 , implying that @xmath84 , which in turn implies that the top endpoint of @xmath63 does not lie inside @xmath53 .",
    "hence , @xmath85 , as claimed .",
    "finally , we repeat the above counting argument , for @xmath86 , where @xmath87 , concluding that the number of intersection points between @xmath88 and @xmath89 is bounded by @xmath90 .",
    "this completes the proof of the lemma .",
    "[ theo : continuous:2 ] let @xmath91 be a set of @xmath1 uncertain points in @xmath7 such that their uncertainty regions are pairwise - disjoint disks and that the ratio of the largest and the smallest radii of the disks is at most @xmath92 .",
    "then , the complexity of @xmath93 is @xmath94 , and it can be computed in @xmath95 expected time , where @xmath96 is the complexity of @xmath93 .",
    "furthermore , there exists such a set @xmath34 of uncertain points for which @xmath93 has @xmath97 complexity .",
    "figs / lb_dd_eq_r    [ fig : l : b : d : d : s : r ]    the upper bound on the complexity of @xmath93 follows from . by the same argument as in the proof of , @xmath93",
    "can be computed in @xmath95 time , where @xmath96 is the number of vertices in @xmath93 .",
    "next we show that there exists a set @xmath34 of @xmath1 uncertain points in @xmath98 such that @xmath93 has @xmath97 vertices .",
    "assume that @xmath99 for some positive integer @xmath100 .",
    "all the disks @xmath101 have the same radius 1 , centered at @xmath102 , for @xmath103 . any pair @xmath104 satisfying that @xmath105 and @xmath106 is even determines 2 vertices : @xmath107 , and @xmath108 , of @xmath109 ( realized with @xmath110 , @xmath111 ) ( ) .",
    "any pair @xmath104 satisfying that @xmath105 and @xmath106 is odd determines 2 vertices : @xmath112 , and @xmath113 , of @xmath109 ( realized with @xmath110 , @xmath114 or @xmath115 ) .",
    "one can verify that @xmath116 , for @xmath117 , @xmath118 .",
    "hence , we obtain a lower bound of @xmath97 for the complexity of @xmath109 .",
    "[ [ remarks . ] ] remarks .",
    "+ + + + + + + +    we note that the proof of is essentially a packing argument , and therefore can be extended to the case when each uncertainty region is a convex @xmath119-fat semialgebraic set of constant description complexity . a convex set @xmath120 is called @xmath119-fat , if there exist two concentric disks @xmath121 and @xmath122 so that @xmath123 and the ratio between the radii of @xmath122 and @xmath121 is at most @xmath119 .",
    "the constant of proportionality also depends on @xmath119 and the description complexity of the sets defining the uncertainty regions .",
    "this in turn implies that @xmath93 has @xmath124 complexity if the uncertainty regions of @xmath34 are pairwise - disjoint convex @xmath119-fat sets , for some constant @xmath125 , and the ratio of the size of the largest to the smallest region is bounded by @xmath126 .",
    "extension of the proof of to this case , however , is even more technical , so we have decided not to state this generalized result as a theorem , especially since , in practice , a fat convex set can be approximated by a circular disk .",
    "[ [ storing - p_phis - for - ensurematheuscriptv_neq-0xspacep . ] ] storing @xmath127 s for @xmath93 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we store the index @xmath128 of each uncertain point @xmath23 instead of @xmath23 itself .",
    "if we store @xmath127 for each cell @xmath129 of @xmath93 explicitly , the size increases by a factor of @xmath1 .",
    "however , we observe that for two adjacent cells @xmath129 , @xmath130 of @xmath93 , i.e. , two cells that share a common edge , @xmath131 , where @xmath132 denotes the symmetric difference of two sets .",
    "therefore , using a persistent data structure  @xcite , we can store @xmath127 for all cells of @xmath93 in @xmath133 space , where @xmath96 is the complexity of @xmath93 , so that for any cell @xmath129 , @xmath127 can be retrieved in @xmath134 time .",
    "intersect transversally at every vertex , it suffices to store @xmath127 for each cell of @xmath93 .",
    "otherwise one may have to store @xmath127 for edges and vertices of @xmath93 .",
    "this does not affect the asymptotic performance of the data structure .",
    "] by combining this with a planar point - location data structure @xcite , we obtain the following :    [ theo : nzvd_continuous_query ] let @xmath34 be a set of @xmath1 uncertain points in @xmath7 , and let @xmath96 be the complexity of @xmath93 . then , @xmath93 can be preprocessed in @xmath135 time into @xmath3 of size @xmath133 so that , for a query point @xmath136 , @xmath137 can be computed in @xmath138 time , where @xmath139 is the output size .",
    "[ sec : vd : discrete ] we now analyze the complexity of @xmath93 when the distribution of each point @xmath23 in @xmath34 is discrete .",
    "let @xmath140 .",
    "for @xmath141 , let @xmath142 $ ] .",
    "as in the previous section , for a point @xmath143 , let @xmath144 note that the projection of the graph of @xmath145 ( resp.@xmath146 ) onto the @xmath147-plane is the farthest - point ( resp.nearest-point ) voronoi diagram of @xmath23 .",
    "let @xmath148 . for each @xmath128 , let @xmath149 , and set @xmath150 .",
    "then @xmath93 is the planar subdivision @xmath151 induced by @xmath152 ( cf . ) .",
    "we define a few functions that will help analyze the structure of @xmath93 .",
    "we first define a function @xmath153 as @xmath154 for @xmath155 , define @xmath156 finally , we define @xmath157 the following lemma is straightforward .",
    "[ lemma : linearize ] for any @xmath158 and for any @xmath19 , @xmath159 if and only if @xmath160 .",
    "[ lemma : some : lemma ] for any pair @xmath161 , @xmath162 , let @xmath163 , then @xmath164 is a convex polygonal curve with @xmath165 vertices .    by , for any pair @xmath166 and for any @xmath167 ,",
    "@xmath168 if and only if @xmath169 . hence , @xmath164 is also the zero set of the function @xmath170 .",
    "@xmath171 is the upper envelope of @xmath16 linear functions , and thus is a piecewise - linear convex function .",
    "similarly , @xmath172 , the lower envelope of @xmath16 linear functions , is a piecewise - linear concave function .",
    "hence , @xmath173 is a piecewise - linear convex function , which implies that @xmath174 is a convex polygonal curve .",
    "since @xmath164 is the projection of the intersection curve of the graphs of @xmath171 and @xmath172 , each of which is the surface of an unbounded convex polyhedron with at most @xmath16 faces , @xmath164 has @xmath165 vertices .",
    "let @xmath91 be a set of @xmath1 uncertain points in @xmath7 , where each @xmath23 has a discrete distribution of size at most @xmath16 .",
    "the complexity of @xmath93 is @xmath175 , and it can be computed in @xmath95 expected time .",
    "furthermore , it can be preprocessed in additional @xmath133 time into @xmath3 of size @xmath133 so that an @xmath176 query can be answered in @xmath177 , where @xmath139 is the output size .",
    "we follow the same argument as in the proof of .",
    "we need to bound the number of intersection points between a pair of curves @xmath178 and @xmath179 .",
    "fix an index @xmath180 .",
    "let @xmath181 and @xmath182 . by , each of @xmath183 and @xmath184 is a convex polygonal curve in @xmath7 with @xmath165 vertices .",
    "since two convex polygonal curves in general position with @xmath185 and @xmath186 vertices intersect in at most @xmath187 points , @xmath183 and @xmath184 intersect at @xmath165 points . hence ,",
    "@xmath178 and @xmath179 intersect at @xmath188 points , implying that @xmath93 has @xmath189 vertices .",
    "the running time follows from the proof of .",
    "[ sec : indexing_schemes ]    with the maximum size of @xmath109 being @xmath191 , we present @xmath192-size data structures that circumvent the need for constructing @xmath93 and answer @xmath190 queries in poly - logarithmic or sublinear time .",
    "they rely on geometric data structures for answering range - searching queries and their variants ; see @xcite for a recent survey .",
    "an @xmath176 query is answered in two stages .",
    "the first stage computes @xmath193 , and the second stage computes all points @xmath194 for which @xmath195 .",
    "we build a separate @xmath196 for each stage .",
    "we first describe the one for the continuous case and then for the discrete case .",
    "[ [ continuous - case . ] ] continuous case .",
    "+ + + + + + + + + + + + + + + +    we assume that the uncertainty region of each point @xmath23 is a disk @xmath101 of radius @xmath197 centered at @xmath198 .",
    "recall from that the projection of the graph of the function @xmath199 onto the @xmath147-plane , a planar subdivision @xmath200 , is the ( additive - weighted ) voronoi diagram of the points @xmath201 , and it has linear complexity .",
    "hence @xmath200 can be preprocessed in @xmath202 time into @xmath3 of size @xmath203 so that for a query point @xmath19 , @xmath193 can be computed in @xmath204 time  @xcite .",
    "next we wish to report all points @xmath194 for which @xmath195 , i.e. , for which @xmath101 intersects the disk of radius @xmath193 centered at @xmath4 .",
    "note that the projection of the graph of the lower envelope of @xmath205 is also an ( additive - weighted ) voronoi diagram of the points @xmath201 and has linear complexity .",
    "recently  @xcite have described a data structure of size @xmath192 that can answer the above query in @xmath138 time , where @xmath139 is the output size .",
    "it can be constructed in @xmath192 randomized expected time .",
    "we thus obtain the following :    [ theo : indexscheme_continuous ] let @xmath17 be a set of @xmath1 uncertain points in @xmath7 so that the uncertainty region of each  @xmath23 is a disk .",
    "@xmath34 can be preprocessed into @xmath3 of size @xmath192 , so that an @xmath176 query can be answered in @xmath138 time , where @xmath139 is the output size .",
    "the data structure can be constructed in @xmath192 randomized expected time .",
    "[ [ remarks.-1 ] ] remarks .",
    "+ + + + + + + +    \\(i ) note that gives a better result than but the @xmath196 based on @xmath93 is simpler and more practical .",
    "\\(ii ) if we use @xmath206 or @xmath207 metric to compute the distance between points and use disks in @xmath206 or @xmath207 metric ( i.e. , a diamond or a square ) , then an @xmath176 query can be answered in @xmath208 time using @xmath209 space : the first stage remains the same and the second stage reduces to reporting a set of axis - aligned squares that intersect a query axis - aligned square  @xcite .",
    "[ [ discrete - case . ] ] discrete case .",
    "+ + + + + + + + + + + + + +    next , we consider the case when each @xmath23 has a discrete distribution of size at most @xmath16 ; set @xmath210 .",
    "the functions @xmath145 and @xmath146 are now more complex and thus the @xmath196 for @xmath176 queries is more involved . as in , instead of working with the functions @xmath146 and @xmath145 , we work with @xmath172 and @xmath211 . by , the problem of reporting all points @xmath23 with @xmath195 is equivalent to returning the points with @xmath212 . as for the continuous case , we construct two data structures ",
    "the first one computes @xmath213 for a query point @xmath19 and the second one reports all @xmath23 s with @xmath212 .",
    "note that @xmath212 if and only if the point @xmath214 lies above the graph of @xmath172 . by triangulating each face of @xmath172 and @xmath211 if necessary",
    ", we can assume that each @xmath172 is a triangulated concave surface and each @xmath211 is a triangulated convex surface .",
    "we now describe the data structure for computing @xmath213 .",
    "note that @xmath215 if @xmath171 is the first surface in the set @xmath216 intersected by @xmath217 , the vertical line passing through @xmath4 , in the @xmath218-direction . we first construct a @xmath219-level partition tree @xcite on the set of triangles in the graphs of @xmath220 , denoted by @xmath221 ,",
    "so that the triangles of @xmath221 intersected by @xmath217 , for a query point @xmath222 , can be reported efficiently .",
    "the partition tree stores a family of _ canonical _ subsets of triangles in @xmath221 so that for any query point @xmath4 , the triangles of @xmath221 intersected by @xmath217 can be reported as the union of @xmath223 canonical subsets in @xmath223 time .",
    "let @xmath224 denote the family of canonical subsets reported by the query procedure .",
    "the size of the data structure is @xmath225 , and it can be constructed in @xmath226 randomized expected time  @xcite .",
    "next , for each canonical subset @xmath120 , let @xmath227 be the set of planes supporting the triangles in @xmath120 .",
    "we construct the lower envelope @xmath228 of @xmath227 ( by regarding each plane in @xmath227 as the graph of a linear function ) , which has size @xmath229 , and preprocess @xmath228 into an @xmath229-size data structure so that for a query point @xmath136 , @xmath230 can be computed in @xmath231 time  @xcite .",
    "summing over all canonical subsets of the partition tree , the overall size of the data structure is @xmath226 and it can be constructed in @xmath232 randomized expected time .    given a query point @xmath19 , we first query the partition tree and compute the family @xmath224 of canonical subsets . for each canonical set @xmath233 , we compute @xmath230 and return the minimum among them as @xmath213 . since , the procedure spends @xmath234 time for each canonical subset , the overall query time is @xmath235 .",
    "the correctness of the procedure follows from the following observation : @xmath217 intersects all triangles of a canonical subset @xmath233 , so for each triangle @xmath236 and its supporting plane @xmath237 , @xmath238 .",
    "therefore @xmath230 is the same as the ( height of the ) first intersection point of @xmath217 with a triangle of @xmath120 , and @xmath239 .",
    "next , we describe the data structure for reporting the points @xmath23 with @xmath212 .",
    "it is very similar to the one just described , except one twist .",
    "first , as above , we construct a 3-level partition tree on the triangles in the graphs of @xmath240 .",
    "let @xmath120 be a canonical subset constructed by the partition tree , and let @xmath227 be the set of planes supporting @xmath120 . using a result by @xcite ( see also  @xcite ) , we preprocess @xmath227 , in @xmath241 randomized expected time , into a data structure of size @xmath242 so that for a query point @xmath243 , all @xmath244 planes of @xmath227 lying below @xmath245 can be reported in @xmath246 time .",
    "summing over all canonical subsets of the partition tree , the overall size of the data structure is @xmath226 , and it can be constructed in @xmath232 randomized expected time .    given a query point @xmath19 , we first query the partition tree and compute the family @xmath224 of canonical subsets . for each canonical set @xmath233 , we next report all planes of @xmath227 lying below @xmath245 .",
    "the overall query time is @xmath247 , where @xmath139 is the output size .",
    "passes through the boundary of a triangle of some @xmath172 , then @xmath23 may be reported multiple times .",
    "if the points of @xmath23 are in general position , then the degree of each vertex of @xmath172 is constant , so @xmath23 will be reported @xmath248 times .",
    "however if points in @xmath23 are in a degenerate position , then additional care is needed , using standard techniques such as symbolic perturbation , to ensure that @xmath23 is reported only @xmath248 times . ]",
    "the correctness of the procedure follows from the same argument as above , namely , since @xmath217 intersects all triangles of a canonical subset @xmath233 , a triangle in @xmath120 lies below @xmath249 if and only if the plane supporting it lies below @xmath249 .    putting everything together ,",
    "we can construct , in @xmath232 randomized expected time , a data structure of @xmath226 size that can answer an @xmath190 query in @xmath235 time .",
    "finally , we remark that the @xmath219-level partition tree can be replaced by a multi - level data structure of size @xmath250 so that the set of triangles intersected by @xmath217 can be returned as the union of @xmath251 canonical subsets  @xcite . using this data structure",
    ", we can answer an @xmath190 query in @xmath252 time using @xmath250 space .",
    "we thus obtain the following :    let @xmath34 be a set of @xmath1 uncertain points in  @xmath7 , each with a discrete distribution of size at most @xmath16 ; set @xmath210 .",
    "@xmath34 can be preprocessed into @xmath3 of size @xmath232 so that an @xmath176 query can be answered in @xmath253 time , or into @xmath3 of size @xmath250 with @xmath254 query time , where @xmath139 is the output size .",
    "the expected preprocessing times are @xmath232 and @xmath255 time , respectively .",
    "[ sec : sec : quanprob ]    we now turn our attention to the second part of answering probabilistic nn queries , namely , returning the quantification probabilities that are positive .",
    "we begin with a data structure for computing quantification probabilities exactly for the case when each uncertain point has a discrete distribution of size at most @xmath16 .",
    "since computing these quantities exactly is quite expensive and they are small for most of the points , we focus on computing quantification probabilities approximately .",
    "[ sec : exact ]    assuming each point in @xmath34 has a discrete distribution of size at most @xmath16 , we build the probabilistic voronoi diagram @xmath256 that decomposes @xmath7 into a set of cells , so that any point @xmath4 in a cell has the same @xmath30 value for all @xmath194 ; that is , for any point @xmath4 in this cell , we know exactly the probability of each point @xmath257 being the @xmath5 of @xmath4 .",
    "[ lemma : pvd ] let @xmath34 be a set of @xmath1 uncertain points in @xmath7 , each with a discrete distribution of size at most @xmath16 ; set @xmath210 .",
    "the complexity of @xmath256 is @xmath258 .",
    "moreover , there exists a set @xmath34 of @xmath1 uncertain points in @xmath98 with @xmath259 such that @xmath256 has size @xmath260 .",
    "we first prove the upper bound .",
    "there are @xmath261 possible locations .",
    "each pair of possible locations determines a bisector , resulting in @xmath262 bisectors .",
    "these bisectors partition the plane into @xmath258 convex cells so that the order of all distances to each of the @xmath263 possible locations , and thus by also all the quantification probabilities , are preserved within each cell .",
    "therefore , the resulting planar subdivision is a refinement of @xmath256 , and thus @xmath264 is an upper bound on the complexity of @xmath256 .",
    "next , we show that there exists a set @xmath34 of @xmath1 uncertain points in @xmath98 with @xmath259 such that @xmath256 has size @xmath260 . for simplicity",
    ", we describe a degenerate configuration of points , but the argument can be generalized to a non - degenerate configuration as well , by being more careful . for every @xmath265",
    ", @xmath194 has two possible locations @xmath266 and @xmath267 , each with probability @xmath268 .",
    "let @xmath121 be the unit disk centered at the origin .",
    "we choose @xmath269 inside @xmath121 so that the bisector @xmath270 of every pair @xmath271 , for @xmath272 , is a distinct line and all pairs of bisectors intersect inside @xmath121 .",
    "we place all @xmath273 s at the same location far away from @xmath121 , say , at @xmath274 .",
    "note that the bisector of @xmath275 and @xmath276 , for any @xmath277 , does not intersect @xmath121 , so for any point @xmath278 , @xmath279 .    ./figs / pvd_n_4_lower_bound    [ fig : pvd_n_4_lower_bound ]    let @xmath280 be the arrangement of the bisectors @xmath281 .",
    "since all pairs of bisectors intersect inside @xmath121 , @xmath282 has @xmath283 faces .",
    "let @xmath284 be any two adjacent faces of @xmath285 inside @xmath121 , let @xmath270 be the bisector separating @xmath286 and @xmath287 , and let @xmath288 be arbitrary points in the interior of @xmath284 , respectively",
    ". without loss of generality , assume that @xmath289 , then @xmath290 .",
    "suppose there are @xmath291 , @xmath292 , points of @xmath293 that are closer to @xmath4 than @xmath276 , i.e. , @xmath276 ( resp .",
    "@xmath294 ) is the @xmath295-st @xmath5 of @xmath4 ( resp .",
    "@xmath296 ) among @xmath297 . then , by , @xmath298 symmetrically , @xmath299 and @xmath300 . in particular @xmath301 and @xmath302 . in other words ,",
    "any two adjacent faces of @xmath280 inside @xmath121 have distinct quantification probability vectors , implying that @xmath256 has @xmath260 complexity .    as in",
    ", we can store the quantification probabilities for all faces of @xmath256 by using @xmath248 storage per face . hence , by preprocessing @xmath256 for point - location queries , for a query point @xmath4 , we can report all @xmath139 quantification probabilities that are positive in @xmath303 time .",
    "[ theo : qp - query ] let @xmath34 be a set of @xmath1 uncertain points in @xmath7 , each with a discrete distribution of size at most @xmath16 ; set @xmath210 .",
    "@xmath34 can be preprocessed in time @xmath304 time into a data structure of size @xmath258 that can report all @xmath139 positive quantification probabilities of a query point in time @xmath303 .",
    "[ sec : monte : carlo ]    in this section we describe a simple monte - carlo approach to build @xmath3 for quickly computing @xmath305 for all @xmath23 for any query point @xmath4 , which approximates the quantification probability @xmath30 . for a fixed value @xmath306 ,",
    "to be specified later , the preprocessing step works in @xmath306 rounds . in the @xmath307-thround",
    "the algorithm creates a sample @xmath308 by choosing each @xmath309 using the distribution of @xmath23 . for each @xmath310",
    ", we construct the voronoi diagram @xmath311 in @xmath312 time and preprocess it for point - location queries in additional @xmath312 time .",
    "to estimate quantification probabilities of a query  @xmath4 , we initialize a counter @xmath313 for each point @xmath23 . for each @xmath310",
    ", we find the point @xmath314 whose cell in @xmath311 contains the query point @xmath4 , and increment @xmath198 by @xmath315 .",
    "finally we estimate @xmath316 .",
    "note that at most @xmath306 distinct @xmath198 s have nonzero values , so we can implicitly set the remaining @xmath317 s to @xmath318 .",
    "[ [ discrete - case.-1 ] ] discrete case .",
    "+ + + + + + + + + + + + + +    if each @xmath194 has a discrete distribution of size @xmath16 , then this algorithm can be implemented very efficiently .",
    "each @xmath309 can be selected in @xmath319 time after preprocessing each @xmath23 , in @xmath165 time , into a balanced binary tree  @xcite .",
    "thus , total preprocessing takes @xmath320 time and @xmath321 space , and each query takes @xmath322 time .",
    "it remains to determine the value of @xmath306 so that @xmath323 for all @xmath23 and all queries @xmath4 , with probability at least @xmath324 . for fixed @xmath4 , @xmath23 , and instantiation @xmath325 , let @xmath326 be the random indicator variable , which is 1",
    "if @xmath309 is the @xmath5 of @xmath4 and 0 otherwise .",
    "since @xmath327 = \\pi_i(q)$ ] and @xmath328 , applying the chernoff - hoeffding bound  @xcite to @xmath329 we obtain that @xmath330 \\leq 2 \\exp(-2\\eps^2 s).\\end{aligned}\\ ] ]    for each cell of @xmath256 , we choose one point , and let @xmath331 be the resulting set of points . if @xmath332 for every point @xmath333 , then @xmath332 for every point @xmath19 .",
    "since there are @xmath1 different values of @xmath128 , by applying the union bound to , the probability that there exist a point @xmath222 and an index @xmath334 with @xmath335 is at most @xmath336 .",
    "hence , by setting @xmath337 @xmath332 for all @xmath19 and for all @xmath334 , with probability at least @xmath338 . by  ,",
    "@xmath339 , so we obtain the following result",
    ".    let @xmath34 be a set of @xmath1 uncertain points in  @xmath7 , each with a discrete distribution of size @xmath16 , and let @xmath340 be two parameters .",
    "@xmath34 can be preprocessed , in @xmath341 time , into @xmath3 of size @xmath342 , which computes , for any query point @xmath19 , in @xmath343 time , a value @xmath305 for every @xmath23 such that @xmath323 for all @xmath128 with probability at least @xmath324 .    [",
    "[ continuous - case.-1 ] ] continuous case .",
    "+ + + + + + + + + + + + + + + +    there are two technical issues in extending this technique and analysis to continuous distributions .",
    "first , how we instantiate a certain point @xmath197 from each @xmath23 .",
    "herein we assume the representation of the is such that this can be done in constant time for each @xmath23 .",
    "second , we need to bound the number of distinct queries that need to be considered to apply the union bound as we did above . since @xmath30 may vary continuously with the query location , unlike the discrete case , we can not hope for a bounded number of distinct results .",
    "however , we just need to define a finite set @xmath344 of query points so that for any point @xmath19 , there is a point @xmath345 such that @xmath346 .",
    "then , we can choose @xmath306 large enough so that it permits at most @xmath347 error on each query in @xmath344 . specifically , choosing @xmath348 is sufficient , so all that remains is to bound @xmath349 .    to choose @xmath344 ,",
    "we show that each of @xmath23 can be approximated with a discrete distribution of size @xmath350 , and then reduce the problem to the discrete case .    for parameters",
    "@xmath351 and @xmath352 , set @xmath353 where @xmath354 is a constant .",
    "for each @xmath334 , we choose a random sample @xmath355 of size @xmath356 , according to the distribution defined by the location @xmath357 @xmath358 of @xmath23 .",
    "we regard @xmath359 as an uncertain point with uniform location probability .",
    "set @xmath360 .    for a point @xmath19 ,",
    "let @xmath361 denote the @xmath362 of the distance between @xmath4 and @xmath359 , i.e. , @xmath363 $ ] , or equivalently , it is the probability of @xmath359 lying in the disk of radius @xmath291 centered at @xmath4 .",
    "a well - known result in the theory of random sampling  @xcite implies that for all @xmath19 and @xmath364 , @xmath365 with probability at least @xmath366 , provided that the constant @xmath354 in @xmath356 is chosen sufficiently large .",
    "let @xmath367 denote the probability of @xmath359 being the @xmath5 of @xmath4 in @xmath368 .",
    "we prove the following :    for any @xmath19 and for any fixed @xmath334 , @xmath369 with probability at least @xmath370 .",
    "recall that by , @xmath371 using , and the fact that @xmath372 $ ] for all @xmath307 , we obtain @xmath373    note that @xmath374 is the probability that the closest point of @xmath4 in @xmath375 is at least distance @xmath291 away from  @xmath4 .",
    "let @xmath376 be the @xmath357 of the distance between @xmath4 and its closest point in @xmath377 .",
    "then @xmath378    therefore @xmath379 by reversing the order of integration , we obtain @xmath380{eq.~(\\ref*{equation : sampling : theory}{)}}}})}\\\\        & =         \\int_0^{\\infty } h_{q , i}(\\theta ) { \\overline{g}}_{q ,          i}(\\theta){{\\ifmmode{\\rm d}\\else{\\mbox{\\(\\rm d\\)}}\\fi}{\\theta } } + n\\alpha          =         { \\overline{\\pi}}_i(q ) + n\\alpha .",
    "\\end{aligned}\\ ] ]    a similar argument shows that @xmath381 .",
    "this completes the proof of the lemma .",
    "thus , by setting @xmath382 , a random sample @xmath359 of size @xmath383 from each @xmath23 ensures that @xmath384 for all queries . by choosing @xmath385 ,",
    "holds for all @xmath334 with probability at least @xmath386 .",
    "we consider @xmath387 , choose one point from each of its cells , and set @xmath344 to be the resulting set of points .",
    "for a point @xmath19 , let @xmath388 be the representative point of the cell of @xmath387 that contains @xmath4 .",
    "then , @xmath389 for all points @xmath19 and @xmath334 , with probability at least @xmath386 .    now applying the analysis for the discrete case to the point set @xmath368 , if we choose @xmath390 then @xmath391 for all points @xmath19 and for all @xmath334 with probability at least @xmath386 . since @xmath392 by  , @xmath393    putting everything together , we obtain the following .",
    "let @xmath394 be a set of @xmath1 uncertain points in @xmath7 so a random instantiation of @xmath23 can be performed in @xmath248 time , and let @xmath395 be two parameters .",
    "@xmath34 can be preprocessed in @xmath396 time into @xmath3 of size @xmath397 that computes for any query point @xmath19 , in @xmath398 time , a value @xmath317 for every @xmath23 such that @xmath323 for all @xmath128 with probability at least @xmath324 .      [ sec : spiralsearch ]    if the distribution of each point in @xmath34 is discrete , then there is an alternative approach to approximate the quantification probabilities for a given query @xmath4 : set a parameter @xmath399 , choose the @xmath100 points of @xmath400 that are closest to @xmath4 , and use only these @xmath100 points to estimate @xmath30 for each @xmath23 .",
    "we show that this works for a small value of @xmath100 when , for each @xmath23 , each location is approximately equally likely , but is not efficient if the location probabilities vary significantly .",
    "recall that @xmath401 is the location probability of a point @xmath402 .",
    "set @xmath400 to be the set of all possible locations of points in @xmath34 .",
    "we define the quantity @xmath403 the ratio of the largest to the smallest location probability over all points of @xmath0 , as the spread of location probabilities .",
    "set @xmath404    fix a query point @xmath19 .",
    "let @xmath405 be the @xmath406 nearest neighbors of @xmath4 in @xmath0 , @xmath407 , and @xmath408 note that @xmath409 is not necessarily equal to 1 , so we can not regard @xmath359 as an uncertain point in our model , but still it will be useful to think of @xmath410 as an uncertain point that does not exist with probability @xmath411 .",
    "for a set @xmath412 of points and another point @xmath413 , let @xmath414 = { \\left\\ { \\bigl . p \\in",
    "y \\;\\middle\\vert\\ ;   \\dist(q , p ) \\leq \\dist(q , \\xi ) \\right\\}}.     \\end{aligned}\\ ] ] for a point @xmath415 , the probability that @xmath416 is the @xmath5 of @xmath4 in @xmath34 , denoted by @xmath417 , is @xmath418 } w_{j , \\ell } \\bigr ) .",
    "\\end{aligned}\\ ] ]    moreover , @xmath419    for each @xmath277 , @xmath19 , and @xmath420 , we analogously define the quantities @xmath421 and @xmath422 using and but replacing @xmath423 with @xmath424 for every @xmath425 .",
    "intuitively , if @xmath368 were a family of uncertain points , then @xmath317 would be the probability of @xmath410 being the @xmath5 of @xmath4 in @xmath368 .    for all @xmath334 , @xmath426    fix a point @xmath427 . if @xmath428 , then for all @xmath429 , @xmath430 = p_j[p]$ ] , therefore by , @xmath431 .",
    "hence , by , @xmath432 therefore @xmath433 .",
    "next , we bound the second term in the right hand side of .",
    "let @xmath434 .",
    "set @xmath435|$ ] , for @xmath29 , and @xmath436 . since @xmath437 , @xmath438 and @xmath439 .",
    "note that each @xmath440 .",
    "therefore , @xmath441}w_{j,\\ell}\\bigr )           \\leq         w_{i , a } \\prod_{\\substack{j \\neq i } } \\bigl(1 -          \\frac{x_j}{\\rho k } \\bigr )         \\leq          w_{i , a } \\prod_{\\substack{j \\neq i } } \\exp \\left          ( -x_j/\\rho k \\right )           \\\\ &              = w_{i , a } \\exp \\left ( -m'/\\rho k \\right ) \\le w_{i , a}\\eps .",
    "\\end{aligned}\\ ] ] consequently , @xmath442 plugging in , we obtain @xmath443 , as claimed .",
    "this completes the proof of the lemma .    for any @xmath128 ,",
    "if @xmath444 , then we can implicitly set @xmath317 to @xmath318 .",
    "using the data structure by @xcite , @xmath0 can be preprocessed in @xmath445 randomized expected time into a data structure of @xmath446 size so that @xmath447 nearest neighbors of a query point can be reported in @xmath448 time .",
    "we thus obtain the following result .",
    "let @xmath34 be a set of @xmath1 uncertain points in @xmath7 , each with a discrete distribution of size at most @xmath16 , let @xmath449 be the spread of the location probabilities , and let @xmath210 .",
    "@xmath34 can be preprocessed in @xmath450 expected time into @xmath3 of size @xmath446 , so that for a query point @xmath19 and a parameter @xmath451 , it can compute , in time @xmath452 , values @xmath317 for all @xmath194 such that @xmath453 for all @xmath334 .",
    "[ [ remarks.-2 ] ] remarks .",
    "+ + + + + + + +    \\(i ) this approach is not efficient when the spread of location probabilities is unbounded . in this case",
    ", one may have to retrieve @xmath454 points .",
    "another approach may be to ignore points with weight smaller than @xmath455 , since even @xmath16 such weights from a single uncertain point @xmath23 can not contribute more than @xmath456 to @xmath30 .",
    "however , the union of all such points may distort other probabilities .",
    "consider the following example .",
    "let @xmath457 be the closest point to the query point @xmath4 .",
    "let @xmath458 . let the next @xmath459 closest points @xmath460 be from different uncertain points @xmath461 and each have weights @xmath462 .",
    "let the next closest point @xmath463 have weight @xmath464 .",
    "with probability @xmath465 the nearest neighbor is  @xmath466 .",
    "the probability that @xmath467 is the nearest neighbor is @xmath468 .",
    "thus , @xmath466 is more likely to be the nearest neighbor than @xmath467 .",
    "however , if we ignore points @xmath460 because they have small weights , then we calculate @xmath467 has probability @xmath469 for being the nearest neighbor ( assuming that @xmath456 is small enough ) . so @xmath470 will be off by more than @xmath471 and it would incorrectly appear that @xmath467 is more likely to be the nearest neighbor than  @xmath466 .",
    "\\(ii ) though the the data structure by @xcite is optimal theoretically , it is too complex to be implemented .",
    "instead , one may use the order-@xmath100 voronoi diagram to retrieve the @xmath100 closest points ( in unsorted order ) to @xmath4 .",
    "this would yield @xmath3 with @xmath472 space and @xmath473 expected preprocessing time  @xcite , while preserving the query time @xmath474 , where @xmath475 .",
    "alternatively , one may use quad - trees and a branch - and - bound algorithm to retrieve @xmath100 points of @xmath0 closest to @xmath4  @xcite .",
    "in this paper , we investigated @xmath5 queries in a probabilistic framework in which the location of each input point is specified as a probability distribution function .",
    "we presented efficient methods for returning all points with non - zero probability of being the nearest neighbor , estimating the quantification probabilities and using it for threshold @xmath5 queries .",
    "we conclude by mentioning two open problems :    the lower - bound constructions for the complexity of @xmath93 are created very carefully , and these configurations are unlikely to occur in practice .",
    "a natural question is to characterize the sets of uncertain points for which the complexity of @xmath93 is near linear .",
    "http://www.cs.duke.edu/~pankaj[p .",
    "k.  agarwal ] , m. de berg , http://kam.mff.cuni.cz/~matousek[j .",
    "matouek ] , and http://www.win.tue.nl/~ocheong/[o .",
    "schwarzkopf ] . constructing levels in arrangements and higher order voronoi diagrams . , 27:654667 , 1998 .",
    "http://www.cs.duke.edu/~pankaj[p .",
    "k.  agarwal ] , http://www.cs.arizona.edu/~alon/[a .",
    "efrat ] , s.  sankararaman , and w.  zhang .",
    "nearest - neighbor searching under uncertainty . in _",
    "31st acm sympos .",
    "principles database syst .",
    "_ , pages 225236 , 2012 .",
    "http://www.cs.duke.edu/~pankaj[p .",
    "k.  agarwal ] .",
    "range searching . in j.",
    "e. goodman , http://cs.smith.edu/~orourke/[j .",
    "orourke ] , and c.  toth , editors , _ handbook of discrete and computational geometry _ , chapter  36 , page to apepar .",
    "crc press llc , 3rd edition , 2016 .",
    "http://www.cs.duke.edu/~pankaj[p .",
    "k.  agarwal ] and http://www.math.tau.ac.il/~michas[m .",
    "arrangements and their applications . in j .-",
    "sack and j.  urrutia , editors , _ handbook of computational geometry _",
    ", pages 49119 .",
    "north - holland publishing co. , amsterdam , 2000 .",
    "t.  bernecker , t.  emrich , h .-",
    "kriegel , n.  mamoulis , m.  renz , and a.  zuefle .",
    "a novel probabilistic pruning approach to speed up similarity queries in uncertain databases . in _ proc .",
    "27th ieee int .",
    "_ , pages 339350 , 2011 .",
    "http://www.cs.tau.ac.il/~haimk/[h .",
    "kaplan ] , w.  mulzer , l.  roditty , p.  seiferth , and http://www.math.tau.ac.il/~michas[m .",
    "dynamic planar voronoi diagrams for general distance functions and their algorithmic applications . , abs/1604.03654 , 2016 .",
    "p.  zhang , r.  cheng , n.  mamoulis , m.  renz , a.  zufile , y.  tang , and t.  emrich .",
    "voronoi - based nearest neighbor search for multi - dimensional uncertain databases . in _ proc .",
    "29th ieee int .",
    "_ , pages 158169 , 2013 ."
  ],
  "abstract_text": [
    "<S> nearest - neighbor search , which returns the nearest neighbor of a query point in a set of points , is an important and widely studied problem in many fields , and it has wide range of applications . in many of them , such as sensor databases , location - based services , face recognition , and mobile data , the location of data is imprecise . </S>",
    "<S> we therefore study nearest - neighbor queries in a probabilistic framework in which the location of each input point is specified as a probability distribution function . </S>",
    "<S> we present efficient algorithms for    computing all points that are nearest neighbors of a query point with nonzero probability ; and    estimating the probability of a point being the nearest neighbor of a query point , either exactly or within a specified additive error . </S>"
  ]
}