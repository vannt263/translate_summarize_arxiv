{
  "article_text": [
    "we consider the problem of minimizing a continuous function @xmath5 over a compact set @xmath6 .",
    "that is , we consider the problem of computing the parameter :    @xmath7    our goal is to compare two convergent hierarchies of upper bounds on @xmath8 , namely measure - based bounds introduced by lasserre @xcite , and simulated annealing bounds , as studied by kalai and vempala @xcite .",
    "the bounds of lasserre are obtained by minimizing over measures on @xmath1 with sum - of - squares polynomial density functions with growing degrees , while simulated annealing bounds use boltzman distributions on @xmath1 with decreasing temparature parameters .    in this note",
    "we establish a relationship between these two approaches , linking the degree and temperature parameters in the two bounds ( see theorem [ thm : main ] for a precise statement ) . as an application ,",
    "when @xmath0 is a polynomial and @xmath9 is a convex body , we can show a faster convergence rate for the measure - based bounds of lasserre .",
    "the new convergence rate is in @xmath10 ( see corollary  [ cor : nonconvex ] ) , where @xmath11 is the degree of the sum - of - squares polynomial density function , while the dependence was in @xmath12 in the previously best known result from @xcite .",
    "polynomial optimization is a very active research area in the recent years since the seminal works of lasserre @xcite and parrilo @xcite ( see also , e.g. , the book @xcite and the survey @xcite ) . in particular , hierarchies of ( lower and upper ) bounds for the parameter @xmath8 have been proposed , based on sum - of - squares polynomials and semidefinite programming . for a general compact set @xmath1 , upper bounds for @xmath8 have been introduced by lasserre @xcite , obtained by searching for a sum - of - squares polynomial density function of given maximum degree @xmath11 , so as to minimize the integration of @xmath0 with respect to the corresponding probability measure on @xmath1 . when @xmath0 is lipschitz continuous and under some mild assumption on @xmath1 ( which holds , e.g. , when @xmath1 is a convex body ) , estimates for the convergence rate of these bounds have been proved in @xcite that are in order @xmath13 .",
    "improved rates have been subsequently shown when restricting to special sets @xmath1 .",
    "related stronger results have been shown for the case when @xmath1 is the hypercube @xmath14^n$ ] or @xmath15^n$ ] . in @xcite the authors show a hierarchy of upper bounds using the beta distribution , with the same convergence rate in @xmath12 , but whose computation needs only elementary operations ; moreover an improved convergence in @xmath10 can be shown , e.g. , when @xmath0 is quadratic .",
    "in addition , a convergence rate in @xmath16 is shown in @xcite , using distributions based on jackson kernels and a larger class of sum - of - squares density functions .    in this paper",
    "we investigate the hierarchy of measure - based upper bounds of @xcite and show that when @xmath9 is a convex body , convexity can be exploited to show an improved convergence rate in @xmath10 , even for nonconvex functions .",
    "the key ingredient for this is to establish a relationship with upper bounds based on simulated annealing and to use a known convergence rate result from @xcite for simulated annealing bounds in the convex case .",
    "simulated annealing was introduced by kirkpatrick et al .",
    "@xcite as a randomized search procedure for general optimization problems .",
    "it has enjoyed renewed interest for convex optimization problems since it was shown by kalai and vempala @xcite that a polynomial - time implementation is possible .",
    "this requires so - called hit - and - run sampling from @xmath17 , as introduced by smith @xcite , that was shown to be a polynomial - time procedure by lovsz @xcite .",
    "most recently , abernethy and hazan @xcite showed formal equivalence with a certain interior point method for convex optimization .",
    "this unexpected equivalence between seemingly different methods has motivated this current work to relate the bounds by lasserre @xcite to the simulating annealing bounds as well .    in what follows ,",
    "we first introduce the measure - based upper bounds of lasserre  @xcite .",
    "then we recall the bounds based on simulated annealing and the known convergence results for a linear objective function @xmath0 , and we give an explicit proof of their extension to the case of a general convex function @xmath0 . after that we state our main result and the next section is devoted to its proof . in the last section",
    "we conclude with numerical examples showing the quality of the two types of bounds and some final remarks .",
    "throughout , @xmath18={{\\mathbb r}}[x_1,\\dots , x_n]$ ] is the set of polynomials in @xmath19 variables with real coefficients and , for an integer @xmath20 , @xmath18_r$ ] is the set of polynomials with degree at most @xmath21 .",
    "any polynomial @xmath22_r$ ] can be written @xmath23 , where we set @xmath24 for @xmath25 and @xmath26 .",
    "we let @xmath27 $ ] denote the set of sums of squares of polynomials , and @xmath27_r=\\sigma[x]\\cap { { \\mathbb r}}[x]_{2r}$ ] consists of all sums of squares of polynomials with degree at most @xmath11 .",
    "we recall the following reformulation for @xmath28 , established by lasserre @xcite :    @xmath29}\\int_{\\mathbf{k}}h(x)f(x)dx \\ \\ \\mbox{s.t .",
    "$ \\int_{\\mathbf{k}}h(x)dx=1$.}\\ ] ]    by bounding the degree of the polynomial @xmath30 $ ] by @xmath11 , we can define the parameter :    @xmath31_r}\\int_{\\mathbf{k}}h(x)f(x)dx \\ \\ \\mbox{s.t .",
    "$ \\int_{\\mathbf{k}}h(x)dx=1$.}\\end{aligned}\\ ] ]    clearly , the inequality @xmath32 holds for all @xmath33 .",
    "lasserre @xcite gave conditions under which the infimum is attained in the program ( [ fundr ] ) .",
    "de klerk , laurent and sun ( * ? ? ?",
    "* ; * ? ? ?",
    "* theorem 3 ) established the following rate of convergence for the bounds @xmath34 .",
    "[ thm : dkls ] let @xmath22 $ ] and @xmath17 a convex body . there exist",
    "constants @xmath35 ( depending only on @xmath0 and @xmath1 ) and @xmath36 ( depending only on @xmath1 ) such that @xmath37 that is , the following asymptotic convergence rate holds : @xmath38    this result of @xcite holds in fact under more general assumptions , namely when @xmath0 is lipschitz continuous and @xmath1 satisfies a technical assumption ( assumption 1 in @xcite ) , which says ( roughly ) that around any point in @xmath39 there is a ball whose intersection with @xmath1 is at least a constant fraction of the unit ball .    as explained in @xcite the parameter @xmath34 can be computed using semidefinite programming , assuming one knows the moments @xmath40 of the lebesgue measure on @xmath1 , where @xmath41 indeed suppose @xmath42 has degree @xmath43 . writing @xmath44_{r}$ ] as @xmath45 , the parameter @xmath34 from ( [ fundr ] ) can be reformulated as follows : @xmath46_r.\\nonumber\\end{aligned}\\ ] ] since the sum - of - squares condition on @xmath47 may be written as a linear matrix inequality , this is a semidefinite program .",
    "in fact , since it only has one linear equality constraint , it may even be rewritten as a generalised eigenvalue problem . in particular , @xmath48 is equal to the the smallest generalized eigenvalue of the system : @xmath49 where the symmetric matrices @xmath50 and @xmath51 are of order @xmath52 with rows and columns indexed by @xmath53 , and @xmath54 for more details , see @xcite .",
    "given a continuous function @xmath0 , consider the associated boltzman distribution over the set @xmath1 , defined by the density function : @xmath55 write @xmath56 if the random variable @xmath57 takes values in @xmath1 according to the boltzman distribution .",
    "the idea of simulated annealing is to sample @xmath58 where @xmath59 is a fixed ` temperature ' parameter , that is subsequently decreased .",
    "clearly , for any @xmath60 , we have @xmath61.\\ ] ] the point is that , under mild assumptions , these bounds converge to the minimum of @xmath0 over @xmath1 ( see , e.g. , @xcite ) : @xmath62 = f_{\\min,\\mathbf{k}}.\\ ] ] the key step in the practical utilization of theses bounds is therefore to perform the sampling of @xmath58 .",
    "[ ex:1 ] consider the minimization of the motzkin polynomial @xmath63 over @xmath64 ^ 2 $ ] , where there are four global minimizers at the points @xmath65 , and @xmath66 .",
    "figure [ figure : motzkin_sa ] shows the corresponding boltzman density function for @xmath67 .",
    "note that this density has four modes , roughly positioned at the four global minimizers of @xmath0 in @xmath15 ^ 2 $ ] .",
    "the corresponding upper bound on @xmath66 is @xmath68 \\approx 0.7257 $ ] ( @xmath67 ) .",
    "graph and contours of the boltzman density with @xmath67 for the motzkin polynomial.,title=\"fig:\",scaledwidth=45.0% ] graph and contours of the boltzman density with @xmath67 for the motzkin polynomial.,title=\"fig:\",scaledwidth=45.0% ] +    to obtain a better upper bound on @xmath69 from the lasserre hierarchy , one needs to use a degree @xmath70 s.o.s .",
    "polynomial density ; in particular , one has @xmath71 ( degree @xmath72 ) and @xmath73 ( degree @xmath70 ) .",
    "more detailed numerical results are given in section [ sec : conclusion ] .",
    "when @xmath0 is linear and @xmath1 a convex body , kalai and vempala ( * ? ?",
    "* ; * ? ? ?",
    "* lemma 4.1 ) show that the rate of convergence of the bounds in ( [ eqboltz ] ) is linear in the temperature @xmath74 .",
    "[ thm : kallai - vempala ] let @xmath75 where @xmath76 is a unit vector , and let @xmath1 be a convex body .",
    "then , for any @xmath60 , we have @xmath77 - \\min_{x \\in { { \\mathbf k } } } f(x ) \\leq   n t.\\ ] ]    we indicate how to extend the result of kalai and vempala in theorem [ thm : kallai - vempala ] to the case of an arbitrary convex function @xmath0 .",
    "this more general result is hinted at in  6 of @xcite , where the authors write    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ... a statement analogous to [ theorem 2 ] holds also for general convex functions ... \" _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    but no precise statement is given there . in any event , as we will now show , the more general result may readily be derived from theorem  [ thm : kallai - vempala ] ( in fact , from the special case of a linear coordinate function @xmath78 for some @xmath79 ) .",
    "[ corconvex ] let @xmath0 be a convex function and let @xmath80 be a convex body . then , for any @xmath60 , we have @xmath77 - \\min_{x \\in { { \\mathbf k } } } f(x ) \\leq   n t.\\ ] ]    set @xmath81 = { \\int_{{\\mathbf k}}f(x)e^{-f(x)/t } dx\\over \\int_{{\\mathbf k}}e^{-f(x)\\over t } dx}.\\ ] ] then we have @xmath82 define the set @xmath83 then @xmath84 is a convex body and we have @xmath85 accordingly , define the parameter @xmath86 corollary [ corconvex ] will follow if we show that @xmath87 to this end set @xmath88 and @xmath89 , where we define @xmath90 @xmath91 we work out the parameters @xmath92 and @xmath93 ( taking integrations by part ) :",
    "@xmath95 then , using the fact that @xmath88 , we obtain : @xmath96 which proves relation ( [ eqee ] ) .",
    "we can now derive the result of corollary [ corconvex ] .",
    "indeed , using theorem 2 applied to @xmath84 and the linear function @xmath97 , we get @xmath77 - \\min_{x \\in { { \\mathbf k } } } f(x ) = e_k - \\min_{x\\in{{\\mathbf k } } } f(x ) = ( e_{\\widehat { { \\mathbf k } } } -\\min_{(x , x_{n+1})\\in \\widehat { { \\mathbf k } } } x_{n+1 } ) + ( e_{{{\\mathbf k } } } -e_{\\widehat { { \\mathbf k } } } ) \\le t(n+1 ) -t = tn.\\ ] ]    the bound in the corollary is tight asymptotically , as the following example shows .",
    "[ ex : tight bound ] consider the univariate problem @xmath98\\}$ ] .",
    "thus , in this case , @xmath99 , @xmath100 $ ] and @xmath101 .",
    "for given temperature @xmath60 , we have @xmath102 - \\min_{x \\in { { \\mathbf k } } } f(x ) = \\frac{\\int_0 ^ 1 x e^{-x / t}dx}{\\int_0^\\ell   e^{-x / t}dx } - 0   = t-{e^{-1/t}\\over 1-e^{-1/t } }   \\sim   t \\ \\mbox { for small } t.\\\\     \\end{aligned}\\ ] ]",
    "we will prove the following relationship between the sum - of - squares based upper bound ( [ fundr ] ) of lasserre and the bound ( [ eqboltz ] ) based on simulated annealing .",
    "[ thm : main ] let @xmath0 be a polynomial of degree @xmath43 , let @xmath1 be a compact set and set @xmath103 then we have @xmath104   + { { \\widehat{f}_{\\max}}\\over 2^r } \\",
    "\\ \\mbox { for any integer } \\",
    "r \\ge { e\\cdot { \\widehat{f}_{\\max}}\\over t}\\ \\mbox { and any } \\ t>0 . \\ ] ]    for the problem of minimizing a convex polynomial function over a convex body , we obtain the following improved convergence rate for the sum - of - squares based bounds of lasserre .    [ cor : main ] let @xmath22 $ ] be a convex polynomial of degree @xmath43 and let @xmath1 be a convex body . then for any integer @xmath105 one has @xmath106 for some constant @xmath107 that does not depend on @xmath21 .",
    "( for instance , @xmath108 . )",
    "let @xmath105 and set @xmath109 . combining theorems [ thm : kallai - vempala ] and [ thm : main ]",
    ", we get @xmath110 \\big ) + \\big ( \\mathop{\\mathbb{e}}_{x \\sim p_{f / t   } } [ f(x ) ] -{f_{\\min,\\mathbf{k}}}\\big ) \\\\ & \\leq & { { \\widehat{f}_{\\max}}\\over 2^r}+nt = { { \\widehat{f}_{\\max}}\\over 2^r }",
    "+ { ne\\cdot { \\widehat{f}_{\\max}}\\over r }   \\le { ( ne+1){\\widehat{f}_{\\max}}\\over r}.\\end{aligned}\\ ] ]    for convex polynomials @xmath0 , this improves on the known @xmath12 result from theorem [ thm : dkls ] .",
    "one may in fact use the last corollary to obtain the same rate of convergence in terms of @xmath21 for all polynomials , without the convexity assumption , as we will now show .",
    "[ cor : nonconvex ] if @xmath0 be a polynomial and @xmath1 a convex body , then there is a @xmath111 depending on @xmath0 and @xmath1 only , so that @xmath112 a suitable value for @xmath76 is @xmath113 where @xmath114 and @xmath115 .",
    "we first define a convex quadratic function @xmath116 that upper bounds @xmath0 on @xmath1 as follows : @xmath117 where @xmath115 , and @xmath118 is the minimizer of @xmath0 on @xmath1 .",
    "note that @xmath119 for all @xmath120 by taylor s theorem , and @xmath121 .    by definition of the lasserre hierarchy , @xmath122_{2r}}\\int_{\\mathbf{k}}h(x)f(x)dx \\",
    "\\ \\mbox{s.t .",
    "$ \\int_{\\mathbf{k}}h(x)dx=1$}\\\\             & \\le&\\inf_{h\\in\\sigma[x]_{2r}}\\int_{\\mathbf{k}}h(x)q(x)dx \\ \\ \\mbox{s.t .",
    "$ \\int_{\\mathbf{k}}h(x)dx=1 $ } \\\\             & \\equiv & \\underline{q}_{{{\\mathbf k}}}^{(2r)}.\\end{aligned}\\ ] ] invoking corollary [ cor : main ] and using that the degree of @xmath116 is @xmath123 , we obtain : @xmath124 where @xmath125 .",
    "the last result improves on the known @xmath126 rate in theorem [ thm : dkls ] .",
    "the key idea in the proof of theorem [ thm : main ] is to replace the boltzman density function by a polynomial approximation .    to this end",
    ", we first recall a basic result on approximating the exponential function by its truncated taylor series .",
    "[ lemf2rsos ] let @xmath127 denote the ( univariate ) polynomial of degree @xmath11 obtained by truncating the taylor series expansion of @xmath128 at the order @xmath11 .",
    "that is , @xmath129 then @xmath130 is a sum of squares of polynomials .",
    "moreover , we have @xmath131    we now define the following approximation of the boltzman density @xmath132 : @xmath133 by construction , @xmath134 is a sum - of - squares polynomial probability density function on @xmath1 , with degree @xmath135 if @xmath0 is a polynomial of degree @xmath43 . moreover , by relation in lemma [ lemf2rsos ] , we obtain @xmath136 from this we can derive the following result .    [ lemma :",
    "err ] for any continuous @xmath0 and scalar @xmath60 one has @xmath137",
    "+   \\frac{\\int_{{{\\mathbf k}}}(f(x)-{f_{\\min,\\mathbf{k } } } ) ( f(x))^{2r+1}dx}{t^{2r+1}(2r+1)!\\int_{{{\\mathbf k } } } \\exp(-f(x)/t)dx}.\\ ] ]    as @xmath138 is a polynomial of degree @xmath135 and a probability density function on @xmath1 ( by ( [ eq : density ] ) ) , we have : @xmath139 using the above inequality ( [ eqphi ] ) for @xmath138 we can upper bound the integral on the right hand side : @xmath140 - { f_{\\min,\\mathbf{k}}}+ \\int_{{\\mathbf k } } { ( f(x)-f_{\\min } ) ( f(x)/t)^{2r+1}\\over ( 2r+1 ) ! \\int_k \\exp(-f(x)/t)dx } dx.\\end{aligned}\\ ] ] combining with the inequality ( [ eq0 ] ) gives the desired result .",
    "we now proceed to the proof of theorem [ thm : main ] . in view of lemma [ lemma :",
    "err ] , we only need to bound the last right - hand - side term in : @xmath141 and to show that @xmath142 .    by the defininition of @xmath143 we have @xmath144 which implies @xmath145 combining with the stirling approximation inequality",
    ", @xmath146 applied to @xmath147 , we obtain : @xmath148 consider @xmath149 , so that @xmath150",
    ". then , using the fact that @xmath151 , we obtain @xmath152 this concludes the proof of theorem [ thm : main ] .",
    "we conclude with a numerical comparison of the two hierarchies of bounds . by theorem [ thm : main ] , it is reasonable to compare the bounds @xmath34 and @xmath153 $ ] , with @xmath154 and @xmath43 the degree of @xmath0 .",
    "thus we define , for the purpose of comparison : @xmath155 , \\mbox { with $ t = \\frac{e\\cdot d \\cdot { \\widehat{f}_{\\max}}}{r}$}.\\ ] ]         the bounds are shown in table [ table : result1 ] .",
    "the bounds @xmath48 were taken from @xcite , while the bounds @xmath157 were computed via numerical integration , in particular using the matlab routine sum2 of the package chebfun @xcite .     &",
    "@xmath48 & @xmath157 & @xmath48 & @xmath157 & @xmath48 & @xmath157 & @xmath48 & @xmath157 + @xmath158 & 118.383 & 367.834 & 4.2817 & 15.4212 & 29.0005&247.462 & 1.0614 & 4.0250 + @xmath159 & 97.6473 & 356.113 & 3.8942 & 14.8521 & 9.5806 & 241.700 & 0.8294 & 3.9697 + @xmath160 & 69.8174 & 345.043 & 3.6894 & 14.3143 & 9.5806 & 236.102 & 0.8010 & 3.9157 + @xmath161 & 63.5454 & 334.585 & 2.9956 & 13.8062 & 4.4398 & 230.663 & 0.8010 & 3.8631 + @xmath162 & 47.0467 & 324.701 & 2.5469 & 13.3262 & 4.4398 & 225.381 & 0.7088 & 3.8118 + @xmath163 & 41.6727 & 315.354 & 2.0430 & 12.8726 & 2.5503 & 220.251 & 0.5655 & 3.7618 + @xmath164 & 34.2140 & 306.510 & 1.8335 & 12.4441 & 2.5503 & 215.269 & 0.5655 & 3.7130 + @xmath165 & 28.7248 & 298.138 & 1.4784 & 12.0390 & 1.7127 & 210.431 & 0.5078 & 3.6654 + @xmath166 & 25.6050 & 290.206 & 1.3764 & 11.6560 & 1.7127 & 205.734 & 0.4060 & 3.6190 + @xmath72 & 21.1869 & 282.687 & 1.1178 & 11.2938 & 1.2775 & 201.173 & 0.4060 & 3.5737 + @xmath167 & 19.5588 & 275.554 & 1.0686 & 10.9511 & 1.2775 & 196.745 & 0.3759 & 3.5296 + @xmath70 & 16.5854 & 268.782 & 0.8742 & 10.6267 & 1.0185 & 192.446 & 0.3004 & 3.4865 + @xmath168 & 15.2815 & 262.348 & 0.8524 & 10.3195 & 1.0185 & 188.272 & 0.3004 & 3.4444 + @xmath169 & 13.4626 & 256.230 & 0.7020 & 10.0284 & 0.8434 & 184.220 & 0.2819 & 3.4034 + @xmath170 & 12.2075 & 250.408 & 0.6952 & 9.75250 & 0.8434 & 180.287 & 0.2300 & 3.3633 + @xmath171 & 11.0959 & 244.863 & 0.5760 & 9.49071 & 0.7113 & 176.469 & 0.2300 & 3.3242 + @xmath172 & 9.9938 & 239.577 & 0.5760 & 9.24220 & 0.7113 & 172.762 & 0.2185 & 3.2860 + @xmath173 & 9.2373 & 234.534 & 0.4815 & 9.00615 & 0.6064 & 169.164 & 0.1817 & 3.2487 +    the results in the table show that the bound in theorem [ thm : main ] is far from tight for these examples .",
    "in fact , it may well be that the convergence rates of @xmath48 and @xmath157 are different for convex @xmath0 .",
    "we know that @xmath174 is the exact convergence rate for the simulated annealing bounds for convex @xmath0 ( cf .",
    "example [ ex : tight bound ] ) , but it was speculated in @xcite that one may in fact have @xmath175 , even for non - convex @xmath0 . determining the exact convergence rate @xmath48 remains an open problem .      for any polynomial @xmath0 and convex body @xmath1 , @xmath34 may be computed by solving a generalised eigenvalue problem with matrices of order @xmath177 , as long as the moments of the lebesgue measure on @xmath1 are known . the generalised eigenvalue computation may be done in @xmath178 operations ; see @xcite for details .",
    "thus this is a polynomial - time procedure for fixed values of @xmath21 .",
    "for non - convex @xmath0 , the complexity of computing @xmath153 $ ] is not known .",
    "when @xmath0 is linear , it is shown in @xcite that @xmath179 $ ] with @xmath180 may be obtained in @xmath181 oracle membership calls for @xmath1 , where the @xmath182 notation suppresses logarithmic factors .",
    "e. de klerk , r. hess and m. laurent . improved convergence rates for lasserre - type hierarchies of upper bounds for box - constrained polynomial optimization .",
    "_ siam j. optim .",
    "_ ( to appear ) , arxiv:1603.03329v1 ( 2016 )    e. de klerk , j .- b .",
    "lasserre , m. laurent , and z. sun .",
    "bound - constrained polynomial optimization using only elementary calculations . _ mathematics of operations research _",
    "( to appear ) , arxiv:1507.04404v2 ( 2016 )    e. de klerk , m. laurent , z. sun .",
    "convergence analysis for lasserre s measure - based hierarchy of upper bounds for polynomial optimization , _ math . program .",
    "a _ , ( 2016 ) .",
    "doi:10.1007/s10107 - 016 - 1043 - 1 .",
    "laurent , m. : sums of squares , moment matrices and optimization over polynomials .",
    "_ in emerging applications of algebraic geometry _ , vol .",
    "149 of i m a volumes in mathematics and its applications , m. putinar and s. sullivant ( eds . ) , springer , pages 157270 ( 2009 )"
  ],
  "abstract_text": [
    "<S> we consider the problem of minimizing a continuous function @xmath0 over a compact set @xmath1 . we compare the hierarchy of upper bounds proposed by lasserre in [ _ siam j. optim . </S>",
    "<S> _ @xmath2 @xmath3 , pp . </S>",
    "<S> @xmath4 to bounds that may be obtained from simulated annealing .    </S>",
    "<S> we show that , when @xmath0 is a polynomial and @xmath1 a convex body , this comparison yields a faster rate of convergence of the lasserre hierarchy than what was previously known in the literature .    </S>",
    "<S> * keywords : * polynomial optimization ; semidefinite optimization ; lasserre hierarchy ; simulated annealing + * ams classification : * 90c22 ; 90c26 ; 90c30 + </S>"
  ]
}