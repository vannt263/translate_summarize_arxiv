{
  "article_text": [
    "the independence sampler is the incorporation of rejection sampling within an mcmc framework .",
    "the rejection sampler obtains samples from a random variable , @xmath0 , with probability density function @xmath1 by first proposing a candidate value @xmath2 from a random variable , @xmath3 , with probability density function @xmath4 , and secondly accepting @xmath2 as a sample from @xmath0 with probability @xmath5 , where @xmath6 .",
    "otherwise @xmath2 is rejected , see @xcite , page 60 .",
    "the success of the rejection sampler depends upon making a good choice of @xmath4 such that @xmath7 is small and that @xmath4 is straightforward to sample from .",
    "the mcmc independence sampler is the modification of the above where a markov chain @xmath8 is constructed with at iteration @xmath9 , a candidate @xmath2 proposed from @xmath3 and if accepted @xmath10 is set equal to @xmath2 .",
    "otherwise @xmath11 . the rejection sampler , and",
    "consequently , the independence sampler can usually be implemented in a straightforward and efficient manner for low dimensional ( target ) distributions but as the dimension of @xmath0 increases it becomes increasingly more challenging to obtain a good choice of @xmath4 .",
    "therefore the independence sampler is rarely used as an mcmc algorithm in its own right but instead independence sampler moves are often incorporated within metropolis - within - gibbs to effectively update low dimensional subsets of @xmath0 , see @xcite , page 15 .",
    "the main focus for independence samplers has been to choose the proposal density @xmath4 so as to have an acceptance probability as close to 1 as possible . whilst this makes intuitive sense ,",
    "the aim of the current paper is to challenge the idea of aiming for an acceptance probability as close to 1 as possible within the context of using independence samplers for updating augmented data in mcmc algorithms .",
    "specifically , we are interested in the bayesian statistical problem of obtaining samples from the posterior distribution of the parameters @xmath12 of a model given data @xmath13 , @xmath14 in the case where the likelihood , @xmath15 is intractable .",
    "we assume that given augmented data @xmath16 , @xmath17 is tractable and an mcmc algorithm can be constructed to obtain samples from the joint posterior of @xmath12 and @xmath16 , @xmath18 .",
    "then it is natural to construct an mcmc algorithm which alternates between updating the parameters and the augmented data as follows :    1 .",
    "update @xmath12 given @xmath13 and @xmath16 .",
    "_ i.e. _  use @xmath19 .",
    "2 .   update @xmath16 given @xmath13 and @xmath12 .",
    "_ i.e. _  use @xmath20 .",
    "our focus is the use of independence samplers to update @xmath16 given @xmath13 and @xmath12 . for updating augmented data",
    "a natural independence sampler often presents itself .",
    "for example , in an epidemic modelling context where @xmath13 denotes the removal times of infected individuals , @xmath12 denotes the infection and infectious period parameters and @xmath16 denotes the infection times of individuals , a natural candidate for the infection time of individual @xmath21 who is removed at time @xmath22 is @xmath23 , where @xmath24 denotes the infectious period distribution , see @xcite , @xcite and section [ ss : homo ] . for non - centered parameterisations , @xcite , we can often denote @xmath25 as a deterministic function @xmath26 with @xmath27 easy to compute , where @xmath28 is a vector of independent and identically distributed uniform random variables , see @xcite and section [ ss : bdm ] . then to update @xmath29 we can propose a new value from @xmath30 .",
    "the dimension of the augmented data , @xmath16 , can be orders of magnitude higher than @xmath12 and @xmath13 , so updating one component of @xmath16 at a time can be prohibitive .",
    "therefore we seek generic guidelines for updating multiple components of @xmath16 at a time and optimising the performance of the resulting independent sampler . specifically , this work formalises findings in @xcite and @xcite in using the independence sampler for data augmentation giving simple guidelines for producing close to optimal independence samplers .",
    "the guidelines obtained are similar to those given in @xcite for the random walk metropolis algorithm and comparisons with the random walk metropolis algorithm are made .",
    "the paper is structured as follows . in section [ s : theo ] , we study the properties of the independence sampler for independent and identically distributed product densities @xmath31 .",
    "this idealised scenario mimics the set up in @xcite where optimal scaling of the random walk metropolis algorithm was first explored and as in @xcite allows us to get a handle on understanding the key factors in optimising the independence sampler .",
    "in particular , we show that the optimal number of components , @xmath32 , of @xmath13 to update , is the @xmath32 which maximises the mean number of components per move . in the case where this optimal @xmath32 is large",
    "this corresponds to a mean acceptance rate of approximately @xmath33 .",
    "thus there is a somewhat surprising link with the optimal scaling of the random walk metropolis algorithm , @xcite with which we make comparison and highlight the benefits of the independence sampler . in section [ s : ex ]",
    ", we explore the optimal performance of the independence sampler for increasingly complex problems . in section [",
    "s : ex : intro ] , we study product gaussian target densities with gaussian and @xmath9-distribution proposals demonstrating the optimal scaling results obtained in section [ s : theo ] . in sections [ ss :",
    "homo ] and [ ss : bdm ] we apply the independence sampler to two epidemic models , the classic homogeneously mixing sir epidemic model , @xcite and @xcite and a birth - death - mutation ( bdm ) model for an emerging , evolving disease , @xcite and @xcite . in section [ ss :",
    "homo ] , we show that for the homogeneously mixing sir epidemic model updating a proportion of the infection times so as to obtain a mean acceptance rate of approximately @xmath33 is optimal .",
    "this demonstrates that as observed with the random walk metropolis algorithm the findings of section [ s : theo ] are informative in designing independence samplers beyond the limited confines of product densities . for the bdm model in section [ ss : bdm ] the findings are somewhat different with a lower optimal mean acceptance rate corresponding to large scale data augmentation",
    ". finally , in section [ s : conc ] , we make some concluding remarks highlighting the possible benefits of the independence sampler over random walk metropolis for large scale data augmentation and the differences seen between the two epidemic models in sections [ ss : homo ] and [ ss : bdm ] .",
    "in this section we consider the theoretical properties of the independence sampler for the special case where @xmath34 , a product of independent and identically distributed univariate densities , @xmath35 .",
    "the main focus is on the asymptotic behaviour as the number of components , @xmath36 mirroring analysis performed in @xcite for the random walk metropolis algorithm .",
    "the aim is to characterise the optimal performance of the independence sampler in terms of the number of components to update and to draw interesting comparisons of similarities and differences with the random walk metropolis algorithm .    for the independence sampler we propose to select uniformly at random @xmath32 components @xmath37 from @xmath38 to update . for @xmath39 , @xmath40",
    "is drawn from @xmath3 with probability density function @xmath41 , whilst for @xmath42 , @xmath43 .",
    "therefore the acceptance probability for the proposed move from @xmath44 to @xmath45 is @xmath46 for @xmath47 and @xmath48 , let @xmath49 denote the position of the markov chain after @xmath9 iterations . as in @xcite , we assume that the markov chain is initiated with @xmath50 drawn from @xmath51 and thus for all @xmath52 , @xmath53 .",
    "the independent and identically distributed nature of the stationary and proposal distributions means that as in @xcite it suffices to focus on the behaviour and performance of the independence sampler on the first component only .",
    "specifically , for @xmath52 , letting @xmath54}$ ] we show that for fixed @xmath32 , as @xmath36 , the movement in the first component of @xmath55 converges to a markov jump process with jumps governed by @xmath56 and @xmath4 .",
    "let @xmath57 , then for the independence sampler to be well - behaved we require that @xmath58 , see @xcite and we make this assumption throughout . for a move to occur in the first component we must propose to move the first component and @xmath59 other components from @xmath60 .",
    "let @xmath61 be a random sample from @xmath62 with @xmath63 , where @xmath64 .",
    "define @xmath65 , @xmath66 and @xmath67 in the obvious fashion .",
    "then we define @xmath68 \\nonumber \\\\ & = & { \\mathbb{e}}_{\\mathbf{y}^{n- } , \\mathbf{j}_{k-1 } } \\left [ 1 \\wedge \\frac{\\omega ( y)}{\\omega ( x_1 ) } \\prod_{i=1}^{k-1 } \\frac{\\omega ( y_{j_i})}{\\omega ( x_{j_i } ) } \\right],\\end{aligned}\\ ] ] where @xmath69 .",
    "a useful observation is that the proposed values @xmath70 are independent of @xmath44 .",
    "let @xmath71 $ ] and let @xmath72 we have the following lemma which mirrors @xcite , lemma 2.1 , which states that with sufficiently high probability we can focus upon @xmath73}^n$ ] ( @xmath74 ) contained in @xmath75 .",
    "the proof of lemma [ lemma1 ] is given in appendix [ app : a ] . [ section ]    [ lemma1 ] for @xmath76 , @xmath77    we are now in position to state and prove the main result of this section , theorem [ thm ] .",
    "[ theorem]theorem    [ thm ] for @xmath78 , let @xmath79 , then @xmath80 where @xmath81 is a markov jump process with infinitesimal generator @xmath82 for any @xmath83 function @xmath84 .    * proof .",
    "* we begin by defining the ( discrete time ) generator of @xmath85 , @xmath86 , \\end{aligned}\\ ] ] where @xmath84 is any @xmath83 function of the first component .",
    "note that if there is no proposed update in the first component then @xmath87 . therefore letting @xmath88",
    "if there is a proposed update of the first component and 0 otherwise , we have that @xmath89 \\nonumber \\\\ & = & n \\times \\frac{k}{n } \\times { \\mathbb{e}}\\left[\\left . \\ { h ( \\mathbf{y}^n ) - h ( \\mathbf{x}^n ) \\ }   \\left\\ { 1 \\wedge \\frac{\\pi_n ( \\mathbf{y}^n)}{\\pi_n ( \\mathbf{x}^n ) } \\right\\ } \\right| \\chi^n = 1 \\right ] \\nonumber \\\\ & = & k { \\mathbb{e}}_{y_1 } \\left [ ( h ( y_1 ) - h ( x_1 ) ) { \\mathbb{e}}_{\\mathbf{y}^{n- } , \\mathbf{j}_{k-1 } } \\left [ 1 \\wedge \\frac{\\omega ( y_1)}{\\omega ( x_1 ) } \\prod_{j=1}^{k-1 } \\frac{\\omega ( y_{j_j})}{\\omega ( x_{j_j } ) } \\right ] \\right ] . \\nonumber \\\\ \\end{aligned}\\ ] ]    we compare @xmath90 with the generator @xmath91 defined in for the limiting jump process .",
    "now by , for all @xmath92 and @xmath93 , @xmath94 - h^\\ast ( y , x )   \\right ) \\ , dy   \\right| \\nonumber \\\\ & = & \\left|   \\int \\ { h ( y ) - h ( x_1 ) \\ } q(y ) \\left ( h(y , x_1 , \\mathbf{x}^{n- } ) - h^\\ast ( y , x )   \\right ) \\ , dy   \\right| \\nonumber \\\\ & \\leq & 2 \\sup_z | h(z)| \\int q(y ) \\left ( h(y , \\mathbf{x}^n ) - h^\\ast ( y , x )   \\right ) \\ , dy \\nonumber \\\\ & \\leq & 2 \\sup_z | h(z)| n^{-\\frac{1}{8 } } \\rightarrow 0 \\hspace{0.5 cm } \\mbox{as } { n \\rightarrow \\infty}. \\end{aligned}\\ ] ] hence , @xmath95    the theorem follows along identical lines to @xcite , theorem 1.1 .",
    "since @xmath83 separates points ( see , @xcite , page 113 ) , the theorem follows from and lemma [ lemma1 ] by corollary 8.7 ( f ) of chapter 4 of @xcite .",
    "@xmath96    we proceed by discussing properties of the limiting jump process .",
    "let @xmath97 where @xmath98 and @xmath99 .",
    "then @xmath100 $ ] denotes the mean acceptance probability , in stationarity , of a proposed move and @xmath101 $ ] denotes the corresponding mean number of components updated .",
    "moreover , @xmath101 $ ] denotes the mean number of jumps , per unit time , of the limiting jump process , and hence , we seek @xmath32 which maximises @xmath101 $ ] .",
    "the distribution of @xmath102 depends largely on the _ closeness _ of the target ( @xmath1 ) and proposal ( @xmath4 ) distributions with @xmath103 if for all @xmath104 , @xmath105 .",
    "let @xmath106 , then @xmath107 where the @xmath108 are independent and identically distributed . note that @xmath109 = -d ( q \\| f)$ ] and @xmath110 = d ( f \\| q)$ ] , where for two probability density functions @xmath111 and @xmath112",
    ", @xmath113 is the kullback - leibler divergence .",
    "hence , @xmath114 = - \\ { d ( q \\| f ) + d ( f \\| q)\\ } = -i , \\mbox { say } , \\end{aligned}\\ ] ] which makes explicit the role played by the _ closeness _ of the two densities . it should be noted that @xmath115 if there exists @xmath104 such that @xmath116 and @xmath117 , in such cases efficient independence sampling may still exist , for example , @xmath118 and @xmath119 for small , positive @xmath120 .    for finite @xmath121",
    ", it follows from by the central limit theorem that for large @xmath32 , @xmath122 is approximately gaussian with mean @xmath123 $ ] and variance @xmath124 , say .",
    "now if @xmath121 is small , which will be the case where the central limit theorem is relevant , then @xmath125 .",
    "moreover , if @xmath126 where @xmath127 is small , then it is straightforward to show that @xmath128 and that @xmath129 .",
    "thus for @xmath32 large , with @xmath130 , we have by @xcite , proposition 2.4 , that @xmath131 & \\approx & k { \\mathbb{e } } [ 1 \\wedge \\exp ( v_k^\\ast ) ] \\nonumber \\\\ & = & k \\times \\left\\{\\phi \\left ( - \\frac{k i}{\\sqrt{k j } } \\right ) + \\exp \\left ( - ki + \\frac{kj}{2 } \\right ) \\phi \\left ( - \\sqrt{kj } + \\frac{ki}{\\sqrt{k j } } \\right ) \\right\\ } \\nonumber \\\\ & \\approx & k \\times 2 \\phi \\left ( - \\sqrt{\\frac{k i}{2 } } \\right),\\end{aligned}\\ ] ] where the latter approximation follows from setting @xmath132 .",
    "replacing @xmath32 by @xmath133 and @xmath121 by @xmath134 in the right hand side of , we obtain @xmath135 , which is the function maximized in @xcite , corollary 1.2 to maximise the optimal scaling of the random walk metropolis algorithm .",
    "the only difference is the form of @xmath121 which here depends upon the kullback - leibler divergence between the target and proposal distribution , whereas in @xcite @xmath136 $ ] and depends upon the _ smoothness _ of @xmath1 .",
    "most importantly , @xmath137 maximises @xmath138 and therefore @xmath32 should be chosen approximately equal to @xmath139 . thus if @xmath121 is small ( there is close agreement between @xmath1 and @xmath4 ) @xmath32 will be large .",
    "moreover , mirroring @xcite , corollary 1.2 , such a @xmath32 corresponds to a mean acceptance probability of ( approximately ) @xmath140 .",
    "thus it is not necessary to compute @xmath121 but instead suffices to monitor the mean acceptance probability .",
    "this will be shown to be a useful guiding principle in the examples below .",
    "however , it should be noted that scenarios exist , see section [ ss : homo ] below , where the acceptance rate is above ( below ) 0.234 for all @xmath32 , in such cases it is optimal to choose @xmath141 @xmath142 .    returning to optimising the independence sampler in the case @xmath118 and @xmath119",
    ", it is straightforward to show that the probability a proposed move is accepted is @xmath143 . optimising the function @xmath144 gives @xmath145 , and hence for small @xmath120 , @xmath146",
    "thus as @xmath147 , the optimal acceptance probability ( @xmath148 ) converges to @xmath149 .",
    "therefore non - trivial asymptotic acceptance probabilities can exist in the case @xmath150 and typically these will be different from 0.234 .",
    "a key question is how does the independence sampler compare to the random walk metropolis algorithm .",
    "provided @xmath58 , theorem [ thm ] holds and we have that the mixing of the independence sampler algorithm is @xmath151 , the same order of mixing as for the random walk metropolis algorithm for continuous ( and sufficiently differentiable ) densities .",
    "the mixing of the random walk metropolis algorithm for discontinuous densities is @xmath152 , @xcite whilst modifications such as metropolis adjusted langevin algorithms ( mala ) and hybrid monte carlo ( hmc ) algorithms mix in @xmath153 and @xmath154 iterations , see @xcite and @xcite , respectively , for sufficiently well behaved ( continuous ) target densities .",
    "thus the independence sampler is competitive with the random walk metropolis algorithm and theorem [ thm ] holds under very weak conditions compared with those imposed for corresponding random walk metropolis algorithms .",
    "the similarity of the right hand side of to @xmath138 might suggest that computing @xmath121 for the two algorithms would assist in comparing there performances with smaller @xmath121 the better .",
    "however , the different nature of the moves , global in the independence sampler and local in the random walk metropolis , means that this is not the case . in simulation studies with @xmath155 , @xmath156 and a range of @xmath157 , the independence sampler , with appropriately chosen @xmath32",
    "was found to outperform the optimal random walk metropolis algorithm ( @xmath158 ) for @xmath159 .",
    "thus the independence sampler is competitive with , and often superior to , random walk metropolis , for continuous target densities so long as a reasonable choice of @xmath4 is made , and is clearly preferable for discontinuous target densities which is often the case in real life bayesian problems , see section [ s : ex ] .",
    "in this section we illustrate how large scale independence sampling can be exploited to construct effective mcmc algorithms .",
    "we start with an independent and identically distributed gaussian product density as the target distribution and consider both gaussian and @xmath9-distribution proposals . specifically , we take @xmath31 , where @xmath160 is a standard gaussian density .",
    "the proposal distributions are symmetric about 0 with gaussian proposals @xmath161 , where @xmath162 and @xmath9-distribution proposals @xmath163 @xmath164 .",
    "we conducted a simulation study using 5 gaussian and 5 @xmath9-distribution proposals with @xmath165 and @xmath166 iterations of the mcmc algorithm starting from the stationary distribution . for each proposal distribution we considered 50 choices of @xmath32 , the exact choices of which depended on @xmath121 and",
    "were chosen to give acceptance rates on the full range 0 to 1 .",
    "for the gaussian proposal it is straightforward to show that @xmath167 .",
    "we considered @xmath168 with corresponding @xmath169 .",
    "a key quantity for comparing the independence sampler for different choices of @xmath170 , and hence @xmath121 , is the normalised efficiency .",
    "we define the normalised efficiency for @xmath32 as the mean number of components updated ( @xmath171 acceptance rate ) when proposing to update @xmath32 components divided through by the maximum mean number of components updated for @xmath172 . correspondingly the normalised theoretical efficiency is given by @xmath173 from applying the central limit theorem approximation obtained in section [ s : theo ] . the plots in figure [ fig.gaus ]",
    "show that in all cases the optimal acceptance rate is close to 0.234 with very similar behaviour for the normalised efficiency varying with acceptance rate , even for @xmath174 with @xmath175 .",
    "similar results are obtained in section in @xcite , section 6 for the optimal performance of the random walk metropolis algorithm .",
    "as @xmath176 , @xmath177 and the agreement between the observed normalised efficiency normalised theoretical efficiency becomes very close .",
    "[ h ]    for the @xmath9-distribution , @xmath150 for @xmath178 , otherwise @xmath179 - { \\mathbb{e } } [ \\log ( 1 + y_\\nu^2/\\nu ) ] \\right\\},\\ ] ] where @xmath155 and @xmath180 .",
    "it is not possible to obtain a closed form analytical expression for @xmath121 but it is straightforward to estimate using monte carlo integration .",
    "we consider @xmath181 with corresponding @xmath182 .",
    "the plots in figure [ fig.t ] show that the optimal acceptance rate is higher than 0.234 for a @xmath9-distribution proposal with an optimal acceptance rate of 0.383 corresponding to @xmath183 for a @xmath184 proposal .",
    "note that this is close to @xmath185 , the optimal acceptance rate of the uniform distributions example given in section [ s : theo ] .",
    "it is worth noting that choosing @xmath32 to obtain an acceptance rate of approximately 0.234 is in general a good approach as only a small loss in efficiency is observed .",
    "as @xmath186 increases the optimal acceptance rate converges towards 0.234 and the normalised efficiency tends towards the theoretical normalised efficiency given by the central limit theorem approximation .",
    "this is further demonstrated in figure [ fig.t2 ] by plotting normalised efficiency against normalised theoretical efficiency .",
    "note that @xmath187 and @xmath188 do not feature on this plot as @xmath189 .",
    "[ h ]      in this section we show how the importance sampler can be applied to temporally observed , homogeneously mixing sir epidemic models , @xcite .",
    "we assume that there is a population of size @xmath190 with the disease introduced into the population via a single introductory case .",
    "( the extension to multiple introductory cases is trivial . )",
    "we assume that the disease follows an @xmath191 epidemic model , where initially all individuals , except the introductory case , are susceptible . on becoming infectious ,",
    "an individual is infectious for a given period of time , distributed according to a gamma random variable @xmath192 .",
    "( alternative infectious period distributions can easily be considered . )",
    "whilst infectious , an individual @xmath21 , say , makes infectious contacts at the points of a homogeneous poisson point process with rate @xmath193 with the individual contacted chosen uniformly at random from the entire population .",
    "infectious contacts with susceptible individuals result in the immediate infection of the individual and the start of their infectious period .",
    "infectious contacts with infectives have no effect on the recipient .",
    "suppose that @xmath194 individuals are infected during the course of the epidemic and we are analysing the completed epidemic data .",
    "for each individual , @xmath21 say , infected during the course of the epidemic there will be an infection time , @xmath195 and a removal ( recovery ) time , @xmath196 , which mark the start and end of the infectious period , respectively .",
    "we follow @xcite , @xcite and @xcite in assuming that the removal times , @xmath197 are observed , whilst the infection times @xmath198 are unobserved .",
    "furthermore , we assume that the removal times are ordered such that @xmath199 .",
    "the key interest is in the posterior distribution of @xmath200 and to obtain samples from this distribution imputation of @xmath201 is required .",
    "we use the mcmc algorithm proposed in @xcite , section 3 with the modification that the number of components to be updated is fixed to @xmath202 . as with @xcite ,",
    "the mcmc algorithm is applied to the extensively studied abakaliki smallpox outbreak , @xcite , @xcite , where @xmath203 and @xmath204 .",
    "we considered various fixed values of @xmath205 with optimal @xmath206 and 30 , respectively , based upon the maximised mean number of components updated over 100000 iterations , see figure [ fig.hme_accept_kaccept_k_m030 ] . for @xmath205 ,",
    "the corresponding values of @xmath32 which had acceptance rates closest to @xmath207 were @xmath208 and 29 , respectively . thus choosing @xmath32 so that the acceptance rate is close to @xmath207 is effective in obtaining a close to optimal algorithm . in @xcite , the situation where @xmath209 is assumed to be unknown is also considered with the posterior mean of @xmath209 being @xmath210 . for unknown @xmath209 ,",
    "the acceptance rate is above @xmath207 for all @xmath32 and thus @xmath211 performs optimally .",
    "we can go further in illustrating the usefulness of the theoretical results derived in section [ s : theo ] for choosing @xmath32 . in figure",
    "[ fig.hme_kaccept_accept_m030 ] , we plot the normalised efficiency for @xmath212 , since for @xmath213 , the acceptance rate is always above @xmath207 . also on the plot ( in red )",
    "is the normalised theoretical curve @xmath214 given by against acceptance rate @xmath215 . in a similar fashion to section [ s : ex : intro ] this illustrates that the asymptotic results which are valid as the number of components updated tend to @xmath216 are applicable for small @xmath32 .",
    "[ h ]    [ h ]    a simulation study was conducted to study the general applicability of the results obtained above for the abakaliki data .",
    "data sets were simulated with @xmath217 , @xmath218 and @xmath219 with @xmath220 chosen to give a mean infectious period of 10 and @xmath193 to give the mean size of a major epidemic outbreak to be 10 . for each @xmath209 , the optimal @xmath32 increases with @xmath190 and vice versa . throughout choosing @xmath32 with acceptance rate closest to @xmath207 produced close to optimal performance .",
    "plots of the normalised efficiency against the acceptance rate showed increasing agreement with the asymptotic theoretical curve as @xmath190 increases .      in this section",
    "we consider a birth - death - mutation ( bdm ) model which is applicable to the early stages of a mutating disease .",
    "the model has previously been used by @xcite to analyse data from a tuberculosis outbreak in san francisco in the early 1990s reported in @xcite .",
    "we explore and seek to optimise the performance of the forward simulation mcmc algorithm introduced by @xcite .",
    "note that all the other analyses reported above used abc algorithms .    the data consist of the genotypes of 473 bacteria samples sampled from individuals infected with tuberculosis in san francisco during an observational period in 1991 - 92 .",
    "the data are clustered by genotype and summarised in table [ tab : tub ] .",
    "let @xmath221 denote the total number of tuberculosis cases at time @xmath9 .",
    "the data are assumed to be a random sample taken at time @xmath222 , where @xmath223 evolving from @xmath224 .",
    ".[tab : tub ] observed cluster size distribution of tuberculosis bacteria genotype data , @xcite . [ cols=\"<,>,>,>,>,>,>,>,>,>,>\",options=\"header \" , ]     the bdm model is a markov process defined as follows .",
    "individuals are classified by ( geno)type .",
    "each individual born into the process has an exponentially distributed lifetime ( infectious period ) with mean @xmath225 .",
    "whilst alive individuals give birth ( infects ) and mutates at the points of independent homogeneous poisson point processes with rates @xmath209 and @xmath226 , respectively .",
    "each individual born inherits the ( geno)type of their parent and all mutations result in the creation of a new , previously unseen ( geno)type ( infinite allele model , @xcite ) .",
    "we reparameterise the model by setting @xmath227 , @xmath228 and @xmath229 , where @xmath230 is the rate at which events occur for an individual , @xmath231 is the probability that the event is a birth ( infection ) and @xmath232 is the probability that the event is a death ( recovery ) .",
    "since the stopping time @xmath222 at which the population is observed only depends upon the number of individuals alive in the population , there is no information in the data about @xmath230 .",
    "thus , without loss of generality , we assume @xmath233 making inference about @xmath234 given the genotype data @xmath13 . in order to construct a tractable likelihood it is necessary to generate the state of the population at time @xmath222 , @xmath235 .",
    "this can be done using a non - centered parameterisation @xcite where the augmented data @xmath236 consist of realisations of @xmath30 with @xmath237 combine with @xmath234 to generate the underlying state of the bdm model at time @xmath222 and @xmath238 is used to estimate the probability of observing @xmath13 .",
    "details of the construction are given in @xcite , section 4 .",
    "the time consuming step of the mcmc algorithm for the bdm model is the simulation of the state of the process using @xmath237 and @xmath234 . in @xcite ,",
    "@xmath234 are updated using random walk metropolis keeping @xmath237 fixed and @xmath237 are updated using an independence sampler , draws from @xmath30 , keeping @xmath234 fixed .",
    "we thus focus on the independence sampler for updating @xmath237 .",
    "note that @xmath238 is updated by a separate independence sampler but this is very fast to implement ( no need to simulate the bdm process ) , and so we do nt comment on this step .",
    "the dimensions of @xmath239 and @xmath240 are the same but vary from iteration to iteration , typically being around 30000 .",
    "to circumvent issues with this @xcite used random vectors of a fixed length @xmath241 with only those elements needed to simulate the process used . in this paper",
    "we also used a fixed length vector updating @xmath32 out of @xmath242 components in @xmath239 and @xmath240 noting that in each simulation not all ( updated ) components will be used .    in @xcite , @xmath239 and @xmath240",
    "are broken down into blocks of 50 components with 1 component in each block proposed to be updated .",
    "this amounts to proposing to update @xmath243 values in each iteration of which typically around 600 are used in the simulation . in this paper",
    "we propose to update @xmath32 components each of @xmath239 and @xmath240 , @xmath244 and @xmath245 , where @xmath246 ( @xmath247 ) is a uniformly random sample without replacement from @xmath248 , for the sake of consistency with the updating strategy throughout this paper .",
    "in addition to using different values for @xmath32 , we also examine the performance of the algorithm using @xmath249 and the original @xmath250 , which are all found to be empirically sufficient .",
    "we ran the mcmc algorithm for @xmath251 iterations with the first @xmath252 iterations discarded as burn - in .",
    "the acceptance rate is plotted against @xmath32 for all three values of @xmath242 on the left of figure [ fig.bdm_accept_kaccept_k ] , which is analogous to figure [ fig.hme_accept_kaccept_k_m030 ] , with the mean number of components updated on the right .",
    "the results shown in figures [ fig.bdm_accept_kaccept_k ] demonstrate an interesting departure from those found earlier in the paper with an optimal acceptance rate of @xmath207 .",
    "the mean number of components updated increases with @xmath32 even as the acceptance rate drops below @xmath253 .",
    "however , for both parameters @xmath231 and @xmath232 , the effective sample size levels off at around 3000 for all @xmath254 , which suggests that seeking to optimise the mean number of components updated does not tell the full story in this case .",
    "in this paper we have demonstrated the potential benefits , both theoretical and practical , of the independence sampler over the random walk metropolis algorithm . in particular , we have shown that simple choices of proposal distributions can be used to construct effective independence samplers and that similar considerations to the tuning of the random walk metropolis algorithm are required .",
    "there are a number of points to consider in the wider application of the results derived in section [ s : theo ] and applied in section [ s : ex ] .",
    "firstly , we have not considered the computational time required to update @xmath32 components . in the homogeneously mixing epidemic model ( section [ ss : homo ] ) , and in particular , the bdm model ( section [ ss : bdm ] ) the time taken per iteration was essentially independent of @xmath32 .",
    "however , it is possible for the homogeneously mixing epidemic model by careful updating of the calculation of the likelihood for the time taken per iteration to be smaller for smaller @xmath32 . in such cases the optimal acceptance rate will be larger than @xmath207 and if the time per iteration is proportional to @xmath32 it will be optimal to update a single component at a time . secondly , the theoretical results of section [ s : theo ] for independent and identically distributed product densities are shown to give clear guidance for optimising the independence sampler for the homogeneously mixing epidemic model but not for the bdm model .",
    "the reason for this difference is not immediately obvious but is likely to depend on the relationship of the observed data to the augmented data . for the homogeneously mixing epidemics the local behaviour of @xmath201 is important , for example ensuring @xmath201 is consistent with an epidemic outbreak , whereas for the bdm model it is global properties of @xmath255 , the total numbers of births , deaths and mutations which are most important . for the random walk metropolis algorithm",
    "optimal scaling results differ depending upon whether the acceptance probability depends on local behaviour ( discontinuous product densities , @xcite ) or global behaviour ( continuous product densities , @xcite , elliptically symmetric densities @xcite ) of the proposed moves .",
    "this research was supported by the engineering and physical sciences research council under grant ep / j008443/1 .",
    "we would like to thank an anonymous referee for their careful reading of the paper and suggestions for improving presentation of the findings .",
    "bailey , n.t.j .",
    "( 1975 ) _ the mathematical theory of infectious diseases and its applications .",
    "second edition .",
    "_ griffin , london .",
    "beskos , a. , pillai , n. , roberts , g. , sanz - serna , j - m . and",
    "stuart , a. ( 2013 ) optimal tuning of the hybrid monte carlo algorithm .",
    "_ bernoulli _ , * 19 * , 15011534 .",
    "dellaportas , p. and roberts , g.o .",
    "( 2013 ) an introduction to mcmc .",
    "_ spatial statistics and computational methods _ ( j.  mller , eds . ) springer , new york , 143 .",
    "del moral , p. , doucet , a.  and jasra , a. ( 2012 ) an adaptive sequential monte carlo method for approximate bayesian compuation .",
    "* 22 * , 10091020 .",
    "ethier , s.n .  and kurtz , t.g .",
    "( 1986 ) _ markov processes , characterization and convergence . _",
    "wiley , new york .",
    "fearnhead , p. and prangle , d. ( 2012 ) constructing summary statistics for approximate bayesian computation : semi - automatic approximate bayesian computation ( with discussion ) .",
    "_ j. r. stat .",
    "methodol . _ * 74 * , 419474    kimura , m. and crow , j. ( 1964 ) .",
    "the number of alleles that can be maintained in a finite population .",
    "_ genetics _ * 49 * , 725-738 .",
    "mckinley , t.j . ,",
    "ross , j.v . ,",
    "deardon , r. and cook , a.r .",
    "( 2014 ) simulation - based bayesian inference for epidemic models .",
    "statist . data anal . _ * 71 * , 434447 .",
    "neal , p. and huang , c.l.t .",
    "( 2015 ) forward simulation mcmc with applications to stochastic epidemic models .",
    "j. stat . _",
    "* 42 * , 378396 .",
    "neal , p.j . and roberts , g.o .",
    "( 2005 ) a case study in non - centering for data augmentation : stochastic epidemics .",
    "comput . _ * 15 * , 315327 .",
    "neal , p.j . and roberts , g.o .",
    "( 2006 ) optimal scaling for partially updating mcmc algorithms .",
    "* 16 * , 475515 .",
    "neal , p.j . , roberts , g.o . and yuen , w.k .",
    "( 2012 ) optimal scaling of random walk metropolis algorithms with discontinuous target densities .",
    "* 22 * , 18801927    oneill , p.d .  and becker , n.g .",
    "inference for an epidemic when susceptibility varies .",
    "_ biostatistics _ * 2 * , 99108 .",
    "oneill , p.d .  and roberts , g.o .",
    "bayesian inference for partially observed stochastic epidemics .",
    "ser . a _ * 162 * , 121129 .",
    "papaspoliopoulos , o.  , roberts , g.o .  and skld , m.  ( 2003 ) non - centered parameterisations for hierarchical models and data augmentation",
    ". _ bayesian statistics 7 _ ( j.m .",
    "bernardo , m.j .",
    "bayarri , j.o .",
    "berger , a.p .",
    "dawid , d.  heckerman , a.f.m .",
    "smith and m.  west , eds . ) oxford university press , 307326 .",
    "ripley , b. ( 1987 ) _ stochastic simulation .",
    "_ wiley , new york .",
    "roberts , g.o . ,",
    "gelman , a. and gilks , w.r .",
    "( 1997 ) weak convergence and optimal scaling of random walk metropolis algorithms . _",
    "_ , * 7 * , 110120",
    ".    roberts , g.  o.  and rosenthal , j.  s.  ( 1998 ) optimal scaling of discrete approximations to langevin diffusions .",
    "_ j. r. stat .",
    "methodol . _ * 60 * 255268 .",
    "sherlock , c. and roberts , g.o .",
    "( 2009 ) optimal scaling of the random walk metropolis on elliptically symmetric unimodal targets .",
    "_ bernoulli _ * 15 * , 774798 .",
    "sisson , s.  a. , fan , y.  and tanaka , m.  m.  ( 2007 ) sequential monte carlo without likelihoods .",
    "usa _ , * 104 * , 17601765 .",
    "small , p.  m. , hopewell , p.  c. , singh , s.  p. , paz , a. , parsonnet , j. , ruston , d.  c. , schecter , g.  f. , daley , c.  l. , and schoolnik , g.  k.  ( 1994 ) the epidemiology of tuberculosis in san francisco .",
    "a population - based study using conventional and molecular methods . _ new england journal of medicine _ * 330 * 1703 - 1709 .",
    "tanaka , m.  m. , francis , a.  r. , luciani , f. and sisson , s.  a.  ( 2006 ) using approximate bayesian computation to estimate tuberculosis transmission parameters from genotype data .",
    "_ genetics _ * 173 * , 15111520 .",
    "tiernay , l. ( 1994 ) markov chains for exploring posterior distributions .",
    "statist . _",
    "* 22 * , 17011728 .",
    "xiang , f. and neal , p. ( 2014 ) efficient mcmc for temporal epidemics via parameter reduction .",
    "statist . data anal . _ * 80 * , 240250 .",
    "since @xmath256 , for all @xmath257 , @xmath258 , since @xmath259 is the stationary distribution of @xmath74 .",
    "therefore , we have that @xmath260        let @xmath266 . then letting @xmath267 , \\end{aligned}\\ ] ] we note that for all @xmath268 , @xmath269 , where @xmath270 denotes equality in distribution .",
    "hence for all @xmath271 , @xmath272 = h^\\ast ( y , x_1)$ ] . therefore given that @xmath273 it follows that @xmath274)^4 ] \\nonumber \\\\ & = & \\binom{n-1}{k-1}^{-4 } \\sum_{\\mathbf{i}_1 \\in \\mathcal{i}_n } \\sum_{\\mathbf{i}_2 \\in \\mathcal{i}_n } \\sum_{\\mathbf{i}_3 \\in \\mathcal{i}_n } \\sum_{\\mathbf{i}_4 \\in \\mathcal{i}_n } { \\mathbb{e}}\\left [ \\prod_{j=1}^4 ( \\hat{h}_{\\mathbf{i}_j } ( y , x_1 , \\mathbf{x}_0^{n- } ) - { \\mathbb{e}}[\\hat{h}_{\\mathbf{i}_j } ( y , x_1 , \\mathbf{x}_0^{n- } ) ] )   \\right ] .",
    "\\nonumber \\\\\\end{aligned}\\ ] ] note that if @xmath268 have no elements in common then @xmath275 and @xmath276 are independent",
    ". therefore @xmath277 )   ] $ ] is only non - zero if and only if for @xmath278 , @xmath279 has at least an element in common with one the other indices .",
    "moreover , @xmath280 )   ] | \\leq 1 $ ] .",
    "the number of combinations of @xmath281 such that @xmath282 and @xmath283 have at least one element in common is @xmath284 which is bounded above by @xmath285 for all sufficiently large @xmath242 .",
    "similarly , the number of combinations of @xmath286 such that @xmath283 , @xmath287 and @xmath288 all have at least one element in common with @xmath282 is @xmath289 which is bounded above by @xmath290 for all sufficiently large @xmath242 .",
    "now @xmath277 )   ] $ ] is only non - zero if either @xmath286 can be grouped into two pairs such that both pairs have at least one element in common or if three of the components all have at least one element in common with the fourth .",
    "( note that there is overlap between these two classifications . ) thus using and , it is straightforward to combine with to show that @xmath291)^4 ] \\nonumber \\\\ & \\leq & \\binom{n-1}{k-1}^{-4 } \\left\\ { 3 \\left(\\frac{n^{2k-3}}{\\{(k-2)!\\}^2 } \\right)^2 + 4 \\frac{(k-1)^2 n^{4k-7}}{\\ { ( k-2)!\\}^4 } \\right\\ } \\nonumber \\\\ & \\leq & \\frac{(k-1)^4}{(n - k)^{4k-4 } } \\left\\ { 3 n^{4k-6 } + 4 ( k-1)^2 n^{4k-7 } \\right\\}. \\end{aligned}\\ ] ] since the bound obtained in , holds for all @xmath292 , it follows from and that @xmath293 the lemma immediately follows by combining and ."
  ],
  "abstract_text": [
    "<S> the independence sampler is one of the most commonly used mcmc algorithms usually as a component of a metropolis - within - gibbs algorithm . </S>",
    "<S> the common focus for the independence sampler is on the choice of proposal distribution to obtain an as high as possible acceptance rate . in this paper </S>",
    "<S> we have a somewhat different focus concentrating on the use of the independence sampler for updating augmented data in a bayesian framework where a natural proposal distribution for the independence sampler exists . </S>",
    "<S> thus we concentrate on the proportion of the augmented data to update to optimise the independence sampler . </S>",
    "<S> generic guidelines for optimising the independence sampler are obtained for independent and identically distributed product densities mirroring findings for the random walk metropolis algorithm . </S>",
    "<S> the generic guidelines are shown to be informative beyond the narrow confines of idealised product densities in two epidemic examples .    _ </S>",
    "<S> correspondence address : _ department of mathematics and statistics , fylde college , lancaster university , lancaster , la1 4yf , uk    _ running title : _ </S>",
    "<S> optimal scaling of the independence sampler    * keywords : * augmented data ; birth - death - mutation model ; markov jump process ; mcmc ; sir epidemic model . </S>"
  ]
}