{
  "article_text": [
    "many applications require realistic 3d human shapes .",
    "for instance , 3d human models are used to design products that fit a target population .",
    "typically , these shapes need to have certain characteristics or to be samples from a population .",
    "although it is possible to digitize humans using 3d imaging technologies , it is impractical to find and scan suitable human subjects for each individual application . on the other hand",
    ", there is a long history of using anthropometric measurements to describe the human shape .",
    "these measurements are linear and curvilinear distances between anatomical landmarks or circumferences at predefined locations . in spite of providing limited shape information , they are readily available , and therefore widely used .",
    "intuitively , the linear measurements should encode information about the body shape .",
    "if accurate 3d human shape can be inferred from a simple set of measurements , traditional anthropometric data can be leveraged to create 3d datasets without resorting to expensive scanning equipment .",
    "the early attempts at solving this problem deform a generic human model to fit the measurement data .",
    "however , the models thus obtained are not necessarily human forms because generating a human shape from a sparse set of measurements is an under - constrained problem .",
    "more sophisticated methods use knowledge of the human shape learned from a database of 3d scans . a statistical model can be built from a set of registered 3d scans and a relationship between the measurements and the shape space can be established . in doing so , detailed 3d shapes can be predicted from sparse and partial shape data .",
    "apart from predicting 3d shapes from measurements  @xcite , other partial shape information , such as marker positions  @xcite and 2d images  @xcite , has also been used to reconstruct 3d shapes .",
    "existing methods that predict the 3d shapes using a statistical model limit the generated shapes to the space spanned by the shape model ( more specifically , within two standard deviations of the shape variability ) and local variations of human shapes that are outside this space can not be predicted accurately .",
    "this means that these methods require a 3d database that accurately represents a target population ( for instance , human subjects of different ethnicities and different weight classes must be present in the database ) . to apply these techniques , one must carefully choose a target population and acquire a representative database .",
    "in reality , the acquisition of a 3d anthropometry data that represents a target population well is complicated and expensive ( the acquisition of the civilian american and european surface anthropometry resource took 4 years and cost $ 6 million ) .    in this paper",
    ", we address the problem of estimating 3d human body and face shapes given a set of anthropometric measurements .",
    "our main goal , in contrast to previous work , is to predict shapes that are inside the space of human shapes , but still account for local variations not captured by the training data .",
    "this extrapolation allows us to create human shapes based on relatively small 3d databases .",
    "as most of the previous approaches , our method does not take posture or expression changes into account .",
    "that is , we assume that all of the training data is in a standard pose .",
    "this scenario is commonly assumed since in a typical 3d anthropometry survey , the human subjects are asked to maintain a standard posture .",
    "the rest of the paper is organized as follows .",
    "section  [ approach ] gives an overview of the approach , and section  [ refinement ] outlines the details of a shape refinement step , which constitutes the main contribution of this paper .",
    "we aim for design applications in engineering where accuracy is essential .",
    "we show , through experiments , that straightforward application of existing techniques does not produce satisfactory results ( section  [ experiments ] ) .",
    "this section reviews existing work that aims to estimate 3d human shapes based on partial input information .",
    "we categorize the related literature by the type of input data that is used to predict human shapes .",
    "decarlo et al .",
    "@xcite presented an early attempt at using anthropometric measurements to compute human face shapes .",
    "the method generates a random set of measurements based on a set of rules that capture , for instance , typical facial proportions .",
    "to create a 3d face shape , the method deforms a template model to fit these measurements using a free - form deformation technique called variational modeling .",
    "variational modeling allows to give the measurements as constraints when deforming the template . to ensure that the estimated shape remains in the shape space of human shapes ,",
    "much care is taken when creating the measurements that are used as constraints .",
    "while this method generates human - like face shapes using a statistical model , the accuracy of the shapes created by this method is limited by the sparse set of measurements used to represent the training data .",
    "that is , the results are overly smooth and do not contain realistic details .",
    "it is not straight forward to extend this technique to allow for the generation of human body shapes from an arbitrary set of anthropometric measurements . by combining statistical learning with a mesh - based technique ,",
    "our method allows the generation of realistic and detailed human body shapes from an arbitrary set of anthropometric measurements .",
    "the following approaches estimate human body shapes from a discrete set of measurements on the body , all proceeding by learning a linear or near - linear mapping between the training set of human shapes and the parameter space of measurements and then using this mapping to predict a shape based on a new set of measurements .",
    "while these approaches work well when the predicted shape is inside the shape space spanned by the training set , they do not allow for extrapolations from this shape space .",
    "wang  @xcite uses a parameterized database of human shapes consisting of _ feature patches _ to find a new human shape based on a given set of measurements .",
    "feature patches are initialized to smooth patches that are subsequently refined to capture geometric details of the body shape .",
    "while this refinement does not maintain the smoothness of the patches , the final results are visually smooth and do not contain realistic localized shape details .",
    "the approach finds models in the database with measurements similar to the given set of measurements and computes the new human shape as a linear combination of these models .",
    "wei et al .",
    "@xcite use a similar approach , but the models are represented using a layer - based representation .",
    "allen et al .",
    "@xcite compute a new triangular mesh based on a given set of measurements . starting from a parameterized database of human bodies in similar poses , the approach performs principal component analysis ( pca ) of the data",
    "this yields one pca weight for each training shape .",
    "the training database is used to learn a linear mapping from the set of measurements measured on the training data to the pca space .",
    "this mapping is called _",
    "feature analysis_. feature analysis can be used to compute a new pca weight based on a new set of measurements , and the learned pca model allows to compute a new triangular mesh from this pca weight .",
    "chu et al .",
    "@xcite perform feature analysis on a database of human shapes consisting of feature patches to find a new model consisting of smooth patches .",
    "seo and megnenat - thalmann  @xcite represent the human body as a triangular mesh with an associated skeleton model . as with the approach of allen et al .",
    ", this approach reduces the dimensionality of the data using pca .",
    "this yields a set of pca weights .",
    "the approach learns a mapping from the set of measurements measured on the training data to the pca space using an interpolating radial basis function ( rbf ) with gaussian kernel  @xcite . as in the approach of allen et al .",
    ", this mapping produces a shape based on a new set of measurements .",
    "hasler et al .",
    "@xcite apply the two previously reviewed approaches to a new representation of human body shapes that is posture invariant .",
    "their method simultaneously models body pose and shape .",
    "recently , baek and lee  @xcite presented a technique that uses hierarchical clustering to build a statistical model of the training data .",
    "the approach proceeds by clustering the training database and by performing a multi - cluster analysis of the training data .",
    "to predict a body shape based on a set of input measurements , the approach finds the shape within the learned shape space that best describes the measurements using an optimization of shape parameters .",
    "it is shown experimentally that accurate and visually pleasing body shapes are estimated when the input body sizes are inside the shape space spanned by the training data .",
    "this approach is conceptually similar to the first optimization step of our algorithm .",
    "hence , we expect that this approach does not allow to model shape variations that are outside of the shape space spanned by the training data .",
    "anguelov et al .",
    "@xcite aim to estimate a 3d human body shape based on a sparse set of marker positions .",
    "this technique is useful when motion capture data is available .",
    "anguelov et al.s scape model represents the human body as a triangular mesh with an associated skeleton model . as with the approach of allen et al .",
    ", this approach reduces the dimensionality of the data using pca .",
    "this yields a set of pca weights .",
    "anguelov et al .",
    "aim to compute a new triangular mesh based on a set of marker positions located on the body .",
    "this is achieved by adjusting the pca weights to solve a non - linear optimization problem .",
    "this method searches the solution in the learned pca space .",
    "hence , it can not find local variations not present in the training database .      finally , we review approaches that aim to estimate human body shapes based on a set of input images .",
    "the following approaches proceed by learning a correlation between a training set of 3d face or body shapes and a set of derived 2d images and by using this learned correlation to predict a shape based on a new set of 2d images .",
    "these approaches work well when the predicted shape is inside the shape space spanned by the training set .",
    "however , they do not handle optimizations outside the learned shape space of 3d models .",
    "blanz and vetter  @xcite estimate a 3d face shape from a single input image in neutral expression .",
    "they start by building a parameterized database of textured 3d faces and performing pca on the shape and texture data . given an input image , the learned pca space is searched to find the textured shape ( and parameters related to rendering the model ) that best explains the input image .",
    "seo et al .",
    "@xcite estimate a body shape from two images of a human in a fixed posture .",
    "starting from a parameterized database of human meshes in similar poses , the approach performs pca of the 3d data .",
    "given the two images , the learned pca space is searched to find a set of pca weights that corresponds to a 3d shape that matches the input images well .",
    "chen and cipolla  @xcite aim to estimate the human body shape in a fixed pose based on a given silhouette . starting from a parameterized database of human meshes in similar poses and a set of corresponding silhouettes , the approach performs pca of the 3d and 2d data separately .",
    "the approach then computes a mapping from the pca space of the silhouette data to the pca space of the 3d data using a shared gaussian process latent variable model ( sgplvm )  @xcite .",
    "given a new silhouette , the approach maps the silhouette into silhouette pca space and uses the sgplvm to map to the pca space of the 3d meshes .",
    "ek et al .",
    "@xcite use a similar approach to estimate the pose of a human body based on a given silhouette .",
    "guan et al .",
    "@xcite estimate both the shape and pose of a human body shape from a single photograph with a set of markers to be identified by the user .",
    "the approach is based on the scape model .",
    "when adjusting the pca weights , the shape is deformed to best match the image in terms of a shape - from - shading energy .",
    "hasler et al .",
    "@xcite estimate both the shape and pose of a human body from a photograph of a dressed person .",
    "this approach requires a manual segmentation of the background and the human in the image .",
    "this section outlines the proposed approach . as input to the method",
    ", we are given a database of triangular manifold meshes @xmath0 of human bodies or faces with similar posture or expression and a set of measurements @xmath1 to be considered .",
    "let @xmath2 in @xmath1 denote the measurements corresponding to @xmath3 .",
    "furthermore , we are given a set of distances @xmath4 .",
    "our aim is to estimate a shape @xmath5 that interpolates the distances @xmath4 .    as previous methods",
    ", the approach proceeds by learning a correlation between the shapes and the measurements .",
    "when predicting a new shape , our approach finds an initial solution based on the learned correlation . unlike previous approaches , however , our approach refines this solution to fit the measurements using two steps of non - linear optimization .",
    "first , we optimize the shape of the model with respect to the learned shape space .",
    "that is , we aim to find the point in the learned shape space that best describes the measurements .",
    "this gives a realistic human shape drawn from the distribution fitted to the training data .",
    "hence , this shape can only contain local shape variations present in the training data . to account for other shape variations ,",
    "we perform a second mesh - based optimization .",
    "this optimization deforms the shape to fit the measurements as close as possible while satisfying a smoothness constraint without using prior knowledge of the body shape , and therefore predicts shapes with local variations not present in the training database .",
    "when using a mesh - based deformation that optimizes the sought measurements , we can only expect to obtain a realistic human body shape if we start with a body shape that is close to the solution .",
    "for this reason , we start from the shape in the learned shape space that best describes the sought measurements as opposed to starting directly from the point in shape space predicted by the learned correlation .    the following sections describe the details of the approach .",
    "anthropometric measurement represents a valuable source of human shape information , from which we can infer the 3d shapes for design applications . to learn a relationship between the anthropometric measurements and a set of 3d models , the measurements computed from the models should be equivalent to the measurements conducted by a human operator .",
    "the measurements can be one of the three types : euclidean , geodesic , and circumference .",
    "an euclidean or geodesic distance can be easily computed from two vertices on the model .",
    "a circumference can be computed by intersecting ( part of ) the model with a plane , finding the ( possibly closed ) polygonal chain of the intersection that contains a specified vertex , and measuring the circumference of the convex hull of this chain .",
    "this type of measurement is shown for the hip and waist circumferences in figure  [ measurements_many_human ] . the reason we measure the length of the convex hull instead of the length of the chain itself is that many anthropometric measurements , such as the chest circumference , measure the length of a convex hull .",
    "we specify the intersecting plane @xmath6 using the specified vertex @xmath7 and a normal direction @xmath8 .",
    "furthermore , we specify a part of the model that is to be intersected with the plane @xmath6 .",
    "this is necessary for some measurements , such as for the chest or hip circumference , where we wish to only intersect the torso ( and not the arms ) of the model with @xmath6 .",
    "note that the intersection of @xmath6 with a subset of @xmath9 consists of a set of polygonal chains , where every vertex of the chain is either a vertex of @xmath9 or the intersection of an edge of @xmath9 with @xmath6 .",
    "we now consider learning a correlation between the set of shapes @xmath3 and the corresponding measurements @xmath2 . to do this",
    ", the database of the human shapes first needs to be parameterized , a process that computes point - to - point correspondences among the shapes .",
    "this is in general a difficult problem  @xcite . in practice ,",
    "anthropometric markers identifying salient anatomic positions are often used to guide correspondence process .",
    "such markers are provided in 3d anthropometric surveys , for example , the civilian american and european surface anthropometry resource ( caesar ) database  @xcite . in this work ,",
    "the known marker positions are used to deform a template shape to each subject of the database  @xcite .",
    "the euclidean and geodesic measurements are specified by their two endpoints and the type of distance to be considered and the circumference measurements are given by one plane ( specified by a vertex and a normal vector ) and the part of the body to be intersected with that plane .",
    "since the database is parameterized , the vertices and body parts can be given in terms of their vertex and triangle numbers on the mesh .",
    "at this point , a set of distances @xmath10 can be computed for @xmath0 .",
    "we then learn a mapping between @xmath1 and the space of human body shapes using feature analysis . to this end",
    ", we first perform pca on the meshes @xmath3 . in pca space ,",
    "each shape @xmath3 is represented by a vector @xmath11 of pca weights .",
    "pca yields a mean shape @xmath12 and a matrix @xmath13 that can be used to compute a new shape @xmath5 based on a new vector of pca weights @xmath14 as @xmath15 . recall that the aim is to create a new shape based on a new point @xmath4 in @xmath1 . to achieve this goal ,",
    "feature analysis learns a linear mapping from @xmath2 to @xmath16 .",
    "this yields a matrix @xmath17 that can be used to compute a new vector of pca weights @xmath14 based on a new point @xmath4 as @xmath18 , which generates a shape @xmath5 based on a new point @xmath4 as @xmath19 . to give all pca",
    "coordinates the same weight , we normalize each entry of the pca weights by its corresponding pca eigenvalue before performing feature analysis .",
    "the mapping between the measurements and the pca weights of the 3d shapes learned in the previous section allows us to find an initial shape @xmath20 given a new set of measurements @xmath4 .",
    "however , straightforward application of feature analysis has the disadvantage that the shapes obtained for atypical @xmath4 are not contained in the space of human shapes ( e.g. see figure  [ atypical_prediction ] ) .",
    "since the subsequent refinement process depends on this initial shape , it is important to restrict it to be within the range of human shape .    given the pca weights obtained by feature analysis @xmath18 , we restrict @xmath14 such that each dimension @xmath21 $ ] is at most @xmath22 times the standard deviation of the pca space along dimension @xmath23 .",
    "this choice is based on the assumption that the shape space is modeled as independent gaussian distributions and most of the shapes are located within @xmath22 standard deviations of the mean for a suitable parameter @xmath22 .",
    "hence , this step restricts the reconstructed shape to stay within the space of human shapes that was learned using pca . in our implementation",
    ", we use the normalized weight vector to find an initial shape @xmath20 .",
    "the shape generated from the pca weights can only serve as an initial estimation , because the shape space spanned by the pca is limited by the sample size and may not account for all of the human shape variation . to find a shape that respects the required measurements while staying in the learned shape space , we need to refine @xmath20 .",
    "the following section presents our novel method for shape refinement in detail .",
    "this section outlines a novel approach to refine the initial estimate @xmath20 to respect the required measurements while staying in the learned shape space .",
    "we formulate the refinement problem as an energy minimization problem .",
    "let @xmath24 denote the vertices of @xmath5 and let @xmath25 denote their position vectors .",
    "furthermore , let @xmath26 be the vector of pca weights corresponding to @xmath5 , where @xmath27 is the pseudo - inverse of @xmath13 .    for euclidean measurements , we are given the target length @xmath28 of the euclidean distance of the segment @xmath29 between two vertices @xmath30 and @xmath31 .",
    "the shape @xmath5 that satisfies all given euclidean distance constraints minimizes @xmath32 where @xmath33 is the set of all euclidean distances that have a desired length , and @xmath30 and @xmath31 are the endpoints of @xmath29 .    for geodesic measurements , we are given the target length @xmath34 of the geodesic path @xmath35 between two vertices @xmath30 and @xmath31 .",
    "let @xmath36 denote the geodesic length of @xmath35 . in the following , we assume that the relative length of each edge @xmath37 of @xmath35 with respect to @xmath36 does not change during the deformation of the mesh . this is a reasonable assumption as we wish to preserve relative edge lengths during the deformation .",
    "furthermore , this assumption translates into an easy optimization problem . with this assumption",
    ", we can compute the target length @xmath38 of @xmath37 as @xmath39 , where @xmath40 is the current length of @xmath37 .",
    "then , the shape @xmath5 that satisfies all given geodesic distance constraints minimizes @xmath41 where @xmath42 is the set of all geodesic paths that have a desired length , and @xmath43 and @xmath44 are the endpoints of @xmath37 .    for circumference measurements , we are given the target length @xmath45 of the circumference @xmath46 of the convex hull of the polygonal chain passing though vertex @xmath30 and contained in the intersection between the mesh and the plane @xmath6 though @xmath30 with normal direction @xmath8 .",
    "we compute the length @xmath47 of the circumference on the mesh as outlined in section  [ sec_measurements ] .",
    "let @xmath48 denote all of the points on the convex hull of the polygonal chain . with a similar reasoning as above , in the following ,",
    "we assume that the relative length of each edge @xmath37 of the convex hull with respect to @xmath47 does not change during the deformation of the mesh .",
    "hence , we can compute the target length @xmath38 of @xmath37 as @xmath49 , where @xmath40 is the current length of @xmath37 .",
    "then , the shape @xmath5 that satisfies all given circumference constraints minimizes @xmath50 where @xmath51 is the set of all circumferences that have a desired length , and @xmath48 and @xmath52 are the endpoints of @xmath37 .",
    "recall that @xmath48 and @xmath52 are not necessarily vertices of the mesh .",
    "our aim is to deform @xmath20 , such that @xmath53 is minimized .",
    "we solve this problem using two consecutive steps by minimizing @xmath54 with respect to @xmath14 followed by minimizing @xmath54 with respect to @xmath55 .",
    "the first minimization finds the shape in the learned shape space that best describes the measurements .",
    "this step finds a realistic human body shape whose measurements are close to the sought ones .",
    "the second minimization then further deforms the shape using a mesh - based optimization without using prior knowledge on the shape .",
    "this minimization allows the shape to deform locally in ways not present in the training data . during this minimization",
    ", a smoothness term is used to keep a realistic body shape .",
    "first , we discuss how to minimize @xmath54 with respect to @xmath14 .",
    "this step finds the shape in the learned shape space that best describes the measurements .",
    "we solve the optimization problem using a quasi - newton approach .",
    "this approach has the advantage of having a near - quadratic convergence rate if the initial solution is close to the minimum .",
    "since this approach requires analytic gradients , we next discuss the derivatives of the different energy terms .",
    "the derivative of @xmath56 with respect to @xmath57 is @xmath58 where @xmath59 is the set of distances in @xmath60 with endpoint @xmath30 .",
    "the derivative of @xmath56 with respect to @xmath14 is @xmath61 .",
    "the derivatives of @xmath62 with respect to @xmath57 and @xmath14 are similar to @xmath63 and @xmath64 . to compute the derivative of @xmath65 with respect to @xmath57 , recall that each vertex @xmath48 of the convex hull of the polygonal chain is either a vertex of the mesh or the intersection of an edge of the mesh with @xmath6 .",
    "hence , every @xmath48 can be expressed as a convex combination of at most two vertices of the mesh .",
    "using this formulation allows us to compute the derivatives of @xmath65 with respect to @xmath57 and @xmath14 in a similar way to @xmath63 and @xmath64 .",
    "note that the geodesic path between @xmath30 and @xmath31 and the circumference measurement specified by @xmath30 and @xmath8 may change when the mesh is deformed . to remedy this problem",
    ", we update the geodesic paths and the circumference measurements and solve the resulting optimization problem @xmath66 times .",
    "this finds the point @xmath14 in pca space corresponding to the shape that has measurements closest to the desired ones . as before , we normalize @xmath14 such that each dimension @xmath21 $ ] of @xmath14 is at most @xmath22 times the standard deviation of the pca space along dimension @xmath23 to ensure that the shape stays within the learned shape space . finally , @xmath14 is used to compute the shape @xmath67 as @xmath68 .",
    "second , we minimize @xmath54 with respect to the vertex positions @xmath55 .",
    "this term ensures that local variations not present in the training data are predicted correctly by locally deforming the shape to fit the required measurements .",
    "however , simply minimizing @xmath54 may result in meshes that are not smooth .",
    "hence , we encourage close - by parts of the mesh to deform similarly by considering the smoothness energy @xmath69 where @xmath70 is the translation vector by which @xmath57 is moved and @xmath71 is the one - ring neighborhood of @xmath30 .",
    "the derivative of @xmath72 with respect to @xmath57 is @xmath73 note that the smoothness term helps ensure the predicted shape stays withing the shape space of human shapes .",
    "the vertex positions are initialized to the vertex positions of @xmath67 .",
    "we minimize the combined energy @xmath74 with respect to @xmath57 , where @xmath75 is the weight for the smoothing term .",
    "as before , we update the geodesic paths and the circumference measurements and solve the resulting optimization problem @xmath66 times , yielding the final result @xmath5 .",
    "the proposed method depends on the parameters @xmath76 , and on the termination criteria of the energy minimization . in our experiments ,",
    "we stop the energy minimization if the relative change of the energy is smaller than @xmath77 times the machine accuracy , if the norm of the gradient is smaller than @xmath78 , or if 100 iterations have been performed .",
    "the parameter @xmath22 determines the size of the acceptable shape space for reconstruction .",
    "this parameter provides a way to trade off high measurement accuracy and likely human shapes .",
    "if the measurements given to the method are known to be accurate measurements of a real human , @xmath22 can be set to a high value .",
    "if the measurements given to the method are randomly generated , however , @xmath22 needs to be low to avoid non - human shapes .",
    "hence , in our experiments with real data , we set @xmath79 and in our experiments with synthetic data , we set @xmath80 .",
    "the parameter @xmath75 determines the relative weight of the smoothing term . in our experiments , we set @xmath81 .",
    "the parameter @xmath66 determines how often the geodesic paths and circumferences are recomputed .",
    "we need to set @xmath66 large enough to achieve the required accuracy , yet small enough to obtain an efficient approach . in our experiments",
    ", we set @xmath82 unless specified otherwise .",
    "we leave it for future work to find the optimal parameter settings automatically .",
    "this is a challenging problem because the result depends on the parameter values , and because including the parameter values in the set of parameters to be optimized gives a highly nonlinear optimization problem .",
    "this section demonstrates the effectiveness of our method using both synthetic experiments and experiments with real data .",
    "we implemented the proposed algorithm using c++ .",
    "the implementation uses dijkstra s",
    "algorithm  @xcite to compute geodesic distances , the quickhull algorithm  @xcite to compute the convex hull to determine circumferences , and the limited - memory broyden - fletcher - goldfarb - shanno scheme  @xcite to solve the optimization problems .",
    "we choose these standard algorithms for their ease of use . to parameterize the database used for training , the efficient approach by xi et al .",
    "@xcite is employed .",
    "we compare our results to the results obtained using feature analysis and to the results obtained by using a sgplvm mapping from the space of the measurements to the pca space of the models .",
    "both approaches are reviewed in section  [ related ] .",
    "we use the code by ek et al .",
    "@xcite to compute the sgplvm .",
    "the synthetic experiments aim to reconstruct human face and body shapes . for each synthetic experiment",
    ", we learn a multivariate gaussian distribution @xmath83 from the available sets of measurements .",
    "first , 200 sets of measurements are generated by randomly sampling 200 points from @xmath83 .",
    "note that since these samples are drawn from the learned distribution , most of the measurements are similar to the ones in the training set .",
    "we denote this set of measurements by @xmath84 .",
    "second , 200 sets of measurements are generated by randomly sampling 200 points that are located on the ellipsoidal surface @xmath85 , where @xmath86 , @xmath87 is a constant , and @xmath88 is the vector that contains the diagonal elements of @xmath89 .",
    "note that the larger the @xmath87 is , the farther the measurements are from the training set .",
    "let @xmath90 denote this set of measurements . in our experiments , we set @xmath91 .",
    "the experiments based on real data aim to reconstruct human body shapes from a set of measurements .",
    "we consider two types of input data .",
    "for the first type of input data , we digitally measure the distances in @xmath1 on a number of parameterized 3d human body scans and use these measurements as input to our algorithm .",
    "we denote these measurements by @xmath92 .",
    "note that in this case , the ground truth of the 3d body shape is known and can be used to evaluate the results .    for the second type of input data",
    ", we asked a number of volunteers to measure each other .",
    "this results in a set of real - world measurements of real subjects .",
    "we denote these measurements by @xmath93 . as in this case",
    ", no ground truth 3d body shape is known , we validate the accuracy of the 3d reconstruction visually by comparing the 3d shape to silhouettes of photographs of the volunteers .",
    "this experiment shows the accuracy we can expect when a person who is not an expert in anthropometry tries to use our method to build a digital clone of herself .",
    "this section validates our approach using a set of synthetic experiments on 3d human face shapes .      the training set consists of 50 faces from the caesar database  @xcite .",
    "after parameterization , each face contains 6957 triangles .",
    "this experiment considers the seven measurements shown in figure  [ measurements ] . here",
    ", each dimension measures the geodesic distance between the pair of points shown in the same color .",
    "note that several geodesic paths may overlap .",
    "we generate new face shapes that aim to interpolate the measurements in @xmath84 and @xmath90 using our approach , feature analysis , and sgplvm .",
    "table  [ error_table ] shows the errors of the generated faces for each method .",
    "we define an error for each dimension as the absolute value between the distance on the generated shape and the input measurement for this dimension , and use this to compute the error in mm as the average error over all dimensions .",
    "note that feature analysis yields the lowest average errors and that sgplvm yields the highest average errors for all experiments .",
    "@xmath94 + feature analysis & 0.67 & 1.63 & 6.76 + sgplvm & 5.35 & 5.28 & 10.88 + our approach & 0.68 & 2.00 & 7.27 +    several of the shapes predicted using feature analysis are clearly outside of the shape space of human faces , as shown on the right of figure  [ reconstructed_shapes ] .",
    "this is undesirable because human perception is sensitive with respect to unrealistic variations in face shape .",
    "in fact , most of the faces predicted using feature analysis in @xmath94 are clearly outside of the shape space of human faces .",
    "it is desirable to have variability among the computed shapes .",
    "both feature analysis and our approach predict significantly different shapes for all of the experiments .",
    "sgplvm produces slightly different face shapes for different samples of @xmath84 and @xmath95 , but for all samples in @xmath94 , the same face shape ( visually similar to the mean shape ) is produced .    in summary ,",
    "our approach is the only one of the compared approaches that yields a variety of face shapes while always estimating shapes that are in the space of human faces .",
    "furthermore , our approach yields lower errors than sgplvm .",
    "this section validates our approach using a set of synthetic experiments and experiments based on real data .",
    "the training set consists of 360 bodies of the caesar database .",
    "after parameterization , each body contains 60000 triangles .",
    "this experiment considers 34 measurements : 14 euclidean measurements , 4 circumference measurements ( hip , waist , chest , and head circumferences ) and 4 circumferences defined by four geodesic measurements each ( knee and arm circumferences ) .",
    "figure  [ measurements_many_human ] shows the measurements on one shape .",
    "we generate new body shapes that aim to interpolate the new measurements in @xmath84 and @xmath90 using our approach , feature analysis , and sgplvm .",
    "table  [ error_table_body ] shows the errors of the generated bodies for each method .",
    "the errors are computed in the same way as in the previous experiment .",
    "note that our approach yields the lowest average errors for all experiments .",
    "@xmath94 & @xmath92 + feature analysis & 3.29 & 14.26 & 36.86 & 3.09 + sgplvm & 4.91 & 12.19 & 22.88 & 4.55 + our approach & 1.74 & 6.39 & 15.49 & 1.10 +    for most samples in @xmath96 and for several samples in @xmath97 , feature analysis predicts shapes that are outside of the shape space of human bodies .",
    "for the samples in @xmath84 , feature analysis yields visually pleasing shapes .",
    "sgplvm always yields body shapes that are in the shape space of human bodies .",
    "however , for the samples in @xmath96 , the variation of the predicted body shapes is low .",
    "some of the shapes predicted using @xmath96 with our approach contain small local artifacts due to the optimization with respect to the vertex coordinates .",
    "note that setting @xmath75 to a higher value will reduce these artifacts at the cost of increased error . for @xmath97 and @xmath84",
    ", our approach always predicts globally and locally realistic body shapes .",
    "figure  [ reconstructed_shapes_body ] shows four of the body shapes in @xmath84 predicted using our approach .",
    "we can see that a large variety of shapes can be computed .      for this experiment",
    ", we consider 50 additional parameterized body shapes from the caesar database and use each of these models to digitally measure the 34 relevant measurements .",
    "we call this set of measurements @xmath92 .    for the body",
    "shapes that aim to interpolate the measurements in @xmath92 , table  [ table : error ] shows the errors of the euclidean measurements and circumferences of the generated bodies .",
    "the error of the knee and arm circumferences is computed as the sum of the errors of the individual dimensions that contribute to the circumference .",
    "we compute the average and maximum errors in mm for each dimension .",
    "note that our approach yields the lowest average errors for all dimensions and the lowest maximum errors for most dimensions .",
    "figure  [ true_bodies ] shows the predictions for three different subjects .",
    "each mesh is shown using a color coding corresponding to the signed distance from the parameterized body scan that was used to compute the measurements in @xmath92 .",
    "note that sgplvm yields predictions with the highest errors and also predictions that are visually most dissimilar from the ground truth .",
    "the predictions obtained using feature analysis and our approach are of similar quality .",
    "note however that the predictions obtained using our approach are more accurate in localized areas of the body such as the waist area of the subject shown in the first row .",
    "this is due to the deformation of the mesh that aims to obtain the correct waist circumference .",
    "[ cols= \" < , > , > , > , > , > , > \" , ]      finally , we demonstrate the ability of our approach to predict shapes that are not covered well by the training data . recall that this is relevant in practice because predicting human shapes based a small training sample avoids the complicated and expensive acquisition of large anthropometric databases .",
    "we use as training data a set of 35 of the bodies of the caesar database .",
    "all of the bodies in the training set are male bodies with typical body shape , see figure  [ typical_male_training ] .",
    "we choose five additional male bodies with body shape variations not covered by the training data and we use each of these models to digitally measure the 34 relevant measurements .",
    "we then use these measurements for prediction . for this experiment , we set @xmath80 since the shapes are not represented well by the training data . furthermore , we set @xmath98 to increase the accuracy of the prediction .",
    "figure  [ atypical_prediction ] shows the results .",
    "the first row shows the bodies of the caesar database used for prediction , the second row shows the result using our approach , the third row shows the result using sgplvm , and the last row shows the result using feature analysis .",
    "note that our approach predicts body shapes that are similar to the ground truth for most shapes although a limited training set was used .",
    "for the body in the last column , the result using our approach is not as large as the ground truth .",
    "the reason is that the input body shape is far from the training data .",
    "the results using sgplvm are all close to the mean shape and far from the ground truth .",
    "the results using feature analysis are outside of the shape space of human body shapes .",
    "this shows that our approach best handles the case where the predicted shapes have variations that are outside of the shape space spanned by the training data .",
    "we conducted experiments based on human face and body shapes using both real and synthetic data .",
    "we conducted an extensive evaluation by estimating 600 face shapes and over 650 body shapes . in summary",
    ", we demonstrated experimentally that our method has the following properties .    *",
    "our method estimates realistic body or face shapes that are outside of the learned shape space . *",
    "our method yields results that are more accurate than sgplvm , and that , unlike feature analysis , always stay within the shape space of human body or face shapes . * our method accurately predicts local shape variations not present in the training set ( which accounts for accurate predictions of the waist shapes in figure  [ true_bodies ] ) . * our method yields visually pleasing results even when a small database is used for training .",
    "this is important in practice because the acquisition of a large database for training is costly . * even for inaccurate input measurements acquired by non - experts ,",
    "our method is able to find visually consistent results . *",
    "our method is computationally efficient .",
    "the running time of the optimization steps is linear in the number of vertices .",
    "to predict one human body shape , our ( non optimized ) implementation takes about 35 seconds on a standard pc with a dual core cpu and 8 gb of ram .",
    "we presented a novel approach to estimate human body and face shapes based on measurements .",
    "we demonstrated that the approach can produce a large variety of likely shapes based on a relatively small training set and a small number of measurements .",
    "we showed experimentally that , unlike feature analysis , the approach always produces shapes that are inside the space of human shapes .",
    "furthermore , the approach yields higher accuracy than sgplvm .",
    "that is , unlike previous approaches , our approach predicts shape variations not present in the training data while maintaining a realistic human body shape .",
    "this allows to generate accurate body shape estimates based on simple modalities without the need to acquire a large - scale 3d database that represents the target population .",
    "we thank the volunteers for participating in the experiment . furthermore , we thank pengcheng xi for helpful discussions and for providing us with the training data , neil lawrence for providing us with the sgplvm code , and the anonymous reviewers for helpful comments .",
    "this work has partially been funded by the cluster of excellence _ multimodal computing and interaction _ within the excellence initiative of the german federal government ."
  ],
  "abstract_text": [
    "<S> the recent advances in 3-d imaging technologies give rise to databases of human shapes , from which statistical shape models can be built . </S>",
    "<S> these statistical models represent prior knowledge of the human shape and enable us to solve shape reconstruction problems from partial information . </S>",
    "<S> generating human shape from traditional anthropometric measurements is such a problem , since these 1-d measurements encode 3-d shape information . </S>",
    "<S> combined with a statistical shape model , these easy - to - obtain measurements can be leveraged to create 3d human shapes . however , existing methods limit the creation of the shapes to the space spanned by the database and thus require a large amount of training data . in this paper , we introduce a technique that extrapolates the statistically inferred shape to fit the measurement data using non - linear optimization . </S>",
    "<S> this method ensures that the generated shape is both human - like and satisfies the measurement conditions . </S>",
    "<S> we demonstrate the effectiveness of the method and compare it to existing approaches through extensive experiments , using both synthetic data and real human measurements . </S>"
  ]
}