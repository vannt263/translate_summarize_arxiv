{
  "article_text": [
    "database search has many applications and is used widely . grover discovered a quantum algorithm that searches faster than a classical algorithm @xcite .",
    "it consists of repetition of the grover iteration @xmath0 , which operates on the computational quantum states .",
    "the number of repetitions is : @xmath1 for a database with large number of entries @xmath2 .",
    "after @xmath3 the algorithm finds the target item . for more details , see also @xcite . below we shall call @xmath0 a global iteration .",
    "sometimes it is sufficient to find an approximate location of the target item .",
    "a partial search considers the following problem : a database is separated into @xmath4 blocks , of a size @xmath5 .",
    "we want to find a block with the target item , not the target item itself .",
    "such partial search was first introduced by mark heiligman in @xcite , as a part of algorithm for list matching .",
    "we can think of partial search in following terms : an exact address of the target item is given by a sequence of @xmath6 bites , but we want to find only first @xmath7 bites ( @xmath8 ) .",
    "fast quantum algorithm for a partial search was found by grover and radhakrishnan in @xcite .",
    "they showed that classical partial search takes @xmath9 queries , but quantum algorithm takes only @xmath10 queries .",
    "it uses several global iterations @xmath11 and then several local iteration @xmath12 , see ( [ liter ] ) .",
    "local searches are grover iterations [ searches ] in each individual block made in each block separately in parallel . grover - radhakrishnan algorithm was improved and simplified in @xcite .",
    "the number of queries to the oracle in this algorithm was minimized by in @xcite , the @xmath13 was maximized .",
    "below we shall explain minimized version of grover - radhakrishnan algorithm .",
    "we shall call it grk algorithm . in this paper",
    "we consider three other versions of partial search algorithm .",
    "they use different sequences of global and local searches : local - global , global - local - global and local - global - local .",
    "we prove that grk version still uses minimal number of queries to the oracle .",
    "we conjecture that_grk algorithm is optimal among all partial search algorithms , which consist of arbitrary sequence of local and global searches_.    the plan of the paper is as follows . in the next section",
    "we remind the grover algorithm . after this",
    "we formulate minimized version of grover - radhakrishnan algorithm [ grk algorithm ] . in the rest of the paper",
    "we consider other partial search algorithms .",
    "we arrive at the conclusion that grk uses minimal number of queries comparing to other algorithms .",
    "first let us remind the full grover search . we shall consider a database with one target item . the aim of the grover algorithm is to identify a target state @xmath14 among an unordered set of @xmath2 states .",
    "this is achieved by repeating global iteration which is defined in terms of two operators .",
    "the first changes the sign of the target state @xmath14 only : @xmath15 where @xmath16 is the identity operator . the second operator , @xmath17 changes the sign of the uniform superposition of all basis states @xmath18 , @xmath19 the * global iteration * is defined as a unitary operator @xmath20 we shall use eigenvectors of @xmath21 : @xmath22 , \\qquad   |\\psi^{\\pm}_1\\rangle   = \\frac{1}{\\sqrt{2}}|t\\rangle \\pm \\frac{i } { \\sqrt{2}}\\left ( \\sum^{n-1}_{\\stackrel{\\mbox{\\small{x=0}}}{\\mbox{\\small{x   $ \\neq$ t } } } } \\frac{|x\\rangle}{\\sqrt{(n-1 ) } } \\right ) .",
    "\\label{value } % \\lambda^{\\pm}_1 & = & \\exp[{\\pm 2i \\theta_1 } ] .",
    "\\label{value}\\end{aligned}\\ ] ] they were found in @xcite , where the angle @xmath23 is defined by @xmath24      the first version of partial search was found in @xcite .",
    "the algorithm uses @xmath25 global iteration and @xmath26 local iterations . *",
    "local iterations * are grover iterations for each block : @xmath27 @xmath28 is given by ( [ target ] ) , but @xmath29 is different .",
    "in one block it acts as : @xmath30 in the whole database @xmath29 is the direct sum of ( [ is2 ] ) with respect to all blocks",
    ". both relevant eigenvectors of @xmath31 were found by in @xcite : @xmath32 , \\label{vector2 }   \\qquad    \\frac{i}{\\sqrt{2 } } |\\mbox{ntt}\\rangle % \\lambda^{\\pm}_2 & = & \\exp[{\\pm 2i \\theta_2 } ] .\\end{aligned}\\ ] ]    here the @xmath33 is a normalized sum of all non - target items in the target block : @xmath34 we shall need an angle @xmath35 given by @xmath36    the partial search algorithm of @xcite creates a vector @xmath37 see . in the state @xmath38 the amplitudes of all items in non - target blocks are zero .",
    "notice that this algorithm uses global - local sequence of searches .",
    "we consider large blocks @xmath39 .",
    "the number of blocks @xmath4 is an important parameter .",
    "we shall replace it with @xmath40 the optimal version of this algorithm was find in @xcite .",
    "it can be described by the following equations : @xmath41 partial search is faster then full search ( [ full ] ) by @xmath42 , the coefficient in front of @xmath43 is explicitly calculated in @xcite and studied as a function of number of blocks .",
    "let us introduce a unite vector : @xmath44 we shall use a three dimensional space . the orthonormal basis is formed by the target item @xmath14 , sum of all non - target items in the target block @xmath45 , defined in ( [ vntt ] ) and @xmath46 .",
    "all the state vectors involved in present quantum search problem can be written in this basis as @xmath47 meaning @xmath48 for example , the global uniform state which is used as initial state of searching is given by @xmath49 and the local uniform state is @xmath50    the algorithms which we consider in this paper can be represented as matrices in this linear space .",
    "for example @xmath26 repetitions of the local iteration ( [ liter ] ) is : @xmath51 the ordering of eigenvectors is @xmath14 , @xmath52 and @xmath46 .",
    "the matrix has three eigenvectors : @xmath53 the eigenvectors can be represented as : @xmath54    now let us turn our attention to global iterations ( [ iter ] ) , @xmath25 repetitions of the global iterations can be represented as @xmath55 this is a simplified asymptotic expression valid in the limit of large blocks @xmath56 .",
    "we used ( [ gam ] ) .",
    "the matrix has three eigenvectors : @xmath57 the eigenvectors can be represented as : @xmath58      the ultimate goal of partial search is to start with the uniform state @xmath59 and locate the target block , and obviously grk is not the only means to achieve the goal .",
    "based on the two types of queries , global and local iterations , we naturally generalize grk into a wide set of partial search algorithms by alternate use of the two iterations : @xmath60 which fulfills the following condition @xmath61 this means that amplitude of each item in non - target block is zero . here all @xmath62 are non - negative integers .",
    "the total number of queries for these algorithms is given by @xmath63 , and we should try to minimize @xmath64 to find the optimal one .    now let s consider various sequences .",
    "a few discussions can be made here : + 1 ) the last queries in the sequence should be the global iterations .",
    "note that local iteration ( [ loc ] ) does nt do anything on @xmath65 but only rotates state component inside the target block , so if an algorithm makes computational state in the target block after the last local queries , it can simply waive the last local queries since the state must already rest in the target block before those unnecessary last local iterations .",
    "that is , if @xmath66 then we must also have @xmath67 .",
    "+ 2 ) the first queries could be either local or global iterations .",
    "sequences starting with the global ( @xmath68 ) include : @xmath69 ( global ) , @xmath70 ( global - local - global ) , and so on . the simplest one , with only global queries involved , gives nothing but the original grover s full search ( [ full ] ) , which saves no steps but precisely locates the target item .",
    "the next simplest one , global - local - global , will be studied in later section .",
    "note that the up - to - now established optimal partial search grk algorithm also falls into this category , with @xmath71 and @xmath72 specified by ( [ korepin ] ) .",
    "+ 3 ) for those starting with local queries ( @xmath73 and @xmath74 ) , we have : @xmath75 ( local - global ) , @xmath76 ( local - global - local - global ) , and so on .",
    "we will later fully consider the local - global algorithm and also discuss one particular case of local - global - local - global which has @xmath77 to be one , namely with only one global query applied after the last local iterations ( we call this as local - global - local sequence ) .",
    "+ 4 ) the argument based on the optimality of grover s full search puts lower limit of the partial search steps @xmath78 .",
    "it was shown in @xcite that @xmath79 . here",
    "@xmath80 is a constant independent of @xmath81 .",
    "the optimal scheme we are seeking should maximize @xmath80 . also according to this thought",
    ", we expect the total number of global queries should scale asymptotically as @xmath82 , since in partial search we should be faster than full search @xmath83 but save steps only of order @xmath43 . as for total number of local queries it should scale like @xmath84 , since @xmath85 times local iteration will have rotated the state vector a whole lap on the target block @xmath86 plane .",
    "it follows from these consideration that @xmath87 .",
    "though the numbers of local and global iterations @xmath62 are integer numbers and in principle not continuous variables , in the large block limit we can reasonably treat them as quasi - continuous and use them as function arguments .",
    "+ 5 ) @xmath80 is a function of block number @xmath4 or instead the parameter @xmath88 with @xmath89 .",
    "another limit we will consider is the large @xmath4 limit , @xmath90 or equivalently @xmath91 . in this limit",
    "the mathematical formulae will be significantly simplified , which will be very helpful to analytical efforts as will be seen in later sections .",
    "the cases with not so large @xmath4 could be complemented by direct numerical verification .",
    "the local - global sequence of searches is the simplest partial search scheme .",
    "for such a sequence @xmath92 with first @xmath25 local iterations applied and then @xmath26 global , we have the final computational state to be : @xmath93 here a , b , c are the coefficients of components @xmath94 respectively ( see ( [ vectorform ] ) ) , which are given by @xmath95 then to accomplish the partial search we should have the constraint equation @xmath96 which means that the amplitude of every item in non - target block vanish ( [ constraint ] ) .",
    "since there are only one set of local and one set of global iterations , we apply the scaling as discussed before and introduce @xmath97 we have the limitation @xmath98 and @xmath99 .",
    "now we can rewritten the constraint equation as following : @xmath100 \\sin(\\frac{2\\eta}{\\sqrt{k } } ) -\\sin\\gamma\\sin(2\\alpha)\\cos(\\frac{2\\eta}{\\sqrt{k } } ) + ( -)^{j_2 } \\sin^2\\gamma[1-\\cos(2\\alpha ) ] { \\bigg ) } \\ , = \\ , 0\\ ] ] note that @xmath101 so @xmath102 , hence it drops out in the above equation and we have @xmath103 \\sin(\\frac{2\\eta}{\\sqrt{k } } ) -\\sin\\gamma\\sin(2\\alpha)\\cos(\\frac{2\\eta}{\\sqrt{k } } ) + ( -)^{j_2 } \\sin^2\\gamma[1-\\cos(2\\alpha)]=0\\ ] ]    remember we are interested in the fastest algorithm ( using the fewest queries ) , especially those using less steps than grover s full search .",
    "now we have the total number of queries to be @xmath104 , thus to minimize @xmath64 we should maximize @xmath87 under the constraint ( [ lg_cons ] ) .",
    "the point here is that from the constraint we can consider @xmath105 as a function of @xmath106 , thus @xmath80 is also a function of @xmath106 , to which it should be optimized .",
    "we then have @xmath107 , which leads to @xmath108=0\\ ] ] again since @xmath109 , we have @xmath110 so we simplify the above equation as @xmath111=0\\ ] ]    there is an apparent solution for ( [ lg_cons ] ) and ( [ lg_dif ] ) , namely @xmath112 .",
    "this gives @xmath113 and @xmath114 , but to maximize @xmath87 we should have @xmath115 , which again recovers the grover s full search solution and is a trivial one for partial search . in the following we only consider nontrivial solutions with @xmath116 .",
    "let s first look at the large @xmath4 or small @xmath117 limit . in leading order ,",
    "the two equations ( [ lg_cons ] ) and ( [ lg_dif ] ) are reduced to be @xmath118 @xmath119=0\\ ] ] to satisfy ( [ lg_limit1 ] ) , the first term @xmath120 must be at least as small as @xmath121 , so in leading order we must have @xmath122 .",
    "this , combined with ( [ lg_limit2 ] ) , requires also @xmath123 must be at least as small as @xmath124 ( we do nt consider @xmath125 as mentioned before ) , which means @xmath126 .",
    "so finally we reduce ( [ lg_limit2 ] ) in leading order to be @xmath127 remember we have @xmath128 thus @xmath129 , so the above equation has solution only for odd values of @xmath26 . for odd @xmath26",
    "the solution is @xmath130 , this yields two solutions @xmath131 and @xmath132 . by substituting @xmath130 back into ( [ lg_limit1 ] )",
    "we get in leading order @xmath133 , which means @xmath134 or @xmath135 , @xmath136 . but again remember our goal is to maximize @xmath87 , so we adopt the optimal local - global solution @xmath131 and @xmath137 in large k limit .",
    "this , however , seems giving no speedup compared with full search since @xmath138 . to clarify this",
    ", we need go to higher order of equations ( [ lg_limit1 ] ) and ( [ lg_limit2 ] ) .",
    "by properly including corrections up to @xmath139 we can find the solution to be @xmath140 now we see in large @xmath4 limit , the local - global sequences of search do achieve speedup @xmath141 which is very small but still nonzero .",
    "let s now turn back to finite values of @xmath4 . from ( [ lg_dif ] )",
    "we have @xmath142 combine ( [ lg_eta ] ) and ( [ lg_cons ] ) together we get @xmath143}\\ ] ] by requiring @xmath144 we obtain the equation determining the value of @xmath106 and from @xmath106 we can obtain @xmath105 .",
    "generally it is hard to analyze the problem analytically , so we proceed to numerical solutions , see the figures fig.[fig_lgodd],[fig_lgeven ] . in these figures",
    "we plot @xmath80 as a function of @xmath106 with different @xmath4 for both even and odd values of @xmath26 , at each point @xmath105 is determined from the constraint ( [ lg_cons ] ) . for the odd @xmath26 case",
    "there is always a positive maximum which is faster than full search , and as @xmath4 approaches very large values , the maximum of the @xmath145 v.s . @xmath106 curve moves",
    "gradually toward the origin which stands for the full search solution .",
    "but for even @xmath26 , @xmath80 is always negative , hence slower than full search .",
    "an important comparison is to be made between this local - global algorithm and the established grk one .",
    "our numeric results show that the odd @xmath26 local - global searches can get @xmath146 with @xmath147 and get @xmath148 for @xmath149 . for grk",
    ", however , it can achieve @xmath150 for all @xmath101 .",
    "so the grk is much faster than the present local - global searches .    to sum up with the local - global sequence of searches , we find it can be faster than full search with @xmath151 speedup for block number @xmath4 up to several tens , but it is always slower than the grk optimized partial search",
    "in this section we shall consider another algorithm for partial search , the global - local - global sequence of searches , which starts with ( [ ave ] ) , first applies @xmath152 global iterations ( [ iter ] ) , then @xmath25 local iterations ( [ liter ] ) and finally @xmath26 global iterations : @xmath153 again amplitudes of all items in non - target blocks should vanish at the end of algorithm : @xmath154 after local iterations the state of the database is : @xmath155 here we neglected @xmath156 terms ( namely taking large block limit ) .",
    "after next set of global searches we have to calculate only third component(coefficient of @xmath157 ) of the vector : @xmath158 \\right\\ } + \\nonumber \\\\ & & \\sin ( 2j_1\\theta_2)\\left\\{-\\sin \\gamma",
    "\\cos \\gamma \\sin ( 2j_2\\theta_1)\\cos ( 2j_0\\theta_1)- \\sin \\gamma \\cos \\gamma \\sin ( 2j_0\\theta_1 )   \\right[(-1)^{j_2 + 1}+\\cos ( 2j_2\\theta_1 ) \\left ] \\right\\ } + \\nonumber \\\\ & & + \\cos \\gamma   \\cos ( 2j_0\\theta_1 ) [ ( -1)^{j_2 } \\sin^2 \\gamma + \\cos^2 \\gamma \\cos ( 2j_2\\theta_1 ) ] \\nonumber\\end{aligned}\\ ] ] this constraint equation guarantees the amplitudes of all items in all non - target blocks vanish to successfully complete the partial search .    first let us check the case @xmath159 , no local searches . in this case",
    "the constraint equation can be reduced to @xmath160 = 0 $ ] .",
    "this is just the full search : we use @xmath161 global iterations to find the target item .",
    "now let us consider more general and complicated case .",
    "we expect the following scaling , namely the global iterations @xmath162 , @xmath163 and total local iterations @xmath164 with @xmath165 , @xmath166 and @xmath128 .",
    "it should be remembered that our purpose is to minimize @xmath167 , or equivalently maximize @xmath80 .",
    "our strategy is similar to that used for analyzing local - global sequence : study the large @xmath4 limit analytically while deal with finite @xmath4 case numerically .    in the large @xmath4 or small @xmath117 limit",
    ", we can take the leading order of ( [ glg_cons ] ) and simplify our constraint to a much simpler form : @xmath168 from this equation , there are two possibilities : + 1 ) @xmath26 is even , thus @xmath169 . in this case",
    "the problem simplifies into maximizing @xmath170 with @xmath166 and @xmath171 .",
    "note that @xmath172 so the maximum of r must occur at @xmath173 , which is again the trivial full search solution ( [ full ] ) .",
    "+ 2 ) @xmath26 is odd , thus @xmath174 .",
    "we then have to maximize @xmath175 with @xmath176 and @xmath128 .",
    "the solution is @xmath177 which has achieved @xmath178 speedup with respect to full search .",
    "this nontrivial optimal solution is exactly the grk algorithm , with vanishingly small odd @xmath26 namely @xmath71 .",
    "now let us discuss finite values of @xmath4 .",
    "we calculated dependence of @xmath80 on @xmath179 by determining @xmath106 from constraint equations and optimizing @xmath105 numerically at each value of @xmath179 .",
    "we done this numerically for up to 200 blocks .",
    "the dependence of @xmath80 on @xmath179 is monotonous .",
    "corresponding figures took too much memory , so we withdraw them from the paper . for even @xmath26 searches we consider are slower than full grover search , while odd @xmath26 these searches are faster than full search .",
    "the optimal searches always occur with odd and vanishing @xmath26 ( the grk case ) , being about @xmath180 faster than full search .",
    "the large @xmath4 case also confirm our analysis above .",
    "our results here also confirm that the optimum partial search is grk @xcite , it has the form @xmath181 .    to conclude",
    ", we have found that global - local - global sequence of searches can be much faster than full search ( [ full ] ) with odd times global iterations applied in the end , and the optimal search is determined to be the grk algorithm for all values of @xmath4 .",
    "in this section we shall discuss another algorithm of partial search .",
    "it belongs to the category of local - global - local - global sequence but with only one global query applied in the end , which we call as local - global - local sequence .",
    "we start with ( [ ave ] ) first apply @xmath25 local iterations , then @xmath26 global iterations ( [ liter ] ) and then @xmath182 local iterations , and eventually a single global query : latexmath:[\\[\\hat{g_1 } \\hat{g_2}^{j_3 }   \\hat{g_1}^{j_2 } \\hat{g_2}^{j_1 }    sequence is that when @xmath25 tends to zero our local - global - local will degenerate to the grk type algorithm .",
    "amplitudes of all items in non - target blocks should vanish at the end : @xmath184 as before , we introduce the scaling of iteration numbers to be @xmath164 , @xmath185 , and @xmath186 . the total number of queries will be @xmath187 with @xmath188 which we want minimize under constraint ( [ lglcons ] ) . the explicit form of the above constraint equation is as follows : @xmath189 } + z \\\\    & & x=\\sin\\gamma \\sin(2\\gamma ) \\sin(2\\delta ) \\sin(\\frac{2\\eta}{\\sqrt{k } } ) + \\sin^2\\gamma \\sin(2\\gamma )",
    "\\cos(2\\delta ) \\cos(\\frac{2\\eta}{\\sqrt{k } } ) + \\sin\\gamma \\cos\\gamma \\cos(2\\gamma ) \\cos(\\frac{2\\eta}{\\sqrt{k } } )   \\nonumber \\\\    & & y= \\sin^2\\gamma \\sin(2\\gamma ) \\sin(2\\delta ) \\cos(\\frac{2\\eta}{\\sqrt{k } } ) - \\sin^3\\gamma \\sin(2\\gamma)\\cos(2\\delta)\\sin(\\frac{2\\eta}{\\sqrt{k } } )          -\\sin^2\\gamma \\cos\\gamma { \\bigg [ } \\cos(2\\gamma)\\sin(\\frac{2\\eta}{\\sqrt{k}})+(-)^{j_2 } { \\bigg ] }    \\nonumber \\\\    & & z= \\sin(2\\gamma ) \\sin(2\\delta ) \\cos(\\frac{2\\eta}{\\sqrt{k } } ) - \\sin\\gamma \\sin(2\\gamma ) \\cos(2\\delta ) \\sin(\\frac{2\\eta}{\\sqrt{k } } )           -\\cos\\gamma \\cos(2\\gamma ) \\sin(\\frac{2\\eta}{\\sqrt{k } } ) \\nonumber\\end{aligned}\\ ] ] though the above equation is complicated , it is very easy to solve numerically . also taking large @xmath4 limit",
    "can significantly simplify it .",
    "so as we did before , we analytically study the large @xmath4 limit , complemented by numerical results from very small @xmath4 to very large @xmath4 .    by taking large @xmath4 or small @xmath117 limit",
    ", we obtain from leading order of ( [ lgl_cons ] ) the following : @xmath190 we then have @xmath191 and hence the total number of queries to be @xmath192 by requiring @xmath193 we get the solution maximizing @xmath80 @xmath194 this , with zero @xmath25 , again recovers the grk optimized solution .",
    "so in large @xmath4 limit we see local - global - local sequence is no faster than grk algorithm .",
    "different from local - global and global - local - global , here in local - global - local we notice that the odd @xmath26 and even @xmath26 converge to each other when approaching the optimal solution and the oscillation terms in ( [ lgl_cons ] ) with factor @xmath195 disappear .    for general values of @xmath4 , we conduct the numerical method and show the results in figures fig.[fig_lglodd][fig_lgleven ] , which plot @xmath80 as a function of @xmath106 with @xmath105 solved from ( [ lgl_cons ] ) and @xmath196 optimized numerically . as can be seen",
    ", the optimal solutions always occur with @xmath113 which goes back to grk case .",
    "also we note that even and odd @xmath26 give same results around optimal point .",
    "so in this section we have established that the local - global - local sequence of searches can be much faster than full search , but is no faster than grk algorithm . in the appendix",
    "an alternative approach for local - global - local sequence based on a conjecture about cancellation of oscillation terms in ( [ lgl_cons ] ) is briefly described , which though is not directly relevant here but arrives at similar result and may shed light for future exploration of even more complicated sequences .",
    "we considered different partial search algorithms , which consists of a sequence of local and global searches .",
    "we introduced a general framework for studying partial quantum search algorithms and classified various possible sequences .",
    "particularly , we studied the local - global , global - local - global as well as local - global - local sequences of searches by combining numerical study for wide range values of @xmath4 and analytical results for large @xmath4 limit .",
    "all these algorithms achieve @xmath43 speedup compared to the grover s full quantum search .",
    "grk algorithm @xcite is the fastest among partial search algorithms , which we considered .",
    "the paper was supported by nsf grant dms-0503712 .",
    "let us make two remarks :    \\1 ) let s start from the explicit form of constraint equation ( [ lgl_cons ] ) .",
    "we minimizing @xmath197 .",
    "it is interesting to note that at the minimum the oscillation terms cancel .",
    "the coefficient at @xmath198 vanishes because of grk equation : @xmath199 this is exactly the first equation of ( [ korepin ] ) .",
    "we also can write it in the form : @xmath200    \\2 ) minimum number of iterations for local - global - local sequences corresponds to @xmath159 case and the algorithm is reduced back to grk version of partial search , see small @xmath25 increase @xmath201 very little since @xmath202 and @xmath203 at @xmath159 .",
    "g. brassard , p. hoyer , m.mosca and a. tapp : quantum amplitude amplification and estimation , contemporary mathematics , vol 305 , p 53 , 2002 m. heiligman , finding matches between two databases on a quantum computer , quant - ph/0006136    l. k.  grover and j. radhakrishnan , e - print quant - ph/0407122 . v. e. korepin and l. k.  grover , accepted to quantum information processing , quant - ph/0504157 .",
    "v. e. korepin , journal of physics a : math .",
    "vol 38 , pages l731-l738 , 2005 and e - print quant - ph/0503238 ."
  ],
  "abstract_text": [
    "<S> a quantum algorithm can find a target item in a database faster than a classical algorithm . </S>",
    "<S> one can trade accuracy for speed and find a part of the database ( a block ) containing the target item even faster , this is partial search . </S>",
    "<S> we consider different partial search algorithms and suggest the optimal one . </S>",
    "<S> efficiency of an algorithm is measured by number of queries to the oracle .    </S>"
  ]
}