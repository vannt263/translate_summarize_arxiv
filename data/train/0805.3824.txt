{
  "article_text": [
    "the problem of error correction for a network implementing linear network coding has been an active research area since 2002 @xcite .",
    "the crucial motivation for the problem is the phenomenon of error propagation , which arises due to the recombination characteristic at the heart of network coding .",
    "a single corrupt packet occurring in the application layer ( e.g. , introduced by a malicious user ) may proceed undetected and contaminate other packets , causing potentially drastic consequences and essentially ruling out classical error correction approaches .    in the basic multicast model for linear network coding ,",
    "a source node transmits @xmath0 packets , each consisting of @xmath1 symbols from a finite field @xmath2 .",
    "each link in the network transports a packet free of errors , and each node creates outgoing packets as @xmath2-linear combinations of incoming packets .",
    "there are one or more destination nodes that wish to obtain the original source packets . at a specific destination node",
    ", the received packets may be represented as the rows of an @xmath3 matrix @xmath4 , where @xmath5 is the matrix whose rows are the source packets and @xmath6 is the transfer matrix of the network .",
    "errors are incorporated in the model by allowing up to @xmath7 error packets to be added ( in the vector space @xmath8 ) to the packets sent over one or more links .",
    "the received matrix @xmath9 at a specific destination node may then be written as @xmath10 where @xmath11 is a @xmath12 matrix whose rows are the error packets , and @xmath13 is the transfer matrix from these packets to the destination . under this model ,",
    "a coding - theoretic problem is how to design an outer code and the underlying network code such that reliable communication ( to all destinations ) is possible .",
    "this coding problem can be posed in a number of ways depending on the set of assumptions made .",
    "for example , we may assume that the network topology and the network code are known at the source and at the destination nodes , in which case we call the system _ coherent network coding_. alternatively , we may assume that such information is unavailable , in which case we call the system _ noncoherent network coding_. the error matrix @xmath11 may be random or chosen by an adversary , and there may be further assumptions on the knowledge or other capabilities of the adversary .",
    "the essential assumption , in order to pose a meaningful coding problem , is that the number of injected error packets , @xmath7 , is bounded .",
    "error correction for coherent network coding was originally studied by cai and yeung @xcite .",
    "aiming to establish fundamental limits , they focused on the fundamental case @xmath14 . in @xcite",
    "( see also @xcite ) , the authors derive a singleton bound in this context and construct codes that achieve this bound .",
    "a drawback of their approach is that the field size required can be very large ( on the order of @xmath15 , where @xmath16 is the number of edges in the network ) , and no efficient decoding method is given .",
    "similar constructions , analyses and bounds appear also in @xcite .    in section  [ sec : coherent - network - coding ]",
    ", we approach this problem ( for general  @xmath1 ) under a different framework .",
    "we assume the pessimistic situation in which the adversary can not only inject up to @xmath7 packets but can also freely choose the matrix @xmath13 . in this scenario ,",
    "it is essential to exploit the structure of the problem when @xmath17 .",
    "the proposed approach allows us to find a metric  the rank metric  that succinctly describes the error correction capability of a code .",
    "we quite easily obtain bounds and constructions analogous to those of @xcite , and show that many of the results in @xcite can be reinterpreted and simplified in this framework .",
    "moreover , we find that our pessimistic assumption actually incurs no penalty since the codes we propose achieve the singleton bound of @xcite .",
    "an advantage of this approach is that it is _ universal _ , in the sense that the outer code and the network code may be designed independently of each other .",
    "more precisely , the outer code may be chosen as any rank - metric code with a good error - correction capability , while the network code can be designed as if the network were error - free ( and , in particular , the field size can be chosen as the minimum required for multicast ) .",
    "an additional advantage is that encoding and decoding of properly chosen rank - metric codes can be performed very efficiently  @xcite",
    ".    for noncoherent network coding , a combinatorial framework for error control was introduced by ktter and kschischang in @xcite . there , the problem is formulated as the transmission of subspaces through an operator channel , where the transmitted and received subspaces are the row spaces of the matrices @xmath5 and @xmath9 in ( [ eq : matrix - model ] ) , respectively .",
    "they proposed a metric that is suitable for this channel , the so - called subspace distance @xcite .",
    "they also presented a singleton - like bound for their metric and subspace codes achieving this bound .",
    "the main justification for their metric is the fact that a minimum subspace distance decoder seems to be the necessary and sufficient tool for optimally decoding the disturbances imposed by the operator channel .",
    "however , when these disturbances are translated to more concrete terms such as the number of error packets injected , only decoding guarantees can be obtained for the minimum distance decoder of @xcite , but no converse .",
    "more precisely , assume that @xmath7 error packets are injected and a general ( not necessarily constant - dimension ) subspace code with minimum subspace distance @xmath18 is used .",
    "in this case , while it is possible to guarantee successful decoding if @xmath19 , and we know of specific examples where decoding fails if this condition is not met , a general converse is not known .    in section  [ sec : noncoherent - network - coding ] , we prove such a converse for a new metric  called the _ injection distance_under a slightly different transmission model .",
    "we assume that the adversary is allowed to arbitrarily select the matrices @xmath6 and @xmath13 , provided that a lower bound on the rank of @xmath6 is respected . under this pessimistic scenario , we show that the injection distance is the fundamental parameter behind the error correction capability of a code ; that is , we can guarantee correction of @xmath7 packet errors _ if and only if _ @xmath7 is less than half the minimum injection distance of the code .",
    "while this approach may seem too pessimistic , we provide a class of examples where a minimum - injection - distance decoder is able to correct more errors than a minimum - subspace - distance decoder .",
    "moreover , the two approaches coincide when a constant - dimension code is used .    in order to give a unified treatment of both coherent and noncoherent network coding ,",
    "we first develop a general approach to error correction over ( certain ) adversarial channels .",
    "our treatment generalizes the more abstract portions of classical coding theory and has the main feature of mathematical simplicity .",
    "the essence of our approach is to use a single function  called a _",
    "discrepancy function_to fully describe an adversarial channel .",
    "we then propose a distance - like function that is easy to handle analytically and ( in many cases , including all the channels considered in this paper ) precisely describes the error correction capability of a code .",
    "the motivation for this approach is that , once such a distance function is found , one can virtually forget about the channel model and fully concentrate on the combinatorial problem of finding the largest code with a specified minimum distance ( just like in classical coding theory ) .",
    "interestingly , our approach is also useful to characterize the error detection capability of a code .",
    "the remainder of the paper is organized as follows .",
    "section  [ sec : preliminaries ] establishes our notation and review some basic facts about matrices and rank - metric codes .",
    "section  [ sec : adversarial - model ] presents our general approach to adversarial error correction , which is subsequently specialized to coherent and noncoherent network coding models .",
    "section  [ sec : coherent - network - coding ] describes our main results for coherent network coding and discusses their relationship with the work of yeung et al .",
    "@xcite . section  [ sec : noncoherent - network - coding ] describes our main results for noncoherent network coding and discusses their relationship with the work of ktter and kschischang @xcite .",
    "section  [ sec : conclusion ] presents our conclusions .",
    "define @xmath20 and @xmath21^+ = \\max\\{x,0\\}$ ] .",
    "the following notation is used many times throughout the paper .",
    "let @xmath22 be a set , and let @xmath23 .",
    "whenever a function @xmath24 is defined , denote @xmath25 if @xmath26 is called a `` distance '' between @xmath27 and @xmath28 , then @xmath29 is called the _ minimum",
    "_ `` distance '' of @xmath30 .",
    "let @xmath2 denote the finite field with @xmath31 elements .",
    "we use @xmath32 to denote the set of all @xmath33 matrices over @xmath2 and use @xmath34 to denote the set of all subspaces of the vector space @xmath8 .",
    "let @xmath35 denote the dimension of a vector space @xmath36 , let @xmath37 denote the row space of a matrix @xmath5 , and let @xmath38 denote the number of nonzero rows of @xmath5 . recall that @xmath39 .",
    "let @xmath40 and @xmath36 be subspaces of some fixed vector space .",
    "recall that the sum @xmath41 is the smallest vector space that contains both @xmath40 and @xmath36 , while the intersection @xmath42 is the largest vector space that is contained in both @xmath40 and @xmath36 .",
    "recall also that @xmath43    the rank of a matrix @xmath44 is the smallest @xmath45 for which there exist matrices @xmath46 and @xmath47 such that @xmath48 . note that both matrices obtained in the decomposition are full - rank ; accordingly , such a decomposition is called a full - rank decomposition @xcite . in this case , note that , by partitioning @xmath49 and @xmath50 , the matrix @xmath5 can be further expanded as @xmath51 where @xmath52 .",
    "another useful property of the rank function is that , for @xmath44 and @xmath53 , we have @xcite @xmath54      let @xmath55 be matrices .",
    "the _ rank distance _ between @xmath5 and @xmath9 is defined as @xmath56 it is well known that the rank distance is indeed a metric ; in particular , it satisfies the triangle inequality @xcite .    a _",
    "rank - metric code _ is a matrix code @xmath57 used in the context of the rank metric .",
    "the singleton bound for the rank metric @xcite ( see also @xcite ) states that every rank - metric code @xmath58 with minimum rank distance @xmath59 must satisfy latexmath:[\\[\\label{eq : singleton - bound }    achieve this bound are called _ maximum - rank - distance _ ( mrd ) codes and they are known to exist for all choices of parameters @xmath31 , @xmath0 , @xmath1 and @xmath61 @xcite .",
    "this section presents a general approach to error correction over adversarial channels .",
    "this approach is specialized to coherent and noncoherent network coding in sections [ sec : coherent - network - coding ] and [ sec : noncoherent - network - coding ] , respectively .",
    "an _ adversarial channel _ is specified by a finite input alphabet @xmath22 , a finite output alphabet @xmath62 and a collection of _ fan - out sets _",
    "@xmath63 for all @xmath64 . for each input @xmath27",
    ", the output @xmath65 is constrained to be in @xmath66 but is otherwise arbitrarily chosen by an adversary .",
    "the constraint on the output is important : otherwise , the adversary could prevent communication simply by mapping all inputs to the same output .",
    "no further restrictions are imposed on the adversary ; in particular , the adversary is potentially omniscient and has unlimited computational power .",
    "a code for an adversarial channel is a subset @xmath23 .",
    "we say that a code is _ unambiguous _ for a channel if the input codeword can always be uniquely determined from the channel output .",
    "more precisely , a code @xmath30 is unambiguous if the sets @xmath66 , @xmath67 , are pairwise disjoint .",
    "the importance of this concept lies in the fact that , if the code is _ not _ unambiguous , then there exist codewords @xmath68 that are _ indistinguishable _ at the decoder : if @xmath69 , then the adversary can ( and will ) exploit this ambiguity by mapping both @xmath27 and @xmath28 to the same output .",
    "a decoder for a code @xmath30 is any function @xmath70 , where @xmath71 denotes a decoding failure ( detected error ) .",
    "when @xmath67 is transmitted and @xmath72 is received , a decoder is said to be _ successful _ if @xmath73 .",
    "we say that a decoder is _",
    "infallible _ if it is successful for all @xmath72 and all @xmath67 .",
    "note that the existence of an infallible decoder for @xmath30 implies that @xmath30 is unambiguous .",
    "conversely , given any unambiguous code @xmath30 , one can always find ( by definition ) a decoder that is infallible .",
    "one example is the exhaustive decoder @xmath74 in other words , an exhaustive decoder returns @xmath27 if @xmath27 is the unique codeword that could possibly have been transmitted when @xmath65 is received , and returns a failure otherwise .",
    "ideally , one would like to find a large ( or largest ) code that is unambiguous for a given adversarial channel , together with a decoder that is infallible ( and computationally - efficient to implement ) .",
    "it is useful to consider adversarial channels parameterized by an _ adversarial effort _ @xmath75 .",
    "assume that the fan - out sets are of the form @xmath76 for some @xmath77 .",
    "the value @xmath78 , which we call the _ discrepancy _ between @xmath27 and @xmath65 , represents the minimum effort needed for an adversary to transform an input @xmath27 into an output @xmath65 .",
    "the value of @xmath7 represents the maximum adversarial effort ( maximum discrepancy ) allowed in the channel .    in principle",
    ", there is no loss of generality in assuming ( [ eq : output - sets ] ) since , by properly defining @xmath78 , one can always express any @xmath66 in this form .",
    "for instance , one could set @xmath79 if @xmath72 , and @xmath80 otherwise .",
    "however , such a definition would be of no practical value since @xmath78 would be merely an indicator function .",
    "thus , an effective limitation of our model is that it requires channels that are _ naturally _ characterized by some discrepancy function . in particular , one should be able to interpret the maximum discrepancy @xmath7 as the level of `` degradedness '' of the channel .",
    "on the other hand , the assumption @xmath81 imposes effectively no constraint .",
    "since @xmath82 is finite , given any `` naturally defined '' @xmath83 , one can always shift , scale and round the image of @xmath84 in order to produce some @xmath85 that induces the same fan - out sets as @xmath84 for all @xmath7 .",
    "[ ex : t - error - channel ] let us use the above notation to define a @xmath7-error channel , i.e. , a vector channel that introduces at most @xmath7 symbol errors ( arbitrarily chosen by an adversary ) .",
    "assume that the channel input and output alphabets are given by @xmath86 .",
    "it is easy to see that the channel can be characterized by a discrepancy function that counts the number of components in which an input vector @xmath27 and an output vector @xmath65 differ .",
    "more precisely , we have @xmath87 , where @xmath88 denotes the _ hamming distance _ function .",
    "a main feature of our proposed discrepancy characterization is to allow us to study a whole family of channels ( with various levels of degradedness ) under the same framework .",
    "for instance , we can use a single decoder for all channels in the same family . define the _ minimum - discrepancy decoder _ given by @xmath89 where any ties in ( [ eq : minimum - discrepancy - decoder ] ) are assumed to be broken arbitrarily .",
    "it is easy to see that a minimum - discrepancy decoder is infallible provided that the code is unambiguous .",
    "thus , we can safely restrict attention to a minimum - discrepancy decoder , regardless of the maximum discrepancy @xmath7 in the channel .      given a fixed family of channels  specified by @xmath22 , @xmath62 and @xmath90 , and parameterized by a maximum discrepancy @xmath7we wish to identify the largest ( worst ) channel parameter for which we can guarantee successful decoding .",
    "we say that a code is _ @xmath7-discrepancy - correcting _ if it is unambiguous for a channel with maximum discrepancy @xmath7 .",
    "the _ discrepancy - correction capability _ of a code @xmath30 is the largest @xmath7 for which @xmath30 is @xmath7-discrepancy - correcting .",
    "we start by giving a general characterization of the discrepancy - correction capability .",
    "let the function @xmath91 be given by @xmath92 we have the following result .",
    "the discrepancy - correction capability of a code @xmath30 is given exactly by @xmath93 .",
    "in other words , @xmath30 is @xmath7-discrepancy - correcting if and only if @xmath94 .",
    "suppose that the code is not @xmath7-discrepancy - correcting , i.e. , that there exist some distinct @xmath95 and some @xmath96 such that @xmath97 and @xmath98",
    ". then @xmath99 .",
    "in other words , @xmath100 implies that the code is @xmath7-discrepancy - correcting .",
    "conversely , suppose that @xmath101 , i.e. , @xmath102 .",
    "then there exist some distinct @xmath95 such that @xmath103 .",
    "this in turn implies that there exists some @xmath96 such that @xmath104 . since this implies that both @xmath97 and @xmath98 , it follows that the code is not @xmath7-discrepancy - correcting .    at this point",
    ", it is tempting to define a `` distance - like '' function given by @xmath105 , since this would enable us to immediately obtain results analogous to those of classical coding theory ( such as the error correction capability being half the minimum distance of the code ) .",
    "this approach has indeed been taken in previous works , such as @xcite .",
    "note , however , that the terminology `` distance '' suggests a geometrical interpretation , which is not immediately clear from ( [ eq : function - exact - capability ] ) .",
    "moreover , the function ( [ eq : function - exact - capability ] ) is not necessarily mathematically tractable .",
    "it is the objective of this section to propose a `` distance '' function @xmath106 that is motivated by geometrical considerations and is easier to handle analytically , yet is useful to characterize the correction capability of a code .",
    "in particular , we shall be able to obtain the same results as @xcite with much greater mathematical simplicity  which will later turn out to be instrumental for code design .    for @xmath107",
    ", define the _ @xmath108-distance _ between @xmath27 and @xmath28 as @xmath109 the following interpretation holds .",
    "consider the complete bipartite graph with vertex sets @xmath22 and @xmath62 , and assume that each edge @xmath110 is labeled by a `` length '' @xmath78 .",
    "then @xmath111 is the length of the shortest path between vertices @xmath107 . roughly speaking",
    ", @xmath111 gives the minimum total effort that an adversary would have to spend ( in independent channel realizations ) in order to make @xmath27 and @xmath28 both plausible explanations for some received output .",
    "let us compute the @xmath108-distance for the channel of example  [ ex : t - error - channel ] .",
    "we have @xmath112 , since the hamming distance satisfies the triangle inequality .",
    "this bound is achievable by taking , for instance , @xmath113 .",
    "thus , @xmath114 , i.e. , the @xmath108-distance for this channel is given precisely by the hamming distance .",
    "the following result justifies our definition of the @xmath108-distance .",
    "[ prop : correction - guarantee ] for any code @xmath30 , @xmath115 .",
    "this follows from the fact that @xmath116 for all @xmath117 .",
    "proposition  [ prop : correction - guarantee ] shows that @xmath118 gives a lower bound on the correction capability of a code  therefore providing a correction guarantee .",
    "the converse result , however , is not necessarily true in general .",
    "thus , up to this point , the proposed function is only partially useful : it is conceivable that the @xmath108-distance might be too conservative and give a guaranteed correction capability that is lower than the actual one .",
    "nevertheless , it is easier to deal with addition , as in ( [ eq : delta - distance - definition ] ) , rather than maximization , as in ( [ eq : function - exact - capability ] ) .    a special case where the converse is true is for a family of channels whose discrepancy function satisfies the following condition :    [ def : magic - property ] a discrepancy function @xmath119 is said to be _ normal _ if , for all @xmath107 and all @xmath120 , there exists some @xmath96 such that @xmath121 and @xmath122 .",
    "[ thm : magic - property - converse ] suppose that @xmath90 is normal .",
    "for every code @xmath23 , we have @xmath123 .",
    "we just need to show that @xmath124 .",
    "take any @xmath107 . since @xmath90 is normal",
    ", there exists some @xmath96 such that @xmath125 and either @xmath126 or @xmath127 .",
    "thus , @xmath128 and therefore @xmath129 .    theorem  [ thm : magic - property - converse ] shows that , for certain families of channels , our proposed @xmath108-distance achieves the goal of this section : it is a ( seemingly ) tractable function that precisely describes the correction capability of a code . in particular ,",
    "the basic result of classical coding theory  that the hamming distance precisely describes the error correction capability of a code  follows from the fact that the hamming distance ( as a discrepancy function ) is normal .",
    "as we shall see , much of our effort in the next sections reduces to showing that a specified discrepancy function is normal .    note",
    "that , for normal discrepancy functions , we actually have @xmath130 , so theorem  [ thm : magic - property - converse ] may also be regarded as providing an alternative ( and more tractable ) expression for @xmath131 .    to give a nontrivial example ,",
    "let us consider a binary vector channel that introduces at most @xmath132 erasures ( arbitrarily chosen by an adversary ) .",
    "the input alphabet is given by @xmath133 , while the output alphabet is given by @xmath134 , where @xmath135 denotes an erasure .",
    "we may define @xmath136 , where @xmath137 the fan - out sets are then given by @xmath138 . in order to compute @xmath111 ,",
    "observe the minimization in ( [ eq : delta - distance - definition ] ) .",
    "it is easy to see that we should choose @xmath139 when @xmath140 , and @xmath141 when @xmath142 .",
    "it follows that @xmath143 .",
    "note that @xmath78 is normal .",
    "it follows from theorem  [ thm : magic - property - converse ] that a code @xmath30 can correct all the @xmath132 erasures introduced by the channel if and only if @xmath144 .",
    "this result precisely matches the well - known result of classical coding theory .",
    "it is worth clarifying that , while we call @xmath145 a `` distance , '' this function may not necessarily be a metric .",
    "while symmetry and non - negativity follow from the definition , a @xmath108-distance may not always satisfy `` @xmath146 '' or the triangle inequality .",
    "nevertheless , we keep the terminology for convenience .",
    "although this is not our main interest in this paper , it is worth pointing out that the framework of this section is also useful for obtaining results on error _",
    "detection_. namely , the @xmath108-distance gives , in general , a lower bound on the discrepancy detection capability of a code under a bounded discrepancy - correcting decoder ; when the discrepancy function is normal , then the @xmath108-distance precisely characterizes this detection capability ( similarly as in classical coding theory ) . for more details on this topic , see appendix  [ sec : detection - capability ] .",
    "the basic channel model for coherent network coding with adversarial errors is a matrix channel with input @xmath44 , output @xmath147 , and channel law given by ( [ eq : matrix - model ] ) , where @xmath53 is fixed and known to the receiver , and @xmath148 is arbitrarily chosen by an adversary . here",
    ", we make the following additional assumptions :    * the adversary has unlimited computational power and is omniscient ; in particular , the adversary knows both @xmath6 and @xmath5 ; * the matrix @xmath149 is arbitrarily chosen by the adversary .",
    "we also assume that @xmath150 ( more precisely , we should assume @xmath151 ) ; otherwise , the adversary may always choose @xmath152 , leading to a trivial communications scenario .",
    "the first assumption above allows us to use the approach of section  [ sec : general - approach ] .",
    "the second assumption may seem somewhat `` pessimistic , '' but it has the analytical advantage of eliminating from the problem any further dependence on the network code .",
    "( recall that , in principle , @xmath13 would be determined by the network code and the choice of links in error . )",
    "the power of the approach of section  [ sec : general - approach ] lies in the fact that the channel model defined above can be _ completely _ described by the following discrepancy function @xmath153 the discrepancy @xmath154 represents the minimum number of error packets that the adversary needs to inject in order to transform an input @xmath5 into an output @xmath9 , given that the transfer matrix is @xmath6 .",
    "the subscript in @xmath155 is to emphasize the dependence on  @xmath6 . for this discrepancy function ,",
    "the minimum - discrepancy decoder becomes @xmath156 similarly , the @xmath108-distance induced by @xmath155 is given by @xmath157 for @xmath158 .",
    "we now wish to find a simpler expression for @xmath155 and @xmath159 , and show that @xmath155 is normal .",
    "[ lem : coherent - discrepancy - rank ] @xmath160    consider @xmath154 as given by ( [ eq : coherent - discrepancy ] ) .",
    "for any feasible triple @xmath161 , we have @xmath162 .",
    "this bound is achievable by setting @xmath163 and letting @xmath164 be a full - rank decomposition of @xmath165 .",
    "@xmath166    from ( [ eq : coherent - delta - between - codewords ] ) and lemma  [ lem : coherent - discrepancy - rank ] , we have @xmath167 . since the rank metric satisfies the triangle inequality , we have @xmath168 .",
    "this lower bound can be achieved by choosing , e.g. , @xmath4 .",
    "note that @xmath169 is a metric if and only if @xmath6 has full column rank  in which case it is precisely the rank metric .",
    "( if @xmath170 , then there exist @xmath171 such that @xmath172 . )",
    "[ thm : coherent - magic ] the discrepancy function @xmath173 is normal .",
    "let @xmath158 and let @xmath174",
    ". then @xmath175 . by performing a full - rank decomposition of @xmath176 ,",
    "we can always find two matrices @xmath177 and @xmath178 such that @xmath179 , @xmath180 and @xmath181 .",
    "taking @xmath182 , we have that @xmath183 and @xmath184 .",
    "note that , under the discrepancy @xmath155 , a @xmath7-discrepancy - correcting code is a code that can correct _ any _ @xmath7 packet errors injected by the adversary . using theorem  [ thm : coherent - magic ] and theorem  [ thm : magic - property - converse ] , we have the following result .",
    "[ thm : coherent - correction - capability ] a code @xmath185 is guaranteed to correct any @xmath7 packet errors if and only if @xmath186 .    theorem  [ thm : coherent - correction - capability ] shows that @xmath187 is indeed a fundamental parameter characterizing the error correction capability of a code in our model .",
    "note that , if the condition of theorem  [ thm : coherent - correction - capability ] is violated , then there exists at least one codeword for which the adversary can certainly induce a decoding failure .    note that the error correction capability of a code @xmath185 is dependent on the network code through the matrix @xmath6 .",
    "let @xmath188 be the column - rank deficiency of @xmath6 .",
    "since @xmath189 , it follows from ( [ eq : bound - rank - product ] ) that @xmath190 and @xmath191 thus , the error correction capability of a code is strongly tied to its minimum rank distance ; in particular , @xmath192 if @xmath193 . while the lower bound @xmath194 may not be tight in general , we should expect it to be tight when @xmath30 is sufficiently large .",
    "this is indeed the case for mrd codes , as discussed in section  [ ssec : coherent - optimality ] .",
    "thus , a rank deficiency of @xmath6 will typically reduce the error correction capability of a code .    taking into account the worst case ,",
    "we can use theorem  [ thm : coherent - correction - capability ] to give a correction guarantee in terms of the minimum rank distance of the code .    [ prop : coherent - guarantee - rank - metric ] a code @xmath185 is guaranteed to correct @xmath7 packet errors , under rank deficiency @xmath132 , if @xmath195 .",
    "note that the guarantee of proposition  [ prop : coherent - guarantee - rank - metric ] depends only on @xmath132 and @xmath7 ; in particular , it is independent of the network code or the specific transfer matrix @xmath6 .      in this subsection , we investigate the model for coherent network coding studied by yeung et al .  in @xcite , which is similar to the one considered in the previous subsection .",
    "the model is that of a matrix channel with input @xmath44 , output @xmath147 , and channel law given by @xmath196 where @xmath53 and @xmath197 are fixed and known to the receiver , and @xmath198 is arbitrarily chosen by an adversary provided @xmath199 .",
    "( recall that @xmath200 is the number of edges in the network . )",
    "in addition , the adversary has unlimited computational power and is omniscient , knowing , in particular , @xmath6 , @xmath201 and @xmath5 .",
    "we now show that some of the concepts defined in @xcite , such as `` network hamming distance , '' can be reinterpreted in the framework of section  [ sec : general - approach ] . as a consequence",
    ", we can easily recover the results of @xcite on error correction and detection guarantees .",
    "first , note that the current model can be completely described by the following discrepancy function @xmath202 the @xmath108-distance induced by this discrepancy function is given by @xmath203 where the last equality follows from the fact that @xmath204 , achievable if @xmath205 .",
    "let us now examine some of the concepts defined in .",
    "for a specific sink node , the decoder proposed in ( * ? ? ?",
    "* eq . ( 2 ) ) has the form @xmath206 the definition of the objective function @xmath207 requires several other definitions presented in @xcite .",
    "specifically , @xmath208 , where @xmath209 , @xmath210 , and @xmath211 . substituting all these values into @xmath207 , we obtain @xmath212 thus , the decoder in @xcite is precisely a minimum - discrepancy decoder .    in @xcite , the `` network hamming distance '' between two messages @xmath213 and @xmath214",
    "is defined as @xmath215 , where @xmath216 .",
    "again , simply substituting the corresponding definitions yields @xmath217 thus , the `` network hamming distance '' is precisely the @xmath108-distance induced by the discrepancy function @xmath218 .",
    "finally , the `` unicast minimum distance '' of a network code with message set @xmath185 @xcite is precisely @xmath219 .",
    "let us return to the problem of characterizing the correction capability of a code .",
    "the discrepancy function @xmath220 is normal .",
    "let @xmath221 and let @xmath222 .",
    "let @xmath223 be a solution to the minimization in ( [ eq : yeung - discrepancy ] )",
    ". then @xmath224 and @xmath225 . by partitioning @xmath226 ,",
    "we can always find two matrices @xmath227 and @xmath228 such that @xmath229 , @xmath230 and @xmath231 .",
    "taking @xmath232 , we have that @xmath233 and @xmath234 .",
    "since @xmath235 , it follows that @xmath236 and @xmath237 .",
    "it follows that a code @xmath30 is guaranteed to correct any @xmath7 packet errors if and only if @xmath238 .",
    "thus , we recover theorems 2 and 3 in @xcite ( for error detection , see appendix  [ sec : detection - capability ] ) .",
    "the analogous results for the multicast case can be obtained in a straightforward manner .",
    "we now wish to compare the parameters devised in this subsection with those of section  [ ssec : coherent - main ] . from the descriptions of ( [ eq : matrix - model ] ) and ( [ eq : channel - model - full ] )",
    ", it is intuitive that the model of this subsection should be equivalent to that of the previous subsection if the matrix @xmath201 , rather than fixed and known to the receiver , is arbitrarily and secretly chosen by the adversary . a formal proof of this fact is given in the following proposition .    [ prop : coherent - yeung - comparison ] @xmath239    consider the minimization @xmath240 for any feasible @xmath241",
    ", we have @xmath242 .",
    "this lower bound can be achieved by taking @xmath243 where @xmath244 is a full - rank decomposition of @xmath165 .",
    "this proves the first statement .",
    "the second statement follows from the first by noticing that @xmath245 and @xmath246 .",
    "the third statement is immediate .",
    "proposition  [ prop : coherent - yeung - comparison ] shows that the model of section  [ ssec : coherent - main ] is indeed more pessimistic , as the adversary has additional power to choose the worst possible @xmath201 .",
    "it follows that any code that is @xmath7-error - correcting for that model must also be @xmath7-error - correcting for the model of yeung et al .",
    "let us now evaluate the performance of an mrd code under the models of the two previous subsections .",
    "the singleton bound of @xcite ( see also @xcite ) states that @xmath247 where @xmath50 is the size of the alphabet .",
    "] from which packets are drawn .",
    "note that @xmath248 in our setting , since each packet consists of @xmath1 symbols from @xmath2 . using proposition  [ prop : coherent - yeung - comparison",
    "] , we can also obtain @xmath249    on the other hand , the size of an mrd code , for @xmath250 , is given by @xmath251 where ( [ eq : coherent - mrd - proof-1 ] ) follows from ( [ eq : coherent - delta - rank - distance ] ) . since @xmath248 , both ( [ eq : singleton - yeung ] ) and ( [ eq : singleton - coherent ] ) are achieved in this case .",
    "thus , we have the following result .",
    "[ thm : coherent - optimality - mrd ] when @xmath250 , an mrd code @xmath57 achieves maximum cardinality with respect to both @xmath252 and @xmath253 .",
    "theorem  [ thm : coherent - optimality - mrd ] shows that , if an alphabet of size @xmath254 is allowed ( i.e. , a packet size of at least @xmath255 bits ) , then mrd codes turn out to be optimal under both models of sections [ ssec : coherent - main ] and [ ssec : coherent - comparison ] .",
    "it is straightforward to extend the results of section  [ ssec : coherent - main ] for the case of multiple heterogeneous receivers , where each receiver @xmath256 experiences a rank deficiency @xmath257 . in this case",
    ", it can be shown that an mrd code with @xmath250 achieves the refined singleton bound of @xcite .",
    "note that , due to ( [ eq : singleton - coherent ] ) , ( [ eq : coherent - mrd - singleton ] ) and ( [ eq : coherent - mrd - proof-1 ] ) , it follows that @xmath258 for an mrd code with @xmath250 .",
    "thus , in this case , we can restate theorem  [ thm : coherent - correction - capability ] in terms of the minimum rank distance of the code .",
    "[ thm : coherent - complete - capability ] an mrd code @xmath58 with @xmath250 is guaranteed to correct @xmath7 packet errors , under rank deficiency @xmath132 , if and only if @xmath195 .",
    "observe that theorem  [ thm : coherent - complete - capability ] holds regardless of the specific transfer matrix @xmath6 , depending only on its column - rank deficiency @xmath132 .",
    "the results of this section imply that , when designing a linear network code , we may focus solely on the objective of making the network code feasible , i.e. , maximizing @xmath259 .",
    "if an error correction guarantee is desired , then an outer code can be applied end - to - end without requiring any modifications on ( or even knowledge of ) the underlying network code .",
    "the design of the outer code is essentially trivial , as any mrd code can be used , with the only requirement that the number of @xmath2-symbols per packet , @xmath1 , is at least @xmath0 .    consider the decoding rule ( [ eq : coherent - decoding - rule ] ) .",
    "the fact that ( [ eq : coherent - decoding - rule ] ) together with ( [ eq : coherent - discrepancy - rank ] ) is equivalent to ( * ? ? ?",
    "* eq . ( 20 ) ) implies that the decoding problem can be solved by exactly the same rank - metric techniques proposed in @xcite .",
    "in particular , for certain mrd codes with @xmath250 and minimum rank distance @xmath18 , there exist efficient encoding and decoding algorithms both requiring @xmath260 operations in @xmath2 per codeword . for more details , see @xcite .",
    "our model for noncoherent network coding with adversarial errors differs from its coherent counterpart of section  [ ssec : coherent - main ] only with respect to the transfer matrix @xmath6 .",
    "namely , the matrix @xmath6 is unknown to the receiver and is freely chosen by the adversary while respecting the constraint @xmath261 .",
    "the parameter @xmath132 , the maximum column rank deficiency of @xmath6 , is a parameter of the system that is known to all .",
    "note that , as discussed above for the matrix @xmath13 , the assumption that @xmath6 is chosen by the adversary is what provides the conservative ( worst - case ) nature of the model .",
    "the constraint on the rank of @xmath6 is required for a meaningful coding problem ; otherwise , the adversary could prevent communication by simply choosing @xmath262 .    as before",
    ", we assume a minimum - discrepancy decoder @xmath263 with discrepancy function given by @xmath264 again , @xmath265 represents the minimum number of error packets needed to produce an output @xmath9 given an input @xmath5 under the current adversarial model .",
    "the subscript is to emphasize that @xmath265 is still a function of @xmath132 .",
    "the @xmath108-distance induced by @xmath266 is defined below . for @xmath158 ,",
    "let @xmath267    we now prove that @xmath266 is normal and therefore @xmath268 characterizes the correction capability of a code .",
    "first , observe that , using lemma  [ lem : coherent - discrepancy - rank ] , we may rewrite @xmath265 as @xmath269 also , note that @xmath270    & \\hspace{8.5em } { } + \\operatorname{\\sf rank\\hspace{0.1em}}(y - a'x ' ) \\ } \\nonumber \\\\[2ex ]    & = \\min_{\\substack{a , a ' \\in { \\mathbb{f}_q}^{n \\times n}:\\\\ \\operatorname{\\sf rank\\hspace{0.1em}}a \\geq n - \\rho\\\\ \\operatorname{\\sf rank\\hspace{0.1em}}a ' \\geq n - \\rho } } \\operatorname{\\sf rank\\hspace{0.1em}}(a'x ' - ax ) \\label{eq : noncoherent - delta - expression - rank }    \\end{aligned}\\ ] ] where the last equality follows from the fact that @xmath271 , achievable by choosing , e.g. , @xmath4 .",
    "[ thm : noncoherent - magic ] the discrepancy function @xmath272 is normal .",
    "let @xmath158 and let @xmath273 .",
    "let @xmath274 be a solution to the minimization in ( [ eq : noncoherent - delta - expression - rank ] )",
    ". then @xmath275 . by performing a full - rank decomposition of @xmath276 ,",
    "we can always find two matrices @xmath177 and @xmath178 such that @xmath277 , @xmath180 and @xmath181 .",
    "taking @xmath182 , we have that @xmath278 and @xmath279 .",
    "since @xmath280 , it follows that @xmath281 and @xmath282 .    as a consequence of theorem  [ thm : noncoherent - magic ] , we have the following result .",
    "[ thm : noncoherent - capability ] a code @xmath185 is guaranteed to correct any @xmath7 packet errors if and only if @xmath283 .    similarly as in section  [ ssec : coherent - main ] , theorem  [ thm : noncoherent - capability ] shows that @xmath284 is a fundamental parameter characterizing the error correction capability of a code in the current model .",
    "in contrast to section  [ ssec : coherent - main ] , however , the expression for @xmath266 ( and , consequently , @xmath285 ) does not seem mathematically appealing since it involves a minimization .",
    "we now proceed to finding simpler expressions for @xmath266 and @xmath285 .",
    "the minimization in ( [ eq : noncoherent - discrepancy - rank ] ) is a special case of a more general expression , which we give as follows . for @xmath44 , @xmath147 and @xmath286 ,",
    "let @xmath287    the quantity defined above is computed in the following lemma .",
    "[ lem : min - rank - quantity ] @xmath288^+.\\ ] ]    see appendix  [ sec : proof - lemma ] .",
    "note that @xmath289 is independent of @xmath290 , for all valid @xmath290 .",
    "thus , we may drop the subscript and write simply @xmath291 .",
    "we can now provide a simpler expression for @xmath265 .",
    "[ thm : noncoherent - discrepancy - expression ] @xmath292    this follows immediately from lemma  [ lem : min - rank - quantity ] by noticing that @xmath293 .    from theorem  [ thm : noncoherent - discrepancy - expression",
    "] , we observe that @xmath265 depends on the matrices @xmath5 and @xmath9 only through their row spaces , i.e. , only the transmitted and received row spaces have a role in the decoding .",
    "put another way , we may say that the channel really accepts an input subspace @xmath37 and delivers an output subspace @xmath294 .",
    "thus , all the communication is made via subspace selection .",
    "this observation provides a fundamental justification for the approach of @xcite .    at this point , it is useful to introduce the following definition .",
    "[ def : modif - subspace - distance ] the _ injection distance _ between subspaces @xmath295 and @xmath296 in @xmath34 is defined as @xmath297    the injection distance can be interpreted as measuring the number of error packets that an adversary needs to inject in order to transform an input subspace @xmath37 into an output subspace @xmath294 .",
    "this can be clearly seen from the fact that @xmath298 .",
    "thus , the injection distance is essentially equal to the discrepancy @xmath265 when the channel is influenced only by the adversary , i.e. , when the non - adversarial aspect of the channel ( the column - rank deficiency of @xmath6 ) is removed from the problem .",
    "note that , in this case , the decoder ( [ eq : noncoherent - decoding - rule ] ) becomes precisely a minimum - injection - distance decoder .",
    "[ prop : injection - metric ] the injection distance is a metric .    we delay the proof of proposition  [ prop : injection - metric ] until section  [ ssec : noncoherent - comparison ] .",
    "we can now use the definition of the injection distance to simplify the expression for the @xmath108-distance .    [",
    "prop : noncoherent - delta - expression ] @xmath299^+.\\ ] ]    this follows immediately after realizing that @xmath300 .    from proposition",
    "[ prop : noncoherent - delta - expression ] , it is clear that @xmath301 is a metric if and only if @xmath193 ( in which case it is precisely the injection metric ) .",
    "if @xmath302 , then @xmath301 does not satisfy the triangle inequality .",
    "it is worth noticing that @xmath303 for any two matrices @xmath5 and @xmath304 that share the same row space .",
    "thus , any reasonable code @xmath185 should avoid this situation .    for @xmath58 ,",
    "let @xmath305 be the subspace code ( i.e. , a collection of subspaces ) consisting of the row spaces of all matrices in @xmath30 .",
    "the following corollary of proposition  [ prop : noncoherent - delta - expression ] is immediate .",
    "[ cor : noncoherent - delta - min - expression ] suppose @xmath185 is such that @xmath306 , i.e. , no two codewords of @xmath185 have the same row space . then @xmath307^+.\\ ] ]    using corollary  [ cor : noncoherent - delta - min - expression ] , we can restate theorem  [ thm : noncoherent - capability ] more simply in terms of the injection distance .",
    "[ thm : noncoherent - complete - capability ] a code @xmath185 is guaranteed to correct @xmath7 packet errors , under rank deficiency @xmath132 , if and only if @xmath308 .",
    "note that , due to equality in corollary  [ cor : noncoherent - delta - min - expression ] , a converse is indeed possible in theorem  [ thm : noncoherent - complete - capability ] ( contrast with proposition  [ prop : coherent - guarantee - rank - metric ] for the coherent case ) .",
    "theorem  [ thm : noncoherent - complete - capability ] shows that @xmath309 is a fundamental parameter characterizing the _ complete _ correction capability ( i.e. , error correction capability and `` rank - deficiency correction '' capability ) of a code in our noncoherent model .",
    "put another way , we may say that a code @xmath185 is good for the model of this subsection if and only if its subspace version @xmath310 is a good code in the injection metric .",
    "let @xmath311 be a subspace code whose elements have maximum dimension @xmath0 . in @xcite ,",
    "the network is modeled as an operator channel that takes in a subspace @xmath312 and puts out a possibly different subspace @xmath313 .",
    "the kind of disturbance that the channel applies to @xmath296 is captured by the notions of `` insertions '' and `` deletions '' of dimensions ( represented mathematically using operators ) , and the degree of such a dissimilarity is captured by the subspace distance @xmath314 the transmitter selects some @xmath315 and transmits @xmath296 over the channel .",
    "the receiver receives some subspace @xmath295 and , using a _ minimum subspace distance decoder _ , decides that the subspace @xmath316 was sent , where @xmath317 this decoder is guaranteed to correct all disturbances applied by the channel if @xmath318 , where @xmath319 is the minimum subspace distance between all pairs of distinct codewords of @xmath320 .",
    "first , let us point out that this setup is indeed the same as that of section  [ ssec : noncoherent - main ] if we set @xmath321 , @xmath322 and @xmath323 , where @xmath185 is such that @xmath306 .",
    "also , any disturbance applied by an operator channel can be realized by a matrix model , and vice - versa .",
    "thus , the difference between the approach of this section and that of @xcite lies in the choice of the decoder .    indeed , by using theorem  [ thm : noncoherent - discrepancy - expression ] and the definition of subspace distance , we get the following relationship :    [ prop : delta - and - subspace - distance ] @xmath324    thus , we can see that when the matrices in @xmath185 do not all have the same rank ( i.e. , @xmath320 is a _ non - constant - dimension code _ ) , then the decoding rules ( [ eq : noncoherent - decoding - rule ] ) and ( [ eq : subspace - decoding - rule ] ) may produce different decisions .",
    "using @xmath325 in the above proposition ( or simply using ( [ eq : injection - distance - definition ] ) and ( [ eq : subspace - distance - definition ] ) ) gives us another formula for the injection distance : @xmath326    we can now prove a result that was postponed in the previous section .    the injection distance is a metric .    since @xmath327 is a metric on @xmath34 and @xmath328",
    "is a norm on @xmath329 , it follows from ( [ eq : injection - and - subspace - distance ] ) that @xmath330 is also a metric on @xmath34 .",
    "we now examine in more detail an example situation where the minimum - subspace - distance decoder and the minimum - discrepancy decoder produce different decisions .",
    "[ ex : decoding - comparison ] for simplicity , assume @xmath193 .",
    "consider a subspace code that contains two codewords @xmath331 and @xmath332 such that @xmath333 satisfies @xmath334 , where @xmath335 .",
    "suppose the received subspace @xmath322 is such that @xmath336 and @xmath337 , as illustrated in fig .",
    "[ fig : subspaces ] . then @xmath338 and @xmath339 ,",
    "while proposition  ( [ prop : delta - and - subspace - distance ] ) gives @xmath340 and @xmath341 .",
    "since , by assumption , @xmath342 and @xmath343 , it follows that @xmath344 but @xmath345 , i.e. , the decoders ( [ eq : subspace - decoding - rule ] ) and ( [ eq : noncoherent - decoding - rule ] ) will produce different decisions .",
    "this situation can be intuitively explained as follows .",
    "the decoder ( [ eq : subspace - decoding - rule ] ) favors the subspace @xmath346 , which is closer in subspace distance to @xmath295 than @xmath347 .",
    "however , since @xmath346 is low - dimensional , @xmath295 can only be produced from @xmath346 by the _ insertion _ of @xmath348 dimensions .",
    "the decoder ( [ eq : noncoherent - decoding - rule ] ) , on the other hand , favors @xmath347 , which , although farther in subspace distance , can produce @xmath295 after the _ replacement _ of @xmath343 dimensions . since one packet error must occur for",
    "each inserted or replaced dimension , we conclude that the decoder ( [ eq : noncoherent - decoding - rule ] ) finds the solution that minimizes the number of packet errors observed .    .",
    "two spaces are joined with a dashed line if one is a subspace of the other.,title=\"fig : \" ] +    the subspace metric of @xcite treats insertions and deletions of dimensions ( called in @xcite `` errors '' and `` erasures '' , respectively ) symmetrically . however , depending upon the position of the adversary in the network ( namely , if there is a source - destination min - cut between the adversary and the destination ) then a single error packet may cause the replacement of a dimension ( i.e. , a simultaneous `` error '' and `` erasure '' in the terminology of @xcite ) . the injection distance , which is designed to `` explain '' a received subspace with as few error - packet injections as possible , properly accounts for this phenomenon , and hence the corresponding decoder produces a different result than a minimum subspace distance decoder . if it were possible to restrict the adversary so that each error - packet injection would only cause either an _ insertion _ or a _ deletion _ of a dimension ( but not both ) , then the subspace distance of @xcite would indeed be appropriate",
    "however , this is not the model considered here .",
    "let us now discuss an important fact about the subspace distance for general subspace codes ( assuming for simplicity that @xmath325 ) .",
    "the packet error correction capability of a minimum - subspace - distance decoder , @xmath349 , is not necessarily equal to @xmath350 or @xmath351 , but lies somewhere in between .",
    "for instance , in the case of a constant - dimension code @xmath320 , we have @xmath352 thus , theorem  [ thm : noncoherent - complete - capability ] implies that @xmath353 exactly .",
    "in other words , in this special case , the approach in @xcite coincides with that of this paper , and theorem  [ thm : noncoherent - complete - capability ] provides a converse that was missing in @xcite . on the other hand ,",
    "suppose @xmath320 is a subspace code consisting of just two codewords , one of which is a subspace of the other .",
    "then we have precisely @xmath354 , since @xmath355 packet - injections are needed to get past halfway between the codewords .",
    "since no single quantity is known that perfectly describes the packet error correction capability of the minimum - subspace - distance decoder ( [ eq : subspace - decoding - rule ] ) for general subspace codes , we can not provide a definitive comparison between decoders ( [ eq : subspace - decoding - rule ] ) and ( [ eq : noncoherent - decoding - rule ] ) .",
    "however , we can still compute bounds for codes that fit into example  [ ex : decoding - comparison ] .",
    "let us continue with example  [ ex : decoding - comparison ] .",
    "now , we adjoin another codeword @xmath356 such that @xmath357 and where @xmath358 satisfies @xmath359 .",
    "also we assume that @xmath360 is sufficiently large so as not to interfere with the problem ( e.g. , @xmath361 ) .",
    "let @xmath362 and @xmath363 denote the packet error correction capabilities of the decoders ( [ eq : subspace - decoding - rule ] ) and ( [ eq : noncoherent - decoding - rule ] ) , respectively . from the argument of example  [ ex : decoding - comparison ] , we get @xmath364 , while @xmath365 , where @xmath366 . by choosing @xmath367 and @xmath368 , we get @xmath369 and @xmath370 .",
    "thus , @xmath371 , i.e. , we obtain a 1/3 increase in error correction capability by using the decoder ( [ eq : noncoherent - decoding - rule ] ) .",
    "we have addressed the problem of error correction in network coding under a worst - case adversarial model .",
    "we show that certain metrics naturally arise as the fundamental parameter describing the error correction capability of a code ; namely , the rank metric for coherent network coding , and the injection metric for noncoherent network coding . for coherent network coding , the framework based on the rank metric essentially subsumes previous analyses and constructions , with the advantage of providing a clear separation between the problems of designing a feasible network code and an error - correcting outer code . for noncoherent network coding ,",
    "the injection metric provides a measure of code performance that is more precise , when a non - constant - dimension code is used , than the so - called subspace metric .",
    "the design of general subspace codes for the injection metric , as well as the derivation of bounds , is left as an open problem for future research .",
    "when dealing with communication over an adversarial channel , there is little justification to consider the possibility of error detection . in principle",
    ", a code should be designed to be unambiguous ( in which case error detection is not needed ) ; otherwise , if there is any possibility for ambiguity at the receiver , then the adversary will certainly exploit this possibility , leading to a high probability of decoding failure ( detected error ) .",
    "still , if a system is such that ( a ) sequential transmissions are made over the same channel , ( b ) there exists a feedback link from the receiver to the transmitter , and ( c ) the adversary is not able to fully exploit the channel at all times , then it might be worth using a code with a lower correction capability ( but higher rate ) that has some ability to detect errors .",
    "following classical coding theory , we consider error detection in the presence of a bounded error - correcting decoder . more precisely ,",
    "bounded - discrepancy decoder with correction radius @xmath7 _ , or simply a _ @xmath7-discrepancy - correcting decoder _ , by @xmath372 of course , when using a @xmath7-discrepancy - correcting decoder , we implicitly assume that the code is @xmath7-discrepancy - correcting .",
    "the _ discrepancy detection capability _ of a code ( under a @xmath7-discrepancy - correcting decoder ) is the maximum value of discrepancy for which the decoder is guaranteed not to make an undetected error , i.e. , it must return either the correct codeword or the failure symbol @xmath373 .    for @xmath75",
    ", let the function @xmath374 be given by @xmath375    the discrepancy - detection capability of a code @xmath30 is given exactly by @xmath376 .",
    "that is , under a @xmath7-discrepancy - correction decoder , any discrepancy of magnitude @xmath377 can be detected if and only if @xmath378 .",
    "let @xmath379 .",
    "suppose that @xmath64 is transmitted and @xmath96 is received , where @xmath380 .",
    "we will show that @xmath381 , for all @xmath382 .",
    "suppose , by way of contradiction , that @xmath98 , for some @xmath382 , @xmath383 .",
    "then @xmath384 , which is a contradiction .",
    "conversely , assume that @xmath385 , i.e. , @xmath386 .",
    "we will show that an undetected error may occur . since @xmath386 , there exist @xmath95 such that @xmath387 .",
    "this implies that there exists some @xmath96 such that @xmath98 and @xmath388 . by assumption ,",
    "@xmath30 is @xmath7-discrepancy - correcting , so @xmath389 .",
    "thus , if @xmath27 is transmitted and @xmath65 is received , an undetected error will occur , even though @xmath390 .",
    "the result above has also been obtained in @xcite , although with a different notation ( in particular , treating @xmath391 as a `` distance '' function ) .",
    "below , we characterize the detection capability of a code in terms of the @xmath108-distance .    for any code @xmath30 , we have @xmath392 .    for any @xmath107 ,",
    "let @xmath96 be a solution to the minimization in ( [ eq : function - exact - detection ] ) , i.e. , @xmath65 is such that @xmath98 and @xmath393 .",
    "then @xmath394 , which implies that @xmath395 .",
    "suppose that @xmath90 is normal .",
    "for every code @xmath23 , we have @xmath396 .",
    "we just need to show that @xmath397 .",
    "take any @xmath107 . since @xmath90 is normal",
    ", there exists some @xmath96 such that @xmath398 and @xmath399 .",
    "thus , @xmath400 .",
    "first , we recall the following useful result shown in ( * ? ? ? * proposition 2 ) . let @xmath401 . then @xmath402    using ( [ eq : rank - difference - bound ] ) and ( [ eq : bound - rank - product ] )",
    ", we have @xmath403    we will now show that this lower bound is achievable",
    ". our approach will be to construct @xmath6 as @xmath404 , where @xmath405 and @xmath406 are both full - rank matrices .",
    "then ( [ eq : bound - rank - product ] ) guarantees that @xmath407 .",
    "the matrix @xmath408 will be constructed similarly : @xmath409 , where @xmath410 and @xmath411 are both full - rank .",
    "let @xmath412 , @xmath413 , and @xmath414 .",
    "let @xmath415 be such that @xmath416 , let @xmath417 be such that @xmath418 and let @xmath419 be such that @xmath420 .",
    "then , let @xmath421 and @xmath422 be such that @xmath423    now , choose any @xmath424 and @xmath425 that have full row rank , where @xmath426^+$ ] and @xmath427^+$ ] .",
    "for instance , we may pick @xmath428 and @xmath429 .",
    "finally , let @xmath430 where , in both cases , the upper identity matrix is @xmath431 .",
    "we have @xmath432^+ .",
    "\\nonumber\\end{aligned}\\ ] ]",
    "the authors would like to thank the anonymous reviewers for their helpful comments .",
    "s.  jaggi , m.  langberg , s.  katti , t.  ho , d.  katabi , m.  mdard , and m.  effros , `` resilient network coding in the presence of byzantine adversaries , '' _ ieee trans .",
    "inf . theory _ ,",
    "54 , no .  6 , pp . 25962603 , jun .",
    "2008 .",
    "s.  yang , c.  k. ngai , and r.  w. yeung , `` construction of linear network codes that achieve a refined singleton bound , '' in _ proc .",
    "information theory _ , nice , france , jun .",
    "2429 , 2007 , pp .",
    "15761580 .",
    "danilo silva ( s06 ) received the b.sc .",
    "degree from the federal university of pernambuco , recife , brazil , in 2002 , the m.sc .",
    "degree from the pontifical catholic university of rio de janeiro ( puc - rio ) , rio de janeiro , brazil , in 2005 , and the ph.d .",
    "degree from the university of toronto , toronto , canada , in 2009 , all in electrical engineering .",
    "frank r. kschischang ( s83m91sm00f06 ) received the b.a.sc .",
    "degree ( with honors ) from the university of british columbia , vancouver , bc , canada , in 1985 and the m.a.sc . and ph.d .",
    "degrees from the university of toronto , toronto , on , canada , in 1988 and 1991 , respectively , all in electrical engineering .",
    "he is a professor of electrical and computer engineering and canada research chair in communication algorithms at the university of toronto , where he has been a faculty member since 1991 . during 19971998 , he was a visiting scientist at the massachusetts institute of technology , cambridge , and in 2005 he was a visiting professor at the eth , zrich , switzerland .",
    "his research interests are focused on the area of channel coding techniques .",
    "kschischang was the recipient of the ontario premier s research excellence award . from 1997 to 2000 , he served as an associate editor for coding theory for the ieee transactions on information theory .",
    "he also served as technical program co - chair for the 2004 ieee international symposium on information theory ( isit ) , chicago , il , and as general co - chair for isit 2008 , toronto ."
  ],
  "abstract_text": [
    "<S> the problem of error correction in both coherent and noncoherent network coding is considered under an adversarial model . for coherent network coding , where knowledge of the network topology and network code is assumed at the source and destination nodes , the error correction capability of an ( outer ) code </S>",
    "<S> is succinctly described by the rank metric ; as a consequence , it is shown that universal network error correcting codes achieving the singleton bound can be easily constructed and efficiently decoded . </S>",
    "<S> for noncoherent network coding , where knowledge of the network topology and network code is not assumed , the error correction capability of a ( subspace ) code is given exactly by a new metric , called the _ injection metric _ , which is closely related to , but different than , the subspace metric of ktter and kschischang . </S>",
    "<S> in particular , in the case of a non - constant - dimension code , the decoder associated with the injection metric is shown to correct more errors then a minimum - subspace - distance decoder . </S>",
    "<S> all of these results are based on a general approach to adversarial error correction , which could be useful for other adversarial channels beyond network coding .    </S>",
    "<S> adversarial channels , error correction , injection distance , network coding , rank distance , subspace codes . </S>"
  ]
}