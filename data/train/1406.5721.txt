{
  "article_text": [
    "in adaptive filtering  @xcite , there is a class of algorithms specifically designed for sparse system identification , where the unknown system only has a few large coefficients while the remaining ones have a very small amplitude so that they can be ignored without significant effect on the overall performance of the system .",
    "a good example of them is the zero - attracting least mean square ( za - lms ) algorithm proposed in  @xcite .",
    "this algorithm can achieve a higher convergence speed , and meanwhile , reduce the steady state excess mean square error ( mse ) .",
    "compared to the classic lms algorithm  @xcite , the za - lms algorithm introduces an @xmath0 norm in its cost function , which modifies the weight vector update equation with a zero attractor term .",
    "recently , the hypercomplex concepts have been introduced to solve problems related to three or four - dimensional signals  @xcite , such as vector - sensor array signal processing  @xcite , color image processing  @xcite and wind profile prediction  @xcite .",
    "as quaternion - valued algorithms can be regarded as an extension of the complex - valued ones , the adaptive filtering algorithms in complex domain could be extended to the quaternion domain as well , such as the quaternion - valued lms ( qlms ) algorithm in  @xcite .    in this paper",
    ", we propose a novel quaternion - valued adaptive algorithm with a sparsity constraint , which is called zero - attracting qlms ( za - qlms ) algorithm .",
    "the additional constraint is formulated based on the @xmath0 norm .",
    "both the qlms and za - qlms algorithms can identify an unknown sparse system effectively .",
    "however , a better performance in terms of convergence speed is achieved by the latter one .",
    "this paper is organized as follows .",
    "a review of basic operations in the quaternion domain is provided in section [ sec : quaternion_basic ] to facilitate the following derivation of the za - qlms algorithm .",
    "the proposed za - qlms algorithm is derived in section [ sec : za - qlms ] .",
    "simulation results are given in section [ sec : simulations ] , and conclusions are drawn in section [ sec : conclusions ] .",
    "quaternion is a non - commutative extension of the complex number , and normally a quaternion consists of one real part and three imaginary parts , denoted by subscripts @xmath1 , @xmath2 , @xmath3 and @xmath4 , respectively .    for a quaternion number @xmath5",
    ", it can be described as @xmath6 where @xmath7 , @xmath8 , @xmath9 , and @xmath10 are real - valued  @xcite . for a quaternion , when its real part is zero , it becomes a pure quaternion . in this paper",
    ", we consider the conjugate operator of @xmath5 as @xmath11 .",
    "the three imaginary units @xmath12 , @xmath13 , and @xmath14 satisfy @xmath15    as a quaternion has the noncommutativity property , in multiplication , the exchange of any two elements in their order will give a different result .",
    "for example , we have @xmath16 rather than @xmath17 .      to derive the quaternion - valued adaptive algorithm , the starting point is the general operation of differentiation with respect to a quaternion - valued vector .    at first , we need to give the definition of differentiation with respect to a quaternion @xmath5 and its conjugate @xmath18 .",
    "assume that @xmath19 is a function of the quaternion variable @xmath5 , which is expressed as @xmath20 where @xmath19 is in general quaternion - valued .",
    "the definition of @xmath21 can be expressed as  @xcite @xmath22    the derivative of @xmath19 with respect to @xmath18 can be defined in a similar way @xmath23    with this definition , we can easily obtain @xmath24    some product rules can be obtained from above formulations , such as the differentiation of quaternion - valued functions to real variables .",
    "suppose @xmath19 and @xmath25 are two quaternion - valued functions of the quaternion variable @xmath5 , and @xmath26 is the real variable .",
    "then we can have the following result @xmath27    when the quaternion variable @xmath5 is replaced by a quaternion - valued vector @xmath28 , given by @xmath29^{t}\\ ] ] where @xmath30 , @xmath31 , the differentiation of the function @xmath32 with respect to the vector @xmath28 can be derived using a combination of ( [ eq : general_definition ] ) straightforwardly in the following @xmath33 \\label{eq : vector_definition}\\end{aligned}\\ ] ] similarly , we define @xmath34 as @xmath35 \\label{eq : conj_vector_definition}\\end{aligned}\\ ] ] obviously , when @xmath36 , ( [ eq : vector_definition ] ) and ( [ eq : conj_vector_definition ] ) are reduced to ( [ eq : general_definition ] ) and ( [ eq : conj_general_definition ] ) , respectively .",
    "to improve the performance of the lms algorithm for sparse system identification , the za - qlms algorithm is derived in this section . to achieve this , similar to @xcite , in the cost function , we add an @xmath0 norm penalty term for the quaternion - valued weight vector @xmath37 $ ] .    for a standard adaptive filter , the output @xmath38 $ ] and error @xmath39",
    "$ ] can be expressed as @xmath40&=&{\\textbf{w}^{t}[n]}{\\textbf{x}[n]}\\\\ e[n]&=&d[n]-{\\textbf{w}^{t}[n]}{\\textbf{x}[n]},\\end{aligned}\\ ] ] where @xmath37 $ ] is the adaptive weight vector with a length of @xmath41 , @xmath42 $ ] is the reference signal , @xmath43=[x[n-1 ] , \\cdots , x[n - l]]^{t}$ ] is the input sample vector , and @xmath44 denotes the transpose operation . moreover ,",
    "the conjugate form @xmath45 $ ] of the error signal @xmath39 $ ] is given by @xmath46=d^{*}[n]-{\\textbf{x}^{h}[n]}{\\textbf{w}^{*}[n]},\\ ] ]    our proposed cost function with a zero attractor term is given by @xmath47=e[n]e^{*}[n]+\\gamma{\\|\\textbf{w}[n]\\|}_1\\;,\\ ] ] where @xmath48 is a small constant .",
    "the gradient of the above cost function with respect to @xmath49 $ ] and @xmath37 $ ] can be respectively expressed as @xmath50=\\frac{\\partial { j_0[n]}}{\\partial \\textbf{w}^ { * } } \\label{eq : conj_gradient_cost_function}\\ ] ] and @xmath51=\\frac{\\partial { j_0[n]}}{\\partial \\textbf{w } } \\label{eq : gradient_cost_function}\\ ] ]    from  @xcite , we know that the conjugate gradient gives the maximum steepness direction for the optimization surface . therefore , the conjugate gradient @xmath52 $ ] will be used to derive the update of the coefficient weight vector .",
    "expanding the cost function , we obtain @xmath53&=&e[n]e^{*}[n]+\\gamma{\\|\\textbf{w}[n]\\|}_1\\nonumber\\\\ & = & d[n]d^{*}[n]-d[n]{\\textbf{x}^{h}[n]}{\\textbf{w}^{*}[n]}-{\\textbf{w}^{t}[n ] } { \\textbf{x}[n]}d^{*}[n]\\nonumber\\\\ & ~&+{\\textbf{w}^{t}[n ] } { \\textbf{x}[n]}{\\textbf{x}^{h}[n]}{\\textbf{w}^{*}[n]}+\\gamma{\\|\\textbf{w}[n]\\|}_1\\;. \\label{eq : extended_cost_function}\\end{aligned}\\ ] ] furthermore , @xmath54}}{\\partial \\textbf{w}^{*}}&=&\\frac{\\partial { ( e[n]e^{*}[n]+\\gamma{\\|\\textbf{w}[n]\\|}_1)}}{\\partial \\textbf{w}^{*}}\\nonumber\\\\ & = & \\frac{\\partial}{\\partial \\textbf{w}^{*}}(d[n]d^{*}[n]-d[n]{\\textbf{x}^{h}[n]}{\\textbf{w}^{*}[n]}\\nonumber\\\\ & & -{\\textbf{w}^{t}[n ] } { \\textbf{x}[n]}d^{*}[n]+{\\textbf{w}^{t}[n ] } { \\textbf{x}[n]}{\\textbf{x}^{h}[n]}{\\textbf{w}^{*}[n]})\\nonumber\\\\ & & + \\frac{\\partial ( { \\gamma{\\|\\textbf{w}[n]\\|}_1})}{\\partial \\textbf{w}^{*}}\\;. \\label{eq : extended_gradient_cost_function}\\end{aligned}\\ ] ]    details of the derivation process for the gradient are shown in the following @xmath55d^{*}[n])}{\\partial { \\textbf{w}^{*}[n ] } } = 0 \\label{eq : part_1}\\ ] ] @xmath55{\\textbf{x}^{h}[n]}{\\textbf{w}^{*}[n]})}{\\partial { \\textbf{w}^{*}[n ] } } = d[n]\\textbf{x}^{*}[n ] \\label{eq : part_2}\\ ] ] @xmath56}{\\textbf{x}[n]}d^{*}[n])}{\\partial { \\textbf{w}^{*}[n ] } } = -\\frac{1}{2}d[n]\\textbf{x}^{*}[n ] \\label{eq : part_3}\\ ] ] @xmath57 } { \\textbf{x}[n]}{\\textbf{x}^{h}[n]}{\\textbf{w}^{*}[n]})}{\\partial { \\textbf{w}^{*}[n]}}=\\frac{1}{2}{\\textbf{w}^{t}[n]}{\\textbf{x}[n]}{\\textbf{x}^{*}[n]}. \\label{eq : part_4}\\ ] ] moreover , the last part of the gradient of cost function is given by @xmath58\\|}_1})}{\\partial \\textbf{w}^ { * } } = \\frac{1}{4 } \\gamma\\cdot{sgn(\\textbf{w}[n])}\\ ; , \\label{eq : part_5}\\ ] ] where the symbol @xmath59 is a component - wise sign function that is defined as  @xcite @xmath60    combining the above results , the final gradient can be obtained as follows @xmath50=-\\frac{1}{2}e[n]\\textbf{x}^{*}[n]+\\frac{1}{4}\\gamma\\cdot{sgn(\\textbf{w}[n])}\\;.\\ ] ]    with the general update equation for the weight vector @xmath61 = \\textbf{w}[n]-\\mu \\nabla_{\\textbf{w}^{*}}j_0[n],\\ ] ] where @xmath62 is the step size , we arrive at the following update equation for the proposed za - qlms algorithm @xmath61 = \\textbf{w}[n]+\\mu(e[n]\\textbf{x}^{*}[n])-\\rho\\cdot{sgn(\\textbf{w}[n])}\\ ; , \\label{eq : update_weight_vector}\\ ] ] where @xmath63 . the last term represents the zero attractor , which enforces the near - zero coefficients to zero and therefore accelerates the convergence process when majority of the system coefficients are nearly zero in a sparse system .    note",
    "that equation will be reduced to the normal qlms algorithm without the zero attractor term , given by  @xcite @xmath61=\\textbf{w}[n]+\\mu(e[n]{\\textbf{x}}^{*}[n])\\;.\\ ] ]",
    "in this part , simulations are performed for sparse system identification using the proposed algorithm in comparison with the qlms algorithm .",
    "two different sparse systems are considered corresponding to scenario one and scenario two in the following .",
    "the input signal to the adaptive filter is colored and generated by passing a quaternion - valued white gaussian signal through a randomly generated filter .",
    "the noise part is quaternion - valued white gaussian and added to the output of the unknown sparse system , with a 30db signal to noise ratio ( snr ) for both scenarios .",
    "for the first scenario , the parameters are : the step size @xmath62 is @xmath64 ; the unknown sparse fir filter length @xmath41 is @xmath65 , with @xmath66 non - zero coefficients at the 2nd , 8th , 16th and 31st taps , and its magnitude of the impulse response is shown in fig .",
    "[ fig : w ] ; the coefficient of the zero attractor @xmath67 is @xmath68 .",
    "the learning curve obtained by averaging @xmath69 runs of the corresponding algorithm is given in fig .",
    "[ fig : learning_curve_1 ] , where we can see that the za - qlms algorithm has achieved a faster convergence speed than the qlms algorithm when they both reach a similar steady state .    ]    ]      for this case , length of the unknown fir filter is reduced to @xmath70 , still with @xmath66 active taps .",
    "the parameters are : step size @xmath62 is @xmath71 and the value of @xmath67 is @xmath71 .",
    "the results are shown in fig .",
    "[ fig : learning_curve_2 ] .",
    "again we see that the za - qlms algorithm has a faster convergence speed and has even converged to a lower steady state error in this specific scenario .    ]",
    "in this paper , a quaternion - valued adaptive algorithm has been proposed for more efficient identification of unknown sparse systems .",
    "it is derived by introducing an @xmath0 penalty term in the original cost function and the resultant zero - attracting quaternion - valued lms algorithm can achieve a faster convergence rate by incorporating the sparsity information of the system into the update process .",
    "simulation results have been provided to show the effectiveness of the new algorithm .",
    "yilun chen , yuantao gu , and alfred  o hero , `` sparse for system identification , '' in _ acoustics , speech and signal processing , 2009 .",
    "icassp 2009 .",
    "ieee international conference on_. ieee , 2009 , pp .",
    "31253128 .",
    "zhang , w.  liu , y.g .",
    "xu , and z.w .",
    "liu , `` quaternion - based worst case constrained beamformer based on electromagnetic vectoe - sensor arrays , '' in _ proc .",
    "ieee international conference on acoustics , speech , and signal processing _ , vancouver , canada , may 2013 , pp .",
    "41496153 .    x.  r. zhang , w.  liu , y.  g. xu , and z.  w. liu , `` quaternion - valued robust adaptive beamformer for electromagnetic vector - sensor arrays with worst - case constraint , '' , vol .",
    "104 , pp . 274283 ,",
    "november 2014 .",
    "m.  b. hawes and w.  liu , `` a quaternion - valued reweighted minimisation approach to sparse vector sensor array design , '' in _ proc . of the international conference on digital signal processing _",
    ", hong kong , august 2014 .",
    "m.  d. jiang , w.  liu , y.  li , and x.  r. zhang , `` frequency - domain quaternion - valued adaptive filtering and its application to wind profile prediction , '' in _ proc .",
    "of the ieee tencon conference _ , xian , china , october 2013 .",
    "m.  d. jiang , w.  liu , and y.  li , `` a general quaternion - valued gradient operator and its applications to computational fluid dynamics and adaptive beamforming , '' in _ proc .",
    "of the international conference on digital signal processing _",
    ", hong kong , august 2014 ."
  ],
  "abstract_text": [
    "<S> recently , quaternion - valued signal processing has received more and more attention . in this paper , </S>",
    "<S> the quaternion - valued sparse system identification problem is studied for the first time and a zero - attracting quaternion - valued least mean square ( lms ) algorithm is derived by considering the @xmath0 norm of the quaternion - valued adaptive weight vector . by incorporating the sparsity information of the system into the update process , a faster convergence speed is achieved , as verified by simulation results .    * _ keywords : _ * quaternion ; sparsity ; system identification ; adaptive filtering ; lms algorithm . </S>"
  ]
}