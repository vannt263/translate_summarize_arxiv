{
  "article_text": [
    "human activities can often be described as a sequence of basic motions .",
    "for instance , common activities like brushing hair or waving a hand can be described as a sequence of successive raising and lowering of the hand . over the past years , researchers have studied multiple strategies to effectively represent motion dynamics and classify activities in videos @xcite .",
    "however , the existing methods suffer from the inability to compactly encode long - term motion dependencies . in this work",
    ", we propose to learn a representation that can describe the sequence of motions by learning to predict it .",
    "in other words , we are interested in learning a representation that , given a pair of video frames , can predict the sequence of basic motions ( see in figure [ fig : pull ] ) .",
    "we believe that if the learned representation has encoded enough information to predict the motion , it is discriminative enough to classify activities in videos .",
    "hence , our final goal is to use our learned representation to classify activities in videos .        to classify activities",
    ", we argue that a video representation needs to capture not only the semantics , but also the motion dependencies in a long temporal sequence .",
    "since robust representations exist to extract semantic information @xcite , we focus our effort on learning a representation that encodes the sequence of basic motions in consecutive frames .",
    "we define basic motions as atomic 3d flows .",
    "the atomic 3d flows are computed by quantizing the estimated dense 3d flows in space and time using rgb - d modality . given a pair of images from a video clip , our framework learns a representation that can predict the sequence of atomic 3d flows .",
    "our learning framework is unsupervised , _",
    "i.e. _ , it does not require human - labeled data .",
    "not relying on labels has the following benefits .",
    "it is not clear how many labels are needed to understand activities in videos . for a single image ,",
    "millions of labels have been used to surpass human - level accuracy in extracting semantic information @xcite .",
    "consequently , we would expect that videos will require several orders of magnitude more labels to learn a representation in a supervised setting",
    ". it will be unrealistic to collect all these labels .",
    "recently , a stream of unsupervised methods have been proposed to learn temporal structures from videos .",
    "these methods are formulated with various objectives - supervision . some focus on constructing future frames @xcite , or enforcing the learned representations to be temporally smooth @xcite , while others make use of the sequential order of frames sampled from a video @xcite .",
    "although they show promising results , most of the learned representations still focus heavily on either capturing semantic features @xcite , or are not discriminative enough for classifying activities as the output supervision is too large and coarse ( e.g. , frame reconstruction ) .",
    "when learning a representation that predicts motions , the following properties are needed : the output supervision needs to be of i ) low dimensionality , ii ) easy to parameterize , and iii ) discriminative enough for other tasks .",
    "we address the first two properties by reducing the dimensionality of the flows through clustering .",
    "then , we address the third property by augmenting the rgb videos with depth modality to reason on 3d motions . by inferring 3d motion as opposed to view - specific 2d optical flow ,",
    "our model is able to learn an intermediate representation that captures less view - specific spatial - temporal interactions .",
    "compared to 2d dense trajectories @xcite , our 3d motions are of much lower dimensionality .",
    "moreover , we focus on inferring the sequence of basic motions that describes an activity as opposed to tracking keypoints over space and time .",
    "we claim that our proposed description of the motion enables our learning framework to predict longer motion dependencies since the complexity of the output space is reduced . in section [ subsec : supervise ] , we show quantitatively that our proposed method outperforms previous methods .",
    "the contributions of our work are as follows :    * we propose to use a recurrent neural network based encoder - decoder framework to effectively learn a representation that predicts the sequence of basic motions . whereas existing unsupervised methods describe motion as either a single optical flow @xcite or 2d dense trajectories @xcite , we propose to describe it as a sequence of atomic 3d flows over a long period of time ( section [ sec : method ] ) . *",
    "the proposed learning framework is generic to any input modality .",
    "we study the performance of our unsupervised task - predicting the sequence of basic motions - using various input modalities : rgb @xmath0 motion , depth @xmath0 motion , and rgb - d @xmath0 motion ( section [ subsec : unsupervise ] ) . *",
    "finally , we show the effectiveness of our learned representations on activity recognition tasks across multiple modalities and datasets ( section [ subsec : supervise ] ) .",
    "we first present previous works on unsupervised representation learning for videos .",
    "then , we give a brief overview of existing methods that classify activities in multi - modal videos .",
    "* unsupervised representation learning .",
    "* in the rgb domain , unsupervised learning of visual representations has shown usefulness for various supervised tasks such as pedestrian detection and object detection @xcite . to exploit temporal structures ,",
    "researchers have started focusing on learning visual representations using rgb videos .",
    "early works such as @xcite focused on inclusion of constraints via video to autoencoder framework .",
    "the most common constraint is enforcing learned representations to be temporally smooth @xcite .",
    "more recently , a stream of reconstruction - based models has been proposed .",
    "ranzato et al .",
    "@xcite proposed a generative model that uses a recurrent neural network to predict the next frame or interpolate between frames .",
    "this was extended by srivastava et al .",
    "@xcite where they utilized a lstm encoder - decoder framework to reconstruct current frame or predict future frames .",
    "another line of work @xcite uses video data to mine patches which belong to the same object to learn representations useful for distinguishing objects .",
    "misra et al .",
    "@xcite presented an approach to learn visual representation with an unsupervised sequential verification task , and showed performance gain for supervised tasks like activity recognition and pose estimation .",
    "one common problem for the learned representations is that they capture mostly semantic features that we can get from imagenet or short - range activities .",
    "* rgb - d / depth - based activity recognition .",
    "* techniques for activity recognition in this domain use appearance and motion information in order to reason about non - rigid human deformations activities .",
    "typical features like hon4d @xcite , hopc @xcite , and dcsf @xcite capture spatio - temporal features in a temporal grid - like structure .",
    "skeleton - based approaches like @xcite move beyond such sparse grid - like pooling and focuses on proposing good skeletal representations .",
    "another stream of work uses probabilistic graphical models such as a hidden markov model ( hmm ) @xcite , a conditional random field ( crf ) @xcite or a latent dialect allocation ( lda ) @xcite to capture spatial - temporal structures and learn the relations in activities from rgb - d videos",
    ". however , most of these works require a lot of feature engineering and can only model short - range action relations .",
    "state - of - the - art methods @xcite for rgb - d / depth - based activity recognition report human level performance on well - established datasets like msrdailyactivity3d @xcite and cad-120 @xcite .",
    "however , these datasets were often constructed under various constraints like single - view , single background , or with very few subjects . on the other hand , @xcite shows that there is a big performance gap between human and existing methods on a more challenging dataset @xcite that contains many more subjects , viewpoints and backgrounds",
    ".    * rgb - based activity recognition . *",
    "the past few years have seen great progress on activity recognition from short clips @xcite .",
    "these works can be roughly categorized into two types .",
    "the first type focuses on handcrafted local features and bag of visual words ( bovws ) representation .",
    "the most successful example is to extract improved trajectory features @xcite and employ fisher vector representation @xcite .",
    "the second type utilizes deep convolutional networks ( convnets ) to learn video representation from raw data ( e.g. rgb images or optical flow fields ) and train recognition system in an end - to - end manner .",
    "the most competitive deep learning model is the deep two - stream convnets @xcite that combines both semantic features extracted by convnets and traditional optical flow that captures motion .",
    "however , unlike image classification , the benefit of using deep neural networks over traditional hand crafted features is not very evident , since supervised training of deep networks requires a lot of data , whilst the current rgb activity recognition datasets are still too small .",
    "the goal of our method is to learn a representation that predicts the sequence of basic motions , which are defined as atomic 3d flows ( described in details in section [ atomic ] ) .",
    "the problem is formulated as follows : given a pair of images @xmath1 , our objective is to predict the sequence of atomic 3d flows over @xmath2 temporal steps : @xmath3 , where @xmath4 is the atomic 3d flow at time @xmath5 ( see figure [ fig : arch ] ) . note that @xmath6 and @xmath7 , where @xmath8 is the number of input channels , and @xmath9 are the height and width of the video frames respectively . in section [ sec : exp ] , we experiment with inputs from three different modalities : rgb only ( @xmath10 ) , depth only ( @xmath11 ) , and rgb - d ( @xmath12 ) .    the learned representation  the red cuboid in figure [ fig : arch ]  can then be used as a motion feature for activity recognition ( as described in section [ sec : activity ] ) . in the remaining of this section , we first present details on how we describe basic motions .",
    "then , we present the learning framework .      to effectively predict the sequence of basic motions , we need to describe the motion as a low - dimensional signal such that it is easy to parameterize and is discriminative enough for other tasks such as activity recognition .",
    "inspired by the vector quantization algorithms for image compression @xcite , we propose to address the first goal by quantizing the estimated 3d flows in space and time , referred to as atomic 3d flows .",
    "we address the discriminative property by inferring more than a single 3d flow but a long - term sequence of 3d flows .",
    "our learned representation has the capacity to model longer term motion dependencies .",
    "+ * reasoning in 3d .",
    "* whereas previous unsupervised learning methods model motion in the 2d image - plane @xcite , we propose to predict motion in 3d .",
    "we augment the rgb videos with depth modality and estimate the 3d flows @xcite . by inferring 3d motion as opposed to 2d motion ,",
    "our model is more robust to ambiguities that occur when reasoning in the 2d space . + * reasoning with sequences .",
    "* previous unsupervised learning methods have modeled motion as either a single optical flow @xcite or a dense trajectories over multiple frames @xcite .",
    "the first approach has the advantage of representing motion with a single fixed size image .",
    "however , it only encodes a short range motion .",
    "the second approach addresses the long - term motion dependencies but is difficult to efficiently model each keypoint .",
    "we propose a third alternative : model the motion as a sequence of flows .",
    "motivated by the recent success of rnn to predict sequence of images @xcite , we propose to learn to predict the sequence of flows over a long period of time . to ease the prediction of the sequence",
    ", we can further transform the flow into a lower dimensionality signal ( referred to as atomic flows ) . + * reasoning with atomic flows .",
    "* flow prediction can be posed as a regression problem where the loss is squared euclidean distance between the ground truth flow and predicted flow .",
    "unfortunately , the squared euclidean distance in pixel space is not a good metric , since it is not stable to small image deformations , and the output space tends to smoothen results to the mean @xcite .",
    "instead , we formulate the flow prediction task as a classification task using @xmath13 , where @xmath14 maps each raw @xmath15 3d flow patch from @xmath16 to a probability distribution over @xmath17 quantized classes ( i.e. atomic flows ) . more specifically , we divide @xmath18 into a @xmath19 grid , where @xmath20 , @xmath21 . after mapping each patch to a probability distribution",
    ", we get a probability distribution @xmath22 over all patches .",
    "we experiment with uniform quantization and k - means clustering for flow quantization .",
    "the former shows better performance .",
    "our uniform quantization is performed as follows : we construct a codebook @xmath23 by quantizing bounded 3d flow into equal - sized bins , where we have @xmath24{k}$ ] distinct classes along each axes . for each @xmath15 3d flow patch , we compute its mean and retrieve its @xmath25 nearest neighbors ( each represents one flow class ) from the codebook .",
    "the @xmath25 flow classes are assigned with normalized weights proportional to their distances to the mean , whilst other classes are assigned a weight of 0 .",
    "after mapping , each flow patch is represented by a probability distribution @xmath26 over all @xmath17 flow classes .",
    "empirically , we find having the number of nearest neighbors @xmath27 yields better performance",
    ". to reconstruct the predicted flow @xmath28 from predicted distribution @xmath29 , we first calculate the quantized flow with simple matrix multiplication @xmath30 , then upsample the image with nearest neighbor interpolation .      to learn a representation that encodes the long - term motion dependencies in videos",
    ", we cast the learning framework as a sequence - to - sequence problem .",
    "we propose to use a recurrent neural network ( rnn ) based encoder - decoder framework to effectively learn these motion dependencies . given two frames ,",
    "our proposed rnn predicts the sequence of atomic 3d flows .",
    "figure [ fig : arch ] presents an overview of our learning framework , which can be divided into an encoding and decoding steps . during encoding , a downsampling network ( referred to as  conv \" )",
    "extracts a low - dimensionality feature from the input frames .",
    "then , the ltsm runs through the sequence of extracted features to learn a temporal representation .",
    "this representation is then decoded with the upsampling network (  deconv \" ) to output the atomic 3d flows .",
    "the lstm encoder - decoder framework @xcite provides a general framework for sequence - to - sequence learning problems , and its ability to capture long - term temporal dependencies makes it a natural choice for this application .",
    "however , vanilla lstms do not take spatial correlations into consideration .",
    "in fact , putting them between the upsampling and downsampling networks leads to much slower convergence speed and significantly worse performance , compared to a single - step flow prediction without lstms . to preserve the spatial information in intermediate representations , we use the convolutional lstm unit @xcite that has convolutional structures in both the input - to - state and state - to - state transitions .    here",
    "are more details on the downsampling and upsampling networks : + * downsampling network (  conv \" ) . *",
    "we train a convolutional neural network ( cnn ) to extract high - level features from each input frame .",
    "the architecture of our network is similar to the standard vgg-16 network @xcite with the following modifications .",
    "our network is fully convolutional , with the first two fully connected layers converted to convolution with the same number of parameters to preserve spatial information .",
    "the last softmax layer is replaced by a convolutional layer with a filter of size @xmath31 , resulting in a downsampled output of shape @xmath32 .",
    "a batch normalization layer @xcite is added to the output of every convolutional layer .",
    "in addition , the number of input channels in the first convolutional layer is adapted according to the modality . +",
    "* upsampling network (  deconv \" ) .",
    "* we use an upsampling cnn with fractionally - strided convolution @xcite to perform spatial upsampling and atomic 3d flow prediction . a stack of five fractionally - strided convolutions upsamples each input to the predicted distribution @xmath33 , where @xmath34 represents the unscaled log probabilities over the @xmath35 flow patch .",
    "finally , we define a loss function that is stable and easy to optimize for motion prediction .",
    "as described in section [ atomic ] , we define the cross - entropy loss between the ground truth distribution @xmath36 over the atomic 3d flow space @xmath37 and the predicted distribution @xmath29 :    @xmath38    where @xmath39 is a weighting vector for rebalancing the loss based on the frequency of each atomic flow vectors .",
    "the distribution of atomic 3d flows is strongly biased towards classes with small flow magnitude , as there is little to no motion in the background . without accounting for this ,",
    "the loss function is dominated by classes with very small flow magnitudes , causing the model to predict only class 0 which represents no motion . following the approach in @xcite",
    ", we define the class weight @xmath40 as follow :    @xmath41    where @xmath42 is the empirical distribution of the codewords in codebook @xmath37 , and @xmath43 is the smoothing weight .",
    "the final goal of our learned representation is to classify activities in videos .",
    "we use our encoder architecture from unsupervised learning for activity recognition .",
    "a final classification layer is added on top of the encoder output to classify activities .    to study the effectiveness of our learned representation , we consider the following three scenarios : + ( i ) initialize the weight of our architecture randomly and learn them with the labels available for the supervision task ( referred to as architecture only in table [ table : ablation ] ) ; + ( ii ) initialize the weights with our learned representation and fine - tune on activity recognition datasets ; + ( iii ) keep the pre - trained encoder fixed and only fine - tune the last classification layer .",
    "note that we do nt combine our learned representation with any pre - trained semantic representation ( such as the fc7 representation learned on imagenet @xcite ) .",
    "we argue that for our model to learn to predict the basic motions , it needs to understand the semantic content .",
    "we follow the same data sampling strategy described in @xcite . during training , a mini - batch of 8 samples is constructed by sampling from 8 training videos , from each of which a pair of consecutive frames is randomly selected . for scenario ( i ) and ( iii ) , the learning rate is initially set to @xmath44 with a decay rate of @xmath45 every 2000 steps . for scenario ( ii ) , the initial learning rates of encoder and the final classification layer are set to @xmath46 and @xmath44 respectively , with the same decay rate . at test time , we uniformly sample 25 frames from each video and average the scores across the sampled frames to get the class score for the video .    our presented classification method is intentionally simple to show the strength of our learned representation . moreover , our method is computationally effective .",
    "it runs in real - time since it consists of a forward pass through our encoder . finally , our learned representation is compact ( @xmath47 ) enabling implementation on embedded devices .",
    ".quantitative results on activity recognition using the * ntu - rgb+d * dataset @xcite with the following input modalities : depth , and rgb .",
    "we report the mean ap in percentage on our ablation study as well as our complete model ( in bold ) . [ cols=\"^,^,^,^\",options=\"header \" , ]      * dataset .",
    "* we train and test our depth - based activity recognition model on two datasets : ntu - rgb+d and msrdailyactivity3d @xcite . for ntu - rgb+d ,",
    "we follow the cross - subject split as described in @xcite .",
    "the msrdailyactivity3d dataset contains 16 activities performed by 10 subjects .",
    "we follow the same leave - one - out training - testing split as in @xcite .",
    "we intentionally use this extra msrdailyactivity3d dataset that is different from the one we use for unsupervised training to show the effectiveness of our learned representation in new domains ( different viewpoints and activities ) . +",
    "* results on ntu .",
    "* table [ table : resultsntu ] shows classification accuracy on the ntu - rgb+d dataset and figure [ fig : confusion1 ] its confusion matrix .",
    "the first group of methods use depth maps as inputs , while the second and the third use skeleton features .",
    "methods in the third group are deep - learning based models .",
    "our proposed method outperforms the state - of - the - art supervised methods .",
    "we use our learned representation that predicts the next 8 frames without fine - tuning it on the classification task .",
    "interestingly , fine - tuning the weights of our encoder did not give a boost in performance .",
    "+ * ablation study . * in table [ table : ablation ] , we present more insights on our design choices .",
    "we first show that by using our encoder architecture without pre - training it to predict the motion ( referred to as `` our architecture only '' ) , the classification accuracy ( mean ap ) is the lowest .",
    "we then show that modeling 3d motion instead of 2d motion positively impacts the performance .",
    "finally , we report the results when shorter sequences ( 3-step prediction ) are encoded during our unsupervised training . increasing the sequence length to 8 time - steps increases the classification accuracy .",
    "the discrimination power of our representation is increased by encoding longer - term dependencies . for the sake of completeness",
    ", we also fine - tune our activity recognition model using rgb videos from the ntu rgb - d dataset .",
    "we notice that the results are comparable to depth - based activity recognition and follow the same trend for ablation studies ( i.e. predicting longer motion in 3d yields better performance ) . +",
    "* results on msr .",
    "* table [ table : resultsmsr ] presents classification accuracy on the msrdailyactivity3d dataset @xcite and figure [ fig : confusion2 ] its confusion matrix .",
    "methods in italic require skeleton detection , while the fourth one makes use of dense 3d trajectories .",
    "note that our unsupervised learning task  predicting the basic motions  has not been trained on these activities and viewpoints .",
    "nevertheless , we outperform previous work specially the method based on the 3d trajectories by a large margin ( + @xmath48 ) .",
    "our compact representation of the 3d motion is more discriminative than the existing representation for 3d trajectories @xcite .",
    "we have presented a general framework to learn long - term temporal representations for videos across different modalities . by using our proposed sequence of atomic 3d flows as supervision",
    ", we can train our model on a large number of unlabeled videos .",
    "we show that our learned representation is effective and discriminative enough for classifying actions as we achieve state - of - the - art activity recognition performance on two well - established rgb - d datasets . for future work",
    ", we aim to explore the performance of our method on rgb based datasets such as activitynet or other supervised tasks beyond activity recognition .",
    "we want to use other free labels from videos such as predicting 3d scenes interactions from rgb frames .",
    "we also want to come up with a compact representation for dense trajectory , which can effectively reduce background motions in many existing datasets ."
  ],
  "abstract_text": [
    "<S> we present an unsupervised representation learning approach that compactly encodes the motion dependencies in videos . given a pair of images from a video clip , our framework learns to predict the long - term 3d motions . </S>",
    "<S> to reduce the complexity of the learning framework , we propose to describe the motion as a sequence of atomic 3d flows computed with rgb - d modality . </S>",
    "<S> we use a recurrent neural network based encoder - decoder framework to predict these sequences of flows . </S>",
    "<S> we argue that in order for the decoder to reconstruct these sequences , the encoder must learn a robust video representation that captures long - term motion dependencies and spatial - temporal relations . </S>",
    "<S> we demonstrate the effectiveness of our learned temporal representations on activity classification across multiple modalities and datasets such as ntu rgb+d and msr daily activity 3d . </S>",
    "<S> our framework is generic to any input modality , _ </S>",
    "<S> i.e. _ , rgb , depth , and rgb - d videos . </S>"
  ]
}