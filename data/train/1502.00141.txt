{
  "article_text": [
    "the past decades , the amount of audio data in our sonic environment have considerably grown .",
    "recent research fields such as eco - acoustics @xcite start to massively record environmental sounds around the world in order to measure potential animal biodiversity modification over large temporal scales due to human activity or climate change @xcite .",
    "other research fields focus on human activities for context inference and surveillance @xcite .",
    "if research on automatic speech recognition ( asr ) @xcite and music information retrieval ( mir ) @xcite are now well established , research addressing automatic analysis of complex environmental acoustic scenes remains relatively young .",
    "in particular , those open research avenues suggest a large range of experimentation in order to 1 ) gain knowledge about the important characteristics of those acoustic scenes and how they can be modeled , 2 ) propose new algorithmic approaches to contribute to the above cited applications area : eco - acoustics and urban sensing .",
    "being relatively new research fields , only few data sets are available , though this number may grow as the interest of scientific and engineering communities for such tasks increases , see @xcite and @xcite for research effort in human environments related tasks .",
    "this paper focuses on building an evaluation framework for the task of detecting events of interest in acoustic scenes using simulated data .",
    "it builds upon the ieee aasp challenge on detection and classification of acoustic scenes and events ( dcase ) , which was organised by the centre for digital music of queen mary university of london and by the institute for research and coordination in acoustics / music ( ircam ) , under the auspices of the audio and acoustic signal processing ( aasp ) technical committee of the ieee signal processing society in 2013 @xcite .",
    "the dcase challenge is the second challenge dedicated to this task after the clear challenge @xcite .    during the formal definition of the event detection task of this challenge ,",
    "besides important questions about evaluation metrics , an interest rose about the potential benefit of considering simulated data to enlarge the scope of evaluation of the submitted systems .",
    "varying the power level of the background , the density of the events , their intra class diversity , all seemed important aspects to would be desirable to study though costly to tackle with recorded and annotated data . to this end",
    ", a simulation protocol was needed , which would be based on a morphological model of environmental acoustic scenes . as discussed in details in section",
    "[ sec : discussion ] , we acknowledge that the use of simulated data shall not be considered as sufficient for the final evaluation of engineering systems .",
    "that being said , the above described potential benefits are still sufficient to justify pursuing that avenue of research .",
    "the aim of the morphological model proposed in this paper is to generate acoustic scenes as a `` skeleton of events on a bed of texture '' @xcite .",
    "as the final use of the simulated scenes are to be analyzed by event recognizers trained on recorded data , one shall minimize both the discrepancy between the simulated scenes and recorded ones and its potential impact .",
    "thus , we do not consider approaches based on actual synthesis of sounds .",
    "it thus departs significantly from models used in research fields such as wave field synthesis @xcite , binaural or spatial scene synthesis @xcite , acoustic event synthesis @xcite and texture synthesis @xcite .",
    "the proposed model is based on several sequences of sound events issued from the same source , where each sound event is drawn from a collection of carefully chosen sound samples .",
    "the morphological aspects of the scene , _ i.e. _ which sound sample is played at what time and which level , are then modeled in an abstract manner , allowing us to control high level properties of the scene .",
    "the contribution of this paper is threefold : 1 ) propose a computational model for the generation of simulated data sets , 2 ) motivate important morphological aspects of the model based on perceptual considerations , and 3 ) consider this simulation paradigm to gain knowledge about the behavior of several event detection systems developed by different research teams worldwide initially submitted to the dcase challenge @xcite .    to this end",
    ", section  [ sec : soundcollection ] motivates some design choices , and details the structure of the so called `` sound collections '' , that is , the input data of the simulation process",
    ". section  [ sec : model ] presents the proposed model of acoustic scenes which underlines the simulation process .",
    "sections  [ sec : corpussimulation ] and [ sec : experiments ] present the evaluation framework for event detection systems using simulated acoustic scenes .",
    "then , the use of simulated data to evaluate detection algorithms is discussed in section  [ sec : discussion ] .",
    "as a simulation process could nt practically deal with each acoustic event that may occur in an acoustic scene separately , the proposed model adopts a `` source - driven '' approach by considering an acoustic scene as a sum of sound sources .",
    "this approach is consistent with the way humans perceive their sonic environment .",
    "studies addressing the auditory scenes analysis ( asa)@xcite problem , and more specifically the sound segregation process@xcite@xcite@xcite@xcite , show that humans make sense from their sonic world by isolating information related to individual sound sources . considering a bottom - up approach ,",
    "the segregation process relies on generic rules involving gestalt - like principles @xcite to group sounds with similar acoustic indicators ( common onset , spectral regularity and harmonicity ) , as well as similar perceptual attributes ( timbre , loudness , perceived location and pitch ) into perceptual entities called `` auditory streams '' .",
    "recently , several neurophysiological studies have shown evidence of the existence of auditory streams@xcite .",
    "besides asa studies which mostly consider pure tones or simple complex sounds @xcite , more recent studies adopting a psycho - linguistic approach to describe recorded sounds , have also demonstrated the existence of top - down source - driven grouping processes involved in sound perception .",
    "investigating the qualitative evaluation of urban acoustic scenes using categorization tasks and linguistic analysis , studies of dubois and colleagues @xcite@xcite have shown that listeners categorize sound environments on the basis of semantic features , that is the meaning attributed to the recalled sound sources .",
    "considering both the asa and the psycho - linguistic approach , it seems intuitive for the simulation process to consider separately the sound activity of each sound source of the scene . in practical terms , to materialize these sound activities , each sound source has to be related to a collection of sound recordings . but this approach introduces fundamental questions about the very nature of such a collection .",
    "it first questions the existence of a standardized taxonomy of sounds .",
    "such taxonomy must be a hierarchical classification system putting together sounds according to their shared characteristics .",
    "each group must be labeled in a way that a specific name may describe its corresponding class , an instance of it , but also at which level of the classification it fits .",
    "unfortunately , if such systems exist for plants , animals or colors , it is not the case for sounds@xcite .",
    "main reasons are :    * sound description and identification are highly subjective . in other words ,",
    "a same sound may be described quite differently according to the subject .",
    "this is due to the relative lack of basic lexicalized terms to describe acoustic phenomena @xcite * sound description and identification are highly context dependent , that is , sound source identification depends on the nature of the other co - occurring sound sources @xcite    even if there is no systematic way to build a sound collection , one may take into account some perceptual considerations to guarantee a certain level of ecological validity .",
    "those considerations are addressed in the next sections .",
    "event detection tasks evaluate if an algorithm is able to detect a specific set of sound classes . ideally , to prevent from low generalization capability",
    ", the training set of a given class shall be consistent , that is , class exemplars should be representative of the diversity of the sounds suggested by the class label that may occur in the real world . in our case ,",
    "the class exemplars are the recordings of a sound collection .",
    "some perceptual considerations can be taken into account to guide the collection building process .",
    "first , one may look at the way humans classify  / categorize sounds . as explained by @xcite ,",
    "`` categorization is a cognitive process that unites different entities of an equivalent status '' . among other categorization strategies ,",
    "several studies show that humans categorize sounds according to 1 ) the type of source ( agent , object , functions ) and  / or 2 ) the action  / movement causing the sounds @xcite .",
    "human categorization occurs at several levels .",
    "rosch @xcite proposed three levels of categorization for real - world objects namely superordinate , basic , and subordinate .",
    "the higher the level , the higher is the abstraction degree of the categories .",
    "considering sound perception , guyot et al .",
    "@xcite proposed a framework where listeners identified sound categories of abstract concepts at a supeordinate level ( noise generated be a mechanical excitation ) , action at the basic level ( grating , scratching , rubbing ) and source at the subordinate level ( dishes , pen sharpening , door ) . although houix et al .",
    "@xcite found some differences by showing that sounds seem `` to be categorized as sound sources first and only second as actions '' , it appears that source and action are adequate verbal descriptors for category .    one way to make",
    "a sound collection consistent is to consider low - level categories as the intra - category diversity decreases with the level . considering that",
    ", one may label a sound collection using a couple `` source - action '' ( _ passing - car _ ) , or at least one of the two , in order to minimize the expected diversity of its recordings .",
    "any name referring to higher category levels may lead to sound collections comprising a too large variety of objects .",
    "such definition of collection then raise two issues :    * building such collections would suppose the availability of a large number of recorded sounds to be representative of the diversity suggested by the collection label ; * adopting a data - centered approach , such collections may lead to a misinterpretation of the results of a detection task for someone who did not build them , as the nature of the entities suggested by the collection labels are ambiguous ( ex : a sound collection of _ traffic sounds _ vs. a sound collection of _ passing - car _ ) .",
    "considering the source - action couple is not sufficient .",
    "the experimenters must also choose generic labels for the couple .",
    "to do so , one may refer to the work of gaver @xcite who proposed a phenomenological taxonomy of everyday sounds , the work of niessen et al .",
    "@xcite who assessed the consensus of categories mentioned in 166 papers of different research domain using linguistic analysis , and recently , the work of salamon et al . @xcite who built a taxonomy of urban sounds based on the work of brown et al .",
    "@xcite .",
    "this section shows evidence that labeling a class using the source - action nomenclature helps us to reduce the expected intra - class diversity .",
    "however , it does not address the issue of inter - class diversity .",
    "indeed , a naive source - driven approach supposes to record in a source - wise way all the sound activities that may occur in an environment . considering dense environments such as cities or forest",
    ", this may raise important practical issues . to circumvent this problem",
    ", one may assume that all the sources do not carry the same potential information , and are not required to be recorded separately .",
    "the human brain may easily distinguish between a voice sound and a background of other competing sounds @xcite .",
    "considering the example of an urban acoustic scene , global traffic hubbub sounds are typically uninformative , compared with closer human sounds @xcite .",
    "maffiolo @xcite showed the existence of two distinct cognitive processes depending on the listener s ability to identify separate sound events . by asking subjects to categorize recordings of urban environments and using linguistic analysis of the verbal descriptions of the categories , she found two cognitive categories of sound environments called respectively `` event sequences '' and `` amorphous sequences '' .",
    "event sequences ( sound environments in which distinct events or sequences of events can be identified ) are processed analytically , that is , based on the meaning of the identified sound sources , whereas amorphous sequences ( sound environments in which no event can be isolated ) are processed holistically using global acoustical indicators ( intensity , spectral content ) .",
    "the distinction observed by maffiolo was validated by guastavino @xcite .",
    "using semantic analysis of verbal descriptions of specific sounds populating the urban environment , guastavino showed that verbal descriptions of low pitched sounds may be divided into two categories called `` source events '' ( sound events which can be attributed to a sound source ) , and `` background noise '' ( where no identifiable event can be isolated ) .",
    "what comes out from these studies is that sound perception highly depends on semantic features ( source identification ) , but also on the informativeness of the isolated source .",
    "sound sources that carry information of interest are processed separately , whereas the other are processed together in a single stream .",
    "based on this notion of informativeness , another common distinction is made between two perceptual objects called `` sound events '' and `` sound textures '' .",
    "based on previous studies on vision , mcdermott and simoncelli @xcite showed that the perception of sound textures may derive from simple statistics of early auditory representations .",
    "these summary statistics would be sufficient to recognize sounds having some temporal homogeneity .",
    "that said , there are few formal definitions concerning the texture object @xcite .",
    "the most notable attempt has been made by saint - arnaud @xcite and saint - arnaud and popat @xcite . from their experiment , they derived the following properties ( quoted from @xcite ) : +    * _ sound textures are formed of basic sound elements , or atoms ; _ * _ atoms occur according to a higher - level pattern , that can be periodic or random , or both ; _ * _ the high - level characteristics must remain the same over long time periods ( which implies that there can be no complex message ) ; _ * _ the high - level pattern must be completely exposed within a few seconds ( `` attention span '' ) ; _ * _ high level randomness is also acceptable , as long as there are enough occurrences within the attention span to make a good example of the random properties . _ +    considering these properties , a texture may be understood as a composite object with two hierarchical levels , the top level being the high level pattern , and the leaf level being the atom .",
    "the nature of an atom remains adaptable as the latter may be considered at several time scales .",
    "thus and to some extent , texture may be considered as a concatenation of recordings , each of them being a sequence of atoms .",
    "in this case , these recordings must comprise at least the high level pattern of the texture , that is , if we consider a texture of ` gallop ' , recordings of atom sequences must be at least composed of the first three sounds of hoofs .",
    "to summarize the previous statements , it appears that all sounds are not processed as a sum of distinct events : +    * amorphous sequences that convey low semantic information are processed holistically ; * sound textures with stable acoustic properties over long period are processed using summary statistics of these acoustics properties .    to circumvent the issue of recording a representative number of sound collections to simulate an acoustic scene , one can take into account those considerations , and use recordings of mixed sound sources , provided that they are amorphous sequences or textures .",
    "we believe that there exist some links between the notions of amorphous sequences and textures . both trigger holistic processing based on global acoustical properties for amorphous sequences @xcite and summary statistics for textures @xcite , and both convey a low potential information content @xcite ) . yet",
    ", amorphous sequences are described as `` background sounds '' with no identifiable events , whereas the texture definition comprises sequences of events such as `` gallop '' that do not meet this last criterion . considering that",
    ", one can consider an amorphous sequence to be a texture , as the physical characteristics of an amorphous sequence remain stable over time , but the reverse is not systematic .      from the considerations discussed above , we derive two types of sound collections to be used as basic elements by the simulation process : the `` event collections '' and the `` texture collections '' .",
    "for both collections , a stream is modeled as being a temporal sequence of sound recordings coming for the same sound collection .",
    "for the texture collection , each recording is an atom sequence , or more precisely , a sequence of sound events which follow a periodic or a stochastic pattern .",
    "the nature of the sequence to be recorded depends on the type of texture considered . for a texture with a periodic pattern such as gallop , recordings are event sequences comprising at least the first three sounds of hooves . and for a texture with a stochastic pattern such as `` rain '' , the recordings are simply samples of rain sounds .",
    "this method offers a certain flexibility , as it makes it possible to quickly generate various versions of a same texture with few recorded samples , by varying the apparition order of the sequence . obviously for a texture to be realistic",
    ", sequences have to come from the same recording session .",
    "moreover , as the human brain is very sensitive to repetition of identical sounds , even when they are individual chunks of white noise @xcite , a sequence shall not be concatenated with itself .",
    "to summarize , the proposed source - driven model uses collections as basic element for the simulation process :    * each collection is a group a sound recordings . *",
    "insofar as possible , the label of the collection should be of the form `` source + action '' and labels of source and action must be generic .",
    "* there are two types of collections called respectively the event collections , and the texture collections .",
    "* sound recordings of a same event collection come from the same sound source . *",
    "sound recordings of a same texture collection are atomic sequences emitted by one or a mixture of sound sources .",
    "* sound recordings of a texture collection must at least comprise the high - level pattern of the texture ( _ e.g. _ three sounds of hooves for the gallop texture ) .",
    "* a texture built from the concatenation of recordings must convey a low semantic information and  / or have stable acoustic properties over time .",
    "building on the above discussed matters , the proposed simulation process considers an acoustic scene as a sum of sound sources .",
    "each sound source activity is symbolized as a semantic sound track , which is a sequence of acoustic samples all emitted by the considered sound source ( see figure [ fig : controlparameters ] ) . to generate each semantic sound track",
    ", the model takes into account a set of four parameters being respectively :    1 .   the mean / variance of the event to background power ratio ( ebr ) between acoustic samples 2 .   the mean / variance time interval between consecutive onsets of acoustic samples 3 .   the mean / variance duration between acoustic samples 4 .",
    "the start / end times of the track    as motivated in section [ sec : informativenes ] , the model distinguishes between sound events and texture .",
    "a track of events is made of discrete sound samples , whereas a track of texture consists of one continuous sound , or a concatenation of samples ( see figure [ fig : controlparameters ] ) .",
    "thus , for texture track , the mean / variance time interval between samples as well as the variance ebr are set to @xmath0 .",
    "each semantic track , texture or event , is related to a specific sound collection . as discussed in section [ sec : soundcollection ] a sound collection may be seen as a group of similar recordings , each of which comprising sound signals that are emitted by the same sound source . for the purpose of this study ,",
    "the notion of sound collection greatly overlaps the notion of sound class , as this term is understood when tackling automatic detection tasks .",
    "the resulting simulation model is depicted on figure [ fig : sequencingmodel ] .",
    "first , the experimenter selects a number of sound sources or class to be used , each of which being related to a specific sound collection .",
    "second , the experimenter sets the simulation parameters depending on the nature of the track ( event or texture ) .",
    "those parameters can also be estimated from pre - existing annotated recorded sound scenes . according to those parameters , the simulation process computes the number of samples used in each semantic track .",
    "lastly , samples are randomly drawn from the corresponding sound collection using a discrete uniform distribution .",
    "schematic of the simulation process . ]",
    "( 1,0.37539404 ) ( 0,0 ) two semantic sound tracks ( event and texture ) and their controlling parameters.,title=\"fig : \" ] ( 0.00575811,0.32512232)(0,0)[lb ] ( 0,0.18795398)(0,0)[lb ] ( 0.45764387,0.07194046)(0,0)[lb ] ( 0.07563472,0.12026615)(0,0)[lb ] ( 0.08172171,0.02294988)(0,0)[b ] ( 0.30597838,0.02294988)(0,0)[b ] ( 0.90093639,0.0226837)(0,0)[b ] ( 0.80635234,0.12026615)(0,0)[lb ] ( 0.40981616,0.33324077)(0,0)[lb ] ( 0.61450068,0.22251218)(0,0)[lb ] ( 0.36263174,0.31999939)(0,0)[lb ] ( 0.36533509,0.35639)(0,0)[lb ] ( 0.62814314,0.25892034)(0,0)[lb ] ( 0.70334704,0.25836979)(0,0)[lb ] ( 0.08285587,0.00359984)(0,0)[b ] ( 0.30283388,0.00359984)(0,0)[b ] ( 0.89944959,0.00359984)(0,0)[b ]      the proposed model is source - driven as it uses as basic elements semantic sound tracks , gathering sounds coming from the same collection of either sound events or sound textures ( see figure  [ fig : sequencingmodel ] ) .",
    "the nature of the recordings depends on the type of collection ( event of texture ) which is considered . after selecting the classes to be used ,",
    "the putative recorded samples are sequenced to generate the sound environment .",
    "the sequencing process depends on the type of collection . ideally , the sound collection design has to fulfill some perceptual constraints for the simulation to be ecologically valid , _",
    "e.g. _ to produce realistic scenes , as described in section [ sec : soundcollection ] .    considering that @xmath1 is a given acoustic scene composed of @xmath2 sound classes @xmath3 , the proposed model is such that :    @xmath4    where each @xmath5 is the time index , @xmath6 is a semantic sound track . for the sake of simplicity , we only detail here the model of an event track",
    ", then explain the adaptation of the model to texture tracks .",
    "@xmath6 is defined as a sequence of @xmath7 sound events @xmath8 randomly chosen among the @xmath9 samples in class @xmath3 : for each @xmath10 in @xmath11 $ ] , @xmath12 , where @xmath13 represents an uniformly distributed integer random value between @xmath14 and @xmath15 included .",
    "each event is scaled by an amplitude factor sampled from a real normal distribution with average @xmath16 and variance @xmath17 .",
    "the interval separating the onset times of consecutive samples for track @xmath18 is , similarly , randomly chosen following a normal distribution with average @xmath19 and variance @xmath20 .",
    "formally , each sequence @xmath21 is thus expressed as :    @xmath22    @xmath23    where @xmath24 is set to @xmath0 by convention .",
    "the signal of an event is defined in such a way that @xmath25 if @xmath26 or beyond the signal s duration .    in the case of a texture track , two implementation differences",
    "must be observed to maintain a perceptually acceptable output : first , signal amplitude is only drawn at random once , and that value is applied to all samples ; second , sample start times are not randomized but chosen so that the texture recordings chosen from class @xmath3 will be played back - to - back with sufficient overlap to create an equal - power cross - fade between them , thus generating a continuous , seamless track .    while implementing this model for the generation of acoustical sound scenes , additional treatments and constraints are applied in order to improve perceptual quality .",
    "namely , the fading of the onset and offsets of events and the whole track , and the fact that the same sound sample can not be sequenced consecutively .",
    "this section describes the different corpora of simulated acoustic scenes considered in the experiments described in section [ sec : experiments ] .",
    "all the scenes are simulated using the dcase challenge test set annotations for the ` office live ' ( ol ) task @xcite .",
    "we run the same automatic event detection algorithms used for the dcase challenge , and compare the results obtained with the simulated scenes to those obtained with the real scenes of the dcase test set .",
    "the root corpus is the test set considered in the dcase challenge .",
    "it is called `` test - qmul '' .",
    "this corpus is composed of 11 recordings of office live scenes roughly one minute long .",
    "scenes have been recorded in 5 different acoustic environments .",
    "the audio events have been divided into 16 sound event classes to be annotated : door knock , door slam , speech , human laughter , clearing throat , coughing , drawer , printer , keyboard click , mouse click , object ( specifically pen , pencil or marker ) put on table surfaces , switch , keys ( put on table ) , phone ringing , short alert ( beep ) sound and page turning .",
    "two different annotations coming from two distinct individuals have been used to measure the algorithm performances , thus leaving us with 22 scene - annotator couples .",
    "there is no time overlap between events .",
    "four corpora of simulated scenes are generated as depicted in figure [ fig : databases ] .",
    "they are respectively called `` instance - qmul '' , `` abstract - qmul '' , `` instance - irccyn '' and `` abstract - irccyn '' .",
    "the labels `` irccyn '' and `` qmul '' refer to the two different datasets of event recordings used to generate the corpora which have been recorded in different offices , the ones of queen mary university of london ( qmul ) for the former and the ones of the insitute of research on communications and cybernetics of nantes ( irccyn ) .",
    "the labels `` instance '' and `` abstract '' correspond to two distinct simulation processes . to generate the two qmul corpora , we use recordings of audio events that have been extracted from recordings done during the preparation of the dcase challenge , but unused during the challenge , see @xcite for further information on recording conditions .",
    "the extracted samples were therefore recorded in the same conditions than the test - qmul corpus .",
    "depending on the sound class considered , 3 to 23 events per class are extracted .",
    "we also use event - free background recordings ( texture ) coming from the same acoustic environments than those of the test - qmul corpus .",
    "these background recordings are used to generate the background noise ( texture ) of the instance - qmul and abstract - qmul corpora .",
    "the two irccyn corpora are generated using new recordings of sound events with respect to the sound classes of the dcase challenge .",
    "all recordings were performed at irccyn in a calm environment using the shotgun microphone at8035 connected to a zoom h4n recorder .",
    "20 samples of each class are used to generate the instance - irccyn and abstract - irccyn corpora , which corresponds to the cardinality of the dcase challenge train set in terms of event classes @xcite .     generation process of the corpora considered in this evaluation . as part of the dcase challenge ,",
    "systems were trained on qmul train and tested on qmul test during the dcase challenge . ]",
    "the instance simulation process simulates acoustic scenes with the same temporal structure and event to background ratios ( ebrs ) than the annotation of the test - qmul corpus .",
    "the ebr of an event of @xmath27 sample length is obtained by computing the ratio in decibel between the event @xmath28 and the background @xmath29 root means square measures .",
    "+ @xmath30 + with @xmath31 x(n ) may be replaced by @xmath32 and @xmath33 , the sound pressures at sample @xmath5 of respectively the sound event and the background noise . + for each event of each scene - annotator couple of the test - qmul corpus , the onset - offset times and an approximation of the ebr are considered . as it is not possible to isolate the background under the events , the background level needed to compute the ebr",
    "is obtained using a event - free sequence of each real scene .",
    "these onsets - offsets and ebr are then used to generate the simulated scenes . for each simulated scene , at each onset of the corresponding annotator - couple scene , we randomly place an audio event belonging to the same audio class .",
    "to ensure that samples of recorded audio events are not too long comparing to the annotated ones , recordings are cut off to the annotation length if the recording duration is larger than the annotation duration of at least 0.5 seconds .",
    "each event has its amplitude scaled to the same ebr than the test - qmul corpus .",
    "instance simulation process provides us with simulated scenes with temporal structures and sound levels that are close as possible as those of the real corpus test - qmul .",
    "+      for the abstract simulation process , the goal is to abstract temporal structures and ebrs of the real scenes .",
    "to do so , the model described in [ proposed model ] is instantiated using estimations of the @xmath16 , @xmath17 , @xmath19 and @xmath20 parameters ( see eq . [ eq1 ] and [ eq2 ] ) .",
    "estimation is done for each annotator - scene couple , using both the sound signals and the annotations of the test - qmul corpus . to generate the simulated scenes , ebrs and time intervals between events",
    "are respectively obtained from the normal distributions @xmath34 and @xmath35 .",
    "similarly to the instance simulation process , event recordings are chosen randomly . for practical considerations ,",
    "the start and termination times of the class sequence ( semantic sound track ) are the same as the ones of the test - qmul corpus . to ensure that the recorded samples are not significantly longer compared to the annotation times , the sample duration of a considered sound class @xmath18 has its duration @xmath36 thresholded as follows : @xmath37 , with @xmath38 and @xmath39 being respectively the average and standard deviation of the duration of the events belonging to the class @xmath18 in a given annotation .",
    "setting the lower bound to 5 seconds allows us to minimize the impact of such operation on short impulsive sounds .",
    "the performance of event detection systems can be evaluated following several metrics . in order to improve legibility of the following",
    ", we shall retain one evaluation metric that is considered to be the most informative for our study .    among the four metrics considered in the dcase challenge@xcite , namely the acoustic event error rate ( aeer ) @xcite , the precision , recall , and f - measure , the f - measure is selected as the most common and interpretable one .",
    "another variation is that those metrics can be computed over each frame or on event boundaries . in the latter case ,",
    "the detection of the onset boundary can be considered solely or together with the offset . as annotating and consequently detecting the duration and",
    "the offset of events is notoriously difficult , we focus on the detection of the onset as the main objective . furthermore , in order to achieve more comparable results across datasets and to ensure that repetitive events do not dominate the accuracy of an algorithm , the metric shall be class normalized .",
    "that is : @xmath40 where @xmath41 is the f - measure achieved by the system while detecting event @xmath18 .",
    "thus , by considering the class - wise event onset based f - measure ( cwebf ) , performance evaluation is more invariant to event duration and distribution .",
    "we thus select this metric that was also collectively agreed upon by dcase participants through the challenge mailing list .",
    "together with a baseline system provided by the organizers , 8 detection systems have been evaluated at the dcase challenge .",
    "those systems roughly follow the processing chain shown on figure [ fig : schematic ] with some variety on the implementation of the different nodes .",
    "features are most commonly mel - frequency cepstral coefficients ( mfcc)s @xcite but other sets fo spectral features are also considered , with or without pre - processing such as denoising .",
    "the classifier of choice is the 2 layer hidden markov model ( hmm ) @xcite where the second layer models the transition between events but other classifiers are also considered such as random forests ( rf ) , support vector machines ( svm ) or non - negative matrix factorization ( nmf ) .",
    "all those algorithmic differences as well as their specific tuning result in specific behaviors that are interesting to evaluate in different testing conditions , especially those which evaluate their generalization capabilities .",
    "( .8,0 ) node[mynode , pos=0.2 ] pre - processing * node[mynode , pos=0.4 ] features node[mynode , pos=0.58 ] classification node[mynode , pos=0.82 ] post - processing * node[pos=0.2 , below=10pt ] denoising node[pos=0.4 , below=10pt ] mfccs node[pos=0.58 , below=10pt ] hmm node[pos=0.82 , below=10pt ] smoothing ;    .summary of submitted event detection systems . [ cols=\"<,^\",options=\"header \" , ]     whereas the expected behavior with the use of the qmul instance and abstract datasets was a equivalent performance compared to the ones achieved on test qmul , the expected behavior with the irccyn dataset is a drop in performance . as can be seen on table [ tab : irccyn ] , this drop is significant for all the systems .",
    "more importantly , all the systems except the scs one achieve similar performance when compared to the baseline on the irccyn datasets , meaning that for most systems , the performance gain may solely be due to an over adaptation of the system to the training data .",
    "figure  [ irccyn ] summarizes the results , where the good behavior of the scs system can be clearly seen .",
    "class - wise event based f - measure achived by the different systems on the qmul and irccyn datasets . ]",
    "in the light of the results discussed above , we believe that considering carefully designed simulated data is useful for gaining knowledge about the properties and behaviors of the systems under evaluation , thus helping the designer in his algorithmic choices and their evaluation .",
    "important factors influencing the performance such as the noise level , the level of polyphony , the intra - class diversity ( acoustical difference between training and testing data ) can be evaluated independently , without the burden of experimentally recording data which the desired properties and manually annotating them .    even though the sole use of synthetic data for validating a computational approach is clearly not sufficient",
    ", we believe that the sole use of real data may not be sufficient either , should one wish to gain deep knowledge about the impact of some design and parametrization issues involved in the implementation of an engineering system .",
    "indeed , real data which is well annotated is most of the time a scarce resource as the careful design of a large evaluation dataset is a demanding task .",
    "moreover , depending on the task at hand , which may not be always well posed , the annotation can be a critical issue leading to some compromise that will greatly contribute to the difficulty of evaluating the performance of the algorithms .",
    "we thus believe that considering simulated data is an in between approach , that together with final validation using real data may be very useful in order to produce more knowledge about the engineering systems under evaluation .",
    "we shall stress that such approach is taken in more mature fields , for example robust asr where challenges are conducted using simulated data such as the chime challenges @xcite .",
    "the simulated acoustic scenes datasets have been generated using a dedicated set of matlab functions publicly available .",
    "a morphological model of acoustic scenes has been presented . following a collection based approach , it generates a set of sound tracks which are sequences of event realizations drawn from specifically tailored sound sample collections .",
    "its potential for generating simulated corpuses of office events scenes is evaluated , by building upon the results obtained thanks to the ieee aasp dcase challenge on the detection of events in an office environment .",
    "we believe that considering those simulated corpora allows us to gain important knowledge about the behavior of the systems under evaluation . as most of the systems under evaluation",
    "were built for monophonic inputs ( one event occurring at a given time ) , this paper focused on modifying the acoustical properties of the background or the events .",
    "future research will focus on the influence of the degree of overlap when facing polyphonic scenes , potentially with temporal interactions between events , both for single events ( e.g. repetitions for a single event ) as well as interactions between event classes .",
    "the authors would like to thank mark plumbley for his support .",
    "research project partly funded by anr-11-js03 - 005 - 01 .      ecology and",
    "acoustics : emergent properties from community to landscape .",
    "page  94 , paris , france , june 2014 .",
    "sueur , j. and farina , a. and bobryk , c. and llusia , d. and mcwilliam , j. and pieretti , n. , musum national dhistoire naturelle .",
    "r.  radhakrishnan , a.  divakaran , and p.  smaragdis .",
    "audio analysis for surveillance applications . in _ applications of signal processing to audio and acoustics , 2005 .",
    "ieee workshop on _ ,",
    "pages 158161 , oct 2005 .",
    "d.  giannoulis , d.  stowell , e.  benetos , m.  rossignol , m.  lagrange , and m.  d. plumbley . a database and challenge for acoustic scene classification and event detection . in _ proceedings of the european signal processing conference ( eusipco ) _ ,",
    "2013 .",
    "dimitrios giannoulis , emmanouil benetos , dan stowell , mathias rossignol , mathieu lagrange , and mark  d plumbley .",
    "detection and classification of acoustic scenes and events : an ieee aasp challenge . in",
    "_ 2013 ieee workshop on applications of signal processing to audio and acoustics ( waspaa ) _ , pages 14 .",
    "ieee , 2013 .",
    "rainer stiefelhagen , keni bernardin , rachel bowers , john garofolo , djamel mostefa , and padmanabhan soundararajan . the clear 2006 evaluation . in rainer stiefelhagen and john garofolo , editors ,",
    "_ multimodal technologies for perception of humans _ , volume 4122 of _ lecture notes in computer science _ , pages 144 .",
    "springer berlin heidelberg , 2007 .",
    "sascha spors , heinz teutsch , achim kuntz , and rudolf rabenstein .",
    "sound field synthesis . in yiteng huang and jacob benesty , editors ,",
    "_ audio signal processing for next - generation multimedia communication systems _ , pages 323344 .",
    "springer us , 2004 .",
    "maria niessen , caroline cance , and danile dubois .",
    "categories for soundscape : toward a hybrid classification . in _ inter - noise and noise - con congress and conference proceedings _ , volume 2010 , page 58165829 , 2010 .",
    "f.  guyot , m.  castellengo , and b.  fabre . , chapter tude de la catgorisation dun corpus de bruits domestiques ( a study of the categorization of an everyday sound set ) , pages 4158 .",
    "dition kim , paris , france , 1997 .",
    "a.  diment , t.  heittola , and t.  virtanen .",
    "sound event detection for office live and office synthetic aasp challenge . technical report , 2013 .",
    "http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/ol/dhv.pdf .",
    "j.  f. gemmeke , l.  vuegen , b.  vanrumste , and h.  van  hamme .",
    "an exemplar - based nmf approach for audio event detection .",
    "technical report , 2013 .",
    "http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/ol/gvv.pdf .",
    "w.  nogueira , g.  roma , and p.  herrera .",
    "automatic event classification using front end single channel noise reduction , mfcc features and a support vector machine classifier",
    ". technical report , 2013 .",
    "http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/ol/nvm.pdf .",
    "j.  schrder , b.  cauchi , m.  r. schdler , n.  moritz , k.  adiloglu , j.  anemller , s.  doclo , b.  kollmeier , and s.  goetze . acoustic event detection using signal enhancement and spectro - temporal feature extraction",
    ". technical report , 2013 .",
    "http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/ol/scs.pdf .",
    "l.  vuegen , b.  van den  broeck , p.  karsmakers , j.  f. gemmeke , b.  vanrumste , and h.  van  hamme .",
    "an mfcc - gmm approach for event detection and classification .",
    "technical report , 2013 ."
  ],
  "abstract_text": [
    "<S> this paper introduces a model of environmental acoustic scenes which adopts a morphological approach by abstracting temporal structures of acoustic scenes . to demonstrate its potential , </S>",
    "<S> this model is employed to evaluate the performance of a large set of acoustic events detection systems . </S>",
    "<S> this model allows us to explicitly control key morphological aspects of the acoustic scene and isolate their impact on the performance of the system under evaluation . </S>",
    "<S> thus , more information can be gained on the behavior of evaluated systems , providing guidance for further improvements . </S>",
    "<S> the proposed model is validated using submitted systems from the ieee dcase challenge ; results indicate that the proposed scheme is able to successfully build datasets useful for evaluating some aspects the performance of event detection systems , more particularly their robustness to new listening conditions and the increasing level of background sounds .    </S>",
    "<S> bare demo of ieeetran.cls for journals    acoustic event detection , auditory scene analysis , experimental validation . </S>"
  ]
}