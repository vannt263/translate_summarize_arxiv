{
  "article_text": [
    "the study of information inequalities is a subfield of information theory that describes linear constraints on the entropies of finite collections of jointly distributed discrete random variables .",
    "historically , the known information inequalities were orignally all special cases of shannon s conditional mutual information inequality @xmath0 , but later were generalized to other types of inequalities , called non - shannon inequalities .",
    "information inequalities have been shown to be useful for computing upper bounds on the network coding capacities of certain networks .",
    "analagously , the study of linear rank inequalities is a topic of linear algebra , which describes linear constraints on the dimensions of collections of subspaces of finite dimensional vector spaces .",
    "in fact , the set of all information inequalities can be viewed as subclass of the set of all linear rank inequalities .",
    "information inequalities hold over all collections of a certain number of random variables . in constrast",
    ", linear rank inequalities may hold over only certain vector spaces , such as those whose scalars have particular field characteristics .    in this paper , we present two new linear rank inequalities over finite fields , which are not information inequalities , and with the peculiar property that they only hold for certain fields , depending on the associated vector space .",
    "the first inequality is shown to hold over all vector spaces when the field characteristic is anything but three ( theorem  [ thm : t8 ] ) , but does not always hold when the field characteristic is three ( theorem  [ thm : t8-char3 ] ) .",
    "in contrast , the second inequality is shown to hold over all vector spaces when the field characteristic is three ( theorem  [ thm : nont8 ] ) , but does not always hold when the field characteristic is not three ( theorem  [ thm : non - t8-non - char3 ] ) .",
    "we also show how these inequalities can be used to obtain bounds on the capacities of certain networks ( corollaries  [ cor : t8-capacity ] and [ cor : nont8-capacity ] ) .",
    "it will be assumed that the reader has familiarity with linear algebra , finite fields , information theory , and network coding .",
    "nevertheless , we will give some brief tutorial descriptions of these topics for completeness .",
    "in 2000 , ahlswede , cai , li , and yeung introduced the field of network coding  @xcite and showed that coding can outperform routing in directed acyclic networks .",
    "there are presently no known algorithms to determine the capacity or the linear capacity of a given network .",
    "in fact , it is not even known if such algorithms exist .",
    "information inequalities are linear inequalities that hold for all jointly distributed random variables , and shannon inequalities are information inequalities of a certain form  @xcite .",
    "both are defined in section  [ section : lri ] .",
    "it is known  @xcite that all information inequalities containing three or fewer variables are shannon inequalities .",
    "the first `` non - shannon '' information inequality was of four variables and was published in 1998 by zhang and yeung  @xcite . since 1998",
    ", various other non - shannon inequalities have been found , for example , by lnnika  @xcite , makarychev , makarychev , romashchenko , and vereshchagin  @xcite , zhang  @xcite , zhang and yeung  @xcite , dougherty , freiling , and zeger  @xcite , and mat  @xcite .",
    "additionally , in 2007 , mat demonstrated an infinite collection of independent non - shannon information inequalities  @xcite and there were necessarily an infinite number of such inequalities . in 2008 ,",
    "xu , wang , and sun  @xcite also gave an infinite list of inequalities but did not establish their necessity .",
    "there is a close connection between information inequalities and network coding  @xcite .",
    "capacities of some networks have been computed by finding matching lower and upper bounds  @xcite .",
    "lower bounds have been found by deriving coding solutions .",
    "upper bounds have been found by using information inequalities and treating the sources as independent random variables that are uniformly distributed over the alphabet .",
    "one `` holy grail '' problem of network coding is to develop an algorithm to compute the coding capacity of an arbitrary network .",
    "if such an algorithm exists , information inequalities may potentially play a role in the solution .",
    "it has been shown that linear codes are insufficient for network coding in general  @xcite . however , linear codes may be desirable to use in practice due to ease of analysis and implementation .",
    "it has been shown that the coding capacity is independent of the alphabet size  @xcite .",
    "however , the linear coding capacity is dependent on alphabet size , or more specifically the field characteristic .",
    "in other words , one can potentially achieve a higher rate of linear communication by choosing one characteristic over another . to provide upper bounds for",
    "the linear coding capacity for a particular field one can look at linear rank inequalities  @xcite .",
    "linear rank inequalities are linear inequalities that are always satisfied by ranks of subspaces of a vector space .",
    "all information inequalities are linear rank inequalities but not all linear rank inequalities are information inequalities .",
    "the first example of a linear rank inequality that is not an information inequality was found by ingleton  @xcite .",
    "information inequalities can provide an upper bound for the capacity of a network , but this upper bound would hold for all alphabets . therefore , to determine the linear coding capacity over a certain characteristic one would have to consider linear rank inequalities .    all linear rank inequalities up to and including five variables are known and none of these depend on the vector spaces field characteristics  @xcite .",
    "the set of all linear rank inequalities for six variables has not yet been determined .",
    "characteristic - dependent linear rank inequalities are given , for example , in  @xcite and  @xcite .",
    "an inequality is given in  @xcite which is valid for characteristic two and another inequality is given which is valid for every characteristic except for two .",
    "these inequalities are then used to provide upper bounds for the linear coding capacity of two networks .    in the present paper , we give two characteristic - dependent linear rank inequalities on eight variables .",
    "one is valid for characteristic three and the other is valid for every characteristic except for three .",
    "these inequalities are then used to provide upper bounds for the linear coding capacity of two networks .",
    "it is our intention that the techniques presented here may prove useful or otherwise motivate further progress in determining network capacities .      in this section a very brief review of matroids",
    "is given which will enable discussion in subsequent sections of a matroid - based method for constructing a particular network that helps in the derivation of the linear rank inequalities presented in this paper .",
    "a matroid is an abstract structure that captures a notion of  independence \" that is found in finite dimensional vector spaces , graphs , and various other mathematical topics .",
    "we will follow the notation and results of  @xcite .    a _ matroid _",
    ", @xmath1 , is a pair @xmath2 , where @xmath3 is a finite set and @xmath4 is a set of subsets of @xmath3 that satisfies the following properties :    1 .",
    "@xmath6 , if @xmath7 , then @xmath8 .",
    "3 .   @xmath6 , if @xmath9 and @xmath10 , then @xmath11 such that @xmath12 .",
    "the sets in @xmath4 are called _",
    "independent sets_. if a subset of @xmath3 is not in @xmath4 , then it is called _",
    "dependent_.    an example of a matroid is obtained from linear algebra .",
    "let @xmath13 be a finite field and let @xmath14 be the vector space of all @xmath15-dimensional vectors whose components are elements of @xmath13 .",
    "suppose @xmath16 is an @xmath17 matrix over @xmath13 .",
    "let @xmath18 and @xmath4 be the set of all @xmath19 such that the multiset of columns of @xmath16 indexed by the elements of @xmath20 is linearly independent in the vector space @xmath14 . then @xmath21 is a matroid called the _ vector matroid _ of @xmath16 .",
    "a matroid is said to be _",
    "representable _ over the field @xmath13 if it is isomorphic to some vector matroid over @xmath14 .",
    "for example , if @xmath13 is the binary field and @xmath22 where @xmath23 denote the columns of @xmath16 from left to right , then @xmath21 is a vector matroid of @xmath16 , where @xmath24 and @xmath25 a _ base _ is a maximal independent set .",
    "let @xmath26 denote the set of all bases of a matroid @xmath1 . in our example",
    ", @xmath27 it is well known that all the bases of a matroid are of the same cardinality .",
    "if we let @xmath19 and @xmath28 , then it is easy to see that @xmath29 is a matroid .",
    "the _ rank _ of @xmath20 , denoted by @xmath30 , is defined to be the cardinality of a base in @xmath31 . in our example , @xmath32 .",
    "a _ circuit _ is a minimal dependent set .",
    "the circuits in our example are @xmath33 .      in this section",
    "we will use the information theoretic concepts of entropy and mutual information to define and use the linear algebraic concept of linear rank inequalities .",
    "connections between information inequalities and linear rank inequalities is also discussed .",
    "let @xmath34 be collections of discrete random variables over a finite alphabet @xmath35 , and let @xmath36 be the probability mass function of @xmath16 .",
    "the _ entropy _ of @xmath16 is defined by @xmath37 the _ conditional entropy _ of @xmath16 given @xmath38 is @xmath39 the _ mutual information _ between @xmath16 and @xmath38 is @xmath40 and the _ conditional mutual information _ between @xmath16 and @xmath38 given @xmath41 is @xmath42 we will make use of the following basic information - theoretic facts @xcite : @xmath43 the equations ( [ h5])-([h9 ] ) were originally given by shannon in 1948 @xcite , and can all be obtained from the single inequality @xmath44 .",
    "let @xmath45 be a positive integer , and let @xmath46 be subsets of @xmath47 .",
    "let @xmath48 for @xmath49 .",
    "a linear inequality of the form @xmath50 is called an _ information inequality _ if it holds for all jointly distributed random variables @xmath51 .    as an example , taking @xmath52 , @xmath53 , @xmath54 , @xmath55 , @xmath56 , @xmath57 , @xmath58 , and using ( [ h8 ] ) shows that @xmath59 is an information inequality .",
    "a _ shannon information inequality _ is any information inequality that can be expressed as a finite sum of the form @xmath60 where each @xmath61 is a nonnegative real number .",
    "any information inequality that can not be expressed in the form above will be called a _",
    "non - shannon information inequality_.    linear rank inequalities are closely related to information inequalities .",
    "in fact , in order to describe linear rank inequalities we will borrow notation from information theory to use in the context of linear algebra in the following manner .",
    "suppose @xmath16 and @xmath38 are subspaces of a given vector space @xmath62 , and let @xmath63 denote the span of @xmath64 .",
    "we will let @xmath65 denote the rank of @xmath16 , and let @xmath66 denote the rank of @xmath63 .",
    "the meanings of some other information theoretic notation in the context of linear algebra then follows from  - .",
    "specifically , note that the conditional entropy notation @xmath67 denotes the excess rank of subspace @xmath16 over that of subspace @xmath68 , or equivalently , the codimension of @xmath68 in @xmath16 ; and the mutual information notation @xmath69 denotes the rank of @xmath68 .",
    "a _ linear rank inequality _ over a vector space @xmath62 is a linear inequality of the form in , that is satisfied by every assignment of subspaces of @xmath62 to the variables @xmath70 .",
    "all information inequalities are linear rank inequalities over all finite vector spaces , but not all linear rank inequalities are information inequalities . for background material on these concepts ,",
    "the reader is referred to hammer , romashchenko , shen , and vereshchagin @xcite .",
    "the first known example of a linear rank inequality over all finite vector spaces that is not an information inequality is the _ ingleton inequality _",
    "@xcite : @xmath71 to see that the ingleton inequality is not an information inequality , let @xmath72 be binary random variables , and let @xmath73 with probabilities : @xmath74 then the ingleton inequality fails since : @xmath75      in this section , we will briefly review some concepts of network coding .",
    "this will enable the discussion later in this paper of our construction of linear rank inequalities using networks constructed from two particular matroids ( t8 and non - t8 ) .",
    "for more details on network coding , see @xcite .",
    "a _ network _ is a finite , directed , acyclic multigraph with messages and demands .",
    "messages _ are arbitrary vectors of @xmath76 symbols over a finite alphabet @xmath77 . each network edge carries a vector of @xmath78 symbols from @xmath77 .",
    "each message originates at a particular node called the _ source node _ for that message and is required by one or more _",
    "demand nodes_. when we draw a network , a message variable appearing above a node indicates the message is generated by such node and [ fig : nont8 ] , for convenience , we label source messages above nodes lying in both the top and bottom layers in each diagram .",
    "this is meant to indicate that there is , in fact , a separate ( but hidden ) distinct node for each such source message , whose out - edges go directly to the nodes labeled by the source message in the top and bottem layers . ] , and a message variable appearing below a node indicates the message is demanded by such node , for a given network , the values of @xmath76 and @xmath78 can be chosen in order to implement certain codes and to obtain certain throughput @xmath79 .",
    "the inputs to a network node are the vectors carried on its in - edges as well as the messages , if any , generated at the node .",
    "the outputs of a network node are the packets carried on its out - edges as well as any demanded messages at the node .",
    "each output of a node must be a function only of its inputs .",
    "a _ coding solution _ for the network is an assignment of such functions to the network edges .",
    "when the values of @xmath76 and @xmath78 need to be emphasized , the coding solution will be called a @xmath80-coding solution .",
    "capacity _ of a network is defined as : @xmath81 a solution is called a _ linear solution _ , if the alphabet @xmath77 is a finite field and the edge functions are linear ( i.e. linear combinations of their input vectors where the coefficients are matrices over the field ) .    the _ linear capacity _ is defined the same as the capacity but restricting solutions to be linear .",
    "it is also easily verified that if @xmath82 is a message , then @xmath83 , and if @xmath82 is a vector carried by an edge , then @xmath84 .     the butterfly network with source messages @xmath82 and @xmath85 , generated by source nodes @xmath86 and @xmath87 , respectively .",
    "demand nodes @xmath88 and @xmath89 demand messages @xmath85 and @xmath82 , respectively . ]",
    "let us illustrate a method for finding capacity bounds by examining the well - known butterfly network , depicted in figure  [ fig : butterfly ] .",
    "we assume the network messages @xmath82 and @xmath85 are independent , @xmath76-dimensional , random vectors with uniformly distributed components .",
    "then in any solution it must be the case that @xmath90 since @xmath85 is a function of @xmath82 and @xmath91 , and also that @xmath92}\\nonumber\\\\          & \\leq h(x , y , z ) & \\text { [ from \\eqref{h9}]}\\nonumber\\\\          & = h(x , z ) + h(y|x , z ) & \\text{[from \\eqref{h1}]}\\nonumber\\\\          & = h(x , z ) & \\text{[from ( \\ref{butterfly:1})]}\\nonumber\\\\          & \\le h(x ) + h(z ) & \\text{[from \\eqref{h8}]}\\nonumber\\\\          & \\le k + n. \\label{rv - inequality}\\end{aligned}\\ ] ] this implies @xmath93 , or equivalently @xmath94 .",
    "since this bound holds for all choices of @xmath76 and @xmath78 , the coding capacity must be at most @xmath95 .",
    "on the other hand , a solution with @xmath96 is obtained by taking @xmath97 over any finite field alphabet , so the coding capacity is at least @xmath95 .",
    "thus the coding capacity for the butterfly network is the same as the linear coding capacity which is exactly equal to @xmath95 .",
    "the inequalities in were based on random variables @xmath98 .",
    "later , in the proofs of corollaries  [ cor : t8-capacity ] and  [ cor : nont8-capacity ] , we will obtain bounds on the capacities of networks by using linear rank inequalities , instead of information inequalities . in those cases , certain vector subspaces",
    "will be used instead of random variables , but the procedure will appear similar .",
    "in this section , we given some technical lemmas which will be useful for proving the main results of the paper .    if @xmath16 is a subspace of vector space @xmath62 , and @xmath99 is a subspace of @xmath16 , then we will use the notation @xmath100 to represent the codimension of @xmath99 in @xmath16 .",
    "we will omit the subscript when it is obvious from the context which space the codimension is with respect to .",
    "[ lemma1 ] @xcite let @xmath62 be a finite dimensional vector space with subspaces @xmath16 and @xmath38 .",
    "then the subspace @xmath101 has codimension at most @xmath102 in @xmath62 .",
    "we know @xmath103 .",
    "then adding @xmath104 to both sides of the inequality gives @xmath105 .",
    "thus , @xmath106 .",
    "[ lemma2 ] @xcite let @xmath16 and @xmath38 be vector spaces over the same finite scalar field and with subspaces @xmath99 and @xmath107 , respectively .",
    "let @xmath108 be a linear function such that @xmath109 .",
    "then the codimension of @xmath99 in @xmath16 is at most the codimension of @xmath107 in @xmath38 .",
    "suppose a base for @xmath16 consists of a base for @xmath99 together with the vectors @xmath110 .",
    "let @xmath111 be field elements which are not all zero .",
    "then @xmath112 , so @xmath113 . thus , the vectors @xmath114 are linearly independent over the subspace @xmath107 , and therefore @xmath115 .",
    "[ lemma3 ] @xcite let @xmath16 and @xmath38 be vector spaces over the same finite scalar field , let @xmath107 be a subspace of @xmath38 , and let @xmath108 be a linear function .",
    "then @xmath116 on a subspace of @xmath16 of codimension at most the codimension of @xmath107 .",
    "let @xmath117 . then @xmath109 and the result follows from lemma  [ lemma2 ] .",
    "[ lemma4 ] @xcite let @xmath62 be a finite dimensional vector space and let @xmath118 be subspaces of @xmath62 .",
    "then for @xmath119 , there exist linear functions @xmath120 such that @xmath121 on a subspace of @xmath38 of codimension @xmath122 .",
    "let @xmath123 be a subspace of @xmath38 defined by @xmath124 .",
    "the subspace on which this lemma holds is @xmath123 .",
    "if @xmath125 , then the lemma would be trivially true .",
    "so , assume that @xmath126 , and let @xmath127 be a basis for @xmath123 . for each @xmath128",
    ", choose @xmath129 for @xmath130 such that @xmath131 . for each @xmath132 , define a linear mapping @xmath133 so that @xmath134 for all @xmath135 and @xmath136 . then extend @xmath137 arbitrarily to @xmath138 .",
    "now we have linear functions @xmath139 such that @xmath121 on @xmath123 .",
    "the dimension of @xmath123 is @xmath140 , so the codimension of @xmath123 is @xmath141 .",
    "[ lemma5 ] @xcite let @xmath62 be a finite - dimensional vector space and let @xmath142 , and @xmath41 be subspaces of @xmath62 .",
    "let @xmath143 and @xmath144 be linear functions such that @xmath145 on @xmath16 .",
    "then @xmath146 on a subspace of @xmath16 of codimension at most @xmath147 .",
    "let @xmath148 be the kernel of @xmath149 . clearly , @xmath149 maps @xmath16 into @xmath150 and since @xmath149 is linear the rank of its domain is at most the sum of the ranks of its kernel and range , so @xmath151    [ lemma6 ] @xcite let @xmath62 be a finite dimensional vector space and let @xmath152 be subspaces of @xmath62 . for",
    "each @xmath132 let @xmath153 be a linear function such that @xmath154 on @xmath16 .",
    "then @xmath155 on a subspace of @xmath16 of codimension at most @xmath156 .",
    "first we apply lemma  [ lemma5 ] to @xmath157 and @xmath158 to get @xmath159 on a subspace @xmath160 of @xmath16 of codimension at most @xmath161 . then apply lemma  [ lemma5 ] to @xmath162 and @xmath163 to get @xmath164 on a subspace @xmath165 of @xmath160 of codimension at most @xmath166 .",
    "continue on until we apply lemma [ lemma5 ] to @xmath167 and @xmath168 to get @xmath169 on a subspace @xmath170 of @xmath171 of codimension at most @xmath172 .",
    "now @xmath170 is a subspace of @xmath16 of codimension at most @xmath173 , on which @xmath174 .",
    "[ lem inj ] let @xmath175 be subspaces of a vector space @xmath62 and let @xmath176 , and @xmath177 be functions such that @xmath178 and @xmath179 .",
    "if @xmath180 on @xmath16 and @xmath181 is injective on @xmath38 , then @xmath182 is injective on @xmath183 .",
    "let @xmath184 .",
    "we know @xmath185 on @xmath186 because @xmath187 for all @xmath188 . since @xmath189 , we know @xmath190 , which implies @xmath191 for some @xmath192 .",
    "similarly , we know @xmath193 for some @xmath194 .",
    "so , we have @xmath195 and @xmath196 .",
    "if we assume @xmath197 , then we have @xmath198 . since @xmath181 is injective on @xmath38 , we know @xmath199 .",
    "thus @xmath200 , which implies @xmath201 .",
    "since @xmath180 on @xmath16 , we know @xmath202",
    ". thus @xmath182 is injective on @xmath183 .",
    "in this section , we use the known t8 matroid to construct a `` t8 network '' , and then in turn we use the t8 network to guide a construction of a `` t8 linear rank inequality '' that is shown to hold for all vector spaces having finite scalar fields of characteristic not equal to @xmath203 .",
    "then we show that the t8 inequality does not necessarily hold when such scalar fields have characteristic @xmath203 . finally , we determine the exact coding capacity of the t8 network and its linear coding capacity over finite field alphabets of characteristic @xmath203 , as well as a linear capacity upper bound for finite field alphabets whose characteristic is not @xmath203 .",
    "the t8 matroid is representable over a field if and only if the field is of characteristic 3 .",
    "figure  [ fig : t8 ] is a network whose dependencies and independencies are consistent with the t8 matroid .",
    "it was designed by the construction process described in @xcite , and we will refer to it as the t8 network .",
    "theorem  [ thm : t8 ] uses the t8 network as a guide to derive a linear rank inequality valid for every characteristic except for 3 .",
    "we refer to the inequality in the following theorem as the _",
    "t8 linear rank inequality_.     and @xmath205 generated at hidden source nodes with certain hidden out - edges pointing to corresponding displayed nodes @xmath86 , @xmath206 , @xmath88 , and @xmath207@xmath208 ( which are labeled by incoming messages above such nodes ) .",
    "the nodes @xmath207@xmath208 each demand one message , as labeled below such nodes . ,",
    "width=510 ]    [ thm : t8 ] let @xmath209 , and @xmath210 be subspaces of a vector space @xmath62 whose scalar field is finite and of characteristic other than @xmath203 .",
    "then the following is a linear rank inequality over @xmath62 : @xmath211         such that @xmath212 now combining some functions we obtained from lemma [ lemma4 ] gives four new functions : @xmath213 using ( [ p3:eq:1])([p3:eq:4 ] ) , ( [ p3:eq:11 ] ) , lemma  [ lemma1 ] , and lemma  [ lemma3 ] we know the sum of these four functions is equal to @xmath4 on a subspace of @xmath16 of codimension at most @xmath214 .    now applying lemma  [ lemma6 ] and lemma  [ lemma1 ] to the functions @xmath215 , @xmath216 , @xmath217 , and @xmath218 , we get a subspace @xmath219 of @xmath16 of codimension at most @xmath220 on which @xmath221 similarly , we get a subspace @xmath99 of @xmath16 of codimension at most @xmath222 on which @xmath223 we get a subspace @xmath107 of @xmath38 of codimension at most @xmath224 on which @xmath225 we get a subspace @xmath226 of @xmath38 of codimension at most @xmath227 on which @xmath228 we get a subspace @xmath229 of @xmath41 of codimension at most @xmath230 on which @xmath231 we get a subspace @xmath232 of @xmath41 of codimension at most @xmath233 on which @xmath234 we get a subspace @xmath235 of @xmath205 of codimension at most @xmath236 on which @xmath237 let @xmath238 . considering ( [ p3:eq : bhat2 ] ) and ( [ p3:eq : chat3 ] ) , we can apply lemma  [ lem inj ] to show that @xmath239 is injective on @xmath240 . by ( [ p3:eq : bhat3 ] )",
    ", we know @xmath241 let @xmath242 . considering again ( [ p3:eq : bhat2 ] ) and ( [ p3:eq : chat3 ] )",
    ", we can apply lemma  [ lem inj ] to show that @xmath243 is injective on @xmath244 . by ( [ p3:eq : chat2 ] )",
    ", we know @xmath245 let @xmath246 . considering ( [ p3:eq : abar1 ] ) and ( [ p3:f5f25 ] ) , we can apply lemma  [ lem inj ] to show that @xmath247 is injective on @xmath248 . by ( [ p3:eq : abar3 ] ) , we know @xmath249 is injective on @xmath248 which implies @xmath250 let @xmath251 . considering ( [ p3:eq : cbar3 ] ) and ( [ p3:eq : dbar4]),we can apply lemma  [ lem inj ] to show that @xmath252 is injective on @xmath253 .",
    "then by ( [ p3:eq : cbar4 ] ) , we know @xmath254 let @xmath255 . considering ( [ p3:eq : bbar2 ] ) and , we can apply lemma  [ lem inj ] to show that @xmath256 by ( [ p3:eq : bbar4 ] ) , we know @xmath257 which implies @xmath258 let us define the functions @xmath259 where @xmath260 and @xmath261 are the restrictions of the functions @xmath262 and @xmath263 to the sets @xmath248 and @xmath264 , respectively . now , considering ( [ p3:eq : bbar2 ] ) , ( [ p3:eq : bhat2 ] ) , ( [ p3:eq : cbar3 ] ) , and ( [ p3:eq : chat3 ] ) we have    @xmath265 } \\label{p3:f1}\\\\ f_2     & = -f_5f_{15}g_{14 } \\mbox { on $ f_{14}\\overline{a}^\\ast$ } & { & [ \\mbox{from   ( \\ref{p3:eq : abar3 } ) } ] } \\label{p3:f2}\\\\ f_3     & = -f_6f_{15}g_{14 } \\mbox { on $ f_{14}\\overline{a}^\\ast$ and } f_3 = -f_9f_{18}f_2 \\mbox { on $ f_{17}\\overline{c}$ }              & { & [ \\mbox{from   ( \\ref{p3:eq : abar4 } ) , ( \\ref{p3:eq : cbar4 } ) } ] } \\label{p3:f3}\\\\ f_4     & = -f_7f_{21}g_{20 } \\mbox { on $ f_{20}\\overline{b}^\\ast$ } & { & [ \\mbox{from   ( \\ref{p3:eq : bbar1 } ) } ] } \\label{p3:f4}\\\\ f_6     & = -f_9f_{21}g_{20 } \\mbox { on $ f_{20}\\overline{b}^\\ast$ } & { & [ \\mbox{from   ( \\ref{p3:eq : bbar4 } ) } ] } \\label{p3:f6}\\\\ f_7     & = -f_4f_{20}f_8 \\mbox { on $ f_{21}\\overline{b}$ } & { & [ \\mbox{from   ( \\ref{p3:eq : bbar1 } ) } ] } \\label{p3:f7}\\\\ f_9     & = -f_6f_{20}f_8 \\mbox { on $ f_{21}\\overline{b}$ } & { & [ \\mbox{from   ( \\ref{p3:eq : bbar4 } ) } ] } \\label{p3:f9}\\\\ f_{10 } & = -f_4f_{25}f_{11 } \\mbox { on $ f_{27}\\widehat{b}$ and } f_{10 } = -f_7f_{28}f_{12 } \\mbox { on $ f_{29}\\widehat{c}$ }              & { & [ \\mbox{from   ( \\ref{p3:eq : bhat1 } ) , ( \\ref{p3:eq : chat1 } ) } ] } \\label{p3:f10}\\\\ f_{11 } & = -f_8f_{28}f_{12 } \\mbox { on $ f_{29}\\widehat{c}$ } & { & [ \\mbox{from   ( \\ref{p3:eq : chat2 } ) } ] } \\label{p3:f11}\\\\ f_{12 } & = -f_5f_{25}f_{11 } \\mbox { on $ f_{27}\\widehat{b}$}. & { & [ \\mbox{from   ( \\ref{p3:eq : bhat3 } ) } ] } \\label{p3:f12}\\end{aligned}\\ ] ]    next , we provide upper bounds for the codimensions of @xmath248 , @xmath240 , @xmath264 , @xmath244 , and @xmath253 . from ( [ p3:eq : bhat2 ] ) , we know @xmath266 is injective on @xmath267 and @xmath268 is injective on @xmath226 .",
    "these facts will be used to arrive on lines ( [ p3:bhatstar:1 ] ) and ( [ p3:bhatstar:2 ] ) . from ( [ p3:eq : chat3 ] ) , we know @xmath269 is injective on @xmath232 , which will also be used to arrive on line ( [ p3:bhatstar:2 ] ) .",
    "lemma  [ lemma1 ] will be used to arrive on ( [ p3:bhatstar:3 ] ) .",
    "@xmath270 from ( [ p3:eq : abar1 ] ) , we know @xmath271 is injective on @xmath272 and @xmath273 is injective on @xmath99 .",
    "these facts will be used on lines ( [ p3:abarstar:1 ] ) and ( [ p3:abarstar:2 ] ) . from ( [ p3:f5f25 ] ) , we know @xmath274 is injective on @xmath240 , which will also be used to arrive on line ( [ p3:abarstar:2 ] ) .",
    "lemma  [ lemma1 ] will be used to arrive on ( [ p3:abarstar:3 ] ) .",
    "@xmath275 from ( [ p3:eq : cbar3 ] ) , we know @xmath162 is injective on @xmath276 and @xmath277 is injective on @xmath229 .",
    "these facts will be used to arrive on lines ( [ p3:cbarstar:1 ] ) and ( [ p3:cbarstar:2 ] ) . from ( [ p3:eq : dbar4 ] ) , we know @xmath278 is injective on @xmath235 , which will also be used on line ( [ p3:cbarstar:2 ] ) .",
    "lemma  [ lemma1 ] will be used to arrive on ( [ p3:cbarstar:3 ] ) .",
    "@xmath279 from ( [ p3:eq : bbar2 ] ) , we know @xmath280 is injective on @xmath281 and @xmath282 is injective on @xmath107 .",
    "these facts will be used to arrive on lines ( [ p3:bbarstar:1 ] ) and ( [ p3:bbarstar:2 ] ) . from ( [ p3:f9f18 ] ) , we know @xmath283 is injective on @xmath253 , which will also be used on line ( [ p3:bbarstar:2 ] ) .",
    "lemma  [ lemma1 ] will be used to arrive on ( [ p3:bbarstar:3 ] ) .",
    "@xmath284 from ( [ p3:eq : chat3 ] ) , we know @xmath285 is injective on @xmath286 and @xmath269 is injective on @xmath232 .",
    "these facts will be used to arrive on lines ( [ p3:chatstar:1 ] ) and ( [ p3:chatstar:2 ] ) . from ( [ p3:eq : bhat2 ] ) , we know @xmath268 is injective on @xmath226 , which will also be used on line ( [ p3:chatstar:2 ] ) .",
    "lemma  [ lemma1 ] will be used to arrive on ( [ p3:chatstar:3 ] ) .",
    "@xmath287 let @xmath288 .",
    "now , we will assume @xmath289 satisfies conditions ( [ p3:ass1])([p3:ass7 ] ) .",
    "the justifications can be found below .",
    "@xmath290 now , we need to make two assumptions on @xmath289 simultaneously . @xmath291 to justify ( [ p3:ass3 ] ) , first we know @xmath263 is injective on @xmath264 by ( [ p3:f6f20 ] ) .",
    "then by lemma  [ lemma3 ] , we know @xmath292 on a subspace of @xmath16 of codimension at most @xmath293 . by ( [ p3:f5f25 ] ) , we also know @xmath274 is injective on @xmath240 . then by lemma  [ lemma3 ] , we know @xmath294 on a subspace of @xmath16 of codimension at most @xmath295 . then using lemma  [ lemma1 ] , we have @xmath296 on a subspace of @xmath16 of codimension at most @xmath297 . conditions ( [ p3:ass4])([p3:ass6 ] ) can be justified similarly .    to justify ( [ p3:ass7 ] ) ,",
    "first we know @xmath277 is injective on @xmath229 by ( [ p3:eq : cbar3 ] ) .",
    "then by lemma  [ lemma3 ] , we know @xmath298 on a subspace of @xmath16 of codimension at most @xmath299 . by ( [ p3:f14 ] ) , we also know @xmath262 is injective on @xmath248 . then by lemma  [ lemma3 ] ,",
    "we know @xmath300 on a subspace of @xmath16 of codimension at most @xmath301 . then using lemma  [ lemma1 ] , we have @xmath302 on a subspace , @xmath303 , of @xmath16 of codimension at most @xmath304 . since @xmath262 is injective on @xmath248 , the function @xmath305 is defined on @xmath303 . using the same technique as before we can show that @xmath306 on a subspace , @xmath307 , of codimension with respect to @xmath303 at most @xmath308 .",
    "thus both conditions are true on @xmath307 , which has codimension with respect to @xmath16 at most @xmath309 .",
    "our final goal is to show that @xmath310 for some @xmath82 so that we may conclude that @xmath311 if the characteristic is 3 .",
    "we will accomplish this by using ( [ p3:eq : ahat1 ] ) and by proving that @xmath312 .",
    "first we must show that @xmath314 . by ( [ p3:eq : ahat2 ] )",
    ", we know @xmath315 then by using ( [ p3:f11 ] ) and condition ( [ p3:ass5 ] ) , we have @xmath316 now , by using ( [ p3:f1 ] ) and condition ( [ p3:ass7 ] ) , we have @xmath317 by ( [ p3:f8f28 ] ) , we know @xmath280 is injective on @xmath318 . by condition ( [ p3:ass4 ] ) , we know @xmath319 . by condition ( [ p3:ass6 ] ) , we know @xmath320 . by condition ( [ p3:ass5 ] ) , we know @xmath321 . using ( [ p3:eq : chat3 ] ) , we know @xmath322 .",
    "thus , we have @xmath323 by ( [ p3:eq : ahat4 ] ) , we have @xmath324 then by using ( [ p3:f6 ] ) and condition ( [ p3:ass3 ] ) , we have @xmath325 now , by using ( [ p3:f3 ] ) and condition ( [ p3:ass7 ] ) , we have @xmath326 by ( [ p3:f9f21 ] ) , we know @xmath327 is injective on @xmath328 . by condition ( [ p3:ass4 ] ) , we know @xmath329 . by condition ( [ p3:ass3 ] ) , we know @xmath292 so @xmath330 . by condition ( [ p3:ass6 ] ) , we know @xmath331 .",
    "thus , we have @xmath332 now , setting ( [ p3:claim1:1 ] ) and ( [ p3:claim1:2 ] ) equal to each other , we have @xmath333 by ( [ p3:f4 ] ) and condition ( [ p3:ass3 ] ) , we know @xmath334 using ( [ p3:claim1:3 ] ) , we have @xmath335 then using ( [ p3:f10 ] ) and condition ( [ p3:ass5 ] ) , we know @xmath336      first we must show that @xmath338 . by ( [ p3:eq : ahat3 ] ) ,",
    "we know @xmath339 then by using ( [ p3:f12 ] ) and condition ( [ p3:ass5 ] ) , we have @xmath340 now , by using ( [ p3:f2 ] ) and condition ( [ p3:ass7 ] ) , we have @xmath341 by ( [ p3:f5f25 ] ) , we know @xmath342 is injective on @xmath343 . by condition ( [ p3:ass3 ] ) , we know @xmath294 . by condition ( [ p3:ass5 ] ) , we know @xmath344 . now , using ( [ p3:eq : bhat2 ] ) , we know @xmath345 . by condition ( [ p3:ass7 ] ) , we know @xmath346 .",
    "thus , we have @xmath347 by ( [ p3:eq : ahat4 ] ) , we have @xmath348 then using ( [ p3:f9 ] ) and condition ( [ p3:ass4 ] ) , we have @xmath349 now , by using ( [ p3:f3 ] ) and condition ( [ p3:ass7 ] ) , we have @xmath350 by ( [ p3:f6f20 ] ) , we know that @xmath351 is injective on @xmath352 . by condition ( [ p3:ass3 ] ) , we know @xmath292 . by condition ( [ p3:ass4 ] ) , we know @xmath329 .",
    "now , using ( [ p3:eq : bbar2 ] ) , we know @xmath353 . by condition ( [ p3:ass7 ] ) , we know @xmath354 .",
    "thus , we have @xmath355 now , setting ( [ p3:claim2:1 ] ) and ( [ p3:claim2:2 ] ) equal to each other , we have @xmath356 by ( [ p3:f7 ] ) and condition ( [ p3:ass4 ] ) , we know @xmath357 using ( [ p3:claim2:3 ] ) , we have @xmath358 then using ( [ p3:f10 ] ) and condition ( [ p3:ass5 ] ) , we know @xmath359    now , by and the two claims , we have @xmath360 thus if the field has characteristic 3 , then @xmath361 no nonzero @xmath289 can satisfy all of the conditions ( [ p3:ass1])([p3:ass7 ] ) , so we must have @xmath362      [ thm : non - t8-non - char3 ] for each prime number @xmath363 there exists a vector space @xmath62 with a finite scalar field of characteristic @xmath36 such that the non - t8 inequality in theorem  [ thm : nont8 ] is not a linear rank inequality over @xmath62 .",
    "let @xmath62 be the vector space of @xmath364-dimensional vectors whose components are from @xmath365 , and define the following subspaces of @xmath62 : @xmath366 we have : @xmath367}\\nonumber\\\\              & = h(x|a , c , d )     & { & [ \\mbox{from   $ ( 1,0,1,1)=(1,0,0,0)+(0,0,1,0)+(0,0,0,1)$}]}\\nonumber\\\\              & = h(y|a , b , d )     & { & [ \\mbox{from   $ ( 1,1,0,1)=(1,0,0,0)+(0,1,0,0)+(0,0,0,1)$}]}\\nonumber\\\\              & = h(z|a , b , c )     & { & [ \\mbox{from   $ ( 1,1,1,0)=(1,0,0,0)+(0,1,0,0)+(0,0,1,0)$}]}\\nonumber\\\\              & = h(a|b , w , x )     & { & [ \\mbox{from   $ ( 1,0,0,0)=(1,0,1,1)+(0,1,0,0)-(0,1,1,1)$}]}\\nonumber\\\\              & = h(c|a , w , y )     & { & [ \\mbox{from   $ ( 0,0,1,0)=(0,1,1,1)+(1,0,0,0)-(1,1,0,1)$}]}\\nonumber\\\\              & = h(b|c , x , y )     & { & [ \\mbox{from   $ ( 0,1,0,0)=(1,1,0,1)+(0,0,1,0)-(1,0,1,1)$}]}\\nonumber\\\\              & = h(d|a , w , z )     & { & [ \\mbox{from   $ ( 0,0,0,1)=(0,1,1,1)+(1,0,0,0)-(1,1,1,0)$}]}\\nonumber\\\\              & = h(b|d , x , z )     & { & [ \\mbox{from   $ ( 0,1,0,0)=(1,1,1,0)+(0,0,0,1)-(1,0,1,1)$}]}\\nonumber\\\\              & = h(c|d , y , z )     & { & [ \\mbox{from   $ ( 0,0,1,0)=(1,1,1,0)+(0,0,0,1)-(1,1,0,1)$}]}\\nonumber\\\\              & = h(a|w , x , y , z )   & { & [ \\mbox{from   $ ( 1,0,0,0)=3^{-1 } ( ( 1,0,1,1){+}(1,1,0,1){+}(1,1,1,0 ) { - } 2(0,1,1,1))$}]}. \\label{eq : zero - entropies - nont8}\\end{aligned}\\ ] ] we know @xmath368 , also , we have @xmath369 so , if the inequality in theorem  [ thm : nont8 ] were to hold over @xmath62 , then we would have @xmath370 which is impossible .    for the non - t8 network ,",
    "the linear coding capacity is at most @xmath371 over any finite field alphabet of characteristic equal to @xmath203 .",
    "the linear coding capacity over finite field alphabets of characteristic not @xmath203 and the coding capacity are all equal to @xmath95 .",
    "[ cor : nont8-capacity ]    let @xmath13 be a finite field alphabet . consider a @xmath80 linear solution of the non - t8 network over @xmath13 , such that the characteristic of @xmath13 is @xmath203",
    "let @xmath16 , @xmath38 , @xmath41 , @xmath205 be message random variables in the t8 network , that are uniformly distributed over vectors in @xmath372 .",
    "let @xmath123 , @xmath20 , @xmath373 , @xmath210 be the resulting random variables associated with the corresponding labeled edges of t8 in figure  [ fig : nont8 ] .    equations now hold with random variables @xmath374 are taken as random variables ( i.e. not as subspaces as in theorem  [ thm : non - t8-non - char3 ] ) by lemma  [ lem : conditional - dimensions ] : @xmath375}\\nonumber\\\\              & = h(x|a , c , d )     & { & [ \\mbox{from   $ ( n_3,n_4)$}]}\\nonumber\\\\              & = h(y|a , b , d )     & { & [ \\mbox{from   $ ( n_5,n_6)$}]}\\nonumber\\\\              & = h(z|a , b , c )     & { & [ \\mbox{from   $ ( n_7,n_8)$}]}\\nonumber\\\\              & = h(a|b , w , x )     & { & [ \\mbox{from   $ n _ { 9}$}]}\\nonumber\\\\              & = h(c|a , w , y )     & { & [ \\mbox{from   $ n_{10}$}]}\\nonumber\\\\              & = h(b|c , x , y )     & { & [ \\mbox{from   $ n_{11}$}]}\\nonumber\\\\              & = h(d|a , w , z )     & { & [ \\mbox{from   $ n_{12}$}]}\\nonumber\\\\              & = h(b|d , x , z )     & { & [ \\mbox{from   $ n_{13}$}]}\\nonumber\\\\              & = h(c|d , y , z )     & { & [ \\mbox{from   $ n_{14}$}]}\\nonumber\\\\              & = h(a|w , x , y , z )   & { & [ \\mbox{from   $ n_{15}$}]}\\end{aligned}\\ ] ] and since the source message @xmath72 are independent random variables , we have @xmath376 so the non - t8 inequality in theorem  [ thm : nont8 ] reduces to @xmath377 now , since @xmath378 and @xmath379 , we have @xmath380",
    "so , the linear coding capacity over characteristic 3 is at most @xmath381    the non - t8 network has a scalar linear solution over every characteristic except for 3 by using the following edge functions ( here we are using the notations @xmath374 to denote edge variables rather than vector spaces ) : @xmath382 and decoding functions : @xmath383 we know the coding capacity is at most 1 because there is a unique path from source @xmath16 to node @xmath207 ( through node @xmath384 ) . since the coding capacity is at least as large as the linear coding capacity for characteristics other than 3",
    ", we conclude that the coding capacity is exactly equal to 1 .",
    "r.  dougherty , c.  freiling , and k.  zeger , `` linear rank inequalities on five or more variables , '' _ arxiv 0910.0284 _ , 2012 .",
    "r.  dougherty , c.  freiling , and k.  zeger , `` linear network codes and systems of polynomial equations , '' _ ieee transactions on information theory _ ,",
    "54 , no .  5 , pp . 23032316 , 2008 .",
    "k.  makarychev , y.  makarychev , a.  romashchenko , and n.  vereshchagin , `` a new class of non - shannon - type inequalities for entropies , '' _ communications in information and systems _ , vol .  2 , no .  2 ,",
    "pp . 147166 , 2002 ."
  ],
  "abstract_text": [
    "<S> two characteristic - dependent linear rank inequalities are given for eight variables . </S>",
    "<S> specifically , the first inequality holds for all finite fields whose characteristic is not three and does not in general hold over characteristic three . </S>",
    "<S> the second inequality holds for all finite fields whose characteristic is three and does not in general hold over characteristics other than three . </S>",
    "<S> applications of these inequalities to the computation of capacity upper bounds in network coding are demonstrated .    </S>",
    "<S> [ theorem ] corollary [ theorem ] proposition [ theorem ] remark [ theorem ] algorithm [ theorem ] conjecture [ theorem ] example    [ theorem ] definition </S>"
  ]
}