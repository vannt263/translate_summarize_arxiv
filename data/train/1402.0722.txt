{
  "article_text": [
    "specification tests are important in many nonparametric settings .",
    "generally , one is interested in testing whether certain nonparametric components are significant , or whether they have a more parsimonious and efficient parametric representation . in the time series context",
    ", there is a large literature devoting to the latter topic , see for instance hjellvik _ et al . _",
    "@xcite , fan and li @xcite , dette and spreckelsen @xcite , an and cheng @xcite and paparoditis @xcite , among others .",
    "many of the previous results perform specification for stationary time series .    the purpose of the paper is to develop specification tests for nonparametric regression of non - stationary time series .",
    "specifically , consider the following time - varying coefficient model : @xmath0 where @xmath1 , @xmath2 are @xmath3 dimensional time series of regressors or predictors , @xmath4 are error series satisfying @xmath5 . here",
    "@xmath6 denotes matrix or vector transpose .",
    "the processes @xmath7 and @xmath8 are allowed to be non - stationary and can be cross correlated .",
    "we assume that the regression parameters @xmath9 is a smooth function on @xmath10 $ ] .",
    "nonparametric specification of model ( [ eqmodel ] ) boils down to testing whether @xmath11 or a component of it has a certain parametric representation .    due to their flexility and interpretability in investigating shifting association between the response and predictors over time , model ( [ eqmodel ] ) and its stochastic coefficient version",
    "have attracted considerable attention in various fields .",
    "see , for instance , orbe _ et al . _",
    "@xcite , cai @xcite , brown _ et al .",
    "_ @xcite an stock and watson @xcite for applications in econometrics ; kitagawa and gersch @xcite and gersch and kitagawa @xcite for applications in signal processing ; hoover _ et al . _ @xcite and ramsay and silverman @xcite for applications in longitudinal and functional data analysis .",
    "most of the aforementioned literature on model ( [ eqmodel ] ) focused on parameter estimation .",
    "however , it seems that the important issue of model validation or specification of ( [ eqmodel ] ) have received little attention .    for varying coefficient models of i.i.d .",
    "samples , fan , zhang and zhang @xcite proposed the generalized likelihood ratio test ( glrt ) as a general rule for nonparametric specification ; see also dette @xcite for a closely related earlier test based on nonparametric analysis of variance ( anova ) .",
    "we also refer to the excellent review paper of fan and jiang @xcite and the references cited therein for a more detailed discussion of the glrt and related tests .",
    "the glrt has three major advantages .",
    "first , it is of simple and intuitively appealing form .",
    "for instance , consider testing @xmath12 where @xmath13 is a known function on @xmath14 $ ] .",
    "then the glrt statistic is proportional to @xmath15 , where @xmath16 and @xmath17 are residual sum of squares under the null and alternative hypothesis , respectively .",
    "hence , it is similar in form to the classic analysis of variance .",
    "second , the glrt is powerful to apply .",
    "fan , zhang and zhang @xcite showed that the glrt can detect local alternatives with the optimal rate in the sense of ingster @xcite .",
    "third , the test is asymptotically nuisance parameter free ; known as the wilks phenomenon .",
    "the wilks phenomenon insures that the residual wild bootstrap , that is , drawing i.i.d .",
    "samples from the centered empirical distribution of the residuals , is asymptotically consistent for the inference .",
    "in fact , the wilks phenomenon is shown to hold for a wide range of nonparametric models when testing under the glrt .",
    "see , for instance , fan and jiang @xcite for additive models and fan and huang  @xcite for varying coefficient partially linear models . for state - domain nonparametric regression for stationary time",
    "series , hong and lee @xcite showed that the wilks phenomenon continue to hold when the errors are conditionally homogeneous .    in this paper",
    ", we shall prove that the wilks phenomenon is sensitive to either conditional heteroscedasticity of the errors , non - stationarity or temporal dependence in model ( [ eqmodel ] ) .",
    "in particular , the wilks phenomenon fails for model ( [ eqmodel ] ) even when the errors and regressors are stationary and conditionally homogeneous .",
    "the latter finding is drastically different from the state domain regression case in hong and lee @xcite where the wilks phenomenon is shown to hold when the errors are conditionally homogeneous . as a consequence",
    ", the residual wild bootstrap fails for model ( [ eqmodel ] ) under dependence since the latter bootstrap generates ( conditional ) i.i.d .",
    "samples and hence mimics the wilks type asymptotic behavior .",
    "a new robust methodology is needed when performing model specification for ( [ eqmodel ] ) under dependence and non - stationarity .    according to a result on gaussian quadratic form approximation to the glrt",
    ", we shall propose in this paper a new wild bootstrap method for the nonparametric specification of model ( [ eqmodel ] ) .",
    "the latter bootstrap is shown to be consistent under non - stationarity and dependence .",
    "we further discover that the glrt , though fails to be asymptotically pivotal , retains the minimax rate of local alternative detection under weak dependence and non - stationarity .",
    "hence , the glrt with the robust wild bootstrap is powerful to apply .",
    "note that zhou and wu @xcite discussed simultaneous confidence band ( scb ) construction for model ( [ eqmodel ] ) which could be used for model specification .",
    "however , the scb can detect local alternatives with inferior rates than that of the glrt and hence is not a powerful tool for specification .",
    "it is known that nonparametric specification is sensitive to the choice of smoothing bandwidth . to alleviate the problem , horowitz and spokoiny @xcite and fan , zhang and zhang @xcite , among others , proposed to maximize the test statistic over a wide range of bandwidths . however , for the glrt test , the asymptotic behavior of the resulting statistic is unknown even for i.i.d . samples , which hampers the application of the latter test .",
    "it is worth mentioning that zhang @xcite derived the asymptotic null distribution of the maximum test for a bounded number of bandwidths . on the other hand",
    ", mller @xcite suggested to average the glrt over a range of bandwidths as an alternative to the maximum test .",
    "the latter suggestion stems from surprising results , such as lehmann @xcite , that the averaged likelihood ratio test can be more powerful than the maximum likelihood ratio test for complex alternatives . in this paper",
    ", we shall propose to use the averaged test for the specification of model ( [ eqmodel ] ) to alleviate the sensitivity of the test to the choice of bandwidth .",
    "we derive the asymptotic distribution and the local power of the averaged test .",
    "it is found that the averaged test is asymptotically at least as powerful as the best test based on a single bandwidth regardless of the shape of the alternative , the non - stationary dependence structure of the data or the kernel function .",
    "our finding is potentially interesting for a wide range of nonparametric specification problems .",
    "recently , there have been many results on modeling non - stationary time series from the spectral domain .",
    "see , for instance , dahlhaus @xcite , nason _",
    "_ @xcite and ombao _ et al . _",
    "@xcite , among others .",
    "at the same time , there is a great recent interest in specification of non - stationary time series in the spectral domain .",
    "examples include , among others , dahlhaus @xcite , neumann and von sachs @xcite , paparoditis @xcite , sergides and paparoditis @xcite and dette _ et al .",
    "however , for the varying coefficient regression ( [ eqmodel ] ) , models from the spectral domain do not seem to be directly useful for an asymptotic theory . in this paper",
    ", we shall adopt the time domain modeling of locally stationary time series in zhou and wu @xcite . the latter framework and",
    "the associated dependence measures directly facilitate the theory of the current paper .",
    "the rest of the paper is organized as follows .",
    "section [ secpre ] introduces the glrt statistic and the non - stationary time series models for the error and regressor series . in section [ secresults ]",
    ", we shall derive the asymptotic null distribution and local power of the glrt for parametric and semi - parametric null hypotheses .",
    "a detailed discussion on the failure of the wilks phenomenon is included . in section [ secnewtest ]",
    ", we shall introduce the averaged test and the corresponding robust bootstrap and investigate their asymptotic behavior . in section [ secsimu ]",
    ", we shall construct a monte carlo experiment to study the finite sample accuracy of the proposed averaged test .",
    "proofs of the asymptotic results are placed in section [ secproofs ] .",
    "consider the testing problem ( [ eqsimplenull ] ) .",
    "the glrt compares the residual sum of squares ( rss ) under the null and alternative hypotheses , and a large difference indicates violation of the null .",
    "we refer to fan , zhang and zhang @xcite for a detailed derivation of the statistic . specifically , the glrt statistic @xmath18 where @xmath19 is the rss under the null hypothesis and @xmath20 is the rss under the nonparametric alternative . here",
    "@xmath21 is the local linear kernel estimate of @xmath11 ( fan and gijbels , @xcite ) , which is defined as @xmath22 where @xmath23 is a kernel function , @xmath24 is the bandwidth , and @xmath25 , @xmath26 . throughout this paper",
    ", we shall always assume that the kernel @xmath27 , the collection of symmetric density functions @xmath23 with support @xmath28 $ ] and @xmath29 $ ] .",
    "define @xmath30^l k_{b_n}(t_i - t)\\ ] ] for @xmath31 where @xmath32 , and @xmath33^lk_{b_n}(t_i - t).\\ ] ] let @xmath34",
    ". then it can be shown that ( fan and gijbels , @xcite ) @xmath35 we shall omit the subscript @xmath36 in @xmath37 , @xmath38 and @xmath39 hereafter if no confusion will be caused .      throughout this paper",
    ", we shall assume that both @xmath40 and @xmath41 belong to a general class of locally stationary time series in the sense of zhou and wu @xcite as follows , @xmath42 \\\\[-8pt ] \\nonumber \\varepsilon_i&=&h\\bigl(t_i , ( \\ldots , \\xi_{i-1 } , \\xi_i)\\bigr ) v\\bigl(t_i , ( \\ldots , \\epsilon_{i-1 } , \\epsilon_i)\\bigr),\\qquad i=1,2,\\ldots , n,\\end{aligned}\\ ] ] where @xmath43 , @xmath44 are i.i.d .",
    ", @xmath45 are also i.i.d . and @xmath44 is independent of @xmath46 .",
    "let @xmath47 and @xmath48 .",
    "we assume that @xmath49 almost surely for all @xmath50 $ ] , in which case @xmath51 is the conditional variance of @xmath4 given  @xmath52 .",
    "it is clear from ( [ eqnonstatioanrymodelce ] ) that @xmath53 and @xmath41 are non - stationary .",
    "formulation ( [ eqnonstatioanrymodelce ] ) can be interpreted as physical systems with @xmath54 and @xmath55 being the inputs and @xmath56 , @xmath4 being the outputs , respectively , and @xmath57 , @xmath58 and @xmath59 being the transforms or filters that represent the underlying physical mechanism . by allowing  @xmath60 , @xmath58 and @xmath59 varying smoothly with respect to @xmath61",
    ", we have local stationarity of @xmath40 and @xmath41 .",
    "see also zhou and wu @xcite for more discussions .",
    "the above formulation of covariates and error processes is very general and includes many settings in the existing time series regression literature as special cases . to help understand the formulation",
    ", we shall consider the following three cases :    ( i.i.d .",
    "model ) . assume that @xmath62 and @xmath63 .",
    "then @xmath64 is a random sample and @xmath65 is independent of @xmath66 .",
    "this type of design was discussed extensively in fan , zhang and zhang @xcite and fan and jiang @xcite , among others .",
    "( exogenous model ) . in ( [ eqnonstatioanrymodelce ] ) , we assume that @xmath67 . in this case , the regressors and errors are two independent locally stationary processes . under further restrictions on the processes , this type of model was studied in robinson @xcite , orbe _ et al . _",
    "@xcite among others .",
    "( endogenous model ) .",
    "assume ( [ eqnonstatioanrymodelce ] ) .",
    "note that in this case the errors are correlated with the regressors since they both depend on inputs @xmath52 .",
    "this type of model is suitable when the errors exhibit heteroscedasticity with respect to time and the regressors . when @xmath68 and @xmath69 are stationary , the case was considered in cai @xcite among others .",
    "write @xmath70 and @xmath71 . for a generic locally stationary time series @xmath72 .",
    "the strength of the temporal dependence in @xmath73 can be measured by how strongly the ` current ' observation of the time series , @xmath74 , is influenced by the innovation @xmath75 which occurred @xmath76 steps ahead .",
    "more specifically , we can define @xmath77 and @xmath78 is an i.i.d .",
    "copy of @xmath79 .",
    "implementing the idea of coupling , @xmath80 measures the effect of @xmath75 in generating observations that are @xmath81 steps away .",
    "therefore , if @xmath80 decays fast as @xmath81 gets large , short range dependence is implied .",
    "we refer to zhou and wu @xcite for more discussions and examples on the above dependence measures .",
    "for a family of stochastic processes @xmath82 , we say that it is @xmath83 stochastic lipschitz continuous on @xmath14 $ ] if @xmath84 < \\infty$ ] .",
    "denote by @xmath85 the collection of such systems .",
    "let @xmath86 be the collection of processes @xmath82 such that @xmath87 for all @xmath88 $ ] .",
    "let @xmath89 , @xmath90 , be the collection of functions that have @xmath91th order continuous derivatives on the interval @xmath92 .",
    "we shall make the following assumptions :    let @xmath93 be the @xmath94 matrix with @xmath95th entry @xmath96 $ ] .",
    "assume that the smallest eigenvalue of @xmath93 is bounded away from @xmath97 on @xmath14 $ ] and @xmath98 $ ] .",
    "@xmath99 for some @xmath100 .",
    "@xmath101 .",
    "@xmath102 .",
    "@xmath103 .",
    "@xmath104 for some @xmath105 .",
    "the smallest eigenvalue of @xmath106 is bounded away from @xmath97 on @xmath14 $ ] , where @xmath107    the coefficient functions @xmath108 $ ] , @xmath109 .",
    "a few remarks on the regularity conditions are in order .",
    "conditions ( a1 ) , ( a2 ) and ( a4 ) insures local stationarity and short memory of the regressor process @xmath68 .",
    "the existence of the @xmath110rd moment is for technical convenience only and may be relaxed . the eigenvalue constraint in condition ( a1 )",
    "insures the non - singularity of the design .",
    "conditions ( a3 ) , ( a5 ) and ( a6 ) guarantees the smoothness and short range dependence of the error process @xmath4 .",
    "furthermore , condition ( a7 ) means that the asymptotic covariance matrix of @xmath111 is non - singular .",
    "[ thm1 ] assume that condition holds and that @xmath112 and @xmath113",
    ". then under @xmath114 , we have @xmath115 \\,\\mathrm{d}t+\\frac{nb_n^4\\mu_2^{2}}{4\\mathcal { v}}\\int_0 ^ 1\\bigl [ { \\bolds{\\beta}}''(t)\\bigr]^\\top m(t ) { \\bolds{\\beta}}''(t ) \\,\\mathrm{d}t\\biggr\\}\\rightarrow n\\bigl(0 , \\sigma^2/\\mathcal { v}^2\\bigr),\\end{aligned}\\ ] ] where @xmath116 \\,\\mathrm{d}t,\\ ] ] @xmath117 , @xmath118 , @xmath119 ^ 2 \\,\\mathrm{d}t$ ] , @xmath120 , ` @xmath121 ' is the convolution operator and ` @xmath122 ' denotes the trace of a matrix .",
    "theorem [ thm1 ] reveals the asymptotic behavior of the glrt for a very wide class of predictor and error processes .",
    "in particular , the latter theorem explains when and why the wilks phenomenon fails . in the following",
    ", we will consider four special cases to see how endogeneity , non - stationarity and temporal dependence influence the wilks phenomenon . to simplify the discussion ,",
    "we will assume in the examples below that the asymptotic bias effect , @xmath123^\\top m(t){\\bolds{\\beta}}''(t ) \\,\\mathrm{d}t$ ] , is asymptotically negligible in ( [ eqnull ] ) .",
    "in practice , the latter task can be achieved by pre - whitening .",
    "we will discuss bias reduction techniques for glrt in section  [ secbandwidth ] .",
    "[ ex1 ] consider the case when @xmath124 and @xmath125 , where @xmath126 is a positive constant . in this case , the covarites and errors are two independent i.i.d . sequences and the conditions in fan , zhang and zhang @xcite are satisfied .",
    "note that @xmath127 , @xmath128 and @xmath129 , where @xmath130 is the @xmath94 identity matrix .",
    "in particular , @xmath131 \\,\\mathrm{d}t/\\mathcal { v}=p\\quad \\mbox{and}\\quad \\int_{0}^1 { \\operatorname{tr}}\\bigl[h(t)^2\\bigr ] \\,\\mathrm{d}t/\\mathcal { v}^2=p\\ ] ] in ( [ eqnull ] ) .",
    "hence , it is easy to check that @xmath132 which coincides with theorem 5 of fan , zhang and zhang @xcite and the wilks phenomenon holds .",
    "[ ex2 ] in this case @xmath133 and @xmath134 , where @xmath126 is a positive constant . hence , @xmath7 and @xmath135 are two stationary processes which are independent of each other .",
    "in particular , neither endogeneity nor non - stationary is assumed in the model .",
    "it is easy to see that , in this case , @xmath136{{\\mathbb{e}}}\\bigl[h({\\mathcal{g}}_0 ) h ( { \\mathcal{g}}_i)\\bigr],\\ ] ] @xmath127 and @xmath137 $ ] .",
    "an important observation is that @xmath138 \\,\\mathrm{d}t/ \\mathcal { v } = { \\operatorname{tr}}\\biggl(\\bigl\\{{{\\mathbb{e}}}\\bigl[\\mathbf{g}({\\mathcal{f}}_0 ) \\mathbf { g}^{\\top}({\\mathcal{f}}_0)\\bigr]\\bigr\\}^{-1}\\!\\sum _ { i=-\\infty}^{\\infty}\\!{{\\mathbb{e}}}\\bigl[\\mathbf{g}({\\mathcal{f}}_0 ) \\mathbf { g}^{\\top}({\\mathcal{f}}_i)\\bigr]{{\\mathbb{e}}}\\bigl[h({\\mathcal{g}}_0 ) h({\\mathcal{g}}_i)\\bigr ] \\biggr ) , \\\\ & & \\!\\!\\int_{0}^1\\",
    "! { \\operatorname{tr}}\\bigl[h(t)^2\\bigr ] \\,\\mathrm{d}t/\\mathcal { v}^2 = { \\operatorname{tr}}\\biggl(\\biggl[\\!\\bigl\\{{{\\mathbb{e}}}\\bigl[\\mathbf{g}({\\mathcal{f}}_0 ) \\mathbf{g}^{\\top } ( { \\mathcal{f}}_0)\\bigr]\\bigr\\}^{-1}\\!\\sum_{i=-\\infty}^{\\infty}\\ ! { { \\mathbb{e}}}\\bigl[\\mathbf{g}({\\mathcal{f}}_0 ) \\mathbf{g}^{\\top } ( { \\mathcal{f}}_i)\\bigr]{{\\mathbb{e}}}\\bigl[h({\\mathcal{g}}_0 ) h({\\mathcal{g}}_i)\\bigr ] \\biggr]^{\\!2 } \\biggr)\\end{aligned}\\ ] ] are no longer nuisance parameter free compared with the results in ( [ eqpivotal ] ) . as a consequence , the wilks phenomenon fails to hold in this case .",
    "additionally , it is easy to see that the latter loss of pivotality is due to the fact that the summands in ( [ eqstationarylrt ] ) are generally nonzero for @xmath139 , which is caused by the temporal dependence .",
    "indeed , if the summands are zero for @xmath139 in ( [ eqstationarylrt ] ) , then @xmath140 $ ] and we have ( [ eqpivotal ] ) .",
    "like in many pivotal tests such as the wald test , the term @xmath141 in the glrt serves as a scaling device which cancels out the variance factor in @xmath142 and makes the test pivotal in the i.i.d . case .",
    "however , as shown above , @xmath143 fails to fulfill the latter scaling task under dependence .",
    "[ ex3 ] let @xmath144 and @xmath145 . here",
    "@xmath7 and @xmath146 are two independent but non - stationary sequences which are independent of each other . in this case",
    ", we have @xmath147 \\,\\mathrm{d}t/\\mathcal { v}=p\\quad \\mbox{and}\\quad \\int_{0}^1 { \\operatorname{tr}}\\bigl[h(t)^2\\bigr ] \\,\\mathrm{d}t/\\mathcal { v}^2=p \\frac{\\int_0 ^ 1v^4(t ) \\,\\mathrm{d}t}{(\\int_0 ^ 1v^2(t ) \\,\\mathrm{d}t)^2}.\\end{aligned}\\ ] ] note that the second term in ( [ eqnon - stati ] ) depends on the time - varying variance @xmath148 and hence the wilks phenomenon fails to hold in this case . additionally , observe that @xmath149 and the equation holds if and only if @xmath150 is a constant function . compared with the results in ( [ eqpivotal ] ) ,",
    "we conclude that , in this case , non - stationarity in the errors tends to inflate the variance of glrt .",
    "furthermore , if @xmath135 has constant variance , then the wilks phenomenon holds even if @xmath7 is a non - stationary sequence .",
    "[ ex4 ] suppose that @xmath124 and @xmath151 . in this case",
    "@xmath7 and @xmath135 are two i.i.d .",
    "sequences which are dependent of each other .",
    "we obtain @xmath152 \\,\\mathrm{d}t/ \\mathcal { v}&=&{\\operatorname{tr}}\\bigl(\\bigl\\{{{\\mathbb{e}}}\\bigl[\\mathbf{g}(\\epsilon _ 0)\\mathbf { g}^{\\top}(\\epsilon_0)\\bigr]\\bigr\\}^{-1}{{\\mathbb{e}}}\\bigl [ \\mathbf{g}(\\epsilon_0)\\mathbf{g}^{\\top } ( \\epsilon_0)v^2 ( \\epsilon_0)\\bigr ] \\bigr)/{{\\mathbb{e}}}\\bigl[v^2(\\epsilon_0 ) \\bigr ] , \\\\",
    "\\int_{0}^1{\\operatorname{tr}}\\bigl[h(t)^2 \\bigr ] \\,\\mathrm{d}t/\\mathcal { v}^2&=&{\\operatorname{tr}}\\bigl(\\bigl[\\bigl\\{{{\\mathbb{e}}}\\bigl [ \\mathbf{g}(\\epsilon_0)\\mathbf{g}^{\\top}(\\epsilon_0 ) \\bigr]\\bigr\\}^{-1}{{\\mathbb{e}}}\\bigl[\\mathbf{g}(\\epsilon_0 ) \\mathbf{g}^{\\top } ( \\epsilon_0)v^2 ( \\epsilon_0)\\bigr]\\bigr]^2 \\bigr)/\\bigl({{\\mathbb{e}}}\\bigl[v^2(\\epsilon_0)\\bigr]\\bigr)^2.\\end{aligned}\\ ] ] note that if @xmath153={{\\mathbb{e}}}[\\mathbf{g}(\\epsilon_0)\\mathbf{g}^{\\top } ( \\epsilon_0)]{{\\mathbb{e}}}[v^2(\\epsilon_0)]$ ] , then we have ( [ eqpivotal ] ) and hence the wilks phenomenon .",
    "due to the dependence of @xmath154 and @xmath155 , the latter factorization generally fails and hence the wilks phenomenon fails to hold in this case .    in many real applications ,",
    "one is interested in specifying a component of @xmath11 .",
    "for instance , one may want to test whether @xmath156 is significantly different from zero .",
    "this leads us to consider the following hypothesis testing problem where both @xmath157 and @xmath158 are nonparametric : @xmath159 where @xmath160 @xmath161 , @xmath162 and @xmath163 are @xmath164 dimensional and @xmath162 is a known function .",
    "define @xmath165^{\\top}\\mathbf{x}_{i}^{(1)}$ ] .",
    "then under @xmath157 the functions @xmath166 , @xmath167 can be estimated by the local linear regression of @xmath168 on @xmath169 with bandwidth @xmath36 . throughout the paper",
    "we assume that the bandwidth @xmath36 used under @xmath157 is the same as that under @xmath158 .",
    "asymptotic results can be easily obtained using the arguments of the paper when the two bandwidths are different .",
    "the resulting asymptotic bias and variance are much more complicated . for the sake of presentational clarity",
    ", we will only consider the case of equal bandwidth .",
    "the glrt statistic for testing @xmath157 against @xmath158 is defined as @xmath170\\approx-\\frac{n}{2}\\frac{\\rss _",
    "a-\\rss_1}{\\rss_0},\\end{aligned}\\ ] ] where @xmath171 is the rss under @xmath157 .",
    "write @xmath172 where @xmath173 and @xmath174 are of dimension @xmath175",
    ".    define @xmath94 matrix @xmath176 .",
    "we have the following theorem .    [ thm2 ]",
    "assume that condition holds and that @xmath112 and @xmath113",
    ". then under @xmath157 , we have @xmath177 \\,\\mathrm{d}t+ \\frac{nb_n^4\\mu_2^{2}}{4\\mathcal { v}}\\int_0 ^ 1\\upsilon(t ) \\ ,",
    "\\mathrm{d}t\\biggr\\ } \\rightarrow n\\bigl(0,\\sigma_1 ^ 2/ \\mathcal { v}^2\\bigr),\\end{aligned}\\ ] ] where @xmath178 , @xmath179^\\top m(t){\\bolds{\\beta}}''(t)-\\{[{\\bolds{\\beta}}^{(2)}(t)]''\\}^\\top m_{22}(t)[{\\bolds{\\beta}}^{(2)}(t)]''$ ] and @xmath180 \\,\\mathrm{d}t.\\ ] ]    theorem [ thm2 ] unveils the asymptotic null distribution of the test under @xmath157 .",
    "following very similar arguments as those in examples  [ ex1][ex4 ] , the wilks phenomenon can be shown to be sensitive to non - stationary , temporal dependence and endogeneity in this case as well .",
    "practitioners and researchers often encounter testing problems where the null is specified up to a parametric part . for instance , one may want to test whether @xmath11 is really time varying in model  ( [ eqmodel ] ) , which amounts to testing @xmath181 for some unspecified constant vector @xmath126 .",
    "heuristically , since the convergence rate of the local linear estimates is always slower than the @xmath182 parametric rate , it is expected that the null distribution will not be altered as long as we plug in a @xmath182 consistent estimate of the unspecified parametric part .",
    "the following discussion rigorously confirms the intuition .",
    "consider testing @xmath183 where @xmath184 is a parametric family of smooth functions .",
    "let @xmath185 and @xmath186 be the residual sum of squares of the local linear regression of @xmath187 on @xmath169 with bandwidth @xmath36 .",
    "we shall make the following assumptions on the parametric family @xmath188 and the estimate @xmath189 :    for each @xmath50 $ ] , @xmath190 is @xmath191 in @xmath192 in a neighborhood @xmath193 of @xmath194 . additionally , @xmath195,\\theta\\in\\theta } \\biggl\\ { \\biggl|\\frac{\\partial{\\bolds{\\beta}}^{(1)}_{0}(t,\\theta)}{\\partial\\theta } \\biggr|+ \\biggl|\\frac{\\partial^2 { \\bolds{\\beta}}^{(1)}_{0}(t,\\theta)}{\\partial\\theta^2 } \\biggr| \\biggr\\}<\\infty.\\ ] ]    under @xmath196 , @xmath197 .",
    "[ propequasemi ] under @xmath196 , condition and the assumptions of theorem [ thm2 ] , we have @xmath198    the @xmath199 term on the left - hand side of ( [ eqequasemi ] ) corresponds to the extra bias introduced by the estimation error of @xmath192 .",
    "and the @xmath200 term on the right - hand side of ( [ eqequasemi ] ) corresponds to the extra variance caused by the latter error .",
    "both terms are asymptotically negligible compared to the @xmath201 bias and @xmath202 variance of @xmath171 . as a consequence , the results of theorems [ thm1 ] and [ thm2 ] continues to hold if @xmath192 is replaced by @xmath189 .",
    "[ proplocalpower ] assume the alternative @xmath203 , where @xmath204 $ ] .",
    "further assume that @xmath205 for some @xmath206 , that @xmath207 and that @xmath208^\\top m(t)\\mathbf{f}_n''(t ) \\,\\mathrm{d}t",
    "\\rightarrow f_2\\end{aligned}\\ ] ] for some finite constants @xmath209 and @xmath210 .",
    "then under condition , we have @xmath211 \\,\\mathrm{d}t \\biggr \\}+\\frac{c^{9/2}\\mu_2^{2}}{4\\mathcal { v}}\\int_0 ^ 1\\bigl [ { \\bolds{\\beta}}''(t)\\bigr]^\\top m(t ) { \\bolds{\\beta}}''(t ) \\,\\mathrm{d}t+\\frac{c^{9/2}\\mu_2^{2}}{4\\mathcal { v}}f_2 -\\frac{c^{1/2}}{\\mathcal { v}}f_1\\\\ \\hspace*{-4pt}&&\\quad\\rightarrow n\\bigl(0,\\sigma^2/ \\mathcal { v}^2\\bigr).\\end{aligned}\\ ] ]    when the errors and regressors are weakly dependent locally stationary time series , proposition [ proplocalpower ] claims that the glrt can still detect local alternatives with the optimal rate @xmath212 in the sense of ingster @xcite . as a consequence ,",
    "the glrt is powerful to apply for nonparametric model validation of model ( [ eqmodel ] ) under non - stationarity and dependence .",
    "however , it should be noted that the glrt may not be the most powerful among all rate optimal tests . in the literature , among other examples",
    ", zhang and dette @xcite discovered that other tests may yield smaller variance than the glrt for independent samples .",
    "from proposition [ proplocalpower ] , the asymptotic local power of the glrt with level @xmath213 @xmath214 @xmath215 and @xmath216 denote the cumulative distribution function and the @xmath217 quantile of the standard normal distribution .",
    "assume that @xmath218 and @xmath219 , then simple calculations show that the bandwidth which maximizes the above power is @xmath220    a typical example which satisfies @xmath218 and @xmath219 is when @xmath221 , where @xmath222 $ ] , @xmath223 and @xmath224 .",
    "simple calculations show that @xmath225^\\top m(t_0)\\mathbf{f}''(t ) \\,\\mathrm{d}t.\\end{aligned}\\ ] ] hence @xmath218 and @xmath219 as long as the corresponding terms in ( [ eqinte ] ) are nonzero .",
    "consider the testing problem ( [ eqsimplenull ] ) .",
    "two important observations lead to the following modifications of the original glrt when testing for non - stationary time series .",
    "first , as shown in examples  [ ex2][ex4 ] , the denominator @xmath143 is redundant when testing for non - stationary time series .",
    "second , as we discussed in the , averaging the test over a range of bandwidths can reduce the sensitivity of the test with respect to the selection of bandwidth and may also gain power over tests based on a single ( optimal ) bandwidth . based on the above discussions , we suggest using the following averaged test when specifying model ( [ eqmodel ] ) for non - stationary time series : @xmath226 where @xmath227 is the rss under @xmath228 when bandwidth is chosen as @xmath229 , @xmath230 .",
    "large @xmath231 indicates evidence against @xmath114 . in the literature ,",
    "nonparametric anova tests ignoring the denominator were first proposed in dette @xcite for independent samples .",
    "dette and hetzler  @xcite also considered averaged nonparametric specification tests over a range of bandwidths .",
    "the following theorem derives the asymptotic null distribution of the averaged test .",
    "[ thmnewtest ] assume that condition holds and that @xmath232",
    ". then under @xmath114 , we have @xmath233\\int _ { 0}^1{\\operatorname{tr}}\\bigl[h(t)\\bigr ] \\,\\mathrm{d}t \\\\ & & \\quad\\qquad{}+ \\frac{n^{1 - 4\\gamma}\\mu_2^{2}(c_{\\max}^5-c_{\\min}^5)}{20}\\int _ 0 ^ 1\\bigl [ { \\bolds{\\beta}}''(t)\\bigr]^\\top m(t ) { \\bolds{\\beta}}''(t ) \\,\\mathrm{d}t \\biggr\\}\\rightarrow n \\bigl(0,\\bigl(\\sigma^*\\bigr)^2\\bigr),\\end{aligned}\\ ] ] where @xmath234 \\,\\mathrm{d}t\\quad\\mbox { and}\\\\ q(x , y)&=&\\int_{c_{\\min}}^{x } \\bigl[2k(y / z)-k\\ast k(y / z)\\bigr]/z \\,\\mathrm{d}z.\\end{aligned}\\ ] ]    now we consider the local power of @xmath231 under the alternative @xmath235 specified in proposition  [ proplocalpower ] . by theorem [ thmnewtest ] and similar arguments as those of proposition [ proplocalpower ] ,",
    "it is easy to show that the asymptotic local power of @xmath231 with level @xmath213 @xmath236 \\\\[-8pt ] \\eqntext{\\mbox{where } \\displaystyle r_2= \\frac{(c_{\\max}-c_{\\min})f_1-(c^5_{\\max}-c^5_{\\min})\\mu _ 2 ^ 2f_2/20}{\\sigma^*}.\\qquad\\qquad}\\end{aligned}\\ ] ] suppose that @xmath237 is asymptotically unbiased ; namely @xmath238 . from ( [ powernewtest ] ) and ( [ powerglrt ] )",
    ", we observe that @xmath231 is asymptotically more powerful than @xmath237 if and only if @xmath239 .",
    "simple calculations show that @xmath240\\sqrt{\\int_{{{\\mathbb{r}}}}\\tilde{k}^2(t ) \\,\\mathrm { d}t}}{[c^{1/2}f_1-c^{9/2}\\mu_2 ^ 2f_2/4]\\sqrt{\\int_{{{\\mathbb{r}}}}q^2(c_{\\max } , t ) \\,\\mathrm{d}t}}.\\end{aligned}\\ ] ] an interesting observation from the above equation is that @xmath241 does not depend on the dependence or the non - stationarity structure of the data .",
    "furthermore , we have the following result .    [ proppower ] under @xmath235 and the assumptions of proposition [ proplocalpower ]",
    ", we have @xmath242    proposition [ proppower ] claims that , asymptotically , the averaged test @xmath231 is at least as powerful as the test which is based on the maximum generalized likelihood ratio .",
    "the result is very general in the sense that it does not depend on the nature of the local alternative @xmath243 , the dependence structure of the data or the kernel function .",
    "when we restrict ourselves to a specific kernel function , the power comparison can be more exact .",
    "let us consider the following example :     as a function of @xmath244 in example [ expower ] . the uniform kernel is used . ]",
    "[ expower ] suppose that @xmath237 is asymptotically unbiased and that the bandwidth for @xmath237 is chosen as @xmath245 .",
    "let @xmath246 for some fixed @xmath247 and let @xmath248 such that @xmath249 solves the equation @xmath250 .",
    "choosing @xmath251 in the latter way insures that @xmath209 and @xmath210 do not enter the ratio @xmath241 and hence the power comparison is relatively simple .",
    "now simple calculations show that @xmath252/z \\,\\mathrm{d}z ) ^2 \\,\\mathrm{d}y}}.\\end{aligned}\\ ] ] an application of the cauchy ",
    "schwarz inequality similar to the proof of proposition [ proppower ] shows that @xmath253 regardless of the kernel function .",
    "now let us consider the uniform kernel @xmath254 .",
    "figure [ fidpower ] shows @xmath241 as a function of @xmath244 .",
    "we observe from the figure that the averaged test @xmath231 is asymptotically more powerful than @xmath237 on @xmath255 regardless of the shape of the alternative .",
    "figure [ fidpower ] further supports the use of the averaged test .",
    "as we see from theorem [ thmnewtest ] , the asymptotic bias of @xmath231 involves the second derivative of @xmath256 and the estimation of the latter quantity is generally highly nontrivial .",
    "following the idea of fan and jiang @xcite , a prewhitening technique can be used to alleviate the problem .",
    "more specifically , consider the following null hypothesis : @xmath257 where @xmath258 is a parametric family of smooth functions .",
    "let @xmath259 be a @xmath182 consistent estimator of @xmath260 and define @xmath261 . then by the similar arguments as those of proposition [ propequasemi ]",
    ", the asymptotic bias and variance of estimating @xmath260 is negligible in the current setting and hence testing @xmath262 is equivalent to testing @xmath263 then we can perform @xmath231 to testing @xmath264 with transformed regression coefficients @xmath265 and response @xmath266 .",
    "note that the local linear estimator of @xmath265 has no bias under @xmath267 and we can avoid the notorious problem of bias estimation .    as mentioned in fan and jiang @xcite , a choice of larger bandwidth favors smoother alternatives and a smaller bandwidth tends to detect less smooth alternatives .",
    "thanks to the introduction of the averaged test , the sensitivity of the test to the choice of bandwidth is alleviated due to the introduction of a group of bandwidths .",
    "on the other hand , the correlation of @xmath237 between nearby bandwidths are usually quite high and hence in practice one only needs to average the test over a grid of relatively separated bandwidths .",
    "zhang @xcite found that the correlation between @xmath268 and @xmath269 is quite high for @xmath270 .",
    "as suggested by fan and jiang @xcite , here we recommend choosing the grid of three bandwidths @xmath271 , @xmath272 and @xmath273 to represent small , medium and large bandwidths and average the test over the latter grid . here",
    "@xmath274 and @xmath275 is the optimal bandwidth for nonparametric curve estimation .",
    "a direct implementation of the asymptotic distribution in theorem [ thmnewtest ] may not perform satisfactorily in practice due to the following two reasons .",
    "first , the convergence rate of test statistic equals @xmath276 when bandwidth @xmath36 is chosen optimally .",
    "the rate is quite slow and hence the asymptotic approximation may not be accurate for moderate samples .",
    "second , as we can see from the proof of lemma [ lemasy5 ] in section [ secproofs ] , the asymptotic normal approximation is particularly rough at the boundaries of the time interval for finite samples . as a remedy , we observe the following proposition .    [ propwildboots ] let the bandwidth range be @xmath277 $ ] for some @xmath230 .",
    "suppose that either ( 1 ) : @xmath13 is a linear function or ( 2 ) : @xmath278 . then under @xmath114 , condition   and the assumption that @xmath279 , on a possibly richer probability space , there exist i.i.d .",
    "@xmath280-dimensional standard gaussian random vectors @xmath281 , such that @xmath282 where @xmath283^{-1}\\tilde { \\mathbf{t}}_{n , n(s)}(t_i)-\\sum_{i=1}^n \\bigl[\\mathbf { z}^{\\top}_i\\bigl[{{\\mathbb{e}}}\\mathbf { s}_{n ,",
    "n(s)}(t_i)\\bigr]^{-1}\\tilde { \\mathbf{t}}_{n , n(s)}(t_i)\\bigr]^2 \\biggr\\ } \\ , \\mathrm{d}s\\end{aligned}\\ ] ] with @xmath284 , @xmath285 , @xmath286 , @xmath287 and @xmath288^l k_{b}(t_i - t),\\qquad l=0,1.\\end{aligned}\\ ] ]    proposition [ propwildboots ] follows easily from ( [ eq1 ] ) and lemma [ lemasy3 ] in section [ secproofs ] .",
    "details are omitted .",
    "the latter proposition claims that @xmath231 can be well approximated by a gaussian quadratic form @xmath289 .",
    "in particular , we observe from the proofs in section [ secproofs ] that the approximation is accurate at the boundaries due to the fact that it directly mimics the form of the test statistic .",
    "when implementing  @xmath290 , we recommend generating a large ( say of size 1000 ) sample of i.i.d . copies of @xmath289 and use the resulting empirical distribution to approximate that of @xmath290 under the null hypothesis and obtain the @xmath280-value of the test .    as we suggested in section [ secbandwidth ] , in practice , one usually uses a grid of bandwidths @xmath291 and calculate @xmath292 . to perform wild bootstrap in those cases ,",
    "one compares @xmath293 to the simulated quantiles of @xmath294^{-1}\\tilde { \\mathbf{t}}_{n , b_j}(t_i)-\\sum_{i=1}^n \\bigl[\\mathbf { z}^{\\top}_i\\bigl[{{\\mathbb{e}}}\\mathbf { s}_{n , b_j}(t_i)\\bigr]^{-1}\\tilde { \\mathbf{t}}_{n , b_j}(t_i)\\bigr]^2 \\biggr\\}\\end{aligned}\\ ] ] to calculate the @xmath280-value of the test . in section [ secsimu ] , we shall conduct a simulation study to compare the finite sample performance of the wild bootstrap and the direct implementation of the asymptotic distribution .",
    "if one is interested in the semiparametric testing problem @xmath157 versus @xmath158 in ( [ eqseminull ] ) , then the corresponding averaged test is    @xmath295    write @xmath296^{\\top},[\\varepsilon ^{(2)}_{i}]^\\top)^{\\top}$ ] and @xmath297^{\\top } , [ v^{(2)}_{i}]^\\top)^{\\top}$ ] , where @xmath298 and @xmath299 are @xmath300 dimensional .",
    "define @xmath301 , @xmath302 , @xmath303 , @xmath304 , @xmath305 , @xmath306 , @xmath307 and @xmath308 in the same way as their counterparts without the superscript @xmath309 with @xmath68 , @xmath4 , @xmath106 and @xmath310 therein replaced by @xmath311 , @xmath312 , @xmath313 and @xmath314 , respectively .",
    "we have the following proposition .",
    "[ propwildbootscomplex ] suppose that @xmath315 .",
    "then under @xmath157 and condition , on a possibly richer probability space , there exist i.i.d .",
    "@xmath280-dimensional standard gaussian random vectors @xmath281 , such that @xmath316    note that @xmath317 is a quadratic form of @xmath318 . by proposition [ propwildbootscomplex ] , in practice , one could generate a large sample of i.i.d .",
    "copies of @xmath317 to obtain the @xmath280-value of testing @xmath157 .      by lemma [ lemsninv ] in section [ secproofs ] , @xmath319 in proposition [ propwildboots ] can be well approximated by @xmath320 .",
    "therefore , in order to implement the wild bootstrap , one only needs to estimate the long - run covariance matrix @xmath321 .",
    "here we suggest using the local lag window estimate of @xmath322 proposed in zhou and wu @xcite . for the sake of completeness",
    ", we will briefly introduce the estimator here .",
    "we refer to the latter paper for more details including the derivation of convergence rates of the estimator and the choice of smoothing parameters .",
    "define @xmath323 , where @xmath324 s are the residuals under the alternative . for a window size @xmath325 and a bandwidth @xmath326 ,",
    "@xmath327 can be estimated by @xmath328 and @xmath329 .",
    "zhou and wu @xcite showed that @xmath330 is always positive semidefinite and has convergence rate @xmath331 when @xmath332 and @xmath333 .",
    "in this section , we shall design simulations to study the accuracy of the wild bootstrap procedure of the paper and compare it with that of the bootstrap procedure of fan and jiang @xcite and the method of direct implementation of the asymptotic distribution in ( [ eqnull ] ) .",
    "let us consider the following model @xmath334 and the test @xmath335 .",
    "the following four scenarios are considered in order to investigate the effects of endogeneity , non - stationarity and temporal dependence .    in this case",
    "@xmath336 s are i.i.d .",
    "exponential random variables with mean 1 and @xmath4 s are i.i.d .",
    "standard normal .",
    "the two processes @xmath337 and @xmath135 are independent . the latter design satisfies the conditions in fan , zhang and zhang @xcite and hence it is expected that the bootstrap procedure in fan and jiang @xcite will work in this case .    in this scenario",
    "@xmath336 s are i.i.d .",
    "exponential random variables with mean 1 and @xmath338 , where @xmath339 s are i.i.d .",
    "standard normal and are independent of @xmath337 . in scenario ( b ) we are interested in investigating the effect of endogeneity on the behavior of glrt .",
    "let @xmath336 s be independent student @xmath61 random variables and the degrees of freedom of @xmath340 .",
    "let @xmath341 , where @xmath339 s are i.i.d .",
    "standard normal .",
    "further let @xmath336 s and @xmath4 s be independent .",
    "note that @xmath8 is a locally stationary process with time - varying variance and @xmath337 is locally stationary process with smoothly varying tail index . in this case",
    ", we are investigating the effect of non - stationarity on the behavior of glrt .",
    "let @xmath342 , where @xmath343 s are i.i.d .",
    "standard normal .",
    "let @xmath344 , where @xmath339 s are i.i.d .",
    "standard normal .",
    "further let @xmath345 be independent of @xmath346 .",
    "note @xmath337 and @xmath8 are two stationary weakly dependent processes . in this case",
    "we are interested in investigating the effect of temporal dependence on the behavior of glrt .",
    "we consider two different sample sizes , @xmath347 and @xmath348 .",
    "we compare three different methods , namely the robust wild bootstrap test ( [ eqwildboots ] ) ( wild ) , test based on the asymptotic distribution ( [ eqnull ] ) ( asym ) and the residual bootstrap test of fan and jiang @xcite ( iid ) . both the single bandwidth test @xmath237 in ( [ eqglrtoriginal ] ) and the suggested averaged test @xmath290 in ( [ eqtest ] ) are considered . for the averaged test , the bandwidth ranges are selected as @xmath349 $ ] according to the discussion in section [ secbandwidth ] . to investigate the sensitivity of the accuracy of the wild bootstrap method on the choice of bandwidth , three different bandwidths , namely @xmath350 and @xmath351 are considered in the simulation .",
    "based on 500 replications , the simulated type i error rates at @xmath352 nominal level are summarized in table [ tab1 ] below.=1    @lld2.1d2.2d2.1d2.1d2.1d2.1d2.1d2.1@ & & & + & & & + & & & & & & & & & +   + wild & @xmath353 & 7.5 & 7.4 & 10.4 & 7.1 & 8.1 & 8 & 9.7 & 9.1 + wild & @xmath354 & 8.5 & 8.15 & 10.2 & 7.7 & 8.5 & 8.4 & 9.8 & 9.7 + wild & @xmath355 & 8.9 & 8.7 & 10 & 7.7 & 8.7 & 9.1 & 9.2 & 9.8 + asym & @xmath353 & 35.4 & 14.4 & 18.8 & 28.2 & 38.3 & 18.5 & 15.0 & 33 + asym & @xmath354 & 39.1 & 18.5 & 19.4 & 33.3 & 39.9 & 21.2 & 17.8 & 36.3 + asym & @xmath355 & 44.1 & 21.4 & 18.0 & 36.2 & 44.5 & 23.8 & 20.7 & 38.4 + iid & @xmath353 & 10.4 & 83.6 & 20.5 & 68.8 & 11.9 & 87.7 & 15.7 & 73.3 + iid & @xmath354 & 11.4 & 79.6 & 19.1 & 61.9 & 9.9 & 82.7 & 17.9 & 63.8 + iid & @xmath355 & 11.0 & 74.3 & 17.8 & 55.9 & 10.2 & 78.8 & 19.8 & 56.8 +   + wild & @xmath356 & 5.0 & 5.8 & 10.2 & 5.8 & 8.6 & 7.2 & 11.2 & 9.4 + wild & @xmath357 & 8.2 & 7.8 & 9.4 & 8.8 & 9.2 & 8.2 & 10.2 & 11.6 + wild & @xmath358 & 9.8 & 9.2 & 9.0 & 8.2 & 11.2 & 9.6 & 11.2 & 11.4 + asym & @xmath356 & 32.2 & 13.2 & 17.8 & 27.8 & 27.4 & 16.8 & 13.8 & 30 + asym & @xmath357 & 36.2 & 19.6 & 20.4 & 36.8 & 29 & 20.2 & 16.8 & 36.6 + asym & @xmath358 & 43.6 & 21.2 & 20.4 & 38.8 & 34 & 22 & 18 & 38 + iid & @xmath356 & 8.2 & 86.8 & 20.8 & 73.2 & 10.8 & 89 & 15.2 & 76.2 + iid & @xmath357 & 7.8 & 82.2 & 20.6 & 63 & 9.4 & 80.2 & 18 & 63.4 + iid & @xmath358 & 10.4 & 76.2 & 17.4 & 55.6 & 12 & 77.2 & 17.8 & 56.6 +    we observe from table [ tab1 ] that , for the robust wild bootstrap , the simulated type i errors of the averaged test and the single bandwidth test are reasonably close to the nominal and the performance is stable for all four cases when @xmath359 . for @xmath347 ,",
    "the robust bootstrap is slightly anti - conservative in cases ( a ) , ( b ) and ( d ) for small bandwidths .",
    "as we expected , the averaged test performs more stably than the single bandwidth test . on the other hand",
    ", we observe that tests based on the asymptotic distribution do not perform well for moderately large samples . as we discussed in section [ secwildboots ] , the reason is due to the slow convergence of the test statistic and the rough approximation of the asymptotic distribution at the boundaries .",
    "the residual wild bootstrap performs slightly better than our robust wild bootstrap for i.i.d .",
    "data without endogeneity .",
    "however , we observe that the residual bootstrap is no longer consistent under non - stationarity , temporal dependence or endogeneity , which is consistent with our theoretical findings.=1",
    "note that under the null hypothesis @xmath114 , @xmath360 on the other hand , by ( [ eqsol ] ) , @xmath361 where @xmath362 , and @xmath363^l k_{b_n}(t_i - t),\\qquad   l=0,1 , \\ldots\\end{aligned}\\ ] ] with @xmath364 . in ( [ eqthm11 ] ) , @xmath365 corresponds to the bias of the local linear estimate at time @xmath61 .",
    "lemmas [ lembias1 ] and [ lembias2 ] below control the asymptotic influence of the bias term @xmath366 on @xmath367 .    [ lembias1 ] define @xmath368 , where @xmath369 is the column vector of @xmath280 zeros . under condition",
    ", we have @xmath370 , where @xmath371 .    by ( [ eqp1 ] ) and ( [ eqthm11 ] ) ,",
    "we have @xmath372 define @xmath373 $ ] and @xmath374 . using the facts that @xmath375 and @xmath376 and",
    "@xmath377 are orthogonal for @xmath378 , elementary calculations show that @xmath379\\\\[-2pt ] & & \\hspace*{54pt}{}\\times v(t_i , { \\mathcal{f}}_i)\\mathbf { s}^{-1}_n(t_i ) \\mathbf{b}_n(t_i)v(t_j,{\\mathcal{f}}_j ) \\mathbf{s}^{-1}_n(t_j)\\mathbf { b}_n(t_j).\\end{aligned}\\ ] ] let @xmath380 if @xmath381 . note that @xmath382\\bigr|&\\le & \\sum_{k=-\\infty}^n \\bigl\\|{\\mathcal{p}}_kh(t_i,{\\mathcal{g}}_i)\\bigr\\|\\bigl\\|{\\mathcal{p}}_kh(t_j , { \\mathcal{g}}_j)\\bigr\\| \\\\[-2pt ] & \\le&\\sum_{k=-\\infty}^n\\delta_h(i - k,2 ) \\delta_h(j - k,2 ) \\\\[-2pt ] & \\le & c\\bigl(|i - j|+1\\bigr)^{-2}.\\end{aligned}\\ ] ] on the other hand , by lemma [ lemsninv ] , the hlder s inequality and similar arguments as those of lemma 6 in zhou and wu @xcite , we have @xmath383 & & \\quad\\le\\bigl\\|v(t_i,{\\mathcal{f}}_i)\\bigr\\|_{4}\\bigl\\| \\mathbf{s}^{-1}_n(t_i)\\bigr\\|_{8}\\bigl\\| \\mathbf { b}_n(t_i)\\bigr\\|_8\\bigl\\|v(t_j , { \\mathcal{f}}_j)\\bigr\\|_{4}\\bigl\\|\\mathbf{s}^{-1}_n(t_j ) \\bigr\\|_8\\bigl\\|\\mathbf { b}_n(t_j)\\bigr\\|_8\\le cb_n^4.\\end{aligned}\\ ] ] therefore , @xmath384 note that @xmath385 .",
    "therefore , this lemma follows .",
    "[ lembias2 ] under condition and the assumption that @xmath386 , we have @xmath387^\\top m(t ) { \\bolds{\\beta}}''(t ) \\,\\mathrm{d}t+\\mathrm{o}_{{\\mathbb{p}}}\\bigl(nb_n^4\\bigr),\\ ] ] where @xmath388 .    by ( [ eqp1 ] ) and ( [ eqthm11 ] )",
    ", we have @xmath389 by lemma [ lemsninv ] and the hlder s inequality , it follows that @xmath390^{-1}\\mathbf{b}_n(t_i)\\bigr \\}^2=\\mathrm{o}_{{\\mathbb{p}}}\\bigl(nb_n^4/ \\sqrt{nb_n}\\bigr).\\ ] ] by condition ( a4 ) and the similar arguments as those in the proof of lemma [ lembias1 ] , we have @xmath391^{-1 } \\mathbf{b}_n(t_i)\\bigr\\}^2-{{\\mathbb{e}}}\\biggl[\\sum _ { i=1}^n\\bigl\\{\\mathbf{z}^{\\top}_i \\bigl[{{\\mathbb{e}}}\\mathbf { s}_n(t_i)\\bigr]^{-1 } \\mathbf{b}_n(t_i)\\bigr\\}^2 \\biggr]=\\mathrm{o}_{{\\mathbb{p}}}\\bigl(\\sqrt{n}b_n^4\\bigr).\\end{aligned}\\ ] ] it is easy to see that , for @xmath392 , @xmath393^{-1}\\mathbf{b}_n(t_i ) \\bigr)^2-b_n^4{{\\mathbb{e}}}\\biggl(\\mathbf{z}^{\\top}_i \\bigl[{{\\mathbb{e}}}\\mathbf{s}_n(t_i)\\bigr]^{-1}\\pmatrix{\\mathbf { s}_{n,2}(t_i ) { \\bolds{\\beta}}''(t_i)/2 \\vspace*{2pt}\\cr \\mathbf { s}_{n,3}(t_i){\\bolds{\\beta}}''(t_i)/2 }   \\biggr)^2=\\mathrm{o}\\bigl(b_n^4 \\bigr).\\ ] ] additionally , by lemma [ lemsninv ] and simple algebra , we have @xmath394^{-1}\\pmatrix{\\mathbf { s}_{n,2}(t_i){\\bolds{\\beta}}''(t_i)/2 \\vspace*{2pt}\\cr \\mathbf { s}_{n,3}(t_i){\\bolds{\\beta}}''(t_i)/2 }   \\biggr)^2=n\\mu^2_2 \\int_0 ^ 1\\bigl[{\\bolds{\\beta}}''(t ) \\bigr]^\\top m(t){\\bolds{\\beta}}''(t ) \\ , \\mathrm{d}t/4+\\mathrm{o}(n).\\end{aligned}\\ ] ] therefore , @xmath395^\\top m(t){\\bolds{\\beta}}''(t ) \\,\\mathrm{d}t/4+\\mathrm{o}_p(nb_n^4)$ ] .",
    "furthermore , @xmath396 recall that @xmath397 . following the similar arguments as those in the proof of lemma [ lembias1 ] , we have @xmath398 .",
    "details are omitted .",
    "hence , the lemma follows .",
    "[ lemasy1 ] under condition and the assumption that @xmath399 , we have @xmath400 where @xmath401^{-1}\\mathbf{t}_n(t_i)$ ] .",
    "let @xmath402 and @xmath403^{-1}$ ]",
    ". then @xmath404 let @xmath405 and @xmath406 .",
    "then by lemma [ lemsninv ] and the similar arguments as those of lemma [ lembias1 ] , it is easy to show that @xmath407 .",
    "note that @xmath408 by the similar arguments as those of lemma [ lembias1 ] , we have @xmath409 and @xmath410 .",
    "therefore , @xmath411 therefore , the lemma follows .",
    "[ lemasy2 ] under condition and the assumption that @xmath412 , we have @xmath413 where @xmath414^{-1}\\mathbf{t}_n(t_i)\\}^2 $ ] .",
    "note that @xmath415 where @xmath416^{-1})\\times \\mathbf{t}_n(t_i)$ ] and @xmath417^{-1})\\mathbf { t}_n(t_i)$ ] .",
    "let @xmath418 for @xmath419 and @xmath420 .",
    "then @xmath421 note that @xmath422^{-1 } \\bigr)k_{b_n}(t_k - t_j)\\pmatrix{\\mathbf{x}_k \\varepsilon_k \\vspace*{2pt}\\cr \\mathbf{x}_k \\varepsilon_k \\bigl[(t_k - t_j)/b_n \\bigr ] } \\\\ & = & r_n^2 \\sum_{k=1}^n\\xi_1(i , k ) \\varepsilon_k+r_n^2\\sum _ { k=1}^n\\xi_2(i , k)\\varepsilon_k,\\end{aligned}\\ ] ] where @xmath423^{-1 } \\bigr)k_{b_n}(t_k - t_j)\\mathbf{z}^{\\top}_k , \\\\",
    "\\xi_2(i , k)&=&\\sum_{j=1}^i \\mathbf{z}^{\\top}_j\\bigl(\\mathbf{s}^{-1}_n(t_j)+ \\bigl[{{\\mathbb{e}}}\\mathbf { s}_n(t_j)\\bigr]^{-1 } \\bigr)k_{b_n}(t_k - t_j ) \\bigl ( \\mathbf{0}^{\\top}_p,\\mathbf{x}^{\\top } _ k \\bigr)^{\\top}.\\end{aligned}\\ ] ] by lemma [ lemsninv ] and the hlder s inequality , @xmath424 . hence by similar conditioning arguments as those in the proof lemma [ lembias1 ] , @xmath425 similarly , @xmath426 . hence , @xmath427 . by similar arguments",
    ", we have @xmath428 therefore @xmath429 the lemma follows .    [ lemasy3 ] under condition and the assumption that @xmath412 , we have @xmath430 where @xmath431^{-1}{{\\mathbb{e}}}[\\mathbf{z}_i\\mathbf{z}^{\\top}_i][{{\\mathbb{e}}}\\mathbf { s}_n(t_i)]^{-1}\\mathbf{t}_n(t_i)$ ] .",
    "note that @xmath432^{-1}\\mathbf{z}_i\\mathbf{z}^{\\top}_i[{{\\mathbb{e}}}\\mathbf { s}_n(t_i)]^{-1}\\mathbf{t}_n(t_i).$ ] therefore @xmath433 where @xmath434^{-1}\\{\\mathbf{z}_i\\mathbf{z}^{\\top}_i-{{\\mathbb{e}}}[\\mathbf { z}_i\\mathbf{z}^{\\top } _ i]\\}[{{\\mathbb{e}}}\\mathbf { s}_n(t_i)]^{-1}\\mathbf{t}_n(t_i)$ ] . note that @xmath435^{-1}\\bigl\\{\\mathbf{z}_j\\mathbf{z}^{\\top}_j- { { \\mathbb{e}}}\\bigl[\\mathbf{z}_j\\mathbf{z}^{\\top } _",
    "j\\bigr ] \\bigr\\}\\bigl[{{\\mathbb{e}}}\\mathbf { s}_n(t_j)\\bigr]^{-1}\\\\ & & \\hspace*{40pt}{}\\times k_{b_n}(t_k - t_j ) \\pmatrix{\\mathbf{x}_k",
    "\\varepsilon_k \\vspace*{2pt}\\cr \\mathbf{x}_k \\varepsilon_k \\bigl[(t_k - t_j)/b_n \\bigr ] } .\\end{aligned}\\ ] ] by the short memory property of @xmath68 in condition ( a4 ) and similar arguments as those in the proof of lemma [ lembias1 ] , we have @xmath436^{-1}\\bigl\\ { \\mathbf{z}_j\\mathbf{z}^{\\top}_j-{{\\mathbb{e}}}\\bigl [ \\mathbf{z}_j\\mathbf{z}^{\\top } _",
    "j\\bigr]\\bigr\\ } \\bigl[{{\\mathbb{e}}}\\mathbf { s}_n(t_j)\\bigr]^{-1}k_{b_n}(t_k - t_j ) \\biggr\\|=\\mathrm{o}(\\sqrt{nb_n}).\\vadjust{\\goodbreak}\\end{aligned}\\ ] ] hence by similar conditioning arguments as those in the proof of lemma [ lembias1 ] , we have @xmath437 together with ( [ eq4 ] ) and the summation by parts technique used in lemma [ lemasy1 ] , it follows that @xmath438 .",
    "the lemma follows .",
    "[ lemasy4 ] assume condition . then on a possibly richer probability space ,",
    "there exist i.i.d standard @xmath280 dimensional gaussian random vectors @xmath281 , such that @xmath439 where @xmath440^{-1}{{\\mathbb{e}}}\\bigl [ \\mathbf{z}_i\\mathbf{z}^{\\top}_i\\bigr ] \\bigl[{{\\mathbb{e}}}\\mathbf { s}_n(t_i)\\bigr]^{-1}\\tilde { \\mathbf{t}}_n(t_i ) , \\\\[-2pt ] \\bar{d}_{n1}^*&=&\\sum _ { i=1}^n\\tilde{v}^{\\top}_i \\bigl[{{\\mathbb{e}}}\\mathbf { s}_n(t_i)\\bigr]^{-1}\\tilde { \\mathbf{t}}_{n}(t_i).\\end{aligned}\\ ] ]    recall the definitions of @xmath441 , @xmath442 and @xmath443 in proposition [ propwildboots ]",
    ". we will only prove @xmath444 since @xmath445 follows by similar arguments .",
    "note that @xmath446^{-1}{{\\mathbb{e}}}\\bigl [ \\mathbf{z}_i\\mathbf{z}^{\\top}_i\\bigr ] \\bigl[{{\\mathbb{e}}}\\mathbf { s}_n(t_i)\\bigr]^{-1 } \\mathbf{t}_n(t_i):=\\sum_{i=1}^n \\mathbf{t}^{\\top}_n(t_i)\\tilde { \\theta}_n(i).\\end{aligned}\\ ] ] by corollaries 1 and 2 of wu and zhou @xcite , on a possibly richer probability space , there exist i.i.d @xmath280 dimensional standard gaussian random vectors @xmath281 , such that @xmath447 where @xmath448 .",
    "write @xmath449 . then @xmath450 & & \\quad=\\biggl |\\sum _ { i=1}^n\\bigl[\\mathbf{t}^{\\top } _ n(t_i)- \\tilde{\\mathbf{t}}^{\\top}_n(t_i)\\bigr]\\tilde { \\theta}_n(i ) \\biggr| \\\\ & & \\quad= \\biggl|\\sum_{i=1}^n \\bigl[\\bigl(\\mathbf{t}^{\\top}_{n,0}(t_i ) , \\mathbf{0}^{\\top } _",
    "p\\bigr)-\\bigl(\\tilde{\\mathbf{t}}^{\\top}_{n,0}(t_i ) , \\mathbf{0}^{\\top}_p\\bigr)\\bigr]\\tilde{\\theta } _ n(i)+\\bigl[\\bigl(\\mathbf{0}^{\\top}_p , \\mathbf{t}^{\\top}_{n,1}(t_i)\\bigr)-\\bigl ( \\mathbf{0}^{\\top } _",
    "p,\\tilde{\\mathbf{t}}^{\\top}_{n,1}(t_i ) \\bigr)\\bigr]\\tilde{\\theta}_n(i)\\biggr | \\\\ & & \\hspace*{-3pt}\\quad:= \\biggl|\\sum _ { i=1}^n\\bigl[w^{\\top}_{n,0}(t_i ) \\tilde{\\theta}_n(i)+w^{\\top } _ { n,1}(t_i ) \\tilde{\\theta}_n(i)\\bigr ] \\biggr|.\\end{aligned}\\ ] ] write @xmath451 and @xmath452 .",
    "note that @xmath453 by the summation by parts formula , @xmath454 by the smoothness of @xmath455 and the similar arguments as those in the proof of lemma [ lembias1 ] , it follows that @xmath456 therefore by ( [ eq3 ] ) , we have @xmath457 similarly , @xmath458 hence , @xmath459 .",
    "note that @xmath460^{-1}{{\\mathbb{e}}}\\bigl [ \\mathbf{z}_i\\mathbf{z}^{\\top}_i\\bigr ] \\bigl[{{\\mathbb{e}}}\\mathbf { s}_n(t_i)\\bigr]^{-1}\\tilde { \\mathbf{t}}_n(t_i)\\biggr|=\\sum_{i=1}^n \\hat{\\theta}_n(t_i)\\bigl[\\mathbf{t}_n(t_i)- \\tilde{\\mathbf{t}}_n(t_i)\\bigr],\\end{aligned}\\ ] ] where @xmath461^{-1}{{\\mathbb{e}}}[\\mathbf{z}_i\\mathbf{z}^{\\top}_i][{{\\mathbb{e}}}\\mathbf { s}_n(t_i)]^{-1}$ ] .",
    "hence by similar arguments , it follows that @xmath462\\biggr|=\\mathrm{o}_{{\\mathbb{p}}}\\bigl((\\log n)^{3/2}/\\bigl(n^{1/4}b_n^{3/2}\\bigr ) \\bigr).\\ ] ] the lemma follows .",
    "[ lemasy5 ] under condition and the assumption that @xmath463 , @xmath464 , we have @xmath465 \\,\\mathrm{d}t / b_n\\biggr\\}\\rightarrow n\\bigl(0 , \\sigma^2\\bigr).\\end{aligned}\\ ] ]    note that both @xmath466 and @xmath467 are quadratic forms of i.i.d .",
    "standard gaussian random vectors . by lemma [ lemsninv ] and similar arguments as those in the proof of lemma [ lemasy3 ]",
    ", it can be shown that @xmath468 and @xmath469 , where @xmath470 note that @xmath471\\lambda^{1/2}(t_r)v_r\\end{aligned}\\ ] ] and that @xmath472 if @xmath473 or @xmath474 .",
    "hence by lemma [ lemsninv ] and similar arguments as those in the proof of lemma [ lemasy3 ] , it follows that @xmath475 where @xmath476 .",
    "similarly , @xmath477 using the fact that @xmath310 s are i.i.d .",
    "standard gaussian , elementary calculations show that @xmath478 \\,\\mathrm{d}t / b_n\\biggr\\}\\rightarrow n\\bigl(0 , \\sigma^2\\bigr).\\end{aligned}\\ ] ] the lemma follows .",
    "[ lemasy6 ] under conditions , we have @xmath479 where @xmath480 ^ 2 $ ] .    note that @xmath481 . therefore",
    "@xmath482=\\sum_{k=-\\infty}^n \\sum_{i=1}^n{\\mathcal{p}}^*_k \\varepsilon_i^2,\\ ] ] where @xmath483 . since @xmath484 and @xmath485 are orthogonal for @xmath378 , we have @xmath486\\biggr\\|^2=\\sum _ { i=1}^n\\sum_{j=1}^n \\sum_{k=-\\infty}^n{{\\mathbb{e}}}\\bigl[{\\mathcal{p}}^*_k \\varepsilon_i^2{\\mathcal{p}}^*_k\\varepsilon_j^2 \\bigr]\\le\\sum_{i=1}^n\\sum _ { j=1}^n\\sum_{k=-\\infty}^n \\bigl\\|{\\mathcal{p}}^*_k\\varepsilon_i^2\\bigr\\|\\bigl\\| { \\mathcal{p}}^*_k\\varepsilon_j^2\\bigr\\|.\\end{aligned}\\ ] ]",
    "let @xmath487 be an i.i.d .",
    "copy of @xmath488 . by theorem 1 in wu @xcite , @xmath489 , where @xmath490 if @xmath491 and @xmath492 otherwise . by the cauchy ",
    "schwarz inequality , we have for @xmath493 @xmath494 therefore , @xmath486\\biggr\\|^2\\le c\\sum _ { i=1}^n\\sum_{j=1}^n \\sum_{k=-\\infty}^{\\min ( i , j)}(i - k+1)^{-2}(j - k+1)^{-2 } \\le cn.\\end{aligned}\\ ] ] hence , @xmath495\\|=\\mathrm{o}(\\sqrt{n})$ ] .",
    "note that @xmath496 . the lemma follows .",
    "[ lemsninv ] recall that @xmath497 . under condition",
    ", we have @xmath498^{-1}\\bigr\\|_{8}=\\mathrm{o } \\biggl ( \\frac{1}{\\sqrt{nb_n } } \\biggr).\\end{aligned}\\ ] ] additionally , @xmath499^{-1}|=\\mathrm{o}(1)$ ] . for @xmath500",
    ", we have @xmath501^{-1 } - \\bigl[\\mu_h m(t)\\bigr]^{-1}\\bigr| = \\mathrm{o}\\bigl(b_n^2 \\bigr).\\end{aligned}\\ ] ]    the proof follows by the similar arguments as those of lemma 6 in zhou and wu @xcite . details are omitted .",
    "proof of theorem [ thm1 ] theorem [ thm1 ] follows from lemmas [ lembias1][lemasy6 ] above and the slutsky s theorem .",
    "proof of theorem [ thm2 ] recall that @xmath296^{\\top } , [ \\varepsilon^{(2)}_{i}]^\\top)^{\\top}$ ] and @xmath297^{\\top } , [ v^{(2)}_{i}]^\\top)^{\\top}$ ] , where @xmath298 and @xmath299 are @xmath300 dimensional . note that , under @xmath157 , we have a local linear regression of @xmath168 on @xmath502 .",
    "recall again the definitions of @xmath503 , @xmath504 , @xmath505 , @xmath304 , @xmath506 , @xmath507 , @xmath508 and @xmath509 in section  [ secwildboots ] .",
    "following very similar arguments as those in lemmas [ lembias1 ] to [ lemasy6 ] , it can be shown that @xmath510 where @xmath511''\\}^\\top m_{22}(t)[{\\bolds{\\beta}}^{(2)}(t ) ] '' \\,\\mathrm { d}t+\\mathrm{o}_{{\\mathbb{p}}}(nb_n^4)$ ] , @xmath512^{\\top}\\bigl[{{\\mathbb{e}}}\\mathbf { s}^{(2)}_n(t_i ) \\bigr]^{-1}{{\\mathbb{e}}}\\bigl[\\mathbf{z}^{(2)}_i \\mathbf{z}^{(2)\\top}_i\\bigr ] \\bigl[{{\\mathbb{e}}}\\mathbf { s}^{(2)}_n(t_i)\\bigr]^{-1}\\tilde { \\mathbf{t}}^{(2)}_n(t_i ) , \\\\",
    "\\bar{d}_{n1}^{(2)*}&=&\\sum_{i=1}^n \\tilde{v}^{(2)\\top}_i\\bigl[{{\\mathbb{e}}}\\mathbf { s}^{(2)}_n(t_i ) \\bigr]^{-1}\\tilde{\\mathbf{t}}^{(2)}_{n}(t_i).\\end{aligned}\\ ] ] note that @xmath513 and @xmath514 are quadratic forms of i.i.d .",
    "gaussian vectors @xmath281 .",
    "theorem [ thm2 ] follows easily from ( [ eq1 ] ) and ( [ eq5 ] ) .",
    "proof of proposition [ propequasemi ] define @xmath515 and @xmath516 .",
    "let @xmath324 and @xmath517 be the @xmath76th residual of the local linear regression of @xmath168 and @xmath187 on @xmath169 , respectively . from ( [ eqsol ] ) , we can write @xmath518 , where @xmath519 is a @xmath520 vector which can be written in a closed form ( [ eqsol ] ) . note also that @xmath519 is functionally independent of the errors @xmath4 .",
    "hence , @xmath521 let @xmath522 and @xmath523 .",
    "hence , @xmath524 from condition ( b ) , it is easy to see that , for sufficiently large @xmath525 , @xmath526 therefore , it is easy to derive from condition ( a ) that @xmath527 hence , @xmath528 .",
    "we now deal with @xmath529 .",
    "note that , by ( [ eq6 ] ) , @xmath530.\\end{aligned}\\ ] ] hence , @xmath531+\\sum _ { i=1}^n\\varepsilon_i[\\tilde { \\varepsilon}_i-\\hat{\\varepsilon}_i ] \\\\ & & { } + \\sum _ { i=1}^n\\bigl(\\mathbf{z}^{(2)}_i \\bigr)^{\\top } \\bigl(\\mathbf{s}_n^{(2)}(t_i ) \\bigr)^{-1}\\mathbf{t}^{(2)}_n(t_i ) [ \\tilde{\\varepsilon}_i-\\hat{\\varepsilon}_i ] \\\\ & : = & \\mathit{ii}^{*}+\\mathit{ii}^{**}+\\mathit{ii}^{***}.\\end{aligned}\\ ] ] by hlder inequality , condition ( a ) and ( [ eq7 ] ) , the bias term @xmath532=\\mathrm{o}\\bigl ( \\sqrt{n}b_n^2\\bigr).\\ ] ] write @xmath533 and let @xmath534 . by second order taylor expansion of @xmath535 at @xmath260 and condition ( b ) , it is easy to see that @xmath536 with the reminder term @xmath537 satisfying @xmath538 . therefore , @xmath539 by the similar conditioning arguments as those in the proof of lemma [ lembias1 ] , it is easy to show that @xmath540 .",
    "hence @xmath541 . by similar arguments and elementary but tedious calculations",
    ", it follows that @xmath542 .",
    "therefore , the proposition follows .",
    "proof of proposition [ proplocalpower ] let @xmath543",
    ". then @xmath544 . under the local alternative @xmath545",
    ", we have @xmath546 ^ 2.\\end{aligned}\\ ] ] by the similar arguments as those in the proof of lemma [ lembias1 ] , it is easy to show that @xmath547 ^ 2&=&c^{1/2}\\int_0 ^ 1 \\mathbf{f}_n^{\\top}(t)m(t)\\mathbf{f}_n(t ) \\ , \\mathrm{d}t+\\mathrm{o}_{{\\mathbb{p}}}(1 ) , \\\\",
    "\\sum_{i=1}^n \\mathbf{f}_n^{\\top}(t_i)\\mathbf{x}_i \\varepsilon_i&=&\\mathrm{o}_{{\\mathbb{p}}}\\bigl(n^{1/2}\\bigr).\\end{aligned}\\ ] ] on the other hand , by lemmas [ lembias1][lemasy6 ] and the fact that @xmath548 , it is easy to show that @xmath549 \\,\\mathrm{d}t\\biggr\\}-\\frac{c^{9/2}\\mu_2^{2}}{4}\\int_0 ^ 1 \\bigl[{\\bolds{\\beta}}''(t)\\bigr]^\\top m(t ) { \\bolds{\\beta}}''(t ) \\,\\mathrm{d}t -\\frac{c^{9/2}\\mu_2^{2}}{4}f_2 \\\\ \\hspace*{-4pt}&&\\quad\\rightarrow n\\bigl(0,\\sigma^2\\bigr)\\end{aligned}\\ ] ] and @xmath550 . therefore , the proposition follows .",
    "proof of theorem [ thmnewtest ] a careful check of lemmas [ lembias1 ] and [ lembias2 ] shows that the asymptotic bias of @xmath290 @xmath551^\\top m(t ) { \\bolds{\\beta}}''(t ) \\,\\mathrm{d}t+\\mathrm{o}_{{\\mathbb{p}}}\\bigl(n^{1 - 4\\gamma}\\bigr).\\end{aligned}\\ ] ] another careful check of lemmas [ lemasy1 ] to [ lemasy6 ] and using lemma [ lemsninv ] show that @xmath552 \\\\[-8pt ] \\nonumber & & \\hspace*{56pt}{}-k\\ast k_{zn^{-\\gamma}}(t_k - t_r)\\bigr ] \\tilde{h}^{\\top } ( t_r)v_r/\\bigl(nzn^{-\\gamma } \\bigr ) \\,\\mathrm{d}z+\\mathrm{o}_{{\\mathbb{p}}}\\bigl(n^{-\\gamma/2}\\bigr).\\qquad\\end{aligned}\\ ] ] since @xmath310 s are i.i.d .",
    "standard gaussian , a central limit theorem for @xmath553 can be easily derived .",
    "now theorem [ thmnewtest ] follows from ( [ eqnewbias ] ) and ( [ eqnewvar ] ) .",
    "details are omitted .",
    "proof of proposition [ proppower ] by the cauchy ",
    "schwarz inequality , @xmath554/\\sqrt{z}\\bigr)\\times 1/\\sqrt{z } \\",
    ", \\mathrm{d}z \\biggr]^2 \\,\\mathrm{d}y \\\\ & \\le & \\int_{{\\mathbb{r}}}\\biggl[\\int_{c_{\\min}}^{c_{\\max}}\\bigl[2k(y / z)-k\\ast k(y / z ) \\bigr]^2/z \\,\\mathrm{d}z\\int_{c_{\\min}}^{c_{\\max}}1/z \\,\\mathrm{d}z\\biggr ] \\,\\mathrm{d}y \\\\ & = & \\bigl(\\log(c_{\\max})- \\log(c_{\\min})\\bigr)\\int_{c_{\\min}}^{c_{\\max}}\\int _ { { \\mathbb{r}}}\\bigl[2k(y / z)-k\\ast k(y / z)\\bigr]^2/z \\ , \\mathrm{d}y \\,\\mathrm{d}z \\\\ & = & \\bigl(\\log(c_{\\max})- \\log(c_{\\min})\\bigr ) ( c_{\\max}-c_{\\min})\\int _ { { { \\mathbb{r}}}}\\tilde{k}^2(t ) \\,\\mathrm{d}t.\\end{aligned}\\ ] ] consider any fixed @xmath555 . plugging the above inequality into ( [ powernewtest ] ) and letting @xmath556 and @xmath557",
    ", it follows that @xmath558 .",
    "hence , the proposition follows .",
    "i am grateful to the two anonymous referees for their many helpful comments which greatly improved the quality of the original version of the paper .",
    "the research was supported in part by nserc of canada ."
  ],
  "abstract_text": [
    "<S> we investigate the behavior of the generalized likelihood ratio test ( glrt ) ( fan , zhang and zhang [ _ ann . </S>",
    "<S> statist . _ * 29 * ( 2001 ) 153193 ] ) for time varying coefficient models where the regressors and errors are non - stationary time series and can be cross correlated . </S>",
    "<S> it is found that the glrt retains the minimax rate of local alternative detection under weak dependence and non - stationarity . </S>",
    "<S> however , in general , the wilks phenomenon as well as the classic residual bootstrap are sensitive to either conditional heteroscedasticity of the errors , non - stationarity or temporal dependence . </S>",
    "<S> an averaged test is suggested to alleviate the sensitivity of the test to the choice of bandwidth and is shown to be more powerful than tests based on a single bandwidth . </S>",
    "<S> an alternative wild bootstrap method is proposed and shown to be consistent when making inference of time varying coefficient models for non - stationary time series . </S>"
  ]
}