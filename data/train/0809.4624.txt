{
  "article_text": [
    "detailed measurements of fluctuations in the cosmic microwave background ( cmb ) have established cosmology as a high - precision science .",
    "one striking illustration of this is the fact that it is today possible to predict a vast number of observables based on six numbers only , with only a few ( but nevertheless intriguing ) `` glitches '' overall .",
    "the key to this success has been making accurate measurements of the cmb power spectrum , perhaps most prominently exemplified by wilkinson microwave anisotropy probe ( wmap ; bennett et al .",
    "2003 ; hinshaw et al .  2007 ,",
    "hinshaw et al .  2008 ) .",
    "the primary connection between theoretical models and cmb observations is made through the cmb likelihood , @xmath18 .",
    "this is a multivariate , non - gaussian function that quantifies the match between the data and a given power spectrum , @xmath6 .",
    "unfortunately , it is impossible to evaluate this function explicitly for modern high - resolution data sets , due to the sheer size of the problem , and one therefore instead typically resolves to various approximations .",
    "however , given the importance of the cmb in modern cosmology , it is of critical importance to characterize this likelihood accurately , and all approximations must be thoroughly verified .",
    "one example is the approximation of the large angular scale likelihood , where @xmath7 is strongly non - gaussian .",
    "this turned out to be a non - trivial issue after the original analysis of the 3-year wmap temperature data by @xcite , in which a master - based @xcite approximation was used at @xmath19 .",
    "an exact likelihood analysis @xcite later demonstrated that this sub - optimal approximation , when applied to harmonic modes between @xmath20 and 30 , biased the spectral index of scalar perturbations , @xmath15 , low by @xmath16 .",
    "a second example is that of non - cosmological foregrounds . unless properly accounted for , such foregrounds bias the observed power spectrum to high values , and can seriously compromise any cosmological conclusions . while important for temperature observations , this is an absolutely crucial issue for polarization observations , as the desired cmb in amplitude is comparable to or weaker than the interfering foregrounds over most of the sky .    in recent years , a new set of statistical methods",
    "have been developed that allows the user to address these issues within a single well - defined framework @xcite .",
    "the heart of this method is the gibbs sampling algorithm ( see , e.g , gelfand and smith 1990 ) , in which samples from a ( typically complicated ) joint distribution are drawn by alternately sampling from ( simpler ) conditional distributions . in the cmb setting , this is realized by drawing joint samples from @xmath21 , by alternately sampling from @xmath22 , where @xmath6 is the cmb power spectrum , @xmath23 is the cmb sky signal , and @xmath24 are the observed data .",
    "in addition to allow for exact likelihood analysis at reasonable computational cost , an equally important feature of this framework is its unique capability of including additional degrees of freedom , such as non - cosmological foregrounds , into the analysis @xcite .",
    "further , very recently an additional metropolis - hastings mcmc sampling step was introduced by @xcite , that effectively resolves the previously described inefficiency of the gibbs sampler at low signal - to - noise @xcite .",
    "the framework has also been extended to handle polarization @xcite and anisotropic universe models @xcite .    by now , the cmb gibbs sampler is well established and demonstrated to sample efficiently from the exact cmb posterior . however , a long - standing issue has been the characterization of the joint likelihood , given a set of such samples .",
    "originally , @xcite proposed to use the so - called blackwell - rao ( br ) estimator for this purpose , and this approach was later implemented and studied in detail by @xcite . while highly accurate for the large angular scale and high signal - to - noise temperature likelihood , it suffers from one major drawback : because it attempts to describe the full @xmath25-dimensional likelihood without any constraints on allowed correlations , the number of samples required for convergence scales exponentially with @xmath25 . in practice , this limits the br estimator to @xmath26 for temperature data , and just @xmath27 for low signal - to - noise polarization data .    in this paper",
    ", we introduce a new temperature likelihood approximation based on samples drawn from the cmb posterior , by modifying the original br estimator in a way that restricts the allowed @xmath28-point functions of @xmath7 , but still captures most of the relevant information .",
    "explicitly , this is done through a specific change of variables , such that the observed marginal posterior for each multipole , @xmath29 , is transformed into a gaussian .",
    "then , in these new variables the joint distribution is approximated by a multivariate gaussian .",
    "as long as the correlation between any two multipoles is reasonably small , as is the case for nearly full - sky experiments such as wmap and planck , we shall see that this provides an excellent approximation to the exact joint likelihood . as a result",
    ", the new approach greatly reduces the overall number of samples required for convergence , and allows us to obtain a highly accurate likelihood approximation to arbitrary @xmath25 .",
    "generalization to a full polarized likelihood will be discussed in a future paper ( eriksen et al .",
    ", in preparation ) .",
    "this paper is organized as follows : in  [ sec : review ] , we first briefly review the gibbs sampling algorithm together with the original blackwell - rao estimator , and in  [ sec : method ] we introduce the new gaussianized blackwell - rao estimator .",
    "next , in ",
    "[ sec : application ] , we apply the new estimator to simulated data , and compare results with brute - force likelihood evaluations in pixel space . in  [ sec : analysis ] , we analyze the 5-year wmap temperature data , and provide an updated power spectrum and set of cosmological parameters .",
    "we summarize and conclude in  [ sec : conclusion ] .",
    "we start by reviewing the current state of the cmb gibbs sampling framework , as previously developed through a series of papers @xcite , and highlight the problem of likelihood modelling as currently presented in the literature .",
    "first , we assume that our observations , @xmath24 , in direction @xmath30 may be modelled in terms of a signal , @xmath23 and a noise , @xmath31 , component , @xmath32 further , we assume that both @xmath23 and @xmath31 are gaussian distributed with vanishing mean and covariances @xmath33 and @xmath34 , respectively .",
    "the cmb is in this paper additionally assumed to be isotropic , such that in spherical harmonic space ( @xmath35 ) the cmb covariance matrix may be written as @xmath36 , where @xmath37 is the angular power spectrum .",
    "our goal is now to map out the cmb posterior distribution @xmath38 and the cmb likelihood @xmath39 .",
    "note that we in this paper are concerned with the problem of likelihood characterization only , which is a post - processing step relative to the gibbs sampler . for notational transparency , we therefore neglect issues such as foreground marginalization , instrumental beams , multi - frequency observations etc . for full details on these issues ,",
    "see , e.g. , eriksen et al .  2008a .",
    "when working with real - world cmb data , there are a number of issues that complicate the analysis .",
    "two important examples are anisotropic noise and galactic foregrounds .",
    "first , because of the scanning motion of a cmb satellite , the pixels in a given data set are observed over unequal amounts of time .",
    "this implies that the effective noise is a function of pixel location on the sky .",
    "second , large regions of the sky are obscured by galactic foregrounds ( e.g. , synchrotron , free - free and dust emission ) , and these regions must be rejected from the analysis by masking .    because of such issues , the total data covariance matrix @xmath40 is dense in both pixel and harmonic space . as a result ,",
    "it is computationally unfeasible to evaluate and sample directly from @xmath38 .",
    "fortunately , this problem was originally solved by @xcite , @xcite and @xcite , who developed a particular cmb gibbs sampler for precisely this purpose . for full details on this method",
    ", we refer the interested reader to the original papers , and in the following we only describe the main ideas .",
    "the practical implementation of the algorithm used in this paper is called `` commander '' , and has been described in detail by @xcite .    the idea behind the cmb gibbs sampler is to draw samples from the joint posterior by alternately sampling from the two corresponding conditionals . the sampling scheme may thus be written on the symbolic form @xmath41 where the left arrow implies sampling from the distribution on the right - hand side .",
    "then , after some burn - in period , @xmath42 will be drawn from the desired distribution .",
    "the only remaining step is to write down sampling algorithms for each of the two above conditional distributions , both of which are readily available for our problem , since the former is simply a multivariate gaussian , and the second is a product of independent inverse gamma distributions .",
    "for one possible general sampling algorithm for @xmath43 , see , e.g. , @xcite .",
    "the gibbs sampler produces a set of samples drawn from the joint cmb posterior , @xmath38 .",
    "however , for these samples to be useful for estimation of cosmological parameters , we have to transform the information contained in this sample set into a smooth approximation to the likelihood @xmath18 . in principle",
    ", we could simply generate a multi - variate histogram and read off corresponding values , but this does not work in practice because of the large dimensionality of the parameter space .    in the current literature ,",
    "the best approach for handling this problem is the blackwell - rao ( br ) estimator @xcite , which attempts to smooth the sampled histogram by taking advantage of the known analytic distribution , @xmath43 : first , we define the observed power spectrum , @xmath44 , of the current cmb sky gibbs sample , @xmath45 , @xmath46 then the br estimator is derived as follows , @xmath47 in other words , the br estimator is nothing but the average of @xmath48 over the sample set , where @xmath44 refers to the power spectrum of a full - sky noiseless cmb signal gibbs sample .",
    "this distribution has a simple analytic expression ( e.g. , * ? ? ?",
    "* ) , @xmath49    while equation [ eq : br ] does constitute a computationally convenient and accurate approximation to the full likelihood for some special applications , it suffers badly from poor convergence properties with increasing dimensionality of the sampled space .",
    "this behaviour may be understood in terms of relative distribution widths : suppose we want to map out an @xmath25-dimensional distribution , and each of the univariate blackwell - rao functions [ i.e. , @xmath48 ] have a standard deviation of , say , 90% of the corresponding marginal distributions .",
    "the total volume fraction spanned by a single sample in @xmath25 dimensions is then @xmath51 , an exponentially decreasing function with @xmath25 .",
    "therefore it also takes an exponential number of samples in order to build up the full histogram , and this becomes computationally unfeasible for realistic data sets already at @xmath52 @xcite .",
    "the main problem with this approach is that one attempts to map out all possible @xmath28-point correlation functions between all multipoles .",
    "the number of such @xmath28-point functions is obviously overwhelming with increasing dimensionality . but",
    "this also hints at a possible resolution of the problem : we know by experience that the cmb likelihood is a reasonably well behaved function , in that 1 ) there are only weak correlations between multipoles for data sets with nearly full - sky coverage , and 2 ) that even including just two - point correlations ( in transformed variables ) produces very reasonable results ( e.g. , bond , jaffe & knox 2000 ; verde et al .  2003 ) .",
    "this intuition will be used in the next section to define a stable likelihood estimator .",
    "we now introduce a new gibbs - based likelihood estimator we call the `` gaussianized blackwell - rao estimator '' ( gbr ) . the basic idea behind this approach is similar to that employed by , e.g. , @xcite and @xcite , namely approximation by a multivariate gaussian in a transformed set of variables .    explicitly , our approximation is defined by transforming the univariate marginal distributions @xmath29 into gaussianized variables , @xmath53 , and then assuming a multivariate gaussian distribution in these transformed variables , @xmath54 here @xmath55 is the jacobian of the transformation , and @xmath56 is a gaussian random vector with mean @xmath57 and covariance matrix @xmath58 .",
    "thus , the approximation of our likelihood estimator relies on the assumption that @xmath59 note that this is by construction exact for the full - sky uniform noise case , because the covariance matrix in this case is diagonal , and the full expression factorizes in @xmath0 ; in that case we are only performing an identity operation .",
    "the first step in our algorithm is to compute the change - of - variables rule from @xmath6 to @xmath53 that transforms the marginal distribution , @xmath29 , for each @xmath0 into a gaussian distribution , @xmath60 .",
    "the data used for this process are the @xmath44 samples drawn from the joint posterior @xmath61 by the cmb gibbs sampler .",
    "we use two different methods of estimating the marginal distributions from these samples .",
    "the first approach is to estimate @xmath29 with the blackwell - rao estimator as defined by equation [ eq : br ] , over a grid in @xmath6 for each @xmath0 .",
    "then , a cubic spline is fitted to the resulting distribution .",
    "this is the preferred approach for high signal - to - noise or low-@xmath0 modes .",
    "however , for low signal - to - noise and high-@xmath0 modes one observes similarly poor convergence properties of this marginal estimator as for the full joint estimator . in these cases",
    "we therefore instead compute a simple histogram directly from the @xmath6 samples , and fit a smooth spline @xcite through this histogram .",
    "for further stability , we also produce @xmath62 @xmath6 samples from @xmath48 based on the same @xmath44 set as used for the br estimator .",
    "this essentially corresponds to computing the blackwell - rao estimator by monte carlo , and the computational cost of producing these extra samples is small .",
    "( the computational expense of the gibbs sampler is driven by sampling from @xmath63 , not by @xmath43 . )",
    "note that this approach naturally supports arbitrary @xmath6 binning schemes @xcite , and also interfaces naturally with the hybrid mcmc scheme described by @xcite .    given these spline approximations",
    "to @xmath29 for each @xmath0 , we compute the corresponding cumulative distributions by numerical integration , @xmath64 this is subsequently identified with a standard gaussian distribution with zero mean and unity variance .",
    "explicitly , we find @xmath65 over a grid in @xmath66 such that @xmath67 where @xmath68 is the error function .",
    "this equation is straightforward to solve using standard numerical root - finding routines .",
    "the result is a convenient set of look - up tables @xmath69 , again stored in the form of cubic splines , that allows for very efficient transformation from standard to gaussian variables for arbitrary values of @xmath6 . from these splines",
    ", it is also easy to compute the derivatives required for the jacobian in equation [ eq : transformation ] .",
    "having defined a change - of - variables for each @xmath0 , the remaining task is to estimate the joint distribution , @xmath70 , in the new variables . in this paper , we approximate this distribution by a joint gaussian , but any parametric function could of course serve this purpose . for example",
    ", we implemented support for the skew - gaussian distribution ( e.g. , * ? ? ?",
    "* ) in our codes , but found that the improvement over a simple gaussian was very small .",
    "the only free parameters in this multivariate gaussian distribution are the mean , @xmath71 , and the covariance , @xmath72 .",
    "these are again estimated from the samples produced by the gibbs sampler .",
    "first , we draw @xmath73 @xmath6 samples from @xmath48 , as described above , but this time including all @xmath0 s for each sample",
    ". then we gaussianize these @xmath0-by-@xmath0 , by evaluating @xmath69 for each sample and multipole moment .",
    "finally , we compute the corresponding means and standard deviations , @xmath74 where the sums run over sample index .",
    "before applying the machinery described in the previous section to the 5-year wmap data , we verify the method by a analyzing a simulated low - resolution data set .",
    "the reason for considering a low - resolution simulation is that only in this case is it possible to evaluate the exact likelihood by brute force in pixel space , without making any approximations .",
    "the simulation is made by drawing a gaussian realization from the best - fit 5-year wmap @xmath9cdm power spectrum @xcite , smoothing this with a @xmath75 fwhm gaussian beam , and projecting it on an @xmath76 healpix grid .",
    "finally , @xmath77 rms white noise is added to each pixel , and the ( degraded ) wmap kq85 sky cut @xcite is applied to the data .",
    "the maximum multipole considered in this analysis was @xmath78 , and the spectrum was binned with a bin size of @xmath79 from @xmath80 .",
    "the signal - to - noise is unity at @xmath81 , and negligible beyond @xmath82 .",
    "we now compute slices for each @xmath0 through the full multivariate likelihood , both with the method described in  [ sec : method ] and by brute - force pixel space evaluation ( e.g. , * ? ? ?",
    "* ) , fixing all other @xmath0 s at the input @xmath9cdm spectrum .",
    "for comparison , we also compute the the marginal distributions for each @xmath0 .",
    "the results from this exercise are shown in figure [ fig : verification ] .",
    "black lines indicate the brute - force likelihoods , and red lines show the gaussianized blackwell - rao likelihoods .",
    "the green lines show the marginal distributions , visualizing the effect of mode coupling due to the sky cut .",
    "first , we see that all distributions agree very closely at @xmath83 . in this very large - scale regime ,",
    "all harmonic modes are sufficiently well sampled with the kq85 sky cut that mode coupling is negligible . however , from @xmath84 the marginal distributions are noticeably different from the likelihood slices , with a typical shift in peak position of @xmath85 s .",
    "we also see that these correlations are accurately captured by the gaussian approximation implemented in the gbr estimator , as the gbr likelihoods are essentially identical to the brute - force slices up to @xmath86 .    at the very high @xmath0 and low signal - to - noise end , we see slight differences between the gbr and the pixel space slices , and in fact , the agreement is better with the marginal distributions .",
    "this is caused by poor convergence of the covariance matrix in this particular run , and is included here for pedagogical purposes only : in a real analysis , one must always make sure that all distributions have converged well , typically by analyzing different chain sets separately .",
    "note also that with sufficiently wide bins , the correlations to neighboring bins eventually vanish , and in this case it may be better to remove these correlations by hand from the covariance matrix , rather than trying to estimate them by sampling . whether this is the case or not for a given set can again be estimated by jack - knife tests . finally , for the 5-year wmap analysis presented in this paper",
    ", we will only use the gbr estimator in the high signal - to - noise regime , and in that case the distributions converge very quickly .",
    "we now apply the tools described in  [ sec : method ] to the 5-year wmap temperature data .",
    "we only consider @xmath8 in this paper , to avoid issues with error propagation for unresolved point sources and beam estimation .",
    "however , we do correct for the mean spectrum of unresolved point sources , as described below .",
    "we analyze the foreground reduced 5-year wmap v - band temperature sky maps , which are available from lambda .",
    "the v - band data was chosen because these are considered to be the cleanest in terms of foregrounds out of the five wmap bands @xcite .",
    "further , at @xmath8 the v - band alone is strongly cosmic variance dominated , and one does therefore not gain any significant statistical power by co - adding with other bands .",
    "instead , one only increases the chance of introducing foreground biases by adding more frequencies .",
    "we work with the individual differencing assembly ( da ) maps @xcite , and take into account the beam and noise pattern for each map separately .",
    "the wmap sky maps are pixelized at a healpix resolution of @xmath87 , corresponding to a pixel size of @xmath88 , and the instrumental beam of the two v - band channels has a fwhm of 21. we therefore impose an upper harmonic mode limit of @xmath89 in the gibbs sampling ( commander ) step , probing deeply into the noise dominated regime .",
    "note , however , that we only use @xmath8 in the gbr estimator , to avoid high-@xmath0 complications , such as beam and point source error propagation , in the cosmological parameter stage .",
    "we correct the spectrum for unresolved point sources using the wmap model .",
    "explicitly , the mean spectrum due to unresolved point sources in a single frequency , @xmath90 , for the 5-year wmap data is modelled as @xcite @xmath91 where @xmath92 is the point source amplitude relative to the q - band channel ( @xmath93 ) , @xmath94 is the best - fit spectral index of the point sources , and @xmath95 is the conversion factor between antenna and thermodynamic temperature units . to correct for this in our analysis ,",
    "we subtract @xmath96 , evaluated at @xmath97 , from each @xmath44 sample before computing the gbr estimator .",
    "finally , we impose the wmap kq85 sky cut @xcite on the data that masks point sources , removing 18% of the sky .",
    "note that we adopt the template corrected maps provided by the wmap team in this analysis , and postpone an internal gibbs sampling based foreground analysis to a future paper ; for now our main focus is the new likelihood approximation , not the impact of foregrounds .",
    "the analysis consists of the following steps :    1 .",
    "generate 4000 @xmath44 samples with commander from the 5-year v1 and v2 differencing assemblies , including @xmath0 s up to @xmath89 , divided over 8 chains .",
    "generate 500000 @xmath6 samples from these @xmath44 s , including @xmath0 s between @xmath98 and 250 .",
    "compute the corresponding gbr parameters , i.e. , transformation tables , means @xmath71 and covariance matrix @xmath72 .",
    "4 .   modify the 5-year wmap temperature likelihood by replacing the existing low-@xmath0 part with equation [ eq : transformation ] , with the parameters given in ( 3 ) .",
    "the transition multipole between the low-@xmath0 and high-@xmath0 is increased from @xmath99 to 200 .",
    "multipoles between @xmath100 and 250 are included in the gbr estimator to avoid truncation effects , but the spectrum in this range is kept fixed at a fiducial spectrum , in order not to count these multipoles twice .",
    "cosmological parameters are estimated using cosmomc @xcite .      before presenting the results from the wmap analysis",
    ", we consider the question of convergence .",
    "first , we compute the gelman - rubin statistic @xcite for each @xmath44 using the eight chains computed with commander and removing the first 20 samples for burn - in .",
    "we find that @xmath101 is less than 0.01 for @xmath102 and less than 1.1 for @xmath103 , indicating very good convergence in terms of power spectra .",
    "however , the fact that each @xmath44 individually is well converged does not automatically imply that the full likelihood is well converged , since the latter depends crucially on the correlations between @xmath44 s . to assess the convergence in terms of cosmological parameters , we therefore analyse a toy model , by fitting a simple two - parameter amplitude and tilt , @xmath104 and @xmath105 , model , @xmath106 to the wmap data between @xmath98 and 250 with the gbr likelihood . here",
    "@xmath107 is a fiducial power spectrum , which is chosen to be the best - fit 5-year wmap @xmath9cdm power spectrum @xcite , and @xmath108 .",
    "we then map out the likelihood in a grid over @xmath104 and @xmath105 .",
    "this is repeated twice , first including samples from chains number 1 to 4 and then from chains number 5 to 8 .",
    "the results from this exercise are shown in figure [ fig : qn_model ] in terms of two sets of likelihood contours , corresponding to each of the two chain sets , respectively .",
    "the agreement between the two is excellent , indicating that we also have good convergence in terms of cosmological parameters with the existing sample set .",
    "note also that the point @xmath109 lies well inside the @xmath110 confidence region , indicating that the best - fit wmap model , which is obtained including @xmath0 s between @xmath98 and 1024 , also is a good fit to @xmath98 to 250 separately .",
    "third , as described in ",
    "[ sec : method ] , we construct the gbr covariance matrix from @xmath111 @xmath6 samples drawn from the ( smaller ) set of @xmath44 samples . an outstanding question is how large @xmath28 should be in order for this covariance matrix to reach convergence , as a function of @xmath25 . to settle this question ,",
    "we carry out the following simple exercise : first we produce two @xmath6 sample sets , each containing @xmath28 samples , and all drawn from a single @xmath44 sample .",
    "second , we compute the two corresponding covariance matrices , invert these , then subtract them from each other , and finally compute the standard deviation of all elements .",
    "third , we define the inverse covariance matrix to be converged if the rms mcmc noise is less than 0.005 , corresponding to 0.5% of the diagonal elements .",
    "( we have checked that this produces robust parameter estimates . )",
    "we then find the smallest @xmath28 such that this is satisfied , as a function of @xmath25 .",
    "the results from this exercise are shown in figure [ fig : covar_convergence ] . here",
    "we see that the number of samples required for convergence rises rapidly up to @xmath112 , reaching a maximum of @xmath113 samples , and then flattens to a plateau .",
    "to be on the safe side , we therefore always use either @xmath114 or @xmath115 samples in the wmap analysis .",
    "the reason for this behaviour becomes intuitive when considering the structure of the actual matrix .",
    "this is shown in figure [ fig : covar ] , on the form of a correlation matrix @xmath116 the main features of this matrix are negative correlations around the diagonal , with the largest amplitudes observed between @xmath0 and @xmath117 .",
    "this is expected : first , two modes separated by @xmath118 have different parity , and can therefore not easily mimic each other . on the other hand , modes separated by @xmath119 have both identical parity and similar angular scale , and it is therefore possible to add power to one mode and subtract it from the other , and still maintain an essentially unchanged image .",
    "the result is a noticeable anti - correlation between @xmath0 and @xmath117 .    at larger separations in @xmath0 ,",
    "the correlations die off rapidly , since it is difficult for a large - scale mode to mimic a small - scale mode with a reasonably small sky cut . and",
    "this explains the convergence behaviour seen in figure [ fig : covar_convergence ] : the covariance matrix is strongly band - limited .",
    "therefore , once one has a sufficiently large number of @xmath6 samples for a sub - block to converge , there is also enough samples for a sub - block further away to converge .",
    "these are essentially uncorrelated .",
    "we now present the main results derived from the 5-year wmap temperature data with the gbr estimator between @xmath98 and 200 .",
    "first , in the top panel of figure [ fig : powspec ] we plot the power spectrum obtained by maximizing the gbr likelihood together with the official 5-year wmap power spectrum .",
    "the bottom panel shows the difference between these two , and the gray band indicates the standard deviation of @xmath44 , i.e. , the uncertainty due to noise and sky cut , but not to cosmic variance . clearly , the agreement between the two power spectra is very good .",
    "next , in figure [ fig : likelihood_comparison ] we compare a few selected slices through the gbr likelihood with slices through the wmap likelihood . all other @xmath0 s than the one currently considered are kept fixed at the best - fit @xmath9cdm spectrum . here",
    "we see that there are small shifts in peak positions , corresponding to the small differences seen in the power spectra in figure [ fig : powspec ] .",
    "however , a main point in this plot is that the gbr likelihood slices are well behaved even at the highest @xmath0 s , and this is not the case for the standard br estimator @xcite .",
    "finally , in table [ tab : parameters ] and figure [ fig : parameters ] we summarize the marginal cosmological parameter posteriors obtained with the two likelihood codes from cosmomc .",
    "interestingly , there are some notable differences at the 0.3@xmath12 level , with the most striking example being the spectral index of scalar perturbations , @xmath120 .",
    "this is only @xmath11 away from unity , and @xmath12 higher than the official wmap values .",
    "we have presented a new likelihood approximation to be used within the cmb gibbs sampling framework .",
    "this approximation is defined by gaussianizing the observed marginal power spectrum posteriors , @xmath29 , through a specific change - of - variables , and then coupling these univariate posteriors into a joint distribution through a multivariate gaussian in the new variables .",
    "this process is exact , i.e. , an identity operation , in the uniform and full - sky coverage case , and it is also an excellent approximation in for the moderate sky cuts relevant to satellite missions such as wmap and planck .",
    "our new approach relies on the previously described cmb gibbs sampling framework @xcite , and thereby inherits many important advantages from that .",
    "first and foremost , this framework allows for seamless propagation of uncertainties from various systematic effects ( e.g. , foregrounds , beam uncertainties , calibration or noise estimation errors ) to the final cosmological parameters .",
    "this is not straightforward in the hybrid scheme used by the wmap code .",
    "second , this new approach corresponds to the exact low-@xmath0 pixel space likelihood part of the wmap code , not the approximate high-@xmath0 master part .",
    "still , our method can handle arbitrary high @xmath0 s .",
    "third , once the one - time pre - processing step has been completed , the computational expense of our estimator is determined by the cost of @xmath25 spline evaluations , while a pixel space approach requires a matrix inversion , and therefore scales as @xmath121 . for the cases considered in this paper , the cpu time required for the gbr wmap estimator up to @xmath122 was @xmath123 milliseconds , while it was @xmath5 seconds for the pixel space approach up to @xmath99 , for a map with @xmath124 pixels .",
    "in order to validate our estimator , we applied it to a low - resolution simulated data set , and compared it to slices through the exact joint likelihood as computed by brute - force evaluation in pixel space .",
    "the agreement between the two approaches was excellent .",
    "we then applied the same estimator to the 5-year wmap temperature data , and estimated both a new power spectrum and new cosmological parameters within a standard six - parameter @xmath9cdm model .",
    "the results from these calculations are interesting .",
    "first , our power spectrum is statistically very similar to the official wmap spectrum , with no visible biases seen and relative fluctuations within the level predicted by noise and sky cut .",
    "nevertheless , we do find significant differences in terms of cosmological parameters , and most notably in the spectral index of scalar perturbations , @xmath15 .",
    "specifically , we find @xmath125 , which is only @xmath11 away from unity and @xmath12 higher than the official wmap result , @xmath126 .",
    "this result resembles very much the outcome of a re - analysis we did with the 3-year wmap temperature data @xcite , for which we found a bias of @xmath16 in @xmath15 compared to the official wmap results .",
    "this bias was due to the sub - optimal master - based likelihood approximation @xcite used by the wmap team between @xmath14 and 30 , whereas we used an exact estimator in the same range .",
    "this study later prompted the wmap to change their codes to use an exact likelihood evaluator up to @xmath17 .",
    "in the same study , we also tried to increase the @xmath0-range for our exact estimator to @xmath127 , but found small differences .",
    "we therefore concluded , perhaps somewhat prematurely , that an exact estimator up to @xmath17 was sufficient for obtaining accurate results . on the contrary , in this paper we find",
    "still find significant changes when increasing the exact estimator up to @xmath122 .",
    "in retrospect , this should perhaps not come as a complete surprise , when realizing that the impact on a particular cosmological parameter typically depends logarithmically on @xmath0 .",
    "for instance , @xcite considered a simple power spectrum model with a single free amplitude , @xmath128 , and found that , for a given likelihood estimator to be `` statistically unbiased '' , the systematic errors in that same estimator must fall off faster than @xmath129 .",
    "cccc @xmath130 & @xmath131 & @xmath132 & 0.4 + @xmath133 & @xmath134 & @xmath135 & -0.3 + @xmath136 & @xmath137 & @xmath137 & 0.0 + @xmath138 & @xmath139 & @xmath140 & 0.3 + @xmath15 & @xmath141 & @xmath142 & 0.6 + @xmath143 & @xmath144 & @xmath144 & 0.0    a similar consideration holds for @xmath15 .",
    "intuitively , @xmath15 is as much affected by @xmath98 to 10 as it is between @xmath80 and 100 . in the previous 3-year wmap re - analysis paper , we increased the range of the accurate likelihood estimator from @xmath14 to 30 , corresponding to a factor of 2.5 in @xmath0 , and removed a bias of @xmath145 in @xmath15 . in this paper",
    ", we increase the range from @xmath17 to 200 , corresponding to a factor of 6.7 in @xmath0 , and find an additional bias of @xmath12 .",
    "however , increasing @xmath0 from 30 to 50 corresponds only to a factor of 1.7 in @xmath0 , and this appears to be too small to produce a statistically significant result .",
    "the main conclusions from this work are two - fold .",
    "first , it seems that an accurate likelihood description is required to higher @xmath0 s than previously believed , and at least up to @xmath122 , in order to obtain unbiased results . by extrapolation",
    ", it also does not seem unlikely that even higher multipoles should be included .",
    "this issue will be revisited in a future publication .",
    "our second main conclusion is that we find a spectral index only @xmath11 away from unity , namely @xmath146 . to us",
    ", it therefore seem premature to make strong claims concerning @xmath147 ; the statistical significance of this is rather low , and there are likely still unknown systematic errors in this number .    in a future publication",
    "we will generalize the gbr estimator to polarization .",
    "once completed , this will enable a fully gibbs - based cmb likelihood analysis at low @xmath0 s , and remove the need for likelihood techniques based on matrix operations , i.e. , inversion and determinant evaluation .",
    "the computational cost of a standard cosmological parameter mcmc analysis ( e.g. , cosmomc ) will then once again be driven by the required boltzmann codes ( e.g. , camb or cmbfast ) and not by the likelihood evaluation . in turn , this will increase the importance of fast interpolation codes such as pico @xcite or cosmonet @xcite .",
    "with such fast algorithms for both spectrum and likelihood evaluations ready at hand , the cpu requirements for cosmological parameter estimation may possibly be reduced by orders of magnitude .",
    "we thank tony banday , ben wandelt and graca rocha for useful and interesting discussions .",
    "we acknowledge use of the healpix software @xcite and analysis package for deriving the results in this paper .",
    "we acknowledge use of the legacy archive for microwave background data analysis ( lambda ) .",
    "this work was partially performed at the jet propulsion laboratory , california institute of technology , under a contract with the national aeronautics and space administration .",
    "r , neg and hke acknowledge financial support from the research council of norway ."
  ],
  "abstract_text": [
    "<S> we introduce a new cmb temperature likelihood approximation called the gaussianized blackwell - rao ( gbr ) estimator . </S>",
    "<S> this estimator is derived by transforming the observed marginal power spectrum distributions obtained by the cmb gibbs sampler into standard univariate gaussians , and then approximate their joint transformed distribution by a multivariate gaussian . </S>",
    "<S> the method is exact for full - sky coverage and uniform noise , and an excellent approximation for sky cuts and scanning patterns relevant for modern satellite experiments such as wmap and planck . </S>",
    "<S> the result is a stable , accurate and computationally very efficient cmb temperature likelihood representation that allows the user to exploit the unique error propagation capabilities of the gibbs sampler to high @xmath0 s . </S>",
    "<S> a single evaluation of this estimator between @xmath1 and 200 takes @xmath2 cpu milliseconds , while for comparison , a singe pixel space likelihood evaluation between @xmath3 and 30 for a map with @xmath4 pixels requires @xmath5 seconds . </S>",
    "<S> we apply this tool to the 5-year wmap temperature data , and re - estimate the angular temperature power spectrum , @xmath6 , and likelihood , @xmath7 , for @xmath8 , and derive new cosmological parameters for the standard six - parameter @xmath9cdm model . </S>",
    "<S> our spectrum is in excellent agreement with the official wmap spectrum , but we find slight differences in the derived cosmological parameters . </S>",
    "<S> most importantly , the spectral index of scalar perturbations is @xmath10 , @xmath11 away from unity and @xmath12 higher than the official wmap result , @xmath13 . </S>",
    "<S> this suggests that an exact likelihood treatment is required to higher @xmath0 s than previously believed , reinforcing and extending our conclusions from the 3-year wmap analysis . in that case </S>",
    "<S> , we found that the sub - optimal likelihood approximation adopted between @xmath14 and 30 by the wmap team biased @xmath15 low by @xmath16 , while here we find that the same approximation between @xmath17 and 200 introduces a bias of @xmath12 in @xmath15 . </S>"
  ]
}