{
  "article_text": [
    "orthogonal matching pursuit ( omp ) is a popular algorithm for the recovery of sparse signals and it is also commonly used in compressed sensing .",
    "let @xmath3 be a matrix of size @xmath13 and @xmath14 be a vector of size @xmath15 .",
    "the aim of omp is to find the approximate solution to the following @xmath16-minimization problem : @xmath17 where @xmath18 denotes the number of non - zero entries in @xmath19 . in compressed sensing and the sparse representation of signals",
    ", we often have @xmath20 . throughout this paper",
    ", we suppose that the sampling matrix @xmath21 whose columns @xmath22 are @xmath23-normalized .",
    "to introduce the performance of omp , we first recall the definition of the restricted isometry property ( rip ) @xcite which is frequently used in the analysis of the recovering algorithm in compressed sensing . following cands and tao , for @xmath24 and @xmath25",
    ", we say that the matrix @xmath3 satisfies @xmath26-rip if @xmath27 holds for all @xmath7-sparse signals @xmath19 .",
    "we say that the signal @xmath19 is _",
    "@xmath7-sparse _ if @xmath28 and use @xmath29 to denote the set of @xmath7-sparse signals , i.e. , @xmath30 we next state the definition of the spark ( see also @xcite ) .",
    "the spark of a matrix @xmath3 is the size of the smallest linearly dependent subset of columns , i.e. , @xmath31    theoretical analysis of omp has concentrated primarily on two directions .",
    "the first one is to study the condition for the matrix @xmath3 under which omp can recover @xmath7-sparse signals in exactly @xmath7 iterations . in this direction",
    ", one uses the coherence and rip to analyze the performance of omp .",
    "in particular , davenport and wakin showed that , when the matrix @xmath3 satisfies @xmath32-rip , omp can recover @xmath7-sparse signal in exactly @xmath7 iterations @xcite .",
    "the sufficient condition is improved to @xmath33-rip in @xcite ( see also @xcite ) .",
    "however , it was observed in @xcite , when the matrix @xmath3 satisfies @xmath34-rip for some fixed constants @xmath35 and @xmath36 , that @xmath7 iterations of omp is not enough to uniformly recover @xmath7-sparse signals , which implies that omp has to run for more than @xmath7 iterations to uniformly recover the @xmath7-sparse signals .",
    "hence , one investigates the performance of omp along the second line with allowing to omp run more than @xmath7 iterations . for this case , it is possible that omp add wrong atoms to the optimal atom set , but one can identify the correct atoms by the least square . a main result in this direction is presented by zhang @xcite with proving that when @xmath3 satisfies @xmath37-rip omp can recover the @xmath7-sparse signal in at most @xmath38 iterations .    the other type of greedy algorithms , which are based on omp , have been proposed including the regularized orthogonal matching pursuit ( romp ) @xcite , subspace pursuit ( sp ) @xcite , cosamp @xcite , and many other variants . for each of these algorithms , it has been shown that , under a natural rip setting , they can recover the @xmath7-sparse signals in @xmath7 iterations .",
    "a more natural extension of omp is the orthogonal multi - matching pursuit ( ommp ) @xcite .",
    "we denote the ommp with the parameter @xmath0 as @xmath1 where @xmath2 is an integer .",
    "the main difference between omp and @xmath1 is that @xmath1 selects @xmath0 atoms per iteration , while omp only adds one atom to the optimal atom set .",
    "the algorithm 1 outlines the procedure of @xmath1 with initial feature set @xmath39 . in comparision with omp",
    ", ommp has fewer iterations and computational complexity @xcite .",
    "we note that , when @xmath40 , @xmath1 is identical to omp .",
    "ommp is also studied in @xcite under the names of komp , momp and gomp , respectively .",
    "these results show that , when rip constant @xmath41 , @xmath1 can recover the @xmath7-sparse signal in @xmath7 iterations .    sampling matrix @xmath3 , samples @xmath42 , candidate number @xmath0 for each step , stopping iteration index @xmath43 , initial feature set @xmath44 the @xmath45 . @xmath46 .",
    "@xmath47 @xmath48 @xmath49 @xmath50 @xmath51 @xmath52 @xmath53 @xmath54    the aim of this paper is to study the performance of @xmath1 under a more natural setting of rip ( the rip constant is an absolute constant ) .",
    "particularly , we also would like to understand the relation between the number of iterations and the parameter @xmath0 .",
    "so , we are interested in the following questions :    1 .   _ does there exist an absolute constant @xmath55 so that @xmath6 can recover all the @xmath7-sparse signals within @xmath7 iterations ?",
    "_ 2 .   _ for @xmath56 , can @xmath1 recover the @xmath7-sparse signals within @xmath8 iterations ? _",
    "we next state one of our main results which gives an affirmative answer to question 1 .",
    "[ th : ommpt0 ] let @xmath57 and @xmath58 .",
    "suppose that the sampling matrix @xmath21 satisfies @xmath59-rip and @xmath60 where @xmath39 is the initial feature set in @xmath12 algorithm .",
    "then @xmath1 can recover the signal @xmath19 within , at most , @xmath61 iterations , where @xmath62 .",
    "the above theorem shows that , when @xmath63 , @xmath1 with the initial feature set @xmath64 can recover all the @xmath7-sparse signal within , at most , @xmath7 iterations .",
    "it implies that there exists an absolute constant @xmath5 so that @xmath6 can recover all the @xmath7-sparse signals within @xmath7 iterations .",
    "we believe that the constant @xmath65 is not optimal .",
    "the numerical experiments make us conjecture that the optimal number is @xmath66 , i.e. , under rip , @xmath67 can recover the @xmath7-sparse signal within @xmath7 iterations .",
    "we next turn to question 2 .",
    "the following theorem shows that , when @xmath68 , @xmath1 can recover slowly - decaying signal within @xmath8 iterations .",
    "[ th : ommpt1 ] let @xmath57 , @xmath58 and @xmath69 .",
    "consider the @xmath1 algorithm with @xmath70 and the initial feature set @xmath39 .",
    "if the sampling matrix @xmath21 satisfies @xmath71-rip and @xmath72 then @xmath1 recovers the @xmath19 within @xmath73 iterations where @xmath74    the theorem above shows that , for @xmath68 , @xmath1 can recover @xmath7-sparse signals within @xmath75 iterations . here , the constant @xmath76 depends on the signal @xmath19 . in particular ,",
    "if we take @xmath77 in theorem [ th : ommpt1 ] , we have    under the condition of theorem [ th : ommpt1 ] , if @xmath77 with @xmath10 $ ] , then @xmath1 with the initial feature set @xmath64 recovers the @xmath7-sparse signal within @xmath78 iterations .",
    "we next consider the case with @xmath79 .",
    "in particular , for ` small ' @xmath80 , we give an affirmative answer to question 2 up to a log factor .",
    "[ th : ommpt2 ] let @xmath57 and @xmath58 .",
    "suppose that the sampling matrix @xmath21 satisfies @xmath81-rip and @xmath82 consider the @xmath1 algorithm with the initial feature set @xmath64 .",
    "if @xmath79 , then @xmath1 recover the @xmath7-sparse signal @xmath19 from @xmath42 within @xmath83 iterations , where @xmath84 and @xmath74    we prove the main results using some of the techniques developed by zhang in his study of omp @xcite ( see also @xcite ) . to make the paper more readable , we state our results for the strictly sparse signal .",
    "in fact , using a similar method , one also can extend the results in this paper to the case where the measurement vector @xmath14 is subjected to an additive noise and @xmath19 is not strictly sparse .",
    "in @xcite , liu and tymlyakov proved that , when @xmath3 satisfies @xmath85-rip with @xmath86 , @xmath6 can recover @xmath7-sparse signal within , at most , @xmath7 iterations .",
    "the result requires the rip constant @xmath87 depends on @xmath88 . in theorem",
    "[ th : ommpt0 ] , we require that the measurement matrix @xmath3 satisfies @xmath89-rip with @xmath87 being an absolute constant @xmath90 .",
    "hence , theorem [ th : ommpt0 ] gives an affirmative answer to question 1 under the more natural setting for the measurement matrix @xmath3 .",
    "it is of interest to know which matrices @xmath3 obey the @xmath26-rip and the @xmath91 where @xmath92 is a fixed constant .",
    "much is known about finding matrices that satisfy the @xmath26-rip ( see @xcite ) .",
    "if we draw a random @xmath13 matrix @xmath3 whose entries are i.i.d .",
    "gaussian random variables , then @xmath93 with probability @xmath94 ( see @xcite ) . moreover , the random matrix @xmath3 also satisfies @xmath26-rip with high probability provided @xmath95 so , to make the random matrices @xmath3 obey the @xmath26-rip and the @xmath91 , one can take @xmath96",
    "the purpose of the experiment is the comparison for the reconstruction performances of and the iteration number of @xmath1 with different parameter @xmath0 . given the parameters @xmath97 and @xmath98",
    ", we randomly generate a @xmath13 sampling matrix @xmath3 from the standard i.i.d gaussian ensemble .",
    "the support set @xmath99 of the sparse signal @xmath19 is drawn from the uniform distribution over the set of all subsets of @xmath100\\cap { \\mathbb{z}}$ ] of size @xmath7 .",
    "we then generate the sparse signal @xmath19 according to the probability model : the entries @xmath101 are independent random variable having the gaussian distribution with mean @xmath102 and standard deviation @xmath94 .",
    "we apply the @xmath1 to recover the sparse signal @xmath19 from @xmath42 for different parameters @xmath103 .",
    "note that when @xmath40 , @xmath104 is identical with omp .",
    "we repeat the experiment 200 times for each number @xmath105 and calculate the success rate .",
    "when @xmath12 succeeds , we record the number of the iteration steps .",
    "the left graph in fig .",
    "1 depicts the success rate of the reconstructing algorithm @xmath1 with @xmath106 .",
    "the number of the average iteration steps of @xmath1 with @xmath106 are illustrated in the right graph in fig .",
    "1 . the numerical results show that the performance of @xmath107 , is similar with that of omp , while the number of iteration steps of @xmath108 , is far less than that of omp , which agrees with the theoretical results presented in this paper .",
    "according to theorem [ th : ommpt1 ] and theorem [ th : ommpt2 ] , @xmath12 has a good performance for the slowly - decaying sparse signal @xmath19 .",
    "naturally , one may want to know whether @xmath1 can recover all the @xmath7-sparse signal within less than @xmath7 iterations for some @xmath109\\cap { \\mathbb{z}}$ ] .",
    "numerical experiments show that , for some fast - decaying @xmath7-sparse signal @xmath19 , @xmath1 has to run at least @xmath7 steps to recover @xmath19 for any @xmath109\\cap { \\mathbb{z}}$ ] . however , as shown in @xcite , when the @xmath7-sparse signal @xmath19 is fast - decaying , omp has a good performance . to state the result in @xcite",
    ", we firstly introduce the definition of _ @xmath80-decaying _ signals . for any @xmath7-sparse signal @xmath110 ,",
    "we denote by @xmath99 the support of @xmath19 . without loss of generality",
    ", we suppose that @xmath111 and @xmath112 for @xmath113 , we call the @xmath19 _ @xmath80-decaying _ if @xmath114 for all @xmath115 .",
    "( @xcite)[th : omps ] suppose that @xmath3 satisfies @xmath116-rip with @xmath117 .",
    "suppose that @xmath19 with @xmath28 is @xmath80-decaying signal .",
    "if @xmath118 then omp will recover @xmath19 exactly from @xmath42 in @xmath7 iterations .    in this paper , motivated by the proof of theorem [ th : ommpt0 ] , we can improve theorem [ th : omps ] as follows :    [ th : ompss ] suppose that @xmath3 satisfies @xmath119-rip with @xmath120 .",
    "suppose that @xmath110 with @xmath28 is @xmath80-decaying . if @xmath121 then omp can recover @xmath19 exactly from @xmath42 in @xmath7 iterations .",
    "in theorem [ th : omps ] , the right side of ( [ eq : alphalow ] ) depends on rip constant and @xmath88 , while in theorem [ th : ompss ] , the right side of ( [ eq : alphaup ] ) only depends on the rip constant .",
    "so , theorem [ th : ompss ] is an improvement over theorem [ th : omps ] .",
    "in this section , we introduce many lemmas , which extend some results in @xcite . to state conveniently ,",
    "for any set @xmath122 of column indices , we denote by @xmath123 the @xmath124 matrix composed of these columns .",
    "similarly , for a vector @xmath110 , we use @xmath125 to denote the vector formed by the entries of @xmath19 with indices from @xmath126 . for @xmath127 and @xmath128 , we extend the @xmath129-norm to a generalized @xmath129-norm defined as    @xmath130    similarly , we also can extend the @xmath131-norm as follows @xmath132 then the following lemma presents some inequalities for the extension norm :    [ le : cauch ] suppose that @xmath127 , @xmath133 and @xmath128",
    ". then    1 .",
    "@xmath134 where @xmath135 denotes the real part ; 2 .",
    "@xmath136    to state conveniently , we set @xmath137 and @xmath138 , where @xmath139",
    ". then @xmath140 we now consider ( ii ) .",
    "note that @xmath141 then cauchy - schwarz inequality implies that @xmath142    [ th:1 ] suppose that @xmath143 and set @xmath144 with @xmath145 .",
    "suppose that the sampling matrix @xmath21 satisfies @xmath146 .",
    "let @xmath147 and @xmath148 where @xmath149 .",
    "then @xmath150    the definition of @xmath151 implies that the residuality @xmath152 is orthogonal to the space @xmath153 .",
    "noting @xmath154 , we obtain that @xmath155 which implies that @xmath156 furthermore , @xmath157 implies that @xmath158 similarly , we have @xmath159 according to ( [ eq : cc1 ] ) , we obtain that @xmath160 since @xmath161 to this end , we consider @xmath162 where the third and the fourth equality follow from ( [ eq : lamn1 ] ) and ( [ eq : cc2 ] ) , respectively . according to , @xmath163 where @xmath164 is the moore - penrose pseudoinverse of @xmath165 .",
    "and hence @xmath166 we can write @xmath165 as @xmath167 $ ] .",
    "then @xmath168.\\ ] ] we next consider @xmath169,\\ ] ] where @xmath170 noting ( [ eq : m1234 ] ) and that @xmath171,\\ ] ] we obtain that @xmath172 combining ( [ eq : axn2 ] ) and ( [ eq : xm4vn ] ) we have @xmath173 to this end , we consider @xmath174 for any @xmath175 .",
    "note that @xmath176 where @xmath177 denotes the orthogonal projection of @xmath178 in the subspace @xmath179 .",
    "the last inequality follows from the rip property of @xmath3 . since @xmath180",
    ", we have @xmath181 which implies that @xmath182 provided @xmath183 . and hence , accoridng to ( [ eq : um4u ] ) , @xmath184 which implies that @xmath185 is a positive - definite matrix since @xmath186 provided @xmath183 . combining and , we obtain that @xmath187 then the implies that @xmath188    [ le:1 ] consider @xmath1 and @xmath189 .",
    "set @xmath190 and @xmath145 .",
    "suppose that the sampling matrix @xmath21 whose columns @xmath22 are @xmath23-normalized .",
    "then for any @xmath127 whose support @xmath191 not included in @xmath192 , we have @xmath193 where @xmath194 .    to this end , we only need prove that @xmath195 when @xmath196 the conclusion holds .",
    "so , we only consider the case where @xmath197 recall that @xmath198 is the @xmath199 indices corresponding to the largest magnitude entries in the vector @xmath200 .",
    "then @xmath201 noting that @xmath202 and @xmath203 , we have @xmath204 which implies the result , where the second inequality follows from lemma [ le : cauch ] .",
    "[ th : ite ] under the conditions of lemma [ le:1 ] , we have @xmath205 where @xmath206 .    according to lemma [ th:1 ] and lemma [ le:1 ]",
    ", we have @xmath207 from lemma [ le : cauch ] , we have @xmath208 also , @xmath209 putting ( [ eq : leeq1 ] ) , ( [ eq : leeq2 ] ) and ( [ eq : leeq3 ] ) together , we arrive at the conclusion .",
    "lemma [ th : ite ] extends some results in @xcite , where foucart considered the case with @xmath210 , to the general case .",
    "in fact , if takes @xmath211 in lemma [ th : ite ] , one can obtain lemma 4 in @xcite .",
    "to state conveniently , we set @xmath212 and @xmath213 .",
    "we claim that the conclusion follows provided @xmath214 . indeed ,",
    "since @xmath215 one can recover @xmath19 by solving the least square , i.e. , @xmath216 thus , to this end , we only need prove that @xmath214 , i.e. @xmath217 . the proof is by induction on @xmath69 . if @xmath218 , then the conclusion holds . for the induction step ,",
    "we assume that the result holds up to an integer @xmath219 .",
    "we next show that it holds for @xmath220 .    without loss of generality",
    ", we suppose that @xmath221 for @xmath222 , we set @xmath223 and @xmath224 .",
    "suppose that @xmath225 such that @xmath226 and @xmath227 and hence , @xmath228 is the least integer such that @xmath229 and we will choose @xmath230 late .",
    "the existence of such a @xmath228 can follow from @xmath231 when @xmath232 . and",
    "hence , we have @xmath233    we first consider the case where @xmath234 .",
    "we take @xmath235 and @xmath236 in ( [ eq : ite ] ) .",
    "then a simple observation is that @xmath237 noting that @xmath238 and @xmath239 by subtracting @xmath240 on both sides of ( [ eq : ite ] ) , we can obtain that @xmath241 which implies that @xmath242 where the last inequality uses the fact that @xmath234 and hence @xmath243 . on the other hand",
    ", we note that @xmath244 then , combining ( [ eq : com1 ] ) and ( [ eq : com2 ] ) , we obtain that @xmath245 noting @xmath246 , we have @xmath247 which implies that @xmath248 and hence , @xmath249",
    "i.e. @xmath250 now we continue the algorithm with the initial feature set @xmath251 . according to the induction assumption",
    ", we can recover the @xmath7-sparse signal @xmath19 within @xmath252 iterations provided the initial feature set is @xmath251 .",
    "thus , if one chooses the initial feature set as @xmath39 then @xmath19 can be recovered within @xmath253 iterations .",
    "then , the conclusion follows since @xmath254    we next consider the case where @xmath255 .",
    "we take @xmath256 and @xmath236 in ( [ eq : ite ] ) .",
    "then a simple observation is that @xmath257 thus , for any @xmath258 , @xmath259 to state conveniently , we set @xmath260 if @xmath261",
    "then we obtain that @xmath262 which follows by subtracting @xmath263 on both sides of ( [ eq : ite ] ) in lemma [ th : ite ] . for the case",
    "@xmath264 , ( [ eq : itexpt0 ] ) still holds since both sides of ( [ eq : itexpt0 ] ) are equal to @xmath265 .",
    "iterating ( [ eq : itexpt0 ] ) @xmath266 times leads to @xmath267 which implies that @xmath268 here , if the left side of ( [ eq : ite00 ] ) is @xmath265 , then @xmath269 thus , ( [ eq : itexp1t0 ] ) still holds since @xmath270 . to state conveniently , for @xmath271 , we set @xmath272 , @xmath273 , @xmath274 and @xmath275 , and we will choose @xmath276 late . for @xmath277 , we take @xmath278 and @xmath279 in ( [ eq : itexp1t0 ] ) and arrive at @xmath280 then , using the inequality ( [ eq : bude ] ) for @xmath228 times , we can obtain that @xmath281 here , for the second relation , we use the fact of @xmath282 with @xmath283 . combining rip property of @xmath3 , ( [ eq :",
    "l11t0 ] ) and ( [ eq : l21t0 ] ) , we obtain that @xmath284 for @xmath285 .",
    "note that @xmath286 and @xmath287 combining ( [ eq : leq1t0 ] ) and ( [ eq : leq2t0 ] ) , we have @xmath288 we can choose @xmath289 , @xmath290 , and @xmath291 with @xmath292 noting that @xmath293 and @xmath294 , we have @xmath295 combining ( [ eq : di1 ] ) and ( [ eq : di2 ] ) , we obtain that @xmath296 as a result , after @xmath92 iterations , we have @xmath297 with @xmath298 now we continue the algorithm with the initial feature set @xmath299 . according to the induction assumption , we can recover the @xmath7-sparse signal @xmath19 within @xmath300 iterations provided the initial feature set is @xmath299 , where @xmath301 thus , if one chooses the initial feature set as @xmath39 then @xmath19 can be recovered within @xmath302 iterations .",
    "then , the conclusion follows since @xmath303 .",
    "the proof proceed by induction .",
    "we assume that @xmath397 holds for @xmath398 .",
    "we next consider @xmath192 .",
    "set @xmath399 where @xmath400 is the indices of the largest entries of @xmath401 in magnitude .",
    "lemma [ th : ite ] implies that @xmath402 where @xmath191 . noting that @xmath403 , we have @xmath404 we claim that @xmath405 then we have @xmath406 here , for the last inequality , we use the fact of @xmath407 since @xmath19 is @xmath80-decaying . on the other hand , we have @xmath408 combing the results above , we obtain that @xmath409 where @xmath410 note that @xmath411 and hence @xmath412 .",
    "then when @xmath413 we have @xmath414 and hence , @xmath415 which implies that @xmath416 .",
    "we remain to argue that @xmath405 we assume that @xmath417 and we shall derive a contradiction .",
    "the rip property of the matrix @xmath3 implies that @xmath418 and hence , @xmath419 noting that @xmath420 , we have @xmath421 which contradicts with @xmath422 .",
    "[ le : slowdecay ] consider the @xmath1 algorithm with @xmath56 .",
    "suppose that the sampling matrix @xmath21 satisfies @xmath71-rip .",
    "suppose that @xmath57 , @xmath58 .",
    "then @xmath304 where @xmath305 , @xmath306 and @xmath74    to state conveniently , we set @xmath307 and @xmath308 we will choose @xmath230 late so that @xmath309 . to this end , we will prove that @xmath310 with @xmath311 , which implies the result .",
    "the proof is by induction on @xmath69 .",
    "we first consider the case where @xmath312 . according to theorem [ th : ommpt0 ] ,",
    "@xmath1 recover the @xmath7-sparse signal within @xmath313 iterations .",
    "thus , we arrive at the result provided @xmath312 .",
    "we next consider the case where @xmath314 . without loss of generality",
    ", we suppose that @xmath221 to state coneniently , for @xmath315 , we set @xmath316 and @xmath224 .",
    "suppose that @xmath225 such that @xmath317 and @xmath318 and hence , @xmath228 is the least integer such that @xmath229 .",
    "the existence of such a @xmath228 can follow from @xmath231 when @xmath319 .",
    "we next show that the assumption of @xmath314 implies that @xmath320 and hence @xmath255 .",
    "indeed , @xmath320 is equivelent to @xmath321 hence , we only need argue ( [ eq : bx ] ) .",
    "note that @xmath322 where the second relation uses the fact of @xmath323 and hence , we have @xmath324 . we take @xmath325 and @xmath236 in ( [ eq : ite ] ) .",
    "then a simple observation is that @xmath326 for any @xmath258 , @xmath327 to state conveniently , we set @xmath328 noting that @xmath329 by ( [ eq : ite ] ) , we obtain that @xmath330 iterating ( [ eq : itexp0 ] ) for @xmath331 times leads to @xmath332 which implies that @xmath333 where @xmath331 and @xmath92 are integers satisfying @xmath334 .    to state conveniently , for @xmath271 , we set @xmath272 , @xmath274 and @xmath335 and we will choose @xmath276 late",
    ". we use ( [ eq : itexp10 ] ) and a similar argument in the proof of theorem [ th : ommpt0 ] to obtain that @xmath336 note that @xmath337 combining ( [ eq : leq101 ] ) and ( [ eq : leq201 ] ) , we arrive at @xmath338 we can choose @xmath289 , @xmath339 , and @xmath340 and therefore @xmath341 and @xmath342 here , we use @xmath343 since @xmath344 then @xmath345 which implies that @xmath296 as a result , after @xmath92 iterations , we have @xmath346 now we continue the algorithm with the inital feature set @xmath299 . according to the induction assumption , we can recover the @xmath7-sparse signal @xmath19 in @xmath302 iterations where @xmath347 note that @xmath255 and @xmath348 then we arrive at @xmath349 which implies the result .    [ le : smalls ] suppose that @xmath19 is @xmath7-sparse , @xmath58 and @xmath350 consider the @xmath1 algorithm with @xmath351 .",
    "suppose that the sampling matrix @xmath21 whose columns @xmath22 are @xmath23-normalized , and that @xmath3 satisfies @xmath352-rip .",
    "set @xmath306 and @xmath353 then @xmath354      without loss of generality , we suppose that @xmath221 for convenience , for @xmath356 , we set @xmath357 and @xmath224 .",
    "similar with the proof of lemma [ le : slowdecay ] , suppose that @xmath228 is the least integer such that @xmath229",
    ". we will choose @xmath230 late .",
    "the assumption of @xmath358 implies that @xmath359 and hence , we have @xmath360 . we take @xmath325 and @xmath236 in ( [ eq : ite ] ) .",
    "then a simple observation is that @xmath361 for any @xmath258 , @xmath362 to state conveniently , we set @xmath363 @xmath364 @xmath274 and @xmath365 , and we will choose @xmath276 late .",
    "we use ( [ eq : itexp10 ] ) and a similar argument in the proof of theorem [ th : ommpt0 ] to obtain that @xmath366 note that @xmath367 combining ( [ eq : leq10 ] ) and ( [ eq : leq20 ] ) , we arrive at @xmath338 we can choose @xmath289 , @xmath368 , and @xmath369 . and hence @xmath370 and @xmath371 . here , we use @xmath372 with @xmath373 then @xmath374 which implies that @xmath375 as a result , after @xmath92 iterations , we have @xmath376 with @xmath377 now we continue the algorithm from the iteration @xmath92 . according to the induction assumption , we have @xmath378 with @xmath379 note that @xmath255 and that @xmath380 a simple calculation shows that @xmath381 then we arrive at @xmath382 which implies the result .    according to lemma [ le : slowdecay ] , after @xmath1 running @xmath383 steps , we have @xmath384 where @xmath385 here we use the assumption of @xmath386 . since @xmath1 chooses @xmath0 atoms at each iteration , we have @xmath387 noting that @xmath388 , we obtain that @xmath389 which implies that @xmath1 can recover the @xmath7-sparse signal @xmath19 within @xmath390 iterations .",
    "by lemma [ le : smalls ] , we have @xmath391 since @xmath392 here , we use the fact of @xmath64 and hence @xmath393 . also , noting that @xmath394 and @xmath395 we obtain that @xmath396 which implies the result ."
  ],
  "abstract_text": [
    "<S> the orthogonal multi - matching pursuit ( ommp ) is a natural extension of the orthogonal matching pursuit ( omp ) . </S>",
    "<S> we denote the ommp with the parameter @xmath0 as @xmath1 where @xmath2 is an integer . </S>",
    "<S> the main difference between omp and @xmath1 is that @xmath1 selects @xmath0 atoms per iteration , while omp only adds one atom to the optimal atom set . in this paper </S>",
    "<S> , we study the performance of orthogonal multi - matching pursuit under rip . </S>",
    "<S> in particular , we show that , when the measurement matrix @xmath3 satisfies @xmath4-rip , there exists an absolute constant @xmath5 so that @xmath6 can recover @xmath7-sparse signal within @xmath7 iterations . </S>",
    "<S> we furthermore prove that @xmath1 can recover @xmath7-sparse signal within @xmath8 iterations for a large class of @xmath0 provided the signal is slowly - decaying . in particular , for @xmath9 with @xmath10 $ ] , @xmath1 can recover slowly - decaying @xmath7-sparse signals within @xmath11 iterations . </S>",
    "<S> the result implies that @xmath12 can reduce the computational complexity heavily . </S>"
  ]
}