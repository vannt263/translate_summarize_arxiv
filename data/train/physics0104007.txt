{
  "article_text": [
    "it is common in studying controllers to describe the interplay between the _ sensors _ which estimate the state of a system intended to be controlled , and the _ actuators _ used to actually modify the dynamics of the controlled system as a transfer of information involving three steps : estimation , decision , and actuation . in the first step ,",
    "sensors are used to gather information from the controlled system in the form of data relative to its state ( estimation step ) .",
    "this information is then processed according to some plan or control strategy in order to determine which control dynamics is to be applied ( decision step ) , to be finally transferred to the actuators which feed the processed information back to the controlled system to modify its dynamics , typically with the goal of decreasing the uncertainty in the value of the system s variables ( actuation step ) @xcite .    whether or not the estimation step is present in this sequence is optional , and determines",
    "which type of control strategy is used . in so - called _ closed - loop _ or _ feedback _",
    "control techniques , actuators rely explicitly on the information provided by sensors to apply the actuation dynamics , whereas in _ open - loop _ control there is no estimation step preceding the actuation step . in other words ,",
    "an open - loop controller distinguishes itself from a closed - loop controller in that it does not need a continual input of ` selective ' information @xcite to work : like a throttle or a hand brake , it implements a control action independently of the state of the controlled system . in this respect ,",
    "open - loop control techniques represent a subclass of closed - loop controls that neglect the information made available by estimation .    since control is fundamentally about information ( getting it , processing it , and applying it ) it is perhaps surprising to note that few efforts have been made to develop a quantitative theory of controllers focused on a clear and rigorous definition of information .",
    "indeed , although controllers have been described by numerous authors as information gathering and using systems ( see , e.g. , @xcite ) , and despite many results related to this problem @xcite , there exists at present no general information - theoretic formalism characterizing the exchange of information between a controlled system and a controller , and more importantly , which allows for the assignation of a definite value of information in control processes @xcite . to address this deficiency ,",
    "we present in this paper with a quantitative study of the role of information in control .",
    "the basis of the results presented here was first elaborated first in @xcite , and draws upon the work of several of the papers cited above by bringing together some aspects of dynamical systems , information theory , in addition to probabilistic networks to construct control models in the context of which quantities analogous to entropy can be defined .",
    "central to our approach is the notion of a communication channel , and its extension to the idea of _ control channels_. as originally proposed by shannon @xcite , a ( memoryless ) communication channel can be represented mathematically by a probability transition matrix , say @xmath0 , relating the two random variables @xmath1 and @xmath2 which are interpreted , respectively , as the input and the output of the channel . in the next two sections of the present work , we adapt this common probabilistic picture of communication engineering to describe the operation of a basic control setup , composed of a sensor linked to an actuator , in terms of two channels : one coupling the initial state of the system to be controlled and the state of the sensor ( sensor channel ) , and another one describing the state evolution of the controlled system as influenced by the sensor - actuator s states ( actuation channel ) .    in sections",
    "iv and v , we use this model in conjunction with the properties of entropy - like quantities to exhibit fundamental results pertaining to control systems . as a first of these results ,",
    "we show that the classical definition of controllability , a concept well - known to the field of control theory , can be rephrased in an information - theoretic fashion .",
    "this definition is used , in turn , to show that a system is perfectly controllable upon the application of controls if , and only if , the target state of that system is statistically independent of any other external systems playing the role of noise sources .",
    "a similar information - theoretic result is also derived for the complementary concept of observability .",
    "moreover , we provide bounds on the amount of information a feedback controller must gather in order to stabilize the state of a system . more precisely , we prove that the amount of information gathered by the controller must be bounded below by the difference @xmath3 , where @xmath4 is the closed - loop entropy reduction that results from utilizing information in the control process , and @xmath5 is the maximum decrease of entropy attainable when restricted to open - loop control techniques . this last result , as we will see , can be used to define an information - based optimality criterion for control systems .",
    "the idea of reducing the entropy of a system using information gathered from estimating its state is not novel by itself . indeed , as he wondered about the validity of the second law of thermodynamics , the physicist james clerk maxwell was probably the first to imagine in 1897 a device ( or a ` demon ' as it was later called ) whose task is to reduce the entropy of a gas using information about the positions and velocities of the particles forming the gas .",
    "( see @xcite for a description of maxwell s demon and a guide to this subject s literature . ) in the more specific context of control theory , the problem of reducing the entropy of a dynamical system has also been investigated , notably by poplavski @xcite and by weidemann @xcite .",
    "poplavski analyzed the information gathered by sensors in terms of brillouin s notion of negentropy @xcite , and derived a series of physical limits to control .",
    "his study focuses on the sensor part of controllers , leaving aside the actuation process which , as will be shown , can be also treated in an information - theoretic fashion . in a similar way",
    ", weidemann performed an information - based analysis of a class of linear controllers having measure preserving sensors .",
    "other related ideas and results can be found in refs .",
    "@xcite .    in the present paper ,",
    "we build on these studies and go further by presenting results which apply equally to linear and nonlinear systems , and can be generalized with the aid of a few modifications to encompass continuous - space systems as well as continuous - time dynamics . to illustrate this scope of applications , we study in section vi specific examples of control systems . among these , we consider two variants of proportional controllers , which play a predominant role in the design of present - day controllers , in addition to complete our numerical investigation of noise - perturbed chaotic controllers initiated in @xcite .",
    "finally , we remark in section vii on the relationship of our framework with thermodynamics and optimal control theory .",
    "in this section , we introduce a simple control model that allows investigation of the dynamical interplay that exists between a sensor and an actuator to ` move ' a system from an unknown initial state to a desired final target state . such a process is depicted schematically in figure 1 in the form of directed acyclic graphs , also known as bayesian networks @xcite .",
    "the vertices of these graphs correspond to random variables representing the state of a ( classical ) system ; the arrows give the probabilistic dependencies among the random variables according to the general decomposition @xmath6 ) ,   \\label{dec1}\\ ] ] where @xmath7 $ ] is the set of random variables which are direct parents of @xmath8 , @xmath9 , ( @xmath10=\\emptyset $ ] ) .",
    "the acyclic condition of the graphs ensures that no vertex is a descendant or an ancestor of itself , in which case we can order the vertices chronologically , i.e. , from ancestors to descendants .",
    "this defines a causal ordering , and , consequently , a time line directed on the graphs from left to right .    in the control graph of figure 1a ,",
    "the random variable @xmath1 represents the initial state of the system to be controlled , and whose values @xmath11 are drawn according to a fixed probability distribution @xmath12 . in conformity with our introductory description of controllers , this initial state",
    "is controlled to a final state @xmath13 with state values @xmath14 by means of a sensor , of state variable @xmath15 , and an actuator whose state variable @xmath16 influences the transition from @xmath1 to @xmath13 . for simplicity ,",
    "all the random variables describing the different systems are taken to be discrete random variables with finite sets of outcomes .",
    "the extension to continuous - state systems is discussed in section iv . also , to further simplify the analysis of this model , we assume throughout this paper that the sensor and the actuator are merged into a single device , called the _ controller _ , which fulfills both the roles of estimation and actuation ( see figure 1b ) .",
    "the state of the controller is denoted by @xmath17 , and assumes values from some set @xmath18 of admissible controls @xcite .    using this notation together with the decomposition of eq.([dec1 ] ) , the joint distribution @xmath19 describing the causal dependencies between the states of the control graphs can now be constructed .",
    "for instance , the complete joint distribution corresponding to the closed - loop graph of figure 1b is written as @xmath20 while the open - loop version of this graph , depicted in figure 1c , is characterized by a joint distribution of the form @xmath21 following the definition of closed- and open - loop control given above , what distinguishes probabilistically and graphically both control strategies is the presence , for closed - loop control , of a direct correlation link between @xmath22 and @xmath17 represented by the conditional probability @xmath23 .",
    "this correlation can be thought of as a ( possibly noisy ) communication channel , referred here to as the _ sensor _ or _ measurement _ channel , that enables the controller to gather an amount of information identified formally with the _ mutual information _",
    "@xmath24 where @xmath25 .",
    "( all logarithms are assumed to the base 2 , except where explicitly noted . )",
    "recall that @xmath26 with equality if and only if the random variables @xmath1 and @xmath17 are statistically independent @xcite , so that in view of this quantity we are naturally led to define open - loop control with the requirement that @xmath27 ; closed - loop control , on the other hand , must be such that @xmath28 .    as for the actuation part of the control process , the joint distributions of eqs.([cld])-([opd ] ) show that it is accounted for by the channel - like probability transition matrix @xmath29 .",
    "the entries of this _ actuation _ matrix give the probability that the controlled system in state @xmath30 is actuated to @xmath31 given that the controller s state is @xmath32 . from here on , it will be convenient to think of the control actions indexed by each value of @xmath17 as a set of _",
    "actuation channels _ , with memoryless transition matrices @xmath33 governing the transmission of the random variable @xmath1 to a target state @xmath34 . in terms of the control graphs ,",
    "such channels are represented in the same form as in figure 1d to show that the fixed value @xmath32 ( filled circle in the graph ) enacts a transformation of the random variable @xmath1 ( open circle ) to a yet unspecified value associated with the random variable @xmath13 ( open circle as well ) .",
    "guided by this graphical representation , we will show in the next section that the overall action of a controller can be decomposed into a series of single conditional actuation actions or _ subdynamics _ triggered by the internal state of @xmath17 .    here",
    "we characterize the effect of the subdynamics available to a controller on the _ entropy _ of the initial state @xmath1 : @xmath35 in theory , this effect is completely determined by the choice of the initial state @xmath1 , and the form of the actuation matrices .",
    "the effect of these two ` variables ' on @xmath36 is categorized according to the three following classes of dynamics :    _ one - to - one transitions _ : a given control subdynamics specified by @xmath37 conserves the entropy of the initial state @xmath1 if the corresponding probability matrix @xmath38 is that of a noiseless channel . permutations or translations of @xmath1 are examples of this sort of dynamics .    _",
    "many - to - one transitions _ :  a control channel @xmath38 may cause some subset @xmath39 of the state space @xmath40 to be mapped onto a smaller subset of values for @xmath13 . in this case",
    ", the corresponding subdynamics is said to be _ dissipative _ or _ volume - contracting _ as it decreases the entropy of ensembles of states lying in @xmath39 .",
    "_ one - to - many transitions _ :  a channel @xmath38 can also lead @xmath36 to increase if it is _ non - deterministic _ ,",
    "i.e. , if it specifies the image of one or more values of @xmath1 only up to a certain probability different than zero or one .",
    "this will be the case , for example , if the actuator is unable to accurately manipulate the dynamics of the controlled system , or if any part of the control system is affected by external and non - controllable systems .    from a strict mathematical point of view ,",
    "note that any non - deterministic channel modeling a source of noise at the level of actuation or estimation can be represented abstractly as a randomly selected deterministic channel with transition matrix containing only zeros and ones .",
    "the outcome of a random variable undisclosed to the controller can be thought of as being responsible for the choice of the channel to use .",
    "figure 2 shows specifically how this can be done by supplementing our original control graphs of figure 1 with an exogenous and non - controllable random variable @xmath41 in order to ` purify ' the channel considered ( actuation or estimation ) @xcite . for the actuation channel , as for instance",
    ", the purification condition simply refers to the two following properties :    \\(i ) the mapping from @xmath1 to @xmath13 conditioned on the values @xmath42 and @xmath43 , as described by the extended transition matrix @xmath44 , is deterministic for all @xmath45 and @xmath46 ;    \\(ii ) when traced out of @xmath41 , @xmath44 reproduces the dynamics of @xmath29 , i.e. , @xmath47 for all @xmath48 , @xmath49 , and all @xmath45 .",
    "to complement the material introduced in the previous section , we now present a technique for analyzing the control graphs that emphasizes further the conceptual importance of the actuation channel and its graphical representation .",
    "the technique is based on a useful symmetry of figure 1c that enables us to separate the effect of the random variable @xmath1 in the actuation matrix from the effect of the control variable @xmath17 . from one perspective",
    ", the open - loop decomposition @xmath50   \\label{opds}\\ ] ] suggests that an open - loop control process can be decomposed into an ensemble of actuations , each one indexed by a particular value @xmath42 that takes the initial distribution @xmath12 to a conditional distribution ( first sum in parentheses ) @xmath51 the final marginal distribution @xmath52 is then obtained by evaluating the second sum in eq.([opds ] ) , thus averaging @xmath53 over the control variable .",
    "from another perspective , eq.([opds ] ) , re - ordered as @xmath54 , \\ ] ] indicates that the overall action of a controller can be seen as transmitting @xmath1 through an ` averaged ' channel ( sum in parentheses ) whose transition matrix is given by @xmath55 in the former perspective , each actuation subdynamics represented by the control graph of figure 1d can be characterized by a _",
    "conditional open - loop entropy reduction _ defined by @xmath56 where @xmath57 ( subscripts of @xmath58 indicate from which distribution the entropy is to be calculated . ) in the latter perspective , the entropy reduction associated with the unconditional transition from @xmath1 to @xmath13 is simply the _ open - loop entropy reduction _",
    "@xmath59 which characterizes the control process as a whole , without regard to any knowledge of the controller s state",
    ".    for closed - loop control , the decomposition of the control action into a set of conditional actuations seems _ a priori _ inapplicable , for the controller s state itself depends on the initial state of the controlled system , and thus can not be fixed at will .",
    "despite this fact , one can use the bayesian rule of statistical inference @xmath60 where @xmath61 to invert the dependency between @xmath1 and @xmath17 in the sensor channel so as to rewrite the closed - loop decomposition in the following form : @xmath62 .",
    "\\label{clpds}\\ ] ] by comparing this last equation with eq.([opds ] ) , we see that a closed - loop controller is essentially an open - loop controller acting on the basis of @xmath63 instead of @xmath12 @xcite .",
    "thus , given that @xmath42 is fixed , a closed - loop equivalent of eq.([opc ] ) can be calculated simply by substituting @xmath12 with @xmath63 , thereby obtaining @xmath64 for all @xmath42 .",
    "the rationale for decomposing a closed - loop control action into a set of conditional actuations can be justified by observing that _ a closed - loop controller , after the estimation step , can be thought of as an ensemble of open - loop controllers acting on a set of estimated states_. in other words , what differentiates open - loop and closed - loop control from the viewpoint of the actuator is the fact that , for the former strategy , a given control action selected by @xmath32 transforms all the values @xmath65 contained in the _ support _ of @xmath1 , i.e. , the set @xmath66 whereas for the latter strategy , namely closed - loop control , the same actuation only affects the support of the posterior distribution @xmath63 associated with @xmath67 , the random variable @xmath1 conditioned on the outcome @xmath42 .",
    "this is so because the decision as to which control value is used has been determined according to the observation of specific values of @xmath1 which are in turn affected by the chosen control value . by combining the influence of all the control values",
    ", we thus have that information gathered by the sensor affects the entire control process by inducing a _ covering _ of the support space @xmath68 in such a way that values @xmath69 , for a fixed @xmath70 , are controlled by the corresponding actuation channel @xmath71 , while other values in @xmath72 are controlled using @xmath73 , and so on for all @xmath74 .",
    "this is manifest if one compares eqs.([opds ] ) and ( [ clpds ] ) .",
    "note that a particular value @xmath65 included in @xmath75 may be actuated by many different control values if it is part of more than one ` conditional ' support @xmath76 .",
    "hence the fact that eq.([cov1 ] ) only specifies a covering , and not necessarily a partition constructed from non - overlapping sets .",
    "whenever this occurs , we say that the control is _",
    "mixing_.    to illustrate the above ideas about subdynamics applied to conditional subsets of @xmath40 in a more concrete setting , we proceed in the next paragraph with a basic example involving the control of a binary state system using a controller restricted to use permutations as actuation rules @xcite .",
    "this example will be used throughout the article as a test situation for other concepts .",
    "_ example 1 .",
    "_ let @xmath17 be a binary state controller acting on a bit @xmath1 by means of a so - called controlled - not ( cnot ) logical gate .",
    "as shown in the circuits of figures 3a - b , the state @xmath1 , under the action of the gate , is left intact or is negated depending on the control value : @xmath77 ( @xmath78 stands for modulo @xmath79 addition . ) furthermore , assume that the controller s state is determined by the outcome of a ` perfect ' sensor which can be modeled by another cnot gate such that @xmath80 when @xmath17 is initially set to @xmath81 ( figure 3c ) . as a result of these actuation rules",
    ", it can be verified that @xmath82 , and so the application of a single open- or closed - loop control action can not increase the uncertainty @xmath36 .",
    "in fact , whether the subdynamics is applied in an open- or closed - loop fashion is irrelevant here : a permutation is just a permutation in either cases . now , since @xmath80 , we have that the random variable @xmath1 conditioned on @xmath32 must be equal to @xmath42 with probability one . for closed - loop control , this implies that the value @xmath83 , which is the only element of @xmath84 , is kept constant during actuation , whereas the value @xmath85 in @xmath86 is negated to @xmath81 in accordance with the controller s state @xmath87 ( figure 3e ) . under this control action",
    ", the conditional random variable @xmath88 is forced to assume the same deterministic value for all @xmath42 , implying that @xmath13 must be deterministic as well , regardless of the statistics of @xmath17 ( figures 3f - g ) .",
    "therefore , @xmath89 .",
    "in contrast , the application of the same actuation rules in an open - loop fashion transform the state @xmath1 to a final state having , at best , no less uncertainty than what is initially specified by the statistics of @xmath1 , i.e. , @xmath90.@xmath91",
    "the first instance of the general control problem that we now proceed to study involves the dual concepts of controllability and observability . in control theory ,",
    "the importance of these concepts arises from the fact that they characterize mathematically the input - output structure of a system intended to be controlled , and thereby determine whether a given control task is realizable or not @xcite . in short , controllability is concerned with the possibilities and limitations of the actuation channel or , in other words , the class of control dynamics that can be effected by a controller .",
    "observability , on the other hand , is concerned with the set of states which are accessible to estimation given that a particular sensor channel is used . in this section , prompted by preliminary results obtained by lloyd and slotine @xcite , we define entropic analogs of the widely held control - theoretic definitions of controllability and observability , and explore the consequences of these new definitions .      in its simplest expression ,",
    "a system is said to be _ controllable _ at @xmath92 if any of the final state @xmath31 can be reached from @xmath30 using at least one control input @xmath32 @xcite .",
    "allowing for non - deterministic control actions , we may refine this definition and say that a system is _ perfectly controllable _ at @xmath30 if it is controllable at @xmath30 with probability 1 , i.e. , if , for any @xmath93 , there exists at least one @xmath42 such that @xmath94 .",
    "in other words , a system is perfectly controllable if ( i ) all final states for @xmath13 are reachable from @xmath30 ( complete reachability condition ) ; and ( ii ) all final states for @xmath13 are connected to @xmath95 by at least one deterministic subdynamics ( deterministic transitions condition ) . in terms of entropy ,",
    "these two conditions are translated as follows .",
    "( the next result was originally put forward in @xcite without a complete proof . )    _ theorem 1 . _",
    "a system is perfectly controllable at @xmath30 if and only if there exists a distribution @xmath23 @xcite such that @xmath96 for all @xmath48 , and @xmath97 where @xmath98    _ proof . _",
    "if @xmath65 is controllable , then for each @xmath48 there exists at least one control value @xmath99 such that @xmath94 , and thus @xmath100 .",
    "also , choosing @xmath101 over all @xmath14 and @xmath30 ensures that the average conditional entropy over the conditional random variable @xmath102 vanishes , and that @xmath103 .",
    "this proves the direct part of the theorem . to prove the converse , note that if @xmath103 for a given @xmath93 , then there is at least one value @xmath42 for which @xmath104 , which means that there is at least one subdynamics connecting @xmath65 to @xmath48 .",
    "if in addition we have @xmath105 , then we can conclude that such a subdynamics must in fact be deterministic .",
    "as this is verified for any state value @xmath48 , we obtain in conclusion that for all @xmath14 there exists a @xmath42 such that @xmath106.@xmath91    in the case where a system is only _ approximately controllable _ , i.e. , controllable but not in a deterministic fashion , the conditional entropy @xmath107 has the desirable feature of being interpretable as the residual uncertainty or uncontrolled variation left in the output @xmath13 when the controller s state @xmath17 is chosen with respect to the initial value @xmath65 @xcite .",
    "if one regards @xmath17 as an input to a communication channel and @xmath13 as the channel output , then the degree to which the final state @xmath13 is controlled by manipulating the controller s state can be identified with the conditional mutual information @xmath108 .",
    "this latter quantity can be expressed either using a formula similar to eq.([mutual ] ) , or by using the expression @xmath109 which is a conditional version of the chain rule @xmath110 valid for any random variables @xmath1 and @xmath2 .",
    "note that the two above equations allow for another interpretation of @xmath111 .",
    "the conditional entropy @xmath112 , entering in ( [ cr1 ] ) , is often interpreted in communication theory as representing an information loss ( the so - called equivocation of shannon @xcite ) , which results from substracting the maximum noiseless capacity @xmath113 of a communication channel with input @xmath1 and output @xmath2 from the actual capacity of that channel as measured by @xmath114 . in our case , we can apply the same reasoning to eq.([mutualc ] ) , and interpret the quantity @xmath111 as a _ control loss _ which appears as a negative contribution in the expression of @xmath108 , the number of bits of accuracy to which specifying the control variable specifies the output state of the controlled system .",
    "this means that higher is the quantity @xmath111 , then higher is the uncertainty or imprecision associated with the outcome of @xmath13 upon application of the control action .      in order to characterize the _ complete _ controllability of a system , i.e.",
    ", its controllability properties over all possible initial states , define @xmath115 as the _ average control loss_. ( the minimization over all conditional distributions for @xmath17 is there to ensure that @xmath116 reflects the properties of the actuation channel , and does not depend on one s choice of control inputs . ) with this definition , we have that a system is perfectly controllable over the support of @xmath1 if @xmath117 and @xmath103 for all @xmath48 . in any other cases , it is approximately controllable for at least one @xmath65 .",
    "the proof of this result follows essentially by noting that , since discrete entropy is positive definite , the condition @xmath118 necessarily implies @xmath105 for all @xmath119 .",
    "the next two results relate the average control loss with other quantities of interest .",
    "control graphs containing the purification of the actuation channel , as depicted in figure 2 , are used throughout the rest of this section .",
    "_ theorem 2 .",
    "_ under the assumption that @xmath13 is a deterministic random variable conditioned on the values @xmath65 , @xmath42 , and @xmath120 ( purification assumption ) , we have @xmath121 with equality if , and only if , @xmath122 .",
    "_ using the general inequality @xmath123 , and the chain rule for joint entropies , one may write @xmath124 however , @xmath125 , since the knowledge of the triplet @xmath126 is sufficient to infer the value of @xmath13 ( see the conditions in section ii ) .",
    "hence , @xmath127 where the last equality follows from the fact that @xmath41 is chosen independently of @xmath1 and @xmath17 as illustrated in the control graph of figure 2a .",
    "now , from the chain rule @xmath128 it is clear that equality in the first line of expression ( [ clin1 ] ) is achieved if and only if @xmath122.@xmath91    the result of theorem 2 demonstrates that the uncertainty associated with the control of the state @xmath1 is upper bounded by the noise level of the actuation channel as measured by the entropy of @xmath41 .",
    "this agrees well with the fact that one goal of controllers is to protect a system against the effects of its environment so as to ensure that it is minimally affected by noise . in the limit where the control loss vanishes",
    ", the state @xmath13 of the controlled system should show no variability given that we know the initial state and the control action , even in the presence of actuation noise , and should thus be independent of the random variable @xmath41 .",
    "this is the essence of the next two results which hold for the same conditions as theorem 2 ( the minimization over the set of conditional probability distributions @xmath129 is implied at this point ) .",
    "_ theorem 3 .",
    "_ @xmath130 .",
    "_ from the chain rule of mutual information , we can easily derive @xmath131 thus , @xmath132 if we use again the deterministic property of the random variable @xmath133 upon purification of @xmath29.@xmath91    _ theorem 4 .",
    "_ @xmath134 .",
    "_ using the chain rule of mutual information , we write @xmath135 for the last equality , we have used eq.([clin2 ] ) .",
    "now , by substituting @xmath136 from the previous theorem , we obtain the desired result.@xmath91    as a direct corollary of these two results , we have that a system is completely and perfectly controllable if , and only if , @xmath137 is equal to zero or equivalently if , and only if , @xmath138 hence , a necessary and sufficient entropic condition for perfect controllability is that the final state of the controlled system , after the actuation step , is statistically independent of the noise variable @xmath41 given @xmath1 and @xmath17 . in that case , the ` information ' @xmath137 conveyed in the form of noise from @xmath41 to the controlled system is zero .",
    "another ` common sense ' interpretation of this result can be given if the quantity @xmath139 is instead viewed as representing the ` information ' about @xmath13 that has been transferred to the non - controllable state @xmath140 in the form of ` lost ' correlations .",
    "this analysis of control systems in terms of noise and information protection is similar to that of error - correcting codes .",
    "the design of error - correcting codes is closely related to that of control systems : the information duplicated by a code , when corrupted by noise , is used to detect errors ( sensor step ) which are then corrected by enacting specific correcting or erasure actions ( actuation step ) @xcite .",
    "the analogy to error - correcting codes can be strengthened even further if probabilities accounting for undetected and uncorrected errors are modeled by means of communication channels similar to the sensor and actuation channels . in this context ,",
    "whether or not a prescribed set of erasure actions is sufficient to correct for a particular type of errors is determined by the control loss .",
    "the concept of observability is concerned with the issue of inferring the state @xmath1 of the controlled system based on some knowledge or data of the state provided by a measurement apparatus , taken here to correspond to @xmath17 .",
    "more precisely , a controlled system is termed _ perfectly observable _ if the sensor s transition matrix @xmath23 maps no two values of @xmath1 to a single observational output value @xmath42 , or in other words if for all @xmath141 there exists only one value @xmath65 such that @xmath142 . as a consequence",
    ", we have the following result @xcite .",
    "( we omit the proof which readily follows from well - known properties of entropy . )    _ theorem 5 .",
    "_ a system with state variable @xmath1 is perfectly observable , with respect to all observed value @xmath143 , if and only if @xmath144    the information - theoretic analog of a perfectly observable system is a _ lossless _ communication channel @xmath145 characterized by @xmath146 for all input distributions @xcite . as a consequence of this association ,",
    "we interpret the conditional entropy @xmath147 as the information loss , or _ sensor loss _ , of the sensor channel , denoted by @xmath148 .",
    "we now extend our results on controllability into the domain of observability . the first question that arises",
    "is , given the similarity between the average control loss @xmath116 and the sensor loss , do we obtain true results for observability by merely substituting @xmath116 by @xmath148 in theorems 2 and 3 ?",
    "the answer is no : the fact that a communication channel is lossless has nothing to do with the fact that it can be non - deterministic .",
    "an example of such a channel is one that maps the singleton input set @xmath149 to multiple instances of the output set @xmath18 with equal probabilities .",
    "this is clearly a non - deterministic channel , and yet since there is only one possible value for @xmath1 , the conditional entropy @xmath150 must be equal to zero for all @xmath45 . hence",
    ", contrary to theorem 2 , the observation loss @xmath148 can not be bounded above by the entropy of the random variable responsible for the non - deterministic properties of the sensor channel .",
    "however , we are not far from a similar result : by analyzing the meaning of the sensor loss a bit further , the generalization of theorem 2 for observability can in fact be derived using the ` backward ' version of the sensor channel .",
    "more precisely , @xmath151 where @xmath152 is now the random variable associated with the purification of the transition matrix @xmath153 . to prove this result ,",
    "the reader may revise the proof of theorem 2 , and replace the forward purification condition @xmath154 for the sensor channel by its backward analog @xmath155 .    to close this section , we present next what is left to generalization of the results on controllability .",
    "one example aimed at illustrating the interplay between the controllability and observability properties of a system is also given .",
    "_ theorem 6 .",
    "_ if the state @xmath1 is perfectly observable , then @xmath156 . ( the random variable @xmath41 stands for the purification variable of the ` forward ' sensor channel @xmath23 . )    _ proof . _",
    "the proof is rather straightforward .",
    "since @xmath157 , the condition @xmath158 implies @xmath159 .",
    "thus by the chain rule @xmath160 we conclude with @xmath161.@xmath91    _ corollary 7 .",
    "_ if @xmath158 , then @xmath162 .",
    "the interpretations of the two above results follow closely those given for controllability .",
    "we will not discuss these results further except to mention that , contrary to the case of controllability , @xmath161 is not a sufficient condition for a system to be observable .",
    "this follows simply from the fact that @xmath161 implies @xmath163 , and at this point the purification condition @xmath154 for the sensor channel is of no help to obtain @xmath164 .",
    "_ example 2 .",
    "_ consider again the control system of figure 3 .",
    "given the actuation rules described by the cnot logical gate , it can be verified easily that for @xmath83 or @xmath165 , @xmath105 and @xmath166 for all @xmath48 .",
    "therefore , the controlled system is completely and perfectly controllable .",
    "this implies , in particular , that @xmath82 , and that the final state of the controlled system may be actuated to a single value with probability 1 , as noted before . for the latter observation ,",
    "note that @xmath31 with probability 1 so long as the initial state @xmath1 is known with probability 1 ( perfectly observable ) .",
    "in general , if a system is perfectly controllable ( actuation property ) _ and _ perfectly observable ( sensor property ) , then it is possible to perfectly control its state to any desired value with vanishing probability of error . in such a case , we can say that the system is _ closed - loop controllable_.@xmath91      the concept of a deterministic continuous random variable is somewhat ill - defined , and , in any case , can not be associated with the condition @xmath167 formally .",
    "( consider , e.g. , the peaked distribution @xmath168 which is such that @xmath169 . ) to circumvent this difficulty , controllability and observability for continuous random variables may be extended via a quantization or coarse - graining of the relevant state spaces @xcite .",
    "for example , a continuous - state system can be defined to be perfectly controllable at @xmath65 if for every final destination @xmath48 there exists at least one control value @xmath42 which forces the system to reach a small neighborhood of radius @xmath170 around @xmath48 with probability 1 .",
    "equivalently , @xmath65 can be termed perfectly controllable to accuracy @xmath171 if the variable @xmath172 obtained by quantizing @xmath173 at a scale @xmath171 is perfectly controllable .",
    "similar definitions involving quantized random variables can also be given for observability .",
    "the recourse to the quantized description of continuous variables has the virtue that @xmath174 and @xmath175 are well - defined functions which can not be infinite .",
    "it is also the natural representation used for representing continuous - state models on computers .",
    "the emphasis in the previous section was on proving upper limits for the control and the observation loss , and on finding conditions for which these losses vanish . in this section , we depart from these quantities to focus our attention on other measures which are interesting in view of the stability properties of a controlled system .",
    "how can a system be stabilized to a target state or a target subset ( attractor ) of states ?",
    "also , how much information does a controller need to gather in order to achieve successfully a stabilization procedure ? to answer these questions , we first propose an entropic criterion of stability , and justify its usefulness for problems of control . in a second step , we investigate the quantitative relationship between the closed - loop mutual information @xmath176 and the gain in stability which results from using information in a control process .      intuitively , a stable system is a system which , when activated in the proximity of a desired operating point , stays relatively close to that point indefinitely in time , even in the presence of small perturbations . in the field of control engineering , there exist several formalizations of this intuition , some less stringent than others , whose range of applications depend on theoretical as well as practical considerations .",
    "it would be impossible , and , perhaps inappropriate , to review here all the definitions of stability currently used in the study and design of control systems ; for our purposes , it suffices to say that a necessary condition for stabilizing a dynamical system is to be able to decrease its entropy , or immunize it from sources of entropy like those associated with environment noise , motion instabilities , and incomplete specification of control conditions .",
    "this entropic aspect of stabilization is implicit in almost all criteria of stability insofar as a probabilistic description of systems focusing on sets of responses , rather than on individual response one at a time , is adopted @xcite . in this sense , what is usually sought in controlling a system is to confine its possible states , trajectories or responses within a set as small as possible ( low entropy final state )  starting from a wide range of initial states or initial conditions ( high entropy initial random state ) .",
    "the fundamental role of entropy reduction in control suggests the two following problems .",
    "first , given the initial state @xmath1 and its entropy @xmath36 , a set of actuation subdynamics , and the type of controller ( open- or closed - loop ) , what is the maximum entropy reduction achievable during the controlled transition from @xmath1 to @xmath13 ?",
    "second , what is the quantitative relationship between the maximal open - loop entropy reduction and the closed - loop entropy reduction ?",
    "note that for control purposes it does not suffice to reduce the entropy of @xmath13 conditionally on the state of another system ( the controller in particular ) .",
    "for instance , the fact that @xmath177 vanishes for a given controller acting on a system does not imply by itself that @xmath178 must vanish as well , or that @xmath13 is stabilized .",
    "what is required for control is that actuators modify the dynamics of the system intended to be controlled by acting directly on it , so as to reduce the marginal entropy @xmath178 .",
    "this unconditional aspect of stability has been discussed in more detail in @xcite .      using the concavity property of entropy , and the fact that @xmath179 is upper bounded by the maximum of @xmath180 over all control values @xmath42 , we show in this section that the maximum decrease of entropy achieved by a particular subdynamics of control variable @xmath181 is _ open - loop optimal _ in the sense that no random ( i.e. , non - deterministic ) choice of the controller s state can improve upon that decrease .",
    "more precisely , we have the following results .",
    "( theorem 9 was originally stated without a proof in @xcite . )    _ lemma 8 . _ for any initial state @xmath1 , the open - loop entropy reduction @xmath182 satisfies @xmath183 where @xmath184 with @xmath180 defined as in eq.([opc ] ) .",
    "the equality is achieved if and only if @xmath185 .",
    "_ using the inequality @xmath186 , we write directly @xmath187 now , let us prove the equality part .",
    "if @xmath17 is statistically independent of @xmath34 , then @xmath188 , and @xmath189 conversely , the above equality implies @xmath188 , and thus we must have that @xmath17 is independent of @xmath13.@xmath190    _ theorem 9 . _",
    "the entropy reduction achieved by a set of actuation subdynamics used in open - loop control is always such that @xmath191 for all @xmath12 .",
    "the equality can always be achieved for the deterministic controller @xmath192 , with @xmath193 defined as in eq.([argm1 ] ) .",
    "_ the average conditional entropy @xmath177 is always such that @xmath194 therefore , making use of the previous lemma , we obtain @xmath195 also , note that if @xmath192 with probability 1 , then the two above inequalities are saturated since in this case @xmath185 and @xmath196.@xmath190    an open - loop controller or a control strategy is called _ pure _ if the control random variable @xmath17 is deterministic , i.e. , if it assumes only one value with probability 1 .",
    "an open - loop controller that is not pure is called _ mixed_. ( we also say that a mixed controller activates a mixture of control actions . ) in view of these definitions , what we have just proved is that a pure controller with @xmath192 is necessarily optimal ; any mixture of the control variable either achieves the maximum entropy decrease prescribed by eq.([opop ] ) or yields a smaller value . as shown in the next example , this is so even if the actuation subdynamics used in the control process are deterministic .",
    "_ example 3 .",
    "_ for the cnot controller of example 1 , we noted that @xmath197 , or equivalently that @xmath198 , only _ at best_. to be more precise , @xmath199 only if a pure controller is used or if @xmath200 bit ( already at maximum entropy ) .",
    "if the control is mixed , and if @xmath201 bit , then @xmath202 must necessarily be negative .",
    "this is so because uncertainty as to which actuation rule is used must imply uncertainty as to which state the controlled system is actuated to.@xmath91    note that purity alone is not a sufficient condition for open - loop optimality , nor it is a necessary one in fact . to see this , note on the one hand that a pure controller having @xmath203 with probability one is surely not optimal , unless all entropy reductions @xmath204 have the same value . on the other hand , to prove that a mixed controller can be optimal , note that if any subset @xmath205 of actuation subdynamics is such that @xmath206 , and @xmath180 assumes a constant value for all @xmath207 , then one can build an optimal controller by choosing a non - deterministic distribution @xmath208 with @xmath209 .",
    "the distinguishing characteristic of an open - loop controller is that it usually fails to operate efficiently when faced with uncertainty and noise .",
    "an open - loop controller acting independently of the state of the controlled system , or solely based on the statistical information provided by the distribution @xmath12 , can not reliably determine which control subdynamics is to be applied in order for the initial ( _ a priori _ unknown ) state @xmath22 to be propagated to a given target state .",
    "furthermore , an open - loop control system can not compensate actively in time for any disturbances that add to the actuator s driving state ( actuation noise ) . to overcome these difficulties",
    ", the controller must be adaptive : it must be capable of estimating the unpredictable features of the controlled system during the control process , and must be able to use the information provided by estimation to decide of specific control actions , just as in closed - loop control .",
    "a basic closed - loop controller was presented in example 1 .",
    "for this example , we noted that the perfect knowledge of the initial state s value ( @xmath83 or @xmath210 ) enabled the controller to decide which actuation subdynamics ( identity or permutation ) is to be used in order to actuate the system to @xmath211 with probability 1 .",
    "the fact that the sensor gathers @xmath212 bits of information during estimation is a necessary condition for this specific controller to achieve @xmath89 , since having @xmath213 may result in generating the value @xmath214 with non - vanishing probability . in general , just as a subdynamics mapping the input states @xmath215 to the single value @xmath216 would require no information to force @xmath13 to assume the value @xmath81 , we expect that the closed - loop entropy reduction should not only depend on @xmath176 , the effective information available to the controller , but should also depend on the reduction of entropy attainable by open - loop control",
    ". the next theorem , which constitutes the main result of this work , embodies exactly this statement by showing that one bit of information gathered by the controller has a maximum value of one bit in the improvement of entropy reduction that closed - loop gives over open - loop control .",
    "_ theorem 10 .",
    "_ the amount of entropy @xmath217 that can be extracted from a system with given initial state @xmath1 by using a closed - loop controller with fixed set of actuation subdynamics satisfies @xmath218 where @xmath219 is the maximum entropy decrease that can be obtained by ( pure ) open - loop control over _ any _ input distribution chosen in the set @xmath220 of all probability distributions .    a proof of the result , based on the conservation of entropy for closed systems ,",
    "was given in @xcite following results found in @xcite .",
    "here , we present an alternative proof based on conditional analysis which has the advantage over our previous work to give some indications about the conditions for equality in ( [ clot1 ] ) . some of these conditions are derived in the next section .    _",
    "_ given that @xmath221 is the optimal entropy reduction for open - loop control over any input distribution , we can write @xmath222 now , using the fact that a closed - loop controller is formally equivalent to an ensemble of open - loop controllers acting on the conditional supports @xmath223 instead of @xmath75 , we also have for all @xmath141 @xmath224 and , on average , @xmath225 that @xmath221 must enter in the lower bounds of @xmath226 and @xmath227 can be explained in other words by saying that each conditional distribution @xmath228 is a legitimate input distribution for the initial state of the controlled system .",
    "it is , in any cases , an element of @xmath220 .",
    "this being said , notice now that @xmath186 implies @xmath229 hence , we obtain @xmath230 which is the desired upper bound . to close the proof , note that @xmath5 can not be evaluated using the initial distribution @xmath231 alone because the maximum reduction of entropy in open - loop control starting from @xmath12 may differ from the reduction of entropy obtained when some actuation channel is applied in closed - loop to @xmath63 .",
    "see @xcite for a specific example of this.@xmath91    the above theorem enables us to finally understand all the results of example 1 . as noted already , since the actuation subdynamics consist of permutations , we have @xmath232 for any distribution @xmath12 .",
    "thus , we should have @xmath233",
    ". for the particular case studied where @xmath80 , the controller is found to be _ optimal _ , i.e. , it achieves the maximum possible entropy reduction @xmath234 .",
    "this proves , incidentally , that the bound of inequality ( [ clot1 ] ) is tight . in general",
    ", we may define a control system to be optimal in terms of information if the gain in stability obtained by substracting @xmath235 from @xmath236 is exactly equal to the sensor mutual information @xmath176 .",
    "equivalently , a closed - loop control system is optimal if its _ efficiency _",
    "@xmath237 , defined by @xmath238 is equal to 1 .",
    "having determined that optimal controllers do exist , we now turn to the problem of finding general conditions under which a given controller is found to be either optimal ( @xmath239 ) or sub - optimal ( @xmath240 ) . by analyzing thoroughly the proof of theorem 10 ,",
    "one finds that the assessment of the condition @xmath185 , which was not a sufficient condition for open - loop optimality , is again not sufficient here to conclude that a closed - loop controller is optimal .",
    "this comes as a result of the fact that not all control subdynamics applied in a closed - loop fashion are such that @xmath241 in general .",
    "therefore the average final condition entropy @xmath242 need not necessarily be equal to the bound imposed by inequality ( [ bd1 ] ) .",
    "however , in a scenario where the entropy reductions @xmath243 and @xmath244 are both equal to a constant for all control subdynamics , then we effectively recover an analog of the open - loop optimality condition , namely that a zero mutual information between the controller and the controlled system _ after _ actuation is a necessary and sufficient condition for optimality .    _",
    "theorem 11 .",
    "_ under the condition that , for all @xmath45 , @xmath245 where @xmath246 is a constant , then a closed - loop controller is optimal if and only if @xmath185",
    ".    _ proof .",
    "_ to prove the sufficiency part of the theorem , note that the constancy condition ( [ const1 ] ) implies that the minimum for @xmath247 equals @xmath248 .",
    "similarly , closed - loop control must be such that @xmath249 combining these results with the fact that @xmath185 , or equivalently that @xmath250 we obtain @xmath251 to prove the converse , namely that optimality under condition ( [ const1 ] ) implies @xmath185 , notice that eq.([const2 ] ) leads to @xmath252 hence , given that we have optimality , i.e. , given eq.([opt1 ] ) , then @xmath34 must effectively be independent of @xmath17.@xmath91    _ example 4 . _",
    "consider again the now familiar cnot controller .",
    "let us assume that instead of the perfect sensor channel @xmath80 , we have a binary symmetric channel such that @xmath253 and @xmath254 where @xmath255 , i.e. , an error in the transmission occurs with probability @xmath256 @xcite .",
    "the mutual information for this channel is readily calculated to be @xmath257 where @xmath258 is the binary entropy function . by proceeding similarly as in example 1 , the distribution of the final controlled state can be calculated .",
    "the solution is @xmath259 and @xmath260 , so that @xmath261 and @xmath262 by comparing the value of @xmath263 with the mutual information @xmath176 ( recall that @xmath232 ) , we arrive at the conclusion that the controller is optimal for @xmath264 , @xmath265 ( perfect sensor channel ) , and for @xmath200 ( maximum entropy state ) . in going through more calculations",
    ", it can be shown that these cases of optimality are all such that @xmath185.@xmath91      to derive a differential analog of the closed - loop optimality theorem for systems evolving continuously in time , one could try to proceed as follows : sample the state , say @xmath266 , of a controlled system at two time instants separated by some ( infinitesimal ) interval @xmath267 , and from there directly apply inequality ( [ clot1 ] ) to the open- and closed - loop entropy reductions associated with the two end - points @xmath266 and @xmath268 using @xmath269 as the information gathered at time @xmath270 .",
    "however sound this approach might appear , it unfortunately proves to be inconsistent for many reasons .",
    "first , although one may obtain well - defined rates for @xmath271 in the open- or closed - loop regime , the quantity @xmath272 does not constitute a rate , for @xmath269 is not a differential element which vanishes as @xmath267 approaches @xmath81 .",
    "second , our very definition of open - loop control , namely the requirement that @xmath176 be equal to @xmath81 prior to actuation , fails to apply for continuous - time dynamics .",
    "indeed , open - loop controllers operating continuously in time must always be such that @xmath273 if purposeful control is to take place .",
    "finally , are we allowed to extend a result derived in the context of a markovian or memoryless model of controllers to sampled continuous - time processes , even if the sampled version of such processes has a memoryless structure ? surely , the answer is no .    to overcome these problems , we suggest the following conditional version of the optimality theorem .",
    "let @xmath274 , @xmath266 and @xmath268 be three consecutive sampled points of a controlled trajectory @xmath266 .",
    "also , let @xmath275 and @xmath276 be the states of the controller during the time interval in which the state of the controlled system is estimated .",
    "( the actuation step is assumed to take place between the time instants @xmath270 and @xmath277 . ) then , by redefining the entropy reductions as conditional entropy reductions following @xmath278 where @xmath279 represents the control history up to time @xmath270 , we must have @xmath280 note that by thus conditioning all quantities with @xmath281 , we extend the applicability of the closed - loop optimality theorem to any class of control processes , memoryless or not . now , since @xmath282 by the definition of the mutual information , we also have @xmath283 as a result , by dividing both sides of the inequality by @xmath267 , and by taking the limit @xmath284 , we obtain the rate equation @xmath285 if , indeed , the limit exists .",
    "this equation relates the rate at which the conditional entropy @xmath286 is dissipated in time with the rate at which the conditional mutual information @xmath287 is gathered upon estimation .",
    "the difference between the above information rate and the previous pseudo - rate reported in eq.([pr1 ] ) lies in the fact that @xmath288 represents the differential information gathered during the _ latest _ estimation stage of the control process .",
    "it does not include past correlations induced by the control history @xmath281 .",
    "this sort of conditioning allows , in passing , a perfectly meaningful re - definition of open - loop control in continuous - time , namely @xmath289 , since the only correlations between @xmath290 and @xmath276 which can be accounted for in the absence of direct estimation are those due to the past control history .",
    "there are several controllers in the real world which have the character of applying a control signal with amplitude proportional to the distance or error between some estimate @xmath291 of the state @xmath1 , and a desired target point @xmath292 . in the control",
    "engineering literature , such controllers are designated simply by the term _ proportional _",
    "controllers @xcite . as a simple version of a controller of this type",
    ", we study in this section the following system : @xmath293 with all random variables assuming values on the real line . for simplicity",
    ", we set @xmath294 and consider two different estimation or sensor channels defined mathematically by @xmath295 and @xmath296 where @xmath297 ( gaussian distribution with zero mean and variance @xmath298 ) . the first kind of estimation , eq.([cgch ] ) , is a coarse - grained measurement of @xmath1 with a grid of size @xmath171 ; it basically allows the controller to ` see ' @xmath1 within a precision @xmath171 , and selects the middle coordinate of each cell of the grid as the control value for @xmath299 .",
    "the other sensor channel represented by the control state @xmath300 is simply the gaussian channel with noise variance @xmath298 .",
    "let us start our study of the proportional controller by considering the coarse - grained sensor channel first .",
    "if we assume that @xmath301 ( uniform distribution over an interval @xmath302 centered around @xmath81 ) , and pose that @xmath303 is an integer , then we must have @xmath304 now , to obtain @xmath305 , note that the conditional random variables @xmath67 defined by conditional analysis are all uniformly distributed over non - overlapping intervals of width @xmath306 , and that , moreover , all of these intervals must be moved under the control law around @xmath307 without deformation .",
    "hence , @xmath308 , and @xmath309 these results , combined with the fact that @xmath232 , prove that the coarse - grained controller is always optimal , at least provided again that @xmath302 is a multiple of @xmath171 .    in the case of the gaussian channel ,",
    "the situation for optimality is different . under the application of the estimation law ( [ gsch ] ) ,",
    "the final state of the controlled system is @xmath310 so that @xmath311 .",
    "this means that if we start with @xmath312 , then @xmath313 and @xmath314 again , @xmath232 ( recall that @xmath315 does not depend on the choice of the sensor channel ) , and so we conclude that optimality is achieved only in the limit where the signal - to - noise ratio goes to infinity .",
    "non - optimality , for this control setup , can be traced back to the presence of some overlap between the different conditional distributions @xmath63 which is responsible for the mixing upon application of the control .",
    "as @xmath316 , the ` area ' covered by the overlapping regions decreases , and so is @xmath317 .",
    "based on this observation , we have attempted to change the control law slightly so as to minimize the mixing in the control while keeping the overlap constant and found that complete optimality for the gaussian channel controller can be achieved if the control law is modified to @xmath318 with a _ gain _ parameter @xmath319 set to @xmath320 this controller can readily be verified to be optimal .      the second application is aimed at illustrating the closed - loop optimality theorem in the context of a controller restricted to use entropy - increasing actuation dynamics , as is often the case in the control of chaotic systems . to this end , we consider the feedback control scheme proposed by ott , grebogi and yorke ( ogy ) @xcite as applied to the _ logistic map _",
    "@xmath321 where @xmath322 $ ] , and @xmath323 $ ] , @xmath324 . in a nutshell ,",
    "the ogy control method consists in setting the control parameter @xmath325 at each time step @xmath326 according to @xmath327 whenever the estimated state @xmath328 falls into a small control region @xmath329 in the vicinity of a target point @xmath292 .",
    "this target state is usually taken to be an unstable fixed point satisfying the equation @xmath330 , where @xmath331 is the unperturbed map having @xmath332 as a constant control parameter .",
    "moreover , the gain @xmath319 is fixed so as to ensure that the trajectory @xmath333 is stable under the control action .",
    "( see @xcite for a derivation of the stability conditions for @xmath319 based on linear analysis , and @xcite for a review of the field of chaotic control . )",
    "figure 4 illustrates the effect of ogy controller when applied to the logistic map .",
    "the plot of figure 4a shows a typical chaotic trajectory obtained by iterating the dynamical equation ( [ logmap ] ) with @xmath334 .",
    "note on this plot the presence of non - recurring oscillations around the unstable fixed point @xmath335 .",
    "figure 4b shows the orbit of the same initial point @xmath336 now stabilized by the ogy controller around @xmath292 for @xmath337 $ ] . for this latter simulation , and",
    "more generally for any initial points in the unit interval , the controller is able to stabilize the state of the logistic map in some region surrounding @xmath292 , provided that @xmath319 is a stable gain , and that the sensor channel is not too noisy . to evidence the stability properties of the controller",
    ", we have calculated the entropy @xmath338 by constructing a normalized histogram @xmath339 of the positions of a large ensemble of trajectories ( @xmath340 ) starting at different initial points .",
    "the result of this numerical computation is shown in figure 4c . on this graph",
    ", one can clearly distinguish four different regimes in the evolution of @xmath338 , numbered from ( i ) to ( iv ) , which mark four different regimes of dynamics :    \\(i ) _ chaotic motion with constant _",
    "@xmath341 : exponential divergence of nearby trajectories initially located in a very small region of the state space . the slope of the linear growth of entropy",
    ", the signature of chaos @xcite , is probed by the value of the lyapunov exponent @xmath342    \\(ii ) _ saturation _ : at this point , the distribution of positions @xmath343 for the chaotic system has reached a limiting or equilibrium distribution which nearly fills all the unit interval .",
    "\\(iii ) _ transient stabilization _ :  when the controller is activated , the set of trajectories used in the calculation of @xmath338 is compressed around @xmath292 exponentially rapidly in time .",
    "\\(iv ) _ controlled regime _",
    ": an equilibrium situation is reached whereby @xmath338 stays nearly constant . in this regime ,",
    "the system has been controlled down to a given residual entropy which specifies the size of the basin of control , i.e. , the average distance from @xmath292 to which @xmath344 has been controlled .",
    "it is the size of the basin of control , and , more precisely , its dependence on the amount of information provided by the sensor channel which is of interest to us here . in order to study this dependence , we have simulated the ogy controller , and have compared the value of the residual entropy @xmath345 for two types of sensor channel :  the coarse - grained channel @xmath346 , and the gaussian channel @xmath347 .    in the case of the coarse - grained channel",
    ", we have found that the distribution of @xmath348 in the controlled regime was well approximated by a uniform distribution of width @xmath302 centered around the target point @xmath292 .",
    "thus , the indicator value for the size of the basin of control is taken to correspond to @xmath349 which , according to the closed - loop optimality theorem , must be such that @xmath350 where @xmath351 is the lyapunov exponent associated with the @xmath341 value of the unperturbed logistic map , and where @xmath352 is the coarse - grained measurement interval or precision of the sensor channel .",
    "( all logarithms are in natural base in this section . ) to understand the above inequality , note that a uniform distribution for @xmath348 covering an interval of size @xmath353 must stretch by a factor @xmath354 after one iteration of the map with parameter @xmath341 .",
    "this follows from the fact that @xmath355 corresponds to an entropy rate of the dynamical system @xcite ( see also @xcite ) , and holds in an average sense inasmuch as the support of @xmath348 is not too small or does not cover the entire unit interval .",
    "now , for open - loop control , it can be seen that if @xmath356 for all admissible control values @xmath341 , then no control of the state @xmath348 is possible , and the optimal control strategy must consist in using the smallest lyapunov exponent @xmath357 available in order to achieve @xmath358 in the course of the simulations , we noticed that only a very narrow range of @xmath341 values were actually used in the controlled regime , which means that @xmath359 can be taken for all purposes to be equal to @xmath360 . at this point , then , we need only to use expression ( [ coinf ] ) for the mutual information of the coarse - grained channel , substituting @xmath171 with @xmath352 , to obtain @xmath361 this expression yields the aforementioned inequality by posing @xmath362 ( controlled regime ) .",
    ".characteristics of the four target points . [ cols=\"^,^,^,^\",options=\"header \" , ]     the plots of figure 5 present our numerical calculations of @xmath302 as a function of @xmath352 .",
    "each of these plots has been obtained by calculating eq.([contint ] ) using the entropy of the normalized histogram of the positions of about @xmath363 different controlled trajectories .",
    "other details about the simulations may be found in the caption .",
    "what differentiates the four plots is the fixed point to which the ensemble of trajectories have been stabilized , and , accordingly , the value of the lyapunov exponent @xmath351 associated to @xmath364 .",
    "these are listed in table 1 and illustrated in figure 6 .",
    "one can verify on the plots of figure 5 that the points of @xmath302 versus @xmath352 all lie above the critical line ( solid line in the graphs ) which corresponds to the optimality prediction of inequality ( [ cgopt1 ] ) .",
    "also , the relatively small departure of the numerical data from the optimal prediction shows that the ogy controller with the coarse - grained channel is nearly optimal with respect to the entropy criterion .",
    "this may be explained by noticing that this sort of controller complies with all the requirements of the first class of linear proportional controllers studied previously .",
    "hence , we expect it to be optimal for all precision @xmath352 , although the fact must be considered that @xmath365 is only an approximation . in reality",
    ", not all points are controlled with the same parameter @xmath341 for a given value of @xmath352 , as shown in figure 6 .",
    "moreover , how @xmath302 is calculated explicitly relies on the assumption that the distribution for @xmath348 is uniform .",
    "this assumption has been verified numerically ; yet , it must also be regarded as an approximation . taken together",
    ", these two approximations may explain the observed deviations of @xmath302 from its optimal value .    for the gaussian channel , optimality is also closely related to our results about proportional controllers .",
    "the results of our simulations , for this type of channel , indicated that the normalized histogram of the controlled positions for @xmath348 is very close to a normal distribution with mean @xmath292 and variance @xmath366 . as a consequence , we now consider the variance @xmath366 , which for gaussian random variables is given by @xmath367 as the correlate of the size of the basin of control . for this quantity ,",
    "the closed - loop optimality theorem with @xmath368 yields @xmath369 where @xmath298 is the variance of the zero - mean gaussian noise perturbing the sensor channel .    in figure 7",
    ", we have displayed our numerical data for @xmath366 as a function of the noise power @xmath298 .",
    "the solid line gives the optimal relationship which results from taking equality in the above expression , and from substituting the lyapunov exponent associated with one of the four stabilized points listed in table 1 . from the plots of this figure ,",
    "we verify again that @xmath366 is lower bounded by the optimal value predicted analytically .",
    "however , now it can be seen that @xmath366 deviates significantly from its optimal value , making clear that the ogy controller driven by the gaussian noisy sensor channel is not optimal ( except in the trivial limit where @xmath370 ) .",
    "this is in agreement with our proof that linear proportional controllers with gaussian sensor channel are not optimal in general . on the plots of fig .  7",
    ", it is quite remarkable to see that the data points all converge to straight lines .",
    "this suggests that the mixing induced by the controller , the source of non - optimality , can be accounted for simply by modifying our inequality for @xmath366 so as to obtain @xmath371 the new exponent @xmath372 can be interpreted as an _ effective _ lyapunov exponent ; its value is necessarily greater than @xmath373 , since the chaoticity properties of the controlled system are enhanced by the mixing effect of the controller .",
    "the reader familiar with thermodynamics may have noted a strong similarity between the functioning of a controller , when viewed as a device aimed at reducing the entropy of a system , and the thought experiment of maxwell known as the maxwell s demon paradox @xcite . such a similarity was already noted in the introduction section of this work . in the case of maxwell s",
    "demon , the system to be controlled or ` cooled ' is a volume of gas ; the entropy to be reduced is the equilibrium thermodynamic entropy of the gas ; and the ` pieces ' of information gathered by the controller ( the demon ) are the velocities of the atoms or molecules constituting the gas .",
    "when applied to this scheme , our result on closed - loop optimality can be translated into an absolute limit to the ability of the demon , or any control devices , to convert heat to work .",
    "indeed , consider a feedback controller operating in a cyclic fashion on a system in contact with a heat reservoir at temperature @xmath374 . according to clausius law of thermodynamic @xcite",
    ", the amount of heat @xmath375 extracted by the controller upon reducing the entropy of the controlled system by a concomitant amount @xmath263 must be such that @xmath376 in the above equation , @xmath377 is the boltzmann constant which provides the necessary conversion between units of energy ( joule ) and units of temperature ( kelvin ) ; the constant @xmath378 arises because physicists usually prefer to express logarithms in base @xmath256 . from the closed - loop optimality theorem ,",
    "we then write @xmath379   \\nonumber \\\\ & = & \\delta q_{\\text{open}}^{\\max } + ( k_bt\\ln 2)i(x;c),\\end{aligned}\\ ] ] where @xmath380 .",
    "this limit should be compared with analogous results found by other authors on the subject of thermodynamic demons ( see , e.g. , the articles reprinted in @xcite , and especially szilard s analysis of maxwell s demon @xcite which contains many premonitory insights about the use of information in control . )",
    "it should be remarked that the connection between the problem of maxwell s demon , thermodynamics , and control is effective only to the extent that clausius law provides a link between entropy and the physically measurable quantity that is energy .",
    "but , of course , the notion of entropy is a more general notion than what is implied by clausius law ; it can be defined in relation to several situations which have no direct relationship whatsoever with physics ( e.g. , coding theory , rate distortion theory , decision theory ) .",
    "this versatility of entropy is implicit here .",
    "our results do not rely on thermodynamic principles , or even physical principles for that matter , to be true .",
    "they constitute valid results derived in the context of a general model of control processes whose precise nature is yet to be specified .",
    "consideration of entropy as a measure of dispersion and uncertainty led us to choose this quantity as a control function of interest , but other information - theoretic quantities may well have been chosen instead if different control applications require so . from the point of view of optimal control theory ,",
    "all that is required is to minimize a desired performance criterion ( a cost or a lyapunov function ) , such as the distance to a target point or the energy consumption , while achieving some desired dynamic performance ( stability ) using a set of permissible controls @xcite .",
    "for example , one may be interested in maximizing @xmath381 instead of minimizing this quantity if destabilization ( anti - control ) or mixing is an issue @xcite .",
    "as other examples , let us mention the minimization of the relative entropy distance between the distribution of the state of a controlled system and some target distribution @xcite , the problem of coding @xcite , as well as the minimization of rate - like functions in decision or game theory @xcite",
    ".      many questions pertaining to issues of information and control remain at present unanswered .",
    "we have considered in this paper the first level of investigation of a much broader and definitive program of research aimed at providing information - theoretic tools for the study of general control systems , such as those involving many interacting components , as well as controllers exploiting non - markovian features of dynamics ( e.g. , memory , learning , and adaptation ) . in a sense , what we have studied can be compared with the memoryless channel of information theory ; what is needed in the future is something like a control analog of network information theory .",
    "work is ongoing along this direction .",
    "h.t . would like to thank p. dumais for correcting a preliminary version of the manuscript , s. patagonia for inspiring thoughts , an anonymous referee for useful suggestions , and especially v. poulin for her always critical comments .",
    "many thanks are also due to a .-",
    "tremblay for the permission to access the supercomputing facilities of the cerpema at the universit de sherbrooke .",
    "s.l . was supported by darpa , by arda / aro and by the nsf under the national nanotechnology initiative .",
    "was supported by nserc ( canada ) , and by a grant from the darbeloff laboratory for information systems and technology at mit during the initial phase of this work .",
    "from the viewpoint of information , the simplification @xmath382 amounts to a situation whereby the sensor is connected to the actuator by a noiseless communication channel described by a one - to - one mapping between the input @xmath15 and the output @xmath16 of the controller .",
    "the embedding of classical noisy channels into non - noisy channels is analogous to a procedure commonly used in quantum information theory which consists in embedding superoperators into unitary transformations .",
    "bennett , p.w .",
    "shor , ieee trans .",
    "info . th . *",
    "44 * , 2724 , 1998 for more details .",
    "how the distribution for @xmath17 is chosen depends , in general , on which value @xmath30 is characterized as being controllable ; hence the fact that we must consider a conditional distribution @xmath23 for @xmath17 and not the unconditional distribution @xmath383 ."
  ],
  "abstract_text": [
    "<S> we propose an information - theoretic framework for analyzing control systems based on the close relationship of controllers to communication channels . </S>",
    "<S> a communication channel takes an input state and transforms it into an output state . a controller , </S>",
    "<S> similarly , takes the initial state of a system to be controlled and transforms it into a target state . in this sense , a controller can be thought of as an actuation channel that acts on inputs to produce desired outputs . in this transformation process </S>",
    "<S> , two different control strategies can be adopted : ( i ) the controller applies an actuation dynamics that is independent of the state of the system to be controlled ( open - loop control ) ; or ( ii ) the controller enacts an actuation dynamics that is based on some information about the state of the controlled system ( closed - loop control ) . using this communication channel model of control , </S>",
    "<S> we provide necessary and sufficient conditions for a system to be perfectly controllable and perfectly observable in terms of information and entropy . </S>",
    "<S> in addition , we derive a quantitative trade - off between the amount of information gathered by a closed - loop controller and its relative performance advantage over an open - loop controller in stabilizing a system . </S>",
    "<S> this work supplements earlier results [ h. touchette , s. lloyd , phys .  </S>",
    "<S> rev .  </S>",
    "<S> lett .  * 84 * , 1156 ( 2000 ) ] by providing new derivations of the advantage afforded by closed - loop control and by proposing an information - based optimality criterion for control systems . </S>",
    "<S> new applications of this approach pertaining to proportional controllers , and the control of chaotic maps are also presented . </S>"
  ]
}