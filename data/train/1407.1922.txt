{
  "article_text": [
    "we consider a source that communicates with a destination over a line network with n edges , where each intermediate node represents a relay , and each edge represents an erasure channel with state feedback ( all channels are assumed to be orthogonal ) .",
    "the source aims to send a message securely to the destination , in the presence of a passive eavesdropper , eve , who wiretaps an ( unknown ) subset with ( known ) cardinality v of the n channels .",
    "eve receives independently erased versions of the transmissions , as well as the transmitted state feedback from all the channels .",
    "we are interested in ( strong ) information theoretical secrecy .",
    "we believe that the above setup is an interesting scenario for two reasons .",
    "first , line networks capture single paths in arbitrary networks ; indeed , today the vast majority of communication occurs by connecting a source to a destination through a single path .",
    "moreover , feedback is an integral part of most communication protocols , making it possible to exploit it for secrecy .",
    "thus the setup we consider approaches current practices .",
    "second , an understanding of the single path is a necessary first step towards exact characterizations of more general networks .",
    "the main contribution of this paper is to exactly characterize the capacity over an arbitrarily long line network with erasures and feedback when v = 1 and v = n. a series of recent papers in the literature have exactly characterized the secret message capacity for the case of a single link @xcite , a v - network ( with 2 links ) @xcite , and a triangle network ( with 3-links ) @xcite , when only one of these channels is eavesdropped ; in all cases these are at most two - hop networks .",
    "our work builds on these results and further develops new achievability techniques and outer bounds for the case of a multi - hop line network .",
    "the work in @xcite has developed achievability schemes and bounds for arbitrary networks with erasures and feedback but not exact characterizations .",
    "the work in @xcite looks at error free networks , while the work in @xcite does not consider feedback ; additionally , all these works do not allow intermediate nodes to generate ( possibly limited ) randomness , as we do .    to develop our results , we introduce new achievability schemes and outer bounds . in our schemes ,",
    "we consider a spectrum of choices for the intermediate node ( relay ) private randomness , ranging from the extreme case where each relay can generate unlimited private randomness , to the other extreme case where each relay can generate no private randomness , and including all the cases in - between ( limited randomness ) .",
    "we provide an outer bound in the form of a linear program ( lp ) , that applies for arbitrary values of v , and uses a new technique to incorporate the available randomness at the network nodes for the derivation of the outer bound constraints .",
    "we also provide achievability algorithms for the cases v = 1 and v = n , that come from the solution of an achievability lp , and employ new techniques to generate secret keys between the network nodes .",
    "these algorithms use the available randomness at each node efficiently and illustrate the dependency between the amount of available randomness and the achievable secret - message rates .",
    "we prove that for v = 1 and v = n the outer bound lps matches the achievability lps , and thus we have an exact characterization , that applies for all cases of private randomness at the relays ( unlimited , limited , no private randomness ) .    as a side result",
    ", we provide the exact secret key and secret message capacity characterization of a source that has limited private randomness , and is connected to a destination over a single erasure channel with feedback ( eavesdropped by eve ) .",
    "this is a generalization of the scenario examined in @xcite , which assumes unlimited private randomness at the source .",
    "we use this result as a building block for characterizing the secrecy capacity over line networks ; indeed , intermediate relays , if they can not have access to an unlimited private randomness source , they are necessarily limited to use the randomness received by their predecessor node in the line network .",
    "our results enable to make several interesting observations .",
    "first , we verify the usefulness of erasures as well as feedback in securely sending messages and generating secret keys over line networks . indeed , assuming perfect channels in a line network",
    "gives a zero secret message rate even in the case when @xmath0 .",
    "second , our results imply that having feedback between all network nodes is unnecessary : we can achieve the same rates even if we only have feedback from a node to its predecessor .",
    "third , it is also interesting that designing an optimal achievability scheme when intermediate nodes have private randomness is a polynomial - time problem over a line network , while it is known that this a np - hard problem over arbitrary networks @xcite .",
    "finally , like in all previous cases for smaller networks @xcite , a 2-phase scheme where we generate secret keys and then consume them for message encryption ( in each hop ) remains optimal .",
    "the rest of this paper is organized as follows .",
    "section  [ sec : system - model - and ] describes the system model ; section  [ sec : main - results ] summarizes the main results of our work ; section  [ sec : broadcast - erasure - channel ] presents the secret key and secret message achievability algorithms of the broadcast erasure channel with feedback and limited randomness , while sections  [ sec : one - eve - line - network ] and [ sec : all - eves - line - network ] provide the line network achievability algorithms for @xmath0 and @xmath1 , respectively .",
    "all outer bounds are delegate to the appendices .",
    "@xmath2    @xmath3    we consider a line network with @xmath4 hops , i.e. a network where the nodes are ordered and each communicates through a channel with the next one , as shown in fig .",
    "[ fig : line ] . in our case : 1 ) each hop is a discrete memoryless broadcast erasure channel with two receivers : the next node and potentially a passive eavesdropper ( eve ) .",
    "the broadcast channel is conditionally independent ( defined formally in the next paragraph ) 2 ) we have is public state feedback .",
    "that is , each node sends an ack ( or nack ) so that all other nodes ( including eve ) learn whether the packet transmission was successful .",
    "the source ( node 0 , or alice ) aims to end a message w securely ( formally defined later ) to the destination ( node n , or bob ) .",
    "we denote with @xmath5 the set @xmath6 $ ] .",
    "we denote with @xmath7 the set of eavesdropped edges and with @xmath8 its cardinality .",
    "the notation @xmath9 is used to denote that @xmath7 is a subset of @xmath5 of cardinality @xmath8 . for a set @xmath10",
    "we define @xmath11 .",
    "also , we denote @xmath12\\triangleq[1, ... ,j]$ ] .",
    "we use @xmath13 as a time variable and @xmath14 to index the nodes and the edges .",
    "node @xmath14 is connected with node @xmath15 through edge ( channel ) @xmath14 .",
    "we denote with @xmath16 the message that has to be transmitted securely from node @xmath17 to node @xmath4 .",
    "the input to channel @xmath14 sent by node @xmath18 at time slot @xmath13 is denoted @xmath19 and it is a length @xmath20 vector over @xmath21 . in the achievability algorithms",
    "we use the convention that @xmath22 .",
    "we denote with @xmath23 and @xmath24 the @xmath25 output of the @xmath26 channel , i.e. , the vectors received by node @xmath14 and eve respectively .",
    "we use @xmath27 as the symbol of an erasure .",
    "channels are memoryless and conditionally independent , i.e. , @xmath28 , and    @xmath29",
    "@xmath30    let @xmath31 denote the random variable that describes the state of node @xmath14 s channel at the @xmath13th transmission .",
    "@xmath31 is a random variable with values in @xmath32 , where @xmath33 meaning node @xmath14 correctly received the @xmath13th packet . @xmath31",
    "is independent of @xmath34 .",
    "we model the feedback channel as our nodes and eve having access causally to the channel states , i.e.  before the @xmath13th transmission they both know the vector @xmath35 ( defined next ) .",
    "the notation @xmath36 is used to denote the vector @xmath37 , @xmath38 is used to denote the vector @xmath39 , @xmath40 is used to denote the vector @xmath41 , @xmath42}^{i}$ ] is used to denote the vector @xmath43 and similarly for @xmath44 , @xmath45 , @xmath46 . furthermore , each node has access to a rate - limited private random source .",
    "we denote by @xmath47 the available private random source at node @xmath14 .",
    "we will call the case where @xmath0 the one - eve line network , the case where @xmath1 , i.e. , all channels are eavesdropped , the all - eves line network , and in - between cases the v - eves line network .",
    "[ def1]we say that @xmath48 is an achievable secret message rate if for any @xmath49 and sufficiently large @xmath50 the following conditions hold for some functions @xmath51 : @xmath52 where the message @xmath16 is uniformly distributed over @xmath53 .",
    "node @xmath4 is able to recover @xmath16 with high probability : @xmath54 eve gains negligible useful information : @xmath55 the supremum of all achievable secret message rates is the secret message capacity of the network denoted by @xmath56 .    broadcast erasure channel with feedback and limited randomness ]",
    "we say that @xmath57 is an achievable secret key rate if for any @xmath49 and sufficiently large @xmath50 the following conditions hold . for a function @xmath58",
    "node @xmath59 creates , @xmath60 where @xmath61 is the random variable representing the key which takes values in the set @xmath62 node @xmath4 creates , @xmath63 which also takes values in @xmath62 .",
    "the same key is computed with high probability : @xmath64 the key is ( almost ) uniform : @xmath65 the key remains secret form eve : @xmath66 the supremum of all achievable secret key rates is the secret key capacity of the network denoted by @xmath67 .    @xmath68",
    "we here collect the main results of our work . @xmath69      [ thm : the - secret - key]the secret key capacity @xmath67 of the broadcast erasure channel with state feedback and a limited randomness source @xmath70 with @xmath71@xmath72 equals : @xmath73 [ thm : the - secret - message ]    @xmath69    @xmath74    the secret message capacity @xmath56 of the broadcast erasure channel with a limited randomness source @xmath70 with @xmath71@xmath72 equals :    @xmath75    this theorem generalizes the result of @xcite and shows how secrecy depends on the available randomness @xmath76 .",
    "the achievability scheme is presented in section  [ sec : broadcast - erasure - channel ] and the converse proof in appendix a.      [ thm : the - secret - message-1 - 1]the secret message capacity of the one - eve line network , with erasures , state feedback , no private randomness at the intermediate nodes and unlimited private randomness at the source , equals the solution of the following lp : @xmath77    [ thm : the - secret -mess - gen-1]the secret message capacity @xmath67 of the one - eve line network with erasures , state feedback , and at intermediate nodes limited randomness sources @xmath47 , @xmath78 with @xmath71@xmath79 , equals the solution of the following lp : @xmath80 where @xmath81 .    the achievability scheme and the lp variables are explained in sec .",
    "[ sec : one - eve - line - network ] ; the outer bound is in appendix b.@xmath2      [ thm : the - secret - message-1 - 1 - 1]the secret message capacity of the erasure all - eves line network , with erasures , state feedback , no randomness at the intermediate nodes and unlimited randomness at the source , is the solution of the following lp :    @xmath82    [ thm : the - secret -mess - gen-1 - 1]the secret message capacity @xmath67 of the all - eves line network with erasures , state feedback , and limited randomness sources @xmath47 , @xmath78 with @xmath71@xmath79 at intermediate nodes , is the solution of the following lp : @xmath83 where @xmath81 .",
    "the achievability scheme and the lp variables are explained in sec .",
    "[ sec : all - eves - line - network ] ; the outer bound is in appendix b.      the following outer bound , provided in appendix b , applies for all v.    [ thm : outerbound]the secret message capacity @xmath67 of the v - eves line network with erasures , state feedback , and limited randomness sources @xmath47 , @xmath78 with @xmath71@xmath79 is smaller or equal to the solution of the following lp , @xmath84 where @xmath85 @xmath86 .    in order to derive this outer bound we developed a number of techniques that may be useful for other networks .",
    "first we considered all the different @xmath87 `` positionings '' of eve in the channels and we derived constraints for all these cases .",
    "next , in order to connect the constraints for each channel in the line network , we identified the information theoretic term that plays the role of `` available randomness '' for the secret key generation in the next channel .",
    "since we want this randomness to be unknown by eve , this term has to represent the `` secure available randomness '' .",
    "putting all these constraints , for each channel and for each `` positioning '' of eve , together , results in the provided outer bound .",
    "in this section we present the achievability algorithm for secret key generation and secret message transmission of the broadcast erasure channel with feedback and limited randomness depicted in fig .",
    "[ fig:1-hop - network ] .",
    "this serves as a building block of our line network algorithms : indeed , each edge from node @xmath14 to node @xmath15 in the line network can be viewed as a broadcast channel with potentially limited randomness at the source .    from previous work @xcite , we know that , when the source in fig . [ fig:1-hop - network ] has unlimited randomness , the optimal achievability scheme involves two stages : in the first ( key generation phase ) , the source sends at each transmission a different random packet so as to create a secret key with the destination ; in the second ( message transmission phase ) , the source uses the secret key to securely send the message .    when the source has limited randomness , we prove in this paper that the optimal scheme is still a two - phase scheme , where again in the first phase we generate a secret key , and in the second phase we use the key to secure the message .",
    "what changes from the unlimited randomness case , is how we generate the secret key in the first phase , i.e. , how do we best use the limited randomness at the source so as to create a maximum rate key between the source and the destination . additionally ,",
    "because we want to use this scheme as a building block for the line network , we are interested in a second goal as well : we want the destination to receive as many random packets from the source as possible ( independently of whether eve has overhead these packets or not ) .",
    "the reason for this is that , if intermediate nodes in a line network do not generate ( enough ) private randomness , they need to rely on the randomness the receive from previous nodes ( that is , node j+1 relies on node j to receive random packets ) ; thus we want to maximize the amount of random packets they receive . in summary",
    ", we set two goals :    * * g1 : * given limited randomness at the source , achieve the optimal key - generation rate . *",
    "* g2 : * given limited randomness at the source , and optimal key - generation rate , maximize the amount of randomness that the receiver gets from the source .",
    "table [ tab : eff ] compares three algorithms for using the source randomness ( assuming rate d for the source ) for key generation :    1 .",
    "* kg * sends a different random packet at each transmission .",
    "* arq * repeats each random packet until the destination receives it .",
    "* mds - exp * expands the @xmath76 random packets by multiplying them with an mds matrix of size @xmath88 and transmits each of the resulting packets once .",
    "each of these schemes can be optimal wrt our first goal ( max key rate ) in different scenaria . the first scheme ( kg )",
    "is optimal when @xmath89 ( we have a new random packet to send at every transmission ) . a main property it ensures is that , all packets that eve receives and the destination does not , will not be useful to eve , as they will not be used for the key generation .",
    "however , it is inefficient in ensuring this property , because , there will exist random packet transmissions that neither eve nor the destination will receive ; and thus these random packets will be wasted .",
    "the second method ( arq ) ensures that every random packet does reach the destination . in this case",
    "we do not waste any random packets , but since each packet is transmitted multiple times , eve will observe it with higher probability .",
    "this scheme is optimal only when the source randomness is lower than @xmath90 , i.e. we have enough time to send all the random packets we have with arq .",
    "the third method ( mds - exp ) achieves the same property as the first , i.e. , packets eve receives and the receiver does not , are not useful to eve , but avoids the inefficiency in the random packet consumption by expanding in advance the random keys .",
    "this scheme is optimal in key generation for the general case of limited randomness at the source .",
    "the next two theorems prove that arq and mds - exp algorithms preserve the security condition [ eq : security ] .",
    ".[tab : eff ] comparing three ways to use the source randomness for secret key generation . [ cols=\"^,^,^,^\",options=\"header \" , ]     the next general lemma is going to be used extensively in the proofs that follow . it is a generalization of the corresponding lemma in @xcite .",
    "[ lem : c]it is for @xmath91 $ ] :    @xmath92    @xmath93    all we needed was the independence property of @xmath94 .",
    "we can perform the same steps recursively to obtain the result .",
    "the following lemma connects the available randomness with the random innovative ( both to the next node and eve ) packets that the transmitter can produce .",
    "[ lem : d]it is :    @xmath95    @xmath96    the next two theorems provide the converse for theorems [ thm : the - secret - key ] and [ thm : the - secret - message ] .",
    "[ thm:(coverse of sk)](coverse for secret key )    @xmath97    it is , @xmath98 where the second to last inequality is due to @xmath99 being a markov chain ( even when conditioned on @xmath100 ) . and using lemma [ lem : c ] for @xmath101 and @xmath102 we conclude ( dropping the @xmath14 subscripts ) , @xmath103    thus :    @xmath104    the second inequality is direct application of the maurer bound .",
    "[ thm:(coverse - for - sm](coverse for secret message )    @xmath105    the the converse linear program is :    @xmath106    the first two equations where derived in @xcite and the last is derived in theorem [ thm:(coverse of sk ) ] . solving this linear program ,",
    "we come to the desired conclusion .",
    "in this section we will prove theorem [ thm : outerbound ] .",
    "we will construct a converse lp which will be equivalent to the achievability lp and consequently will have the same optimal value . after we derive the inequalities we make the following correspondance of terms :          this means that we forget the meaning of these information theoretic measures and we only use the fact that they are non - negative variables .",
    "some terms correspond to more than one variables .",
    "this can only increase the value of the lp .",
    "@xmath113_{e}}^{n}s_{\\mathcal{n}}^{n})\\\\   & \\geq & i(w;z_{j}^{n}s_{\\mathcal{n}}^{n}|z_{[j-1]_{e}}^{n})\\\\   & = & i(w;z_{j}^{n}s_{j}^{n}|s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})\\;\\textrm{since \\ensuremath{s_{\\mathcal{n}_{-j}}^{n } } is indep .",
    "of \\ensuremath{w}}\\textrm{and \\ensuremath{z_{[j-1]_{e}}^{n}}}\\\\   & = & \\sum_{i=1}^{n}i(w;z_{ji}s_{ji}|z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})\\\\   & = & \\sum_{i=1}^{n}i(w;z_{ji}|z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}s_{ji}z_{[j-1]_{e}}^{n})\\;\\textrm{since \\ensuremath{s_{ji}}is indep .",
    "of \\ensuremath{(wy_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})}}\\\\   & = & \\sum_{i=1}^{n}i(w;x_{ji}|z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}s_{ji}\\in\\{e_{j},e_{j}b_{j}\\})\\cdot\\pr\\{s_{i}\\in\\{e_{j},e_{j}b_{j}\\}\\}\\\\   & = & ( 1-\\delta_{je})\\sum_{i=1}^{n}i(w;x_{ji}|z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})\\end{aligned}\\ ] ]        @xmath115_{e}}^{n}s_{\\mathcal{n}}^{n})\\\\   & \\leq & i(w;y_{j}^{n}z_{[j]_{e}}^{n}s_{\\mathcal{n}}^{n})\\;\\textrm{since it is a markov chain } \\\\   & = & i(w;y_{j}^{n}z_{[j]_{e}}^{n}s_{j}^{n}|s_{\\mathcal{n}_{-j}}^{n})\\;\\textrm{since \\ensuremath{s_{\\mathcal{n}_{-j}}^{n}}is indep . of \\ensuremath{w}}\\\\   &",
    "= & i(w;y_{j}^{n}z_{j}^{n}s_{\\mathcal{n}}^{n}|s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})+\\epsilon\\;\\textrm{due to ( \\ref{eq : def1_5})}\\\\   & = & \\sum_{i=1}^{n}i(w;y_{ji}z_{ji}s_{ji}|y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})+\\epsilon\\\\   & = & \\sum_{i=1}^{n}i(w;y_{ji}z_{ji}|y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}s_{ji})+\\epsilon\\;\\textrm{since \\ensuremath{s_{ji}}is indep . of \\ensuremath{(wy_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]}^{n})}}\\\\   &",
    "= & \\sum_{i=1}^{n}i(w;x_{ji}|y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}s_{ji}\\in\\{b_{j},e_{j}b_{j},e_{j}\\})\\cdot\\pr\\{s_{ji}\\in\\{b_{j},e_{j}b_{j},e_{j}\\}\\}+\\epsilon\\\\   & = & ( 1-\\delta_{j}\\delta_{je})\\sum_{i=1}^{n}i(w;x_{ji}|y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})+\\epsilon.\\end{aligned}\\ ] ]        @xmath118_{e}}^{n})-h\\left(y_{j}^{n}\\mid ws_{\\mathcal{n}}^{n}z_{[j]_{e}}^{n}\\right)\\\\   & \\geq & ( 1-\\delta_{je})\\sum_{i=1}^{n}i(y_{j}^{i-1}s_{j}^{i-1};x_{ji}|z_{j}^{i-1}s_{j}^{i-1}ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})\\:\\textrm{due to lemma } \\ref{lem : c}\\\\   & = & ( 1-\\delta_{je})\\sum_{i=1}^{n}h(x_{i}|z^{i-1}s^{i-1}ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})-h(x_{i}|y^{i-1}z^{i-1}s^{i-1}ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})\\\\   & = & ( 1-\\delta_{je})\\sum_{i=1}^{n}h(x_{i}|z^{i-1}s^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})-h(x_{i}|y^{i-1}z^{i-1}s^{i-1}ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})\\\\   &   & -i(w;x_{i}|z^{i-1}s^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})\\\\   & \\geq & ( 1-\\delta_{je})\\sum_{i=1}^{n}h(x_{i}|y^{i-1}z^{i-1}s^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})-h(x_{i}|y^{i-1}z^{i-1}s^{i-1}ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})\\\\   &   & -i(x_{i};w|z^{i-1}s^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})\\\\   & = & ( 1-\\delta_{je})\\sum_{i=1}^{n}i(w;x_{ji}|y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})-i(w;x_{ji}|z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})\\\\   & \\geq & \\frac{1-\\delta_{je}}{1-\\delta_{j}\\delta_{je}}n\\cdot m-\\epsilon\\;\\textrm{by lemmas \\ref{e-2 } and \\ref{dd-2}}\\end{aligned}\\ ] ]          @xmath121_{e}}^{n}\\right)+h(u_{j-1})\\\\   & = & h\\left(y_{j-1}^{n}u_{j-1}\\mid ws_{\\mathcal{n}}^{n}z_{[j-1]_{e}}^{n}\\right)\\;\\textrm{since \\ensuremath{u_{j-1}}is ind .",
    "of \\ensuremath{(y_{j-1}^{n}ws_{\\mathcal{n}}^{n}z_{[j-1]_{e}}^{n})}}\\\\   & = & h\\left(y_{j-1}^{n}u_{j-1}\\mid ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}\\right)\\;\\textrm{since \\ensuremath{s_{j}^{n}}is ind . of \\ensuremath{(y_{j-1}^{n}wu_{j-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})}}\\\\   & \\geq & i\\left(y_{j-1}^{n}u_{j-1};y_{j}^{n}z_{j}^{n}s_{j}^{n}\\mid ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}\\right)\\\\   & = & \\sum_{i=1}^{n}i\\left(y_{j-1}^{n}u_{j-1};y_{ji}z_{ji}s_{ji}\\mid y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}\\right)\\\\   & = & \\sum_{i=1}^{n}i\\left(y_{j-1}^{n}u_{j-1};y_{ji}z_{ji}\\mid y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}s_{ji}\\right)\\;\\textrm{since \\ensuremath{s_{ji}}is ind . of \\ensuremath{(y_{j-1}^{n}u_{j-1}wy^{i-1}z^{i-1}s^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})}}\\\\   &",
    "= & \\sum_{i=1}^{n}i\\left(y_{j-1}^{n}u_{j-1};y_{ji}z_{ji}\\mid y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}s_{ji}\\in\\left\\ { b_{j},e_{j},e_{j}b_{j}\\right\\ } \\right)\\cdot pr\\left\\ { s_{i}\\in\\left\\ { b_{j},e_{j},e_{j}b_{j}\\right\\ } \\right\\ } \\\\   & = & \\left(1-\\delta_{j}\\delta_{je}\\right)\\sum_{i=1}^{n}i\\left(y_{j-1}^{n}u_{j-1};x_{ji}\\mid y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}s_{ji}\\in\\left\\ { b_{j},e_{j},e_{j}b_{j}\\right\\ } \\right)\\\\   & = & \\left(1-\\delta_{j}\\delta_{je}\\right)\\sum_{i=1}^{n}i\\left(y_{j-1}^{n}u_{j-1};x_{ji}\\mid y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}z_{[j-1]_{e}}^{n}ws_{\\mathcal{n}_{-j}}^{n}\\right)\\\\   &   & \\textrm{since \\ensuremath{s_{ji}}is ind . of \\ensuremath{(y_{j-1}^{n}u_{j-1}x_{ji}wy_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n})}}\\\\   & = & \\left(1-\\delta_{j}\\delta_{je}\\right)\\sum_{i=1}^{n}h\\left(x_{ji}\\mid y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}\\right)-h\\left(x_{i}\\mid y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}wy_{j-1}^{n}u_{j-1}s_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}\\right)\\\\   & = & \\left(1-\\delta_{j}\\delta_{je}\\right)\\sum_{i=1}^{n}h\\left(x_{ji}\\mid y_{j}^{i-1}z_{j}^{i-1}s_{j}^{i-1}ws_{\\mathcal{n}_{-j}}^{n}z_{[j-1]_{e}}^{n}\\right)\\;\\textrm{due to ( \\ref{eq : def1_1})}\\\\   & = & \\frac{1-\\delta_{j}\\delta_{je}}{(1-\\delta_{j})\\delta_{je}}n\\cdot k_{j}^{\\mathcal{n_{\\textrm{e}}}}\\end{aligned}\\ ] ]        * for the fourth constraint * @xmath123 * * : * * @xmath124_{e}}^{n})\\\\   & = & i(w;y_{j}^{n}\\mid s_{\\mathcal{n}}^{n})+h(y_{j}^{n}\\mid ws_{\\mathcal{n}}^{n}z_{[j]_{e}}^{n})\\;\\textrm{since \\ensuremath{s_{\\mathcal{n}}^{n}}is indep . of \\ensuremath{w}}\\\\   & \\leq & i(w;y_{j}^{n}\\mid s_{\\mathcal{n}}^{n}z_{[j]_{e}}^{n})+h(y_{j}^{n}\\mid ws_{\\mathcal{n}}^{n}z_{[j]_{e}}^{n})+\\epsilon\\;\\textrm{due to ( \\ref{eq : def1_5})}\\\\   & = & h(y_{j}^{n}\\mid s_{\\mathcal{n}}^{n}z_{[j]_{e}}^{n})+\\epsilon\\\\   & \\leq & ( 1-\\delta_{j})nl\\log q+\\epsilon\\end{aligned}\\ ] ]      @xmath125_{e}}^{n})\\\\   & = & h(y_{j}^{n}\\mid ws_{\\mathcal{n}}^{n}z_{[j-1]_{e}}^{n})\\textrm { since } j\\in\\mathcal{n_{\\textrm{}}}-\\mathcal{n_{\\textrm{e}}}\\\\   & = & h(y_{j}^{n}z_{j}^{n}\\mid ws_{\\mathcal{n}}^{n}z_{[j-1]_{e}}^{n})\\\\   & \\leq & h(y_{j-1}^{n}u_{j-1}\\mid ws_{\\mathcal{n}}^{n}z_{[j-1]_{e}}^{n})\\;\\textrm{due to markovity}\\\\   & = & h\\left(y_{j-1}^{n}\\mid ws_{\\mathcal{n}}^{n}z_{[j-1]_{e}}^{n}\\right)+h(u_{j-1})\\\\   & = & n\\cdot d_{j-1}^{\\mathcal{n_{\\textrm{e}}}}+n\\cdot d_{j-1}\\end{aligned}\\ ] ]"
  ],
  "abstract_text": [
    "<S> we investigate the problem of information theoretically secure communication in a line network with erasure channels and state feedback . </S>",
    "<S> we consider a spectrum of cases for the private randomness that intermediate nodes can generate , ranging from having intermediate nodes generate unlimited private randomness , to having intermediate nodes generate no private randomness , and all cases in between . </S>",
    "<S> we characterize the secret message capacity when either only one of the channels is eavesdropped or all of the channels are eavesdropped , and we develop polynomial time algorithms that achieve these capacities . </S>",
    "<S> we also give an outer bound for the case where an arbitrary number of channels is eavesdropped . </S>",
    "<S> our work is the first to characterize the secrecy capacity of a network of arbitrary size , with imperfect channels and feedback . as a side result </S>",
    "<S> , we derive the secret key and secret message capacity of an one - hop network , when the source has limited randomness . </S>"
  ]
}