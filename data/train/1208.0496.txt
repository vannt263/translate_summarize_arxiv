{
  "article_text": [
    "the analysis of charged hadron multiplicities in au - au and cu - cu collisions at @xmath0 and 200 gev was done by the phenix collaboration in @xcite .",
    "it was also claimed there that these multiplicities are distributed according to the negative binomial form .",
    "the ua5 collaboration noticed for the first time that charged - particle multiplicity distributions measured in high energy proton-(anti)proton collisions in limited intervals of pseudo - rapidity have this form @xcite .",
    "the negative binomial distribution ( nbd ) is defined as    @xmath1    where @xmath2 , @xmath3 and @xmath4 is a positive real number . in the application to high energy physics",
    "@xmath5 has the meaning of the number of charged particles detected in an event .",
    "the expected value @xmath6 and variance @xmath7 and the variance @xmath8 . [ przyp1 ] ] are expressed as :    @xmath9    multiplicity fluctuations are expressed in terms of the scaled variance :    @xmath10    where @xmath11 is the charged particle multiplicity and the last equality is valid only for the whole population ( the set of all possible outcomes if the experiment is repeated infinitely many times ) , assuming that the hypothesis about the nbd is true .    in application to the high energy physics , the parameters @xmath12 instead of @xmath13 are used usually and    @xmath14    which is the scaled variance , eq .",
    "( [ chargfluct ] ) .",
    "but because the centrality bins have the nonzero width , fluctuations defined by eq .",
    "( [ chargfluct ] ) also include a non - dynamical component .",
    "this component is the result of the fluctuations of the geometry of the collisions within a given centrality bin .",
    "the geometrical fluctuations were evaluated by the phenix collaboration in @xcite .",
    "it turned out that those fluctuations can be expressed by a correction factor , @xmath15 , which is independent of centrality but varies with the collision type . then the pure scaled variance now representing only dynamical fluctuations , i.e. after subtraction of the geometrical component",
    ", can be calculated from the following equation @xcite :    @xmath16    also parameter @xmath4 changes to @xmath17 accordingly    @xmath18    in this analysis the hypothesis that the charged - particle multiplicities measured in ultra - relativistic heavy - ion collisions are distributed according to the nbd is verified with the use of the maximum likelihood method ( ml ) and the likelihood ratio test . more details of this approach can be found in refs .",
    "@xcite .",
    "there are two crucial reasons for this approach :    1 .",
    "the fitted quantity is a probability distribution function ( p.d.f . ) , so the most natural way is to use the ml method , where the likelihood function is constructed directly from the tested p.d.f .. in fact , what is fitted are parameters of the distribution .",
    "the fitted values are the _ estimators _ of these parameters .",
    "it is well - known in mathematical statistics that an ml estimator is consistent , asymptotically unbiased and efficient @xcite .",
    "but even more important is that because of wilks s theorem ( see appendix  [ wilks ] ) one can easily define a statistic , the distribution of which converges to a @xmath19 distribution as the number of measurements goes to infinity .",
    "thus for the large sample the goodness - of - fit can be expressed as a @xmath20-value computed with the corresponding @xmath19 distribution .",
    "the most commonly used method , the least - squares ( ls ) method ( called also the @xmath19 minimization ) , has the disadvantage of providing only the qualitative measure of the significance of the fit , in general .",
    "only if observables are represented by gaussian random variables with known variances , the conclusion about the goodness - of - fit equivalent to that mentioned in the point 1 can be derived ( see appendix  [ capsule ] ) .",
    "it is worth noting that the ml method with binned data and poisson fluctuations within a bin was already applied to fitting multiplicity distributions to the nbd but at much lower energies ( e-802 collaboration @xcite ) .",
    "the number of charged particles @xmath11 is assumed to be a random variable with the p.d.f . given by eq .",
    "( [ nbdist ] ) .",
    "each event is treated as an independent observation of @xmath11 and a set of a given class of events is a sample . for @xmath21 events in the class",
    "there are @xmath21 measurements of @xmath11 , say @xmath22",
    ". some of these measurements can be equal , _",
    "i.e. _ @xmath23 for @xmath24 can happen .",
    "the whole population consists of all possible events with the measurements of 0 , 1 , 2 , ... charged particles and by definition is infinite . ]",
    "let divide the sample into @xmath25 bins characterized by @xmath26 - the number of measured charged particles for @xmath24 and @xmath27 .",
    "[ przyp3 ] ] and @xmath28 - the number of entries in the @xmath29th bin , @xmath30 ( details of the theoretical framework of this section can be found in refs .",
    "then the expectation value of the number of events in the @xmath29th bin can be written as    @xmath31    where @xmath32 is the expected number of all events in the sample , @xmath33 .",
    "this is because one can treat the number of events in the sample @xmath21 also as a random variable with its own distribution - poisson one .",
    "generally , the whole histogram can be treated as one measurement of @xmath25-dimensional random vector @xmath34 which has a multinomial distribution , so the joint p.d.f . for the measurement of @xmath21 and @xmath35",
    "can be converted to the form @xcite :    @xmath36    since now @xmath37 is the p.d.f . for one measurement , @xmath38 is also the likelihood function    @xmath39    with the use of eq .",
    "( [ neventi ] ) the corresponding likelihood function can be written as    @xmath40    then the likelihood ratio is defined as    @xmath41    where @xmath42 , @xmath43 and @xmath44 are the ml estimates of @xmath32 , @xmath45 and @xmath4 with the likelihood function given by eq .",
    "( [ liksubset ] ) and @xmath46 , @xmath47 are the ml estimates of @xmath48 treated as free parameters .",
    "note that since the denominator in eq .",
    "( [ likeliratio ] ) does not depend on parameters , the log - ratio defined as    @xmath49    where @xmath48 are expressed by eq .",
    "( [ neventi ] ) , can be used to find the ml estimates of @xmath32 , @xmath45 and @xmath4 .",
    "the values @xmath42 , @xmath43 and @xmath44 for which @xmath50 has its maximum are the maximum likelihood estimates of parameters @xmath32 , @xmath45 and @xmath4",
    ". then one can defined the test statistic called  likelihood @xmath19 ",
    "@xcite :    @xmath51    note that the maximum of @xmath52 is the minimum of @xmath53 , so the estimates from the condition of the minimum of @xmath53 are the ml estimates .",
    "further , the statistic given by    @xmath54    approaches a @xmath19 distribution asymptotically , i.e. as the number of measurements , here the number of events @xmath21 , goes to infinity ( the consequence of the wilks s theorem , see appendix  [ wilks ] ) .",
    "the values @xmath55 are the estimates of @xmath48 given by    @xmath56    and if one assumes that @xmath32 does not depend on @xmath45 and @xmath4 then @xmath57 .",
    "for such a case    @xmath58    and eq .  ( [ poissonchi ] ) becomes    @xmath59    also then one can just put @xmath60 and eq .",
    "( [ logratio ] ) can be rewritten as    @xmath61    where @xmath62 . thus with the help of eqs .",
    "( [ multinomchi ] ) and ( [ logratfreq ] ) one arrives at    @xmath63    it can be proven that one of the necessary conditions for the existence of the maximum is ( see appendix  [ aaa ] for details ) :    @xmath64    _ i.e. _ the distribution average has to be equal to the experimental average .",
    "this is very good because @xmath65 is what is called in statistics _",
    "a sample mean_. the sample mean is an estimator for the expectation value of the random variable , which is consistent and unbiased @xcite . in other words",
    "the ml estimator of @xmath6 is @xmath65 ( @xmath66 ) .",
    "the method described in sec .",
    "[ liktest ] requires that all bins in a given data set have the width equal to 1 , so as the experimental probability @xmath67 to measure a signal in the @xmath29th bin was equivalent to the probability of the measurement of @xmath68 charged particles ( the first bin is the bin of 0 charged particles detected ) .",
    "this is fulfilled for all bins of the considered data sets    since the test statistic @xmath69 has a @xmath70 distribution approximately in the large sample limit , it can be used as a test of the goodness - of - fit .",
    "the result of the test is given by the so - called @xmath20-value which is the probability of obtaining the value of the statistic , eq .",
    "( [ poissonchi ] ) , equal to or greater then the value just obtained for the present data set , when repeating the whole experiment many times ( see appendix  [ capsule ] ) :    @xmath71    where @xmath72 is the @xmath70 p.d.f . and @xmath73 the number of degrees of freedom , @xmath74 here .",
    "the results of the analysis are presented in tables  [ table1]-[table8 ] and illustrated with figs .",
    "[ fig1]-[fig6 ] .",
    "in fact the whole analysis was done for the two kinds of histograms : ( _ i _ ) bins with the number of entries @xmath75 excluded , tables  [ table1 ] , [ table3 ] , [ table5 ] and [ table7 ] ; ( _ ii _ ) bins with the number of entries @xmath76 , table  [ table4 ] , @xmath77 , tables  [ table2 ] and [ table8 ] or @xmath78 , table  [ table6 ] , excluded . in practice",
    "this corresponds to cutting off less ( _ i _ ) or more ( _ ii _ ) the tails of the full measured histograms .",
    "the tails break the visual agreement between the data and the nbd , cf .",
    "[ fig1 ] and [ fig2 ] .",
    "the condition that only bins with @xmath79 are taken into account is the minimal condition imposed on a histogram to do any statistical inference without monte carlo simulations @xcite .",
    "the condition ( _ ii _ ) corresponds roughly to the choice made originally by the phenix collaboration in their analysis @xcite .",
    "it has turned out that the results of this analysis are qualitatively the same for both choices .",
    "as one can see , the hypothesis in question should be rejected in all considered cases .",
    "but it was claimed that charged - particle multiplicities measured in au - au and cu - cu collisions at @xmath0 and 200 gev are distributed according to the nbd @xcite .",
    "however that conclusion was the result of the application of the ls method .",
    "therefore it seems to be reasonable to check what are the values of the ls test statistic at the ml estimators listed in the third and fourth columns of tables  [ table1]-[table8 ] . for the sample described in sec .",
    "[ liktest ] one can define the ls test statistic ( commonly called the @xmath70 function ) as :    @xmath80    where @xmath81 is given by eq .",
    "( [ neventi ] ) with @xmath60 and @xmath82 ( @xmath83 ) is the uncertainty on @xmath28 ( @xmath67 respectively ) .",
    "note that for @xmath84 the above equation is the pearson s @xmath19 test statistic , whereas for @xmath85 this is the neyman s @xmath19 test statistic ( also called the modified chi - square or modified least - squares method ) , both well known in mathematical statistics @xcite .",
    "the advantage of the use of these statistics is that both follow a @xmath19 distribution asymptotically .",
    "the errors given by @xmath86 or @xmath87 are interpreted as theoretical or experimental statistical errors respectively ( for the discussion of the pros and cons of both see @xcite ) .",
    "it should be stressed that when @xmath82 includes also a systematic error ( e.g. by adding in quadrature to statistical one ) , then the statement about asymptotic form of the distribution of the test statistic is no longer valid .    in the present analysis @xmath88 function , eq .",
    "( [ chidef ] ) , * is not minimized * with respect to @xmath6 and @xmath4 ( or @xmath45 and @xmath4 ) as in the ls method but is calculated at ml estimates of @xmath6 and @xmath4 .",
    "generally , this is allowed in statistics and is equivalent to test a single point in the parameter space . then the tested point might not be the best estimate of the true value but the hypothesis in question becomes the hypothesis only about a particular distribution ( a _ simple _ hypothesis ) . at first sight ,",
    "@xmath89/@xmath73 values of the ninth column of tables  [ table1]-[table8 ] seem to be significant for almost all centrality classes , what agrees with the results of ref .",
    "but this contradicts the results of the likelihood ratio test , which are expressed by @xmath53/@xmath73 and @xmath20-values listed in the seventh and eight columns of tables  [ table1]-[table8 ] .",
    "the crucial question is now why the conclusions from @xmath53 and @xmath89 test statistics are entirely opposite for phenix measurements ?",
    "the main difference between both statistics is that @xmath53 does not depend on the actual errors but @xmath89 does .",
    "additionally , @xmath53 depends explicitly on the number of events whereas @xmath89 does not , cf .",
    "( [ finalchi ] ) and ( [ chidef ] ) . in principle",
    ", one can conclude that @xmath53 statistic implicitly assumes errors of the type @xmath87 because the statistic originated from the likelihood function , eqs .",
    "( [ jointpdf ] ) and ( [ ljointpdf ] ) , which is the product of poisson distributions .",
    "but there is no place to insert actual experimental errors into @xmath53 statistic , eqs .",
    "( [ logratio ] ) and ( [ poissonchi ] ) , this test statistic does not take by definition the experimental errors into account . and",
    "last but not least , the distribution of @xmath69 is known asymptotically , whereas the distribution of @xmath89 at the minimum , when systematic errors are included , is not known , even asymptotically .    in the phenix analysis @xcite errors @xmath90 in eq .",
    "( [ chidef ] ) are represented by the quadrature sum of the statistical and systematic components , the statistical error on the number of entries @xmath28 is equal to @xmath87 exactly @xcite ( the statistical error on @xmath67 is @xmath91 then ) .",
    "the systematic errors were mostly caused by time - dependent variation of results .",
    "data sets were taken over spans of several days to several weeks , during which the total acceptance and efficiency were changing , mainly because of degradation of the tracking detectors @xcite . to estimate these systematic errors , the entire data set was divided into 10 subsets of approximately equal sizes .",
    "then plots from these subsets were overlaid with each other , from which bin - by - bin systematic errors were estimated as 3.0 times the statistical errors , the same for all data sets and centralities @xcite . ] this causes that @xmath92 ( @xmath93 ) , where @xmath94 is the statistical error of the _ _ i__th measurement . hence if statistical errors only were taken into account the values of @xmath89/@xmath73 would be 10 times greater than those listed in tables  [ table1]-[table8 ] .",
    "so it seems that the acceptance of the nbd hypothesis by @xmath89 test is entirely due to the magnitude of systematic errors .",
    "but in fact this is the result of confused inference as it will be shown further .    if one inserts explicit values of phenix errors , @xmath95 , into eq .",
    "( [ chidef ] ) , then @xmath89 test statistic takes the form called @xmath96 from now on ( the author strongly advices to read appendix  [ capsule ] first , before going further ) :    @xmath97    but this exactly is the neyman s @xmath19 test statistic , @xmath98 , multiplied by 0.1",
    ". therefore phenix test statistic estimators of parameters @xmath6 and @xmath4 are neyman s @xmath19 estimators , @xmath99 and @xmath100 respectively .",
    "further , the distribution of the neyman s @xmath19 test statistic @xmath101 asymptotically approaches a @xmath19 distribution with @xmath74 @xcite .",
    "now , the more rigorous justification for inserting ml estimates into @xmath88 , eq .",
    "( [ chidef ] ) , can be given .",
    "the likelihood @xmath19 , pearson s @xmath19 and neyman s @xmath19 test statistics are asymptotically equivalent , i.e. their estimators are consistent , asymptotically normal , with the same minimum variance ( ref .",
    "@xcite , p. 192 ; ref .",
    "@xcite , sec . 18.58 ; ref .",
    "@xcite , pp .",
    "457 - 458 ) . moreover , _ ",
    "so far as the @xmath19 s considered for tests of significance are concerned , any can be used with any of the estimates  _ ( ref .",
    "@xcite , p. 464 ; also see p. 444 ) .",
    "this means that e.g. ml estimates could be put into the neyman s @xmath19 test statistic and still the distribution of such test statistic would approach a @xmath19 distribution asymptotically .",
    "since phenix samples are very large ( see the second column in tables  [ table1]-[table8 ] ) one can reasonably approximate the distribution of @xmath102 by the corresponding @xmath19 distribution .",
    "but what is the distribution of the phenix test statistic @xmath103 then ?",
    "this can be easily done with the use of the general rule of finding the distribution @xmath104 of a function @xmath105 of a random variable @xmath106 with the known p.d.f .",
    "@xmath107 ( ref .",
    "@xcite , p. 14 ) :    @xmath108    if @xmath105 has a unique inverse . in the present case @xmath109 and @xmath110",
    ", so @xmath111 and @xmath112 is the distribution in question .",
    "the expectation value of the phenix test statistic is @xmath113 = e[0.1 \\cdot t_n ] = 0.1 \\cdot e[t_n ] = 0.1 \\cdot n_d$ ] .",
    "thus @xmath114 = 0.1 $ ] or rewriting it a in more familiar way : @xmath115 = 0.1 $ ] , * not 1*. therefore , if the ( phenix ) experiment is reasonable and the hypothesis is true , one should expect to obtain @xmath116 - values of @xmath117 much greater than 0.1 suggests that the hypothesis ( of the nbd ) should be rejected . in the language of appendix  [ capsule ] , the decision boundary for the phenix test statistic @xmath96 should be placed at @xmath118 , * not at @xmath119*. in the case of @xmath96 statistic the @xmath20-value for the hypothesis is given by    @xmath120    where @xmath72 is the @xmath70 p.d.f . with @xmath73 degrees of freedom .",
    "the corresponding values are given in the tenth column of tables  [ table1]-[table8 ] .",
    "altogether there are 33 classes of collision systems and centralities of the phenix measurements @xcite considered here .",
    "they are doubled because of two possibilities of cutting tails in full histograms .",
    "the assessment of the quality of fits presented in tables  [ table1]-[table8 ] depends on the assumed significance level . following the choice done by the ua5 collaboration @xcite",
    ", the @xmath121 level is fixed here .",
    "there are 8 cases where the phenix test is significant at the @xmath121 level at least for one of the two histograms corresponding to the same class .",
    "it is interesting that half of them belong to the case of au - au collisions at @xmath0 gev and are significant for both kinds of histograms with @xmath20-values greater than @xmath122 , see tables  [ table3 ] and [ table4 ] .",
    "the next two happen for au - au collisions at @xmath123 gev , table  [ table2 ] , and the last two for cu - cu collisions at @xmath123 gev , table  [ table6 ] , but only in the case of narrower histograms and with @xmath20-values smaller than @xmath122 .",
    "on opposite , the case of cu - cu collisions at @xmath0 gev has no any significant fit at all , see tables  [ table7 ] and [ table8 ] .",
    "thus one can conclude that only for the phenix collision system au - au at @xmath0 gev the hypothesis of the nbd could not be rejected .",
    "for other systems the hypothesis of the nbd seems to be very unlikely .",
    "what distinguishes the case of au - au collisions at @xmath0 gev from others ?",
    "the only thing which can be noticed from tables  [ table1]-[table8 ] is that the number of events is substantially greater ( about @xmath124 ) in this case .    in principle , the accuracy with which experimental distributions approximate the nbd should increase with the sample size because if the hypothesis is true the postulated form of distribution is exact for the whole population .",
    "so with the growing number of events , the experimental distribution should be closer to the postulated one .",
    "this is also seen in the form of @xmath69 , eq .",
    "( [ finalchi ] ) , where the linear dependence on @xmath21 is explicit . to keep @xmath69 at least constant when @xmath21 ( the sample size ) is growing the relative differences between @xmath125 and @xmath67 have to decrease . the phenix test statistic @xmath96 , eq .",
    "( [ chiphen ] ) , reveals the same feature because relative errors behave like @xmath91 .",
    "so the results of fits for the collision system au - au at @xmath0 gev are even more valuable .",
    "another surprising point is the comparison of the values of the phenix test statistic @xmath96 divided by @xmath73 , the ninth column of tables  [ table1]-[table8 ] , with the corresponding values of ref .",
    "for the choice ( _ ii _ ) , tables  [ table2 ] , [ table4 ] , [ table6 ] and [ table8 ] , the @xmath126/@xmath73 values obtained here are lower than corresponding ones in ref .",
    "values of the parameters @xmath127 are also different from those in ref .",
    "@xcite , what has resulted in slightly different ( @xmath128 lower ) values of the scaled variance @xmath129 , see figs .  [ fig7 ] and [ fig8 ] . to make the comparison easier also values of @xmath130",
    "are presented in the fifth column of tables  [ table1]-[table8 ] .",
    "generally , @xmath131 is greater but the difference does not exceed @xmath132 and decreases with the centrality .",
    "@xmath130 is smaller , especially for case ( _ ii _ ) and the difference also decreases with the centrality ; from about @xmath133 for the least central classes to about @xmath134 for the most central ones .",
    "results of the likelihood ratio test ( likelihood @xmath19 ) suggest that the hypothesis of the nbd of charged - particle multiplicities measured by the phenix collaboration in au - au and cu - cu collisions at @xmath0 and 200 gev should be rejected for all centrality classes .",
    "however , it must be stressed that the maximum likelihood method and the likelihood ratio test do not take actual experimental errors into account .",
    "this could be seen as a drawback but , in fact , only the ls test statistic takes actual experimental errors into account . then the problem with the size of errors might occur when the ls method is used not only to fit parameters of a theoretical model but also to assess how confident the rejection or acceptance of a hypothesis is .",
    "this is because too big or too small errors cause the false inference in this case .",
    "but the judgement whether errors are too big already or still adequate is subjective .",
    "when errors are large enough it is likely that a false hypothesis would be accepted ( this situation is called  error of the second kind  in statistics @xcite ) .",
    "also one can encounter serious difficulties when tries to express somehow the goodness - of - fit when the ls method is applied , as it has been explained in appendix b.    the goodness - of - fit expressed by the @xmath20-value is necessary to assess the quality of fit .",
    "here is an example : let @xmath135 for a test which is @xmath19 distributed .",
    "is this fit good or bad ?",
    "well , it depends on @xmath73 . but how to find any quantitative measure to decide ?",
    "this measure is the @xmath20-value . for @xmath136 , @xmath137",
    "so the fit should be accepted at the significance level @xmath121 , but for @xmath138 , @xmath139 so the fit should be rejected at the same significance level ( ref .",
    "@xcite , p.62 ) . but to calculate the @xmath20-value one has to know the distribution of the test statistic at the parameter estimates . in the general case of the ls test statistic",
    "this distribution is unknown , unless very specific assumptions are fulfilled as it has been shown in appendix b. certainly , assumptions 1 and 3 are not fulfilled when the nbd hypothesis is tested and systematic errors are added in quadrature to statistical ones .",
    "thus at the beginning of the investigations the situation is the following : the likelihood @xmath19 does not take the errors into account , but its distribution is known asymptotically ; the ls test statistic takes errors ( including systematic ones ) into account but its distribution is not known , even asymptotically . in the phenix case and with their estimations of systematic errors ,",
    "these problems have been resolved naturally , i.e. both goals have been achieved - statistical and systematic errors are taken into account and the test statistic distribution is known .",
    "the application of the ls method , in the way as the phenix collaboration did , i.e. with their systematic errors included , has revealed a few very interesting things .",
    "first of all it has turned out that the corresponding ls test statistic ( the phenix test statistic @xmath96 ) equals the neyman s @xmath19 test statistic multiplied by 0.1 .",
    "this enables to use the well known asymptotic properties of the neyman s @xmath19 to find the asymptotic distribution of the phenix test statistic , so the goodness - of - fit can be now calculated because sample sizes are very large here . additionally ,",
    "phenix test statistic estimators of nbd parameters are neyman s @xmath19 estimators . but likelihood @xmath19 and neyman s @xmath19 test statistics are asymptotically equivalent , so for a very large sample their estimators ( and estimates ) should coincide",
    ". therefore determination of nbd parameters with the use of ml method and then insertion of them into the phenix test statistic is reasonable .",
    "note that this way of the determination of nbd parameters has turned out to be much simpler than with the use of the ls method , e.g. the optimal @xmath6 equals @xmath65 ( see appendix  [ aaa ] ) . and last but not least , because the likelihood @xmath19 converges faster to efficiency then the neyman s @xmath19 , this method should be preferable when estimation of parameters and errors on estimates are considered ( ref .",
    "@xcite , p. 193 ; ref .",
    "@xcite , sec . 18.59 ) .",
    "the correct inference from the results of the phenix test statistic @xmath96 , i.e. the test statistic which in opposite to the likelihood @xmath19 takes the systematic errors into account , shows that the hypothesis of the nbd of charged - particle multiplicities measured in au - au and cu - cu collisions at @xmath0 and 200 gev should be accepted roughly in one fourth of phenix classes of the collision system and centrality . in particular , for the phenix collision system au - au at @xmath0 gev as a whole the hypothesis of the nbd could not be rejected , whereas for the cu - cu system at the same energy should be rejected . for two other systems ( both at @xmath123 gev ) the hypothesis of the nbd seems to be very unlikely .",
    "the author thanks jeffery mitchell for helpful explanations of the phenix data .",
    "this work was supported in part by the polish ministry of science and higher education under contract no .",
    "n n202 0523 40 .    [ cols=\"^,^,^,^,^,^,^,^,^,^ \" , ]     [ [ aaa ] ]    dropping terms not depending on the parameters in eq .",
    "( [ logratfreq ] ) , one obtains the following form for the log - likelihood function under consideration :    @xmath140    since the logarithm of the nbd is given by    @xmath141    the necessary conditions for the existence of the maximum have the following form :    @xmath142 \\cr \\cr & & = n \\bigg [ -\\frac{1}{1-p } \\sum_{i=1}^{m}\\;p_i^{ex } y_i   + \\frac{k}{p } \\sum_{i=1}^{m}\\;p_i^{ex } \\bigg ] \\cr \\cr & & = n \\bigg [ -\\frac{1}{1-p } \\langle n_{ch } \\rangle + \\frac{k}{p } \\bigg ] = 0 \\ ; , \\label{dloglikeqp}\\end{aligned}\\ ] ]    @xmath143 \\cr \\cr & & = n \\bigg [ \\sum_{i=1}^{m}\\;p_i^{ex}\\ ; \\sum_{j=1}^{y_i}\\ ; \\frac{1}{k+j-1 } + \\ln{p } \\bigg ] = 0 \\ ; , \\label{dloglikeqk}\\end{aligned}\\ ] ]    where the sum over @xmath144 is 0 if @xmath145 .    from eqs .",
    "( [ dloglikeqp ] ) and ( [ parametpk ] ) one can obtain :    @xmath146    expressing @xmath45 as a function of @xmath4 and @xmath65    @xmath147    and substituting it to eq .",
    "( [ dloglikeqk ] ) the equation which determines @xmath44 is obtained :    @xmath148 = 0 \\;. \\cr & &   \\label{dloglikfk}\\end{aligned}\\ ] ]    the above equation can be solved numerically .",
    "having obtained @xmath44 and substituting it into eq .",
    "( [ oneoverp ] ) @xmath43 is derived .",
    "let @xmath149 be a set of repeated observations of a random variable @xmath150 or a set of a single observation of @xmath21-dimensional random variable @xmath151 ( this appendix is a brief summary based on refs .",
    "the null hypothesis , @xmath152 , specifies a p.d.f . of @xmath150 or a joint p.d.f . of @xmath153 .",
    "the test statistic @xmath154 is a function of the observations ( a function of @xmath21 random variables equivalently ) : @xmath155 . for simplicity",
    "let us assume that @xmath154 is a scalar function .",
    "let @xmath156 be a given p.d.f .",
    "for the statistic @xmath154 if @xmath152 is true .",
    "the qualitative assessment about the compatibility of @xmath152 with the data is expressed as a decision to accept or reject the null hypothesis .",
    "this is done by choosing a value @xmath157 , called the cut or decision boundary .",
    "then , for given observations @xmath149 @xmath158 and if @xmath159 , the hypothesis is rejected ; if @xmath160 , @xmath152 is accepted .",
    "usually @xmath157 is chosen in such a way that one obtains the assumed probability @xmath161 to reject @xmath152 if @xmath152 is true - this is called the significance level :    @xmath162    now , let @xmath153 be an @xmath21-dimensional gaussian random variable with known covariance matrix @xmath163 but not known expectation values .",
    "@xmath153 is related to another variable @xmath164 in such a way that there is a true value function ( @xmath165 a hypothesis ) @xmath166 , which depends on unknown parameters @xmath167 and expectation value of @xmath26 , @xmath168 = \\lambda(x_i;\\vec{\\theta})$ ] .",
    "then one defines the least - squares ( ls ) statistic as    @xmath169_{ij } ( y_j - \\lambda(x_j;\\vec{\\theta } ) ) \\;.",
    "\\label{chilsdef}\\ ] ]    instead , if one has @xmath21 independent gaussian random variables with different unknown means but known variances @xmath170 and the true value function @xmath166 , then the ls statistic , eq .",
    "( [ chilsdef ] ) , becomes    @xmath171    let @xmath153 be a single measurement of the @xmath21-dimensional random variable ( or a set of independent measurements of @xmath21 random variables ) at points @xmath172 .",
    "having replaced the variables by their measured values in eq .",
    "( [ chilsdef ] ) ( or eq .  ( [ chilsdef2 ] ) )",
    "one converts the ls statistic @xmath173 into the function of @xmath174 only .",
    "the next step is to minimize this function with respect to @xmath174 .",
    "values of parameters at the minimum are called the ls estimators , @xmath175 . when one has replaced parameters @xmath174 ( treated as free until now ) by their estimators in eq .",
    "( [ chilsdef ] ) ( or eq .  ( [ chilsdef2 ] ) ) , then a test statistic @xmath176 is obtained .",
    "what is the decision boundary @xmath177 for this test statistic ?",
    "the choice of the proper @xmath177 is the consequence of the following theorem ( see ref .",
    "@xcite , pp .",
    "95 - 96 , 104 ; ref .",
    "@xcite , @xmath17810.4.3 ) . if    1 .",
    "@xmath179 is an @xmath21-dimensional gaussian random variable with known covariance matrix @xmath163 or @xmath179 are independent gaussian random variables with known variances @xmath170 ; 2 .",
    "variables @xmath180 are measured with infinite precision , i.e. without any errors ; 3 .",
    "the hypothesis @xmath181 is linear in the parameters @xmath182 ; and 4 .",
    "the hypothesis is correct ,    then the test statistic @xmath183 is distributed according to a @xmath70 distribution with @xmath184 degrees of freedom .",
    "if the hypothesis @xmath181 is nonlinear in the parameters , the exact distribution of @xmath183 is not known . however , asymptotically ( when @xmath185 ) the distribution of @xmath183 approaches a @xmath70 distribution as well ( ref .",
    "@xcite , p. 287 ; ref .",
    "@xcite , p. 147 ) .",
    "thus when assumptions 1 , 2 and 4 at least are fulfilled and the sample size is large one can consider @xmath183 test statistic as @xmath70 distributed .",
    "the expectation value of a random variable @xmath186 distributed according to the @xmath70 distribution with @xmath73 degrees of freedom is @xmath187 = n_d$ ] and the variance @xmath188 = 2n_d$ ] . as",
    "a result one expects in a `` reasonable '' experiment to obtain @xmath189 ( ref .",
    "@xcite , p. 15 ) .",
    "therefore for the test statistic @xmath190 the decision boundary @xmath191 = n_d$ ] is chosen . usually the so - called reduced @xmath70 is reported , which equals @xmath192 .",
    "so for @xmath192 the decision boundary is just one .",
    "it must be stressed here that this choice is the consequence of the fact that the @xmath183 test statistic is @xmath70 distributed .",
    "if the distribution of @xmath183 is not known at all ( e.g. one of the assumptions 1 , 2 or 4 is not fulfilled or the sample size is small ) , this choice is arbitrary - based on common believe rather than on any justification .",
    "the comparison of the actually obtained value of the test statistic @xmath158 with the decision boundary @xmath157 gives only qualitative information about validity of the hypothesis @xmath152 .",
    "if one wants to express quantitatively how the null hypothesis agrees with the data a test of goodness - of - fit is necessary @xcite .",
    "the value of this test shows the level of the compatibility of the observed data with the predictions of @xmath152 .",
    "this value is given by the probability @xmath20 , under assumption that @xmath152 is true and the experiment would be repeated many times under the same circumstances , of obtaining results as compatible or less with @xmath152 than the result just observed . this probability is called the @xmath20-value of the test and can be expressed as ( ref .",
    "@xcite , p. 300 )    @xmath193    where @xmath194 is the p.d.f . of the @xmath21-dimensional random variable @xmath153 under the null hypothesis @xmath152 . in general",
    "the above integral could be very difficult to calculate unless the p.d.f .",
    "@xmath156 of the test statistic @xmath154 is known somehow , then one obtains ( ref .",
    "@xcite , p. 13 ) :    @xmath195    note that this is not the same as eq .",
    "( [ signiflev ] ) because that expression is the equation for @xmath157 given the significance level @xmath161 and should be solved before the measurement , whereas eq .",
    "( [ pvalueg ] ) is calculated after the measurement and reflects the obtained ( dis)agreement of the observation with the hypothesis @xmath152 .",
    "the criterion for the rejection or acceptance of @xmath152 can be now formulated with the use of @xmath20 and @xmath161 instead of @xmath196 and @xmath157 : if @xmath197 then the hypothesis should be rejected , otherwise should be accepted .    however , the most interesting class of test statistics is such that their distributions are known independently of @xmath152 .",
    "the most important class consists of so - called @xmath70 statistics , i.e. test statistics which are distributed ( at least asymptotically ) in the @xmath70 distribution @xcite .",
    "note that @xmath88 defined earlier , when the assumptions of the theorem are fulfilled , belongs to this class .",
    "the likelihood @xmath19 , eq .",
    "( [ poissonchi ] ) , the pearson s @xmath19 and the neyman s",
    "@xmath19 mentioned in sec .",
    "[ finl ] do as well .",
    "then @xmath20-value is given by    @xmath198    where @xmath72 is the @xmath70 p.d.f . and @xmath73 the number of degrees of freedom .",
    "let @xmath199 be a random variable with p.d.f @xmath200 , which depends on parameters @xmath201 , where a parameter space @xmath202 is an open set in @xmath203 .",
    "for the set of @xmath21 independent observations of @xmath199 , @xmath204 , one can defined the likelihood function          this is a statistic because it does not depend on parameters @xmath208 no more , in the numerator and the denominator there are likelihood function values at the ml estimators of parameters @xmath208 with respect to sets @xmath152 and @xmath202 , respectively .",
    "the wilks s theorem says that under certain regularity conditions if the hypothesis @xmath152 is true ( _ i.e. _ it is true that @xmath209 ) , then the distribution of the statistic @xmath210 converges to a @xmath19 distribution with @xmath211 degrees of freedom as @xmath185 @xcite .",
    "the proof can be found in ref .",
    "note that @xmath212 is possible , so one point in the parameter space ( one value of the parameter ) can be tested as well .",
    "99 a.  adare _ et al . _",
    "( phenix collaboration ) , phys .",
    "c * 78 * , 044902 ( 2008 ) .",
    "g.  j.  alner _",
    "( ua5 collaboration ) , phys .",
    "b * 160 * , 193 ( 1985 ) .",
    "r. e. ansorge _",
    "( ua5 collaboration ) , z.  phys .",
    "c * 43 * , 357 ( 1989 ) .",
    "g. cowan , _ statistical data analysis _ , ( oxford university press , oxford , 1998 )    f. james , _ statistical methods in experimental physics _ , ( world scientific , singapore , 2006 ) s. baker and r. d. cousins , nucl .",
    "* 221 * , 437 ( 1984 ) .",
    "p. g. hoel , _ introduction to mathematical statistics _ , 4th ed . , ( wiley , new york , 1971 )            j.  berkson , ann .",
    "* 8 * , 457 ( 1980 ) .",
    "j.  berkson , biometrics  * 28 * , 443 ( 1972 ) .",
    "f.  beaujean , a.  caldwell , d.  kollar and k.  kroninger , in proceedings of the phystat 2011 workshop on statistical issues related to discovery claims in search experiments and unfolding , cern , geneva , switzerland , 17 - 20 january 2011 , edited by h.  b.  prosper and l.  lyons , cern-2011 - 006 , pp .",
    "177 - 182 .",
    "r. m. dudley , _",
    "18.466 mathematical statistics , spring 2003 _ , ( massachusetts institute of technology : mit opencourseware ) , http://ocw.mit.edu/courses/ mathematics/18 - 466-mathematical - statistics - spring-2003/lecture - notes/"
  ],
  "abstract_text": [
    "<S> likelihood ratio tests are performed for the hypothesis that charged - particle multiplicities measured in au - au and cu - cu collisions at @xmath0 and 200 gev are distributed according to the negative binomial form . </S>",
    "<S> results suggest that the hypothesis should be rejected in the all classes of collision systems and centralities of phenix - rhic measurements . </S>",
    "<S> however , the application of the least - squares test statistic with systematic errors included shows that for the collision system au - au at @xmath0 gev the hypothesis could not be rejected in general . </S>"
  ]
}