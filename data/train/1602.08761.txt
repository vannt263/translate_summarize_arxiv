{
  "article_text": [
    "structured prediction is a powerful and flexible framework for making a joint prediction over mutually dependent output variables .",
    "it has been successfully applied to a wide range of computer vision and natural language processing tasks ranging from text classification to human detection .",
    "however , the superior performance and flexibility of structured predictors come at the cost of computational complexity . in order to construct computationally efficient algorithms , a trade - off",
    "must be made between the expressiveness and speed of structured models .",
    "the cost of inference in structured prediction can be broken down into three parts : acquiring the features , evaluating the part responses and solving a combinatorial optimization problem to make a prediction based on part responses .",
    "past research has focused on evaluating part responses and solving the combinatorial optimization problem , and proposed efficient inference algorithms for specific structures ( e.g. , viterbi and cky parsing algorithms ) and general structures  ( e.g. , variational inference  @xcite ) . however , these methods overlook feature acquisition and part response , which are bottlenecks when the underlying structure is relative simple or is efficiently solved .",
    "consider the dependency parsing task , where the goal is to create a directed tree that describes semantic relations between words in a sentence .",
    "the task can be formulated as a structured prediction problem , where the inference problem concerns finding the maximum spanning trees ( msts ) in a directed graphs @xcite .",
    "each node in the graph represents a word , and the directed edge @xmath0 represents how likely @xmath1 depends on @xmath2 .",
    "[ fig : motivate ] shows an example of a dependency parse and the trade off between a rich set of features and the prediction time .",
    "introducing complex features has the potential to increase system performance , however they only distinguish among a small subset of `` difficult '' parts .",
    "therefore , computing complex features for all parts on every example is both computationally costly and unnecessary to achieve high levels of performance .",
    "we address the problem of structured prediction under test - time budget constraints , where the goal is to learn a system that is computationally efficient during test - time with little loss of predictive performance .",
    "we consider test - time costs associated with the computational cost of evaluating feature transforms or acquiring new sensor measurements .",
    "intuitively , our goal is to learn a system that identifies the parts in each example incorrectly classified / localized using `` cheap '' features and additionally yield large reductions in error over the entire structure given `` expensive '' features due to improved distinguishability and relationships to other parts in the example .",
    "we consider two forms of the budgeted structured learning problem , prediction under expected budget constraints and anytime prediction . for both cases ,",
    "we consider the streaming test - time scenario where the system operates on each test example without observation or interaction of other test examples . in the _ expected budget constraint _ setting , the system chooses features to acquire for each example , to minimize prediction error subject to an average feature cost constraint . a fixed budget is given by the user during training time , and during test - time , the system is tasked with both allocating resources as well as determining the features to be acquired with the allocated resources .",
    "in the _ anytime structured prediction _ setting , the system chooses features to be acquired sequentially for each example to minimize prediction error at each time step , allowing for accurate prediction at anytime .",
    "no budget is specified by the user during training time .",
    "instead , the system sequentially chooses features to minimize prediction error at any time as features are acquired .",
    "this setting requires a single system able to predict for any budget constraint on each example .",
    "we learn systems capable of adaptive feature acquisition for both settings .",
    "we propose learning policy functions to exploit relationships between parts and adapt to varying length examples .",
    "this problem naturally reduces policy learning to a structured learning problem , allowing the original model to be used with minor modification .",
    "the resulting systems reduce prediction cost during test - time with minimal loss of predictive performance .",
    "we summarize our contributions as follows : + formulation of structured prediction under expected budget constraints and anytime prediction . + reduction of both these settings to conventional structured prediction problems .",
    "+ demonstration that structured models benefit from having access to features of multiple complexities and can perform well when a only a subset of parts use the expensive features .",
    "we begin with reviewing structured prediction problem and formulating it under an expected budget constraint .",
    "we then extend the formulation to anytime structured prediction .",
    "* structured prediction : * the goal in structured prediction is to learn a function , @xmath3 , that maps from an input space , @xmath4 , to a structure space , @xmath5 .",
    "in contrast to multi - class classification , the space of outputs @xmath5 is not simply categorical but instead is assumed to be some exponential space of outputs ( often of varying size dependent on the feature space ) containing some underlying structure , generally represented by multiple parts and relationships between parts .",
    "for example , in dependency parsing , @xmath6 are features representing a sentence ( e.g. , words , pos tags ) , and @xmath7 is a parse tree .    in a structured prediction model , the mapping function @xmath3 is often modeled as @xmath8 , where @xmath9 is a scoring function .",
    "we assume the score can be broken up into sub - scores across components @xmath10 , @xmath11 , where @xmath12 is the output assignment associated with the component @xmath13 .",
    "the number of sub - components , @xmath14 , varies across examples . for the dependency parsing example",
    ", each @xmath13 is an edge in the directed graphs , and @xmath12 is an indicator variable for whether the edge is in the parse tree .",
    "the score of a parse tree consists of the scores @xmath15 of all its edges .",
    "our goal is to reduce the cost of prediction during test - time ( representing computational time , energy consumption , etc . ) .",
    "we consider the case where a variety of scoring functions are available to be used for each component .",
    "additionally , associated with each scoring function is an evaluation cost ( such as the time or energy consumption required to extract the features for the scoring function ) .    for each example",
    ", we define a state @xmath16 , where the space of states is defined @xmath17 , representing which of the @xmath18 features is used for the @xmath14 components during prediction . in the state",
    ", the element @xmath19 indicates that the @xmath20 feature will be used during prediction for component @xmath13 . for any state @xmath21",
    ", we define the evaluation cost : @xmath22 where @xmath23 is the ( known ) cost of evaluating the @xmath24 feature for a single part .",
    "we assume that we are given a structured prediction model @xmath25 that maps from a set of features @xmath26 and a state @xmath27 to a structured label prediction @xmath28 . for a predicted label",
    ", we have a loss @xmath29 that maps from a predicted and true structured label , @xmath30 and @xmath31 , respectively , to an error cost , generally either an indicator error , @xmath32 , or a hamming error , @xmath33 . for an example @xmath34 and state @xmath21 , we now define the modified loss @xmath35 that represents the error induced by predicting a label from @xmath36 using the sensors in @xmath21 combined with the cost of acquiring the sensors in @xmath21 , where @xmath37 is a trade - off pattern adjusted according to the budget @xmath38 , or the state cost , @xmath39 and extends to general losses ] .",
    "a small value of @xmath37 encourages correct classification at the expense of feature cost , whereas a large value of @xmath37 penalizes use of costly features , enforcing a tighter budget constraint .",
    "we define a policy @xmath40 that maps from the feature space @xmath4 and the initial state @xmath41 to a new state . for ease of reference",
    ", we refer to this policy as the feature selection policy .",
    "our goal is to learn a policy @xmath42 chosen from a family of functions @xmath43 that , for a given example @xmath36 , maps to a state with minimal expected modified loss , @xmath44.$ ] in practice , @xmath45 denotes a set of i.i.d training examples : @xmath46 note that the objective of the minimization can be expanded with respect to the space of states , allowing the optimization problem in to be expressed @xmath47 from this , we can reformulate the problem of learning a policy as a structured learning problem .",
    "[ thm.onestep_theorem ] the minimization in is equivalent to the structured learning problem : @xmath48    proofs can be found in suppl .",
    "theorem [ thm.onestep_theorem ] maps the policy learning problem in to a weighted structured learning problem . for each example",
    "@xmath49 , an example / label pair is created for each state @xmath21 with an importance weight representing the savings lost by not choosing the state @xmath21 .",
    "unfortunately , the expansion of the cost function over the space of states introduces the summation over the combinatorial space of states . to avoid this",
    ", we instead introduce an approximation to the objective in . using a single indicator function ,",
    "we formulate the approximate policy @xmath50,\\end{aligned}\\ ] ]    [ eq : s_star ] & s^*(x_i , y_i)=_s c(x_i , y_i , s ) & &    and the example weight is defined as @xmath51 .",
    "this formulation reduces the objective from a summation over the combinatorial set of states to a single indicator function for each example and represents an upper - bound on the original risk .",
    "[ thm.onestep_ub ] the objective in is an upper - bound on the objective in .",
    "note that the second term is not dependent on @xmath42 .",
    "thus , theorem [ thm.onestep_ub ] leads to an efficient algorithm for learning a policy function @xmath42 by solving an importance - weighted structured learning problem : @xmath52 where each example @xmath49 having a pseudo - label @xmath53 and importance weight @xmath54 .",
    "* combinatorial search space : * finding the psuedo - label in eqn . involves searching over the combinatorially large search space of states , @xmath55 , which is computationally intractable .",
    "instead , we present trajectory - based and parsimonious pseudo - labels for approximating @xmath56 . _",
    "trajectory search : _ the trajectory - based pseudo - label is a greedy approximation to the optimization in eqn . . to this end , define @xmath57 as the 1-stage feasible transitions : @xmath58 where @xmath59 is the hamming distance .",
    "we define a trajectory of states @xmath60 where @xmath61 .",
    "the initial state is assumed to be @xmath62 where none of the @xmath18 features are evaluated for the @xmath10 components .",
    "for each example @xmath63 , we obtain a trajectory @xmath64 , where the terminal state @xmath65 is the all - one state .",
    "we choose the pseudo - label from the trajectory : @xmath66 note that by restricting the search space of states differing by a single component , the approximation needs to only perform a polynomial search over states as opposed to the exhaustive combinatorial search in eqn . .",
    "observe that the modified loss is not strictly decreasing , as the cost of adding features may outweigh the reduction in loss at any time . empirically , this approach is computationally tractable and is shown to produce strong results .",
    "_ parsimonious search : _ rather than a trajectory search , which requires an inference update as we acquire more features , we consider an alternative one stage update here . the idea is to look for 1-step transitions that can potentially improve the cost .",
    "we then simultaneously update all the features that produce improvement .",
    "this obviates the need for a trajectory search .",
    "in addition we can incorporate a guaranteed loss improvement for our parsimonious search .",
    "@xmath67 note that the potential candidate transitions can be non - unique and thus we generate a collection of potential state transitions , @xmath57 . to obtain the final state we take the union over these transitions ,",
    "namely , @xmath68 suppose we set the margin @xmath69 , replace the cost - function with the loss function then this optimization is relatively simple ( assuming that acquiring more features does not increase the loss ) .",
    "this is because the new state is simply the collection of transitions where the sub - components are incorrect .",
    "finding the parsinomious pseudo - label is computationally efficient and empirically shows similar performance to the trajectory - based pseudo - label .",
    "choosing the pseudo - label requires knowledge of the budget @xmath38 to set the cost trade - off parameter @xmath37 .",
    "if the budget is unspecified or varies over time , a system capable of adapting to changing budget demands is necessary . to handle this scenario",
    ", we propose an anytime system in the next section .      in many applications ,",
    "the budget constraint is unknown a priori or varies from example to example due to changing resource availability and an expected budget system as in section [ section.expected_budget ] does not yield a feasible system .",
    "we instead consider the problem of learning an anytime system @xcite . in this",
    "setting , a single system is designed such that when a new example arrives during test - time , features are acquired until an arbitrary budget constraint ( that may vary over different examples ) is met for the particular example . note that an anytime system is a special case of the expected budget constrained system . instead of an expected budget , instead",
    "a hard per - example budget is given .",
    "a single system is applied to all feasible budgets , as opposed to learning unique systems for each budget constraint .",
    "we model the anytime learning problem as sequential state selection .",
    "the goal is to select a trajectory of states , starting from an initial state @xmath70 where all components use features with negligible cost . to select this trajectory of states ,",
    "we define policy functions @xmath71 , where @xmath72 is a function that maps from a set of structured features @xmath36 and current state @xmath21 to a new state @xmath73 .",
    "the sequential selection system is then defined by the policy functions @xmath74 . for an example @xmath36 ,",
    "the policy functions produce a trajectory of states @xmath75 defined as follows : @xmath76    our goal is to learn a system with small expected loss at any time @xmath77 $ ] .",
    "formally , we define this as the average modified loss of the system over the trajectory of states : @xmath78\\end{aligned}\\ ] ] where @xmath43 is a user - specified family of functions .",
    "unfortunately , the problem of learning the policy functions is highly coupled due to the dependence of the state trajectory on all policy functions .",
    "note that as there is no fixed budget , the choice of @xmath37 dictates the behavior of the anytime system .",
    "decreasing @xmath37 leads to larger increases in classification performance at the expense of budget granularity .",
    "we propose a greedy approximation to the policy learning problem by sequentially learning policy functions @xmath71 that minimize the modified loss : @xmath79\\end{aligned}\\ ] ] for @xmath80 .",
    "note that the @xmath81 selected in does not take into account the future effect on the loss in .",
    "we consider @xmath81 in to be a greedy approximation as it is instead chosen to minimize the immediate loss at time @xmath82 .",
    "we restrict the output space of states for the policy @xmath81 to have the same non - zero components as the previous state with a single feature added .",
    "this space of states can be defined @xmath83 where @xmath59 is the hamming distance .",
    "note that this mirrors the trajectory used for the trajectory - based pseudo - label .    as in section [ section.expected_budget",
    "] , we take an empirical risk minimization approach to learning policies . to this end",
    "we sequentially learn a set of function @xmath71 minimizing the risk : @xmath84{\\sum_{s \\in \\mathcal{s}(s^{t-1}(x_i))}}&c\\left(x_i , y_i , s\\right)\\mathbbm{1}_{\\pi(x_i , s^{t-1}(x_i))=s},\\end{aligned}\\ ] ] enumerating over the space of states that the policy @xmath81 can map each example .",
    "note that the space of states @xmath85 may be empty if all features are acquired for example @xmath49 by step @xmath86 .",
    "training set , @xmath87 @xmath88 train @xmath81 according to thm .",
    "[ thm.structured_learning_eq ] update states : @xmath89 @xmath90 @xmath91    policy , @xmath92 , example , @xmath36 , budget ,",
    "@xmath38 @xmath93 @xmath94 , @xmath95 @xmath96    as in thm . [ thm.onestep_theorem ] , the problem of learning the sequence of policy functions @xmath71 can be viewed as a weighted structured learning problem .",
    "[ thm.structured_learning_eq ] the optimization problem in is equivalent to solving an importance weighted structured learning problem using an indicator risk of the form : @xmath97{\\sum_{s \\in \\mathcal{s}(s^{t-1}(x_i))}}\\,\\,\\,w(x_i , y_i , s)\\mathbbm{1}_{\\pi(x_i , s^{t-1}(x_i))\\neq s},\\end{aligned}\\ ] ]    & w(x_i , y_i , s)=_s(s^t-1(x_i))c(x_i , y_i , s)- c(x_i , y_i , s ) . &",
    "&    this is equivalent to an importance weighted structured learning problem , where each state @xmath98 in @xmath85 defines a pseudo - label for the example @xmath49 with an associated importance @xmath99 .",
    "theorem [ thm.structured_learning_eq ] reduces the problem of learning a policy to an importance weighted structured learning problem .",
    "replacement of the indicators with upper - bounding convex surrogate functions results in a convex minimization problem to learn the policies @xmath92 .",
    "in particular , use of a hinge - loss surrogate converts this problem to the commonly used structural svm .",
    "experimental results show significant cost savings by applying this sequential policy .    the training algorithm is presented in algorithm [ alg : policy_training ] . at time @xmath100 , the policy @xmath101 is trained to minimize the immediate loss . given this policy ,",
    "the states of examples at time @xmath102 are fixed , and @xmath103 is trained to minimize the immediate loss given these states .",
    "the algorithm continues learning policies until every feature for every example as been acquired . during test - time",
    ", the system sequentially applies the trained policy functions until the specified budget is reaches , as shown in algorithm [ alg : test - time_policy ] .",
    "multi - class prediction with test - time budget has received significant attention ( see e.g. ,  @xcite ) .",
    "fundamentally , multi - class classification based approaches can not be directly applied to structured settings for two reasons : ( 1 ) unlike multi - class prediction , in a structured setting , we have many parts with associated features and costs for each part .",
    "this often requires a coupled adaptive part by part feature selection policy applied to varying structures ; ( 2 ) : in contrast to multi - class prediction , structured prediction requires solving a constrained optimization problem in test - time , which is often computationally expensive and must be taken into account .",
    "strubell et al .",
    "@xcite improve the speed of a parser that operates on search - based structured prediction models , where joint prediction is decomposed to a sequence of decisions .",
    "in such a case , resource - constrained multi - class approaches can be applied , however this reduction only applies to search - based models that are fundamentally different from the graph - based models we discussed ( with different types of theoretical guarantees and use cases ) . applying their policy to the case of graphical models",
    "requires repeated inferences , dramatically increasing the computational cost when inference is slow .",
    "similar observations apply to weiss et al .",
    "@xcite , who present a scheme for adaptive feature selection assuming the computational costs of policy execution and inference are negligible .",
    "their approach uses a reinforcement learning scheme , requiring inference at each step of their policy to estimate rewards . for complex inference tasks , repeatedly executing the policy ( performing inference ) can negate any computational gains induced by adaptive feature selection ( see fig . 3 in @xcite ) .",
    "@xcite use imitation learning to adaptively select features for dependency parsing .",
    "their approach can be viewed as an approximation of eqn . with a parsimonious search .",
    "although their policy avoids performing inference to estimate reward , multiple inferences are required for each instance due to the design of action space .",
    "overhead is avoided by exploiting the specific inference structure ( maximal spanning tree over fully connected graph ) , and it is unclear if it can be generalized .",
    "methods to increase the speed of inference ( predicting the given part responses ) have been proposed @xcite .",
    "these approaches can be incorporated into our approach to further reduce computational cost and therefore are complementary .",
    "more focused research has improved the speed of individual algorithms such as object detection using deformable parts models @xcite and dependency parsing  @xcite .",
    "these methods are specialized , failing to generalize to varying graph size and/or structures and relying on problem - specific heuristics or algorithm - specific properties .",
    "adaptive features approaches have been designed to improve accuracy , including easy - first decoding strategies  @xcite , however these methods focus on performance as opposed to computational cost .",
    "in this section , we demonstrate the effectiveness of the proposed algorithm on two structured prediction tasks in different domains : dependency parsing and ocr . we report the results on both anytime and expected case policies and refer to the latter one as one - shot policy .",
    "our focus is mainly on the policy and not on achieving the state of the art performance on either of these domains .    at a high - level , policies for resource constrained structured prediction must manage & tradeoff benefits of three resources , namely , feature acquisition costs , intermediate inferencing costs , and policy overhead costs that decides between feature acquisition and inferencing .",
    "some methods as described earlier account for feature costs but not inference and overhead costs .",
    "other methods incorporate inference into their policy ( meta - features ) for selecting new features but do not account for the resulting policy overhead .",
    "our approach poses policy optimization as a structured learning problem and in turn jointly optimizes these resources as demonstrated empirically in our experiments .",
    "we compare our system to the q - learning approach in @xcite and two baselines : a uniform policy and a myopic policy .",
    "the uniform policy takes random part level actions .",
    "the uniform policy will help us show that the performance of our policy does not come from removing redundant features , but clever allocation of them among samples . as a second baseline",
    ", we adapt the myopic policy used by @xcite to the structured prediction case .",
    "the myopic policy runs the structured predictor initially on all cheap features , then looks at the total confidence of the classifier normalized by the sample size ( e.g. sentence length ) .",
    "if the confidence is below a threshold , it chooses to acquire expensive features for all positions . finally , we compare against the q - learning method proposed by @xcite .",
    "this method requires global features for structures with varying size . from now on we will refer to features that require access to more than one part as complex features and part level features as simple features . in their case , they use confidence feedback from the structured predictor which induces additional inference overhead for the policy .",
    "in addition to this , it is not straightforward to apply this approach to do part by part feature selection on structures with varying sizes .",
    "we adopt structured - svm  @xcite to solve the policy learning problems for expected and anytime cases defined in and , respectively . for the structure of the policy @xmath42 we use a graph with no edges due to its simplicity . in this form",
    ", the policy learning problem can be written as a sample weighted svm .",
    "we discuss the details in the appendix due to space constraints .",
    "we show in the following that complex features indeed benefit the policy , but simple features perform better for cases where the inference time and feature costs are comparable and the additional overhead is unwanted .",
    "finally , we show that part by part selection outperforms global selection .",
    "* optical character recognition * we tested our algorithm on a sequence - label problem , the ocr dataset @xcite composed of 6,877 handwritten words , where each word is represented as a sequence of 16x8 binary letter images .",
    "we use a linear - chain markov model , and similar to the setup in @xcite , use raw pixel values and hog features with 3x3 cell size as our feature templates .",
    "we split the data such that 90% percent is used for training and 10% is used for test .",
    "[ fig : ocr_results ] shows the average letter accuracy vs. total running time .",
    "the proposed system reduces the budget for all performance levels , with a savings of up to 50 percent at the top performance .",
    "note that weiss13 can not operate on part by part level when the graph structure is varying .",
    "we see that using complex part by part selection has significant advantage over using uniform feature templates .",
    "furthermore , fig [ fig : ocr_easy_example ] shows the behavior of the policy on an individual example for the anytime model , significant gains in accuracy are made in first several steps by correctly identifying the noisy letters .",
    "* dependency parsing * we follow the setting in @xcite and conduct experiments on english penn treebank ( ptb ) corpus  @xcite . all algorithms are implemented based on the graph - based dependency parser  @xcite in illinois - sl library  @xcite , where the code is optimized for speed . two sets of feature templates are considered for the parser .",
    "the first ( @xmath104 ) considers the part - of - speech ( pos ) tags and lexicons of @xmath2 , @xmath1 , and their surrounding words ( see @xcite ) .",
    "the other ( @xmath105 ) only considers the pos features .",
    "the policy assigns one of these two feature templates to each word in the sentence , such that all the directed edges @xmath0 corresponding to the word @xmath2 share the same feature templates .",
    "the first feature template , @xmath105 , takes 165 @xmath106s per word and the second feature template , @xmath104 , takes 275 @xmath106s per word to extract the features and compute edge scores .",
    "the decoding by chu  liu - edmonds algorithm is 75 @xmath106s per word , supporting our hypothesis that feature extraction makes a significant portion of the total running time yet the inference time is not negligible . due to the space limit , we present further details of the experiment setting in the appendix .        fig . [",
    "fig : depparse_results ] shows the test performance ( unlabeled attachment accuracy ) along with inference time .",
    "we see that all one - shot policies perform similarly , losing negligible accuracy when using half of the available expensive features .",
    "when we apply the length dictionary filtering heuristic in @xcite , our parser achieves 89.7% uas on ptb section 23 with overall running time merely 7.5 seconds ( i / o excluded , 10s with i / o ) and obtains 2.9x total speed - up with losing only 1% uas comparing to the baseline . as it does not reflect the performance of policies in general",
    "] this significant speed - up over an efficient implementation is remarkable .",
    "although marginal , one - shot policy with greedy trajectory has the strongest performance in low budget regions .",
    "this is because the greedy trajectory search has better granularity than parsimonious search in choosing positions that decrease the loss early on .",
    "the anytime policy is below one - shot policy for all budget levels . as discussed in [ sec.anytime_pol ] ,",
    "the anytime policy is more constrained in that it has to achieve a fixed budget for all examples .",
    "the naive myopic policy performs worse than uniform since it has to run inference on samples with low confidence two times , adding approximately 4.5 seconds of extra time for the full test dataset .",
    "we then explore the effect of importance weights for the greedy policy .",
    "we notice a small improvement .",
    "we hypothesize that this is due to the policy functional complexity being a limiting factor .",
    "we also conduct ablative studies to better understand the policy behavior .",
    "[ fig.depth_dis ] shows the distribution of depth for the words that use expensive and cheap features in the ground truth dependency tree .",
    "we expect investing more time on the low - depth words ( root in the extreme ) to yield higher accuracy gains .",
    "we observe this phenomenon empirically , as the policy concentrates on extracting features close to the root .",
    "[ [ proof - of - theorem-2.1 ] ] proof of theorem 2.1 + + + + + + + + + + + + + + + + + + + +     + the objective in ( 1 ) can be expressed : @xmath107.\\end{aligned}\\ ] ] note that @xmath108 , allowing for further simplification : removing constant terms ( that do not affect the output of the @xmath109 ) yields the expression in thm .",
    "[ [ proof - of - theorem-2.2 ] ] proof of theorem 2.2 + + + + + + + + + + + + + + + + + + + +     + for a single example / label pair @xmath110 , consider the two possible values of the term in the summation of ( 4 ) . in the event that @xmath111 : @xmath112 which is equivalent to the value of ( 2 ) if @xmath111 .",
    "otherwise , @xmath113 , and therefore : @xmath114 this is an upper - bound on ( 1 ) , and therefore ( 2 ) is a valid upper - bound on ( 1 ) .    [ [ proof - of - theorem-2.3 ] ] proof of theorem 2.3 + + + + + + + + + + + + + + + + + + + +     + note that the objective in ( 7 ) can be expressed : @xmath115.\\end{aligned}\\ ] ] note that @xmath116 , allowing for further simplification : @xmath117\\\\ = \\sum_{i=1}^{n}&\\bigg[\\max_{s'\\in \\mathcal{s}(s^{t-1}(x_i))}c(x_i , y_i , s')\\\\ & + \\sum_{s \\in \\mathcal{s}(s^{t-1}(x_i))}\\bigg(\\max_{s'\\in \\mathcal{s}(s^{t-1})(x_i))}c(x_i , y_i , s')\\\\ -&c\\left(x_i , y_i , s\\right)\\bigg)\\left(\\mathbbm{1}_{\\pi(x_i , s^{t-1}(x_i))\\neq s}-1\\right)\\bigg].\\end{aligned}\\ ] ] removing constant terms ( that do not affect the output of the @xmath109 ) yields the expression in ( 8) .",
    "[ [ dependency - parsing ] ] dependency parsing + + + + + + + + + + + + + + + + + +    we split ptb corpus into two parts , sections 02 - 22 and section 23 as training and test sets .",
    "we then conduct a modified cross - validation mechanism to train the feature selector and the dependency parser .",
    "note that the cost of policy is dependent on the structured predictor .",
    "therefore , learning policy on the same training set of the predictor may cause the structured loss to be overly optimistic .",
    "we follow the cross validation scheme in to deal with this issue by splitting the training data into @xmath118 folds . for each fold , we generate label predictions based on the structured predictor trained on the remaining folds .",
    "finally , we gather these label predictions and train a policy on the complete data .    the dependency parser is trained by the averaged structured perceptron modelwith learning rate and number of epochs set to be 0.1 and 50 , respectively .",
    "this setting achieves the best test performance as reported in notice that if we trained two dependency models with different feature sets separately the scale of the edge scores may be different , resulting sub - optimal test performance . to fix this issue",
    ", we generate data with random edge features and train the model to minimize the joint loss over all states .",
    "@xmath119\\end{aligned}\\ ] ]    finally , we found that for dependency parsing expensive features are only necessary in several critical locations in the sentence .",
    "therefore , budget levels above 10% turned out to be unachievable for any feature - tradeoff parameter lambda in the pseudo - labels . to obtain those regions",
    ", we varied the class weights of feature templates in the training of one - shot feature selector ."
  ],
  "abstract_text": [
    "<S> we study the problem of structured prediction under test - time budget constraints . we propose a novel approach applicable to a wide range of structured prediction problems in computer vision and natural language processing . </S>",
    "<S> our approach seeks to adaptively generate computationally costly features during test - time in order to reduce the computational cost of prediction while maintaining prediction performance . </S>",
    "<S> we show that training the adaptive feature generation system can be reduced to a series of structured learning problems , resulting in efficient training using existing structured learning algorithms . </S>",
    "<S> this framework provides theoretical justification for several existing heuristic approaches found in literature . </S>",
    "<S> we evaluate our proposed adaptive system on two structured prediction tasks , optical character recognition ( ocr ) and dependency parsing and show strong performance in reduction of the feature costs without degrading accuracy . </S>"
  ]
}