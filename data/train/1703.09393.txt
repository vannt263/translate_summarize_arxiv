{
  "article_text": [
    "this paper addresses a crowd counting task .",
    "an automatic counting is expected to use in many applications ( e.g. crowd counting in surveillance cameras@xcite , cars counting in aerial images@xcite and particles counting in microscope images@xcite ) .",
    "however , those objects are manually counted by observers now .",
    "such manual counting can not treat a lot of images .",
    "moreover , counting result becomes subjective .",
    "therefore , an automatically object counting method is really required to obtain objective counting results .    however , crowd counting task has three difficult problems in comparison with general image recognition task .",
    "the first problem is the occlusion of counting targets . since counting targets densely",
    "exist in an image , the appearance of targets is much different at sparse and dense places .",
    "the second problem is that a small target is represented by a few pixels .",
    "the last problem is the appearance change caused by scale change of a target .",
    "figure [ fig:1 ] shows the examples of crowd , the appearance of crowd is largely changed by scale change and congestion .",
    "some counting methods have been proposed to overcome those difficulties .",
    "it is reported that regression based methods @xcite gave better result than detection based method@xcite for occluded targets in dense regions .",
    "those methods learn the pair of training images and the number of targets contained in the images , and they become robust to occlusion in dense regions .",
    "it is reported that multiple features are effective for targets with low resolution @xcite .",
    "however , the last problem about appearance change caused by scaling has not been sufficiently studied in the approach .",
    "this paper proposes a robust counting method to such appearance changes . as drawbacks of conventional methods ,",
    "those methods utilize only one predictor ( e.g. regression , random forest and cnn ) for the various appearances of targets .",
    "such one predictor can not handle the various appearance changes .",
    "thus , we propose multiple predictors specialized to a specific appearance .",
    "those predictors are adaptively selected according to the appearance of targets . by integrating the selected predictors , it is robust to various appearance changes .",
    "we use cnn as the predictor because cnn gave the state - of - the - art results in many image recognition tasks @xcite in recent years .",
    "the effectiveness of cnn for crowd counting is also reported @xcite .",
    "our method adaptively integrates some cnns based on the idea of mixture of experts @xcite ( moe ) .",
    "thus , we call our proposed cnn as _ mixture of counting cnns _ ( moc - cnn )",
    ". the overview of moc - cnn is shown in figure [ fig:2 ] .",
    "the moc - cnn is consists of two types of cnns .",
    "the first cnn specializes to a specific appearance of targets .",
    "for example , the specific appearances mean targets in a dense region , targets in a sparse region , small targets and large targets . the specialized cnn is called _ expert cnn_.",
    "we use some expert cnns specialized to each appearance .",
    "the second cnn selects expert cnns according to the appearance of targets .",
    "this cnn is called _ gating cnn_.    to count targets in an image , the image is fed into both expert cnns and gating cnn . each expert cnn predicts the number of targets in the image . on the other hand ,",
    "gating cnn predicts the probabilities of expert cnns , and those probabilities are used as the weight for integrating the prediction results by expert cnns .",
    "thus , the number of target in the image is the weighted mean of results by expert cnns .        in experiments , we use two crowd count datasets ; the ucf crowd count ( ucf_cc_50 ) dataset and the mall dataset .",
    "we confirm that our method obtain comparable accuracy with the state - of - the - art methods on the both datasets . in the ucf_cc_50 dataset ,",
    "our method achieved that mean absolute error is 360.8 and mean squared deviation is 488.2 . in the mall dataset",
    ", our method achieved that absolute error is 2.75 and mean deviation error is 0.087 . in the experiments",
    ", we confirm that gating cnn adaptively selects expert cnns for the appearance of an input image .",
    "moreover , we confirm that each predictor automatically specialized to a specific appearance .    this paper is organized as follows . in section [ sec:2 ] , we describe related works .",
    "the details of the moc - cnn are described in section [ sec:3 ] . in section [ sec:4 ] ,",
    "we evaluate our proposed method on two crowd counting datasets with various appearances .",
    "finally , we describe conclusion and future works in section [ sec:5 ] .",
    "some crowd counting methods have been proposed in recent years .",
    "chan proposed a crowd counting method based on gaussian process regression@xcite .",
    "loy proposed multiple - output ridge regression@xcite .",
    "chen @xcite proposed a cumulative attribute ridge regression which uses the number of targets as attribute .",
    "those methods can count targets with low counting error .",
    "however , they are not essentially robust to scale changes of targets .",
    "therefore , those methods used a perspective map@xcite to obtain the similar features from targets of different scales .",
    "perspective map is very simple and effective for appearance change by perspective .",
    "however , this method has two drawbacks . at first , if filming location is changed , we must reset the parameters of the perspective map manually .",
    "the second drawback is that the normalization is effective to only targets which are similar sizes ( human ) .",
    "however , when the size of targets changes ( particles in microscope images and vehicles in areal images ) , this normalization is not effective .    in other object counting methods , density map is often utilized .",
    "the density map was proposed by lempitsky @xcite . in general , dot annotations",
    "are given to the center of each target .",
    "density map is generated by replacing dots to gaussian distributions .",
    "the advantage of density map is the robustness to vague target on the boundary of image .",
    "however , density map does not consider scale changes , those methods do not have sufficient robustness to scale changes . zhang et al.@xcite proposed density estimation method using cnn .",
    "this method also utilizes the perspective map .",
    "thus , this method has the same drawbacks as the methods using perspective map described previously .    in recent years , counting methods using cnn are proposed without the perspective map .",
    "zhang proposed to automatically create a density map considered perspective @xcite .",
    "moreover , they propose a counting method based on multi - column cnn . this cnn has multiple feature extraction units , each feature extraction unit has the filters of different sizes to treat targets with different scales .",
    "the features obtained from each cnn are combined into one feature , and the feature is fed into fully - connected layer to predict the number of targets .",
    "ooro also proposed cnn with multiple feature extraction units @xcite to count the without perspective map . in those methods",
    ", each feature extraction unit is specialized to an appearance of specific scale ( e.g. , small , middle and large ) , those conventional methods can obtain features considering multiple scales .",
    "however , those methods use only one predictor .",
    "only one predictor can not handle various appearances of a target , and those methods are not essentially robust to appearance changes .",
    "therefore , we propose a more robust counting method to appearance changes . our moc - cnn integrates expert cnns , and we adaptively integrate expert cnns specialized to various appearance in an image .",
    "our method can count targets regardless of the filming location and target size .",
    "this section describes the details of moc - cnn . at first",
    ", we explain a counting method using expert and gating cnns in section [ ssec:3 - 1 ] . how to train expert cnns and gating cnn",
    "is explained in section [ ssec:3 - 2 ] .",
    "finally , the settings of moc - cnn is explained in section [ ssec:3 - 3 ] .",
    "moc - cnns predicts the number of targets in an input image using following equation .",
    "@xmath0    where @xmath1 is the number of expert cnns , and @xmath2 is the counting result of the @xmath3-th expert cnn .",
    "@xmath4 is the @xmath3-th output value of gating cnn , and this is probability value obtained by softmax of output layer .",
    "the probability @xmath4 is used as the weight for integrating the expert cnns .",
    "the number of targets @xmath5 is estimated by weighed sum of output @xmath2 of each expert cnn .",
    "for example , we assume that the 1st expert cnn is specialized to an appearance of dense crowd . if a test image has an appearance of dense crowd , gating cnn increases the weight @xmath6 to 1st expert cnn .",
    "thus , the output of the 1st expert cnn @xmath7 largely reflects to the final counting result @xmath5 . by adaptively selecting , we can obtain the strong robustness than one predictor .",
    "moreover , our moc - cnn does not require to manually decide the role of each expert cnn , and each expert cnn automatically specialize to a specific appearance by end - to - end manner .",
    "the reason is explained in section [ ssec:3 - 3 ] .",
    "this section describes how to train expert cnns and gating cnn . at first , expert cnn trains using the following loss function .",
    "@xmath8    where @xmath9 is mini - batch size , @xmath10 is the prediction value for the @xmath11-th image , and @xmath12 is the ground truth of the @xmath11-th image .",
    "this loss function is the mean squared error between prediction value and ground truth .",
    "moc - cnn is inspired by moe .",
    "original moe can automatically decide that each expert cnn assigns to one of appearance variations from random initial parameters .",
    "however , if gating cnn also trains using the loss function ( [ eq:2 ] ) as well as expert cnn , gating cnn can not train the role of each expert from random parameter , and gating cnn will select only one expert cnn for all images . the possible reason for selecting only one expert is explained follows .    at first",
    ", training data contain a lot of similar images such as background images with little texture shown in figure [ fig : notex ] . at initial stage of training ,",
    "those similar images are fed into one expert cnn by gating cnn .",
    "the expert cnn trains those similar images . on the other hand ,",
    "few training images are given to other expert cnns .",
    "therefore , the bias about the number of training images occurs in each expert cnn , and only expert cnn which has many training images obtains high generality . since gating cnn learns to select expert cnn with low counting error .",
    "gating cnn frequently selects the expert cnn trained by many images , and our network finally uses only one expert cnn .",
    "one expert cnn is the same as ordinary cnn , and it is not robust to appearance changes . on the other hand ,",
    "original moe integrates neural networks with weak generality .",
    "thus , original moe can automatically decide the role but expert cnn does not automatically decide the role because cnn has high generality .        to prevent selecting only one expert cnn , gating cnn trains using the following loss function .",
    "@xmath13    where the first term is the mean squared loss between prediction and ground truth .",
    "this is same as the loss function of expert cnn .",
    "the second term is variance regularization term .",
    "this term works to minimize the variance of outputs of gating cnn , where @xmath14 is the mean of output values of gating cnn for the @xmath11-th training sample .",
    "@xmath15 is trade - off parameter between loss and variance regularization .",
    "if gating cnn selects only one expert cnn , the variance becomes large . on the other hand ,",
    "if gating cnn selects some expert cnns , the variance becomes small .",
    "therefore , minimization of variance can prevent to select only one expert cnn .",
    "expert cnns and gating cnn are simultaneously trained using each different loss function .",
    "the update of output layer in expert and gating cnns is as follows .",
    "@xmath16    @xmath17    where @xmath18 is weight vector for the @xmath3-th output layer of gating cnn , @xmath19 is weight vector for output layer of the @xmath3-th expert cnn . @xmath20 and @xmath21 are learning rate of expert cnn and gating cnn .",
    "those learning rates are adaptively decided by adam @xcite .",
    "the parameters on more shallow layers are updated using chain rule as well as the train of ordinary cnn .",
    "* the reason of specialization . * we explain how to automatically specialize expert cnn to a specific appearance . at first",
    ", the gradient of loss function in ( [ eq:4 ] ) is as follows .    @xmath22    where the output of gating cnn @xmath4 works like a learning rate .",
    "if the @xmath3-th expert cnn is selected by gating cnn for a training image , @xmath4 becomes large .",
    "therefore , the @xmath3-th expert cnn strongly learns the training image      this section describes the details of moc - cnn setting . at first , the network architecture of expert cnn and gating cnn are shown in figures [ fig : arch ] .",
    "we prepare @xmath1 expert cnns , and the architecture of expert cnn is set to smaller than that of gating cnn .",
    "our method integrates some expert cnns and assigns the roles to each expert cnn .",
    "therefore , each expert cnn does not learn all training data , and each expert cnn learns only training data given by gating cnn .",
    "thus , expert cnn has small architecture . in this paper",
    ", we set the number of experts @xmath1 to 10 empirically .",
    "* architecture of expert cnn .",
    "* we explain the architecture of expert cnn .",
    "expert cnn is constructed by 2 convolutional layers , 2 pooling layers and a fully - connected layer .",
    "although pooling layers are omitted in figure [ fig : arch ] , we adopt max pooling after each convolution layer .",
    "we use max pooling with 2@xmath232 kernel size in the first pooling layer , and the second pooling layer has 3@xmath233 kernel size . we use batch normalization@xcite and exponential linear unit(elu ) function @xcite after each convolutional layer .",
    "the architecture is experimentally optimized .",
    "* architecture of gating cnn .",
    "* we explain the architecture of gating cnn .",
    "the architecture is also shown in figure [ fig : arch ] .",
    "although the output of expert cnns is single , gating cnn is multi - class classifier . in general , the problem of multiple outputs is more difficult than that of single output .",
    "thus , we consider that gating cnn requires more complex network architecture than expert cnn .",
    "the number of filters in each convolution layer of gating cnn is larger than expert cnn .",
    "the kernels size in pooling is the same as expert cnn .",
    "batch normalization and elu are also used .",
    "classification unit of gating cnn consists of two fully - connected layers .",
    "we introduce dropout @xcite after the first fully - connected layer , and output layer has softmax function because gating cnn predicts the probabilities for expert cnns .",
    "* input image settings . * in our cnn , the size of input image is set to 72@xmath2372 pixels .",
    "the size refers to @xcite .",
    "when the size of a test image is larger than 72@xmath2372 pixels , we divide the image into grid of 72@xmath2372 pixels .",
    "if an image is indivisible by 72@xmath2472 pixels , image patches below 72@xmath2372 pixels are obtained at peripheral region .",
    "they are not used for evaluation .",
    "the divided patches are fed into moc - cnn , and we obtain counting results for each patch . counting results of image patches are summarized , and a final counting result for the test image is obtained .    *",
    "ground truth .",
    "* our method uses the summation of a density map as ground truth .",
    "the summation of a density map is shown as follows .",
    "@xmath25    where @xmath12 is ground truth of the @xmath11-th training patch , @xmath26 is the @xmath11-th training patch , @xmath27 is the density map of the @xmath11-th training patch . by using density map ,",
    "our method slightly becomes the robust to vague target which existing on boundary of patches .",
    "our moc - cnn is evaluated using two challenging crowd counting datasets ; the ucf_cc_50 dataset@xcite and the mall dataset@xcite .",
    "the examples of two datasets are shown in figure [ fig : dataset ] .",
    "both datasets contain various appearance crowd caused by perspective and congestion .    in the rest of this section , we explain evaluation in each crowd counting dataset . in section [ ssec:3 - 1 ] , we show experimental results using the ucf_cc_50 dataset .",
    "next , we show experimental result on the mall dataset in section [ ssec:3 - 2 ] .",
    "three images in figure [ fig : dataset ] on the upper row show the examples of the ucf_cc_50 dataset .",
    "the dataset contains 50 images .",
    "each image contains people from 94 to 4543 , the average number of crowd is 1280 persons .",
    "this dataset contains images filming at various scenes ( e.g. , demo , event and convention ) .    in this experiment",
    ", we use the same experimental setting as previous works@xcite .",
    "we randomly divide the dataset into 5 validation sets , and our method is evaluated by 5-fold cross - validation .",
    "the way to make training data refers to @xcite , and we randomly crop 1600 patches from a training image .",
    "thus , the total number of training image is 64000 patches .    in this dataset , we use two evaluation metrics ; mean absolute error ( mae ) and mean squares deviation ( msd ) .",
    "equations of these metrics are as follows .",
    "[ 1]0 @xmath28 where @xmath29 is the total number of test image , @xmath12 is the ground truth of the @xmath11-th test image and @xmath30 is predicted value in the @xmath11-th test image .    to evaluate the effectiveness of the integration by gating cnn ,",
    "we compare our method with two methods .",
    "the overview of those methods are shown in figure [ fig : conv ] .",
    "the first method is single ordinary cnn which is shown in left image of figure [ fig : conv ] .",
    "the architecture of the cnn is the same as our expert cnn .",
    "we call this method as ordinary cnn .",
    "the second method integrates expert cnns using a fully - connected layer instead of using gating cnn .",
    "the overview of this method is shown in right image of figure [ fig : conv ] .",
    "this method also uses expert cnns .",
    "the outputs of expert cnns are fed into the fully - connected layer , and the fully - connected layer predicts the number of targets from the outputs of expert cnns .",
    "thus , the weight for integrating the cnns is fixed for all test images while our method adaptively integrate expert cnns .",
    "we call this method as fc - layer gating .",
    "l c c & mae & msd + idrees @xcite & 419.5 & - + zhang @xcite & 467.0 & 498.5 + zhang @xcite & 377.6 & 509.1 + ooro @xcite & 333.7 & 425.3 + ordinary cnn & 545.6 & 697.5 + fc - layer gating & 509.6 & 670.0 + moc - cnn & 361.7 & 493.3 +        experiment result is shown in table [ table:1 ] .",
    "we compare moc - cnn , above two compatative methods and five state - of - the - art methods . in the state - of - the - art method ,",
    "idrees @xcite uses regression based method without cnn .",
    "zhang @xcite uses single cnn .",
    "zhang @xcite and ooro @xcite are cnn based methods , and those methods use cnn constructed by multiple feature extraction units .",
    "walach @xcite uses multiple cnns , and the first cnn predicts the number of targets .",
    "then , the second cnn predicts the counting error of the first cnn , and the second cnn corrects the counting error of the first cnn .",
    "mae of the proposed method decreases 34% and 29% in comparison with the ordinary cnn and fc - layer gating .",
    "we confirm the effectiveness of the integration by gating cnn .",
    "moreover , we confirm that our method obtains comparable accuracy with the state - of - the - art methods .",
    "ooro marked the best accuracy in table [ table:1 ] .",
    "however , this method increases training data using data augmentation , and the number of training data of this method is larger than our method and other comparative methods . in methods using same experiment setting ,",
    "moc - cnn obtains the best accuracy .",
    "figure [ fig : ucf_result ] shows test images and the outputs of gating cnn . in figure [ fig : ucf_result ] , images on upper row shows background and few humans , and images on lower row shows dense crowd .",
    "graphs on right side of each image shows the outputs of gating cnn for each image . on the graphs ,",
    "horizontal axis means each gating cnn , and vertical axis is the output of gating cnn .",
    "we confirm that the 6th and 7th outputs of gating cnn often react to few humans and background . on the other hand ,",
    "the 2nd output of gating cnn often reacts the image of dense crowd , the 5th output of gating cnn reacts middle level density .",
    "thus , gating cnn adaptively select expert cnns according to the appearance of test images .",
    "mall dataset contains 2000 frames .",
    "we use the same experimental setting as previous works @xcite .",
    "we use the first 800 frames for training and the rest 1200 frames for evaluation . to make training data",
    ", we randomly crop 80 patches from a training image .",
    "the total number of training patches is 64000 , it is the same as the experiment using the ucf_cc_50 dataset .",
    "in this dataset , we use three metrics for evaluation ; mae , mean squared error ( mse ) and mean deviation error ( mde ) .",
    "equation of those metrics are shown as follows .",
    "[ 1]0 @xmath31    l | c c c & mae & mse & mde + lssvr @xcite & 3.51 & 18.2 & 0.108 + krr @xcite & 3.51 & 18.1 & 0.108 + rfr @xcite & 3.91 & 21.5 & 0.121 + gpr @xcite & 3.72 & 20.1 & 0.115 + rr @xcite & 3.59 & 19.0 & 0.105 + ca - rr @xcite & 3.43 & 17.7 & 0.105 + ssr @xcite & - & 17.8 & - + cf @xcite & 2.50 & 10.0 & 0.080 + boosting cnn @xcite & 2.01 & - & - + moc - cnn & 2.75 & 13.4 & 0.087 +        in this experiment , we compare our method with the recent works ; least square support vector regression @xcite ( lssvr ) , kernel ridge regression@xcite ( krr ) , random forest regression @xcite ( rfr ) , gaussian process regression @xcite ( gpr ) , multiple output ridge regression @xcite ( rr ) , cumulative attribute ridge regression @xcite ( ca - rr ) , semi - supervised regression @xcite ( ssr ) , random forest based method @xcite ( cf ) and multiple cnns based method @xcite(boosting cnn ) .",
    "our method outperforms conventional methods except for cf and boosting cnn . although our method directly predicts the number of target . on the other hand , cf and boosting cnn",
    "predicts density map , density map estimation has the robustness to vague target which existing on boundary of patches . since training data of the proposed method contain a lot of vague targets , our method is affected by vague targets .",
    "therefore , we consider that our method improves the accuracy by introducing density map .",
    "test images of the mall dataset and the outputs of gating cnn are shown in figure [ fig : mall_result ] .",
    "images on upper row are background image , and gating cnn predicts similar outputs to those background image . on the other hand ,",
    "if small person exists in an image , the 2nd output of gating cnn strongly react .",
    "the variations of appearance on the mall dataset is smaller than the ucf_cc_50 dataset .",
    "thus , the output of gating cnn do not variously change as much as the result of the ucf_cc_50 dataset .",
    "we proposed moc - cnn which integrates cnns specialized to a specific appearance for crowd counting .",
    "we show the effectiveness of adaptive integration of some cnns by the comparison with a cnn and integration using fixed weights .",
    "the proposed method obtains comparable result to conventional counting methods .",
    "the proposed method is affected by vague training data .",
    "therefore , we should use density map to improve the accuracy . moreover",
    ", we may use the idea of hierarchical mixture of experts .",
    "they are subjects for future works ."
  ],
  "abstract_text": [
    "<S> this paper proposes a crowd counting method . </S>",
    "<S> crowd counting is difficult because of large appearance changes of a target which caused by density and scale changes . </S>",
    "<S> conventional crowd counting methods generally utilize one predictor ( regression and multi - class classifier ) . </S>",
    "<S> however , such only one predictor can not count targets with large appearance changes well . in this paper </S>",
    "<S> , we propose to predict the number of targets using multiple cnns specialized to a specific appearance , and those cnns are adaptively selected according to the appearance of a test image . by integrating the selected cnns , the proposed method has the robustness to large appearance changes . in experiments , we confirm that the proposed method can count crowd with lower counting error than a cnn and integration of cnns with fixed weights . </S>",
    "<S> moreover , we confirm that each predictor automatically specialized to a specific appearance . </S>"
  ]
}