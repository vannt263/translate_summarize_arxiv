{
  "article_text": [
    "an electroencephalogram ( eeg ) is a direct measure of electrical activities of the brain along the scalp .",
    "it is a rich source of information about the brain for healthy individuals and patients with neurological diseases .",
    "compared to the blood flow neuroimaging techniques , such as magnetic resonance imaging ( mri ) and functional magnetic resonance imaging ( fmri ) , which are indirect measures of brain activity , eeg is cheaper and easier to use .",
    "an additional strength of eeg is that it can detect changes within a millisecond time frame whereas fmri has time resolution between seconds and minutes .",
    "quantitative evaluation of cognitive functioning and mental states using eeg records is one of the important problems in applied psychophysiology @xcite .",
    "they include brain - computer interface @xcite for decoding intentions and their translation into commands , and diagnosis of mental illnesses such as schizophrenia @xcite .",
    "to obtain useful information from the eeg data feature extraction is necessary . in the literature",
    "a whole set of quantitative estimates of the spectral and temporal features of the eeg signal have been developed ( see , e.g. @xcite ) .",
    "in particular , there is an extensive literature on attempts to use these characteristics for schizophrenia diagnosis ( for review and meta - analysis of such papers see e.g. @xcite ) .",
    "however such approach requires assumptions on a data generating mechanism but there are no generally excepted model on the data generated mechanism for eeg data .",
    "another approach to select features is related to the fundamental concepts of the modern theory of nonlinear dynamical systems such as entropy , correlation dimension @xmath1 and lyapunov exponent ( see , e.g. @xcite ) .",
    "these features can really reflect the complexity of a generating mechanism of a signal , but only under the assumptions of stationarity and ergodicity of a signal .",
    "due to the nature of eeg signals these assumptions are not fully justifiable ( see , e.g. @xcite ) .    to the best of our knowledge the papers which produce a high accuracy on classification of eeg signal use high - dimensional feature space and face the problem of overfitting ( see e.g. @xcite )    in this paper we propose an approach to the feature selection problem which is model free ( e.g. does not have any assumptions on data generating mechanism such as stationarity or ergodicity of the data ) .",
    "it also assures a good accuracy in small dimensional feature space .",
    "more precisely , we propose to apply the notion of the @xmath0-complexity of continuous functions to the classification problem of multichannel eeg - records .",
    "such approach is in line with general kolmogorov s idea on a `` complexity '' of an object . at the basic level",
    "the idea of a kolmogorov can be expressed as follows : a `` complex '' object requires a lot of information for its reconstruction and , for a `` simple '' object , little information is needed .",
    "therefore , it is quite natural to measure the complexity of a continuous function by the number of function values on a uniform grid ( e.g. function values given at equally distant points ) which are necessary to reconstruct the function with a given error by a given set of methods . this characteristic of complexity was tested on evaluation of the functional states of the brain using the eeg recordings in @xcite .",
    "it was found that the mean values of complexity are statistically significantly different for the groups of subjects with different functional states .",
    "this result was obtained despite the fact that the easiest method of function reconstruction by piecewise - constant approximation was used . however , for further progress in this area the development of computational procedure for estimation of the `` complexity '' of an _ individual recording _",
    "( i.e. an _ individual continuous function _ ) was required .",
    "this was impossible without development of an appropriate mathematical theory .    in 2012 - 2014",
    "( see , @xcite ) the theory of the @xmath0-complexity of continuous functions defined on a compact set in a finite - dimensional space was developed .",
    "it was proven that the @xmath0-complexity of `` almost all '' hlder functions is effectively characterized by a pair of real numbers , which we call the _",
    "@xmath0-complexity coefficients_. this theory enabled us to develop a _ novel approach _ to the problems of segmentation and classification of time series of arbitrary nature . in this paper",
    "we extended the theory of the @xmath0-complexity of continuous functions to the case of continuous vector - functions ( see appendix ) .",
    "this extension enables us to apply such approach to the binary classification problem of eeg records .",
    "the paper is organized as follows . in section 1",
    "we describe our methodology .",
    "in particular , in subsection 1.1 we give a description of the notion of the @xmath0-complexity of a vector function on a semantic level and provide a characterization of the @xmath0-complexity for vector functions given by a finite set of values . in subsection 1.2 we provide an algorithm for estimation of the @xmath0-complexity coefficients for the multichannel eeg records . in subsection 1.3",
    "we describe our classification procedure . in section 2",
    "we apply our methodology to the classification of the eeg records of adolescents with schizophrenic type of disorder and of healthy subjects .",
    "we have established that these data permit accurate classification in the four - dimensional space of the @xmath0-complexity coefficients of original eeg signals and @xmath0-complexity coefficients of fourth differences of eeg signals . in section 3",
    "we provide conclusions and discuss our results .",
    "the appendix provides the precise definition of @xmath0-complexity and the theorem characterizing the complexity of hlder vector functions",
    "in this section , we give a description of proposed methodology for classification of multi - channel eeg - records .",
    "we will treat a multichannel eeg record as a @xmath2-dimensional vector function @xmath3 , where @xmath2 is a number of channels , which is given on some fixed time interval @xmath4 $ ] .    since the modern recording equipment is digital , instead of a continuous vector function @xmath5 the researcher received a discrete samples @xmath6 , e.g. , the sequence of @xmath7 @xmath2-dimensional vectors .",
    "here @xmath8 , where @xmath9 is a sample frequency ( if the frequency is measured in hz , e.g. time in seconds ) .",
    "for example , if @xmath10 seconds , and @xmath11hz , then we have 7680 @xmath2-dimensional vectors .",
    "without loss of generality we can assume that @xmath12 , e.g. in each channel of eeg signal is present .",
    "let us describe our notion of the @xmath0-complexity on semantic level . the precise definition and formulation of the theorem",
    "are given in appendix .",
    "we choose a number @xmath13 and discard from each component of a vector function @xmath14 @xmath15 $ ] values ( henceforth , the symbol @xmath16 $ ] denotes the integral part of a number @xmath17 ) , in such a way that the remaining values are approximately uniformly distributed .",
    "for example , if @xmath18 , then we retain even or odds values in each component of the function .",
    "assume we have some fixed collection @xmath19 of approximation methods which can be used for reconstruction of a continuous function by its values at some uniform grid . employing collection of methods",
    "@xmath19 , we reconstruct the values of each component of the vector function @xmath20 in discarded points using the retained values of the function .",
    "we find the methods which reconstruct the function with minimum relative ( in relation to @xmath21 ) error ( the error can be measured in any norm , because we are dealing with a finite a set of values ) .",
    "denote the value of the minimum relative reconstruction error in the @xmath22-th component through @xmath23 and find the value @xmath24 .",
    "now we will _ define the @xmath25-complexity ( hereafter , for simplicity of presentation we will write @xmath0-complexity ) of continuous vector function @xmath5 , which is given by its values on the uniform grid by @xmath26_.    in other words , the @xmath0-complexity of a vector function is the ( minus ) logarithm of relative fraction of their values , required for its recovery by methods from family @xmath27 with a relative error no more than @xmath0 . in other words , it is `` the shortest '' description of the vector function .",
    "let us consider the class of vector functions satisfying the hlder condition .",
    "it means that for any @xmath28\\times [ 0,t]$ ] the following inequality holds @xmath29    this class of vector functions is very wide , and it includes practically all vector functions which can be found in applications .",
    "the main point of our classification methodology is as follows .",
    "for `` almost all '' vector functions satisfying the hlder condition , in case of sufficiently rich family @xmath19 of approximation methods and a sufficiently large sample size @xmath7 there exists range @xmath30 ( which depends from vector function ) such that the following equality holds @xmath31    the precise meaning of the expression `` almost any '' and symbol @xmath32 will be explained in the appendix .",
    "the above parameters @xmath33 are called the _ @xmath0-complexity coefficients_.",
    "these @xmath0-complexity coefficients will be utilized as features for classification of multichannel eeg records . in our work",
    "we will use supervised classifiers such as random forest and support vector machine .",
    "these features do nt depend from the data generating mechanism and therefore they are _ model - free_. in the scalar case they have been introduced and applied for the purpose to detect changes in generating mechanism @xcite .",
    "we would like to mention two facts .",
    "firstly , in practical applications the family of function reconstruction methods @xmath19 is finite .",
    "it follows from our main theorem ( see appendix ) that if this family @xmath19 is reach enough and the sample size of function values is large enough then the error of vector function reconstruction in discarded points by methods from this family ( and therefore the @xmath0-complexity ) is closed to the error of the reconstruction by _ all ( computable ) methods_.    our experience with simulations and real data shows that the dependence ( [ eq2 ] ) has been observed in case we chose piece - wise polynomial functions up to fourth degree as family @xmath19 .    secondly , it is not significant which method gives the smallest error of reconstruction @xmath23 in @xmath22-th channel ( @xmath34 ) . to find dependence ( [ eq2 ] )",
    "we need only values of minimal errors .      in this subsection",
    "we will describe main steps of our algorithm for estimation of the @xmath0-complexity coefficients for multichannel eeg records .    1 .",
    "normalize each component of the eeg record @xmath35 , i.e replace our original components of the multichannel record by @xmath36 .",
    "2 .   select @xmath37 , the fraction of the remaining points as follows : @xmath38 , @xmath39 , @xmath40 , @xmath41 , @xmath42 , @xmath43 .",
    "3 .   for each fixed @xmath44 ( @xmath45 ) and for each component of the multichannel record discard the values of the functions at points which are placed uniformly , or almost uniformly , according to the following scheme : let @xmath46,@xmath47 be the values of a function on a grid .",
    "@xmath48 * : values of @xmath49 or @xmath50 are discarded .",
    "notice we have two different ways to discard function values ; 2 .   *",
    "@xmath39 * : values of @xmath51 ; or @xmath52 or @xmath53 are discarded .",
    "we have three different placements of discarded values ; 3 .   * @xmath54 * : values of @xmath55 or @xmath56 ; + or @xmath57 or @xmath58 are discarded .",
    "we have 4 different placements of discarded values ; 4 .",
    "the procedures are similar in the case @xmath40 , @xmath42 and @xmath43 .",
    "4 .   for each @xmath59 and for each of those placements",
    "we consider all possible reconstructions of the function by piecewise polynomials up to fourth degree and select the one which provides the minimal error of reconstruction .",
    "record this value of the minimal error .",
    "5 .   for the same @xmath59 we consider other placements of the retained points and repeat the procedure .",
    "record the obtained minimal errors .",
    "then we take a mean of the recorded errors calculated over all placements for each channel of the eeg - record .",
    "take sum of the mean errors over all channels .",
    "it is our estimation of @xmath60 in the case of @xmath59 .",
    "repeat the procedure for @xmath61 .",
    "consider points @xmath62 , and find the best linear fit @xmath63 using the least squares method .",
    "each graph in fig [ line1 ] demonstrates the typical dependence of the form ( 2 ) for given eeg recording ( the theoretical dependence is shown by a solid line , and the experimental points are shown by circles ) .",
    "the left plot corresponds to the normal subject and the right one to the patient with schizophrenia .    ) of eeg recordings ,",
    "left ( a ) : normal subject , right ( b ) : patient with schizophrenia .",
    "the theoretical dependence is shown by a solid line , and the experimental points are shown by circles .",
    ", title=\"fig:\",scaledwidth=45.0% ] ) of eeg recordings , left ( a ) : normal subject , right ( b ) : patient with schizophrenia .",
    "the theoretical dependence is shown by a solid line , and the experimental points are shown by circles .",
    ", title=\"fig:\",scaledwidth=45.0% ]    let us notice that the obtained above values of the coefficients @xmath64 and @xmath65 are our estimates for the @xmath0-complexity coefficients which are used in classification algorithm .",
    "for each subject we estimate the @xmath0-complexity coefficients as well as the @xmath0-complexity coefficients of some transformations of the eeg data ( see next section ) .      in the next step we use the calculated @xmath0-complexity coefficients as an input to the supervised classifiers , such as random forest and support vector machine .",
    "the results will be evaluated using the out - of - bag ( oob ) @xcite error in case of the random forest and k - fold cross - validation procedure in both cases to be able to compare the performance of two classifiers .",
    "note that in case of oob the model calculates the error using observations not trained for each decision tree in the forest and aggregates over all of them ; therefore it has no bias .",
    "this is considered to be an accurate estimate of the test error for the random forest @xcite .",
    "cross - validation ( cv ) , ( see e.g,@xcite ) is a model validation technique for assessing how the results of a statistical analysis will be generalized to a new data set .",
    "in particular , the data set is partitioned into complementary subsets ( so called training and validation sets ) .",
    "the classifier is built using the training data set and performance is tested on the validation set . in @xmath66-fold cross - validation ( see , e.g @xcite ) , the original sample is randomly partitioned into @xmath66 equal - sized subsamples . of the @xmath66 subsamples ,",
    "a single subsample is retained as the validation data for testing the classifier , and the remaining @xmath67 subsamples are used as training data .",
    "the cross - validation process is then repeated @xmath66 times , with each of the @xmath66 subsamples used exactly once as the validation data .",
    "the @xmath66 results from the folds are averaged to produce a single estimate .",
    "* data description .",
    "* eeg recordings which were analyzed previously in @xcite are also used in this study .",
    "the data are publicly available at http://brain.bio.msu.ru/eeg_schizophrenia.htm .",
    "the recordings have been obtained for 45 boys ( 10 - 14 years old ) suffering from schizophrenia and diagnosed using clinical interviews at the research center for psychological disorders of the russian academy of medical sciences according to the criteria given in @xcite . because the patients had not taken psychoactive drugs before participating in the study",
    ", we could exclude the influence of medications .",
    "the control group consists of 39 healthy boys ( 11 - 13 years old ) .",
    "the traditional approach to placement of electrodes used at pirogov russian national research medical university in similar studies was employed . for all subjects",
    "eeg were registered using the standard 10/20 international electrode scheme involving 16 electrodes ( o1 , o2 , p3 , p4 , pz , t5 , t6 , c3 , c4 , cz , t3 , t4 , f3 , f4 , f7 , f8 ) with the reference earlobe electrode .    artifacts , mostly head and eyes movements , were removed manually based on the opinion of two experts .",
    "we received data which are free of the artifacts . during the recordings patients were in resting state with closed eyes .",
    "impedance for all electrodes was kept below 10 k@xmath68 .",
    "signal was sampled at frequency 128hz and bandpass filter between 0.5hz and 45hz was applied .",
    "the length of each recording after removal of the artifacts is 7680 points",
    ".    * remark . *",
    "the bandpass - filter between 0.5 and 45hz was performed initially .",
    "we did not perform any additional filtration of the signal in different frequency bands .",
    "note the filtration changes the signal and therefore , generally speaking its @xmath0-complexity . however in our attempt to classify the eeg signals into schizophrenic and control groups we did not have a preliminary information which frequency band can be used as classification feature .",
    "therefore we did not perform such filtration and as it turned out later , we need not it .    in our analysis",
    "the multichannel eeg record is treated as a restriction of a continuous vector function @xmath69 $ ] at the uniform grid , i.e. values of continuous vector function are given in equally distant points of time with distance 1/128 sec .",
    "for all individuals in our study we estimated the @xmath0-complexity coefficients @xmath70 according to the above algorithm . here , @xmath22 is the subject s number , @xmath71 , where the first 39 subjects are normal and the last 45 subjects are schizophrenic .",
    "after that we consider differences of the original eeg signals , @xmath72 , @xmath73 , @xmath74 @xmath75 , and etc .",
    "the @xmath0-complexity coefficients @xmath76 , @xmath77 are estimated up to the fourth difference .",
    "the employment of differences corresponds to the analysis of derivatives of the eeg signal . since , a priory , we did not know the features of the signal which are useful for classification , we tested different combinations of the @xmath0-complexity coefficients of the original series and the series of finite differences and found that the complexity coefficients @xmath78 , and complexity coefficients of 4th differences @xmath79 ( @xmath71 ) form the best set of features for classification of our patients into two groups : schizophrenic and control .    after that we use the machine learning techniques to separate data into two clusters . in particular , we feed the vectors @xmath80 into the supervised classifiers such as random forest ( rf ) and support vector machine classifiers ( svm ) . this step is performed using r project software and its package `` randomforest '' for the random forest classifier and package `` e1071 '' for the svm .",
    "we also perform 10-fold cross - validation using the `` cart '' package .",
    "the results for the oob and the @xmath81-fold cross - validation for random forest and svm classifiers are presented in the table 1 . in this table",
    "we provide the accuracy of these classifiers and the percentage of false negative and false positive cases .",
    "false positive cases are the cases in which we classify the healthy patient as a patient with schizophrenia and false negative cases are the cases in which we classify a patient with schizophrenia as a healthy patient . to get 95% bootstrap confidence intervals ( ci ) we performed 10,000 replications of our experiments using random re - sampling of the data .",
    "( results for the random forest ( rf ) and support vector machine ( svm ) classifiers )    [ cols=\"<,<,<,<,<\",options=\"header \" , ]",
    "until now the problem of detecting eeg mental states in humans and in particular , in the diagnosis of mental diseases , remains open @xcite .",
    "this is due to the lack of effectiveness of traditional methods of eeg analysis in relation to the classification of normal and pathological mental states @xcite that causes the researchers to seek new methods of quantitative evaluation of the eeg including schizophrenia detection and classification @xcite .    in this paper , we proposed methodology which employs the @xmath0-complexity for the separation of different mental state .",
    "in particular , we apply this methodology to separate eeg records of patients with schizophrenia and control group .",
    "we selected the multivariate @xmath0-complexity coefficients of the original data as well as the multivariate @xmath0-complexity coefficients of the fourth differences as markers in identification of schizophrenia in adolescents .",
    "we found that random forest classifier performs better for this data set than support vector machine .",
    "the accuracy of proposed markers is relatively high , reaching on average @xmath82 in the test set used in the cross - validation on a sample of 45 schizophrenic patients and @xmath83 healthy subjects .",
    "the false positive error rate on average is 11.6% and false negative is 20.7% .",
    "we would like to emphasize that the feature space used in classification algorithm has _ only four dimensions _ which is much smaller than the sample size .",
    "to the best of our knowledge , the literature does not contain any results on the classification of schizophrenic diseases in a space of features of eeg data of such small dimension .    in the previous work on these eeg data @xcite six spectral and",
    "four time domain characteristics for 16 channels were considered as features for classification . in total 160 features were tested .",
    "it was found that 38 characteristics are sufficient for the separation of two groups of subjects : schizophrenic and normal .    in this paper",
    "we analyze eeg data for patients in resting condition without medical treatment .",
    "there are other known approaches to diagnose schizophrenia using eeg data(@xcite ) , which are based on using different stimuli and post - treatment eeg in different groups of patients .",
    "this is a fundamentally different approach , and it is difficult to produce a comparative analysis of our approach with these approaches .",
    "the proposed methodology expands the arsenal of methods for classification of eeg signal into groups of schizophrenic and normal subjects .",
    "let us emphasize that this paper is the first attempt to apply the @xmath0-complexity of vector functions to real eeg data .",
    "preliminarily , we verified this methodology on simulations but such results are not presented in this paper . in the future",
    "we will apply such methodology to other types of studies and classification problem for eeg signals , such as identification of pre - seizer states for epileptic patients .    of interest",
    "is further development of the proposed methodology for the detection of fixed mental states ( motor imagery ) in real time in the context of brain - computer interface @xcite .",
    "this study was partially supported by funding from the skolkovo foundation ( project @xmath84 1110034 ) and from pirogov russian national research medical university .",
    "we would like to thank dr .",
    "gorbachevskaya n.l .",
    "( senior researcher as russian mental health research center , moscow ) , dr .",
    "borisov s.v .",
    "( senior researcher at faculty of biology m.v.lomonosov moscow state university ) for collection and preliminary processing of the data .",
    "let us provide precise definitions and results following from the general @xmath0-complexity theory of continuous functions ( see , @xcite ) .",
    "let @xmath88 be an approximation of the @xmath22-th component @xmath89 of the vector function @xmath90 constructed using its values at the nodes of a uniform grid with spacing @xmath91 by one of the allowable methods of function reconstruction from a given collection of approximation methods @xmath92 .",
    "the function @xmath93 is called _ @xmath19-nontrivial ( correspondingly , totally nontrivial ) _ if it can not be recovered with an arbitrary small error by methods @xmath19 ( correspondingly , by any enumerable collection of methods ) for any @xmath94 .",
    "denote by @xmath95 , and put @xmath96 } |x_i(t)-\\hat{x}_i(t)|,\\,i\\in i.\\ ] ] the function @xmath97 is called the _ absolute recovery error of the component @xmath93 by methods @xmath19_. for each @xmath98 , define @xmath99 we will call @xmath100 _ the relative recovery error of the component @xmath93 by methods @xmath19_.        in most modern applications , one deals with functions ( vector functions ) defined by their values at a discrete set of equally distant moments of time ( or as it is called , on uniform grid ) .",
    "we will assume that this array of values is the restriction of a continuous function to the points of some uniform grid .",
    "it can be shown that @xmath103 is everywhere dense in the set of vector functions satisfying the hlder condition .",
    "in other words , `` almost any '' hlder vector function is totally nontrivial , i.e. has totally nontrivial component s.    in our context a vector function satisfying the hlder condition is given by its @xmath7 values ( i.e. by @xmath7 vectors from @xmath106 ) on a uniform grid .",
    "we choose @xmath13 and discard @xmath15 $ ] of the function values from each component of the vector function sample . using the remaining values we approximate the values of the components of the vector function at the discarded points by the set of approximation methods @xmath19 , and for each component find the best approximation in the sense of minimal relative recovery error .",
    "let the minimal relative recovery error of the @xmath22-th component be equal to @xmath107 .",
    "define the relative error of the vector function approximation as @xmath108 .",
    "following the main idea , we define now the @xmath0-complexity of continuous vector function , given by its values at a uniform grid , as ( minus ) logarithm of relative fraction of their values ( i.e. , @xmath109 ) , which should be retained to reconstruct this function in discarded points with relative error not large then the @xmath0 .",
    "it is easy to show that the definition of the @xmath0-complexity of function given on discrete set of points converges to the @xmath0-complexity of the corresponding continuous function with the increasing of sampling frequency ( see @xcite ) .      for any vector function @xmath90 from a dense subset of set @xmath103 , any ( sufficiently small )",
    "@xmath110 , and @xmath111 there exist a set of approximation methods @xmath112 , numbers @xmath113 , functions @xmath114 and a set @xmath115,\\mu(n)>\\mu(q)-\\delta$ ] ( @xmath116 is lebesgue measure ) such that for all @xmath117 and @xmath118 the following relations hold : @xmath119    it follows from this theorem that ( in the case of sufficiently rich family of approximation methods @xmath19 and sufficiently large @xmath7 ) for vector functions satisfying the hllder condition and defined by their @xmath7 values at a uniform grid the @xmath0-complexity is characterized by a pair of real numbers @xmath120 via the formula @xmath121      these two parameters @xmath64 , @xmath65 are _ features of the eeg signal _ useful in the classification of the `` short '' eeg records .",
    "these features do nt depend from the data generating mechanism and are model - free .",
    "in the scalar case they have been introduced and applied for the purpose to detect changes in generating mechanism @xcite of `` long '' eeg data .",
    "t. aflalo , s. kellis , c. klaes , b. lee , y. shi , k. pejsa , k. shanfield , s. hayes - jackson , m. aisen , c. heck , et al . , decoding motor imagery from the posterior parietal cortex of a tetraplegic human , science 348 ( 6237 ) ( 2015 ) 906 - 910 .",
    "a. y. kaplan , j .-",
    "byeon , j .- j .",
    "lim , k .- s .",
    "park , s. u. tarasova , unconscious operant conditioning in the paradigm of brain - computer interface based on color perception , international journal of neuroscience 115 ( 6 ) ( 2005 ) 781 - 802 .",
    "a. kaplan , s. shishkin , i. ganin , i. basyul , a. zhigalov , adapting the p300-based brain - computer interface for gaming : a review , computational intelligence and ai in games , ieee transactions on 5 ( 2 ) ( 2013 ) 141 - 149 .",
    "a. kaplan , j. rschke , b. darkhovsky , j. fell , macrostructural eeg characterization based on nonparametric change point segmentation : application to sleep analysis , journal of neuroscience methods 106 ( 1 ) ( 2001 ) 81 - 90 .",
    "z. dvey - aharon , n. fogelson , a. peled , n. intrator , schizophrenia detection and classification by advanced analysis of eeg recordings using a single electrode approach , plos one 10 ( 4 ) ( 2015 ) e0123033 .",
    "b. darkhovskii , a. kaplan , s. shishkin , on an approach to the estimation of the complexity of curves ( using as an example an electroencephalogram of a human being ) , automation and remote control 63 ( 3 ) ( 2002 ) 468 - 474 .",
    "b. darkhovsky , a. kaplan , m. kosinov , the estimation of complexity for the electroencephalogram in humans , in : 2006 ieee conference on computer aided control system design , 2006 ieee international conference on control applications , 2006 ieee international symposium on intelligent control , 2006",
    ". b. darkhovsky , a. piryatinska , a new complexity - based algorithmic procedures for electroencephalogram ( eeg ) segmentation , in : signal processing in medicine and biology symposium ( spmb ) , 2012 ieee , ieee , 2012 , pp . 1 - 5",
    ". b. darkhovsky , a. piryatinska , new approach to the segmentation problem for time series of arbitrary nature , proceedings of the steklov institute of mathematics 287 ( 1 ) ( 2014 ) 54 - 67 .",
    "b. darkhovsky , a. piryatinska , novel methodology of change - points detection for time series with arbitrary generating mechanisms , in : stochastic models , statistics and their applications , springer , 2015 , pp .",
    "241 - 251 .",
    "s. borisov , a. kaplan , n. gorbachevskaia , i. kozlova , segmental structure of the eeg alpha activity in adolescents with disorders of schizophrenic spectrum , zhurnal vysshei nervnoi deiatelnosti imeni ip pavlova 55 ( 3 ) ( 2004 ) 329 - 335 .",
    "a. kaplan , s. borisov , v. zheligovskii , classification of the adolescent eeg by the spectral and segmental characteristics for normals , zh vyssh nerv deiat i m ip pavlova 55 ( 2005 ) 478 - 86 . s. borisov , a. kaplan , n. gorbachevskaia , i. kozlova , analysis of eeg structural synchrony in adolescents suffering from schizophrenic disorders , fiziologiia cheloveka 31 ( 3 ) ( 2005 ) 16 .",
    "g. a. light , n. r. swerdlow , m. l. thomas , m. e. calkins , m. f. green , t. a. greenwood , r. e. gur , r. c. gur , l. c. lazzeroni , k. h. nuechterlein , et al .",
    ", validation of mismatch negativity and p3a for use in multi - site studies of schizophrenia : characterization of demographic , clinical , cognitive , and functional correlates in cogs-2 , schizophrenia research 163 ( 1 ) ( 2015 ) 63 - 72 ."
  ],
  "abstract_text": [
    "<S> a methodology for binary classification of eeg records which correspond to different mental states is proposed . </S>",
    "<S> this model - free methodology is based on our theory of the @xmath0-complexity of continuous functions which is extended here ( see appendix ) to the case of vector functions . </S>",
    "<S> this extension permits us to handle multichannel eeg recordings . </S>",
    "<S> the essence of the methodology is to use the @xmath0-complexity coefficients as features to classify ( using well known classifiers ) different types of vector functions representing eeg - records corresponding to different types of mental states . </S>",
    "<S> we apply our methodology to the problem of classification of multichannel eeg - records related to a group of healthy adolescents and a group of adolescents with schizophrenia . </S>",
    "<S> we found that our methodology permits accurate classification of the data in the four - dimensional feather space of the @xmath0-complexity coefficients . </S>"
  ]
}