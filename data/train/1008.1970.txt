{
  "article_text": [
    "we consider the classical cipher system of shannon @xcite .",
    "let @xmath0 be a message where each letter takes values on a finite set @xmath1 .",
    "this message should be communicated securely from a transmitter to a receiver , both of which have access to a common secure key @xmath2 of @xmath3 purely random bits independent of @xmath4 .",
    "the transmitter computes the cryptogram @xmath5 and sends it to the receiver over a public channel .",
    "the cryptogram may be of variable length .",
    "the encryption function @xmath6 is invertible for any fixed @xmath2 .",
    "the receiver , knowing @xmath7 and @xmath2 , computes @xmath8 .",
    "the functions @xmath6 and @xmath9 are published .",
    "a wiretapping attacker has access to the cryptogram @xmath7 , knows @xmath6 and @xmath9 , and attempts to identify @xmath4 without knowledge of @xmath2 .",
    "the attacker can use knowledge of the statistics of @xmath4 .",
    "we assume that the attacker has a test mechanism that tells him whether a guess @xmath10 is correct or not .",
    "for example , the attacker may wish to attack an encrypted password or personal information to gain access to , say , a computer account , or a bank account via internet , or a classified database @xcite . in these situations , successful entry into the system provides the natural test mechanism .",
    "we assume that the attacker is allowed an unlimited number of guesses .",
    "the _ key rate _ for the cipher system is @xmath11 nats nats per input symbol is the same as @xmath12 bits per input symbol .",
    "] of secrecy per message ( or source ) letter .",
    "merhav & arikan @xcite studied discrete memoryless sources ( dms ) in the above setting and characterized the best attainable moments of the number of guesses required by an attacker .",
    "in particular , they showed that for a dms with the governing single letter pmf @xmath13 on @xmath1 , the value of the optimal exponent for the @xmath14th moment @xmath15 is given by @xmath16 the maximization is over all pmfs @xmath17 on @xmath1 , @xmath18 is the shannon entropy of @xmath17 , and @xmath19 is the kullback - leibler divergence between @xmath17 and @xmath13 .",
    "they also showed that @xmath20 increases linearly in @xmath21 for @xmath22 , continues to increase in a concave fashion for @xmath23 $ ] , where @xmath24 is a threshold , and is constant for @xmath25 .",
    "unlike the classical equivocation rate analysis , atypical sequences do affect the behavior of @xmath20 for @xmath23 $ ] and perfect secrecy is obtained , i.e. , cryptogram is uncorrelated with the message , only for @xmath26 .",
    "merhav & arikan also determined the best achievable performance based on the probability of a large deviation in the number of guesses , and showed that it equals the legendre - fenchel transform of @xmath20 as a function of @xmath14 .",
    "sundaresan @xcite extended the above results to unifilar sources .",
    "hayashi & yamamoto @xcite proved coding theorems for the shannon cipher system with correlated outputs @xmath27 where the wiretapper is interested in @xmath4 while the receiver in @xmath28 .    in this paper",
    ", we extend merhav & arikan s notion of computational secrecy @xcite to general sources .",
    "one motivation is that secret messages typically come from the natural languages which are modeled well as sources with memory , for e.g. , a markov source of appropriate order .",
    "another motivation is that the study of general sources clearly brings out the connection between guessing and compression , as discussed next .    as with other studies of general sources , _ information spectrum _ plays crucial role in this paper .",
    "we show that @xmath29 is closely related to ( a ) the error exponent of a rate-@xmath21 source code , and ( b ) the correct decoding exponent of a rate-@xmath21 source code , when exponentiated probabilities are considered ( see sec .",
    "[ subsubsec : correctdecodingexponent ] ) .",
    "in particular , the exponents in ( a ) and ( b ) appear in the first and second terms below when we rewrite @xmath20 for a dms as @xmath30 this brings out the fundamental connection between source coding exponents and key - rate constrained guessing exponents .",
    "further , unlike the case for the probability of a large deviation in the number of guesses ( * ? ? ?",
    "v ) , both the error exponent and the correct decoding exponent determine @xmath29 .",
    "we extend the above result to general sources by getting upper and lower bounds on @xmath29 .",
    "we then show that these are tight for dms , markov and unifilar sources .",
    "the bounds may be of interest even if they are not tight because the upper bound specifies the amount of effort need by an attacker and the lower bound specifies the secrecy strength of the cryptosystem to a designer .",
    "the limiting case as @xmath31 in ( b ) yields classical framework for probability of correct decoding .",
    "this special case is related to the work of han @xcite and iriyama @xcite who studied the dual problem of rates required to meet a specified error exponent or a specified correct decoding exponent .",
    "the paper is organized as follows .",
    "section [ sec : specifiedkeyrateguessing ] relates our problem to a modification of campbell s compression problem @xcite .",
    "section [ sec : information spectrum results ] gives bounds on the limits of exponential rate of guessing moments , in terms of information spectrum quantities .",
    "section [ sec : examples ] evaluates the bounds for some specific examples .",
    "section [ sec : conclusion ] concludes the paper with additional remarks .",
    "proofs are given in the appendices .",
    "in this section , we make a precise statement of our problem , and establish a connection between guessing and source compression subject to a new cost criterion .",
    "let @xmath32 denote the set of messages and @xmath33 the set of pmfs on @xmath32 . by a source ,",
    "we mean a sequence of pmfs @xmath34 , where in place of @xmath35 when we refer to the distribution of the random vector @xmath4 . ] @xmath36 .",
    "let @xmath4 denote a message put out by the source and @xmath2 the secure key of @xmath3 purely random bits independent of @xmath4 . recall that the transmitter computes the cryptogram @xmath37 and sends it to the receiver over a public channel .    for a given cryptogram @xmath38 ,",
    "define a _ guessing strategy _ @xmath39 as a bijection that denotes the order in which elements of @xmath32 are guessed .",
    "@xmath40 indicates that @xmath41 is the @xmath42th guess , when the cryptogram is @xmath43 . with knowledge of @xmath35 , the encryption function @xmath6 , and the cryptogram @xmath7",
    ", the attacker can exhaustively calculate the posterior probabilities of all plaintexts @xmath44 given the cryptogram .",
    "the attacker s optimal guessing strategy is then to guess in the decreasing order of these posterior probabilities @xmath44 .",
    "let us denote this optimal attack strategy as @xmath45 .",
    "the key rate for the system is @xmath11 nats of secrecy per source letter .",
    "let @xmath46 denote the sequence of encryption functions , where @xmath47 denotes the set of natural numbers .",
    "this sequence is known to the attacker .",
    "we assume that the attacker employs the aforementioned optimal guessing strategy .    for a given @xmath48 , key rate @xmath49 , define the normalized guessing exponent @xmath50.\\ ] ] the supremum is taken over all encryption functions .",
    "further define performance limits of guessing moments as in @xcite : @xmath51    we next define the related compression quantities .",
    "a length function @xmath52 is a mapping that satisfies kraft s inequality : @xmath53 where the code alphabet is taken to be binary and @xmath54 .",
    "( we shall use @xmath55 to denote the inverse of the natural logarithm @xmath56 ) .",
    "every length function yields an attack strategy with a performance characterized as follows .",
    "[ prop : key : lengthbasedguessing ] let @xmath57 be any length function on @xmath32 .",
    "there is a guessing list @xmath58 such that for any encryption function @xmath6 , we have is measured in nats . ]",
    "@xmath59    we use a technique of merhav & arikan @xcite . let @xmath60 denote the guessing function that ignores the cryptogram and proceeds in the increasing order of @xmath57 lengths .",
    "suppose @xmath60 proceeds in the order @xmath61 . by ( * ? ? ?",
    "2 ) , we need at most @xmath62 guesses to identify @xmath41 ( this is a simple consequence of the fact that there are at most @xmath62 strings of length less than or equal to @xmath63 ) .    as an alternative attack ,",
    "consider the exhaustive key - search attack defined by the following guessing list : @xmath64 where @xmath65 is an arbitrary ordering of the keys .",
    "this strategy identifies @xmath41 in at most @xmath66 guesses .",
    "finally , let @xmath67 be the list that alternates between the two lists , skipping those already guessed , i.e. , the one that proceeds in the order @xmath68 clearly , for every @xmath41 , we need at most twice the minimum over the two individual lists .",
    "we now look at a weak converse in the expected sense to the above .",
    "we first state without proof the following lemma which associates a length function to any guessing function ( see ( * ? ? ? * prop .",
    "[ lema : guesslengthrelation ] given a guessing function @xmath58 , there exists a length function @xmath69 satisfying @xmath70 where @xmath71    for a proof , we refer the reader to ( * ? ? ?",
    "we then have the following proposition .",
    "[ prop : key : optimalencryption ] fix @xmath72 , @xmath73 .",
    "there is an encryption function @xmath6 and a length function @xmath57 such that every guessing strategy @xmath58 ( and in particular @xmath45 ) satisfies @xmath74 } \\\\    & \\geq & \\frac{1}{(2 c_n)^{\\rho } ( 2 +    \\rho ) } \\mathbb{e } \\left[\\exp \\left\\ { \\rho \\min \\left\\ { l_n\\left(x^n\\right ) \\ln 2 , nr \\right\\ } \\right\\ }    \\right].\\end{aligned}\\ ] ]    see appendix [ subsec : proofoptimalencryption ] .",
    "the proof is an extension of merhav & arikan s proof of ( * ? ? ?",
    "* th.1 ) to sources with memory .",
    "the idea is to identify an encryption mechanism that maps messages of roughly equal probability to each other .",
    "our proof also suggests an asymptotically optimal encryption strategy for sources with memory .",
    "note that @xmath75 , so that @xmath76 a fact that will be put to good use in the sequel .",
    "propositions [ prop : key : lengthbasedguessing ] and [ prop : key : optimalencryption ] naturally suggest the following coding problem : identify @xmath77.\\ ] ] the minimum is taken over all length functions .",
    "we may interpret the cost of using length @xmath63 as @xmath78 , i.e. , the cost is exponential in @xmath57 , but saturates at @xmath79 and so all lengths larger than @xmath80 nats ( i.e. , @xmath81 bits ) enjoy the saturated cost .",
    "then @xmath82 is the minimum normalized exponent of the @xmath14th moment of this new compression cost . in analogy with ( [ eqn : limsupguessexpo ] ) and ( [ eqn : liminfguessexpo ] ) we define @xmath83 @xmath84 the following is a corollary to propositions [ prop : key : lengthbasedguessing ] and [ prop : key : optimalencryption ] , and relates @xmath85 and @xmath82 .",
    "[ cor : enenl ] for a given @xmath86 , we have @xmath87    let @xmath88 be the length function that achieves @xmath89 .",
    "using proposition [ prop : key : lengthbasedguessing ] , and after taking expectation , we have the guessing strategy @xmath58 that satisfies @xmath90 } \\\\    & \\geq & \\sup_{f_n } \\frac{1}{2^{\\rho } } \\mathbb{e } \\left [ g_n(x^n \\mid y)^{\\rho }    \\right ] \\\\    & \\geq & \\sup_{f_n } \\frac{1}{2^{\\rho } } \\mathbb{e } \\left [ g_{f_n}(x^n \\mid y)^{\\rho }    \\right ] \\\\    & \\geq & \\frac{1}{(4 c_n)^{\\rho } ( 2 + \\rho ) } \\mathbb{e } \\left[\\exp \\left\\{\\rho \\min \\left\\ { l_n(x^n ) \\ln 2 , nr\\right\\ } \\right\\ } \\right ] \\\\    & & \\mbox{for some $ f_n$ and $ l_n$ , given by proposition \\ref{prop : key : optimalencryption } , } \\\\",
    "& \\geq & \\frac{1}{(4 c_n)^{\\rho } ( 2 + \\rho ) } \\mathbb{e } \\left [ \\exp \\left\\{\\rho \\min \\left\\{l_n^*(x^n ) \\ln 2 , nr \\right\\ } \\right\\ } \\right].\\end{aligned}\\ ] ] take logarithms , normalize by @xmath91 , use @xmath92 and @xmath48 to get ( [ eqn : diffenenl ] ) .",
    "we now state the equivalence between compression and guessing .",
    "[ prop : guessing - sourcecode - equivalence ] for any @xmath73 and @xmath49 , we have @xmath93 and @xmath94",
    ".    from corollary [ cor : enenl ] and ( [ eqn : c_n / n - bound ] ) , magnitude of the difference between @xmath85 and @xmath82 decays as @xmath95 and vanishes as @xmath96 .",
    "thus , the problem of finding the optimal guessing exponent is the same as that of finding the optimal exponent for the coding problem in ( [ eqn : newcodingproblem ] ) .",
    "when @xmath97 , the coding problem in ( [ eqn : newcodingproblem ] ) reduces to the one considered by campbell in @xcite ; this is a case where perfect secrecy is obtained and is studied in @xcite .",
    "proposition [ prop : key : lengthbasedguessing ] shows that the optimal length function attaining the minimum in ( [ eqn : newcodingproblem ] ) yields an asymptotically optimal attack strategy on the cipher system .",
    "moreover , the encryption strategy in the proof of proposition [ prop : key : optimalencryption ] ( see appendix [ subsec : proofoptimalencryption ] ) is asymptotically optimal , from the designer s point of view .    in the rest of the paper we focus on the equivalent compression problem and find bounds on @xmath98 and @xmath99 .",
    "we begin with some words on notation . recall that @xmath33 denotes the set of pmfs on @xmath32 .",
    "the shannon entropy for a @xmath36 is @xmath100 and the rnyi entropy of order @xmath101 is @xmath102 the kullback - leibler divergence or relative entropy between two pmfs @xmath103 and @xmath35 is @xmath104 where @xmath105 means @xmath103 is absolutely continuous with respect to @xmath35 .",
    "we shall use @xmath106 to denote a sequence of random variables on @xmath32 , with corresponding sequence of probability measures denoted by @xmath107 .",
    "thus @xmath108 is a source and @xmath4 its @xmath91-letter message output .",
    "abusing notation , we let @xmath109 denote the set of all sequences @xmath110 of probability measures , and for each @xmath111 , we define @xmath112 in the rest of this section @xmath108 is a fixed source . for any @xmath113 and @xmath48 , define @xmath114 and @xmath115    we next state a large deviation result that plays a key role in the derivation of bounds on @xmath98 and @xmath99 .",
    "[ prop : limit - variational - formula ] for all @xmath116 and @xmath117 , we have @xmath118 @xmath119 the maximum - achieving distribution in ( [ eqn : limsup - eu ] ) and ( [ eqn : liminf - el ] ) is the source @xmath120 given by @xmath121    see appendix [ subsec : limit - variational - formula - proof ] .",
    "this proposition is a generalization of iriyama s ( * ? ? ?",
    "1 ) , which is obtained by setting @xmath122 .      we first obtain an upper bound on @xmath98 .",
    "we use @xmath123 $ ] to denote the expectation with respect to distribution @xmath124 .",
    "[ prop : upperbound ] let @xmath125 and @xmath48",
    ". then @xmath126.\\ ] ]    we first recall the useful variational formula ( * ? ? ?",
    "1.4.2 ) @xmath127 } \\nonumber\\\\ \\label{eqn : variationalequation } & & = \\sup_{p_{y^n}}\\left\\{\\mathbb{e}_{y^n}[u(y^n)]-d(p_{y^n } \\parallel p_{x^n})\\right\\}\\end{aligned}\\ ] ] for any @xmath128 , where @xmath129 denotes set of real numbers . for notational convenience ,",
    "let @xmath130 .",
    "observe that @xmath131 } \\nonumber \\\\ \\label{eqn : vari_formula_ubound } & = & \\sup_{p_{y^n } } [ \\rho \\mathbb{e}_{y^n } \\left [ \\min\\{l_n(y^n ) \\ln 2 , nr\\ } \\right ] - ~ d({y^n } ) ]   \\\\ \\label{eqn : jesen - applic-1 } & \\leq &   \\sup_{p_{y^n } } [ \\rho \\min\\{\\mathbb{e}_{y^n } \\left [ l_n(y^n ) \\ln 2\\right ] , nr\\ } - ~ d({y^n } ) ]   \\\\ & = & \\sup_{p_{y^n } } \\bigg \\ {   \\min _ { 0\\leq \\theta\\leq \\rho }   [ ( \\rho -\\theta)nr + \\theta \\mathbb{e}_{y^n } \\left [ l_n(y^n ) \\ln 2\\right ] \\nonumber \\\\ \\label{eqn : min - linear - combo } & & \\hspace*{2 in } - ~ d({y^n } ) \\bigg \\ } \\\\ & = & \\min _ { 0\\leq \\theta\\leq \\rho }   \\sup_{p_{y^n } } \\bigg \\{(\\rho",
    "-\\theta)nr + \\theta \\mathbb{e}_{y^n } \\left [ l_n(y^n ) \\ln 2\\right ] \\nonumber \\\\ \\label{eqn : supinf - interchange - first } & & \\hspace*{2 in } - ~ d({y^n})\\bigg \\ } \\\\ & = & \\min _ { 0\\leq \\theta\\leq \\rho }    \\bigg\\{(\\rho -\\theta)nr + \\sup_{p_{y^n}}\\bigg \\{\\theta \\mathbb{e}_{y^n}\\left [ l_n(y^n ) \\ln 2\\right ] \\nonumber \\\\ & & \\hspace*{2 in } - ~ d({y^n } ) \\bigg\\ } \\bigg\\}. \\nonumber\\end{aligned}\\ ] ] in the above sequence of inequalities , ( [ eqn : vari_formula_ubound ] ) follows from the variational formula ( [ eqn : variationalequation ] ) with @xmath132 inequality ( [ eqn : jesen - applic-1 ] ) follows from jensen s inequality because @xmath133 is concave for a fixed @xmath80 .",
    "equality ( [ eqn : min - linear - combo ] ) follows from the identity @xmath134 equality ( [ eqn : supinf - interchange - first ] ) follows because the term within braces is linear in @xmath135 for a fixed @xmath136 , concave in @xmath136 for a fixed @xmath135 , and the sets @xmath137 $ ] and @xmath33 are compact and convex ; these permit an interchange of sup and inf , thanks to a minmax theorem ( * ? ? ?",
    "2 , p. 53 ) .",
    "taking @xmath138 over @xmath57 , and interchanging the @xmath138 over @xmath57 and the @xmath139 over @xmath135 , we get @xmath140 } \\nonumber\\\\ & \\leq & \\min _ { 0\\leq \\theta\\leq \\rho }     \\bigg \\{(\\rho -\\theta)nr + \\inf_{l_n } \\sup_{p_{y^n}}\\bigg \\{\\theta \\mathbb{e}_{y^n } \\left [ l_n(y^n ) \\ln 2\\right ] \\nonumber \\\\ & & \\hspace*{2.1 in }   - ~ d({y^n})\\bigg \\}\\bigg \\}\\nonumber\\\\ & = & \\min _ { 0\\leq \\theta\\leq \\rho }     \\bigg \\{(\\rho -\\theta)nr + \\sup_{p_{y^n } } \\bigg \\{\\theta \\inf_{l_n } \\mathbb{e}_{y^n } \\left [ l_n(y^n ) \\ln 2\\right ]   \\nonumber\\\\ \\label{eqn : supinf - interchange - second } & & \\hspace{1.5 in } - ~ d({y^n})\\bigg \\ } + o(1)\\bigg\\ } \\\\ \\label{eqn : sourcecodind - entropy - ubound } & = &   \\min _ { 0\\leq \\theta\\leq \\rho }     \\bigg \\{(\\rho -\\theta)nr + \\sup_{p_{y^n } } \\bigg \\{\\theta h(p_{y^n } )    \\nonumber\\\\ & & \\hspace{1.5 in } -",
    "~ d({y^n})\\bigg \\}+ o(1)\\bigg \\ } \\\\ \\label{eqn : variationalubound } & = & \\min _ { 0\\leq \\theta\\leq \\rho }     \\bigg \\{(\\rho -\\theta)nr + \\theta h_{\\frac{1}{1+\\theta}}(p_{x^n } ) + o(1 ) \\bigg \\}.\\end{aligned}\\ ] ] equality ( [ eqn : supinf - interchange - second ] ) follows because the function inside the inner braces is concave in @xmath136 , asymptotically linear in @xmath57 ( see proof of ( * ? ? ?",
    "* prop . 6 ) ) , and @xmath33 is compact ; this allows us to interchange @xmath138 and @xmath141 .",
    "inequality ( [ eqn : sourcecodind - entropy - ubound ] ) follows because @xmath138 of expected compression lengths over all prefix codes is within @xmath142 nats ( 1 bit ) of entropy .",
    "the last equality follows from the well - known variational characterization of rnyi entropy , @xmath143 a fact that can also be gleaned from the variational formula ( [ eqn : variationalequation ] ) .",
    "divide both sides of ( [ eqn : variationalubound ] ) by @xmath91 and take limit supremum as @xmath96 to get    @xmath144    where the last inequality follows from proposition [ prop : limit - variational - formula ] and the formula for rnyi entropy .",
    "this completes the proof .    from the above proof",
    "it is clear that the upper bound holds with equality , when jensen s inequality holds with equality in ( [ eqn : jesen - applic-1 ] ) , i.e , the random variable @xmath145 tends asymptotically to a constant .",
    "this would happen , for example , when normalized encoded lengths concentrate around the entropy rate of the source .",
    "we now derive a lower bound on @xmath99 . for",
    "a given distribution @xmath136 arrange the elements of set @xmath32 in the decreasing order of their @xmath136-probabilities as done in sundaresan ( * ? ? ?",
    "iv ) . enumerate the sequences from 1 to @xmath146 .",
    "henceforth refer to a message by its index .",
    "let @xmath147 denote the first @xmath148 elements in the list .",
    "we denote the probability of this set by @xmath149 , i.e. , @xmath150 and the probability of the complement of this set @xmath151 by @xmath152 .",
    "let the restriction of @xmath136 to this set @xmath147 be @xmath153 .",
    "let @xmath88 denote the length function that attains @xmath89 in ( [ eqn : newcodingproblem ] ) .",
    "as the length functions are uniquely decipherable we have @xmath154 .",
    "+    [ prop : lowerbound ] for a given @xmath48 and rate @xmath49 , we have @xmath155    the first term contains limit infimum of the error exponent for a rate-@xmath21 source code .",
    "the second exponent is the correct decoding exponent for a rate-@xmath21 code when @xmath31 .",
    "the variational formula ( [ eqn : variationalequation ] ) applied to the function @xmath156 gives @xmath157 } \\nonumber\\\\ & = & \\inf_{l_n}\\sup_{p_{y^n } } \\{\\rho \\mathbb{e}_{y^n}[\\min\\{l_n(y^n ) \\ln 2 , nr\\ } ] -d(y^n ) \\ } \\nonumber \\\\ & \\geq &   \\sup_{p_{y^n } } \\bigg \\{\\rho \\inf_{l_n } \\mathbb{e}_{y^n}\\left[\\min\\{l_n(x^n ) \\ln 2 , nr\\}\\right]-d(y^n)\\bigg \\ }",
    "\\nonumber \\\\ \\label{eqn : maxminlowerbound } & & \\end{aligned}\\ ] ] where the interchange of inf and sup yields the lower bound in ( [ eqn : maxminlowerbound ] ) .",
    "fix a distribution @xmath136 and consider the first term in ( [ eqn : maxminlowerbound ] ) . using the enumeration indicated above ,",
    "we may write @xmath158 } \\nonumber\\\\ & = & \\sum_{i=1}^{|\\mathbb{x}|^n } p_{y^n}(i)\\min\\{l_n^*(i ) \\ln 2 , nr\\ } \\nonumber\\\\ & = & \\sum_{i=1}^m p_{y^n}(i)\\min\\{l_n^*(i ) \\ln 2 , nr\\ } + \\sum_{i = m+1}^{|\\mathbb{x}|^n } p_{y^n}(i)nr \\nonumber\\\\ \\label{eqn : optimal guess } & \\geq &   \\sum_{i=1}^{m } p_{y^n}(i)\\ln g_n^*(i ) + nrf_{y^n}^{c } \\\\ & \\geq & f_{y^n } \\sum_{i=1}^m   \\frac{p_{y^n}(i)}{f_{y^n } }   { l_{g_n^*}(i ) } \\ln 2 - \\ln 2 - \\ln",
    "( 1 + n \\ln |\\mathbb{x}| ) \\nonumber \\\\ \\label{eqn : guess_lentgh prop } & & ~ + ~ nrf_{y^n}^{c } \\\\ \\label{eqn : lbound - min - expect } & \\geq & f_{y^n } h(p_{y^n}^{\\prime})- \\ln 2 - \\ln ( 1 + n\\ln |\\mathbb{x}| ) + nrf_{y^n}^{c}.\\end{aligned}\\ ] ] inequality ( [ eqn : optimal guess ] ) follows because @xmath159 with @xmath160 the guessing strategy that guesses in decreasing order of @xmath136 probabilities .",
    "@xmath161 in ( [ eqn : guess_lentgh prop ] ) denotes the length function given by lemma [ lema : guesslengthrelation ] .",
    "inequality ( [ eqn : lbound - min - expect ] ) follows from the source coding theorem s lower bound",
    ". substitute ( [ eqn : lbound - min - expect ] ) in ( [ eqn : maxminlowerbound ] ) , normalize by @xmath91 , and take limit infimum to get @xmath162 @xmath136 may be thought of as a triplet made of @xmath163 and the restriction of @xmath136 to @xmath151 .",
    "we now perform the optimization @xmath164 in four steps .",
    "* step 1 * : we first optimize over permutations of probabilities over strings .",
    "@xmath149 , @xmath165 , @xmath166 , and @xmath167 remain unchanged over these permutations .",
    "observe that @xmath168 and so the maximum for @xmath169 is attained when the permutation that orders @xmath170 in decreasing order also orders @xmath171 in decreasing order . in particular , @xmath147 equals @xmath172 .    * step 2 * : we now optimize over restriction of @xmath136 to @xmath151 . for a fixed @xmath149 ,",
    "the log - sum inequality yields @xmath173 with equality if and only if @xmath174 for all @xmath175 .",
    "* step 3 * : to optimize over @xmath153 rewrite ( [ eqn : equationtooptimize ] ) as @xmath176 equality ( [ eqn : diver_lower_bound ] ) is obtained by substituting the attained lower bound in step  2 . in ( [ eqn : binary_restricted_diver ] ) , @xmath153 and @xmath177 denote conditional distributions of @xmath136 and @xmath124 given @xmath147 and @xmath172 , respectively , where @xmath178 as argued in step  1 .",
    "@xmath179 denotes the divergence between binary random variables whose probabilities are @xmath180 and @xmath181 respectively .",
    "finally we used variational characterization of rnyi entropy given in ( [ eqn : renyivariationalcharac ] ) to arrive at ( [ eqn : renyi_entropy ] ) .    * step 4 * : we now optimize over @xmath182 $ ] .",
    "let @xmath183 be a binary random variable defined as @xmath184 by @xmath185 $ ] we mean the expectation of @xmath183 with respect to the above distribution .",
    "since @xmath183 is a positive random variable , the variational formula yields @xmath186-d(f_{y^n}\\parallel f_{x^n})\\right \\ } = \\ln   \\mathbb{e}_{f_{x^n}}\\left [ \\exp\\{z\\}\\right].\\ ] ] continuing with the chain of equalities from ( [ eqn : renyi_entropy ] ) we get @xmath187 finally normalize both sides of ( [ eqn : maximum - varational - difference ] ) by @xmath91 , take limit infimum , and apply ( * ? ? ?",
    "* lemma 1.2.15 ) , which states that the exponential rate of a sum is governed by the maximum of the individual terms exponential rates , to get the desired result .    in the subsequent subsections we further lower bound each of the two terms under max on the right - hand side of ( [ eqn : aymptoticlowerbound ] ) .",
    "for an arbitrary source we first recall the source coding error exponent .",
    "we also identify the growth rate of sum of exponentiated probabilities of the correct decoding set .",
    "we then relate these to the terms in the lower bound obtained in ( [ eqn : aymptoticlowerbound ] ) .",
    "we largely follow the approach and notation of iriyama @xcite , which we now describe .    given @xmath188 and @xmath189 , we define the upper divergence @xmath190 and lower divergence @xmath191 by @xmath192 @xmath193 for a @xmath194 , denote the _ spectral sup - entropy - rate _",
    "ii ) , @xcite as @xmath195 and the _ spectral inf - entropy - rate _ as @xmath196 also define , as in ( * ? ? ?",
    "ii ) , the following quantity which determines the performance under mismatched compression : @xmath197      in this subsection we recall the decoding error exponent for fixed - rate encoding of an arbitrary source .",
    "we identify the first term in ( [ eqn : aymptoticlowerbound ] ) as composed of the exponent of minimum probability of decoding error , and obtain a lower bound for it , or alternatively an upper bound on the error exponent .",
    "this is made precise in the following definitions .    by an @xmath198-code",
    "we mean an encoding mapping @xmath199 and a decoding mapping @xmath200 with probability of error @xmath201 .",
    "@xmath21 is @xmath202-achievable if for all @xmath203 there exists a sequence of @xmath198-codes such that @xmath204 the _ infimum fixed - length coding rate _ for exponent",
    "@xmath202 is @xmath205 on the other hand , the _ supremum fixed - length coding exponent _ for rate @xmath21 is @xmath206 see iriyama @xcite and han ( * ? ? ?",
    "1.9 ) for a pessimistic definition for fixed rate source coding , i.e. , the liminf in place of limsup in ( [ eqn : error - liminf - exponent ] ) .",
    "see also iriyama & ihara @xcite for both the pessimistic and optimistic definitions .",
    "these works obtained bounds on the infimum coding rate .",
    "in particular , iriyama ( * ? ? ? * eqn .",
    "( 13 ) ) , iriyama & ihara ( * ? ? ?",
    "( 12 ) ) obtained lower bounds on the infimum coding rate @xmath207 under the optimistic definition , the definition of interest to us .",
    "we however work with the error exponent , and obtain an upper bound on supremum coding exponent .",
    "this suffices to lower bound the first term in ( [ eqn : aymptoticlowerbound ] )",
    ".    clearly , @xmath208 satisfies ( [ eqn : r - rate ] ) , and with @xmath209 @xmath21 is @xmath210-achievable .",
    "it follows from the definition of @xmath211 that @xmath212 so that @xmath213 the following proposition upper bounds the supremum coding exponent .",
    "[ prop : sup - exponent - error - liminf ] for any rate @xmath49 , @xmath214    see appendix [ subsec : sup - exponent - error - liminf - proof ] .",
    "[ remark : errorexponentemptyset ] when @xmath215 , the probability of decoding error @xmath216 , so that @xmath217 .",
    "the right - hand side is an infimum over an empty set and is @xmath218 by convention , and the proposition holds for such @xmath21 as well .",
    "one can also show the alternative bound @xmath219 see the end of appendix [ subsec : sup - exponent - error - liminf - proof ] on how to prove this",
    ". this result would be the functional inverse of iriyama s ( * ? ? ?",
    "( 13 ) ) , while proposition [ prop : sup - exponent - error - liminf ] is the functional inverse of iriyama & ihara s ( * ? ? ?",
    "proposition [ prop : sup - exponent - error - liminf ] , as we will soon see , provides a more natural extension of arikan & merhav s expression for @xmath20 to general sources .",
    "we now study a generalization of the exponential rate for probability of correct decoding .    for a given @xmath198-code , let @xmath220 denote the set of correctly decoded sequences . for a given @xmath221",
    ", @xmath21 is @xmath222-admissible if for every @xmath203 there exists a sequence of @xmath198-codes such that @xmath223 @xmath224 unlike the exponent for the probability of error , here @xmath202 can be positive or negative .",
    "the _ infimum fixed - length admissible rate _ for a given @xmath202 and @xmath48 is @xmath225 it is easy to see that the set @xmath226 is closed and so @xmath227 is @xmath222-admissible .",
    "+ the _ supremum fixed - length coding exponent _ for a given @xmath21 and @xmath14 is @xmath228    the choice of limit infimum in ( [ eqn : correct - liminf - exponent ] ) makes the definition of admissibility pessimistic . for @xmath229 ,",
    "the above definitions reduce to the special case of exponential rate for probability of correct decoding ( see ( * ? ? ?",
    "* sec . 1.10 ) ) .    clearly , @xmath230 should be @xmath172 to maximize the left - hand side of ( [ eqn : correct - liminf - exponent ] ) , and hence @xmath231 the following proposition gives an expression for @xmath232 and generalizes ( * ? ? ?",
    "4 ) to any arbitrary @xmath73 . en route to its derivation",
    "we find the expression for @xmath227 .",
    "[ prop : inf - rate - correct ] for any @xmath48 , we have @xmath233 @xmath234    see appendix [ subsec : inf - rate - correct - proof ] .",
    "we now combine propositions [ prop : upperbound]-[prop : inf - rate - correct ] of the previous subsections to obtain the main result of the paper .    for a given @xmath48 and @xmath49 , @xmath235",
    "the last inequality was proved in proposition [ prop : upperbound ] .",
    "proposition [ prop : lowerbound ] indicates that @xmath236 where ( [ eqn : substitute - definition ] ) follows from the lower bound on @xmath211 and the definition of @xmath232 , and ( [ eqn : substitute - expression ] ) from propositions [ prop : sup - exponent - error - liminf ] and [ prop : inf - rate - correct ] .",
    "in this section we evaluate the bounds for some examples where they are tight , and recover some known results .",
    "first consider the perfect secrecy case , for example , @xmath237 . because of remark [ remark : errorexponentemptyset ] and because we may take @xmath238 in the upper bound in ( [ eqn : finalbounds ] ) , the limiting exponential rate of guessing moments simplifies to @xmath239 on account of ( [ eqn : liminf - el ] ) in proposition [ prop : limit - variational - formula ] , sup in the left - most term is achieved . from proposition",
    "[ prop : limit - variational - formula ] , upper and lower bounds are @xmath14 times the liminf and limsup rnyi entropy rates of order @xmath240 . in a related work we proved in (",
    "7 ) that whenever the _ information spectrum _ of the source satisfies the large deviation property with rate function @xmath241 , the rnyi entropy rate converges and limiting guessing exponent equals the legendre - fenchel dual of the scaled rate function @xmath242 , i.e. , @xmath243 in the next examples , we consider the case @xmath244 .",
    "this example was first studied by merhav & arikan @xcite . recall that an iid source is one for which @xmath245 , where @xmath246 denotes the marginal of @xmath247 .",
    "we will now evaluate each term in ( [ eqn : finalbounds ] ) .",
    "we first argue that @xmath248 to prove that the left - hand side in ( [ eqn : iiderrorexpo ] ) is less than or equal to the right - hand side , let @xmath249 be such that @xmath250 . construct an iid source @xmath251 such that @xmath252 for all @xmath253 .",
    "the iid property easily implies that @xmath254 and the law of large numbers for iid random variables yields @xmath255 from ( [ eqn : iidconverserdiffd ] ) , we have that the infimum on the left - hand side of ( [ eqn : iiderrorexpo ] ) is over a larger set .",
    "we can therefore conclude that `` @xmath256 '' holds in ( [ eqn : iiderrorexpo ] ) .    to prove `` @xmath257 '' in ( [ eqn : iiderrorexpo ] ) we use the result ( see ( * ? ? ?",
    "1.7.2 ) ) @xmath258 to get that the infimum over a larger set is smaller , i.e. , @xmath259 because of ( [ eqn : anotherexponentbound ] ) it is sufficient to prove @xmath260 let @xmath261 be such that @xmath262 .",
    "construct a source @xmath263 such that , @xmath264 for @xmath253 and @xmath265 are independent .",
    "let @xmath266 be another source such that @xmath267 is an iid sequence with distribution @xmath268 as the marginals of @xmath269 and @xmath270 with independent components are the same , it easily follows from the formula for kullback - leibler divergence that @xmath271 where ( [ eqn : divergenceconvexbound ] ) follows from the convexity of divergence . from the concavity of shannon entropy",
    ", we also have @xmath272 normalize by @xmath91 take limsup in ( [ eqn : divergenceconvexbound ] ) and liminf in ( [ eqn : entropyconcavebound ] ) to get @xmath273 and @xmath274 for a @xmath275 that is a limit point of the sequence @xmath276 . from these",
    "we conclude that ( [ eqn : iidanotherbound ] ) holds .",
    "this proves ( [ eqn : iiderrorexpo ] ) .    following a similar procedure as above",
    ", we can bound the other terms in ( [ eqn : finalbounds ] ) for an iid source as @xmath277 and @xmath278 substitution of ( [ eqn : iiderrorexpo ] ) and ( [ eqn : iidellbound ] ) in the lower bound of ( [ eqn : finalbounds ] ) yields @xmath279 similarly substitution of ( [ eqn : iideuubound ] ) in the upper bound of ( [ eqn : finalbounds ] ) yields @xmath280 where the interchange of sup and min in ( [ eqn : minsupinterchange ] ) holds because the function within braces is linear in @xmath135 and concave in @xmath281 . from ( [ eqn : iidguessexponentlbound ] ) and ( [ eqn : iidguessexponentubound ] ) , we recover merhav & arikan s result ( [ eqn : iidguessexponent ] ) for an iid source ( * ? ? ?",
    "( 3 ) ) .",
    "[ example : markov ] in this example we focus on an irreducible stationary markov source taking values on @xmath1 and having a transition probability matrix @xmath282 .",
    "let @xmath283 denote the set of _ stationary _ pmfs defined by @xmath284 denote the common marginal by @xmath285 and let @xmath286 we may then denote @xmath287 , where @xmath285 is the distribution of @xmath247 and @xmath288 the conditional distribution of @xmath289 given @xmath247 .",
    "following steps similar to the iid case , we have    @xmath290 where @xmath291 is the conditional one - step entropy , and @xmath292 for a unifilar source the underlying state space forms a markov chain and the entropy and divergence of the source equals those of the underlying markov state space source ( * ? ? ?",
    "the arguments for the markov source are now directly applicable to a unifilar source .",
    "we saw the close connection between the problem of guessing a source realization given a cryptogram and the problem of compression with saturated exponential costs .",
    "the latter is a modification of a problem posed by campbell @xcite .",
    "moreover , the exponents for both these problems coincide .",
    "this exponent is determined by the error exponent and a generalization of correct decoding exponent for fixed length block source codes .",
    "we end this paper with some open questions .",
    "* the equivalence between guessing and compression exploits the finite alphabet size assumption .",
    "can this be relaxed ?",
    "* how do the results of this paper extend to the case with receiver side information ?",
    "can the result of hayashi & yamamoto be extended to general sources ? *",
    "if guessing to within a distortion is allowed , can the result of merhav & arikan @xcite be extended to general sources ? both cases of perfect secrecy and key - rate constrained secrecy remain open .",
    "[ sec : conclusion ]    [ sec : appendix ]",
    "let @xmath35 be any pmf on @xmath32 .",
    "enumerate the elements of @xmath32 from 1 to @xmath293 in the decreasing order of their @xmath35-probabilities .",
    "let @xmath294 denote the number of distinct key strings . for convenience",
    ", we shall assume that @xmath295 is a power of 2 so that the number of key bits @xmath296 is an integer .",
    "the general case will be easily handled towards the end of this section .",
    "if @xmath295 does not divide @xmath293 , append a few dummy messages of zero probability to make the number of messages @xmath297 a multiple of @xmath295 .",
    "further , index the messages from 0 to @xmath298 .",
    "henceforth , we identify a message @xmath41 by its index .",
    "divide the messages into groups of @xmath295 so that message @xmath299 belongs to group @xmath300 , where @xmath301 , and @xmath302 is the floor function .",
    "enumerate the key streams from 0 to @xmath303 , so that @xmath304 .",
    "the function @xmath6 is now defined as follows . for @xmath305 set @xmath306 where @xmath307 is the bit - wise xor operation .",
    "thus messages in group @xmath300 are encrypted to messages in the same group .",
    "the index @xmath308 identifying the specific message in group @xmath300 , i.e. , the last @xmath296 bits of @xmath299 , are encrypted via bit - wise xor with the key stream . given @xmath309 and the cryptogram ,",
    "decryption is clear  perform bit - wise xor with @xmath309 on the last @xmath310 bits of @xmath43 .",
    "given a cryptogram @xmath43 , the only information that the attacker gleans is that the message belongs to the group determined by @xmath43 . indeed , if @xmath311 , then @xmath312 and therefore @xmath313 which decreases with @xmath299 for @xmath314 , because of our enumeration in the decreasing order of probabilities , and is 0 for @xmath315 .",
    "the attacker s best strategy @xmath316 is therefore to restrict his guesses to @xmath300 and guess in the order @xmath317 .",
    "thus , when @xmath318 , the optimal attack strategy requires @xmath319 guesses .",
    "we now analyze the performance of this attack strategy as follows .",
    "@xmath320 } \\\\",
    "\\nonumber      &   =    & \\sum_{j=0}^{n / m-1 } \\sum_{i=0}^{m-1 } p_n \\ { x^n = j m + i \\ } ( i+1)^{\\rho } \\\\",
    "\\label{eqn : sumprobm }      & \\geq & \\sum_{j=0}^{n / m-1 } \\sum_{i=0}^{m-1 } p_n \\ { x^n = ( j+1)m - 1 \\ } ( i+1)^{\\rho } \\\\",
    "\\label{eqn : sumintbound }      & \\geq & \\sum_{j=0}^{n / m-1 } p_n \\ { x^n = ( j+1)m - 1 \\ } \\frac { m^{1 + \\rho } } { 1+\\rho } \\\\      \\nonumber      & \\geq & \\frac{1}{1+\\rho } \\sum_{j=0}^{n / m-1 } \\sum_{i=0}^{m-1 } p_n \\ { x^n = ( j+1)m + i \\ } m^{\\rho } \\\\      \\label{eqn : sumprobmbound }          & & \\\\",
    "\\label{eqn : g*lowerbound }      & =     & \\frac{1}{1+\\rho } \\sum_{m = m}^{n-1 } p_n \\ { x^n = m \\ } m^{\\rho}\\end{aligned}\\ ] ] where ( [ eqn : sumprobm ] ) follows because the arrangement in the decreasing order of probabilities implies that @xmath321 for @xmath322 . inequality ( [ eqn : sumintbound ] ) follows because @xmath323 inequality ( [ eqn : sumprobmbound ] ) follows because the decreasing probability arrangement implies @xmath324 inequality ( [ eqn : g*lowerbound ] ) follows because we take @xmath325 for all the further dummy messages with indices @xmath326 .",
    "thus ( [ eqn : g*lowerbound ] ) implies that @xmath327 + ( 1 + \\rho ) \\mathbb{e } \\left [ g_{f_n}(x^n|y)^{\\rho }    \\right ] \\\\",
    "\\label{eqn : expectedg*bound }    & = & \\hspace*{-.05 in } ( 2 + \\rho ) \\mathbb{e } \\left [ g_{f_n}(x^n|y)^{\\rho } \\right].\\end{aligned}\\ ] ] let @xmath328 be the guessing function that guesses in the decreasing order of @xmath35-probabilities without regard to @xmath7 , i.e. , @xmath329 . let @xmath330 be the associated length function , given in lemma [ lema : guesslengthrelation ] . now use ( [ eqn : expectedg*bound ] ) and lemma [ lema : guesslengthrelation ] to get @xmath331 } \\nonumber \\\\    & \\geq &    \\frac{1}{2+\\rho } \\mathbb{e } \\left [ \\left ( \\min \\left\\ { g(x^n ) , m \\right\\ } \\right)^{\\rho }    \\right ] \\nonumber \\\\    & \\geq &    \\frac{1}{2+\\rho } \\mathbb{e } \\left [ \\left ( \\min \\left\\ { \\frac{\\exp_2\\{l_{g}(x^n)\\}}{2 c_n } , m \\right\\ } \\right)^{\\rho }    \\right ] \\nonumber \\\\    & \\geq &    \\frac{1}{(2 c_n)^{\\rho } ( 2+\\rho ) } \\mathbb{e } \\left [ \\exp\\left\\{\\rho \\min \\left\\ { l_{g}(x^n ) \\ln 2 , nr \\right\\ } \\right\\ } \\right ] , \\nonumber \\\\    \\label{eqn : eg - lb }    & & \\end{aligned}\\ ] ] where the last inequality follows by pulling out @xmath332 and recognizing that @xmath333 . since @xmath45 is the strategy that minimizes @xmath334 $ ] , the proof is complete for the cases when @xmath296 is an integer .",
    "let @xmath343 .",
    "we then have @xmath344 where ( [ eqn : variational - inequality ] ) follows from the variational formula for rnyi entropy of @xmath345 .",
    "the maximum achieving distribution in ( [ eqn : renyi - formaula ] ) is @xmath346 given by @xmath347 a fact that is easily verified via direct substitution .",
    "we now prove ( [ eqn : liminf - el ] ) ; proof of ( [ eqn : limsup - eu ] ) is similar and therefore omitted .",
    "we begin by showing `` @xmath256 '' in ( [ eqn : liminf - el ] ) .",
    "let @xmath348 be as defined in ( [ eqn : macachiev - sequnce - distribution ] ) .",
    "it is straightforward to verify by direct substitution that @xmath349 normalize by @xmath91 and take limit infimum , and use the definition of @xmath350 to get @xmath351    to prove `` @xmath257 '' in ( [ eqn : liminf - el ] ) , let @xmath352 be an arbitrary sequence .",
    "we may assume that for all sufficiently large @xmath91 , @xmath353 holds ; otherwise @xmath354 and the inequality ",
    "@xmath257 \" holds automatically .",
    "define @xmath355 by @xmath356 it is clear that @xmath357 for every @xmath91 . from lemma",
    "[ lema : variational - lemma ] , we have @xmath358 we now study each term on the right - hand side of ( [ eqn : renyi - expo - lowerbound ] ) .",
    "the entropy term is lower bounded as follows : @xmath359 the divergence term is upper bounded , as in the proof of iriyama s ( * ? ? ?",
    "1 ) , as follows : @xmath360 to get ( [ eqn : log - bound ] ) , we used the fact that @xmath361 for all @xmath362 and in inequality ( [ eqn : set - bound ] ) we used the relation @xmath363 substitution of ( [ eqn : bound - entropy ] ) and ( [ eqn : set - bound ] ) in ( [ eqn : renyi - expo - lowerbound ] ) and the fact that @xmath364 yield @xmath365 since the choice of @xmath366 was arbitrary , we have proved  @xmath257 \" in ( [ eqn : liminf - el ] ) .",
    "iriyama & ihara showed the following lower bound on the infimum coding rate ( ( * ? ? ?",
    "* th.3 , eqn .",
    "( 12 ) ) ) : @xmath368 we claim that ( [ eqn : rhatr - lowerbound ] ) is equivalent to ( [ eqn : ehatr - upperbound ] ) .",
    "this proves the proposition .",
    "we first show that ( [ eqn : rhatr - lowerbound ] ) implies ( [ eqn : ehatr - upperbound ] ) .",
    "fix the source @xmath108 .",
    "let @xmath21 be a given rate .",
    "consider an arbitrary candidate exponent @xmath202 and an arbitrary source @xmath261 .",
    "we argue that @xmath369 taking the infimum on the right - hand side of ( [ eqn : alt - condition - ehatr ] ) over @xmath261 with @xmath370 , and then the supremum over @xmath202 will yield ( [ eqn : ehatr - upperbound ] ) .    to argue ( [ eqn : alt - condition - ehatr ] ) by contraposition",
    ", we shall show that @xmath371 or equivalently , we shall show that @xmath372 but the conditions on the left - hand side imply @xmath373 which together with ( [ eqn : rhatr - lowerbound ] ) yields @xmath374 , and this is the same as saying @xmath21 is not @xmath202-achievable .",
    "this completes the proof of ( [ eqn : rhatr - lowerbound ] ) @xmath375 ( [ eqn : ehatr - upperbound ] ) .",
    "( this direction suffices to prove proposition  [ prop : sup - exponent - error - liminf ] ) .",
    "the proof of the other direction is analogous .    to prove the upper bound in ( [ eqn : ehatr - upperbound - alternative ] ) , we begin with iriyama s ( * ? ? ?",
    "( 13 ) ) , which is @xmath376 instead of ( [ eqn : rhatr - lowerbound ] ) .",
    "the rest of the proof is completely analogous to the proof of proposition [ prop : sup - exponent - error - liminf ] .",
    "we use the following notations in this proof . for",
    "each @xmath377 define @xmath378 and @xmath379 note that @xmath380 .",
    "we will first prove ( [ eqn : correct - rate - expression - liminf ] ) .",
    "define a set @xmath381 then , by definition , @xmath382 fix a @xmath383 .",
    "proposition [ prop : limit - variational - formula ] then implies @xmath384 we can therefore conclude using ( [ eqn : variationalset ] ) that the following set equivalence holds : @xmath385 from ( [ eqn : rate - definition - renyi ] ) and ( [ eqn : set - equivalence ] ) we get @xmath386 where last equality follows because @xmath387 as proved by han & verd @xcite .",
    "this proves ( [ eqn : correct - rate - expression - liminf ] ) .",
    "we now prove ( [ eqn : correct - exponent - expression - liminf ] ) .",
    "we first show that if @xmath21 is @xmath222-admissible then @xmath388 .",
    "+ since @xmath21 is @xmath222-admissible , definition of @xmath389 and ( [ eqn : correct - rate - expression - liminf ] ) imply @xmath390 i.e. , for all @xmath391 there exists a @xmath263 such that @xmath392 which further implies that @xmath393 since @xmath394 was arbitrary , letting @xmath395 yields @xmath396 and the converse part is proved .    for the direct part it is sufficient to show that given @xmath14 , any @xmath21 with @xmath397 is @xmath222-admissible . by choice of @xmath202 , for all @xmath398 ,",
    "there exists a @xmath263 such that @xmath399 this implies that @xmath400 since @xmath394 was arbitrary , let @xmath395 and use ( [ eqn : correct - rate - expression - liminf ] ) to get @xmath401 i.e. , is @xmath222-admissible .",
    "this completes the proof ."
  ],
  "abstract_text": [
    "<S> the shannon cipher system is studied in the context of general sources using a notion of computational secrecy introduced by merhav & arikan . </S>",
    "<S> bounds are derived on limiting exponents of guessing moments for general sources . </S>",
    "<S> the bounds are shown to be tight for iid , markov , and unifilar sources , thus recovering some known results . a close relationship between error exponents and correct decoding exponents for fixed rate source compression on the one hand and exponents for guessing moments on the other hand </S>",
    "<S> is established .    </S>",
    "<S> cipher systems , correct decoding exponent , error exponent , information spectrum , key rate , length function , large deviations , secrecy , sources with memory , fixed - rate source coding </S>"
  ]
}