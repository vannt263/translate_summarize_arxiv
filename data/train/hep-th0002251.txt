{
  "article_text": [
    "most computational work in non - perturbative quantum field theory and many body phenomena rely on one of two general techniques , monte carlo or diagonalization .",
    "these methods are nearly opposite in their strengths and weaknesses .",
    "monte carlo requires relatively little storage , can be performed using parallel processors , and in some cases the computational effort scales reasonably with system size .",
    "but it has great difficulty for systems with sign or phase oscillations and provides only indirect information on wavefunctions and excited states .",
    "in contrast diagonalization methods do not suffer from fermion sign problems , can handle complex - valued actions , and can extract details of the spectrum and eigenstate wavefunctions .",
    "however the main problem with diagonalization is that the required memory and cpu time scales exponentially with the size of the system .    in view of the complementary nature of the two methods",
    ", we consider the combination of both diagonalization and monte carlo within a computational scheme .",
    "we propose a new approach which takes advantage of the strengths of the two computational methods in their respective domains .",
    "the first half of the method involves finding and diagonalizing the hamiltonian restricted to an optimal subspace .",
    "this subspace is designed to include the most important basis vectors of the lowest energy eigenstates .",
    "once the most important basis vectors are found and their interactions treated exactly , monte carlo is used to sample the contribution of the remaining basis vectors .  by this two - step procedure",
    "much of the sign problem is negated by treating the interactions of the most important basis states exactly , while storage and cpu problems are resolved by stochastically sampling the collective effect of the remaining states .    in our approach diagonalization",
    "is used as the starting point of the monte carlo calculation .",
    "therefore the two methods should not only be efficient but work well together .  on the diagonalization side",
    "there are several existing methods using tamm - dancoff truncation @xcite , similarity transformations @xcite , density matrix renormalization group @xcite , or variational algorithms such as stochastic diagonalization @xcite .",
    "however we find that each of these methods is either not sufficiently general , not able to search an infinite or large dimensional hilbert space , not efficient at finding important basis vectors , or not compatible with the subsequent monte carlo part of the calculation .",
    "the monte carlo part of our diagonalization / monte carlo scheme is discussed separately in a companion paper @xcite .  in this paper",
    "we consider the diagonalization part of the scheme .",
    "we introduce a new diagonalization method called quasi - sparse eigenvector ( qse ) diagonalization .",
    "it is a general algorithm which can operate using any basis , either orthogonal or non - orthogonal , and any sparse hamiltonian , either real , complex , hermitian , non - hermitian , finite - dimensional , or infinite - dimensional .",
    "it is able to find the most important basis states of several low energy eigenvectors simultaneously , including those with identical quantum numbers , from a random start with no prior knowledge about the form of the eigenvectors .",
    "our discussion is organized as follows .",
    "we first define the notion of quasi - sparsity in eigenvectors and introduce the quasi - sparse eigenvector method .",
    "we discuss when the low energy eigenvectors are likely to be quasi - sparse and make an analogy with anderson localization .",
    "we then consider three examples which test the performance of the algorithm .  in the first example we find the lowest energy eigenstates for a random sparse real symmetric matrix .  in the second example we find",
    "the lowest eigenstates sorted according to the real part of the eigenvalue for a random sparse complex non - hermitian matrix .  in the last example we consider the case of an infinite - dimensional hamiltonian defined by @xmath0 dimensional @xmath1 theory in a periodic box .",
    "we conclude with a summary and some comments on the role of quasi - sparse eigenvector diagonalization within the context of the new diagonalization / monte carlo approach .",
    "let @xmath2 denote a complete set of basis vectors .  for a given energy eigenstate @xmath3 we define the important basis states of @xmath4 to be those @xmath5 such that for fixed normalizations of @xmath4 and the basis states",
    ", @xmath6 exceeds a prescribed threshold value .",
    "if @xmath4 can be well - approximated by the contribution from only its important basis states we refer to the eigenvector @xmath4 as _ quasi - sparse _ with respect to @xmath2 .",
    "standard sparse matrix algorithms such as the lanczos or arnoldi methods allow one to find the extreme eigenvalues and eigenvectors of a sparse matrix efficiently , without having to store or manipulate large non - sparse matrices .  however in quantum field theory or many body theory one considers very large or infinite dimensional spaces where even storing the components of a general vector is impossible .  for these more difficult problems",
    "the strategy is to approximate the low energy eigenvectors of the large space by diagonalizing smaller subspaces .",
    "if one has sufficient intuition about the low energy eigenstates it may be possible to find a useful truncation of the full vector space to an appropriate smaller subspace .  in most cases , however , not enough is known _ a priori _ about the low energy eigenvectors .",
    "the dilemma is that to find the low energy eigenstates one must truncate the vector space , but in order to truncate the space something must be known about the low energy states .",
    "our solution to this puzzle is to find the low energy eigenstates and the appropriate subspace truncation at the same time by a recursive process .",
    "we call the method quasi - sparse eigenvector ( qse ) diagonalization , and we describe the steps of the algorithm as follows .",
    "the starting point is any complete basis for which the hamiltonian matrix @xmath7 is sparse .  the basis vectors may be non - orthogonal and/or the hamiltonian matrix may be non - hermitian .",
    "the following steps are now iterated :    1 .",
    "select a subset of basis vectors @xmath8 and call the corresponding subspace @xmath9 .",
    "diagonalize @xmath10 restricted to @xmath9 and find one eigenvector @xmath11 .",
    "sort the basis components of @xmath11 according to their magnitude and remove the least important basis vectors .",
    "4 .   replace the discarded basis vectors by new basis vectors .",
    "these are selected at random according to some weighting function from a pool of candidate basis vectors which are connected to the old basis vectors through non - vanishing matrix elements of @xmath10 .",
    "redefine @xmath9 as the subspace spanned by the updated set of basis vectors and repeat steps 2 through 5 .",
    "if the subset of basis vectors is sufficiently large , the exact low energy eigenvectors will be stable fixed points of the qse update process .",
    "we can show this as follows .",
    "let @xmath12 be the eigenvectors of the submatrix of @xmath10 restricted to the subspace @xmath9 , where @xmath9 is the span of the subset of basis vectors after step 3 of the qse algorithm .",
    "let @xmath13 be the remaining basis vectors in the full space not contained in @xmath9 .",
    "we can represent @xmath10 as @xmath14{cccccc}% \\lambda_{1 } & 0 & \\cdots & \\left\\langle 1\\right|   h\\left|   a_{1}\\right\\rangle & \\left\\langle 1\\right|   h\\left|   a_{2}\\right\\rangle   & \\cdots\\\\ 0 & \\lambda_{2 } & \\cdots & \\left\\langle 2\\right|   h\\left|   a_{1}\\right\\rangle & \\left\\langle 2\\right|   h\\left|   a_{2}\\right\\rangle   & \\cdots\\\\ \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\cdots\\\\ \\left\\langle a_{1}\\right|   h\\left|   1\\right\\rangle   & \\left\\langle a_{1}\\right|   h\\left|   2\\right\\rangle   & \\cdots &   e\\cdot\\lambda_{a_{1 } } & \\left\\langle a_{1}\\right|   h\\left|   a_{2}\\right\\rangle   & \\cdots\\\\ \\left\\langle a_{2}\\right|   h\\left|   1\\right\\rangle   & \\left\\langle a_{2}\\right|   h\\left|   2\\right\\rangle   & \\cdots & \\left\\langle a_{2}\\right| h\\left|   a_{1}\\right\\rangle   & e\\cdot\\lambda_{a_{2 } } & \\cdots\\\\ \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots \\end{array } \\right ]   .",
    "\\label{matrix}%\\ ] ] we have used dirac s bra - ket notation to represent the terms of the hamiltonian matrix .  in cases where the basis is non - orthogonal and/or the hamiltonian is non - hermitian , the meaning of this notation may not be clear .  when writing @xmath15 , for example , we mean the result of the dual vector to @xmath16 acting upon the vector @xmath17 .  in ( [ matrix ] )",
    "we have written the diagonal terms for the basis vectors @xmath18 with an explicit factor @xmath19 .",
    "we let @xmath20 be the approximate eigenvector of interest and have shifted the diagonal entries so that @xmath21  our starting hypothesis is that @xmath22 is close to some exact eigenvector of @xmath10 which we denote as @xmath23 .",
    "more precisely we assume that the components of @xmath23 outside @xmath9 are small enough so that we can expand in inverse powers of the introduced parameter @xmath24    we now expand the eigenvector as @xmath25{c}% 1\\\\ c_{2}^{\\prime}e^{-1}+\\cdots\\\\ \\vdots\\\\ c_{a_{1}}^{\\prime}e^{-1}+\\cdots\\\\ c_{a_{2}}^{\\prime}e^{-1}+\\cdots\\\\ \\vdots \\end{array } \\right ]   \\label{eigvec}%\\ ] ] and the corresponding eigenvalue as @xmath26 in ( [ eigvec ] ) we have chosen the normalization of @xmath27 such that @xmath28 .  from the eigenvalue equation @xmath29 we find at lowest order @xmath30 we see that at lowest order the component of @xmath27 in the @xmath31 direction is independent of the other vectors @xmath32 .",
    "if @xmath22 is sufficiently close to @xmath27 then the limitation that only a fixed number of new basis vectors is added in step 4 of the qse algorithm is not relevant .",
    "at lowest order in @xmath33 the comparison of basis components in step 3 ( in the next iteration ) is the same as if we had included all remaining vectors @xmath13 at once .",
    "therefore at each update only the truly largest components are kept and the algorithm converges to some optimal approximation of @xmath23 .",
    "this is consistent with the actual performance of the algorithm as we will see in some examples later .  in those examples",
    "we also demonstrate that the qse algorithm is able to find several low energy eigenvectors simultaneously .",
    "the only change is that when diagonalizing the subspace @xmath9 we find more than one eigenvector and apply steps 3 and 4 of the algorithm to each of the eigenvectors .",
    "as the name indicates the accuracy of the quasi - sparse eigenvector method depends on the quasi - sparsity of the low energy eigenstates in the chosen basis .",
    "if the eigenvectors are quasi - sparse then the qse method provides an efficient way to find the important basis vectors .  in the context of our diagonalization / monte carlo approach ,",
    "this means that diagonalization does most of the work and only a small amount of correction is needed .",
    "this correction is found by monte carlo sampling the remaining basis vectors , a technique called stochastic error correction @xcite .  if however the eigenvectors are not quasi - sparse then one must rely more heavily on the monte carlo portion of the calculation .    the fastest and most reliable way",
    "we know to determine whether the low energy eigenstates of a hamiltonian are quasi - sparse with respect to a chosen basis is to use the qse algorithm and look at the results of the successive iterations .",
    "but it is also useful to consider the question more intuitively , and so we consider the following example",
    ".    let @xmath10 be a sparse hermitian @xmath34 matrix defined by @xmath35 where @xmath36 and @xmath37 run from @xmath38 to @xmath39 , @xmath40 is a gaussian random real variable centered at zero with standard deviation @xmath41 , and  @xmath42 is a sparse symmetric matrix consisting of random @xmath43 s and @xmath38 s such that the density of @xmath38 s is @xmath44 .",
    "the reason for introducing the @xmath45 term in the diagonal is to produce a large variation in the density of states . with this choice the density of states increases exponentially with energy .",
    "our test matrix is small enough that all eigenvectors can be found without difficulty .",
    "we will consider the distribution of basis components for the eigenvectors of @xmath10 .  in figure 1",
    "we show the square of the basis components for a given low energy eigenvector @xmath46  the basis components are sorted in order of descending importance .",
    "the ratio of @xmath47 , the average spacing between neighboring energy levels , to @xmath48 is @xmath49 .",
    "we see that the eigenvector is dominated by a few of its most important basis components .  in figure 2",
    "we show the same plot for another eigenstate but one where the spacing between levels is three times smaller , @xmath50  this eigenvector is not nearly as quasi - sparse .",
    "the effect is even stronger in figure 3 , where we show an eigenvector such that the spacing between levels is @xmath51 .",
    "our observations show a strong effect of the density of states on the quasi - sparsity of the eigenvectors .",
    "states with a smaller spacing between neighboring levels tend to have basis components that extend throughout the entire space , while states with a larger spacing tend to be quasi - sparse .",
    "the relationship between extended versus localized eigenstates and the density of states has been studied in the context of anderson localization and metal - insulator transitions @xcite .",
    "the simplest example is the tight - binding model for a single electron on a one - dimensional lattice with @xmath52 sites , @xmath53 @xmath54 denotes the atomic orbital state at site @xmath55 @xmath56 is the on - site potential , and @xmath57 is the hopping term between nearest neighbor sites @xmath36 and @xmath58",
    ".  if both terms are uniform ( @xmath59 @xmath60 ) then the eigenvalues and eigenvectors of @xmath10 are @xmath61 where @xmath62 labels the eigenvectors .  in the absence of diagonal and off - diagonal disorder ,",
    "the eigenstates of @xmath10 extend throughout the entire lattice .",
    "the eigenvalues are also approximately degenerate , all lying within an interval of size 4@xmath63 .",
    "however , if diagonal and/or off - diagonal disorder is introduced , the eigenvalue spectrum becomes less degenerate .",
    "if the disorder is sufficiently large , the eigenstates become localized to only a few neighboring lattice sites giving rise to a transition of the material from metal to insulator .",
    "we can regard a sparse quantum hamiltonian as a similar type of system , one with both diagonal and general off - diagonal disorder .",
    "if the disorder is sufficient such that the eigenvalues become non - degenerate , then the eigenvectors will be quasi - sparse .",
    "we reiterate that the most reliable way to determine if the low energy states are quasi - sparse is to use the qse algorithm .",
    "intuitively , though , we expect the eigenstates to be quasi - sparse with respect to a chosen basis if the spacing between energy levels is not too small compared with the size of the off - diagonal entries of the hamiltonian matrix .",
    "as a first test of the qse method , we will find the lowest four energy states of the random symmetric matrix @xmath10 defined in ( [ sym ] ) .  so that there is no misunderstanding , we should repeat that diagonalizing a @xmath34 matrix is not difficult .",
    "the purpose of this test is to analyze the performance of the method in a controlled environment .",
    "one interesting twist is that the algorithm uses only small pieces of the matrix and operates under the assumption that the space may be infinite dimensional .",
    "a sample matlab program similar to the one used here has been printed out as a tutorial example in @xcite .",
    "the program starts from a random configuration , 70 basis states for each of the four eigenvectors .  with each iteration",
    "we select @xmath64 replacement basis states for each of the eigenvectors .  in figure 4",
    "we show the exact energies and the results of the qse  method as functions of iteration number .  in figure 5",
    "we show the inner products of the normalized qse eigenvectors with the normalized exact eigenvectors .",
    "we note that all of the eigenvectors were found after about 15 iterations and remained stable throughout successive iterations .",
    "errors are at the @xmath65 to @xmath66 level , which is about the theoretical limit one can achieve using this number of basis states .",
    "the qse method has little difficulty finding several low lying eigenvectors simultaneously because it uses the distribution of basis components for each of the eigenvectors to determine the update process .",
    "this provides a performance advantage over variational - based techniques such as stochastic diagonalization in finding eigenstates other than the ground state .     as a second test",
    "we consider a sparse non - hermitian matrix with complex eigenvalues .",
    "this type of matrix is not amenable to variational - based methods .",
    "we will find the four eigenstates corresponding with eigenvalues with the lowest real part for the random complex non - hermitian matrix @xmath67 @xmath68 is the same matrix used previously and@xmath69 is a uniform random variable distributed between @xmath70 and 1 .",
    "as before the program is started from a random configuration , 70 basis states for each of the four eigenvectors .  for each iteration @xmath64",
    "replacement basis vectors are selected for each of the eigenvectors .  in figure 6",
    "the exact eigenvalues and the results of the qse run are shown in the complex plane as functions of iteration number .  in figure 7",
    "we show the inner products of the qse eigenvectors with the exact eigenvectors .",
    "all of the eigenvectors were found after about 20 iterations and remained stable throughout successive iterations .",
    "errors were again at about the @xmath65 to @xmath66 level .",
    "we now apply the qse method to an infinite dimensional quantum hamiltonian .",
    "we consider @xmath1 theory in @xmath0 dimensions , a system that is familiar to us from previous studies using monte carlo @xcite and explicit diagonalization @xcite .",
    "the hamiltonian density for @xmath1 theory in @xmath0 dimensions has the form @xmath71 where the normal ordering is with respect to the mass @xmath72 .",
    "we consider the system in a periodic box of length @xmath73 .",
    "we then expand in momentum modes and reinterpret  the problem as an equivalent schrdinger equation @xcite .",
    "the resulting hamiltonian is @xmath74 where @xmath75 and @xmath76 is the coefficient for the mass counterterm @xmath77    it is convenient to split the hamiltonian into free and interacting parts with respect to an arbitrary mass @xmath78 : @xmath79@xmath80 @xmath78 is used to define the basis states of our fock space .  since @xmath10 is independent of @xmath78 , we perform calculations for different @xmath78 to obtain a reasonable estimate of the error .",
    "it is also useful to find the range of values for @xmath78 which maximizes the quasi - sparsity of the eigenvectors and therefore improves the accuracy of the calculation .  for the calculations presented here , we set the length of the box to size @xmath81 .",
    "we restrict our attention to momentum modes @xmath82 such that @xmath83 , where @xmath84 .",
    "this corresponds with a momentum cutoff scale of @xmath85    to implement the qse algorithm on this infinite dimensional hilbert space , we first define ladder operators with respect to @xmath78 , @xmath86 \\\\ a_{n}^{\\dagger}(\\mu^{\\prime } )   &   = \\tfrac{1}{\\sqrt{2\\omega_{n}(\\mu^{\\prime})}% } \\left [   q_{-n}\\omega_{n}(\\mu^{\\prime})-\\tfrac{\\partial}{\\partial q_{n}% } \\right ]   .\\end{aligned}\\ ] ] the hamiltonian can now be rewritten as @xmath87   .\\nonumber\\end{aligned}\\ ] ] in ( [ ha ] ) we have omitted constants contributing only to the vacuum energy .",
    "we represent any momentum - space fock state as a string of occupation numbers , @xmath88 , where @xmath89 from the usual ladder operator relations , it is straightforward to calculate the matrix element of @xmath10 between two arbitrary fock states .    aside from calculating matrix elements ,",
    "the only other fundamental operation needed for the qse algorithm is the generation of new basis vectors .",
    "the new states should be connected to some old basis vector through non - vanishing matrix elements of @xmath10 .",
    "let us refer to the old basis vector as @xmath90 .",
    "for this example there are two types of terms in our interaction hamiltonian , a quartic interaction @xmath91 and a quadratic interaction @xmath92 to produce a new vector from @xmath93 we simply choose one of the possible operator monomials @xmath94 and act on @xmath93 .",
    "our experience is that the interactions involving the small momentum modes are generally more important than those for the large momentum modes , a signal that the ultraviolet divergences have been properly renormalized .",
    "for this reason it is best to arrange the selection probabilities such that the smaller values of @xmath95 , @xmath96 , @xmath97 and @xmath98 are chosen more often .    for each qse iteration , @xmath99 new basis vectors were selected for each eigenstate and @xmath100 basis vectors were retained .",
    "the results for the lowest energy eigenvalues are shown in figure 8 .",
    "the error bars were estimated by repeating the calculation for different values of the auxiliary mass parameter @xmath78 .    from prior monte carlo calculations",
    "we know that the theory has a phase transition at @xmath101 corresponding with spontaneous breaking of the @xmath102 reflection symmetry .",
    "in the broken phase there are two degenerate ground states and we refer to these as the even and odd vacuum states .  in figure 8",
    "we see signs of a second order phase transition near @xmath101 .",
    "since we are working in a finite volume the spectrum is discrete , and we can track the energy eigenvalues as functions of the coupling .  crossing the phase boundary , we see that the vacuum in the symmetric phase becomes the even vacuum in the broken phase while the one - particle state in the symmetric phase becomes the odd vacuum .",
    "the energy difference between the states is also in agreement with a monte carlo calculation of the same quantities .",
    "the state marking the two - particle threshold in the symmetric phase becomes the one - particle state above the odd vacuum , while the state at the three - particle threshold becomes the one - particle state above the even vacuum .",
    "these one - particle states should be degenerate in the infinite volume limit .",
    "one rather unusual feature is the behavior of the first two - particle state above threshold in the symmetric phase .  in the symmetric phase this state lies close to the two - particle threshold .",
    "but as we cross the phase boundary the state which was the two - particle threshold is changed into a one - particle state .",
    "thus our two - particle state is pushed up even further to become a two - particle state above the even vacuum and we see a pronounced level crossing .",
    "we note that while the one - particle mass vanishes near the critical point , the energies of the two - particle and three - particle thresholds reach a minimum but do not come as close to zero energy .",
    "it is known that this model is repulsive in the two - particle scattering channel .  in a large but finite volume",
    "the ground state and one - particle states do not feel significant finite volume effects .",
    "the two - particle state at threshold , however , requires that the two asymptotic particles be widely separated .  in our periodic box of length 2@xmath103",
    "the maximal separation distance is @xmath103 and we expect an increase in energy with respect to twice the one - particle mass of size @xmath104 , where @xmath105 is the potential energy between particles .",
    "likewise a three - particle state will increase in energy an amount @xmath106 .",
    "our results indicate that finite volume effects for the excited states are significant for this value of @xmath103 .",
    "we have proposed a new approach which combines both diagonalization and monte carlo within a computational scheme .",
    "the motivation for our approach is to take advantage of the strengths of the two computational methods in their respective domains .",
    "we remedy sign and phase oscillation problems by handling the interactions of the most important basis states exactly using diagonalization , and we deal with storage and cpu problems by stochastically sampling the contribution of the remaining states .",
    "we discussed the diagonalization part of the method in this paper .",
    "the goal of diagonalization within our scheme is to find the most important basis vectors of the low energy eigenstates and treat the interactions among them exactly .",
    "we have introduced a new diagonalization method called quasi - sparse eigenvector diagonalization which achieves this goal efficiently and can operate using any basis , either orthogonal or non - orthogonal , and any sparse hamiltonian , either real , complex , hermitian , non - hermitian , finite - dimensional , or infinite - dimensional .",
    "quasi - sparse eigenvector diagonalization is the only method we know which can address all of these problems .",
    "we considered three examples which tested the performance of the algorithm .",
    "we found the lowest energy eigenstates for a random sparse real symmetric matrix , the lowest eigenstates ( sorted according to the real part of the eigenvalue ) for a random sparse complex non - hermitian matrix , and the lowest energy eigenstates for an infinite - dimensional hamiltonian defined by @xmath0 dimensional @xmath1 theory in a periodic box .",
    "we regard qse diagonalization as only a starting point for the monte carlo part of the calculation .  once the most important basis vectors are found and their interactions treated exactly , a technique called stochastic error correction is used to sample the contribution of the remaining basis vectors .",
    "this method is introduced in @xcite .",
    "p. biswas , p. cain , r. rmer , m. schreiber , cond - mat/0001315 ; c. soukoulis , i. weman , g. grest , e. economou , phys .",
    "b26 ( 1982 ) 1838 ; t. ziman , phys .",
    "b26 ( 1982 ) 7066 ; m. inui , s. trugman , e. abrahams , phys .",
    "b49 ( 1994 ) 3190 ."
  ],
  "abstract_text": [
    "<S> we introduce a new diagonalization method called quasi - sparse eigenvector diagonalization which finds the most important basis vectors of the low energy eigenstates of a quantum hamiltonian .  </S>",
    "<S> it can operate using any basis , either orthogonal or non - orthogonal , and any sparse hamiltonian , either hermitian , non - hermitian , finite - dimensional , or infinite - dimensional .  </S>",
    "<S> the method is part of a new computational approach which combines both diagonalization and monte carlo techniques . </S>"
  ]
}