{
  "article_text": [
    "spectrum estimation from a finite set of noisy measurements is a classical problem with wide applications in communications , astronomy , seismology , radar , sonar signal processing , etc . @xcite , @xcite .",
    "existing spectrum estimation techniques can be categorized as low - resolution and high - resolution methods .",
    "low - resolution techniques such as the periodogram and correlogram methods are based on estimating the autocorrelation function of a signal .",
    "high - resolution techniques such as the multiple signal classification ( music ) method @xcite and the estimation of signal parameters via rotational invariance techniques ( esprit ) @xcite are based on modeling and parameterizing a signal .    in practice , the rate at which the measurements are collected can be restricted .",
    "therefore , it is desirable to make spectrum estimation from measurements obtained at a rate lower than the nyquist rate . in @xcite and @xcite , authors have shown that for signals with sparse fourier representations , the fourier coefficients can be estimated using a subset of the _ nyquist samples _ ( samples obtained at the nyquist rate ) .",
    "the existing low- and high - resolution spectrum estimation techniques can be generalized for the case that the measurements are obtained at a rate lower than the nyquist rate @xcite , @xcite .",
    "similar to the conventional spectrum estimation techniques , the low- and high - resolution methods working on undersampled data use the autocorrelation function and the model of the signal , respectively .    in @xcite ,",
    "authors have considered power spectral density ( psd ) estimation based on the autocorrelation matrices of the data .",
    "we refer to this method as the correlogram for undersampled data , as it is able to reconstruct the spectrum from a subset of the nyquist samples . in this method ,",
    "samples are collected using multiple channels , each operating at a rate @xmath0 times lower than the nyquist rate .",
    "the algorithm partitions the spectrum into @xmath0 segments , and it estimates the average power within each segment .",
    "we will later show that increasing the value of @xmath0 reduces the quality of the estimation .",
    "therefore , the parameter @xmath0 can not be chosen arbitrarily large , which indicates that this method lies in the category of low - resolution spectrum estimation techniques .",
    "high - resolution spectrum estimation techniques for undersampled data can be obtained by considering the signal model . in @xcite ,",
    "two model - based methods have been introduced for recovering sparse signals from _",
    "compressive measurements_. these measurements are obtained by correlating the signal with a set of sensing waveforms .",
    "this is the basic sampling technique in _ compressive sensing _ ( cs ) @xcite , @xcite , where signals with sparse representations are recovered from a number of measurements that is much less than the number of the nyquist samples . in @xcite , authors consider signals composed of linear combinations of sinusoids .",
    "this type of signals appear frequently in signal processing and digital communications @xcite , @xcite . albeit these signals generate sparse coefficients by the discrete - time fourier transform ( dtft ) , their representation in the fourier basis obtained by the discrete fourier transform ( dft ) exhibits frequency leakage .",
    "this problem results in the poor performance of the conventional cs recovery algorithms that rely on the fourier basis ( see @xcite ) .",
    "although these signals do not have a sparse representation in the fourier basis , they possess a sparse model in terms of the dtft . in @xcite , the advantages of taking a signal model into account for signal reconstruction have been demonstrated and the name _ model - based cs _ has been coined . in @xcite , the model - based cs method has been modified for spectral estimation . according to the model - based method , the signal is reconstructed in an iterative manner , where at each iteration",
    ", a signal estimate is formed and pruned according to the model .",
    "the contributions of this paper are presented in two parts . in the first part ,",
    "the correlogram for undersampled data is analyzed , and in the second part , an improved model - based spectrum estimation algorithm for spectral compressive sensing is introduced .",
    "we have reported a summary of the results in @xcite and @xcite .",
    "here , we provide in - depth derivations and present new simulation results .",
    "first , we study the correlogram for undersampled data .",
    "we compute the bias of the estimator and show that the estimation is unbiased for any signal length .",
    "moreover , the covariance matrix of the estimator is derived , and it is proved that the estimation variance tends to zero asymptotically . therefore , the correlogram for undersampled data is a consistent estimator . using our derivations",
    ", we show that for finite - length signals , there exists a tradeoff between the estimation accuracy and the frequency resolution of the estimator .",
    "specifically , higher resolution reduces the accuracy of the estimation .    in the second part of the paper",
    ", we introduce a new cs recovery method .",
    "the important difference of our method from that of @xcite is the approach used for estimating the amplitudes of the signal elements . in @xcite",
    ", the unknown amplitudes are estimated using the dtft , while we estimate the amplitudes by minimizing the squared norm of the compressed estimation error .",
    "furthermore , we analyze the proposed method , derive the cramer - rao bound ( crb ) for spectral compressive sensing , and show that the proposed algorithm approaches the crb .",
    "the rest of the paper is organized as follows .",
    "the correlogram for undersampled data is reviewed and revised in section [ sec : undr_corr ] .",
    "in section [ sec : bias_var ] , the bias and the variance of the correlogram for undersampled data estimator are derived .",
    "the model - based nested least squares method is introduced in section [ sec : nested_ls ] , and the cramer - rao bound for spectral compressive sensing is derived in section [ sec : crb ] .",
    "section [ sec : examples_sim ] presents some numerical examples on the estimation variance of the correlogram method for finite - length signals as well as simulation results for the model - based nested least squares algorithm .",
    "finally , section [ sec : conclude ] concludes the paper .",
    "this paper is reproducible research @xcite and the software needed to generate the simulation results will be provided to the ieee xplore together with the paper upon its acceptance .",
    "consider a wide - sense stationary ( wss ) stochastic process @xmath1 bandlimited to @xmath2 with power spectral density ( psd ) @xmath3 .",
    "let @xmath1 be sampled using the multi - coset ( mc ) sampler as described in @xcite .",
    "samples are collected by a multi - channel system .",
    "the @xmath4-th channel ( @xmath5 ) samples @xmath1 at the time instants @xmath6 for @xmath7 , where @xmath8 is the number of samples obtained from each channel , @xmath9 is the nyquist period ( @xmath10 ) , @xmath0 is a suitable integer , and @xmath11 is the number of sampling channels .",
    "the time offsets @xmath12 ( @xmath13 ) are distinct random positive integer numbers less than @xmath0 .",
    "let the output of the @xmath4-th channel be denoted by @xmath14 .",
    "the @xmath4-th channel can be easily implemented by a system that shifts @xmath1 by @xmath15 seconds and then samples uniformly at a rate of @xmath16 hz . the samples obtained in this manner form a subset of the nyquist samples .",
    "the average sampling rate is @xmath17 hz , and it is less than the nyquist rate since @xmath11 .    given the mc samples , the psd of the signal can be estimated by transforming the output sequences @xmath14 into a system of frequency domain equations .",
    "let @xmath18 and @xmath19 denote the fourier transform of @xmath20 and @xmath1 , respectively .",
    "then , the following relationship holds @xcite @xmath21 here @xmath22 and its @xmath23-th element is given as @xmath24_{i , l}=\\frac{w}{l}e^{-j\\frac{2\\pi}{l}c_im_l}$ ] where @xmath0 is an odd number and @xmath25 .",
    "the vector @xmath26^{t } \\in \\mathbb{c}^{q \\times 1}$ ] contains the elements @xmath27 and the vector @xmath28^{t } \\in \\mathbb{c}^{l \\times 1}$ ] contains the elements @xmath29 where @xmath30 stands for the transposition operator and @xmath31 represents the indicator function .",
    "let @xmath32 and @xmath33 be the autocorrelation matrices of @xmath34 and @xmath35 , respectively .",
    "then , it can be found that @xmath36 \\boldsymbol{\\gamma}^h \\nonumber \\\\",
    "\\hspace{-2 mm } & = & \\hspace{-2 mm } \\boldsymbol{\\gamma } \\boldsymbol{r}_{\\boldsymbol{s } } \\boldsymbol{\\gamma}^h \\label{eq : base_cov}\\end{aligned}\\ ] ] where @xmath37 and @xmath38 stand for the hermitian transposition and the expectation operators , respectively .",
    "consider partitioning the bandwidth of @xmath1 into @xmath0 equal segments .",
    "it is shown in @xcite that the diagonal elements of @xmath39 represent the average power within such spectral segments , and the off - diagonal elements are zeros .",
    "thus , the @xmath40-th element of @xmath41 in can be rewritten as @xmath42_{a , b } \\hspace{-2 mm } & = & \\hspace{-2 mm } \\sum_{l=1}^l[\\boldsymbol{\\gamma}]_{a , l } [ \\boldsymbol{\\gamma}]_{b , l}^ * [ \\boldsymbol{r}_{\\boldsymbol{s}}]_{l , l } \\nonumber\\\\ \\hspace{-2 mm } & = & \\hspace{-2 mm } \\left(\\frac{w}{l } \\right)^2 \\sum_{l=1}^le^{-j\\frac{2\\pi}{l } ( c_a - c_b)m_l } [ \\boldsymbol{r}_{\\boldsymbol{s}}]_{l , l}. \\label{eq : base_cov_elmnt}\\end{aligned}\\ ] ] the @xmath43-th diagonal element of @xmath39 , i.e. , @xmath44_{l , l}$ ] , corresponds to the average power within the spectral segment @xmath45 .",
    "note that @xmath41 is a hermitian matrix with equal diagonal elements .",
    "then , it is sufficient to let the indices @xmath46 and @xmath47 just refer to the elements of the upper triangle and the first diagonal element of @xmath41 . therefore , there are @xmath48 equations of type ( @xmath49 ) . in matrix - vector form",
    ", can be rewritten as @xmath50 where @xmath51^{t } \\hspace{-1mm}\\in \\hspace{-1 mm } \\mathbb{r}^{l\\times 1}$ ] consists of the diagonal elements of @xmath39 , @xmath52^{t } \\in   \\mathbb{c}^{q\\times 1}$ ] with @xmath53_{1,1}$ ] and @xmath54 corresponding to the elements of the upper triangle of @xmath41 , and @xmath55 with elements given by @xmath56_{k , l}=(w / l)^2e^{-j\\frac{2\\pi}{l}(c_a - c_b)m_l}.\\ ] ]    since the elements of @xmath57 are real - valued , the number of equations in can be doubled by solving @xmath58 , where @xmath59^{t } \\in \\mathbb{r}^{2q\\times 1}$ ] and @xmath60^{t } \\in \\mathbb{r}^{2q\\times l}$ ] .",
    "suppose @xmath61 is full rank and @xmath62 .",
    "then , @xmath57 can be determined using the pseudoinverse of @xmath61 as @xmath63 the elements of @xmath64 are comprised of the elements of @xmath41 .",
    "the autocorrelation matrix @xmath41 is not known and has to be estimated .",
    "the estimation of @xmath41 can be found from a finite number of samples as @xmath65_{a , b}=2\\pi\\frac{w}{nl } \\sum_{n=0}^{n-1}y_a\\left(n-\\frac{c_a}{l}\\right)y_b^*\\left ( n-\\frac{c_b}{l}\\right)\\label{eq : est_rz}\\ ] ] where @xmath66 denotes the conjugate of a complex number .",
    "the fractional delays @xmath67 and @xmath68 can be implemented by fractional delay filters such as the lagrange interpolator which is a finite impulse response ( fir ) filter @xcite .",
    "fir fractional delay filters perform the best when the total delay is approximately equal to half of the order of the filter @xcite .",
    "the fractional delays @xmath67 and @xmath68 are positive numbers less than one , and the performance of the fir fractional delay filters is very poor with such delays . to remedy this problem ,",
    "a suitable integer delay can be added to the fractional part . referring to the definition of @xmath41 in and noting that @xmath69 we can rewrite as @xmath70_{a , b}=\\nonumber\\\\ & & \\hspace{-7.5 mm } 2\\pi\\frac{w}{nl}\\sum_{n=0}^{n-1}y_a\\left(n-\\left(\\frac{c_a}{l}+d\\right ) \\right)y_b^*\\left(n-\\left(\\frac{c_b}{l}+d\\right)\\right)\\label{eq : est_rz_d}\\end{aligned}\\ ] ] where @xmath71 is a suitable integer number .",
    "let @xmath72 be the impulse response of a causal filter that delays a signal for @xmath73 steps .",
    "the output of the filter can be written as @xmath74 where @xmath75 is the length of the filter s impulse response . using the elements of @xmath76 ,",
    "the vector @xmath77 is formed as an estimation for @xmath64 .",
    "next , @xmath78 ( the estimation for @xmath57 ) is formed by replacing @xmath64 with @xmath77 in as @xmath79 the elements of @xmath78 represent an estimation for the average power within each spectral segment .",
    "let @xmath1 be a zero - mean white gaussian random process with psd @xmath80 .",
    "the estimation bias can be found by computing the expected value of @xmath78 . from we",
    "have @xmath81 in order to determine @xmath82 , it is required to find the expected value of the real and imaginary parts of @xmath76 .",
    "the expectation operation can be performed before taking the real or imaginary parts of @xmath76 , as these operators are linear .",
    "moreover , is used to form @xmath76 .",
    "taking expectation from both sides of along with using results in @xmath83_{a , b}\\}\\hspace{-2mm}&=&\\hspace{-2mm}2\\pi\\frac{w}{nl}\\sum_{n=0}^{n-1}e\\{y_a^d(n)y_b^{d*}(n))\\}\\nonumber\\\\ \\hspace{-2mm}&=&\\hspace{-2mm}2\\pi\\frac{w}{nl}\\sum_{n=0}^{n-1}\\sum_{\\underset{\\scriptstyle ( 0,n - n_h+1)}{r=\\textnormal{max}}}^n\\sum_{\\underset{\\scriptstyle ( 0,n - n_h+1)}{p=\\textnormal{max}}}^n\\nonumber\\\\ & & \\quad h_a(n - r)h_b(n - p)e\\{y_a(r)y_b^*(p)\\}.\\label{eq : erz1}\\end{aligned}\\ ] ] the problem is now reduced to finding @xmath84 , which is obtained as @xmath85 for @xmath86 ( or @xmath87 ) , and it equals zero otherwise .",
    "this results from the fact that @xmath1 is a white process with psd @xmath80 . applying to ,",
    "we find that @xmath88_{a , b}\\}=0\\label{eq : erz2}\\ ] ] for @xmath89 , and @xmath90_{a , b}\\}\\hspace{-2mm}&=&\\hspace{-2mm}2\\pi\\frac{w}{nl}\\sum_{n=0}^{n-1}\\sum_{\\underset{\\scriptstyle ( 0,n - n_h+1)}{r=\\textnormal{max}}}^n h_a^2(n - r)\\sigma^2\\nonumber\\\\ \\hspace{-2mm}&=&\\hspace{-2mm}2\\pi\\frac{w}{l}h_a\\sigma^2\\label{eq : erz3}\\end{aligned}\\ ] ] for @xmath91 , where @xmath92 recalling that the first diagonal element of @xmath76 is used in @xmath77 and taking the real and imaginary parts of and , @xmath82 can be obtained as @xmath93 where @xmath94 is a column vector of length @xmath95 with all its elements equal to zero except for the first element which is @xmath96 .",
    "the expected value of @xmath78 can be found using and as @xmath97    we analyze next the asymptotic behavior of the correlogram for undersampled data .",
    "first , note that @xmath76 is an asymptotically unbiased estimator of @xmath41 . to show this , it is enough to take expectation of both sides of while letting the number of samples tend to infinity .",
    "this directly leads to @xmath41 without requiring any more computation .",
    "since @xmath77 consists of the elements of @xmath76 and the operation of taking the real and imaginary parts are linear , it follows that @xmath77 is also an asymptotically unbiased estimator of @xmath64 .",
    "furthermore , letting the number of samples tend to infinity in and using , we find that @xmath98 in other words , @xmath78 is also an asymptotically unbiased estimator of @xmath57 .",
    "consider the fact that @xmath1 has equal power in all spectral segments ( the elements of @xmath57 are all the same ) .",
    "since @xmath78 is asymptotically unbiased , it follows that the elements of @xmath99 are also equal .    replacing the true values in with the estimated values for @xmath100 ,",
    "taking expectation from both sides , and letting the number of samples tend to infinity , we obtain that @xmath101_{1,1}\\}\\hspace{-2mm}&=&\\hspace{-2mm}\\left(\\frac{w}{l}\\right)^2\\sum_{l=1}^l\\lim_{n\\rightarrow\\infty}e\\{\\hat{v}_l\\}\\nonumber\\\\ \\hspace{-2mm}&=&\\hspace{-2mm}\\left(\\frac{w}{l}\\right)^2\\boldsymbol{1}_l^t\\lim_{n\\rightarrow\\infty}e\\{\\hat{\\boldsymbol{v}}\\}\\label{eq : limrz1}\\end{aligned}\\ ] ] where @xmath102 ( @xmath103 ) are the elements of @xmath78 , and @xmath104 is the column vector of length @xmath0 with all its elements equal to @xmath96 . considering normalized fractional delay filters ( @xmath105 ) and referring to",
    ", we also find that @xmath106 therefore , using , we can find that @xmath107_{1,1}\\}=2\\pi\\frac{w}{l}\\sigma^2.\\label{eq : limrz2}\\ ] ] combining with results in @xmath108 letting the number of samples tend to infinity in and using , we obtain @xmath109 it follows form that all the elements of the first column of @xmath110 are equal to @xmath111 .",
    "therefore , can be simplified as @xmath112    finally , let us define @xmath113 as @xmath114 note that @xmath115 .",
    "therefore , the @xmath43-th element of @xmath113 ( @xmath116 ) gives an unbiased estimation of the average power in the @xmath43-th spectral segment .",
    "_ theorem 1 : _ the correlogram estimation based on undersampled data is a consistent estimator of the average power in each spectral segment",
    ".    the covariance matrix of the correlogram for undersampled data estimator is given by @xmath117 where @xmath118 is a vector of length @xmath0 consisting of the average power in each spectral segment .",
    "for the gaussian signal case , all the elements of @xmath118 are equal to @xmath119 .",
    "it follows from and that @xmath120 where @xmath121 .",
    "computation of the elements of @xmath122 involves taking expectation of the multiplication of the real or imaginary parts of the elements of @xmath76 .",
    "we will use the following lemma @xcite for interchanging the expectation and the operation of taking real or imaginary parts .",
    "[ ]    let @xmath123 and @xmath124 be two arbitrary complex numbers .",
    "the following equations hold @xmath125    the elements of @xmath122 can be easily obtained using @xmath126_{a , b}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{c , d } \\}$ ] , @xmath126_{a , b}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{c , d}^*\\}$ ] , and lemma @xmath96 , where @xmath127_{a , b}$ ] and @xmath127_{c , d}$ ] are the elements of @xmath76 used for forming @xmath77 . using and , we obtain @xmath128_{a , b}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{c , d}\\}\\nonumber\\\\ & & ~=\\left(2\\pi\\frac{w}{nl}\\right)^2\\sum_{n=0}^{n-1}\\sum_{u=0}^{n-1}e\\{y_a^d(n)y_b^{d*}(n)y_c^d(u)y_d^{d*}(u)\\}\\nonumber\\\\ & & ~=\\left(2\\pi\\frac{w}{nl}\\right)^2\\sum_n\\sum_u\\sum_r\\sum_p\\sum_s\\sum_m\\nonumber\\\\ & & \\qquad \\qquad h_a(n - r)h_b(n - p)h_c(u - s)h_d(u - m)\\nonumber\\\\ & & \\qquad \\qquad \\times e\\{y_a(r)y_b^*(p)y_c(s)y_d^*(m)\\}\\label{eq : erzrz1}\\end{aligned}\\ ] ] where @xmath129 , @xmath130 , @xmath131 , @xmath132 , @xmath133 , and @xmath134 are notations for @xmath135 , @xmath136 , @xmath137 , @xmath138 , @xmath139 , and @xmath140 , respectively .",
    "the expectation operation in can be obtained using the forth moment of @xmath1 as @xmath141 where @xmath142 is the kronecker delta . in a similar way , @xmath126_{a",
    ", b}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{c , d}^*\\}$ ] can be obtained as @xmath143_{a , b}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{c , d}^*\\}\\nonumber\\\\ \\hspace{-5mm}&&~=\\left(2\\pi\\frac{w}{nl}\\right)^2\\sum_n\\sum_u\\sum_r\\sum_p\\sum_s\\sum_m\\nonumber\\\\ \\hspace{-5mm}&&\\quad",
    "\\quad h_a(n - r)h_b(n - p)h_c(u - s)h_d(u - m)e_2\\label{eq : erzrz2}\\end{aligned}\\ ] ] where @xmath144 is defined as @xmath145    recalling that only the first diagonal element of @xmath76 is present in @xmath77 , @xmath146 can be found to be equal to @xmath147 for @xmath148 , and it equals to zero otherwise .",
    "similarly , @xmath144 can be found to be equal to @xmath149 for @xmath150 and @xmath151 , and it equals zero otherwise . noting that @xmath126_{a , b}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{c , d}\\}$ ] and @xmath126_{a , b}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{c , d}^*\\}$ ] are real - valued and using , , and",
    ", we can find that all the off - diagonal elements of @xmath122 are equal to zero .",
    "let us start computing the diagonal elements of @xmath122 by setting @xmath148 .",
    "it follows from , , and that @xmath128_{1,1}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{1,1}\\}=\\sigma^4\\left(2\\pi\\frac{w}{nl}\\right)^2\\big(\\sum_n\\sum_u\\sum_r\\sum_s\\nonumber\\\\ & & \\quad \\quad \\qquad \\qquad h_1 ^ 2(n - r)h_1 ^ 2(u - s)+\\sum_ns_1(n)\\big)\\label{eq : erzrz3}\\end{aligned}\\ ] ] where @xmath152 is defined as @xmath153 it is straightforward to show that for @xmath154 , @xmath152 is given by @xmath155 ^ 2\\ ] ] where @xmath156 denotes the convolution operation .",
    "note that @xmath157 is not a function of @xmath158 . for @xmath159 , @xmath152",
    "is given by @xmath160 ^ 2\\ ] ] where @xmath161 is equal to @xmath96 for @xmath162 and zero elsewhere .",
    "for @xmath163 , @xmath152 is given by @xmath164 ^ 2.\\ ] ] next , can be rewritten as @xmath165_{1,1}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{1,1}\\}=\\sigma^4\\left(2\\pi\\frac{w}{nl}\\right)^2\\nonumber\\\\ \\hspace{-8 mm } & &   \\qquad \\qquad\\times\\big(\\sum_n\\sum_rh_1 ^ 2(n - r)\\sum_u\\sum_sh_1 ^ 2(u - s)\\nonumber\\\\ \\hspace{-8 mm } & & + ( n-2n_h+2)g_1+\\sum_{n=0}^{n_h-2}s_1(n)+\\hspace{-5mm}\\sum_{n = n - n_h+1}^{n-1}s_1(n)\\big)\\end{aligned}\\ ] ] and simplified using as @xmath128_{1,1}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{1,1}\\}=\\sigma^4\\left(2\\pi\\frac{w}{nl}\\right)^2\\nonumber\\\\ & & \\qquad \\qquad\\times\\big(n^2h_1 ^ 2+(n-2n_h+2)g_1+\\sigma_1\\big)\\label{eq : erzrz4}\\end{aligned}\\ ] ] where @xmath166 .",
    "note that @xmath127_{1,1}$ ] is real - valued .",
    "therefore , @xmath167_{1,1}$ ] is equal to @xmath126_{1,1}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{1,1}\\}$ ] as given in and @xmath167_{q+1,q+1}$ ] equals zero since the imaginary part of @xmath127_{1,1}$ ] is zero .    for the rest of the diagonal elements of @xmath122 , @xmath126_{a , b}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{a , b}\\}$ ] equals zero , as @xmath146 is zero .",
    "therefore , @xmath167_{k , k}$ ] ( @xmath168 and @xmath169 ) can be obtained using and as @xmath170_{k , k}=\\frac{1}{2}re\\left(e\\{[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{a , b}[\\hat{\\boldsymbol{r}}_{\\boldsymbol{z}}]_{a , b}^*\\}\\right).\\ ] ] from and we have @xmath170_{k , k}=\\frac{1}{2}\\sigma^4\\left(2\\pi\\frac{w}{nl}\\right)^2\\sum_ns_k(n)\\label{eq : ukk}\\ ] ] where @xmath171 is defined as @xmath172 it is again straightforward to show that for @xmath173 , @xmath171 is given by @xmath174 for @xmath159 , @xmath171 is given by @xmath175 for @xmath163 , @xmath171 is given by @xmath176 thus , can be rewritten as @xmath170_{k , k}=\\frac{1}{2}\\sigma^4\\left(2\\pi\\frac{w}{nl}\\right)^2\\left((n-2n_h+2)g_k+\\sigma_k\\right)\\label{eq : ukk2}\\ ] ] where @xmath177 .",
    "all the elements of the matrix @xmath122 are determined , and thus , the covariance matrix of the correlogram for undersampled data can be obtained from and .",
    "we analyze next the asymptotic behavior of the correlogram for undersampled data . letting the number of samples tend to infinity in yields @xmath178 from and",
    ", we obtain @xmath179 recall that all the off - diagonal elements of @xmath122 are zeros , and the first diagonal element of @xmath122 is given by . letting the number of samples tend to infinity in",
    ", we obtain @xmath180_{1,1}\\}=\\sigma^4\\left(2\\pi\\frac{w}{l}\\right)^2.\\label{eq : limeu11}\\ ] ] the @xmath181-th element of @xmath122 is zero , and if the number of samples tend to infinity in , @xmath182_{k , k}=0 $ ]",
    ". therefore , all the elements of @xmath183 are equal to zero except for its first diagonal element given by .    in order to further simplify ,",
    "only the elements of the first column of @xmath110 are required .",
    "we have shown in the previous section that these elements are all equal to @xmath111 .",
    "therefore , can be simplified to @xmath184 where @xmath185 is an @xmath186 matrix with all its elements equal to @xmath96 .",
    "it follows from and that @xmath187 in other words , the variance of the correlogram for undersampled data estimator tends to zero as the number of samples goes to infinity , which proves the consistency of the estimator .",
    "the spectral estimation method based on multi - coset sampling as studied in the previous sections requires the number of samples to be large . otherwise , the variance of @xmath76 rises leading to poor spectral estimation .",
    "moreover , the frequency resolution of the estimation is limited by the parameter @xmath0 .",
    "the value of @xmath0 can not be increased arbitrarily , as the total length of the signal is limited in practice . besides",
    ", this method is limited to wss signals .    in our conference contribution @xcite",
    ", we have introduced an improved model - based spectral analysis method using nested least squares , which detects sinusoids from noisy compressive measurements . for this method ,",
    "the signals do not need to be wss in general .",
    "the algorithm can handle short - length signals , and it provides high resolution spectral estimation . here",
    "we explain this method in details and provide its analysis as well as derivations of the crb .",
    "let the signal @xmath188^{t } \\in \\mathbb{c}^{n_x\\times 1 } $ ] be a linear combination of @xmath189 sinusoids ( @xmath190 ) where @xmath191 ( @xmath192 ) are the samples of the signal obtained at the nyquist rate . here",
    "the sample @xmath191 is given by @xmath193 where @xmath194 and @xmath195 ( @xmath196 ) are unknown amplitudes and frequencies of the @xmath189 sinusoids , respectively . by arranging the amplitude parameters in the vector @xmath197^t \\in \\mathbb{c}^{k \\times 1}$ ] and forming the matrix @xmath198 @xmath199 \\in \\mathbb{c}^{n\\times k}$ ] with the frequency parameters ,",
    "the model can be rewritten in the matrix - vector form as @xmath200 where @xmath201^t \\in \\mathbb{c}^{n\\times 1}$ ] is the vandermonde vector .",
    "let the vector of the measurements @xmath202 be given by @xmath203 where @xmath204 is the measurement matrix , and @xmath205 is the measurement noise with circularly symmetric complex normal distribution @xmath206 .",
    "the elements of the measurement matrix @xmath207 are drawn independently from , for example , the gaussian distribution @xmath208 .",
    "the goal is to estimate the unknown amplitudes and frequencies of the signal from the noisy compressive measurements .",
    "two criteria are taken into consideration for developing the estimation algorithm : minimization of the estimation error and matching the estimated signal to the sparsity model .",
    "the squared norm of the compressed estimation error is @xmath209 where @xmath210 is the estimated signal .",
    "thus , the problem of finding the estimate @xmath210 can be formulated as @xmath211 the estimation error is a convex function , and the minimization of can be obtained using the least squares technique with the iterative solution @xmath212 where @xmath213 is the estimated signal at the @xmath4th iteration and @xmath214 represents the step size of the ls algorithm or equivalently the scaling factor for the residual signal of the previous iteration , that is , @xmath215 .",
    "the ls problem of is underdetermined and has many solutions . in order to match the estimated signal to the model in",
    ", a pruning step is inserted in the iterative solution of .",
    "specifically , let @xmath216 , then the frequencies @xmath217 can be estimated from @xmath218 using , for example , the root - music technique @xcite .",
    "this method needs the knowledge of the autocorrelation matrix of the data @xmath219 for estimating the frequencies .",
    "consider windowing @xmath218 by overlapping frames of length @xmath220 .",
    "then , the elements of @xmath219 can be estimated as @xmath221_{a , b}=\\frac{1}{n_x - w_x+1}\\sum_{n = w_x}^{n_x}x^{e*}_{n - a}x^e_{n - b}\\ ] ] where @xmath222 is an estimation for @xmath219 , @xmath223 ( @xmath224 ) are the elements of @xmath218 , and @xmath225 .",
    "let @xmath226^t \\in [ -\\pi , \\",
    ", \\pi]^{k \\times 1}$ ] be the vector of the estimated frequencies . then",
    ", the estimate of the vandermonde matrix @xmath227 ( denoted by @xmath228 ) can be straightforwardly computed based on @xmath229 .",
    "recalling the objective of minimizing the squared norm of the compressed estimation error , the vector of the amplitudes @xmath230 can be estimated by minimizing @xmath231 . the solution for this problem",
    "is given by @xmath232 where @xmath233 .",
    "note that in @xcite , the amplitudes are estimated as @xmath234 where @xmath235 is the vector of the estimated amplitudes at the @xmath4-th iteration .",
    "the algorithm based on is referred to as _ spectral iterative hard thresholding _ ( siht ) via root - music .",
    "finally , @xmath236 can be obtained using the estimated frequencies and amplitudes as @xmath237 .",
    "the steps of the algorithm are summarized in algorithm @xmath96 .",
    "the algorithm consists of the outer and the inner least squares steps along with the root - music method . in each iteration",
    ", the algorithm converges to the true signal in three steps .",
    "first , the outer least squares makes an estimation of the subspace in which the original signal lies .",
    "this is done by minimizing the squared norm of the compressed estimation error .",
    "note that due to the fact that the problem is underdetermined , the signal @xmath238 can not be estimated , but only an improved estimate of the subspace to which the signal @xmath238 belongs can be found .",
    "then , the signal estimate @xmath210 is enhanced in the second and the third steps of the algorithm . in the second step , the estimation is forced to match the signal model by applying the root - music method .",
    "the frequencies are estimated at this stage .",
    "note that each frequency represents one of the dimensions of the signal subspace .",
    "in the first few iterations of the algorithm , some of the frequencies might be estimated incorrectly , as the output of the outer least squares step might not be close enough to the true signal subspace . in the third step of the algorithm ,",
    "the amplitudes are estimated by applying the inner least squares .",
    "the last two steps are building the signal subspace according to the signal model , and then , estimating the projection coefficients for each dimension of the subspace .",
    "finally , the estimated signal is fed back to the outer least squares step for the next iteration .",
    "the algorithm continues until some stopping criterion is satisfied .",
    "for example , the criterion can be satisfied when a predetermined fixed number of iterations is performed or the normalized compressed estimation error ( @xmath239 ) is less than a given threshold value .",
    "[ cols=\"<\",options=\"header \" , ]",
    "we have considered two spectrum estimation techniques for undersampled data : the correlogram method which estimates the spectrum from a subset of the nyquist samples and the model - based nested least squares algorithm which works with compressive measurements .",
    "the correlogram estimation method for low - resolution spectral estimation has been analyzed in this paper by computing the bias and the variance of the estimator .",
    "it has been shown that the estimator is unbiased for any signal length , and it has been proven that the variance of the method tends to zero asymptotically . therefore , this method is a consistent estimator .",
    "the behavior of the estimator for finite - length signals has been also investigated , and it has been illustrated that there is a tradeoff between the accuracy of the estimator and the frequency resolution .",
    "it has been shown that at a fixed average sampling rate , the performance of the estimator degrades for the estimation with higher frequency resolution .",
    "furthermore , for a given frequency resolution , the performance improves by increasing the average sampling rate .    in the second part of the paper",
    ", we introduced a new signal recovery algorithm for model - based spectral compressive sensing for high - resolution spectral estimation .",
    "we considered a general signal model consisting of complex - valued sinusoids with unknown frequencies and amplitudes .",
    "although the signal model is inherently sparse , its representation in the fourier basis does not offer much sparsity .",
    "for this reason , the conventional cs recovery algorithms do not perform well for such signals .",
    "the proposed algorithm estimates the signal iteratively by performing three steps at each iteration .",
    "first , the outer least squares makes an estimation of the subspace in which the original signal lies .",
    "this is done by minimizing the squared norm of the compressed estimation error .",
    "next , the unknown frequencies are estimated using the root - music algorithm .",
    "then , the amplitudes of the signal elements are estimated by the inner least squares , and the result is fed back to the outer least squares for the next iteration .",
    "the cramer - rao bound for the given signal model has been also derived .",
    "finally , the simulation results have been presented , and it has been shown that the proposed algorithm is able to converge after @xmath240 iterations for the given settings and it approaches the crb at high signal to noise ratio values .",
    "d.  g.  manolakis , v.  k.  ingle , and s.  m.  kogon , _ statistical and adaptive signal processing : spectral estimation , signal modeling , adaptive filtering and array processing._1em plus 0.5em minus 0.4emboston , ma : mcgraw - hill , 2000 .",
    "a.  c.  gilbert , s.  guha , p.  indyk , s.  muthukrishnan , and m.  j.  strauss , `` near - optimal sparse fourier representations via sampling , '' in _ proc .",
    "34th acm symp .",
    "theory of computing _",
    ", montreal , qc , canada , may 2002 , pp .  152161 .",
    "m.  f.  duarte and r.  g.  baraniuk , `` recovery of frequency - sparse signals from compressive measurements , '' in _ proc .",
    "allerton conf .",
    "communication , control and computing _ , monticello ,",
    "il , sept .",
    "2010 , pp .",
    "599606 .",
    "e.  cands , j.  romberg , and t.  tao , `` robust uncertainty principles : exact signal reconstruction from highly incomplete frequency information , '' _ ieee trans .",
    "inform . theory _ , vol .",
    "52 , no .  2 , pp .",
    "489509 , feb .",
    "j.  a.  tropp , j.  n.  laska , m.  f.  duarte , j.  k.  romberg , and r.  g.  baraniuk , `` beyond nyquist : efficient sampling of sparse bandlimited signals , '' _ ieee trans .",
    "inform . theory _",
    "56 , no .  1 , pp .  520544 , jan ."
  ],
  "abstract_text": [
    "<S> this paper studies two spectrum estimation methods for the case that the samples are obtained at a rate lower than the nyquist rate . </S>",
    "<S> the first method is the correlogram method for undersampled data . </S>",
    "<S> the algorithm partitions the spectrum into a number of segments and estimates the average power within each spectral segment . </S>",
    "<S> we derive the bias and the variance of the spectrum estimator , and show that there is a tradeoff between the accuracy of the estimation and the frequency resolution . </S>",
    "<S> the asymptotic behavior of the estimator is also investigated , and it is proved that this spectrum estimator is consistent .    a new algorithm for reconstructing signals with sparse spectrum from noisy compressive measurements is also introduced . </S>",
    "<S> such model - based algorithm takes the signal structure into account for estimating the unknown parameters which are the frequencies and the amplitudes of linearly combined sinusoidal signals . </S>",
    "<S> a high - resolution spectral estimation method is used to recover the frequencies of the signal elements , while the amplitudes of the signal components are estimated by minimizing the squared norm of the compressed estimation error using the least squares technique . </S>",
    "<S> the cramer - rao bound for the given system model is also derived . </S>",
    "<S> it is shown that the proposed algorithm approaches the bound at high signal to noise ratios .    </S>",
    "<S> shell : bare demo of ieeetran.cls for journals    spectral analysis , correlogram , undersampling , consistency , compressive sensing , least squares , cramer - rao bound . </S>"
  ]
}