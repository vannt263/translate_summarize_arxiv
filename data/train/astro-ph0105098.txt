{
  "article_text": [
    "simulating the formation process of galaxies in clusters and fields simultaneously is one of the promising strategies to study how statistical properties of observed galaxies have originated . for this purpose ,",
    "the box size in which the simulation is performed must be larger than a typical cluster separation , which is a few tens to a hundred mpc . at the same time , in order to reproduce the intrinsic dynamical structure of each simulated galaxy , the newtonian gravity should be calculated on a scale well below the characteristic length of individual galaxies , which is a few kpcs . hence , for the simulation of formation of multiple galaxies , the ratio of box size to minimum resolved scale or the spatial dynamic range must be greater than @xmath0 .",
    "in addition , there is another dynamic range in @xmath1-body systems often called the mass dynamic range , or simply , the number of particles if the mass of particles is the same . strictly speaking",
    ", dark matter component evolves according to the collisionless boltzmann equation .",
    "however , since computer resources are finite , the distribution function of ideal collisionless component is replaced by a finite sum of localized distribution functions corresponding to the finite number of particles in the @xmath1-body simulation .",
    "this causes two - body relaxation which artificially affects the evolution of dark matter distribution .",
    "the effect of relaxation can be suppressed by introducing more particles .",
    "we crudely estimate how many particles are required to trace the evolution of galactic dark halos in a cosmological simulation by comparing the relaxation time scale of dark halos and their age .",
    "our naive estimation gives @xmath2 at the minimum ( see appendix [ sec : mass_res ] ) .",
    "it is instructive to examine whether the particle - mesh ( pm ) method is capable of the required spatial dynamic range of @xmath0 and the required mass dynamic range of @xmath3 .",
    "the spatial dynamic range of the pm method is restricted by the mesh spacing . when the number of meshes is taken as many as the number of particles , the spatial dynamic range is about @xmath4 for a simulation with @xmath3 particles , which is two orders smaller than required . however , a simulation with @xmath5 meshes and particles , whose spatial dynamic range is about @xmath0 , is not only unrealistic today , but also inefficient .",
    "the adaptive mesh refinement ( amr ) is one of the prescriptions to resolve this problem by introducing finer meshes hierarchically in regions where higher spatial resolution is required ( berger & oliger 1984 ) .    first , villumsen ( 1989 ) introduced cubic subgrids hierarchically into the pm method to increase its spatial resolution . while his hierarchical pm code places adaptive meshes by hand , subgrids are automatically located in the particle ",
    "multiple mesh code developed by jessop , duncan , & chau ( 1994 ) .",
    "gelato , chernoff , & wasserman ( 1997 ) extended their methods to handle isolated @xmath1-body systems .",
    "their code is applicable to non - cosmological problems . on the other hand , adopting the multigrid method as the poisson solver , suisalu & saar ( 1995 ) developed a code which can treat rectangular adaptive meshes .",
    "furthermore , kravtsov , klypin , & khokhlov ( 1997 ) developed the adaptive refinement tree ( art ) code which subdivides all cells which satisfy the user defined refinement criterion regardless of the shape of the boundary between coarse meshes and refined meshes .",
    "calculating the force between particles is the most time consuming part in @xmath1-body methods . in order to overcome this problem , aarseth ( 1963 )",
    "changed the timing to calculate the force , from particle to particle , depending on the time scale of force variation .",
    "this technique , named individual time steps is implemented in the art code ( kravtsov et al . 1998 ) with modification such that the time steps of particles are determined by the local density , though not described in detail in their paper .",
    "we also adopted the modified individual time steps , or hierarchical time steps ( hts ) so that our code is adaptive not only in space but also in time , or our code is four dimensionally adaptive .",
    "furthermore , our code is designed to incorporate the hydrodynamics code with amr ( yahagi & yoshii 2000 ) , similar to the codes developed by anninos , norman , & clarke ( 1994 ) and norman & bryan ( 1999 ) .",
    "while the refined regions are restricted to be rectangular parallelepipeds in their codes , this limitation has been relaxed in ours .    in  [ sec : code ] we review the basic equations for the cosmological @xmath1-body simulation and describe our code in detail putting emphasis on the parts related to amr and hts .",
    "details of tests and the results are discussed in  [ sec : test ] .",
    "finally , we summarize this work in  [ sec : summary ] .",
    "for the cosmological simulation , the comoving coordinate system is suitable to represent particle position : @xmath6 where @xmath7 is the scale factor , and @xmath8 and @xmath9 are comoving and proper positions , respectively .",
    "however , in order to incorporate the hydrodynamics code , the proper coordinate system is suitable to represent the velocity : @xmath10 using these variables , the basic equations for @xmath1-body systems in the expanding universe are given by : @xmath11 and @xmath12 note that @xmath13 denotes the comoving density , here .",
    "how to discretize these equations depends on the problem to be solved and the strategy for it .",
    "since the primary objective of our code is to perform the cosmological simulation with a wide dynamic range in both space and mass , we must save memory as much as possible . thus using the variable time - step leapfrog integrator which does not require additional memory , we discretize equations ( [ eq : velocity ] ) and ( [ eq : eq_of_motion ] ) as follows : @xmath14    among a variety of methods to solve equations ( [ eq : force_diff ] ) and ( [ eq : poisson ] ) , we adopt the mesh based method , such as the pm method , which calculates the force between particles through the following steps : ( i ) mass of particles is assigned to their adjacent grid nodes .",
    "( ii ) discretized poisson equation is solved to give the potential on each node .",
    "( iii ) force on each node is calculated as the difference of the potential on nearby nodes .",
    "( iv ) force on particles is interpolated from those on the adjacent nodes .",
    "we discuss the mass assignment ( i ) , force interpolation ( iv ) , and potential differentiation ( iii ) in  [ sec : interpolation ] , while the poisson solver ( ii ) in  [ sec : poisson ] .",
    "the pm method uses a cubic mesh to calculate the force on particles .",
    "therefore , the spatial resolution of the pm method is limited by the spacing of this mesh . like the art code developed by @xcite ,",
    "our code overcomes this limitation by subdividing the cells in regions where higher spatial resolution is required .",
    "this adaptive mesh refinement corresponds to adding data sets for small cells onto the homogeneous and cubic base mesh hierarchically . in order to maintain and modify the hierarchical mesh structure , it is required to access the parent , child , and neighbor cells .",
    "the storage for pointers to the parent and neighbor cells can be saved by grouping the cells which have the same parent cell @xcite . since one refinement process divides a cell into eight half - sized cells , we group these eight cells together and call this group a cell octet ( fig .",
    "[ fig : data_structure ] ) .",
    "each cell octet keeps a pointer to the parent cell and pointers to the six neighboring cell octets . in the @xmath1-body code ,",
    "in addition to these data , a pointer to the first particle in the cell octet , the number of particles in the cell octet , and the integral position of the cell octet are also stored .",
    "the integral position is the position rounded off to integer . while cell octets residing in the same level are connected by the doubly linked lists in the art code , our code stores the cell octets having the same level in an array consecutively .",
    "the level of a cell , @xmath15 , is defined as @xmath16 , where @xmath17 and @xmath18 are the sizes of the simulation box and the cell , respectively .",
    "we use cells having integral level only",
    ".    moreover , the same level cell octets are sorted by the morton ordering ( barnes & hut 1989 ; warren & salmon 1993 ) . the key for the morton ordering , @xmath19 , is given by @xmath20 where @xmath21 is the level of the smallest hierarchical mesh , and @xmath22 , and @xmath23 are the @xmath24-th bit of the integral position of the cell octet normalized by @xmath25 ( @xmath26 , and @xmath27 ) .",
    "thus , @xmath28 we do not sort particles as warren and salmon s hashed oct - tree code ( warren & salmon 1993 ) , because it is incompatible with hts , though sorting hierarchical cells is compatible with hts .",
    "the hierarchical mesh is maintained using the cell octets as the building blocks ( fig .",
    "[ fig : hierarchical_mesh ] ) , which are added or removed from meshes freely .",
    "basically each cell has only one pointer to the child octet , but the storage changes depending on what physics is incorporated in the code . in the code for the self gravitating system , density and potential is stored .",
    "no additional storage is required for the @xmath1-body code , since the storage for a pointer to the first particle in the cell is shared by the pointer to the child cell octet .",
    "the hydrodynamics code requires storage for fluid density , specific energy and fluid velocity in each cell .",
    "the condition for subdividing the cells , or the refinement criterion , plays an important role in the amr . in general context of the amr",
    ", the refinement criterion is defined using error estimators such as the residual of the partial differential equation to be solved . however , since we introduced the amr to keep the mass dynamic range all the way from homogeneous to clustered configurations , we refined all cells which contain @xmath29 particles and more as the art code .",
    "this criterion sets the upper limit to the mass in unrefined cells .",
    "we set @xmath30 throughout this paper unless otherwise stated . following this refinement criterion ,",
    "the hierarchical meshes are constructed recursively on the cubic structured mesh whose base level is @xmath31 , until they reach the dynamic range level , @xmath21 . at the same time , the cells which do not satisfy the refinement criterion are removed from the hierarchical meshes .",
    "in addition to the refined cells which satisfy the refinement criterion , we also subdivide those cells , named buffer cells , which are adjacent to the refined cells ( fig .",
    "[ fig : refine_buffer ] ) .    for the illustrative purpose ,",
    "we take an example from a slice of the cosmological simulation for an lcdm universe described in  [ sec : lcdm test ] .",
    "the left panel of figure [ fig : eg mesh ] shows the distribution of particles , and the right panel shows the configuration of hierarchical meshes placed in accordance with the above prescription .",
    "while the cells including the sheet structure are refined once , more levels of hierarchical meshes are placed in the regions where massive halos reside .",
    "we adopted a time stepping scheme called the hierarchical time steps ( e.g. makino 1991 ) .",
    "the time step of each particle is not the same but restricted to @xmath32 times of the longest time steps .",
    "we chose @xmath33 to be the refinement level , @xmath34 , ( kravtsov et al .",
    "1998 ) so that the trajectory of the level @xmath15 particle , which is included in the level @xmath15 refined cell but not in any level @xmath35 refined cells , is integrated by the time interval @xmath36 which is related to the time interval for the base level @xmath31 particles , @xmath37 , as @xmath38 in our code , @xmath37 is given by @xmath39 where @xmath40 is a free parameter and fixed as @xmath41 throughout this paper .",
    "equation ( [ eq : indiv_time ] ) indicates that the level @xmath15 particles step twice while the level @xmath42 particles step once .",
    "each step of particles is split into three steps such as velocity step by half time interval ( @xmath43 ) , position step by full time interval ( @xmath44 ) , and velocity step by half time interval ( @xmath45 ) again . for example , when the times of hierarchical meshes of level @xmath46 and larger synchronize , their mesh structure is modified simultaneously in accordance with the refinement criterion .",
    "when this synchronization occurs at @xmath47 , the level @xmath15 particles , for which @xmath48 , step their velocity from @xmath49 to @xmath50 , where @xmath15 and @xmath51 are the particle s levels at @xmath52 and @xmath47 , respectively .",
    "the force on particles is interpolated from the corners of the level @xmath51 refined cells . hence ,",
    "even if the cell to which a particle belongs is removed , the particle can step their velocity properly .",
    "as far as the particle s levels at @xmath52 and @xmath47 are the same , the integration of its trajectory is the same as that by the leapfrog method .",
    "the pseudo - code describing this flow of procedures is given in appendix [ sec : pseudo - code ] .",
    "in our code the mass of particles is assigned to the corners of the neighboring cells , and the force on particles is interpolated from them . among various assignment and interpolation schemes for the pm method ( see e.g. hockney & eastwood 1988 ) , we adopted the cloud - in - cell ( cic ) scheme : @xmath53 and @xmath54 where @xmath55 , @xmath56 and @xmath57 are the mesh spacing , the mass of particles and the position of cell corners , respectively .",
    "the force on each node is calculated by two - point differencing scheme which uses the difference equation for equation ( [ eq : force_diff ] ) : @xmath58 and @xmath59    the cic scheme is applied also to the hierarchical meshes .",
    "the mass of particles is assigned to the corners of all levels of cells including the particles , while the force onto the level @xmath15 particles is interpolated from those on the corners of the level @xmath15 refined cells : @xmath60 and @xmath61 where @xmath62 and @xmath63 are the sets of particles in level @xmath15 cells and nodes of level @xmath15 cells , respectively .",
    "we repeatedly note that the particle s level is defined as the level of the finest refined cell including the particle .",
    "thus , level @xmath15 particles can reside in buffer cells whose level is larger than @xmath15 .",
    "we adopt the multigrid method ( brandt 1977 ) to solve the discretized poisson equation for the base mesh .",
    "equation ( [ eq : poisson ] ) is discretized as @xmath64 where @xmath15 is the discretized laplacian operator and stands for @xmath65 and , the indices @xmath66 , @xmath67 and @xmath68 specify the position of nodes on the base mesh .",
    "since we do not know the exact solution of this equation initially , we try to estimate it iteratively .",
    "the error ( @xmath69 ) is defined as the difference between the solution ( @xmath70 ) and the estimate ( @xmath71 ) :    @xmath72    roughly , @xmath73 can be split into the short and long wavelength modes .",
    "the short wavelength modes converge quickly by the basic stationary iterative methods , such as the red - black gauss - seidel method which updates @xmath71 by solving equation ( [ eq : dis poi ] ) about @xmath74 and substituting @xmath71 into @xmath70 :    @xmath75    this updating of estimate is not carried out all at once , but through two steps which do not update the estimate on a node and its six neighboring nodes simultaneously .",
    "for example , @xmath76 , @xmath77 , @xmath78 and @xmath79 are updated in the first step , then @xmath80 , @xmath81 , @xmath82 and @xmath83 in the second .    on the other hand ,",
    "the long wavelength modes converge slowly .",
    "this drawback of the iterative methods is overcome in the multigrid method as follows : first , the poisson equation is rewritten as @xmath84 where @xmath85 is called the residual .",
    "note that equation ( [ eq : mg res ] ) relating the error to the residual keeps the same form as the original poisson equation .",
    "next , we prepare meshes for each level from @xmath86 to @xmath31 . the residual on the base mesh",
    "is projected onto the level @xmath87 mesh by the fine - to - coarse operator ( see appendix [ sec : multigrid ] ) , then the error on the base mesh is relaxed using the red - black gauss - seidel method . in the two - grid method , the error on the level @xmath87 mesh is projected back to the base level and added to the estimate .",
    "this procedure proceeds further in the multigrid method by estimating the error on the level @xmath87 mesh using the level @xmath88 mesh , and the error on the level @xmath88 mesh using the level @xmath89 mesh and so on .    in the multigrid method",
    "described so far , iteration begins from the base mesh , but in the full multigrid method , it begins from the level @xmath86 mesh where the solution is given trivially .",
    "figure [ fig : v cycle ] schematically shows the schedule of a sequence of relaxation , coarse - to - fine and fine - to - coarse operations .",
    "since the iteration from level @xmath15 to 0 then from 0 to @xmath15 is v - shaped , this multigrid iteration is called a v - cycle . further description of the multigrid algorithm and the terminology used here is found in e.g. @xcite and @xcite .    in our code , the potential on the hierarchical meshes is solved as follows : first , the full multigrid method is applied to solve the poisson equation on the base mesh .",
    "then the projection of the potential on the level @xmath42 meshes onto the level @xmath15 meshes and the two grid iteration using the level @xmath42 and @xmath15 meshes are executed from the level @xmath90 meshes to the @xmath21 meshes .",
    "as the particles belonging to the hierarchical cells change the position , the potential on hierarchical meshes must be modified .",
    "after the level @xmath15 particles step their position at time @xmath91 , provided @xmath92 , two grid iteration is successively applied from the level @xmath42 meshes to the level @xmath21 meshes .",
    "figure [ fig : amr v cycle ] exhibits this amr poisson solver s schedule for the coarse - to - fine and fine - to - coarse operations and relaxation in the case of @xmath93 and @xmath94 .    the boundary values of the hierarchical meshes are defined on nodes in buffer cells ( fig .",
    "[ fig : amr boundary ] ) .",
    "the potential at the boundary is calculated by the coarse - to - fine operator from the lower level following the full weighting scheme .",
    "since the potential on the level @xmath42 meshes reflect the density distribution on the level @xmath15 meshes after the two grid iteration among them , the potential at the boundary is corrected from the initial guess which is projected from the lower level meshes .",
    "we first wrote a code using the nested iteration which applies the coarse - to - fine projection and the one level red - black gauss - seidel iteration instead of the two grid iteration . but",
    "a slight discrepancy was observed between the correlation functions in the lcdm model calculated by the nested iteration code with hts and the code without hts , though the difference is negligible between the results calculated by the two grid iteration code with and without hts (  [ sec : lcdm test ] ) .",
    "hence , it is crucial to adopt the two grid or the multi grid potential solver to implement the hts technique .",
    "as the first test , we have checked whether the force between particles is calculated correctly .",
    "first , we placed a truncated singular isothermal sphere . following the mesh refinement in accordance with the way described in ",
    "[ sec : hrch mesh ] , the force on the particles is calculated .",
    "then we placed a fiducial particle in a level @xmath21 cell randomly and recalculate the force on all particles . subtracting the previously calculated force from this force",
    ", we obtained the gravitational force from the fiducial particle on the rest of particles .",
    "we repeated the above process 32 times . in figure",
    "[ fig : force resolution ] the force from the fiducial particle to the rest of particles is plotted against distance between them .",
    "circles , squares , and crosses represent the cases of @xmath21= 5 , 7 , and 9 , respectively , while the level of the base mesh is fixed as @xmath31=5 . in this test ,",
    "the spacing of the base mesh , the mass of particles , and the gravitational constant are normalized to unity .",
    "although the force is softened when the separation is much smaller than the spacing of the level @xmath21 mesh in each case , the force coincides with that expected from the newtonian law at radius sufficiently larger than this spacing but smaller than the box size .",
    "we also put a homogeneous sphere consists of massless particles added to a massive particle at the center . setting @xmath95 so that all particles belong to the level @xmath21 cells , we calculated the force on the massless particles from the central particle . since our code adopts the periodic boundary condition , we compared this force not with the newtonian law , but with the sum of the newtonian force from periodically placed particles which is calculated efficiently using the ewald expansion ( ewald 1921 ; sangster & dixon 1976 ) . figure [ fig : force error ] shows the relative error of the force calculated by our code in comparison with that calculated by the ewald expansion .",
    "circles , squares , and crosses represent the cases of @xmath21=6 , 8 , and 10 , respectively , with @xmath96 in common . in any cases ,",
    "the error is largest at @xmath97 but is kept within 20% .",
    "@xcite formulated the liner approximation for particle trajectories : @xmath98 where is the lagrangian position of the particle and @xmath99 is the growing mode of the linear density perturbation normalized so that ( ) gives the initial positional perturbation .",
    "this zeldovich approximation is not only applicable to particles in the sub - linear regime , but also gives their exact trajectories for a system of one - dimensional sheets until any pairs of sheets crosses each other .",
    "connecting the trajectories before and after sheet crossings , the trajectories of sheets are calculated with high accuracy .",
    "we test our code by comparing the trajectories calculated by our code and those calculated by yano s one - dimensional code for which the details are described in yano & gouda ( 1998 ) .",
    "initially we have imposed a single sinusoidal plane wave perturbation to the einstein - de sitter ( eds ) universe : @xmath100 and @xmath101 where @xmath17 and @xmath55 are the size of simulation box and the base mesh spacing , respectively . in this test , the level of the base mesh is fixed as @xmath102 .    the following equations for position , velocity , and density hold until the first caustic appears : @xmath103 and @xmath104 where the scale factor @xmath105 is normalized to unity at the initial time . when @xmath13 diverges to infinity , the first caustics form .",
    "this occurs at @xmath106 when @xmath107 .",
    "we run the simulations setting @xmath108 with sheets consisting of @xmath109 particles arranged on the grid .",
    "figure [ fig:1stspw ] shows the distribution of sheets in the phase space at @xmath110 taken from the four runs using the one - dimensional code ( solid line ) , the pm code ( @xmath111 , _ crosses _ ) , our code with hts ( @xmath112 , _ circles _ ) , and our code without hts ( @xmath112 , _ squares _ ) .",
    "although the cells bordering on the caustics are refined only once , the velocity degradation for @xmath112 is weaker than that for @xmath111 .",
    "the difference between the @xmath1135 and 7 results is more prominent when the second caustic appears at @xmath114 ( fig . [ fig:2ndspw ] ) .",
    "near the center of the spiral pattern in the phase space , the @xmath111 result is wound weaker than the other two @xmath112 results . no obvious difference between the @xmath112 results with hts and without it shows that our implementation of the hts is very successful .",
    "58 base level time steps are used from the beginning of the simulation to the second caustics generation . note that the positions of the first caustics in the three runs are the same .",
    "this is because sheets in low resolution run are pulled toward the center more weakly than those in high resolution runs , not only when they fall toward the center , but also when they leave it in the same way .",
    "thus , the position of caustics does not change much by the resolution of the code .",
    "this is the reason why sheets position in the phase space is different among low resolution run and high resolution runs , even though the position of the caustics are the same .",
    "this is true not only for the plane wave test , but also for the spherical infall test described in the next .      as the third test",
    ", our code is checked against the spherical self - similar infall model where the infall of collisionless material onto the collapsed density perturbation in the eds universe is considered .",
    "this model is solved semi - analytically ( fillmore & goldreich 1984 ; bertschinger 1985 ) . as its name indicates",
    ", this infall model possesses the symmetry which is different from the planar symmetry of the base mesh in our code and the single plane wave test .",
    "moreover , the infall onto the virialized objects is thought to be common in the hierarchical clustering .",
    "for these reasons , this model is widely used as a test for cosmological simulation codes ( e.g. splinter 1996 ; kravtsov et al .",
    "1997 ; gelato et al .",
    "1997 ; yahagi , mori , & yoshii 1999 ) .    in order to prepare the initial particle distribution for this test problem",
    ", we place @xmath115 particles at the center of particles distributed homogeneously and amorphously .",
    "such a distribution is obtained as follows @xcite : first , particles are distributed randomly .",
    "next , the system is evolved in the eds universe reversing the sign of the force to make particles repulsive each other , and is expanded million times from the initial time until the kinetic energy of the system converges to be negligibly small .    in this test",
    ", we set @xmath116 , @xmath117 , @xmath118 , and use @xmath119 particles .",
    "we normalize the time by the initial age of the universe , @xmath120 , and the radius by the turn - around radius , @xmath121 , given by @xmath122 where @xmath1 , @xmath123 and @xmath124 are the total number of particles , the initial density contrast and its radial extension , respectively .",
    "figure [ fig : bertschinger test ] shows the radial density profile calculated by our code ( _ circles _ ) .",
    "crosses connected by the solid line denote the semi - analytic solution taken from table 4 of @xcite .",
    "our result shows good coincidence with the semi - analytic solution including the position of the first caustic and the power law asymptote of density profile toward the center whose index is @xmath125 .",
    "finally , we have performed three lcdm simulations , using @xmath126 particles and @xmath96 in common .",
    "we adopt @xmath127 for the pm run and @xmath117 for the amr+hts and amr runs .",
    "the difference between the amr+hts and amr runs is only that the amr+hts run adopts the hts while the amr run does not . for these simulations ,",
    "we adopt @xmath128 and @xmath129 .",
    "the size of simulation box is 70@xmath130 mpc and the mass of particles is @xmath131 .",
    "the initial data of the simulations are generated by the cosmics code provided by bertschinger & bode using the analytic fitting function for the power spectrum of the cdm universe described in bardeen et al .",
    "( 1986 ) .",
    "figure [ fig : z0map ] shows the map of projected density in the logarithmic unit at @xmath132 .",
    "filtering is not applied to the density maps in any panels .",
    "the overall mass distributions from the amr+hts and amr runs agree well with each other , and are more centrally concentrated than that from the pm run .",
    "this is confirmed by the comparison among the particle distributions in a slice of 1/16 thickness of the side ( fig .",
    "[ fig : z0slice ] ) , and the two - point correlation functions from the amr+hts , amr , and pm runs ( fig .",
    "[ fig : crr ] ) .",
    "there are many cosmological @xmath1-body simulations with parameters similar to our lcdm simulations .",
    "figure [ fig : crr2 ] shows the correlation function from our amr+hts run ( _ thick dotted line _ ) overlaid with those from the pm run in klypin et al .",
    "( 1996 ) ( _ crosses _ , hereafter kpm run ) , ap@xmath133 m run in jenkins et al .",
    "( 1998 ) ( _ dashed line _ ) , and art run in coln et al .",
    "( 1999 ) ( _ solid line _ ) .",
    "data of overlaid three runs are taken from figure 4 of coln et al .",
    "vertical solid lines shown with @xmath134 , @xmath135 , @xmath136 represent the force resolution of our amr+hts run , kpm run , and the ap@xmath133 m run in jenkins et al .",
    "( 1998 ) , respectively .",
    "among the three lcdm simulation runs , the size of the simulation box and the force resolution of the kpm run is closest to those of our amr+hts run .",
    "the root mean square amplitude of the fluctuation at 8 h@xmath137mpc ( @xmath138 ) of our run is 1.0 while the kpm run adopted @xmath139 .",
    "although the number of particles used in the amr+hts run is @xmath140 of particles in the kpm run , magnitude of the correlation function at @xmath141 of the amr+hts run coincides with that of the kpm run within 10@xmath142 .",
    "we have also compared the density profiles of the halos in the amr+hts and amr runs .",
    "figure [ fig : halo_cmp ] shows the density profiles of halos in the amr+hts run ( _ circles _ ) and the amr run ( _ squares _ ) .",
    "the universal profile proposed by navarro , frenk , & white ( 1996 ) , @xmath143 is fitted to the halos in the amr+hts run , and the result is denoted by the solid line in each panel of figure [ fig : halo_cmp ] .",
    "this universal profile provides a good fit to the dark halos over the entire range of radius .",
    "the profiles of the halos from the amr+hts run are in agreement with those from the amr run .",
    "slight discrepancies between them are primarily due to the different positions of satellite halos in these two runs .",
    "this agreement of halo profiles between the amr+hts and amr runs also indicate that our implementation of the hts is successful .",
    "finally we compare the performance of the amr+hts and amr codes on a pc with an amd s athlon 750 mhz processor .",
    "the lcdm simulations for which we set @xmath144 are performed from @xmath7=0.0366 to @xmath7=1 .",
    "thereby the amr+hts code uses 133 base - level time steps , while the amr code uses 1932 global time steps . the cpu time spent by these codes",
    "is plotted against @xmath7 in figure 15 . as seen from this figure , the amr+hts code spends less than a half of the cpu time spent by the amr code .",
    "thus the amr+hts code saves much of the cpu time , while keeping the same spatial resolution as the amr code .",
    "higher performance of the amr+hts code is achieved when we set a higher @xmath145 .",
    "we have described two techniques of amr and hts which are able to increase the spatial and time resolutions of the pm method .",
    "the amr divides and removes cells in each time step in compliance with the refinement criterion , and enhances the spatial resolution . on the other hand ,",
    "the hts changes the time step interval depending on the level of particles and enhances the time resolution .",
    "three different tests described in  [ sec : test ] show that our implementation of amr and hts is successful .",
    "compared with the previous codes with amr , we describe the hts technique in detail .",
    "it is found that the hts is an indispensable technique for the wide dynamic range simulation because importance of the hts increases as the finer cells are introduced into the simulation .",
    "we will parallelize our code for massively parallel processors to realize simulations with more than @xmath3 particles which are needed to study the links between the formation of galaxies and their environments ( see .",
    "appendix [ sec : mass_res ] ) . sorting the hierarchical cells by the morton ordering is a preparatory step for the parallelization .",
    "finally it is worth mentioning that we have already combined our @xmath1-body code with the hydrodynamics code @xcite .",
    "this combined code enables us to study the dynamical evolution of both dark matter and baryonic components . including some physical and phenomenological processes such as cooling of the gas , star formation , energy feedback from supernovae etc",
    ", we will trace the formation process of galaxies under the realistic condition in the universe .",
    "we would like to thank shu - ichiro inutsuka for his useful comments on the poisson solver of our code and taihei yano for providing us the data for the single plane wave test using his one - dimensional code for collisionless systems .",
    "some calculations were conducted using the resources of the the astronomical data analysis center of the national astronomical observatory , japan .",
    "acknowledges the jsps research fellowships for young scientists . this work has been supported in part by the grant - in - aid for coe research ( 07ce2002 )",
    "the relaxation time scale for a halo is given by ( see e.g. binney & tremaine 1987 ) @xmath146 where @xmath1 is the number of particles which compose the halo . for a halo formed at @xmath147 in the einstein - de sitter ( eds ) universe , we have @xmath148 in order to calculate the evolution of the halo correctly , the relaxation time scale must exceed the age of the halo at @xmath132 , i.e. @xmath149 the required minimum number of particles , @xmath150 , can be estimated crudely by solving the following non - linear equality : @xmath151 thus the total number of particles , required to keep simulated galactic halos unrelaxed , is given by @xmath152 where @xmath153 is the minimum mass of halos which do not relax until the simulation is completed , and @xmath15 is the size of simulated region .",
    "for the reference values of @xmath154 , and @xmath155 , we have @xmath156 for the eds universe .",
    "the above estimate is based on many assumptions .",
    "for example , halos are assumed to have been isolated after they formed , although there are cluster galaxies which interact with the cluster and other galaxies , and these interactions can increase the required number of particles .",
    "hence , this estimation is quite naive and optimistic , but it gives the lower limit of the number of particles necessary to reproduce un - relaxed galactic haloes in simulations .",
    "@xmath157 ( ) + \\ { + int l ; +   + @xmath158 ( ) ; + @xmath159(l@xmath160l@xmath161l@xmath162 ) ; + if ( l@xmath163 l@xmath162 ) @xmath164(l@xmath165 ) ; + @xmath166(l@xmath160l@xmath161l@xmath162 ) ; + @xmath167(l@xmath168l@xmath161l@xmath162 ) ; + @xmath169(l@xmath160l@xmath161l@xmath162 ) ; + @xmath159(l@xmath160l@xmath161l@xmath162 ) ; + } +   + @xmath164 ( int l@xmath170 ) + \\ { + int l ; +   + if ( l@xmath171 l@xmath162 ) @xmath164(l@xmath172 ) ; + @xmath166(l@xmath173l@xmath161l@xmath162 ) ; + @xmath167(l@xmath174l@xmath161l@xmath162 ) ; + @xmath169(l@xmath173l@xmath161l@xmath162 ) ; + @xmath175(l@xmath173l@xmath161l@xmath162 ) ; + if ( l@xmath176 l@xmath162 ) @xmath164(l@xmath172 ) ; + }",
    "the full - weighting scheme for the fine - to - coarse and the coarse - to - fine operators are adopted as @xmath177 and @xmath178 here , @xmath179 represents any variables defined on the node which is placed at @xmath180 on the level @xmath15 mesh .",
    "aarseth , s. j. 1963 , , 126 , 223 anninos , p. , norman , m. l. , & clarke , d. a. 1994 , , 436 , 11 bardeen , j. m. , bond , j. r. , kaiser , n. , & szalay , a. s. 1986 , , 304 , 15 barnes , j. e. , & hut , p. 1989",
    ", , 70 , 389 berger , m. j. , & oliger , j. 1984 j. comp .",
    "phys . , 53 , 484 bertschinger , , 58 , 39 binney , j. , & tremaine , s. 1987 , galactic dynamics ( princeton university press : princeton ) brandt , a. 1977 , mathematics of computation , 31 , 333 briggs , w. l. 1987 , a multigrid tutorial ( society of industrial and applied mathematics : philadelphia ) coln , p. , klypin , a. a. , kravtsov , a. v. , & khokhlov a. m. 1999 , , 523 , 32 ewald , p. p. 1921",
    "phys . , 64 , 253 fillmore , j. a. , & goldreich , p. 1984",
    ", , 281 , 1 gelato , s. , chernoff , d. f. , & wasserman , i. 1997 , , 480 , 115 hockney , r. w. , & eastwood , j. w. 1988 , computer simulation using particles ( institute of physics publishing : bristol ) jenkins , a. , frenk , c. s. , pearce , f. r. , thomas , p. a. , coleberg , j. m. , white , s. d. m. , couchman , h. m. p. , peacock , j. a. , efstathiou , g. , & nelson , a. h. 1998 , , 499 , 20 jessop , c. , duncan , m. , & chau , w. y. 1994 , j. comp .",
    "phys . , 115 , 339 khokhlov , a. m. 1998 , j. comp .",
    "phys . , 143 , 519 klypin , a. a. , primack , j. , & holtzman , j. 1996 , , 466 , 13 kravtsov , a. v. , klypin , a. a. , & khokhlov , a. m. 1997 , , 111 , 73 kravtsov , a. v. , klypin , a. a. , bullock , j. s. , & primack , j. 1998 , , 502 , 48 makino , j. 1991 , , 1991 , 43 , 859 navarro , j. f. , frenk , c. s. , & white s. d. m. 1996 , , 462 , 563 norman , m. l. & bryan , g. l. 1999 , in numerical astrophysics , ed . s. miyama , k. tomisaka & t. hanawa ( dordrecht : kluwer ) , 19 press , w. h. , teukolsky , s. a. , vetterling , w. t. , & flannery , b. p. 1992",
    ", numerical recipes 2nd ed .",
    "( cambridge university press : cambridge ) sangster , m. i. l. , & dixon , m. 1976 , adv .",
    "phys . , 25 , 247 splinter r. j. 1996 , , 281 , 281 suisalu , i. , & saar , e. 1995 , , 274 , 287 villumsen , j. v. 1989 , , 71 , 407 warren , m. s. , & salmon , j. k. , 1993 , in supercomputing 93 ( los alamitos : ieee computer society ) , 12 white , s. d. m. 1993 , in cosmology and large scale structure , les houches session lx , ed .",
    "r. schaeffer , j. silk , m. spiro , & j. zimn - justin ( amsterdam : elsevier ) , 349 yahagi , h. , mori , m. , & yoshii , y. 1999 , , 124 , 1 yahagi , h. , & yoshii , y. 2000 , in asp conf .",
    "ser . , physics of galaxy formation , ed .",
    "m. umemura , & h. susa ( san francisco : asp ) yano , t. , & gouda , n. 1998 , , 118 , 274 zeldovich , ya .",
    "b. 1970 , , 5 , 84"
  ],
  "abstract_text": [
    "<S> we have developed a simulation code with the techniques which enhance both spatial and time resolution of the pm method for which the spatial resolution is restricted by the spacing of structured mesh . </S>",
    "<S> the adaptive mesh refinement ( amr ) technique subdivides the cells which satisfy the refinement criterion recursively . </S>",
    "<S> the hierarchical meshes are maintained by the special data structure and are modified in accordance with the change of particle distribution . in general , as the resolution of the simulation increases , its time step must be shortened and more computational time is required to complete the simulation . since the amr enhances the spatial resolution locally , we reduce the time step locally also , instead of shortening it globally . </S>",
    "<S> for this purpose we used a technique of hierarchical time steps ( hts ) which changes the time step , from particle to particle , depending on the size of the cell in which particles reside . </S>",
    "<S> some test calculations show that our implementation of amr and hts is successful . </S>",
    "<S> we have performed cosmological simulation runs based on our code and found that many of halo objects have density profiles which are well fitted to the universal profile proposed by navarro , frenk , & white ( 1996 ) over the entire range of their radius . </S>"
  ]
}