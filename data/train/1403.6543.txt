{
  "article_text": [
    "direct numerical approaches based on molecular interactions have become standard computational , as well as modeling , tools nowadays for modeling molecular structures . for dynamics problems ,",
    "the trajectory of each atom can be described by the newton s equations of motion , @xmath0 this approach is the essences of the molecular dynamics ( md ) modeling .",
    "the interatomic potential @xmath1 embodies the interactions between particles ( atoms ) through the changes of bond lengths , bond angles , dihedral angles , electrostatics , van der waals etc @xcite .",
    "direct md simulations capture all the physics in a biological system , but they particularly suited for studying small scale transitions due to the computational complexity . meanwhile , most biological processes are intrinsically multiscale : the overall dynamics consists of large number of atoms associated with many different types of motions , spanning a wide range of time scales @xcite .",
    "in fact , typical biological functions begin at the @xmath2s time scale , which is far beyond the reach of direct md simulations .    to overcome this significant modeling difficulty , much effort has been devoted to developing coarse - grained ( cg ) molecular models to access processes on a longer time scale .",
    "problems of this type have been identified as one of the most important and challenging problems in molecule modeling @xcite .",
    "one of the key components in a cg model is to find out the direct interaction of the cg variables , represented , , by the many - body potential of mean force ( pmf ) @xcite . in a cg approach , this interaction , in terms of forces , can in principle be obtained by integrating out the remaining degrees of freedom @xcite .",
    "however in practice , approximation schemes have to be introduced , and the main issue for pmf is to ensure the consistency with the original full molecular interaction as well as to control the accuracy .",
    "we refer to the reviews @xcite for the recent progress and existing issues .",
    "the calculation of pmf is often formulated based on a thermodynamic consideration . in particular , one considers a system where the remaining degrees of freedom are at a conditional equilibrium .",
    "another remarkable approach is through the generalized langevin equations ( gle ) , which can be derived directly from the equations of motion using the mori - zwanzig ( mz ) projection formalism @xcite .",
    "the mode has been considered by many researchers over the years @xcite .",
    "the mz projection procedure , when the conditional expectation is used as projector , yields an averaged force , which is consistent with that in the pmf approach @xcite .",
    "in addition , the formalism gives rise to a _ history - dependent term _ , which with reasonable approximations , simplifies to a linear convolutional term with a memory function , and a _ random noise _",
    "term , which is consistent with the memory function via the second fluctuation - dissipation theorem ( fdt ) @xcite .    the main practical difficulty in implementing the gle is the computation of the memory function . in some cases ,",
    "markovian approximations can be made @xcite to reduce the gle to langevin equation , or one may simply use exponential functions @xcite , assuming a rapid decay .",
    "however , it is difficult to quantify and control the modeling error in such an ad hoc approximation . a more systematic approach is to related the memory function to correlation functions , , the velocity auto - correlation function ( vacf ) , which is computed from equilibrium md simulations .",
    "for instance , berkowitz et al @xcite considered a gle where the mean force term is linear , and then derived an integral equation of volterra type for the memory function . as input of the integral equation ,",
    "the correlation function of the velocity and position are obtained from md experiments .",
    "this has been the approach followed by many other groups @xcite . in general",
    ", the calculation of vacf tends to be expensive due to the large size of the system .",
    "more importantly , the sampling of the random noise is still a challenge . in this paper",
    ", we propose a more efficient approach to obtain the memory functions without performing direct md simulations .",
    "the method for computing the kernel functions is based on the krylov - subspace method , motivated by the numerical methods for evaluating matrix functions .",
    "we will present the algorithm , and detailed implementation procedure . as will be shown",
    ", this approach offers the added advantage that the random force term can be approximated in the same subspace , and it automatically satisfy the second fdt .",
    "it is important to point out that the memory functions will depend on how the cg variables are selected , and what reduction procedure is used .",
    "the point will be illustrated and clarified using two reduction methods , and three different selection schemes for the cg variables .",
    "the rest of the paper is organized as follows : we first discuss the reduction method of mori - zwanzig , from which we derive the exact expression of the memory functions .",
    "then , we present an efficient numerical algorithm to compute these functions .",
    "examples are given in the following section to demonstrate the effectiveness of the methods .",
    "the generalized langevin ( gle ) models can be derived from many different coarse graining procedures , , by using appropriate linearization procedure @xcite .",
    "a more systematic procedure is the mori - zwanzig projection formalism @xcite . here",
    "we will consider two different projection operators , and derive two types of gles models .",
    "in particular , we derive an explicit expression for the memory function .",
    "we start with the full molecular dynamics ( md ) model , @xmath3 here @xmath4 denotes the position of _ all _ the atoms .",
    "further , we let @xmath5 be the velocity .",
    "let us introduce a scaling , @xmath6 this reduces the equation to @xmath7 which is expressed in a vector form .",
    "the coarse - graining procedure will be applied to these rescaled equations . in particular , the position will be mass weighted .",
    "the collective motions are often represented in terms of the dynamics of a number of coarse - grained variables .",
    "we will define such variables through a projection to a subspace . toward this end , we let @xmath8 be the entire configuration space , and @xmath9 be a subspace with dimension @xmath10 ; @xmath11 .",
    "specific examples of such subspaces will be discussed later . to derive explicit formulas ,",
    "let us choose a set of orthonormal basis vectors of @xmath12 , denoted here by @xmath13 by grouping these vectors , we form a @xmath14 matrix @xmath15 .",
    "further , we let @xmath16 be an orthonormal basis for the orthogonal complement of the subspace @xmath12 , denoted by @xmath17 .",
    "they form a @xmath18 matrix @xmath19 . in practice , it is often difficult , if not impossible , to construct the matrix @xmath19",
    ". nevertheless , we will use this set of basis to express certain functions , and then we will discuss how to approximate these functions without actually computing @xmath19 .    to proceed , we define the cg variables through the projection to the subspace @xmath12 : @xmath20 where @xmath21 is the displacement to the equilibrium state @xmath22 .",
    "the displacement is often easier to work with , and we further switch the notation @xmath23 to @xmath24 since all the columns in @xmath15 are unit vectors , @xmath25 can be regarded as average position and average velocity , respectively .",
    "similarly , one can define @xmath26 and @xmath27 ; @xmath28 .",
    "they represent the additional degrees of freedom , referred to as _ under - resolved variables _ , and they will not appear explicitly in the cg models .",
    "it is clear now that for any @xmath29 or @xmath30 , we have a unique decomposition in the form of , @xmath31    the first step of the mz reduction procedure is to express the time evolution of the cg variables .",
    "this is best represented by a semi - group operator , _",
    "i.e. , _ for any dynamical variable @xmath32 , we have @xmath33 , where the operator @xmath34 is given by , @xmath35 as is customary in statistical mechanics theory , we use @xmath36 to denote the initial value , _",
    "@xmath37 , and these differential operators are defined with respect to the initial coordinate and momentum @xcite . more specifically , the solution ( @xmath38 and @xmath39 ) of the md model at time @xmath40 depends on the initial condition @xmath41 and @xmath30 .",
    "such dependence defines a symplectic mapping @xcite . as a result , any dynamic variable @xmath36 , as a function of @xmath38 and @xmath39 ,",
    "are also functions of @xmath41 and @xmath30 .",
    "the partial derivatives in @xmath34 should be calculated with respect to the initial condition .    in order to distinguish thermodynamic forces of different nature",
    ", one defines a projection operator @xmath42 , with its complementary operator given by @xmath43 .",
    "it can either be defined as a projection to a subspace @xcite or a conditional average @xcite .",
    "this will be discussed separately in the next section .    once the dynamic variables and the projection are defined , the mori - zwanzig procedure yields the effective model @xcite , @xmath44 where , @xmath45 and , @xmath46    the first term on the right hand side of is typically considered as the reversible thermodynamic force . the second term represents the history dependence and provides a more general form of frictional forces .",
    "it dictates the strong coupling with the under - resolved variables .",
    "the last term , @xmath47 , takes into account the influence of the under - resolved variables , in the form of a random force .",
    "next , we discuss the specific forms of the memory function and the random noise for different choices of the projection operator .      here",
    "we choose the following projection : for any function @xmath48 , or @xmath49 we define , @xmath50 the operator is a projection since @xmath51 this is motivated by the galerkin method for coarse - graining md models @xcite .",
    "if @xmath52 the mz equation is reduced to , @xmath53 no memory term arises from this equation .",
    "next , we let @xmath54",
    ". we will derive the cg model in several steps .",
    "first we start with the random noise @xmath47 . at @xmath55 , we find @xmath56 from .",
    "@xmath57.\\ ] ] in order to simplify this term , we introduce the approximation , @xmath58 in principle , one can choose @xmath59 .",
    "but here we let @xmath60 , i.e. , the hessian matrix of the potential energy at a local minimum @xmath22 , which has the same second order accuracy of approximation near the reference position .    with this approximation",
    ", we find that , @xmath61 applying the operator @xmath62 , we get , @xmath63 we proceed to compute @xmath64 . a direct calculation yields , @xmath65 which by a similar approximation , can be written as , @xmath66 similarly , @xmath67 @xmath68    repeating such calculations , we find that the random noise can be approximated by @xmath69,\\ ] ] where @xmath70 with @xmath71",
    ". this can be verified by examining the taylor expansion of the trigonometric functions .",
    "we now turn to the function @xmath72 with the approximation of @xmath47 , we obtain , @xmath73 to further simplify this , we make another approximation that @xmath74 in this expression , which leads to , @xmath75 this simplifies the integral to a convolutional form , @xmath76 where the @xmath77 matrix function @xmath78 is given by , @xmath79    collecting terms , we obtain the gle , @xmath80    the first term in the gle is related to the inter - molecular force as follows : @xmath81      another choice of the projection operator is the conditional expectative , which for the canonical ensemble , is given by , @xmath82\\\\ & \\stackrel{\\text{def}}{=}\\frac{\\dsp\\int_{\\mathbb{r}^{6n } } g(\\bm x,\\bm v)e^{-\\beta[v(\\bm x)+\\half\\bm v^2]}\\delta(\\bm q-\\phi^t\\bm x)\\delta(\\bm p-\\phi^t \\bm v)d\\bm xd\\bm v}{\\dsp\\int_{\\mathbb{r}^{6n}}e^{-\\beta[v(\\bm x)+\\half \\bm v^2]}\\delta(\\bm q-\\phi^t \\bm x)\\delta(\\bm p-\\phi^t\\bm v ) d\\bm xd\\bm v } \\end{split}\\ ] ] here @xmath83 is the inverse temperature , and the delta functions are introduced to enforce the given conditions",
    ".    again we start with the construction of the random noise in the mz equation . here",
    "we introduce two approximations .",
    "first , we let @xmath84 be an approximate hessian of the potential energy , and we approximate the projection by , @xmath85 } \\delta(\\bm q - \\phi^t \\bm x ) \\delta(\\bm p - \\phi^t \\bm v )    d\\bm x d\\bm v } { \\dsp\\int_{\\mathbb{r}^{6n } } e^{-\\beta[\\half \\bm x^t a \\bm x + \\half \\bm v^2 ] } \\delta(\\bm q - \\phi^t \\bm x ) \\delta(\\bm p - \\phi^t \\bm v )    d\\bm x d\\bm v}. \\end{split}\\ ] ] as a result , the expectation is with respect to a multi - variant gaussian distribution .",
    "the second approximation also involves the same linearization used in the previous section , @xmath86 to facilitate the following calculations , we define projection matrices @xcite , @xmath87 in particular , we have @xmath88 , and with the approximation , we have , @xmath89 therefore , the projection operator has been turned into a matrix - vector multiplication .",
    "the following identities can be easily verified , @xmath90    we proceed to compute the random noise . at @xmath55 , @xmath91 by invoking the two approximations , we find that , @xmath92 in addition , we have , @xmath93 repeating these steps , we have , @xmath94 again we defined @xmath71 .",
    "these calculations suggest that the random noise may be approximated by , @xmath95 , \\end{split}\\ ] ] which can be validated by checking each term in the taylor series .    with the approximation of @xmath47 , we can approximate @xmath96 by , @xmath97 here we have used the first and third identities in .    similar to the previous section , we neglect the second term using . as a result",
    ", we obtain a memory function , @xmath98 further , the memory term is reduced to a convolutional integral , @xmath99 notice that the memory function involves the coarse - grained momentum instead of the coarse - grained coordinate .    using the matrix identity @xcite ,",
    "@xmath100 we can simplify the memory function to , @xmath101    to get some insight , we let the eigenvalues of @xmath102 be @xmath103 , and let @xmath104 be the associated eigenvectors .",
    "then , we can express the kernel function as follows , @xmath105 further , let @xmath106 .",
    "this can be interpreted as the residual error , when @xmath103 is viewed as the approximate eigenvalue of @xmath107 obtained by a projection to the orthogonal complement .",
    "a direct substitution yields , @xmath108 intuitively , when the eigenvalues are well approximated within the initial subspace @xmath12 , they make less contribution to the memory function .    with the condition expectation chosen as the projection operator ,",
    "the first term in the mz equation has a natural interpretation .",
    "to explain this , we define the free energy by integrating out the under - resolved variables , @xmath109 then the first term in coincides with the mean force @xmath110 .",
    "now we can collect all the terms and the gle is expressed as , @xmath111    with the approximation of the probability density , we see that @xmath112 and @xmath113 follow the conditional distribution , @xmath114},\\ ] ] where @xmath115 .    in addition",
    ", we have @xmath116 therefore , the random process @xmath47 in is a gaussian process .",
    "furthermore , with direct calculation , we can verify that it is stationary with zero mean and it satisfies the second fluctuation - dissipation theorem ( fdt ) @xcite , @xmath117 based on the theory of gaussian processes @xcite , @xmath47 is uniquely determined by the correlation function .",
    "thus , the gle is closed .",
    "the fdt a critical property of the generalized langevin model .",
    "it is a necessary condition to ensure that the system will approach to a thermodynamic equilibrium @xcite .",
    "therefore , it is also important to preserve this condition at the level of numerical approximations .",
    "this will be discussed in the next section .",
    "in contrast , the random noise derived from the previous section is not stationary .",
    "however , notice that @xmath118 using integration by parts , one can show that the memory functions and random noises in the gles and can be related to one another . for the rest of the paper , we will focus on the gle and the memory function @xmath119 .",
    "the function @xmath120 can be computed using a similar procedure .",
    "in most of previous works , the memory functions are computed from molecular dynamics simulations . in this paper , we present another approach , based on the analytical expression of the kernel . due to the matrix function form , we will use the krylov subspace approximation , a popular method for computing matrix functions @xcite .",
    "next , we explain the general idea , and address some implementation issues .",
    "we first consider the approximation of @xmath121 to illustrate the idea .",
    "recall that @xmath71 , and so @xmath122 consider the vector @xmath123 for some @xmath124 , @xmath125 , and we define the krylov subspace with _ order _",
    "@xmath126 , @xmath127 with the standard lanczos algorithm @xcite , we can construct orthogonal basis vectors @xmath128 $ ] for @xmath129 .",
    "further , it reduces the matrix @xmath102 to the form , @xmath130 the last term , which is a rank - one matrix , contains the error .    as a result",
    ", we make the approximation @xmath131 therefore , the @xmath132 entry of @xmath121 can be approximated by , @xmath133 the vector @xmath134 is the standard basis vector .",
    "consequently , the computation of the inverse of a large matrix is reduced to the inversion of a much smaller , tri - diagonal , matrix @xmath135 @xcite .    for the present problem ,",
    "several issues arise :    1 .   both @xmath136 and the matrix @xmath102 are difficult to compute directly , since the basis functions @xmath137 are usually not available ; 2 .",
    "there are a number of basis vectors @xmath138 to begin with , and we need to compute the entire matrix @xmath119 .",
    "the standard krylov space method has to be implemented multiple times to obtain the entire matrix .    to overcome the first difficulty",
    ", we introduce a mathematically equivalent procedure based on the following observation .",
    "recall that @xmath139 , and we now define @xmath140 , and @xmath141 . it can be directly verified that , @xmath142    in addition ,    the lanczos algorithm , when applied to the subspace @xmath143 , yields the same results as those obtained from the lanczos algorithm applied to the subspace @xmath144    now in the krylov space @xmath145 , @xmath19 is not involved .",
    "further , @xmath146 . this can be drastically simplified when the basis functions in @xmath15 are localized .",
    "one such example is the rotational - translational block method ( rtb ) @xcite , which divides the entire molecule into non - overlapping blocks . in each block , the rotational and translational degrees of freedom can be selected as basis functions .",
    "the explicit formulas can be found in @xcite .",
    "when such basis functions are used , the matrix @xmath147 is block diagonal , and the matrix @xmath148 can be easily computed .",
    "in fact , the implementation of the above algorithm only involves the product of @xmath148 with another vector .",
    "the multiplication can be done separately in each block .    to address the second issue",
    ", we employ the _ block _ krylov method and _ block _ lanszos method .",
    "the application of the block krylov method can be found in @xcite .",
    "here we provide some details .",
    "we first let @xmath149 and define , @xmath150 the right hand side is interpreted as the linear combination of the columns of the matrices .",
    "it is a natural generalization of the krylov space . to obtain orthonormal basis for the subspace",
    ", we follow the steps below : + * algorithm . *",
    "( block lanczos ) set @xmath151 , @xmath152 and @xmath153 . for @xmath154 , repeat :    * * step 1 . * rank revealing qr factorization of the @xmath155 matrix @xmath156 : @xmath157 .",
    "@xmath158 may be a permuted upper triangular matrix .",
    "* * step 2 .",
    "* let @xmath159 @xmath160 be the first @xmath161 columns of @xmath162 , and @xmath163 be the first @xmath161 rows of @xmath158 ; * * step 3 .",
    "* @xmath164 ; * * step 4 .",
    "* @xmath165 ; * * step 5 . * @xmath166 .",
    "let @xmath167^t$ ] .",
    "we then have @xmath168 similarly , we have , @xmath169      we now turn to the random noise @xmath47 , which can also be sampled within the krylov subspace .",
    "more precisely , we state that ,    let @xmath170 be given by , @xmath171 where @xmath172 and @xmath173 are independent normal random variables with zero mean and variance @xmath174 and @xmath175 , respectively , then @xmath170 is stationary random noise with zero mean and the correlation is given by , @xmath176    as a result , the sampling of the random force is reduced to the sampling of low - dimensional quantities @xmath172 and @xmath173 .",
    "more importantly , the approximate random force @xmath170 and memory function @xmath177 still satisfy the fluctuation - dissipation theorem .",
    "in this section , we present some numerical results . as an example , we choose a hiv-1 protease whose pdb i d is 1dif .",
    "the protein contains 198 residues and 3128 atoms .",
    "the cartoon picture of the structure is shown in fig .",
    "[ pdbfig ] .",
    "the kernel functions depend on the choice of the coarse - grained variables .",
    "in particular , it depends on the initial subspace . here ,",
    "three different subspaces are considered :    * * subspace - i : * the subspace spanned by the rtb basis corresponding to the translations and rotations of rigid blocks .",
    "the partition of the blocks is obtained from the partition scheme first @xcite .",
    "the implementation was done by using the software proflex .",
    "the dimension of the subspace is 380 . * * subspace - ii : * the subspace generated by the rtb basis functions with each residue as a rigid block .",
    "there are 1188 basis functions in total . * * subspace - iii : * the subspace spanned by 540 low frequency modes , obtained from the principle component analysis ( pca ) @xcite . to obtain the basis functions ,",
    "trajectories are generated from direct molecular dynamics simulations .",
    "these basis functions may not be localized .",
    "nonetheless , we still choose this subspace due to its importance in dimension reduction .    for each subspace",
    ", we use the krylov subspace methods and compute the approximate memory functions in ( [ approx3 ] ) . for comparison",
    ", we also computed the exact memory function using brutal force .",
    "the kernel functions have the unit of @xmath178 .    in fig .",
    "[ fig1 ] - [ fig5 ] , we show the profiles of the entries @xmath179 , @xmath180 and @xmath181 , @xmath182 of the kernel function @xmath119 within a time period of 0.1ps obtained from different computational methods and different coarse grained subspaces . based on these figures",
    ", we can see that the krylov space method produces good approximations of the kernel functions , especially at the beginning period .",
    "another observation is that these memory functions do not exhibit fast decay at this scale .",
    "instead , they exhibit many oscillations , which indicate that a markovian or exponential approximation is premature .",
    "currently the order of the krylov subspace in these examples are 4 .",
    "if we increase the order of the krylov subspace , the approximations will further improve , see fig .",
    "[ fig6 ] .     and @xmath180 of the exact kernel function ( lines without markers ) produced by brutal - force computation according to ( [ kernel ] ) and approximated kernel ( [ approx3 ] ) using the krylov space method ( lines with markers ) with order 4 .",
    "these two entries are corresponding to the correlations of the noises in the first two translational modes of the first rigid block.[fig1],width=340,height=188 ]    ) and the approximated kernel ( [ approx3 ] ) using the krylov space method and subspace - ii ( lines with markers ) .",
    "these two entries are corresponding to the correlations of the noises in the first two translational modes of the first rigid block .",
    "the order of the krylov space is 4.,width=340,height=188 ]    ) using krylov space method ( lines with markers ) with order 4 .",
    "these two entries are corresponding to the correlations of the noises in the first two rotational modes of the first rigid block.,width=340,height=188 ]                 fig .",
    "[ fig2 ] also indicates that the memory functions for the residue - based subspaces look smoother .",
    "this is because the residue - based subspaces admit more low frequency modes than those of rigid bodies from the partitions of proflex .",
    "next , we consider the same type of partitions ( subspace -ii based on residues ) , but with different block sizes . in particular , we first start with a fine partition , in which each residue is a block .",
    "we then form a coarser partition , where there are 3 residues in each block ( it is clear that this partition is not based on the flexibility of the molecule ) .",
    "one observes from fig .",
    "[ fig7 ] that the memory functions become smaller for the coarser partition .",
    "to further confirm this observation , we divide the entire system equally into 22 blocks with 9 residues in each block . we also form a 6-block partition , each of which contains 33 residues .",
    "the results , shown in fig .",
    "[ fig8 ] , exhibit the same trend : as we coarse - grain more and more , the memory functions become smaller and smaller .",
    "in this paper , we have presented a methodology to compute memory functions which are important parameters in the generalized langevin model .",
    "computing such memory functions directly from molecular dynamics simulations would require extensive effort .",
    "in contrast , the method proposed here relies on a technique in numerical linear algebra , and it can be implemented without performing molecular simulations .",
    "we have also demonstrated that under the current framework , the random noise term in the generalized langevin equation can be consistently approximated . to our knowledge , none of the existing methods offers such advantage .",
    "together with the average force @xmath183 , the generalized langevin equation can be solved to describe the collective motion of the system .",
    "this is work in progress .",
    "the work has been partially supported by nsf grants dms1109107 , dms-1216938 , and dms-1159937 .",
    "this work was initialized during chen s visitation to the department of mathematics , at the pennsylvania state university .",
    "he would like to thank the hospitality of the department .",
    "chen was supported by the china nsf ( nsfc11301368 ) and the nsf of jiangsu province ( bk20130278 ) .",
    "48ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ] ",
    "+ 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty @noop _",
    "_  ( ,  ) @noop _ _  ( , ) @noop * * ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * , ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * , ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * , ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop _ _  ( ,  ) @noop _ _  ( , ) @noop _ _  ( , ) @noop _ _ ,  vol .",
    "( ,  ) @noop * * ( ) @noop _ _  ( ,  ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop _ _ ,  ed .",
    "( ,  ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop _ _  ( , ) @noop * * ,   ( ) @noop * * ,   ( ) @noop _ _  ( ,  )"
  ],
  "abstract_text": [
    "<S> we present a numerical method to compute the approximation of the memory functions in the generalized langevin models for collective dynamics of macromolecules . </S>",
    "<S> we first derive the exact expressions of the memory functions , obtained from projection to subspaces that correspond to the selection of coarse - grain variables . </S>",
    "<S> in particular , the memory functions are expressed in the forms of matrix functions , which will then be approximated by krylov - subspace methods . </S>",
    "<S> it will also be demonstrated that the random noise can be approximated under the same framework , and the fluctuation - dissipation theorem is automatically satisfied . </S>",
    "<S> the accuracy of the method is examined through several numerical examples . </S>"
  ]
}