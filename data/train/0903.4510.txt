{
  "article_text": [
    "consider the following problems :    assign people using a social network to one of two servers so that most pairs of friends are assigned to the same server .",
    "open some number of hiv treatment centers so that the average commute time for patients is small .",
    "open a small number of drop - off centers for undercover agents so that each agent is able to visit some site convenient to her ( each providing a list of acceptable sites ) .",
    "the above problems can be modeled as instances of well - known combinatorial optimization problems : respectively the minimum cut problem , the @xmath0-median problem , and the set cover problem .",
    "good heuristics have been designed for these problems , and hence they may be considered well - studied and solved . however , in the above scenarios and in many others , the input data ( friendship relations , medical history , agents locations ) represent sensitive information about individuals .",
    "data privacy is a crucial design goal , and it may be vastly preferable to use a private algorithm that gives somewhat suboptimal solutions to a non - private optimal algorithm .",
    "this leads us to the following central questions : _ given that the most benign of actions possibly leaks sensitive information , how should we design algorithms for the above problems ? what are the fundamental trade - offs between the utility of these algorithms and the privacy guarantees they give us ? _",
    "the notion of privacy we consider in this paper is that of _ differential privacy_. informally , differential privacy guarantees that the distribution of outcomes of the computation does not change significantly when one individual changes her input data .",
    "this is a very strong privacy guarantee : anything significant about any individual that an adversary could learn from the algorithm s output , he could also learn were the individual not participating in the database at all  and this holds true no matter what auxiliary information the adversary may have . this definition guarantees privacy of an individual s sensitive data , while allowing the computation to respond when a large number of individuals change their data , as any useful computation must do .      in this paper",
    "we initiate a systematic study of designing algorithms for combinatorial optimization problems under the constraint of differential privacy . here is a short summary of some of the main contributions of our work .    *",
    "while the exponential mechanism of @xcite is an easy way to obtain _ computationally inefficient _ private approximation algorithms for some problems , the approximation guarantees given by a direct application of this can be far from optimal ( e.g. , see our results on min - cut and weighted set cover ) .",
    "in these cases , we have to use different techniques",
    " often more sophisticated applications of the exponential mechanism  to get good ( albeit computationally expensive ) solutions .",
    "* however , we want our algorithms to be _ computationally efficient _ and _ private _ at the same time : here we can not use the exponential mechanism directly , and hence we develop new algorithmic ideas .",
    "we give private algorithms for a wide variety of _ search _ problems , where we must not only approximate the _ value _ of the solution , but also produce a solution that optimizes this value .",
    "see for our results .",
    "* for some problems , unfortunately , just outputting an explicit solution might leak private information .",
    "for example , if we output a vertex cover of some graph explicitly , any pair of vertices not output reveals that they do not share an edge so any private explicit vertex cover algorithm must output @xmath1 vertices . to overcome this hurdle",
    ", we instead privately output an implicit representation of a small vertex cover we view vertex cover as a location problem , and output an orientation of the edges .",
    "each edge can cover itself using the end point that it points to .",
    "the orientation is output privately , and the resulting vertex cover approximates the optimal vertex cover well .",
    "we deal with similar representational issues for other problems like set cover as well .",
    "* we also show lower bounds on the approximation guarantees regardless of computational considerations .",
    "for example , for vertex cover , we show that any @xmath2-differentially private algorithm must have an approximation guarantee of @xmath3 .",
    "we show that each of our lower bounds are tight : we give ( computationally inefficient ) algorithms with matching approximation guarantees . *",
    "our results have implications beyond privacy as well : papadimitriou et al .",
    "@xcite introduce the _ combinatorial public project _",
    "problem , a special case of submodular maximization , and show that the problem can be well approximated by either a truthful mechanism or an efficient algorithm , but not by both simultaneously .",
    "in contrast to this negative result , we show that under differential privacy ( which can be interpreted as an approximate but robust alternative to truthfulness ) we can achieve the same approximation factor as the best non - truthful algorithm , plus an additive logarithmic loss . *",
    "finally , we develop a private amplification lemma : we show how to take private algorithms that gives bounds in expectation and efficiently convert them ( privately ) into bounds with high probability .",
    "this answers an open question in the paper of feldman et al .",
    "@xcite .    [ cols=\">,^,^,^,^\",options=\"header \" , ]     summarizes the bounds we prove in this paper . for each problem , it reports ( in the first column ) the best known non - private approximation guarantees , ( in the second column ) our best efficient @xmath2-differentially private algorithms , and in each ( in the third column ) case matching upper and lower bounds for inefficient @xmath2-differentially private algorithms . for a few of the efficient algorithms ( marked with a @xmath4 ) the guarantees are only for an approximate form of differential privacy , incorporating a failure probability @xmath5 , and scaling the effective value of @xmath2 up by @xmath6 .",
    "differential privacy is a relatively recent privacy definition ( e.g. , see  @xcite , and see @xcite for an excellent survey ) , that tries to capture the intuition of individual privacy .",
    "many algorithms in this framework have focused on measurement , statistics , and learning tasks applied to statistical data sets , rather than on processing and producing combinatorial objects .",
    "one exception to this is the exponential mechanism of @xcite which allows the selection from a set of discrete alternatives .",
    "independently , feldman et al .",
    "@xcite also consider the problem of privately approximating @xmath0-medians for points in @xmath7 .",
    "their model differs slightly from ours , which makes the results largely incomparable : while our results for general metrics translated to @xmath7 give smaller additive errors than theirs , we only output a @xmath0-median approximation whereas they output coresets for the problem .",
    "their lower bound argument for private coresets is similar to ours .",
    "prior work on secure function evaluation ( sfe ) tells us that in fact the minimum cut in a graph can be computed in a distributed fashion in such a way that computations _ reveals nothing that can not be learnt from the output of the computation_. while this is a strong form of a privacy guarantee , it may be unsatisfying to an individual whose private data can be inferred from the privately computed output .",
    "indeed , it is not hard to come up with instances where an attacker with some limited auxiliary information can infer the presence or absence of specific edges from local information about the minimum cut in the graph . by relaxing the whole input privacy requirement of sfe ,",
    "differential privacy is able to provide unconditional per element privacy , which sfe need not provide if the output itself discloses properties of input .",
    "feigenbaum et al .",
    "@xcite extend the notion of sfe to np hard problems for which efficient algorithms must output an approximation to the optimum , unless p = np .",
    "they defined as _ functional privacy _",
    "the constraint that two inputs with the same output value ( e.g. the size of an optimal vertex cover ) must produce the same value under the approximation algorithm . under this constraint , halevi et al .",
    "@xcite show that approximating the value of vertex cover to within @xmath8 is as hard as computing the value itself , for any constant @xmath9 .",
    "these hardness results were extended to _ search _ problems by beimel et al .",
    "@xcite , where the constraint is relaxed to only equate those inputs whose sets of optimal solutions are identical .",
    "these results were extended and strengthened by beimel et al .",
    "@xcite .",
    "nonetheless , feigenbaum et al .",
    "@xcite and others show a number of positive approximation results under versions of the functional privacy model .",
    "halevi et al .",
    "@xcite provide positive results in the function privacy setting when the algorithm is permitted to leak few bits ( each equivalence class of input need not produce identical output , but must be one of at most @xmath10 possible outcomes ) .",
    "indyk and woodruff also give some positive results for the approximation of @xmath11 distance and a nearest neighbor problem @xcite .",
    "however , as functional privacy extends sfe , it does not protect sensitive data that can be inferred from the output .",
    "nevertheless , sfe provides an implementation of any function in a distributed setting such that nothing other than the output of the function is revealed .",
    "one can therefore run a differentially private algorithm is a distributed manner using sfe ( see e.g.  @xcite ) , in the absence of a trusted curator .",
    "differential privacy is a privacy definition for computations run against sensitive input data sets .",
    "its requirement , informally , is that the computation behaves nearly identically on two input data sets that are nearly identical ; the probability of any outcome must not increase by more than a small constant factor when the input set is altered by a single element .",
    "formally ,    we say a randomized computation @xmath12 has @xmath2-_differential privacy _ if for any two input sets @xmath13 and @xmath14 with symmetric difference one , and for any set of outcomes @xmath15 , @xmath16 & \\le & \\exp(\\epsilon ) \\times { { \\bf pr}}[m(b ) \\in s ] \\ ; .",
    "\\end{aligned}\\ ] ]    the definition has several appealing properties from a privacy perspective .",
    "one that is most important for us is that arbitrary sequences of differentially private computations are also differentially private , with an @xmath2 parameter equal to the sum of those comprising the sequence .",
    "this is true even when subsequent computations can depend on and incorporate the results of prior differentially private computations  @xcite , allowing repetition of differentially private steps to improve solutions .",
    "one relaxation of differential privacy @xcite allows a small additive term in the bound :    we say a randomized computation @xmath12 has @xmath5-_approximate _ @xmath2-_differential privacy _ if for any two input sets @xmath13 and @xmath14 with symmetric difference one , and for any set of outcomes @xmath17 , = 1 @xmath18 & \\le & \\exp(\\epsilon ) \\times { { \\bf pr}}[m(b ) \\in s ] + \\delta\\ ; .",
    "\\end{aligned}\\ ] ] @xmath19 & \\le & \\exp(\\epsilon ) \\times { { \\bf pr}}[m(b ) \\in s ] + \\delta\\ ; .",
    "\\end{aligned}\\ ] ]    the flavor of guarantee is that although not all events have their probabilities preserved , the alteration is only for very low probability events , and is very unlikely to happen .",
    "the @xmath5 is best thought of as @xmath20 for a data set containing some subset of @xmath21 candidate records .",
    "we note that there are stronger notions of approximate differential privacy ( c.f .",
    "@xcite ) , but in our settings , they are equivalent upto @xmath22 changes in @xmath5 . we therefore restrict ourselves to this definition here .",
    "one particularly general tool that we will often use is the exponential mechanism of @xcite .",
    "this construction allows differentially private computation over arbitrary domains and ranges , parametrized by a query function @xmath23 mapping a pair of input data set @xmath13 ( a multiset over some domain ) and candidate result @xmath24 to a real valued `` score '' . with @xmath25 and a target privacy value @xmath2 , the mechanism selects an output with exponential bias in favor of high scoring outputs : @xmath26 & \\propto & \\exp(\\epsilon q(a , r ) )",
    "\\ ; .\\end{aligned}\\ ] ]    if the query function @xmath25 has the property that any two adjacent data sets have score within @xmath27 of each other , for all possible outputs @xmath24 , the mechanism provides @xmath28-differential privacy .",
    "typically , we would normalize @xmath25 so that @xmath29 .",
    "we will be using this mechanism almost exclusively over discrete ranges , where we can derive the following simple analogue of a theorem of @xcite , that the probability of a highly suboptimal output is exponentially low :    the exponential mechanism , when used to select an output @xmath30 gives @xmath28-differential privacy , letting @xmath31 be the subset of @xmath32 achieving @xmath33 , ensures that = 1 @xmath34 & \\le & \\exp(-t ) \\ ; .",
    "\\end{aligned}\\ ] ] @xmath35\\ ] ] @xmath36    the proof of the theorem is almost immediate : any outcome with score less than @xmath37 will have normalized probability at most @xmath38 ; each has weight at most @xmath39 , but is normalized by at least @xmath40 from the optimal outputs .",
    "as there are at most @xmath41 such outputs their cumulative probability is at most  @xmath42 .",
    "given a graph @xmath43 the minimum cut problem is to find a cut @xmath44 so as to minimize @xmath45 . in absence of privacy constraints , this problem is efficiently solvable exactly .",
    "however , outputting an exact solution violates privacy , as we show in section [ sec : mincut - lb ] .",
    "thus , we give an algorithm to output a cut within additive @xmath46 edges of optimal .",
    "the algorithm has two stages : first , given a graph @xmath47 , we add edges to the graph to raise the cost of the min cut to at least @xmath48 , in a differentially private manner .",
    "second , we deploy the exponential mechanism over all cuts in the graph , using a theorem of karger to show that for graphs with min cut at least @xmath48 the number of cuts within additive @xmath49 of opt  increases no faster than exponentially with @xmath49 .",
    "although the exponential mechanism takes time exponential in @xmath21 , we can construct a polynomial time version by considering only the polynomially many cuts within @xmath50 of opt .",
    "below , let @xmath51 denote the size @xmath52 of the cut @xmath44 in a graph @xmath53 .",
    "* input : * @xmath43,@xmath2 .",
    "* let * @xmath54 be arbitrary strictly increasing sets of edges on @xmath55 .",
    "* choose * index @xmath56 $ ] with probability proportional to @xmath57 .",
    "* choose * a subset @xmath58 with probability proportional to @xmath59 .",
    "* output * the cut @xmath60 .",
    "our result relies on a result of karger about the number of near - minimum cuts in a graph  @xcite    [ kargerlemma ] for any graph @xmath47 with min cut @xmath61 , there are at most @xmath62 cuts of size at most @xmath63 .    by enlarging the size of the min cut in @xmath64 to at least @xmath65",
    ", we ensure that the number of cuts of value @xmath66 is bounded by @xmath67 .",
    "the downweighting of the exponential mechanism will be able to counteract this growth in number and ensure that we select a good cut .",
    "for any graph @xmath47 , the expected cost of alg is at most @xmath68 .",
    "first , we argue that the selected index @xmath69 satisfies @xmath70 with probability at least @xmath71 . for @xmath72 , equation",
    "[ eqn : expmech ] ensures that the probability of exceeding the optimal choice ( @xmath73 ) by @xmath74 is at most @xmath75 .",
    "likewise , for @xmath76 , there is some optimal @xmath77 achieving min cut size @xmath78 , and the probability we end up farther away than @xmath48 is at most @xmath71 .",
    "assuming now that @xmath79 , karger s lemma argues that the number @xmath80 of cuts in @xmath64 of cost at most @xmath81 is at most @xmath82 .",
    "as we are assured a cut of size @xmath83 exists , each cut of size @xmath84 will receive probability at most @xmath85 .",
    "put together , the probability of a cut exceeding @xmath86 is at most = 1 @xmath87 & \\le & \\sum_{t > b } \\exp(-\\epsilon t ) ( c_t - c_{t-1 } ) \\\\    & \\le & ( \\exp(\\epsilon)-1)\\sum_{t > b } \\exp(-\\epsilon t ) c_t \\\\    & \\le & ( \\exp(\\epsilon)-1)\\sum_{t > b } \\exp(-\\epsilon t/2 ) n^2 \\end{aligned}\\ ] ] @xmath88 \\\\    & \\le   \\sum_{t > b } \\exp(-\\epsilon t ) ( c_t - c_{t-1})\\\\    & \\le   ( \\exp(\\epsilon)-1)\\sum_{t > b } \\exp(-\\epsilon t ) c_t \\\\    & \\le   ( \\exp(\\epsilon)-1)\\sum_{t > b } \\exp(-\\epsilon",
    "t/2 ) n^2 \\end{aligned}\\ ] ] the sum telescopes to @xmath89 , and the denominator is within a constant factor of the leading factor of @xmath90 , for @xmath91 . for @xmath92 ,",
    "this probability becomes at most @xmath93 .    the algorithm above preserves @xmath94-differential privacy .",
    "note that the first instance of the exponential mechanism in our algorithm runs efficiently ( since it is selecting from only @xmath95 objects ) , but the second instance does not .",
    "we now describe how to achieve @xmath96-differential privacy efficiently .",
    "first recall that using karger s algorithm we can efficiently ( with high probability ) generate all cuts of size at most @xmath97 for any constant @xmath0 .",
    "indeed it is shown in  @xcite that in a single run of his algorithm , any such cut is output with probability at least @xmath98 so that @xmath99 runs of the algorithm will output all such cuts except with an exponentially small probability .",
    "our efficient algorithm works as follows : in step 4 of algorithm  [ alg : mincut ] , instead of sampling amongst all possible cuts , we restrict attention to the set of cuts generated in @xmath100 runs of karger s algorithm .",
    "we claim that the output distribution of this algorithm has statistical distance @xmath101 from that of algorithm  [ alg : mincut ] , which would imply that we get @xmath102-differential privacy .",
    "consider a hypothetical algorithm that generates the cut @xmath44 as in algorithm  [ alg : mincut ] but then outputs whenever this cut is not in the set of cuts generated by @xmath100 runs of karger s .",
    "we first show that the probability that this algorithm outputs is @xmath103 . as shown above , @xmath83 is at least @xmath104 except with probability @xmath105 .",
    "conditioned on this , the cut chosen in step 4 has cost at most @xmath106 except with probability @xmath105 . since",
    "each such cut is in the sample except with exponentially small probability , the claim follows .",
    "finally , note that this hypothetical algorithm can be naturally coupled with both the algorithms so that the outputs agree whenever the former does nt output .",
    "this implies the claimed bound on the statistical distance .",
    "we remark that we have not attempted to optimize the running time here ; both the running time and the value of @xmath5 can be improved by choosing a larger constant ( instead of 8) in step 3 , at the cost of increasing the additive error by an additional constant .",
    "we next show that this additive error is unavoidable for any differentially private algorithm .",
    "the lower bound is information - theoretic and thus applies also to computationally inefficient algorithms .",
    "any @xmath2-differentially private algorithm for min - cut must incur an expected additive @xmath107 cost over opt , for any @xmath108 .",
    "consider a @xmath109-regular graph @xmath110 on @xmath21 vertices such that the minimum cuts are exactly those that isolate a single vertex , and any other cut has size at least @xmath111 ( a simple probabilistic argument establishes the existence of such a @xmath47 ; in fact a randomly chosen @xmath109-regular graph has this property with high probability ) .",
    "let @xmath12 be an @xmath2-differentially private algorithm for the min - cut .",
    "given the graph @xmath47 , @xmath12 outputs a partition of @xmath55 .",
    "since there are @xmath112 singleton cuts , there exists a vertex @xmath113 such that the mechanism @xmath12 run on @xmath47 outputs the cut @xmath114 with probability at most @xmath115 , i.e. @xmath116    now consider the graph @xmath117 , with the edges incident on @xmath113 removed from @xmath47 , i.e. @xmath118 . since @xmath12 satisfies @xmath2-differential privacy and @xmath119 and @xmath120 differ in at most @xmath121 edges , @xmath122 \\leq 1/n^{1/3}.\\ ] ]    thus with probability @xmath123 , @xmath124 outputs a cut other than the minimum cut @xmath125 .",
    "but all other cuts , even with these edges removed , cost at least @xmath126 . since optis zero for @xmath127",
    ", the claim follows .",
    "we next consider a private version of the metric @xmath0-median problem : there is a pre - specified set of points @xmath55 and a metric on them , @xmath128 .",
    "there is a ( private ) set of demand points @xmath129 .",
    "we wish to select a set of medians @xmath130 with @xmath131 to minimize the quantity @xmath132 where @xmath133 .",
    "let @xmath134 be the diameter of the space .    as we show in section [ sec : kmedian - lb ] , any privacy - preserving algorithm for @xmath0-median must incur an additive loss of @xmath135 , regardless of computational constraints .",
    "we observe that running the exponential mechanism to choose one of the @xmath136 subsets of medians gives an ( computationally inefficient ) additive guarantee .",
    "using the exponential mechanism to pick a set of @xmath0 facilities gives an @xmath137-time @xmath2-differentially private algorithm that outputs a solution with expected cost @xmath138 .",
    "we next give a polynomial - time algorithm that gives a slightly worse approximation guarantee .",
    "our algorithm is based on the local search algorithm of arya _ et al . _",
    "we start with an arbitrary set of @xmath0 medians , and use the exponential mechanism to look for a ( usually ) improving swap . after running this local search for a suitable number of steps , we select a good solution from amongst the ones seen during the local search .",
    "the following result shows that if the current solution is far from optimal , then one can find improving swaps .",
    "for any set @xmath139 with @xmath140 , there exists a set of @xmath0 swaps @xmath141 such that @xmath142 .",
    "[ swapcorollary ] for any set @xmath139 with @xmath140 , there exists some swap @xmath143 such that @xmath144    * input : * @xmath55 , demand points @xmath145 , @xmath0,@xmath2 .",
    "* let * @xmath146 arbitrarily with @xmath147 , @xmath148 .",
    "select @xmath149 with probability proportional to @xmath150 .",
    "* let * @xmath151 .",
    "select @xmath152 from @xmath153 with probability proportional to @xmath154 .",
    "* output * @xmath155 .",
    "[ thm : kmedian ] setting @xmath156 and @xmath157 , the @xmath0-median algorithm provides @xmath2-differential privacy and except with probability @xmath158 outputs a solution of cost at most @xmath159 .",
    "we first prove the privacy .",
    "since the @xmath160 function has sensitivity @xmath27 , step  4 of the algorithm preserves @xmath161 differential privacy .",
    "since step  4 is run at most @xmath162 times and privacy composes additively , outputting all of the @xmath162 candidate solutions would give us @xmath163 differential privacy .",
    "picking out a good solution from the @xmath162 candidates costs us another @xmath161 , leading to the stated privacy guarantee .",
    "we next show the approximation guarantee . by corollary [ swapcorollary ] , so long as @xmath164 , there exists a swap @xmath143 that reduces the cost by at least @xmath165 . as there are only @xmath166 possible swaps",
    ", the exponential mechanism ensures through that we are within additive @xmath167 with probability at least @xmath71 . when @xmath168 , with probability @xmath71 we have @xmath169 .",
    "this multiplicative decrease by @xmath170 applies for as long as @xmath168 .",
    "since @xmath171 , and @xmath172 , there must exist an @xmath173 such that @xmath174 , with probability at least @xmath175 .",
    "finally , by applying the exponential mechanism again in the final stage , we select from the @xmath176 scoring within an additive @xmath177 of the optimal visited @xmath176 with probability at least @xmath71 , again by . plugging in the value of @xmath178 , we get the desired result .",
    "increasing the constants in the additive term can drive the probability of failure to an arbitrarily small polynomial .",
    "[ thm : kmed - lbd ] any @xmath2-differentially private algorithm for the @xmath0-median problem must incur cost @xmath179 on some inputs .",
    "consider a point set @xmath180\\times[l]$ ] of @xmath181 points , with @xmath182 , and a distance function @xmath183 whenever @xmath184 and @xmath185 .",
    "let @xmath12 be a differentially private algorithm that takes a subset @xmath145 and outputs a set of @xmath0 locations , for some @xmath186 .",
    "given the nature of the metric space , we assume that @xmath12 outputs a @xmath0-subset of @xmath187 $ ] . for a set",
    "@xmath188 $ ] , let @xmath189 $ ] .",
    "let @xmath13 be a size-@xmath0 subset of @xmath55 chosen at random .",
    "we claim that that @xmath190 \\leq \\frac{k}{2}$ ] for any @xmath2-differentially private algorithm @xmath12 .",
    "before we prove this claim , note that it implies the expected cost of @xmath191 is @xmath192 , which proves the claim since @xmath193 .    now to prove the claim : define @xmath194 $ ] .",
    "we can rewrite = 1 @xmath195 = k \\cdot { \\mathbf{\\mathbb{e}}}_{i\\in        [ n]}{\\mathbf{\\mathbb{e}}}_{a\\setminus\\{i\\},m}[\\mathbf{1}_{i \\in m(d_a ) } ]    \\end{gathered}\\ ] ] @xmath196 \\\\&= & k \\cdot { \\mathbf{\\mathbb{e}}}_{i\\in        [ n]}{\\mathbf{\\mathbb{e}}}_{a\\setminus\\{i\\},m}[\\mathbf{1}_{i \\in m(d_a ) } ]    \\end{aligned}\\ ] ] now changing @xmath13 to @xmath197 for some random @xmath198 requires altering at most @xmath199 elements in @xmath200 , which by the differential privacy guarantee should change the probability of the output by at most @xmath201 . hence @xmath202}{\\mathbf{\\mathbb{e}}}_{a',m}[\\mathbf{1}_{i \\in",
    "m(d_{a ' } ) } ] \\geq \\phi \\cdot      ( k / n)^{1/5}.    \\end{gathered}\\ ] ] but the expression on",
    "the left is just @xmath203 , since there at at most @xmath0 medians .",
    "hence @xmath204 , which proves the claim .",
    "[ cor : facloc - lbd ] any @xmath205-differentially private algorithm for uniform facility location that outputs the set of chosen facilities must have approximation ratio @xmath206 .",
    "we consider instances defined on the uniform metric on @xmath21 points , with @xmath207 for all @xmath208 , and facility opening cost @xmath209 . consider a @xmath205-differentially private mechanism @xmath12 when run on a randomly chosen subset @xmath13 of size @xmath210 .",
    "since @xmath211 is @xmath212 for these instances , any @xmath213-approximation must select at least @xmath214 locations from @xmath13 in expectation . by an argument analogous to the above theorem , it follows that any differentially private @xmath12 must output @xmath215 of the locations in expectation .",
    "this leads to a facility opening cost of @xmath206 .",
    "et al . _",
    "@xcite study private coresets for the @xmath0-median problem when the input points are in @xmath7 . for @xmath216 points in the unit ball in @xmath7 , they give coresets with @xmath217 multiplicative error , and additive errors about @xmath218 and @xmath219 respectively for their inefficient and efficient algorithms . since euclidean @xmath0-median has a ptas , this leads to @xmath0-median approximations with the same guarantees .",
    "we can translate our results to their setting by looking at a @xmath220-net of the unit ball as the candidate set of @xmath21-points , of which some may appear .",
    "this would lead to an inefficient algorithm with additive error @xmath221 , and an efficient algorithm with additive error @xmath222 .",
    "the latter has a multiplicative error of 6 and hence our efficient algorithms are incomparable .",
    "note that coresets are more general objects than just the @xmath0-median solution .",
    "we now turn to the problem of ( unweighted ) vertex cover , where we want to pick a set @xmath223 of vertices of minimal size so that every edge in the graph is incident to at least one vertex in @xmath223 . in the privacy - preserving version of the problem , the private information we wish to conceal is the presence of absence of each edge .    _ approximating the vertex cover . _ as mentioned earlier , even approximating the vertex cover size was shown to be polynomially inapproximable under the constraint of _ functional _ privacy  @xcite .",
    "on the other hand , it is easy to approximate the size of the optimal vertex cover under differential privacy : twice the size of a maximum matching is a 2-approximation to the optimal vertex cover , and this value only changes by at most two with the presence or absence of a single edge .",
    "hence , this value plus @xmath224 noise provides @xmath2-differential privacy  @xcite .",
    "( here it is important that we use _ maximum _ rather than just maximal matchings , since the size of the latter is not uniquely determined by the graph , and the presence or absence of an edge may dramatically alter the size of the solution . )",
    "interestingly enough , for _ weighted _ vertex cover with maximum weight @xmath225 ( which we study in ) , we have to add in @xmath226 noise to privately estimate the weight of the optimal solution , which can be much larger than @xmath211 itself . the mechanism in avoids this barrier by outputting an implicit representation of the vertex cover , and",
    "hence gives us a @xmath227 multiplicative approximation with @xmath2-differential privacy .",
    "_ the vertex cover problem .",
    "_ if we want to find a vertex cover ( and not just estimate its size ) , how can we do this privately ?",
    "in covering problems , the ( private ) data imposes hard constraints on the a solution , making them quite different from , say , min - cut .",
    "indeed , while the private data only influences the _ objective function _ in the min - cut problem , the data determines the _ constraints _ defining feasible solutions in the case of the vertex cover problem .",
    "this hard covering constraint make it impossible to actually output a small vertex cover privately : as noted in the introduction , any differentially private algorithm for vertex cover that outputs an explicit vertex cover ( a subset of the @xmath21 vertices ) must output a cover of size at least @xmath1 with probability 1 on any input , an essentially useless result .    in order to address this challenge ,",
    "we require our algorithms to output an _ implicit representation _ of a cover : we privately output an orientation of the edges .",
    "now for each edge , if we pick the endpoint that it points to , we clearly get a vertex cover .",
    "our analysis ensures that this vertex cover has size not much larger than the size of the optimal vertex cover for the instance .",
    "hence , such an orientation may be viewed as a privacy - preserving set of instructions that allows for the construction of a good vertex cover in a distributed manner : in the case of the undercover agents mentioned in the introduction , the complete set of active dropoff sites ( nodes ) is not revealed to the agents , but an orientation on the edges tells each agent which dropoff site to use , if she is indeed an active agent .",
    "our algorithms in fact output a permutation of all the vertices of the graph . each edge can be considered oriented towards the endpoint appearing earlier in the permutation .",
    "our lower bounds apply to the more general setting where we are allowed to output any orientation ( and hence are stronger ) .",
    "our ( randomized ) algorithm will output a permutation , and the vertex cover will be defined by picking , for each edge , whichever of its endpoints appears first in the permutation .",
    "we show that this vertex cover will be @xmath228-approximate and @xmath2-differentially private .",
    "our algorithm is based on a simple ( non - private ) 2-approximation to vertex cover  @xcite that repeatedly selects an uncovered edge uniformly at random , and includes a random endpoint of the edge .",
    "we can view the process , equivalently , as selecting a vertex at random with probability proportional to its uncovered degree .",
    "we will take this formulation and mix in a uniform distribution over the vertices , using a weight that will grow as the number of remaining vertices decreases .",
    "let us start from @xmath229 , and let @xmath230 be the graph with @xmath231 vertices remaining .",
    "we will write @xmath232 for the degree of vertex @xmath113 in graph @xmath47 .",
    "the algorithm @xmath233 in step @xmath69 chooses from the @xmath234 vertices of @xmath230 with probability proportional to @xmath235 , for an appropriate sequence @xmath236 .",
    "taking @xmath237 provides @xmath2-differential privacy and a @xmath238 approximation factor , the proof of which will follow from the forthcoming and .",
    "as stated the algorithm outputs a sequence of vertices , one per iteration .",
    "as remarked above , this permutation defines a vertex cover by picking the earlier occurring end point of each edge .",
    "* let * @xmath239 , @xmath240 .",
    "* let * @xmath241 .",
    "* pick * a vertex @xmath242 with probability proportional to @xmath243 .",
    "* output * @xmath113 .",
    "* let * @xmath244 , @xmath245 .",
    "[ thm : privacy ] alg satisfies @xmath2-differential privacy for the settings of @xmath246 above .    for any two sets of edges @xmath13 and @xmath14 , and any permutation @xmath247 ,",
    "let @xmath248 be the degree of the @xmath249 vertex in the permutation @xmath247 and let @xmath250 be the remaining edges , both ignoring edges incident to the first @xmath251 vertices in @xmath247 .",
    "= 1 @xmath252}{{{\\bf pr}}[alg(b ) = \\pi ] } = \\prod_{i = 1}^n      \\frac{(w_i + d_i(a))/((n - i+1)w_i + 2m_i(a))}{(w_i + d_i(b))/((n - i+1)w_i +        2m_i(b ) ) } \\ ; .",
    "\\end{gathered}\\ ] ] @xmath253}{{{\\bf pr}}[alg(b ) = \\pi]}\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\\\      \\;\\;\\ ; = \\prod_{i = 1}^n      \\frac{(w_i + d_i(a))/((n - i+1)w_i + 2m_i(a))}{(w_i + d_i(b))/((n - i+1)w_i +        2m_i(b ) ) } \\ ; .",
    "\\end{gathered}\\ ] ] when @xmath13 and @xmath14 differ in exactly one edge , @xmath254 for all @xmath69 except the first endpoint incident to the edge in the difference .",
    "until this term @xmath255 and @xmath256 differ by exactly one , and after this term @xmath257 .",
    "the number of nodes is always equal , of course .",
    "letting @xmath152 be the index in @xmath247 of the first endpoint of the edge in difference , we can cancel all terms after @xmath152 and rewrite = 1 @xmath252}{{{\\bf pr}}[alg(b ) = \\pi ] } = \\frac{w_j +        d_j(a)}{w_j + d_j(b ) } \\times \\prod_{i \\leq j } \\frac{(n - i+1)w_i +        2m_i(b)}{(n - i+1)w_i + 2m_i(a ) } \\ ; .",
    "\\end{gathered}\\ ] ] @xmath252}{{{\\bf pr}}[alg(b ) = \\pi]}\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\\\       = \\frac{w_j +        d_j(a)}{w_j + d_j(b ) } \\times \\prod_{i \\leq j } \\frac{(n - i+1)w_i +        2m_i(b)}{(n - i+1)w_i + 2m_i(a ) } \\ ; .",
    "\\end{gathered}\\ ] ] an edge may have arrived in @xmath13 , in which case @xmath258 for all @xmath259 , and each term in the product is at most one ; moreover , @xmath260 , and hence the leading term is at most @xmath261 , which is bounded by @xmath262 .",
    "alternately , an edge may have departed from @xmath13 , in which case the lead term is no more than one , but each term in the product exceeds one and their product must now be bounded .",
    "note that @xmath263 for all relevant @xmath69 , and that by ignoring all other edges we only make the product larger .",
    "simplifying , and using @xmath264 , we see = 1 @xmath265 @xmath266 the @xmath246 are chosen so that @xmath267 is at most @xmath268 .",
    "[ thm : accuracy ] for all @xmath47 , @xmath269 \\ ; \\le \\ ; ( 2 + 2{\\mathop{\\textrm{avg}}}_{i\\le n } w_i ) \\times    |opt(g)| \\ ; \\le \\ ; ( 2 + 16/\\epsilon)|{{\\sf opt}}(g)|$ ] .",
    "let @xmath270 denote an arbitrary optimal solution to the vertex cover problem on @xmath47 .",
    "the proof is inductive , on the size @xmath21 of @xmath47 . for @xmath47 with @xmath271 ,",
    "the theorem holds . for @xmath47 with @xmath272 ,",
    "the expected cost of the algorithm is the probability that the chosen vertex @xmath113 is incident to an edge , plus the expected cost of @xmath273 .",
    "= 1 @xmath274 & = & { { \\bf pr}}[v \\mbox { incident on edge } ] + { \\mathbf{\\mathbb{e}}}_v[{\\mathbf{\\mathbb{e}}}_{}[alg(g      \\setminus v ) ] ] \\ ; .",
    "\\end{aligned}\\ ] ] @xmath274 & = & { { \\bf pr}}[v \\mbox { incident on edge } ] \\\\ & & + { \\mathbf{\\mathbb{e}}}_v[{\\mathbf{\\mathbb{e}}}_{}[alg(g      \\setminus v ) ] ] \\ ; .",
    "\\end{aligned}\\ ] ] we will bound the second term using the inductive hypothesis . to bound the first term , the probability that @xmath113 is chosen incident to an edge is at most @xmath275 , as there are at most @xmath276 vertices incident to edges . on the other hand ,",
    "the probability that we pick a vertex in @xmath270 is at least @xmath277 . since @xmath278 is non - negative ,",
    "we conclude that = 1 @xmath279 \\leq ( 2 + 2w_n)(m/(nw_n+2 m ) ) \\leq    ( 2 + 2w_n){{\\bf pr}}[v \\in opt(g)]\\ ] ] @xmath280 & \\leq & ( 2 + 2w_n)(m/(nw_n+2m))\\\\ & \\leq &   ( 2 + 2w_n){{\\bf pr}}[v \\in opt(g)]\\end{aligned}\\ ] ] since @xmath281 \\leq |opt(g)| - |opt(g\\setminus v)|$ ] , and using the inductive hypothesis , we get @xmath282 & \\le & ( 2 + 2w_n ) \\times ( |opt(g)| - { \\mathbf{\\mathbb{e}}}_v[|opt(g      \\setminus v)| ] ) + ( 2 + 2{\\mathop{\\textrm{avg}}}_{i < n }   w_i ) \\times { \\mathbf{\\mathbb{e}}}_v[|opt(g      \\setminus v)| ] \\\\ & = & ( 2 + 2w_n ) \\times |opt(g)| + ( 2{\\mathop{\\textrm{avg}}}_{i < n }      w_i - 2w_n ) \\times { \\mathbf{\\mathbb{e}}}_v[|opt(g \\setminus v)| ]    \\end{aligned}\\ ] ] the probability that @xmath113 is from an optimal vertex cover is at least @xmath283 , as mentioned above , and ( using @xmath284 ) is at least @xmath285 , since @xmath286 by assumption . thus @xmath287 $ ] is bounded above by @xmath288 , giving @xmath282 & \\le & ( 2 + 2w_n ) \\times |opt(g)| + ( 2 { \\mathop{\\textrm{avg}}}_{i < n } w_i      - 2w_n ) \\times ( 1 - 1/n ) \\times |opt(g)|   \\ ; .",
    "\\end{aligned}\\ ] ] simplification yields the claimed results , and instantiating @xmath246 completes the proof .",
    "= 1    [ [ hallucinated - edges . ] ] hallucinated edges .",
    "+ + + + + + + + + + + + + + + + + + +    here is a slightly different way to implement the intuition behind the above algorithm : imagine adding @xmath227 `` hallucinated '' edges to each vertex ( the other endpoints of these hallucinated edges being fresh `` hallucinated '' vertices ) , and then sampling vertices without replacement proportional to these altered degrees",
    ". however , once ( say ) @xmath289 vertices have been sampled , output the remaining vertices in random order .",
    "this view will be useful to keep in mind for the weighted vertex cover proof .",
    "( a formal analysis of this algorithm is in . )",
    "[ [ hallucinated - edges.-1 ] ] hallucinated edges .",
    "+ + + + + + + + + + + + + + + + + + +    here is a slightly different way to implement the intuition behind the above algorithm : imagine adding @xmath227 `` hallucinated '' edges to each vertex ( the other endpoints of these hallucinated edges being fresh `` hallucinated '' vertices ) , and then sampling vertices without replacement proportional to these altered degrees",
    ". however , once ( say ) @xmath289 vertices have been sampled , output the remaining vertices in random order .",
    "this view will be useful to keep in mind for the weighted vertex cover proof .",
    "( a formal analysis of this algorithm appears in the full version . )      in the weighted vertex cover problem , each vertex @xmath55 is assigned a weight @xmath290 , and the cost of any vertex cover is the sum of the weights of the participating vertices .",
    "one can extend the unweighted 2-approximation that draws vertices at random with probability proportional to their uncovered degree to a weighted 2-approximation by drawing vertices with probability proportional to their uncovered degree divided by their weight .",
    "the differentially private analog of this algorithm essentially draws vertices with probability proportional to @xmath291 plus their degree , all divided by the weight of the vertex ; the algorithm we present here is based on this idea .",
    "define the _ score _ of a vertex to be @xmath292 .",
    "our algorithm involves hallucinating edges : to each vertex , we add in @xmath291 hallucinated edges , the other endpoints of which are imaginary vertices , whose weight is considered to be  @xmath293 ( and hence has zero score ) .",
    "the score of an edge @xmath294 is defined to be @xmath295 ; hence the score of a fake edge @xmath296 incident on @xmath297 is @xmath298 , since its other ( imaginary ) endpoint has infinite weight and zero score . we will draw edges with probability proportional to their score , and then select an endpoint to output with probability proportional to its score .",
    "in addition , once a substantial number of vertices of at least a particular weight have been output , we will output the rest of those vertices .",
    "assume the minimum vertex weight is @xmath205 and the maximum is @xmath299 .",
    "for simplicity , we round the weight of each vertex up to a power of  @xmath300 , at a potential loss of a factor of two in the approximation .",
    "define the @xmath301 weight class @xmath302 to be the set of vertices of weight @xmath303 .",
    "in addition , we will assume that @xmath304 for all weight classes . in order to achieve this , we hallucinate additional fake vertices",
    ". we will never actually output a hallucinated vertex .",
    "let @xmath305 denote @xmath306 .",
    "* pick * an uncovered ( real or hallucinated ) edge @xmath294 with probability proportional to @xmath307 . * output * endpoint @xmath308 with probability proportional to @xmath309 . *",
    "pick * the smallest such value of @xmath152 * output * ( `` dump '' ) all remaining vertices in @xmath302 in random order .",
    "we imagine the @xmath249 iteration of the outer loop of the algorithm as happening at _ time _",
    "@xmath69 ; note that one vertex is output in step  3 , whereas multiple vertices might be output in step  6 .",
    "let @xmath310 be the sum of the scores of all real vertices not output before time @xmath69 , and @xmath311 be the sum of the scores of all real edges not covered before time @xmath69 .",
    "[ thm : wvc - privacy ] the weighted vertex cover algorithm preserves @xmath312 differential privacy .",
    "consider some potential output @xmath247 of the private vertex cover algorithm , and two weighted vertex cover instances @xmath13 and @xmath14 that are identical except for one edge @xmath313 .",
    "let @xmath314 appear before @xmath25 in the permutation @xmath247 ; since the vertex sets are the same , if the outputs of both @xmath13 and @xmath14 are @xmath247 , then @xmath314 will be output at the same time  @xmath49 in both executions .",
    "let @xmath315 be the vertex output in step  3 at time @xmath49 in such an execution ; note that either @xmath316 , or @xmath314 is output in step  6 after @xmath315 is output .",
    "the probability that ( conditioned on the history ) a surviving vertex  @xmath113 is output in step  3 of the algorithm at time  @xmath69 is : = 1 @xmath317 \\cdot { { \\bf pr } } [ \\text{output } v      \\mid \\text{pick } e ] = \\sum_{e \\ni v } \\frac{s(e)}{\\widetilde{m}_i        + \\widetilde{n}_i/\\epsilon } \\cdot \\frac{s(v)}{s(e ) } = \\frac{(d(v ) +        1/\\epsilon ) \\cdot s(v)}{\\widetilde{m}_i +        \\widetilde{n}_i/\\epsilon}. \\label{eq : prob - v - picked }    \\end{gathered}\\ ] ] @xmath317 \\cdot { { \\bf pr } } [ \\text{output } v      \\mid \\text{pick } e ] \\\\=",
    "\\sum_{e \\ni v } \\frac{s(e)}{\\widetilde{m}_i        + \\widetilde{n}_i/\\epsilon } \\cdot \\frac{s(v)}{s(e ) } = \\frac{(d(v ) +        1/\\epsilon ) \\cdot s(v)}{\\widetilde{m}_i +        \\widetilde{n}_i/\\epsilon}. \\label{eq : prob - v - picked }    \\end{gathered}\\ ] ] since we compare the runs of the algorithm on @xmath13 and @xmath14 which differ only in edge @xmath318 , these will be identical after time @xmath49 when @xmath318 is covered , and hence @xmath319}{{{\\bf pr}}[m(b ) = \\pi ] } = \\frac{(d_a(v_t ) +    1/\\epsilon)s(v_t)}{(d_b(v_t ) + 1/\\epsilon ) s(v_t ) } \\prod_{i \\leq t }    \\left ( \\frac{\\widetilde{m}_i^b + \\widetilde{n}_i/\\epsilon}{\\widetilde{m}_i^a +    \\widetilde{n}_i/\\epsilon } \\right ) .",
    "\\end{gathered}\\ ] ]    note that if the extra edge @xmath320 then @xmath321 and @xmath322 , so the ratio of the probabilities is at most @xmath323 .",
    "otherwise , the leading term is less than @xmath205 and @xmath324 , and we get @xmath319}{{{\\bf pr}}[m(b ) = \\pi ] } \\leq \\prod_{i \\leq t }      \\left(1 + \\frac{s({\\mathbf{e}})}{\\widetilde{n}_i/\\epsilon }      \\right ) \\leq \\exp \\left ( s({\\mathbf{e } } ) \\cdot \\epsilon \\cdot \\sum_{i \\leq t }        \\frac{1}{\\widetilde{n}_i } \\right ) .",
    "\\end{gathered}\\ ] ]    let @xmath325 be the time steps @xmath326 where vertices in @xmath302 are output in @xmath247 . letting @xmath327 be the weight of the lighter endpoint of edge @xmath318 , we can break the sum @xmath328 into two pieces and analyze each separately : @xmath329    for the first partial sum , for some @xmath330 , let @xmath331 such that @xmath332 .",
    "we claim that @xmath333 . indeed , since @xmath318 has not yet been covered , we must have output fewer than @xmath334 vertices from levels @xmath335 or higher , and hence at least @xmath334 remaining vertices from @xmath336 contribute to @xmath337 .    in each time step in @xmath338 ,",
    "at least one vertex of score @xmath339 is output , so we have that @xmath340 .",
    "hence = 1 @xmath341 @xmath342 defining @xmath343 , the expression above simplifies to = 1 @xmath344 @xmath345    now using the assumption on the size of the weight classes , we have @xmath346 , and hence @xmath347 , for any @xmath330 .",
    "finally , @xmath348    we now consider the other partial sum @xmath349 . for any such value of @xmath69 , we know that @xmath350 .",
    "moreover , there are at most @xmath334 times when we output a vertex from some weight class @xmath351 before we output all of @xmath336 ; hence there are at most @xmath334 terms in the sum , each of which is at most @xmath352 , giving a bound of @xmath327 on the second partial sum . putting the two together",
    ", we get that @xmath353}{{{\\bf pr}}[m(b ) = \\pi ] } \\leq \\exp(s({\\mathbf{e } } ) \\cdot      \\epsilon \\cdot o(2^{j^ * } ) ) = \\exp(o(\\epsilon ) ) ,    \\end{gathered}\\ ] ] using the fact that @xmath354 , since the lighter endpoint of @xmath318 had weight @xmath327 .",
    "call a vertex @xmath113 _ interesting _ if it is incident on a real uncovered edge when it is picked .",
    "consider the weight class @xmath302 : let @xmath355 be the set of interesting vertices output due to steps  3 , and @xmath356 be the set of interesting vertices of class  @xmath152 output due to step  6 .",
    "the cost incurred by the algorithm is @xmath357 .",
    "[ lem : wvc - stage1 ] @xmath358 \\leq \\frac{4(1+{\\varepsilon})}{{\\varepsilon } } { { \\sf opt}}$ ]    every interesting vertex that our algorithm picks in steps  3 has at least one real edge incident on it , and at most @xmath359 hallucinated edges . conditioned on selecting an interesting vertex @xmath113 ,",
    "the selection is due to a real edge with probability at least @xmath360 .",
    "one can show that the ( non - private ) algorithm @xmath361 that selects only real edges is a @xmath300-approximation  @xcite . on the other hand each vertex in @xmath362",
    "can be coupled to a step of @xmath361 with probability @xmath363 . since we rounded up the costs by at most a factor of two",
    ", the claim follows .",
    "@xmath364 \\leq 6\\ , { \\mathbf{\\mathbb{e}}}[\\sum_{j'\\geq j } |i^1_{j'}|]$ ]    let @xmath365 denote the time that class @xmath152 is dumped . recall that by  , we pick a surviving vertex @xmath113 with probability @xmath366 at each step .",
    "this expression summed over all uninteresting vertices is @xmath367 is at most @xmath368 . on the other hand , at each step before time @xmath369 , all the interesting vertices in @xmath370 are available and the same expression summed over them is at least @xmath371 .",
    "thus for any @xmath372 , conditioned on outputting a vertex @xmath373 in step  3 , the probability that it is interesting is at least @xmath374 ( using @xmath375 ) . now since we output @xmath376 vertices from @xmath367 in step  3 before time @xmath369 , we conclude that @xmath377 \\geq \\frac{n_j}{2 } \\times \\frac{|i^2_j|}{3n_j } =    \\frac{|i^2_j|}{6}$ ] .",
    "taking expectations completes the proof .",
    "we can now compute the total cost of all the interesting vertices dumped in steps  6 of the algorithm .",
    "= 1 @xmath378 & = { \\textstyle}\\sum_j 2^j\\ , { \\mathbf{\\mathbb{e}}}[|i_j^2| ] \\leq   6    \\;\\sum_j 2^j \\ ; \\sum_{j ' \\geq j } { \\mathbf{\\mathbb{e } } } [ |i_{j'}^1| ]   { \\textstyle}\\leq 6 \\;\\sum_{j ' } { \\mathbf{\\mathbb{e}}}[|i_{j'}^1| ] \\ ; 2^{j'+1 }      \\leq   12\\ ; \\cdot { \\mathbf{\\mathbb{e}}}[\\textsf{cost}(\\bigcup_j i_j^1)].\\end{aligned}\\ ] ] @xmath378 & = & { \\textstyle}\\sum_j 2^j\\ , { \\mathbf{\\mathbb{e}}}[|i_j^2| ] \\\\&\\leq &   6    \\;\\sum_j 2^j \\ ; \\sum_{j ' \\geq j } { \\mathbf{\\mathbb{e } } } [ |i_{j'}^1| ] \\\\",
    "{ \\textstyle}&\\leq & 6 \\;\\sum_{j ' } { \\mathbf{\\mathbb{e}}}[|i_{j'}^1| ] \\ ; 2^{j'+1 }     \\\\ & \\leq &   12\\ ; \\cdot { \\mathbf{\\mathbb{e}}}[\\textsf{cost}(\\bigcup_j i_j^1)].\\end{aligned}\\ ] ] finally , combining this calculation with , we conclude that our algorithm gives an @xmath379 approximation to the weighted vertex cover problem .",
    "[ thm : vc - lbd ] any algorithm for the vertex cover problem that prescribes edge - orientations with @xmath2-differential privacy must have an @xmath3 approximation guarantee , for any @xmath380 $ ] .",
    "let @xmath381 , and let @xmath12 be an @xmath2-differentially private algorithm that takes as input a private set @xmath119 of edges , and outputs an orientation @xmath382 , with @xmath383 indicating to the edge which endpoint to use . picking two distinct vertices @xmath384 uniformly at random ( and equating @xmath385 with @xmath386 ) , we have by symmetry : @xmath387 = \\frac{1}{2}.\\ ] ] let @xmath388 be the star graph rooted at @xmath297 . since @xmath389 and @xmath390 differ in at most @xmath391 edges and @xmath12 satisfies @xmath2-differential privacy , we conclude that @xmath392 \\ge \\frac{1}{2e}.\\ ] ] thus the expected cost of @xmath12 when input a uniformly random @xmath389 is at least @xmath393 , while @xmath394 is 1 .",
    "we can repeat this pattern arbitrarily , picking a random star from each group of @xmath291 vertices ; this results in graphs with arbitrarily large vertex covers where @xmath12 incurs cost @xmath291 times the cost .",
    "we now turn our attention to private approximations for the set cover problem ; here the set system @xmath395 is public , but the actual set of elements to be covered @xmath396 is the private information . as for vertex cover , we can not explicitly output a set cover that is good and private at the same time .",
    "hence , we again output a permutation over all the sets in the set system ; this implicitly defines a set cover for @xmath32 by picking , for each element @xmath32 , the first set in this permutation that contains it .",
    "our algorithms for set cover give the slightly weaker @xmath397-privacy guarantees .",
    "we are given a set system @xmath398 and must cover a private subset @xmath399 . let the cardinality of the set system be @xmath400 , and let @xmath401 .",
    "we first observe a computationally inefficient algorithm .",
    "the exponential mechanism , when used to pick a permutation of sets , runs in time @xmath402 and gives an @xmath403-approximation .    a random permutation , with probability at least @xmath404 has all the sets in @xmath211 before any set in @xmath405 .",
    "thus the additive error is @xmath406 .",
    "the rest of the section gives a computationally efficient algorithm with slightly worse guarantees : this is a modified version of the greedy algorithm , using the exponential mechanism to bias towards picking large sets .    *",
    "input : * set system @xmath398 , private @xmath407 of elements to cover , @xmath2,@xmath5 .",
    "* let * @xmath408 , @xmath409 , @xmath410 . @xmath411 . * pick * a set @xmath223 from @xmath412 with probability proportional to @xmath413 . * output * set @xmath223 .",
    "@xmath414 , @xmath415 .      at the beginning of iteration  @xmath69 , say there are @xmath416 remaining sets and @xmath417 remaining elements , and define @xmath418 , the largest number of uncovered elements covered by any set in @xmath419 . by a standard argument , any algorithm that always picks sets of size",
    "@xmath420 is an @xmath421 approximation algorithm .",
    "the above algorithm achieves an expected approximation ratio of @xmath422 .",
    "as there is at least one set containing @xmath423 elements , our use of the exponential mechanism to select sets combined with equation [ eqn : expmech ] ensures that the probability we select a set covering fewer than @xmath424 elements is at most @xmath425 . while @xmath426 , with probability at least @xmath427 we always select sets that cover at least @xmath420 elements , and can therefore use no more than @xmath428 sets .",
    "once @xmath423 drops below this bound , we observe that the number of remaining elements @xmath429 is at most @xmath430 .",
    "any permutation therefore costs at most an additional @xmath431 .",
    "[ thm : unwtdsetcoverprivacy ] the unweighted set cover algorithm preserves @xmath432 differential privacy for any @xmath433 , and @xmath434",
    ".    let @xmath13 and @xmath14 be two set cover instances that differ in some element @xmath435 .",
    "say that @xmath436 is the collection of sets containing @xmath435 .",
    "fix an output permutation @xmath247 , and write @xmath437 to denote the size of set @xmath438 after the first @xmath251 sets in @xmath247 have been added to the cover .",
    "= 1 @xmath439}{{{\\bf pr}}[m(b)=\\pi ] } & = & \\prod_{i=1}^n\\left(\\frac{\\exp(\\epsilon'\\cdot s_{i,\\pi_i}(a))/(\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(a)))}{\\exp(\\epsilon'\\cdot s_{i,\\pi_i}(b))/(\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(b)))}\\right ) \\\\      & = & \\frac{\\exp(\\epsilon'\\cdot s_{t,\\pi_t}(a))}{\\exp(\\epsilon'\\cdot s_{t,\\pi_t}(b))}\\cdot \\prod_{i=1}^t\\left(\\frac{\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(b))}{\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(a))}\\right )    \\end{aligned}\\ ] ] @xmath440}{{{\\bf pr}}[m(b)=\\pi ] } \\\\      & = \\prod_{i=1}^n\\left(\\frac{\\exp(\\epsilon'\\cdot s_{i,\\pi_i}(a))/(\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(a)))}{\\exp(\\epsilon'\\cdot s_{i,\\pi_i}(b))/(\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(b)))}\\right ) \\\\      & = \\frac{\\exp(\\epsilon'\\cdot s_{t,\\pi_t}(a))}{\\exp(\\epsilon'\\cdot s_{t,\\pi_t}(b))}\\cdot \\prod_{i=1}^t\\left(\\frac{\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(b))}{\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(a))}\\right )    \\end{aligned}\\ ] ] where @xmath49 is such that @xmath441 is the first set containing @xmath435 to fall in the permutation @xmath247 .",
    "after @xmath49 , the remaining elements in @xmath13 and @xmath14 are identical , and all subsequent terms cancel .",
    "moreover , except for the @xmath442 term , the numerators of both the top and bottom expression cancel , since all the relevant set sizes are equal .",
    "if @xmath13 contains @xmath435 and @xmath14 does not the first term is @xmath443 and the each term in the product is at most 1 .",
    "now suppose that @xmath14 contains @xmath435 and @xmath13 does not . in this case",
    ", the first term is @xmath444 .",
    "moreover , in instance @xmath14 , every set in @xmath436 is larger by 1 than in @xmath13 , and all others remain the same size .",
    "therefore , we have : = 1 @xmath439}{{{\\bf pr}}[m(b)=\\pi ] } & \\leq &   \\prod_{i=1}^t\\left(\\frac{(\\exp(\\epsilon')-1)\\cdot\\sum_{j\\in s^i}\\exp(\\epsilon'\\cdot s_{i , j}(a ) ) + \\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(a))}{\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(a))}\\right ) \\\\      & = &   \\prod_{i=1}^t \\left(1 + ( \\exp(\\epsilon')-1)\\cdot p_i(a ) \\right )    \\end{aligned}\\ ] ] @xmath445}{{{\\bf pr}}[m(b)=\\pi ] } \\\\      & { \\textstyle}\\leq   \\prod_{i=1}^t\\left(\\frac{(\\exp(\\epsilon')-1)\\cdot\\sum_{j\\in s^i}\\exp(\\epsilon'\\cdot s_{i , j}(a ) ) + \\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(a))}{\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(a))}\\right ) \\\\      & { \\textstyle}=   \\prod_{i=1}^t \\left(1 + ( \\exp(\\epsilon')-1)\\cdot p_i(a ) \\right )    \\end{aligned}\\ ] ] where @xmath446 is the probability that a set containing @xmath435 is chosen at step @xmath69 of the algorithm running on instance @xmath13 , conditioned on picking the sets @xmath447 in the previous steps .",
    "for an instance @xmath13 and an element @xmath448 , we say that an output @xmath449 is _",
    "@xmath25-bad _ if @xmath450 ( strictly ) exceeds @xmath25 , where @xmath446 is as defined above .",
    "we call a permutation _",
    "@xmath25-good _ otherwise .",
    "we first consider the case when the output @xmath247 is @xmath451-good . by the definition of @xmath49",
    ", we have @xmath452 continuing the analysis from above , @xmath439}{{{\\bf pr}}[m(b)=\\pi ] } & \\leq      \\prod_{i=1}^t \\exp((\\exp(\\epsilon')-1)p_i(a ) )      \\leq \\exp(2\\epsilon'\\sum_{i=1}^tp_i(a ) ) \\\\      & \\leq \\exp(2\\epsilon'(\\ln(\\frac{1}{\\delta})+p_t(a ) ) )      \\leq \\exp(2\\epsilon'(\\ln(\\frac{1}{\\delta})+1 ) ) .",
    "\\end{aligned}\\ ] ] thus , for any @xmath451-good output @xmath247 , we have @xmath453}{{{\\bf pr}}[m(b)=\\pi ] } \\leq \\exp(\\epsilon)$ ] .",
    "we can then invoke the following lemma , proved in appendix  [ sec : deltafix ]    [ lem : deltafix ] for any set system @xmath398 , any instance @xmath13 and any @xmath454 , the probability that the output @xmath247 of the algorithm above is @xmath25-bad is bounded by @xmath455 .",
    "thus for any set @xmath456 of outcomes , we have = 1 @xmath457 & = & \\sum_{\\pi \\in \\mathcal{p } } { { \\bf pr}}[m(a)=\\pi]\\\\ & = & \\sum_{\\pi \\in \\mathcal{p } : \\pi\\mbox { is } ( \\ln \\delta^{-1})\\mbox{-good } } { { \\bf pr}}[m(a)=\\pi ] + \\sum_{\\pi \\in \\mathcal{p } : \\pi\\mbox { is } ( \\ln \\delta^{-1})\\mbox{-bad } } { { \\bf pr}}[m(a)=\\pi ] \\\\ & \\leq & \\sum_{\\pi \\in \\mathcal{p } : \\pi\\mbox { is } ( \\ln \\delta^{-1})\\mbox{-good } } \\exp(\\epsilon ) { { \\bf pr}}[m(b)=\\pi ] + \\delta\\\\ & \\leq & \\exp(\\epsilon){{\\bf pr}}[m(b ) \\in \\mathcal{p } ] + \\delta.\\end{aligned}\\ ] ] @xmath458\\\\ & = \\sum_{\\pi \\in \\mathcal{p } } { { \\bf pr}}[m(a)=\\pi]\\\\ & = \\sum_{\\pi \\in \\mathcal{p } : \\pi\\mbox { is } ( \\ln \\delta^{-1})\\mbox{-good } } { { \\bf pr}}[m(a)=\\pi ] \\\\ & \\;\\;\\;\\;+ \\sum_{\\pi \\in \\mathcal{p } : \\pi\\mbox { is } ( \\ln \\delta^{-1})\\mbox{-bad } } { { \\bf pr}}[m(a)=\\pi ] \\\\ & \\leq \\sum_{\\pi \\in \\mathcal{p } : \\pi\\mbox { is } ( \\ln \\delta^{-1})\\mbox{-good } } \\exp(\\epsilon ) { { \\bf pr}}[m(b)=\\pi ] + \\delta\\\\ & \\leq \\exp(\\epsilon){{\\bf pr}}[m(b ) \\in \\mathcal{p } ] + \\delta.\\end{aligned}\\ ] ]    for @xmath459 and @xmath460 , there is an @xmath461-approximation algorithm for the unweighted set cover problem preserving @xmath432-differential privacy .",
    "we are given a set system @xmath398 and a cost function @xmath462 .",
    "we must cover a private subset @xmath463 . w.l.o.g .",
    ", let @xmath464 , and denote @xmath465 .",
    "let the cardinality of the set system be @xmath400 , and let @xmath401 .",
    "* let * @xmath408 , @xmath409 , @xmath410 , @xmath466 , @xmath467 , @xmath468    * pick * a set @xmath223 from @xmath412 with probability proportional to @xmath469 +  or ` halve ` with probability proportional to @xmath470 * let * @xmath471 , @xmath472 , @xmath473 , @xmath474 * output * set @xmath223 * let * @xmath414 , @xmath415 , @xmath475 , @xmath476 * output * all remaining sets in @xmath412 in random order    let us first analyze the utility of the algorithm . if @xmath477 , the algorithm has cost zero and there is nothing to prove .",
    "so we can assume that @xmath478 .",
    "we first show that ( * whp * ) @xmath479 .",
    "[ firstsetcoverlemma ] except with probability @xmath480 , we have @xmath481 for all iterations  @xmath69 .",
    "clearly @xmath482 .",
    "for @xmath483 to fall below @xmath484 , it must be in @xmath485 $ ] and be halved in step  6 of some iteration @xmath69 .",
    "we ll show that this is unlikely : if at some iteration @xmath69 , @xmath486 , then we argue that with high probability , the algorithm will not output ` halve ` and thus not halve @xmath483 .",
    "since all remaining elements @xmath487 can be covered at cost at most @xmath211 , there must exist a set @xmath223 such that @xmath488 , and hence @xmath489    hence @xmath490 in this case , and the algorithm will output @xmath223 with probability at least proportional to @xmath205 , whereas it outputs ` halve ` with probability proportional to @xmath470 .",
    "thus , @xmath491 < \\exp(-\\epsilon ' t ) = 1/{\\operatorname{poly}}(m \\log    nw)$ ] . since there are @xmath492 sets in total , and @xmath24 ranges from @xmath21 to @xmath493 , there are at most @xmath494 iterations , and the proof follows by a union bound .",
    "let us define a _ score _",
    "function @xmath495 , and @xmath496 : note that in step  4 of our algorithm , we output either ` halve ` or a set @xmath223 , with probabilities proportional to @xmath497 .",
    "the following lemma states that with high probability , none of the sets output by our algorithm have very low scores ( since we are much more likely to output ` halve ` than a low - scoring set ) .",
    "[ goodanswerlemma ] except with probability at most @xmath480 , step  4 only returns sets @xmath223 with @xmath498 .",
    "there are at most @xmath499 sets @xmath223 with score @xmath500 , and",
    "so one is output with probability at most proportional to @xmath501 .",
    "we will denote this bad event by @xmath502 . on the other hand , ` halve ` is output with probability proportional to @xmath503 .",
    "hence , @xmath504/{{\\bf pr}}[\\mathcal{b } ] \\geq \\exp(t\\epsilon)/m$ ] , and so @xmath505 \\leq m/\\exp(t\\epsilon ) \\leq",
    "1/{\\operatorname{poly}}(m \\log nw)$ ] .",
    "again there are at most @xmath506 iterations , and the lemma follows by a trivial union bound .",
    "we now analyze the cost incurred by the algorithm in each stage .",
    "let us divide the algorithm s execution into _ stages _ : stage  @xmath152 consists of all iterations @xmath69 where @xmath507 $ ] .",
    "call a set @xmath223 _ _ i__nteresting if it is incident on an uncovered element when it is picked .",
    "let @xmath508 be the set of interesting sets selected in stage @xmath152 , and @xmath509 be the total cost incurred on these sets .",
    "[ secondsetcoverlemma ] consider stages @xmath510 of the algorithm . except with probability @xmath480",
    ", we can bound the cost of the interesting sets in stage  @xmath510 by : @xmath511    by all the output sets have @xmath512 * whp*. rewriting , each @xmath513 selected in a round @xmath514 satisfies @xmath515 where the second inequality is * whp * , and uses . now summing over all rounds @xmath514",
    ", we get = 1 @xmath516 @xmath517 consider the inner sum for any particular value of @xmath518 : let the first iteration in stage @xmath518 be iteration  @xmath519naturally @xmath520 for any iteration @xmath69 in this stage .",
    "now , since @xmath521 and @xmath522 is disjoint from @xmath523 , the sum over @xmath524 is at most @xmath525 , which is at most @xmath526 by definition of stage @xmath518 .",
    "moreover , since we are only concerned with bounding the cost of interesting sets , each @xmath527 , and so @xmath528 . putting this together ,  ( [ eq : wsc-1 ] ) implies = 1 @xmath529 @xmath530 which proves the lemma .",
    "the weighted set cover algorithm incurs a cost of @xmath531 except with probability @xmath480 .    since the number of uncovered elements halves in each stage by definition , there are at most @xmath532 stages , which by incur a total cost of at most @xmath533 .",
    "the sets that remain and are output at the very end of the algorithm incur cost at most @xmath534 for each remaining uncovered element ; since @xmath535 at the end , implies that @xmath536 ( * whp * ) , giving an additional cost of at most @xmath537 .",
    "we can adapt the above argument to bound the expected cost by @xmath538 .",
    "[ lem : wtdsetcoverprivacy ] for any @xmath539 , the weighted set cover algorithm preserves @xmath540 differential privacy .",
    "we imagine that the algorithm outputs a set named `` halve '' when step  4 of the algorithm returns ` halve ` , and show that even this output is privacy preserving .",
    "let @xmath13 and @xmath14 be two set cover instances that differ in some element @xmath435 .",
    "say that @xmath436 is the collection of sets containing @xmath435 . fix an output @xmath247 , and write @xmath541 to denote the score of @xmath542 ( recall this may be ` halve ` ) after the first @xmath251 sets in @xmath247 have been selected .",
    "= 1 @xmath543}{{{\\bf pr}}[m(b)=\\pi ] } = \\prod_{i=1}^n\\left(\\frac{\\exp(\\epsilon'\\cdot u_{i,\\pi_i}(a))/(\\sum_j\\exp(\\epsilon'\\cdot u_{i , j}(a)))}{\\exp(\\epsilon'\\cdot u_{i,\\pi_i}(b))/(\\sum_j\\exp(\\epsilon'\\cdot u_{i , j}(b)))}\\right )      = \\frac{\\exp(\\epsilon'\\cdot u_{t,\\pi_t}(a))}{\\exp(\\epsilon'\\cdot u_{t,\\pi_t}(b))}\\cdot \\prod_{i=1}^t\\left(\\frac{\\sum_j\\exp(\\epsilon'\\cdot u_{i , j}(b))}{\\sum_j\\exp(\\epsilon'\\cdot u_{i , j}(a))}\\right)\\ ] ] @xmath440}{{{\\bf pr}}[m(b)=\\pi ] } \\\\      & = \\prod_{i=1}^n\\left(\\frac{\\exp(\\epsilon'\\cdot u_{i,\\pi_i}(a))/(\\sum_j\\exp(\\epsilon'\\cdot u_{i , j}(a)))}{\\exp(\\epsilon'\\cdot u_{i,\\pi_i}(b))/(\\sum_j\\exp(\\epsilon'\\cdot u_{i , j}(b)))}\\right)\\\\      & = \\frac{\\exp(\\epsilon'\\cdot u_{t,\\pi_t}(a))}{\\exp(\\epsilon'\\cdot u_{t,\\pi_t}(b))}\\cdot \\prod_{i=1}^t\\left(\\frac{\\sum_j\\exp(\\epsilon'\\cdot u_{i , j}(b))}{\\sum_j\\exp(\\epsilon'\\cdot u_{i , j}(a))}\\right )    \\end{aligned}\\ ] ] where @xmath49 is such that @xmath441 is the first set containing @xmath435 to fall in the permutation @xmath247 .",
    "after @xmath49 , the remaining elements in @xmath13 and @xmath14 are identical , and all subsequent terms cancel . moreover , except for the @xmath442 term , the numerators of both the top and bottom expression cancel , since all the relevant set sizes are equal .",
    "if @xmath13 contains @xmath435 and @xmath14 does not the first term is @xmath443 and the each term in the product is at most 1 . since @xmath544 , we conclude that in this case , for any set @xmath456 of outputs , @xmath545 \\leq \\exp(\\epsilon){{\\bf pr}}[m(b)\\in \\mathcal{p}]$ ]",
    ".    now suppose that @xmath14 contains @xmath435 and @xmath13 does not . in this case , the first term is @xmath444 . moreover , in instance @xmath14 , every set in @xmath436 is larger by 1 than in @xmath13 , and all others remain the same size .",
    "therefore , we have : @xmath543}{{{\\bf pr}}[m(b)=\\pi ] } \\leq   \\prod_{i=1}^t\\left(\\frac{(\\exp(\\epsilon')-1)\\cdot\\sum_{j\\in s^i}\\exp(\\epsilon'\\cdot u_{i , j}(a ) ) + \\sum_j\\exp(\\epsilon'\\cdot u_{i , j}(a))}{\\sum_j\\exp(\\epsilon'\\cdot u_{i , j}(a))}\\right )      =   \\prod_{i=1}^t \\left(1 + ( e^{\\epsilon'}-1)\\cdot p_i(a ) \\right)\\ ] ] where @xmath446 is the probability that a set containing @xmath435 is chosen at step @xmath69 of the algorithm running on instance @xmath13 , conditioned on picking the sets @xmath447 in the previous steps .",
    "for an instance @xmath13 and an element @xmath448 , we say that an output @xmath449 is _",
    "@xmath25-bad _ if @xmath450 ( strictly ) exceeds @xmath25 , where @xmath446 is as defined above .",
    "we call a permutation _ @xmath25-good _ otherwise .",
    "we first consider the case when the output @xmath247 is @xmath451-good . by the definition of @xmath49",
    ", we have @xmath452 continuing the analysis from above , @xmath439}{{{\\bf pr}}[m(b)=\\pi ] } & \\leq      \\prod_{i=1}^t \\exp((\\exp(\\epsilon')-1)p_i(a ) )      \\leq \\exp\\left(2\\epsilon'\\sum_{i=1}^tp_i(a)\\right ) \\\\      & \\leq \\exp\\left(2\\epsilon'\\left(\\ln \\delta^{-1 } + p_t(a)\\right)\\right )      \\leq \\exp\\left(2\\epsilon'\\left(\\ln \\delta^{-1 } + 1\\right)\\right ) .",
    "\\end{aligned}\\ ] ] thus , for any @xmath451-good output @xmath247 , we have @xmath453}{{{\\bf pr}}[m(b)=\\pi ] } \\leq \\exp(\\epsilon)$ ] .    finally , as in the proof of theorem  [ thm : unwtdsetcoverprivacy ]",
    ", we can use lemma  [ lem : deltafix ] to complete the proof .",
    "we can remove the dependence of the algorithm on @xmath534 with a simple idea .",
    "for an instance @xmath546 , let @xmath547\\,\\}$ ] .",
    "let @xmath548 be the set of elements such that the cheapest set containing them is in @xmath549 .",
    "suppose that for each @xmath152 and each @xmath550 , we remove all elements that can be covered by a set of cost at most @xmath551 , and hence define @xmath552 to be @xmath553 .",
    "this would change the cost of the optimal solution only by a factor of @xmath300 , since if we were earlier using @xmath223 in the optimal solution , we can pick @xmath552 and at most @xmath21 sets of cost at most @xmath551 to cover the elements covered by @xmath554 . call this instance @xmath555 .",
    "now we partition this instance into two instances @xmath556 and @xmath557 , where @xmath558 , and where @xmath559 . since we have just partitioned the universe , the optimal solution on both these instances costs at most @xmath560 . but",
    "both these instances @xmath561 are themselves collections of _ disjoint _ instances , with each of these instances having @xmath562 ; this immediately allows us to remove the dependence on @xmath534 .",
    "note that this transformation is based only on the set system @xmath563 , and not on the private subset  @xmath32 .    for any @xmath564 , @xmath565",
    ", there is an @xmath566-approximation for the weighted set cover problem that preserves @xmath432-differential privacy .",
    "any @xmath2-differentially private algorithm that maps elements to sets must have approximation factor @xmath567 , for a set cover instance with @xmath492 sets and @xmath568 elements , for any @xmath569 .",
    "we consider a set system with @xmath570 and @xmath419 a uniformly random selection of @xmath492 size-@xmath0 subsets of @xmath571",
    ". we will consider problem instances @xmath513 consisting of one of these @xmath492 subsets , so @xmath572 .",
    "let @xmath12 be an @xmath2-differentially private algorithm that on input @xmath573 , outputs an assignment @xmath296 mapping each element in @xmath571 to some set in @xmath419 that covers it .",
    "the number of possible assignments is at most @xmath574 .",
    "the cost on input @xmath162 under an assignment @xmath296 is the cardinality of the set @xmath575 .",
    "we say assignment @xmath296 is good for a subset @xmath573 if its cost @xmath576 is at most @xmath577 .",
    "we first show that any fixed assignment @xmath578 $ ] , such that @xmath579 for all @xmath152 , is unlikely to be good for a randomly picked size-@xmath0 subset @xmath162 of @xmath571 .",
    "the number of ways to choose @xmath580 sets from among those with non - empty @xmath581 is at most @xmath582 .",
    "thus the probability that @xmath296 is good for a random size-@xmath0 subset is at most @xmath583 .",
    "setting @xmath584 , and @xmath585 , this is at most @xmath586 let @xmath587 .",
    "the probability that @xmath296 is good for at least @xmath49 of our @xmath492 randomly picked sets is bounded by @xmath588 thus , with probability at most @xmath589 , a fixed assignment is good for more than @xmath590 of @xmath492 randomly chosen size-@xmath0 sets . taking a union bound over @xmath591 possible assignments , the probability that _",
    "any _ feasible assignment @xmath296 is good for more than @xmath590 sets is at most @xmath592 .",
    "thus there exists a selection of size-@xmath0 sets @xmath593 such that no feasible assignment @xmath296 is good for more than @xmath590 of the @xmath513 s .",
    "let @xmath594 be the probability that an assignment drawn from the distribution defined by running @xmath12 on the the empty set as input is good for @xmath513 .",
    "since any fixed assignment is good for at most @xmath590 of the @xmath492 sets , the average value of @xmath595 is at most @xmath596 .",
    "thus there exists a set , say @xmath597 such that @xmath598 . since @xmath599 and @xmath12 is @xmath2-differentially private , @xmath600 . thus with probability at least half , the assignment @xmath12 picks on @xmath597 is not good for @xmath597 .",
    "since @xmath601 , the expected approximation ratio of @xmath12 is at least @xmath602 .",
    "additionally , one can take @xmath603 distinct instances of the above problem , leading to a new instance on @xmath604 elements and @xmath605 sets .",
    "@xmath211 is now @xmath603 , while it is easy to check that any private algorithm must cost @xmath606 in expectation .",
    "thus the lower bound in fact rules out additive approximations .      for completeness",
    ", we now show that the lower bound shown above is tight even in the weighted case , in the absence of computational constraints . recall that we are given a collection @xmath607 of subsets of a universe @xmath571 , and a private subset @xmath608 of elements to be covered .",
    "additionally , we have weights on sets ; we round up weights to powers of 2 , so that sets in @xmath609 have weight exactly @xmath339 . without loss of generality ,",
    "the largest weight is 1 and the smallest weight is @xmath610 .    as before , we will output a permutation @xmath247 on @xmath607 , with the understanding that the cost @xmath611 of a permutation @xmath247 on input @xmath32 is defined to be the total cost of the set cover resulting from picking the first set in the permutation containing @xmath612 , for each @xmath613 .",
    "our algorithm constructs this permutation in a gradual manner .",
    "it maintains a permutation @xmath542 on @xmath614 and a threshold @xmath325 . in step",
    "@xmath152 , given @xmath615 and @xmath616 , the algorithm constructs a partial permutation @xmath542 on @xmath617 , and a threshold @xmath325 . in each step",
    ", we use the exponential mechanism to select an extension with an appropriate base distribution @xmath618 and score function @xmath25 . at the end of step @xmath619 ,",
    "we get our permutation @xmath620 on @xmath607",
    ".    our permutations @xmath542 will all have a specific structure .",
    "the weight of the @xmath69th set in the permutation , as a function of @xmath69 will be a unimodal function that is non - increasing until @xmath325 , and then non - decreasing .",
    "in other words , @xmath542 contains sets from @xmath609 as a continuous block .",
    "the sets that appear before @xmath325 are said to be in the _",
    "bucket_. we call a partial permutation respecting this structure _",
    "good_. we say a good permutation @xmath247 _ extends _ a good partial permutation @xmath542 if @xmath542 and @xmath247 agree on their ordering on @xmath614 .",
    "we first define the score function that is used in these choices .",
    "a natural objective function would be @xmath621 , i.e. the cost of the optimal solution conditioned on respecting the partial permutation @xmath542 .",
    "we use a slight modification of this score function : we force the cover to contain all sets from the bucket and denote as @xmath622 the resulting cover defined by @xmath32 on @xmath247 .",
    "we then define @xmath623 naturally as @xmath624 .",
    "we first record the following easy facts :    [ obs : wsc - ineff ] for any @xmath32 , @xmath625 .",
    "moreover , for any @xmath247 , @xmath626 .    to get @xmath627 given @xmath628 , we insert a permutation @xmath629 of @xmath609 after the first @xmath616 elements of @xmath615 , and choose @xmath325 , where both @xmath629 and @xmath325 are chosen using the exponential mechanism . the base measure on @xmath629 is uniform and",
    "the base measure on @xmath630 is the geometric distribution with parameter @xmath425 .",
    "let @xmath631 be defined as @xmath632 , where @xmath542 is constructed from @xmath615 and @xmath633 as above .",
    "the score function we use to pick @xmath634 is @xmath635 .",
    "thus @xmath636 \\propto ( 1/m^2(t_j - t_{j-1 } ) ) \\exp({\\varepsilon}score({(\\sigma_j , t_j)}))$ ] .",
    "let the optimal solution to the instance contain @xmath637 sets from @xmath609 .",
    "thus @xmath638 .",
    "we first show that @xmath639 is @xmath640 . by observation  [ obs : wsc - ineff ]",
    ", the approximation guarantee would follow .",
    "the probability that the @xmath637 sets in @xmath211 fall in the bucket when picking from the base measure is at least @xmath641 .",
    "when that happens , @xmath642 .",
    "thus the exponential mechanism ensures that except with probability @xmath643 : @xmath644    thus with high probability , @xmath645    finally , we analyze the privacy .",
    "let @xmath646 be an element such that the cheapest set covering @xmath571 has cost @xmath647 .",
    "let @xmath13 and @xmath14 be two instances that differ in element @xmath612 .",
    "it is easy to see that @xmath648 is bounded by @xmath339 for all @xmath152 .",
    "we show something stronger :    [ lem : wsc - ineff - sens ] for any good partial permutation @xmath542 and any @xmath649 such that @xmath650 , @xmath651    let @xmath652 be the permutation realizing @xmath653 . for @xmath654 , if @xmath612 is covered by a set in the bucket in @xmath652 , then the cost of @xmath652 is no larger in instance @xmath13 and hence @xmath655 , and is the reason we had to modify it to @xmath656 . ] . in the case that the bucket in @xmath652 does not cover @xmath612 , then @xmath657 .",
    "since this also holds for @xmath615 , this implies the claim from @xmath654 .    for @xmath658 ,",
    "observe that the first set in @xmath652 that covers @xmath612 is fully determined by the partial permutation @xmath542 , since the sets in @xmath659 do not contain @xmath612 .",
    "thus @xmath660 and the claim follows .",
    "then for any @xmath654 , lemma  [ lem : wsc - ineff - sens ] implies that for any @xmath633 , @xmath661 $ ] .",
    "thus @xmath662}{{{\\bf pr}}[\\sigma_j , t_j|b ] } & \\in & [ \\exp(-2^{j - j_e+2}\\epsilon),\\exp(2^{j - j_e+2}\\epsilon)]\\end{aligned}\\ ] ] moreover , for any @xmath663 , this ratio is 1 .",
    "thus @xmath662}{{{\\bf pr}}[\\sigma_j , t_j|b ] } & \\in & [ \\pi_{j\\leq j_e}\\exp(-2^{j - j_e+2}\\epsilon ) , \\pi_{j\\leq j_e}\\exp(2^{j - j_e+2}\\epsilon)]\\\\ & \\subseteq & [ \\exp(-8\\epsilon),\\exp(8\\epsilon)],\\end{aligned}\\ ] ] which implies @xmath664-differential privacy .",
    "consider the metric facility location problem : we are given a metric space @xmath665 , a facility cost @xmath296 and a ( private ) set of demand points @xmath145 .",
    "we want to select a set of facilities @xmath139 to minimize @xmath666 .",
    "( note that we assume `` uniform '' facility costs here instead of different costs @xmath667 for different @xmath668 . )",
    "assume that distances are at least @xmath205 , and let @xmath669 denote the diameter of the space .",
    "we use the result of fakcharoenphol et al .",
    "@xcite that any metric space on @xmath21 points can be approximated by a distribution over dominating trees with expected stretch @xmath670 ; moreover all the trees in the support of the distribution are rooted @xmath300-hsts  they have @xmath671 levels , with the leaves ( at level @xmath672 ) being exactly @xmath673 , the internal nodes being all steiner nodes , the root having level @xmath619 , and all edges between levels  @xmath674 and  @xmath69 having length @xmath675 .",
    "given such a tree @xmath162 and node @xmath113 at level @xmath69 , let @xmath676 denote the ( vertices in ) the subtree rooted at @xmath113 .    by , it is clear that we can not output the actual set of facilities , so we will instead output instructions in the form of an hst @xmath677 and a set of facilities @xmath678 : each demand @xmath679 then gets assigned to its ancestor facility at the lowest level in the tree .",
    "( we guarantee that the root is always in @xmath680 , hence this is well - defined . )",
    "now we are charged for the connection costs , and for the _ facilities that have at least one demand assigned to them_.    * input : * metric @xmath665 , facility cost @xmath296 , demands @xmath681,@xmath2 .",
    "pick a random distance - preserving frt tree @xmath162 ; recall this is a @xmath300-hst with @xmath671 levels . *",
    "let * @xmath682 root @xmath24 . *",
    "let * @xmath683 and @xmath684 .",
    "[ step - fl - noise ] * if * @xmath685 * then * @xmath686 . *",
    "output * @xmath687 : each demand @xmath679 is assigned to the ancestor facility at lowest level in @xmath162 .",
    "[ thm : facloc ] the above algorithm preserves @xmath2-differential privacy and outputs a solution of cost @xmath688 .    for the privacy analysis , instead of outputting the set @xmath680 we could imagine outputting the tree @xmath162 and all the counts @xmath689 ; this information clearly determines @xmath680 .",
    "note that the tree is completely oblivious of the demand set . since adding or removing any particular demand vertex can only change @xmath619 counts , and the noise added in step  [ step - fl - noise ] gives us @xmath690-differential privacy , the fact that differential privacy composes linearly gives us the privacy claim .    for the utility analysis , consider the `` noiseless '' version of the algorithm which opens a facility at @xmath113 when @xmath691 .",
    "it can be shown that this ideal algorithm incurs cost at most @xmath692 ( see , e.g. ,  ( * ? ? ?",
    "* theorem  3 ) ) .",
    "we now have two additional sources of error due to the noise :    consider the case when @xmath693 , which increases the connection cost of some demands in @xmath694 .",
    "however , the noise is symmetric , and so we overshoot the mark with probability at most @xmath695and when this happens the @xmath300-hst property ensures that the connection cost for any demand @xmath696 increases by at most a factor of @xmath300 . since there are at most @xmath671 levels , the expected connection cost increases by at most a factor of  @xmath619 .",
    "consider the other case when @xmath697 , which increases the facility cost .",
    "note that if @xmath698 , then opening a facility at @xmath113 can be charged again in the same way as for the noiseless algorithm ( up to a factor of  @xmath300 ) .",
    "hence suppose that @xmath699 , and hence we need to consider the probability @xmath700 of the event that @xmath701 , which is just @xmath702 .",
    "note that if for some value of @xmath69 , @xmath703 , the above probability @xmath700 is at most @xmath704 , and hence the expected cost of opening up spurious facilities at nodes with such values of @xmath69 is at most @xmath705 .",
    "( there are @xmath619 levels , and at most @xmath21 nodes at each level . )    for the values of @xmath69 which are higher ;",
    "i.e. , for which @xmath706 , we pay for this facility only if there is a demand @xmath679 in the subtree below @xmath113 that actually uses this facility . hence this demand @xmath696 must have used a facility above @xmath113 in the noiseless solution , and we can charge the cost @xmath296 of opening this facility to length of the edge @xmath707 above @xmath113 .",
    "thus the total cost of spurious facilities we pay for is the cost of the noiseless solution times a factor @xmath708 .",
    "thus the expected cost of the solution is at most @xmath709",
    "recently papadimitriou et al.@xcite introduced the combinatorial public projects problem ( cpp problem ) and showed that there is a succinctly representable version of the problem for which , although there exists a constant factor approximation algorithm , no efficient _ truthful _ algorithm can guarantee an approximation ratio better than @xmath710 , unless @xmath711 . here",
    "we adapt our set cover algorithm to give a privacy preserving approximation to the cpp problem within logarithmic ( additive ) factors .    in the cpp problem ,",
    "we have @xmath21 agents and @xmath492 resources publicly known .",
    "each agent submits a private non - decreasing and _ submodular _ valuation function @xmath667 over subsets of resources , and our goal is to select a size-@xmath0 subset @xmath223 of the resources to maximize @xmath712 .",
    "we assume that we have oracle access to the functions @xmath667 .",
    "note that since each @xmath667 is submodular , so is @xmath712 , and our goal is to produce a algorithm for submodular maximization that preserves the privacy of the individual agent valuation functions . without loss of generality , we will scale the valuation functions such that they take maximum value 1 : @xmath713 .    once again , we have an easy computationally inefficient algorithm .",
    "the exponential mechanism when used to choose @xmath0 sets runs in time @xmath714 and has expected quality at least @xmath715 .",
    "we next give a computationally efficient algorithm with slightly worse guarantees .",
    "we adapt our unweighted set cover algorithm , simply selecting @xmath0 items greedily :    * input : * a set of @xmath12 of @xmath492 resources , private functions @xmath716 , a number of resources @xmath0 , @xmath717 .",
    "* let * @xmath718 , @xmath719 , @xmath720 , @xmath721 . * pick * a resource @xmath24 from @xmath722 with probability proportional to @xmath723 .",
    "* let * @xmath724 , @xmath725 .",
    "* output * @xmath726 .      except with probability @xmath727 ,",
    "the algorithm for the cpp problem returns a solution with quality at least @xmath728    since @xmath680 is submodular and there exists a set @xmath729 with @xmath730 and @xmath731 , there always exists a resource @xmath24 such that @xmath732",
    ". if we always selected the optimizing resource , the distance to @xmath211 would decrease by a factor of @xmath733 each round , and we would achieve an approximation factor of @xmath734 .",
    "instead , we use the exponential mechanism which , by , selects a resource within @xmath735 of the optimizing resource with probability at least @xmath736 . with probability at least @xmath737",
    "each of the @xmath0 selections decreases @xmath738 by a factor of @xmath739 , while increasing it by at most an additive @xmath735 , giving @xmath740 .      for any @xmath741 ,",
    "the cpp problem algorithm preserves @xmath742-differential privacy .",
    "let @xmath13 and @xmath14 be two @xmath743 instances that differ in a single agent @xmath435 with utility function @xmath744 .",
    "we show that the output set of resources , even revealing the order in which the resources were chosen , is privacy preserving .",
    "fix some ordered set of @xmath0 resources , @xmath745 write @xmath746 to denote the first @xmath251 elements , and write @xmath747 to denote the marginal utility of item @xmath152 at time @xmath69 in instance @xmath13 .",
    "define @xmath748 similarly for instance @xmath14 .",
    "we consider the relative probability of our mechanism outputting ordering @xmath247 when given inputs @xmath13 and @xmath14 : = 1 @xmath543}{{{\\bf pr}}[m(b)=\\pi ] } =   \\prod_{i=1}^k\\left(\\frac{\\exp(\\epsilon'\\cdot       s_{i,\\pi_i}(a))/(\\sum_j\\exp(\\epsilon'\\cdot       s_{i , j}(a)))}{\\exp(\\epsilon'\\cdot       s_{i,\\pi_i}(b))/(\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(b)))}\\right),\\ ] ] @xmath749}{{{\\bf pr}}[m(b)=\\pi]}\\\\ & =   \\prod_{i=1}^k\\left(\\frac{\\exp(\\epsilon'\\cdot       s_{i,\\pi_i}(a))/(\\sum_j\\exp(\\epsilon'\\cdot       s_{i , j}(a)))}{\\exp(\\epsilon'\\cdot       s_{i,\\pi_i}(b))/(\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(b)))}\\right ) ,       \\end{aligned}\\ ] ] where the sum over @xmath152 is over all remaining unselected resources .",
    "we can separate this into two products @xmath750 if @xmath13 contains agent @xmath435 but @xmath14 does not , the second product is at most 1 , and the first is at most @xmath751 .",
    "if @xmath14 contains agent @xmath435 , and @xmath13 does not , the first product is at most 1 , and in the remainder of the proof , we focus on this case",
    ". we will write @xmath752 to be the additional marginal utility of item @xmath152 at time @xmath69 in instance @xmath14 over instance @xmath13 , due to agent @xmath435 .",
    "thus @xmath753}{{{\\bf pr}}[m(b)=\\pi ] } & \\leq &     \\prod_{i=1}^k\\left(\\frac{\\sum_j\\exp(\\epsilon'\\cdot         s_{i , j}(b))}{\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(a))}\\right ) \\\\     & = &           \\prod_{i=1}^k\\left(\\frac{\\sum_j\\exp(\\epsilon'\\beta_{i , j})\\cdot\\exp(\\epsilon'\\cdot         s_{i , j}(a))}{\\sum_j\\exp(\\epsilon'\\cdot s_{i , j}(a))}\\right ) \\\\     & = &    \\prod_{i=1}^k{\\mathbf{\\mathbb{e}}}_i[\\exp(\\epsilon'\\beta_{i } ) ] ,   \\end{aligned}\\ ] ] where @xmath754 is the marginal utility actually achieved at time @xmath69 by agent @xmath435 , and the expectation is taken over the probability distribution over resources selected at time @xmath69 in instance @xmath13 .",
    "for all @xmath755 , @xmath756 .",
    "therefore , for all @xmath757 , we have : @xmath758 & \\leq & \\prod_{i=1}^ke_i[1   + ( e-1)\\epsilon'\\beta_i ] \\\\   & \\leq & \\exp((e-1)\\epsilon'\\sum_{i=1}^ke_i[\\beta_i ] ) .",
    "\\end{aligned}\\ ] ] as in the set - cover proof , we split the set of possible outputs into two sets .",
    "we call an output sequence",
    "_ @xmath25-good _ for an agent @xmath435 in instance @xmath13 if this sum @xmath759 $ ] is bounded above by @xmath25 , and call it _",
    "_ otherwise . for a @xmath760-good output @xmath247 , we can then write @xmath543}{{{\\bf pr}}[m(b)=\\pi ] } \\leq   \\exp((e-1)\\epsilon'\\cdot\\ln ( e\\delta^{-1}).\\ ] ] moreover",
    ", note that since the total realized utility of any agent is at most @xmath205 , if agent @xmath435 has realized utility @xmath761 before the @xmath69th set is chosen , then @xmath754 is distributed in @xmath762 $ ] .",
    "moreover , @xmath763 .",
    "lemma  [ lem : headsprobcont ] then implies that the probability that the algorithms outputs a @xmath760-bad permutation is at most @xmath5 . the theorem follows .    by choosing @xmath764",
    ", we immediately get @xmath2-differential privacy and expected utility at least @xmath765",
    ". this may give better guarantees for some values of @xmath0 and @xmath5 .",
    "we remark that the @xmath0-coverage problem is a special case of the cpp problem . therefore :    the cpp algorithm ( with _ sets _ as resources ) is an @xmath432-differential privacy preserving algorithm for the @xmath0-coverage problem achieving approximation factor at least @xmath766      the cpp problem can be viewed as a mechanism design problem when each agent @xmath69 has a choice of whether to submit his actual valuation function @xmath667 , or to lie and submit a different valuation function @xmath767 if such a misrepresentation yields a better outcome for agent @xmath69 .",
    "a mechanism is _ truthful _ if for every valuation function of agents @xmath768 , and every valuation function @xmath667 of agent @xmath69 , there is never a function @xmath769 such that agent @xmath69 can benefit by misrepresenting his valuation function as @xmath767 .",
    "intuitively , a mechanism is approximately truthful if no agent can make more than a slight gain by not truthfully reporting .",
    "a mechanism for the cpp problem is @xmath770-truthful if for every agent @xmath69 , for every set of player valuations @xmath771 for @xmath772 , and for every valuation function @xmath769 : = 1 @xmath773 \\geq e[f_i(m(f_1,\\ldots , f'_i,\\ldots , f_n))]-\\gamma\\ ] ] @xmath774 \\\\ & \\geq e[f_i(m(f_1,\\ldots , f'_i,\\ldots , f_n))]-\\gamma\\end{aligned}\\ ] ] note that @xmath672-truthfulness corresponds to the usual notion of ( exact ) truthfulness .",
    "@xmath432-differential privacy in our setting immediately implies @xmath775-approximate truthfulness .",
    "we note that papadimitriou et al .",
    "@xcite showed that the cpp problem is inapproximable to an @xmath710 multiplicative factor by any polynomial time @xmath672-truthful mechanism .",
    "our result shows that relaxing that to @xmath770-truthfulness allows us to give a constant approximation to the utility whenever @xmath776 for any @xmath770 .      no @xmath2-differentially private algorithm for the maximum coverage problem can guarantee profit larger than @xmath777 .",
    "the proof is almost identical to that of the lower bound for @xmath0-median , and hence is omitted .",
    "consider the steiner network problem , where we are given a metric space @xmath778 on @xmath21 points , and a ( private ) subset @xmath779 of source - sink ( terminal ) pairs .",
    "the goal is to buy a minimum - cost set of edges @xmath780 such that these edges connect up each terminal pair in @xmath32 . as in previous cases ,",
    "we give instructions in the form of a tree @xmath781 ; each terminal pair @xmath782 takes the unique path @xmath783 in this tree @xmath162 between themselves , and the ( implicit ) solution is the set of edges @xmath784 .    the tree @xmath162",
    "is given by the randomized construction of fakcharoenphol et al .",
    "@xcite , which guarantees that @xmath785 \\leq o(\\log n ) \\cdot { { \\sf opt}}$ ] ; moreover , since the construction is oblivious to the set @xmath32 , it preserves the privacy of the terminal pairs perfectly ( i.e. , @xmath786 ) .",
    "the same idea can be used for a variety of network design problem ( such as the `` buy - at - bulk '' problem ) which can be solved by reducing it to a tree instance .",
    "in this section , we show that differentially private mechanisms that give good guarantees in expectation can be repeated privately to amplify the probability of a good outcome . first note that if we simply repeat a private algorithm @xmath162 times , and select the best outcome , we can get the following result :    let @xmath787 be an @xmath2-differentially private mechanism such that for a query function @xmath25 , and a parameter @xmath788 , @xmath789 \\geq \\frac{1}{2}$ ] .",
    "then for any @xmath790 , @xmath791 , there is a mechanism @xmath792 which satisfies the following properties :    * utility : * @xmath789 \\geq ( 1 - 2^{-t})$ ] .",
    "* efficiency : * @xmath792 makes @xmath162 calls to @xmath12 .    * privacy : * @xmath792 satisfies @xmath793-differential privacy .",
    "note that the privacy parameter degrades linearly with @xmath162 .",
    "thus to bring down the failure probability to inverse polynomial , one will have to make @xmath162 logarithmic . to get @xmath178-differential privacy , one",
    "would then take @xmath2 to be @xmath794 .",
    "if @xmath788 was inversely proportional to @xmath2 , as is the case in many of our algorithms , this leads to an additional logarithmic loss .",
    "the next theorem shows a more sophisticated amplification technique that does better .",
    "let @xmath787 be an @xmath2-differentially private mechanism such that for a query function @xmath25 with sensitivity  @xmath205 , and a parameter @xmath788 , @xmath789 \\geq p$ ] for some @xmath795 .",
    "then for any @xmath790 , @xmath791 , there is a mechanism @xmath792 which satisfies the following properties :    @xmath796 \\geq ( 1-\\delta)$ ] .",
    "@xmath792 makes @xmath797 calls to @xmath12 .",
    "@xmath792 satisfies @xmath798-differential privacy .",
    "let @xmath799 .",
    "the mechanism @xmath792 runs @xmath12 on the input @xmath13 independently @xmath800 times to get outputs @xmath801 .",
    "it also adds in @xmath802 dummy outcomes @xmath803 and selects an outcome from @xmath804 using the exponential mechanism with privacy parameter @xmath805 and score function @xmath806    the efficiency of @xmath792 is immediate from the construction . to analyze the utility , note that   ensures that the exponential mechanism s output @xmath24 satisfies @xmath807 with probability @xmath808 .",
    "conditioned on the output @xmath24 satisfying this property , the ratio @xmath809/{{\\bf pr}}[r \\in s_2]$ ] is at least @xmath810 .",
    "since the numerator is at least @xmath811 in expectation , the probability of @xmath24 being a dummy outcome is at most @xmath812 .",
    "this establishes the utility property .",
    "it is easy to bound the change in the first two terms when we change from input @xmath13 to a neighboring input @xmath14 , since @xmath12 satisfies @xmath2-differential privacy , and @xmath817 has sensitivity 1 .",
    "let @xmath818 denote the denominator in the final expectation ; we would like to show that @xmath819 \\leq \\exp(\\epsilon){\\mathbf{\\mathbb{e}}}[\\frac{1}{d(b)}]$ ] for neighboring inputs @xmath13 and @xmath14 .",
    "let @xmath820 denote the constant term in @xmath821",
    ".    first observe that @xmath822&=&c+t \\cdot { \\mathbf{\\mathbb{e}}}_{r\\in m(a)}[\\exp(\\epsilon'(\\widetilde{q}(a , r)-q ) ] \\\\ & \\geq & c+t\\cdot \\exp(-\\epsilon ' ) \\cdot { \\mathbf{\\mathbb{e}}}_{r\\in m(a)}[\\exp(\\epsilon'(\\widetilde{q}(b , r)-q)]\\\\ & \\geq & c+t\\cdot \\exp(-2\\epsilon')\\cdot { \\mathbf{\\mathbb{e}}}_{r\\in m(b)}[\\exp(\\epsilon'(\\widetilde{q}(b , r)-q)]\\\\ & \\geq & \\exp(-2\\epsilon ' ) \\cdot { \\mathbf{\\mathbb{e}}}[d(b)],\\end{aligned}\\ ] ] where the first inequality follows from the sensitivity of @xmath25 and the second from the @xmath2-differential privacy of @xmath12 .",
    "thus @xmath823 $ ] is close to @xmath824 $ ] .",
    "we now show that @xmath819 $ ] is close to @xmath825}$ ] for each @xmath13 , which will complete the proof .",
    "the first step is to establish that @xmath821 is concentrated around its expectation . since @xmath826 , where the @xmath827 s are i.i.d .",
    "random variables in @xmath828 $ ] , standard concentration bounds imply @xmath829 + t ] \\leq \\exp(-2t^2/t ) ; \\;\\;\\;\\;\\;\\;\\;\\;{{\\bf pr}}[d \\leq { \\mathbf{\\mathbb{e}}}[d ] - t ] \\leq \\exp(-2t^2/t);\\ ] ]    since @xmath830 , we can now estimate @xmath831 & \\leq & \\frac{\\exp(\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d ] } + \\int_{\\frac{\\exp(\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d]}}^{\\frac{1}{c } } { { \\bf pr}}[\\frac{1}{d } \\geq y ] { \\mathrm{d}}y\\\\ & \\leq & \\frac{\\exp(\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d ] } + \\int_{c}^{\\exp(-\\epsilon'){\\mathbf{\\mathbb{e}}}[d ] } \\frac{{{\\bf pr}}[d \\leq z]}{z^2 } { \\mathrm{d}}z\\\\ & \\leq & \\frac{\\exp(\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d ] } + \\frac{1}{c^2}\\int_{c}^{\\exp(-\\epsilon'){\\mathbf{\\mathbb{e}}}[d ] } \\exp(-2(z-{\\mathbf{\\mathbb{e}}}[d])^2/t ) { \\mathrm{d}}z\\\\ & \\leq & \\frac{\\exp(\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d ] } + \\frac{(\\exp(-\\epsilon'){\\mathbf{\\mathbb{e}}}[d]-c)}{c^2 } \\exp(-(\\epsilon ' { \\mathbf{\\mathbb{e}}}[d])^2/t)\\\\ & \\leq & \\frac{\\exp(\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d ] } + \\frac{1}{t^2}\\end{aligned}\\ ] ] since @xmath832 > c > \\frac{\\sqrt{4t\\log t}}{\\epsilon'}$ ] , @xmath832 < 2t$ ] , and @xmath833 .",
    "thus @xmath834 \\leq \\frac{\\exp(2{\\varepsilon}')}{{\\mathbf{\\mathbb{e}}}[d]}$ ] .",
    "similarly , @xmath831 & \\geq & \\frac{\\exp(-\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d ] } -   \\int_{0}^{\\frac{\\exp(-\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d ] } } { { \\bf pr}}[\\frac{1}{d } \\leq y ] { \\mathrm{d}}y\\\\ & \\geq & \\frac{\\exp(-\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d ] } -   \\int_{\\exp(\\epsilon'){\\mathbf{\\mathbb{e}}}[d]}^{\\infty } \\frac{{{\\bf pr}}[d \\geq z]}{z^2 } { \\mathrm{d}}z\\\\ & \\geq & \\frac{\\exp(-\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d ] } -   \\frac{\\exp(-2\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d]^2}\\int_{\\exp(\\epsilon'){\\mathbf{\\mathbb{e}}}[d]}^{\\infty } \\exp(-2(z-{\\mathbf{\\mathbb{e}}}[d])^2/t ) { \\mathrm{d}}z\\\\ & \\geq & \\frac{\\exp(-\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d ] } -   \\frac{\\exp(-2\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d]^2}\\sqrt{t}\\\\ & \\geq & \\frac{\\exp(-\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d ] } - \\frac{\\epsilon'}{{\\mathbf{\\mathbb{e}}}[d]},\\end{aligned}\\ ] ] so that @xmath834 \\geq \\frac{\\exp(-3\\epsilon')}{{\\mathbf{\\mathbb{e}}}[d]}$ ] .",
    "thus @xmath819\\leq \\exp(7\\epsilon'){\\mathbf{\\mathbb{e}}}[\\frac{1}{d(b)}]$ ] for neighboring inputs @xmath13 and @xmath14 .",
    "now using this fact in expression   for @xmath835 $ ] above , we conclude that @xmath792 satisfies @xmath836-differential privacy .",
    "bmnw07    vijay arya , naveen garg , rohit khandekar , adam meyerson , kamesh munagala , and vinayaka pandit .",
    "local search heuristics for @xmath0-median and facility location problems . , 33(3):544562 , 2004 .",
    "a.  beimel , p.  carmi , k.  nissim , and e.  weinreb . .",
    "in _ proceedings of the thirty - eighth annual acm symposium on theory of computing _ , pages 119128 .",
    "acm new york , ny , usa , 2006 .    a.  beimel , r.  hallak , and k.  nissim . . ,",
    "4392:383 , 2007 .",
    "a.  blum , k.  ligett , and a.  roth . .",
    "in _ proceedings of the fourtieth annual acm symposium on theory of computing _ , pages 609618 .",
    "acm new york , ny , usa , 2008 .",
    "a.  beimel , t.  malkin , k.  nissim , and e.  weinreb . in _",
    "volume 4622 , page  31 .",
    "springer , 2007 .",
    "amos beimel , kobbi nissim , and eran omri . distributed private data analysis : simultaneously solving how and what . in david wagner , editor , _",
    "crypto _ , volume 5157 of _ lecture notes in computer science _ , pages 451468 .",
    "springer , 2008 .",
    "v.  chvtal . . ,",
    "pages 233235 , 1979 .",
    "cynthia dwork , krishnaram kenthapadi , frank mcsherry , ilya mironov , and moni naor . our data , ourselves : privacy via distributed noise generation .",
    "in _ advances in cryptology ",
    "eurocrypt 2006 _ , volume 4004 of _ lecture notes in comput .",
    "_ , pages 486503 .",
    "springer , berlin , 2006 .    c.  dwork , f.  mcsherry , k.  nissim , and a.  smith . . ,",
    "pages 265284 , 2006 .    c.  dwork , m.  naor , o.  reingold , g.n .",
    "rothblum , and s.  vadhan . .",
    "in _ proceedings of the 41st annual acm symposium on symposium on theory of computing _ , pages 381390 .",
    "acm new york , ny , usa , 2009 .    cynthia dwork . differential privacy . in _",
    "automata , languages and programming .",
    "part ii _ ,",
    "volume 4052 of _ lecture notes in comput .",
    "_ , pages 112 .",
    "springer , berlin , 2006 .    c.  dwork . .",
    "in _ theory and applications of models of computation ",
    "tamc 2008 _ , volume 4978 of _ lecture notes in computer science _",
    ", pages 119 , 2008 .",
    "ford and d.r .",
    "fulkerson . .",
    ", 8(3):399404 , 1956 .",
    "d.  feldman , a.  fiat , h.  kaplan , and k.  nissim . .",
    "in _ proceedings of the 41st annual acm symposium on symposium on theory of computing _ , pages 361370 .",
    "acm new york , ny , usa , 2009 .",
    "joan feigenbaum , yuval ishai , tal malkin , kobbi nissim , martin  j. strauss , and rebecca  n. wright .",
    "secure multiparty computation of approximations .",
    ", 2(3):435472 , 2006 .",
    "jittat fakcharoenphol , satish rao , and kunal talwar .",
    "a tight bound on approximating arbitrary metrics by tree metrics .",
    ", 69(3):485497 , 2004 .",
    "s.  halevi , r.  krauthgamer , e.  kushilevitz , and k.  nissim . .",
    "in _ proceedings of the thirty - third annual acm symposium on theory of computing _ , pages 550559 .",
    "acm new york , ny , usa , 2001 .    d.s .",
    "hochbaum . .",
    ", 11:555 , 1982 .",
    "p.  indyk . .",
    "in _ proceedings of the thirty - sixth annual acm symposium on theory of computing _ , pages 373380 .",
    "acm new york , ny , usa , 2004 .",
    "p.  indyk and d.  woodruff . .",
    ", 3876:245 , 2006 .",
    "johnson . .",
    ", 9:256278 , 1974 .",
    "david  r. karger .",
    "global min - cuts in rnc , and other ramifications of a simple min - cut algorithm . in _ proceedings of the fourth annual acm - siam symposium on discrete algorithms ( austin , tx , 1993 ) _",
    ", pages 2130 , new york , 1993 .",
    "shiva kasiviswanathan , homin  k. lee , kobbi nissim , sofya raskhodnikova , and adam smith .",
    "what can we learn privately ?",
    "in _ proceedings of the 49th annual symposium on foundations of computer science _ , 2008 .",
    "ashwin machanavajjhala , daniel kifer , john  m. abowd , johannes gehrke , and lars vilhuber .",
    "privacy : theory meets practice on the map . in _",
    "icde _ , pages 277286 .",
    "ieee , 2008 .",
    "f.  mcsherry and k.  talwar . .",
    "in _ proceedings of the 48th annual ieee symposium on foundations of computer science _ , pages 94103 , 2007 .",
    "kobbi nissim , sofya raskhodnikova , and adam smith .",
    "smooth sensitivity and sampling in private data analysis . in _ stoc07proceedings of the 39th annual acm symposium on theory of computing _ , pages 7584 .",
    "acm , new york , 2007 .",
    "gl  nemhauser , la  wolsey , and ml  fisher . .",
    ", 14(1):265294 , 1978 .",
    "l.  pitt . a simple probabilistic approximation algorithm for vertex cover . technical report , yale university , 1985 .    c.  papadimitriou , m.  schapira , and y.  singer . .",
    "in _ proceedings of the 49th annual ieee symposium on foundations of computer science _ , 2008 .",
    "in this section , we consider a slightly different way to implement the vertex cover algorithm . given a graph @xmath43 , we mimic the randomized proportional - to - degree algorithm for @xmath837 rounds ( @xmath838 ) , and output the remaining vertices in random order . that is , in each of the first @xmath837 rounds , we select the next vertex @xmath69 with probability proportional to @xmath839 : this is equivalent to imagining that each vertex has @xmath291 `` hallucinated '' edges in addition to its real edges .",
    "( it is most convenient to imagine the other endpoint of these hallucinated edges as being fake vertices which are always ignored by the algorithm . )",
    "when we select a vertex , we remove it from the graph , together with the real and hallucinated edges adjacent to it .",
    "this is equivalent to picking a random ( real or hallucinated ) edge from the graph , and outputting a random real endpoint .",
    "outputting a vertex affects the real edges in the remaining graph , but does not change the hallucinated edges incident to other vertices .",
    "[ [ privacy - analysis . ] ] privacy analysis .",
    "+ + + + + + + + + + + + + + + + +    the privacy analysis is similar to that of theorem  [ thm : privacy ] : imagine the weights being @xmath840 for the first @xmath837 rounds and @xmath841 for the remaining rounds , which gives us @xmath842-differential privacy .",
    "[ [ utility - analysis . ] ] utility analysis .",
    "+ + + + + + + + + + + + + + + + +    to analyze the utility , we couple our algorithm with a run of the non - private algorithm @xmath361 that at each step picks an arbitrary edge of the graph and then picks a random endpoint : it is an easy exercise that this an @xmath300-approximation algorithm .",
    "we refer to vertices that have non - zero `` real '' degree at the time they are selected by our algorithm as _ interesting vertices _",
    ": the cost of our algorithm is simply the number of interesting vertices it selects in the course of its run .",
    "let @xmath843 denote the number of interesting vertices it selects during the first @xmath837 steps , and @xmath844 denote the number of interesting vertices it selects during its remaining @xmath845 steps , when it is simply ordering vertices randomly .",
    "clearly , the total cost is @xmath846 .",
    "we may view the first phase of our algorithm as selecting an edge at random ( from among both real and hallucinated ones ) and then outputting one of its endpoints at random .",
    "now , for the rounds in which our algorithm selects a real edge , we can couple this selection with one step of an imagined run of @xmath361 ( selecting the same edge and endpoint ) . note that this run of @xmath361 maintains a vertex cover that is a subset of our vertex cover , and that once our algorithm has completed a vertex cover , no interesting vertices remain . therefore , while our algorithm continues to incur cost , @xmath361 has not yet found a vertex cover .    in the first phase of our algorithm",
    ", every interesting vertex our algorithm selects has at least one real edge adjacent to it , as well as @xmath291 hallucinated edges . conditioned on selecting an interesting vertex , our algorithm had selected a real edge with probability at least @xmath847 .",
    "let @xmath32 denote the random variable that represents the number of steps @xmath361 is run for .",
    "@xmath848 \\leq 2{{\\sf opt}}$ ] since @xmath361 is a @xmath300-approximation algorithm . by linearity of expectation : @xmath849 \\geq \\epsilon'\\cdot e[i_1]\\ ] ] we now show that most of our algorithm s cost comes from the first phase , and hence that @xmath844 is not much larger than @xmath843 .",
    "@xmath850 \\geq \\ln \\left(\\frac{1}{1-\\alpha}\\right ) \\cdot { \\mathbf{\\mathbb{e}}}[i_2]\\ ] ]    consider each of the @xmath837 steps of the first phase of our algorithm .",
    "let @xmath851 denote the number of interesting vertices remaining at step @xmath69 .",
    "note that @xmath852 is a non - increasing sequence . at step",
    "@xmath69 , there are @xmath851 interesting vertices and @xmath853 remaining vertices .",
    "note that the probability of picking an interesting vertex is strictly greater than @xmath854 at each step .",
    "we may therefore bound the expected number of interesting vertices picked in the first phase : @xmath850 > \\sum_{i=1}^{\\alpha n}\\frac{{\\mathbf{\\mathbb{e}}}[n_i]}{n - i+1 } \\geq { \\mathbf{\\mathbb{e}}}[n_{\\alpha      n}]\\sum_{j=(1-\\alpha)n}^{n}\\frac{1}{j } \\geq \\ln    \\left(\\frac{1}{1-\\alpha}\\right ) \\cdot { \\mathbf{\\mathbb{e}}}[n_{\\alpha n}]\\ ] ] noting that @xmath855 \\leq { \\mathbf{\\mathbb{e}}}[n_{\\alpha n}]$ ] completes the proof .",
    "combining the facts above , we get that @xmath856}{{{\\sf opt } } } \\leq \\frac{2}{\\epsilon ' } \\ ; \\left(1 +      \\frac{1}{\\ln ( 1-\\alpha)^{-1}}\\right).\\end{gathered}\\ ] ]",
    "[ sec : deltafix ] in this section , we prove lemma  [ lem : deltafix ] . the lemma is a consequence of the following more general inequality .",
    "consider the following @xmath21 round probabilistic process . in each round ,",
    "an adversary chooses a @xmath857 $ ] possibly based on the first @xmath858 rounds and a coin is tossed with heads probability @xmath700 .",
    "let @xmath859 be the indicator for the the event that no coin comes up heads in the first @xmath69 steps .",
    "let @xmath860 denote the random variable @xmath861 and let @xmath862 .",
    "we claim that for any @xmath152 and any @xmath25 ,",
    "@xmath865 \\leq \\exp(-q)$ ] , which implies the lemma .",
    "the proof is by reverse induction on @xmath152 . for @xmath866",
    ", @xmath867 is @xmath672 if the @xmath21th coin or any coin before it comes up heads and @xmath868 otherwise .",
    "thus for @xmath869 , the left hand side is zero . for @xmath870 ,",
    "the left hand side is at most @xmath871 .",
    "finally , for @xmath872 the right hand side exceeds 1 .",
    "now suppose that for any adversary s strategy and for all @xmath25 , @xmath873 \\leq \\exp(-q)$ ] .",
    "we will show the claim for @xmath860 . once again , for @xmath874 , the claim is trivial . in round",
    "@xmath152 , if the adversary chooses @xmath875 , there is a probability @xmath875 that the coin comes up heads so that @xmath876 .",
    "thus for any @xmath877 , @xmath865 = { { \\bf pr}}[p_j z_j + y_{j+1 } > q ] = ( 1-p_j )    { { \\bf pr}}[y_{j+1 } > q - p_j]$ ] . using the inequality @xmath878 and the inductive hypothesis",
    ", the claim follows for @xmath860 .    to map the randomized algorithm to the setting of lemma  [ lem : headsprob ] , we consider running the randomized weighted set cover algorithm as follows .",
    "when choosing a set @xmath223 in step @xmath69 , the algorithm first tosses a coin whose heads probability is @xmath446 to decide whether to pick a set covering @xmath435 or not . then it uses a second source of randomness to determine the set @xmath223 itself , sampling from @xmath879 or @xmath880 with the appropriate conditional probabilities based on the outcome of the coin .",
    "clearly this is a valid implementation of the weighted set cover algorithm .",
    "note that the probabilities @xmath446 may depend on the actual sets chosen in the first @xmath858 steps if none of the first @xmath858 coins come up heads . since lemma  [ lem : headsprob ] applies even when @xmath446 s are chosen adversarially",
    ", lemma  [ lem : deltafix ] follows .",
    "we also prove a more general version of lemma  [ lem : headsprob ] that applies to non - bernoulli distributions .",
    "this lemma will be needed to prove the privacy of our algorithm for submodular minimization in section  [ sec : cpp ] .",
    "we now consider a different @xmath21 round probabilistic process . in each round ,",
    "an adversary chooses a distribution @xmath881 over @xmath828 $ ] , possibly based on the first @xmath858 rounds and a sample @xmath487 is drawn from the distribution @xmath881 .",
    "let @xmath882 and let @xmath883 .",
    "let @xmath860 denote the random variable @xmath884 $ ] and let @xmath863 denote @xmath885 .",
    "we prove a stronger claim .",
    "we show that for @xmath886 \\leq e\\exp(-q)$ ] .",
    "the proof is by reverse induction on @xmath152 . for @xmath866 , @xmath887 z_n \\leq z_n$ ] since @xmath888 is supported on @xmath828 $ ] and hence has expectation at most 1 .",
    "thus the claim is trivial for any @xmath889 . for @xmath890 ,",
    "the right hand side is at least 1 and there is nothing to prove .",
    "supppose that for any @xmath25 and any strategy of the adversary , @xmath891 \\leq e\\exp(-q)$ ] .",
    "we show the claim for @xmath860 .",
    "once again the case @xmath892 is trivial , so we assume @xmath889 .",
    "let @xmath618 denote @xmath893 $ ] .",
    "note that @xmath894 .",
    "moreover , @xmath895 .",
    "thus , = 1 @xmath896 = e_{r_j \\in { \\mathcal{d}}_j } [ { { \\bf pr}}[y_{j+1 } \\geq qz_j - \\mu_j z_j ] ] = e_{r_j \\in { \\mathcal{d}}_j } [ { { \\bf pr}}[y_{j+1 } \\geq \\frac{q-\\mu_j}{1-r_j } z_{j+1 } ] ] \\leq e_{r_j \\in { \\mathcal{d}}_j}[e \\exp(-\\frac{q-\\mu_j}{1-r_j})].\\ ] ] @xmath897 & = & e_{r_j \\in { \\mathcal{d}}_j } [ { { \\bf pr}}[y_{j+1 } \\geq qz_j - \\mu_j z_j]]\\\\ & = & e_{r_j \\in { \\mathcal{d}}_j } [ { { \\bf pr}}[y_{j+1 } \\geq \\frac{q-\\mu_j}{1-r_j } z_{j+1 } ] ] \\\\ & \\leq & e_{r_j \\in { \\mathcal{d}}_j}[e \\exp(-\\frac{q-\\mu_j}{1-r_j})].\\end{aligned}\\ ] ] we show that for any distribution @xmath898 , the last term is bounded by @xmath899 , which will complete the proof .",
    "re - arranging , it suffices to show that for any distribution @xmath898 on @xmath828 $ ] , @xmath900 \\leq 1.\\ ] ] since @xmath901 is positive when @xmath902 and negative otherwise , one can verify that for any @xmath32 , @xmath903 .",
    "moreover , since @xmath904 is convex , the function lies below the chord and we can conclude that @xmath905 .",
    "thus it suffices to prove that @xmath906 or equivalently @xmath907 this rearranges to @xmath908 consider the function @xmath909 .",
    "@xmath296 is convex with @xmath910 and @xmath911 .",
    "thus @xmath912 , for @xmath889 .",
    "the claim follows ."
  ],
  "abstract_text": [
    "<S> consider the following problem : given a metric space , some of whose points are `` clients , '' select a set of at most @xmath0 facility locations to minimize the average distance from the clients to their nearest facility . </S>",
    "<S> this is just the well - studied @xmath0-median problem , for which many approximation algorithms and hardness results are known . </S>",
    "<S> note that the objective function encourages opening facilities in areas where there are many clients , and given a solution , it is often possible to get a good idea of where the clients are located . </S>",
    "<S> this raises the following quandary : what if the locations of the clients are sensitive information that we would like to keep private ? _ is it even possible to design good algorithms for this problem that preserve the privacy of the clients ? _    in this paper , we initiate a systematic study of algorithms for discrete optimization problems in the framework of differential privacy ( which formalizes the idea of protecting the privacy of individual input elements ) . </S>",
    "<S> we show that many such problems indeed have good approximation algorithms that preserve differential privacy ; this is even in cases where it is impossible to preserve cryptographic definitions of privacy while computing any non - trivial approximation to even the _ value _ of an optimal solution , let alone the entire solution .    </S>",
    "<S> apart from the @xmath0-median problem , we consider the problems of vertex and set cover , min - cut , facility location , and steiner tree , and give approximation algorithms and lower bounds for these problems . </S>",
    "<S> we also consider the recently introduced submodular maximization problem , `` combinatorial public projects '' ( cpp ) , shown by papadimitriou et al . </S>",
    "<S> @xcite to be inapproximable to subpolynomial multiplicative factors by any efficient and _ truthful _ algorithm . </S>",
    "<S> we give a differentially private ( and hence approximately truthful ) algorithm that achieves a logarithmic additive approximation .    </S>",
    "<S> = 1 </S>"
  ]
}