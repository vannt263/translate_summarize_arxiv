{
  "article_text": [
    "the segmentation of multi - view video data , with respect to physically distinct objects of interest , is an essential task in automatic scene - interpretation .",
    "visual segmentation can be based on colour , texture , parallax and motion information ( e.g.  @xcite ) .",
    "the task remains very difficult , however , owing to the combined effects of non - rigid surfaces , variable lighting , and occlusion .",
    "it has become clear that depth cameras can make an important contribution to scene understanding , by enabling direct _ depth segmentation _ , based on the measured scene - structure ( see cviu special issue @xcite ) .",
    "this approach is also highly effective for dynamic tasks , such as body tracking and action recognition @xcite .",
    "furthermore , if depth and colour information can be merged into a single representation , then a complete  representation is possible , in principle .",
    "this is clearly desirable , because colour and texture data are essential to many other aspects of scene - understanding , such as identification and tracking @xcite .",
    "there are two major obstacles to the construction of a complete scene representation , from a multi - modal camera network .",
    "firstly , typical depth sensors are unable to capture rgb  data @xcite .",
    "this means that the depth and colour cameras will have different viewpoints , and so the raw data are _",
    "inconsistent_. secondly , typical  and rgb  cameras have limited fields of view , and so the depth and colour data are _",
    "incomplete_. this paper addresses both of these problems , by showing how to estimate the geometric relationships in a multi - view , multi - modal camera network .",
    "this task will be called _ cross - calibration_.    in order to constrain the problem , two practical constraints are imposed from the outset .",
    "firstly , the system will be based on _ time - of - flight _ ( ) cameras , in conjunction with ordinary rgb  cameras .",
    "the  cameras are compact , can be properly synchronized , and are industrially specified , e.g. , @xcite .",
    "secondly , a _ modular _ network of + rgb  units is required .",
    "this is so that individual units can be added or removed , in order to optimize the scene - coverage .",
    "time - of - flight cameras can , in principle , be geometrically calibrated by standard methods @xcite .",
    "this means that each pixel records an estimate of the scene - distance ( range ) along the corresponding ray .",
    "the  structure of a scene can also be reconstructed from two or more ordinary images , via the _ parallax _",
    "( e.g.  binocular disparity ) between corresponding image points .",
    "there are many advantages to be gained by combining the range and parallax data .",
    "most obviously , each point in a parallax - based reconstruction can be mapped back into the original images , from which colour and texture can be obtained .",
    "parallax - based reconstructions are , however , difficult to obtain , owing to the difficulty of putting the image points into correspondence .",
    "indeed , it may be impossible to find any correspondences in untextured regions .",
    "furthermore , if a euclidean reconstruction is required , then the cameras must be calibrated .",
    "the accuracy of the resulting reconstruction will also tend to decrease with the distance of the scene from the cameras @xcite .",
    "the range data , on the other hand , are often corrupted by noise and surface - scattering .",
    "the spatial resolution of current  sensors is relatively low , the depth - range is limited , and the luminance signal may be unusable for rendering and for classical image processing .",
    "it should also be recalled that  cameras , of the type used here , can not be used in outdoor lighting conditions .",
    "these considerations lead to the idea of a _",
    "mixed _ colour and time - of - flight system , as described in  @xcite .",
    "such a system could , in principle , be used to make high - resolution euclidean reconstructions , including photometric information @xcite .    in order to make full use of a mixed range / parallax system ,",
    "it is necessary to find the exact geometric relationship between the different devices .",
    "in particular , the reprojection of the  data , into the colour images , must be obtained .",
    "this paper is concerned with the estimation of these geometric relationships . specifically , the aim is to align the range and parallax reconstructions , by a suitable  transformation .",
    "multi - view depth and colour camera - networks , of the kind used here , produce data - streams that are subject to a variety of geometric relationships @xcite .",
    "these relationships depend on the calibration state , relative orientation , and fields of view of the different cameras .",
    "it follows that a variety of calibration strategies can be adopted .",
    "these are discussed below , with reference to the literature , and contrasted with the approach presented here .",
    "perhaps the simplest way to combine rgb  and  data is to perform an essentially  registration between the images and depth maps , as reviewed in @xcite ; see also @xcite .",
    "this  approach , however , can only provide an instantaneous solution , because changes in the scene - structure produce corresponding changes in the image - to - image mapping .",
    "moreover , owing to the different viewpoints , a complete registration will usually be impossible .",
    "if the depth camera also produces a reliable intensity image , then photo - consistency can be used as a  calibration criterion . for example , beder et al .",
    "@xcite ( see also @xcite ) reproject the _ intensities _ of the depth data into the colour images , and optimize the camera parameters with respect to the photo - consistency .",
    "zhu et al .",
    "@xcite ( see also @xcite ) present a sensor - fusion framework for the integration of  depth and binocular disparity information .",
    "this method assumes that a dense disparity map is being computed on - line , which is not required by the method presented in this paper .",
    "furthermore , the geometric calibration method @xcite requires manual identification of corresponding points , and is based on a weak perspective camera model .",
    "in contrast , our method is automatic , and is based on the more appropriate perspective camera model .",
    "however , @xcite is complementary to our method , in the sense that their sensor - fusion framework ( along with a dense stereo - matcher ) could be combined with the projective calibration method described below .",
    "wang and jia @xcite describe a related sensor - fusion framework for kinect ( rather than ) depth data and colour images .",
    "another approach to the multi - modal calibration problem is to apply standard methods , as far as possible , to the depth cameras .",
    "@xcite describe an example of this approach .",
    "lindner et al .",
    "@xcite analyze the applicability of standard methods to  cameras , as well as characterizing the accuracy of the depth data .",
    "mure - dubois and hgli @xcite describe the euclidean alignment of multiple  point clouds , having calibrated the cameras by standard methods .",
    "silva et  al .",
    "@xcite describe a cross - calibration methodology that is based on the identification of  lines in the  data , which are then projected to corresponding  lines in the rgb  images .",
    "this method does not require a chequerboard or other calibration pattern ; it does , however , require the existence and detection of straight depth - edges throughout the scene .",
    "the approach of silva et al .  also involves a non - trivial correspondence problem , which in turn influences the calibration accuracy .",
    "our method uses a standard chequerboard pattern , with a known number of vertices , for which the correspondence problem is relatively straightforward .",
    "zhang and zhang @xcite present cross - calibration methodology that is based on plane constraints , as given in @xcite .",
    "this has the advantage of not requiring  features to be detected in the ( low resolution )  images .",
    "however , this method can not address the crucial issue of lens distortion , which is considerable in typical  cameras @xcite .",
    "a related kinect - based calibration system is described by herrera et  al .",
    "@xcite , again using the plane - based method of @xcite .",
    "herrera et al .",
    "give a careful analysis of the kinect intrinsic parameters , including lens and depth distortion .",
    "the latter is analyzed in more detail by teichman et  al .",
    "our method does require features to be detected in the  images , but this also makes it straightforward to estimate the lens parameters , using standard techniques .",
    "mikhelson  et  al .",
    "@xcite describe an automatic method for registering a euclidean point - cloud ( obtained from a kinect device ) to its  image - projections .",
    "this method , like ours , is based on a chequerboard target",
    ". however , mikhelson et al .",
    "perform euclidean /  registration , in contrast to the more general projective /  registration that is described below .",
    "finally , there are methods that perform /  registration of dense data , subject to pointwise adjustments @xcite .",
    "this strategy can achieve very close registrations , but introduces a more complex optimization problem , which is not fully compatible with the standard calibration pipeline .",
    "this paper is organized as follows .",
    "section [ sec : parallax ] briefly reviews some standard material on projective reconstruction , while section [ sec : range ] describes the representation of range data in the present work .",
    "the chief contributions of the subsequent sections are as follows : section  [ sec : alignment ] describes a point - based method that maps a classical multi - view reconstruction ( projective or euclidean ) of the scene onto the corresponding  representation .",
    "the data are obtained from a  system , as shown in figure  [ fig : system ] .",
    "this does not require the colour cameras to be calibrated ( although it is necessary to correct for lens distortion ) .",
    "it is established that this model includes a projective - linear approximation of the systematic  depth - error .",
    "section  [ sec : multi - align ] addresses the problem of multi - system alignment , which is necessary for complete scene - coverage .",
    "it is shown that this can be achieved in a way that is compatible with the individual  calibrations .",
    "the complete cross - calibration pipeline , given a collection of chequerboard images , is fully automatic .",
    "section  [ sec : evaluation ] contains a detailed evaluation of these methods , using several large data - sets , captured by three  systems ( i.e.  a nine - camera network ) .",
    "in particular , section [ sec : cal - err ] extends the usual concepts of reprojection error @xcite to the multi - modal case .",
    "section [ sec : tot - err ] then introduces a new metric for mixed /rgb  systems , which measures instantaneous sensor noise , as well as calibration error .",
    "the appropriateness of the  homography transformation , as opposed to a similarity transformation , is tested in section  [ sec : similarity ] .",
    "section [ sec : applications ] discusses possible applications of these systems , including some real  reconstruction examples .",
    "conclusions and future directions are discussed in section  [ sec : conclusion ] .",
    "the system presented here is based on the approach introduced by hansard et al .",
    "the earlier work has been improved , and extended to the case of multiple   and colour cameras .",
    "in addition , a new evaluation methodology has been developed , as described above .",
    "the automatic detection of calibration targets in the low - resolution  images , which is a pre - requisite for the methods described here , was developed in a separate paper @xcite .",
    "this section describes the theory of projective alignment , using the following notation .",
    "bold type will be used for vectors and matrices . in particular , points @xmath0 , @xmath1 and planes @xmath2 , @xmath3 in the  scene will be represented by column - vectors of homogeneous coordinates , e.g.@xmath4 where @xmath5 and @xmath6 .",
    "the homogeneous coordinates are defined up to a non - zero scaling ; for example , @xmath7 . in particular , if @xmath8 , then @xmath9 contains the ordinary space coordinates of the point @xmath0 .",
    "furthermore , if @xmath10 , then @xmath11 is the signed perpendicular distance of the plane @xmath2 from the origin , and @xmath12 is the unit normal .",
    "the point @xmath0 is on the plane @xmath2 if @xmath13 .",
    "the cross product @xmath14 is often expressed as @xmath15 , where @xmath16 is a @xmath17 antisymmetric matrix .",
    "the column - vector of @xmath18 zeros is written @xmath19 .",
    "projective cameras are represented by @xmath20 matrices .",
    "for example , the range projection is @xmath21 is a block - decomposition of the @xmath20 camera matrix .",
    "the left and right colour cameras @xmath22 and @xmath23 are similarly defined , e.g.  .",
    "table [ tab : notation ] summarizes the geometric objects that will be aligned .",
    "r|ccc & observed & + & points & points & planes +   + binocular @xmath22,@xmath23 & @xmath24 , @xmath25 & @xmath0 & @xmath2 + range @xmath26 & @xmath27 & @xmath1 & @xmath3    points and planes in the two systems are related by the unknown @xmath28 space - homography @xmath29 , so that @xmath30 this model encompasses all rigid , similarity and affine transformations in  .",
    "it preserves _ collinearity _ and _ flatness _ , and is linear in homogeneous coordinates .",
    "note that , in the reprojection process , @xmath29 can be interpreted as a modification of the camera matrices .",
    "for example , , where is the point that would theoretically be reconstructed by triangulation .",
    "the @xmath28 homographies @xmath29 include , as special cases , the rigid transformations that would align a fully - calibrated euclidean stereo - reconstruction to the  measurements .",
    "there are two motivations for the generalization .",
    "firstly , it allows uncalibrated binocular reconstructions to be used , as described above .",
    "secondly , it has been shown elsewhere @xcite that  data are subject to _ systematic _ depth biases and nonlinear distortions .",
    "these are difficult to correct , owing to the lack of a complete parametric model , and to their dependence on the camera settings ( e.g.  integration time ) .",
    "nonetheless , the homography model effectively includes a projective - linear approximation of the depth distortion , which is fitted along with the other transformation parameters .",
    "this model is quite powerful : it includes rational depth - distortions , with varying parameters , across each bundle of rays .",
    "for example , the two - parameter inverse disparity calibration , as used with kinect devices @xcite , is a special case of the homography model described here .",
    "indeed , even if the rgb  cameras are fully calibrated , the  homographies are needed to account for depth - distortions and residual reconstruction errors , as demonstrated in  @xcite .",
    "this issue will be explored in section [ sec : similarity ] , below .",
    "a projective reconstruction of the scene can be obtained from matched points @xmath31 and @xmath32 , together with the fundamental matrix @xmath33 , where .",
    "the fundamental matrix can be estimated automatically , using the well - established ransac method .",
    "the camera matrices can then be determined , up to a four - parameter projective ambiguity @xcite . in particular , from @xmath33 and the epipole @xmath34 , the cameras can be defined as @xmath35 where @xmath36 and @xmath37 can be used to bring the cameras into a plausible form .",
    "this makes it easier to visualize the projective reconstruction and , more importantly , can improve the numerical conditioning of subsequent procedures .",
    "the  camera @xmath26 provides the range ( i.e.  radial distance ) @xmath38 of each scene - point from the camera - centre , as well as the associated image - coordinates @xmath39 .",
    "the back - projection of this point into the scene is @xmath40 hence the point @xmath41 is at distance @xmath38 from the optical centre @xmath42 , in the direction @xmath43 .",
    "the scalar @xmath44 serves to normalize the direction - vector .",
    "this is the standard pinhole model , as used in @xcite .",
    "the range data are noisy and incomplete , owing to illumination and scattering effects .",
    "this means that , given a sparse set of features in the intensity image ( of the  device ) , it is not advisable to use the back - projected point directly .",
    "a better approach is to segment the image of the plane in each  camera ( using the the range and/or intensity data ) .",
    "it is then possible to back - project _ all _ of the enclosed points , and to robustly fit a plane @xmath45 to the enclosed points @xmath46 , so that @xmath47 if point @xmath48 lies on plane @xmath49 . now , the back - projection @xmath50 of each sparse feature point @xmath51 can be obtained by intersecting the corresponding ray with the plane @xmath3 , so that the new range estimate @xmath52 is @xmath53 where @xmath54 is the distance of the plane to the camera centre , and @xmath55 is the unit - normal of the range plane . the new point @xmath56 is obtained by substituting @xmath52 into .",
    "the choice of plane - fitting method is affected by two issues .",
    "firstly , there may be very severe outliers in the data , due to the photometric and geometric errors in the depth - estimation process .",
    "secondly , the noise - model should be based on the pinhole geometry , which means that perturbations occur radially along visual directions , which are not ( in general ) perpendicular to the observed plane @xcite .",
    "several plane - fitting methods , both iterative @xcite and non - iterative @xcite have been proposed for the pinhole model . however , for  data , the chief problem is the large number of outliers .",
    "this means that a ransac - based method is the most effective in this context  @xcite .",
    "it is straightforward to show that the transformation @xmath29 in could be estimated from five binocular points @xmath57 , together with the corresponding range points @xmath58",
    ". this would provide @xmath59 equations , which determine the @xmath28 entries of @xmath29 , subject to an overall projective scaling .",
    "it is better , however , to use the ` direct linear transformation ' method @xcite , which fits @xmath29 to _ all _ of the data .",
    "this method is based on the fact that if @xmath60 is a perfect match for @xmath1 , then @xmath61 , and the scalars @xmath62 and @xmath63 can be eliminated between pairs of the four implied equations @xcite .",
    "this results in @xmath64 interdependent constraints per point .",
    "it is convenient to write these homogeneous equations as @xmath65 { \\mathitbf{q}}_{{\\mspace{-1mu}\\vartriangle}}\\times { \\mathitbf{p}}_{{\\mspace{-1mu}\\vartriangle } } ' \\end{pmatrix } = { \\mathitbf{0}}_{\\mspace{2mu}6}. \\label{eqn : constraints}\\ ] ] note that if @xmath66 and @xmath1 are normalized so that @xmath67 and @xmath68 , then the magnitude of the top half of is simply the distance between the points .",
    "following frstner @xcite , the left - hand side of can be expressed as @xmath69 where @xmath70 \\bigl({\\mathitbf{q}}_{{\\mspace{-1mu}\\vartriangle}}\\bigr)_\\times & { \\mathitbf{0}}_{\\mspace{2mu}3 }   \\end{pmatrix } \\label{eqn : operator}\\ ] ] is a @xmath71 matrix , and @xmath72 , as usual .",
    "the equations can now be written in terms of and as @xmath73 this system of equations is linear in the unknown entries of @xmath29 , the columns of which can be stacked into the @xmath74 vector @xmath75 . the kronecker product identity can now be applied , to give @xmath76 if @xmath77 points are observed on each of @xmath18 planes , then there are @xmath78 observed pairs of points , @xmath57 from the projective reconstruction and @xmath58 from the range back - projection .",
    "the @xmath79 corresponding @xmath80 matrices are stacked together , to give the complete system @xmath81 subject to the constraint @xmath82 , which excludes the trivial solution @xmath83 .",
    "it is straightforward to obtain an estimate of @xmath75 from the svd of the the @xmath84 matrix on the left of ( [ eqn : dlt - system ] ) .",
    "this solution , which minimizes an _ algebraic error _",
    "@xcite , is the singular vector corresponding to the smallest singular value of the matrix .",
    "note that the point coordinates should be transformed , to ensure that is numerically well - conditioned @xcite . in this case",
    "the transformation ensures that @xmath85 and @xmath86 , where @xmath87 . the analogous transformation is applied to the range points @xmath58 .",
    "the above procedure effectively computes a projective basis in , which requires five points , no four of which may be co - planar .",
    "this gives @xmath59 numbers , which are equivalent to the 15 parameters of the homogeneous @xmath28 matrix @xmath29 . in practice , however , we require full detection of 35 vertices per board , and around 10 boards per homography ( depending on visibility constraints ) .",
    "hence the procedure operates far from any degenerate cases , which would involve fewer than 15 degrees of freedom in total .",
    "the dlt method , in practice , gives a good approximation @xmath88 of the homography .",
    "this can be used as a starting - point for the iterative minimization of a more appropriate error measure . in particular , consider the _ reprojection error _ in the left image , @xmath89 where @xmath90 .",
    "a minimization of the reprojection error , starting with the linear estimate , is then performed by the levenberg - marquardt algorithm @xcite",
    ". the result will be the camera matrix @xmath91 that best reprojects the range data into the left image ( @xmath92 is similarly obtained ) .",
    "the solution , provided that the calibration points adequately covered the scene volume , will remain valid for subsequent depth and range data .",
    "alternatively , it is possible to minimize the _ joint _ reprojection error , defined as the sum of left and right contributions , @xmath93 over the ( inverse ) homography @xmath94 .",
    "the 16 parameters are again minimized by the levenberg - marquardt algorithm , starting from the dlt solution @xmath95 .",
    "the difference between the separate and joint minimizations is that the latter preserves the original epipolar geometry , whereas the former does not .",
    "recall that @xmath22 @xmath23 , @xmath29 and @xmath33 are all defined up to scale , and that @xmath33 satisfies an additional rank - two constraint @xcite .",
    "hence the underlying parameters can be counted as in the separate minimizations , and as in the joint minimization .",
    "the fixed epipolar geometry accounts for the @xmath96 missing parameters in the joint minimization .",
    "if @xmath33 is known to be very accurate ( or must be preserved ) then the joint minimization should be performed .",
    "this will also preserve the original binocular triangulation , provided that a projective - invariant method was used @xcite .",
    "however , if minimal reprojection error is the objective , then the cameras should be treated separately .",
    "this will lead to a new fundamental matrix , where @xmath97 is the generalized inverse , and @xmath91 , @xmath92 are the optimized camera - matrices .",
    "the epipole in the right - hand image is obtained from , where the vector @xmath98 represents the nullspace .",
    "the methods described in section [ sec : alignment ] can be used to calibrate a single  system ; the joint calibration of _ several _ such systems will now be explained . in this section",
    "the notation @xmath99 will be used for the binocular coordinates ( with respect to the left camera ) of a point in the system , and likewise @xmath100 for the  coordinates of a point in the same system .",
    "hence the , left and right rgb  cameras ( sharing the same physical mounting ) have the form @xmath101 where @xmath102 and @xmath103 contain only _ intrinsic _ parameters , whereas @xmath104 also encodes the relative orientation of @xmath105 with respect to @xmath106 .",
    "each system has a transformation @xmath107 that maps  points @xmath100 into the corresponding rgb  coordinate system of @xmath106 .",
    "furthermore , let the @xmath28 matrix @xmath108 be the transformation from system @xmath49 , mapping _",
    "back _ to system @xmath48 ( between different physical mountings ) .",
    "this matrix , in the binocularly - calibrated case , is a rigid  transformation .",
    "however , by analogy with the -to - rgb  matrices @xmath29 , each @xmath108 could be a _ projective _ transformation in the uncalibrated case ; this would allow euclidean structure to propagate from the  measurements , across the entire camera network .",
    "the left and right cameras , in all cases , that project a scene - point @xmath109 in coordinate to image - points @xmath110 and @xmath111 in system  @xmath48 are @xmath112 note that if a single global coordinate system is chosen to coincide with the rgb  system , then a point @xmath57 projects via @xmath113 and @xmath114 .",
    "these two cameras are respectively equal to @xmath106 and @xmath105 in ( [ eqn : stereo - cams ] ) only when @xmath115 , such that @xmath116 in  ( [ eqn : cams - ij ] ) .",
    "a typical three - system configuration is shown in fig .",
    "[ fig : cams ] .    .",
    "each ellipse represents a separate system , with system 2 chosen as the reference .",
    "the arrows ( with camera - labels ) show some possible -to - rgb  projections .",
    "for example , a point @xmath117 in the centre projects directly to rgb  view @xmath118 via @xmath119 , whereas the same point projects to @xmath120 via @xmath121 . ]",
    "the transformation @xmath108 can only be estimated directly if there is a region of common visibility between systems @xmath48 and @xmath49 .",
    "if this is not the case ( as when the systems face each other , such that the front of the calibration board is not simultaneously visible ) , then @xmath108 can be computed indirectly . for example , @xmath122 where @xmath123 .",
    "note that , in all cases , the stereo - reconstructed points @xmath0 are used to estimate these transformations this is because they are always more reliable than the  points @xmath1 , as demonstrated below .",
    "the following sections will describe the accuracy of a nine - camera setup , calibrated by the methods described above .",
    "section [ sec : cal - err ] will evaluate _ calibration _ error , whereas section [ sec : tot - err ] will evaluate _ total _ error .",
    "the former is essentially a fixed function of the estimated camera matrices , for a given scene .",
    "the latter also includes the range - noise from the  cameras , which varies from moment to moment ( due to intrinsic noise , changing illumination , and object motion ) .",
    "the importance of this distinction will be discussed . in section [ sec : similarity ] we analyze the avantages of using homographies to align the data , as opposed to similarity transformations .",
    "finally , in section [ sec : applications ] we demonstrate some applications of the complete system .",
    "the setup consists of three rail - mounted  systems , @xmath124 , as in fig .",
    "[ fig : cams ] .",
    "the stereo baselines are 17 cm on average , and the  cameras are separated by 107 cm on average .",
    "the rgb  images are @xmath125 , whereas the mesa imaging  images are @xmath126 , with a depth range of 500 cm @xcite .",
    "the three stereo systems are first calibrated by standard methods  @xcite , returning a full euclidean decomposition of @xmath106 and @xmath105 , as well as the associated lens parameters .",
    "the lenses of the  cameras are also calibrated by standard methods @xcite .",
    "this removes some of the radial depth deformation that has been observed in the  data @xcite .",
    "the matrices @xmath108 are rigid - body transformations , which are estimated by the svd method of arun et al .",
    "projective alignment is preferred for the /rgb  alignment , for reasons discussed in sections  [ sec : methods ] and [ fig : hom - sim ] .",
    "hence the transformations @xmath127 are @xmath28 homographies , estimated by the method of section [ sec : alignment ] .",
    "specifically , the dlt solutions were refined by levenberg - marquardt minimization of the joint geometric error , as in  ( [ eqn : reproj - err - points - joint ] ) .",
    "the calibration error is measured by first taking  points @xmath128 corresponding to chequerboard _ vertices _ on the reconstructed calibration plane @xmath129 in system @xmath49 , as described in section  [ sec : range ] .",
    "these can then be projected into a pair of rgb  images in system @xmath48 , so that the geometric image - error @xmath130 can be computed , where @xmath131 and @xmath132 is similarly defined .",
    "the function @xmath133 computes the image - distance between two inhomogenized points , as in ( [ eqn : reproj - err - points ] ) , and the denominator corresponds to the number of vertices on the board , with @xmath134 in the present experiments .",
    "the measure  ( [ eqn : cal - err ] ) can of course be averaged over all images in which the board is visible .",
    "the rgb  cameras were calibrated , by standard methods , as described above .",
    "subpixel accuracy was obtained , which confirms the accuracy of the camera matrices @xmath106 and @xmath105 , as well as the inter - system matrices @xmath108 , where @xmath135 .",
    "for the purpose of evaluation , a _ new _ set of -vertices @xmath136 were reconstructed , fitted and reprojected within each system @xmath48 .",
    "this evaluation effectively tests the quality of the @xmath107 matrices , by comparing @xmath137 to @xmath110 , and analogously to points @xmath111 in the other image .",
    "note that all camera and transformations parameters are now fixed ; no optimization was performed with respect to the evaluation data .",
    "the whole experiment was performed on three large data - sets , from different capture - sessions , and with different camera configurations , labelled a , b and c. such a configuration leads to one triplet per system as shown in fig .",
    "[ fig : camera_configuration ] . while an image can be fronto - parallel for one frame , it may appear very slanted to the other frames .",
    "the example of fig .",
    "[ fig : camera_configuration ] shows a calibration image that is almost fronto - parallel to the  frame of the central  unit .",
    "table [ tab : vts - intra ] shows that the average reprojection error remains subpixel in all three data - sets .",
    "the corresponding error - distributions are shown as histograms in fig .",
    "[ fig : vts - intra ] .        .calibration error ( [ eqn : cal - err ] ) , measured by projecting the fitted  vertices @xmath136 to the left and right rgb  images ( @xmath125 ) of the _ respective _ systems @xmath138 .",
    "the experiment was repeated three times ( a  c ) , with different camera configurations .",
    "each statistic was computed from the left and right rgb - reprojections of 35 vertices in 7 views of the board ( total number of  points , per data - set : @xmath139 ) .",
    "[ cols=\"^,^,^,^,^\",options=\"header \" , ]      +   +     when the raw  points are reprojected to a _ different _",
    "system , a high total error is expected , because the sensor s range - noise may be viewed ` from the side ' .",
    "indeed , fig .",
    "[ fig : pix - inter ] shows that a substantial proportion of the  points reproject with total errors in excess of ten pixels .",
    "these kind of gross errors are characteristic of the  data , owing to the inevitable presence of absorbing and scattering surfaces in a typical scene .",
    "in fact , calibration error and total error are both influenced by surface orientation .",
    "for example , the higher errors in set  b of the data ( see tables [ tab : vts - intra ] and [ tab : pix - intra ] ) are due to the presence of some very slanted boards , in both the fitting and evaluation data - sets ; this causes two problems , as follows .",
    "firstly , the images of these boards are very foreshortened in some systems .",
    "this leads to increased _ calibration _ error , because the vertices are hard to detect in the corresponding  images .",
    "secondly , the strength of the reflected ir signal is reduced whenever the surface is oblique to a given  camera . if the surface is also absorbent ( like the black squares of the board ) , then the _ total _ error is greatly increased , due to the combined effects of scattering and absorption .    ) , measured by projecting the fitted  points @xmath140 to the left and right rgb  images ( @xmath125 ) of two _ different _ systems , @xmath141 .",
    "the range errors are emphasized by the difference in viewpoints between the two systems .",
    "average error is now around five pixels , and the noisiest  points reproject with tens of pixels of error.,title=\"fig : \" ] + ) , measured by projecting the fitted  points @xmath140 to the left and right rgb  images ( @xmath125 ) of two _ different _ systems , @xmath141 .",
    "the range errors are emphasized by the difference in viewpoints between the two systems .",
    "average error is now around five pixels , and the noisiest  points reproject with tens of pixels of error.,title=\"fig : \" ] + ) , measured by projecting the fitted  points @xmath140 to the left and right rgb  images ( @xmath125 ) of two _ different _ systems , @xmath141 .",
    "the range errors are emphasized by the difference in viewpoints between the two systems .",
    "average error is now around five pixels , and the noisiest  points reproject with tens of pixels of error.,title=\"fig : \" ] +    it is possible to understand these results more fully by examining the distribution of the total error across individual boards .",
    "figure  [ fig : board - err ] shows the distribution for a board reprojected to same / different systems ( i.e.  part of the data from figs .",
    "[ fig : pix - intra ] & [ fig : pix - inter ] ) .",
    "there is a relatively smooth gradient of error across the board , which is attributable to errors in the fitting of plane @xmath129 , and in the estimation of the camera parameters .",
    "in addition to these effects , it is clear that the gross errors are correlated with the black squares of the board , which reflect too little of the  signal .",
    "for instance , in the bottom example of figure  [ fig : board - err ] , the mean reprojection error associated with the black squares is @xmath142 pixels , whereas the white squares are associated with a mean error of @xmath143 pixels .",
    "the effect is particularly noticeable , as expected from the histograms , when reprojecting to different camera systems .    ) in each case ( larger errors are shown in yellow ) .",
    "black crosses mark the detected vertices in the rgb  image .",
    "the black squares of the board are associated with larger reprojection errors , particularly after reprojecting to a different system ( mean error in the bottom example is 10.05px for black squares , and 3.55px for white).,title=\"fig : \" ] ) in each case ( larger errors are shown in yellow ) .",
    "black crosses mark the detected vertices in the rgb  image",
    ". the black squares of the board are associated with larger reprojection errors , particularly after reprojecting to a different system ( mean error in the bottom example is 10.05px for black squares , and 3.55px for white).,title=\"fig : \" ]      it was argued in section [ sec : methods ] that the  homography model is an appropriate way to compensate for miscalibrations of the  and stereo systems ( and indeed it allows the stereo system to be left uncalibrated , if preferred @xcite ) .",
    "this claim is tested in the following experiments , using data images from two new data sets .",
    "the most obvious alternative to the homography is a rigid motion and scaling ; i.e.  a  _ similarity _ transformation .",
    "specifically , the @xmath28 matrix @xmath29 in ( [ eqn : homog ] ) can be replaced by the similarity transformation @xmath144 where @xmath145 is a ( positive ) scalar , @xmath146 is a @xmath17 rotation matrix , and @xmath147 is a @xmath148 translation vector .",
    "hence there are only seven degrees of freedom , in contrast to the fifteen of the homography .",
    "geometrically , the similarity model can be interpreted as a rigid transformation between the  and stereo systems , where the baseline distance of the latter is unknown .    in principle",
    ", a homography should always result in equal or lower error , because it includes the similarity transformation as a special case .",
    "in particular , a homography can always be written as @xmath149 where the deformation @xmath150 is composed of an affinity and an elation @xcite . however , there are two practical issues to consider .",
    "firstly , the quality of the actual estimate in each case ; and secondly , the possible danger of over - fitting with the homography .    it was argued in section [ sec : methods ] that the  homography model is an appropriate way to compensate for miscalibrations of the  and stereo systems ( and also allows the stereo system to be left uncalibrated , if preferred @xcite ) .",
    "in particular the deformation @xmath150 can help to account for locally linear depth bias in the  camera @xcite .",
    "hence the additional eight degrees of freedom in the homography model allow for an overall approximation to the per - pixel corrections performed by cui et al .",
    "@xcite .",
    "the procedure to estimate the optimal similarity ( [ eqn : sim ] ) is analogous to that used to estimate the homography in section [ sec : methods ] . instead of dlt",
    ", an initial estimate is obtained from the procrustes algorithm @xcite , using three or more correspondences .",
    "the reprojection error is then minimized using the levenberg - marquardt procedure , as with the homography .",
    "note that the rotation @xmath146 in ( [ eqn : sim ] ) is appropriately parameterized by the rodrigues formula .",
    "the results of these experiments are shown in figure [ fig : hom - sim ] . in every  system , and in both capture sessions , the homography results in lower error than the similarity .",
    "the mean reprojections errors ( in pixels ) were 0.22 vs.  0.65 , and 0.46 vs.  1.06 , for the respective capture sessions .",
    "the generally higher figures from the second set are due to a broader distribution of board - poses in the evaluation data - set .",
    "these experiments show that the  homography transformation is a suitable model for /rgb  alignment , as argued in section [ sec : methods ] .",
    "it may also be noted that the homography is effectively easier to estimate than the similarity , as there is no need to maintain the orthogonality of @xmath146 during the final minimization .",
    "the proposed cross - calibration methodology also allows a fully - textured  model to be segmented and rendered .",
    "this is because the depth - data are automatically assigned to pixels in the rgb  images .",
    "figure  [ fig:360-reconstruction ] shows reconstruction instances with and without texture from a @xmath151 reconstruction , obtained from the cross - calibration of four  systems .",
    "meshing was performed by the standard poisson reconstruction method @xcite , followed by simple triangle - based texture mapping .",
    "more dense reconstruction can be achieved by exploiting the full resolution of stereo cameras , as described elsewhere @xcite .",
    "figure  [ fig : sparse_vs_dense_recon ] shows the difference between the raw reconstruction obtained from the cross - calibration of a  system , and that obtained after using the  data in a subsequent stereo algorithm  @xcite .",
    "a high - resolution depth map is produced , making full use of the high - resolution rgb  cameras .",
    "reconstruction , after poisson meshing , with and without rgb  texture . ]",
    "it has been shown that  projective transformations can be used to cross - calibrate a system of  and stereo reconstructions .",
    "a practical method for computing these transformations , based on geometric principles , has been introduced .",
    "this calibration procedure has been extended to a nine - camera network of six rgb  and three  cameras , and evaluated in detail .",
    "a clear distinction has been made between _ calibration error _",
    ", which is due to imperfect camera and image models , versus _ total error _ , which incorporates -specific noise and biases",
    ". it has been shown that these errors can be separated geometrically , and used to characterize the performance of a /rgb  camera network .",
    "the overall performance of the system has been visualized in segmented 360@xmath152  reconstructions .",
    "this type of reconstruction is challenging to compute , and shows that the system is more than adequate as a basis for scene - segmentation tasks .",
    "the accuracy of the method presented here is somewhat limited by the relatively poor localization of points , even when spatially interpolated , in the  images .",
    "the detection of standard chequerboard patterns , in  images , has been discussed elsewhere @xcite .",
    "the design of more convenient calibration patterns , for  cameras , would be a worthwhile direction for future research .",
    "meanwhile , in mitigation , the spatial resolution of  cameras will continue to increase .",
    "future work should also consider the distribution of range - errors in , and how this can be used to design custom meshing and surface reconstruction algorithms for time - of - flight data .",
    "this , in conjunction with the rgb  textures provided by the present method , would lead to a comprehensive approach to  reconstruction , rendering and scene - understanding .",
    "z.  liu , m.  beetz , d.  cremers , j.  gall , w.  li , d.  pangercic , j.  sturm , y .- w .",
    "tai , special issue on visual understanding and applications with rgb - d cameras , journal of visual communication and image representation 25  ( 1 ) .",
    "r.  nair , k.  ruhl , s.  meister , h.  schfer , c.  s. garbe , m.  eisemann , m.  magnor , d.  kondermann , a survey on time - of - flight stereo fusion , in : m.  grzegorzek , c.  theobalt , r.  koch , a.  kolb ( eds . ) , time - of - flight and depth imaging , vol .",
    "8200 of lncs , springer , 2013 , ch . a survey on time - of - flight stereo fusion , pp .",
    "105127 .          c.  beder , i.  schiller , r.  koch , photoconsistent relative pose estimation between a pmd 2d3d - camera and multiple intensity cameras , in : proc",
    ".  symp . of the german association for pattern recognition ( dagm ) , 2008 ,",
    ". 264273 .",
    "i.  schiller , c.  beder , r.  koch , calibration of a pmd camera using a planar calibration object together with a multi - camera setup , in : int .",
    "photogrammetry , remote sensing and spatial information sciences xxi , 2008 , pp .",
    "297302 .",
    "m.  silva , r.  ferreira , j.  gaspar , camera calibration using a color - depth camera : points and lines based dlt including radial distortion , in : proc . of iros workshop in color - depth camera fusion in robotics , 2012 .",
    "i.  v. mikhelsona , p.  g. leea , a.  v. sahakiana , y.  wua , a.  k. katsaggelosa , http://dx.doi.org/10.1016/j.bbr.2011.03.031[automatic , fast , online calibration between depth and color cameras ] , journal of visual communication and image representationin press ( available online ) ."
  ],
  "abstract_text": [
    "<S> time - of - flight cameras provide depth information , which is complementary to the photometric appearance of the scene in ordinary images . </S>",
    "<S> it is desirable to merge the depth and colour information , in order to obtain a coherent scene representation . </S>",
    "<S> however , the individual cameras will have different viewpoints , resolutions and fields of view , which means that they must be mutually calibrated . </S>",
    "<S> this paper presents a geometric framework for the resulting multi - view and multi - modal calibration problem . </S>",
    "<S> it is shown that three - dimensional projective transformations can be used to align depth and parallax - based representations of the scene , with or without euclidean reconstruction . </S>",
    "<S> a new evaluation procedure is also developed ; this allows the reprojection error to be decomposed into calibration and sensor - dependent components . </S>",
    "<S> the complete approach is demonstrated on a network of three time - of - flight and six colour cameras . </S>",
    "<S> the applications of such a system , to a range of automatic scene - interpretation problems , are discussed . </S>"
  ]
}