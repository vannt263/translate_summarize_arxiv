{
  "article_text": [
    "model selection is the task of choosing the best model for a particular data analysis task .",
    "it generally makes a compromise between fit with the data and the complexity of the model .",
    "furthermore , the chosen model is used in subsequent analysis of test data .",
    "currently the most popular techniques used by practitioners are cross - validation ( cv ) and leave - one - out ( loo ) . in this paper",
    "the model we concentrate on is the support vector machine ( svm ) @xcite .",
    "cv and loo are the modus operandi despite there being a number of alternative approaches proposed in the svm literature .",
    "for instance , explore model selection using the span of the support vectors and re - scaling of the feature space , whereas , , motivated by an application in drug design , propose a fully - automated search methodology for model selection in svms for regression and classification . give an in depth review of a number of model selection alternatives for tuning the kernel parameters and penalty coefficient @xmath0 for svms , and",
    "although they find a model selection technique that performs well ( at high computational cost ) , the authors conclude that  _ the hunt is still on for a model selection criterion for svm classification which is both simple and gives consistent generalisation performance _ \" .",
    "more recent attempts at model selection have been given by who derive an algorithm that fits the entire path of svm solutions for every value of the cost parameter , while propose to use the vapnik - chervonenkis ( vc ) bound ; they put forward an algorithm that employs a coarse - to - fine search strategy to obtain the best parameters in some predefined ranges for a given problem .",
    "furthermore , propose a tighter pac - bayes bound to measure the performance of svm classifiers which in turn can be used as a way of estimating the hyperparameters .",
    "finally , have addressed model selection for multi - class svms using particle swarm optimisation .    recently ,",
    ", following on work by , show that selecting a model whose hyperplane achieves the maximum separation from a test point obtains comparable error rates to those found by selecting the svm model through cv .",
    "in other words , while methods such as cv involve finding one svm model ( together with its optimal parameters ) that minimises the cv error , keep all of the models generated during the model selection stage and make predictions according to the model whose hyperplane achieves the maximum separation from a test point .",
    "the main advantage of this approach is the computational saving when compared to cv or loo . however , their method is only applicable to large margin classifiers like svms .",
    "we continue this line of research , but rather than using the distance of each test point from the hyperplane we explore the idea of using the _ nonconformity measure _ @xcite of a test sample to a particular label set .",
    "the nonconformity measure is a function that evaluates how ` strange ' a prediction is according to the different possibilities available .",
    "the notion of nonconformity has been proposed in the on - line learning framework of conformal prediction @xcite , and is a way of scoring how different a new sample is from a bag of old samples .",
    "the premise is that if the observed samples are well - sampled then we should have high confidence on correct prediction of new samples , given that they _",
    "conform _ to the observations .",
    "we take the nonconformity measure and apply it to the svm algorithm during testing in order to gain a time advantage over cv and to generalise the algorithm of .",
    "hence we are not restricted to svms ( or indeed a measure of the margin for prediction ) and can apply our method to a broader class of learning algorithms .",
    "however , due to space constraints we only address the svm technique and leave the application to other algorithms ( and other nonconformity measures not using the margin ) as a future research study .",
    "furthermore we also derive a novel learning theory bound that uses nonconformity as a measure of complexity .",
    "to our knowledge this is the first attempt at using this type of measure to upper bound the loss of learning algorithms .",
    "the paper is laid out as follows . in section [ sec : nom ] we present the definitions used throughout the paper .",
    "our main algorithmic contributions are given in section [ sec : con ] where we present our nonconformity measure and its novel use in prediction .",
    "section [ sec : bound ] presents a novel generalisation error bound for our proposed algorithm .",
    "finally , we present experiments in section [ sec : exp ] and conclude in section [ sec : dis ] .",
    "the definitions are mainly taken from .",
    "let @xmath1 be the @xmath2th input - output pair from an input space @xmath3 and output space @xmath4 .",
    "let @xmath5 denote short hand notation for each pair taken from the joint space @xmath6 .",
    "we define a _ nonconformity measure _ as a real valued function @xmath7 that measures how different a sample @xmath8 is from a set of observed samples @xmath9 .",
    "a nonconformity measure must be fixed _ a priori _ before any data has been observed .",
    "conformal predictions work by making predictions according to the nonconformity measure outlined above . given a set @xmath9 of training samples observed over @xmath10 time steps and a new sample @xmath11",
    ", a conformal prediction algorithm will predict @xmath12 from a set containing the correct output with probability @xmath13 .",
    "for example , if @xmath14 then the prediction is within the so - called _ prediction region _",
    " a set containing the correct @xmath12 , with @xmath15 probability . in this paper",
    ", we extend this framework to the batch learning model to make predictions using confidence estimates , where for example we are @xmath15 confident that our prediction is correct .    in",
    "the batch learning setting , rather than observing samples incrementally such as @xmath16 we have a training set @xmath17 containing all the samples for training that are assumed to be distributed i.i.d . from a fixed ( but unknown )",
    "distribution @xmath18 .",
    "given a function ( hypothesis ) space @xmath19 the batch algorithm takes training sample @xmath20 and outputs a hypothesis @xmath21 that maps samples to labels .    for the svm notation",
    "let @xmath22 map the training samples to a higher dimensional feature space @xmath23 .",
    "the primal svm optimisation problem can be defined like so : @xmath24 where @xmath25 is the bias term , @xmath26 is the vector of slack variables and @xmath27 is the primal weight vector , whose 2-norm minimisation corresponds to the maximisation of the margin between the set of positive and negative samples .",
    "the notation @xmath28 denotes the inner product .",
    "the dual optimisation problem gives us the flexibility of using _ kernels _ to solve nonlinear problems @xcite .",
    "the dual svm optimisation problem can be formulated like so : @xmath29 where @xmath30 is the kernel function and @xmath31 is the dual ( lagrangian ) variables . throughout the paper",
    "we will use the dual optimisation formulation of the svm as we attempt to find the optimal regularisation parameter for the svm together with the optimal kernel parameters .",
    "we now discuss the main focus of the paper .",
    "let @xmath32 be composed of a training set @xmath33 and a validation set @xmath34 .",
    "we assume without loss of generality that , @xmath35 where @xmath36 and @xmath37 .",
    "we start by defining our nonconformity measure @xmath38 for a function @xmath39 over the validation set @xmath34 and @xmath40 as , @xmath41 note that this does not depend on the whole sample but just the test point . in itself",
    "it does not characterise how different the point is . to do this we need the so called @xmath42_-value _ @xmath43 that computes the fraction of points in @xmath34 with ` stranger ' values : @xmath44 which , in this case , measures the number of samples from the validation set that have smaller functional margin than the test point functional margin .",
    "the larger the margin obtained the more confidence we have in our prediction .",
    "the nonconformity p - value of @xmath8 is between @xmath45 and @xmath46 .",
    "if it is small ( tends to @xmath46 ) then sample @xmath8 is non - conforming and if it is large ( tends to @xmath45 ) then it is conforming .    in order to better illustrate this idea we show a simple pictorial example in figure [ fig : exa ] .",
    "we are given six validation samples ordered around @xmath47 ( solid line ) in terms of their correct / incorrect classification , the value @xmath48 for an @xmath49 pair will be correctly classified by @xmath39 iff @xmath50 . in our example two",
    "are incorrectly classified ( below the threshold ) and four are correct .",
    "the picture on the left also includes @xmath51 for a test sample @xmath11 when its label is considered to be positive , @xmath52 . in this case there",
    "remain @xmath53 validation samples below its value of @xmath51 giving us a nonconformity measure p - value using equation ( [ eq : ncmeasure ] ) as @xmath54 .",
    "a similar calculation can be made for the picture on the right when we consider the label @xmath55 for test point @xmath11 , @xmath56 .",
    "we are able to conclude , for this sample , that assigning @xmath11 a label of @xmath57 gives a nonconformity p - value of @xmath58 while assigning a label of @xmath55 gives a p - value of @xmath59 .",
    "therefore , with a higher probability , our test sample @xmath11 is conforming to @xmath60 ( or equally non - conforming to @xmath61 ) and should be predicted positive .",
    "( left ) and @xmath61 ( right ) . ]",
    "we state the standard result for nonconformity measures , but first define a nonconformity prediction scheme and its associated error .    for a fixed nonconformity measure @xmath7 , its associated @xmath42-value , and @xmath62 ,",
    "the confidence predictor @xmath63 predicts the label set @xmath64 the confidence predictor @xmath63 makes an error on sample @xmath65 if @xmath66 .",
    "[ ncprop ] for exchangeable distributions we have that @xmath67    by exchangeability all permutations of a training set are equally likely .",
    "denote with @xmath68 the set @xmath20 extended with the sample @xmath69 and for @xmath70 a permutation of @xmath71 objects .",
    "let @xmath72 be the sequence of samples permuted by @xmath70 .",
    "consider the permutations for which the corresponding prediction of the final element of the sequence is not an error .",
    "this implies that the value @xmath73 is in the upper @xmath74 fraction of the values @xmath75 .",
    "this will happen at least @xmath74 of the time under the permutations , hence upper bounding the probability of error over all possible sequences by @xmath76 as required .    following the theoretical motivation from we proceed by computing all the svm models and applying them throughout the prediction stage .",
    "a fixed validation set , withheld from training , is used to calculate the nonconformity measures .",
    "we start by constructing @xmath77 svm models so that each decision function @xmath78 is in the set @xmath79 of decision functions with @xmath80 .",
    "the different set of svm models can be characterised by different regularisation parameters for @xmath0 ( or @xmath81 in @xmath81-svm ) and the width parameter @xmath82 in the gaussian kernel case .",
    "for instance , given @xmath83 @xmath84 values and @xmath83 @xmath85 values for a gaussian kernel we would have a total of @xmath86 svm models , where @xmath87 denotes the cardinality of a set .",
    "we now describe our new model selection algorithm for the svm using nonconformity .",
    "if the following @xmath88 statement holds , then we include @xmath89 where @xmath90 is the prediction region ( set of labels conforming ) . for classification",
    ", the set @xmath90 can take the following values : @xmath91 clearly finding the prediction region @xmath92 or @xmath93 is useful in the classification scenario as it gives higher confidence of the prediction being correct , while the sets @xmath94 and @xmath95 are useless as the first abstains from making a prediction whilst the second is unbiased towards a label .",
    "let @xmath96 be the critical @xmath97 that creates one label in the set @xmath98 for at least one of the @xmath77 models : @xmath99 furthermore , let @xmath100 be arguments that realise the minimum @xmath96 , chosen randomly in the event of a tie .",
    "this now gives the prediction of @xmath11 as @xmath101 .",
    "this is because @xmath102 is non - conforming ( strange ) and we wish to select the _ opposite _ ( conforming ) label . in the experiments section",
    "we refer to the prediction strategy outlined above and the model selection strategy given by equation ( [ eqn : nonc ] ) as the nonconformity model selection strategy .",
    "we set out the pseudo - code for this procedure in algorithm [ al : alg ] .",
    "sample @xmath103 , svm parameters @xmath0 and @xmath82 ( for gaussian kernel ) where @xmath104 predictions of test points @xmath105 take training data @xmath20 and randomly split into training set @xmath106 and validation set @xmath107 where @xmath108 .",
    "train @xmath77 svm models on training data @xmath33 to find @xmath109 . : for a test point @xmath11 compute : @xmath110 realised by @xmath111 and @xmath112 .",
    "predict label @xmath113 for @xmath11 .    before proceeding",
    "we would like to clarify some aspects of the algorithm .",
    "the data is split into a training and validation set _ once _ and therefore all @xmath77 models are computed on the training data  after this procedure we only require to calculate the nonconformity measure p - value for all test points in order to make predictions .",
    "however , in @xmath25-fold cross - validation we require to train , for each @xmath0 and @xmath82 parameter , a further @xmath25 times .",
    "hence cv will be at most @xmath25 times more computationally expensive .",
    "the problem with proposition [ ncprop ] is that it requires the validation set to be generated afresh for each test point , specifies just one value of @xmath76 , and only applies to a single test function . in our application",
    "we would like to reuse the validation set for all of our test data and use an empirically determined value of @xmath76 .",
    "furthermore we would like to use the computed errors for different functions in order to select one for classifying the test point .",
    "we therefore need to have uniform convergence of empirical estimates to true values for all values of @xmath76 and all functions @xmath77 .",
    "we first consider the question of uniform convergence for all values of @xmath76 .",
    "if we consider the cumulative distribution function @xmath114 defined by @xmath115 we need to bound the difference between empirical estimates of this function and its true value .",
    "this corresponds to bounding the difference between true and empirical probabilities over the sets @xmath116 : a \\in { \\mathbb{r}}\\right\\}.\\ ] ] observe that we can not shatter two points of the real line with this set system as the larger can not be included in a set without the smaller .",
    "it follows that this class of functions has vapnik - chervonenkis ( vc ) dimension 1 .",
    "we can therefore apply the following standard result , see for example .",
    "[ thm ] let @xmath117 be a measurable space with a fixed but unknown probability distribution @xmath118 .",
    "let @xmath119 be a set system over @xmath117 with vc dimension @xmath120 and fix @xmath121 .",
    "with probability at least @xmath122 over the generation of an i.i.d .",
    "@xmath123-sample @xmath124 , @xmath125    we now apply this result to the error estimations derived by our algorithm for the @xmath77 possible choices of model .",
    "[ prop : bound ] fix @xmath126 .",
    "suppose that the validation set @xmath127 of size @xmath128 in algorithm",
    "[ al : alg ] has been chosen i.i.d . according to a fixed but unknown distribution that is also used to generate the test data .",
    "then with probability at least @xmath129 over the generation of @xmath127 , if for a test point @xmath11 the algorithm returns a classification @xmath130 , using function @xmath131 , @xmath132 , realising a minimum value of @xmath96 , then the probability of misclassification satisfies @xmath133    we apply theorem [ thm ] once for each function @xmath134 , @xmath135 with @xmath136 replaced by @xmath137 .",
    "this implies that with probability @xmath138 the bound holds for all of the functions @xmath134 , including the chosen @xmath131 . for this function the empirical probability of the label @xmath102 being observed is @xmath96 , hence the true probability of this opposite label is bounded as required .",
    "the bound in proposition [ prop : bound ] is applied _ using _ each test sample which in turn gives a different bound value for each test point ( , see ) .",
    "therefore , we are unable to compare this bound with existing training set cv bounds @xcite as they are traditional a _ priori _ bounds computed over the training data , and which give a uniform value for all test points ( , training set bounds @xcite ) .",
    "in the following experiments we compare svm model selection using traditional cv to our proposed nonconformity strategy as well as to the model selection using the maximum margin @xcite from a test sample .    we make use of the votes , glass , haberman , bupa , credit , pima , breastw and ionosphere data sets acquired from the uci machine learning repository .",
    "the data sets were pre - processed such that samples containing unknown values and contradictory labels were removed . table [ tab : data ] lists the various attributes of each data set . the libsvm package 2.85 @xcite and the gaussian kernel were used throughout the experiments .",
    "[ cols=\"^,^,^,^,^\",options=\"header \" , ]     [ tab : res ]    since we do not have a single number for the bound on generalisation ( as traditional bounds ) but rather individual values for each test sample , it is not possible to simply compare the bound with the test error . in order to show how the bound performs we plot the generalisation error as a function of the bound value .    for each value of the bound",
    "we take the average error of all test points with predicted error less than or equal to that value . in other words , we create a set @xmath139 containing the various bound values computed on the test samples . subsequently , for each element in the set , @xmath140 we compute the average error value for the test samples that have a bound value that is smaller or equal to @xmath141 .",
    "figure [ fig : bnd ] shows a plot of this error rate as a function of the bound value",
    ". the final value of the function is the overall generalisation error , while the lower error rates earlier in the curve are those attainable by filtering at different bound values .",
    "as expected the error increases monotonically as a function of the bound value .",
    "clearly there is considerable weakness in the bound , but this is partly a result of our using a quite conservative vc bound ",
    "our main aim here is to show that the predictions are correlated with the actual error rates .",
    "we believe these results to be encouraging as our theoretically motivated model selection technique is faster and achieves similar error rates to cross - validation , which is generally considered to be the gold standard .",
    "we also find that the nonconformity strategy is slightly slower than the maximum margin approach but performs better in terms of generalisation error .",
    "we have presented a novel approach for model - selection and test sample prediction using a nonconformity ( strangeness ) measure .",
    "furthermore we have given a novel generalisation error bound on the loss of the learning method .",
    "the proposed model selection approach is both simple and gives consistent generalisation performance @xcite .",
    "we find these results encouraging as it constitutes a much needed shift from costly model selection based approaches to a faster method that is competitive in terms of generalisation error .",
    "furthermore , in relation to the work of we have presented a method that is 1 ) not restricted to svms and 2 ) can use measures other than the margin to make predictions .",
    "therefore the nonconformity measure approach gives us a general way of choosing to make predictions , allowing us the flexibility to apply it to algorithms that are not based on large margins . in",
    "future work we aim to investigate the applicability of our proposed model selection technique to other learning methods .",
    "another future research direction is to apply different nonconformity measures to the svm algorithm presented in this paper such as , for example , a nearest neighbour nonconformity measure @xcite ."
  ],
  "abstract_text": [
    "<S> we investigate the issue of model selection and the use of the nonconformity ( strangeness ) measure in batch learning . using the nonconformity measure we propose a new training algorithm that helps avoid the need for cross - validation or leave - one - out model selection strategies . </S>",
    "<S> we provide a new generalisation error bound using the notion of nonconformity to upper bound the loss of each test example and show that our proposed approach is comparable to standard model selection methods , but with theoretical guarantees of success and faster convergence . </S>",
    "<S> we demonstrate our novel model selection technique using the support vector machine . </S>"
  ]
}