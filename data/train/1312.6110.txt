{
  "article_text": [
    "building rich generative models that are capable of extracting useful , high - level latent representations from high - dimensional sensory input lies at the core of solving many ai - related tasks , including object recognition , speech perception and language understanding .",
    "these models capture underlying structure in data by defining flexible probability distributions over high - dimensional data as part of a complex , partially observed system .",
    "some of the successful generative models that are able to discover meaningful high - level latent representations include the boltzmann machine family of models : restricted boltzmann machines , deep belief nets  @xcite , and deep boltzmann machines  @xcite .",
    "mixture models , such as mixtures of factor analyzers  @xcite and mixtures of gaussians , have also been used for modeling natural image patches  @xcite .",
    "more recently , denoising auto - encoders have been proposed as a way to model the transition operator that has the same invariant distribution as the data generating distribution  @xcite .",
    "generative models have an advantage over discriminative models when part of the images are occluded or missing .",
    "occlusions are very common in realistic settings and have been largely ignored in recent literature on deep learning .",
    "in addition , prior knowledge can be easily incorporated in generative models in the forms of structured latent variables , such as lighting and deformable parts .",
    "however , the enormous amount of content in high - resolution images makes generative learning difficult  @xcite .",
    "therefore , generative models have found most success in learning to model small patches of natural images and objects : zoran and weiss  @xcite learned a mixture of gaussians model over @xmath0 image patches ; salakhutdinov and hinton  @xcite used @xmath1 centered and uncluttered stereo images of toy objects on a clear background ; tang et al .",
    "@xcite used @xmath2 images of centered and cropped faces .",
    "the fact that these models require curated training data limits their applicability on using the ( virtually ) unlimited unlabeled data .    in this paper",
    ", we propose a framework to infer the region of interest in a big image for generative modeling .",
    "this will allow us to learn a generative model of faces on a very large dataset of ( unlabeled ) images containing faces .",
    "our framework is able to dynamically route the relevant information to the generative model and can ignore the background clutter .",
    "the need to dynamically and selectively route information is also present in the biological brain .",
    "plethora of evidence points to the presence of attention in the visual cortex  @xcite .",
    "recently , in visual neuroscience , attention has been shown to exist not only in extrastriate areas , but also all the way down to v1  @xcite .",
    "attention as a form of routing was originally proposed by anderson and van essen  @xcite and then extended by olshausen et al .",
    "dynamic routing has been hypothesized as providing a way for achieving shift and size invariance in the visual cortex  @xcite .",
    "tsotsos et al .",
    "@xcite proposed a model combining search and attention called the selective tuning model .",
    "larochelle and hinton  @xcite proposed a way of using third - order boltzmann machines to combine information gathered from many foveal glimpses .",
    "their model chooses where to look next to find locations that are most informative of the object class .",
    "reichert et al .",
    "@xcite proposed a hierarchical model to show that certain aspects of _ covert _ object - based attention can be modeled by deep boltzmann machines .",
    "several other related models attempt to learn where to look for objects  @xcite and for video based tracking  @xcite .",
    "inspired by olshausen et al .",
    "@xcite , we use 2d similarity transformations to implement the scaling , rotation , and shift operation required for routing .",
    "our main motivation is to enable the learning of generative models in big images where the location of the object of interest is unknown a - priori .",
    "before we describe our model , we briefly review the gaussian restricted boltzmann machine ( grbm )  @xcite , as it will serve as the building block for our attention - based model .",
    "grbms are a type of markov random field model that has a bipartite structure with real - valued visible variables @xmath3 connected to binary stochastic hidden variables @xmath4 .",
    "the energy of the joint configuration @xmath5 of the gaussian rbm is defined as follows : e_grbm ( , ;) & = & _ i -_j c_j h_j - _ ij w_ij v_i h_j , where @xmath6 are the model parameters . the marginal distribution over the visible vector @xmath7 is @xmath8 and the corresponding conditional distributions take the following form : [ eq : lik_gauss ] p(h_j=1 |@xmath9 ) & = & 1 / ( 1 + ( -_i w_ij v_i -c_j ) ) , [ eq : rbm_post ] + p(v_i |@xmath10 ) & = & ( v_i ; _ i , _",
    "i^2 ) , _ i = b_i + _ i^2 _ j w_ij h_j .",
    "[ eq : rbm_mu ] observe that conditioned on the states of the hidden variables ( eq .",
    "[ eq : rbm_mu ] ) , each visible unit is modeled by a gaussian distribution , whose mean is shifted by the weighted combination of the hidden unit activations . unlike directed models , an rbm s conditional distribution over hidden nodes is factorial and can be easily computed .",
    "we can also add a binary rbm on top of the learned grbm by treating the inferred  @xmath10 as the `` visible '' layer together with a second hidden layer @xmath11 .",
    "this results in a 2-layer gaussian deep belief network ( gdbn )  @xcite that is a more powerful model of @xmath9 .",
    "specifically , in a gdbn model , @xmath12 is modeled by the energy function of the 2nd - layer rbm , while @xmath13 is given by eq .",
    "[ eq : rbm_mu ] .",
    "efficient inference can be performed using the greedy approach of  @xcite by treating each dbn layer as a separate rbm model .",
    "gdbns have been applied to various tasks , including image classification , video action and speech recognition  @xcite .",
    "let @xmath14 be a high resolution image of a scene , e.g. a @xmath15 image .",
    "we want to use attention to propagate regions of interest from @xmath16 up to a canonical representation .",
    "for example , in order to learn a model of faces , the canonical representation could be a @xmath2 aligned and cropped frontal face image .",
    "let @xmath17 represent this low resolution canonical image .",
    "in this work , we focus on a deep belief network to model @xmath9 .",
    "this is illustrated in the diagrams of fig .",
    "[ fig : shiftercircuit ] .",
    "the left panel displays the model of olshausen  et.al .",
    "@xcite , whereas the right panel shows a graphical diagram of our proposed generative model with an attentional mechanism . here ,",
    "@xmath18 and @xmath19 represent the latent hidden variables of the dbn model , and @xmath20 ( position , rotation , and scale ) are the parameters of the 2d similarity transformation .",
    "the 2d similarity transformation is used to rotate , scale , and translate the canonical image @xmath21 onto the canvas that we denote by @xmath22 .",
    "let @xmath23 { ^\\mathsf{t}}$ ] be a pixel coordinate ( e.g. @xmath24 $ ] or @xmath25 $ ] ) of the canonical image @xmath9 .",
    "let @xmath26 be the set of all coordinates of @xmath9 .",
    "for example , if @xmath9 is @xmath2 , then @xmath26 ranges from @xmath24 $ ] to @xmath27 $ ] .",
    "let the `` gaze '' variables @xmath28 $ ] be the parameter of the similarity transformation .",
    "in order to simplify derivations and to make transformations be linear w.r.t .",
    "the transformation parameters , we can equivalently redefine @xmath29 $ ] , where @xmath30 and @xmath31 ( see  @xcite for details ) .",
    "we further define a function @xmath32 as the transformation function to _ warp _ points @xmath33 to @xmath34 : @xmath35   = \\big [ \\begin{array}{cc } 1+a & -b \\\\",
    "b   & 1+a \\end{array } \\big ]   \\big [ \\begin{array}{c } x\\\\ y   \\end{array } \\big ] + \\big [ \\begin{array}{c } \\triangle x\\\\ \\triangle y   \\end{array } \\big].\\ ] ] we use the notation @xmath36 to denote the bilinear interpolation of @xmath22 at coordinates @xmath37 with anti - aliasing .",
    "let @xmath38 be the extracted low - resolution image at warped locations @xmath34 : @xmath39 intuitively , @xmath40 is a patch extracted from @xmath16 according to the shift , rotation and scale parameters of  @xmath41 , as shown in fig .",
    "[ fig : shiftercircuit ] , right panel .",
    "it is this patch of data that we seek to model generatively .",
    "note that the dimensionality of @xmath42 is equal to the cardinality of @xmath43 , where @xmath44 denotes the set of pixel coordinates of the canonical image  @xmath21 . unlike standard generative learning tasks , the data @xmath40 is not static but changes with the latent variables @xmath45 .",
    "given @xmath21 and @xmath46 , we model the top - down generative process over on @xmath45 for clarity of presentation . ]",
    "@xmath47 with a gaussian distribution having a diagonal covariance matrix  @xmath48 : @xmath49 the fact that we do not seek to model the rest of the regions / pixels of @xmath14 is by design . by using 2d similarity transformation to mimic attention",
    ", we can discard the complex background of the scene and let the generative model focus on the object of interest .",
    "the proposed generative model takes the following form : @xmath50 where for @xmath51 we use a flat prior that is constant for all @xmath45 , and @xmath52 is defined by a 2-layer gaussian deep belief network .",
    "the conditional @xmath53 is given by a gaussian distribution as in  eq .",
    "[ eq : condx ] . to simplify the inference procedure ,",
    "@xmath54 and the gdbn model of @xmath9 , @xmath55 , will share the same noise parameters @xmath56 .",
    "[ sec : inf ] while the generative equations in the last section are straightforward and intuitive , inference in these models is typically intractable due to the complicated energy landscape of the posterior . during inference",
    ", we wish to compute the distribution over the gaze variables @xmath46 and canonical object @xmath21 given the big image @xmath22 . unlike in standard rbms and dbns",
    ", there are no simplifying factorial assumptions about the conditional distribution of the latent variable @xmath46 . having a 2d similarity transformation is reminiscent of third - order boltzmann machines with @xmath46 performing top - down multiplicative gating of the connections between @xmath21 and @xmath22 .",
    "it is well known that inference in these higher - order models is rather complicated .",
    "one way to perform inference in our model is to resort to gibbs sampling by computing the set of alternating conditional posteriors : the conditional distribution over the canonical image @xmath21 takes the following form : @xmath57 where @xmath58 is the top - down influence of the dbn .",
    "note that if we know the gaze variable @xmath45 and the first layer of hidden variables @xmath59 , then @xmath21 is simply defined by a gaussian distribution , where the mean is given by the average of the top - down influence and bottom - up information from @xmath60 .",
    "the conditional distributions over @xmath59 and @xmath11 given @xmath9 are given by the standard dbn inference equations  @xcite .",
    "the conditional posterior over the gaze variables @xmath46 is given by : @xmath61 using bayes rule , the unnormalized log probability of @xmath62 is defined in eq .",
    "[ eq : hmc ] .",
    "we stress that this equation is atypical in that the random variable of interest @xmath46 actually affects the conditioning variable @xmath60 ( see eq .",
    "[ eq : x_u ] ) we can explore the gaze variables using hamiltonian monte carlo ( hmc ) algorithm  @xcite .",
    "intuitively , conditioned on the canonical object @xmath21 that our model has in `` mind '' , hmc searches over the entire image @xmath22 to find a region @xmath60 with a good match to @xmath21 .",
    "if the goal is only to find the map estimate of @xmath62 , then we may want to use second - order methods for optimizing @xmath46",
    ". this would be equivalent to the lucas - kanade framework in computer vision , developed for image alignment  @xcite . however , hmc has the advantage of being a proper mcmc sampler that satisfies detailed balance and fits nicely with our probabilistic framework .",
    "the hmc algorithm first specifies the hamiltonian over the position variables @xmath46 and auxiliary momentum variables @xmath63 : @xmath64 , where the potential function is defined by @xmath65 and the kinetic energy function is given by @xmath66 .",
    "the dynamics of the system is defined by : @xmath67 @xmath68    observe that eq .",
    "[ eq : dxdu ] decomposes into sums over single coordinate positions @xmath69 { ^\\mathsf{t}}$ ] .",
    "let us denote @xmath70 to be the coordinate @xmath71 warped by @xmath72 .",
    "for the first term on the rhs of eq .",
    "[ eq : dxdu ] ,    @xmath73    where @xmath74 denotes the sampling of the gradient images of @xmath75 at the warped location @xmath71 . for the second term on the rhs of eq .",
    "[ eq : dxdu ] , we note that we can re - write eq .",
    "[ eq : w ] as : @xmath76   = \\big [ \\begin{array}{cccc } x & -y & 1 & 0 \\\\ y & x & 0 & 1   \\end{array } \\big ]   \\bigg [ \\begin{array}{c } a\\\\ b \\\\ \\triangle x \\\\ \\triangle y \\end{array } \\bigg ] + \\big [ \\begin{array}{c } x\\\\ y   \\end{array } \\big],\\ ] ] giving us @xmath77.\\ ] ]    hmc simulates the discretized system by performing leap - frog updates of @xmath46 and @xmath63 using eq .",
    "[ eq : hmc_update ] .",
    "additional hyperparameters that need to be specified include the step size @xmath78 , number of leap - frog steps , and the mass of the variables ( see  @xcite for details ) .",
    "[ sec : approx ]    r0.35     +    [ fig : why ]    hmc essentially performs gradient descent with momentum , therefore it is prone to getting stuck at local optimums .",
    "this is especially a problem for our task of finding the best transformation parameters .",
    "while the posterior over @xmath46 should be unimodal near the optimum , many local minima exist away from the global optimum .",
    "for example , in fig .",
    "[ fig : why](a ) , the big image @xmath22 is enclosed by the blue box , and the canonical image @xmath21 is enclosed by the green box .",
    "the current setting of @xmath46 aligns together the wrong eyes .",
    "however , it is hard to move the green box to the left due to the local optima created by the dark intensities of the eye . resampling the momentum variable every iteration in hmc",
    "does not help significantly because we are modeling real - valued images using a gaussian distribution as the residual , leading to quadratic costs in the difference between @xmath38 and @xmath21 ( see eq .",
    "[ eq : hmc ] ) .",
    "this makes the energy barriers between modes extremely high . to alleviate this problem we need to find good initializations of  @xmath46 .",
    "we use a convolutional network ( convnet ) to perform efficient approximate inference , resulting in good initial guesses .",
    "specifically , given @xmath21 , @xmath46 and @xmath22 , we predict the change in @xmath46 that will lead to the maximum @xmath79 . in other words , instead of using the gradient field for updating @xmath46 , we learn a convnet to output a better vector field in the space of  @xmath45 .",
    "we used a fairly standard convnet architecture and the standard stochastic gradient descent learning procedure .",
    "we note that standard feedforward face detectors seek to model @xmath80 , while completely ignoring the canonical face @xmath21 .",
    "in contrast , here we take @xmath21 into account as well .",
    "the convnet is used to initialize @xmath46 for the hmc algorithm .",
    "this is important in a proper generative model because conditioning on @xmath21 is appealing when multiple faces are present in the scene .",
    "[ fig : why](b ) is a hypothesized euclidean space of @xmath21 , where the black manifold represents canonical faces and the blue manifold represents cropped faces @xmath81 .",
    "the blue manifold has a low intrinsic dimensionality of 4 , spanned by @xmath46 . at a and b ,",
    "the blue comes close to black manifold .",
    "this means that there are at least two modes in the posterior over @xmath46 . by conditioning on @xmath9",
    ", we can narrow the posterior to a single mode , depending on whom we want to focus our attention .",
    "we demonstrate this exact capability in sec .",
    "[ sec : exp_bimodal ] .",
    "[ fig : inf ] demonstrates the iterative process of how approximate inference works in our model .",
    "specifically , based on @xmath46 , the convnet takes a window patch around @xmath38 ( @xmath82 ) and @xmath21 ( @xmath2 ) as input , and predicts the output @xmath83 $ ] . in step 2",
    ", @xmath46 is updated accordingly , followed by step 3 of alternating gibbs updates of @xmath21 and @xmath84 , as discussed in sec .",
    "[ sec : inf ] .",
    "the process is repeated . for the details of the convnet",
    "see the supplementary materials .",
    "while inference in our framework localizes objects of interest and is akin to object detection , it is not the main objective .",
    "our motivation is not to compete with state - of - the - art object detectors but rather propose a probabilistic generative framework capable of generative modeling of objects which are at unknown locations in big images .",
    "this is because labels are expensive to obtain and are often not available for images in an unconstrained environment .    to learn generatively without labels we propose a simple monte carlo based expectation - maximization algorithm .",
    "this algorithm is an unbiased estimator of the maximum likelihood objective . during the e - step ,",
    "we use the gibbs sampling algorithm developed in sec .",
    "[ sec : inf ] to draw samples from the posterior over the latent gaze variables @xmath46 , the canonical variables @xmath21 , and the hidden variables @xmath59 , @xmath11 of a gaussian dbn model . during the m - step , we can update the weights of the gaussian dbn by using the posterior samples as its training data .",
    "in addition , we can update the parameters of the convnet that performs approximate inference . due to the fact that the first e - step requires a good inference algorithm",
    ", we need to pretrain the convnet using labeled gaze data as part of a bootstrap process .",
    "obtaining training data for this initial phase is not a problem as we can jitter / rotate / scale to create data . in sec .",
    "[ sec : exp_learn ] , we demonstrate the ability to learn a good generative model of face images from the cmu multi - pie dataset .",
    "we used two face datasets in our experiments .",
    "the first dataset is a frontal face dataset , called the caltech faces from 1999 , collected by markus weber . in this dataset , there are 450 faces of 27 unique individuals under different lighting conditions , expressions , and backgrounds .",
    "we downsampled the images from their native 896 by 692 by a factor of 2 .",
    "the dataset also contains manually labeled eyes and mouth coordinates , which will serve as the gaze labels .",
    "we also used the cmu multi - pie dataset  @xcite , which contains 337 subjects , captured under 15 viewpoints and 19 illumination conditions in four recording sessions for a total of more than 750,000 images .",
    "we demonstrate our model s ability to perform approximate inference , to learn without labels , and to perform identity - based attention given an image with two people ."
  ],
  "abstract_text": [
    "<S> attention has long been proposed by psychologists to be important for efficiently dealing with the massive amounts of sensory stimulus in the neocortex . inspired by the attention models in visual neuroscience and the need for object - centered data for generative models , we propose a deep - learning based generative framework using attention . </S>",
    "<S> the attentional mechanism propagates signals from the region of interest in a scene to an aligned canonical representation for generative modeling . by ignoring scene background clutter , </S>",
    "<S> the generative model can concentrate its resources on the object of interest . </S>",
    "<S> a convolutional neural net is employed to provide good initializations during posterior inference which uses hamiltonian monte carlo . upon learning images of faces </S>",
    "<S> , our model can robustly attend to the face region of novel test subjects . </S>",
    "<S> more importantly , our model can learn generative models of new faces from a novel dataset of large images where the face locations are not known . </S>"
  ]
}