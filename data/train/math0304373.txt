{
  "article_text": [
    "-5 mm    let @xmath2 be mean zero independent @xmath0-valued random vectors and @xmath3 the covariance operator of the sum @xmath4 . by the central limit theorem , under some simple moment conditions the distribution of normalized sums",
    "@xmath5 is close to the standard gaussian distribution .",
    "the invariance principle states that , in a sense , the distribution of the _ whole _ sequence @xmath6 is close to the distribution of the sequence @xmath7 , @xmath8 , where @xmath9 and @xmath10 is a corresponding sequence of independent gaussian random vectors ( this means that @xmath11 has the same mean and the same covariance operator as @xmath12 , @xmath13 ) .",
    "we consider here the problem of strong approximation which is more delicate than that of estimating the closeness of distributions .",
    "it is required to construct on a probability space a sequence of independent random vectors @xmath14 ( with given distributions ) and a corresponding sequence of independent gaussian random vectors @xmath15 so that the quantity @xmath16 would be so small as possible with large probability . here @xmath17 is the euclidean norm .",
    "it is clear that the vectors even with the same distributions can be very far one from another .    in some sense",
    "this problem is one of the most important in probability approximations because many well - known probability theorems can be considered as consequences of results about strong approximation of sequences of sums by corresponding gaussian sequences .",
    "this is related to the law of iterated logarithm , to several theorems about large deviations , to the estimates for the rate of convergence of the prokhorov distance in the invariance principles ( prokhorov [ 19 ] , skorokhod [ 26 ] , borovkov [ 4 ] ) , as well as to the strassen - type approximations ( strassen [ 28 ] , see , for example , csrg and hall [ 8 ] ) .",
    "the rate for strong approximation in the one - dimensional invariance principle was studied by many authors ( see , e.g. , prokhorov  [ 19 ] , skorokhod  [ 26 ] , borovkov  [ 4 ] , csrg and rvsz  [ 6 ] and the bibliography in  csrg and rvsz  [ 7 ] , csrg and hall  [ 8 ] , shao  [ 20 ] ) . skorokhod  [ 26 ] developed a method of construction of close sequences of sequential sums of independent random variables on the same probability space . for a long time the best rates of approximation were obtained by this method , known now as the skorokhod embedding . however , komls , major and tusndy ( kmt )  [ 17 ] elaborated a new , more powerful method of dyadic approximation . with",
    "the help of this method they obtained optimal rates of gaussian approximation for sequences of independent identically distributed random variables .",
    "we restrict ourselves on the most important case , where the summands have finite exponential moments .",
    "sakhanenko  [ 24 ] generalized and essentially sharpened kmt results in the case of non - identically distributed random variables .",
    "he considered the following class of one - dimensional distributions : @xmath18 ( the distribution of a random vector @xmath19 will be denoted by @xmath20 . his main result is formulated as follows .    * * theorem 1 * *   _ suppose that _ @xmath21 _ _ , and _",
    "_ @xmath22 _ _  are independent random variables with _ _ @xmath23 _ _ , _ _ @xmath24__. then one can construct on a probability space a sequence of independent random variables _ _ @xmath14 _ _  and a sequence of independent gaussian random variables _ _ @xmath25 _ _  so that _ _",
    "@xmath27 _ _ ,  _ _ @xmath28 _ _ ,  _ _ @xmath29 _ _ ,  _ _ @xmath24 _ _ ,  and _ _ @xmath30 _ where _ @xmath31 _ _  is an absolute constant and  _ _ @xmath32__. _ _    kmt [ 17 ] supposed that @xmath33 are identically distributed and @xmath34 , for @xmath35 , where @xmath36 is some neighborhood of zero . the kmt ( 197576 ) result follows from theorem 1 .",
    "it is easy to see that there exists @xmath37 such that @xmath38 . applying the chebyshev inequality",
    ", we observe that ( [ expsah ] ) imply that @xmath39 inequality ( [ kmt ] ) provides more information than the original kmt formulation which contains unspecified constants depending on @xmath40 . in ( [ kmt ] ) the dependence of constants on the distribution @xmath40 is written out in an explicit form .",
    "the quantity @xmath37 can be easily calculated or estimated for any concrete distribution @xmath40 .",
    "the first attempts to extend the kmt and sakhanenko approximations to the multidimensional case ( see berkes and philipp  [ 3 ] , philipp  [ 18 ] , berger  [ 2 ] , einmahl  [ 10 , 11 ] ) had a partial success only .",
    "comparatively recently u. einmahl [ 12 ] obtained multidimensional analogs of kmt results which are close to optimal .",
    "zaitsev [ 33 , 34 ] removed an unnecessary logarithmic factor from the result of einmahl  [ 12 ] and obtained multidimensional analogs of kmt results ( see theorem 2 below ) . in theorem 2 the random vectors are , generally speaking , non - identically distributed .",
    "however , they have the same identity covariance operator  @xmath41 . therefore , the problem of obtaining an adequate multidimensional generalization of the main result of sakhanenko  [ 24 ] remained open .",
    "this generalization is given in theorem  3 below .",
    "-5 mm    for formulations of results we need some notations .",
    "let @xmath42 , @xmath43 , @xmath44 , denote classes of @xmath1-dimensional distributions , introduced in zaitsev [ 29 ] , see as well zaitsev [ 3335 ] .",
    "the class @xmath45 ( with a fixed @xmath43 ) consists of @xmath1-dimensional distributions  @xmath40 for which the function @xmath46 @xmath47 is defined and analytic for @xmath48 , @xmath49 , and @xmath50 for all @xmath51 and @xmath48 , where @xmath52 , the covariance operator corresponding to @xmath40 , and @xmath53 is the derivative of the function @xmath54 in direction @xmath55 .",
    "* theorem 2 * ( zaitsev , [ 33 , 34 ] ) * * _ suppose that _ @xmath56 _ _ , _ _ @xmath57__and _ _ @xmath22 _ _  are random vectors with distributions _ _ @xmath58 _ _ , _ _ @xmath59 _ _ , _ _ @xmath60 _ _ , _ _ @xmath61__. then one can construct on a probability space a sequence of independent random vectors _ _ @xmath14 _ _  and a sequence of independent gaussian random vectors _ _ @xmath62 _ _  so that _ _ @xmath63 _ and _ @xmath64 _ where _ @xmath65 _ _ , _ _ @xmath66 _ _  are positive quantities depending on  _ _ @xmath67 _ _  only and _ _ @xmath68 , @xmath69 _ _ , for _ _ @xmath70    * corollary 1 .",
    "* _ _ in the conditions of theorem  _",
    "_ @xmath71 _  for all _ @xmath72 _ _  the following inequality is valid _ _",
    "@xmath73    it is easy to see that if @xmath74 is some neighborhood of zero and @xmath75 , for @xmath35 , then @xmath76 .",
    "below we list some simple and useful properties of classes @xmath45 which are essential in the proof of theorem 2 . theorem 2 implies in one - dimensional case sakhanenko s theorem 1 for identically distributed random variables with finite exponential moments as well as the result of kmt [ 17 ] .    *",
    "corollary 2 . *",
    "_ _ suppose that a random vector  _ _ @xmath19 _  has finite exponential moments _ @xmath77 _ _ , for _ _ @xmath35 _ _ , where _ _ @xmath74__is some neighborhood of zero .",
    "then one can construct on a probability space a sequence of independent random vectors _ _ @xmath78 _ _  and a sequence of independent gaussian random vectors _ _ @xmath79 _ _  so that _ _ @xmath80 _ and _",
    "@xmath81    as it is noted in kmt [ 17 ] , from the results of brtfai [ 1 ] that the rate of approximation in corollary  2 is the best possible for non - gaussian vectors  @xmath19 . an analog of corollary 2 was obtained by einmahl [ 12 ] under additional smoothness - type restrictions on the distribution @xmath82 .",
    "the following statement is a sharpening of corollary 2 .",
    "* corollary 3 * ( zaitsev [ 36])*. * _ _ suppose that a random vector  _ _ @xmath19 _  has the distribution such that _ @xmath83 _ _ , where _ _ @xmath84 _ is a reversible operator .",
    "@xmath85 , @xmath86 , _ be the maximal eigenvalue of _ @xmath87 . _ then for any _",
    "there exists a construction from corollary _ @xmath71 _ such that _ @xmath88 _ with _",
    "_  depending on _ _ @xmath67__only . _ _    in theorems 2 and corollary 3 we consider the case @xmath56 .",
    "the case of small @xmath90 was investigated by gtze and zaitsev [ 16 ] .",
    "it is shown that under additional smoothness - type restrictions on the distribution @xmath91 the expression in the right - hand side of the inequality in ( [ cor3 ] ) can be arbitrarily small if the parameter @xmath90 is small enough .",
    "it is clear that the statements of theorem  2 and corollary 3 becomes stronger for small  @xmath90 . in gtze and zaitsev",
    "[ 16 ] one can find simple examples in which the sufficiently complicated smoothness condition is satisfied .",
    "the approximation is better in the case when summands have smooth distributions which are close to gaussian ones ( see inequalities ( [ pi0 ] ) and ( [ pi ] ) below ) .",
    "the following theorem 3 is a generalization of theorem 2 to the case of multivariate random variables . in one - dimensional situation ,",
    "theorem 3 implies theorem  1 . _ _    * * theorem 3 * *   _ suppose that _ @xmath92 _ _ , _ _ @xmath56 _ _ , and _ _ @xmath22__are independent random vectors with _",
    "_ @xmath93 _ _ , _ _ @xmath24__. assume that there exists a strictly increasing sequence of non - negative integers _ _ @xmath94 _ _ , _ _ @xmath95 _ _  satisfying the following conditions .",
    "_ @xmath96 _ and suppose that _ @xmath97__for all _ _ @xmath98 _ _  _ _ @xmath99 _ _ , _ _ @xmath100 _ _  and , for all _ _ @xmath101 _ _ , _ _ @xmath102 _ with some constants _ @xmath103 _ _  and _ _",
    "@xmath104__. then one can construct on a probability space a sequence of independent random vectors _ _ @xmath14 _ _  and a corresponding sequence of independent gaussian random vectors _ _ @xmath25 _ _  so that _ _ @xmath105 _ _ , _ _ @xmath28 _ _ , _ _ @xmath106 _ _ , _ _ @xmath24 _ _ , and _ _ @xmath107 _ where _ @xmath108 _ _ , _ _ @xmath109 _ _  are positive quantities depending only on _",
    "_ @xmath110__. _ _",
    "-5 mm    let us consider elementary properties of classes @xmath45 which are essentially used in the proof of theorems 2 and 3 , see zaitsev [ 29 , 31 , 3335 ] . it is easy to see that @xmath111 implies @xmath112 .",
    "moreover , the class @xmath113 is closed with respect to convolution : if  @xmath114 , then  @xmath115@xmath116 .",
    "products of measures are understood in the convolution sense .",
    "note that the condition @xmath117 in theorem 3 is satisfied if @xmath118 , for @xmath24 .",
    "let @xmath119 , @xmath120 , @xmath121 , and @xmath122 is a linear operator .",
    "then @xmath123    suppose that @xmath119 , @xmath124 , and the vectors @xmath125 , @xmath126 , are independent .",
    "let @xmath127 be the vector with the first @xmath128  coordinates coinciding with those of  @xmath129 and with the last @xmath130  coordinates coinciding with those of @xmath131",
    ". then @xmath132 .    the classes @xmath45 are closely connected with other naturally defined classes of multidimensional distributions . from the definition of @xmath45",
    "it follows that if @xmath133 then the vector  @xmath19 has finite exponential moments @xmath34 , for @xmath134 , @xmath135 .",
    "this leads to exponential estimates for the tails of distributions .",
    "the condition @xmath136 is equivalent to statuleviius [ 27 ] conditions on the rate of increasing of cumulants @xmath137 of the random variable @xmath138 : @xmath139 this equivalence means that if one of these conditions is satisfied with parameter  @xmath90 , then the second is valid with parameter  @xmath140 , where @xmath31 denotes an absolute constant .",
    "however , the condition @xmath141 differs essentially from other multidimensional analogs of statuleviius conditions , considered by rudzkis  [ 23 ] and saulis  [ 25 ] .",
    "zaitsev [ 30 ] considered classes of distributions @xmath142 satisfying multidimensional analogs of the bernstein inequality condition .",
    "sakhanenko s condition @xmath143 is equivalent to the condition @xmath144 .",
    "note that if @xmath145then @xmath146    let us formulate a relation between classes @xmath147 and @xmath148 .",
    "denote by @xmath149 the maximal eigenvalue of the covariance operator of a  distribution  @xmath150 .",
    "then    \\a ) if @xmath151 , then @xmath152 , @xmath153 and @xmath154 .",
    "\\b ) if @xmath155 , @xmath156 and @xmath153 , then @xmath157 .    if @xmath40 is an infinitely divisible distributions with spectral measure concentrated on the ball @xmath158 then @xmath159 , where @xmath31 is an absolute constant .",
    "it is obvious that the class @xmath160 coincides with the class of all @xmath1-dimensional gaussian distributions .",
    "the following inequality was proved in  zaitsev [ 29 ] and can be considered as an estimate of stability of this characterization : @xmath161 where @xmath162 is the prokhorov distance and @xmath163 denotes the gaussian distribution whose mean and covariance operator coincide with those of  @xmath40 . the prokhorov distance between distributions @xmath164",
    "may be defined by means of the formula @xmath165 where @xmath166 and @xmath167 is the @xmath168-neighborhood of the borel set  @xmath169 .",
    "moreover , in  zaitsev [ 29 ] it was established that @xmath170 it  is very essential ( and important ) that the inequality  ( [ pi ] ) is proved for all  @xmath171 and for arbitrary  cov@xmath40 , in contrast to theorems  2 and  3 , where @xmath56 and covariance operators satisfy condition ( [ c ] ) .",
    "the question about the necessity of condition   ( [ c ] ) in theorems  2 and  3 remains open . in  zaitsev [ 30 ]",
    "inequalities ( [ pi0 ] ) and ( [ pi ] ) were proved for convolutions of distributions from @xmath148    by the strassen  dudley theorem ( see dudley [ 9 ] ) coupled with inequality ( [ pi ] ) , one can construct on a probability space the random vectors @xmath19 and @xmath172 with @xmath173 and @xmath174 so that @xmath175 for convolutions of bounded measures , this fact was used by rio  [ 21 ] , einmahl and mason [ 13 ] , bovier and mason [ 5 ] , gentz and lwe [ 15 ] , einmahl and kuelbs [ 14 ] .",
    "the scheme of the proof of theorems  2 and 3 is very close to that of the main results of sakhanenko [ 24 ] and einmahl [ 12 ] .",
    "we suppose that the gaussian vectors @xmath25 , @xmath176 , are already constructed and construct the independent vectors which are bounded with probability one , have sufficiently smooth distributions and the same moments of the first , second and third orders as the needed independent random vectors  @xmath14 . for the construction",
    "we use the dyadic scheme proposed by kmt [ 17 ] .",
    "firstly we construct the sum of @xmath177 summands using the rosenblatt [ 22 ] quantile transform for conditional distributions ( see einmahl [ 12 ] ) .",
    "then we construct blocks of @xmath178 summands .",
    "the rate of approximation is estimated using the fact that , for smooth summands distributions , the corresponding conditional distribution are smooth and close to gaussian ones .",
    "then we construct the vectors   @xmath14 in several steps .",
    "after each step the number of  @xmath179 which are not constructed becomes smaller in @xmath180  times , where @xmath181  is a suitably chosen positive integer . in each step",
    "we begin with already constructed vectors which are bounded with probability one and have sufficiently smooth distributions and the needed moments up to the third order .",
    "then we construct the vectors such that , in each block of @xmath182  summands , only the first vector has the initial bounded smooth distribution .",
    "the rest @xmath183  vectors have the needed distributions  @xmath184 .",
    "these @xmath183  vectors from each block will be chosen as @xmath179 and will be not involved in the next steps of the procedure .",
    "the coincidence of third moments will allow us to use more precise estimates of the closeness of quantiles of conditional distributions contained in zaitsev [ 32 ] . in the estimation of closeness of random vectors in the steps of the procedure described above",
    ", we use essentially properties of classes @xmath45 .",
    "-5 mm    let us finally mention a result about strong approximation of sums of independent random vectors by infinitely divisible distributions .",
    "theorem 4 below follows from the main result of zaitsev [ 32 ] coupled with the strassen  dudley theorem .",
    "inequality ( [ infdiv ] ) can be considered as a generalization of inequality ( [ pi1 ] ) to convolution of distribution with unbounded supports .",
    "* theorem 4 * _ let _ @xmath1__-dimensional probability distributions _",
    "_ @xmath185 _ _ , _ _ @xmath186 _ _ , be represented as mixtures of _ _ @xmath1__-dimensional probability distributions _ _ @xmath187 _ _  and _ _ @xmath188 _ _ : _ _ @xmath189 _ where _ @xmath190 _ and _ @xmath188 _ _  are arbitrary distributions . then for any fixed _",
    "_ @xmath191 _",
    "_  one can construct on the same probability space the random vectors _ _ @xmath19 _ _  and _ _ @xmath192 _ _  so that _ _ @xmath193 _ and _ @xmath194 _ where _ @xmath195 _ _  depends on only and _ _ @xmath196 _ _  denotes the compound poisson infinitely divisible distribution with characteristic function _ _ @xmath197 _ _ , where _ _ @xmath198__. if the distributions _ _ @xmath188 _ _  are identical , the term _ _ @xmath199 _ _  in _ _ ( [ infdiv ] ) _  can be omitted_.    99 p. brtfai , die bestimmung der zu einem wiederkehrenden prozess gehrenden verteilungfunktion aus den mit fehlern behafteten daten einer einzigen realisation , _ studia sci .",
    "hungar . , _ 1 ( 1966 ) , 161168 .",
    "f. gtze & a. yu .",
    "zaitsev , multidimensional hungarian construction for vectors with almost gaussian smooth distributions , _ in : asymptotic methods in probability and statsistics ( n. balakrishnan , i. ibragimov , v. nevzorov eds . ) , _ birkhuser , boston , 2001 , 101 - 132 .",
    "a. i. sakhanenko , rate of convergence in the invariance principles for variables with exponential moments that are not identically distributed , _ in : trudy inst .",
    "so an sssr 3 , _ nauka , novosibirsk , 1984 , 449 ( in russian ) .",
    "zaitsev , on the connection between two classes of probability distributions , _ in : rings and modulus .",
    "limit theorems of probability theory .",
    "vol .  2 , _ leningrad university press , leningrad , 1988 , 153158 .",
    "zaitsev , multidimensional version of the results of sakhanenko in the invariance principle for vectors with finite exponential moments .",
    "i ; ii ; iii , _ theor . probab .",
    "_ , 45 * * ( * * 2000 ) , 718738 ; 46 ( 2001 ) , 535 - 561 ; 744 - 769 ."
  ],
  "abstract_text": [
    "<S> in a recent paper the author obtained optimal bounds for the strong gaussian approximation of sums of independent @xmath0-valued random vectors with finite exponential moments . </S>",
    "<S> the results may be considered as generalizations of well - known results of komls  major  tusndy and sakhanenko . </S>",
    "<S> the dependence of constants on the dimension @xmath1 and on distributions of summands is given explicitly . </S>",
    "<S> some related problems are discussed .    </S>",
    "<S> 4.5 mm    * 2000 mathematics subject classification : * 60f05 , 60f15 , 60f17 .    * keywords and phrases : * strong approximation , prokhorov distance , central limit theorem , sums of independent random vectors . </S>"
  ]
}