{
  "article_text": [
    "nowadays , many engineering applications can be posed as conic convex problems .",
    "several important applications that can be modeled in this framework , the network utility maximization problem @xcite , the resource allocation problem @xcite , the optimal power flow problem for a power system @xcite or model predictive control problem for a dynamical system @xcite , have attracted great attention lately .",
    "when it is difficult to project on the primal feasible set of the convex problem , we use the lagrangian relaxation to handle the complicated constraints and then solve the corresponding dual .",
    "first order methods for solving the corresponding dual of constrained convex problems have been extensively studied in the literature .",
    "dual subgradient methods based on averaging ( so called ergodic sequence ) , that produce primal solutions in the limit , can be found e.g. in @xcite .",
    "convergence rate analysis for the dual subgradient method has been studied e.g. in @xcite , where estimates for suboptimality and feasibility violation of an average primal sequence are provided . in @xcite",
    "the authors have combined a dual fast gradient algorithm and a smoothing technique for solving non - smooth dual problems and derived rate of convergence of order @xmath0 , with @xmath1 denoting the iteration counter , for primal suboptimality and feasibility violation for an average primal sequence .",
    "also , in @xcite the authors proposed inexact dual ( fast ) gradient algorithms for solving dual problems and estimates of order @xmath0 ( @xmath2 ) in an average primal sequence are provided for primal suboptimality and feasibility violation .",
    "convergence properties of a dual fast gradient algorithm were also analyzed in @xcite in the context of predictive control .",
    "however , most of the papers enumerated above provide an approximate primal solution for convex problems based on averaging .",
    "there are very few papers deriving the iteration complexity of dual first order methods using as an approximate primal solution the last iterate of the algorithm ( see e.g. @xcite ) , although from our practical experience we have observed that usually these methods are converging faster in the primal last iterate than in a primal average sequence .",
    "for example , for a dual fast gradient method , rate of convergence of order @xmath0 in the last iterate is provided in @xcite under the assumptions of lipschitz continuity and strong convexity of the primal objective function and primal linear constraints . from our knowledge first result on the linear convergence of dual gradient method in the last iterate was provided in @xcite under a _ local _ error bound property of the dual . however , in @xcite linear convergence is proved only locally and for dual gradient method .",
    "recently , in @xcite the authors show that , for linearly constrained smooth convex problems satisfying a slater type condition , the dual problem has a global error bound property .",
    "moreover , in @xcite tseng posed the question whether there exist fast gradient schemes that converge linearly on convex problems having an error bound property .",
    "another strand of this literature uses augmented lagrangian based methods @xcite or newton methods @xcite . for example , @xcite established a linear convergence rate of alternating direction method of multipliers using an error bound condition that holds under specific assumptions on the primal problem . in @xcite",
    "the iteration complexity of inexact augmented lagrangian methods is analyzed , where the inner problems are solved approximately and the dual variables are updated using dual ( fast ) gradient schemes . in @xcite dual newton algorithms are derived under the assumption that the primal objective function is self - concordant .    in conclusion , despite the fact that there are attempts to analyze the convergence properties of dual first order methods , the results are dispersed , incomplete and many aspects",
    "have not been fully studied .",
    "in particular , in practical applications the main interest is in finding approximate primal solutions .",
    "moreover , we need to characterize the convergence rate for these near - feasible and near - optimal primal solutions . finally , we are interested in providing schemes with fast convergence rate .",
    "these issues motivate our work here , which provides a detailed convergence analyzes of dual first order methods for solving conic convex  problems .    _",
    "contributions_. in this paper we provide a convergence analysis of dual first order methods producing approximate primal feasible and suboptimal solutions for conic convex problems .",
    "our analysis is based on the lipschitz gradient property of the dual function or an error bound property of the dual problem .",
    "further , the iteration complexity analysis is based on two types of approximate primal solutions : the last primal iterate or an average primal sequence .",
    "we prove that first order algorithms for solving the dual problem have the following iteration complexity in terms of primal suboptimality and infeasibility :    \\(i ) for strongly convex primal objective functions we prove : for dual gradient method a sublinear convergence rate in both , an average primal sequence ( convergence rate of order @xmath3 ) , or the last primal iterate sequence ( convergence rate @xmath4 ) ) ; for dual fast gradient method a sublinear convergence rate in an average primal sequence ( convergence rate @xmath5 ) , or the last primal iterate sequence ( convergence rate @xmath3 ) .",
    "\\(ii ) if we use regularization techniques we prove that the convergence estimates of dual fast gradient method for both primal sequences ( the last iterate and an average of iterates ) have the same order ( up to a logarithmic factor ) .",
    "\\(iii ) if additionally the dual problem has an error bound property , then we prove that dual first order methods ( including a fast gradient scheme with restart ) converge _ globally _ with linear rate in the last primal iterate sequence ( convergence rate @xmath6 , with @xmath7 ) , a result which appears to be new in this area .",
    "\\(iv ) finally , if the conic constraints are linear constraints , then based on the properties of dual first order methods and regularization techniques we improve the previous convergence rates of dual first order methods in the last iterate with one order of magnitude .",
    "an important feature of our results is that these rates of convergence are not only for the average of iterates but also for the latest iterate .",
    "this feature is of practical importance since usually the last iterates are employed in practical applications and the present paper provides computational complexity certificates for them .    _",
    "notations : _ we work in the space @xmath8 composed by column vectors . for @xmath9",
    "we denote the standard euclidean inner product @xmath10 , the euclidean norm @xmath11 and the projection of @xmath12 onto the convex set @xmath13 as @xmath14_x$ ] .",
    "further , @xmath15 denotes the distance from @xmath12 to the convex set @xmath13 , i.e. @xmath16 .",
    "moreover , for a matrix @xmath17 we use the notation @xmath18 for the spectral norm .",
    "we consider the following conic convex optimization problem : @xmath19 where @xmath20 is convex function , @xmath21 , @xmath22 is a proper cone and @xmath23 is a closed convex set .",
    "moreover , we assume that both sets @xmath24 and @xmath25 are simple , i.e. the projection on these sets is easy . many engineering applications can be posed as constrained convex problems ( e.g. network utility maximization problem @xcite : @xmath26 is @xmath27 function and @xmath25 is a box set ; optimal power flow problem @xcite : @xmath26 is quadratic function and @xmath25 is a box set ; model predictive control problem @xcite : @xmath26 is quadratic function and @xmath25 is a set described by linear equality constraints ) .",
    "thus , we are interested in deriving tight convergence estimates of dual first order methods for this optimization model .",
    "we denote with @xmath28 the corresponding dual cone of @xmath24 , i.e. @xmath29 .",
    "further , for simplicity of the exposition we use the short notation : @xmath30    throughout the paper , we make the following assumption on optimization problem :    [ as_strong ] the function @xmath26 is @xmath31-strongly convex w.r.t .",
    "the euclidean norm and there exists a finite optimal lagrange multiplier @xmath32 for the conic constraints of .    note that if the objective function @xmath26 is not strongly convex , we can apply smoothing techniques by adding a regularization term to the convex function @xmath26 in order to obtain a strongly convex approximation of it and a corresponding smooth approximation of the dual function .",
    "then , we can use a dual fast gradient method for maximizing the smooth approximation of the dual function and then we can recover an approximate primal solution for the original problem ( see e.g. @xcite for more details regarding the iteration complexity estimates for this approach ) .",
    "furthermore , we can always guarantee the existence of a finite optimal lagrange multiplier @xmath32 provided that e.g. slater condition holds : there exists @xmath33 such that @xmath34 .    since there exists a finite optimal lagrange multiplier @xmath32 , strong duality holds for optimization problem ( see @xcite ) .",
    "in particular , we have : @xmath35 where @xmath36 denote the dual function of problem : @xmath37    we denote by @xmath38 the set of optimal solutions of dual problem , which is nonempty and convex according to assumption [ as_strong ] . since @xmath26 is strongly convex function , the lagrangian function @xmath39 is also strongly convex .",
    "then , the inner problem @xmath40 has always a unique finite optimal solution for any fixed @xmath41 . in conclusion",
    ", the dual function @xmath42 has the effective domain the entire euclidean space @xmath43 , i.e. @xmath44 . moreover , since the minimizer of for any fixed @xmath41 is unique , from danskin s theorem @xcite we get that the dual function @xmath42 is differentiable everywhere and its gradient is given by the following expression : @xmath45 where @xmath46 denotes the unique optimal solution of the inner problem , i.e. : @xmath47 moreover , from theorem 1 in @xcite it follows immediately that the dual gradient @xmath48 is lipschitz continuous on @xmath49 with constant @xmath50 , i.e. : @xmath51 from lipschitz continuity of the dual gradient the following inequality ( so - called descent lemma ) is valid @xcite : @xmath52    in this paper we analyze several dual first order methods for solving problem and derive convergence estimates for dual and primal suboptimality and also for primal feasibility violation , i.e. finding an @xmath53-primal - dual pair @xmath54 such that : @xmath55 where @xmath53 is a given accuracy and @xmath56 is the unique minimizer of problem .",
    "thus , we introduce the following definition :    we say that @xmath57 is an _ @xmath53-primal solution _ for the original convex problem if we have the following relations for primal infeasibility and suboptimality : @xmath58      in this section we derive first some relations between the optimal solution of the inner problem @xmath46 and the dual function @xmath36 .",
    "then , we also derive some properties of the gradient map .",
    "these results will be used in the subsequent sections .    in the next lemma",
    "we derive some relations between the optimal solution of the inner problem @xmath46 and the dual function @xmath36 .",
    "these relations have been proven in @xcite for @xmath59 ( non - negative orthant ) . for completeness",
    ", we also give a short proof :    [ lemma_sc ] under assumption [ as_strong ] , the following inequality holds : @xmath60 and the primal feasibility violation can be expressed in terms of @xmath61 as : @xmath62    first , let us recall that @xmath63 and the following relations : @xmath64 since @xmath65 is @xmath31-strongly convex , it follows that @xmath66 is also @xmath31-strongly convex in the variable @xmath67 for any fixed @xmath68 , which gives the following inequality : @xmath69 taking now @xmath70 in the previous inequality and using that @xmath71 for any @xmath72 and that @xmath73 for any @xmath74 , we have : @xmath75 valid for all @xmath74 .",
    "we now express the primal feasibility violation in terms of @xmath61 for any @xmath76 . indeed , using that @xmath77 and that @xmath78 we get : @xmath79 these relations prove the statements of the lemma .",
    "we now express the primal suboptimality in terms of @xmath80 , a result which appears to be new :    under assumption [ as_strong ] , the following inequality holds : @xmath81    firstly , using the complementarity condition @xmath82 we get : @xmath83   \\leq f(u(x ) ) + \\langle x^ * , g(u(x ) )   \\rangle,\\end{aligned}\\ ] ] which leads to the following relation : @xmath84 using the cauchy - schwartz inequality we derive : @xmath85 secondly , from the definition of the dual function we have : @xmath86 subtracting @xmath87 from both sides and using the complementarity condition @xmath88 we get : @xmath89 valid for all @xmath74 , where in the first inequality we used concavity of dual function @xmath42 , in the second inequality the relation @xmath90 and cauchy - schwartz inequality and in the third inequality a property of the euclidean norm . in conclusion , using the triangle inequality for vector norms , we obtain the following inequality : @xmath91 combining and we obtain the bound on primal suboptimality .    note that , based on our derivations from above , we are able to characterize primal suboptimality without assuming any lipschitz property on @xmath26 as opposed to the results in @xcite , where the authors had to require lipschitz continuity of @xmath26 for providing estimates on primal suboptimality .",
    "however , for many applications @xmath25 is unbounded set and @xmath26 is quadratic function ( e.g. in model predictive control @xmath26 is quadratic and @xmath25 might be a set described by linear equality constraints @xcite ) and thus it is not lipschitz continuous , so that our theory covers this important case .",
    "further , let us introduce the notion of gradient map denoted @xmath92 and the gradient step from @xmath93 denoted @xmath94 ( see also @xcite ) : @xmath95_{{\\mathcal{k}}^ * } - x    \\quad \\text{and } \\quad x^+ = \\left[x + \\frac{1}{l_\\text{d } } \\nabla d(x)\\right]_{{\\mathcal{k}}^*}.\\ ] ] clearly , @xmath72 if and only if @xmath96 and @xmath97 .",
    "next lemma proves that the norm of the gradient map is decreasing along a gradient step , i.e. :    [ lemma2_dg ] under assumption [ as_strong ] the following inequality holds : @xmath98    since the dual function @xmath42 has @xmath99-lipschitz gradient on @xmath49 ( see ) and is concave , the following relation holds @xcite : @xmath100    if we replace in the previous inequality @xmath101 with a gradient step in @xmath93 , i.e. @xmath102_{{\\mathcal{k}}^*}$ ] , and arranging the terms we get : @xmath103 grouping the terms appropriately we obtain : @xmath104 using now the triangle inequality for a norm @xmath105 we get : @xmath106 finally ,",
    "since the projection is non - expansive we obtain : @xmath107_{{\\mathcal{k}}^ * } - [ x + \\frac{1}{l_\\text{d } } \\nabla d(x)]_{{\\mathcal{k}}^ * } \\| \\leq   \\|x^+ - x\\|.\\ ] ] combining the previous inequality with the definitions of @xmath108 and of @xmath94 , we obtain the statement of the lemma .",
    "finally we show a relation between the dual gradient and the gradient map :    [ lemma2_dg ] under assumption [ as_strong ] the following inequality holds : @xmath109    first , we derive a property of the projection , namely : @xmath110_{{\\mathcal{k}}^ * } - y \\in { \\mathcal{k}}\\quad \\forall y \\in { \\mathbb{r}}^p.\\end{aligned}\\ ] ] indeed , @xmath111_{{\\mathcal{k}}^ * } \\in \\arg \\min_{z \\in { \\mathcal{k}}^ * } \\|z - y\\|$ ] if and only if @xmath112_{{\\mathcal{k}}^ * } -y , z - [ y]_{{\\mathcal{k}}^ * } \\rangle \\geq 0 $ ] for all @xmath113 .",
    "hence @xmath112_{{\\mathcal{k}}^ * } -y , z \\rangle   \\geq \\langle [ y]_{{\\mathcal{k}}^ * } - y , [ y]_{{\\mathcal{k}}^ * } \\rangle$ ] for all @xmath113 .",
    "since the left hand side of the last inequality is bounded below for all @xmath113 , it follows that @xmath111_{{\\mathcal{k}}^ * } -y \\in { \\mathcal{k}}$ ] .",
    "then , we have : @xmath114_{{\\mathcal{k}}^ * } - x\\| \\\\ & = \\| \\underbrace{[x + \\frac{1}{l_\\text{d } } \\nabla d(x)]_{{\\mathcal{k}}^ * }   - ( x + \\frac{1}{l_\\text{d } } \\nabla d(x))}_{\\eqref{prop_proj } \\;\\ ; \\rightarrow \\;\\ ; \\in { \\mathcal{k } } } - ( -\\frac{1}{l_\\text{d } } \\nabla d(x ) ) \\| \\\\ & \\geq \\text{dist}_{{\\mathcal{k}}}(-\\frac{1}{l_\\text{d } } \\nabla d(x ) ) ) = \\frac{1}{l_\\text{d } } \\text{dist}_{{\\mathcal{k}}}(- \\nabla d(x))).\\end{aligned}\\ ] ] since @xmath115 , we also obtain a bound for primal infeasibility : @xmath116      in this section we present a general framework for dual first order methods generating approximate primal feasible and primal optimal solutions for the convex problem .",
    "this general framework covers important particular algorithms @xcite : e.g. dual gradient algorithm , dual fast gradient algorithm , hybrid fast gradient / gradient algorithm or restart fast gradient algorithm , as we will see in the next sections .",
    "thus , we will analyze the iteration complexity of some particular cases of the following general dual first order method that updates two dual sequences @xmath117 and one primal sequence @xmath118 as follows :    where @xmath119 and @xmath120 are the parameters of the method and in the next sections we show how we can choose them in an appropriate way .",
    "recall also the following relations : @xmath121 and @xmath122 .",
    "note that if we can not solve the inner problem @xmath123 ( step 1 in algorithm * ( dfo ) * ) exactly , but approximatively with some inner accuracy , then our framework allows us to use approximate solutions @xmath118 and inexact dual gradients .",
    "this is beyond the scope of the present paper , but for more details see e.g. @xcite .",
    "in this section we consider a variant of algorithm * ( dfo ) * , where @xmath124 for all @xmath125 . under this choice for the parameter @xmath120 we have that @xmath126 and",
    "thus we obtain the following dual gradient algorithm with variable step size @xmath119 :    where @xmath127 such that @xmath128 and recall that @xmath129 .",
    "let us now derive some important properties of the dual gradient method that will be useful in the following sections .",
    "[ lemma1_dg ] let assumption [ as_strong ] hold and the sequence @xmath130 be generated by algorithm * ( dg)*. then , the following inequalities are valid : @xmath131    based on the update rule for the gradient method we get : @xmath132 where the first inequality follows from the definition of @xmath133 , i.e. from the property of the projection operator @xmath134 for any @xmath74 , and @xmath135 .",
    "in conclusion , for all @xmath125 and @xmath74 we obtain : @xmath136 now , if we take @xmath137 in and use concavity of @xmath42 , we get that : @xmath138 thus , we obtain : @xmath139 moreover , if we take @xmath140 in and use @xmath141 , then we get that the dual gradient algorithm is an ascent method : @xmath142 finally , if we take @xmath143 in , using that @xmath144 and that @xmath145 , then we get : @xmath146 relations , and prove the statements of the lemma .",
    "furthermore , for any @xmath74 we can define the following finite quantity : @xmath147 from assumption [ as_strong ] it follows that there exists a finite optimal lagrange multiplier @xmath32 and thus @xmath148 , i.e. it is finite , for any finite @xmath74 .",
    "the well - known sublinear convergence rate of algorithm * ( dg ) * in terms of dual suboptimality is given in the next lemma ( see theorem 4 in @xcite ) :    @xcite [ th_sublin ] let assumption [ as_strong ] hold and the sequence @xmath130 be generated by algorithm * ( dg)*. then , defining @xmath149 , a sublinear estimate on dual suboptimality for dual problem is given by : @xmath150    although the convergence rate is given for constant step size in @xcite , it is easy to show that for variable step size the convergence rate is similar . therefore , we omit the proof and we refer e.g. to theorem 4 in @xcite for details .    in the sequel we use @xmath151_{x^*}$ ] and thus @xmath152 .",
    "our iteration complexity analysis for algorithm * ( dg ) * is based on two types of approximate primal solutions : the last primal iterate sequence @xmath153 or an average primal sequence @xmath154 of the form : @xmath155      in this section we derive sublinear estimates for primal feasibility and primal suboptimality for the last primal iterate sequence @xmath156 generated by algorithm * ( dg)*. let us notice that from the definition of algorithm * ( dg ) * we have @xmath157 .",
    "[ th_dglast ] let assumption [ as_strong ] hold and the sequences @xmath158 be generated by algorithm * ( dg)*. then , for a given accuracy @xmath159 we get an @xmath53-primal solution for in the last primal iterate @xmath118 of algorithm * ( dg ) * after @xmath160 iterations .",
    "firstly , combining and we obtain the following important relation characterizing the distance from the last iterate @xmath118 to the unique optimal solution @xmath56 of our original problem : @xmath161 secondly , combining the previous relation and we obtain a sublinear estimate for feasibility violation of the last iterate @xmath118 for algorithm * ( dg ) * : @xmath162 where we used that @xmath163 and @xmath164 .",
    "finally , we derive a sublinear estimate for primal suboptimality of the last iterate @xmath118 . combining , and",
    "we obtain : @xmath165 where in the second inequality we used the definition of the finite constants @xmath152 and @xmath163 . in conclusion ,",
    "we have obtained sublinear estimates of order @xmath166 for primal infeasibility ( inequality ) and primal suboptimality ( inequality ) for the last primal iterate sequence @xmath167 generated by algorithm  * ( dg)*. now , it is straightforward to see that if we want to get an @xmath53-primal solution in @xmath118 we need to perform @xmath168 iterations .      in this section",
    "we derive sublinear convergence estimates for primal infeasibility and primal suboptimality for the average primal sequence @xmath169 defined in .",
    "[ th_dgav ] let assumption [ as_strong ] hold and the sequences @xmath158 be generated by algorithm * ( dg)*. then , for a given accuracy @xmath159 we get an @xmath53-primal solution for in the average primal sequence @xmath170 of algorithm * ( dg ) * after @xmath171 iterations .    our proof follows similar lines as in ( * ? ? ?",
    "* proposition 1 ) given for the dual subgradient method .",
    "however , in our case , by taking into account that the dual is smooth and the nice properties of gradient method ( see lemma [ lemma1_dg ] ) and of the projection on cones , we get better convergence estimates than in @xcite .",
    "first , given the definition of @xmath172 in algorithm * ( dg ) * we get : @xmath173_{\\mathcal{k}^ * } = x^{j+1 } \\quad \\forall j \\geq 0.\\ ] ] subtracting @xmath174 from both sides , adding up the above inequality for @xmath175 to @xmath176 , we get : @xmath177_{\\mathcal{k}^ * } - x^j\\right\\| = { \\lvertx^{k+1 } - x^0\\rvert}.\\end{aligned}\\ ] ] denoting @xmath178_{\\mathcal{k}^ * } \\!\\!-   ( x^j \\!+\\ !",
    "\\alpha_j \\nabla d(x^j ) ) \\right ) \\!\\!\\overset{\\eqref{prop_proj}}{\\in}\\!\\ ! { \\mathcal{k}}$ ] and",
    "dividing by @xmath179 we get : @xmath180 since @xmath181 , then also @xmath182 . moreover , from the definition of @xmath170 and the relation @xmath183 , we obtain @xmath184 . using the definition of the distance and the previous facts we obtain : @xmath185    it remains to bound @xmath186 . using the inequality",
    "we get : @xmath187 using this bound in and the fact that @xmath188 , we get the following estimate on feasibility violation : @xmath189    in order to derive estimates for primal suboptimality we use the definition of dual cone @xmath49 and that @xmath190 , which imply : @xmath191_{{\\mathcal{k } } } - ( g \\hat u^k + g ) \\rangle \\\\ & \\leq f(\\hat u^k ) + { \\lvertx^*\\rvert } \\text{dist}_{\\mathcal{k}}(g\\hat{u}^k + g )   \\overset{\\eqref{subl_2}}{\\leq } f(\\hat u^k ) +   \\frac{2 l_g \\mathcal{r}_\\text{d}}{k+1 }   \\|x^*\\|.\\end{aligned}\\ ] ] using the definition of @xmath192 and the previous inequality we get : @xmath193 on the other hand , from we have : @xmath194 adding up these inequalities for @xmath195 to @xmath196 we obtain : @xmath197 using the definition of @xmath170 and the convexity of @xmath26 we get : @xmath198 combining and we obtain the following bounds on primal suboptimality : @xmath199 in conclusion , we have obtained sublinear estimates of order @xmath200 for primal infeasibility ( inequality ) and primal suboptimality ( inequality ) for the average primal sequence @xmath201 generated by algorithm  * ( dg)*. now , if we want to get an @xmath53-primal solution in @xmath170 we need to perform @xmath171 iterations",
    ".    we can also characterize the distance from @xmath170 to the unique primal solution @xmath56 of problem .",
    "indeed , taking @xmath202 and @xmath203 in and using that @xmath77 , we have : @xmath204 therefore , we obtain : @xmath205.\\end{aligned}\\ ] ] using now and , we get : @xmath206.\\ ] ]    note that if we assume constant step size @xmath207 , then @xmath208 .",
    "thus , this choice for the step size provides us the best convergence estimates .",
    "further , the iteration complexity estimates of order @xmath166 in the last primal iterate sequence @xmath118 ( see section [ sublinear_first ] ) are inferior to those estimates of order @xmath200 corresponding to an average of primal iterates @xmath170 ( see this section ) .",
    "however , in section [ extensions ] we show that for the particular case of linearly constrained convex problems the convergence estimates for both sequences , the last iterate and an average of iterates , have the same order .",
    "in this section we consider a variant of algorithm * ( dfo ) * , where the step size @xmath119 is chosen constant , i.e. @xmath209 for all @xmath125 and @xmath120 is updated iteratively as shown below . in this case we obtain the following dual fast gradient algorithm , which is an extension of nesterov s optimal gradient method @xcite ( see @xcite ) :    where we recall that @xmath121 and @xmath210 .",
    "since @xmath26 is strongly convex , the lagrangian @xmath211 is also strongly convex for any fixed @xmath212 .",
    "therefore , the minimizer of for any fixed @xmath212 is unique and from danskin s theorem @xcite we get that the dual function @xmath42 is differentiable everywhere and thus @xmath213 is well defined even for @xmath214 .",
    "it can be easily seen that @xmath215 and the step size sequence @xmath120 satisfies : @xmath216 .",
    "therefore , we obtain the following bound : @xmath217 rearranging the terms in the step size update @xmath218 , we have the relation : @xmath219 . summing on the history and defining @xmath220",
    ", we also obtain : @xmath221    denoting @xmath222 and @xmath223 , we now state the following auxiliary result ( for a similar result corresponding to another formulation of algorithm * ( dfg ) * see @xcite ) .",
    "[ corr2 ] let assumption [ as_strong ] hold and the sequences @xmath224 be generated by algorithm * ( dfg ) * , then for any lagrange multiplier @xmath225 and @xmath125 we have the following relation : @xmath226    from the lipschitz gradient relation and the strong convexity property of the corresponding quadratic approximation of , we have : @xmath227 taking now @xmath68 , then @xmath228 and we have : @xmath229 where in the last inequality we used concavity of @xmath42 .",
    "subtracting now @xmath36 and multiplying with @xmath230 both hand sides , we obtain : @xmath231 further , note that the choice @xmath232 in algorithm * ( dfg ) * implies that @xmath233 . on the other hand , using the iteration of algorithm * ( dfg ) * we have @xmath234 .",
    "then , summing on the history , we obtain our result .",
    "the sublinear convergence rate of algorithm * ( dfg ) * in terms of dual suboptimality is given in the next lemma .",
    "@xcite [ th_sublin_dfg ] let assumption [ as_strong ] hold and the sequences @xmath235 be generated by algorithm * ( dfg)*. then , a sublinear estimate on dual suboptimality for dual problem is given by ( recall that @xmath236 ) : @xmath237    our iteration complexity analysis for algorithm * ( dfg ) * is based on two types of approximate primal solutions : the last primal iterate sequence @xmath238 defined as @xmath239 or an average primal sequence @xmath201 of the form @xmath240      in this section we derive sublinear convergence estimates for primal infeasibility and suboptimality for the last primal iterate sequence @xmath238 as defined in of algorithm  * ( dfg)*.    [ th_dfglast ] let assumption [ as_strong ] hold and the sequences @xmath241 be generated by algorithm * ( dfg)*. then , for a given accuracy @xmath159 we get an @xmath53-primal solution for in the last primal iterate @xmath242 of algorithm * ( dfg ) * after @xmath243 iterations .",
    "let us notice that @xmath242 ( see ) .",
    "firstly , combining and we obtain the following important relation characterizing the distance from the last iterate @xmath244 to the unique optimal solution @xmath56 of our original problem : @xmath245 secondly , combining the previous relation and we obtain a sublinear estimate for feasibility violation of the last iterate @xmath244 for algorithm * ( dfg ) * : @xmath246 where we again used @xmath163 .",
    "finally , we derive a sublinear estimate for primal suboptimality of the last iterate @xmath244 .",
    "we first prove that @xmath247 . indeed ,",
    "taking @xmath202 in theorem [ corr2 ] and using that the terms @xmath248 and @xmath249 are positive we have : @xmath250 using the triangle inequality and dividing by @xmath218 , we further have : @xmath251 using an inductive argument , we can conclude that : @xmath252 combining with relations and and using the definition of @xmath192 we obtain : @xmath253 in conclusion , we have obtained sublinear estimates of order @xmath200 for primal infeasibility ( inequality ) and primal suboptimality ( inequality ) for the last primal iterate sequence @xmath238 generated by algorithm * ( dfg)*. now , if we want to get an @xmath53-primal solution in @xmath244 we need to perform @xmath243 iterations .    in @xcite estimates of order @xmath200 have been given for primal infeasibility and suboptimality for the last primal iterate @xmath244 generated by algorithm *",
    "( dfg)*. however , those derivations are based on the assumption of lipschitz continuity of the objective function @xmath26 , while in our derivations we do not need to impose this additional condition , since our proofs make use explicitly of the properties of the algorithm as given in theorem [ corr2 ] and the inequality .",
    "note that for some applications the assumption of lipschitz continuity of objective function @xmath26 may be conservative : e.g. quadratic objective function @xmath26 and unbounded set @xmath25 .",
    "finally , we consider the application of dual fast gradient algorithm ( * dfg * ) for the regularization of the dual problem of , i.e. : @xmath254 note that regularization strategies have been also used in other papers , e.g. in order to make the norm of the gradient of some objective function small by using first order methods @xcite .",
    "we show in the sequel that by regularization we can improve substantially the convergence rate of dual fast gradient method in the last iterate . denoting @xmath255 the optimal solution of ,",
    "its optimality conditions are given by : @xmath256 note that the regularized dual objective function @xmath257 in is strongly concave with @xmath258 and has lipschitz gradient with @xmath259 .",
    "then , if we replace in step 3 of algorithm ( * dfg * ) the term @xmath260 with the constant term @xmath261 , i.e. : @xmath262 the modified dual fast gradient algorithm achieves linear convergence @xcite .",
    "more precisely , for solving the regularized dual problem with the modified algorithm ( * dfg * ) described above we have the convergence rate : @xmath263    we want to find first an upper bound on @xmath264 in terms of @xmath265 . since @xmath257 is @xmath266-strongly concave function and @xmath267",
    ", we have : @xmath268 based on the previous inequality we can bound @xmath269 as follows : @xmath270    thus , the number of iterations @xmath1 we need in order to attain @xmath271 accuracy , i.e. @xmath272 , is given by : @xmath273 since @xmath274 and @xmath275 , we get that after the number of iterations we have from @xmath272 that : @xmath276 let us assume for simplicity that @xmath277 and choose : @xmath278 then , we get an estimate on dual suboptimality for the dual problem of : @xmath279    we are now ready to prove one the main results of this paper :    [ th_dfglast_cone ] let assumption [ as_strong ] hold and the sequences @xmath241 be generated by the modified algorithm * ( dfg)*. then , for a given accuracy @xmath159 we get an @xmath53-primal solution for in the last primal iterate @xmath280 of modified algorithm * ( dfg ) * after @xmath281 iterations .",
    "first , we determine a bound on @xmath282 .",
    "since @xmath257 is @xmath266-strongly concave function and @xmath283 , we have : @xmath284 moreover , since the dual gradient @xmath285 is lipschitz , it satisfies @xcite : @xmath286_{\\mathcal{k}^ * } \\right ) \\geq d_\\delta ( x^k ) + \\frac{l_{d,\\delta}}{2 } \\|\\nabla^+ d_\\delta ( x^k)\\|^2.\\ ] ] using that @xmath283 in the previous inequality we obtain : @xmath287 now using the previous bound on @xmath288 , the fact that @xmath242 and the expressions of @xmath289 and @xmath290 we get an estimate on primal infeasibility in the last primal iterate @xmath244 : @xmath291_{{\\mathcal{k}}}\\| \\\\ & \\le d_{{\\mathcal{k}}}(- \\nabla d_\\delta ( x^k ) ) + \\delta \\|x^k - x^0\\| \\overset{\\eqref{decrease_ggm}}{\\le } l_{\\text{d},\\delta } \\| \\nabla^+ d_\\delta ( x^k)\\| + \\delta \\|x^k - x^0\\| \\\\ & \\leq \\sqrt{2 l_{d,\\delta}^3 } \\epsilon + \\delta ( \\|x^k - x^*_\\delta\\| + \\|x^0 - x^*_\\delta\\| ) \\overset{\\eqref{bound_delta_cone}}{\\leq } \\sqrt{2 l_{d,\\delta}^3 } \\epsilon + \\epsilon \\sqrt{2 \\delta } + 2 \\delta   r_\\text{d } \\\\ & \\overset{\\eqref{delta_cone}}{\\leq } 4\\epsilon \\left(\\sqrt{l_\\text{d}^3 } + \\frac{1}{\\mathcal{r}_{\\text{d } } } \\right).\\end{aligned}\\ ] ]    in order to derive a convergence estimate on primal suboptimality , we observe that for any @xmath225 , the optimality conditions of the inner subproblem are given by : @xmath292 since @xmath293 is concave and has lipschitz continuous gradient , it satisfies @xcite : @xmath294 taking into account the expression for @xmath285 , using @xmath295 in the previous inequality and the optimality conditions for @xmath296 , we have : @xmath297    on the other hand , using the strong convexity of the function @xmath26 and taking @xmath298 in , we obtain : @xmath299 adding in both sides the term @xmath300 , we get : @xmath301 taking @xmath143 in , using , lipschitz gradient property of @xmath302,the fact that @xmath303 , the cauchy - schwartz inequality and previous inequality , we obtain : @xmath304 on the other hand , we have : @xmath305_{{\\mathcal{k } } } - ( g u(x ) + g ) \\rangle \\nonumber\\\\ & \\leq f(u(x ) ) + { \\lvertx^*\\rvert } \\text{dist}_{\\mathcal{k}}(g u(x ) + g).\\end{aligned}\\ ] ]    therefore , using and the facts that @xmath306 and @xmath307 , we derive the convergence rate for primal suboptimality from the previous estimates on suboptimality and infeasibility : @xmath308 where @xmath309 .",
    "now , if we replace the expression for @xmath266 from in the expression of @xmath1 from it follows that we obtain @xmath53-accuracy for primal suboptimality and infeasibility in the last primal iterate @xmath244 for the modified algorithm ( * dfg * ) after @xmath281 iterations .",
    "from theorem [ th_dfglast_cone ] it follows that we obtain @xmath53-accuracy for primal suboptimality and infeasibility for the modified algorithm ( * dfg * ) in the last primal iterate @xmath280 after @xmath281 iterations which is better than @xmath310 iterations obtained in theorem [ th_dfglast ] for the last primal iterate @xmath244 or in @xcite . from our knowledge theorem [ th_dfglast_cone ] provides the best convergence rate for dual fast gradient method in the last iterate .",
    "however , the modified algorithm needs to know the parameter @xmath266 , that according to , is depending on @xmath265 . in practice , we need to know an estimate of @xmath265 .      in this section",
    "we derive sublinear estimates for primal infeasibility and suboptimality of the average primal sequence @xmath311 as defined in for algorithm * ( dfg)*.    [ th_dfgav ] let assumption [ as_strong ] hold and the sequences @xmath241 be generated by algorithm * ( dfg)*. then , for a given accuracy @xmath159 we get an @xmath53-primal solution for in the average primal iterate @xmath170 of algorithm * ( dfg ) * after @xmath312 iterations .",
    "for any @xmath313 we have @xmath314_{\\mathcal{k}^ * } = x^{j}.$ ] let us denote @xmath315 .",
    "then , we can write as follows : @xmath316_{\\mathcal{k}^ * } - z^j + \\frac{1}{l_{\\text{d}}}\\nabla",
    "d(y^j ) \\right ) = \\theta_j \\left(\\left [ y^{j } + \\frac{1}{l_{\\text{d}}}\\nabla d(y^{j } ) \\right]_{\\mathcal{k}^ * } - y^{j } \\right ) \\nonumber\\\\ & =   \\theta_{j } ( x^{j } - y^{j } )   = \\theta_{j}(x^{j } - x^{j-1 } ) + ( \\theta_{j-1 } -1)(x^{j-2 } - x^{j-1})\\nonumber\\\\ & = \\underbrace{x^{j-1 } + \\theta_{j}(x^{j}-x^{j-1})}_{w^{j } } - \\underbrace{(x^{j-2 } + \\theta_{j-1}(x^{j-1}-x^{j-2}))}_{w^{j-1}}.\\end{aligned}\\ ] ]    note that @xmath317 .",
    "further , summing on the history , multiplying by @xmath318 the previous relation and using the definition of @xmath170 , we obtain : @xmath319_{\\mathcal{k}^ * } - z^j ) + \\sum\\limits_{j=0}^k   \\frac{\\theta_j}{s_k^\\theta }   \\nabla d(y^j ) \\\\ & = l_{\\text{d}}\\sum\\limits_{j=0}^k   \\frac{\\theta_j}{s_k^\\theta}([z^j]_{\\mathcal{k}^ * } - z^j ) - ( g \\hat u^k + g).\\end{aligned}\\ ] ] since @xmath320_{\\mathcal{k^ * } } - z^j \\in \\mathcal{k}$ ] ( according to ) , we have @xmath321_{\\mathcal{k}^ * } - z^j ) \\in { \\mathcal{k}}$ ] .",
    "in conclusion , using the definition of the distance , we obtain : @xmath322_{\\mathcal{k}^ * } - z^j ) - ( g \\hat u^k + g )   \\right\\| \\\\ & = \\frac{l_\\text{d}}{s_k^\\theta}{\\lvertw^{k}-w^0\\rvert } \\le \\frac{4l_\\text{d}}{(k+1)^2 } { \\lvertw^k -w^{0}\\rvert}.\\end{aligned}\\ ] ]    taking @xmath323 in and using that the two terms @xmath248 and @xmath324 are positive , we get @xmath325 for all @xmath125 . moreover , we have @xmath326 .",
    "thus , we can further bound the primal infeasibility as follows : @xmath327    further , we derive sublinear estimates for primal suboptimality .",
    "first , note that : @xmath328 summing on the history and using the convexity of @xmath329 , we get : @xmath330 using in , and dropping the term @xmath331 , we have : @xmath332    taking @xmath333 in the previous inequality , we get : @xmath334 taking in account that @xmath335 , then we have : @xmath336    on the other hand , we have : @xmath337 from and we obtain an estimate on primal suboptimality : @xmath338.\\ ] ]    thus , we have obtained sublinear estimates of order @xmath339 for primal infeasibility ( inequality ) and primal suboptimality ( inequality ) for the average primal sequence @xmath340 generated by algorithm * ( dfg)*. now , if we want to get an @xmath53-primal solution in @xmath341 we need to perform @xmath312 iterations .",
    "based on , we can also characterize the distance from @xmath170 to the unique primal optimal solution @xmath56 . using and , we get : @xmath342.\\ ] ]    in theorem [ th_dfglast_cone ] we obtained an @xmath53-primal solution for the modified algorithm ( * dfg * ) in the last primal iterate @xmath280 after @xmath281 iterations , which is of the same order ( up to a logarithmic term ) as for the primal average sequence @xmath170 from previous theorem [ th_dfgav ] .",
    "moreover , the reader should also notice that all our previous convergence estimates depend only on three constants : the lipschitz constant @xmath99 , the initial starting dual point @xmath343 and its distance to the dual optimal set denoted @xmath192 .",
    "moreover , if @xmath344 , then @xmath345 , i.e. the function values in the primal average sequences are always below the optimal value for algorithms * ( dg ) * and * ( dfg)*.",
    "in this section , we show that if the dual problem has an error bound type property we can get an @xmath53-primal solution for problem with the previous dual first order methods in @xmath346 iterations .",
    "thus , in this section we assume that the dual problem of has an error bound property .",
    "more precisely , we assume that for any @xmath347 there exists a constant @xmath348 depending on @xmath349 and the data of problem such that the following error bound property holds for the corresponding dual problem of : @xmath350 where @xmath351_{x^*}$ ] ( i.e. the euclidean projection of @xmath93 onto the optimal dual set @xmath352 ) and recall that @xmath92 denotes the gradient map : @xmath353_{+ } - x$ ] .",
    "for example , if we consider a linearly constrained convex problem ( @xmath354 ) : @xmath355 where we assume that @xmath26 is @xmath356-strongly convex function and has @xmath357-lipschitz continuous gradient , @xmath358 and @xmath359 , then in @xcite it has been proved that the corresponding dual problem satisfies an error bound type property . indeed , for the convex function @xmath26 , we denote its conjugate by @xcite : @xmath360 . according to proposition 12.60 in @xcite , under the previous assumptions , function @xmath361 is strongly convex w.r.t .",
    "euclidean norm , with constant @xmath362 and has lipschitz continuous gradient with constant @xmath363 .",
    "note that in these settings our dual function of can be written as : @xmath364 .",
    "since @xmath26 is strongly convex , the dual gradient @xmath365 is lipschitz continuous with constant @xmath50 @xcite . furthermore",
    ", if @xmath366 has full row rank , then it follows immediately that the dual function @xmath42 is strongly convex .",
    "therefore , we consider the nontrivial case when @xmath366 is rank deficient . in @xcite",
    "it has been proved that for convex problem with function @xmath26 being @xmath367-strongly convex and having @xmath357-lipschitz gradient and @xmath358 , for any @xmath347 there exists a constant @xmath348 depending on @xmath349 and the data of problem such that an error bound property of the form holds for the corresponding dual problem .",
    "next , we derive a strong convex like inequality that will be used in the sequel .    under assumption and the error bound property for the corresponding dual of convex problem",
    "the following inequality holds : @xmath368    let us define @xmath369_{{\\mathcal{k}}^*}$ ] so that @xmath370 . note that @xmath94 is the optimal solution of the following convex problem : @xmath371 from and the optimality conditions of we get the following increase in terms of the objective function @xmath42 : @xmath372 combining and we obtain : @xmath373 which shows the statement of the theorem .",
    "firstly , we consider algorithm ( * dg * ) ) . for simplicity , we assume constant step size @xmath209",
    ". since algorithm ( * dg * ) is an ascent method according to , we can take @xmath374 .",
    "thus , the error bound property holds for the sequence @xmath375 generated by algorithm ( * dg * ) , i.e. there exists @xmath348 such that : @xmath376 where @xmath377_{x^*}$ ] .",
    "the following theorem provides an estimate on the dual suboptimality for algorithm ( * dg * ) with constant step size .",
    "[ theorem_dual_optim_dg ] under assumption and the error bound property for the corresponding dual of problem , the sequence @xmath130 generated by algorithm ( * dg * ) converges linearly in terms of the distance to the dual optimal set @xmath352 and of the dual objective function values : @xmath378    from and concavity of @xmath42 , we get : @xmath379 taking now in the previous relations @xmath380 and using @xmath381 and the strong convex like inequality , we get : @xmath382 or equivalently @xmath383 thus , we obtain linear convergence rate in terms of distance to the optimal set @xmath352 : @xmath384    we can also derive linear convergence in terms of dual function values : @xmath385    note that our proof from theorem [ theorem_dual_optim_dg ] is different from tseng s proof @xcite for linear convergence of gradient method under an error bound property .",
    "more precisely , in our proof we make use explicitly of the strong convex like inequality which allows us to get for @xmath386 better convergence rate than in @xcite .",
    "we now derive linear estimates for primal infeasibility and primal suboptimality for the last iterate sequence @xmath156 generated by our algorithm ( * dg * ) with constant step size @xmath209 . for simplicity of the exposition",
    "let us denote : @xmath387 clearly , @xmath388 . from theorem",
    "we obtain : @xmath389    [ th_urndglast ] under the assumptions of theorem [ theorem_dual_optim_dg ] , let the sequences @xmath390 be generated by algorithm * ( dg)*. then , for a given accuracy @xmath159 we get an @xmath53-primal solution for in the last primal iterate @xmath391 of algorithm * ( dg ) * after @xmath392 iterations .    combining and we obtain the following relation : @xmath393    then , combining the previous relation and we obtain a linear estimate for feasibility violation of the last iterate @xmath118 : @xmath394 where we used the definitions of @xmath395 and @xmath396 .",
    "finally , we derive linear estimates for primal suboptimality of the last iterate @xmath118 . combining and",
    "we obtain : @xmath397 in conclusion , we have obtained linear estimates of order @xmath6 , with @xmath7 , for primal infeasibility ( inequality ) and suboptimality ( inequality ) for the last iterate sequence @xmath156 generated by algorithm * ( dg)*. now , if we want to get an @xmath53-primal solution in @xmath391 we need to perform @xmath392 iterations .    secondly , we show that under assumption and the error bound property for the corresponding dual of problem , a restarting version of algorithm * ( dfg ) * has linear convergence . similar to algorithm ( * dg * ) , we can also take in this case @xmath398 and thus the error bound property holds for the sequence @xmath399 generated by a restarting version of algorithm ( * dfg * ) . indeed , combining and we get : @xmath400 where we choose a positive constant @xmath401 such",
    "that @xmath402 then , for fixed @xmath403 , the number of iterations @xmath404 that we need to perform in order to obtain @xmath405 is given by : @xmath406 note that if the optimal value @xmath407 is known in advance , then we just need to restart algorithm * ( r - dfg ) * at iteration @xmath408 when the following condition holds : @xmath409 which can be practically verified .",
    "after each @xmath404 steps of algorithm * ( dfg ) * we restart it obtaining the following scheme :    then , after @xmath410 restarts of algorithm * ( r - dfg ) * we obtain linear convergence in terms of dual suboptimality :    [ th_ebdualsuboptdfg ] under assumption and the error bound property for the corresponding dual of problem , the sequence @xmath411 generated by algorithm ( * r - dfg * ) converges linearly in terms of the dual objective function values , i.e. : @xmath412    after @xmath410 restarts of algorithm * ( r - dfg ) * we have : @xmath413 thus , the total number of iterations is @xmath414 . since @xmath415 it follows that @xmath416 is the gradient step from @xmath417 and thus @xmath418",
    "therefore , we may assume for simplicity that @xmath419 .",
    "for @xmath420 we have : @xmath421 provided that we perform @xmath422 number of iterations .",
    "next theorem shows linear convergence in terms of primal suboptimality and infeasibility of the last primal iterate @xmath244 generated by algorithm * ( r - dfg)*.    [ th_urndfglast ] under the assumptions of theorem [ th_ebdualsuboptdfg ] , we get an @xmath53-primal solution for in the last primal iterate @xmath423 of algorithm * ( r - dfg ) * after @xmath424 iterations .    combining and we obtain the following relation : @xmath425    then , combining the previous relation and we obtain a linear estimate for feasibility violation of the last iterate @xmath244 : @xmath426 where we used the definition of @xmath395 .",
    "finally , we derive linear estimates for primal suboptimality of the last iterate @xmath118 . combining with we get : @xmath427 in conclusion",
    ", we get an @xmath53-primal solution in the last primal iterate @xmath280 provided that we perform @xmath428 iterations of algorithm * ( r - dfg)*.    from our knowledge , the results stated in theorems [ th_ebdualsuboptdfg ] and [ th_urndfglast ] answer for the first time to a question posed by tseng @xcite related to whether there exist fast gradient schemes that converge linearly on convex problems having an error bound property .",
    "in this section we prove that for linearly constrained convex problems ( @xmath429 ) we can get better iteration complexity estimates for dual first order methods corresponding to the last primal iterate sequence .",
    "more precisely , we prove that we can improve substantially the convergence rate of dual first order methods ( * dg * ) and ( * dfg * ) ) in the last iterate when the optimization problem has linear equality constraints : i.e. @xmath430 instead of @xmath431 . therefore ,",
    "in this section we consider a particular case for the optimization problem , namely a linearly constrained convex optimization problem of the form : @xmath432 for we still require assumption to hold : i.e. @xmath26 is @xmath356-strongly convex function , @xmath25 a simple convex set and there exists a finite optimal lagrange multiplier @xmath32",
    ". since @xmath26 is strongly convex and @xmath429 , the dual gradient @xmath365 is lipschitz continuous with constant @xmath433 ( see e.g. @xcite ) .",
    "we analyze below the convergence behavior of dual first order methods for solving the linearly constrained convex problem . note that since we have linear constraints in , i.e. @xmath434 , the corresponding dual problem is unconstrained , i.e. @xmath435 .    * case 1 * : we first consider applying @xmath436 steps of algorithm ( * dg * ) . for simplicity ,",
    "let us assume constant step size @xmath437 for solving the corresponding dual of problem .",
    "[ th_lingdglast ] for problem let @xmath26 be @xmath356-strongly convex function , @xmath25 be simple convex set and the set of optimal multipliers @xmath352 be nonempty .",
    "further , let the sequences @xmath158 be generated by algorithm * ( dg ) * with @xmath438 .",
    "then , for a given accuracy @xmath159 we get an @xmath53-primal solution for in the last primal iterate @xmath439 of algorithm * ( dg ) * after @xmath440 iterations .",
    "we have proved in that gradient algorithm is an ascent method , i.e. : @xmath441    adding for @xmath196 to @xmath442 and using that the gradient map sequence is decreasing along the iterations of algorithm * ( dg ) * ( see lemma [ lemma2_dg ] ) , we get : @xmath443 since @xmath444 , we obtain : @xmath445 from @xmath446 we obtain a sublinear estimate for feasibility violation of the last primal iterate @xmath447 of algorithm ( * dg * ) : @xmath448    we can also characterize primal suboptimality in the last iterate @xmath449 for algorithm ( * dg * ) using that @xmath450 , the estimate on infeasibility and the inequalities  : @xmath451    therefore , we have obtained sublinear estimates of order @xmath200 for primal infeasibility ( inequality ) and primal suboptimality ( inequality ) for the last primal iterate sequence @xmath452 generated by algorithm  * ( dg)*. now , it is straightforward to see that if we want to get an @xmath53-primal solution in @xmath439 we need to perform @xmath440 iterations .",
    "in conclusion , from theorem [ th_lingdglast ] it follows that we obtain @xmath53-accuracy for primal suboptimality and infeasibility for algorithm ( * dg * ) in the last primal iterate @xmath391 after @xmath453 iterations .",
    "this is better than @xmath454 iterations obtained in theorem [ th_dglast ] for the last primal iterate @xmath118 and it is of the same order as for the primal average sequence @xmath170 from theorem [ th_dgav ] .",
    "however , this better result is obtained for the particular linearly constrained convex problem .",
    "note that an immediate consequence of lemma [ lemma2_dg ] for this case @xmath455 is that the sequence @xmath456 is decreasing , i.e. : @xmath457    * case 2 * : we now consider an hybrid algorithm that applies @xmath1 steps of algorithm ( * dfg * ) and then @xmath1 steps of algorithm ( * dg * ) for solving the corresponding dual of problem .    [ th_linghdfgdglast ] under the assumptions of theorem [ th_lingdglast ]",
    "let the sequences @xmath458 be generated by applying @xmath1 steps of algorithm ( * dfg * ) and then @xmath1 steps of algorithm ( * dg * ) with @xmath438 .",
    "then , for a given accuracy @xmath159 we get an @xmath53-primal solution for in the last primal iterate @xmath439 of this algorithm after @xmath459 iterations .    since the gradient algorithm is an ascent method ( see ) , we have : @xmath460    adding for @xmath196 to @xmath442 and using the decrease of the gradient map , we get : @xmath461    since @xmath444",
    ", we obtain : @xmath462 . from @xmath463",
    "we obtain a sublinear estimate for feasibility violation of the last primal iterate @xmath447 of this hybrid algorithm : @xmath464    we can also characterize primal suboptimality in the last iterate @xmath449 for this hybrid algorithm using that @xmath450 , the estimate and the inequalities  :",
    "@xmath465    therefore , we have obtained sublinear estimates of order @xmath466 for primal infeasibility ( inequality ) and primal suboptimality ( inequality ) for the last primal iterate sequence @xmath156 generated by an algorithm applying @xmath1 steps of * ( dfg ) * and then @xmath1 steps of * ( dg)*. now , it is straightforward to see that if we want to get an @xmath53-primal solution in @xmath439 we need to perform @xmath459 iterations .    for the linear constrained problem in @xcite convergence rate @xmath200",
    "was derived for the last primal iterate of algorithm * ( dfg ) * ( see also our theorem [ th_dfglast ] that gives the same convergence rate for conic problems ) .",
    "however , theorem [ th_linghdfgdglast ] shows that applying further @xmath1 gradient steps we can improve the convergence rate to @xmath466 for problem .    in conclusion",
    ", in this paper we obtained the following estimates for the convergence rate of dual first order methods :    * in a primal average sequence we have @xmath310 for algorithm ( * dg * ) and @xmath467 for algorithm ( * dfg * ) * in the last iterate they are are summarized in table 1 .",
    "dfg & dg & r - dfg & @xmath436-dg & hybrid dfg - dg + [ 1ex]prob . & & & & @xmath468 & @xmath468 & & + [ 1ex]rates & @xmath454 & @xmath310 & @xmath469 & @xmath470 & @xmath471 & @xmath310 & @xmath472 + [ 1ex ]",
    "in this section we prove that some of the results of the previous section can be extended to conic convex problem .",
    "more precisely , we prove that we can improve substantially the convergence estimates for primal infeasibility and left hand side suboptimality of dual first order methods in the last iterate for the general problem .",
    "* case 1 * : we first consider applying @xmath436 steps of algorithm ( * dg * ) . for simplicity ,",
    "let us assume constant step size @xmath438 for solving the corresponding dual of problem .",
    "indeed , we have proved in that gradient algorithm is an ascent method , i.e. : @xmath473    adding for @xmath196 to @xmath442 and using that the gradient map sequence is decreasing along the iterations of algorithm * ( dg ) * ( see lemma [ lemma2_dg ] ) , we get : @xmath474 since @xmath444 , we obtain : @xmath475 from @xmath476 we obtain a sublinear estimate for feasibility violation of the last primal iterate @xmath447 of algorithm ( * dg * ) : @xmath477    we can also characterize primal suboptimality in the last iterate @xmath449 for algorithm ( * dg * ) . on one hand ,",
    "using the estimate on infeasibility and the definition of the dual cone @xmath49 , we have : @xmath478_{{\\mathcal{k } } } - ( g u^{2k } + g ) \\rangle \\nonumber\\\\ & \\leq f(u^{2k } ) + { \\lvertx^*\\rvert } \\text{dist}_{\\mathcal{k}}(g u^{2k } + g )   \\overset{\\eqref{conegps_left}}{\\leq } f(u^{2k } ) + \\frac{3 l_{\\text{d } } \\mathcal{r}_\\text{d}}{k } ( \\mathcal{r}_\\text{d } + \\|x^0\\|).\\end{aligned}\\ ] ] on the other hand , using , we have @xmath479 therefore , we have obtained sublinear estimates of order @xmath200 for primal infeasibility ( inequality ) and left hand side suboptimality ( inequality ) and of order @xmath166 for right hand side primal suboptimality ( inequality ) for the last primal iterate sequence @xmath452 generated by algorithm  * ( dg)*.    * case 2 * : we now consider an hybrid algorithm that applies @xmath1 steps of algorithm ( * dfg * ) and then @xmath1 steps of algorithm ( * dg * ) for solving the corresponding dual of problem .",
    "since the gradient algorithm is an ascent method ( see ) , we have : @xmath480    adding for @xmath196 to @xmath442 and using the decrease of the gradient map , we get : @xmath481    since @xmath444 , we obtain : @xmath482 . from @xmath483",
    "we obtain a sublinear estimate for feasibility violation of the last primal iterate @xmath447 of this hybrid algorithm : @xmath484    we can also characterize primal suboptimality in the last iterate @xmath449 for this hybrid algorithm . using the estimate , a similar reasoning as in the relations leads to : @xmath485 on the other hand , from it can be derived : @xmath486 therefore , we have obtained sublinear estimates of order @xmath466 for primal infeasibility ( inequality ) and for left hand side primal suboptimality ( inequality ) and of order @xmath200 for right hand side primal suboptimality ( inequality ) for the last primal iterate sequence @xmath452 generated by algorithm  * ( dg)*.",
    "for numerical experiments we consider random problems of the following form :      where @xmath488 is positive definite matrix with @xmath489 , @xmath490 , @xmath491 and @xmath492 . we need to remark that the objective function is not convex for @xmath493 , but it is convex e.g. when @xmath494 on @xmath495 or when @xmath496 on @xmath8 .",
    "note that this type of problems arises in many practical applications : in network utility maximization @xcite @xmath497 ; in resource allocation problems @xcite @xmath498 ; in optimal power flow or model predictive control @xcite ( @xmath499 ) .",
    "all the data of the problem are generated randomly and @xmath366 is sparse having tens of nonzeros ( @xmath500 ) on each row for large problems ( @xmath501 ) .",
    "we have considered the accuracy @xmath502 , the value for @xmath503 and the stopping criteria in the tables below were chosen as follows : @xmath504_+\\| \\leq \\epsilon,\\ ] ] where @xmath505 is either the last primal iterate ( @xmath506 ) or average of primal iterates  ( @xmath507 ) and we allow at most @xmath508 number of iterations for each algorithm .      in the first set of experiments we choose @xmath509 and simple constraints @xmath510 (",
    "e.g. network utility maximization problems @xcite can be recast in this form ) . in this type of applications the complicating constraints @xmath511",
    "are related to the capacity of the links and we need to also impose simple constraints @xmath510 , since @xmath12 represents the source rates .",
    "note that the objective function is strongly convex and with lipschitz gradient on @xmath512 .",
    "however , the presence of simple constraints @xmath510 makes the dual function degenerate ( i.e. @xmath42 does not satisfy an error bound property ) .    typically , the performance in terms of primal suboptimality and infeasibility of algorithms * ( dg ) * and * ( dfg ) * in the primal last iterate or in the average of primal iterates is oscillating as fig .",
    "however , these algorithms have a smoother behavior in the average of iterates than in the last iterate .",
    "moreover , from our numerical experience we have observed that for our dual first order methods we usually have a better behavior in the last iterate than in the average of iterates as we can also see from fig . 1 and table 1 ( in the table we display the average number of iterations for @xmath513 random problems for each dimension @xmath514 ranging from @xmath513 to @xmath515 ) .",
    "on the other hand , our worst case convergence analysis says differently , i.e. we have obtained better theoretical estimates in the primal average sequence than in the last primal iterate sequence .",
    "this does not mean that our analysis is weak , since we can also construct problems which show the behavior predicted by our theory , see e.g. fig . 2 where indeed we have a better behavior in the average of iterates than in the last iterate .    finally , in fig",
    "3 we plot the practical number of iterations of algorithms * ( dg ) * and * ( dfg ) * for different test cases of the same dimension @xmath516 ( left ) and for different test cases of variable dimension ranging from @xmath517 to @xmath518 ( right ) . from this figure",
    "we observe that the number of iterations are not varying much for different test cases and also that the number of iterations are mildly dependent of problem s dimension .",
    "then , we also take @xmath499 and we solve the corresponding qp problems over an increasing dimension @xmath517 to @xmath519 . in fig .",
    "4 we compare for algorithm * ( dfg ) * the real number of iterates in the primal latest iterate and average of iterates and the estimated number of iterates @xmath520 for a primal suboptimality and infeasibility level of @xmath521 .",
    "we observe from fig .",
    "4 that our theoretical estimates are quite close to the practical ones for the dual fast gradient method .",
    "finally , we drop the simple box constraints ( i.e. now @xmath522 ) and for dimension @xmath523 we plot in fig .",
    "5 the behavior of algorithm * ( dg ) * in the last iterate along iterations , starting from @xmath344 . from our results ( see section [ sec_lin ] ) we have linear convergence , which is also seen in practice from this figure ( in logarithmic scale ) . in the same figure we also plot the theoretical sublinear estimates for the convergence rate of algorithm * ( dg ) * in the last iterate",
    "as given in section [ sublinear_first ] ( see and ) .",
    "the plot clearly confirms our theoretical findings , i.e. linear convergence of algorithm * ( dg ) * in the last iterate , provided that @xmath524 .",
    ": logarithmic scale of primal suboptimality .",
    "we also compare with the theoretical sublinear estimates ( dot lines ) for the convergence rate in the last iterate .",
    "the plot clearly shows our theoretical findings , i.e. linear convergence .",
    ", width=604,height=207 ]"
  ],
  "abstract_text": [
    "<S> in this paper we provide a detailed analysis of the iteration complexity of dual first order methods for solving conic convex problems . </S>",
    "<S> when it is difficult to project on the primal feasible set described by convex constraints , we use the lagrangian relaxation to handle the complicated constraints and then , we apply dual first order algorithms for solving the corresponding dual problem . we give convergence analysis for dual first order algorithms ( dual gradient and fast gradient algorithms ) : </S>",
    "<S> we provide sublinear or linear estimates on the primal suboptimality and feasibility violation of the generated approximate primal solutions . </S>",
    "<S> our analysis relies on the lipschitz property of the gradient of the dual function or an error bound property of the dual . </S>",
    "<S> furthermore , the iteration complexity analysis is based on two types of approximate primal solutions : the last primal iterate or an average primal sequence .    </S>",
    "<S> conic convex problem , smooth optimization , dual first order methods , approximate primal solutions , rate of convergence .    </S>",
    "<S> 90c25 ; 90c46 ; 49n15 ; 65k05 . </S>"
  ]
}