{
  "article_text": [
    "most design problems in engineering make an intensive use of numerical simulations of some physical process in order to predict the actual behavior of the target part .",
    "when the mathematical model supporting the numerical simulation involves partial differential equations , finite element methods ( fem ) are today one of the most widely used method by engineers to actually obtain an approximate numerical solution to their theoretical model .",
    "however , the computational cost of up - to - date numerical methods used in fem directly depends on the way the nodes of the underlying mesh ( i.e. the discretization ) are numbered . solving the mesh numbering problem ( mnp ) amounts to find the permutation of the order of the nodes that minimizes that computational cost .",
    "numerical engineers have developed a powerful heuristic technique ( the so - called _ gibb s method _ ) that gives reasonably good results , thus providing a clear reference to any a new mesh numbering algorithm .",
    "the goal of this paper is to use evolutionary algorithms ( eas ) to tackle the mnp .",
    "eas have been widely applied to other combinatorial optimization problems , among which the popular tsp @xcite . however , as far as we know , this is the first attempt to solve the mnp using eas .",
    "unfortunately , though both problem look for a solution in the space of permutations of @xmath0 $ ] , the specificity of the mnp might make inefficient the simple transposition of tsp techniques to the mnp .",
    "indeed , looking at the history of evolutionary tsp , it seems clear that the key of success is hybridization with problem - specific techniques : from the grefenstette s early incorporation of domain knowledge @xcite to the most recent works @xcite where evolutionary results can  at last  be compared to the best operational research results , even for large size tsp instances .",
    "so the path to follow here seems rather clear : design some nmp - specific operators , and compare their performances to either `` blind '' problem independent operators or tsp - specific operators .",
    "the paper is organized as follows : section [ fem ] recalls the basics of finite element methods , and precisely defines the objective function .",
    "the state - of - the - art ",
    "gibbs method is also briefly described .",
    "section [ ea ] presents the design of the particular evolutionary algorithm used thereafter , discussing in turn the representation issue , specific crossover and mutation operators , and the initialization procedure .",
    "this algorithm is then experimented in section [ results ] , with emphasis on the tuning of the probabilities of application of all operators at hand ( both problem - specific and problem independent ) .",
    "first , the crossover operators all rapidly appear harmful .",
    "second , surprising interactions between the selection scheme and the different mutation operators seem to indicate that , though at the moment domain knowledge did not increase the performances of the algorithm , there is still some room for improvement in that direction . finally , the usefulness of evolutionary mesh numbering with respect to gibbs method is discussed : the results are indeed better , but the cost is also several orders of magnitude greater .",
    "many models for physical , mechanical , chemical and biological phenomenon end up in partial differential equations ( pde ) where the unknown are functions defined on some domain @xmath1 of @xmath2 .",
    "a popular way to transform a system of pdes into a finite linear system is the finite element method ( fem ) @xcite .",
    "the domain @xmath1 is discretized into small _",
    "elements _ , who build up a _ mesh_. a typical mesh  on a non - typical domain  is given in figure [ test - mesh ] .",
    "the solution of the initial pdes is sought in spaces of functions that are polynomial on each element .",
    "such an approximate solution is completely determined by its values at some points of each element , called the _ nodes _ of the mesh .",
    "those values are computed by writing the original pdes locally on each element , resulting in a linear system of size the number of nodes times the number of _ degrees of freedom _ , or unknown values , at each node ) .",
    "usual sizes for such systems range from a few hundreds ( e.g. in two - dimensional structural mechanics ) to millions ( e.g. for three - dimensional problems in aerodynamics ) .    however , as a consequence of the local discretization , the equation at each node only involves values at a few neighboring nodes : the resulting matrix is hence very sparse . and",
    "specific methods exist for sparse system @xcite , whose complexity is proportional to the square of the _ bandwidth _ of the matrix , i.e. the average size of the _ profile _ of the matrix , given by the sum over all lines of the maximal distance to the diagonal of non - zero terms . for full matrices ,",
    "the bandwidth is @xmath3 while it is @xmath4 for tridiagonal matrices ( for @xmath5 matrices ) .",
    "cc      the contribution of each single line to the total bandwidth of the matrix is highly dependent on the order of the nodes of the mesh : the equation for node number @xmath6 only involves the neighboring nodes ; hence the only non - zero terms of the corresponding equation will appear in the matrix in the column equal to the number of the node in the mesh . depending on the order of the nodes in the mesh , the bandwidth can range from a few units to almost the size of the matrix .    [ cols=\"^,^ \" , ]      this section presents some results obtained on the _ medium _ and _ large _ meshes , using mutation operators only inside some @xmath7 evolution scheme . at first , the goal of these experiments was to sort out the usefulness of problem - specific knowledge , in the initialization procedure and in the mutations operators .",
    "bur it rapidly turned out that the population size also was a very important parameter .",
    "figure [ res - medium ] witnesses the surprising results obtained on the medium mesh : each dot indicates the best fitness reached after 1 million fitness evaluations of a single run of the evolutionary algorithm .",
    "the different shapes of the dots represent different settings of the relative mutation rates @xmath8 , @xmath9 and @xmath10 .",
    "figure [ res - medium]-a shows the runs that used the gibbs initialization procedure while figure [ res - medium]-b those who used the breadth - first initialization procedure . on each figure",
    ", the two distinct sets of points correspond to the @xmath11- and the @xmath12-es schemes , as indicated .",
    "note that all trials with larger population sizes were unsuccessful .",
    "some clear conclusions can be drawn from these results .",
    "first , the overall best results are obtained for the @xmath11-es scheme starting from the gibbs initialization and using the `` blind '' _ transposition mutation _ only ( figure [ res - medium]-a ) ( see section [ discussion ] for a detailed comparison with the results of gibbs method ) . but comparing the results between gibbs and breadth - first initialization procedures on the one hand , and @xmath11- and @xmath12-es schemes on the other hand gave some unexpected results :    * whereas the @xmath11-es scheme consistently outperformed the the @xmath12-es scheme when using gibbs initialization , the reverse is true for the breadth - first initialization ; * whereas different settings of the mutation rates gave rather different results for the gibbs runs , this does not seem to be so clear for the breadth - first runs ; * whatever the initialization , the @xmath12 results are more stable than the @xmath11 results with respect to mutation rates ; this is striking on the breadth - first plot , but also true on the other plot . *",
    "the worst results are obtained for the lowest values of @xmath8 ( the results with even lower values of @xmath8 are not presented here , but were very poor ) . however , domain specific mutation operators ( see the black circles and squares , compared to the `` + '' dots ) are more efficient with the @xmath12 scheme than with the @xmath11 scheme .",
    "this is specially visible on the gibbs runs .",
    "note that these tendancies were confirmed when the runs were allowed more fitness evaluations ( e.g. 10 millions , see forthcoming section [ discussion ] ) .",
    "some tentative explanations can however be proposed , after noticing that the @xmath11 scheme can be viewed more like a _ depth - first _ algorithm while the @xmath12 scheme searches in a more _ breadth - first _ manner .",
    "so , using gibbs initialization probably tights the population in a very limited area of the search space from which it is useless to try to escape : this favors the performance of depth - first search , as breadth oriented search does not have the possibility to jump to other promising regions .",
    "moreover , it seems that the transpositions of neighbor nodes in a depth - first search does not allow large enough moves to easily escape local optima , resulting in the best results for the pure random mutation for the @xmath11 .    on the other hand ,",
    "successive local moves have greater chances of survival in the @xmath12 breadth search , and give the best results in that case ( though some random mutation are still needed ) . and when it comes to a more widely spread population after the breadth - first initialization , the breadth - first search demonstrates better results by being able to use more efficiently in that case the domain neighboring information .",
    "+ this situation suggests further directions of research : first , the @xmath11-es scheme with pure random mutation resembles some sort of tabu search @xcite , and so might be greatly improved by adding some memory to it , either deterministically , like in standard tabu search , or stochastically , as proposed in @xcite .",
    "second , more than one neighbor transposition seems necessary to generate improvements .",
    "hence , the number of transpositions should not be forced to 1 , and can be made either self - adaptive , with the same problems than in the case of integer variables in evolution strategies @xcite , or exogenously adaptive , as proposed in @xcite where some hyperbolic decreasing law is used for the mutation rate along generations .",
    "but apart from optimizing the evolutionary algorithm itself on the mnp , a critical point is whether evolutionary mesh numbering can compete with the gibbs method .",
    "of course , if the gibbs initialization is used , as the original gibbs numbering is included in the initial population , any improvement is in fact giving a better result than the gibbs method . but",
    "how interesting is that improvement , especially when the computational cost is taken into account ?",
    "+ on the medium mesh ( 1545 nodes ) , the bandwidth using gibbs method is 39055 . as can be seen on figure [ res - medium ] ,",
    "the best result of the @xmath11-es with pure random mutation after 1 millions evaluations is 34604 , i.e. an improvement of 11.4% .",
    "the computational cost of one run is 15 - 20mn ( on a pentium 200mhz linux workstation ) , to be compared to the 20s seconds of gibbs method !",
    "if the maximum number of function evaluations is set to 10 millions , the best result in the same conditions is 32905 ( i.e. 15.75% improvement ) , with an average over 21 runs of 33152 ( 15.11% ) . of course , in that latter case",
    ", the computational cost is 10 times larger @xmath13 + the results on the large mesh ( 5453 nodes ) follow the same lines , though only the combinations of parameters found optimal on the medium mesh were experimented with , due to the computational cost ( around 12 - 14 hours for 10 millions evaluations ) .    from a gibbs bandwidth of 287925 ( obtained in about one minute ) , the best result for the @xmath11-es with only random mutation was 257623 ( 10.52% ) while the average of 6 runs was 258113 ( 10.35% ) . on the other hand , the best for @xmath12-es was 262800 ( 8.73% ) , the average being 263963.43 ( 8,32% ) , with @xmath14 and @xmath15 ( best parameters of figure [ res - medium]-a ) .",
    "+ the first a priori conclusion is that the computational cost of the evolutionary algorithm makes it useless in practical situations : an improvement of between 10 and 15% requires a computational power of several order of magnitude larger .",
    "this quick conclusion must however be moderated : first , due to the quadratic dependency of the computational cost of the matrix inversion in term of the bandwidth , the actual gain in computing time is around 35% for a 15% bandwidth decrease .",
    "and second , many meshes used nowadays in industry require a few months of manpower to be built and validated .",
    "so 24 more hours of computation for a better numbering is relatively low increase in cost . and",
    "if the mesh is then put in an exploitation environment , and is used in several thousands of different finite element analyses , then the overall gain might be in favor of getting a really better numbering , even at what a priori seems a high computational cost .",
    "but of course this means that meshes of up to a few thousands nodes can be handled by evolutionary algorithms .",
    "it is nevertheless important to notice that the computation of the bandwidth can be greatly optimized .",
    "the present algorithm was designed to be very general , handling any possible operator .",
    "hence it always computes the fitness from scratch .",
    "however , in the case where only a small number of transpositions are performed , the variation of the fitness could be computed , by examining only the neighbors of the transposed nodes .",
    "we have presented feasibility results for the application of evolutionary computation to the problem of mesh numbering .",
    "our best results outperform the state - of - the - art gibbs method by 10 to 15% on the two test meshes used ( with 1545 and 5453 nodes respectively ) .",
    "whereas these sizes would appear fairly high for tsp problems for instance , they are still small figures with respect to real - world problems , where hundreds of thousands of nodes are frequent .    from the evolutionary point of view ,",
    "two issues should be highlighted .",
    "first , though both general - purpose and domain - specific crossover operators were tried , none proved efficient .",
    "a possible further trial could be to use more global geometrical information ( e.g. divide the mesh into some connected components , and exchange the relative orders of such blocks , in the line of @xcite ) .",
    "second , the overall best results were obtained by a @xmath11-es using pure random transposition mutation and starting from an initial population made of slightly perturbed gibbs meshes .",
    "this which might be an indication that other heuristic local search methods ( e.g. tabu search ) might be better suited to the mnp .",
    "however , as discussed in section [ res - medium ] , some hints make us believe that there is still a large room for improvement using evolutionary ideas : on the one hand , the problem - specific mutations proved useful for the @xmath12-es , indicating that we might not have make good usage of the domain knowledge ; on the other hand , the @xmath12-es ( with problem - specific mutation ) outperformed the @xmath11-es when the initial population was not limited to modified gibbs meshes : our hope is that starting from totally different parts of the search space could provide much better results in some particular situations ... which still remain to be identified .",
    "but in those yet hypothetical cases , the relevance of the evolutionary approach for the mnp would be clear .",
    "t.  bck and m.  schtz .",
    "evolution strategies for mixed - integer optimization of optical multilayer systems . in j.  r. mcdonnell ,",
    "r.  g. reynolds , and d.  b. fogel , editors , _ proc . of the 4@xmath16 annual conf . on evolutionary programming_. mit press , march 1995 .",
    "t.  bck and m.  schtz .",
    "intelligent mutation rate control in canonical gas . in z.",
    "w. ras and m.  michalewicz , editors , _ foundation of intelligent systems 9th intl symposium , ismis 96 _ , pages 158167 .",
    "springer verlag , 1996 .",
    "b.  freisleben and p.  merz .",
    "new genetic local search operators for the tsp . in h .-",
    "voigt , w.  ebeling , i.  rechenberg , and h .-",
    "schwefel , editors , _ proc . of the @xmath17 conf .",
    "on parallel problems solving from nature _ , lncs 1141 , pages 890899 .",
    "springer verlag , 1996 .",
    "m.  george - schleuter . asparagos96 and the travelling salesman problem . in t.  bck , z.  michalewicz , and x.  yao , editors ,",
    "_ proc . of the 4@xmath16 ieee intl conf . on evolutionary computation _ ,",
    "pages 171174 .",
    "ieee press , 1997 .",
    "f.  glover and g.  kochenberger .",
    "critical event tabu search for multidimensional knapsack problems . in _ proc .",
    "of the intl conf . on metaheuristics for optimization _ , pages 113133 .",
    "kluwer publishing , 1995 .        c.  kane and m.  schoenauer .",
    "genetic operators for two - dimensional shape optimization . in j .-",
    "alliot , e.  lutton , e.  ronald , m.  schoenauer , and d.  snyers , editors , _ artificial evolution _ , lncs 1063 .",
    "springer verlag , septembre 1995 .",
    "p.  merz and b.  freisleben .",
    "genetic local search for the tsp : new results . in t.",
    "bck , z.  michalewicz , and x.  yao , editors , _ proc . of the 4@xmath16 ieee intl conf . on evolutionary computation _ ,",
    "pages 159164 .",
    "ieee press , 1997 .",
    "n.  j. radcliffe and p.  d. surry .",
    "fitness variance of formae and performance prediction . in l.  d. whitley and m.  d. vose , editors , _ foundations of genetic algorithms 3 _ , pages 5172 .",
    "morgan kaufmann , 1995 .",
    "d.  whitley , t.  starkweather , and d.  fuquay .",
    "scheduling problems and travelling salesman : the genetic edge recombination operator . in j.",
    "d. schaffer , editor , _ proc . of the @xmath19 intl conf . on genetic algorithms_. morgan kaufmann , 1989 ."
  ],
  "abstract_text": [
    "<S> mesh numbering is a critical issue in finite element methods , as the computational cost of one analysis is highly dependent on the order of the nodes of the mesh . </S>",
    "<S> this paper presents some preliminary investigations on the problem of mesh numbering using evolutionary algorithms . </S>",
    "<S> three conclusions can be drawn from these experiments . </S>",
    "<S> first , the results of the up - to - date method used in all fem softwares ( gibb s method ) can be consistently improved ; second , none of the crossover operators tried so far ( either general or problem specific ) proved useful ; third , though the general tendency in evolutionary computation seems to be the hybridization with other methods ( deterministic or heuristic ) , none of the presented attempt did encounter any success yet . the good news , however , is that this algorithm allows an improvement over the standard heuristic method between 12% and 20% for both the 1545 and 5453-nodes meshes used as test - bed . </S>",
    "<S> finally , some strange interaction between the selection scheme and the use of problem specific mutation operator was observed , which appeals for further investigation . </S>"
  ]
}