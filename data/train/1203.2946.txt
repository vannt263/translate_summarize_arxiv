{
  "article_text": [
    "the sparse matrix - vector ( spmv ) multiplication is one of the most important kernels in scientific computing with numerous applications ranging from sparse linear solvers to the pagerank algorithm used by google in its web search engine .",
    "however , its high memory bandwidth requirements combined with the poor data locality exhibited by typical sparse matrices result in poor performance on general purpose processors which usually attain only a small fraction of their peak performance in this kernel .",
    "the literature devoted to spmv optimization techniques on traditional , cache - based processor designs is ample ( see @xcite for an extensive overview ) , and currently one of the major issues is how to exploit new features available in multicore hardware .",
    "several spmv optimization strategies were already proposed for various designs of chip multiprocessors , including multicore central processing units ( cpus ) from intel and amd @xcite , single- and dual - socket sti cell @xcite , sun ultrasparc t2 @xcite , field programmable gate arrays ( ) @xcite , intel xeon phi coprocessors @xcite , and graphics processing units ( gpus ) @xcite .    in just a few years gpus",
    "have evolved from fixed - pipeline application - specific integrated circuits into highly programmable , versatile computing devices with peak computational performance matching that of the most powerful supercomputers of only a decade ago .",
    "these devices can be programmed in high - level programming languages , e.g.  nvidia s c++ for cuda ( proprietary ) or opencl ( open standard ) .",
    "the major problem in their usage is software : any new hardware architecture will succeed only if appropriate software can be developed to exploit the parallelism in the hardware efficiently .",
    "however , the current multicore architectures are so diverse and are subject to so frequent changes that to exploit their potential the applications must be highly specialized and use architecture - specific optimization strategies",
    ". moreover , massively parallel architectures , like the one utilized in modern gpus , require to use a new programming paradigm , which in turn requires radical rethinking of how numerical computations should be performed . since the vast majority of the existing scientific software adheres to `` old '' programming paradigms , and since development of this software took millions of man - hours , perhaps the best way to introduce new concepts",
    "is by concentrating on the most important kernels and showing their usability in the `` old '' environment .    in this paper",
    "we present an efficient spmv algorithm optimized for processors with programmable on - chip shared memory and examine its implementation for nvidia s cuda - enabled gpus .",
    "the algorithm is based on a new sparse matrix storage format , cmrs , designed as an extension of a popular compressed row storage ( crs , also known as compressed sparse row , csr ) format .",
    "it is characterized by a small memory footprint and small conversion times to other storage formats , which should facilitate its adoption in existing applications .",
    "it also turns out to be among the fastest spmv algorithms available for gpus .",
    "moreover , in contrast to many recent studies on gpu spmv , which were based on small sets of sparse matrices , which in turn almost reduced the papers to case studies , here we use a far larger set from the university of florida sparse matrix collection ( uf smc ) @xcite .",
    "this enabled us to make some general statements not only about the absolute performance of our cmrs - based implementation , but also about relative performance of several other alternative solutions for two generations of gpu architectures .",
    "the aim of the spmv multiplication algorithm is to calculate the product @xmath1 , where @xmath2 is a large sparse matrix and @xmath3 , @xmath4 are dense vectors .",
    "typical matrices involved in the spmv product have thousands or even millions of rows and columns , but the average number of nonzero elements per row rarely exceeds 100 . the most interesting  and difficult  matrices are those whose distribution of nonzero elements appears to be unpredictable .",
    "nonzero elements of @xmath5 are usually stored in an auxiliary array , and additional information is needed to uniquely map the values in the array to their locations in @xmath5 . the way this information is stored",
    "is called a sparse matrix format .",
    "calculation of a sparse matrix - vector product essentially reduces to many `` multiply and add '' operations , which in modern gpus are implemented as a single fused multiple - add ( fma ) instruction .",
    "since spmv multiplication involves several memory accesses per arithmetic instruction , the spmv kernel is inherently memory - bound .",
    "for example , a server - class tesla k20x gpu can perform @xmath6 fma operations per second and can access its main memory at @xmath7 b / s , which yields approximately 2.5 operations per byte . for the spmv kernel",
    "this sets the upper bound for the processor computational efficiency to @xmath8 of its peak theoretical value .",
    "although this value can be increased by using fast on - chip caches , other factors , like additional memory transactions necessary to read sparse matrix format data or reduced off - chip memory throughput due to poor data locality can decrease it to even smaller values .",
    "the main challenge is thus how to exploit and balance all the performance - related features available in hardware , focusing on the utilization of the memory .",
    "the architecture of modern gpus is a massively parallel design which excels in computing - intensive stream data processing .",
    "here we briefly discuss the main properties of the `` fermi '' ( 2010 ) and  kepler ",
    "( 2012 ) gpu architectures from nvidia @xcite .",
    "a gpu contains a number of units called multiprocessors , each one containing a set of relatively simple computing cores called cuda cores . from the programmer s perspective , multiprocessors are essentially independent single - instruction multiple data ( simd ) devices in which groups of 32 cuda threads , called warps , execute the same instruction on multiple data simultaneously .",
    "multiprocessors are connected to high bandwidth ( up to @xmath9 290  gb / s ) , high latency ( @xmath9 800 clock cycles ) , limited size ( @xmath1012  gb ) external dynamic random access memory through a coherent l2 cache ( up to 1.5  mb ) .",
    "each multiprocessor has an l1 cache , a read - only texture cache , a 48-kb read - only cache ( kepler k20 and k40 gpus only ) and a constant cache ( 8  kb ) . beside these hardware - managed caches ,",
    "multiprocessors contain also several fast on - chip memories managed in software : so called shared memory ( up to 48 kb ) and registers .",
    "the shared memory is shared by all threads belonging to well - defined groups of warps ( called blocks ) executing on the same multiprocessor .",
    "the sizes of these resources are available and , to some extent , configurable at run - time .",
    "various memories available in gpus differ not only in their size and speed , but also in latencies .",
    "for example , the latency of registers is @xmath11 clock cycles , whereas the latency of the global memory accesses can be as high as 800 clock cycles . to hide such high latencies , each multiprocessor loads into its registers the states of up to 1536 ( fermi ) or 2048 ( kepler ) threads and attempts to execute the warp that has all operands ready for execution .",
    "this leads to massive parallelism with thousands of threads being processed on - chip simultaneously . for this approach to be efficient ,",
    "the occupancy , defined as the ratio of the number of resident threads to the maximum number of resident threads , must be sufficiently high .",
    "another factor crucial for gpu efficiency is the memory access pattern .",
    "for example , the condition for the global memory to be utilized at full speed is that all threads in a warp should access contiguous , 128-byte aligned locations .",
    "cuda is an abstract general purpose parallel computing architecture , programming model , and programming environment designed for nvidia s gpus @xcite .",
    "it is based on a few key concepts such as groups of threads ( arranged hierarchically in warps , blocks and a grid ) , shared memories and barrier synchronization .",
    "these concepts are exposed to the programmer through a minimal set of extensions to a high - level programming language ( c or c++ ) .",
    "warps within a block of threads can be executed in any order ; similarly , each block of threads can be run on any of the available multiprocessors in an arbitrary order , sequentially or in parallel .",
    "the simplest sparse matrix format is the coordinate ( coo ) format , in which the information about the row index , column index , and the value of each non - zero matrix element is stored in three one - dimensional arrays , ` rowind ` , ` colind ` , and ` val ` , respectively . as an example , consider a @xmath12 matrix :    @xmath13.\\ ] ]    its coo representation ( with zero - based indexing ) reads @xmath14 , \\\\",
    "\\texttt{colind } & = & \\left[\\ ; 0 \\;\\ ; 3 \\;\\ ; 1 \\;\\ ; 4 \\;\\ ; 2 \\;\\ ; 4 \\;\\ ; 2 \\;\\ ; 3 \\;\\ ; 4 \\;\\ ; 4   \\ ; \\right ] , \\\\",
    "\\texttt{rowind } & = & \\left[\\ ; 0 \\;\\ ; 0 \\;\\ ; 1 \\;\\ ; 1 \\;\\ ; 2 \\;\\ ; 2 \\;\\ ; 3 \\;\\ ; 3 \\;\\ ; 3 \\;\\ ; 4   \\ ; \\right].\\end{aligned}\\ ] ] to complete the matrix definition , one also needs to supply three integers : the number of matrix rows ( ` rows ` ) , columns ( ` cols ` ) and non - zero elements ( ` nnz ` ) .    in the above example",
    "the row - major ordering was used , i.e. , the matrix index arrays were first sorted by row indices and then by column indices .",
    "in such a case array ` rowind ` will typically contain sequences of many identical entries .",
    "this property is utilized in the crs format to reduce the memory footprint by replacing array ` rowind ` with a shorter array ` rowptr ` . in the most general case",
    "this array is defined by the requirement that ` rowptr[j+1 ] - rowptr[j ] ` be equal to the number of non - zero elements in the @xmath15-th row ( @xmath16 ) .",
    "if the matrix contains no empty rows , ` rowptr`[j ] gives the index into ` val ` corresponding to the first non - zero element in the @xmath15-th matrix row .",
    "array ` rowptr ` has exactly ` rows`@xmath17 elements and ` rowptr[rows ] ` = ` nnz ` .",
    "thus , the crs representation of @xmath18 reads @xmath19 , \\\\",
    "\\texttt{colind } & = & \\left[\\ ; 0 \\;\\ ; 3 \\;\\ ; 1 \\;\\ ; 4 \\;\\ ; 2 \\;\\ ; 4 \\;\\ ; 2 \\;\\ ; 3 \\;\\ ; 4 \\;\\ ; 4 \\;\\right ] , \\\\ \\texttt{rowptr } & = & \\left[\\ ; 0 \\;\\ ; 2 \\;\\ ; 4 \\;\\ ; 6 \\;\\ ; 9 \\;\\ ; 10 \\;\\right].\\end{aligned}\\ ] ] note that arrays ` val ` and ` colind ` are the same as in the coo format .",
    "let @xmath20 be the maximum number of non - zero elements per row .",
    "in the ellpack / itpack ( ell ) format an @xmath21 sparse matrix is represented by two @xmath22 dense arrays , ` val ` and ` colind ` . array ` val ` is constructed from the original matrix by removing all zeros , while ` colind ` holds column indices into ` val ` . the rows with less than @xmath20 non - zero elements are padded in",
    "` val ` and ` colind ` arrays with @xmath23 and @xmath24 , respectively .",
    "the ell representation of @xmath18 is thus : @xmath25 , \\hspace{0.025\\textwidth }   \\texttt{colind } = \\left [    \\begin{array}{rrr }       0 &   3 & -1 \\\\       1 &   4 & -1 \\\\       2 &   4 & -1   \\\\       2 & 3 & 4 \\\\       4 & -1 & -1 \\\\",
    "\\end{array }   \\right].\\ ] ]    while the ell format belongs to the most efficient sparse matrix formats for vector architectures , it may involve a costly storage overhead .",
    "several attempts have been made to modify this format so as to extend its practical usability for general sparse matrices .",
    "one such attempt is the hybrid ( hyb ) format @xcite , which is a combination of the ell and coo formats .",
    "another idea is to divide the matrix into several slices , each represented separately in the ell format , and/or use some kind of matrix transformation , e.g.  permutation of rows @xcite , to reduce padding .",
    "one of the first efficient implementations of spmv on the gpu architecture were proposed by bell and garland @xcite .",
    "they implemented spmv kernels for several sparse matrix formats , including coo , ell , and hyb .",
    "in addition , two spmv kernels for the crs format were provided : scalar and vector .",
    "the scalar kernel assigns one thread per matrix row , which results in non - coalesced access to memory and poor performance .",
    "the vector kernel assigns a 32-thread warp to each row  while this ensures contiguous access to the memory , it leads to a large bandwidth waste whenever a row size is much smaller than the warp size . as for coo",
    ", the tests showed that it is not flexible enough to handle unstructured matrices efficiently .",
    "the ell format is often the fastest , but fails whenever row sizes vary significantly , as it leads to a large memory overhead .",
    "this problem was addressed in the hyb format , in which the matrix is partitioned into a regular part , stored in ell , and an irregular part , stored in coo @xcite .",
    "the partitioning of a general matrix is a rather complex operation which requires building a histogram of the row sizes to find the balance between the potential storage overhead of ell and the computational inefficiency of coo .",
    "the authors recommended hyb as the fastest format for a broad selection of unstructured matrices .",
    "bell s and garland s spmv kernels served as building blocks for the cusp @xcite library . to improve coalescing of matrix data accesses for matrices in the crs representation",
    ", cusp can virtually divide each warp into 2 , 4 , 8 or 16 smaller parts and assign them to different rows .",
    "mukunoki and takahashi used the same idea to optimize their crs kernel for the kepler gpu architecture @xcite .",
    "baskaran and bordawekar @xcite proposed a few other optimization techniques based on exploiting synchronization - free parallelism and optimized off - chip memory access .",
    "another direction of research on improving the efficiency of the spmv kernel on gpus focuses on various extensions and modifications of the ell or crs formats .",
    "this resulted in the development of the ell - r @xcite , sliced - ell @xcite , ellr - t @xcite , and sliced ellr - t @xcite formats , tiling and composite storage @xcite , as well as the crs - t @xcite and csr sic @xcite formats .",
    "efficiency of existing gpu implementations of the spmv product is often significantly better if an ell - based format , e.g.  hyb , is used instead of crs .",
    "the main reason for this is that gpus are simd - like machines with relatively wide simd units , often far wider than the average row length .",
    "since efficient utilization of the crs format requires the matrix elements to be accessed row by row , processing short rows in long simd - like units leads to wasting of the computational capability of the device .",
    "therefore , our main idea is to process a sparse matrix in chunks larger than individual rows , at the same time preserving the overall structure of the matrix representation typical of the crs format .",
    "a group of rows processed by an individual simd unit shall be called ` strip ' , and the number of rows in a strip shall be called ` strip height ' and denoted ` height ` .",
    "the number of strips , ` strips ` is thus equal to ` ceil(rows / height ) ` .",
    "the new sparse matrix format , which we call compressed multi - row storage ( cmrs ) format , comprises one integer parameter ` height ` and four arrays : data array ` val ` and three auxiliary integer arrays , ` colind ` , ` stripptr ` , and ` rowinstrip ` .",
    "arrays ` val ` and ` colind ` are the same as in the crs format .",
    "array ` stripptr ` is a generalization of crs array ` rowptr ` and is defined by the requirement that ` stripptr[j+1 ] - stripptr[j ] ` be equal to the number of non - zero elements in the @xmath15-th strip ( @xmath26 ) .",
    "if the sparse matrix contains no empty strips , ` stripptr`[j ] gives the index into ` val ` corresponding to the first non - zero element in the @xmath15-th strip .",
    "finally , array ` rowinstrip ` , of length ` nnz ` , holds the row numbers within individual strips .",
    "assume @xmath27 .",
    "then the cmrs representation of @xmath18 reads : @xmath19 , \\\\",
    "\\texttt{colind } & = & \\left[\\ ; 0 \\;\\ ; 3 \\;\\ ; 1 \\;\\ ; 4 \\;\\ ; 2 \\;\\ ; 4 \\;\\ ; 2 \\;\\ ; 3 \\;\\ ; 4 \\;\\ ; 4 \\;\\right ] , \\\\ \\texttt{stripptr } & = & \\left[\\ ; 0 \\;\\ ; 4 \\;\\ ; 9 \\;\\ ; 10 \\;\\right],\\\\ \\texttt{rowinstrip } & = & \\left[\\ ; 0 \\;\\ ; 0 \\;\\ ; 1 \\;\\ ; 1 \\;\\ ; 0 \\;\\ ; 0 \\;\\ ; 1 \\;\\ ; 1 \\;\\ ; 1 \\;\\ ; 0 \\;\\right].\\end{aligned}\\ ] ] note that the conversion between the crs and cmrs formats is trivial and easy to parallelize .",
    "in particular , @xmath28 } =   \\mathtt{rowptr[j*height]}$ ] for @xmath29 and @xmath30 } = \\mathtt{nnz}$ ] , whereas ` rowinstrip[k ] ` is the remainder of the row number divided by ` height ` .",
    "it is also clear that both formats are equivalent if @xmath31 , hence cmrs can be regarded as an extension of the crs format .",
    "the idea that a warp could process a group of adjacent matrix rows was already exploited in refs .",
    "they all used a static mapping of warp threads to the rows , which is inefficient if the lengths of adjacent rows vary significantly .",
    "in particular , the csr sic format @xcite interleaves several matrix rows to form a new sic row .",
    "this , however , requires padding shorter rows with explicit zeroes . as this",
    "could easily lead to prohibitive memory overhead , the rows must be first reordered according to their lengths , then combined into larger sic rows , and these are then combined into a few large segments processed by separate gpu kernels .",
    "the cmrs format solves these problems by dynamically assigning threads to rows through the ` rowinstrip ` array .",
    "an efficient cmrs - based spmv kernel requires neither zero - padding nor row reordering and can be implemented as a single gpu kernel .",
    "our gpu implementation of the spmv product for matrices in the cmrs format is based on the vector kernel by garland and bell @xcite , with rows replaced by strips .",
    "each simd unit , or warp made of @xmath32 threads , is assigned a strip to process .",
    "the method of doing the spmv product in a strip is presented in algorithm  [ alg : cmrs ] and explained below .",
    "note that we used 28 bits of ` colind[j ] ` to store a column index and the remaining 4 bits ( denoted as ` cmrs_bits ` ) to store the corresponding value of ` rowinstrip ` .",
    "this made array ` rowinstrip ` superfluous and explains ` uncompression ' steps in algorithm  [ alg : cmrs ] .    `",
    "val ` , ` colind ` , ` stripptr ` , ` height ` , @xmath3 , @xmath4 , @xmath33 @xmath34 for all @xmath35 @xmath36 @xmath37 @xmath38 @xmath39 @xmath40 @xmath41 @xmath42 @xmath43 @xmath44 @xmath45 , @xmath46",
    "@xmath47 @xmath48    this algorithm is assumed to be executed in parallel by all threads in a warp .",
    "implicit synchronization of the threads forming a warp is assumed . all auxiliary buffers and temporary variables are local to a warp , so no explicit synchronization of different warps is necessary , which allows for massively parallel processing of strips .",
    "the values of matrix elements and the corresponding column indices are read in parallel directly from arrays ` val ` and ` colind ` , whereas row indices are assembled from the information held in arrays ` stripptr ` and ` rowinstrip ` . for",
    "sufficiently long strips these memory operations are coalesced to a high degree ( @xmath15 runs through consecutive matrix elements ) , and hence are very fast",
    ". then the necessary elements of the input vector are fetched from the memory .",
    "this is the most sensitive part of each parallel spmv implementation , as the vector elements required by a simd unit are often stored in memory locations scattered almost randomly in the memory , and hence their parallel processing is very problematic .",
    "individual products of the matrix by vector elements are computed and stored in a buffer ` buf ` allocated in the fast on - chip shared memory .",
    "the buffer size is quite large , @xmath49 , as each thread needs its own memory buffer for each row .",
    "the exact mapping of thread lanes and row numbers into ` buf ` is arbitrary , as long as it is one - to - one , and affects the number of shared memory bank conflicts and the efficiency of the parallel reduction step .",
    "the mapping presented in algorithm  [ alg : cmrs ] , i.e. a cyclic assignment of threads , is designed to minimize the latter factor .",
    "for example , for @xmath50 one can reduce @xmath51 partial row sums in ` buf ` into 8 row sums using just 9 instructions .",
    "our implementation needs ` height`-fold more shared memory than the vector kernel of ref.@xcite . on the one hand",
    "this is beneficial for the parallel reduction , but on the other hand it imposes a severe limit on acceptable values of ` height ` , as the buffer size in currently available gpus is restricted to 48  kb . for example , if we take @xmath52 and store the data as 4-byte numbers , 64 bytes of the shared memory will be needed for each thread , and so the maximum number of resident threads per multiprocessor will be limited to 768 , which translates into the occupancy of 50% for the fermi and only 37.5% for the kepler architecture .",
    "taking into account that a large number of resident threads is necessary to hide large memory latencies , we can safely assume that the maximum value of @xmath53 in an efficient implementation for fermi- or kepler - class gpus does not exceed 16 .",
    "this , in turn , implies that the values stored in array ` rowinstrip ` are in the range 0,  ,15 and hence can be encoded in just ` cmrs_bits ` = 4 bits .",
    "the remaining 28 bits are enough to store column indices of matrices with less than @xmath54 columns .",
    "this is @xmath9 20 times more than the size of the largest sparse matrix that we were able to test on a 6  gb device .",
    "the spmv kernel on gpus is so much memory - bound that it is of utmost importance to reduce its memory footprint , even at the cost of several arithmetic operations , which in this kernel are almost free , hence the idea of compressing two integers into a single 32-bit word .",
    "we also implemented several optional performance optimizations .",
    "the first one consists in buffering the input vector in the texture cache @xcite or the new 48k read - only cache @xcite rather than in the l1 cache .",
    "the second one consists in enlarging the shared memory size from 16 to 48  kb , at the cost of the l1 cache size .",
    "the third optimization strategy , adapted from @xcite , aims at improving the effective memory bandwidth for arrays ` val ` and ` colind ` , for large @xmath55 , by first accessing the non - aligned portion of a strip and then accessing the remaining , aligned portion at full speed .",
    "the fourth one consists in reordering the elements of cmrs arrays so that the index array ` colind ` is first sorted by strip indices and then within the same strip by column indices .",
    "the idea behind such ordering is the same as for the row - major ordering in the crs format : enhance the frequency of coalesced or cache - buffered accesses of a simd unit to the elements of the input vector .",
    "note that most matrices coming from real problems have some internal structure and the locations of nonzero elements in neighboring rows are correlated . in such cases reordering the entries in the cmrs arrays can have a pronounced impact on spmv efficiency .",
    "assuming again @xmath27 , the cmrs representation of @xmath18 after data reordering would read : @xmath56 , \\\\ \\texttt{colind } & = & \\left[\\ ; 0 \\;\\ ; 1 \\;\\ ; 3 \\;\\ ; 4 \\;\\ ; 2 \\;\\ ; 2 \\;\\ ; 3 \\;\\ ; 4 \\;\\ ; 4 \\;\\ ; 4 \\;\\right ] , \\\\ \\texttt{rowinstrip } & = & \\left[\\ ; 0 \\;\\ ; 1 \\;\\ ; 0 \\;\\ ; 1 \\;\\ ; 0 \\;\\ ; 1 \\;\\ ; 1 \\;\\ ; 0 \\;\\ ; 1 \\;\\ ; 0 \\;\\right ] , \\\\ \\texttt{stripptr } & = & \\left[\\ ; 0 \\;\\ ; 4 \\;\\ ; 9 \\;\\ ; 10 \\;\\right],\\end{aligned}\\ ] ] note that the reordering affects only the matrix internal representation and does not involve any actions on the input and output vectors .",
    "moreover , reordering is local to strips and hence is prone to parallelization .",
    "the performance model of the cmrs format is based on a few simplifying assumptions : the kernel is memory - bound ; each warp processes exactly @xmath57 nonzero matrix elements ; the data is read from or written to contiguous chunks of memory of size @xmath58 , where @xmath59 or @xmath60 is the number of bytes occupied by a data item ; finally , the number of memory transactions is equal to the number of distinct memory segments of size @xmath61 touched by the warp while accessing the @xmath62-byte chunk of memory , see fig .",
    "[ fig : model_explained ]",
    ".     consecutive bytes to or from the device accessing the memory in @xmath61-byte - long segments .",
    "this can lead to the bandwidth waste and low kernel efficiency . ]    if one also assumes that the beginning of the @xmath62-byte long chunk is uncorrelated with the the global memory segment boundaries , one concludes ( see the additional material ) that the ratio of the mean number bytes transferred to the bytes actually requested by the kernel is @xmath63 where @xmath64 denotes the strip height ( note that @xmath65 = @xmath66 and @xmath67 ) .",
    "this number must be as close to 1 as possible for the kernel to be efficient . for",
    "@xmath68 this formula estimates the efficiency of the vector kernel in the plain crs format .",
    "thus , substituting @xmath69 @xcite , @xmath70 ( single precision ) , and @xmath71 ( only two nonzero matrix elements per row on average ) , one obtains @xmath72 , which means that for every 16 bytes transferred by the crs vector kernel , @xmath9 15 are wasted .",
    "however , the cmrs kernel with @xmath73 would reduce @xmath74 down to @xmath75 .",
    "equation ( [ eq : def - f ] ) can be used to estimate the acceleration of the cmrs kernel over the plain crs vector kernel , @xmath76    assuming that @xmath77 , this formula suggests that for extremely sparse matrices ( @xmath78 ) and small values of @xmath64 the cmrs format should be able to accelerate the plain crs - based vector kernel ` height`-fold , as in this case @xmath79 .",
    "however , the advantages of the cmrs format are not expected to be particularly high for @xmath80 . moreover",
    ", for @xmath81 the value of @xmath82 is rather small , which gives a theorethical justification of setting 16 as the upper bound for ` height ` in our implementation .",
    "this formula implies also that processing several matrix rows with a single warp will become even more critical if the value of @xmath61 increases in some future gpu architectures .",
    "the tests were performed on two nvidia devices , gtx 480 ( 1.5  gb , `` fermi '' architecture ) and tesla k20 m ( 5  gb",
    ". `` kepler '' architecture ) . the ecc memory support in the tesla device",
    "was switched off for a larger bandwidth . in both cases",
    "the operating system was a 64-bit linux with nvidia gpu driver v.  319.21 and cuda 5.5 .",
    "theoretical capabilities of these devices are listed in table [ tab:1 ] .",
    ".theoretical peak capabilities of the devices used in tests [ tab:1 ] [ cols=\"<,>,>,>\",options=\"header \" , ]      the tests were performed using 132 square real matrices from the university of florida sparse matrix collection satisfying @xmath83 , including all matrices with @xmath84 , and three additional sparse matrices of our choice .",
    "the matrices are of various sizes and represent a wide spectrum of applications and structure patterns . in particular , our tests include all symmetric matrices used in several recent studies on gpu spmv performance @xcite .",
    "we excluded from the tests a few sparse matrices with dense rows ( ` lp1 ` , ` circuit5 m ` , ` chebyshev4 ` , ` rajat30 ` , ` fullchip ` ) , because such matrices require special algorithms , as will be discussed below .",
    "some uf smc matrices , e.g. ` shipsec8 ` , are available in two versions : with and without explicit zero entries . in such cases we tested both representations if the number of explicit zeros is larger than ` nnz`/10 .",
    "the additional matrices of our choice include a synthetic matrix , ` p7 ` , which is a large ( @xmath85 ) random permutation matrix , ` dense4 ` , which is a dense @xmath86 matrix treated as a sparse one , and ` aorta ` , which is a sparse matrix representing the pressure equation in the problem of the flow through the human abdominal aorta @xcite .",
    "we included ` p7 ` to get a better insight into the role played by structural correlations between adjacent rows and the impact of ( un)coalesced accesses to the input vector ; ` dense4 ` is an example of a matrix which can be processed at the highest performance ; and ` aorta ` is an example of a sparse matrix for which efficiency of the spmv kernel is of utmost importance , as it directly affects the time to solution in biomedical applications .      for each test matrix and each combination of optimization parameters ,",
    "our cmrs implementation of the spmv product was called 11 times and the execution times were recorded . the largest time was omitted and the remaining 10 results were analyzed to find their average and standard deviation .",
    "the optimization parameters included the strip height ( @xmath87 ) , the number of threads per block ( @xmath88 ) , and four boolean parameters referring to the optimization techniques described in sec .",
    "[ sec : implementation ] , independently for k20 m ( kepler ) and gtx  480 ( fermi ) gpus .",
    "we searched this parameter space for universal values that would give spmv times as close as possible to the shortest spmv execution time @xmath89 obtained through the brute - force search , for as many test matrices as possible .",
    "we came to the following conclusions .",
    "the optimal block size is 128 threads .",
    "the optimal strip height depends on the gpu architecture and the number of bytes occupied by each matrix value and reads 6 ( k20 m , float ) , 4 ( k20 m , double ) , 12 ( gtx  480 , float ) , or 8 ( gtx  480 , double ) . the data should be sorted , the size of the shared memory per multiprocessor should be set to the maximum value ( 48  kb ) , the input vector should be cached either in the texture cache ( gtx  480 ) or , if supported by the device , in the new 48  kb read - only cache ( k20 m ) , and arrays ` val ` and ` colind ` should be aligned for reading if @xmath90 .",
    "one should bear in mind that all these optimization parameters are not only correlated with each other , but also depend on the representation of the matrix values ( float or double ) and on the matrix structure .",
    "for example , for some matrices the texture cache turns out more efficient than the much larger 48  kb cache and quite often there exist better values of the strip height .",
    "fortunately , the above - mentioned choice of the optimization parameters yields optimal or nearly optimal spmv times for most of the matrices ( see sec .  [",
    "sub : tuning ] below ) .",
    "while the choice of the boolean optimization parameters can be rather easily justified based on general properties of gpus , the values of the optimal block size and strip height deserve closer inspection . the value of ` bs ` = 128 is the smallest block size which allows for the full utilization of gpu s memory bandwidth ( data not shown ) , and small blocks are preferable for problems where different warps may have to process different amounts of data . as for the optimum value of the strip height , its value limits the occupancy , which , in turn , has a profound impact on the kernel bandwidth .",
    "this is illustrated in fig .",
    "[ fig : rma10 ] .",
    "metric of eq .",
    "( [ eq : beta ] ) .",
    "arrows point at the data obtained for the values of the optimal strip height , as adopted in our cmrs implementation .",
    "the arrow labels in panel ( a ) show the corresponding multiprocessor occupancy , whereas `` float '' and  double refer to the type of elements stored in ` val ` .",
    "[ fig : rma10],title=\"fig:\",scaledwidth=47.5% ]   metric of eq .",
    "( [ eq : beta ] ) .",
    "arrows point at the data obtained for the values of the optimal strip height , as adopted in our cmrs implementation .",
    "the arrow labels in panel ( a ) show the corresponding multiprocessor occupancy , whereas `` float '' and  double refer to the type of elements stored in ` val ` .",
    "[ fig : rma10],title=\"fig:\",scaledwidth=47.5% ]    panel ( a ) shows how the speed of reading arrays ` colind ` and ` val ` depends on ` height ` .",
    "we measured this relation using a very simple kernel that does nothing but read simultaneously two streams of data from the arrays , given that ` height ` words ( floats or doubles ) per thread are reserved in the shared memory and limit the occupancy .",
    "the results show some regression of the kepler architecture relative to its predecessor .",
    "first , since the maximum number of concurrent threads per multiprocessor was increased in kepler by 4/3 without increasing the size of the shared memory , the number of shared memory words per thread available in kepler for a given target occupancy was lowered by 3/4 .",
    "second , while lowering the occupancy down to 2/3 does not affect the speed at which fermi can access the global memory , this speed deteriorates quickly in kepler once the occupancy drops below 100% .",
    "consequently , the optimal value of ` height ` for kepler is expected to be @xmath91 times lower than for fermi , which we can actually see in our tests .",
    "the impact of the bandwidth - occupancy relation on the actual performance of the cmrs spmv kernel is visualised in fig .",
    "[ fig : rma10 ]  ( b ) .",
    "note that as the value of ` height ` is increased , the kernel bandwidth initially quickly increases and either saturates at ` height ` @xmath92 or hits the threshold value above which the gpu memory bandwidth starts to deteriorate .",
    "from this point on the performance of the spmv kernel starts to decrease , as it is limited by the occupancy - related factors .",
    "it is instructive to see how closely the curves in panel ( b ) follow those in panel ( a ) , especially for k20 m .",
    "all computations were also repeated using two standard crs - based spmv kernels : scalar and vector , as described in sec .",
    "[ sub : existing - implementations ] .",
    "we used our own implementations of these kernels and applied the brute - force method to find the best possible spmv times .",
    "the vector kernel was optimized with respect to all relevant parameters used for cmrs optimization , whereas the scalar kernel was optimized with respect to the value of the block size and the usage of the cache(s ) .",
    "the purpose of using extensive brute - force search for the crs data format was to ensure that any acceleration of the cmrs over crs implementation is related to the data format .",
    "finally , we also measured the computational efficiency of three freely available spmv implementations for gpus : nvidia cusparse 5.5 implementations for crs and hyb formats and the cusp  0.3.0 implementation ( csr - tex ) for the crs format .",
    "each library function was treated as a black box and called using the default configuration .",
    "cusparse is a closed - source , proprietary library that can be regarded as an industry standard and reference point , whereas cusp is an open - source library containing several spmv implementations for various data formats . while we found that the cusp kernels are generally less efficient than other kernels considered in this study , we decided to include the data for the cusp csr - tex kernel , as it features an improved version of the crs - vector kernel , aimed at accelerating the spmv operation for extremely sparse matrices .    for each matrix the computational efficiency of the cmrs spmv kernel",
    "was determined as the ratio of the number of elementary arithmetic operations to the spmv kernel time , i.e.  @xmath93 .",
    "the bandwidth was calculated as the total number of bytes that had to be transferred to or from the gpu main memory , @xmath94 , divided by @xmath95 .",
    "we considered two extreme cases : the input vector either is not cached or is fully cached .",
    "the bytes transferred in each case , @xmath96 and @xmath97 , respectively , are calculated from @xmath98 where @xmath99 is the size ( in bytes ) of data entries in ` val ` and @xmath100 .",
    "the expression for @xmath97 is the number of bytes necessary to store the matrix and the input and output vectors .",
    "the value of @xmath96 exceeds @xmath97 by @xmath101 , for if the cache is absent , reading elements of the input vector requires @xmath102 rather than @xmath103 transfers of the input vector components .",
    "the bandwidth can be defined either as @xmath104 or @xmath105 , which leads to two definitions of memory utilization efficiency , @xmath106 : @xmath107 where @xmath108 is the theoretical hardware bandwidth of the device .",
    "clearly , @xmath109 and a value of @xmath110 indicates that the device efficiently buffers the input vector in its caches .",
    "the memory bandwidth @xmath104 for five spmv kernels running on the kepler k20 m gpu for selected matrices ( double precision ) is presented in fig .",
    "[ fig:2 ] .     of five spmv kernels on the kepler k20 m gpu for selected sparse matrices in double precision representation .",
    "the matrices are ordered according to @xmath65 .",
    "[ fig:2],scaledwidth=90.0% ]    the matrices in this figure include all square matrices used in ref .",
    "they were ordered according to the average row length , @xmath65 , which ranges from 1 ( matrix ` p7 ` ) to @xmath111 ( ` tsopf - rs - b2383 ` ) . in this",
    "set , matrix ` p7 ` constitutes an extreme case in which accesses to the input vector are totally uncoalesced .",
    "moreover , since in this case the cmrs algorithm uses the value of ` height ` = 4 , only 4 of the 32 threads in a warp are actively processing the matrix elements .",
    "this leads to very inefficient memory bandwidth utilization , with @xmath112 .",
    "matrix ` tsopf - rs - b2383 ` constitutes another extreme case in which accesses to the input vector are well coalesced .",
    "the memory bandwidth attained for this matrix by the cmrs kernel is 250  gb / s , which yields @xmath113 and @xmath114 .",
    "the fact that @xmath115 indicates that k20 m can efficiently buffer the input vector in its caches .",
    "however , the efficiency of the previous generation gpu , gtx  480 , turned out to be even better for this matrix ( @xmath116 , @xmath117 , 248  gb / s ) , even though gtx  480 has a smaller l2 cache , no 48  kb read - only cache , and is 7 times slower at double precision arithmetics ( c.f .",
    "[ tab:1 ] ) .",
    "note that pre - fermi gpus , e.g.  gtx  285 , which had neither l1 nor l2 caches , allowed for far less efficient data caching ( @xmath118 ) @xcite .    to compare different spmv algorithms",
    ", we analysed the results obtained for the sparse matrices from uf smc , assuming that this collection contains a representative sample of sparse matrices .",
    "the speedup of our implementation over three other spmv kernels , vector , scalar and hybrid , for k20 m ( double precision ) and gtx  480 ( single precision ) is shown in fig .",
    "[ fig:3 ] .    , for ( a )  k20 m and ( b ) gtx  480 in double precision .",
    "the smooth lines were computed from eq .",
    "( [ eq : def - a ] ) with @xmath119 .",
    "[ fig:3],title=\"fig:\",scaledwidth=49.0% ] , for ( a )  k20 m and ( b ) gtx  480 in double precision .",
    "the smooth lines were computed from eq .",
    "( [ eq : def - a ] ) with @xmath119 .",
    "[ fig:3],title=\"fig:\",scaledwidth=49.0% ]    results for k20 m in double precision ( @xmath120 ) are interesting from the practical point of view , whereas the results for gtx  480 in single precision ( @xmath121 ) allow to estimate to what extent the performance of the cmrs kernel is affected by the kernel occupancy .",
    "clearly , @xmath65 turns out to be a relevant parameter for determining relative performance of various spmv implementations .",
    "however , perhaps an even more striking feature of the two graphs is their similarity , which reflects the fact that the performance of spmv kernels is highly influenced by the matrix structure .",
    "the scalar and hybrid kernels give the shortest spmv times for small @xmath65 , but their efficiency decreases as @xmath65 is increased , with the scalar kernel being very inefficient for large @xmath65 .",
    "this is related to the inability of the scalar kernel to coalesce data transfers if @xmath65 is large .",
    "the vector kernel behaves in just the opposite way : its efficiency relative to other kernels is very good for large @xmath65 , but it decreases as @xmath65 drops below @xmath122 , as predicted by eq .",
    "( [ eq : def - a ] ) .    the smooth lines in fig .  [ fig:3 ]",
    "show the speedup of the cmrs kernel over the vector kernel , as predicted by eq .",
    "( [ eq : def - a ] ) , for the data in double precision ( @xmath123 ) .",
    "we used two values of @xmath61 , 128 ( as suggested by nvidia for accessing contiguous streams of 4-byte data @xcite ) and 256 . for k20 m",
    "the agreement is very good for @xmath124 , whereas for the older architecture the experimental values appear to lie between the two theoretical curves .",
    "the superiority of @xmath124 for 8-byte data on the kepler architecture will be also discussed in sec .",
    "[ subsec : boost ] .    to better validate the performance model of the cmrs format , in fig .",
    "[ fig:4 ]    , for gtx  480 in single precision and @xmath125 ( symbols ) and the performance model predictions , eq .",
    "( [ eq : def - a ] ) with @xmath126 ( lines ) . [ fig:4],scaledwidth=60.0% ]",
    "we compare its predictions for the 4-byte data with the results obtained for gtx  480 in single precision . with this choice of the matrix value representation and the gpu architecture",
    ", the device runs at the full occupancy up to ` height ` = 8 .",
    "as can be seen , the model describes the actual speedup well .",
    "the speedup of our cmrs spmv kernel over two remaining , crs - based spmv kernels , cusparse and cusp , is shown in fig .",
    "[ fig : cusp - susparse ] .    , for ( a )  k20 m in double precision and ( b ) gtx  480 in single precision .",
    "[ fig : cusp - susparse],title=\"fig:\",scaledwidth=47.5% ] , for ( a )  k20 m in double precision and ( b ) gtx  480 in single precision .",
    "[ fig : cusp - susparse],title=\"fig:\",scaledwidth=47.5% ]    again we show only the data for the extreme cases of k20 m in double precision ( left panel ) and gtx  480 in single precision ( right panel ) .",
    "the cusparse implementation turns out to be better optimized then cusp and our cmrs spmv kernel outperforms each of them for sufficiently large values of  @xmath65 .      to compare the computational efficiency of different spmv kernels , we adopt a convention that implementation @xmath127 is significantly faster than @xmath108 if and only if its execution time is at least 10% shorter .",
    "we found only one matrix ( ` kktpower ` ) for which the cusparse 5.5 crs is significantly faster than any other spmv kernel consider here .",
    "although for 26 matrices this kernel turns out significantly faster than our cmrs implementation , each of these matrices is characterized by a low number of nonzero elements per row and for such matrices the hyb kernel is usually even faster .",
    "a similar situation is observed for the scalar kernel , which is significantly faster than any other spmv kernel for only one matrix ( ` asia_osm ` ) .",
    "the cusp implementation is generally even less efficient than .",
    "we found no matrix for which the vector kernel is significantly faster than any other kernel .",
    "similar results were obtained for gtx  480 as well as for calculations in single precision .",
    "the most interesting is comparison of our algorithm with the cusparse 5.5 hyb implementation .",
    "we found hyb to be significantly faster than any implementation ( our implementation ) for 55 ( 58 ) matrices . on the other hand ,",
    "our implementation is significantly faster than any other ( hyb ) implementation for 29 ( 46 ) matrices .",
    "this is a good result , especially if one takes into account that the hyb implementation analyses the matrix structure and transforms it ( e.g.  by zero padding ) accordingly before the first spmv routine can be called on it . in sec .",
    "[ subsec : boost ] we shall examine how techniques like zero - padding could be used to further optimize the cmrs spmv kernel .",
    "note also that the currently available implementation of the hyb format has rather high memory requirements .",
    "for this reason the hyb implementation could not be run on gtx  480 for 14 largest matrices in double precision .    from fig .",
    "[ fig:3 ] it can be immediately seen that our cmrs implementation generally does not yield much improvement over the vector implementation for @xmath128 , and tends to be systematically slower than hyb for @xmath129 .",
    "hence one expects that the advantages of cmrs will be most pronounced for moderate values of @xmath65 .",
    "this is confirmed by fig .",
    "[ fig : best ] ,    ) , for k20 m and gtx 480 , in double and single precision .",
    "[ fig : best ] , title=\"fig:\",scaledwidth=47.5% ] ) , for k20 m and gtx 480 , in double and single precision .",
    "[ fig : best ] , title=\"fig:\",scaledwidth=47.5% ] ) , for k20 m and gtx 480 , in double and single precision .",
    "[ fig : best ] , title=\"fig:\",scaledwidth=47.5% ] ) , for k20 m and gtx 480 , in double and single precision .",
    "[ fig : best ] , title=\"fig:\",scaledwidth=47.5% ]    which depicts the speedup of our cmrs spmv implementation against the best of all five alternative spmv implementations considered here , calculated individually for each matrix , for the k20 m and gtx  480 gpus running in double and single precision mode . a striking similarity of the results obtained for different architectures and different matrix value representations indicates that the efficiency of an spmv kernel depends mainly on the matrix structure .",
    "it is also clear that the efficiency of our cmrs implementation in the most important case of the kepler architecture ( k20 m ) in double precision is @xmath130 worse than for the fermi architecture ( gtx  480 ) . in particular ,",
    "the largest speedup for k20 m and gtx  480 is 34% and 44% , respectively .",
    "we believe this is an effect of the bandwidth - occupancy relation in gpus , as discussed in sec .",
    "[ sub : optimal - choice ] .",
    "as might be expected , the cmrs format allows for even better acceleration of the spmv kernel if the calculations are performed in single precision .",
    "the maximum speedup is @xmath131 for k20 m and @xmath132 for gtx  480 , even though in the former case we used a smaller value of the cmrs strip height .",
    "we attribute this to the fact that the cusparse 5.5 csr kernel is apparently not well optimized for the kepler architecture in single precision ( data not shown ) .    since the spmv operation is memory - bound , efficiency of various implementations of this kernel",
    "can be compared using the memory utilization efficiency parameters @xmath133 , eq .",
    "( [ eq : def : eta ] ) .",
    "the results for all tested spmv kernels , gpu devices and matrix value representations , averaged over all tested matrices , are shown in fig .",
    "[ fig : eta ] .",
    "( left ) and @xmath134 ( right ) , as defined in eq .",
    "( [ eq : def : eta ] ) , for all tested spmv kernels , gpu devices and matrix value representations , as a function of @xmath65 .",
    "label `` best '' denotes the results for the most efficient of all 6 spmv kernels considered in this study , selected individually for each matrix .",
    "[ fig : eta],title=\"fig:\",scaledwidth=47.5% ]   ( left ) and @xmath134 ( right ) , as defined in eq .",
    "( [ eq : def : eta ] ) , for all tested spmv kernels , gpu devices and matrix value representations , as a function of @xmath65 .",
    "label `` best '' denotes the results for the most efficient of all 6 spmv kernels considered in this study , selected individually for each matrix .",
    "[ fig : eta],title=\"fig:\",scaledwidth=47.5% ]    we also included the results for a hypothetical kernel , denoted as `` best '' , in which the most optimal kernel is selected for a given sparse matrix ( in practice , this choice is limited to choosing between hyb and cmrs ) .",
    "these results confirm that the scalar kernel is very inefficient as a general - purpose spmv kernel , especially in the newer ( kepler ) architecture .",
    "optimization of the cusparse 5.5 csr kernel appears to be unsatisfactory for single precision arithmetics on k20 m .",
    "the best results , on average , are obtained for the cusparse 5.5 hyb and our cmrs implementation .",
    "note that if one used the best kernel for a given matrix , @xmath135 would rise to @xmath136 for double precision arithmetics on both fermi and kepler architectures , which a very good result .    since the value of @xmath137 is bounded from above by 1 , its value carries valuable information about the extent to which a kernel utilizes the hardware .",
    "its mean value for the best kernel is @xmath138 for both architectures , which again should be considered as a very good result .",
    "its value for individual matrices varies from @xmath139 for permutation matrices to @xmath140 for the ` af_shell10 ` sparse matrix and can be as high as @xmath141 for a dense @xmath142 matrix treated as a sparse one .",
    "a value of @xmath137 much smaller than 1 might be used as an indicator that a significant performance boost could probably be achieved through reordering of the matrix rows .      the basic cmrs format , as defined in sec .",
    "[ sec : cmrs ] , allows for a quick and straightforward conversion to and from the crs format without any memory overhead .",
    "can we relax these two conditions to allow for an even faster spmv kernel ?    a major issue with the implementation presented in sec .",
    "[ sec : implementation ] is that it requires each warp to reserve a ` warp_size`@xmath143`height ` data array in the shared memory , of which only ` warp_size ` elements are utilized simultaneously . in many cases most of the shared memory",
    "may never be used by the warp that controls it .",
    "the central problem is , however , that reducing the size of per - warp buffers in the shared memory would allow to increase the value of ` height ` , which , following eq .",
    "( [ eq : def - a ] ) , should result in a significant kernel performance boost .",
    "this problem can be coped with by changing the structure of the sparse matrix . here",
    "we briefly examine one such approach . in algorithm",
    "[ alg : cmrs ] the buffer is accessed always through the same pattern : ` buf[thread_lane , r ] ` . if we could replace it with ` buf[thread_lane m , r ] ` , where ` m ` @xmath144 ` warp_size ` , the size of each per - warp buffer could be reduced to ` m`@xmath143`height ` , i.e.  by a factor of ` warp_size`/`m ` . this will work provided that no threads in a warp can access the same buffer location simultaneously . in most cases",
    "this condition can be met by taking advantage of the fact that the cmrs format permits one to reorder the items in a strip arbitrarily : it suffices to arrange the items in such a way that each warp processes at most ` m ` items from a given row ` r ` and these items are stored contiguously in the array .",
    "such arrangement ensures that if the value of the row identifier ` r ` in ` buf[thread_lane m , r ] ` is the same for some threads , the values of the first indices into the buffer are different .",
    "such arrangement can be , however , impossible for some sparse matrices with highly variable row lengths , especially for small values of ` m ` .",
    "in such cases the matrices must be filled with explicit zeroes , which modifies the structure of the matrix internal representation .",
    "we examined numerically the case ` height ` = 16 and ` m ` = 8 , which requires the same buffer size as in the implementation analysed in the previous section for k20 m and double precision , but is characterized by a 4-fold larger value of the strip height . since the value of ` height ` is now relatively high so that each strip contains hundreds or even thousands of matrix elements , we also applied another optimization : all strips were padded with zeroes to ensure the number of matrix items they contain is a multiple of ` warp_size ` . in this way all memory accesses to arrays ` val ` and ` colind ` are fully coalesced .",
    "this comes at the cost of an additional modification of the internal matrix representation , which in some cases may result in a noticeable memory overhead . for 4 matrices ,",
    "the implementation considered here turned out to be significantly slower than that defined in sec .",
    "[ sec : implementation ] and we excluded them from further analysis .",
    "the results are shown in fig .",
    "[ fig : super - fast]a ,    ) , for k20 m in double precision .",
    "different symbols in panel ( a ) represent different levels of memory overhead related to padding the internal matrix representation with explicit zeroes .",
    "[ fig : super - fast],title=\"fig:\",scaledwidth=45.0% ] ) , for k20 m in double precision .",
    "different symbols in panel ( a ) represent different levels of memory overhead related to padding the internal matrix representation with explicit zeroes .",
    "[ fig : super - fast],title=\"fig:\",scaledwidth=45.0% ]    which corresponds directly to fig .",
    "[ fig : best]a . clearly , padding the cmrs matrix with explicit zeroes can result in a considerable shortening of the spmv execution time , especially for small values of @xmath65 , as expected from eq .",
    "( [ eq : def - a ] ) . for example the new algorithm turned out to be 3 times faster than the implementation presented in sec .",
    "[ sec : implementation ] for matrix ` mc2depi ` .",
    "our modified implementation is significantly faster than any of five alternative spmv kernels for 58 matrices , with the greatest relative speed - up reaching 1.63 for the matrix ` mac_econ_fwd500 ` , and significantly slower than an alternative solution for only 13 cases , the worst case being ` webbase-1 m ` for which the execution time relative to the hyb kernel is 0.68 .",
    "the average memory efficiency is @xmath145 and @xmath146 , c.f .",
    "[ fig : eta ] .",
    "note that the zero padding introduced a significant memory overhead only for some matrices with @xmath147 .",
    "thus , the main advantage of cmrs over hyb is that it allows for an efficient single - kernel implementation without a significant memory overhead .",
    "in contrast to this , hyb attempts to strike the balance between a format that is computationally efficient but often requires a prohibitive memory overhead ( ell ) and a format that imposes no memory overhead , but is computationally inefficient ( coo ) .    figure  [ fig : best]b shows the speedup of the modified algorithm over the vector kernel for sparse matrices in double precision on k20 m and compares it with the model , eq .",
    "( [ eq : def - a ] ) , with two values of @xmath119 .",
    "clearly , the fit is much better for @xmath124 .",
    "performance of many spmv kernels can be significantly improved by adjusting kernel optimization parameters to both the structure of the matrix and the hardware on which the kernel is to be executed @xcite .",
    "for example , vuduc @xcite showed an up to four - fold acceleration for modern cache - based superscalar machines .",
    "however , finding optimal optimization parameters is usually costly and hence is often performed `` off - line '' . in particular , choi et al .",
    "@xcite developed efficient autotuning techniques for their bellpack sparse matrix format and tested it on pre - fermi gpus .",
    "however , unlike bellpack , cmrs does not use explicit storage of dense blocks to compress the data structure and hence requires a different optimization strategy .    by comparing the default cmrs kernel times with those obtained for the same kernel launched with the optimal parameters determined by the brute - force search",
    ", we found that while the tuning of the default cmrs parameters is possible , it is not expected to give a spectacular performance boost .",
    "for example , the cmrs parameters could be tuned to speed up the kernel by at least 10% for only only 14 ( 16 ) test matrices on k20 m ( gtx 480 ) in double precision , and the maximum acceleration was 18% and 36% for k20 m and gtx  480 , respectively .",
    "our preliminary results presented in the previous section indicate that better results can be obtained by modifying the internal structure of the sparse matrix , e.g.  by a suitable zero - padding",
    ". further research on this issue is necessary .",
    "the cmrs format is designed specifically for optimizing the spmv operation on modern graphics processing units .",
    "it has several features distinguishing it from other formats developed for the same purpose : ( i )  it is an extension of a popular format , crs , with a quick and in - place conversion to and from it ; ( ii ) it has an efficient , single - kernel implementation ; ( iii ) it allows for dynamic assignment of threads to the matrix rows ; ( iv ) it does not _ require _ zero - padding , row reordering nor any other matrix transformations for good performance ; ( v ) it has a great potential for off - line optimization techniques , including zero - padding and row reordering , which improve its efficiency for extremely sparse matrices and can turn it into one of the most efficient spmv formats for gpus .",
    "property ( iii ) distinguishes cmrs from other derivatives of the crs format in which a warp processes more than one matrix row , while properties ( ii ) and ( v ) distinguish it from the hyb format .",
    "these features should facilitate its adoption in existing software and open new possibilities for its further optimization .",
    "moreover , the fact that our cmrs - based implementation of the spmv kernel often approaches the hardware limit suggests that this format will scale well into future gpu architectures .    the performance model of the cmrs spmv kernel , despite its simplicity ,",
    "turns out to fit the actual results of numerical experiments well .",
    "this indicates that the structure of typical sparse matrices from the uf smc is at least partially ordered  otherwise the spmv efficiency would be determined by indirect addressing of the input vector , a factor completely neglected in the model .",
    "the model explains the acceleration of the cmrs over the standard vector kernel .",
    "it also identifies the mean number of nonzero elements per row ( @xmath65 ) as a relevant parameter for the crs - based spmv kernels on gpus .",
    "the bandwidth efficiency @xmath148 ( or @xmath137 ) can be used to identify matrices for which further optimization is required as well as help determine the quality of hardware support for the spmv operation .",
    "our current implementations of the cmrs kernel are not without limitations .",
    "the column index is stored on only 28 bits , which might prove insufficient for future devices with larger amounts of memory .",
    "however , applications usually store much more data than just a single sparse matrix . for example",
    ", a gpu - based computational fluid dynamics solver may require @xmath149 bytes of storage per each column of several of its sparse matrices @xcite , which corresponds to the memory threshold at @xmath150  b  @xmath151  gb , far above the 12  gb available in modern accelerators .",
    "consequently , compression of the column index should not become a serious problem very soon .",
    "a much more serious problem is related to the fact that cmrs is inherently limited by the amount of the shared memory per multiprocessor . while in most cases",
    "this can be circumvented by a suitable matrix transformation , as explained in sec .",
    "[ subsec : boost ] , its efficient usage on kepler - class gpus for matrices with values occupying more than 8 bytes , e.g. , double precision complex numbers , may be problematic .",
    "it is also not clear whether cmrs can be efficiently implemented on architectures lacking a programmable , on - chip shared memory buffer . moreover , cmrs requires the matrix to be sufficiently large .",
    "further research is also required to find the best `` off - line '' cmrs matrix optimization strategy  while our preliminary results with zero - padding are very encouraging , our approach is rather complex and is not universal .",
    "finally , our results reveal the importance of developing a representative collection ( or collections ) of sparse matrices for which the spmv product is a truly relevant operation .",
    "the uf smc contains some very unusual matrices for which the spmv product is unlikely to be applicable , e.g.  matrices with empty rows or columns .",
    "such atypical matrices can obfuscate the general picture of the spmv performance and its dependence on the matrix format and techniques used to implement it .",
    "zk and mm prepared this publication as part of the project of the city of wrocaw , entitled `` green transfer ''  academia - to - business knowledge transfer project co - financed by the european union under the european social fund , under the operational programme human capital ( op hc ) : sub - measure 8.2.1 .",
    "ss acknowledges support from polish ministry of science and higher education grant no .",
    "n n519 437939",
    ".    10    , _ efficient sparse matrix - vector multiplication on cuda _ , nvidia technical report nvr-2008 - 004 , nvidia corporation , dec . 2008 .    height 2pt depth -1.6pt width 23pt , _ implementing sparse matrix - vector multiplication on throughput - oriented processors _ , in sc09 : proceedings of the conference on high performance computing networking , storage and analysis , new york , ny , usa , 2009 , acm , pp .",
    "height 2pt depth -1.6pt width 23pt , _ cusp : a c++ templated sparse matrix library _ , 2012 .",
    "version 0.3.0 .    , _ optimizing sparse matrix - vector multiplication on gpus _ , tech .",
    "report rc24704 , imb research , april 2008 .",
    ", _ model - driven autotuning of sparse matrix - vector multiply on gpus _ , sigplan not . , 45 ( 2010 ) ,",
    "115126 .    , _ the university of florida sparse matrix collection _ ,",
    "acm trans .",
    "softw . , 38 ( 2011 ) , pp",
    ".  1:11:25 .    , _ an implementation of the conjugate gradient algorithm on fpgas _ , in fccm 08 : proceedings of the 2008 16th international symposium on field - programmable custom computing machines , washington , dc , usa , 2008 , ieee computer society , pp .",
    "296297 .    , _ sparse matrix - vector multiplication on a reconfigurable supercomputer _ ,",
    "field - programmable custom computing machines , annual ieee symposium on , ( 2008 ) , pp .",
    "239247 .    , _ a memory efficient and fast sparse matrix vector product on a gpu _ , progress in electromagnetics research , 116 ( 2011 ) , pp .",
    "4963 .    , _ cuda application design and development _ , morgan kaufmann , 1  ed . , 2011 .    ,",
    "_ optimization of sparse matrix - vector multiplication with variant csr on gpus _ , in parallel and distributed systems ( icpads ) , 2011 ieee 17th international conference on , ieee , 2011 , pp .",
    "165172 .    , _ sparse matrix computations on manycore gpus _ , in dac 08 : proceedings of the 45th annual conference on design automation , new york , ny , usa , 2008 , acm , pp .",
    "_ automatically generating and tuning gpu code for sparse matrix - vector multiplication from a high - level representation _ , in gpgpu-4 , proceedings of the fourth workshop on general purpose processing on graphics pro - cessing units ( gpgpu2011 ) , acm , 2011 , p.  12 .",
    ", _ efficient sparse matrix - vector multiplication on x86-based many - core processors _ , in proceedings of the 27th international acm conference on international conference on supercomputing , ics 13 , new york , ny , usa , 2013 , acm , pp .",
    "273282 .    , _ an architecture - aware technique for optimizing sparse matrix - vector multiplication on gpus _ , procedia computer science , 18 ( 2013 ) , pp .  329  338 .    , _ gpu - based simulation of 3d blood flow in abdominal aorta using openfoam _ , arch .",
    "mech . , 63 ( 2011 ) , pp .",
    "137161 .    , _ automatically tuning sparse matrix - vector multiplication for gpu architectures _ , in high performance embedded architectures and compilers , y.  patt , p.  foglia , e.  duesterwald , p.  faraboschi , and x.  martorell , eds . , vol .",
    "5952 of lecture notes in comput .",
    "sci . , springer berlin / heidelberg , 2010 , pp .",
    "10.1007/978 - 3 - 642 - 11515 - 8_10 .    ,",
    "_ optimization of sparse matrix - vector multiplication for crs format on nvidia kepler architecture gpus _ , in computational science and its applications ",
    "iccsa 2013 , b.  murgante , s.  misra , m.  carlini , c.  m. torre , h .- q .",
    "nguyen , d.  taniar , b.  o. apduhan , and o.  gervasi , eds .",
    "7975 of lecture notes in computer science , springer berlin heidelberg , 2013 , pp .  211223 .    , _ cuda c programming guide version 5.5 _ , may 2013 .    ,",
    "_ performance evaluation of sparse matrix multiplication kernels on intel xeon phi_. arxiv:1302.1078 [ cs.pf ] , 2013 .    , _ acceleration of iterative navier - stokes solvers on graphics processing units _ ,",
    "j. comput .",
    "fluid dyn . , 27 ( 2013 ) , pp .",
    "201209 .    , _ automatic tuning of the sparse matrix vector product on gpus based on the ellr - t approach _ , parallel comput .",
    ", 38 ( 2012 ) , pp .  408420 .",
    ", _ accelerating sparse matrix vector product with gpus _ , in proceedings of the international conference on computational and mathematical methods in science and engineering ( cmmse 2009 ) , cmmse , 2009 , pp .",
    "10811092 .    ,",
    "_ improving the performance of the sparse matrix vector product with gpus _ , in 2010 10th ieee international conference on computer and information technology ( cit 2010 ) , ieee computer society , 2010 , pp .  11461151 .    , _ oski : a library of automatically tuned sparse matrix kernels _ , journal of physics : conference series , 16 ( 2005 ) , p.  521 .",
    ", _ automatic performance tuning of sparse matrix kernels _ , phd thesis , university of california , berkeley , 2003 .    ,",
    "_ optimization of sparse matrix - vector multiplication on emerging multicore platforms _ , in sc 07 : proceedings of the 2007 acm / ieee conference on supercomputing , new york , ny , usa , 2007 , acm , pp .",
    "112 .    , _ fast sparse matrix - vector multiplication on gpus : implications for graph mining _ , proceedings of the vldb endowment , 4 ( 2011 ) , pp .",
    "231242 .    , _ automatic tuning of sparse matrix - vector multiplication for crs format on gpus _ , 2012 ieee 15th international conference on computational science and engineering , 0 ( 2012 ) , pp .",
    "130136 .    additional material",
    "let @xmath62 denote the size of the memory chunk ( in bytes ) to be accessed by a device that communicates with the global memory only through aligned memory segments of @xmath61 bytes .",
    "for the spmv kernel the value of @xmath62 is a multiple of @xmath152 ( the size of the data items stored in the chunk ) and @xmath153 is a multiple of 32 on modern gpus ( nvidia suggests @xmath154 for @xmath59 ) .",
    "moreover , the chunk is aligned to @xmath155 bytes ( see fig .  [",
    "fig : add - model_explained ] ) .",
    "let also assume that the number of memory transactions necessary to access the memory chunk is equal to the minimum number of segments covering it .",
    "consecutive bytes made up of @xmath155-byte long words , this request is serviced by the l2 cache ( middle ) , which is serviced by the main memory only through @xmath61-byte - long , @xmath61-byte - aligned memory segments . if the requested chunk is located randomly relative to the segment boundaries , such an access pattern leads to the bandwidth waste and low kernel efficiency , unless @xmath156 . ]",
    "let @xmath157 , where @xmath158 are integers , @xmath159 .",
    "if the beginning of the @xmath155-byte - aligned chunk is located randomly relative to the memory segment boundaries , then the number of distinct memory segments is @xmath160 with probability @xmath161 and @xmath162 with probability @xmath163 .",
    "thus , the expected number of memory segments accessed by the chunk is @xmath164 consequently , the ratio of the bytes transferred , @xmath165 , to the bytes actually requested , @xmath62 , is @xmath166 substituting @xmath167 , one arrives at ( [ eq : def - f ] ) .",
    "note that the spmv kernel actually transfers several independent streams of data , but for each of them eq .",
    "( 5.1 ) predicts the same bandwidth efficiency .",
    "this justifies the usage of this equation for the spmv kernel .",
    "the basic crs kernel is implemented as a a device function // to facilitate experiments with dynamically vs. statically allocated shared memory template < int height , typename t ,   bool use_texture , bool align_data > _ _ device _ _ inline void device_cmrs_multiply_original (    const t * const _ _ restrict _ _ x ,   // input vector    const int *      const _ _ restrict _ _ stripe_offset ,    const int *      const _ _ restrict _ _",
    "col_idx ,    const t * const _ _ restrict _ _ a ,   //",
    "matrix values    t *       const _ _ restrict _ _ r ,   //",
    "result vector    unsigned        const num_rows ,    t    volatile * ptr   // pointer to shared memory ) {    const int thread_id    = blockdim.x * blockidx.x + threadidx.x ;    const int warp_id      = thread_id / warp_size ;    const int thread_lane = threadidx.x & ( warp_size-1 ) ;    const int num_warps    = ( ( blockdim.x + warp_size - 1 ) / warp_size ) * griddim.x ;      // a warp can process several strips to balance their sizes    for(int stripe = warp_id ; stripe*height < num_rows ; stripe + = num_warps )    {      for(int k = 0 ; k < height ; k++ )        ptr[thread_lane + warp_size*k ] = 0 ;        const int stripe_start = stripe_offset[stripe ] ;      const int stripe_end    = stripe_offset[stripe + 1 ] ;      //",
    "stripe_mid is used only if align_data = = true      const int stripe_mid    = align_data ?",
    "min(stripe_end , stripe_start - ( stripe_start & 31 ) + 32 ) : stripe_start ;        // this attempts to read unaligned portion of the strip      if ( align_data )      {        int j = stripe_start + thread_lane ;        if ( j < stripe_mid )        {          int c = col_idx[j ] ;          int r = c % cmrs_max_height ; //",
    "we use cmrs_max_height = = 16          c > > = cmrs_bits ;   // we use cmrs_bits = = 4",
    "// macro fetch_x reads from an array directly or via one of the caches          t xx = fetch_x <",
    "use_texture>(c , x ) ; //",
    "xx = x[c ] ;          xx * = a[j ] ;          r + = height * thread_lane ;          ptr[r ] + = xx ;        }      }        //",
    "standard cmrs loop      for(int j = stripe_mid + thread_lane ; j < stripe_end ; j + = warp_size )      {        int c = col_idx[j ] ;        int r = c % cmrs_max_height ; //",
    "we use cmrs_max_height = 16        c > > = cmrs_bits ; // we use cmrs_bits = = 4        t xx = fetch_x < use_texture>(c , x ) ; // xx = x[c ] ;        xx * = a[j ] ;        r + = height * thread_lane ;        ptr[r ] + = xx ;      }        // now the parallel reduction for arbitrary 1 < = height < = 16      //",
    "we assume warp_size = = 32        t z = ptr[thread_lane ] ; // not sure if this register helps ...    // # 1      ptr[thread_lane ]    + = ptr[thread_lane + height*16 ] ;      if ( height > = 4 or ( height = = 3 & & thread_lane < 16 ) )         ptr[thread_lane + 1 * 32 ]    + = ptr[thread_lane + height*16 + 1 * 32 ] ;      if ( height > = 6 or ( height = = 5 & & thread_lane < 16 ) )        ptr[thread_lane + 2 * 32 ]    + = ptr[thread_lane + height*16 + 2 * 32 ] ;      if ( height > = 8 or ( height = = 7 & & thread_lane < 16 ) )        ptr[thread_lane + 3 * 32 ]    + = ptr[thread_lane + height*16 + 3 * 32 ] ;      if ( height > = 10 or ( height = = 9 & & thread_lane < 16 ) )        ptr[thread_lane + 4 * 32 ]    + = ptr[thread_lane + height*16 + 4 * 32 ] ;      if ( height > = 12 or ( height = = 11 & & thread_lane < 16 ) )        ptr[thread_lane + 5 * 32 ]    + = ptr[thread_lane + height*16 + 5 * 32 ] ;      if ( height > = 14 or ( height = = 13 & & thread_lane < 16 ) )        ptr[thread_lane + 6 * 32 ]    + = ptr[thread_lane + height*16 + 6 * 32 ] ;      if ( height > = 16 or ( height = = 15 & & thread_lane < 16 ) )        ptr[thread_lane + 7 * 32 ]    + = ptr[thread_lane + height*16 + 7 * 32 ] ;     // # 2      ptr[thread_lane ]           + = ptr[thread_lane + height*8 ] ;      if ( height > = 5 )        ptr[thread_lane + 1 * 32 ]    + = ptr[thread_lane + height*8 + 1 * 32 ] ;      if ( height > = 9 )        ptr[thread_lane + 2 * 32 ]    + = ptr[thread_lane + height*8 + 2 * 32 ] ;      if ( height > = 13 )        ptr[thread_lane + 3 * 32 ]    + = ptr[thread_lane + height*8 + 3 * 32 ] ;    // # 3      ptr[thread_lane ]    + = ptr[thread_lane + height*4 ] ;      if ( height > = 9 )        ptr[thread_lane + 1 * 32 ]    + = ptr[thread_lane + height*4 + 1 * 32 ] ;    // # 4       z =   ptr[thread_lane ]    + = ptr[thread_lane + height*2 ] ;    // # 5       z   + = ptr[thread_lane + height ] ;        // write the results      int row = stripe*height + thread_lane ;      if ( thread_lane < height & & row < num_rows )      {        r[row ] = z ;      }    } } ....",
    ".... template < int modulo , bool use_texture , typename t > _ _ global _ _ void cmrs_multiply (    const t    * const _ _ restrict    x ,     // input vector    const int * const _ _ restrict _ _ stripe_offset ,   // strip offset , see the paper    const int * const _ _ restrict _ _ col_idx ,",
    "// contains colind and rowinstrip arrays , see the paper    const    t * const _ _ restrict _ _ a ,     //",
    "matrix values    t * const _ _ restrict _ _ r ,     //",
    "result vector    unsigned   const               num_rows ) {    const int height = 16 ;   //",
    "fixed strip height    const int asize = height*modulo ;   // size of warp - owned array in shared memory            const int thread_id    = blockdim.x * blockidx.x + threadidx.x ;    const int warp_id      = thread_id / warp_size ;    const int thread_lane = threadidx.x % warp_size ;    const int num_warps    = ( ( blockdim.x + warp_size - 1 ) / warp_size ) * griddim.x ;      for(int stripe = warp_id ; stripe*height < num_rows ; stripe + = num_warps )    {      // let 's zero the local buffer      if ( modulo > 1 )      { # pragma unroll        for(int k = 0 ; k < modulo/2 ; k++ )        {          ptr[thread_lane + warp_size*k ] = 0 ;        }      }      else      {         if ( thread_lane < height )           ptr[thread_lane ] = 0 ;      }          for(int j = stripe_start + thread_lane ; j < stripe_end ; j + = warp_size )      {        int c = col_idx[j ] ;        int r = c % cmrs_max_height ;   // we use cmrs_max_height = = 16 = = 2**4        c >",
    "> = cmrs_bits ;               // we use cmrs_bits = = 4            // now the parallel reduction of the data pointed by ptr .      //",
    "the size of the array pointed by ptr depends on modulo , hence many conditionals .      //",
    "in the paper we use modulo = 8 , sometimes 4 and 2 .      //",
    "modulo = 1 , 16 and 32 were used in tests and are also supported below .      //",
    "caveat : nvidia discourages the coding style that neglects _ _ syncthreads ( )      //    and relies on implicit inter - warp thread synchronization in future architectures .            if ( modulo = = 32 )      {        ptr[thread_lane ]         + = ptr[thread_lane + height*16 ] ;        ptr[thread_lane + 1 * 32 ] + = ptr[thread_lane + height*16 + 1 * 32 ] ;        ptr[thread_lane + 2 * 32 ] + = ptr[thread_lane + height*16 + 2 * 32 ] ;        ptr[thread_lane + 3 * 32 ] + = ptr[thread_lane + height*16 + 3 * 32 ] ;        ptr[thread_lane + 4 * 32 ] + = ptr[thread_lane + height*16 + 4 * 32 ] ;        ptr[thread_lane + 5 * 32 ] + = ptr[thread_lane + height*16 + 5 * 32 ] ;        ptr[thread_lane + 6 * 32 ] + = ptr[thread_lane + height*16 + 6 * 32 ] ;        ptr[thread_lane + 7 * 32 ] + = ptr[thread_lane + height*16 + 7 * 32 ] ;      }        if ( modulo > 8)      {        ptr[thread_lane ]         + = ptr[thread_lane + height*8 ] ;        ptr[thread_lane + 1 * 32 ] + = ptr[thread_lane + height*8 + 1 * 32 ] ;        ptr[thread_lane + 2 * 32 ] + = ptr[thread_lane + height*8 + 2 * 32 ] ;        ptr[thread_lane + 3 * 32 ] + = ptr[thread_lane + height*8 + 3 * 32 ] ;      }        // here starts the parallel reduction for modulo==8 , as used in the paper      if ( modulo > 4 )      {        ptr[thread_lane ]         + = ptr[thread_lane + height*4 ] ;        ptr[thread_lane + 1 * 32 ] + = ptr[thread_lane + height*4 + 1 * 32 ] ;      }"
  ],
  "abstract_text": [
    "<S> a new format for storing sparse matrices is proposed for efficient sparse matrix - vector ( spmv ) product calculation on modern graphics processing units ( gpus ) . </S>",
    "<S> this format extends the standard compressed row storage ( crs ) format and can be quickly converted to and from it . </S>",
    "<S> computational performance of two spmv kernels for the new format is determined for over 130 sparse matrices on fermi - class and kepler - class gpus and compared with that of five existing generic algorithms and industrial implementations , including nvidia cusparse csr and hyb kernels . </S>",
    "<S> we found the speedup of up to @xmath0 over the best of the five alternative kernels .    </S>",
    "<S> spmv , crs format , csr format , cuda , hardware accelerators    65f50 , 65y10 </S>"
  ]
}