{
  "article_text": [
    "free - recall experiments are one of the key tools for the controlled investigation of episodic memory . in a typical free - recall experiment ,",
    "a list of words is presented to a subject who is then asked to recall them in any order .",
    "a key variable is the difference between the positions of two consecutively recalled words , called a `` lag '' .",
    "e.g. , if the @xmath0th word in the list is remembered right after the @xmath1th , the corresponding lag is @xmath2 ( kahana , 2012 ) .",
    "a large database of free - recall data has been recently assembled for the university of pennsylvania electrophysiology of encoding and retrieval study .",
    "collapsing the data described in lohnas et al .",
    "( 2015 ) with those described in healey and kahana ( 2016 ) yields a total of @xmath3 free - recall trials , all performed with lists of @xmath4 words .",
    "the wordpool from which the lists were assembled contains @xmath5 words of up to @xmath6 syllables .",
    "my analysis of this database has revealed three word - length related features , displayed in figure 1 :    \\(1 ) the average lag through which a word is recalled is an increasing function of its length ;    \\(2 ) the probability @xmath7 that , if a word of length @xmath8 is retrieved , it is retrieved with a lag @xmath9 depends strongly on @xmath8 only for @xmath10 ( `` sequential '' recall ) ;    \\(3 ) the average recall probability of words from a given list is an increasing function of their length ( this fact was first reported by katkov et al . , 2014 )",
    ".    observations ( 1 ) and ( 2 ) entail that @xmath11 is a decreasing function of @xmath8 , as previously reported in ( fumarola , 2016 ) .",
    "[ fig1 ]    over the last two decades ,",
    "experimental results have pushed psychological research toward the idea that word length may not affect free recall directly , but as a statistical indicator of other word properties ( neath et al .",
    ", 2003 ; campoy , 2008 ; jalbert et al . , 2011 ) .",
    "recent fmri measurements ( musz and thompson - schill , 2015 ) have shown that the typical neural response to the presentation of a word exhibits a strong statistical dependence on the word s `` polysemy ''  the variability of the word s meaning with context .",
    "if the polysemy of a word affects importantly its perception at the neural level , one would suppose that it may also affect our ability to memorize it and recall it .",
    "in a suspicious coincidence , word length happens to be a strong statistical indicator of polysemy ; more specifically , a word s length is known to correlate negatively with its number of meanings .",
    "this has been proven in a host of languages ranging from french to maori ( zipf , 1949 ; guiter , 1974 ; sambor , 1984 ; rother , 1994 ) .",
    "the aim of this paper is to show that the phenomena listed above are interdependent components of a single `` polysemy effect '' , born out of a mechanism through which the semantic variability of input enforces our chronological memory . in the next section ,",
    "i will begin by defining a simple mathematical model of polysemy .",
    "i will then use it to simulate the various stages of a standard free - recall experiment .",
    "all the experimental observations i mentioned above will be reproduced and justified by the model . at last",
    ", some general conclusions will be drawn on the role of chronology in memory - storage processes .",
    "a graph representation of neural attractors has recently allowed for a quantitative understanding of some key features of associative recall ( romani et al . , 2013 ) , and would therefore be a natural approach to our problem .",
    "i will focus here on the general properties that the system of attractors must satisfy in order to reproduce the experimental results , postponing to future work the identification of networks with the attractor structure i will demonstrate .",
    "this task is facilitated by the knowledge garnered over the last two decades in the field of verbal recall . as was first proven through retrieved - context theories ( howard and kahana , 2002 )",
    ", the object of verbal retrieval in episodic memory is never the word itself , but rather the `` context '' corresponding to its presentation .",
    "the attractor graph , therefore , has to include both a set of verbal nodes ( the various meanings of each word ) and a set of nonverbal nodes that provide the contextual `` bath '' in which verbal meanings are immersed .",
    "we may call the latter a `` contextual reservoir '' .",
    "i will consider here the case where the reservoir is a circular graph , and each word is linked to two contextual states .",
    "a word can then only be monosemous or bisemous : a monosemous word has a single meaning linked to two `` contexts '' of the reservoir , while a bisemous word is linked to two contexts through two different meanings .",
    "these two types of word can be interpreted as corresponding to different word - lengths ( or syllable counts ) with the bisemous words being shorter .",
    "( this is a simplified variant of the lattice model of ( fumarola , 2016 ) .",
    "some of the results i will obtain replicate results from the lattice version . )    [ fig2 ]    suppose the vocabulary contains @xmath12 short words and @xmath12 long words .",
    "since each long word is represented by a single node and each short word by @xmath13 nodes , there are @xmath14 verbal nodes , connected to the reservoir through @xmath15 links .",
    "if every site of the reservoir is connected to one verbal node , the full graph ( including both the reservoir and the verbal nodes ) contains @xmath16 nodes .",
    "observables must be predicted by averaging over all inequivalent graph configurations corresponding to the same value of @xmath12 , of which there are @xmath17 $ ] .",
    "figure 1 displays one of the configurations for @xmath18 .",
    "all thought process is represented as a simple random walk on the graph , where the graph s edges are undirected and have all the same weight .",
    "once a word has been presented , the system will recognize it only when it chances upon any of the verbal nodes associated to it .",
    "a memory trace is conserved in all nodes visited recently , where `` recently '' means within a time lapse longer than the duration of a typical free - recall experiment .    to simulate free - recall experiments ,",
    "i submit word - lists that are permutations of the full vocabulary . by discounting permutations of words of the same type within the vocabulary",
    ", it is sufficient to check @xmath19 inequivalent lists .",
    "the initial location of the system is a random site in the circular reservoir ; each time a new word is presented , the process random - walks until it recognizes the word , and only then the next word is presented .",
    "thus verbal memories are formed .",
    "experimentally , the memory test begins after a delay of several seconds from the end of the presentation stage .",
    "accordingly , i reset the position of the system at random before starting a new random walk whose purpose is to retrieve memories .",
    "this amounts to ignoring recency effects ( murdock , 1962 ) .",
    "memories are retrieved in the order in which they are encountered .",
    "when no new memory is encountered for a maximal time @xmath20 , the retrieval process comes to an end .",
    "the maximal inter - response time @xmath20 and the half - size @xmath12 of the vocabulary are the only free parameters in the model .",
    "[ fig3 ]    the upper left panel of fig .",
    "3 displays a typical example of the distribution of transition probabilities , computed numerically for @xmath21 and @xmath22 .",
    "its most conspicuous feature is the emergence , for short words , of one of the universal features of free - recall data ( kahana , 2012 ) : the `` sequential peak '' , i.e. , a sharp peak in correspondence of the lag @xmath10 .",
    "this is the same peak we noticed in the distribution in the lower panel of fig . 1 .",
    "i mentioned that only for @xmath23 the transition probability exhibits a strong dependence on length , and this is readily seen from the lower panel of fig .",
    "1 . in the upper - left panel of fig .",
    "3 , we find that the same is true in the simulations ( with the sole difference that there are now two word lengths ) .",
    "the probabilities of transitions between words during the recall process approach steady asymptotes for @xmath24 . in the upper - right panel of fig .",
    "3 , i show the asymptotic values of @xmath25 ( i.e. of the sequential transition probability ) as functions of the number @xmath12 of short and long words in the vocabulary .",
    "while both curves decrease , the short - word curve lies always above the long - word curve .",
    "this , too , replicates the experiments  the lower panel of fig . 1  where the probability that a word is recalled sequentially decreases with its length .    the lower left panel of fig .",
    "3 shows the values of the average recall probabilities for short and long words , plotted as functions of @xmath20 , for two representative values of @xmath12 .",
    "increasing @xmath12 while keeping @xmath20 fixed decreases both probabilities , but their comparative magnitudes remain in the same order , i.e. , long words are systematically easier to recall .",
    "this is just another of the observations we made from experimental data , discernible in the upper left panel of fig . 1",
    ".    the lower right panel of fig .",
    "3 shows the absolute value @xmath26 of the lag , averaged over transitions in which short or long words are recalled .",
    "@xmath27 tends to a steady asymptote for large @xmath20 , and this is the value plotted in the figure ( normalized by the number of words in the lists , which is @xmath28 ) .",
    "the mean lag for short words is always longer , precisely as we had found in the upper right panel of fig . 1 .",
    "we may conclude that , in spite of the model s simplicity , its agreement with the experimental data is substantial .",
    "we can also grasp intuitively , in terms of polysemy , why sequential transitions are favored for short words .",
    "since each short word we present has multiple meanings , the system is likely to give it the meaning closest at hand , which depends on the system s current position ",
    "mostly , on the last word presented .",
    "a short - word memory tends therefore to cluster with the word - memory that precedes it ; this enhances the sequential recall of a short word , whether it is preceded by a long word or by another short word .",
    "the enhancement of backward contiguous transitions is less relevant for two reasons : first , because a word only clusters with the word that follows if that word is a short word , which makes the effect at @xmath29 smaller than the effect at @xmath10 ; second , because the backward contiguous recall of short and long words are enhanced to the same extent whenever they are followed by a short word , i.e. , the effect acts equally on words of different length .",
    "the first conceptual result of the above is a new way of understanding the observed asymmetry of recall data with respect to the direction of time during the presentation process , that is , the asymmetry of the distribution in the lower panel of fig . 1 around @xmath30 .",
    "suppose that all words were monosemous .",
    "the retrieval process would then be independent on the system s history during presentation , and would only depend on the structure of the list .",
    "the distribution of transition probabilities could then be calculated from first principles and would be @xmath31 , where @xmath32 is the length of the lists .",
    "this is completely invariant under the reversal operation @xmath33 .",
    "therefore , if we used an ideal language in which all words have a single meaning , our verbal memory would be invariant under the inversion of the time arrow , and the plot in the lower panel of fig",
    ". 1 would be perfectly symmetric . by introducing some degree of polysemy",
    ", we force the receiver of verbal input to choose one of many possible understandings , and this process is intrinsically irreversible .",
    "semantic ambiguities are thus found to play the same role that the multiplicity of microscopic configurations plays in thermodynamics .",
    "a thermodynamic system can behave irreversibly because each of its macroscopic states can correspond to multiple microscopic configurations . in our model ,",
    "words function as `` macroscopic '' observables , meanings as `` microscopically '' defined states .",
    "the psychological interpretation of this finding is clear . during a purely receptive task the intensity of time s flow",
    "is proportional to our hermeneutic freedom .",
    "the relationship between polysemy and irreversibility may be understood as implementing a principle of least effort ( zipf , 1949 ) : we do nt need to remember the chronology where it does not play a role in determining the meaning of events .      in experiments ,",
    "the asymmetry parameter @xmath34 has the value @xmath35 if contiguous transitions ( @xmath36 ) are counted in , and @xmath37 if they are excluded .",
    "the same qualitative behavior is found in simulations , e.g. for @xmath18 we find @xmath38 and @xmath39 .",
    "hence , ignoring contiguous transitions is enough to eliminate the forward asymmetry completely , both in simulations and experiments , leaving in fact a slight degree of backward asymmetry .",
    "thus , information on the chronology is stored almost entirely in the sequential peak ( the peak in transition probabilities corresponding to @xmath10 ) .",
    "all conscious observation of a polysemous sensorial input may be modeled similarly , and forward asymmetry will arise likewise .",
    "we expect therefore that , when we are paying attention to consecutive events , the corresponding memories will be stored in such a way that the chronological order is the most probable order of recall",
    ". we will refer to this fact as `` sequentiality '' .",
    "suppose that a logical discourse , e.g. a narrative , is interrupted abruptly and immediately followed by a random word . instinctively , we will try to fit the meaning of the word into the ongoing narrative .",
    "our ease in doing so will depend on the particular word .",
    "short words allow for a wider semantic choice , so they are easier to fit into an existing narrative , while long words have fixed meanings , probably difficult to graft coherently into the current narrative . with a long word ,",
    "therefore , our mind perceives a `` change of scenery '' , and assumes that a _ new _ narrative is beginning .",
    "( for more on this argument , see fumarola , 2016 ) .",
    "this is precisely what we found to happen within the model .",
    "since @xmath40 is a decreasing function of @xmath8 , episodic memory will break each list into multiple `` narratives '' , and long words will tend to correspond to the points of fragmentation of the list .",
    "the probability peak at @xmath41 tends to guide the recall process through each narrative from start to finish .",
    "then it surrenders the command back to free association , allowing associative mechanisms to decide which narrative will be recalled next .",
    "it is not completely obvious that sequentiality is the optimal way to preserve chronological information .",
    "after all , even where information was stored sequentially , the retrieval process has a finite probability of occurring in non - chronological orders .",
    "moreover , even without the peak , the system may still be able to assess in what order the events occurred  through some computation on the probability landscape encountered in the region of semantic space where the presentation procedure has taken place .    if the chronological order is the `` most '' probable , however , the system has a particularly simple way of singling it out with arbitrary accuracy .",
    "it is sufficient to re - explore the same contextual area a large number of times , and choose the ordering of memories that has been experienced most often during this re - exploration .",
    "the more strictly `` sequential '' our memory storage is ( i.e. the larger @xmath25 ) , the less time we will take to perform the iterative sampling needed to establish a chronology with arbitrary accuracy . this procedure may act as a probabilistic version of the long - term enhancement of the principal eigenvector that plays a similar role in neural networks .      a final question ( whose answer i will merely sketch ) is what determines the precise height of the sequential peak .",
    "if the sequential peak is too low , the number of iterations needed to find the most probable ordering will become large , and the iterative sampling procedure slow .",
    "devoting more than a fraction of a second to ordering any sequence of past events may be impractical .    if , on the contrary , the sequential peak is too high , all associative retrieval of a memory will be blocked .",
    "that follows from the normalization of probabilities .",
    "when a memory can only be accessed chronologically , it is consequently not available for associative reasoning  comparisons , deductions  and becomes useless for most conceivable purposes .",
    "thus , sequentiality and retrievability are in conflict and a trade - off between the two requirements is necessary .",
    "a memory must stay available for associative reasoning , and yet its chronology needs to be trackable through iterative sampling . from these two constraints , the optimal value of the @xmath42 is determined .",
    "this optimization process will depend on the use we make of a given memory .",
    "some memories are meaningless without their chronology , others are just as useful without .",
    "we have seen here an example of this . after splitting a word list into separate narratives",
    ", our model adheres to the policy that the chronology of events within a narrative is more important than the ordering of the various narratives , and it stores memories accordingly .",
    "if the links in the contextual graph can be created and destroyed over time , the optimization process will be dynamical .",
    "the degree of sequentiality of a memory may decrease over time or stay constant .",
    "of course it can be ruled out , statistically , that it will increase back toward its original value .",
    "chronological information obeys the entropic principle , and if we call @xmath43 the time that iterative sampling needs to provides the correct chronology for a set of memories , we may write @xmath44 .    a memory that hasnt yet been overwritten by the time it loses its chronology is , by definition , no longer episodic and de facto transitioning into long - term memory .",
    "the existence of a polysemy effect in free recall has been proven through the analysis of data from the experiments of lohnas et al .",
    "( 2015 ) and healey and kahana ( 2016 ) .",
    "three word - length features were observed : ( 1 ) the average distance between the serial positions of consecutively recalled words is an increasing function of the second word s length ; ( 2 ) the recall of words in the order in which they were presented is more likely to occur for shorter words ; ( 3 ) longer words are easier to recall than shorter words from the same list .",
    "the well - documented fact that shorter words have a larger number of meanings allowed to build a simple model for these phenomena . within the model ,",
    "long words are easier to recall because their single meaning is more easily accessible during the retrieval process .",
    "short words are distributed more widely in semantic space , and the meaning we assign to them during presentation is accordingly harder to retrieve .    our ability to choose among various meanings results also in a higher probability to recall words in the order in which they were presented .",
    "this is analogous to the mechanism that makes macroscopic motion irreversible in thermodynamics .",
    "short words , having a larger number of meanings , exhibit this tendency toward sequential recall to a greater degree .",
    "the probability peak at sequential transitions has a crucial cognitive function .",
    "it allows to reconstruct the chronology of past events , which would otherwise be lost .",
    "this could be done with arbitrary accuracy through a process of iterative sampling , by exploring multiple times the region of semantic space where the memories are stored , and by choosing the ordering that occurs most often .",
    "the sequential peak , however , must not be too high or it would hinder associative operations .",
    "future experimental work may provide a much better understanding of the polysemy effect .",
    "for instance , we have argued that the polysemy effect has no direct connection to the phonology or duration of words .",
    "experiments with words that are outliers in the polysemy / word - length scatter plot would provide a definitive test of this assumption .",
    "the concept of orthographic neighborhood ( on which experiments have been carried out by jalbert et al . , 2011 ) grades almost continuously into the notion of polysemy",
    ". words with a large orthographic neighborhood , therefore , may behave just like polysemous words where sequentiality is concerned .",
    "this , too , should be the object of further study .",
    "i would like to thank michael j. kahana , of the university of pennsylvania , for generously sharing the data obtained in his laboratory .",
    "campoy g. ( 2008 ) . the effect of word length in short - term memory : is rehearsal necessary ?",
    "quarterly journal of experimental psychology , 61:5 , 724 - 734 ."
  ],
  "abstract_text": [
    "<S> the existence of a polysemy effect in episodic memory is demonstrated through an analysis of data from the experiments of lohnas et al . </S>",
    "<S> ( 2015 ) and healey and kahana ( 2016 ) . </S>",
    "<S> three word - length related features are reported : ( 1 ) the average distance between the serial positions of consecutively recalled words is an increasing function of the second word s length ; ( 2 ) the recall of words in the order in which they were presented is more likely to occur for shorter words ; ( 3 ) longer words are easier to recall than shorter words from the same list . </S>",
    "<S> these phenomena are reproduced by modeling the fact that shorter words have a larger number of meanings ( polysemy ) . </S>",
    "<S> this is shown to be at the root of our tendency to recall verbal sequences in forward order , and a conjecture is put forth regarding the general methods we employ to store information on the chronology of events . </S>"
  ]
}