{
  "article_text": [
    "what is the minimum number of 1 s needed to write an integer @xmath2 , using only @xmath7 , @xmath8 and parentheses ? in this paper we will denote by @xmath0 the minimum number of ones needed to express @xmath2 in this manner .",
    "for example , we have that @xmath9 since @xmath10 can be written with five ones as @xmath11 , but not using four or fewer . note that @xmath12 ; concatenation is not allowed .",
    "the problem dates back to a 1953 paper of mahler & popken @xcite .",
    "guy popularized the problem in his survey @xcite and also included it in his book _ unsolved problems in number theory _",
    "recently , there has been renewed interest @xcite in the problem  the focus of our paper is on the asymptotic size of @xmath0 . an interesting expression for @xmath0 given by guy in @xcite is @xmath13 which shows that the problem can be seen as arising from the difficulty of mixing additive and multiplicative behavior .",
    "several initial results are given in guy s article @xcite .",
    "one of these , due to john selfridge , is a lower bound of @xmath14 with equality exactly when @xmath2 is a power of 3 .",
    "as the author is not aware of any published proof of this fact , one is given below in appendix [ sec : guyproof ] .",
    "guy also describes several ways of obtaining an upper bound .",
    "a simple upper bound , resulting from expanding @xmath2 in base 2 and using horner s scheme , yields @xmath15 it seems difficult to get unconditional improvements since there exist numbers requiring an atypically large number of 1 s to be represent , see for example ( taken from @xcite ) @xmath16 much of the recent focus has been on improvements for subsets of density 1 .",
    "returning to guy s original argument , we see that a ` typical ' number @xmath17 should have roughly the same amount of 0 s and 1 s in its binary expansion , which suggests the upper bound @xmath18 in the ` generic ' case ( that is , numbers for which the proportion of 0 s and 1 s in the binary expansion is not too atypical ) .",
    "it is not difficult to show that the ` generic ' case gives rise to a subset with density 1 on which the bound holds .",
    "guy also cites an improvements by isbell , the best of which is achieved by performing the same type of analysis in base 24 giving @xmath19 on a set of density 1 .",
    "the currently best result is due to arias de reyna & van de lune @xcite and is based on similar considerations carried out in base @xmath20    the set of natural numbers @xmath2 for which @xmath21    experimental results suggest that this can be improved : iraids , balodis , cernenoks , opmanis , opmanis , and podnieks @xcite have conjectured , based on extensive numerical computation , that @xmath22    we emphasize that while there are several other fascinating problems related to integer complexity , our focus will be on the asymptotic behavior .",
    "we refer to the bibliography for further details on other aspects of the problem .",
    "our main result will be to develop tools to analyze a class of algorithms generalizing the one used by steinerberger @xcite .",
    "the algorithm used in @xcite is a refinement of the methods discussed above and consists of a simultaneous consideration of numbers in both base 2 and 3 .",
    "more precisely , the algorithm proceeds as follows .",
    "+ * algorithm * ( greedy , base 6)*. *    1 .",
    "take an arbitrary natural number @xmath2 .",
    "if @xmath23 , use one of the optimal representations @xmath24 , @xmath25 , @xmath26 , @xmath27 , or @xmath28 . otherwise determine @xmath29 and move to step 2 .",
    "choose the best representation according to table [ table_mod6 ] , depending on @xmath29 : * if @xmath30 , write as @xmath31 $ ] .",
    "* if @xmath32 , write as @xmath33 + 1 $ ] .",
    "* if @xmath34 , write as @xmath35 $ ] . * if @xmath36 , write as @xmath31 $ ] .",
    "* if @xmath37 , write as @xmath35 $ ] .",
    "* if @xmath38 , write as @xmath39 + 1 $ ] .",
    "+ then apply step 2 to the result ( the number in brackets ) until one of the representations in step 1 can be applied .",
    "3 .   replace every 2 by ( 1 + 1 ) and every 3 by ( 1 + 1 + 1 ) .",
    "an asymptotic analysis of the algorithm shows that @xmath40 this notion of ` generic ' is measure - theoretic and weaker than that of a density one subsequence .",
    "we start by substantially improving the result using the same notion of ` generic ' as in @xcite .",
    "[ maintheorem ] there exists a partition of @xmath41 into sets @xmath42 such that @xmath43    the construction is based on a very fine analysis of markov chains that allows us to study more effective algorithms of the type discussed above , answering an open problem stated in @xcite .",
    "it seems very likely ( and is further substantiated by numerical experiments ) that the result actually holds for a set of density 1 ; we comment on this further below .",
    "the result is close to optimal with regards to the methods that are being used and it seems that a significant further improvement would require substantially new ideas .",
    "table [ tab : thmcomp ] shows the improvement of the new algorithm over the base 6 greedy algorithm and how well it fits the bound of theorem [ maintheorem ] for a few arbitrarily chosen large numbers .     &",
    "base 6 greedy & algorithm of theorem 2    ' '' ''    & + @xmath44 & 7616 & 7386 & 7396    ' '' ''     + @xmath45 & 15314 & 14732 & 14792 + @xmath46 & 22893 & 22161 & 22189 +      we complement theorem [ maintheorem ] by giving a detailed analysis of the sets @xmath47 , which are defined to be the sets of natural numbers which the algorithm under consideration takes @xmath48 steps to process , showing that their distribution is asymptotically log - normal .",
    "our results are rather general and apply to the entire family of algorithms in this class .",
    "the sets @xmath47 have log - normal distribution : there exist constants @xmath49 such that @xmath50 in distribution as @xmath51 .",
    "this statement guarantees that a typical element in @xmath52 is roughly of size @xmath53 stronger error bounds ( i.e. large deviation inequalities ) seem to be the key to showing that the result holds indeed for a subset of density 1 .",
    "however , we consider this class of algorithms to be of independent interest .",
    "we note that similar structures appear in the definition of an _ automatic sequence _ ( see e.g. @xcite ) :",
    "the main difference is that in automatic sequence only the last step of the algorithm is kept while we are interested in the entire sequence ( since we use that to create a way of representing @xmath2 using only 1 s ) .",
    "this could be an interesting direction for further research . + it is a simple consequence of this theorem that , for large enough @xmath48 , @xmath54 should be close to normally distributed with smaller and smaller variance , approaching a point distribution at @xmath55 . figure",
    "[ fig : kdist38 ] shows that this is visible even for relatively small @xmath48 .     for random @xmath56",
    "( base 6 greedy algorithm).,scaledwidth=55.0% ]      our approach seems to fully exhaust the markov chain method and substantial further improvements seem difficult ; clearly , new ideas are needed .",
    "it seems worthwhile to note the following elementary fact pointing out that the only theoretical limit to the methods discussed above is of a computational nature .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * fact .",
    "* if , for some constant @xmath57 @xmath58 then both guy s basis method as well as the markov chain method will be able to prove the upper bound @xmath59 for every @xmath60 . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    this can be easily proven using an estimate of the type @xmath61 to guarantee that a typical ` digit ' in a base @xmath62 representation requires at most @xmath63 times the digit 1 s .",
    "at the same time , to represent an integer @xmath64 , we need @xmath65 and therefore a total number of @xmath66 this implies that the guy basis algorithm will eventually be effective",
    ". however , since the markov chain algorithm is a generalization of the guy basis algorithm , it will also be able to show the same bound , likely with less computational effort .",
    "still , there is a limit to what is computationally feasible even with the generalized algorithms , and it seems that the current result is near this limit .",
    "this section is primarily dedicated to an exposition of steinerberger s approach , which did not receive a detailed explanation in the original paper .",
    "it is actually very similar to the method of proving guy s upper bound of @xmath67 by writing @xmath68 with @xmath69 ( this is the expression of @xmath2 in terms of its base 2 digits using horner s scheme ) .",
    "an algorithmic description of horner s scheme is as follows .",
    "given a number @xmath2 ,    1 .",
    "if @xmath70 , use one of the optimal representations @xmath24 , @xmath71 .",
    "otherwise move to step 2",
    "calculate @xmath72 , then : * if @xmath73 , write as @xmath74 $ ] * if @xmath75 , write as @xmath76 + 1 $ ] .",
    "+ then repeat this step on the result ( i.e. the number in brackets ) until one of the representations in step 1 can be applied .",
    "3 .   replace every 2 by ( 1 + 1 ) .",
    "steinerberger s improvement was to look at the residue of @xmath2 modulo 6 , and depending on the residue divide by either 2 or 3 .",
    "as an example , given a number of the form @xmath77 one could write @xmath78 the first method provides a number that is half the size of its input at the cost of 3 ones while the second approach gives a number that is a third of its input size at the cost of 5 ones .",
    "clearly , we want to decrease the number by large factors as much as possible but at the same time we want to avoid using more ones than necessary",
    ". we will now discuss a way of comparing those two situations to decide on which is favorable .",
    "this section describes the heuristic used in @xcite .",
    "we wish to emphasize that this heuristic will _ not _ always lead to optimal results ( this answers a question posed at the end of @xcite ) .",
    "suppose that a step writes @xmath2 as @xmath79 + r\\ ] ] at a cost of @xmath80 ones .",
    "then the inefficiency is defined to be @xmath81 we remark that this quantity is never negative .",
    "note that @xmath80 is the number of ones it takes to write @xmath62 and @xmath82 , so @xmath83 and therefore @xmath84      the algorithm given in @xcite is now simply motivated by taking every residue class modulo 6 , studying the inefficiency of the two representations arising from dividing by either 2 or 3 and then taking the representation with the smaller inefficiency .",
    "explicit values for the inefficiency are given in table [ table_mod6 ] .",
    "choosing the option with the lowest efficiency for each step , we get the algorithm discussed above . + _ local - global relations .",
    "_ it is natural to ask whether such a local greedy selection procedure can give rise to optimal algorithms .",
    "fixing a greedy selection at every residue class gives rise to a unique global algorithm ",
    "the behavior of the global algorithm depends nonlinearly on local steps ( i.e. greedy local steps may create an overall global dynamics that stays away from ` effective ' residue classes ) .",
    "the question of whether optimal local steps necessarily imply optimal global steps was posed as an open problem in @xcite .",
    "we will answer this question in the negative ( see section 5.2 ) .     &",
    "representation & cost & inefficiency & representation & cost & inefficiency + 0 & @xmath85 & 2 & 0.107 & @xmath86 & 3 & 0    ' '' ''     + 1 & @xmath87 & 3 & 1.107 & @xmath88 & 4 & 1 + 2 & @xmath85 & 2 & 0.107 & @xmath89 & 5 & 2 + 3 & @xmath87 & 3 & 1.107 & @xmath86 & 3 & 0 + 4 & @xmath85 & 2 & 0.107 & @xmath88 & 4 & 1 + 5 & @xmath87 & 3 & 1.107 & @xmath89 & 5 & 2 +      the key idea in the analysis of an algorithm of such a type is to interpret its large scale behavior as a markov chain .",
    "a markov chain is a sequence of random variables @xmath90 on a measurable space @xmath91 , such that the distribution of @xmath92 is dependent only on the distribution of @xmath93 . for our purposes",
    ", @xmath91 will be finite and the dependence will be described by a matrix @xmath94 via the relation @xmath95 where @xmath96 is the vector giving the probability distribution of @xmath92 ( that is , @xmath97 is the probability that @xmath98 ) .",
    "we denote by @xmath99 the probability that @xmath100 lands in the set @xmath101 after @xmath80 iterations : @xmath102.\\ ] ]    to model the algorithm described above , we let @xmath103 be the set of residues modulo 6 .",
    "the transition matrix is constructed as follows : given an integer of the form @xmath104 , for example , the algorithm proceeds by writing @xmath105 a number of the form @xmath106 has residue class @xmath107 or @xmath108 when re - interpreted modulo 6 .",
    "this means that the state 1 can be followed by either 0 , 2 or 4 . a complete list of possible paths through states",
    "are represented by the directed graph in figure [ fig : graph ] .",
    "+        the @xmath109th entry of the transition matrix is given by @xmath110 , the probability that one step of the algorithm sends a number congruent to @xmath111 to a number congruent to @xmath112 .",
    "let us consider the same example again : suppose @xmath113 , and let @xmath114 .",
    "then , following the algorithm , the next number we get is @xmath115 with no further assumptions on @xmath2 , it is equally likely that this is @xmath116 , @xmath117 , or @xmath118 . therefore @xmath119 .",
    "similar calculations give the rest of the matrix : @xmath120 note that given an initial distribution @xmath121 , we have @xmath122 a straightforward calculation shows that @xmath94 has an eigenvalue @xmath1 of multiplicity @xmath1 .",
    "therefore there is a unique probability distribution that is a @xmath1-eigenvector , which is @xmath123 since all other eigenvalues have absolute value strictly less than @xmath1 , it is easy to see that for any initial distribution @xmath121 we have @xmath124 the vector @xmath125 is therefore called the _ stationary _ or _ limit distribution _ of @xmath126 .",
    "standard deviation inequalities then imply that the algorithm , when processing a ` typical ' large number @xmath2 will spend a proportion of time in each state that is roughly proportional to what is given by the limiting distribution .",
    "this , however , uniquely identifies the average rate of decay and the average number of times a digit 1 is being used .",
    "we start by establishing a central limit theorem which allows us to control the average deviation of sample paths from the asymptotic limit .",
    "[ lem : clt ] let @xmath126 be a markov chain on a finite space @xmath91 . if there exists a state @xmath127 and some @xmath128 such that @xmath111 can be reached in exactly @xmath80 steps from any starting point with positive probability , that is , @xmath129 then any starting distribution approaches the unique stationary distribution @xmath125 at a geometric rate .",
    "moreover , we have a central limit theorem : let @xmath130 and @xmath131 then if we let @xmath132 $ ] where @xmath125 is the limit distribution , there exists a constant @xmath133 such that for any initial condition @xmath134 we have @xmath135 = \\int_{-\\infty}^t \\frac{1}{2\\pi } e^{-s^2/2 } ds   \\qquad \\mbox{whenever } \\quad \\gamma_g^2 > 0\\ ] ] and @xmath136    we prove this using results from meyn and tweedie @xcite .",
    "an important concept is _ uniform ergodicity _ : we say that a markov chain @xmath126 is uniformly ergodic if there exist @xmath137 and @xmath138 such that for all @xmath100 @xmath139 where @xmath125 is the stationary distribution , interpreted as a measure on @xmath91 ( see ( * ? ? ?",
    "* theorem 16.0.2 . ) ) . put differently ,",
    "@xmath140 approaches @xmath141 geometrically . here",
    "we define @xmath142 for a measure @xmath143 to be @xmath144 uniform ergodicity is a special case of what is called @xmath145-uniform ergodicity ( see ( * ? ? ?",
    "* chapter 16 ) ) such that @xmath145 is a constant function .",
    "theorem 17.5.4 in @xcite implies that this is enough for a central limit theorem for @xmath126 .",
    "so if we can establish uniform ergodicity we have geometric convergence to the limit distribution and convergence of @xmath146 to a normal distribution ( possibly with variance 0 ) .",
    "the criterion we will use for showing ergodicity uses the notion of a small set ( see ( * ? ? ?",
    "* section 5.2 . ) ) .",
    "if @xmath143 is a measure on the state space @xmath91 , a measurable set @xmath147 is called _ @xmath143-small _ if there exists @xmath128 such that for all @xmath134 and all measurable sets @xmath148 @xmath149 theorem 16.0.2 in @xcite states that a markov chain is uniformly ergodic if and only if @xmath91 is @xmath143-small for some @xmath143 .",
    "this is quite easy to show for our purposes : suppose that @xmath91 is finite and some state @xmath127 can be reached in exactly @xmath80 steps from any starting point .",
    "then let @xmath150 and define a measure @xmath151 now if a set @xmath148 does not contain @xmath111 then its @xmath143-measure is 0 and the condition is trivially satisfied .",
    "otherwise , @xmath152 therefore @xmath91 is @xmath143-small and the markov chain is uniformly ergodic .",
    "we now use this to show that a class of algorithms generalizing the one in section [ sec : steineralg ] can ( with one additional condition ) be used to prove strong concentration bounds for the outcome of the algorithm .",
    "first we introduce some notation .",
    "+ we consider algorithms @xmath101 defined by a map @xmath153 assigning dividing factors to residue classes such that @xmath154 and @xmath155 for all @xmath156 , which produces a representation for a natural number @xmath2 according to the following process :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * general algorithm . * define @xmath157 .",
    "let @xmath158 , @xmath159 , and @xmath160 .",
    "we then have @xmath161 + s_0.\\ ] ] iteratively define @xmath162 , and similarly @xmath163 and @xmath164 as above , until we get to @xmath165 for some @xmath48",
    ". then we have the expression @xmath166 and expressing the @xmath163 and @xmath164 using their optimal representations gives a representation for @xmath2 .",
    "( note that @xmath167 so only finitely many optimal representations must be known . ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    we say that @xmath101 is a base @xmath168 algorithm , since it operates at each step on residue classes modulo @xmath168 .",
    "if we write @xmath169 as an @xmath168-tuple , guy s algorithm would be represented as @xmath170 and the one used by steinerberger as @xmath171 .",
    "a greedy algorithm can be produced for any base using the heuristic in section [ sec : heuristic ] by choosing @xmath172 for each @xmath111 that gives the lowest inefficiency .",
    "+ given a base @xmath168 algorithm @xmath101 , let @xmath173 be the resulting markov chain on the space @xmath174 and @xmath94 its transition matrix .",
    "if there is some state @xmath127 which can be reached from any other in @xmath80 steps , then from the above discussion there exists a unique stationary distribution which can be written as a vector @xmath175^a$ ] .",
    "our goal is to bound @xmath0 by estimating @xmath176 , the number of ones used by the algorithm @xmath101 to represent @xmath2 .",
    "we can estimate this by @xmath177 where @xmath178 is the average cost ( that is , the average number of ones used per step ) and @xmath48 is the number of steps the algorithm takes , and estimating these factors in terms of @xmath2 .",
    "if we let @xmath179 , then @xmath180 we will use the markov chain central limit theorem ( lemma [ lem : clt ] ) to approximate @xmath178 and @xmath181 assuming @xmath48 to be large .",
    "the average cost @xmath178 can be written as @xmath182 where @xmath183 is the number of ones used by one step of the algorithm applied to @xmath127 , that is , the total number of ones needed to represent @xmath172 and @xmath184 in their optimal forms .",
    "clearly @xmath147 is a bounded function , so we can apply lemma [ lem : clt ] .",
    "thus @xmath185 ) = \\frac{1}{\\sqrt{k } } \\big ( s_k(c ) - k \\cdot { \\mathbb{e}}_\\pi(c ) \\big)\\ ] ] approaches a normal distribution with finite ( possibly zero ) variance , so @xmath186 \\big ) = \\bar{c } - { \\mathbb{e}}_\\pi[c]\\ ] ] approaches a delta distribution at 0 .",
    "this means that for large enough @xmath48 , the distribution of @xmath178 is clustered arbitrarily tightly around @xmath187 $ ] : given any @xmath188 there exists @xmath189 such that for all @xmath190 , @xmath191 \\big| > \\delta \\ \\big| \\ n",
    "\\in a_k \\big ] < { \\varepsilon}.\\ ] ] + a similar approach gives an estimate of @xmath181 in terms of @xmath2 .",
    "we can write @xmath2 as @xmath192       & = \\lambda_0 \\lambda_1 \\cdots \\lambda_{k-1 } + \\lambda_0 \\cdots \\lambda_{k-2 } s_{k-1 } + \\ldots + \\lambda_0 \\lambda_1 s_2 + \\lambda_0 s_1 + s_0 \\\\       & = \\lambda_0 \\lambda_1 \\cdots \\lambda_{k-1 } \\left ( 1 + \\frac{s_{k-1}}{\\lambda_{k-1 } } + \\ldots + \\frac{s_2}{\\lambda_2 \\cdots \\lambda_{k-1 } } + \\frac{s_1}{\\lambda_1 \\cdots \\lambda_{k-1 } } + \\frac{s_0}{\\lambda_0 \\cdots \\lambda_{k-1 } } \\right)\\end{aligned}\\ ] ] then of course @xmath193 and since @xmath194 and @xmath195 @xmath196 taking logarithms and dividing by @xmath48 , the last two inequalities combined give @xmath197 therefore since @xmath198 , for large enough @xmath48 @xmath199 can be made arbitrarily small for all @xmath52 .",
    "but @xmath200 , so @xmath201 just as before , @xmath169 is a bounded function on @xmath91 so @xmath202\\ ] ] approaches a delta distribution at 0 .",
    "thus for any @xmath188 there exists @xmath189",
    "so that for @xmath190 @xmath203 and @xmath204 \\big| > \\frac{\\delta}{2 } \\big ] < { \\varepsilon},\\ ] ] so @xmath205 \\big| > \\delta \\ \\big| \\",
    "n \\in a_k \\big ] < { \\varepsilon}.\\ ] ]    recalling that @xmath206 , it follows that for any @xmath188 there exists @xmath189 such that for @xmath190 , @xmath207}{{\\mathbb{e}}_\\pi [ \\log_3 \\lambda ] } \\big| > \\delta \\ \\big| \\",
    "n \\in a_k \\big ] < { \\varepsilon}.\\ ] ] in particular , @xmath208}{{\\mathbb{e}}_\\pi [ \\log_3 \\lambda ] } + \\delta \\big ) \\log_3 n \\ \\big| \\ n \\in a_k \\big ] < { \\varepsilon}.\\ ] ]    since @xmath209 , we now have that , for any @xmath210 , @xmath211}{{\\mathbb{e}}_\\pi [ \\log_3 \\lambda ] } + \\delta \\big ) \\log_3 n \\big\\ } \\right| = 0.\\ ] ] so given an algorithm @xmath101 such that some state is accessible from any other in precisely @xmath80 steps ( for some @xmath128 ) we can calculate @xmath125 , @xmath187 $ ] , and @xmath212 $ ] to get an upper bound for @xmath0 .      from equation [ eqn : squeezing ] above , for all @xmath52 @xmath213 so as @xmath48 approaches infinity , @xmath214 approaches @xmath215 in distribution , which we know approaches a normal distribution with mean @xmath216 $ ] . from this",
    "it follows that @xmath217 approaches a point distribution at @xmath218 $ ] .",
    "this convergence is already visible for relatively small @xmath48 .",
    "a histogram for a random selection of numbers in @xmath219 , where @xmath101 is the greedy algorithm in base 6 , is shown in figure  [ fig : kdist38 ] .",
    "the most obvious new class of algorithms to consider is greedy algorithms for higher bases .",
    "for example , the greedy algorithm in base 30 can be succinctly written as @xmath220 giving rise to a transition matrix @xmath221    it is quite easy to derive a numerical approximation of the stationary distribution as @xmath222 using the transition matrix it can be checked that any nontransient state can be reached from any other state in exactly 9 steps , so that our central limit theorem applies . from this algorithm",
    "we get the improved result that @xmath223 where @xmath47 is the set of numbers which the base 30 greedy algorithm takes @xmath48 steps to process .",
    "it is possible to improve on the greedy algorithm ( this was not clear a priori ) .",
    "we define a ` landscape ' of algorithms by associating to each algorithm @xmath101 of the type above a cost @xmath224}{{\\mathbb{e}}_\\pi [ \\log_3 \\lambda ] } \\ ] ] and saying that two algorithms @xmath225 are adjacent if their tuples @xmath226 agree on all but exactly one entry .",
    "the problem of finding a better bound is now a nonlinear optimization problem on a large search space .",
    "the best known algorithm was found using simulated annealing .",
    "it has base @xmath227 and constant @xmath228 .",
    "the corresponding @xmath229-tuple @xmath169 is given in appendix [ app : alg ] .",
    "this algorithm implies the result @xmath230    .comparison of frequency of factors used by improved algorithm with greedy algorithms .",
    "the frequency is the proportion of states which use a given factor , weighted by the limit distribution .",
    "dots represent factors not allowed given the base . [ cols=\"^,^,^,^ \" , ]     in comparison ,",
    "the greedy algorithm for base 2310 gives a constant of @xmath231 .",
    "the improvement can be seen to come in part from the increased frequency with which 3 is used as a dividing factor , as shown in table [ tab : factfreq ] .",
    "note in particular that one way the greedy algorithm accomplishes this is by using 11 as a dividing factor one in every fifty steps , even though it is never locally optimal ( as can be seen from the center column ) . by taking a few locally inefficient steps ,",
    "the algorithm is able to use 3 in ten percent more steps .",
    "using higher bases and running simulated annealing for more iterations will produce slightly better bounds .",
    "the bound produced by an algorithm is limited by the complexity of its dividing factors , and since most small numbers have suboptimal complexity ( that is , @xmath232 is well above @xmath233 ) , very good algorithms will have to include large dividing factors .",
    "but large factors will be used infrequently by an optimized algorithm , since dividing out by any factor is only worth it if the number of ones it costs to remove the remainder is small .",
    "this happens infrequently for large numbers , so including a single large factor , no matter how efficient it is by itself , will not have much of an effect on the resulting bound .",
    "while , computationally , this method will always be able to produce better results than guy s basis method ( since guy s basis method can actually be implemented as a special case ) , it is at this point not clear to us how one would most effectively optimize over the class of algorithms .",
    "we consider this to be a fascinating problem .",
    "it would also be interesting to strengthen theorem [ maintheorem ] to state that @xmath234 for a set of integers of density 1 , with the same holding for all bounds produced by the same type of algorithm .",
    "the key difficulty seems to be as follows : the set @xmath235 for @xmath64 large can be written @xmath236 the first half is easily controlled since we know that only a small proportion of elements in @xmath47 ( @xmath237 ) can violate the bound .",
    "however , the second part is much more difficult to control because while we do have fairly explicit control on every single set @xmath47 ( @xmath238 ) and know the number of explicit violations to the bound to be small , we have not yet established sufficient control on @xmath239 to draw any conclusions .",
    "the missing element in establishing the desired bound for a subset of density 1 is a statement guaranteeing that the number of ` bad ' elements in @xmath239 is not disproportinately larger than the proportion of ` bad ' elements in @xmath47 .",
    "numerical experiments strongly hint at this being the case .",
    "this comment is inspired by work of sinai on large - scale properties of the @xmath240 problem .",
    "define @xmath241 via @xmath242 the @xmath240 problem asks whether for every @xmath17 there is some @xmath48 such that repeated iteration yields @xmath243 .",
    "if one were to assume that being even or odd is equally likely for numbers arising in the course of these iterations , then one would expect an average decay of @xmath244 some rigorous results in that direction have been obtained by sinai @xcite . since our class of algorithms is related to the @xmath240 problem ( the only but admittedly crucial difference being that our algorithms always decrease the input ) , we were motivated to see whether similar phenomena appear .",
    "indeed , it seems that a suitable rescaled series of numbers behaves like brownian motion on a logarithmic scale ( see figure [ fig : brownian ] ) .",
    "we consider this to be a promising direction for further research .",
    "using the base 6 greedy algorithm for a random element in @xmath245 ( left ) and one in @xmath246 ( right).,title=\"fig:\",scaledwidth=49.0% ]   using the base 6 greedy algorithm for a random element in @xmath245 ( left ) and one in @xmath246 ( right).,title=\"fig:\",scaledwidth=49.0% ]    * acknowledgements * the author gratefully acknowledges access to the omega cluster of the yale university high performance computing center .",
    "h. altman , integer complexity and well - ordering .",
    "michigan math .",
    "j. 64 ( 2015 ) , no . 3 , 509 - 538 .",
    "h. altman , j. zelinsky , numbers with integer complexity close to the lower bound .",
    "integers 12 ( 2012 ) , no . 6 , 1093 - 1125 .",
    "j. arias de reyna and j. van de lune , algorithms for determining integer complexity .",
    "j. cernenoks , j. iraids , m. opmanis , r. opmanis , and k. podnieks , integer complexity : experimental and analytical results ii .",
    "arxiv:1409.0446v1    r. k. guy , unsolved problems : some suspiciously simple sequences .",
    "monthly 93 ( 1986 ) , no .",
    "3 , 186190 .",
    "r. k. guy , unsolved problems in number theory , @xmath247 edition , springer , 2004 .",
    "j. iraids , k. balodis , j. cernenoks , m. opmanis , r. opmanis , and k. podnieks , integer complexity : experimental and analytical results .",
    "arxiv:1203.6462    k. mahler and j. popken , on a maximum problem in arithmetic .",
    "( dutch ) nieuw arch .",
    "wiskunde ( 3 ) 1 , ( 1953 ) .",
    "meyn and r.l .",
    "tweedie , markov chains and stochastic stability .",
    "springer - verlag , london ( 1993 ) .",
    "available at : probability.ca/mt    ya .",
    "sinai , statistical ( @xmath240 ) problem . dedicated to the memory of jrgen k. moser .",
    "pure appl .",
    "56 ( 2003 ) , no . 7",
    ", 1016 - 1028 .",
    "sinai , uniform distribution in the ( @xmath240)-problem .",
    "j. 3 ( 2003 ) , no . 4",
    ", 1429 - 1440 .",
    "sinai , a theorem about uniform distribution .",
    "phys . 252 ( 2004 ) , no . 1 - 3 , 581 - 588 .    j .- p . allouche and j. shallit , automatic sequences .",
    "theory , applications , generalizations .",
    "cambridge university press , cambridge , 2003 .",
    "s. steinerberger , a short note on integer complexity .",
    "contributions to discrete mathematics 9 ( 2014 ) , 6369 .",
    "here we give a prove of a result mentioned in @xcite and attributed to john selfridge because we were unable to find it in the literature and consider it worthwhile to have it written .",
    "however , we also note that very similar ( and more advanced ) types of argument along the same lines also appear in a paper by altman & zelinsky @xcite .",
    "we have @xmath14 with equality exactly when @xmath2 is a power of 3 .",
    "we use induction : suppose the bound holds for all numbers less than @xmath2 . use the formula @xmath248 first consider the case where @xmath168 or @xmath62 is 1 ; assume without loss of generality that @xmath249 . then @xmath250 a straightforward calculation shows that this is greater than @xmath251 for @xmath252 .",
    "the other case is where @xmath253 .",
    "then @xmath254 if @xmath255 then this satisfies the desired bound . otherwise , suppose without loss of generality that @xmath256",
    ". then @xmath257 so @xmath258 the two cases considered together give a proof for @xmath252 ; the remaining cases are easy to check .",
    "the following is the @xmath229-tuple representation of the current best known algorithm , which was used to prove theorem [ maintheorem ] .    ....",
    "( 3 ,   5 ,   2 ,   3 ,   2 ,   5 ,   3 ,   7 ,   2 ,   3 ,   2 , 11 ,   2 ,   2 ,   2 ,   3 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   3 ,   7 ,   3 ,   2 ,   7 ,   7 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,   2 ,   5 ,   2 ,   3 ,   2 ,   2 ,    2 ,   3 ,   2 ,   3 ,   3 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   3 ,   2 ,   3 ,   3 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   5 ,   2 ,   2 ,   3 ,   2 ,   2 ,    7 ,   3 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   3 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 ,   2 ,   3 ,   3 ,   2 ,   2 ,   5 ,   2 ,   2 ,   2 ,   7 ,    3 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   3 ,   3 ,   2 ,   2 ,   2 ,   7 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 ,   2 ,   3 ,   2 , 11 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,    2 ,   3 ,   2 ,   3 ,   2 ,   5 ,   3 ,   2 ,   5 ,   3 ,   2 ,   7 ,   2 ,   3 ,   2 ,   3 ,   3 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 , 11 ,   7 ,   2 ,   3 ,   2 ,   2 ,    3 ,   3 ,   3 ,   3 ,   5 ,   5 ,   3 ,   3 ,   2 ,   7 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   7 ,   7 ,   2 ,   3 ,   2 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 , 11 ,    3 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   7 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   7 ,   3 ,   2 ,   2 ,   3 ,   3 ,   3 ,   7 ,   7 ,   3 ,   3 ,   3 ,   5 ,   3 ,   7 ,   7 ,    3 ,   2 ,   2 ,   3 ,   2 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   7 ,   2 ,   2 ,   3 ,   3 ,   3 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   7 ,   3 ,   2 ,   2 ,   11 ,   2 ,   2 ,   3 ,   3 ,   5 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 , 11 ,   2 ,   2 ,   3 ,   2 ,   2 ,    3 ,   3 ,   2 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   7 ,   3 ,   3 ,   3 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,    3 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   5 ,   3 ,   2 , 11 ,   2 ,   7 ,   2 ,   3 ,   3 ,   3 ,   5 ,   3 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,    2 ,   3 ,   2 ,   3 ,   7 ,   5 ,   2 ,   2 ,   5 ,   7 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   7 , 11 ,   3 ,   3 ,   2 ,   3 ,   2 ,   5 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,    3 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   7 ,   3 ,   2 ,   2 ,   7 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   5 ,   2 ,   3 ,   2 ,   2 ,    3 ,   3 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   2 ,   3 ,   5 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 , 11 ,   2 ,   3 ,   3 , 11 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,    3 ,   3 ,   2 ,   2 ,   2 ,   5 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   5 ,   3 ,   2 ,   3 ,   2 ,   2 ,    5 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   7 ,   2 ,   2 ,   7 ,   3 ,   3 ,   5 ,   2 ,   2 ,   3 ,   7 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,    3 ,   3 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   2 ,   7 ,   2 ,   3 ,   2 ,   2 ,   7 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   3 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   7 ,   2 ,   5 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 ,   3 ,   5 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 , 11 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   5 ,   2 ,   2 ,   3 ,   2 ,   7 ,   2 ,   2 ,   2 ,   3 ,   3 ,   3 ,    3 ,   3 ,   2 ,   3 ,   2 ,   5 ,   2 ,   7 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   2 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,    2 ,   3 ,   5 ,   3 , 11 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 , 11 ,   2 ,   2 ,   2 ,   3 ,   3 ,   3 ,   2 ,   7 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   3 ,   5 ,   3 ,   3 ,   5 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   3 , 11 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 , 11 ,   3 ,   3 ,   2 ,   3 ,   7 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,    2 ,   2 , 11 ,   3 ,   2 ,   5 ,   2 ,   2 ,   3 ,   3 ,   2 ,   2 ,   2 ,   7 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 ,   5 ,   3 ,   2 ,   2 ,   2 ,   5 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 , 11 ,   5 ,   2 ,   2 ,   5 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   3 ,   2 ,   2 ,   2 ,   3 ,   2 , 11 ,   2 ,   7 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   7 ,   7 ,   5 ,   3 ,   2 ,   3 ,   2 ,   5 ,   7 ,   3 ,   2 ,   3 ,   2 ,   2 ,    3 ,   3 ,   2 ,   3 ,   2 ,   5 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,   2 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   7 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 , 11 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 ,   3 ,   2 ,   7 ,   2 ,   3 ,   2 ,   3 , 11 ,   2 ,   2 ,   3 ,   2 ,   2 ,    3 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,    2 ,   7 ,   2 ,   3 , 11 ,   5 ,   2 ,   2 ,   7 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 , 11 ,   3 ,   2 ,   3 ,   2 ,   7 ,    3 ,   2 ,   2 ,   3 ,   2 ,   5 ,   7 ,   7 ,   2 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   5 ,   3 ,   2 ,   3 ,   7 ,   2 , 11 ,   2 ,   2 ,   7 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   7 ,   5 ,   2 ,   3 ,   5 ,   3 ,   2 , 11 ,   2 ,   2 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 , 11 ,   7 ,   2 ,   3 ,   2 ,   2 ,    5 ,   3 ,   2 ,   3 ,   2 ,   5 ,   3 ,   3 ,   5 ,   7 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   5 ,   2 ,   7 ,   3 ,   2 ,   3 ,   2 ,   7 ,   2 ,   5 ,   2 ,   3 ,   2 ,   2 ,    3 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 , 11 ,   2 ,   3 ,   2 ,   3 ,   2 ,   2 ,   7 ,   3 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   3 ,   3 ,   2 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   3 ,   2 ,   7 ,   2 ,   3 ,   2 ,   2 , 11 ,   2 ,   2 ,   2 ,   2 ,   2 ,    3 ,   3 ,   2 ,   3 , 11 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 , 11 , 11 ,   2 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   7 ,   3 ,   2 ,   7 ,   5 ,   5 ,   3 ,   3 ,   2 ,   3 ,   7 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,    3 ,   3 ,   7 ,   3 ,   7 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   7 ,   2 ,   3 ,   3 ,   3 ,   7 ,   3 ,   2 ,   3 ,   2 ,   2 , 11 ,   3 ,   2 ,   3 ,   2 , 11 ,    7 ,   2 ,   2 ,   3 ,   7 ,   5 ,   2 ,   2 ,   3 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,    3 ,   3 ,   2 ,   3 ,   5 ,   5 ,   3 ,   3 ,   7 ,   5 ,   2 ,   2 , 11 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,    2 ,   3 ,   2 ,   3 ,   2 ,   5 ,   2 ,   7 ,   2 ,   3 , 11 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   3 ,   3 ,   2 ,   7 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,    3 ,   3 ,   2 ,   3 ,   3 ,   5 ,   2 ,   2 ,   2 ,   3 ,   2 , 11 ,   2 ,   3 ,   2 ,   3 ,   2 ,   7 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   3 ,   3 ,   2 ,   3 ,   2 ,   3 ,   7 ,   7 ,   3 ,   5 ,   2 ,   3 ,   2 ,   7 ,   11 ,   3 ,   2 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   7 ,   2 ,   3 ,   3 , 11 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   2 ,   2 ,   2 ,    2 ,   3 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   5 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   5 ,   7 ,   2 ,   3 ,   2 ,   2 ,    3 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   5 ,   2 ,   2 ,   3 ,   5 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   7 ,   7 ,    2 ,   2 ,   7 ,   3 ,   3 ,   5 ,   2 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 ,   3 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 , 11 ,    2 ,   2 ,   2 ,   3 ,   3 ,   5 ,   2 ,   2 ,   2 ,   3 ,   5 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,   7 ,   7 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 , 11 ,   3 ,   2 ,   2 ,   7 ,   2 ,   2 ,   3 ,   3 ,   3 ,   7 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   2 ,   7 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   5 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   3 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 ,   3 ,    3 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   5 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   7 ,   3 ,   5 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 , 11 ,   7 ,   2 ,   2 ,   3 ,   7 ,   7 ,   7 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 , 11 ,   2 ,   2 ,   3 ,   5 ,   2 ,   5 ,   2 ,   2 ,   7 ,   2 ,   2 ,   3 ,   5 ,   2 ,   3 ,   2 ,   2 ,   11 ,   3 ,   2 ,   3 ,   7 ,   7 ,   2 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 , 11 ,   2 ,   7 ,   2 ,   3 ,   2 ,   2 ,   5 ,   2 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   7 ,   2 ,   2 ,   3 ,   2 ,   2 ,   2 ,   3 ,   2 ,   3 ,   2 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   5 ,   2 ,   2 ,   3 ,   2 ,   2 ,    3 ,   3 ,   2 ,   3 ,   2 ,   5 , 11 ,   2 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 ,   5 ,   3 , 11 , 11 ,   7 ,   2 ,   2 ,   3 ,   2 ,   7 ,    3 ,   2 ,   2 ,   3 ,   2 ,   5 ,   5 ,   2 ,   7 ,   3 ,   2 ,   2 ,   3 ,   7 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   7 ,   7 ,   7 ,    2 ,   2 ,   2 ,   3 ,   7 ,   5 ,   5 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   7 ,   2 ,   3 ,   2 , 11 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   5 ,   2 ,   2 ,   5 ,   2 ,   2 ,   2 ,   3 ,   2 ,   7 ,   2 ,   2 ,   2 ,   3 ,   2 , 11 ,   7 ,   3 ,   2 ,   3 ,   2 ,   2 ,    3 ,   3 ,   2 ,   3 ,   2 ,   5 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   5 ,   3 , 11 ,   2 ,   3 ,   3 ,   2 ,   7 ,   2 ,   2 ,   5 ,   3 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   3 ,   2 ,   3 ,   2 ,   2 ,   7 ,   7 ,   2 ,   3 ,   2 ,   2 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,   3 ,   2 ,   7 ,   3 ,   2 ,   2 ,    2 ,   3 ,   2 ,   3 ,   3 ,   5 ,   2 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   2 ,   3 ,   3 ,   3 ,   7 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   7 ,   3 ,   2 , 11 ,   2 ,   2 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   7 ,    2 ,   2 ,   2 ,   3 ,   3 ,   5 ,   2 ,   2 ,   3 ,   3 ,   2 ,   2 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   5 ,   2 ,   7 ,   2 ,   2 ,    5 ,   3 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   7 ,   3 ,   7 ,   2 ,   2 ,   3 ,   2 ,   3 ,   3 , 11 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,    2 ,   2 ,   3 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   7 ,   7 ,   3 ,   3 ,   5 ,   3 ,   2 ,   7 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   11 ,   2 ,   2 ,   3 ,   2 ,   5 , 11 ,   7 ,   2 ,   3 ,   2 ,   2 ,   3 ,   2 ,   7 ,   3 , 11 ,   2 ,   3 ,   2 ,   2 ,   7 ,   2 , 11 ,   2 ,   2 ,   2 ,   3 ,   7 ,   7 ,    3 ,   2 ,   5 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   3 ,   3 ,   3 ,   7 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ,    3 ,   2 , 11 ,   3 ,   5 ,   5 , 11 ,   3 ,   2 ,   3 ,   2 ,   2 ,   2 ,   3 ,   2 ,   3 ,   2 ,   7 ,   2 ,   3 ,   2 ,   3 ,   2 ,   2 ,   7 ,   7 ,   2 ,   3 ,   2 , 11 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   3 ,   3 ,   3 ,   3 ,   2 ,   3 ,   5 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 , 11 ,    3 ,   3 ,   2 ,   3 ,   2 ,   5 ,   5 ,   3 , 11 ,   3 ,   2 ,   2 ,   3 ,   7 ,   2 ,   3 ,   3 ,   3 ,   7 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   7 ,   2 ,   2 ,    2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   2 ,   3 ,   2 ,   2 ,   2 ,   3 ,   2 ,   5 ,   2 ,   2 ,   7 ,   3 ,   2 ,   3 ,   2 ,   2 , 11 ,   7 ,   2 ,   3 ,   2 ,   2 ,    3 ,   3 ,   2 ,   3 ,   2 ,   5 ,   3 ,   3 ,   2 ,   7 ,   2 ,   2 ,   2 ,   2 ,   2 ,   3 ,   7 ,   7 ,   7 ,   3 ,   2 ,   3 ,   2 ,   2 ,   3 ,   3 ,   2 ,   3 ,   2 ,   2 ) ...."
  ],
  "abstract_text": [
    "<S> the complexity @xmath0 of an integer was introduced in 1953 by mahler & popken : it is defined as the smallest number of @xmath1 s needed in conjunction with arbitrarily many + , * and parentheses to write an integer @xmath2 ( for example @xmath3 since @xmath4 ) . </S>",
    "<S> the best known bounds are @xmath5 where the lower bound is due to selfridge ( with equality for powers of 3 ) while the upper bound was recently proven by arias de reyna & van de lune and holds for ` generic ' integers @xmath2 . </S>",
    "<S> we use markov chain methods to develop an explicit algorithm that improves the upper bound to @xmath6 </S>"
  ]
}