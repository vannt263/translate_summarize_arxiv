{
  "article_text": [
    "let @xmath6 be the bicriteria polynomial optimization problem @xmath7 , where @xmath8 is the basic semialgebraic set : @xmath9    for some polynomials @xmath10 $ ] . here , we assume the following :    [ hyp : order ] the image space @xmath11 is partially ordered with the positive orthant @xmath12 .",
    "that is , given @xmath13 and @xmath14 , it holds @xmath15 whenever @xmath16 .    for the multiobjective optimization problem  @xmath6 ,",
    "one is usually interested in computing , or at least approximating , the following optimality set , defined e.g. in ( * ? ? ?",
    "* definition 11.5 ) .",
    "let assumption  [ hyp : order ] be satisfied .",
    "a point @xmath17 is called an _ edgeworth - pareto ( ep ) optimal point _ of problem  @xmath6 , when there is no @xmath18 such that @xmath19 and @xmath20 .",
    "a point @xmath17 is called a _ weakly edgeworth - pareto optimal point _ of problem  @xmath6 , when there is no @xmath18 such that @xmath21 .    in this paper , for conciseness , we will also use the following terminology :    the image set of weakly edgeworth - pareto optimal points is called the _ pareto curve_.    given a positive integer @xmath22 and @xmath23 $ ] both fixed , a common workaround consists in solving the _ scalarized _ problem : @xmath24^{1/p } \\}\\:,\\end{aligned}\\ ] ] which includes the weighted sum approximation ( @xmath25 ) @xmath26 and the weighted chebyshev approximation ( @xmath27 ) @xmath28 here , we assume that for almost all ( a.a . ) @xmath29 $ ] , the solution @xmath30 of the scalarized problem   ( resp .  ) is unique .",
    "non - uniqueness may be tolerated on a borel set @xmath31 $ ] , in which case one assumes image uniqueness of the solution .",
    "then , by computing a solution @xmath30 , one can approximate the set @xmath32\\}$ ] , where @xmath33 other approaches include using a numerical scheme such as the modified polak method @xcite : first , one considers a finite discretization @xmath34 of the interval @xmath35 $ ] , where @xmath36 with @xmath37 being a solution of @xmath38 .",
    "then , for each @xmath39 , one computes an optimal solution @xmath40 of the constrained optimization problem @xmath41 and select the pareto front from the finite collection @xmath42 .",
    "this method can be improved with the iterative eichfelder - polak algorithm , see e.g.  @xcite . assuming the smoothness of the pareto curve",
    ", one can use the lagrange multiplier of the equality constraint to select the next point @xmath43 .",
    "it allows to combine the adaptive control of discretization points with the modified polak method . in  @xcite , das and dennis",
    "introduce the normal - boundary intersection method which can find a uniform spread of points on the pareto curve with more than two conflicting criteria and without assuming that the pareto curve is either connected or smooth .",
    "however , there is no guarantee that the nbi method succeeds in general and even in case it works well , the spread of points is only uniform under certain additional assumptions .",
    "interactive methods such as stem  @xcite rely on a _ decision maker _ to select at each iteration the weight @xmath44 ( most often in the case @xmath27 ) and to make a trade - off between criteria after solving the resulting scalar optimization problem .",
    "so discretization methods suffer from two major drawbacks .",
    "( i ) they only provide a _",
    "finite subset _ of the pareto curve and ( ii ) for each discretization point one has to compute a _ global _ minimizer of the resulting optimization problem ( e.g. ( [ eq : flamx ] ) or ( [ eq : flamx - infty ] ) ) .",
    "notice that when @xmath45 and @xmath46 are both convex then point ( ii ) is not an issue .    in a recent work @xcite , gorissen and den hertog",
    "avoid discretization schemes for convex problems with multiple linear criteria @xmath47 and a convex polytope @xmath46 .",
    "they provide an inner approximation of @xmath48 by combining robust optimization techniques with semidefinite programming ; for more details the reader is referred to  @xcite .",
    "[ [ contribution . ] ] contribution .",
    "+ + + + + + + + + + + + +    we provide a numerical scheme with two characteristic features : it avoids a discretization scheme and approximates the pareto curve in a relatively strong sense .",
    "more precisely , the idea is consider multiobjective optimization as a particular instance of _ parametric polynomial optimization _ for which some strong approximation results are available when the data are polynomials and semi - algebraic sets .",
    "in fact we will investigate this approach :    method ( a ) : :    for the first formulation ( [ eq : flamx ] ) when @xmath49 , this is    a _ weighted convex sum approximation _ ; method ( b ) : :    for the second formuation ( [ eq : flamx - infty ] ) when    @xmath50 , this is a _ weighted chebyshev approximation _ ; method ( c ) : :    for a third formulation inspired by  @xcite , this is a _",
    "parametric    sublevel set approximation_.    when using some weighted combination of criteria ( @xmath49 , method ( a ) or @xmath50 , method ( b ) ) we treat each function @xmath51 , @xmath52 , as the signed density of the signed borel measure @xmath53 with respect to the lebesgue measure @xmath54 on @xmath55 $ ] .",
    "then the procedure consists of two distinct steps :    1 .   in a first step ,",
    "we solve a hierarchy of semidefinite programs ( called sdp hierarchy ) which permits to approximate any finite number @xmath56 of moments @xmath57 where : @xmath58 more precisely , for any fixed integer @xmath59 , step @xmath60 of the sdp hierarchy provides an approximation @xmath61 of @xmath62 which converges to @xmath62 as @xmath63 .",
    "the second step consists of two _ density estimation _ problems : namely , for each @xmath64 , and given the moments @xmath62 of the measure @xmath65 with unknown density @xmath66 on @xmath55 $ ] , one computes a univariate polynomial @xmath67 $ ] which solves the optimization problem @xmath68 } \\int_0 ^ 1 ( f_j^*(\\lambda ) - h)^2 d \\lambda$ ] if the moments @xmath62 are known exactly .",
    "the corresponding vector of coefficients @xmath69 is given by @xmath70 , @xmath64 , where @xmath71 is the @xmath59-moment matrix of the lebesgue measure @xmath54 on @xmath55 $ ] ; therefore in the expression for @xmath72 we replace @xmath62 with its approximation .    hence for both methods ( a ) and ( b )",
    ", we have _",
    "@xmath4-norm convergence guarantees_.    alternatively , in our method ( c ) , one can estimate the pareto curve by solving for each @xmath73 $ ] the following parametric pop : @xmath74 with @xmath75 and @xmath76 as in  . notice that by definition @xmath77 .",
    "then , we derive an sdp hierarchy parametrized by @xmath60 , so that the optimal solution @xmath78_{2 d}$ ] of the @xmath60-th relaxation underestimates @xmath79 over @xmath35 $ ] .",
    "in addition , @xmath80 converges to @xmath79 with respect to the @xmath81-norm , as @xmath82 . in this way",
    ", one can approximate from below the set of pareto points , as closely as desired .",
    "hence for method ( c ) , we have _",
    "@xmath5-norm convergence guarantees_.    it is important to observe that even though @xmath83 , @xmath84 and @xmath85 are all global optimization problems we do _ not _ need to solve them exactly .",
    "in all cases the information provided at step @xmath60 of the sdp hierarchy ( i.e. @xmath61 for @xmath83 and @xmath84 and the polynomial @xmath80 for @xmath85 ) permits to define an approximation of the pareto front . in other words even in the absence of convexity the sdp hierarchy allows to approximate the pareto front and of course the higher in the hierarchy the better is the approximation .",
    "the paper is organized as follows .",
    "section  [ sec : prelim ] is dedicated to recalling some background about moment and localizing matrices .",
    "section  [ sec : approx ] describes our framework to approximate the set of pareto points using sdp relaxations of parametric optimization programs .",
    "these programs are presented in section  [ subsec : parampop ] while we describe how to reconstruct the pareto curve in section  [ subsec : sdp ] .",
    "section  [ sec : bench ] presents some numerical experiments which illustrate the different approximation schemes .",
    "let @xmath86 $ ] ( resp .",
    "@xmath86_{2d}$ ] ) denote the ring of real polynomials ( resp . of degree at most @xmath87 ) in the variables @xmath44 and @xmath88 , whereas @xmath89 $ ] ( resp .",
    "@xmath89_d$ ] ) denotes its subset of sums of squares ( sos ) of polynomials ( resp .  of degree at most @xmath87 ) .",
    "for every @xmath90 the notation @xmath91 stands for the monomial @xmath92 and for every @xmath93 , let @xmath94 , whose cardinal is @xmath95 .",
    "a polynomial @xmath96 $ ] is written @xmath97 and @xmath45 can be identified with its vector of coefficients @xmath98 in the canonical basis @xmath99 , @xmath90 . for any symmetric matrix @xmath100 the notation @xmath101 stands for",
    "@xmath100 being semidefinite positive .",
    "a real sequence @xmath102 , @xmath103 , has a _ representing measure _ if there exists some finite borel measure @xmath104 on @xmath105 such that @xmath106 given a real sequence @xmath102 define the linear functional @xmath107\\to{\\mathbb{r}}$ ] by : @xmath108 \\:.\\ ] ]    [ [ moment - matrix ] ] moment matrix + + + + + + + + + + + + +    the _ moment _ matrix associated with a sequence @xmath102 , @xmath103 , is the real symmetric matrix @xmath109 with rows and columns indexed by @xmath110 , and whose entry @xmath111 is just @xmath112 , for every @xmath113 .",
    "if @xmath114 has a representing measure @xmath104 then @xmath115 because @xmath116    [ [ localizing - matrix ] ] localizing matrix + + + + + + + + + + + + + + + + +    with @xmath114 as above and @xmath117 $ ] ( with @xmath118 ) , the _ localizing _ matrix associated with @xmath114 and @xmath119 is the real symmetric matrix @xmath120 with rows and columns indexed by @xmath121 , and whose entry @xmath122 is just @xmath123 , for every @xmath113 . if @xmath114 has a representing measure @xmath104 whose support is contained in the set @xmath124 then @xmath125 because @xmath126    in the sequel , we assume that @xmath127 is contained in a box .",
    "it ensures that there is some integer @xmath128 such that the quadratic polynomial @xmath129 is nonnegative over @xmath46 .",
    "then , we add the redundant polynomial constraint @xmath130 to the definition of @xmath46 .",
    "here , we show that computing the set of pareto points associated with problem  @xmath6 can be achieved with three different parametric polynomial problems . recall that the feasible set of problem  @xmath6 is @xmath131 .",
    "[ [ subsubsec : cvx ] ] method ( a ) : convex sum approximation + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    consider the scalar objective function @xmath132 , @xmath29 $ ] .",
    "let @xmath133 \\times \\s$ ] .",
    "recall from ( [ eq : flamx ] ) that function @xmath134\\to{\\mathbb{r}}$ ] is the optimal value of problem  @xmath83 , i.e.  @xmath135 .",
    "if the set @xmath136 is convex , then one can recover the pareto curve by computing @xmath137 , for all @xmath29 $ ] , see  ( * ? ? ?",
    "* table 11.5 ) .",
    "[ th : fscvx ] assume that @xmath136 is convex .",
    "then , a point @xmath138 belongs to the set of ep points of problem  @xmath6 if and only if there exists some weight @xmath29 $ ] such that @xmath37 is an image unique optimal solution of problem  @xmath83 .    [ [ subsubsec : cheb ] ] method ( b ) : weighted chebyshev approximation + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    reformulating problem  @xmath6 using the chebyshev norm approach is more suitable when the set @xmath136 is not convex .",
    "we optimize the scalar criterion @xmath139 $ ] , @xmath29 $ ] . in this case , we assume without loss of generality that both @xmath1 and @xmath2 are positive . indeed ,",
    "for each @xmath52 , one can always consider the criterion @xmath140 , where @xmath141 is any lower bound of the global minimum of @xmath142 over @xmath46 .",
    "such bounds can be computed efficiently by solving polynomial optimization problems using an sdp hierarchy , see e.g.  @xcite . in practice , we introduce a lifting variable @xmath143 to represent the @xmath144 of the objective function . for scaling purpose , we introduce the constant @xmath145 , with @xmath146 , @xmath52 . then , one defines the constraint set @xmath147 , \\lambda f_1 ( { \\mathbf{x } } ) / c \\leq \\omega , ( 1 - \\lambda ) f_2 ( { \\mathbf{x } } ) / c \\leq \\omega   \\}$ ] , which leads to the reformulation of @xmath148 consistent with ( [ eq : flamx - infty ] ) .",
    "the following lemma is a consequence of  ( * ? ? ?",
    "* corollary 11.21 ( a ) ) .",
    "[ th : fsnoncvx ] suppose that @xmath1 and @xmath2 are both positive .",
    "then , a point @xmath138 belongs to the set of ep points of problem  @xmath6 if and only if there exists some weight @xmath149 such that @xmath37 is an image unique optimal solution of problem  @xmath84 .    [ [ subsubsec : l1 ] ] method ( c ) : parametric sublevel set approximation + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    here , we use an alternative method inspired by  @xcite .",
    "problem  @xmath6 can be approximated using the criterion @xmath2 as the objective function and the constraint set @xmath150 \\times \\s : ( f_1 ( { \\mathbf{x } } ) - a_1 ) / ( b_1 - a_1 ) \\leq \\lambda\\},\\ ] ] which leads to the parametric pop @xmath151 which is consistent with ( [ eq : flamx - u ] ) , and such that @xmath77 for all @xmath152 $ ] , with @xmath75 and @xmath76 as in  .",
    "[ th : f2u ] suppose that @xmath138 is an optimal solution of problem  @xmath85 , with @xmath153 $ ]",
    ". then @xmath37 belongs to the set of weakly ep points of problem  @xmath6 .",
    "[ pr : f2u ] suppose that there exists @xmath18 such that @xmath154 and @xmath155 .",
    "then @xmath156 is feasible for problem  @xmath85 ( since @xmath157 ) and @xmath158 , which leads to a contradiction .",
    "note that if a solution @xmath159 is unique then it is ep optimal .",
    "moreover , if a solution @xmath159 of problem @xmath160 solves also the optimization problem @xmath161 , then it is an ep optimal point ( see  @xcite for more details ) .",
    "notice that the three problems  @xmath83 , @xmath84 and @xmath85 are particular instances of the generic parametric optimization problem @xmath162 .",
    "the feasible set @xmath163 ( resp .",
    "the objective function @xmath164 ) corresponds to @xmath165 ( resp .",
    "@xmath166 ) for problem  @xmath83 , @xmath167 ( resp .",
    "@xmath168 ) for problem  @xmath84 and @xmath169 ( resp .",
    "@xmath170 ) for problem  @xmath85 .",
    "we write @xmath171 .",
    "note also that @xmath172 ( resp .",
    "@xmath173 ) when considering problem  @xmath83 and problem  @xmath85 ( resp .",
    "problem  @xmath84 ) .",
    "let @xmath174 be the space of probability measures supported on @xmath163 .",
    "the function @xmath164 is well - defined because @xmath45 is a polynomial and @xmath163 is compact .",
    "let @xmath175 , with @xmath176 , @xmath177 and consider the optimization problem : @xmath178    [ th:1 ] the optimization problem @xmath179 has an optimal solution @xmath180 and if @xmath181 is as in   then @xmath182 suppose that for almost all ( a.a . ) @xmath183 $ ] , the parametric optimization problem @xmath184 has a unique global minimizer @xmath185 and let @xmath186 \\to { \\mathbb{r}}$ ] be the function @xmath187 , @xmath64 . then for problem  @xmath83 , @xmath188 , for problem  @xmath84 , @xmath189 and for problem  @xmath85 , @xmath190",
    "the proof of   follows from  ( * ? ? ?",
    "* theorem 2.2 ) with @xmath191 in lieu of @xmath192 .",
    "now , consider the particular case of problem  @xmath83 . if @xmath83 has a unique optimal solution @xmath193 for a.a .",
    "@xmath152 $ ] then @xmath194 for a.a .  @xmath152 $ ] .",
    "the proofs for @xmath84 and @xmath195 are similar .",
    "we set @xmath196 , @xmath197 , @xmath198 and @xmath199 .",
    "then , consider the following semidefinite relaxations for @xmath200 : @xmath201    [ lem2 ] assume that for a.a .",
    "@xmath183 $ ] , the parametric optimization problem @xmath184 has a unique global minimizer @xmath185 , and let @xmath202 , @xmath203 , be an optimal solution of",
    ". then @xmath204 in particular , for @xmath205 , for all @xmath206 , @xmath64 , @xmath207    let @xmath180 be an optimal solution of problem @xmath179 . from ( * ? ? ?",
    "* theorem 3.3 ) , @xmath208 which is  .",
    "next , from ( [ eq : lem2 - 1 ] ) , one has for @xmath205 : @xmath209 for all @xmath210 , @xmath64 . thus   holds .",
    "the dual of the sdp   reads : @xmath211_{2d } , \\sigma_l \\in \\sigma[y,{\\mathbf{x}}]_{d - v_l } , \\ : l=0,\\ldots , m ' \\ : .\\\\",
    "\\end{array}\\right.\\ ] ]    [ th : dual ] consider the dual semidefinite relaxations defined in  .",
    "then , one has :    1 .",
    "@xmath212 as @xmath82 .",
    "2 .   let @xmath80 be a nearly optimal solution of  , i.e. , such that @xmath213 .",
    "then @xmath214 underestimates @xmath164 over @xmath46 and @xmath215 .",
    "[ pr : dual ] it follows from  ( * ? ? ? * theorem 3.5 ) .",
    "note that one can directly approximate the pareto curve from below when considering problem  @xmath85 .",
    "indeed , solving the dual sdp   yields polynomials that underestimate the function @xmath216 over @xmath55 $ ] .",
    "[ rk : hertog ] in  ( * ? ? ?",
    "* appendix a ) , the authors derive the following relaxation from problem  @xmath85 : @xmath217_{d } }   & \\displaystyle\\int_{0}^1 q ( \\lambda ) \\ , d\\lambda\\:,\\\\ \\mbox{s.t .",
    "} & f_2 ( { \\mathbf{x } } ) \\geq q (   \\frac{f_1({\\mathbf{x } } ) - a_1}{b_1 - a_1 } ) \\ : , \\forall { \\mathbf{x}}\\in \\s \\:.\\\\ \\end{array}\\right.\\ ] ] since one wishes to approximate the pareto curve , suppose that in ( [ eq : dualsdphertog ] ) one also imposes that @xmath218 is nonincreasing over @xmath55 $ ] . for even degree approximations , the formulation   is equivalent to @xmath219_{2 d } }   &",
    "\\displaystyle\\int_{0}^1 q ( \\lambda ) \\ , d\\lambda \\:,\\\\ \\mbox{s.t . } & f_2 ( \\lambda ) \\geq q(\\lambda )   \\ : , \\forall \\lambda \\in [ 0 , 1 ] \\:,\\\\   & \\frac{f_1({\\mathbf{x } } ) - a_1}{b_1 - a_1 } \\leq \\lambda \\ : , \\forall \\lambda \\in [ 0 , 1]\\ : , \\forall { \\mathbf{x}}\\in \\s \\ : .\\\\ \\end{array}\\right.\\ ] ] thus , our framework is related to  @xcite by observing that is a strengthening of  .    when using the reformulations @xmath83 and @xmath84 , computing the pareto curve is computing ( or at least providing good approximations ) of the functions @xmath220\\to{\\mathbb{r}}$ ] defined above , and we consider this problem as an _ inverse problem from generalized moments_.    @xmath221 for any fixed @xmath205 , we first compute approximations @xmath222 , @xmath223 , @xmath224 , of the generalized moments @xmath225 , with the convergence property @xmath226 as @xmath63 , for each @xmath64 .",
    "@xmath221 then we solve the inverse problem : given a ( good ) approximation @xmath227 of @xmath228 , find a polynomial @xmath229 of degree at most @xmath59 such that @xmath230 .",
    "importantly , if @xmath231 then @xmath229 minimizes the @xmath232-norm @xmath233 ( see  [ sec : inverse ] for more details ) .",
    "[ [ computational - considerations ] ] computational considerations + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the presented parametric optimization methodology has a high computational cost mainly due to the size of sdp relaxations ( [ eq : primalsdp ] ) and the state - of - the - art for sdp solvers . indeed , when the relaxation order @xmath60 is fixed , the size of the sdp matrices involved in   grows like @xmath234 for problem  @xmath83 and like @xmath235 for problems @xmath84 and @xmath85 . by comparison ,",
    "when using a discretization scheme , one has to solve @xmath236 polynomial optimization problems , each one being solved by programs whose sdp matrix size grows like @xmath237 . section  [ sec : bench ] compares both methods .    therefore these techniques are of course limited to problems of modest size involving a small or medium number of variables @xmath238 .",
    "we have been able to handle non convex problems with about @xmath239 variables .",
    "however when a correlative sparsity pattern is present then one may benefit from a sparse variant of the sdp relaxations for parametric pop which permits to handle problems of much larger size ( e.g. with more than @xmath240 variables ) ; see e.g.  @xcite for more details .",
    "the semidefinite relaxations of problems  @xmath83 , @xmath84 and @xmath85 have been implemented in matlab , using the gloptipoly software package  @xcite , on an intel core i5 cpu ( @xmath241ghz ) .",
    "we have considered the following test problem mentioned in  ( * ? ? ?",
    "* example 11.8 ) :    [ ex : ex11_4 ] let @xmath242 figure  [ fig : sfscvx ] displays the discretization of the feasible set @xmath46 as well as the image set @xmath243 . the weighted sum approximation method ( a ) being suitable when the set @xmath136 is convex , one reformulates the problem as a particular instance of problem  @xmath83 .",
    "for comparison , we fix discretization points @xmath244 uniformly distributed on the interval @xmath55 $ ] ( in our experiments , we set @xmath245 ) .",
    "then for each @xmath246 , we compute the optimal value @xmath247 of the polynomial optimization problem @xmath248 .",
    "the dotted curves from figure  [ fig : undercvx ] display the results of this discretization scheme . from the optimal solution of the dual sdp   corresponding to our method ( a ) , namely weighted convex sum approximation , one obtains the degree 4 polynomial @xmath249 ( resp . degree 6 polynomial @xmath250 ) with moments up to order 8 ( resp .  12 ) , displayed on figure  [ fig : undercvx ]  ( a ) ( resp .",
    "one observes that @xmath251 and @xmath252 , which illustrates lemma  [ th : dual ] ( ii ) .",
    "the higher relaxation order also provides a tighter underestimator , as expected .",
    "then , for each @xmath253 , we compute an optimal solution @xmath254 of problem  @xmath248 and we set @xmath255 , @xmath256 .",
    "hence , we obtain a discretization @xmath257 of the pareto curve , represented by the dotted curve on figure  [ fig : approxcvx ] .",
    "the required cpu running time for the corresponding sdp relaxations is @xmath258sec .",
    "we compute an optimal solution of the primal sdp   at order @xmath259 , in order to provide a good approximation of @xmath260 moments with @xmath261 .",
    "then , we approximate each function @xmath66 , @xmath262 with a polynomial @xmath263 of degree @xmath59 by solving the inverse problem from generalized moments ( see appendix  [ sec : inverse ] ) . the resulting pareto curve approximation using degree 4 estimators @xmath264 and @xmath265 is displayed on figure  [ fig : approxcvx ]  ( a ) . for comparison purpose , higher",
    "degree approximations are also represented on figure  [ fig : approxcvx ]  ( b ) ( degree 6 polynomials ) and figure  [ fig : approxcvx ]  ( c ) ( degree 8 polynomials ) .",
    "it consumes only @xmath266sec to compute the two degree 4 polynomials @xmath264 and @xmath265 , @xmath267sec for the degree 6 polynomials and @xmath268sec for the degree 8 polynomials .",
    "we have also solved the following two - dimensional nonlinear problem proposed in  @xcite :    [ ex : test4 ] let @xmath269 \\times [ 0 , 3 ] : g_1({\\mathbf{x } } ) \\geq 0 , g_2({\\mathbf{x } } ) \\geq 0 \\ } \\ : . & & \\end{aligned}\\ ] ] figure  [ fig : sfsnoncvx ] depicts the discretization of the feasible set @xmath46 as well as the image set @xmath243 for this problem . note that the pareto curve is non - connected and non - convex .    in this case , the weighted convex sum approximation of method ( a ) would not allow to properly reconstruct the pareto curve , due to the apparent nonconvex geometry of the set @xmath136 .",
    "hence we have considered methods ( b ) and ( c ) .    [ [ method - b - weighted - chebyshev - approximation ] ]",
    "method ( b ) : weighted chebyshev approximation + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    as for example  [ ex : ex11_4 ] , one solves the sdp   at order @xmath259 and approximate each function @xmath66 , @xmath262 using polynomials of degree 4 , 6 and 8 .",
    "the approximation results are displayed on figure  [ fig : approxnoncvx ] .",
    "degree 8 polynomials give a closer approximation of the pareto curve than degree 4 or 6 polynomials .",
    "the solution time range is similar to the benchmarks of example  [ ex : ex11_4 ] .",
    "the sdp running time for the discretization is about @xmath270min .",
    "the degree 4 polynomials are obtained after @xmath271sec , the degree 6 polynomials @xmath272 , @xmath273 after @xmath274sec and the degree 8 polynomials after @xmath275min .    [ [ method - c - parametric - sublevel - set - approximation ] ] method ( c ) : parametric sublevel set approximation + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    better approximations can be directly obtained by reformulating example  [ ex : test4 ] as an instance of problem  @xmath85 and compute the degree @xmath60 optimal solutions @xmath214 of the dual sdp  .",
    "figure  [ fig : f2utest4 ] reveals that with degree 4 polynomials one can already capture the change of sign of the pareto front curvature ( arising when the values of @xmath1 lie over @xmath276 $ ] ) .",
    "observe also that higher - degree polynomials yield tighter underestimators of the left part of the pareto front .",
    "the cpu time ranges from @xmath267sec to compute the degree 4 polynomial @xmath249 , to @xmath275sec for the degree 6 computation and @xmath277sec for the degree 8 computation .",
    "the discretization of the pareto front is obtained by solving the polynomial optimization problems @xmath278 .",
    "the corresponding running time of sdp programs is @xmath279sec .",
    "the same approach is used to solve the random bicriteria problem of example  [ ex : rnd ] .",
    "[ ex : rnd ] here , we generate two random symmetric real matrices @xmath280 as well as two random vectors @xmath281",
    ". then we solve the quadratic bicriteria problem @xmath282^{15 } } \\{f_1({\\mathbf{x } } ) , f_2({\\mathbf{x } } ) \\}$ ] , with @xmath283 , for each @xmath64 .",
    "experimental results are displayed in figure  [ fig : rnd ] .",
    "for a 15 variable random instance , it consumes @xmath284min of cpu time to compute @xmath249 against only @xmath267sec for @xmath285 but the degree 4 underestimator yields a better point - wise approximation of the pareto curve .",
    "the running time of sdp programs is more than @xmath286 hours to compute the discretization of the front .",
    "the present framework can tackle multicriteria polynomial problems by solving semidefinite relaxations of parametric optimization programs .",
    "the reformulations based on the weighted sum approach and the chebyshev approximation allow to recover the pareto curve , defined here as the set of weakly edgeworth - pareto points , by solving an inverse problem from generalized moments .",
    "an alternative method builds directly a hierarchy of polynomial underestimators of the pareto curve .",
    "the numerical experiments illustrate the fact that the pareto curve can be estimated as closely as desired using semidefinite programming within a reasonable amount of time for problem still of modest size . finally our approach could be extended to higher - dimensional problems by exploiting the system properties such as sparsity patterns or symmetries .",
    "this work was partly funded by an award of the simone and cino del duca foundation of institut de france .",
    "suppose that one wishes to approximate each function @xmath287 , @xmath64 , with a polynomial of degree @xmath59 . one way to do this is to search for @xmath288 $ ] , @xmath64 , optimal solution of @xmath289 } \\ : \\displaystyle\\int_0 ^ 1(h(\\lambda)-f^*_j(\\lambda))^2d\\lambda\\ : , \\quad j=1,2 \\:.\\ ] ] let @xmath290 be the hankel matrix associated with the moments of the lebesgue measure on @xmath291 $ ] , i.e.  @xmath292 , @xmath293 .",
    "elijah polak . on the approximation of solutions to multiple criteria decision making problems . in milan",
    "zeleny , editor , _ multiple criteria decision making kyoto 1975 _ , volume 123 of _ lecture notes in economics and mathematical systems _ , pages 271282 .",
    "springer berlin heidelberg , 1976 .",
    "hayato waki , sunyoung kim , masakazu kojima , and masakazu muramatsu .",
    "sums of squares and semidefinite programming relaxations for polynomial optimization problems with structured sparsity .",
    ", 17(1):218242 , 2006 ."
  ],
  "abstract_text": [
    "<S> we consider the problem of constructing an approximation of the pareto curve associated with the multiobjective optimization problem @xmath0 , where @xmath1 and @xmath2 are two conflicting polynomial criteria and @xmath3 is a compact basic semialgebraic set . </S>",
    "<S> we provide a systematic numerical scheme to approximate the pareto curve . </S>",
    "<S> we start by reducing the initial problem into a scalarized polynomial optimization problem ( pop ) . </S>",
    "<S> three scalarization methods lead to consider different parametric pops , namely ( a ) a weighted convex sum approximation , ( b ) a weighted chebyshev approximation , and ( c ) a parametric sublevel set approximation . for each case </S>",
    "<S> , we have to solve a semidefinite programming ( sdp ) hierarchy parametrized by the number of moments or equivalently the degree of a polynomial sums of squares approximation of the pareto curve . </S>",
    "<S> when the degree of the polynomial approximation tends to infinity , we provide guarantees of convergence to the pareto curve in @xmath4-norm for methods ( a ) and ( b ) , and @xmath5-norm for method ( c ) .    </S>",
    "<S> [ [ keywords ] ] keywords + + + + + + + +    parametric polynomial optimization problems , semidefinite programming , multicriteria optimization , sums of squares relaxations , pareto curve , inverse problem from generalized moments </S>"
  ]
}