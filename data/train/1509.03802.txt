{
  "article_text": [
    "stochastic simulations have been an essential tool in analyzing reaction networks encountered in biology , catalysis , and materials growth . however ,",
    "it is commonplace for reaction networks to exhibit a large disparity in time scales .",
    "these multi - scale stochastic reaction networks can impose an enormous computational burden in order to simulate them exactly .",
    "exact techniques require computation of every reaction at the fastest time - scale , resulting in an exponentially growing load to observe dynamics on the slowest time - scale .",
    "many works have attempted to develop approximate algorithms which allow faster computation with minimal loss of accuracy @xcite .",
    "one approach , which we refer to as stochastic averaging , takes its inspiration from classical singular perturbation theory of ordinary differential equations @xcite .",
    "the idea is that the fast dynamics come to quasi - equilibrium before the slow dynamics take effect , hence one may model the slow time scale dynamics with their averages against the steady - state distribution of the fast dynamics . by estimating the steady - state expectations of the slow propensities",
    ", one can then jump the system ahead to the next slow reaction and advance the time clock on the slow scale ( skipping over needless computations of fast reactions ) .",
    "in addition , one often desires the sensitivities of the system @xmath0 with respect to the reaction parameters @xmath1 .",
    "the sensitivities give important insight into the system , indicating directions for gradient - descent type optimization as well as determining bounds for quantifying the uncertainty @xcite .",
    "current techniques for estimating the sensitivities have _ large variance _ , requiring many more samples than those for estimating @xmath2 alone @xcite .",
    "thus computing sensitivities of multi - scale systems using single - scale techniques is often a computationally intractable problem .    in this work ,",
    "we use results from two - time - scale ( tts ) markov chains @xcite to show the error of stochastic averaging algorithms is inverse to the scale disparity in the system .",
    "as opposed to the previous approaches of transforming the system variables into auxiliary fast and slow variables@xcite , we partition the underlying ( discrete ) state space and derive a singular perturbation expansion of the corresponding probability measure .",
    "the first order term can then be identified from computables of the averaged process , leading to a rigorous theoretical framework for applying singular perturbation averaging for stochastic systems .",
    "furthermore , this new formulation allows one to identify a macroscopic `` averaged '' reaction network on a reduced state space whose time - steps are on the macro ( slow ) time - scale .",
    "thus , it provides a framework for applying single - scale sensitivity analysis techniques to the multi - scale system .",
    "previous works have exploited similar model reduction techniques to estimate sensitivities via finite differences@xcite or a `` truncated '' version of a likelihood ratio estimator@xcite .",
    "this work develops an accelerated `` two - time - scale '' version of the likelihood ratio ( girsanov transform ) method @xcite for estimating system sensitivities of the multiscale system .",
    "the tts - lr method computes sensitivity reweighting coefficients of the macro ( reduced - state ) process using a representation in terms of the steady - state sensitivities of the micro ( fast ) process .",
    "these micro - level sensitivities can in turn be computed online during the micro - equilibriation process . to this end",
    ", we propose a new lower - variance `` ergodic likelihood ratio '' estimator for approximating _ steady - state sensitivities _ of single and multi - scale systems .",
    "the outline of the remainder of the paper is as follows : section [ sec : formulation ] gives the theoretical basis of the paper .",
    "the two - time - scale formulation is presented and error bounds are established .",
    "section [ sec : tts_sens ] then uses the tts framework for the purpose of sensitivity analysis . a new ergodic likelihood ratio estimator is developed for single - scale steady - state sensitivity analysis , and is then adapted to the multiscale system .",
    "section [ sec : bmstop ] develops a batch - means stopping rule for determining when the micro - scale system has come to equilibrium .",
    "numerical results are presented in section [ sec : sim_results ] supporting the effectiveness of the methods presented .",
    "concluding remarks are given in section [ sec : conclusion ] , and proofs of theorems are relegated to the appendix .",
    "we briefly review the markov chain model of reaction networks . while our motivation stems from chemical reaction networks , we note that much of the formulation carries over to general markov chains on integer lattices .",
    "suppose we have @xmath3 species described by @xmath4 \\in { \\mathcal{m}}\\subset \\mathbb{z}^d$ ] and @xmath5 reactions @xmath6 .",
    "in stochastic reaction networks , one views @xmath7 as a continuous - time markov chain ( ctmc ) in the state space @xmath8 . when reaction @xmath9 fires at time @xmath10 , the state is updated by the _ stoichiometric vector _",
    "@xmath11 so that @xmath12",
    ". given the set of reaction parameters @xmath13 $ ] , one characterizes the probabilistic evolution of @xmath7 by the _ propensity functions _",
    "( intensity functions ) @xmath14 .",
    "the propensity functions are such that , given @xmath15 , the probability of one or more firing of reaction @xmath9 during time @xmath16 $ ] is @xmath17 as @xmath18 ; i.e. @xmath14 is the instantaneous rate / probability of reaction @xmath9 firing .",
    "a common model for the propensities functions is that of _ mass - action kinetics_. under this assumption , the propensity functions are of the form @xmath19 where @xmath20 is the number of molecules of species @xmath21 required for reaction @xmath9 to fire .",
    "mass action kinetics assumes the system is well - mixed , so molecular interactions are proportional to their counts . from the propensity functions @xmath14",
    ", one can construct the infinitesimal generator @xmath22 of the markov chain .",
    "viewed as an operator on functions @xmath23 of the state - space @xmath8 , we have @xmath24 for finite state - space @xmath8 ( bounded molecule counts ) , one may also view the generator @xmath25 as a matrix . while the state - space is typically intractably large ,",
    "the generator is sparse with only @xmath26 non - zero entries in each row , @xmath27 where @xmath28 .",
    "writing @xmath29 to be the counting process representing how many reactions of type @xmath9 have fired by the time @xmath10 , we have that @xmath30 . using the _ random time change _ representation @xcite",
    ", we write @xmath7 as @xmath31 where @xmath32 are independent unit - rate poisson processes .",
    "this representation is tremendously useful in conducting analysis of the trajectories . in particular",
    ", it leads to formulations of the next - reaction method @xcite and interpreting simulated trajectories in the path - space to allow for coupling paths @xcite as well as path - wise differentiation @xcite .",
    "when simulating exact trajectories ( using any exact method ; direct ssa , next - reaction , etc ) , the propensity functions @xmath33 probabilistically determine both the time between reactions @xmath34 as well as the next reaction @xmath35 to fire .",
    "the likelihood that reaction @xmath36 is the next to fire is proportional to its propensity @xmath37 ; i.e. @xmath38 .",
    "the time between reactions has an exponential distribution with the rate @xmath39 ; i.e. @xmath40 with the mean @xmath41 .",
    "multi - scale dynamics occur when the propensity functions have large magnitude disparities .",
    "if @xmath42 for all @xmath43 , then @xmath44 and @xmath45 . thus , with a high probability",
    "the next reaction in an exact trajectory will be @xmath36 and the time clock will advance on the order of @xmath46 .",
    "such multi - scale networks then require an enormous number of computations to sample `` slow '' reactions and reach the required time horizon for the entire system to relax .",
    "we now consider reaction networks with two scales of dynamics . for further motivation and discussion of reaction networks with multiple time - scales , we refer readers to refs .",
    "kang_separation_2013 , e_nested_2007 , huang_strong_2014 , gupta_sensitivity_2014 and references therein .",
    "we instead focus on our formulation for the separation of time - scales and the averaged process via the partitioning of the state space into `` fast - classes '' . though analogous to the techniques of transforming the species variables into auxiliary fast / slow variables @xcite or projecting to remainder spaces @xcite",
    ", the direct partitioning of the state space will allow us to construct a singular perturbation expansion of the probability measure and establish the rate of convergence of such averaging methods .",
    "in addition , it provides a framework for applying likelihood ratio type sensitivity estimates to the averaged process as we shall see in the sequel .    here",
    ", we assume that the disparity in the propensity functions results from magnitude disparities in the reaction parameters @xmath47 . in order to illustrate the stiffness",
    ", we consider the reaction network @xmath48 where @xmath49 is a measure of the scale disparity ( stiffness ) between the fast reaction parameters @xmath50 $ ] and the slow reaction parameters @xmath51 $ ] .",
    "as the stiffness parameter @xmath52 the fast reactions @xmath53 dominate the system , resulting in the multi - scale computational problem described above .    in general ,",
    "suppose a reaction network has species @xmath54 $ ] and reactions @xmath55 .",
    "we shall assume that the propensity functions @xmath14 are of the form ( [ eq : mass - action - prop ] ) ( mass - action kinetics , though other forms may also be treated ) , and that each reaction is indexed by its own reaction parameter @xmath47 .",
    "as in the illustrating example , we assume that there is a scale disparity in the reaction parameters between a set of `` fast reactions '' and a set of `` slow reactions '' .",
    "thus we can write @xmath56 = [ { { { \\boldsymbol{\\alpha } } } } /{\\varepsilon } , { { { \\boldsymbol{\\beta } } } } ] $ ] , where @xmath57 $ ] are the slow reaction parameters , @xmath49 is the stiffness parameter , and @xmath58 $ ] are the underlying ( rescaled ) reaction parameters for the fast reactions .",
    "to ease referencing , we will often index reactions and propensity functions directly by their reaction parameter .",
    "e.g. , @xmath59 is the reaction with reaction parameter @xmath60 and propensity function @xmath61 ( where @xmath62 is given by ) . for the fast reactions",
    "@xmath63 , we use @xmath64 to denote the exact propensity function and @xmath65 to denote the rescaled version .",
    "let @xmath66 denote the markov chain determined by the exact propensity functions @xmath67 and @xmath68 .",
    "we can write the generator @xmath69 of the exact process as before , and observe that @xmath70 f \\right ) ( x ) \\end{aligned}\\end{aligned}\\ ] ] where @xmath71 is the generator of the chain under only the slow dynamics ( determined by slow reactions @xmath72 ) , and @xmath73 is the generator of the chain under only the fast dynamics ( with the rescaled propensity functions @xmath74 ) .",
    "thus we have a decomposition of the generator into the fast and slow dynamics , @xmath75 one can also view the generator @xmath76 as a matrix . in this case , we can write the element corresponding to the rate of transition from state @xmath77 to state @xmath78 as @xmath79_{x , y }    = \\left\\ {      \\begin{array}{*1{>{\\displaystyle}c } l }      -\\sum_{\\alpha \\in \\boldsymbol{\\alpha } } \\lambda_\\alpha(x )      & \\quad x = y \\\\      \\sum_{\\alpha : r_\\alpha(x)=y }",
    "\\lambda_\\alpha(x )      & \\quad x \\neq y    \\end{array }    \\right .",
    "\\ ] ] and similarly for @xmath80_{x , y}$ ] .    as @xmath52 only the fast reactions @xmath81 fire , and so we define an equivalence relation on states @xmath82 , by @xmath83 if they are mutually accessible through only fast reactions .",
    "this defines a partition of the state space @xmath8 into `` fast - classes '' @xmath84 which are by construction the invariant ( irreducible ) classes of @xmath8 under @xmath73 ; e.g. @xmath85 where @xmath86 are the number of invariant `` fast - classes '' , and @xmath87 is the number of states inside fast - class @xmath84 .",
    "for ease of presentation , in the present discussion we shall assume the state space is finite .",
    "[ assum : finite_states ] the state space @xmath8 is finite , such that @xmath88 .",
    "thus the number of fast classes @xmath89 and the number of states in each fast - class @xmath90 , so that @xmath91 .",
    "assumption  [ assum : finite_states ] is made only to simplify the discussion .",
    "one may also treat the infinite state case with some mild additional conditions on @xmath73 and @xmath71 to ensure non - explosiveness and ergodicity of the underlying ( rescaled ) chain@xcite . in addition",
    ", we shall impose the following assumption .",
    "[ assum : recurr_states ] each state of @xmath8 is recurrent , so that there are no absorbing / transient states .    assumption  [ assum : recurr_states ] is satisfied if , for example , all reactions are reversible ( or often times if only the fast reactions are reversible ) .",
    "one may also treat the case with transient / absorbing classes with some additional stability assumptions to ensure the fast dynamics decay to steady - state ; see section 4.4 of ref .",
    "yin_continuous - time_2013 for more details .",
    "under assumption  [ assum : recurr_states ] , we can reorder the state space so that @xmath92 $ ] is block - diagonal .",
    "here , one can view the generators @xmath93 as the restriction of @xmath73 to the ( irreducible ) fast - class @xmath84 ( fast - only dynamics when @xmath94 ) . in light of the finite state - space and positive",
    "recurrence , each @xmath95 is ergodic and has a stationary ( steady - state ) probability measure @xmath96 such that @xmath97 ( with @xmath98 interpreted as row vectors ) .    using the above formulation",
    ", we can restate the averaging principle @xcite as follows .",
    "for small @xmath99 and @xmath94 , @xmath100 will relax to its steady - state distribution @xmath101 on the micro time - scale @xmath102 before any slow reaction fires ( on the macro time scale @xmath10 ) .",
    "thus , one can use the stationary average of the slow propensity functions @xmath103 to determine the distribution of time until the next slow reaction as well as the probabilities for the next slow reaction being @xmath104 .",
    "these can then be used to simulate a trajectory of the slow ( macro - scale ) process .",
    "we shall further develop this idea more precisely in the remainder .",
    "write @xmath105 , and @xmath106 as before , so that @xmath107 , @xmath108 , and @xmath109 .",
    "write @xmath110 \\in \\mathbb{r}^ { { { n_{c}}}\\times m}$ ] .",
    "write @xmath111 for @xmath112 ' \\in \\mathbb{r}^{m_k \\times 1}$ ] and @xmath113 $ ]    with @xmath114 describing the limit behavior inside each fast - class on the micro time scale , one can then consider the distribution of the exact system @xmath115 on the macro time scale .",
    "heuristically , one expects a trajectory to enter a fast - class of states @xmath116 and quickly iterate through many fast reactions until the distribution of the trajectory reaches the steady - state @xmath117 .",
    "eventually , a slow reaction will fire to move the trajectory to a new fast - class @xmath118 ( see figure  [ fig : tts_crn_example ] ) .",
    "indeed , writing @xmath119",
    "\\in \\mathbb{r}^ { { { n_{c}}}\\times { { n_{c } } } } ,    \\end{aligned}\\end{aligned}\\ ] ] we see that @xmath120 is itself a generator of an `` averaged '' ctmc reaction network , whose `` states '' correspond to fast - classes @xmath84 .",
    "write @xmath121 for the `` averaged '' process generated by @xmath120 .",
    "together , @xmath120 and @xmath121 describe the limit ( as @xmath52 ) of the average rate that the exact process @xmath66 moves between the fast - classes @xmath122 via slow reactions .",
    "furthermore , we can identify the elements of @xmath120 from the steady - state averages of the slow propensity functions .",
    "first , note that every slow reaction carries each fast class to a unique new fast - class ; that is , if @xmath123 and @xmath124 , then @xmath125 .",
    "thus , @xmath126 is well - defined .",
    "then , using the form of @xmath127 together with , we have @xmath128 for @xmath129 , and similarly we see that @xmath130 with this formulation , we see that generator @xmath120 corresponds to a meta `` macro '' reaction network with the state - space @xmath131 , reactions @xmath132 and propensities @xmath133 .",
    "figure  [ fig : tts_crn_example ] depicts such a macro chain for the macro process @xmath121 .",
    "is an equivalence class of states accessible by fast - reactions @xmath81 .",
    "slow reactions @xmath72 carry each fast - class to a unique new fast - class .",
    "the averaged system @xmath121 forms a meta `` macro '' markov chain among fast - classes with propensities @xmath134.,scaledwidth=45.0% ]    if we can estimate the average slow - propensities @xmath135 within each fast - class ( say , through ergodic time averages of the fast - only process ) , then one can simulate a trajectory of the macro process @xmath121 from these average propensities using _ any _ single - scale monte carlo simulation ( e.g. direct ssa , next - reaction , etc ) . furthermore ,",
    "if one is ultimately concerned with estimating @xmath136 for some observable ( quantity of interest ) @xmath137 , then one can define an augmented functional @xmath138 on @xmath139 by @xmath140 it shall be shown that @xmath141 for large enough @xmath10 and sufficiently small @xmath99 .    to illustrate how one can implement the averaging scheme to generate macro - trajectories , we present the following tts vlersion of the direct ssa ( since it is the most succinct to write ) . in this case",
    ", the tts ssa is essentially the same algorithm as in refs .",
    "e_nested_2007 , samant_overcoming_2005 . however , we emphasize that the same method can be used to create a tts version of any exact method defined by the propensity functions .",
    "in particular , one can just as easily construct an analogous tts next - reaction type algorithm @xcite for tightly coupled trajectories .",
    "[ alg : tts - ssa ] to simulate a trajectory of the macro - process @xmath142 until macro time - horizon @xmath143 :    1 .",
    "initialize @xmath77 at a macro time @xmath144 ; @xmath145 for some ( unknown ) @xmath146 2 .",
    "simulate the fast - only reaction network @xmath147 until time - averages of observable @xmath23 and slow propensities @xmath148 relax to steady - state : @xmath149 3 .",
    "observe terminal state @xmath150 .",
    "compute @xmath151 4 .",
    "sample time to next slow reaction : @xmath152 5 .",
    "sample next slow rxn to fire @xmath153 $ ] 6 .",
    "update macro time @xmath154 and move to the next fast class by taking @xmath155 7 .",
    "return to * ( 1 ) * until macro time horizon @xmath143 is reached      here we use the above formulation of stiff networks to establish convergence results and error bounds for the averaged process obtained by algorithm  [ alg : tts - ssa ] .",
    "they are largely obtained by applying results from ref .",
    "yin_continuous - time_2013 to the two - time - scale markov chain developed above .",
    "we give the statements below and defer to the appendix for the proofs .    from the exact chain @xmath66 ,",
    "define a stochastic process @xmath156 taking values in @xmath157 by @xmath158 for @xmath159 . note that @xmath156 is not , in general , a markov chain .",
    "however , one expects that as @xmath52 , the process @xmath156 converges to @xmath121 in some sense .",
    "[ prop : weak_convergence ] under assumptions  [ assum : recurr_states ] and [ assum : finite_states ] , as @xmath52 , @xmath160 converges weakly to @xmath161 in the skorohod space @xmath162 ; \\overline{{\\mathcal{m } } } ) $ ] for any time horizon @xmath144 .",
    "the above proposition establishes weak convergence of the projection ( onto fast - classes ) of the exact system @xmath115 to the averaged meta system @xmath163 as @xmath52 .",
    "this is essentially the same result as established in ref .",
    "kang_separation_2013 , where the authors instead consider the disparity of the propensities as the system size ( molecule count ) @xmath164 . in both formulations",
    ", one selects a reference scale and then examines limit behavior against the reference scale as the disparity increases ( @xmath52 or @xmath164 ) .",
    "however , in practice one implements the averaging procedure to approximate a system with a fixed , positive scale disparity . naturally , one is then concerned about the induced error from the averaging approximation .",
    "write @xmath165 for the probability measure ( on @xmath139 ) induced by the averaged process @xmath163 at time @xmath144 . at the end of a tts simulation ,",
    "one obtains a terminal state @xmath166 , where @xmath167 is the probability measure on @xmath8 induced by the last state observed from the terminal fast - class .",
    "thus , @xmath167 is determined by @xmath168 and @xmath114 .",
    "write @xmath169 for the probability measure on @xmath8 induced from the exact process @xmath115 . since @xmath170 is the distribution we would see from an exact simulation , and",
    "@xmath167 is the distribution from the tts simulation , the question becomes : what is the error of @xmath167 from @xmath170 ?",
    "one can take a singular perturbation expansion of @xmath170 in terms of @xmath99 and identify the leading term as @xmath167 to obtain the following result .",
    "[ thm : prob_err_bound ] let @xmath171 . then under assumptions [ assum : finite_states ] , [ assum : recurr_states ] , we have @xmath172 where @xmath173 denotes the @xmath174 norm",
    ".    in theorem  [ thm : prob_err_bound ] , @xmath175 is the slowest rate of convergence of @xmath176 to the steady - state @xmath177 among all fast - classes @xmath84 . thus , as long as the macro time horizon @xmath144 is large enough to ensure the fast dynamics have relaxed to steady state ( @xmath178 ) , then the error becomes @xmath179 .",
    "writing @xmath180 for the stationary distribution corresponding to the tts probability measure @xmath181 , it is not hard to see that @xmath182 , the product of the steady - state distribution between fast - classes @xmath183 and the steady - state distribution within fast - classes @xmath114 .",
    "write @xmath184 for the steady - state distribution corresponding to the exact process generated by @xmath185 . then using theorem  [ thm : prob_err_bound ] and exponential convergence to the steady state",
    ", we obtain the following error bounds .",
    "[ cor : expectation - error ] under assumptions [ assum : finite_states ] and [ assum : recurr_states ] , @xmath186 and @xmath187 for sufficiently large @xmath144 .",
    "thus , for all bounded functions @xmath23 on the state space @xmath8 , @xmath188    corollary [ cor : expectation - error ] is of great practical use , as it says that the expected value of the macro - process @xmath142 with macro - observable @xmath189 provides an @xmath190 estimate of the expected value of the exact system @xmath191 with observable @xmath192 .",
    "since we can use tts algorithms ( such as algorithm [ alg : tts - ssa ] ) to quickly generate trajectories of @xmath142 while estimating the macro - observable @xmath193 at each state along the way , this provides a method to very quickly generate estimates of @xmath194 with at most @xmath190 bias . as @xmath52 ,",
    "the bias decreases linearly while the computational savings increase as @xmath195 .",
    "computing the system sensitivities @xmath196 with respect to reaction parameters @xmath197 provides great insight into the model . as such ,",
    "numerous works have constructed and analyzed methods to estimate the sensitivities from sample trajectories of the system @xcite .",
    "different methods work better for different systems or different criteria , but all methods have higher ( sometimes stupendously higher ) variance in the estimation of @xmath198 compared to the estimation of @xmath199 , thus requiring a very large number of samples to estimate the sensitivity precisely . if the system is stiff ( as in ) so that each exact trajectory @xmath191 requires a prohibitively large computational load , then the large number of sample paths required to estimate the sensitivity @xmath200 make the problem computationally intractable .",
    "corollary  [ cor : expectation - error ] gives that the expectation of macro `` averaged '' reaction network @xmath201 gives an accurate approximation of the expectation of the exact network ; @xmath202 .",
    "a natural question to ask is whether the sensitivities of the exact system converge to the sensitivities of the averaged system .",
    "using the recent result of ref .",
    "gupta_sensitivity_2014 , we can derive the following ( the details are deferred to appendix ) .",
    "convergence of sensitivities [ prop : sens_converge ] @xmath203    thus , if we can compute the sensitivity of the macro reaction network @xmath201 ( whose sample paths have orders of magnitude less cost to simulate than the exact stiff network @xmath204 ) , then this provides an accurate estimate of the exact sensitivity .",
    "furthermore , since @xmath205 is formulated as a reaction network with propensities @xmath206 and observable values @xmath193 ( both of which are estimated during a tts simulation ) , we can apply most of existing single - scale sensitivity estimation methods to estimate @xmath207 and thus @xmath208 .",
    "we note that gives that the sensitivity of the exact system converges to the sensitivity of the averaged system , but does not give the rate of convergence .",
    "currently , this is an open question . since from we",
    "have the expectation converges at a rate @xmath190 , one might suspect that the sensitivity also converges at rate @xmath190 , at least for certain classes of networks ( e.g. linear propensities ) .",
    "ongoing work aims to establish the rate of convergence via singular perturbation expansions of sensitivity reweighting measures .",
    "however , the remainder of this work shall focus on the development and practical implementation of a multiscale likelihood ratio estimator of the limit sensitivity @xmath209 .    in what follows , we review the likelihood ratio method for computing system sensitivities for single - scale reaction networks .",
    "furthermore , we shall introduce a new ergodic likelihood ratio method which has much smaller variance when estimating sensitivities at steady - state .",
    "we then derive a two - time - scale version that allows one to estimate the full gradient of a stiff system using any tts monte carlo method for simulating a macro trajectory",
    ".      likelihood ratio ( lr ) methods @xcite ( aka the girsanov transform method ) attempt to compute the derivative by reweighting the observed trajectory by its `` score '' function of the density . here",
    ", one views @xmath210 as parametrizing the probability measure on the path - space @xmath211 .",
    "if @xmath211 is differentiable with respect to @xmath1 , then under mild regularity conditions we have @xmath212 using the random - time - change representation it can be shown@xcite that the reweighting process @xmath213 is a zero - mean martingale process and can be represented by @xmath214 where @xmath215 is simply the counting measure of reaction @xmath9 which equals @xmath216 at times @xmath217 at which reaction @xmath9 fires and is zero otherwise .",
    "thus , assuming one can compute @xmath218 , then @xmath213 has a computationally tractable form as follows .",
    "we write @xmath219 for the @xmath220-th state of the system through a trajectory , and @xmath221 for the holding time in the @xmath220-th state .",
    "write @xmath222 for the time of the @xmath220 jump , so that @xmath223 .",
    "we denote @xmath224 as the total number of reactions which have fired by time @xmath10 and @xmath225 for the index of the reaction which takes the system from the @xmath220-th state to the @xmath226-th state",
    ". then @xmath227 has the explicit form @xmath228 \\\\    - \\sum_{r=1}^m   \\frac{\\partial \\lambda_r}{\\partial \\theta }     \\left ( \\hat{x}_l , \\boldsymbol{\\theta^0 } \\right )   \\left [ t - t_{n(t ) } \\right ] .\\end{gathered}\\ ] ]    in simulation , the lr estimate is computed via ensemble averages estimated by empirical averaging @xmath229 with the empirical estimator @xmath230}_n      \\widehat{\\left [ w_{\\theta_i}(t ) \\right]}_n .\\end{gathered}\\ ] ] where @xmath231 is the number sample paths , @xmath232}_n$ ] is the observable value at terminal time @xmath144 for the @xmath233th sample path , and similarly @xmath234}_n$ ] is the terminal value of @xmath235 for the @xmath233th sample path .",
    "while the reweighting process @xmath213 has zero mean , its variance grows with time @xcite , making it quite inefficient for large time horizons .",
    "the variance can be reduced by using the centered likelihood ratio estimate @xmath236}_n    \\right\\ }      \\left\\ { \\sum_{n=1}^ { { n_{s}}}\\widehat{\\left [ w_{\\theta_i}(t ) \\right]}_n     \\right\\ } .\\end{gathered}\\ ] ] since the @xmath237 , the second term does nt impose any bias into the estimate , but is coupled to the first term to reduce the observed variance @xcite .",
    "suppose one is interested in the steady - state sensitivities , @xmath238 .",
    "it is well known that @xmath239 for some mixing rate @xmath240 , and thus for large @xmath144 one can use the terminal distribution of @xmath241 and @xmath235 in to obtain an estimate of the steady - state sensitivity with exponentially small bias @xcite .",
    "however , the major difficulty in using likelihood ratio estimates is the large variance of the estimator @xmath242 , which is proportional to @xmath243 @xcite .",
    "it can be seen that @xmath244 , so one must balance choosing a terminal time @xmath144 large enough to ensure sufficient decay of the bias @xmath245 , yet as small as possible to contain the growth of the @xmath246 . while centering as in helps to reduce the variance of the estimator , the variance is usually much larger than comparable finite difference of pathwise derivative methods @xcite .    instead of using the terminal distribution @xmath241 as an approximation of the steady - state distribution",
    ", one could instead use the ergodic - average ( time - average ) @xmath247 .",
    "the bias of the ergodic - average decays slower than the terminal distribution ( @xmath248 compared to @xmath249 ) , but has the advantage that variance decays with time as well ; that is , @xmath250 whereas @xmath251 ( see ref .",
    "asmussen_stochastic_2007 for more details ) .",
    "motivated by the variance reduction one obtains with ergodic averaging , we introduce a new method for computing likelihood - ratio type steady state sensitivity estimates .",
    "the idea is to simply replace the terminal - state observable @xmath241 with the ergodic average @xmath252 in the lr scheme  .",
    "the philosophy is that by incurring some small amount of additional bias in the mean value , the ergodic steady - state sensitivity estimate has much smaller variance than the terminal - state distribution",
    ". we shall refer to this method the _ ergodic likelihood ratio _",
    ", @xmath253}_n      \\widehat{\\left [ w_{\\theta_i}(t ) \\right]}_n .\\end{gathered}\\ ] ] similarly , one can center the * elr * to derive the _ centered ergodic likelihood ratio _ * celr * , @xmath254}_n    \\right\\ }      \\left\\ { \\sum_{n=1}^ { { n_{s}}}\\widehat{\\left [ w_{\\theta_i}(t ) \\right]}_n     \\right\\ } .\\end{gathered}\\ ] ]    in the numerical experiments , it shall be seen that the * celr * method performs much better than the * clr * for steady - state sensitivity estimation .      in",
    "what follows , we describe how the above single - scale likelihood ratio methods can be adapted to the macro - process @xmath142 for use in .",
    "recall that the reaction parameters can be classified as fast or slow , @xmath255 $ ] with @xmath256 $ ] and @xmath257 $ ] . to apply likelihood ratio methods to compute @xmath258",
    ", we exploit that the macro process @xmath142 is identified as reaction network with propensities @xmath259 ( for @xmath260 ) , and observable @xmath261 thus the macro - sensitivities can be represented by @xmath262 where the macro - reweighting process @xmath263 is given by @xmath264 therefore , in order to apply we need to be able to compute the derivatives of the averaged observable @xmath265 as well as the derivatives of the averaged propensity functions @xmath266 .",
    "suppose @xmath267 is a slow reaction parameter .",
    "if the original observable @xmath268 has no direct parameter dependence , then @xmath269 .",
    "furthermore , under mass - action kinetics , the averaged propensities have @xmath270 , where @xmath271 is already computed during a tts simulation and @xmath272 if @xmath273 and @xmath274 otherwise .",
    "thus the slow sensitivities are directly computable from a standard tts simulation .",
    "suppose @xmath275 is a fast reaction parameter .",
    "then computing @xmath276 and @xmath277 is more problematic , as they only depend indirectly on @xmath53 through the fast - class steady - state measures @xmath114 .",
    "thus explicit computation is often infeasible .",
    "however , one may estimate @xmath278 and @xmath279 through any sensitivity analysis method from a simulation with only fast reactions .",
    "for example , when running the fast - only simulation ( under @xmath280 ) for equilibration in algorithm [ alg : tts - ssa ] , one can compute the corresponding likelihood ratio process @xmath281 as in ( with @xmath10 large enough so that @xmath282 ) . then one can estimate the derivitives in , by @xmath283 using the proposed celr method during the micro - equilibration computation . plugging these estimated values into",
    "allows one to calculate @xmath284 for each macro - trajectory , which in turn allows for sensitivity estimation with respect to @xmath63 in .",
    "we note that our derivation leads to a different form of the multi - scale lr estimator compared with ref .",
    "the latter estimated the reweighting measures for the exact process @xmath285 by adding together the micro reweighting measures @xmath286 from within each fast class visited , the idea being that @xmath287 is a zero - mean martingale which adds no new information and only increases in variance once the fast - only process has converged to steady - state .",
    "henceforth , we refer to this approach as the `` truncated likelihood ratio '' , as it approximates the exact reweighting coefficient @xmath288 via a truncated observation within each fast - class .",
    "conversely , the tts likelihood ratio uses the exact representation for the macro process , and then estimates the terms via    lastly , we note that the above procedure will estimate sensitivities with respect to the parameter set @xmath255 $ ]",
    ". however , the original goal was to estimate sensitivities with respect to @xmath289   = [ { { { \\boldsymbol{\\alpha } } } } ^{\\varepsilon } , { { { \\boldsymbol{\\beta } } } } ] $ ] .",
    "the sensitivities of the slow parameters @xmath290 are the same , but the tts sensitivity scheme computes fast sensitivities against the rescaled parameter @xmath63 rather than against the original parameter @xmath291 . however , it can be shown ( appendix [ sec : analytic_ss ] ) that at steady - state we have @xmath292 therefore , by multiplying the tts sensitivity estimate ( against @xmath63 ) by a factor of @xmath99 , one thus obtains the estimate against the original parameter @xmath293 .",
    "thus one can use the tts scheme to estimate the full gradient of @xmath294 .",
    "a crucial question when implementing a tts simulation is : how long to run the micro - equilibration for ?",
    "that is , how large a value of @xmath10 does one use to compute the ergodic averages @xmath295 for a desired level of accuracy @xmath296 ?",
    "taking too small a value for @xmath10 risks imposing a large bias .",
    "however , the @xmath297 rate of convergence for the ergodic average implies almost nothing is gained by integrating @xmath10 past the relaxation time of the system .",
    "furthermore , when computing the micro - sensitivities one uses the micro - reweighting process @xmath287 by @xmath298 where the variance of @xmath287 increases with the time - horizon @xmath10 .",
    "thus , we would ideally take the smallest value of @xmath10 such that @xmath299 . however , different fast - classes @xmath163 can have vastly different sizes",
    ". this can result in significantly different relaxation times for each class .",
    "it is then ideal to have an _ adaptive stopping rule _ which terminates the micro ( fast - only ) simulations when the ergodic averages have converged to the steady state mean .",
    "current implementations of an `` averaged '' or `` multi - scale '' ssa use a constant relaxation time @xmath300 for the micro - averaging step@xcite whose choice is motivated by some a priori insight into the system . in refs.cao_multiscale_2005 , cao_slow - scale_2005 the authors also use a fixed time @xmath10 , but then exploit algebraic relations of the steady - state means to try to obtain better approximations . in ref .",
    "samant_overcoming_2005 , a stopping rule is developed which determines that equilibrium is reached when the averaged values of the propensities of the forward and backward reactions are approximately equal for each reaction pair .",
    "however , experience has shown this `` partial - equilibrium '' stopping rule can stop prematurely ( in the transient regime ) with significant probability for systems with relatively few reaction - pairs .",
    "thus , we seek to obtain a robust , adaptive stopping rule for terminating the micro - equilibration simulation .",
    "the problem at hand is really one about markov chain mixing - times and the integrated autocorrelation time @xmath301 .",
    "analytically , the mixing and integrated autocorrelation times are related to the spectral gap of the underlying generator @xcite .",
    "unfortunately , for large systems direct computation is usually infeasible .",
    "some common approaches involve estimation autocorrelation function @xmath302 of the process and then exploiting the relation @xmath303 to derive estimates of @xmath301 from the estimates of @xmath302 @xcite .",
    "however , if the goal is to terminate the simulation when the ergodic average has converged appropriately , then these methods are indirect and can be computationally intensive .",
    "another common approach is to exploit the regenerative structure of markov chains @xcite to obtain independent and identically distributed samples of the process and obtain confidence bounds on the ergodic average .",
    "however , these methods can be inefficient for complex systems where the return time to the initial state can be quite large .",
    "we instead turn to the method of batch means @xcite for determining confidence bounds ( and thus a measure of convergence ) for the steady - state estimation problem inside each fast - class .",
    "the use of batch means is applicable to a wide range of problems ( any which satisfy a central limit theorem ) , and its implementation is very straightforward . for a general markov chain @xmath304 with an observable function @xmath23 , write @xmath305 and @xmath306 .",
    "we denote @xmath307 for the steady - state value we wish to estimate . then under some general conditions",
    "@xcite @xmath308 satisfies a functional central limit theorem : @xmath309 in the sense of weak convergence as @xmath52 .",
    "suppose that @xmath310 , where @xmath311 is the relaxation time of the system and @xmath312 is a number of `` batches '' ( bins ) to partition the trajectory into .",
    "then the batch means @xmath313 are approximately ( as @xmath314 ) independent and identically distributed samples of @xmath315 . thus @xmath316 as @xmath314 , where @xmath317 is the student s @xmath10-distribution and @xmath318 is the sample variance among batches , @xmath319 ^ 2 .\\end{aligned}\\ ] ] thus , for @xmath10 sufficiently large , a @xmath320 confidence interval for the value of @xmath321 is given by @xmath322 , where @xmath323 and @xmath324 is the @xmath325th quantile of the student s @xmath10-distribution with @xmath326 degrees of freedom .",
    "the usual perspective for applying batch means is that one has a fixed set of data @xmath327 \\right\\}$ ] to partition , and then must choose the number of batches @xmath312 appropriately so that each batch length @xmath328 is long enough so that the batch mean errors @xmath329 $ ] are approximately independent , identically distributed , and gaussian .",
    "one then often chooses @xmath312 to be relatively small ( say , 5 to 30 ) @xcite to ensure the independent and gaussian assumptions hold . when viewing the asymptotic structure as the amount of data @xmath10 grows",
    ", then one can ensure that the asymptotic central limit theorem holds if the number of batches grows as @xmath330 . in ref .",
    "alexopoulos_implementing_1996 , the authors consider strategies which let the number of batches grow if the correlation between batches is near 0 , and otherwise hold @xmath331 fixed until the batch correlation decays to 0 .    since our goal is to simulate only enough ( micro - scale ) data so as to determine the steady - state values @xmath321 , we instead take the perspective that one has a fixed number of batches @xmath312 desired , and that one should generate data @xmath332 \\right\\ } $ ] until each of the batch means @xmath333 are ( approximately ) independent and identically distributed about @xmath321 . for a fixed level of precision @xmath334 , confidence level @xmath335 , and the number of batches ( independent samples ) @xmath312 ,",
    "the batch - means stopping rule terminates the simulation when @xmath336 , where @xmath337 is defined by .",
    "figure [ fig : batching_diagram ] gives a depiction of how the batch - means stopping rule is implemented .    ) to a terminal time @xmath338 , and then the trajectory is partitioned into @xmath339 batches to compute the variance between the batch means @xmath340 .",
    "if the confidence bounds are precise enough ( @xmath341 ) , then the simulation is terminated and each batch gives an iid sample of @xmath342 . otherwise , another @xmath343 jumps are simulated and the process is repeated . ]",
    "in addition to giving an on - line estimate of the relaxation time of the system , the batch - means stopping rule gives @xmath344 ( nearly ) independent samples of trajectories with initial distribution approximately equal to the stationary distribution .",
    "furthermore , one can compute the reweighting coefficients @xmath345 in each batch to give @xmath312 ( nearly ) independent samples of the steady - state reweighting coefficients ( in a manner similar to the `` time - averaged correlation function '' method of ref .",
    "warren_steady - state_2012 ) .",
    "suppose we have a general reaction network with @xmath346 reactions and @xmath347 reaction parameters .",
    "here we allow the possibility that @xmath348 for general propensity functions @xmath14 ( e.g. michaelis - menten kinetics ) , whose parameter derivatives @xmath349 we can compute explicitly for all @xmath350 and all @xmath351 .",
    "denote by @xmath11 the stoichiometric vector for the @xmath9th reaction .",
    "our goal is to estimate the gradient @xmath352 for some observable function @xmath23 .",
    "we introduce the following notation for the batch - means stopping rule .",
    "@xmath353 is the @xmath233th state of the reaction network , @xmath354 is the time of the @xmath233th jump and @xmath355 for the value of the observable at the @xmath233th state .",
    "@xmath356 is the time - integrated value of @xmath23 up to the @xmath233th jump , @xmath357 is the reaction which fires at jump @xmath233 ( taking the system from @xmath353 to @xmath358 ) , @xmath359 is the vector in @xmath360 with @xmath216 in the @xmath21th component and zeros elsewhere .",
    "@xmath361 and @xmath362 are the first and second terms of with respect to each of the parameters @xmath197 ( @xmath363 ) .",
    "@xmath312 is the number of batches ( approximately independent samples ) to be used , @xmath335 is the desired confidence level ( for a @xmath364 confidence interval , and @xmath334 is the maximum allowed radius of the confidence interval at the stopping time .",
    "@xmath365 is the number of jumps to simulate before retesting the batches for convergence",
    ". then one can write the batch - means stopping rule as follows .",
    "[ alg : batch - means ]   +    1 .",
    "* initialize * * @xmath366 , @xmath367 , @xmath368 , @xmath369 , @xmath370 \\in { \\mathbb{r}}^{1 \\times m_\\theta}$ ] , @xmath371 \\in { \\mathbb{r}}^{1 \\times m_\\theta}$ ] . @xmath372 ( number of times the data has been tested for convergence ) .",
    "calculate @xmath373 quantile of a student s @xmath10-distribution with @xmath344 degrees of freedom .",
    "2 .   * generate and record data * simulate @xmath365 jumps and record values immediately after each jump . for @xmath374 , * compute @xmath375 , @xmath376 for all @xmath351 and all @xmath377 .",
    "set @xmath378 , and @xmath379 for all @xmath197 . * sample @xmath380 , and @xmath381 + @xmath382 $ ] .",
    "* update @xmath383 + @xmath384 + @xmath385 + @xmath386 + @xmath387            / \\lambda_{r^*(n)}\\left ( \\hat{x}(n ) , { { \\boldsymbol{\\theta}}}\\right)$ ] + @xmath388 $ ] + @xmath389 + @xmath390 .",
    "* test batches for convergence * * @xmath391= index of last available data point",
    ". + @xmath392 = total time - averaged value + @xmath393= time length each of batch + initialize @xmath394 ( total integral through end of previous batch ) .",
    "* for @xmath395 * * @xmath396= @xmath397=index of the last jump in batch @xmath146 . * * @xmath398 + @xmath399          - f^b$]=total integrated value of @xmath400 inside batch @xmath146 . * * @xmath401= @xmath146th batch - mean * * @xmath402 ( update integral to end of previous batch ) * @xmath403 ^ 2 $ ] = variance between batches * @xmath404 = margin of error for confidence interval * if @xmath405 , then go to * ( 4)*. else , @xmath406 and go back to * ( 2)*. 4 .    *",
    "compute lr weights * in each batch .",
    "+ initialize @xmath407 \\in { \\mathbb{r}}^{1 \\times m_\\theta}$ ] . for @xmath395 ,",
    "* @xmath408 + @xmath409 $ ] + @xmath410 * @xmath411 5 .   *",
    "compute sensitivity estimates * for @xmath412 : * likelihood ratio @xmath413 * centered likelihood ratio @xmath414           \\cdot \\left [ \\frac{1}{n_b } \\sum_{k=1}^{n_b }            w_a^b(k , { { \\boldsymbol{\\theta } } } ) \\right ]            \\end{gathered}\\ ] ] * ergodic likelihood ratio @xmath415 * centered ergodic likelihood ratio @xmath416 \\cdot          \\left [ \\frac{1}{n_b } \\sum_{k=1}^{n_b }           w_a^b(k,{{\\boldsymbol{\\theta } } } ) \\right ]            \\end{aligned}\\ ] ]",
    "here we present numerical results to display the performance of the proposed algorithms . in",
    "what follows , we compare the output of an exact simulation at the single time scale ( sts ) to the accelerated two time scale ( tts ) approximation . from",
    ", we expect the differences in observable averages and their derivatives to be @xmath190 .",
    "because differences are small , we use a simple test system for which many samples can be run to obtain accurate statistics .    consider a reaction network with species a , b , and c and isomerization reactions given by @xmath417 for small values of @xmath99 , the system becomes stiff as the isomerization between a and b reaches equilibrium much faster than b is converted to c. a tts approximation assumes that @xmath418 and @xmath419 are fast and equilibrated .",
    "we first compare the output of the accelerated tts simulation against the exact sts simulation for varying levels of stiffness @xmath99 . for our simulations ,",
    "initial conditions of @xmath420 and the parameters @xmath421 are chosen .",
    "10,000 replicate ( independent ) trajectories are run for various values of @xmath99 .",
    "statistics are taken at a termination time of @xmath422s .",
    "species averages are calculated as arithmetic averages over the independent trajectories while sensitivities are computed with the clr method shown in .",
    "the error due to statistical averaging is estimated using t - test statistics for averages and a bootstrapping method for sensitivities .",
    "sensitivities with respect to the `` slow '' parameter @xmath423 are displayed for each species . as discussed in previous works@xcite , sensitivities with respect to parameters related to fast reactions",
    "encounter significant noise , and thus we omit them in order to clearly observe the difference between sts and tts .",
    "figure [ fig : sts_eps_converge ] shows the disparity between the sts and tts systems for various values of @xmath99 .",
    "errors are normalized by the tts value such that @xmath424 .",
    "indeed , one observes the difference is proportional to @xmath99 , as expected from corollary  [ cor : expectation - error ] and .",
    "next , the clr and celr methods from section [ sec : lrmethods ] are tested in performing sensitivity analysis in a tts system .",
    "the reaction network described in section [ sec : ttsrn ] is simulated using algorithm [ alg : tts - ssa ] . to assess convergence of the microscale distribution , the batch - means stopping criterion described in section [ sec : bmstop ]",
    "is used with a tolerance of @xmath425 .",
    "1000 replicate trajectories are run to a time horizon of @xmath426s .",
    "the initial conditions used are @xmath427 and the parameters used are @xmath428 .",
    "species populations , time - averaged species populations , and trajectory derivatives are recorded for each run over time . using these recorded statistics , the sensitivities for all 15 ( 3 species and 5 parameters ) species / parameter combinations",
    "are computed at each time point .",
    "figure [ fig : tts_ergodicsaerror ] shows the time evolution of the normalized errors in sensitivity estimates of the species b over time .",
    "estimated values from simulation are referenced to the analytical answer as computed from a differential algebraic equation ( see appendix [ sec : analylicsolnexample ] ) and normalized by that amount so that @xmath429 .",
    "as expected , clr estimates are noisy , with variance that grows linearly with time . at short times , the variance is small enough to obtain reasonable estimates . as time increases ,",
    "the noise becomes significant with respect to the actual values ( the magnitude of the normalized error becomes comparable to 1 ) .",
    "in contrast , the ergodic likelihood ratio ( celr ) fails at short times with a noticeable bias .",
    "however , the bias , which exists due to a relaxation period , decays as @xmath297 when time increases and the system approaches its steady - state .",
    "the variance of the celr estimates remain constant because the variance of trajectory derivatives increases linearly in time while the variance of ergodic species averages is proportional to @xmath430 . at long times ( where the clr is too noisy for efficient estimation )",
    ", the ergodic likelihood ratio obtains accurate estimates with very low variance .",
    "therefore , it is advisable to use the clr method for short times ( in the transient regime ) and the celr method for long times to obtain steady state values .",
    "table [ tab : table1 ] shows the error and statistical noise of the clr and celr estimations of sensitivities of the species b at a short ( @xmath431s ) and long ( @xmath432s ) times .",
    "statistical noise is obtained from bootstrapping the samples used to compute the sensitivity estimates . at @xmath431 ,",
    "the clr method has low error ( theoretically , there is no bias ) as well as low variance .",
    "the celr estimator has a similarly low variance , but high error ( due to the @xmath433 bias ) . at @xmath432s ,",
    "the clr estimates have much higher variance which induces large empirical error .",
    "in contrast , the bias of the celr estimate decreases in time while the variance remains low , providing very small empirical errors at large times .",
    ".comparison of the error and statistical noise for the clr and celr estimators at a short time ( during the transient regime ) and at a long time ( corresponding to steady state ) .",
    "values in the table refer to the sensitivity of the species b with respect to the parameter given by the row label .",
    "values are reported as a percent of the analytically obtained sensitivity value . [ cols=\"^,^,^,^,^ \" , ]                                  paul dupuis , markos  a. katsoulakis , yannis pantazis , and petr plechac .",
    "path - space information bounds for uncertainty quantification and sensitivity analysis of stochastic dynamics . , march 2015 .",
    "arxiv : 1503.05136 .",
    "patrick  w. sheppard , muruhan rathinam , and mustafa khammash . a pathwise derivative approach to the computation of parameter sensitivities in discrete stochastic chemical systems .",
    ", 136(3):034115 , january 2012 .",
    "david  f. anderson and thomas  g. kurtz .",
    "continuous time markov chain models for chemical reaction networks . in heinz koeppl , gianluca setti , mario  di bernardo , and douglas densmore , editors , _ design and analysis of biomolecular circuits _ , pages 342 .",
    "springer new york , january 2011 .",
    "jacob  a. mcgill , babatunde  a. ogunnaike , and dionisios  g. vlachos .",
    "efficient gradient estimation using finite differencing and likelihood ratios for kinetic monte carlo simulations .",
    ", 231(21):71707186 , august 2012 .",
    "christos alexopoulos and andrew  f. seila . implementing",
    "the batch means method in simulation experiments . in _ proceedings of the 28th conference on winter simulation _ , wsc 96 , pages 214221 ,",
    "washington , dc , usa , 1996 .",
    "ieee computer society ."
  ],
  "abstract_text": [
    "<S> in the presence of multiscale dynamics in a reaction network , direct simulation methods become inefficient as they can only advance the system on the smallest scale . </S>",
    "<S> this work presents stochastic averaging techniques to accelerate computations for obtaining estimates of expected values and sensitivities with respect to the steady state distribution . </S>",
    "<S> a two - time - scale formulation is used to establish bounds on the bias induced by the averaging method . </S>",
    "<S> further , this formulation provides a framework to create an accelerated ` averaged ' version of most single - scale sensitivity estimation methods . </S>",
    "<S> in particular , we propose a new lower - variance ergodic likelihood ratio method for steady state estimation and show how one can adapt it to accelerate simulations of multiscale systems . </S>",
    "<S> lastly , we develop an adaptive `` batch - means '' stopping rule for determining when to terminate the micro - equilibration process . </S>"
  ]
}