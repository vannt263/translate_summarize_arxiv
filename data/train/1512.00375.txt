{
  "article_text": [
    "the paper deals with novel sparse preconditioning for model predictive control using , as a specific example , the continuation / gmres method for on - line nonlinear model predictive control suggested by t.  ohtsuka in  @xcite .",
    "the method becomes popular in solving industrial applications ; see , e.g. @xcite .",
    "the paper @xcite gives guidelines how to use the method in cases , when the system dynamics obeys a geometric structure , e.g. the symplectic one , or when the state lies on a smooth manifold .",
    "the structure - preserving solver may increase accuracy of the numerical solution .",
    "the paper @xcite treats the problems with the particle solutions for nonlinear mpc using continuation / gmres .",
    "the continuation / gmres method is based on newton - type optimization schemes .",
    "the exact newton method requires an analytic expression of a corresponding jacobian matrix , which is rarely available in practice and is often replaced with a forward difference ( fd ) approximation ; see , e.g. , @xcite .",
    "such approximate newton - type optimization schemes utilize the fd approximation of the original nonlinear equation at every time step .",
    "t.  ohtsuka uses the gmres algorithm to solve a finite - difference approximation @xmath2 to the optimality conditions . to cope with possible ill - conditioning of @xmath3 , the authors of @xcite propose a preconditioning strategy , which proved to be not very efficient .    in @xcite and @xcite ,",
    "we systematically search for better preconditioners to accelerate the gmres and minres convergence in the c / gmres method . in the present paper ,",
    "we propose a sparse efficient @xmath0 preconditioner for this method , where @xmath1 is the number of gridpoints on the prediction horizon .",
    "another popular approach to numerical solution of mpc problems is developed in @xcite , @xcite , @xcite and based on the interior - point method .",
    "the authors of @xcite develop a direct method for a linear mpc model with the @xmath0 arithmetic complexity .",
    "the papers @xcite apply the minres iteration with special preconditioners to similar linear mpc problems and prove the @xmath0 arithmetical complexity of the preconditioned iteration .",
    "in contrast to the above methods , which use the newton or quasi - newton approximations , the recent papers @xcite and @xcite investigate performance of the first - order methods and their nesterov s acceleration .",
    "our proposed preconditioning technique is essentially based on two ideas .",
    "the symmetric matrix @xmath3 is a schur complement of the hessian of the lagrangian function , associated with the model prediction problem .",
    "apart from a few rows and columns , the preconditioner @xmath4 is a sort of an incomplete lu factorization @xcite of the schur complement without these exceptional rows and columns .",
    "this results in sparse @xmath5 and its factors , @xmath6 and @xmath7 , having only @xmath0 nonzero entries . on the one hand ,",
    "application of this preconditioner is almost as fast as that of a diagonal preconditioner . on the other hand",
    ", our preconditioner has high quality leading to fast convergence of the iterative method , such as gmres .",
    "the rest of the paper is organized as follows .",
    "section  [ sec : predict ] derives the nonlinear equation ( [ e7 ] ) , which solves the model prediction problem , following @xcite .",
    "we prove the symmetry of the jacobian matrix for the function defining ( [ e7 ] ) in theorem  [ th1 ] .",
    "section  [ sec : algo ] describes the continuation method for solving ( [ e7 ] ) .",
    "section  [ sec : gmres ] formulates the preconditioned gmres , as in @xcite .",
    "section  [ sec : sprec ] describes our new preconditioner .",
    "the preconditioner construction is the main result of the paper .",
    "section  [ sec : ex ] illustrates all details of the preconditioner setup on a representative example . section  [ sec : numer ] displays plots of numerical results",
    "the model predictive control ( mpc ) method solves a finite horizon prediction problem along a fictitious time @xmath8 $ ] .",
    "our model finite horizon problem consists , following @xcite , in choosing the control @xmath9 and parameter vector @xmath10 , which minimize the performance index @xmath11 as follows : @xmath12 where @xmath13 subject to the equation for the state dynamics @xmath14 and the constraints @xmath15 @xmath16 the initial value condition @xmath17 for ( [ e1 ] ) is the state vector @xmath18 of the dynamic system .",
    "the control vector @xmath19 , solving the problem over the horizon , is used as an input to control the system at time @xmath20 .",
    "the components of the vector @xmath21 are parameters of the system .",
    "equation ( [ e1 ] ) describes the system dynamic that may be nonlinear in @xmath22 and @xmath23 .",
    "equations ( [ e2 ] ) and ( [ e3 ] ) give equality constraints for the state @xmath22 and the control @xmath23 .",
    "the horizon time length @xmath24 may in principle also depend on @xmath20 .",
    "the continuous formulation of the finite horizon problem stated above is discretized on a uniform , for simplicity of presentation , time grid over the horizon @xmath25 $ ] partitioned into @xmath1 time steps of size @xmath26 , and the time - continuous vector functions @xmath27 and @xmath9 are replaced by their indexed values @xmath28 and @xmath29 at the grid points @xmath30 , @xmath31 .",
    "the integral of the performance cost @xmath11 over the horizon is approximated by the rectangular quadrature rule .",
    "the time derivative of the state vector is approximated by the forward difference formula .",
    "the discretized optimal control problem is formulated as follows : @xmath32,\\ ] ] subject to @xmath33 @xmath34 @xmath35    the necessary optimality conditions for the discretized finite horizon problem are obtained by means of the discrete lagrangian function @xmath36\\\\ & & + \\sum_{i=0}^{n-1}\\lambda_{i+1}^t[x_i - x_{i+1}+f(\\tau_i , x_i , u_i , p)\\delta\\tau]\\\\ & & + \\sum_{i=0}^{n-1}\\mu_i^tc(\\tau_i , x_i , u_i , p)\\delta\\tau+\\nu^t\\psi(x_n , p),\\end{aligned}\\ ] ] where @xmath37^t$ ] , @xmath31 , and @xmath38^t$ ] , @xmath39 . here , @xmath40 is the costate vector , @xmath41 is the lagrange multiplier vector associated with the constraint  ( [ e5 ] ) .",
    "the terminal constraint ( [ e6 ] ) is relaxed by the aid of the lagrange multiplier @xmath42 . for further covenience",
    ", we also introduce the hamiltonian function @xmath43    the necessary optimality conditions are the ( kkt ) stationarity conditions : @xmath44 , @xmath45 , @xmath31 , @xmath46 , @xmath47 , @xmath39 , @xmath48 , @xmath49 .",
    "the kkt conditions are reformulated in terms of a mapping @xmath50 $ ] , where the vector @xmath7 combines the control input @xmath23 , the lagrange multiplier @xmath41 , the lagrange multiplier @xmath42 , and the parameter @xmath10 , all in one vector : @xmath51^t.\\ ] ] the vector argument @xmath22 in @xmath50 $ ] denotes the current measured or estimated state vector , which serves as the initial vector @xmath52 in the following procedure .    1 .",
    "starting from the current measured or estimated state @xmath52 , compute @xmath28 , @xmath53 , by the forward recursion @xmath54 then starting from @xmath55 compute the costates @xmath56 , @xmath57 , by the backward recursion @xmath58 2 .",
    "calculate @xmath50 $ ] , using just obtained @xmath28 and @xmath56 , as @xmath59}\\\\ & & \\hspace*{-2em}=\\left[\\begin{array}{c}\\begin{array}{c } \\frac{\\partial h^t}{\\partial u}(\\tau_0,x_0,\\lambda_{1},u_0,\\mu_0,p)\\delta\\tau\\\\ \\vdots\\\\\\frac{\\partial h^t}{\\partial u}(\\tau_i , x_i,\\lambda_{i+1},u_i,\\mu_i , p)\\delta\\tau\\\\ \\vdots\\\\\\frac{\\partial h^t}{\\partial u}(\\tau_{n-1},x_{n-1},\\lambda_{n},u_{n-1 } , \\mu_{n-1},p)\\delta\\tau\\end{array}\\\\\\;\\\\ \\begin{array}{c}c(\\tau_0,x_0,u_0,p)\\delta\\tau\\\\ \\vdots\\\\c(\\tau_i , x_i , u_i , p)\\delta\\tau\\\\\\vdots\\\\ c(\\tau_{n-1},x_{n-1},u_{n-1},p)\\delta\\tau\\end{array}\\\\\\;\\\\ \\psi(x_n , p)\\\\[2ex ] \\begin{array}{c}\\frac{\\partial\\phi^t}{\\partial p}(x_n , p)+ \\frac{\\partial\\psi^t}{\\partial p}(x_n , p)\\nu\\\\ + \\sum_{i=0}^{n-1}\\frac{\\partial h^t}{\\partial p}(\\tau_i , x_i , \\lambda_{i+1},u_i,\\mu_i , p)\\delta\\tau\\end{array } \\end{array}\\right].\\end{aligned}\\ ] ]    the equation with respect to the unknown vector @xmath60 @xmath61=0\\ ] ] gives the required necessary optimality conditions .",
    "[ th1 ] the jacobian matrix @xmath62 $ ] is symmetric for all @xmath7 , @xmath22 , and @xmath20 .",
    "the equation @xmath63 is always solvable with respect to @xmath64 by the forward recursion for @xmath28 and backward recursion for @xmath56 .",
    "let us denote its solution by @xmath65",
    ". then @xmath66=\\mathcal{l}_u(g(u),u)$ ] and @xmath67 .",
    "differentiation of the identity @xmath68 with respect to @xmath7 gives the identity @xmath69 .",
    "differentiation of the identity @xmath70 with respect to @xmath7 gives the identity @xmath71 .",
    "hence @xmath72 and @xmath73 = & \\mathcal{l}_{uu}(g(u),u)\\label{e7a}\\\\ & { } -\\mathcal{l}_{ux}(g(u),u)\\mathcal{l}_{xx}^{-1}(g(u),u)\\mathcal{l}_{xu}(g(u),u),\\notag\\end{aligned}\\ ] ] which is the schur complement of the symmetric hessian matrix of @xmath74 at the point @xmath75 .",
    "the schur complement of any symmetric matrix is symmetric .",
    "the controlled system is sampled on a uniform time grid @xmath76 , @xmath77 .",
    "solution of equation ( [ e7 ] ) must be found at each time step @xmath78 on the controller board , which is a challenging part of implementation of nmpc .",
    "let us denote @xmath79 , @xmath80 , and rewrite the equation @xmath81=0 $ ] equivalently in the form @xmath82-f[u_{j-1},x_j , t_j]=b_j,\\ ] ] where @xmath83.\\ ] ]    using a small @xmath84 , which may be different from @xmath85 and @xmath26 , we introduce the forward difference operator @xmath86-f[u_{j-1},x_j , t_j])/h.\\end{aligned}\\ ] ] we note that the equation @xmath81=0 $ ] is equivalent to the equation @xmath87 , where @xmath88 .",
    "let us denote the @xmath89-th column of the @xmath90 identity matrix by @xmath91 , where @xmath92 is the dimension of the vector @xmath7 , and define an @xmath90 matrix @xmath93 with the columns @xmath94 , @xmath95 , given by the formula @xmath96 .",
    "the matrix @xmath93 is an @xmath97 approximation of the jacobian matrix @xmath98 $ ] .",
    "the jacobian matrix @xmath99 is symmetric by theorem  [ th1 ] .",
    "suppose that an approximate solution @xmath100 to the equation @xmath101=0 $ ] is available .",
    "the first block entry of @xmath100 is then taken as the control @xmath102 at the state @xmath52 .",
    "the next state @xmath103 is either sensor estimated or computed by the formula @xmath104 ; cf .",
    "( [ e1 ] ) .    at the time @xmath78 , @xmath105",
    ", we have the state @xmath106 and the vector @xmath107 from the previous time @xmath108 .",
    "our goal is to solve the following equation with respect to @xmath109 : @xmath110 then we set @xmath111 , @xmath112 and choose the first block component of @xmath113 as the control @xmath114 .",
    "the next system state @xmath115 is either sensor estimated or computed by the formula @xmath116 .",
    "a direct way to solve ( [ e11 ] ) is generating the matrix @xmath93 and then solving the system of linear equations @xmath117 ; e.g. , by the gaussian elimination .",
    "a less expensive alternative is solving ( [ e11 ] ) by the gmres method , where the operator @xmath118 is used without explicit construction of the matrix @xmath93 ; cf .",
    "we recall that , for a given system of linear equations @xmath2 and initial approximation @xmath52 , gmres constructs orthonormal bases of the krylov subspaces @xmath119 , @xmath120 , given by the columns of matrices @xmath121 , such that @xmath122 with the upper hessenberg matrices  @xmath123 and then searches for approximations to the solution @xmath22 in the form @xmath124 , where @xmath125 .",
    "the convergence of gmres may stagnate for an ill - conditioned matrix @xmath3 .",
    "the convergence can be improved by preconditioning .",
    "a matrix @xmath5 that is close to the matrix @xmath3 and such that computing @xmath126 for an arbitrary vector @xmath127 is relatively easy , is referred to as a preconditioner .",
    "the preconditioning for the system of linear equations @xmath2 with the preconditioner @xmath5 formally replaces the original system @xmath2 with the equivalent preconditioned linear system @xmath128 . if the condition number @xmath129 of the matrix @xmath130 is small , convergence of iterative solvers for the preconditioned system can be fast .",
    "a typical implementation of the preconditioned gmres is given by algorithm [ a1 ] .",
    "gmres without preconditioning is the same algorithm with @xmath131 . in the pseudocode ,",
    "we denote by @xmath132 the submatrix of @xmath133 with the entries @xmath134 such that @xmath135 and @xmath136 .",
    "[ a1 ] @xmath137 , @xmath138 , @xmath52 , @xmath139 , @xmath5 solution @xmath22 of @xmath140 @xmath141 , @xmath142 , @xmath143 , @xmath144 @xmath145 , @xmath142 @xmath146^tz$ ] @xmath147h_{1:k , k}$ ] @xmath148 @xmath149 @xmath150^t\\|_2 $ ] @xmath151y$ ]    it is a common practice to compute the lu factorization @xmath4 by the gaussian elimination and then compute the vector @xmath126 by the rule @xmath152 .",
    "our finite horizon model prediction problem allows us to construct sparse preconditioners @xmath153 with a particular structure .",
    "these preconditioners are highly efficient , which is confirmed by the numerical experiments described below .",
    "we first observe that the states @xmath28 , computed by the forward recursion , and the costates @xmath56 , computed by the subsequent backward recursion , satisfy , in practice , the following property : @xmath154 , @xmath155 , @xmath156 and @xmath157 .",
    "it is a corollary of theorems about the derivatives of solutions of ordinary differential equations with respect to a parameter ; see , e.g. ,  @xcite .",
    "now we assume that the predicted states @xmath28 and costates @xmath56 are computed by the forward and backward recursions for the vector @xmath107 at the current system state @xmath79 during computation of the right - hand side vector @xmath158 and use the predicted @xmath28 and @xmath56 to form the blocks @xmath159 , @xmath160 , @xmath161 , @xmath162 of the symmetric matrix @xmath163,\\ ] ] where @xmath164 $ ] coincides with the last @xmath165 rows of @xmath93 .",
    "the integer @xmath165 denotes the sum of dimensions of @xmath166 and @xmath10 .    in the notation of theorem  [ th1 ] ,",
    "the above construction is explained as follows .",
    "we discard the second term in formula  [ e7a ] and use the truncated expression @xmath167=\\mathcal{l}_{uu}(g(u),u)$ ] for the entries of @xmath153 apart from the last @xmath165 columns and last @xmath165 rows .",
    "the last @xmath165 columns are computed exactly , the last @xmath165 rows equal the transposed last @xmath165 columns because of the symmetry of @xmath153 .",
    "the possibility to use the truncated expression is due to the above observation that @xmath154 , @xmath155 , @xmath156 , @xmath157 .",
    "moreover , the norm of @xmath168 is of order @xmath169 .",
    "the matrix @xmath153 is sparse since the blocks @xmath159 , @xmath160 , @xmath161 , @xmath162 are block diagonal and @xmath165 is small .",
    "the particular structure of @xmath153 is convenient for efficient lu factorization .",
    "it is possible to simultaneously permute the rows and columns of @xmath153 and to obtain an arrow - like pattern of nonzero elements , which admits a fast lu factorization .",
    "a representative example of the sparse preconditioners @xmath153 and their lu factorization is given in the next section .",
    "as a result , the setup of @xmath153 , computation of its lu factorization , and application of the preconditioner all cost @xmath0 floating point operations .",
    "the memory requirements are also of order @xmath0 .",
    "we consider a test nonlinear problem , which describes the minimum - time motion from a state @xmath170 to a state @xmath171 with an inequality constrained control :    * state vector @xmath172 $ ] and input control @xmath173 $ ] .",
    "* parameter variables @xmath174 $ ] , where @xmath175 denotes the length of the evaluation horizon . *",
    "nonlinear dynamics is governed by the system of ode @xmath176.\\ ] ] * constraints : @xmath177=0 $ ] , where @xmath178 , i.e. , the control @xmath23 always stays within the curvilinear band @xmath179 ) . * terminal constraints : @xmath180=0 $ ] ( the state should pass through the point @xmath171 at @xmath181 ) * objective function to minimize : @xmath182 where @xmath183 ( the state should arrive at @xmath171 in the shortest time ; the function @xmath6 serves to stabilize the slack variable @xmath184 ) * constants : @xmath185 , @xmath186 , @xmath187 , @xmath188 , @xmath189 , @xmath190 , @xmath191 , @xmath192 .",
    "the horizon @xmath193 $ ] is parameterized by the affine mapping @xmath194 with @xmath195 $ ] .",
    "the components of the corresponding discretized problem on the horizon are given below :    * @xmath196 , @xmath197 , @xmath198 ; * the participating variables are the state @xmath199 $ ] , the costate @xmath200 $ ] , the control @xmath201 $ ] , the lagrange multipliers @xmath202 and @xmath203 $ ] , the parameter @xmath10 ; * the state is governed by the model equation @xmath204,\\\\ y_{i+1}=y_i+\\delta\\tau\\left[p\\left(ax_{i}+b\\right)\\sin u_{i}\\right],\\end{array}\\right.\\ ] ] where @xmath39 ; * the costate is determined by the backward recursion ( @xmath205 , @xmath206 ) @xmath207,\\\\ \\lambda_{2,i } = \\lambda_{2,i+1},\\end{array}\\right.\\ ] ] where @xmath208 ; * the equation @xmath209 , where @xmath210,\\end{aligned}\\ ] ] has the following rows from the top to bottom : @xmath211 = 0 \\\\ \\delta\\tau\\left[2\\mu_iu_{di}-w_{d}p\\right ] = 0 \\end{array}\\right.\\ ] ] @xmath212=0 \\right.\\hspace*{7em}\\ ] ] @xmath213 @xmath214 + 1 = 0.\\end{array}\\right.\\ ] ]    the matrices @xmath93 have the sparsity structure as in fig .",
    "the preconditioner @xmath153 is the symmetric matrix @xmath215\\ ] ] having the diagonal blocks @xmath216 , @xmath217 , @xmath218 , @xmath219 .",
    "the diagonal entries of @xmath216 equal @xmath220 $ ] .",
    "the diagonal entries of @xmath218 equal @xmath221 .",
    "the diagonal entries of @xmath222 equal @xmath223 .",
    "the diagonal entries of @xmath224 equal @xmath225 .",
    "the entries of the vector @xmath226 equal @xmath227 .",
    "the entries of the vector @xmath228 equal @xmath229 .",
    "the entries of the vector @xmath230 equal @xmath231 .",
    "the blocks @xmath232 , @xmath233 , and @xmath234 equal to the respective blocks of @xmath3 and have to be computed exactly .",
    "the sparsity pattern of @xmath153 is displayed in fig .",
    "[ fig4 ] .    to compute the lu factorization of @xmath153 with @xmath0 floating point operations , we first repartition @xmath153 as @xmath235 , k_{11}=\\left[\\begin{array}{ccccc}m_{11}&0&m_{13}\\\\ 0&m_{22}&m_{23}\\\\m_{31}&m_{32}&0\\end{array}\\right],\\ ] ] where @xmath236 is usually nonsingular . using the representation @xmath237\\\\\\ ] ]",
    "@xmath238,\\ ] ] where @xmath239 , we obtain the block triangular factors @xmath240,\\ ; u = \\left[\\begin{array}{cc}k_{11}&k_{12}\\\\0&s_{22}\\end{array}\\right],\\ ] ] where @xmath241 . the application of the preconditioner costs @xmath0 operations .",
    "an alternative construction of the lu factorization uses a suitable simultaneous permutation of the rows and columns of @xmath153 with the permutation indices @xmath242 ,  ,",
    "@xmath243,  ,@xmath244 .",
    "the sparsity patterns of the permuted matrix and its lower triangular factor @xmath6 are displayed in fig .",
    "[ fig5 ] , the sparsity pattern of the upper triangular factor @xmath7 is the transpose of that of the factor @xmath6 .",
    "in our numerical experiments , carried out in matlab , the system of weakly nonlinear equations ( [ e11 ] ) for the test problem from section  [ sec : ex ] is solved by the gmres method .",
    "the error tolerance in gmres is @xmath245 .",
    "the number of grid points on the horizon is @xmath246 , the sampling time of the simulation is @xmath247 , and @xmath248 .",
    "the sparse preconditioners for gmres are constructed as in section  [ sec : ex ] , and the lu factorization is computed as proposed in the last paragraph of section  [ sec : ex ] .",
    "figure [ fig1 ] shows the computed trajectory for the test example and figure [ fig2 ] shows the optimal control by the mpc approach using gmres with preconditioning .",
    "gmres with preconditioning executes only 2 iterations at each step while keeping @xmath249 close to @xmath250 . for comparison",
    ", we show the number of iterations in gmres without preconditioning in figure [ fig3 ] , which is 4 - 14 times larger .",
    "we propose an efficient sparse preconditioner for the continuation / gmres method for nonlinear mpc problems .",
    "the arithmetical cost of preconditioning is @xmath0 , memory storage is @xmath0 , where @xmath1 is the number of gridpoints on the prediction horizon .",
    "p.  giselsson , optimal preconditioning and iteration complexity bounds for gradient - based optimization in model predictive control , in proc .",
    "american control conf . ,",
    "washington d.c .",
    ", usa , june , 2013 , pp .  358364 .",
    "m.  huang , h.  nakada , k.  r.  butts , and i.  v.  kolmanovsky , nonlinear model predictive control of a diesel engine air path : a comparison of constraint handling and computational strategies , in proc .",
    "5th ifac conf .",
    "nonlinear model predictive control , seville , spain , september 1720 , 2015 , pp .",
    "372379 .",
    "a.  knyazev and a.  malyshev , preconditioning for continuation model predictive control , in proc .",
    "5th ifac conf .",
    "nonlinear model predictive control , seville , spain , september 1720 , 2015 , pp .",
    "available at arxiv:1509.02861 .",
    "a.  knyazev and a.  malyshev , continuation model predictive control on smooth manifolds , in proc .",
    "16th ifac workshop control applications of optimization , garmisch - partenkirchen , germany , october 69 , 2015 .",
    "available at arxiv:1509.02848 .",
    "a.  knyazev and a.  malyshev , efficient particle continuation model predictive control , in proc .",
    "16th ifac workshop control applications of optimization , garmisch - partenkirchen , germany , october 69 , 2015 .",
    "available at arxiv:1509.02852 .",
    "a.  shahzad , e.  c.  kerrigan , and g.  a.  constantinides , preconditioners for inexact interior point methods for predictive control , in proc .",
    "american control conf . ,",
    "baltimore , md , usa , june 30july 2 , 2010 , pp .  57145719 .",
    "a.  shahzad , e.  c.  kerrigan , and g.  a.  constantinides , a fast well - conditionend interior point method for predictive control , in proc .",
    "ieee conf .",
    "decision control , atlanta , ga , usa , december 1517 , 2010 , pp .",
    "508513 .",
    "t.  tanida and t.  ohtsuka , preconditioned c / gmres algorithm for nonlinear receding horizon control of hovercrafts connected by a string , in proc .",
    "control appl . ,",
    "taipei , taiwan , september 2 - 4 , 2004 , pp ."
  ],
  "abstract_text": [
    "<S> we propose fast @xmath0 preconditioning , where @xmath1 is the number of gridpoints on the prediction horizon , for iterative solution of ( non)-linear systems appearing in model predictive control methods such as forward - difference newton - krylov methods . </S>",
    "<S> the continuation / gmres method for nonlinear model predictive control , suggested by t.  ohtsuka in 2004 , is a specific application of the newton - krylov method , which uses the gmres iterative algorithm to solve a forward difference approximation of the optimality equations on every time step . </S>"
  ]
}