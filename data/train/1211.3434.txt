{
  "article_text": [
    "the asymptotic behaviour of bayesian methods has been a long - standing topic of interest , including approximation of the posterior distribution and questions that are important from a frequentist point of view , such as consistency , efficiency and coverage of bayesian credible regions .",
    "for instance , for correctly specified regular finite - dimensional models with @xmath0 independent observations , these properties are captured by the bernstein ",
    "von mises theorem that implies that the posterior distribution can be approximated in a @xmath1 neighbourhood of the true value of the parameter by a gaussian distribution with variance determined by the fisher information . more generally , the bernstein ",
    "von mises theorem holds for dependent observations if the likelihood satisfies local asymptotic normality ( lan ) conditions [ @xcite ] .",
    "a  total variation distance version of the theorem was derived by @xcite .",
    "this theorem implies that the prior has no asymptotic influence on the posterior , that posterior inference is consistent and efficient in the frequentist sense , and that posterior credible regions are asymptotically the same as frequentist ones .",
    "one of the key assumptions of the bernstein ",
    "von mises ( bvm ) theorem is that the `` true '' value of the parameter is an interior point of the parameter space .",
    "however , for many problems , including our motivating example of a poisson inverse problem in tomography , and , more generally for the class of models we consider , this assumption of the bvm theorem does not hold .",
    "for the tomography example , the unknown parameter is a vector of tracer concentrations , which are nonnegative and can be zero .",
    "the situation where the unknown parameter can be on the boundary of the parameter support has been addressed in the frequentist literature by studying the asymptotic distribution of the maximum likelihood estimator [ @xcite , among others ] ; however it has been studied very little under the bayesian approach .",
    "@xcite investigated the asymptotic behaviour of the posterior probability of the unknown parameter belonging to a half - space @xmath2 for a regular correctly specified model , where they found that if the true value of the parameter belongs to the complement of @xmath2 , then the posterior probability of half - space @xmath2 goes to zero much faster , namely at least at rate @xmath0 rather than at the standard parametric rate @xmath3 ( @xmath0 here is the sample size ) , and there is an exponential upper bound on this posterior probability .",
    "also , @xcite gave a formula for calculating the expectation of a smooth functional of a 3-dimensional posterior distribution where the unknown parameter is on a smooth boundary .",
    "in this paper , we extend the bernstein ",
    "von mises theorem by relaxing the assumption that the `` true '' value of the parameter is interior to the parameter space , in a finite - dimensional setting .",
    "we consider a broad class of probability distributions for the data and allow the prior distribution to be improper and to have zero or infinite density on the boundary .",
    "a key model assumption is that the `` true '' value of the parameter minimises a generalised kullback ",
    "leibler distance .",
    "there is no assumption of any finite moments .",
    "we will show that for these models the consequences of relaxing this assumption are twofold : firstly , the convergence is faster , at least at rate @xmath0 , if the `` true '' parameter is on the boundary , and secondly , the limit of the posterior distribution has non - gaussian components .",
    "we motivate our study by presenting in section  [ secmotivation ] an inverse problem from medical imaging ; section  [ secsetup ] establishes the class of models we study . in section  [ secmainresult ] we state the result on the local behaviour of the posterior distribution in a neighbourhood of the limit that is formulated as a modified bernstein ",
    "von mises theorem , discuss the assumptions , and give a nonasymptotic version of the result . in section  [ secbvmexamples ]",
    "we illustrate the application of our analogue of the bvm theorem for various examples including the problem of variance estimation in mixed effects models , and discuss the choice of prior distribution .",
    "we discuss issues in using the approximation of the posterior distribution in practice and apply it to data from the motivating example in section  [ secspectexample ] .",
    "we conclude with a discussion .",
    "all proofs are deferred to the .",
    "single photon emission computed tomography ( spect ) is a medical imaging technique in which a radioactively - labelled tracer , known to concentrate in the tissue to be imaged , is introduced into the subject .",
    "emitted particles are detected in a device called a gamma camera , forming an array of counts .",
    "tomographic reconstruction is the process of inferring the spatial pattern of concentration of the tracer in the tissue from these counts .",
    "the poisson linear model @xmath4 comes close to reality for the spect problem ( there are some dead - time effects and other artifacts in recording ) . here",
    "@xmath5 represents the spatial distribution of the tracer , typically discretised on a grid , with @xmath6 for all @xmath7 , @xmath8 the array of the rate of detected photons per time unit , also discretised by the recording process , and @xmath9 is the exposure time for photon detection .",
    "the @xmath10 array @xmath11 with rows @xmath12 quantifies the emission , transmission , attenuation , decay , and recording process ; @xmath13 is the mean number of photons recorded at @xmath14 per unit concentration per unit time at pixel / voxel @xmath7 , and is nonnegative . in some methods of reconstruction",
    ", elements of the matrix @xmath15 are modelled as discretised values of the radon transform .",
    "since poisson distributions form an exponential family , this model can be seen as a generalised linear model [ @xcite ] , with identity link function and dispersion @xmath16 ; see also example  [ expoissonm ] in section  [ secexamplesboundary ] .",
    "we formalise the notion of small - noise limit for this poisson model in a practically - relevant way , by supposing that the exposure time for photon detection becomes large , that is , letting @xmath17 .",
    "the `` true image '' @xmath18 in emission tomography corresponds to a physical reality , the discretised spatial distribution of concentration of the tracer .",
    "since this is nonnegative , we impose the constraints @xmath19 .",
    "unless @xmath20 is too large , that is , the spatial resolution of @xmath21 is too fine , the matrix @xmath15 is normally of full rank @xmath20 , and hence the inverse problem is well posed ( although it may be ill - conditioned ) ; see @xcite for eigenvalues of the radon transform .",
    "see @xcite for further detail about this model , and an approach based on em estimation for map reconstruction of @xmath21 , in a bayesian formulation in which spatial smoothness of the solution is promoted by using a pairwise difference markov random field prior .      from the beginning of bayesian image analysis [ @xcite ]",
    ", use has been made of markov random fields as prior distributions for image scenes that express generic , qualitative beliefs about smoothness , yet do not rule out abrupt changes for real discontinuities ( e.g. , at tissue type boundaries in the case of medical imaging ) .",
    "the prior distribution we consider for the spect model is a log cosh pairwise - interaction markov random field [ @xcite ] , @xmath22 where @xmath23 stands for @xmath7 and @xmath24 being neighbouring pixels . in this paper",
    "the parameters @xmath25 and @xmath26 are considered to be fixed .",
    "this model has some attractive properties . while giving less penalty to large abrupt changes in @xmath21 compared to the gaussian",
    ", it remains log - concave .",
    "it bridges the extremes @xmath27 , the gaussian pairwise - interaction prior , and @xmath28 , the corresponding laplace pairwise - interaction model , sometimes called the `` median prior . ''",
    "this distribution is improper since it is invariant to perturbing @xmath21 by an arbitrary additive constant , but leads to a proper posterior distribution as long as @xmath29 for some @xmath14 .",
    "the bayesian model for spect has three nonstandard features : ( a ) the true image @xmath18 can lie on the boundary of the parameter space @xmath30 ; ( b ) if @xmath31 for some @xmath14 , then the distribution of the corresponding @xmath32 degenerates to a point mass at 0 ; ( c ) the prior distribution is not proper .    in the next section we formulate a model that includes the bayesian spect model as a particular case .",
    "the approximate behaviour of the posterior distribution of @xmath21 for large @xmath9 is investigated in section  [ secspectexample ] .",
    "we now list assumptions on the distribution of the observable responses @xmath33 , taking values in @xmath34 ; it has density ( with respect to lebesgue or counting measure ) denoted by @xmath35 for @xmath36 .",
    "these assumptions are expressed in terms of the scaled log - likelihood defined by @xmath37 as we shall see from the assumptions , @xmath38 is related to the level of noise , and we are interested in the case where @xmath38 is small .",
    "we assume that the `` true '' value of the unknown parameter that generated the data is @xmath39 , and denote the true probability measure of @xmath33 by @xmath40 .",
    "below , where it does not lead to ambiguity , we will omit the index @xmath38 to simplify the notation and will write @xmath41 and @xmath42 .",
    "[ assm ] ( 1 ) for @xmath43 , there exists a deterministic function @xmath44 such that for all @xmath45 , @xmath46    \\(2 ) the function @xmath47 has a unique maximum over @xmath48 at @xmath49 .",
    "further assumptions on @xmath50 are given in section  [ secquadraticapprox ] .",
    "assumption  [ assm ] is satisfied for a wide class of models , in particular for models with independent identically distributed ( i.i.d . )",
    "observations with @xmath51 and for distributions from the exponential family in canonical form with dispersion @xmath52 , that are discussed below .    the function @xmath47 , defined in assumption  [ assm](1 ) , can be viewed as the limit of the negative kullback ",
    "leibler ( @xmath53 ) distance , rescaled by @xmath54 , between distributions with densities @xmath55 and @xmath56 , that was used , for instance , in @xcite and @xcite . for i.i.d .",
    "models , @xmath47 is the negative kullback  leibler distance based on a single observation , and for generalised linear models @xmath47 is the log - likelihood for `` noise - free '' data .",
    "assumption  [ assm](2 ) states that this generalised kullback ",
    "leibler distance is minimised at the `` true '' value @xmath18 , as holds for the usual @xmath57 distance .",
    "assumption  [ assm](2 ) has been used by other authors , for instance , in the context of hidden markov models by @xcite where it was called the _ identifiability assumption _ , and a finite sample analogue of this assumption was used in the context of a misspecified model by @xcite .",
    "this assumption holds for some models where the parameter set @xmath48 is not open and thus where the true value of the parameter @xmath58 can be on the boundary of @xmath48 ; see example  [ expoissonm ] .",
    "these assumptions are satisfied for the tomography model discussed in section  [ secmotivation ] where the unknown tracer image @xmath58 can have zero intensity values in some pixels , as shown in section  [ secexamplesboundary ] .",
    "next we show that assumption  [ assm ] is satisfied for two important classes of models , generalised linear models , and i.i.d .",
    "models , including the case when @xmath18 is on the boundary of @xmath48 .      in the generalised linear models of @xcite , an important class of nonlinear statistical regression problems , responses @xmath59 , @xmath60 are drawn independently from a one - parameter exponential family of distributions in canonical form , with density or probability function @xmath61 \\biggr ) , \\ ] ] using the mean parameterisation , for appropriate functions @xmath62 , @xmath63 , and @xmath64 characterising the particular distribution family .",
    "the parameter @xmath54 is a common dispersion parameter shared by all responses . assuming that functions @xmath65 and @xmath66 are twice differentiable",
    ", the expectation of this distribution is @xmath67 , and the variance is @xmath68 /[b'(\\eta_i)]^3 $ ] .",
    "this implies that the random variable @xmath33 converges in probability to a finite deterministic limit @xmath69 as @xmath70 and that the dispersion @xmath54 is related to the noise level of the observations .",
    "firstly consider the case @xmath71 .",
    "then , @xmath72 is linear in @xmath33 , and hence it converges to @xmath73 in probability as @xmath70 .",
    "therefore , assumption  [ assm](1 ) is satisfied with @xmath74 . if @xmath75 and the hessian , which is diagonal , has negative entries , then @xmath18 uniquely maximises @xmath47 ; that is , assumption  [ assm](2 ) is satisfied .",
    "if @xmath18 is on the boundary and the gradient is nonzero , see examples  [ expoissonm ] and  [ exbinomm ] below .    now consider a generalised linear model with @xmath76 and matrix @xmath15 such that @xmath77 is of full rank , that is , such that the likelihood is identifiable with respect to parameter @xmath21 . in this case ,",
    "assumption  [ assm ] holds with @xmath78 . the tomography example given in section  [ secmotivation ] belongs to this class of models , with @xmath79 , @xmath80 , @xmath81 , and @xmath82 .",
    "now we show that assumption  [ assm](2 ) is satisfied when @xmath18 is on the boundary of  @xmath48 for some distributions from the exponential family .",
    "[ expoissonm ] consider the poisson distribution @xmath83 with @xmath84 .",
    "the scaled log - likelihood for @xmath85 is @xmath86 .",
    "if @xmath33 is generated with @xmath87 , then we observe @xmath88 with probability 1 , so in this case the scaled log - likelihood for @xmath85 is always @xmath89 , which is maximised over @xmath84 at @xmath87 , that is , the true value of @xmath85 .    [ exbinomm ] for the binomial distribution @xmath90 ,",
    "the scaled log - likelihood for @xmath91 $ ] is @xmath92/n$ ] . if the true value of @xmath85 is @xmath93 , then @xmath94 and the scaled log - likelihood for @xmath85 is @xmath95 , which is maximised over @xmath96 $ ] at @xmath97 , so that again we recover the true value , and assumption  [ assm](2 ) is satisfied for this model .",
    "the same holds for the other boundary point @xmath87 , and also for multinomial and negative binomial distributions .",
    "let @xmath98 be independent identically distributed random variables where the density or probability mass function of @xmath32 is @xmath99 , with unknown parameter @xmath100 where @xmath20 is finite and independent of @xmath0 . here , @xmath101 and @xmath102 . in this case",
    ", @xmath103 are i.i.d .",
    "random variables , so , as @xmath104 , assumption  [ assm](1 ) is satisfied under the conditions of the weak law of large numbers for the random variable @xmath105 , for all  @xmath21 , which implies that there exists @xmath47 such that @xmath106 converges in probability to @xmath47 as @xmath104 .",
    "if @xmath107 $ ] exists for all @xmath108 , then @xmath109 $ ] , equal to the negative kullback ",
    "leibler distance between the distributions with densities @xmath110 and @xmath111 , and then assumption  [ assm](2 ) holds .",
    "for instance , it is easy to check that assumption  [ assm ] is satisfied for i.i.d .",
    "cauchy random variables @xmath32 with @xmath112 and @xmath113 .",
    "we adopt a bayesian paradigm , using a @xmath38-finite prior measure @xmath114 on @xmath48 .",
    "thus the posterior distribution satisfies @xmath115 here we do not assume that the prior distribution is proper , nor do we assume that its density is bounded away from 0 and infinity on the boundary of @xmath48 ; see assumption  [ assp ] in section  [ secquadraticapprox ] .",
    "we shall use the default norms @xmath116 for both vectors and matrices . if the appropriate derivatives exists , define the gradient @xmath117 of a function @xmath118 on @xmath48 as a vector of partial derivatives ( one - sided if @xmath21 is on the boundary of @xmath48 ) , and @xmath119 is a matrix of second derivatives of @xmath118 ( again , one - sided if @xmath21 is on the boundary of @xmath48 ) .",
    "we use notation @xmath120 to define the vector for @xmath121 , a convention which also applies to the gradient @xmath122 , that is , @xmath123 .",
    "we denote a submatrix @xmath124 indexed by subsets @xmath125 by @xmath126 ; this also applies to the matrix of second derivatives , so we can write @xmath127 to denote the corresponding submatrix .    we use @xmath128 to denote the image of an affine transformation of the set @xmath129 given matrix @xmath15 and vector @xmath130 .",
    "the limit of the posterior distribution has a different character in different directions , and we need to partition the index set @xmath131 of @xmath21 accordingly .",
    "let @xmath132 with dimensions @xmath133 and @xmath134 , respectively .",
    "we partition @xmath135 further : @xmath136 with dimensions @xmath137 and @xmath138 where @xmath139 corresponds to @xmath18 being on the boundary of @xmath48 ; see assumption  [ assb](1 ) below .",
    "we then introduce a permutation of coordinates of @xmath21 , defined by any matrix @xmath140 that maps @xmath141 to the first @xmath142 coordinates , @xmath143 to the next @xmath144 , and @xmath145 to the last @xmath146 .",
    "the first @xmath133 rows of @xmath140 will be denoted @xmath147 and the remainder @xmath148 .",
    "we denote the index set @xmath149 by @xmath150 which is the image of @xmath143 under the map defined by @xmath140 .",
    "note that @xmath151 for all @xmath152 ( for @xmath153 , this is given by lemma  [ lemopt ] below ) , so this set describes the coordinates of @xmath58 that lie on the boundary ; in the case of @xmath143 the gradient is also zero in this direction .",
    "we introduce the notation @xmath154 for a polynomially - tilted multivariate gaussian distribution truncated to @xmath155 , for which the corresponding measure of any measurable @xmath156 is defined by @xmath157\\\\[-15pt ] & & \\qquad   = \\frac{\\int_{\\mathcal{b } } \\prod_{j\\in t_0^\\star } x_j^{\\alpha_{0,j } -1 } e^ { - ( x - a_0 ) ^t \\omega_{00}(x - a_0 ) /2 } \\,dx } { \\int_{\\mathcal{v}_0 } \\prod_{j\\in t_0^\\star } x_j^{\\alpha_{0,j } -1 } e^ { - ( x - a_0 ) ^t \\omega_{00}(x - a_0 ) /2 } \\,dx},\\nonumber\\end{aligned}\\ ] ] where @xmath158 , @xmath159 is a @xmath160 positive definite matrix , and @xmath161 .",
    "@xmath162 could also be interpreted as a @xmath133-dimensional vector whose first @xmath138 coordinates are irrelevant .",
    "note that this distribution is gaussian if @xmath163 , and truncated gaussian if @xmath164 and @xmath165 for all @xmath7 .    for @xmath166",
    ", @xmath167 denotes the gamma distribution with density @xmath168 , @xmath169 , and @xmath170 the corresponding probability measure .",
    "in addition to assumption  [ assm ] ( section  [ seclik ] ) , we make the following assumptions .",
    "they make use of the following neighbourhoods of @xmath18 : @xmath171 where @xmath172 , @xmath173 and @xmath174 .",
    "[ assb ] ( 1 ) @xmath175 and @xmath176 .",
    "\\(2 ) @xmath177 for some @xmath178 .",
    "[ asss ] there exist @xmath173 depending on @xmath38 such that :    @xmath179 , @xmath180 , @xmath181 , @xmath182 as @xmath70 .    for all @xmath183 , @xmath184 , @xmath185 and @xmath186 exist @xmath40-almost everywhere , for small enough @xmath38 .",
    "for any @xmath187 , @xmath188    @xmath189 for small enough @xmath38 .",
    "there exists a @xmath160 positive definite matrix @xmath190 such that @xmath191    [ assp ] the @xmath38-finite measure @xmath114 on @xmath48 satisfies the following conditions :    @xmath192 for @xmath193-almost all @xmath194 , for small enough @xmath38 .    for @xmath183",
    ", there exists @xmath195 such that @xmath196 .",
    "there exist @xmath197 and @xmath198 for @xmath199 , independent of @xmath38 , and there exists @xmath200 , such that @xmath201 as @xmath70 and for @xmath202 , @xmath203 denote @xmath204 , @xmath205 .",
    "[ assl ] assume @xmath206 as @xmath70 , where @xmath207    assumption  [ assl ] implies consistency of the posterior distribution at a certain rate , and it can be written as @xmath208 as @xmath70 .",
    "consistency of the posterior is a necessary assumption for the bernstein ",
    "von mises theorem [ @xcite , theorem  10.1 ] . under assumption  [ assm ] , assumption  [ assl ] holds if the following condition is satisfied : @xmath209\\\\[-10pt ] \\eqntext{\\mbox { as } \\sigma\\to0,}\\end{aligned}\\ ] ] where the function @xmath210 is such that @xmath211    under assumption  [ assb ] , the complement of the polar cone of the set @xmath212 coincides with @xmath213 in a small enough neighbourhood of @xmath214 ; this is essential for the analytic arguments of the paper .",
    "this property holds for other polyhedral boundaries ; for affine transformations of the positive orthant this is trivial , while in general it relies on the fact that @xmath70 .",
    "for a set @xmath48 that does not satisfy these conditions , the support of the posterior distribution in the limit may depend on the complement of the polar cone of @xmath213 ; see also @xcite .    in assumption  [ asss ] , we assume uniform convergence in probability of the derivatives of the scaled log - likelihood at @xmath18 as @xmath215 tends to 0 , and that the score function of @xmath216 converges to 0 at rate @xmath217 .    in assumption  [ assp ] , we assume that the posterior distribution is proper but we do not assume that the prior measure itself is proper .",
    "neither do we assume that @xmath218 is finite and bounded away from 0 on the boundary of the parameter space , that is , that @xmath219 for all @xmath7 , which is the assumption of the bvm theorem .",
    "in particular , the log cosh markov random field prior distribution that was discussed in section  [ secmotivation ] for the motivating example , satisfies these conditions with @xmath219 for all @xmath220 .",
    "other improper priors such as the jeffreys prior for a poisson likelihood , as well as the conjugate gamma prior and beta prior conjugate to a binomial likelihood , satisfy this assumption ; see examples in section  [ secbvmexamples ] .      before presenting the main result , we state two preliminary lemmas .",
    "firstly , we show that the elements @xmath221 are on the boundary of @xmath48 , and secondly , we study properties of the derivatives of @xmath47 .",
    "[ lemopt ] if assumption  [ assm ] in section  [ seclik ] and assumption  [ assb ] in section  [ secquadraticapprox ] hold , then @xmath222 and vector @xmath223 has negative coordinates .",
    "if also for any @xmath187 , @xmath224 as @xmath70 , then the matrix @xmath225 is positive semi - definite .",
    "this lemma follows from standard optimality conditions [ e.g. , proposition  2.1.2 in @xcite ] .",
    "define the following scaling transform @xmath226 : @xmath227 where @xmath228 and @xmath229 is defined in section  [ secquadraticapprox ] .",
    "the two subsets of coordinates are scaled differently ; we are considering @xmath230 and @xmath231 . in the next lemma",
    "we study the image of @xmath232 defined by ( [ eqdefbdelta ] ) under this transformation , in the limit .",
    "[ lemlimitx ] let assumption  [ assb ] in section  [ secquadraticapprox ] hold , and take @xmath233 and @xmath234 such that @xmath235 , @xmath236 , @xmath237 , and @xmath238 as @xmath70 .",
    "then , @xmath239 the @xmath240 being in the sense of @xcite .",
    "the proof of the lemma is given in appendix  [ secproofaux ] .",
    "the limit of the posterior distribution is described by the following parameters : @xmath204 and @xmath241 defined in assumption  [ assp ] , @xmath159 defined in assumption  [ asss ] , and @xmath242 and @xmath243 defined by @xmath244 the vector @xmath245 has positive coordinates , which follows from lemma  [ lemopt ] .",
    "the matrix @xmath246 is an analogue of the fisher information for @xmath216 .    in the theorem below , which is an analogue of the bernstein ",
    "von mises theorem , we claim that under the stated assumptions , the posterior distribution of @xmath247 , @xmath248 , converges to a finite limit .",
    "[ thpostapproxbvm ] consider the bayesian model defined in section  [ secsetup ] under assumption  [ assm ] and such that assumptions  [ assb ] ,  [ asss ] ,  [ assp ] and  [ assl ] hold .",
    "define a random probability measure on @xmath249 , with @xmath250 : @xmath251 where @xmath252 , @xmath253 is the polynomially - tilted truncated gaussian distribution defined by ( [ eqmodifgauss ] ) , and @xmath254 is the probability measure of a @xmath146-dimensional vector @xmath255 with independent coordinates @xmath256 .    then , with transform @xmath257 defined by ( [ defscaledtransform ] ) , as @xmath70 , @xmath258    the proof is given in appendix  [ sectheproof ] . if @xmath18 is an interior point , then @xmath259 , the additional factor in the definition of @xmath260 disappears , and the limit is gaussian , as in the classical bernstein ",
    "von mises theorem .",
    "assumptions  [ assm ] and  [ asss ] imply that the log - likelihood can be approximated quadratically with respect to the parameter @xmath216 ( which includes @xmath261 where the `` true '' parameter is on the boundary of the parameter space ) but not with respect to  @xmath262 .",
    "this is related to the lan property [ @xcite ] . in particular , the rate of convergence for @xmath261 is still @xmath217 , and the limit of the rescaled posterior is truncated gaussian , possibly modified by the behaviour of the local prior density on the boundary , whereas for @xmath263 the rate of convergence is faster ( @xmath264 instead of @xmath217 ) , @xmath263 is asymptotically independent of @xmath216 given data , and its limiting distribution is gamma .",
    "see examples in section  [ secbvmexamples ] .",
    "we shall see in section  [ secbvmexamples ] that in a number of models parameter components on the boundary can only be either all regular or all nonregular .",
    "however , in the motivating spect example , both types of boundary behaviour can occur . hence the chosen prior , satisfying assumption  [ assp ] with @xmath219 for all @xmath265 , results in asymptotically efficient inference for the regular parameters .",
    "the key property of the posterior distribution , when the true parameter is on the boundary , is that the gradient of the log - likelihood at this point does not vanish asymptotically .",
    "thus in some directions the leading term at the taylor expansion of log posterior density is linear rather than quadratic , as would be the case when @xmath18 is an interior point . if the local prior density at @xmath18 is bounded away from 0 and infinity , then the limit of the posterior in these directions is an exponential distribution ; if the local prior density has an additional polynomial term in a neighbourhood of @xmath266 , then the limit is a gamma distribution .",
    "if the prior density behaves like a positive constant on the boundary or the `` regular '' part of the parameter is not on the boundary , then the limiting distribution @xmath267 has a simple form .    [ thpostapproxbvmgamma ]",
    "assume that assumption  [ assp ] is satisfied with @xmath268 for , or the set @xmath269 is empty ( i.e. , @xmath163 ) .",
    "then , under the conditions of theorem  [ thpostapproxbvm ] , the limiting probability measure @xmath267 on @xmath270 is defined by @xmath271 where @xmath272 denotes the gaussian distribution truncated to @xmath273 and normalised to be a probability measure .    in particular ,",
    "if the prior distribution behaves as a constant in a neighbourhood of @xmath18 ( @xmath274 for all @xmath7 ) , then the limit of @xmath275 is multivariate exponential .",
    "we can see that for @xmath276 the standard bernstein ",
    "von mises theorem holds under the assumption that the prior density in the neighbourhood of @xmath276 is bounded away from 0 and infinity , a standard assumption of the bvm theorem .",
    "thus inference for @xmath276 is asymptotically independent of the prior and is asymptotically equivalent to efficient frequentist inference .",
    "however , inference for @xmath263 is different .",
    "the first key difference is that there is no need to require a similar assumption on the prior distribution : even if the local prior density tends to infinity or zero ( both at a polynomial rate ) on the boundary , for i.i.d .",
    "observations with @xmath277 , bayesian inference is still consistent , at a rate faster than the parametric @xmath3 rate .",
    "the second difference is that the limit of the rescaled and recentred posterior distribution for @xmath221 is not random ( i.e. , does not depend on @xmath278 ) .",
    "these two properties lead to the third important difference which is the formulation of efficiency of the estimation procedure for these `` nonregular '' parameters .",
    "this point is elaborated below .",
    "consider the case where @xmath279 and @xmath18 is on the boundary ( i.e. , @xmath280 ) with @xmath281 . if the prior density at @xmath18 is not bounded away from 0 and infinity , the limit of the posterior distribution depends on the behaviour of the prior distribution on the boundary via exponent @xmath282 ( @xmath283 with @xmath284 ) .",
    "this exponent is a construct of the statistician and does not depend on the data or its model and can be chosen freely .",
    "if @xmath285 , then the prior density at the true value @xmath18 is 0 , and if @xmath286 , the local prior density of @xmath21 tends to infinity as @xmath287 .",
    "the length of the asymptotic posterior credible interval for @xmath21 decreases to 0 as @xmath288 ( see examples  [ expoisson ] and [ exbinom ] in section  [ secbvmexamples ] ) ; hence it is possible to recover the true value on the boundary as precisely as desired , up to the error of approximation of the posterior distribution by its limit ( an upper bound on that is presented in proposition  [ propbvmnonasympt ] ) . note that for the poisson and binomial distributions discussed in examples  [ expoisson ] and  [ exbinom ] , the jeffreys prior satisfies assumption  [ assp ] with @xmath289 .",
    "this property raises questions about the formulation of efficiency in this case , as , from a theoretical perspective , there appears to be no lower bound on the length of the credible interval as in the regular case .",
    "we also state a nonasymptotic bound on the distance between the posterior distribution of the rescaled parameter and its limit .",
    "[ propbvmnonasympt ] assume that the following conditions hold for @xmath233 and @xmath290 and for some @xmath291 , @xmath292 that may depend on @xmath233 and @xmath234 : @xmath293\\\\[-8pt ] \\nonumber \\delta_0 & \\leq & c_0,\\qquad \\delta_1 \\leq c_1,\\end{aligned}\\ ] ] where @xmath294 , @xmath295 is the smallest eigenvalue of @xmath159 , and @xmath296 are constants from assumption  [ assb ] .",
    "let the assumptions of theorem  [ thpostapproxbvm ] hold , and define the following events : @xmath297\\\\[-8pt]\\nonumber \\mathcal{a}_1 & = & \\bigl\\ { \\omega\\dvtx   \\sup_{\\theta\\in\\theta^\\star ( \\delta ) } \\bigl\\| \\nabla_{s_1 } \\ell_{y(\\omega ) } ( \\theta ) + a_1\\bigr\\| _ { \\infty } \\leq\\delta_{*1 } \\bigr\\}.\\end{aligned}\\ ] ] then , on @xmath298 , @xmath299\\\\[-8pt ] & & \\quad\\qquad{}+ 2 \\max \\biggl\\ { c_0\\delta_{*0 } , c_{\\alpha_0 } \\gamma \\biggl ( \\biggl ( \\frac{\\lambda_{\\min}(\\omega _ { 00})}{2 } \\biggl[\\frac{\\delta_0}{\\sigma } - \\bigl\\|a_0(\\omega)\\bigr\\| \\biggr]^2 , \\infty \\biggr ) ; \\frac{p_{\\alpha0 } } 2 , 1 \\biggr ) \\biggr\\}\\hspace*{-10pt } \\nonumber \\\\ & & \\quad\\qquad{}+ c_2 \\delta_{\\pi } + c_{\\delta } \\delta_0(\\delta),\\nonumber\\end{aligned}\\ ] ] where @xmath300 and the constants are defined in the proof .",
    "if also @xmath301 and @xmath302 as @xmath303 , then the upper bound in ( [ eqnonasymp ] ) tends to 0 .    the proof is given in appendix  [ sectheproof ]",
    "note that under the assumptions of theorem  [ thpostapproxbvm ] , @xmath304 as @xmath301 and @xmath302 .",
    "for the upper bound of the total variation to be small in practical applications , the dimensions @xmath305 should not be too large compared to the corresponding rate , the smallest eigenvalue of the precision matrix @xmath159 can not be too small , that is , that @xmath306 should be large , and that the combination of parameters @xmath307 should be such that value @xmath308 is far in the tail of all corresponding gamma distributions . if @xmath309 for all @xmath7 , this requires that the smallest value @xmath310 of the parameter @xmath245 should not be too small , that is , @xmath311 should be large .",
    "it is interesting to note that , for each @xmath312 , if @xmath313 , which holds in many cases , the value of @xmath314 minimising the local upper bound ( the first two lines of the upper bound ) coincides with the upper bound of the ky fan distance between the posterior distribution of @xmath315 and its limit , a point mass at @xmath316 .",
    "these are @xmath317 and @xmath318 [ @xcite ] .",
    "we now give examples where the asymptotic posterior distribution differs from gaussian .",
    "we start with a rule to verify assumption  [ assl ] which applies to exponential family distributions that we consider below .",
    "[ lemassumptionl ] take @xmath173 such that @xmath319 , and assume that for any @xmath320 , @xmath321 for some @xmath322 with probability close to 1 for small enough @xmath38 , and that there exist @xmath323 , @xmath324 , and @xmath325 such that for all @xmath45 , @xmath326 if @xmath327 and @xmath328 , then @xmath329 as @xmath70 with probability 1 , that is , assumption  [ assl ] is satisfied .    the proof is given in appendix  [ secproofaux ] .",
    "[ expoisson ] consider @xmath330 independently for @xmath331 , where the true value is @xmath280 . in this case ,",
    "@xmath101 and @xmath332 .",
    "consider an improper prior for @xmath21 with density @xmath333 with some @xmath334 ; the case @xmath289 corresponds to the jeffreys prior for parameter @xmath21 . in this case , the exact posterior distribution for @xmath21 is @xmath335 , that is , @xmath336 which agrees with theorem  [ thpostapproxbvm ] , and the exact @xmath337 credible interval for @xmath21 is @xmath338 $ ] where @xmath339 is the 95% percentile of the @xmath340 distribution . for @xmath341 ,",
    "the credible interval is @xmath342 $ ] , and for @xmath343 , it is @xmath344 $ ] . by decreasing @xmath282 to 0 , we can construct a credible interval of arbitrarily small length for fixed @xmath0 , even for @xmath345 .",
    "[ exbinom ] consider the problem of estimating the unknown probabilities of binomial distributions @xmath346 independently , @xmath347 , for @xmath348 $ ] , where the true value @xmath349 of some @xmath350 is 0 .",
    "we assume that all @xmath351 ( if @xmath352 for some @xmath14 , consider @xmath353 as data and @xmath354 as the corresponding parameter ) .",
    "we study the limit of the posterior distribution for large @xmath355 for all @xmath347 such that @xmath356 where @xmath357 , and @xmath20 is fixed .",
    "this situation is not covered by the standard bvm theorem .",
    "consider a conjugate beta prior @xmath358 independently , with some fixed @xmath334 . in this case ,",
    "@xmath101 and , as @xmath104 , @xmath359.\\end{aligned}\\ ] ] if @xmath360 , the corresponding summand in @xmath361 is @xmath362 which is defined for @xmath363 , and then @xmath364 . in this case",
    ", @xmath143 is always empty , @xmath365 for @xmath366 and @xmath367 for @xmath368 .",
    "assumption  [ assm ] was verified in example  [ exbinomm ] , and it is easy to check that assumptions  [ asss ] ,  [ assp ] and  [ assl ] are satisfied ( e.g. , for @xmath279 and @xmath369 , conditions of lemma  [ lemassumptionl ] hold with and @xmath370 ) .",
    "therefore , @xmath371 , @xmath372 , and @xmath373 .",
    "theorem  [ thpostapproxbvm ] implies the following asymptotic approximation of the posterior distribution of @xmath374 : @xmath375 similarly to the poisson likelihood case ( example  [ expoisson ] ) , for @xmath282 close to 0 , the approximate credible intervals for @xmath350 , @xmath376 , are small .",
    "this is easy to see from the marginal @xmath377 credible intervals which are @xmath378 $ ] .",
    "consider a model studied by @xcite : @xmath379 where @xmath380 independently , for @xmath331 and @xmath381 .",
    "here there are @xmath0 classes with @xmath382 elements in each , and the parameter of interest is the contribution of the classes that is characterised by the parameter @xmath383 , where the value @xmath384 corresponds to the absence of the random effects @xmath385 .",
    "we study the asymptotic concentration of the posterior distribution of @xmath21 when the number of classes @xmath0 grows while the number of class elements @xmath382 remains fixed .",
    "we consider a prior distribution for @xmath21 with density @xmath386 for @xmath334 and @xmath387 , which includes a case of improper prior distributions when @xmath388 .",
    "note that the inverse gamma prior with density @xmath389 potentially leads to very slow convergence , since it has a root of infinite order at 0 .",
    "we start with the case @xmath390 and @xmath391 known , so without loss of generality we fix @xmath392 and @xmath393 . after integrating out @xmath394 we have that @xmath395 , independently , where @xmath18 is the true value of the parameter @xmath21 . if @xmath396 , then the model is regular and the posterior distribution of @xmath21 is asymptotically gaussian .",
    "now we consider the case @xmath280 . using the marginal likelihood of @xmath397 given @xmath21 and taking @xmath101 , we have @xmath398 since @xmath399 , and assumption  [ assm ] is satisfied with @xmath400 .",
    "it is easy to check that assumptions  [ assb ] ,  [ asss ] ,  [ assp ] and  [ assl ] are satisfied , and @xmath401 .",
    "thus , by theorem  [ thpostapproxbvm ] , the approximate posterior distribution of @xmath402 has density @xmath403 with @xmath404 .",
    "it is easy to show that the cramer  rao lower bound on the variance of estimators of @xmath21 applies here , even in the case @xmath405 .",
    "thus , using a prior with @xmath406 ( i.e. , introducing a bias towards 0 ) would lead to superefficiency , that is , loss of efficiency for @xmath407 . in the case",
    "@xmath408 the posterior distribution is gaussian with the same mean and variance as in the bvm theorem but truncated to @xmath409 .",
    "the length of the credible interval for @xmath21 in this case is smaller than in the case where @xmath18 is an interior point .",
    "now consider the case where parameters @xmath410 are estimated jointly with a continuous prior for @xmath411 whose density is finite and positive at the true value @xmath412 .",
    "then @xmath413 since @xmath414 and @xmath415 .",
    "the function @xmath416 is maximised at @xmath417 , @xmath418 and @xmath419 , with zero gradient and the negative matrix of the second order derivatives @xmath159 and its inverse ( the covariance matrix ) being @xmath420    if @xmath421",
    ", then the approximate joint posterior distribution of @xmath422 is gaussian truncated to @xmath423 with bias as given in theorem  [ thpostapproxbvm ] and the covariance matrix @xmath424 given above .",
    "note that @xmath21 and @xmath425 are asymptotically correlated , with correlation @xmath426 .",
    "consider the spect model defined in section  [ secmotivation ] , in which @xmath18 has some zero coordinates .",
    "the assumptions of theorem  [ thpostapproxbvm ] were verified in examples  [ expoissonm ] and [ expoisson ] ( assumptions  [ assm ] ,  [ assb ] ,  [ asss ] ) , and the log cosh markov random field prior distribution satisfies assumption  [ assp ] with @xmath427 for all @xmath7 .",
    "assumption  [ assl ] also holds , since the conditions of lemma  [ lemassumptionl ] are satisfied for independent poisson random variables with @xmath428 , @xmath429 , where @xmath430 with @xmath431 for small enough @xmath432 , due to the inequality @xmath433 for @xmath434 .    for this model , @xmath435 , which is nonzero if @xmath436 is not empty",
    "hence , nonregularity arises from the elements where there are no detected photons ( @xmath437 ) and the likelihood degenerates : @xmath438 for @xmath439 but , since @xmath440 , this gives us information about those  @xmath441 where @xmath442 , that is , on @xmath443 and @xmath444 .",
    "the limiting distribution of @xmath275 is exponential with parameter @xmath445 .",
    "the parameter @xmath446 has approximately a truncated gaussian distribution with parameters @xmath447_{{\\overline}{z}}\\bigr ) a_{{\\overline}{z } , s_0 } , \\qquad a_0 = \\omega_{00}^{-1 } a_{{\\overline}{z},s_0}^t \\widetilde{y } /\\sigma , \\ ] ] where @xmath448 is a vector with coordinates @xmath449 for @xmath450 .",
    "truncation takes place for parameters @xmath451 with @xmath452 and @xmath453 .",
    "if the vector of poisson means @xmath454 has only positive coordinates ( @xmath455 is empty ) , the model is regular , and the posterior distribution of @xmath456 is approximately truncated gaussian",
    ".      we will briefly discuss some practical implications of theorem  [ thpostapproxbvm ] .",
    "well - developed methods for spect reconstruction using our model , using markov chain monte carlo computation , deliver both approximate , simulation - consistent , posterior means and variances ; see @xcite for a fully bayesian reconstruction .",
    "the theorem provides valuable knowledge which can enrich the interpretation of such results , enabling approximate probabilistic inference .",
    "inferential questions of real interest , including ( a ) quantitative inference about amounts of radio - labelled tracer within specified regions of interest , or ( b ) tests for significance of apparent hot- or cold - spots , can be answered using approximate posteriors for _ linear combinations _ @xmath457 of parameters , and are particularly amenable to treatment .",
    "specifically , suppose that for any nonempty set of pixels , @xmath458 denotes the vector with elements @xmath459 for @xmath460 , 0  otherwise .",
    "then to deal with case ( a ) we can take @xmath461 to deliver @xmath457 as the average concentration of tracer in region @xmath462 , and for case ( b ) take @xmath463 for the difference in average concentration between regions @xmath464 and  @xmath465 .    to construct an approximation of the posterior distribution , we require estimates of unknown parameters .",
    "we use the marginal posterior modes estimate @xmath466 , @xmath467 , instead of @xmath18 , @xmath468 instead of @xmath469 , @xmath470 a more robust way to estimate @xmath471 would be to use @xmath472 for some small enough @xmath187 ; however , sensitivity to the choice of @xmath473 would need to be investigated .",
    "then , the approximate posterior of @xmath474 is @xmath475 \\bigl(2\\pi\\sigma^2 \\bigr)^{-p_0/2 } \\bigl[\\det(\\widehat{\\omega})\\bigr]^{1/2 } \\exp\\bigl \\ { - z_{\\widehat{s}_0}^t \\widehat{\\omega } z_{\\widehat{s}_0}/\\bigl(2 \\sigma^2\\bigr ) - z_{\\widehat{s}}^t \\hat{a}/ \\sigma^2\\bigr\\ } , \\ ] ] where @xmath476 ^ 2 a_{i , \\widehat{s}_0 } a_{i , \\widehat{s}_0}^t$ ] and @xmath477 .",
    "we briefly discuss the extent to which the approximation in theorem [ thpostapproxbvm ] holds true for data on the scale of a real spect study .",
    "a formal assessment of this would entail a major study beyond the scope of this paper , so we present selected results from analysis of two data sets based on a spect scan of the pelvis of a human subject .",
    "in the first experiment , the matrix @xmath15 was constructed according to the model in @xcite and @xcite , capturing geometry , attenuation , and radioactive decay for a setup consisting of 64 projections from a 2-dimensional slice through the patient , each projection yielding an array of 52 photon counts , on a spatial resolution of 0.57  cm .",
    "the data set was obtained from bristol royal infirmary ; the total photon count was 45,652 ; individual counts ranged from 0 to 85 , averaging  13.7 .",
    "reconstruction was performed on a @xmath478 square grid of 0.64  cm pixels , using the log cosh prior with hyperparameters fixed at @xmath479 and @xmath480 , obtained using a simple mcmc sampler .",
    "we employed 20,000 sweeps of a deterministic - raster - scan single - pixel random walk metropolis sampler on a square - root scale for @xmath21 , chosen to avoid extremes in acceptance rate at high- and low - spots in the image .",
    "figure  [ figbrimh1 ] shows selected aspects of this analysis ; see caption for details .",
    "our tentative conclusion is that the marginal posterior distributions for individual pixels  @xmath441 do appear to be approximately gaussian in high - spots and approximately exponential in low - spots , consistent with the theoretical limits presented in theorem  [ thpostapproxbvm ] .",
    "a second experiment was focussed on a more precise and quantitative assessment of the approximation to the posterior derived in the previous section .",
    "the setup is the same as in the first experiment , except at half the resolution , so that reconstruction was on a @xmath481 grid of 1.28  cm pixels .",
    "the corresponding @xmath15 matrix is now better - conditioned , and @xmath20 is only 576 , so that manipulation of the matrices is entirely tractable .",
    "synthetic data was generated using this @xmath15 and a `` ground truth '' obtained from an approximate map reconstruction from the same real data set as used above , yielding photon counts between 0 and 243 , totalling 138,310 .",
    "50,000 sweeps of the mcmc sampler were used , with prior settings @xmath482 , @xmath480 .     and the reciprocals of the mcmc - computed posterior means of @xmath21 , for pixels in @xmath483 , and also that between ( right panel ) the diagonal elements of @xmath484 and the posterior variances of @xmath21 for pixels in @xmath485 . ]",
    "figure  [ figapproxnpars ] displays the agreement between the elements of @xmath486 and the reciprocals of the mcmc - computed posterior means of @xmath21 , for pixels in @xmath483 , and also that between the diagonal elements of @xmath484 and the posterior variances of @xmath21 for pixels in  @xmath485 .     and one in @xmath487 ,",
    "so the approximation is gaussian / exponential ; in the right panel both pixels are from @xmath485 , so we have a bivariate gaussian .",
    "the outermost contour represents the 95% hpd credible region based on the approximation . ]",
    "figure  [ figpostcomp ] displays two bivariate posterior marginals , computed by mcmc , and the corresponding approximations . in the left panel ,",
    "one component is in @xmath483 and one in @xmath487 , so the approximation is gaussian / exponential ; on the right both components are from @xmath485 , so we have a bivariate gaussian .    we conclude that for this realistic / modest - scale spect reconstruction problem , the small - variance asymptotics of this paper provide a good approximation to the posterior , even for @xmath488 .",
    "when the posterior distribution concentrates on the boundary , we have shown that the classic bernstein  von mises theorem does not hold for all components .",
    "there are two different types of non - gaussian component : one , with the same parametric rate of convergence , is a truncated gaussian or a polynomially tilted modification of this if the prior density is not bounded away from zero and infinity on the boundary , and the second is a gamma , with a faster rate of convergence .",
    "an interesting property of the components of the second type is that they are not subject to a lower bound on efficiency , unlike the `` regular '' and the first - type boundary components . under some models with this property , at least part of the data",
    "is observed exactly , so perhaps it should not be an unexpected phenomenon ; see examples of poisson and binomial likelihoods in section  [ secbvmexamples ] . this property is quite remarkable : in principle , it allows the recovery of the unknown parameter on the boundary with an arbitrarily small precision ( particularly in the case there is no approximation error ) , by choosing an appropriate prior distribution , without losing asymptotic efficiency if the parameter is not on the boundary .",
    "this property is related to convergence in finitely - many steps of the projected gradient method for a sharp minimum for a noise - free function [ @xcite , theorem  1 , page  182 ; thanks to alexandre tsybakov for bringing this to our attention ] .",
    "a related but different problem involves a nonregular model where the density of the observations has one or more jumps at a point that depends on the unknown parameter , for example , @xmath489 $ ] , @xmath490 , independently .",
    "this type of problem has been extensively studied from both frequentist and bayesian perspectives [ @xcite ] . in the problem",
    "treated in this paper , the rate of convergence of the posterior distribution of the unknown nonregular parameter as a function of @xmath0 is the same as in this case where the unknown parameter controls the positions of jumps , faster than the standard parametric rate .",
    "however , there is a crucial difference : in the former case , the posterior distribution has a data - dependent random shift , whereas in the latter case there is no such shift .",
    "the nonasymptotic version of the main result shows that other parameters of the model can also affect convergence in practice , such as the smallest eigenvalues of the precision matrices in the @xmath491 part of the limit and the smallest parameter of the scale of the gamma distributions .",
    "it is easy to verify that theorem  [ thpostapproxbvm ] derived here applies also to misspecified models , with @xmath193 being replaced by the true distribution of @xmath492 and @xmath18 defined as the unique maximum of @xmath47 as in assumption  [ assm ] .",
    "this will be discussed elsewhere .",
    "an interesting direction for future work is to study both the behaviour of the posterior distribution , and the question of optimal prior specification , in a framework where the spatial resolution is infinitely refined , placing smoothness class constraints on @xmath58 .",
    "[ lemapproxnonrandom ] consider the function @xmath493 defined in section  [ seclik ] and assume that assumptions  [ assm ] ,  [ assb ] and  [ asss ] hold .",
    "then , on the event @xmath494 defined by ( [ eqdefeventa ] ) with some @xmath495 , for @xmath183 , @xmath496 where @xmath497 here @xmath498a vector of length @xmath146 , and @xmath499 is @xmath500 identity matrix .    applying the taylor expansion of @xmath106 as a function of @xmath263 at point  @xmath221 , and then expanding @xmath501 where @xmath502 and @xmath503 , as a function of @xmath216 at point @xmath504 , for some @xmath505 , we have @xmath506 applying the bounds defining events @xmath507 and @xmath508 to @xmath509 and@xmath510 , and using that @xmath511 is a vector with nonnegative components , we have @xmath512 + \\bigl(\\theta _ { s_0 } -\\theta^\\star_{s_0 } \\bigr)^t \\nabla_{s_0 } \\ell_y(\\theta ) \\\\ & & { } + \\bigl(\\theta_{s_0 } -\\theta^\\star_{s_0 } \\bigr)^t [ -\\omega_{00}+ \\delta _ { * 0 } i_{|s_0| } ] \\bigl(\\theta_{s_0 } -\\theta^\\star_{s_0 } \\bigr)/2,\\end{aligned}\\ ] ] and hence the first statement of the lemma . applying the inequalities on the events",
    "@xmath513 as lower bounds , we obtain the second statement of the lemma .",
    "proof of theorem  [ thpostapproxbvm ] denote @xmath514 where @xmath515 and @xmath516 ; the jacobian of this change of variables is @xmath517 .",
    "the image of @xmath232 under this transform is @xmath518 with @xmath519 and @xmath520 . under assumptions",
    "[ assb ] and  [ asss ] , the conditions of lemma  [ lemlimitx ] hold , which implies that if @xmath521 and @xmath522 , @xmath523 \\times[0 , r_1]^{p_1}$ ] where @xmath524 , and the set @xmath525 becomes @xmath526 as @xmath70 .",
    "the triangle inequality for the total variation norm gives @xmath527 where the balls @xmath525 are defined above .",
    "here @xmath528 is a probability measure @xmath390 truncated to @xmath525 and normalised to be a probability measure .",
    "if the measure @xmath529 is absolutely continuous with respect to measure @xmath530 , with density @xmath118 , the total variation norm can be written as @xmath531 where @xmath532 [ @xcite ] .",
    "this can be used in each of the summands in the upper bound ( [ eqtriangletv ] ) .",
    "we start with the first term in ( [ eqtriangletv ] ) . by lemma  [ lemapproxnonrandom ] , on the event @xmath545 defined by  ( [ eqdefeventa ] ) , for any measurable @xmath546 , with @xmath547",
    ", we have @xmath548/\\sigma^2 \\bigr\\ } \\pi(d\\theta ) \\\\ & & \\qquad \\geq j_\\sigma c_{\\pi } ( 1-\\delta_{\\pi } ) \\\\ & & \\quad\\qquad{}\\times \\int _ { \\mathcal{b}_v } \\prod_{j\\in t_0^{\\star}\\cup t_1 } v_{j}^{\\alpha_j-1 } \\exp \\bigl\\{v_0^t \\nabla_{s_0 } \\ell_y\\bigl(\\theta ^\\star\\bigr)/ \\sigma- \\bigl\\|\\widetilde{\\omega}_{00}^{1/2}v_{0 } \\bigr\\|^2/2 - \\tilde{a}^t v_1 \\bigr\\ } \\,dv \\\\ & & \\qquad = j_{\\sigma } c_{\\pi } ( 1 - \\delta_{\\pi } ) \\mu\\bigl ( \\mathcal{b}_v ; \\tilde{a},\\alpha , \\nabla_{s_0 } \\ell_y\\bigl(\\theta^\\star\\bigr)/\\sigma , \\widetilde { \\omega}_{00}\\bigr),\\end{aligned}\\ ] ] where @xmath549 , and the measure @xmath550 is defined by ( [ eqmeasuremu ] ) .",
    "similarly , using lemma  [ lemapproxnonrandom ] , we obtain an upper bound on the event  @xmath494 , @xmath551/ \\sigma^2 \\bigr\\ } \\pi(d\\theta ) \\\\ & & \\qquad \\leq j_\\sigma c_{\\pi } ( 1+\\delta_{\\pi } ) \\\\ & & \\quad\\qquad { } \\times\\int_{\\mathcal{b}_v } \\prod_{j \\in",
    "t_0^\\star\\cup t_1 } v_{j}^{\\alpha_{j}-1 } \\exp \\bigl\\{v_0^t \\nabla_{s_0 } \\ell_y\\bigl(\\theta ^\\star\\bigr)/ \\sigma- \\bigl\\|{\\overline}{\\omega}_{00}^{1/2}v_{0 } \\bigr\\|^2/2 - \\bar{a}^t v_1 \\bigr\\ } \\,dv \\\\ & & \\qquad = j_\\sigma c_{\\pi } ( 1+\\delta_{\\pi } ) \\mu\\bigl ( \\mathcal{b}_v ; \\bar{a } , \\alpha , \\nabla_{s_0 } \\ell_y\\bigl(\\theta^\\star\\bigr)/\\sigma,{\\overline } { \\omega}_{00}\\bigr).\\end{aligned}\\ ] ] to simplify the notation , denote @xmath552 and @xmath553 the measure @xmath554 is finite since @xmath555 is finite with high probability due to assumption  [ asss](4 ) , and all its other parameters are positive or positive definite .",
    "the measure @xmath556 is finite if @xmath557 and @xmath558 .",
    "these conditions hold if @xmath559 are small enough which is possible due to assumption  [ asss ] .    for @xmath560 for some @xmath561 and @xmath562 , we have @xmath563 \\int_{\\mathcal{v}_0 } \\prod _ { j\\in t_0^\\star } v_{0 , j}^{\\alpha_{0,j}-1 } e^ { - v_0^t \\sigma v_0 /2",
    "+ v_0^t b } \\,d v_0 ,",
    "\\\\ \\frac{\\mu ( \\mathcal{b}_v ; a_1 , \\alpha , b , \\sigma ) } { \\mu ( \\mathcal{v}^\\star ; a_1 , \\alpha , b , \\sigma ) } & = & \\mathcal { ptn}_{p_0 } \\bigl(\\mathcal{b}_1 ; \\sigma^{-1 } b , \\sigma^{-1 } , p_0^\\star,\\alpha_0\\bigr ) \\prod _ { j=1}^{p_1 } \\gamma\\bigl((0,r_1 ) ; \\alpha_{1,j } , a_{1,j}\\bigr),\\end{aligned}\\ ] ] where the probability measure @xmath564 is defined by ( [ eqmodifgauss ] ) , and  @xmath565 is the probability measure associated with distribution @xmath566 .    hence , the posterior density of @xmath567 normalised by the posterior measure of @xmath525 , is bounded on @xmath568 by @xmath569 therefore , the first term in ( [ eqtriangletv ] ) is bounded on @xmath570 by @xmath571_+ \\frac{\\mu^\\star ( dv ) } { \\mu^\\star(b_r ) } \\\\ & & \\qquad \\leq 2 \\int_{b_r } \\biggl [ \\frac { \\bar\\mu ( dv ) } { \\tilde\\mu ( b_r ) } \\frac{\\mu^\\star(b_r ) } { \\mu^\\star(dv)}\\frac{(1+\\delta_{\\pi } ) } { ( 1- \\delta_{\\pi } ) } -1 \\biggr]_+ \\frac { \\mu^\\star(dv ) } { \\mu ^\\star(b_r)}.\\end{aligned}\\ ] ] define @xmath572 . then @xmath573 and @xmath574 which implies @xmath575 & & \\hspace*{259pt } { } + v_{0}^t \\omega_{00 } a_0 \\bigr\\ } \\,dv \\biggr).\\end{aligned}\\ ] ] to show that this expression is greater than 1 , it is sufficient to show that for any @xmath576 , the following expression is positive : @xmath577 \\,dw > 0\\end{aligned}\\ ] ] which is the case . thus , on @xmath570 , @xmath578 and hence @xmath579 \\frac { \\mu^\\star(dv ) } { \\mu^\\star(b_r ) } \\\\ & & \\qquad = 2 \\biggl [ \\frac { \\bar\\mu(b_r ) } { \\tilde\\mu(b_r)}\\frac { ( 1+\\delta_{\\pi})}{(1- \\delta_{\\pi } ) } -1 \\biggr ] \\\\ & & \\qquad = 2 \\frac { \\bar\\mu(b_r ) -\\tilde\\mu(b_r ) } { \\tilde\\mu ( b_r)}\\frac{(1+\\delta_{\\pi})}{(1- \\delta_{\\pi } ) } + 2 \\biggl [ \\frac { ( 1+\\delta_{\\pi})}{(1- \\delta_{\\pi } ) } -1 \\biggr].\\end{aligned}\\ ] ] the difference of measures @xmath580 is bounded by @xmath581 \\,dv \\\\ & & \\qquad \\leq \\int_{b_r } \\prod_{i \\in t_0^\\star\\cup t_1 } v_{i}^{\\alpha _ i-1 } \\bigl[\\delta_{*0 } \\|v_0 \\|^2/2 + \\delta_{*1 } 1_{p_1}^t v_1\\bigr ] e^ { - v_{0}^t{\\overline}\\omega_{00 } v_{0 } /2",
    "+ v_0^t \\omega_{00 } a_0 - \\bar{a } v_1 } \\,dv \\\\ & & \\qquad \\leq \\biggl[\\delta_{*0 } e_{\\phi } + \\delta_{*1 } \\sum_{j=1}^{p_1 } ( \\alpha_{1,j}/ \\bar{a}_j ) \\biggr ] \\bar{\\mu}\\bigl(\\mathcal{v}^\\star\\bigr)\\end{aligned}\\ ] ] due to the inequality @xmath582 for @xmath169 , where @xmath583 is defined by @xmath584 which is finite",
    ". therefore , @xmath585 + \\frac{4\\delta_{\\pi}}{1- \\delta_{\\pi}},\\end{aligned}\\ ] ] which goes to zero since @xmath586 and @xmath587 as @xmath70 . for small @xmath38 and hence large @xmath588 and @xmath464 , the ratios @xmath589 and @xmath590 are close to 1 .",
    "therefore , @xmath591 as @xmath70",
    ".        combining these bounds , we have that on @xmath570 , @xmath600^{-1 } \\delta_0(\\delta ) \\\\ & & \\quad\\qquad{}+ 2\\frac{\\bar{\\mu}(\\mathcal{v}^\\star)}{\\tilde\\mu(b_r ) } \\frac{(1+\\delta_{\\pi})}{(1- \\delta_{\\pi } ) } \\biggl[\\delta_{*0 } e_{\\phi } + \\delta_{*1 } \\sum_{j=1}^{p_1 } ( \\alpha_{1,j}/\\bar{a}_j ) \\biggr ] + \\frac{4 \\delta_{\\pi } } { ( 1- \\delta_{\\pi } ) } \\to0 \\ ] ] and as @xmath70 due to assumption  [ asss ] , which gives the statement of the theorem .",
    "proof of proposition  [ propbvmnonasympt ] in the proof of theorem  [ thpostapproxbvm ] , we derived the following upper bound on event @xmath601 : @xmath602 where @xmath603^{-1}$ ] , @xmath604 , @xmath605 with @xmath606 defined by ( [ eqdefephi ] ) , @xmath607 and with @xmath608 , @xmath609^{\\alpha_{1,j } } \\frac{(1+\\delta_{\\pi})}{(1- \\delta_{\\pi})},\\ ] ] where @xmath610 for a measure @xmath390 , @xmath611 . if @xmath612 , @xmath613^{1/2}}{\\mathcal { tn}(b_{r,0 } ; \\widetilde\\omega_{00}^{-1}\\omega_{00}a_0 , \\widetilde \\omega_{00}^{-1})}.\\end{aligned}\\ ] ] we bound the term @xmath614 by @xmath615 using the inequality @xmath616 for @xmath617 .",
    "we can also use @xmath618 \\\\ & = & p_1 \\max_{j}\\gamma \\bigl(\\bigl ( \\delta_1/\\sigma^2,\\infty\\bigr ) ; \\alpha_{1,j } , a_{1,j } \\bigr),\\end{aligned}\\ ] ] and , changing to polar coordinates and denoting @xmath619 and @xmath620 for @xmath621 , we have @xmath622 under the assumption that @xmath623 where @xmath624^{p_{\\alpha0}/2}\\pi ^{(p_0-p^\\star_0)/2}\\prod_{i\\in t_0^\\star } \\gamma(\\alpha_{0,i}/2).\\ ] ]        proof of lemma  [ lemlimitx ] due to assumption  [ assb ] and the fact that @xmath625 , the set @xmath626 contains @xmath627 where @xmath628 .",
    "these sets monotonically increase to @xmath629 as @xmath630 due to the assumption @xmath631 and @xmath632 ; this implies the statement of the lemma .",
    "proof of lemma  [ lemassumptionl ] under the assumptions of the lemma , for small enough  @xmath38 , with @xmath633 , we have that @xmath634 } + \\frac{p_1\\sigma^2}{c_{\\delta1 } } e^{-c_{\\delta1 } \\delta_1/\\sigma^2 } \\\\ & & \\quad\\qquad{}+ \\sum_{j\\in s_0\\setminus s_0^\\star } \\bigl[\\sigma^{\\bolds\\alpha _ j-1}i(\\bolds",
    "\\alpha_j<1 ) + { \\theta^\\star_j}^{\\bolds\\alpha _ j-1}i ( \\bolds\\alpha _ j\\geq1 ) \\bigr ] \\frac{\\sigma^2}{c_{\\delta0 } } e^{-c_{\\delta 0}\\tilde{\\delta}_0/ \\sigma^2 } \\\\ & & \\qquad \\leq c \\bigl [ \\sigma^{\\min_{j}(\\bolds\\alpha_j ) } + \\sigma\\bigr ] e^{-c_{\\delta0 } \\delta_0/[\\sqrt{p_0}\\sigma^2 ] } + p_1 e^{-c_{\\delta1 } \\delta _ 1/\\sigma^2 } \\sigma^2/c_{\\delta1}\\end{aligned}\\ ] ] for a constant @xmath635 .",
    "this implies that , with @xmath636 , @xmath637 e^{-c_{\\delta0 } \\delta_0/[\\sqrt{p_0}\\sigma^2 ] } + \\frac { p_1 \\sigma^2}{c_{\\delta1 } } e^{-c_{\\delta1 } \\delta_1/\\sigma^2 } \\biggr ] \\to0\\ ] ] as @xmath70 under the assumptions of the lemma ."
  ],
  "abstract_text": [
    "<S> we study the asymptotic behaviour of the posterior distribution in a broad class of statistical models where the `` true '' solution occurs on the boundary of the parameter space . </S>",
    "<S> we show that in this case bayesian inference is consistent , and that the posterior distribution has not only gaussian components as in the case of regular models ( the bernstein  </S>",
    "<S> von mises theorem ) but also has gamma distribution components whose form depends on the behaviour of the prior distribution near the boundary and have a faster rate of convergence . </S>",
    "<S> we also demonstrate a remarkable property of bayesian inference , that for some models , there appears to be no bound on efficiency of estimating the unknown parameter if it is on the boundary of the parameter space . </S>",
    "<S> we illustrate the results on a problem from emission tomography . </S>"
  ]
}