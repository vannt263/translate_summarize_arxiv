{
  "article_text": [
    "restoration is one of the most fundamental issues in imaging science and plays an important role in many mid - level and high - level image processing applications . on account of the imperfection of an imaging system ,",
    "a recorded image may be inevitably degraded during the process of image capture , transmission , and storage .",
    "the image formation process is commonly modeled as the following linear system @xmath1 where the vectors @xmath2 and @xmath3 represent the @xmath4 true scene and observation whose column vectors are the successive @xmath5-vectors of @xmath2 and @xmath3 , respectively .",
    "@xmath6 is gaussian white noise with zero mean , and @xmath7 is a blurring matrix constructed from the discrete point spread function , together with the given boundary conditions .",
    "it is well known that image restoration belongs to a general class of problems which are rigorously classified as ill - posed problems @xcite . to tackle the ill - posed nature of the problem , regularization techniques are usually considered to obtain a stable and accurate solution . in other words , we seek to approximately recover @xmath2 by minimizing the following variational problem : @xmath8 where @xmath9 denotes the euclidean norm ,",
    "@xmath10 is conventionally called a regularization functional , and @xmath11 is referred to as a regularization parameter which controls the balance between fidelity and regularization terms in ( [ eq2 ] ) .    how to choose a good functional @xmath10 is an active area of research in imaging science . in the early 1960s ,",
    "d. l. phillips @xcite and a. n. tikhonov @xcite proposed the definition of @xmath10 as an @xmath0-type norm ( often called tikhonov regularization in the literature ) , that is , @xmath12 with @xmath13 an identity operator or difference operator .",
    "the functional @xmath10 of this type has the advantage of simple calculations , however , it produces a smoothing effect on the restored image , i.e. , it overly smoothes edges which are important features in human perception .",
    "therefore , it is not a good choice since natural images have many edges . to overcome this shortcoming , rudin , osher and fatemi @xcite proposed to replace the @xmath0-type norm with the total variation ( tv ) seminorm , that is , they set @xmath14 . then the corresponding minimization problem is @xmath15 where @xmath16 and the discrete gradient operator @xmath17 is defined by @xmath18 with @xmath19 and @xmath20 for @xmath21 and @xmath22 refers to the @xmath23th entry of the vector @xmath2 ( it is the @xmath24th pixel location of the @xmath4 image , and this notation is valid throughout the paper unless otherwise specified ) .    the problem ( [ eq3 ] ) is commonly referred to as the rof model .",
    "the tv is isotropic if the norm @xmath25 is the euclidean norm and anisotropic if 1-norm is defined . in this work ,",
    "we only consider the isotropic case since the isotropic tv usually behaves better than the anisotropic version .    in the literature , many algorithms have been proposed for solving ( [ eq3 ] ) . in case @xmath7 is the identity matrix , then the problem ( [ eq3 ] ) is referred to as the denoising problem . in the pioneering work @xcite , the authors proposed to employ a time marching scheme to solve the associated euler - lagrange equation of ( [ eq3 ] ) .",
    "however , their method is very slow due to cfl stability constraints @xcite .",
    "later , vogel and oman @xcite proposed a lagged diffusivity fixed point method to solve the same euler - lagrange equation of ( [ eq3 ] ) . in @xcite ,",
    "chan and mulet proved this method had a global convergent property and was asymptotically faster than the explicit time marching scheme .",
    "chambolle @xcite studied a dual formulation of the tv denoising problem and proposed a semi - implicit gradient descent algorithm to solve the resulting constrained optimization problem .",
    "he also proved his algorithm is globally convergent with a suitable step size . in @xcite , goldstein and osher proposed the novel split bregman iterative algorithm to deal with the artificial constraints , their method has several advantages such as fast convergence rate and stability , etc .",
    "in @xcite , chan , golub and mulet considered to apply newton s method to solve the nonlinear primal - dual system of the system ( [ eq3 ] ) for image deblurring problem .",
    "recently , wang _",
    "@xcite proposed a fast total variation deconvolution ( ftvd ) method which used splitting technique and constructs an iterative procedure of alternately solving a pair of easy subproblems associated with an increasing sequence of penalty parameter values . almost at the same time",
    ", huang , ng and wen @xcite proposed a fast total variation ( fast - tv ) minimization method by introducing an auxiliary variable to replace the true image @xmath2 .",
    "their methods belong to penalty methods from the perspective of optimization . in @xcite ,",
    "beck and teboulle studied a fast iterative shrinkage - thresholding algorithm ( fista ) which is a non - smooth variant of nesterov s optimal gradient - based algorithm for smooth convex problems @xcite .",
    "later , afonso _ et al . _",
    "@xcite proposed an augmented lagrangian shrinkage algorithm ( salsa ) which is an instance of the so - called alternating direction method of multipliers ( admm ) .",
    "more recently , chan , tao and yuan @xcite proposed an efficient and effective method by imposing box constraint on the rof model ( [ eq3 ] ) .",
    "their numerical experiments showed that their method could obtain much more accurate solutions and was superior to other state - of - the - art methods .",
    "the methods of solving rof model ( [ eq3 ] ) mentioned above are just a few examples , we refer the interested readers to @xcite and the references therein for further details .",
    "although total variation regularization has been proven to be extremely useful in a variety of applications , it is well known that tv yields staircase artifacts @xcite .",
    "therefore , the approaches involving the classical tv regularization often develop false edges that do not exist in the true image since they tend to transform smooth regions ( ramps ) into piecewise constant regions ( stairs ) .",
    "to avoid these drawbacks , nonlocal methods were considered in @xcite .",
    "besides , in the literature , there is a growing interest for replacing the tv regularizer by the high - order total variation ( htv ) regularizer , which can comprise more than merely piecewise constant regions .",
    "the majority of the high - order norms involve second - order differential operators because piecewise - vanishing second - order derivatives lead to piecewise - linear solutions that better fit smooth intensity changes @xcite , namely , we choose the regularization functional @xmath26",
    ". then the minimization problem ( [ eq2 ] ) is treated as following htv - based problem : @xmath27 where @xmath28 with @xmath29 .",
    "note that @xmath30 , @xmath31 denotes the second order difference of @xmath2 at pixel @xmath24",
    ". the minimization problem ( [ eq4 ] ) is usually called llt model which was first proposed by lysaker , lundervold , and tai @xcite .    in @xcite , the authors applied gradient descent algorithm to solve the corresponding fourth - order partial differential equation . later in @xcite ,",
    "chen , song and tai employed the dual algorithm of chambolle for solving ( [ eq4 ] ) and they verified that their method was faster than the original gradient descent algorithm .",
    "a similar dual method was also proposed by steidl @xcite but from the linear algebra point of view by consequently using matrix - vector notation .",
    "recently , wu and tai considered to employ the alternating direction method of multipliers ( admm ) to tackle the problem ( [ eq3 ] ) .",
    "also , some other high order models have been proposed in the literature , we refer the interested reader to see @xcite and references therein for details .",
    "note that there exist other different types of regularization functionals , such as the markov random field ( mrf ) regularization @xcite , the mumford - shah regularization @xcite , and frame - based @xmath32 regularization @xcite . in this paper , however , we consider to set @xmath10 in ( [ eq2 ] ) to be the overlapping group sparsity total variation ( ogs - tv ) functional which we have introduced in @xcite for the one - dimension signal denoising problem .",
    "the numerical experiments there showed that the ogs - tv regularizer can alleviate staircase effect effectively .",
    "then it is natural to extend this idea to the 2-dimensional case such as image restoration considered in this work .",
    "the rest of the paper is organized as follows . in the next section",
    ", we will briefly introduce the definition of the overlapping group sparsity total variation functional for image restoration .",
    "we will also review the majorization - minimization ( mm ) methods and admm , which are the essential tools for us to propose our efficient method . in section 3 ,",
    "we derive an efficient algorithm for solving the considered minimization problem .",
    "consequently , in section 4 , we give a number of numerical experiments of image denoising and image deblurring to demonstrate the effectiveness of the proposed method , as compared to some other state - of - the - art methods .",
    "finally , discussions and conclusions are made in section 5 .",
    "in @xcite , we have denoted a @xmath33-point group of the vector @xmath34 by @xmath35 \\in \\mathbb{r}^k\\ ] ] note that @xmath36 can be seen as a block of @xmath33 contiguous samples of @xmath37 staring at index @xmath38 . with the notation ( [ eq5 ] ) ,",
    "a group sparsity regularizer @xcite is defined as @xmath39 the group size is denoted by @xmath33 . for the two - dimensional case , we define a @xmath40-point group of the image @xmath41 ( note that the vector @xmath2 is obtained by stacking the @xmath42 columns of the @xmath4 matrix ) @xmath43\\\\ & \\in \\mathbb{r}^{k\\times k}\\\\   \\end{split}\\ ] ] with @xmath44 , m_2 = [ \\frac{k}{2}]$ ] , where @xmath45 $ ] denotes the greatest integer not greater than @xmath46 .",
    "let @xmath47 be a vector which is obtained by stacking the @xmath33 columns of the matrix @xmath48 , i.e. , @xmath49 .",
    "then the overlapping group sparsity functional of a two - dimensional array can be defined by @xmath50 the group size of functional ( [ eq8 ] ) is denoted by @xmath40 .",
    "consequently , we set the regularization functional @xmath10 in ( [ eq2 ] ) to be of the form @xmath51    in ( [ eq9 ] ) , if @xmath52 , then @xmath53 is the commonly used anisotropic tv functional",
    ". then we refer to the regularizer @xmath10 in ( [ eq9 ] ) as the overlapping group sparsity anisotropic total variation functional ( ogs - atv ) .",
    "the admm technique was initially proposed to solve the following constrained separable convex optimization problem : @xmath54 where @xmath55 are closed convex functions , @xmath56 are linear transforms , @xmath57 are nonempty closed convex sets , and @xmath58 is a given vector .    using a lagrangian multiplier @xmath59 to the linear constraint in ( [ cop ] ) , the augmented lagrangian function @xcite for problem ( [ cop ] ) is @xmath60 where @xmath61 is the lagrange multiplier and @xmath62 is a penalty parameter , which controls the linear constraint .",
    "the idea of the admm is to find a saddle point @xmath63 of @xmath64 .",
    "usually , the admm consists in minimizing @xmath65 alternatively , subject to @xmath66 , such as minimizing @xmath64 with respect to @xmath67 , keeping @xmath68 and @xmath69 fixed .",
    "notice that the term @xmath70 in the definition of the augmented lagrangian functional @xmath65 in ( [ alf ] ) can be written as a single quadratic term after simple mathematical operations , leading to the following alternative form for a simple but powerful algorithm : the admm +   +    _ _    l + _ * initialization * _ : starting point @xmath71 , @xmath72 , + _ * iteration * _ : + @xmath73 + @xmath74 + @xmath75 + @xmath76 + * until a stopping criterion is satisfied . *",
    "+     +   + an important advantage of the admm is to make full use of the separable structure of the objective function @xmath77 .",
    "note that the admm is a splitting version of the augmented lagrangian method where the augmented lagrangian method s subproblem is decomposed into two subproblems in the gauss - seidel fashion at each iteration , and thus the variables @xmath67 and @xmath68 can be solved separably in alternating order .",
    "the convergence of the alternating direction method can be found in @xcite .",
    "moreover , we have @xmath78 hence , @xmath79 and @xmath80 . especially , if matrices @xmath81 and @xmath82 have full column rank , it leads to @xmath83 and @xmath84 .",
    "[ [ mm ] ] mm ~~    the mm method substitutes a simple optimization problem for a difficult optimization problem .",
    "that is to say , instead of minimizing a difficult cost functional @xmath85 directly , the mm approach solves a sequence of optimization problems , @xmath86 .",
    "the idea is that each @xmath87 is easier to solve that @xmath85 . of course , iteration is the price we pay for simplifying the original problem .",
    "generally , a mm iterative algorithm for minimizing @xmath85 has the form @xmath88 where @xmath89 , for any @xmath90 , and @xmath91 , i.e. , each functional @xmath92 is a majorizor of @xmath85 .",
    "when @xmath85 is convex , then under mild conditions , the sequence @xmath93 produced by ( [ eq13 ] ) converges to the minimizer of @xmath85 .",
    "a good majorizing functional @xmath94 usually satisfies the following characteristics @xcite : ( a ) avoiding large matrix inversions , ( b ) linearizing an optimization problem , ( c ) separating the parameters of an optimization problem , ( d ) dealing with equality and inequality constraints gracefully , or ( e ) turning a nondifferentiable problem into a smooth problem .",
    "more details about the mm procedure can be found in @xcite and the references therein .",
    "before we proceed with the discussion of the proposed method , we consider a minimization problem of the form @xmath95 where @xmath96 is a positive parameter and the functional @xmath97 is given by ( [ eq8 ] ) . in @xcite",
    ", we analysed this problem elaborately .",
    "however , for the sake of completeness , we briefly introduce the solving method here . to derive an effective and efficient algorithm with the mm approach for solving the problem ( [ eq14 ] ) , we need a majorizor of @xmath98 , and fortunately , we only need to find a majorizor of @xmath99 because of the simple quadratic term of the first term in ( [ eq14 ] ) . to this end , note that @xmath100 for all @xmath101 and @xmath102 with equality when @xmath103 . substituting each group of @xmath99 into ( [ eq15 ] ) and summing them",
    ", we get a majorizor of @xmath99 @xmath104 \\end{split}\\ ] ] with @xmath105 provided @xmath106 for all @xmath107 . with a simple calculation , @xmath108 can be rewritten as @xmath109 where @xmath110 is a constant that does not depend on @xmath101 , and @xmath111 is a diagonal matrix with each diagonal component @xmath112_{l , l } = \\sqrt{\\sum_{i , j =- m_1}^{m_2 } \\left[\\sum_{k_1,k_2=-m_1}^{m_2}\\left|u_{r - i+k_1,t - j+k_2}\\right|^2 \\right]^{-\\frac{1}{2}}}\\ ] ] with @xmath113 .",
    "the entries of @xmath114 can be easily computed using matlab built - in function ` conv2 ` .",
    "then a majorizor of @xmath98 can be easily given by @xmath115 with @xmath116 for all @xmath117 , and @xmath118 .",
    "to minimize @xmath98 , the mm aims to iteratively solve @xmath119 which has the solution @xmath120 where @xmath121 is a identity matrix with the same size of @xmath122 .",
    "note that the inversion of the matrix @xmath123 can be computed very efficiently via simple component - wise calculation .",
    "to summerize , we obtain the algorithm 2 for solving the problem ( [ eq14 ] ) .",
    "+   +    _ _    l +   + _ * initialization * _ : + starting point @xmath124 , @xmath125 , @xmath33 , maximum inner + iterations @xmath126 .",
    "+ _ * iteration * _ : + .",
    "@xmath127_{l , l}= \\sqrt{\\sum\\limits_{i , j =- m_1}^{m_2 } \\left[\\sum\\limits_{k_1,k_2=-m_1}^{m_2}\\left|u_{r - i+k_1,t - j+k_2}\\right|^2 \\right]^{-\\frac{1}{2}}}$ ] + .",
    "@xmath128 + .",
    "@xmath129 ; + * until * @xmath130 or @xmath131 .",
    "+     +   +",
    "with the definion of ( [ eq9 ] ) , in this section , we address the minimization problem of the form @xmath132 we refer to this model as @xmath133-ogs - atv",
    ". note that for any true digital image , its pixel can attain only a fine number of values .",
    "hence , it is natural to require all pixel values of the restored image to lie in a certain interval @xmath134 $ ] .",
    "such a constraint is called the box constraint @xcite .",
    "for instance , the images considered in this work are all 8-bit images , we would like to restore them in a dynamic range @xmath135 $ ] . for convenience ,",
    "we define an orthogonal projection operator @xmath136 on the set @xmath137 $ ] ,    @xmath138\\\\           & a_u ,     & f_{i , j}>a_u\\quad   \\ \\ \\\\           \\end{aligned } \\right.\\ ] ]    by introducing new auxiliary variables @xmath139 , we change the minimization problem ( [ eq23 ] ) together with a constraint ( [ eq24 ] ) to the equivalent constrained minimization problem    @xmath140    thus , problem ( [ eq25 ] ) satisfies",
    "the framework in ( [ cop ] ) with the following specifications : + 1 ) @xmath141 ; + 2 ) @xmath142 ; + 3 ) @xmath143    according to algorithm 1 , we get the iterative scheme @xmath144    @xmath145    @xmath146    we now investigate these subproblems one by one .",
    "the minimization problem ( [ eq26 ] ) with respect to @xmath2 is a least square problem which is equivalent to the corresponding normal equation    @xmath147    since the parameters @xmath62 is positive , the coefficient matrix in ( [ eq29 ] ) is always invertible even when @xmath148 is singular .",
    "note that @xmath149 , and @xmath150 block circulant with circulant blocks ( bccb ) when the periodic boundary conditions are used .",
    "we know that the computations with bccb matrices can be very efficiently performed by using fast fourier transforms ( ffts ) .    clearly ,",
    "the minimization ( [ eq27 ] ) with respect to @xmath139 are decoupled , i.e. , they can be solved separately .",
    "considering @xmath151 , we have @xmath152 + the @xmath153subproblem corresponds to the following optimization problem @xmath154 for simplicity , we denote @xmath155 . it can be observed that problems ( [ eq30 ] ) and ( [ eq31 ] ) match the framework of the problem ( [ eq14 ] ) , thus the solutions of ( [ eq30 ] ) and ( [ eq31 ] ) can be obtained by using algorithm 3 , respectively .     to @xmath156.,scaledwidth=45.0% ]    besides , the @xmath157subproblem can be solved by the simple projection @xmath136 onto the box @xmath158\\ ] ]    based on the discussions above , we get the resulting algorithm for solving ( [ eq23 ] ) shown as algorithm 3 .",
    "+   +    _ _    l +   + _ * initialization * _ : + starting point @xmath159 , @xmath160 , @xmath161 , + @xmath162=0 , @xmath163 maximum inner iterations @xmath164 .",
    "+ _ * iteration * _ : + .  compute @xmath165 according to @xmath166 + .",
    "compute @xmath167 according to @xmath168 + .",
    "compute @xmath169 according to @xmath170 + .  compute @xmath171",
    "according to @xmath172 + .",
    "update @xmath173 according to @xmath174 + .",
    "k = k+1 ; + * until a stopping criterion is satisfied . * +     +   +   + obviously , ogsatv - adm4 is an instance of admm if the minimizations in steps 1@xmath1754 are solved exactly ( i.e. , the subproblems have closed - form solutions ) , the convergence of ogsatv - adm4 is guaranteed .",
    "note that , although steps ( 2 ) and ( 3 ) in algorithm 3 can not be solved exactly , the convergence of algorithm 3 is not compromised as long as the sequence of errors of successive solutions in ( 2 ) and ( 3 ) are absolutely summable , respectively .",
    "the corresponding theoretical proof is given elaborately in @xcite and we will also verify this property in our numerical experiments .",
    "in this section , we present some numerical results to illustrate the performance of the proposed method .",
    "the test images are shown in fig .",
    "1 with sizes from @xmath176 to @xmath177 .",
    "all experiments are carried out on windows 7 32-bit and matlab v7.10 running on a desktop equipped with an intel core i3 - 2130 cpu 3.4 ghz and 4 gb of ram .",
    "+    .restoration results for different numbers ( @xmath178 ) of mm iterations in the ogsatv - adm4 [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     [ tab : addlabel ]    we make use of 9 test images for comparisons .",
    "we simulate the noisy images with two different noise levels .",
    "all of these images were corrupted by the zero - mean additive gaussian noise with the standard deviation @xmath179 and @xmath180 , respectively .    in fig .",
    "3 , we show a noisy ( @xmath181 ) vase image and the corresponding denoised version using proposed ogsatv - adm4 . visually , we see that ogsatv - adm4 works very well for image denoising .",
    "the evolutions of relerrs vs iterations and cpu time using four different methods are plotted in fig .",
    "4 . from this figure",
    ", we observe that split bregman method converges extremely fast and consumes the least cpu time , and chambolle s method is the slowest one no matter in terms of iterations or consuming time . however , our method ogsatv - adm4 reach the lowest relerr value at the convergence point in reasonable time .",
    "moreover , the denoising comparison among four different methods is further illustrated in fig .",
    "5 , where we show fragments of two true images , noisy images ( @xmath179 ) and the corresponding denoised ones . as can be seen from the fig . 5 ,",
    "denoised images obtained by using tv methods ( the split bregman method and chambolle s dual method ) have apparent staircase effect ( such as the parts pointed by the left below arrow and upper right arrow of boats image , and the nose and the lower jaw of man image ) , while the llt - alm method and the ogsatv - adm4 overcome this drawback to a great extent .",
    "however , there also exists shortcoming caused by llt - alm , i.e. , some parts of the restored images are overly smoothed .",
    "the parts pointed by the upper left arrow and lower right arrow of boats image , and the eyelid and lips ( the parts pointed by left two arrows ) of man image show this effect .",
    "note that our method can avoid this drawback effectively .",
    "+    the output results in terms of psnr , relerr , cpu time , and iterations of four methods are given in table ii . from the table , we observe that the split bregman method and chambolle s dual method achieve similar psnr results , while the llt - alm method can sometimes performs better than both of them in terms of psnr .",
    "overall , our method ogsatv - adm4 can reach the highest psnr results among the four methods .",
    "we should also note that the split bregman usually costs least cpu time .",
    "+   + @xmath182 : _ image deblurring _ + in case @xmath7 is a blurring matrix , then the problem we aim to solve is deblurring . for this example",
    ", we compare our method with the method fasttv proposed by huang , ng , and wen @xcite , the admm method for solving constrained tv - l2 model ( cadmtvl2 ) by chan , tao , and yuan @xcite and the method llt - alm @xcite .",
    "note that the test images used in cadmtvl2 @xcite are all scaled to the interval @xmath183 $ ] , so the box constraint in their constrained models is simply @xmath183 $ ] .",
    "+    in this example , we test two different types of blurring kernels : gaussian blur ( g ) and average blur ( a ) , which can be generated by the matlab built - in function ` fspecial ` , more specifically , ` fspecial('gaussian',[7 7],2 ) ` and ` fspecial('average',9 ) ` . for each blurring case ,",
    "the blurred images are further corrupted by zero mean gaussian noise with bsnr = 40 .",
    "two image estimates obtained by ogsatv - adm4 are shown in fig .",
    "6 , with the blurred images also shown for illustration .",
    "it is clear from fig . 6",
    "that the proposed method can restore blurred images effectively and in high quality .",
    "7 shows the evolution of the psnr over computing time and iterations for four different methods with respect to restoration of the  lena \" image with average blur .",
    "it is obvious that our method reaches the highest psnr with least iterations .",
    "it is obvious that cadmtvl2 needs fewer computing time to achieve the convergency point .",
    "we also observe that the penalty method fasttv needs the maximum computing time and iterations comparing with other three methods .",
    "table iii shows the output results in terms of psnr , relerr , cpu time and iterations of four methods . from the table",
    ", we see that the quality in terms of psnr of the restored images by fasttv and cadmtvl2 is almost the same .",
    "however , cadmtvl2 consumes much less time and needs much fewer iterations than fasttv .",
    "overall , the proposed method reaches the highest psnr compared with other three state - of - the - art methods , and needs less computing time and iterations than fasttv and llt - alm ( except in the case of the  jellyfish \" image , the computing time and iterations by using llt - alm are less than our method ) .",
    "quantitatively , however , our method can obtain @xmath184 db improvement in psnr on average .",
    "+    moreover , in order to illustrate the superior capability of our method for image deblurring .",
    "we show the fragments of restored images  w.station \" and  lena \" in fig .",
    "8 . in the top row of fig .",
    "8 , we observe that the fences of the w.station image estimates obtained by fasttv and cadmtvl2 are very blocky ( staircase effect ) , however , they are restored very well by both llt - alm and the proposed method . on the other hand",
    ", llt - alm makes the white boxes locally over - smoothed while our method , together with fasttv and cadmtvl2 , can restore them almost the same as the true image .",
    "similar phenomena can also be seen from the bottom row of fig .",
    "8 , llt - alm and the proposed method can avoid staircase effect effectively , such as the lips and cheek .",
    "however , we notice that llt - alm fails to recover the brim of the hat ( edges ) correctly since it makes the brim over - smoothed . in contrast",
    ", our method can not only recover the edges very well , but avoids staircase effect as well .",
    "in this paper , we study the image restoration problem based on the overlapping group sparsity total variation regularizer . to solve the corresponding minimization problem",
    ", we proposed a very efficient algorithm ogsatv - adm4 under the framework of the classic admm and using mm method to tackle the associated subproblem . the numerical comparisons with many state - of - the - art methods",
    "show that our method is very effective and efficient .",
    "the results verify that the proposed method avoids staircase effect and yet preserves edges .",
    "we are currently working on extending our method to real applications involving compressed sensing , blind deconvolution , image enhancement and so on .",
    "the authors would like to thank prof .",
    "m. tao for providing us the code ( cadmtvl2 ) in @xcite and prof .",
    "m. ng for making their code ( fasttv ) in @xcite available online .",
    "n. b. karayiannis and a. n. venetsanopoulos , ",
    "regularization theory in image restoration - the stabilizing functional approach , \" _ ieee trans .",
    "speech signal processing , _ vol .",
    "1155 - 1179 , 1990 .",
    "r. chan , m. tao , and x. m. yuan ,  constrained total variational deblurring models and fast algorithms based on alternating direction method of multipliers , \" _ siam j. imag .",
    "6 , 680 - 697 , 2013 .",
    "m. lysaker , a. lundervold , and x .- c .",
    "tai ,  noise removal using fourth - order partial differential equation with applications to medical magnetic resonance images in space and time , \" _ ieee trans . image process .",
    "1579 - 1590 , 2003 ."
  ],
  "abstract_text": [
    "<S> image restoration is one of the most fundamental issues in imaging science . </S>",
    "<S> total variation ( tv ) regularization is widely used in image restoration problems for its capability to preserve edges . in the literature , however , it is also well known for producing staircase - like artifacts . usually , the high - order total variation ( htv ) regularizer is an good option except its over - smoothing property . in this work , </S>",
    "<S> we study a minimization problem where the objective includes an usual @xmath0 data - fidelity term and an overlapping group sparsity total variation regularizer which can avoid staircase effect and allow edges preserving in the restored image . </S>",
    "<S> we also proposed a fast algorithm for solving the corresponding minimization problem and compare our method with the state - of - the - art tv based methods and htv based method . </S>",
    "<S> the numerical experiments illustrate the efficiency and effectiveness of the proposed method in terms of psnr , relative error and computing time .    image restoration , convex optimization , total variation , overlapping group sparsity , admm , mm . </S>"
  ]
}