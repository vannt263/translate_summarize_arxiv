{
  "article_text": [
    "this paper develops profile likelihood inference methodology for situations where computationally intensive monte carlo methods are employed to evaluate and maximize the likelihood function . if the profile log likelihood function can be computed with a monte carlo error small compared to one unit , carrying out statistical inference from the monte carlo profile as if it were the true profile will have relatively small effects on resulting confidence intervals . sometimes , no reasonable amount of computation can reduce the monte carlo error in evaluating the profile to levels at or below one log unit .",
    "this predicament typically arises with large datasets and complex models .",
    "however , to investigate large datasets in the context of complex models there is little alternative to the use of monte carlo methods .",
    "we develop an approach to effective likelihood - based statistical inference taking into account the non - negligible monte carlo error .",
    "we choose to focus on monte carlo profile likelihood confidence intervals , since their construction gives convenient opportunities to assess monte carlo variability and make appropriate compensations .",
    "our paper is organized as follows .",
    "first , we set up mathematical notation to formalize the task of monte carlo profile likelihood estimation via a metamodel .",
    "section  [ sec : related ] puts this task in the context of some previous work on likelihood - based inference for intractable models .",
    "section  [ sec : cutoff ] develops our methodological approach .",
    "section  [ sec : pomp ] presents a dynamic latent variable modeling framework of broad applicability for which the methodology is appropriate . for this class of models ,",
    "we demonstrate the capabilities of our methodology by solving three inferential challenges , each representing a different data type for which scientific progress is limited by the availability of effective statistical methodology .",
    "these examples all arise from the study of transmissible human diseases , a field characterized by extensive and diverse data , indirectly observation of the underlying infection processes , strongly nonlinear stochastic dynamics , and public health importance .",
    "infectious disease data therefore provide many inference opportunities and challenges .",
    "section  [ sec : genpomp ] concerns inference on population dynamics from genetic data ; section  [ sec : panelpomp ] concerns fitting nonlinear partially observed markov models to panel data ; section  [ sec : spacetime ] concerns fitting a nonlinear partially observed spatiotemporal model .",
    "section  [ sec : timeseries ] discusses the role of our methodology in nonlinear time series analysis .",
    "section  [ sec : sim ] investigates our methodology via a simulation study on a toy example .",
    "section  [ sec : discussion ] is a concluding discussion which situates our paper within the broader goal of inference for large datasets and complex models .",
    "we consider a general statistical inference framework in which data are a real - valued vector , @xmath0 , modeled as a realization of a random variable @xmath1 having density @xmath2 , where @xmath3 is an unknown parameter in @xmath4 .",
    "we are concerned with inference on @xmath3 in situations where the data analyst can not directly evaluate @xmath2 .",
    "instead , we suppose that approximate evaluation of @xmath2 is possible through monte carlo approaches .",
    "one situation in which this arises is when the statistician can simulate draws from the density @xmath2 despite being unable to directly evaluate it @xcite .",
    "in addition to a simulator for the full joint distribution of @xmath1 , we might also have access to simulators for various marginal and conditional distributions related to @xmath2 .",
    "for example , this can arise if @xmath1 has the structure of a fully or partially observed markov process @xcite .",
    "simulation - based methods are growing in usage , motivated by advances in the availability of complex data and the desire for statistical fitting of complex models to these data .",
    "although we can not calculate them , we can nevertheless define the log likelihood function , @xmath5 and a maximum likelihood estimate ( mle ) , @xmath6 to formalize the task of constructing marginal confidence intervals , we suppose that @xmath7 with @xmath8 and @xmath9 . here , @xmath10 is a focal parameter for which we are interested in obtaining a confidence interval using the data , @xmath0 . by changing the focal parameter ,",
    "we are equivalently interested in the general problem of obtaining a marginal confidence interval for each component of a parameter vector .",
    "the profile log likelihood function for @xmath10 is defined as @xmath11 the profile log likelihood is maximized at a marginal mle , @xmath12 a profile likelihood confidence interval with cutoff @xmath13 is defined as @xmath14 profile likelihood confidence intervals are a widespread inference approach with some favorable properties , including asymptotic efficiency and natural transformation under reparameterization @xcite .",
    "modifications can lead to higher - order asymptotic performance @xcite but these are not routinely available . in our context , and are not directly accessible to the data analyst .",
    "instead , we work with independent monte carlo profile likelihood evaluations at a sequence of points @xmath15 .",
    "we denote the evaluations as @xmath16 , using a breve accent to distinguish monte carlo quantities .",
    "we write a decomposition , @xmath17 where @xmath18 are monte carlo random variables which are , by construction , mean zero and independent conditional on @xmath1 .",
    "thus , @xmath19 gives the monte carlo bias of each profile log likelihood evaluation .",
    "if the amount of information about @xmath10 in the data is large , the curvature of the profile log likelihood is large and the statistically relevant region of high likelihood is narrow . in that case , it may be reasonable to approximate the monte carlo bias and error distribution as constant across the profile , modeling @xmath20 as conditionally independent and identically distributed with .",
    "we suppose that the conditional variance of @xmath21 is @xmath22 , and we write @xmath23 .",
    "the metamodel becomes , @xmath24 emprical evidence for non - constant monte carlo variance could motivate the inclusion of heteroskadistic errors in .",
    "the assumption in of approximately constant monte carlo bias is hard to quantify empirically on challenging computational problems , since one can not readily obtain an estimate with negligible bias .",
    "figure  [ fig : bias ] demonstrates pictorially the consequence of linear bias on confidence intervals constructed for a quadratic profile log likelihood function .",
    "we see that linear bias , @xmath25 , affects the location of the maximum of the profile but does not affect the curvature and therefore has no effect on the width of the resulting profile confidence interval .",
    "although the bias on the monte carlo profile likelihood estimate may be intractable , the coverage of a constructed confidence interval can be checked by simulation at a specific parameter value such as an mle , as demonstrated in section  [ sec : sim ] .",
    ", is shown as a red dashed line . a profile including this bias , and the corresponding biased confidence intervals ,",
    "are shown as red solid lines . ]",
    "a prescient paper by @xcite developed monte carlo maximum likelihood methodology with similar motivation to our current goals .",
    "however , @xcite did not work with profile likelihood and did not show how to correct the resulting confidence intervals for monte carlo error .",
    "further , @xcite assumed that the monte carlo methods would involve simulating from the modeled joint distribution of the entire dataset , whereas modern computationally efficient monte carlo algorithms may be based on simulating sequentially from conditional distributions in a carefully crafted decomposition of the entire joint distribution . @xcite and @xcite introduced the term _ plug - and - play _ to describe statistical methodology for which the model ( viewed as an input to an inference algorithm ) is specified via a simulator in this broader sense .",
    "the term _ likelihood - free _ has been used similarly , in the context of markov chain monte carlo @xcite and sequential monte carlo @xcite .",
    "the term _ equation - free _ has been used for the related concept of simulation - based model investigations in the physical sciences @xcite . related terms _ implicit _ @xcite and _ doubly intractable _",
    "@xcite have been used to describe models for which only plug - and - play algorithms are practical . from the point of view of categorizing statistical methodology , it is convenient to view the way in which an inference algorithm accesses the statistical model as a property of the algorithm rather than a property of the model .",
    "@xcite investigated nonparametric estimation of a likelihood surface via approximate bayesian computing ( abc ) . @xcite also provided a literature review of previous approaches to carry out statistical inferences in situations where likelihood evaluation and maximization necessarily involve computationally intensive and noisy monte carlo procedures .",
    "we are not aware of previous work developing monte carlo profile likelihood methodology .",
    "profile methodology focuses the computational effort on parameters of key interest  specifically , those for which one computes the profile .",
    "the process of constructing a profile requires computation of a relevant feature of the likelihood surface in the region of inferential interest .",
    "studying the likelihood surface on this scale , rather than focusing exclusively on a point estimate such as the maximum likelihood estimate , has some theoretical justification @xcite . in the general theory of stochastic simulation - based optimization ,",
    "building metamodels describing the response surface is a standard technique @xcite .",
    "our goal is to develop metamodel methodology that takes advantage of the statistical properties of the profile likelihood and constructs confidence intervals correcting properly for monte carlo variability .",
    "local asymptotic normality ( lan ) provides a general theoretical framework in which the log likelihood function is asymptotically well approximated by a quadratic @xcite . under sufficient regularity conditions ,",
    "this quadratic approximation is inherited by the profile log likelihood @xcite . here",
    ", we write the marginal @xmath10 component of the lan property as a finite sample normal approximation given by @xmath26 where @xmath27 for @xmath28 , and @xmath29 $ ] is a normal random variable with mean @xmath30 and variance @xmath31 . in , @xmath32 indicates approximate equality in distribution . under regular asymptotics ,",
    "the curvature of the quadratic approximation in lan is the fisher information , and lan is therefore a similar property to asymptotic normality of the maximum likelihood estimate .",
    "the quantity @xmath33 in can be interpreted as the marginal fisher information for @xmath10 , also known as the @xmath10-aspect of the fisher information ( * ? ? ?",
    "* section  3.4 ) . specifically , if we write the inverse of the full fisher information as @xmath34,\\ ] ] then @xmath35 . in this article , we focus on developing and demonstrating statistical methodology rather than on presenting theoretical results .",
    "therefore , the formal mathematical representation of the approximations in this paper as asymptotic limit theorems is postponed to subsequent work .",
    "the lan property suggests that the monte carlo profile log likelihood evaluated at @xmath36 can be approximated , in a neighborhood of its maximum , by a quadratic metamodel , @xmath37 this local quadratic metamodel is a special case of .",
    "the unknown coefficients @xmath38 , @xmath39 and @xmath40 , corresponding to equation evaluated at @xmath41 , describe a quadratic approximation to the numerically intractable likelihood surface",
    ". we can use standard linear regression to estimate @xmath38 , @xmath39 and @xmath40 from the monte carlo profile evaluations .",
    "writing @xmath42 , we denote the resulting linear regression coefficients as @xmath43 , @xmath44 and @xmath45 .",
    "the monte carlo quadratic profile likelihood approximation is @xmath46 the marginal mle @xmath47 can be approximated by the maximum of @xmath48 , which is given by @xmath49 now , for @xmath27 , we separate the variability in @xmath50 into two components :    1 .   _",
    "statistical error _ is the uncertainty resulting from randomness in the data , if the data were a draw from the statistical model .",
    "this is the error in the ideal quadratic profile approximation estimate @xmath51 as an estimate of @xmath52 .",
    "monte carlo _ error is the uncertainty resulting from implementing a monte carlo estimator .",
    "this is the error in @xmath53 as a monte carlo estimate of @xmath51 .",
    "the lan approximation in suggests a normal approximation for the distribution of the marginal mle @xmath47 which we write as @xmath54.\\ ] ] the usual statistical standard error , @xmath55 , is not available to us , but we can instead use its monte carlo estimate , @xmath56 to quantify the monte carlo error , we first note that standard linear model methodology provides variance and covariance estimates @xmath57 $ ] , @xmath58 $ ] and @xmath59 $ ] .",
    "the regression errors representing only monte carlo variability conditional on @xmath60 , i.e. , @xmath61={\\mathrm{var}}[\\breve a(y,\\epsilon)| y={y^*}]$ ] .",
    "a standard central limit approximation for regression coefficient estimates is @xmath62 & \\breve{\\mathrm{cov}}[\\breve a({y^*},\\epsilon),\\breve b({y^*},\\epsilon ) ] \\\\                    \\breve{\\mathrm{cov}}[\\breve a({y^*},\\epsilon),\\breve b({y^*},\\epsilon ) ] & \\breve{\\mathrm{var}}[\\breve b({y^*},\\epsilon ) ] \\end{array}\\right ) \\right].\\ ] ] an application of the delta method gives a central limit approximation for the maximum , conditional on @xmath60 , given by @xmath63,\\ ] ] where @xmath64 \\\\ \\label{deltavariance } & & \\hspace{3mm}\\approx   \\frac{1}{4\\breve a^2({y^*},\\epsilon ) } \\hspace{-1 mm } \\left\\ {   \\breve{\\mathrm{var}}\\big[\\breve b({y^*},\\epsilon ) ] - \\frac{2\\breve b({y^*},\\epsilon)}{\\breve a({y^*},\\epsilon)}\\breve{\\mathrm{cov}}\\big[\\breve a({y^*},\\epsilon),\\breve b({y^*},\\epsilon)\\big ] + \\frac{\\breve b^2({y^*},\\epsilon)}{\\breve a^2({y^*},\\epsilon)}\\breve{\\mathrm{var}}\\big[\\breve a({y^*},\\epsilon)\\big ] \\hspace{-1 mm } \\right\\}. \\hspace{8mm}\\end{aligned}\\ ] ] to obtain the combined statistical and monte carlo error , we write @xmath65 = { \\mathbb{e}}\\left\\{{\\mathrm{var}}\\left[\\frac{\\breve b ( y,\\epsilon)}{2\\breve a(y,\\epsilon)}\\big| y\\right]\\right\\ } + { \\mathrm{var}}\\left\\{{\\mathbb{e}}\\left[\\frac{\\breve b ( y,\\epsilon)}{2\\breve a(y,\\epsilon ) } \\big| y\\right]\\right\\}.\\ ] ] now , from , the curvature of the profile log likelihood is approximately constant , independent of @xmath1 . we suppose that the profile points used to obtain @xmath50 are approximately centered on @xmath50 regardless of the value of @xmath1 .",
    "this assumption can be satisfied by construction , for example by fitting the quadratic metamodel in using local weights ( as in the mcap algorithm below ) .",
    "further , we suppose that @xmath66\\approx{\\mathrm{var}}[\\epsilon_k({y^*})]$ ] .",
    "together , these approximations imply @xmath67 \\approx { \\mathrm{var}}\\left[\\frac{\\breve b({y^*},\\epsilon)}{2\\breve a({y^*},\\epsilon)}\\right].\\ ] ] also , from the central limit approximation in , we have @xmath68 \\approx \\hat\\phi(y).\\ ] ] putting and into , and using the approximations in and , we get @xmath69,\\ ] ] where @xmath70 the usual asymptotic profile likelihood confidence interval cutoff value can be obtained by converting the standard error of the mle into an equivalent cutoff on a quadratic approximation to the profile log likelihood . in our setting , the asymptotic @xmath71 confidence interval , @xmath72 where @xmath73=\\alpha/2 $ ] , is equivalent to a monte carlo adjusted profile cutoff for the quadratic approximation @xmath74 of @xmath75 note that , if @xmath76 , the calculation in for @xmath77 reduces to @xmath78 the usual cutoff to construct a 95% confidence interval for an exact profile likelihood .",
    "confidence intervals based on a quadratic approximation to the exact log likelihood are asymptotically equivalent to using the same cutoff @xmath13 with a smoothed version of the likelihood , so long as an appropriate smoother is used @xcite .",
    "an appropriate smoother should return a quadratic when the points do indeed lie on a quadratic , a property satisfied , for example , by local quadratic smoothing such as the r function ` loess ` .",
    "we therefore propose using @xmath13 as an appropriate cutoff on a profile likelihood estimate obtained by applying a suitable smoother to the monte carlo evaluations in .",
    "a smoother , @xmath79 , generates a value at @xmath10 based on fitting a smooth curve through the points @xmath80 with an algorithmic parameter @xmath81 determining the smoothness of the fit . a resulting maximum smoothed monte carlo profile likelihood estimate is @xmath82 a corresponding monte carlo profile likelihood confidence interval for a cutoff @xmath13 is @xmath83 here , we suppose that @xmath84 is evaluated at @xmath10 via local quadratic regression with weight @xmath85 on the point @xmath86 , where @xmath85 depends on the proximity of @xmath10 to @xmath87 .",
    "specifically , we take @xmath88 to be the widely used local quadratic smoother of @xcite as implemented in the r function ` loess ` . in this case",
    ", @xmath81 is the _ span _ of the smoother , defined as the fraction of the data used to construct the weights in the local regression at any point @xmath10 . in practice",
    ", the statistician needs to specify @xmath81 .",
    "while automated choices of smoothing parameter have been proposed , it remains standard practice to choose the smoothing parameter based on some experimentation and looking at the resulting fit . in our experience",
    ", the default ` loess ` choice of @xmath89 has been appropriate in most cases .",
    "however , a larger value of @xmath81 is needed when the profile is evaluated at very few points ( as demonstrated in section  [ sec : spacetime ] ) . when the exact profile is not far from quadratic",
    ", one can expect local quadratic smoothing of the monte carlo profile likelihood to be insensitive to the choice of @xmath81 .",
    "just as the local quadratic regression smoother has weights @xmath90 , the quadratic metamodel in can be fitted using regression weights .",
    "a natural choice of these weights for obtaining a profile confidence interval cutoff for @xmath84 is @xmath91 .",
    "this choice is used for the mcap algorithm below . for our numerical results",
    ", we used the implementation of this mcap algorithm given in a supplement ( section  [ sec : mcap : code ] ) .",
    "l    ' '' ''     +    ' '' ''     + monte carlo profile @xmath92 evaluated at @xmath36 + local quadratic regression smoother , @xmath88 + smoothing parameter , @xmath81 + confidence level , @xmath93 + * output : *    ' '' ''     + cutoff , @xmath13 , for a monte carlo profile likelihood confidence interval + fit a local quadratic smoother , @xmath94 + obtain @xmath95 + obtain regression weights @xmath96 for the evaluation of @xmath97 at @xmath98 + fit a linear regression model , @xmath99 , with weights @xmath96 + obtain regression estimates @xmath100 and @xmath101 + obtain regression covariances @xmath102 $ ] , @xmath103 $ ] , @xmath104 $ ] + let @xmath105 - \\frac{2\\breve b}{\\breve a}\\breve{\\mathrm{cov}}[\\breve a,\\breve b ] + \\frac{\\breve b^2}{\\breve a^2}\\breve{\\mathrm{var}}[\\breve a ]   \\right\\}$ ] + let @xmath106 be the @xmath71 quantile of the chi - square distribution on one degree of freedom + let @xmath107 +",
    "many dynamic systems with indirectly observed latent processes can be modeled within the partially observed markov process ( pomp ) framework . a general pomp model , also known as a hidden markov model or a state space model , consists of a latent markov process @xmath108 , with @xmath109 taking values in a space @xmath110 , together with a sequence of observable random variables @xmath111 .",
    "we suppose @xmath112 occurs at a time @xmath113 , and the observations are conditionally independent of each other and of @xmath108 given @xmath114 .",
    "for example , we may have @xmath115 , the space of @xmath116-dimensional real vectors . when @xmath117 ( or @xmath116 is small ) @xmath111 is called a univariate ( or multivariate ) time series model .",
    "the pomp framework provides a fundamental approach for nonlinear time series analysis , with innumerable applications @xcite .",
    "when @xmath116 becomes large , the pomp framework allows for nonlinear panel data and spatiotemporal data , as well as other complex data structures .",
    "unless the pomp model is linear and gaussian , or @xmath110 is a sufficiently small finite set , monte carlo techniques such as sequential monte carlo ( smc ) are required to evaluate the likelihood function . for our examples ,",
    "we focus on likelihood maximization by iterated filtering @xcite .",
    "similar issues arise with alternative computational approaches , including monte  carlo expectation - maximization algorithms ( * ? ? ?",
    "* chapter  11 ) . even for",
    "the relatively simple case of time series pomp models ( discussed further in section  [ sec : timeseries ] ) numerical issues can be computationally demanding for currently available methodology , giving opportunity for mcap methodology to facilitate data analysis . however , to demonstrate the capabilities of our methodology , we present three high - dimensional pomp inference challenges that become computationally tractable using mcap",
    ".      genetic sequence data on a sample of individuals in an ecological system has potential to reveal population dynamics .",
    "extraction of this information has been termed _",
    "phylodynamics _ @xcite .",
    "likelihood - based inference for joint models of the molecular evolution process , population dynamics , and measurement process is a challenging computational problem .",
    "the bulk of extant phylodynamic methodology has therefore focused on inference for population dynamics conditional on an estimated phylogeny and replacing the population dynamic model with an approximation , called a _ coalescent model _ that is convenient for calculations backwards in time @xcite .",
    "working with the full joint likelihood is not entirely beyond modern computational capabilities ; in particular it can be done using the ` genpomp ` algorithm of @xcite .",
    "the ` genpomp ` algorithm is an application of iterated filtering methodology @xcite to phylodynamic models and data . to the best of our knowledge , ` genpomp ` is the first algorithm capable of carrying out full joint likelihood - based inference for population - level phylodynamic inference .",
    "however , the ` genpomp ` algorithm leads to estimators with high monte carlo variance , indeed , too high for reasonable amounts of computation resources to reduce monte carlo variability to negligibility .",
    "this , therefore , provides a useful scenario to demonstrate our methodology .",
    "figure  [ fig : gen_profile ] presents a monte carlo profile computed by @xcite , with confidence intervals constructed by applying the mcap algorithm implemented by the ` mcap ` procedure ( section  [ sec : mcap : code ] ) with default smoothing parameter .",
    "the model and data concern hiv transmission in southeast michigan , but details of the model and computations are not of immediate interest since all we need to consider are the estimated profile likelihood points . the profiled parameter quantifies hiv transmission from recently infected , diagnosed individuals ",
    "it is @xmath118 in the notation of @xcite but we rename it as @xmath10 for the current paper .",
    "the computations for figure  [ fig : gen_profile ] took approximately 10 days using 500 cores on a linux cluster . to scale this methodology to increasingly large datasets and more complex models ,",
    "it is apparent that one may be limited by the computational effort required to control monte carlo error .",
    "the mcap procedure gives a monte carlo standard error of @xmath119 on the value maximizing the smoothed monte carlo profile , based on the quadratic approximation at the maximum .",
    "the statistical error is @xmath120 . combining these sources of uncertainty",
    "gives a total standard error of @xmath121 .",
    "from , the resulting @xmath122 confidence profile cutoff is @xmath123 . we see in figure  [ fig : gen_profile ] that the smoothed profile is close to its quadratic approximation in the neighborhood of the maximum statistically supported by the data .",
    "we also see that the monte carlo uncertainty in the profile confidence interval is rather small , leading to a profile cutoff not much bigger than the value of 1.92 for zero monte carlo error , despite the large monte carlo variability in the evaluation of any one point on the profile .",
    "panel data consists of a collection of time series which have some shared parameters , but negligible dynamic dependence .",
    "we consider inference using mechanistic models for panel data , i.e. , equations for how the process progresses through time derived from scientific principles about the system under investigation . in principle , statistical methods for mechanistic time series analysis @xcite extend to the panel situation @xcite .",
    "however , extensive data add computational challenges to monte carlo inference schemes .",
    "in particular , with increasing amounts of data , it must eventually become infeasible to calculate the likelihood with an error as small as one log unit .",
    "the mcap procedure nevertheless succeeds so long as the signal - to - noise ratio in the monte carlo profile is adequate . in a simple situation , where each time series is modeled as independent and identically distributed and each time series model",
    "contains the same parameters , we can check how this ratio scales .",
    "the fisher information scales linearly with the number of time series in the panel , and therefore the curvature of the log likelihood profile also scales linearly .",
    "the monte carlo standard error on the likelihood scales at a square - root rate . in this case",
    ", we therefore expect the mcap methodology to scale successfully with the number of time series in the panel .",
    "investigations of population - level infectious disease transmission lead to highly nonlinear , stochastic , partially observed dynamic models .",
    "the great majority of disease transmission is local , despite the importance of spatial transmission to seed the local epidemics @xcite .",
    "fitting models to panels of epidemiological time series data , such as incidence data for collections of cities or states , offers potential to elucidate the similarities and differences between these local epidemics .",
    "we demonstrate the mcap procedure on a panel estimate of the reporting rate of paralytic polio in the pre - vaccination era united states .",
    "reporting rate has important consequences for understanding the system : conditional on observed incidence data , reporting rate determines the extent of the unreported epidemic . yet , in the presence of many uncertainties about this complex disease transmission system , a single disease incidence time series often can not conclusively pin down this epidemiological parameter . the profile evaluations in figure  [ fig : panel_profile ]",
    "were obtained by @xcite in an extension of the analysis of @xcite .",
    "@xcite analyzed state level paralytic polio incidence data in order to study the role of unobserved asymptomatic polio infections in disease persistence . here ,",
    "the reporting rate parameter ( @xmath124 in the terminology of * ? ? ?",
    "* ) is denoted by @xmath10 .",
    "the mcap procedure gives a monte carlo standard error of @xmath125 and a statistical error of @xmath126 .",
    "combining them gives a total standard error of @xmath127 .",
    "the resulting profile cutoff is @xmath128 the profile decreases slowly to the right of the mle , since higher reporting rates can be compensated for by lower transmission intensities .",
    "the model struggles to explain reporting rates much lower than the mle , since the reporting rate must be sufficient to explain the observed number of cases in a situation where almost all individuals acquire non - paralytic polio infections .",
    "this asymmmetrical tradeoff may explain why the profile log likelihood shows some noticeable deviation from its quadratic approximation in a neighborhood of the maximum .",
    "the computations for figure  [ fig : panel_profile ] required approximately 24 hours on 300 cores . at this level of computational intensity , we see that the majority of uncertainty about the parameter @xmath10 is due to monte carlo error rather than statistical error . for this large panel dataset , in the context of the fitted model , the parameter @xmath10",
    "would be identified very accurately by the data if we had access to the actual likelihood surface .",
    "additional computation could , therefore , reduce the uncertainty on our estimate of @xmath10 by a factor of three .",
    "however , the data analyst may decide the available computational effort is better used exploring other parameters or alternative model specifications .",
    "spatiotemporal data consists of time series collected at various locations .",
    "spatiotemporal models extend panel models by allowing for dynamic dependence between locations .",
    "we consider statistical inference for a mechanistic spatiotemporal model , meaning a collection of nonlinear partially observed spatially coupled markov process .",
    "smc methods , that provide a foundation for much likelihood - based inference relating pomp models to time series data , struggle with spatiotemporal data since they scale poorly with spatial dimension @xcite .",
    "theoretically , smc methods with sub - exponential scaling can be developed for weakly coupled spatiotemporal systems @xcite . in practice ,",
    "appropriately designed smc schemes can successfully carry out monte carlo likelihood evaluation for general partially observed spatiotemporal processes of modest dimension @xcite .",
    "@xcite then employed iterated filtering methodology @xcite which modifies an smc algorithm to maximize the likelihood .",
    "figure  [ fig : stif ] shows an estimated likelihood profile for a parameter",
    "@xmath10 corresponding to the contact rate between individuals ( denoted as @xmath129 by * ? ? ?",
    "* ) when fitting a ten parameter model to pre - vaccination measles incidence in 20 cities in the united kingdom .",
    "this profile corresponds to a simulation test of the methodology of @xcite in which the true parameter is known . here ,",
    "we are not immediately concerned with the details of the model and the monte carlo methodology ( described by * ? ? ?",
    "* ) but rather with showing another example of how a computationally demanding inference problem can give rise to noisy monte carlo points estimating a profile likelihood . for this computation ,",
    "only five distinct parameter values were used when computing the profile .",
    "the default smoothing parameter @xmath89 was too small in this case , since the local quadratic fit by the smoother at the maximum placed almost all its weights on only three distinct parameter values .",
    "the resulting numerical instability was avoided by taking @xmath130 . for this analysis ,",
    "the profile cutoff adjusted for monte carlo uncertainty is @xmath131 , and we see that the monte carlo variability @xmath132 in the parameter estimate greatly exceeds the statistical variability @xmath133 . evidently , the simulated spatiotemporal data have a considerable amount of information about the parameter @xmath10 , but extracting that information in a statistically efficient way is complicated by the computational challenge of working with the likelihood of a nonlinear partially observed spatiotemporal process .      the examples in sections  [ sec : genpomp ] , [ sec : panelpomp ] and  [ sec : spacetime ] demonstrate applications which were computationally intractable without mcap . applications of the pomp framework to nonlinear time series analysis typically involve smaller data sets , and a relatively simple dependence structure , and are therefore less computationally demanding .",
    "this consideration has facilitated the utilization of monte carlo profile likelihood , without the benefits of mcap , as a technique at the cutting edge of nonlinear time series analysis . in the context of infectious disease dynamics",
    ", @xcite wrote , `` powerful new inferential fitting methods @xcite considerably increase the accuracy of outbreak predictions while also allowing models whose structure reflects different underlying assumptions to be compared .",
    "these approaches move well beyond time series and statistical regression analyses as they include mechanistic details as mathematical functions that define rates of loss of immunity and the response of vector abundance to climate .",
    "'' examples showing a central role for monte carlo profile likelihood in such analyses are given by ( * ? ? ?",
    "2 ) , ( * ? ? ?",
    "s3 and s8a ) , ( * ? ? ?",
    "3a ) , ( * ? ? ?",
    "2b-2 g and 4l-4p ) and ( * ? ? ? * figs .",
    "s1 , s4 and s5 ) .",
    "the main practical limitation of this approach is computational resources @xcite .",
    "we have shown that our methodology can both quantify and dramatically reduce the monte carlo error in computationally intensive inferences for pomp models .",
    "the mcap procedure therefore improves the accessibility and scalability of inference for nonlinear time series models .",
    "we look for a numerically convenient toy scenario that generates monte carlo profiles resembling figures  [ fig : gen_profile ] ,  [ fig : panel_profile ] and  [ fig : stif ] .",
    "our simulated data are an independent , identically distributed log normal sample @xmath134 where @xmath135 $ ] for @xmath136 .",
    "we consider a profile likelihood confidence interval for the log mean parameter , @xmath10 .",
    "the log normal distribution leads to log likelihood profiles that deviate from quadratic . to set up a situation with monte carlo error in evaluating and maximizing the likelihood",
    ", we supposed that the likelihood is accessed via monte carlo integration of a latent variable . specifically , we write @xmath137 with @xmath138 $ ] .",
    "then , our monte carlo density estimator is @xmath139 where @xmath140 is the log normal density , @xmath141 and @xmath142 is a sequence of standard normal pseudo - random numbers corresponding to a seed @xmath143 .",
    "we suppose that we are working with a parallel random number generator such that pseudo - random sequences corresponding to different seeds behave numerically like independent random sequences .",
    "our monte carlo log likelihood estimator is @xmath144 our monte carlo profile is calculated at @xmath145 .",
    "we maximize the likelihood numerically , at a fixed seed , to give a corresponding estimate of @xmath146 given by @xmath147 we do not wish to imply that practical examples will generally result from a fixed - seed monte carlo likelihood calculation .",
    "seed fixing is an effective technique for removing monte carlo variability from relatively small calculations , but can become difficult or impossible to implement effectively for complex , coupled , nonlinear systems .    the following numerical results used @xmath148 and @xmath149 with true parameter values @xmath150 and @xmath151 .",
    "there are two ways to increase the monte carlo error in the log likelihood for this toy example , by increasing the sample size , @xmath152 , and decreasing the monte carlo effort , @xmath153 .",
    "the monte carlo variance of the log likelihood estimate increases linearly with @xmath152 , but at the same time the curvature of the log likelihood increases and , within the inferentially relevant region , the profile log likelihood becomes increasingly close to quadratic .",
    "thus , in the context of our methodology , increasing @xmath152 actually makes inference easier despite the increasing monte carlo noise .",
    "this avoids a paradoxical difficulty of monte carlo inference for big data : more data should be a help for a statistician , not a hindrance !",
    "decreasing @xmath153 represents a situation where monte carlo variability increases without increasing information about the parameter of interest . in this case , the monte carlo variability and the monte carlo bias on the log likelihood due to jensen s inequality both increase . also , likelihood maximization becomes more erratic for small @xmath153 since the maximization error due to the fixed seed becomes more important .",
    "figure  [ fig : toy - plot ] shows that , even when there is considerable bias and variance in the monte carlo profile evaluations , the monte carlo profile confidence intervals can be little wider than the exact interval .     smoothing parameter . the quadratic approximation used to calculate the mcap profile cutoff",
    "is shown as a dotted blue line . ]",
    "we computed intervals with nominal coverage of 95% .",
    "the mcap coverage here was @xmath154% , compared to @xmath155% for the asymptotically exact profile ( with a simulation study monte carlo standard error of @xmath156% ) .",
    "the mcap intervals were , on average , @xmath157% larger than the corresponding exact profile interval , with the increased width accounting for the additional monte carlo uncertainty .",
    "this paper has focused on likelihood - based confidence intervals .",
    "an alternative to likelihood - based inference is to compare the data with simulations using some summary statistic .",
    "various plug - and - play methodologies of this kind have been proposed , such as synthetic likelihood @xcite and nonlinear forecasting @xcite . for large nonlinear systems",
    ", it can be hard to find low - dimensional summary statistics that capture a good fraction of the information in the data .",
    "even summary statistics derived by careful scientific or statistical reasoning have been found surprisingly uninformative compared to the whole data likelihood in both scientific investigations @xcite and simulation experiments @xcite .",
    "much attention has been given to scaling bayesian computation to complex models and large data .",
    "bayesian computation is closely related to likelihood inference for stochastic dynamic models : the random variables generating a dynamic system are typically not directly observed , and these latent random variables are therefore similar to bayesian parameters .",
    "we refer to these latent random variables as _ random effects _ since they have a similar role as linear model random effects . to carry out inference on the structural parameters of the model ( i.e. , the vector @xmath3 in this article ) the bayesian approach looks for the marginal posterior of @xmath3 , which involves integration over the random effects .",
    "likelihood - based inference for @xmath3 similarly involves integrating out the random effects .",
    "numerical methods such as expectation propagation ( ep ) @xcite and variational bayes @xcite are effective for some model classes .",
    "another approach is to combine markov chain monte carlo ( mcmc ) computations on subsets of the data , as in the posterior interval estimation ( pie ) method of @xcite .",
    "the above approaches ( ep , vb and pie ) all emphasize situations where the joint density of the data and latent variables can be conveniently split up into conditionally independent chunks , such as a hierarchical model structure .",
    "our methodology has no such requirement .",
    "the panel model example above does have a natural hierarchical structure , with individual panels being independent ( in the frequentist model sense ) or conditionally independent given the shared parameters ( in the bayesian model sense ) .",
    "our spatiotemporal and genetic examples do not have such a representation .",
    "some simulation - based bayesian computation methodologies have built on the observation that unbiased monte carlo likelihood computations can be used inside an mcmc algorithm @xcite . for large systems ,",
    "high monte carlo variability of likelihood estimates is a concern , in this context , since it slows down mcmc convergence @xcite .",
    "@xcite found that , for a given computational budget , the optimal balance between number of mcmc iterations and time spent on each likelihood evaluation occurs at a monte carlo likelihood standard deviation of one log unit .",
    "for the systems we demonstrate , monte carlo errors that small are not computationally feasible .",
    "our simple and general approach permits inference when the signal - to - noise ratio in the monte carlo profile log likelihood is sufficient to uncover the main features of this function , up to an unimportant vertical shift . for large datasets",
    "in which the signal ( quantified as the curvature of the log likelihood ) is large , the methodology can be effective even when the monte carlo noise is far too big to carry out standard mcmc techniques .",
    "although the frequentist motivation for likelihood - based inference differs from the goal of bayesian posterior inference , both approaches can be used for deductive scientific reasoning @xcite .",
    "andrieu , c. and roberts , g.  o. ( 2009 ) .",
    "the pseudo - marginal approach for efficient computation .",
    ", 37:697725 .",
    "bardenet , r. , doucet , a. , and holmes , c. ( 2015 ) .",
    "on markov chain monte carlo methods for tall data . .",
    "barndorff - nielsen , o.  e. and cox , d.  r. ( 1994 ) . .",
    "chapman and hall , london .",
    "barton , r.  r. and meckesheimer , m. ( 2006 ) .",
    "metamodel - based simulation optimization .",
    ", 13:535574 .",
    "bengtsson , t. , bickel , p. , and li , b. ( 2008 ) .",
    "curse - of - dimensionality revisited : collapse of the particle filter in very large scale systems . in speed ,",
    "t. and nolan , d. , editors , _ probability and statistics : essays in honor of david a. freedman _ , pages 316334 .",
    "institute of mathematical statistics , beachwood , oh .    bjornstad , o. and grenfell , b. ( 2008 ) .",
    "hazards , spatial transmission and timing of outbreaks in epidemic metapopulations .",
    ", 15:265277 .",
    "blackwood , j.  c. , cummings , d. a.  t. , broutin , h. , iamsirithaworn , s. , and rohani , p. ( 2013 ) . deciphering the impacts of vaccination and immunity on pertussis epidemiology in thailand .",
    ", 110:95959600 .",
    "blake , i.  m. , martin , r. , goel , a. , khetsuriani , n. , everts , j. , wolff , c. , wassilak , s. , aylward , r.  b. , and grassly , n.  c. ( 2014 ) .",
    "the role of older children and adults in wild poliovirus transmission .",
    ", 111(29):1060410609 .",
    "bret , c. , he , d. , ionides , e.  l. , and king , a.  a. ( 2009 ) .",
    "time series analysis via mechanistic models .",
    ", 3:319348 .",
    "bret , c. , ionides , e.  l. , and king , a.  a. ( 2016 ) .",
    "panel data analysis via mechanistic models . .",
    "camacho , a. , ballesteros , s. , graham , a.  l. , carrat , f. , ratmann , o. , and cazelles , b. ( 2011 ) . explaining rapid reinfections in multiple - wave influenza outbreaks :",
    "tristan da cunha 1971 epidemic as a case study .",
    ", 278(1725):36353643 .",
    "capp , o. , moulines , e. , and rydn , t. ( 2005 ) . .",
    "springer , new york .",
    "cleveland , w.  s. , grosse , e. , and shyu , w.  m. ( 1993 ) . local regression models . in chambers , j.  m. and hastie , t.  j. , editors , _ statistical models in s _ , pages 309376 . chapman and hall , london .",
    "diggle , p.  j. and gratton , r.  j. ( 1984 ) .",
    "monte carlo methods of inference for implicit statistical models .",
    ", 46:193227 .",
    "dobson , a. ( 2014 ) .",
    "mathematical models for emerging disease .",
    ", 346:12941295 .",
    "doucet , a. , pitt , m.  k. , deligiannidis , g. , and kohn , r. ( 2015 ) .",
    "efficient implementation of markov chain monte carlo when using an unbiased likelihood estimator .",
    ", 102:295313 .",
    "ellner , s.  p. , bailey , b.  a. , bobashev , g.  v. , gallant , a.  r. , grenfell , b.  t. , and nychka , d.  w. ( 1998 ) .",
    "noise and nonlinearity in measles epidemics : combining mechanistic and statistical approaches to population modeling .",
    ", 151:425440 .",
    "fasiolo , m. , pya , n. , and wood , s.  n. ( 2016 ) . a comparison of inferential methods for highly nonlinear state space models in ecology and epidemiology .",
    ", 31:96118 .",
    "gelman , a. and shalizi , c.  r. ( 2013 ) .",
    "philosophy and the practice of bayesian statistics .",
    ", 66:838 .",
    "gelman , a. , vehtari , a. , jylnki , p. , robert , c. , chopin , n. , and cunningham , j.  p. ( 2014 ) .",
    "expectation propagation as a way of life . .",
    "grenfell , b.  t. , pybus , o.  g. , gog , j.  r. , wood , j. l.  n. , daly , j.  m. , mumford , j.  a. , and holmes , e.  c. ( 2004 ) .",
    "unifying the epidemiological and evolutionary dynamics of pathogens . , 303:327332 .    he , d. , ionides , e.  l. , and king , a.  a. ( 2010 )",
    ". plug - and - play inference for disease dynamics : measles in large and small towns as a case study .",
    ", 7:271283 .",
    "hoffman , m.  d. , blei , d.  m. , wang , c. , and paisley , j.  w. ( 2013 ) .",
    "stochastic variational inference .",
    ", 14:13031347 .",
    "ionides , e.  l. ( 2005 ) . maximum smoothed likelihood estimation .",
    ", 15:10031014 .",
    "ionides , e.  l. , bret , c. , and king , a.  a. ( 2006 ) .",
    "inference for nonlinear dynamical systems .",
    ", 103:1843818443 .",
    "ionides , e.  l. , giessing , a. , ritov , y. , and page , s.  e. ( 2016 ) .",
    "response to the asa s statement on p - values : context , process , and purpose .",
    ", to appear .",
    "ionides , e.  l. , nguyen , d. , atchad , y. , stoev , s. , and king , a.  a. ( 2015 ) .",
    "inference for dynamic and latent variable models via iterated , perturbed bayes maps .",
    ", 112:719724 .",
    "karcher , m.  d. , palacios , j.  a. , lan , s. , and minin , v.  n. ( 2016 ) .",
    "phylodyn : an r package for phylodynamic simulation and inference .",
    ", 17:96100 .",
    "kevrekidis , i.  g. , gear , c.  w. , and hummer , g. ( 2004 ) .",
    "equation - free : the computer - assisted analysis of complex , multiscale systems .",
    ", 50:13461354 .",
    "king , a.  a. , ionides , e.  l. , pascual , m. , and bouma , m.  j. ( 2008 ) .",
    "inapparent infections and cholera dynamics . , 454:877880 .",
    "le  cam , l. and yang , g.  l. ( 2000 ) . .",
    "springer , new york , 2nd edition .",
    "li , c. , srivastava , s. , and dunson , d.  b. ( 2016 ) . simple , scalable and accurate posterior interval estimation . .",
    "lyne , a .-",
    "m . , girolami , m. , atchade , y. , strathmann , h. , simpson , d. , et  al .",
    "on russian roulette estimates for bayesian inference with doubly - intractable likelihoods . , 30:443467 .",
    "marjoram , p. , molitor , j. , plagnol , v. , and tavar , s. ( 2003 ) .",
    "markov chain monte carlo without likelihoods .",
    ", 100:1532415328 .",
    "martinez - bakker , m. , king , a.  a. , and rohani , p. ( 2015 ) .",
    "unraveling the transmission ecology of polio .",
    ", 13:e1002172 .",
    "murphy , s.  a. and van  der vaart , a.  w. ( 2000 ) . on profile likelihood .",
    ", 95:449465 .",
    "park , j. and ionides , e.  l. ( 2016 ) .",
    "particle filter for continuous time partially observed markov processes in high dimension via intermediate resampling . .",
    "pawitan , y. ( 2001 ) . .",
    "clarendon press , oxford .",
    "rebeschini , p. and van handel , r. ( 2015 ) .",
    "can local particle filters beat the curse of dimensionality ?",
    ", 25:28092866 .",
    "rubio , f.  j. and johansen , a.  m. ( 2013 ) . a simple approach to maximum intractable likelihood estimation .",
    ", 7:16321654 .",
    "shrestha , s. , foxman , b. , weinberger , d.  m. , steiner , c. , viboud , c. , and rohani , p. ( 2013 ) . identifying the interaction between influenza and pneumococcal pneumonia using incidence data .",
    ", 5(191):191ra84 .",
    "shrestha , s. , king , a.  a. , and rohani , p. ( 2011 ) .",
    "statistical inference for multi - pathogen systems .",
    ", 7:e1002135 .",
    "sisson , s.  a. , fan , y. , and tanaka , m.  m. ( 2007 ) .",
    "sequential monte carlo without likelihoods .",
    ", 104:17601765 .",
    "smith , r.  a. , ionides , e.  l. , and king , a.  a. ( 2016 ) .",
    "infectious disease dynamics inferred from genetic data via sequential monte carlo . .",
    "wood , s.  n. ( 2010 ) . statistical inference for noisy nonlinear ecological dynamic systems .",
    ", 466:11021104 .",
    "the following r code carries out the mcap algorithm , as used for the results in this paper .    `",
    "`` ) { ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` + `  ` +"
  ],
  "abstract_text": [
    "<S> monte carlo methods to evaluate and maximize the likelihood function enable the construction of confidence intervals and hypothesis tests , facilitating scientific investigation using models for which the likelihood function is intractable . when monte carlo error can be made small , by sufficiently exhaustive computation , </S>",
    "<S> then the standard theory and practice of likelihood - based inference applies . </S>",
    "<S> as data become larger , and models more complex , situations arise where no reasonable amount of computation can render monte carlo error negligible . </S>",
    "<S> we develop profile likelihood methodology to provide frequentist inferences that take into account monte carlo uncertainty . </S>",
    "<S> we investigate the role of this methodology in facilitating inference for computationally challenging dynamic latent variable models . </S>",
    "<S> we present three examples arising in the study of infectious disease transmission . </S>",
    "<S> these three examples demonstrate our methodology for inference on nonlinear dynamic models using genetic sequence data , panel time series data , and spatiotemporal data . </S>",
    "<S> we also discuss applicability to nonlinear time series analysis .    </S>",
    "<S> * keywords : * likelihood - based inference ; sequential monte carlo ; panel data ; spatiotemporal data ; phylodynamic inference . </S>"
  ]
}