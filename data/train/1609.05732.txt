{
  "article_text": [
    "in this paper , we propose an opinion dynamics model in which agents move via convex combinations of the positions of neighbors specified by a sequence of graphs .",
    "the key feature of our model is that each agent gradually increases its self - confidence represented by its weight in the convex combination .",
    "the intuition is that by constantly incorporating signals into its own belief , the agent becomes more and more confident about its own opinion .",
    "the motivation and validity of such a scheme are further testified by its relations between related works including social learning  @xcite , bayesian inference  @xcite , multi - armed bandits  @xcite , as well as opinion dynamics with stubborn or static agents  @xcite .",
    "we first give a brief introduction of related works , followed by formally presenting the model and its relations to the above areas .",
    "our main results regarding consensus and convergence rate of the model under fixed and changing social networks are presented in section [ sec : fixed ] and section [ sec : changing ] , respectively .",
    "section [ sec : conclusion ] concludes the paper .",
    "opinion dynamics model and network - based dynamical systems have received a surge of attention lately  @xcite . in these systems , typically , a group of agents will interact by communicating through a sequence of graphs .",
    "the original goal of opinion dynamics is to model the formation and propagation of opinions and knowledge in a crowd of interacting individuals  @xcite .",
    "later the model grows its popularity due to its widespread use in economics and social sciences  @xcite .",
    "opinion dynamics models are usually diffusive , in the sense that the new opinion comes from a convex combination of the old ones@xcite .",
    "thus , in its matrix form , the dynamics of the opinions is equivalent to repeated stochastic matrix multiplications to the opinions .",
    "we refer interested readers to  @xcite for more detailed discussions on product of stochastic matrices and averaging processes .",
    "the major question to ask regarding opinion dynamics systems is whether the agents will achieve consensus , a state that all the agents share the same opinion .",
    "in fact , we will show that , with the existence of a static agent ( truth ) , the system achieves consensus under mild assumptions about the network structure . for fixed graph , convergence is achieved of polynomial order @xmath0 , where @xmath1 is the spectral gap of the graph laplacian . for periodically changing graphs",
    ", the system converges to consensus asymptotically of order @xmath2 , where @xmath3 is the maximum total outdegree in a period .",
    "both the convergence bounds are tight .",
    "if the graphs are generated randomly , we obtain an almost - sure convergence result .",
    "we note that related opinion dynamics systems usually feature exponential convergence  @xcite .",
    "the slower convergence in our model originates from the increasing self - confidence : larger self - weight after repeated interactions makes the agents reluctant to move .",
    "the system consists of @xmath4 agents represented by scalars or vectors @xmath5 , where @xmath6 is the time .",
    "the interactions between agents are captured by a sequence of graphs @xmath7 , where @xmath8 can be any directed graph over @xmath9 , and self - loop is allowed .",
    "it should be noted that we do not assert constraint of how @xmath8 is formed , and thus @xmath8 can be fixed , arbitrarily specified , randomly generated , or even coupled with the opinions .",
    "a truth ( static agent ) refers to the agent which never interacts with other agents , and thus it is stuck at its initial position eternally .",
    "though being interesting , it is not necessary for a truth to exist in the system ; if it does , the other mobile agents are usually referred to as the learners .",
    "we use @xmath10 to denote the neighbor set of @xmath11 at time @xmath12 , and @xmath13 if and only if edge @xmath14 . in this case",
    ", @xmath11 gets information from @xmath15 , or equivalently , @xmath15 influences @xmath11 .",
    "the dynamics of the model is written as @xmath16 where the weight @xmath17 is a scalar associated with agent @xmath11 at time @xmath12 .",
    "@xmath17 is regarded as @xmath11 s self - confidence , representing the degree of how much agent @xmath11 believes in its current opinion . in spite of various seemingly plausible ways of modeling the dynamics of the self - confidence @xmath17 , we assume in each step @xmath12 , @xmath17 increases by the number of @xmath11 s neighbors @xmath18 : @xmath19 the intuition is that after communicating with @xmath18 agents and obtaining @xmath18 signals , the amount of self - confidence should also increase in that amount .",
    "the modeling of the dynamics of self - confidence is further justified by the relations between the proposed model and existing works on social learning , bayesian inference , inertial opinion dynamics , and multi - armed bandits in section [ sec : relation ] , [ sec : relation2 ] , and [ sec : relation3 ] . in the mean time , out results regarding the proposed model in section [ sec : fixed ] and [ sec : changing ] directly apply to the above fields .      in the framework of social learning , a group of learners ( mobile agents ) tries to learn the state of the world denoted by a truth ( static agent ) via a social network . recently ,",
    "rahimian and jadbabaie proposed the so - called bayesian without recall ( _ bwr _ ) model  @xcite , in which the agents are assumed to be rational and memoryless . in the _ bwr _ model , each agent adopts an initial belief , updates the belief via bayes s rule based on signals transferred from the truth or other agents , while ignoring the mechanism behind the data generating process  @xcite .",
    "assume the belief of agent @xmath11 is gaussian distributed @xmath20 , and the signal being transferred @xmath21 is noisy measurement of @xmath15 s belief @xmath22 , where @xmath23 is independent gaussian noise . in @xcite ,",
    "the explicit update rule is demonstrated as @xmath24 where @xmath25 and @xmath26 are inverse variances following update rule @xmath27 by taking expectations on both sides of , it is clear that @xmath28 together with the weight @xmath29 follows the proposed increasing self - confidence model .      in the famous hegselmann - krause ( _ hk _ )",
    "system , each agent moves to the mass center of all the agents within a fixed distance @xmath30  @xcite .",
    "stubborn agent in an _ hk _ system moves toward the mass center of its neighbors by any fraction of length : @xmath31 setting this fraction to zero makes the agent static .",
    "_ hk _ systems with stubborn or static agents attract much attention recently , for the model is more realistic and addresses issues like symmetry breaking and non - shrinking convex hull  @xcite .",
    "the factor @xmath32 in can be regarded as the normalized self - confidence in the proposed model . in the extreme case of static agents ,",
    "the corresponding self - confidence is infinity .",
    "we note that in  @xcite , the inertial @xmath33 is endowed with more degrees of freedom and may follow different dynamics other than .",
    "the self - confidence @xmath17 should be distinguished from the confidence bound .",
    "the former refers to the self - weight during the convex combination , while the latter is the cut - off threshold of the neighbor set .      to evaluate a quantity @xmath34 by repeated taking noisy measurement @xmath35",
    ", one can adopt a gaussian estimator @xmath36 and update it sequentially according to bayes rule by formula @xmath37 where the inverse variance @xmath38 and @xmath26 .",
    "note that @xmath39 forms an increasing self - confidence model of a single truth and a single learner .",
    "the bayesian multi - armed bandit problem considers @xmath40 arms with unknown values @xmath41 .",
    "a learner sequentially picks arms and obtains noisy feedbacks .",
    "based on , all the @xmath42 together with the arms form an increasing self - confidence model with @xmath40 leaners and @xmath40 truths . in multi - armed bandits ,",
    "the goal is either to identify the best arm @xmath43 , or to maximize the expected cumulative rewards @xmath44 , which lies on whether and how fast @xmath28 or @xmath45 converges to @xmath46 . in the language of opinion dynamics ,",
    "the problem is whether and how fast consensus can be achieved for each pair @xmath46 and @xmath47 .",
    "let @xmath48 denote the associated adjacency matrix of @xmath8 , thus @xmath49 if @xmath14 , and otherwise @xmath50 .",
    "we use @xmath51 to denote the outdegree matrix of @xmath8 : @xmath51 is a diagonal matrix with its @xmath11-th diagonal element being the ourdegree of @xmath11 in @xmath8 .",
    "the weight matrix @xmath52 , can alternatively be defined as @xmath53 for @xmath54 , where @xmath55 is the initial self - confidence .",
    "we use the letter without the subscript @xmath11 , namely @xmath56 , to denote the column vector @xmath57 . in this symbol system , the dynamics is written as @xmath58 notice that @xmath51 is the outdegree matrix of @xmath48 , then @xmath59 is a row - stochastic matrix . for simplicity ,",
    "whenever a row @xmath11 of matrix @xmath60 is zero , the dynamics should be understood in the sense @xmath61 , since a zero row of matrix @xmath60 means the corresponding agent never interacts with anyone . without loss of generality ,",
    "we assume the initial self - confidence is 0 for each agent throughout this paper . for any matrix @xmath62 used in the paper",
    ", we use the small letter with double subscripts @xmath63 to denote the @xmath64-th element of @xmath62 .",
    "in this section , we consider the increasing self - confidence model with a truth and fixed graph @xmath65 . in this case ,",
    "@xmath66 , @xmath67 , @xmath68 , and the matrix - form dynamics becomes @xmath69 notice that , unlike the degroot model  @xcite , a sequence of the same graph does not lead to repeated multiplication of the same stochastic matrix .",
    "this is because the self - confidence of an agent will increase after it receives signals , and thus the update rule does not remain the same for different @xmath12 .    without loss of generality ,",
    "we assume that agent 1 is the truth that stays at the origin forever .",
    "thus , @xmath70 for all @xmath71 .",
    "notice that the value of @xmath72 will not affect the dynamics , hence we assume @xmath73 for convenience . by recursively adopting , we have @xmath74 let @xmath75 , then from , the dynamics of @xmath76 is written as @xmath77 by repeatedly adopting , we obtain a formula of @xmath56 as @xmath78 intuitively , if we replace the matrix @xmath79 with a real number @xmath80 , then the product of matrices in becomes @xmath81 therefore the vanishing speed is of polynomial order @xmath82 .",
    "back to the dynamics of , we claim that whether @xmath83 vanishes ( converges to the truth ) depends on the difference between 1 and the modulus of the second largest eigenvalue of @xmath79 , which in fact is the spectral gap of @xmath84 .",
    "formally , we claim :    [ th : fixed ] if the graph of the system @xmath85 is fixed , and each leaner has a path to the truth in @xmath84 , then the system converges to the truth in polynomial order @xmath0 , where @xmath86 is the spectral gap of @xmath84 .",
    "notice that under the assumption that each learner has a path to the truth , the outdegree of each agent is positive , and thus @xmath87 is invertible .",
    "the proof proceeds in two stages .",
    "we will first show that @xmath86 , then we will prove the convergence and estimate the convergence rate . since @xmath79 is a row - stochastic matrix ,",
    "therefore 1 is its largest eigenvalue . to prove that @xmath86 , it is sufficient to prove that @xmath79 does not have other eigenvalues with modulus 1 . by regarding the truth and the learners as two groups ,",
    "it is clear that @xmath79 is a block lower - triangular matrix .",
    "we use @xmath88 and @xmath89 to denote the remaining matrices by removing the first row and the first column of @xmath87 and @xmath90 , respectively .",
    "what is left to show is that @xmath91 does not have an eigenvalue @xmath92 on the unit circle in the complex plane .",
    "suppose otherwise @xmath93 for a non - zero vector @xmath94 , then @xmath95 .",
    "recall that @xmath87 is the outdegree matrix of @xmath90 , we have latexmath:[\\[\\label{eq : tau }    and the second inequality is strict if @xmath11 has an edge to the truth .",
    "suppose @xmath97 , then from @xmath95 we have @xmath98 one conclusion from is that equalities hold in , which means @xmath11 does not have an edge to the truth .",
    "furthermore , implies that for all @xmath99 , @xmath100 also has the largest modulus .",
    "therefore , by repeating the same argument of @xmath11 to @xmath15 , it is clear that @xmath15 , and hence any learner reachable from @xmath11 in @xmath84 , can not have edge to the truth .",
    "this contradicts the assumption in theorem [ th : fixed ] that each leaner has a path to the truth .",
    "therefore , @xmath101 and thus we have proved that @xmath86 .    for the convergence of the system , let @xmath102 denote the dynamics of the learners ,",
    "then it follows the update rule : @xmath103 now let @xmath104 be an invertible matrix such that the similarity transformation @xmath105 is the jordan normal form of @xmath91 , then for the vanishing speed of the product of matrices in , it is equivalent to estimate the vanishing speed of @xmath106 where @xmath107 is any jordan block of matrix @xmath105 : @xmath108 and @xmath109 is an eigenvalue of @xmath91 . since @xmath110 , and it commutes with multiples of @xmath111 in the definition of @xmath112 in , then for any @xmath113 , @xmath114 notice that @xmath104 only depends on the graph @xmath84 . as a result , @xmath115 which completes the proof .    a prevailing assumption of the graph structure in social learning is the network being strongly connected  @xcite , which guarantees the truth to be reachable by each learner .",
    "we note that the reachability of truth is similar to the definition of rooted graph in  @xcite , in which cao _ et al . _",
    "carefully analyzed the convergence of the system with fixed self - confidence .",
    "in addition to the convergence result , we prove that the bound of convergence is tight by constructing the following system .",
    "the initial positions @xmath116 for @xmath117 ; the outdegree of each learner is the same number @xmath118 ; each leaner has one edge to the truth ; and @xmath119 if and only if @xmath120 , where the subscript is understood modulo @xmath121 . in the extreme case @xmath122 , @xmath89 is a zero matrix . under this construction ,",
    "@xmath123 , and @xmath91 is a circulant matrix whose eigenvalues are straightforward to get : @xmath124 , where @xmath125 is the @xmath121-th root of unity and @xmath126 stands for the imaginary unit .",
    "it is clear to check that @xmath127 and thus @xmath128 .    on the other hand , since each learner starts at the same position and talks to the same number of learners , we have @xmath129 . in view of ,",
    "@xmath130 from taylor expansion , we have @xmath131 for any @xmath132 .",
    "therefore @xmath133 we have proved    [ prop ] for any @xmath4 , there exists a graph @xmath84 with spectral gap @xmath1 such that @xmath134 .",
    "in this section , we consider the increasing self - confidence model in changing social networks . in order to achieve consensus , information from the truth should be well spread to the learners .",
    "indeed , if an agent is not able to get signals from the truth constantly , its dynamics should eventually be free from the influence of the truth .",
    "this intuition leads to the definition and analysis of _ influence indicator_.      we use @xmath135 to denote the remaining matrix by removing the first row and the first column of @xmath136 .",
    "recall that whenever @xmath137 , @xmath138 is set to 0 for all @xmath15 .",
    "note that @xmath135 is a sub - stochastic matrix since its row - sums are no greater than 1 .",
    "if at time @xmath12 , agent @xmath11 has an edge pointing to the truth , then @xmath139 .",
    "thus , the corresponding row - sum is strictly less than one , implying non - zero impact from the truth . indeed ,",
    "if the row - sum is exactly 1 , then the dynamics of the corresponding agent is completely determined by only the learners .",
    "therefore , the difference between 1 and each row - sum of @xmath135 is an indicator of the influence from the truth .",
    "formally , we define the influence indicator from time @xmath140 to time @xmath12 , denoted by @xmath141 , as : @xmath142 where @xmath143 is the all - one column vector . when @xmath144 , is reduced to @xmath145 notice that @xmath146 indicates @xmath147 . by repeatedly left - multiplying @xmath148 to both sides of , we obtain @xmath149 which builds up the relation between the single - step indicator @xmath150 and the multi - step indicator @xmath141 .",
    "the dynamics of the learners @xmath151 is determined by the product of @xmath152 for @xmath153 : @xmath154 , and thus @xmath155 on the other hand , taking infinity norm on both sides of yields @xmath156 therefore , whether @xmath157 converges to the truth depends on the minimum value of the indicator .    to estimate the indicator ,",
    "notice that matrix @xmath135 is non - negative , thus @xmath158 .",
    "in addition , for any learner @xmath11 and time @xmath159 , @xmath160 . therefore , for any @xmath161 , @xmath162 again , when @xmath163 , then @xmath164 , and should be understood as the trivial inequality @xmath165 . in view of , , and notice that the matrices and vectors involved are all non - negative , we obtain a lower bound estimate for the indicator .",
    "formally , we have    [ lemma ] for any @xmath166 , the following inequality of the influence indicator holds : @xmath167    the inequality is element - wise .",
    "we will also use matrix inequality in the same sense for the rest of this paper .",
    "@xmath168      in this subsection , we consider the case when the graph sequence is periodic : @xmath169 for @xmath54 , where @xmath170 is the period .",
    "note that the special case @xmath171 reduces to the fixed graph scenario .",
    "we define the total outdegree of agent @xmath11 in a period @xmath172 , and its maximum @xmath173 .",
    "since the graph sequence is periodic , the self - confidence @xmath174 grows linearly .",
    "we first state our main result in this subsection :    [ th : periodic ] if the graph sequence @xmath175 is periodic , and each learner has at least one edge to the truth in a period , then the system will converge to the truth in the order @xmath176 , and the bound is tight .",
    "since each learner has at least one edge to the truth in a period , then @xmath177 for any @xmath178 , and thus each element of the indicator",
    "@xmath179 is positive .",
    "more precisely , @xmath180 and thus @xmath181 based on lemma [ lemma ] , for @xmath182 : @xmath183 in view of the last inequality and , @xmath184    now let @xmath185 , by the sub - multiplicativity of the matrix infinity norm , @xmath186 this completes the proof of convergence .    for any positive integer @xmath187 and period @xmath188 , we build a system with graph sequence @xmath8 such that @xmath189 is the graph in the proof of proposition [ prop ] , and @xmath190 is an empty graph for @xmath191 .",
    "then we have @xmath192 which completes the proof .",
    "note that @xmath187 can be interpreted as the maximum total degree centrality of all the learners , which indicates a slower convergence rate when highly - important leaner exists .",
    "now we consider the scenario when the graph @xmath8 is randomly sampled .",
    "there are various ways of generating a random graph , and we adopt the following scheme . in each step",
    ", every learner randomly picks @xmath193 agents as its neighbors , where @xmath194 is a fixed integer , and we define @xmath195 .",
    "we will show an almost - sure convergence result :    [ th : random ] assume in each step , each learner @xmath11 independently picks @xmath193 agents as its neighbors uniformly at random , then almost surely , the system converges to the truth , and the convergence rate is polynomial in @xmath12 .    since in each step",
    ", the outdegree of agent @xmath11 is the fixed number @xmath193 , then the self - confidence @xmath196 . in view of ,",
    "@xmath197 notice that @xmath198 is a bernoulli random variable with @xmath199=d_i / n$ ] .",
    "define random process @xmath200 .",
    "since @xmath198 and @xmath201 are independent for @xmath202 , then @xmath203 is again a bernoulli random variable , and @xmath204=d_2d_3\\dots d_n / n^{n-1}.\\ ] ] based on , @xmath205 we only need to show that , with probability one , the sum of the series @xmath206 goes to infinity .",
    "let @xmath207 , then @xmath208 and @xmath209=\\mathrm{var}~[\\beta(s)]=q(1-q)$ ] .",
    "define the random process @xmath210 and @xmath211 the sigma algebra generated by @xmath212",
    ". then @xmath213=\\frac{\\mathbb{e}v_s}{s}=0,\\ ] ] hence @xmath214 is a martingale .",
    "in addition , @xmath215 therefore by martingale convergence theorem , the random variable @xmath216 exists and has finite variance  @xcite . now let @xmath217 , then almost surely @xmath218 which completes the proof .",
    "we simulate the system with @xmath219 agents with @xmath220 .",
    "the initial positions of the learners are uniformly sampled in the unit interval . for each pair",
    "@xmath221 , we simulate 100 independent systems and calculate the averaged error @xmath222 .",
    "the log - log curve of each case is demonstrated in figure [ fig ] .",
    "it is clear that the curves eventually become straight lines , indicating a convergence rate of polynomial order .     and",
    "@xmath12 for @xmath219 and @xmath220 .",
    "the curves eventually become straight lines with negative slopes.[fig],scaledwidth=70.0% ]    we further use linear regression to get the slope @xmath223 of each curve after it becomes steady , and obtain a rough relation : @xmath224 , which does not depend on @xmath225 . for learner @xmath11 , when @xmath225 increases , it is more likely for the truth to be a neighbor of @xmath11 , which contributes the convergence .",
    "but in the mean time , there are more learners in the neighbor set of @xmath11 , which harms the convergence since the information from other learners is less perfect compared to the information from the truth",
    ".      the presence of multiple truths will immediately complicates the behavior of the system .",
    "for example , if a learner communicates with truth 1 enough times in order to be in the vicinity of truth 1 , and then starts to communicate with truth 2 and does the same , by repeating this process , the learner will oscillate between the two truths forever .",
    "if the system contains no truth , then the previous example could still happen : we only need to replace each truth by two colliding agents .",
    "nevertheless , from the proof of theorem [ th : fixed ] , it is clear that the components of each learner that is perpendicular to @xmath226 should vanish in polynomial order , where @xmath226 is the space spanned by all the truths .",
    "the dynamics in the perpendicular space @xmath226 is more involved in the graph sequence @xmath8 .",
    "we note that more powerful techniques are required for such general cases .",
    "in this paper , we proposed an opinion dynamics model with increasing self - confidence .",
    "the growing confidence of an agent after it repeatedly communicates with others is reflected in its increasing self - weight .",
    "we proved that , with fixed or periodically changing social network and a single truth , the system achieves consensus asymptotically and a tight convergence rate of polynomial order is obtained .",
    "if each learner randomly selects a fixed number of neighbors , then the system is proved to converge to the truth almost surely .",
    "we also discussed the behavior of the model when zero truth or multiple truths are present , which requires delicate analysis in the future ."
  ],
  "abstract_text": [
    "<S> we propose an opinion dynamics model in which agents gradually increase their own self - confidence while interacting with each other . </S>",
    "<S> the relations between the newly proposed model and existing works of social learning , inertial opinion dynamics , bayesian inference , and stochastic multi - armed bandits are demonstrated . </S>",
    "<S> we prove the convergence of the system with the existence of a truth under fixed and periodically changing social networks , and obtain tight convergence bounds related to the spectral gap of the graph laplacian and the maximum total degree centrality , respectively . in the case of </S>",
    "<S> randomly generated social networks , an almost - sure convergence result is obtained . </S>",
    "<S> the dynamics of the model with multiple truths or zero truth is also discussed .    0.3 in </S>"
  ]
}