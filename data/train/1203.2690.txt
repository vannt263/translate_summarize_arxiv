{
  "article_text": [
    "while radar systems have been in use for many decades , radar is far from being a ` solved problem ' . indeed ,",
    "exciting new developments in radar pose great challenges both to engineers and mathematicians  @xcite .",
    "two such developments are the advent of mimo ( multi - input multi - output ) radar @xcite , and the application of compressed sensing to radar signal processing @xcite .",
    "mimo radar is characterized by using multiple antennas to simultaneously transmit diverse , usually orthogonal , waveforms in addition to using multiple antennas to receive the reflected signals .",
    "mimo radar has the potential for enhancing spatial resolution and improving interference and jamming suppression .",
    "the ability of mimo radar to shape the transmit beam post facto allows for adapting the transmission based on the received data in a way which is not possible in non - mimo radar .",
    "a radar system illuminates a given area and attempts to detect and determine the location of objects of interest in its field of view , and to estimate their strength ( radar reflectivity ) .",
    "the space of interest may be divided into range - azimuth ( distance and direction ) cells , or range - doppler - azimuth ( distance , direction and speed ) cells in the case there is relative motion between the radar and the object . in many cases",
    "the radar scene is sparse in the sense that only a small fraction ( often a _ very _ small fraction ) of the cells is occupied by the objects of interest .",
    "conventional radar processing does not take into account the a - priori knowledge that the radar scene is sparse .",
    "recent works , such as @xcite developed techniques which attempt to exploit this sparsity using tools from the area of compressed sensing  @xcite .",
    "the exploitation of sparsity has the potential to improve the performance of radar systems under certain conditions and is therefore of considerable practical interest .",
    "in this paper we study the issue of sparsity in the specific context of a mimo radar system employing multiple antennas at the transmitter the receiver , where the two arrays are co - located .",
    "we note that related work on the application of compressive sensing techniques to mimo radar can be found in @xcite .",
    "our emphasis here is on developing the basic theory needed to apply sparse recovery techniques for the detection of the locations and reflectivities of targets for mimo radar .",
    "the basic model for the problem we are considering involves a linear measurement equation @xmath0 where @xmath1 is a vector of measurements collected by the receiver antennas over an observation interval , @xmath2 is a measurement matrix whose columns correspond to the signal received from a single unit - strength scatterer at a particular range - azimuth ( or range - azimuth - doppler ) cell , @xmath3 is a vector whose elements represent the complex amplitudes of the scatterers , and @xmath4 is a noise vector .",
    "the measurement equation is assumed to be under - determined , possibly highly under - determined .",
    "the sparsity of the radar scene is introduced by assuming that only @xmath5 elements of the vector @xmath3 are non - zero , where @xmath5 is much smaller than the dimension of the vector . the measurement matrix @xmath2 embodies in it the details of the radar system such as the transmitted waveforms and the structure of antenna array .    in this paper",
    "we study the conditions under which this problem has a satisfactory solution .",
    "this is a fundamental issue of both theoretical and practical importance .",
    "more specifically , the analysis presented in the following sections addresses the following issues :    * it is known from the theory of compressed sensing @xcite that the matrix @xmath2 must satisfy certain conditions in order that the solution computed via an appropriate convex program will indeed coincide with the desired sparsest solution ( whose computation is in general an np - hard problem ) . in our problem",
    "the characteristics of this matrix depend on the choice of the radar waveforms and the number and positions of the transmit and receive antennas .",
    "we develop the results necessary for understanding how the selection of the parameters of the radar system affects the conditions mentioned above . *",
    "the ability of the algorithm to correctly detect targets depends on the number of these targets , @xmath5 , and the signal to noise ratio .",
    "we show that as long as the number of the targets is less than a maximal value @xmath6 , and the signal to noise is larger than some minimal value @xmath7 , the targets can be correctly detected with high probability by solving an @xmath8-regularized least squares problem known under the name _",
    "lasso_. explicit formulas are presented for @xmath6 and @xmath7 as a function of the number of transmit and receive antennas and the number of azimuth and range cells .",
    "the structure of the paper is as follows .",
    "subsection  [ ss : notation ] introduces notation used throughout the paper . in section  [",
    "s : setup ] we describe the problem formulation and the setup .",
    "we derive conditions for the recovery of targets in the doppler - free case in section  [ s : nodoppler ] , and the case of detecting targets in presence of doppler is analyzed in section  [ s : doppler ] .",
    "our theoretical results are supported by numerical simulations , see section  [ s : numerics ] .",
    "we conclude in section  [ s : conclusion ] .",
    "finally , some auxiliary results are collected in the appendices .",
    "let @xmath9 . as usual , we define latexmath:[$\\|\\vv\\|_1 : = \\sum_{k=1}^{n }    for a given matrix @xmath2 we denote its @xmath11-th column by @xmath12 and the element in the @xmath13-th row and @xmath11-th column by @xmath14}$ ] .",
    "the operator norm of @xmath2 is the largest singular value of @xmath2 and is denoted by @xmath15 , the frobenius norm of @xmath2 is @xmath16}|^2}$ ] .",
    "the coherence of @xmath2 is defined as @xmath17 for @xmath18 , let @xmath19 denote the circulant translation operator , defined by @xmath20 where @xmath21 is understood modulo @xmath22 , and let @xmath23 be the modulation operator defined by @xmath24",
    "we refer to  @xcite for the mathematical foundations of radar and to  @xcite for an introduction to mimo radar . however , the reader needs only a very basic knowledge of the mathematical concepts underlying radar to be able to follow our approach .",
    "we consider a mimo radar employing @xmath25 antennas at the transmitter and @xmath26 antennas at the receiver .",
    "we assume that the element spacing is sufficiently small so that the radar return from a given scatterer is fully correlated across the array .",
    "in other words , this is a coherent propagation scenario .    to simplify the presentation",
    "we assume that the two arrays are co - located , i.e. this is a mono - static radar .",
    "the extension to the bi - static case is straightforward as long as the coherency assumption holds for each array .",
    "the arrays are characterized by the array manifolds : @xmath27 for the receive array and @xmath28 for the transmit array , where @xmath29 is the direction relative to the array .",
    "we assume that the arrays and all the scatterers are in the same 2-d plane .",
    "the extension to the 3-d case is straightforward and all of the following results hold for that case as well .    for convenience",
    "we formulate our theorems and analysis in terms of delay @xmath30 instead of range @xmath31 .",
    "this is no loss of generality , as delay and range are related by @xmath32 , with @xmath33 denoting the speed of light .",
    "the @xmath13-th transmit antenna repeatedly transmits the signal @xmath34 .",
    "let @xmath35 be the @xmath36 noise - free received signal matrix from a unit strength target at direction @xmath37 and delay @xmath30 , where @xmath38 is the number of samples in time .",
    "then @xmath39 where @xmath40 is an @xmath41 matrix whose columns are the circularly delayed signals @xmath42 , sampled at the discrete time points @xmath43 .",
    "if @xmath44 , we often write simply @xmath45 instead of @xmath46 .",
    "assuming uniformly spaced linear arrays , the array manifolds are given by @xmath47\\ ] ] and @xmath48\\ ] ] where @xmath49 and @xmath50 are the normalized spacings ( distance divided by wavelength ) between the elements of the transmit and receive arrays , respectively .",
    "the spatial characteristics of a mimo radar are closely related to that of a virtual array with @xmath51 antennas , whose array manifold is @xmath52 .",
    "it is known @xcite that the following choices for the spacing of the transmit and receive array spacing will yield a uniformly spaced virtual array with half wavelength spacing : @xmath53 both of these choices lead to a virtual array whose aperture is @xmath54 wavelengths .",
    "this is the largest virtual aperture free of grating lobes .",
    "the choices   and   will also show up in our theoretical analysis , e.g.  see theorem  [ th : lasso ] .",
    "next let @xmath55 be the noise - free vectorized received signal .",
    "we set up a discrete delay - azimuth grid @xmath56 , where @xmath57 and @xmath58 denote the corresponding discretization stepsizes .",
    "using vectors @xmath59 for all grid points @xmath60 we construct a complete response matrix @xmath2 whose columns are @xmath59 for @xmath61 and @xmath62 . in other words",
    ", we have @xmath63 delay values and @xmath64 azimuth values , so that @xmath2 is a @xmath65 matrix .",
    "assume that the radar illuminates a scene consisting of @xmath5 scatterers located on @xmath5 points of the @xmath66 grid .",
    "let @xmath3 be a sparse vector whose non - zero elements are the complex amplitudes of the scatterers in the scene .",
    "the zero elements corresponds to grid points which are not occupied by scatterers .",
    "we can then define the radar signal @xmath1 received from this scene by @xmath67 where @xmath1 is a @xmath68 vector , @xmath3 is a @xmath69 sparse vector , @xmath70 is a @xmath68 complex gaussian noise vector , and @xmath2 is a @xmath71 matrix .",
    "the discussion so far was for the case of a stationary radar scene and a fixed radar , in which case there is no doppler shift .",
    "the extension of this signal model to include the doppler effect is conceptually straightforward , but leads to a significant increase in the problem dimension .    the signal model for the return from a unit strength scatterer at direction @xmath37 , delay @xmath30 , and doppler @xmath72 ( corresponding to its radial velocity with respect to the radar ) is given by @xmath73 where @xmath74 is a @xmath41 matrix whose columns are the circularly delayed and doppler shifted signals @xmath75 .    as before we let @xmath76 be the noise - free vectorized received signal",
    "we extend the discrete delay - azimuth grid by adding a discretized doppler component ( with stepsize @xmath77 and corresponding doppler values @xmath78 ) and obtain a uniform delay - azimuth - doppler grid @xmath79 . using vectors @xmath80 for all discrete @xmath81 we construct a complete response matrix @xmath2 whose columns are @xmath80 for @xmath61 , @xmath62 , @xmath82 .",
    "assume that the radar illuminates a scene consisting of @xmath5 scatterers located on @xmath5 points of the @xmath83 grid .",
    "let @xmath3 be a sparse vector whose non - zero elements are the complex amplitudes of the scatterers in the scene .",
    "the zero elements corresponds to grid points which are not occupied by scatterers .",
    "we can then define the radar signal received from this scene @xmath1 by    @xmath84    where @xmath1 is a @xmath68 vector , @xmath3 is a @xmath85 sparse vector , @xmath70 is a @xmath68 complex gaussian noise vector , and @xmath2 is a @xmath86 matrix .",
    "we define the _ sign function _ for a vector @xmath87 as @xmath88    we introduce the following _ generic @xmath5-sparse target model _ :    * the support @xmath89 of the @xmath5 nonzero coefficients of @xmath3 is selected uniformly at random .",
    "* the non - zero coefficients of @xmath90 form a steinhaus sequence , i.e. , the phases of the non - zero entries of @xmath3 are random and uniformly distributed in @xmath91",
    ".    we do not impose any condition on the amplitudes of the non - zero entries of @xmath3 .",
    "we do assume however that the targets are exactly located at the discretized grid points .",
    "this is certainly an idealized assumption , that is not satisfied in this strict sense in practice , resulting in a `` gridding error '' .",
    "we refer the reader to  @xcite for an initial analysis of the associated perturbation error , and to  @xcite for an interesting numerical approach to deal with this issue .      a standard approach to find a sparse ( and under appropriate conditions _ the sparsest _ ) solution to a noisy system @xmath92 is via @xmath93 which is also known as lasso  @xcite . here",
    "@xmath94 is a regularization parameter .    in this paper",
    "we adopt the following two - step version of lasso . in the first step",
    "we compute an estimate @xmath95 for the support of @xmath3 by solving  . in the second step",
    "we estimate the amplitudes of @xmath3 by solving the reduced - size least squares problem @xmath96 , where @xmath97 is the submatrix of @xmath2 consisting of the columns corresponding to the index set @xmath95 , and similarly for @xmath98 .",
    "this is a standard way to `` debias '' the solution , we thus will call this approach in the sequel _ debiased lasso_.",
    "we assume that @xmath34 is a periodic , continuous - time white gaussian noise signal of period - duration @xmath99 seconds and bandwidth @xmath100 .",
    "the transmit waveforms are normalized so that the total transmit power is fixed , independent of the number of transmit antennas .",
    "thus , we assume that the entries of @xmath34 have variance @xmath101 .",
    "it is convenient to introduce the finite - length vector @xmath102 associated with @xmath103 , via @xmath104 , where @xmath105 and @xmath106 .",
    "[ th : lasso ] consider @xmath0 , where @xmath2 is as defined in subsection  [ ss : nodoppler ] and @xmath107 .",
    "choose the discretization stepsizes to be @xmath108 and @xmath109 .",
    "let @xmath110 or @xmath111 , and suppose that @xmath112 if @xmath3 is drawn from the generic @xmath5-sparse target model with @xmath113 for some constant @xmath114 , and if @xmath115 then the solution @xmath116 of the debiased lasso computed with @xmath117 obeys @xmath118 with probability at least @xmath119 and @xmath120 with probability at least @xmath121 where @xmath122 @xmath123 @xmath124 and @xmath125    * remark : *    * while the expressions for the probability of success in the above theorem are admittedly somewhat unpleasant , we point out that the individual terms are fairly small .",
    "moreover , the probabilities can easily be made smaller by slightly increasing the constants in the assumptions on @xmath126 .",
    "* the assumptions in   are fairly mild and easy to satisfy in practice .",
    "* we emphasize that there is no constraint on the dynamic range of the target amplitudes",
    ". the lasso estimate will recover all target locations correctly as long as they exceed the noise level  , regardless of the dynamical range between the targets .",
    "* we note that @xmath127 is the signal - to - noise ratio for the @xmath11-th scatterer at the receiver array input .",
    "the measurement vector @xmath1 provides @xmath128 measurements of @xmath129 .",
    "therefore it is useful to define the signal - to - noise ratio associated with the @xmath11-th scatterer as @xmath130 .",
    "this is often referred to as the output snr because it is the effective snr at the output of a matched - filter receiver .",
    "equation   can thus be written as @xmath131 , however , the factor 200 is definitely way too conservative . as is evident from the comments following theorem 1.3 in  @xcite",
    ", one can replace the factor 10 in   by a factor @xmath132 for some @xmath133 , at the cost of a somewhat reduced probability of success and some slightly stronger conditions on the coherence and sparsity .",
    "this indicates that the snr condition for which perfect target detection can be achieved is @xmath134 where @xmath135 is a constant of size @xmath136 .",
    "* the condition that the target locations are assumed to be random can likely be removed by using a different proof technique that relies on a dual certificate approach ( e.g. see  @xcite ) and tools developed in  @xcite .",
    "we do not pursue this direction in this paper .",
    "the proof of theorem  [ th : lasso ] is carried out in several steps .",
    "we need two key estimates , one concerns a bound for the operator norm of @xmath2 , the other one concerns a bound for the coherence of @xmath2 .",
    "we start with deriving a bound for @xmath15 .",
    "[ th : normbound ] let @xmath2 be as defined in theorem  [ th : lasso ] .",
    "then @xmath137 where @xmath138 is some numerical constant .",
    "there holds @xmath139 .",
    "it is convenient to consider @xmath140 as block matrix @xmath141 where the blocks @xmath142 are matrices of size @xmath143 .",
    "we claim that @xmath140 is a block - toeplitz matrix ( i.e. , @xmath144 ) and the individual blocks @xmath145 are circulant matrices . to see this , recall the structure of @xmath2 and consider the entry @xmath146}$ ] , @xmath147 : @xmath148 }   =   ( \\va \\va^{\\ast})_{[i , l;i',l ' ] } =   \\sum_{\\beta } \\sum_{\\tau } \\va_{[i , l;\\beta,\\tau ] }   \\va_{[i',l';\\beta,\\tau ] } \\notag",
    "\\\\   = \\sum_{\\beta } \\sum_{n=1}^{n_\\tau } \\ar_i   \\sum_{k=1}^{n_t } \\at_k s_k(l \\delta_t - n \\delta_\\tau ) \\conj{\\ar}_{i ' }   \\overline{\\sum_{k'=1}^{n_t } \\at_{k ' } s_{k'}(l ' \\delta_t - n \\delta_\\tau ) } \\notag \\\\   =   \\sum_{\\beta }",
    "\\ar_i \\conj{\\ar}_{i ' }   \\sum_{k=1}^{n_t } \\sum_{k'=1}^{n_t } \\at_k \\conj{\\at}_{k ' }   \\sum_{n=1}^{n_\\tau } s_k(l \\delta_t   - n \\delta_\\tau )   \\overline{s_{k'}(l ' \\delta_t   - n \\delta_\\tau ) } \\notag \\\\",
    "=   \\sum_{\\beta } e^{j2\\pi d_r ( i - i ' ) \\beta } \\sum_{k=1}^{n_t } \\sum_{k'=1}^{n_t } e^{j2\\pi d_t ( k - k')\\beta } \\sum_{n=1}^{n_\\tau } s_k(l\\delta_t - n \\delta_\\tau )   \\overline{s_{k'}(l ' \\delta_t - n \\delta_\\tau ) } , \\label{matrixstructure}\\end{gathered}\\ ] ] where we used the delay discretization @xmath149 .",
    "the block - toeplitz structure , @xmath150 , follows from observing that the expression   depends on the difference @xmath151 , but not on the individual values of @xmath152 .",
    "the circulant structure of an individual block @xmath145 ( @xmath152 are now fixed ) follows readily from noting that @xmath153 since we have chosen @xmath154 and since the shifts are circulant in this case .",
    "we will now show that the blocks @xmath155 are actually zero - matrices for @xmath156 . for convenience",
    "we introduce the notation @xmath157 substituting @xmath110 ( the very similar calculation for @xmath158 is left to the reader ) and the discretization @xmath159 with @xmath160 in   we can write @xmath148 } =   \\sum_{n=\\nfrom}^{\\nto } e^{j2\\pi \\frac{n_t}{2 } ( i - i ' ) \\frac{2n}{n_r n_t } } \\sum_{k=1}^{n_t } \\sum_{k'=1}^{n_t }   e^{j2\\pi \\frac{1}{2}(k - k')\\frac{2n}{n_r n_t } } g_{k , k'}(l , l ' ) \\notag\\\\ = \\sum_{k=1}^{n_t } \\sum_{k'=1}^{n_t } g_{k , k'}(l , l ' ) \\sum_{n=0}^{n_r n_t-1 } e^{j2\\pi n_t ( i - i ' ) \\frac{n}{n_r n_t } } e^{j2\\pi(k - k')\\frac{n}{n_r n_t}}.   \\label{bsum}\\end{gathered}\\ ] ] we analyze the inner summation in   separately .",
    "@xmath161 hence @xmath148 }   = n_t \\sum_{k=1}^{n_t } \\sum_{k'=1}^{n_t } \\delta_{k - k ' } g_{k , k'}(l , l ' ) \\sum_{n_2=0}^{n_r-1 }   \\underbrace{e^{j2\\pi(k - k')\\frac{n_2}{n_r n_t}}}_{\\text{$=1 $ for $ k = k'$ } }   e^{j2\\pi ( i - i ' ) \\frac{n_2}{n_r } }   \\\\ = n_t \\sum_{k=1}^{n_t } g_{k , k}(l , l ' ) \\sum_{n_2=0}^{n_r-1 } e^{j2\\pi ( i - i ' ) \\frac{n_2}{n_r } }    = n_t n_r \\sum_{k=1}^{n_t } g_{k , k}(l , l ' ) \\delta_{i - i'}.\\end{gathered}\\ ] ] thus , @xmath162 for @xmath163 , and @xmath164 is indeed a block - diagonal matrix , which in turn implies @xmath165 .",
    "but due to the block - toeplitz structure of @xmath164 we have @xmath166 .",
    "therefore @xmath167    to bound @xmath168 we utilize its circulant structure as well as tail bounds of quadratic forms .",
    "let @xmath169 be the first column of @xmath170 , then @xmath171 where @xmath172 is the fourier transform of @xmath169 . from our previous computations we have ( after a change of variables )",
    "@xmath173 we will rewrite this expression so that we can apply lemma  [ le : quadform ] to bound @xmath174 . let @xmath175 denote the translation operator on @xmath176 as introduced in   and define the @xmath177 block - diagonal matrix @xmath178 by @xmath179 furthermore , let @xmath180^t$ ] , then @xmath181 and therefore @xmath182 where we have denoted @xmath183 for @xmath184 and @xmath185 .",
    "it follows from   and standard properties of the fourier transform that the matrix @xmath186 is a block - diagonal matrix with @xmath25 blocks of size @xmath143 , where each non - zero entry of such a block has absolute value @xmath187 .",
    "furthermore , a little algebra shows that @xmath188 , @xmath189 , @xmath190 , and @xmath191 we can now apply lemma  [ le : quadform ] ( keeping in mind that @xmath192 ) and obtain @xmath193 where @xmath138 is some numerical constant .",
    "choosing @xmath194 gives @xmath195 for @xmath196 .",
    "forming the union bound over the @xmath38 possibilities for @xmath197 gives @xmath198    we recall that @xmath199 , and substitute   into   to complete the proof .",
    "next we estimate the coherence of @xmath2 .",
    "since the columns of @xmath2 do not all have the same norm , we will proceed in two steps .",
    "first we bound the modulus of the inner product of any two columns of @xmath2 and then use this result to bound the coherence of a properly normalized version of @xmath2 . since the columns of @xmath2 depend on azimuth and delay , we index them via the double - index @xmath200 .",
    "thus the @xmath200-th column of @xmath2 is @xmath201 .",
    "[ th : coherencebound ] let @xmath2 be as defined in theorem  [ th : lasso ] .",
    "assume that @xmath202 then @xmath203 with probability at least @xmath204 .",
    "we assume @xmath205 and leave the case @xmath206 to the reader .",
    "we need to find an upper bound for @xmath207 it follows from the definition of @xmath208 via a simple calculation that @xmath209 from which we readily compute @xmath210 we use the discretization @xmath211 , @xmath212 , where @xmath108 , @xmath213 , with @xmath214 , and obtain after a standard calculation @xmath215 and @xmath216 as a consequence of  , concerning @xmath217 we only need to focus on the case @xmath218 for @xmath219 . moreover , since @xmath220 and @xmath221 to @xmath222 .",
    "we split our analysis into three cases , ( i ) @xmath223 , ( ii ) @xmath224 , and ( iii ) @xmath225 .",
    "* case ( i ) @xmath223 : * we will first find a bound for @xmath226 and then invoke lemma  [ le : concentration3 ] to obtain a bound for @xmath227 .    0 using the definitions of @xmath228 and @xmath229 and @xmath230 , ( or @xmath205 ) , and substituting the discretization @xmath231 with @xmath108 for @xmath232 , we obtain @xmath233 if @xmath234",
    ", then @xmath235 , whence @xmath236 .",
    "assume now that @xmath237 , using   we get @xmath238 based on   and  , to bound @xmath227 we only need to consider those @xmath239 for which @xmath240 is not a multiple of @xmath26 , in which case @xmath229 and @xmath241 are orthogonal .",
    "we have @xmath242 by lemma  [ le : concentration3 ] there holds @xmath243 for all @xmath244 , where @xmath245 and @xmath246 .",
    "we choose @xmath247 in   and get @xmath248 we claim that @xmath249 to verify this claim we first note that   is equivalent to @xmath250 using both assumptions in   and the fact that @xmath251 we obtain @xmath252 which establishes  .",
    "substituting now   into   gives @xmath253 to bound @xmath254 we only have to take the union bound over @xmath187 different possibilities associated with @xmath217 , as @xmath255 .",
    "forming now the union bound , and using  , yields @xmath256    0 case ( ii ) : @xmath257 ;    we have that @xmath258 ( this needs to be made more precise ) .",
    "thus , instead of @xmath259 we consider for now @xmath260 .",
    "using the definitions of @xmath228 and @xmath229 and @xmath230 , ( or @xmath205 ) , we calculate @xmath261    * case ( ii ) @xmath224 : * we need to consider the case @xmath262 where @xmath263 , @xmath264 , with @xmath218 for @xmath265 . since the entries of @xmath45 are i.i.d .",
    "gaussian random variables , it follows that the entries of @xmath266 are i.i.d .",
    "@xmath267-distributed , and similar for @xmath268 . moreover , the fact that @xmath269 implies that @xmath266 and @xmath268 are independent . consequently , the entries of @xmath270 are jointly independent",
    ". therefore , we can apply lemma  [ le : gaussianinner ] with @xmath271 , form the union bound over the @xmath272 possibilities associated with @xmath30 ( we do not take advantage of the fact we actually have only @xmath273 and not @xmath63 possibilities for @xmath30 ) and @xmath217 ( here , we take again into account property  ) , and eventually obtain @xmath274    * case ( iii ) @xmath275 : * we need to find an upper bound for @xmath276 where @xmath277 . since since each of the entries of @xmath266 and of @xmath278 is a sum of @xmath25 i.i.d .",
    "gaussian random variables of variance @xmath279 , we can write @xmath280 . note that the terms @xmath281 in this sum are no longer all jointly independent . but similar to the proof of theorem 5.1 in  @xcite we observe that for any @xmath282 we can split the index set @xmath283 into two subsets @xmath284 , each of size @xmath285 , such that the @xmath285 variables @xmath286 are jointly independent for @xmath287 , and analogous for @xmath288 .",
    "( for convenience we assume here that @xmath38 is even , but with a negligible modification the argument also applies for odd @xmath38 . ) in other words , each of the sums @xmath289 , contains only jointly independent terms",
    ". hence we can apply lemma  [ le : gaussianinner ] and obtain @xmath290 for all @xmath291 .",
    "choosing @xmath292 gives @xmath293 condition   implies that @xmath294 , hence the estimate in   becomes @xmath295 using equation  , inequality  , and the pigeonhole principle , we obtain @xmath296 combining this estimate with   yields @xmath297 we apply the union bound over the @xmath298 different possibilities and arrive at @xmath299 where the maximum is taken over all @xmath300 with @xmath301 .",
    "an inspection of the bounds  , , and   establishes  , which is what we wanted to prove .",
    "the key to proving theorem  [ th : lasso ] is to combine lemma  [ th : normbound ] and lemma  [ th : coherencebound ] with theorem  [ th : cp ] .",
    "the latter theorem requires the matrix to have columns of unit - norm , whereas the columns of our matrix @xmath2 have all different norms ( although the norms concentrate nicely around @xmath302 ) .",
    "thus instead of @xmath303 we now consider @xmath304 here @xmath305 is the @xmath306 diagonal matrix defined by @xmath307 in the noise - free case we can easily recover @xmath3 from @xmath308 via @xmath309 . in the noisy case we will utilize the fact that for proper choices of @xmath310 the associated lasso solutions of   and  , respectively , have the same support , see also the proof of theorem  [ th : lasso ] .",
    "the following lemma gives a bound for @xmath311 and @xmath312 in terms of the corresponding bounds for @xmath2 .",
    "[ le : tildebounds ] let @xmath313 , where the @xmath305 the diagonal matrix is defined by  . under the conditions of theorem",
    "[ th : lasso ] , there holds @xmath314 where @xmath315 , and @xmath316 where @xmath317 .",
    "we have @xmath318 recall that @xmath319 hence @xmath320 .",
    "since the entries @xmath321 , we have @xmath322 , and thus by lemma  [ le : concentration1 ] @xmath323 for all @xmath291 , hence @xmath324 choosing @xmath325 in   and forming the union bound only over the @xmath187 different possibilities associated with @xmath37 ( note that @xmath326 for all @xmath30 ) , gives @xmath327 the diligent reader may convince herself that the probability in   is indeed close to one under the condition  .",
    "we insert   and   into   and obtain @xmath328 which proves  .    to establish   we first note that @xmath329 where @xmath330 . using lemma  [ le : concentration1 ] and   we compute @xmath331 therefore @xmath332 and thus @xmath333 by choosing @xmath334 , we can write   as @xmath335 finally , plugging   into   and using   we arrive at @xmath336    we are now ready to prove theorem  [ th : lasso ] . among others",
    "it hinges on a ( complex version of a ) theorem by cands and plan  @xcite , which is stated in appendix b.    * proof of theorem  [ th : lasso ] : * we first point out that the assumptions of theorem  [ th : lasso ] imply that the conditions of lemma  [ th : normbound ] and lemma  [ th : coherencebound ] are fulfilled . for lemma",
    "[ th : normbound ] this is obvious .",
    "concerning lemma  [ th : coherencebound ] , an easy calculation shows that the conditions @xmath337 and @xmath338 indeed yield that @xmath339 .",
    "note that the solution @xmath116 of   and the solution @xmath340 of the following lasso problem @xmath341 satisfy @xmath342 .",
    "we will first establish the claims in theorem  [ th : lasso ] for the system @xmath343 in   where @xmath344 , @xmath345 and then switch back to @xmath303 .",
    "we verify first condition  .",
    "property   and the fact that @xmath346 imply that @xmath347 using lemma  [ le : concentration1 ] we get that @xmath348 choosing @xmath349 and combining   with   gives @xmath350 with probability at least @xmath351 , thus establishing condition  .    note that @xmath352 has unit - norm columns as required by theorem  [ th : cp ] .",
    "it remains to verify condition  . using the assumption  , and",
    "the coherence bound   we compute @xmath353 which holds with probability as in  , and thus the coherence property   is fulfilled .",
    "furthermore , using   we see that condition   implies @xmath354 with probability as stated in  . thus assumption   of theorem  [ th : cp ]",
    "is also fulfilled ( with high probability ) and we obtain that @xmath355 we note that the relation @xmath356 holds with the same probability as the relation @xmath357 ( see equation  ) , since @xmath358 and multiplication by an invertible diagonal matrix does not change the support of a vector .",
    "this establishes   with the corresponding probability .    as a consequence of   we",
    "have the following error bound @xmath359 which holds with probability at least @xmath360 where the probabilities @xmath361 are as in  lemma  [ le : tildebounds ] .",
    "using the fact that @xmath362 , we compute @xmath363 or , equivalently , @xmath364 proceeding along the lines of  - , we estimate @xmath365 the bound   follows now from combining   with   and  .",
    "in this section we analyze the case of moving targets / antennas , as described in  [ ss : doppler ] . as in the stationary setting",
    ", we assume that @xmath34 is a periodic , continuous - time white gaussian noise signal of period - duration @xmath99 seconds and bandwidth @xmath100 .",
    "the transmit waveforms are normalized so that the total transmit power is fixed , independent of the number of transmit antennas .",
    "thus , we assume that the entries of @xmath34 have variance @xmath101 .",
    "[ th : doppler ] consider @xmath0 , where @xmath2 is as defined in subsection  [ ss : doppler ] and @xmath107 .",
    "choose the discretization stepsizes to be @xmath108 , @xmath109 and @xmath366 .",
    "let @xmath110 or @xmath111 , and suppose that @xmath367 if @xmath3 is drawn from the generic @xmath5-sparse target model with @xmath368 for some constant @xmath114 , and if @xmath369 then the solution @xmath116 of the debiased lasso computed with @xmath370 obeys @xmath371 with probability at least @xmath119 and @xmath372 with probability at least @xmath121 where @xmath373 @xmath374 @xmath375 and @xmath376    the proof is very similar to that of theorem  [ th : lasso ] . below we will establish the analogs of the key steps , lemma  [ th : normbound ] , lemma  [ th : coherencebound ] , and lemma  [ le : tildebounds ] , and leave the rest to the reader .",
    "[ th : normboundoppler ] let @xmath2 be as defined in theorem  [ th : doppler ] .",
    "then @xmath377    we proceed as in the proof of lemma  [ th : normbound ]",
    ". there holds @xmath139 .",
    "it is convenient to consider @xmath140 as block matrix @xmath141 where the blocks @xmath142 are matrices of size @xmath143 .",
    "we claim that @xmath140 is a block - toeplitz matrix ( i.e. , @xmath144 ) and the individual blocks @xmath145 are circulant matrices . to see this , recall the structure of @xmath2 and consider the entry @xmath146}$ ] , @xmath147 : @xmath148 }   =   ( \\va \\va^{\\ast})_{[i , l;i',l ' ] } =   \\sum_{\\beta } \\sum_{\\tau } \\sum_{f}^{}\\va_{[i , l;\\tau , f,\\beta ] }   \\va_{[i',l';\\tau , f,\\beta]}\\notag \\\\   =   \\sum_{\\beta } e^{j2\\pi d_r ( i - i ' ) \\beta } \\sum_{k=1}^{n_t } \\sum_{k'=1}^{n_t } e^{j2\\pi d_t ( k - k')\\beta } g_{k , k'}(l , l ' ) \\sum_{m=1}^{n_f } e^{j2\\pi ( l - l')\\delta_t m\\delta_f } \\notag\\\\   =   \\sum_{n=0}^{n_r n_t-1 } e^{j2\\pi ( i - i')\\frac{nn_t}{n_r n_t } } \\sum_{k=1}^{n_t } \\sum_{k'=1}^{n_t } e^{j2\\pi ( k - k')\\frac{n}{n_r n_t } } g_{k , k'}(l , l ' ) n_f",
    "\\delta_{l - l ' } \\label{eq : expsum}\\\\ = n_t n_r n_f \\sum_{k=1}^{n_t } \\|\\vs_{k}\\|^2 \\delta_{i - i'}\\delta_{l - l ' }   \\label{matrixstructuredoppler}\\end{gathered}\\ ] ] where we have used in   that @xmath378 , whence @xmath379 .",
    "thus @xmath380 i.e. , @xmath140 is just a scaled identity matrix . since @xmath381 is a gaussian random vector with @xmath382 , lemma  [ le : concentration1 ] yields @xmath383 where we note that @xmath384 .",
    "we choose @xmath385 , and obtain , after forming the union bound over @xmath386 , @xmath387 the bound   now follows from  .",
    "next we establish a coherence bound for @xmath2 .",
    "[ th : coherencedoppler ] let @xmath2 be as defined in the doppler case .",
    "assume that @xmath388 where @xmath389 .",
    "then @xmath390 with probability at least @xmath391 .",
    "we have that @xmath392 .",
    "a standard calculation shows that @xmath393 , thus we only need to consider @xmath394 . as in the proof of lemma",
    "[ th : coherencebound ] we distinguish several cases .",
    "* case ( a ) @xmath395 : * in this case we are concerned with @xmath396 , which is the same as case ( i ) of lemma  [ th : coherencebound ] , except that in the present case we have a bit more flexibility in choosing @xmath397 in the analogous version of  .",
    "here we can choose @xmath398 , where @xmath399 .",
    "proceeding then as in the proof of case  ( i ) of lemma  [ th : coherencebound ] we obtain @xmath400    * case ( b ) @xmath401 : * this is exactly the same as case ( ii ) of lemma  [ th : coherencebound ] .",
    "we obtain @xmath402    * case ( c ) @xmath403 : * it is well known that @xmath404 . hence , by parseval s theorem , @xmath405 .",
    "since the normal distribution is invariant under fourier transform , this case is therefore already covered by case ( b ) , and we leave the details to the reader .",
    "we get @xmath406    * case ( d ) @xmath407 : * this is similar to case ( ii ) of lemma  [ th : coherencebound ] .",
    "the only difference is that we have @xmath408 different possibilities to consider when forming the union bound ( the additional factor @xmath409 is of course due to frequency shifts associated with the doppler effect ) .",
    "thus in this case the bound reads @xmath410    * case ( e ) @xmath411 : * we need to bound @xmath412 , where we recall that @xmath278 is a gaussian random vector with variance @xmath25 .",
    "( we note that a related case is covered by theorem 5.1 in  @xcite , which considers @xmath413 , where @xmath414 is a steinhaus sequence . )",
    "this case is essentially taken care off by case ( iii ) of lemma  [ th : coherencebound ] , by noting that a gaussian random vector of variance @xmath415 remains gaussian ( with the same @xmath415 ) when pointwise multiplied by a fixed vector with entries from the torus .",
    "the only difference is that , as in case ( d ) above , we have @xmath408 different possibilities to consider when forming the union bound .",
    "hence , the bound in this case becomes @xmath416    [ le : tildeboundsdoppler ] let @xmath313 , where the entries of the @xmath417 diagonal matrix are given by @xmath418 . under the conditions of theorem",
    "[ th : lasso ] there holds @xmath419 where @xmath420 and @xmath421 where @xmath422    since the proof of this lemma follows closely that of lemma  [ le : tildebounds ] , we omit it .",
    "next we illustrate the performance of the compressive mimo radar developed in previous sections .",
    "we consider a doppler - free scenario .",
    "the following parameters are used in this example : @xmath423 transmit antennas , @xmath424 receive antennas , @xmath425 samples , @xmath426 range values .    at each experiment",
    "@xmath5 scatterers of unit amplitude are placed randomly on the range / azimuth grid , i.e the vector @xmath3 has @xmath5 unit entries at random locations along the vector .",
    "white gaussian noise is added to the composite data vector @xmath427 with variance @xmath428 determined to as to produce the specified output signal - to - noise ratio ( see also item ( iv ) of the remark after theorem  [ th : lasso ] ) .",
    "the lasso solution @xmath429 is calculated with @xmath310 as specified in theorem  [ th : lasso ] . the numerical algorithm to solve",
    "was implemented in matlab using tfocs  @xcite .",
    "the experiment is repeated @xmath430 times using independent noise realizations .",
    "the probabilities of detection @xmath431 and false alarm @xmath432 are computed as follows .",
    "the values of the estimated vector @xmath429 corresponding to the true scatterer locations are compared to a threshold .",
    "detection is declared whenever a value exceeds the threshold .",
    "the probability of detection is defined as the number of detections divided by the total number of scatterers @xmath5 .",
    "next the values of the estimated vector @xmath429 corresponding to locations not containing scatterers are compared to a threshold .",
    "a false alarm is declared whenever one of these values exceeds the threshold .",
    "the probability of false alarm is defined as the number of false alarms divided by the total number of scatterers @xmath5 .",
    "the probabilities of detection and false alarm are averaged over the 100 repetitions of the experiment .",
    "the probabilities are re - computed for a range of values of the threshold to produce the so - called receiver operating characteristics ( roc ) @xcite - the graph of @xmath431 vs. @xmath432 . as the threshold decreases , the probability of detection increases and so does the probability of false alarm . in practice the threshold is usually adjusted to as to achieve a specified probability of false alarm .",
    "figures [ fig1 ] , [ fig2 ] , [ fig3 ] and [ fig4 ] depict the roc for different values of the output signal to noise ratio .",
    "we note that the probability of detection increases as the snr increases and decreases as @xmath5 , the number of scatterers increases .    :",
    "@xmath433.,width=480,height=316 ]    : @xmath433.,width=480,height=316 ]    : @xmath433.,width=480,height=316 ]    : @xmath433.,width=480,height=316 ]",
    "techniques from compressive sensing and sparse approximation make it possible to exploit the sparseness of radar scenes to potentially improve system performance of mimo radar . in this paper we have derived a mathematical framework that yields explicit conditions for the radar waveforms and the transmit and receive arrays so that the radar sensing matrix has small coherence and robust sparse recovery in the presence of noise becomes possible .",
    "our approach relies on a deterministic ( and very specific ) positioning of transmit and receive antennas and random waveforms .",
    "it seems plausible that results similar to the ones derived in this paper can be established for the case where the antenna locations are chosen at random and the transmission signals are deterministic .",
    "this would be of interest , since one could then potentially take advantage of specific properties of recently designed deterministic radar waveforms such as in  @xcite .",
    "in this appendix we collect some auxiliary results .",
    "* proposition 34 ) [ le : concentration1 ] let @xmath18 be a vector with @xmath434 , then for every @xmath435 one has @xmath436    0 the real - valued version of the following lemma can be found e.g. in  @xcite , its extension to the complex case is straightforward .    [",
    "le : concentration4 ] let @xmath437 a gaussian random matrix with @xmath438 .",
    "then for all @xmath439 and all @xmath244 we have @xmath440    we get @xmath441    as a consequence we obtain    [ le : concentration7 ] let @xmath437 be a gaussian random matrix with @xmath442 . then for all @xmath443 with @xmath444 and @xmath445 , there holds for @xmath244 : @xmath446    we only prove the real - valued case , as the complex version follows readily .",
    "the parallelogram identity gives @xmath447 furthermore we have @xmath448 , whence @xmath449 we apply the concentration inequality   to @xmath450 and @xmath451 and obtain @xmath452 and therefore @xmath453 by combining these estimates and then substituting in   we obtain  .    in this appendix",
    "we collect some auxiliary results .",
    "the following lemma , which relates moments and tails , can be found e.g.  in  ( * ? ? ?",
    "* proposition 6.5 ) .",
    "[ le : moments ] suppose @xmath454 is a random variable satisfying @xmath455 for some constants @xmath456",
    ". then @xmath457 for all @xmath458 .",
    "0 we will need the following tail bound estimate for rademacher chaos of order two .",
    "this bound can be extracted from various theorems or proofs in the literature . for convenience",
    "we present a version that is most suitable for our purposes .",
    "[ le : quadform ] let @xmath459 be a matrix and let @xmath460 be independent rademacher random variables .",
    "denote @xmath461 then @xmath462 where @xmath138 is a numerical constant independent of @xmath463 and @xmath22 .",
    "let @xmath464 we will use the moment bound for rademacher chaos ( see @xcite ) @xmath465 a straightforward computation gives @xmath466 .",
    "we now invoke lemma  [ le : moments ] , using @xmath467 and @xmath468 in  , and obtain @xmath469 where @xmath135 is some numerical constant independent of @xmath22 and @xmath463 .",
    "the following lemma is a rescaled version of lemma 3.1 in  @xcite .",
    "[ le : concentration3 ] let @xmath437 be a gaussian random matrix with @xmath470 .",
    "then for all @xmath443 with @xmath445 and all @xmath291 @xmath471 with @xmath245 and @xmath472 .    0 recall that a random variable @xmath473 is called _ subgaussian _ if there are constants @xmath474 such that @xmath475 if @xmath476 , then equivalently , @xmath473 is subgaussian if there is a constant @xmath477 , called _ scale _ , such @xmath478 in this case the constants @xmath474 in   are given by @xmath479",
    ".    the following result must be well - known , but since we could not find a proper reference we include a proof ( due to a.  soshnikov ) for completeness .",
    "[ le : sasha ] let @xmath480 be an i.i.d .",
    "subgaussian random vector with scale @xmath5 and let @xmath481 an @xmath482 unitary matrix .",
    "then the entries of the vector @xmath483 are also independent and subgaussian with scale @xmath5 .",
    "we denote @xmath484 .",
    "we need to show that there is a constant @xmath477 such that @xmath485 for all @xmath486 and all @xmath487 . there holds @xmath488 where independence of the @xmath489 was used in the second step and the unitarity of @xmath490 in the last step .",
    "we leave it to the reader to extend this result to complex subgaussian random vectors .",
    "the following two lemmata might be of independent interest , they are extensions of results in  @xcite from gaussian to subgaussian random variables .    [ le : circmat1 ] given a sequence @xmath491 of i.i.d .  complex subgaussian random variables with scale @xmath5 ,",
    "let @xmath135 be the @xmath482 circulant matrix @xmath492 then the sequence @xmath493 of eigenvalues of @xmath135 is distributed as @xmath22 independent complex subgaussian random variables with scale @xmath5 .",
    "it is well known that the eigenvalues of @xmath135 are given by the entries of @xmath494 , where @xmath495 is the @xmath482 ( unitary ) discrete fourier transform matrix and @xmath496^{t}$ ] .",
    "the results follows now by applying lemma  [ le : sasha ] .",
    "[ le : circmat2 ] let @xmath497 be a hermitian @xmath482 circulant matrix of the form @xmath498 where @xmath499 are independent , @xmath500 for @xmath501 , @xmath502 and @xmath503 ( if @xmath22 is even ) are real subgaussian with scale @xmath504 , @xmath505 are complex subgaussian with scale @xmath5 .",
    "then the eigenvalues of @xmath497 are independent real subgaussian random variables with scale @xmath5",
    ".    we can write @xmath497 as @xmath506 , where @xmath135 is as in lemma  [ le : circmat1 ] . since @xmath135 is normal , the eigenvalues of @xmath135 are @xmath507 . by lemma",
    "[ le : circmat1 ] , these are distributed as @xmath22 independent real subgaussian random variables with scale @xmath5 .    the next lemma is a slight generalization of a result by hanson and wright on tail bounds for quadratic forms  @xcite .",
    "[ le : quadform ] let @xmath459 be a normal matrix and let @xmath508 be independent , @xmath267-distributed random variables . denote @xmath509 then for all @xmath291 @xmath510 where @xmath135 is a numerical constant independent of @xmath463 and @xmath22 .",
    "the proof follows essentially the same steps as the proof of the main theorem in  @xcite , which considers the case where @xmath463 is hermitian and the @xmath489 are real - valued . extending the @xmath489 to",
    "the complex case is trivial , thus the only modification that needs to be addressed is the extension of @xmath463 from the hermitian to the normal case .",
    "but lemma  5 in  @xcite holds for normal matrices as well , therefore the lemma follows .",
    "0    the following large deviation inequality for random variables with `` mixed tails '' is due to roman vershynin  @xcite .    [ le : mixedtails ] let @xmath511 be mean - zero i.i.d .  random variables with @xmath512 where @xmath477 is some parameter that may depend on the @xmath489 and on @xmath22 .",
    "then @xmath513    there holds @xmath514 hence @xmath515 where @xmath33 is an absolute constant .",
    "here we have used that @xmath516 and the standard ways to estimate @xmath517 elaborate ....    therefore @xmath518 we optimize in @xmath397 : let @xmath519 if @xmath520 , i.e. , if @xmath521 .",
    "then @xmath522 if @xmath523 then let @xmath524 , whence @xmath525 and the proof is complete .    for convenience we state the following version of bernstein s inequality , which will be used in the proof of lemma  [ le : gaussianinner ] .",
    "[ th : bernstein ] let @xmath526 be independent random variables with zero mean such that @xmath527 for some constants @xmath477 and @xmath528 .",
    "then , for all @xmath291 @xmath529 where @xmath530",
    ".    we also need the following deviation inequality for unbounded random variables .",
    "it is a complex - valued and slightly sharpened version of lemma  6 in @xcite , the better constant will be useful when we apply lemma  [ le : gaussianinner ] in the proof of lemma  [ th : coherencebound ] .    [ le : gaussianinner ] let @xmath531 and @xmath532 , @xmath533 , be sequences of i.i.d .",
    "complex gaussian random variables with variance @xmath415 .",
    "then , @xmath534    in order to apply bernstein s inequality , we need to compute the moments @xmath535 .",
    "since @xmath531 and @xmath532 are independent , there holds @xmath536 the moments of @xmath531 are well - known : @xmath537 hence @xmath538 we apply bernstein s inequality   with @xmath539 and @xmath540 and obtain  .",
    "we consider a general linear system of equations @xmath541 , where @xmath542 , @xmath543 and @xmath544 .",
    "we introduce the following generic @xmath5-sparse model :    * the support @xmath545 of the @xmath5 nonzero coefficients of @xmath3 is selected uniformly at random . * the non - zero entries of @xmath90 form a steinhaus sequence , i.e.",
    ", @xmath546 is a complex random variable that is uniformly distributed on the unit circle .",
    "the following theorem is a slightly extended version of theorem  1.3 in  @xcite .",
    "[ th : cp ] given @xmath547 , where @xmath548 has all unit-@xmath549-norm columns , @xmath3 is drawn from the generic @xmath5-sparse model and @xmath550 .",
    "assume that @xmath551 where @xmath552 is a constant independent of @xmath553 .",
    "furthermore , suppose @xmath554 for some constant @xmath555 and that @xmath556 then the solution @xmath429 to the debiased lasso computed with @xmath557 obeys @xmath558 and @xmath559 with probability at least @xmath560    the paper  @xcite treats only the real - values case .",
    "however it is not difficult to see that the results by cands and plan can be extended to the complex setting if their definition of the sign - function is replaced by   and consequently their generic sparse model is replaced by the generic sparsity model introduced in the beginning of this appendix .",
    "the proofs of the theorems in  @xcite can then be easily adapted to the complex case via some straightforward modifications , such as replacing in many steps @xmath561 by its real part , @xmath562 and replacing certain scalar quantities by its conjugate analogs . to give a concrete example of such a modification , consider ( in the notation of  @xcite ) the inequality right before eq.(3.10 ) in  @xcite ,",
    "@xmath563 this inequality needs to be replaced by its complex counterpart @xmath564 by carrying out these easy modifications ( the details of which are left to the reader ) we can readily establish   analogous to ( 1.11 ) of theorem  1.3 in  @xcite .",
    "once we have recovered the support of @xmath3 , call it @xmath565 , we can solve for the coefficients of @xmath3 by solving the standard least squares problem @xmath566 , where @xmath567 is tbe submatrix of @xmath2 whose columns correspond to the support set @xmath565 , and similarly for @xmath568 .",
    "statement   follows by noting that the proof of theorem  3.2 in  @xcite yields as side result that with high probability the eigenvalues of any submatrix @xmath569 with @xmath570 are contained in the interval @xmath571 $ ] , which of course implies that @xmath572 .",
    "the statement follows now by substituting this bound into the standard error bound , eq .",
    "( 5.8.11 ) in  @xcite .",
    "t.s .  wants to thank sasha soshnikov for helpful discussions on random matrix theory and haichao wang for a careful reading of the manuscript .",
    "h.  rauhut .",
    "compressive sensing and structured random matrices . in _",
    "theoretical foundations and numerical methods for sparse recovery _ , volume  9 of _ radon series comp .",
    "_ , pages 192 .",
    "degruyter , 2010 .",
    "r.  vershynin .",
    "introduction to the non - asymptotic analysis of random matrices . in yonina  c. eldar and gitta kutyniok , editors , _ compressed sensing : theory and applications_. cambridge university press , 2010 . to appear .",
    "preprint available at http://www-personal.umich.edu/~romanv/papers/papers.html ."
  ],
  "abstract_text": [
    "<S> we consider a multiple - input - multiple - output radar system and derive a theoretical framework for the recoverability of targets in the azimuth - range domain and the azimuth - range - doppler domain via sparse approximation algorithms . </S>",
    "<S> using tools developed in the area of compressive sensing , we prove bounds on the number of detectable targets and the achievable resolution in the presence of additive noise . </S>",
    "<S> our theoretical findings are validated by numerical simulations .    </S>",
    "<S> * keywords : * sparsity , radar , compressive sensing , random matrix , mimo </S>"
  ]
}