{
  "article_text": [
    "consider two discrete - time , stationary , zero - mean , ( real - valued for notational convenience ) random processes @xmath1 and @xmath2 ( @xmath3 ) having power spectral densities @xmath4 and @xmath5 ( @xmath6 $ ] ) , and autocorrelation functions @xmath7 and @xmath8 ( @xmath9 ) , respectively , i.e. , @xmath10 and similarly for the `` hatted '' quantities . when the power spectrum contains a singular part , then @xmath11 needs to be replaced by a non - negative finite spectral measure @xmath12 .",
    "we are interested in quantifying the distance between respective spectra and statistics for two such random process @xmath1 and @xmath2 .",
    "when two vectors @xmath13 , \\mbox { and}\\\\ \\hat{{\\rm r}}_n&:=&\\left[\\begin{matrix}r_0&r_1&\\ldots & r_{n-1}\\end{matrix}\\right]\\end{aligned}\\ ] ] of autocorrelation samples are available and need to be compared , one may use any metric in @xmath14 for that purpose , as for instance @xmath15 .",
    "however , we are not aware of any significance that can be attached to such a distance other than the fact that it is a metric in @xmath14 .",
    "our goal in this paper , is to seek a metric which can be physically motivated .",
    "similarly , if we are to compare @xmath4 and @xmath5 , it appears difficult to motivate the use of an @xmath16-distance @xmath17 .",
    "for one thing , the @xmath16-distance can not be generalized to deal with spectral measures when singular parts are present .",
    "there are certainly other alternatives . in the speech processing literature in particular",
    "there is a plethora of distances that , however , are not metrics @xcite but have been motivated by specific needs .",
    "function theoretic alternatives that one can use ( e.g. , @xmath18-norms , etc . ) including wasserstein - like transportation measures typically lack a physical interpretation . in a recent study @xcite a pseudometric",
    "was constructed as a geodesic between spectral densities / measures with respect to a rather natural riemannian metric this metric quantifies the degradation of predictive - error variance when the predictor is designed based on the wrong choice between two alternatives and the geometry is , in essence , euclidean but only after we transform spectral densities using the logarithmic map .    in the current paper we focus on the @xmath0 distance @xmath19 which has also a rather natural interpretation . after a brief discussion of the relevance of the @xmath0-distance , following a similar rationale",
    ", we will develop an analogous metric between finite partial covariance data of the corresponding random processes .",
    "given @xmath1 and @xmath2 we postulate that ther exist two random processes @xmath20 and @xmath21 so that @xmath22 alternatively , we postulate that there exists a random process @xmath23 and that the two original random processes relate to @xmath23 via @xmath24 it is natural to seek such perturbations of minimal total combined variance @xmath25 that is sufficient to `` reconcile '' the two processes .",
    "the combined variance @xmath26 represents the minimal amount of `` energy '' of perturbations in the two time - series that is needed to render the two indistinguishable .",
    "intuitively , the minimal combined variance which is consistent with the available data quantifies the distance between the two .",
    "given @xmath27 , the optimal choice consists of random processes @xmath20 and @xmath28 such that @xmath20 and @xmath28 are independent , @xmath2 and @xmath21 are also independent , and    @xmath29    then , the power spectrum of the `` sum '' @xmath30 is simply @xmath31,\\ ] ] and @xmath32 obviously , this construction extends in the obvious way to the case of not - necessarily absolutely continuous power spectra as well , and the metric includes the measure of any discrepancies between the singular parts of the two spectral measures . ] ] clearly , @xmath33 is a metric as seen from ( [ l1 ] ) .",
    "building on a similar rationale , in the next section , we develop a metric for covariance matrices .",
    "it is often the case that only a finite segment of the autocorrelation function of time - series @xmath1 and @xmath2 is available ( and even then , possibly uncertain ) .",
    "thus , it is of interest to consider distances between the partial autocorrelation statistics @xmath34 and @xmath35 . to this end , we follow the dictum of the previous section and define as a distance measure the minimal combined variance of random processes @xmath20 and @xmath21 for which ( [ equalityholds ] ) holds .",
    "naturally , since only partial covariance samples are available , the random processes @xmath36 and ( [ equalityholds ] ) need to be consistent with these data .",
    "first denote by @xmath37\\ ] ] the @xmath38 covariance matrix corresponding to @xmath1 and the covariance samples in @xmath39 and , similarly , @xmath40 for the toeplitz matrix based on @xmath41 . if @xmath42 denote the corresponding finite toeplitz covariances of the random processes @xmath20 and @xmath21 , respectively , for which ( [ equalityholds ] ) holds , then @xmath43 and the minimal sum @xmath44 of the respective variances can serve as a metric quantifying the distance between @xmath45 and @xmath46 .    the computation of @xmath42 minimizing",
    "the sum @xmath44 , or equivalently minimizing @xmath47 is a convex problem since the positivity constraints are convex .",
    "the toeplitz structure is peripheral , and the idea of defining such metrics extends equally well to non - negative definite hermitian matrices and to more general positive operators . for notational convenience",
    "we develop the framework in the context of real symmetric matrices .",
    "so , we let @xmath48 be the cone of non - negative symmetric @xmath38-matrices and @xmath49 be the cone of non - negative toeplitz matrices in @xmath50 .",
    "we address the case of matrices in @xmath50 and define a suitable metric , which is then specialized to @xmath51 .",
    "[ proposition2]let @xmath52 and @xmath53 then @xmath54 defines a metric on @xmath50 .",
    "given @xmath52 , @xmath55 is a ( convex ) cone of non - negative definite matrices .",
    "it follows that there is an element @xmath56 having minimal trace .",
    "clearly @xmath57 is symmetric in its arguments and takes positive values unless @xmath58 , in which case @xmath59 .",
    "thus , we only need to prove the triangle inequality . given @xmath60 for @xmath61 ,",
    "we denote by @xmath62 corresponding minimal elements as above for @xmath63 , and we let @xmath64 these matrices are non - negative by construction , the identities @xmath65 hold , and @xmath66 for @xmath63 . but then , @xmath67 and hence , @xmath68 from the minimal property of @xmath69 and of @xmath70 with regard to having the least value for the combined trace so that @xmath71 , it follows that @xmath72 therefore , @xmath73 which completes the proof.@xmath74    we now observe that the steps of the proof of proposition [ proposition2 ] permit incorporating linear constraints on the structure of elements of @xmath50 , such as the constraint of all matrices being toeplitz .",
    "hence , whereas @xmath75 may be used directly as a distance measure between elements of @xmath51 , the corresponding minimal - trace perturbations @xmath76 may not belong to @xmath51 in general .",
    "but , since the toeplitz property is a linear constraint , we may define a completely analogous distance measure enforcing such perturbations ( if so desired ) to be toeplitz .",
    "[ proposition3]let @xmath77 and @xmath78 then @xmath79 defines a metric on @xmath51 .",
    "the proof follows the steps of the proof of proposition [ proposition2 ] verbatim , except for the fact that we now constraint all matrices to belong to @xmath51.@xmath74    [ proposition4]let @xmath80 , @xmath81 be power spectral densities , i.e. , nonnegative and integrable on @xmath82 $ ] .",
    "let as before @xmath83 , @xmath84 denote the corresponding toeplitz covariance matrices , and let @xmath85 .",
    "then @xmath86    clearly @xmath87 since a choice of @xmath20 and @xmath28 with power spectra as in ( [ psi]-[psihat ] ) gives rise to partial covariance matrices @xmath88 , @xmath89 , for all @xmath90 , for which ( [ rq ] ) holds .",
    "the respective @xmath91th elements @xmath92 and @xmath93 remain the same for all @xmath90 and the left hand side is @xmath94 since the power spectra in ( [ psi]-[psihat ] ) have no overlap in their support .    to show the converse inequality , consider the sequence of minimizing @xmath88 , @xmath89 .",
    "these are toeplitz matrices with bounded entries ( since their corresponding @xmath91th element is bounded by @xmath95 ) .",
    "each can be extended to an infinite toeplitz matrix , and thereby , gives rise to power spectral densities @xmath96 and @xmath97 such that the first @xmath90 fourier coefficients of @xmath98 and @xmath99 coincide .",
    "the spectral densities @xmath96 and @xmath97 can be obtained from @xmath88 , @xmath89 by any particular positive extension , for instance a `` maximum entropy '' one .",
    "we can take those as pairs , and since they are bounded there exists a subsequence weakly convergent to possibly non - negative measures , @xmath100 and @xmath101 , such that @xmath102 since their fourier coefficients must coincide . if @xmath100 , @xmath101 do have singular parts then these should be identical and the absolutely continuous parts must balance as well , so there exist power spectral densities @xmath103 and @xmath104 such that @xmath105 but then , @xmath106 the last inequality from ( [ balance ] ) . @xmath74",
    "the metric @xmath107 of the previous section admits no simple expression in terms of the respective eigenvalues .",
    "this should be contrasted with its limiting value @xmath33 which is the @xmath0 distance between the corresponding power spectral densities .",
    "we highlight this with an example .",
    "let @xmath108\\ ] ] and @xmath109.\\ ] ] then , clearly , @xmath110\\ ] ] and @xmath111\\ ] ] where @xmath112 and @xmath113 is minimal subject to @xmath114 as well as @xmath115 .",
    "the last two inequalities imply that @xmath116 it follows that the optimal choice ( minimal @xmath113 ) is @xmath117 then @xmath118 while the respective eigenvalues are @xmath119 it appears that there is no simple expression for @xmath120 based solely on knowledge of @xmath121 and @xmath122 .",
    "the covariance @xmath123 has a unique extension and corresponds to a measure with unit weight at @xmath124 , i.e. , a spectral line ( dirac delta ) at @xmath124 . assuming that @xmath125 originates from a spectral measure which has a similar weight of amplitude @xmath126 at @xmath124 and a uniform absolutely continuous part of amplitude @xmath126 , then @xmath127 adding the @xmath0-norm of the difference of the absolutely continuous parts with the absolute integral of the discrepancy between the two measures",
    "we leave it as an exercise to the reader to verify that if @xmath84 is as we just assumed , namely @xmath128 for @xmath129 , and similarly , @xmath130 for all @xmath131 , then @xmath132 as @xmath133 .",
    "it is often the case that the autocovariance matrix @xmath83 of a random process @xmath1 is estimated in a way that does not guarantee this to be toeplitz .",
    "for instance , it is quite common for @xmath83 to be estimated by averaging observation samples @xmath134 \\left[\\begin{array}{ccc}y_{1+\\ell}&\\ldots&y_{n+\\ell}\\end{array}\\right]\\ ] ] the estimate @xmath135 is non - negative definite by construction , but may not be toeplitz . yet",
    ", for purposes of analysis it is often beneficial to approximate @xmath136 by a toeplitz one , or possibly , by one with additional structure ( e.g. , corresponding to a moving average process or , more generally , to the state of a known dynamical system ) .",
    "the problem of seeking such an approximant which is closest to @xmath136 in @xmath75 , is readily solvable via convex optimization .      in @xcite ,",
    "the question was raised as to what are appropriate ways to approximate a given sample covariance with one that abides by a known linear structure .",
    "it was proposed that the kullback - leibler - von neuman distance @xmath137 provides a convenient convex functional for which the optimal approximant is uniquely defined .",
    "an academic example was presented in @xcite which is recapitulated here as it helps underscore differences with approximation in the sense of minimizing @xmath138 .",
    "consider the positive - definite matrix below as the estimated value for a covariance matrix @xmath139.\\ ] ] the minimizer of @xmath140 is unique ( see @xcite ) and given by @xmath141.\\ ] ] it is interesting to point out the the closest toeplitz matrix to @xmath142 in the least - squares sense fails to be positive - definite ( @xcite , cf .",
    "@xcite ) . on the other hand ,",
    "the optimal approximant in @xmath75-sense can be obtained by observation and is equal to @xmath143.\\ ] ] in the above , a second subscript indicates the sense in which the matrix approximates @xmath144 .",
    "obviously the traces of @xmath145 and @xmath144 are not the same , in general .",
    "however , equality of the traces can be easily imposed as an added linear constraint .      for purposes of illustration ,",
    "consider a moving average process @xmath146 where @xmath147 is a zero - mean , unit - variance , gaussian white noise process .",
    "the autocorrelation sequence of @xmath1 is @xmath148= \\left[\\begin{matrix } 3&2 & 1 & 0 & 0 & \\ldots\\end{matrix}\\right].\\ ] ] simulating @xmath1 over a window @xmath149 , and based on a particular such realization , the corresponding @xmath38 sample covariance matrix , for @xmath150 , was computed to be @xmath151.\\ ] ] obviously , this matrix is not toeplitz due to the finiteness of the observation record .",
    "the closest toeplitz approximant to @xmath152 , in the sense of the metric @xmath75 , turns out to be @xmath153\\ ] ] for which @xmath154 interestingly , @xmath155 does not correspond to a moving average process of order @xmath156 ( or even , of order @xmath157 ) as it can be readily verified by the fact that the trigonometric polynomials , e.g. , @xmath158 takes negative values .",
    "the set of covariance matrices which are generated by moving average processes of a given order , is convex and admits a characterization via a set of linear matrix inequalities ( @xcite ) .",
    "thus , the closest approximant to @xmath142 which corresponds to a moving average process of any given order can be readily computed . in particular ,",
    "if we specify the order to be @xmath156 , then the optimal approximant to @xmath159 becomes @xmath160\\ ] ] for which @xmath161      t.t .",
    "georgiou ( 2003 ) toeplitz covariance matrices and the von neumann relative entropy . in : k. hashimoto , y. oishi , and y. yamamoto ( eds ) control and modeling of complex systems : cybernetics in the 21st century .",
    "ma : birkhauser , boston"
  ],
  "abstract_text": [
    "<S> we begin with an interpretation of the @xmath0-distance between two power spectral densities and then , following an analogous rationale , we develop a natural metric for quantifying distance between respective covariance matrices . </S>"
  ]
}