{
  "article_text": [
    "let @xmath11 be a @xmath3-tall vector whose components @xmath12 are random variables ( not necessarily independent ) @xmath13 \\ ; .\\ ] ] next , sample @xmath2 independent vectors @xmath14 ; creating a @xmath15 matrix @xmath1 .",
    "then , the _ random gram matrix _ of size @xmath2 , @xmath16 has a distribution that depends on the underlying distribution of the random vector @xmath11 .",
    "( the symbol @xmath17 as a superscript is used to denote transpose . )    some general features and convergence properties of the eigenvalues of certain random gram matrices were derived by fannes and spincemaille @xcite .",
    "fyodorov formulated correlation functions for permanental polynomials of certain random matrices and noted some similarities and differences between their characteristic and permanental polynomials @xcite .",
    "our paper presents combinatorial theory and an efficient algorithm for calculating @xmath18 and @xmath10 , which are factors comprising the coefficients of the expected characteristic and expected permanental polynomials of @xmath8 .",
    "the computation of the determinant is equivalent to matrix multiplication and is therefore contained in the complexity class p ( see chapter 16 of @xcite ) .",
    "currently , the fastest asymptotic algorithm for matrix multiplication is @xmath19 @xcite , with a recent unpublished work @xcite claiming an improvement to @xmath20 .",
    "some researchers have suggested that group theoretic observations imply that @xmath21 algorithms also exist @xcite .    at the other complexity extreme , even though the sign is the only difference between the formula for the determinant , @xmath22 and the formula for the permanent , @xmath23 the computation of the permanent is # p - complete @xcite .",
    "the standard reference for properties of permanents is minc @xcite .",
    "the most efficient algorithm currently known for calculating the exact permanent has complexity @xmath24 , due to ryser @xcite .",
    "jerrum and sinclair provided a fully - polynomial randomized approximation scheme for approximating permanents of nonnegative matrices @xcite .",
    "matrix permanents have found applications in physics for calculating bose - einstein corrections @xcite and in quantum computing for encoding quantum circuit amplitudes @xcite .",
    "permanental polynomials have been used as invariants for chemical structures @xcite .",
    "the rest of the paper is organized as follows : section 2 is a statement of results , section 3 contains all proofs , section 4 reports on some numerical experiments , section 5 points out a connection to prior work involving the cycle index polynomial of the symmetric group , and section 6 presents summary and conclusions .",
    "before stating our results , we explain all notation . let @xmath11 be a @xmath3-tall vector whose components @xmath12 are random variables ( not necessarily independent ) .",
    "let @xmath1 be a @xmath0 matrix whose columns are a random sample of @xmath2 vectors @xmath25 .",
    "let @xmath4 ; we call @xmath26 _ the random gram matrix of size _",
    "@xmath2 , it being understood that the exact distribution of @xmath26 depends on the underlying distribution on @xmath3-dimensional vectors @xmath27 .",
    "although @xmath26 is an @xmath28 matrix , its rank is at most @xmath3 , and generally speaking we take the viewpoint henceforth that @xmath2 is much larger than @xmath3 .",
    "one may even regard @xmath3 as fixed , and @xmath29 , as we study the effect of taking larger and larger samples .",
    "we are especially interested in two expected values , the determinant and the permanent of @xmath26 ; these are denoted @xmath30 respectively : @xmath31 we define @xmath32 to be the @xmath33 matrix of underlying second moments , @xmath34 and define the infinite sequence @xmath35 as the traces of the powers of @xmath32 : @xmath36 finally , we define @xmath37 , @xmath38 , to be the sign - adjusted coefficients of the characteristic polynomial of @xmath32 , with the familiar indexing : @xmath39    [ theorem1 ] let @xmath40 , @xmath41 , @xmath35 denote @xmath18 , @xmath10 , @xmath42 , respectively , as given above . then , @xmath43 and @xmath44    the generating function identities in the previous theorem lead immediately to recursions for the sequences @xmath30 as given in the corollary :    [ corollary2 ] let @xmath40 , @xmath41 , @xmath35 denote @xmath18 , @xmath10 , @xmath42 , respectively , as given above . then , we have the recursions @xmath45 and @xmath46    the next theorem relates the expected values @xmath47 to the coefficients @xmath37 of the characteristic polynomial for @xmath32 .",
    "[ theorem3 ] let @xmath26 , @xmath32 , @xmath48 be respectively the random gram matrix of size @xmath2 , the underlying @xmath33 matrix of second moments , and the sign - adjusted coefficients of the characteristic polynomial , @xmath49 then @xmath50 and @xmath51 \\ , ( 1-c_1x + c_2x^2 - \\cdots)^{-1}.\\ ] ]    the last theorem concerns the expected values of the coefficients of the characteristic and permanental polynomials of @xmath26 .",
    "[ theorem4 ] let @xmath40 , @xmath41 denote @xmath18 , @xmath10 , respectively , as given above .",
    "let @xmath52 be the sign - adjusted coefficients of , respectively , the characteristic and permanental polynomials @xmath26 : @xmath53 then , @xmath54 and @xmath55    * remark .",
    "* the characteristic polynomials @xmath56 and @xmath57 have exactly ( including multiplicity ) the same nonzero roots .",
    "with @xmath1 a @xmath15 matrix , and assuming @xmath58 , then , the latter characteristic polynomial has a factor of @xmath59 , and so @xmath60 for @xmath61 .",
    "this is consistent with the fact that the @xmath62 are nonzero for at most @xmath38 .",
    "the leibniz formula for the determinant is @xmath63 with @xmath64 where @xmath65 is the _ symmetric group _ on @xmath66 , and @xmath67 signifies the _ sign _ of the permutation @xmath68 .",
    "similarly , for the permanent , @xmath69    since expectation is a linear operator , @xmath70 may be obtained by the following strategy @xmath71 furthermore , @xmath72 can be obtained in the same manner but omitting step @xmath73 .      continuing the proof",
    ", we introduce the sign of the permutation to obtain @xmath96 we are now in position to carry out the three - step strategy ( * ) proposed above .",
    "the number of permutations @xmath68 which have a given cycle structure @xmath97 is @xmath98 if we multiply the right side of ( [ eqsignedexpect ] ) by the latter multiplicity and by @xmath99  note the resulting cancellation of @xmath100  and then sum over all sequences @xmath97 of nonnegative integers which are zero from some point on , we obtain the desired exponential generating function .",
    "hence , @xmath101 as was to be shown .",
    "this completes the proof of the first part of theorem  [ theorem1 ] .",
    "the second part of the theorem , equation ( [ eqgfperm ] ) giving the exponential generating function of the sequence of permanents @xmath41 , is proven in a similar manner .",
    "these are proven in the standard manner by comparing the coefficients of @xmath102 on both sides of the identities obtained from ( [ eqgfdet ] ) and ( [ eqgfperm ] ) by differentiating with respect to @xmath103 .    in the next proof of theorem [ theorem3 ]",
    "we use the identity @xmath104 valid for any complex square matrix @xmath105 .",
    "see , for example , section 1.1.10 , item 7 , page 11 of [ @xcite ] , where the identity is attributed to jacobi .",
    "we start with the expected determinant , @xmath106 \\exp{\\left\\lbrace\\frac{t_{1}x}{1}-\\frac{t_{2}x^{2}}{2}+\\frac{t_{3}x^{3}}{3}- \\dots\\right\\rbrace } .\\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ] \\exp { \\left\\lbrace \\trace\\left ( \\frac{m^{1}x}{1}-\\frac{m^{2}x^{2}}{2}+\\frac{m^{3}x^{3}}{3}- \\dots \\right ) \\right\\rbrace } \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ] \\det { \\left ( \\exp{\\left\\lbrace   \\frac{m^{1}x}{1}-\\frac{m^{2}x^{2}}{2}+\\frac{m^{3}x^{3}}{3}- \\dots \\right\\rbrace } \\right ) }   \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ] \\det { \\left ( \\exp \\left\\lbrace \\log{(i+xm ) } \\right\\rbrace \\right ) } \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ] \\det{(i+xm ) }   \\\\   & = \\left [ \\frac{x^{n}}{n ! } \\right ]   ( -x)^{t } \\cdot \\det{(\\lambda i - m ) \\vert_{\\lambda=-\\frac{1}{x } } } \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ]   ( -x)^{t } \\left ( \\lambda^{t } - c_{1}\\lambda^{t-1 } + \\cdots \\right ) \\vert_{\\lambda=-\\frac{1}{x } } \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ]   ( -x)^{t } \\left ( \\left(-\\frac{1}{x}\\right)^{t } - c_{1}\\left(-\\frac{1}{x}\\right)^{t-1 } + \\cdots \\right ) \\\\   & = \\left [ \\frac{x^{n}}{n ! } \\right ] \\left(1 + c_{1}x + c_{2}x^{2 } + c_{3}x^{3 } + \\cdots \\right )     \\\\   & = n!c_{n } \\ ; \\ ; \\nonumber .\\end{aligned}\\ ] ] the first equality comes from ( [ eqgfdet ] ) , the third from ( [ eqexptrace ] ) , and the rest are straightforward manipulations . the proof for the expected permanent is similar : @xmath107 \\exp{\\left\\lbrace\\frac{t_{1}x}{1}+\\frac{t_{2}x^{2}}{2}+\\frac{t_{3}x^{3}}{3}+ \\dots\\right\\rbrace } \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ] \\exp { \\left\\lbrace \\trace\\left ( \\frac{m^{1}x}{1}+\\frac{m^{2}x^{2}}{2}+\\frac{m^{3}x^{3}}{3}+ \\dots \\right ) \\right\\rbrace } \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ] \\det { \\left ( \\exp{\\left\\lbrace   \\frac{m^{1}x}{1}+\\frac{m^{2}x^{2}}{2}+\\frac{m^{3}x^{3}}{3}+ \\dots \\right\\rbrace } \\right ) }   \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ] \\det { \\left ( \\exp \\left\\lbrace \\log{(i - xm)^{-1 } } \\right\\rbrace \\right ) } \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ] \\det{(i - xm)^{-1 } }   \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ] \\frac{1}{\\det{(i - xm ) } } \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ]   \\dfrac{1}{(x)^{t } \\cdot \\det{(\\lambda i - m ) } \\vert_{\\lambda=\\frac{1}{x } } } \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ]   \\frac{1}{(x)^{t } \\left ( \\left(\\frac{1}{x}\\right)^{t } - c_{1}\\left(\\frac{1}{x}\\right)^{t-1 } + \\cdots \\right ) } \\\\ & = \\left [ \\frac{x^{n}}{n ! } \\right ]   \\frac{1 } {               1 - c_{1}x + c_2x^2 - c_3x^3 + \\cdots                                               } \\end{aligned}\\ ] ] this time the first equality follows from ( [ eqgfperm ] ) , the third again is from ( [ eqexptrace ] ) , and , as was the case with the determinant , the rest are straightforward manipulations .    * remark . * the function @xmath108 where @xmath17 is hashimoto s edge adjacency operator , is called the _ ihara zeta - function of the graph _",
    "@xmath109 , see @xcite , @xcite .    for simplicity ,",
    "let us assume the probability distribution on vectors @xmath11 is discrete ; say , @xmath110 , @xmath111 , @xmath112 with probabilities @xmath113 , @xmath114 , @xmath112 . in order to obtain a term @xmath59 in the expansion of @xmath115",
    ", we choose the @xmath116 @xmath117 s from the main diagonal , and then expand the remaining principal submatrix of size @xmath3 .",
    "since the remaining submatrix is that of @xmath118 , we obtain the sign - adjustment @xmath119 and find @xmath120 since expectation is a linear operator , the expected value of the @xmath75th coefficient of the characteristic polynomial of @xmath121 is @xmath122 this proves the first assertion of the theorem , and the second assertion regarding the permanental polynomial is demonstrated in a similar manner .",
    "we wrote a matlab program to compare the expected characteristic and permanental polynomials given by theorem  [ theorem4 ] to those of randomly sampled matrices of various sizes .",
    "we computed all permanents using a programmatic link with maple via the maple toolbox for matlab , and all characteristic polynomials using the matlab command _",
    "poly_.    there are , of course , infinitely many different distributions which might underly the vectors @xmath11 .",
    "we chose to use one based on _",
    "sample counts_. this is an easily understood distribution , and of interest for possible applications . the idea is to assume a set @xmath123 of size @xmath3 , @xmath124 , with probabilities @xmath125 , where @xmath126 .",
    "we take a sample , with replacement , from @xmath123 of size @xmath127 , and record @xmath128 as the number of times that the element @xmath129 is chosen .",
    "then , each of our @xmath3-tall vectors @xmath11 is integral , satisfies @xmath130 , and the distribution on these vectors is the familiar multinomial distribution : @xmath131 = \\left [ \\begin{array}{c } b_{1 } \\\\",
    "b_{2 } \\\\ \\vdots \\\\",
    "b_{t } \\end{array } \\right ] \\right\\rbrace = { \\binom{l}{b_{1 } \\dots b_{t } } } p_{1}^{b_{1 } } \\cdots p_{t}^{b_{t } } \\ ; \\ ; .\\ ] ] the corresponding matrix @xmath32 of second moments is found to be @xmath132 we have derived the matrix @xmath32 for several other scenarios which seem natural for applications , but do not report any of these results in the present paper , with one exception .",
    "namely , suppose that the random vectors @xmath11 are generated as counts , much as above , except the sample size @xmath127 is also a random quantity .",
    "that is , the @xmath11 come about by a compound process .",
    "if we assume the sample size @xmath127 to be given by a distribution @xmath133 , then @xmath134 in our experiments , we used the above multinomial distribution to generate random vectors with @xmath135 , @xmath136 and @xmath137 $ ] .    we know , theoretically , that @xmath138 for @xmath139",
    "however , we computed these for confirmation .",
    "thus , we computed @xmath140 for @xmath75 up to @xmath141 .    [ cols=\"<,^\",options=\"header \" , ]      matrices for particular sample sizes ( columns ) with the model @xmath142 , @xmath136 and",
    "@xmath137 $ ] . to normalize the results ,",
    "each coefficient of @xmath143 was divided by @xmath144 before plotting .",
    "green line represents @xmath145 as computed by the recursion ( [ eqpermrecursion]).,width=624,height=528 ]",
    "for a permutation @xmath146 belonging to the symmetric group of order @xmath2 , let @xmath147 denote the number of cycles in @xmath68 of size @xmath75 .",
    "let @xmath148 be a countably infinite sequence of variables , and define the polynomial @xmath149 by @xmath150 then the quotient @xmath151 is called the _ cycle index polynomial of the symmetric group_. the generating function identity @xmath152 was observed in @xcite .",
    "the latter paper was devoted to proving that assigning nonnegative real values to the variables @xmath153 subject to certain inequalities would result in the real values @xmath149 satisfying similar inequalities . coincidentally ,",
    "the pairs of quantities @xmath154 and @xmath155 studied in this paper satisfy identical generating function identities . in particular , the sequence of expected permanents @xmath156 are hereby identified as evaluations of the cycle index polynomials at certain weights @xmath157 .",
    "we have introduced the notion of a random gram matrix , and provided theory enabling the efficient computation of the expected determinant and expected permanent of it .",
    "the random gram matrix consists of dot products of vectors taken from various distributions .",
    "we further proved generating function identities and recursions relating these expectations to the traces of powers of a second moment matrix .",
    "the expected coefficients of the characteristic and permanental polynomials have also been studied , with some numerical experiments checking on the theory .",
    "some of the formulas found are the same as those studied in earlier work in an entirely different context @xcite .",
    "we have observed empirically that as the number of columns in the sample matrix @xmath1 increases , the standard deviation of the normalized expected coefficients of the determinantal and permanental polynomials decreases according to a power law .",
    "although the empirical data presented in this paper was limited to the multinomial counting model , the theoretical relationships between the different quantities remain no matter which representation is used . in future work , the theoretical rate of convergence should be formulated according to the representation and probability model used to generate the matrix @xmath1 ( e.g. trivially , when a=0 , the truth converges immediately to the expected value ) .",
    "can the probabilistic results presented in this work be of any help in managing the complexity of computing the permanent ?",
    "already , @xcite , there is a polynomial time algorithm for computing the permanent of an @xmath28 matrix of rank @xmath3 , @xmath3 being fixed .",
    "one way for our probabilistic methods to impact complexity considerations would be via finding a distribution on @xmath3-vectors ( @xmath3 small ) such that a given @xmath28 permanent per@xmath158 is equal to or well approximated by the expected value of per@xmath159 .",
    "we have no ideas in this direction .",
    "it is hoped that the theoretical observations we have made will prove useful in processing and comparing large amounts of numerical data , such as those algorithms that use permanental polynomials of large chemical graphs @xcite .",
    "moreover , the combinatorial relationships between traces of matrix powers , characteristic coefficients , expected permanents , and expected determinants will help us better understand how to use these quantities , create bounds for them , and illuminate what has made them so especially useful in applied numerical science ."
  ],
  "abstract_text": [
    "<S> a @xmath0 random matrix @xmath1 can be formed by sampling @xmath2 independent random column vectors , each containing @xmath3 components . </S>",
    "<S> the _ random gram matrix _ of size @xmath2 , @xmath4 , contains the dot products between all pairs of column vectors in the randomly generated matrix @xmath1 , and has characteristic roots coinciding with the singular values of @xmath1 . </S>",
    "<S> furthermore , the sequences @xmath5 and @xmath6 ( for @xmath7 ) are factors that comprise the expected coefficients of the characteristic and permanental polynomials of @xmath8 . </S>",
    "<S> we prove theorems that relate the generating functions and recursions for the traces of matrix powers , expected characteristic coefficients , expected determinants @xmath9 , and expected permanents @xmath10 in terms of each other . using the derived recursions , we exhibit the efficient computation of the expected determinant and expected permanent of a random gram matrix @xmath8 , formed according to any underlying distribution . </S>",
    "<S> these theoretical results may be used both to speed up numerical algorithms and to investigate the numerical properties of the expected characteristic and permanental coefficients of any matrix comprised of independently sampled columns . </S>"
  ]
}