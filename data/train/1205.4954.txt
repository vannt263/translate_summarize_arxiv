{
  "article_text": [
    "in the past century , the seminal works by minsky and papert @xcite , turing @xcite and von neumann @xcite set the basis of modern artificial intelligence and , remarkably , established a link between robotics and information theory @xcite . another fundamental contribution in this sense was achieved by hopfield @xcite , who , beyond offering a simple mathematical prescription for the hebbian rule for learning @xcite , also pointed out that artificial neural networks can be embedded in a statistical mechanics framework .",
    "the latter was rigorously settled by amit , gutfreund and sompolinsky ( ags ) @xcite , ultimately reinforcing the bridge between cybernetics and information theory @xcite , given the deep connection between the latter and statistical mechanics @xcite .    as a second - order result , artificial intelligence ,",
    "whose development had been mainly due to mathematicians and engineers , became accessible to theoretical physicists too : in particular , when hopfield published his celebrated paper , the statistical mechanics of disordered systems ( mainly spin glasses @xcite ) had just reached its maturity and served as a theoretical laboratory where ags , as well as many others , gave rise to the mathematical backbone of these associative networks .    in a nutshell",
    ", the standard hopfield model can be described by a two - bodies mean - field hamiltonian ( a liapounov cost function @xcite ) , which somehow interpolates between the one describing ferromagnetism , already introduced by curie and weiss ( cw ) @xcite , and the one describing spin - glasses developed by sherrington and kirkpatrick ( sk ) @xcite .",
    "its dichotomic variables ( initially termed  spins `` in the original cw or sk theories ) are here promoted to perform as binary neurons ( some ' ' on / off \" exasperations of more standard integrate - and - fire models @xcite ) and the interaction matrix ( called synaptic matrix in this context ) assumes a ( symmetrized ) hebbian fashion where information , represented as a set of patterns ( namely vectors of @xmath3 random entries ) , is stored .",
    "one of the main goals achieved by the statistical mechanics analysis of this model is a clear picture where memory is no longer thought of as statically stored into a confined region ( somehow similar to hard disks ) , but it is spread over the non - linear retroactive synaptic loops merging neurons themselves .",
    "furthermore , it has been offering a methodology where puzzling questions , such as the memory capacity of the network or its stability under the presence of noise , could finally be consistently formulated .",
    "the success of the statistical - mechanics analysis of neural networks is confirmed by the fact that several variations on theme followed and many scientific journals dedicated to this very subject arose .",
    "for instance , amit , cugliandolo , griniatsly and tsodsky @xcite considered a simple modification of the hebbian prescription , able to capture the spatial correlation between attractors observed experimentally as a consequence of a proper learning .",
    "more precisely , a scalar correlation parameter @xmath0 is introduced and when its value overcomes a threshold ( whose value contains valuable physics as we will explain ) , the retrieval of a given pattern induces the simultaneous retrieval of its most - correlated counterparts , in some hierarchical way , hence bypassing the standard single retrieval of the original framework ( the so called  pure state \" ) .    in another extension ,",
    "proposed by some of the authors of the present paper @xcite , the hypothesis of strictly non - zero pattern entries is relaxed in such a way that a fraction @xmath1 of entries is blank .",
    "this is shown to imply retrieval of a given pattern without exhausting all the neurons and , following thermodynamic prescriptions ( free energy minimizations ) , the remaining free neurons arrange cooperatively to retrieve further patterns , again in a hierarchical fashion . as a result ,",
    "the network is able to perform a parallel retrieval of uncorrelated patterns .",
    "here we consider an hopfield network exhibiting both correlated patterns and diluted pattern entries , and we study its equilibrium properties through statistical mechanics and monte carlo simulations , focusing on the low - storage regime .",
    "the analytical investigation is accomplished through a novel mathematical methodology , i.e , the hamilton - jacobi technique ( early developed in @xcite ) , which is also carefully explained .",
    "the emerging behavior of the system is found to depend qualitatively on @xmath0 and on @xmath1 , and we can distinguish different kinds of fixed points , corresponding to the so called pure - state or to hierarchical states referred to as `` correlated '' , `` parallel '' or `` dense '' . in particular , hierarchy among patterns is stronger for small degree of dilution , while at large @xmath1 the hierarchy is smoother .",
    "moreover , we consider the equivalence between the hopfield model and a class of boltzmann machines @xcite developed in @xcite and we show that this equivalence is rather robust and can be established also for the correlated _ and _ diluted hopfield studied here .",
    "interestingly , this approach allows the investigation of dynamic properties of the model which are as well discussed .",
    "the paper is organized as follows . in section @xmath4 , starting from the low - storage hopfield model , we revise , quickly and pedagogically , the three extensions ( and relative phase diagrams ) of interest , namely the high storage case ( tuned by a scalar parameter @xmath5 ) , the correlated case ( tuned by a scalar parameter @xmath0 ) and the parallel case ( tuned by a scalar parameter @xmath1 ) . in sec .",
    "@xmath6 , we move to the general scenario and we present our main results both theoretically and numerically . then , in sec .",
    "@xmath7 , we analyze the system from the perspective of boltzmann machines .",
    "finally , sec .",
    "@xmath8 is devoted to a summary and a discussion of results .",
    "the technical details of our investigations are all collected in the appendices .",
    "here , we briefly describe the main features of the conventional hopfield model ( for extensive treatment see , e.g. , @xcite ) .",
    "let us consider a network of @xmath9 neurons .",
    "each neuron @xmath10 can take two states , namely , @xmath11 ( fire ) and @xmath12 ( quiescent ) .",
    "neuronal states are given by the set of variables @xmath13 .",
    "each neuron is located on a complete graph and the synaptic connection between two arbitrary neurons , say , @xmath10 and @xmath14 , is defined by the following hebb rule : @xmath15 where @xmath16 denotes the set of memorized patterns , each specified by a label @xmath17 .",
    "the entries are usually dichotomic , i.e. , @xmath18 , chosen randomly and independently with equal probability , namely , for any @xmath19 and @xmath20 , @xmath21 where the kronecker @xmath22 equals @xmath23 iff @xmath24 , otherwise it is zero .",
    "patterns are usually assumed as quenched , that is , the performance of the network is analyzed keeping the synaptic values fixed .",
    "the hamiltonian describing this system is @xmath25 so that the field insisting on spin @xmath19 is @xmath26 the evolution of the system is ruled by a stochastic dynamics , according to which the probability that the activity of a neuron @xmath19 assumes the value @xmath10 is @xmath27,\\ ] ] where @xmath28 tunes the level of noise such that for @xmath29 the system behaves completely randomly , while for @xmath30 it becomes noiseless and deterministic ; note that the noiseless limit of eq .",
    "( [ eq : glauber ] ) is @xmath31 $ ] .    the main feature of the model described by eqs .",
    "( [ eq : hopfield ] ) and ( [ eq : glauber ] ) is its ability to work as an associative memory .",
    "more precisely , the patterns are said to be memorized if each of the network configurations @xmath32 for @xmath33 , for everyone of the @xmath34 patterns labelled by @xmath20 , is a fixed point of the dynamics . introducing the overlap @xmath35 between the state of neurons @xmath36 and one of the patterns @xmath37 , as @xmath38 a pattern @xmath20",
    "is said to be retrieved if , in the thermodynamic limit , @xmath39 .    given the definition ( [ eq : overlap ] ) , the hamiltonian ( [ eq : hopfield ] ) can also be written as @xmath40 and , similarly , @xmath41    the analytical investigation of the system is usually accomplished in the thermodynamic limit @xmath42 , consistently with the fact that real networks are comprised of a very large number of neurons . dealing with this limit",
    ", it is convenient to specify the relative number of stored patterns , namely @xmath43 and to define the ratio @xmath44 .",
    "the case @xmath45 , corresponding to a number @xmath34 of stored patterns scaling sub - linearly with respect to the amount of performing neurons @xmath9 , is often referred to as `` low storage '' .",
    "conversely , the case of finite @xmath5 is often referred to as `` high storage '' .",
    "the overall behavior of the system is ruled by the parameters @xmath46 ( fast noise ) and @xmath5 ( slow noise ) and it can be summarized by means of the phase diagram shown in fig .",
    "[ fig : amit ] notice that for @xmath45 , the so - called pure - state ansatz @xmath47 always corresponds to a stable solution for @xmath48 ; the order in the entries is purely conventional and here we assume that the first pattern is the one stimulated .     at a high level of noise",
    "the system is ergodic ( pm ) and no retrieval can be accomplished ( @xmath49 ) . by decreasing the noise level below a critical temperature ( dashed line )",
    "one enters a `` spin - glass '' phase ( sg ) , where there is no retrieval ( @xmath50 ) , yet the system is no longer full - ergodic .",
    "now , if the number of patterns is small enough ( @xmath51 ) , by further decreasing the level of noise , one eventually crosses a line ( solid curve ) , below which the system develops @xmath52 meta - stable retrieval states , each can be separately retrieved with a macroscopic overlap ( @xmath53 ) .",
    "finally , when @xmath5 is small enough ( @xmath54 ) , a further transition occurs at a critical temperature ( dotted line ) , such that below this line the retrieval states become global minima ( r ) . ]",
    "the hebbian coupling in eq .",
    "[ eq : hebb ] can be generalized in order to include possible more complex combinations among patterns ; for instance , we can write @xmath55 where @xmath56 is a symmetric matrix ; of course , by taking @xmath56 equal to the identity matrix we recover eq .",
    "[ eq : hebb ] .",
    "a particular example of generalized hebbian kernel was introduced in @xcite , and further investigated in @xcite , as @xmath57 in this way the coupling between two arbitrary neurons turns out to be @xmath58.\\ ] ] hence , each memorized pattern , meant as a cyclic sequence , couples the consecutive patterns with a strength @xmath0 , in addition to the usual auto - associative term .",
    "this modification of the hopfield model was proposed in @xcite to capture some basic experimental features about coding in the temporal cortex of the monkey @xcite : a temporal correlation among visual stimuli can evoke a neuronal activity displaying spatial correlation . indeed",
    ", the synaptic matrix ( [ eq : j_leticia ] ) is able to reproduce this experimental feature in both low @xcite and high @xcite storage regimes .    for the former case ,",
    "one derives the mean - field equations determining the attractors , which , since the matrix is symmetric , are simple fixed points . in the limit of a large network , they read off as @xcite @xmath59 \\right ) \\right \\rangle_{\\xi},\\ ] ] where @xmath60 means an average over the quenched distribution of patterns .    in @xcite ,",
    "the previous equation was solved by starting from a pure pattern state and iterating until convergence . in the noiseless case , where the hyperbolic tangent can be replaced by the sign function ,",
    "the pure state ansatz is still a fixed point of the dynamics if @xmath61 , while if @xmath62 $ ] , the system evolves to an attractor characterized by the mattis magnetizations ( assuming @xmath63 , see appendix a ) @xmath64 namely , the overlap with the pattern used as stimulus is the largest and the overlap with the neighboring patterns in the stored sequence decays symmetrically until vanishing at a distance of @xmath8 .",
    "some insights into these results can be found in appendix a.    in the presence of noise , one can distinguish four different regimes according to the value of the parameters @xmath0 and @xmath65 .",
    "the overall behavior of the system is summarized in the plot of fig .",
    "[ fig : leti ] .",
    "a similar phase diagram , as a function of @xmath5 and @xmath0 , was drawn in @xcite for the high - storage regime .",
    "phase diagram for the correlated model with low storage ( @xmath66 ) , as originally reported in @xcite . at a high level of noise",
    "the system is ergodic ( pm ) and it eventually reaches a state with @xmath67 . at smaller temperatures ( below the dashed line )",
    ", the system evolves to a so - called symmetric state ( s ) , characterized by , approximately , @xmath68 .",
    "then , if @xmath0 is small enough , by further reducing the temperature ( below the solid line ) , the network behaves as a hopfield network and the pure state retrieval ( ps ) can be recovered . on the other hand ,",
    "if @xmath0 is larger , as the temperature is reduced , correlated attractors ( c ) appear according to eq .",
    "[ eq : ansatz_leti ] . then , if the temperature is further lowered , the system recovers the hopfield - like regime . if @xmath69 , the pure state regime is no longer achievable . ]    a further generalization can be implemented in order to account for the fact that the pattern distribution may not be uniform or that pattern may possibly be blank .",
    "for instance , in the latter case one may replace eq .",
    "[ eq : pattern_equi ] by @xmath70 where @xmath1 encodes the degree of dilution of pattern entries .",
    "this kind of extension has strong biological motivations , too .",
    "in fact , the distribution in eq .",
    "[ eq : pattern_equi ] necessarily implies that the retrieval of a unique pattern does employ all the available neurons , so that no resources are left for further tasks .",
    "conversely , with eq .",
    "[ eq : pattern_blank ] the retrieval of one pattern still allows available neurons which can be used to recall other patterns . the resulting network is therefore able to process several patterns simultaneously .",
    "the behavior of this system is deeply investigated in @xcite , as far as the low storage regime is concerned .    in particular , it was shown both analytically ( via density of states analysis ) and numerically ( via monte carlo simulations ) , that the system evolves to an equilibrium state where several patterns are contemporary retrieved ; in the noiseless limit @xmath71 , the equilibrium state is characterized by a hierarchical overlap @xmath72 hereafter referred to as `` parallel ansatz '' , while , in the presence of noise , one can distinguish different phases as shown by the diagram in fig .",
    "[ fig : diagramma_alps ] .     at high levels of noise the system is ergodic ( pm ) and below the temperature @xmath73 ( continous line ) it can develop a pure state retrieval ( ps ) or a symmetric retrieval ( s ) , according to whether the dilution is small or large , respectively . at small temperatures and intermediate degree of dilution the system can develop a parallel ( p ) retrieval , according to eq .",
    "[ eq : h_retrieval ] .",
    "the continuous line works for any value of @xmath34 , while the dotted and dashed lines were obtained numerically for the case @xmath74 . ]    to summarize , both generalizations discussed above , i.e. eqs .  [ eq : j_leticia ] and  [ eq : pattern_blank ] , induce the break - down of the pure - state ansatz and allow the retrieval of multiple patterns without falling in spurious states . , spurious states are anyhow expected not to emerge since they just appear when pushing the system toward the spin - glass boundary on @xmath75 . ] in the following , we merge such generalizations and consider a system exhibiting both correlation among patterns and dilution in pattern entries .",
    "considering a low - storage regime with constant @xmath34 , the general case with @xmath76 $ ] and @xmath77 $ ] can be visualized as a square ( see fig .",
    "[ fig : square ] ) , where vertices and nodes correspond to either already - known or trivial cases , while the bulk will be discussed in the following .     schematic representation of the general model considered in the low - stare regime ( @xmath45 ) and zero noise ( @xmath71 ) . according to the value of the parameters @xmath0 ( degree of correlation ) and @xmath1 ( degree of dilution )",
    "the system can recover different kinds of systems .",
    "the red curve corresponds to eq .",
    "[ eq : d_1 ] . ]",
    "first , we notice that the coupling distribution is still normal with average @xmath78 and variance @xmath79 .",
    "the last result can be realized easily by considering a random walk of length @xmath34 : the walker is endowed with a waiting probability @xmath1 and at each unit time it performs three steps , one of length @xmath23 and two of length @xmath0 .    moreover ,",
    "as shown in appendix c , the self - consistance equations found in @xcite can be properly extended to the case @xmath80 as @xmath81 where @xmath56 is the matrix inducing the correlation ( see eq .",
    "[ eq : connection ] ) and the brakets @xmath82 now mean an average over the possible realizations of dilution too .      the numerical solution of the self - consistence equation ( [ emmes eq ] )",
    "are shown in figs .",
    "[ fig : p5t0 ] and [ fig : p5p7p9t0 ] , as functions of @xmath1 and @xmath0 ; several choices of @xmath34 are also compared .",
    "let us focus on the case @xmath83 ( see fig .  [",
    "fig : p5t0 ] ) for a detailed description of the system performance .",
    "magnetization @xmath84 versus degree of dilution for fixed @xmath83 and @xmath85 ; magnetizations related to different patterns are shown in different colors .",
    "several values of @xmath0 are considered , as specified in each panel . ]",
    "magnetization @xmath84 versus degree of dilution for fixed @xmath86 and @xmath85 .",
    "several values of @xmath34 are considered for comparison : @xmath83 ( leftmost panel ) , @xmath87 ( central panel ) and @xmath88 ( rightmost panel ) .",
    "magnetizations related to different patterns are shown in different colors . ]    when @xmath89 , the parallel ansatz ( [ eq : h_retrieval ] ) works up to a critical dilution @xmath90 , above which the gap between magnetizations , i.e. @xmath91 , drops abruptly and , for @xmath92 , all magnetizations are close and decrease monotonically to zero . to see this ,",
    "let us reshuffle the ansatz in ( [ eq : h_retrieval ] ) , so to account for the hierarchy induced by correlation , that is , @xmath93 which can be straightforwardly extended to any arbitrary @xmath34 .",
    "given the state ( [ eq : ansatz_order ] ) , the field insisting on @xmath10 is @xmath94 m^{\\mu }   \\\\ \\nonumber & = & ( 1-d ) \\ { \\xi_i^{1 } [ 1+ad(1+d ) ] + \\xi_i^2 [ d+ a ( 1+d^3 ) ] + \\xi_i^3 [ d^3 + ad ( 1+d^3)]\\\\ \\nonumber & + & \\xi_i^4 [ d^4 + ad^2 ( 1+d ) ] + \\xi_i^5 [ d^2 + a ( 1+d^4 ) ] \\}.\\end{aligned}\\ ] ] a signal - to - noise analysis suggests that this state is stable only for small degrees of dilution . in fact , there exist configurations ( e.g. , @xmath95 and @xmath96 , for any @xmath97 ) possibly giving rise to a misalignment between @xmath10 and @xmath98 , with consequent reduction of @xmath99 .",
    "this can occur only for @xmath92 , being @xmath90 the root of the equation @xmath100 $ ] , as confirmed numerically ( see fig .  [",
    "fig : p5t0 ] ) . in general , for arbitrary @xmath34 , one has @xmath101,\\ ] ] which is plotted in fig .",
    "[ fig : square ] .    as @xmath102 , the magnetic configuration corresponding to eq .",
    "( [ eq : ansatz_order ] ) undergoes an updating where a fraction of the spins aligned with @xmath103 flips to agree mostly with @xmath104 and @xmath105 , and partly also with @xmath106 and @xmath107 ; as a result , @xmath99 is reduced , while the other magnetizations are increased .",
    "analogously , a fraction of the spins aligned with @xmath104 is unstable and flips so to align mostly with @xmath105 ; consequently , there is a second - order correction which is upwards for @xmath108 ( and to less extent for @xmath99 , @xmath109 and @xmath110 ) and downwards for @xmath111 .",
    "similar arguments apply for higher - order corrections .    at large values of dilution it convenient to start from a different ansatz , namely from the symmetric state @xmath112 this",
    "is expected to work properly when dilution is so large that the signal on any arbitrary spin @xmath10 stems from only one pattern , i.e. , @xmath113 and @xmath114 .",
    "this approximately corresponds to @xmath115 .",
    "the related magnetization is therefore @xmath116 .",
    "now , reducing @xmath1 , we can imagine , for simplicity , that each spin @xmath10 feels a signal from just two different patterns , say @xmath103 and @xmath104 .",
    "the prevailing pattern , say @xmath103 , will increase the related magnetization and vice versa .",
    "this induces the breakdown of the symmetric condition so that @xmath99 grows larger , followed by @xmath111 , @xmath108 , and so on .",
    "the gap between magnetizations corresponds to the amount of spins which have broken the local symmetry , that is @xmath117 .",
    "thus , magnetizations differs by the same amount and this configuration is stable for large enough dilutions . by further thickening non - null entries",
    ", each spin has to manage a more complex signal and higher order corrections arise .",
    "for instance , one finds @xmath118 , and similarly for @xmath119 .",
    "this picture is consistent with numerical data and , for large enough values of @xmath1 , it is independent of @xmath0 ( see fig .  [",
    "fig : p5t0 ] ) . notice that in this regime of high dilution hierarchy effects are smoothed down , that is , magnetizations are close and we refer to this kind of state as `` dense '' .    when @xmath69 , the parallel ansatz in eq .",
    "[ eq : ansatz_order ] is no longer successful at small @xmath1 , in fact , correlation effects prevail and one should rather consider a perturbed version of the correlated ansatz ( [ eq : ansatz_leti ] ) , that is , @xmath120 we use ( [ eq : ansatz_leti_pert ] ) as initial state for our numerical calculations finding , as fixed point , @xmath121 , @xmath122 , @xmath123 , @xmath124 .",
    "this state works up to a critical dilution @xmath125 , where , again there is the establishment of a situation with magnetizations close and monotonically decreasing to zero .",
    "this scenario is analogous to the one describe above and , basically , @xmath125 marks the onset of the region where dilution effects prevails .",
    "the threshold value @xmath126 is slowly decreasing with @xmath0 .",
    "the noisy case gives rise to a very rich phenomenology , as evidenced by the plots shown in fig  [ fig : p5t01 ] .    in the range of temperatures considered ,",
    "i.e. @xmath128 , we found that , when @xmath129 and @xmath130 , the parallel ansatz ( [ eq : ansatz_order ] ) works ; in general , @xmath131 decreases with @xmath65 and with @xmath0 , consistently with what found in the noiseless case ( see fig .",
    "[ fig : square ] ) .",
    "moreover , @xmath132 also decreases with @xmath65 , consistently with the case @xmath133 @xcite , ( see fig .  [",
    "fig : leti ] ) : from @xmath134 onwards correlation effects get non - negligible . for larger values of @xmath0 , namely @xmath135 , the perturbed correlated ansatz ( [ eq : ansatz_leti_pert ] ) works , while for @xmath136 correlations",
    "effects are so important that a symmetric state emerges .",
    "again , we underline the consistentcy with the case @xmath133 @xcite : the region @xmath137 corresponds to an intermediate degree of correlation which yields a hierarchical state , while @xmath136 corresponds to a high degree of correlation which induces a symmetric state ( see fig .",
    "[ fig : leti ] ) .    as for the region of high dilution",
    ", we notice that when @xmath1 is close to @xmath23 the paramagnetic state @xmath138 emerges .",
    "in fact , as long as the signal @xmath139 is smaller than noise @xmath65 , no retrieval can be accomplished , therefore , the condition @xmath140 must be fulfilled for @xmath141 to hold .",
    "the system then relaxes to a symmetric state which lasts up to intermediate dilution , where a state with `` dense '' magnetizations , analogous to the one described in sec .",
    "@xmath142 , emerges .",
    "magnetization @xmath84 versus degree of dilution for fixed @xmath83 and @xmath143 ; magnetizations related to different patterns are shown in different colors .",
    "several values of @xmath0 are considered , as specified in each panel . ]",
    "the model was analyzed also via monte carlo simulations , which were implemented to determine the equilibrium values of the order parameter associated to the following hopfield - like hamiltonian h=-_i < j _",
    "j j_ij=_ij _ i _ j _ . where the coupling encodes correlation among patterns according to eq .",
    "( [ eq : j_leticia ] ) , and pattern entries are extracted according to eq .",
    "( [ eq : pattern_blank ] ) .",
    "the dynamical microscopic variables evolve under the stochastic glauber dynamic @xcite _ i(t+t)= [ + _ i(t ) ] , where the fields @xmath144 represent the post - synaptic potentials of the neurons .",
    "the independent random numbers @xmath145 , distributed uniformly in @xmath146 $ ] , provides the dynamics with a source of stochasticity .",
    "the parameter @xmath147 controls the influence of the noise on the microscopic variables @xmath10 . in the limit @xmath148 ,",
    "namely @xmath149 the process becomes deterministic and the system evolves according to @xmath150 $ ] .",
    "in general , simulations were carried out using lattices consisting of @xmath151  neurons \" and averaging on statistical samples composed of @xmath152 realizations .",
    "for each realization of the pattern set @xmath153 , the equilibrium values of mattis magnetizations were determined as a function of @xmath1 and the degree of dilution in pattern entries is incremented in steps of @xmath154 , by sequentially set equal to zeros the entries of the @xmath34 vectors , in agreement with the distribution ( [ eq : pattern_blank ] ) .",
    "overall , there is a very good agreement between results from mc simulations , from numerical solution of self - consistent equations and from analytical investigations ( see fig .",
    "[ fig : p5t01 ] ) .",
    "magnetization @xmath84 versus degree of dilution for fixed @xmath83 , @xmath85 and @xmath86 ( left panel ) or @xmath155 ( right panel ) .",
    "results from numerical solution of eq .",
    "[ emmes eq ] ( dashed , thick line ) and monte carlo simulations ( solid , thin lines ) with associated error ( shadows ) are compared showing , overall , a very good agreement . ]",
    "it is possible to get a deeper insight into the behavior of the system from the perspective of boltzmann machines ( bms ) , exploiting the approach first introduced in @xcite . in particular",
    ", it was shown that a `` hybrid '' bm characterized by a bipartite topology ( where the two parties are made up by @xmath9 visible units @xmath10 and by @xmath34 hidden units @xmath156 , respectively ) , after a marginalization over the ( analog ) hidden units , turns out to be ( thermodynamically ) equivalent to a hopfield network . in this equivalence",
    "the @xmath9 visible units play the role of neurons and the link connecting @xmath10 to @xmath156 is associated to a weight @xmath157 .",
    "the term `` hybrid '' refers to the choice of the variables associated to units : the visible units are binary ( @xmath158 ) , as in a restricted boltzmann machine , while the hidden ones are analog ( @xmath159 ) , as in a restricted diffusion network .",
    "schematic representation of a hybrid bm , with @xmath160 visible nodes ( @xmath161 ) and @xmath74 hidden nodes ( @xmath162 ) .",
    "the number of boxes ( @xmath163 ) is @xmath34 as well .",
    "the average number of links stemming from visible units is @xmath4 , due to dilution .",
    "the link between the @xmath19-th visible unit and the @xmath20-th box is @xmath157 ; the link between the @xmath20-th box and the @xmath20-th [ ( @xmath164)-th ] hidden unit is @xmath165 [ @xmath166 .",
    "]    as we are going to show , this picture can be extended to include also the correlation among attractors and the dilution in pattern entries .",
    "more precisely , we introduce an additional layer made up by @xmath34 `` boxes '' , which switches the signal @xmath157 on the two hidden variables @xmath156 and @xmath167 ( see fig .  [",
    "fig : bm ] ) .",
    "such boxes do not correspond to any dynamical variable , but they retain a structural function as they properly organize the interactions between the two `` active '' layers : the binary layer is linked to boxes by a synaptic matrix @xmath168 , the boxes are in turn connected to the analog layer by a `` connection matrix '' that we call @xmath169 .",
    "the synaptic matrix @xmath168 is @xmath170 dimensional , each row @xmath37 being a stored pattern .",
    "a link between the discrete neuron @xmath171 and the @xmath20-th box is drawn with weight @xmath157 , which take value in the alphabet @xmath172 following a proper probability distribution .",
    "a null weight corresponds to a lack of link , that is , we are introducing a random dilution in the left of the structure . on the other hand ,",
    "the matrix @xmath169 is @xmath173 dimensional and meant to recover the correlation among the stored patterns . here , we choose @xmath168 according to eq .",
    "[ eq : pattern_blank ] and @xmath169 such to recover @xcite , namely    @xmath174    where @xmath165 and @xmath175 are parameters tuning the strength of correlation between consecutive patterns entries ( vide infra ) .",
    "more complex and intriguing choices of @xmath169 could be implemented , possibly related to a major adherence to biology .",
    "the dynamics of the hidden and visible layers are quite different . as explained in @xcite , the activity in the analog layer follows a ornstein - uhlembeck ( ou ) diffusion process as @xmath176 where @xmath177 represents a leakage term , @xmath178 denotes the input due to the state of the visible layer , @xmath179 is a white gaussian noise with zero mean and covariance @xmath180 , @xmath181 is the typical timescale and @xmath28 tunes the strength of the input fluctuations . in vector notation",
    "the field on the analog layer is @xmath182 , or , more explicitly , @xmath183 the activity in the digital layer follows a glauber dynamics as @xmath184 \\right \\rangle_{\\xi},\\ ] ] where the interaction with the hidden layer is encoded by @xmath185 , that is , @xmath186 the timescale of the analog dynamics ( [ ouprocess ] ) is assumed to be much faster than that of the digital one ( [ gprocess ] ) , that is @xmath187 .",
    "since all the interactions are symmetric , it is possible to describe this system through a hamiltonian formulation : from the ou process of eq .",
    "( [ ouprocess ] ) we can write @xmath188 being [ acca ] ( , , , ) = z^2/2 - _ = 1^p _ z_. the partition function @xmath189 for such a system then reads off as @xmath190 where @xmath191 is the gaussian weight obtained integrating the leakage term in the ou equation .",
    "now , by performing the gaussian integration , we get @xmath192 where @xmath193 which corresponds to an hopfield model with patterns @xmath194 , under the shift @xmath195 .",
    "we then call @xmath196 the correlation matrix which is obviously symmetric ,  so that the interactions between the @xmath197s are symmetric ,  leading to an equilibrium scenario . using eq .",
    "[ xtilde ] , the matrix @xmath56 is @xmath198 and we can fix @xmath199 and @xmath200 , to recover the coupling in eq .  [ eq : j_leticia ] .",
    "it is easy to see that , as long as @xmath201 , @xmath202 . in general , with some algebra , we get @xmath203 therefore , the product @xmath204 appearing in both fields @xmath178 ( see eq .",
    "[ eq : campo1 ] ) and @xmath205 ( see eq .",
    "[ eq : campo3 ] ) , turns out to be @xmath206.\\ ] ] thus , when @xmath202 , @xmath207 , while for @xmath208 , @xmath209 can be either real or pure imaginary , according to whether the @xmath20-th entry and the following @xmath164-th are aligned or not .",
    "having described the behavior of the fields , we can now deepen our investigation on the dynamics of the boltzman machine underlying our generalized hopfield model .",
    "let us write down explicitly the two coupled stochastic langevin equations ( namely one ou process for the hidden layer , and one glauber process for the hopfield neurons ) as @xmath210 \\right\\rangle_{\\xi}.\\end{aligned}\\ ] ] note that by assuming thermalization of the fastest variables with respect to the dynamical evolution of the magnetizations , namely requiring @xmath211 , we can use eq .",
    "[ eq : sis1 ] to explicit the term @xmath212 in the argument of the hyperbolic tangent in eq .",
    "[ eq : sis2 ] , hence recovering the self - consistencies of eq .",
    "( [ emmes eq ] ) , ( see also appendix c ) .",
    "assuming that the two time scales belong to two distinct time sectors , it is possible to proceed in the opposite way , that is 0m_=^_. for the sake of simplicity let us deal with the @xmath213 case , being the generalization to the case @xmath214 straightforward .",
    "linearization implies @xmath215 \\right\\rangle_{\\xi } , \\\\",
    "\\label{eq : primosistema_2 }     \\tau \\dot{z_2 } & = & -z_2+\\left\\langle(c\\xi^2+b\\xi^1)\\beta^2[z_1(c\\xi^1+b\\xi^2)+z_2(c\\xi^2+b\\xi^1 ] \\right\\rangle_{\\xi},\\end{aligned}\\ ] ] which , recalling that @xmath216 and @xmath217 , turn out to be @xmath218 + z_2 \\left [ 2a(1-d)\\beta^2 \\right ] , \\\\",
    "\\tau \\dot{z_2 } & = & z_2 \\left [ -1+(1-d)\\beta^2 \\right ]   + z_1 \\left [ 2a(1-d)\\beta^2 \\right].\\end{aligned}\\ ] ] it is convenient to rotate the plane variables @xmath219 and define @xmath220 such that eqs .",
    "[ eq : primosistema_1 ] and [ eq : primosistema_2 ] can be restated as @xmath221\\\\     \\dot{y } & = & -y\\left[\\frac{1}{\\tau}-\\frac{(1-d)\\beta^2 ( c - b)^2 } { \\tau } \\right],\\end{aligned}\\ ] ] which , in terms of the parameter @xmath0 , are @xmath222\\\\     \\dot{y}&= & -y \\left [ \\frac{1}{\\tau}-\\frac{(1-d)\\beta^2 ( 1 - 2a)}{\\tau } \\right],\\end{aligned}\\ ] ] whose solution is \\ {    ll x(t)= x(0)e^y_x t = x(0 ) + y(t)= y(0)e^y_y t = y(0 ) .    .",
    "the lyapunov exponents of the dynamical system @xmath223 turn out to be @xmath224,\\\\ y_y & = & -\\frac{1}{\\tau}\\left [ 1 - \\beta^2(1-d)(1 - 2a ) \\right ] .\\end{aligned}\\ ] ] this dynamic scenario can be summarized as follows : if the noise level is high @xmath225 , the dynamics is basically quenched on its fixed points @xmath226 and the corresponding hopfield model is in the ergodic phase . if the noise level is reduced below the critical threshold , then two behavior may appear : if @xmath202 both @xmath227 and @xmath228 increase , which means that only one @xmath229 variable is moving away from its trivial equilibrium state ( this corresponds to a retrieval of a single pattern in the generalized hopfield counterpart ) ; if @xmath208 , @xmath227 increases while @xmath228 points to zero , which means that both the variables @xmath219 are moving away from their trivial equilibrium values ( this corresponds to a correlated retrieval in the generalized hopfield counterpart ) .",
    "switching to the original variables we get @xmath230(z_1(0)\\cosh[\\frac{t(1-d)\\beta 2a}{\\tau}]+z_2(0)\\sinh[\\frac{t(1-d)\\beta 2a}{\\tau}]),\\\\ \\nonumber",
    "z_2(t ) & = & \\exp [ \\frac{-t}{\\tau}(1-(1-d)\\beta)](z_1(0)\\sinh[\\frac{t(1-d)\\beta 2a}{\\tau}]+z_2(0)\\cosh[\\frac{t(1-d)\\beta 2a}{\\tau}]).\\end{aligned}\\ ] ] again , lyapunov exponents describe a dynamics in agreement with the statistical mechanics findings .",
    "while technology becomes more and more automatized , our need for a systemic description of cybernetics , able to go over the pure mechanicistic approach , gets more urgent . among the several ways tried in this sense , neural networks , with their feedback loops among neurons , the multitude of their stable states and their stability under attacks ( being the latter noise , dilution or various perturbations ) , seem definitely promising and worth being further investigated .    along this line , in this work we considered a complex perturbation of the paradigmatic hopfield model , by assuming correlation among patterns of stored information _ and _ dilution in pattern entries .",
    "first , we reviewed and deepened both the limiting cases , corresponding to a hopfield model with correlated attractors ( introduced and developed by amit , cugliandolo , griniatsly and tsodsky @xcite ) and to a hopfield model with diluted patterns ( introduced by some of us @xcite ) . the general case , displaying a correlation parameter @xmath231 and",
    "a degree of dilution @xmath232 , has been analyzed from different perspectives obtaining a consistent and broad description .",
    "in particular , we showed that the system exhibits a very rich behavior depending qualitatively on @xmath0 , on @xmath1 and on the noise @xmath65 : in the phase space there are regions where the pure - state ansatz is recovered , others where several patterns can be retrieved simultaneously and such parallel retrieval can he highly hierarchical or rather homogeneous or even symmetric .",
    "further , recalling that interactions among spins are symmetric and therefore a hamiltonian description is always achievable , we can look at the system as the result of marginalization of a suitable ( restricted ) boltzman machine made of by two layers ( a visible , digital layer built of by the hopfield neurons and a hidden , analog layer made of by continuous variables ) interconnected by a passive layer of bridges allowing for pattern correlations . in this way",
    "the dynamics of the system can as well be addressed .",
    "* appendix a. * - in this appendix we provide some insights into the shape of the attractors emerging for the correlated model in the noiseless case .",
    "we recall for consistency the coupling @xmath233,\\ ] ] where the pattern matrix @xmath168 is quenched . due to the definition above",
    ", magnetizations are expected to reach a hierarchical structure , where the largest one , say @xmath99 , corresponds to the stimulus and the remaining are symmetrically decreasing , say @xmath234 where we assumed @xmath34 as odd .",
    "the distance between the pattern @xmath20 and the stimulated pattern is @xmath235 $ ] .",
    "moreover , each pattern @xmath20 determines a field @xmath236 , which tends to align the @xmath19-th spin with @xmath157 .",
    "the field reads off as @xmath237 at zero fast noise we have that @xmath238 . \\ ] ] due to eqs .",
    "( [ eq : series ] ) and ( [ eq : field_mu ] ) , the first pattern is likely to be associated to a large field and therefore to determine the sign of the overall sum appearing in eq .",
    "( [ eq : field_mu ] ) . on the other hand ,",
    "patterns with @xmath20 close to @xmath239 are unlikely to give an effective contribution to @xmath240 and therefore to align the corresponding spins . indeed , the field @xmath241 may determine the sign of @xmath240 for special arrangements of the patterns @xmath20 corresponding to smaller distance , i.e. @xmath242 . more precisely , their configuration must be staggered , i.e. , under gauge symmetry , @xmath243 , @xmath244 , @xmath245 . by counting such configurations",
    "one gets @xmath246 .    with some abuse of language , in the following we will denote with @xmath247 the mattis magnetization corresponding to patterns at a distance @xmath248 from the first one . for simplicity , we also assume @xmath34 small such that @xmath249 .    then , it is easy to see that , over the @xmath250 possible pattern configurations , those which effectively contribute to @xmath251 are only @xmath7 .",
    "in fact , it must be @xmath252 and all the remaining must be staggered ; therefore , @xmath253 .    as for @xmath254 , contributes come from configurations where the patterns corresponding to @xmath255 are staggered .",
    "such configurations are @xmath256 , but we need to exclude those which are actually ruled by the farthest patterns , which are @xmath7 , hence , the overall contribute is @xmath257 and @xmath258",
    ".    we can proceed analogously for the following contributes . in general , by denoting with @xmath259 the @xmath248-th contribute , one has the following recursive expression @xmath260 with @xmath261 and @xmath262 . for the last contribute , one has @xmath263 , because the last pattern has no `` twin '' .",
    "let us now consider the case @xmath265 ; following the previous machinery we get @xmath266 .",
    "however , such state is not stable over the whole range of @xmath0 .",
    "in fact , by requiring that the field due to the farthest pattern is larger than the field generated by the staggered configuration of patterns we get @xmath267 which implies @xmath268 .",
    "hence , from that value of @xmath0 , the previous state is replaced by @xmath269 , which is always stable .",
    "similarly , for @xmath66 , we get a state for @xmath270 with @xmath271 , which is stable only when @xmath272 , for larger values of @xmath0 this is replaced by the state found for @xmath265 and then for the state found for @xmath88 .",
    "* appendix b. * -in this appendix we want to show that the model is well behaved , namely , that its intensive free energy has a thermodynamic limit that exists and is unique : despite it may look as a redundant check , we stress that the thermodynamic limit of the high storage hopfield model ( e.g. the @xmath273 case ) is still lacking , hence rigorous results on its possible variants still deserve some interest . to obtain the desired result ,",
    "our approach follows two steps : first we show , via annealing , that the intensive free energy is bounded in the system size , then we show that it is also super - additive . as a consequence of these two results the statement straightly follows @xcite . remembering that @xmath274 , where @xmath275 is the partition function . annealing the free energy consists in considering the following bound @xmath276 where in the last line we used jensen inequality . as a result",
    "we get @xmath277 \\right \\ } } \\\\ & \\leq & 2^n e^{\\frac{p}{2}(n-1)\\beta(1 + 2a)(1-d),}\\end{aligned}\\ ] ] by which the annealed free energy bound reads off as f_n(,a , d ) 2 + ( 1 + 2a)(1-d)(1 + 1n ) , such that the annealed free energy is @xmath278 .",
    "let us move over toward proving the super - additivity property and consider two systems independent of each other and with respect to to the original @xmath9-neurons model , and made of respectively by @xmath279 and @xmath280 neurons , such that @xmath281",
    ". in complete analogy with the original system we can introduce @xmath282 and note that the original mattis magnetizations are linear combinations of the sub - systems counterparts such that @xmath283 since the function @xmath284 is convex ( and the translation @xmath285 innocent ) we have @xmath286 \\right \\ } } \\\\ \\nonumber & \\cdot & e^{\\beta   n_2 \\sum_{\\mu}^p \\left\\ {   m_{\\mu}^{(2),2}(\\sigma ) + a \\left [ m_{\\mu}^{(2)}(\\sigma ) m_{\\mu+1}^{(2)}(\\sigma)+ m_{\\mu}^{(2)}(\\sigma ) m_{\\mu-1}^{(2)}(\\sigma ) \\right ] \\right \\ } } \\\\ & = & z_{n_1}(\\beta , a , d)z_{n_2}(\\beta , a , d),\\end{aligned}\\ ] ] by which the free energy density @xmath287 is shown to be sub - additive as @xmath288 as the free energy density is sub - additive and it is limited ( and this is an obvious consequence of the annealed bound ) , the infinite volume limit exists and is unique and equal to its sup over the system size @xmath289 .    * appendix c. * in this appendix we outline the statistical mechanics calculations that brought to the self consistency used in the text ( eq . [ eq : selfcons_a ] ) .",
    "our calculations are based on the hamilton - jacobi interpolation technique @xcite@xcite@xcite .",
    "this appendix aims two different targets . from one side",
    "it outlines the physics of the model and describes it through the self - consistent equation ; from the other side it develops a novel mathematical technique able to solve this kind of statistical mechanics problems . in a nutshell",
    "the idea is to think at @xmath28 as a  time - variable `` and to introduce @xmath34 ficticious axes @xmath290 , meant as  space - variables '' , then , within an hamilton - jacobi framework , the free energy with respect to these euclidean coordinates , is shown to play the role of the principal hamilton function , whose solution can then be extrapolated from classical mechanics .",
    "our generalization of the hopfield model is described by the hamiltonian : @xmath291 as discussed in the text ( see sects .",
    "@xmath4 and @xmath6 ) .",
    "the @xmath9-neuron partition function @xmath292 and the free energy @xmath293 can be written as @xmath294 , \\\\",
    "f(\\beta , a , d ) & = &   \\lim_{n\\to \\infty } \\frac1n \\langle \\log z_n(\\beta , a , d)\\rangle,\\end{aligned}\\ ] ] where @xmath295 again denotes the full averages over both the distribution of the quenched patterns @xmath296 and the boltzman weight ( for the sake of clearness , let us stress that the factor @xmath297 $ ] is termed boltzman factor ) .",
    "as anticipated , the idea of the hamilton - jacobi interpolation is to enlarge the  space of the parameters \" by introducing a @xmath298 euclidean structure ( where @xmath34 dimensions are of space type and mirrors the @xmath34 mattis magnetization , while the remaining one is of time type and mirrors the temperature dependence ) and to find a general solution for the free energy in this space thanks to techniques stemmed from classical mechanics .",
    "the statistical mechanics free energy will then be simply this extended free energy evaluated in a particular point of this larger space .",
    "analogously , the average @xmath299 extends the ones earlier introduced by accounting for this generalized boltzmann factor and will be denoted by @xmath300 , wherever evaluated in the sense of statistical mechanics .",
    "the  euclidean \" free energy for @xmath9 neurons , namely @xmath301 , can then be written in vectorial terms as @xmath302 \\right \\}\\right\\rangle.\\ ] ] the matrix @xmath56 can be diagonalized trough @xmath303 , where @xmath304 and @xmath305 are ( unitary ) rotation matrices and @xmath306 is the diagonal expression , such that @xmath307\\right\\rangle,\\\\ & = & \\frac1n \\left\\langle \\ln \\sum_{\\sigma } \\exp \\left [ -\\frac{t}{2n}(\\sqrt{d}u \\bold{\\xi}\\bold{\\sigma } , \\sqrt{d}u \\bold{\\xi}\\bold{\\sigma } ) + ( \\sqrt{d}^{-1}u^{\\dagger}\\bold{x } , \\sqrt{d}u \\bold{\\xi}\\bold{\\sigma})\\right]\\right\\rangle , \\nonumber\\end{aligned}\\ ] ] as @xmath308 and @xmath309 .",
    "if we switch to the new variables @xmath310 and @xmath311 we can write the euclidean free energy in a canonical form as @xmath312 thus , we write the @xmath313-dependent boltzmann factor as @xmath314,\\ ] ] remembering that @xmath315 matches the classical statistical mechanics factor for @xmath316 and @xmath317 @xmath318 , as even a visual check can immediately confirm .",
    "we notice that the free energy implicitly acts as a principal hamilton action if we introduce the potential @xmath321.\\ ] ] in fact , we can write the hamilton - jacobi equation for the @xmath322 action as @xmath323 interestingly , the potential is the sum of the variances of the order parameters and we know from central limit theorem argument that in the thermodynamic limit they must vanish , one by one , and , consequently , @xmath324 .",
    "such self - averaging property play a key role in our approach as , in the thermodynamic limit , the motion turns out to be free .",
    "moreover , as shown in appendix a , the limit f(t,)=_nf_n(t , ) , exists , and @xmath325 can then be obtained solving the free - field hamilton - jacobi problem as @xmath326 from standard arguments of classical mechanics , it is simple to show that the solution for the principal hamilton function , i.e. the free energy , is the integral of the lagrangian over time plus the initial condition ( which has the great advantage of being a trivial one - body calculation as @xmath327 decouples the neurons ) .",
    "more explicitly , @xmath328 where the lagrangian can be written as @xmath329 having neglected the potential , the motion must be constrained in straight hyperplanes , and the cauchy problem is @xmath330 we can now write the solution more explicitly as @xmath331\\\\ \\nonumber & = & \\ln 2+\\frac{t}{2}\\sum_\\mu \\langle \\tilde{m}_\\mu   \\rangle^2 + \\left \\langle \\ln \\left \\ { \\cosh \\left [ \\sum_\\mu ( \\tilde{x}_\\mu -t \\langle \\tilde{m}_\\mu\\rangle)\\tilde{\\xi}^\\mu \\right ] \\right \\ } \\right \\rangle.\\end{aligned}\\ ] ]        we can proceed to extremization , namely @xmath334 to get @xmath335      \\rangle,\\ ] ] which , turning to the original variables , can be written as @xmath336 \\right \\rangle.\\end{aligned}\\ ] ] which are the equations that have been used trough the text . for the sake of clearness ,",
    "the expression for the mattis magnetizations m_= ^is written extensively for @xmath213 , namely @xmath337 + \\\\ & + & \\frac{(1-d)^2}{2}\\tanh[\\frac{\\beta}{2}(z_1-z_2)(c - b)]+d(1-d ) \\tanh \\left [ \\frac{\\beta}{2}(z_1 c+z_2 b ) \\right],\\\\ m_2 & = & \\frac{(1-d)^2}{2}\\tanh[\\frac{\\beta}{2}(z_1+z_2)(c+b)]+\\frac{(1-d)^2}{2 } \\tanh[\\frac{\\beta}{2}(z_1-z_2)(c - b)]+ \\nonumber \\\\ & + & d(1-d ) \\tanh[\\frac{\\beta}{2}\\frac{1}{2}((z_1+z_2)(c+b)-(z_1-z_2)(b - c )   ) ] , \\end{aligned}\\ ] ]            this work is supported by firb grant rbfr08ekev .",
    "+ sapienza universita di roma and infn are acknowledged too for partial financial support .",
    "+ the authors are grateful to ton coolen and francesco moauro for useful discussions ."
  ],
  "abstract_text": [
    "<S> in this work , we first revise some extensions of the standard hopfield model in the low storage limit , namely the correlated attractor case and the multitasking case recently introduced by the authors . the former case is based on a modification of the hebbian prescription , which induces a coupling between consecutive patterns and this effect is tuned by a parameter @xmath0 . in the latter case , dilution is introduced in pattern entries , in such a way that a fraction @xmath1 of them is blank . </S>",
    "<S> then , we merge these two extensions to obtain a system able to retrieve several patterns in parallel and the quality of retrieval , encoded by the set of mattis magnetizations @xmath2 , is reminiscent of the correlation among patterns . by tuning the parameters @xmath1 and @xmath0 , qualitatively different outputs emerge , ranging from highly hierarchical , to symmetric . </S>",
    "<S> the investigations are accomplished by means of both numerical simulations and statistical mechanics analysis , properly adapting a novel technique originally developed for spin glasses , i.e. the hamilton - jacobi interpolation , with excellent agreement . </S>",
    "<S> finally , we show the thermodynamical equivalence of this associative network with a ( restricted ) boltzmann machine and study its stochastic dynamics to obtain even a dynamical picture , perfectly consistent with the static scenario earlier discussed . </S>"
  ]
}