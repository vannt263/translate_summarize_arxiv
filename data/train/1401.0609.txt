{
  "article_text": [
    "the main driver for this work was the need for a class of distribution - free tests for discrete distributions .",
    "the basic step , reported in section  [ sec2 ] below , could have been made long ago , maybe even soon after the publication of the classical papers of @xcite and fisher ( @xcite , @xcite ) .",
    "however , the tradition of using the chi - square goodness - of - fit statistic became so widely spread , and the point of view that , for discrete distributions , other statistics `` have to '' have their asymptotic distributions dependent on the individual probabilities , became so predominant and `` evident , '' that it required a strong impulse to examine the situation again .",
    "it came , in this case , in the form of a question from professor ritei shibata , `` why is the theory of distribution - free tests for discrete distributions so much more narrow than for continuous distributions ? ''",
    "if it is true that sometimes a question is half of the answer , then this is one such case .",
    "we recall that for continuous distributions , the idea of the time transformation @xmath4 of @xcite , along with subsequent papers of @xcite and @xcite , was always associated with a _ class _ of goodness - of - fit statistics .",
    "the choice of statistics invariant under this time transformation , at least since the paper of @xcite , became an accepted in goodness - of - fit theory for continuous distributions . for discrete distributions , however , everything is locked on a single statistic , the chi - square goodness - of - fit statistic .",
    "it certainly is true that in cases like the maximum likelihood statistic for multinomial distributions [ see , e.g. , @xcite ] or like the empirical likelihood [ see , e.g. , @xcite and @xcite ] , the chi - square statistic appears as a natural asymptotic object .",
    "yet most of the time the choice of this statistic comes as a deliberate choice of one particular asymptotically distribution - free statistic .",
    "the idea of a _ class _ of asymptotically distribution free tests , to the best of our knowledge , was never considered in any serious and systematic way .",
    "this is a pity , because unlike the transformation @xmath4 , which is basically a tool for one - dimensional time @xmath5 , if we do not digress onto the transformation of @xcite or spatial martingales of @xcite , the idea behind pearson s chi - square test is applicable to any measurable space .",
    "the potential of its generalization seems , therefore , worth investigation .",
    "we will undertake one such investigation in this paper .",
    "namely , we will obtain a transformation of the vector @xmath6 of components of pearson s chi - square statistic ( see below ) into a vector @xmath7 , which will be shown to be asymptotically distribution free .",
    "therefore , any functional based on @xmath7 can be used as a statistic of an asymptotically distribution - free test for the corresponding discrete distribution .",
    "thus the paper demonstrates , we hope , that the geometric insight behind the papers of @xcite or @xcite goes considerably further than one goodness - of - fit statistic .    in the remaining part of this we present a typical result of this paper .",
    "general results and other , may be more convenient , forms of the transformation are given in the appropriate sections later on .",
    "let @xmath8 be a discrete probability distribution ; all @xmath9 and @xmath10 .",
    "denote @xmath11 the corresponding frequencies in a sample of size @xmath12 , and consider the vector @xmath6 of components of the chi - square statistic @xmath13 let @xmath14 denote a vector of @xmath15 independent @xmath16 random variables . as @xmath17 the vector @xmath6 has a limit distribution of the zero - mean gaussian vector @xmath18 such that @xmath19 where @xmath20 denotes the vector @xmath21 . here and",
    "below we use the notation @xmath22 for inner product of vectors @xmath23 and @xmath24 in @xmath25 : @xmath26 .    according to ( [ chi ] )",
    "the vector @xmath27 is an orthogonal projection of @xmath28 parallel to @xmath20 .",
    "of course its distribution depends on @xmath29it is only the sum of squares @xmath30 which is chi - square distributed and hence has a distribution free from @xmath20 .",
    "it is for this reason that we do not have any other asymptotically distribution - free goodness - of - fit test for discrete distributions except the chi - square statistic @xmath31 in particular , the asymptotic distribution of partial sums based on @xmath32 , like @xmath33 which would be discrete time analogues of the empirical process , will certainly depend on @xmath20 , as will the asymptotic distribution of statistics based on them .",
    "here we would like to refer to paper of @xcite , which advances the point of view that goodness - of - fit tests for discrete distributions should be thought of as based on empirical processes in discrete time , that is , on the partial sums on the right . in the same vein",
    ", @xcite considered quadratic functionals based on these partial sums , as direct analogues of ( weighted ) omega - square statistics .",
    "we refer also to @xcite , where tables for some quantiles of kolmogorov  smirnov statistics from the partial sums are calculated in the parametric problem , described in the supplementary material [ @xcite ] .",
    "these papers illustrate the dependence on the hypothetical distribution @xmath34 very clearly .",
    "we do not know of many attempts to construct distribution - free tests for discrete distributions , but one such , suggested in @xcite , stands out for its simplicity and clarity : any discrete distribution function @xmath35 can be replaced by a piece - wise linear distribution function @xmath36 with the same values as @xmath35 at the ( nowhere dense ) jump points of the latter ; this opens up the possibility to use time transformation @xmath37 and thus obtain distribution - free tests .",
    "however , without inquiring about the consequences of implied additional randomization between the jump points , this approach remains a one - dimensional tool .    in this paper",
    "we introduce a vector @xmath38 as follows : let @xmath39 be the unit length `` diagonal '' vector with all coordinates @xmath40 , and put @xmath41 more explicitly , @xmath42 we will see that the following statement for @xmath7 is true :    [ notag ] let @xmath43 denote the vector with all @xmath15 coordinates equal to @xmath44 .",
    "the asymptotic distribution of @xmath7 is that of another , standard orthogonal projection @xmath45 and therefore any statistic based on @xmath7 is asymptotically distribution free .",
    "the transformation of @xmath6 to @xmath7 is one - to - one .",
    "thus the problem of testing @xmath34 is translated into the problem of testing uniform discrete distribution of the same dimension @xmath15 .",
    "in particular , partial sums @xmath46 will asymptotically behave as a discrete time analog of the standard brownian bridge . on the other hand ,",
    "since the transformation from @xmath6 to @xmath7 is one - to - one , @xmath7 carries the same amount of statistical information as @xmath6 .    for the proof of the proposition , see theorem [ teoteo1 ] below",
    "we will see that this is not an isolated result , but one of several possible results , and it follows from one particular point of view , which is explained in the next section .",
    "we carry it on to the parametric case in section  [ sec3 ] .",
    "the idea behind the transformation ( [ z ] ) can be explained as follows : the problem with the vector @xmath27 is that it projects a  standard vector @xmath28 parallel to a specific vector , the vector @xmath20 . this vector changes and with it changes the distribution of @xmath27 . however , using an appropriate unitary operator , which incorporates @xmath20 , one can `` turn '' @xmath27 so that the result will be an orthogonal projection parallel to a standard vector .",
    "one such standard vector can be the vector @xmath47 above .",
    "slightly more generally , let @xmath48 and @xmath39 be two vectors of unit length in @xmath15-dimensional space @xmath25 .",
    "apart from obvious particular choice of @xmath49 and @xmath50 , we will consider other choices later on as well .",
    "denote by @xmath51 the @xmath52-dimensional subspace of @xmath25 , generated by the vectors @xmath48  and  @xmath39 , and by @xmath53 its orthogonal complement in @xmath25 . in the lemma below we write @xmath54 for the part of @xmath48 orthogonal to @xmath39 , and @xmath55 for the part of @xmath39 orthogonal to @xmath48 : @xmath56 and let @xmath57 .",
    "obviously , vectors @xmath39 and @xmath58 form an orthonormal basis of @xmath59 and vectors @xmath48 and @xmath60 form another orthonormal basis . consider @xmath61 with some @xmath62 , as a linear operator in @xmath59 .    [ lem1 ]",
    "the operator @xmath63 is unitary if and only if the vectors @xmath64 and @xmath65 are orthonormal , @xmath66    the unitary operator @xmath63 maps @xmath48 to @xmath39 , @xmath67 if and only if @xmath68 and @xmath69 .",
    "altogether @xmath70 is the unitary operator in @xmath71 , which maps vector @xmath48 to vector @xmath39",
    ". it also maps vector @xmath55 to vector @xmath72 .    in what follows in this section",
    "we will choose the sign @xmath73 .",
    "it is clear that if vector @xmath5 is orthogonal to @xmath48 and @xmath39 , then @xmath74 .",
    "in other words , @xmath63 annihilates @xmath75 . denote @xmath76 the projection operator parallel to @xmath71 , so that it is the identity operator on @xmath75 and annihilates the subspace @xmath59 .",
    "then the operator @xmath77 is a unitary operator on @xmath25 .",
    "we use it to obtain our first result .",
    "suppose vector @xmath27 is projection of @xmath28 , parallel to the vector @xmath48 , @xmath78    [ teoteo1 ] the vector @xmath79 is also a vector with independent @xmath16 coordinates .",
    "the vector @xmath80 is projection of @xmath81 parallel to @xmath39 , @xmath82    ( i )  by its definition , vector @xmath27 is the orthogonal projection of @xmath28 , parallel to @xmath48 .",
    "therefore , if we project it further as @xmath83 we will obtain the vector @xmath84 orthogonal to both @xmath48 and @xmath39 , that is , a vector in @xmath85 .",
    "if we apply operator @xmath76 to @xmath84 it will not change , while @xmath63 will annihilate it , and thus @xmath86 noting that @xmath87 we obtain the right - hand side of ( [ total ] ) .",
    "coordinates of @xmath81 are independent @xmath16 random variables if the covariance matrix @xmath88 is the identity matrix on @xmath25 .",
    "we have @xmath89    \\(ii ) note that the orthogonality property of @xmath27 , @xmath90 , implies that @xmath91 , and re - write ( [ total ] ) as @xmath92 also note that @xmath93 and so that @xmath94 is indeed the projection of @xmath81 , we need @xmath95    the second statement of this theorem , together with the classical statement @xmath96 , and the choice of @xmath97 and @xmath98 , proves the proposition of the .",
    "the nature of the transformation and the proof given above does not depend on a particular choice of the vector @xmath39 and is correct for any @xmath39 of unit length .",
    "for example , we can choose @xmath99 .",
    "then the transformed vector @xmath7 will have coordinates @xmath100 or @xmath101 as a corollary of the previous theorem we obtain a vector with very simple asymptotic behavior .    [ cor2 ] if @xmath102 , then for the vector @xmath7 defined in ( [ ind ] ) we have @xmath103    to find the asymptotic distribution of statistics based on this choice of @xmath7 may be more convenient than in the previous case . yet",
    "the relationship between the two is one - to - one .",
    "it is often the case that the probabilities @xmath8 depend on a parameter , which has to be estimated from observed frequencies .",
    "this case needs additional consideration which we defer to the next section . however , there are also cases when the hypothetical probabilities are fixed , or the value of the parameter is estimated from previous samples , and therefore needs to be treated as a given . in these cases",
    "theorem [ teoteo1 ] is directly applicable .",
    "one important case of this type is the two - sample problem .",
    "namely , let events , labeled by @xmath104 , be basically as above , and let @xmath105 and @xmath106 be frequencies of these events in two independent samples of size @xmath107  and  @xmath108 , respectively .",
    "let @xmath109 denote the frequencies in the pooled sample of size @xmath110 .",
    "then the normalized differences @xmath111 are the components of the two sample chi - square statistic : the sum of their squares is the statistic .",
    "conditions which guarantee convergence of the vector @xmath112 of these differences in distribution to the vector @xmath27 are well known ; see , for example , @xcite , or @xcite and references therein .",
    "then it follows from theorem [ teoteo1 ] that under these conditions the vector @xmath113 with coordinates @xmath114 converges in distribution to vector @xmath115 and , hence , is asymptotically distribution free . to show this result one needs only to choose as @xmath48 the vector @xmath116 in theorem [ teoteo1 ] above .",
    "corollary [ cor2 ] suggests another choice of the transformed vector with coordinates @xmath117 with also simple asymptotic behavior .",
    "we will now see that the pivotal property of @xmath6 to behave as asymptotically orthogonal projection of @xmath28 remains true for components of chi - square statistic with estimated parameter .",
    "indeed , if the hypothetical probabilities depend on a @xmath118-dimensional parameter , @xmath119 , which is estimated via maximum likelihood or minimum chi - square , then the statistic @xmath120 has chi - square distribution with @xmath121 degrees of freedom ; see extensive review of this matter in @xcite , chapter  19",
    ". notwithstanding great convenience of this result , note , however , that the asymptotic distribution of the vector @xmath122 itself , with @xmath123 depends , under hypothesis , not only on the probabilities @xmath124 at the true value of  @xmath125 , but also on their derivatives in @xmath125 .",
    "therefore , the limit distribution of statistics from @xmath126 in general will depend on the hypothetical parametric family and on the value of the parameter .    at the same time , it is well known since long ago [ see , e.g. , @xcite , chapter  20 ; a modern treatment can be found in @xcite ] that under mild assumptions the maximum likelihood ( and minimum chi - square ) estimator possesses asymptotic expansion of the form @xmath127 where @xmath128 denotes the @xmath118-dimensional vector of derivatives of @xmath124 in @xmath125 and @xmath129 denotes the @xmath130 fisher information matrix . at the same time",
    ", the expansion @xmath131 is also true . combining these two expansions ,",
    "one obtains @xmath132 use the notation @xmath133 and remember that @xmath134 that is , that the vectors in @xmath135 , which form @xmath136 , are orthogonal to the vector @xmath137 .",
    "therefore all @xmath118 coordinates of @xmath138 form , in @xmath135 , vectors which are orthonormal and orthogonal to the vector @xmath139 .",
    "together with ( [ chi ] ) this implies the convergence in distribution of @xmath140 to gaussian vector @xmath141    it is easily seen that expression ( [ limyhat ] ) describes @xmath142 as an orthogonal projection of  @xmath28 parallel to vectors @xmath137 and @xmath136 ; see @xcite for an analogous description of empirical processes . using this description , we can extend the method of section  [ sec2 ] to the present situation .",
    "indeed , let us assume from now on that @xmath143 , which will make the presentation more transparent .",
    "having two vectors , @xmath144 and @xmath145 , which determine the asymptotics of @xmath122 , let us choose now a standard vector @xmath39 of unit length and another vector , @xmath146 , also of unit length and orthogonal to @xmath39 .",
    "heuristically , one may think of it as a normalized `` score function '' for some `` standard '' family around @xmath39 .",
    "for example , choose @xmath147 and choose any unit vector , such that @xmath148 .",
    "two such choices , we think , will be particularly useful : for @xmath15 even , @xmath149 or @xmath150 with the `` plateau '' of @xmath151s taken @xmath152-long , and for @xmath15 odd put , say , the last coordinate equal @xmath153 .",
    "whatever the choice of @xmath146 , suppose we chose and fixed it .",
    "it is obvious that the vector @xmath154 has a distribution totally unconnected , and hence free from the parametric family  @xmath155 .",
    "consider now the subspace @xmath156 .",
    "we do not need to insist that it is a 4-dimensional subspace , but typically it is , at least , as far as we have freedom in @xmath146 .",
    "let @xmath157 denote the orthogonal complement of @xmath158 to @xmath25 .",
    "two bases of the space @xmath158 will be useful : one is formed by @xmath159 where @xmath160 and @xmath161 are re - arrangements of @xmath48 and @xmath145 , which are orthonormal and orthogonal to @xmath39  and  @xmath146 ; the other is formed by @xmath162 where @xmath163  and  @xmath164 are , re - arrangements of @xmath39  and  @xmath146 , which are orthonormal and orthogonal to @xmath48 and @xmath145 .",
    "we will consider particular forms of these vectors later on .",
    "[ lem2 ] the operator @xmath165 is a unitary operator on @xmath158 and such that @xmath166    [ therm3 ] under convergence in distribution of the vector @xmath122 with coordinates ( [ 3 - 1 ] ) to the gaussian vector @xmath142 given by ( [ limyhat ] ) , the vector @xmath167 converges in distribution to the gaussian vector @xmath168 given by ( [ zhat ] ) .",
    "therefore , any statistic based on @xmath7 is asymptotically distribution free .",
    "let @xmath169 be orthogonal complement of the subspace @xmath170 in @xmath25 and let @xmath171 be projector on the @xmath172 . we need to verify two things : ( a )  that the vector @xmath168 can be obtained as @xmath173 and ( b ) that its explicit form is as given in the theorem .",
    "we show ( a ) slightly differently from what was done in theorem [ teoteo1 ] .",
    "namely , recall that the covariance operator of @xmath142 is the projector @xmath174 , where @xmath175 stands for an identity operator on @xmath25 , and consider the covariance operator of @xmath176 : @xmath177 however , @xmath178 while @xmath179 and @xmath180 .",
    "this implies that @xmath181 which is the covariance operator of @xmath168 .    to show ( b ) use the basis @xmath162 and the orthogonality of @xmath142 to @xmath48 and @xmath145 to find that the projection of @xmath142 on @xmath182 can be written as @xmath183 and therefore the difference @xmath184 will remain unchanged by the operator @xmath171 . at the same time @xmath185 and @xmath186 .",
    "this leads to the following form of our transformed vector @xmath168 : @xmath187    with regard to practical applications , there are several natural choices of vectors @xmath188 .",
    "for example , denote @xmath189 the part of @xmath39 orthogonal to both @xmath48 and @xmath145 , and choose @xmath190 and , similarly , choose @xmath164 as @xmath191 in dual way , we can choose specific @xmath160 and @xmath161 as @xmath192 and @xmath193    a more symmetric choice would be @xmath194 and @xmath195 where @xmath196 is correlation coefficient between @xmath189 and @xmath197 . note that in both cases the inner products @xmath198 and",
    "@xmath199 become linear combinations of just @xmath200 and @xmath201 . for the last , symmetric choice ,",
    "for example , they are @xmath202 respectively .",
    "although the choice of @xmath203 is a natural one , the different choice of the vectors @xmath39 and @xmath146 leads to simpler form of the transformed vector with convenient and simple asymptotic distribution .",
    "namely , let @xmath204 and @xmath205 . then @xmath200 and @xmath206 become @xmath207 respectively , with @xmath208 the form of vectors @xmath209 and @xmath161 also becomes simpler .",
    "similar to corollary  [ cor2 ] , we have the following :    [ corh2 ] if @xmath99 and @xmath210 and if @xmath211 with @xmath142 described in ( [ limyhat ] ) , then for the vector @xmath212 described in the theorem [ therm3 ] , we have @xmath213 where @xmath214 are independent and @xmath16-distributed .",
    "although explicit coordinate representation through vectors @xmath163 , @xmath164 , @xmath160 , @xmath161 is useful in several ways , another representation may be simpler , especially when more than one parameter is present .",
    "let us start with notation @xmath215 this is a unitary operator in @xmath25 , which maps @xmath48 into @xmath39 and @xmath39 into @xmath48 , while any vector orthogonal to @xmath39 and @xmath48 is mapped into itself .",
    "note that @xmath216 is hellinger distance between distributions given by probabilities @xmath217 and @xmath218 and that @xmath219 we thus see that @xmath220 is simply a shorter notation for the operator @xmath77 of section  [ sec2 ] . now consider an image @xmath221 of @xmath145 .",
    "this vector is orthogonal to  @xmath39 .",
    "consider another operator @xmath222 .",
    "since both @xmath223 and @xmath146 are orthogonal to @xmath39 , this operator will leave @xmath39 unchanged , while mapping @xmath223 to @xmath146 .",
    "the product @xmath224 will be another form of the operator @xmath225 , and ( [ teo3 ] ) can be written as=-1 @xmath226=0 this recursive representation can obviously be extended for any @xmath227 .",
    "one would hope that numerical verification of the whole approach will be attempted in the future .",
    "this will require a substantial amount of time and more room than the present paper could allow .",
    "we also stress that this paper does not advocate any particular test ; its aim is to provide a  satisfactory foundation on which various goodness - of - fit tests can be based .",
    "however , in the supplementary material [ @xcite ] we tried the approach on a testing problem of independent interest : goodness - of - fit testing of the power - law distributions with the zipf law and the karlin ",
    "rouault law as alternatives .",
    "we show some illustrations of how particular test statistics based on partial sums of @xmath32 and partial sums of @xmath228 perform in this problem .    in this section we restrict ourselves with one numerical illustration of",
    "how quickly the asymptotic distribution freeness of vector @xmath229 of ( [ teo3 ] ) start manifesting itself for finite @xmath12 .",
    "for this we considered three different choices of @xmath230 of the same @xmath231 . as the first choice we picked these probabilities at random : 9 uniform random variables have been generated once and the resulting uniform spacings were used as these probabilities ; as the second and third choices we used increments @xmath232 , @xmath233 , of beta distribution function with a bell shaped density , with parameters 3 and 3 , and then with @xmath234-shaped density , with parameters 0.8 and 1.5 .     for three different discrete distributions , as described in the text .",
    "10,000 simulations of samples of size @xmath235 have been used .",
    "the dimension of the discrete distributions ( number of different events ) was @xmath231 . ]    from each of these distributions we generated 10,000 samples of size @xmath235 , and for each sample calculated a discrete version of the kolmogorov ",
    "smirnov statistic @xmath236 figure  [ figdiscrete ] shows three graphs of the resulting empirical distribution functions .",
    "in our choice of @xmath12 we tried to achieve what is typically required for an application of pearson s chi - square statistics , that all @xmath237 will be at least @xmath238 .",
    "otherwise we tried to choose @xmath12 not large .",
    "for @xmath235 the requirement @xmath239 was not strictly satisfied , and in the last two cases we had about three cells with @xmath237 about 5 .",
    "this could have somewhat spoiled the asymptotic result , but has not .",
    "if the three graphs are not very distinct , that is because for all three cases they are very close .",
    "our statistic @xmath240 indeed looks distribution free .",
    "for numerical results of the last section and in the supplementary material [ @xcite ] i am indebted to boyd anderson and thuong nguyen , and also to dr ray brownrigg ."
  ],
  "abstract_text": [
    "<S> the paper proposes one - to - one transformation of the vector of components @xmath0 of pearson s chi - square statistic , @xmath1 into another vector @xmath2 , which , therefore , contains the same `` statistical information , '' but is asymptotically distribution free . </S>",
    "<S> hence any functional / test statistic based on @xmath2 is also asymptotically distribution free . </S>",
    "<S> natural examples of such test statistics are traditional goodness - of - fit statistics from partial sums @xmath3 .    </S>",
    "<S> the supplement shows how the approach works in the problem of independent interest : the goodness - of - fit testing of power - law distribution with the zipf law and the karlin  </S>",
    "<S> rouault law as particular alternatives . </S>"
  ]
}