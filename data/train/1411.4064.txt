{
  "article_text": [
    "we present an algorithmic improvement to the method of siddharth  @xcite .",
    "this prior work presented the _ sentence tracker _ , a method for scoring how well a sentence describes a video clip or alternatively how well a video clip depicts a sentence .",
    "this method operates by applying an object detector to each frame of the video clip to detect and localize instances of the nouns in the sentence and stringing these detections together into tracks that satisfy the conditions of the sentence . to compensate for false negatives in the object - detection process , the detectors are biased to overgenerate ; the tracker must then select a single best detection for each noun in the sentence in each frame of the video clip that , when assembled into a collection of tracks , best depicts the sentence .",
    "this prior work presented both a cost function for doing this as well as an algorithm for finding the optimum of this cost function . while this algorithm is guaranteed to find the global optimum of this cost function",
    ", the space and time needed is exponential in the number of nouns in the sentence ,  the number of simultaneous objects to track . here ,",
    "we present an improved method for optimizing the same cost function .",
    "we prove that a relaxed form of the cost function has the same global optimum as the original cost function .",
    "we empirically demonstrate that local search on the relaxed cost function finds a local optimum that is qualitatively close to the global optimum .",
    "moreover , this local search method takes space that is only linear in the number of nouns in the sentence .",
    "each iteration takes time that is also only linear in the number of nouns in the sentence . in practice",
    ", the search process converges quickly .",
    "this result is important because the sentence tracker , as a scoring function , supports three novel applications @xcite : the ability to focus the attention of a tracker with a sentence that describes which actions and associated participants to track in a video clip that depicts multiple such , the ability to generate rich sentential descriptions of video clips with nouns , adjectives , verbs , prepositions , and adverbs , and the ability to search for video clips , in a large video database , that satisfy such rich sentential queries .",
    "since the method presented here optimizes the same cost function , it yields essentially identical scoring results , allowing it to apply in a plug - compatible fashion , unchanged , to all three of these applications , allowing them to scale to significantly larger problems .",
    "the sentence tracker is based on the _ event tracker _",
    "@xcite which is , in turn , based on detection - based tracking @xcite .",
    "the general idea is to bias an object detector to overgenerate , producing  @xmath0 detections , denoted @xmath1 , for each frame @xmath2 in the video clip .",
    "each detection  @xmath3 has a score  @xmath4 , higher scores indicating greater confidence .",
    "moreover , there is a measure  @xmath5 of temporal coherence between detections in adjacent frames .",
    "if  @xmath6 is a detection in frame @xmath7 and @xmath3  is a detection in frame  @xmath8 , higher values of @xmath5 indicate that the position of  @xmath3 relative to  @xmath6 is consistent with observed motion in the video , between frames  @xmath7 and  @xmath8 , such as may be computed with optical flow .",
    "detection - based tracking seeks to find a detection index  @xmath9 for each frame  @xmath8 such that the track @xmath10 , composed of the selected detections @xmath11 , maximizes both the overall detection score and the overall temporal coherence .",
    "one way that this can be done is by adopting the following cost function : @xmath12 the advantage of this cost function is that a global optimum can be found in polynomial time with the viterbi algorithm @xcite .",
    "this is done with dynamic programming @xcite on a lattice whose columns are frames and whose rows are detections .",
    "the overall time complexity of this approach is @xmath13 and the overall space complexity is @xmath14 , where  @xmath15 is the maximal number of detections per frame .",
    "the event tracker @xcite extends this approach by adding a term to the cost function that measures the degree to which the track depicts an event .",
    "events are modeled as hmms @xcite .",
    "[ eq : tracker ] is analogous to the map estimate for an hmm over a track  @xmath16 : @xmath17 where @xmath18 denotes the transition probability from state  @xmath19 to  @xmath20 , @xmath21 denotes the state in frame  @xmath8 , and  @xmath22 denotes the probability of generating a detection  @xmath3 in state  @xmath20 . a global map estimate for the optimal state sequence @xmath23",
    "can also be found with the viterbi algorithm , on a lattice whose columns are frames and whose rows are states , in time @xmath24 and space @xmath25 , where  @xmath26 is the number of states .",
    "the event tracker operates by jointly optimizing the objectives of eqs .",
    "[ eq : tracker ] and  [ eq : map ] : @xmath27{l }      \\left(\\displaystyle\\sum_{t=1}^tf(b^t_{j^t})\\right)+      \\left(\\displaystyle\\sum_{t=2}^tg(b^{t-1}_{j^{t-1}},b^t_{j^t})\\right)\\\\      { } + \\left(\\displaystyle\\sum_{t=1}^th(k^t , b^t_{j^t})\\right)+      \\left(\\displaystyle\\sum_{t=2}^ta(k^{t-1},k^t)\\right )    \\end{array }    \\label{eq : event}\\ ] ] the global optimum of this cost function can also be found with the viterbi algorithm using a lattice whose columns are frames and whose rows are pairs of detections and states in time @xmath28 and space @xmath29 .",
    "this finds a track that not only has high scoring detections and is temporally coherent but also exhibits the spatiotemporal characteristics of the event as modeled by the hmm .",
    "the sentence tracker forms a factorial @xcite event tracker with factors for multiple tracks to represent multiple event participants and multiple hmms to represent the meanings of multiple words in a sentence to mutually constrain the overall spatiotemporal characteristics of a collection of event participants to satisfy the semantics of a sentence .",
    "different pairs of participants are constrained by different words in the sentence .",
    "for example , the sentence _ the person to the left of the chair carried the backpack away from the traffic cone towards the stool _ mutually constrains the spatiotemporal characteristics of five participants : a * person * , a * chair * , a * backpack * , a * traffic cone * , and a * stool * with the pairwise constituent spatiotemporal relations    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ [ cols= \" < \" , ]    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the sentence tracker operates by optimizing the following cost function : @xmath30{l }      \\displaystyle      \\left[\\sum_{l=1}^l        \\left(\\sum_{t=1}^tf(b^t_{j^t_l})\\right)+        \\left(\\sum_{t=2}^tg(b^{t-1}_{j^{t-1}_l},b^t_{j^t_l})\\right)\\right]\\\\      \\displaystyle          { } + \\left[\\begin{array}{l}\\displaystyle\\sum_{w=1}^w            \\begin{array}[t]{@{}l@ { } }              \\left(\\displaystyle\\sum_{t=1}^t              h_w              ( k^t_w , b^t_{j^t_{\\theta^1_w}},\\ldots , b^t_{j^t_{\\theta^{i_w}_w}})\\right)\\\\              { } + \\left(\\displaystyle\\sum_{t=2}^ta_w(k^{t-1}_w , k^t_w)\\right )            \\end{array}\\end{array}\\right ]    \\end{array }    \\label{eq : sentence}\\ ] ] where there are  @xmath31 event participants constrained by  @xmath32 content words , @xmath33  denotes the track collection @xmath34 , and @xmath35  denotes the state - sequence collection @xmath36 . in the above , the hmm output model @xmath37 is generalized to take more than one detection as input .",
    "this is to model spatiotemporal relations of arity  @xmath38 between multiple participants ( typically two ) .",
    "the _ linking function _",
    "@xmath39 specifies which participants apply in which order and is derived by syntactic and semantic analysis of the sentence .    while a global optimum to this cost function",
    "can still be found with the viterbi algorithm , using a lattice whose columns are frames and whose rows are tuples containing  @xmath31 detections and  @xmath32 states , the time complexity of such is @xmath40 and the space complexity is @xmath41 .",
    "thus both the space and time complexity is exponential in  @xmath31 and  @xmath32 , values which increase linearly with the number of nouns in the sentence .",
    "@xmath42{l }        \\left[\\begin{array}{l}\\displaystyle\\sum_{l=1}^l            \\begin{array}[t]{l }              \\left(\\displaystyle\\sum_{t=1}^t              \\displaystyle\\sum_{j=1}^{j^t } p^{t , l}_j f(b^t_j)\\right)\\\\                               { } + \\left(\\displaystyle\\sum_{t=2}^t                               \\displaystyle\\sum_{j'=1}^{j^{t-1 } }                               \\displaystyle\\sum_{j=1}^{j^t }                               p^{t-1,l}_{j ' } p^{t , l}_j                               g(b^{t-1}_{j'},b^t_j)\\right)\\\\          \\end{array}\\end{array}\\right]\\\\             { } + \\left[\\begin{array}{l}\\displaystyle\\sum_{w=1}^w                 \\begin{array}[t]{l }                   \\left(\\displaystyle\\sum_{t=1}^t                   \\displaystyle\\sum_{j_1=1}^{j^t}\\cdots                   \\displaystyle\\sum_{j_{i_w}=1}^{j^t }                   \\displaystyle\\sum_{k=1}^k                   q^{t , w}_k p^{t,{\\theta^1_w}}\\cdots",
    "p^{t,{\\theta^{i_w}_w}}_j                   h_w(k , b^t_{j_1},\\ldots , b^t_{j_{i_w}})\\right)\\\\                   { } + \\left(\\displaystyle\\sum_{t=2}^t                   \\displaystyle\\sum_{k'=1}^{k_w }                   \\displaystyle\\sum_{k=1}^{k_w }                   q^{t-1,w}_{k ' } q^{t , w}_k a_w(k',k)\\right )               \\end{array}\\end{array}\\right ]      \\end{array }      \\label{eq : sentence - relax}\\ ] ]    we reformulate eqs .  [ eq : tracker ] , [ eq : map ] , and  [ eq : event ] using indicator variables instead of indices . instead of using  @xmath9 to indicate the index of a detection  @xmath11 in frame  @xmath8",
    ", we use  @xmath43 as an indicator variable , which is zero for all indices  @xmath44 , except the index of the selected detection , for which it is one .",
    "this allows eq .",
    "[ eq : tracker ] to be reformulated as : @xmath45{l }      \\left(\\displaystyle\\sum_{t=1}^t      \\displaystyle\\sum_{j=1}^{j^t } p^t_j f(b^t_j)\\right)\\\\                       { } + \\left(\\displaystyle\\sum_{t=2}^t                       \\displaystyle\\sum_{j'=1}^{j^{t-1 } }                       \\displaystyle\\sum_{j=1}^{j^t }                       p^{t-1}_{j ' } p^t_j g(b^{t-1}_{j'},b^t_j)\\right )    \\end{array }    \\label{eq : tracker - relax}\\ ] ] similarly , instead of using  @xmath21 to indicate the state in frame  @xmath8 , we use  @xmath46 as an indicator variable , which is zero for all states  @xmath20 , except that which is selected in frame  @xmath8 , for which it is one .",
    "this allows eq .",
    "[ eq : map ] to be reformulated as : @xmath47{l }      \\left(\\displaystyle\\sum_{t=1}^t      \\displaystyle\\sum_{k=1}^k q^t_k h(k , b^t_{\\hat{\\jmath}^t}\\right)\\\\                       { } + \\left(\\displaystyle\\sum_{t=2}^t                       \\displaystyle\\sum_{k'=1}^k                       \\displaystyle\\sum_{k=1}^k q^{t-1}_{k ' } q^t_k",
    "a(k',k)\\right )    \\end{array }    \\label{eq : map - relax}\\ ] ] combining the two allows eq .",
    "[ eq : event ] to be reformulated as : @xmath48{l }      \\left(\\displaystyle\\sum_{t=1}^t      \\displaystyle\\sum_{j=1}^{j^t } p^t_j f(b^t_j)\\right)\\\\      { } + \\left(\\displaystyle\\sum_{t=2}^t      \\displaystyle\\sum_{j'=1}^{j^{t-1 } }      \\displaystyle\\sum_{j=1}^{j^t } p^{t-1}_{j ' } p^t_j g(b^{t-1}_{j'},b^t_j)\\right)\\\\      { } + \\left(\\displaystyle\\sum_{t=1}^t      \\displaystyle\\sum_{j=1}^{j^t }      \\displaystyle\\sum_{k=1}^k q^t_k p^t_j h(k , b^t_j)\\right)\\\\      { } + \\left(\\displaystyle\\sum_{t=2}^t      \\displaystyle\\sum_{k'=1}^k      \\displaystyle\\sum_{k=1}^k q^{t-1}_{k ' } q^t_k a(k',k)\\right )    \\end{array }    \\label{eq : event - relax}\\ ] ] in the above , @xmath49  and  @xmath50 denote the collections of the indicator variables  @xmath43 and  @xmath46 respectively .",
    "one can view the indicator variables  @xmath43 and  @xmath46 to be constrained to be in @xmath51 and to satisfy the sum - to - one constraints @xmath52 and @xmath53 . under these constraints , it is obvious that the formulations underlying eqs .",
    "[ eq : tracker ] and  [ eq : tracker - relax ] , as well as eqs .",
    "[ eq : map ] and  [ eq : map - relax ] , are identical .",
    "one can further apply a similar transformation to eq .",
    "[ eq : sentence ] to get eq .",
    "[ eq : sentence - relax ] , where the indicator variables  @xmath54 are further indexed by the track  @xmath55 and the indicator variables  @xmath56 are further indexed by the word  @xmath57 .",
    "@xmath58  and  @xmath59 denote the collections of all indicator variables  @xmath54 and  @xmath56 respectively .",
    "similarly , it is again clear that the formulations underlying eqs .",
    "[ eq : sentence ] and  [ eq : sentence - relax ] are identical .",
    "note that because @xmath37 is generalized to take more than one detection as input , the objective in eq .",
    "[ eq : sentence - relax ] becomes a multivariate polynomial of degree  @xmath60 , where  @xmath38 is the maximum of all of the arities  @xmath61 of all of the words , instead of a quadratic form as in eqs .",
    "[ eq : tracker - relax ] , [ eq : map - relax ] , and  [ eq : event - relax ] .    eqs .",
    "[ eq : sentence - relax ] , [ eq : tracker - relax ] , [ eq : map - relax ] , and  [ eq : event - relax ] , with unknowns taking binary values , are binary integer - programming problems ( linearly constrained in our case ) and are difficult to optimize with a large number of unknowns .",
    "thus we solve relaxed variants of these problems , taking the domain of the indicator variables to be @xmath62 $ ] instead of @xmath51 .",
    "with the unchanged sum - to - one constraints , the subcollections  @xmath63 and  @xmath64 of the indicator variables  @xmath54 and  @xmath56 over all  @xmath44 and  @xmath20 , respectively , can be viewed as discrete distributions .",
    "we show in section  [ sec : relaxation ] that , despite such relaxation , eqs .",
    "[ eq : tracker - relax ] , [ eq : map - relax ] , [ eq : event - relax ] , and  [ eq : sentence - relax ] have the same global optima as eqs .",
    "[ eq : tracker ] , [ eq : map ] , [ eq : event ] , and  [ eq : sentence ] , respectively .",
    "note that eqs .",
    "[ eq : tracker - relax ] , [ eq : map - relax ] , and  [ eq : event - relax ] are all linearly constrained quadratic - programming problems . in the typical use case of the sentence tracker , where words have maximal arity two (  the words in the sentence describe only pairwise relations between nouns ) , eq .",
    "[ eq : sentence - relax ] becomes linearly constrained cubic programming .",
    "an important property of this formulation is that the global optima of eq .",
    "[ eq : sentence - relax ] ( and thus eqs .",
    "[ eq : tracker - relax ] , [ eq : map - relax ] , and  [ eq : event - relax ] as special cases ) are the same whether the domains of the indicator variables are discrete or continuous ,  @xmath51 or @xmath62 $ ] .",
    "we prove this below .",
    "this allows us to introduce a local - search technique to solve the relaxed problems .",
    "eq .  [ eq : sentence - relax ] has the following general form : @xmath65{l }      \\displaystyle\\max_{\\mathbf{x } }      \\sum_{n=1}^n\\hspace*{-3pt}\\left(\\hspace*{-3pt }      \\mathop{\\sum_{v_{u_1}\\in v_{u_1}}\\hspace*{-7pt}\\cdots\\hspace*{-7pt}\\sum_{v_{u_n}\\in v_{u_n } } }      \\limits_{\\{u_1,\\ldots , u_n\\}\\in\\mathcal{e}_n }      \\hspace*{-8pt}\\phi(v_{u_1},\\ldots , v_{u_n } )      x^{u_1}_{v_{u_1}}\\cdots x^{u_n}_{v_{u_n } }      \\hspace*{-5pt}\\right)\\\\      \\begin{aligned }        { \\textrm{s.t.,}}\\ & ( \\forall u)(\\forall v_u)x_{v_u}^u\\ge0\\\\             & ( \\forall u)\\sum_{v_u\\in v_u } x^u_{v_u}=1\\\\      \\end{aligned}\\\\    \\end{array } }    \\label{eq : score - general}\\ ] ] where  @xmath66 are ( indicator ) variables that form a polynomial objective , @xmath67 are the coefficients of the terms in this polynomial , and we sum over all terms of the varying degree  @xmath68 .",
    "this polynomial can be viewed as denoting the overall compatibility of a labeling of an undirected hypergraph with vertices  @xmath69 , labeled  @xmath70 from a set  @xmath71 of labels , where each term denotes the compatibility of a possible labeling configuration for the vertices of some hyperedge .",
    "@xmath72 denotes the set of all hyperedges @xmath73 of size  @xmath74 .",
    "the inner nested summation over the indices  @xmath75 sums over all possible labeling configurations for a particular hyperedge . summing this over",
    "all elements of @xmath72 sums over all hyperedges of size  @xmath74 .",
    "the overall polynomial sums over all hyperedges of size @xmath68 . in the limiting case of maximal arity two",
    ", the hypergraph becomes an ordinary undirected graph and the hyperedges become ordinary undirected edges .",
    "the collection  @xmath76 of variables @xmath66 can be viewed as a discrete distribution over possible labels  @xmath77 for vertex  @xmath69 .",
    "the coefficient @xmath67 associated with each hyperedge measures the compatibility of the labels for the constituent vertices .",
    "this hypergraph can be viewed as a high - order markov random field ( mrf ) .",
    "the common case of an mrf is when @xmath78 .",
    "ravikumar and lafferty  @xcite showed that , for this case , the global optima of eq .",
    "[ eq : score - general ] are the same whether the domains of the variables are discrete or continuous ,  @xmath51 or @xmath62 $ ] .",
    "below , we generalize this result to @xmath79 .",
    "the optimal value of eq.[eq : score - general ] is the same irrespective of whether the domains of the variables are @xmath51 or @xmath62 $ ] .",
    "_ let the optimal value before relaxation be @xmath80 and the optimal value after relaxation be  @xmath81 .",
    "it is obvious that @xmath82 since @xmath83 $ ] .",
    "now we show that @xmath84 .",
    "let @xmath85 be the solution to the relaxed problem . under a probabilistic interpretation , the inner nested summation over the indices  @xmath70 constitutes an expectation of the hyperedge compatibility .",
    "thus for a particular set  @xmath85 of distributions , there must be some labeling  @xmath86 with compatibility @xmath87 . since @xmath80 is the value of the optimal labeling , @xmath88 .",
    "thus @xmath84 .",
    "@xmath89    given a solution to the relaxed problem , we can obtain a discrete solution to the original problem with the following algorithm that performs a single pass over the vertices :    label any vertex  @xmath69 for which @xmath90 , with the label  @xmath91 for which @xmath92 .",
    "label any unlabeled vertex  @xmath69 which does not satisfy the above condition with the label  @xmath91 that maximizes eq .",
    "[ eq : score - general ] while keeping the label distributions of other vertices unchanged .",
    "then set @xmath92 and @xmath93 if @xmath94 .",
    "repeat this process until all vertices are labeled .",
    "since at each step the overall compatibility does not decrease , the resulting discrete labeling will yield overall compatibility at least as good as that of the relaxed problem .",
    "however , since the relaxed overall compatibility is optimal , the discrete solution constructed by the above process must be equivalent to the continuous one .",
    "thus a global optimum of the relaxed continuous optimization problem is also a global optimum of the original combinatorial optimization problem .",
    "unfortunately , there is no effective method for finding the global optima of nonlinear objectives such as the relaxed objective in eq .",
    "[ eq : score - general ] .",
    "local search methods such as gradient descent are often used to find local optima of constrained nonlinear programs .",
    "while local search is not guaranteed to find a global optimum , we demonstrate empirically in section  [ sec : experiments ] that local search generates solutions qualitatively identical to the global optimum for eq .",
    "[ eq : sentence - relax ] .    the discrete formulation of eqs .",
    "[ eq : tracker ] , [ eq : map ] , and  [ eq : event ] , constitutes combinatorial optimization . such is feasible with the viterbi algorithm because it exploits the sequential structure of these objectives , allowing it to find a global optimum in polynomial time .",
    "more specifically , the graph structure is layered in the form of a lattice .",
    "the viterbi algorithm enumerates all possible labeling configurations at each layer in this lattice .",
    "the viterbi algorithm not only explicitly enumerates all possible labeling configurations , it achieves optimality by saving all such at one layer in the lattice to search through while computing the next layer .",
    "thus both the space and time complexity of the viterbi algorithm depends on enumeration of all possible labeling configurations .",
    "this number of possible labeling configurations is small for eqs .",
    "[ eq : tracker ] , [ eq : map ] , and  [ eq : event ] but becomes exponential in  @xmath31 and  @xmath32 for eq .",
    "[ eq : sentence ] .",
    "in contrast , the relaxation approach never explicitly enumerates all possible labeling configurations ; such enumeration is performed implicitly by local search .",
    "moreover , it never stores such .",
    "since there is no explicit enumeration in the relaxation approach , the space complexity does not depend on the number of possible labeling configurations and is polynomial in  @xmath95 , @xmath15 , @xmath26 , @xmath31 , and  @xmath32 . for eq .",
    "[ eq : sentence - relax ] , the maximal hyperedge size is the maximal arity of the semantic primitives used to represent the meanings of words out of which the meanings of sentences are constructed .",
    "this will always be independent of , and much smaller than , the sentence length",
    ". if the maximal hyperedge size is constant , then the space complexity of eq .",
    "[ eq : sentence - relax ] is polynomial .",
    "furthermore , in most cases the maximal arity is two and thus the maximal hyperedge size is three , which limits the polynomial degree to cubic objectives .",
    "we know of no analytical bound on the time complexity of the relaxation approach ; however one can construct , as we do below , a local search method where each iteration takes polynomial time but we know of no bound on the number of iterations .",
    "intuitively , one can view the iterative process as searching through possible labeling configurations . performing local search in the continuous domain",
    "can avail itself of gradient information that is unavailable when doing discrete combinatorial optimization .",
    "below we show how to use efficient local search to find a local optimum of the objective in eq .",
    "[ eq : score - general ] .",
    "note that the objective may have degree greater than two .",
    "thus we can not employ conventional methods (  belief propagation @xcite and tree - reweighted message passing @xcite ) that solve mrfs which correspond to polynomial objectives of degree two .",
    "we instead employ the growth transform ( gt )  @xcite to solve this constrained nonlinear programming problem as it applies to polynomials of any degree .",
    "other methods , such as generalized belief propagation ( gbp )  @xcite , that apply to hyperedges of any order , may be used as well .",
    "gt is a local - search technique for optimizing polynomial objectives .",
    "it is a generalized form of the baum - welch reestimation procedure  @xcite which is widely used to perform maximum - likelihood estimation of hmm parameters . in order to apply gt ,",
    "the objective must satisfy three conditions :    the objective @xmath96 must be a homogeneous polynomial ,  all terms must have the same degree . [ a ]    the coefficients must be nonnegative .",
    "[ b ]    the variables  @xmath66 must be nonnegative and satisfy the sum - to - one constraint : @xmath97 for each  @xmath69 .",
    "[ c ]    gt maximizes the objective iteratively with the following update formula : @xmath98 where  @xmath99 is an iteration - dependent normalization factor to maintain the sum - to - one constraint .",
    "we now show that eq .",
    "[ eq : sentence - relax ] , as formulated as a special case of eq .",
    "[ eq : score - general ] , can be modified to satisfy these conditions without changing the objective . clearly , condition  ( [ c ] ) is already met .",
    "conditions  ( [ a ] ) and  ( [ b ] ) can be satisfied by leveraging condition  ( [ c ] ) .",
    "suppose the maximal degree of the objective is  @xmath100 .",
    "any term with degree @xmath101 can be converted to a form with degree @xmath100 by adding redundant free variables as follows : @xmath102{@{}l@ { } }        \\displaystyle      \\sum_{v_{u_1},\\ldots , v_{u_m } }      \\phi(v_{u_1},\\ldots , v_{u_m } )      x^{u_1}_{v_{u_1}}\\cdots x^{u_m}_{v_{u_m}}\\\\        \\displaystyle      { } = \\sum_{v_{u_1},\\ldots , v_{u_m } }      \\left(\\sum_{v_{u_{m+1}},\\ldots , v_{u_n } }      x^{u_{m+1}}_{v_{u_{m+1}}}\\cdots x^{u_n}_{v_{u_n } }      \\phi(v_{u_1},\\ldots , v_{u_m})\\right )      x^{u_1}_{v_{u_1}}\\cdots x^{u_m}_{v_{u_m}}\\\\        \\displaystyle      { } = \\sum_{v_{u_1},\\ldots , v_{u_m } }      \\sum_{v_{u_{m+1}},\\ldots , v_{u_n } }      \\phi(v_{u_1},\\ldots , v_{u_m } )      x^{u_1}_{v_{u_1}}\\cdots x^{u_m}_{v_{u_m } }      x^{u_{m+1}}_{v_{u_{m+1}}}\\cdots x^{u_n}_{v_{u_n } }    \\end{array}}\\hspace*{-30pt}\\ ] ] the objective can be made homogeneous by applying the above transformation to each hyperedge of the original nonhomogeneous objective , thus satisfying condition  ( [ a ] ) .",
    "this transformation does not change the gradient with respect to existing variables , and thus does not effect the gt update formula .",
    "therefore its mere existence demonstrates that gt can apply even without performing the transformation .",
    "this is important because the transformation would increase the space and time complexity of gt .    to satisfy condition  ( [ b ] )",
    ", we increase each coefficient in the objective with a term - dependent positive constant : @xmath103{@{}l@ { } }      c_{\\{u_1,\\ldots , u_m\\}}=      \\max(\\epsilon,-\\min_{v_{u_1},\\ldots , v_{u_m}}\\phi(v_{u_1},\\ldots , v_{u_m } ) )    \\end{array } }    \\label{eq : constant}\\ ] ] where @xmath104 .",
    "we add each such constant to its corresponding term : @xmath105{l }        \\displaystyle        \\sum_{v_{u_1},\\ldots , v_{u_m } }        \\left[\\phi(v_{u_1},\\ldots , v_{u_m } ) + c_{\\{u_1,\\ldots , u_m\\}}\\right ]        x^{u_1}_{v_{u_1}}\\cdots x^{u_m}_{v_{u_m}}\\\\        \\displaystyle      { } = \\begin{array}[t]{l }      \\displaystyle      \\sum_{v_{u_1},\\ldots , v_{u_m } }        \\phi(v_{u_1},\\ldots , v_{u_m } )        x^{u_1}_{v_{u_1}}\\cdots x^{u_m}_{v_{u_m}}\\\\      \\displaystyle        { } + \\sum_{v_{u_1},\\ldots , v_{u_m } }        x^{u_1}_{v_{u_1}}\\ldots x^{u_m}_{v_{u_m } }        c_{\\{u_1,\\ldots , u_m\\ } }        \\end{array}\\\\      \\displaystyle      { } = c_{\\{u_1,\\ldots , u_m\\}}+\\sum_{v_{u_1},\\ldots , v_{u_m } }      \\phi(v_{u_1},\\ldots , v_{u_m } )      x^{u_1}_{v_{u_1}}\\ldots x^{u_m}_{v_{u_m}}\\\\    \\end{array}}\\hspace*{-20pt}\\ ] ] this term now has positive coefficients , and thus so does the whole objective , yet , the objective is unchanged .    when applying gt to eqs .",
    "[ eq : sentence - relax ] , [ eq : tracker - relax ] , [ eq : map - relax ] , and  [ eq : event - relax ] , one must store the indicator variables .",
    "however , one need not store the coefficients ; one could recompute them at every iteration .",
    "thus the space complexity is driven by the indicator variables : @xmath14 for eq .",
    "[ eq : tracker - relax ] , @xmath25 for eq .",
    "[ eq : map - relax ] , @xmath106 for eq .",
    "[ eq : event - relax ] , and @xmath107 for eq .",
    "[ eq : sentence - relax ] .",
    "each iteration of eq .",
    "[ eq : update ] is dominated by the time to compute the gradient .",
    "doing so with reverse - mode automatic differentiation ( ad ) @xcite takes the same time as computing the objective .",
    "thus the time complexity of each iteration is : @xmath13 for eq .",
    "[ eq : tracker - relax ] , @xmath24 for eq .",
    "[ eq : map - relax ] , @xmath108 for eq .",
    "[ eq : event - relax ] , and @xmath109 for eq .",
    "[ eq : sentence - relax ] .",
    "we have shown so far that    eqs .  [",
    "eq : tracker - relax ] , [ eq : map - relax ] , [ eq : event - relax ] , and [ eq : sentence - relax ] yield the same optima as eqs .",
    "[ eq : tracker ] , [ eq : map ] , [ eq : event ] , and [ eq : sentence ] when the indicator variables are constrained to be in @xmath51 and    the global optima for eqs .",
    "[ eq : tracker - relax ] , [ eq : map - relax ] , [ eq : event - relax ] , and [ eq : sentence - relax ] are the same whether the domains of the indicator variables are discrete or continuous ,  @xmath51 or @xmath62 $ ] .",
    "moreover , we have presented a gt method for performing local search for local optima of eqs .",
    "[ eq : tracker - relax ] , [ eq : map - relax ] , [ eq : event - relax ] , and [ eq : sentence - relax ] .",
    "we now present empirical evidence that the local optima produced by gt are qualitatively identical to the global optima .    when performing gt , we employed the following procedure .",
    "we randomly initialized the local search at 150 different label distributions .",
    "for each one , we ran 300 iterations of eq .",
    "[ eq : update ] .",
    "we then selected the resulting label distribution that corresponded to the highest objective and ran 5000 additional iterations on this label distribution to yield the resulting label distribution and objective . performing 150 restarts",
    "may only be necessary for problems with a large number of variables . nonetheless , for simplicity , we employed this uniform number of restarts for all experiments .",
    "we evaluated the gt method on the same dataset that was used by yu and siskind @xcite .",
    "this dataset contains 94 video clips , each with between two and five sentential annotations of activities that occur in the corresponding clip .",
    "all but one of these clips contain at least one annotated sentence with exactly three content words : a subject , a verb , and a direct object .",
    "we did not process the single clip that does not .",
    "for the remaining 93 video clips , we selected the first annotated sentence with exactly three content words .",
    "for each such video - sentence pair , we computed the global optimum to eq .",
    "[ eq : sentence ] with the viterbi algorithm using the same features and hand - crafted word hmms ( for @xmath110 , for @xmath111 extra states were added ) as used by yu and siskind @xcite . for each video - sentence pair",
    ", we also computed a local optimum to eq .",
    "[ eq : sentence - relax ] with gt using these same features and hmms .",
    "we then computed relative error ( percentage ) between the global optimum computed by the viterbi algorithm and local optimum computed by gt for each video - sentence pair , and averaged over all 93 pairs .",
    "we repeated this three times :    the average relative errors for @xmath112 , @xmath113 , and @xmath114 , are 2.22% , 2.79% , and 5.08% , respectively .",
    "[ fig : histogram ] gives histograms of the number of videos with given ranges of relative error .",
    "[ fig : histogram ]    we limited the above experiment to sentences with no more than three content words because we wished to compare against the global optimum which can only be computed with the viterbi algorithm .",
    "this process may become intractable with sentences with more than three content words , especially with large  @xmath15 . to demonstrate that the local - search approach can scale to process longer sentences we performed a second experiment . in this experiment , we processed six video clips with longer sentences .",
    "[ fig : videos ] illustrates the tracks produced for these video - sentence pairs , as derived from the indicator variables  @xmath54 .",
    "note that for the example in the fourth row in fig .",
    "[ fig : videos ] , computing the global optimum with the viterbi algorithm would take @xmath115 lattice comparisons .",
    "we estimate that this would take about 20 years on a current computer .",
    "@cccccc@ & & & & &   +   +   + & & & & &   +   +   + & & & & &   +   +   + & & & & &   +   +   + & & & & &   +   +   + & & & & &   +   +   +    [ fig : videos ]",
    "lin  @xcite present an approach for searching a database of video clips for those that match a sentential query .",
    "implicit in this is a function that scores how well a video clip depicts a sentence or alternatively how well a sentence describes a video clip .",
    "that work differs from the current work in several ways .",
    "first , they run a tracker in isolation , independently for each object , before scoring a video - sentence pair . here , we jointly perform tracking and scoring , and do so jointly for all tracks described by a sentence . this allows scoring to influence tracking and tracking one object to influence tracking other objects .",
    "second , their scoring function composes only unary primitive predicates , each applied to a single track .",
    "here , our scoring function composes multivariate primitive predicates , each applied to multiple tracks .",
    "this is what links the word meanings together and allows the entire sentential semantics to influence the joint tracking of all participants .",
    "third , the essence of their recognition process ( not training ) is that they automatically find what they denote as  @xmath116 .",
    "this maps tracks  @xmath117 to ( unary ) arguments of primitive predicates  @xmath69 . here",
    ", we solve a dual problem of automatically finding what we denote as  @xmath118 , a map from event participants  @xmath55 to detections  @xmath44 .",
    "fourth , they allow predicates to be assigned to a dummy track `` no - obj '' which allows them to ignore portions of the sentence . here , we constrain the track collection to satisfy all primitive predicates contained in a sentence .",
    "fifth , they adopt a `` no coreference '' constraint that requires that each nondummy track be assigned to a different primitive predicate . here",
    ", we allow such .",
    "this allows us to process sentences like _ the person approached the backpack to the left of the chair _ that contain , in part , primitive predicates like @xmath119 where the track @xmath120 is assigned to two different primitive predicates .",
    "sixth , they do not model temporally - varying features in their primitive predicates . here",
    ", we do so with hmms .",
    "the relaxed sentence tracker also shares some similarity in spirit with current research in image / video object co - detection / discovery @xcite based on object proposals @xcite .",
    "the goal of this line of work is to find instances of a common object across a set of different images or video frames , given a pool of object candidates generated by measuring the ` objectness ' of image windows in each image .",
    "this is done by associating a unary cost with each candidate to represent the confidence that that candidate is an object , and a binary cost between pairs of candidates to measure their similarity in appearance , resulting in a second - order mrf / crf .",
    "selecting the best candidate for each image constitutes a map estimate on this random field , and is usually relaxed to constrained nonlinear programming @xcite , or computed by a combinatorial optimization technique such as tree - reweighted message passing @xcite .",
    "except for its loopy graph structure , this formulation is analogous to detection - based tracking in eq .",
    "[ eq : tracker - relax ] .",
    "in contrast to the work presented here , prior work on object co - detection / discovery only exploits visual appearance ",
    "analogous to the term  @xmath4 in eq .",
    "[ eq : tracker - relax]and object - pair similarity  analogous to the term @xmath5 in eq .",
    "[ eq : tracker - relax]but not the degree to which an object track exhibits particular spatiotemporal behavior , as is done by the terms @xmath22 and @xmath18 in the event tracker , eq .",
    "[ eq : event - relax ] , let alone the joint detection / discovery of multiple objects that exhibit the collective spatiotemporal behavior described by a sentence , as is done in the sentence tracker , eq .",
    "[ eq : sentence - relax ] .",
    "siddharth  @xcite , barbu @xcite , and yu and siskind @xcite present a variety of applications for the sentence tracker . since the sentence tracker is simply a scoring function that scores a video - sentence pair , one can use it for the following applications :    given a single video clip as input , that contains two different activities taking place with different subsets of participants , along with two different sentences that each describe these different activities , produce two different track collections that delineate the participants in the two different activities .    given a video clip as input ,",
    "produce a sentence as output that best describes the video clip by searching the space of all possible sentences to find the one with the highest score on the input video clip .    given a sentential query as input ,",
    "search a dataset of video clips to find that clip that best depicts the query by searching all clips to find the one with the highest score on the input query .",
    "given a training corpus of video clips paired with sentences that described these clips , search the parameter space of the models for the words in the lexicon that yields the highest aggregate score on the training corpus .",
    "with the exception of the last use case , language acquisition , the other use cases all treat the sentence tracker as a black box .",
    "we have demonstrated a plug - compatible black box that takes the same input in the form of a video - sentence pair and produces the same output in the form of a score and a track collection .",
    "since we have proven that the global optimum to the relaxed objective is the same as that for the original objective , and further empirically demonstrated that local search tends to find a local optimum that is qualitatively the same as the global one , one can employ this relaxed method to perform exactly the same first three uses cases as the original sentence tracker with identical , or nearly identical results .",
    "the chief advantage of the relaxed method is that it scales to longer sentences .",
    "more precisely , we demonstrate three distinct kinds of scaling :    because the original sentence tracker had space complexity of @xmath41 and time complexity @xmath40 it was , in practice , limited to small  @xmath15 , typically at most  20 . here , we perform experiments that demonstrate scaling to @xmath121 .    similarly , the original sentence tracker was limited , in practice , to small  @xmath26 , typically at most  3 . here , we perform experiments that demonstrate scaling to @xmath111 .",
    "is , in fact , determined by the number of frames , which is 15 , on average , in our experiments ]    similarly , the original sentence tracker was limited , in practice , to small  @xmath31 and  @xmath32 , typically @xmath122 ,  at most three nouns in the sentence , and typically at most two words that have more than one state in their hmm .",
    "( words that describe static properties , like nouns , adjectives , and spatial - relation prepositions , typically have a single - state hmm while words that describe dynamic properties , like verbs , adverbs , and motion prepositions , typically have multiple states . ) here , we perform experiments that demonstrate scaling to @xmath123 and @xmath124 .",
    "since the method of yu and siskind @xcite for the fourth use case , namely language acquisition , does not use the sentence tracker as a black box , extending our new method to this use case is beyond the scope of this current work .",
    "the sentence tracker has previously been demonstrated to be a powerful framework for a variety of applications , both theoretical and potentially practical . it can serve as a model of grounded child language acquisition @xcite as well as the basis for searching full - length hollywood movies for clips that match rich sentential queries @xcite in a way that is sensitive to subtle semantic distinctions in the queries .",
    "however , until now , it was impractical to apply in many situations that require scaling to complex sentences with many event participants .",
    "our results remove that barrier .",
    "this research was sponsored , in part , by the army research laboratory and was accomplished under cooperative agreement number w911nf-10 - 2 - 0060 . the views and conclusions contained in this document",
    "are those of the authors and should not be interpreted as representing the official policies , either express or implied , of the army research laboratory or the u.s .",
    "government is authorized to reproduce and distribute reprints for government purposes , notwithstanding any copyright notation herein ."
  ],
  "abstract_text": [
    "<S> prior work presented the sentence tracker , a method for scoring how well a sentence describes a video clip or alternatively how well a video clip depicts a sentence . </S>",
    "<S> we present an improved method for optimizing the same cost function employed by this prior work , reducing the space complexity from exponential in the sentence length to polynomial , as well as producing a qualitatively identical result in time polynomial in the sentence length instead of exponential . </S>",
    "<S> since this new method is plug - compatible with the prior method , it can be used for the same applications : video retrieval with sentential queries , generating sentential descriptions of video clips , and focusing the attention of a tracker with a sentence , while allowing these applications to scale with significantly larger numbers of object detections , word meanings modeled with hmms with significantly larger numbers of states , and significantly longer sentences , with no appreciable degradation in quality of results . </S>"
  ]
}