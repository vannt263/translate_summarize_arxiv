{
  "article_text": [
    "consider a book recommendation system . given a customer s profile , the system recommends a few possible books to the user by means of , e.g. , a limited number of banners placed at different positions on a webpage . the system s goal is to select books that the user likes and possibly purchases .",
    "typical feedback in such systems is the actual action of the user or , in particular , what books he has bought / preferred , if any .",
    "the system can not observe what would have been the user s actions had other books got recommended , or had the same book ads been placed in a different order within the webpage .",
    "such problems are collectively referred to as learning with partial feedback . as opposed to the full information case , where the system ( the learning algorithm ) knows the outcome of each possible response ( e.g. , the user s action for each and every possible book recommendation placed in the largest banner ad ) , in the partial feedback setting",
    ", the system only observes the response to very limited options and , specifically , the option that was actually recommended .    in this and many other examples of this sort , it is reasonable to assume that recommended options are not given the same treatment by the system , e.g. , large banners which are displayed on top of the page should somehow be more committing as a recommendation than smaller ones placed elsewhere .",
    "moreover , it is often plausible to interpret the user feedback as a preference ( if any ) _ restricted to _ the displayed alternatives .    in this paper",
    ", we consider instantiations of this problem in the multilabel and learning - to - rank settings .",
    "learning proceeds in rounds , in each time step @xmath1 the algorithm receives an instance @xmath2 and outputs an ordered subset @xmath3 of labels from a finite set of possible labels @xmath4 = \\{1 , 2 , \\ldots , k\\}$ ] .",
    "restrictions might apply to the size of @xmath3 ( due , e.g. , to the number of available slots in the webpage ) .",
    "the set @xmath3 corresponds to the aforementioned recommendations , and is intended to approximate the true set of preferences associated with @xmath2 .",
    "however , the latter set is never observed . in its stead , the algorithm receives @xmath5 , where @xmath6 $ ] is a _ noisy version _ of the true set of user preferences on @xmath2 .",
    "when we are restricted to @xmath7 for all @xmath1 , this becomes a multiclass classification problem with bandit feedback  see below .",
    "this paper lies at the intersection between online learning with partial feedback and multilabel classification / ranking .",
    "both fields include a substantial amount of work , so we can hardly do it justice here . in the sequel , we outline some of the main contributions in the two fields , with an emphasis on those we believe are the most related to this paper .",
    "a well - known tool for facing the problem of partial feedback in online learning is to trade off exploration and exploitation through upper confidence bounds .",
    "this technique has been introduced by @xcite , and can by now be considered a standard tool . in the",
    "so - called _ bandit _ setting with contextual information ( sometimes called bandits with side information or bandits with covariates , e.g. , @xcite , and references therein ) an online algorithm receives at each time step a _ context _ ( typically , in the form of a feature vector @xmath8 ) and is compelled to select an action ( e.g. , a label ) , whose goodness is quantified by a predefined loss function .",
    "full information about the loss function ( one that would perhaps allow to minimizes the total loss over the contexts seen so far ) is not available .",
    "the specifics of the interaction model determines which pieces of loss will be observed by the algorithm , e.g. , the actual value of the loss on the chosen action , some information on more profitable directions on the action space , noisy versions thereof , etc .",
    "the overall goal is to compete against classes of functions that map contexts to ( expected ) losses in a regret sense , that is , to obtain _ sublinear _ cumulative regret bounds .",
    "all these algorithms share the common need to somehow trade off an exploratory attitude for gathering loss information on unchosen directions of the context - action space , and an exploitatory attitude for choosing actions that are deemed best according to the available data .",
    "for instance , @xcite work in a finite action space where the mappings context - to - loss for each action are linear ( or generalized linear , as @xcite s ) functions of the features .",
    "they all obtain @xmath9-like regret bounds , where @xmath10 is the time horizon .",
    "this is extended by @xcite , where the loss function is modeled as a sample from a gaussian process over the joint context - action space .",
    "we are using a similar ( generalized ) linear modeling here . an earlier ( but somehow more general ) setting that models such mappings by vc - classes",
    "is considered by @xcite , where a @xmath11 regret bound has been proven under i.i.d .",
    "linear multiclass classification problems with bandit feedback are considered by , e.g. , @xcite , where either @xmath11 or @xmath9 or even logarithmic regret bounds are proven , depending on the noise model and the underlying loss functions .",
    "all the above papers do not consider _ structured _ action spaces , where the learner is afforded to select _ sets _ of actions , which is more suitable to multilabel and ranking problems . along these lines",
    "are @xcite .",
    "the general problem of online minimization of a submodular loss function under both full and bandit information without covariates is considered by @xcite , achieving a regret @xmath11 in the bandit case .",
    "@xcite consider the problem of online learning of assignments , where at each round an algorithm is requested to assign positions ( e.g. , rankings ) to sets of items ( e.g. , ads ) with given constraints on the set of items that can be placed in each position .",
    "their problem shares similar motivations as ours but , again , the bandit version of their algorithm does not explicitly take side information into account , and leads to a @xmath11 regret bound . another paper with similar goals but",
    "a different mathematical model is by @xcite , where the aim is to learn a suitable ordering ( an  ordered slate \" ) of the available actions . among other things ,",
    "the authors prove a @xmath9 regret bound in the bandit setting with a multiplicative weight updating scheme . yet",
    ", no contextual information is incorporated .",
    "@xcite motivate the ability of selecting sets of actions by a problem of diverse retrieval in large document collections which are meant to live in a general metric space .",
    "in contrast to our paper , that approach does not lead to strong regret guarantees for specific ( e.g. , smooth ) loss functions .",
    "@xcite use a simple linear model for the hidden utility function of users interacting with a web system and providing partial feedback in any form that allows the system to make significant progress in learning this function ( this is called an @xmath12-informative feedback by the authors ) . under these assumptions , a regret bound of @xmath9 is again provided that depends on the degree of informativeness of the feedback , as measured by the progress made during the learning process .",
    "it is experimentally argued that this feedback is typically made available by a user that clicks on relevant urls out of a list presented by a search engine . despite the neatness of the argument ,",
    "no formal effort is put into relating this information to the context information at hand or , more generally , to the way data are generated .",
    "the recent paper @xcite investigates classes of graphical models for contextual bandit settings that afford richer interaction between contexts and actions leading again to a @xmath11 regret bound .",
    "finally , a very interesting recent work that came to our attention at the time of writing this extended version of our conference paper @xcite is @xcite . in that paper , the authors provide sufficient conditions that insure rates of the form @xmath9 in partial monitoring games with side information .",
    "partial monitoring is an attempt to formalize through a unifying language the partial information settings where the algorithm is observing only partial information about the loss of its action , in the form of some kind of feedback or  signal \" .",
    "the results presented by @xcite do not seem to conveniently extend to the structured action space setting we are interested in ( or , if they do , we do not see it in the current version of their paper ) .",
    "moreover , being very general in scope , that paper is missing a tight dependence of the regret bound on the number of available actions , which can be very large in structured action spaces .",
    "the literature on multilabel learning and learning to rank is overwhelming . the wide attention this literature attracts is often motivated by its web - search - engine or recommender - system applications , and many of the papers are experimental in nature .",
    "relevant references include @xcite , along with references therein . moreover , when dealing with multilabel , the typical assumption is full supervision , an important concern being modeling correlations among classes .",
    "in contrast to that , the specific setting we are considering here need not face such a modeling @xcite . the more recent work @xcite reduces any online algorithm working on pairwise loss functions ( like a ranking loss ) to a batch algorithm with generalization bound guarantees .",
    "but , again , only fully supervised settings are considered .",
    "other related references are @xcite , where learning is by pairs of examples . yet , these approaches need i.i.d .",
    "assumptions on the data , and typically deliver batch learning procedures .    to summarize , whereas we are technically closer to the linear modeling approaches by @xcite , from a motivational standpoint we are perhaps closest to @xcite .",
    "we investigate the multilabel and learning - to - rank problems in a partial feedback scenario with contextual information , where we assume a probabilistic linear model over the labels , although the contexts can be chosen by an adaptive adversary .",
    "we consider two families of loss functions , one is a cost - sensitive multilabel loss that generalizes the standard hamming loss in several respects , the other is a kind of ( unnormalized ) ranking loss . in both cases ,",
    "the learning algorithm is maintaining a ( generalized ) linear predictor for the probability that a given label occurs , the ranking being produced by upper confidence - corrected estimated probabilities . in such settings , we prove @xmath13 cumulative regret bounds , which are essentially optimal ( up to log factors ) in some cases .",
    "a distinguishing feature of our user feedback model is that , unlike previous papers ( e.g. , @xcite ) , we are not assuming the algorithm is observing a noisy version of the risk function on the currently selected action .",
    "in fact , when a generalized linear model is adopted , the mapping context - to - risk turns out to be nonconvex in the parameter space .",
    "furthermore , when operating on structured action spaces this more traditional form of bandit model does not seem appropriate to capture the typical user preference feedback . our approach is based on having the loss decouple from the label generating model , the user feedback being a noisy version of the gradient of a _ surrogate _ convex loss associated with the model itself .",
    "as a consequence , the algorithm is not directly dealing with the original loss when making exploration . in this sense",
    ", we are more similar to the multiclass bandit algorithm by @xcite . yet",
    ", our work is a substantial departure from @xcite s in that we lift their machinery to nontrivial structured action spaces , and we do so by means of generalized linear models . on one hand ,",
    "these extensions pose several extra technical challenges ; on the other , they provide additional modeling power and practical advantage .    though the emphasis is on theoretical results",
    ", we also validate our algorithms on two real - world multilabel datasets w.r.t .",
    "a number of loss functions , showing good comparative performance against simple multilabel / ranking baselines that operate with full information .",
    "the paper is organized as follows . in section",
    "[ s : model ] we introduce our learning model , our first loss function , the label generation model , and some preliminary results and notation used throughout the rest of the paper . in section [ s : alg ]",
    "we describe our partial feedback algorithm working under the loss function introduced in section [ s : model ] , along with the associated regret analysis . in section [",
    "s : rank ] we show that a very similar machinery applies to ranking with partial feedback , where the loss function is a kind of pairwise ranking loss ( with partial feedback ) . similar regret bounds are then presented that work under additional modeling restrictions . in section [",
    "s : exp ] we provide our experimental evidence comparing our method with its immediate full information counterpart .",
    "section [ s : tech ] gives proof ideas and technical details .",
    "the paper is concluded with section [ s : concl ] , where possible directions for future research are mentioned .",
    "we consider a setting where the algorithm receives at time @xmath1 the side information vector @xmath14 , is allowed to output a ( possibly ordered ) subset @xmath15 $ ] of the set of possible labels , then the subset of labels @xmath6 $ ] associated with @xmath16 is generated , and the algorithm gets as feedback @xmath17 .",
    "the loss suffered by the algorithm may take into account several things : the _ distance _ between @xmath18 and @xmath3 ( both viewed as sets ) , as well as the _ cost _ for playing @xmath3 .",
    "the cost @xmath19 associated with @xmath3 might be given by the sum of costs suffered on each class @xmath20 , where we possibly take into account the _ order _ in which @xmath21 occurs within @xmath3 ( viewed as an ordered list of labels ) .",
    "specifically , given constant @xmath22 $ ] and costs @xmath23 \\}$ ] , such that @xmath24 , for all @xmath25 $ ] , we consider the loss function @xmath26 where @xmath27 is the position of class @xmath21 in @xmath3 , and @xmath28 depends on @xmath3 only through its size @xmath29 . in the above , the first term accounts for the false negative mistakes , hence there is no specific ordering of labels therein .",
    "the second term collects the loss contribution provided by all false positive classes , taking into account through the costs @xmath30 the order in which labels occur in @xmath3 .",
    "the constant @xmath31 serves as weighting the relative importance of false positive vs. false negative mistakes is not redundant here , since the costs @xmath32 have been normalized to [ 0,1 ] . ] . as a specific example",
    ", suppose that @xmath33 , the costs @xmath32 are given by @xmath34 , the algorithm plays @xmath35 , but @xmath36 is @xmath37 .",
    "in this case , @xmath38 , and @xmath39 , i.e. , the cost for mistakingly playing class 4 in the top slot of @xmath3 is more damaging than mistakingly playing class 6 in the third slot . in the special case",
    "when all costs are unitary , there is no longer need to view @xmath3 as an ordered collection , and the above loss reduces to a standard hamming - like loss between sets @xmath36 and @xmath3 , i.e. , @xmath40 .",
    "notice that the partial feedback @xmath17 allows the algorithm to know which of the chosen classes in @xmath3 are good or bad ( and to what extent , because of the selected ordering within @xmath3 ) .",
    "yet , the algorithm does not observe the value of @xmath41 bacause @xmath42 remains hidden .",
    "the reader should also observe the asymmetry between the label set @xmath3 produced by the algorithm and the true label set @xmath36 : the algorithm predicts an ordered set of labels , but the true set of labels is unordered .",
    "in fact , it is often the case in , e.g. , recommender system practice , that the user feedback does not contain preference information in the form of an ordered set of items .",
    "still , in such systems we would like to get back to the user with an appropriate ranking over the items . * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * specifically , we are thinking of a setting , like online advertisement , where it is more expensive for the algorithm to play a large @xmath3 than a small one ( @xmath3 might contain ad banners to be displayed on a web page ) .",
    "the cost @xmath19 associated with @xmath3 might be given by the sum of costs suffered on each class @xmath20 , where we possibly take into account the _ order _ in which @xmath21 occurs within @xmath3 ( viewed as a ordered list of classes ) .",
    "for instance , for a given ordered sequence @xmath43 , we let @xmath44 be the sequence of cost values we associate with slots @xmath45 in @xmath3 . the the loss suffered on @xmath3 might be given by @xmath46 * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * working with the above loss function makes the algorithm s output @xmath3 become a ranked list of classes , where ranking is _ restricted _ to the deemed relevant classes only . in this sense , the above problem can be seen as a partial information version of the multilabel ranking problem ( see @xcite , and references therein ) . in a standard multilabel ranking problem",
    "a classifier has to provide for any given instance @xmath2 , both a separation between relevant and irrelevant classes and a ranking of the classes within the two sets ( or , perhaps , over the whole set of classes , as long as ranking is consistent with the relevance separation ) . in our setting , instead , ranking applies to the selected classes only , but the information gathered by the algorithm while training is partial .",
    "that is , only a relevance feedback among the selected classes is observed ( the set @xmath47 ) , but no supervised ranking information ( e.g. , in the form of pairwise preferences ) is provided to the algorithm within this set .",
    "alternatively , we can think of a ranking framework where restrictions on the size of @xmath3 are set by an exogenous ( and possibly time - varying ) parameter of the problem , and the algorithm is required to provide a ranking complying with these restrictions .",
    "another important concern we would like to address with our loss function @xmath48 is to avoid combinatorial explosions due to the exponential number of possible choices for @xmath3 .",
    "as we shall see below , this is guaranteed by the chosen structure for costs @xmath32 . another loss function",
    "providing similar guarantees ( though with additional modeling restrictions ) is the ( pairwise ) ranking loss considered in section [ s : rank ] , where more on the connection to the ranking setting with partial feedback is given .    * * * * * * * * * * * * * * * * * * * for a constant @xmath22 $ ] and a nonnegative and nondecreasing function @xmath49 .",
    "the constant @xmath31 in the distance term serves as weighting the relative importance of false positive vs. false negative mistaken classes .",
    "in particular , when @xmath31 is close to 0 we put more emphasis on the _ precision _ of our classifier , when @xmath31 is close to 1 we rather emphasize its _",
    "recall_. , recall is the ratio @xmath50 , accuracy is the ratio @xmath51 , ] when @xmath52 , @xmath53 is ( half the ) size of the symmetric difference between @xmath36 and @xmath3 ( also called hamming loss by @xcite ) plus the cost @xmath54 of playing a set of cardinality @xmath29 .",
    "hence , at a given level of hamming loss between @xmath36 and @xmath3 , the loss @xmath53 is large when so is @xmath29 . * * * * * * * * * * * * * * * * * * * *    the problem arises as to which noise model we should adopt so as to encompass significant real - world settings while at the same time affording _ efficient implementation _ of the resulting algorithms . for any subset @xmath6 $ ] , we let @xmath55 be the corresponding indicator vector .",
    "then it is easy to see that @xmath56 moreover , because the first sum does not depend on @xmath3 , for the sake of optimizing over @xmath3 ( but also for the sake of defining the regret @xmath57  see below ) we can equivalently define @xmath58 let @xmath59 be a shorthand for the conditional probability @xmath60 , where the side information vector @xmath2 can in principle be generated by an adaptive adversary as a function of the past .",
    "then @xmath61 where the marginals @xmath62 satisfy as the ( inverse ) link function of the associated canonical exponential family of distributions @xcite . ]",
    "@xmath63 for some @xmath64 vectors @xmath65 and some ( known ) function @xmath66 .",
    "the model is well defined if @xmath67 for all @xmath21 and all @xmath68 chosen by the adversary .",
    "we assume for the sake of simplicity that @xmath69 for all @xmath1 .",
    "notice that here the variables @xmath70 _ need not _ be conditionally independent .",
    "we are only definining a family of allowed joint distributions @xmath71 through the properties of their marginals @xmath72 .",
    "a classical result in the theory of copulas @xcite makes one derive all allowed joint distributions starting from the corresponding one - dimensional marginals .",
    "the function @xmath73 above will be instantiated to the negative derivative of a suitable convex and nonincreasing loss function @xmath74 which our algorithm will be based upon .",
    "for instance , if @xmath74 is the square loss @xmath75 , then @xmath76 , resulting in @xmath77 , under the assumption @xmath78 $ ] . if @xmath74 is the logistic loss @xmath79 , then @xmath80 , and @xmath81 , with domain @xmath82 .",
    "observe that in both cases @xmath62 is an increasing function of @xmath83 .",
    "this will be true in general .",
    "set for brevity @xmath84 .",
    "taking into account ( [ e : symmdiff ] ) , this model allows us to write the ( conditional ) expected loss of the algorithm playing @xmath3 as @xmath85   =    ( 1-a)\\,\\sum_{i \\in { { \\hat y}}_t } \\left ( c(j_i,|{{\\hat y}}_t| ) - \\left({\\mbox{$\\frac{a}{1-a}$ } } + c(j_i,|{{\\hat y}}_t|)\\right)\\,p_{i , t } \\right)~,\\ ] ] where we introduced the shorthands @xmath86 and the expectation @xmath87 in ( [ e : expectedloss ] ) is w.r.t .",
    "the generation of labels @xmath36 , conditioned on both @xmath2 , and all previous @xmath8 and @xmath88 .",
    "a key aspect of this formalization is that the bayes optimal ordered subset @xmath89 } { \\ensuremath{\\mathbb{e}}}_t[\\ell_{a , c}(y_t , y)]\\ ] ] can be computed efficiently when knowing @xmath90 .",
    "this is handled by the next lemma . in words",
    ", this lemma says that , in order to minimize ( [ e : expectedloss ] ) , it suffices to try out all possible sizes @xmath91 for @xmath92 and , for each such value , determine the sequence @xmath93 that minimizes ( [ e : expectedloss ] ) over all sequences of size @xmath94 . in turn",
    ", @xmath93 can be computed just by sorting classes @xmath95 $ ] in decreasing order of @xmath96 , sequence @xmath93 being given by the first @xmath94 classes in this sorted list .",
    "[ l : bayes ] with the notation introduced so far , let @xmath97 be the sequence of @xmath96 sorted in nonincreasing order .",
    "then we have that @xmath98~,\\ ] ] where @xmath99 , and @xmath100 .",
    "first observe that , for any given size @xmath94 , the sequence @xmath93 must contain the @xmath94 top - ranked classes in the sorted order of @xmath96 .",
    "this is because , for any candidate sequence @xmath101 , we have @xmath102   =   ( 1-a)\\,\\sum_{i \\in y_s } \\left ( c(j_i , s ) - \\left({\\mbox{$\\frac{a}{1-a}$ } } + c(j_i , s)\\right)\\,p_{i , t } \\right)~. $ ] if there exists @xmath103 which is not among the @xmath94-top ranked ones , then we could replace class @xmath21 in position @xmath27 within @xmath104 with class @xmath105 such that @xmath106 obtaining a smaller loss .    next , we show that the optimal ordering within @xmath93 is precisely ruled by the nonicreasing order of @xmath96 . by the sake of contradiction , assume there are @xmath21 and @xmath107 in @xmath93 such that @xmath21 preceeds @xmath107 in @xmath93 but @xmath106 .",
    "specifically , let @xmath21 be in position @xmath108 and @xmath107 be in position @xmath109 with @xmath110 and such that @xmath111 . then , disregarding the common @xmath112-factor , switching the two classes within @xmath93 yields an expected loss difference of @xmath113 since @xmath106 and @xmath111 .",
    "hence switching would get a smaller loss which leads as a consequence to @xmath114 .    * * * * * * * * * * * * * * * * * * * * * * single out all classes @xmath21 such that @xmath115 and include in @xmath92 those ones only . however",
    ", since we are requiring @xmath116 , if no such @xmath21 exists , then @xmath92 will be the singleton containing only the class @xmath117}{\\mathbb{p}}_t(y_{i , t } = 1 )   = { \\rm argmax}_{i \\in [ k ] } \\frac{g(-{\\boldsymbol{u}}_{i}^\\top{\\boldsymbol{x}}_t)}{g({\\boldsymbol{u}}_{i}^\\top{\\boldsymbol{x}}_t)+g(-{\\boldsymbol{u}}_{i}^\\top{\\boldsymbol{x}}_t)}$ ] . * * * * * * * * * * * * * * * * * * * * * * *    notice the way costs @xmath32 influence the bayes optimal computation .",
    "we see from ( [ e : expectedloss ] ) that placing class @xmath21 within @xmath3 in position @xmath27 is beneficial ( i.e. , it leads to a reduction of loss ) if and only if @xmath118 hence , the higher is the slot @xmath119 in @xmath3 the larger should be @xmath96 in order for this inclusion to be convenient . , so we can not decompose this problem into @xmath64 independent problems .",
    "the decomposition does occur if the costs @xmath32 are constants , independent of @xmath21 and @xmath94 , the criterion for inclusion becoming @xmath120 , for some constant threshold @xmath121 . ]",
    "it is @xmath92 above that we interpret as the true set of user preferences on @xmath2 .",
    "we would like to compete against @xmath92 in a cumulative regret sense , i.e. , we would like to bound @xmath122 - { \\ensuremath{\\mathbb{e}}}_t[\\ell_{a , c}(y_t , y^*_t)]\\ ] ] with high probability .",
    "we use a similar but largely more general analysis than @xcite s to devise an online second - order descent algorithm whose updating rule makes the comparison vector @xmath123 defined through ( [ e : labgenmult ] ) be bayes optimal w.r.t .",
    "a surrogate convex loss @xmath124 such that @xmath125 .",
    "observe that the expected loss function defined in ( [ e : expectedloss ] ) is , generally speaking , nonconvex in the margins @xmath126 ( consider , for instance the logistic case @xmath80 ) .",
    "thus , we can not directly minimize this expected loss .",
    "in figure [ f:2 ] is our bandit algorithm for ( ordered ) multiple labels . the algorithm is based on replacing the unknown model vectors @xmath127 with prototype vectors @xmath128 , being @xmath129 the time-@xmath1 approximation to @xmath130 , satisying similar constraints we set for the @xmath130 vectors . for the sake of brevity , we let @xmath131 , and @xmath84 , @xmath95 $ ] .",
    "the algorithm uses @xmath132 as proxies for the underlying @xmath126 according to the ( upper confidence ) approximation scheme @xmath133_d$ ] , where @xmath134 is a suitable upper - confidence level for class @xmath21 at time @xmath1 , and @xmath135_d$ ] denotes the clipping - to-@xmath136 operation : if @xmath137 $ ] , then @xmath138_d = \\begin{cases } r & { \\mbox{if $ x > r$}}\\\\   x & { \\mbox{if $ -r \\leq x \\leq r$}}\\\\   -r & { \\mbox{if $ x < -r$}}~. \\end{cases}\\ ] ] the algorithm s prediction at time @xmath1 has the same form as the computation of the bayes optimal sequence @xmath92 , where we replace the true ( and unknown ) @xmath139 with the corresponding upper confidence proxy @xmath140_d)~.\\ ] ] being @xmath141 }    \\left ( \\sum_{i \\in y } \\left ( c(j_i,|y| ) - \\left({\\mbox{$\\frac{a}{1-a}$ } } + c(j_i,|y|)\\right)\\,{\\widehat { p}}_{i , t } \\right)\\right)~.\\end{aligned}\\ ] ] computing @xmath3 above can be done by mimicking the computation of the bayes optimal ordered subset @xmath142 ( just replace @xmath96 by @xmath143 ) . from a computational viewpoint , this essentially amounts to sorting classes @xmath95 $ ] in decreasing value of @xmath143 , i.e. , order of @xmath144 running time per prediction .",
    "thus the algorithm is producing a ranked list of relevant classes based on upper - confidence - corrected scores @xmath143 .",
    "class @xmath21 is deemed relevant and ranked high among the relevant ones when either @xmath132 is a good approximation to @xmath126 and @xmath96 is large , or when the algorithm is not very confident on its own approximation about @xmath21 ( that is , the upper confidence level @xmath145 is large ) .",
    "the algorithm in figure [ f:2 ] receives in input the loss parameters @xmath31 and @xmath32 , the model function @xmath146 and the associated margin domain @xmath137 $ ] , and maintains both @xmath64 positive definite matrices @xmath147 of dimension @xmath148 ( initially set to the @xmath149 identity matrix ) , and @xmath64 weight vector @xmath150 ( initially set to the zero vector ) . at each time step @xmath1 , upon receiving the @xmath148-dimensional instance vector @xmath2 the algorithm uses the weight vectors @xmath151 to compute the prediction vectors @xmath129 .",
    "these vectors can easily be seen as the result of projecting @xmath151 onto interval @xmath137 $ ] w.r.t .",
    "the distance function @xmath152 , i.e. , @xmath153,\\ ] ] where @xmath154 vectors @xmath129 are then used to produce prediction values @xmath132 involved in the upper - confidence calculation of the predicted ordered subset @xmath15 $ ] .",
    "next , the feedback @xmath47 is observed , and the algorithm in figure [ f:2 ] promotes all classes @xmath155 ( sign @xmath156 ) , demotes all classes @xmath157 ( sign @xmath158 ) , and leaves all remaining classes @xmath159 unchanged ( sign @xmath160 ) .",
    "promotion of class @xmath21 on @xmath2 implies that if the new vector @xmath161 is close to @xmath2 then @xmath21 will be ranked higher on @xmath161 .",
    "the update @xmath162 is based on the gradients @xmath163 of a loss function @xmath124 satisfying @xmath164 . on the other hand , the update @xmath165 uses the rank one matrix rather than @xmath166 , as in , e.g. , @xcite .",
    "this is due to technical reasons that will be made clear in section [ s : tech ] .",
    "this feature tells this algorithm slightly apart from the online newton step algorithm @xcite , which is the starting point of our analysis . ]",
    "@xmath167 . in both",
    "the update of @xmath129 and the one involving @xmath168 , the reader should observe the role played by the signs @xmath169 . finally , the constants @xmath170 and @xmath171 occurring in the expression for @xmath172 are related to smoothness properties of @xmath124 , as explained in the next theorem .. ]    [ t : cumregret ] let @xmath173 \\subseteq { { { \\mathcal{r}}}}\\rightarrow { { { \\mathcal{r}}}}^+$ ] be a @xmath174 convex and nonincreasing function of its argument , @xmath175 be defined in ( [ e : labgenmult ] ) with @xmath125 for all @xmath176 , and such that @xmath177 for all @xmath95 $ ] .",
    "assume there are positive constants @xmath178 , @xmath170 and @xmath171 such that :    1 .",
    "@xmath179 , 2 .",
    "@xmath180 , 3 .",
    "@xmath181    simultaneously hold for all @xmath176 .",
    "then the cumulative regret @xmath57 of the algorithm in figure [ f:2 ] satisfies , with probability at least @xmath182 , @xmath183 where @xmath184    it is easy to see that when @xmath124 is the square loss @xmath75 and @xmath78 $ ] , we have @xmath185 , @xmath186 and @xmath187 ; when @xmath124 is the logistic loss @xmath79 and @xmath137 $ ] , we have @xmath188 , @xmath189 and @xmath190 , where @xmath191 .",
    "the following remarks are in order at this point .",
    "a drawback of theorem [ t : cumregret ] is that , in order to properly set the upper confidence levels @xmath145 , we assume prior knowledge of the norm upper bound @xmath192 .",
    "because this information is often unavailable , we present here a simple modification to the algorithm that copes with this limitation .",
    "we change the definition of @xmath172 in figure [ f:2 ] to @xmath193 that is , we substitute @xmath194 by @xmath195 , and cap the maximal value of @xmath172 to @xmath196 .",
    "this immediately leads to the following result .. ]    [ t : cumregret_logt ] with the same assumptions and notation as in theorem [ t : cumregret ] , if we replace @xmath172 as explained above we have that , with probability at least @xmath182 , @xmath57 satisfies @xmath197    [ r : comp ] from a computational standpoint , the most demanding operation in figure [ f:2 ] is computing the upper confidence levels @xmath145 involving the inverse matrices @xmath198 , @xmath95 $ ] .",
    "this can be done incrementally in @xmath199 time per round , which makes it hardly practical if both @xmath148 and @xmath64 are large .",
    "in practice ( as explained , e.g. , by @xcite ) , one can use a version of the algorithm which maintains _ diagonal _ matrices @xmath147 instead of full ones .",
    "all the steps remain the same except step @xmath200 of algorithm  [ f:2 ] where one defines the @xmath201th diagonal element of matrix @xmath147 as @xmath202 , being @xmath203 .",
    "the resulting running time per round ( including prediction and update ) becomes @xmath204 .",
    "in fact , when a limitation on the size of @xmath3 is given , the running time may be further reduced , see remark [ r : typical ] .",
    "as lemma [ l : bayes ] points out , when the cost values @xmath32 in the loss function @xmath48 are _ stricly _ decreasing i.e. , @xmath205 , for all @xmath25 $ ] , then the bayes optimal ordered sequence @xmath92 on @xmath2 is unique can be obtained by sorting classes in decreasing values of @xmath96 , and then decide on a cutoff point induced by the loss parameters , so as to tell relevant classes apart from irrelevant ones . in turn , because @xmath206 is increasing in @xmath207 , this ordering corresponds to sorting classes in decreasing values of @xmath126 .",
    "now , if parameter @xmath31 in @xmath48 is very close , the algorithm only cares about false negative mistakes , the best strategy being always predicting @xmath208 $ ] .",
    "unsurprisingly , this yields zero regret in both theorems [ t : cumregret ] and [ t : cumregret_logt ] . ] to @xmath209 , then @xmath210 , and the algorithm itself will produce ordered subsets @xmath3 such that @xmath211 . moreover , it does so by receiving _ full _",
    "feedback on the relevant classes at time @xmath1 ( since @xmath212 ) .",
    "as is customary ( e.g. , @xcite ) , one can view any multilabel assignment @xmath213 as a ranking among the @xmath64 classes in the most natural way : @xmath21 preceeds @xmath214 if and only if @xmath215 . the ( unnormalized ) ranking loss function @xmath216 between the multilabel @xmath88 and a ranking function @xmath217 , representing degrees of class relevance sorted in a decreasing order @xmath218 , counts the number of class pairs that disagree in the two rankings : @xmath219\\,:\\ , y_i > y_j } \\left ( \\ { f_{i}({\\boldsymbol{x}}_t ) < f_{j}({\\boldsymbol{x}}_t ) \\ }",
    "+ { \\mbox{$\\frac{1}{2}$}}\\,\\ { f_{i}({\\boldsymbol{x}}_t ) = f_{j}({\\boldsymbol{x}}_t ) \\ } \\right),\\ ] ] where @xmath220 is the indicator function of the predicate at argument . as pointed out by @xcite ,",
    "the ranking function @xmath221 is also bayes optimal w.r.t .",
    "@xmath216 , _ no matter if _ the class labels @xmath222 are conditionally independent or not .",
    "hence we can use the algorithm in figure [ f:2 ] with @xmath31 close to @xmath209 for tackling ranking problems derived from multilabel ones , when the measure of choice is @xmath223 and the feedback is full .",
    "we now consider a partial information version of the above ranking problem .",
    "suppose that at each time @xmath1 , the environment discloses both @xmath2 and a maximal _ size _",
    "@xmath224 for the ordered subset @xmath225 ( both @xmath2 and @xmath224 can be chosen adaptively by an adversary ) . here",
    "@xmath224 might be the number of available slots in a webpage or the number of urls returned by a search engine in response to query @xmath2 .",
    "then it is plausible to compete in a regret sense against the best time-@xmath1 offline ranking of the form @xmath226 where the number of strictly positive @xmath227 values is at most @xmath224 .",
    "further , the ranking loss could be reasonably restricted to count the number of class pairs disagreeing within @xmath3 plus a quantity related to the number of false negative mistakes .",
    "if @xmath3 is the sequence of length @xmath224 associated with ranking function @xmath228 , we consider the loss function @xmath229 (  partial information @xmath223 at time @xmath1 \" ) @xmath230 in this loss function , the factor @xmath224 multiplying @xmath231 serves as balancing the contribution of the double sum @xmath232 with the contribution of false negative mistakes @xmath231 .",
    "for convenience , we will interchangeably use the notations @xmath233 and @xmath234 , whenever it is clear from the surrounding context that @xmath3 is the sequence corresponding to @xmath228 .    the next lemma . ]",
    "is the ranking counterpart to lemma [ l : bayes ] .",
    "it shows that the bayes optimal ranking for @xmath229 is given by @xmath235 where @xmath236 if @xmath237 is among the @xmath224 largest values in the sequence @xmath238 , and 0 otherwise .",
    "that is , @xmath239 is the function that ranks classes according to decreasing values of @xmath96 and cuts off exactly at position @xmath224 . in order for this result to go through",
    "we need to restrict model ( [ e : labgenmult ] ) to the case of conditionally independent classes , i.e. , to the case when @xmath240 } p_{i , t}\\,.\\ ] ] this is in striking contrast to the full information setting , where the bayes optimal ranking only depends on the marginal distribution values @xmath96 @xcite . due to the interaction between the two terms in the definition of @xmath229 ,",
    "the bayes optimal ranking for @xmath229 turns out to depend on both marginal and pairwise correlation values of the joint class distribution .",
    "this would force us to maintain @xmath241 upper confidence values @xmath242 , one for each pair @xmath243 , leading to an extra computational burder which can also become prohibitive when the number of classes @xmath64 is large .",
    "[ l : bayesrank ] with the notation introduced so far , let the joint distribution @xmath71 factorize as in ( [ e : indep ] ) . then @xmath239 introduced above satisfies @xmath244~.\\ ] ]",
    "if we add to the argmin of our algorithm ( step 3 in figure [ f:2 ] ) the further constraint @xmath245 ( notice that the resulting computation is still about sorting classes according to decreasing values of @xmath143 ) , we are defining a partial information ranking algorithm that ranks classes according to decreasing values of @xmath143 up to position @xmath224 ( i.e. , @xmath246 ) .",
    "let @xmath247 be the resulting ranking .",
    "we can then define the cumulative regret @xmath248 w.r.t .",
    "@xmath229 as @xmath249   - { \\ensuremath{\\mathbb{e}}}_t[\\ell_{p - rank , t}(y_t , f^*({\\boldsymbol{x}}_t , s_t)],\\ ] ] that is , the amount to which the conditional @xmath229-risk of @xmath247 exceeds the one of the bayes optimal ranking @xmath239 , cumulated over time .",
    "we have the following ranking counterpart to theorem [ t : cumregret ] .",
    "[ t : cumregret_rank ] with the same assumptions and notation as in theorem [ t : cumregret ] , combined with the independence assumption ( [ e : indep ] ) , let the cumulative regret @xmath248 w.r.t .",
    "@xmath229 be defined as in ( [ e : rankingregret ] ) .",
    "then , with probability at least @xmath182 , we have that the algorithm in figure [ f:2 ] working with @xmath250 and strictly decreasing cost values @xmath32",
    "( i.e. , the one computing in round @xmath1 the ranking function @xmath247 ) achieves @xmath251 where @xmath252 .",
    "the proof ( see section [ s : tech ] ) is very similar to the one of theorem [ t : cumregret ] .",
    "this suggests that , to some extent , we are decoupling the label generating model from the loss function @xmath253 under consideration .",
    "[ r : typical ] as is typical in many multilabel classification settings , the number of classes @xmath64 can either be very large or have an inner structure ( e.g. , a hierarchical or dag - like structure ) .",
    "it is often the case that in such a large label space , many classes are relatively rare .",
    "this has lead researchers to consider methods that are specifically taylored to leverage the label sparsity of the chosen classifier ( e.g. , @xcite and references therein ) and/or the specific structure of the set of labels ( e.g. , @xcite , and references therein ) .",
    "though our algorithm is not designed to exploit the label structure , we would like to stress that the restriction @xmath254 in theorem [ t : cumregret_rank ] allows us to replace the linear dependence on the total number of classes @xmath64 ( which is often much larger than @xmath255 ) by @xmath256 .",
    "it is very easy to see that this restriction would bring similar benefits to theorem [ t : cumregret ] .",
    "the above restriction is not only beneficial from a  statistical \" point of view , but also from a computational one .",
    "in fact , as is by now standard , algorithms like the one in figure [ f:2 ] can easily be cast in dual variables ( i.e. , in a rkhs ) .",
    "this comes with at least two consequences :    1 .",
    "we can depart from the ( generalized ) linear modeling assumption ( [ e : labgenmult ] ) , and allow for more general nonlinear dependences of @xmath96 on the input vectors @xmath2 .",
    "2 .   we can maintain a dual variable representation for margins @xmath132 and quadratic forms @xmath257 , so that computing each one of them takes @xmath258 inner products , where @xmath259 is the number of times class @xmath21 has been updated up to time @xmath1 , each inner product being @xmath260 .",
    "now , each of the ( at most @xmath261 ) updates is @xmath258 .",
    "hence , the overall running time in round @xmath1 is coarsely overapproximated by @xmath262 } n^2_{i , t } + k\\log k)$ ] . from @xmath263 }",
    "n_{i , t } \\leq st$ ] , we see that when @xmath255 is small compared to @xmath64 , then @xmath264 tends to be small as well . for instance , if @xmath265 this leads to a running time per round of the form @xmath266 , which can be smaller than @xmath267 mentioned in remark [ r : comp ] .",
    "finally , observe that one can also combine theorem [ t : cumregret_rank ] with the argument contained in remark 1 .",
    "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *    yet , observe that @xmath48 and @xmath223 are not the same loss function , even if @xmath31 is very close to @xmath209 .",
    "the following lemma is a ranking loss counterpart to the one - step regret contained in lemma [ l : onestepsingle ] .",
    "combined with the other lemmas , lemma [ l : onestepsingle_ranking ] allows to carry out a regret analysis that leads to a @xmath268 cumulative regret bound on the ranking loss under full supervision . in this sense , our analysis decouples the actual loss we are interested in ( e.g. , the @xmath48 loss or the ranking loss ) from both the label generating model and the algorithm itself .",
    "in fact , our algorithm can do more than just ranking , since it automatically infers the cutoff point that separates relevant classes ( which are ranked by the algorithm ) from unrelevant ones ( which are not ranked ) , and it does so with partial feedback only , i.e. , _ without _ observing explicit ranking information among the classes .",
    "however , we have been unable to prove sublinear regret bounds on the ranking loss working with partial feedback only .    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *    * * * * * * * * * * * * * * * * * * * * * * * * *    one can abstract away the properties of the loss function @xmath253 under consideration that makes    that makes this lemma go through .",
    "for instance , point forward to ranking loss    but a more general loss need not ensure computational efficiency .",
    "notice decoupling between @xmath48 and label model ...    * * * * * * * * * * * * * * * * * * * * * * * * * *",
    "the experiments we report here are meant to validate the exploration - exploitation tradeoff implemented by our algorithm under different conditions ( restricted vs. nonrestricted number of classes ) , loss measures ( @xmath48 , @xmath269 , and hamming loss ) and model / parameter settings ( @xmath74 = square loss , @xmath74 = logistic loss , with varying @xmath270 ) .",
    "* datasets . *",
    "we used two multilabel datasets .",
    "the first one , called mediamill , was introduced in a video annotation challenge  @xcite .",
    "it comprises 30,993 training samples and 12,914 test ones .",
    "the number of features @xmath148 is 120 , and the number of classes @xmath64 is 101 .",
    "the second dataset is sony csl paris  @xcite , made up of 16,452 train samples and 16,519 test samples , each sample being described by @xmath271 features .",
    "the number of classes @xmath64 is 632 . in both cases ,",
    "feature vectors have been normalized to unit l2 norm .",
    "* parameter setting and loss measures . * we used the algorithm in figure [ f:2 ] with two different loss functions , the square loss and the logistic loss , and varied the parameter @xmath270 for the latter .",
    "the setting of the cost function @xmath32 depends on the task at hand , and for this preliminary experiments we decided to evaluate two possible settings only .",
    "the first one , denoted by `` decreasing @xmath272 '' is @xmath273 , the second one , denoted by `` constant @xmath272 '' , is @xmath274 for all @xmath21 and @xmath94 . in all experiments ,",
    "the @xmath31 parameter was set to 0.5 , so that @xmath48 with constant @xmath272 reduces to half the hamming loss . in the decreasing @xmath272 scenario",
    ", we evaluated the performance of the algorithm on the loss @xmath48 that the algorithm is minimizing , but also its ability to produce meaningful ( partial ) rankings through @xmath269 . on the constant @xmath272 setting",
    ", we evaluated the hamming loss . as is typical of multilabel problems , the label _ density _",
    ", i.e. , the average fraction of labels associated with the examples , is quite small .",
    "for instance , on mediamill this is 4.3% .",
    "hence , it is clearly beneficial to impose an upper bound @xmath255 on @xmath29 . for the constant @xmath272 and ranking loss experiments we tried out different values of @xmath255 , and reported the final performance .    *",
    "baseline . * as baseline , we considered a full information version of algorithm  [ f:2 ] using the square loss , that receives after each prediction the full array of true labels @xmath36 for each sample .",
    "we call this algorithm obr ( online binary relevance ) , because it is a natural online adaptation of the binary relevance algorithm , widely used as a baseline in the multilabel literature . comparing",
    "to obr stresses the effectiveness of the exploration / exploitation rule above and beyond the details of underlying generalized linear predictor .",
    "obr was used to produce subsets ( as in the hamming loss case ) , and restricted rankings ( as in the case of @xmath269 ) .",
    "* results . *",
    "our results are summarized in figures  [ fig : sony ] and  [ fig : mediamill ] .",
    "the algorithms have been trained by sweeping only once over the training data . though preliminary in nature ,",
    "these experiments allow us to draw a few conclusions .",
    "our results for the avarage @xmath41 with decreasing @xmath272 are contained in the two left plots .",
    "we can see that the performance is improving over time on both datasets , as predicted by theorem  [ t : cumregret ] . in the middle plots are the final cumulative hamming losses with constant @xmath272 divided by the number of training samples , as a function of @xmath255 .",
    "similar plots are on the right with the final average ranking losses @xmath269 divided by @xmath255 . in both cases",
    "we see that there is an optimal value of @xmath255 that allows to balance the exploration and the exploitation of the algorithm .",
    "moreover the performance of our algorithm is always pretty close to the performance of obr , even if our algorithm is receiving only partial feedback . in many experiments",
    "the square loss seems to give better results .",
    "exception is the ranking loss on the mediamill dataset ( figure [ fig : mediamill ] , right ) .    [",
    "cols=\"^,^,^ \" , ]",
    "this section contains all proofs missing from the main text , along with ancillary results and comments .",
    "the algorithm in figure [ f:2 ] works by updating through the gradients @xmath163 of a modular margin - based loss function @xmath275 associated with the label generation model ( [ e : labgenmult ] ) , i.e. , associated with function @xmath73 , so as to make the parameters @xmath175 therein achieve the bayes optimality condition @xmath276~,\\ ] ] where @xmath277 $ ] above is over the generation of @xmath36 in producing the sign value @xmath278 , conditioned on the past ( in particular , conditioned on @xmath3 ) .",
    "the requirement in ( [ e : bayes_cond_mult ] ) is akin to the classical construction of _ proper scoring rules _ in the statistical literature ( e.g. , @xcite ) .",
    "the above is combined with the ability of the algorithm to guarantee the high probability convergence of the prototype vectors @xmath129 to the corresponding @xmath130 ( lemma [ l : upperconfsingle ] ) .",
    "the rate of convergence is ruled by the fact that the associated upper confidence values @xmath145 shrink to zero as @xmath279 when @xmath1 grows large . in order for this convergence to take place",
    ", it is important to insure that the algorithm is observing informative feedback ( either  correct \" , i.e. , @xmath156 , or  mistaken \" , i.e. , @xmath158 ) for each class @xmath21 contained in the selected @xmath3 .",
    "this in turn implies regret bounds for both @xmath48 ( lemma [ l : onestepsingle ] ) and @xmath269 ( lemma [ l : onestepsingle_ranking ] ) .",
    "the following lemma faces the problem of hand - crafting a convenient loss function @xmath124 such that ( [ e : bayes_cond_mult ] ) holds .",
    "[ l : expectation ] let @xmath280 be arbitrary weight vectors such that @xmath281 , @xmath95 $ ] , @xmath175 be defined in ( [ e : labgenmult ] ) , @xmath169 be the updating signs computed by the algorithm at the end ( step 5 ) of time @xmath1 , @xmath173 \\subseteq { { { \\mathcal{r}}}}\\rightarrow { { { \\mathcal{r}}}}^+$ ] be a convex and differentiable function of its argument , with @xmath125 . then for any @xmath1 we have @xmath282   \\geq   { \\ensuremath{\\mathbb{e}}}_t\\left[\\sum_{i = 1}^k l(s_{i , t}\\,{\\boldsymbol{u}}_i^\\top{\\boldsymbol{x}}_t)\\right],\\ ] ] i.e. , ( [ e : bayes_cond_mult ] ) holds .",
    "let us introduce the shorthands @xmath283 , @xmath284 , @xmath285 , and @xmath286 .",
    "moreover , let @xmath59 be an abbreviation for the conditional probability @xmath287 .",
    "recalling the way @xmath169 is constructed ( figure [ f:2 ] ) , we can write @xmath288   & = \\sum_{i \\in { { \\hat y}}_t } \\left({\\mathbb{p}}_t(s_{i , t}= 1)\\,l({\\widehat { \\delta}}_i ) + { \\mathbb{p}}_t(s_{i , t}= -1)\\,l(-{\\widehat { \\delta}}_i ) \\right ) + ( k - |{{\\hat y}}_t|)\\,l(0)\\\\ & = \\sum_{i \\in { { \\hat y}}_t } \\left(p_i\\,l({\\widehat { \\delta}}_i)+(1-p_i)\\,l(-{\\widehat { \\delta}}_i ) \\right ) + ( k - |{{\\hat y}}_t|)\\,l(0)~,\\end{aligned}\\ ] ] for similar reasons , @xmath289   = \\sum_{i \\in { { \\hat y}}_t } \\left(p_i\\,l(\\delta_i)+(1-p_i)\\,l(-\\delta_i ) \\right ) + ( k - |{{\\hat y}}_t|)\\,l(0)~.\\ ] ] since @xmath124 is convex , so is @xmath290 $ ] when viewed as a function of the @xmath291 . we have that @xmath292 } { \\partial { \\widehat { \\delta}}_i } = 0 $ ] if and only if for all @xmath20 we have that @xmath291 satisfies @xmath293 since @xmath294 , we have that @xmath290 $ ] is minimized when @xmath295 for all @xmath95 $ ] .",
    "the claimed result immediately follows .",
    "let now @xmath296 be a shorthand for @xmath297 .",
    "the following lemma shows that under additional assumptions on the loss @xmath124 , we are afforded to bound the variance of a difference of losses @xmath124 by the expectation of this difference",
    ". this will be key to proving the fast rates of convergence contained in the subsequent lemma [ l : upperconfsingle ] .",
    "[ l : variancesingle ] let @xmath298 be the weight vectors computed by the algorithm in figure [ f:2 ] at the beginning ( step 2 ) of time @xmath1 , @xmath169 be the updating signs computed at the end ( step 5 ) of time @xmath1 , and @xmath299 be the comparison vectors defined through ( [ e : labgenmult ] ) .",
    "let @xmath173\\subseteq { { { \\mathcal{r}}}}\\rightarrow { { { \\mathcal{r}}}}^+$ ] be a @xmath174 convex function of its argument , with @xmath125 and such that there are positive constants @xmath170 and @xmath171 with @xmath180 and @xmath181 for all @xmath176 .",
    "then for any @xmath20 @xmath300~.\\ ] ]    let us introduce the shorthands @xmath301 , @xmath302 , @xmath285 , and recall that @xmath286 .",
    "then , for any @xmath95 $ ] , @xmath303 moreover , for any @xmath20 we can write @xmath304   & = p_i\\,(l({\\widehat { \\delta}}_i ) - l(\\delta_i ) ) + ( 1-p_i)\\,(l(-{\\widehat { \\delta}}_i ) - l(-\\delta_i))\\notag\\\\ & \\geq p_i\\,\\left(l'(\\delta_i)({\\widehat",
    "{ \\delta}}_i-\\delta_i ) + \\frac{c''_l}{2}({\\widehat { \\delta}}_i-\\delta_i)^2\\right)\\notag\\\\   & \\ \\ \\ + ( 1-p_i)\\,\\left(l'(-\\delta_i)(\\delta_i-{\\widehat { \\delta } } ) + \\frac{c''_l}{2}({\\widehat { \\delta}}_i-\\delta_i)^2\\right)\\notag\\\\ & =   p_i\\,\\frac{c''_l}{2}({\\widehat { \\delta}}_i-\\delta_i)^2 + ( 1-p_i)\\,\\frac{c''_l}{2}({\\widehat { \\delta}}_i-\\delta_i)^2\\notag\\\\ & =   \\frac{c''_l}{2}({\\widehat { \\delta}}_i-\\delta_i)^2,\\label{e : meansingle}\\end{aligned}\\ ] ] where the second equality uses the definition of @xmath305 . combining ( [ e : variancesingle ] ) with ( [ e : meansingle ] ) gives the desired bound .",
    "we continue by showing a one - step regret bound _ for our original _",
    "loss @xmath48 .",
    "the precise connection to loss @xmath124 will be established with the help of a later lemma ( lemma [ l : upperconfsingle ] ) .",
    "[ l : onestepsingle ] let @xmath173 \\subseteq { { { \\mathcal{r}}}}\\rightarrow { { { \\mathcal{r}}}}^+$ ] be a convex , twice differentiable , and nonincreasing function of its argument .",
    "let @xmath175 be defined in ( [ e : labgenmult ] ) with @xmath125 for all @xmath176 .",
    "let also @xmath178 be a positive constant such that @xmath306 holds for all @xmath176 . finally , let @xmath126 denote @xmath307 , and @xmath132 denote @xmath308 , where @xmath129 is the @xmath21-the weight vector computed by the algorithm at the beginning ( step 2 ) of time @xmath1 .",
    "if time @xmath1 is such that @xmath309 for all @xmath95 $ ] , then @xmath310 - { \\ensuremath{\\mathbb{e}}}_t[\\ell_{a , c}(y_t , y^*_t ) ]   \\leq   2\\,(1-a)\\,c_l\\,\\sum_{i \\in { { \\hat y}}_t } \\epsilon_{i , t}~.\\ ] ]    recall the shorthand notation @xmath206 .",
    "we can write @xmath311 & - { \\ensuremath{\\mathbb{e}}}_t[\\ell_{a , c}(y_t , y^*_t)]\\\\ & = ( 1-a)\\,\\sum_{i \\in { { \\hat y}}_t }   \\left ( c({\\hat j_i},|{{\\hat y}}_t| ) - \\left({\\mbox{$\\frac{a}{1-a}$ } } + c({\\hat j_i},|{{\\hat y}}_t|)\\right)\\,p(\\delta_{i , t } ) \\right)\\\\ & \\ \\ - ( 1-a)\\,\\sum_{i \\in y^*_t }   \\left ( c(j^*_i,|y^*_t| ) - \\left({\\mbox{$\\frac{a}{1-a}$ } } + c(j^*_i,|y^*_t|)\\right)\\,p(\\delta_{i , t } ) \\right),\\end{aligned}\\ ] ] where @xmath312 denotes the position of class @xmath21 in @xmath3 and @xmath313 is the position of class @xmath21 in @xmath92 .",
    "now , @xmath314 since @xmath315 , and @xmath124 is convex and nonincreasing .",
    "hence @xmath316 is itself a nondecreasing function of @xmath207 .",
    "moreover , the extra condition on @xmath74 involving @xmath317 and @xmath318 is a lipschitz condition on @xmath316 via a uniform bound on @xmath319 .",
    "hence , from @xmath309 and the definition of @xmath3 we can write @xmath311 & - { \\ensuremath{\\mathbb{e}}}_t[\\ell_{a , c}(y_t , y^*_t)]\\\\ & \\leq    ( 1-a)\\,\\sum_{i \\in { { \\hat y}}_t }   \\left ( c({\\hat j_i},|{{\\hat y}}_t|)-\\left({\\mbox{$\\frac{a}{1-a}$ } }                   + c({\\hat j_i},|{{\\hat y}}_t|)\\right)\\,p([{\\widehat { \\delta}}'_{i , t } - \\epsilon_{i , t}]_d ) \\right)\\\\ & \\ \\ - ( 1-a)\\,\\sum_{i \\in y^*_t }   \\left ( c(j^*_i,|y^*_t| ) - \\left({\\mbox{$\\frac{a}{1-a}$ } } + c(j^*_i,|y^*_t|)\\right)\\,p([{\\widehat { \\delta}}'_{i , t}+\\epsilon_{i , t}]_d ) \\right)\\\\ & \\leq    ( 1-a)\\,\\sum_{i \\in { { \\hat y}}_t }   \\left ( c({\\hat j_i},|{{\\hat y}}_t|)-\\left({\\mbox{$\\frac{a}{1-a}$ } }                   + c({\\hat j_i},|{{\\hat y}}_t|)\\right)\\,p([{\\widehat { \\delta}}'_{i , t } - \\epsilon_{i , t}]_d ) \\right)\\\\ & \\ \\ - ( 1-a)\\,\\sum_{i \\in { { \\hat y}}_t }   \\left ( c({\\hat j_i},|{{\\hat y}}_t|)-\\left({\\mbox{$\\frac{a}{1-a}$ } } + c({\\hat j_i},|{{\\hat y}}_t|)\\right)\\,p([{\\widehat { \\delta}}'_{i , t}+\\epsilon_{i , t}]_d ) \\right)\\\\ & =   ( 1-a)\\,\\sum_{i \\in { { \\hat y}}_t }   \\left ( c({\\hat j_i},|{{\\hat y}}_t|)\\left(p([{\\widehat { \\delta}}'_{i , t}+\\epsilon_{i , t}]_d)-p([{\\widehat { \\delta}}'_{i , t}-\\epsilon_{i , t}]_d ) \\right)\\right)\\\\ & \\leq 2\\,(1-a)\\,c_l\\,\\sum_{i \\in { { \\hat y}}_t } \\epsilon_{i , t}~ , \\end{aligned}\\ ] ] the last inequality deriving from @xmath320 for all @xmath321 , and @xmath322_d)-p([{\\widehat { \\delta}}'_{i , t}-\\epsilon_{i , t}]_d )   \\leq   c_l \\bigl([{\\widehat { \\delta}}'_{i ,",
    "t}+\\epsilon_{i , t}]_d - [ { \\widehat { \\delta}}'_{i , t}-\\epsilon_{i , t}]_d\\bigl )   \\leq 2\\,c_l\\,\\epsilon_{i , t}.\\ ] ]    now , we first give a proof of lemma [ l : bayesrank ] , and then provide a one step regret for the partial information ranking loss .",
    "recall the notation @xmath323 , and @xmath324 . for notational convenience , in this proof",
    "we drop subscript @xmath1 from @xmath96 , @xmath224 , @xmath70 , @xmath3 , and @xmath229 .",
    "a simple adaptation of @xcite ( proof of theorem 1 therein ) shows that for a generic sequence @xmath325 with at most @xmath255 nonzero values @xmath326 and associated set of indices @xmath327 , one has @xmath328",
    "= \\sum_{i , j \\in { { \\hat y}},\\ , i < j } \\left({\\widehat { r}}_{i , j } + { \\widehat { r}}_{j , i}\\right ) +   s\\,\\left(\\sum_{i \\in [ k ] } p_{i } - \\sum_{i \\in { { \\hat y } } } p_{i } \\right)\\ ] ] where @xmath329 moreover , if @xmath330 denotes the sequence made up of at most @xmath255 nonzero values taken from @xmath331\\}$ ] , _ where @xmath21 ranges again in _ @xmath327 , we have @xmath332   = \\sum_{i , j \\in { { \\hat y}},\\ , i < j } \\left(r_{i , j } + r_{j , i}\\right ) + s\\,\\left(\\sum_{i \\in [ k ] } p_{i } - \\sum_{i \\in { { \\hat y } } } p_{i } \\right)\\ ] ] with @xmath333 hence @xmath328 - { \\ensuremath{\\mathbb{e}}}_t[\\ell_{p - rank}(y_t , p^ * ) ] =   \\sum_{i , j \\in { { \\hat y}},\\ , i < j } \\left({\\widehat { r}}_{i , j } - r_{i , j } + { \\widehat { r}}_{j , i } - r_{j , i}\\right).\\ ] ] since @xmath334 a simple ( but lengthy ) case analysis reveals that @xmath335 notice that the above quantity is always nonnegative , and is strictly positive if the @xmath336 are all different .",
    "the nonnegativity implies that _ whatever set of indices @xmath327 we select _ , the best way to sort them within @xmath327 in order to minimize @xmath337 $ ] is by following the ordering of the corresponding @xmath336 .",
    "we are left to show that the best choice for @xmath327 is to collect the @xmath255 largest values in @xmath331\\}$ ] .",
    "to this effect , consider again @xmath338 = { \\ensuremath{\\mathbb{e}}}_t[\\ell_{p - rank}(y_t,{{\\hat y}})]$ ] , and introduce the shorthand @xmath339 .",
    "disregarding the term @xmath340 } p_{i}$ ] , which is independent of @xmath327 , we can write @xmath341   & =   \\sum_{i , j \\in { { \\hat y}},\\ , i < j } { \\mathbb{p}}_t(y_{i } >",
    "y_{j})\\ , \\left(\\ { p_{i } < p_{j } \\ } + { \\mbox{$\\frac{1}{2}$}}\\,\\ { p_{i } = p_{j } \\ } \\right)\\notag\\\\   & \\ \\ \\ \\ \\ +   \\sum_{i , j \\in { { \\hat y}},\\ , i < j } { \\mathbb{p}}_t(y_{j } > y_{i})\\ , \\left(\\ { p_{j } < p_{i } \\ } + { \\mbox{$\\frac{1}{2}$}}\\,\\ { p_{j } = p_{i } \\ } \\right )        - s\\,\\sum_{i \\in { { \\hat y } } } p_{i } \\notag\\\\ & =   \\sum_{i , j \\in { { \\hat y}},\\ , i < j } ( p_i - p_{i , j})\\ { p_{i } < p_{j } \\ } +                ( p_i - p_{i , j } ) { \\mbox{$\\frac{1}{2}$}}\\,\\ { p_{i } = p_{j } \\ } \\notag\\\\ & \\ \\ \\ \\ \\ +   \\sum_{i , j \\in { { \\hat y}},\\ , i < j } ( p_j - p_{i , j})\\ { p_{j } < p_{i } \\ } +                ( p_j - p_{i , j } ) { \\mbox{$\\frac{1}{2}$}}\\,\\ { p_{j } = p_{i } \\ }        - s\\,\\sum_{i \\in { { \\hat y } } } p_{i}\\notag\\\\ & =   \\sum_{i , j \\in { { \\hat y}},\\ , i < j } ( p_i - p_{j})\\ { p_{i } < p_{j } \\ } +                { \\mbox{$\\frac{1}{2}$}}\\,(p_i - p_j)\\,\\ { p_{i } = p_{j } \\ } + p_j - p_{i , j }       - s\\,\\sum_{i \\in { { \\hat y } } } p_{i}\\notag\\\\ & =   \\sum_{i , j \\in { { \\hat y}},\\ , i < j } \\left(\\min\\{p_i , p_j\\ }",
    "-p_i p_j\\right )     - s\\,\\sum_{i \\in { { \\hat y } } } p_{i}\\notag\\end{aligned}\\ ] ] which can be finally seen to be equal to @xmath342 where @xmath343 is the position of class @xmath21 within @xmath3 in decreasing order of @xmath305 .",
    "now , rename the indices in @xmath327 as @xmath344 , in such a way that @xmath345 ( so that @xmath346 ) , and consider the way to increase ( [ e : minloss ] ) by adding to @xmath327 item @xmath347 such that @xmath348 and removing from @xmath327 the item in position @xmath253 .",
    "denote the resulting sequence by @xmath349 . from ( [ e : minloss ] ) , it is not hard to see that @xmath350 -   { \\ensuremath{\\mathbb{e}}}_t[\\ell_{p",
    "- rank}(y_t,{{\\hat y}}')]\\notag\\\\ & = ( \\ell-1)\\,p_{\\ell } + \\sum_{i=\\ell+1}^{s}p_{i } - \\sum_{i=1}^{\\ell-1}p_{i}\\,p_{\\ell }   - \\sum_{i=\\ell+1}^{s}p_{\\ell}\\,p_{i } -(s-1)\\,p_k   + \\sum_{i=1,i \\neq \\ell}^{s}p_{i}\\,p_{k } - s(p_{\\ell}-p_k)\\notag\\\\ & = ( \\ell-1)\\,p_{\\ell } + \\sum_{i=\\ell+1}^{s}p_{i }   - ( p_{\\ell}-\\,p_k)\\,\\sum_{i=1,i \\neq \\ell}^{s}p_{i } - ( s-1)\\,p_k -   s(p_{\\ell}-p_k)\\notag\\\\ & \\leq ( s-1)\\,p_{\\ell } - ( p_{\\ell}-\\,p_k)\\,\\sum_{i=1,i \\neq \\ell}^{s}p_{i }   - ( s-1)\\,p_k -   s(p_{\\ell}-p_k)\\notag\\\\ & = ( p_{k}-\\,p_{\\ell})\\left(1+\\sum_{i=1,i \\neq \\ell}^{s}p_{i}\\right)\\end{aligned}\\ ] ] which is smaller than zero since , by assumption , @xmath351 . reversing the direction ,",
    "if we maintain a sequence @xmath327 of size @xmath255 , we can always reduce ( [ e : minloss ] ) by removing its the last element and replacing it with a larger element outside the sequence .",
    "we continue until no element outside the current sequence exists which is larger than the smallest one in the sequence .",
    "clearly , we end up collecting the @xmath255 largest elements in @xmath331\\}$ ] .",
    "finally , from ( [ e : minloss ] ) it is very clear that removing an element from a sequence @xmath327 with length @xmath352 can only increase the value of ( [ e : minloss ] ) .",
    "since this holds for an arbitrary @xmath327 , and an arbitrary @xmath352 this shows , that no matter which set @xmath327 we start off from , we always converge to the same set containing exaclty the @xmath255 largest elements in @xmath331\\}$ ] .",
    "this concludes the proof .",
    "[ l : onestepsingle_ranking ] under the same assumptions and notation as in lemma [ l : onestepsingle ] , combined with the independence assumption ( [ e : indep ] ) , let the algorithm in figure [ f:2 ] be working with @xmath250 and strictly decreasing cost values @xmath32",
    ", i.e. , the algorithm is computing in round @xmath1 the ranking function @xmath353 defined in section [ s : rank ] .",
    "let @xmath129 be the @xmath21-th weight vector computed by this algorithm at the beginning ( step 2 ) of time @xmath1 .",
    "if time @xmath1 is such that @xmath309 for all @xmath95 $ ] , then @xmath354   - { \\ensuremath{\\mathbb{e}}}_t[\\ell_{rank , t}(y_t , f^*({\\boldsymbol{x}}_t;s_t ) ] \\leq",
    "4\\,s_t\\,c_l\\,\\sum_{i \\in { { \\hat y}}_t } \\epsilon_{i , t}~.\\ ] ]    we use the same notation as in the proof of lemma [ l : bayesrank ] , where @xmath355 is now @xmath3 , the sequence produced by ranking @xmath353 operating on @xmath143 .",
    "denote by @xmath92 the sequences determined by @xmath356 , and let @xmath343 and @xmath357 be the position of class @xmath21 in decreasing order of @xmath96 within @xmath3 and @xmath92 , respectively .",
    "proceeding as in lemma [ l : onestepsingle ] and recalling ( [ e : minloss ] ) we can write @xmath358   - { \\ensuremath{\\mathbb{e}}}_t[\\ell_{p - rank , t}(y_t , f^*({\\boldsymbol{x}}_t;s_t)]\\\\   & = \\sum_{i \\in y^*_t } ( s_t+1-j^*_i)\\,p_i + \\sum_{i , j \\in y^*_t,\\ , i < j } p_i\\,p_j - \\sum_{i \\in { { \\hat y}}_t } ( s_t+1-{\\hat j_i})\\,p_i - \\sum_{i , j \\in",
    "{ { \\hat y}}_t,\\ , i < j } p_i\\,p_j\\\\ & \\leq \\sum_{i \\in y^*_t } ( s_t+1-j^*_i)\\,p([{\\widehat { \\delta}}'_{i , t}+\\epsilon_{i , t}]_d )   + \\sum_{i , j \\in y^*_t,\\ , i < j }           p([{\\widehat { \\delta}}'_{i , t}+\\epsilon_{i , t}]_d)\\,p([{\\widehat { \\delta}}'_{j , t}+\\epsilon_{j , t}]_d)\\\\ & \\qquad - \\sum_{i \\in { { \\hat y}}_t } ( s_t+1-{\\hat j_i})\\,p([{\\widehat { \\delta}}'_{i , t}-\\epsilon_{i , t}]_d )   - \\sum_{i , j \\in { { \\hat y}}_t,\\ , i < j }            p([{\\widehat { \\delta}}'_{i , t}-\\epsilon_{i , t}]_d)\\,p([{\\widehat { \\delta}}'_{j , t}-\\epsilon_{j , t}]_d)\\\\ & \\leq \\sum_{i \\in { { \\hat y}}_t }      ( s_t+1-{\\hat j_i})\\,\\left(p([{\\widehat { \\delta}}'_{i , t}+\\epsilon_{i , t}]_d )                            - p([{\\widehat { \\delta}}'_{i , t}-\\epsilon_{i , t}]_d ) \\right ) \\\\ & \\qquad + \\sum_{i , j \\in { { \\hat y}}_t,\\ , i < j }        \\left(p([{\\widehat { \\delta}}'_{i , t}+\\epsilon_{i , t}]_d)\\,p([{\\widehat { \\delta}}'_{j , t}+\\epsilon_{j , t}]_d ) -          p([{\\widehat { \\delta}}'_{i , t}-\\epsilon_{i , t}]_d)\\,p([{\\widehat { \\delta}}'_{j , t}-\\epsilon_{j , t}]_d)\\right)\\\\ & \\leq 2s_t c_l\\,\\sum_{i \\in { { \\hat y}}_t}\\epsilon_{i , t } + \\sum_{i , j \\in { { \\hat y}}_t,\\ , i < j } 2c_l\\,(\\epsilon_{i , t}+\\epsilon_{j , t})\\\\ & = 2\\,s_t\\,c_l\\,\\sum_{i \\in { { \\hat y}}_t } \\epsilon_{i , t } +   2\\,(s_t-1)\\,c_l\\,\\sum_{i \\in { { \\hat y}}_t}\\epsilon_{i , t } \\\\ & < 4\\,s_t\\,c_l\\,\\sum_{i \\in { { \\hat y}}_t } \\epsilon_{i , t}\\,,\\end{aligned}\\ ] ] as claimed .",
    "[ l : upperconfsingle ] let @xmath173 \\subseteq { { { \\mathcal{r}}}}\\rightarrow { { { \\mathcal{r}}}}^+$ ] be a @xmath174 convex and nonincreasing function of its argument , @xmath175 be defined in ( [ e : labgenmult ] ) with @xmath125 for all @xmath176 , and such that @xmath177 for all @xmath95 $ ] .",
    "assume there are positive constants @xmath170 and @xmath171 with @xmath180 and @xmath181 for all @xmath176 . with the notation introduced in figure [ f:2 ] , we have that @xmath359 holds with probability at least @xmath182 for any @xmath360 , _ uniformly _ over @xmath95 $ ] , @xmath361 and @xmath362 .    for any given class @xmath21 , the time-@xmath1 update rule @xmath363 in figure [ f:2 ]",
    "allows us to start off from @xcite ( proof of theorem 2 therein ) , from which one can extract the following inequality @xmath364 where we set @xmath365 . using the lower bound on the second derivative of @xmath74 we have @xmath366 plugging back into ( [ e : partialres ] ) yields @xmath367 we now borrow a proof technique from @xcite ( see also @xcite and references therein ) . define @xmath368 and @xmath369 - l_{i , k}$ ] .",
    "notice that the sequence of random variables @xmath370 , @xmath371 forms a martingale difference sequence such that , for any @xmath372 :    1 .",
    "@xmath373 \\geq 0 $ ] , by lemma [ l : variancesingle ] ; 2 .",
    "@xmath374 , since @xmath124 is nonincreasing over @xmath136 , and @xmath375 , @xmath376 ; 3 .",
    "@xmath377 $ ] ( again , because of lemma [ l : variancesingle ] ) .    on the other hand , when @xmath378 then @xmath379 , and the above three properties are trivally satisfied .",
    "under the above conditions , we are in a position to apply any fast concentration result for bounded martingale difference sequences . for instance , setting for brevity @xmath380 , a result contained in @xcite allows us derive the inequality @xmath381 - \\sum_{k=1}^{t-1 } l_{i , k }   \\geq \\max\\left\\ { \\sqrt{\\frac{8c'_l}{c''_l}\\,b\\,\\sum_{k=1}^{t-1 } { \\ensuremath{\\mathbb{e}}}_k[l_{i , k } ] } , 6 l(-r)\\,b \\right\\}~,\\ ] ] that holds with probability at most @xmath382 for any @xmath383 .",
    "we use the inequality @xmath384 with @xmath385 , and @xmath386 $ ] , and simplify .",
    "this gives @xmath387 with probability at least @xmath388 . using the cauchy - schwarz inequality @xmath389 holding for any @xmath68 , and replacing back into ( [ e : partialres2 ] ) allows us to conclude that @xmath390 holds with probability at least @xmath391 , _ uniformly _ over @xmath362 .",
    "the bounds on @xmath392 can be obtained in a standard way . applying known inequalities @xcite , and using the fact that @xmath393 we have based on @xmath394 rather than @xmath395 .",
    "notice that using the latter ( as in the worst - case analysis by @xcite ) , does not guarantee a significant progress in the positive definiteness of @xmath147 .",
    "this is due to the presence of the multiplicative factor @xmath396 ( step 5 in figure [ f:2 ] ) which can be arbitrarily small . ]",
    "@xmath397 combining as in ( [ e : partialres3 ] ) and stratifying over @xmath398 , and @xmath95 $ ] concludes the proof .",
    "we are now ready to put all pieces together .    from lemma  [ l : onestepsingle ] and lemma  [ l : upperconfsingle ] , we see that with probability at least @xmath182 , @xmath399 when @xmath172 is the one given in figure [ f:2 ] .",
    "we continue by proving a pointwise upper bound on the sum in the rhs .",
    "more in detail , we will find an upper bound on @xmath400 , and then derive a resulting upper bound on the rhs of ( [ e : partial ] ) .    from lemma [ l : upperconfsingle ] and the update rule ( step 5 ) of the algorithm we can write @xmath401 hence ,",
    "if we set @xmath402 and proceed as in the proof of lemma [ l : upperconfsingle ] , we end up with the upper bound @xmath403 , holding for all @xmath95 $ ] . denoting by @xmath404 the quantity @xmath405",
    ", we conclude from ( [ e : partial ] ) that @xmath406 } \\sum_{t=1}^t \\epsilon_{i , t } \\,\\bigl|\\ ,   \\sum_{t = 1}^t \\epsilon^2_{i , t } \\leq m,\\,\\,\\ , i \\in [ k ] \\right\\ } = 2\\,(1-a)\\,c_l\\,k\\,\\sqrt{t\\,m}~,\\ ] ] as claimed .",
    "as we said , we change the definition of @xmath172 in the algorithm in figure [ f:2 ] to @xmath407    we start from the one step - regret delivered by lemma [ l : onestepsingle_ranking ] , and proceed as in the proof of theorem [ t : cumregret ] .",
    "this yields @xmath408 } \\epsilon_{i , t}\\\\ & = 4\\,s\\,c_l \\,\\sum_{i \\in [ k ] } \\sum_{t=1}^t \\epsilon_{i , t}\\,,\\end{aligned}\\ ] ] with probability at least @xmath182 , where @xmath172 is the one given in figure [ f:2 ] .",
    "let @xmath404 be as in the proof of theorem [ t : cumregret ] .",
    "if @xmath409 denotes the total number of times class @xmath21 occurs in @xmath3 , we have that @xmath410 , implying @xmath411 for all @xmath95 $ ] . moreover , @xmath263 } n_{i , t } \\leq st$ ] . hence @xmath412 } \\sqrt{n_{i , t}\\,m } \\leq 4\\,c_l\\,\\sqrt { m\\,s\\,k\\,t}\\,,\\ ] ] as claimed .",
    "we have used generalized linear models to formalize the exploration - exploitation tradeoff in a multilabel / ranking setting with partial feedback , providing @xmath9-like regret bounds under semi - adversarial settings .",
    "our analysis decouples the multilabel / ranking loss at hand from the label - generation model .",
    "thanks to the usage of calibrated score values @xmath143 , our algorithm is capable of automatically inferring where to split the ranking between relevant and nonrelevant classes @xcite , the split being clearly induced by the loss parameters in @xmath48 .",
    "we are planning on using more general label models that explicitly capture label correlations to be applied to other loss functions ( e.g. , f - measure , 0/1 , average precision , etc . ) .",
    "we are also planning on carrying out a more thorough experimental comparison , especially to full information multilabel methods that take such correlations into account .",
    "finally , we are currenty working on extending our framework to structured output tasks , like ( multilabel ) hierarchical classification .                                                                            c.  g.  m. snoek , m.  worring , j.c .",
    "van gemert , j .-",
    "geusebroek , and a.  w.  m. smeulders .",
    "the challenge problem for automated detection of 101 semantic concepts in multimedia . in _ proc . of the 14th acm international conference on multimedia _ , pages 421430 , 2006 ."
  ],
  "abstract_text": [
    "<S> we present a novel multilabel / ranking algorithm working in partial information settings . </S>",
    "<S> the algorithm is based on 2nd - order descent methods , and relies on upper - confidence bounds to trade - off exploration and exploitation . </S>",
    "<S> we analyze this algorithm in a partial adversarial setting , where covariates can be adversarial , but multilabel probabilities are ruled by ( generalized ) linear models . </S>",
    "<S> we show @xmath0 regret bounds , which improve in several ways on the existing results . </S>",
    "<S> we test the effectiveness of our upper - confidence scheme by contrasting against full - information baselines on real - world multilabel datasets , often obtaining comparable performance . </S>"
  ]
}