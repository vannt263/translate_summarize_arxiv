{
  "article_text": [
    "al index data were retrieved from the kyoto geomagnetism data service ( http://wdc.kugi.kyoto-u.ac.jp/ , accessed on september 2016 ) . solar wind ( @xmath111 and @xmath112 )",
    "data were provided by the ace @xcite spacecraft mission , and retrieved from the omniweb service ( http://omniweb.gsfc.nasa.gov/ , accessed on september 2016 ) .",
    "following @xcite , we build our data - driven basis @xmath113 using eigenfunctions associated with the variable - bandwidth kernel @xmath114 defined as @xmath115 in  , @xmath116 is the dimension of the ambient data space ( i.e. , @xmath117 or @xmath118 for bivariate and univariate diffusion forecast models , where @xmath24 is the number of delays ) , @xmath119 is a positive bandwidth parameter , @xmath120 is a positive bandwidth function ( to be described momentarily ) , and @xmath121 is an estimate of the intrinsic dimension @xmath122 of the state space manifold @xmath14 . note that because @xmath14 is embedded in @xmath123 by the smooth observation map @xmath124 ( see main text ) , it inherits a smooth riemannian metric @xmath125 .",
    "we also note that for now the bandwidth parameter @xmath119 is unspecified , but we will select it below using an automatic procedure which also returns the dimension estimate @xmath121 .    following the theory developed in @xcite ,",
    "we use as a bandwidth function @xmath126 in   is an estimate of the sampling density of the data relative to the riemannian measure associated with the observation map .",
    "that is , @xmath126 is a function chosen such that for @xmath127 , @xmath128 is equal to the sampling density @xmath129 up to an @xmath130 error , where @xmath131 is the riemannian measure associated with @xmath125 . here , we compute @xmath132 using kernel density estimation as in @xcite , namely @xmath133 where @xmath134 is the number of samples in the training data , @xmath135 is a bandwidth parameter , @xmath136 an estimate of @xmath122 ( note that @xmath135 and @xmath137 are not necessarily equal to @xmath119 and @xmath121 , respectively ) .",
    "moreover , @xmath138 is a bandwidth function given by @xmath139 where @xmath140 is the index of the @xmath141-th nearest neighbor of @xmath142 in the training dataset @xmath59 , and @xmath143 is an integer - valued parameter controlling the size of the neighborhood used for kernel density estimation .",
    "the results in this work were obtained using the value @xmath144 as in @xcite , although the properties of the basis are not too sensitive on that choice .    to select appropriate values for the bandwidth parameters @xmath119 and @xmath135 , as well as to estimate the intrinsic dimension @xmath122 ,",
    "we compute the kernel sums @xmath145 and @xmath146 and select @xmath119 and @xmath135 as the maximizers of @xmath147 and @xmath148 , respectively . as discussed in @xcite , this criterion can be interpreted as maximizing the `` resolution '' associated with the kernels @xmath149 and @xmath150 . moreover , as @xmath151 , the maximum values @xmath152 and @xmath153 are both equal to the intrinsic dimension @xmath122 . numerically , we approximate @xmath154 and @xmath155 , using finite differences computed for equispaced values of @xmath156 and @xmath157 , and set @xmath121 and @xmath136 to the corresponding approximate maximum values . in our experiments ,",
    "we obtain values of @xmath121 and @xmath136 in the range 3.44.3 .",
    "next , following @xcite , we normalize the kernel in   to construct a markov operator @xmath158 acting on functions on @xmath159 using the normalization procedure introduced in the diffusion maps algorithm @xcite .",
    "this operator is represented by a discrete markov kernel @xmath160 such that @xmath161 where @xmath37 is an arbitrary point in @xmath14 , @xmath127 is the corresponding data point in @xmath123 , and @xmath162 is the training data point associated with the state @xmath30 . in particular , given a function @xmath163 , we define @xmath164 . by ergodicity , as @xmath151 , @xmath165 converges almost surely to @xmath166 , where @xmath167 is a markov operator with a smooth transition kernel relative to the invariant measure @xmath34 .",
    "moreover , it can be shown that @xmath166 admits the asymptotic expansion , @xmath168 uniformly on @xmath14 , where @xmath169 is the laplace - beltrami operator associated with the conformally transformed riemannian metric @xmath170 with @xmath171 .",
    "due to the conformal scaling by @xmath172 , the volume form @xmath173 of @xmath174 is equal to the invariant measure of the dynamics ( i.e. , @xmath175 ) .",
    "thus , @xmath169 is a self - adjoint operator on @xmath36 and its eigenfunctions @xmath176 provide an orthonormal basis of this space .",
    "an important property of these basis functions is that they are extrema of the dirichlet energy functional @xmath177 where @xmath178 is the gradient operator associated with the ambient space metric @xmath125 , and @xmath179 is equal to the corresponding eigenvalue . intuitively , we think of @xmath180 as a measure of roughness of functions that ( due to the @xmath181 term in the integrand ) penalizes large gradients with respect to @xmath125 in regions of @xmath14 with small sampling density  this property endows the @xmath182 with robustness against sampling errors . moreover , ordering the @xmath182 in order of increasing dirichlet energy , we interpret @xmath183 as the least - rough @xmath75-element orthonormal set in @xmath36 with respect to the dirichlet functional in  .    with these considerations in mind , we build our data - driven basis @xmath47 using the leading @xmath75 eigenfunctions ( ordered in order of increasing eigenvalue ) of the operator @xmath184 , which converges pointwise to @xmath185 as @xmath151 and @xmath186 .",
    "this is equivalent to representing each @xmath187 by an @xmath134-dimensional column vector @xmath188 storing the eigenfunction values at the sampled points in @xmath14 , and solving the matrix eigenvalue problem @xmath189 , where @xmath190 is an @xmath191 matrix with elements @xmath192 given by  , and the eigenvalues @xmath193 are ordered in decreasing order .",
    "numerically , we solve this problem by first computing the eigenvectors @xmath194 of the symmetric matrix @xmath195 , where @xmath196 is an @xmath191 diagonal matrix with entries @xmath197 , and then evaluating @xmath198 .",
    "moreover , for computational efficiency , we sparsify @xmath199 by zeroing out the entries in each row which lie outside a pre - selected mutual affinity neighborhood of the corresponding data point .",
    "that is , we set @xmath200 to zero if @xmath201 is not in the @xmath202 largest values of @xmath203 and @xmath204 . due to the exponential decay of the kernel",
    ", this truncation does not impart an additional asymptotic error in the approximation of @xmath205 by @xmath206 at fixed @xmath202 .    before proceeding",
    ", we note that @xcite perform a different kernel normalization procedure than the one described above and in @xcite .",
    "in particular , they approximate a weighted laplacian @xmath207 associated with the ambient space metric @xmath125 , as opposed to the unweighted laplace - beltrami operator @xmath169 associated with the conformally transformed metric @xmath174 . the weighted laplacian in @xcite is associated with the dirichlet functional @xmath208 which differs from   in that it does not feature the density - dependent term @xmath181 in the integrand .",
    "however , both @xmath209 and @xmath169 are self - adjoint on @xmath210 , and their eigenfunctions provide suitable orthonormal bases for diffusion forecasting .",
    "supporting information ( si ) figs .",
    "[ figal2003 ] and  [ figzoom2003 ] show analogous prediction results for 2003 to figs .  2 and  3 in the main text , but for the lower al index threshold values @xmath211 and @xmath212 nt corresponding to the mean minus two and three standard deviations of the al time series , respectively .",
    "as expected , the prediction probabilities for these thresholds are generally lower than the results for the @xmath213 nt threshold shown in the main text , but they still exhibit significant increases when the al verification signal crosses the chosen threshold .",
    "this suggests that the diffusion model has skill even for thresholds as low as three standard deviations , as is indeed confirmed in the roc results in fig .  4 in the main text .",
    "moreover , comparing si fig .",
    "[ figzoom2003 ] to fig .",
    "3 in the main text indicates that the improvement of skill of the bivariate models over the univariate models is higher for the lower thresholds .",
    "si figs .  [ figal2000_1 ] and  [ figal2000_2 ] show analogous prediction probability results to fig .  2 in the main text and si fig .  [ figal2003 ] , respectively , but for the year 2000 dataset .",
    "the corresponding roc results are shown in si fig .",
    "[ figroc ] . as in the case of year 2003",
    ", the bivariate models trained with both al and @xmath1 data for 2000 have generally higher prediction skill than the corresponding univariate models trained on al index data alone , apart from small lead times ( @xmath214 minutes ) where the univariate models appear to benefit from better initial conditions . moreover , the improvement of skill of the bivariate models over the univariate ones is higher for the more challenging forecasts with the smaller ( @xmath105 and @xmath215 nt ) al index thresholds .",
    "same as si fig .",
    "[ figal2003 ] , but for the year 2000 dataset and the threshold @xmath216 nt . ]          data ( dashed ) and the model trained with al data alone ( solid ) . in each curve , circles denote the thresholds indicated in the main text from the smaller values ( with larger tpr ) to the larger values ( with smaller tpr ) . triangles indicate the roc values for a trivial random forecast lying on the @xmath107 line . ]",
    "since the diffusion forecast models constructed here are autonomous , the bivariate models trained with both the al and @xmath1 data can also be used to predict @xmath1 .",
    "[ figure2 ] shows the root mean squared ( rms ) errors of @xmath1 prediction for years 2000 and 2003 . here",
    ", the rms error is defined as @xmath217(t)= \\int_m z^\\text{sw } \\rho_t \\ , d\\mu \\approx \\frac { 1 } { n } \\sum_{i=0}^{n-1 } z^\\text{sw } ( x_i ) \\hat{\\rho}_t(x_i),\\nonumber\\end{aligned}\\ ] ] where the average is taken over the 20000 sample verification period . notice that the rms errors relax to the corresponding steady - state values ( i.e. , the ensemble spread ) beyond lead times of 200 minutes .",
    "13ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ]",
    " + 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty link:\\doibase 10.1029/94ja02725 [ * * ,   ( ) ] link:\\doibase 10.1103/physreve.65.016116 [ * * ,   ( ) ] link:\\doibase 10.1029/2001ja009160 [ * * ,   ( ) ] link:\\doibase 10.1029/2001ja900118 [ * * , ( ) ] link:\\doibase 10.1103/physreve.91.032915 [ * * ,   ( ) ] link:\\doibase 10.1016/j.acha.2006.04.006 [ * * ,   ( ) ] link:\\doibase 10.1016/j.acha.2015.01.001 [ * * , ( ) ] link:\\doibase 10.1016/j.physd.2016.01.012 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevlett.45.712 [ * * ,   ( ) ] in  link:\\doibase 10.1007/bfb0091924 [ _ _ ] ,  , vol .",
    "( ,  ,  )  pp .",
    "link:\\doibase 10.1007/bf01053745 [ * * ,   ( ) ] \\doibase    10.1023/a:1005082526237 [ * * ,   ( ) ] @noop `` , ''   ( ) ,"
  ],
  "abstract_text": [
    "<S> we propose a nonparametric approach for probabilistic prediction of the al index trained with al and solar wind ( @xmath0 ) data . </S>",
    "<S> our framework relies on the diffusion forecasting technique , which views al and @xmath1 data as observables of an autonomous , ergodic , stochastic dynamical system operating on a manifold . </S>",
    "<S> diffusion forecasting builds a data - driven representation of the markov semigroup governing the evolution of probability measures of the dynamical system . </S>",
    "<S> in particular , the markov semigroup operator is represented in an orthonormal basis acquired from data using the diffusion maps algorithm and takens delay embeddings . </S>",
    "<S> this representation of the evolution semigroup is used in conjunction with a bayesian filtering algorithm for forecast initialization to predict the probability that the al index is less than a user - selected threshold over arbitrary lead times and without requiring exogenous inputs . </S>",
    "<S> we find that the model produces skillful forecasts out to at least two - hour leads despite gaps in the training data .    </S>",
    "<S> the interaction of the solar wind ( sw ) and the embedded interplanetary magnetic field ( imf ) with the intrinsic dipolar geomagnetic field creates a cavity in the earth s magnetosphere . </S>",
    "<S> southward turning of the imf allows for the efficient penetration and storage of sw energy in that cavity , whose subsequent release leads to an explosive phenomenon known as magnetospheric substorm . during substorms , </S>",
    "<S> a strong ionospheric current is developed , inducing geomagnetic field disturbances on the ground . </S>",
    "<S> the intensity of a substorm is quantified by the al index , which is a measure of the magnitude of those disturbances . understanding and predicting geomagnetic substorms , and thus one of the major modes of sw  magnetosphere coupling , has been a long - standing , unresolved issue in space physics . </S>",
    "<S> this is because substorms involve multiscale , nonlinear interactions of plasmas that are either not in equilibrium , or are in unstable equilibrium . </S>",
    "<S> largely due to the multiscale nature of the phenomenon , first - principles physics - based modeling is not always feasible and often produces erroneous predictions of the magnetospheric state during substorms . </S>",
    "<S> therefore , developing data - driven predictive models that take advantage of the abundance of al index measurements is of the essence . </S>",
    "<S> various data - driven techniques have been proposed , such as non - autonomous models @xcite and techniques based on support vector machines @xcite . </S>",
    "<S> frequently , sw conditions are used as external factors in order to predict the al index . in particular , the external input is the product @xmath2 where @xmath3 is the bulk sw velocity along the sun - earth axis and @xmath4 the north - south component of the imf . </S>",
    "<S> as stated above , when the imf is southward ( @xmath5 ) , the sw  magnetosphere coupling becomes very efficient and more likely to cause a geomagnetic substorm , and thus decrease of the al index .    in this paper </S>",
    "<S> , we propose a nonparametric approach for statistical prediction of al index time series using a recently developed data - driven technique called diffusion forecasting @xcite . </S>",
    "<S> this approach models the al index as an observable ( function of the state ) of an abstract stochastic dynamical system operating on a manifold . in diffusion forecasting , </S>",
    "<S> the semigroup operator governing the evolution of probability measures is represented on a smooth data - driven basis acquired from time - ordered data using the diffusion maps algorithm @xcite with a variable - bandwidth kernel @xcite . using this representation of the dynamics and a bayesian filtering scheme for forecast initialization @xcite , </S>",
    "<S> our method predicts the probability for the observable of interest ( in this case , the al index ) to lie in given intervals for arbitrary lead times without requiring exogenous inputs . </S>",
    "<S> in particular , unlike other approaches @xcite , our model does not treat @xmath1 as an external factor for al index prediction but rather as an observable of a single autonomous dynamical system . </S>",
    "<S> thus , as an auxiliary result , our model also predicts analogous probabilities for the @xmath1 data ( see supporting information ( si ) ) .    </S>",
    "<S> consider time - ordered datasets , @xmath6 and @xmath7 , of al index and @xmath1 time series , respectively , taken at times @xmath8 for a fixed sampling interval @xmath9 and starting time @xmath10 , and normalized to unit variance . in our training procedure we use @xmath11 min and @xmath12 corresponding to a physical interval of approximately 69 days . here , </S>",
    "<S> we focus on results from a training interval starting on 1/1/2003 ; a 10-day portion of the al index and @xmath1 data in that interval is shown in fig .  </S>",
    "<S> [ figraw ] . </S>",
    "<S> our data sources are listed in the si . </S>",
    "<S> note that the @xmath1 data sometimes contain gaps , which we fill in using linear interpolation in time . as demonstrated below </S>",
    "<S> , diffusion forecasting is able to produce skillful forecasts despite such missing data . </S>",
    "<S> results from a training interval starting on 1/1/2000 are presented in the si .     </S>",
    "<S> ( top ) and al index ( bottom ) time series for the interval 1/1/2003 0:00 utc to 1/11/2003 10:00 utc . </S>",
    "<S> notice the missing sw data occurring around the 1/07 22:40 utc tickmark which are filled in using linear interpolation in time . ]    </S>",
    "<S> the diffusion forecasting approach views the al index and @xmath13 time series as observables on the state space manifold @xmath14 of an ergodic ( hence autonomous ) stochastic dynamical system ; that is , we consider that there exist smooth mappings @xmath15 and @xmath16 such that @xmath17 and @xmath18 , where @xmath19 is the system state at time @xmath20 . similarly , we have the composite map @xmath21 with @xmath22 . in general , knowledge of @xmath23 alone </S>",
    "<S> is not sufficient to uniquely determine the underlying state @xmath19 . </S>",
    "<S> nevertheless , according to the theory of delay - coordinate maps @xcite , for a sufficiently large number of delays @xmath24 and under mild assumptions on @xmath25 , @xmath26 , and the dynamical system , the map @xmath27 with @xmath28 is an embedding of @xmath14 , i.e. , a one - to - one map with continuous inverse on its image . thus , the data @xmath29 are in one - to - one correspondence with the states @xmath30 . in </S>",
    "<S> what follows , we set @xmath31 to give the model the information in a 50-minute interval ; this is the typical time delay between the observed solar wind southward turning and the al index decreases . </S>",
    "<S> another crucial property that we make use of is ergodicity  this allows us to approximate expectation values with respect to the invariant probability measure of the dynamics by time averages . in particular </S>",
    "<S> , ergodicity implies that for an integrable observable @xmath32 , @xmath33 , where @xmath34 is an invariant probability measure .    </S>",
    "<S> suppose now that at forecast initialization time knowledge about the system state is characterized by a probability measure with density @xmath35 relative to @xmath34 , and that @xmath35 lies in the hilbert space @xmath36 . at lead time </S>",
    "<S> @xmath9 , the probability density for the system state @xmath37 is given by @xmath38 , where @xmath39 is the fokker - planck operator governing the evolution of probability densities with respect to @xmath34 . </S>",
    "<S> the key observation made in @xcite ( which is a consequence of ergodicity ) is that given two functions @xmath40 whose values @xmath41 at the sampled states are known , the time - shifted correlation @xmath42 is an unbiased estimate of the inner product @xmath43 on @xmath44 with variance scaling as @xmath45 . here </S>",
    "<S> , @xmath46 is the kolmogorov generator of the dynamics , i.e. , the adjoint of the fokker - planck operator @xmath39 . in particular , given a finite orthonormal set @xmath47 in @xmath36 , we can compute the matrix elements @xmath48 . </S>",
    "<S> the key idea in diffusion forecasting is to approximate all densities by their projections onto the finite - dimensional subspace of @xmath36 spanned by the @xmath49 ; that is @xmath50 . at lead time </S>",
    "<S> @xmath51 , @xmath52 , we obtain the forecast density @xmath53_{ji } \\phi_i ( x_k ) , \\end{aligned}\\ ] ] where @xmath54 approximate the expansion coefficients at initial time . as is evident from  </S>",
    "<S> , @xmath55 can be evaluated for arbitrary @xmath56 without requiring exogenous inputs , so long as the expansion coefficients @xmath57 are known . </S>",
    "<S> moreover , no restrictions on the stepsize @xmath9 are placed .    </S>",
    "<S> in diffusion forecasting , the basis functions @xmath58 are computed from the dataset @xmath59 using the diffusion maps algorithm with a variable - bandwidth kernel designed to induce orthogonality of the @xmath60 with respect to the invariant measure . moreover , the basis satisfies an optimality condition for the variance of the matrix elements @xmath61 . in summary , diffusion forecasting can be thought of as a spectral method for the dynamical evolution semigroup in a smooth data - driven basis inherited from the dataset . </S>",
    "<S> we refer the reader to @xcite for further details on the construction of the basis and for error bounds . in our experiments , we set the number of basis functions to @xmath62 ; the attained forecast skill is not too sensitive on this choice . </S>",
    "<S> we also build univariate diffusion forecast models using delay - coordinate mapped al index data alone . </S>",
    "<S> we use such models to assess the contribution of the @xmath1 data in the prediction skill of our bivariate models based on joint al index and @xmath1 observations .    as with any forecasting technique </S>",
    "<S> , the skill of diffusion forecasting depends strongly on the initial density @xmath35 . here , we perform forecast initialization using the bayesian filtering approach developed in @xcite . in particular , </S>",
    "<S> let @xmath63 be the ( unknown ) system state at forecast initialization time , @xmath64 , and @xmath65 be the corresponding al index and sw data . </S>",
    "<S> let also @xmath66 and @xmath67 with @xmath68 be the system states at the @xmath69 preceding timesteps to forecast initialization where @xmath69 represents a filter spinup time . </S>",
    "<S> the scheme of @xcite utilizes the familiar predictor - corrector approach from data assimilation to construct an initial density @xmath70 on the training data @xmath71 that approximates the conditional density @xmath72 . </S>",
    "<S> the method employs a gaussian likelihood @xmath73 , where the variance @xmath74 is estimated from the reconstruction error of the training data for the @xmath75 eigenfunctions used in the diffusion forecast model ; i.e. , @xmath76 , where @xmath77 . </S>",
    "<S> in the first filtering timestep we use a uniform prior , @xmath78 , which we update to the posterior @xmath79 using bayes rule ( here , @xmath80 is a normalization factor computed via ergodic averages ) . </S>",
    "<S> the density @xmath81 is then updated using the diffusion forecast model to obtain the prior @xmath82 via  . repeating this procedure @xmath83 times , we arrive at the density @xmath84 which we use as the initial condition for the diffusion forecast model . </S>",
    "<S> given the predicted probability densities from diffusion forecasting , we perform probabilistic al index prediction by computing the probabilities @xmath85 for the al index to be smaller than pre - selected thresholds @xmath86 . </S>",
    "<S> these probabilities are given by @xmath87 , where @xmath88 is the indicator function of the subset @xmath89 . </S>",
    "<S> numerically , we approximate @xmath90 by identifying the timestamps @xmath91 in the training dataset where the al index is smaller than the given threshold , and evaluating @xmath92 .     for @xmath93 nt ( horizontal magenta line ) at lead times @xmath94 minutes . </S>",
    "<S> green and red lines show the predictions based on the bivariate and univariate models , respectively . </S>",
    "<S> the vertical doted lines indicate the interval shown in detail in fig .  </S>",
    "<S> [ figzoom ] . ]    , but for the interval 5/9/2003 11:15 utc to 5/12/2003 22:35 utc . </S>",
    "<S> note the skill improvement of the bivariate model trained on al and @xmath1 data ( green line ) over the univariate model trained on al data alone ( red line ) . ]    </S>",
    "<S> figure  [ figure1 ] displays the probabilities @xmath95 for running forecasts from 3/1/2003 0:35 utc to 3/4/2003 11:55 utc ( a disjoint interval from the training data ) and lead times @xmath56 in the range 2080 minutes . in each panel , we show the al index superimposed with the probabilities @xmath95 for the univariate and bivariate models trained by the al index alone and joint @xmath96 data , respectively . </S>",
    "<S> the threshold is @xmath93 nt which corresponds to one standard deviation below the al index mean . in fig .  </S>",
    "<S> [ figure1 ] , significant decreases of the al index have a clear correspondence with high probability , predicted by our model , that the al magnitude will cross the threshold at lead @xmath56 . </S>",
    "<S> moreover , it is evident that the bivariate model provides improved long - term forecasts . </S>",
    "<S> for instance , for the substorm shown in detail in fig .  </S>",
    "<S> [ figzoom ] , the bivariate model gives predictions with higher probabilities compared to those of the univariate model when the al index is actually smaller than @xmath97 and lower probabilities when the al exceeds @xmath97 . </S>",
    "<S> these differences persist even for smaller thresholds ( see si ) . </S>",
    "<S> the higher skill of the bivariate model is to be expected since magnetospheric substorms are highly driven by changes in the solar wind .    to compare the performance of these two models in a more quantitative manner </S>",
    "<S> , we compute the receiver operating characteristic ( roc ) used for evaluating a binary classifier system . here , we use the roc to assess the skill of predictions for the al index to lie below the threshold @xmath86 . in fig .  </S>",
    "<S> [ figure3 ] , we show the true positive rate ( tpr ) versus false positive rate ( fpr ) , which are defined as follows . the tpr is defined as the ratio between the number of times the prediction that the al index below @xmath86 is correct and the number of times the al index is below @xmath86 . </S>",
    "<S> the fpr is defined as the ratio between the number of times the prediction that the al index is below @xmath86 is incorrect and the number of times the al index is above @xmath86 . for a skillful prediction </S>",
    "<S> tpr should be close to 1 while fpr should be close to 0 . </S>",
    "<S> from the training data , we can count that the al index is below the thresholds @xmath98 , @xmath99 , @xmath100 , and @xmath101 nt for 37.0% , 14.3% , 5.24% , and 1.81% of the time , respectively ( see the triangles in fig.[figure3 ] ) . for a prediction scheme based on drawing randomly from the training dataset , </S>",
    "<S> then we predict 37% of the time that the al index is below the threshold @xmath102 nt regardless of whether the index is below the threshold or not . for this trivial prediction scheme , </S>",
    "<S> the tpr and fpr of the al index to be below that threshold are both equal to @xmath103 . with a similar strategy , </S>",
    "<S> the tpr and fpr of the al index to be below the thresholds @xmath104 and @xmath105 nt are 0.143 and 0.0524 , respectively . </S>",
    "<S> in fact , the roc curve for this prediction strategy is given by the @xmath106 diagonal .     </S>",
    "<S> data ( dashed ) and the model trained with al data alone ( solid ) . in each curve , circles denote the thresholds indicated in the main text from the smaller values ( with larger tpr ) to the larger values ( with smaller tpr ) . </S>",
    "<S> triangles indicate the roc values for a trivial random forecast lying on the @xmath107 line.,scaledwidth=40.0% ]    .[figure3 ]    for diffusion forecasting , the tpr is simply the average of @xmath108 on timestamps where the al index is below @xmath86 in the verification period . </S>",
    "<S> similarly , the fpr is the average of @xmath108 on timestamps where the al index is above @xmath86 . </S>",
    "<S> figure  [ figure3 ] shows the roc curves for both the bivariate and univariate models . </S>",
    "<S> as expected , the @xmath109 ratios decrease with increasing leads . </S>",
    "<S> an important observation is that the tpr values from our nonparametric models always exceed the corresponding fprs , which implies that they are more skillful than randomly drawing from the training dataset . </S>",
    "<S> note that for @xmath110 minutes the bivariate model gives higher tpr ( as well as lower fpr ) than the univariate model . </S>",
    "<S> this long - term improvement occurs despite the fact that at short leads ( e.g. , 10 minutes ) the univariate model performs better ; this is due to apparently better initial conditions with the univariate filter . </S>",
    "<S> a similar overall behavior is also observed for the year 2000 dataset ( see si ) .    in this paper , we have studied al index prediction with the diffusion forecast model  a nonparametric autonomous model that approximates the fokker - planck equation of the underlying processes at arbitrary lead times . </S>",
    "<S> the forecasting outputs are probabilities that the al index is below a user - defined threshold , which indicates the occurrence of a substorm . </S>",
    "<S> we found that the model trained with both the al index and sw data time series gives higher ( lower ) probabilities on time intervals when the al index is lower ( higher ) than the given threshold . </S>",
    "<S> this high prediction skill becomes more apparent at lead times 4080 minutes . </S>",
    "<S> we also assessed the forecast skill with the roc metric and found that diffusion forecasting has significantly higher skill than trivial forecasts based on random draws from the training data set , even for longer lead times such as 60120 minutes .    </S>",
    "<S> this research was supported by the onr muri grant n00014 - 12 - 1 - 0912 . </S>",
    "<S> d.g .  received support from onr grant n00014 - 14 - 1 - 0150 and onr yip grant n00014 - 16 - 1 - 2649 . </S>",
    "<S> m.g .  received support from nsf grant ags-1303646 . </S>",
    "<S> j.h .  received support from onr grant n00014 - 16 - 1 - 2888 and nsf grant dms-1317919 . </S>",
    "<S> j.h .  </S>",
    "<S> also thanks kayo ide who brought this problem to his attention . </S>"
  ]
}